{"created":"2023-11-21 18:59:58","title":"Physics-guided Shape-from-Template: Monocular Video Perception through Neural Surrogate Models","abstract":"3D reconstruction of dynamic scenes is a long-standing problem in computer graphics and increasingly difficult the less information is available. Shape-from-Template (SfT) methods aim to reconstruct a template-based geometry from RGB images or video sequences, often leveraging just a single monocular camera without depth information, such as regular smartphone recordings. Unfortunately, existing reconstruction methods are either unphysical and noisy or slow in optimization. To solve this problem, we propose a novel SfT reconstruction algorithm for cloth using a pre-trained neural surrogate model that is fast to evaluate, stable, and produces smooth reconstructions due to a regularizing physics simulation. Differentiable rendering of the simulated mesh enables pixel-wise comparisons between the reconstruction and a target video sequence that can be used for a gradient-based optimization procedure to extract not only shape information but also physical parameters such as stretching, shearing, or bending stiffness of the cloth. This allows to retain a precise, stable, and smooth reconstructed geometry while reducing the runtime by a factor of 400-500 compared to $\\phi$-SfT, a state-of-the-art physics-based SfT approach.","sentences":["3D reconstruction of dynamic scenes is a long-standing problem in computer graphics and increasingly difficult the less information is available.","Shape-from-Template (SfT) methods aim to reconstruct a template-based geometry from RGB images or video sequences, often leveraging just a single monocular camera without depth information, such as regular smartphone recordings.","Unfortunately, existing reconstruction methods are either unphysical and noisy or slow in optimization.","To solve this problem, we propose a novel SfT reconstruction algorithm for cloth using a pre-trained neural surrogate model that is fast to evaluate, stable, and produces smooth reconstructions due to a regularizing physics simulation.","Differentiable rendering of the simulated mesh enables pixel-wise comparisons between the reconstruction and a target video sequence that can be used for a gradient-based optimization procedure to extract not only shape information but also physical parameters such as stretching, shearing, or bending stiffness of the cloth.","This allows to retain a precise, stable, and smooth reconstructed geometry while reducing the runtime by a factor of 400-500 compared to $\\phi$-SfT, a state-of-the-art physics-based SfT approach."],"url":"http://arxiv.org/abs/2311.12796v1"}
{"created":"2023-11-21 18:58:11","title":"ShareGPT4V: Improving Large Multi-Modal Models with Better Captions","abstract":"In the realm of large multi-modal models (LMMs), efficient modality alignment is crucial yet often constrained by the scarcity of high-quality image-text data. To address this bottleneck, we introduce the ShareGPT4V dataset, a pioneering large-scale resource featuring 1.2 million highly descriptive captions, which surpasses existing datasets in diversity and information content, covering world knowledge, object properties, spatial relationships, and aesthetic evaluations. Specifically, ShareGPT4V originates from a curated 100K high-quality captions collected from advanced GPT4-Vision and has been expanded to 1.2M with a superb caption model trained on this subset. ShareGPT4V first demonstrates its effectiveness for the Supervised Fine-Tuning (SFT) phase, by substituting an equivalent quantity of detailed captions in existing SFT datasets with a subset of our high-quality captions, significantly enhancing the LMMs like LLaVA-7B, LLaVA-1.5-13B, and Qwen-VL-Chat-7B on the MME and MMBench benchmarks, with respective gains of 222.8/22.0/22.3 and 2.7/1.3/1.5. We further incorporate ShareGPT4V data into both the pre-training and SFT phases, obtaining ShareGPT4V-7B, a superior LMM based on a simple architecture that has remarkable performance across a majority of the multi-modal benchmarks. This project is available at https://ShareGPT4V.github.io to serve as a pivotal resource for advancing the LMMs community.","sentences":["In the realm of large multi-modal models (LMMs), efficient modality alignment is crucial yet often constrained by the scarcity of high-quality image-text data.","To address this bottleneck, we introduce the ShareGPT4V dataset, a pioneering large-scale resource featuring 1.2 million highly descriptive captions, which surpasses existing datasets in diversity and information content, covering world knowledge, object properties, spatial relationships, and aesthetic evaluations.","Specifically, ShareGPT4V originates from a curated 100K high-quality captions collected from advanced GPT4-Vision and has been expanded to 1.2M with a superb caption model trained on this subset.","ShareGPT4V first demonstrates its effectiveness for the Supervised Fine-Tuning (SFT) phase, by substituting an equivalent quantity of detailed captions in existing SFT datasets with a subset of our high-quality captions, significantly enhancing the LMMs like LLaVA-7B, LLaVA-1.5-13B, and Qwen-VL-Chat-7B on the MME and MMBench benchmarks, with respective gains of 222.8/22.0/22.3 and 2.7/1.3/1.5.","We further incorporate ShareGPT4V data into both the pre-training and SFT phases, obtaining ShareGPT4V-7B, a superior LMM based on a simple architecture that has remarkable performance across a majority of the multi-modal benchmarks.","This project is available at https://ShareGPT4V.github.io to serve as a pivotal resource for advancing the LMMs community."],"url":"http://arxiv.org/abs/2311.12793v1"}
{"created":"2023-11-21 18:58:01","title":"Intrinsic Image Decomposition via Ordinal Shading","abstract":"Intrinsic decomposition is a fundamental mid-level vision problem that plays a crucial role in various inverse rendering and computational photography pipelines. Generating highly accurate intrinsic decompositions is an inherently under-constrained task that requires precisely estimating continuous-valued shading and albedo. In this work, we achieve high-resolution intrinsic decomposition by breaking the problem into two parts. First, we present a dense ordinal shading formulation using a shift- and scale-invariant loss in order to estimate ordinal shading cues without restricting the predictions to obey the intrinsic model. We then combine low- and high-resolution ordinal estimations using a second network to generate a shading estimate with both global coherency and local details. We encourage the model to learn an accurate decomposition by computing losses on the estimated shading as well as the albedo implied by the intrinsic model. We develop a straightforward method for generating dense pseudo ground truth using our model's predictions and multi-illumination data, enabling generalization to in-the-wild imagery. We present an exhaustive qualitative and quantitative analysis of our predicted intrinsic components against state-of-the-art methods. Finally, we demonstrate the real-world applicability of our estimations by performing otherwise difficult editing tasks such as recoloring and relighting.","sentences":["Intrinsic decomposition is a fundamental mid-level vision problem that plays a crucial role in various inverse rendering and computational photography pipelines.","Generating highly accurate intrinsic decompositions is an inherently under-constrained task that requires precisely estimating continuous-valued shading and albedo.","In this work, we achieve high-resolution intrinsic decomposition by breaking the problem into two parts.","First, we present a dense ordinal shading formulation using a shift- and scale-invariant loss in order to estimate ordinal shading cues without restricting the predictions to obey the intrinsic model.","We then combine low-","and high-resolution ordinal estimations using a second network to generate a shading estimate with both global coherency and local details.","We encourage the model to learn an accurate decomposition by computing losses on the estimated shading as well as the albedo implied by the intrinsic model.","We develop a straightforward method for generating dense pseudo ground truth using our model's predictions and multi-illumination data, enabling generalization to in-the-wild imagery.","We present an exhaustive qualitative and quantitative analysis of our predicted intrinsic components against state-of-the-art methods.","Finally, we demonstrate the real-world applicability of our estimations by performing otherwise difficult editing tasks such as recoloring and relighting."],"url":"http://arxiv.org/abs/2311.12792v1"}
{"created":"2023-11-21 18:51:04","title":"Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks","abstract":"Fine-tuning large pre-trained models has become the de facto strategy for developing both task-specific and general-purpose machine learning systems, including developing models that are safe to deploy. Despite its clear importance, there has been minimal work that explains how fine-tuning alters the underlying capabilities learned by a model during pretraining: does fine-tuning yield entirely novel capabilities or does it just modulate existing ones? We address this question empirically in synthetic, controlled settings where we can use mechanistic interpretability tools (e.g., network pruning and probing) to understand how the model's underlying capabilities are changing. We perform an extensive analysis of the effects of fine-tuning in these settings, and show that: (i) fine-tuning rarely alters the underlying model capabilities; (ii) a minimal transformation, which we call a 'wrapper', is typically learned on top of the underlying model capabilities, creating the illusion that they have been modified; and (iii) further fine-tuning on a task where such hidden capabilities are relevant leads to sample-efficient 'revival' of the capability, i.e., the model begins reusing these capability after only a few gradient steps. This indicates that practitioners can unintentionally remove a model's safety wrapper merely by fine-tuning it on a, e.g., superficially unrelated, downstream task. We additionally perform analysis on language models trained on the TinyStories dataset to support our claims in a more realistic setup.","sentences":["Fine-tuning large pre-trained models has become the de facto strategy for developing both task-specific and general-purpose machine learning systems, including developing models that are safe to deploy.","Despite its clear importance, there has been minimal work that explains how fine-tuning alters the underlying capabilities learned by a model during pretraining: does fine-tuning yield entirely novel capabilities or does it just modulate existing ones?","We address this question empirically in synthetic, controlled settings where we can use mechanistic interpretability tools (e.g., network pruning and probing) to understand how the model's underlying capabilities are changing.","We perform an extensive analysis of the effects of fine-tuning in these settings, and show that: (i) fine-tuning rarely alters the underlying model capabilities; (ii) a minimal transformation, which we call a 'wrapper', is typically learned on top of the underlying model capabilities, creating the illusion that they have been modified; and (iii) further fine-tuning on a task where such hidden capabilities are relevant leads to sample-efficient 'revival' of the capability, i.e., the model begins reusing these capability after only a few gradient steps.","This indicates that practitioners can unintentionally remove a model's safety wrapper merely by fine-tuning it on a, e.g., superficially unrelated, downstream task.","We additionally perform analysis on language models trained on the TinyStories dataset to support our claims in a more realistic setup."],"url":"http://arxiv.org/abs/2311.12786v1"}
{"created":"2023-11-21 18:51:03","title":"Prompting Frameworks for Large Language Models: A Survey","abstract":"Since the launch of ChatGPT, a powerful AI Chatbot developed by OpenAI, large language models (LLMs) have made significant advancements in both academia and industry, bringing about a fundamental engineering paradigm shift in many areas. While LLMs are powerful, it is also crucial to best use their power where \"prompt'' plays a core role. However, the booming LLMs themselves, including excellent APIs like ChatGPT, have several inherent limitations: 1) temporal lag of training data, and 2) the lack of physical capabilities to perform external actions. Recently, we have observed the trend of utilizing prompt-based tools to better utilize the power of LLMs for downstream tasks, but a lack of systematic literature and standardized terminology, partly due to the rapid evolution of this field. Therefore, in this work, we survey related prompting tools and promote the concept of the \"Prompting Framework\" (PF), i.e. the framework for managing, simplifying, and facilitating interaction with large language models. We define the lifecycle of the PF as a hierarchical structure, from bottom to top, namely: Data Level, Base Level, Execute Level, and Service Level. We also systematically depict the overall landscape of the emerging PF field and discuss potential future research and challenges. To continuously track the developments in this area, we maintain a repository at https://github.com/lxx0628/Prompting-Framework-Survey, which can be a useful resource sharing platform for both academic and industry in this field.","sentences":["Since the launch of ChatGPT, a powerful AI Chatbot developed by OpenAI, large language models (LLMs) have made significant advancements in both academia and industry, bringing about a fundamental engineering paradigm shift in many areas.","While LLMs are powerful, it is also crucial to best use their power where \"prompt'' plays a core role.","However, the booming LLMs themselves, including excellent APIs like ChatGPT, have several inherent limitations: 1) temporal lag of training data, and 2) the lack of physical capabilities to perform external actions.","Recently, we have observed the trend of utilizing prompt-based tools to better utilize the power of LLMs for downstream tasks, but a lack of systematic literature and standardized terminology, partly due to the rapid evolution of this field.","Therefore, in this work, we survey related prompting tools and promote the concept of the \"Prompting Framework\" (PF), i.e. the framework for managing, simplifying, and facilitating interaction with large language models.","We define the lifecycle of the PF as a hierarchical structure, from bottom to top, namely: Data Level, Base Level, Execute Level, and Service Level.","We also systematically depict the overall landscape of the emerging PF field and discuss potential future research and challenges.","To continuously track the developments in this area, we maintain a repository at https://github.com/lxx0628/Prompting-Framework-Survey, which can be a useful resource sharing platform for both academic and industry in this field."],"url":"http://arxiv.org/abs/2311.12785v1"}
{"created":"2023-11-21 18:45:52","title":"Quantifying Impairment and Disease Severity Using AI Models Trained on Healthy Subjects","abstract":"Automatic assessment of impairment and disease severity is a key challenge in data-driven medicine. We propose a novel framework to address this challenge, which leverages AI models trained exclusively on healthy individuals. The COnfidence-Based chaRacterization of Anomalies (COBRA) score exploits the decrease in confidence of these models when presented with impaired or diseased patients to quantify their deviation from the healthy population. We applied the COBRA score to address a key limitation of current clinical evaluation of upper-body impairment in stroke patients. The gold-standard Fugl-Meyer Assessment (FMA) requires in-person administration by a trained assessor for 30-45 minutes, which restricts monitoring frequency and precludes physicians from adapting rehabilitation protocols to the progress of each patient. The COBRA score, computed automatically in under one minute, is shown to be strongly correlated with the FMA on an independent test cohort for two different data modalities: wearable sensors ($\\rho = 0.845$, 95% CI [0.743,0.908]) and video ($\\rho = 0.746$, 95% C.I [0.594, 0.847]). To demonstrate the generalizability of the approach to other conditions, the COBRA score was also applied to quantify severity of knee osteoarthritis from magnetic-resonance imaging scans, again achieving significant correlation with an independent clinical assessment ($\\rho = 0.644$, 95% C.I [0.585,0.696]).","sentences":["Automatic assessment of impairment and disease severity is a key challenge in data-driven medicine.","We propose a novel framework to address this challenge, which leverages AI models trained exclusively on healthy individuals.","The COnfidence-Based chaRacterization of Anomalies (COBRA) score exploits the decrease in confidence of these models when presented with impaired or diseased patients to quantify their deviation from the healthy population.","We applied the COBRA score to address a key limitation of current clinical evaluation of upper-body impairment in stroke patients.","The gold-standard Fugl-Meyer Assessment (FMA) requires in-person administration by a trained assessor for 30-45 minutes, which restricts monitoring frequency and precludes physicians from adapting rehabilitation protocols to the progress of each patient.","The COBRA score, computed automatically in under one minute, is shown to be strongly correlated with the FMA on an independent test cohort for two different data modalities: wearable sensors ($\\rho = 0.845$, 95% CI","[0.743,0.908]) and video ($\\rho = 0.746$, 95% C.I [0.594, 0.847]).","To demonstrate the generalizability of the approach to other conditions, the COBRA score was also applied to quantify severity of knee osteoarthritis from magnetic-resonance imaging scans, again achieving significant correlation with an independent clinical assessment ($\\rho = 0.644$, 95% C.I","[0.585,0.696])."],"url":"http://arxiv.org/abs/2311.12781v1"}
{"created":"2023-11-21 18:43:16","title":"Finding Adversarial Inputs for Heuristics using Multi-level Optimization","abstract":"Production systems use heuristics because they are faster or scale better than their optimal counterparts. Yet, practitioners are often unaware of the performance gap between a heuristic and the optimum or between two heuristics in realistic scenarios. We present MetaOpt, a system that helps analyze heuristics. Users specify the heuristic and the optimal (or another heuristic) as input, and MetaOpt automatically encodes these efficiently for a solver to find performance gaps and their corresponding adversarial inputs. Its suite of built-in optimizations helps it scale its analysis to practical problem sizes. To show it is versatile, we used MetaOpt to analyze heuristics from three domains (traffic engineering, vector bin packing, and packet scheduling). We found a production traffic engineering heuristic can require 30% more capacity than the optimal to satisfy realistic demands. Based on the patterns in the adversarial inputs MetaOpt produced, we modified the heuristic to reduce its performance gap by 12.5$\\times$. We examined adversarial inputs to a vector bin packing heuristic and proved a new lower bound on its performance.","sentences":["Production systems use heuristics because they are faster or scale better than their optimal counterparts.","Yet, practitioners are often unaware of the performance gap between a heuristic and the optimum or between two heuristics in realistic scenarios.","We present MetaOpt, a system that helps analyze heuristics.","Users specify the heuristic and the optimal (or another heuristic) as input, and MetaOpt automatically encodes these efficiently for a solver to find performance gaps and their corresponding adversarial inputs.","Its suite of built-in optimizations helps it scale its analysis to practical problem sizes.","To show it is versatile, we used MetaOpt to analyze heuristics from three domains (traffic engineering, vector bin packing, and packet scheduling).","We found a production traffic engineering heuristic can require 30% more capacity than the optimal to satisfy realistic demands.","Based on the patterns in the adversarial inputs MetaOpt produced, we modified the heuristic to reduce its performance gap by 12.5$\\times$. We examined adversarial inputs to a vector bin packing heuristic and proved a new lower bound on its performance."],"url":"http://arxiv.org/abs/2311.12779v1"}
{"created":"2023-11-21 18:39:55","title":"Calibration System and Algorithm Design for a Soft Hinged Micro Scanning Mirror with a Triaxial Hall Effect Sensor","abstract":"We report a new calibration system and algorithm design for micro scanning mirrors (MSMs) which are an important component in many active sensors used in robotic applications. In fact, our MSM is a 3 degree-of-freedom soft-hinged robot with a triaxial Hall sensor as feedback. Our calibration rig design employs a minimal 2-laser beam approach and the new algorithm builds on reflection principle to precisely measure MSM poses. To establish the mapping between Hall sensor readings and MSM poses, we propose a self-synchronizing periodicity-based model fitting calibration approach. We achieve an MSM poses estimation accuracy of 0.020{\\deg} with a standard deviation of 0.011{\\deg}.","sentences":["We report a new calibration system and algorithm design for micro scanning mirrors (MSMs) which are an important component in many active sensors used in robotic applications.","In fact, our MSM is a 3 degree-of-freedom soft-hinged robot with a triaxial Hall sensor as feedback.","Our calibration rig design employs a minimal 2-laser beam approach and the new algorithm builds on reflection principle to precisely measure MSM poses.","To establish the mapping between Hall sensor readings and MSM poses, we propose a self-synchronizing periodicity-based model fitting calibration approach.","We achieve an MSM poses estimation accuracy of 0.020{\\deg} with a standard deviation of 0.011{\\deg}."],"url":"http://arxiv.org/abs/2311.12778v1"}
{"created":"2023-11-21 18:38:03","title":"SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh Rendering","abstract":"We propose a method to allow precise and extremely fast mesh extraction from 3D Gaussian Splatting. Gaussian Splatting has recently become very popular as it yields realistic rendering while being significantly faster to train than NeRFs. It is however challenging to extract a mesh from the millions of tiny 3D gaussians as these gaussians tend to be unorganized after optimization and no method has been proposed so far. Our first key contribution is a regularization term that encourages the gaussians to align well with the surface of the scene. We then introduce a method that exploits this alignment to extract a mesh from the Gaussians using Poisson reconstruction, which is fast, scalable, and preserves details, in contrast to the Marching Cubes algorithm usually applied to extract meshes from Neural SDFs. Finally, we introduce an optional refinement strategy that binds gaussians to the surface of the mesh, and jointly optimizes these Gaussians and the mesh through Gaussian splatting rendering. This enables easy editing, sculpting, rigging, animating, compositing and relighting of the Gaussians using traditional softwares by manipulating the mesh instead of the gaussians themselves. Retrieving such an editable mesh for realistic rendering is done within minutes with our method, compared to hours with the state-of-the-art methods on neural SDFs, while providing a better rendering quality.","sentences":["We propose a method to allow precise and extremely fast mesh extraction from 3D Gaussian Splatting.","Gaussian Splatting has recently become very popular as it yields realistic rendering while being significantly faster to train than NeRFs.","It is however challenging to extract a mesh from the millions of tiny 3D gaussians as these gaussians tend to be unorganized after optimization and no method has been proposed so far.","Our first key contribution is a regularization term that encourages the gaussians to align well with the surface of the scene.","We then introduce a method that exploits this alignment to extract a mesh from the Gaussians using Poisson reconstruction, which is fast, scalable, and preserves details, in contrast to the Marching Cubes algorithm usually applied to extract meshes from Neural SDFs.","Finally, we introduce an optional refinement strategy that binds gaussians to the surface of the mesh, and jointly optimizes these Gaussians and the mesh through Gaussian splatting rendering.","This enables easy editing, sculpting, rigging, animating, compositing and relighting of the Gaussians using traditional softwares by manipulating the mesh instead of the gaussians themselves.","Retrieving such an editable mesh for realistic rendering is done within minutes with our method, compared to hours with the state-of-the-art methods on neural SDFs, while providing a better rendering quality."],"url":"http://arxiv.org/abs/2311.12775v1"}
{"created":"2023-11-21 18:35:21","title":"Iris Presentation Attack: Assessing the Impact of Combining Vanadium Dioxide Films with Artificial Eyes","abstract":"Iris recognition systems, operating in the near infrared spectrum (NIR), have demonstrated vulnerability to presentation attacks, where an adversary uses artifacts such as cosmetic contact lenses, artificial eyes or printed iris images in order to circumvent the system. At the same time, a number of effective presentation attack detection (PAD) methods have been developed. These methods have demonstrated success in detecting artificial eyes (e.g., fake Van Dyke eyes) as presentation attacks. In this work, we seek to alter the optical characteristics of artificial eyes by affixing Vanadium Dioxide (VO2) films on their surface in various spatial configurations. VO2 films can be used to selectively transmit NIR light and can, therefore, be used to regulate the amount of NIR light from the object that is captured by the iris sensor. We study the impact of such images produced by the sensor on two state-of-the-art iris PA detection methods. We observe that the addition of VO2 films on the surface of artificial eyes can cause the PA detection methods to misclassify them as bonafide eyes in some cases. This represents a vulnerability that must be systematically analyzed and effectively addressed.","sentences":["Iris recognition systems, operating in the near infrared spectrum (NIR), have demonstrated vulnerability to presentation attacks, where an adversary uses artifacts such as cosmetic contact lenses, artificial eyes or printed iris images in order to circumvent the system.","At the same time, a number of effective presentation attack detection (PAD) methods have been developed.","These methods have demonstrated success in detecting artificial eyes (e.g., fake Van Dyke eyes) as presentation attacks.","In this work, we seek to alter the optical characteristics of artificial eyes by affixing Vanadium Dioxide (VO2) films on their surface in various spatial configurations.","VO2 films can be used to selectively transmit NIR light and can, therefore, be used to regulate the amount of NIR light from the object that is captured by the iris sensor.","We study the impact of such images produced by the sensor on two state-of-the-art iris PA detection methods.","We observe that the addition of VO2 films on the surface of artificial eyes can cause the PA detection methods to misclassify them as bonafide eyes in some cases.","This represents a vulnerability that must be systematically analyzed and effectively addressed."],"url":"http://arxiv.org/abs/2311.12773v1"}
{"created":"2023-11-21 18:32:05","title":"The T-Complexity Costs of Error Correction for Control Flow in Quantum Computation","abstract":"Numerous quantum algorithms require the use of quantum error correction to overcome the intrinsic unreliability of physical qubits. However, error correction imposes a unique performance bottleneck, known as T-complexity, that can make an implementation of an algorithm as a quantum program run more slowly than on idealized hardware. In this work, we identify that programming abstractions for control flow, such as the quantum if-statement, can introduce polynomial increases in the T-complexity of a program. If not mitigated, this slowdown can diminish the computational advantage of a quantum algorithm.   To enable reasoning about the costs of control flow, we present a cost model, using which a developer can analyze the T-complexity of a program under quantum error correction and pinpoint the sources of slowdown. We also present a set of program-level optimizations, using which a developer can rewrite a program to reduce its T-complexity, predict the T-complexity of the optimized program using the cost model, and then compile it to an efficient circuit via a straightforward strategy.   We implement the program-level optimizations in Spire, an extension of the Tower quantum compiler. Using a set of 11 benchmark programs that use control flow, we show that the cost model is accurate, and that Spire's optimizations recover programs that are asymptotically efficient, meaning their runtime T-complexity under error correction is equal to their time complexity on idealized hardware.   Our results show that optimizing a program before it is compiled to a circuit can yield better results than compiling the program to an inefficient circuit and then invoking a quantum circuit optimizer found in prior work. For our benchmarks, only 2 of 8 existing circuit optimizers recover circuits with asymptotically efficient T-complexity. Compared to these 2 optimizers, Spire uses 54x to 2400x less compile time.","sentences":["Numerous quantum algorithms require the use of quantum error correction to overcome the intrinsic unreliability of physical qubits.","However, error correction imposes a unique performance bottleneck, known as T-complexity, that can make an implementation of an algorithm as a quantum program run more slowly than on idealized hardware.","In this work, we identify that programming abstractions for control flow, such as the quantum if-statement, can introduce polynomial increases in the T-complexity of a program.","If not mitigated, this slowdown can diminish the computational advantage of a quantum algorithm.   ","To enable reasoning about the costs of control flow, we present a cost model, using which a developer can analyze the T-complexity of a program under quantum error correction and pinpoint the sources of slowdown.","We also present a set of program-level optimizations, using which a developer can rewrite a program to reduce its T-complexity, predict the T-complexity of the optimized program using the cost model, and then compile it to an efficient circuit via a straightforward strategy.   ","We implement the program-level optimizations in Spire, an extension of the Tower quantum compiler.","Using a set of 11 benchmark programs that use control flow, we show that the cost model is accurate, and that Spire's optimizations recover programs that are asymptotically efficient, meaning their runtime T-complexity under error correction is equal to their time complexity on idealized hardware.   ","Our results show that optimizing a program before it is compiled to a circuit can yield better results than compiling the program to an inefficient circuit and then invoking a quantum circuit optimizer found in prior work.","For our benchmarks, only 2 of 8 existing circuit optimizers recover circuits with asymptotically efficient T-complexity.","Compared to these 2 optimizers, Spire uses 54x to 2400x less compile time."],"url":"http://arxiv.org/abs/2311.12772v1"}
{"created":"2023-11-21 18:18:50","title":"Investigating Weight-Perturbed Deep Neural Networks With Application in Iris Presentation Attack Detection","abstract":"Deep neural networks (DNNs) exhibit superior performance in various machine learning tasks, e.g., image classification, speech recognition, biometric recognition, object detection, etc. However, it is essential to analyze their sensitivity to parameter perturbations before deploying them in real-world applications. In this work, we assess the sensitivity of DNNs against perturbations to their weight and bias parameters. The sensitivity analysis involves three DNN architectures (VGG, ResNet, and DenseNet), three types of parameter perturbations (Gaussian noise, weight zeroing, and weight scaling), and two settings (entire network and layer-wise). We perform experiments in the context of iris presentation attack detection and evaluate on two publicly available datasets: LivDet-Iris-2017 and LivDet-Iris-2020. Based on the sensitivity analysis, we propose improved models simply by perturbing parameters of the network without undergoing training. We further combine these perturbed models at the score-level and at the parameter-level to improve the performance over the original model. The ensemble at the parameter-level shows an average improvement of 43.58% on the LivDet-Iris-2017 dataset and 9.25% on the LivDet-Iris-2020 dataset. The source code is available at \\href{https://github.com/redwankarimsony/WeightPerturbation-MSU}{https://github.com/redwankarimsony/WeightPerturbation-MSU}.","sentences":["Deep neural networks (DNNs) exhibit superior performance in various machine learning tasks, e.g., image classification, speech recognition, biometric recognition, object detection, etc.","However, it is essential to analyze their sensitivity to parameter perturbations before deploying them in real-world applications.","In this work, we assess the sensitivity of DNNs against perturbations to their weight and bias parameters.","The sensitivity analysis involves three DNN architectures (VGG, ResNet, and DenseNet), three types of parameter perturbations (Gaussian noise, weight zeroing, and weight scaling), and two settings (entire network and layer-wise).","We perform experiments in the context of iris presentation attack detection and evaluate on two publicly available datasets: LivDet-Iris-2017 and LivDet-Iris-2020.","Based on the sensitivity analysis, we propose improved models simply by perturbing parameters of the network without undergoing training.","We further combine these perturbed models at the score-level and at the parameter-level to improve the performance over the original model.","The ensemble at the parameter-level shows an average improvement of 43.58% on the LivDet-Iris-2017 dataset and 9.25% on the LivDet-Iris-2020 dataset.","The source code is available at \\href{https://github.com/redwankarimsony/WeightPerturbation-MSU}{https://github.com/redwankarimsony/WeightPerturbation-MSU}."],"url":"http://arxiv.org/abs/2311.12764v1"}
{"created":"2023-11-21 18:11:26","title":"High-resolution Image-based Malware Classification using Multiple Instance Learning","abstract":"This paper proposes a novel method of classifying malware into families using high-resolution greyscale images and multiple instance learning to overcome adversarial binary enlargement. Current methods of visualisation-based malware classification largely rely on lossy transformations of inputs such as resizing to handle the large, variable-sized images. Through empirical analysis and experimentation, it is shown that these approaches cause crucial information loss that can be exploited. The proposed solution divides the images into patches and uses embedding-based multiple instance learning with a convolutional neural network and an attention aggregation function for classification. The implementation is evaluated on the Microsoft Malware Classification dataset and achieves accuracies of up to $96.6\\%$ on adversarially enlarged samples compared to the baseline of $22.8\\%$. The Python code is available online at https://github.com/timppeters/MIL-Malware-Images .","sentences":["This paper proposes a novel method of classifying malware into families using high-resolution greyscale images and multiple instance learning to overcome adversarial binary enlargement.","Current methods of visualisation-based malware classification largely rely on lossy transformations of inputs such as resizing to handle the large, variable-sized images.","Through empirical analysis and experimentation, it is shown that these approaches cause crucial information loss that can be exploited.","The proposed solution divides the images into patches and uses embedding-based multiple instance learning with a convolutional neural network and an attention aggregation function for classification.","The implementation is evaluated on the Microsoft Malware Classification dataset and achieves accuracies of up to $96.6\\%$ on adversarially enlarged samples compared to the baseline of $22.8\\%$.","The Python code is available online at https://github.com/timppeters/MIL-Malware-Images ."],"url":"http://arxiv.org/abs/2311.12760v1"}
{"created":"2023-11-21 18:02:52","title":"Digital Twin Framework for Optimal and Autonomous Decision-Making in Cyber-Physical Systems: Enhancing Reliability and Adaptability in the Oil and Gas Industry","abstract":"The concept of creating a virtual copy of a complete Cyber-Physical System opens up numerous possibilities, including real-time assessments of the physical environment and continuous learning from the system to provide reliable and precise information. This process, known as the twinning process or the development of a digital twin (DT), has been widely adopted across various industries. However, challenges arise when considering the computational demands of implementing AI models, such as those employed in digital twins, in real-time information exchange scenarios. This work proposes a digital twin framework for optimal and autonomous decision-making applied to a gas-lift process in the oil and gas industry, focusing on enhancing the robustness and adaptability of the DT. The framework combines Bayesian inference, Monte Carlo simulations, transfer learning, online learning, and novel strategies to confer cognition to the DT, including model hyperdimensional reduction and cognitive tack. Consequently, creating a framework for efficient, reliable, and trustworthy DT identification was possible. The proposed approach addresses the current gap in the literature regarding integrating various learning techniques and uncertainty management in digital twin strategies. This digital twin framework aims to provide a reliable and efficient system capable of adapting to changing environments and incorporating prediction uncertainty, thus enhancing the overall decision-making process in complex, real-world scenarios. Additionally, this work lays the foundation for further developments in digital twins for process systems engineering, potentially fostering new advancements and applications across various industrial sectors.","sentences":["The concept of creating a virtual copy of a complete Cyber-Physical System opens up numerous possibilities, including real-time assessments of the physical environment and continuous learning from the system to provide reliable and precise information.","This process, known as the twinning process or the development of a digital twin (DT), has been widely adopted across various industries.","However, challenges arise when considering the computational demands of implementing AI models, such as those employed in digital twins, in real-time information exchange scenarios.","This work proposes a digital twin framework for optimal and autonomous decision-making applied to a gas-lift process in the oil and gas industry, focusing on enhancing the robustness and adaptability of the DT.","The framework combines Bayesian inference, Monte Carlo simulations, transfer learning, online learning, and novel strategies to confer cognition to the DT, including model hyperdimensional reduction and cognitive tack.","Consequently, creating a framework for efficient, reliable, and trustworthy DT identification was possible.","The proposed approach addresses the current gap in the literature regarding integrating various learning techniques and uncertainty management in digital twin strategies.","This digital twin framework aims to provide a reliable and efficient system capable of adapting to changing environments and incorporating prediction uncertainty, thus enhancing the overall decision-making process in complex, real-world scenarios.","Additionally, this work lays the foundation for further developments in digital twins for process systems engineering, potentially fostering new advancements and applications across various industrial sectors."],"url":"http://arxiv.org/abs/2311.12755v1"}
{"created":"2023-11-21 17:59:14","title":"SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction","abstract":"3D occupancy prediction is an important task for the robustness of vision-centric autonomous driving, which aims to predict whether each point is occupied in the surrounding 3D space. Existing methods usually require 3D occupancy labels to produce meaningful results. However, it is very laborious to annotate the occupancy status of each voxel. In this paper, we propose SelfOcc to explore a self-supervised way to learn 3D occupancy using only video sequences. We first transform the images into the 3D space (e.g., bird's eye view) to obtain 3D representation of the scene. We directly impose constraints on the 3D representations by treating them as signed distance fields. We can then render 2D images of previous and future frames as self-supervision signals to learn the 3D representations. We propose an MVS-embedded strategy to directly optimize the SDF-induced weights with multiple depth proposals. Our SelfOcc outperforms the previous best method SceneRF by 58.7% using a single frame as input on SemanticKITTI and is the first self-supervised work that produces reasonable 3D occupancy for surround cameras on Occ3D. SelfOcc produces high-quality depth and achieves state-of-the-art results on novel depth synthesis, monocular depth estimation, and surround-view depth estimation on the SemanticKITTI, KITTI-2015, and nuScenes, respectively. Code: https://github.com/huang-yh/SelfOcc.","sentences":["3D occupancy prediction is an important task for the robustness of vision-centric autonomous driving, which aims to predict whether each point is occupied in the surrounding 3D space.","Existing methods usually require 3D occupancy labels to produce meaningful results.","However, it is very laborious to annotate the occupancy status of each voxel.","In this paper, we propose SelfOcc to explore a self-supervised way to learn 3D occupancy using only video sequences.","We first transform the images into the 3D space (e.g., bird's eye view) to obtain 3D representation of the scene.","We directly impose constraints on the 3D representations by treating them as signed distance fields.","We can then render 2D images of previous and future frames as self-supervision signals to learn the 3D representations.","We propose an MVS-embedded strategy to directly optimize the SDF-induced weights with multiple depth proposals.","Our SelfOcc outperforms the previous best method SceneRF by 58.7% using a single frame as input on SemanticKITTI and is the first self-supervised work that produces reasonable 3D occupancy for surround cameras on Occ3D. SelfOcc produces high-quality depth and achieves state-of-the-art results on novel depth synthesis, monocular depth estimation, and surround-view depth estimation on the SemanticKITTI, KITTI-2015, and nuScenes, respectively.","Code: https://github.com/huang-yh/SelfOcc."],"url":"http://arxiv.org/abs/2311.12754v1"}
{"created":"2023-11-21 17:54:08","title":"An Improved Line-Point Low-Degree Test","abstract":"We prove that the most natural low-degree test for polynomials over finite fields is ``robust'' in the high-error regime for linear-sized fields. Specifically we consider the ``local'' agreement of a function $f: \\mathbb{F}_q^m \\to \\mathbb{F}_q$ from the space of degree-$d$ polynomials, i.e., the expected agreement of the function from univariate degree-$d$ polynomials over a randomly chosen line in $\\mathbb{F}_q^m$, and prove that if this local agreement is $\\epsilon \\geq \\Omega((\\frac{d}{q})^\\tau))$ for some fixed $\\tau > 0$, then there is a global degree-$d$ polynomial $Q: \\mathbb{F}_q^m \\to \\mathbb{F}_q$ with agreement nearly $\\epsilon$ with $f$. This settles a long-standing open question in the area of low-degree testing, yielding an $O(d)$-query robust test in the ``high-error'' regime (i.e., when $\\epsilon < \\frac{1}{2}$). The previous results in this space either required $\\epsilon > \\frac{1}{2}$ (Polishchuk \\& Spielman, STOC 1994), or $q = \\Omega(d^4)$ (Arora \\& Sudan, Combinatorica 2003), or needed to measure local distance on $2$-dimensional ``planes'' rather than one-dimensional lines leading to $\\Omega(d^2)$-query complexity (Raz \\& Safra, STOC 1997).   Our analysis follows the spirit of most previous analyses in first analyzing the low-variable case ($m = O(1)$) and then ``bootstrapping'' to general multivariate settings. Our main technical novelty is a new analysis in the bivariate setting that exploits a previously known connection between multivariate factorization and finding (or testing) low-degree polynomials, in a non ``black-box'' manner. A second contribution is a bootstrapping analysis which manages to lift analyses for $m=2$ directly to analyses for general $m$, where previous works needed to work with $m = 3$ or $m = 4$ -- arguably this bootstrapping is significantly simpler than those in prior works.","sentences":["We prove that the most natural low-degree test for polynomials over finite fields is ``robust'' in the high-error regime for linear-sized fields.","Specifically we consider the ``local'' agreement of a function $f: \\mathbb{F}_q^m \\to \\mathbb{F}_q$ from the space of degree-$d$ polynomials, i.e., the expected agreement of the function from univariate degree-$d$ polynomials over a randomly chosen line in $\\mathbb{F}_q^m$, and prove that if this local agreement is $\\epsilon \\geq \\Omega((\\frac{d}{q})^\\tau))$ for some fixed $\\tau > 0$, then there is a global degree-$d$ polynomial $Q: \\mathbb{F}_q^m \\to \\mathbb{F}_q$ with agreement nearly $\\epsilon$ with $f$. This settles a long-standing open question in the area of low-degree testing, yielding an $O(d)$-query robust test in the ``high-error'' regime (i.e., when $\\epsilon < \\frac{1}{2}$).","The previous results in this space either required $\\epsilon > \\frac{1}{2}$ (Polishchuk \\& Spielman, STOC 1994), or $q = \\Omega(d^4)$ (Arora \\& Sudan, Combinatorica 2003), or needed to measure local distance on $2$-dimensional ``planes'' rather than one-dimensional lines leading to $\\Omega(d^2)$-query complexity (Raz \\& Safra, STOC 1997).   ","Our analysis follows the spirit of most previous analyses in first analyzing the low-variable case ($m = O(1)$) and then ``bootstrapping'' to general multivariate settings.","Our main technical novelty is a new analysis in the bivariate setting that exploits a previously known connection between multivariate factorization and finding (or testing) low-degree polynomials, in a non ``black-box'' manner.","A second contribution is a bootstrapping analysis which manages to lift analyses for $m=2$ directly to analyses for general $m$, where previous works needed to work with $m = 3$ or $m = 4$ -- arguably this bootstrapping is significantly simpler than those in prior works."],"url":"http://arxiv.org/abs/2311.12752v1"}
{"created":"2023-11-21 17:52:30","title":"Towards Natural Language-Guided Drones: GeoText-1652 Benchmark with Spatially Relation Matching","abstract":"Drone navigation through natural language commands remains a significant challenge due to the lack of publicly available multi-modal datasets and the intricate demands of fine-grained visual-text alignment. In response to this pressing need, we present a new human-computer interaction annotation benchmark called GeoText-1652, meticulously curated through a robust Large Language Model (LLM)-based data generation framework and the expertise of pre-trained vision models. This new dataset seamlessly extends the existing image dataset, \\ie, University-1652, with spatial-aware text annotations, encompassing intricate image-text-bounding box associations. Besides, we introduce a new optimization objective to leverage fine-grained spatial associations, called blending spatial matching, for region-level spatial relation matching. Extensive experiments reveal that our approach maintains an exceptional recall rate under varying description complexities. This underscores the promising potential of our approach in elevating drone control and navigation through the seamless integration of natural language commands in real-world scenarios.","sentences":["Drone navigation through natural language commands remains a significant challenge due to the lack of publicly available multi-modal datasets and the intricate demands of fine-grained visual-text alignment.","In response to this pressing need, we present a new human-computer interaction annotation benchmark called GeoText-1652, meticulously curated through a robust Large Language Model (LLM)-based data generation framework and the expertise of pre-trained vision models.","This new dataset seamlessly extends the existing image dataset, \\ie, University-1652, with spatial-aware text annotations, encompassing intricate image-text-bounding box associations.","Besides, we introduce a new optimization objective to leverage fine-grained spatial associations, called blending spatial matching, for region-level spatial relation matching.","Extensive experiments reveal that our approach maintains an exceptional recall rate under varying description complexities.","This underscores the promising potential of our approach in elevating drone control and navigation through the seamless integration of natural language commands in real-world scenarios."],"url":"http://arxiv.org/abs/2311.12751v1"}
{"created":"2023-11-21 17:51:30","title":"Learning to Optimise Wind Farms with Graph Transformers","abstract":"This work proposes a novel data-driven model capable of providing accurate predictions for the power generation of all wind turbines in wind farms of arbitrary layout, yaw angle configurations and wind conditions. The proposed model functions by encoding a wind farm into a fully-connected graph and processing the graph representation through a graph transformer. The graph transformer surrogate is shown to generalise well and is able to uncover latent structural patterns within the graph representation of wind farms. It is demonstrated how the resulting surrogate model can be used to optimise yaw angle configurations using genetic algorithms, achieving similar levels of accuracy to industrially-standard wind farm simulation tools while only taking a fraction of the computational cost.","sentences":["This work proposes a novel data-driven model capable of providing accurate predictions for the power generation of all wind turbines in wind farms of arbitrary layout, yaw angle configurations and wind conditions.","The proposed model functions by encoding a wind farm into a fully-connected graph and processing the graph representation through a graph transformer.","The graph transformer surrogate is shown to generalise well and is able to uncover latent structural patterns within the graph representation of wind farms.","It is demonstrated how the resulting surrogate model can be used to optimise yaw angle configurations using genetic algorithms, achieving similar levels of accuracy to industrially-standard wind farm simulation tools while only taking a fraction of the computational cost."],"url":"http://arxiv.org/abs/2311.12750v1"}
{"created":"2023-11-21 17:32:42","title":"Learn to Augment Network Simulators Towards Digital Network Twins","abstract":"Digital network twin (DNT) is a promising paradigm to replicate real-world cellular networks toward continual assessment, proactive management, and what-if analysis. Existing discussions have been focusing on using only deep learning techniques to build DNTs, which raises widespread concerns regarding their generalization, explainability, and transparency. In this paper, we explore an alternative approach to augment network simulators with context-aware neural agents. The main challenge lies in the non-trivial simulation-to-reality (sim-to-real) discrepancy between offline simulators and real-world networks. To solve the challenge, we propose a new learn-to-bridge algorithm to cost-efficiently bridge the sim-to-real discrepancy in two alternative stages. In the first stage, we select states to query performances in real-world networks by using newly-designed cost-aware Bayesian optimization. In the second stage, we train the neural agent to learn the state context and bridge the probabilistic discrepancy based on Bayesian neural networks (BNN). In addition, we build a small-scale end-to-end network testbed based on OpenAirInterface RAN and Core with USRP B210 and a smartphone, and replicate the network in NS-3. The evaluation results show that, our proposed solution substantially outperforms existing methods, with more than 92\\% reduction in the sim-to-real discrepancy.","sentences":["Digital network twin (DNT) is a promising paradigm to replicate real-world cellular networks toward continual assessment, proactive management, and what-if analysis.","Existing discussions have been focusing on using only deep learning techniques to build DNTs, which raises widespread concerns regarding their generalization, explainability, and transparency.","In this paper, we explore an alternative approach to augment network simulators with context-aware neural agents.","The main challenge lies in the non-trivial simulation-to-reality (sim-to-real) discrepancy between offline simulators and real-world networks.","To solve the challenge, we propose a new learn-to-bridge algorithm to cost-efficiently bridge the sim-to-real discrepancy in two alternative stages.","In the first stage, we select states to query performances in real-world networks by using newly-designed cost-aware Bayesian optimization.","In the second stage, we train the neural agent to learn the state context and bridge the probabilistic discrepancy based on Bayesian neural networks (BNN).","In addition, we build a small-scale end-to-end network testbed based on OpenAirInterface RAN and Core with USRP B210 and a smartphone, and replicate the network in NS-3.","The evaluation results show that, our proposed solution substantially outperforms existing methods, with more than 92\\% reduction in the sim-to-real discrepancy."],"url":"http://arxiv.org/abs/2311.12745v1"}
{"created":"2023-11-21 17:31:10","title":"Image Transformation for IoT Time-Series Data: A Review","abstract":"In the era of the Internet of Things (IoT), where smartphones, built-in systems, wireless sensors, and nearly every smart device connect through local networks or the internet, billions of smart things communicate with each other and generate vast amounts of time-series data. As IoT time-series data is high-dimensional and high-frequency, time-series classification or regression has been a challenging issue in IoT. Recently, deep learning algorithms have demonstrated superior performance results in time-series data classification in many smart and intelligent IoT applications. However, it is hard to explore the hidden dynamic patterns and trends in time-series. Recent studies show that transforming IoT data into images improves the performance of the learning model. In this paper, we present a review of these studies which use image transformation/encoding techniques in IoT domain. We examine the studies according to their encoding techniques, data types, and application areas. Lastly, we emphasize the challenges and future dimensions of image transformation.","sentences":["In the era of the Internet of Things (IoT), where smartphones, built-in systems, wireless sensors, and nearly every smart device connect through local networks or the internet, billions of smart things communicate with each other and generate vast amounts of time-series data.","As IoT time-series data is high-dimensional and high-frequency, time-series classification or regression has been a challenging issue in IoT. Recently, deep learning algorithms have demonstrated superior performance results in time-series data classification in many smart and intelligent IoT applications.","However, it is hard to explore the hidden dynamic patterns and trends in time-series.","Recent studies show that transforming IoT data into images improves the performance of the learning model.","In this paper, we present a review of these studies which use image transformation/encoding techniques in IoT domain.","We examine the studies according to their encoding techniques, data types, and application areas.","Lastly, we emphasize the challenges and future dimensions of image transformation."],"url":"http://arxiv.org/abs/2311.12742v1"}
{"created":"2023-11-21 17:30:57","title":"Content Augmented Graph Neural Networks","abstract":"In recent years, graph neural networks (GNNs) have become a popular tool for solving various problems over graphs. In these models, the link structure of the graph is typically exploited and nodes' embeddings are iteratively updated based on adjacent nodes. Nodes' contents are used solely in the form of feature vectors, served as nodes' first-layer embeddings. However, the filters or convolutions, applied during iterations/layers to these initial embeddings lead to their impact diminish and contribute insignificantly to the final embeddings. In order to address this issue, in this paper we propose augmenting nodes' embeddings by embeddings generating from their content, at higher GNN layers. More precisely, we propose models wherein a structural embedding using a GNN and a content embedding are computed for each node. These two are combined using a combination layer to form the embedding of a node at a given layer. We suggest methods such as using an auto-encoder or building a content graph, to generate content embeddings. In the end, by conducting experiments over several real-world datasets, we demonstrate the high accuracy and performance of our models.","sentences":["In recent years, graph neural networks (GNNs) have become a popular tool for solving various problems over graphs.","In these models, the link structure of the graph is typically exploited and nodes' embeddings are iteratively updated based on adjacent nodes.","Nodes' contents are used solely in the form of feature vectors, served as nodes' first-layer embeddings.","However, the filters or convolutions, applied during iterations/layers to these initial embeddings lead to their impact diminish and contribute insignificantly to the final embeddings.","In order to address this issue, in this paper we propose augmenting nodes' embeddings by embeddings generating from their content, at higher GNN layers.","More precisely, we propose models wherein a structural embedding using a GNN and a content embedding are computed for each node.","These two are combined using a combination layer to form the embedding of a node at a given layer.","We suggest methods such as using an auto-encoder or building a content graph, to generate content embeddings.","In the end, by conducting experiments over several real-world datasets, we demonstrate the high accuracy and performance of our models."],"url":"http://arxiv.org/abs/2311.12741v1"}
{"created":"2023-11-21 17:23:05","title":"Exploring Graph Classification Techniques Under Low Data Constraints: A Comprehensive Study","abstract":"This survey paper presents a brief overview of recent research on graph data augmentation and few-shot learning. It covers various techniques for graph data augmentation, including node and edge perturbation, graph coarsening, and graph generation, as well as the latest developments in few-shot learning, such as meta-learning and model-agnostic meta-learning. The paper explores these areas in depth and delves into further sub classifications. Rule based approaches and learning based approaches are surveyed under graph augmentation techniques. Few-Shot Learning on graphs is also studied in terms of metric learning techniques and optimization-based techniques. In all, this paper provides an extensive array of techniques that can be employed in solving graph processing problems faced in low-data scenarios.","sentences":["This survey paper presents a brief overview of recent research on graph data augmentation and few-shot learning.","It covers various techniques for graph data augmentation, including node and edge perturbation, graph coarsening, and graph generation, as well as the latest developments in few-shot learning, such as meta-learning and model-agnostic meta-learning.","The paper explores these areas in depth and delves into further sub classifications.","Rule based approaches and learning based approaches are surveyed under graph augmentation techniques.","Few-Shot Learning on graphs is also studied in terms of metric learning techniques and optimization-based techniques.","In all, this paper provides an extensive array of techniques that can be employed in solving graph processing problems faced in low-data scenarios."],"url":"http://arxiv.org/abs/2311.12737v1"}
{"created":"2023-11-21 17:21:15","title":"LowResource at BLP-2023 Task 2: Leveraging BanglaBert for Low Resource Sentiment Analysis of Bangla Language","abstract":"This paper describes the system of the LowResource Team for Task 2 of BLP-2023, which involves conducting sentiment analysis on a dataset composed of public posts and comments from diverse social media platforms. Our primary aim is to utilize BanglaBert, a BERT model pre-trained on a large Bangla corpus, using various strategies including fine-tuning, dropping random tokens, and using several external datasets. Our final model is an ensemble of the three best BanglaBert variations. Our system has achieved overall 3rd in the Test Set among 30 participating teams with a score of 0.718. Additionally, we discuss the promising systems that didn't perform well namely task-adaptive pertaining and paraphrasing using BanglaT5. Training codes and external datasets which are used for our system are publicly available at https://github.com/Aunabil4602/bnlp-workshop-task2-2023","sentences":["This paper describes the system of the LowResource Team for Task 2 of BLP-2023, which involves conducting sentiment analysis on a dataset composed of public posts and comments from diverse social media platforms.","Our primary aim is to utilize BanglaBert, a BERT model pre-trained on a large Bangla corpus, using various strategies including fine-tuning, dropping random tokens, and using several external datasets.","Our final model is an ensemble of the three best BanglaBert variations.","Our system has achieved overall 3rd in the Test Set among 30 participating teams with a score of 0.718.","Additionally, we discuss the promising systems that didn't perform well namely task-adaptive pertaining and paraphrasing using BanglaT5.","Training codes and external datasets which are used for our system are publicly available at https://github.com/Aunabil4602/bnlp-workshop-task2-2023"],"url":"http://arxiv.org/abs/2311.12735v1"}
{"created":"2023-11-21 17:15:43","title":"Not Just Training, Also Testing: High School Youths' Perspective-Taking through Peer Testing Machine Learning-Powered Applications","abstract":"Most attention in K-12 artificial intelligence and machine learning (AI/ML) education has been given to having youths train models, with much less attention to the equally important testing of models when creating machine learning applications. Testing ML applications allows for the evaluation of models against predictions and can help creators of applications identify and address failure and edge cases that could negatively impact user experiences. We investigate how testing each other's projects supported youths to take perspective about functionality, performance, and potential issues in their own projects. We analyzed testing worksheets, audio and video recordings collected during a two week workshop in which 11 high school youths created physical computing projects that included (audio, pose, and image) ML classifiers. We found that through peer-testing youths reflected on the size of their training datasets, the diversity of their training data, the design of their classes and the contexts in which they produced training data. We discuss future directions for research on peer-testing in AI/ML education and current limitations for these kinds of activities.","sentences":["Most attention in K-12 artificial intelligence and machine learning (AI/ML) education has been given to having youths train models, with much less attention to the equally important testing of models when creating machine learning applications.","Testing ML applications allows for the evaluation of models against predictions and can help creators of applications identify and address failure and edge cases that could negatively impact user experiences.","We investigate how testing each other's projects supported youths to take perspective about functionality, performance, and potential issues in their own projects.","We analyzed testing worksheets, audio and video recordings collected during a two week workshop in which 11 high school youths created physical computing projects that included (audio, pose, and image) ML classifiers.","We found that through peer-testing youths reflected on the size of their training datasets, the diversity of their training data, the design of their classes and the contexts in which they produced training data.","We discuss future directions for research on peer-testing in AI/ML education and current limitations for these kinds of activities."],"url":"http://arxiv.org/abs/2311.12733v1"}
{"created":"2023-11-21 17:13:00","title":"Serial Monopoly on Blockchains","abstract":"We study the following problem that is motivated by Blockchains where ``miners'' are serially given the monopoly for assembling transactions into the next block. Our model has a single good that is sold repeatedly every day where new demand for the good arrives every day. The novel element in our model is that all unsatisfied demand from one day remains in the system and is added to the new demand of the next day. Every day there is a new monopolist that gets to sell a fixed supply $s$ of the good and naturally chooses to do so at the monopolist's price for the combined demand. What will the dynamics of the prices chosen by the sequence of monopolists be? What level of efficiency will be obtained in the long term?   We start with a non-strategic analysis of users' behavior and our main result shows that prices keep fluctuating wildly and this is an endogenous property of the model and happens even when demand is stable with nothing stochastic in the model. These price fluctuations underscore the necessity of an analysis under strategic behavior of the users, which we show results in the prices being stable at the market equilibrium price.","sentences":["We study the following problem that is motivated by Blockchains where ``miners'' are serially given the monopoly for assembling transactions into the next block.","Our model has a single good that is sold repeatedly every day where new demand for the good arrives every day.","The novel element in our model is that all unsatisfied demand from one day remains in the system and is added to the new demand of the next day.","Every day there is a new monopolist that gets to sell a fixed supply $s$ of the good and naturally chooses to do so at the monopolist's price for the combined demand.","What will the dynamics of the prices chosen by the sequence of monopolists be?","What level of efficiency will be obtained in the long term?   ","We start with a non-strategic analysis of users' behavior and our main result shows that prices keep fluctuating wildly and this is an endogenous property of the model and happens even when demand is stable with nothing stochastic in the model.","These price fluctuations underscore the necessity of an analysis under strategic behavior of the users, which we show results in the prices being stable at the market equilibrium price."],"url":"http://arxiv.org/abs/2311.12731v1"}
{"created":"2023-11-21 17:03:21","title":"Soft Random Sampling: A Theoretical and Empirical Analysis","abstract":"Soft random sampling (SRS) is a simple yet effective approach for efficient training of large-scale deep neural networks when dealing with massive data. SRS selects a subset uniformly at random with replacement from the full data set in each epoch. In this paper, we conduct a theoretical and empirical analysis of SRS. First, we analyze its sampling dynamics including data coverage and occupancy. Next, we investigate its convergence with non-convex objective functions and give the convergence rate. Finally, we provide its generalization performance. We empirically evaluate SRS for image recognition on CIFAR10 and automatic speech recognition on Librispeech and an in-house payload dataset to demonstrate its effectiveness. Compared to existing coreset-based data selection methods, SRS offers a better accuracy-efficiency trade-off. Especially on real-world industrial scale data sets, it is shown to be a powerful training strategy with significant speedup and competitive performance with almost no additional computing cost.","sentences":["Soft random sampling (SRS) is a simple yet effective approach for efficient training of large-scale deep neural networks when dealing with massive data.","SRS selects a subset uniformly at random with replacement from the full data set in each epoch.","In this paper, we conduct a theoretical and empirical analysis of SRS.","First, we analyze its sampling dynamics including data coverage and occupancy.","Next, we investigate its convergence with non-convex objective functions and give the convergence rate.","Finally, we provide its generalization performance.","We empirically evaluate SRS for image recognition on CIFAR10 and automatic speech recognition on Librispeech and an in-house payload dataset to demonstrate its effectiveness.","Compared to existing coreset-based data selection methods, SRS offers a better accuracy-efficiency trade-off.","Especially on real-world industrial scale data sets, it is shown to be a powerful training strategy with significant speedup and competitive performance with almost no additional computing cost."],"url":"http://arxiv.org/abs/2311.12727v1"}
{"created":"2023-11-21 16:51:33","title":"Attacking Motion Planners Using Adversarial Perception Errors","abstract":"Autonomous driving (AD) systems are often built and tested in a modular fashion, where the performance of different modules is measured using task-specific metrics. These metrics should be chosen so as to capture the downstream impact of each module and the performance of the system as a whole. For example, high perception quality should enable prediction and planning to be performed safely. Even though this is true in general, we show here that it is possible to construct planner inputs that score very highly on various perception quality metrics but still lead to planning failures. In an analogy to adversarial attacks on image classifiers, we call such inputs \\textbf{adversarial perception errors} and show they can be systematically constructed using a simple boundary-attack algorithm. We demonstrate the effectiveness of this algorithm by finding attacks for two different black-box planners in several urban and highway driving scenarios using the CARLA simulator. Finally, we analyse the properties of these attacks and show that they are isolated in the input space of the planner, and discuss their implications for AD system deployment and testing.","sentences":["Autonomous driving (AD) systems are often built and tested in a modular fashion, where the performance of different modules is measured using task-specific metrics.","These metrics should be chosen so as to capture the downstream impact of each module and the performance of the system as a whole.","For example, high perception quality should enable prediction and planning to be performed safely.","Even though this is true in general, we show here that it is possible to construct planner inputs that score very highly on various perception quality metrics but still lead to planning failures.","In an analogy to adversarial attacks on image classifiers, we call such inputs \\textbf{adversarial perception errors} and show they can be systematically constructed using a simple boundary-attack algorithm.","We demonstrate the effectiveness of this algorithm by finding attacks for two different black-box planners in several urban and highway driving scenarios using the CARLA simulator.","Finally, we analyse the properties of these attacks and show that they are isolated in the input space of the planner, and discuss their implications for AD system deployment and testing."],"url":"http://arxiv.org/abs/2311.12722v1"}
{"created":"2023-11-21 16:49:15","title":"LiFi: Learn to Incentivize Federated Learning in Automotive Edge Computing","abstract":"Federated learning (FL) is the promising privacy-preserve approach to continually update the central machine learning (ML) model (e.g., object detectors in edge servers) by aggregating the gradients obtained from local observation data in distributed connected and automated vehicles (CAVs). The incentive mechanism is to incentivize individual selfish CAVs to participate in FL towards the improvement of overall model accuracy. It is, however, challenging to design the incentive mechanism, due to the complex correlation between the overall model accuracy and unknown incentive sensitivity of CAVs, especially under the non-independent and identically distributed (Non-IID) data of individual CAVs. In this paper, we propose a new learn-to-incentivize algorithm to adaptively allocate rewards to individual CAVs under unknown sensitivity functions. First, we gradually learn the unknown sensitivity function of individual CAVs with accumulative observations, by using compute-efficient Gaussian process regression (GPR). Second, we iteratively update the reward allocation to individual CAVs with new sampled gradients, derived from GPR. Third, we project the updated reward allocations to comply with the total budget. We evaluate the performance of extensive simulations, where the simulation parameters are obtained from realistic profiling of the CIFAR-10 dataset and NVIDIA RTX 3080 GPU. The results show that our proposed algorithm substantially outperforms existing solutions, in terms of accuracy, scalability, and adaptability.","sentences":["Federated learning (FL) is the promising privacy-preserve approach to continually update the central machine learning (ML) model (e.g., object detectors in edge servers) by aggregating the gradients obtained from local observation data in distributed connected and automated vehicles (CAVs).","The incentive mechanism is to incentivize individual selfish CAVs to participate in FL towards the improvement of overall model accuracy.","It is, however, challenging to design the incentive mechanism, due to the complex correlation between the overall model accuracy and unknown incentive sensitivity of CAVs, especially under the non-independent and identically distributed (Non-IID) data of individual CAVs.","In this paper, we propose a new learn-to-incentivize algorithm to adaptively allocate rewards to individual CAVs under unknown sensitivity functions.","First, we gradually learn the unknown sensitivity function of individual CAVs with accumulative observations, by using compute-efficient Gaussian process regression (GPR).","Second, we iteratively update the reward allocation to individual CAVs with new sampled gradients, derived from GPR.","Third, we project the updated reward allocations to comply with the total budget.","We evaluate the performance of extensive simulations, where the simulation parameters are obtained from realistic profiling of the CIFAR-10 dataset and NVIDIA RTX 3080 GPU.","The results show that our proposed algorithm substantially outperforms existing solutions, in terms of accuracy, scalability, and adaptability."],"url":"http://arxiv.org/abs/2311.12720v1"}
{"created":"2023-11-21 16:48:10","title":"Development of a Legal Document AI-Chatbot","abstract":"With the exponential growth of digital data and the increasing complexity of legal documentation, there is a pressing need for efficient and intelligent tools to streamline the handling of legal documents.With the recent developments in the AI field, especially in chatbots, it cannot be ignored as a very compelling solution to this problem.An insight into the process of creating a Legal Documentation AI Chatbot with as many relevant features as possible within the given time frame is presented.The development of each component of the chatbot is presented in detail.Each component's workings and functionality has been discussed.Starting from the build of the Android app and the Langchain query processing code till the integration of both through a Flask backend and REST API methods.","sentences":["With the exponential growth of digital data and the increasing complexity of legal documentation, there is a pressing need for efficient and intelligent tools to streamline the handling of legal documents.","With the recent developments in the AI field, especially in chatbots, it cannot be ignored as a very compelling solution to this problem.","An insight into the process of creating a Legal Documentation AI Chatbot with as many relevant features as possible within the given time frame is presented.","The development of each component of the chatbot is presented in detail.","Each component's workings and functionality has been discussed.","Starting from the build of the Android app and the Langchain query processing code till the integration of both through a Flask backend and REST API methods."],"url":"http://arxiv.org/abs/2311.12719v1"}
{"created":"2023-11-21 16:43:13","title":"minimax: Efficient Baselines for Autocurricula in JAX","abstract":"Unsupervised environment design (UED) is a form of automatic curriculum learning for training robust decision-making agents to zero-shot transfer into unseen environments. Such autocurricula have received much interest from the RL community. However, UED experiments, based on CPU rollouts and GPU model updates, have often required several weeks of training. This compute requirement is a major obstacle to rapid innovation for the field. This work introduces the minimax library for UED training on accelerated hardware. Using JAX to implement fully-tensorized environments and autocurriculum algorithms, minimax allows the entire training loop to be compiled for hardware acceleration. To provide a petri dish for rapid experimentation, minimax includes a tensorized grid-world based on MiniGrid, in addition to reusable abstractions for conducting autocurricula in procedurally-generated environments. With these components, minimax provides strong UED baselines, including new parallelized variants, which achieve over 120$\\times$ speedups in wall time compared to previous implementations when training with equal batch sizes. The minimax library is available under the Apache 2.0 license at https://github.com/facebookresearch/minimax.","sentences":["Unsupervised environment design (UED) is a form of automatic curriculum learning for training robust decision-making agents to zero-shot transfer into unseen environments.","Such autocurricula have received much interest from the RL community.","However, UED experiments, based on CPU rollouts and GPU model updates, have often required several weeks of training.","This compute requirement is a major obstacle to rapid innovation for the field.","This work introduces the minimax library for UED training on accelerated hardware.","Using JAX to implement fully-tensorized environments and autocurriculum algorithms, minimax allows the entire training loop to be compiled for hardware acceleration.","To provide a petri dish for rapid experimentation, minimax includes a tensorized grid-world based on MiniGrid, in addition to reusable abstractions for conducting autocurricula in procedurally-generated environments.","With these components, minimax provides strong UED baselines, including new parallelized variants, which achieve over 120$\\times$ speedups in wall time compared to previous implementations when training with equal batch sizes.","The minimax library is available under the Apache 2.0 license at https://github.com/facebookresearch/minimax."],"url":"http://arxiv.org/abs/2311.12716v1"}
{"created":"2023-11-21 16:42:03","title":"Attacks of fairness in Federated Learning","abstract":"Federated Learning is an important emerging distributed training paradigm that keeps data private on clients. It is now well understood that by controlling only a small subset of FL clients, it is possible to introduce a backdoor to a federated learning model, in the presence of certain attributes. In this paper, we present a new type of attack that compromises the fairness of the trained model. Fairness is understood to be the attribute-level performance distribution of a trained model. It is particularly salient in domains where, for example, skewed accuracy discrimination between subpopulations could have disastrous consequences. We find that by employing a threat model similar to that of a backdoor attack, an attacker is able to influence the aggregated model to have an unfair performance distribution between any given set of attributes. Furthermore, we find that this attack is possible by controlling only a single client. While combating naturally induced unfairness in FL has previously been discussed in depth, its artificially induced kind has been neglected. We show that defending against attacks on fairness should be a critical consideration in any situation where unfairness in a trained model could benefit a user who participated in its training.","sentences":["Federated Learning is an important emerging distributed training paradigm that keeps data private on clients.","It is now well understood that by controlling only a small subset of FL clients, it is possible to introduce a backdoor to a federated learning model, in the presence of certain attributes.","In this paper, we present a new type of attack that compromises the fairness of the trained model.","Fairness is understood to be the attribute-level performance distribution of a trained model.","It is particularly salient in domains where, for example, skewed accuracy discrimination between subpopulations could have disastrous consequences.","We find that by employing a threat model similar to that of a backdoor attack, an attacker is able to influence the aggregated model to have an unfair performance distribution between any given set of attributes.","Furthermore, we find that this attack is possible by controlling only a single client.","While combating naturally induced unfairness in FL has previously been discussed in depth, its artificially induced kind has been neglected.","We show that defending against attacks on fairness should be a critical consideration in any situation where unfairness in a trained model could benefit a user who participated in its training."],"url":"http://arxiv.org/abs/2311.12715v1"}
{"created":"2023-11-21 16:31:27","title":"Regression-Based Analysis of Multimodal Single-Cell Data Integration Strategies","abstract":"Multimodal single-cell technologies enable the simultaneous collection of diverse data types from individual cells, enhancing our understanding of cellular states. However, the integration of these datatypes and modeling the interrelationships between modalities presents substantial computational and analytical challenges in disease biomarker detection and drug discovery. Established practices rely on isolated methodologies to investigate individual molecular aspects separately, often resulting in inaccurate analyses. To address these obstacles, distinct Machine Learning Techniques are leveraged, each of its own kind to model the co-variation of DNA to RNA, and finally to surface proteins in single cells during hematopoietic stem cell development, which simplifies understanding of underlying cellular mechanisms and immune responses. Experiments conducted on a curated subset of a 300,000-cell time course dataset, highlights the exceptional performance of Echo State Networks, boasting a remarkable state-of-the-art correlation score of 0.94 and 0.895 on Multi-omic and CiteSeq datasets. Beyond the confines of this study, these findings hold promise for advancing comprehension of cellular differentiation and function, leveraging the potential of Machine Learning.","sentences":["Multimodal single-cell technologies enable the simultaneous collection of diverse data types from individual cells, enhancing our understanding of cellular states.","However, the integration of these datatypes and modeling the interrelationships between modalities presents substantial computational and analytical challenges in disease biomarker detection and drug discovery.","Established practices rely on isolated methodologies to investigate individual molecular aspects separately, often resulting in inaccurate analyses.","To address these obstacles, distinct Machine Learning Techniques are leveraged, each of its own kind to model the co-variation of DNA to RNA, and finally to surface proteins in single cells during hematopoietic stem cell development, which simplifies understanding of underlying cellular mechanisms and immune responses.","Experiments conducted on a curated subset of a 300,000-cell time course dataset, highlights the exceptional performance of Echo State Networks, boasting a remarkable state-of-the-art correlation score of 0.94 and 0.895 on Multi-omic and CiteSeq datasets.","Beyond the confines of this study, these findings hold promise for advancing comprehension of cellular differentiation and function, leveraging the potential of Machine Learning."],"url":"http://arxiv.org/abs/2311.12711v1"}
{"created":"2023-11-21 16:25:17","title":"Short Voting Codes For Practical Code Voting","abstract":"To preserve voter secrecy on untrusted voter devices we propose to use short voting codes. This ensures voting codes remain practical even if the voter is able to select multiple voting choices. We embed the mechanism in a protocol that avoids complex cryptography in both the setup and the voting phase and relies only on standard cryptographic primitives. Trusting the setup, and one out of multiple server components, the protocol provides vote secrecy, cast-as-intended, recorded-as-cast, tallied-as-recorded, eligibility and universal verifiability.","sentences":["To preserve voter secrecy on untrusted voter devices we propose to use short voting codes.","This ensures voting codes remain practical even if the voter is able to select multiple voting choices.","We embed the mechanism in a protocol that avoids complex cryptography in both the setup and the voting phase and relies only on standard cryptographic primitives.","Trusting the setup, and one out of multiple server components, the protocol provides vote secrecy, cast-as-intended, recorded-as-cast, tallied-as-recorded, eligibility and universal verifiability."],"url":"http://arxiv.org/abs/2311.12710v1"}
{"created":"2023-11-21 16:24:02","title":"LBR-Stack: ROS 2 and Python Integration of KUKA FRI for Med and IIWA Robots","abstract":"The LBR-Stack is a collection of packages that simplify the usage and extend the capabilities of KUKA's Fast Robot Interface (FRI). It is designed for mission critical hard real-time applications. Supported are the KUKA LBR Med7/14 and KUKA LBR iiwa7/14 robots in the Gazebo simulation and for communication with real hardware.","sentences":["The LBR-Stack is a collection of packages that simplify the usage and extend the capabilities of KUKA's Fast Robot Interface (FRI).","It is designed for mission critical hard real-time applications.","Supported are the KUKA LBR Med7/14 and KUKA LBR iiwa7/14 robots in the Gazebo simulation and for communication with real hardware."],"url":"http://arxiv.org/abs/2311.12709v1"}
{"created":"2023-11-21 16:20:49","title":"Keeping Users Engaged During Repeated Administration of the Same Questionnaire: Using Large Language Models to Reliably Diversify Questions","abstract":"Standardized, validated questionnaires are vital tools in HCI research and healthcare, offering dependable self-report data. However, their repeated use in longitudinal or pre-post studies can induce respondent fatigue, impacting data quality via response biases and decreased response rates. We propose utilizing large language models (LLMs) to generate diverse questionnaire versions while retaining good psychometric properties. In a longitudinal study, participants engaged with our agent system and responded daily for two weeks to either a standardized depression questionnaire or one of two LLM-generated questionnaire variants, alongside a validated depression questionnaire. Psychometric testing revealed consistent covariation between the external criterion and the focal measure administered across the three conditions, demonstrating the reliability and validity of the LLM-generated variants. Participants found the repeated administration of the standardized questionnaire significantly more repetitive compared to the variants. Our findings highlight the potential of LLM-generated variants to invigorate questionnaires, fostering engagement and interest without compromising validity.","sentences":["Standardized, validated questionnaires are vital tools in HCI research and healthcare, offering dependable self-report data.","However, their repeated use in longitudinal or pre-post studies can induce respondent fatigue, impacting data quality via response biases and decreased response rates.","We propose utilizing large language models (LLMs) to generate diverse questionnaire versions while retaining good psychometric properties.","In a longitudinal study, participants engaged with our agent system and responded daily for two weeks to either a standardized depression questionnaire or one of two LLM-generated questionnaire variants, alongside a validated depression questionnaire.","Psychometric testing revealed consistent covariation between the external criterion and the focal measure administered across the three conditions, demonstrating the reliability and validity of the LLM-generated variants.","Participants found the repeated administration of the standardized questionnaire significantly more repetitive compared to the variants.","Our findings highlight the potential of LLM-generated variants to invigorate questionnaires, fostering engagement and interest without compromising validity."],"url":"http://arxiv.org/abs/2311.12707v1"}
{"created":"2023-11-21 16:19:14","title":"Cascade Learning Localises Discriminant Features in Visual Scene Classification","abstract":"Lack of interpretability of deep convolutional neural networks (DCNN) is a well-known problem particularly in the medical domain as clinicians want trustworthy automated decisions. One way to improve trust is to demonstrate the localisation of feature representations with respect to expert labeled regions of interest. In this work, we investigate the localisation of features learned via two varied learning paradigms and demonstrate the superiority of one learning approach with respect to localisation. Our analysis on medical and natural datasets show that the traditional end-to-end (E2E) learning strategy has a limited ability to localise discriminative features across multiple network layers. We show that a layer-wise learning strategy, namely cascade learning (CL), results in more localised features. Considering localisation accuracy, we not only show that CL outperforms E2E but that it is a promising method of predicting regions. On the YOLO object detection framework, our best result shows that CL outperforms the E2E scheme by $2\\%$ in mAP.","sentences":["Lack of interpretability of deep convolutional neural networks (DCNN) is a well-known problem particularly in the medical domain as clinicians want trustworthy automated decisions.","One way to improve trust is to demonstrate the localisation of feature representations with respect to expert labeled regions of interest.","In this work, we investigate the localisation of features learned via two varied learning paradigms and demonstrate the superiority of one learning approach with respect to localisation.","Our analysis on medical and natural datasets show that the traditional end-to-end (E2E) learning strategy has a limited ability to localise discriminative features across multiple network layers.","We show that a layer-wise learning strategy, namely cascade learning (CL), results in more localised features.","Considering localisation accuracy, we not only show that CL outperforms E2E but that it is a promising method of predicting regions.","On the YOLO object detection framework, our best result shows that CL outperforms the E2E scheme by $2\\%$ in mAP."],"url":"http://arxiv.org/abs/2311.12704v1"}
{"created":"2023-11-21 16:15:21","title":"\"There Has To Be a Lot That We're Missing\": Moderating AI-Generated Content on Reddit","abstract":"Generative AI threatens to disrupt how we work, learn, communicate, and participate in online communities. We performed a qualitative interview study to understand how online communities on the social sharing site Reddit are challenged by AI-generated content (AIGC) and how they are adapting. We conducted fifteen in-depth, semi-structured interviews with subreddit moderators about their experiences moderating AIGC. Though our participants see both legitimate and illegitimate motivations for using AIGC, on the whole they view it as detrimental to their communities, with a level of concern that is dependent on the purpose and size of their subreddits. Moderators reported developing rules and using a variety of strategies that may help communities prevent or curb AIGC, but without foolproof detection tools, enforcement is challenging and relies on heuristics. Overall, for online communities, the threat of Generative AI is not speculative: the disruption has already begun.","sentences":["Generative AI threatens to disrupt how we work, learn, communicate, and participate in online communities.","We performed a qualitative interview study to understand how online communities on the social sharing site Reddit are challenged by AI-generated content (AIGC) and how they are adapting.","We conducted fifteen in-depth, semi-structured interviews with subreddit moderators about their experiences moderating AIGC.","Though our participants see both legitimate and illegitimate motivations for using AIGC, on the whole they view it as detrimental to their communities, with a level of concern that is dependent on the purpose and size of their subreddits.","Moderators reported developing rules and using a variety of strategies that may help communities prevent or curb AIGC, but without foolproof detection tools, enforcement is challenging and relies on heuristics.","Overall, for online communities, the threat of Generative AI is not speculative: the disruption has already begun."],"url":"http://arxiv.org/abs/2311.12702v1"}
{"created":"2023-11-21 16:03:51","title":"Can Large Language Models Understand Content and Propagation for Misinformation Detection: An Empirical Study","abstract":"Large Language Models (LLMs) have garnered significant attention for their powerful ability in natural language understanding and reasoning. In this paper, we present a comprehensive empirical study to explore the performance of LLMs on misinformation detection tasks. This study stands as the pioneering investigation into the understanding capabilities of multiple LLMs regarding both content and propagation across social media platforms. Our empirical studies on five misinformation detection datasets show that LLMs with diverse prompts achieve comparable performance in text-based misinformation detection but exhibit notably constrained capabilities in comprehending propagation structure compared to existing models in propagation-based misinformation detection. Besides, we further design four instruction-tuned strategies to enhance LLMs for both content and propagation-based misinformation detection. These strategies boost LLMs to actively learn effective features from multiple instances or hard instances, and eliminate irrelevant propagation structures, thereby achieving better detection performance. Extensive experiments further demonstrate LLMs would play a better capacity in content and propagation structure under these proposed strategies and achieve promising detection performance. These findings highlight the potential ability of LLMs to detect misinformation.","sentences":["Large Language Models (LLMs) have garnered significant attention for their powerful ability in natural language understanding and reasoning.","In this paper, we present a comprehensive empirical study to explore the performance of LLMs on misinformation detection tasks.","This study stands as the pioneering investigation into the understanding capabilities of multiple LLMs regarding both content and propagation across social media platforms.","Our empirical studies on five misinformation detection datasets show that LLMs with diverse prompts achieve comparable performance in text-based misinformation detection but exhibit notably constrained capabilities in comprehending propagation structure compared to existing models in propagation-based misinformation detection.","Besides, we further design four instruction-tuned strategies to enhance LLMs for both content and propagation-based misinformation detection.","These strategies boost LLMs to actively learn effective features from multiple instances or hard instances, and eliminate irrelevant propagation structures, thereby achieving better detection performance.","Extensive experiments further demonstrate LLMs would play a better capacity in content and propagation structure under these proposed strategies and achieve promising detection performance.","These findings highlight the potential ability of LLMs to detect misinformation."],"url":"http://arxiv.org/abs/2311.12699v1"}
{"created":"2023-11-21 16:02:39","title":"Informative Path Planning with Limited Adaptivity","abstract":"We consider the informative path planning ($\\mathtt{IPP}$) problem in which a robot interacts with an uncertain environment and gathers information by visiting locations. The goal is to minimize its expected travel cost to cover a given submodular function. Adaptive solutions, where the robot incorporates all available information to select the next location to visit, achieve the best objective. However, such a solution is resource-intensive as it entails recomputing after every visited location. A more practical approach is to design solutions with a small number of adaptive \"rounds\", where the robot recomputes only once at the start of each round. In this paper, we design an algorithm for $\\mathtt{IPP}$ parameterized by the number $k$ of adaptive rounds, and prove a smooth trade-off between $k$ and the solution quality (relative to fully adaptive solutions). We validate our theoretical results by experiments on a real road network, where we observe that a few rounds of adaptivity suffice to obtain solutions of cost almost as good as fully-adaptive ones.","sentences":["We consider the informative path planning ($\\mathtt{IPP}$) problem in which a robot interacts with an uncertain environment and gathers information by visiting locations.","The goal is to minimize its expected travel cost to cover a given submodular function.","Adaptive solutions, where the robot incorporates all available information to select the next location to visit, achieve the best objective.","However, such a solution is resource-intensive as it entails recomputing after every visited location.","A more practical approach is to design solutions with a small number of adaptive \"rounds\", where the robot recomputes only once at the start of each round.","In this paper, we design an algorithm for $\\mathtt{IPP}$ parameterized by the number $k$ of adaptive rounds, and prove a smooth trade-off between $k$ and the solution quality (relative to fully adaptive solutions).","We validate our theoretical results by experiments on a real road network, where we observe that a few rounds of adaptivity suffice to obtain solutions of cost almost as good as fully-adaptive ones."],"url":"http://arxiv.org/abs/2311.12698v1"}
{"created":"2023-11-21 15:51:06","title":"Fair Text Classification with Wasserstein Independence","abstract":"Group fairness is a central research topic in text classification, where reaching fair treatment between sensitive groups (e.g. women vs. men) remains an open challenge. This paper presents a novel method for mitigating biases in neural text classification, agnostic to the model architecture. Considering the difficulty to distinguish fair from unfair information in a text encoder, we take inspiration from adversarial training to induce Wasserstein independence between representations learned to predict our target label and the ones learned to predict some sensitive attribute. Our approach provides two significant advantages. Firstly, it does not require annotations of sensitive attributes in both testing and training data. This is more suitable for real-life scenarios compared to existing methods that require annotations of sensitive attributes at train time. Second, our approach exhibits a comparable or better fairness-accuracy trade-off compared to existing methods.","sentences":["Group fairness is a central research topic in text classification, where reaching fair treatment between sensitive groups (e.g. women vs. men) remains an open challenge.","This paper presents a novel method for mitigating biases in neural text classification, agnostic to the model architecture.","Considering the difficulty to distinguish fair from unfair information in a text encoder, we take inspiration from adversarial training to induce Wasserstein independence between representations learned to predict our target label and the ones learned to predict some sensitive attribute.","Our approach provides two significant advantages.","Firstly, it does not require annotations of sensitive attributes in both testing and training data.","This is more suitable for real-life scenarios compared to existing methods that require annotations of sensitive attributes at train time.","Second, our approach exhibits a comparable or better fairness-accuracy trade-off compared to existing methods."],"url":"http://arxiv.org/abs/2311.12689v1"}
{"created":"2023-11-21 15:50:37","title":"On the Out-of-Distribution Coverage of Combining Split Conformal Prediction and Bayesian Deep Learning","abstract":"Bayesian deep learning and conformal prediction are two methods that have been used to convey uncertainty and increase safety in machine learning systems. We focus on combining Bayesian deep learning with split conformal prediction and how this combination effects out-of-distribution coverage; particularly in the case of multiclass image classification. We suggest that if the model is generally underconfident on the calibration set, then the resultant conformal sets may exhibit worse out-of-distribution coverage compared to simple predictive credible sets. Conversely, if the model is overconfident on the calibration set, the use of conformal prediction may improve out-of-distribution coverage. We evaluate prediction sets as a result of combining split conformal methods and neural networks trained with (i) stochastic gradient descent, (ii) deep ensembles, and (iii) mean-field variational inference. Our results suggest that combining Bayesian deep learning models with split conformal prediction can, in some cases, cause unintended consequences such as reducing out-of-distribution coverage.","sentences":["Bayesian deep learning and conformal prediction are two methods that have been used to convey uncertainty and increase safety in machine learning systems.","We focus on combining Bayesian deep learning with split conformal prediction and how this combination effects out-of-distribution coverage; particularly in the case of multiclass image classification.","We suggest that if the model is generally underconfident on the calibration set, then the resultant conformal sets may exhibit worse out-of-distribution coverage compared to simple predictive credible sets.","Conversely, if the model is overconfident on the calibration set, the use of conformal prediction may improve out-of-distribution coverage.","We evaluate prediction sets as a result of combining split conformal methods and neural networks trained with (i) stochastic gradient descent, (ii) deep ensembles, and (iii) mean-field variational inference.","Our results suggest that combining Bayesian deep learning models with split conformal prediction can, in some cases, cause unintended consequences such as reducing out-of-distribution coverage."],"url":"http://arxiv.org/abs/2311.12688v1"}
{"created":"2023-11-21 15:47:06","title":"Managing ML-Based Application Non-Functional Behavior: A Multi-Model Approach","abstract":"Modern applications are increasingly driven by Machine Learning (ML) models whose non-deterministic behavior is affecting the entire application life cycle from design to operation. The pervasive adoption of ML is urgently calling for approaches that guarantee a stable non-functional behavior of ML-based applications over time and across model changes. To this aim, non-functional properties of ML models, such as privacy, confidentiality, fairness, and explainability, must be monitored, verified, and maintained. This need is even more pressing when modern applications operate in the edge-cloud continuum, increasing their complexity and dynamicity. Existing approaches mostly focus on i) implementing classifier selection solutions according to the functional behavior of ML models, ii) finding new algorithmic solutions to this need, such as continuous re-training. In this paper, we propose a multi-model approach built on dynamic classifier selection, where multiple ML models showing similar non-functional properties are made available to the application and one model is selected over time according to (dynamic and unpredictable) contextual changes. Our solution goes beyond the state of the art by providing an architectural and methodological approach that continuously guarantees a stable non-functional behavior of ML-based applications, is applicable to different ML models, and is driven by non-functional properties assessed on the models themselves. It consists of a two-step process working during application operation, where model assessment verifies non-functional properties of ML models trained and selected at development time, and model substitution guarantees a continuous and stable support of non-functional properties. We experimentally evaluate our solution in a real-world scenario focusing on non-functional property fairness.","sentences":["Modern applications are increasingly driven by Machine Learning (ML) models whose non-deterministic behavior is affecting the entire application life cycle from design to operation.","The pervasive adoption of ML is urgently calling for approaches that guarantee a stable non-functional behavior of ML-based applications over time and across model changes.","To this aim, non-functional properties of ML models, such as privacy, confidentiality, fairness, and explainability, must be monitored, verified, and maintained.","This need is even more pressing when modern applications operate in the edge-cloud continuum, increasing their complexity and dynamicity.","Existing approaches mostly focus on i) implementing classifier selection solutions according to the functional behavior of ML models, ii) finding new algorithmic solutions to this need, such as continuous re-training.","In this paper, we propose a multi-model approach built on dynamic classifier selection, where multiple ML models showing similar non-functional properties are made available to the application and one model is selected over time according to (dynamic and unpredictable) contextual changes.","Our solution goes beyond the state of the art by providing an architectural and methodological approach that continuously guarantees a stable non-functional behavior of ML-based applications, is applicable to different ML models, and is driven by non-functional properties assessed on the models themselves.","It consists of a two-step process working during application operation, where model assessment verifies non-functional properties of ML models trained and selected at development time, and model substitution guarantees a continuous and stable support of non-functional properties.","We experimentally evaluate our solution in a real-world scenario focusing on non-functional property fairness."],"url":"http://arxiv.org/abs/2311.12686v1"}
{"created":"2023-11-21 15:46:11","title":"Adversarial Reweighting Guided by Wasserstein Distance for Bias Mitigation","abstract":"The unequal representation of different groups in a sample population can lead to discrimination of minority groups when machine learning models make automated decisions. To address these issues, fairness-aware machine learning jointly optimizes two (or more) metrics aiming at predictive effectiveness and low unfairness. However, the inherent under-representation of minorities in the data makes the disparate treatment of subpopulations less noticeable and difficult to deal with during learning. In this paper, we propose a novel adversarial reweighting method to address such \\emph{representation bias}. To balance the data distribution between the majority and the minority groups, our approach deemphasizes samples from the majority group. To minimize empirical risk, our method prefers samples from the majority group that are close to the minority group as evaluated by the Wasserstein distance. Our theoretical analysis shows the effectiveness of our adversarial reweighting approach. Experiments demonstrate that our approach mitigates bias without sacrificing classification accuracy, outperforming related state-of-the-art methods on image and tabular benchmark datasets.","sentences":["The unequal representation of different groups in a sample population can lead to discrimination of minority groups when machine learning models make automated decisions.","To address these issues, fairness-aware machine learning jointly optimizes two (or more) metrics aiming at predictive effectiveness and low unfairness.","However, the inherent under-representation of minorities in the data makes the disparate treatment of subpopulations less noticeable and difficult to deal with during learning.","In this paper, we propose a novel adversarial reweighting method to address such \\emph{representation bias}.","To balance the data distribution between the majority and the minority groups, our approach deemphasizes samples from the majority group.","To minimize empirical risk, our method prefers samples from the majority group that are close to the minority group as evaluated by the Wasserstein distance.","Our theoretical analysis shows the effectiveness of our adversarial reweighting approach.","Experiments demonstrate that our approach mitigates bias without sacrificing classification accuracy, outperforming related state-of-the-art methods on image and tabular benchmark datasets."],"url":"http://arxiv.org/abs/2311.12684v1"}
{"created":"2023-11-21 15:39:21","title":"Transferring to Real-World Layouts: A Depth-aware Framework for Scene Adaptation","abstract":"Scene segmentation via unsupervised domain adaptation (UDA) enables the transfer of knowledge acquired from source synthetic data to real-world target data, which largely reduces the need for manual pixel-level annotations in the target domain. To facilitate domain-invariant feature learning, existing methods typically mix data from both the source domain and target domain by simply copying and pasting the pixels. Such vanilla methods are usually sub-optimal since they do not take into account how well the mixed layouts correspond to real-world scenarios. Real-world scenarios are with an inherent layout. We observe that semantic categories, such as sidewalks, buildings, and sky, display relatively consistent depth distributions, and could be clearly distinguished in a depth map. Based on such observation, we propose a depth-aware framework to explicitly leverage depth estimation to mix the categories and facilitate the two complementary tasks, i.e., segmentation and depth learning in an end-to-end manner. In particular, the framework contains a Depth-guided Contextual Filter (DCF) forndata augmentation and a cross-task encoder for contextual learning. DCF simulates the real-world layouts, while the cross-task encoder further adaptively fuses the complementing features between two tasks. Besides, it is worth noting that several public datasets do not provide depth annotation. Therefore, we leverage the off-the-shelf depth estimation network to generate the pseudo depth. Extensive experiments show that our proposed methods, even with pseudo depth, achieve competitive performance on two widely-used bench-marks, i.e. 77.7 mIoU on GTA to Cityscapes and 69.3 mIoU on Synthia to Cityscapes.","sentences":["Scene segmentation via unsupervised domain adaptation (UDA) enables the transfer of knowledge acquired from source synthetic data to real-world target data, which largely reduces the need for manual pixel-level annotations in the target domain.","To facilitate domain-invariant feature learning, existing methods typically mix data from both the source domain and target domain by simply copying and pasting the pixels.","Such vanilla methods are usually sub-optimal since they do not take into account how well the mixed layouts correspond to real-world scenarios.","Real-world scenarios are with an inherent layout.","We observe that semantic categories, such as sidewalks, buildings, and sky, display relatively consistent depth distributions, and could be clearly distinguished in a depth map.","Based on such observation, we propose a depth-aware framework to explicitly leverage depth estimation to mix the categories and facilitate the two complementary tasks, i.e., segmentation and depth learning in an end-to-end manner.","In particular, the framework contains a Depth-guided Contextual Filter (DCF) forndata augmentation and a cross-task encoder for contextual learning.","DCF simulates the real-world layouts, while the cross-task encoder further adaptively fuses the complementing features between two tasks.","Besides, it is worth noting that several public datasets do not provide depth annotation.","Therefore, we leverage the off-the-shelf depth estimation network to generate the pseudo depth.","Extensive experiments show that our proposed methods, even with pseudo depth, achieve competitive performance on two widely-used bench-marks, i.e. 77.7 mIoU on GTA to Cityscapes and 69.3 mIoU on Synthia to Cityscapes."],"url":"http://arxiv.org/abs/2311.12682v1"}
{"created":"2023-11-21 15:37:19","title":"BundleMoCap: Efficient, Robust and Smooth Motion Capture from Sparse Multiview Videos","abstract":"Capturing smooth motions from videos using markerless techniques typically involves complex processes such as temporal constraints, multiple stages with data-driven regression and optimization, and bundle solving over temporal windows. These processes can be inefficient and require tuning multiple objectives across stages. In contrast, BundleMoCap introduces a novel and efficient approach to this problem. It solves the motion capture task in a single stage, eliminating the need for temporal smoothness objectives while still delivering smooth motions. BundleMoCap outperforms the state-of-the-art without increasing complexity. The key concept behind BundleMoCap is manifold interpolation between latent keyframes. By relying on a local manifold smoothness assumption, we can efficiently solve a bundle of frames using a single code. Additionally, the method can be implemented as a sliding window optimization and requires only the first frame to be properly initialized, reducing the overall computational burden. BundleMoCap's strength lies in its ability to achieve high-quality motion capture results with simplicity and efficiency. More details can be found at https://moverseai.github.io/bundle/.","sentences":["Capturing smooth motions from videos using markerless techniques typically involves complex processes such as temporal constraints, multiple stages with data-driven regression and optimization, and bundle solving over temporal windows.","These processes can be inefficient and require tuning multiple objectives across stages.","In contrast, BundleMoCap introduces a novel and efficient approach to this problem.","It solves the motion capture task in a single stage, eliminating the need for temporal smoothness objectives while still delivering smooth motions.","BundleMoCap outperforms the state-of-the-art without increasing complexity.","The key concept behind BundleMoCap is manifold interpolation between latent keyframes.","By relying on a local manifold smoothness assumption, we can efficiently solve a bundle of frames using a single code.","Additionally, the method can be implemented as a sliding window optimization and requires only the first frame to be properly initialized, reducing the overall computational burden.","BundleMoCap's strength lies in its ability to achieve high-quality motion capture results with simplicity and efficiency.","More details can be found at https://moverseai.github.io/bundle/."],"url":"http://arxiv.org/abs/2311.12679v1"}
{"created":"2023-11-21 15:36:20","title":"Interpretation of the Transformer and Improvement of the Extractor","abstract":"It has been over six years since the Transformer architecture was put forward. Surprisingly, the vanilla Transformer architecture is still widely used today. One reason is that the lack of deep understanding and comprehensive interpretation of the Transformer architecture makes it more challenging to improve the Transformer architecture. In this paper, we first interpret the Transformer architecture comprehensively in plain words based on our understanding and experiences. The interpretations are further proved and verified. These interpretations also cover the Extractor, a family of drop-in replacements for the multi-head self-attention in the Transformer architecture. Then, we propose an improvement on a type of the Extractor that outperforms the self-attention, without introducing additional trainable parameters. Experimental results demonstrate that the improved Extractor performs even better, showing a way to improve the Transformer architecture.","sentences":["It has been over six years since the Transformer architecture was put forward.","Surprisingly, the vanilla Transformer architecture is still widely used today.","One reason is that the lack of deep understanding and comprehensive interpretation of the Transformer architecture makes it more challenging to improve the Transformer architecture.","In this paper, we first interpret the Transformer architecture comprehensively in plain words based on our understanding and experiences.","The interpretations are further proved and verified.","These interpretations also cover the Extractor, a family of drop-in replacements for the multi-head self-attention in the Transformer architecture.","Then, we propose an improvement on a type of the Extractor that outperforms the self-attention, without introducing additional trainable parameters.","Experimental results demonstrate that the improved Extractor performs even better, showing a way to improve the Transformer architecture."],"url":"http://arxiv.org/abs/2311.12678v1"}
{"created":"2023-11-21 15:31:16","title":"Contrastive Left-Right Wearable Sensors (IMUs) Consistency Matching for HAR","abstract":"Machine learning algorithms are improving rapidly, but annotating training data remains a bottleneck for many applications. In this paper, we show how real data can be used for self-supervised learning without any transformations by taking advantage of the symmetry present in the activities. Our approach involves contrastive matching of two different sensors (left and right wrist or leg-worn IMUs) to make representations of co-occurring sensor data more similar and those of non-co-occurring sensor data more different. We test our approach on the Opportunity and MM-Fit datasets. In MM-Fit we show significant improvement over the baseline supervised and self-supervised method SimCLR, while for Opportunity there is significant improvement over the supervised baseline and slight improvement when compared to SimCLR. Moreover, our method improves supervised baselines even when using only a small amount of the data for training. Future work should explore under which conditions our method is beneficial for human activity recognition systems and other related applications.","sentences":["Machine learning algorithms are improving rapidly, but annotating training data remains a bottleneck for many applications.","In this paper, we show how real data can be used for self-supervised learning without any transformations by taking advantage of the symmetry present in the activities.","Our approach involves contrastive matching of two different sensors (left and right wrist or leg-worn IMUs) to make representations of co-occurring sensor data more similar and those of non-co-occurring sensor data more different.","We test our approach on the Opportunity and MM-Fit datasets.","In MM-Fit we show significant improvement over the baseline supervised and self-supervised method SimCLR, while for Opportunity there is significant improvement over the supervised baseline and slight improvement when compared to SimCLR.","Moreover, our method improves supervised baselines even when using only a small amount of the data for training.","Future work should explore under which conditions our method is beneficial for human activity recognition systems and other related applications."],"url":"http://arxiv.org/abs/2311.12674v1"}
{"created":"2023-11-21 15:28:44","title":"Towards a more inductive world for drug repurposing approaches","abstract":"Drug-target interaction (DTI) prediction is a challenging, albeit essential task in drug repurposing. Learning on graph models have drawn special attention as they can significantly reduce drug repurposing costs and time commitment. However, many current approaches require high-demanding additional information besides DTIs that complicates their evaluation process and usability. Additionally, structural differences in the learning architecture of current models hinder their fair benchmarking. In this work, we first perform an in-depth evaluation of current DTI datasets and prediction models through a robust benchmarking process, and show that DTI prediction methods based on transductive models lack generalization and lead to inflated performance when evaluated as previously done in the literature, hence not being suited for drug repurposing approaches. We then propose a novel biologically-driven strategy for negative edge subsampling and show through in vitro validation that newly discovered interactions are indeed true. We envision this work as the underpinning for future fair benchmarking and robust model design. All generated resources and tools are publicly available as a python package.","sentences":["Drug-target interaction (DTI) prediction is a challenging, albeit essential task in drug repurposing.","Learning on graph models have drawn special attention as they can significantly reduce drug repurposing costs and time commitment.","However, many current approaches require high-demanding additional information besides DTIs that complicates their evaluation process and usability.","Additionally, structural differences in the learning architecture of current models hinder their fair benchmarking.","In this work, we first perform an in-depth evaluation of current DTI datasets and prediction models through a robust benchmarking process, and show that DTI prediction methods based on transductive models lack generalization and lead to inflated performance when evaluated as previously done in the literature, hence not being suited for drug repurposing approaches.","We then propose a novel biologically-driven strategy for negative edge subsampling and show through in vitro validation that newly discovered interactions are indeed true.","We envision this work as the underpinning for future fair benchmarking and robust model design.","All generated resources and tools are publicly available as a python package."],"url":"http://arxiv.org/abs/2311.12670v1"}
{"created":"2023-11-21 15:20:48","title":"From Concept to Manufacturing: Evaluating Vision-Language Models for Engineering Design","abstract":"Engineering Design is undergoing a transformative shift with the advent of AI, marking a new era in how we approach product, system, and service planning. Large language models have demonstrated impressive capabilities in enabling this shift. Yet, with text as their only input modality, they cannot leverage the large body of visual artifacts that engineers have used for centuries and are accustomed to. This gap is addressed with the release of multimodal vision language models, such as GPT-4V, enabling AI to impact many more types of tasks. In light of these advancements, this paper presents a comprehensive evaluation of GPT-4V, a vision language model, across a wide spectrum of engineering design tasks, categorized into four main areas: Conceptual Design, System-Level and Detailed Design, Manufacturing and Inspection, and Engineering Education Tasks. Our study assesses GPT-4V's capabilities in design tasks such as sketch similarity analysis, concept selection using Pugh Charts, material selection, engineering drawing analysis, CAD generation, topology optimization, design for additive and subtractive manufacturing, spatial reasoning challenges, and textbook problems. Through this structured evaluation, we not only explore GPT-4V's proficiency in handling complex design and manufacturing challenges but also identify its limitations in complex engineering design applications. Our research establishes a foundation for future assessments of vision language models, emphasizing their immense potential for innovating and enhancing the engineering design and manufacturing landscape. It also contributes a set of benchmark testing datasets, with more than 1000 queries, for ongoing advancements and applications in this field.","sentences":["Engineering Design is undergoing a transformative shift with the advent of AI, marking a new era in how we approach product, system, and service planning.","Large language models have demonstrated impressive capabilities in enabling this shift.","Yet, with text as their only input modality, they cannot leverage the large body of visual artifacts that engineers have used for centuries and are accustomed to.","This gap is addressed with the release of multimodal vision language models, such as GPT-4V, enabling AI to impact many more types of tasks.","In light of these advancements, this paper presents a comprehensive evaluation of GPT-4V, a vision language model, across a wide spectrum of engineering design tasks, categorized into four main areas: Conceptual Design, System-Level and Detailed Design, Manufacturing and Inspection, and Engineering Education Tasks.","Our study assesses GPT-4V's capabilities in design tasks such as sketch similarity analysis, concept selection using Pugh Charts, material selection, engineering drawing analysis, CAD generation, topology optimization, design for additive and subtractive manufacturing, spatial reasoning challenges, and textbook problems.","Through this structured evaluation, we not only explore GPT-4V's proficiency in handling complex design and manufacturing challenges but also identify its limitations in complex engineering design applications.","Our research establishes a foundation for future assessments of vision language models, emphasizing their immense potential for innovating and enhancing the engineering design and manufacturing landscape.","It also contributes a set of benchmark testing datasets, with more than 1000 queries, for ongoing advancements and applications in this field."],"url":"http://arxiv.org/abs/2311.12668v1"}
{"created":"2023-11-21 15:14:54","title":"The DURel Annotation Tool: Human and Computational Measurement of Semantic Proximity, Sense Clusters and Semantic Change","abstract":"We present the DURel tool that implements the annotation of semantic proximity between uses of words into an online, open source interface. The tool supports standardized human annotation as well as computational annotation, building on recent advances with Word-in-Context models. Annotator judgments are clustered with automatic graph clustering techniques and visualized for analysis. This allows to measure word senses with simple and intuitive micro-task judgments between use pairs, requiring minimal preparation efforts. The tool offers additional functionalities to compare the agreement between annotators to guarantee the inter-subjectivity of the obtained judgments and to calculate summary statistics giving insights into sense frequency distributions, semantic variation or changes of senses over time.","sentences":["We present the DURel tool that implements the annotation of semantic proximity between uses of words into an online, open source interface.","The tool supports standardized human annotation as well as computational annotation, building on recent advances with Word-in-Context models.","Annotator judgments are clustered with automatic graph clustering techniques and visualized for analysis.","This allows to measure word senses with simple and intuitive micro-task judgments between use pairs, requiring minimal preparation efforts.","The tool offers additional functionalities to compare the agreement between annotators to guarantee the inter-subjectivity of the obtained judgments and to calculate summary statistics giving insights into sense frequency distributions, semantic variation or changes of senses over time."],"url":"http://arxiv.org/abs/2311.12664v1"}
{"created":"2023-11-21 15:13:18","title":"Similar Document Template Matching Algorithm","abstract":"This study outlines a comprehensive methodology for verifying medical documents, integrating advanced techniques in template extraction, comparison, and fraud detection. It begins with template extraction using sophisticated region-of-interest (ROI) methods, incorporating contour analysis and edge identification. Pre-processing steps ensure template clarity through morphological operations and adaptive thresholding. The template comparison algorithm utilizes advanced feature matching with key points and descriptors, enhancing robustness through histogram-based analysis for accounting variations. Fraud detection involves the SSIM computation and OCR for textual information extraction. The SSIM quantifies structural similarity, aiding in potential match identification. OCR focuses on critical areas like patient details, provider information, and billing amounts. Extracted information is compared with a reference dataset, and confidence thresholding ensures reliable fraud detection. Adaptive parameters enhance system flexibility for dynamic adjustments to varying document layouts. This methodology provides a robust approach to medical document verification, addressing complexities in template extraction, comparison, fraud detection, and adaptability to diverse document structures.","sentences":["This study outlines a comprehensive methodology for verifying medical documents, integrating advanced techniques in template extraction, comparison, and fraud detection.","It begins with template extraction using sophisticated region-of-interest (ROI) methods, incorporating contour analysis and edge identification.","Pre-processing steps ensure template clarity through morphological operations and adaptive thresholding.","The template comparison algorithm utilizes advanced feature matching with key points and descriptors, enhancing robustness through histogram-based analysis for accounting variations.","Fraud detection involves the SSIM computation and OCR for textual information extraction.","The SSIM quantifies structural similarity, aiding in potential match identification.","OCR focuses on critical areas like patient details, provider information, and billing amounts.","Extracted information is compared with a reference dataset, and confidence thresholding ensures reliable fraud detection.","Adaptive parameters enhance system flexibility for dynamic adjustments to varying document layouts.","This methodology provides a robust approach to medical document verification, addressing complexities in template extraction, comparison, fraud detection, and adaptability to diverse document structures."],"url":"http://arxiv.org/abs/2311.12663v1"}
{"created":"2023-11-21 15:08:17","title":"Visually Guided Object Grasping","abstract":"In this paper we present a visual servoing approach to the problem of object grasping and more generally, to the problem of aligning an end-effector with an object. First we extend the method proposed by Espiau et al. [1] to the case of a camera which is not mounted onto the robot being controlled and we stress the importance of the real-time estimation of the image Jacobian. Second, we show how to represent a grasp or more generally, an alignment between two solids in 3-D projective space using an uncalibrated stereo rig. Such a 3-D projective representation is view-invariant in the sense that it can be easily mapped into an image set-point without any knowledge about the camera parameters. Third, we perform an analysis of the performances of the visual servoing algorithm and of the grasping precision that can be expected from this type of approach.","sentences":["In this paper we present a visual servoing approach to the problem of object grasping and more generally, to the problem of aligning an end-effector with an object.","First we extend the method proposed by Espiau et al.","[1] to the case of a camera which is not mounted onto the robot being controlled and we stress the importance of the real-time estimation of the image Jacobian.","Second, we show how to represent a grasp or more generally, an alignment between two solids in 3-D projective space using an uncalibrated stereo rig.","Such a 3-D projective representation is view-invariant in the sense that it can be easily mapped into an image set-point without any knowledge about the camera parameters.","Third, we perform an analysis of the performances of the visual servoing algorithm and of the grasping precision that can be expected from this type of approach."],"url":"http://arxiv.org/abs/2311.12660v1"}
{"created":"2023-11-21 15:01:14","title":"Carbohydrate NMR chemical shift predictions using E(3) equivariant graph neural networks","abstract":"Carbohydrates, vital components of biological systems, are well-known for their structural diversity. Nuclear Magnetic Resonance (NMR) spectroscopy plays a crucial role in understanding their intricate molecular arrangements and is essential in assessing and verifying the molecular structure of organic molecules. An important part of this process is to predict the NMR chemical shift from the molecular structure. This work introduces a novel approach that leverages E(3) equivariant graph neural networks to predict carbohydrate NMR spectra. Notably, our model achieves a substantial reduction in mean absolute error, up to threefold, compared to traditional models that rely solely on two-dimensional molecular structure. Even with limited data, the model excels, highlighting its robustness and generalization capabilities. The implications are far-reaching and go beyond an advanced understanding of carbohydrate structures and spectral interpretation. For example, it could accelerate research in pharmaceutical applications, biochemistry, and structural biology, offering a faster and more reliable analysis of molecular structures. Furthermore, our approach is a key step towards a new data-driven era in spectroscopy, potentially influencing spectroscopic techniques beyond NMR.","sentences":["Carbohydrates, vital components of biological systems, are well-known for their structural diversity.","Nuclear Magnetic Resonance (NMR) spectroscopy plays a crucial role in understanding their intricate molecular arrangements and is essential in assessing and verifying the molecular structure of organic molecules.","An important part of this process is to predict the NMR chemical shift from the molecular structure.","This work introduces a novel approach that leverages E(3) equivariant graph neural networks to predict carbohydrate NMR spectra.","Notably, our model achieves a substantial reduction in mean absolute error, up to threefold, compared to traditional models that rely solely on two-dimensional molecular structure.","Even with limited data, the model excels, highlighting its robustness and generalization capabilities.","The implications are far-reaching and go beyond an advanced understanding of carbohydrate structures and spectral interpretation.","For example, it could accelerate research in pharmaceutical applications, biochemistry, and structural biology, offering a faster and more reliable analysis of molecular structures.","Furthermore, our approach is a key step towards a new data-driven era in spectroscopy, potentially influencing spectroscopic techniques beyond NMR."],"url":"http://arxiv.org/abs/2311.12657v1"}
{"created":"2023-11-21 14:57:24","title":"Hand-Eye Calibration","abstract":"Whenever a sensor is mounted on a robot hand it is important to know the relationship between the sensor and the hand. The problem of determining this relationship is referred to as hand-eye calibration, which is important in at least two types of tasks: (i) map sensor centered measurements into the robot workspace and (ii) allow the robot to precisely move the sensor. In the past some solutions were proposed in the particular case of a camera. With almost no exception, all existing solutions attempt to solve the homogeneous matrix equation AX=XB. First we show that there are two possible formulations of the hand-eye calibration problem. One formulation is the classical one that we just mentioned. A second formulation takes the form of the following homogeneous matrix equation: MY=M'YB. The advantage of the latter is that the extrinsic and intrinsic camera parameters need not be made explicit. Indeed, this formulation directly uses the 3 by 4 perspective matrices (M and M') associated with two positions of the camera. Moreover, this formulation together with the classical one cover a wider range of camera-based sensors to be calibrated with respect to the robot hand. Second, we develop a common mathematical framework to solve for the hand-eye calibration problem using either of the two formulations. We present two methods, (i) a rotation then translation and (ii) a non-linear solver for rotation and translation. Third, we perform a stability analysis both for our two methods and for the classical linear method developed. In the light of this comparison, the non-linear optimization method, that solves for rotation and translation simultaneously, seems to be the most robust one with respect to noise and to measurement errors.","sentences":["Whenever a sensor is mounted on a robot hand it is important to know the relationship between the sensor and the hand.","The problem of determining this relationship is referred to as hand-eye calibration, which is important in at least two types of tasks: (i) map sensor centered measurements into the robot workspace and (ii) allow the robot to precisely move the sensor.","In the past some solutions were proposed in the particular case of a camera.","With almost no exception, all existing solutions attempt to solve the homogeneous matrix equation AX=XB.","First we show that there are two possible formulations of the hand-eye calibration problem.","One formulation is the classical one that we just mentioned.","A second formulation takes the form of the following homogeneous matrix equation: MY=M'YB.","The advantage of the latter is that the extrinsic and intrinsic camera parameters need not be made explicit.","Indeed, this formulation directly uses the 3 by 4 perspective matrices (M and M') associated with two positions of the camera.","Moreover, this formulation together with the classical one cover a wider range of camera-based sensors to be calibrated with respect to the robot hand.","Second, we develop a common mathematical framework to solve for the hand-eye calibration problem using either of the two formulations.","We present two methods, (i) a rotation then translation and (ii) a non-linear solver for rotation and translation.","Third, we perform a stability analysis both for our two methods and for the classical linear method developed.","In the light of this comparison, the non-linear optimization method, that solves for rotation and translation simultaneously, seems to be the most robust one with respect to noise and to measurement errors."],"url":"http://arxiv.org/abs/2311.12655v1"}
{"created":"2023-11-21 14:56:55","title":"PARK: Parkinson's Analysis with Remote Kinetic-tasks","abstract":"We present a web-based framework to screen for Parkinson's disease (PD) by allowing users to perform neurological tests in their homes. Our web framework guides the users to complete three tasks involving speech, facial expression, and finger movements. The task videos are analyzed to classify whether the users show signs of PD. We present the results in an easy-to-understand manner, along with personalized resources to further access to treatment and care. Our framework is accessible by any major web browser, improving global access to neurological care.","sentences":["We present a web-based framework to screen for Parkinson's disease (PD) by allowing users to perform neurological tests in their homes.","Our web framework guides the users to complete three tasks involving speech, facial expression, and finger movements.","The task videos are analyzed to classify whether the users show signs of PD.","We present the results in an easy-to-understand manner, along with personalized resources to further access to treatment and care.","Our framework is accessible by any major web browser, improving global access to neurological care."],"url":"http://arxiv.org/abs/2311.12654v1"}
{"created":"2023-11-21 14:53:39","title":"FedDRO: Federated Compositional Optimization for Distributionally Robust Learning","abstract":"Recently, compositional optimization (CO) has gained popularity because of its applications in distributionally robust optimization (DRO) and many other machine learning problems. Large-scale and distributed availability of data demands the development of efficient federated learning (FL) algorithms for solving CO problems. Developing FL algorithms for CO is particularly challenging because of the compositional nature of the objective. Moreover, current state-of-the-art methods to solve such problems rely on large batch gradients (depending on the solution accuracy) not feasible for most practical settings. To address these challenges, in this work, we propose efficient FedAvg-type algorithms for solving non-convex CO in the FL setting. We first establish that vanilla FedAvg is not suitable to solve distributed CO problems because of the data heterogeneity in the compositional objective at each client which leads to the amplification of bias in the local compositional gradient estimates. To this end, we propose a novel FL framework FedDRO that utilizes the DRO problem structure to design a communication strategy that allows FedAvg to control the bias in the estimation of the compositional gradient. A key novelty of our work is to develop solution accuracy-independent algorithms that do not require large batch gradients (and function evaluations) for solving federated CO problems. We establish $\\mathcal{O}(\\epsilon^{-2})$ sample and $\\mathcal{O}(\\epsilon^{-3/2})$ communication complexity in the FL setting while achieving linear speedup with the number of clients. We corroborate our theoretical findings with empirical studies on large-scale DRO problems.","sentences":["Recently, compositional optimization (CO) has gained popularity because of its applications in distributionally robust optimization (DRO) and many other machine learning problems.","Large-scale and distributed availability of data demands the development of efficient federated learning (FL) algorithms for solving CO problems.","Developing FL algorithms for CO is particularly challenging because of the compositional nature of the objective.","Moreover, current state-of-the-art methods to solve such problems rely on large batch gradients (depending on the solution accuracy) not feasible for most practical settings.","To address these challenges, in this work, we propose efficient FedAvg-type algorithms for solving non-convex CO in the FL setting.","We first establish that vanilla FedAvg is not suitable to solve distributed CO problems because of the data heterogeneity in the compositional objective at each client which leads to the amplification of bias in the local compositional gradient estimates.","To this end, we propose a novel FL framework FedDRO that utilizes the DRO problem structure to design a communication strategy that allows FedAvg to control the bias in the estimation of the compositional gradient.","A key novelty of our work is to develop solution accuracy-independent algorithms that do not require large batch gradients (and function evaluations) for solving federated CO problems.","We establish $\\mathcal{O}(\\epsilon^{-2})$ sample and $\\mathcal{O}(\\epsilon^{-3/2})$ communication complexity in the FL setting while achieving linear speedup with the number of clients.","We corroborate our theoretical findings with empirical studies on large-scale DRO problems."],"url":"http://arxiv.org/abs/2311.12652v1"}
{"created":"2023-11-21 14:53:02","title":"Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for Mobile Robots","abstract":"Precise and rapid delineation of sharp boundaries and robust semantics is essential for numerous downstream robotic tasks, such as robot grasping and manipulation, real-time semantic mapping, and online sensor calibration performed on edge computing units. Although boundary detection and semantic segmentation are complementary tasks, most studies focus on lightweight models for semantic segmentation but overlook the critical role of boundary detection. In this work, we introduce Mobile-Seed, a lightweight, dual-task framework tailored for simultaneous semantic segmentation and boundary detection. Our framework features a two-stream encoder, an active fusion decoder (AFD) and a dual-task regularization approach. The encoder is divided into two pathways: one captures category-aware semantic information, while the other discerns boundaries from multi-scale features. The AFD module dynamically adapts the fusion of semantic and boundary information by learning channel-wise relationships, allowing for precise weight assignment of each channel. Furthermore, we introduce a regularization loss to mitigate the conflicts in dual-task learning and deep diversity supervision. Compared to existing methods, the proposed Mobile-Seed offers a lightweight framework to simultaneously improve semantic segmentation performance and accurately locate object boundaries. Experiments on the Cityscapes dataset have shown that Mobile-Seed achieves notable improvement over the state-of-the-art (SOTA) baseline by 2.2 percentage points (pp) in mIoU and 4.2 pp in mF-score, while maintaining an online inference speed of 23.9 frames-per-second (FPS) with 1024x2048 resolution input on an RTX 2080 Ti GPU. Additional experiments on CamVid and PASCAL Context datasets confirm our method's generalizability. Code and additional results are publicly available at \\url{https://martin-liao.github.io/Mobile-Seed/}.","sentences":["Precise and rapid delineation of sharp boundaries and robust semantics is essential for numerous downstream robotic tasks, such as robot grasping and manipulation, real-time semantic mapping, and online sensor calibration performed on edge computing units.","Although boundary detection and semantic segmentation are complementary tasks, most studies focus on lightweight models for semantic segmentation but overlook the critical role of boundary detection.","In this work, we introduce Mobile-Seed, a lightweight, dual-task framework tailored for simultaneous semantic segmentation and boundary detection.","Our framework features a two-stream encoder, an active fusion decoder (AFD) and a dual-task regularization approach.","The encoder is divided into two pathways: one captures category-aware semantic information, while the other discerns boundaries from multi-scale features.","The AFD module dynamically adapts the fusion of semantic and boundary information by learning channel-wise relationships, allowing for precise weight assignment of each channel.","Furthermore, we introduce a regularization loss to mitigate the conflicts in dual-task learning and deep diversity supervision.","Compared to existing methods, the proposed Mobile-Seed offers a lightweight framework to simultaneously improve semantic segmentation performance and accurately locate object boundaries.","Experiments on the Cityscapes dataset have shown that Mobile-Seed achieves notable improvement over the state-of-the-art (SOTA) baseline by 2.2 percentage points (pp) in mIoU and 4.2 pp in mF-score, while maintaining an online inference speed of 23.9 frames-per-second (FPS) with 1024x2048 resolution input on an RTX 2080 Ti GPU.","Additional experiments on CamVid and PASCAL Context datasets confirm our method's generalizability.","Code and additional results are publicly available at \\url{https://martin-liao.github.io/Mobile-Seed/}."],"url":"http://arxiv.org/abs/2311.12651v1"}
{"created":"2023-11-21 14:49:00","title":"MathGloss: Building mathematical glossaries from text","abstract":"MathGloss is a project to create a knowledge graph (KG) for undergraduate mathematics from text, automatically, using modern natural language processing (NLP) tools and resources already available on the web. MathGloss is a linked database of undergraduate concepts in mathematics. So far, it combines five resources: (i) Wikidata, a collaboratively edited, multilingual knowledge graph hosted by the Wikimedia Foundation, (ii) terms covered in mathematics courses at the University of Chicago, (iii) the syllabus of the French undergraduate mathematics curriculum which includes hyperlinks to the automated theorem prover Lean 4, (iv) MuLiMa, a multilingual dictionary of mathematics curated by mathematicians, and (v) the nLab, a wiki for category theory also curated by mathematicians. MathGloss's goal is to bring together resources for learning mathematics and to allow every mathematician to tailor their learning to their own preferences. Moreover, by organizing different resources for learning undergraduate mathematics alongside those for learning formal mathematics, we hope to make it easier for mathematicians and formal tools (theorem provers, computer algebra systems, etc) experts to \"understand\" each other and break down some of the barriers to formal math.","sentences":["MathGloss is a project to create a knowledge graph (KG) for undergraduate mathematics from text, automatically, using modern natural language processing (NLP) tools and resources already available on the web.","MathGloss is a linked database of undergraduate concepts in mathematics.","So far, it combines five resources: (i) Wikidata, a collaboratively edited, multilingual knowledge graph hosted by the Wikimedia Foundation, (ii) terms covered in mathematics courses at the University of Chicago, (iii) the syllabus of the French undergraduate mathematics curriculum which includes hyperlinks to the automated theorem prover Lean 4, (iv) MuLiMa, a multilingual dictionary of mathematics curated by mathematicians, and (v) the nLab, a wiki for category theory also curated by mathematicians.","MathGloss's goal is to bring together resources for learning mathematics and to allow every mathematician to tailor their learning to their own preferences.","Moreover, by organizing different resources for learning undergraduate mathematics alongside those for learning formal mathematics, we hope to make it easier for mathematicians and formal tools (theorem provers, computer algebra systems, etc) experts to \"understand\" each other and break down some of the barriers to formal math."],"url":"http://arxiv.org/abs/2311.12649v1"}
{"created":"2023-11-21 14:48:12","title":"D-GATE: Decentralized Geolocation and Time Enforcement for Usage Control","abstract":"In the context of cloud environments, data providers entrust their data to data consumers in order to allow further computing on their own IT infrastructure. Usage control measures allow the data provider to restrict the usage of its data even on the data consumer's system. Two of these restrictions can be the geographic location and time limitations. Current solutions that could be used to enforce such constraints can be easily manipulated. These include solutions based on the system time, organizational agreements, GPS-based techniques or simple delay measurements to derive the distance to known reference servers. With D-GATE, we propose a reliable solution that uses trusted execution environments and relies on a decentralized mesh of reference nodes, so-called GeoClients. Here, participants periodically measure the lowest network delay to each other to geolocate themselves. For data providers, it is thus possible to technically attest usage control with time and geolocation constraints without depending on centralized reference systems.","sentences":["In the context of cloud environments, data providers entrust their data to data consumers in order to allow further computing on their own IT infrastructure.","Usage control measures allow the data provider to restrict the usage of its data even on the data consumer's system.","Two of these restrictions can be the geographic location and time limitations.","Current solutions that could be used to enforce such constraints can be easily manipulated.","These include solutions based on the system time, organizational agreements, GPS-based techniques or simple delay measurements to derive the distance to known reference servers.","With D-GATE, we propose a reliable solution that uses trusted execution environments and relies on a decentralized mesh of reference nodes, so-called GeoClients.","Here, participants periodically measure the lowest network delay to each other to geolocate themselves.","For data providers, it is thus possible to technically attest usage control with time and geolocation constraints without depending on centralized reference systems."],"url":"http://arxiv.org/abs/2311.12647v1"}
{"created":"2023-11-21 14:44:51","title":"Careful Selection and Thoughtful Discarding: Graph Explicit Pooling Utilizing Discarded Nodes","abstract":"Graph pooling has been increasingly recognized as crucial for Graph Neural Networks (GNNs) to facilitate hierarchical graph representation learning. Existing graph pooling methods commonly consist of two stages: selecting top-ranked nodes and discarding the remaining to construct coarsened graph representations. However, this paper highlights two key issues with these methods: 1) The process of selecting nodes to discard frequently employs additional Graph Convolutional Networks or Multilayer Perceptrons, lacking a thorough evaluation of each node's impact on the final graph representation and subsequent prediction tasks. 2) Current graph pooling methods tend to directly discard the noise segment (dropped) of the graph without accounting for the latent information contained within these elements. To address the first issue, we introduce a novel Graph Explicit Pooling (GrePool) method, which selects nodes by explicitly leveraging the relationships between the nodes and final representation vectors crucial for classification. The second issue is addressed using an extended version of GrePool (i.e., GrePool+), which applies a uniform loss on the discarded nodes. This addition is designed to augment the training process and improve classification accuracy. Furthermore, we conduct comprehensive experiments across 12 widely used datasets to validate our proposed method's effectiveness, including the Open Graph Benchmark datasets. Our experimental results uniformly demonstrate that GrePool outperforms 14 baseline methods for most datasets. Likewise, implementing GrePool+ enhances GrePool's performance without incurring additional computational costs.","sentences":["Graph pooling has been increasingly recognized as crucial for Graph Neural Networks (GNNs) to facilitate hierarchical graph representation learning.","Existing graph pooling methods commonly consist of two stages: selecting top-ranked nodes and discarding the remaining to construct coarsened graph representations.","However, this paper highlights two key issues with these methods: 1) The process of selecting nodes to discard frequently employs additional Graph Convolutional Networks or Multilayer Perceptrons, lacking a thorough evaluation of each node's impact on the final graph representation and subsequent prediction tasks.","2) Current graph pooling methods tend to directly discard the noise segment (dropped) of the graph without accounting for the latent information contained within these elements.","To address the first issue, we introduce a novel Graph Explicit Pooling (GrePool) method, which selects nodes by explicitly leveraging the relationships between the nodes and final representation vectors crucial for classification.","The second issue is addressed using an extended version of GrePool (i.e., GrePool+), which applies a uniform loss on the discarded nodes.","This addition is designed to augment the training process and improve classification accuracy.","Furthermore, we conduct comprehensive experiments across 12 widely used datasets to validate our proposed method's effectiveness, including the Open Graph Benchmark datasets.","Our experimental results uniformly demonstrate that GrePool outperforms 14 baseline methods for most datasets.","Likewise, implementing GrePool+ enhances GrePool's performance without incurring additional computational costs."],"url":"http://arxiv.org/abs/2311.12644v1"}
{"created":"2023-11-21 14:41:21","title":"Polyhedral Object Recognition by Indexing","abstract":"In computer vision, the indexing problem is the problem of recognizing a few objects in a large database of objects while avoiding the help of the classical image-feature-to-object-feature matching paradigm. In this paper we address the problem of recognizing 3-D polyhedral objects from 2-D images by indexing. Both the objects to be recognized and the images are represented by weighted graphs. The indexing problem is therefore the problem of determining whether a graph extracted from the image is present or absent in a database of model graphs. We introduce a novel method for performing this graph indexing process which is based both on polynomial characterization of binary and weighted graphs and on hashing. We describe in detail this polynomial characterization and then we show how it can be used in the context of polyhedral object recognition. Next we describe a practical recognition-by-indexing system that includes the organization of the database, the representation of polyhedral objects in terms of 2-D characteristic views, the representation of this views in terms of weighted graphs, and the associated image processing. Finally, some experimental results allow the evaluation of the system performance.","sentences":["In computer vision, the indexing problem is the problem of recognizing a few objects in a large database of objects while avoiding the help of the classical image-feature-to-object-feature matching paradigm.","In this paper we address the problem of recognizing 3-D polyhedral objects from 2-D images by indexing.","Both the objects to be recognized and the images are represented by weighted graphs.","The indexing problem is therefore the problem of determining whether a graph extracted from the image is present or absent in a database of model graphs.","We introduce a novel method for performing this graph indexing process which is based both on polynomial characterization of binary and weighted graphs and on hashing.","We describe in detail this polynomial characterization and then we show how it can be used in the context of polyhedral object recognition.","Next we describe a practical recognition-by-indexing system that includes the organization of the database, the representation of polyhedral objects in terms of 2-D characteristic views, the representation of this views in terms of weighted graphs, and the associated image processing.","Finally, some experimental results allow the evaluation of the system performance."],"url":"http://arxiv.org/abs/2311.12641v1"}
{"created":"2023-11-21 14:39:18","title":"KNVQA: A Benchmark for evaluation knowledge-based VQA","abstract":"Within the multimodal field, large vision-language models (LVLMs) have made significant progress due to their strong perception and reasoning capabilities in the visual and language systems. However, LVLMs are still plagued by the two critical issues of object hallucination and factual accuracy, which limit the practicality of LVLMs in different scenarios. Furthermore, previous evaluation methods focus more on the comprehension and reasoning of language content but lack a comprehensive evaluation of multimodal interactions, thereby resulting in potential limitations. To this end, we propose a novel KNVQA-Eval, which is devoted to knowledge-based VQA task evaluation to reflect the factuality of multimodal LVLMs. To ensure the robustness and scalability of the evaluation, we develop a new KNVQA dataset by incorporating human judgment and perception, aiming to evaluate the accuracy of standard answers relative to AI-generated answers in knowledge-based VQA. This work not only comprehensively evaluates the contextual information of LVLMs using reliable human annotations, but also further analyzes the fine-grained capabilities of current methods to reveal potential avenues for subsequent optimization of LVLMs-based estimators. Our proposed VQA-Eval and corresponding dataset KNVQA will facilitate the development of automatic evaluation tools with the advantages of low cost, privacy protection, and reproducibility. Our code will be released upon publication.","sentences":["Within the multimodal field, large vision-language models (LVLMs) have made significant progress due to their strong perception and reasoning capabilities in the visual and language systems.","However, LVLMs are still plagued by the two critical issues of object hallucination and factual accuracy, which limit the practicality of LVLMs in different scenarios.","Furthermore, previous evaluation methods focus more on the comprehension and reasoning of language content but lack a comprehensive evaluation of multimodal interactions, thereby resulting in potential limitations.","To this end, we propose a novel KNVQA-Eval, which is devoted to knowledge-based VQA task evaluation to reflect the factuality of multimodal LVLMs.","To ensure the robustness and scalability of the evaluation, we develop a new KNVQA dataset by incorporating human judgment and perception, aiming to evaluate the accuracy of standard answers relative to AI-generated answers in knowledge-based VQA.","This work not only comprehensively evaluates the contextual information of LVLMs using reliable human annotations, but also further analyzes the fine-grained capabilities of current methods to reveal potential avenues for subsequent optimization of LVLMs-based estimators.","Our proposed VQA-Eval and corresponding dataset KNVQA will facilitate the development of automatic evaluation tools with the advantages of low cost, privacy protection, and reproducibility.","Our code will be released upon publication."],"url":"http://arxiv.org/abs/2311.12639v1"}
{"created":"2023-11-21 14:29:24","title":"A new paradigm for the efficient inclusion of stochasticity in engineering simulations","abstract":"As a physical fact, randomness is an inherent and ineliminable aspect in all physical measurements and engineering production. As a consequence, material parameters, serving as input data, are only known in a stochastic sense and thus, also output parameters, e.g., stresses, fluctuate. For the estimation of those fluctuations it is imperative to incoporate randomness into engineering simulations. Unfortunately, incorporating uncertain parameters into the modeling and simulation of inelastic materials is often computationally expensive, as many individual simulations may have to be performed. The promise of the proposed method is simple: using extended material models to include stochasticity reduces the number of needed simulations to one. This single computation is cheap, i.e., it has a comparable numerical effort as a single standard simulation. The extended material models are easily derived from standard deterministic material models and account for the effect of uncertainty by an extended set of deterministic material parameters. The time-dependent and stochastic material behavior are separated, such that only the deterministic time-dependent behavior of the extended material model needs to be simulated. The effect of stochasticity is then included during post-processing. The feasibility of this approach is demonstrated for three different and highly non-linear material models: viscous damage, viscous phase transformations and elasto-viscoplasticity. A comparison to the Monte Carlo method showcases that the method is indeed able to provide reliable estimates of the expectation and variance of internal variables and stress at a minimal fraction of the computation cost.","sentences":["As a physical fact, randomness is an inherent and ineliminable aspect in all physical measurements and engineering production.","As a consequence, material parameters, serving as input data, are only known in a stochastic sense and thus, also output parameters, e.g., stresses, fluctuate.","For the estimation of those fluctuations it is imperative to incoporate randomness into engineering simulations.","Unfortunately, incorporating uncertain parameters into the modeling and simulation of inelastic materials is often computationally expensive, as many individual simulations may have to be performed.","The promise of the proposed method is simple: using extended material models to include stochasticity reduces the number of needed simulations to one.","This single computation is cheap, i.e., it has a comparable numerical effort as a single standard simulation.","The extended material models are easily derived from standard deterministic material models and account for the effect of uncertainty by an extended set of deterministic material parameters.","The time-dependent and stochastic material behavior are separated, such that only the deterministic time-dependent behavior of the extended material model needs to be simulated.","The effect of stochasticity is then included during post-processing.","The feasibility of this approach is demonstrated for three different and highly non-linear material models: viscous damage, viscous phase transformations and elasto-viscoplasticity.","A comparison to the Monte Carlo method showcases that the method is indeed able to provide reliable estimates of the expectation and variance of internal variables and stress at a minimal fraction of the computation cost."],"url":"http://arxiv.org/abs/2311.12636v1"}
{"created":"2023-11-21 14:24:37","title":"GPT4Motion: Scripting Physical Motions in Text-to-Video Generation via Blender-Oriented GPT Planning","abstract":"Recent advances in text-to-video generation have harnessed the power of diffusion models to create visually compelling content conditioned on text prompts. However, they usually encounter high computational costs and often struggle to produce videos with coherent physical motions. To tackle these issues, we propose GPT4Motion, a training-free framework that leverages the planning capability of large language models such as GPT, the physical simulation strength of Blender, and the excellent image generation ability of text-to-image diffusion models to enhance the quality of video synthesis. Specifically, GPT4Motion employs GPT-4 to generate a Blender script based on a user textual prompt, which commands Blender's built-in physics engine to craft fundamental scene components that encapsulate coherent physical motions across frames. Then these components are inputted into Stable Diffusion to generate a video aligned with the textual prompt. Experimental results on three basic physical motion scenarios, including rigid object drop and collision, cloth draping and swinging, and liquid flow, demonstrate that GPT4Motion can generate high-quality videos efficiently in maintaining motion coherency and entity consistency. GPT4Motion offers new insights in text-to-video research, enhancing its quality and broadening its horizon for future explorations.","sentences":["Recent advances in text-to-video generation have harnessed the power of diffusion models to create visually compelling content conditioned on text prompts.","However, they usually encounter high computational costs and often struggle to produce videos with coherent physical motions.","To tackle these issues, we propose GPT4Motion, a training-free framework that leverages the planning capability of large language models such as GPT, the physical simulation strength of Blender, and the excellent image generation ability of text-to-image diffusion models to enhance the quality of video synthesis.","Specifically, GPT4Motion employs GPT-4 to generate a Blender script based on a user textual prompt, which commands Blender's built-in physics engine to craft fundamental scene components that encapsulate coherent physical motions across frames.","Then these components are inputted into Stable Diffusion to generate a video aligned with the textual prompt.","Experimental results on three basic physical motion scenarios, including rigid object drop and collision, cloth draping and swinging, and liquid flow, demonstrate that GPT4Motion can generate high-quality videos efficiently in maintaining motion coherency and entity consistency.","GPT4Motion offers new insights in text-to-video research, enhancing its quality and broadening its horizon for future explorations."],"url":"http://arxiv.org/abs/2311.12631v1"}
{"created":"2023-11-21 14:24:21","title":"Hierarchical Joint Graph Learning and Multivariate Time Series Forecasting","abstract":"Multivariate time series is prevalent in many scientific and industrial domains. Modeling multivariate signals is challenging due to their long-range temporal dependencies and intricate interactions--both direct and indirect. To confront these complexities, we introduce a method of representing multivariate signals as nodes in a graph with edges indicating interdependency between them. Specifically, we leverage graph neural networks (GNN) and attention mechanisms to efficiently learn the underlying relationships within the time series data. Moreover, we suggest employing hierarchical signal decompositions running over the graphs to capture multiple spatial dependencies. The effectiveness of our proposed model is evaluated across various real-world benchmark datasets designed for long-term forecasting tasks. The results consistently showcase the superiority of our model, achieving an average 23\\% reduction in mean squared error (MSE) compared to existing models.","sentences":["Multivariate time series is prevalent in many scientific and industrial domains.","Modeling multivariate signals is challenging due to their long-range temporal dependencies and intricate interactions--both direct and indirect.","To confront these complexities, we introduce a method of representing multivariate signals as nodes in a graph with edges indicating interdependency between them.","Specifically, we leverage graph neural networks (GNN) and attention mechanisms to efficiently learn the underlying relationships within the time series data.","Moreover, we suggest employing hierarchical signal decompositions running over the graphs to capture multiple spatial dependencies.","The effectiveness of our proposed model is evaluated across various real-world benchmark datasets designed for long-term forecasting tasks.","The results consistently showcase the superiority of our model, achieving an average 23\\% reduction in mean squared error (MSE) compared to existing models."],"url":"http://arxiv.org/abs/2311.12630v1"}
{"created":"2023-11-21 14:22:48","title":"Empirical Validation of the Impedance-Based RIS Channel Model in an Indoor Scattering Environment","abstract":"Ensuring the precision of channel modeling plays a pivotal role in the development of wireless communication systems, and this requirement remains a persistent challenge within the realm of networks supported by Reconfigurable Intelligent Surfaces (RIS). Achieving a comprehensive and reliable understanding of channel behavior in RIS-aided networks is an ongoing and complex issue that demands further exploration. In this paper, we empirically validate a recently-proposed impedance-based RIS channel model that accounts for the mutual coupling at the antenna array and precisely models the presence of scattering objects within the environment as a discrete array of loaded dipoles. To this end, we exploit real-life channel measurements collected in an office environment to demonstrate the validity of such a model and its applicability in a practical scenario. Finally, we provide numerical results demonstrating that designing the RIS configuration based upon such model leads to superior performance as compared to reference schemes.","sentences":["Ensuring the precision of channel modeling plays a pivotal role in the development of wireless communication systems, and this requirement remains a persistent challenge within the realm of networks supported by Reconfigurable Intelligent Surfaces (RIS).","Achieving a comprehensive and reliable understanding of channel behavior in RIS-aided networks is an ongoing and complex issue that demands further exploration.","In this paper, we empirically validate a recently-proposed impedance-based RIS channel model that accounts for the mutual coupling at the antenna array and precisely models the presence of scattering objects within the environment as a discrete array of loaded dipoles.","To this end, we exploit real-life channel measurements collected in an office environment to demonstrate the validity of such a model and its applicability in a practical scenario.","Finally, we provide numerical results demonstrating that designing the RIS configuration based upon such model leads to superior performance as compared to reference schemes."],"url":"http://arxiv.org/abs/2311.12628v1"}
{"created":"2023-11-21 14:18:28","title":"Bridging Algorithmic Information Theory and Machine Learning: A New Approach to Kernel Learning","abstract":"Machine Learning (ML) and Algorithmic Information Theory (AIT) look at Complexity from different points of view. We explore the interface between AIT and Kernel Methods (that are prevalent in ML) by adopting an AIT perspective on the problem of learning kernels from data, in kernel ridge regression, through the method of Sparse Kernel Flows. In particular, by looking at the differences and commonalities between Minimal Description Length (MDL) and Regularization in Machine Learning (RML), we prove that the method of Sparse Kernel Flows is the natural approach to adopt to learn kernels from data. This paper shows that it is not necessary to use the statistical route to derive Sparse Kernel Flows and that one can directly work with code-lengths and complexities that are concepts that show up in AIT.","sentences":["Machine Learning (ML) and Algorithmic Information Theory (AIT) look at Complexity from different points of view.","We explore the interface between AIT and Kernel Methods (that are prevalent in ML) by adopting an AIT perspective on the problem of learning kernels from data, in kernel ridge regression, through the method of Sparse Kernel Flows.","In particular, by looking at the differences and commonalities between Minimal Description Length (MDL) and Regularization in Machine Learning (RML), we prove that the method of Sparse Kernel Flows is the natural approach to adopt to learn kernels from data.","This paper shows that it is not necessary to use the statistical route to derive Sparse Kernel Flows and that one can directly work with code-lengths and complexities that are concepts that show up in AIT."],"url":"http://arxiv.org/abs/2311.12624v1"}
{"created":"2023-11-21 14:16:57","title":"Bridging Generalization Gaps in High Content Imaging Through Online Self-Supervised Domain Adaptation","abstract":"High Content Imaging (HCI) plays a vital role in modern drug discovery and development pipelines, facilitating various stages from hit identification to candidate drug characterization. Applying machine learning models to these datasets can prove challenging as they typically consist of multiple batches, affected by experimental variation, especially if different imaging equipment have been used. Moreover, as new data arrive, it is preferable that they are analyzed in an online fashion. To overcome this, we propose CODA, an online self-supervised domain adaptation approach. CODA divides the classifier's role into a generic feature extractor and a task-specific model. We adapt the feature extractor's weights to the new domain using cross-batch self-supervision while keeping the task-specific model unchanged. Our results demonstrate that this strategy significantly reduces the generalization gap, achieving up to a 300% improvement when applied to data from different labs utilizing different microscopes. CODA can be applied to new, unlabeled out-of-domain data sources of different sizes, from a single plate to multiple experimental batches.","sentences":["High Content Imaging (HCI) plays a vital role in modern drug discovery and development pipelines, facilitating various stages from hit identification to candidate drug characterization.","Applying machine learning models to these datasets can prove challenging as they typically consist of multiple batches, affected by experimental variation, especially if different imaging equipment have been used.","Moreover, as new data arrive, it is preferable that they are analyzed in an online fashion.","To overcome this, we propose CODA, an online self-supervised domain adaptation approach.","CODA divides the classifier's role into a generic feature extractor and a task-specific model.","We adapt the feature extractor's weights to the new domain using cross-batch self-supervision while keeping the task-specific model unchanged.","Our results demonstrate that this strategy significantly reduces the generalization gap, achieving up to a 300% improvement when applied to data from different labs utilizing different microscopes.","CODA can be applied to new, unlabeled out-of-domain data sources of different sizes, from a single plate to multiple experimental batches."],"url":"http://arxiv.org/abs/2311.12623v1"}
{"created":"2023-11-21 14:12:17","title":"Crowd management, crime detection, work monitoring using aiml","abstract":"This research endeavors to harness the potential of existing Closed-Circuit Television (CCTV) networks for a comprehensive approach to crowd management, crime prevention, and workplace monitoring through the integration of Artificial Intelligence (AI) and Machine Learning (ML) technologies. The primary objective is to develop and implement advanced algorithms capable of real-time analysis of video feeds, enabling the identification and assessment of crowd dynamics, early detection of potential criminal activities, and continuous monitoring of workplace environments. By leveraging AI/ML, the project aims to optimize surveillance capabilities, thereby enhancing public safety measures and improving organizational productivity. This initiative underscores the transformative impact that intelligent video analytics can have on existing infrastructure, mitigating the need for extensive system overhauls while significantly advancing security and operational efficiency.","sentences":["This research endeavors to harness the potential of existing Closed-Circuit Television (CCTV) networks for a comprehensive approach to crowd management, crime prevention, and workplace monitoring through the integration of Artificial Intelligence (AI) and Machine Learning (ML) technologies.","The primary objective is to develop and implement advanced algorithms capable of real-time analysis of video feeds, enabling the identification and assessment of crowd dynamics, early detection of potential criminal activities, and continuous monitoring of workplace environments.","By leveraging AI/ML, the project aims to optimize surveillance capabilities, thereby enhancing public safety measures and improving organizational productivity.","This initiative underscores the transformative impact that intelligent video analytics can have on existing infrastructure, mitigating the need for extensive system overhauls while significantly advancing security and operational efficiency."],"url":"http://arxiv.org/abs/2311.12621v1"}
{"created":"2023-11-21 14:03:16","title":"Leveraging Unlabeled Data for 3D Medical Image Segmentation through Self-Supervised Contrastive Learning","abstract":"Current 3D semi-supervised segmentation methods face significant challenges such as limited consideration of contextual information and the inability to generate reliable pseudo-labels for effective unsupervised data use. To address these challenges, we introduce two distinct subnetworks designed to explore and exploit the discrepancies between them, ultimately correcting the erroneous prediction results. More specifically, we identify regions of inconsistent predictions and initiate a targeted verification training process. This procedure strategically fine-tunes and harmonizes the predictions of the subnetworks, leading to enhanced utilization of contextual information. Furthermore, to adaptively fine-tune the network's representational capacity and reduce prediction uncertainty, we employ a self-supervised contrastive learning paradigm. For this, we use the network's confidence to distinguish between reliable and unreliable predictions. The model is then trained to effectively minimize unreliable predictions. Our experimental results for organ segmentation, obtained from clinical MRI and CT scans, demonstrate the effectiveness of our approach when compared to state-of-the-art methods. The codebase is accessible on \\href{https://github.com/xmindflow/SSL-contrastive}{GitHub}.","sentences":["Current 3D semi-supervised segmentation methods face significant challenges such as limited consideration of contextual information and the inability to generate reliable pseudo-labels for effective unsupervised data use.","To address these challenges, we introduce two distinct subnetworks designed to explore and exploit the discrepancies between them, ultimately correcting the erroneous prediction results.","More specifically, we identify regions of inconsistent predictions and initiate a targeted verification training process.","This procedure strategically fine-tunes and harmonizes the predictions of the subnetworks, leading to enhanced utilization of contextual information.","Furthermore, to adaptively fine-tune the network's representational capacity and reduce prediction uncertainty, we employ a self-supervised contrastive learning paradigm.","For this, we use the network's confidence to distinguish between reliable and unreliable predictions.","The model is then trained to effectively minimize unreliable predictions.","Our experimental results for organ segmentation, obtained from clinical MRI and CT scans, demonstrate the effectiveness of our approach when compared to state-of-the-art methods.","The codebase is accessible on \\href{https://github.com/xmindflow/SSL-contrastive}{GitHub}."],"url":"http://arxiv.org/abs/2311.12617v1"}
{"created":"2023-11-21 13:52:31","title":"ChessVision -- A Dataset for Logically Coherent Multi-label Classification","abstract":"Starting with early successes in computer vision tasks, deep learning based techniques have since overtaken state of the art approaches in a multitude of domains. However, it has been demonstrated time and again that these techniques fail to capture semantic context and logical constraints, instead often relying on spurious correlations to arrive at the answer. Since application of deep learning techniques to critical scenarios are dependent on adherence to domain specific constraints, several attempts have been made to address this issue. One limitation holding back a thorough exploration of this area, is a lack of suitable datasets which feature a rich set of rules. In order to address this, we present the ChessVision Dataset, consisting of 200,000+ images of annotated chess games in progress, requiring recreation of the game state from its corresponding image. This is accompanied by a curated set of rules which constrains the set of predictions to \"reasonable\" game states, and are designed to probe key semantic abilities like localization and enumeration. Alongside standard metrics, additional metrics to measure performance with regards to logical consistency is presented. We analyze several popular and state of the art vision models on this task, and show that, although their performance on standard metrics are laudable, they produce a plethora of incoherent results, indicating that this dataset presents a significant challenge for future works.","sentences":["Starting with early successes in computer vision tasks, deep learning based techniques have since overtaken state of the art approaches in a multitude of domains.","However, it has been demonstrated time and again that these techniques fail to capture semantic context and logical constraints, instead often relying on spurious correlations to arrive at the answer.","Since application of deep learning techniques to critical scenarios are dependent on adherence to domain specific constraints, several attempts have been made to address this issue.","One limitation holding back a thorough exploration of this area, is a lack of suitable datasets which feature a rich set of rules.","In order to address this, we present the ChessVision Dataset, consisting of 200,000+ images of annotated chess games in progress, requiring recreation of the game state from its corresponding image.","This is accompanied by a curated set of rules which constrains the set of predictions to \"reasonable\" game states, and are designed to probe key semantic abilities like localization and enumeration.","Alongside standard metrics, additional metrics to measure performance with regards to logical consistency is presented.","We analyze several popular and state of the art vision models on this task, and show that, although their performance on standard metrics are laudable, they produce a plethora of incoherent results, indicating that this dataset presents a significant challenge for future works."],"url":"http://arxiv.org/abs/2311.12610v1"}
{"created":"2023-11-21 13:52:20","title":"Reinforcement Learning for the Near-Optimal Design of Zero-Delay Codes for Markov Sources","abstract":"In the classical lossy source coding problem, one encodes long blocks of source symbols that enables the distortion to approach the ultimate Shannon limit. Such a block-coding approach introduces large delays, which is undesirable in many delay-sensitive applications. We consider the zero-delay case, where the goal is to encode and decode a finite-alphabet Markov source without any delay. It has been shown that this problem lends itself to stochastic control techniques, which lead to existence, structural, and general structural approximation results. However, these techniques so far have resulted only in computationally prohibitive algorithmic implementations for code design. To address this problem, we present a reinforcement learning design algorithm and rigorously prove its asymptotic optimality. In particular, we show that a quantized Q-learning algorithm can be used to obtain a near-optimal coding policy for this problem. The proof builds on recent results on quantized Q-learning for weakly Feller controlled Markov chains whose application necessitates the development of supporting technical results on regularity and stability properties, and relating the optimal solutions for discounted and average cost infinite horizon criteria problems. These theoretical results are supported by simulations.","sentences":["In the classical lossy source coding problem, one encodes long blocks of source symbols that enables the distortion to approach the ultimate Shannon limit.","Such a block-coding approach introduces large delays, which is undesirable in many delay-sensitive applications.","We consider the zero-delay case, where the goal is to encode and decode a finite-alphabet Markov source without any delay.","It has been shown that this problem lends itself to stochastic control techniques, which lead to existence, structural, and general structural approximation results.","However, these techniques so far have resulted only in computationally prohibitive algorithmic implementations for code design.","To address this problem, we present a reinforcement learning design algorithm and rigorously prove its asymptotic optimality.","In particular, we show that a quantized Q-learning algorithm can be used to obtain a near-optimal coding policy for this problem.","The proof builds on recent results on quantized Q-learning for weakly Feller controlled Markov chains whose application necessitates the development of supporting technical results on regularity and stability properties, and relating the optimal solutions for discounted and average cost infinite horizon criteria problems.","These theoretical results are supported by simulations."],"url":"http://arxiv.org/abs/2311.12609v1"}
{"created":"2023-11-21 13:49:28","title":"Adaptive Dense Pseudo Label Selection for Semi-supervised Oriented Object Detection","abstract":"Recently, dense pseudo-label, which directly selects pseudo labels from the original output of the teacher model without any complicated post-processing steps, has received considerable attention in semi-supervised object detection (SSOD). However, for the multi-oriented and dense objects that are common in aerial scenes, existing dense pseudo-label selection methods are inefficient and impede the performance in semi-supervised oriented object detection. Therefore, we propose Adaptive Dense Pseudo Label Selection (ADPLS) for semi-supervised oriented object detection. In ADPLS, we design a simple but effective adaptive mechanism to guide the selection of dense pseudo labels. Specifically, we propose the mean Feature-Richness Score (mFRS) to estimate the density of potential objects and use this score to adjust the number of dense pseudo labels. On the DOTA-v1.5 benchmark, the proposed method outperforms previous methods especially when labeled data are scarce. For example, it achieves 49.78 mAP given only 5% of annotated data, which surpasses previous state-of-the-art method given 10% of annotated data by 1.15 mAP. Our codes will be available soon.","sentences":["Recently, dense pseudo-label, which directly selects pseudo labels from the original output of the teacher model without any complicated post-processing steps, has received considerable attention in semi-supervised object detection (SSOD).","However, for the multi-oriented and dense objects that are common in aerial scenes, existing dense pseudo-label selection methods are inefficient and impede the performance in semi-supervised oriented object detection.","Therefore, we propose Adaptive Dense Pseudo Label Selection (ADPLS) for semi-supervised oriented object detection.","In ADPLS, we design a simple but effective adaptive mechanism to guide the selection of dense pseudo labels.","Specifically, we propose the mean Feature-Richness Score (mFRS) to estimate the density of potential objects and use this score to adjust the number of dense pseudo labels.","On the DOTA-v1.5 benchmark, the proposed method outperforms previous methods especially when labeled data are scarce.","For example, it achieves 49.78 mAP given only 5% of annotated data, which surpasses previous state-of-the-art method given 10% of annotated data by 1.15 mAP.","Our codes will be available soon."],"url":"http://arxiv.org/abs/2311.12608v1"}
{"created":"2023-11-21 13:43:58","title":"Trustworthy AI: Deciding What to Decide","abstract":"When engaging in strategic decision-making, we are frequently confronted with overwhelming information and data. The situation can be further complicated when certain pieces of evidence contradict each other or become paradoxical. The primary challenge is how to determine which information can be trusted when we adopt Artificial Intelligence (AI) systems for decision-making. This issue is known as deciding what to decide or Trustworthy AI. However, the AI system itself is often considered an opaque black box. We propose a new approach to address this issue by introducing a novel framework of Trustworthy AI (TAI) encompassing three crucial components of AI: representation space, loss function, and optimizer. Each component is loosely coupled with four TAI properties. Altogether, the framework consists of twelve TAI properties. We aim to use this framework to conduct the TAI experiments by quantitive and qualitative research methods to satisfy TAI properties for the decision-making context. The framework allows us to formulate an optimal prediction model trained by the given dataset for applying the strategic investment decision of credit default swaps (CDS) in the technology sector. Finally, we provide our view of the future direction of TAI research","sentences":["When engaging in strategic decision-making, we are frequently confronted with overwhelming information and data.","The situation can be further complicated when certain pieces of evidence contradict each other or become paradoxical.","The primary challenge is how to determine which information can be trusted when we adopt Artificial Intelligence (AI) systems for decision-making.","This issue is known as deciding what to decide or Trustworthy AI.","However, the AI system itself is often considered an opaque black box.","We propose a new approach to address this issue by introducing a novel framework of Trustworthy AI (TAI) encompassing three crucial components of AI: representation space, loss function, and optimizer.","Each component is loosely coupled with four TAI properties.","Altogether, the framework consists of twelve TAI properties.","We aim to use this framework to conduct the TAI experiments by quantitive and qualitative research methods to satisfy TAI properties for the decision-making context.","The framework allows us to formulate an optimal prediction model trained by the given dataset for applying the strategic investment decision of credit default swaps (CDS) in the technology sector.","Finally, we provide our view of the future direction of TAI research"],"url":"http://arxiv.org/abs/2311.12604v1"}
{"created":"2023-11-21 13:43:16","title":"Surgical Temporal Action-aware Network with Sequence Regularization for Phase Recognition","abstract":"To assist surgeons in the operating theatre, surgical phase recognition is critical for developing computer-assisted surgical systems, which requires comprehensive understanding of surgical videos. Although existing studies made great progress, there are still two significant limitations worthy of improvement. First, due to the compromise of resource consumption, frame-wise visual features are extracted by 2D networks and disregard spatial and temporal knowledge of surgical actions, which hinders subsequent inter-frame modeling for phase prediction. Second, these works simply utilize ordinary classification loss with one-hot phase labels to optimize the phase predictions, and cannot fully explore surgical videos under inadequate supervision. To overcome these two limitations, we propose a Surgical Temporal Action-aware Network with sequence Regularization, named STAR-Net, to recognize surgical phases more accurately from input videos. Specifically, we propose an efficient multi-scale surgical temporal action (MS-STA) module, which integrates visual features with spatial and temporal knowledge of surgical actions at the cost of 2D networks. Moreover, we devise the dual-classifier sequence regularization (DSR) to facilitate the training of STAR-Net by the sequence guidance of an auxiliary classifier with a smaller capacity. Our STAR-Net with MS-STA and DSR can exploit visual features of surgical actions with effective regularization, thereby leading to the superior performance of surgical phase recognition. Extensive experiments on a large-scale gastrectomy surgery dataset and the public Cholec80 benchmark prove that our STAR-Net significantly outperforms state-of-the-arts of surgical phase recognition.","sentences":["To assist surgeons in the operating theatre, surgical phase recognition is critical for developing computer-assisted surgical systems, which requires comprehensive understanding of surgical videos.","Although existing studies made great progress, there are still two significant limitations worthy of improvement.","First, due to the compromise of resource consumption, frame-wise visual features are extracted by 2D networks and disregard spatial and temporal knowledge of surgical actions, which hinders subsequent inter-frame modeling for phase prediction.","Second, these works simply utilize ordinary classification loss with one-hot phase labels to optimize the phase predictions, and cannot fully explore surgical videos under inadequate supervision.","To overcome these two limitations, we propose a Surgical Temporal Action-aware Network with sequence Regularization, named STAR-Net, to recognize surgical phases more accurately from input videos.","Specifically, we propose an efficient multi-scale surgical temporal action (MS-STA) module, which integrates visual features with spatial and temporal knowledge of surgical actions at the cost of 2D networks.","Moreover, we devise the dual-classifier sequence regularization (DSR) to facilitate the training of STAR-Net by the sequence guidance of an auxiliary classifier with a smaller capacity.","Our STAR-Net with MS-STA and DSR can exploit visual features of surgical actions with effective regularization, thereby leading to the superior performance of surgical phase recognition.","Extensive experiments on a large-scale gastrectomy surgery dataset and the public Cholec80 benchmark prove that our STAR-Net significantly outperforms state-of-the-arts of surgical phase recognition."],"url":"http://arxiv.org/abs/2311.12603v1"}
{"created":"2023-11-21 13:43:06","title":"TouchSDF: A DeepSDF Approach for 3D Shape Reconstruction using Vision-Based Tactile Sensing","abstract":"Humans rely on their visual and tactile senses to develop a comprehensive 3D understanding of their physical environment. Recently, there has been a growing interest in exploring and manipulating objects using data-driven approaches that utilise high-resolution vision-based tactile sensors. However, 3D shape reconstruction using tactile sensing has lagged behind visual shape reconstruction because of limitations in existing techniques, including the inability to generalise over unseen shapes, the absence of real-world testing, and limited expressive capacity imposed by discrete representations. To address these challenges, we propose TouchSDF, a Deep Learning approach for tactile 3D shape reconstruction that leverages the rich information provided by a vision-based tactile sensor and the expressivity of the implicit neural representation DeepSDF. Our technique consists of two components: (1) a Convolutional Neural Network that maps tactile images into local meshes representing the surface at the touch location, and (2) an implicit neural function that predicts a signed distance function to extract the desired 3D shape. This combination allows TouchSDF to reconstruct smooth and continuous 3D shapes from tactile inputs in simulation and real-world settings, opening up research avenues for robust 3D-aware representations and improved multimodal perception in robotics. Code and supplementary material are available at: https://touchsdf.github.io/","sentences":["Humans rely on their visual and tactile senses to develop a comprehensive 3D understanding of their physical environment.","Recently, there has been a growing interest in exploring and manipulating objects using data-driven approaches that utilise high-resolution vision-based tactile sensors.","However, 3D shape reconstruction using tactile sensing has lagged behind visual shape reconstruction because of limitations in existing techniques, including the inability to generalise over unseen shapes, the absence of real-world testing, and limited expressive capacity imposed by discrete representations.","To address these challenges, we propose TouchSDF, a Deep Learning approach for tactile 3D shape reconstruction that leverages the rich information provided by a vision-based tactile sensor and the expressivity of the implicit neural representation DeepSDF.","Our technique consists of two components: (1) a Convolutional Neural Network that maps tactile images into local meshes representing the surface at the touch location, and (2) an implicit neural function that predicts a signed distance function to extract the desired 3D shape.","This combination allows TouchSDF to reconstruct smooth and continuous 3D shapes from tactile inputs in simulation and real-world settings, opening up research avenues for robust 3D-aware representations and improved multimodal perception in robotics.","Code and supplementary material are available at: https://touchsdf.github.io/"],"url":"http://arxiv.org/abs/2311.12602v1"}
{"created":"2023-11-21 13:42:40","title":"Deep learning-based detection of morphological features associated with hypoxia in H&E breast cancer whole slide images","abstract":"Hypoxia occurs when tumour cells outgrow their blood supply, leading to regions of low oxygen levels within the tumour. Calculating hypoxia levels can be an important step in understanding the biology of tumours, their clinical progression and response to treatment. This study demonstrates a novel application of deep learning to evaluate hypoxia in the context of breast cancer histomorphology. More precisely, we show that Weakly Supervised Deep Learning (WSDL) models can accurately detect hypoxia associated features in routine Hematoxylin and Eosin (H&E) whole slide images (WSI). We trained and evaluated a deep Multiple Instance Learning model on tiles from WSI H&E tissue from breast cancer primary sites (n=240) obtaining on average an AUC of 0.87 on a left-out test set. We also showed significant differences between features of hypoxic and normoxic tissue regions as distinguished by the WSDL models. Such DL hypoxia H&E WSI detection models could potentially be extended to other tumour types and easily integrated into the pathology workflow without requiring additional costly assays.","sentences":["Hypoxia occurs when tumour cells outgrow their blood supply, leading to regions of low oxygen levels within the tumour.","Calculating hypoxia levels can be an important step in understanding the biology of tumours, their clinical progression and response to treatment.","This study demonstrates a novel application of deep learning to evaluate hypoxia in the context of breast cancer histomorphology.","More precisely, we show that Weakly Supervised Deep Learning (WSDL) models can accurately detect hypoxia associated features in routine Hematoxylin and Eosin (H&E) whole slide images (WSI).","We trained and evaluated a deep Multiple Instance Learning model on tiles from WSI H&E tissue from breast cancer primary sites (n=240) obtaining on average an AUC of 0.87 on a left-out test set.","We also showed significant differences between features of hypoxic and normoxic tissue regions as distinguished by the WSDL models.","Such DL hypoxia H&E WSI detection models could potentially be extended to other tumour types and easily integrated into the pathology workflow without requiring additional costly assays."],"url":"http://arxiv.org/abs/2311.12601v1"}
