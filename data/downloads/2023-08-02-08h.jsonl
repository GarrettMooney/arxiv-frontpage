{"created":"2023-08-01 17:54:26","title":"Harnessing the Power of Sample Abundance: Theoretical Guarantees and Algorithms for Accelerated One-Bit Sensing","abstract":"One-bit quantization with time-varying sampling thresholds (also known as random dithering) has recently found significant utilization potential in statistical signal processing applications due to its relatively low power consumption and low implementation cost. In addition to such advantages, an attractive feature of one-bit analog-to-digital converters (ADCs) is their superior sampling rates as compared to their conventional multi-bit counterparts. This characteristic endows one-bit signal processing frameworks with what one may refer to as sample abundance. We show that sample abundance plays a pivotal role in many signal recovery and optimization problems that are formulated as (possibly non-convex) quadratic programs with linear feasibility constraints. Of particular interest to our work are low-rank matrix recovery and compressed sensing applications that take advantage of one-bit quantization. We demonstrate that the sample abundance paradigm allows for the transformation of such problems to merely linear feasibility problems by forming large-scale overdetermined linear systems -- thus removing the need for handling costly optimization constraints and objectives. To make the proposed computational cost savings achievable, we offer enhanced randomized Kaczmarz algorithms to solve these highly overdetermined feasibility problems and provide theoretical guarantees in terms of their convergence, sample size requirements, and overall performance. Several numerical results are presented to illustrate the effectiveness of the proposed methodologies.","sentences":["One-bit quantization with time-varying sampling thresholds (also known as random dithering) has recently found significant utilization potential in statistical signal processing applications due to its relatively low power consumption and low implementation cost.","In addition to such advantages, an attractive feature of one-bit analog-to-digital converters (ADCs) is their superior sampling rates as compared to their conventional multi-bit counterparts.","This characteristic endows one-bit signal processing frameworks with what one may refer to as sample abundance.","We show that sample abundance plays a pivotal role in many signal recovery and optimization problems that are formulated as (possibly non-convex) quadratic programs with linear feasibility constraints.","Of particular interest to our work are low-rank matrix recovery and compressed sensing applications that take advantage of one-bit quantization.","We demonstrate that the sample abundance paradigm allows for the transformation of such problems to merely linear feasibility problems by forming large-scale overdetermined linear systems -- thus removing the need for handling costly optimization constraints and objectives.","To make the proposed computational cost savings achievable, we offer enhanced randomized Kaczmarz algorithms to solve these highly overdetermined feasibility problems and provide theoretical guarantees in terms of their convergence, sample size requirements, and overall performance.","Several numerical results are presented to illustrate the effectiveness of the proposed methodologies."],"url":"http://arxiv.org/abs/2308.00695v1"}
{"created":"2023-08-01 17:50:17","title":"LISA: Reasoning Segmentation via Large Language Model","abstract":"Although perception systems have made remarkable advancements in recent years, they still rely on explicit human instruction to identify the target objects or categories before executing visual recognition tasks. Such systems lack the ability to actively reason and comprehend implicit user intentions. In this work, we propose a new segmentation task -- reasoning segmentation. The task is designed to output a segmentation mask given a complex and implicit query text. Furthermore, we establish a benchmark comprising over one thousand image-instruction pairs, incorporating intricate reasoning and world knowledge for evaluation purposes. Finally, we present LISA: large Language Instructed Segmentation Assistant, which inherits the language generation capabilities of the multi-modal Large Language Model (LLM) while also possessing the ability to produce segmentation masks. We expand the original vocabulary with a <SEG> token and propose the embedding-as-mask paradigm to unlock the segmentation capability. Remarkably, LISA can handle cases involving: 1) complex reasoning; 2) world knowledge; 3) explanatory answers; 4) multi-turn conversation. Also, it demonstrates robust zero-shot capability when trained exclusively on reasoning-free datasets. In addition, fine-tuning the model with merely 239 reasoning segmentation image-instruction pairs results in further performance enhancement. Experiments show our method not only unlocks new reasoning segmentation capabilities but also proves effective in both complex reasoning segmentation and standard referring segmentation tasks. Code, models, and demo are at https://github.com/dvlab-research/LISA.","sentences":["Although perception systems have made remarkable advancements in recent years, they still rely on explicit human instruction to identify the target objects or categories before executing visual recognition tasks.","Such systems lack the ability to actively reason and comprehend implicit user intentions.","In this work, we propose a new segmentation task -- reasoning segmentation.","The task is designed to output a segmentation mask given a complex and implicit query text.","Furthermore, we establish a benchmark comprising over one thousand image-instruction pairs, incorporating intricate reasoning and world knowledge for evaluation purposes.","Finally, we present LISA: large Language Instructed Segmentation Assistant, which inherits the language generation capabilities of the multi-modal Large Language Model (LLM) while also possessing the ability to produce segmentation masks.","We expand the original vocabulary with a <SEG> token and propose the embedding-as-mask paradigm to unlock the segmentation capability.","Remarkably, LISA can handle cases involving: 1) complex reasoning; 2) world knowledge; 3) explanatory answers; 4) multi-turn conversation.","Also, it demonstrates robust zero-shot capability when trained exclusively on reasoning-free datasets.","In addition, fine-tuning the model with merely 239 reasoning segmentation image-instruction pairs results in further performance enhancement.","Experiments show our method not only unlocks new reasoning segmentation capabilities but also proves effective in both complex reasoning segmentation and standard referring segmentation tasks.","Code, models, and demo are at https://github.com/dvlab-research/LISA."],"url":"http://arxiv.org/abs/2308.00692v1"}
{"created":"2023-08-01 17:45:13","title":"AnyLoc: Towards Universal Visual Place Recognition","abstract":"Visual Place Recognition (VPR) is vital for robot localization. To date, the most performant VPR approaches are environment- and task-specific: while they exhibit strong performance in structured environments (predominantly urban driving), their performance degrades severely in unstructured environments, rendering most approaches brittle to robust real-world deployment. In this work, we develop a universal solution to VPR -- a technique that works across a broad range of structured and unstructured environments (urban, outdoors, indoors, aerial, underwater, and subterranean environments) without any re-training or fine-tuning. We demonstrate that general-purpose feature representations derived from off-the-shelf self-supervised models with no VPR-specific training are the right substrate upon which to build such a universal VPR solution. Combining these derived features with unsupervised feature aggregation enables our suite of methods, AnyLoc, to achieve up to 4X significantly higher performance than existing approaches. We further obtain a 6% improvement in performance by characterizing the semantic properties of these features, uncovering unique domains which encapsulate datasets from similar environments. Our detailed experiments and analysis lay a foundation for building VPR solutions that may be deployed anywhere, anytime, and across anyview. We encourage the readers to explore our project page and interactive demos: https://anyloc.github.io/.","sentences":["Visual Place Recognition (VPR) is vital for robot localization.","To date, the most performant VPR approaches are environment- and task-specific: while they exhibit strong performance in structured environments (predominantly urban driving), their performance degrades severely in unstructured environments, rendering most approaches brittle to robust real-world deployment.","In this work, we develop a universal solution to VPR -- a technique that works across a broad range of structured and unstructured environments (urban, outdoors, indoors, aerial, underwater, and subterranean environments) without any re-training or fine-tuning.","We demonstrate that general-purpose feature representations derived from off-the-shelf self-supervised models with no VPR-specific training are the right substrate upon which to build such a universal VPR solution.","Combining these derived features with unsupervised feature aggregation enables our suite of methods, AnyLoc, to achieve up to 4X significantly higher performance than existing approaches.","We further obtain a 6% improvement in performance by characterizing the semantic properties of these features, uncovering unique domains which encapsulate datasets from similar environments.","Our detailed experiments and analysis lay a foundation for building VPR solutions that may be deployed anywhere, anytime, and across anyview.","We encourage the readers to explore our project page and interactive demos: https://anyloc.github.io/."],"url":"http://arxiv.org/abs/2308.00688v1"}
{"created":"2023-08-01 17:42:35","title":"Learning from Hypervectors: A Survey on Hypervector Encoding","abstract":"Hyperdimensional computing (HDC) is an emerging computing paradigm that imitates the brain's structure to offer a powerful and efficient processing and learning model. In HDC, the data are encoded with long vectors, called hypervectors, typically with a length of 1K to 10K. The literature provides several encoding techniques to generate orthogonal or correlated hypervectors, depending on the intended application. The existing surveys in the literature often focus on the overall aspects of HDC systems, including system inputs, primary computations, and final outputs. However, this study takes a more specific approach. It zeroes in on the HDC system input and the generation of hypervectors, directly influencing the hypervector encoding process. This survey brings together various methods for hypervector generation from different studies and explores the limitations, challenges, and potential benefits they entail. Through a comprehensive exploration of this survey, readers will acquire a profound understanding of various encoding types in HDC and gain insights into the intricate process of hypervector generation for diverse applications.","sentences":["Hyperdimensional computing (HDC) is an emerging computing paradigm that imitates the brain's structure to offer a powerful and efficient processing and learning model.","In HDC, the data are encoded with long vectors, called hypervectors, typically with a length of 1K to 10K.","The literature provides several encoding techniques to generate orthogonal or correlated hypervectors, depending on the intended application.","The existing surveys in the literature often focus on the overall aspects of HDC systems, including system inputs, primary computations, and final outputs.","However, this study takes a more specific approach.","It zeroes in on the HDC system input and the generation of hypervectors, directly influencing the hypervector encoding process.","This survey brings together various methods for hypervector generation from different studies and explores the limitations, challenges, and potential benefits they entail.","Through a comprehensive exploration of this survey, readers will acquire a profound understanding of various encoding types in HDC and gain insights into the intricate process of hypervector generation for diverse applications."],"url":"http://arxiv.org/abs/2308.00685v1"}
{"created":"2023-08-01 17:40:48","title":"CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code","abstract":"Recent works have widely adopted large language model pretraining for source code, suggested source code-specific pretraining objectives and investigated the applicability of various Transformer-based language model architectures for source code. This work investigates another important aspect of such models, namely the effect of different subtokenization options, and aims at identifying most effective and length-efficient subtokenizations, taking into account code specifics. We propose subtokenziation that reduces average length by 17% without downstream performance drop, and show that a carefully chosen subtokenization may improve quality by 0.5-2%, possibly with some length increase.","sentences":["Recent works have widely adopted large language model pretraining for source code, suggested source code-specific pretraining objectives and investigated the applicability of various Transformer-based language model architectures for source code.","This work investigates another important aspect of such models, namely the effect of different subtokenization options, and aims at identifying most effective and length-efficient subtokenizations, taking into account code specifics.","We propose subtokenziation that reduces average length by 17% without downstream performance drop, and show that a carefully chosen subtokenization may improve quality by 0.5-2%, possibly with some length increase."],"url":"http://arxiv.org/abs/2308.00683v1"}
{"created":"2023-08-01 17:37:24","title":"TimePool: Visually Answer \"Which and When\" Questions On Univariate Time Series","abstract":"When exploring time series datasets, analysts often pose \"which and when\" questions. For example, with world life expectancy data over one hundred years, they may inquire about the top 10 countries in life expectancy and the time period when they achieved this status, or which countries have had longer life expectancy than Ireland and when. This paper proposes TimePool, a new visualization prototype, to address this need for univariate time series analysis. It allows users to construct interactive \"which and when\" queries and visually explore the results for insights.","sentences":["When exploring time series datasets, analysts often pose \"which and when\" questions.","For example, with world life expectancy data over one hundred years, they may inquire about the top 10 countries in life expectancy and the time period when they achieved this status, or which countries have had longer life expectancy than Ireland and when.","This paper proposes TimePool, a new visualization prototype, to address this need for univariate time series analysis.","It allows users to construct interactive \"which and when\" queries and visually explore the results for insights."],"url":"http://arxiv.org/abs/2308.00682v1"}
{"created":"2023-08-01 17:21:38","title":"Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models","abstract":"Today, large language models (LLMs) are taught to use new tools by providing a few demonstrations of the tool's usage. Unfortunately, demonstrations are hard to acquire, and can result in undesirable biased usage if the wrong demonstration is chosen. Even in the rare scenario that demonstrations are readily available, there is no principled selection protocol to determine how many and which ones to provide. As tasks grow more complex, the selection search grows combinatorially and invariably becomes intractable. Our work provides an alternative to demonstrations: tool documentation. We advocate the use of tool documentation, descriptions for the individual tool usage, over demonstrations. We substantiate our claim through three main empirical findings on 6 tasks across both vision and language modalities. First, on existing benchmarks, zero-shot prompts with only tool documentation are sufficient for eliciting proper tool usage, achieving performance on par with few-shot prompts. Second, on a newly collected realistic tool-use dataset with hundreds of available tool APIs, we show that tool documentation is significantly more valuable than demonstrations, with zero-shot documentation significantly outperforming few-shot without documentation. Third, we highlight the benefits of tool documentations by tackling image generation and video tracking using just-released unseen state-of-the-art models as tools. Finally, we highlight the possibility of using tool documentation to automatically enable new applications: by using nothing more than the documentation of GroundingDino, Stable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the just-released Grounded-SAM and Track Anything models.","sentences":["Today, large language models (LLMs) are taught to use new tools by providing a few demonstrations of the tool's usage.","Unfortunately, demonstrations are hard to acquire, and can result in undesirable biased usage if the wrong demonstration is chosen.","Even in the rare scenario that demonstrations are readily available, there is no principled selection protocol to determine how many and which ones to provide.","As tasks grow more complex, the selection search grows combinatorially and invariably becomes intractable.","Our work provides an alternative to demonstrations: tool documentation.","We advocate the use of tool documentation, descriptions for the individual tool usage, over demonstrations.","We substantiate our claim through three main empirical findings on 6 tasks across both vision and language modalities.","First, on existing benchmarks, zero-shot prompts with only tool documentation are sufficient for eliciting proper tool usage, achieving performance on par with few-shot prompts.","Second, on a newly collected realistic tool-use dataset with hundreds of available tool APIs, we show that tool documentation is significantly more valuable than demonstrations, with zero-shot documentation significantly outperforming few-shot without documentation.","Third, we highlight the benefits of tool documentations by tackling image generation and video tracking using just-released unseen state-of-the-art models as tools.","Finally, we highlight the possibility of using tool documentation to automatically enable new applications: by using nothing more than the documentation of GroundingDino, Stable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the just-released Grounded-SAM and Track Anything models."],"url":"http://arxiv.org/abs/2308.00675v1"}
{"created":"2023-08-01 17:02:45","title":"Program Repair by Fuzzing over Patch and Input Space","abstract":"Fuzz testing (fuzzing) is a well-known method for exposing bugs/vulnerabilities in software systems. Popular fuzzers, such as AFL, use a biased random search over the domain of program inputs, where 100s or 1000s of inputs (test cases) are executed per second in order to expose bugs. If a bug is discovered, it can either be fixed manually by the developer or fixed automatically using an Automated Program Repair (APR) tool. Like fuzzing, many existing APR tools are search-based, but over the domain of patches rather than inputs.   In this paper, we propose search-based program repair as patch-level fuzzing. The basic idea is to adapt a fuzzer (AFL) to fuzz over the patch space rather than the input space. Thus we use a patch-space fuzzer to explore a patch space, while using a traditional input level fuzzer to rule out patch candidates and help in patch selection. To improve the throughput, we propose a compilation-free patch validation methodology, where we execute the original (unpatched) program natively, then selectively interpret only the specific patched statements and expressions. Since this avoids (re)compilation, we show that compilation-free patch validation can achieve a similar throughput as input-level fuzzing (100s or 1000s of execs/sec). We show that patch-level fuzzing and input-level fuzzing can be combined, for a co-exploration of both spaces in order to find better quality patches. Such a collaboration between input-level fuzzing and patch-level fuzzing is then employed to search over candidate fix locations, as well as patch candidates in each fix location.","sentences":["Fuzz testing (fuzzing) is a well-known method for exposing bugs/vulnerabilities in software systems.","Popular fuzzers, such as AFL, use a biased random search over the domain of program inputs, where 100s or 1000s of inputs (test cases) are executed per second in order to expose bugs.","If a bug is discovered, it can either be fixed manually by the developer or fixed automatically using an Automated Program Repair (APR) tool.","Like fuzzing, many existing APR tools are search-based, but over the domain of patches rather than inputs.   ","In this paper, we propose search-based program repair as patch-level fuzzing.","The basic idea is to adapt a fuzzer (AFL) to fuzz over the patch space rather than the input space.","Thus we use a patch-space fuzzer to explore a patch space, while using a traditional input level fuzzer to rule out patch candidates and help in patch selection.","To improve the throughput, we propose a compilation-free patch validation methodology, where we execute the original (unpatched) program natively, then selectively interpret only the specific patched statements and expressions.","Since this avoids (re)compilation, we show that compilation-free patch validation can achieve a similar throughput as input-level fuzzing (100s or 1000s of execs/sec).","We show that patch-level fuzzing and input-level fuzzing can be combined, for a co-exploration of both spaces in order to find better quality patches.","Such a collaboration between input-level fuzzing and patch-level fuzzing is then employed to search over candidate fix locations, as well as patch candidates in each fix location."],"url":"http://arxiv.org/abs/2308.00666v1"}
{"created":"2023-08-01 17:00:33","title":"HyDe: A Hybrid PCM/FeFET/SRAM Device-search for Optimizing Area and Energy-efficiencies in Analog IMC Platforms","abstract":"Today, there are a plethora of In-Memory Computing (IMC) devices- SRAMs, PCMs & FeFETs, that emulate convolutions on crossbar-arrays with high throughput. Each IMC device offers its own pros & cons during inference of Deep Neural Networks (DNNs) on crossbars in terms of area overhead, programming energy and non-idealities. A design-space exploration is, therefore, imperative to derive a hybrid-device architecture optimized for accurate DNN inference under the impact of non-idealities from multiple devices, while maintaining competitive area & energy-efficiencies. We propose a two-phase search framework (HyDe) that exploits the best of all worlds offered by multiple devices to determine an optimal hybrid-device architecture for a given DNN topology. Our hybrid models achieve upto 2.30-2.74x higher TOPS/mm^2 at 22-26% higher energy-efficiencies than baseline homogeneous models for a VGG16 DNN topology. We further propose a feasible implementation of the HyDe-derived hybrid-device architectures in the 2.5D design space using chiplets to reduce design effort and cost in the hardware fabrication involving multiple technology processes.","sentences":["Today, there are a plethora of In-Memory Computing (IMC) devices-","SRAMs, PCMs & FeFETs, that emulate convolutions on crossbar-arrays with high throughput.","Each IMC device offers its own pros & cons during inference of Deep Neural Networks (DNNs) on crossbars in terms of area overhead, programming energy and non-idealities.","A design-space exploration is, therefore, imperative to derive a hybrid-device architecture optimized for accurate DNN inference under the impact of non-idealities from multiple devices, while maintaining competitive area & energy-efficiencies.","We propose a two-phase search framework (HyDe) that exploits the best of all worlds offered by multiple devices to determine an optimal hybrid-device architecture for a given DNN topology.","Our hybrid models achieve upto 2.30-2.74x higher TOPS/mm^2 at 22-26% higher energy-efficiencies than baseline homogeneous models for a VGG16 DNN topology.","We further propose a feasible implementation of the HyDe-derived hybrid-device architectures in the 2.5D design space using chiplets to reduce design effort and cost in the hardware fabrication involving multiple technology processes."],"url":"http://arxiv.org/abs/2308.00664v1"}
{"created":"2023-08-01 16:48:50","title":"Considerations on the EMF Exposure Relating to the Next Generation Non-Terrestrial Networks","abstract":"The emerging fifth generation (5G) and the upcoming sixth generation (6G) communication technologies introduce the use of space- and airborne networks in their architectures under the scope of non-terrestrial networks (NTNs). With this integration of satellite and aerial platform networks, better coverage, network flexibility and easier deployment can be achieved. Correspondingly, satellite broadband internet providers have launched an increasing number of small satellites operating in low earth orbit (LEO). These recent developments imply an increased electromagnetic field (EMF) exposure to humans and the environment. In this work, we provide a short overview of the state of consumer-grade satellite networks including broadband satellites and future NTN services. We also consider the regulatory state governing their operation within the context of EMF exposure. Finally, we highlight the aspects that are relevant to the assessment of EMF exposure in relation to NTNs.","sentences":["The emerging fifth generation (5G) and the upcoming sixth generation (6G) communication technologies introduce the use of space- and airborne networks in their architectures under the scope of non-terrestrial networks (NTNs).","With this integration of satellite and aerial platform networks, better coverage, network flexibility and easier deployment can be achieved.","Correspondingly, satellite broadband internet providers have launched an increasing number of small satellites operating in low earth orbit (LEO).","These recent developments imply an increased electromagnetic field (EMF) exposure to humans and the environment.","In this work, we provide a short overview of the state of consumer-grade satellite networks including broadband satellites and future NTN services.","We also consider the regulatory state governing their operation within the context of EMF exposure.","Finally, we highlight the aspects that are relevant to the assessment of EMF exposure in relation to NTNs."],"url":"http://arxiv.org/abs/2308.00658v1"}
{"created":"2023-08-01 16:41:30","title":"Toward Zero-shot Character Recognition: A Gold Standard Dataset with Radical-level Annotations","abstract":"Optical character recognition (OCR) methods have been applied to diverse tasks, e.g., street view text recognition and document analysis. Recently, zero-shot OCR has piqued the interest of the research community because it considers a practical OCR scenario with unbalanced data distribution. However, there is a lack of benchmarks for evaluating such zero-shot methods that apply a divide-and-conquer recognition strategy by decomposing characters into radicals. Meanwhile, radical recognition, as another important OCR task, also lacks radical-level annotation for model training. In this paper, we construct an ancient Chinese character image dataset that contains both radical-level and character-level annotations to satisfy the requirements of the above-mentioned methods, namely, ACCID, where radical-level annotations include radical categories, radical locations, and structural relations. To increase the adaptability of ACCID, we propose a splicing-based synthetic character algorithm to augment the training samples and apply an image denoising method to improve the image quality. By introducing character decomposition and recombination, we propose a baseline method for zero-shot OCR. The experimental results demonstrate the validity of ACCID and the baseline model quantitatively and qualitatively.","sentences":["Optical character recognition (OCR) methods have been applied to diverse tasks, e.g., street view text recognition and document analysis.","Recently, zero-shot OCR has piqued the interest of the research community because it considers a practical OCR scenario with unbalanced data distribution.","However, there is a lack of benchmarks for evaluating such zero-shot methods that apply a divide-and-conquer recognition strategy by decomposing characters into radicals.","Meanwhile, radical recognition, as another important OCR task, also lacks radical-level annotation for model training.","In this paper, we construct an ancient Chinese character image dataset that contains both radical-level and character-level annotations to satisfy the requirements of the above-mentioned methods, namely, ACCID, where radical-level annotations include radical categories, radical locations, and structural relations.","To increase the adaptability of ACCID, we propose a splicing-based synthetic character algorithm to augment the training samples and apply an image denoising method to improve the image quality.","By introducing character decomposition and recombination, we propose a baseline method for zero-shot OCR.","The experimental results demonstrate the validity of ACCID and the baseline model quantitatively and qualitatively."],"url":"http://arxiv.org/abs/2308.00655v1"}
{"created":"2023-08-01 16:23:06","title":"Comparability of Automated Vehicle Crash Databases","abstract":"Advanced driving assistance systems are available on many late-model vehicles, and automated driving systems are testing on public roads. Regulators and developers continue to assess the safety of these vehicles by comparing automated vehicle crash rates to baseline, human-driven crash rates. While there are several widely-cited automated vehicle and conventional vehicle crash databases, these databases have different underlying assumptions and inclusion criteria. Crash rates among databases may be directly comparable only with significant filtering and normalization, if at all. This paper reviews current automated vehicle and baseline human-driven crash databases and evaluates their comparability. Recommendations are presented to improve their comparability, both in terms of normalization and contextualization, as well as additional data fields that can be incorporated into existing databases. These findings may assist researchers, regulators, and automated vehicle developers attempting to evaluate the safety of driving automation systems.","sentences":["Advanced driving assistance systems are available on many late-model vehicles, and automated driving systems are testing on public roads.","Regulators and developers continue to assess the safety of these vehicles by comparing automated vehicle crash rates to baseline, human-driven crash rates.","While there are several widely-cited automated vehicle and conventional vehicle crash databases, these databases have different underlying assumptions and inclusion criteria.","Crash rates among databases may be directly comparable only with significant filtering and normalization, if at all.","This paper reviews current automated vehicle and baseline human-driven crash databases and evaluates their comparability.","Recommendations are presented to improve their comparability, both in terms of normalization and contextualization, as well as additional data fields that can be incorporated into existing databases.","These findings may assist researchers, regulators, and automated vehicle developers attempting to evaluate the safety of driving automation systems."],"url":"http://arxiv.org/abs/2308.00645v1"}
{"created":"2023-08-01 16:15:45","title":"Reversible complement cyclic codes over finite chain rings","abstract":"Let k be an arbitrary element of a finite commutative chain ring R and u be a unit in R. In this work, we present necessary conditions which are sufficient as well for a cyclic code to be a (u,k) reversible complement code over R. Using these conditions, all principally generated cyclic codes over the ring Z_{2}+vZ_{2}+v^{2}Z_{2}, v^{3}=0 of length 4 have been checked to find whether they are (1,1) reversible complement or not.","sentences":["Let k be an arbitrary element of a finite commutative chain ring R and u be a unit in R. In this work, we present necessary conditions which are sufficient as well for a cyclic code to be a (u,k) reversible complement code over R. Using these conditions, all principally generated cyclic codes over the ring Z_{2}+vZ_{2}+v^{2}Z_{2}, v^{3}=0 of length 4 have been checked to find whether they are (1,1) reversible complement or not."],"url":"http://arxiv.org/abs/2308.00642v1"}
{"created":"2023-08-01 16:13:35","title":"VL-Grasp: a 6-Dof Interactive Grasp Policy for Language-Oriented Objects in Cluttered Indoor Scenes","abstract":"Robotic grasping faces new challenges in human-robot-interaction scenarios. We consider the task that the robot grasps a target object designated by human's language directives. The robot not only needs to locate a target based on vision-and-language information, but also needs to predict the reasonable grasp pose candidate at various views and postures. In this work, we propose a novel interactive grasp policy, named Visual-Lingual-Grasp (VL-Grasp), to grasp the target specified by human language. First, we build a new challenging visual grounding dataset to provide functional training data for robotic interactive perception in indoor environments. Second, we propose a 6-Dof interactive grasp policy combined with visual grounding and 6-Dof grasp pose detection to extend the universality of interactive grasping. Third, we design a grasp pose filter module to enhance the performance of the policy. Experiments demonstrate the effectiveness and extendibility of the VL-Grasp in real world. The VL-Grasp achieves a success rate of 72.5\\% in different indoor scenes. The code and dataset is available at https://github.com/luyh20/VL-Grasp.","sentences":["Robotic grasping faces new challenges in human-robot-interaction scenarios.","We consider the task that the robot grasps a target object designated by human's language directives.","The robot not only needs to locate a target based on vision-and-language information, but also needs to predict the reasonable grasp pose candidate at various views and postures.","In this work, we propose a novel interactive grasp policy, named Visual-Lingual-Grasp (VL-Grasp), to grasp the target specified by human language.","First, we build a new challenging visual grounding dataset to provide functional training data for robotic interactive perception in indoor environments.","Second, we propose a 6-Dof interactive grasp policy combined with visual grounding and 6-Dof grasp pose detection to extend the universality of interactive grasping.","Third, we design a grasp pose filter module to enhance the performance of the policy.","Experiments demonstrate the effectiveness and extendibility of the VL-Grasp in real world.","The VL-Grasp achieves a success rate of 72.5\\% in different indoor scenes.","The code and dataset is available at https://github.com/luyh20/VL-Grasp."],"url":"http://arxiv.org/abs/2308.00640v1"}
{"created":"2023-08-01 15:56:24","title":"Hessian-Aware Bayesian Optimization for Decision Making Systems","abstract":"Many approaches for optimizing decision making systems rely on gradient based methods requiring informative feedback from the environment. However, in the case where such feedback is sparse or uninformative, such approaches may result in poor performance. Derivative-free approaches such as Bayesian Optimization mitigate the dependency on the quality of gradient feedback, but are known to scale poorly in the high-dimension setting of complex decision making systems. This problem is exacerbated if the system requires interactions between several actors cooperating to accomplish a shared goal. To address the dimensionality challenge, we propose a compact multi-layered architecture modeling the dynamics of actor interactions through the concept of role. Additionally, we introduce Hessian-aware Bayesian Optimization to efficiently optimize the multi-layered architecture parameterized by a large number of parameters. Experimental results demonstrate that our method (HA-GP-UCB) works effectively on several benchmarks under resource constraints and malformed feedback settings.","sentences":["Many approaches for optimizing decision making systems rely on gradient based methods requiring informative feedback from the environment.","However, in the case where such feedback is sparse or uninformative, such approaches may result in poor performance.","Derivative-free approaches such as Bayesian Optimization mitigate the dependency on the quality of gradient feedback, but are known to scale poorly in the high-dimension setting of complex decision making systems.","This problem is exacerbated if the system requires interactions between several actors cooperating to accomplish a shared goal.","To address the dimensionality challenge, we propose a compact multi-layered architecture modeling the dynamics of actor interactions through the concept of role.","Additionally, we introduce Hessian-aware Bayesian Optimization to efficiently optimize the multi-layered architecture parameterized by a large number of parameters.","Experimental results demonstrate that our method (HA-GP-UCB) works effectively on several benchmarks under resource constraints and malformed feedback settings."],"url":"http://arxiv.org/abs/2308.00629v1"}
{"created":"2023-08-01 15:55:41","title":"Human-M3: A Multi-view Multi-modal Dataset for 3D Human Pose Estimation in Outdoor Scenes","abstract":"3D human pose estimation in outdoor environments has garnered increasing attention recently. However, prevalent 3D human pose datasets pertaining to outdoor scenes lack diversity, as they predominantly utilize only one type of modality (RGB image or pointcloud), and often feature only one individual within each scene. This limited scope of dataset infrastructure considerably hinders the variability of available data. In this article, we propose Human-M3, an outdoor multi-modal multi-view multi-person human pose database which includes not only multi-view RGB videos of outdoor scenes but also corresponding pointclouds. In order to obtain accurate human poses, we propose an algorithm based on multi-modal data input to generate ground truth annotation. This benefits from robust pointcloud detection and tracking, which solves the problem of inaccurate human localization and matching ambiguity that may exist in previous multi-view RGB videos in outdoor multi-person scenes, and generates reliable ground truth annotations. Evaluation of multiple different modalities algorithms has shown that this database is challenging and suitable for future research. Furthermore, we propose a 3D human pose estimation algorithm based on multi-modal data input, which demonstrates the advantages of multi-modal data input for 3D human pose estimation. Code and data will be released on https://github.com/soullessrobot/Human-M3-Dataset.","sentences":["3D human pose estimation in outdoor environments has garnered increasing attention recently.","However, prevalent 3D human pose datasets pertaining to outdoor scenes lack diversity, as they predominantly utilize only one type of modality (RGB image or pointcloud), and often feature only one individual within each scene.","This limited scope of dataset infrastructure considerably hinders the variability of available data.","In this article, we propose Human-M3, an outdoor multi-modal multi-view multi-person human pose database which includes not only multi-view RGB videos of outdoor scenes but also corresponding pointclouds.","In order to obtain accurate human poses, we propose an algorithm based on multi-modal data input to generate ground truth annotation.","This benefits from robust pointcloud detection and tracking, which solves the problem of inaccurate human localization and matching ambiguity that may exist in previous multi-view RGB videos in outdoor multi-person scenes, and generates reliable ground truth annotations.","Evaluation of multiple different modalities algorithms has shown that this database is challenging and suitable for future research.","Furthermore, we propose a 3D human pose estimation algorithm based on multi-modal data input, which demonstrates the advantages of multi-modal data input for 3D human pose estimation.","Code and data will be released on https://github.com/soullessrobot/Human-M3-Dataset."],"url":"http://arxiv.org/abs/2308.00628v1"}
{"created":"2023-08-01 15:51:41","title":"JIANG: Chinese Open Foundation Language Model","abstract":"With the advancements in large language model technology, it has showcased capabilities that come close to those of human beings across various tasks. This achievement has garnered significant interest from companies and scientific research institutions, leading to substantial investments in the research and development of these models. While numerous large models have emerged during this period, the majority of them have been trained primarily on English data. Although they exhibit decent performance in other languages, such as Chinese, their potential remains limited due to factors like vocabulary design and training corpus. Consequently, their ability to fully express their capabilities in Chinese falls short. To address this issue, we introduce the model named JIANG (Chinese pinyin of ginger) specifically designed for the Chinese language. We have gathered a substantial amount of Chinese corpus to train the model and have also optimized its structure. The extensive experimental results demonstrate the excellent performance of our model.","sentences":["With the advancements in large language model technology, it has showcased capabilities that come close to those of human beings across various tasks.","This achievement has garnered significant interest from companies and scientific research institutions, leading to substantial investments in the research and development of these models.","While numerous large models have emerged during this period, the majority of them have been trained primarily on English data.","Although they exhibit decent performance in other languages, such as Chinese, their potential remains limited due to factors like vocabulary design and training corpus.","Consequently, their ability to fully express their capabilities in Chinese falls short.","To address this issue, we introduce the model named JIANG (Chinese pinyin of ginger) specifically designed for the Chinese language.","We have gathered a substantial amount of Chinese corpus to train the model and have also optimized its structure.","The extensive experimental results demonstrate the excellent performance of our model."],"url":"http://arxiv.org/abs/2308.00624v1"}
{"created":"2023-08-01 15:50:49","title":"Secure and Trustworthy Computing 2.0 Vision Statement","abstract":"The Secure and Trustworthy Computing (SaTC) program within the National Science Foundation (NSF) program serves as the primary instrument for creating novel fundamental science in security and privacy in the United States with broad impacts that influence the world. The program funds research in a vast array of research topics that span technology, theory, policy, law, and society. In the Spring of 2023, the program managers of SaTC requested that the community prepare a vision for the next ten years of research. This document represents the results of that effort which involved collecting input from numerous members of the security and privacy community, industry, academics, and government. Assembled from that input, this document offers a comprehensive view of general themes and specific areas of focus for future research as envisioned by the community.","sentences":["The Secure and Trustworthy Computing (SaTC) program within the National Science Foundation (NSF) program serves as the primary instrument for creating novel fundamental science in security and privacy in the United States with broad impacts that influence the world.","The program funds research in a vast array of research topics that span technology, theory, policy, law, and society.","In the Spring of 2023, the program managers of SaTC requested that the community prepare a vision for the next ten years of research.","This document represents the results of that effort which involved collecting input from numerous members of the security and privacy community, industry, academics, and government.","Assembled from that input, this document offers a comprehensive view of general themes and specific areas of focus for future research as envisioned by the community."],"url":"http://arxiv.org/abs/2308.00623v1"}
{"created":"2023-08-01 15:49:40","title":"NeRT: Implicit Neural Representations for General Unsupervised Turbulence Mitigation","abstract":"The atmospheric and water turbulence mitigation problems have emerged as challenging inverse problems in computer vision and optics communities over the years. However, current methods either rely heavily on the quality of the training dataset or fail to generalize over various scenarios, such as static scenes, dynamic scenes, and text reconstructions. We propose a general implicit neural representation for unsupervised atmospheric and water turbulence mitigation (NeRT). NeRT leverages the implicit neural representations and the physically correct tilt-then-blur turbulence model to reconstruct the clean, undistorted image, given only dozens of distorted input images. Moreover, we show that NeRT outperforms the state-of-the-art through various qualitative and quantitative evaluations of atmospheric and water turbulence datasets. Furthermore, we demonstrate the ability of NeRT to eliminate uncontrolled turbulence from real-world environments. Lastly, we incorporate NeRT into continuously captured video sequences and demonstrate $48 \\times$ speedup.","sentences":["The atmospheric and water turbulence mitigation problems have emerged as challenging inverse problems in computer vision and optics communities over the years.","However, current methods either rely heavily on the quality of the training dataset or fail to generalize over various scenarios, such as static scenes, dynamic scenes, and text reconstructions.","We propose a general implicit neural representation for unsupervised atmospheric and water turbulence mitigation (NeRT).","NeRT leverages the implicit neural representations and the physically correct tilt-then-blur turbulence model to reconstruct the clean, undistorted image, given only dozens of distorted input images.","Moreover, we show that NeRT outperforms the state-of-the-art through various qualitative and quantitative evaluations of atmospheric and water turbulence datasets.","Furthermore, we demonstrate the ability of NeRT to eliminate uncontrolled turbulence from real-world environments.","Lastly, we incorporate NeRT into continuously captured video sequences and demonstrate $48 \\times$ speedup."],"url":"http://arxiv.org/abs/2308.00622v1"}
{"created":"2023-08-01 15:35:06","title":"Explainable Cost-Sensitive Deep Neural Networks for Brain Tumor Detection from Brain MRI Images considering Data Imbalance","abstract":"This paper presents a research study on the use of Convolutional Neural Network (CNN), ResNet50, InceptionV3, EfficientNetB0 and NASNetMobile models to efficiently detect brain tumors in order to reduce the time required for manual review of the report and create an automated system for classifying brain tumors. An automated pipeline is proposed, which encompasses five models: CNN, ResNet50, InceptionV3, EfficientNetB0 and NASNetMobile. The performance of the proposed architecture is evaluated on a balanced dataset and found to yield an accuracy of 99.33% for fine-tuned InceptionV3 model. Furthermore, Explainable AI approaches are incorporated to visualize the model's latent behavior in order to understand its black box behavior. To further optimize the training process, a cost-sensitive neural network approach has been proposed in order to work with imbalanced datasets which has achieved almost 4% more accuracy than the conventional models used in our experiments. The cost-sensitive InceptionV3 (CS-InceptionV3) and CNN (CS-CNN) show a promising accuracy of 92.31% and a recall value of 1.00 respectively on an imbalanced dataset. The proposed models have shown great potential in improving tumor detection accuracy and must be further developed for application in practical solutions. We have provided the datasets and made our implementations publicly available at - https://github.com/shahariar-shibli/Explainable-Cost-Sensitive-Deep-Neural-Networks-for-Brain-Tumor-Detection-from-Brain-MRI-Images","sentences":["This paper presents a research study on the use of Convolutional Neural Network (CNN), ResNet50, InceptionV3, EfficientNetB0 and NASNetMobile models to efficiently detect brain tumors in order to reduce the time required for manual review of the report and create an automated system for classifying brain tumors.","An automated pipeline is proposed, which encompasses five models: CNN, ResNet50, InceptionV3, EfficientNetB0 and NASNetMobile.","The performance of the proposed architecture is evaluated on a balanced dataset and found to yield an accuracy of 99.33% for fine-tuned InceptionV3 model.","Furthermore, Explainable AI approaches are incorporated to visualize the model's latent behavior in order to understand its black box behavior.","To further optimize the training process, a cost-sensitive neural network approach has been proposed in order to work with imbalanced datasets which has achieved almost 4% more accuracy than the conventional models used in our experiments.","The cost-sensitive InceptionV3 (CS-InceptionV3) and CNN (CS-CNN) show a promising accuracy of 92.31% and a recall value of 1.00 respectively on an imbalanced dataset.","The proposed models have shown great potential in improving tumor detection accuracy and must be further developed for application in practical solutions.","We have provided the datasets and made our implementations publicly available at - https://github.com/shahariar-shibli/Explainable-Cost-Sensitive-Deep-Neural-Networks-for-Brain-Tumor-Detection-from-Brain-MRI-Images"],"url":"http://arxiv.org/abs/2308.00608v1"}
{"created":"2023-08-01 15:34:02","title":"Beyond One-Hot-Encoding: Injecting Semantics to Drive Image Classifiers","abstract":"Images are loaded with semantic information that pertains to real-world ontologies: dog breeds share mammalian similarities, food pictures are often depicted in domestic environments, and so on. However, when training machine learning models for image classification, the relative similarities amongst object classes are commonly paired with one-hot-encoded labels. According to this logic, if an image is labelled as 'spoon', then 'tea-spoon' and 'shark' are equally wrong in terms of training loss. To overcome this limitation, we explore the integration of additional goals that reflect ontological and semantic knowledge, improving model interpretability and trustworthiness. We suggest a generic approach that allows to derive an additional loss term starting from any kind of semantic information about the classification label. First, we show how to apply our approach to ontologies and word embeddings, and discuss how the resulting information can drive a supervised learning process. Second, we use our semantically enriched loss to train image classifiers, and analyse the trade-offs between accuracy, mistake severity, and learned internal representations. Finally, we discuss how this approach can be further exploited in terms of explainability and adversarial robustness. Code repository: https://github.com/S1M0N38/semantic-encodings","sentences":["Images are loaded with semantic information that pertains to real-world ontologies: dog breeds share mammalian similarities, food pictures are often depicted in domestic environments, and so on.","However, when training machine learning models for image classification, the relative similarities amongst object classes are commonly paired with one-hot-encoded labels.","According to this logic, if an image is labelled as 'spoon', then 'tea-spoon' and 'shark' are equally wrong in terms of training loss.","To overcome this limitation, we explore the integration of additional goals that reflect ontological and semantic knowledge, improving model interpretability and trustworthiness.","We suggest a generic approach that allows to derive an additional loss term starting from any kind of semantic information about the classification label.","First, we show how to apply our approach to ontologies and word embeddings, and discuss how the resulting information can drive a supervised learning process.","Second, we use our semantically enriched loss to train image classifiers, and analyse the trade-offs between accuracy, mistake severity, and learned internal representations.","Finally, we discuss how this approach can be further exploited in terms of explainability and adversarial robustness.","Code repository: https://github.com/S1M0N38/semantic-encodings"],"url":"http://arxiv.org/abs/2308.00607v1"}
{"created":"2023-08-01 15:23:02","title":"QualityBLE: A QoS Aware Implementation for BLE Mesh Networks","abstract":"Bluetooth Low Energy (BLE) Mesh is widely recognized as a driver technology for IoT applications. However, the lack of quality of service (QoS) in BLE Mesh, represented by packet prioritization, significantly limits its potential. This work implements a quality-of-service (QoS) method for BLE Mesh to prioritize the data packets and provide them with different network transmission settings according to their assigned priority. Unlike existing works on QoS for BLE Mesh, our proposed approach does not require any modifications to the BLE Mesh protocol and can be smoothly adopted in existing BLE Mesh networks. We conducted an extensive measurement campaign to evaluate our solution over a 15-node BLE Mesh network deployed to emulate a smart healthcare scenario where 45 sensors with an assigned priority transmit information over the network. The experiments provide performance results for single and multi channel network scenarios. The obtained results validate our solution, showing the difference between the established priorities and providing insights and guidelines to conduct further research on QoS over BLE Mesh and broadcast-based networks.","sentences":["Bluetooth Low Energy (BLE) Mesh is widely recognized as a driver technology for IoT applications.","However, the lack of quality of service (QoS) in BLE Mesh, represented by packet prioritization, significantly limits its potential.","This work implements a quality-of-service (QoS) method for BLE Mesh to prioritize the data packets and provide them with different network transmission settings according to their assigned priority.","Unlike existing works on QoS for BLE Mesh, our proposed approach does not require any modifications to the BLE Mesh protocol and can be smoothly adopted in existing BLE Mesh networks.","We conducted an extensive measurement campaign to evaluate our solution over a 15-node BLE Mesh network deployed to emulate a smart healthcare scenario where 45 sensors with an assigned priority transmit information over the network.","The experiments provide performance results for single and multi channel network scenarios.","The obtained results validate our solution, showing the difference between the established priorities and providing insights and guidelines to conduct further research on QoS over BLE Mesh and broadcast-based networks."],"url":"http://arxiv.org/abs/2308.00599v1"}
{"created":"2023-08-01 15:15:40","title":"MonoNext: A 3D Monocular Object Detection with ConvNext","abstract":"Autonomous driving perception tasks rely heavily on cameras as the primary sensor for Object Detection, Semantic Segmentation, Instance Segmentation, and Object Tracking. However, RGB images captured by cameras lack depth information, which poses a significant challenge in 3D detection tasks. To supplement this missing data, mapping sensors such as LIDAR and RADAR are used for accurate 3D Object Detection. Despite their significant accuracy, the multi-sensor models are expensive and require a high computational demand. In contrast, Monocular 3D Object Detection models are becoming increasingly popular, offering a faster, cheaper, and easier-to-implement solution for 3D detections. This paper introduces a different Multi-Tasking Learning approach called MonoNext that utilizes a spatial grid to map objects in the scene. MonoNext employs a straightforward approach based on the ConvNext network and requires only 3D bounding box annotated data. In our experiments with the KITTI dataset, MonoNext achieved high precision and competitive performance comparable with state-of-the-art approaches. Furthermore, by adding more training data, MonoNext surpassed itself and achieved higher accuracies.","sentences":["Autonomous driving perception tasks rely heavily on cameras as the primary sensor for Object Detection, Semantic Segmentation, Instance Segmentation, and Object Tracking.","However, RGB images captured by cameras lack depth information, which poses a significant challenge in 3D detection tasks.","To supplement this missing data, mapping sensors such as LIDAR and RADAR are used for accurate 3D Object Detection.","Despite their significant accuracy, the multi-sensor models are expensive and require a high computational demand.","In contrast, Monocular 3D Object Detection models are becoming increasingly popular, offering a faster, cheaper, and easier-to-implement solution for 3D detections.","This paper introduces a different Multi-Tasking Learning approach called MonoNext that utilizes a spatial grid to map objects in the scene.","MonoNext employs a straightforward approach based on the ConvNext network and requires only 3D bounding box annotated data.","In our experiments with the KITTI dataset, MonoNext achieved high precision and competitive performance comparable with state-of-the-art approaches.","Furthermore, by adding more training data, MonoNext surpassed itself and achieved higher accuracies."],"url":"http://arxiv.org/abs/2308.00596v1"}
{"created":"2023-08-01 15:07:38","title":"Visibility Enhancement for Low-light Hazy Scenarios","abstract":"Low-light hazy scenes commonly appear at dusk and early morning. The visual enhancement for low-light hazy images is an ill-posed problem. Even though numerous methods have been proposed for image dehazing and low-light enhancement respectively, simply integrating them cannot deliver pleasing results for this particular task. In this paper, we present a novel method to enhance visibility for low-light hazy scenarios. To handle this challenging task, we propose two key techniques, namely cross-consistency dehazing-enhancement framework and physically based simulation for low-light hazy dataset. Specifically, the framework is designed for enhancing visibility of the input image via fully utilizing the clues from different sub-tasks. The simulation is designed for generating the dataset with ground-truths by the proposed low-light hazy imaging model. The extensive experimental results show that the proposed method outperforms the SOTA solutions on different metrics including SSIM (9.19%) and PSNR(5.03%). In addition, we conduct a user study on real images to demonstrate the effectiveness and necessity of the proposed method by human visual perception.","sentences":["Low-light hazy scenes commonly appear at dusk and early morning.","The visual enhancement for low-light hazy images is an ill-posed problem.","Even though numerous methods have been proposed for image dehazing and low-light enhancement respectively, simply integrating them cannot deliver pleasing results for this particular task.","In this paper, we present a novel method to enhance visibility for low-light hazy scenarios.","To handle this challenging task, we propose two key techniques, namely cross-consistency dehazing-enhancement framework and physically based simulation for low-light hazy dataset.","Specifically, the framework is designed for enhancing visibility of the input image via fully utilizing the clues from different sub-tasks.","The simulation is designed for generating the dataset with ground-truths by the proposed low-light hazy imaging model.","The extensive experimental results show that the proposed method outperforms the SOTA solutions on different metrics including SSIM (9.19%) and PSNR(5.03%).","In addition, we conduct a user study on real images to demonstrate the effectiveness and necessity of the proposed method by human visual perception."],"url":"http://arxiv.org/abs/2308.00591v1"}
{"created":"2023-08-01 15:05:57","title":"Game Theoretic Modelling of a Ransom and Extortion Attack on Ethereum Validators","abstract":"Consensus algorithms facilitate agreement on and resolution of blockchain functions, such as smart contracts and transactions. Ethereum uses a Proof-of-Stake (PoS) consensus mechanism, which depends on financial incentives to ensure that validators perform certain duties and do not act maliciously. Should a validator attempt to defraud the system, legitimate validators will identify this and then staked cryptocurrency is `burned' through a process of slashing.   In this paper, we show that an attacker who has compromised a set of validators could threaten to perform malicious actions that would result in slashing and thus, hold those validators to ransom. We use game theory to study how an attacker can coerce payment from a victim, for example by deploying a smart contract to provide a root of trust shared between attacker and victim during the extortion process. Our game theoretic model finds that it is in the interests of the validators to fully pay the ransom due to a lack of systemic protections for validators. Financial risk is solely placed on the victim during such an attack, with no mitigations available to them aside from capitulation (payment of ransom) in many scenarios. Such attacks could be disruptive to Ethereum and, likely, to many other PoS networks, if public trust in the validator system is eroded. We also discuss and evaluate potential mitigation measures arising from our analysis of the game theoretic model.","sentences":["Consensus algorithms facilitate agreement on and resolution of blockchain functions, such as smart contracts and transactions.","Ethereum uses a Proof-of-Stake (PoS) consensus mechanism, which depends on financial incentives to ensure that validators perform certain duties and do not act maliciously.","Should a validator attempt to defraud the system, legitimate validators will identify this and then staked cryptocurrency is `burned' through a process of slashing.   ","In this paper, we show that an attacker who has compromised a set of validators could threaten to perform malicious actions that would result in slashing and thus, hold those validators to ransom.","We use game theory to study how an attacker can coerce payment from a victim, for example by deploying a smart contract to provide a root of trust shared between attacker and victim during the extortion process.","Our game theoretic model finds that it is in the interests of the validators to fully pay the ransom due to a lack of systemic protections for validators.","Financial risk is solely placed on the victim during such an attack, with no mitigations available to them aside from capitulation (payment of ransom) in many scenarios.","Such attacks could be disruptive to Ethereum and, likely, to many other PoS networks, if public trust in the validator system is eroded.","We also discuss and evaluate potential mitigation measures arising from our analysis of the game theoretic model."],"url":"http://arxiv.org/abs/2308.00590v1"}
{"created":"2023-08-01 15:04:56","title":"Relation-Aware Distribution Representation Network for Person Clustering with Multiple Modalities","abstract":"Person clustering with multi-modal clues, including faces, bodies, and voices, is critical for various tasks, such as movie parsing and identity-based movie editing. Related methods such as multi-view clustering mainly project multi-modal features into a joint feature space. However, multi-modal clue features are usually rather weakly correlated due to the semantic gap from the modality-specific uniqueness. As a result, these methods are not suitable for person clustering. In this paper, we propose a Relation-Aware Distribution representation Network (RAD-Net) to generate a distribution representation for multi-modal clues. The distribution representation of a clue is a vector consisting of the relation between this clue and all other clues from all modalities, thus being modality agnostic and good for person clustering. Accordingly, we introduce a graph-based method to construct distribution representation and employ a cyclic update policy to refine distribution representation progressively. Our method achieves substantial improvements of +6% and +8.2% in F-score on the Video Person-Clustering Dataset (VPCD) and VoxCeleb2 multi-view clustering dataset, respectively. Codes will be released publicly upon acceptance.","sentences":["Person clustering with multi-modal clues, including faces, bodies, and voices, is critical for various tasks, such as movie parsing and identity-based movie editing.","Related methods such as multi-view clustering mainly project multi-modal features into a joint feature space.","However, multi-modal clue features are usually rather weakly correlated due to the semantic gap from the modality-specific uniqueness.","As a result, these methods are not suitable for person clustering.","In this paper, we propose a Relation-Aware Distribution representation Network (RAD-Net) to generate a distribution representation for multi-modal clues.","The distribution representation of a clue is a vector consisting of the relation between this clue and all other clues from all modalities, thus being modality agnostic and good for person clustering.","Accordingly, we introduce a graph-based method to construct distribution representation and employ a cyclic update policy to refine distribution representation progressively.","Our method achieves substantial improvements of +6% and","+8.2% in F-score on the Video Person-Clustering Dataset (VPCD) and VoxCeleb2 multi-view clustering dataset, respectively.","Codes will be released publicly upon acceptance."],"url":"http://arxiv.org/abs/2308.00588v1"}
{"created":"2023-08-01 14:52:09","title":"Epistemic Planning for Heterogeneous Robotic Systems","abstract":"In applications such as search and rescue or disaster relief, heterogeneous multi-robot systems (MRS) can provide significant advantages for complex objectives that require a suite of capabilities. However, within these application spaces, communication is often unreliable, causing inefficiencies or outright failures to arise in most MRS algorithms. Many researchers tackle this problem by requiring all robots to either maintain communication using proximity constraints or assuming that all robots will execute a predetermined plan over long periods of disconnection. The latter method allows for higher levels of efficiency in a MRS, but failures and environmental uncertainties can have cascading effects across the system, especially when a mission objective is complex or time-sensitive. To solve this, we propose an epistemic planning framework that allows robots to reason about the system state, leverage heterogeneous system makeups, and optimize information dissemination to disconnected neighbors. Dynamic epistemic logic formalizes the propagation of belief states, and epistemic task allocation and gossip is accomplished via a mixed integer program using the belief states for utility predictions and planning. The proposed framework is validated using simulations and experiments with heterogeneous vehicles.","sentences":["In applications such as search and rescue or disaster relief, heterogeneous multi-robot systems (MRS) can provide significant advantages for complex objectives that require a suite of capabilities.","However, within these application spaces, communication is often unreliable, causing inefficiencies or outright failures to arise in most MRS algorithms.","Many researchers tackle this problem by requiring all robots to either maintain communication using proximity constraints or assuming that all robots will execute a predetermined plan over long periods of disconnection.","The latter method allows for higher levels of efficiency in a MRS, but failures and environmental uncertainties can have cascading effects across the system, especially when a mission objective is complex or time-sensitive.","To solve this, we propose an epistemic planning framework that allows robots to reason about the system state, leverage heterogeneous system makeups, and optimize information dissemination to disconnected neighbors.","Dynamic epistemic logic formalizes the propagation of belief states, and epistemic task allocation and gossip is accomplished via a mixed integer program using the belief states for utility predictions and planning.","The proposed framework is validated using simulations and experiments with heterogeneous vehicles."],"url":"http://arxiv.org/abs/2308.00579v1"}
{"created":"2023-08-01 14:41:50","title":"Sliding Touch-based Exploration for Modeling Unknown Object Shape with Multi-fingered Hands","abstract":"Efficient and accurate 3D object shape reconstruction contributes significantly to the success of a robot's physical interaction with its environment. Acquiring accurate shape information about unknown objects is challenging, especially in unstructured environments, e.g. the vision sensors may only be able to provide a partial view. To address this issue, tactile sensors could be employed to extract local surface information for more robust unknown object shape estimation. In this paper, we propose a novel approach for efficient unknown 3D object shape exploration and reconstruction using a multi-fingered hand equipped with tactile sensors and a depth camera only providing a partial view. We present a multi-finger sliding touch strategy for efficient shape exploration using a Bayesian Optimization approach and a single-leader-multi-follower strategy for multi-finger smooth local surface perception. We evaluate our proposed method by estimating the 3D shape of objects from the YCB and OCRTOC datasets based on simulation and real robot experiments. The proposed approach yields successful reconstruction results relying on only a few continuous sliding touches. Experimental results demonstrate that our method is able to model unknown objects in an efficient and accurate way.","sentences":["Efficient and accurate 3D object shape reconstruction contributes significantly to the success of a robot's physical interaction with its environment.","Acquiring accurate shape information about unknown objects is challenging, especially in unstructured environments, e.g. the vision sensors may only be able to provide a partial view.","To address this issue, tactile sensors could be employed to extract local surface information for more robust unknown object shape estimation.","In this paper, we propose a novel approach for efficient unknown 3D object shape exploration and reconstruction using a multi-fingered hand equipped with tactile sensors and a depth camera only providing a partial view.","We present a multi-finger sliding touch strategy for efficient shape exploration using a Bayesian Optimization approach and a single-leader-multi-follower strategy for multi-finger smooth local surface perception.","We evaluate our proposed method by estimating the 3D shape of objects from the YCB and OCRTOC datasets based on simulation and real robot experiments.","The proposed approach yields successful reconstruction results relying on only a few continuous sliding touches.","Experimental results demonstrate that our method is able to model unknown objects in an efficient and accurate way."],"url":"http://arxiv.org/abs/2308.00576v1"}
{"created":"2023-08-01 14:35:29","title":"PVG: Progressive Vision Graph for Vision Recognition","abstract":"Convolution-based and Transformer-based vision backbone networks process images into the grid or sequence structures, respectively, which are inflexible for capturing irregular objects. Though Vision GNN (ViG) adopts graph-level features for complex images, it has some issues, such as inaccurate neighbor node selection, expensive node information aggregation calculation, and over-smoothing in the deep layers. To address the above problems, we propose a Progressive Vision Graph (PVG) architecture for vision recognition task. Compared with previous works, PVG contains three main components: 1) Progressively Separated Graph Construction (PSGC) to introduce second-order similarity by gradually increasing the channel of the global graph branch and decreasing the channel of local branch as the layer deepens; 2) Neighbor nodes information aggregation and update module by using Max pooling and mathematical Expectation (MaxE) to aggregate rich neighbor information; 3) Graph error Linear Unit (GraphLU) to enhance low-value information in a relaxed form to reduce the compression of image detail information for alleviating the over-smoothing. Extensive experiments on mainstream benchmarks demonstrate the superiority of PVG over state-of-the-art methods, e.g., our PVG-S obtains 83.0% Top-1 accuracy on ImageNet-1K that surpasses GNN-based ViG-S by +0.9 with the parameters reduced by 18.5%, while the largest PVG-B obtains 84.2% that has +0.5 improvement than ViG-B. Furthermore, our PVG-S obtains +1.3 box AP and +0.4 mask AP gains than ViG-S on COCO dataset.","sentences":["Convolution-based and Transformer-based vision backbone networks process images into the grid or sequence structures, respectively, which are inflexible for capturing irregular objects.","Though Vision GNN (ViG) adopts graph-level features for complex images, it has some issues, such as inaccurate neighbor node selection, expensive node information aggregation calculation, and over-smoothing in the deep layers.","To address the above problems, we propose a Progressive Vision Graph (PVG) architecture for vision recognition task.","Compared with previous works, PVG contains three main components: 1) Progressively Separated Graph Construction (PSGC) to introduce second-order similarity by gradually increasing the channel of the global graph branch and decreasing the channel of local branch as the layer deepens; 2) Neighbor nodes information aggregation and update module by using Max pooling and mathematical Expectation (MaxE) to aggregate rich neighbor information; 3) Graph error Linear Unit (GraphLU) to enhance low-value information in a relaxed form to reduce the compression of image detail information for alleviating the over-smoothing.","Extensive experiments on mainstream benchmarks demonstrate the superiority of PVG over state-of-the-art methods, e.g., our PVG-S obtains 83.0% Top-1 accuracy on ImageNet-1K that surpasses GNN-based ViG-S by +0.9 with the parameters reduced by 18.5%, while the largest PVG-B obtains 84.2% that has +0.5 improvement than","ViG-B. Furthermore, our PVG-S obtains +1.3 box AP and +0.4 mask AP gains than ViG-S on COCO dataset."],"url":"http://arxiv.org/abs/2308.00574v1"}
{"created":"2023-08-01 14:20:27","title":"Enhancing Sample Efficiency and Uncertainty Compensation in Learning-based Model Predictive Control for Aerial Robots","abstract":"The recent increase in data availability and reliability has led to a surge in the development of learning-based model predictive control (MPC) frameworks for robot systems. Despite attaining substantial performance improvements over their non-learning counterparts, many of these frameworks rely on an offline learning procedure to synthesize a dynamics model. This implies that uncertainties encountered by the robot during deployment are not accounted for in the learning process. On the other hand, learning-based MPC methods that learn dynamics models online are computationally expensive and often require a significant amount of data. To alleviate these shortcomings, we propose a novel learning-enhanced MPC framework that incorporates components from $\\mathcal{L}_1$ adaptive control into learning-based MPC. This integration enables the accurate compensation of both matched and unmatched uncertainties in a sample-efficient way, enhancing the control performance during deployment. In our proposed framework, we present two variants and apply them to the control of a quadrotor system. Through simulations and physical experiments, we demonstrate that the proposed framework not only allows the synthesis of an accurate dynamics model on-the-fly, but also significantly improves the closed-loop control performance under a wide range of spatio-temporal uncertainties.","sentences":["The recent increase in data availability and reliability has led to a surge in the development of learning-based model predictive control (MPC) frameworks for robot systems.","Despite attaining substantial performance improvements over their non-learning counterparts, many of these frameworks rely on an offline learning procedure to synthesize a dynamics model.","This implies that uncertainties encountered by the robot during deployment are not accounted for in the learning process.","On the other hand, learning-based MPC methods that learn dynamics models online are computationally expensive and often require a significant amount of data.","To alleviate these shortcomings, we propose a novel learning-enhanced MPC framework that incorporates components from $\\mathcal{L}_1$ adaptive control into learning-based MPC.","This integration enables the accurate compensation of both matched and unmatched uncertainties in a sample-efficient way, enhancing the control performance during deployment.","In our proposed framework, we present two variants and apply them to the control of a quadrotor system.","Through simulations and physical experiments, we demonstrate that the proposed framework not only allows the synthesis of an accurate dynamics model on-the-fly, but also significantly improves the closed-loop control performance under a wide range of spatio-temporal uncertainties."],"url":"http://arxiv.org/abs/2308.00570v1"}
{"created":"2023-08-01 14:09:19","title":"AOSoar: Autonomous Orographic Soaring of a Micro Air Vehicle","abstract":"Utilizing wind hovering techniques of soaring birds can save energy expenditure and improve the flight endurance of micro air vehicles (MAVs). Here, we present a novel method for fully autonomous orographic soaring without a priori knowledge of the wind field. Specifically, we devise an Incremental Nonlinear Dynamic Inversion (INDI) controller with control allocation, adapting it for autonomous soaring. This allows for both soaring and the use of the throttle if necessary, without changing any gain or parameter during the flight. Furthermore, we propose a simulated-annealing-based optimization method to search for soaring positions. This enables for the first time an MAV to autonomously find a feasible soaring position while minimizing throttle usage and other control efforts. Autonomous orographic soaring was performed in the wind tunnel. The wind speed and incline of a ramp were changed during the soaring flight. The MAV was able to perform autonomous orographic soaring for flight times of up to 30 minutes. The mean throttle usage was only 0.25% for the entire soaring flight, whereas normal powered flight requires 38%. Also, it was shown that the MAV can find a new soaring spot when the wind field changes during the flight.","sentences":["Utilizing wind hovering techniques of soaring birds can save energy expenditure and improve the flight endurance of micro air vehicles (MAVs).","Here, we present a novel method for fully autonomous orographic soaring without a priori knowledge of the wind field.","Specifically, we devise an Incremental Nonlinear Dynamic Inversion (INDI) controller with control allocation, adapting it for autonomous soaring.","This allows for both soaring and the use of the throttle if necessary, without changing any gain or parameter during the flight.","Furthermore, we propose a simulated-annealing-based optimization method to search for soaring positions.","This enables for the first time an MAV to autonomously find a feasible soaring position while minimizing throttle usage and other control efforts.","Autonomous orographic soaring was performed in the wind tunnel.","The wind speed and incline of a ramp were changed during the soaring flight.","The MAV was able to perform autonomous orographic soaring for flight times of up to 30 minutes.","The mean throttle usage was only 0.25% for the entire soaring flight, whereas normal powered flight requires 38%.","Also, it was shown that the MAV can find a new soaring spot when the wind field changes during the flight."],"url":"http://arxiv.org/abs/2308.00565v1"}
{"created":"2023-08-01 14:00:31","title":"Reinforcement Learning-based Non-Autoregressive Solver for Traveling Salesman Problems","abstract":"The Traveling Salesman Problem (TSP) is a well-known problem in combinatorial optimization with applications in various domains. However, existing TSP solvers face challenges in producing high-quality solutions with low latency. To address this issue, we propose NAR4TSP, which produces TSP solutions in a Non-Autoregressive (NAR) manner using a specially designed Graph Neural Network (GNN), achieving faster inference speed. Moreover, NAR4TSP is trained using an enhanced Reinforcement Learning (RL) strategy, eliminating the dependency on costly labels used to train conventional supervised learning-based NAR models. To the best of our knowledge, NAR4TSP is the first TSP solver that successfully combines RL and NAR decoding. The experimental results on both synthetic and real-world TSP instances demonstrate that NAR4TSP outperforms four state-of-the-art models in terms of solution quality, inference latency, and generalization ability. Lastly, we present visualizations of NAR4TSP's decoding process and its overall path planning to showcase the feasibility of implementing NAR4TSP in an end-to-end manner and its effectiveness, respectively.","sentences":["The Traveling Salesman Problem (TSP) is a well-known problem in combinatorial optimization with applications in various domains.","However, existing TSP solvers face challenges in producing high-quality solutions with low latency.","To address this issue, we propose NAR4TSP, which produces TSP solutions in a Non-Autoregressive (NAR) manner using a specially designed Graph Neural Network (GNN), achieving faster inference speed.","Moreover, NAR4TSP is trained using an enhanced Reinforcement Learning (RL) strategy, eliminating the dependency on costly labels used to train conventional supervised learning-based NAR models.","To the best of our knowledge, NAR4TSP is the first TSP solver that successfully combines RL and NAR decoding.","The experimental results on both synthetic and real-world TSP instances demonstrate that NAR4TSP outperforms four state-of-the-art models in terms of solution quality, inference latency, and generalization ability.","Lastly, we present visualizations of NAR4TSP's decoding process and its overall path planning to showcase the feasibility of implementing NAR4TSP in an end-to-end manner and its effectiveness, respectively."],"url":"http://arxiv.org/abs/2308.00560v1"}
{"created":"2023-08-01 13:58:21","title":"Gradient Scaling on Deep Spiking Neural Networks with Spike-Dependent Local Information","abstract":"Deep spiking neural networks (SNNs) are promising neural networks for their model capacity from deep neural network architecture and energy efficiency from SNNs' operations. To train deep SNNs, recently, spatio-temporal backpropagation (STBP) with surrogate gradient was proposed. Although deep SNNs have been successfully trained with STBP, they cannot fully utilize spike information. In this work, we proposed gradient scaling with local spike information, which is the relation between pre- and post-synaptic spikes. Considering the causality between spikes, we could enhance the training performance of deep SNNs. According to our experiments, we could achieve higher accuracy with lower spikes by adopting the gradient scaling on image classification tasks, such as CIFAR10 and CIFAR100.","sentences":["Deep spiking neural networks (SNNs) are promising neural networks for their model capacity from deep neural network architecture and energy efficiency from SNNs' operations.","To train deep SNNs, recently, spatio-temporal backpropagation (STBP) with surrogate gradient was proposed.","Although deep SNNs have been successfully trained with STBP, they cannot fully utilize spike information.","In this work, we proposed gradient scaling with local spike information, which is the relation between pre- and post-synaptic spikes.","Considering the causality between spikes, we could enhance the training performance of deep SNNs.","According to our experiments, we could achieve higher accuracy with lower spikes by adopting the gradient scaling on image classification tasks, such as CIFAR10 and CIFAR100."],"url":"http://arxiv.org/abs/2308.00558v1"}
{"created":"2023-08-01 13:47:27","title":"FLAIRS: FPGA-Accelerated Inference-Resistant & Secure Federated Learning","abstract":"Federated Learning (FL) has become very popular since it enables clients to train a joint model collaboratively without sharing their private data. However, FL has been shown to be susceptible to backdoor and inference attacks. While in the former, the adversary injects manipulated updates into the aggregation process; the latter leverages clients' local models to deduce their private data. Contemporary solutions to address the security concerns of FL are either impractical for real-world deployment due to high-performance overheads or are tailored towards addressing specific threats, for instance, privacy-preserving aggregation or backdoor defenses. Given these limitations, our research delves into the advantages of harnessing the FPGA-based computing paradigm to overcome performance bottlenecks of software-only solutions while mitigating backdoor and inference attacks. We utilize FPGA-based enclaves to address inference attacks during the aggregation process of FL. We adopt an advanced backdoor-aware aggregation algorithm on the FPGA to counter backdoor attacks. We implemented and evaluated our method on Xilinx VMK-180, yielding a significant speed-up of around 300 times on the IoT-Traffic dataset and more than 506 times on the CIFAR-10 dataset.","sentences":["Federated Learning (FL) has become very popular since it enables clients to train a joint model collaboratively without sharing their private data.","However, FL has been shown to be susceptible to backdoor and inference attacks.","While in the former, the adversary injects manipulated updates into the aggregation process; the latter leverages clients' local models to deduce their private data.","Contemporary solutions to address the security concerns of FL are either impractical for real-world deployment due to high-performance overheads or are tailored towards addressing specific threats, for instance, privacy-preserving aggregation or backdoor defenses.","Given these limitations, our research delves into the advantages of harnessing the FPGA-based computing paradigm to overcome performance bottlenecks of software-only solutions while mitigating backdoor and inference attacks.","We utilize FPGA-based enclaves to address inference attacks during the aggregation process of FL.","We adopt an advanced backdoor-aware aggregation algorithm on the FPGA to counter backdoor attacks.","We implemented and evaluated our method on Xilinx VMK-180, yielding a significant speed-up of around 300 times on the IoT-Traffic dataset and more than 506 times on the CIFAR-10 dataset."],"url":"http://arxiv.org/abs/2308.00553v1"}
{"created":"2023-08-01 13:45:04","title":"Copula for Instance-wise Feature Selection and Ranking","abstract":"Instance-wise feature selection and ranking methods can achieve a good selection of task-friendly features for each sample in the context of neural networks. However, existing approaches that assume feature subsets to be independent are imperfect when considering the dependency between features. To address this limitation, we propose to incorporate the Gaussian copula, a powerful mathematical technique for capturing correlations between variables, into the current feature selection framework with no additional changes needed. Experimental results on both synthetic and real datasets, in terms of performance comparison and interpretability, demonstrate that our method is capable of capturing meaningful correlations.","sentences":["Instance-wise feature selection and ranking methods can achieve a good selection of task-friendly features for each sample in the context of neural networks.","However, existing approaches that assume feature subsets to be independent are imperfect when considering the dependency between features.","To address this limitation, we propose to incorporate the Gaussian copula, a powerful mathematical technique for capturing correlations between variables, into the current feature selection framework with no additional changes needed.","Experimental results on both synthetic and real datasets, in terms of performance comparison and interpretability, demonstrate that our method is capable of capturing meaningful correlations."],"url":"http://arxiv.org/abs/2308.00549v1"}
{"created":"2023-08-01 13:39:42","title":"On the Performance Tradeoff of an ISAC System with Finite Blocklength","abstract":"Integrated sensing and communication (ISAC) has been proposed as a promising paradigm in the future wireless networks, where the spectral and hardware resources are shared to provide a considerable performance gain. It is essential to understand how sensing and communication (S\\&C) influences each other to guide the practical algorithm and system design in ISAC. In this paper, we investigate the performance tradeoff between S\\&C in a single-input single-output (SISO) ISAC system with finite blocklength. In particular, we present the system model and the ISAC scheme, after which the rate-error tradeoff is introduced as the performance metric. Then we derive the achievability and converse bounds for the rate-error tradeoff, determining the boundary of the joint S\\&C performance. Furthermore, we develop the asymptotic analysis at large blocklength regime, where the performance tradeoff between S\\&C is proved to vanish as the blocklength tends to infinity. Finally, our theoretical analysis is consolidated by simulation results.","sentences":["Integrated sensing and communication (ISAC) has been proposed as a promising paradigm in the future wireless networks, where the spectral and hardware resources are shared to provide a considerable performance gain.","It is essential to understand how sensing and communication (S\\&C) influences each other to guide the practical algorithm and system design in ISAC.","In this paper, we investigate the performance tradeoff between S\\&C in a single-input single-output (SISO) ISAC system with finite blocklength.","In particular, we present the system model and the ISAC scheme, after which the rate-error tradeoff is introduced as the performance metric.","Then we derive the achievability and converse bounds for the rate-error tradeoff, determining the boundary of the joint S\\&C performance.","Furthermore, we develop the asymptotic analysis at large blocklength regime, where the performance tradeoff between S\\&C is proved to vanish as the blocklength tends to infinity.","Finally, our theoretical analysis is consolidated by simulation results."],"url":"http://arxiv.org/abs/2308.00543v1"}
{"created":"2023-08-01 13:36:56","title":"SF-IDS: An Imbalanced Semi-Supervised Learning Framework for Fine-grained Intrusion Detection","abstract":"Deep learning-based fine-grained network intrusion detection systems (NIDS) enable different attacks to be responded to in a fast and targeted manner with the help of large-scale labels. However, the cost of labeling causes insufficient labeled samples. Also, the real fine-grained traffic shows a long-tailed distribution with great class imbalance. These two problems often appear simultaneously, posing serious challenges to fine-grained NIDS. In this work, we propose a novel semi-supervised fine-grained intrusion detection framework, SF-IDS, to achieve attack classification in the label-limited and highly class imbalanced case. We design a self-training backbone model called RI-1DCNN to boost the feature extraction by reconstructing the input samples into a multichannel image format. The uncertainty of the generated pseudo-labels is evaluated and used as a reference for pseudo-label filtering in combination with the prediction probability. To mitigate the effects of fine-grained class imbalance, we propose a hybrid loss function combining supervised contrastive loss and multi-weighted classification loss to obtain more compact intra-class features and clearer inter-class intervals. Experiments show that the proposed SF-IDS achieves 3.01% and 2.71% Marco-F1 improvement on two classical datasets with 1% labeled, respectively.","sentences":["Deep learning-based fine-grained network intrusion detection systems (NIDS) enable different attacks to be responded to in a fast and targeted manner with the help of large-scale labels.","However, the cost of labeling causes insufficient labeled samples.","Also, the real fine-grained traffic shows a long-tailed distribution with great class imbalance.","These two problems often appear simultaneously, posing serious challenges to fine-grained NIDS.","In this work, we propose a novel semi-supervised fine-grained intrusion detection framework, SF-IDS, to achieve attack classification in the label-limited and highly class imbalanced case.","We design a self-training backbone model called RI-1DCNN to boost the feature extraction by reconstructing the input samples into a multichannel image format.","The uncertainty of the generated pseudo-labels is evaluated and used as a reference for pseudo-label filtering in combination with the prediction probability.","To mitigate the effects of fine-grained class imbalance, we propose a hybrid loss function combining supervised contrastive loss and multi-weighted classification loss to obtain more compact intra-class features and clearer inter-class intervals.","Experiments show that the proposed SF-IDS achieves 3.01% and 2.71% Marco-F1 improvement on two classical datasets with 1% labeled, respectively."],"url":"http://arxiv.org/abs/2308.00542v1"}
{"created":"2023-08-01 13:36:46","title":"Detecting Cloud Presence in Satellite Images Using the RGB-based CLIP Vision-Language Model","abstract":"This work explores capabilities of the pre-trained CLIP vision-language model to identify satellite images affected by clouds. Several approaches to using the model to perform cloud presence detection are proposed and evaluated, including a purely zero-shot operation with text prompts and several fine-tuning approaches. Furthermore, the transferability of the methods across different datasets and sensor types (Sentinel-2 and Landsat-8) is tested. The results that CLIP can achieve non-trivial performance on the cloud presence detection task with apparent capability to generalise across sensing modalities and sensing bands. It is also found that a low-cost fine-tuning stage leads to a strong increase in true negative rate. The results demonstrate that the representations learned by the CLIP model can be useful for satellite image processing tasks involving clouds.","sentences":["This work explores capabilities of the pre-trained CLIP vision-language model to identify satellite images affected by clouds.","Several approaches to using the model to perform cloud presence detection are proposed and evaluated, including a purely zero-shot operation with text prompts and several fine-tuning approaches.","Furthermore, the transferability of the methods across different datasets and sensor types (Sentinel-2 and Landsat-8) is tested.","The results that CLIP can achieve non-trivial performance on the cloud presence detection task with apparent capability to generalise across sensing modalities and sensing bands.","It is also found that a low-cost fine-tuning stage leads to a strong increase in true negative rate.","The results demonstrate that the representations learned by the CLIP model can be useful for satellite image processing tasks involving clouds."],"url":"http://arxiv.org/abs/2308.00541v1"}
{"created":"2023-08-01 13:36:33","title":"Compressed Private Aggregation for Scalable and Robust Federated Learning over Massive Networks","abstract":"Federated learning (FL) is an emerging paradigm that allows a central server to train machine learning models using remote users' data. Despite its growing popularity, FL faces challenges in preserving the privacy of local datasets, its sensitivity to poisoning attacks by malicious users, and its communication overhead. The latter is additionally considerably dominant in large-scale networks. These limitations are often individually mitigated by local differential privacy (LDP) mechanisms, robust aggregation, compression, and user selection techniques, which typically come at the cost of accuracy. In this work, we present compressed private aggregation (CPA), that allows massive deployments to simultaneously communicate at extremely low bit rates while achieving privacy, anonymity, and resilience to malicious users. CPA randomizes a codebook for compressing the data into a few bits using nested lattice quantizers, while ensuring anonymity and robustness, with a subsequent perturbation to hold LDP. The proposed CPA is proven to result in FL convergence in the same asymptotic rate as FL without privacy, compression, and robustness considerations, while satisfying both anonymity and LDP requirements. These analytical properties are empirically confirmed in a numerical study, where we demonstrate the performance gains of CPA compared with separate mechanisms for compression and privacy for training different image classification models, as well as its robustness in mitigating the harmful effects of malicious users.","sentences":["Federated learning (FL) is an emerging paradigm that allows a central server to train machine learning models using remote users' data.","Despite its growing popularity, FL faces challenges in preserving the privacy of local datasets, its sensitivity to poisoning attacks by malicious users, and its communication overhead.","The latter is additionally considerably dominant in large-scale networks.","These limitations are often individually mitigated by local differential privacy (LDP) mechanisms, robust aggregation, compression, and user selection techniques, which typically come at the cost of accuracy.","In this work, we present compressed private aggregation (CPA), that allows massive deployments to simultaneously communicate at extremely low bit rates while achieving privacy, anonymity, and resilience to malicious users.","CPA randomizes a codebook for compressing the data into a few bits using nested lattice quantizers, while ensuring anonymity and robustness, with a subsequent perturbation to hold LDP.","The proposed CPA is proven to result in FL convergence in the same asymptotic rate as FL without privacy, compression, and robustness considerations, while satisfying both anonymity and LDP requirements.","These analytical properties are empirically confirmed in a numerical study, where we demonstrate the performance gains of CPA compared with separate mechanisms for compression and privacy for training different image classification models, as well as its robustness in mitigating the harmful effects of malicious users."],"url":"http://arxiv.org/abs/2308.00540v1"}
{"created":"2023-08-01 13:32:07","title":"Predicting Early Dropouts of an Active and Healthy Ageing App","abstract":"In this work, we present a machine learning approach for predicting early dropouts of an active and healthy ageing app. The presented algorithms have been submitted to the IFMBE Scientific Challenge 2022, part of IUPESM WC 2022. We have processed the given database and generated seven datasets. We used pre-processing techniques to construct classification models that predict the adherence of users using dynamic and static features. We submitted 11 official runs and our results show that machine learning algorithms can provide high-quality adherence predictions. Based on the results, the dynamic features positively influence a model's classification performance. Due to the imbalanced nature of the dataset, we employed oversampling methods such as SMOTE and ADASYN to improve the classification performance. The oversampling approaches led to a remarkable improvement of 10\\%. Our methods won first place in the IFMBE Scientific Challenge 2022.","sentences":["In this work, we present a machine learning approach for predicting early dropouts of an active and healthy ageing app.","The presented algorithms have been submitted to the IFMBE Scientific Challenge 2022, part of IUPESM WC 2022.","We have processed the given database and generated seven datasets.","We used pre-processing techniques to construct classification models that predict the adherence of users using dynamic and static features.","We submitted 11 official runs and our results show that machine learning algorithms can provide high-quality adherence predictions.","Based on the results, the dynamic features positively influence a model's classification performance.","Due to the imbalanced nature of the dataset, we employed oversampling methods such as SMOTE and ADASYN to improve the classification performance.","The oversampling approaches led to a remarkable improvement of 10\\%.","Our methods won first place in the IFMBE Scientific Challenge 2022."],"url":"http://arxiv.org/abs/2308.00539v1"}
{"created":"2023-08-01 13:31:25","title":"PressureTransferNet: Human Attribute Guided Dynamic Ground Pressure Profile Transfer using 3D simulated Pressure Maps","abstract":"We propose PressureTransferNet, a novel method for Human Activity Recognition (HAR) using ground pressure information. Our approach generates body-specific dynamic ground pressure profiles for specific activities by leveraging existing pressure data from different individuals. PressureTransferNet is an encoder-decoder model taking a source pressure map and a target human attribute vector as inputs, producing a new pressure map reflecting the target attribute. To train the model, we use a sensor simulation to create a diverse dataset with various human attributes and pressure profiles. Evaluation on a real-world dataset shows its effectiveness in accurately transferring human attributes to ground pressure profiles across different scenarios. We visually confirm the fidelity of the synthesized pressure shapes using a physics-based deep learning model and achieve a binary R-square value of 0.79 on areas with ground contact. Validation through classification with F1 score (0.911$\\pm$0.015) on physical pressure mat data demonstrates the correctness of the synthesized pressure maps, making our method valuable for data augmentation, denoising, sensor simulation, and anomaly detection. Applications span sports science, rehabilitation, and bio-mechanics, contributing to the development of HAR systems.","sentences":["We propose PressureTransferNet, a novel method for Human Activity Recognition (HAR) using ground pressure information.","Our approach generates body-specific dynamic ground pressure profiles for specific activities by leveraging existing pressure data from different individuals.","PressureTransferNet is an encoder-decoder model taking a source pressure map and a target human attribute vector as inputs, producing a new pressure map reflecting the target attribute.","To train the model, we use a sensor simulation to create a diverse dataset with various human attributes and pressure profiles.","Evaluation on a real-world dataset shows its effectiveness in accurately transferring human attributes to ground pressure profiles across different scenarios.","We visually confirm the fidelity of the synthesized pressure shapes using a physics-based deep learning model and achieve a binary R-square value of 0.79 on areas with ground contact.","Validation through classification with F1 score (0.911$\\pm$0.015) on physical pressure mat data demonstrates the correctness of the synthesized pressure maps, making our method valuable for data augmentation, denoising, sensor simulation, and anomaly detection.","Applications span sports science, rehabilitation, and bio-mechanics, contributing to the development of HAR systems."],"url":"http://arxiv.org/abs/2308.00538v1"}
{"created":"2023-08-01 13:28:24","title":"Graph Contrastive Learning with Generative Adversarial Network","abstract":"Graph Neural Networks (GNNs) have demonstrated promising results on exploiting node representations for many downstream tasks through supervised end-to-end training. To deal with the widespread label scarcity issue in real-world applications, Graph Contrastive Learning (GCL) is leveraged to train GNNs with limited or even no labels by maximizing the mutual information between nodes in its augmented views generated from the original graph. However, the distribution of graphs remains unconsidered in view generation, resulting in the ignorance of unseen edges in most existing literature, which is empirically shown to be able to improve GCL's performance in our experiments. To this end, we propose to incorporate graph generative adversarial networks (GANs) to learn the distribution of views for GCL, in order to i) automatically capture the characteristic of graphs for augmentations, and ii) jointly train the graph GAN model and the GCL model. Specifically, we present GACN, a novel Generative Adversarial Contrastive learning Network for graph representation learning. GACN develops a view generator and a view discriminator to generate augmented views automatically in an adversarial style. Then, GACN leverages these views to train a GNN encoder with two carefully designed self-supervised learning losses, including the graph contrastive loss and the Bayesian personalized ranking Loss. Furthermore, we design an optimization framework to train all GACN modules jointly. Extensive experiments on seven real-world datasets show that GACN is able to generate high-quality augmented views for GCL and is superior to twelve state-of-the-art baseline methods. Noticeably, our proposed GACN surprisingly discovers that the generated views in data augmentation finally conform to the well-known preferential attachment rule in online networks.","sentences":["Graph Neural Networks (GNNs) have demonstrated promising results on exploiting node representations for many downstream tasks through supervised end-to-end training.","To deal with the widespread label scarcity issue in real-world applications, Graph Contrastive Learning (GCL) is leveraged to train GNNs with limited or even no labels by maximizing the mutual information between nodes in its augmented views generated from the original graph.","However, the distribution of graphs remains unconsidered in view generation, resulting in the ignorance of unseen edges in most existing literature, which is empirically shown to be able to improve GCL's performance in our experiments.","To this end, we propose to incorporate graph generative adversarial networks (GANs) to learn the distribution of views for GCL, in order to i) automatically capture the characteristic of graphs for augmentations, and ii) jointly train the graph GAN model and the GCL model.","Specifically, we present GACN, a novel Generative Adversarial Contrastive learning Network for graph representation learning.","GACN develops a view generator and a view discriminator to generate augmented views automatically in an adversarial style.","Then, GACN leverages these views to train a GNN encoder with two carefully designed self-supervised learning losses, including the graph contrastive loss and the Bayesian personalized ranking Loss.","Furthermore, we design an optimization framework to train all GACN modules jointly.","Extensive experiments on seven real-world datasets show that GACN is able to generate high-quality augmented views for GCL and is superior to twelve state-of-the-art baseline methods.","Noticeably, our proposed GACN surprisingly discovers that the generated views in data augmentation finally conform to the well-known preferential attachment rule in online networks."],"url":"http://arxiv.org/abs/2308.00535v1"}
{"created":"2023-08-01 13:26:59","title":"A Novel Temporal Multi-Gate Mixture-of-Experts Approach for Vehicle Trajectory and Driving Intention Prediction","abstract":"Accurate Vehicle Trajectory Prediction is critical for automated vehicles and advanced driver assistance systems. Vehicle trajectory prediction consists of two essential tasks, i.e., longitudinal position prediction and lateral position prediction. There is a significant correlation between driving intentions and vehicle motion. In existing work, the three tasks are often conducted separately without considering the relationships between the longitudinal position, lateral position, and driving intention. In this paper, we propose a novel Temporal Multi-Gate Mixture-of-Experts (TMMOE) model for simultaneously predicting the vehicle trajectory and driving intention. The proposed model consists of three layers: a shared layer, an expert layer, and a fully connected layer. In the model, the shared layer utilizes Temporal Convolutional Networks (TCN) to extract temporal features. Then the expert layer is built to identify different information according to the three tasks. Moreover, the fully connected layer is used to integrate and export prediction results. To achieve better performance, uncertainty algorithm is used to construct the multi-task loss function. Finally, the publicly available CitySim dataset validates the TMMOE model, demonstrating superior performance compared to the LSTM model, achieving the highest classification and regression results. Keywords: Vehicle trajectory prediction, driving intentions Classification, Multi-task","sentences":["Accurate Vehicle Trajectory Prediction is critical for automated vehicles and advanced driver assistance systems.","Vehicle trajectory prediction consists of two essential tasks, i.e., longitudinal position prediction and lateral position prediction.","There is a significant correlation between driving intentions and vehicle motion.","In existing work, the three tasks are often conducted separately without considering the relationships between the longitudinal position, lateral position, and driving intention.","In this paper, we propose a novel Temporal Multi-Gate Mixture-of-Experts (TMMOE) model for simultaneously predicting the vehicle trajectory and driving intention.","The proposed model consists of three layers: a shared layer, an expert layer, and a fully connected layer.","In the model, the shared layer utilizes Temporal Convolutional Networks (TCN) to extract temporal features.","Then the expert layer is built to identify different information according to the three tasks.","Moreover, the fully connected layer is used to integrate and export prediction results.","To achieve better performance, uncertainty algorithm is used to construct the multi-task loss function.","Finally, the publicly available CitySim dataset validates the TMMOE model, demonstrating superior performance compared to the LSTM model, achieving the highest classification and regression results.","Keywords: Vehicle trajectory prediction, driving intentions Classification, Multi-task"],"url":"http://arxiv.org/abs/2308.00533v1"}
{"created":"2023-08-01 13:25:10","title":"Adaptive Bitrate Video Semantic Communication over Wireless Networks","abstract":"This paper investigates the adaptive bitrate (ABR) video semantic communication over wireless networks. In the considered model, video sensing devices must transmit video semantic information to an edge server, to facilitate ubiquitous video sensing services such as road environment monitoring at the edge server in autonomous driving scenario. However, due to the varying wireless network conditions, it is challenging to guarantee both low transmission delay and high semantic accuracy at the same time if devices continuously transmit a fixed bitrate video semantic information. To address this challenge, we develop an adaptive bitrate video semantic communication (ABRVSC) system, in which devices adaptively adjust the bitrate of video semantic information according to network conditions. Specifically, we first define the quality of experience (QoE) for video semantic communication. Subsequently, a swin transformer-based semantic codec is proposed to extract semantic information with considering the influence of QoE. Then, we propose an Actor-Critic based ABR algorithm for the semantic codec to enhance the robustness of the proposed ABRVSC scheme against network variations. Simulation results demonstrate that at low bitrates, the mean intersection over union (MIoU) of the proposed ABRVSC scheme is nearly twice that of the traditional scheme. Moreover, the proposed ABRVSC scheme, which increases the QoE in video semantic communication by 36.57%, exhibits more robustness against network variations compared to both the fixed bitrate schemes and traditional ABR schemes.","sentences":["This paper investigates the adaptive bitrate (ABR) video semantic communication over wireless networks.","In the considered model, video sensing devices must transmit video semantic information to an edge server, to facilitate ubiquitous video sensing services such as road environment monitoring at the edge server in autonomous driving scenario.","However, due to the varying wireless network conditions, it is challenging to guarantee both low transmission delay and high semantic accuracy at the same time if devices continuously transmit a fixed bitrate video semantic information.","To address this challenge, we develop an adaptive bitrate video semantic communication (ABRVSC) system, in which devices adaptively adjust the bitrate of video semantic information according to network conditions.","Specifically, we first define the quality of experience (QoE) for video semantic communication.","Subsequently, a swin transformer-based semantic codec is proposed to extract semantic information with considering the influence of QoE.","Then, we propose an Actor-Critic based ABR algorithm for the semantic codec to enhance the robustness of the proposed ABRVSC scheme against network variations.","Simulation results demonstrate that at low bitrates, the mean intersection over union (MIoU) of the proposed ABRVSC scheme is nearly twice that of the traditional scheme.","Moreover, the proposed ABRVSC scheme, which increases the QoE in video semantic communication by 36.57%, exhibits more robustness against network variations compared to both the fixed bitrate schemes and traditional ABR schemes."],"url":"http://arxiv.org/abs/2308.00531v1"}
{"created":"2023-08-01 13:15:58","title":"Variational Label-Correlation Enhancement for Congestion Prediction","abstract":"The physical design process of large-scale designs is a time-consuming task, often requiring hours to days to complete, with routing being the most critical and complex step. As the the complexity of Integrated Circuits (ICs) increases, there is an increased demand for accurate routing quality prediction. Accurate congestion prediction aids in identifying design flaws early on, thereby accelerating circuit design and conserving resources. Despite the advancements in current congestion prediction methodologies, an essential aspect that has been largely overlooked is the spatial label-correlation between different grids in congestion prediction. The spatial label-correlation is a fundamental characteristic of circuit design, where the congestion status of a grid is not isolated but inherently influenced by the conditions of its neighboring grids. In order to fully exploit the inherent spatial label-correlation between neighboring grids, we propose a novel approach, {\\ours}, i.e., VAriational Label-Correlation Enhancement for Congestion Prediction, which considers the local label-correlation in the congestion map, associating the estimated congestion value of each grid with a local label-correlation weight influenced by its surrounding grids. {\\ours} leverages variational inference techniques to estimate this weight, thereby enhancing the regression model's performance by incorporating spatial dependencies. Experiment results validate the superior effectiveness of {\\ours} on the public available \\texttt{ISPD2011} and \\texttt{DAC2012} benchmarks using the superblue circuit line.","sentences":["The physical design process of large-scale designs is a time-consuming task, often requiring hours to days to complete, with routing being the most critical and complex step.","As the the complexity of Integrated Circuits (ICs) increases, there is an increased demand for accurate routing quality prediction.","Accurate congestion prediction aids in identifying design flaws early on, thereby accelerating circuit design and conserving resources.","Despite the advancements in current congestion prediction methodologies, an essential aspect that has been largely overlooked is the spatial label-correlation between different grids in congestion prediction.","The spatial label-correlation is a fundamental characteristic of circuit design, where the congestion status of a grid is not isolated but inherently influenced by the conditions of its neighboring grids.","In order to fully exploit the inherent spatial label-correlation between neighboring grids, we propose a novel approach, {\\ours}, i.e., VAriational Label-Correlation Enhancement for Congestion Prediction, which considers the local label-correlation in the congestion map, associating the estimated congestion value of each grid with a local label-correlation weight influenced by its surrounding grids.","{\\ours} leverages variational inference techniques to estimate this weight, thereby enhancing the regression model's performance by incorporating spatial dependencies.","Experiment results validate the superior effectiveness of {\\ours} on the public available \\texttt{ISPD2011} and \\texttt{DAC2012} benchmarks using the superblue circuit line."],"url":"http://arxiv.org/abs/2308.00529v1"}
{"created":"2023-08-01 13:14:10","title":"Unimodal Intermediate Training for Multimodal Meme Sentiment Classification","abstract":"Internet Memes remain a challenging form of user-generated content for automated sentiment classification. The availability of labelled memes is a barrier to developing sentiment classifiers of multimodal memes. To address the shortage of labelled memes, we propose to supplement the training of a multimodal meme classifier with unimodal (image-only and text-only) data. In this work, we present a novel variant of supervised intermediate training that uses relatively abundant sentiment-labelled unimodal data. Our results show a statistically significant performance improvement from the incorporation of unimodal text data. Furthermore, we show that the training set of labelled memes can be reduced by 40% without reducing the performance of the downstream model.","sentences":["Internet Memes remain a challenging form of user-generated content for automated sentiment classification.","The availability of labelled memes is a barrier to developing sentiment classifiers of multimodal memes.","To address the shortage of labelled memes, we propose to supplement the training of a multimodal meme classifier with unimodal (image-only and text-only) data.","In this work, we present a novel variant of supervised intermediate training that uses relatively abundant sentiment-labelled unimodal data.","Our results show a statistically significant performance improvement from the incorporation of unimodal text data.","Furthermore, we show that the training set of labelled memes can be reduced by 40% without reducing the performance of the downstream model."],"url":"http://arxiv.org/abs/2308.00528v1"}
{"created":"2023-08-01 13:07:39","title":"Transfer-Ensemble Learning based Deep Convolutional Neural Networks for Diabetic Retinopathy Classification","abstract":"This article aims to classify diabetic retinopathy (DR) disease into five different classes using an ensemble approach based on two popular pre-trained convolutional neural networks: VGG16 and Inception V3. The proposed model aims to leverage the strengths of the two individual nets to enhance the classification performance for diabetic retinopathy. The ensemble model architecture involves freezing a portion of the layers in each pre-trained model to utilize their learned representations effectively. Global average pooling layers are added to transform the output feature maps into fixed-length vectors. These vectors are then concatenated to form a consolidated representation of the input image. The ensemble model is trained using a dataset of diabetic retinopathy images (APTOS), divided into training and validation sets. During the training process, the model learns to classify the retinal images into the corresponding diabetic retinopathy classes. Experimental results on the test set demonstrate the efficacy of the proposed ensemble model for DR classification achieving an accuracy of 96.4%.","sentences":["This article aims to classify diabetic retinopathy (DR) disease into five different classes using an ensemble approach based on two popular pre-trained convolutional neural networks: VGG16 and Inception V3.","The proposed model aims to leverage the strengths of the two individual nets to enhance the classification performance for diabetic retinopathy.","The ensemble model architecture involves freezing a portion of the layers in each pre-trained model to utilize their learned representations effectively.","Global average pooling layers are added to transform the output feature maps into fixed-length vectors.","These vectors are then concatenated to form a consolidated representation of the input image.","The ensemble model is trained using a dataset of diabetic retinopathy images (APTOS), divided into training and validation sets.","During the training process, the model learns to classify the retinal images into the corresponding diabetic retinopathy classes.","Experimental results on the test set demonstrate the efficacy of the proposed ensemble model for DR classification achieving an accuracy of 96.4%."],"url":"http://arxiv.org/abs/2308.00525v1"}
{"created":"2023-08-01 12:59:36","title":"SurveyLM: A platform to explore emerging value perspectives in augmented language models' behaviors","abstract":"This white paper presents our work on SurveyLM, a platform for analyzing augmented language models' (ALMs) emergent alignment behaviors through their dynamically evolving attitude and value perspectives in complex social contexts. Social Artificial Intelligence (AI) systems, like ALMs, often function within nuanced social scenarios where there is no singular correct response, or where an answer is heavily dependent on contextual factors, thus necessitating an in-depth understanding of their alignment dynamics. To address this, we apply survey and experimental methodologies, traditionally used in studying social behaviors, to evaluate ALMs systematically, thus providing unprecedented insights into their alignment and emergent behaviors. Moreover, the SurveyLM platform leverages the ALMs' own feedback to enhance survey and experiment designs, exploiting an underutilized aspect of ALMs, which accelerates the development and testing of high-quality survey frameworks while conserving resources. Through SurveyLM, we aim to shed light on factors influencing ALMs' emergent behaviors, facilitate their alignment with human intentions and expectations, and thereby contributed to the responsible development and deployment of advanced social AI systems. This white paper underscores the platform's potential to deliver robust results, highlighting its significance to alignment research and its implications for future social AI systems.","sentences":["This white paper presents our work on SurveyLM, a platform for analyzing augmented language models' (ALMs) emergent alignment behaviors through their dynamically evolving attitude and value perspectives in complex social contexts.","Social Artificial Intelligence (AI) systems, like ALMs, often function within nuanced social scenarios where there is no singular correct response, or where an answer is heavily dependent on contextual factors, thus necessitating an in-depth understanding of their alignment dynamics.","To address this, we apply survey and experimental methodologies, traditionally used in studying social behaviors, to evaluate ALMs systematically, thus providing unprecedented insights into their alignment and emergent behaviors.","Moreover, the SurveyLM platform leverages the ALMs' own feedback to enhance survey and experiment designs, exploiting an underutilized aspect of ALMs, which accelerates the development and testing of high-quality survey frameworks while conserving resources.","Through SurveyLM, we aim to shed light on factors influencing ALMs' emergent behaviors, facilitate their alignment with human intentions and expectations, and thereby contributed to the responsible development and deployment of advanced social AI systems.","This white paper underscores the platform's potential to deliver robust results, highlighting its significance to alignment research and its implications for future social AI systems."],"url":"http://arxiv.org/abs/2308.00521v1"}
{"created":"2023-08-01 12:59:33","title":"NormKD: Normalized Logits for Knowledge Distillation","abstract":"Logit based knowledge distillation gets less attention in recent years since feature based methods perform better in most cases. Nevertheless, we find it still has untapped potential when we re-investigate the temperature, which is a crucial hyper-parameter to soften the logit outputs. For most of the previous works, it was set as a fixed value for the entire distillation procedure. However, as the logits from different samples are distributed quite variously, it is not feasible to soften all of them to an equal degree by just a single temperature, which may make the previous work transfer the knowledge of each sample inadequately. In this paper, we restudy the hyper-parameter temperature and figure out its incapability to distill the knowledge from each sample sufficiently when it is a single value. To address this issue, we propose Normalized Knowledge Distillation (NormKD), with the purpose of customizing the temperature for each sample according to the characteristic of the sample's logit distribution. Compared to the vanilla KD, NormKD barely has extra computation or storage cost but performs significantly better on CIRAR-100 and ImageNet for image classification. Furthermore, NormKD can be easily applied to the other logit based methods and achieve better performance which can be closer to or even better than the feature based method.","sentences":["Logit based knowledge distillation gets less attention in recent years since feature based methods perform better in most cases.","Nevertheless, we find it still has untapped potential when we re-investigate the temperature, which is a crucial hyper-parameter to soften the logit outputs.","For most of the previous works, it was set as a fixed value for the entire distillation procedure.","However, as the logits from different samples are distributed quite variously, it is not feasible to soften all of them to an equal degree by just a single temperature, which may make the previous work transfer the knowledge of each sample inadequately.","In this paper, we restudy the hyper-parameter temperature and figure out its incapability to distill the knowledge from each sample sufficiently when it is a single value.","To address this issue, we propose Normalized Knowledge Distillation (NormKD), with the purpose of customizing the temperature for each sample according to the characteristic of the sample's logit distribution.","Compared to the vanilla KD, NormKD barely has extra computation or storage cost but performs significantly better on CIRAR-100 and ImageNet for image classification.","Furthermore, NormKD can be easily applied to the other logit based methods and achieve better performance which can be closer to or even better than the feature based method."],"url":"http://arxiv.org/abs/2308.00520v1"}
{"created":"2023-08-01 12:59:07","title":"Markerless human pose estimation for biomedical applications: a survey","abstract":"Markerless Human Pose Estimation (HPE) proved its potential to support decision making and assessment in many fields of application. HPE is often preferred to traditional marker-based Motion Capture systems due to the ease of setup, portability, and affordable cost of the technology. However, the exploitation of HPE in biomedical applications is still under investigation. This review aims to provide an overview of current biomedical applications of HPE. In this paper, we examine the main features of HPE approaches and discuss whether or not those features are of interest to biomedical applications. We also identify those areas where HPE is already in use and present peculiarities and trends followed by researchers and practitioners. We include here 25 approaches to HPE and more than 40 studies of HPE applied to motor development assessment, neuromuscolar rehabilitation, and gait & posture analysis. We conclude that markerless HPE offers great potential for extending diagnosis and rehabilitation outside hospitals and clinics, toward the paradigm of remote medical care.","sentences":["Markerless Human Pose Estimation (HPE) proved its potential to support decision making and assessment in many fields of application.","HPE is often preferred to traditional marker-based Motion Capture systems due to the ease of setup, portability, and affordable cost of the technology.","However, the exploitation of HPE in biomedical applications is still under investigation.","This review aims to provide an overview of current biomedical applications of HPE.","In this paper, we examine the main features of HPE approaches and discuss whether or not those features are of interest to biomedical applications.","We also identify those areas where HPE is already in use and present peculiarities and trends followed by researchers and practitioners.","We include here 25 approaches to HPE and more than 40 studies of HPE applied to motor development assessment, neuromuscolar rehabilitation, and gait & posture analysis.","We conclude that markerless HPE offers great potential for extending diagnosis and rehabilitation outside hospitals and clinics, toward the paradigm of remote medical care."],"url":"http://arxiv.org/abs/2308.00519v1"}
{"created":"2023-08-01 12:54:12","title":"Understanding URDF: A Dataset and Analysis","abstract":"As the complexity of robot systems increases, it becomes more effective to simulate them before deployment. To do this, a model of the robot's kinematics or dynamics is required, and the most commonly used format is the Unified Robot Description Format (URDF). This article presents, to our knowledge, the first dataset of URDF files from various industrial and research organizations, with metadata describing each robot, its type, manufacturer, and the source of the model. The dataset contains 322 URDF files of which 195 are unique robot models, meaning the excess URDFs are either of a robot that is multiply defined across sources or URDF variants of the same robot. We analyze the files in the dataset, where we, among other things, provide information on how they were generated, which mesh file types are most commonly used, and compare models of multiply defined robots. The intention of this article is to build a foundation of knowledge on URDF and how it is used based on publicly available URDF files. Publishing the dataset, analysis, and the scripts and tools used enables others using, researching or developing URDFs to easily access this data and use it in their own work.","sentences":["As the complexity of robot systems increases, it becomes more effective to simulate them before deployment.","To do this, a model of the robot's kinematics or dynamics is required, and the most commonly used format is the Unified Robot Description Format (URDF).","This article presents, to our knowledge, the first dataset of URDF files from various industrial and research organizations, with metadata describing each robot, its type, manufacturer, and the source of the model.","The dataset contains 322 URDF files of which 195 are unique robot models, meaning the excess URDFs are either of a robot that is multiply defined across sources or URDF variants of the same robot.","We analyze the files in the dataset, where we, among other things, provide information on how they were generated, which mesh file types are most commonly used, and compare models of multiply defined robots.","The intention of this article is to build a foundation of knowledge on URDF and how it is used based on publicly available URDF files.","Publishing the dataset, analysis, and the scripts and tools used enables others using, researching or developing URDFs to easily access this data and use it in their own work."],"url":"http://arxiv.org/abs/2308.00514v1"}
{"created":"2023-08-01 12:53:43","title":"UVIO: An UWB-Aided Visual-Inertial Odometry Framework with Bias-Compensated Anchors Initialization","abstract":"This paper introduces UVIO, a multi-sensor framework that leverages Ultra Wide Band (UWB) technology and Visual-Inertial Odometry (VIO) to provide robust and low-drift localization. In order to include range measurements in state estimation, the position of the UWB anchors must be known. This study proposes a multi-step initialization procedure to map multiple unknown anchors by an Unmanned Aerial Vehicle (UAV), in a fully autonomous fashion. To address the limitations of initializing UWB anchors via a random trajectory, this paper uses the Geometric Dilution of Precision (GDOP) as a measure of optimality in anchor position estimation, to compute a set of optimal waypoints and synthesize a trajectory that minimizes the mapping uncertainty. After the initialization is complete, the range measurements from multiple anchors, including measurement biases, are tightly integrated into the VIO system. While in range of the initialized anchors, the VIO drift in position and heading is eliminated. The effectiveness of UVIO and our initialization procedure has been validated through a series of simulations and real-world experiments.","sentences":["This paper introduces UVIO, a multi-sensor framework that leverages Ultra Wide Band (UWB) technology and Visual-Inertial Odometry (VIO) to provide robust and low-drift localization.","In order to include range measurements in state estimation, the position of the UWB anchors must be known.","This study proposes a multi-step initialization procedure to map multiple unknown anchors by an Unmanned Aerial Vehicle (UAV), in a fully autonomous fashion.","To address the limitations of initializing UWB anchors via a random trajectory, this paper uses the Geometric Dilution of Precision (GDOP) as a measure of optimality in anchor position estimation, to compute a set of optimal waypoints and synthesize a trajectory that minimizes the mapping uncertainty.","After the initialization is complete, the range measurements from multiple anchors, including measurement biases, are tightly integrated into the VIO system.","While in range of the initialized anchors, the VIO drift in position and heading is eliminated.","The effectiveness of UVIO and our initialization procedure has been validated through a series of simulations and real-world experiments."],"url":"http://arxiv.org/abs/2308.00513v1"}
{"created":"2023-08-01 12:46:58","title":"Relational Contrastive Learning for Scene Text Recognition","abstract":"Context-aware methods achieved great success in supervised scene text recognition via incorporating semantic priors from words. We argue that such prior contextual information can be interpreted as the relations of textual primitives due to the heterogeneous text and background, which can provide effective self-supervised labels for representation learning. However, textual relations are restricted to the finite size of dataset due to lexical dependencies, which causes the problem of over-fitting and compromises representation robustness. To this end, we propose to enrich the textual relations via rearrangement, hierarchy and interaction, and design a unified framework called RCLSTR: Relational Contrastive Learning for Scene Text Recognition. Based on causality, we theoretically explain that three modules suppress the bias caused by the contextual prior and thus guarantee representation robustness. Experiments on representation quality show that our method outperforms state-of-the-art self-supervised STR methods. Code is available at https://github.com/ThunderVVV/RCLSTR.","sentences":["Context-aware methods achieved great success in supervised scene text recognition via incorporating semantic priors from words.","We argue that such prior contextual information can be interpreted as the relations of textual primitives due to the heterogeneous text and background, which can provide effective self-supervised labels for representation learning.","However, textual relations are restricted to the finite size of dataset due to lexical dependencies, which causes the problem of over-fitting and compromises representation robustness.","To this end, we propose to enrich the textual relations via rearrangement, hierarchy and interaction, and design a unified framework called RCLSTR: Relational Contrastive Learning for Scene Text Recognition.","Based on causality, we theoretically explain that three modules suppress the bias caused by the contextual prior and thus guarantee representation robustness.","Experiments on representation quality show that our method outperforms state-of-the-art self-supervised STR methods.","Code is available at https://github.com/ThunderVVV/RCLSTR."],"url":"http://arxiv.org/abs/2308.00508v1"}
{"created":"2023-08-01 12:45:55","title":"Trade-offs Between Weak-Noise Performance and Probability of Anomaly in Parameter Estimation from Noisy Chaotic Signals","abstract":"We consider the problem of parameter estimation, based on noisy chaotic signals, from the viewpoint of twisted modulation for waveform communication. In particular, we study communication systems where the parameter to be estimated is conveyed as the initial condition of a chaotic dynamical system of a certain class and we examine its estimation performance in terms of the expectation of a given convex function of the estimation error at high SNR, under the demand that the probability of anomaly is kept small. We derive a lower bound on the weak-noise estimation error for this class of chaotic modulators, and argue that it can be outperformed by using the itinerary signal associated with the chaotic system instead of the main chaotic output signal.","sentences":["We consider the problem of parameter estimation, based on noisy chaotic signals, from the viewpoint of twisted modulation for waveform communication.","In particular, we study communication systems where the parameter to be estimated is conveyed as the initial condition of a chaotic dynamical system of a certain class and we examine its estimation performance in terms of the expectation of a given convex function of the estimation error at high SNR, under the demand that the probability of anomaly is kept small.","We derive a lower bound on the weak-noise estimation error for this class of chaotic modulators, and argue that it can be outperformed by using the itinerary signal associated with the chaotic system instead of the main chaotic output signal."],"url":"http://arxiv.org/abs/2308.00506v1"}
{"created":"2023-08-01 12:39:42","title":"Explainable Graph Spectral Clustering of Text Documents","abstract":"Spectral clustering methods are known for their ability to represent clusters of diverse shapes, densities etc. However, results of such algorithms, when applied e.g. to text documents, are hard to explain to the user, especially due to embedding in the spectral space which has no obvious relation to document contents. Therefore there is an urgent need to elaborate methods for explaining the outcome of the clustering. This paper presents a contribution towards this goal. We present a proposal of explanation of results of combinatorial Laplacian based graph spectral clustering. It is based on showing (approximate) equivalence of combinatorial Laplacian embedding, $K$-embedding (proposed in this paper) and term vector space embedding. Hence a bridge is constructed between the textual contents and the clustering results. We provide theoretical background for this approach. We performed experimental study showing that $K$-embedding approximates well Laplacian embedding under favourable block matrix conditions and show that approximation is good enough under other conditions.","sentences":["Spectral clustering methods are known for their ability to represent clusters of diverse shapes, densities etc.","However, results of such algorithms, when applied e.g. to text documents, are hard to explain to the user, especially due to embedding in the spectral space which has no obvious relation to document contents.","Therefore there is an urgent need to elaborate methods for explaining the outcome of the clustering.","This paper presents a contribution towards this goal.","We present a proposal of explanation of results of combinatorial Laplacian based graph spectral clustering.","It is based on showing (approximate) equivalence of combinatorial Laplacian embedding, $K$-embedding (proposed in this paper) and term vector space embedding.","Hence a bridge is constructed between the textual contents and the clustering results.","We provide theoretical background for this approach.","We performed experimental study showing that $K$-embedding approximates well Laplacian embedding under favourable block matrix conditions and show that approximation is good enough under other conditions."],"url":"http://arxiv.org/abs/2308.00504v1"}
{"created":"2023-08-01 12:36:58","title":"Massively Parallel Algorithms for High-Dimensional Euclidean Minimum Spanning Tree","abstract":"We study the classic Euclidean Minimum Spanning Tree (MST) problem in the Massively Parallel Computation (MPC) model. Given a set $X \\subset \\mathbb{R}^d$ of $n$ points, the goal is to produce a spanning tree for $X$ with weight within a small factor of optimal. Euclidean MST is one of the most fundamental hierarchical geometric clustering algorithms, and with the proliferation of enormous high-dimensional data sets, such as massive transformer-based embeddings, there is now a critical demand for efficient distributed algorithms to cluster such data sets.   In low-dimensional space, where $d = O(1)$, Andoni, Nikolov, Onak, and Yaroslavtsev [STOC '14] gave a constant round MPC algorithm that obtains a high accuracy $(1+\\epsilon)$-approximate solution. However, the situation is much more challenging for high-dimensional spaces: the best-known algorithm to obtain a constant approximation requires $O(\\log n)$ rounds. Recently Chen, Jayaram, Levi, and Waingarten [STOC '22] gave a $\\tilde{O}(\\log n)$ approximation algorithm in a constant number of rounds based on embeddings into tree metrics. However, to date, no known algorithm achieves both a constant number of rounds and approximation.   In this paper, we make strong progress on this front by giving a constant factor approximation in $\\tilde{O}(\\log \\log n)$ rounds of the MPC model. In contrast to tree-embedding-based approaches, which necessarily must pay $\\Omega(\\log n)$-distortion, our algorithm is based on a new combination of graph-based distributed MST algorithms and geometric space partitions. Additionally, although the approximate MST we return can have a large depth, we show that it can be modified to obtain a $\\tilde{O}(\\log \\log n)$-round constant factor approximation to the Euclidean Traveling Salesman Problem (TSP) in the MPC model. Previously, only a $O(\\log n)$ round was known for the problem.","sentences":["We study the classic Euclidean Minimum Spanning Tree (MST) problem in the Massively Parallel Computation (MPC) model.","Given a set $X \\subset \\mathbb{R}^d$ of $n$ points, the goal is to produce a spanning tree for $X$ with weight within a small factor of optimal.","Euclidean MST is one of the most fundamental hierarchical geometric clustering algorithms, and with the proliferation of enormous high-dimensional data sets, such as massive transformer-based embeddings, there is now a critical demand for efficient distributed algorithms to cluster such data sets.   ","In low-dimensional space, where $d = O(1)$, Andoni, Nikolov, Onak, and Yaroslavtsev","[STOC '14] gave a constant round MPC algorithm that obtains a high accuracy $(1+\\epsilon)$-approximate solution.","However, the situation is much more challenging for high-dimensional spaces: the best-known algorithm to obtain a constant approximation requires $O(\\log n)$ rounds.","Recently Chen, Jayaram, Levi, and Waingarten [STOC '22] gave a $\\tilde{O}(\\log n)$ approximation algorithm in a constant number of rounds based on embeddings into tree metrics.","However, to date, no known algorithm achieves both a constant number of rounds and approximation.   ","In this paper, we make strong progress on this front by giving a constant factor approximation in $\\tilde{O}(\\log \\log n)$ rounds of the MPC model.","In contrast to tree-embedding-based approaches, which necessarily must pay $\\Omega(\\log n)$-distortion, our algorithm is based on a new combination of graph-based distributed MST algorithms and geometric space partitions.","Additionally, although the approximate MST we return can have a large depth, we show that it can be modified to obtain a $\\tilde{O}(\\log \\log n)$-round constant factor approximation to the Euclidean Traveling Salesman Problem (TSP) in the MPC model.","Previously, only a $O(\\log n)$ round was known for the problem."],"url":"http://arxiv.org/abs/2308.00503v1"}
{"created":"2023-08-01 12:35:20","title":"Structural Parameterizations of the Biclique-Free Vertex Deletion Problem","abstract":"In this work, we study the Biclique-Free Vertex Deletion problem: Given a graph $G$ and integers $k$ and $i \\le j$, find a set of at most $k$ vertices that intersects every (not necessarily induced) biclique $K_{i, j}$ in $G$. This is a natural generalization of the Bounded-Degree Deletion problem, wherein one asks whether there is a set of at most $k$ vertices whose deletion results in a graph of a given maximum degree $r$. The two problems coincide when $i = 1$ and $j = r + 1$. We show that Biclique-Free Vertex Deletion is fixed-parameter tractable with respect to $k + d$ for the degeneracy $d$ by developing a $2^{O(d k^2)} \\cdot n^{O(1)}$-time algorithm. We also show that it can be solved in $2^{O(f k)} \\cdot n^{O(1)}$ time for the feedback vertex number $f$ when $i \\ge 2$. In contrast, we find that it is W[1]-hard for the treedepth for any integer $i \\ge 1$. Finally, we show that Biclique-Free Vertex Deletion has a polynomial kernel for every $i \\ge 1$ when parameterized by the feedback edge number. Previously, for this parameter, its fixed-parameter tractability for $i = 1$ was known [Betzler et al., DAM '12] but the existence of polynomial kernel was open.","sentences":["In this work, we study the Biclique-Free Vertex Deletion problem: Given a graph $G$ and integers $k$ and $i \\le j$, find a set of at most $k$ vertices that intersects every (not necessarily induced) biclique $K_{i, j}$ in $G$.","This is a natural generalization of the Bounded-Degree Deletion problem, wherein one asks whether there is a set of at most $k$ vertices whose deletion results in a graph of a given maximum degree $r$. The two problems coincide when $i = 1$ and $j = r + 1$.","We show that Biclique-Free Vertex Deletion is fixed-parameter tractable with respect to $k + d$ for the degeneracy $d$ by developing a $2^{O(d k^2)}","\\cdot n^{O(1)}$-time algorithm.","We also show that it can be solved in $2^{O(f k)}","\\cdot n^{O(1)}$ time for the feedback vertex number $f$ when $i \\ge 2$.","In contrast, we find that it is W[1]-hard for the treedepth for any integer","$i \\ge 1$.","Finally, we show that Biclique-Free Vertex Deletion has a polynomial kernel for every $i \\ge 1$ when parameterized by the feedback edge number.","Previously, for this parameter, its fixed-parameter tractability for $i = 1$ was known","[Betzler et al., DAM '12] but the existence of polynomial kernel was open."],"url":"http://arxiv.org/abs/2308.00501v1"}
{"created":"2023-08-01 12:35:06","title":"Stochastic Geometry Based Modeling and Analysis on Network NOMA in Downlink CoMP Systems","abstract":"This paper investigates the performance of network non-orthogonal multiple access (N-NOMA) in a downlink coordinated multi-point (CoMP) system. In the considered N-NOMA scheme, multiple base stations (BSs) cooperatively serve a CoMP user, meanwhile, each BS serves additional NOMA users by occupying the same resource block allocated to the CoMP user. The locations of the BSs and users are modeled by stochastic geometric models and the interference from the whole network is considered. Through rigorous derivations, the outage probabilities achieved by the CoMP and NOMA users are obtained, respectively. Numerical results are provided to verify the accuracy of the analytical results and also demonstrate the superior performance of N-NOMA compared to orthogonal multiple access (OMA) based CoMP scheme.","sentences":["This paper investigates the performance of network non-orthogonal multiple access (N-NOMA) in a downlink coordinated multi-point (CoMP) system.","In the considered N-NOMA scheme, multiple base stations (BSs) cooperatively serve a CoMP user, meanwhile, each BS serves additional NOMA users by occupying the same resource block allocated to the CoMP user.","The locations of the BSs and users are modeled by stochastic geometric models and the interference from the whole network is considered.","Through rigorous derivations, the outage probabilities achieved by the CoMP and NOMA users are obtained, respectively.","Numerical results are provided to verify the accuracy of the analytical results and also demonstrate the superior performance of N-NOMA compared to orthogonal multiple access (OMA) based CoMP scheme."],"url":"http://arxiv.org/abs/2308.00499v1"}
{"created":"2023-08-01 12:32:26","title":"Leveraging MLIR for Loop Vectorization and GPU Porting of FFT Libraries","abstract":"FFTc is a Domain-Specific Language (DSL) for designing and generating Fast Fourier Transforms (FFT) libraries. The FFTc uniqueness is that it leverages and extend Multi-Level Intermediate Representation (MLIR) dialects to optimize FFT code generation. In this work, we present FFTc extensions and improvements such as the possibility of using different data layout for complex-value arrays, and sparsification to enable efficient vectorization, and a seamless porting of FFT libraries to GPU systems. We show that, on CPUs, thanks to vectorization, the performance of the FFTc-generated FFT is comparable to performance of FFTW, a state-of-the-art FFT libraries. We also present the initial performance results for FFTc on Nvidia GPUs.","sentences":["FFTc is a Domain-Specific Language (DSL) for designing and generating Fast Fourier Transforms (FFT) libraries.","The FFTc uniqueness is that it leverages and extend Multi-Level Intermediate Representation (MLIR) dialects to optimize FFT code generation.","In this work, we present FFTc extensions and improvements such as the possibility of using different data layout for complex-value arrays, and sparsification to enable efficient vectorization, and a seamless porting of FFT libraries to GPU systems.","We show that, on CPUs, thanks to vectorization, the performance of the FFTc-generated FFT is comparable to performance of FFTW, a state-of-the-art FFT libraries.","We also present the initial performance results for FFTc on Nvidia GPUs."],"url":"http://arxiv.org/abs/2308.00497v1"}
{"created":"2023-08-01 12:07:08","title":"On the Effects of Regional Spelling Conventions in Retrieval Models","abstract":"One advantage of neural ranking models is that they are meant to generalise well in situations of synonymity i.e. where two words have similar or identical meanings. In this paper, we investigate and quantify how well various ranking models perform in a clear-cut case of synonymity: when words are simply expressed in different surface forms due to regional differences in spelling conventions (e.g., color vs colour). We first explore the prevalence of American and British English spelling conventions in datasets used for the pre-training, training and evaluation of neural retrieval methods, and find that American spelling conventions are far more prevalent. Despite these biases in the training data, we find that retrieval models often generalise well in this case of synonymity. We explore the effect of document spelling normalisation in retrieval and observe that all models are affected by normalising the document's spelling. While they all experience a drop in performance when normalised to a different spelling convention than that of the query, we observe varied behaviour when the document is normalised to share the query spelling convention: lexical models show improvements, dense retrievers remain unaffected, and re-rankers exhibit contradictory behaviour.","sentences":["One advantage of neural ranking models is that they are meant to generalise well in situations of synonymity i.e. where two words have similar or identical meanings.","In this paper, we investigate and quantify how well various ranking models perform in a clear-cut case of synonymity: when words are simply expressed in different surface forms due to regional differences in spelling conventions (e.g., color vs colour).","We first explore the prevalence of American and British English spelling conventions in datasets used for the pre-training, training and evaluation of neural retrieval methods, and find that American spelling conventions are far more prevalent.","Despite these biases in the training data, we find that retrieval models often generalise well in this case of synonymity.","We explore the effect of document spelling normalisation in retrieval and observe that all models are affected by normalising the document's spelling.","While they all experience a drop in performance when normalised to a different spelling convention than that of the query, we observe varied behaviour when the document is normalised to share the query spelling convention: lexical models show improvements, dense retrievers remain unaffected, and re-rankers exhibit contradictory behaviour."],"url":"http://arxiv.org/abs/2308.00480v1"}
{"created":"2023-08-01 12:07:08","title":"EdgeMatrix: A Resource-Redefined Scheduling Framework for SLA-Guaranteed Multi-Tier Edge-Cloud Computing Systems","abstract":"With the development of networking technology, the computing system has evolved towards the multi-tier paradigm gradually. However, challenges, such as multi-resource heterogeneity of devices, resource competition of services, and networked system dynamics, make it difficult to guarantee service-level agreement (SLA) for the applications. In this paper, we propose a multi-tier edge-cloud computing framework, EdgeMatrix, to maximize the throughput of the system while guaranteeing different SLA priorities. First, in order to reduce the impact of physical resource heterogeneity, EdgeMatrix introduces the Networked Multi-agent Actor-Critic (NMAC) algorithm to re-define physical resources with the same quality of service as logically isolated resource units and combinations, i.e., cells and channels. In addition, a multi-task mechanism is designed in EdgeMatrix to solve the problem of Joint Service Orchestration and Request Dispatch (JSORD) for matching the requests and services, which can significantly reduce the optimization runtime. For integrating above two algorithms, EdgeMatrix is designed with two time-scales, i.e., coordinating services and resources at the larger time-scale, and dispatching requests at the smaller time-scale. Realistic trace-based experiments proves that the overall throughput of EdgeMatrix is 36.7% better than that of the closest baseline, while the SLA priorities are guaranteed still.","sentences":["With the development of networking technology, the computing system has evolved towards the multi-tier paradigm gradually.","However, challenges, such as multi-resource heterogeneity of devices, resource competition of services, and networked system dynamics, make it difficult to guarantee service-level agreement (SLA) for the applications.","In this paper, we propose a multi-tier edge-cloud computing framework, EdgeMatrix, to maximize the throughput of the system while guaranteeing different SLA priorities.","First, in order to reduce the impact of physical resource heterogeneity, EdgeMatrix introduces the Networked Multi-agent Actor-Critic (NMAC) algorithm to re-define physical resources with the same quality of service as logically isolated resource units and combinations, i.e., cells and channels.","In addition, a multi-task mechanism is designed in EdgeMatrix to solve the problem of Joint Service Orchestration and Request Dispatch (JSORD) for matching the requests and services, which can significantly reduce the optimization runtime.","For integrating above two algorithms, EdgeMatrix is designed with two time-scales, i.e., coordinating services and resources at the larger time-scale, and dispatching requests at the smaller time-scale.","Realistic trace-based experiments proves that the overall throughput of EdgeMatrix is 36.7% better than that of the closest baseline, while the SLA priorities are guaranteed still."],"url":"http://arxiv.org/abs/2308.00481v1"}
{"created":"2023-08-01 12:04:50","title":"Retrieval Augmented Generation and Representative Vector Summarization for large unstructured textual data in Medical Education","abstract":"Large Language Models are increasingly being used for various tasks including content generation and as chatbots. Despite their impressive performances in general tasks, LLMs need to be aligned when applying for domain specific tasks to mitigate the problems of hallucination and producing harmful answers. Retrieval Augmented Generation (RAG) allows to easily attach and manipulate a non-parametric knowledgebases to LLMs. Applications of RAG in the field of medical education are discussed in this paper. A combined extractive and abstractive summarization method for large unstructured textual data using representative vectors is proposed.","sentences":["Large Language Models are increasingly being used for various tasks including content generation and as chatbots.","Despite their impressive performances in general tasks, LLMs need to be aligned when applying for domain specific tasks to mitigate the problems of hallucination and producing harmful answers.","Retrieval Augmented Generation (RAG) allows to easily attach and manipulate a non-parametric knowledgebases to LLMs.","Applications of RAG in the field of medical education are discussed in this paper.","A combined extractive and abstractive summarization method for large unstructured textual data using representative vectors is proposed."],"url":"http://arxiv.org/abs/2308.00479v1"}
{"created":"2023-08-01 12:02:17","title":"A many-sorted epistemic logic for chromatic hypergraphs","abstract":"We propose a many-sorted modal logic for reasoning about knowledge in multi-agent systems. Our logic introduces a clear distinction between participating agents and the environment. This allows to express local properties of agents and global properties of worlds in a uniform way, as well as to talk about the presence or absence of agents in a world. The logic subsumes the standard epistemic logic and is a conservative extension of it. The semantics is given in chromatic hypergraphs, a generalization of chromatic simplicial complexes, which were recently used to model knowledge in distributed systems. We show that the logic is sound and complete with respect to the intended semantics. We also show a further connection of chromatic hypergraphs with neighborhood frames.","sentences":["We propose a many-sorted modal logic for reasoning about knowledge in multi-agent systems.","Our logic introduces a clear distinction between participating agents and the environment.","This allows to express local properties of agents and global properties of worlds in a uniform way, as well as to talk about the presence or absence of agents in a world.","The logic subsumes the standard epistemic logic and is a conservative extension of it.","The semantics is given in chromatic hypergraphs, a generalization of chromatic simplicial complexes, which were recently used to model knowledge in distributed systems.","We show that the logic is sound and complete with respect to the intended semantics.","We also show a further connection of chromatic hypergraphs with neighborhood frames."],"url":"http://arxiv.org/abs/2308.00477v1"}
{"created":"2023-08-01 11:55:52","title":"Simulating the Geometric Growth of the Marine Sponge Crella Incrustans","abstract":"Simulating marine sponge growth helps marine biologists analyze, measure, and predict the effects that the marine environment has on marine sponges, and vice versa. This paper describes a way to simulate and grow geometric models of the marine sponge Crella incrustans while considering environmental factors including fluid flow and nutrients. The simulation improves upon prior work by changing the skeletal architecture of the sponge in the growth model to better suit the structure of Crella incrustans. The change in skeletal architecture and other simulation parameters are then evaluated qualitatively against photos of a real-life Crella incrustans sponge. The results support the hypothesis that changing the skeletal architecture from radiate accretive to Halichondrid produces a sponge model which is closer in resemblance to Crella incrustans than the prior work.","sentences":["Simulating marine sponge growth helps marine biologists analyze, measure, and predict the effects that the marine environment has on marine sponges, and vice versa.","This paper describes a way to simulate and grow geometric models of the marine sponge Crella incrustans while considering environmental factors including fluid flow and nutrients.","The simulation improves upon prior work by changing the skeletal architecture of the sponge in the growth model to better suit the structure of Crella incrustans.","The change in skeletal architecture and other simulation parameters are then evaluated qualitatively against photos of a real-life Crella incrustans sponge.","The results support the hypothesis that changing the skeletal architecture from radiate accretive to Halichondrid produces a sponge model which is closer in resemblance to Crella incrustans than the prior work."],"url":"http://arxiv.org/abs/2308.00474v1"}
