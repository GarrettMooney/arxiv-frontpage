{"created":"2023-08-07 17:59:59","title":"3D Motion Magnification: Visualizing Subtle Motions with Time Varying Radiance Fields","abstract":"Motion magnification helps us visualize subtle, imperceptible motion. However, prior methods only work for 2D videos captured with a fixed camera. We present a 3D motion magnification method that can magnify subtle motions from scenes captured by a moving camera, while supporting novel view rendering. We represent the scene with time-varying radiance fields and leverage the Eulerian principle for motion magnification to extract and amplify the variation of the embedding of a fixed point over time. We study and validate our proposed principle for 3D motion magnification using both implicit and tri-plane-based radiance fields as our underlying 3D scene representation. We evaluate the effectiveness of our method on both synthetic and real-world scenes captured under various camera setups.","sentences":["Motion magnification helps us visualize subtle, imperceptible motion.","However, prior methods only work for 2D videos captured with a fixed camera.","We present a 3D motion magnification method that can magnify subtle motions from scenes captured by a moving camera, while supporting novel view rendering.","We represent the scene with time-varying radiance fields and leverage the Eulerian principle for motion magnification to extract and amplify the variation of the embedding of a fixed point over time.","We study and validate our proposed principle for 3D motion magnification using both implicit and tri-plane-based radiance fields as our underlying 3D scene representation.","We evaluate the effectiveness of our method on both synthetic and real-world scenes captured under various camera setups."],"url":"http://arxiv.org/abs/2308.03757v1"}
{"created":"2023-08-07 17:59:48","title":"FSD V2: Improving Fully Sparse 3D Object Detection with Virtual Voxels","abstract":"LiDAR-based fully sparse architecture has garnered increasing attention. FSDv1 stands out as a representative work, achieving impressive efficacy and efficiency, albeit with intricate structures and handcrafted designs. In this paper, we present FSDv2, an evolution that aims to simplify the previous FSDv1 while eliminating the inductive bias introduced by its handcrafted instance-level representation, thus promoting better general applicability. To this end, we introduce the concept of \\textbf{virtual voxels}, which takes over the clustering-based instance segmentation in FSDv1. Virtual voxels not only address the notorious issue of the Center Feature Missing problem in fully sparse detectors but also endow the framework with a more elegant and streamlined approach. Consequently, we develop a suite of components to complement the virtual voxel concept, including a virtual voxel encoder, a virtual voxel mixer, and a virtual voxel assignment strategy. Through empirical validation, we demonstrate that the virtual voxel mechanism is functionally similar to the handcrafted clustering in FSDv1 while being more general. We conduct experiments on three large-scale datasets: Waymo Open Dataset, Argoverse 2 dataset, and nuScenes dataset. Our results showcase state-of-the-art performance on all three datasets, highlighting the superiority of FSDv2 in long-range scenarios and its general applicability to achieve competitive performance across diverse scenarios. Moreover, we provide comprehensive experimental analysis to elucidate the workings of FSDv2. To foster reproducibility and further research, we have open-sourced FSDv2 at https://github.com/tusen-ai/SST.","sentences":["LiDAR-based fully sparse architecture has garnered increasing attention.","FSDv1 stands out as a representative work, achieving impressive efficacy and efficiency, albeit with intricate structures and handcrafted designs.","In this paper, we present FSDv2, an evolution that aims to simplify the previous FSDv1 while eliminating the inductive bias introduced by its handcrafted instance-level representation, thus promoting better general applicability.","To this end, we introduce the concept of \\textbf{virtual voxels}, which takes over the clustering-based instance segmentation in FSDv1.","Virtual voxels not only address the notorious issue of the Center Feature Missing problem in fully sparse detectors but also endow the framework with a more elegant and streamlined approach.","Consequently, we develop a suite of components to complement the virtual voxel concept, including a virtual voxel encoder, a virtual voxel mixer, and a virtual voxel assignment strategy.","Through empirical validation, we demonstrate that the virtual voxel mechanism is functionally similar to the handcrafted clustering in FSDv1 while being more general.","We conduct experiments on three large-scale datasets: Waymo Open Dataset, Argoverse 2 dataset, and nuScenes dataset.","Our results showcase state-of-the-art performance on all three datasets, highlighting the superiority of FSDv2 in long-range scenarios and its general applicability to achieve competitive performance across diverse scenarios.","Moreover, we provide comprehensive experimental analysis to elucidate the workings of FSDv2.","To foster reproducibility and further research, we have open-sourced FSDv2 at https://github.com/tusen-ai/SST."],"url":"http://arxiv.org/abs/2308.03755v1"}
{"created":"2023-08-07 17:53:21","title":"Mask Frozen-DETR: High Quality Instance Segmentation with One GPU","abstract":"In this paper, we aim to study how to build a strong instance segmenter with minimal training time and GPUs, as opposed to the majority of current approaches that pursue more accurate instance segmenter by building more advanced frameworks at the cost of longer training time and higher GPU requirements. To achieve this, we introduce a simple and general framework, termed Mask Frozen-DETR, which can convert any existing DETR-based object detection model into a powerful instance segmentation model. Our method only requires training an additional lightweight mask network that predicts instance masks within the bounding boxes given by a frozen DETR-based object detector. Remarkably, our method outperforms the state-of-the-art instance segmentation method Mask DINO in terms of performance on the COCO test-dev split (55.3% vs. 54.7%) while being over 10X times faster to train. Furthermore, all of our experiments can be trained using only one Tesla V100 GPU with 16 GB of memory, demonstrating the significant efficiency of our proposed framework.","sentences":["In this paper, we aim to study how to build a strong instance segmenter with minimal training time and GPUs, as opposed to the majority of current approaches that pursue more accurate instance segmenter by building more advanced frameworks at the cost of longer training time and higher GPU requirements.","To achieve this, we introduce a simple and general framework, termed Mask Frozen-DETR, which can convert any existing DETR-based object detection model into a powerful instance segmentation model.","Our method only requires training an additional lightweight mask network that predicts instance masks within the bounding boxes given by a frozen DETR-based object detector.","Remarkably, our method outperforms the state-of-the-art instance segmentation method Mask DINO in terms of performance on the COCO test-dev split (55.3% vs. 54.7%) while being over 10X times faster to train.","Furthermore, all of our experiments can be trained using only one Tesla V100 GPU with 16 GB of memory, demonstrating the significant efficiency of our proposed framework."],"url":"http://arxiv.org/abs/2308.03747v1"}
{"created":"2023-08-07 17:46:49","title":"What about translation? New coding system for content analysis on the perception of literary translation around the political transformation in 1989 in Hungary as a classification problem on an unbalanced dataset","abstract":"To track trends in the perception of literary translation around the political transformation in 1989 in Hungary, a coding system was developed on the paragraphs of the 1980-1999 issues of the literary journal Alf\\\"old. This paper describes how we trained BERT models to carry over the coding system to the 1980-1999 issues of the literary journal Nagyvil\\'ag. We use extensive hyperparameter tuning, loss functions robust to label unbalance, 10-fold cross-validation for precise evaluations and a model ensemble for prediction, manual validation on the predict set, a new calibration method to better predict label counts for sections of the Nagyvil\\'ag corpus, and to study the relations between labels, we construct label relation networks.","sentences":["To track trends in the perception of literary translation around the political transformation in 1989 in Hungary, a coding system was developed on the paragraphs of the 1980-1999 issues of the literary journal Alf\\\"old.","This paper describes how we trained BERT models to carry over the coding system to the 1980-1999 issues of the literary journal Nagyvil\\'ag.","We use extensive hyperparameter tuning, loss functions robust to label unbalance, 10-fold cross-validation for precise evaluations and a model ensemble for prediction, manual validation on the predict set, a new calibration method to better predict label counts for sections of the Nagyvil\\'ag corpus, and to study the relations between labels, we construct label relation networks."],"url":"http://arxiv.org/abs/2308.03742v1"}
{"created":"2023-08-07 17:38:41","title":"A Cost Analysis of Generative Language Models and Influence Operations","abstract":"Despite speculation that recent large language models (LLMs) are likely to be used maliciously to improve the quality or scale of influence operations, uncertainty persists regarding the economic value that LLMs offer propagandists. This research constructs a model of costs facing propagandists for content generation at scale and analyzes (1) the potential savings that LLMs could offer propagandists, (2) the potential deterrent effect of monitoring controls on API-accessible LLMs, and (3) the optimal strategy for propagandists choosing between multiple private and/or open source LLMs when conducting influence operations. Primary results suggest that LLMs need only produce usable outputs with relatively low reliability (roughly 25%) to offer cost savings to propagandists, that the potential reduction in content generation costs can be quite high (up to 70% for a highly reliable model), and that monitoring capabilities have sharply limited cost imposition effects when alternative open source models are available. In addition, these results suggest that nation-states -- even those conducting many large-scale influence operations per year -- are unlikely to benefit economically from training custom LLMs specifically for use in influence operations.","sentences":["Despite speculation that recent large language models (LLMs) are likely to be used maliciously to improve the quality or scale of influence operations, uncertainty persists regarding the economic value that LLMs offer propagandists.","This research constructs a model of costs facing propagandists for content generation at scale and analyzes (1) the potential savings that LLMs could offer propagandists, (2) the potential deterrent effect of monitoring controls on API-accessible LLMs, and (3) the optimal strategy for propagandists choosing between multiple private and/or open source LLMs when conducting influence operations.","Primary results suggest that LLMs need only produce usable outputs with relatively low reliability (roughly 25%) to offer cost savings to propagandists, that the potential reduction in content generation costs can be quite high (up to 70% for a highly reliable model), and that monitoring capabilities have sharply limited cost imposition effects when alternative open source models are available.","In addition, these results suggest that nation-states -- even those conducting many large-scale influence operations per year -- are unlikely to benefit economically from training custom LLMs specifically for use in influence operations."],"url":"http://arxiv.org/abs/2308.03740v1"}
{"created":"2023-08-07 17:34:58","title":"Randomized algorithms for precise measurement of differentially-private, personalized recommendations","abstract":"Personalized recommendations form an important part of today's internet ecosystem, helping artists and creators to reach interested users, and helping users to discover new and engaging content. However, many users today are skeptical of platforms that personalize recommendations, in part due to historically careless treatment of personal data and data privacy. Now, businesses that rely on personalized recommendations are entering a new paradigm, where many of their systems must be overhauled to be privacy-first. In this article, we propose an algorithm for personalized recommendations that facilitates both precise and differentially-private measurement. We consider advertising as an example application, and conduct offline experiments to quantify how the proposed privacy-preserving algorithm affects key metrics related to user experience, advertiser value, and platform revenue compared to the extremes of both (private) non-personalized and non-private, personalized implementations.","sentences":["Personalized recommendations form an important part of today's internet ecosystem, helping artists and creators to reach interested users, and helping users to discover new and engaging content.","However, many users today are skeptical of platforms that personalize recommendations, in part due to historically careless treatment of personal data and data privacy.","Now, businesses that rely on personalized recommendations are entering a new paradigm, where many of their systems must be overhauled to be privacy-first.","In this article, we propose an algorithm for personalized recommendations that facilitates both precise and differentially-private measurement.","We consider advertising as an example application, and conduct offline experiments to quantify how the proposed privacy-preserving algorithm affects key metrics related to user experience, advertiser value, and platform revenue compared to the extremes of both (private) non-personalized and non-private, personalized implementations."],"url":"http://arxiv.org/abs/2308.03735v1"}
{"created":"2023-08-07 17:32:33","title":"Labeling without Seeing? Blind Annotation for Privacy-Preserving Entity Resolution","abstract":"The entity resolution problem requires finding pairs across datasets that belong to different owners but refer to the same entity in the real world. To train and evaluate solutions (either rule-based or machine-learning-based) to the entity resolution problem, generating a ground truth dataset with entity pairs or clusters is needed. However, such a data annotation process involves humans as domain oracles to review the plaintext data for all candidate record pairs from different parties, which inevitably infringes the privacy of data owners, especially in privacy-sensitive cases like medical records. To the best of our knowledge, there is no prior work on privacy-preserving ground truth dataset generation, especially in the domain of entity resolution. We propose a novel blind annotation protocol based on homomorphic encryption that allows domain oracles to collaboratively label ground truths without sharing data in plaintext with other parties. In addition, we design a domain-specific easy-to-use language that hides the sophisticated underlying homomorphic encryption layer. Rigorous proof of the privacy guarantee is provided and our empirical experiments via an annotation simulator indicate the feasibility of our privacy-preserving protocol (f-measure on average achieves more than 90\\% compared with the real ground truths).","sentences":["The entity resolution problem requires finding pairs across datasets that belong to different owners but refer to the same entity in the real world.","To train and evaluate solutions (either rule-based or machine-learning-based) to the entity resolution problem, generating a ground truth dataset with entity pairs or clusters is needed.","However, such a data annotation process involves humans as domain oracles to review the plaintext data for all candidate record pairs from different parties, which inevitably infringes the privacy of data owners, especially in privacy-sensitive cases like medical records.","To the best of our knowledge, there is no prior work on privacy-preserving ground truth dataset generation, especially in the domain of entity resolution.","We propose a novel blind annotation protocol based on homomorphic encryption that allows domain oracles to collaboratively label ground truths without sharing data in plaintext with other parties.","In addition, we design a domain-specific easy-to-use language that hides the sophisticated underlying homomorphic encryption layer.","Rigorous proof of the privacy guarantee is provided and our empirical experiments via an annotation simulator indicate the feasibility of our privacy-preserving protocol (f-measure on average achieves more than 90\\% compared with the real ground truths)."],"url":"http://arxiv.org/abs/2308.03734v1"}
{"created":"2023-08-07 17:18:37","title":"SurvBeX: An explanation method of the machine learning survival models based on the Beran estimator","abstract":"An explanation method called SurvBeX is proposed to interpret predictions of the machine learning survival black-box models. The main idea behind the method is to use the modified Beran estimator as the surrogate explanation model. Coefficients, incorporated into Beran estimator, can be regarded as values of the feature impacts on the black-box model prediction. Following the well-known LIME method, many points are generated in a local area around an example of interest. For every generated example, the survival function of the black-box model is computed, and the survival function of the surrogate model (the Beran estimator) is constructed as a function of the explanation coefficients. In order to find the explanation coefficients, it is proposed to minimize the mean distance between the survival functions of the black-box model and the Beran estimator produced by the generated examples. Many numerical experiments with synthetic and real survival data demonstrate the SurvBeX efficiency and compare the method with the well-known method SurvLIME. The method is also compared with the method SurvSHAP. The code implementing SurvBeX is available at: https://github.com/DanilaEremenko/SurvBeX","sentences":["An explanation method called SurvBeX is proposed to interpret predictions of the machine learning survival black-box models.","The main idea behind the method is to use the modified Beran estimator as the surrogate explanation model.","Coefficients, incorporated into Beran estimator, can be regarded as values of the feature impacts on the black-box model prediction.","Following the well-known LIME method, many points are generated in a local area around an example of interest.","For every generated example, the survival function of the black-box model is computed, and the survival function of the surrogate model (the Beran estimator) is constructed as a function of the explanation coefficients.","In order to find the explanation coefficients, it is proposed to minimize the mean distance between the survival functions of the black-box model and the Beran estimator produced by the generated examples.","Many numerical experiments with synthetic and real survival data demonstrate the SurvBeX efficiency and compare the method with the well-known method SurvLIME.","The method is also compared with the method SurvSHAP.","The code implementing SurvBeX is available at: https://github.com/DanilaEremenko/SurvBeX"],"url":"http://arxiv.org/abs/2308.03730v1"}
{"created":"2023-08-07 17:17:05","title":"Tiny LVLM-eHub: Early Multimodal Experiments with Bard","abstract":"Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated significant progress in tackling complex multimodal tasks. Among these cutting-edge developments, Google's Bard stands out for its remarkable multimodal capabilities, promoting comprehensive comprehension and reasoning across various domains. This work presents an early and holistic evaluation of LVLMs' multimodal abilities, with a particular focus on Bard, by proposing a lightweight variant of LVLM-eHub, named Tiny LVLM-eHub. In comparison to the vanilla version, Tiny LVLM-eHub possesses several appealing properties. Firstly, it provides a systematic assessment of six categories of multimodal capabilities, including visual perception, visual knowledge acquisition, visual reasoning, visual commonsense, object hallucination, and embodied intelligence, through quantitative evaluation of $42$ standard text-related visual benchmarks. Secondly, it conducts an in-depth analysis of LVLMs' predictions using the ChatGPT Ensemble Evaluation (CEE), which leads to a robust and accurate evaluation and exhibits improved alignment with human evaluation compared to the word matching approach. Thirdly, it comprises a mere $2.1$K image-text pairs, facilitating ease of use for practitioners to evaluate their own offline LVLMs. Through extensive experimental analysis, this study demonstrates that Bard outperforms previous LVLMs in most multimodal capabilities except object hallucination, to which Bard is still susceptible. Tiny LVLM-eHub serves as a baseline evaluation for various LVLMs and encourages innovative strategies aimed at advancing multimodal techniques. Our project is publicly available at \\url{https://github.com/OpenGVLab/Multi-Modality-Arena}.","sentences":["Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated significant progress in tackling complex multimodal tasks.","Among these cutting-edge developments, Google's Bard stands out for its remarkable multimodal capabilities, promoting comprehensive comprehension and reasoning across various domains.","This work presents an early and holistic evaluation of LVLMs' multimodal abilities, with a particular focus on Bard, by proposing a lightweight variant of LVLM-eHub, named Tiny LVLM-eHub.","In comparison to the vanilla version, Tiny LVLM-eHub possesses several appealing properties.","Firstly, it provides a systematic assessment of six categories of multimodal capabilities, including visual perception, visual knowledge acquisition, visual reasoning, visual commonsense, object hallucination, and embodied intelligence, through quantitative evaluation of $42$ standard text-related visual benchmarks.","Secondly, it conducts an in-depth analysis of LVLMs' predictions using the ChatGPT Ensemble Evaluation (CEE), which leads to a robust and accurate evaluation and exhibits improved alignment with human evaluation compared to the word matching approach.","Thirdly, it comprises a mere $2.1$K image-text pairs, facilitating ease of use for practitioners to evaluate their own offline LVLMs.","Through extensive experimental analysis, this study demonstrates that Bard outperforms previous LVLMs in most multimodal capabilities except object hallucination, to which Bard is still susceptible.","Tiny LVLM-eHub serves as a baseline evaluation for various LVLMs and encourages innovative strategies aimed at advancing multimodal techniques.","Our project is publicly available at \\url{https://github.com/OpenGVLab/Multi-Modality-Arena}."],"url":"http://arxiv.org/abs/2308.03729v1"}
{"created":"2023-08-07 17:12:54","title":"AdaptiveSAM: Towards Efficient Tuning of SAM for Surgical Scene Segmentation","abstract":"Segmentation is a fundamental problem in surgical scene analysis using artificial intelligence. However, the inherent data scarcity in this domain makes it challenging to adapt traditional segmentation techniques for this task. To tackle this issue, current research employs pretrained models and finetunes them on the given data. Even so, these require training deep networks with millions of parameters every time new data becomes available. A recently published foundation model, Segment-Anything (SAM), generalizes well to a large variety of natural images, hence tackling this challenge to a reasonable extent. However, SAM does not generalize well to the medical domain as is without utilizing a large amount of compute resources for fine-tuning and using task-specific prompts. Moreover, these prompts are in the form of bounding-boxes or foreground/background points that need to be annotated explicitly for every image, making this solution increasingly tedious with higher data size. In this work, we propose AdaptiveSAM - an adaptive modification of SAM that can adjust to new datasets quickly and efficiently, while enabling text-prompted segmentation. For finetuning AdaptiveSAM, we propose an approach called bias-tuning that requires a significantly smaller number of trainable parameters than SAM (less than 2\\%). At the same time, AdaptiveSAM requires negligible expert intervention since it uses free-form text as prompt and can segment the object of interest with just the label name as prompt. Our experiments show that AdaptiveSAM outperforms current state-of-the-art methods on various medical imaging datasets including surgery, ultrasound and X-ray. Code is available at https://github.com/JayParanjape/biastuning","sentences":["Segmentation is a fundamental problem in surgical scene analysis using artificial intelligence.","However, the inherent data scarcity in this domain makes it challenging to adapt traditional segmentation techniques for this task.","To tackle this issue, current research employs pretrained models and finetunes them on the given data.","Even so, these require training deep networks with millions of parameters every time new data becomes available.","A recently published foundation model, Segment-Anything (SAM), generalizes well to a large variety of natural images, hence tackling this challenge to a reasonable extent.","However, SAM does not generalize well to the medical domain as is without utilizing a large amount of compute resources for fine-tuning and using task-specific prompts.","Moreover, these prompts are in the form of bounding-boxes or foreground/background points that need to be annotated explicitly for every image, making this solution increasingly tedious with higher data size.","In this work, we propose AdaptiveSAM - an adaptive modification of SAM that can adjust to new datasets quickly and efficiently, while enabling text-prompted segmentation.","For finetuning AdaptiveSAM, we propose an approach called bias-tuning that requires a significantly smaller number of trainable parameters than SAM (less than 2\\%).","At the same time, AdaptiveSAM requires negligible expert intervention since it uses free-form text as prompt and can segment the object of interest with just the label name as prompt.","Our experiments show that AdaptiveSAM outperforms current state-of-the-art methods on various medical imaging datasets including surgery, ultrasound and X-ray.","Code is available at https://github.com/JayParanjape/biastuning"],"url":"http://arxiv.org/abs/2308.03726v1"}
{"created":"2023-08-07 17:07:48","title":"Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation","abstract":"Temporal Sentence Grounding in Videos (TSGV) aims to detect the event timestamps described by the natural language query from untrimmed videos. This paper discusses the challenge of achieving efficient computation in TSGV models while maintaining high performance. Most existing approaches exquisitely design complex architectures to improve accuracy with extra layers and loss, suffering from inefficiency and heaviness. Although some works have noticed that, they only make an issue of feature fusion layers, which can hardly enjoy the highspeed merit in the whole clunky network. To tackle this problem, we propose a novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks. Specifically, We first unify different outputs of the heterogeneous models into one single form. Next, a Knowledge Aggregation Unit (KAU) is built to acquire high-quality integrated soft labels from multiple teachers. After that, the KAU module leverages the multi-scale video and global query information to adaptively determine the weights of different teachers. A Shared Encoder strategy is then proposed to solve the problem that the student shallow layers hardly benefit from teachers, in which an isomorphic teacher is collaboratively trained with the student to align their hidden states. Extensive experimental results on three popular TSGV benchmarks demonstrate that our method is both effective and efficient without bells and whistles.","sentences":["Temporal Sentence Grounding in Videos (TSGV) aims to detect the event timestamps described by the natural language query from untrimmed videos.","This paper discusses the challenge of achieving efficient computation in TSGV models while maintaining high performance.","Most existing approaches exquisitely design complex architectures to improve accuracy with extra layers and loss, suffering from inefficiency and heaviness.","Although some works have noticed that, they only make an issue of feature fusion layers, which can hardly enjoy the highspeed merit in the whole clunky network.","To tackle this problem, we propose a novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks.","Specifically, We first unify different outputs of the heterogeneous models into one single form.","Next, a Knowledge Aggregation Unit (KAU) is built to acquire high-quality integrated soft labels from multiple teachers.","After that, the KAU module leverages the multi-scale video and global query information to adaptively determine the weights of different teachers.","A Shared Encoder strategy is then proposed to solve the problem that the student shallow layers hardly benefit from teachers, in which an isomorphic teacher is collaboratively trained with the student to align their hidden states.","Extensive experimental results on three popular TSGV benchmarks demonstrate that our method is both effective and efficient without bells and whistles."],"url":"http://arxiv.org/abs/2308.03725v1"}
{"created":"2023-08-07 16:58:48","title":"Dimensionality Reduction for Improving Out-of-Distribution Detection in Medical Image Segmentation","abstract":"Clinically deployed segmentation models are known to fail on data outside of their training distribution. As these models perform well on most cases, it is imperative to detect out-of-distribution (OOD) images at inference to protect against automation bias. This work applies the Mahalanobis distance post hoc to the bottleneck features of a Swin UNETR model that segments the liver on T1-weighted magnetic resonance imaging. By reducing the dimensions of the bottleneck features with principal component analysis, OOD images were detected with high performance and minimal computational load.","sentences":["Clinically deployed segmentation models are known to fail on data outside of their training distribution.","As these models perform well on most cases, it is imperative to detect out-of-distribution (OOD) images at inference to protect against automation bias.","This work applies the Mahalanobis distance post hoc to the bottleneck features of a Swin UNETR model that segments the liver on T1-weighted magnetic resonance imaging.","By reducing the dimensions of the bottleneck features with principal component analysis, OOD images were detected with high performance and minimal computational load."],"url":"http://arxiv.org/abs/2308.03723v1"}
{"created":"2023-08-07 16:43:46","title":"SEM-GAT: Explainable Semantic Pose Estimation using Learned Graph Attention","abstract":"This paper proposes a GNN-based method for exploiting semantics and local geometry to guide the identification of reliable pointcloud registration candidates. Semantic and morphological features of the environment serve as key reference points for registration, enabling accurate lidar-based pose estimation. Our novel lightweight static graph structure informs our attention-based keypoint node aggregation GNN network by identifying semantic instance-based relationships, acting as inductive bias to significantly reduce the computational burden of pointcloud registration. By connecting candidate nodes and exploiting cross-graph attention, we identify confidence scores for all potential registration correspondences, estimating the displacement between pointcloud scans. Our pipeline enables introspective analysis of the model's performance by correlating it with the individual contributions of local structures in the environment, providing valuable insights into the system's behaviour. We test our method on the KITTI odometry dataset, achieving competitive accuracy compared to benchmark methods and a higher track smoothness while relying on significantly fewer network parameters.","sentences":["This paper proposes a GNN-based method for exploiting semantics and local geometry to guide the identification of reliable pointcloud registration candidates.","Semantic and morphological features of the environment serve as key reference points for registration, enabling accurate lidar-based pose estimation.","Our novel lightweight static graph structure informs our attention-based keypoint node aggregation GNN network by identifying semantic instance-based relationships, acting as inductive bias to significantly reduce the computational burden of pointcloud registration.","By connecting candidate nodes and exploiting cross-graph attention, we identify confidence scores for all potential registration correspondences, estimating the displacement between pointcloud scans.","Our pipeline enables introspective analysis of the model's performance by correlating it with the individual contributions of local structures in the environment, providing valuable insights into the system's behaviour.","We test our method on the KITTI odometry dataset, achieving competitive accuracy compared to benchmark methods and a higher track smoothness while relying on significantly fewer network parameters."],"url":"http://arxiv.org/abs/2308.03718v1"}
{"created":"2023-08-07 16:40:19","title":"Automated Real Time Delineation of Supraclavicular Brachial Plexus in Neck Ultrasonography Videos: A Deep Learning Approach","abstract":"Peripheral nerve blocks are crucial to treatment of post-surgical pain and are associated with reduction in perioperative opioid use and hospital stay. Accurate interpretation of sono-anatomy is critical for the success of ultrasound (US) guided peripheral nerve blocks and can be challenging to the new operators. This prospective study enrolled 227 subjects who were systematically scanned for supraclavicular and interscalene brachial plexus in various settings using three different US machines to create a dataset of 227 unique videos. In total, 41,000 video frames were annotated by experienced anaesthesiologists using partial automation with object tracking and active contour algorithms. Four baseline neural network models were trained on the dataset and their performance was evaluated for object detection and segmentation tasks. Generalizability of the best suited model was then tested on the datasets constructed from separate US scanners with and without fine-tuning. The results demonstrate that deep learning models can be leveraged for real time segmentation of supraclavicular brachial plexus in neck ultrasonography videos with high accuracy and reliability. Model was also tested for its ability to differentiate between supraclavicular and adjoining interscalene brachial plexus. The entire dataset has been released publicly for further study by the research community.","sentences":["Peripheral nerve blocks are crucial to treatment of post-surgical pain and are associated with reduction in perioperative opioid use and hospital stay.","Accurate interpretation of sono-anatomy is critical for the success of ultrasound (US) guided peripheral nerve blocks and can be challenging to the new operators.","This prospective study enrolled 227 subjects who were systematically scanned for supraclavicular and interscalene brachial plexus in various settings using three different US machines to create a dataset of 227 unique videos.","In total, 41,000 video frames were annotated by experienced anaesthesiologists using partial automation with object tracking and active contour algorithms.","Four baseline neural network models were trained on the dataset and their performance was evaluated for object detection and segmentation tasks.","Generalizability of the best suited model was then tested on the datasets constructed from separate US scanners with and without fine-tuning.","The results demonstrate that deep learning models can be leveraged for real time segmentation of supraclavicular brachial plexus in neck ultrasonography videos with high accuracy and reliability.","Model was also tested for its ability to differentiate between supraclavicular and adjoining interscalene brachial plexus.","The entire dataset has been released publicly for further study by the research community."],"url":"http://arxiv.org/abs/2308.03717v1"}
{"created":"2023-08-07 16:32:14","title":"Communication-Efficient Framework for Distributed Image Semantic Wireless Transmission","abstract":"Multi-node communication, which refers to the interaction among multiple devices, has attracted lots of attention in many Internet-of-Things (IoT) scenarios. However, its huge amounts of data flows and inflexibility for task extension have triggered the urgent requirement of communication-efficient distributed data transmission frameworks. In this paper, inspired by the great superiorities on bandwidth reduction and task adaptation of semantic communications, we propose a federated learning-based semantic communication (FLSC) framework for multi-task distributed image transmission with IoT devices. Federated learning enables the design of independent semantic communication link of each user while further improves the semantic extraction and task performance through global aggregation. Each link in FLSC is composed of a hierarchical vision transformer (HVT)-based extractor and a task-adaptive translator for coarse-to-fine semantic extraction and meaning translation according to specific tasks. In order to extend the FLSC into more realistic conditions, we design a channel state information-based multiple-input multiple-output transmission module to combat channel fading and noise. Simulation results show that the coarse semantic information can deal with a range of image-level tasks. Moreover, especially in low signal-to-noise ratio and channel bandwidth ratio regimes, FLSC evidently outperforms the traditional scheme, e.g. about 10 peak signal-to-noise ratio gain in the 3 dB channel condition.","sentences":["Multi-node communication, which refers to the interaction among multiple devices, has attracted lots of attention in many Internet-of-Things (IoT) scenarios.","However, its huge amounts of data flows and inflexibility for task extension have triggered the urgent requirement of communication-efficient distributed data transmission frameworks.","In this paper, inspired by the great superiorities on bandwidth reduction and task adaptation of semantic communications, we propose a federated learning-based semantic communication (FLSC) framework for multi-task distributed image transmission with IoT devices.","Federated learning enables the design of independent semantic communication link of each user while further improves the semantic extraction and task performance through global aggregation.","Each link in FLSC is composed of a hierarchical vision transformer (HVT)-based extractor and a task-adaptive translator for coarse-to-fine semantic extraction and meaning translation according to specific tasks.","In order to extend the FLSC into more realistic conditions, we design a channel state information-based multiple-input multiple-output transmission module to combat channel fading and noise.","Simulation results show that the coarse semantic information can deal with a range of image-level tasks.","Moreover, especially in low signal-to-noise ratio and channel bandwidth ratio regimes, FLSC evidently outperforms the traditional scheme, e.g. about 10 peak signal-to-noise ratio gain in the 3 dB channel condition."],"url":"http://arxiv.org/abs/2308.03713v1"}
{"created":"2023-08-07 16:31:38","title":"Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience","abstract":"This paper asks whether current self-supervised learning methods, if sufficiently scaled up, would be able to reach human-level visual object recognition capabilities with the same type and amount of visual experience humans learn from. Previous work on this question only considered the scaling of data size. Here, we consider the simultaneous scaling of data size, model size, and image resolution. We perform a scaling experiment with vision transformers up to 633M parameters in size (ViT-H/14) trained with up to 5K hours of human-like video data (long, continuous, mostly egocentric videos) with image resolutions of up to 476x476 pixels. The efficiency of masked autoencoders (MAEs) as a self-supervised learning algorithm makes it possible to run this scaling experiment on an unassuming academic budget. We find that it is feasible to reach human-level object recognition capacity at sub-human scales of model size, data size, and image size, if these factors are scaled up simultaneously. To give a concrete example, we estimate that a 2.5B parameter ViT model trained with 20K hours (2.3 years) of human-like video data with a spatial resolution of 952x952 pixels should be able to reach human-level accuracy on ImageNet. Human-level competence is thus achievable for a fundamental perceptual capability from human-like perceptual experience (human-like in both amount and type) with extremely generic learning algorithms and architectures and without any substantive inductive biases.","sentences":["This paper asks whether current self-supervised learning methods, if sufficiently scaled up, would be able to reach human-level visual object recognition capabilities with the same type and amount of visual experience humans learn from.","Previous work on this question only considered the scaling of data size.","Here, we consider the simultaneous scaling of data size, model size, and image resolution.","We perform a scaling experiment with vision transformers up to 633M parameters in size (ViT-H/14) trained with up to 5K hours of human-like video data (long, continuous, mostly egocentric videos) with image resolutions of up to 476x476 pixels.","The efficiency of masked autoencoders (MAEs) as a self-supervised learning algorithm makes it possible to run this scaling experiment on an unassuming academic budget.","We find that it is feasible to reach human-level object recognition capacity at sub-human scales of model size, data size, and image size, if these factors are scaled up simultaneously.","To give a concrete example, we estimate that a 2.5B parameter ViT model trained with 20K hours (2.3 years) of human-like video data with a spatial resolution of 952x952 pixels should be able to reach human-level accuracy on ImageNet.","Human-level competence is thus achievable for a fundamental perceptual capability from human-like perceptual experience (human-like in both amount and type) with extremely generic learning algorithms and architectures and without any substantive inductive biases."],"url":"http://arxiv.org/abs/2308.03712v1"}
{"created":"2023-08-07 16:30:24","title":"Prototype Learning for Out-of-Distribution Polyp Segmentation","abstract":"Existing polyp segmentation models from colonoscopy images often fail to provide reliable segmentation results on datasets from different centers, limiting their applicability. Our objective in this study is to create a robust and well-generalized segmentation model named PrototypeLab that can assist in polyp segmentation. To achieve this, we incorporate various lighting modes such as White light imaging (WLI), Blue light imaging (BLI), Linked color imaging (LCI), and Flexible spectral imaging color enhancement (FICE) into our new segmentation model, that learns to create prototypes for each class of object present in the images. These prototypes represent the characteristic features of the objects, such as their shape, texture, color. Our model is designed to perform effectively on out-of-distribution (OOD) datasets from multiple centers. We first generate a coarse mask that is used to learn prototypes for the main object class, which are then employed to generate the final segmentation mask. By using prototypes to represent the main class, our approach handles the variability present in the medical images and generalize well to new data since prototype capture the underlying distribution of the data. PrototypeLab offers a promising solution with a dice coefficient of $\\geq$ 90\\% and mIoU $\\geq$ 85\\% with a near real-time processing speed for polyp segmentation. It achieved superior performance on OOD datasets compared to 16 state-of-the-art image segmentation architectures, potentially improving clinical outcomes. Codes are available at https://github.com/xxxxx/PrototypeLab.","sentences":["Existing polyp segmentation models from colonoscopy images often fail to provide reliable segmentation results on datasets from different centers, limiting their applicability.","Our objective in this study is to create a robust and well-generalized segmentation model named PrototypeLab that can assist in polyp segmentation.","To achieve this, we incorporate various lighting modes such as White light imaging (WLI), Blue light imaging (BLI), Linked color imaging (LCI), and Flexible spectral imaging color enhancement (FICE) into our new segmentation model, that learns to create prototypes for each class of object present in the images.","These prototypes represent the characteristic features of the objects, such as their shape, texture, color.","Our model is designed to perform effectively on out-of-distribution (OOD) datasets from multiple centers.","We first generate a coarse mask that is used to learn prototypes for the main object class, which are then employed to generate the final segmentation mask.","By using prototypes to represent the main class, our approach handles the variability present in the medical images and generalize well to new data since prototype capture the underlying distribution of the data.","PrototypeLab offers a promising solution with a dice coefficient of $\\geq$ 90\\% and mIoU $\\geq$ 85\\% with a near real-time processing speed for polyp segmentation.","It achieved superior performance on OOD datasets compared to 16 state-of-the-art image segmentation architectures, potentially improving clinical outcomes.","Codes are available at https://github.com/xxxxx/PrototypeLab."],"url":"http://arxiv.org/abs/2308.03709v1"}
{"created":"2023-08-07 16:23:04","title":"Combining Proofs for Description Logic and Concrete Domain Reasoning (Technical Report)","abstract":"Logic-based approaches to AI have the advantage that their behavior can in principle be explained with the help of proofs of the computed consequences. For ontologies based on Description Logic (DL), we have put this advantage into practice by showing how proofs for consequences derived by DL reasoners can be computed and displayed in a user-friendly way. However, these methods are insufficient in applications where also numerical reasoning is relevant. The present paper considers proofs for DLs extended with concrete domains (CDs) based on the rational numbers, which leave reasoning tractable if integrated into the lightweight DL $\\mathcal{E}\\hspace{-0.1em}\\mathcal{L}_\\bot$. Since no implemented DL reasoner supports these CDs, we first develop reasoning procedures for them, and show how they can be combined with reasoning approaches for pure DLs, both for $\\mathcal{E}\\hspace{-0.1em}\\mathcal{L}_\\bot$ and the more expressive DL $\\mathcal{ALC}$. These procedures are designed such that it is easy to extract proofs from them. We show how the extracted CD proofs can be combined with proofs on the DL side into integrated proofs that explain both the DL and the CD reasoning.","sentences":["Logic-based approaches to AI have the advantage that their behavior can in principle be explained with the help of proofs of the computed consequences.","For ontologies based on Description Logic (DL), we have put this advantage into practice by showing how proofs for consequences derived by DL reasoners can be computed and displayed in a user-friendly way.","However, these methods are insufficient in applications where also numerical reasoning is relevant.","The present paper considers proofs for DLs extended with concrete domains (CDs) based on the rational numbers, which leave reasoning tractable if integrated into the lightweight DL $\\mathcal{E}\\hspace{-0.1em}\\mathcal{L}_\\bot$. Since no implemented DL reasoner supports these CDs, we first develop reasoning procedures for them, and show how they can be combined with reasoning approaches for pure DLs, both for $\\mathcal{E}\\hspace{-0.1em}\\mathcal{L}_\\bot$ and the more expressive DL $\\mathcal{ALC}$. These procedures are designed such that it is easy to extract proofs from them.","We show how the extracted CD proofs can be combined with proofs on the DL side into integrated proofs that explain both the DL and the CD reasoning."],"url":"http://arxiv.org/abs/2308.03705v1"}
{"created":"2023-08-07 16:22:59","title":"DeRisk: An Effective Deep Learning Framework for Credit Risk Prediction over Real-World Financial Data","abstract":"Despite the tremendous advances achieved over the past years by deep learning techniques, the latest risk prediction models for industrial applications still rely on highly handtuned stage-wised statistical learning tools, such as gradient boosting and random forest methods. Different from images or languages, real-world financial data are high-dimensional, sparse, noisy and extremely imbalanced, which makes deep neural network models particularly challenging to train and fragile in practice. In this work, we propose DeRisk, an effective deep learning risk prediction framework for credit risk prediction on real-world financial data. DeRisk is the first deep risk prediction model that outperforms statistical learning approaches deployed in our company's production system. We also perform extensive ablation studies on our method to present the most critical factors for the empirical success of DeRisk.","sentences":["Despite the tremendous advances achieved over the past years by deep learning techniques, the latest risk prediction models for industrial applications still rely on highly handtuned stage-wised statistical learning tools, such as gradient boosting and random forest methods.","Different from images or languages, real-world financial data are high-dimensional, sparse, noisy and extremely imbalanced, which makes deep neural network models particularly challenging to train and fragile in practice.","In this work, we propose DeRisk, an effective deep learning risk prediction framework for credit risk prediction on real-world financial data.","DeRisk is the first deep risk prediction model that outperforms statistical learning approaches deployed in our company's production system.","We also perform extensive ablation studies on our method to present the most critical factors for the empirical success of DeRisk."],"url":"http://arxiv.org/abs/2308.03704v1"}
{"created":"2023-08-07 16:22:47","title":"Video-based Person Re-identification with Long Short-Term Representation Learning","abstract":"Video-based person Re-Identification (V-ReID) aims to retrieve specific persons from raw videos captured by non-overlapped cameras. As a fundamental task, it spreads many multimedia and computer vision applications. However, due to the variations of persons and scenes, there are still many obstacles that must be overcome for high performance. In this work, we notice that both the long-term and short-term information of persons are important for robust video representations. Thus, we propose a novel deep learning framework named Long Short-Term Representation Learning (LSTRL) for effective V-ReID. More specifically, to extract long-term representations, we propose a Multi-granularity Appearance Extractor (MAE), in which four granularity appearances are effectively captured across multiple frames. Meanwhile, to extract short-term representations, we propose a Bi-direction Motion Estimator (BME), in which reciprocal motion information is efficiently extracted from consecutive frames. The MAE and BME are plug-and-play and can be easily inserted into existing networks for efficient feature learning. As a result, they significantly improve the feature representation ability for V-ReID. Extensive experiments on three widely used benchmarks show that our proposed approach can deliver better performances than most state-of-the-arts.","sentences":["Video-based person Re-Identification (V-ReID) aims to retrieve specific persons from raw videos captured by non-overlapped cameras.","As a fundamental task, it spreads many multimedia and computer vision applications.","However, due to the variations of persons and scenes, there are still many obstacles that must be overcome for high performance.","In this work, we notice that both the long-term and short-term information of persons are important for robust video representations.","Thus, we propose a novel deep learning framework named Long Short-Term Representation Learning (LSTRL) for effective V-ReID.","More specifically, to extract long-term representations, we propose a Multi-granularity Appearance Extractor (MAE), in which four granularity appearances are effectively captured across multiple frames.","Meanwhile, to extract short-term representations, we propose a Bi-direction Motion Estimator (BME), in which reciprocal motion information is efficiently extracted from consecutive frames.","The MAE and BME are plug-and-play and can be easily inserted into existing networks for efficient feature learning.","As a result, they significantly improve the feature representation ability for V-ReID.","Extensive experiments on three widely used benchmarks show that our proposed approach can deliver better performances than most state-of-the-arts."],"url":"http://arxiv.org/abs/2308.03703v1"}
{"created":"2023-08-07 16:14:27","title":"Screen-based 3D Subjective Experiment Software","abstract":"Recently, widespread 3D graphics (e.g., point clouds and meshes) have drawn considerable efforts from academia and industry to assess their perceptual quality by conducting subjective experiments. However, lacking a handy software for 3D subjective experiments complicates the construction of 3D graphics quality assessment datasets, thus hindering the prosperity of relevant fields. In this paper, we develop a powerful platform with which users can flexibly design their 3D subjective methodologies and build high-quality datasets, easing a broad spectrum of 3D graphics subjective quality study. To accurately illustrate the perceptual quality differences of 3D stimuli, our software can simultaneously render the source stimulus and impaired stimulus and allows both stimuli to respond synchronously to viewer interactions. Compared with amateur 3D visualization tool-based or image/video rendering-based schemes, our approach embodies typical 3D applications while minimizing cognitive overload during subjective experiments. We organized a subjective experiment involving 40 participants to verify the validity of the proposed software. Experimental analyses demonstrate that subjective tests on our software can produce reasonable subjective quality scores of 3D models. All resources in this paper can be found at https://openi.pcl.ac.cn/OpenDatasets/3DQA.","sentences":["Recently, widespread 3D graphics (e.g., point clouds and meshes) have drawn considerable efforts from academia and industry to assess their perceptual quality by conducting subjective experiments.","However, lacking a handy software for 3D subjective experiments complicates the construction of 3D graphics quality assessment datasets, thus hindering the prosperity of relevant fields.","In this paper, we develop a powerful platform with which users can flexibly design their 3D subjective methodologies and build high-quality datasets, easing a broad spectrum of 3D graphics subjective quality study.","To accurately illustrate the perceptual quality differences of 3D stimuli, our software can simultaneously render the source stimulus and impaired stimulus and allows both stimuli to respond synchronously to viewer interactions.","Compared with amateur 3D visualization tool-based or image/video rendering-based schemes, our approach embodies typical 3D applications while minimizing cognitive overload during subjective experiments.","We organized a subjective experiment involving 40 participants to verify the validity of the proposed software.","Experimental analyses demonstrate that subjective tests on our software can produce reasonable subjective quality scores of 3D models.","All resources in this paper can be found at https://openi.pcl.ac.cn/OpenDatasets/3DQA."],"url":"http://arxiv.org/abs/2308.03698v1"}
{"created":"2023-08-07 16:12:31","title":"Quantifiers closed under partial polymorphisms","abstract":"We study Lindstrom quantifiers that satisfy certain closure properties which are motivated by the study of polymorphisms in the context of constraint satisfaction problems (CSP). When the algebra of polymorphisms of a finite structure B satisfies certain equations, this gives rise to a natural closure condition on the class of structures that map homomorphically to B. The collection of quantifiers that satisfy closure conditions arising from a fixed set of equations are rather more general than those arising as CSP. For any such conditions P, we define a pebble game that delimits the distinguishing power of the infinitary logic with all quantifiers that are P-closed. We use the pebble game to show that the problem of deciding whether a system of linear equations is solvable in Z2 is not expressible in the infinitary logic with all quantifiers closed under a near-unanimity condition.","sentences":["We study Lindstrom quantifiers that satisfy certain closure properties which are motivated by the study of polymorphisms in the context of constraint satisfaction problems (CSP).","When the algebra of polymorphisms of a finite structure B satisfies certain equations, this gives rise to a natural closure condition on the class of structures that map homomorphically to B.","The collection of quantifiers that satisfy closure conditions arising from a fixed set of equations are rather more general than those arising as CSP.","For any such conditions P, we define a pebble game that delimits the distinguishing power of the infinitary logic with all quantifiers that are P-closed.","We use the pebble game to show that the problem of deciding whether a system of linear equations is solvable in Z2 is not expressible in the infinitary logic with all quantifiers closed under a near-unanimity condition."],"url":"http://arxiv.org/abs/2308.03695v1"}
{"created":"2023-08-07 16:08:21","title":"Safe Multimodal Communication in Human-Robot Collaboration","abstract":"The new industrial settings are characterized by the presence of human and robots that work in close proximity, cooperating in performing the required job. Such a collaboration, however, requires to pay attention to many aspects. Firstly, it is crucial to enable a communication between this two actors that is natural and efficient. Secondly, the robot behavior must always be compliant with the safety regulations, ensuring always a safe collaboration. In this paper, we propose a framework that enables multi-channel communication between humans and robots by leveraging multimodal fusion of voice and gesture commands while always respecting safety regulations. The framework is validated through a comparative experiment, demonstrating that, thanks to multimodal communication, the robot can extract valuable information for performing the required task and additionally, with the safety layer, the robot can scale its speed to ensure the operator's safety.","sentences":["The new industrial settings are characterized by the presence of human and robots that work in close proximity, cooperating in performing the required job.","Such a collaboration, however, requires to pay attention to many aspects.","Firstly, it is crucial to enable a communication between this two actors that is natural and efficient.","Secondly, the robot behavior must always be compliant with the safety regulations, ensuring always a safe collaboration.","In this paper, we propose a framework that enables multi-channel communication between humans and robots by leveraging multimodal fusion of voice and gesture commands while always respecting safety regulations.","The framework is validated through a comparative experiment, demonstrating that, thanks to multimodal communication, the robot can extract valuable information for performing the required task and additionally, with the safety layer, the robot can scale its speed to ensure the operator's safety."],"url":"http://arxiv.org/abs/2308.03690v1"}
{"created":"2023-08-07 16:08:11","title":"AgentBench: Evaluating LLMs as Agents","abstract":"Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks. As a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments. We present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting. Our extensive test over 25 LLMs (including APIs and open-sourced models) shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and open-sourced competitors. It also serves as a component of an ongoing project with wider coverage and deeper consideration towards systematic LLM evaluation. Datasets, environments, and an integrated evaluation package for AgentBench are released at https://github.com/THUDM/AgentBench","sentences":["Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks.","As a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments.","We present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting.","Our extensive test over 25 LLMs (including APIs and open-sourced models) shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and open-sourced competitors.","It also serves as a component of an ongoing project with wider coverage and deeper consideration towards systematic LLM evaluation.","Datasets, environments, and an integrated evaluation package for AgentBench are released at https://github.com/THUDM/AgentBench"],"url":"http://arxiv.org/abs/2308.03688v1"}
{"created":"2023-08-07 16:00:22","title":"Learning Concise and Descriptive Attributes for Visual Recognition","abstract":"Recent advances in foundation models present new opportunities for interpretable visual recognition -- one can first query Large Language Models (LLMs) to obtain a set of attributes that describe each class, then apply vision-language models to classify images via these attributes. Pioneering work shows that querying thousands of attributes can achieve performance competitive with image features. However, our further investigation on 8 datasets reveals that LLM-generated attributes in a large quantity perform almost the same as random words. This surprising finding suggests that significant noise may be present in these attributes. We hypothesize that there exist subsets of attributes that can maintain the classification performance with much smaller sizes, and propose a novel learning-to-search method to discover those concise sets of attributes. As a result, on the CUB dataset, our method achieves performance close to that of massive LLM-generated attributes (e.g., 10k attributes for CUB), yet using only 32 attributes in total to distinguish 200 bird species. Furthermore, our new paradigm demonstrates several additional benefits: higher interpretability and interactivity for humans, and the ability to summarize knowledge for a recognition task.","sentences":["Recent advances in foundation models present new opportunities for interpretable visual recognition -- one can first query Large Language Models (LLMs) to obtain a set of attributes that describe each class, then apply vision-language models to classify images via these attributes.","Pioneering work shows that querying thousands of attributes can achieve performance competitive with image features.","However, our further investigation on 8 datasets reveals that LLM-generated attributes in a large quantity perform almost the same as random words.","This surprising finding suggests that significant noise may be present in these attributes.","We hypothesize that there exist subsets of attributes that can maintain the classification performance with much smaller sizes, and propose a novel learning-to-search method to discover those concise sets of attributes.","As a result, on the CUB dataset, our method achieves performance close to that of massive LLM-generated attributes (e.g., 10k attributes for CUB), yet using only 32 attributes in total to distinguish 200 bird species.","Furthermore, our new paradigm demonstrates several additional benefits: higher interpretability and interactivity for humans, and the ability to summarize knowledge for a recognition task."],"url":"http://arxiv.org/abs/2308.03685v1"}
{"created":"2023-08-07 15:52:00","title":"Evaluation of ARM CPUs for IceCube available through Google Kubernetes Engine","abstract":"The IceCube experiment has substantial simulation needs and is in continuous search for the most cost-effective ways to satisfy them. The most CPU-intensive part relies on CORSIKA, a cosmic ray air shower simulation. Historically, IceCube relied exclusively on x86-based CPUs, like Intel Xeon and AMD EPYC, but recently server-class ARM-based CPUs are also becoming available, both on-prem and in the cloud. In this paper we present our experience in running a sample CORSIKA simulation on both ARM and x86 CPUs available through Google Kubernetes Engine (GKE). We used the production binaries for the x86 instances, but had to build the binaries for ARM instances from source code, which turned out to be mostly painless. Our benchmarks show that ARM-based CPUs in GKE were not only the most cost-effective but were also the fastest in absolute terms in all the tested configurations. While the advantage is not drastic, about 20% in cost-effectiveness and less than 10% in absolute terms, it is still large enough to warrant an investment in ARM support for IceCube.","sentences":["The IceCube experiment has substantial simulation needs and is in continuous search for the most cost-effective ways to satisfy them.","The most CPU-intensive part relies on CORSIKA, a cosmic ray air shower simulation.","Historically, IceCube relied exclusively on x86-based CPUs, like Intel Xeon and AMD EPYC, but recently server-class ARM-based CPUs are also becoming available, both on-prem and in the cloud.","In this paper we present our experience in running a sample CORSIKA simulation on both ARM and x86 CPUs available through Google Kubernetes Engine (GKE).","We used the production binaries for the x86 instances, but had to build the binaries for ARM instances from source code, which turned out to be mostly painless.","Our benchmarks show that ARM-based CPUs in GKE were not only the most cost-effective but were also the fastest in absolute terms in all the tested configurations.","While the advantage is not drastic, about 20% in cost-effectiveness and less than 10% in absolute terms, it is still large enough to warrant an investment in ARM support for IceCube."],"url":"http://arxiv.org/abs/2308.03678v1"}
{"created":"2023-08-07 15:47:15","title":"Merge Tree Geodesics and Barycenters with Path Mappings","abstract":"Comparative visualization of scalar fields is often facilitated using similarity measures such as edit distances. In this paper, we describe a novel approach for similarity analysis of scalar fields that combines two recently introduced techniques: Wasserstein geodesics/barycenters as well as path mappings, a branch decomposition-independent edit distance. Effectively, we are able to leverage the reduced susceptibility of path mappings to small perturbations in the data when compared with the original Wasserstein distance. Our approach therefore exhibits superior performance and quality in typical tasks such as ensemble summarization, ensemble clustering, and temporal reduction of time series, while retaining practically feasible runtimes. Beyond studying theoretical properties of our approach and discussing implementation aspects, we describe a number of case studies that provide empirical insights into its utility for comparative visualization, and demonstrate the advantages of our method in both synthetic and real-world scenarios. We supply a C++ implementation that can be used to reproduce our results.","sentences":["Comparative visualization of scalar fields is often facilitated using similarity measures such as edit distances.","In this paper, we describe a novel approach for similarity analysis of scalar fields that combines two recently introduced techniques: Wasserstein geodesics/barycenters as well as path mappings, a branch decomposition-independent edit distance.","Effectively, we are able to leverage the reduced susceptibility of path mappings to small perturbations in the data when compared with the original Wasserstein distance.","Our approach therefore exhibits superior performance and quality in typical tasks such as ensemble summarization, ensemble clustering, and temporal reduction of time series, while retaining practically feasible runtimes.","Beyond studying theoretical properties of our approach and discussing implementation aspects, we describe a number of case studies that provide empirical insights into its utility for comparative visualization, and demonstrate the advantages of our method in both synthetic and real-world scenarios.","We supply a C++ implementation that can be used to reproduce our results."],"url":"http://arxiv.org/abs/2308.03672v1"}
{"created":"2023-08-07 15:46:39","title":"SemOpenAlex: The Scientific Landscape in 26 Billion RDF Triples","abstract":"We present SemOpenAlex, an extensive RDF knowledge graph that contains over 26 billion triples about scientific publications and their associated entities, such as authors, institutions, journals, and concepts. SemOpenAlex is licensed under CC0, providing free and open access to the data. We offer the data through multiple channels, including RDF dump files, a SPARQL endpoint, and as a data source in the Linked Open Data cloud, complete with resolvable URIs and links to other data sources. Moreover, we provide embeddings for knowledge graph entities using high-performance computing. SemOpenAlex enables a broad range of use-case scenarios, such as exploratory semantic search via our website, large-scale scientific impact quantification, and other forms of scholarly big data analytics within and across scientific disciplines. Additionally, it enables academic recommender systems, such as recommending collaborators, publications, and venues, including explainability capabilities. Finally, SemOpenAlex can serve for RDF query optimization benchmarks, creating scholarly knowledge-guided language models, and as a hub for semantic scientific publishing.","sentences":["We present SemOpenAlex, an extensive RDF knowledge graph that contains over 26 billion triples about scientific publications and their associated entities, such as authors, institutions, journals, and concepts.","SemOpenAlex is licensed under CC0, providing free and open access to the data.","We offer the data through multiple channels, including RDF dump files, a SPARQL endpoint, and as a data source in the Linked Open Data cloud, complete with resolvable URIs and links to other data sources.","Moreover, we provide embeddings for knowledge graph entities using high-performance computing.","SemOpenAlex enables a broad range of use-case scenarios, such as exploratory semantic search via our website, large-scale scientific impact quantification, and other forms of scholarly big data analytics within and across scientific disciplines.","Additionally, it enables academic recommender systems, such as recommending collaborators, publications, and venues, including explainability capabilities.","Finally, SemOpenAlex can serve for RDF query optimization benchmarks, creating scholarly knowledge-guided language models, and as a hub for semantic scientific publishing."],"url":"http://arxiv.org/abs/2308.03671v1"}
{"created":"2023-08-07 15:44:58","title":"Improving FHB Screening in Wheat Breeding Using an Efficient Transformer Model","abstract":"Fusarium head blight is a devastating disease that causes significant economic losses annually on small grains. Efficiency, accuracy, and timely detection of FHB in the resistance screening are critical for wheat and barley breeding programs. In recent years, various image processing techniques have been developed using supervised machine learning algorithms for the early detection of FHB. The state-of-the-art convolutional neural network-based methods, such as U-Net, employ a series of encoding blocks to create a local representation and a series of decoding blocks to capture the semantic relations. However, these methods are not often capable of long-range modeling dependencies inside the input data, and their ability to model multi-scale objects with significant variations in texture and shape is limited. Vision transformers as alternative architectures with innate global self-attention mechanisms for sequence-to-sequence prediction, due to insufficient low-level details, may also limit localization capabilities. To overcome these limitations, a new Context Bridge is proposed to integrate the local representation capability of the U-Net network in the transformer model. In addition, the standard attention mechanism of the original transformer is replaced with Efficient Self-attention, which is less complicated than other state-of-the-art methods. To train the proposed network, 12,000 wheat images from an FHB-inoculated wheat field at the SDSU research farm in Volga, SD, were captured. In addition to healthy and unhealthy plants, these images encompass various stages of the disease. A team of expert pathologists annotated the images for training and evaluating the developed model. As a result, the effectiveness of the transformer-based method for FHB-disease detection, through extensive experiments across typical tasks for plant image segmentation, is demonstrated.","sentences":["Fusarium head blight is a devastating disease that causes significant economic losses annually on small grains.","Efficiency, accuracy, and timely detection of FHB in the resistance screening are critical for wheat and barley breeding programs.","In recent years, various image processing techniques have been developed using supervised machine learning algorithms for the early detection of FHB.","The state-of-the-art convolutional neural network-based methods, such as U-Net, employ a series of encoding blocks to create a local representation and a series of decoding blocks to capture the semantic relations.","However, these methods are not often capable of long-range modeling dependencies inside the input data, and their ability to model multi-scale objects with significant variations in texture and shape is limited.","Vision transformers as alternative architectures with innate global self-attention mechanisms for sequence-to-sequence prediction, due to insufficient low-level details, may also limit localization capabilities.","To overcome these limitations, a new Context Bridge is proposed to integrate the local representation capability of the U-Net network in the transformer model.","In addition, the standard attention mechanism of the original transformer is replaced with Efficient Self-attention, which is less complicated than other state-of-the-art methods.","To train the proposed network, 12,000 wheat images from an FHB-inoculated wheat field at the SDSU research farm in Volga, SD, were captured.","In addition to healthy and unhealthy plants, these images encompass various stages of the disease.","A team of expert pathologists annotated the images for training and evaluating the developed model.","As a result, the effectiveness of the transformer-based method for FHB-disease detection, through extensive experiments across typical tasks for plant image segmentation, is demonstrated."],"url":"http://arxiv.org/abs/2308.03670v1"}
{"created":"2023-08-07 15:29:44","title":"QDax: A Library for Quality-Diversity and Population-based Algorithms with Hardware Acceleration","abstract":"QDax is an open-source library with a streamlined and modular API for Quality-Diversity (QD) optimization algorithms in Jax. The library serves as a versatile tool for optimization purposes, ranging from black-box optimization to continuous control. QDax offers implementations of popular QD, Neuroevolution, and Reinforcement Learning (RL) algorithms, supported by various examples. All the implementations can be just-in-time compiled with Jax, facilitating efficient execution across multiple accelerators, including GPUs and TPUs. These implementations effectively demonstrate the framework's flexibility and user-friendliness, easing experimentation for research purposes. Furthermore, the library is thoroughly documented and tested with 95\\% coverage.","sentences":["QDax is an open-source library with a streamlined and modular API for Quality-Diversity (QD) optimization algorithms in Jax.","The library serves as a versatile tool for optimization purposes, ranging from black-box optimization to continuous control.","QDax offers implementations of popular QD, Neuroevolution, and Reinforcement Learning (RL) algorithms, supported by various examples.","All the implementations can be just-in-time compiled with Jax, facilitating efficient execution across multiple accelerators, including GPUs and TPUs.","These implementations effectively demonstrate the framework's flexibility and user-friendliness, easing experimentation for research purposes.","Furthermore, the library is thoroughly documented and tested with 95\\% coverage."],"url":"http://arxiv.org/abs/2308.03665v1"}
{"created":"2023-08-07 15:28:39","title":"Two-stage Early Prediction Framework of Remaining Useful Life for Lithium-ion Batteries","abstract":"Early prediction of remaining useful life (RUL) is crucial for effective battery management across various industries, ranging from household appliances to large-scale applications. Accurate RUL prediction improves the reliability and maintainability of battery technology. However, existing methods have limitations, including assumptions of data from the same sensors or distribution, foreknowledge of the end of life (EOL), and neglect to determine the first prediction cycle (FPC) to identify the start of the unhealthy stage. This paper proposes a novel method for RUL prediction of Lithium-ion batteries. The proposed framework comprises two stages: determining the FPC using a neural network-based model to divide the degradation data into distinct health states and predicting the degradation pattern after the FPC to estimate the remaining useful life as a percentage. Experimental results demonstrate that the proposed method outperforms conventional approaches in terms of RUL prediction. Furthermore, the proposed method shows promise for real-world scenarios, providing improved accuracy and applicability for battery management.","sentences":["Early prediction of remaining useful life (RUL) is crucial for effective battery management across various industries, ranging from household appliances to large-scale applications.","Accurate RUL prediction improves the reliability and maintainability of battery technology.","However, existing methods have limitations, including assumptions of data from the same sensors or distribution, foreknowledge of the end of life (EOL), and neglect to determine the first prediction cycle (FPC) to identify the start of the unhealthy stage.","This paper proposes a novel method for RUL prediction of Lithium-ion batteries.","The proposed framework comprises two stages: determining the FPC using a neural network-based model to divide the degradation data into distinct health states and predicting the degradation pattern after the FPC to estimate the remaining useful life as a percentage.","Experimental results demonstrate that the proposed method outperforms conventional approaches in terms of RUL prediction.","Furthermore, the proposed method shows promise for real-world scenarios, providing improved accuracy and applicability for battery management."],"url":"http://arxiv.org/abs/2308.03664v1"}
{"created":"2023-08-07 15:24:49","title":"Matrix Completion in Almost-Verification Time","abstract":"We give a new framework for solving the fundamental problem of low-rank matrix completion, i.e., approximating a rank-$r$ matrix $\\mathbf{M} \\in \\mathbb{R}^{m \\times n}$ (where $m \\ge n$) from random observations. First, we provide an algorithm which completes $\\mathbf{M}$ on $99\\%$ of rows and columns under no further assumptions on $\\mathbf{M}$ from $\\approx mr$ samples and using $\\approx mr^2$ time. Then, assuming the row and column spans of $\\mathbf{M}$ satisfy additional regularity properties, we show how to boost this partial completion guarantee to a full matrix completion algorithm by aggregating solutions to regression problems involving the observations.   In the well-studied setting where $\\mathbf{M}$ has incoherent row and column spans, our algorithms complete $\\mathbf{M}$ to high precision from $mr^{2+o(1)}$ observations in $mr^{3 + o(1)}$ time (omitting logarithmic factors in problem parameters), improving upon the prior state-of-the-art [JN15] which used $\\approx mr^5$ samples and $\\approx mr^7$ time. Under an assumption on the row and column spans of $\\mathbf{M}$ we introduce (which is satisfied by random subspaces with high probability), our sample complexity improves to an almost information-theoretically optimal $mr^{1 + o(1)}$, and our runtime improves to $mr^{2 + o(1)}$. Our runtimes have the appealing property of matching the best known runtime to verify that a rank-$r$ decomposition $\\mathbf{U}\\mathbf{V}^\\top$ agrees with the sampled observations. We also provide robust variants of our algorithms that, given random observations from $\\mathbf{M} + \\mathbf{N}$ with $\\|\\mathbf{N}\\|_{F} \\le \\Delta$, complete $\\mathbf{M}$ to Frobenius norm distance $\\approx r^{1.5}\\Delta$ in the same runtimes as the noiseless setting. Prior noisy matrix completion algorithms [CP10] only guaranteed a distance of $\\approx \\sqrt{n}\\Delta$.","sentences":["We give a new framework for solving the fundamental problem of low-rank matrix completion, i.e., approximating a rank-$r$ matrix $\\mathbf{M} \\in \\mathbb{R}^{m \\times n}$ (where $m \\ge n$) from random observations.","First, we provide an algorithm which completes $\\mathbf{M}$ on $99\\%$ of rows and columns under no further assumptions on $\\mathbf{M}$ from $\\approx mr$ samples and using $\\approx mr^2$ time.","Then, assuming the row and column spans of $\\mathbf{M}$ satisfy additional regularity properties, we show how to boost this partial completion guarantee to a full matrix completion algorithm by aggregating solutions to regression problems involving the observations.   ","In the well-studied setting where $\\mathbf{M}$ has incoherent row and column spans, our algorithms complete $\\mathbf{M}$ to high precision from $mr^{2+o(1)}$ observations in $mr^{3 + o(1)}$ time (omitting logarithmic factors in problem parameters), improving upon the prior state-of-the-art [JN15] which used $\\approx mr^5$ samples and $\\approx mr^7$ time.","Under an assumption on the row and column spans of $\\mathbf{M}$ we introduce (which is satisfied by random subspaces with high probability), our sample complexity improves to an almost information-theoretically optimal $mr^{1 + o(1)}$, and our runtime improves to $mr^{2 + o(1)}$.","Our runtimes have the appealing property of matching the best known runtime to verify that a rank-$r$ decomposition $\\mathbf{U}\\mathbf{V}^\\top$ agrees with the sampled observations.","We also provide robust variants of our algorithms that, given random observations from $\\mathbf{M} + \\mathbf{N}$ with $\\|\\mathbf{N}\\|_{F} \\le \\Delta$, complete $\\mathbf{M}$ to Frobenius norm distance $\\approx r^{1.5}\\Delta$ in the same runtimes as the noiseless setting.","Prior noisy matrix completion algorithms","[CP10] only guaranteed a distance of $\\approx \\sqrt{n}\\Delta$."],"url":"http://arxiv.org/abs/2308.03661v1"}
{"created":"2023-08-07 15:20:20","title":"Detecting Spells in Fantasy Literature with a Transformer Based Artificial Intelligence","abstract":"Transformer architectures and models have made significant progress in language-based tasks. In this area, is BERT one of the most widely used and freely available transformer architecture. In our work, we use BERT for context-based phrase recognition of magic spells in the Harry Potter novel series. Spells are a common part of active magic in fantasy novels. Typically, spells are used in a specific context to achieve a supernatural effect. A series of investigations were conducted to see if a Transformer architecture could recognize such phrases based on their context in the Harry Potter saga. For our studies a pre-trained BERT model was used and fine-tuned utilising different datasets and training methods to identify the searched context. By considering different approaches for sequence classification as well as token classification, it is shown that the context of spells can be recognised. According to our investigations, the examined sequence length for fine-tuning and validation of the model plays a significant role in context recognition. Based on this, we have investigated whether spells have overarching properties that allow a transfer of the neural network models to other fantasy universes as well. The application of our model showed promising results and is worth to be deepened in subsequent studies.","sentences":["Transformer architectures and models have made significant progress in language-based tasks.","In this area, is BERT one of the most widely used and freely available transformer architecture.","In our work, we use BERT for context-based phrase recognition of magic spells in the Harry Potter novel series.","Spells are a common part of active magic in fantasy novels.","Typically, spells are used in a specific context to achieve a supernatural effect.","A series of investigations were conducted to see if a Transformer architecture could recognize such phrases based on their context in the Harry Potter saga.","For our studies a pre-trained BERT model was used and fine-tuned utilising different datasets and training methods to identify the searched context.","By considering different approaches for sequence classification as well as token classification, it is shown that the context of spells can be recognised.","According to our investigations, the examined sequence length for fine-tuning and validation of the model plays a significant role in context recognition.","Based on this, we have investigated whether spells have overarching properties that allow a transfer of the neural network models to other fantasy universes as well.","The application of our model showed promising results and is worth to be deepened in subsequent studies."],"url":"http://arxiv.org/abs/2308.03660v1"}
{"created":"2023-08-07 15:20:05","title":"Emerging Nonvolatile Memories for Machine Learning","abstract":"Digital computers have been getting exponentially faster for decades, but huge challenges exist today. Transistor scaling, described by Moore's law, has been slowing down over the last few years, ending the era of fully predictable performance improvements. Furthermore, the data-centric computing demands fueled by machine learning applications are rapidly growing, and current computing systems -- even with the historical rate of improvements driven by Moore's law -- cannot keep up with these enormous computational demands. Some are turning to analogue in-memory computing as a solution, where specialised systems operating on physical principles accelerate specific tasks. We explore how emerging nonvolatile memories can be used to implement such systems tailored for machine learning. In particular, we discuss how memristive crossbar arrays can accelerate key linear algebra operations used in neural networks, what technological challenges remain, and how they can be overcome.","sentences":["Digital computers have been getting exponentially faster for decades, but huge challenges exist today.","Transistor scaling, described by Moore's law, has been slowing down over the last few years, ending the era of fully predictable performance improvements.","Furthermore, the data-centric computing demands fueled by machine learning applications are rapidly growing, and current computing systems -- even with the historical rate of improvements driven by Moore's law -- cannot keep up with these enormous computational demands.","Some are turning to analogue in-memory computing as a solution, where specialised systems operating on physical principles accelerate specific tasks.","We explore how emerging nonvolatile memories can be used to implement such systems tailored for machine learning.","In particular, we discuss how memristive crossbar arrays can accelerate key linear algebra operations used in neural networks, what technological challenges remain, and how they can be overcome."],"url":"http://arxiv.org/abs/2308.03659v1"}
{"created":"2023-08-07 15:18:30","title":"Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench","abstract":"Recently, the community has witnessed the advancement of Large Language Models (LLMs), which have shown remarkable performance on various downstream tasks. Led by powerful models like ChatGPT and Claude, LLMs are revolutionizing how users engage with software, assuming more than mere tools but intelligent assistants. Consequently, evaluating LLMs' anthropomorphic capabilities becomes increasingly important in contemporary discourse. Utilizing the emotion appraisal theory from psychology, we propose to evaluate the empathy ability of LLMs, i.e., how their feelings change when presented with specific situations. After a careful and comprehensive survey, we collect a dataset containing over 400 situations that have proven effective in eliciting the eight emotions central to our study. Categorizing the situations into 36 factors, we conduct a human evaluation involving more than 1,200 subjects worldwide. With the human evaluation results as references, our evaluation includes five LLMs, covering both commercial and open-source models, including variations in model sizes, featuring the latest iterations, such as GPT-4 and LLaMA 2. A conclusion can be drawn from the results that, despite several misalignments, LLMs can generally respond appropriately to certain situations. Nevertheless, they fall short in alignment with the emotional behaviors of human beings and cannot establish connections between similar situations. Our collected dataset of situations, the human evaluation results, and the code of our testing framework, dubbed EmotionBench, is made publicly in https://github.com/CUHK-ARISE/EmotionBench. We aspire to contribute to the advancement of LLMs regarding better alignment with the emotional behaviors of human beings, thereby enhancing their utility and applicability as intelligent assistants.","sentences":["Recently, the community has witnessed the advancement of Large Language Models (LLMs), which have shown remarkable performance on various downstream tasks.","Led by powerful models like ChatGPT and Claude, LLMs are revolutionizing how users engage with software, assuming more than mere tools but intelligent assistants.","Consequently, evaluating LLMs' anthropomorphic capabilities becomes increasingly important in contemporary discourse.","Utilizing the emotion appraisal theory from psychology, we propose to evaluate the empathy ability of LLMs, i.e., how their feelings change when presented with specific situations.","After a careful and comprehensive survey, we collect a dataset containing over 400 situations that have proven effective in eliciting the eight emotions central to our study.","Categorizing the situations into 36 factors, we conduct a human evaluation involving more than 1,200 subjects worldwide.","With the human evaluation results as references, our evaluation includes five LLMs, covering both commercial and open-source models, including variations in model sizes, featuring the latest iterations, such as GPT-4 and LLaMA 2.","A conclusion can be drawn from the results that, despite several misalignments, LLMs can generally respond appropriately to certain situations.","Nevertheless, they fall short in alignment with the emotional behaviors of human beings and cannot establish connections between similar situations.","Our collected dataset of situations, the human evaluation results, and the code of our testing framework, dubbed EmotionBench, is made publicly in https://github.com/CUHK-ARISE/EmotionBench.","We aspire to contribute to the advancement of LLMs regarding better alignment with the emotional behaviors of human beings, thereby enhancing their utility and applicability as intelligent assistants."],"url":"http://arxiv.org/abs/2308.03656v1"}
{"created":"2023-08-07 15:10:21","title":"FFF: Fragments-Guided Flexible Fitting for Building Complete Protein Structures","abstract":"Cryo-electron microscopy (cryo-EM) is a technique for reconstructing the 3-dimensional (3D) structure of biomolecules (especially large protein complexes and molecular assemblies). As the resolution increases to the near-atomic scale, building protein structures de novo from cryo-EM maps becomes possible. Recently, recognition-based de novo building methods have shown the potential to streamline this process. However, it cannot build a complete structure due to the low signal-to-noise ratio (SNR) problem. At the same time, AlphaFold has led to a great breakthrough in predicting protein structures. This has inspired us to combine fragment recognition and structure prediction methods to build a complete structure. In this paper, we propose a new method named FFF that bridges protein structure prediction and protein structure recognition with flexible fitting. First, a multi-level recognition network is used to capture various structural features from the input 3D cryo-EM map. Next, protein structural fragments are generated using pseudo peptide vectors and a protein sequence alignment method based on these extracted features. Finally, a complete structural model is constructed using the predicted protein fragments via flexible fitting. Based on our benchmark tests, FFF outperforms the baseline methods for building complete protein structures.","sentences":["Cryo-electron microscopy (cryo-EM) is a technique for reconstructing the 3-dimensional (3D) structure of biomolecules (especially large protein complexes and molecular assemblies).","As the resolution increases to the near-atomic scale, building protein structures de novo from cryo-EM maps becomes possible.","Recently, recognition-based de novo building methods have shown the potential to streamline this process.","However, it cannot build a complete structure due to the low signal-to-noise ratio (SNR) problem.","At the same time, AlphaFold has led to a great breakthrough in predicting protein structures.","This has inspired us to combine fragment recognition and structure prediction methods to build a complete structure.","In this paper, we propose a new method named FFF that bridges protein structure prediction and protein structure recognition with flexible fitting.","First, a multi-level recognition network is used to capture various structural features from the input 3D cryo-EM map.","Next, protein structural fragments are generated using pseudo peptide vectors and a protein sequence alignment method based on these extracted features.","Finally, a complete structural model is constructed using the predicted protein fragments via flexible fitting.","Based on our benchmark tests, FFF outperforms the baseline methods for building complete protein structures."],"url":"http://arxiv.org/abs/2308.03654v1"}
{"created":"2023-08-07 15:07:21","title":"WarpEM: Dynamic Time Warping for Accurate Catheter Registration in EM-guided Procedures","abstract":"Accurate catheter tracking is crucial during minimally invasive endovascular procedures (MIEP), and electromagnetic (EM) tracking is a widely used technology that serves this purpose. However, registration between preoperative images and the EM tracking system is often challenging. Existing registration methods typically require manual interactions, which can be time-consuming, increase the risk of errors and change the procedural workflow. Although several registration methods are available for catheter tracking, such as marker-based and path-based approaches, their limitations can impact the accuracy of the resulting tracking solution, consequently, the outcome of the medical procedure.   This paper introduces a novel automated catheter registration method for EM-guided MIEP. The method utilizes 3D signal temporal analysis, such as Dynamic Time Warping (DTW) algorithms, to improve registration accuracy and reliability compared to existing methods. DTW can accurately warp and match EM-tracked paths to the vessel's centerline, making it particularly suitable for registration. The introduced registration method is evaluated for accuracy in a vascular phantom using a marker-based registration as the ground truth. The results indicate that the DTW method yields accurate and reliable registration outcomes, with a mean error of $2.22$mm. The introduced registration method presents several advantages over state-of-the-art methods, such as high registration accuracy, no initialization required, and increased automation.","sentences":["Accurate catheter tracking is crucial during minimally invasive endovascular procedures (MIEP), and electromagnetic (EM) tracking is a widely used technology that serves this purpose.","However, registration between preoperative images and the EM tracking system is often challenging.","Existing registration methods typically require manual interactions, which can be time-consuming, increase the risk of errors and change the procedural workflow.","Although several registration methods are available for catheter tracking, such as marker-based and path-based approaches, their limitations can impact the accuracy of the resulting tracking solution, consequently, the outcome of the medical procedure.   ","This paper introduces a novel automated catheter registration method for EM-guided MIEP.","The method utilizes 3D signal temporal analysis, such as Dynamic Time Warping (DTW) algorithms, to improve registration accuracy and reliability compared to existing methods.","DTW can accurately warp and match EM-tracked paths to the vessel's centerline, making it particularly suitable for registration.","The introduced registration method is evaluated for accuracy in a vascular phantom using a marker-based registration as the ground truth.","The results indicate that the DTW method yields accurate and reliable registration outcomes, with a mean error of $2.22$mm.","The introduced registration method presents several advantages over state-of-the-art methods, such as high registration accuracy, no initialization required, and increased automation."],"url":"http://arxiv.org/abs/2308.03652v1"}
{"created":"2023-08-07 15:05:25","title":"Cluster-Aware Grid Layout","abstract":"Grid visualizations are widely used in many applications to visually explain a set of data and their proximity relationships. However, existing layout methods face difficulties when dealing with the inherent cluster structures within the data. To address this issue, we propose a cluster-aware grid layout method that aims to better preserve cluster structures by simultaneously considering proximity, compactness, and convexity in the optimization process. Our method utilizes a hybrid optimization strategy that consists of two phases. The global phase aims to balance proximity and compactness within each cluster, while the local phase ensures the convexity of cluster shapes. We evaluate the proposed grid layout method through a series of quantitative experiments and two use cases, demonstrating its effectiveness in preserving cluster structures and facilitating analysis tasks.","sentences":["Grid visualizations are widely used in many applications to visually explain a set of data and their proximity relationships.","However, existing layout methods face difficulties when dealing with the inherent cluster structures within the data.","To address this issue, we propose a cluster-aware grid layout method that aims to better preserve cluster structures by simultaneously considering proximity, compactness, and convexity in the optimization process.","Our method utilizes a hybrid optimization strategy that consists of two phases.","The global phase aims to balance proximity and compactness within each cluster, while the local phase ensures the convexity of cluster shapes.","We evaluate the proposed grid layout method through a series of quantitative experiments and two use cases, demonstrating its effectiveness in preserving cluster structures and facilitating analysis tasks."],"url":"http://arxiv.org/abs/2308.03651v1"}
{"created":"2023-08-07 14:58:53","title":"Generative Forests","abstract":"Tabular data represents one of the most prevalent form of data. When it comes to data generation, many approaches would learn a density for the data generation process, but would not necessarily end up with a sampler, even less so being exact with respect to the underlying density. A second issue is on models: while complex modeling based on neural nets thrives in image or text generation (etc.), less is known for powerful generative models on tabular data. A third problem is the visible chasm on tabular data between training algorithms for supervised learning with remarkable properties (e.g. boosting), and a comparative lack of guarantees when it comes to data generation. In this paper, we tackle the three problems, introducing new tree-based generative models convenient for density modeling and tabular data generation that improve on modeling capabilities of recent proposals, and a training algorithm which simplifies the training setting of previous approaches and displays boosting-compliant convergence. This algorithm has the convenient property to rely on a supervised training scheme that can be implemented by a few tweaks to the most popular induction scheme for decision tree induction with two classes. Experiments are provided on missing data imputation and comparing generated data to real data, displaying the quality of the results obtained by our approach, in particular against state of the art.","sentences":["Tabular data represents one of the most prevalent form of data.","When it comes to data generation, many approaches would learn a density for the data generation process, but would not necessarily end up with a sampler, even less so being exact with respect to the underlying density.","A second issue is on models: while complex modeling based on neural nets thrives in image or text generation (etc.), less is known for powerful generative models on tabular data.","A third problem is the visible chasm on tabular data between training algorithms for supervised learning with remarkable properties (e.g. boosting), and a comparative lack of guarantees when it comes to data generation.","In this paper, we tackle the three problems, introducing new tree-based generative models convenient for density modeling and tabular data generation that improve on modeling capabilities of recent proposals, and a training algorithm which simplifies the training setting of previous approaches and displays boosting-compliant convergence.","This algorithm has the convenient property to rely on a supervised training scheme that can be implemented by a few tweaks to the most popular induction scheme for decision tree induction with two classes.","Experiments are provided on missing data imputation and comparing generated data to real data, displaying the quality of the results obtained by our approach, in particular against state of the art."],"url":"http://arxiv.org/abs/2308.03648v1"}
{"created":"2023-08-07 14:48:23","title":"Perceptually Uniform Construction of Illustrative Textures","abstract":"Illustrative textures, such as stippling or hatching, were predominantly used as an alternative to conventional Phong rendering. Recently, the potential of encoding information on surfaces or maps using different densities has also been recognized. This has the significant advantage that additional color can be used as another visual channel and the illustrative textures can then be overlaid. Effectively, it is thus possible to display multiple information, such as two different scalar fields on surfaces simultaneously. In previous work, these textures were manually generated and the choice of density was unempirically determined. Here, we first want to determine and understand the perceptual space of illustrative textures. We chose a succession of simplices with increasing dimensions as primitives for our textures: Dots, lines, and triangles. Thus, we explore the texture types of stippling, hatching, and triangles. We create a range of textures by sampling the density space uniformly. Then, we conduct three perceptual studies in which the participants performed pairwise comparisons for each texture type. We use multidimensional scaling (MDS) to analyze the perceptual spaces per category. The perception of stippling and triangles seems relatively similar. Both are adequately described by a 1D manifold in 2D space. The perceptual space of hatching consists of two main clusters: Crosshatched textures, and textures with only one hatching direction. However, the perception of hatching textures with only one hatching direction is similar to the perception of stippling and triangles. Based on our findings, we construct perceptually uniform illustrative textures. Afterwards, we provide concrete application examples for the constructed textures.","sentences":["Illustrative textures, such as stippling or hatching, were predominantly used as an alternative to conventional Phong rendering.","Recently, the potential of encoding information on surfaces or maps using different densities has also been recognized.","This has the significant advantage that additional color can be used as another visual channel and the illustrative textures can then be overlaid.","Effectively, it is thus possible to display multiple information, such as two different scalar fields on surfaces simultaneously.","In previous work, these textures were manually generated and the choice of density was unempirically determined.","Here, we first want to determine and understand the perceptual space of illustrative textures.","We chose a succession of simplices with increasing dimensions as primitives for our textures: Dots, lines, and triangles.","Thus, we explore the texture types of stippling, hatching, and triangles.","We create a range of textures by sampling the density space uniformly.","Then, we conduct three perceptual studies in which the participants performed pairwise comparisons for each texture type.","We use multidimensional scaling (MDS) to analyze the perceptual spaces per category.","The perception of stippling and triangles seems relatively similar.","Both are adequately described by a 1D manifold in 2D space.","The perceptual space of hatching consists of two main clusters: Crosshatched textures, and textures with only one hatching direction.","However, the perception of hatching textures with only one hatching direction is similar to the perception of stippling and triangles.","Based on our findings, we construct perceptually uniform illustrative textures.","Afterwards, we provide concrete application examples for the constructed textures."],"url":"http://arxiv.org/abs/2308.03644v1"}
{"created":"2023-08-07 14:47:45","title":"Mamba: Bringing Multi-Dimensional ABR to WebRTC","abstract":"Contemporary real-time video communication systems, such as WebRTC, use an adaptive bitrate (ABR) algorithm to assure high-quality and low-delay services, e.g., promptly adjusting video bitrate according to the instantaneous network bandwidth. However, target bitrate decisions in the network and bitrate control in the codec are typically incoordinated and simply ignoring the effect of inappropriate resolution and frame rate settings also leads to compromised results in bitrate control, thus devastatingly deteriorating the quality of experience (QoE). To tackle these challenges, Mamba, an end-to-end multi-dimensional ABR algorithm is proposed, which utilizes multi-agent reinforcement learning (MARL) to maximize the user's QoE by adaptively and collaboratively adjusting encoding factors including the quantization parameters (QP), resolution, and frame rate based on observed states such as network conditions and video complexity information in a video conferencing system. We also introduce curriculum learning to improve the training efficiency of MARL. Both the in-lab and real-world evaluation results demonstrate the remarkable efficacy of Mamba.","sentences":["Contemporary real-time video communication systems, such as WebRTC, use an adaptive bitrate (ABR) algorithm to assure high-quality and low-delay services, e.g., promptly adjusting video bitrate according to the instantaneous network bandwidth.","However, target bitrate decisions in the network and bitrate control in the codec are typically incoordinated and simply ignoring the effect of inappropriate resolution and frame rate settings also leads to compromised results in bitrate control, thus devastatingly deteriorating the quality of experience (QoE).","To tackle these challenges, Mamba, an end-to-end multi-dimensional ABR algorithm is proposed, which utilizes multi-agent reinforcement learning (MARL) to maximize the user's QoE by adaptively and collaboratively adjusting encoding factors including the quantization parameters (QP), resolution, and frame rate based on observed states such as network conditions and video complexity information in a video conferencing system.","We also introduce curriculum learning to improve the training efficiency of MARL.","Both the in-lab and real-world evaluation results demonstrate the remarkable efficacy of Mamba."],"url":"http://arxiv.org/abs/2308.03643v1"}
{"created":"2023-08-07 14:42:49","title":"KITLM: Domain-Specific Knowledge InTegration into Language Models for Question Answering","abstract":"Large language models (LLMs) have demonstrated remarkable performance in a wide range of natural language tasks. However, as these models continue to grow in size, they face significant challenges in terms of computational costs. Additionally, LLMs often lack efficient domain-specific understanding, which is particularly crucial in specialized fields such as aviation and healthcare. To boost the domain-specific understanding, we propose, KITLM, a novel knowledge base integration approach into language model through relevant information infusion. By integrating pertinent knowledge, not only the performance of the language model is greatly enhanced, but the model size requirement is also significantly reduced while achieving comparable performance. Our proposed knowledge-infused model surpasses the performance of both GPT-3.5-turbo and the state-of-the-art knowledge infusion method, SKILL, achieving over 1.5 times improvement in exact match scores on the MetaQA. KITLM showed a similar performance boost in the aviation domain with AeroQA. The drastic performance improvement of KITLM over the existing methods can be attributed to the infusion of relevant knowledge while mitigating noise. In addition, we release two curated datasets to accelerate knowledge infusion research in specialized fields: a) AeroQA, a new benchmark dataset designed for multi-hop question-answering within the aviation domain, and b) Aviation Corpus, a dataset constructed from unstructured text extracted from the National Transportation Safety Board reports. Our research contributes to advancing the field of domain-specific language understanding and showcases the potential of knowledge infusion techniques in improving the performance of language models on question-answering.","sentences":["Large language models (LLMs) have demonstrated remarkable performance in a wide range of natural language tasks.","However, as these models continue to grow in size, they face significant challenges in terms of computational costs.","Additionally, LLMs often lack efficient domain-specific understanding, which is particularly crucial in specialized fields such as aviation and healthcare.","To boost the domain-specific understanding, we propose, KITLM, a novel knowledge base integration approach into language model through relevant information infusion.","By integrating pertinent knowledge, not only the performance of the language model is greatly enhanced, but the model size requirement is also significantly reduced while achieving comparable performance.","Our proposed knowledge-infused model surpasses the performance of both GPT-3.5-turbo and the state-of-the-art knowledge infusion method, SKILL, achieving over 1.5 times improvement in exact match scores on the MetaQA.","KITLM showed a similar performance boost in the aviation domain with AeroQA.","The drastic performance improvement of KITLM over the existing methods can be attributed to the infusion of relevant knowledge while mitigating noise.","In addition, we release two curated datasets to accelerate knowledge infusion research in specialized fields: a) AeroQA, a new benchmark dataset designed for multi-hop question-answering within the aviation domain, and b) Aviation Corpus, a dataset constructed from unstructured text extracted from the National Transportation Safety Board reports.","Our research contributes to advancing the field of domain-specific language understanding and showcases the potential of knowledge infusion techniques in improving the performance of language models on question-answering."],"url":"http://arxiv.org/abs/2308.03638v1"}
{"created":"2023-08-07 14:42:29","title":"Implementing Immune Repertoire Models Using Weighted Finite State Machines","abstract":"The adaptive immune system's T and B cells can be viewed as large populations of simple, diverse classifiers. Artificial immune systems (AIS) $\\unicode{x2013}$ algorithmic models of T or B cell repertoires $\\unicode{x2013}$ are used in both computational biology and natural computing to investigate how the immune system adapts to its changing environments. However, researchers have struggled to build such systems at scale. For string-based AISs, finite state machines (FSMs) can store cell repertoires in compressed representations that are orders of magnitude smaller than explicitly stored receptor sets. This strategy allows AISs with billions of receptors to be generated in a matter of seconds. However, to date, these FSM-based AISs have been unable to deal with multiplicity in input data. Here, we show how weighted FSMs can be used to represent cell repertoires and model immunological processes like negative and positive selection, while also taking into account the multiplicity of input data. We use our method to build simple immune-inspired classifier systems that solve various toy problems in anomaly detection, showing how weights can be crucial for both performance and robustness to parameters. Our approach can potentially be extended to increase the scale of other population-based machine learning algorithms such as learning classifier systems.","sentences":["The adaptive immune system's T and B cells can be viewed as large populations of simple, diverse classifiers.","Artificial immune systems (AIS) $\\unicode{x2013}$ algorithmic models of T or B cell repertoires $\\unicode{x2013}$ are used in both computational biology and natural computing to investigate how the immune system adapts to its changing environments.","However, researchers have struggled to build such systems at scale.","For string-based AISs, finite state machines (FSMs) can store cell repertoires in compressed representations that are orders of magnitude smaller than explicitly stored receptor sets.","This strategy allows AISs with billions of receptors to be generated in a matter of seconds.","However, to date, these FSM-based AISs have been unable to deal with multiplicity in input data.","Here, we show how weighted FSMs can be used to represent cell repertoires and model immunological processes like negative and positive selection, while also taking into account the multiplicity of input data.","We use our method to build simple immune-inspired classifier systems that solve various toy problems in anomaly detection, showing how weights can be crucial for both performance and robustness to parameters.","Our approach can potentially be extended to increase the scale of other population-based machine learning algorithms such as learning classifier systems."],"url":"http://arxiv.org/abs/2308.03637v1"}
{"created":"2023-08-07 14:41:28","title":"Comparing biased random walks in graph embedding and link prediction","abstract":"Random walks find extensive application across various complex network domains, including embedding generation and link prediction. Despite the widespread utilization of random walks, the precise impact of distinct biases on embedding generation from sequence data and their subsequent effects on link prediction remain elusive. In this study, we conduct a comparative analysis of several random walk strategies, each rooted in different biases: true self-avoidance, unbiased randomness, bias towards node degree, and inverse node degree bias. Furthermore, we explore diverse adaptations of the node2vec algorithm to induce distinct exploratory behaviors. Our empirical findings demonstrate that despite the varied behaviors inherent in these embeddings, only slight performance differences manifest in the context of link prediction. This implies the resilient recovery of network structure, regardless of the specific walk heuristic employed to traverse the network. Consequently, the results suggest that data generated from sequences governed by unknown mechanisms can be successfully reconstructed.","sentences":["Random walks find extensive application across various complex network domains, including embedding generation and link prediction.","Despite the widespread utilization of random walks, the precise impact of distinct biases on embedding generation from sequence data and their subsequent effects on link prediction remain elusive.","In this study, we conduct a comparative analysis of several random walk strategies, each rooted in different biases: true self-avoidance, unbiased randomness, bias towards node degree, and inverse node degree bias.","Furthermore, we explore diverse adaptations of the node2vec algorithm to induce distinct exploratory behaviors.","Our empirical findings demonstrate that despite the varied behaviors inherent in these embeddings, only slight performance differences manifest in the context of link prediction.","This implies the resilient recovery of network structure, regardless of the specific walk heuristic employed to traverse the network.","Consequently, the results suggest that data generated from sequences governed by unknown mechanisms can be successfully reconstructed."],"url":"http://arxiv.org/abs/2308.03636v1"}
{"created":"2023-08-07 14:41:11","title":"Collapsing the Hierarchy of Compressed Data Structures: Suffix Arrays in Optimal Compressed Space","abstract":"In the last decades, the necessity to process massive amounts of textual data fueled the development of compressed text indexes: data structures efficiently answering queries on a given text while occupying space proportional to the compressed representation of the text. A widespread phenomenon in compressed indexing is that more powerful queries require larger indexes. For example, random access, the most basic query, can be supported in $O(\\delta\\log\\frac{n\\log\\sigma}{\\delta\\log n})$ space (where $n$ is the text length, $\\sigma$ is the alphabet size, and $\\delta$ is text's substring complexity), which is the asymptotically smallest space to represent a string, for all $n$, $\\sigma$, and $\\delta$ (Kociumaka, Navarro, Prezza; IEEE Trans. Inf. Theory 2023). The other end of the hierarchy is occupied by indexes supporting the powerful suffix array (SA) queries. The currently smallest one takes $O(r\\log\\frac{n}{r})$ space, where $r\\geq\\delta$ is the number of runs in the BWT of the text (Gagie, Navarro, Prezza; J. ACM 2020).   We present a new compressed index that needs only $O(\\delta\\log\\frac{n\\log\\sigma}{\\delta\\log n})$ space to support SA functionality in $O(\\log^{4+\\epsilon} n)$ time. This collapses the hierarchy of compressed data structures into a single point: The space required to represent the text is simultaneously sufficient for efficient SA queries. Our result immediately improves the space complexity of dozens of algorithms, which can now be executed in optimal compressed space.   In addition, we show how to construct our index in $O(\\delta\\text{ polylog } n)$ time from the LZ77 parsing of the text. For highly repetitive texts, this is up to exponentially faster than the previously best algorithm. To obtain our results, we develop numerous techniques of independent interest, including the first $O(\\delta\\log\\frac{n\\log\\sigma}{\\delta\\log n})$-size index for LCE queries.","sentences":["In the last decades, the necessity to process massive amounts of textual data fueled the development of compressed text indexes: data structures efficiently answering queries on a given text while occupying space proportional to the compressed representation of the text.","A widespread phenomenon in compressed indexing is that more powerful queries require larger indexes.","For example, random access, the most basic query, can be supported in $O(\\delta\\log\\frac{n\\log\\sigma}{\\delta\\log n})$ space (where $n$ is the text length, $\\sigma$ is the alphabet size, and $\\delta$ is text's substring complexity), which is the asymptotically smallest space to represent a string, for all $n$, $\\sigma$, and $\\delta$ (Kociumaka, Navarro, Prezza; IEEE Trans.","Inf.","Theory 2023).","The other end of the hierarchy is occupied by indexes supporting the powerful suffix array (SA) queries.","The currently smallest one takes $O(r\\log\\frac{n}{r})$ space, where $r\\geq\\delta$ is the number of runs in the BWT of the text (Gagie, Navarro, Prezza; J. ACM 2020).   ","We present a new compressed index that needs only $O(\\delta\\log\\frac{n\\log\\sigma}{\\delta\\log n})$ space to support SA functionality in $O(\\log^{4+\\epsilon} n)$ time.","This collapses the hierarchy of compressed data structures into a single point: The space required to represent the text is simultaneously sufficient for efficient SA queries.","Our result immediately improves the space complexity of dozens of algorithms, which can now be executed in optimal compressed space.   ","In addition, we show how to construct our index in $O(\\delta\\text{ polylog }","n)$ time from the LZ77 parsing of the text.","For highly repetitive texts, this is up to exponentially faster than the previously best algorithm.","To obtain our results, we develop numerous techniques of independent interest, including the first $O(\\delta\\log\\frac{n\\log\\sigma}{\\delta\\log n})$-size index for LCE queries."],"url":"http://arxiv.org/abs/2308.03635v1"}
{"created":"2023-08-07 14:36:49","title":"Segmentation Framework for Heat Loss Identification in Thermal Images: Empowering Scottish Retrofitting and Thermographic Survey Companies","abstract":"Retrofitting and thermographic survey (TS) companies in Scotland collaborate with social housing providers to tackle fuel poverty. They employ ground-level infrared (IR) camera-based-TSs (GIRTSs) for collecting thermal images to identi-fy the heat loss sources resulting from poor insulation. However, this identifica-tion process is labor-intensive and time-consuming, necessitating extensive data processing. To automate this, an AI-driven approach is necessary. Therefore, this study proposes a deep learning (DL)-based segmentation framework using the Mask Region Proposal Convolutional Neural Network (Mask RCNN) to validate its applicability to these thermal images. The objective of the framework is to au-tomatically identify, and crop heat loss sources caused by weak insulation, while also eliminating obstructive objects present in those images. By doing so, it min-imizes labor-intensive tasks and provides an automated, consistent, and reliable solution. To validate the proposed framework, approximately 2500 thermal imag-es were collected in collaboration with industrial TS partner. Then, 1800 repre-sentative images were carefully selected with the assistance of experts and anno-tated to highlight the target objects (TO) to form the final dataset. Subsequently, a transfer learning strategy was employed to train the dataset, progressively aug-menting the training data volume and fine-tuning the pre-trained baseline Mask RCNN. As a result, the final fine-tuned model achieved a mean average precision (mAP) score of 77.2% for segmenting the TO, demonstrating the significant po-tential of proposed framework in accurately quantifying energy loss in Scottish homes.","sentences":["Retrofitting and thermographic survey (TS) companies in Scotland collaborate with social housing providers to tackle fuel poverty.","They employ ground-level infrared (IR) camera-based-TSs (GIRTSs) for collecting thermal images to identi-fy the heat loss sources resulting from poor insulation.","However, this identifica-tion process is labor-intensive and time-consuming, necessitating extensive data processing.","To automate this, an AI-driven approach is necessary.","Therefore, this study proposes a deep learning (DL)-based segmentation framework using the Mask Region Proposal Convolutional Neural Network (Mask RCNN) to validate its applicability to these thermal images.","The objective of the framework is to au-tomatically identify, and crop heat loss sources caused by weak insulation, while also eliminating obstructive objects present in those images.","By doing so, it min-imizes labor-intensive tasks and provides an automated, consistent, and reliable solution.","To validate the proposed framework, approximately 2500 thermal imag-es were collected in collaboration with industrial TS partner.","Then, 1800 repre-sentative images were carefully selected with the assistance of experts and anno-tated to highlight the target objects (TO) to form the final dataset.","Subsequently, a transfer learning strategy was employed to train the dataset, progressively aug-menting the training data volume and fine-tuning the pre-trained baseline Mask RCNN.","As a result, the final fine-tuned model achieved a mean average precision (mAP) score of 77.2% for segmenting the TO, demonstrating the significant po-tential of proposed framework in accurately quantifying energy loss in Scottish homes."],"url":"http://arxiv.org/abs/2308.03631v1"}
{"created":"2023-08-07 14:36:03","title":"MedMine: Examining Pre-trained Language Models on Medication Mining","abstract":"Automatic medication mining from clinical and biomedical text has become a popular topic due to its real impact on healthcare applications and the recent development of powerful language models (LMs). However, fully-automatic extraction models still face obstacles to be overcome such that they can be deployed directly into clinical practice for better impacts. Such obstacles include their imbalanced performances on different entity types and clinical events. In this work, we examine current state-of-the-art pre-trained language models (PLMs) on such tasks, via fine-tuning including the monolingual model Med7 and multilingual large language model (LLM) XLM-RoBERTa. We compare their advantages and drawbacks using historical medication mining shared task data sets from n2c2-2018 challenges. We report the findings we get from these fine-tuning experiments such that they can facilitate future research on addressing them, for instance, how to combine their outputs, merge such models, or improve their overall accuracy by ensemble learning and data augmentation. MedMine is part of the M3 Initiative \\url{https://github.com/HECTA-UoM/M3}","sentences":["Automatic medication mining from clinical and biomedical text has become a popular topic due to its real impact on healthcare applications and the recent development of powerful language models (LMs).","However, fully-automatic extraction models still face obstacles to be overcome such that they can be deployed directly into clinical practice for better impacts.","Such obstacles include their imbalanced performances on different entity types and clinical events.","In this work, we examine current state-of-the-art pre-trained language models (PLMs) on such tasks, via fine-tuning including the monolingual model Med7 and multilingual large language model (LLM) XLM-RoBERTa.","We compare their advantages and drawbacks using historical medication mining shared task data sets from n2c2-2018 challenges.","We report the findings we get from these fine-tuning experiments such that they can facilitate future research on addressing them, for instance, how to combine their outputs, merge such models, or improve their overall accuracy by ensemble learning and data augmentation.","MedMine is part of the M3 Initiative \\url{https://github.com/HECTA-UoM/M3}"],"url":"http://arxiv.org/abs/2308.03629v1"}
{"created":"2023-08-07 14:34:36","title":"Monitoring Hyperproperties With Prefix Transducers","abstract":"Hyperproperties are properties that relate multiple execution traces. Previous work on monitoring hyperproperties focused on synchronous hyperproperties, usually specified in HyperLTL. When monitoring synchronous hyperproperties, all traces are assumed to proceed at the same speed. We introduce (multi-trace) prefix transducers and show how to use them for monitoring synchronous as well as, for the first time, asynchronous hyperproperties. Prefix transducers map multiple input traces into one or more output traces, by incrementally matching prefixes of the input traces against expressions similar to regular expressions. The prefixes of different traces which are consumed by a single matching step of the monitor may have different lengths. The deterministic and executable nature of prefix transducers makes them more suitable as an intermediate formalism for runtime verification than logical specifications, which tend to be highly nondeterministic, especially in the case of asynchronous hyperproperties. We report on a set of experiments about monitoring asynchronous version of observational determinism.","sentences":["Hyperproperties are properties that relate multiple execution traces.","Previous work on monitoring hyperproperties focused on synchronous hyperproperties, usually specified in HyperLTL.","When monitoring synchronous hyperproperties, all traces are assumed to proceed at the same speed.","We introduce (multi-trace) prefix transducers and show how to use them for monitoring synchronous as well as, for the first time, asynchronous hyperproperties.","Prefix transducers map multiple input traces into one or more output traces, by incrementally matching prefixes of the input traces against expressions similar to regular expressions.","The prefixes of different traces which are consumed by a single matching step of the monitor may have different lengths.","The deterministic and executable nature of prefix transducers makes them more suitable as an intermediate formalism for runtime verification than logical specifications, which tend to be highly nondeterministic, especially in the case of asynchronous hyperproperties.","We report on a set of experiments about monitoring asynchronous version of observational determinism."],"url":"http://arxiv.org/abs/2308.03626v1"}
{"created":"2023-08-07 14:31:07","title":"MOMA-Force: Visual-Force Imitation for Real-World Mobile Manipulation","abstract":"In this paper, we present a novel method for mobile manipulators to perform multiple contact-rich manipulation tasks. While learning-based methods have the potential to generate actions in an end-to-end manner, they often suffer from insufficient action accuracy and robustness against noise. On the other hand, classical control-based methods can enhance system robustness, but at the cost of extensive parameter tuning. To address these challenges, we present MOMA-Force, a visual-force imitation method that seamlessly combines representation learning for perception, imitation learning for complex motion generation, and admittance whole-body control for system robustness and controllability. MOMA-Force enables a mobile manipulator to learn multiple complex contact-rich tasks with high success rates and small contact forces. In a real household setting, our method outperforms baseline methods in terms of task success rates. Moreover, our method achieves smaller contact forces and smaller force variances compared to baseline methods without force imitation. Overall, we offer a promising approach for efficient and robust mobile manipulation in the real world. Videos and more details can be found on \\url{https://visual-force-imitation.github.io}","sentences":["In this paper, we present a novel method for mobile manipulators to perform multiple contact-rich manipulation tasks.","While learning-based methods have the potential to generate actions in an end-to-end manner, they often suffer from insufficient action accuracy and robustness against noise.","On the other hand, classical control-based methods can enhance system robustness, but at the cost of extensive parameter tuning.","To address these challenges, we present MOMA-Force, a visual-force imitation method that seamlessly combines representation learning for perception, imitation learning for complex motion generation, and admittance whole-body control for system robustness and controllability.","MOMA-Force enables a mobile manipulator to learn multiple complex contact-rich tasks with high success rates and small contact forces.","In a real household setting, our method outperforms baseline methods in terms of task success rates.","Moreover, our method achieves smaller contact forces and smaller force variances compared to baseline methods without force imitation.","Overall, we offer a promising approach for efficient and robust mobile manipulation in the real world.","Videos and more details can be found on \\url{https://visual-force-imitation.github.io}"],"url":"http://arxiv.org/abs/2308.03624v1"}
{"created":"2023-08-07 14:24:52","title":"Exploring Visual Pre-training for Robot Manipulation: Datasets, Models and Methods","abstract":"Visual pre-training with large-scale real-world data has made great progress in recent years, showing great potential in robot learning with pixel observations. However, the recipes of visual pre-training for robot manipulation tasks are yet to be built. In this paper, we thoroughly investigate the effects of visual pre-training strategies on robot manipulation tasks from three fundamental perspectives: pre-training datasets, model architectures and training methods. Several significant experimental findings are provided that are beneficial for robot learning. Further, we propose a visual pre-training scheme for robot manipulation termed Vi-PRoM, which combines self-supervised learning and supervised learning. Concretely, the former employs contrastive learning to acquire underlying patterns from large-scale unlabeled data, while the latter aims learning visual semantics and temporal dynamics. Extensive experiments on robot manipulations in various simulation environments and the real robot demonstrate the superiority of the proposed scheme. Videos and more details can be found on \\url{https://explore-pretrain-robot.github.io}.","sentences":["Visual pre-training with large-scale real-world data has made great progress in recent years, showing great potential in robot learning with pixel observations.","However, the recipes of visual pre-training for robot manipulation tasks are yet to be built.","In this paper, we thoroughly investigate the effects of visual pre-training strategies on robot manipulation tasks from three fundamental perspectives: pre-training datasets, model architectures and training methods.","Several significant experimental findings are provided that are beneficial for robot learning.","Further, we propose a visual pre-training scheme for robot manipulation termed Vi-PRoM, which combines self-supervised learning and supervised learning.","Concretely, the former employs contrastive learning to acquire underlying patterns from large-scale unlabeled data, while the latter aims learning visual semantics and temporal dynamics.","Extensive experiments on robot manipulations in various simulation environments and the real robot demonstrate the superiority of the proposed scheme.","Videos and more details can be found on \\url{https://explore-pretrain-robot.github.io}."],"url":"http://arxiv.org/abs/2308.03620v1"}
{"created":"2023-08-07 14:21:15","title":"MeTACAST: Target- and Context-aware Spatial Selection in VR","abstract":"We propose three novel spatial data selection techniques for particle data in VR visualization environments. They are designed to be target- and context-aware and be suitable for a wide range of data features and complex scenarios. Each technique is designed to be adjusted to particular selection intents: the selection of consecutive dense regions, the selection of filament-like structures, and the selection of clusters -- with all of them facilitating post-selection threshold adjustment. These techniques allow users to precisely select those regions of space for further exploration -- with simple and approximate 3D pointing, brushing, or drawing input -- using flexible point- or path-based input and without being limited by 3D occlusions, non-homogeneous feature density, or complex data shapes. These new techniques are evaluated in a controlled experiment and compared with the Baseline method, a region-based 3D painting selection. Our results indicate that our techniques are effective in handling a wide range of scenarios and allow users to select data based on their comprehension of crucial features. Furthermore, we analyze the attributes, requirements, and strategies of our spatial selection methods and compare them with existing state-of-the-art selection methods to handle diverse data features and situations. Based on this analysis we provide guidelines for choosing the most suitable 3D spatial selection techniques based on the interaction environment, the given data characteristics, or the need for interactive post-selection threshold adjustment.","sentences":["We propose three novel spatial data selection techniques for particle data in VR visualization environments.","They are designed to be target- and context-aware and be suitable for a wide range of data features and complex scenarios.","Each technique is designed to be adjusted to particular selection intents: the selection of consecutive dense regions, the selection of filament-like structures, and the selection of clusters -- with all of them facilitating post-selection threshold adjustment.","These techniques allow users to precisely select those regions of space for further exploration -- with simple and approximate 3D pointing, brushing, or drawing input -- using flexible point- or path-based input and without being limited by 3D occlusions, non-homogeneous feature density, or complex data shapes.","These new techniques are evaluated in a controlled experiment and compared with the Baseline method, a region-based 3D painting selection.","Our results indicate that our techniques are effective in handling a wide range of scenarios and allow users to select data based on their comprehension of crucial features.","Furthermore, we analyze the attributes, requirements, and strategies of our spatial selection methods and compare them with existing state-of-the-art selection methods to handle diverse data features and situations.","Based on this analysis we provide guidelines for choosing the most suitable 3D spatial selection techniques based on the interaction environment, the given data characteristics, or the need for interactive post-selection threshold adjustment."],"url":"http://arxiv.org/abs/2308.03616v1"}
{"created":"2023-08-07 14:20:02","title":"Dirigo: Self-scaling Stateful Actors For Serverless Real-time Data Processing","abstract":"We propose Dirigo, a distributed stream processing service built atop virtual actors. Dirigo achieves both a high level of resource efficiency and performance isolation driven by user intent (SLO). To improve resource efficiency, Dirigo adopts a serverless architecture that enables time-sharing of compute resources among streaming operators, both within and across applications. Meanwhile, Dirigo improves performance isolation by inheriting the property of function autoscaling from serverless architecture. Specifically, Dirigo proposes (i) dual-mode actor, an actor abstraction that dynamically provides orderliness guarantee for streaming operator during autoscaling and (ii) a data plane scheduling mechanism, along with its API, that allows scheduling and scaling at the message-level granularity.","sentences":["We propose Dirigo, a distributed stream processing service built atop virtual actors.","Dirigo achieves both a high level of resource efficiency and performance isolation driven by user intent (SLO).","To improve resource efficiency, Dirigo adopts a serverless architecture that enables time-sharing of compute resources among streaming operators, both within and across applications.","Meanwhile, Dirigo improves performance isolation by inheriting the property of function autoscaling from serverless architecture.","Specifically, Dirigo proposes (i) dual-mode actor, an actor abstraction that dynamically provides orderliness guarantee for streaming operator during autoscaling and (ii) a data plane scheduling mechanism, along with its API, that allows scheduling and scaling at the message-level granularity."],"url":"http://arxiv.org/abs/2308.03615v1"}
{"created":"2023-08-07 14:09:46","title":"AvatarVerse: High-quality & Stable 3D Avatar Creation from Text and Pose","abstract":"Creating expressive, diverse and high-quality 3D avatars from highly customized text descriptions and pose guidance is a challenging task, due to the intricacy of modeling and texturing in 3D that ensure details and various styles (realistic, fictional, etc). We present AvatarVerse, a stable pipeline for generating expressive high-quality 3D avatars from nothing but text descriptions and pose guidance. In specific, we introduce a 2D diffusion model conditioned on DensePose signal to establish 3D pose control of avatars through 2D images, which enhances view consistency from partially observed scenarios. It addresses the infamous Janus Problem and significantly stablizes the generation process. Moreover, we propose a progressive high-resolution 3D synthesis strategy, which obtains substantial improvement over the quality of the created 3D avatars. To this end, the proposed AvatarVerse pipeline achieves zero-shot 3D modeling of 3D avatars that are not only more expressive, but also in higher quality and fidelity than previous works. Rigorous qualitative evaluations and user studies showcase AvatarVerse's superiority in synthesizing high-fidelity 3D avatars, leading to a new standard in high-quality and stable 3D avatar creation. Our project page is: https://avatarverse3d.github.io","sentences":["Creating expressive, diverse and high-quality 3D avatars from highly customized text descriptions and pose guidance is a challenging task, due to the intricacy of modeling and texturing in 3D that ensure details and various styles (realistic, fictional, etc).","We present AvatarVerse, a stable pipeline for generating expressive high-quality 3D avatars from nothing but text descriptions and pose guidance.","In specific, we introduce a 2D diffusion model conditioned on DensePose signal to establish 3D pose control of avatars through 2D images, which enhances view consistency from partially observed scenarios.","It addresses the infamous Janus Problem and significantly stablizes the generation process.","Moreover, we propose a progressive high-resolution 3D synthesis strategy, which obtains substantial improvement over the quality of the created 3D avatars.","To this end, the proposed AvatarVerse pipeline achieves zero-shot 3D modeling of 3D avatars that are not only more expressive, but also in higher quality and fidelity than previous works.","Rigorous qualitative evaluations and user studies showcase AvatarVerse's superiority in synthesizing high-fidelity 3D avatars, leading to a new standard in high-quality and stable 3D avatar creation.","Our project page is: https://avatarverse3d.github.io"],"url":"http://arxiv.org/abs/2308.03610v1"}
{"created":"2023-08-07 14:09:08","title":"Recurrent Self-Supervised Video Denoising with Denser Receptive Field","abstract":"Self-supervised video denoising has seen decent progress through the use of blind spot networks. However, under their blind spot constraints, previous self-supervised video denoising methods suffer from significant information loss and texture destruction in either the whole reference frame or neighbor frames, due to their inadequate consideration of the receptive field. Moreover, the limited number of available neighbor frames in previous methods leads to the discarding of distant temporal information. Nonetheless, simply adopting existing recurrent frameworks does not work, since they easily break the constraints on the receptive field imposed by self-supervision. In this paper, we propose RDRF for self-supervised video denoising, which not only fully exploits both the reference and neighbor frames with a denser receptive field, but also better leverages the temporal information from both local and distant neighbor features. First, towards a comprehensive utilization of information from both reference and neighbor frames, RDRF realizes a denser receptive field by taking more neighbor pixels along the spatial and temporal dimensions. Second, it features a self-supervised recurrent video denoising framework, which concurrently integrates distant and near-neighbor temporal features. This enables long-term bidirectional information aggregation, while mitigating error accumulation in the plain recurrent framework. Our method exhibits superior performance on both synthetic and real video denoising datasets. Codes will be available at https://github.com/Wang-XIaoDingdd/RDRF.","sentences":["Self-supervised video denoising has seen decent progress through the use of blind spot networks.","However, under their blind spot constraints, previous self-supervised video denoising methods suffer from significant information loss and texture destruction in either the whole reference frame or neighbor frames, due to their inadequate consideration of the receptive field.","Moreover, the limited number of available neighbor frames in previous methods leads to the discarding of distant temporal information.","Nonetheless, simply adopting existing recurrent frameworks does not work, since they easily break the constraints on the receptive field imposed by self-supervision.","In this paper, we propose RDRF for self-supervised video denoising, which not only fully exploits both the reference and neighbor frames with a denser receptive field, but also better leverages the temporal information from both local and distant neighbor features.","First, towards a comprehensive utilization of information from both reference and neighbor frames, RDRF realizes a denser receptive field by taking more neighbor pixels along the spatial and temporal dimensions.","Second, it features a self-supervised recurrent video denoising framework, which concurrently integrates distant and near-neighbor temporal features.","This enables long-term bidirectional information aggregation, while mitigating error accumulation in the plain recurrent framework.","Our method exhibits superior performance on both synthetic and real video denoising datasets.","Codes will be available at https://github.com/Wang-XIaoDingdd/RDRF."],"url":"http://arxiv.org/abs/2308.03608v1"}
{"created":"2023-08-07 14:04:15","title":"Negative Lexical Constraints in Neural Machine Translation","abstract":"This paper explores negative lexical constraining in English to Czech neural machine translation. Negative lexical constraining is used to prohibit certain words or expressions in the translation produced by the neural translation model. We compared various methods based on modifying either the decoding process or the training data. The comparison was performed on two tasks: paraphrasing and feedback-based translation refinement. We also studied to which extent these methods \"evade\" the constraints presented to the model (usually in the dictionary form) by generating a different surface form of a given constraint.We propose a way to mitigate the issue through training with stemmed negative constraints to counter the model's ability to induce a variety of the surface forms of a word that can result in bypassing the constraint. We demonstrate that our method improves the constraining, although the problem still persists in many cases.","sentences":["This paper explores negative lexical constraining in English to Czech neural machine translation.","Negative lexical constraining is used to prohibit certain words or expressions in the translation produced by the neural translation model.","We compared various methods based on modifying either the decoding process or the training data.","The comparison was performed on two tasks: paraphrasing and feedback-based translation refinement.","We also studied to which extent these methods \"evade\" the constraints presented to the model (usually in the dictionary form) by generating a different surface form of a given constraint.","We propose a way to mitigate the issue through training with stemmed negative constraints to counter the model's ability to induce a variety of the surface forms of a word that can result in bypassing the constraint.","We demonstrate that our method improves the constraining, although the problem still persists in many cases."],"url":"http://arxiv.org/abs/2308.03601v1"}
{"created":"2023-08-07 13:59:31","title":"Why We Don't Have AGI Yet","abstract":"The original vision of AI was re-articulated in 2002 via the term 'Artificial General Intelligence' or AGI. This vision is to build 'Thinking Machines' - computer systems that can learn, reason, and solve problems similar to the way humans do. This is in stark contrast to the 'Narrow AI' approach practiced by almost everyone in the field over the many decades. While several large-scale efforts have nominally been working on AGI (most notably DeepMind), the field of pure focused AGI development has not been well funded or promoted. This is surprising given the fantastic value that true AGI can bestow on humanity. In addition to the dearth of effort in this field, there are also several theoretical and methodical missteps that are hampering progress. We highlight why purely statistical approaches are unlikely to lead to AGI, and identify several crucial cognitive abilities required to achieve human-like adaptability and autonomous learning. We conclude with a survey of socio-technical factors that have undoubtedly slowed progress towards AGI.","sentences":["The original vision of AI was re-articulated in 2002 via the term 'Artificial General Intelligence' or AGI.","This vision is to build 'Thinking Machines' - computer systems that can learn, reason, and solve problems similar to the way humans do.","This is in stark contrast to the 'Narrow AI' approach practiced by almost everyone in the field over the many decades.","While several large-scale efforts have nominally been working on AGI (most notably DeepMind), the field of pure focused AGI development has not been well funded or promoted.","This is surprising given the fantastic value that true AGI can bestow on humanity.","In addition to the dearth of effort in this field, there are also several theoretical and methodical missteps that are hampering progress.","We highlight why purely statistical approaches are unlikely to lead to AGI, and identify several crucial cognitive abilities required to achieve human-like adaptability and autonomous learning.","We conclude with a survey of socio-technical factors that have undoubtedly slowed progress towards AGI."],"url":"http://arxiv.org/abs/2308.03598v1"}
{"created":"2023-08-07 13:52:21","title":"FeatEnHancer: Enhancing Hierarchical Features for Object Detection and Beyond Under Low-Light Vision","abstract":"Extracting useful visual cues for the downstream tasks is especially challenging under low-light vision. Prior works create enhanced representations by either correlating visual quality with machine perception or designing illumination-degrading transformation methods that require pre-training on synthetic datasets. We argue that optimizing enhanced image representation pertaining to the loss of the downstream task can result in more expressive representations. Therefore, in this work, we propose a novel module, FeatEnHancer, that hierarchically combines multiscale features using multiheaded attention guided by task-related loss function to create suitable representations. Furthermore, our intra-scale enhancement improves the quality of features extracted at each scale or level, as well as combines features from different scales in a way that reflects their relative importance for the task at hand. FeatEnHancer is a general-purpose plug-and-play module and can be incorporated into any low-light vision pipeline. We show with extensive experimentation that the enhanced representation produced with FeatEnHancer significantly and consistently improves results in several low-light vision tasks, including dark object detection (+5.7 mAP on ExDark), face detection (+1.5 mAPon DARK FACE), nighttime semantic segmentation (+5.1 mIoU on ACDC ), and video object detection (+1.8 mAP on DarkVision), highlighting the effectiveness of enhancing hierarchical features under low-light vision.","sentences":["Extracting useful visual cues for the downstream tasks is especially challenging under low-light vision.","Prior works create enhanced representations by either correlating visual quality with machine perception or designing illumination-degrading transformation methods that require pre-training on synthetic datasets.","We argue that optimizing enhanced image representation pertaining to the loss of the downstream task can result in more expressive representations.","Therefore, in this work, we propose a novel module, FeatEnHancer, that hierarchically combines multiscale features using multiheaded attention guided by task-related loss function to create suitable representations.","Furthermore, our intra-scale enhancement improves the quality of features extracted at each scale or level, as well as combines features from different scales in a way that reflects their relative importance for the task at hand.","FeatEnHancer is a general-purpose plug-and-play module and can be incorporated into any low-light vision pipeline.","We show with extensive experimentation that the enhanced representation produced with FeatEnHancer significantly and consistently improves results in several low-light vision tasks, including dark object detection (+5.7 mAP on ExDark), face detection (+1.5 mAPon DARK FACE), nighttime semantic segmentation (+5.1 mIoU on ACDC ), and video object detection (+1.8 mAP on DarkVision), highlighting the effectiveness of enhancing hierarchical features under low-light vision."],"url":"http://arxiv.org/abs/2308.03594v1"}
{"created":"2023-08-07 13:46:18","title":"Feature Importance versus Feature Influence and What It Signifies for Explainable AI","abstract":"When used in the context of decision theory, feature importance expresses how much changing the value of a feature can change the model outcome (or the utility of the outcome), compared to other features. Feature importance should not be confused with the feature influence used by most state-of-the-art post-hoc Explainable AI methods. Contrary to feature importance, feature influence is measured against a reference level or baseline. The Contextual Importance and Utility (CIU) method provides a unified definition of global and local feature importance that is applicable also for post-hoc explanations, where the value utility concept provides instance-level assessment of how favorable or not a feature value is for the outcome. The paper shows how CIU can be applied to both global and local explainability, assesses the fidelity and stability of different methods, and shows how explanations that use contextual importance and contextual utility can provide more expressive and flexible explanations than when using influence only.","sentences":["When used in the context of decision theory, feature importance expresses how much changing the value of a feature can change the model outcome (or the utility of the outcome), compared to other features.","Feature importance should not be confused with the feature influence used by most state-of-the-art post-hoc Explainable AI methods.","Contrary to feature importance, feature influence is measured against a reference level or baseline.","The Contextual Importance and Utility (CIU) method provides a unified definition of global and local feature importance that is applicable also for post-hoc explanations, where the value utility concept provides instance-level assessment of how favorable or not a feature value is for the outcome.","The paper shows how CIU can be applied to both global and local explainability, assesses the fidelity and stability of different methods, and shows how explanations that use contextual importance and contextual utility can provide more expressive and flexible explanations than when using influence only."],"url":"http://arxiv.org/abs/2308.03589v1"}
{"created":"2023-08-07 13:45:48","title":"Multi-View Graph Convolutional Network for Multimedia Recommendation","abstract":"Multimedia recommendation has received much attention in recent years. It models user preferences based on both behavior information and item multimodal information. Though current GCN-based methods achieve notable success, they suffer from two limitations: (1) Modality noise contamination to the item representations. Existing methods often mix modality features and behavior features in a single view (e.g., user-item view) for propagation, the noise in the modality features may be amplified and coupled with behavior features. In the end, it leads to poor feature discriminability; (2) Incomplete user preference modeling caused by equal treatment of modality features. Users often exhibit distinct modality preferences when purchasing different items. Equally fusing each modality feature ignores the relative importance among different modalities, leading to the suboptimal user preference modeling. To tackle the above issues, we propose a novel Multi-View Graph Convolutional Network for the multimedia recommendation. Specifically, to avoid modality noise contamination, the modality features are first purified with the aid of item behavior information. Then, the purified modality features of items and behavior features are enriched in separate views, including the user-item view and the item-item view. In this way, the distinguishability of features is enhanced. Meanwhile, a behavior-aware fuser is designed to comprehensively model user preferences by adaptively learning the relative importance of different modality features. Furthermore, we equip the fuser with a self-supervised auxiliary task. This task is expected to maximize the mutual information between the fused multimodal features and behavior features, so as to capture complementary and supplementary preference information simultaneously. Extensive experiments on three public datasets demonstrate the effectiveness of our methods.","sentences":["Multimedia recommendation has received much attention in recent years.","It models user preferences based on both behavior information and item multimodal information.","Though current GCN-based methods achieve notable success, they suffer from two limitations: (1) Modality noise contamination to the item representations.","Existing methods often mix modality features and behavior features in a single view (e.g., user-item view) for propagation, the noise in the modality features may be amplified and coupled with behavior features.","In the end, it leads to poor feature discriminability; (2) Incomplete user preference modeling caused by equal treatment of modality features.","Users often exhibit distinct modality preferences when purchasing different items.","Equally fusing each modality feature ignores the relative importance among different modalities, leading to the suboptimal user preference modeling.","To tackle the above issues, we propose a novel Multi-View Graph Convolutional Network for the multimedia recommendation.","Specifically, to avoid modality noise contamination, the modality features are first purified with the aid of item behavior information.","Then, the purified modality features of items and behavior features are enriched in separate views, including the user-item view and the item-item view.","In this way, the distinguishability of features is enhanced.","Meanwhile, a behavior-aware fuser is designed to comprehensively model user preferences by adaptively learning the relative importance of different modality features.","Furthermore, we equip the fuser with a self-supervised auxiliary task.","This task is expected to maximize the mutual information between the fused multimodal features and behavior features, so as to capture complementary and supplementary preference information simultaneously.","Extensive experiments on three public datasets demonstrate the effectiveness of our methods."],"url":"http://arxiv.org/abs/2308.03588v1"}
{"created":"2023-08-07 13:44:44","title":"SoilNet: An Attention-based Spatio-temporal Deep Learning Framework for Soil Organic Carbon Prediction with Digital Soil Mapping in Europe","abstract":"Digital soil mapping (DSM) is an advanced approach that integrates statistical modeling and cutting-edge technologies, including machine learning (ML) methods, to accurately depict soil properties and their spatial distribution. Soil organic carbon (SOC) is a crucial soil attribute providing valuable insights into soil health, nutrient cycling, greenhouse gas emissions, and overall ecosystem productivity. This study highlights the significance of spatial-temporal deep learning (DL) techniques within the DSM framework. A novel architecture is proposed, incorporating spatial information using a base convolutional neural network (CNN) model and spatial attention mechanism, along with climate temporal information using a long short-term memory (LSTM) network, for SOC prediction across Europe. The model utilizes a comprehensive set of environmental features, including Landsat-8 images, topography, remote sensing indices, and climate time series, as input features. Results demonstrate that the proposed framework outperforms conventional ML approaches like random forest commonly used in DSM, yielding lower root mean square error (RMSE). This model is a robust tool for predicting SOC and could be applied to other soil properties, thereby contributing to the advancement of DSM techniques and facilitating land management and decision-making processes based on accurate information.","sentences":["Digital soil mapping (DSM) is an advanced approach that integrates statistical modeling and cutting-edge technologies, including machine learning (ML) methods, to accurately depict soil properties and their spatial distribution.","Soil organic carbon (SOC) is a crucial soil attribute providing valuable insights into soil health, nutrient cycling, greenhouse gas emissions, and overall ecosystem productivity.","This study highlights the significance of spatial-temporal deep learning (DL) techniques within the DSM framework.","A novel architecture is proposed, incorporating spatial information using a base convolutional neural network (CNN) model and spatial attention mechanism, along with climate temporal information using a long short-term memory (LSTM) network, for SOC prediction across Europe.","The model utilizes a comprehensive set of environmental features, including Landsat-8 images, topography, remote sensing indices, and climate time series, as input features.","Results demonstrate that the proposed framework outperforms conventional ML approaches like random forest commonly used in DSM, yielding lower root mean square error (RMSE).","This model is a robust tool for predicting SOC and could be applied to other soil properties, thereby contributing to the advancement of DSM techniques and facilitating land management and decision-making processes based on accurate information."],"url":"http://arxiv.org/abs/2308.03586v1"}
{"created":"2023-08-07 13:42:38","title":"A Polystore Architecture Using Knowledge Graphs to Support Queries on Heterogeneous Data Stores","abstract":"Modern applications commonly need to manage dataset types composed of heterogeneous data and schemas, making it difficult to access them in an integrated way. A single data store to manage heterogeneous data using a common data model is not effective in such a scenario, which results in the domain data being fragmented in the data stores that best fit their storage and access requirements (e.g., NoSQL, relational DBMS, or HDFS). Besides, organization workflows independently consume these fragments, and usually, there is no explicit link among the fragments that would be useful to support an integrated view. The research challenge tackled by this work is to provide the means to query heterogeneous data residing on distinct data repositories that are not explicitly connected. We propose a federated database architecture by providing a single abstract global conceptual schema to users, allowing them to write their queries, encapsulating data heterogeneity, location, and linkage by employing: (i) meta-models to represent the global conceptual schema, the remote data local conceptual schemas, and mappings among them; (ii) provenance to create explicit links among the consumed and generated data residing in separate datasets. We evaluated the architecture through its implementation as a polystore service, following a microservice architecture approach, in a scenario that simulates a real case in Oil \\& Gas industry. Also, we compared the proposed architecture to a relational multidatabase system based on foreign data wrappers, measuring the user's cognitive load to write a query (or query complexity) and the query processing time. The results demonstrated that the proposed architecture allows query writing two times less complex than the one written for the relational multidatabase system, adding an excess of no more than 30% in query processing time.","sentences":["Modern applications commonly need to manage dataset types composed of heterogeneous data and schemas, making it difficult to access them in an integrated way.","A single data store to manage heterogeneous data using a common data model is not effective in such a scenario, which results in the domain data being fragmented in the data stores that best fit their storage and access requirements (e.g., NoSQL, relational DBMS, or HDFS).","Besides, organization workflows independently consume these fragments, and usually, there is no explicit link among the fragments that would be useful to support an integrated view.","The research challenge tackled by this work is to provide the means to query heterogeneous data residing on distinct data repositories that are not explicitly connected.","We propose a federated database architecture by providing a single abstract global conceptual schema to users, allowing them to write their queries, encapsulating data heterogeneity, location, and linkage by employing: (i) meta-models to represent the global conceptual schema, the remote data local conceptual schemas, and mappings among them; (ii) provenance to create explicit links among the consumed and generated data residing in separate datasets.","We evaluated the architecture through its implementation as a polystore service, following a microservice architecture approach, in a scenario that simulates a real case in Oil \\& Gas industry.","Also, we compared the proposed architecture to a relational multidatabase system based on foreign data wrappers, measuring the user's cognitive load to write a query (or query complexity) and the query processing time.","The results demonstrated that the proposed architecture allows query writing two times less complex than the one written for the relational multidatabase system, adding an excess of no more than 30% in query processing time."],"url":"http://arxiv.org/abs/2308.03584v1"}
{"created":"2023-08-07 13:38:54","title":"WIKITIDE: A Wikipedia-Based Timestamped Definition Pairs Dataset","abstract":"A fundamental challenge in the current NLP context, dominated by language models, comes from the inflexibility of current architectures to 'learn' new information. While model-centric solutions like continual learning or parameter-efficient fine tuning are available, the question still remains of how to reliably identify changes in language or in the world. In this paper, we propose WikiTiDe, a dataset derived from pairs of timestamped definitions extracted from Wikipedia. We argue that such resource can be helpful for accelerating diachronic NLP, specifically, for training models able to scan knowledge resources for core updates concerning a concept, an event, or a named entity. Our proposed end-to-end method is fully automatic, and leverages a bootstrapping algorithm for gradually creating a high-quality dataset. Our results suggest that bootstrapping the seed version of WikiTiDe leads to better fine-tuned models. We also leverage fine-tuned models in a number of downstream tasks, showing promising results with respect to competitive baselines.","sentences":["A fundamental challenge in the current NLP context, dominated by language models, comes from the inflexibility of current architectures to 'learn' new information.","While model-centric solutions like continual learning or parameter-efficient fine tuning are available, the question still remains of how to reliably identify changes in language or in the world.","In this paper, we propose WikiTiDe, a dataset derived from pairs of timestamped definitions extracted from Wikipedia.","We argue that such resource can be helpful for accelerating diachronic NLP, specifically, for training models able to scan knowledge resources for core updates concerning a concept, an event, or a named entity.","Our proposed end-to-end method is fully automatic, and leverages a bootstrapping algorithm for gradually creating a high-quality dataset.","Our results suggest that bootstrapping the seed version of WikiTiDe leads to better fine-tuned models.","We also leverage fine-tuned models in a number of downstream tasks, showing promising results with respect to competitive baselines."],"url":"http://arxiv.org/abs/2308.03582v1"}
{"created":"2023-08-07 13:37:05","title":"Towards Controllable Natural Language Inference through Lexical Inference Types","abstract":"Explainable natural language inference aims to provide a mechanism to produce explanatory (abductive) inference chains which ground claims to their supporting premises. A recent corpus called EntailmentBank strives to advance this task by explaining the answer to a question using an entailment tree \\cite{dalvi2021explaining}. They employ the T5 model to directly generate the tree, which can explain how the answer is inferred. However, it lacks the ability to explain and control the generation of intermediate steps, which is crucial for the multi-hop inference process. % One recent corpus, EntailmentBank, aims to push this task forward by explaining an answer to a question according to an entailment tree \\cite{dalvi2021explaining}. They employ T5 to generate the tree directly, which can explain how the answer is inferred but cannot explain how the intermediate is generated, which is essential to the multi-hop inference process. In this work, we focus on proposing a controlled natural language inference architecture for multi-premise explanatory inference. To improve control and enable explanatory analysis over the generation, we define lexical inference types based on Abstract Meaning Representation (AMR) graph and modify the architecture of T5 to learn a latent sentence representation (T5 bottleneck) conditioned on said type information. We also deliver a dataset of approximately 5000 annotated explanatory inference steps, with well-grounded lexical-symbolic operations. Experimental results indicate that the inference typing induced at the T5 bottleneck can help T5 to generate a conclusion under explicit control.","sentences":["Explainable natural language inference aims to provide a mechanism to produce explanatory (abductive) inference chains which ground claims to their supporting premises.","A recent corpus called EntailmentBank strives to advance this task by explaining the answer to a question using an entailment tree \\cite{dalvi2021explaining}.","They employ the T5 model to directly generate the tree, which can explain how the answer is inferred.","However, it lacks the ability to explain and control the generation of intermediate steps, which is crucial for the multi-hop inference process.","%","One recent corpus, EntailmentBank, aims to push this task forward by explaining an answer to a question according to an entailment tree \\cite{dalvi2021explaining}.","They employ T5 to generate the tree directly, which can explain how the answer is inferred but cannot explain how the intermediate is generated, which is essential to the multi-hop inference process.","In this work, we focus on proposing a controlled natural language inference architecture for multi-premise explanatory inference.","To improve control and enable explanatory analysis over the generation, we define lexical inference types based on Abstract Meaning Representation (AMR) graph and modify the architecture of T5 to learn a latent sentence representation (T5 bottleneck) conditioned on said type information.","We also deliver a dataset of approximately 5000 annotated explanatory inference steps, with well-grounded lexical-symbolic operations.","Experimental results indicate that the inference typing induced at the T5 bottleneck can help T5 to generate a conclusion under explicit control."],"url":"http://arxiv.org/abs/2308.03581v1"}
{"created":"2023-08-07 13:35:53","title":"Revealing the Underlying Patterns: Investigating Dataset Similarity, Performance, and Generalization","abstract":"Supervised deep learning models require significant amount of labelled data to achieve an acceptable performance on a specific task. However, when tested on unseen data, the models may not perform well. Therefore, the models need to be trained with additional and varying labelled data to improve the generalization. In this work, our goal is to understand the models, their performance and generalization. We establish image-image, dataset-dataset, and image-dataset distances to gain insights into the model's behavior. Our proposed distance metric when combined with model performance can help in selecting an appropriate model/architecture from a pool of candidate architectures. We have shown that the generalization of these models can be improved by only adding a small number of unseen images (say 1, 3 or 7) into the training set. Our proposed approach reduces training and annotation costs while providing an estimate of model performance on unseen data in dynamic environments.","sentences":["Supervised deep learning models require significant amount of labelled data to achieve an acceptable performance on a specific task.","However, when tested on unseen data, the models may not perform well.","Therefore, the models need to be trained with additional and varying labelled data to improve the generalization.","In this work, our goal is to understand the models, their performance and generalization.","We establish image-image, dataset-dataset, and image-dataset distances to gain insights into the model's behavior.","Our proposed distance metric when combined with model performance can help in selecting an appropriate model/architecture from a pool of candidate architectures.","We have shown that the generalization of these models can be improved by only adding a small number of unseen images (say 1, 3 or 7) into the training set.","Our proposed approach reduces training and annotation costs while providing an estimate of model performance on unseen data in dynamic environments."],"url":"http://arxiv.org/abs/2308.03580v1"}
{"created":"2023-08-07 13:35:02","title":"TeraHAC: Hierarchical Agglomerative Clustering of Trillion-Edge Graphs","abstract":"We introduce TeraHAC, a $(1+\\epsilon)$-approximate hierarchical agglomerative clustering (HAC) algorithm which scales to trillion-edge graphs. Our algorithm is based on a new approach to computing $(1+\\epsilon)$-approximate HAC, which is a novel combination of the nearest-neighbor chain algorithm and the notion of $(1+\\epsilon)$-approximate HAC. Our approach allows us to partition the graph among multiple machines and make significant progress in computing the clustering within each partition before any communication with other partitions is needed.   We evaluate TeraHAC on a number of real-world and synthetic graphs of up to 8 trillion edges. We show that TeraHAC requires over 100x fewer rounds compared to previously known approaches for computing HAC. It is up to 8.3x faster than SCC, the state-of-the-art distributed algorithm for hierarchical clustering, while achieving 1.16x higher quality. In fact, TeraHAC essentially retains the quality of the celebrated HAC algorithm while significantly improving the running time.","sentences":["We introduce TeraHAC, a $(1+\\epsilon)$-approximate hierarchical agglomerative clustering (HAC) algorithm which scales to trillion-edge graphs.","Our algorithm is based on a new approach to computing $(1+\\epsilon)$-approximate HAC, which is a novel combination of the nearest-neighbor chain algorithm and the notion of $(1+\\epsilon)$-approximate HAC.","Our approach allows us to partition the graph among multiple machines and make significant progress in computing the clustering within each partition before any communication with other partitions is needed.   ","We evaluate TeraHAC on a number of real-world and synthetic graphs of up to 8 trillion edges.","We show that TeraHAC requires over 100x fewer rounds compared to previously known approaches for computing HAC.","It is up to 8.3x faster than SCC, the state-of-the-art distributed algorithm for hierarchical clustering, while achieving 1.16x higher quality.","In fact, TeraHAC essentially retains the quality of the celebrated HAC algorithm while significantly improving the running time."],"url":"http://arxiv.org/abs/2308.03578v1"}
{"created":"2023-08-07 13:24:52","title":"When Federated Learning meets Watermarking: A Comprehensive Overview of Techniques for Intellectual Property Protection","abstract":"Federated Learning (FL) is a technique that allows multiple participants to collaboratively train a Deep Neural Network (DNN) without the need of centralizing their data. Among other advantages, it comes with privacy-preserving properties making it attractive for application in sensitive contexts, such as health care or the military. Although the data are not explicitly exchanged, the training procedure requires sharing information about participants' models. This makes the individual models vulnerable to theft or unauthorized distribution by malicious actors. To address the issue of ownership rights protection in the context of Machine Learning (ML), DNN Watermarking methods have been developed during the last five years. Most existing works have focused on watermarking in a centralized manner, but only a few methods have been designed for FL and its unique constraints. In this paper, we provide an overview of recent advancements in Federated Learning watermarking, shedding light on the new challenges and opportunities that arise in this field.","sentences":["Federated Learning (FL) is a technique that allows multiple participants to collaboratively train a Deep Neural Network (DNN) without the need of centralizing their data.","Among other advantages, it comes with privacy-preserving properties making it attractive for application in sensitive contexts, such as health care or the military.","Although the data are not explicitly exchanged, the training procedure requires sharing information about participants' models.","This makes the individual models vulnerable to theft or unauthorized distribution by malicious actors.","To address the issue of ownership rights protection in the context of Machine Learning (ML), DNN Watermarking methods have been developed during the last five years.","Most existing works have focused on watermarking in a centralized manner, but only a few methods have been designed for FL and its unique constraints.","In this paper, we provide an overview of recent advancements in Federated Learning watermarking, shedding light on the new challenges and opportunities that arise in this field."],"url":"http://arxiv.org/abs/2308.03573v1"}
{"created":"2023-08-07 13:24:50","title":"Provably Efficient Learning in Partially Observable Contextual Bandit","abstract":"In this paper, we investigate transfer learning in partially observable contextual bandits, where agents have limited knowledge from other agents and partial information about hidden confounders. We first convert the problem to identifying or partially identifying causal effects between actions and rewards through optimization problems. To solve these optimization problems, we discretize the original functional constraints of unknown distributions into linear constraints, and sample compatible causal models via sequentially solving linear programmings to obtain causal bounds with the consideration of estimation error. Our sampling algorithms provide desirable convergence results for suitable sampling distributions. We then show how causal bounds can be applied to improving classical bandit algorithms and affect the regrets with respect to the size of action sets and function spaces. Notably, in the task with function approximation which allows us to handle general context distributions, our method improves the order dependence on function space size compared with previous literatures. We formally prove that our causally enhanced algorithms outperform classical bandit algorithms and achieve orders of magnitude faster convergence rates. Finally, we perform simulations that demonstrate the efficiency of our strategy compared to the current state-of-the-art methods. This research has the potential to enhance the performance of contextual bandit agents in real-world applications where data is scarce and costly to obtain.","sentences":["In this paper, we investigate transfer learning in partially observable contextual bandits, where agents have limited knowledge from other agents and partial information about hidden confounders.","We first convert the problem to identifying or partially identifying causal effects between actions and rewards through optimization problems.","To solve these optimization problems, we discretize the original functional constraints of unknown distributions into linear constraints, and sample compatible causal models via sequentially solving linear programmings to obtain causal bounds with the consideration of estimation error.","Our sampling algorithms provide desirable convergence results for suitable sampling distributions.","We then show how causal bounds can be applied to improving classical bandit algorithms and affect the regrets with respect to the size of action sets and function spaces.","Notably, in the task with function approximation which allows us to handle general context distributions, our method improves the order dependence on function space size compared with previous literatures.","We formally prove that our causally enhanced algorithms outperform classical bandit algorithms and achieve orders of magnitude faster convergence rates.","Finally, we perform simulations that demonstrate the efficiency of our strategy compared to the current state-of-the-art methods.","This research has the potential to enhance the performance of contextual bandit agents in real-world applications where data is scarce and costly to obtain."],"url":"http://arxiv.org/abs/2308.03572v1"}
{"created":"2023-08-07 13:16:42","title":"Topological Interpretations of GPT-3","abstract":"This is an experiential study of investigating a consistent method for deriving the correlation between sentence vector and semantic meaning of a sentence. We first used three state-of-the-art word/sentence embedding methods including GPT-3, Word2Vec, and Sentence-BERT, to embed plain text sentence strings into high dimensional spaces. Then we compute the pairwise distance between any possible combination of two sentence vectors in an embedding space and map them into a matrix. Based on each distance matrix, we compute the correlation of distances of a sentence vector with respect to the other sentence vectors in an embedding space. Then we compute the correlation of each pair of the distance matrices. We observed correlations of the same sentence in different embedding spaces and correlations of different sentences in the same embedding space. These observations are consistent with our hypothesis and take us to the next stage.","sentences":["This is an experiential study of investigating a consistent method for deriving the correlation between sentence vector and semantic meaning of a sentence.","We first used three state-of-the-art word/sentence embedding methods including GPT-3, Word2Vec, and Sentence-BERT, to embed plain text sentence strings into high dimensional spaces.","Then we compute the pairwise distance between any possible combination of two sentence vectors in an embedding space and map them into a matrix.","Based on each distance matrix, we compute the correlation of distances of a sentence vector with respect to the other sentence vectors in an embedding space.","Then we compute the correlation of each pair of the distance matrices.","We observed correlations of the same sentence in different embedding spaces and correlations of different sentences in the same embedding space.","These observations are consistent with our hypothesis and take us to the next stage."],"url":"http://arxiv.org/abs/2308.03565v1"}
{"created":"2023-08-07 13:10:35","title":"Mondrian: Prompt Abstraction Attack Against Large Language Models for Cheaper API Pricing","abstract":"The Machine Learning as a Service (MLaaS) market is rapidly expanding and becoming more mature. For example, OpenAI's ChatGPT is an advanced large language model (LLM) that generates responses for various queries with associated fees. Although these models can deliver satisfactory performance, they are far from perfect. Researchers have long studied the vulnerabilities and limitations of LLMs, such as adversarial attacks and model toxicity. Inevitably, commercial ML models are also not exempt from such issues, which can be problematic as MLaaS continues to grow. In this paper, we discover a new attack strategy against LLM APIs, namely the prompt abstraction attack. Specifically, we propose Mondrian, a simple and straightforward method that abstracts sentences, which can lower the cost of using LLM APIs. In this approach, the adversary first creates a pseudo API (with a lower established price) to serve as the proxy of the target API (with a higher established price). Next, the pseudo API leverages Mondrian to modify the user query, obtain the abstracted response from the target API, and forward it back to the end user. Our results show that Mondrian successfully reduces user queries' token length ranging from 13% to 23% across various tasks, including text classification, generation, and question answering. Meanwhile, these abstracted queries do not significantly affect the utility of task-specific and general language models like ChatGPT. Mondrian also reduces instruction prompts' token length by at least 11% without compromising output quality. As a result, the prompt abstraction attack enables the adversary to profit without bearing the cost of API development and deployment.","sentences":["The Machine Learning as a Service (MLaaS) market is rapidly expanding and becoming more mature.","For example, OpenAI's ChatGPT is an advanced large language model (LLM) that generates responses for various queries with associated fees.","Although these models can deliver satisfactory performance, they are far from perfect.","Researchers have long studied the vulnerabilities and limitations of LLMs, such as adversarial attacks and model toxicity.","Inevitably, commercial ML models are also not exempt from such issues, which can be problematic as MLaaS continues to grow.","In this paper, we discover a new attack strategy against LLM APIs, namely the prompt abstraction attack.","Specifically, we propose Mondrian, a simple and straightforward method that abstracts sentences, which can lower the cost of using LLM APIs.","In this approach, the adversary first creates a pseudo API (with a lower established price) to serve as the proxy of the target API (with a higher established price).","Next, the pseudo API leverages Mondrian to modify the user query, obtain the abstracted response from the target API, and forward it back to the end user.","Our results show that Mondrian successfully reduces user queries' token length ranging from 13% to 23% across various tasks, including text classification, generation, and question answering.","Meanwhile, these abstracted queries do not significantly affect the utility of task-specific and general language models like ChatGPT.","Mondrian also reduces instruction prompts' token length by at least 11% without compromising output quality.","As a result, the prompt abstraction attack enables the adversary to profit without bearing the cost of API development and deployment."],"url":"http://arxiv.org/abs/2308.03558v1"}
{"created":"2023-08-07 13:09:19","title":"Joint Device Identification, Channel Estimation, and Signal Detection for LEO Satellite-Enabled Random Access","abstract":"This paper investigates joint device identification, channel estimation, and signal detection for LEO satellite-enabled grant-free random access, where a multiple-input multipleoutput (MIMO) system with orthogonal time-frequency space modulation (OTFS) is utilized to combat the dynamics of the terrestrial-satellite link (TSL). We divide the receiver structure into three modules: first, a linear module for identifying active devices, which leverages the generalized approximate message passing (GAMP) algorithm to eliminate inter-user interference in the delay-Doppler domain; second, a non-linear module adopting the message passing algorithm to jointly estimate channel and detect transmit signals; the third aided by Markov random field (MRF) aims to explore the three dimensional block sparsity of channel in the delay-Doppler-angle domain. The soft information is exchanged iteratively between these three modules by careful scheduling. Furthermore, the expectation-maximization algorithm is embedded to learn the hyperparameters in prior distributions. Simulation results demonstrate that the proposed scheme outperforms the conventional methods significantly in terms of activity error rate, channel estimation accuracy, and symbol error rate.","sentences":["This paper investigates joint device identification, channel estimation, and signal detection for LEO satellite-enabled grant-free random access, where a multiple-input multipleoutput (MIMO) system with orthogonal time-frequency space modulation (OTFS) is utilized to combat the dynamics of the terrestrial-satellite link (TSL).","We divide the receiver structure into three modules: first, a linear module for identifying active devices, which leverages the generalized approximate message passing (GAMP) algorithm to eliminate inter-user interference in the delay-Doppler domain; second, a non-linear module adopting the message passing algorithm to jointly estimate channel and detect transmit signals; the third aided by Markov random field (MRF) aims to explore the three dimensional block sparsity of channel in the delay-Doppler-angle domain.","The soft information is exchanged iteratively between these three modules by careful scheduling.","Furthermore, the expectation-maximization algorithm is embedded to learn the hyperparameters in prior distributions.","Simulation results demonstrate that the proposed scheme outperforms the conventional methods significantly in terms of activity error rate, channel estimation accuracy, and symbol error rate."],"url":"http://arxiv.org/abs/2308.03556v1"}
{"created":"2023-08-07 13:08:26","title":"NeuroAiR: Deep Learning Framework for Airwriting Recognition from Scalp-recorded Neural Signals","abstract":"Airwriting recognition is a task that involves identifying letters written in free space using finger movement. It is a special case of gesture recognition, where gestures correspond to letters in a specific language. Electroencephalography (EEG) is a non-invasive technique for recording brain activity and has been widely used in brain-computer interface applications. Leveraging EEG signals for airwriting recognition offers a promising alternative input method for Human-Computer Interaction. One key advantage of airwriting recognition is that users don't need to learn new gestures. By concatenating recognized letters, a wide range of words can be formed, making it applicable to a broader population. However, there has been limited research in the recognition of airwriting using EEG signals, which forms the core focus of this study. The NeuroAiR dataset comprising EEG signals recorded during writing English uppercase alphabets is first constructed. Various features are then explored in conjunction with different deep learning models to achieve accurate airwriting recognition. These features include processed EEG data, Independent Component Analysis components, source-domain-based scout time series, and spherical and head harmonic decomposition-based features. Furthermore, the impact of different EEG frequency bands on system performance is comprehensively investigated. The highest accuracy achieved in this study is 44.04% using Independent Component Analysis components and the EEGNet classification model. The results highlight the potential of EEG-based airwriting recognition as a user-friendly modality for alternative input methods in Human-Computer Interaction applications. This research sets a strong baseline for future advancements and demonstrates the viability and utility of EEG-based airwriting recognition.","sentences":["Airwriting recognition is a task that involves identifying letters written in free space using finger movement.","It is a special case of gesture recognition, where gestures correspond to letters in a specific language.","Electroencephalography (EEG) is a non-invasive technique for recording brain activity and has been widely used in brain-computer interface applications.","Leveraging EEG signals for airwriting recognition offers a promising alternative input method for Human-Computer Interaction.","One key advantage of airwriting recognition is that users don't need to learn new gestures.","By concatenating recognized letters, a wide range of words can be formed, making it applicable to a broader population.","However, there has been limited research in the recognition of airwriting using EEG signals, which forms the core focus of this study.","The NeuroAiR dataset comprising EEG signals recorded during writing English uppercase alphabets is first constructed.","Various features are then explored in conjunction with different deep learning models to achieve accurate airwriting recognition.","These features include processed EEG data, Independent Component Analysis components, source-domain-based scout time series, and spherical and head harmonic decomposition-based features.","Furthermore, the impact of different EEG frequency bands on system performance is comprehensively investigated.","The highest accuracy achieved in this study is 44.04% using Independent Component Analysis components and the EEGNet classification model.","The results highlight the potential of EEG-based airwriting recognition as a user-friendly modality for alternative input methods in Human-Computer Interaction applications.","This research sets a strong baseline for future advancements and demonstrates the viability and utility of EEG-based airwriting recognition."],"url":"http://arxiv.org/abs/2308.03555v1"}
{"created":"2023-08-07 13:06:34","title":"TemporalFED: Detecting Cyberattacks in Industrial Time-Series Data Using Decentralized Federated Learning","abstract":"Industry 4.0 has brought numerous advantages, such as increasing productivity through automation. However, it also presents major cybersecurity issues such as cyberattacks affecting industrial processes. Federated Learning (FL) combined with time-series analysis is a promising cyberattack detection mechanism proposed in the literature. However, the fact of having a single point of failure and network bottleneck are critical challenges that need to be tackled. Thus, this article explores the benefits of the Decentralized Federated Learning (DFL) in terms of cyberattack detection and resource consumption. The work presents TemporalFED, a software module for detecting anomalies in industrial environments using FL paradigms and time series. TemporalFED incorporates three components: Time Series Conversion, Feature Engineering, and Time Series Stationary Conversion. To evaluate TemporalFED, it was deployed on Fedstellar, a DFL framework. Then, a pool of experiments measured the detection performance and resource consumption in a chemical gas industrial environment with different time-series configurations, FL paradigms, and topologies. The results showcase the superiority of the configuration utilizing DFL and Semi-Decentralized Federated Learning (SDFL) paradigms, along with a fully connected topology, which achieved the best performance in anomaly detection. Regarding resource consumption, the configuration without feature engineering employed less bandwidth, CPU, and RAM than other configurations.","sentences":["Industry 4.0 has brought numerous advantages, such as increasing productivity through automation.","However, it also presents major cybersecurity issues such as cyberattacks affecting industrial processes.","Federated Learning (FL) combined with time-series analysis is a promising cyberattack detection mechanism proposed in the literature.","However, the fact of having a single point of failure and network bottleneck are critical challenges that need to be tackled.","Thus, this article explores the benefits of the Decentralized Federated Learning (DFL) in terms of cyberattack detection and resource consumption.","The work presents TemporalFED, a software module for detecting anomalies in industrial environments using FL paradigms and time series.","TemporalFED incorporates three components: Time Series Conversion, Feature Engineering, and Time Series Stationary Conversion.","To evaluate TemporalFED, it was deployed on Fedstellar, a DFL framework.","Then, a pool of experiments measured the detection performance and resource consumption in a chemical gas industrial environment with different time-series configurations, FL paradigms, and topologies.","The results showcase the superiority of the configuration utilizing DFL and Semi-Decentralized Federated Learning (SDFL) paradigms, along with a fully connected topology, which achieved the best performance in anomaly detection.","Regarding resource consumption, the configuration without feature engineering employed less bandwidth, CPU, and RAM than other configurations."],"url":"http://arxiv.org/abs/2308.03554v1"}
{"created":"2023-08-07 12:56:13","title":"Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-world Multi-turn Dialogue","abstract":"Recent advances in Large Language Models (LLMs) have achieved remarkable breakthroughs in understanding and responding to user intents. However, their performance lag behind general use cases in some expertise domains, such as Chinese medicine. Existing efforts to incorporate Chinese medicine into LLMs rely on Supervised Fine-Tuning (SFT) with single-turn and distilled dialogue data. These models lack the ability for doctor-like proactive inquiry and multi-turn comprehension and cannot always align responses with safety and professionalism experts. In this work, we introduce Zhongjing, the first Chinese medical LLaMA-based LLM that implements an entire training pipeline from pre-training to reinforcement learning with human feedback (RLHF). Additionally, we introduce a Chinese multi-turn medical dialogue dataset of 70,000 authentic doctor-patient dialogues, CMtMedQA, which significantly enhances the model's capability for complex dialogue and proactive inquiry initiation. We define a refined annotation rule and evaluation criteria given the biomedical domain's unique characteristics. Results show that our model outperforms baselines in various capacities and matches the performance of ChatGPT in a few abilities, despite having 50x training data with previous best model and 100x parameters with ChatGPT. RLHF further improves the model's instruction-following ability and safety. We also release our code, datasets and model for further research.","sentences":["Recent advances in Large Language Models (LLMs) have achieved remarkable breakthroughs in understanding and responding to user intents.","However, their performance lag behind general use cases in some expertise domains, such as Chinese medicine.","Existing efforts to incorporate Chinese medicine into LLMs rely on Supervised Fine-Tuning (SFT) with single-turn and distilled dialogue data.","These models lack the ability for doctor-like proactive inquiry and multi-turn comprehension and cannot always align responses with safety and professionalism experts.","In this work, we introduce Zhongjing, the first Chinese medical LLaMA-based LLM that implements an entire training pipeline from pre-training to reinforcement learning with human feedback (RLHF).","Additionally, we introduce a Chinese multi-turn medical dialogue dataset of 70,000 authentic doctor-patient dialogues, CMtMedQA, which significantly enhances the model's capability for complex dialogue and proactive inquiry initiation.","We define a refined annotation rule and evaluation criteria given the biomedical domain's unique characteristics.","Results show that our model outperforms baselines in various capacities and matches the performance of ChatGPT in a few abilities, despite having 50x training data with previous best model and 100x parameters with ChatGPT.","RLHF further improves the model's instruction-following ability and safety.","We also release our code, datasets and model for further research."],"url":"http://arxiv.org/abs/2308.03549v1"}
{"created":"2023-08-07 12:55:29","title":"Near-optimal pilot assignment in cell-free massive MIMO","abstract":"The main source of performance degradation in cell-free massive MIMO is pilot contamination, which causes interference during uplink training and affects channel estimation negatively. Contamination occurs when the same pilot sequence is assigned to more than one user. This is in general inevitable, as the number of mutually orthogonal pilot sequences corresponds to only a fraction of the coherence interval. We introduce an algorithm for pilot assignment that has an approximation ratio close to 1 for a plausibly large number of orthogonal pilot sequences. It also has low computational complexity under massive parallelism.","sentences":["The main source of performance degradation in cell-free massive MIMO is pilot contamination, which causes interference during uplink training and affects channel estimation negatively.","Contamination occurs when the same pilot sequence is assigned to more than one user.","This is in general inevitable, as the number of mutually orthogonal pilot sequences corresponds to only a fraction of the coherence interval.","We introduce an algorithm for pilot assignment that has an approximation ratio close to 1 for a plausibly large number of orthogonal pilot sequences.","It also has low computational complexity under massive parallelism."],"url":"http://arxiv.org/abs/2308.03547v1"}
