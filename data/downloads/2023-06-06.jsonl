{"created":"2023-06-05","title":"SelfEvolve: A Code Evolution Framework via Large Language Models","abstract":"Large language models (LLMs) have already revolutionized code generation, after being pretrained on publicly available code data. However, while various methods have been proposed to augment LLMs with retrieved knowledge and enhance the quality of code generation, the performance of these retrieval-based methods is limited by the strength of the retrievers used. In addition, while LLMs show great emergent ability, they still struggle to produce the correct code in one turn. To address these challenges, we propose a novel two-step pipeline, called \\autoknow, that leverages LLMs as both knowledge providers and self-reflective programmers. Unlike retrieval-based methods, \\autoknow~obtains the knowledge from input prompts and generates intermediate code based on the generated knowledge. After that, \\autoknow~asks LLM to act as an expert programmer to perform debugging for the generated code. This is achieved by receiving the error message from the interpreter, without requiring special test cases for correctness verification. We evaluate \\autoknow~on three code generation datasets, including DS-1000 for data science code, HumanEval for software engineering code, and TransCoder for C++-to-Python translation. Our empirical experiments show that \\autoknow~outperforms strong baselines by a significant margin on all datasets. We also conduct exhaustive analytical experiments to validate the effectiveness of the two stages of \\autoknow, and find that both are superior to other prompting-based methods. Further scalability analysis demonstrates that \\autoknow~can be adapted to other more advanced models, such as GPT-4, and bring consistent efficacy improvement.","sentences":["Large language models (LLMs) have already revolutionized code generation, after being pretrained on publicly available code data.","However, while various methods have been proposed to augment LLMs with retrieved knowledge and enhance the quality of code generation, the performance of these retrieval-based methods is limited by the strength of the retrievers used.","In addition, while LLMs show great emergent ability, they still struggle to produce the correct code in one turn.","To address these challenges, we propose a novel two-step pipeline, called \\autoknow, that leverages LLMs as both knowledge providers and self-reflective programmers.","Unlike retrieval-based methods, \\autoknow~obtains the knowledge from input prompts and generates intermediate code based on the generated knowledge.","After that, \\autoknow~asks LLM to act as an expert programmer to perform debugging for the generated code.","This is achieved by receiving the error message from the interpreter, without requiring special test cases for correctness verification.","We evaluate \\autoknow~on three code generation datasets, including DS-1000 for data science code, HumanEval for software engineering code, and TransCoder for C++-to-Python translation.","Our empirical experiments show that \\autoknow~outperforms strong baselines by a significant margin on all datasets.","We also conduct exhaustive analytical experiments to validate the effectiveness of the two stages of \\autoknow, and find that both are superior to other prompting-based methods.","Further scalability analysis demonstrates that \\autoknow~can be adapted to other more advanced models, such as GPT-4, and bring consistent efficacy improvement."],"url":"http://arxiv.org/abs/2306.02907v1"}
{"created":"2023-06-05","title":"Cheap-fake Detection with LLM using Prompt Engineering","abstract":"The misuse of real photographs with conflicting image captions in news items is an example of the out-of-context (OOC) misuse of media. In order to detect OOC media, individuals must determine the accuracy of the statement and evaluate whether the triplet (~\\textit{i.e.}, the image and two captions) relates to the same event. This paper presents a novel learnable approach for detecting OOC media in ICME'23 Grand Challenge on Detecting Cheapfakes. The proposed method is based on the COSMOS structure, which assesses the coherence between an image and captions, as well as between two captions. We enhance the baseline algorithm by incorporating a Large Language Model (LLM), GPT3.5, as a feature extractor. Specifically, we propose an innovative approach to feature extraction utilizing prompt engineering to develop a robust and reliable feature extractor with GPT3.5 model. The proposed method captures the correlation between two captions and effectively integrates this module into the COSMOS baseline model, which allows for a deeper understanding of the relationship between captions. By incorporating this module, we demonstrate the potential for significant improvements in cheap-fakes detection performance. The proposed methodology holds promising implications for various applications such as natural language processing, image captioning, and text-to-image synthesis. Docker for submission is available at https://hub.docker.com/repository/docker/mulns/ acmmmcheapfakes.","sentences":["The misuse of real photographs with conflicting image captions in news items is an example of the out-of-context (OOC) misuse of media.","In order to detect OOC media, individuals must determine the accuracy of the statement and evaluate whether the triplet (~\\textit{i.e.}, the image and two captions) relates to the same event.","This paper presents a novel learnable approach for detecting OOC media in ICME'23 Grand Challenge on Detecting Cheapfakes.","The proposed method is based on the COSMOS structure, which assesses the coherence between an image and captions, as well as between two captions.","We enhance the baseline algorithm by incorporating a Large Language Model (LLM), GPT3.5, as a feature extractor.","Specifically, we propose an innovative approach to feature extraction utilizing prompt engineering to develop a robust and reliable feature extractor with GPT3.5 model.","The proposed method captures the correlation between two captions and effectively integrates this module into the COSMOS baseline model, which allows for a deeper understanding of the relationship between captions.","By incorporating this module, we demonstrate the potential for significant improvements in cheap-fakes detection performance.","The proposed methodology holds promising implications for various applications such as natural language processing, image captioning, and text-to-image synthesis.","Docker for submission is available at https://hub.docker.com/repository/docker/mulns/ acmmmcheapfakes."],"url":"http://arxiv.org/abs/2306.02776v1"}
{"created":"2023-06-05","title":"User-friendly Image Editing with Minimal Text Input: Leveraging Captioning and Injection Techniques","abstract":"Recent text-driven image editing in diffusion models has shown remarkable success. However, the existing methods assume that the user's description sufficiently grounds the contexts in the source image, such as objects, background, style, and their relations. This assumption is unsuitable for real-world applications because users have to manually engineer text prompts to find optimal descriptions for different images. From the users' standpoint, prompt engineering is a labor-intensive process, and users prefer to provide a target word for editing instead of a full sentence. To address this problem, we first demonstrate the importance of a detailed text description of the source image, by dividing prompts into three categories based on the level of semantic details. Then, we propose simple yet effective methods by combining prompt generation frameworks, thereby making the prompt engineering process more user-friendly. Extensive qualitative and quantitative experiments demonstrate the importance of prompts in text-driven image editing and our method is comparable to ground-truth prompts.","sentences":["Recent text-driven image editing in diffusion models has shown remarkable success.","However, the existing methods assume that the user's description sufficiently grounds the contexts in the source image, such as objects, background, style, and their relations.","This assumption is unsuitable for real-world applications because users have to manually engineer text prompts to find optimal descriptions for different images.","From the users' standpoint, prompt engineering is a labor-intensive process, and users prefer to provide a target word for editing instead of a full sentence.","To address this problem, we first demonstrate the importance of a detailed text description of the source image, by dividing prompts into three categories based on the level of semantic details.","Then, we propose simple yet effective methods by combining prompt generation frameworks, thereby making the prompt engineering process more user-friendly.","Extensive qualitative and quantitative experiments demonstrate the importance of prompts in text-driven image editing and our method is comparable to ground-truth prompts."],"url":"http://arxiv.org/abs/2306.02717v1"}
{"created":"2023-06-05","title":"Is ChatGPT a Good Teacher Coach? Measuring Zero-Shot Performance For Scoring and Providing Actionable Insights on Classroom Instruction","abstract":"Coaching, which involves classroom observation and expert feedback, is a widespread and fundamental part of teacher training. However, the majority of teachers do not have access to consistent, high quality coaching due to limited resources and access to expertise. We explore whether generative AI could become a cost-effective complement to expert feedback by serving as an automated teacher coach. In doing so, we propose three teacher coaching tasks for generative AI: (A) scoring transcript segments based on classroom observation instruments, (B) identifying highlights and missed opportunities for good instructional strategies, and (C) providing actionable suggestions for eliciting more student reasoning. We recruit expert math teachers to evaluate the zero-shot performance of ChatGPT on each of these tasks for elementary math classroom transcripts. Our results reveal that ChatGPT generates responses that are relevant to improving instruction, but they are often not novel or insightful. For example, 82% of the model's suggestions point to places in the transcript where the teacher is already implementing that suggestion. Our work highlights the challenges of producing insightful, novel and truthful feedback for teachers while paving the way for future research to address these obstacles and improve the capacity of generative AI to coach teachers.","sentences":["Coaching, which involves classroom observation and expert feedback, is a widespread and fundamental part of teacher training.","However, the majority of teachers do not have access to consistent, high quality coaching due to limited resources and access to expertise.","We explore whether generative AI could become a cost-effective complement to expert feedback by serving as an automated teacher coach.","In doing so, we propose three teacher coaching tasks for generative AI: (A) scoring transcript segments based on classroom observation instruments, (B) identifying highlights and missed opportunities for good instructional strategies, and (C) providing actionable suggestions for eliciting more student reasoning.","We recruit expert math teachers to evaluate the zero-shot performance of ChatGPT on each of these tasks for elementary math classroom transcripts.","Our results reveal that ChatGPT generates responses that are relevant to improving instruction, but they are often not novel or insightful.","For example, 82% of the model's suggestions point to places in the transcript where the teacher is already implementing that suggestion.","Our work highlights the challenges of producing insightful, novel and truthful feedback for teachers while paving the way for future research to address these obstacles and improve the capacity of generative AI to coach teachers."],"url":"http://arxiv.org/abs/2306.03090v1"}
{"created":"2023-06-05","title":"InstructZero: Efficient Instruction Optimization for Black-Box Large Language Models","abstract":"Large language models~(LLMs) are instruction followers, but it can be challenging to find the best instruction for different situations, especially for black-box LLMs on which backpropagation is forbidden. Instead of directly optimizing the discrete instruction, we optimize a low-dimensional soft prompt applied to an open-source LLM to generate the instruction for the black-box LLM. On each iteration of the proposed method, which we call InstructZero, a soft prompt is converted into an instruction using the open-source LLM, which is then submitted to the black-box LLM for zero-shot evaluation, and the performance is sent to Bayesian optimization to produce new soft prompts improving the zero-shot performance. We evaluate InstructZero on different combinations of open-source LLMs and APIs including Vicuna and ChatGPT. Our results show that InstructZero outperforms SOTA auto-instruction methods across a variety of downstream tasks. Our code and data are publicly available at https://github.com/Lichang-Chen/InstructZero.","sentences":["Large language models~(LLMs) are instruction followers, but it can be challenging to find the best instruction for different situations, especially for black-box LLMs on which backpropagation is forbidden.","Instead of directly optimizing the discrete instruction, we optimize a low-dimensional soft prompt applied to an open-source LLM to generate the instruction for the black-box LLM.","On each iteration of the proposed method, which we call InstructZero, a soft prompt is converted into an instruction using the open-source LLM, which is then submitted to the black-box LLM for zero-shot evaluation, and the performance is sent to Bayesian optimization to produce new soft prompts improving the zero-shot performance.","We evaluate InstructZero on different combinations of open-source LLMs and APIs including Vicuna and ChatGPT.","Our results show that InstructZero outperforms SOTA auto-instruction methods across a variety of downstream tasks.","Our code and data are publicly available at https://github.com/Lichang-Chen/InstructZero."],"url":"http://arxiv.org/abs/2306.03082v1"}
{"created":"2023-06-05","title":"PokemonChat: Auditing ChatGPT for Pok\u00e9mon Universe Knowledge","abstract":"The recently released ChatGPT model demonstrates unprecedented capabilities in zero-shot question-answering. In this work, we probe ChatGPT for its conversational understanding and introduce a conversational framework (protocol) that can be adopted in future studies. The Pok\\'emon universe serves as an ideal testing ground for auditing ChatGPT's reasoning capabilities due to its closed world assumption. After bringing ChatGPT's background knowledge (on the Pok\\'emon universe) to light, we test its reasoning process when using these concepts in battle scenarios. We then evaluate its ability to acquire new knowledge and include it in its reasoning process. Our ultimate goal is to assess ChatGPT's ability to generalize, combine features, and to acquire and reason over newly introduced knowledge from human feedback. We find that ChatGPT has prior knowledge of the Pokemon universe, which can reason upon in battle scenarios to a great extent, even when new information is introduced. The model performs better with collaborative feedback and if there is an initial phase of information retrieval, but also hallucinates occasionally and is susceptible to adversarial attacks.","sentences":["The recently released ChatGPT model demonstrates unprecedented capabilities in zero-shot question-answering.","In this work, we probe ChatGPT for its conversational understanding and introduce a conversational framework (protocol) that can be adopted in future studies.","The Pok\\'emon universe serves as an ideal testing ground for auditing ChatGPT's reasoning capabilities due to its closed world assumption.","After bringing ChatGPT's background knowledge (on the Pok\\'emon universe) to light, we test its reasoning process when using these concepts in battle scenarios.","We then evaluate its ability to acquire new knowledge and include it in its reasoning process.","Our ultimate goal is to assess ChatGPT's ability to generalize, combine features, and to acquire and reason over newly introduced knowledge from human feedback.","We find that ChatGPT has prior knowledge of the Pokemon universe, which can reason upon in battle scenarios to a great extent, even when new information is introduced.","The model performs better with collaborative feedback and if there is an initial phase of information retrieval, but also hallucinates occasionally and is susceptible to adversarial attacks."],"url":"http://arxiv.org/abs/2306.03024v1"}
{"created":"2023-06-05","title":"Will ChatGPT and Related AI-Tools Alter the Future of the Geosciences and Petroleum Engineering?","abstract":"A key aim of this paper is to explore how our professional tasks as geoscientists and petroleum engineers can be completed more effectively making use of tools powered by Artificial Intelligence (AI), offered in commercial platforms now readily available to individual users. This paper intends to provide some guidance, but at the same time does not claim to be comprehensive or conclusive in any way. The paper presents a utility assessment from the research and teaching vantage points of two professors and one student, from geosciences and petroleum engineering departments. After a brief overview of the new technologies, some key questions raised include: How can one assess originality of class papers by students and research papers by their professors? How will the contribution of intelligent devices be acknowledged? Will the presentation of conference papers by author avatars be accepted by the organizing committee?","sentences":["A key aim of this paper is to explore how our professional tasks as geoscientists and petroleum engineers can be completed more effectively making use of tools powered by Artificial Intelligence (AI), offered in commercial platforms now readily available to individual users.","This paper intends to provide some guidance, but at the same time does not claim to be comprehensive or conclusive in any way.","The paper presents a utility assessment from the research and teaching vantage points of two professors and one student, from geosciences and petroleum engineering departments.","After a brief overview of the new technologies, some key questions raised include: How can one assess originality of class papers by students and research papers by their professors?","How will the contribution of intelligent devices be acknowledged?","Will the presentation of conference papers by author avatars be accepted by the organizing committee?"],"url":"http://arxiv.org/abs/2306.02882v1"}
{"created":"2023-06-05","title":"Orca: Progressive Learning from Complex Explanation Traces of GPT-4","abstract":"Recent research has focused on enhancing the capability of smaller models through imitation learning, drawing on the outputs generated by large foundation models (LFMs). A number of issues impact the quality of these models, ranging from limited imitation signals from shallow LFM outputs; small scale homogeneous training data; and most notably a lack of rigorous evaluation resulting in overestimating the small model's capability as they tend to learn to imitate the style, but not the reasoning process of LFMs. To address these challenges, we develop Orca (We are working with our legal team to publicly release a diff of the model weights in accordance with LLaMA's release policy to be published at https://aka.ms/orca-lm), a 13-billion parameter model that learns to imitate the reasoning process of LFMs. Orca learns from rich signals from GPT-4 including explanation traces; step-by-step thought processes; and other complex instructions, guided by teacher assistance from ChatGPT. To promote this progressive learning, we tap into large-scale and diverse imitation data with judicious sampling and selection. Orca surpasses conventional state-of-the-art instruction-tuned models such as Vicuna-13B by more than 100% in complex zero-shot reasoning benchmarks like Big-Bench Hard (BBH) and 42% on AGIEval. Moreover, Orca reaches parity with ChatGPT on the BBH benchmark and shows competitive performance (4 pts gap with optimized system message) in professional and academic examinations like the SAT, LSAT, GRE, and GMAT, both in zero-shot settings without CoT; while trailing behind GPT-4. Our research indicates that learning from step-by-step explanations, whether these are generated by humans or more advanced AI models, is a promising direction to improve model capabilities and skills.","sentences":["Recent research has focused on enhancing the capability of smaller models through imitation learning, drawing on the outputs generated by large foundation models (LFMs).","A number of issues impact the quality of these models, ranging from limited imitation signals from shallow LFM outputs; small scale homogeneous training data; and most notably a lack of rigorous evaluation resulting in overestimating the small model's capability as they tend to learn to imitate the style, but not the reasoning process of LFMs.","To address these challenges, we develop Orca (We are working with our legal team to publicly release a diff of the model weights in accordance with LLaMA's release policy to be published at https://aka.ms/orca-lm), a 13-billion parameter model that learns to imitate the reasoning process of LFMs.","Orca learns from rich signals from GPT-4 including explanation traces; step-by-step thought processes; and other complex instructions, guided by teacher assistance from ChatGPT.","To promote this progressive learning, we tap into large-scale and diverse imitation data with judicious sampling and selection.","Orca surpasses conventional state-of-the-art instruction-tuned models such as Vicuna-13B by more than 100% in complex zero-shot reasoning benchmarks like Big-Bench Hard (BBH) and 42% on AGIEval.","Moreover, Orca reaches parity with ChatGPT on the BBH benchmark and shows competitive performance (4 pts gap with optimized system message) in professional and academic examinations like the SAT, LSAT, GRE, and GMAT, both in zero-shot settings without CoT; while trailing behind GPT-4.","Our research indicates that learning from step-by-step explanations, whether these are generated by humans or more advanced AI models, is a promising direction to improve model capabilities and skills."],"url":"http://arxiv.org/abs/2306.02707v1"}
{"created":"2023-06-05","title":"LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion","abstract":"We present LLM-Blender, an ensembling framework designed to attain consistently superior performance by leveraging the diverse strengths of multiple open-source large language models (LLMs). Our framework consists of two modules: PairRanker and GenFuser, addressing the observation that optimal LLMs for different examples can significantly vary. PairRanker employs a specialized pairwise comparison method to distinguish subtle differences between candidate outputs. It jointly encodes the input text and a pair of candidates, using cross-attention encoders to determine the superior one. Our results demonstrate that PairRanker exhibits the highest correlation with ChatGPT-based ranking. Then, GenFuser aims to merge the top-ranked candidates, generating an improved output by capitalizing on their strengths and mitigating their weaknesses. To facilitate large-scale evaluation, we introduce a benchmark dataset, MixInstruct, which is a mixture of multiple instruction datasets featuring oracle pairwise comparisons. Our LLM-Blender significantly outperform individual LLMs and baseline methods across various metrics, establishing a substantial performance gap.","sentences":["We present LLM-Blender, an ensembling framework designed to attain consistently superior performance by leveraging the diverse strengths of multiple open-source large language models (LLMs).","Our framework consists of two modules: PairRanker and GenFuser, addressing the observation that optimal LLMs for different examples can significantly vary.","PairRanker employs a specialized pairwise comparison method to distinguish subtle differences between candidate outputs.","It jointly encodes the input text and a pair of candidates, using cross-attention encoders to determine the superior one.","Our results demonstrate that PairRanker exhibits the highest correlation with ChatGPT-based ranking.","Then, GenFuser aims to merge the top-ranked candidates, generating an improved output by capitalizing on their strengths and mitigating their weaknesses.","To facilitate large-scale evaluation, we introduce a benchmark dataset, MixInstruct, which is a mixture of multiple instruction datasets featuring oracle pairwise comparisons.","Our LLM-Blender significantly outperform individual LLMs and baseline methods across various metrics, establishing a substantial performance gap."],"url":"http://arxiv.org/abs/2306.02561v1"}
{"created":"2023-06-05","title":"Evaluation of AI Chatbots for Patient-Specific EHR Questions","abstract":"This paper investigates the use of artificial intelligence chatbots for patient-specific question answering (QA) from clinical notes using several large language model (LLM) based systems: ChatGPT (versions 3.5 and 4), Google Bard, and Claude. We evaluate the accuracy, relevance, comprehensiveness, and coherence of the answers generated by each model using a 5-point Likert scale on a set of patient-specific questions.","sentences":["This paper investigates the use of artificial intelligence chatbots for patient-specific question answering (QA) from clinical notes using several large language model (LLM) based systems: ChatGPT (versions 3.5 and 4), Google Bard, and Claude.","We evaluate the accuracy, relevance, comprehensiveness, and coherence of the answers generated by each model using a 5-point Likert scale on a set of patient-specific questions."],"url":"http://arxiv.org/abs/2306.02549v1"}
{"created":"2023-06-05","title":"MotionDiffuser: Controllable Multi-Agent Motion Prediction using Diffusion","abstract":"We present MotionDiffuser, a diffusion based representation for the joint distribution of future trajectories over multiple agents. Such representation has several key advantages: first, our model learns a highly multimodal distribution that captures diverse future outcomes. Second, the simple predictor design requires only a single L2 loss training objective, and does not depend on trajectory anchors. Third, our model is capable of learning the joint distribution for the motion of multiple agents in a permutation-invariant manner. Furthermore, we utilize a compressed trajectory representation via PCA, which improves model performance and allows for efficient computation of the exact sample log probability. Subsequently, we propose a general constrained sampling framework that enables controlled trajectory sampling based on differentiable cost functions. This strategy enables a host of applications such as enforcing rules and physical priors, or creating tailored simulation scenarios. MotionDiffuser can be combined with existing backbone architectures to achieve top motion forecasting results. We obtain state-of-the-art results for multi-agent motion prediction on the Waymo Open Motion Dataset.","sentences":["We present MotionDiffuser, a diffusion based representation for the joint distribution of future trajectories over multiple agents.","Such representation has several key advantages: first, our model learns a highly multimodal distribution that captures diverse future outcomes.","Second, the simple predictor design requires only a single L2 loss training objective, and does not depend on trajectory anchors.","Third, our model is capable of learning the joint distribution for the motion of multiple agents in a permutation-invariant manner.","Furthermore, we utilize a compressed trajectory representation via PCA, which improves model performance and allows for efficient computation of the exact sample log probability.","Subsequently, we propose a general constrained sampling framework that enables controlled trajectory sampling based on differentiable cost functions.","This strategy enables a host of applications such as enforcing rules and physical priors, or creating tailored simulation scenarios.","MotionDiffuser can be combined with existing backbone architectures to achieve top motion forecasting results.","We obtain state-of-the-art results for multi-agent motion prediction on the Waymo Open Motion Dataset."],"url":"http://arxiv.org/abs/2306.03083v1"}
{"created":"2023-06-05","title":"Of Mice and Mates: Automated Classification and Modelling of Mouse Behaviour in Groups using a Single Model across Cages","abstract":"Behavioural experiments often happen in specialised arenas, but this may confound the analysis. To address this issue, we provide tools to study mice in the homecage environment, equipping biologists with the possibility to capture the temporal aspect of the individual's behaviour and model the interaction and interdependence between cage-mates with minimal human intervention. We develop the Activity Labelling Module (ALM) to automatically classify mouse behaviour from video, and a novel Group Behaviour Model (GBM) for summarising their joint behaviour across cages, using a permutation matrix to match the mouse identities in each cage to the model. We also release two datasets, ABODe for training behaviour classifiers and IMADGE for modelling behaviour.","sentences":["Behavioural experiments often happen in specialised arenas, but this may confound the analysis.","To address this issue, we provide tools to study mice in the homecage environment, equipping biologists with the possibility to capture the temporal aspect of the individual's behaviour and model the interaction and interdependence between cage-mates with minimal human intervention.","We develop the Activity Labelling Module (ALM) to automatically classify mouse behaviour from video, and a novel Group Behaviour Model (GBM) for summarising their joint behaviour across cages, using a permutation matrix to match the mouse identities in each cage to the model.","We also release two datasets, ABODe for training behaviour classifiers and IMADGE for modelling behaviour."],"url":"http://arxiv.org/abs/2306.03066v1"}
{"created":"2023-06-05","title":"A GALEX view of the DA White Dwarf Population","abstract":"We present a detailed model atmosphere analysis of 14001 DA white dwarfs from the Montreal White Dwarf Database with ultraviolet photometry from the GALEX mission. We use the 100 pc sample, where the extinction is negligible, to demonstrate that there are no major systematic differences between the best-fit parameters derived from optical only data and the optical + UV photometry. GALEX FUV and NUV data improve the statistical errors in the model fits, especially for the hotter white dwarfs with spectral energy distributions that peak in the UV. Fitting the UV to optical spectral energy distributions also reveals UV-excess or UV-deficit objects. We use two different methods to identify outliers in our model fits. Known outliers include objects with unusual atmospheric compositions, strongly magnetic white dwarfs, and binary white dwarfs, including double degenerates and white dwarf + main-sequence systems. We present a list of 89 newly identified outliers based on GALEX UV data; follow-up observations of these objects will be required to constrain their nature. Several current and upcoming large scale spectroscopic surveys are targeting $>10^5$ white dwarfs. In addition, the ULTRASAT mission is planning an all-sky survey in the NUV band. A combination of the UV data from GALEX and ULTRASAT and optical data on these large samples of spectroscopically confirmed DA white dwarfs will provide an excellent opportunity to identify unusual white dwarfs in the solar neighborhood.","sentences":["We present a detailed model atmosphere analysis of 14001 DA white dwarfs from the Montreal White Dwarf Database with ultraviolet photometry from the GALEX mission.","We use the 100 pc sample, where the extinction is negligible, to demonstrate that there are no major systematic differences between the best-fit parameters derived from optical only data and the optical + UV photometry.","GALEX FUV and NUV data improve the statistical errors in the model fits, especially for the hotter white dwarfs with spectral energy distributions that peak in the UV.","Fitting the UV to optical spectral energy distributions also reveals UV-excess or UV-deficit objects.","We use two different methods to identify outliers in our model fits.","Known outliers include objects with unusual atmospheric compositions, strongly magnetic white dwarfs, and binary white dwarfs, including double degenerates and white dwarf + main-sequence systems.","We present a list of 89 newly identified outliers based on GALEX UV data; follow-up observations of these objects will be required to constrain their nature.","Several current and upcoming large scale spectroscopic surveys are targeting $>10^5$ white dwarfs.","In addition, the ULTRASAT mission is planning an all-sky survey in the NUV band.","A combination of the UV data from GALEX and ULTRASAT and optical data on these large samples of spectroscopically confirmed DA white dwarfs will provide an excellent opportunity to identify unusual white dwarfs in the solar neighborhood."],"url":"http://arxiv.org/abs/2306.03063v1"}
{"created":"2023-06-05","title":"Analyzing Syntactic Generalization Capacity of Pre-trained Language Models on Japanese Honorific Conversion","abstract":"Using Japanese honorifics is challenging because it requires not only knowledge of the grammatical rules but also contextual information, such as social relationships. It remains unclear whether pre-trained large language models (LLMs) can flexibly handle Japanese honorifics like humans. To analyze this, we introduce an honorific conversion task that considers social relationships among people mentioned in a conversation. We construct a Japanese honorifics dataset from problem templates of various sentence structures to investigate the syntactic generalization capacity of GPT-3, one of the leading LLMs, on this task under two settings: fine-tuning and prompt learning. Our results showed that the fine-tuned GPT-3 performed better in a context-aware honorific conversion task than the prompt-based one. The fine-tuned model demonstrated overall syntactic generalizability towards compound honorific sentences, except when tested with the data involving direct speech.","sentences":["Using Japanese honorifics is challenging because it requires not only knowledge of the grammatical rules but also contextual information, such as social relationships.","It remains unclear whether pre-trained large language models (LLMs) can flexibly handle Japanese honorifics like humans.","To analyze this, we introduce an honorific conversion task that considers social relationships among people mentioned in a conversation.","We construct a Japanese honorifics dataset from problem templates of various sentence structures to investigate the syntactic generalization capacity of GPT-3, one of the leading LLMs, on this task under two settings: fine-tuning and prompt learning.","Our results showed that the fine-tuned GPT-3 performed better in a context-aware honorific conversion task than the prompt-based one.","The fine-tuned model demonstrated overall syntactic generalizability towards compound honorific sentences, except when tested with the data involving direct speech."],"url":"http://arxiv.org/abs/2306.03055v1"}
{"created":"2023-06-05","title":"Forecasting seasonal criminality using SARIMA: an application to monthly aggravated assaults in California","abstract":"California experienced an increase in violent criminality during the last decade, largely driven by a surge in aggravated assaults. To address this challenge, accurate and timely forecasts of criminal activity may help state authorities plan ahead and distribute public resources efficiently to reduce crime. This paper forecasts monthly aggravated assaults in California using a publicly available dataset on state crimes and a time series SARIMA model that incorporates the highly seasonal behavior observed in the data. Results show that predictions with reasonable accuracy up to six months in advance are produced, showing the usefulness of these techniques to anticipate state-level criminal patterns and inform public policy.","sentences":["California experienced an increase in violent criminality during the last decade, largely driven by a surge in aggravated assaults.","To address this challenge, accurate and timely forecasts of criminal activity may help state authorities plan ahead and distribute public resources efficiently to reduce crime.","This paper forecasts monthly aggravated assaults in California using a publicly available dataset on state crimes and a time series SARIMA model that incorporates the highly seasonal behavior observed in the data.","Results show that predictions with reasonable accuracy up to six months in advance are produced, showing the usefulness of these techniques to anticipate state-level criminal patterns and inform public policy."],"url":"http://arxiv.org/abs/2306.03053v1"}
{"created":"2023-06-05","title":"SERT: A Transfomer Based Model for Spatio-Temporal Sensor Data with Missing Values for Environmental Monitoring","abstract":"Environmental monitoring is crucial to our understanding of climate change, biodiversity loss and pollution. The availability of large-scale spatio-temporal data from sources such as sensors and satellites allows us to develop sophisticated models for forecasting and understanding key drivers. However, the data collected from sensors often contain missing values due to faulty equipment or maintenance issues. The missing values rarely occur simultaneously leading to data that are multivariate misaligned sparse time series. We propose two models that are capable of performing multivariate spatio-temporal forecasting while handling missing data naturally without the need for imputation. The first model is a transformer-based model, which we name SERT (Spatio-temporal Encoder Representations from Transformers). The second is a simpler model named SST-ANN (Sparse Spatio-Temporal Artificial Neural Network) which is capable of providing interpretable results. We conduct extensive experiments on two different datasets for multivariate spatio-temporal forecasting and show that our models have competitive or superior performance to those at the state-of-the-art.","sentences":["Environmental monitoring is crucial to our understanding of climate change, biodiversity loss and pollution.","The availability of large-scale spatio-temporal data from sources such as sensors and satellites allows us to develop sophisticated models for forecasting and understanding key drivers.","However, the data collected from sensors often contain missing values due to faulty equipment or maintenance issues.","The missing values rarely occur simultaneously leading to data that are multivariate misaligned sparse time series.","We propose two models that are capable of performing multivariate spatio-temporal forecasting while handling missing data naturally without the need for imputation.","The first model is a transformer-based model, which we name SERT (Spatio-temporal Encoder Representations from Transformers).","The second is a simpler model named SST-ANN (Sparse Spatio-Temporal Artificial Neural Network) which is capable of providing interpretable results.","We conduct extensive experiments on two different datasets for multivariate spatio-temporal forecasting and show that our models have competitive or superior performance to those at the state-of-the-art."],"url":"http://arxiv.org/abs/2306.03042v1"}
{"created":"2023-06-05","title":"Learning Similarity among Users for Personalized Session-Based Recommendation from hierarchical structure of User-Session-Item","abstract":"The task of the session-based recommendation is to predict the next interaction of the user based on the anonymized user's behavior pattern. And personalized version of this system is a promising research field due to its availability to deal with user information. However, there's a problem that the user's preferences and historical sessions were not considered in the typical session-based recommendation since it concentrates only on user-item interaction. In addition, the existing personalized session-based recommendation model has a limited capability in that it only considers the preference of the current user without considering those of similar users. It means there can be the loss of information included within the hierarchical data structure of the user-session-item. To tackle with this problem, we propose USP-SBR(abbr. of User Similarity Powered - Session Based Recommender). To model global historical sessions of users, we propose UserGraph that has two types of nodes - ItemNode and UserNode. We then connect the nodes with three types of edges. The first type of edges connects ItemNode as chronological order, and the second connects ItemNode to UserNode, and the last connects UserNode to ItemNode. With these user embeddings, we propose additional contrastive loss, that makes users with similar intention be close to each other in the vector space. we apply graph neural network on these UserGraph and update nodes. Experimental results on two real-world datasets demonstrate that our method outperforms some state-of-the-art approaches.","sentences":["The task of the session-based recommendation is to predict the next interaction of the user based on the anonymized user's behavior pattern.","And personalized version of this system is a promising research field due to its availability to deal with user information.","However, there's a problem that the user's preferences and historical sessions were not considered in the typical session-based recommendation since it concentrates only on user-item interaction.","In addition, the existing personalized session-based recommendation model has a limited capability in that it only considers the preference of the current user without considering those of similar users.","It means there can be the loss of information included within the hierarchical data structure of the user-session-item.","To tackle with this problem, we propose USP-SBR(abbr.","of User Similarity Powered - Session Based Recommender).","To model global historical sessions of users, we propose UserGraph that has two types of nodes - ItemNode and UserNode.","We then connect the nodes with three types of edges.","The first type of edges connects ItemNode as chronological order, and the second connects ItemNode to UserNode, and the last connects UserNode to ItemNode.","With these user embeddings, we propose additional contrastive loss, that makes users with similar intention be close to each other in the vector space.","we apply graph neural network on these UserGraph and update nodes.","Experimental results on two real-world datasets demonstrate that our method outperforms some state-of-the-art approaches."],"url":"http://arxiv.org/abs/2306.03040v1"}
{"created":"2023-06-05","title":"Classification of Edge-dependent Labels of Nodes in Hypergraphs","abstract":"A hypergraph is a data structure composed of nodes and hyperedges, where each hyperedge is an any-sized subset of nodes. Due to the flexibility in hyperedge size, hypergraphs represent group interactions (e.g., co-authorship by more than two authors) more naturally and accurately than ordinary graphs. Interestingly, many real-world systems modeled as hypergraphs contain edge-dependent node labels, i.e., node labels that vary depending on hyperedges. For example, on co-authorship datasets, the same author (i.e., a node) can be the primary author in a paper (i.e., a hyperedge) but the corresponding author in another paper (i.e., another hyperedge).   In this work, we introduce a classification of edge-dependent node labels as a new problem. This problem can be used as a benchmark task for hypergraph neural networks, which recently have attracted great attention, and also the usefulness of edge-dependent node labels has been verified in various applications. To tackle this problem, we propose WHATsNet, a novel hypergraph neural network that represents the same node differently depending on the hyperedges it participates in by reflecting its varying importance in the hyperedges. To this end, WHATsNet models the relations between nodes within each hyperedge, using their relative centrality as positional encodings. In our experiments, we demonstrate that WHATsNet significantly and consistently outperforms ten competitors on six real-world hypergraphs, and we also show successful applications of WHATsNet to (a) ranking aggregation, (b) node clustering, and (c) product return prediction.","sentences":["A hypergraph is a data structure composed of nodes and hyperedges, where each hyperedge is an any-sized subset of nodes.","Due to the flexibility in hyperedge size, hypergraphs represent group interactions (e.g., co-authorship by more than two authors) more naturally and accurately than ordinary graphs.","Interestingly, many real-world systems modeled as hypergraphs contain edge-dependent node labels, i.e., node labels that vary depending on hyperedges.","For example, on co-authorship datasets, the same author (i.e., a node) can be the primary author in a paper (i.e., a hyperedge) but the corresponding author in another paper (i.e., another hyperedge).   ","In this work, we introduce a classification of edge-dependent node labels as a new problem.","This problem can be used as a benchmark task for hypergraph neural networks, which recently have attracted great attention, and also the usefulness of edge-dependent node labels has been verified in various applications.","To tackle this problem, we propose WHATsNet, a novel hypergraph neural network that represents the same node differently depending on the hyperedges it participates in by reflecting its varying importance in the hyperedges.","To this end, WHATsNet models the relations between nodes within each hyperedge, using their relative centrality as positional encodings.","In our experiments, we demonstrate that WHATsNet significantly and consistently outperforms ten competitors on six real-world hypergraphs, and we also show successful applications of WHATsNet to (a) ranking aggregation, (b) node clustering, and (c) product return prediction."],"url":"http://arxiv.org/abs/2306.03032v1"}
{"created":"2023-06-05","title":"Constraining extended cosmologies with GW$\\times$LSS cross-correlations","abstract":"The rapid development of gravitational wave astronomy provides the unique opportunity of exploring the dynamics of the Universe using clustering properties of coalescing binary black hole mergers. Gravitational wave data, along with information coming from future galaxy surveys, have the potential of shedding light about many open questions in Cosmology, including those regarding the nature of dark matter and dark energy. In this work we explore which combination of gravitational wave and galaxy survey datasets are able to provide the best constraints both on modified gravity theories and on the nature of the very same binary black hole events. In particular, by using the public Boltzmann code \\texttt{Multi\\_CLASS}, we compare cosmological constraints on popular $\\Lambda$CDM extensions coming from gravitational waves alone and in conjunction with either deep and localized or wide and shallow galaxy surveys. We show that constraints on extensions of General Relativity will be at the same level of existing limits from gravitational waves alone or one order of magnitude better when galaxy surveys are included. Furthermore, cross-correlating both kind of galaxy survey with gravitational waves datasets will allow to confidently rule in or out primordial black holes as dark matter candidate in the majority of the allowed parameter space.","sentences":["The rapid development of gravitational wave astronomy provides the unique opportunity of exploring the dynamics of the Universe using clustering properties of coalescing binary black hole mergers.","Gravitational wave data, along with information coming from future galaxy surveys, have the potential of shedding light about many open questions in Cosmology, including those regarding the nature of dark matter and dark energy.","In this work we explore which combination of gravitational wave and galaxy survey datasets are able to provide the best constraints both on modified gravity theories and on the nature of the very same binary black hole events.","In particular, by using the public Boltzmann code \\texttt{Multi\\_CLASS}, we compare cosmological constraints on popular $\\Lambda$CDM extensions coming from gravitational waves alone and in conjunction with either deep and localized or wide and shallow galaxy surveys.","We show that constraints on extensions of General Relativity will be at the same level of existing limits from gravitational waves alone or one order of magnitude better when galaxy surveys are included.","Furthermore, cross-correlating both kind of galaxy survey with gravitational waves datasets will allow to confidently rule in or out primordial black holes as dark matter candidate in the majority of the allowed parameter space."],"url":"http://arxiv.org/abs/2306.03031v1"}
{"created":"2023-06-05","title":"Benchmarking Large Language Models on CMExam -- A Comprehensive Chinese Medical Exam Dataset","abstract":"Recent advancements in large language models (LLMs) have transformed the field of question answering (QA). However, evaluating LLMs in the medical field is challenging due to the lack of standardized and comprehensive datasets. To address this gap, we introduce CMExam, sourced from the Chinese National Medical Licensing Examination. CMExam consists of 60K+ multiple-choice questions for standardized and objective evaluations, as well as solution explanations for model reasoning evaluation in an open-ended manner. For in-depth analyses of LLMs, we invited medical professionals to label five additional question-wise annotations, including disease groups, clinical departments, medical disciplines, areas of competency, and question difficulty levels. Alongside the dataset, we further conducted thorough experiments with representative LLMs and QA algorithms on CMExam. The results show that GPT-4 had the best accuracy of 61.5% and a weighted F1 score of 0.616. These results highlight a great disparity when compared to human accuracy, which stood at 71.6%. For explanation tasks, while LLMs could generate relevant reasoning and demonstrate improved performance after finetuning, they fall short of a desired standard, indicating ample room for improvement. To the best of our knowledge, CMExam is the first Chinese medical exam dataset to provide comprehensive medical annotations. The experiments and findings of LLM evaluation also provide valuable insights into the challenges and potential solutions in developing Chinese medical QA systems and LLM evaluation pipelines. The dataset and relevant code are available at https://github.com/williamliujl/CMExam.","sentences":["Recent advancements in large language models (LLMs) have transformed the field of question answering (QA).","However, evaluating LLMs in the medical field is challenging due to the lack of standardized and comprehensive datasets.","To address this gap, we introduce CMExam, sourced from the Chinese National Medical Licensing Examination.","CMExam consists of 60K+ multiple-choice questions for standardized and objective evaluations, as well as solution explanations for model reasoning evaluation in an open-ended manner.","For in-depth analyses of LLMs, we invited medical professionals to label five additional question-wise annotations, including disease groups, clinical departments, medical disciplines, areas of competency, and question difficulty levels.","Alongside the dataset, we further conducted thorough experiments with representative LLMs and QA algorithms on CMExam.","The results show that GPT-4 had the best accuracy of 61.5% and a weighted F1 score of 0.616.","These results highlight a great disparity when compared to human accuracy, which stood at 71.6%.","For explanation tasks, while LLMs could generate relevant reasoning and demonstrate improved performance after finetuning, they fall short of a desired standard, indicating ample room for improvement.","To the best of our knowledge, CMExam is the first Chinese medical exam dataset to provide comprehensive medical annotations.","The experiments and findings of LLM evaluation also provide valuable insights into the challenges and potential solutions in developing Chinese medical QA systems and LLM evaluation pipelines.","The dataset and relevant code are available at https://github.com/williamliujl/CMExam."],"url":"http://arxiv.org/abs/2306.03030v1"}
{"created":"2023-06-05","title":"Local Boosting for Weakly-Supervised Learning","abstract":"Boosting is a commonly used technique to enhance the performance of a set of base models by combining them into a strong ensemble model. Though widely adopted, boosting is typically used in supervised learning where the data is labeled accurately. However, in weakly supervised learning, where most of the data is labeled through weak and noisy sources, it remains nontrivial to design effective boosting approaches. In this work, we show that the standard implementation of the convex combination of base learners can hardly work due to the presence of noisy labels. Instead, we propose $\\textit{LocalBoost}$, a novel framework for weakly-supervised boosting. LocalBoost iteratively boosts the ensemble model from two dimensions, i.e., intra-source and inter-source. The intra-source boosting introduces locality to the base learners and enables each base learner to focus on a particular feature regime by training new base learners on granularity-varying error regions. For the inter-source boosting, we leverage a conditional function to indicate the weak source where the sample is more likely to appear. To account for the weak labels, we further design an estimate-then-modify approach to compute the model weights. Experiments on seven datasets show that our method significantly outperforms vanilla boosting methods and other weakly-supervised methods.","sentences":["Boosting is a commonly used technique to enhance the performance of a set of base models by combining them into a strong ensemble model.","Though widely adopted, boosting is typically used in supervised learning where the data is labeled accurately.","However, in weakly supervised learning, where most of the data is labeled through weak and noisy sources, it remains nontrivial to design effective boosting approaches.","In this work, we show that the standard implementation of the convex combination of base learners can hardly work due to the presence of noisy labels.","Instead, we propose $\\textit{LocalBoost}$, a novel framework for weakly-supervised boosting.","LocalBoost iteratively boosts the ensemble model from two dimensions, i.e., intra-source and inter-source.","The intra-source boosting introduces locality to the base learners and enables each base learner to focus on a particular feature regime by training new base learners on granularity-varying error regions.","For the inter-source boosting, we leverage a conditional function to indicate the weak source where the sample is more likely to appear.","To account for the weak labels, we further design an estimate-then-modify approach to compute the model weights.","Experiments on seven datasets show that our method significantly outperforms vanilla boosting methods and other weakly-supervised methods."],"url":"http://arxiv.org/abs/2306.02859v1"}
{"created":"2023-06-05","title":"OTF: Optimal Transport based Fusion of Supervised and Self-Supervised Learning Models for Automatic Speech Recognition","abstract":"Self-Supervised Learning (SSL) Automatic Speech Recognition (ASR) models have shown great promise over Supervised Learning (SL) ones in low-resource settings. However, the advantages of SSL are gradually weakened when the amount of labeled data increases in many industrial applications. To further improve the ASR performance when abundant labels are available, we first explore the potential of combining SL and SSL ASR models via analyzing their complementarity in recognition accuracy and optimization property. Then, we propose a novel Optimal Transport based Fusion (OTF) method for SL and SSL models without incurring extra computation cost in inference. Specifically, optimal transport is adopted to softly align the layer-wise weights to unify the two different networks into a single one. Experimental results on the public 1k-hour English LibriSpeech dataset and our in-house 2.6k-hour Chinese dataset show that OTF largely outperforms the individual models with lower error rates.","sentences":["Self-Supervised Learning (SSL) Automatic Speech Recognition (ASR) models have shown great promise over Supervised Learning (SL) ones in low-resource settings.","However, the advantages of SSL are gradually weakened when the amount of labeled data increases in many industrial applications.","To further improve the ASR performance when abundant labels are available, we first explore the potential of combining SL and SSL ASR models via analyzing their complementarity in recognition accuracy and optimization property.","Then, we propose a novel Optimal Transport based Fusion (OTF) method for SL and SSL models without incurring extra computation cost in inference.","Specifically, optimal transport is adopted to softly align the layer-wise weights to unify the two different networks into a single one.","Experimental results on the public 1k-hour English LibriSpeech dataset and our in-house 2.6k-hour Chinese dataset show that OTF largely outperforms the individual models with lower error rates."],"url":"http://arxiv.org/abs/2306.02541v1"}
{"created":"2023-06-05","title":"On Emergence of Clean-Priority Learning in Early Stopped Neural Networks","abstract":"When random label noise is added to a training dataset, the prediction error of a neural network on a label-noise-free test dataset initially improves during early training but eventually deteriorates, following a U-shaped dependence on training time. This behaviour is believed to be a result of neural networks learning the pattern of clean data first and fitting the noise later in the training, a phenomenon that we refer to as clean-priority learning. In this study, we aim to explore the learning dynamics underlying this phenomenon. We theoretically demonstrate that, in the early stage of training, the update direction of gradient descent is determined by the clean subset of training data, leaving the noisy subset has minimal to no impact, resulting in a prioritization of clean learning. Moreover, we show both theoretically and experimentally, as the clean-priority learning goes on, the dominance of the gradients of clean samples over those of noisy samples diminishes, and finally results in a termination of the clean-priority learning and fitting of the noisy samples.","sentences":["When random label noise is added to a training dataset, the prediction error of a neural network on a label-noise-free test dataset initially improves during early training but eventually deteriorates, following a U-shaped dependence on training time.","This behaviour is believed to be a result of neural networks learning the pattern of clean data first and fitting the noise later in the training, a phenomenon that we refer to as clean-priority learning.","In this study, we aim to explore the learning dynamics underlying this phenomenon.","We theoretically demonstrate that, in the early stage of training, the update direction of gradient descent is determined by the clean subset of training data, leaving the noisy subset has minimal to no impact, resulting in a prioritization of clean learning.","Moreover, we show both theoretically and experimentally, as the clean-priority learning goes on, the dominance of the gradients of clean samples over those of noisy samples diminishes, and finally results in a termination of the clean-priority learning and fitting of the noisy samples."],"url":"http://arxiv.org/abs/2306.02533v1"}
{"created":"2023-06-05","title":"Integrated Sensing, Computation, and Communication for UAV-assisted Federated Edge Learning","abstract":"Federated edge learning (FEEL) enables privacy-preserving model training through periodic communication between edge devices and the server. Unmanned Aerial Vehicle (UAV)-mounted edge devices are particularly advantageous for FEEL due to their flexibility and mobility in efficient data collection. In UAV-assisted FEEL, sensing, computation, and communication are coupled and compete for limited onboard resources, and UAV deployment also affects sensing and communication performance. Therefore, the joint design of UAV deployment and resource allocation is crucial to achieving the optimal training performance. In this paper, we address the problem of joint UAV deployment design and resource allocation for FEEL via a concrete case study of human motion recognition based on wireless sensing. We first analyze the impact of UAV deployment on the sensing quality and identify a threshold value for the sensing elevation angle that guarantees a satisfactory quality of data samples. Due to the non-ideal sensing channels, we consider the probabilistic sensing model, where the successful sensing probability of each UAV is determined by its position. Then, we derive the upper bound of the FEEL training loss as a function of the sensing probability. Theoretical results suggest that the convergence rate can be improved if UAVs have a uniform successful sensing probability. Based on this analysis, we formulate a training time minimization problem by jointly optimizing UAV deployment, integrated sensing, computation, and communication (ISCC) resources under a desirable optimality gap constraint. To solve this challenging mixed-integer non-convex problem, we apply the alternating optimization technique, and propose the bandwidth, batch size, and position optimization (BBPO) scheme to optimize these three decision variables alternately.","sentences":["Federated edge learning (FEEL) enables privacy-preserving model training through periodic communication between edge devices and the server.","Unmanned Aerial Vehicle (UAV)-mounted edge devices are particularly advantageous for FEEL due to their flexibility and mobility in efficient data collection.","In UAV-assisted FEEL, sensing, computation, and communication are coupled and compete for limited onboard resources, and UAV deployment also affects sensing and communication performance.","Therefore, the joint design of UAV deployment and resource allocation is crucial to achieving the optimal training performance.","In this paper, we address the problem of joint UAV deployment design and resource allocation for FEEL via a concrete case study of human motion recognition based on wireless sensing.","We first analyze the impact of UAV deployment on the sensing quality and identify a threshold value for the sensing elevation angle that guarantees a satisfactory quality of data samples.","Due to the non-ideal sensing channels, we consider the probabilistic sensing model, where the successful sensing probability of each UAV is determined by its position.","Then, we derive the upper bound of the FEEL training loss as a function of the sensing probability.","Theoretical results suggest that the convergence rate can be improved if UAVs have a uniform successful sensing probability.","Based on this analysis, we formulate a training time minimization problem by jointly optimizing UAV deployment, integrated sensing, computation, and communication (ISCC) resources under a desirable optimality gap constraint.","To solve this challenging mixed-integer non-convex problem, we apply the alternating optimization technique, and propose the bandwidth, batch size, and position optimization (BBPO) scheme to optimize these three decision variables alternately."],"url":"http://arxiv.org/abs/2306.02990v1"}
{"created":"2023-06-05","title":"A Deep Learning Approach Utilizing Covariance Matrix Analysis for the ISBI Edited MRS Reconstruction Challenge","abstract":"This work proposes a method to accelerate the acquisition of high-quality edited magnetic resonance spectroscopy (MRS) scans using machine learning models taking the sample covariance matrix as input. The method is invariant to the number of transients and robust to noisy input data for both synthetic as well as in-vivo scenarios.","sentences":["This work proposes a method to accelerate the acquisition of high-quality edited magnetic resonance spectroscopy (MRS) scans using machine learning models taking the sample covariance matrix as input.","The method is invariant to the number of transients and robust to noisy input data for both synthetic as well as in-vivo scenarios."],"url":"http://arxiv.org/abs/2306.02984v1"}
{"created":"2023-06-05","title":"Simultaneous or Sequential Training? How Speech Representations Cooperate in a Multi-Task Self-Supervised Learning System","abstract":"Speech representation learning with self-supervised algorithms has resulted in notable performance boosts in many downstream tasks. Recent work combined self-supervised learning (SSL) and visually grounded speech (VGS) processing mechanisms for representation learning. The joint training with SSL and VGS mechanisms provides the opportunity to utilize both unlabeled speech and speech-related visual information based on data availability. This has shown to enhance the quality of learned representations, especially at encoding semantic- and lexical-level knowledge. In this work, we further study the joint optimization of wav2vec 2.0-based SSL and transformer-based VGS as a multi-task learning system. We explore a set of training scenarios to understand how speech representations are shared or transferred between the two tasks, and what is the optimal training strategy for cross-modal semantic retrieval and phoneme discrimination performance. As a result, we find that sequential training with wav2vec 2.0 first and VGS next provides higher performance on audio-visual retrieval compared to simultaneous optimization of both learning mechanisms. However, the parallel SSL-VGS training reduces the effects of catastrophic forgetting when switching between optimization criteria. Moreover, the results suggest that phonemic representations learned through the VGS mechanism may generalize better across datasets compared to those learned with SSL.","sentences":["Speech representation learning with self-supervised algorithms has resulted in notable performance boosts in many downstream tasks.","Recent work combined self-supervised learning (SSL) and visually grounded speech (VGS) processing mechanisms for representation learning.","The joint training with SSL and VGS mechanisms provides the opportunity to utilize both unlabeled speech and speech-related visual information based on data availability.","This has shown to enhance the quality of learned representations, especially at encoding semantic- and lexical-level knowledge.","In this work, we further study the joint optimization of wav2vec 2.0-based SSL and transformer-based VGS as a multi-task learning system.","We explore a set of training scenarios to understand how speech representations are shared or transferred between the two tasks, and what is the optimal training strategy for cross-modal semantic retrieval and phoneme discrimination performance.","As a result, we find that sequential training with wav2vec 2.0 first and VGS next provides higher performance on audio-visual retrieval compared to simultaneous optimization of both learning mechanisms.","However, the parallel SSL-VGS training reduces the effects of catastrophic forgetting when switching between optimization criteria.","Moreover, the results suggest that phonemic representations learned through the VGS mechanism may generalize better across datasets compared to those learned with SSL."],"url":"http://arxiv.org/abs/2306.02972v1"}
{"created":"2023-06-05","title":"Complex Preferences for Different Convergent Priors in Discrete Graph Diffusion","abstract":"Diffusion models have achieved state-of-the-art performance in generating many different kinds of data, including images, text, and videos. Despite their success, there has been limited research on how the underlying diffusion process and the final convergent prior can affect generative performance; this research has also been limited to continuous data types and a score-based diffusion framework. To fill this gap, we explore how different discrete diffusion kernels (which converge to different prior distributions) affect the performance of diffusion models for graphs. To this end, we developed a novel formulation of a family of discrete diffusion kernels which are easily adjustable to converge to different Bernoulli priors, and we study the effect of these different kernels on generative performance. We show that the quality of generated graphs is sensitive to the prior used, and that the optimal choice cannot be explained by obvious statistics or metrics, which challenges the intuitions which previous works have suggested.","sentences":["Diffusion models have achieved state-of-the-art performance in generating many different kinds of data, including images, text, and videos.","Despite their success, there has been limited research on how the underlying diffusion process and the final convergent prior can affect generative performance; this research has also been limited to continuous data types and a score-based diffusion framework.","To fill this gap, we explore how different discrete diffusion kernels (which converge to different prior distributions) affect the performance of diffusion models for graphs.","To this end, we developed a novel formulation of a family of discrete diffusion kernels which are easily adjustable to converge to different Bernoulli priors, and we study the effect of these different kernels on generative performance.","We show that the quality of generated graphs is sensitive to the prior used, and that the optimal choice cannot be explained by obvious statistics or metrics, which challenges the intuitions which previous works have suggested."],"url":"http://arxiv.org/abs/2306.02957v1"}
{"created":"2023-06-05","title":"A Simple and Flexible Modeling for Mental Disorder Detection by Learning from Clinical Questionnaires","abstract":"Social media is one of the most highly sought resources for analyzing characteristics of the language by its users. In particular, many researchers utilized various linguistic features of mental health problems from social media. However, existing approaches to detecting mental disorders face critical challenges, such as the scarcity of high-quality data or the trade-off between addressing the complexity of models and presenting interpretable results grounded in expert domain knowledge. To address these challenges, we design a simple but flexible model that preserves domain-based interpretability. We propose a novel approach that captures the semantic meanings directly from the text and compares them to symptom-related descriptions. Experimental results demonstrate that our model outperforms relevant baselines on various mental disorder detection tasks. Our detailed analysis shows that the proposed model is effective at leveraging domain knowledge, transferable to other mental disorders, and providing interpretable detection results.","sentences":["Social media is one of the most highly sought resources for analyzing characteristics of the language by its users.","In particular, many researchers utilized various linguistic features of mental health problems from social media.","However, existing approaches to detecting mental disorders face critical challenges, such as the scarcity of high-quality data or the trade-off between addressing the complexity of models and presenting interpretable results grounded in expert domain knowledge.","To address these challenges, we design a simple but flexible model that preserves domain-based interpretability.","We propose a novel approach that captures the semantic meanings directly from the text and compares them to symptom-related descriptions.","Experimental results demonstrate that our model outperforms relevant baselines on various mental disorder detection tasks.","Our detailed analysis shows that the proposed model is effective at leveraging domain knowledge, transferable to other mental disorders, and providing interpretable detection results."],"url":"http://arxiv.org/abs/2306.02955v1"}
{"created":"2023-06-05","title":"INDigo: An INN-Guided Probabilistic Diffusion Algorithm for Inverse Problems","abstract":"Recently it has been shown that using diffusion models for inverse problems can lead to remarkable results. However, these approaches require a closed-form expression of the degradation model and can not support complex degradations. To overcome this limitation, we propose a method (INDigo) that combines invertible neural networks (INN) and diffusion models for general inverse problems. Specifically, we train the forward process of INN to simulate an arbitrary degradation process and use the inverse as a reconstruction process. During the diffusion sampling process, we impose an additional data-consistency step that minimizes the distance between the intermediate result and the INN-optimized result at every iteration, where the INN-optimized image is composed of the coarse information given by the observed degraded image and the details generated by the diffusion process. With the help of INN, our algorithm effectively estimates the details lost in the degradation process and is no longer limited by the requirement of knowing the closed-form expression of the degradation model. Experiments demonstrate that our algorithm obtains competitive results compared with recently leading methods both quantitatively and visually. Moreover, our algorithm performs well on more complex degradation models and real-world low-quality images.","sentences":["Recently it has been shown that using diffusion models for inverse problems can lead to remarkable results.","However, these approaches require a closed-form expression of the degradation model and can not support complex degradations.","To overcome this limitation, we propose a method (INDigo) that combines invertible neural networks (INN) and diffusion models for general inverse problems.","Specifically, we train the forward process of INN to simulate an arbitrary degradation process and use the inverse as a reconstruction process.","During the diffusion sampling process, we impose an additional data-consistency step that minimizes the distance between the intermediate result and the INN-optimized result at every iteration, where the INN-optimized image is composed of the coarse information given by the observed degraded image and the details generated by the diffusion process.","With the help of INN, our algorithm effectively estimates the details lost in the degradation process and is no longer limited by the requirement of knowing the closed-form expression of the degradation model.","Experiments demonstrate that our algorithm obtains competitive results compared with recently leading methods both quantitatively and visually.","Moreover, our algorithm performs well on more complex degradation models and real-world low-quality images."],"url":"http://arxiv.org/abs/2306.02949v1"}
{"created":"2023-06-05","title":"Continual Learning with Pretrained Backbones by Tuning in the Input Space","abstract":"The intrinsic difficulty in adapting deep learning models to non-stationary environments limits the applicability of neural networks to real-world tasks. This issue is critical in practical supervised learning settings, such as the ones in which a pre-trained model computes projections toward a latent space where different task predictors are sequentially learned over time. As a matter of fact, incrementally fine-tuning the whole model to better adapt to new tasks usually results in catastrophic forgetting, with decreasing performance over the past experiences and losing valuable knowledge from the pre-training stage. In this paper, we propose a novel strategy to make the fine-tuning procedure more effective, by avoiding to update the pre-trained part of the network and learning not only the usual classification head, but also a set of newly-introduced learnable parameters that are responsible for transforming the input data. This process allows the network to effectively leverage the pre-training knowledge and find a good trade-off between plasticity and stability with modest computational efforts, thus especially suitable for on-the-edge settings. Our experiments on four image classification problems in a continual learning setting confirm the quality of the proposed approach when compared to several fine-tuning procedures and to popular continual learning methods.","sentences":["The intrinsic difficulty in adapting deep learning models to non-stationary environments limits the applicability of neural networks to real-world tasks.","This issue is critical in practical supervised learning settings, such as the ones in which a pre-trained model computes projections toward a latent space where different task predictors are sequentially learned over time.","As a matter of fact, incrementally fine-tuning the whole model to better adapt to new tasks usually results in catastrophic forgetting, with decreasing performance over the past experiences and losing valuable knowledge from the pre-training stage.","In this paper, we propose a novel strategy to make the fine-tuning procedure more effective, by avoiding to update the pre-trained part of the network and learning not only the usual classification head, but also a set of newly-introduced learnable parameters that are responsible for transforming the input data.","This process allows the network to effectively leverage the pre-training knowledge and find a good trade-off between plasticity and stability with modest computational efforts, thus especially suitable for on-the-edge settings.","Our experiments on four image classification problems in a continual learning setting confirm the quality of the proposed approach when compared to several fine-tuning procedures and to popular continual learning methods."],"url":"http://arxiv.org/abs/2306.02947v1"}
{"created":"2023-06-05","title":"Zero shot framework for satellite image restoration","abstract":"Satellite images are typically subject to multiple distortions. Different factors affect the quality of satellite images, including changes in atmosphere, surface reflectance, sun illumination, viewing geometries etc., limiting its application to downstream tasks. In supervised networks, the availability of paired datasets is a strong assumption. Consequently, many unsupervised algorithms have been proposed to address this problem. These methods synthetically generate a large dataset of degraded images using image formation models. A neural network is then trained with an adversarial loss to discriminate between images from distorted and clean domains. However, these methods yield suboptimal performance when tested on real images that do not necessarily conform to the generation mechanism. Also, they require a large amount of training data and are rendered unsuitable when only a few images are available. We propose a distortion disentanglement and knowledge distillation framework for satellite image restoration to address these important issues. Our algorithm requires only two images: the distorted satellite image to be restored and a reference image with similar semantics. Specifically, we first propose a mechanism to disentangle distortion. This enables us to generate images with varying degrees of distortion using the disentangled distortion and the reference image. We then propose the use of knowledge distillation to train a restoration network using the generated image pairs. As a final step, the distorted image is passed through the restoration network to get the final output. Ablation studies show that our proposed mechanism successfully disentangles distortion.","sentences":["Satellite images are typically subject to multiple distortions.","Different factors affect the quality of satellite images, including changes in atmosphere, surface reflectance, sun illumination, viewing geometries etc., limiting its application to downstream tasks.","In supervised networks, the availability of paired datasets is a strong assumption.","Consequently, many unsupervised algorithms have been proposed to address this problem.","These methods synthetically generate a large dataset of degraded images using image formation models.","A neural network is then trained with an adversarial loss to discriminate between images from distorted and clean domains.","However, these methods yield suboptimal performance when tested on real images that do not necessarily conform to the generation mechanism.","Also, they require a large amount of training data and are rendered unsuitable when only a few images are available.","We propose a distortion disentanglement and knowledge distillation framework for satellite image restoration to address these important issues.","Our algorithm requires only two images: the distorted satellite image to be restored and a reference image with similar semantics.","Specifically, we first propose a mechanism to disentangle distortion.","This enables us to generate images with varying degrees of distortion using the disentangled distortion and the reference image.","We then propose the use of knowledge distillation to train a restoration network using the generated image pairs.","As a final step, the distorted image is passed through the restoration network to get the final output.","Ablation studies show that our proposed mechanism successfully disentangles distortion."],"url":"http://arxiv.org/abs/2306.02921v1"}
{"created":"2023-06-05","title":"SelfEvolve: A Code Evolution Framework via Large Language Models","abstract":"Large language models (LLMs) have already revolutionized code generation, after being pretrained on publicly available code data. However, while various methods have been proposed to augment LLMs with retrieved knowledge and enhance the quality of code generation, the performance of these retrieval-based methods is limited by the strength of the retrievers used. In addition, while LLMs show great emergent ability, they still struggle to produce the correct code in one turn. To address these challenges, we propose a novel two-step pipeline, called \\autoknow, that leverages LLMs as both knowledge providers and self-reflective programmers. Unlike retrieval-based methods, \\autoknow~obtains the knowledge from input prompts and generates intermediate code based on the generated knowledge. After that, \\autoknow~asks LLM to act as an expert programmer to perform debugging for the generated code. This is achieved by receiving the error message from the interpreter, without requiring special test cases for correctness verification. We evaluate \\autoknow~on three code generation datasets, including DS-1000 for data science code, HumanEval for software engineering code, and TransCoder for C++-to-Python translation. Our empirical experiments show that \\autoknow~outperforms strong baselines by a significant margin on all datasets. We also conduct exhaustive analytical experiments to validate the effectiveness of the two stages of \\autoknow, and find that both are superior to other prompting-based methods. Further scalability analysis demonstrates that \\autoknow~can be adapted to other more advanced models, such as GPT-4, and bring consistent efficacy improvement.","sentences":["Large language models (LLMs) have already revolutionized code generation, after being pretrained on publicly available code data.","However, while various methods have been proposed to augment LLMs with retrieved knowledge and enhance the quality of code generation, the performance of these retrieval-based methods is limited by the strength of the retrievers used.","In addition, while LLMs show great emergent ability, they still struggle to produce the correct code in one turn.","To address these challenges, we propose a novel two-step pipeline, called \\autoknow, that leverages LLMs as both knowledge providers and self-reflective programmers.","Unlike retrieval-based methods, \\autoknow~obtains the knowledge from input prompts and generates intermediate code based on the generated knowledge.","After that, \\autoknow~asks LLM to act as an expert programmer to perform debugging for the generated code.","This is achieved by receiving the error message from the interpreter, without requiring special test cases for correctness verification.","We evaluate \\autoknow~on three code generation datasets, including DS-1000 for data science code, HumanEval for software engineering code, and TransCoder for C++-to-Python translation.","Our empirical experiments show that \\autoknow~outperforms strong baselines by a significant margin on all datasets.","We also conduct exhaustive analytical experiments to validate the effectiveness of the two stages of \\autoknow, and find that both are superior to other prompting-based methods.","Further scalability analysis demonstrates that \\autoknow~can be adapted to other more advanced models, such as GPT-4, and bring consistent efficacy improvement."],"url":"http://arxiv.org/abs/2306.02907v1"}
{"created":"2023-06-05","title":"AutoSamp: Autoencoding MRI Sampling via Variational Information Maximization","abstract":"Accelerating MRI scans requires undersampling k-space data. Optimizing sampling patterns is a daunting task due to the non-convex nature of the problem. To cope with this challenge, we put forth AutoSamp, a novel deep learning framework that leverages variational information maximization to enable joint optimization of sampling pattern and reconstruction of MRI scans. We represent the encoder as a non-uniform Fast Fourier Transform that allows continuous optimization of k-space samples on a non-Cartesian plane, while the decoder is a deep reconstruction network. Experiments with publicly available MRI datasets show improved reconstruction quality of our data-driven sampling over the prevailing variable density and variable density Poisson disc sampling. In particular, we demonstrate that our data-driven sampling optimization method achieves 4.4dB, 2.0dB, 0.75dB, 0.7dB PSNR improvement over reconstruction with Poisson Disc masks for acceleration factors R=5,10,15,25, respectively. Moreover, we analyze the learned sampling patterns with respect to changes in acceleration factor, measurement noise, anatomy, and coil sensitivities. We show that all these factors contribute to the optimization result by impacting the sampling density, k-space coverage and point spread functions of the learned sampling patterns.","sentences":["Accelerating MRI scans requires undersampling k-space data.","Optimizing sampling patterns is a daunting task due to the non-convex nature of the problem.","To cope with this challenge, we put forth AutoSamp, a novel deep learning framework that leverages variational information maximization to enable joint optimization of sampling pattern and reconstruction of MRI scans.","We represent the encoder as a non-uniform Fast Fourier Transform that allows continuous optimization of k-space samples on a non-Cartesian plane, while the decoder is a deep reconstruction network.","Experiments with publicly available MRI datasets show improved reconstruction quality of our data-driven sampling over the prevailing variable density and variable density Poisson disc sampling.","In particular, we demonstrate that our data-driven sampling optimization method achieves 4.4dB, 2.0dB, 0.75dB, 0.7dB PSNR improvement over reconstruction with Poisson Disc masks for acceleration factors R=5,10,15,25, respectively.","Moreover, we analyze the learned sampling patterns with respect to changes in acceleration factor, measurement noise, anatomy, and coil sensitivities.","We show that all these factors contribute to the optimization result by impacting the sampling density, k-space coverage and point spread functions of the learned sampling patterns."],"url":"http://arxiv.org/abs/2306.02888v1"}
