{"created":"2023-11-09 18:59:58","title":"Window Attention is Bugged: How not to Interpolate Position Embeddings","abstract":"Window attention, position embeddings, and high resolution finetuning are core concepts in the modern transformer era of computer vision. However, we find that naively combining these near ubiquitous components can have a detrimental effect on performance. The issue is simple: interpolating position embeddings while using window attention is wrong. We study two state-of-the-art methods that have these three components, namely Hiera and ViTDet, and find that both do indeed suffer from this bug. To fix it, we introduce a simple absolute window position embedding strategy, which solves the bug outright in Hiera and allows us to increase both speed and performance of the model in ViTDet. We finally combine the two to obtain HieraDet, which achieves 61.7 box mAP on COCO, making it state-of-the-art for models that only use ImageNet-1k pretraining. This all stems from what is essentially a 3 line bug fix, which we name \"absolute win\".","sentences":["Window attention, position embeddings, and high resolution finetuning are core concepts in the modern transformer era of computer vision.","However, we find that naively combining these near ubiquitous components can have a detrimental effect on performance.","The issue is simple: interpolating position embeddings while using window attention is wrong.","We study two state-of-the-art methods that have these three components, namely Hiera and ViTDet, and find that both do indeed suffer from this bug.","To fix it, we introduce a simple absolute window position embedding strategy, which solves the bug outright in Hiera and allows us to increase both speed and performance of the model in ViTDet.","We finally combine the two to obtain HieraDet, which achieves 61.7 box mAP on COCO, making it state-of-the-art for models that only use ImageNet-1k pretraining.","This all stems from what is essentially a 3 line bug fix, which we name \"absolute win\"."],"url":"http://arxiv.org/abs/2311.05613v1"}
{"created":"2023-11-09 18:59:38","title":"Efficient Parallelization Layouts for Large-Scale Distributed Model Training","abstract":"Efficiently training large language models requires parallelizing across hundreds of hardware accelerators and invoking various compute and memory optimizations. When combined, many of these strategies have complex interactions regarding the final training efficiency. Prior work tackling this problem did not have access to the latest set of optimizations, such as FlashAttention or sequence parallelism. In this work, we conduct a comprehensive ablation study of possible training configurations for large language models. We distill this large study into several key recommendations for the most efficient training. For instance, we find that using a micro-batch size of 1 usually enables the most efficient training layouts. Larger micro-batch sizes necessitate activation checkpointing or higher degrees of model parallelism and also lead to larger pipeline bubbles. Our most efficient configurations enable us to achieve state-of-the-art training efficiency results over a range of model sizes, most notably a Model FLOPs utilization of 70.5% when training a 13B model.","sentences":["Efficiently training large language models requires parallelizing across hundreds of hardware accelerators and invoking various compute and memory optimizations.","When combined, many of these strategies have complex interactions regarding the final training efficiency.","Prior work tackling this problem did not have access to the latest set of optimizations, such as FlashAttention or sequence parallelism.","In this work, we conduct a comprehensive ablation study of possible training configurations for large language models.","We distill this large study into several key recommendations for the most efficient training.","For instance, we find that using a micro-batch size of 1 usually enables the most efficient training layouts.","Larger micro-batch sizes necessitate activation checkpointing or higher degrees of model parallelism and also lead to larger pipeline bubbles.","Our most efficient configurations enable us to achieve state-of-the-art training efficiency results over a range of model sizes, most notably a Model FLOPs utilization of 70.5% when training a 13B model."],"url":"http://arxiv.org/abs/2311.05610v1"}
{"created":"2023-11-09 18:59:24","title":"What Do I Hear? Generating Sounds for Visuals with ChatGPT","abstract":"This short paper introduces a workflow for generating realistic soundscapes for visual media. In contrast to prior work, which primarily focus on matching sounds for on-screen visuals, our approach extends to suggesting sounds that may not be immediately visible but are essential to crafting a convincing and immersive auditory environment. Our key insight is leveraging the reasoning capabilities of language models, such as ChatGPT. In this paper, we describe our workflow, which includes creating a scene context, brainstorming sounds, and generating the sounds.","sentences":["This short paper introduces a workflow for generating realistic soundscapes for visual media.","In contrast to prior work, which primarily focus on matching sounds for on-screen visuals, our approach extends to suggesting sounds that may not be immediately visible but are essential to crafting a convincing and immersive auditory environment.","Our key insight is leveraging the reasoning capabilities of language models, such as ChatGPT.","In this paper, we describe our workflow, which includes creating a scene context, brainstorming sounds, and generating the sounds."],"url":"http://arxiv.org/abs/2311.05609v1"}
{"created":"2023-11-09 18:59:11","title":"FigStep: Jailbreaking Large Vision-language Models via Typographic Visual Prompts","abstract":"Large vision-language models (VLMs) like GPT-4V represent an unprecedented revolution in the field of artificial intelligence (AI). Compared to single-modal large language models (LLMs), VLMs possess more versatile capabilities by incorporating additional modalities (e.g., images). Meanwhile, there's a rising enthusiasm in the AI community to develop open-source VLMs, such as LLaVA and MiniGPT4, which, however, have not undergone rigorous safety assessment. In this paper, to demonstrate that more modalities lead to unforeseen AI safety issues, we propose FigStep, a novel jailbreaking framework against VLMs. FigStep feeds harmful instructions into VLMs through the image channel and then uses benign text prompts to induce VLMs to output contents that violate common AI safety policies. Our experimental results show that FigStep can achieve an average attack success rate of 94.8% across 2 families of popular open-source VLMs, LLaVA and MiniGPT4 (a total of 5 VLMs). Moreover, we demonstrate that the methodology of FigStep can even jailbreak GPT-4V, which already leverages several system-level mechanisms to filter harmful queries. Above all, our experimental results reveal that VLMs are vulnerable to jailbreaking attacks, which highlights the necessity of novel safety alignments between visual and textual modalities.","sentences":["Large vision-language models (VLMs) like GPT-4V represent an unprecedented revolution in the field of artificial intelligence (AI).","Compared to single-modal large language models (LLMs), VLMs possess more versatile capabilities by incorporating additional modalities (e.g., images).","Meanwhile, there's a rising enthusiasm in the AI community to develop open-source VLMs, such as LLaVA and MiniGPT4, which, however, have not undergone rigorous safety assessment.","In this paper, to demonstrate that more modalities lead to unforeseen AI safety issues, we propose FigStep, a novel jailbreaking framework against VLMs.","FigStep feeds harmful instructions into VLMs through the image channel and then uses benign text prompts to induce VLMs to output contents that violate common AI safety policies.","Our experimental results show that FigStep can achieve an average attack success rate of 94.8% across 2 families of popular open-source VLMs, LLaVA and MiniGPT4 (a total of 5 VLMs).","Moreover, we demonstrate that the methodology of FigStep can even jailbreak GPT-4V, which already leverages several system-level mechanisms to filter harmful queries.","Above all, our experimental results reveal that VLMs are vulnerable to jailbreaking attacks, which highlights the necessity of novel safety alignments between visual and textual modalities."],"url":"http://arxiv.org/abs/2311.05608v1"}
{"created":"2023-11-09 18:59:10","title":"Real-Time Neural Rasterization for Large Scenes","abstract":"We propose a new method for realistic real-time novel-view synthesis (NVS) of large scenes. Existing neural rendering methods generate realistic results, but primarily work for small scale scenes (<50 square meters) and have difficulty at large scale (>10000 square meters). Traditional graphics-based rasterization rendering is fast for large scenes but lacks realism and requires expensive manually created assets. Our approach combines the best of both worlds by taking a moderate-quality scaffold mesh as input and learning a neural texture field and shader to model view-dependant effects to enhance realism, while still using the standard graphics pipeline for real-time rendering. Our method outperforms existing neural rendering methods, providing at least 30x faster rendering with comparable or better realism for large self-driving and drone scenes. Our work is the first to enable real-time rendering of large real-world scenes.","sentences":["We propose a new method for realistic real-time novel-view synthesis (NVS) of large scenes.","Existing neural rendering methods generate realistic results, but primarily work for small scale scenes (<50 square meters) and have difficulty at large scale (>10000 square meters).","Traditional graphics-based rasterization rendering is fast for large scenes but lacks realism and requires expensive manually created assets.","Our approach combines the best of both worlds by taking a moderate-quality scaffold mesh as input and learning a neural texture field and shader to model view-dependant effects to enhance realism, while still using the standard graphics pipeline for real-time rendering.","Our method outperforms existing neural rendering methods, providing at least 30x faster rendering with comparable or better realism for large self-driving and drone scenes.","Our work is the first to enable real-time rendering of large real-world scenes."],"url":"http://arxiv.org/abs/2311.05607v1"}
{"created":"2023-11-09 18:59:05","title":"Diffusion-Generative Multi-Fidelity Learning for Physical Simulation","abstract":"Multi-fidelity surrogate learning is important for physical simulation related applications in that it avoids running numerical solvers from scratch, which is known to be costly, and it uses multi-fidelity examples for training and greatly reduces the cost of data collection. Despite the variety of existing methods, they all build a model to map the input parameters outright to the solution output. Inspired by the recent breakthrough in generative models, we take an alternative view and consider the solution output as generated from random noises. We develop a diffusion-generative multi-fidelity (DGMF) learning method based on stochastic differential equations (SDE), where the generation is a continuous denoising process. We propose a conditional score model to control the solution generation by the input parameters and the fidelity. By conditioning on additional inputs (temporal or spacial variables), our model can efficiently learn and predict multi-dimensional solution arrays. Our method naturally unifies discrete and continuous fidelity modeling. The advantage of our method in several typical applications shows a promising new direction for multi-fidelity learning.","sentences":["Multi-fidelity surrogate learning is important for physical simulation related applications in that it avoids running numerical solvers from scratch, which is known to be costly, and it uses multi-fidelity examples for training and greatly reduces the cost of data collection.","Despite the variety of existing methods, they all build a model to map the input parameters outright to the solution output.","Inspired by the recent breakthrough in generative models, we take an alternative view and consider the solution output as generated from random noises.","We develop a diffusion-generative multi-fidelity (DGMF) learning method based on stochastic differential equations (SDE), where the generation is a continuous denoising process.","We propose a conditional score model to control the solution generation by the input parameters and the fidelity.","By conditioning on additional inputs (temporal or spacial variables), our model can efficiently learn and predict multi-dimensional solution arrays.","Our method naturally unifies discrete and continuous fidelity modeling.","The advantage of our method in several typical applications shows a promising new direction for multi-fidelity learning."],"url":"http://arxiv.org/abs/2311.05606v1"}
{"created":"2023-11-09 18:58:33","title":"3D-QAE: Fully Quantum Auto-Encoding of 3D Point Clouds","abstract":"Existing methods for learning 3D representations are deep neural networks trained and tested on classical hardware. Quantum machine learning architectures, despite their theoretically predicted advantages in terms of speed and the representational capacity, have so far not been considered for this problem nor for tasks involving 3D data in general. This paper thus introduces the first quantum auto-encoder for 3D point clouds. Our 3D-QAE approach is fully quantum, i.e. all its data processing components are designed for quantum hardware. It is trained on collections of 3D point clouds to produce their compressed representations. Along with finding a suitable architecture, the core challenges in designing such a fully quantum model include 3D data normalisation and parameter optimisation, and we propose solutions for both these tasks. Experiments on simulated gate-based quantum hardware demonstrate that our method outperforms simple classical baselines, paving the way for a new research direction in 3D computer vision. The source code is available at https://4dqv.mpi-inf.mpg.de/QAE3D/.","sentences":["Existing methods for learning 3D representations are deep neural networks trained and tested on classical hardware.","Quantum machine learning architectures, despite their theoretically predicted advantages in terms of speed and the representational capacity, have so far not been considered for this problem nor for tasks involving 3D data in general.","This paper thus introduces the first quantum auto-encoder for 3D point clouds.","Our 3D-QAE approach is fully quantum, i.e. all its data processing components are designed for quantum hardware.","It is trained on collections of 3D point clouds to produce their compressed representations.","Along with finding a suitable architecture, the core challenges in designing such a fully quantum model include 3D data normalisation and parameter optimisation, and we propose solutions for both these tasks.","Experiments on simulated gate-based quantum hardware demonstrate that our method outperforms simple classical baselines, paving the way for a new research direction in 3D computer vision.","The source code is available at https://4dqv.mpi-inf.mpg.de/QAE3D/."],"url":"http://arxiv.org/abs/2311.05604v1"}
{"created":"2023-11-09 18:58:22","title":"Reconstructing Objects in-the-wild for Realistic Sensor Simulation","abstract":"Reconstructing objects from real world data and rendering them at novel views is critical to bringing realism, diversity and scale to simulation for robotics training and testing. In this work, we present NeuSim, a novel approach that estimates accurate geometry and realistic appearance from sparse in-the-wild data captured at distance and at limited viewpoints. Towards this goal, we represent the object surface as a neural signed distance function and leverage both LiDAR and camera sensor data to reconstruct smooth and accurate geometry and normals. We model the object appearance with a robust physics-inspired reflectance representation effective for in-the-wild data. Our experiments show that NeuSim has strong view synthesis performance on challenging scenarios with sparse training views. Furthermore, we showcase composing NeuSim assets into a virtual world and generating realistic multi-sensor data for evaluating self-driving perception models.","sentences":["Reconstructing objects from real world data and rendering them at novel views is critical to bringing realism, diversity and scale to simulation for robotics training and testing.","In this work, we present NeuSim, a novel approach that estimates accurate geometry and realistic appearance from sparse in-the-wild data captured at distance and at limited viewpoints.","Towards this goal, we represent the object surface as a neural signed distance function and leverage both LiDAR and camera sensor data to reconstruct smooth and accurate geometry and normals.","We model the object appearance with a robust physics-inspired reflectance representation effective for in-the-wild data.","Our experiments show that NeuSim has strong view synthesis performance on challenging scenarios with sparse training views.","Furthermore, we showcase composing NeuSim assets into a virtual world and generating realistic multi-sensor data for evaluating self-driving perception models."],"url":"http://arxiv.org/abs/2311.05602v1"}
{"created":"2023-11-09 18:57:39","title":"FAMuS: Frames Across Multiple Sources","abstract":"Understanding event descriptions is a central aspect of language processing, but current approaches focus overwhelmingly on single sentences or documents. Aggregating information about an event \\emph{across documents} can offer a much richer understanding. To this end, we present FAMuS, a new corpus of Wikipedia passages that \\emph{report} on some event, paired with underlying, genre-diverse (non-Wikipedia) \\emph{source} articles for the same event. Events and (cross-sentence) arguments in both report and source are annotated against FrameNet, providing broad coverage of different event types. We present results on two key event understanding tasks enabled by FAMuS: \\emph{source validation} -- determining whether a document is a valid source for a target report event -- and \\emph{cross-document argument extraction} -- full-document argument extraction for a target event from both its report and the correct source article. We release both FAMuS and our models to support further research.","sentences":["Understanding event descriptions is a central aspect of language processing, but current approaches focus overwhelmingly on single sentences or documents.","Aggregating information about an event \\emph{across documents} can offer a much richer understanding.","To this end, we present FAMuS, a new corpus of Wikipedia passages that \\emph{report} on some event, paired with underlying, genre-diverse (non-Wikipedia) \\emph{source} articles for the same event.","Events and (cross-sentence) arguments in both report and source are annotated against FrameNet, providing broad coverage of different event types.","We present results on two key event understanding tasks enabled by FAMuS: \\emph{source validation} -- determining whether a document is a valid source for a target report event -- and \\emph{cross-document argument extraction} -- full-document argument extraction for a target event from both its report and the correct source article.","We release both FAMuS and our models to support further research."],"url":"http://arxiv.org/abs/2311.05601v1"}
{"created":"2023-11-09 18:57:36","title":"FogROS2-Sky: Optimizing Latency and Cost for Multi-Cloud Robot Applications","abstract":"This paper studies the cost-performance tradeoffs in cloud robotics with heterogeneous cloud service providers, which have complex pricing models and varying application requirements. We present FogROS2-Sky, a cost-efficient open source robotics platform that offloads unmodified ROS2 applications to multiple cloud providers and enables fine-grained cost analysis for ROS2 applications' communication with multiple cloud providers. As each provider offers different options for CPU, GPU, memory, and latency, it can be very difficult for users to decide which to choose. FogROS2-Sky includes an optimization algorithm, which either finds the best available hardware specification that fulfills the user's latency and cost constraints or reports that such a specification does not exist. We use FogROS2-Sky to perform time-cost analysis on three robotics applications: visual SLAM, grasp planning, and motion planning. We are able to sample different hardware setups at nearly half the cost while still create cost and latency functions suitable for the optimizer. We also evaluate the optimizer's efficacy for these applications with the Pareto frontier and show that the optimizer selects efficient hardware configurations to balance cost and latency. Videos and code are available on the website https://sites.google.com/view/fogros2-sky","sentences":["This paper studies the cost-performance tradeoffs in cloud robotics with heterogeneous cloud service providers, which have complex pricing models and varying application requirements.","We present FogROS2-Sky, a cost-efficient open source robotics platform that offloads unmodified ROS2 applications to multiple cloud providers and enables fine-grained cost analysis for ROS2 applications' communication with multiple cloud providers.","As each provider offers different options for CPU, GPU, memory, and latency, it can be very difficult for users to decide which to choose.","FogROS2-Sky includes an optimization algorithm, which either finds the best available hardware specification that fulfills the user's latency and cost constraints or reports that such a specification does not exist.","We use FogROS2-Sky to perform time-cost analysis on three robotics applications: visual SLAM, grasp planning, and motion planning.","We are able to sample different hardware setups at nearly half the cost while still create cost and latency functions suitable for the optimizer.","We also evaluate the optimizer's efficacy for these applications with the Pareto frontier and show that the optimizer selects efficient hardware configurations to balance cost and latency.","Videos and code are available on the website https://sites.google.com/view/fogros2-sky"],"url":"http://arxiv.org/abs/2311.05600v1"}
{"created":"2023-11-09 18:57:02","title":"SynH2R: Synthesizing Hand-Object Motions for Learning Human-to-Robot Handovers","abstract":"Vision-based human-to-robot handover is an important and challenging task in human-robot interaction. Recent work has attempted to train robot policies by interacting with dynamic virtual humans in simulated environments, where the policies can later be transferred to the real world. However, a major bottleneck is the reliance on human motion capture data, which is expensive to acquire and difficult to scale to arbitrary objects and human grasping motions. In this paper, we introduce a framework that can generate plausible human grasping motions suitable for training the robot. To achieve this, we propose a hand-object synthesis method that is designed to generate handover-friendly motions similar to humans. This allows us to generate synthetic training and testing data with 100x more objects than previous work. In our experiments, we show that our method trained purely with synthetic data is competitive with state-of-the-art methods that rely on real human motion data both in simulation and on a real system. In addition, we can perform evaluations on a larger scale compared to prior work. With our newly introduced test set, we show that our model can better scale to a large variety of unseen objects and human motions compared to the baselines. Project page: https://eth-ait.github.io/synthetic-handovers/","sentences":["Vision-based human-to-robot handover is an important and challenging task in human-robot interaction.","Recent work has attempted to train robot policies by interacting with dynamic virtual humans in simulated environments, where the policies can later be transferred to the real world.","However, a major bottleneck is the reliance on human motion capture data, which is expensive to acquire and difficult to scale to arbitrary objects and human grasping motions.","In this paper, we introduce a framework that can generate plausible human grasping motions suitable for training the robot.","To achieve this, we propose a hand-object synthesis method that is designed to generate handover-friendly motions similar to humans.","This allows us to generate synthetic training and testing data with 100x more objects than previous work.","In our experiments, we show that our method trained purely with synthetic data is competitive with state-of-the-art methods that rely on real human motion data both in simulation and on a real system.","In addition, we can perform evaluations on a larger scale compared to prior work.","With our newly introduced test set, we show that our model can better scale to a large variety of unseen objects and human motions compared to the baselines.","Project page: https://eth-ait.github.io/synthetic-handovers/"],"url":"http://arxiv.org/abs/2311.05599v1"}
{"created":"2023-11-09 18:56:43","title":"Sorting Out Quantum Monte Carlo","abstract":"Molecular modeling at the quantum level requires choosing a parameterization of the wavefunction that both respects the required particle symmetries, and is scalable to systems of many particles. For the simulation of fermions, valid parameterizations must be antisymmetric with respect to the exchange of particles. Typically, antisymmetry is enforced by leveraging the anti-symmetry of determinants with respect to the exchange of matrix rows, but this involves computing a full determinant each time the wavefunction is evaluated. Instead, we introduce a new antisymmetrization layer derived from sorting, the $\\textit{sortlet}$, which scales as $O(N \\log N)$ with regards to the number of particles -- in contrast to $O(N^3)$ for the determinant. We show numerically that applying this anti-symmeterization layer on top of an attention based neural-network backbone yields a flexible wavefunction parameterization capable of reaching chemical accuracy when approximating the ground state of first-row atoms and small molecules.","sentences":["Molecular modeling at the quantum level requires choosing a parameterization of the wavefunction that both respects the required particle symmetries, and is scalable to systems of many particles.","For the simulation of fermions, valid parameterizations must be antisymmetric with respect to the exchange of particles.","Typically, antisymmetry is enforced by leveraging the anti-symmetry of determinants with respect to the exchange of matrix rows, but this involves computing a full determinant each time the wavefunction is evaluated.","Instead, we introduce a new antisymmetrization layer derived from sorting, the $\\textit{sortlet}$, which scales as $O(N \\log N)$ with regards to the number of particles -- in contrast to $O(N^3)$ for the determinant.","We show numerically that applying this anti-symmeterization layer on top of an attention based neural-network backbone yields a flexible wavefunction parameterization capable of reaching chemical accuracy when approximating the ground state of first-row atoms and small molecules."],"url":"http://arxiv.org/abs/2311.05598v1"}
{"created":"2023-11-09 18:54:28","title":"LLM Augmented Hierarchical Agents","abstract":"Solving long-horizon, temporally-extended tasks using Reinforcement Learning (RL) is challenging, compounded by the common practice of learning without prior knowledge (or tabula rasa learning). Humans can generate and execute plans with temporally-extended actions and quickly learn to perform new tasks because we almost never solve problems from scratch. We want autonomous agents to have this same ability. Recently, LLMs have been shown to encode a tremendous amount of knowledge about the world and to perform impressive in-context learning and reasoning. However, using LLMs to solve real world problems is hard because they are not grounded in the current task. In this paper we exploit the planning capabilities of LLMs while using RL to provide learning from the environment, resulting in a hierarchical agent that uses LLMs to solve long-horizon tasks. Instead of completely relying on LLMs, they guide a high-level policy, making learning significantly more sample efficient. This approach is evaluated in simulation environments such as MiniGrid, SkillHack, and Crafter, and on a real robot arm in block manipulation tasks. We show that agents trained using our approach outperform other baselines methods and, once trained, don't need access to LLMs during deployment.","sentences":["Solving long-horizon, temporally-extended tasks using Reinforcement Learning (RL) is challenging, compounded by the common practice of learning without prior knowledge (or tabula rasa learning).","Humans can generate and execute plans with temporally-extended actions and quickly learn to perform new tasks because we almost never solve problems from scratch.","We want autonomous agents to have this same ability.","Recently, LLMs have been shown to encode a tremendous amount of knowledge about the world and to perform impressive in-context learning and reasoning.","However, using LLMs to solve real world problems is hard because they are not grounded in the current task.","In this paper we exploit the planning capabilities of LLMs while using RL to provide learning from the environment, resulting in a hierarchical agent that uses LLMs to solve long-horizon tasks.","Instead of completely relying on LLMs, they guide a high-level policy, making learning significantly more sample efficient.","This approach is evaluated in simulation environments such as MiniGrid, SkillHack, and Crafter, and on a real robot arm in block manipulation tasks.","We show that agents trained using our approach outperform other baselines methods and, once trained, don't need access to LLMs during deployment."],"url":"http://arxiv.org/abs/2311.05596v1"}
{"created":"2023-11-09 18:48:02","title":"Accuracy of a Vision-Language Model on Challenging Medical Cases","abstract":"Background: General-purpose large language models that utilize both text and images have not been evaluated on a diverse array of challenging medical cases.   Methods: Using 934 cases from the NEJM Image Challenge published between 2005 and 2023, we evaluated the accuracy of the recently released Generative Pre-trained Transformer 4 with Vision model (GPT-4V) compared to human respondents overall and stratified by question difficulty, image type, and skin tone. We further conducted a physician evaluation of GPT-4V on 69 NEJM clinicopathological conferences (CPCs). Analyses were conducted for models utilizing text alone, images alone, and both text and images.   Results: GPT-4V achieved an overall accuracy of 61% (95% CI, 58 to 64%) compared to 49% (95% CI, 49 to 50%) for humans. GPT-4V outperformed humans at all levels of difficulty and disagreement, skin tones, and image types; the exception was radiographic images, where performance was equivalent between GPT-4V and human respondents. Longer, more informative captions were associated with improved performance for GPT-4V but similar performance for human respondents. GPT-4V included the correct diagnosis in its differential for 80% (95% CI, 68 to 88%) of CPCs when using text alone, compared to 58% (95% CI, 45 to 70%) of CPCs when using both images and text.   Conclusions: GPT-4V outperformed human respondents on challenging medical cases and was able to synthesize information from both images and text, but performance deteriorated when images were added to highly informative text. Overall, our results suggest that multimodal AI models may be useful in medical diagnostic reasoning but that their accuracy may depend heavily on context.","sentences":["Background: General-purpose large language models that utilize both text and images have not been evaluated on a diverse array of challenging medical cases.   ","Methods: Using 934 cases from the NEJM Image Challenge published between 2005 and 2023, we evaluated the accuracy of the recently released Generative Pre-trained Transformer 4 with Vision model (GPT-4V) compared to human respondents overall and stratified by question difficulty, image type, and skin tone.","We further conducted a physician evaluation of GPT-4V on 69 NEJM clinicopathological conferences (CPCs).","Analyses were conducted for models utilizing text alone, images alone, and both text and images.   ","Results: GPT-4V achieved an overall accuracy of 61% (95% CI, 58 to 64%) compared to 49% (95% CI, 49 to 50%) for humans.","GPT-4V outperformed humans at all levels of difficulty and disagreement, skin tones, and image types; the exception was radiographic images, where performance was equivalent between GPT-4V and human respondents.","Longer, more informative captions were associated with improved performance for GPT-4V but similar performance for human respondents.","GPT-4V included the correct diagnosis in its differential for 80% (95% CI, 68 to 88%) of CPCs when using text alone, compared to 58% (95% CI, 45 to 70%) of CPCs when using both images and text.   ","Conclusions: GPT-4V outperformed human respondents on challenging medical cases and was able to synthesize information from both images and text, but performance deteriorated when images were added to highly informative text.","Overall, our results suggest that multimodal AI models may be useful in medical diagnostic reasoning but that their accuracy may depend heavily on context."],"url":"http://arxiv.org/abs/2311.05591v1"}
{"created":"2023-11-09 18:47:46","title":"Conversational AI Threads for Visualizing Multidimensional Datasets","abstract":"Generative Large Language Models (LLMs) show potential in data analysis, yet their full capabilities remain uncharted. Our work explores the capabilities of LLMs for creating and refining visualizations via conversational interfaces. We used an LLM to conduct a re-analysis of a prior Wizard-of-Oz study examining the use of chatbots for conducting visual analysis. We surfaced the strengths and weaknesses of LLM-driven analytic chatbots, finding that they fell short in supporting progressive visualization refinements. From these findings, we developed AI Threads, a multi-threaded analytic chatbot that enables analysts to proactively manage conversational context and improve the efficacy of its outputs. We evaluate its usability through a crowdsourced study (n=40) and in-depth interviews with expert analysts (n=10). We further demonstrate the capabilities of AI Threads on a dataset outside the LLM's training corpus. Our findings show the potential of LLMs while also surfacing challenges and fruitful avenues for future research.","sentences":["Generative Large Language Models (LLMs) show potential in data analysis, yet their full capabilities remain uncharted.","Our work explores the capabilities of LLMs for creating and refining visualizations via conversational interfaces.","We used an LLM to conduct a re-analysis of a prior Wizard-of-Oz study examining the use of chatbots for conducting visual analysis.","We surfaced the strengths and weaknesses of LLM-driven analytic chatbots, finding that they fell short in supporting progressive visualization refinements.","From these findings, we developed AI Threads, a multi-threaded analytic chatbot that enables analysts to proactively manage conversational context and improve the efficacy of its outputs.","We evaluate its usability through a crowdsourced study (n=40) and in-depth interviews with expert analysts (n=10).","We further demonstrate the capabilities of AI Threads on a dataset outside the LLM's training corpus.","Our findings show the potential of LLMs while also surfacing challenges and fruitful avenues for future research."],"url":"http://arxiv.org/abs/2311.05590v1"}
{"created":"2023-11-09 18:47:44","title":"A Coefficient Makes SVRG Effective","abstract":"Stochastic Variance Reduced Gradient (SVRG), introduced by Johnson & Zhang (2013), is a theoretically compelling optimization method. However, as Defazio & Bottou (2019) highlights, its effectiveness in deep learning is yet to be proven. In this work, we demonstrate the potential of SVRG in optimizing real-world neural networks. Our analysis finds that, for deeper networks, the strength of the variance reduction term in SVRG should be smaller and decrease as training progresses. Inspired by this, we introduce a multiplicative coefficient $\\alpha$ to control the strength and adjust it through a linear decay schedule. We name our method $\\alpha$-SVRG. Our results show $\\alpha$-SVRG better optimizes neural networks, consistently reducing training loss compared to both baseline and the standard SVRG across various architectures and image classification datasets. We hope our findings encourage further exploration into variance reduction techniques in deep learning. Code is available at https://github.com/davidyyd/alpha-SVRG.","sentences":["Stochastic Variance Reduced Gradient (SVRG), introduced by Johnson & Zhang (2013), is a theoretically compelling optimization method.","However, as Defazio & Bottou (2019) highlights, its effectiveness in deep learning is yet to be proven.","In this work, we demonstrate the potential of SVRG in optimizing real-world neural networks.","Our analysis finds that, for deeper networks, the strength of the variance reduction term in SVRG should be smaller and decrease as training progresses.","Inspired by this, we introduce a multiplicative coefficient $\\alpha$ to control the strength and adjust it through a linear decay schedule.","We name our method $\\alpha$-SVRG.","Our results show $\\alpha$-SVRG better optimizes neural networks, consistently reducing training loss compared to both baseline and the standard SVRG across various architectures and image classification datasets.","We hope our findings encourage further exploration into variance reduction techniques in deep learning.","Code is available at https://github.com/davidyyd/alpha-SVRG."],"url":"http://arxiv.org/abs/2311.05589v1"}
{"created":"2023-11-09 18:47:33","title":"Bayesian Methods for Media Mix Modelling with shape and funnel effects","abstract":"In recent years, significant progress in generative AI has highlighted the important role of physics-inspired models that utilize advanced mathematical concepts based on fundamental physics principles to enhance artificial intelligence capabilities. Among these models, those based on diffusion equations have greatly improved image quality. This study aims to explore the potential uses of Maxwell-Boltzmann equation, which forms the basis of the kinetic theory of gases, and the Michaelis-Menten model in Marketing Mix Modelling (MMM) applications. We propose incorporating these equations into Hierarchical Bayesian models to analyse consumer behaviour in the context of advertising. These equation sets excel in accurately describing the random dynamics in complex systems like social interactions and consumer-advertising interactions.","sentences":["In recent years, significant progress in generative AI has highlighted the important role of physics-inspired models that utilize advanced mathematical concepts based on fundamental physics principles to enhance artificial intelligence capabilities.","Among these models, those based on diffusion equations have greatly improved image quality.","This study aims to explore the potential uses of Maxwell-Boltzmann equation, which forms the basis of the kinetic theory of gases, and the Michaelis-Menten model in Marketing Mix Modelling (MMM) applications.","We propose incorporating these equations into Hierarchical Bayesian models to analyse consumer behaviour in the context of advertising.","These equation sets excel in accurately describing the random dynamics in complex systems like social interactions and consumer-advertising interactions."],"url":"http://arxiv.org/abs/2311.05587v1"}
{"created":"2023-11-09 18:45:16","title":"Zero-Shot Goal-Directed Dialogue via RL on Imagined Conversations","abstract":"Large language models (LLMs) have emerged as powerful and general solutions to many natural language tasks. However, many of the most important applications of language generation are interactive, where an agent has to talk to a person to reach a desired outcome. For example, a teacher might try to understand their student's current comprehension level to tailor their instruction accordingly, and a travel agent might ask questions of their customer to understand their preferences in order to recommend activities they might enjoy. LLMs trained with supervised fine-tuning or \"single-step\" RL, as with standard RLHF, might struggle which tasks that require such goal-directed behavior, since they are not trained to optimize for overall conversational outcomes after multiple turns of interaction. In this work, we explore a new method for adapting LLMs with RL for such goal-directed dialogue. Our key insight is that, though LLMs might not effectively solve goal-directed dialogue tasks out of the box, they can provide useful data for solving such tasks by simulating suboptimal but human-like behaviors. Given a textual description of a goal-directed dialogue task, we leverage LLMs to sample diverse synthetic rollouts of hypothetical in-domain human-human interactions. Our algorithm then utilizes this dataset with offline reinforcement learning to train an interactive conversational agent that can optimize goal-directed objectives over multiple turns. In effect, the LLM produces examples of possible interactions, and RL then processes these examples to learn to perform more optimal interactions. Empirically, we show that our proposed approach achieves state-of-the-art performance in various goal-directed dialogue tasks that include teaching and preference elicitation.","sentences":["Large language models (LLMs) have emerged as powerful and general solutions to many natural language tasks.","However, many of the most important applications of language generation are interactive, where an agent has to talk to a person to reach a desired outcome.","For example, a teacher might try to understand their student's current comprehension level to tailor their instruction accordingly, and a travel agent might ask questions of their customer to understand their preferences in order to recommend activities they might enjoy.","LLMs trained with supervised fine-tuning or \"single-step\" RL, as with standard RLHF, might struggle which tasks that require such goal-directed behavior, since they are not trained to optimize for overall conversational outcomes after multiple turns of interaction.","In this work, we explore a new method for adapting LLMs with RL for such goal-directed dialogue.","Our key insight is that, though LLMs might not effectively solve goal-directed dialogue tasks out of the box, they can provide useful data for solving such tasks by simulating suboptimal but human-like behaviors.","Given a textual description of a goal-directed dialogue task, we leverage LLMs to sample diverse synthetic rollouts of hypothetical in-domain human-human interactions.","Our algorithm then utilizes this dataset with offline reinforcement learning to train an interactive conversational agent that can optimize goal-directed objectives over multiple turns.","In effect, the LLM produces examples of possible interactions, and RL then processes these examples to learn to perform more optimal interactions.","Empirically, we show that our proposed approach achieves state-of-the-art performance in various goal-directed dialogue tasks that include teaching and preference elicitation."],"url":"http://arxiv.org/abs/2311.05584v1"}
{"created":"2023-11-09 18:42:20","title":"Joint SDN Synchronization and Controller Placement in Wireless Networks using Deep Reinforcement Learning","abstract":"Software Defined Networking has afforded numerous benefits to the network users but there are certain persisting issues with this technology, two of which are scalability and privacy. The natural solution to overcoming these limitations is a distributed SDN controller architecture where multiple controllers are deployed over the network, with each controller orchestrating a certain segment of the network. However, since the centralized control is the key attribute of SDN that allows it to be so beneficial, a centralized logical view of the network will have to be maintained by each of these controllers; this can be done through synchronization of the distributed controllers, where each controller communicates with the others to ensure that they remain informed about the entire network. There is however a network cost associated with constantly having to update each others about different aspects of the network, which will become a greater issue in dynamic wireless networks. To minimize this network cost, there is a need to consider not only when to get the update information from the neighboring controllers, but also where to dynamically place the controllers such that the network costs may be minimized. The placement should take into consideration both communication for synchronization among the distributed controllers and communication of the controllers with the network devices that they manage. In this work, we show that our multi-objective deep reinforcement learning-based method performs the best at achieving different application goals by developing policy for controller synchronization as well as placement, outperforming different other possible approaches, under a wide variety of network conditions.","sentences":["Software Defined Networking has afforded numerous benefits to the network users but there are certain persisting issues with this technology, two of which are scalability and privacy.","The natural solution to overcoming these limitations is a distributed SDN controller architecture where multiple controllers are deployed over the network, with each controller orchestrating a certain segment of the network.","However, since the centralized control is the key attribute of SDN that allows it to be so beneficial, a centralized logical view of the network will have to be maintained by each of these controllers; this can be done through synchronization of the distributed controllers, where each controller communicates with the others to ensure that they remain informed about the entire network.","There is however a network cost associated with constantly having to update each others about different aspects of the network, which will become a greater issue in dynamic wireless networks.","To minimize this network cost, there is a need to consider not only when to get the update information from the neighboring controllers, but also where to dynamically place the controllers such that the network costs may be minimized.","The placement should take into consideration both communication for synchronization among the distributed controllers and communication of the controllers with the network devices that they manage.","In this work, we show that our multi-objective deep reinforcement learning-based method performs the best at achieving different application goals by developing policy for controller synchronization as well as placement, outperforming different other possible approaches, under a wide variety of network conditions."],"url":"http://arxiv.org/abs/2311.05582v1"}
{"created":"2023-11-09 18:40:12","title":"Inference for Probabilistic Dependency Graphs","abstract":"Probabilistic dependency graphs (PDGs) are a flexible class of probabilistic graphical models, subsuming Bayesian Networks and Factor Graphs. They can also capture inconsistent beliefs, and provide a way of measuring the degree of this inconsistency. We present the first tractable inference algorithm for PDGs with discrete variables, making the asymptotic complexity of PDG inference similar that of the graphical models they generalize. The key components are: (1) the observation that, in many cases, the distribution a PDG specifies can be formulated as a convex optimization problem (with exponential cone constraints), (2) a construction that allows us to express these problems compactly for PDGs of boundeed treewidth, (3) contributions to the theory of PDGs that justify the construction, and (4) an appeal to interior point methods that can solve such problems in polynomial time. We verify the correctness and complexity of our approach, and provide an implementation of it. We then evaluate our implementation, and demonstrate that it outperforms baseline approaches. Our code is available at http://github.com/orichardson/pdg-infer-uai.","sentences":["Probabilistic dependency graphs (PDGs) are a flexible class of probabilistic graphical models, subsuming Bayesian Networks and Factor Graphs.","They can also capture inconsistent beliefs, and provide a way of measuring the degree of this inconsistency.","We present the first tractable inference algorithm for PDGs with discrete variables, making the asymptotic complexity of PDG inference similar that of the graphical models they generalize.","The key components are: (1) the observation that, in many cases, the distribution a PDG specifies can be formulated as a convex optimization problem (with exponential cone constraints), (2) a construction that allows us to express these problems compactly for PDGs of boundeed treewidth, (3) contributions to the theory of PDGs that justify the construction, and (4) an appeal to interior point methods that can solve such problems in polynomial time.","We verify the correctness and complexity of our approach, and provide an implementation of it.","We then evaluate our implementation, and demonstrate that it outperforms baseline approaches.","Our code is available at http://github.com/orichardson/pdg-infer-uai."],"url":"http://arxiv.org/abs/2311.05580v1"}
{"created":"2023-11-09 18:38:46","title":"SigScatNet: A Siamese + Scattering based Deep Learning Approach for Signature Forgery Detection and Similarity Assessment","abstract":"The surge in counterfeit signatures has inflicted widespread inconveniences and formidable challenges for both individuals and organizations. This groundbreaking research paper introduces SigScatNet, an innovative solution to combat this issue by harnessing the potential of a Siamese deep learning network, bolstered by Scattering wavelets, to detect signature forgery and assess signature similarity. The Siamese Network empowers us to ascertain the authenticity of signatures through a comprehensive similarity index, enabling precise validation and comparison. Remarkably, the integration of Scattering wavelets endows our model with exceptional efficiency, rendering it light enough to operate seamlessly on cost-effective hardware systems. To validate the efficacy of our approach, extensive experimentation was conducted on two open-sourced datasets: the ICDAR SigComp Dutch dataset and the CEDAR dataset. The experimental results demonstrate the practicality and resounding success of our proposed SigScatNet, yielding an unparalleled Equal Error Rate of 3.689% with the ICDAR SigComp Dutch dataset and an astonishing 0.0578% with the CEDAR dataset. Through the implementation of SigScatNet, our research spearheads a new state-of-the-art in signature analysis in terms of EER scores and computational efficiency, offering an advanced and accessible solution for detecting forgery and quantifying signature similarities. By employing cutting-edge Siamese deep learning and Scattering wavelets, we provide a robust framework that paves the way for secure and efficient signature verification systems.","sentences":["The surge in counterfeit signatures has inflicted widespread inconveniences and formidable challenges for both individuals and organizations.","This groundbreaking research paper introduces SigScatNet, an innovative solution to combat this issue by harnessing the potential of a Siamese deep learning network, bolstered by Scattering wavelets, to detect signature forgery and assess signature similarity.","The Siamese Network empowers us to ascertain the authenticity of signatures through a comprehensive similarity index, enabling precise validation and comparison.","Remarkably, the integration of Scattering wavelets endows our model with exceptional efficiency, rendering it light enough to operate seamlessly on cost-effective hardware systems.","To validate the efficacy of our approach, extensive experimentation was conducted on two open-sourced datasets: the ICDAR SigComp Dutch dataset and the CEDAR dataset.","The experimental results demonstrate the practicality and resounding success of our proposed SigScatNet, yielding an unparalleled Equal Error Rate of 3.689% with the ICDAR SigComp Dutch dataset and an astonishing 0.0578% with the CEDAR dataset.","Through the implementation of SigScatNet, our research spearheads a new state-of-the-art in signature analysis in terms of EER scores and computational efficiency, offering an advanced and accessible solution for detecting forgery and quantifying signature similarities.","By employing cutting-edge Siamese deep learning and Scattering wavelets, we provide a robust framework that paves the way for secure and efficient signature verification systems."],"url":"http://arxiv.org/abs/2311.05579v1"}
{"created":"2023-11-09 18:22:32","title":"Exploring Emotion Expression Recognition in Older Adults Interacting with a Virtual Coach","abstract":"The EMPATHIC project aimed to design an emotionally expressive virtual coach capable of engaging healthy seniors to improve well-being and promote independent aging. One of the core aspects of the system is its human sensing capabilities, allowing for the perception of emotional states to provide a personalized experience. This paper outlines the development of the emotion expression recognition module of the virtual coach, encompassing data collection, annotation design, and a first methodological approach, all tailored to the project requirements. With the latter, we investigate the role of various modalities, individually and combined, for discrete emotion expression recognition in this context: speech from audio, and facial expressions, gaze, and head dynamics from video. The collected corpus includes users from Spain, France, and Norway, and was annotated separately for the audio and video channels with distinct emotional labels, allowing for a performance comparison across cultures and label types. Results confirm the informative power of the modalities studied for the emotional categories considered, with multimodal methods generally outperforming others (around 68% accuracy with audio labels and 72-74% with video labels). The findings are expected to contribute to the limited literature on emotion recognition applied to older adults in conversational human-machine interaction.","sentences":["The EMPATHIC project aimed to design an emotionally expressive virtual coach capable of engaging healthy seniors to improve well-being and promote independent aging.","One of the core aspects of the system is its human sensing capabilities, allowing for the perception of emotional states to provide a personalized experience.","This paper outlines the development of the emotion expression recognition module of the virtual coach, encompassing data collection, annotation design, and a first methodological approach, all tailored to the project requirements.","With the latter, we investigate the role of various modalities, individually and combined, for discrete emotion expression recognition in this context: speech from audio, and facial expressions, gaze, and head dynamics from video.","The collected corpus includes users from Spain, France, and Norway, and was annotated separately for the audio and video channels with distinct emotional labels, allowing for a performance comparison across cultures and label types.","Results confirm the informative power of the modalities studied for the emotional categories considered, with multimodal methods generally outperforming others (around 68% accuracy with audio labels and 72-74% with video labels).","The findings are expected to contribute to the limited literature on emotion recognition applied to older adults in conversational human-machine interaction."],"url":"http://arxiv.org/abs/2311.05567v1"}
{"created":"2023-11-09 18:20:52","title":"High-Performance Transformers for Table Structure Recognition Need Early Convolutions","abstract":"Table structure recognition (TSR) aims to convert tabular images into a machine-readable format, where a visual encoder extracts image features and a textual decoder generates table-representing tokens. Existing approaches use classic convolutional neural network (CNN) backbones for the visual encoder and transformers for the textual decoder. However, this hybrid CNN-Transformer architecture introduces a complex visual encoder that accounts for nearly half of the total model parameters, markedly reduces both training and inference speed, and hinders the potential for self-supervised learning in TSR. In this work, we design a lightweight visual encoder for TSR without sacrificing expressive power. We discover that a convolutional stem can match classic CNN backbone performance, with a much simpler model. The convolutional stem strikes an optimal balance between two crucial factors for high-performance TSR: a higher receptive field (RF) ratio and a longer sequence length. This allows it to \"see\" an appropriate portion of the table and \"store\" the complex table structure within sufficient context length for the subsequent transformer. We conducted reproducible ablation studies and open-sourced our code at https://github.com/poloclub/tsr-convstem to enhance transparency, inspire innovations, and facilitate fair comparisons in our domain as tables are a promising modality for representation learning.","sentences":["Table structure recognition (TSR) aims to convert tabular images into a machine-readable format, where a visual encoder extracts image features and a textual decoder generates table-representing tokens.","Existing approaches use classic convolutional neural network (CNN) backbones for the visual encoder and transformers for the textual decoder.","However, this hybrid CNN-Transformer architecture introduces a complex visual encoder that accounts for nearly half of the total model parameters, markedly reduces both training and inference speed, and hinders the potential for self-supervised learning in TSR.","In this work, we design a lightweight visual encoder for TSR without sacrificing expressive power.","We discover that a convolutional stem can match classic CNN backbone performance, with a much simpler model.","The convolutional stem strikes an optimal balance between two crucial factors for high-performance TSR: a higher receptive field (RF) ratio and a longer sequence length.","This allows it to \"see\" an appropriate portion of the table and \"store\" the complex table structure within sufficient context length for the subsequent transformer.","We conducted reproducible ablation studies and open-sourced our code at https://github.com/poloclub/tsr-convstem to enhance transparency, inspire innovations, and facilitate fair comparisons in our domain as tables are a promising modality for representation learning."],"url":"http://arxiv.org/abs/2311.05565v1"}
{"created":"2023-11-09 18:18:28","title":"Improving Human Legibility in Collaborative Robot Tasks through Augmented Reality and Workspace Preparation","abstract":"Understanding the intentions of human teammates is critical for safe and effective human-robot interaction. The canonical approach for human-aware robot motion planning is to first predict the human's goal or path, and then construct a robot plan that avoids collision with the human. This method can generate unsafe interactions if the human model and subsequent predictions are inaccurate. In this work, we present an algorithmic approach for both arranging the configuration of objects in a shared human-robot workspace, and projecting ``virtual obstacles'' in augmented reality, optimizing for legibility in a given task. These changes to the workspace result in more legible human behavior, improving robot predictions of human goals, thereby improving task fluency and safety. To evaluate our approach, we propose two user studies involving a collaborative tabletop task with a manipulator robot, and a warehouse navigation task with a mobile robot.","sentences":["Understanding the intentions of human teammates is critical for safe and effective human-robot interaction.","The canonical approach for human-aware robot motion planning is to first predict the human's goal or path, and then construct a robot plan that avoids collision with the human.","This method can generate unsafe interactions if the human model and subsequent predictions are inaccurate.","In this work, we present an algorithmic approach for both arranging the configuration of objects in a shared human-robot workspace, and projecting ``virtual obstacles'' in augmented reality, optimizing for legibility in a given task.","These changes to the workspace result in more legible human behavior, improving robot predictions of human goals, thereby improving task fluency and safety.","To evaluate our approach, we propose two user studies involving a collaborative tabletop task with a manipulator robot, and a warehouse navigation task with a mobile robot."],"url":"http://arxiv.org/abs/2311.05562v1"}
{"created":"2023-11-09 18:05:46","title":"Exploiting Neural-Network Statistics for Low-Power DNN Inference","abstract":"Specialized compute blocks have been developed for efficient DNN execution. However, due to the vast amount of data and parameter movements, the interconnects and on-chip memories form another bottleneck, impairing power and performance. This work addresses this bottleneck by contributing a low-power technique for edge-AI inference engines that combines overhead-free coding with a statistical analysis of the data and parameters of neural networks. Our approach reduces the interconnect and memory power consumption by up to 80% for state-of-the-art benchmarks while providing additional power savings for the compute blocks by up to 39%. These power improvements are achieved with no loss of accuracy and negligible hardware cost.","sentences":["Specialized compute blocks have been developed for efficient DNN execution.","However, due to the vast amount of data and parameter movements, the interconnects and on-chip memories form another bottleneck, impairing power and performance.","This work addresses this bottleneck by contributing a low-power technique for edge-AI inference engines that combines overhead-free coding with a statistical analysis of the data and parameters of neural networks.","Our approach reduces the interconnect and memory power consumption by up to 80% for state-of-the-art benchmarks while providing additional power savings for the compute blocks by up to 39%.","These power improvements are achieved with no loss of accuracy and negligible hardware cost."],"url":"http://arxiv.org/abs/2311.05557v1"}
{"created":"2023-11-09 18:04:15","title":"LCM-LoRA: A Universal Stable-Diffusion Acceleration Module","abstract":"Latent Consistency Models (LCMs) have achieved impressive performance in accelerating text-to-image generative tasks, producing high-quality images with minimal inference steps. LCMs are distilled from pre-trained latent diffusion models (LDMs), requiring only ~32 A100 GPU training hours. This report further extends LCMs' potential in two aspects: First, by applying LoRA distillation to Stable-Diffusion models including SD-V1.5, SSD-1B, and SDXL, we have expanded LCM's scope to larger models with significantly less memory consumption, achieving superior image generation quality. Second, we identify the LoRA parameters obtained through LCM distillation as a universal Stable-Diffusion acceleration module, named LCM-LoRA. LCM-LoRA can be directly plugged into various Stable-Diffusion fine-tuned models or LoRAs without training, thus representing a universally applicable accelerator for diverse image generation tasks. Compared with previous numerical PF-ODE solvers such as DDIM, DPM-Solver, LCM-LoRA can be viewed as a plug-in neural PF-ODE solver that possesses strong generalization abilities. Project page: https://github.com/luosiallen/latent-consistency-model.","sentences":["Latent Consistency Models (LCMs) have achieved impressive performance in accelerating text-to-image generative tasks, producing high-quality images with minimal inference steps.","LCMs are distilled from pre-trained latent diffusion models (LDMs), requiring only ~32 A100 GPU training hours.","This report further extends LCMs' potential in two aspects: First, by applying LoRA distillation to Stable-Diffusion models including SD-V1.5, SSD-1B, and SDXL, we have expanded LCM's scope to larger models with significantly less memory consumption, achieving superior image generation quality.","Second, we identify the LoRA parameters obtained through LCM distillation as a universal Stable-Diffusion acceleration module, named LCM-LoRA.","LCM-LoRA can be directly plugged into various Stable-Diffusion fine-tuned models or LoRAs without training, thus representing a universally applicable accelerator for diverse image generation tasks.","Compared with previous numerical PF-ODE solvers such as DDIM, DPM-Solver, LCM-LoRA can be viewed as a plug-in neural PF-ODE solver that possesses strong generalization abilities.","Project page: https://github.com/luosiallen/latent-consistency-model."],"url":"http://arxiv.org/abs/2311.05556v1"}
{"created":"2023-11-09 17:54:59","title":"Removing RLHF Protections in GPT-4 via Fine-Tuning","abstract":"As large language models (LLMs) have increased in their capabilities, so does their potential for dual use. To reduce harmful outputs, produces and vendors of LLMs have used reinforcement learning with human feedback (RLHF). In tandem, LLM vendors have been increasingly enabling fine-tuning of their most powerful models. However, concurrent work has shown that fine-tuning can remove RLHF protections. We may expect that the most powerful models currently available (GPT-4) are less susceptible to fine-tuning attacks.   In this work, we show the contrary: fine-tuning allows attackers to remove RLHF protections with as few as 340 examples and a 95% success rate. These training examples can be automatically generated with weaker models. We further show that removing RLHF protections does not decrease usefulness on non-censored outputs, providing evidence that our fine-tuning strategy does not decrease usefulness despite using weaker models to generate training data. Our results show the need for further research on protections on LLMs.","sentences":["As large language models (LLMs) have increased in their capabilities, so does their potential for dual use.","To reduce harmful outputs, produces and vendors of LLMs have used reinforcement learning with human feedback (RLHF).","In tandem, LLM vendors have been increasingly enabling fine-tuning of their most powerful models.","However, concurrent work has shown that fine-tuning can remove RLHF protections.","We may expect that the most powerful models currently available (GPT-4) are less susceptible to fine-tuning attacks.   ","In this work, we show the contrary: fine-tuning allows attackers to remove RLHF protections with as few as 340 examples and a 95% success rate.","These training examples can be automatically generated with weaker models.","We further show that removing RLHF protections does not decrease usefulness on non-censored outputs, providing evidence that our fine-tuning strategy does not decrease usefulness despite using weaker models to generate training data.","Our results show the need for further research on protections on LLMs."],"url":"http://arxiv.org/abs/2311.05553v1"}
{"created":"2023-11-09 17:50:23","title":"The Iron(ic) Melting Pot: Reviewing Human Evaluation in Humour, Irony and Sarcasm Generation","abstract":"Human evaluation is often considered to be the gold standard method of evaluating a Natural Language Generation system. However, whilst its importance is accepted by the community at large, the quality of its execution is often brought into question. In this position paper, we argue that the generation of more esoteric forms of language - humour, irony and sarcasm - constitutes a subdomain where the characteristics of selected evaluator panels are of utmost importance, and every effort should be made to report demographic characteristics wherever possible, in the interest of transparency and replicability. We support these claims with an overview of each language form and an analysis of examples in terms of how their interpretation is affected by different participant variables. We additionally perform a critical survey of recent works in NLG to assess how well evaluation procedures are reported in this subdomain, and note a severe lack of open reporting of evaluator demographic information, and a significant reliance on crowdsourcing platforms for recruitment.","sentences":["Human evaluation is often considered to be the gold standard method of evaluating a Natural Language Generation system.","However, whilst its importance is accepted by the community at large, the quality of its execution is often brought into question.","In this position paper, we argue that the generation of more esoteric forms of language - humour, irony and sarcasm - constitutes a subdomain where the characteristics of selected evaluator panels are of utmost importance, and every effort should be made to report demographic characteristics wherever possible, in the interest of transparency and replicability.","We support these claims with an overview of each language form and an analysis of examples in terms of how their interpretation is affected by different participant variables.","We additionally perform a critical survey of recent works in NLG to assess how well evaluation procedures are reported in this subdomain, and note a severe lack of open reporting of evaluator demographic information, and a significant reliance on crowdsourcing platforms for recruitment."],"url":"http://arxiv.org/abs/2311.05552v1"}
{"created":"2023-11-09 17:49:02","title":"Towards End-to-End Spoken Grammatical Error Correction","abstract":"Grammatical feedback is crucial for L2 learners, teachers, and testers. Spoken grammatical error correction (GEC) aims to supply feedback to L2 learners on their use of grammar when speaking. This process usually relies on a cascaded pipeline comprising an ASR system, disfluency removal, and GEC, with the associated concern of propagating errors between these individual modules. In this paper, we introduce an alternative \"end-to-end\" approach to spoken GEC, exploiting a speech recognition foundation model, Whisper. This foundation model can be used to replace the whole framework or part of it, e.g., ASR and disfluency removal. These end-to-end approaches are compared to more standard cascaded approaches on the data obtained from a free-speaking spoken language assessment test, Linguaskill. Results demonstrate that end-to-end spoken GEC is possible within this architecture, but the lack of available data limits current performance compared to a system using large quantities of text-based GEC data. Conversely, end-to-end disfluency detection and removal, which is easier for the attention-based Whisper to learn, does outperform cascaded approaches. Additionally, the paper discusses the challenges of providing feedback to candidates when using end-to-end systems for spoken GEC.","sentences":["Grammatical feedback is crucial for L2 learners, teachers, and testers.","Spoken grammatical error correction (GEC) aims to supply feedback to L2 learners on their use of grammar when speaking.","This process usually relies on a cascaded pipeline comprising an ASR system, disfluency removal, and GEC, with the associated concern of propagating errors between these individual modules.","In this paper, we introduce an alternative \"end-to-end\" approach to spoken GEC, exploiting a speech recognition foundation model, Whisper.","This foundation model can be used to replace the whole framework or part of it, e.g., ASR and disfluency removal.","These end-to-end approaches are compared to more standard cascaded approaches on the data obtained from a free-speaking spoken language assessment test, Linguaskill.","Results demonstrate that end-to-end spoken GEC is possible within this architecture, but the lack of available data limits current performance compared to a system using large quantities of text-based GEC data.","Conversely, end-to-end disfluency detection and removal, which is easier for the attention-based Whisper to learn, does outperform cascaded approaches.","Additionally, the paper discusses the challenges of providing feedback to candidates when using end-to-end systems for spoken GEC."],"url":"http://arxiv.org/abs/2311.05550v1"}
{"created":"2023-11-09 17:47:32","title":"L-WaveBlock: A Novel Feature Extractor Leveraging Wavelets for Generative Adversarial Networks","abstract":"Generative Adversarial Networks (GANs) have risen to prominence in the field of deep learning, facilitating the generation of realistic data from random noise. The effectiveness of GANs often depends on the quality of feature extraction, a critical aspect of their architecture. This paper introduces L-WaveBlock, a novel and robust feature extractor that leverages the capabilities of the Discrete Wavelet Transform (DWT) with deep learning methodologies. L-WaveBlock is catered to quicken the convergence of GAN generators while simultaneously enhancing their performance. The paper demonstrates the remarkable utility of L-WaveBlock across three datasets, a road satellite imagery dataset, the CelebA dataset and the GoPro dataset, showcasing its ability to ease feature extraction and make it more efficient. By utilizing DWT, L-WaveBlock efficiently captures the intricate details of both structural and textural details, and further partitions feature maps into orthogonal subbands across multiple scales while preserving essential information at the same time. Not only does it lead to faster convergence, but also gives competent results on every dataset by employing the L-WaveBlock. The proposed method achieves an Inception Score of 3.6959 and a Structural Similarity Index of 0.4261 on the maps dataset, a Peak Signal-to-Noise Ratio of 29.05 and a Structural Similarity Index of 0.874 on the CelebA dataset. The proposed method performs competently to the state-of-the-art for the image denoising dataset, albeit not better, but still leads to faster convergence than conventional methods. With this, L-WaveBlock emerges as a robust and efficient tool for enhancing GAN-based image generation, demonstrating superior convergence speed and competitive performance across multiple datasets for image resolution, image generation and image denoising.","sentences":["Generative Adversarial Networks (GANs) have risen to prominence in the field of deep learning, facilitating the generation of realistic data from random noise.","The effectiveness of GANs often depends on the quality of feature extraction, a critical aspect of their architecture.","This paper introduces L-WaveBlock, a novel and robust feature extractor that leverages the capabilities of the Discrete Wavelet Transform (DWT) with deep learning methodologies.","L-WaveBlock is catered to quicken the convergence of GAN generators while simultaneously enhancing their performance.","The paper demonstrates the remarkable utility of L-WaveBlock across three datasets, a road satellite imagery dataset, the CelebA dataset and the GoPro dataset, showcasing its ability to ease feature extraction and make it more efficient.","By utilizing DWT, L-WaveBlock efficiently captures the intricate details of both structural and textural details, and further partitions feature maps into orthogonal subbands across multiple scales while preserving essential information at the same time.","Not only does it lead to faster convergence, but also gives competent results on every dataset by employing the L-WaveBlock.","The proposed method achieves an Inception Score of 3.6959 and a Structural Similarity Index of 0.4261 on the maps dataset, a Peak Signal-to-Noise Ratio of 29.05 and a Structural Similarity Index of 0.874 on the CelebA dataset.","The proposed method performs competently to the state-of-the-art for the image denoising dataset, albeit not better, but still leads to faster convergence than conventional methods.","With this, L-WaveBlock emerges as a robust and efficient tool for enhancing GAN-based image generation, demonstrating superior convergence speed and competitive performance across multiple datasets for image resolution, image generation and image denoising."],"url":"http://arxiv.org/abs/2311.05548v1"}
{"created":"2023-11-09 17:45:28","title":"Extending Regev's factoring algorithm to compute discrete logarithms","abstract":"Regev recently introduced a quantum factoring algorithm that may be perceived as a $d$-dimensional variation of Shor's factoring algorithm. In this work, we extend Regev's factoring algorithm to an algorithm for computing discrete logarithms in a natural way. Furthermore, we discuss natural extensions of Regev's factoring algorithm to order finding, and to factoring completely via order finding.","sentences":["Regev recently introduced a quantum factoring algorithm that may be perceived as a $d$-dimensional variation of Shor's factoring algorithm.","In this work, we extend Regev's factoring algorithm to an algorithm for computing discrete logarithms in a natural way.","Furthermore, we discuss natural extensions of Regev's factoring algorithm to order finding, and to factoring completely via order finding."],"url":"http://arxiv.org/abs/2311.05545v1"}
{"created":"2023-11-09 17:35:47","title":"Usability and Adoption of Graphical Data-Driven Development Tools","abstract":"Software development of modern, data-driven applications still relies on tools that use interaction paradigms that have remained mostly unchanged for decades. While rich forms of interactions exist as an alternative to textual command input, they find little adoption in professional software creation. In this work, we compare graphical programming using direct manipulation to the traditional, textual way of creating data-driven applications to determine the benefits and drawbacks of each. In a between-subjects user study (N=18), we compared developing a machine learning architecture with a graphical editor to traditional code-based development. While qualitative and quantitative measures show general benefits of graphical direct manipulation, the user's subjective perception does not always match this. Participants were aware of the possible benefits of such tools but were still biased in their perception. Our findings highlight that alternative software creation tools cannot just rely on good usability but must emphasize the demands of their specific target group, e.g. user control and flexibility, if they want long-term benefits and adoption.","sentences":["Software development of modern, data-driven applications still relies on tools that use interaction paradigms that have remained mostly unchanged for decades.","While rich forms of interactions exist as an alternative to textual command input, they find little adoption in professional software creation.","In this work, we compare graphical programming using direct manipulation to the traditional, textual way of creating data-driven applications to determine the benefits and drawbacks of each.","In a between-subjects user study (N=18), we compared developing a machine learning architecture with a graphical editor to traditional code-based development.","While qualitative and quantitative measures show general benefits of graphical direct manipulation, the user's subjective perception does not always match this.","Participants were aware of the possible benefits of such tools but were still biased in their perception.","Our findings highlight that alternative software creation tools cannot just rely on good usability but must emphasize the demands of their specific target group, e.g. user control and flexibility, if they want long-term benefits and adoption."],"url":"http://arxiv.org/abs/2311.05540v1"}
{"created":"2023-11-09 17:34:57","title":"A Deep Learning Method for Simultaneous Denoising and Missing Wedge Reconstruction in Cryogenic Electron Tomography","abstract":"Cryogenic electron tomography (cryo-ET) is a technique for imaging biological samples such as viruses, cells, and proteins in 3D. A microscope collects a series of 2D projections of the sample, and the goal is to reconstruct the 3D density of the sample called the tomogram. This is difficult as the 2D projections have a missing wedge of information and are noisy. Tomograms reconstructed with conventional methods, such as filtered back-projection, suffer from the noise, and from artifacts and anisotropic resolution due to the missing wedge of information. To improve the visual quality and resolution of such tomograms, we propose a deep-learning approach for simultaneous denoising and missing wedge reconstruction called DeepDeWedge. DeepDeWedge is based on fitting a neural network to the 2D projections with a self-supervised loss inspired by noise2noise-like methods. The algorithm requires no training or ground truth data. Experiments on synthetic and real cryo-ET data show that DeepDeWedge achieves competitive performance for deep learning-based denoising and missing wedge reconstruction of cryo-ET tomograms.","sentences":["Cryogenic electron tomography (cryo-ET) is a technique for imaging biological samples such as viruses, cells, and proteins in 3D.","A microscope collects a series of 2D projections of the sample, and the goal is to reconstruct the 3D density of the sample called the tomogram.","This is difficult as the 2D projections have a missing wedge of information and are noisy.","Tomograms reconstructed with conventional methods, such as filtered back-projection, suffer from the noise, and from artifacts and anisotropic resolution due to the missing wedge of information.","To improve the visual quality and resolution of such tomograms, we propose a deep-learning approach for simultaneous denoising and missing wedge reconstruction called DeepDeWedge.","DeepDeWedge is based on fitting a neural network to the 2D projections with a self-supervised loss inspired by noise2noise-like methods.","The algorithm requires no training or ground truth data.","Experiments on synthetic and real cryo-ET data show that DeepDeWedge achieves competitive performance for deep learning-based denoising and missing wedge reconstruction of cryo-ET tomograms."],"url":"http://arxiv.org/abs/2311.05539v1"}
{"created":"2023-11-09 17:34:53","title":"Embedding Space Interpolation Beyond Mini-Batch, Beyond Pairs and Beyond Examples","abstract":"Mixup refers to interpolation-based data augmentation, originally motivated as a way to go beyond empirical risk minimization (ERM). Its extensions mostly focus on the definition of interpolation and the space (input or feature) where it takes place, while the augmentation process itself is less studied. In most methods, the number of generated examples is limited to the mini-batch size and the number of examples being interpolated is limited to two (pairs), in the input space.   We make progress in this direction by introducing MultiMix, which generates an arbitrarily large number of interpolated examples beyond the mini-batch size and interpolates the entire mini-batch in the embedding space. Effectively, we sample on the entire convex hull of the mini-batch rather than along linear segments between pairs of examples.   On sequence data, we further extend to Dense MultiMix. We densely interpolate features and target labels at each spatial location and also apply the loss densely. To mitigate the lack of dense labels, we inherit labels from examples and weight interpolation factors by attention as a measure of confidence.   Overall, we increase the number of loss terms per mini-batch by orders of magnitude at little additional cost. This is only possible because of interpolating in the embedding space. We empirically show that our solutions yield significant improvement over state-of-the-art mixup methods on four different benchmarks, despite interpolation being only linear. By analyzing the embedding space, we show that the classes are more tightly clustered and uniformly spread over the embedding space, thereby explaining the improved behavior.","sentences":["Mixup refers to interpolation-based data augmentation, originally motivated as a way to go beyond empirical risk minimization (ERM).","Its extensions mostly focus on the definition of interpolation and the space (input or feature) where it takes place, while the augmentation process itself is less studied.","In most methods, the number of generated examples is limited to the mini-batch size and the number of examples being interpolated is limited to two (pairs), in the input space.   ","We make progress in this direction by introducing MultiMix, which generates an arbitrarily large number of interpolated examples beyond the mini-batch size and interpolates the entire mini-batch in the embedding space.","Effectively, we sample on the entire convex hull of the mini-batch rather than along linear segments between pairs of examples.   ","On sequence data, we further extend to Dense MultiMix.","We densely interpolate features and target labels at each spatial location and also apply the loss densely.","To mitigate the lack of dense labels, we inherit labels from examples and weight interpolation factors by attention as a measure of confidence.   ","Overall, we increase the number of loss terms per mini-batch by orders of magnitude at little additional cost.","This is only possible because of interpolating in the embedding space.","We empirically show that our solutions yield significant improvement over state-of-the-art mixup methods on four different benchmarks, despite interpolation being only linear.","By analyzing the embedding space, we show that the classes are more tightly clustered and uniformly spread over the embedding space, thereby explaining the improved behavior."],"url":"http://arxiv.org/abs/2311.05538v1"}
{"created":"2023-11-09 17:10:20","title":"SeaTurtleID2022: A long-span dataset for reliable sea turtle re-identification","abstract":"This paper introduces the first public large-scale, long-span dataset with sea turtle photographs captured in the wild -- SeaTurtleID2022 (https://www.kaggle.com/datasets/wildlifedatasets/seaturtleid2022). The dataset contains 8729 photographs of 438 unique individuals collected within 13 years, making it the longest-spanned dataset for animal re-identification. All photographs include various annotations, e.g., identity, encounter timestamp, and body parts segmentation masks. Instead of standard \"random\" splits, the dataset allows for two realistic and ecologically motivated splits: (i) a time-aware closed-set with training, validation, and test data from different days/years, and (ii) a time-aware open-set with new unknown individuals in test and validation sets. We show that time-aware splits are essential for benchmarking re-identification methods, as random splits lead to performance overestimation. Furthermore, a baseline instance segmentation and re-identification performance over various body parts is provided. Finally, an end-to-end system for sea turtle re-identification is proposed and evaluated. The proposed system based on Hybrid Task Cascade for head instance segmentation and ArcFace-trained feature-extractor achieved an accuracy of 86.8%.","sentences":["This paper introduces the first public large-scale, long-span dataset with sea turtle photographs captured in the wild -- SeaTurtleID2022 (https://www.kaggle.com/datasets/wildlifedatasets/seaturtleid2022).","The dataset contains 8729 photographs of 438 unique individuals collected within 13 years, making it the longest-spanned dataset for animal re-identification.","All photographs include various annotations, e.g., identity, encounter timestamp, and body parts segmentation masks.","Instead of standard \"random\" splits, the dataset allows for two realistic and ecologically motivated splits: (i) a time-aware closed-set with training, validation, and test data from different days/years, and (ii) a time-aware open-set with new unknown individuals in test and validation sets.","We show that time-aware splits are essential for benchmarking re-identification methods, as random splits lead to performance overestimation.","Furthermore, a baseline instance segmentation and re-identification performance over various body parts is provided.","Finally, an end-to-end system for sea turtle re-identification is proposed and evaluated.","The proposed system based on Hybrid Task Cascade for head instance segmentation and ArcFace-trained feature-extractor achieved an accuracy of 86.8%."],"url":"http://arxiv.org/abs/2311.05524v1"}
{"created":"2023-11-09 17:05:53","title":"BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis","abstract":"Synthesizing photorealistic 4D human head avatars from videos is essential for VR/AR, telepresence, and video game applications. Although existing Neural Radiance Fields (NeRF)-based methods achieve high-fidelity results, the computational expense limits their use in real-time applications. To overcome this limitation, we introduce BakedAvatar, a novel representation for real-time neural head avatar synthesis, deployable in a standard polygon rasterization pipeline. Our approach extracts deformable multi-layer meshes from learned isosurfaces of the head and computes expression-, pose-, and view-dependent appearances that can be baked into static textures for efficient rasterization. We thus propose a three-stage pipeline for neural head avatar synthesis, which includes learning continuous deformation, manifold, and radiance fields, extracting layered meshes and textures, and fine-tuning texture details with differential rasterization. Experimental results demonstrate that our representation generates synthesis results of comparable quality to other state-of-the-art methods while significantly reducing the inference time required. We further showcase various head avatar synthesis results from monocular videos, including view synthesis, face reenactment, expression editing, and pose editing, all at interactive frame rates.","sentences":["Synthesizing photorealistic 4D human head avatars from videos is essential for VR/AR, telepresence, and video game applications.","Although existing Neural Radiance Fields (NeRF)-based methods achieve high-fidelity results, the computational expense limits their use in real-time applications.","To overcome this limitation, we introduce BakedAvatar, a novel representation for real-time neural head avatar synthesis, deployable in a standard polygon rasterization pipeline.","Our approach extracts deformable multi-layer meshes from learned isosurfaces of the head and computes expression-, pose-, and view-dependent appearances that can be baked into static textures for efficient rasterization.","We thus propose a three-stage pipeline for neural head avatar synthesis, which includes learning continuous deformation, manifold, and radiance fields, extracting layered meshes and textures, and fine-tuning texture details with differential rasterization.","Experimental results demonstrate that our representation generates synthesis results of comparable quality to other state-of-the-art methods while significantly reducing the inference time required.","We further showcase various head avatar synthesis results from monocular videos, including view synthesis, face reenactment, expression editing, and pose editing, all at interactive frame rates."],"url":"http://arxiv.org/abs/2311.05521v1"}
{"created":"2023-11-09 16:53:55","title":"A Comprehensive Survey of Threshold Digital Signatures: NIST Standards, Post-Quantum Cryptography, Exotic Techniques, and Real-World Applications","abstract":"Threshold digital signatures enable a distributed execution of signature functionalities and will play a crucial role in the security of emerging decentralized next-generation networked systems and applications. In this paper, we provide a comprehensive and systematic survey of threshold and distributed signatures with advanced features. Our survey encompasses threshold signatures in conventional and post-quantum cryptography (PQC) settings and captures custom-design and standard signatures (e.g., conventional NIST and NIST-PQC). We examine both generic (via secure multi-party computation) and custom thresholding techniques for a myriad of signature families while investigating exotic signatures, real-life applications, and potential future research direction.","sentences":["Threshold digital signatures enable a distributed execution of signature functionalities and will play a crucial role in the security of emerging decentralized next-generation networked systems and applications.","In this paper, we provide a comprehensive and systematic survey of threshold and distributed signatures with advanced features.","Our survey encompasses threshold signatures in conventional and post-quantum cryptography (PQC) settings and captures custom-design and standard signatures (e.g., conventional NIST and NIST-PQC).","We examine both generic (via secure multi-party computation) and custom thresholding techniques for a myriad of signature families while investigating exotic signatures, real-life applications, and potential future research direction."],"url":"http://arxiv.org/abs/2311.05514v1"}
{"created":"2023-11-09 16:52:44","title":"From Learning Management System to Affective Tutoring system: a preliminary study","abstract":"In this study, we investigate the combination of indicators, including performance, behavioral engagement, and emotional engagement, to identify students experiencing difficulties. We analyzed data from two primary sources: digital traces extracted from th e Learning Management System (LMS) and images captured by students' webcams. The digital traces provided insights into students' interactions with the educational content, while the images were utilized to analyze their emotional expressions during learnin g activities. By utilizing real data collected from students at a French engineering school, recorded during the 2022 2023 academic year, we observed a correlation between positive emotional states and improved academic outcomes. These preliminary findings support the notion that emotions play a crucial role in differentiating between high achieving and low achieving students.","sentences":["In this study, we investigate the combination of indicators, including performance, behavioral engagement, and emotional engagement, to identify students experiencing difficulties.","We analyzed data from two primary sources: digital traces extracted from th e Learning Management System (LMS) and images captured by students' webcams.","The digital traces provided insights into students' interactions with the educational content, while the images were utilized to analyze their emotional expressions during learnin g activities.","By utilizing real data collected from students at a French engineering school, recorded during the 2022 2023 academic year, we observed a correlation between positive emotional states and improved academic outcomes.","These preliminary findings support the notion that emotions play a crucial role in differentiating between high achieving and low achieving students."],"url":"http://arxiv.org/abs/2311.05513v1"}
{"created":"2023-11-09 16:51:26","title":"Anytime-Constrained Reinforcement Learning","abstract":"We introduce and study constrained Markov Decision Processes (cMDPs) with anytime constraints. An anytime constraint requires the agent to never violate its budget at any point in time, almost surely. Although Markovian policies are no longer sufficient, we show that there exist optimal deterministic policies augmented with cumulative costs. In fact, we present a fixed-parameter tractable reduction from anytime-constrained cMDPs to unconstrained MDPs. Our reduction yields planning and learning algorithms that are time and sample-efficient for tabular cMDPs so long as the precision of the costs is logarithmic in the size of the cMDP. However, we also show that computing non-trivial approximately optimal policies is NP-hard in general. To circumvent this bottleneck, we design provable approximation algorithms that efficiently compute or learn an approximately feasible policy with optimal value so long as the maximum supported cost is bounded by a polynomial in the cMDP or by the absolute budget. Given our hardness results, our approximation guarantees are the best possible in terms of tractability under worst-case analysis.","sentences":["We introduce and study constrained Markov Decision Processes (cMDPs) with anytime constraints.","An anytime constraint requires the agent to never violate its budget at any point in time, almost surely.","Although Markovian policies are no longer sufficient, we show that there exist optimal deterministic policies augmented with cumulative costs.","In fact, we present a fixed-parameter tractable reduction from anytime-constrained cMDPs to unconstrained MDPs.","Our reduction yields planning and learning algorithms that are time and sample-efficient for tabular cMDPs so long as the precision of the costs is logarithmic in the size of the cMDP.","However, we also show that computing non-trivial approximately optimal policies is NP-hard in general.","To circumvent this bottleneck, we design provable approximation algorithms that efficiently compute or learn an approximately feasible policy with optimal value so long as the maximum supported cost is bounded by a polynomial in the cMDP or by the absolute budget.","Given our hardness results, our approximation guarantees are the best possible in terms of tractability under worst-case analysis."],"url":"http://arxiv.org/abs/2311.05511v1"}
{"created":"2023-11-09 16:38:02","title":"Measuring the Prevalence of WiFi Bottlenecks in Home Access Networks","abstract":"As broadband Internet speeds continue to increase, the home wireless (\"WiFi\") network may more frequently become a performance bottleneck. Past research, now nearly a decade old, initially documented this phenomenon through indirect inference techniques, noting the prevalence of WiFi bottlenecks but never directly measuring them. In the intervening years, access network (and WiFi) speeds have increased, warranting a re-appraisal of this important question, particularly with renewed private and federal investment in access network infrastructure. This paper studies this question, developing a new system and measurement technique to perform direct measurements of WiFi and access network performance, ultimately collecting and analyzing a first-of-its-kind dataset of more than 13,000 joint measurements of WiFi and access network throughputs, in a real-world deployment spanning more than 50 homes, for nearly two years. Using this dataset, we re-examine the question of whether, when, and to what extent a user's home wireless network may be a performance bottleneck, particularly relative to their access connection. We do so by directly and continuously measuring the user's Internet performance along two separate components of the Internet path -- from a wireless client inside the home network to the wired point of access (e.g., the cable modem), and from the wired point of access to the user's ISP. Confirming and revising results from more than a decade ago, we find that a user's home wireless network is often the throughput bottleneck. In particular, for users with access links that exceed 800~Mbps, the user's home wireless network was the performance bottleneck 100% of the time.","sentences":["As broadband Internet speeds continue to increase, the home wireless (\"WiFi\") network may more frequently become a performance bottleneck.","Past research, now nearly a decade old, initially documented this phenomenon through indirect inference techniques, noting the prevalence of WiFi bottlenecks but never directly measuring them.","In the intervening years, access network (and WiFi) speeds have increased, warranting a re-appraisal of this important question, particularly with renewed private and federal investment in access network infrastructure.","This paper studies this question, developing a new system and measurement technique to perform direct measurements of WiFi and access network performance, ultimately collecting and analyzing a first-of-its-kind dataset of more than 13,000 joint measurements of WiFi and access network throughputs, in a real-world deployment spanning more than 50 homes, for nearly two years.","Using this dataset, we re-examine the question of whether, when, and to what extent a user's home wireless network may be a performance bottleneck, particularly relative to their access connection.","We do so by directly and continuously measuring the user's Internet performance along two separate components of the Internet path -- from a wireless client inside the home network to the wired point of access (e.g., the cable modem), and from the wired point of access to the user's ISP.","Confirming and revising results from more than a decade ago, we find that a user's home wireless network is often the throughput bottleneck.","In particular, for users with access links that exceed 800~Mbps, the user's home wireless network was the performance bottleneck 100% of the time."],"url":"http://arxiv.org/abs/2311.05499v1"}
{"created":"2023-11-09 16:37:34","title":"Trust your BMS: Designing a Lightweight Authentication Architecture for Industrial Networks","abstract":"With the advent of clean energy awareness and systems that rely on extensive battery usage, the community has seen an increased interest in the development of more complex and secure Battery Management Systems (BMS). In particular, the inclusion of BMS in modern complex systems like electric vehicles and power grids has presented a new set of security-related challenges. A concern is shown when BMS are intended to extend their communication with external system networks, as their interaction can leave many backdoors open that potential attackers could exploit. Hence, it is highly desirable to find a general design that can be used for BMS and its system inclusion. In this work, a security architecture solution is proposed intended for the communication between BMS and other system devices. The aim of the proposed architecture is to be easily applicable in different industrial settings and systems, while at the same time keeping the design lightweight in nature.","sentences":["With the advent of clean energy awareness and systems that rely on extensive battery usage, the community has seen an increased interest in the development of more complex and secure Battery Management Systems (BMS).","In particular, the inclusion of BMS in modern complex systems like electric vehicles and power grids has presented a new set of security-related challenges.","A concern is shown when BMS are intended to extend their communication with external system networks, as their interaction can leave many backdoors open that potential attackers could exploit.","Hence, it is highly desirable to find a general design that can be used for BMS and its system inclusion.","In this work, a security architecture solution is proposed intended for the communication between BMS and other system devices.","The aim of the proposed architecture is to be easily applicable in different industrial settings and systems, while at the same time keeping the design lightweight in nature."],"url":"http://arxiv.org/abs/2311.05498v1"}
{"created":"2023-11-09 16:33:08","title":"Object-centric Cross-modal Feature Distillation for Event-based Object Detection","abstract":"Event cameras are gaining popularity due to their unique properties, such as their low latency and high dynamic range. One task where these benefits can be crucial is real-time object detection. However, RGB detectors still outperform event-based detectors due to the sparsity of the event data and missing visual details. In this paper, we develop a novel knowledge distillation approach to shrink the performance gap between these two modalities. To this end, we propose a cross-modality object detection distillation method that by design can focus on regions where the knowledge distillation works best. We achieve this by using an object-centric slot attention mechanism that can iteratively decouple features maps into object-centric features and corresponding pixel-features used for distillation. We evaluate our novel distillation approach on a synthetic and a real event dataset with aligned grayscale images as a teacher modality. We show that object-centric distillation allows to significantly improve the performance of the event-based student object detector, nearly halving the performance gap with respect to the teacher.","sentences":["Event cameras are gaining popularity due to their unique properties, such as their low latency and high dynamic range.","One task where these benefits can be crucial is real-time object detection.","However, RGB detectors still outperform event-based detectors due to the sparsity of the event data and missing visual details.","In this paper, we develop a novel knowledge distillation approach to shrink the performance gap between these two modalities.","To this end, we propose a cross-modality object detection distillation method that by design can focus on regions where the knowledge distillation works best.","We achieve this by using an object-centric slot attention mechanism that can iteratively decouple features maps into object-centric features and corresponding pixel-features used for distillation.","We evaluate our novel distillation approach on a synthetic and a real event dataset with aligned grayscale images as a teacher modality.","We show that object-centric distillation allows to significantly improve the performance of the event-based student object detector, nearly halving the performance gap with respect to the teacher."],"url":"http://arxiv.org/abs/2311.05494v1"}
{"created":"2023-11-09 16:30:22","title":"General Policies, Subgoal Structure, and Planning Width","abstract":"It has been observed that many classical planning domains with atomic goals can be solved by means of a simple polynomial exploration procedure, called IW, that runs in time exponential in the problem width, which in these cases is bounded and small. Yet, while the notion of width has become part of state-of-the-art planning algorithms such as BFWS, there is no good explanation for why so many benchmark domains have bounded width when atomic goals are considered. In this work, we address this question by relating bounded width with the existence of general optimal policies that in each planning instance are represented by tuples of atoms of bounded size. We also define the notions of (explicit) serializations and serialized width that have a broader scope as many domains have a bounded serialized width but no bounded width. Such problems are solved non-optimally in polynomial time by a suitable variant of the Serialized IW algorithm. Finally, the language of general policies and the semantics of serializations are combined to yield a simple, meaningful, and expressive language for specifying serializations in compact form in the form of sketches, which can be used for encoding domain control knowledge by hand or for learning it from small examples. Sketches express general problem decompositions in terms of subgoals, and sketches of bounded width express problem decompositions that can be solved in polynomial time.","sentences":["It has been observed that many classical planning domains with atomic goals can be solved by means of a simple polynomial exploration procedure, called IW, that runs in time exponential in the problem width, which in these cases is bounded and small.","Yet, while the notion of width has become part of state-of-the-art planning algorithms such as BFWS, there is no good explanation for why so many benchmark domains have bounded width when atomic goals are considered.","In this work, we address this question by relating bounded width with the existence of general optimal policies that in each planning instance are represented by tuples of atoms of bounded size.","We also define the notions of (explicit) serializations and serialized width that have a broader scope as many domains have a bounded serialized width but no bounded width.","Such problems are solved non-optimally in polynomial time by a suitable variant of the Serialized IW algorithm.","Finally, the language of general policies and the semantics of serializations are combined to yield a simple, meaningful, and expressive language for specifying serializations in compact form in the form of sketches, which can be used for encoding domain control knowledge by hand or for learning it from small examples.","Sketches express general problem decompositions in terms of subgoals, and sketches of bounded width express problem decompositions that can be solved in polynomial time."],"url":"http://arxiv.org/abs/2311.05490v1"}
{"created":"2023-11-09 16:22:10","title":"News and Misinformation Consumption in Europe: A Longitudinal Cross-Country Perspective","abstract":"The Internet and social media have transformed news availability and accessibility, reshaping information consumption and production. However, they can also facilitate the rapid spread of misinformation, posing significant societal challenges. To combat misinformation effectively, it is crucial to understand the online information environment and news consumption patterns. Most existing research has primarily focused on single topics or individual countries, lacking cross-country comparisons. This study investigated information consumption in four European countries, analyzing three years of Twitter activity from news outlet accounts in France, Germany, Italy, and the UK and focusing on the role of misinformation sources. Our work offers a perspective on how topics of European significance are interpreted across various countries. Results indicate that reliable sources dominate the information landscape, although unreliable content is still present across all countries and topics. While most users engage with reliable sources, a small percentage consume questionable content. Interestingly, few users have a mixed information diet, bridging the gap between questionable and reliable news in the similarity network. Cross-country comparisons revealed differences in audience overlap of news sources, offering valuable guidance for policymakers and scholars in developing effective and tailored solutions to combat misinformation.","sentences":["The Internet and social media have transformed news availability and accessibility, reshaping information consumption and production.","However, they can also facilitate the rapid spread of misinformation, posing significant societal challenges.","To combat misinformation effectively, it is crucial to understand the online information environment and news consumption patterns.","Most existing research has primarily focused on single topics or individual countries, lacking cross-country comparisons.","This study investigated information consumption in four European countries, analyzing three years of Twitter activity from news outlet accounts in France, Germany, Italy, and the UK and focusing on the role of misinformation sources.","Our work offers a perspective on how topics of European significance are interpreted across various countries.","Results indicate that reliable sources dominate the information landscape, although unreliable content is still present across all countries and topics.","While most users engage with reliable sources, a small percentage consume questionable content.","Interestingly, few users have a mixed information diet, bridging the gap between questionable and reliable news in the similarity network.","Cross-country comparisons revealed differences in audience overlap of news sources, offering valuable guidance for policymakers and scholars in developing effective and tailored solutions to combat misinformation."],"url":"http://arxiv.org/abs/2311.05487v1"}
{"created":"2023-11-09 16:16:31","title":"meta4: semantically-aligned generation of metaphoric gestures using self-supervised text and speech representation","abstract":"Image Schemas are repetitive cognitive patterns that influence the way we conceptualize and reason about various concepts present in speech. These patterns are deeply embedded within our cognitive processes and are reflected in our bodily expressions including gestures. Particularly, metaphoric gestures possess essential characteristics and semantic meanings that align with Image Schemas, to visually represent abstract concepts. The shape and form of gestures can convey abstract concepts, such as extending the forearm and hand or tracing a line with hand movements to visually represent the image schema of PATH. Previous behavior generation models have primarily focused on utilizing speech (acoustic features and text) to drive the generation model of virtual agents. They have not considered key semantic information as those carried by Image Schemas to effectively generate metaphoric gestures. To address this limitation, we introduce META4, a deep learning approach that generates metaphoric gestures from both speech and Image Schemas. Our approach has two primary goals: computing Image Schemas from input text to capture the underlying semantic and metaphorical meaning, and generating metaphoric gestures driven by speech and the computed image schemas. Our approach is the first method for generating speech driven metaphoric gestures while leveraging the potential of Image Schemas. We demonstrate the effectiveness of our approach and highlight the importance of both speech and image schemas in modeling metaphoric gestures.","sentences":["Image Schemas are repetitive cognitive patterns that influence the way we conceptualize and reason about various concepts present in speech.","These patterns are deeply embedded within our cognitive processes and are reflected in our bodily expressions including gestures.","Particularly, metaphoric gestures possess essential characteristics and semantic meanings that align with Image Schemas, to visually represent abstract concepts.","The shape and form of gestures can convey abstract concepts, such as extending the forearm and hand or tracing a line with hand movements to visually represent the image schema of PATH.","Previous behavior generation models have primarily focused on utilizing speech (acoustic features and text) to drive the generation model of virtual agents.","They have not considered key semantic information as those carried by Image Schemas to effectively generate metaphoric gestures.","To address this limitation, we introduce META4, a deep learning approach that generates metaphoric gestures from both speech and Image Schemas.","Our approach has two primary goals: computing Image Schemas from input text to capture the underlying semantic and metaphorical meaning, and generating metaphoric gestures driven by speech and the computed image schemas.","Our approach is the first method for generating speech driven metaphoric gestures while leveraging the potential of Image Schemas.","We demonstrate the effectiveness of our approach and highlight the importance of both speech and image schemas in modeling metaphoric gestures."],"url":"http://arxiv.org/abs/2311.05481v1"}
{"created":"2023-11-09 16:09:12","title":"Robust Retraining-free GAN Fingerprinting via Personalized Normalization","abstract":"In recent years, there has been significant growth in the commercial applications of generative models, licensed and distributed by model developers to users, who in turn use them to offer services. In this scenario, there is a need to track and identify the responsible user in the presence of a violation of the license agreement or any kind of malicious usage. Although there are methods enabling Generative Adversarial Networks (GANs) to include invisible watermarks in the images they produce, generating a model with a different watermark, referred to as a fingerprint, for each user is time- and resource-consuming due to the need to retrain the model to include the desired fingerprint. In this paper, we propose a retraining-free GAN fingerprinting method that allows model developers to easily generate model copies with the same functionality but different fingerprints. The generator is modified by inserting additional Personalized Normalization (PN) layers whose parameters (scaling and bias) are generated by two dedicated shallow networks (ParamGen Nets) taking the fingerprint as input. A watermark decoder is trained simultaneously to extract the fingerprint from the generated images. The proposed method can embed different fingerprints inside the GAN by just changing the input of the ParamGen Nets and performing a feedforward pass, without finetuning or retraining. The performance of the proposed method in terms of robustness against both model-level and image-level attacks is also superior to the state-of-the-art.","sentences":["In recent years, there has been significant growth in the commercial applications of generative models, licensed and distributed by model developers to users, who in turn use them to offer services.","In this scenario, there is a need to track and identify the responsible user in the presence of a violation of the license agreement or any kind of malicious usage.","Although there are methods enabling Generative Adversarial Networks (GANs) to include invisible watermarks in the images they produce, generating a model with a different watermark, referred to as a fingerprint, for each user is time- and resource-consuming due to the need to retrain the model to include the desired fingerprint.","In this paper, we propose a retraining-free GAN fingerprinting method that allows model developers to easily generate model copies with the same functionality but different fingerprints.","The generator is modified by inserting additional Personalized Normalization (PN) layers whose parameters (scaling and bias) are generated by two dedicated shallow networks (ParamGen Nets) taking the fingerprint as input.","A watermark decoder is trained simultaneously to extract the fingerprint from the generated images.","The proposed method can embed different fingerprints inside the GAN by just changing the input of the ParamGen Nets and performing a feedforward pass, without finetuning or retraining.","The performance of the proposed method in terms of robustness against both model-level and image-level attacks is also superior to the state-of-the-art."],"url":"http://arxiv.org/abs/2311.05478v1"}
{"created":"2023-11-09 16:06:37","title":"On the Complexity of the Virtual Network Embedding in Specific Tree Topologies","abstract":"Virtual networks are an innovative abstraction that extends cloud computing concepts to the network: by supporting bandwidth reservations between compute nodes (e.g., virtual machines), virtual networks can provide a predictable performance to distributed and communication-intensive cloud applications. However, in order to make the most efficient use of the shared resources, the Virtual Network Embedding (VNE) problem has to be solved: a virtual network should be mapped onto the given physical network so that resource reservations are minimized. The problem has been studied intensively already and is known to be NP-hard in general. In this paper, we revisit this problem and consider it on specific topologies, as they often arise in practice. To be more precise, we study the weighted version of the VNE problem: we consider a virtual weighted network of a specific topology which we want to embed onto a weighted network with capacities and specific topology. As for topologies, we consider most fundamental and commonly used ones: line, star, $2$-tiered star, oversubscribed $2$-tiered star, and tree, in addition to also considering arbitrary topologies. We show that typically the VNE problem is NP-hard even in more specialized cases, however, sometimes there exists a polynomial algorithm: for example, an embedding of the oversubscribed $2$-tiered star onto the tree is polynomial while an embedding of an arbitrary $2$-tiered star is not.","sentences":["Virtual networks are an innovative abstraction that extends cloud computing concepts to the network: by supporting bandwidth reservations between compute nodes (e.g., virtual machines), virtual networks can provide a predictable performance to distributed and communication-intensive cloud applications.","However, in order to make the most efficient use of the shared resources, the Virtual Network Embedding (VNE) problem has to be solved: a virtual network should be mapped onto the given physical network so that resource reservations are minimized.","The problem has been studied intensively already and is known to be NP-hard in general.","In this paper, we revisit this problem and consider it on specific topologies, as they often arise in practice.","To be more precise, we study the weighted version of the VNE problem: we consider a virtual weighted network of a specific topology which we want to embed onto a weighted network with capacities and specific topology.","As for topologies, we consider most fundamental and commonly used ones: line, star, $2$-tiered star, oversubscribed $2$-tiered star, and tree, in addition to also considering arbitrary topologies.","We show that typically the VNE problem is NP-hard even in more specialized cases, however, sometimes there exists a polynomial algorithm: for example, an embedding of the oversubscribed $2$-tiered star onto the tree is polynomial while an embedding of an arbitrary $2$-tiered star is not."],"url":"http://arxiv.org/abs/2311.05474v1"}
{"created":"2023-11-09 16:05:38","title":"Do Ensembling and Meta-Learning Improve Outlier Detection in Randomized Controlled Trials?","abstract":"Modern multi-centre randomized controlled trials (MCRCTs) collect massive amounts of tabular data, and are monitored intensively for irregularities by humans. We began by empirically evaluating 6 modern machine learning-based outlier detection algorithms on the task of identifying irregular data in 838 datasets from 7 real-world MCRCTs with a total of 77,001 patients from over 44 countries. Our results reinforce key findings from prior work in the outlier detection literature on data from other domains. Existing algorithms often succeed at identifying irregularities without any supervision, with at least one algorithm exhibiting positive performance 70.6% of the time. However, performance across datasets varies substantially with no single algorithm performing consistently well, motivating new techniques for unsupervised model selection or other means of aggregating potentially discordant predictions from multiple candidate models. We propose the Meta-learned Probabilistic Ensemble (MePE), a simple algorithm for aggregating the predictions of multiple unsupervised models, and show that it performs favourably compared to recent meta-learning approaches for outlier detection model selection. While meta-learning shows promise, small ensembles outperform all forms of meta-learning on average, a negative result that may guide the application of current outlier detection approaches in healthcare and other real-world domains.","sentences":["Modern multi-centre randomized controlled trials (MCRCTs) collect massive amounts of tabular data, and are monitored intensively for irregularities by humans.","We began by empirically evaluating 6 modern machine learning-based outlier detection algorithms on the task of identifying irregular data in 838 datasets from 7 real-world MCRCTs with a total of 77,001 patients from over 44 countries.","Our results reinforce key findings from prior work in the outlier detection literature on data from other domains.","Existing algorithms often succeed at identifying irregularities without any supervision, with at least one algorithm exhibiting positive performance 70.6% of the time.","However, performance across datasets varies substantially with no single algorithm performing consistently well, motivating new techniques for unsupervised model selection or other means of aggregating potentially discordant predictions from multiple candidate models.","We propose the Meta-learned Probabilistic Ensemble (MePE), a simple algorithm for aggregating the predictions of multiple unsupervised models, and show that it performs favourably compared to recent meta-learning approaches for outlier detection model selection.","While meta-learning shows promise, small ensembles outperform all forms of meta-learning on average, a negative result that may guide the application of current outlier detection approaches in healthcare and other real-world domains."],"url":"http://arxiv.org/abs/2311.05473v1"}
{"created":"2023-11-09 16:04:17","title":"Text Representation Distillation via Information Bottleneck Principle","abstract":"Pre-trained language models (PLMs) have recently shown great success in text representation field. However, the high computational cost and high-dimensional representation of PLMs pose significant challenges for practical applications. To make models more accessible, an effective method is to distill large models into smaller representation models. In order to relieve the issue of performance degradation after distillation, we propose a novel Knowledge Distillation method called IBKD. This approach is motivated by the Information Bottleneck principle and aims to maximize the mutual information between the final representation of the teacher and student model, while simultaneously reducing the mutual information between the student model's representation and the input data. This enables the student model to preserve important learned information while avoiding unnecessary information, thus reducing the risk of over-fitting. Empirical studies on two main downstream applications of text representation (Semantic Textual Similarity and Dense Retrieval tasks) demonstrate the effectiveness of our proposed approach.","sentences":["Pre-trained language models (PLMs) have recently shown great success in text representation field.","However, the high computational cost and high-dimensional representation of PLMs pose significant challenges for practical applications.","To make models more accessible, an effective method is to distill large models into smaller representation models.","In order to relieve the issue of performance degradation after distillation, we propose a novel Knowledge Distillation method called IBKD.","This approach is motivated by the Information Bottleneck principle and aims to maximize the mutual information between the final representation of the teacher and student model, while simultaneously reducing the mutual information between the student model's representation and the input data.","This enables the student model to preserve important learned information while avoiding unnecessary information, thus reducing the risk of over-fitting.","Empirical studies on two main downstream applications of text representation (Semantic Textual Similarity and Dense Retrieval tasks) demonstrate the effectiveness of our proposed approach."],"url":"http://arxiv.org/abs/2311.05472v1"}
{"created":"2023-11-09 15:58:55","title":"Designing ship hull forms using generative adversarial networks","abstract":"We proposed a GAN-based method to generate a ship hull form. Unlike mathematical hull forms that require geometrical parameters to generate ship hull forms, the proposed method requires desirable ship performance parameters, i.e., the drag coefficient and tonnage. The requirements of ship owners are generally focused on the ship performance and not the geometry itself. Hence, the proposed model is useful for obtaining the ship hull form based on an owner's requirements. The GAN model was trained using a ship hull form dataset generated using the generalized Wigley hull form. The proposed method was evaluated through numerical experiments and successfully generated ship data with small errors.","sentences":["We proposed a GAN-based method to generate a ship hull form.","Unlike mathematical hull forms that require geometrical parameters to generate ship hull forms, the proposed method requires desirable ship performance parameters, i.e., the drag coefficient and tonnage.","The requirements of ship owners are generally focused on the ship performance and not the geometry itself.","Hence, the proposed model is useful for obtaining the ship hull form based on an owner's requirements.","The GAN model was trained using a ship hull form dataset generated using the generalized Wigley hull form.","The proposed method was evaluated through numerical experiments and successfully generated ship data with small errors."],"url":"http://arxiv.org/abs/2311.05470v1"}
{"created":"2023-11-09 15:51:27","title":"3DStyle-Diffusion: Pursuing Fine-grained Text-driven 3D Stylization with 2D Diffusion Models","abstract":"3D content creation via text-driven stylization has played a fundamental challenge to multimedia and graphics community. Recent advances of cross-modal foundation models (e.g., CLIP) have made this problem feasible. Those approaches commonly leverage CLIP to align the holistic semantics of stylized mesh with the given text prompt. Nevertheless, it is not trivial to enable more controllable stylization of fine-grained details in 3D meshes solely based on such semantic-level cross-modal supervision. In this work, we propose a new 3DStyle-Diffusion model that triggers fine-grained stylization of 3D meshes with additional controllable appearance and geometric guidance from 2D Diffusion models. Technically, 3DStyle-Diffusion first parameterizes the texture of 3D mesh into reflectance properties and scene lighting using implicit MLP networks. Meanwhile, an accurate depth map of each sampled view is achieved conditioned on 3D mesh. Then, 3DStyle-Diffusion leverages a pre-trained controllable 2D Diffusion model to guide the learning of rendered images, encouraging the synthesized image of each view semantically aligned with text prompt and geometrically consistent with depth map. This way elegantly integrates both image rendering via implicit MLP networks and diffusion process of image synthesis in an end-to-end fashion, enabling a high-quality fine-grained stylization of 3D meshes. We also build a new dataset derived from Objaverse and the evaluation protocol for this task. Through both qualitative and quantitative experiments, we validate the capability of our 3DStyle-Diffusion. Source code and data are available at \\url{https://github.com/yanghb22-fdu/3DStyle-Diffusion-Official}.","sentences":["3D content creation via text-driven stylization has played a fundamental challenge to multimedia and graphics community.","Recent advances of cross-modal foundation models (e.g., CLIP) have made this problem feasible.","Those approaches commonly leverage CLIP to align the holistic semantics of stylized mesh with the given text prompt.","Nevertheless, it is not trivial to enable more controllable stylization of fine-grained details in 3D meshes solely based on such semantic-level cross-modal supervision.","In this work, we propose a new 3DStyle-Diffusion model that triggers fine-grained stylization of 3D meshes with additional controllable appearance and geometric guidance from 2D Diffusion models.","Technically, 3DStyle-Diffusion first parameterizes the texture of 3D mesh into reflectance properties and scene lighting using implicit MLP networks.","Meanwhile, an accurate depth map of each sampled view is achieved conditioned on 3D mesh.","Then, 3DStyle-Diffusion leverages a pre-trained controllable 2D Diffusion model to guide the learning of rendered images, encouraging the synthesized image of each view semantically aligned with text prompt and geometrically consistent with depth map.","This way elegantly integrates both image rendering via implicit MLP networks and diffusion process of image synthesis in an end-to-end fashion, enabling a high-quality fine-grained stylization of 3D meshes.","We also build a new dataset derived from Objaverse and the evaluation protocol for this task.","Through both qualitative and quantitative experiments, we validate the capability of our 3DStyle-Diffusion.","Source code and data are available at \\url{https://github.com/yanghb22-fdu/3DStyle-Diffusion-Official}."],"url":"http://arxiv.org/abs/2311.05464v1"}
{"created":"2023-11-09 15:50:52","title":"ControlStyle: Text-Driven Stylized Image Generation Using Diffusion Priors","abstract":"Recently, the multimedia community has witnessed the rise of diffusion models trained on large-scale multi-modal data for visual content creation, particularly in the field of text-to-image generation. In this paper, we propose a new task for ``stylizing'' text-to-image models, namely text-driven stylized image generation, that further enhances editability in content creation. Given input text prompt and style image, this task aims to produce stylized images which are both semantically relevant to input text prompt and meanwhile aligned with the style image in style. To achieve this, we present a new diffusion model (ControlStyle) via upgrading a pre-trained text-to-image model with a trainable modulation network enabling more conditions of text prompts and style images. Moreover, diffusion style and content regularizations are simultaneously introduced to facilitate the learning of this modulation network with these diffusion priors, pursuing high-quality stylized text-to-image generation. Extensive experiments demonstrate the effectiveness of our ControlStyle in producing more visually pleasing and artistic results, surpassing a simple combination of text-to-image model and conventional style transfer techniques.","sentences":["Recently, the multimedia community has witnessed the rise of diffusion models trained on large-scale multi-modal data for visual content creation, particularly in the field of text-to-image generation.","In this paper, we propose a new task for ``stylizing'' text-to-image models, namely text-driven stylized image generation, that further enhances editability in content creation.","Given input text prompt and style image, this task aims to produce stylized images which are both semantically relevant to input text prompt and meanwhile aligned with the style image in style.","To achieve this, we present a new diffusion model (ControlStyle) via upgrading a pre-trained text-to-image model with a trainable modulation network enabling more conditions of text prompts and style images.","Moreover, diffusion style and content regularizations are simultaneously introduced to facilitate the learning of this modulation network with these diffusion priors, pursuing high-quality stylized text-to-image generation.","Extensive experiments demonstrate the effectiveness of our ControlStyle in producing more visually pleasing and artistic results, surpassing a simple combination of text-to-image model and conventional style transfer techniques."],"url":"http://arxiv.org/abs/2311.05463v1"}
{"created":"2023-11-09 15:50:44","title":"ChatGPT and other Large Language Models for Cybersecurity of Smart Grid Applications","abstract":"Cybersecurity breaches targeting electrical substations constitute a significant threat to the integrity of the power grid, necessitating comprehensive defense and mitigation strategies. Any anomaly in information and communication technology (ICT) should be detected for secure communications between devices in digital substations. This paper proposes large language models (LLM), e.g., ChatGPT, for the cybersecurity of IEC 61850-based digital substation communications. Multicast messages such as generic object oriented substation event (GOOSE) and sampled value (SV) are used for case studies. The proposed LLM-based cybersecurity framework includes for the first time data pre-processing of communication systems and human-in-the-loop (HITL) training (considering the cybersecurity guidelines recommended by humans). The results show a comparative analysis of detected anomaly data carried out based on the performance evaluation metrics for different LLMs. A hardware-in-the-loop (HIL) testbed is used to generate and extract a dataset of IEC 61850 communications.","sentences":["Cybersecurity breaches targeting electrical substations constitute a significant threat to the integrity of the power grid, necessitating comprehensive defense and mitigation strategies.","Any anomaly in information and communication technology (ICT) should be detected for secure communications between devices in digital substations.","This paper proposes large language models (LLM), e.g., ChatGPT, for the cybersecurity of IEC 61850-based digital substation communications.","Multicast messages such as generic object oriented substation event (GOOSE) and sampled value (SV) are used for case studies.","The proposed LLM-based cybersecurity framework includes for the first time data pre-processing of communication systems and human-in-the-loop (HITL) training (considering the cybersecurity guidelines recommended by humans).","The results show a comparative analysis of detected anomaly data carried out based on the performance evaluation metrics for different LLMs.","A hardware-in-the-loop (HIL) testbed is used to generate and extract a dataset of IEC 61850 communications."],"url":"http://arxiv.org/abs/2311.05462v1"}
{"created":"2023-11-09 15:50:32","title":"Control3D: Towards Controllable Text-to-3D Generation","abstract":"Recent remarkable advances in large-scale text-to-image diffusion models have inspired a significant breakthrough in text-to-3D generation, pursuing 3D content creation solely from a given text prompt. However, existing text-to-3D techniques lack a crucial ability in the creative process: interactively control and shape the synthetic 3D contents according to users' desired specifications (e.g., sketch). To alleviate this issue, we present the first attempt for text-to-3D generation conditioning on the additional hand-drawn sketch, namely Control3D, which enhances controllability for users. In particular, a 2D conditioned diffusion model (ControlNet) is remoulded to guide the learning of 3D scene parameterized as NeRF, encouraging each view of 3D scene aligned with the given text prompt and hand-drawn sketch. Moreover, we exploit a pre-trained differentiable photo-to-sketch model to directly estimate the sketch of the rendered image over synthetic 3D scene. Such estimated sketch along with each sampled view is further enforced to be geometrically consistent with the given sketch, pursuing better controllable text-to-3D generation. Through extensive experiments, we demonstrate that our proposal can generate accurate and faithful 3D scenes that align closely with the input text prompts and sketches.","sentences":["Recent remarkable advances in large-scale text-to-image diffusion models have inspired a significant breakthrough in text-to-3D generation, pursuing 3D content creation solely from a given text prompt.","However, existing text-to-3D techniques lack a crucial ability in the creative process: interactively control and shape the synthetic 3D contents according to users' desired specifications (e.g., sketch).","To alleviate this issue, we present the first attempt for text-to-3D generation conditioning on the additional hand-drawn sketch, namely Control3D, which enhances controllability for users.","In particular, a 2D conditioned diffusion model (ControlNet) is remoulded to guide the learning of 3D scene parameterized as NeRF, encouraging each view of 3D scene aligned with the given text prompt and hand-drawn sketch.","Moreover, we exploit a pre-trained differentiable photo-to-sketch model to directly estimate the sketch of the rendered image over synthetic 3D scene.","Such estimated sketch along with each sampled view is further enforced to be geometrically consistent with the given sketch, pursuing better controllable text-to-3D generation.","Through extensive experiments, we demonstrate that our proposal can generate accurate and faithful 3D scenes that align closely with the input text prompts and sketches."],"url":"http://arxiv.org/abs/2311.05461v1"}
{"created":"2023-11-09 15:48:33","title":"Automated Mobile Sensing Strategies Generation for Human Behaviour Understanding","abstract":"Mobile sensing plays a crucial role in generating digital traces to understand human daily lives. However, studying behaviours like mood or sleep quality in smartphone users requires carefully designed mobile sensing strategies such as sensor selection and feature construction. This process is time-consuming, burdensome, and requires expertise in multiple domains. Furthermore, the resulting sensing framework lacks generalizability, making it difficult to apply to different scenarios. To address these challenges, we propose an automated mobile sensing strategy for human behaviour understanding. First, we establish a knowledge base and consolidate rules for effective feature construction, data collection, and model selection. Then, we introduce the multi-granular human behaviour representation and design procedures for leveraging large language models to generate strategies. Our approach is validated through blind comparative studies and usability evaluation. Ultimately, our approach holds the potential to revolutionise the field of mobile sensing and its applications.","sentences":["Mobile sensing plays a crucial role in generating digital traces to understand human daily lives.","However, studying behaviours like mood or sleep quality in smartphone users requires carefully designed mobile sensing strategies such as sensor selection and feature construction.","This process is time-consuming, burdensome, and requires expertise in multiple domains.","Furthermore, the resulting sensing framework lacks generalizability, making it difficult to apply to different scenarios.","To address these challenges, we propose an automated mobile sensing strategy for human behaviour understanding.","First, we establish a knowledge base and consolidate rules for effective feature construction, data collection, and model selection.","Then, we introduce the multi-granular human behaviour representation and design procedures for leveraging large language models to generate strategies.","Our approach is validated through blind comparative studies and usability evaluation.","Ultimately, our approach holds the potential to revolutionise the field of mobile sensing and its applications."],"url":"http://arxiv.org/abs/2311.05457v1"}
{"created":"2023-11-09 15:39:40","title":"All Should Be Equal in the Eyes of Language Models: Counterfactually Aware Fair Text Generation","abstract":"Fairness in Language Models (LMs) remains a longstanding challenge, given the inherent biases in training data that can be perpetuated by models and affect the downstream tasks. Recent methods employ expensive retraining or attempt debiasing during inference by constraining model outputs to contrast from a reference set of biased templates or exemplars. Regardless, they dont address the primary goal of fairness to maintain equitability across different demographic groups. In this work, we posit that inferencing LMs to generate unbiased output for one demographic under a context ensues from being aware of outputs for other demographics under the same context. To this end, we propose Counterfactually Aware Fair InferencE (CAFIE), a framework that dynamically compares the model understanding of diverse demographics to generate more equitable sentences. We conduct an extensive empirical evaluation using base LMs of varying sizes and across three diverse datasets and found that CAFIE outperforms strong baselines. CAFIE produces fairer text and strikes the best balance between fairness and language modeling capability","sentences":["Fairness in Language Models (LMs) remains a longstanding challenge, given the inherent biases in training data that can be perpetuated by models and affect the downstream tasks.","Recent methods employ expensive retraining or attempt debiasing during inference by constraining model outputs to contrast from a reference set of biased templates or exemplars.","Regardless, they dont address the primary goal of fairness to maintain equitability across different demographic groups.","In this work, we posit that inferencing LMs to generate unbiased output for one demographic under a context ensues from being aware of outputs for other demographics under the same context.","To this end, we propose Counterfactually Aware Fair InferencE (CAFIE), a framework that dynamically compares the model understanding of diverse demographics to generate more equitable sentences.","We conduct an extensive empirical evaluation using base LMs of varying sizes and across three diverse datasets and found that CAFIE outperforms strong baselines.","CAFIE produces fairer text and strikes the best balance between fairness and language modeling capability"],"url":"http://arxiv.org/abs/2311.05451v1"}
{"created":"2023-11-09 15:38:58","title":"Cognitively Inspired Components for Social Conversational Agents","abstract":"Current conversational agents (CA) have seen improvement in conversational quality in recent years due to the influence of large language models (LLMs) like GPT3. However, two key categories of problem remain. Firstly there are the unique technical problems resulting from the approach taken in creating the CA, such as scope with retrieval agents and the often nonsensical answers of former generative agents. Secondly, humans perceive CAs as social actors, and as a result expect the CA to adhere to social convention. Failure on the part of the CA in this respect can lead to a poor interaction and even the perception of threat by the user. As such, this paper presents a survey highlighting a potential solution to both categories of problem through the introduction of cognitively inspired additions to the CA. Through computational facsimiles of semantic and episodic memory, emotion, working memory, and the ability to learn, it is possible to address both the technical and social problems encountered by CAs.","sentences":["Current conversational agents (CA) have seen improvement in conversational quality in recent years due to the influence of large language models (LLMs) like GPT3.","However, two key categories of problem remain.","Firstly there are the unique technical problems resulting from the approach taken in creating the CA, such as scope with retrieval agents and the often nonsensical answers of former generative agents.","Secondly, humans perceive CAs as social actors, and as a result expect the CA to adhere to social convention.","Failure on the part of the CA in this respect can lead to a poor interaction and even the perception of threat by the user.","As such, this paper presents a survey highlighting a potential solution to both categories of problem through the introduction of cognitively inspired additions to the CA.","Through computational facsimiles of semantic and episodic memory, emotion, working memory, and the ability to learn, it is possible to address both the technical and social problems encountered by CAs."],"url":"http://arxiv.org/abs/2311.05450v1"}
{"created":"2023-11-09 15:38:05","title":"Understanding emotions in the context of IT-based self-monitoring","abstract":"This study explores the intersection of information technology-based self-monitoring (ITSM) and emotional responses in chronic care. It critiques the lack of theoretical depth in current ITSM research and proposes a dynamic emotion process theory to understand ITSM's impact on users' emotions. Utilizing computational grounded theory and machine learning analysis of hypertension app reviews, the research seeks to extend emotion theory by examining ITSM stimuli and their influence on emotional episodes, moving beyond discrete emotion models towards a continuous, nuanced understanding of emotional responses.","sentences":["This study explores the intersection of information technology-based self-monitoring (ITSM) and emotional responses in chronic care.","It critiques the lack of theoretical depth in current ITSM research and proposes a dynamic emotion process theory to understand ITSM's impact on users' emotions.","Utilizing computational grounded theory and machine learning analysis of hypertension app reviews, the research seeks to extend emotion theory by examining ITSM stimuli and their influence on emotional episodes, moving beyond discrete emotion models towards a continuous, nuanced understanding of emotional responses."],"url":"http://arxiv.org/abs/2311.05449v1"}
{"created":"2023-11-09 15:31:53","title":"Airfoil generation and feature extraction using the conditional VAE-WGAN-gp","abstract":"A machine learning method was applied to solve an inverse airfoil design problem. A conditional VAE-WGAN-gp model, which couples the conditional variational autoencoder (VAE) and Wasserstein generative adversarial network with gradient penalty (WGAN-gp), is proposed for an airfoil generation method, and then it is compared with the WGAN-gp and VAE models. The VAEGAN model couples the VAE and GAN models, which enables feature extraction in the GAN models. In airfoil generation tasks, to generate airfoil shapes that satisfy lift coefficient requirements, it is known that VAE outperforms WGAN-gp with respect to the accuracy of the reproduction of the lift coefficient, whereas GAN outperforms VAE with respect to the smoothness and variations of generated shapes. In this study, VAE-WGAN-gp demonstrated a good performance in all three aspects. Latent distribution was also studied to compare the feature extraction ability of the proposed method.","sentences":["A machine learning method was applied to solve an inverse airfoil design problem.","A conditional VAE-WGAN-gp model, which couples the conditional variational autoencoder (VAE) and Wasserstein generative adversarial network with gradient penalty (WGAN-gp), is proposed for an airfoil generation method, and then it is compared with the WGAN-gp and VAE models.","The VAEGAN model couples the VAE and GAN models, which enables feature extraction in the GAN models.","In airfoil generation tasks, to generate airfoil shapes that satisfy lift coefficient requirements, it is known that VAE outperforms WGAN-gp with respect to the accuracy of the reproduction of the lift coefficient, whereas GAN outperforms VAE with respect to the smoothness and variations of generated shapes.","In this study, VAE-WGAN-gp demonstrated a good performance in all three aspects.","Latent distribution was also studied to compare the feature extraction ability of the proposed method."],"url":"http://arxiv.org/abs/2311.05445v1"}
{"created":"2023-11-09 15:24:44","title":"A Practical Approach to Novel Class Discovery in Tabular Data","abstract":"The problem of Novel Class Discovery (NCD) consists in extracting knowledge from a labeled set of known classes to accurately partition an unlabeled set of novel classes. While NCD has recently received a lot of attention from the community, it is often solved on computer vision problems and under unrealistic conditions. In particular, the number of novel classes is usually assumed to be known in advance, and their labels are sometimes used to tune hyperparameters. Methods that rely on these assumptions are not applicable in real-world scenarios. In this work, we focus on solving NCD in tabular data when no prior knowledge of the novel classes is available. To this end, we propose to tune the hyperparameters of NCD methods by adapting the $k$-fold cross-validation process and hiding some of the known classes in each fold. Since we have found that methods with too many hyperparameters are likely to overfit these hidden classes, we define a simple deep NCD model. This method is composed of only the essential elements necessary for the NCD problem and performs impressively well under realistic conditions. Furthermore, we find that the latent space of this method can be used to reliably estimate the number of novel classes. Additionally, we adapt two unsupervised clustering algorithms ($k$-means and Spectral Clustering) to leverage the knowledge of the known classes. Extensive experiments are conducted on 7 tabular datasets and demonstrate the effectiveness of the proposed method and hyperparameter tuning process, and show that the NCD problem can be solved without relying on knowledge from the novel classes.","sentences":["The problem of Novel Class Discovery (NCD) consists in extracting knowledge from a labeled set of known classes to accurately partition an unlabeled set of novel classes.","While NCD has recently received a lot of attention from the community, it is often solved on computer vision problems and under unrealistic conditions.","In particular, the number of novel classes is usually assumed to be known in advance, and their labels are sometimes used to tune hyperparameters.","Methods that rely on these assumptions are not applicable in real-world scenarios.","In this work, we focus on solving NCD in tabular data when no prior knowledge of the novel classes is available.","To this end, we propose to tune the hyperparameters of NCD methods by adapting the $k$-fold cross-validation process and hiding some of the known classes in each fold.","Since we have found that methods with too many hyperparameters are likely to overfit these hidden classes, we define a simple deep NCD model.","This method is composed of only the essential elements necessary for the NCD problem and performs impressively well under realistic conditions.","Furthermore, we find that the latent space of this method can be used to reliably estimate the number of novel classes.","Additionally, we adapt two unsupervised clustering algorithms ($k$-means and Spectral Clustering) to leverage the knowledge of the known classes.","Extensive experiments are conducted on 7 tabular datasets and demonstrate the effectiveness of the proposed method and hyperparameter tuning process, and show that the NCD problem can be solved without relying on knowledge from the novel classes."],"url":"http://arxiv.org/abs/2311.05440v1"}
{"created":"2023-11-09 15:22:26","title":"LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents","abstract":"LLaVA-Plus is a general-purpose multimodal assistant that expands the capabilities of large multimodal models. It maintains a skill repository of pre-trained vision and vision-language models and can activate relevant tools based on users' inputs to fulfill real-world tasks. LLaVA-Plus is trained on multimodal instruction-following data to acquire the ability to use tools, covering visual understanding, generation, external knowledge retrieval, and compositions. Empirical results show that LLaVA-Plus outperforms LLaVA in existing capabilities and exhibits new ones. It is distinct in that the image query is directly grounded and actively engaged throughout the entire human-AI interaction sessions, significantly improving tool use performance and enabling new scenarios.","sentences":["LLaVA-Plus is a general-purpose multimodal assistant that expands the capabilities of large multimodal models.","It maintains a skill repository of pre-trained vision and vision-language models and can activate relevant tools based on users' inputs to fulfill real-world tasks.","LLaVA-Plus is trained on multimodal instruction-following data to acquire the ability to use tools, covering visual understanding, generation, external knowledge retrieval, and compositions.","Empirical results show that LLaVA-Plus outperforms LLaVA in existing capabilities and exhibits new ones.","It is distinct in that the image query is directly grounded and actively engaged throughout the entire human-AI interaction sessions, significantly improving tool use performance and enabling new scenarios."],"url":"http://arxiv.org/abs/2311.05437v1"}
{"created":"2023-11-09 15:21:10","title":"Parkinson's Disease Detection through Vocal Biomarkers and Advanced Machine Learning Algorithms: A Comprehensive Study","abstract":"Parkinson's disease (PD) is a prevalent neurodegenerative disorder known for its impact on motor neurons, causing symptoms like tremors, stiffness, and gait difficulties. This study explores the potential of vocal feature alterations in PD patients as a means of early disease prediction. This research aims to predict the onset of Parkinson's disease. Utilizing a variety of advanced machine-learning algorithms, including XGBoost, LightGBM, Bagging, AdaBoost, and Support Vector Machine, among others, the study evaluates the predictive performance of these models using metrics such as accuracy, area under the curve (AUC), sensitivity, and specificity. The findings of this comprehensive analysis highlight LightGBM as the most effective model, achieving an impressive accuracy rate of 96%, alongside a matching AUC of 96%. LightGBM exhibited a remarkable sensitivity of 100% and specificity of 94.43%, surpassing other machine learning algorithms in accuracy and AUC scores. Given the complexities of Parkinson's disease and its challenges in early diagnosis, this study underscores the significance of leveraging vocal biomarkers coupled with advanced machine-learning techniques for precise and timely PD detection.","sentences":["Parkinson's disease (PD) is a prevalent neurodegenerative disorder known for its impact on motor neurons, causing symptoms like tremors, stiffness, and gait difficulties.","This study explores the potential of vocal feature alterations in PD patients as a means of early disease prediction.","This research aims to predict the onset of Parkinson's disease.","Utilizing a variety of advanced machine-learning algorithms, including XGBoost, LightGBM, Bagging, AdaBoost, and Support Vector Machine, among others, the study evaluates the predictive performance of these models using metrics such as accuracy, area under the curve (AUC), sensitivity, and specificity.","The findings of this comprehensive analysis highlight LightGBM as the most effective model, achieving an impressive accuracy rate of 96%, alongside a matching AUC of 96%.","LightGBM exhibited a remarkable sensitivity of 100% and specificity of 94.43%, surpassing other machine learning algorithms in accuracy and AUC scores.","Given the complexities of Parkinson's disease and its challenges in early diagnosis, this study underscores the significance of leveraging vocal biomarkers coupled with advanced machine-learning techniques for precise and timely PD detection."],"url":"http://arxiv.org/abs/2311.05435v1"}
{"created":"2023-11-09 15:17:57","title":"Core determinants of quality criteria for mhealth for hypertension: evidence from machine learning instruments","abstract":"Uncontrolled hypertension is a global problem that needs to be addressed. Despite the many mHealth solutions in the market, the nonadherence relative to intended use jeopardizes treatment success. Although investigating user experience is one of the most important mechanisms for understanding mHealth discontinuance, surprisingly, the core determinants of overall user experience (i.e., positive and negative) about mHealth apps for hypertension are unknown. To address the mentioned gap in knowledge, this study adopts the computational grounded theory methodological framework and employs advanced deep learning algorithms to predict core quality criteria that affect overall user experience of hypertension apps published in the Apple App Store. This study contributes to theory and practice of designing evidence-based interventions for hypertension in the form of propositions and provide valuable managerial implications and recommendations for manufacturers.","sentences":["Uncontrolled hypertension is a global problem that needs to be addressed.","Despite the many mHealth solutions in the market, the nonadherence relative to intended use jeopardizes treatment success.","Although investigating user experience is one of the most important mechanisms for understanding mHealth discontinuance, surprisingly, the core determinants of overall user experience (i.e., positive and negative) about mHealth apps for hypertension are unknown.","To address the mentioned gap in knowledge, this study adopts the computational grounded theory methodological framework and employs advanced deep learning algorithms to predict core quality criteria that affect overall user experience of hypertension apps published in the Apple App Store.","This study contributes to theory and practice of designing evidence-based interventions for hypertension in the form of propositions and provide valuable managerial implications and recommendations for manufacturers."],"url":"http://arxiv.org/abs/2311.05434v1"}
{"created":"2023-11-09 15:17:35","title":"Dual Pipeline Style Transfer with Input Distribution Differentiation","abstract":"The color and texture dual pipeline architecture (CTDP) suppresses texture representation and artifacts through masked total variation loss (Mtv), and further experiments have shown that smooth input can almost completely eliminate texture representation. We have demonstrated through experiments that smooth input is not the key reason for removing texture representations, but rather the distribution differentiation of the training dataset. Based on this, we propose an input distribution differentiation training strategy (IDD), which forces the generation of textures to be completely dependent on the noise distribution, while the smooth distribution will not produce textures at all. Overall, our proposed distribution differentiation training strategy allows for two pre-defined input distributions to be responsible for two generation tasks, with noise distribution responsible for texture generation and smooth distribution responsible for color smooth transfer. Finally, we choose a smooth distribution as the input for the forward inference stage to completely eliminate texture representations and artifacts in color transfer tasks.","sentences":["The color and texture dual pipeline architecture (CTDP) suppresses texture representation and artifacts through masked total variation loss (Mtv), and further experiments have shown that smooth input can almost completely eliminate texture representation.","We have demonstrated through experiments that smooth input is not the key reason for removing texture representations, but rather the distribution differentiation of the training dataset.","Based on this, we propose an input distribution differentiation training strategy (IDD), which forces the generation of textures to be completely dependent on the noise distribution, while the smooth distribution will not produce textures at all.","Overall, our proposed distribution differentiation training strategy allows for two pre-defined input distributions to be responsible for two generation tasks, with noise distribution responsible for texture generation and smooth distribution responsible for color smooth transfer.","Finally, we choose a smooth distribution as the input for the forward inference stage to completely eliminate texture representations and artifacts in color transfer tasks."],"url":"http://arxiv.org/abs/2311.05432v1"}
{"created":"2023-11-09 15:14:08","title":"Taxonomy for Resident Space Objects in LEO: A Deep Learning Approach","abstract":"The increasing number of RSOs has raised concerns about the risk of collisions and catastrophic incidents for all direct and indirect users of space. To mitigate this issue, it is essential to have a good understanding of the various RSOs in orbit and their behaviour. A well-established taxonomy defining several classes of RSOs is a critical step in achieving this understanding. This taxonomy helps assign objects to specific categories based on their main characteristics, leading to better tracking services. Furthermore, a well-established taxonomy can facilitate research and analysis processes by providing a common language and framework for better understanding the factors that influence RSO behaviour in space. These factors, in turn, help design more efficient and effective strategies for space traffic management. Our work proposes a new taxonomy for RSOs focusing on the low Earth orbit regime to enhance space traffic management. In addition, we present a deep learning-based model that uses an autoencoder architecture to reduce the features representing the characteristics of the RSOs. The autoencoder generates a lower-dimensional space representation that is then explored using techniques such as Uniform Manifold Approximation and Projection to identify fundamental clusters of RSOs based on their unique characteristics. This approach captures the complex and non-linear relationships between the features and the RSOs' classes identified. Our proposed taxonomy and model offer a significant contribution to the ongoing efforts to mitigate the overall risks posed by the increasing number of RSOs in orbit.","sentences":["The increasing number of RSOs has raised concerns about the risk of collisions and catastrophic incidents for all direct and indirect users of space.","To mitigate this issue, it is essential to have a good understanding of the various RSOs in orbit and their behaviour.","A well-established taxonomy defining several classes of RSOs is a critical step in achieving this understanding.","This taxonomy helps assign objects to specific categories based on their main characteristics, leading to better tracking services.","Furthermore, a well-established taxonomy can facilitate research and analysis processes by providing a common language and framework for better understanding the factors that influence RSO behaviour in space.","These factors, in turn, help design more efficient and effective strategies for space traffic management.","Our work proposes a new taxonomy for RSOs focusing on the low Earth orbit regime to enhance space traffic management.","In addition, we present a deep learning-based model that uses an autoencoder architecture to reduce the features representing the characteristics of the RSOs.","The autoencoder generates a lower-dimensional space representation that is then explored using techniques such as Uniform Manifold Approximation and Projection to identify fundamental clusters of RSOs based on their unique characteristics.","This approach captures the complex and non-linear relationships between the features and the RSOs' classes identified.","Our proposed taxonomy and model offer a significant contribution to the ongoing efforts to mitigate the overall risks posed by the increasing number of RSOs in orbit."],"url":"http://arxiv.org/abs/2311.05430v1"}
{"created":"2023-11-09 15:04:14","title":"Statistical Learning of Conjunction Data Messages Through a Bayesian Non-Homogeneous Poisson Process","abstract":"Current approaches for collision avoidance and space traffic management face many challenges, mainly due to the continuous increase in the number of objects in orbit and the lack of scalable and automated solutions. To avoid catastrophic incidents, satellite owners/operators must be aware of their assets' collision risk to decide whether a collision avoidance manoeuvre needs to be performed. This process is typically executed through the use of warnings issued in the form of CDMs which contain information about the event, such as the expected TCA and the probability of collision. Our previous work presented a statistical learning model that allowed us to answer two important questions: (1) Will any new conjunctions be issued in the next specified time interval? (2) When and with what uncertainty will the next CDM arrive? However, the model was based on an empirical Bayes homogeneous Poisson process, which assumes that the arrival rates of CDMs are constant over time. In fact, the rate at which the CDMs are issued depends on the behaviour of the objects as well as on the screening process performed by third parties. Thus, in this work, we extend the previous study and propose a Bayesian non-homogeneous Poisson process implemented with high precision using a Probabilistic Programming Language to fully describe the underlying phenomena. We compare the proposed solution with a baseline model to demonstrate the added value of our approach. The results show that this problem can be successfully modelled by our Bayesian non-homogeneous Poisson Process with greater accuracy, contributing to the development of automated collision avoidance systems and helping operators react timely but sparingly with satellite manoeuvres.","sentences":["Current approaches for collision avoidance and space traffic management face many challenges, mainly due to the continuous increase in the number of objects in orbit and the lack of scalable and automated solutions.","To avoid catastrophic incidents, satellite owners/operators must be aware of their assets' collision risk to decide whether a collision avoidance manoeuvre needs to be performed.","This process is typically executed through the use of warnings issued in the form of CDMs which contain information about the event, such as the expected TCA and the probability of collision.","Our previous work presented a statistical learning model that allowed us to answer two important questions: (1) Will any new conjunctions be issued in the next specified time interval?","(2) When and with what uncertainty will the next CDM arrive?","However, the model was based on an empirical Bayes homogeneous Poisson process, which assumes that the arrival rates of CDMs are constant over time.","In fact, the rate at which the CDMs are issued depends on the behaviour of the objects as well as on the screening process performed by third parties.","Thus, in this work, we extend the previous study and propose a Bayesian non-homogeneous Poisson process implemented with high precision using a Probabilistic Programming Language to fully describe the underlying phenomena.","We compare the proposed solution with a baseline model to demonstrate the added value of our approach.","The results show that this problem can be successfully modelled by our Bayesian non-homogeneous Poisson Process with greater accuracy, contributing to the development of automated collision avoidance systems and helping operators react timely but sparingly with satellite manoeuvres."],"url":"http://arxiv.org/abs/2311.05426v1"}
{"created":"2023-11-09 15:03:57","title":"Active Mining Sample Pair Semantics for Image-text Matching","abstract":"Recently, commonsense learning has been a hot topic in image-text matching. Although it can describe more graphic correlations, commonsense learning still has some shortcomings: 1) The existing methods are based on triplet semantic similarity measurement loss, which cannot effectively match the intractable negative in image-text sample pairs. 2) The weak generalization ability of the model leads to the poor effect of image and text matching on large-scale datasets. According to these shortcomings. This paper proposes a novel image-text matching model, called Active Mining Sample Pair Semantics image-text matching model (AMSPS). Compared with the single semantic learning mode of the commonsense learning model with triplet loss function, AMSPS is an active learning idea. Firstly, the proposed Adaptive Hierarchical Reinforcement Loss (AHRL) has diversified learning modes. Its active learning mode enables the model to more focus on the intractable negative samples to enhance the discriminating ability. In addition, AMSPS can also adaptively mine more hidden relevant semantic representations from uncommented items, which greatly improves the performance and generalization ability of the model. Experimental results on Flickr30K and MSCOCO universal datasets show that our proposed method is superior to advanced comparison methods.","sentences":["Recently, commonsense learning has been a hot topic in image-text matching.","Although it can describe more graphic correlations, commonsense learning still has some shortcomings: 1) The existing methods are based on triplet semantic similarity measurement loss, which cannot effectively match the intractable negative in image-text sample pairs.","2) The weak generalization ability of the model leads to the poor effect of image and text matching on large-scale datasets.","According to these shortcomings.","This paper proposes a novel image-text matching model, called Active Mining Sample Pair Semantics image-text matching model (AMSPS).","Compared with the single semantic learning mode of the commonsense learning model with triplet loss function, AMSPS is an active learning idea.","Firstly, the proposed Adaptive Hierarchical Reinforcement Loss (AHRL) has diversified learning modes.","Its active learning mode enables the model to more focus on the intractable negative samples to enhance the discriminating ability.","In addition, AMSPS can also adaptively mine more hidden relevant semantic representations from uncommented items, which greatly improves the performance and generalization ability of the model.","Experimental results on Flickr30K and MSCOCO universal datasets show that our proposed method is superior to advanced comparison methods."],"url":"http://arxiv.org/abs/2311.05425v1"}
{"created":"2023-11-09 15:02:50","title":"ESPORT: Electronic Sports Professionals Observations and Reflections on Training","abstract":"Esports and high performance human-computer interaction are on the forefront of applying new hardware and software technologies in practice. Despite that, there is a paucity of research on how semi-professional and professional championship level players approach aspects of their preparation.   To address that, we have performed, transcribed, and analyzed interviews with top-tournament players, coaches, and managers across multiple game titles. The interviews range from competitive events occuring between 2015-2020. Initial processing included transcription and manual verification. The pre-processed interview data were then organized and structured into relevant categories, touching on psychological, physical, and nutritional aspects of esports preparation. Further, where applicable, interview responses where rated and quantified via consensus judgement by a panel of experts.   The results indicate that physical training was most often mentioned as a relevant or consistent activity, while nutrition was indicated as relatively unimportant. Qualitative analysis also indicated that consistency and resiliency were noted as the most key factors recommended for upcoming esports competitors. It is also clear that many players put emphasis on balancing their gameplay time and with activities. Lastly, we identified important areas of inquiry towards a deeper understanding of the mental and physical demands of professional esports players.","sentences":["Esports and high performance human-computer interaction are on the forefront of applying new hardware and software technologies in practice.","Despite that, there is a paucity of research on how semi-professional and professional championship level players approach aspects of their preparation.   ","To address that, we have performed, transcribed, and analyzed interviews with top-tournament players, coaches, and managers across multiple game titles.","The interviews range from competitive events occuring between 2015-2020.","Initial processing included transcription and manual verification.","The pre-processed interview data were then organized and structured into relevant categories, touching on psychological, physical, and nutritional aspects of esports preparation.","Further, where applicable, interview responses where rated and quantified via consensus judgement by a panel of experts.   ","The results indicate that physical training was most often mentioned as a relevant or consistent activity, while nutrition was indicated as relatively unimportant.","Qualitative analysis also indicated that consistency and resiliency were noted as the most key factors recommended for upcoming esports competitors.","It is also clear that many players put emphasis on balancing their gameplay time and with activities.","Lastly, we identified important areas of inquiry towards a deeper understanding of the mental and physical demands of professional esports players."],"url":"http://arxiv.org/abs/2311.05424v1"}
{"created":"2023-11-09 14:59:26","title":"Diffusion Based Causal Representation Learning","abstract":"Causal reasoning can be considered a cornerstone of intelligent systems. Having access to an underlying causal graph comes with the promise of cause-effect estimation and the identification of efficient and safe interventions. However, learning causal representations remains a major challenge, due to the complexity of many real-world systems. Previous works on causal representation learning have mostly focused on Variational Auto-Encoders (VAE). These methods only provide representations from a point estimate, and they are unsuitable to handle high dimensions. To overcome these problems, we proposed a new Diffusion-based Causal Representation Learning (DCRL) algorithm. This algorithm uses diffusion-based representations for causal discovery. DCRL offers access to infinite dimensional latent codes, which encode different levels of information in the latent code. In a first proof of principle, we investigate the use of DCRL for causal representation learning. We further demonstrate experimentally that this approach performs comparably well in identifying the causal structure and causal variables.","sentences":["Causal reasoning can be considered a cornerstone of intelligent systems.","Having access to an underlying causal graph comes with the promise of cause-effect estimation and the identification of efficient and safe interventions.","However, learning causal representations remains a major challenge, due to the complexity of many real-world systems.","Previous works on causal representation learning have mostly focused on Variational Auto-Encoders (VAE).","These methods only provide representations from a point estimate, and they are unsuitable to handle high dimensions.","To overcome these problems, we proposed a new Diffusion-based Causal Representation Learning (DCRL) algorithm.","This algorithm uses diffusion-based representations for causal discovery.","DCRL offers access to infinite dimensional latent codes, which encode different levels of information in the latent code.","In a first proof of principle, we investigate the use of DCRL for causal representation learning.","We further demonstrate experimentally that this approach performs comparably well in identifying the causal structure and causal variables."],"url":"http://arxiv.org/abs/2311.05421v1"}
{"created":"2023-11-09 14:58:53","title":"Counterfactually Fair Representation","abstract":"The use of machine learning models in high-stake applications (e.g., healthcare, lending, college admission) has raised growing concerns due to potential biases against protected social groups. Various fairness notions and methods have been proposed to mitigate such biases. In this work, we focus on Counterfactual Fairness (CF), a fairness notion that is dependent on an underlying causal graph and first proposed by Kusner \\textit{et al.}~\\cite{kusner2017counterfactual}; it requires that the outcome an individual perceives is the same in the real world as it would be in a \"counterfactual\" world, in which the individual belongs to another social group. Learning fair models satisfying CF can be challenging. It was shown in \\cite{kusner2017counterfactual} that a sufficient condition for satisfying CF is to \\textbf{not} use features that are descendants of sensitive attributes in the causal graph. This implies a simple method that learns CF models only using non-descendants of sensitive attributes while eliminating all descendants. Although several subsequent works proposed methods that use all features for training CF models, there is no theoretical guarantee that they can satisfy CF. In contrast, this work proposes a new algorithm that trains models using all the available features. We theoretically and empirically show that models trained with this method can satisfy CF\\footnote{The code repository for this work can be found in \\url{https://github.com/osu-srml/CF_Representation_Learning}}.","sentences":["The use of machine learning models in high-stake applications (e.g., healthcare, lending, college admission) has raised growing concerns due to potential biases against protected social groups.","Various fairness notions and methods have been proposed to mitigate such biases.","In this work, we focus on Counterfactual Fairness (CF), a fairness notion that is dependent on an underlying causal graph and first proposed by Kusner \\textit{et al.}~\\cite{kusner2017counterfactual}; it requires that the outcome an individual perceives is the same in the real world as it would be in a \"counterfactual\" world, in which the individual belongs to another social group.","Learning fair models satisfying CF can be challenging.","It was shown in \\cite{kusner2017counterfactual} that a sufficient condition for satisfying CF is to \\textbf{not} use features that are descendants of sensitive attributes in the causal graph.","This implies a simple method that learns CF models only using non-descendants of sensitive attributes while eliminating all descendants.","Although several subsequent works proposed methods that use all features for training CF models, there is no theoretical guarantee that they can satisfy CF.","In contrast, this work proposes a new algorithm that trains models using all the available features.","We theoretically and empirically show that models trained with this method can satisfy CF\\footnote{The code repository for this work can be found in \\url{https://github.com/osu-srml/CF_Representation_Learning}}."],"url":"http://arxiv.org/abs/2311.05420v1"}
{"created":"2023-11-09 14:58:46","title":"Mirror: A Universal Framework for Various Information Extraction Tasks","abstract":"Sharing knowledge between information extraction tasks has always been a challenge due to the diverse data formats and task variations. Meanwhile, this divergence leads to information waste and increases difficulties in building complex applications in real scenarios. Recent studies often formulate IE tasks as a triplet extraction problem. However, such a paradigm does not support multi-span and n-ary extraction, leading to weak versatility. To this end, we reorganize IE problems into unified multi-slot tuples and propose a universal framework for various IE tasks, namely Mirror. Specifically, we recast existing IE tasks as a multi-span cyclic graph extraction problem and devise a non-autoregressive graph decoding algorithm to extract all spans in a single step. It is worth noting that this graph structure is incredibly versatile, and it supports not only complex IE tasks, but also machine reading comprehension and classification tasks. We manually construct a corpus containing 57 datasets for model pretraining, and conduct experiments on 30 datasets across 8 downstream tasks. The experimental results demonstrate that our model has decent compatibility and outperforms or reaches competitive performance with SOTA systems under few-shot and zero-shot settings. The code, model weights, and pretraining corpus are available at https://github.com/Spico197/Mirror .","sentences":["Sharing knowledge between information extraction tasks has always been a challenge due to the diverse data formats and task variations.","Meanwhile, this divergence leads to information waste and increases difficulties in building complex applications in real scenarios.","Recent studies often formulate IE tasks as a triplet extraction problem.","However, such a paradigm does not support multi-span and n-ary extraction, leading to weak versatility.","To this end, we reorganize IE problems into unified multi-slot tuples and propose a universal framework for various IE tasks, namely Mirror.","Specifically, we recast existing IE tasks as a multi-span cyclic graph extraction problem and devise a non-autoregressive graph decoding algorithm to extract all spans in a single step.","It is worth noting that this graph structure is incredibly versatile, and it supports not only complex IE tasks, but also machine reading comprehension and classification tasks.","We manually construct a corpus containing 57 datasets for model pretraining, and conduct experiments on 30 datasets across 8 downstream tasks.","The experimental results demonstrate that our model has decent compatibility and outperforms or reaches competitive performance with SOTA systems under few-shot and zero-shot settings.","The code, model weights, and pretraining corpus are available at https://github.com/Spico197/Mirror ."],"url":"http://arxiv.org/abs/2311.05419v1"}
{"created":"2023-11-09 14:54:28","title":"Generalization in medical AI: a perspective on developing scalable models","abstract":"Over the past few years, research has witnessed the advancement of deep learning models trained on large datasets, some even encompassing millions of examples. While these impressive performance on their hidden test sets, they often underperform when assessed on external datasets. Recognizing the critical role of generalization in medical AI development, many prestigious journals now require reporting results both on the local hidden test set as well as on external datasets before considering a study for publication. Effectively, the field of medical AI has transitioned from the traditional usage of a single dataset that is split into train and test to a more comprehensive framework using multiple datasets, some of which are used for model development (source domain) and others for testing (target domains). However, this new experimental setting does not necessarily resolve the challenge of generalization. This is because of the variability encountered in intended use and specificities across hospital cultures making the idea of universally generalizable systems a myth. On the other hand, the systematic, and a fortiori recurrent re-calibration, of models at the individual hospital level, although ideal, may be overoptimistic given the legal, regulatory and technical challenges that are involved. Re-calibration using transfer learning may not even be possible in some instances where reference labels of target domains are not available. In this perspective we establish a hierarchical three-level scale system reflecting the generalization level of a medical AI algorithm. This scale better reflects the diversity of real-world medical scenarios per which target domain data for re-calibration of models may or not be available and if it is, may or not have reference labels systematically available.","sentences":["Over the past few years, research has witnessed the advancement of deep learning models trained on large datasets, some even encompassing millions of examples.","While these impressive performance on their hidden test sets, they often underperform when assessed on external datasets.","Recognizing the critical role of generalization in medical AI development, many prestigious journals now require reporting results both on the local hidden test set as well as on external datasets before considering a study for publication.","Effectively, the field of medical AI has transitioned from the traditional usage of a single dataset that is split into train and test to a more comprehensive framework using multiple datasets, some of which are used for model development (source domain) and others for testing (target domains).","However, this new experimental setting does not necessarily resolve the challenge of generalization.","This is because of the variability encountered in intended use and specificities across hospital cultures making the idea of universally generalizable systems a myth.","On the other hand, the systematic, and a fortiori recurrent re-calibration, of models at the individual hospital level, although ideal, may be overoptimistic given the legal, regulatory and technical challenges that are involved.","Re-calibration using transfer learning may not even be possible in some instances where reference labels of target domains are not available.","In this perspective we establish a hierarchical three-level scale system reflecting the generalization level of a medical AI algorithm.","This scale better reflects the diversity of real-world medical scenarios per which target domain data for re-calibration of models may or not be available and if it is, may or not have reference labels systematically available."],"url":"http://arxiv.org/abs/2311.05418v1"}
{"created":"2023-11-09 14:54:08","title":"Predicting the Position Uncertainty at the Time of Closest Approach with Diffusion Models","abstract":"The risk of collision between resident space objects has significantly increased in recent years. As a result, spacecraft collision avoidance procedures have become an essential part of satellite operations. To ensure safe and effective space activities, satellite owners and operators rely on constantly updated estimates of encounters. These estimates include the uncertainty associated with the position of each object at the expected TCA. These estimates are crucial in planning risk mitigation measures, such as collision avoidance manoeuvres. As the TCA approaches, the accuracy of these estimates improves, as both objects' orbit determination and propagation procedures are made for increasingly shorter time intervals. However, this improvement comes at the cost of taking place close to the critical decision moment. This means that safe avoidance manoeuvres might not be possible or could incur significant costs. Therefore, knowing the evolution of this variable in advance can be crucial for operators. This work proposes a machine learning model based on diffusion models to forecast the position uncertainty of objects involved in a close encounter, particularly for the secondary object (usually debris), which tends to be more unpredictable. We compare the performance of our model with other state-of-the-art solutions and a na\\\"ive baseline approach, showing that the proposed solution has the potential to significantly improve the safety and effectiveness of spacecraft operations.","sentences":["The risk of collision between resident space objects has significantly increased in recent years.","As a result, spacecraft collision avoidance procedures have become an essential part of satellite operations.","To ensure safe and effective space activities, satellite owners and operators rely on constantly updated estimates of encounters.","These estimates include the uncertainty associated with the position of each object at the expected TCA.","These estimates are crucial in planning risk mitigation measures, such as collision avoidance manoeuvres.","As the TCA approaches, the accuracy of these estimates improves, as both objects' orbit determination and propagation procedures are made for increasingly shorter time intervals.","However, this improvement comes at the cost of taking place close to the critical decision moment.","This means that safe avoidance manoeuvres might not be possible or could incur significant costs.","Therefore, knowing the evolution of this variable in advance can be crucial for operators.","This work proposes a machine learning model based on diffusion models to forecast the position uncertainty of objects involved in a close encounter, particularly for the secondary object (usually debris), which tends to be more unpredictable.","We compare the performance of our model with other state-of-the-art solutions and a na\\\"ive baseline approach, showing that the proposed solution has the potential to significantly improve the safety and effectiveness of spacecraft operations."],"url":"http://arxiv.org/abs/2311.05417v1"}
{"created":"2023-11-09 14:45:22","title":"Linear Gaussian Bounding Box Representation and Ring-Shaped Rotated Convolution for Oriented Object Detection","abstract":"Due to the frequent variability of object orientation, accurate prediction of orientation information remains a challenge in oriented object detection. To better extract orientation-related information, current methods primarily focus on the design of reasonable representations of oriented bounding box (OBB) and rotation-sensitive feature extraction. However, existing OBB representations often suffer from boundary discontinuity and representation ambiguity problems. Methods of designing continuous and unambiguous regression losses do not essentially solve such problems. Gaussian bounding box (GBB) avoids these OBB representation problems, but directly regressing GBB is susceptible to numerical instability. In this paper, we propose linear GBB (LGBB), a novel OBB representation. By linearly transforming the elements of GBB, LGBB does not have the boundary discontinuity and representation ambiguity problems, and have high numerical stability. On the other hand, current rotation-sensitive feature extraction methods based on convolutions can only extract features under a local receptive field, which is slow in aggregating rotation-sensitive features. To address this issue, we propose ring-shaped rotated convolution (RRC). By adaptively rotating feature maps to arbitrary orientations, RRC extracts rotation-sensitive features under a ring-shaped receptive field, rapidly aggregating rotation-sensitive features and contextual information. RRC can be applied to various models in a plug-and-play manner. Experimental results demonstrate that the proposed LGBB and RRC are effective and achieve state-of-the-art (SOTA) performance. By integrating LGBB and RRC into various models, the detection accuracy is effectively improved on DOTA and HRSC2016 datasets.","sentences":["Due to the frequent variability of object orientation, accurate prediction of orientation information remains a challenge in oriented object detection.","To better extract orientation-related information, current methods primarily focus on the design of reasonable representations of oriented bounding box (OBB) and rotation-sensitive feature extraction.","However, existing OBB representations often suffer from boundary discontinuity and representation ambiguity problems.","Methods of designing continuous and unambiguous regression losses do not essentially solve such problems.","Gaussian bounding box (GBB) avoids these OBB representation problems, but directly regressing GBB is susceptible to numerical instability.","In this paper, we propose linear GBB (LGBB), a novel OBB representation.","By linearly transforming the elements of GBB, LGBB does not have the boundary discontinuity and representation ambiguity problems, and have high numerical stability.","On the other hand, current rotation-sensitive feature extraction methods based on convolutions can only extract features under a local receptive field, which is slow in aggregating rotation-sensitive features.","To address this issue, we propose ring-shaped rotated convolution (RRC).","By adaptively rotating feature maps to arbitrary orientations, RRC extracts rotation-sensitive features under a ring-shaped receptive field, rapidly aggregating rotation-sensitive features and contextual information.","RRC can be applied to various models in a plug-and-play manner.","Experimental results demonstrate that the proposed LGBB and RRC are effective and achieve state-of-the-art (SOTA) performance.","By integrating LGBB and RRC into various models, the detection accuracy is effectively improved on DOTA and HRSC2016 datasets."],"url":"http://arxiv.org/abs/2311.05410v1"}
