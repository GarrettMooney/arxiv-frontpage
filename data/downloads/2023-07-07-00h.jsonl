{"created":"2023-07-05 17:59:38","title":"LongNet: Scaling Transformers to 1,000,000,000 Tokens","abstract":"Scaling sequence length has become a critical demand in the era of large language models. However, existing methods struggle with either computational complexity or model expressivity, rendering the maximum sequence length restricted. In this work, we introduce LongNet, a Transformer variant that can scale sequence length to more than 1 billion tokens, without sacrificing the performance on shorter sequences. Specifically, we propose dilated attention, which expands the attentive field exponentially as the distance grows. LongNet has significant advantages: 1) it has a linear computation complexity and a logarithm dependency between tokens; 2) it can be served as a distributed trainer for extremely long sequences; 3) its dilated attention is a drop-in replacement for standard attention, which can be seamlessly integrated with the existing Transformer-based optimization. Experiments results demonstrate that LongNet yields strong performance on both long-sequence modeling and general language tasks. Our work opens up new possibilities for modeling very long sequences, e.g., treating a whole corpus or even the entire Internet as a sequence.","sentences":["Scaling sequence length has become a critical demand in the era of large language models.","However, existing methods struggle with either computational complexity or model expressivity, rendering the maximum sequence length restricted.","In this work, we introduce LongNet, a Transformer variant that can scale sequence length to more than 1 billion tokens, without sacrificing the performance on shorter sequences.","Specifically, we propose dilated attention, which expands the attentive field exponentially as the distance grows.","LongNet has significant advantages: 1) it has a linear computation complexity and a logarithm dependency between tokens; 2) it can be served as a distributed trainer for extremely long sequences; 3) its dilated attention is a drop-in replacement for standard attention, which can be seamlessly integrated with the existing Transformer-based optimization.","Experiments results demonstrate that LongNet yields strong performance on both long-sequence modeling and general language tasks.","Our work opens up new possibilities for modeling very long sequences, e.g., treating a whole corpus or even the entire Internet as a sequence."],"url":"http://arxiv.org/abs/2307.02486v1"}
{"created":"2023-07-05 17:59:27","title":"Building Cooperative Embodied Agents Modularly with Large Language Models","abstract":"Large Language Models (LLMs) have demonstrated impressive planning abilities in single-agent embodied tasks across various domains. However, their capacity for planning and communication in multi-agent cooperation remains unclear, even though these are crucial skills for intelligent embodied agents. In this paper, we present a novel framework that utilizes LLMs for multi-agent cooperation and tests it in various embodied environments. Our framework enables embodied agents to plan, communicate, and cooperate with other embodied agents or humans to accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs, such as GPT-4, can surpass strong planning-based methods and exhibit emergent effective communication using our framework without requiring fine-tuning or few-shot prompting. We also discover that LLM-based agents that communicate in natural language can earn more trust and cooperate more effectively with humans. Our research underscores the potential of LLMs for embodied AI and lays the foundation for future research in multi-agent cooperation. Videos can be found on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.","sentences":["Large Language Models (LLMs) have demonstrated impressive planning abilities in single-agent embodied tasks across various domains.","However, their capacity for planning and communication in multi-agent cooperation remains unclear, even though these are crucial skills for intelligent embodied agents.","In this paper, we present a novel framework that utilizes LLMs for multi-agent cooperation and tests it in various embodied environments.","Our framework enables embodied agents to plan, communicate, and cooperate with other embodied agents or humans to accomplish long-horizon tasks efficiently.","We demonstrate that recent LLMs, such as GPT-4, can surpass strong planning-based methods and exhibit emergent effective communication using our framework without requiring fine-tuning or few-shot prompting.","We also discover that LLM-based agents that communicate in natural language can earn more trust and cooperate more effectively with humans.","Our research underscores the potential of LLMs for embodied AI and lays the foundation for future research in multi-agent cooperation.","Videos can be found on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/."],"url":"http://arxiv.org/abs/2307.02485v1"}
{"created":"2023-07-05 17:58:21","title":"Elastic Decision Transformer","abstract":"This paper introduces Elastic Decision Transformer (EDT), a significant advancement over the existing Decision Transformer (DT) and its variants. Although DT purports to generate an optimal trajectory, empirical evidence suggests it struggles with trajectory stitching, a process involving the generation of an optimal or near-optimal trajectory from the best parts of a set of sub-optimal trajectories. The proposed EDT differentiates itself by facilitating trajectory stitching during action inference at test time, achieved by adjusting the history length maintained in DT. Further, the EDT optimizes the trajectory by retaining a longer history when the previous trajectory is optimal and a shorter one when it is sub-optimal, enabling it to \"stitch\" with a more optimal trajectory. Extensive experimentation demonstrates EDT's ability to bridge the performance gap between DT-based and Q Learning-based approaches. In particular, the EDT outperforms Q Learning-based methods in a multi-task regime on the D4RL locomotion benchmark and Atari games. Videos are available at: https://kristery.github.io/edt/","sentences":["This paper introduces Elastic Decision Transformer (EDT), a significant advancement over the existing Decision Transformer (DT) and its variants.","Although DT purports to generate an optimal trajectory, empirical evidence suggests it struggles with trajectory stitching, a process involving the generation of an optimal or near-optimal trajectory from the best parts of a set of sub-optimal trajectories.","The proposed EDT differentiates itself by facilitating trajectory stitching during action inference at test time, achieved by adjusting the history length maintained in DT.","Further, the EDT optimizes the trajectory by retaining a longer history when the previous trajectory is optimal and a shorter one when it is sub-optimal, enabling it to \"stitch\" with a more optimal trajectory.","Extensive experimentation demonstrates EDT's ability to bridge the performance gap between DT-based and Q Learning-based approaches.","In particular, the EDT outperforms Q Learning-based methods in a multi-task regime on the D4RL locomotion benchmark and Atari games.","Videos are available at: https://kristery.github.io/edt/"],"url":"http://arxiv.org/abs/2307.02484v1"}
{"created":"2023-07-05 17:58:10","title":"Jailbroken: How Does LLM Safety Training Fail?","abstract":"Large language models trained for safety and harmlessness remain susceptible to adversarial misuse, as evidenced by the prevalence of \"jailbreak\" attacks on early releases of ChatGPT that elicit undesired behavior. Going beyond recognition of the issue, we investigate why such attacks succeed and how they can be created. We hypothesize two failure modes of safety training: competing objectives and mismatched generalization. Competing objectives arise when a model's capabilities and safety goals conflict, while mismatched generalization occurs when safety training fails to generalize to a domain for which capabilities exist. We use these failure modes to guide jailbreak design and then evaluate state-of-the-art models, including OpenAI's GPT-4 and Anthropic's Claude v1.3, against both existing and newly designed attacks. We find that vulnerabilities persist despite the extensive red-teaming and safety-training efforts behind these models. Notably, new attacks utilizing our failure modes succeed on every prompt in a collection of unsafe requests from the models' red-teaming evaluation sets and outperform existing ad hoc jailbreaks. Our analysis emphasizes the need for safety-capability parity -- that safety mechanisms should be as sophisticated as the underlying model -- and argues against the idea that scaling alone can resolve these safety failure modes.","sentences":["Large language models trained for safety and harmlessness remain susceptible to adversarial misuse, as evidenced by the prevalence of \"jailbreak\" attacks on early releases of ChatGPT that elicit undesired behavior.","Going beyond recognition of the issue, we investigate why such attacks succeed and how they can be created.","We hypothesize two failure modes of safety training: competing objectives and mismatched generalization.","Competing objectives arise when a model's capabilities and safety goals conflict, while mismatched generalization occurs when safety training fails to generalize to a domain for which capabilities exist.","We use these failure modes to guide jailbreak design and then evaluate state-of-the-art models, including OpenAI's GPT-4 and Anthropic's Claude v1.3, against both existing and newly designed attacks.","We find that vulnerabilities persist despite the extensive red-teaming and safety-training efforts behind these models.","Notably, new attacks utilizing our failure modes succeed on every prompt in a collection of unsafe requests from the models' red-teaming evaluation sets and outperform existing ad hoc jailbreaks.","Our analysis emphasizes the need for safety-capability parity -- that safety mechanisms should be as sophisticated as the underlying model -- and argues against the idea that scaling alone can resolve these safety failure modes."],"url":"http://arxiv.org/abs/2307.02483v1"}
{"created":"2023-07-05 17:54:36","title":"A Dataset of Inertial Measurement Units for Handwritten English Alphabets","abstract":"This paper presents an end-to-end methodology for collecting datasets to recognize handwritten English alphabets by utilizing Inertial Measurement Units (IMUs) and leveraging the diversity present in the Indian writing style. The IMUs are utilized to capture the dynamic movement patterns associated with handwriting, enabling more accurate recognition of alphabets. The Indian context introduces various challenges due to the heterogeneity in writing styles across different regions and languages. By leveraging this diversity, the collected dataset and the collection system aim to achieve higher recognition accuracy. Some preliminary experimental results demonstrate the effectiveness of the dataset in accurately recognizing handwritten English alphabet in the Indian context. This research can be extended and contributes to the field of pattern recognition and offers valuable insights for developing improved systems for handwriting recognition, particularly in diverse linguistic and cultural contexts.","sentences":["This paper presents an end-to-end methodology for collecting datasets to recognize handwritten English alphabets by utilizing Inertial Measurement Units (IMUs) and leveraging the diversity present in the Indian writing style.","The IMUs are utilized to capture the dynamic movement patterns associated with handwriting, enabling more accurate recognition of alphabets.","The Indian context introduces various challenges due to the heterogeneity in writing styles across different regions and languages.","By leveraging this diversity, the collected dataset and the collection system aim to achieve higher recognition accuracy.","Some preliminary experimental results demonstrate the effectiveness of the dataset in accurately recognizing handwritten English alphabet in the Indian context.","This research can be extended and contributes to the field of pattern recognition and offers valuable insights for developing improved systems for handwriting recognition, particularly in diverse linguistic and cultural contexts."],"url":"http://arxiv.org/abs/2307.02480v1"}
{"created":"2023-07-05 17:51:26","title":"Linear Regression on Manifold Structured Data: the Impact of Extrinsic Geometry on Solutions","abstract":"In this paper, we study linear regression applied to data structured on a manifold. We assume that the data manifold is smooth and is embedded in a Euclidean space, and our objective is to reveal the impact of the data manifold's extrinsic geometry on the regression. Specifically, we analyze the impact of the manifold's curvatures (or higher order nonlinearity in the parameterization when the curvatures are locally zero) on the uniqueness of the regression solution. Our findings suggest that the corresponding linear regression does not have a unique solution when the embedded submanifold is flat in some dimensions. Otherwise, the manifold's curvature (or higher order nonlinearity in the embedding) may contribute significantly, particularly in the solution associated with the normal directions of the manifold. Our findings thus reveal the role of data manifold geometry in ensuring the stability of regression models for out-of-distribution inferences.","sentences":["In this paper, we study linear regression applied to data structured on a manifold.","We assume that the data manifold is smooth and is embedded in a Euclidean space, and our objective is to reveal the impact of the data manifold's extrinsic geometry on the regression.","Specifically, we analyze the impact of the manifold's curvatures (or higher order nonlinearity in the parameterization when the curvatures are locally zero) on the uniqueness of the regression solution.","Our findings suggest that the corresponding linear regression does not have a unique solution when the embedded submanifold is flat in some dimensions.","Otherwise, the manifold's curvature (or higher order nonlinearity in the embedding) may contribute significantly, particularly in the solution associated with the normal directions of the manifold.","Our findings thus reveal the role of data manifold geometry in ensuring the stability of regression models for out-of-distribution inferences."],"url":"http://arxiv.org/abs/2307.02478v1"}
{"created":"2023-07-05 17:50:42","title":"Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks","abstract":"The impressive performance of recent language models across a wide range of tasks suggests that they possess a degree of abstract reasoning skills. Are these skills general and transferable, or specialized to specific tasks seen during pretraining? To disentangle these effects, we propose an evaluation framework based on \"counterfactual\" task variants that deviate from the default assumptions underlying standard tasks. Across a suite of 11 tasks, we observe nontrivial performance on the counterfactual variants, but nevertheless find that performance substantially and consistently degrades compared to the default conditions. This suggests that while current LMs may possess abstract task-solving skills to a degree, they often also rely on narrow, non-transferable procedures for task-solving. These results motivate a more careful interpretation of language model performance that teases apart these aspects of behavior.","sentences":["The impressive performance of recent language models across a wide range of tasks suggests that they possess a degree of abstract reasoning skills.","Are these skills general and transferable, or specialized to specific tasks seen during pretraining?","To disentangle these effects, we propose an evaluation framework based on \"counterfactual\" task variants that deviate from the default assumptions underlying standard tasks.","Across a suite of 11 tasks, we observe nontrivial performance on the counterfactual variants, but nevertheless find that performance substantially and consistently degrades compared to the default conditions.","This suggests that while current LMs may possess abstract task-solving skills to a degree, they often also rely on narrow, non-transferable procedures for task-solving.","These results motivate a more careful interpretation of language model performance that teases apart these aspects of behavior."],"url":"http://arxiv.org/abs/2307.02477v1"}
{"created":"2023-07-05 17:48:45","title":"The Calissons Puzzle","abstract":"In 2022, Olivier Longuet, a French mathematics teacher, created a game called the \\textit{calissons puzzle}. Given a triangular grid in a hexagon and some given edges of the grid, the problem is to find a calisson tiling such that no input edge is overlapped and calissons adjacent to an input edge have different orientations. We extend the puzzle to regions $R$ that are not necessarily hexagonal. The first interesting property of this puzzle is that, unlike the usual calisson or domino problems, it is solved neither by a maximal matching algorithm, nor by Thurston's algorithm. This raises the question of its complexity.   We prove that if the region $R$ is finite and simply connected, then the puzzle can be solved by an algorithm that we call the \\textit{advancing surface algorithm} and whose complexity is $O(|\\partial R|^3)$ where $\\partial R|$ is the size of the boundary of the region $R$. In the case where the region is the entire infinite triangular grid, we prove that the existence of a solution can be solved with an algorithm of complexity $O(|X|^3)$ where $X$ is the set of input edges. To prove these theorems, we revisit William Thurston's results on the calisson tilability of a region $R$. The solutions involve equivalence between calisson tilings, stepped surfaces and certain DAG cuts that avoid passing through a set of edges that we call \\textit{unbreakable}. It allows us to generalize Thurston's theorem characterizing tilable regions by rewriting it in terms of descending paths or absorbing cycles. Thurston's algorithm appears as a distance calculation algorithm following Dijkstra's paradigm. The introduction of a set $X$ of interior edges introduces negative weights that force a Bellman-Ford strategy to be preferred. These results extend Thurston's legacy by using computer science structures and algorithms.","sentences":["In 2022, Olivier Longuet, a French mathematics teacher, created a game called the \\textit{calissons puzzle}.","Given a triangular grid in a hexagon and some given edges of the grid, the problem is to find a calisson tiling such that no input edge is overlapped and calissons adjacent to an input edge have different orientations.","We extend the puzzle to regions $R$ that are not necessarily hexagonal.","The first interesting property of this puzzle is that, unlike the usual calisson or domino problems, it is solved neither by a maximal matching algorithm, nor by Thurston's algorithm.","This raises the question of its complexity.   ","We prove that if the region $R$ is finite and simply connected, then the puzzle can be solved by an algorithm that we call the \\textit{advancing surface algorithm} and whose complexity is $O(|\\partial R|^3)$ where $\\partial R|$ is the size of the boundary of the region $R$.","In the case where the region is the entire infinite triangular grid, we prove that the existence of a solution can be solved with an algorithm of complexity $O(|X|^3)$ where $X$ is the set of input edges.","To prove these theorems, we revisit William Thurston's results on the calisson tilability of a region $R$.","The solutions involve equivalence between calisson tilings, stepped surfaces and certain DAG cuts that avoid passing through a set of edges that we call \\textit{unbreakable}.","It allows us to generalize Thurston's theorem characterizing tilable regions by rewriting it in terms of descending paths or absorbing cycles.","Thurston's algorithm appears as a distance calculation algorithm following Dijkstra's paradigm.","The introduction of a set $X$ of interior edges introduces negative weights that force a Bellman-Ford strategy to be preferred.","These results extend Thurston's legacy by using computer science structures and algorithms."],"url":"http://arxiv.org/abs/2307.02475v1"}
{"created":"2023-07-05 17:45:48","title":"Deductive Additivity for Planning of Natural Language Proofs","abstract":"Current natural language systems designed for multi-step claim validation typically operate in two phases: retrieve a set of relevant premise statements using heuristics (planning), then generate novel conclusions from those statements using a large language model (deduction). The planning step often requires expensive Transformer operations and does not scale to arbitrary numbers of premise statements. In this paper, we investigate whether an efficient planning heuristic is possible via embedding spaces compatible with deductive reasoning. Specifically, we evaluate whether embedding spaces exhibit a property we call deductive additivity: the sum of premise statement embeddings should be close to embeddings of conclusions based on those premises. We explore multiple sources of off-the-shelf dense embeddings in addition to fine-tuned embeddings from GPT3 and sparse embeddings from BM25. We study embedding models both intrinsically, evaluating whether the property of deductive additivity holds, and extrinsically, using them to assist planning in natural language proof generation. Lastly, we create a dataset, Single-Step Reasoning Contrast (SSRC), to further probe performance on various reasoning types. Our findings suggest that while standard embedding methods frequently embed conclusions near the sums of their premises, they fall short of being effective heuristics and lack the ability to model certain categories of reasoning.","sentences":["Current natural language systems designed for multi-step claim validation typically operate in two phases: retrieve a set of relevant premise statements using heuristics (planning), then generate novel conclusions from those statements using a large language model (deduction).","The planning step often requires expensive Transformer operations and does not scale to arbitrary numbers of premise statements.","In this paper, we investigate whether an efficient planning heuristic is possible via embedding spaces compatible with deductive reasoning.","Specifically, we evaluate whether embedding spaces exhibit a property we call deductive additivity: the sum of premise statement embeddings should be close to embeddings of conclusions based on those premises.","We explore multiple sources of off-the-shelf dense embeddings in addition to fine-tuned embeddings from GPT3 and sparse embeddings from BM25.","We study embedding models both intrinsically, evaluating whether the property of deductive additivity holds, and extrinsically, using them to assist planning in natural language proof generation.","Lastly, we create a dataset, Single-Step Reasoning Contrast (SSRC), to further probe performance on various reasoning types.","Our findings suggest that while standard embedding methods frequently embed conclusions near the sums of their premises, they fall short of being effective heuristics and lack the ability to model certain categories of reasoning."],"url":"http://arxiv.org/abs/2307.02472v2"}
{"created":"2023-07-05 17:44:28","title":"What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?","abstract":"Recent advancements in Large Language Models (LLMs) such as GPT4 have displayed exceptional multi-modal capabilities in following open-ended instructions given images. However, the performance of these models heavily relies on design choices such as network structures, training data, and training strategies, and these choices have not been extensively discussed in the literature, making it difficult to quantify progress in this field. To address this issue, this paper presents a systematic and comprehensive study, quantitatively and qualitatively, on training such models. We implement over 20 variants with controlled settings. Concretely, for network structures, we compare different LLM backbones and model designs. For training data, we investigate the impact of data and sampling strategies. For instructions, we explore the influence of diversified prompts on the instruction-following ability of the trained models. For benchmarks, we contribute the first, to our best knowledge, comprehensive evaluation set including both image and video tasks through crowd-sourcing. Based on our findings, we present Lynx, which performs the most accurate multi-modal understanding while keeping the best multi-modal generation ability compared to existing open-sourced GPT4-style models.","sentences":["Recent advancements in Large Language Models (LLMs) such as GPT4 have displayed exceptional multi-modal capabilities in following open-ended instructions given images.","However, the performance of these models heavily relies on design choices such as network structures, training data, and training strategies, and these choices have not been extensively discussed in the literature, making it difficult to quantify progress in this field.","To address this issue, this paper presents a systematic and comprehensive study, quantitatively and qualitatively, on training such models.","We implement over 20 variants with controlled settings.","Concretely, for network structures, we compare different LLM backbones and model designs.","For training data, we investigate the impact of data and sampling strategies.","For instructions, we explore the influence of diversified prompts on the instruction-following ability of the trained models.","For benchmarks, we contribute the first, to our best knowledge, comprehensive evaluation set including both image and video tasks through crowd-sourcing.","Based on our findings, we present Lynx, which performs the most accurate multi-modal understanding while keeping the best multi-modal generation ability compared to existing open-sourced GPT4-style models."],"url":"http://arxiv.org/abs/2307.02469v1"}
{"created":"2023-07-05 17:38:48","title":"Large-scale Detection of Marine Debris in Coastal Areas with Sentinel-2","abstract":"Detecting and quantifying marine pollution and macro-plastics is an increasingly pressing ecological issue that directly impacts ecology and human health. Efforts to quantify marine pollution are often conducted with sparse and expensive beach surveys, which are difficult to conduct on a large scale. Here, remote sensing can provide reliable estimates of plastic pollution by regularly monitoring and detecting marine debris in coastal areas. Medium-resolution satellite data of coastal areas is readily available and can be leveraged to detect aggregations of marine debris containing plastic litter. In this work, we present a detector for marine debris built on a deep segmentation model that outputs a probability for marine debris at the pixel level. We train this detector with a combination of annotated datasets of marine debris and evaluate it on specifically selected test sites where it is highly probable that plastic pollution is present in the detected marine debris. We demonstrate quantitatively and qualitatively that a deep learning model trained on this dataset issued from multiple sources outperforms existing detection models trained on previous datasets by a large margin. Our experiments show, consistent with the principles of data-centric AI, that this performance is due to our particular dataset design with extensive sampling of negative examples and label refinements rather than depending on the particular deep learning model. We hope to accelerate advances in the large-scale automated detection of marine debris, which is a step towards quantifying and monitoring marine litter with remote sensing at global scales, and release the model weights and training source code under https://github.com/marccoru/marinedebrisdetector","sentences":["Detecting and quantifying marine pollution and macro-plastics is an increasingly pressing ecological issue that directly impacts ecology and human health.","Efforts to quantify marine pollution are often conducted with sparse and expensive beach surveys, which are difficult to conduct on a large scale.","Here, remote sensing can provide reliable estimates of plastic pollution by regularly monitoring and detecting marine debris in coastal areas.","Medium-resolution satellite data of coastal areas is readily available and can be leveraged to detect aggregations of marine debris containing plastic litter.","In this work, we present a detector for marine debris built on a deep segmentation model that outputs a probability for marine debris at the pixel level.","We train this detector with a combination of annotated datasets of marine debris and evaluate it on specifically selected test sites where it is highly probable that plastic pollution is present in the detected marine debris.","We demonstrate quantitatively and qualitatively that a deep learning model trained on this dataset issued from multiple sources outperforms existing detection models trained on previous datasets by a large margin.","Our experiments show, consistent with the principles of data-centric AI, that this performance is due to our particular dataset design with extensive sampling of negative examples and label refinements rather than depending on the particular deep learning model.","We hope to accelerate advances in the large-scale automated detection of marine debris, which is a step towards quantifying and monitoring marine litter with remote sensing at global scales, and release the model weights and training source code under https://github.com/marccoru/marinedebrisdetector"],"url":"http://arxiv.org/abs/2307.02465v1"}
{"created":"2023-07-05 17:33:41","title":"Performance Scaling via Optimal Transport: Enabling Data Selection from Partially Revealed Sources","abstract":"Traditionally, data selection has been studied in settings where all samples from prospective sources are fully revealed to a machine learning developer. However, in practical data exchange scenarios, data providers often reveal only a limited subset of samples before an acquisition decision is made. Recently, there have been efforts to fit scaling laws that predict model performance at any size and data source composition using the limited available samples. However, these scaling functions are black-box, computationally expensive to fit, highly susceptible to overfitting, or/and difficult to optimize for data selection. This paper proposes a framework called <projektor>, which predicts model performance and supports data selection decisions based on partial samples of prospective data sources. Our approach distinguishes itself from existing work by introducing a novel *two-stage* performance inference process. In the first stage, we leverage the Optimal Transport distance to predict the model's performance for any data mixture ratio within the range of disclosed data sizes. In the second stage, we extrapolate the performance to larger undisclosed data sizes based on a novel parameter-free mapping technique inspired by neural scaling laws. We further derive an efficient gradient-based method to select data sources based on the projected model performance. Evaluation over a diverse range of applications demonstrates that <projektor> significantly improves existing performance scaling approaches in terms of both the accuracy of performance inference and the computation costs associated with constructing the performance predictor. Also, <projektor> outperforms by a wide margin in data selection effectiveness compared to a range of other off-the-shelf solutions.","sentences":["Traditionally, data selection has been studied in settings where all samples from prospective sources are fully revealed to a machine learning developer.","However, in practical data exchange scenarios, data providers often reveal only a limited subset of samples before an acquisition decision is made.","Recently, there have been efforts to fit scaling laws that predict model performance at any size and data source composition using the limited available samples.","However, these scaling functions are black-box, computationally expensive to fit, highly susceptible to overfitting, or/and difficult to optimize for data selection.","This paper proposes a framework called <projektor>, which predicts model performance and supports data selection decisions based on partial samples of prospective data sources.","Our approach distinguishes itself from existing work by introducing a novel *two-stage* performance inference process.","In the first stage, we leverage the Optimal Transport distance to predict the model's performance for any data mixture ratio within the range of disclosed data sizes.","In the second stage, we extrapolate the performance to larger undisclosed data sizes based on a novel parameter-free mapping technique inspired by neural scaling laws.","We further derive an efficient gradient-based method to select data sources based on the projected model performance.","Evaluation over a diverse range of applications demonstrates that <projektor> significantly improves existing performance scaling approaches in terms of both the accuracy of performance inference and the computation costs associated with constructing the performance predictor.","Also, <projektor> outperforms by a wide margin in data selection effectiveness compared to a range of other off-the-shelf solutions."],"url":"http://arxiv.org/abs/2307.02460v1"}
{"created":"2023-07-05 17:32:51","title":"Gaussian Database Alignment and Gaussian Planted Matching","abstract":"Database alignment is a variant of the graph alignment problem: Given a pair of anonymized databases containing separate yet correlated features for a set of users, the problem is to identify the correspondence between the features and align the anonymized user sets based on correlation alone. This closely relates to planted matching, where given a bigraph with random weights, the goal is to identify the underlying matching that generated the given weights. We study an instance of the database alignment problem with multivariate Gaussian features and derive results that apply both for database alignment and for planted matching, demonstrating the connection between them. The performance thresholds for database alignment converge to that for planted matching when the dimensionality of the database features is \\(\\omega(\\log n)\\), where \\(n\\) is the size of the alignment, and no individual feature is too strong. The maximum likelihood algorithms for both planted matching and database alignment take the form of a linear program and we study relaxations to better understand the significance of various constraints under various conditions and present achievability and converse bounds. Our results show that the almost-exact alignment threshold for the relaxed algorithms coincide with that of maximum likelihood, while there is a gap between the exact alignment thresholds. Our analysis and results extend to the unbalanced case where one user set is not fully covered by the alignment.","sentences":["Database alignment is a variant of the graph alignment problem: Given a pair of anonymized databases containing separate yet correlated features for a set of users, the problem is to identify the correspondence between the features and align the anonymized user sets based on correlation alone.","This closely relates to planted matching, where given a bigraph with random weights, the goal is to identify the underlying matching that generated the given weights.","We study an instance of the database alignment problem with multivariate Gaussian features and derive results that apply both for database alignment and for planted matching, demonstrating the connection between them.","The performance thresholds for database alignment converge to that for planted matching when the dimensionality of the database features is \\(\\omega(\\log n)\\), where \\(n\\) is the size of the alignment, and no individual feature is too strong.","The maximum likelihood algorithms for both planted matching and database alignment take the form of a linear program and we study relaxations to better understand the significance of various constraints under various conditions and present achievability and converse bounds.","Our results show that the almost-exact alignment threshold for the relaxed algorithms coincide with that of maximum likelihood, while there is a gap between the exact alignment thresholds.","Our analysis and results extend to the unbalanced case where one user set is not fully covered by the alignment."],"url":"http://arxiv.org/abs/2307.02459v1"}
{"created":"2023-07-05 17:31:44","title":"DeSRA: Detect and Delete the Artifacts of GAN-based Real-World Super-Resolution Models","abstract":"Image super-resolution (SR) with generative adversarial networks (GAN) has achieved great success in restoring realistic details. However, it is notorious that GAN-based SR models will inevitably produce unpleasant and undesirable artifacts, especially in practical scenarios. Previous works typically suppress artifacts with an extra loss penalty in the training phase. They only work for in-distribution artifact types generated during training. When applied in real-world scenarios, we observe that those improved methods still generate obviously annoying artifacts during inference. In this paper, we analyze the cause and characteristics of the GAN artifacts produced in unseen test data without ground-truths. We then develop a novel method, namely, DeSRA, to Detect and then Delete those SR Artifacts in practice. Specifically, we propose to measure a relative local variance distance from MSE-SR results and GAN-SR results, and locate the problematic areas based on the above distance and semantic-aware thresholds. After detecting the artifact regions, we develop a finetune procedure to improve GAN-based SR models with a few samples, so that they can deal with similar types of artifacts in more unseen real data. Equipped with our DeSRA, we can successfully eliminate artifacts from inference and improve the ability of SR models to be applied in real-world scenarios. The code will be available at https://github.com/TencentARC/DeSRA.","sentences":["Image super-resolution (SR) with generative adversarial networks (GAN) has achieved great success in restoring realistic details.","However, it is notorious that GAN-based SR models will inevitably produce unpleasant and undesirable artifacts, especially in practical scenarios.","Previous works typically suppress artifacts with an extra loss penalty in the training phase.","They only work for in-distribution artifact types generated during training.","When applied in real-world scenarios, we observe that those improved methods still generate obviously annoying artifacts during inference.","In this paper, we analyze the cause and characteristics of the GAN artifacts produced in unseen test data without ground-truths.","We then develop a novel method, namely, DeSRA, to Detect and then Delete those SR Artifacts in practice.","Specifically, we propose to measure a relative local variance distance from MSE-SR results and GAN-SR results, and locate the problematic areas based on the above distance and semantic-aware thresholds.","After detecting the artifact regions, we develop a finetune procedure to improve GAN-based SR models with a few samples, so that they can deal with similar types of artifacts in more unseen real data.","Equipped with our DeSRA, we can successfully eliminate artifacts from inference and improve the ability of SR models to be applied in real-world scenarios.","The code will be available at https://github.com/TencentARC/DeSRA."],"url":"http://arxiv.org/abs/2307.02457v1"}
{"created":"2023-07-05 17:27:17","title":"Transgressing the boundaries: towards a rigorous understanding of deep learning and its (non-)robustness","abstract":"The recent advances in machine learning in various fields of applications can be largely attributed to the rise of deep learning (DL) methods and architectures. Despite being a key technology behind autonomous cars, image processing, speech recognition, etc., a notorious problem remains the lack of theoretical understanding of DL and related interpretability and (adversarial) robustness issues. Understanding the specifics of DL, as compared to, say, other forms of nonlinear regression methods or statistical learning, is interesting from a mathematical perspective, but at the same time it is of crucial importance in practice: treating neural networks as mere black boxes might be sufficient in certain cases, but many applications require waterproof performance guarantees and a deeper understanding of what could go wrong and why it could go wrong. It is probably fair to say that, despite being mathematically well founded as a method to approximate complicated functions, DL is mostly still more like modern alchemy that is firmly in the hands of engineers and computer scientists. Nevertheless, it is evident that certain specifics of DL that could explain its success in applications demands systematic mathematical approaches. In this work, we review robustness issues of DL and particularly bridge concerns and attempts from approximation theory to statistical learning theory. Further, we review Bayesian Deep Learning as a means for uncertainty quantification and rigorous explainability.","sentences":["The recent advances in machine learning in various fields of applications can be largely attributed to the rise of deep learning (DL) methods and architectures.","Despite being a key technology behind autonomous cars, image processing, speech recognition, etc., a notorious problem remains the lack of theoretical understanding of DL and related interpretability and (adversarial) robustness issues.","Understanding the specifics of DL, as compared to, say, other forms of nonlinear regression methods or statistical learning, is interesting from a mathematical perspective, but at the same time it is of crucial importance in practice: treating neural networks as mere black boxes might be sufficient in certain cases, but many applications require waterproof performance guarantees and a deeper understanding of what could go wrong and why it could go wrong.","It is probably fair to say that, despite being mathematically well founded as a method to approximate complicated functions, DL is mostly still more like modern alchemy that is firmly in the hands of engineers and computer scientists.","Nevertheless, it is evident that certain specifics of DL that could explain its success in applications demands systematic mathematical approaches.","In this work, we review robustness issues of DL and particularly bridge concerns and attempts from approximation theory to statistical learning theory.","Further, we review Bayesian Deep Learning as a means for uncertainty quantification and rigorous explainability."],"url":"http://arxiv.org/abs/2307.02454v1"}
{"created":"2023-07-05 17:19:15","title":"Stair Climbing using the Angular Momentum Linear Inverted Pendulum Model and Model Predictive Control","abstract":"A new control paradigm using angular momentum and foot placement as state variables in the linear inverted pendulum model has expanded the realm of possibilities for the control of bipedal robots. This new paradigm, known as the ALIP model, has shown effectiveness in cases where a robot's center of mass height can be assumed to be constant or near constant as well as in cases where there are no non-kinematic restrictions on foot placement. Walking up and down stairs violates both of these assumptions, where center of mass height varies significantly within a step and the geometry of the stairs restrict the effectiveness of foot placement. In this paper, we explore a variation of the ALIP model that allows the length of the virtual pendulum formed by the robot's stance foot and center of mass to follow smooth trajectories during a step. We couple this model with a control strategy constructed from a novel combination of virtual constraint-based control and a model predictive control algorithm to stabilize a stair climbing gait that does not soley rely on foot placement. Simulations on a 20-degree of freedom model of the Cassie biped in the SimMechanics simulation environment show that the controller is able to achieve periodic gait.","sentences":["A new control paradigm using angular momentum and foot placement as state variables in the linear inverted pendulum model has expanded the realm of possibilities for the control of bipedal robots.","This new paradigm, known as the ALIP model, has shown effectiveness in cases where a robot's center of mass height can be assumed to be constant or near constant as well as in cases where there are no non-kinematic restrictions on foot placement.","Walking up and down stairs violates both of these assumptions, where center of mass height varies significantly within a step and the geometry of the stairs restrict the effectiveness of foot placement.","In this paper, we explore a variation of the ALIP model that allows the length of the virtual pendulum formed by the robot's stance foot and center of mass to follow smooth trajectories during a step.","We couple this model with a control strategy constructed from a novel combination of virtual constraint-based control and a model predictive control algorithm to stabilize a stair climbing gait that does not soley rely on foot placement.","Simulations on a 20-degree of freedom model of the Cassie biped in the SimMechanics simulation environment show that the controller is able to achieve periodic gait."],"url":"http://arxiv.org/abs/2307.02448v1"}
{"created":"2023-07-05 17:17:16","title":"Using Rewrite Strategies for Efficient Functional Automatic Differentiation","abstract":"Automatic Differentiation (AD) has become a dominant technique in ML. AD frameworks have first been implemented for imperative languages using tapes. Meanwhile, functional implementations of AD have been developed, often based on dual numbers, which are close to the formal specification of differentiation and hence easier to prove correct. But these papers have focussed on correctness not efficiency. Recently, it was shown how an approach using dual numbers could be made efficient through the right optimizations. Optimizations are highly dependent on order, as one optimization can enable another. It can therefore be useful to have fine-grained control over the scheduling of optimizations. One method expresses compiler optimizations as rewrite rules, whose application can be combined and controlled using strategy languages. Previous work describes the use of term rewriting and strategies to generate high-performance code in a compiler for a functional language. In this work, we implement dual numbers AD in a functional array programming language using rewrite rules and strategy combinators for optimization. We aim to combine the elegance of differentiation using dual numbers with a succinct expression of the optimization schedule using a strategy language. We give preliminary evidence suggesting the viability of the approach on a micro-benchmark.","sentences":["Automatic Differentiation (AD) has become a dominant technique in ML.","AD frameworks have first been implemented for imperative languages using tapes.","Meanwhile, functional implementations of AD have been developed, often based on dual numbers, which are close to the formal specification of differentiation and hence easier to prove correct.","But these papers have focussed on correctness not efficiency.","Recently, it was shown how an approach using dual numbers could be made efficient through the right optimizations.","Optimizations are highly dependent on order, as one optimization can enable another.","It can therefore be useful to have fine-grained control over the scheduling of optimizations.","One method expresses compiler optimizations as rewrite rules, whose application can be combined and controlled using strategy languages.","Previous work describes the use of term rewriting and strategies to generate high-performance code in a compiler for a functional language.","In this work, we implement dual numbers AD in a functional array programming language using rewrite rules and strategy combinators for optimization.","We aim to combine the elegance of differentiation using dual numbers with a succinct expression of the optimization schedule using a strategy language.","We give preliminary evidence suggesting the viability of the approach on a micro-benchmark."],"url":"http://arxiv.org/abs/2307.02447v1"}
{"created":"2023-07-05 17:15:15","title":"Vulnerable Source Code Detection using SonarCloud Code Analysis","abstract":"In Software Development Life Cycle (SDLC), security vulnerabilities are one of the points introduced during the construction stage. Failure to detect software defects earlier after releasing the product to the market causes higher repair costs for the company. So, it decreases the company's reputation, violates user privacy, and causes an unrepairable issue for the application. The introduction of vulnerability detection enables reducing the number of false alerts to focus the limited testing efforts on potentially vulnerable files. UMKM Masa Kini (UMI) is a Point of Sales application to sell any Micro, Small, and Medium Enterprises Product (UMKM). Therefore, in the current work, we analyze the suitability of these metrics to create Machine Learning based software vulnerability detectors for UMI applications. Code is generated using a commercial tool, SonarCloud. Experimental result shows that there are 3,285 vulnerable rules detected.","sentences":["In Software Development Life Cycle (SDLC), security vulnerabilities are one of the points introduced during the construction stage.","Failure to detect software defects earlier after releasing the product to the market causes higher repair costs for the company.","So, it decreases the company's reputation, violates user privacy, and causes an unrepairable issue for the application.","The introduction of vulnerability detection enables reducing the number of false alerts to focus the limited testing efforts on potentially vulnerable files.","UMKM Masa Kini (UMI) is a Point of Sales application to sell any Micro, Small, and Medium Enterprises Product (UMKM).","Therefore, in the current work, we analyze the suitability of these metrics to create Machine Learning based software vulnerability detectors for UMI applications.","Code is generated using a commercial tool, SonarCloud.","Experimental result shows that there are 3,285 vulnerable rules detected."],"url":"http://arxiv.org/abs/2307.02446v1"}
{"created":"2023-07-05 17:13:00","title":"An Exploratory Literature Study on Sharing and Energy Use of Language Models for Source Code","abstract":"Large language models trained on source code can support a variety of software development tasks, such as code recommendation and program repair. Large amounts of data for training such models benefit the models' performance. However, the size of the data and models results in long training times and high energy consumption. While publishing source code allows for replicability, users need to repeat the expensive training process if models are not shared. The main goal of the study is to investigate if publications that trained language models for software engineering (SE) tasks share source code and trained artifacts. The second goal is to analyze the transparency on training energy usage. We perform a snowballing-based literature search to find publications on language models for source code, and analyze their reusability from a sustainability standpoint.   From 494 unique publications, we identified 293 relevant publications that use language models to address code-related tasks. Among them, 27% (79 out of 293) make artifacts available for reuse. This can be in the form of tools or IDE plugins designed for specific tasks or task-agnostic models that can be fine-tuned for a variety of downstream tasks. Moreover, we collect insights on the hardware used for model training, as well as training time, which together determine the energy consumption of the development process. We find that there are deficiencies in the sharing of information and artifacts for current studies on source code models for software engineering tasks, with 40% of the surveyed papers not sharing source code or trained artifacts. We recommend the sharing of source code as well as trained artifacts, to enable sustainable reproducibility. Moreover, comprehensive information on training times and hardware configurations should be shared for transparency on a model's carbon footprint.","sentences":["Large language models trained on source code can support a variety of software development tasks, such as code recommendation and program repair.","Large amounts of data for training such models benefit the models' performance.","However, the size of the data and models results in long training times and high energy consumption.","While publishing source code allows for replicability, users need to repeat the expensive training process if models are not shared.","The main goal of the study is to investigate if publications that trained language models for software engineering (SE) tasks share source code and trained artifacts.","The second goal is to analyze the transparency on training energy usage.","We perform a snowballing-based literature search to find publications on language models for source code, and analyze their reusability from a sustainability standpoint.   ","From 494 unique publications, we identified 293 relevant publications that use language models to address code-related tasks.","Among them, 27% (79 out of 293) make artifacts available for reuse.","This can be in the form of tools or IDE plugins designed for specific tasks or task-agnostic models that can be fine-tuned for a variety of downstream tasks.","Moreover, we collect insights on the hardware used for model training, as well as training time, which together determine the energy consumption of the development process.","We find that there are deficiencies in the sharing of information and artifacts for current studies on source code models for software engineering tasks, with 40% of the surveyed papers not sharing source code or trained artifacts.","We recommend the sharing of source code as well as trained artifacts, to enable sustainable reproducibility.","Moreover, comprehensive information on training times and hardware configurations should be shared for transparency on a model's carbon footprint."],"url":"http://arxiv.org/abs/2307.02443v1"}
{"created":"2023-07-05 17:12:48","title":"Robotic Sonographer: Autonomous Robotic Ultrasound using Domain Expertise in Bayesian Optimization","abstract":"Ultrasound is a vital imaging modality utilized for a variety of diagnostic and interventional procedures. However, an expert sonographer is required to make accurate maneuvers of the probe over the human body while making sense of the ultrasound images for diagnostic purposes. This procedure requires a substantial amount of training and up to a few years of experience. In this paper, we propose an autonomous robotic ultrasound system that uses Bayesian Optimization (BO) in combination with the domain expertise to predict and effectively scan the regions where diagnostic quality ultrasound images can be acquired. The quality map, which is a distribution of image quality in a scanning region, is estimated using Gaussian process in BO. This relies on a prior quality map modeled using expert's demonstration of the high-quality probing maneuvers. The ultrasound image quality feedback is provided to BO, which is estimated using a deep convolution neural network model. This model was previously trained on database of images labelled for diagnostic quality by expert radiologists. Experiments on three different urinary bladder phantoms validated that the proposed autonomous ultrasound system can acquire ultrasound images for diagnostic purposes with a probing position and force accuracy of 98.7% and 97.8%, respectively.","sentences":["Ultrasound is a vital imaging modality utilized for a variety of diagnostic and interventional procedures.","However, an expert sonographer is required to make accurate maneuvers of the probe over the human body while making sense of the ultrasound images for diagnostic purposes.","This procedure requires a substantial amount of training and up to a few years of experience.","In this paper, we propose an autonomous robotic ultrasound system that uses Bayesian Optimization (BO) in combination with the domain expertise to predict and effectively scan the regions where diagnostic quality ultrasound images can be acquired.","The quality map, which is a distribution of image quality in a scanning region, is estimated using Gaussian process in BO.","This relies on a prior quality map modeled using expert's demonstration of the high-quality probing maneuvers.","The ultrasound image quality feedback is provided to BO, which is estimated using a deep convolution neural network model.","This model was previously trained on database of images labelled for diagnostic quality by expert radiologists.","Experiments on three different urinary bladder phantoms validated that the proposed autonomous ultrasound system can acquire ultrasound images for diagnostic purposes with a probing position and force accuracy of 98.7% and 97.8%, respectively."],"url":"http://arxiv.org/abs/2307.02442v1"}
{"created":"2023-07-05 16:58:39","title":"Exploring Continual Learning for Code Generation Models","abstract":"Large-scale code generation models such as Codex and CodeT5 have achieved impressive performance. However, libraries are upgraded or deprecated very frequently and re-training large-scale language models is computationally expensive. Therefore, Continual Learning (CL) is an important aspect that remains underexplored in the code domain. In this paper, we introduce a benchmark called CodeTask-CL that covers a wide range of tasks, including code generation, translation, summarization, and refinement, with different input and output programming languages. Next, on our CodeTask-CL benchmark, we compare popular CL techniques from NLP and Vision domains. We find that effective methods like Prompt Pooling (PP) suffer from catastrophic forgetting due to the unstable training of the prompt selection mechanism caused by stark distribution shifts in coding tasks. We address this issue with our proposed method, Prompt Pooling with Teacher Forcing (PP-TF), that stabilizes training by enforcing constraints on the prompt selection mechanism and leads to a 21.54% improvement over Prompt Pooling. Along with the benchmark, we establish a training pipeline that can be used for CL on code models, which we believe can motivate further development of CL methods for code models. Our code is available at https://github.com/amazon-science/codetaskcl-pptf","sentences":["Large-scale code generation models such as Codex and CodeT5 have achieved impressive performance.","However, libraries are upgraded or deprecated very frequently and re-training large-scale language models is computationally expensive.","Therefore, Continual Learning (CL) is an important aspect that remains underexplored in the code domain.","In this paper, we introduce a benchmark called CodeTask-CL that covers a wide range of tasks, including code generation, translation, summarization, and refinement, with different input and output programming languages.","Next, on our CodeTask-CL benchmark, we compare popular CL techniques from NLP and Vision domains.","We find that effective methods like Prompt Pooling (PP) suffer from catastrophic forgetting due to the unstable training of the prompt selection mechanism caused by stark distribution shifts in coding tasks.","We address this issue with our proposed method, Prompt Pooling with Teacher Forcing (PP-TF), that stabilizes training by enforcing constraints on the prompt selection mechanism and leads to a 21.54% improvement over Prompt Pooling.","Along with the benchmark, we establish a training pipeline that can be used for CL on code models, which we believe can motivate further development of CL methods for code models.","Our code is available at https://github.com/amazon-science/codetaskcl-pptf"],"url":"http://arxiv.org/abs/2307.02435v1"}
{"created":"2023-07-05 16:51:54","title":"DarkHorse: A UDP-based Framework to Improve the Latency of Tor Onion Services","abstract":"Tor is the most popular anonymous communication overlay network which hides clients' identities from servers by passing packets through multiple relays. To provide anonymity to both clients and servers, Tor onion services were introduced by increasing the number of relays between a client and a server. Because of the limited bandwidth of Tor relays, large numbers of users, and multiple layers of encryption at relays, onion services suffer from high end-to-end latency and low data transfer rates, which degrade user experiences, making onion services unsuitable for latency-sensitive applications. In this paper, we present a UDP-based framework, called DarkHorse, that improves the end-to-end latency and the data transfer overhead of Tor onion services by exploiting the connectionless nature of UDP. Our evaluation results demonstrate that DarkHorse is up to 3.62x faster than regular TCP-based Tor onion services and reduces the Tor network overhead by up to 47%.","sentences":["Tor is the most popular anonymous communication overlay network which hides clients' identities from servers by passing packets through multiple relays.","To provide anonymity to both clients and servers, Tor onion services were introduced by increasing the number of relays between a client and a server.","Because of the limited bandwidth of Tor relays, large numbers of users, and multiple layers of encryption at relays, onion services suffer from high end-to-end latency and low data transfer rates, which degrade user experiences, making onion services unsuitable for latency-sensitive applications.","In this paper, we present a UDP-based framework, called DarkHorse, that improves the end-to-end latency and the data transfer overhead of Tor onion services by exploiting the connectionless nature of UDP.","Our evaluation results demonstrate that DarkHorse is up to 3.62x faster than regular TCP-based Tor onion services and reduces the Tor network overhead by up to 47%."],"url":"http://arxiv.org/abs/2307.02429v1"}
{"created":"2023-07-05 16:49:06","title":"FOCUS: Object-Centric World Models for Robotics Manipulation","abstract":"Understanding the world in terms of objects and the possible interplays with them is an important cognition ability, especially in robotics manipulation, where many tasks require robot-object interactions. However, learning such a structured world model, which specifically captures entities and relationships, remains a challenging and underexplored problem. To address this, we propose FOCUS, a model-based agent that learns an object-centric world model. Thanks to a novel exploration bonus that stems from the object-centric representation, FOCUS can be deployed on robotics manipulation tasks to explore object interactions more easily. Evaluating our approach on manipulation tasks across different settings, we show that object-centric world models allow the agent to solve tasks more efficiently and enable consistent exploration of robot-object interactions. Using a Franka Emika robot arm, we also showcase how FOCUS could be adopted in real-world settings.","sentences":["Understanding the world in terms of objects and the possible interplays with them is an important cognition ability, especially in robotics manipulation, where many tasks require robot-object interactions.","However, learning such a structured world model, which specifically captures entities and relationships, remains a challenging and underexplored problem.","To address this, we propose FOCUS, a model-based agent that learns an object-centric world model.","Thanks to a novel exploration bonus that stems from the object-centric representation, FOCUS can be deployed on robotics manipulation tasks to explore object interactions more easily.","Evaluating our approach on manipulation tasks across different settings, we show that object-centric world models allow the agent to solve tasks more efficiently and enable consistent exploration of robot-object interactions.","Using a Franka Emika robot arm, we also showcase how FOCUS could be adopted in real-world settings."],"url":"http://arxiv.org/abs/2307.02427v1"}
{"created":"2023-07-05 16:43:56","title":"DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models","abstract":"Despite the ability of existing large-scale text-to-image (T2I) models to generate high-quality images from detailed textual descriptions, they often lack the ability to precisely edit the generated or real images. In this paper, we propose a novel image editing method, DragonDiffusion, enabling Drag-style manipulation on Diffusion models. Specifically, we construct classifier guidance based on the strong correspondence of intermediate features in the diffusion model. It can transform the editing signals into gradients via feature correspondence loss to modify the intermediate representation of the diffusion model. Based on this guidance strategy, we also build a multi-scale guidance to consider both semantic and geometric alignment. Moreover, a cross-branch self-attention is added to maintain the consistency between the original image and the editing result. Our method, through an efficient design, achieves various editing modes for the generated or real images, such as object moving, object resizing, object appearance replacement, and content dragging. It is worth noting that all editing and content preservation signals come from the image itself, and the model does not require fine-tuning or additional modules. Our source code will be available at https://github.com/MC-E/DragonDiffusion.","sentences":["Despite the ability of existing large-scale text-to-image (T2I) models to generate high-quality images from detailed textual descriptions, they often lack the ability to precisely edit the generated or real images.","In this paper, we propose a novel image editing method, DragonDiffusion, enabling Drag-style manipulation on Diffusion models.","Specifically, we construct classifier guidance based on the strong correspondence of intermediate features in the diffusion model.","It can transform the editing signals into gradients via feature correspondence loss to modify the intermediate representation of the diffusion model.","Based on this guidance strategy, we also build a multi-scale guidance to consider both semantic and geometric alignment.","Moreover, a cross-branch self-attention is added to maintain the consistency between the original image and the editing result.","Our method, through an efficient design, achieves various editing modes for the generated or real images, such as object moving, object resizing, object appearance replacement, and content dragging.","It is worth noting that all editing and content preservation signals come from the image itself, and the model does not require fine-tuning or additional modules.","Our source code will be available at https://github.com/MC-E/DragonDiffusion."],"url":"http://arxiv.org/abs/2307.02421v1"}
{"created":"2023-07-05 16:41:01","title":"In-Context Learning for Attention Scheme: from Single Softmax Regression to Multiple Softmax Regression via a Tensor Trick","abstract":"Large language models (LLMs) have brought significant and transformative changes in human society. These models have demonstrated remarkable capabilities in natural language understanding and generation, leading to various advancements and impacts across several domains.   We consider the in-context learning under two formulation for attention related regression in this work. Given matrices $A_1 \\in \\mathbb{R}^{n \\times d}$, and $A_2 \\in \\mathbb{R}^{n \\times d}$ and $B \\in \\mathbb{R}^{n \\times n}$, the purpose is to solve some certain optimization problems: Normalized version $\\min_{X} \\| D(X)^{-1} \\exp(A_1 X A_2^\\top) - B \\|_F^2$ and Rescaled version $\\| \\exp(A_1 X A_2^\\top) - D(X) \\cdot B \\|_F^2$. Here $D(X) := \\mathrm{diag}( \\exp(A_1 X A_2^\\top) {\\bf 1}_n )$.   Our regression problem shares similarities with previous studies on softmax-related regression. Prior research has extensively investigated regression techniques related to softmax regression: Normalized version $\\| \\langle \\exp(Ax) , {\\bf 1}_n \\rangle^{-1} \\exp(Ax) - b \\|_2^2$ and Resscaled version $\\| \\exp(Ax) - \\langle \\exp(Ax), {\\bf 1}_n \\rangle b \\|_2^2 $   In contrast to previous approaches, we adopt a vectorization technique to address the regression problem in matrix formulation. This approach expands the dimension from $d$ to $d^2$, resembling the formulation of the regression problem mentioned earlier.   Upon completing the lipschitz analysis of our regression function, we have derived our main result concerning in-context learning.","sentences":["Large language models (LLMs) have brought significant and transformative changes in human society.","These models have demonstrated remarkable capabilities in natural language understanding and generation, leading to various advancements and impacts across several domains.   ","We consider the in-context learning under two formulation for attention related regression in this work.","Given matrices $A_1 \\in \\mathbb{R}^{n \\times d}$, and $A_2 \\in \\mathbb{R}^{n \\times d}$ and $B \\in \\mathbb{R}^{n \\times n}$, the purpose is to solve some certain optimization problems: Normalized version $\\min_{X} \\| D(X)^{-1} \\exp(A_1 X A_2^\\top) - B \\|_F^2$ and Rescaled version $\\| \\exp(A_1 X A_2^\\top) - D(X) \\cdot B \\|_F^2$. Here $D(X) :","= \\mathrm{diag}( \\exp(A_1 X A_2^\\top) {\\bf 1}_n )$.   ","Our regression problem shares similarities with previous studies on softmax-related regression.","Prior research has extensively investigated regression techniques related to softmax regression: Normalized version $\\| \\langle \\exp(Ax) , {\\bf 1}_n \\rangle^{-1} \\exp(Ax) - b \\|_2^2$ and Resscaled version $\\| \\exp(Ax) - \\langle \\exp(Ax), {\\bf 1}_n \\rangle b \\|_2^2 $   In contrast to previous approaches, we adopt a vectorization technique to address the regression problem in matrix formulation.","This approach expands the dimension from $d$ to $d^2$, resembling the formulation of the regression problem mentioned earlier.   ","Upon completing the lipschitz analysis of our regression function, we have derived our main result concerning in-context learning."],"url":"http://arxiv.org/abs/2307.02419v1"}
{"created":"2023-07-05 16:40:23","title":"3D Multi-Robot Exploration with a Two-Level Coordination Strategy and Prioritization","abstract":"This work presents a 3D multi-robot exploration framework for a team of UGVs moving on uneven terrains. The framework was designed by casting the two-level coordination strategy presented in [1] into the context of multi-robot exploration. The resulting distributed exploration technique minimizes and explicitly manages the occurrence of conflicts and interferences in the robot team. Each robot selects where to scan next by using a receding horizon next-best-view approach [2]. A sampling-based tree is directly expanded on segmented traversable regions of the terrain 3D map to generate the candidate next viewpoints. During the exploration, users can on-demand assign locations with higher priorities to steer the robot exploration toward areas of interest. The proposed framework can be also used to perform coverage tasks in the case a map of the environment is a priori provided as input. An open-source implementation is available online.","sentences":["This work presents a 3D multi-robot exploration framework for a team of UGVs moving on uneven terrains.","The framework was designed by casting the two-level coordination strategy presented in [1] into the context of multi-robot exploration.","The resulting distributed exploration technique minimizes and explicitly manages the occurrence of conflicts and interferences in the robot team.","Each robot selects where to scan next by using a receding horizon next-best-view approach [2].","A sampling-based tree is directly expanded on segmented traversable regions of the terrain 3D map to generate the candidate next viewpoints.","During the exploration, users can on-demand assign locations with higher priorities to steer the robot exploration toward areas of interest.","The proposed framework can be also used to perform coverage tasks in the case a map of the environment is a priori provided as input.","An open-source implementation is available online."],"url":"http://arxiv.org/abs/2307.02417v1"}
{"created":"2023-07-05 16:37:32","title":"Density-Sensitive Algorithms for $(\u0394+ 1)$-Edge Coloring","abstract":"Vizing's theorem asserts the existence of a {$(\\Delta+1)$-edge coloring} for any graph $G$, where $\\Delta = \\Delta(G)$ denotes the maximum degree of $G$. Several polynomial time $(\\Delta+1)$-edge coloring algorithms are known, and the state-of-the-art running time (up to polylogarithmic factors) is $\\tilde{O}(\\min\\{m \\cdot \\sqrt{n}, m \\cdot \\Delta\\})$, by Gabow et al.\\ from 1985, where $n$ and $m$ denote the number of vertices and edges in the graph, respectively. (The $\\tilde{O}$ notation suppresses polylogarithmic factors.) Recently, Sinnamon shaved off a polylogarithmic factor from the time bound of Gabow et al.   The {arboricity} $\\alpha = \\alpha(G)$ of a graph $G$ is the minimum number of edge-disjoint forests into which its edge set can be partitioned, and it is a measure of the graph's ``uniform density''. While $\\alpha \\le \\Delta$ in any graph, many natural and real-world graphs exhibit a significant separation between $\\alpha$ and $\\Delta$.   In this work we design a $(\\Delta+1)$-edge coloring algorithm with a running time of $\\tilde{O}(\\min\\{m \\cdot \\sqrt{n}, m \\cdot \\Delta\\})\\cdot \\frac{\\alpha}{\\Delta}$, thus improving the longstanding time barrier by a factor of $\\frac{\\alpha}{\\Delta}$. In particular, we achieve a near-linear runtime for bounded arboricity graphs (i.e., $\\alpha = \\tilde{O}(1)$) as well as when $\\alpha = \\tilde{O}(\\frac{\\Delta}{\\sqrt{n}})$. Our algorithm builds on Sinnamon's algorithm, and can be viewed as a density-sensitive refinement of it.","sentences":["Vizing's theorem asserts the existence of a {$(\\Delta+1)$-edge coloring} for any graph $G$, where $\\Delta = \\Delta(G)$ denotes the maximum degree of $G$. Several polynomial time $(\\Delta+1)$-edge coloring algorithms are known, and the state-of-the-art running time (up to polylogarithmic factors) is $\\tilde{O}(\\min\\{m \\cdot \\sqrt{n}, m \\cdot \\Delta\\})$, by Gabow et al.\\ from 1985, where $n$ and $m$ denote the number of vertices and edges in the graph, respectively.","(The $\\tilde{O}$ notation suppresses polylogarithmic factors.)","Recently, Sinnamon shaved off a polylogarithmic factor from the time bound of Gabow et al.   ","The {arboricity} $\\alpha = \\alpha(G)$ of a graph $G$ is the minimum number of edge-disjoint forests into which its edge set can be partitioned, and it is a measure of the graph's ``uniform density''.","While $\\alpha \\le \\Delta$ in any graph, many natural and real-world graphs exhibit a significant separation between $\\alpha$ and $\\Delta$.   In this work we design a $(\\Delta+1)$-edge coloring algorithm with a running time of $\\tilde{O}(\\min\\{m \\cdot \\sqrt{n}, m \\cdot \\Delta\\})\\cdot \\frac{\\alpha}{\\Delta}$, thus improving the longstanding time barrier by a factor of $\\frac{\\alpha}{\\Delta}$. In particular, we achieve a near-linear runtime for bounded arboricity graphs (i.e., $\\alpha = \\tilde{O}(1)$) as well as when $\\alpha = \\tilde{O}(\\frac{\\Delta}{\\sqrt{n}})$.","Our algorithm builds on Sinnamon's algorithm, and can be viewed as a density-sensitive refinement of it."],"url":"http://arxiv.org/abs/2307.02415v1"}
{"created":"2023-07-05 16:32:25","title":"Utility-Aware Load Shedding for Real-time Video Analytics at the Edge","abstract":"Real-time video analytics typically require video frames to be processed by a query to identify objects or activities of interest while adhering to an end-to-end frame processing latency constraint. Such applications impose a continuous and heavy load on backend compute and network infrastructure because of the need to stream and process all video frames. Video data has inherent redundancy and does not always contain an object of interest for a given query. We leverage this property of video streams to propose a lightweight Load Shedder that can be deployed on edge servers or on inexpensive edge devices co-located with cameras and drop uninteresting video frames. The proposed Load Shedder uses pixel-level color-based features to calculate a utility score for each ingress video frame, which represents the frame's utility toward the query at hand. The Load Shedder uses a minimum utility threshold to select interesting frames to send for query processing. Dropping unnecessary frames enables the video analytics query in the backend to meet the end-to-end latency constraint with fewer compute and network resources. To guarantee a bounded end-to-end latency at runtime, we introduce a control loop that monitors the backend load for the given query and dynamically adjusts the utility threshold. Performance evaluations show that the proposed Load Shedder selects a large portion of frames containing each object of interest while meeting the end-to-end frame processing latency constraint. Furthermore, the Load Shedder does not impose a significant latency overhead when running on edge devices with modest compute resources.","sentences":["Real-time video analytics typically require video frames to be processed by a query to identify objects or activities of interest while adhering to an end-to-end frame processing latency constraint.","Such applications impose a continuous and heavy load on backend compute and network infrastructure because of the need to stream and process all video frames.","Video data has inherent redundancy and does not always contain an object of interest for a given query.","We leverage this property of video streams to propose a lightweight Load Shedder that can be deployed on edge servers or on inexpensive edge devices co-located with cameras and drop uninteresting video frames.","The proposed Load Shedder uses pixel-level color-based features to calculate a utility score for each ingress video frame, which represents the frame's utility toward the query at hand.","The Load Shedder uses a minimum utility threshold to select interesting frames to send for query processing.","Dropping unnecessary frames enables the video analytics query in the backend to meet the end-to-end latency constraint with fewer compute and network resources.","To guarantee a bounded end-to-end latency at runtime, we introduce a control loop that monitors the backend load for the given query and dynamically adjusts the utility threshold.","Performance evaluations show that the proposed Load Shedder selects a large portion of frames containing each object of interest while meeting the end-to-end frame processing latency constraint.","Furthermore, the Load Shedder does not impose a significant latency overhead when running on edge devices with modest compute resources."],"url":"http://arxiv.org/abs/2307.02409v1"}
{"created":"2023-07-05 16:21:52","title":"Unbalanced Optimal Transport: A Unified Framework for Object Detection","abstract":"During training, supervised object detection tries to correctly match the predicted bounding boxes and associated classification scores to the ground truth. This is essential to determine which predictions are to be pushed towards which solutions, or to be discarded. Popular matching strategies include matching to the closest ground truth box (mostly used in combination with anchors), or matching via the Hungarian algorithm (mostly used in anchor-free methods). Each of these strategies comes with its own properties, underlying losses, and heuristics. We show how Unbalanced Optimal Transport unifies these different approaches and opens a whole continuum of methods in between. This allows for a finer selection of the desired properties. Experimentally, we show that training an object detection model with Unbalanced Optimal Transport is able to reach the state-of-the-art both in terms of Average Precision and Average Recall as well as to provide a faster initial convergence. The approach is well suited for GPU implementation, which proves to be an advantage for large-scale models.","sentences":["During training, supervised object detection tries to correctly match the predicted bounding boxes and associated classification scores to the ground truth.","This is essential to determine which predictions are to be pushed towards which solutions, or to be discarded.","Popular matching strategies include matching to the closest ground truth box (mostly used in combination with anchors), or matching via the Hungarian algorithm (mostly used in anchor-free methods).","Each of these strategies comes with its own properties, underlying losses, and heuristics.","We show how Unbalanced Optimal Transport unifies these different approaches and opens a whole continuum of methods in between.","This allows for a finer selection of the desired properties.","Experimentally, we show that training an object detection model with Unbalanced Optimal Transport is able to reach the state-of-the-art both in terms of Average Precision and Average Recall as well as to provide a faster initial convergence.","The approach is well suited for GPU implementation, which proves to be an advantage for large-scale models."],"url":"http://arxiv.org/abs/2307.02402v1"}
{"created":"2023-07-05 16:14:51","title":"A Versatile Hub Model For Efficient Information Propagation And Feature Selection","abstract":"Hub structure, characterized by a few highly interconnected nodes surrounded by a larger number of nodes with fewer connections, is a prominent topological feature of biological brains, contributing to efficient information transfer and cognitive processing across various species. In this paper, a mathematical model of hub structure is presented. The proposed method is versatile and can be broadly applied to both computational neuroscience and Recurrent Neural Networks (RNNs) research. We employ the Echo State Network (ESN) as a means to investigate the mechanistic underpinnings of hub structures. Our findings demonstrate a substantial enhancement in performance upon incorporating the hub structure. Through comprehensive mechanistic analyses, we show that the hub structure improves model performance by facilitating efficient information processing and better feature extractions.","sentences":["Hub structure, characterized by a few highly interconnected nodes surrounded by a larger number of nodes with fewer connections, is a prominent topological feature of biological brains, contributing to efficient information transfer and cognitive processing across various species.","In this paper, a mathematical model of hub structure is presented.","The proposed method is versatile and can be broadly applied to both computational neuroscience and Recurrent Neural Networks (RNNs) research.","We employ the Echo State Network (ESN) as a means to investigate the mechanistic underpinnings of hub structures.","Our findings demonstrate a substantial enhancement in performance upon incorporating the hub structure.","Through comprehensive mechanistic analyses, we show that the hub structure improves model performance by facilitating efficient information processing and better feature extractions."],"url":"http://arxiv.org/abs/2307.02398v1"}
{"created":"2023-07-05 16:09:21","title":"Won't Get Fooled Again: Answering Questions with False Premises","abstract":"Pre-trained language models (PLMs) have shown unprecedented potential in various fields, especially as the backbones for question-answering (QA) systems. However, they tend to be easily deceived by tricky questions such as \"How many eyes does the sun have?\". Such frailties of PLMs often allude to the lack of knowledge within them. In this paper, we find that the PLMs already possess the knowledge required to rebut such questions, and the key is how to activate the knowledge. To systematize this observation, we investigate the PLMs' responses to one kind of tricky questions, i.e., the false premises questions (FPQs). We annotate a FalseQA dataset containing 2365 human-written FPQs, with the corresponding explanations for the false premises and the revised true premise questions. Using FalseQA, we discover that PLMs are capable of discriminating FPQs by fine-tuning on moderate numbers (e.g., 256) of examples. PLMs also generate reasonable explanations for the false premise, which serve as rebuttals. Further replaying a few general questions during training allows PLMs to excel on FPQs and general questions simultaneously. Our work suggests that once the rebuttal ability is stimulated, knowledge inside the PLMs can be effectively utilized to handle FPQs, which incentivizes the research on PLM-based QA systems.","sentences":["Pre-trained language models (PLMs) have shown unprecedented potential in various fields, especially as the backbones for question-answering (QA) systems.","However, they tend to be easily deceived by tricky questions such as \"How many eyes does the sun have?\".","Such frailties of PLMs often allude to the lack of knowledge within them.","In this paper, we find that the PLMs already possess the knowledge required to rebut such questions, and the key is how to activate the knowledge.","To systematize this observation, we investigate the PLMs' responses to one kind of tricky questions, i.e., the false premises questions (FPQs).","We annotate a FalseQA dataset containing 2365 human-written FPQs, with the corresponding explanations for the false premises and the revised true premise questions.","Using FalseQA, we discover that PLMs are capable of discriminating FPQs by fine-tuning on moderate numbers (e.g., 256) of examples.","PLMs also generate reasonable explanations for the false premise, which serve as rebuttals.","Further replaying a few general questions during training allows PLMs to excel on FPQs and general questions simultaneously.","Our work suggests that once the rebuttal ability is stimulated, knowledge inside the PLMs can be effectively utilized to handle FPQs, which incentivizes the research on PLM-based QA systems."],"url":"http://arxiv.org/abs/2307.02394v1"}
{"created":"2023-07-05 16:04:44","title":"RADiff: Controllable Diffusion Models for Radio Astronomical Maps Generation","abstract":"Along with the nearing completion of the Square Kilometre Array (SKA), comes an increasing demand for accurate and reliable automated solutions to extract valuable information from the vast amount of data it will allow acquiring. Automated source finding is a particularly important task in this context, as it enables the detection and classification of astronomical objects. Deep-learning-based object detection and semantic segmentation models have proven to be suitable for this purpose. However, training such deep networks requires a high volume of labeled data, which is not trivial to obtain in the context of radio astronomy. Since data needs to be manually labeled by experts, this process is not scalable to large dataset sizes, limiting the possibilities of leveraging deep networks to address several tasks. In this work, we propose RADiff, a generative approach based on conditional diffusion models trained over an annotated radio dataset to generate synthetic images, containing radio sources of different morphologies, to augment existing datasets and reduce the problems caused by class imbalances. We also show that it is possible to generate fully-synthetic image-annotation pairs to automatically augment any annotated dataset. We evaluate the effectiveness of this approach by training a semantic segmentation model on a real dataset augmented in two ways: 1) using synthetic images obtained from real masks, and 2) generating images from synthetic semantic masks. We show an improvement in performance when applying augmentation, gaining up to 18% in performance when using real masks and 4% when augmenting with synthetic masks. Finally, we employ this model to generate large-scale radio maps with the objective of simulating Data Challenges.","sentences":["Along with the nearing completion of the Square Kilometre Array (SKA), comes an increasing demand for accurate and reliable automated solutions to extract valuable information from the vast amount of data it will allow acquiring.","Automated source finding is a particularly important task in this context, as it enables the detection and classification of astronomical objects.","Deep-learning-based object detection and semantic segmentation models have proven to be suitable for this purpose.","However, training such deep networks requires a high volume of labeled data, which is not trivial to obtain in the context of radio astronomy.","Since data needs to be manually labeled by experts, this process is not scalable to large dataset sizes, limiting the possibilities of leveraging deep networks to address several tasks.","In this work, we propose RADiff, a generative approach based on conditional diffusion models trained over an annotated radio dataset to generate synthetic images, containing radio sources of different morphologies, to augment existing datasets and reduce the problems caused by class imbalances.","We also show that it is possible to generate fully-synthetic image-annotation pairs to automatically augment any annotated dataset.","We evaluate the effectiveness of this approach by training a semantic segmentation model on a real dataset augmented in two ways: 1) using synthetic images obtained from real masks, and 2) generating images from synthetic semantic masks.","We show an improvement in performance when applying augmentation, gaining up to 18% in performance when using real masks and 4% when augmenting with synthetic masks.","Finally, we employ this model to generate large-scale radio maps with the objective of simulating Data Challenges."],"url":"http://arxiv.org/abs/2307.02392v1"}
{"created":"2023-07-05 16:02:05","title":"Physical Layer Secret Key Agreement Using One-Bit Quantization and Low-Density Parity-Check Codes","abstract":"Physical layer approaches for generating secret encryption keys for wireless systems using channel information have attracted increased interest from researchers in recent years. This paper presents a new approach for calculating log-likelihood ratios (LLRs) for secret key generation that is based on one-bit quantization of channel measurements and the difference between channel estimates at legitimate reciprocal nodes. The studied secret key agreement approach, which implements advantage distillation along with information reconciliation using Slepian-Wolf low-density parity-check (LDPC) codes, is discussed and illustrated with numerical results obtained from simulations. These results show the probability of bit disagreement for keys generated using the proposed LLR calculations compared with alternative LLR calculation methods for key generation based on channel state information. The proposed LLR calculations are shown to be an improvement to the studied approach of physical layer secret key agreement.","sentences":["Physical layer approaches for generating secret encryption keys for wireless systems using channel information have attracted increased interest from researchers in recent years.","This paper presents a new approach for calculating log-likelihood ratios (LLRs) for secret key generation that is based on one-bit quantization of channel measurements and the difference between channel estimates at legitimate reciprocal nodes.","The studied secret key agreement approach, which implements advantage distillation along with information reconciliation using Slepian-Wolf low-density parity-check (LDPC) codes, is discussed and illustrated with numerical results obtained from simulations.","These results show the probability of bit disagreement for keys generated using the proposed LLR calculations compared with alternative LLR calculation methods for key generation based on channel state information.","The proposed LLR calculations are shown to be an improvement to the studied approach of physical layer secret key agreement."],"url":"http://arxiv.org/abs/2307.02391v1"}
{"created":"2023-07-05 16:01:38","title":"Causal Discovery with Language Models as Imperfect Experts","abstract":"Understanding the causal relationships that underlie a system is a fundamental prerequisite to accurate decision-making. In this work, we explore how expert knowledge can be used to improve the data-driven identification of causal graphs, beyond Markov equivalence classes. In doing so, we consider a setting where we can query an expert about the orientation of causal relationships between variables, but where the expert may provide erroneous information. We propose strategies for amending such expert knowledge based on consistency properties, e.g., acyclicity and conditional independencies in the equivalence class. We then report a case study, on real data, where a large language model is used as an imperfect expert.","sentences":["Understanding the causal relationships that underlie a system is a fundamental prerequisite to accurate decision-making.","In this work, we explore how expert knowledge can be used to improve the data-driven identification of causal graphs, beyond Markov equivalence classes.","In doing so, we consider a setting where we can query an expert about the orientation of causal relationships between variables, but where the expert may provide erroneous information.","We propose strategies for amending such expert knowledge based on consistency properties, e.g., acyclicity and conditional independencies in the equivalence class.","We then report a case study, on real data, where a large language model is used as an imperfect expert."],"url":"http://arxiv.org/abs/2307.02390v1"}
{"created":"2023-07-05 15:50:50","title":"Floating-base manipulation on zero-perturbation manifolds","abstract":"To achieve high-dexterity motion planning on floating-base systems, the base dynamics induced by arm motions must be treated carefully. In general, it is a significant challenge to establish a fixed-base frame during tasking due to forces and torques on the base that arise directly from arm motions (e.g. arm drag in low Reynolds environments and arm momentum in high Reynolds environments). While thrusters can in theory be used to regulate the vehicle pose, it is often insufficient to establish a stable pose for precise tasking, whether the cause be due to underactuation, modeling inaccuracy, suboptimal control parameters, or insufficient power. We propose a solution that asks the thrusters to do less high bandwidth perturbation correction by planning arm motions that induce zero perturbation on the base. We are able to cast our motion planner as a nonholonomic rapidly-exploring random tree (RRT) by representing the floating-base dynamics as pfaffian constraints on joint velocity. These constraints guide the manipulators to move on zero-perturbation manifolds (which inhabit a subspace of the tangent space of the internal configuration space). To invoke this representation (termed a \\textit{perturbation map}) we assume the body velocity (perturbation) of the base to be a joint-defined linear mapping of joint velocity and describe situations where this assumption is realistic (including underwater, aerial, and orbital environments). The core insight of this work is that when perturbation of the floating-base has affine structure with respect to joint velocity, it provides the system a class of kinematic reduction that permits the use of sample-based motion planners (specifically a nonholonomic RRT). We show that this allows rapid, exploration-geared motion planning for high degree of freedom systems in obstacle rich environments, even on floating-base systems with nontrivial dynamics.","sentences":["To achieve high-dexterity motion planning on floating-base systems, the base dynamics induced by arm motions must be treated carefully.","In general, it is a significant challenge to establish a fixed-base frame during tasking due to forces and torques on the base that arise directly from arm motions (e.g. arm drag in low Reynolds environments and arm momentum in high Reynolds environments).","While thrusters can in theory be used to regulate the vehicle pose, it is often insufficient to establish a stable pose for precise tasking, whether the cause be due to underactuation, modeling inaccuracy, suboptimal control parameters, or insufficient power.","We propose a solution that asks the thrusters to do less high bandwidth perturbation correction by planning arm motions that induce zero perturbation on the base.","We are able to cast our motion planner as a nonholonomic rapidly-exploring random tree (RRT) by representing the floating-base dynamics as pfaffian constraints on joint velocity.","These constraints guide the manipulators to move on zero-perturbation manifolds (which inhabit a subspace of the tangent space of the internal configuration space).","To invoke this representation (termed a \\textit{perturbation map}) we assume the body velocity (perturbation) of the base to be a joint-defined linear mapping of joint velocity and describe situations where this assumption is realistic (including underwater, aerial, and orbital environments).","The core insight of this work is that when perturbation of the floating-base has affine structure with respect to joint velocity, it provides the system a class of kinematic reduction that permits the use of sample-based motion planners (specifically a nonholonomic RRT).","We show that this allows rapid, exploration-geared motion planning for high degree of freedom systems in obstacle rich environments, even on floating-base systems with nontrivial dynamics."],"url":"http://arxiv.org/abs/2307.02383v1"}
{"created":"2023-07-05 15:47:22","title":"Expressiveness Results for an Inductive Logic of Separated Relations","abstract":"In this paper we study a Separation Logic of Relations (SLR) and compare its expressiveness to (Monadic)Second Order Logic (M)SO. SLR is based on the well-known Symbolic Heap fragment of Separation Logic, whose formulae are composed of points-to assertions, inductively defined predicates, with the separating conjunction as the only logical connective. SLR generalizes the Symbolic Heap fragment by supporting general relational atoms, instead of only points-to assertions. In this paper, we restrict ourselves to finite relational structures, and hence only consider Weak (M)SO, where quantification ranges over finite sets. Our main results are that SLR and MSO are incomparable on structures of unbounded treewidth, while SLR can be embedded in SO in general. Furthermore, MSO becomes a strict subset of SLR, when the treewidth of the models is bounded by a parameter and all vertices attached to some hyperedge belong to the interpretation of a fixed unary relation symbol. We also discuss the problem of identifying a fragment of SLR that is equivalent to MSO over models of bounded treewidth.","sentences":["In this paper we study a Separation Logic of Relations (SLR) and compare its expressiveness to (Monadic)Second Order Logic (M)SO.","SLR is based on the well-known Symbolic Heap fragment of Separation Logic, whose formulae are composed of points-to assertions, inductively defined predicates, with the separating conjunction as the only logical connective.","SLR generalizes the Symbolic Heap fragment by supporting general relational atoms, instead of only points-to assertions.","In this paper, we restrict ourselves to finite relational structures, and hence only consider Weak (M)SO, where quantification ranges over finite sets.","Our main results are that SLR and MSO are incomparable on structures of unbounded treewidth, while SLR can be embedded in SO in general.","Furthermore, MSO becomes a strict subset of SLR, when the treewidth of the models is bounded by a parameter and all vertices attached to some hyperedge belong to the interpretation of a fixed unary relation symbol.","We also discuss the problem of identifying a fragment of SLR that is equivalent to MSO over models of bounded treewidth."],"url":"http://arxiv.org/abs/2307.02381v1"}
{"created":"2023-07-05 15:38:45","title":"Planning and Control for a Dynamic Morphing-Wing UAV Using a Vortex Particle Model","abstract":"Achieving precise, highly-dynamic maneuvers with Unmanned Aerial Vehicles (UAVs) is a major challenge due to the complexity of the associated aerodynamics. In particular, unsteady effects -- as might be experienced in post-stall regimes or during sudden vehicle morphing -- can have an adverse impact on the performance of modern flight control systems. In this paper, we present a vortex particle model and associated model-based controller capable of reasoning about the unsteady aerodynamics during aggressive maneuvers. We evaluate our approach in hardware on a morphing-wing UAV executing post-stall perching maneuvers. Our results show that the use of the unsteady aerodynamics model improves performance during both fixed-wing and dynamic-wing perching, while the use of wing-morphing planned with quasi-steady aerodynamics results in reduced performance. While the focus of this paper is a pre-computed control policy, we believe that, with sufficient computational resources, our approach could enable online planning in the future.","sentences":["Achieving precise, highly-dynamic maneuvers with Unmanned Aerial Vehicles (UAVs) is a major challenge due to the complexity of the associated aerodynamics.","In particular, unsteady effects -- as might be experienced in post-stall regimes or during sudden vehicle morphing -- can have an adverse impact on the performance of modern flight control systems.","In this paper, we present a vortex particle model and associated model-based controller capable of reasoning about the unsteady aerodynamics during aggressive maneuvers.","We evaluate our approach in hardware on a morphing-wing UAV executing post-stall perching maneuvers.","Our results show that the use of the unsteady aerodynamics model improves performance during both fixed-wing and dynamic-wing perching, while the use of wing-morphing planned with quasi-steady aerodynamics results in reduced performance.","While the focus of this paper is a pre-computed control policy, we believe that, with sufficient computational resources, our approach could enable online planning in the future."],"url":"http://arxiv.org/abs/2307.02371v1"}
{"created":"2023-07-05 15:32:39","title":"Distance Preserving Machine Learning for Uncertainty Aware Accelerator Capacitance Predictions","abstract":"Providing accurate uncertainty estimations is essential for producing reliable machine learning models, especially in safety-critical applications such as accelerator systems. Gaussian process models are generally regarded as the gold standard method for this task, but they can struggle with large, high-dimensional datasets. Combining deep neural networks with Gaussian process approximation techniques have shown promising results, but dimensionality reduction through standard deep neural network layers is not guaranteed to maintain the distance information necessary for Gaussian process models. We build on previous work by comparing the use of the singular value decomposition against a spectral-normalized dense layer as a feature extractor for a deep neural Gaussian process approximation model and apply it to a capacitance prediction problem for the High Voltage Converter Modulators in the Oak Ridge Spallation Neutron Source. Our model shows improved distance preservation and predicts in-distribution capacitance values with less than 1% error.","sentences":["Providing accurate uncertainty estimations is essential for producing reliable machine learning models, especially in safety-critical applications such as accelerator systems.","Gaussian process models are generally regarded as the gold standard method for this task, but they can struggle with large, high-dimensional datasets.","Combining deep neural networks with Gaussian process approximation techniques have shown promising results, but dimensionality reduction through standard deep neural network layers is not guaranteed to maintain the distance information necessary for Gaussian process models.","We build on previous work by comparing the use of the singular value decomposition against a spectral-normalized dense layer as a feature extractor for a deep neural Gaussian process approximation model and apply it to a capacitance prediction problem for the High Voltage Converter Modulators in the Oak Ridge Spallation Neutron Source.","Our model shows improved distance preservation and predicts in-distribution capacitance values with less than 1% error."],"url":"http://arxiv.org/abs/2307.02367v1"}
{"created":"2023-07-05 15:18:52","title":"To be or not to be: a translation reception study of a literary text translated into Dutch and Catalan using machine translation","abstract":"This article presents the results of a study involving the reception of a fictional story by Kurt Vonnegut translated from English into Catalan and Dutch in three conditions: machine-translated (MT), post-edited (PE) and translated from scratch (HT). 223 participants were recruited who rated the reading conditions using three scales: Narrative Engagement, Enjoyment and Translation Reception. The results show that HT presented a higher engagement, enjoyment and translation reception in Catalan if compared to PE and MT. However, the Dutch readers show higher scores in PE than in both HT and MT, and the highest engagement and enjoyments scores are reported when reading the original English version. We hypothesize that when reading a fictional story in translation, not only the condition and the quality of the translations is key to understand its reception, but also the participants reading patterns, reading language, and, perhaps language status in their own societies.","sentences":["This article presents the results of a study involving the reception of a fictional story by Kurt Vonnegut translated from English into Catalan and Dutch in three conditions: machine-translated (MT), post-edited (PE) and translated from scratch (HT).","223 participants were recruited who rated the reading conditions using three scales: Narrative Engagement, Enjoyment and Translation Reception.","The results show that HT presented a higher engagement, enjoyment and translation reception in Catalan if compared to PE and MT.","However, the Dutch readers show higher scores in PE than in both HT and MT, and the highest engagement and enjoyments scores are reported when reading the original English version.","We hypothesize that when reading a fictional story in translation, not only the condition and the quality of the translations is key to understand its reception, but also the participants reading patterns, reading language, and, perhaps language status in their own societies."],"url":"http://arxiv.org/abs/2307.02358v1"}
{"created":"2023-07-05 15:18:15","title":"Decentralized Data Governance as Part of a Data Mesh Platform: Concepts and Approaches","abstract":"Data mesh is a socio-technical approach to decentralized analytics data management. To manage this decentralization efficiently, data mesh relies on automation provided by a self-service data infrastructure platform. A key aspect of this platform is to enable decentralized data governance. Because data mesh is a young approach, there is a lack of coherence in how data mesh concepts are interpreted in the industry, and almost no work on how a data mesh platform facilitates governance. This paper presents a conceptual model of key data mesh concepts and discusses different approaches to drive governance through platform means. The insights presented are drawn from concrete experiences of implementing a fully-functional data mesh platform that can be used as a reference on how to approach data mesh platform development.","sentences":["Data mesh is a socio-technical approach to decentralized analytics data management.","To manage this decentralization efficiently, data mesh relies on automation provided by a self-service data infrastructure platform.","A key aspect of this platform is to enable decentralized data governance.","Because data mesh is a young approach, there is a lack of coherence in how data mesh concepts are interpreted in the industry, and almost no work on how a data mesh platform facilitates governance.","This paper presents a conceptual model of key data mesh concepts and discusses different approaches to drive governance through platform means.","The insights presented are drawn from concrete experiences of implementing a fully-functional data mesh platform that can be used as a reference on how to approach data mesh platform development."],"url":"http://arxiv.org/abs/2307.02357v1"}
{"created":"2023-07-05 15:08:34","title":"Error Approximation and Bias Correction in Dynamic Problems using a Recurrent Neural Network/Finite Element Hybrid Model","abstract":"This work proposes a hybrid modeling framework based on recurrent neural networks (RNNs) and the finite element (FE) method to approximate model discrepancies in time dependent, multi-fidelity problems, and use the trained hybrid models to perform bias correction of the low-fidelity models. The hybrid model uses FE basis functions as a spatial basis and RNNs for the approximation of the time dependencies of the FE basis' degrees of freedom. The training data sets consist of sparse, non-uniformly sampled snapshots of the discrepancy function, pre-computed from trajectory data of low- and high-fidelity dynamic FE models. To account for data sparsity and prevent overfitting, data upsampling and local weighting factors are employed, to instigate a trade-off between physically conforming model behavior and neural network regression. The proposed hybrid modeling methodology is showcased in three highly non-trivial engineering test-cases, all featuring transient FE models, namely, heat diffusion out of a heat sink, eddy-currents in a quadrupole magnet, and sound wave propagation in a cavity. The results show that the proposed hybrid model is capable of approximating model discrepancies to a high degree of accuracy and accordingly correct low-fidelity models.","sentences":["This work proposes a hybrid modeling framework based on recurrent neural networks (RNNs) and the finite element (FE) method to approximate model discrepancies in time dependent, multi-fidelity problems, and use the trained hybrid models to perform bias correction of the low-fidelity models.","The hybrid model uses FE basis functions as a spatial basis and RNNs for the approximation of the time dependencies of the FE basis' degrees of freedom.","The training data sets consist of sparse, non-uniformly sampled snapshots of the discrepancy function, pre-computed from trajectory data of low- and high-fidelity dynamic FE models.","To account for data sparsity and prevent overfitting, data upsampling and local weighting factors are employed, to instigate a trade-off between physically conforming model behavior and neural network regression.","The proposed hybrid modeling methodology is showcased in three highly non-trivial engineering test-cases, all featuring transient FE models, namely, heat diffusion out of a heat sink, eddy-currents in a quadrupole magnet, and sound wave propagation in a cavity.","The results show that the proposed hybrid model is capable of approximating model discrepancies to a high degree of accuracy and accordingly correct low-fidelity models."],"url":"http://arxiv.org/abs/2307.02349v2"}
{"created":"2023-07-05 15:03:10","title":"Detecting Images Generated by Deep Diffusion Models using their Local Intrinsic Dimensionality","abstract":"Diffusion models recently have been successfully applied for the visual synthesis of strikingly realistic appearing images. This raises strong concerns about their potential for malicious purposes. In this paper, we propose using the lightweight multi Local Intrinsic Dimensionality (multiLID), which has been originally developed in context of the detection of adversarial examples, for the automatic detection of synthetic images and the identification of the according generator networks. In contrast to many existing detection approaches, which often only work for GAN-generated images, the proposed method provides close to perfect detection results in many realistic use cases. Extensive experiments on known and newly created datasets demonstrate that multiLID exhibits superiority in diffusion detection and model identification. Since the empirical evaluations of recent publications on the detection of generated images is often too focused on the \"LSUN-Bedroom\" dataset, we further establish a comprehensive benchmark for the detection of diffusion-generated images, including samples from several diffusion models with different image sizes to evaluate the performance of their multiLID.   Code for our experiments is provided at https://github.com/deepfake-study/deepfake_multiLID.","sentences":["Diffusion models recently have been successfully applied for the visual synthesis of strikingly realistic appearing images.","This raises strong concerns about their potential for malicious purposes.","In this paper, we propose using the lightweight multi Local Intrinsic Dimensionality (multiLID), which has been originally developed in context of the detection of adversarial examples, for the automatic detection of synthetic images and the identification of the according generator networks.","In contrast to many existing detection approaches, which often only work for GAN-generated images, the proposed method provides close to perfect detection results in many realistic use cases.","Extensive experiments on known and newly created datasets demonstrate that multiLID exhibits superiority in diffusion detection and model identification.","Since the empirical evaluations of recent publications on the detection of generated images is often too focused on the \"LSUN-Bedroom\" dataset, we further establish a comprehensive benchmark for the detection of diffusion-generated images, including samples from several diffusion models with different image sizes to evaluate the performance of their multiLID.   ","Code for our experiments is provided at https://github.com/deepfake-study/deepfake_multiLID."],"url":"http://arxiv.org/abs/2307.02347v1"}
{"created":"2023-07-05 15:00:29","title":"LLQL: Logistic Likelihood Q-Learning for Reinforcement Learning","abstract":"Currently, research on Reinforcement learning (RL) can be broadly classified into two categories: online RL and offline RL. Both in online and offline RL, the primary focus of research on the Bellman error lies in the optimization techniques and performance improvement, rather than exploring the inherent structural properties of the Bellman error, such as distribution characteristics. In this study, we analyze the distribution of the Bellman approximation error in both online and offline settings. We find that in the online environment, the Bellman error follows a Logistic distribution, while in the offline environment, the Bellman error follows a constrained Logistic distribution, where the constrained distribution is dependent on the prior policy in the offline data set. Based on this finding, we have improved the MSELoss which is based on the assumption that the Bellman errors follow a normal distribution, and we utilized the Logistic maximum likelihood function to construct $\\rm LLoss$ as an alternative loss function. In addition, we observed that the rewards in the offline data set should follow a specific distribution, which would facilitate the achievement of offline objectives. In our numerical experiments, we performed controlled variable corrections on the loss functions of two variants of Soft-Actor-Critic in both online and offline environments. The results confirmed our hypothesis regarding the online and offline settings, we also found that the variance of LLoss is smaller than MSELoss. Our research provides valuable insights for further investigations based on the distribution of Bellman errors.","sentences":["Currently, research on Reinforcement learning (RL) can be broadly classified into two categories: online RL and offline RL.","Both in online and offline RL, the primary focus of research on the Bellman error lies in the optimization techniques and performance improvement, rather than exploring the inherent structural properties of the Bellman error, such as distribution characteristics.","In this study, we analyze the distribution of the Bellman approximation error in both online and offline settings.","We find that in the online environment, the Bellman error follows a Logistic distribution, while in the offline environment, the Bellman error follows a constrained Logistic distribution, where the constrained distribution is dependent on the prior policy in the offline data set.","Based on this finding, we have improved the MSELoss which is based on the assumption that the Bellman errors follow a normal distribution, and we utilized the Logistic maximum likelihood function to construct $\\rm LLoss$ as an alternative loss function.","In addition, we observed that the rewards in the offline data set should follow a specific distribution, which would facilitate the achievement of offline objectives.","In our numerical experiments, we performed controlled variable corrections on the loss functions of two variants of Soft-Actor-Critic in both online and offline environments.","The results confirmed our hypothesis regarding the online and offline settings, we also found that the variance of LLoss is smaller than MSELoss.","Our research provides valuable insights for further investigations based on the distribution of Bellman errors."],"url":"http://arxiv.org/abs/2307.02345v1"}
{"created":"2023-07-05 14:56:03","title":"Towards a Formal Verification of the Lightning Network with TLA+","abstract":"Payment channel networks are an approach to improve the scalability of blockchain-based cryptocurrencies. Because payment channel networks are used for transfer of financial value, their security in the presence of adversarial participants should be verified formally. We formalize the protocol of the Lightning Network, a payment channel network built for Bitcoin, and show that the protocol fulfills the expected security properties. As the state space of a specification consisting of multiple participants is too large for model checking, we formalize intermediate specifications and use a chain of refinements to validate the security properties where each refinement is justified either by model checking or by a pen-and-paper proof.","sentences":["Payment channel networks are an approach to improve the scalability of blockchain-based cryptocurrencies.","Because payment channel networks are used for transfer of financial value, their security in the presence of adversarial participants should be verified formally.","We formalize the protocol of the Lightning Network, a payment channel network built for Bitcoin, and show that the protocol fulfills the expected security properties.","As the state space of a specification consisting of multiple participants is too large for model checking, we formalize intermediate specifications and use a chain of refinements to validate the security properties where each refinement is justified either by model checking or by a pen-and-paper proof."],"url":"http://arxiv.org/abs/2307.02342v1"}
{"created":"2023-07-05 14:55:18","title":"MuLMS-AZ: An Argumentative Zoning Dataset for the Materials Science Domain","abstract":"Scientific publications follow conventionalized rhetorical structures. Classifying the Argumentative Zone (AZ), e.g., identifying whether a sentence states a Motivation, a Result or Background information, has been proposed to improve processing of scholarly documents. In this work, we adapt and extend this idea to the domain of materials science research. We present and release a new dataset of 50 manually annotated research articles. The dataset spans seven sub-topics and is annotated with a materials-science focused multi-label annotation scheme for AZ. We detail corpus statistics and demonstrate high inter-annotator agreement. Our computational experiments show that using domain-specific pre-trained transformer-based text encoders is key to high classification performance. We also find that AZ categories from existing datasets in other domains are transferable to varying degrees.","sentences":["Scientific publications follow conventionalized rhetorical structures.","Classifying the Argumentative Zone (AZ), e.g., identifying whether a sentence states a Motivation, a Result or Background information, has been proposed to improve processing of scholarly documents.","In this work, we adapt and extend this idea to the domain of materials science research.","We present and release a new dataset of 50 manually annotated research articles.","The dataset spans seven sub-topics and is annotated with a materials-science focused multi-label annotation scheme for AZ.","We detail corpus statistics and demonstrate high inter-annotator agreement.","Our computational experiments show that using domain-specific pre-trained transformer-based text encoders is key to high classification performance.","We also find that AZ categories from existing datasets in other domains are transferable to varying degrees."],"url":"http://arxiv.org/abs/2307.02340v1"}
{"created":"2023-07-05 14:50:36","title":"GAFAR: Graph-Attention Feature-Augmentation for Registration A Fast and Light-weight Point Set Registration Algorithm","abstract":"Rigid registration of point clouds is a fundamental problem in computer vision with many applications from 3D scene reconstruction to geometry capture and robotics. If a suitable initial registration is available, conventional methods like ICP and its many variants can provide adequate solutions. In absence of a suitable initialization and in the presence of a high outlier rate or in the case of small overlap though the task of rigid registration still presents great challenges. The advent of deep learning in computer vision has brought new drive to research on this topic, since it provides the possibility to learn expressive feature-representations and provide one-shot estimates instead of depending on time-consuming iterations of conventional robust methods. Yet, the rotation and permutation invariant nature of point clouds poses its own challenges to deep learning, resulting in loss of performance and low generalization capability due to sensitivity to outliers and characteristics of 3D scans not present during network training. In this work, we present a novel fast and light-weight network architecture using the attention mechanism to augment point descriptors at inference time to optimally suit the registration task of the specific point clouds it is presented with. Employing a fully-connected graph both within and between point clouds lets the network reason about the importance and reliability of points for registration, making our approach robust to outliers, low overlap and unseen data. We test the performance of our registration algorithm on different registration and generalization tasks and provide information on runtime and resource consumption. The code and trained weights are available at https://github.com/mordecaimalignatius/GAFAR/.","sentences":["Rigid registration of point clouds is a fundamental problem in computer vision with many applications from 3D scene reconstruction to geometry capture and robotics.","If a suitable initial registration is available, conventional methods like ICP and its many variants can provide adequate solutions.","In absence of a suitable initialization and in the presence of a high outlier rate or in the case of small overlap though the task of rigid registration still presents great challenges.","The advent of deep learning in computer vision has brought new drive to research on this topic, since it provides the possibility to learn expressive feature-representations and provide one-shot estimates instead of depending on time-consuming iterations of conventional robust methods.","Yet, the rotation and permutation invariant nature of point clouds poses its own challenges to deep learning, resulting in loss of performance and low generalization capability due to sensitivity to outliers and characteristics of 3D scans not present during network training.","In this work, we present a novel fast and light-weight network architecture using the attention mechanism to augment point descriptors at inference time to optimally suit the registration task of the specific point clouds it is presented with.","Employing a fully-connected graph both within and between point clouds lets the network reason about the importance and reliability of points for registration, making our approach robust to outliers, low overlap and unseen data.","We test the performance of our registration algorithm on different registration and generalization tasks and provide information on runtime and resource consumption.","The code and trained weights are available at https://github.com/mordecaimalignatius/GAFAR/."],"url":"http://arxiv.org/abs/2307.02339v1"}
{"created":"2023-07-05 14:48:24","title":"FAM: Relative Flatness Aware Minimization","abstract":"Flatness of the loss curve around a model at hand has been shown to empirically correlate with its generalization ability. Optimizing for flatness has been proposed as early as 1994 by Hochreiter and Schmidthuber, and was followed by more recent successful sharpness-aware optimization techniques. Their widespread adoption in practice, though, is dubious because of the lack of theoretically grounded connection between flatness and generalization, in particular in light of the reparameterization curse - certain reparameterizations of a neural network change most flatness measures but do not change generalization. Recent theoretical work suggests that a particular relative flatness measure can be connected to generalization and solves the reparameterization curse. In this paper, we derive a regularizer based on this relative flatness that is easy to compute, fast, efficient, and works with arbitrary loss functions. It requires computing the Hessian only of a single layer of the network, which makes it applicable to large neural networks, and with it avoids an expensive mapping of the loss surface in the vicinity of the model. In an extensive empirical evaluation we show that this relative flatness aware minimization (FAM) improves generalization in a multitude of applications and models, both in finetuning and standard training. We make the code available at github.","sentences":["Flatness of the loss curve around a model at hand has been shown to empirically correlate with its generalization ability.","Optimizing for flatness has been proposed as early as 1994 by Hochreiter and Schmidthuber, and was followed by more recent successful sharpness-aware optimization techniques.","Their widespread adoption in practice, though, is dubious because of the lack of theoretically grounded connection between flatness and generalization, in particular in light of the reparameterization curse - certain reparameterizations of a neural network change most flatness measures but do not change generalization.","Recent theoretical work suggests that a particular relative flatness measure can be connected to generalization and solves the reparameterization curse.","In this paper, we derive a regularizer based on this relative flatness that is easy to compute, fast, efficient, and works with arbitrary loss functions.","It requires computing the Hessian only of a single layer of the network, which makes it applicable to large neural networks, and with it avoids an expensive mapping of the loss surface in the vicinity of the model.","In an extensive empirical evaluation we show that this relative flatness aware minimization (FAM) improves generalization in a multitude of applications and models, both in finetuning and standard training.","We make the code available at github."],"url":"http://arxiv.org/abs/2307.02337v1"}
{"created":"2023-07-05 14:42:02","title":"Co-creating a Transdisciplinary Map of Technology-mediated Harms, Risks and Vulnerabilities: Challenges, Ambivalences and Opportunities","abstract":"The phrase \"online harms\" has emerged in recent years out of a growing political willingness to address the ethical and social issues associated with the use of the Internet and digital technology at large. The broad landscape that surrounds online harms gathers a multitude of disciplinary, sectoral and organizational efforts while raising myriad challenges and opportunities for the crossing entrenched boundaries. In this paper we draw lessons from a journey of co-creating a transdisciplinary knowledge infrastructure within a large research initiative animated by the online harms agenda. We begin with a reflection of the implications of mapping, taxonomizing and constructing knowledge infrastructures and a brief review of how online harm and adjacent themes have been theorized and classified in the literature to date. Grounded on our own experience of co-creating a map of online harms, we then argue that the map -- and the process of mapping -- perform three mutually constitutive functions, acting simultaneously as method, medium and provocation. We draw lessons from how an open-ended approach to mapping, despite not guaranteeing consensus, can foster productive debate and collaboration in ethically and politically fraught areas of research. We end with a call for CSCW research to surface and engage with the multiple temporalities, social lives and political sensibilities of knowledge infrastructures.","sentences":["The phrase \"online harms\" has emerged in recent years out of a growing political willingness to address the ethical and social issues associated with the use of the Internet and digital technology at large.","The broad landscape that surrounds online harms gathers a multitude of disciplinary, sectoral and organizational efforts while raising myriad challenges and opportunities for the crossing entrenched boundaries.","In this paper we draw lessons from a journey of co-creating a transdisciplinary knowledge infrastructure within a large research initiative animated by the online harms agenda.","We begin with a reflection of the implications of mapping, taxonomizing and constructing knowledge infrastructures and a brief review of how online harm and adjacent themes have been theorized and classified in the literature to date.","Grounded on our own experience of co-creating a map of online harms, we then argue that the map -- and the process of mapping -- perform three mutually constitutive functions, acting simultaneously as method, medium and provocation.","We draw lessons from how an open-ended approach to mapping, despite not guaranteeing consensus, can foster productive debate and collaboration in ethically and politically fraught areas of research.","We end with a call for CSCW research to surface and engage with the multiple temporalities, social lives and political sensibilities of knowledge infrastructures."],"url":"http://arxiv.org/abs/2307.02332v1"}
{"created":"2023-07-05 14:40:23","title":"References and citations in NIME papers","abstract":"This paper presents a bibliographic study that analyzes works cited in as well as works that cite NIME papers. We build on existing tools to computationally analyze data retrieved from publicly available databases. We present a variety of metrics, statistics, visualizations and trends aiming to provide quantitative figures on the scholarly impact of NIME, influential authors, related publication venues, associated fields of study, and key works published in other venues.","sentences":["This paper presents a bibliographic study that analyzes works cited in as well as works that cite NIME papers.","We build on existing tools to computationally analyze data retrieved from publicly available databases.","We present a variety of metrics, statistics, visualizations and trends aiming to provide quantitative figures on the scholarly impact of NIME, influential authors, related publication venues, associated fields of study, and key works published in other venues."],"url":"http://arxiv.org/abs/2307.02330v1"}
{"created":"2023-07-05 14:39:47","title":"Data-driven Predictive Latency for 5G: A Theoretical and Experimental Analysis Using Network Measurements","abstract":"The advent of novel 5G services and applications with binding latency requirements and guaranteed Quality of Service (QoS) hastened the need to incorporate autonomous and proactive decision-making in network management procedures. The objective of our study is to provide a thorough analysis of predictive latency within 5G networks by utilizing real-world network data that is accessible to mobile network operators (MNOs). In particular, (i) we present an analytical formulation of the user-plane latency as a Hypoexponential distribution, which is validated by means of a comparative analysis with empirical measurements, and (ii) we conduct experimental results of probabilistic regression, anomaly detection, and predictive forecasting leveraging on emerging domains in Machine Learning (ML), such as Bayesian Learning (BL) and Machine Learning on Graphs (GML). We test our predictive framework using data gathered from scenarios of vehicular mobility, dense-urban traffic, and social gathering events. Our results provide valuable insights into the efficacy of predictive algorithms in practical applications.","sentences":["The advent of novel 5G services and applications with binding latency requirements and guaranteed Quality of Service (QoS) hastened the need to incorporate autonomous and proactive decision-making in network management procedures.","The objective of our study is to provide a thorough analysis of predictive latency within 5G networks by utilizing real-world network data that is accessible to mobile network operators (MNOs).","In particular, (i) we present an analytical formulation of the user-plane latency as a Hypoexponential distribution, which is validated by means of a comparative analysis with empirical measurements, and (ii) we conduct experimental results of probabilistic regression, anomaly detection, and predictive forecasting leveraging on emerging domains in Machine Learning (ML), such as Bayesian Learning (BL) and Machine Learning on Graphs (GML).","We test our predictive framework using data gathered from scenarios of vehicular mobility, dense-urban traffic, and social gathering events.","Our results provide valuable insights into the efficacy of predictive algorithms in practical applications."],"url":"http://arxiv.org/abs/2307.02329v1"}
{"created":"2023-07-05 14:30:41","title":"Security Defect Detection via Code Review: A Study of the OpenStack and Qt Communities","abstract":"Background: Despite the widespread use of automated security defect detection tools, software projects still contain many security defects that could result in serious damage. Such tools are largely context-insensitive and may not cover all possible scenarios in testing potential issues, which makes them susceptible to missing complex security defects. Hence, thorough detection entails a synergistic cooperation between these tools and human-intensive detection techniques, including code review. Code review is widely recognized as a crucial and effective practice for identifying security defects. Aim: This work aims to empirically investigate security defect detection through code review. Method: To this end, we conducted an empirical study by analyzing code review comments derived from four projects in the OpenStack and Qt communities. Through manually checking 20,995 review comments obtained by keyword-based search, we identified 614 comments as security-related. Results: Our results show that (1) security defects are not prevalently discussed in code review, (2) more than half of the reviewers provided explicit fixing strategies/solutions to help developers fix security defects, (3) developers tend to follow reviewers' suggestions and action the changes, (4) Not worth fixing the defect now and Disagreement between the developer and the reviewer are the main causes for not resolving security defects. Conclusions: Our research results demonstrate that (1) software security practices should combine manual code review with automated detection tools, achieving a more comprehensive coverage to identifying and addressing security defects, and (2) promoting appropriate standardization of practitioners' behaviors during code review remains necessary for enhancing software security.","sentences":["Background: Despite the widespread use of automated security defect detection tools, software projects still contain many security defects that could result in serious damage.","Such tools are largely context-insensitive and may not cover all possible scenarios in testing potential issues, which makes them susceptible to missing complex security defects.","Hence, thorough detection entails a synergistic cooperation between these tools and human-intensive detection techniques, including code review.","Code review is widely recognized as a crucial and effective practice for identifying security defects.","Aim: This work aims to empirically investigate security defect detection through code review.","Method: To this end, we conducted an empirical study by analyzing code review comments derived from four projects in the OpenStack and Qt communities.","Through manually checking 20,995 review comments obtained by keyword-based search, we identified 614 comments as security-related.","Results:","Our results show that (1) security defects are not prevalently discussed in code review, (2) more than half of the reviewers provided explicit fixing strategies/solutions to help developers fix security defects, (3) developers tend to follow reviewers' suggestions and action the changes, (4) Not worth fixing the defect now and Disagreement between the developer and the reviewer are the main causes for not resolving security defects.","Conclusions: Our research results demonstrate that (1) software security practices should combine manual code review with automated detection tools, achieving a more comprehensive coverage to identifying and addressing security defects, and (2) promoting appropriate standardization of practitioners' behaviors during code review remains necessary for enhancing software security."],"url":"http://arxiv.org/abs/2307.02326v1"}
{"created":"2023-07-05 14:30:21","title":"Formally Verifying a Real World Smart Contract","abstract":"Nowadays, smart contracts have become increasingly popular and, as with software development in general, testing is the standard method for verifying their correctness. However, smart contracts require a higher level of certainty regarding correctness because they are diffcult to modify once deployed and errors can result in significant financial losses. Therefore, formal verification is essential. In this article, we present our search for a tool capable of formally verifying a real-world smart contract written in a recent version of Solidity.","sentences":["Nowadays, smart contracts have become increasingly popular and, as with software development in general, testing is the standard method for verifying their correctness.","However, smart contracts require a higher level of certainty regarding correctness because they are diffcult to modify once deployed and errors can result in significant financial losses.","Therefore, formal verification is essential.","In this article, we present our search for a tool capable of formally verifying a real-world smart contract written in a recent version of Solidity."],"url":"http://arxiv.org/abs/2307.02325v1"}
{"created":"2023-07-05 14:22:31","title":"MSViT: Dynamic Mixed-Scale Tokenization for Vision Transformers","abstract":"The input tokens to Vision Transformers carry little semantic meaning as they are defined as regular equal-sized patches of the input image, regardless of its content. However, processing uniform background areas of an image should not necessitate as much compute as dense, cluttered areas. To address this issue, we propose a dynamic mixed-scale tokenization scheme for ViT, MSViT. Our method introduces a conditional gating mechanism that selects the optimal token scale for every image region, such that the number of tokens is dynamically determined per input. The proposed gating module is lightweight, agnostic to the choice of transformer backbone, and trained within a few epochs (e.g., 20 epochs on ImageNet) with little training overhead. In addition, to enhance the conditional behavior of the gate during training, we introduce a novel generalization of the batch-shaping loss. We show that our gating module is able to learn meaningful semantics despite operating locally at the coarse patch-level. We validate MSViT on the tasks of classification and segmentation where it leads to improved accuracy-complexity trade-off.","sentences":["The input tokens to Vision Transformers carry little semantic meaning as they are defined as regular equal-sized patches of the input image, regardless of its content.","However, processing uniform background areas of an image should not necessitate as much compute as dense, cluttered areas.","To address this issue, we propose a dynamic mixed-scale tokenization scheme for ViT, MSViT.","Our method introduces a conditional gating mechanism that selects the optimal token scale for every image region, such that the number of tokens is dynamically determined per input.","The proposed gating module is lightweight, agnostic to the choice of transformer backbone, and trained within a few epochs (e.g., 20 epochs on ImageNet) with little training overhead.","In addition, to enhance the conditional behavior of the gate during training, we introduce a novel generalization of the batch-shaping loss.","We show that our gating module is able to learn meaningful semantics despite operating locally at the coarse patch-level.","We validate MSViT on the tasks of classification and segmentation where it leads to improved accuracy-complexity trade-off."],"url":"http://arxiv.org/abs/2307.02321v1"}
{"created":"2023-07-05 14:20:20","title":"Deep Contract Design via Discontinuous Piecewise Affine Neural Networks","abstract":"Contract design involves a principal who establishes contractual agreements about payments for outcomes that arise from the actions of an agent. In this paper, we initiate the study of deep learning for the automated design of optimal contracts. We formulate this as an offline learning problem, where a deep network is used to represent the principal's expected utility as a function of the design of a contract. We introduce a novel representation: the Discontinuous ReLU (DeLU) network, which models the principal's utility as a discontinuous piecewise affine function where each piece corresponds to the agent taking a particular action. DeLU networks implicitly learn closed-form expressions for the incentive compatibility constraints of the agent and the utility maximization objective of the principal, and support parallel inference on each piece through linear programming or interior-point methods that solve for optimal contracts. We provide empirical results that demonstrate success in approximating the principal's utility function with a small number of training samples and scaling to find approximately optimal contracts on problems with a large number of actions and outcomes.","sentences":["Contract design involves a principal who establishes contractual agreements about payments for outcomes that arise from the actions of an agent.","In this paper, we initiate the study of deep learning for the automated design of optimal contracts.","We formulate this as an offline learning problem, where a deep network is used to represent the principal's expected utility as a function of the design of a contract.","We introduce a novel representation: the Discontinuous ReLU (DeLU) network, which models the principal's utility as a discontinuous piecewise affine function where each piece corresponds to the agent taking a particular action.","DeLU networks implicitly learn closed-form expressions for the incentive compatibility constraints of the agent and the utility maximization objective of the principal, and support parallel inference on each piece through linear programming or interior-point methods that solve for optimal contracts.","We provide empirical results that demonstrate success in approximating the principal's utility function with a small number of training samples and scaling to find approximately optimal contracts on problems with a large number of actions and outcomes."],"url":"http://arxiv.org/abs/2307.02318v1"}
{"created":"2023-07-05 14:16:26","title":"Maximum edge colouring problem on graphs that exclude a fixed minor","abstract":"The maximum edge colouring problem considers the maximum colour assignment to edges of a graph under the condition that every vertex has at most a fixed number of distinct coloured edges incident on it. If that fixed number is $q$ we call the colouring a maximum edge $q$-colouring. The problem models a non-overlapping frequency channel assignment question on wireless networks. The problem has also been studied from a purely combinatorial perspective in the graph theory literature.   We study the question when the input graph is sparse. We show the problem remains $NP$-hard on $1$-apex graphs. We also show that there exists $PTAS$ for the problem on minor-free graphs. The $PTAS$ is based on a recently developed Baker game technique for proper minor-closed classes, thus avoiding the need to use any involved structural results. This further pushes the Baker game technique beyond the problems expressible in the first-order logic.","sentences":["The maximum edge colouring problem considers the maximum colour assignment to edges of a graph under the condition that every vertex has at most a fixed number of distinct coloured edges incident on it.","If that fixed number is $q$ we call the colouring a maximum edge $q$-colouring.","The problem models a non-overlapping frequency channel assignment question on wireless networks.","The problem has also been studied from a purely combinatorial perspective in the graph theory literature.   ","We study the question when the input graph is sparse.","We show the problem remains $NP$-hard on $1$-apex graphs.","We also show that there exists $PTAS$ for the problem on minor-free graphs.","The $PTAS$ is based on a recently developed Baker game technique for proper minor-closed classes, thus avoiding the need to use any involved structural results.","This further pushes the Baker game technique beyond the problems expressible in the first-order logic."],"url":"http://arxiv.org/abs/2307.02314v1"}
{"created":"2023-07-05 14:15:15","title":"Utilizing ChatGPT Generated Data to Retrieve Depression Symptoms from Social Media","abstract":"In this work, we present the contribution of the BLUE team in the eRisk Lab task on searching for symptoms of depression. The task consists of retrieving and ranking Reddit social media sentences that convey symptoms of depression from the BDI-II questionnaire. Given that synthetic data provided by LLMs have been proven to be a reliable method for augmenting data and fine-tuning downstream models, we chose to generate synthetic data using ChatGPT for each of the symptoms of the BDI-II questionnaire. We designed a prompt such that the generated data contains more richness and semantic diversity than the BDI-II responses for each question and, at the same time, contains emotional and anecdotal experiences that are specific to the more intimate way of sharing experiences on Reddit. We perform semantic search and rank the sentences' relevance to the BDI-II symptoms by cosine similarity. We used two state-of-the-art transformer-based models for embedding the social media posts, the original and generated responses of the BDI-II, MentalRoBERTa and a variant of MPNet. Our results show that an approach using for sentence embeddings a model that is designed for semantic search outperforms the model pre-trained on mental health data. Furthermore, the generated synthetic data were proved too specific for this task, the approach simply relying on the BDI-II responses had the best performance.","sentences":["In this work, we present the contribution of the BLUE team in the eRisk Lab task on searching for symptoms of depression.","The task consists of retrieving and ranking Reddit social media sentences that convey symptoms of depression from the BDI-II questionnaire.","Given that synthetic data provided by LLMs have been proven to be a reliable method for augmenting data and fine-tuning downstream models, we chose to generate synthetic data using ChatGPT for each of the symptoms of the BDI-II questionnaire.","We designed a prompt such that the generated data contains more richness and semantic diversity than the BDI-II responses for each question and, at the same time, contains emotional and anecdotal experiences that are specific to the more intimate way of sharing experiences on Reddit.","We perform semantic search and rank the sentences' relevance to the BDI-II symptoms by cosine similarity.","We used two state-of-the-art transformer-based models for embedding the social media posts, the original and generated responses of the BDI-II, MentalRoBERTa and a variant of MPNet.","Our results show that an approach using for sentence embeddings a model that is designed for semantic search outperforms the model pre-trained on mental health data.","Furthermore, the generated synthetic data were proved too specific for this task, the approach simply relying on the BDI-II responses had the best performance."],"url":"http://arxiv.org/abs/2307.02313v1"}
{"created":"2023-07-05 14:10:29","title":"Multi-Scale Prototypical Transformer for Whole Slide Image Classification","abstract":"Whole slide image (WSI) classification is an essential task in computational pathology. Despite the recent advances in multiple instance learning (MIL) for WSI classification, accurate classification of WSIs remains challenging due to the extreme imbalance between the positive and negative instances in bags, and the complicated pre-processing to fuse multi-scale information of WSI. To this end, we propose a novel multi-scale prototypical Transformer (MSPT) for WSI classification, which includes a prototypical Transformer (PT) module and a multi-scale feature fusion module (MFFM). The PT is developed to reduce redundant instances in bags by integrating prototypical learning into the Transformer architecture. It substitutes all instances with cluster prototypes, which are then re-calibrated through the self-attention mechanism of the Trans-former. Thereafter, an MFFM is proposed to fuse the clustered prototypes of different scales, which employs MLP-Mixer to enhance the information communication between prototypes. The experimental results on two public WSI datasets demonstrate that the proposed MSPT outperforms all the compared algorithms, suggesting its potential applications.","sentences":["Whole slide image (WSI) classification is an essential task in computational pathology.","Despite the recent advances in multiple instance learning (MIL) for WSI classification, accurate classification of WSIs remains challenging due to the extreme imbalance between the positive and negative instances in bags, and the complicated pre-processing to fuse multi-scale information of WSI.","To this end, we propose a novel multi-scale prototypical Transformer (MSPT) for WSI classification, which includes a prototypical Transformer (PT) module and a multi-scale feature fusion module (MFFM).","The PT is developed to reduce redundant instances in bags by integrating prototypical learning into the Transformer architecture.","It substitutes all instances with cluster prototypes, which are then re-calibrated through the self-attention mechanism of the Trans-former.","Thereafter, an MFFM is proposed to fuse the clustered prototypes of different scales, which employs MLP-Mixer to enhance the information communication between prototypes.","The experimental results on two public WSI datasets demonstrate that the proposed MSPT outperforms all the compared algorithms, suggesting its potential applications."],"url":"http://arxiv.org/abs/2307.02308v1"}
{"created":"2023-07-05 13:59:35","title":"Sumformer: Universal Approximation for Efficient Transformers","abstract":"Natural language processing (NLP) made an impressive jump with the introduction of Transformers. ChatGPT is one of the most famous examples, changing the perception of the possibilities of AI even outside the research community. However, besides the impressive performance, the quadratic time and space complexity of Transformers with respect to sequence length pose significant limitations for handling long sequences. While efficient Transformer architectures like Linformer and Performer with linear complexity have emerged as promising solutions, their theoretical understanding remains limited. In this paper, we introduce Sumformer, a novel and simple architecture capable of universally approximating equivariant sequence-to-sequence functions. We use Sumformer to give the first universal approximation results for Linformer and Performer. Moreover, we derive a new proof for Transformers, showing that just one attention layer is sufficient for universal approximation.","sentences":["Natural language processing (NLP) made an impressive jump with the introduction of Transformers.","ChatGPT is one of the most famous examples, changing the perception of the possibilities of AI even outside the research community.","However, besides the impressive performance, the quadratic time and space complexity of Transformers with respect to sequence length pose significant limitations for handling long sequences.","While efficient Transformer architectures like Linformer and Performer with linear complexity have emerged as promising solutions, their theoretical understanding remains limited.","In this paper, we introduce Sumformer, a novel and simple architecture capable of universally approximating equivariant sequence-to-sequence functions.","We use Sumformer to give the first universal approximation results for Linformer and Performer.","Moreover, we derive a new proof for Transformers, showing that just one attention layer is sufficient for universal approximation."],"url":"http://arxiv.org/abs/2307.02301v1"}
{"created":"2023-07-05 13:58:26","title":"Improving Address Matching using Siamese Transformer Networks","abstract":"Matching addresses is a critical task for companies and post offices involved in the processing and delivery of packages. The ramifications of incorrectly delivering a package to the wrong recipient are numerous, ranging from harm to the company's reputation to economic and environmental costs. This research introduces a deep learning-based model designed to increase the efficiency of address matching for Portuguese addresses. The model comprises two parts: (i) a bi-encoder, which is fine-tuned to create meaningful embeddings of Portuguese postal addresses, utilized to retrieve the top 10 likely matches of the un-normalized target address from a normalized database, and (ii) a cross-encoder, which is fine-tuned to accurately rerank the 10 addresses obtained by the bi-encoder. The model has been tested on a real-case scenario of Portuguese addresses and exhibits a high degree of accuracy, exceeding 95% at the door level. When utilized with GPU computations, the inference speed is about 4.5 times quicker than other traditional approaches such as BM25. An implementation of this system in a real-world scenario would substantially increase the effectiveness of the distribution process. Such an implementation is currently under investigation.","sentences":["Matching addresses is a critical task for companies and post offices involved in the processing and delivery of packages.","The ramifications of incorrectly delivering a package to the wrong recipient are numerous, ranging from harm to the company's reputation to economic and environmental costs.","This research introduces a deep learning-based model designed to increase the efficiency of address matching for Portuguese addresses.","The model comprises two parts: (i) a bi-encoder, which is fine-tuned to create meaningful embeddings of Portuguese postal addresses, utilized to retrieve the top 10 likely matches of the un-normalized target address from a normalized database, and (ii) a cross-encoder, which is fine-tuned to accurately rerank the 10 addresses obtained by the bi-encoder.","The model has been tested on a real-case scenario of Portuguese addresses and exhibits a high degree of accuracy, exceeding 95% at the door level.","When utilized with GPU computations, the inference speed is about 4.5 times quicker than other traditional approaches such as BM25.","An implementation of this system in a real-world scenario would substantially increase the effectiveness of the distribution process.","Such an implementation is currently under investigation."],"url":"http://arxiv.org/abs/2307.02300v1"}
{"created":"2023-07-05 13:52:10","title":"Meta-Learning Adversarial Bandit Algorithms","abstract":"We study online meta-learning with bandit feedback, with the goal of improving performance across multiple tasks if they are similar according to some natural similarity measure. As the first to target the adversarial online-within-online partial-information setting, we design meta-algorithms that combine outer learners to simultaneously tune the initialization and other hyperparameters of an inner learner for two important cases: multi-armed bandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners initialize and set hyperparameters of the Tsallis-entropy generalization of Exp3, with the task-averaged regret improving if the entropy of the optima-in-hindsight is small. For BLO, we learn to initialize and tune online mirror descent (OMD) with self-concordant barrier regularizers, showing that task-averaged regret varies directly with an action space-dependent measure they induce. Our guarantees rely on proving that unregularized follow-the-leader combined with two levels of low-dimensional hyperparameter tuning is enough to learn a sequence of affine functions of non-Lipschitz and sometimes non-convex Bregman divergences bounding the regret of OMD.","sentences":["We study online meta-learning with bandit feedback, with the goal of improving performance across multiple tasks if they are similar according to some natural similarity measure.","As the first to target the adversarial online-within-online partial-information setting, we design meta-algorithms that combine outer learners to simultaneously tune the initialization and other hyperparameters of an inner learner for two important cases: multi-armed bandits (MAB) and bandit linear optimization (BLO).","For MAB, the meta-learners initialize and set hyperparameters of the Tsallis-entropy generalization of Exp3, with the task-averaged regret improving if the entropy of the optima-in-hindsight is small.","For BLO, we learn to initialize and tune online mirror descent (OMD) with self-concordant barrier regularizers, showing that task-averaged regret varies directly with an action space-dependent measure they induce.","Our guarantees rely on proving that unregularized follow-the-leader combined with two levels of low-dimensional hyperparameter tuning is enough to learn a sequence of affine functions of non-Lipschitz and sometimes non-convex Bregman divergences bounding the regret of OMD."],"url":"http://arxiv.org/abs/2307.02295v1"}
{"created":"2023-07-05 13:51:15","title":"Sorting Pattern-Avoiding Permutations via 0-1 Matrices Forbidding Product Patterns","abstract":"We consider the problem of comparison-sorting an $n$-permutation $S$ that avoids some $k$-permutation $\\pi$. Chalermsook, Goswami, Kozma, Mehlhorn, and Saranurak prove that when $S$ is sorted by inserting the elements into the GreedyFuture binary search tree, the running time is linear in the extremal function $\\mathrm{Ex}(P_\\pi\\otimes \\text{hat},n)$. This is the maximum number of 1s in an $n\\times n$ 0-1 matrix avoiding $P_\\pi \\otimes \\text{hat}$, where $P_\\pi$ is the $k\\times k$ permutation matrix of $\\pi$, $\\otimes$ the Kronecker product, and $\\text{hat} = \\left(\\begin{array}{ccc}&\\bullet&\\\\\\bullet&&\\bullet\\end{array}\\right)$. The same time bound can be achieved by sorting $S$ with Kozma and Saranurak's SmoothHeap.   In this paper we give nearly tight upper and lower bounds on the density of $P_\\pi\\otimes\\text{hat}$-free matrices in terms of the inverse-Ackermann function $\\alpha(n)$. \\[ \\mathrm{Ex}(P_\\pi\\otimes \\text{hat},n) = \\left\\{\\begin{array}{ll} \\Omega(n\\cdot 2^{\\alpha(n)}), & \\mbox{for most $\\pi$,}\\\\ O(n\\cdot 2^{O(k^2)+(1+o(1))\\alpha(n)}), & \\mbox{for all $\\pi$.} \\end{array}\\right. \\] As a consequence, sorting $\\pi$-free sequences can be performed in $O(n2^{(1+o(1))\\alpha(n)})$ time. For many corollaries of the dynamic optimality conjecture, the best analysis uses forbidden 0-1 matrix theory. Our analysis may be useful in analyzing other classes of access sequences on binary search trees.","sentences":["We consider the problem of comparison-sorting an $n$-permutation $S$ that avoids some $k$-permutation $\\pi$. Chalermsook, Goswami, Kozma, Mehlhorn, and Saranurak prove that when $S$ is sorted by inserting the elements into the GreedyFuture binary search tree, the running time is linear in the extremal function $\\mathrm{Ex}(P_\\pi\\otimes \\text{hat},n)$.","This is the maximum number of 1s in an $n\\times n$ 0-1 matrix avoiding $P_\\pi \\otimes \\text{hat}$, where $P_\\pi$ is the $k\\times k$ permutation matrix of $\\pi$, $\\otimes$ the Kronecker product, and $\\text{hat} = \\left(\\begin{array}{ccc}&\\bullet&\\\\\\bullet&&\\bullet\\end{array}\\right)$. The same time bound can be achieved by sorting $S$ with Kozma and Saranurak's SmoothHeap.   ","In this paper we give nearly tight upper and lower bounds on the density of $P_\\pi\\otimes\\text{hat}$-free matrices in terms of the inverse-Ackermann function $\\alpha(n)$. \\[ \\mathrm{Ex}(P_\\pi\\otimes \\text{hat},n) = \\left\\{\\begin{array}{ll} \\Omega(n\\cdot 2^{\\alpha(n)}), & \\mbox{for most $\\pi$,}\\\\ O(n\\cdot 2^{O(k^2)+(1+o(1))\\alpha(n)}), & \\mbox{for all $\\pi$.} \\end{array}\\right.","\\]","As a consequence, sorting $\\pi$-free sequences can be performed in $O(n2^{(1+o(1))\\alpha(n)})$ time.","For many corollaries of the dynamic optimality conjecture, the best analysis uses forbidden 0-1 matrix theory.","Our analysis may be useful in analyzing other classes of access sequences on binary search trees."],"url":"http://arxiv.org/abs/2307.02294v1"}
{"created":"2023-07-05 13:42:31","title":"Focusing on what to decode and what to train: Efficient Training with HOI Split Decoders and Specific Target Guided DeNoising","abstract":"Recent one-stage transformer-based methods achieve notable gains in the Human-object Interaction Detection (HOI) task by leveraging the detection of DETR. However, the current methods redirect the detection target of the object decoder, and the box target is not explicitly separated from the query embeddings, which leads to long and hard training. Furthermore, matching the predicted HOI instances with the ground-truth is more challenging than object detection, simply adapting training strategies from the object detection makes the training more difficult. To clear the ambiguity between human and object detection and share the prediction burden, we propose a novel one-stage framework (SOV), which consists of a subject decoder, an object decoder, and a verb decoder. Moreover, we propose a novel Specific Target Guided (STG) DeNoising strategy, which leverages learnable object and verb label embeddings to guide the training and accelerates the training convergence. In addition, for the inference part, the label-specific information is directly fed into the decoders by initializing the query embeddings from the learnable label embeddings. Without additional features or prior language knowledge, our method (SOV-STG) achieves higher accuracy than the state-of-the-art method in one-third of training epochs. The code is available at \\url{https://github.com/cjw2021/SOV-STG}.","sentences":["Recent one-stage transformer-based methods achieve notable gains in the Human-object Interaction Detection (HOI) task by leveraging the detection of DETR.","However, the current methods redirect the detection target of the object decoder, and the box target is not explicitly separated from the query embeddings, which leads to long and hard training.","Furthermore, matching the predicted HOI instances with the ground-truth is more challenging than object detection, simply adapting training strategies from the object detection makes the training more difficult.","To clear the ambiguity between human and object detection and share the prediction burden, we propose a novel one-stage framework (SOV), which consists of a subject decoder, an object decoder, and a verb decoder.","Moreover, we propose a novel Specific Target Guided (STG) DeNoising strategy, which leverages learnable object and verb label embeddings to guide the training and accelerates the training convergence.","In addition, for the inference part, the label-specific information is directly fed into the decoders by initializing the query embeddings from the learnable label embeddings.","Without additional features or prior language knowledge, our method (SOV-STG) achieves higher accuracy than the state-of-the-art method in one-third of training epochs.","The code is available at \\url{https://github.com/cjw2021/SOV-STG}."],"url":"http://arxiv.org/abs/2307.02291v1"}
{"created":"2023-07-05 13:41:35","title":"Fuzzing with Quantitative and Adaptive Hot-Bytes Identification","abstract":"Fuzzing has emerged as a powerful technique for finding security bugs in complicated real-world applications. American fuzzy lop (AFL), a leading fuzzing tool, has demonstrated its powerful bug finding ability through a vast number of reported CVEs. However, its random mutation strategy is unable to generate test inputs that satisfy complicated branching conditions (e.g., magic-byte comparisons, checksum tests, and nested if-statements), which are commonly used in image decoders/encoders, XML parsers, and checksum tools. Existing approaches (such as Steelix and Neuzz) on addressing this problem assume unrealistic assumptions such as we can satisfy the branch condition byte-to-byte or we can identify and focus on the important bytes in the input (called hot-bytes) once and for all. In this work, we propose an approach called \\tool~which is designed based on the following principles. First, there is a complicated relation between inputs and branching conditions and thus we need not only an expressive model to capture such relationship but also an informative measure so that we can learn such relationship effectively. Second, different branching conditions demand different hot-bytes and we must adjust our fuzzing strategy adaptively depending on which branches are the current bottleneck. We implement our approach as an open source project and compare its efficiency with other state-of-the-art fuzzers. Our evaluation results on 10 real-world programs and LAVA-M dataset show that \\tool~achieves sustained increases in branch coverage and discovers more bugs than other fuzzers.","sentences":["Fuzzing has emerged as a powerful technique for finding security bugs in complicated real-world applications.","American fuzzy lop (AFL), a leading fuzzing tool, has demonstrated its powerful bug finding ability through a vast number of reported CVEs.","However, its random mutation strategy is unable to generate test inputs that satisfy complicated branching conditions (e.g., magic-byte comparisons, checksum tests, and nested if-statements), which are commonly used in image decoders/encoders, XML parsers, and checksum tools.","Existing approaches (such as Steelix and Neuzz) on addressing this problem assume unrealistic assumptions such as we can satisfy the branch condition byte-to-byte or we can identify and focus on the important bytes in the input (called hot-bytes) once and for all.","In this work, we propose an approach called \\tool~which is designed based on the following principles.","First, there is a complicated relation between inputs and branching conditions and thus we need not only an expressive model to capture such relationship but also an informative measure so that we can learn such relationship effectively.","Second, different branching conditions demand different hot-bytes and we must adjust our fuzzing strategy adaptively depending on which branches are the current bottleneck.","We implement our approach as an open source project and compare its efficiency with other state-of-the-art fuzzers.","Our evaluation results on 10 real-world programs and LAVA-M dataset show that \\tool~achieves sustained increases in branch coverage and discovers more bugs than other fuzzers."],"url":"http://arxiv.org/abs/2307.02289v1"}
{"created":"2023-07-05 13:40:57","title":"Performance Comparison of Large Language Models on VNHSGE English Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard","abstract":"This paper presents a performance comparison of three large language models (LLMs), namely OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard, on the VNHSGE English dataset. The results show that BingChat is better than ChatGPT and Bard. Therefore, BingChat and Bard can replace ChatGPT while ChatGPT is not yet officially available in Vietnam. The results also indicate that ChatGPT, Bing Chat, and Bard outperform Vietnamese students in English language proficiency. The findings of this study contribute to the understanding of the potential of LLMs in English language education. The remarkable performance of ChatGPT, Bing Chat, and Bard demonstrates their potential as effective tools for teaching and learning English at the high school level.","sentences":["This paper presents a performance comparison of three large language models (LLMs), namely OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard, on the VNHSGE English dataset.","The results show that BingChat is better than ChatGPT and Bard.","Therefore, BingChat and Bard can replace ChatGPT while ChatGPT is not yet officially available in Vietnam.","The results also indicate that ChatGPT, Bing Chat, and Bard outperform Vietnamese students in English language proficiency.","The findings of this study contribute to the understanding of the potential of LLMs in English language education.","The remarkable performance of ChatGPT, Bing Chat, and Bard demonstrates their potential as effective tools for teaching and learning English at the high school level."],"url":"http://arxiv.org/abs/2307.02288v1"}
{"created":"2023-07-05 13:29:05","title":"Interactive Image Segmentation with Cross-Modality Vision Transformers","abstract":"Interactive image segmentation aims to segment the target from the background with the manual guidance, which takes as input multimodal data such as images, clicks, scribbles, and bounding boxes. Recently, vision transformers have achieved a great success in several downstream visual tasks, and a few efforts have been made to bring this powerful architecture to interactive segmentation task. However, the previous works neglect the relations between two modalities and directly mock the way of processing purely visual information with self-attentions. In this paper, we propose a simple yet effective network for click-based interactive segmentation with cross-modality vision transformers. Cross-modality transformers exploits mutual information to better guide the learning process. The experiments on several benchmarks show that the proposed method achieves superior performance in comparison to the previous state-of-the-art models. The stability of our method in term of avoiding failure cases shows its potential to be a practical annotation tool. The code and pretrained models will be released under https://github.com/lik1996/iCMFormer.","sentences":["Interactive image segmentation aims to segment the target from the background with the manual guidance, which takes as input multimodal data such as images, clicks, scribbles, and bounding boxes.","Recently, vision transformers have achieved a great success in several downstream visual tasks, and a few efforts have been made to bring this powerful architecture to interactive segmentation task.","However, the previous works neglect the relations between two modalities and directly mock the way of processing purely visual information with self-attentions.","In this paper, we propose a simple yet effective network for click-based interactive segmentation with cross-modality vision transformers.","Cross-modality transformers exploits mutual information to better guide the learning process.","The experiments on several benchmarks show that the proposed method achieves superior performance in comparison to the previous state-of-the-art models.","The stability of our method in term of avoiding failure cases shows its potential to be a practical annotation tool.","The code and pretrained models will be released under https://github.com/lik1996/iCMFormer."],"url":"http://arxiv.org/abs/2307.02280v1"}
{"created":"2023-07-05 13:24:27","title":"Privacy-Preserving Federated Heavy Hitter Analytics for Non-IID Data","abstract":"Federated heavy-hitter analytics involves the identification of the most frequent items within distributed data. Existing methods for this task often encounter challenges such as compromising privacy or sacrificing utility. To address these issues, we introduce a novel privacy-preserving algorithm that exploits the hierarchical structure to discover local and global heavy hitters in non-IID data by utilizing perturbation and similarity techniques. We conduct extensive evaluations on both synthetic and real datasets to validate the effectiveness of our approach. We also present FedCampus, a demonstration application to showcase the capabilities of our algorithm in analyzing population statistics.","sentences":["Federated heavy-hitter analytics involves the identification of the most frequent items within distributed data.","Existing methods for this task often encounter challenges such as compromising privacy or sacrificing utility.","To address these issues, we introduce a novel privacy-preserving algorithm that exploits the hierarchical structure to discover local and global heavy hitters in non-IID data by utilizing perturbation and similarity techniques.","We conduct extensive evaluations on both synthetic and real datasets to validate the effectiveness of our approach.","We also present FedCampus, a demonstration application to showcase the capabilities of our algorithm in analyzing population statistics."],"url":"http://arxiv.org/abs/2307.02277v1"}
{"created":"2023-07-05 13:20:21","title":"First-Explore, then Exploit: Meta-Learning Intelligent Exploration","abstract":"Standard reinforcement learning (RL) agents never intelligently explore like a human (i.e. by taking into account complex domain priors and previous explorations). Even the most basic intelligent exploration strategies such as exhaustive search are only inefficiently or poorly approximated by approaches such as novelty search or intrinsic motivation, let alone more complicated strategies like learning new skills, climbing stairs, opening doors, or conducting experiments. This lack of intelligent exploration limits sample efficiency and prevents solving hard exploration domains. We argue a core barrier prohibiting many RL approaches from learning intelligent exploration is that the methods attempt to explore and exploit simultaneously, which harms both exploration and exploitation as the goals often conflict. We propose a novel meta-RL framework (First-Explore) with two policies: one policy learns to only explore and one policy learns to only exploit. Once trained, we can then explore with the explore policy, for as long as desired, and then exploit based on all the information gained during exploration. This approach avoids the conflict of trying to do both exploration and exploitation at once. We demonstrate that First-Explore can learn intelligent exploration strategies such as exhaustive search and more, and that it outperforms dominant standard RL and meta-RL approaches on domains where exploration requires sacrificing reward. First-Explore is a significant step towards creating meta-RL algorithms capable of learning human-level exploration which is essential to solve challenging unseen hard-exploration domains.","sentences":["Standard reinforcement learning (RL) agents never intelligently explore like a human (i.e. by taking into account complex domain priors and previous explorations).","Even the most basic intelligent exploration strategies such as exhaustive search are only inefficiently or poorly approximated by approaches such as novelty search or intrinsic motivation, let alone more complicated strategies like learning new skills, climbing stairs, opening doors, or conducting experiments.","This lack of intelligent exploration limits sample efficiency and prevents solving hard exploration domains.","We argue a core barrier prohibiting many RL approaches from learning intelligent exploration is that the methods attempt to explore and exploit simultaneously, which harms both exploration and exploitation as the goals often conflict.","We propose a novel meta-RL framework (First-Explore) with two policies: one policy learns to only explore and one policy learns to only exploit.","Once trained, we can then explore with the explore policy, for as long as desired, and then exploit based on all the information gained during exploration.","This approach avoids the conflict of trying to do both exploration and exploitation at once.","We demonstrate that First-Explore can learn intelligent exploration strategies such as exhaustive search and more, and that it outperforms dominant standard RL and meta-RL approaches on domains where exploration requires sacrificing reward.","First-Explore is a significant step towards creating meta-RL algorithms capable of learning human-level exploration which is essential to solve challenging unseen hard-exploration domains."],"url":"http://arxiv.org/abs/2307.02276v1"}
{"created":"2023-07-05 13:19:41","title":"Convolutions Through the Lens of Tensor Networks","abstract":"Despite their simple intuition, convolutions are more tedious to analyze than dense layers, which complicates the generalization of theoretical and algorithmic ideas. We provide a new perspective onto convolutions through tensor networks (TNs) which allow reasoning about the underlying tensor multiplications by drawing diagrams, and manipulating them to perform function transformations, sub-tensor access, and fusion. We demonstrate this expressive power by deriving the diagrams of various autodiff operations and popular approximations of second-order information with full hyper-parameter support, batching, channel groups, and generalization to arbitrary convolution dimensions. Further, we provide convolution-specific transformations based on the connectivity pattern which allow to re-wire and simplify diagrams before evaluation. Finally, we probe computational performance, relying on established machinery for efficient TN contraction. Our TN implementation speeds up a recently-proposed KFAC variant up to 4.5x and enables new hardware-efficient tensor dropout for approximate backpropagation.","sentences":["Despite their simple intuition, convolutions are more tedious to analyze than dense layers, which complicates the generalization of theoretical and algorithmic ideas.","We provide a new perspective onto convolutions through tensor networks (TNs) which allow reasoning about the underlying tensor multiplications by drawing diagrams, and manipulating them to perform function transformations, sub-tensor access, and fusion.","We demonstrate this expressive power by deriving the diagrams of various autodiff operations and popular approximations of second-order information with full hyper-parameter support, batching, channel groups, and generalization to arbitrary convolution dimensions.","Further, we provide convolution-specific transformations based on the connectivity pattern which allow to re-wire and simplify diagrams before evaluation.","Finally, we probe computational performance, relying on established machinery for efficient TN contraction.","Our TN implementation speeds up a recently-proposed KFAC variant up to 4.5x and enables new hardware-efficient tensor dropout for approximate backpropagation."],"url":"http://arxiv.org/abs/2307.02275v1"}
{"created":"2023-07-05 13:17:52","title":"RBDCore: Robot Rigid Body Dynamics Accelerator with Multifunctional Pipelines","abstract":"Rigid body dynamics is a key technology in the robotics field. In trajectory optimization and model predictive control algorithms, there are usually a large number of rigid body dynamics computing tasks. Using CPUs to process these tasks consumes a lot of time, which will affect the real-time performance of robots. To this end, we propose a multifunctional robot rigid body dynamics accelerator, named RBDCore, to address the performance bottleneck. By analyzing different functions commonly used in robot dynamics calculations, we summarize their reuse relationship and optimize them according to the hardware. Based on this, RBDCore can fully reuse common hardware modules when processing different computing tasks. By dynamically switching the dataflow path, RBDCore can accelerate various dynamics functions without reconfiguring the hardware. We design Structure-Adaptive Pipelines for RBDCore, which can greatly improve the throughput of the accelerator. Robots with different structures and parameters can be optimized specifically. Compared with the state-of-the-art CPU, GPU dynamics libraries and FPGA accelerator, RBDCore can significantly improve the performance.","sentences":["Rigid body dynamics is a key technology in the robotics field.","In trajectory optimization and model predictive control algorithms, there are usually a large number of rigid body dynamics computing tasks.","Using CPUs to process these tasks consumes a lot of time, which will affect the real-time performance of robots.","To this end, we propose a multifunctional robot rigid body dynamics accelerator, named RBDCore, to address the performance bottleneck.","By analyzing different functions commonly used in robot dynamics calculations, we summarize their reuse relationship and optimize them according to the hardware.","Based on this, RBDCore can fully reuse common hardware modules when processing different computing tasks.","By dynamically switching the dataflow path, RBDCore can accelerate various dynamics functions without reconfiguring the hardware.","We design Structure-Adaptive Pipelines for RBDCore, which can greatly improve the throughput of the accelerator.","Robots with different structures and parameters can be optimized specifically.","Compared with the state-of-the-art CPU, GPU dynamics libraries and FPGA accelerator, RBDCore can significantly improve the performance."],"url":"http://arxiv.org/abs/2307.02274v1"}
{"created":"2023-07-05 13:17:14","title":"Joint Hierarchical Priors and Adaptive Spatial Resolution for Efficient Neural Image Compression","abstract":"Recently, the performance of neural image compression (NIC) has steadily improved thanks to the last line of study, reaching or outperforming state-of-the-art conventional codecs. Despite significant progress, current NIC methods still rely on ConvNet-based entropy coding, limited in modeling long-range dependencies due to their local connectivity and the increasing number of architectural biases and priors, resulting in complex underperforming models with high decoding latency. Motivated by the efficiency investigation of the Tranformer-based transform coding framework, namely SwinT-ChARM, we propose to enhance the latter, as first, with a more straightforward yet effective Tranformer-based channel-wise auto-regressive prior model, resulting in an absolute image compression transformer (ICT). Through the proposed ICT, we can capture both global and local contexts from the latent representations and better parameterize the distribution of the quantized latents. Further, we leverage a learnable scaling module with a sandwich ConvNeXt-based pre-/post-processor to accurately extract more compact latent codes while reconstructing higher-quality images. Extensive experimental results on benchmark datasets showed that the proposed framework significantly improves the trade-off between coding efficiency and decoder complexity over the versatile video coding (VVC) reference encoder (VTM-18.0) and the neural codec SwinT-ChARM. Moreover, we provide model scaling studies to verify the computational efficiency of our approach and conduct several objective and subjective analyses to bring to the fore the performance gap between the adaptive image compression transformer (AICT) and the neural codec SwinT-ChARM.","sentences":["Recently, the performance of neural image compression (NIC) has steadily improved thanks to the last line of study, reaching or outperforming state-of-the-art conventional codecs.","Despite significant progress, current NIC methods still rely on ConvNet-based entropy coding, limited in modeling long-range dependencies due to their local connectivity and the increasing number of architectural biases and priors, resulting in complex underperforming models with high decoding latency.","Motivated by the efficiency investigation of the Tranformer-based transform coding framework, namely SwinT-ChARM, we propose to enhance the latter, as first, with a more straightforward yet effective Tranformer-based channel-wise auto-regressive prior model, resulting in an absolute image compression transformer (ICT).","Through the proposed ICT, we can capture both global and local contexts from the latent representations and better parameterize the distribution of the quantized latents.","Further, we leverage a learnable scaling module with a sandwich ConvNeXt-based pre-/post-processor to accurately extract more compact latent codes while reconstructing higher-quality images.","Extensive experimental results on benchmark datasets showed that the proposed framework significantly improves the trade-off between coding efficiency and decoder complexity over the versatile video coding (VVC) reference encoder (VTM-18.0) and the neural codec SwinT-ChARM.","Moreover, we provide model scaling studies to verify the computational efficiency of our approach and conduct several objective and subjective analyses to bring to the fore the performance gap between the adaptive image compression transformer (AICT) and the neural codec SwinT-ChARM."],"url":"http://arxiv.org/abs/2307.02273v1"}
{"created":"2023-07-05 13:10:37","title":"SVDM: Single-View Diffusion Model for Pseudo-Stereo 3D Object Detection","abstract":"One of the key problems in 3D object detection is to reduce the accuracy gap between methods based on LiDAR sensors and those based on monocular cameras. A recently proposed framework for monocular 3D detection based on Pseudo-Stereo has received considerable attention in the community. However, so far these two problems are discovered in existing practices, including (1) monocular depth estimation and Pseudo-Stereo detector must be trained separately, (2) Difficult to be compatible with different stereo detectors and (3) the overall calculation is large, which affects the reasoning speed. In this work, we propose an end-to-end, efficient pseudo-stereo 3D detection framework by introducing a Single-View Diffusion Model (SVDM) that uses a few iterations to gradually deliver right informative pixels to the left image. SVDM allows the entire pseudo-stereo 3D detection pipeline to be trained end-to-end and can benefit from the training of stereo detectors. Afterwards, we further explore the application of SVDM in depth-free stereo 3D detection, and the final framework is compatible with most stereo detectors. Among multiple benchmarks on the KITTI dataset, we achieve new state-of-the-art performance.","sentences":["One of the key problems in 3D object detection is to reduce the accuracy gap between methods based on LiDAR sensors and those based on monocular cameras.","A recently proposed framework for monocular 3D detection based on Pseudo-Stereo has received considerable attention in the community.","However, so far these two problems are discovered in existing practices, including (1) monocular depth estimation and Pseudo-Stereo detector must be trained separately, (2) Difficult to be compatible with different stereo detectors and (3) the overall calculation is large, which affects the reasoning speed.","In this work, we propose an end-to-end, efficient pseudo-stereo 3D detection framework by introducing a Single-View Diffusion Model (SVDM) that uses a few iterations to gradually deliver right informative pixels to the left image.","SVDM allows the entire pseudo-stereo 3D detection pipeline to be trained end-to-end and can benefit from the training of stereo detectors.","Afterwards, we further explore the application of SVDM in depth-free stereo 3D detection, and the final framework is compatible with most stereo detectors.","Among multiple benchmarks on the KITTI dataset, we achieve new state-of-the-art performance."],"url":"http://arxiv.org/abs/2307.02270v1"}
{"created":"2023-07-05 13:08:18","title":"SpaceNLI: Evaluating the Consistency of Predicting Inferences in Space","abstract":"While many natural language inference (NLI) datasets target certain semantic phenomena, e.g., negation, tense & aspect, monotonicity, and presupposition, to the best of our knowledge, there is no NLI dataset that involves diverse types of spatial expressions and reasoning. We fill this gap by semi-automatically creating an NLI dataset for spatial reasoning, called SpaceNLI. The data samples are automatically generated from a curated set of reasoning patterns, where the patterns are annotated with inference labels by experts. We test several SOTA NLI systems on SpaceNLI to gauge the complexity of the dataset and the system's capacity for spatial reasoning. Moreover, we introduce a Pattern Accuracy and argue that it is a more reliable and stricter measure than the accuracy for evaluating a system's performance on pattern-based generated data samples. Based on the evaluation results we find that the systems obtain moderate results on the spatial NLI problems but lack consistency per inference pattern. The results also reveal that non-projective spatial inferences (especially due to the \"between\" preposition) are the most challenging ones.","sentences":["While many natural language inference (NLI) datasets target certain semantic phenomena, e.g., negation, tense & aspect, monotonicity, and presupposition, to the best of our knowledge, there is no NLI dataset that involves diverse types of spatial expressions and reasoning.","We fill this gap by semi-automatically creating an NLI dataset for spatial reasoning, called SpaceNLI.","The data samples are automatically generated from a curated set of reasoning patterns, where the patterns are annotated with inference labels by experts.","We test several SOTA NLI systems on SpaceNLI to gauge the complexity of the dataset and the system's capacity for spatial reasoning.","Moreover, we introduce a Pattern Accuracy and argue that it is a more reliable and stricter measure than the accuracy for evaluating a system's performance on pattern-based generated data samples.","Based on the evaluation results we find that the systems obtain moderate results on the spatial NLI problems but lack consistency per inference pattern.","The results also reveal that non-projective spatial inferences (especially due to the \"between\" preposition) are the most challenging ones."],"url":"http://arxiv.org/abs/2307.02269v1"}
{"created":"2023-07-05 13:01:21","title":"Dynamical Isometry based Rigorous Fair Neural Architecture Search","abstract":"Recently, the weight-sharing technique has significantly speeded up the training and evaluation procedure of neural architecture search. However, most existing weight-sharing strategies are solely based on experience or observation, which makes the searching results lack interpretability and rationality. In addition, due to the negligence of fairness, current methods are prone to make misjudgments in module evaluation. To address these problems, we propose a novel neural architecture search algorithm based on dynamical isometry. We use the fix point analysis method in the mean field theory to analyze the dynamics behavior in the steady state random neural network, and how dynamic isometry guarantees the fairness of weight-sharing based NAS. Meanwhile, we prove that our module selection strategy is rigorous fair by estimating the generalization error of all modules with well-conditioned Jacobian. Extensive experiments show that, with the same size, the architecture searched by the proposed method can achieve state-of-the-art top-1 validation accuracy on ImageNet classification. In addition, we demonstrate that our method is able to achieve better and more stable training performance without loss of generality.","sentences":["Recently, the weight-sharing technique has significantly speeded up the training and evaluation procedure of neural architecture search.","However, most existing weight-sharing strategies are solely based on experience or observation, which makes the searching results lack interpretability and rationality.","In addition, due to the negligence of fairness, current methods are prone to make misjudgments in module evaluation.","To address these problems, we propose a novel neural architecture search algorithm based on dynamical isometry.","We use the fix point analysis method in the mean field theory to analyze the dynamics behavior in the steady state random neural network, and how dynamic isometry guarantees the fairness of weight-sharing based NAS.","Meanwhile, we prove that our module selection strategy is rigorous fair by estimating the generalization error of all modules with well-conditioned Jacobian.","Extensive experiments show that, with the same size, the architecture searched by the proposed method can achieve state-of-the-art top-1 validation accuracy on ImageNet classification.","In addition, we demonstrate that our method is able to achieve better and more stable training performance without loss of generality."],"url":"http://arxiv.org/abs/2307.02263v2"}
{"created":"2023-07-05 13:00:33","title":"Security Risk Analysis Methodologies for Automotive Systems","abstract":"Nowadays, systematic security risk analysis plays a vital role in the automotive domain. The demand for advanced driver assistance systems and connectivity of vehicles to the internet makes cyber-security a crucial requirement for vehicle manufacturers. This paper summarizes the risk analysis method stated in the recently released automotive security standard ISO/SAE 21434, which lays the high-level principles for threat analysis and risk assessment (TARA) methods. Following, we introduce a specific use case to compare different security analysis approaches which OEMs can benefit from to achieve compliance with the standard.","sentences":["Nowadays, systematic security risk analysis plays a vital role in the automotive domain.","The demand for advanced driver assistance systems and connectivity of vehicles to the internet makes cyber-security a crucial requirement for vehicle manufacturers.","This paper summarizes the risk analysis method stated in the recently released automotive security standard ISO/SAE 21434, which lays the high-level principles for threat analysis and risk assessment (TARA) methods.","Following, we introduce a specific use case to compare different security analysis approaches which OEMs can benefit from to achieve compliance with the standard."],"url":"http://arxiv.org/abs/2307.02261v1"}
{"created":"2023-07-05 12:56:06","title":"Hybrid NOMA for STAR-RIS Enhanced Communication","abstract":"In this paper, a hybrid non-orthogonal multiple access (NOMA) framework for the simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) enhanced cell-edge communication is investigated. Specifically, one transmitted user and one reflected user are paired as one NOMA-pair, while multiple NOMA-pairs are served via time division multiple access (TDMA). The objective is to maximize the minimum downlink rate by jointly optimizing the user pairing, decoding order, passive beamforming, power and time allocation. A novel two-layer iterative algorithm is proposed to solve the highly coupled problem. Simulation results show that: 1) the proposed framework outperforms the conventional reflecting-only-RIS-based and the OMA-based frameworks; 2) the beamforming design and power allocation dominate the achieved performance; 3) increasing the number of passive elements and shortening the distance between BS and STAR-RIS are two effective ways to further improve the performance.","sentences":["In this paper, a hybrid non-orthogonal multiple access (NOMA) framework for the simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) enhanced cell-edge communication is investigated.","Specifically, one transmitted user and one reflected user are paired as one NOMA-pair, while multiple NOMA-pairs are served via time division multiple access (TDMA).","The objective is to maximize the minimum downlink rate by jointly optimizing the user pairing, decoding order, passive beamforming, power and time allocation.","A novel two-layer iterative algorithm is proposed to solve the highly coupled problem.","Simulation results show that: 1) the proposed framework outperforms the conventional reflecting-only-RIS-based and the OMA-based frameworks; 2) the beamforming design and power allocation dominate the achieved performance; 3) increasing the number of passive elements and shortening the distance between BS and STAR-RIS are two effective ways to further improve the performance."],"url":"http://arxiv.org/abs/2307.02257v1"}
{"created":"2023-07-05 12:53:40","title":"Analyzing Different Expert-Opined Strategies to Enhance the Effect on the Goal of a Multi-Attribute Decision-Making System Using a Concept of Effort Propagation and Application in Enhancement of High School Students' Performance","abstract":"In many real-world multi-attribute decision-making (MADM) problems, mining the inter-relationships and possible hierarchical structures among the factors are considered to be one of the primary tasks. But, besides that, one major task is to determine an optimal strategy to work on the factors to enhance the effect on the goal attribute. This paper proposes two such strategies, namely parallel and hierarchical effort assignment, and propagation strategies. The concept of effort propagation through a strategy is formally defined and described in the paper. Both the parallel and hierarchical strategies are divided into sub-strategies based on whether the assignment of efforts to the factors is uniform or depends upon some appropriate heuristics related to the factors in the system. The adapted and discussed heuristics are the relative significance and effort propagability of the factors. The strategies are analyzed for a real-life case study regarding Indian high school administrative factors that play an important role in enhancing students' performance. Total effort propagation of around 7%-15% to the goal is seen across the proposed strategies given a total of 1 unit of effort to the directly accessible factors of the system. A comparative analysis is adapted to determine the optimal strategy among the proposed ones to enhance student performance most effectively. The highest effort propagation achieved in the work is approximately 14.4348%. The analysis in the paper establishes the necessity of research towards the direction of effort propagation analysis in case of decision-making problems.","sentences":["In many real-world multi-attribute decision-making (MADM) problems, mining the inter-relationships and possible hierarchical structures among the factors are considered to be one of the primary tasks.","But, besides that, one major task is to determine an optimal strategy to work on the factors to enhance the effect on the goal attribute.","This paper proposes two such strategies, namely parallel and hierarchical effort assignment, and propagation strategies.","The concept of effort propagation through a strategy is formally defined and described in the paper.","Both the parallel and hierarchical strategies are divided into sub-strategies based on whether the assignment of efforts to the factors is uniform or depends upon some appropriate heuristics related to the factors in the system.","The adapted and discussed heuristics are the relative significance and effort propagability of the factors.","The strategies are analyzed for a real-life case study regarding Indian high school administrative factors that play an important role in enhancing students' performance.","Total effort propagation of around 7%-15% to the goal is seen across the proposed strategies given a total of 1 unit of effort to the directly accessible factors of the system.","A comparative analysis is adapted to determine the optimal strategy among the proposed ones to enhance student performance most effectively.","The highest effort propagation achieved in the work is approximately 14.4348%.","The analysis in the paper establishes the necessity of research towards the direction of effort propagation analysis in case of decision-making problems."],"url":"http://arxiv.org/abs/2307.02254v1"}
{"created":"2023-07-05 12:50:48","title":"Multivariate Time Series Classification: A Deep Learning Approach","abstract":"This paper investigates different methods and various neural network architectures applicable in the time series classification domain. The data is obtained from a fleet of gas sensors that measure and track quantities such as oxygen and sound. With the help of this data, we can detect events such as occupancy in a specific environment. At first, we analyze the time series data to understand the effect of different parameters, such as the sequence length, when training our models. These models employ Fully Convolutional Networks (FCN) and Long Short-Term Memory (LSTM) for supervised learning and Recurrent Autoencoders for semisupervised learning. Throughout this study, we spot the differences between these methods based on metrics such as precision and recall identifying which technique best suits this problem.","sentences":["This paper investigates different methods and various neural network architectures applicable in the time series classification domain.","The data is obtained from a fleet of gas sensors that measure and track quantities such as oxygen and sound.","With the help of this data, we can detect events such as occupancy in a specific environment.","At first, we analyze the time series data to understand the effect of different parameters, such as the sequence length, when training our models.","These models employ Fully Convolutional Networks (FCN) and Long Short-Term Memory (LSTM) for supervised learning and Recurrent Autoencoders for semisupervised learning.","Throughout this study, we spot the differences between these methods based on metrics such as precision and recall identifying which technique best suits this problem."],"url":"http://arxiv.org/abs/2307.02253v1"}
{"created":"2023-07-05 12:49:02","title":"RanPAC: Random Projections and Pre-trained Models for Continual Learning","abstract":"Continual learning (CL) aims to incrementally learn different tasks (such as classification) in a non-stationary data stream without forgetting old ones. Most CL works focus on tackling catastrophic forgetting under a learning-from-scratch paradigm. However, with the increasing prominence of foundation models, pre-trained models equipped with informative representations have become available for various downstream requirements. Several CL methods based on pre-trained models have been explored, either utilizing pre-extracted features directly (which makes bridging distribution gaps challenging) or incorporating adaptors (which may be subject to forgetting). In this paper, we propose a concise and effective approach for CL with pre-trained models. Given that forgetting occurs during parameter updating, we contemplate an alternative approach that exploits training-free random projectors and class-prototype accumulation, which thus bypasses the issue. Specifically, we inject a frozen Random Projection layer with nonlinear activation between the pre-trained model's feature representations and output head, which captures interactions between features with expanded dimensionality, providing enhanced linear separability for class-prototype-based CL. We also demonstrate the importance of decorrelating the class-prototypes to reduce the distribution disparity when using pre-trained representations. These techniques prove to be effective and circumvent the problem of forgetting for both class- and domain-incremental continual learning. Compared to previous methods applied to pre-trained ViT-B/16 models, we reduce final error rates by between 10\\% and 62\\% on seven class-incremental benchmark datasets, despite not using any rehearsal memory. We conclude that the full potential of pre-trained models for simple, effective, and fast continual learning has not hitherto been fully tapped.","sentences":["Continual learning (CL) aims to incrementally learn different tasks (such as classification) in a non-stationary data stream without forgetting old ones.","Most CL works focus on tackling catastrophic forgetting under a learning-from-scratch paradigm.","However, with the increasing prominence of foundation models, pre-trained models equipped with informative representations have become available for various downstream requirements.","Several CL methods based on pre-trained models have been explored, either utilizing pre-extracted features directly (which makes bridging distribution gaps challenging) or incorporating adaptors (which may be subject to forgetting).","In this paper, we propose a concise and effective approach for CL with pre-trained models.","Given that forgetting occurs during parameter updating, we contemplate an alternative approach that exploits training-free random projectors and class-prototype accumulation, which thus bypasses the issue.","Specifically, we inject a frozen Random Projection layer with nonlinear activation between the pre-trained model's feature representations and output head, which captures interactions between features with expanded dimensionality, providing enhanced linear separability for class-prototype-based CL.","We also demonstrate the importance of decorrelating the class-prototypes to reduce the distribution disparity when using pre-trained representations.","These techniques prove to be effective and circumvent the problem of forgetting for both class- and domain-incremental continual learning.","Compared to previous methods applied to pre-trained ViT-B/16 models, we reduce final error rates by between 10\\% and 62\\% on seven class-incremental benchmark datasets, despite not using any rehearsal memory.","We conclude that the full potential of pre-trained models for simple, effective, and fast continual learning has not hitherto been fully tapped."],"url":"http://arxiv.org/abs/2307.02251v1"}
{"created":"2023-07-05 12:45:07","title":"Stress-testing Road Networks and Access to Medical Care","abstract":"This research studies how populations depend on road networks for access to health care during crises or natural disasters. So far, most researchers rather studied the accessibility of the whole network or the cost of network disruptions in general, rather than as a function of the accessibility of specific priority destinations like hospitals. Even short delays in accessing healthcare can have significant adverse consequences. We carry out a comprehensive stress test of the entire Austrian road network from this perspective. We simplify the whole network into one consisting of what we call accessibility corridors, deleting single corridors to evaluate the change in accessibility of populations to healthcare. The data created by our stress test was used to generate an importance ranking of the corridors. The findings suggest that certain road segments and corridors are orders of magnitude more important in terms of access to hospitals than the typical one. Our method also highlights vulnerable municipalities and hospitals who may experience demand surges as populations are cut off from their usual nearest hospitals. Even though the skewed importance of some corridors highlights vulnerabilities, they provide policymakers with a clear agenda.","sentences":["This research studies how populations depend on road networks for access to health care during crises or natural disasters.","So far, most researchers rather studied the accessibility of the whole network or the cost of network disruptions in general, rather than as a function of the accessibility of specific priority destinations like hospitals.","Even short delays in accessing healthcare can have significant adverse consequences.","We carry out a comprehensive stress test of the entire Austrian road network from this perspective.","We simplify the whole network into one consisting of what we call accessibility corridors, deleting single corridors to evaluate the change in accessibility of populations to healthcare.","The data created by our stress test was used to generate an importance ranking of the corridors.","The findings suggest that certain road segments and corridors are orders of magnitude more important in terms of access to hospitals than the typical one.","Our method also highlights vulnerable municipalities and hospitals who may experience demand surges as populations are cut off from their usual nearest hospitals.","Even though the skewed importance of some corridors highlights vulnerabilities, they provide policymakers with a clear agenda."],"url":"http://arxiv.org/abs/2307.02250v1"}
{"created":"2023-07-05 12:44:52","title":"Rethinking Multiple Instance Learning for Whole Slide Image Classification: A Good Instance Classifier is All You Need","abstract":"Weakly supervised whole slide image classification is usually formulated as a multiple instance learning (MIL) problem, where each slide is treated as a bag, and the patches cut out of it are treated as instances. Existing methods either train an instance classifier through pseudo-labeling or aggregate instance features into a bag feature through attention mechanisms and then train a bag classifier, where the attention scores can be used for instance-level classification. However, the pseudo instance labels constructed by the former usually contain a lot of noise, and the attention scores constructed by the latter are not accurate enough, both of which affect their performance. In this paper, we propose an instance-level MIL framework based on contrastive learning and prototype learning to effectively accomplish both instance classification and bag classification tasks. To this end, we propose an instance-level weakly supervised contrastive learning algorithm for the first time under the MIL setting to effectively learn instance feature representation. We also propose an accurate pseudo label generation method through prototype learning. We then develop a joint training strategy for weakly supervised contrastive learning, prototype learning, and instance classifier training. Extensive experiments and visualizations on four datasets demonstrate the powerful performance of our method. Codes will be available.","sentences":["Weakly supervised whole slide image classification is usually formulated as a multiple instance learning (MIL) problem, where each slide is treated as a bag, and the patches cut out of it are treated as instances.","Existing methods either train an instance classifier through pseudo-labeling or aggregate instance features into a bag feature through attention mechanisms and then train a bag classifier, where the attention scores can be used for instance-level classification.","However, the pseudo instance labels constructed by the former usually contain a lot of noise, and the attention scores constructed by the latter are not accurate enough, both of which affect their performance.","In this paper, we propose an instance-level MIL framework based on contrastive learning and prototype learning to effectively accomplish both instance classification and bag classification tasks.","To this end, we propose an instance-level weakly supervised contrastive learning algorithm for the first time under the MIL setting to effectively learn instance feature representation.","We also propose an accurate pseudo label generation method through prototype learning.","We then develop a joint training strategy for weakly supervised contrastive learning, prototype learning, and instance classifier training.","Extensive experiments and visualizations on four datasets demonstrate the powerful performance of our method.","Codes will be available."],"url":"http://arxiv.org/abs/2307.02249v1"}
{"created":"2023-07-05 12:41:46","title":"S3C: Self-Supervised Stochastic Classifiers for Few-Shot Class-Incremental Learning","abstract":"Few-shot class-incremental learning (FSCIL) aims to learn progressively about new classes with very few labeled samples, without forgetting the knowledge of already learnt classes. FSCIL suffers from two major challenges: (i) over-fitting on the new classes due to limited amount of data, (ii) catastrophically forgetting about the old classes due to unavailability of data from these classes in the incremental stages. In this work, we propose a self-supervised stochastic classifier (S3C) to counter both these challenges in FSCIL. The stochasticity of the classifier weights (or class prototypes) not only mitigates the adverse effect of absence of large number of samples of the new classes, but also the absence of samples from previously learnt classes during the incremental steps. This is complemented by the self-supervision component, which helps to learn features from the base classes which generalize well to unseen classes that are encountered in future, thus reducing catastrophic forgetting. Extensive evaluation on three benchmark datasets using multiple evaluation metrics show the effectiveness of the proposed framework. We also experiment on two additional realistic scenarios of FSCIL, namely where the number of annotated data available for each of the new classes can be different, and also where the number of base classes is much lesser, and show that the proposed S3C performs significantly better than the state-of-the-art for all these challenging scenarios.","sentences":["Few-shot class-incremental learning (FSCIL) aims to learn progressively about new classes with very few labeled samples, without forgetting the knowledge of already learnt classes.","FSCIL suffers from two major challenges: (i) over-fitting on the new classes due to limited amount of data, (ii) catastrophically forgetting about the old classes due to unavailability of data from these classes in the incremental stages.","In this work, we propose a self-supervised stochastic classifier (S3C) to counter both these challenges in FSCIL.","The stochasticity of the classifier weights (or class prototypes) not only mitigates the adverse effect of absence of large number of samples of the new classes, but also the absence of samples from previously learnt classes during the incremental steps.","This is complemented by the self-supervision component, which helps to learn features from the base classes which generalize well to unseen classes that are encountered in future, thus reducing catastrophic forgetting.","Extensive evaluation on three benchmark datasets using multiple evaluation metrics show the effectiveness of the proposed framework.","We also experiment on two additional realistic scenarios of FSCIL, namely where the number of annotated data available for each of the new classes can be different, and also where the number of base classes is much lesser, and show that the proposed S3C performs significantly better than the state-of-the-art for all these challenging scenarios."],"url":"http://arxiv.org/abs/2307.02246v1"}
{"created":"2023-07-05 12:39:58","title":"Set Learning for Accurate and Calibrated Models","abstract":"Model overconfidence and poor calibration are common in machine learning and difficult to account for when applying standard empirical risk minimization. In this work, we propose a novel method to alleviate these problems that we call odd-$k$-out learning (OKO), which minimizes the cross-entropy error for sets rather than for single examples. This naturally allows the model to capture correlations across data examples and achieves both better accuracy and calibration, especially in limited training data and class-imbalanced regimes. Perhaps surprisingly, OKO often yields better calibration even when training with hard labels and dropping any additional calibration parameter tuning, such as temperature scaling. We provide theoretical justification, establishing that OKO naturally yields better calibration, and provide extensive experimental analyses that corroborate our theoretical findings. We emphasize that OKO is a general framework that can be easily adapted to many settings and the trained model can be applied to single examples at inference time, without introducing significant run-time overhead or architecture changes.","sentences":["Model overconfidence and poor calibration are common in machine learning and difficult to account for when applying standard empirical risk minimization.","In this work, we propose a novel method to alleviate these problems that we call odd-$k$-out learning (OKO), which minimizes the cross-entropy error for sets rather than for single examples.","This naturally allows the model to capture correlations across data examples and achieves both better accuracy and calibration, especially in limited training data and class-imbalanced regimes.","Perhaps surprisingly, OKO often yields better calibration even when training with hard labels and dropping any additional calibration parameter tuning, such as temperature scaling.","We provide theoretical justification, establishing that OKO naturally yields better calibration, and provide extensive experimental analyses that corroborate our theoretical findings.","We emphasize that OKO is a general framework that can be easily adapted to many settings and the trained model can be applied to single examples at inference time, without introducing significant run-time overhead or architecture changes."],"url":"http://arxiv.org/abs/2307.02245v1"}
{"created":"2023-07-05 12:36:39","title":"Self-supervised learning with diffusion-based multichannel speech enhancement for speaker verification under noisy conditions","abstract":"The paper introduces Diff-Filter, a multichannel speech enhancement approach based on the diffusion probabilistic model, for improving speaker verification performance under noisy and reverberant conditions. It also presents a new two-step training procedure that takes the benefit of self-supervised learning. In the first stage, the Diff-Filter is trained by conducting timedomain speech filtering using a scoring-based diffusion model. In the second stage, the Diff-Filter is jointly optimized with a pre-trained ECAPA-TDNN speaker verification model under a self-supervised learning framework. We present a novel loss based on equal error rate. This loss is used to conduct selfsupervised learning on a dataset that is not labelled in terms of speakers. The proposed approach is evaluated on MultiSV, a multichannel speaker verification dataset, and shows significant improvements in performance under noisy multichannel conditions.","sentences":["The paper introduces Diff-Filter, a multichannel speech enhancement approach based on the diffusion probabilistic model, for improving speaker verification performance under noisy and reverberant conditions.","It also presents a new two-step training procedure that takes the benefit of self-supervised learning.","In the first stage, the Diff-Filter is trained by conducting timedomain speech filtering using a scoring-based diffusion model.","In the second stage, the Diff-Filter is jointly optimized with a pre-trained ECAPA-TDNN speaker verification model under a self-supervised learning framework.","We present a novel loss based on equal error rate.","This loss is used to conduct selfsupervised learning on a dataset that is not labelled in terms of speakers.","The proposed approach is evaluated on MultiSV, a multichannel speaker verification dataset, and shows significant improvements in performance under noisy multichannel conditions."],"url":"http://arxiv.org/abs/2307.02244v1"}
{"created":"2023-07-05 12:35:29","title":"Power-up! What Can Generative Models Do for Human Computation Workflows?","abstract":"We are amidst an explosion of artificial intelligence research, particularly around large language models (LLMs). These models have a range of applications across domains like medicine, finance, commonsense knowledge graphs, and crowdsourcing. Investigation into LLMs as part of crowdsourcing workflows remains an under-explored space. The crowdsourcing research community has produced a body of work investigating workflows and methods for managing complex tasks using hybrid human-AI methods. Within crowdsourcing, the role of LLMs can be envisioned as akin to a cog in a larger wheel of workflows. From an empirical standpoint, little is currently understood about how LLMs can improve the effectiveness of crowdsourcing workflows and how such workflows can be evaluated. In this work, we present a vision for exploring this gap from the perspectives of various stakeholders involved in the crowdsourcing paradigm -- the task requesters, crowd workers, platforms, and end-users. We identify junctures in typical crowdsourcing workflows at which the introduction of LLMs can play a beneficial role and propose means to augment existing design patterns for crowd work.","sentences":["We are amidst an explosion of artificial intelligence research, particularly around large language models (LLMs).","These models have a range of applications across domains like medicine, finance, commonsense knowledge graphs, and crowdsourcing.","Investigation into LLMs as part of crowdsourcing workflows remains an under-explored space.","The crowdsourcing research community has produced a body of work investigating workflows and methods for managing complex tasks using hybrid human-AI methods.","Within crowdsourcing, the role of LLMs can be envisioned as akin to a cog in a larger wheel of workflows.","From an empirical standpoint, little is currently understood about how LLMs can improve the effectiveness of crowdsourcing workflows and how such workflows can be evaluated.","In this work, we present a vision for exploring this gap from the perspectives of various stakeholders involved in the crowdsourcing paradigm -- the task requesters, crowd workers, platforms, and end-users.","We identify junctures in typical crowdsourcing workflows at which the introduction of LLMs can play a beneficial role and propose means to augment existing design patterns for crowd work."],"url":"http://arxiv.org/abs/2307.02243v1"}
{"created":"2023-07-05 12:35:14","title":"Multi-IRS-Enabled Integrated Sensing and Communications","abstract":"This paper studies a multi-intelligent-reflecting-surface-(IRS)-enabled integrated sensing and communications (ISAC) system, in which multiple IRSs are installed to help the base station (BS) provide ISAC services at separate line-of-sight (LoS) blocked areas. We focus on the scenario with semi-passive uniform linear array (ULA) IRSsfor sensing, in which each IRS is integrated with dedicated sensors for processing echo signals, and each IRS simultaneously serves one sensing target and one communication user (CU) in its coverage area. In particular, we suppose that the BS sends combined information and dedicated sensing signals for ISAC, and we consider two cases with point and extended targets, in which each IRS aims to estimate the direction-of-arrival (DoA) of the corresponding target and the complete target response matrix, respectively. Under this setup, we first derive the closed-form Cram{\\'e}r-Rao bounds (CRBs) for parameters estimation under the two target models. For the point target case, the CRB for AoA estimation is shown to be inversely proportional to the cubic of the number of sensors at each IRS, while for the extended target case, the CRB for target response matrix estimation is proportional to the number of IRS sensors. Next, we consider two different types of CU receivers that can and cannot cancel the interference from dedicated sensing signals prior to information decoding. To achieve fair and optimized sensing performance, we minimize the maximum CRB at all IRSs for the two target cases, via jointly optimizing the transmit beamformers at the BS and the reflective beamformers at the multiple IRSs, subject to the minimum signal-to-interference-plus-noise ratio (SINR) constraints at individual CUs, the maximum transmit power constraint at the BS, and the unit-modulus constraints at the multiple IRSs.","sentences":["This paper studies a multi-intelligent-reflecting-surface-(IRS)-enabled integrated sensing and communications (ISAC) system, in which multiple IRSs are installed to help the base station (BS) provide ISAC services at separate line-of-sight (LoS) blocked areas.","We focus on the scenario with semi-passive uniform linear array (ULA) IRSsfor sensing, in which each IRS is integrated with dedicated sensors for processing echo signals, and each IRS simultaneously serves one sensing target and one communication user (CU) in its coverage area.","In particular, we suppose that the BS sends combined information and dedicated sensing signals for ISAC, and we consider two cases with point and extended targets, in which each IRS aims to estimate the direction-of-arrival (DoA) of the corresponding target and the complete target response matrix, respectively.","Under this setup, we first derive the closed-form Cram{\\'e}r-Rao bounds (CRBs) for parameters estimation under the two target models.","For the point target case, the CRB for AoA estimation is shown to be inversely proportional to the cubic of the number of sensors at each IRS, while for the extended target case, the CRB for target response matrix estimation is proportional to the number of IRS sensors.","Next, we consider two different types of CU receivers that can and cannot cancel the interference from dedicated sensing signals prior to information decoding.","To achieve fair and optimized sensing performance, we minimize the maximum CRB at all IRSs for the two target cases, via jointly optimizing the transmit beamformers at the BS and the reflective beamformers at the multiple IRSs, subject to the minimum signal-to-interference-plus-noise ratio (SINR) constraints at individual CUs, the maximum transmit power constraint at the BS, and the unit-modulus constraints at the multiple IRSs."],"url":"http://arxiv.org/abs/2307.02242v1"}
{"created":"2023-07-05 12:32:29","title":"Approximate Turing kernelization and lower bounds for domination problems","abstract":"An $\\alpha$-approximate polynomial Turing kernelization is a polynomial-time algorithm that computes an $(\\alpha c)$-approximate solution for a parameterized optimization problem when given access to an oracle that can compute $c$-approximate solutions to instances with size bounded by a polynomial in the parameter. Hols et al. [ESA 2020] showed that a wide array of graph problems admit a $(1+\\varepsilon)$-approximate polynomial Turing kernelization when parameterized by the treewidth of the graph and left open whether Dominating Set also admits such a kernelization.   We show that Dominating Set and several related problems parameterized by treewidth do not admit constant-factor approximate polynomial Turing kernelizations, even with respect to the much larger parameter vertex cover number, under certain reasonable complexity assumptions.On the positive side, we show that all of them do have a $(1+\\varepsilon)$-approximate polynomial Turing kernelization for every $\\varepsilon>0$ for the joint parameterization by treewidth and maximum degree, a parameter which generalizes cutwidth, for example.","sentences":["An $\\alpha$-approximate polynomial Turing kernelization is a polynomial-time algorithm that computes an $(\\alpha c)$-approximate solution for a parameterized optimization problem when given access to an oracle that can compute $c$-approximate solutions to instances with size bounded by a polynomial in the parameter.","Hols et al.","[ESA 2020] showed that a wide array of graph problems admit a $(1+\\varepsilon)$-approximate polynomial Turing kernelization when parameterized by the treewidth of the graph and left open whether Dominating Set also admits such a kernelization.   ","We show that Dominating Set and several related problems parameterized by treewidth do not admit constant-factor approximate polynomial Turing kernelizations, even with respect to the much larger parameter vertex cover number, under certain reasonable complexity assumptions.","On the positive side, we show that all of them do have a $(1+\\varepsilon)$-approximate polynomial Turing kernelization for every $\\varepsilon>0$ for the joint parameterization by treewidth and maximum degree, a parameter which generalizes cutwidth, for example."],"url":"http://arxiv.org/abs/2307.02241v1"}
{"created":"2023-07-05 12:27:58","title":"Source Identification: A Self-Supervision Task for Dense Prediction","abstract":"The paradigm of self-supervision focuses on representation learning from raw data without the need of labor-consuming annotations, which is the main bottleneck of current data-driven methods. Self-supervision tasks are often used to pre-train a neural network with a large amount of unlabeled data and extract generic features of the dataset. The learned model is likely to contain useful information which can be transferred to the downstream main task and improve performance compared to random parameter initialization. In this paper, we propose a new self-supervision task called source identification (SI), which is inspired by the classic blind source separation problem. Synthetic images are generated by fusing multiple source images and the network's task is to reconstruct the original images, given the fused images. A proper understanding of the image content is required to successfully solve the task. We validate our method on two medical image segmentation tasks: brain tumor segmentation and white matter hyperintensities segmentation. The results show that the proposed SI task outperforms traditional self-supervision tasks for dense predictions including inpainting, pixel shuffling, intensity shift, and super-resolution. Among variations of the SI task fusing images of different types, fusing images from different patients performs best.","sentences":["The paradigm of self-supervision focuses on representation learning from raw data without the need of labor-consuming annotations, which is the main bottleneck of current data-driven methods.","Self-supervision tasks are often used to pre-train a neural network with a large amount of unlabeled data and extract generic features of the dataset.","The learned model is likely to contain useful information which can be transferred to the downstream main task and improve performance compared to random parameter initialization.","In this paper, we propose a new self-supervision task called source identification (SI), which is inspired by the classic blind source separation problem.","Synthetic images are generated by fusing multiple source images and the network's task is to reconstruct the original images, given the fused images.","A proper understanding of the image content is required to successfully solve the task.","We validate our method on two medical image segmentation tasks: brain tumor segmentation and white matter hyperintensities segmentation.","The results show that the proposed SI task outperforms traditional self-supervision tasks for dense predictions including inpainting, pixel shuffling, intensity shift, and super-resolution.","Among variations of the SI task fusing images of different types, fusing images from different patients performs best."],"url":"http://arxiv.org/abs/2307.02238v1"}
{"created":"2023-07-05 12:22:53","title":"Tit-for-Token: fair rewards for moving data in decentralized storage networks","abstract":"Centralized data silos are not only becoming prohibitively expensive but also raise issues of data ownership and data availability. These developments are affecting the industry, researchers, and ultimately society in general. Decentralized storage solutions present a promising alternative. Furthermore, such systems can become a crucial layer for new paradigms of edge-centric computing and web3 applications. Decentralized storage solutions based on p2p networks can enable scalable and self-sustaining open-source infrastructures. However, like other p2p systems, they require well-designed incentive mechanisms for participating peers. These mechanisms should be not only effective but also fair in regard to individual participants. Even though several such systems have been studied in deployment, there is still a lack of systematic understanding regarding these issues. We investigate the interplay between incentive mechanisms, network characteristics, and fairness of peer rewards. In particular, we identify and evaluate three core and up-to-date reward mechanisms for moving data in p2p networks: distance-based payments, reciprocity, and time-limited free service. Distance-based payments are relevant since libp2p Kademlia, which enables distance-based algorithms for content lookup and retrieval, is part of various modern p2p systems. We base our model on the Swarm network that uses a combination of the three mechanisms and serves as inspiration for our Tit-for-Token model. We present our Tit-for-Token model and develop a tool to explore the behaviors of these payment mechanisms. Our evaluation provides novel insights into the functioning and interplay of these mechanisms and helps. Based on these insights, we propose modifications to these mechanisms that better address fairness concerns and outline improvement proposals for the Swarm network.","sentences":["Centralized data silos are not only becoming prohibitively expensive but also raise issues of data ownership and data availability.","These developments are affecting the industry, researchers, and ultimately society in general.","Decentralized storage solutions present a promising alternative.","Furthermore, such systems can become a crucial layer for new paradigms of edge-centric computing and web3 applications.","Decentralized storage solutions based on p2p networks can enable scalable and self-sustaining open-source infrastructures.","However, like other p2p systems, they require well-designed incentive mechanisms for participating peers.","These mechanisms should be not only effective but also fair in regard to individual participants.","Even though several such systems have been studied in deployment, there is still a lack of systematic understanding regarding these issues.","We investigate the interplay between incentive mechanisms, network characteristics, and fairness of peer rewards.","In particular, we identify and evaluate three core and up-to-date reward mechanisms for moving data in p2p networks: distance-based payments, reciprocity, and time-limited free service.","Distance-based payments are relevant since libp2p Kademlia, which enables distance-based algorithms for content lookup and retrieval, is part of various modern p2p systems.","We base our model on the Swarm network that uses a combination of the three mechanisms and serves as inspiration for our Tit-for-Token model.","We present our Tit-for-Token model and develop a tool to explore the behaviors of these payment mechanisms.","Our evaluation provides novel insights into the functioning and interplay of these mechanisms and helps.","Based on these insights, we propose modifications to these mechanisms that better address fairness concerns and outline improvement proposals for the Swarm network."],"url":"http://arxiv.org/abs/2307.02231v1"}
{"created":"2023-07-05 12:13:56","title":"Knowledge-Guided Additive Modeling For Supervised Regression","abstract":"Learning processes by exploiting restricted domain knowledge is an important task across a plethora of scientific areas, with more and more hybrid methods combining data-driven and model-based approaches. However, while such hybrid methods have been tested in various scientific applications, they have been mostly tested on dynamical systems, with only limited study about the influence of each model component on global performance and parameter identification. In this work, we assess the performance of hybrid modeling against traditional machine learning methods on standard regression problems. We compare, on both synthetic and real regression problems, several approaches for training such hybrid models. We focus on hybrid methods that additively combine a parametric physical term with a machine learning term and investigate model-agnostic training procedures. We also introduce a new hybrid approach based on partial dependence functions. Experiments are carried out with different types of machine learning models, including tree-based models and artificial neural networks.","sentences":["Learning processes by exploiting restricted domain knowledge is an important task across a plethora of scientific areas, with more and more hybrid methods combining data-driven and model-based approaches.","However, while such hybrid methods have been tested in various scientific applications, they have been mostly tested on dynamical systems, with only limited study about the influence of each model component on global performance and parameter identification.","In this work, we assess the performance of hybrid modeling against traditional machine learning methods on standard regression problems.","We compare, on both synthetic and real regression problems, several approaches for training such hybrid models.","We focus on hybrid methods that additively combine a parametric physical term with a machine learning term and investigate model-agnostic training procedures.","We also introduce a new hybrid approach based on partial dependence functions.","Experiments are carried out with different types of machine learning models, including tree-based models and artificial neural networks."],"url":"http://arxiv.org/abs/2307.02229v1"}
{"created":"2023-07-05 12:08:56","title":"MAE-DFER: Efficient Masked Autoencoder for Self-supervised Dynamic Facial Expression Recognition","abstract":"Dynamic facial expression recognition (DFER) is essential to the development of intelligent and empathetic machines. Prior efforts in this field mainly fall into supervised learning paradigm, which is restricted by the limited labeled data in existing datasets. Inspired by recent unprecedented success of masked autoencoders (e.g., VideoMAE), this paper proposes MAE-DFER, a novel self-supervised method which leverages large-scale self-supervised pre-training on abundant unlabeled data to advance the development of DFER. Since the vanilla Vision Transformer (ViT) employed in VideoMAE requires substantial computation during fine-tuning, MAE-DFER develops an efficient local-global interaction Transformer (LGI-Former) as the encoder. LGI-Former first constrains self-attention in local spatiotemporal regions and then utilizes a small set of learnable representative tokens to achieve efficient local-global information exchange, thus avoiding the expensive computation of global space-time self-attention in ViT. Moreover, in addition to the standalone appearance content reconstruction in VideoMAE, MAE-DFER also introduces explicit facial motion modeling to encourage LGI-Former to excavate both static appearance and dynamic motion information. Extensive experiments on six datasets show that MAE-DFER consistently outperforms state-of-the-art supervised methods by significant margins, verifying that it can learn powerful dynamic facial representations via large-scale self-supervised pre-training. Besides, it has comparable or even better performance than VideoMAE, while largely reducing the computational cost (about 38\\% FLOPs). We believe MAE-DFER has paved a new way for the advancement of DFER and can inspire more relavant research in this field and even other related tasks. Codes and models are publicly available at https://github.com/sunlicai/MAE-DFER.","sentences":["Dynamic facial expression recognition (DFER) is essential to the development of intelligent and empathetic machines.","Prior efforts in this field mainly fall into supervised learning paradigm, which is restricted by the limited labeled data in existing datasets.","Inspired by recent unprecedented success of masked autoencoders (e.g., VideoMAE), this paper proposes MAE-DFER, a novel self-supervised method which leverages large-scale self-supervised pre-training on abundant unlabeled data to advance the development of DFER.","Since the vanilla Vision Transformer (ViT) employed in VideoMAE requires substantial computation during fine-tuning, MAE-DFER develops an efficient local-global interaction Transformer (LGI-Former) as the encoder.","LGI-Former first constrains self-attention in local spatiotemporal regions and then utilizes a small set of learnable representative tokens to achieve efficient local-global information exchange, thus avoiding the expensive computation of global space-time self-attention in ViT.","Moreover, in addition to the standalone appearance content reconstruction in VideoMAE, MAE-DFER also introduces explicit facial motion modeling to encourage LGI-Former to excavate both static appearance and dynamic motion information.","Extensive experiments on six datasets show that MAE-DFER consistently outperforms state-of-the-art supervised methods by significant margins, verifying that it can learn powerful dynamic facial representations via large-scale self-supervised pre-training.","Besides, it has comparable or even better performance than VideoMAE, while largely reducing the computational cost (about 38\\% FLOPs).","We believe MAE-DFER has paved a new way for the advancement of DFER and can inspire more relavant research in this field and even other related tasks.","Codes and models are publicly available at https://github.com/sunlicai/MAE-DFER."],"url":"http://arxiv.org/abs/2307.02227v1"}
{"created":"2023-07-05 11:58:58","title":"Personalized Federated Learning via Amortized Bayesian Meta-Learning","abstract":"Federated learning is a decentralized and privacy-preserving technique that enables multiple clients to collaborate with a server to learn a global model without exposing their private data. However, the presence of statistical heterogeneity among clients poses a challenge, as the global model may struggle to perform well on each client's specific task. To address this issue, we introduce a new perspective on personalized federated learning through Amortized Bayesian Meta-Learning. Specifically, we propose a novel algorithm called \\emph{FedABML}, which employs hierarchical variational inference across clients. The global prior aims to capture representations of common intrinsic structures from heterogeneous clients, which can then be transferred to their respective tasks and aid in the generation of accurate client-specific approximate posteriors through a few local updates. Our theoretical analysis provides an upper bound on the average generalization error and guarantees the generalization performance on unseen data. Finally, several empirical results are implemented to demonstrate that \\emph{FedABML} outperforms several competitive baselines.","sentences":["Federated learning is a decentralized and privacy-preserving technique that enables multiple clients to collaborate with a server to learn a global model without exposing their private data.","However, the presence of statistical heterogeneity among clients poses a challenge, as the global model may struggle to perform well on each client's specific task.","To address this issue, we introduce a new perspective on personalized federated learning through Amortized Bayesian Meta-Learning.","Specifically, we propose a novel algorithm called \\emph{FedABML}, which employs hierarchical variational inference across clients.","The global prior aims to capture representations of common intrinsic structures from heterogeneous clients, which can then be transferred to their respective tasks and aid in the generation of accurate client-specific approximate posteriors through a few local updates.","Our theoretical analysis provides an upper bound on the average generalization error and guarantees the generalization performance on unseen data.","Finally, several empirical results are implemented to demonstrate that \\emph{FedABML} outperforms several competitive baselines."],"url":"http://arxiv.org/abs/2307.02222v1"}
{"created":"2023-07-05 11:37:17","title":"Object Recognition System on a Tactile Device for Visually Impaired","abstract":"People with visual impairments face numerous challenges when interacting with their environment. Our objective is to develop a device that facilitates communication between individuals with visual impairments and their surroundings. The device will convert visual information into auditory feedback, enabling users to understand their environment in a way that suits their sensory needs. Initially, an object detection model is selected from existing machine learning models based on its accuracy and cost considerations, including time and power consumption. The chosen model is then implemented on a Raspberry Pi, which is connected to a specifically designed tactile device. When the device is touched at a specific position, it provides an audio signal that communicates the identification of the object present in the scene at that corresponding position to the visually impaired individual. Conducted tests have demonstrated the effectiveness of this device in scene understanding, encompassing static or dynamic objects, as well as screen contents such as TVs, computers, and mobile phones.","sentences":["People with visual impairments face numerous challenges when interacting with their environment.","Our objective is to develop a device that facilitates communication between individuals with visual impairments and their surroundings.","The device will convert visual information into auditory feedback, enabling users to understand their environment in a way that suits their sensory needs.","Initially, an object detection model is selected from existing machine learning models based on its accuracy and cost considerations, including time and power consumption.","The chosen model is then implemented on a Raspberry Pi, which is connected to a specifically designed tactile device.","When the device is touched at a specific position, it provides an audio signal that communicates the identification of the object present in the scene at that corresponding position to the visually impaired individual.","Conducted tests have demonstrated the effectiveness of this device in scene understanding, encompassing static or dynamic objects, as well as screen contents such as TVs, computers, and mobile phones."],"url":"http://arxiv.org/abs/2307.02211v1"}
{"created":"2023-07-05 11:06:32","title":"An Approximation Algorithm for the Exact Matching Problem in Bipartite Graphs","abstract":"In 1982 Papadimitriou and Yannakakis introduced the Exact Matching problem, in which given a red and blue edge-colored graph $G$ and an integer $k$ one has to decide whether there exists a perfect matching in $G$ with exactly $k$ red edges. Even though a randomized polynomial-time algorithm for this problem was quickly found a few years later, it is still unknown today whether a deterministic polynomial-time algorithm exists. This makes the Exact Matching problem an important candidate to test the RP=P hypothesis.   In this paper we focus on approximating Exact Matching. While there exists a simple algorithm that computes in deterministic polynomial-time an almost perfect matching with exactly $k$ red edges, not a lot of work focuses on computing perfect matchings with almost $k$ red edges. In fact such an algorithm for bipartite graphs running in deterministic polynomial-time was published only recently (STACS'23). It outputs a perfect matching with $k'$ red edges with the guarantee that $0.5k \\leq k' \\leq 1.5k$. In the present paper we aim at approximating the number of red edges without exceeding the limit of $k$ red edges. We construct a deterministic polynomial-time algorithm, which on bipartite graphs computes a perfect matching with $k'$ red edges such that $k/3 \\leq k' \\leq k$.","sentences":["In 1982 Papadimitriou and Yannakakis introduced the Exact Matching problem, in which given a red and blue edge-colored graph $G$ and an integer $k$ one has to decide whether there exists a perfect matching in $G$ with exactly $k$ red edges.","Even though a randomized polynomial-time algorithm for this problem was quickly found a few years later, it is still unknown today whether a deterministic polynomial-time algorithm exists.","This makes the Exact Matching problem an important candidate to test the RP=P hypothesis.   ","In this paper we focus on approximating Exact Matching.","While there exists a simple algorithm that computes in deterministic polynomial-time an almost perfect matching with exactly $k$ red edges, not a lot of work focuses on computing perfect matchings with almost $k$ red edges.","In fact such an algorithm for bipartite graphs running in deterministic polynomial-time was published only recently (STACS'23).","It outputs a perfect matching with $k'$ red edges with the guarantee that $0.5k \\leq k' \\leq 1.5k$.","In the present paper we aim at approximating the number of red edges without exceeding the limit of $k$ red edges.","We construct a deterministic polynomial-time algorithm, which on bipartite graphs computes a perfect matching with $k'$ red edges such that $k/3 \\leq k' \\leq k$."],"url":"http://arxiv.org/abs/2307.02205v1"}
{"created":"2023-07-05 10:54:50","title":"Neural Fields for Interactive Visualization of Statistical Dependencies in 3D Simulation Ensembles","abstract":"We present the first neural network that has learned to compactly represent and can efficiently reconstruct the statistical dependencies between the values of physical variables at different spatial locations in large 3D simulation ensembles. Going beyond linear dependencies, we consider mutual information as a measure of non-linear dependence. We demonstrate learning and reconstruction with a large weather forecast ensemble comprising 1000 members, each storing multiple physical variables at a 250 x 352 x 20 simulation grid. By circumventing compute-intensive statistical estimators at runtime, we demonstrate significantly reduced memory and computation requirements for reconstructing the major dependence structures. This enables embedding the estimator into a GPU-accelerated direct volume renderer and interactively visualizing all mutual dependencies for a selected domain point.","sentences":["We present the first neural network that has learned to compactly represent and can efficiently reconstruct the statistical dependencies between the values of physical variables at different spatial locations in large 3D simulation ensembles.","Going beyond linear dependencies, we consider mutual information as a measure of non-linear dependence.","We demonstrate learning and reconstruction with a large weather forecast ensemble comprising 1000 members, each storing multiple physical variables at a 250 x 352 x 20 simulation grid.","By circumventing compute-intensive statistical estimators at runtime, we demonstrate significantly reduced memory and computation requirements for reconstructing the major dependence structures.","This enables embedding the estimator into a GPU-accelerated direct volume renderer and interactively visualizing all mutual dependencies for a selected domain point."],"url":"http://arxiv.org/abs/2307.02203v1"}
{"created":"2023-07-05 10:53:49","title":"On the Adversarial Robustness of Generative Autoencoders in the Latent Space","abstract":"The generative autoencoders, such as the variational autoencoders or the adversarial autoencoders, have achieved great success in lots of real-world applications, including image generation, and signal communication.   However, little concern has been devoted to their robustness during practical deployment.   Due to the probabilistic latent structure, variational autoencoders (VAEs) may confront problems such as a mismatch between the posterior distribution of the latent and real data manifold, or discontinuity in the posterior distribution of the latent.   This leaves a back door for malicious attackers to collapse VAEs from the latent space, especially in scenarios where the encoder and decoder are used separately, such as communication and compressed sensing.   In this work, we provide the first study on the adversarial robustness of generative autoencoders in the latent space.   Specifically, we empirically demonstrate the latent vulnerability of popular generative autoencoders through attacks in the latent space.   We also evaluate the difference between variational autoencoders and their deterministic variants and observe that the latter performs better in latent robustness.   Meanwhile, we identify a potential trade-off between the adversarial robustness and the degree of the disentanglement of the latent codes.   Additionally, we also verify the feasibility of improvement for the latent robustness of VAEs through adversarial training.   In summary, we suggest concerning the adversarial latent robustness of the generative autoencoders, analyze several robustness-relative issues, and give some insights into a series of key challenges.","sentences":["The generative autoencoders, such as the variational autoencoders or the adversarial autoencoders, have achieved great success in lots of real-world applications, including image generation, and signal communication.   ","However, little concern has been devoted to their robustness during practical deployment.   ","Due to the probabilistic latent structure, variational autoencoders (VAEs) may confront problems such as a mismatch between the posterior distribution of the latent and real data manifold, or discontinuity in the posterior distribution of the latent.   ","This leaves a back door for malicious attackers to collapse VAEs from the latent space, especially in scenarios where the encoder and decoder are used separately, such as communication and compressed sensing.   ","In this work, we provide the first study on the adversarial robustness of generative autoencoders in the latent space.   ","Specifically, we empirically demonstrate the latent vulnerability of popular generative autoencoders through attacks in the latent space.   ","We also evaluate the difference between variational autoencoders and their deterministic variants and observe that the latter performs better in latent robustness.   ","Meanwhile, we identify a potential trade-off between the adversarial robustness and the degree of the disentanglement of the latent codes.   ","Additionally, we also verify the feasibility of improvement for the latent robustness of VAEs through adversarial training.   ","In summary, we suggest concerning the adversarial latent robustness of the generative autoencoders, analyze several robustness-relative issues, and give some insights into a series of key challenges."],"url":"http://arxiv.org/abs/2307.02202v1"}
{"created":"2023-07-05 10:52:02","title":"Multi-Agent Cooperation via Unsupervised Learning of Joint Intentions","abstract":"The field of cooperative multi-agent reinforcement learning (MARL) has seen widespread use in addressing complex coordination tasks. While value decomposition methods in MARL have been popular, they have limitations in solving tasks with non-monotonic returns, restricting their general application. Our work highlights the significance of joint intentions in cooperation, which can overcome non-monotonic problems and increase the interpretability of the learning process. To this end, we present a novel MARL method that leverages learnable joint intentions. Our method employs a hierarchical framework consisting of a joint intention policy and a behavior policy to formulate the optimal cooperative policy. The joint intentions are autonomously learned in a latent space through unsupervised learning and enable the method adaptable to different agent configurations. Our results demonstrate significant performance improvements in both the StarCraft micromanagement benchmark and challenging MAgent domains, showcasing the effectiveness of our method in learning meaningful joint intentions.","sentences":["The field of cooperative multi-agent reinforcement learning (MARL) has seen widespread use in addressing complex coordination tasks.","While value decomposition methods in MARL have been popular, they have limitations in solving tasks with non-monotonic returns, restricting their general application.","Our work highlights the significance of joint intentions in cooperation, which can overcome non-monotonic problems and increase the interpretability of the learning process.","To this end, we present a novel MARL method that leverages learnable joint intentions.","Our method employs a hierarchical framework consisting of a joint intention policy and a behavior policy to formulate the optimal cooperative policy.","The joint intentions are autonomously learned in a latent space through unsupervised learning and enable the method adaptable to different agent configurations.","Our results demonstrate significant performance improvements in both the StarCraft micromanagement benchmark and challenging MAgent domains, showcasing the effectiveness of our method in learning meaningful joint intentions."],"url":"http://arxiv.org/abs/2307.02200v1"}
{"created":"2023-07-05 10:50:40","title":"ChiENN: Embracing Molecular Chirality with Graph Neural Networks","abstract":"Graph Neural Networks (GNNs) play a fundamental role in many deep learning problems, in particular in cheminformatics. However, typical GNNs cannot capture the concept of chirality, which means they do not distinguish between the 3D graph of a chemical compound and its mirror image (enantiomer). The ability to distinguish between enantiomers is important especially in drug discovery because enantiomers can have very distinct biochemical properties. In this paper, we propose a theoretically justified message-passing scheme, which makes GNNs sensitive to the order of node neighbors. We apply that general concept in the context of molecular chirality to construct Chiral Edge Neural Network (ChiENN) layer which can be appended to any GNN model to enable chirality-awareness. Our experiments show that adding ChiENN layers to a GNN outperforms current state-of-the-art methods in chiral-sensitive molecular property prediction tasks.","sentences":["Graph Neural Networks (GNNs) play a fundamental role in many deep learning problems, in particular in cheminformatics.","However, typical GNNs cannot capture the concept of chirality, which means they do not distinguish between the 3D graph of a chemical compound and its mirror image (enantiomer).","The ability to distinguish between enantiomers is important especially in drug discovery because enantiomers can have very distinct biochemical properties.","In this paper, we propose a theoretically justified message-passing scheme, which makes GNNs sensitive to the order of node neighbors.","We apply that general concept in the context of molecular chirality to construct Chiral Edge Neural Network (ChiENN) layer which can be appended to any GNN model to enable chirality-awareness.","Our experiments show that adding ChiENN layers to a GNN outperforms current state-of-the-art methods in chiral-sensitive molecular property prediction tasks."],"url":"http://arxiv.org/abs/2307.02198v1"}
{"created":"2023-07-05 10:41:54","title":"Abstractions, Scenarios, and Prompt Definitions for Process Mining with LLMs: A Case Study","abstract":"Large Language Models (LLMs) are capable of answering questions in natural language for various purposes. With recent advancements (such as GPT-4), LLMs perform at a level comparable to humans for many proficient tasks. The analysis of business processes could benefit from a natural process querying language and using the domain knowledge on which LLMs have been trained. However, it is impossible to provide a complete database or event log as an input prompt due to size constraints. In this paper, we apply LLMs in the context of process mining by i) abstracting the information of standard process mining artifacts and ii) describing the prompting strategies. We implement the proposed abstraction techniques into pm4py, an open-source process mining library. We present a case study using available event logs. Starting from different abstractions and analysis questions, we formulate prompts and evaluate the quality of the answers.","sentences":["Large Language Models (LLMs) are capable of answering questions in natural language for various purposes.","With recent advancements (such as GPT-4), LLMs perform at a level comparable to humans for many proficient tasks.","The analysis of business processes could benefit from a natural process querying language and using the domain knowledge on which LLMs have been trained.","However, it is impossible to provide a complete database or event log as an input prompt due to size constraints.","In this paper, we apply LLMs in the context of process mining by i) abstracting the information of standard process mining artifacts and ii) describing the prompting strategies.","We implement the proposed abstraction techniques into pm4py, an open-source process mining library.","We present a case study using available event logs.","Starting from different abstractions and analysis questions, we formulate prompts and evaluate the quality of the answers."],"url":"http://arxiv.org/abs/2307.02194v1"}
{"created":"2023-07-05 10:41:21","title":"Directed Poincar\u00e9 Inequalities and $L^1$ Monotonicity Testing of Lipschitz Functions","abstract":"We study the connection between directed isoperimetric inequalities and monotonicity testing. In recent years, this connection has unlocked breakthroughs for testing monotonicity of functions defined on discrete domains. Inspired the rich history of isoperimetric inequalities in continuous settings, we propose that studying the relationship between directed isoperimetry and monotonicity in such settings is essential for understanding the full scope of this connection.   Hence, we ask whether directed isoperimetric inequalities hold for functions $f : [0,1]^n \\to \\mathbb{R}$, and whether this question has implications for monotonicity testing. We answer both questions affirmatively. For Lipschitz functions $f : [0,1]^n \\to \\mathbb{R}$, we show the inequality $d^{\\mathsf{mono}}_1(f) \\lesssim \\mathbb{E}\\left[\\|\\nabla^- f\\|_1\\right]$, which upper bounds the $L^1$ distance to monotonicity of $f$ by a measure of its \"directed gradient\". A key ingredient in our proof is the monotone rearrangement of $f$, which generalizes the classical \"sorting operator\" to continuous settings. We use this inequality to give an $L^1$ monotonicity tester for Lipschitz functions $f : [0,1]^n \\to \\mathbb{R}$, and this framework also implies similar results for testing real-valued functions on the hypergrid.","sentences":["We study the connection between directed isoperimetric inequalities and monotonicity testing.","In recent years, this connection has unlocked breakthroughs for testing monotonicity of functions defined on discrete domains.","Inspired the rich history of isoperimetric inequalities in continuous settings, we propose that studying the relationship between directed isoperimetry and monotonicity in such settings is essential for understanding the full scope of this connection.   ","Hence, we ask whether directed isoperimetric inequalities hold for functions $f : [0,1]^n \\to \\mathbb{R}$, and whether this question has implications for monotonicity testing.","We answer both questions affirmatively.","For Lipschitz functions $f : [0,1]^n \\to \\mathbb{R}$, we show the inequality $d^{\\mathsf{mono}}_1(f) \\lesssim \\mathbb{E}\\left[\\|\\nabla^- f\\|_1\\right]$, which upper bounds the $L^1$ distance to monotonicity of $f$ by a measure of its \"directed gradient\".","A key ingredient in our proof is the monotone rearrangement of $f$, which generalizes the classical \"sorting operator\" to continuous settings.","We use this inequality to give an $L^1$ monotonicity tester for Lipschitz functions $f : [0,1]^n \\to \\mathbb{R}$, and this framework also implies similar results for testing real-valued functions on the hypergrid."],"url":"http://arxiv.org/abs/2307.02193v1"}
{"created":"2023-07-05 10:39:58","title":"The FormAI Dataset: Generative AI in Software Security Through the Lens of Formal Verification","abstract":"This paper presents the FormAI dataset, a large collection of 112,000 AI-generated compilable and independent C programs with vulnerability classification. We introduce a dynamic zero-shot prompting technique, constructed to spawn a diverse set of programs utilizing Large Language Models (LLMs). The dataset is generated by GPT-3.5-turbo and comprises programs with varying levels of complexity. Some programs handle complicated tasks such as network management, table games, or encryption, while others deal with simpler tasks like string manipulation. Every program is labeled with the vulnerabilities found within the source code, indicating the type, line number, and vulnerable function name. This is accomplished by employing a formal verification method using the Efficient SMT-based Bounded Model Checker (ESBMC), which performs model checking, abstract interpretation, constraint programming, and satisfiability modulo theories, to reason over safety/security properties in programs. This approach definitively detects vulnerabilities and offers a formal model known as a counterexample, thus eliminating the possibility of generating false positive reports. This property of the dataset makes it suitable for evaluating the effectiveness of various static and dynamic analysis tools. Furthermore, we have associated the identified vulnerabilities with relevant Common Weakness Enumeration (CWE) numbers. We make the source code available for the 112,000 programs, accompanied by a comprehensive list detailing the vulnerabilities detected in each individual program including location and function name, which makes the dataset ideal to train LLMs and machine learning algorithms.","sentences":["This paper presents the FormAI dataset, a large collection of 112,000 AI-generated compilable and independent C programs with vulnerability classification.","We introduce a dynamic zero-shot prompting technique, constructed to spawn a diverse set of programs utilizing Large Language Models (LLMs).","The dataset is generated by GPT-3.5-turbo and comprises programs with varying levels of complexity.","Some programs handle complicated tasks such as network management, table games, or encryption, while others deal with simpler tasks like string manipulation.","Every program is labeled with the vulnerabilities found within the source code, indicating the type, line number, and vulnerable function name.","This is accomplished by employing a formal verification method using the Efficient SMT-based Bounded Model Checker (ESBMC), which performs model checking, abstract interpretation, constraint programming, and satisfiability modulo theories, to reason over safety/security properties in programs.","This approach definitively detects vulnerabilities and offers a formal model known as a counterexample, thus eliminating the possibility of generating false positive reports.","This property of the dataset makes it suitable for evaluating the effectiveness of various static and dynamic analysis tools.","Furthermore, we have associated the identified vulnerabilities with relevant Common Weakness Enumeration (CWE) numbers.","We make the source code available for the 112,000 programs, accompanied by a comprehensive list detailing the vulnerabilities detected in each individual program including location and function name, which makes the dataset ideal to train LLMs and machine learning algorithms."],"url":"http://arxiv.org/abs/2307.02192v1"}
{"created":"2023-07-05 10:33:45","title":"Evaluating AI systems under uncertain ground truth: a case study in dermatology","abstract":"For safety, AI systems in health undergo thorough evaluations before deployment, validating their predictions against a ground truth that is assumed certain. However, this is actually not the case and the ground truth may be uncertain. Unfortunately, this is largely ignored in standard evaluation of AI models but can have severe consequences such as overestimating the future performance. To avoid this, we measure the effects of ground truth uncertainty, which we assume decomposes into two main components: annotation uncertainty which stems from the lack of reliable annotations, and inherent uncertainty due to limited observational information. This ground truth uncertainty is ignored when estimating the ground truth by deterministically aggregating annotations, e.g., by majority voting or averaging. In contrast, we propose a framework where aggregation is done using a statistical model. Specifically, we frame aggregation of annotations as posterior inference of so-called plausibilities, representing distributions over classes in a classification setting, subject to a hyper-parameter encoding annotator reliability. Based on this model, we propose a metric for measuring annotation uncertainty and provide uncertainty-adjusted metrics for performance evaluation. We present a case study applying our framework to skin condition classification from images where annotations are provided in the form of differential diagnoses. The deterministic adjudication process called inverse rank normalization (IRN) from previous work ignores ground truth uncertainty in evaluation. Instead, we present two alternative statistical models: a probabilistic version of IRN and a Plackett-Luce-based model. We find that a large portion of the dataset exhibits significant ground truth uncertainty and standard IRN-based evaluation severely over-estimates performance without providing uncertainty estimates.","sentences":["For safety, AI systems in health undergo thorough evaluations before deployment, validating their predictions against a ground truth that is assumed certain.","However, this is actually not the case and the ground truth may be uncertain.","Unfortunately, this is largely ignored in standard evaluation of AI models but can have severe consequences such as overestimating the future performance.","To avoid this, we measure the effects of ground truth uncertainty, which we assume decomposes into two main components: annotation uncertainty which stems from the lack of reliable annotations, and inherent uncertainty due to limited observational information.","This ground truth uncertainty is ignored when estimating the ground truth by deterministically aggregating annotations, e.g., by majority voting or averaging.","In contrast, we propose a framework where aggregation is done using a statistical model.","Specifically, we frame aggregation of annotations as posterior inference of so-called plausibilities, representing distributions over classes in a classification setting, subject to a hyper-parameter encoding annotator reliability.","Based on this model, we propose a metric for measuring annotation uncertainty and provide uncertainty-adjusted metrics for performance evaluation.","We present a case study applying our framework to skin condition classification from images where annotations are provided in the form of differential diagnoses.","The deterministic adjudication process called inverse rank normalization (IRN) from previous work ignores ground truth uncertainty in evaluation.","Instead, we present two alternative statistical models: a probabilistic version of IRN and a Plackett-Luce-based model.","We find that a large portion of the dataset exhibits significant ground truth uncertainty and standard IRN-based evaluation severely over-estimates performance without providing uncertainty estimates."],"url":"http://arxiv.org/abs/2307.02191v1"}
{"created":"2023-07-05 10:25:45","title":"Citation: A Key to Building Responsible and Accountable Large Language Models","abstract":"Large Language Models (LLMs) bring transformative benefits alongside unique challenges, including intellectual property (IP) and ethical concerns. This position paper explores a novel angle to mitigate these risks, drawing parallels between LLMs and established web systems. We identify \"citation\" as a crucial yet missing component in LLMs, which could enhance content transparency and verifiability while addressing IP and ethical dilemmas. We further propose that a comprehensive citation mechanism for LLMs should account for both non-parametric and parametric content. Despite the complexity of implementing such a citation mechanism, along with the inherent potential pitfalls, we advocate for its development. Building on this foundation, we outline several research problems in this area, aiming to guide future explorations towards building more responsible and accountable LLMs.","sentences":["Large Language Models (LLMs) bring transformative benefits alongside unique challenges, including intellectual property (IP) and ethical concerns.","This position paper explores a novel angle to mitigate these risks, drawing parallels between LLMs and established web systems.","We identify \"citation\" as a crucial yet missing component in LLMs, which could enhance content transparency and verifiability while addressing IP and ethical dilemmas.","We further propose that a comprehensive citation mechanism for LLMs should account for both non-parametric and parametric content.","Despite the complexity of implementing such a citation mechanism, along with the inherent potential pitfalls, we advocate for its development.","Building on this foundation, we outline several research problems in this area, aiming to guide future explorations towards building more responsible and accountable LLMs."],"url":"http://arxiv.org/abs/2307.02185v1"}
{"created":"2023-07-05 10:22:53","title":"An Equivalent Graph Reconstruction Model and its Application in Recommendation Prediction","abstract":"Recommendation algorithm plays an important role in recommendation system (RS), which predicts users' interests and preferences for some given items based on their known information. Recently, a recommendation algorithm based on the graph Laplacian regularization was proposed, which treats the prediction problem of the recommendation system as a reconstruction issue of small samples of the graph signal under the same graph model. Such a technique takes into account both known and unknown labeled samples information, thereby obtaining good prediction accuracy. However, when the data size is large, solving the reconstruction model is computationally expensive even with an approximate strategy. In this paper, we propose an equivalent reconstruction model that can be solved exactly with extremely low computational cost. Finally, a final prediction algorithm is proposed. We find in the experiments that the proposed method significantly reduces the computational cost while maintaining a good prediction accuracy.","sentences":["Recommendation algorithm plays an important role in recommendation system (RS), which predicts users' interests and preferences for some given items based on their known information.","Recently, a recommendation algorithm based on the graph Laplacian regularization was proposed, which treats the prediction problem of the recommendation system as a reconstruction issue of small samples of the graph signal under the same graph model.","Such a technique takes into account both known and unknown labeled samples information, thereby obtaining good prediction accuracy.","However, when the data size is large, solving the reconstruction model is computationally expensive even with an approximate strategy.","In this paper, we propose an equivalent reconstruction model that can be solved exactly with extremely low computational cost.","Finally, a final prediction algorithm is proposed.","We find in the experiments that the proposed method significantly reduces the computational cost while maintaining a good prediction accuracy."],"url":"http://arxiv.org/abs/2307.02183v1"}
{"created":"2023-07-05 10:20:33","title":"A Scheme to resist Fast Correlation Attack for Word Oriented LFSR based Stream Cipher","abstract":"In LFSR-based stream ciphers, the knowledge of the feedback equation of the LFSR plays a critical role in most attacks. In word-based stream ciphers such as those in the SNOW series, even if the feedback configuration is hidden, knowing the characteristic polynomial of the state transition matrix of the LFSR enables the attacker to create a feedback equation over $GF(2)$. This, in turn, can be used to launch fast correlation attacks. In this work, we propose a method for hiding both the feedback equation of a word-based LFSR and the characteristic polynomial of the state transition matrix. Here, we employ a $z$-primitive $\\sigma$-LFSR whose characteristic polynomial is randomly sampled from the distribution of primitive polynomials over $GF(2)$ of the appropriate degree. We propose an algorithm for locating $z$-primitive $\\sigma$-LFSR configurations of a given degree. Further, an invertible matrix is generated from the key. This is then employed to generate a public parameter which is used to retrieve the feedback configuration using the key. If the key size is $n$- bits, the process of retrieving the feedback equation from the public parameter has a average time complexity $\\mathbb{O}(2^{n-1})$. The proposed method has been tested on SNOW 2.0 and SNOW 3G for resistance to fast correlation attacks. We have demonstrated that the security of SNOW 2.0 and SNOW 3G increases from 128 bits to 256 bits.","sentences":["In LFSR-based stream ciphers, the knowledge of the feedback equation of the LFSR plays a critical role in most attacks.","In word-based stream ciphers such as those in the SNOW series, even if the feedback configuration is hidden, knowing the characteristic polynomial of the state transition matrix of the LFSR enables the attacker to create a feedback equation over $GF(2)$. This, in turn, can be used to launch fast correlation attacks.","In this work, we propose a method for hiding both the feedback equation of a word-based LFSR and the characteristic polynomial of the state transition matrix.","Here, we employ a $z$-primitive $\\sigma$-LFSR whose characteristic polynomial is randomly sampled from the distribution of primitive polynomials over $GF(2)$ of the appropriate degree.","We propose an algorithm for locating $z$-primitive $\\sigma$-LFSR configurations of a given degree.","Further, an invertible matrix is generated from the key.","This is then employed to generate a public parameter which is used to retrieve the feedback configuration using the key.","If the key size is $n$- bits, the process of retrieving the feedback equation from the public parameter has a average time complexity $\\mathbb{O}(2^{n-1})$. The proposed method has been tested on SNOW 2.0 and SNOW 3G for resistance to fast correlation attacks.","We have demonstrated that the security of SNOW 2.0 and SNOW 3G increases from 128 bits to 256 bits."],"url":"http://arxiv.org/abs/2307.02182v1"}
{"created":"2023-07-05 10:18:51","title":"Runtime Repeated Recursion Unfolding: A Just-In-Time Online Program Optimization That Can Achieve Super-Linear Speedup","abstract":"We introduce a just-in-time runtime program transformation based on repeated recursion unfolding. Our online polyvariant program specialization generates several versions of a recursion differentiated by the minimal number of recursive steps covered. The base case of the recursion is ignored in our technique.   Our method is presented here on the basis of linear direct recursive rules. When a recursive call is encountered at runtime, first an unfolder creates specializations of the associated recursive rule on-the-fly and then an interpreter applies these rules to the call. Our approach reduces the number of recursive rule applications to its logarithm at the expense of introducing a logarithmic number of unfolded rules. Each rule is applied at most once.   We prove correctness of our technique and determine its worst-case time complexity. For recursions that solve tractable problems and which have enough unfoldings that can sufficiently simplified, we prove a super-linear speedup theorem, i.e. speedup by more than a constant factor. The simplification is problem-specific and has to be provided at compile-time. In the best case, the complexity of the given recursion is reduced to that of its first recursive step.   We have implemented the necessary unfolder and meta-interpreter for runtime repeated recursion unfolding in Constraint Handling Rules (CHR) with just five rules. We illustrate the feasibility of our approach with complexity results and benchmarks for several classical algorithms. The runtime improvement quickly reaches several orders of magnitude.","sentences":["We introduce a just-in-time runtime program transformation based on repeated recursion unfolding.","Our online polyvariant program specialization generates several versions of a recursion differentiated by the minimal number of recursive steps covered.","The base case of the recursion is ignored in our technique.   ","Our method is presented here on the basis of linear direct recursive rules.","When a recursive call is encountered at runtime, first an unfolder creates specializations of the associated recursive rule on-the-fly and then an interpreter applies these rules to the call.","Our approach reduces the number of recursive rule applications to its logarithm at the expense of introducing a logarithmic number of unfolded rules.","Each rule is applied at most once.   ","We prove correctness of our technique and determine its worst-case time complexity.","For recursions that solve tractable problems and which have enough unfoldings that can sufficiently simplified, we prove a super-linear speedup theorem, i.e. speedup by more than a constant factor.","The simplification is problem-specific and has to be provided at compile-time.","In the best case, the complexity of the given recursion is reduced to that of its first recursive step.   ","We have implemented the necessary unfolder and meta-interpreter for runtime repeated recursion unfolding in Constraint Handling Rules (CHR) with just five rules.","We illustrate the feasibility of our approach with complexity results and benchmarks for several classical algorithms.","The runtime improvement quickly reaches several orders of magnitude."],"url":"http://arxiv.org/abs/2307.02180v1"}
{"created":"2023-07-05 10:15:07","title":"Open-Source Large Language Models Outperform Crowd Workers and Approach ChatGPT in Text-Annotation Tasks","abstract":"This study examines the performance of open-source Large Language Models (LLMs) in text annotation tasks and compares it with proprietary models like ChatGPT and human-based services such as MTurk. While prior research demonstrated the high performance of ChatGPT across numerous NLP tasks, open-source LLMs like HugginChat and FLAN are gaining attention for their cost-effectiveness, transparency, reproducibility, and superior data protection. We assess these models using both zero-shot and few-shot approaches and different temperature parameters across a range of text annotation tasks. Our findings show that while ChatGPT achieves the best performance in most tasks, open-source LLMs not only outperform MTurk but also demonstrate competitive potential against ChatGPT in specific tasks.","sentences":["This study examines the performance of open-source Large Language Models (LLMs) in text annotation tasks and compares it with proprietary models like ChatGPT and human-based services such as MTurk.","While prior research demonstrated the high performance of ChatGPT across numerous NLP tasks, open-source LLMs like HugginChat and FLAN are gaining attention for their cost-effectiveness, transparency, reproducibility, and superior data protection.","We assess these models using both zero-shot and few-shot approaches and different temperature parameters across a range of text annotation tasks.","Our findings show that while ChatGPT achieves the best performance in most tasks, open-source LLMs not only outperform MTurk but also demonstrate competitive potential against ChatGPT in specific tasks."],"url":"http://arxiv.org/abs/2307.02179v1"}
{"created":"2023-07-05 10:07:44","title":"Age of Information Analysis in Shared Edge Computing Servers","abstract":"Mobile Edge Computing (MEC) is expected to play a significant role in the development of 6G networks, as new applications such as cooperative driving and eXtended Reality (XR) require both communication and computational resources from the network edge. However, the limited capabilities of edge servers may be strained to perform complex computational tasks within strict latency bounds for multiple clients. In these contexts, both maintaining a low average Age of Information (AoI) and guaranteeing a low Peak AoI (PAoI) even in the worst case may have significant user experience and safety implications. In this work, we investigate a theoretical model of a MEC server, deriving the expected AoI and the PAoI and latency distributions under the First In First Out (FIFO) and Generalized Processor Sharing (GPS) resource allocation policies. We consider both synchronized and unsynchronized systems, and draw insights on the robust design of resource allocation policies from the analytical results.","sentences":["Mobile Edge Computing (MEC) is expected to play a significant role in the development of 6G networks, as new applications such as cooperative driving and eXtended Reality (XR) require both communication and computational resources from the network edge.","However, the limited capabilities of edge servers may be strained to perform complex computational tasks within strict latency bounds for multiple clients.","In these contexts, both maintaining a low average Age of Information (AoI) and guaranteeing a low Peak AoI (PAoI) even in the worst case may have significant user experience and safety implications.","In this work, we investigate a theoretical model of a MEC server, deriving the expected AoI and the PAoI and latency distributions under the First In First Out (FIFO) and Generalized Processor Sharing (GPS) resource allocation policies.","We consider both synchronized and unsynchronized systems, and draw insights on the robust design of resource allocation policies from the analytical results."],"url":"http://arxiv.org/abs/2307.02166v1"}
{"created":"2023-07-05 10:06:10","title":"Safety Shielding under Delayed Observation","abstract":"Agents operating in physical environments need to be able to handle delays in the input and output signals since neither data transmission nor sensing or actuating the environment are instantaneous. Shields are correct-by-construction runtime enforcers that guarantee safe execution by correcting any action that may cause a violation of a formal safety specification. Besides providing safety guarantees, shields should interfere minimally with the agent. Therefore, shields should pick the safe corrective actions in such a way that future interferences are most likely minimized. Current shielding approaches do not consider possible delays in the input signals in their safety analyses. In this paper, we address this issue. We propose synthesis algorithms to compute \\emph{delay-resilient shields} that guarantee safety under worst-case assumptions on the delays of the input signals. We also introduce novel heuristics for deciding between multiple corrective actions, designed to minimize future shield interferences caused by delays. As a further contribution, we present the first integration of shields in a realistic driving simulator. We implemented our delayed shields in the driving simulator \\textsc{Carla}. We shield potentially unsafe autonomous driving agents in different safety-critical scenarios and show the effect of delays on the safety analysis.","sentences":["Agents operating in physical environments need to be able to handle delays in the input and output signals since neither data transmission nor sensing or actuating the environment are instantaneous.","Shields are correct-by-construction runtime enforcers that guarantee safe execution by correcting any action that may cause a violation of a formal safety specification.","Besides providing safety guarantees, shields should interfere minimally with the agent.","Therefore, shields should pick the safe corrective actions in such a way that future interferences are most likely minimized.","Current shielding approaches do not consider possible delays in the input signals in their safety analyses.","In this paper, we address this issue.","We propose synthesis algorithms to compute \\emph{delay-resilient shields} that guarantee safety under worst-case assumptions on the delays of the input signals.","We also introduce novel heuristics for deciding between multiple corrective actions, designed to minimize future shield interferences caused by delays.","As a further contribution, we present the first integration of shields in a realistic driving simulator.","We implemented our delayed shields in the driving simulator \\textsc{Carla}.","We shield potentially unsafe autonomous driving agents in different safety-critical scenarios and show the effect of delays on the safety analysis."],"url":"http://arxiv.org/abs/2307.02164v1"}
{"created":"2023-07-05 10:03:08","title":"Multi Object Tracking for Predictive Collision Avoidance","abstract":"The safe and efficient operation of Autonomous Mobile Robots (AMRs) in complex environments, such as manufacturing, logistics, and agriculture, necessitates accurate multi-object tracking and predictive collision avoidance. This paper presents algorithms and techniques for addressing these challenges using Lidar sensor data, emphasizing ensemble Kalman filter. The developed predictive collision avoidance algorithm employs the data provided by lidar sensors to track multiple objects and predict their velocities and future positions, enabling the AMR to navigate safely and effectively. A modification to the dynamic windowing approach is introduced to enhance the performance of the collision avoidance system. The overall system architecture encompasses object detection, multi-object tracking, and predictive collision avoidance control. The experimental results, obtained from both simulation and real-world data, demonstrate the effectiveness of the proposed methods in various scenarios, which lays the foundation for future research on global planners, other controllers, and the integration of additional sensors. This thesis contributes to the ongoing development of safe and efficient autonomous systems in complex and dynamic environments.","sentences":["The safe and efficient operation of Autonomous Mobile Robots (AMRs) in complex environments, such as manufacturing, logistics, and agriculture, necessitates accurate multi-object tracking and predictive collision avoidance.","This paper presents algorithms and techniques for addressing these challenges using Lidar sensor data, emphasizing ensemble Kalman filter.","The developed predictive collision avoidance algorithm employs the data provided by lidar sensors to track multiple objects and predict their velocities and future positions, enabling the AMR to navigate safely and effectively.","A modification to the dynamic windowing approach is introduced to enhance the performance of the collision avoidance system.","The overall system architecture encompasses object detection, multi-object tracking, and predictive collision avoidance control.","The experimental results, obtained from both simulation and real-world data, demonstrate the effectiveness of the proposed methods in various scenarios, which lays the foundation for future research on global planners, other controllers, and the integration of additional sensors.","This thesis contributes to the ongoing development of safe and efficient autonomous systems in complex and dynamic environments."],"url":"http://arxiv.org/abs/2307.02161v1"}
{"created":"2023-07-05 09:58:08","title":"Generative Job Recommendations with Large Language Model","abstract":"The rapid development of online recruitment services has encouraged the utilization of recommender systems to streamline the job seeking process. Predominantly, current job recommendations deploy either collaborative filtering or person-job matching strategies. However, these models tend to operate as \"black-box\" systems and lack the capacity to offer explainable guidance to job seekers. Moreover, conventional matching-based recommendation methods are limited to retrieving and ranking existing jobs in the database, restricting their potential as comprehensive career AI advisors. To this end, here we present GIRL (GeneratIve job Recommendation based on Large language models), a novel approach inspired by recent advancements in the field of Large Language Models (LLMs). We initially employ a Supervised Fine-Tuning (SFT) strategy to instruct the LLM-based generator in crafting suitable Job Descriptions (JDs) based on the Curriculum Vitae (CV) of a job seeker. Moreover, we propose to train a model which can evaluate the matching degree between CVs and JDs as a reward model, and we use Proximal Policy Optimization (PPO)-based Reinforcement Learning (RL) method to further fine-tine the generator. This aligns the generator with recruiter feedback, tailoring the output to better meet employer preferences. In particular, GIRL serves as a job seeker-centric generative model, providing job suggestions without the need of a candidate set. This capability also enhances the performance of existing job recommendation models by supplementing job seeking features with generated content. With extensive experiments on a large-scale real-world dataset, we demonstrate the substantial effectiveness of our approach. We believe that GIRL introduces a paradigm-shifting approach to job recommendation systems, fostering a more personalized and comprehensive job-seeking experience.","sentences":["The rapid development of online recruitment services has encouraged the utilization of recommender systems to streamline the job seeking process.","Predominantly, current job recommendations deploy either collaborative filtering or person-job matching strategies.","However, these models tend to operate as \"black-box\" systems and lack the capacity to offer explainable guidance to job seekers.","Moreover, conventional matching-based recommendation methods are limited to retrieving and ranking existing jobs in the database, restricting their potential as comprehensive career AI advisors.","To this end, here we present GIRL (GeneratIve job Recommendation based on Large language models), a novel approach inspired by recent advancements in the field of Large Language Models (LLMs).","We initially employ a Supervised Fine-Tuning (SFT) strategy to instruct the LLM-based generator in crafting suitable Job Descriptions (JDs) based on the Curriculum Vitae (CV) of a job seeker.","Moreover, we propose to train a model which can evaluate the matching degree between CVs and JDs as a reward model, and we use Proximal Policy Optimization (PPO)-based Reinforcement Learning (RL) method to further fine-tine the generator.","This aligns the generator with recruiter feedback, tailoring the output to better meet employer preferences.","In particular, GIRL serves as a job seeker-centric generative model, providing job suggestions without the need of a candidate set.","This capability also enhances the performance of existing job recommendation models by supplementing job seeking features with generated content.","With extensive experiments on a large-scale real-world dataset, we demonstrate the substantial effectiveness of our approach.","We believe that GIRL introduces a paradigm-shifting approach to job recommendation systems, fostering a more personalized and comprehensive job-seeking experience."],"url":"http://arxiv.org/abs/2307.02157v1"}
{"created":"2023-07-05 09:46:41","title":"Harmonizing Feature Attributions Across Deep Learning Architectures: Enhancing Interpretability and Consistency","abstract":"Ensuring the trustworthiness and interpretability of machine learning models is critical to their deployment in real-world applications. Feature attribution methods have gained significant attention, which provide local explanations of model predictions by attributing importance to individual input features. This study examines the generalization of feature attributions across various deep learning architectures, such as convolutional neural networks (CNNs) and vision transformers. We aim to assess the feasibility of utilizing a feature attribution method as a future detector and examine how these features can be harmonized across multiple models employing distinct architectures but trained on the same data distribution. By exploring this harmonization, we aim to develop a more coherent and optimistic understanding of feature attributions, enhancing the consistency of local explanations across diverse deep-learning models. Our findings highlight the potential for harmonized feature attribution methods to improve interpretability and foster trust in machine learning applications, regardless of the underlying architecture.","sentences":["Ensuring the trustworthiness and interpretability of machine learning models is critical to their deployment in real-world applications.","Feature attribution methods have gained significant attention, which provide local explanations of model predictions by attributing importance to individual input features.","This study examines the generalization of feature attributions across various deep learning architectures, such as convolutional neural networks (CNNs) and vision transformers.","We aim to assess the feasibility of utilizing a feature attribution method as a future detector and examine how these features can be harmonized across multiple models employing distinct architectures but trained on the same data distribution.","By exploring this harmonization, we aim to develop a more coherent and optimistic understanding of feature attributions, enhancing the consistency of local explanations across diverse deep-learning models.","Our findings highlight the potential for harmonized feature attribution methods to improve interpretability and foster trust in machine learning applications, regardless of the underlying architecture."],"url":"http://arxiv.org/abs/2307.02150v1"}
{"created":"2023-07-05 09:42:51","title":"Recommendation Unlearning via Influence Function","abstract":"Recommendation unlearning is an emerging task to serve users for erasing unusable data (e.g., some historical behaviors) from a well-trained recommender model. Existing methods process unlearning requests by fully or partially retraining the model after removing the unusable data. However, these methods are impractical due to the high computation cost of full retraining and the highly possible performance damage of partial training. In this light, a desired recommendation unlearning method should obtain a similar model as full retraining in a more efficient manner, i.e., achieving complete, efficient and innocuous unlearning. In this work, we propose an Influence Function-based Recommendation Unlearning (IFRU) framework, which efficiently updates the model without retraining by estimating the influence of the unusable data on the model via the influence function. In the light that recent recommender models use historical data for both the constructions of the optimization loss and the computational graph (e.g., neighborhood aggregation), IFRU jointly estimates the direct influence of unusable data on optimization loss and the spillover influence on the computational graph to pursue complete unlearning. Furthermore, we propose an importance-based pruning algorithm to reduce the cost of the influence function. IFRU is innocuous and applicable to mainstream differentiable models. Extensive experiments demonstrate that IFRU achieves more than250times acceleration compared to retraining-based methods with recommendation performance comparable to full retraining.","sentences":["Recommendation unlearning is an emerging task to serve users for erasing unusable data (e.g., some historical behaviors) from a well-trained recommender model.","Existing methods process unlearning requests by fully or partially retraining the model after removing the unusable data.","However, these methods are impractical due to the high computation cost of full retraining and the highly possible performance damage of partial training.","In this light, a desired recommendation unlearning method should obtain a similar model as full retraining in a more efficient manner, i.e., achieving complete, efficient and innocuous unlearning.","In this work, we propose an Influence Function-based Recommendation Unlearning (IFRU) framework, which efficiently updates the model without retraining by estimating the influence of the unusable data on the model via the influence function.","In the light that recent recommender models use historical data for both the constructions of the optimization loss and the computational graph (e.g., neighborhood aggregation), IFRU jointly estimates the direct influence of unusable data on optimization loss and the spillover influence on the computational graph to pursue complete unlearning.","Furthermore, we propose an importance-based pruning algorithm to reduce the cost of the influence function.","IFRU is innocuous and applicable to mainstream differentiable models.","Extensive experiments demonstrate that IFRU achieves more than250times acceleration compared to retraining-based methods with recommendation performance comparable to full retraining."],"url":"http://arxiv.org/abs/2307.02147v1"}
{"created":"2023-07-05 09:42:47","title":"LOAF-M2L: Joint Learning of Wording and Formatting for Singable Melody-to-Lyric Generation","abstract":"Despite previous efforts in melody-to-lyric generation research, there is still a significant compatibility gap between generated lyrics and melodies, negatively impacting the singability of the outputs. This paper bridges the singability gap with a novel approach to generating singable lyrics by jointly Learning wOrding And Formatting during Melody-to-Lyric training (LOAF-M2L). After general-domain pretraining, our proposed model acquires length awareness first from a large text-only lyric corpus. Then, we introduce a new objective informed by musicological research on the relationship between melody and lyrics during melody-to-lyric training, which enables the model to learn the fine-grained format requirements of the melody. Our model achieves 3.75% and 21.44% absolute accuracy gains in the outputs' number-of-line and syllable-per-line requirements compared to naive fine-tuning, without sacrificing text fluency. Furthermore, our model demonstrates a 63.92% and 74.18% relative improvement of music-lyric compatibility and overall quality in the subjective evaluation, compared to the state-of-the-art melody-to-lyric generation model, highlighting the significance of formatting learning.","sentences":["Despite previous efforts in melody-to-lyric generation research, there is still a significant compatibility gap between generated lyrics and melodies, negatively impacting the singability of the outputs.","This paper bridges the singability gap with a novel approach to generating singable lyrics by jointly Learning wOrding And Formatting during Melody-to-Lyric training (LOAF-M2L).","After general-domain pretraining, our proposed model acquires length awareness first from a large text-only lyric corpus.","Then, we introduce a new objective informed by musicological research on the relationship between melody and lyrics during melody-to-lyric training, which enables the model to learn the fine-grained format requirements of the melody.","Our model achieves 3.75% and 21.44% absolute accuracy gains in the outputs' number-of-line and syllable-per-line requirements compared to naive fine-tuning, without sacrificing text fluency.","Furthermore, our model demonstrates a 63.92% and 74.18% relative improvement of music-lyric compatibility and overall quality in the subjective evaluation, compared to the state-of-the-art melody-to-lyric generation model, highlighting the significance of formatting learning."],"url":"http://arxiv.org/abs/2307.02146v1"}
{"created":"2023-07-05 09:40:36","title":"Kolam Simulation using Angles at Lattice Points","abstract":"Kolam is a ritual art form practised by people in South India and consists of rule-bound geometric patterns of dots and lines. Single loop Kolams are mathematical closed loop patterns drawn over a grid of dots and conforming to certain heuristics. In this work, we propose a novel encoding scheme where we map the angular movements of Kolam at lattice points into sequences containing $4$ distinct symbols. This is then used to simulate single loop Kolam procedure via turtle moves in accordance with the desired angular direction at specific points. We thus obtain sequential codes for Kolams, unique up to cyclic permutations. We specify the requirements for the algorithm and indicate the general methodology. We demonstrate a sample of Kolams using our algorithm with a software implementation in Python.","sentences":["Kolam is a ritual art form practised by people in South India and consists of rule-bound geometric patterns of dots and lines.","Single loop Kolams are mathematical closed loop patterns drawn over a grid of dots and conforming to certain heuristics.","In this work, we propose a novel encoding scheme where we map the angular movements of Kolam at lattice points into sequences containing $4$ distinct symbols.","This is then used to simulate single loop Kolam procedure via turtle moves in accordance with the desired angular direction at specific points.","We thus obtain sequential codes for Kolams, unique up to cyclic permutations.","We specify the requirements for the algorithm and indicate the general methodology.","We demonstrate a sample of Kolams using our algorithm with a software implementation in Python."],"url":"http://arxiv.org/abs/2307.02144v1"}
{"created":"2023-07-05 09:30:14","title":"Towards Open Federated Learning Platforms: Survey and Vision from Technical and Legal Perspectives","abstract":"Traditional Federated Learning (FL) follows a server-domincated cooperation paradigm which narrows the application scenarios of FL and decreases the enthusiasm of data holders to participate. To fully unleash the potential of FL, we advocate rethinking the design of current FL frameworks and extending it to a more generalized concept: Open Federated Learning Platforms. We propose two reciprocal cooperation frameworks for FL to achieve this: query-based FL and contract-based FL. In this survey, we conduct a comprehensive review of the feasibility of constructing an open FL platform from both technical and legal perspectives. We begin by reviewing the definition of FL and summarizing its inherent limitations, including server-client coupling, low model reusability, and non-public. In the query-based FL platform, which is an open model sharing and reusing platform empowered by the community for model mining, we explore a wide range of valuable topics, including the availability of up-to-date model repositories for model querying, legal compliance analysis between different model licenses, and copyright issues and intellectual property protection in model reusing. In particular, we introduce a novel taxonomy to streamline the analysis of model license compatibility in FL studies that involve batch model reusing methods, including combination, amalgamation, distillation, and generation. This taxonomy provides a systematic framework for identifying the corresponding clauses of licenses and facilitates the identification of potential legal implications and restrictions when reusing models. Through this survey, we uncover the the current dilemmas faced by FL and advocate for the development of sustainable open FL platforms. We aim to provide guidance for establishing such platforms in the future, while identifying potential problems and challenges that need to be addressed.","sentences":["Traditional Federated Learning (FL) follows a server-domincated cooperation paradigm which narrows the application scenarios of FL and decreases the enthusiasm of data holders to participate.","To fully unleash the potential of FL, we advocate rethinking the design of current FL frameworks and extending it to a more generalized concept: Open Federated Learning Platforms.","We propose two reciprocal cooperation frameworks for FL to achieve this: query-based FL and contract-based FL.","In this survey, we conduct a comprehensive review of the feasibility of constructing an open FL platform from both technical and legal perspectives.","We begin by reviewing the definition of FL and summarizing its inherent limitations, including server-client coupling, low model reusability, and non-public.","In the query-based FL platform, which is an open model sharing and reusing platform empowered by the community for model mining, we explore a wide range of valuable topics, including the availability of up-to-date model repositories for model querying, legal compliance analysis between different model licenses, and copyright issues and intellectual property protection in model reusing.","In particular, we introduce a novel taxonomy to streamline the analysis of model license compatibility in FL studies that involve batch model reusing methods, including combination, amalgamation, distillation, and generation.","This taxonomy provides a systematic framework for identifying the corresponding clauses of licenses and facilitates the identification of potential legal implications and restrictions when reusing models.","Through this survey, we uncover the the current dilemmas faced by FL and advocate for the development of sustainable open FL platforms.","We aim to provide guidance for establishing such platforms in the future, while identifying potential problems and challenges that need to be addressed."],"url":"http://arxiv.org/abs/2307.02140v1"}
{"created":"2023-07-05 09:28:25","title":"Prompting Diffusion Representations for Cross-Domain Semantic Segmentation","abstract":"While originally designed for image generation, diffusion models have recently shown to provide excellent pretrained feature representations for semantic segmentation. Intrigued by this result, we set out to explore how well diffusion-pretrained representations generalize to new domains, a crucial ability for any representation. We find that diffusion-pretraining achieves extraordinary domain generalization results for semantic segmentation, outperforming both supervised and self-supervised backbone networks. Motivated by this, we investigate how to utilize the model's unique ability of taking an input prompt, in order to further enhance its cross-domain performance. We introduce a scene prompt and a prompt randomization strategy to help further disentangle the domain-invariant information when training the segmentation head. Moreover, we propose a simple but highly effective approach for test-time domain adaptation, based on learning a scene prompt on the target domain in an unsupervised manner. Extensive experiments conducted on four synthetic-to-real and clear-to-adverse weather benchmarks demonstrate the effectiveness of our approaches. Without resorting to any complex techniques, such as image translation, augmentation, or rare-class sampling, we set a new state-of-the-art on all benchmarks. Our implementation will be publicly available at \\url{https://github.com/ETHRuiGong/PTDiffSeg}.","sentences":["While originally designed for image generation, diffusion models have recently shown to provide excellent pretrained feature representations for semantic segmentation.","Intrigued by this result, we set out to explore how well diffusion-pretrained representations generalize to new domains, a crucial ability for any representation.","We find that diffusion-pretraining achieves extraordinary domain generalization results for semantic segmentation, outperforming both supervised and self-supervised backbone networks.","Motivated by this, we investigate how to utilize the model's unique ability of taking an input prompt, in order to further enhance its cross-domain performance.","We introduce a scene prompt and a prompt randomization strategy to help further disentangle the domain-invariant information when training the segmentation head.","Moreover, we propose a simple but highly effective approach for test-time domain adaptation, based on learning a scene prompt on the target domain in an unsupervised manner.","Extensive experiments conducted on four synthetic-to-real and clear-to-adverse weather benchmarks demonstrate the effectiveness of our approaches.","Without resorting to any complex techniques, such as image translation, augmentation, or rare-class sampling, we set a new state-of-the-art on all benchmarks.","Our implementation will be publicly available at \\url{https://github.com/ETHRuiGong/PTDiffSeg}."],"url":"http://arxiv.org/abs/2307.02138v1"}
{"created":"2023-07-05 09:26:15","title":"Improved Approximation for Two-dimensional Vector Multiple Knapsack","abstract":"We study the uniform $2$-dimensional vector multiple knapsack (2VMK) problem, a natural variant of multiple knapsack arising in real-world applications such as virtual machine placement. The input for 2VMK is a set of items, each associated with a $2$-dimensional weight vector and a positive profit, along with $m$ $2$-dimensional bins of uniform (unit) capacity in each dimension. The goal is to find an assignment of a subset of the items to the bins, such that the total weight of items assigned to a single bin is at most one in each dimension, and the total profit is maximized.   Our main result is a $(1- \\frac{\\ln 2}{2} - \\varepsilon)$-approximation algorithm for 2VMK, for every fixed $\\varepsilon > 0$, thus improving the best known ratio of $(1 - \\frac{1}{e}-\\varepsilon)$ which follows as a special case from a result of [Fleischer at al., MOR 2011]. Our algorithm relies on an adaptation of the Round$\\&$Approx framework of [Bansal et al., SICOMP 2010], originally designed for set covering problems, to maximization problems. The algorithm uses randomized rounding of a configuration-LP solution to assign items to $\\approx m\\cdot \\ln 2 \\approx 0.693\\cdot m$ of the bins, followed by a reduction to the ($1$-dimensional) Multiple Knapsack problem for assigning items to the remaining bins.","sentences":["We study the uniform $2$-dimensional vector multiple knapsack (2VMK) problem, a natural variant of multiple knapsack arising in real-world applications such as virtual machine placement.","The input for 2VMK is a set of items, each associated with a $2$-dimensional weight vector and a positive profit, along with $m$ $2$-dimensional bins of uniform (unit) capacity in each dimension.","The goal is to find an assignment of a subset of the items to the bins, such that the total weight of items assigned to a single bin is at most one in each dimension, and the total profit is maximized.   ","Our main result is a $(1- \\frac{\\ln 2}{2} - \\varepsilon)$-approximation algorithm for 2VMK, for every fixed $\\varepsilon > 0$, thus improving the best known ratio of $(1 - \\frac{1}{e}-\\varepsilon)$ which follows as a special case from a result of [Fleischer at al., MOR 2011].","Our algorithm relies on an adaptation of the Round$\\&$Approx framework of [Bansal et al., SICOMP 2010], originally designed for set covering problems, to maximization problems.","The algorithm uses randomized rounding of a configuration-LP solution to assign items to $\\approx m\\cdot \\ln 2 \\approx 0.693\\cdot m$ of the bins, followed by a reduction to the ($1$-dimensional) Multiple Knapsack problem for assigning items to the remaining bins."],"url":"http://arxiv.org/abs/2307.02137v1"}
{"created":"2023-07-05 09:20:46","title":"Going Retro: Astonishingly Simple Yet Effective Rule-based Prosody Modelling for Speech Synthesis Simulating Emotion Dimensions","abstract":"We introduce two rule-based models to modify the prosody of speech synthesis in order to modulate the emotion to be expressed. The prosody modulation is based on speech synthesis markup language (SSML) and can be used with any commercial speech synthesizer. The models as well as the optimization result are evaluated against human emotion annotations. Results indicate that with a very simple method both dimensions arousal (.76 UAR) and valence (.43 UAR) can be simulated.","sentences":["We introduce two rule-based models to modify the prosody of speech synthesis in order to modulate the emotion to be expressed.","The prosody modulation is based on speech synthesis markup language (SSML) and can be used with any commercial speech synthesizer.","The models as well as the optimization result are evaluated against human emotion annotations.","Results indicate that with a very simple method both dimensions arousal (.76 UAR) and valence (.43 UAR) can be simulated."],"url":"http://arxiv.org/abs/2307.02132v1"}
{"created":"2023-07-05 09:14:09","title":"Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research","abstract":"This study employs counterfactual explanations to explore \"what if?\" scenarios in medical research, with the aim of expanding our understanding beyond existing boundaries. Specifically, we focus on utilizing MRI features for diagnosing pediatric posterior fossa brain tumors as a case study. The field of artificial intelligence and explainability has witnessed a growing number of studies and increasing scholarly interest. However, the lack of human-friendly interpretations in explaining the outcomes of machine learning algorithms has significantly hindered the acceptance of these methods by clinicians in their clinical practice. To address this, our approach incorporates counterfactual explanations, providing a novel way to examine alternative decision-making scenarios. These explanations offer personalized and context-specific insights, enabling the validation of predictions and clarification of variations under diverse circumstances. Importantly, our approach maintains both statistical and clinical fidelity, allowing for the examination of distinct tumor features through alternative realities. Additionally, we explore the potential use of counterfactuals for data augmentation and evaluate their feasibility as an alternative approach in medical research. The results demonstrate the promising potential of counterfactual explanations to enhance trust and acceptance of AI-driven methods in clinical settings.","sentences":["This study employs counterfactual explanations to explore \"what if?\" scenarios in medical research, with the aim of expanding our understanding beyond existing boundaries.","Specifically, we focus on utilizing MRI features for diagnosing pediatric posterior fossa brain tumors as a case study.","The field of artificial intelligence and explainability has witnessed a growing number of studies and increasing scholarly interest.","However, the lack of human-friendly interpretations in explaining the outcomes of machine learning algorithms has significantly hindered the acceptance of these methods by clinicians in their clinical practice.","To address this, our approach incorporates counterfactual explanations, providing a novel way to examine alternative decision-making scenarios.","These explanations offer personalized and context-specific insights, enabling the validation of predictions and clarification of variations under diverse circumstances.","Importantly, our approach maintains both statistical and clinical fidelity, allowing for the examination of distinct tumor features through alternative realities.","Additionally, we explore the potential use of counterfactuals for data augmentation and evaluate their feasibility as an alternative approach in medical research.","The results demonstrate the promising potential of counterfactual explanations to enhance trust and acceptance of AI-driven methods in clinical settings."],"url":"http://arxiv.org/abs/2307.02131v1"}
{"created":"2023-07-05 09:11:23","title":"Implicit Differentiation for Hyperparameter Tuning the Weighted Graphical Lasso","abstract":"We provide a framework and algorithm for tuning the hyperparameters of the Graphical Lasso via a bilevel optimization problem solved with a first-order method. In particular, we derive the Jacobian of the Graphical Lasso solution with respect to its regularization hyperparameters.","sentences":["We provide a framework and algorithm for tuning the hyperparameters of the Graphical Lasso via a bilevel optimization problem solved with a first-order method.","In particular, we derive the Jacobian of the Graphical Lasso solution with respect to its regularization hyperparameters."],"url":"http://arxiv.org/abs/2307.02130v1"}
{"created":"2023-07-05 09:11:09","title":"How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model","abstract":"Learning generic high-dimensional tasks is notably hard, as it requires a number of training data exponential in the dimension. Yet, deep convolutional neural networks (CNNs) have shown remarkable success in overcoming this challenge. A popular hypothesis is that learnable tasks are highly structured and that CNNs leverage this structure to build a low-dimensional representation of the data. However, little is known about how much training data they require, and how this number depends on the data structure. This paper answers this question for a simple classification task that seeks to capture relevant aspects of real data: the Random Hierarchy Model. In this model, each of the $n_c$ classes corresponds to $m$ synonymic compositions of high-level features, which are in turn composed of sub-features through an iterative process repeated $L$ times. We find that the number of training data $P^*$ required by deep CNNs to learn this task (i) grows asymptotically as $n_c m^L$, which is only polynomial in the input dimensionality; (ii) coincides with the training set size such that the representation of a trained network becomes invariant to exchanges of synonyms; (iii) corresponds to the number of data at which the correlations between low-level features and classes become detectable. Overall, our results indicate how deep CNNs can overcome the curse of dimensionality by building invariant representations, and provide an estimate of the number of data required to learn a task based on its hierarchically compositional structure.","sentences":["Learning generic high-dimensional tasks is notably hard, as it requires a number of training data exponential in the dimension.","Yet, deep convolutional neural networks (CNNs) have shown remarkable success in overcoming this challenge.","A popular hypothesis is that learnable tasks are highly structured and that CNNs leverage this structure to build a low-dimensional representation of the data.","However, little is known about how much training data they require, and how this number depends on the data structure.","This paper answers this question for a simple classification task that seeks to capture relevant aspects of real data: the Random Hierarchy Model.","In this model, each of the $n_c$ classes corresponds to $m$ synonymic compositions of high-level features, which are in turn composed of sub-features through an iterative process repeated $L$ times.","We find that the number of training data $P^*$ required by deep CNNs to learn this task (i) grows asymptotically as $n_c m^L$, which is only polynomial in the input dimensionality; (ii) coincides with the training set size such that the representation of a trained network becomes invariant to exchanges of synonyms; (iii) corresponds to the number of data at which the correlations between low-level features and classes become detectable.","Overall, our results indicate how deep CNNs can overcome the curse of dimensionality by building invariant representations, and provide an estimate of the number of data required to learn a task based on its hierarchically compositional structure."],"url":"http://arxiv.org/abs/2307.02129v1"}
{"created":"2023-07-05 09:06:56","title":"Leveraging Denoised Abstract Meaning Representation for Grammatical Error Correction","abstract":"Grammatical Error Correction (GEC) is the task of correcting errorful sentences into grammatically correct, semantically consistent, and coherent sentences. Popular GEC models either use large-scale synthetic corpora or use a large number of human-designed rules. The former is costly to train, while the latter requires quite a lot of human expertise. In recent years, AMR, a semantic representation framework, has been widely used by many natural language tasks due to its completeness and flexibility. A non-negligible concern is that AMRs of grammatically incorrect sentences may not be exactly reliable. In this paper, we propose the AMR-GEC, a seq-to-seq model that incorporates denoised AMR as additional knowledge. Specifically, We design a semantic aggregated GEC model and explore denoising methods to get AMRs more reliable. Experiments on the BEA-2019 shared task and the CoNLL-2014 shared task have shown that AMR-GEC performs comparably to a set of strong baselines with a large number of synthetic data. Compared with the T5 model with synthetic data, AMR-GEC can reduce the training time by 32\\% while inference time is comparable. To the best of our knowledge, we are the first to incorporate AMR for grammatical error correction.","sentences":["Grammatical Error Correction (GEC) is the task of correcting errorful sentences into grammatically correct, semantically consistent, and coherent sentences.","Popular GEC models either use large-scale synthetic corpora or use a large number of human-designed rules.","The former is costly to train, while the latter requires quite a lot of human expertise.","In recent years, AMR, a semantic representation framework, has been widely used by many natural language tasks due to its completeness and flexibility.","A non-negligible concern is that AMRs of grammatically incorrect sentences may not be exactly reliable.","In this paper, we propose the AMR-GEC, a seq-to-seq model that incorporates denoised AMR as additional knowledge.","Specifically, We design a semantic aggregated GEC model and explore denoising methods to get AMRs more reliable.","Experiments on the BEA-2019 shared task and the CoNLL-2014 shared task have shown that AMR-GEC performs comparably to a set of strong baselines with a large number of synthetic data.","Compared with the T5 model with synthetic data, AMR-GEC can reduce the training time by 32\\% while inference time is comparable.","To the best of our knowledge, we are the first to incorporate AMR for grammatical error correction."],"url":"http://arxiv.org/abs/2307.02127v1"}
{"created":"2023-07-05 09:05:14","title":"Robust Graph Structure Learning with the Alignment of Features and Adjacency Matrix","abstract":"To improve the robustness of graph neural networks (GNN), graph structure learning (GSL) has attracted great interest due to the pervasiveness of noise in graph data. Many approaches have been proposed for GSL to jointly learn a clean graph structure and corresponding representations. To extend the previous work, this paper proposes a novel regularized GSL approach, particularly with an alignment of feature information and graph information, which is motivated mainly by our derived lower bound of node-level Rademacher complexity for GNNs. Additionally, our proposed approach incorporates sparse dimensional reduction to leverage low-dimensional node features that are relevant to the graph structure. To evaluate the effectiveness of our approach, we conduct experiments on real-world graphs. The results demonstrate that our proposed GSL method outperforms several competitive baselines, especially in scenarios where the graph structures are heavily affected by noise. Overall, our research highlights the importance of integrating feature and graph information alignment in GSL, as inspired by our derived theoretical result, and showcases the superiority of our approach in handling noisy graph structures through comprehensive experiments on real-world datasets.","sentences":["To improve the robustness of graph neural networks (GNN), graph structure learning (GSL) has attracted great interest due to the pervasiveness of noise in graph data.","Many approaches have been proposed for GSL to jointly learn a clean graph structure and corresponding representations.","To extend the previous work, this paper proposes a novel regularized GSL approach, particularly with an alignment of feature information and graph information, which is motivated mainly by our derived lower bound of node-level Rademacher complexity for GNNs.","Additionally, our proposed approach incorporates sparse dimensional reduction to leverage low-dimensional node features that are relevant to the graph structure.","To evaluate the effectiveness of our approach, we conduct experiments on real-world graphs.","The results demonstrate that our proposed GSL method outperforms several competitive baselines, especially in scenarios where the graph structures are heavily affected by noise.","Overall, our research highlights the importance of integrating feature and graph information alignment in GSL, as inspired by our derived theoretical result, and showcases the superiority of our approach in handling noisy graph structures through comprehensive experiments on real-world datasets."],"url":"http://arxiv.org/abs/2307.02126v1"}
{"created":"2023-07-05 08:48:19","title":"Multilingual Controllable Transformer-Based Lexical Simplification","abstract":"Text is by far the most ubiquitous source of knowledge and information and should be made easily accessible to as many people as possible; however, texts often contain complex words that hinder reading comprehension and accessibility. Therefore, suggesting simpler alternatives for complex words without compromising meaning would help convey the information to a broader audience. This paper proposes mTLS, a multilingual controllable Transformer-based Lexical Simplification (LS) system fined-tuned with the T5 model. The novelty of this work lies in the use of language-specific prefixes, control tokens, and candidates extracted from pre-trained masked language models to learn simpler alternatives for complex words. The evaluation results on three well-known LS datasets -- LexMTurk, BenchLS, and NNSEval -- show that our model outperforms the previous state-of-the-art models like LSBert and ConLS. Moreover, further evaluation of our approach on the part of the recent TSAR-2022 multilingual LS shared-task dataset shows that our model performs competitively when compared with the participating systems for English LS and even outperforms the GPT-3 model on several metrics. Moreover, our model obtains performance gains also for Spanish and Portuguese.","sentences":["Text is by far the most ubiquitous source of knowledge and information and should be made easily accessible to as many people as possible; however, texts often contain complex words that hinder reading comprehension and accessibility.","Therefore, suggesting simpler alternatives for complex words without compromising meaning would help convey the information to a broader audience.","This paper proposes mTLS, a multilingual controllable Transformer-based Lexical Simplification (LS) system fined-tuned with the T5 model.","The novelty of this work lies in the use of language-specific prefixes, control tokens, and candidates extracted from pre-trained masked language models to learn simpler alternatives for complex words.","The evaluation results on three well-known LS datasets -- LexMTurk, BenchLS, and NNSEval -- show that our model outperforms the previous state-of-the-art models like LSBert and ConLS.","Moreover, further evaluation of our approach on the part of the recent TSAR-2022 multilingual LS shared-task dataset shows that our model performs competitively when compared with the participating systems for English LS and even outperforms the GPT-3 model on several metrics.","Moreover, our model obtains performance gains also for Spanish and Portuguese."],"url":"http://arxiv.org/abs/2307.02120v1"}
{"created":"2023-07-05 08:34:54","title":"Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization","abstract":"Simple regret minimization is a critical problem in learning optimal treatment assignment policies across various domains, including healthcare and e-commerce. However, it remains understudied in the contextual bandit setting. We propose a new family of computationally efficient bandit algorithms for the stochastic contextual bandit settings, with the flexibility to be adapted for cumulative regret minimization (with near-optimal minimax guarantees) and simple regret minimization (with SOTA guarantees). Furthermore, our algorithms adapt to model misspecification and extend to the continuous arm settings. These advantages come from constructing and relying on \"conformal arm sets\" (CASs), which provide a set of arms at every context that encompass the context-specific optimal arm with some probability across the context distribution. Our positive results on simple and cumulative regret guarantees are contrasted by a negative result, which shows that an algorithm can't achieve instance-dependent simple regret guarantees while simultaneously achieving minimax optimal cumulative regret guarantees.","sentences":["Simple regret minimization is a critical problem in learning optimal treatment assignment policies across various domains, including healthcare and e-commerce.","However, it remains understudied in the contextual bandit setting.","We propose a new family of computationally efficient bandit algorithms for the stochastic contextual bandit settings, with the flexibility to be adapted for cumulative regret minimization (with near-optimal minimax guarantees) and simple regret minimization (with SOTA guarantees).","Furthermore, our algorithms adapt to model misspecification and extend to the continuous arm settings.","These advantages come from constructing and relying on \"conformal arm sets\" (CASs), which provide a set of arms at every context that encompass the context-specific optimal arm with some probability across the context distribution.","Our positive results on simple and cumulative regret guarantees are contrasted by a negative result, which shows that an algorithm can't achieve instance-dependent simple regret guarantees while simultaneously achieving minimax optimal cumulative regret guarantees."],"url":"http://arxiv.org/abs/2307.02108v1"}
{"created":"2023-07-05 08:31:55","title":"Exact and Parameterized Algorithms for the Independent Cutset Problem","abstract":"The Independent Cutset problem asks whether there is a set of vertices in a given graph that is both independent and a cutset. Such a problem is $\\textsf{NP}$-complete even when the input graph is planar and has maximum degree five. In this paper, we first present a $\\mathcal{O}^*(1.4423^{n})$-time algorithm for the problem. We also show how to compute a minimum independent cutset (if any) in the same running time. Since the property of having an independent cutset is MSO$_1$-expressible, our main results are concerned with structural parameterizations for the problem considering parameters that are not bounded by a function of the clique-width of the input. We present $\\textsf{FPT}$-time algorithms for the problem considering the following parameters: the dual of the maximum degree, the dual of the solution size, the size of a dominating set (where a dominating set is given as an additional input), the size of an odd cycle transversal, the distance to chordal graphs, and the distance to $P_5$-free graphs. We close by introducing the notion of $\\alpha$-domination, which allows us to identify more fixed-parameter tractable and polynomial-time solvable cases.","sentences":["The Independent Cutset problem asks whether there is a set of vertices in a given graph that is both independent and a cutset.","Such a problem is $\\textsf{NP}$-complete even when the input graph is planar and has maximum degree five.","In this paper, we first present a $\\mathcal{O}^*(1.4423^{n})$-time algorithm for the problem.","We also show how to compute a minimum independent cutset (if any) in the same running time.","Since the property of having an independent cutset is MSO$_1$-expressible, our main results are concerned with structural parameterizations for the problem considering parameters that are not bounded by a function of the clique-width of the input.","We present $\\textsf{FPT}$-time algorithms for the problem considering the following parameters: the dual of the maximum degree, the dual of the solution size, the size of a dominating set (where a dominating set is given as an additional input), the size of an odd cycle transversal, the distance to chordal graphs, and the distance to $P_5$-free graphs.","We close by introducing the notion of $\\alpha$-domination, which allows us to identify more fixed-parameter tractable and polynomial-time solvable cases."],"url":"http://arxiv.org/abs/2307.02107v1"}
{"created":"2023-07-05 08:29:31","title":"SoK: Privacy-Preserving Data Synthesis","abstract":"As the prevalence of data analysis grows, safeguarding data privacy has become a paramount concern. Consequently, there has been an upsurge in the development of mechanisms aimed at privacy-preserving data analyses. However, these approaches are task-specific; designing algorithms for new tasks is a cumbersome process. As an alternative, one can create synthetic data that is (ideally) devoid of private information. This paper focuses on privacy-preserving data synthesis (PPDS) by providing a comprehensive overview, analysis, and discussion of the field. Specifically, we put forth a master recipe that unifies two prominent strands of research in PPDS: statistical methods and deep learning (DL)-based methods. Under the master recipe, we further dissect the statistical methods into choices of modeling and representation, and investigate the DL-based methods by different generative modeling principles. To consolidate our findings, we provide comprehensive reference tables, distill key takeaways, and identify open problems in the existing literature. In doing so, we aim to answer the following questions: What are the design principles behind different PPDS methods? How can we categorize these methods, and what are the advantages and disadvantages associated with each category? Can we provide guidelines for method selection in different real-world scenarios? We proceed to benchmark several prominent DL-based methods on the task of private image synthesis and conclude that DP-MERF is an all-purpose approach. Finally, upon systematizing the work over the past decade, we identify future directions and call for actions from researchers.","sentences":["As the prevalence of data analysis grows, safeguarding data privacy has become a paramount concern.","Consequently, there has been an upsurge in the development of mechanisms aimed at privacy-preserving data analyses.","However, these approaches are task-specific; designing algorithms for new tasks is a cumbersome process.","As an alternative, one can create synthetic data that is (ideally) devoid of private information.","This paper focuses on privacy-preserving data synthesis (PPDS) by providing a comprehensive overview, analysis, and discussion of the field.","Specifically, we put forth a master recipe that unifies two prominent strands of research in PPDS: statistical methods and deep learning (DL)-based methods.","Under the master recipe, we further dissect the statistical methods into choices of modeling and representation, and investigate the DL-based methods by different generative modeling principles.","To consolidate our findings, we provide comprehensive reference tables, distill key takeaways, and identify open problems in the existing literature.","In doing so, we aim to answer the following questions: What are the design principles behind different PPDS methods?","How can we categorize these methods, and what are the advantages and disadvantages associated with each category?","Can we provide guidelines for method selection in different real-world scenarios?","We proceed to benchmark several prominent DL-based methods on the task of private image synthesis and conclude that DP-MERF is an all-purpose approach.","Finally, upon systematizing the work over the past decade, we identify future directions and call for actions from researchers."],"url":"http://arxiv.org/abs/2307.02106v1"}
{"created":"2023-07-05 08:26:18","title":"Incremental Model Transformations with Triple Graph Grammars for Multi-version Models","abstract":"Like conventional software projects, projects in model-driven software engineering require adequate management of multiple versions of development artifacts, importantly allowing living with temporary inconsistencies. In previous work, multi-version models for model-driven software engineering have been introduced, which allow checking well-formedness and finding merge conflicts for multiple versions of a model at once. However, also for multi-version models, situations where different artifacts, that is, different models, are linked via automatic model transformations have to be handled.   In this paper, we propose a technique for jointly handling the transformation of multiple versions of a source model into corresponding versions of a target model, which enables the use of a more compact representation that may afford improved execution time of both the transformation and further analysis operations. Our approach is based on the well-known formalism of triple graph grammars and the aforementioned encoding of model version histories called multi-version models. In addition to batch transformation of an entire model version history, the technique also covers incremental synchronization of changes in the framework of multi-version models.   We show the correctness of our approach with respect to the standard semantics of triple graph grammars and conduct an empirical evaluation to investigate the performance of our technique regarding execution time and memory consumption. Our results indicate that the proposed technique affords lower memory consumption and may improve execution time for batch transformation of large version histories, but can also come with computational overhead in unfavorable cases.","sentences":["Like conventional software projects, projects in model-driven software engineering require adequate management of multiple versions of development artifacts, importantly allowing living with temporary inconsistencies.","In previous work, multi-version models for model-driven software engineering have been introduced, which allow checking well-formedness and finding merge conflicts for multiple versions of a model at once.","However, also for multi-version models, situations where different artifacts, that is, different models, are linked via automatic model transformations have to be handled.   ","In this paper, we propose a technique for jointly handling the transformation of multiple versions of a source model into corresponding versions of a target model, which enables the use of a more compact representation that may afford improved execution time of both the transformation and further analysis operations.","Our approach is based on the well-known formalism of triple graph grammars and the aforementioned encoding of model version histories called multi-version models.","In addition to batch transformation of an entire model version history, the technique also covers incremental synchronization of changes in the framework of multi-version models.   ","We show the correctness of our approach with respect to the standard semantics of triple graph grammars and conduct an empirical evaluation to investigate the performance of our technique regarding execution time and memory consumption.","Our results indicate that the proposed technique affords lower memory consumption and may improve execution time for batch transformation of large version histories, but can also come with computational overhead in unfavorable cases."],"url":"http://arxiv.org/abs/2307.02105v1"}
{"created":"2023-07-05 08:22:46","title":"Do predictability factors towards signing avatars hold across cultures?","abstract":"Avatar technology can offer accessibility possibilities and improve the Deaf-and-Hard of Hearing sign language users access to communication, education and services, such as the healthcare system. However, sign language users acceptance of signing avatars as well as their attitudes towards them vary and depend on many factors. Furthermore, research on avatar technology is mostly done by researchers who are not Deaf. The study examines the extent to which intrinsic or extrinsic factors contribute to predict the attitude towards avatars across cultures. Intrinsic factors include the characteristics of the avatar, such as appearance, movements and facial expressions. Extrinsic factors include users technology experience, their hearing status, age and their sign language fluency. This work attempts to answer questions such as, if lower attitude ratings are related to poor technology experience with ASL users, for example, is that also true for Moroccan Sign Language (MSL) users? For the purposes of the study, we designed a questionnaire to understand MSL users attitude towards avatars. Three groups of participants were surveyed: Deaf (57), Hearing (20) and Hard-of-Hearing (3). The results of our study were then compared with those reported in other relevant studies.","sentences":["Avatar technology can offer accessibility possibilities and improve the Deaf-and-Hard of Hearing sign language users access to communication, education and services, such as the healthcare system.","However, sign language users acceptance of signing avatars as well as their attitudes towards them vary and depend on many factors.","Furthermore, research on avatar technology is mostly done by researchers who are not Deaf.","The study examines the extent to which intrinsic or extrinsic factors contribute to predict the attitude towards avatars across cultures.","Intrinsic factors include the characteristics of the avatar, such as appearance, movements and facial expressions.","Extrinsic factors include users technology experience, their hearing status, age and their sign language fluency.","This work attempts to answer questions such as, if lower attitude ratings are related to poor technology experience with ASL users, for example, is that also true for Moroccan Sign Language (MSL) users?","For the purposes of the study, we designed a questionnaire to understand MSL users attitude towards avatars.","Three groups of participants were surveyed: Deaf (57), Hearing (20) and Hard-of-Hearing (3).","The results of our study were then compared with those reported in other relevant studies."],"url":"http://arxiv.org/abs/2307.02103v1"}
{"created":"2023-07-05 08:19:29","title":"MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets","abstract":"Despite its clinical utility, medical image segmentation (MIS) remains a daunting task due to images' inherent complexity and variability. Vision transformers (ViTs) have recently emerged as a promising solution to improve MIS; however, they require larger training datasets than convolutional neural networks. To overcome this obstacle, data-efficient ViTs were proposed, but they are typically trained using a single source of data, which overlooks the valuable knowledge that could be leveraged from other available datasets. Naivly combining datasets from different domains can result in negative knowledge transfer (NKT), i.e., a decrease in model performance on some domains with non-negligible inter-domain heterogeneity. In this paper, we propose MDViT, the first multi-domain ViT that includes domain adapters to mitigate data-hunger and combat NKT by adaptively exploiting knowledge in multiple small data resources (domains). Further, to enhance representation learning across domains, we integrate a mutual knowledge distillation paradigm that transfers knowledge between a universal network (spanning all the domains) and auxiliary domain-specific branches. Experiments on 4 skin lesion segmentation datasets show that MDViT outperforms state-of-the-art algorithms, with superior segmentation performance and a fixed model size, at inference time, even as more domains are added. Our code is available at https://github.com/siyi-wind/MDViT.","sentences":["Despite its clinical utility, medical image segmentation (MIS) remains a daunting task due to images' inherent complexity and variability.","Vision transformers (ViTs) have recently emerged as a promising solution to improve MIS; however, they require larger training datasets than convolutional neural networks.","To overcome this obstacle, data-efficient ViTs were proposed, but they are typically trained using a single source of data, which overlooks the valuable knowledge that could be leveraged from other available datasets.","Naivly combining datasets from different domains can result in negative knowledge transfer (NKT), i.e., a decrease in model performance on some domains with non-negligible inter-domain heterogeneity.","In this paper, we propose MDViT, the first multi-domain ViT that includes domain adapters to mitigate data-hunger and combat NKT by adaptively exploiting knowledge in multiple small data resources (domains).","Further, to enhance representation learning across domains, we integrate a mutual knowledge distillation paradigm that transfers knowledge between a universal network (spanning all the domains) and auxiliary domain-specific branches.","Experiments on 4 skin lesion segmentation datasets show that MDViT outperforms state-of-the-art algorithms, with superior segmentation performance and a fixed model size, at inference time, even as more domains are added.","Our code is available at https://github.com/siyi-wind/MDViT."],"url":"http://arxiv.org/abs/2307.02100v1"}
{"created":"2023-07-05 08:11:40","title":"DARE: Towards Robust Text Explanations in Biomedical and Healthcare Applications","abstract":"Along with the successful deployment of deep neural networks in several application domains, the need to unravel the black-box nature of these networks has seen a significant increase recently. Several methods have been introduced to provide insight into the inference process of deep neural networks. However, most of these explainability methods have been shown to be brittle in the face of adversarial perturbations of their inputs in the image and generic textual domain. In this work we show that this phenomenon extends to specific and important high stakes domains like biomedical datasets. In particular, we observe that the robustness of explanations should be characterized in terms of the accuracy of the explanation in linking a model's inputs and its decisions - faithfulness - and its relevance from the perspective of domain experts - plausibility. This is crucial to prevent explanations that are inaccurate but still look convincing in the context of the domain at hand. To this end, we show how to adapt current attribution robustness estimation methods to a given domain, so as to take into account domain-specific plausibility. This results in our DomainAdaptiveAREstimator (DARE) attribution robustness estimator, allowing us to properly characterize the domain-specific robustness of faithful explanations. Next, we provide two methods, adversarial training and FAR training, to mitigate the brittleness characterized by DARE, allowing us to train networks that display robust attributions. Finally, we empirically validate our methods with extensive experiments on three established biomedical benchmarks.","sentences":["Along with the successful deployment of deep neural networks in several application domains, the need to unravel the black-box nature of these networks has seen a significant increase recently.","Several methods have been introduced to provide insight into the inference process of deep neural networks.","However, most of these explainability methods have been shown to be brittle in the face of adversarial perturbations of their inputs in the image and generic textual domain.","In this work we show that this phenomenon extends to specific and important high stakes domains like biomedical datasets.","In particular, we observe that the robustness of explanations should be characterized in terms of the accuracy of the explanation in linking a model's inputs and its decisions - faithfulness - and its relevance from the perspective of domain experts - plausibility.","This is crucial to prevent explanations that are inaccurate but still look convincing in the context of the domain at hand.","To this end, we show how to adapt current attribution robustness estimation methods to a given domain, so as to take into account domain-specific plausibility.","This results in our DomainAdaptiveAREstimator (DARE) attribution robustness estimator, allowing us to properly characterize the domain-specific robustness of faithful explanations.","Next, we provide two methods, adversarial training and FAR training, to mitigate the brittleness characterized by DARE, allowing us to train networks that display robust attributions.","Finally, we empirically validate our methods with extensive experiments on three established biomedical benchmarks."],"url":"http://arxiv.org/abs/2307.02094v1"}
{"created":"2023-07-05 08:10:17","title":"Make A Long Image Short: Adaptive Token Length for Vision Transformers","abstract":"The vision transformer is a model that breaks down each image into a sequence of tokens with a fixed length and processes them similarly to words in natural language processing. Although increasing the number of tokens typically results in better performance, it also leads to a considerable increase in computational cost. Motivated by the saying \"A picture is worth a thousand words,\" we propose an innovative approach to accelerate the ViT model by shortening long images. Specifically, we introduce a method for adaptively assigning token length for each image at test time to accelerate inference speed. First, we train a Resizable-ViT (ReViT) model capable of processing input with diverse token lengths. Next, we extract token-length labels from ReViT that indicate the minimum number of tokens required to achieve accurate predictions. We then use these labels to train a lightweight Token-Length Assigner (TLA) that allocates the optimal token length for each image during inference. The TLA enables ReViT to process images with the minimum sufficient number of tokens, reducing token numbers in the ViT model and improving inference speed. Our approach is general and compatible with modern vision transformer architectures, significantly reducing computational costs. We verified the effectiveness of our methods on multiple representative ViT models on image classification and action recognition.","sentences":["The vision transformer is a model that breaks down each image into a sequence of tokens with a fixed length and processes them similarly to words in natural language processing.","Although increasing the number of tokens typically results in better performance, it also leads to a considerable increase in computational cost.","Motivated by the saying \"A picture is worth a thousand words,\" we propose an innovative approach to accelerate the ViT model by shortening long images.","Specifically, we introduce a method for adaptively assigning token length for each image at test time to accelerate inference speed.","First, we train a Resizable-ViT (ReViT) model capable of processing input with diverse token lengths.","Next, we extract token-length labels from ReViT that indicate the minimum number of tokens required to achieve accurate predictions.","We then use these labels to train a lightweight Token-Length Assigner (TLA) that allocates the optimal token length for each image during inference.","The TLA enables ReViT to process images with the minimum sufficient number of tokens, reducing token numbers in the ViT model and improving inference speed.","Our approach is general and compatible with modern vision transformer architectures, significantly reducing computational costs.","We verified the effectiveness of our methods on multiple representative ViT models on image classification and action recognition."],"url":"http://arxiv.org/abs/2307.02092v1"}
{"created":"2023-07-05 08:06:26","title":"Interactive Conversational Head Generation","abstract":"We introduce a new conversation head generation benchmark for synthesizing behaviors of a single interlocutor in a face-to-face conversation. The capability to automatically synthesize interlocutors which can participate in long and multi-turn conversations is vital and offer benefits for various applications, including digital humans, virtual agents, and social robots. While existing research primarily focuses on talking head generation (one-way interaction), hindering the ability to create a digital human for conversation (two-way) interaction due to the absence of listening and interaction parts. In this work, we construct two datasets to address this issue, ``ViCo'' for independent talking and listening head generation tasks at the sentence level, and ``ViCo-X'', for synthesizing interlocutors in multi-turn conversational scenarios. Based on ViCo and ViCo-X, we define three novel tasks targeting the interaction modeling during the face-to-face conversation: 1) responsive listening head generation making listeners respond actively to the speaker with non-verbal signals, 2) expressive talking head generation guiding speakers to be aware of listeners' behaviors, and 3) conversational head generation to integrate the talking/listening ability in one interlocutor. Along with the datasets, we also propose corresponding baseline solutions to the three aforementioned tasks. Experimental results show that our baseline method could generate responsive and vivid agents that can collaborate with real person to fulfil the whole conversation. Project page: https://vico.solutions/.","sentences":["We introduce a new conversation head generation benchmark for synthesizing behaviors of a single interlocutor in a face-to-face conversation.","The capability to automatically synthesize interlocutors which can participate in long and multi-turn conversations is vital and offer benefits for various applications, including digital humans, virtual agents, and social robots.","While existing research primarily focuses on talking head generation (one-way interaction), hindering the ability to create a digital human for conversation (two-way) interaction due to the absence of listening and interaction parts.","In this work, we construct two datasets to address this issue, ``ViCo'' for independent talking and listening head generation tasks at the sentence level, and ``ViCo-X'', for synthesizing interlocutors in multi-turn conversational scenarios.","Based on ViCo and ViCo-X, we define three novel tasks targeting the interaction modeling during the face-to-face conversation: 1) responsive listening head generation making listeners respond actively to the speaker with non-verbal signals, 2) expressive talking head generation guiding speakers to be aware of listeners' behaviors, and 3) conversational head generation to integrate the talking/listening ability in one interlocutor.","Along with the datasets, we also propose corresponding baseline solutions to the three aforementioned tasks.","Experimental results show that our baseline method could generate responsive and vivid agents that can collaborate with real person to fulfil the whole conversation.","Project page: https://vico.solutions/."],"url":"http://arxiv.org/abs/2307.02090v1"}
{"created":"2023-07-05 07:56:48","title":"Trust in Software Supply Chains: Blockchain-Enabled SBOM and the AIBOM Future","abstract":"Software Bill of Materials (SBOM) serves as a critical pillar in ensuring software supply chain security by providing a detailed inventory of the components and dependencies integral to software development. However, challenges abound in the sharing of SBOMs, including potential data tampering, hesitation among software vendors to disclose comprehensive information, and bespoke requirements from software procurers or users. These obstacles have stifled widespread adoption and utilization of SBOMs, underscoring the need for a more secure and flexible mechanism for SBOM sharing. This study proposes a novel solution to these challenges by introducing a blockchain-empowered approach for SBOM sharing, leveraging verifiable credentials to allow for selective disclosure. This strategy not only heightens security but also offers flexibility. Furthermore, this paper broadens the remit of SBOM to encompass AI systems, thereby coining the term AI Bill of Materials (AIBOM). This extension is motivated by the rapid progression in AI technology and the escalating necessity to track the lineage and composition of AI software and systems. Particularly in the era of foundational models like large language models (LLMs), understanding their composition and dependencies becomes crucial. These models often serve as a base for further development, creating complex dependencies and paving the way for innovative AI applications. The evaluation of our solution indicates the feasibility and flexibility of the proposed SBOM sharing mechanism, positing a new solution for securing (AI) software supply chains.","sentences":["Software Bill of Materials (SBOM) serves as a critical pillar in ensuring software supply chain security by providing a detailed inventory of the components and dependencies integral to software development.","However, challenges abound in the sharing of SBOMs, including potential data tampering, hesitation among software vendors to disclose comprehensive information, and bespoke requirements from software procurers or users.","These obstacles have stifled widespread adoption and utilization of SBOMs, underscoring the need for a more secure and flexible mechanism for SBOM sharing.","This study proposes a novel solution to these challenges by introducing a blockchain-empowered approach for SBOM sharing, leveraging verifiable credentials to allow for selective disclosure.","This strategy not only heightens security but also offers flexibility.","Furthermore, this paper broadens the remit of SBOM to encompass AI systems, thereby coining the term AI Bill of Materials (AIBOM).","This extension is motivated by the rapid progression in AI technology and the escalating necessity to track the lineage and composition of AI software and systems.","Particularly in the era of foundational models like large language models (LLMs), understanding their composition and dependencies becomes crucial.","These models often serve as a base for further development, creating complex dependencies and paving the way for innovative AI applications.","The evaluation of our solution indicates the feasibility and flexibility of the proposed SBOM sharing mechanism, positing a new solution for securing (AI) software supply chains."],"url":"http://arxiv.org/abs/2307.02088v1"}
{"created":"2023-07-05 07:51:47","title":"Different Games in Dialogue: Combining character and conversational types in strategic choice","abstract":"In this paper, we show that investigating the interaction of conversational type (often known as language game or speech genre) with the character types of the interlocutors is worthwhile. We present a method of calculating the decision making process for selecting dialogue moves that combines character type and conversational type. We also present a mathematical model that illustrate these factors' interactions in a quantitative way.","sentences":["In this paper, we show that investigating the interaction of conversational type (often known as language game or speech genre) with the character types of the interlocutors is worthwhile.","We present a method of calculating the decision making process for selecting dialogue moves that combines character type and conversational type.","We also present a mathematical model that illustrate these factors' interactions in a quantitative way."],"url":"http://arxiv.org/abs/2307.02087v1"}
{"created":"2023-07-05 07:44:36","title":"L\u00d8: An Accountable Mempool for MEV Resistance","abstract":"Possible manipulation of user transactions by miners in a permissionless blockchain systems is a growing concern. This problem is a pervasive and systemic issue, known as Miner Extractable Value (MEV), incurs highs costs on users of decentralised applications. Furthermore, transaction manipulations create other issues in blockchain systems such as congestion, higher fees, and system instability. Detecting transaction manipulations is difficult, even though it is known that they originate from the pre-consensus phase of transaction selection for a block building, at the base layer of blockchain protocols. In this paper we summarize known transaction manipulation attacks. We then present L{\\O}, an accountable base layer protocol specifically designed to detect and mitigate transaction manipulations. L{\\O} is built around accurate detection of transaction manipulations and assignment of blame at the granularity of a single mining node. L{\\O} forces miners to log all the transactions they receive into a secure mempool data structure and to process them in a verifiable manner. Overall, L{\\O} quickly and efficiently detects reordering, injection or censorship attempts. Our performance evaluation shows that L{\\O} is also practical and only introduces a marginal performance overhead.","sentences":["Possible manipulation of user transactions by miners in a permissionless blockchain systems is a growing concern.","This problem is a pervasive and systemic issue, known as Miner Extractable Value (MEV), incurs highs costs on users of decentralised applications.","Furthermore, transaction manipulations create other issues in blockchain systems such as congestion, higher fees, and system instability.","Detecting transaction manipulations is difficult, even though it is known that they originate from the pre-consensus phase of transaction selection for a block building, at the base layer of blockchain protocols.","In this paper we summarize known transaction manipulation attacks.","We then present L{\\O}, an accountable base layer protocol specifically designed to detect and mitigate transaction manipulations.","L{\\O} is built around accurate detection of transaction manipulations and assignment of blame at the granularity of a single mining node.","L{\\O} forces miners to log all the transactions they receive into a secure mempool data structure and to process them in a verifiable manner.","Overall, L{\\O} quickly and efficiently detects reordering, injection or censorship attempts.","Our performance evaluation shows that L{\\O} is also practical and only introduces a marginal performance overhead."],"url":"http://arxiv.org/abs/2307.02081v1"}
{"created":"2023-07-05 07:39:47","title":"Graph Contrastive Topic Model","abstract":"Existing NTMs with contrastive learning suffer from the sample bias problem owing to the word frequency-based sampling strategy, which may result in false negative samples with similar semantics to the prototypes. In this paper, we aim to explore the efficient sampling strategy and contrastive learning in NTMs to address the aforementioned issue. We propose a new sampling assumption that negative samples should contain words that are semantically irrelevant to the prototype. Based on it, we propose the graph contrastive topic model (GCTM), which conducts graph contrastive learning (GCL) using informative positive and negative samples that are generated by the graph-based sampling strategy leveraging in-depth correlation and irrelevance among documents and words. In GCTM, we first model the input document as the document word bipartite graph (DWBG), and construct positive and negative word co-occurrence graphs (WCGs), encoded by graph neural networks, to express in-depth semantic correlation and irrelevance among words. Based on the DWBG and WCGs, we design the document-word information propagation (DWIP) process to perform the edge perturbation of DWBG, based on multi-hop correlations/irrelevance among documents and words. This yields the desired negative and positive samples, which will be utilized for GCL together with the prototypes to improve learning document topic representations and latent topics. We further show that GCL can be interpreted as the structured variational graph auto-encoder which maximizes the mutual information of latent topic representations of different perspectives on DWBG. Experiments on several benchmark datasets demonstrate the effectiveness of our method for topic coherence and document representation learning compared with existing SOTA methods.","sentences":["Existing NTMs with contrastive learning suffer from the sample bias problem owing to the word frequency-based sampling strategy, which may result in false negative samples with similar semantics to the prototypes.","In this paper, we aim to explore the efficient sampling strategy and contrastive learning in NTMs to address the aforementioned issue.","We propose a new sampling assumption that negative samples should contain words that are semantically irrelevant to the prototype.","Based on it, we propose the graph contrastive topic model (GCTM), which conducts graph contrastive learning (GCL) using informative positive and negative samples that are generated by the graph-based sampling strategy leveraging in-depth correlation and irrelevance among documents and words.","In GCTM, we first model the input document as the document word bipartite graph (DWBG), and construct positive and negative word co-occurrence graphs (WCGs), encoded by graph neural networks, to express in-depth semantic correlation and irrelevance among words.","Based on the DWBG and WCGs, we design the document-word information propagation (DWIP) process to perform the edge perturbation of DWBG, based on multi-hop correlations/irrelevance among documents and words.","This yields the desired negative and positive samples, which will be utilized for GCL together with the prototypes to improve learning document topic representations and latent topics.","We further show that GCL can be interpreted as the structured variational graph auto-encoder which maximizes the mutual information of latent topic representations of different perspectives on DWBG.","Experiments on several benchmark datasets demonstrate the effectiveness of our method for topic coherence and document representation learning compared with existing SOTA methods."],"url":"http://arxiv.org/abs/2307.02078v1"}
{"created":"2023-07-05 07:34:54","title":"Optimal Transmit Antenna Deployment and Power Allocation for Wireless Power Supply in an Indoor Space","abstract":"As Internet of Things (IoT) devices proliferate, sustainable methods for powering them are becoming indispensable. The wireless provision of power enables battery-free operation and is crucial for complying with weight and size restrictions. For the energy harvesting components of these devices to be small, a high operating frequency is necessary. In conjunction with an electrically large antenna, the receivers may be located in the radiating near-field (Fresnel) region, e.g., in indoor scenarios. In this paper, we propose a wireless power transfer system to ensure a reliable supply of power to an arbitrary number of mobile, low-power, and single-antenna receivers, which are located in a three-dimensional cuboid room. To this end, we formulate a max-min optimisation problem to determine the optimal allocation of transmit power among an infinite number of radiating elements of the system's transmit antenna array. Thereby, the optimal deployment, i.e, the set of transmit antenna positions that are allocated non-zero transmit power according to the optimal allocation, is obtained implicitly. Generally, the set of transmit antenna positions corresponding to the optimal deployment has Lebesgue measure zero and the closure of the set has empty interior. Moreover, for a one-dimensional transmit antenna array, the set of transmit antenna positions is proven to be finite. The proposed optimal solution is validated through simulation. Simulation results indicate that the optimal deployment requires a finite number of transmit antennas and depends on the geometry of the environment and the dimensionality of the transmit antenna array. The robustness of the solution, which is obtained under a line-of-sight (LoS) assumption between the transmitter and receiver, is assessed in an isotropic scattering environment containing a strong LoS component.","sentences":["As Internet of Things (IoT) devices proliferate, sustainable methods for powering them are becoming indispensable.","The wireless provision of power enables battery-free operation and is crucial for complying with weight and size restrictions.","For the energy harvesting components of these devices to be small, a high operating frequency is necessary.","In conjunction with an electrically large antenna, the receivers may be located in the radiating near-field (Fresnel) region, e.g., in indoor scenarios.","In this paper, we propose a wireless power transfer system to ensure a reliable supply of power to an arbitrary number of mobile, low-power, and single-antenna receivers, which are located in a three-dimensional cuboid room.","To this end, we formulate a max-min optimisation problem to determine the optimal allocation of transmit power among an infinite number of radiating elements of the system's transmit antenna array.","Thereby, the optimal deployment, i.e, the set of transmit antenna positions that are allocated non-zero transmit power according to the optimal allocation, is obtained implicitly.","Generally, the set of transmit antenna positions corresponding to the optimal deployment has Lebesgue measure zero and the closure of the set has empty interior.","Moreover, for a one-dimensional transmit antenna array, the set of transmit antenna positions is proven to be finite.","The proposed optimal solution is validated through simulation.","Simulation results indicate that the optimal deployment requires a finite number of transmit antennas and depends on the geometry of the environment and the dimensionality of the transmit antenna array.","The robustness of the solution, which is obtained under a line-of-sight (LoS) assumption between the transmitter and receiver, is assessed in an isotropic scattering environment containing a strong LoS component."],"url":"http://arxiv.org/abs/2307.02076v1"}
{"created":"2023-07-05 07:32:34","title":"Combating Confirmation Bias: A Unified Pseudo-Labeling Framework for Entity Alignment","abstract":"Entity alignment (EA) aims at identifying equivalent entity pairs across different knowledge graphs (KGs) that refer to the same real-world identity. To systematically combat confirmation bias for pseudo-labeling-based entity alignment, we propose a Unified Pseudo-Labeling framework for Entity Alignment (UPL-EA) that explicitly eliminates pseudo-labeling errors to boost the accuracy of entity alignment. UPL-EA consists of two complementary components: (1) The Optimal Transport (OT)-based pseudo-labeling uses discrete OT modeling as an effective means to enable more accurate determination of entity correspondences across two KGs and to mitigate the adverse impact of erroneous matches. A simple but highly effective criterion is further devised to derive pseudo-labeled entity pairs that satisfy one-to-one correspondences at each iteration. (2) The cross-iteration pseudo-label calibration operates across multiple consecutive iterations to further improve the pseudo-labeling precision rate by reducing the local pseudo-label selection variability with a theoretical guarantee. The two components are respectively designed to eliminate Type I and Type II pseudo-labeling errors identified through our analyse. The calibrated pseudo-labels are thereafter used to augment prior alignment seeds to reinforce subsequent model training for alignment inference. The effectiveness of UPL-EA in eliminating pseudo-labeling errors is both theoretically supported and experimentally validated. The experimental results show that our approach achieves competitive performance with limited prior alignment seeds.","sentences":["Entity alignment (EA) aims at identifying equivalent entity pairs across different knowledge graphs (KGs) that refer to the same real-world identity.","To systematically combat confirmation bias for pseudo-labeling-based entity alignment, we propose a Unified Pseudo-Labeling framework for Entity Alignment (UPL-EA) that explicitly eliminates pseudo-labeling errors to boost the accuracy of entity alignment.","UPL-EA consists of two complementary components: (1) The Optimal Transport (OT)-based pseudo-labeling uses discrete OT modeling as an effective means to enable more accurate determination of entity correspondences across two KGs and to mitigate the adverse impact of erroneous matches.","A simple but highly effective criterion is further devised to derive pseudo-labeled entity pairs that satisfy one-to-one correspondences at each iteration.","(2) The cross-iteration pseudo-label calibration operates across multiple consecutive iterations to further improve the pseudo-labeling precision rate by reducing the local pseudo-label selection variability with a theoretical guarantee.","The two components are respectively designed to eliminate Type I and Type II pseudo-labeling errors identified through our analyse.","The calibrated pseudo-labels are thereafter used to augment prior alignment seeds to reinforce subsequent model training for alignment inference.","The effectiveness of UPL-EA in eliminating pseudo-labeling errors is both theoretically supported and experimentally validated.","The experimental results show that our approach achieves competitive performance with limited prior alignment seeds."],"url":"http://arxiv.org/abs/2307.02075v1"}
{"created":"2023-07-05 07:31:27","title":"Arbitrageurs' profits, LVR, and sandwich attacks: batch trading as an AMM design response","abstract":"We consider an automated market maker (AMM) in which all trades are batched and executed at a price equal to the marginal price (i.e., the price of an arbitrary small trade) after the batch trades. We show that such an AMM is a function maximizing AMM (or FM-AMM): for given prices, it trades to reach the highest possible value of a given function. Also, competition between arbitrageurs guarantees that an FM-AMM always trades at a fair, equilibrium price, and arbitrage profits (also known as LVR) are eliminated. Sandwich attacks are also eliminated because all trades occur at the exogenously-determined equilibrium price. We use Binance price data to simulate a lower bound to the return of providing liquidity to an FM-AMM and show that, at least for the token pairs and the period we consider, such lower bound is very close to the empirical returns of providing liquidity on Uniswap v3.","sentences":["We consider an automated market maker (AMM) in which all trades are batched and executed at a price equal to the marginal price (i.e., the price of an arbitrary small trade) after the batch trades.","We show that such an AMM is a function maximizing AMM (or FM-AMM): for given prices, it trades to reach the highest possible value of a given function.","Also, competition between arbitrageurs guarantees that an FM-AMM always trades at a fair, equilibrium price, and arbitrage profits (also known as LVR) are eliminated.","Sandwich attacks are also eliminated because all trades occur at the exogenously-determined equilibrium price.","We use Binance price data to simulate a lower bound to the return of providing liquidity to an FM-AMM and show that, at least for the token pairs and the period we consider, such lower bound is very close to the empirical returns of providing liquidity on Uniswap v3."],"url":"http://arxiv.org/abs/2307.02074v1"}
{"created":"2023-07-05 07:30:53","title":"Performance Modeling of Data Storage Systems using Generative Models","abstract":"High-precision modeling of systems is one of the main areas of industrial data analysis. Models of systems, their digital twins, are used to predict their behavior under various conditions. We have developed several models of a storage system using machine learning-based generative models. The system consists of several components: hard disk drive (HDD) and solid-state drive (SSD) storage pools with different RAID schemes and cache. Each storage component is represented by a probabilistic model that describes the probability distribution of the component performance in terms of IOPS and latency, depending on their configuration and external data load parameters. The results of the experiments demonstrate the errors of 4-10 % for IOPS and 3-16 % for latency predictions depending on the components and models of the system. The predictions show up to 0.99 Pearson correlation with Little's law, which can be used for unsupervised reliability checks of the models. In addition, we present novel data sets that can be used for benchmarking regression algorithms, conditional generative models, and uncertainty estimation methods in machine learning.","sentences":["High-precision modeling of systems is one of the main areas of industrial data analysis.","Models of systems, their digital twins, are used to predict their behavior under various conditions.","We have developed several models of a storage system using machine learning-based generative models.","The system consists of several components: hard disk drive (HDD) and solid-state drive (SSD) storage pools with different RAID schemes and cache.","Each storage component is represented by a probabilistic model that describes the probability distribution of the component performance in terms of IOPS and latency, depending on their configuration and external data load parameters.","The results of the experiments demonstrate the errors of 4-10 % for IOPS and 3-16 % for latency predictions depending on the components and models of the system.","The predictions show up to 0.99 Pearson correlation with Little's law, which can be used for unsupervised reliability checks of the models.","In addition, we present novel data sets that can be used for benchmarking regression algorithms, conditional generative models, and uncertainty estimation methods in machine learning."],"url":"http://arxiv.org/abs/2307.02073v1"}
{"created":"2023-07-05 07:26:27","title":"A Comparison of Machine Learning Methods for Data with High-Cardinality Categorical Variables","abstract":"High-cardinality categorical variables are variables for which the number of different levels is large relative to the sample size of a data set, or in other words, there are few data points per level. Machine learning methods can have difficulties with high-cardinality variables. In this article, we empirically compare several versions of two of the most successful machine learning methods, tree-boosting and deep neural networks, and linear mixed effects models using multiple tabular data sets with high-cardinality categorical variables. We find that, first, machine learning models with random effects have higher prediction accuracy than their classical counterparts without random effects, and, second, tree-boosting with random effects outperforms deep neural networks with random effects.","sentences":["High-cardinality categorical variables are variables for which the number of different levels is large relative to the sample size of a data set, or in other words, there are few data points per level.","Machine learning methods can have difficulties with high-cardinality variables.","In this article, we empirically compare several versions of two of the most successful machine learning methods, tree-boosting and deep neural networks, and linear mixed effects models using multiple tabular data sets with high-cardinality categorical variables.","We find that, first, machine learning models with random effects have higher prediction accuracy than their classical counterparts without random effects, and, second, tree-boosting with random effects outperforms deep neural networks with random effects."],"url":"http://arxiv.org/abs/2307.02071v1"}
{"created":"2023-07-05 07:12:58","title":"Universal Rates for Multiclass Learning","abstract":"We study universal rates for multiclass classification, establishing the optimal rates (up to log factors) for all hypothesis classes. This generalizes previous results on binary classification (Bousquet, Hanneke, Moran, van Handel, and Yehudayoff, 2021), and resolves an open question studied by Kalavasis, Velegkas, and Karbasi (2022) who handled the multiclass setting with a bounded number of class labels. In contrast, our result applies for any countable label space. Even for finite label space, our proofs provide a more precise bounds on the learning curves, as they do not depend on the number of labels. Specifically, we show that any class admits exponential rates if and only if it has no infinite Littlestone tree, and admits (near-)linear rates if and only if it has no infinite Daniely-Shalev-Shwartz-Littleston (DSL) tree, and otherwise requires arbitrarily slow rates. DSL trees are a new structure we define in this work, in which each node of the tree is given by a pseudo-cube of possible classifications of a given set of points. Pseudo-cubes are a structure, rooted in the work of Daniely and Shalev-Shwartz (2014), and recently shown by Brukhim, Carmon, Dinur, Moran, and Yehudayoff (2022) to characterize PAC learnability (i.e., uniform rates) for multiclass classification. We also resolve an open question of Kalavasis, Velegkas, and Karbasi (2022) regarding the equivalence of classes having infinite Graph-Littlestone (GL) trees versus infinite Natarajan-Littlestone (NL) trees, showing that they are indeed equivalent.","sentences":["We study universal rates for multiclass classification, establishing the optimal rates (up to log factors) for all hypothesis classes.","This generalizes previous results on binary classification (Bousquet, Hanneke, Moran, van Handel, and Yehudayoff, 2021), and resolves an open question studied by Kalavasis, Velegkas, and Karbasi (2022) who handled the multiclass setting with a bounded number of class labels.","In contrast, our result applies for any countable label space.","Even for finite label space, our proofs provide a more precise bounds on the learning curves, as they do not depend on the number of labels.","Specifically, we show that any class admits exponential rates if and only if it has no infinite Littlestone tree, and admits (near-)linear rates if and only if it has no infinite Daniely-Shalev-Shwartz-Littleston (DSL) tree, and otherwise requires arbitrarily slow rates.","DSL trees are a new structure we define in this work, in which each node of the tree is given by a pseudo-cube of possible classifications of a given set of points.","Pseudo-cubes are a structure, rooted in the work of Daniely and Shalev-Shwartz (2014), and recently shown by Brukhim, Carmon, Dinur, Moran, and Yehudayoff (2022) to characterize PAC learnability (i.e., uniform rates) for multiclass classification.","We also resolve an open question of Kalavasis, Velegkas, and Karbasi (2022) regarding the equivalence of classes having infinite Graph-Littlestone (GL) trees versus infinite Natarajan-Littlestone (NL) trees, showing that they are indeed equivalent."],"url":"http://arxiv.org/abs/2307.02066v1"}
{"created":"2023-07-05 07:08:58","title":"Line Graphics Digitization: A Step Towards Full Automation","abstract":"The digitization of documents allows for wider accessibility and reproducibility. While automatic digitization of document layout and text content has been a long-standing focus of research, this problem in regard to graphical elements, such as statistical plots, has been under-explored. In this paper, we introduce the task of fine-grained visual understanding of mathematical graphics and present the Line Graphics (LG) dataset, which includes pixel-wise annotations of 5 coarse and 10 fine-grained categories. Our dataset covers 520 images of mathematical graphics collected from 450 documents from different disciplines. Our proposed dataset can support two different computer vision tasks, i.e., semantic segmentation and object detection. To benchmark our LG dataset, we explore 7 state-of-the-art models. To foster further research on the digitization of statistical graphs, we will make the dataset, code, and models publicly available to the community.","sentences":["The digitization of documents allows for wider accessibility and reproducibility.","While automatic digitization of document layout and text content has been a long-standing focus of research, this problem in regard to graphical elements, such as statistical plots, has been under-explored.","In this paper, we introduce the task of fine-grained visual understanding of mathematical graphics and present the Line Graphics (LG) dataset, which includes pixel-wise annotations of 5 coarse and 10 fine-grained categories.","Our dataset covers 520 images of mathematical graphics collected from 450 documents from different disciplines.","Our proposed dataset can support two different computer vision tasks, i.e., semantic segmentation and object detection.","To benchmark our LG dataset, we explore 7 state-of-the-art models.","To foster further research on the digitization of statistical graphs, we will make the dataset, code, and models publicly available to the community."],"url":"http://arxiv.org/abs/2307.02065v1"}
{"created":"2023-07-05 07:00:31","title":"Facing off World Model Backbones: RNNs, Transformers, and S4","abstract":"World models are a fundamental component in model-based reinforcement learning (MBRL) agents. To perform temporally extended and consistent simulations of the future in partially observable environments, world models need to possess long-term memory. However, state-of-the-art MBRL agents, such as Dreamer, predominantly employ recurrent neural networks (RNNs) as their world model backbone, which have limited memory capacity. In this paper, we seek to explore alternative world model backbones for improving long-term memory. In particular, we investigate the effectiveness of Transformers and Structured State Space Sequence (S4) models, motivated by their remarkable ability to capture long-range dependencies in low-dimensional sequences and their complementary strengths. We propose S4WM, the first S4-based world model that can generate high-dimensional image sequences through latent imagination. Furthermore, we extensively compare RNN-, Transformer-, and S4-based world models across four sets of environments, which we have specifically tailored to assess crucial memory capabilities of world models, including long-term imagination, context-dependent recall, reward prediction, and memory-based reasoning. Our findings demonstrate that S4WM outperforms Transformer-based world models in terms of long-term memory, while exhibiting greater efficiency during training and imagination. These results pave the way for the development of stronger MBRL agents.","sentences":["World models are a fundamental component in model-based reinforcement learning (MBRL) agents.","To perform temporally extended and consistent simulations of the future in partially observable environments, world models need to possess long-term memory.","However, state-of-the-art MBRL agents, such as Dreamer, predominantly employ recurrent neural networks (RNNs) as their world model backbone, which have limited memory capacity.","In this paper, we seek to explore alternative world model backbones for improving long-term memory.","In particular, we investigate the effectiveness of Transformers and Structured State Space Sequence (S4) models, motivated by their remarkable ability to capture long-range dependencies in low-dimensional sequences and their complementary strengths.","We propose S4WM, the first S4-based world model that can generate high-dimensional image sequences through latent imagination.","Furthermore, we extensively compare RNN-, Transformer-, and S4-based world models across four sets of environments, which we have specifically tailored to assess crucial memory capabilities of world models, including long-term imagination, context-dependent recall, reward prediction, and memory-based reasoning.","Our findings demonstrate that S4WM outperforms Transformer-based world models in terms of long-term memory, while exhibiting greater efficiency during training and imagination.","These results pave the way for the development of stronger MBRL agents."],"url":"http://arxiv.org/abs/2307.02064v1"}
{"created":"2023-07-05 06:55:04","title":"Traversability Analysis for Autonomous Driving in Complex Environment: A LiDAR-based Terrain Modeling Approach","abstract":"For autonomous driving, traversability analysis is one of the most basic and essential tasks. In this paper, we propose a novel LiDAR-based terrain modeling approach, which could output stable, complete and accurate terrain models and traversability analysis results. As terrain is an inherent property of the environment that does not change with different view angles, our approach adopts a multi-frame information fusion strategy for terrain modeling. Specifically, a normal distributions transform mapping approach is adopted to accurately model the terrain by fusing information from consecutive LiDAR frames. Then the spatial-temporal Bayesian generalized kernel inference and bilateral filtering are utilized to promote the stability and completeness of the results while simultaneously retaining the sharp terrain edges. Based on the terrain modeling results, the traversability of each region is obtained by performing geometric connectivity analysis between neighboring terrain regions. Experimental results show that the proposed method could run in real-time and outperforms state-of-the-art approaches.","sentences":["For autonomous driving, traversability analysis is one of the most basic and essential tasks.","In this paper, we propose a novel LiDAR-based terrain modeling approach, which could output stable, complete and accurate terrain models and traversability analysis results.","As terrain is an inherent property of the environment that does not change with different view angles, our approach adopts a multi-frame information fusion strategy for terrain modeling.","Specifically, a normal distributions transform mapping approach is adopted to accurately model the terrain by fusing information from consecutive LiDAR frames.","Then the spatial-temporal Bayesian generalized kernel inference and bilateral filtering are utilized to promote the stability and completeness of the results while simultaneously retaining the sharp terrain edges.","Based on the terrain modeling results, the traversability of each region is obtained by performing geometric connectivity analysis between neighboring terrain regions.","Experimental results show that the proposed method could run in real-time and outperforms state-of-the-art approaches."],"url":"http://arxiv.org/abs/2307.02060v1"}
{"created":"2023-07-05 06:40:08","title":"Adversarial Attacks on Image Classification Models: FGSM and Patch Attacks and their Impact","abstract":"This chapter introduces the concept of adversarial attacks on image classification models built on convolutional neural networks (CNN). CNNs are very popular deep-learning models which are used in image classification tasks. However, very powerful and pre-trained CNN models working very accurately on image datasets for image classification tasks may perform disastrously when the networks are under adversarial attacks. In this work, two very well-known adversarial attacks are discussed and their impact on the performance of image classifiers is analyzed. These two adversarial attacks are the fast gradient sign method (FGSM) and adversarial patch attack. These attacks are launched on three powerful pre-trained image classifier architectures, ResNet-34, GoogleNet, and DenseNet-161. The classification accuracy of the models in the absence and presence of the two attacks are computed on images from the publicly accessible ImageNet dataset. The results are analyzed to evaluate the impact of the attacks on the image classification task.","sentences":["This chapter introduces the concept of adversarial attacks on image classification models built on convolutional neural networks (CNN).","CNNs are very popular deep-learning models which are used in image classification tasks.","However, very powerful and pre-trained CNN models working very accurately on image datasets for image classification tasks may perform disastrously when the networks are under adversarial attacks.","In this work, two very well-known adversarial attacks are discussed and their impact on the performance of image classifiers is analyzed.","These two adversarial attacks are the fast gradient sign method (FGSM) and adversarial patch attack.","These attacks are launched on three powerful pre-trained image classifier architectures, ResNet-34, GoogleNet, and DenseNet-161.","The classification accuracy of the models in the absence and presence of the two attacks are computed on images from the publicly accessible ImageNet dataset.","The results are analyzed to evaluate the impact of the attacks on the image classification task."],"url":"http://arxiv.org/abs/2307.02055v1"}
{"created":"2023-07-05 06:38:52","title":"Emoji Prediction using Transformer Models","abstract":"In recent years, the use of emojis in social media has increased dramatically, making them an important element in understanding online communication. However, predicting the meaning of emojis in a given text is a challenging task due to their ambiguous nature. In this study, we propose a transformer-based approach for emoji prediction using BERT, a widely-used pre-trained language model. We fine-tuned BERT on a large corpus of text containing both text and emojis to predict the most appropriate emoji for a given text. Our experimental results demonstrate that our approach outperforms several state-of-the-art models in predicting emojis with an accuracy of over 75 \\% This work has potential applications in natural language processing, sentiment analysis, and social media marketing.","sentences":["In recent years, the use of emojis in social media has increased dramatically, making them an important element in understanding online communication.","However, predicting the meaning of emojis in a given text is a challenging task due to their ambiguous nature.","In this study, we propose a transformer-based approach for emoji prediction using BERT, a widely-used pre-trained language model.","We fine-tuned BERT on a large corpus of text containing both text and emojis to predict the most appropriate emoji for a given text.","Our experimental results demonstrate that our approach outperforms several state-of-the-art models in predicting emojis with an accuracy of over 75 \\% This work has potential applications in natural language processing, sentiment analysis, and social media marketing."],"url":"http://arxiv.org/abs/2307.02054v1"}
{"created":"2023-07-05 06:36:54","title":"Flacuna: Unleashing the Problem Solving Power of Vicuna using FLAN Fine-Tuning","abstract":"Recently, the release of INSTRUCTEVAL has provided valuable insights into the performance of large language models (LLMs) that utilize encoder-decoder or decoder-only architecture. Interestingly, despite being introduced four years ago, T5-based LLMs, such as FLAN-T5, continue to outperform the latest decoder-based LLMs, such as LLAMA and VICUNA, on tasks that require general problem-solving skills. This performance discrepancy can be attributed to three key factors: (1) Pre-training data, (2) Backbone architecture, and (3) Instruction dataset. In this technical report, our main focus is on investigating the impact of the third factor by leveraging VICUNA, a large language model based on LLAMA, which has undergone fine-tuning on ChatGPT conversations. To achieve this objective, we fine-tuned VICUNA using a customized instruction dataset collection called FLANMINI. This collection includes a subset of the large-scale instruction dataset known as FLAN, as well as various code-related datasets and conversational datasets derived from ChatGPT/GPT-4. This dataset comprises a large number of tasks that demand problem-solving skills. Our experimental findings strongly indicate that the enhanced problem-solving abilities of our model, FLACUNA, are obtained through fine-tuning VICUNA on the FLAN dataset, leading to significant improvements across numerous benchmark datasets in INSTRUCTEVAL. FLACUNA is publicly available at https://huggingface.co/declare-lab/flacuna-13b-v1.0.","sentences":["Recently, the release of INSTRUCTEVAL has provided valuable insights into the performance of large language models (LLMs) that utilize encoder-decoder or decoder-only architecture.","Interestingly, despite being introduced four years ago, T5-based LLMs, such as FLAN-T5, continue to outperform the latest decoder-based LLMs, such as LLAMA and VICUNA, on tasks that require general problem-solving skills.","This performance discrepancy can be attributed to three key factors: (1) Pre-training data, (2) Backbone architecture, and (3) Instruction dataset.","In this technical report, our main focus is on investigating the impact of the third factor by leveraging VICUNA, a large language model based on LLAMA, which has undergone fine-tuning on ChatGPT conversations.","To achieve this objective, we fine-tuned VICUNA using a customized instruction dataset collection called FLANMINI.","This collection includes a subset of the large-scale instruction dataset known as FLAN, as well as various code-related datasets and conversational datasets derived from ChatGPT/GPT-4.","This dataset comprises a large number of tasks that demand problem-solving skills.","Our experimental findings strongly indicate that the enhanced problem-solving abilities of our model, FLACUNA, are obtained through fine-tuning VICUNA on the FLAN dataset, leading to significant improvements across numerous benchmark datasets in INSTRUCTEVAL.","FLACUNA is publicly available at https://huggingface.co/declare-lab/flacuna-13b-v1.0."],"url":"http://arxiv.org/abs/2307.02053v1"}
{"created":"2023-07-05 06:17:22","title":"From Ideal to Practice: Data Encryption in eADR-based Secure Non-Volatile Memory Systems","abstract":"Extended Asynchronous DRAM Refresh (eADR) proposed by Intel extends the persistence domain from the Non-Volatile Memory (NVM) to CPU caches and offers the persistence guarantee. Due to allowing lazy persistence and decreasing the amounts of instructions, eADR-based NVM systems significantly improve performance. Existing designs however fail to provide efficient encryption schemes to ensure data confidentiality in eADR-based NVM systems. It is challenging to guarantee both data persistence and confidentiality in a cost-efficient manner due to the transient persistence property of caches in eADR. Once the system crashes, eADR flushes the unencrypted data from the cache into NVM, in which security issues occur due to no encryption. To bridge the gap between persistence and confidentiality, we propose cost-efficient BBE and Sepencr encryption schemes that efficiently match different eADR execution models from ideal to practice. Under the ideal eADR execution model, BBE supports the encryption module via the battery of eADR upon crashes. Under the practical eADR execution model, Sepencr generates the one-time paddings (OTPs) at the system startup to encrypt the cached data in case the system crashes. Our evaluation results show that compared with an intuitive in-cache encryption scheme in eADR-based systems, our designs significantly reduce performance overheads while efficiently ensuring data confidentiality.","sentences":["Extended Asynchronous DRAM Refresh (eADR) proposed by Intel extends the persistence domain from the Non-Volatile Memory (NVM) to CPU caches and offers the persistence guarantee.","Due to allowing lazy persistence and decreasing the amounts of instructions, eADR-based NVM systems significantly improve performance.","Existing designs however fail to provide efficient encryption schemes to ensure data confidentiality in eADR-based NVM systems.","It is challenging to guarantee both data persistence and confidentiality in a cost-efficient manner due to the transient persistence property of caches in eADR.","Once the system crashes, eADR flushes the unencrypted data from the cache into NVM, in which security issues occur due to no encryption.","To bridge the gap between persistence and confidentiality, we propose cost-efficient BBE and Sepencr encryption schemes that efficiently match different eADR execution models from ideal to practice.","Under the ideal eADR execution model, BBE supports the encryption module via the battery of eADR upon crashes.","Under the practical eADR execution model, Sepencr generates the one-time paddings (OTPs) at the system startup to encrypt the cached data in case the system crashes.","Our evaluation results show that compared with an intuitive in-cache encryption scheme in eADR-based systems, our designs significantly reduce performance overheads while efficiently ensuring data confidentiality."],"url":"http://arxiv.org/abs/2307.02050v1"}
{"created":"2023-07-05 06:05:36","title":"CAME: Confidence-guided Adaptive Memory Efficient Optimization","abstract":"Adaptive gradient methods, such as Adam and LAMB, have demonstrated excellent performance in the training of large language models. Nevertheless, the need for adaptivity requires maintaining second-moment estimates of the per-parameter gradients, which entails a high cost of extra memory overheads. To solve this problem, several memory-efficient optimizers (e.g., Adafactor) have been proposed to obtain a drastic reduction in auxiliary memory usage, but with a performance penalty. In this paper, we first study a confidence-guided strategy to reduce the instability of existing memory efficient optimizers. Based on this strategy, we propose CAME to simultaneously achieve two goals: fast convergence as in traditional adaptive methods, and low memory usage as in memory-efficient methods. Extensive experiments demonstrate the training stability and superior performance of CAME across various NLP tasks such as BERT and GPT-2 training. Notably, for BERT pre-training on the large batch size of 32,768, our proposed optimizer attains faster convergence and higher accuracy compared with the Adam optimizer. The implementation of CAME is publicly available.","sentences":["Adaptive gradient methods, such as Adam and LAMB, have demonstrated excellent performance in the training of large language models.","Nevertheless, the need for adaptivity requires maintaining second-moment estimates of the per-parameter gradients, which entails a high cost of extra memory overheads.","To solve this problem, several memory-efficient optimizers (e.g., Adafactor) have been proposed to obtain a drastic reduction in auxiliary memory usage, but with a performance penalty.","In this paper, we first study a confidence-guided strategy to reduce the instability of existing memory efficient optimizers.","Based on this strategy, we propose CAME to simultaneously achieve two goals: fast convergence as in traditional adaptive methods, and low memory usage as in memory-efficient methods.","Extensive experiments demonstrate the training stability and superior performance of CAME across various NLP tasks such as BERT and GPT-2 training.","Notably, for BERT pre-training on the large batch size of 32,768, our proposed optimizer attains faster convergence and higher accuracy compared with the Adam optimizer.","The implementation of CAME is publicly available."],"url":"http://arxiv.org/abs/2307.02047v1"}
{"created":"2023-07-05 06:03:40","title":"Recommender Systems in the Era of Large Language Models (LLMs)","abstract":"With the prosperity of e-commerce and web applications, Recommender Systems (RecSys) have become an important component of our daily life, providing personalized suggestions that cater to user preferences. While Deep Neural Networks (DNNs) have made significant advancements in enhancing recommender systems by modeling user-item interactions and incorporating textual side information, DNN-based methods still face limitations, such as difficulties in understanding users' interests and capturing textual side information, inabilities in generalizing to various recommendation scenarios and reasoning on their predictions, etc. Meanwhile, the emergence of Large Language Models (LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural Language Processing (NLP) and Artificial Intelligence (AI), due to their remarkable abilities in fundamental responsibilities of language understanding and generation, as well as impressive generalization and reasoning capabilities. As a result, recent studies have attempted to harness the power of LLMs to enhance recommender systems. Given the rapid evolution of this research direction in recommender systems, there is a pressing need for a systematic overview that summarizes existing LLM-empowered recommender systems, to provide researchers in relevant fields with an in-depth understanding. Therefore, in this paper, we conduct a comprehensive review of LLM-empowered recommender systems from various aspects including Pre-training, Fine-tuning, and Prompting. More specifically, we first introduce representative methods to harness the power of LLMs (as a feature encoder) for learning representations of users and items. Then, we review recent techniques of LLMs for enhancing recommender systems from three paradigms, namely pre-training, fine-tuning, and prompting. Finally, we comprehensively discuss future directions in this emerging field.","sentences":["With the prosperity of e-commerce and web applications, Recommender Systems (RecSys) have become an important component of our daily life, providing personalized suggestions that cater to user preferences.","While Deep Neural Networks (DNNs) have made significant advancements in enhancing recommender systems by modeling user-item interactions and incorporating textual side information, DNN-based methods still face limitations, such as difficulties in understanding users' interests and capturing textual side information, inabilities in generalizing to various recommendation scenarios and reasoning on their predictions, etc.","Meanwhile, the emergence of Large Language Models (LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural Language Processing (NLP) and Artificial Intelligence (AI), due to their remarkable abilities in fundamental responsibilities of language understanding and generation, as well as impressive generalization and reasoning capabilities.","As a result, recent studies have attempted to harness the power of LLMs to enhance recommender systems.","Given the rapid evolution of this research direction in recommender systems, there is a pressing need for a systematic overview that summarizes existing LLM-empowered recommender systems, to provide researchers in relevant fields with an in-depth understanding.","Therefore, in this paper, we conduct a comprehensive review of LLM-empowered recommender systems from various aspects including Pre-training, Fine-tuning, and Prompting.","More specifically, we first introduce representative methods to harness the power of LLMs (as a feature encoder) for learning representations of users and items.","Then, we review recent techniques of LLMs for enhancing recommender systems from three paradigms, namely pre-training, fine-tuning, and prompting.","Finally, we comprehensively discuss future directions in this emerging field."],"url":"http://arxiv.org/abs/2307.02046v1"}
{"created":"2023-07-05 05:55:10","title":"Multimodal Imbalance-Aware Gradient Modulation for Weakly-supervised Audio-Visual Video Parsing","abstract":"Weakly-supervised audio-visual video parsing (WS-AVVP) aims to localize the temporal extents of audio, visual and audio-visual event instances as well as identify the corresponding event categories with only video-level category labels for training. Most previous methods pay much attention to refining the supervision for each modality or extracting fruitful cross-modality information for more reliable feature learning. None of them have noticed the imbalanced feature learning between different modalities in the task. In this paper, to balance the feature learning processes of different modalities, a dynamic gradient modulation (DGM) mechanism is explored, where a novel and effective metric function is designed to measure the imbalanced feature learning between audio and visual modalities. Furthermore, principle analysis indicates that the multimodal confusing calculation will hamper the precise measurement of multimodal imbalanced feature learning, which further weakens the effectiveness of our DGM mechanism. To cope with this issue, a modality-separated decision unit (MSDU) is designed for more precise measurement of imbalanced feature learning between audio and visual modalities. Comprehensive experiments are conducted on public benchmarks and the corresponding experimental results demonstrate the effectiveness of our proposed method.","sentences":["Weakly-supervised audio-visual video parsing (WS-AVVP) aims to localize the temporal extents of audio, visual and audio-visual event instances as well as identify the corresponding event categories with only video-level category labels for training.","Most previous methods pay much attention to refining the supervision for each modality or extracting fruitful cross-modality information for more reliable feature learning.","None of them have noticed the imbalanced feature learning between different modalities in the task.","In this paper, to balance the feature learning processes of different modalities, a dynamic gradient modulation (DGM) mechanism is explored, where a novel and effective metric function is designed to measure the imbalanced feature learning between audio and visual modalities.","Furthermore, principle analysis indicates that the multimodal confusing calculation will hamper the precise measurement of multimodal imbalanced feature learning, which further weakens the effectiveness of our DGM mechanism.","To cope with this issue, a modality-separated decision unit (MSDU) is designed for more precise measurement of imbalanced feature learning between audio and visual modalities.","Comprehensive experiments are conducted on public benchmarks and the corresponding experimental results demonstrate the effectiveness of our proposed method."],"url":"http://arxiv.org/abs/2307.02041v1"}
{"created":"2023-07-05 05:55:08","title":"VertiBench: Advancing Feature Distribution Diversity in Vertical Federated Learning Benchmarks","abstract":"Vertical Federated Learning (VFL) is a crucial paradigm for training machine learning models on feature-partitioned, distributed data. However, due to privacy restrictions, few public real-world VFL datasets exist for algorithm evaluation, and these represent a limited array of feature distributions. Existing benchmarks often resort to synthetic datasets, derived from arbitrary feature splits from a global set, which only capture a subset of feature distributions, leading to inadequate algorithm performance assessment. This paper addresses these shortcomings by introducing two key factors affecting VFL performance - feature importance and feature correlation - and proposing associated evaluation metrics and dataset splitting methods. Additionally, we introduce a real VFL dataset to address the deficit in image-image VFL scenarios. Our comprehensive evaluation of cutting-edge VFL algorithms provides valuable insights for future research in the field.","sentences":["Vertical Federated Learning (VFL) is a crucial paradigm for training machine learning models on feature-partitioned, distributed data.","However, due to privacy restrictions, few public real-world VFL datasets exist for algorithm evaluation, and these represent a limited array of feature distributions.","Existing benchmarks often resort to synthetic datasets, derived from arbitrary feature splits from a global set, which only capture a subset of feature distributions, leading to inadequate algorithm performance assessment.","This paper addresses these shortcomings by introducing two key factors affecting VFL performance - feature importance and feature correlation - and proposing associated evaluation metrics and dataset splitting methods.","Additionally, we introduce a real VFL dataset to address the deficit in image-image VFL scenarios.","Our comprehensive evaluation of cutting-edge VFL algorithms provides valuable insights for future research in the field."],"url":"http://arxiv.org/abs/2307.02040v1"}
{"created":"2023-07-05 05:37:13","title":"Ranking with Abstention","abstract":"We introduce a novel framework of ranking with abstention, where the learner can abstain from making prediction at some limited cost $c$. We present a extensive theoretical analysis of this framework including a series of $H$-consistency bounds for both the family of linear functions and that of neural networks with one hidden-layer. These theoretical guarantees are the state-of-the-art consistency guarantees in the literature, which are upper bounds on the target loss estimation error of a predictor in a hypothesis set $H$, expressed in terms of the surrogate loss estimation error of that predictor. We further argue that our proposed abstention methods are important when using common equicontinuous hypothesis sets in practice. We report the results of experiments illustrating the effectiveness of ranking with abstention.","sentences":["We introduce a novel framework of ranking with abstention, where the learner can abstain from making prediction at some limited cost $c$. We present a extensive theoretical analysis of this framework including a series of $H$-consistency bounds for both the family of linear functions and that of neural networks with one hidden-layer.","These theoretical guarantees are the state-of-the-art consistency guarantees in the literature, which are upper bounds on the target loss estimation error of a predictor in a hypothesis set $H$, expressed in terms of the surrogate loss estimation error of that predictor.","We further argue that our proposed abstention methods are important when using common equicontinuous hypothesis sets in practice.","We report the results of experiments illustrating the effectiveness of ranking with abstention."],"url":"http://arxiv.org/abs/2307.02035v1"}
{"created":"2023-07-05 05:30:22","title":"ScalOTA: Scalable Secure Over-the-Air Software Updates for Vehicles","abstract":"Over-the-Air (OTA) software updates are becoming essential for electric/electronic vehicle architectures in order to reduce recalls amid the increasing software bugs and vulnerabilities. Current OTA update architectures rely heavily on direct cellular repository-to-vehicle links, which makes the repository a communication bottleneck, and increases the cellular bandwidth utilization cost as well as the software download latency. In this paper, we introduce ScalOTA, an end-to-end scalable OTA software update architecture and secure protocol for modern vehicles. For the first time, we propose using a network of update stations, as part of Electric Vehicle charging stations, to boost the download speed through these stations, and reduce the cellular bandwidth overhead significantly. Our formalized OTA update protocol ensures proven end-to-end chain-of-trust including all stakeholders: manufacturer, suppliers, update stations, and all layers of in-vehicle Electric Control Units (ECUs). The empirical evaluation shows that ScalOTA reduces the bandwidth utilization and download latency up to an order of magnitude compared with current OTA update systems.","sentences":["Over-the-Air (OTA) software updates are becoming essential for electric/electronic vehicle architectures in order to reduce recalls amid the increasing software bugs and vulnerabilities.","Current OTA update architectures rely heavily on direct cellular repository-to-vehicle links, which makes the repository a communication bottleneck, and increases the cellular bandwidth utilization cost as well as the software download latency.","In this paper, we introduce ScalOTA, an end-to-end scalable OTA software update architecture and secure protocol for modern vehicles.","For the first time, we propose using a network of update stations, as part of Electric Vehicle charging stations, to boost the download speed through these stations, and reduce the cellular bandwidth overhead significantly.","Our formalized OTA update protocol ensures proven end-to-end chain-of-trust including all stakeholders: manufacturer, suppliers, update stations, and all layers of in-vehicle Electric Control Units (ECUs).","The empirical evaluation shows that ScalOTA reduces the bandwidth utilization and download latency up to an order of magnitude compared with current OTA update systems."],"url":"http://arxiv.org/abs/2307.02032v1"}
{"created":"2023-07-05 05:28:38","title":"Improving Automatic Parallel Training via Balanced Memory Workload Optimization","abstract":"Transformer models have emerged as the leading approach for achieving state-of-the-art performance across various application domains, serving as the foundation for advanced large-scale deep learning (DL) models. However, efficiently training these models across multiple GPUs remains a complex challenge due to the abundance of parallelism options. Existing DL systems either require manual efforts to design distributed training plans or limit parallelism combinations to a constrained search space. In this paper, we present Galvatron-BMW, a novel system framework that integrates multiple prevalent parallelism dimensions and automatically identifies the most efficient hybrid parallelism strategy. To effectively navigate this vast search space, we employ a decision tree approach for decomposition and pruning based on intuitive insights. We further utilize a dynamic programming search algorithm to derive the optimal plan. Moreover, to improve resource utilization and enhance system efficiency, we propose a bi-objective optimization workflow that focuses on workload balance. Our evaluations on different Transformer models demonstrate the capabilities of Galvatron-BMW in automating distributed training under varying GPU memory constraints. Across all tested scenarios, Galvatron-BMW consistently achieves superior system throughput, surpassing previous approaches that rely on limited parallelism strategies.","sentences":["Transformer models have emerged as the leading approach for achieving state-of-the-art performance across various application domains, serving as the foundation for advanced large-scale deep learning (DL) models.","However, efficiently training these models across multiple GPUs remains a complex challenge due to the abundance of parallelism options.","Existing DL systems either require manual efforts to design distributed training plans or limit parallelism combinations to a constrained search space.","In this paper, we present Galvatron-BMW, a novel system framework that integrates multiple prevalent parallelism dimensions and automatically identifies the most efficient hybrid parallelism strategy.","To effectively navigate this vast search space, we employ a decision tree approach for decomposition and pruning based on intuitive insights.","We further utilize a dynamic programming search algorithm to derive the optimal plan.","Moreover, to improve resource utilization and enhance system efficiency, we propose a bi-objective optimization workflow that focuses on workload balance.","Our evaluations on different Transformer models demonstrate the capabilities of Galvatron-BMW in automating distributed training under varying GPU memory constraints.","Across all tested scenarios, Galvatron-BMW consistently achieves superior system throughput, surpassing previous approaches that rely on limited parallelism strategies."],"url":"http://arxiv.org/abs/2307.02031v1"}
{"created":"2023-07-05 05:24:59","title":"EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models","abstract":"While the general machine learning (ML) community has benefited from public datasets, tasks, and models, the progress of ML in healthcare has been hampered by a lack of such shared assets. The success of foundation models creates new challenges for healthcare ML by requiring access to shared pretrained models to validate performance benefits. We help address these challenges through three contributions. First, we publish a new dataset, EHRSHOT, containing de-identified structured data from the electronic health records (EHRs) of 6,712 patients from Stanford Medicine. Unlike MIMIC-III/IV and other popular EHR datasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients. Second, we publish the weights of a 141M parameter clinical foundation model pretrained on the structured EHR data of 2.57M patients. We are one of the first to fully release such a model for coded EHR data; in contrast, most prior models released for clinical data (e.g. GatorTron, ClinicalBERT) only work with unstructured text and cannot process the rich, structured data within an EHR. We provide an end-to-end pipeline for the community to validate and build upon its performance. Third, we define 15 few-shot clinical prediction tasks, enabling evaluation of foundation models on benefits such as sample efficiency and task adaption. The code to reproduce our results, as well as the model and dataset (via a research data use agreement), are available at our Github repo here: https://github.com/som-shahlab/ehrshot-benchmark","sentences":["While the general machine learning (ML) community has benefited from public datasets, tasks, and models, the progress of ML in healthcare has been hampered by a lack of such shared assets.","The success of foundation models creates new challenges for healthcare ML by requiring access to shared pretrained models to validate performance benefits.","We help address these challenges through three contributions.","First, we publish a new dataset, EHRSHOT, containing de-identified structured data from the electronic health records (EHRs) of 6,712 patients from Stanford Medicine.","Unlike MIMIC-III/IV and other popular EHR datasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients.","Second, we publish the weights of a 141M parameter clinical foundation model pretrained on the structured EHR data of 2.57M patients.","We are one of the first to fully release such a model for coded EHR data; in contrast, most prior models released for clinical data (e.g. GatorTron, ClinicalBERT) only work with unstructured text and cannot process the rich, structured data within an EHR.","We provide an end-to-end pipeline for the community to validate and build upon its performance.","Third, we define 15 few-shot clinical prediction tasks, enabling evaluation of foundation models on benefits such as sample efficiency and task adaption.","The code to reproduce our results, as well as the model and dataset (via a research data use agreement), are available at our Github repo here: https://github.com/som-shahlab/ehrshot-benchmark"],"url":"http://arxiv.org/abs/2307.02028v1"}
{"created":"2023-07-05 05:23:49","title":"NMS Threshold matters for Ego4D Moment Queries -- 2nd place solution to the Ego4D Moment Queries Challenge 2023","abstract":"This report describes our submission to the Ego4D Moment Queries Challenge 2023. Our submission extends ActionFormer, a latest method for temporal action localization. Our extension combines an improved ground-truth assignment strategy during training and a refined version of SoftNMS at inference time. Our solution is ranked 2nd on the public leaderboard with 26.62% average mAP and 45.69% Recall@1x at tIoU=0.5 on the test set, significantly outperforming the strong baseline from 2023 challenge. Our code is available at https://github.com/happyharrycn/actionformer_release.","sentences":["This report describes our submission to the Ego4D Moment Queries Challenge 2023.","Our submission extends ActionFormer, a latest method for temporal action localization.","Our extension combines an improved ground-truth assignment strategy during training and a refined version of SoftNMS at inference time.","Our solution is ranked 2nd on the public leaderboard with 26.62% average mAP and 45.69% Recall@1x at tIoU=0.5 on the test set, significantly outperforming the strong baseline from 2023 challenge.","Our code is available at https://github.com/happyharrycn/actionformer_release."],"url":"http://arxiv.org/abs/2307.02025v1"}
{"created":"2023-07-05 04:54:22","title":"Independent Sets in Elimination Graphs with a Submodular Objective","abstract":"Maximum weight independent set (MWIS) admits a $\\frac1k$-approximation in inductively $k$-independent graphs and a $\\frac{1}{2k}$-approximation in $k$-perfectly orientable graphs. These are a a parameterized class of graphs that generalize $k$-degenerate graphs, chordal graphs, and intersection graphs of various geometric shapes such as intervals, pseudo-disks, and several others. We consider a generalization of MWIS to a submodular objective. Given a graph $G=(V,E)$ and a non-negative submodular function $f: 2^V \\rightarrow \\mathbb{R}_+$, the goal is to approximately solve $\\max_{S \\in \\mathcal{I}_G} f(S)$ where $\\mathcal{I}_G$ is the set of independent sets of $G$. We obtain an $\\Omega(\\frac1k)$-approximation for this problem in the two mentioned graph classes. The first approach is via the multilinear relaxation framework and a simple contention resolution scheme, and this results in a randomized algorithm with approximation ratio at least $\\frac{1}{e(k+1)}$. This approach also yields parallel (or low-adaptivity) approximations. Motivated by the goal of designing efficient and deterministic algorithms, we describe two other algorithms for inductively $k$-independent graphs that are inspired by work on streaming algorithms: a preemptive greedy algorithm and a primal-dual algorithm. In addition to being simpler and faster, these algorithms, in the monotone submodular case, yield the first deterministic constant factor approximations for various special cases that have been previously considered such as intersection graphs of intervals, disks and pseudo-disks.","sentences":["Maximum weight independent set (MWIS) admits a $\\frac1k$-approximation in inductively $k$-independent graphs and a $\\frac{1}{2k}$-approximation in $k$-perfectly orientable graphs.","These are a a parameterized class of graphs that generalize $k$-degenerate graphs, chordal graphs, and intersection graphs of various geometric shapes such as intervals, pseudo-disks, and several others.","We consider a generalization of MWIS to a submodular objective.","Given a graph $G=(V,E)$ and a non-negative submodular function $f: 2^V \\rightarrow \\mathbb{R}_+$, the goal is to approximately solve $\\max_{S \\in \\mathcal{I}_G} f(S)$ where $\\mathcal{I}_G$ is the set of independent sets of $G$. We obtain an $\\Omega(\\frac1k)$-approximation for this problem in the two mentioned graph classes.","The first approach is via the multilinear relaxation framework and a simple contention resolution scheme, and this results in a randomized algorithm with approximation ratio at least $\\frac{1}{e(k+1)}$. This approach also yields parallel (or low-adaptivity) approximations.","Motivated by the goal of designing efficient and deterministic algorithms, we describe two other algorithms for inductively $k$-independent graphs that are inspired by work on streaming algorithms: a preemptive greedy algorithm and a primal-dual algorithm.","In addition to being simpler and faster, these algorithms, in the monotone submodular case, yield the first deterministic constant factor approximations for various special cases that have been previously considered such as intersection graphs of intervals, disks and pseudo-disks."],"url":"http://arxiv.org/abs/2307.02022v1"}
{"created":"2023-07-05 04:49:58","title":"Parameterized Complexity of Domination Problems Using Restricted Modular Partitions","abstract":"For a graph class $\\mathcal{G}$, we define the $\\mathcal{G}$-modular cardinality of a graph $G$ as the minimum size of a vertex partition of $G$ into modules that each induces a graph in $\\mathcal{G}$. This generalizes other module-based graph parameters such as neighborhood diversity and iterated type partition. Moreover, if $\\mathcal{G}$ has bounded modular-width, the W[1]-hardness of a problem in $\\mathcal{G}$-modular cardinality implies hardness on modular-width, clique-width, and other related parameters. On the other hand, fixed-parameter tractable (FPT) algorithms in $\\mathcal{G}$-modular cardinality may provide new ideas for algorithms using such parameters.   Several FPT algorithms based on modular partitions compute a solution table in each module, then combine each table into a global solution. This works well when each table has a succinct representation, but as we argue, when no such representation exists, the problem is typically W[1]-hard. We illustrate these ideas on the generic $(\\alpha, \\beta)$-domination problem, which asks for a set of vertices that contains at least a fraction $\\alpha$ of the adjacent vertices of each unchosen vertex, plus some (possibly negative) amount $\\beta$. This generalizes known domination problems such as Bounded Degree Deletion, $k$-Domination, and $\\alpha$-Domination. We show that for graph classes $\\mathcal{G}$ that require arbitrarily large solution tables, these problems are W[1]-hard in the $\\mathcal{G}$-modular cardinality, whereas they are fixed-parameter tractable when they admit succinct solution tables. This leads to several new positive and negative results for many domination problems parameterized by known and novel structural graph parameters such as clique-width, modular-width, and $cluster$-modular cardinality.","sentences":["For a graph class $\\mathcal{G}$, we define the $\\mathcal{G}$-modular cardinality of a graph $G$ as the minimum size of a vertex partition of $G$ into modules that each induces a graph in $\\mathcal{G}$. This generalizes other module-based graph parameters such as neighborhood diversity and iterated type partition.","Moreover, if $\\mathcal{G}$ has bounded modular-width, the W[1]-hardness of a problem in $\\mathcal{G}$-modular cardinality implies hardness on modular-width, clique-width, and other related parameters.","On the other hand, fixed-parameter tractable (FPT) algorithms in $\\mathcal{G}$-modular cardinality may provide new ideas for algorithms using such parameters.   ","Several FPT algorithms based on modular partitions compute a solution table in each module, then combine each table into a global solution.","This works well when each table has a succinct representation, but as we argue, when no such representation exists, the problem is typically W[1]-hard.","We illustrate these ideas on the generic $(\\alpha, \\beta)$-domination problem, which asks for a set of vertices that contains at least a fraction $\\alpha$ of the adjacent vertices of each unchosen vertex, plus some (possibly negative) amount $\\beta$. This generalizes known domination problems such as Bounded Degree Deletion, $k$-Domination, and $\\alpha$-Domination.","We show that for graph classes $\\mathcal{G}$ that require arbitrarily large solution tables, these problems are W[1]-hard in the $\\mathcal{G}$-modular cardinality, whereas they are fixed-parameter tractable when they admit succinct solution tables.","This leads to several new positive and negative results for many domination problems parameterized by known and novel structural graph parameters such as clique-width, modular-width, and $cluster$-modular cardinality."],"url":"http://arxiv.org/abs/2307.02021v1"}
{"created":"2023-07-05 04:14:57","title":"Generative Adversarial Networks for Dental Patient Identity Protection in Orthodontic Educational Imaging","abstract":"Objectives: This research introduces a novel area-preserving Generative Adversarial Networks (GAN) inversion technique for effectively de-identifying dental patient images. This innovative method addresses privacy concerns while preserving key dental features, thereby generating valuable resources for dental education and research.   Methods: We enhanced the existing GAN Inversion methodology to maximize the preservation of dental characteristics within the synthesized images. A comprehensive technical framework incorporating several deep learning models was developed to provide end-to-end development guidance and practical application for image de-identification.   Results: Our approach was assessed with varied facial pictures, extensively used for diagnosing skeletal asymmetry and facial anomalies. Results demonstrated our model's ability to adapt the context from one image to another, maintaining compatibility, while preserving dental features essential for oral diagnosis and dental education. A panel of five clinicians conducted an evaluation on a set of original and GAN-processed images. The generated images achieved effective de-identification, maintaining the realism of important dental features and were deemed useful for dental diagnostics and education.   Clinical Significance: Our GAN model and the encompassing framework can streamline the de-identification process of dental patient images, enhancing efficiency in dental education. This method improves students' diagnostic capabilities by offering more exposure to orthodontic malocclusions. Furthermore, it facilitates the creation of de-identified datasets for broader 2D image research at major research institutions.","sentences":["Objectives:","This research introduces a novel area-preserving Generative Adversarial Networks (GAN) inversion technique for effectively de-identifying dental patient images.","This innovative method addresses privacy concerns while preserving key dental features, thereby generating valuable resources for dental education and research.   ","Methods: We enhanced the existing GAN Inversion methodology to maximize the preservation of dental characteristics within the synthesized images.","A comprehensive technical framework incorporating several deep learning models was developed to provide end-to-end development guidance and practical application for image de-identification.   ","Results:","Our approach was assessed with varied facial pictures, extensively used for diagnosing skeletal asymmetry and facial anomalies.","Results demonstrated our model's ability to adapt the context from one image to another, maintaining compatibility, while preserving dental features essential for oral diagnosis and dental education.","A panel of five clinicians conducted an evaluation on a set of original and GAN-processed images.","The generated images achieved effective de-identification, maintaining the realism of important dental features and were deemed useful for dental diagnostics and education.   ","Clinical Significance: Our GAN model and the encompassing framework can streamline the de-identification process of dental patient images, enhancing efficiency in dental education.","This method improves students' diagnostic capabilities by offering more exposure to orthodontic malocclusions.","Furthermore, it facilitates the creation of de-identified datasets for broader 2D image research at major research institutions."],"url":"http://arxiv.org/abs/2307.02019v1"}
{"created":"2023-07-05 04:14:01","title":"Comparative Analysis of GPT-4 and Human Graders in Evaluating Praise Given to Students in Synthetic Dialogues","abstract":"Research suggests that providing specific and timely feedback to human tutors enhances their performance. However, it presents challenges due to the time-consuming nature of assessing tutor performance by human evaluators. Large language models, such as the AI-chatbot ChatGPT, hold potential for offering constructive feedback to tutors in practical settings. Nevertheless, the accuracy of AI-generated feedback remains uncertain, with scant research investigating the ability of models like ChatGPT to deliver effective feedback. In this work-in-progress, we evaluate 30 dialogues generated by GPT-4 in a tutor-student setting. We use two different prompting approaches, the zero-shot chain of thought and the few-shot chain of thought, to identify specific components of effective praise based on five criteria. These approaches are then compared to the results of human graders for accuracy. Our goal is to assess the extent to which GPT-4 can accurately identify each praise criterion. We found that both zero-shot and few-shot chain of thought approaches yield comparable results. GPT-4 performs moderately well in identifying instances when the tutor offers specific and immediate praise. However, GPT-4 underperforms in identifying the tutor's ability to deliver sincere praise, particularly in the zero-shot prompting scenario where examples of sincere tutor praise statements were not provided. Future work will focus on enhancing prompt engineering, developing a more general tutoring rubric, and evaluating our method using real-life tutoring dialogues.","sentences":["Research suggests that providing specific and timely feedback to human tutors enhances their performance.","However, it presents challenges due to the time-consuming nature of assessing tutor performance by human evaluators.","Large language models, such as the AI-chatbot ChatGPT, hold potential for offering constructive feedback to tutors in practical settings.","Nevertheless, the accuracy of AI-generated feedback remains uncertain, with scant research investigating the ability of models like ChatGPT to deliver effective feedback.","In this work-in-progress, we evaluate 30 dialogues generated by GPT-4 in a tutor-student setting.","We use two different prompting approaches, the zero-shot chain of thought and the few-shot chain of thought, to identify specific components of effective praise based on five criteria.","These approaches are then compared to the results of human graders for accuracy.","Our goal is to assess the extent to which GPT-4 can accurately identify each praise criterion.","We found that both zero-shot and few-shot chain of thought approaches yield comparable results.","GPT-4 performs moderately well in identifying instances when the tutor offers specific and immediate praise.","However, GPT-4 underperforms in identifying the tutor's ability to deliver sincere praise, particularly in the zero-shot prompting scenario where examples of sincere tutor praise statements were not provided.","Future work will focus on enhancing prompt engineering, developing a more general tutoring rubric, and evaluating our method using real-life tutoring dialogues."],"url":"http://arxiv.org/abs/2307.02018v1"}
{"created":"2023-07-05 03:53:58","title":"A Survey Report on Hardware Trojan Detection by Multiple-Parameter Side-Channel Analysis","abstract":"A major security threat to an integrated circuit (IC) design is the Hardware Trojan attack which is a malicious modification of the design. Previously several papers have investigated into side-channel analysis to detect the presence of Hardware Trojans. The side channel analysis were prescribed in these papers as an alternative to the conventional logic testing for detecting malicious modification in the design. It has been found that these conventional logic testing are ineffective when it comes to detecting small Trojans due to decrease in the sensitivity due to process variations encountered in the manufacturing techniques. The main paper under consideration in this survey report focuses on proposing a new technique to detect Trojans by using multiple-parameter side-channel analysis. The novel idea will be explained thoroughly in this survey report. We also look into several other papers, which talk about single parameter analysis and how they are implemented. We analyzed the short comings of those single parameter analysis techniques and we then show how this multi-parameter analysis technique is better. Finally we will talk about the combined side-channel analysis and logic testing approach in which there is higher detection coverage for hardware Trojan circuits of different types and sizes.","sentences":["A major security threat to an integrated circuit (IC) design is the Hardware Trojan attack which is a malicious modification of the design.","Previously several papers have investigated into side-channel analysis to detect the presence of Hardware Trojans.","The side channel analysis were prescribed in these papers as an alternative to the conventional logic testing for detecting malicious modification in the design.","It has been found that these conventional logic testing are ineffective when it comes to detecting small Trojans due to decrease in the sensitivity due to process variations encountered in the manufacturing techniques.","The main paper under consideration in this survey report focuses on proposing a new technique to detect Trojans by using multiple-parameter side-channel analysis.","The novel idea will be explained thoroughly in this survey report.","We also look into several other papers, which talk about single parameter analysis and how they are implemented.","We analyzed the short comings of those single parameter analysis techniques and we then show how this multi-parameter analysis technique is better.","Finally we will talk about the combined side-channel analysis and logic testing approach in which there is higher detection coverage for hardware Trojan circuits of different types and sizes."],"url":"http://arxiv.org/abs/2307.02012v1"}
{"created":"2023-07-05 03:43:15","title":"ZJU ReLER Submission for EPIC-KITCHEN Challenge 2023: Semi-Supervised Video Object Segmentation","abstract":"The Associating Objects with Transformers (AOT) framework has exhibited exceptional performance in a wide range of complex scenarios for video object segmentation. In this study, we introduce MSDeAOT, a variant of the AOT series that incorporates transformers at multiple feature scales. Leveraging the hierarchical Gated Propagation Module (GPM), MSDeAOT efficiently propagates object masks from previous frames to the current frame using a feature scale with a stride of 16. Additionally, we employ GPM in a more refined feature scale with a stride of 8, leading to improved accuracy in detecting and tracking small objects. Through the implementation of test-time augmentations and model ensemble techniques, we achieve the top-ranking position in the EPIC-KITCHEN VISOR Semi-supervised Video Object Segmentation Challenge.","sentences":["The Associating Objects with Transformers (AOT) framework has exhibited exceptional performance in a wide range of complex scenarios for video object segmentation.","In this study, we introduce MSDeAOT, a variant of the AOT series that incorporates transformers at multiple feature scales.","Leveraging the hierarchical Gated Propagation Module (GPM), MSDeAOT efficiently propagates object masks from previous frames to the current frame using a feature scale with a stride of 16.","Additionally, we employ GPM in a more refined feature scale with a stride of 8, leading to improved accuracy in detecting and tracking small objects.","Through the implementation of test-time augmentations and model ensemble techniques, we achieve the top-ranking position in the EPIC-KITCHEN VISOR Semi-supervised Video Object Segmentation Challenge."],"url":"http://arxiv.org/abs/2307.02010v1"}
{"created":"2023-07-05 03:39:40","title":"Using Data Augmentations and VTLN to Reduce Bias in Dutch End-to-End Speech Recognition Systems","abstract":"Speech technology has improved greatly for norm speakers, i.e., adult native speakers of a language without speech impediments or strong accents. However, non-norm or diverse speaker groups show a distinct performance gap with norm speakers, which we refer to as bias. In this work, we aim to reduce bias against different age groups and non-native speakers of Dutch. For an end-to-end (E2E) ASR system, we use state-of-the-art speed perturbation and spectral augmentation as data augmentation techniques and explore Vocal Tract Length Normalization (VTLN) to normalise for spectral differences due to differences in anatomy. The combination of data augmentation and VTLN reduced the average WER and bias across various diverse speaker groups by 6.9% and 3.9%, respectively. The VTLN model trained on Dutch was also effective in improving performance of Mandarin Chinese child speech, thus, showing generalisability across languages","sentences":["Speech technology has improved greatly for norm speakers, i.e., adult native speakers of a language without speech impediments or strong accents.","However, non-norm or diverse speaker groups show a distinct performance gap with norm speakers, which we refer to as bias.","In this work, we aim to reduce bias against different age groups and non-native speakers of Dutch.","For an end-to-end (E2E) ASR system, we use state-of-the-art speed perturbation and spectral augmentation as data augmentation techniques and explore Vocal Tract Length Normalization (VTLN) to normalise for spectral differences due to differences in anatomy.","The combination of data augmentation and VTLN reduced the average WER and bias across various diverse speaker groups by 6.9% and 3.9%, respectively.","The VTLN model trained on Dutch was also effective in improving performance of Mandarin Chinese child speech, thus, showing generalisability across languages"],"url":"http://arxiv.org/abs/2307.02009v1"}
{"created":"2023-07-05 03:32:49","title":"Remote Sensing Image Change Detection with Graph Interaction","abstract":"Modern remote sensing image change detection has witnessed substantial advancements by harnessing the potent feature extraction capabilities of CNNs and Transforms.Yet,prevailing change detection techniques consistently prioritize extracting semantic features related to significant alterations,overlooking the viability of directly interacting with bitemporal image features.In this letter,we propose a bitemporal image graph Interaction network for remote sensing change detection,namely BGINet-CD. More specifically,by leveraging the concept of non-local operations and mapping the features obtained from the backbone network to the graph structure space,we propose a unified self-focus mechanism for bitemporal images.This approach enhances the information coupling between the two temporal images while effectively suppressing task-irrelevant interference,Based on a streamlined backbone architecture,namely ResNet18,our model demonstrates superior performance compared to other state-of-the-art methods (SOTA) on the GZ CD dataset. Moreover,the model exhibits an enhanced trade-off between accuracy and computational efficiency,further improving its overall effectiveness","sentences":["Modern remote sensing image change detection has witnessed substantial advancements by harnessing the potent feature extraction capabilities of CNNs and Transforms.","Yet,prevailing change detection techniques consistently prioritize extracting semantic features related to significant alterations,overlooking the viability of directly interacting with bitemporal image features.","In this letter,we propose a bitemporal image graph Interaction network for remote sensing change detection,namely BGINet-CD.","More specifically,by leveraging the concept of non-local operations and mapping the features obtained from the backbone network to the graph structure space,we propose a unified self-focus mechanism for bitemporal images.","This approach enhances the information coupling between the two temporal images while effectively suppressing task-irrelevant interference,Based on a streamlined backbone architecture,namely ResNet18,our model demonstrates superior performance compared to other state-of-the-art methods (SOTA) on the GZ CD dataset.","Moreover,the model exhibits an enhanced trade-off between accuracy and computational efficiency,further improving its overall effectiveness"],"url":"http://arxiv.org/abs/2307.02007v1"}
{"created":"2023-07-05 03:31:12","title":"PULSAR at MEDIQA-Sum 2023: Large Language Models Augmented by Synthetic Dialogue Convert Patient Dialogues to Medical Records","abstract":"This paper describes PULSAR, our system submission at the ImageClef 2023 MediQA-Sum task on summarising patient-doctor dialogues into clinical records. The proposed framework relies on domain-specific pre-training, to produce a specialised language model which is trained on task-specific natural data augmented by synthetic data generated by a black-box LLM. We find limited evidence towards the efficacy of domain-specific pre-training and data augmentation, while scaling up the language model yields the best performance gains. Our approach was ranked second and third among 13 submissions on task B of the challenge. Our code is available at https://github.com/yuping-wu/PULSAR.","sentences":["This paper describes PULSAR, our system submission at the ImageClef 2023 MediQA-Sum task on summarising patient-doctor dialogues into clinical records.","The proposed framework relies on domain-specific pre-training, to produce a specialised language model which is trained on task-specific natural data augmented by synthetic data generated by a black-box LLM.","We find limited evidence towards the efficacy of domain-specific pre-training and data augmentation, while scaling up the language model yields the best performance gains.","Our approach was ranked second and third among 13 submissions on task B of the challenge.","Our code is available at https://github.com/yuping-wu/PULSAR."],"url":"http://arxiv.org/abs/2307.02006v1"}
{"created":"2023-07-05 03:27:31","title":"Multi-Modal Prototypes for Open-Set Semantic Segmentation","abstract":"In semantic segmentation, adapting a visual system to novel object categories at inference time has always been both valuable and challenging. To enable such generalization, existing methods rely on either providing several support examples as visual cues or class names as textual cues. Through the development is relatively optimistic, these two lines have been studied in isolation, neglecting the complementary intrinsic of low-level visual and high-level language information. In this paper, we define a unified setting termed as open-set semantic segmentation (O3S), which aims to learn seen and unseen semantics from both visual examples and textual names. Our pipeline extracts multi-modal prototypes for segmentation task, by first single modal self-enhancement and aggregation, then multi-modal complementary fusion. To be specific, we aggregate visual features into several tokens as visual prototypes, and enhance the class name with detailed descriptions for textual prototype generation. The two modalities are then fused to generate multi-modal prototypes for final segmentation. On both \\pascal and \\coco datasets, we conduct extensive experiments to evaluate the framework effectiveness. State-of-the-art results are achieved even on more detailed part-segmentation, Pascal-Animals, by only training on coarse-grained datasets. Thorough ablation studies are performed to dissect each component, both quantitatively and qualitatively.","sentences":["In semantic segmentation, adapting a visual system to novel object categories at inference time has always been both valuable and challenging.","To enable such generalization, existing methods rely on either providing several support examples as visual cues or class names as textual cues.","Through the development is relatively optimistic, these two lines have been studied in isolation, neglecting the complementary intrinsic of low-level visual and high-level language information.","In this paper, we define a unified setting termed as open-set semantic segmentation (O3S), which aims to learn seen and unseen semantics from both visual examples and textual names.","Our pipeline extracts multi-modal prototypes for segmentation task, by first single modal self-enhancement and aggregation, then multi-modal complementary fusion.","To be specific, we aggregate visual features into several tokens as visual prototypes, and enhance the class name with detailed descriptions for textual prototype generation.","The two modalities are then fused to generate multi-modal prototypes for final segmentation.","On both \\pascal and \\coco datasets, we conduct extensive experiments to evaluate the framework effectiveness.","State-of-the-art results are achieved even on more detailed part-segmentation, Pascal-Animals, by only training on coarse-grained datasets.","Thorough ablation studies are performed to dissect each component, both quantitatively and qualitatively."],"url":"http://arxiv.org/abs/2307.02003v1"}
{"created":"2023-07-05 03:07:00","title":"Zero-Shot Neural Architecture Search: Challenges, Solutions, and Opportunities","abstract":"Recently, zero-shot (or training-free) Neural Architecture Search (NAS) approaches have been proposed to liberate the NAS from training requirements. The key idea behind zero-shot NAS approaches is to design proxies that predict the accuracies of the given networks without training network parameters. The proxies proposed so far are usually inspired by recent progress in theoretical deep learning and have shown great potential on several NAS benchmark datasets. This paper aims to comprehensively review and compare the state-of-the-art (SOTA) zero-shot NAS approaches, with an emphasis on their hardware awareness. To this end, we first review the mainstream zero-shot proxies and discuss their theoretical underpinnings. We then compare these zero-shot proxies through large-scale experiments and demonstrate their effectiveness in both hardware-aware and hardware-oblivious NAS scenarios. Finally, we point out several promising ideas to design better proxies. Our source code and the related paper list are available on https://github.com/SLDGroup/survey-zero-shot-nas.","sentences":["Recently, zero-shot (or training-free) Neural Architecture Search (NAS) approaches have been proposed to liberate the NAS from training requirements.","The key idea behind zero-shot NAS approaches is to design proxies that predict the accuracies of the given networks without training network parameters.","The proxies proposed so far are usually inspired by recent progress in theoretical deep learning and have shown great potential on several NAS benchmark datasets.","This paper aims to comprehensively review and compare the state-of-the-art (SOTA) zero-shot NAS approaches, with an emphasis on their hardware awareness.","To this end, we first review the mainstream zero-shot proxies and discuss their theoretical underpinnings.","We then compare these zero-shot proxies through large-scale experiments and demonstrate their effectiveness in both hardware-aware and hardware-oblivious NAS scenarios.","Finally, we point out several promising ideas to design better proxies.","Our source code and the related paper list are available on https://github.com/SLDGroup/survey-zero-shot-nas."],"url":"http://arxiv.org/abs/2307.01998v1"}
{"created":"2023-07-05 02:56:29","title":"Dynamic Feature-based Deep Reinforcement Learning for Flow Control of Circular Cylinder with Sparse Surface Pressure Sensing","abstract":"This study proposes a self-learning algorithm for closed-loop cylinder wake control targeting lower drag and lower lift fluctuations with the additional challenge of sparse sensor information, taking deep reinforcement learning as the starting point. DRL performance is significantly improved by lifting the sensor signals to dynamic features (DF), which predict future flow states. The resulting dynamic feature-based DRL (DF-DRL) automatically learns a feedback control in the plant without a dynamic model. Results show that the drag coefficient of the DF-DRL model is 25% less than the vanilla model based on direct sensor feedback. More importantly, using only one surface pressure sensor, DF-DRL can reduce the drag coefficient to a state-of-the-art performance of about 8% at Re = 100 and significantly mitigate lift coefficient fluctuations. Hence, DF-DRL allows the deployment of sparse sensing of the flow without degrading the control performance. This method also shows good robustness in controlling flow under higher Reynolds numbers, which reduces the drag coefficient by 32.2% and 46.55% at Re = 500 and 1000, respectively, indicating the broad applicability of the method. Since surface pressure information is more straightforward to measure in realistic scenarios than flow velocity information, this study provides a valuable reference for experimentally designing the active flow control of a circular cylinder based on wall pressure signals, which is an essential step toward further developing intelligent control in realistic multi-input multi-output (MIMO) system.","sentences":["This study proposes a self-learning algorithm for closed-loop cylinder wake control targeting lower drag and lower lift fluctuations with the additional challenge of sparse sensor information, taking deep reinforcement learning as the starting point.","DRL performance is significantly improved by lifting the sensor signals to dynamic features (DF), which predict future flow states.","The resulting dynamic feature-based DRL (DF-DRL) automatically learns a feedback control in the plant without a dynamic model.","Results show that the drag coefficient of the DF-DRL model is 25% less than the vanilla model based on direct sensor feedback.","More importantly, using only one surface pressure sensor, DF-DRL can reduce the drag coefficient to a state-of-the-art performance of about 8% at Re = 100 and significantly mitigate lift coefficient fluctuations.","Hence, DF-DRL allows the deployment of sparse sensing of the flow without degrading the control performance.","This method also shows good robustness in controlling flow under higher Reynolds numbers, which reduces the drag coefficient by 32.2% and 46.55% at Re = 500 and 1000, respectively, indicating the broad applicability of the method.","Since surface pressure information is more straightforward to measure in realistic scenarios than flow velocity information, this study provides a valuable reference for experimentally designing the active flow control of a circular cylinder based on wall pressure signals, which is an essential step toward further developing intelligent control in realistic multi-input multi-output (MIMO) system."],"url":"http://arxiv.org/abs/2307.01995v1"}
{"created":"2023-07-05 02:53:19","title":"Performance Analysis of RIS-Aided Space Shift Keying With Channel Estimation Errors","abstract":"In this paper, we investigate the reconfigurable intelligent surface (RIS) assisted space shift keying (SSK) downlink communication systems under the imperfect channel state information (CSI), where the channel between the base station to RIS follows the Rayleigh fading, while the channel between the RIS to user equipment obeys the Rician fading. Based on the maximum likelihood detector, the conditional pairwise error probability of the composite channel is derived. Then, the probability density function for a non-central chi-square distribution with one degree of freedom is derived. Based on this, the closed-form analytical expression of the RIS-SSK scheme with imperfect CSI is derived. To gain more valuable insights, the asymptotic ABEP expression is also given. Finally, we validate the derived closed-form and asymptotic expressions by Monte Carlo simulations.","sentences":["In this paper, we investigate the reconfigurable intelligent surface (RIS) assisted space shift keying (SSK) downlink communication systems under the imperfect channel state information (CSI), where the channel between the base station to RIS follows the Rayleigh fading, while the channel between the RIS to user equipment obeys the Rician fading.","Based on the maximum likelihood detector, the conditional pairwise error probability of the composite channel is derived.","Then, the probability density function for a non-central chi-square distribution with one degree of freedom is derived.","Based on this, the closed-form analytical expression of the RIS-SSK scheme with imperfect CSI is derived.","To gain more valuable insights, the asymptotic ABEP expression is also given.","Finally, we validate the derived closed-form and asymptotic expressions by Monte Carlo simulations."],"url":"http://arxiv.org/abs/2307.01994v1"}
{"created":"2023-07-05 02:13:25","title":"Task-Specific Alignment and Multiple Level Transformer for Few-Shot Action Recognition","abstract":"In the research field of few-shot learning, the main difference between image-based and video-based is the additional temporal dimension for videos. In recent years, many approaches for few-shot action recognition have followed the metric-based methods, especially, since some works use the Transformer to get the cross-attention feature of the videos or the enhanced prototype, and the results are competitive. However, they do not mine enough information from the Transformer because they only focus on the feature of a single level. In our paper, we have addressed this problem. We propose an end-to-end method named \"Task-Specific Alignment and Multiple Level Transformer Network (TSA-MLT)\". In our model, the Multiple Level Transformer focuses on the multiple-level feature of the support video and query video. Especially before Multiple Level Transformer, we use task-specific TSA to filter unimportant or misleading frames as a pre-processing. Furthermore, we adopt a fusion loss using two kinds of distance, the first is L2 sequence distance, which focuses on temporal order alignment. The second one is Optimal transport distance, which focuses on measuring the gap between the appearance and semantics of the videos. Using a simple fusion network, we fuse the two distances element-wise, then use the cross-entropy loss as our fusion loss. Extensive experiments show our method achieves state-of-the-art results on the HMDB51 and UCF101 datasets and a competitive result on the benchmark of Kinetics and something-2-something V2 datasets. Our code will be available at the URL: https://github.com/cofly2014/tsa-mlt.git","sentences":["In the research field of few-shot learning, the main difference between image-based and video-based is the additional temporal dimension for videos.","In recent years, many approaches for few-shot action recognition have followed the metric-based methods, especially, since some works use the Transformer to get the cross-attention feature of the videos or the enhanced prototype, and the results are competitive.","However, they do not mine enough information from the Transformer because they only focus on the feature of a single level.","In our paper, we have addressed this problem.","We propose an end-to-end method named \"Task-Specific Alignment and Multiple Level Transformer Network (TSA-MLT)\".","In our model, the Multiple Level Transformer focuses on the multiple-level feature of the support video and query video.","Especially before Multiple Level Transformer, we use task-specific TSA to filter unimportant or misleading frames as a pre-processing.","Furthermore, we adopt a fusion loss using two kinds of distance, the first is L2 sequence distance, which focuses on temporal order alignment.","The second one is Optimal transport distance, which focuses on measuring the gap between the appearance and semantics of the videos.","Using a simple fusion network, we fuse the two distances element-wise, then use the cross-entropy loss as our fusion loss.","Extensive experiments show our method achieves state-of-the-art results on the HMDB51 and UCF101 datasets and a competitive result on the benchmark of Kinetics and something-2-something V2 datasets.","Our code will be available at the URL: https://github.com/cofly2014/tsa-mlt.git"],"url":"http://arxiv.org/abs/2307.01985v1"}
{"created":"2023-07-05 02:00:14","title":"The KiTS21 Challenge: Automatic segmentation of kidneys, renal tumors, and renal cysts in corticomedullary-phase CT","abstract":"This paper presents the challenge report for the 2021 Kidney and Kidney Tumor Segmentation Challenge (KiTS21) held in conjunction with the 2021 international conference on Medical Image Computing and Computer Assisted Interventions (MICCAI). KiTS21 is a sequel to its first edition in 2019, and it features a variety of innovations in how the challenge was designed, in addition to a larger dataset. A novel annotation method was used to collect three separate annotations for each region of interest, and these annotations were performed in a fully transparent setting using a web-based annotation tool. Further, the KiTS21 test set was collected from an outside institution, challenging participants to develop methods that generalize well to new populations. Nonetheless, the top-performing teams achieved a significant improvement over the state of the art set in 2019, and this performance is shown to inch ever closer to human-level performance. An in-depth meta-analysis is presented describing which methods were used and how they faired on the leaderboard, as well as the characteristics of which cases generally saw good performance, and which did not. Overall KiTS21 facilitated a significant advancement in the state of the art in kidney tumor segmentation, and provides useful insights that are applicable to the field of semantic segmentation as a whole.","sentences":["This paper presents the challenge report for the 2021 Kidney and Kidney Tumor Segmentation Challenge (KiTS21) held in conjunction with the 2021 international conference on Medical Image Computing and Computer Assisted Interventions (MICCAI).","KiTS21 is a sequel to its first edition in 2019, and it features a variety of innovations in how the challenge was designed, in addition to a larger dataset.","A novel annotation method was used to collect three separate annotations for each region of interest, and these annotations were performed in a fully transparent setting using a web-based annotation tool.","Further, the KiTS21 test set was collected from an outside institution, challenging participants to develop methods that generalize well to new populations.","Nonetheless, the top-performing teams achieved a significant improvement over the state of the art set in 2019, and this performance is shown to inch ever closer to human-level performance.","An in-depth meta-analysis is presented describing which methods were used and how they faired on the leaderboard, as well as the characteristics of which cases generally saw good performance, and which did not.","Overall KiTS21 facilitated a significant advancement in the state of the art in kidney tumor segmentation, and provides useful insights that are applicable to the field of semantic segmentation as a whole."],"url":"http://arxiv.org/abs/2307.01984v1"}
{"created":"2023-07-05 01:55:50","title":"An Envy-Free Online UAV Charging Scheme with Vehicle-Mounted Mobile Wireless Chargers","abstract":"In commercial unmanned aerial vehicle (UAV) applications, one of the main restrictions is UAVs' limited battery endurance when executing persistent tasks. With the mature of wireless power transfer (WPT) technologies, by leveraging ground vehicles mounted with WPT facilities on their proofs, we propose a mobile and collaborative recharging scheme for UAVs in an on-demand manner. Specifically, we first present a novel air-ground cooperative UAV recharging framework, where ground vehicles cooperatively share their idle wireless chargers to UAVs and a swarm of UAVs in the task area compete to get recharging services. Considering the mobility dynamics and energy competitions, we formulate an energy scheduling problem for UAVs and vehicles under practical constraints. A fair online auction-based solution with low complexity is also devised to allocate and price idle wireless chargers on vehicular proofs in real time. We rigorously prove that the proposed scheme is strategy-proof, envy-free, and produces stable allocation outcomes. The first property enforces that truthful bidding is the dominant strategy for participants, the second ensures that no user is better off by exchanging his allocation with another user when the auction ends, while the third guarantees the matching stability between UAVs and UGVs. Extensive simulations validate that the proposed scheme outperforms benchmarks in terms of energy allocation efficiency and UAV's utility.","sentences":["In commercial unmanned aerial vehicle (UAV) applications, one of the main restrictions is UAVs' limited battery endurance when executing persistent tasks.","With the mature of wireless power transfer (WPT) technologies, by leveraging ground vehicles mounted with WPT facilities on their proofs, we propose a mobile and collaborative recharging scheme for UAVs in an on-demand manner.","Specifically, we first present a novel air-ground cooperative UAV recharging framework, where ground vehicles cooperatively share their idle wireless chargers to UAVs and a swarm of UAVs in the task area compete to get recharging services.","Considering the mobility dynamics and energy competitions, we formulate an energy scheduling problem for UAVs and vehicles under practical constraints.","A fair online auction-based solution with low complexity is also devised to allocate and price idle wireless chargers on vehicular proofs in real time.","We rigorously prove that the proposed scheme is strategy-proof, envy-free, and produces stable allocation outcomes.","The first property enforces that truthful bidding is the dominant strategy for participants, the second ensures that no user is better off by exchanging his allocation with another user when the auction ends, while the third guarantees the matching stability between UAVs and UGVs.","Extensive simulations validate that the proposed scheme outperforms benchmarks in terms of energy allocation efficiency and UAV's utility."],"url":"http://arxiv.org/abs/2307.01982v1"}
{"created":"2023-07-05 01:00:44","title":"Open-Domain Hierarchical Event Schema Induction by Incremental Prompting and Verification","abstract":"Event schemas are a form of world knowledge about the typical progression of events. Recent methods for event schema induction use information extraction systems to construct a large number of event graph instances from documents, and then learn to generalize the schema from such instances. In contrast, we propose to treat event schemas as a form of commonsense knowledge that can be derived from large language models (LLMs). This new paradigm greatly simplifies the schema induction process and allows us to handle both hierarchical relations and temporal relations between events in a straightforward way. Since event schemas have complex graph structures, we design an incremental prompting and verification method to break down the construction of a complex event graph into three stages: event skeleton construction, event expansion, and event-event relation verification. Compared to directly using LLMs to generate a linearized graph, our method can generate large and complex schemas with 7.2% F1 improvement in temporal relations and 31.0% F1 improvement in hierarchical relations. In addition, compared to the previous state-of-the-art closed-domain schema induction model, human assessors were able to cover $\\sim$10% more events when translating the schemas into coherent stories and rated our schemas 1.3 points higher (on a 5-point scale) in terms of readability.","sentences":["Event schemas are a form of world knowledge about the typical progression of events.","Recent methods for event schema induction use information extraction systems to construct a large number of event graph instances from documents, and then learn to generalize the schema from such instances.","In contrast, we propose to treat event schemas as a form of commonsense knowledge that can be derived from large language models (LLMs).","This new paradigm greatly simplifies the schema induction process and allows us to handle both hierarchical relations and temporal relations between events in a straightforward way.","Since event schemas have complex graph structures, we design an incremental prompting and verification method to break down the construction of a complex event graph into three stages: event skeleton construction, event expansion, and event-event relation verification.","Compared to directly using LLMs to generate a linearized graph, our method can generate large and complex schemas with 7.2% F1 improvement in temporal relations and 31.0% F1 improvement in hierarchical relations.","In addition, compared to the previous state-of-the-art closed-domain schema induction model, human assessors were able to cover $\\sim$10% more events when translating the schemas into coherent stories and rated our schemas 1.3 points higher (on a 5-point scale) in terms of readability."],"url":"http://arxiv.org/abs/2307.01972v1"}
{"created":"2023-07-05 00:44:00","title":"Understanding Resolution of Multi-Language Bugs: An Empirical Study on Apache Projects","abstract":"Background: In modern software systems, more and more systems are written in multiple programming languages (PLs). There is no comprehensive investigation on the phenomenon of multi-programming-language (MPL) bugs, which resolution involves source files written in multiple PLs. Aim: This work investigated the characteristics of bug resolution in MPL software systems and explored the reasons why bug resolution involves multiple PLs. Method: We conducted an empirical study on 54 MPL projects selected from 655 Apache OSS projects, of which 66,932 bugs were analyzed. Results: (1) the percentage of MPL bugs (MPLBs) in the selected projects ranges from 0.17% to 42.26%, and the percentage of MPLBs for all projects as a whole is 10.01%; (2) 95.0% and 4.5% of all the MPLBs involve source files written in 2 and 3 PLs, respectively; (3) the change complexity resolution characteristics of MPLBs tend to be higher than those of single-programming-language bugs (SPLBs); (4) the open time for MPLBs is 19.52% to 529.57% significantly longer than SPLBs regarding 9 PL combinations; (5) the reopen rate of bugs involving the PL combination of JavaScript and Python reaches 20.66%; (6) we found 6 causes why the bug resolution involves multiple PLs and identified 5 cross-language calling mechanisms. Conclusion: MPLBs are related to increased development difficulty.","sentences":["Background: In modern software systems, more and more systems are written in multiple programming languages (PLs).","There is no comprehensive investigation on the phenomenon of multi-programming-language (MPL) bugs, which resolution involves source files written in multiple PLs.","Aim: This work investigated the characteristics of bug resolution in MPL software systems and explored the reasons why bug resolution involves multiple PLs.","Method: We conducted an empirical study on 54 MPL projects selected from 655 Apache OSS projects, of which 66,932 bugs were analyzed.","Results: (1) the percentage of MPL bugs (MPLBs) in the selected projects ranges from 0.17% to 42.26%, and the percentage of MPLBs for all projects as a whole is 10.01%; (2) 95.0% and 4.5% of all the MPLBs involve source files written in 2 and 3 PLs, respectively; (3) the change complexity resolution characteristics of MPLBs tend to be higher than those of single-programming-language bugs (SPLBs); (4) the open time for MPLBs is 19.52% to 529.57% significantly longer than SPLBs regarding 9 PL combinations; (5) the reopen rate of bugs involving the PL combination of JavaScript and Python reaches 20.66%; (6) we found 6 causes why the bug resolution involves multiple PLs and identified 5 cross-language calling mechanisms.","Conclusion: MPLBs are related to increased development difficulty."],"url":"http://arxiv.org/abs/2307.01970v1"}
{"created":"2023-07-05 00:40:40","title":"Multimodal Prompt Learning for Product Title Generation with Extremely Limited Labels","abstract":"Generating an informative and attractive title for the product is a crucial task for e-commerce. Most existing works follow the standard multimodal natural language generation approaches, e.g., image captioning, and employ the large scale of human-labelled datasets to train desirable models. However, for novel products, especially in a different domain, there are few existing labelled data. In this paper, we propose a prompt-based approach, i.e., the Multimodal Prompt Learning framework, to accurately and efficiently generate titles for novel products with limited labels. We observe that the core challenges of novel product title generation are the understanding of novel product characteristics and the generation of titles in a novel writing style. To this end, we build a set of multimodal prompts from different modalities to preserve the corresponding characteristics and writing styles of novel products. As a result, with extremely limited labels for training, the proposed method can retrieve the multimodal prompts to generate desirable titles for novel products. The experiments and analyses are conducted on five novel product categories under both the in-domain and out-of-domain experimental settings. The results show that, with only 1% of downstream labelled data for training, our proposed approach achieves the best few-shot results and even achieves competitive results with fully-supervised methods trained on 100% of training data; With the full labelled data for training, our method achieves state-of-the-art results.","sentences":["Generating an informative and attractive title for the product is a crucial task for e-commerce.","Most existing works follow the standard multimodal natural language generation approaches, e.g., image captioning, and employ the large scale of human-labelled datasets to train desirable models.","However, for novel products, especially in a different domain, there are few existing labelled data.","In this paper, we propose a prompt-based approach, i.e., the Multimodal Prompt Learning framework, to accurately and efficiently generate titles for novel products with limited labels.","We observe that the core challenges of novel product title generation are the understanding of novel product characteristics and the generation of titles in a novel writing style.","To this end, we build a set of multimodal prompts from different modalities to preserve the corresponding characteristics and writing styles of novel products.","As a result, with extremely limited labels for training, the proposed method can retrieve the multimodal prompts to generate desirable titles for novel products.","The experiments and analyses are conducted on five novel product categories under both the in-domain and out-of-domain experimental settings.","The results show that, with only 1% of downstream labelled data for training, our proposed approach achieves the best few-shot results and even achieves competitive results with fully-supervised methods trained on 100% of training data; With the full labelled data for training, our method achieves state-of-the-art results."],"url":"http://arxiv.org/abs/2307.01969v1"}
{"created":"2023-07-05 00:40:19","title":"Muti-scale Graph Neural Network with Signed-attention for Social Bot Detection: A Frequency Perspective","abstract":"The presence of a large number of bots on social media has adverse effects. The graph neural network (GNN) can effectively leverage the social relationships between users and achieve excellent results in detecting bots. Recently, more and more GNN-based methods have been proposed for bot detection. However, the existing GNN-based bot detection methods only focus on low-frequency information and seldom consider high-frequency information, which limits the representation ability of the model. To address this issue, this paper proposes a Multi-scale with Signed-attention Graph Filter for social bot detection called MSGS. MSGS could effectively utilize both high and low-frequency information in the social graph. Specifically, MSGS utilizes a multi-scale structure to produce representation vectors at different scales. These representations are then combined using a signed-attention mechanism. Finally, multi-scale representations via MLP after polymerization to produce the final result. We analyze the frequency response and demonstrate that MSGS is a more flexible and expressive adaptive graph filter. MSGS can effectively utilize high-frequency information to alleviate the over-smoothing problem of deep GNNs. Experimental results on real-world datasets demonstrate that our method achieves better performance compared with several state-of-the-art social bot detection methods.","sentences":["The presence of a large number of bots on social media has adverse effects.","The graph neural network (GNN) can effectively leverage the social relationships between users and achieve excellent results in detecting bots.","Recently, more and more GNN-based methods have been proposed for bot detection.","However, the existing GNN-based bot detection methods only focus on low-frequency information and seldom consider high-frequency information, which limits the representation ability of the model.","To address this issue, this paper proposes a Multi-scale with Signed-attention Graph Filter for social bot detection called MSGS.","MSGS could effectively utilize both high and low-frequency information in the social graph.","Specifically, MSGS utilizes a multi-scale structure to produce representation vectors at different scales.","These representations are then combined using a signed-attention mechanism.","Finally, multi-scale representations via MLP after polymerization to produce the final result.","We analyze the frequency response and demonstrate that MSGS is a more flexible and expressive adaptive graph filter.","MSGS can effectively utilize high-frequency information to alleviate the over-smoothing problem of deep GNNs.","Experimental results on real-world datasets demonstrate that our method achieves better performance compared with several state-of-the-art social bot detection methods."],"url":"http://arxiv.org/abs/2307.01968v1"}
{"created":"2023-07-05 00:38:16","title":"Linear-time computation of generalized minimal absent words for multiple strings","abstract":"A string $w$ is called a minimal absent word (MAW) for a string $S$ if $w$ does not occur as a substring in $S$ and all proper substrings of $w$ occur in $S$. MAWs are well-studied combinatorial string objects that have potential applications in areas including bioinformatics, musicology, and data compression. In this paper, we generalize the notion of MAWs to a set $\\mathcal{S} = \\{S_1, \\ldots, S_k\\}$ of multiple strings. We first describe our solution to the case of $k = 2$ strings, and show how to compute the set $\\mathsf{M}$ of MAWs in optimal $O(n + |\\mathsf{M}|)$ time and with $O(n)$ working space, where $n$ denotes the total length of the strings in $\\mathcal{S}$. We then move on to the general case of $k > 2$ strings, and show how to compute the set $\\mathsf{M}$ of MAWs in $O(n \\lceil k / \\log n \\rceil + |\\mathsf{M}|)$ time and with $O(n (k + \\log n))$ bits of working space, in the word RAM model with machine word size $\\omega = \\log n$. The latter algorithm runs in optimal $O(n + |\\mathsf{M}|)$ time for $k = O(\\log n)$.","sentences":["A string $w$ is called a minimal absent word (MAW) for a string $S$ if $w$ does not occur as a substring in $S$ and all proper substrings of $w$ occur in $S$. MAWs are well-studied combinatorial string objects that have potential applications in areas including bioinformatics, musicology, and data compression.","In this paper, we generalize the notion of MAWs to a set $\\mathcal{S} = \\{S_1, \\ldots, S_k\\}$ of multiple strings.","We first describe our solution to the case of $k = 2$ strings, and show how to compute the set $\\mathsf{M}$ of MAWs in optimal $O(n + |\\mathsf{M}|)$ time and with $O(n)$ working space, where $n$ denotes the total length of the strings in $\\mathcal{S}$. We then move on to the general case of $k > 2$ strings, and show how to compute the set $\\mathsf{M}$ of MAWs in $O(n \\lceil k / \\log n \\rceil + |\\mathsf{M}|)$ time and with $O(n (k + \\log n))$ bits of working space, in the word RAM model with machine word size $\\omega = \\log n$. The latter algorithm runs in optimal $O(n + |\\mathsf{M}|)$ time for $k = O(\\log n)$."],"url":"http://arxiv.org/abs/2307.01967v1"}
