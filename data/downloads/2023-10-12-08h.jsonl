{"created":"2023-10-11 17:59:56","title":"PAD: A Dataset and Benchmark for Pose-agnostic Anomaly Detection","abstract":"Object anomaly detection is an important problem in the field of machine vision and has seen remarkable progress recently. However, two significant challenges hinder its research and application. First, existing datasets lack comprehensive visual information from various pose angles. They usually have an unrealistic assumption that the anomaly-free training dataset is pose-aligned, and the testing samples have the same pose as the training data. However, in practice, anomaly may exist in any regions on a object, the training and query samples may have different poses, calling for the study on pose-agnostic anomaly detection. Second, the absence of a consensus on experimental protocols for pose-agnostic anomaly detection leads to unfair comparisons of different methods, hindering the research on pose-agnostic anomaly detection. To address these issues, we develop Multi-pose Anomaly Detection (MAD) dataset and Pose-agnostic Anomaly Detection (PAD) benchmark, which takes the first step to address the pose-agnostic anomaly detection problem. Specifically, we build MAD using 20 complex-shaped LEGO toys including 4K views with various poses, and high-quality and diverse 3D anomalies in both simulated and real environments. Additionally, we propose a novel method OmniposeAD, trained using MAD, specifically designed for pose-agnostic anomaly detection. Through comprehensive evaluations, we demonstrate the relevance of our dataset and method. Furthermore, we provide an open-source benchmark library, including dataset and baseline methods that cover 8 anomaly detection paradigms, to facilitate future research and application in this domain. Code, data, and models are publicly available at https://github.com/EricLee0224/PAD.","sentences":["Object anomaly detection is an important problem in the field of machine vision and has seen remarkable progress recently.","However, two significant challenges hinder its research and application.","First, existing datasets lack comprehensive visual information from various pose angles.","They usually have an unrealistic assumption that the anomaly-free training dataset is pose-aligned, and the testing samples have the same pose as the training data.","However, in practice, anomaly may exist in any regions on a object, the training and query samples may have different poses, calling for the study on pose-agnostic anomaly detection.","Second, the absence of a consensus on experimental protocols for pose-agnostic anomaly detection leads to unfair comparisons of different methods, hindering the research on pose-agnostic anomaly detection.","To address these issues, we develop Multi-pose Anomaly Detection (MAD) dataset and Pose-agnostic Anomaly Detection (PAD) benchmark, which takes the first step to address the pose-agnostic anomaly detection problem.","Specifically, we build MAD using 20 complex-shaped LEGO toys including 4K views with various poses, and high-quality and diverse 3D anomalies in both simulated and real environments.","Additionally, we propose a novel method OmniposeAD, trained using MAD, specifically designed for pose-agnostic anomaly detection.","Through comprehensive evaluations, we demonstrate the relevance of our dataset and method.","Furthermore, we provide an open-source benchmark library, including dataset and baseline methods that cover 8 anomaly detection paradigms, to facilitate future research and application in this domain.","Code, data, and models are publicly available at https://github.com/EricLee0224/PAD."],"url":"http://arxiv.org/abs/2310.07716v1"}
{"created":"2023-10-11 17:59:36","title":"To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing","abstract":"NLP is in a period of disruptive change that is impacting our methodologies, funding sources, and public perception. In this work, we seek to understand how to shape our future by better understanding our past. We study factors that shape NLP as a field, including culture, incentives, and infrastructure by conducting long-form interviews with 26 NLP researchers of varying seniority, research area, institution, and social identity. Our interviewees identify cyclical patterns in the field, as well as new shifts without historical parallel, including changes in benchmark culture and software infrastructure. We complement this discussion with quantitative analysis of citation, authorship, and language use in the ACL Anthology over time. We conclude by discussing shared visions, concerns, and hopes for the future of NLP. We hope that this study of our field's past and present can prompt informed discussion of our community's implicit norms and more deliberate action to consciously shape the future.","sentences":["NLP is in a period of disruptive change that is impacting our methodologies, funding sources, and public perception.","In this work, we seek to understand how to shape our future by better understanding our past.","We study factors that shape NLP as a field, including culture, incentives, and infrastructure by conducting long-form interviews with 26 NLP researchers of varying seniority, research area, institution, and social identity.","Our interviewees identify cyclical patterns in the field, as well as new shifts without historical parallel, including changes in benchmark culture and software infrastructure.","We complement this discussion with quantitative analysis of citation, authorship, and language use in the ACL Anthology over time.","We conclude by discussing shared visions, concerns, and hopes for the future of NLP.","We hope that this study of our field's past and present can prompt informed discussion of our community's implicit norms and more deliberate action to consciously shape the future."],"url":"http://arxiv.org/abs/2310.07715v1"}
{"created":"2023-10-11 17:59:05","title":"InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining","abstract":"Pretraining auto-regressive large language models (LLMs) with retrieval demonstrates better perplexity and factual accuracy by leveraging external databases. However, the size of existing pretrained retrieval-augmented LLM is still limited (e.g., Retro has 7.5B parameters), which limits the effectiveness of instruction tuning and zero-shot generalization. In this work, we introduce Retro 48B, the largest LLM pretrained with retrieval before instruction tuning. Specifically, we continue to pretrain the 43B GPT model on additional 100 billion tokens using the Retro augmentation method by retrieving from 1.2 trillion tokens. The obtained foundation model, Retro 48B, largely outperforms the original 43B GPT in terms of perplexity. After instruction tuning on Retro, InstructRetro demonstrates significant improvement over the instruction tuned GPT on zero-shot question answering (QA) tasks. Specifically, the average improvement of InstructRetro is 7% over its GPT counterpart across 8 short-form QA tasks, and 10% over GPT across 4 challenging long-form QA tasks. Surprisingly, we find that one can ablate the encoder from InstructRetro architecture and directly use its decoder backbone, while achieving comparable results. We hypothesize that pretraining with retrieval makes its decoder good at incorporating context for QA. Our results highlights the promising direction to obtain a better GPT decoder for QA through continued pretraining with retrieval before instruction tuning.","sentences":["Pretraining auto-regressive large language models (LLMs) with retrieval demonstrates better perplexity and factual accuracy by leveraging external databases.","However, the size of existing pretrained retrieval-augmented LLM is still limited (e.g., Retro has 7.5B parameters), which limits the effectiveness of instruction tuning and zero-shot generalization.","In this work, we introduce Retro 48B, the largest LLM pretrained with retrieval before instruction tuning.","Specifically, we continue to pretrain the 43B GPT model on additional 100 billion tokens using the Retro augmentation method by retrieving from 1.2 trillion tokens.","The obtained foundation model, Retro 48B, largely outperforms the original 43B GPT in terms of perplexity.","After instruction tuning on Retro, InstructRetro demonstrates significant improvement over the instruction tuned GPT on zero-shot question answering (QA) tasks.","Specifically, the average improvement of InstructRetro is 7% over its GPT counterpart across 8 short-form QA tasks, and 10% over GPT across 4 challenging long-form QA tasks.","Surprisingly, we find that one can ablate the encoder from InstructRetro architecture and directly use its decoder backbone, while achieving comparable results.","We hypothesize that pretraining with retrieval makes its decoder good at incorporating context for QA.","Our results highlights the promising direction to obtain a better GPT decoder for QA through continued pretraining with retrieval before instruction tuning."],"url":"http://arxiv.org/abs/2310.07713v1"}
{"created":"2023-10-11 17:59:02","title":"Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models","abstract":"Large language models (LLMs) exhibit positional bias in how they use context, which especially complicates listwise ranking. To address this, we propose permutation self-consistency, a form of self-consistency over ranking list outputs of black-box LLMs. Our key idea is to marginalize out different list orders in the prompt to produce an order-independent ranking with less positional bias. First, given some input prompt, we repeatedly shuffle the list in the prompt and pass it through the LLM while holding the instructions the same. Next, we aggregate the resulting sample of rankings by computing the central ranking closest in distance to all of them, marginalizing out prompt order biases in the process. Theoretically, we prove the robustness of our method, showing convergence to the true ranking in the presence of random perturbations. Empirically, on five list-ranking datasets in sorting and passage reranking, our approach improves scores from conventional inference by up to 7-18% for GPT-3.5 and 8-16% for LLaMA v2 (70B), surpassing the previous state of the art in passage reranking. Our code is at https://github.com/castorini/perm-sc.","sentences":["Large language models (LLMs) exhibit positional bias in how they use context, which especially complicates listwise ranking.","To address this, we propose permutation self-consistency, a form of self-consistency over ranking list outputs of black-box LLMs.","Our key idea is to marginalize out different list orders in the prompt to produce an order-independent ranking with less positional bias.","First, given some input prompt, we repeatedly shuffle the list in the prompt and pass it through the LLM while holding the instructions the same.","Next, we aggregate the resulting sample of rankings by computing the central ranking closest in distance to all of them, marginalizing out prompt order biases in the process.","Theoretically, we prove the robustness of our method, showing convergence to the true ranking in the presence of random perturbations.","Empirically, on five list-ranking datasets in sorting and passage reranking, our approach improves scores from conventional inference by up to 7-18% for GPT-3.5 and 8-16% for LLaMA v2 (70B), surpassing the previous state of the art in passage reranking.","Our code is at https://github.com/castorini/perm-sc."],"url":"http://arxiv.org/abs/2310.07712v1"}
{"created":"2023-10-11 17:57:35","title":"DiPmark: A Stealthy, Efficient and Resilient Watermark for Large Language Models","abstract":"Watermarking techniques offer a promising way to secure data via embedding covert information into the data. A paramount challenge in the domain lies in preserving the distribution of original data during watermarking. Our research extends and refines existing watermarking framework, placing emphasis on the importance of a distribution-preserving (DiP) watermark. Contrary to the current strategies, our proposed DiPmark preserves the original token distribution during watermarking (stealthy), is detectable without access to the language model API or weights (efficient), and is robust to moderate changes of tokens (resilient). This is achieved by incorporating a novel reweight strategy, combined with a hash function that assigns unique \\textit{i.i.d.} ciphers based on the context. The empirical benchmarks of our approach underscore its stealthiness, efficiency, and resilience, making it a robust solution for watermarking tasks that demand impeccable quality preservation.","sentences":["Watermarking techniques offer a promising way to secure data via embedding covert information into the data.","A paramount challenge in the domain lies in preserving the distribution of original data during watermarking.","Our research extends and refines existing watermarking framework, placing emphasis on the importance of a distribution-preserving (DiP) watermark.","Contrary to the current strategies, our proposed DiPmark preserves the original token distribution during watermarking (stealthy), is detectable without access to the language model API or weights (efficient), and is robust to moderate changes of tokens (resilient).","This is achieved by incorporating a novel reweight strategy, combined with a hash function that assigns unique \\textit{i.i.d.} ciphers based on the context.","The empirical benchmarks of our approach underscore its stealthiness, efficiency, and resilience, making it a robust solution for watermarking tasks that demand impeccable quality preservation."],"url":"http://arxiv.org/abs/2310.07710v1"}
{"created":"2023-10-11 17:57:14","title":"MatFormer: Nested Transformer for Elastic Inference","abstract":"Transformer models are deployed in a wide range of settings, from multi-accelerator clusters to standalone mobile phones. The diverse inference constraints in these scenarios necessitate practitioners to train foundation models such as PaLM 2, Llama, & ViTs as a series of models of varying sizes. Due to significant training costs, only a select few model sizes are trained and supported, limiting more fine-grained control over relevant tradeoffs, including latency, cost, and accuracy. This work introduces MatFormer, a nested Transformer architecture designed to offer elasticity in a variety of deployment constraints. Each Feed Forward Network (FFN) block of a MatFormer model is jointly optimized with a few nested smaller FFN blocks. This training procedure allows for the Mix'n'Match of model granularities across layers -- i.e., a trained universal MatFormer model enables extraction of hundreds of accurate smaller models, which were never explicitly optimized. We empirically demonstrate MatFormer's effectiveness across different model classes (decoders & encoders), modalities (language & vision), and scales (up to 2.6B parameters). We find that a 2.6B decoder-only MatFormer language model (MatLM) allows us to extract smaller models spanning from 1.5B to 2.6B, each exhibiting comparable validation loss and one-shot downstream evaluations to their independently trained counterparts. Furthermore, we observe that smaller encoders extracted from a universal MatFormer-based ViT (MatViT) encoder preserve the metric-space structure for adaptive large-scale retrieval. Finally, we showcase that speculative decoding with the accurate and consistent submodels extracted from MatFormer can further reduce inference latency.","sentences":["Transformer models are deployed in a wide range of settings, from multi-accelerator clusters to standalone mobile phones.","The diverse inference constraints in these scenarios necessitate practitioners to train foundation models such as PaLM 2, Llama, & ViTs as a series of models of varying sizes.","Due to significant training costs, only a select few model sizes are trained and supported, limiting more fine-grained control over relevant tradeoffs, including latency, cost, and accuracy.","This work introduces MatFormer, a nested Transformer architecture designed to offer elasticity in a variety of deployment constraints.","Each Feed Forward Network (FFN) block of a MatFormer model is jointly optimized with a few nested smaller FFN blocks.","This training procedure allows for the Mix'n'Match of model granularities across layers -- i.e., a trained universal MatFormer model enables extraction of hundreds of accurate smaller models, which were never explicitly optimized.","We empirically demonstrate MatFormer's effectiveness across different model classes (decoders & encoders), modalities (language & vision), and scales (up to 2.6B parameters).","We find that a 2.6B decoder-only MatFormer language model (MatLM) allows us to extract smaller models spanning from 1.5B to 2.6B, each exhibiting comparable validation loss and one-shot downstream evaluations to their independently trained counterparts.","Furthermore, we observe that smaller encoders extracted from a universal MatFormer-based ViT (MatViT) encoder preserve the metric-space structure for adaptive large-scale retrieval.","Finally, we showcase that speculative decoding with the accurate and consistent submodels extracted from MatFormer can further reduce inference latency."],"url":"http://arxiv.org/abs/2310.07707v1"}
{"created":"2023-10-11 17:57:13","title":"Pixel State Value Network for Combined Prediction and Planning in Interactive Environments","abstract":"Automated vehicles operating in urban environments have to reliably interact with other traffic participants. Planning algorithms often utilize separate prediction modules forecasting probabilistic, multi-modal, and interactive behaviors of objects. Designing prediction and planning as two separate modules introduces significant challenges, particularly due to the interdependence of these modules. This work proposes a deep learning methodology to combine prediction and planning. A conditional GAN with the U-Net architecture is trained to predict two high-resolution image sequences. The sequences represent explicit motion predictions, mainly used to train context understanding, and pixel state values suitable for planning encoding kinematic reachability, object dynamics, safety, and driving comfort. The model can be trained offline on target images rendered by a sampling-based model-predictive planner, leveraging real-world driving data. Our results demonstrate intuitive behavior in complex situations, such as lane changes amidst conflicting objectives.","sentences":["Automated vehicles operating in urban environments have to reliably interact with other traffic participants.","Planning algorithms often utilize separate prediction modules forecasting probabilistic, multi-modal, and interactive behaviors of objects.","Designing prediction and planning as two separate modules introduces significant challenges, particularly due to the interdependence of these modules.","This work proposes a deep learning methodology to combine prediction and planning.","A conditional GAN with the U-Net architecture is trained to predict two high-resolution image sequences.","The sequences represent explicit motion predictions, mainly used to train context understanding, and pixel state values suitable for planning encoding kinematic reachability, object dynamics, safety, and driving comfort.","The model can be trained offline on target images rendered by a sampling-based model-predictive planner, leveraging real-world driving data.","Our results demonstrate intuitive behavior in complex situations, such as lane changes amidst conflicting objectives."],"url":"http://arxiv.org/abs/2310.07706v1"}
{"created":"2023-10-11 17:55:15","title":"Ferret: Refer and Ground Anything Anywhere at Any Granularity","abstract":"We introduce Ferret, a new Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions. To unify referring and grounding in the LLM paradigm, Ferret employs a novel and powerful hybrid region representation that integrates discrete coordinates and continuous features jointly to represent a region in the image. To extract the continuous features of versatile regions, we propose a spatial-aware visual sampler, adept at handling varying sparsity across different shapes. Consequently, Ferret can accept diverse region inputs, such as points, bounding boxes, and free-form shapes. To bolster the desired capability of Ferret, we curate GRIT, a comprehensive refer-and-ground instruction tuning dataset including 1.1M samples that contain rich hierarchical spatial knowledge, with 95K hard negative data to promote model robustness. The resulting model not only achieves superior performance in classical referring and grounding tasks, but also greatly outperforms existing MLLMs in region-based and localization-demanded multimodal chatting. Our evaluations also reveal a significantly improved capability of describing image details and a remarkable alleviation in object hallucination. Code and data will be available at https://github.com/apple/ml-ferret","sentences":["We introduce Ferret, a new Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions.","To unify referring and grounding in the LLM paradigm, Ferret employs a novel and powerful hybrid region representation that integrates discrete coordinates and continuous features jointly to represent a region in the image.","To extract the continuous features of versatile regions, we propose a spatial-aware visual sampler, adept at handling varying sparsity across different shapes.","Consequently, Ferret can accept diverse region inputs, such as points, bounding boxes, and free-form shapes.","To bolster the desired capability of Ferret, we curate GRIT, a comprehensive refer-and-ground instruction tuning dataset including 1.1M samples that contain rich hierarchical spatial knowledge, with 95K hard negative data to promote model robustness.","The resulting model not only achieves superior performance in classical referring and grounding tasks, but also greatly outperforms existing MLLMs in region-based and localization-demanded multimodal chatting.","Our evaluations also reveal a significantly improved capability of describing image details and a remarkable alleviation in object hallucination.","Code and data will be available at https://github.com/apple/ml-ferret"],"url":"http://arxiv.org/abs/2310.07704v1"}
{"created":"2023-10-11 17:52:39","title":"ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models","abstract":"In this work, we investigate the capability of generating images from pre-trained diffusion models at much higher resolutions than the training image sizes. In addition, the generated images should have arbitrary image aspect ratios. When generating images directly at a higher resolution, 1024 x 1024, with the pre-trained Stable Diffusion using training images of resolution 512 x 512, we observe persistent problems of object repetition and unreasonable object structures. Existing works for higher-resolution generation, such as attention-based and joint-diffusion approaches, cannot well address these issues. As a new perspective, we examine the structural components of the U-Net in diffusion models and identify the crucial cause as the limited perception field of convolutional kernels. Based on this key observation, we propose a simple yet effective re-dilation that can dynamically adjust the convolutional perception field during inference. We further propose the dispersed convolution and noise-damped classifier-free guidance, which can enable ultra-high-resolution image generation (e.g., 4096 x 4096). Notably, our approach does not require any training or optimization. Extensive experiments demonstrate that our approach can address the repetition issue well and achieve state-of-the-art performance on higher-resolution image synthesis, especially in texture details. Our work also suggests that a pre-trained diffusion model trained on low-resolution images can be directly used for high-resolution visual generation without further tuning, which may provide insights for future research on ultra-high-resolution image and video synthesis.","sentences":["In this work, we investigate the capability of generating images from pre-trained diffusion models at much higher resolutions than the training image sizes.","In addition, the generated images should have arbitrary image aspect ratios.","When generating images directly at a higher resolution, 1024 x 1024, with the pre-trained Stable Diffusion using training images of resolution 512 x 512, we observe persistent problems of object repetition and unreasonable object structures.","Existing works for higher-resolution generation, such as attention-based and joint-diffusion approaches, cannot well address these issues.","As a new perspective, we examine the structural components of the U-Net in diffusion models and identify the crucial cause as the limited perception field of convolutional kernels.","Based on this key observation, we propose a simple yet effective re-dilation that can dynamically adjust the convolutional perception field during inference.","We further propose the dispersed convolution and noise-damped classifier-free guidance, which can enable ultra-high-resolution image generation (e.g., 4096 x 4096).","Notably, our approach does not require any training or optimization.","Extensive experiments demonstrate that our approach can address the repetition issue well and achieve state-of-the-art performance on higher-resolution image synthesis, especially in texture details.","Our work also suggests that a pre-trained diffusion model trained on low-resolution images can be directly used for high-resolution visual generation without further tuning, which may provide insights for future research on ultra-high-resolution image and video synthesis."],"url":"http://arxiv.org/abs/2310.07702v1"}
{"created":"2023-10-11 17:51:28","title":"Knowledge-enhanced Memory Model for Emotional Support Conversation","abstract":"The prevalence of mental disorders has become a significant issue, leading to the increased focus on Emotional Support Conversation as an effective supplement for mental health support. Existing methods have achieved compelling results, however, they still face three challenges: 1) variability of emotions, 2) practicality of the response, and 3) intricate strategy modeling. To address these challenges, we propose a novel knowledge-enhanced Memory mODEl for emotional suppoRt coNversation (MODERN). Specifically, we first devise a knowledge-enriched dialogue context encoding to perceive the dynamic emotion change of different periods of the conversation for coherent user state modeling and select context-related concepts from ConceptNet for practical response generation. Thereafter, we implement a novel memory-enhanced strategy modeling module to model the semantic patterns behind the strategy categories. Extensive experiments on a widely used large-scale dataset verify the superiority of our model over cutting-edge baselines.","sentences":["The prevalence of mental disorders has become a significant issue, leading to the increased focus on Emotional Support Conversation as an effective supplement for mental health support.","Existing methods have achieved compelling results, however, they still face three challenges: 1) variability of emotions, 2) practicality of the response, and 3) intricate strategy modeling.","To address these challenges, we propose a novel knowledge-enhanced Memory mODEl for emotional suppoRt coNversation (MODERN).","Specifically, we first devise a knowledge-enriched dialogue context encoding to perceive the dynamic emotion change of different periods of the conversation for coherent user state modeling and select context-related concepts from ConceptNet for practical response generation.","Thereafter, we implement a novel memory-enhanced strategy modeling module to model the semantic patterns behind the strategy categories.","Extensive experiments on a widely used large-scale dataset verify the superiority of our model over cutting-edge baselines."],"url":"http://arxiv.org/abs/2310.07700v1"}
{"created":"2023-10-11 17:49:13","title":"From Scarcity to Efficiency: Improving CLIP Training via Visual-enriched Captions","abstract":"Web-crawled datasets are pivotal to the success of pre-training vision-language models, exemplified by CLIP. However, web-crawled AltTexts can be noisy and potentially irrelevant to images, thereby undermining the crucial image-text alignment. Existing methods for rewriting captions using large language models (LLMs) have shown promise on small, curated datasets like CC3M and CC12M. Nevertheless, their efficacy on massive web-captured captions is constrained by the inherent noise and randomness in such data. In this study, we address this limitation by focusing on two key aspects: data quality and data variety. Unlike recent LLM rewriting techniques, we emphasize exploiting visual concepts and their integration into the captions to improve data quality. For data variety, we propose a novel mixed training scheme that optimally leverages AltTexts alongside newly generated Visual-enriched Captions (VeC). We use CLIP as one example and adapt the method for CLIP training on large-scale web-crawled datasets, named VeCLIP. We conduct a comprehensive evaluation of VeCLIP across small, medium, and large scales of raw data. Our results show significant advantages in image-text alignment and overall model performance, underscoring the effectiveness of VeCLIP in improving CLIP training. For example, VeCLIP achieves a remarkable over 20% improvement in COCO and Flickr30k retrieval tasks under the 12M setting. For data efficiency, we also achieve a notable over 3% improvement while using only 14% of the data employed in the vanilla CLIP and 11% in ALIGN.","sentences":["Web-crawled datasets are pivotal to the success of pre-training vision-language models, exemplified by CLIP.","However, web-crawled AltTexts can be noisy and potentially irrelevant to images, thereby undermining the crucial image-text alignment.","Existing methods for rewriting captions using large language models (LLMs) have shown promise on small, curated datasets like CC3M and CC12M.","Nevertheless, their efficacy on massive web-captured captions is constrained by the inherent noise and randomness in such data.","In this study, we address this limitation by focusing on two key aspects: data quality and data variety.","Unlike recent LLM rewriting techniques, we emphasize exploiting visual concepts and their integration into the captions to improve data quality.","For data variety, we propose a novel mixed training scheme that optimally leverages AltTexts alongside newly generated Visual-enriched Captions (VeC).","We use CLIP as one example and adapt the method for CLIP training on large-scale web-crawled datasets, named VeCLIP.","We conduct a comprehensive evaluation of VeCLIP across small, medium, and large scales of raw data.","Our results show significant advantages in image-text alignment and overall model performance, underscoring the effectiveness of VeCLIP in improving CLIP training.","For example, VeCLIP achieves a remarkable over 20% improvement in COCO and Flickr30k retrieval tasks under the 12M setting.","For data efficiency, we also achieve a notable over 3% improvement while using only 14% of the data employed in the vanilla CLIP and 11% in ALIGN."],"url":"http://arxiv.org/abs/2310.07699v1"}
{"created":"2023-10-11 17:46:59","title":"SurroCBM: Concept Bottleneck Surrogate Models for Generative Post-hoc Explanation","abstract":"Explainable AI seeks to bring light to the decision-making processes of black-box models. Traditional saliency-based methods, while highlighting influential data segments, often lack semantic understanding. Recent advancements, such as Concept Activation Vectors (CAVs) and Concept Bottleneck Models (CBMs), offer concept-based explanations but necessitate human-defined concepts. However, human-annotated concepts are expensive to attain. This paper introduces the Concept Bottleneck Surrogate Models (SurroCBM), a novel framework that aims to explain the black-box models with automatically discovered concepts. SurroCBM identifies shared and unique concepts across various black-box models and employs an explainable surrogate model for post-hoc explanations. An effective training strategy using self-generated data is proposed to enhance explanation quality continuously. Through extensive experiments, we demonstrate the efficacy of SurroCBM in concept discovery and explanation, underscoring its potential in advancing the field of explainable AI.","sentences":["Explainable AI seeks to bring light to the decision-making processes of black-box models.","Traditional saliency-based methods, while highlighting influential data segments, often lack semantic understanding.","Recent advancements, such as Concept Activation Vectors (CAVs) and Concept Bottleneck Models (CBMs), offer concept-based explanations but necessitate human-defined concepts.","However, human-annotated concepts are expensive to attain.","This paper introduces the Concept Bottleneck Surrogate Models (SurroCBM), a novel framework that aims to explain the black-box models with automatically discovered concepts.","SurroCBM identifies shared and unique concepts across various black-box models and employs an explainable surrogate model for post-hoc explanations.","An effective training strategy using self-generated data is proposed to enhance explanation quality continuously.","Through extensive experiments, we demonstrate the efficacy of SurroCBM in concept discovery and explanation, underscoring its potential in advancing the field of explainable AI."],"url":"http://arxiv.org/abs/2310.07698v1"}
{"created":"2023-10-11 17:46:28","title":"ConditionVideo: Training-Free Condition-Guided Text-to-Video Generation","abstract":"Recent works have successfully extended large-scale text-to-image models to the video domain, producing promising results but at a high computational cost and requiring a large amount of video data. In this work, we introduce ConditionVideo, a training-free approach to text-to-video generation based on the provided condition, video, and input text, by leveraging the power of off-the-shelf text-to-image generation methods (e.g., Stable Diffusion). ConditionVideo generates realistic dynamic videos from random noise or given scene videos. Our method explicitly disentangles the motion representation into condition-guided and scenery motion components. To this end, the ConditionVideo model is designed with a UNet branch and a control branch. To improve temporal coherence, we introduce sparse bi-directional spatial-temporal attention (sBiST-Attn). The 3D control network extends the conventional 2D controlnet model, aiming to strengthen conditional generation accuracy by additionally leveraging the bi-directional frames in the temporal domain. Our method exhibits superior performance in terms of frame consistency, clip score, and conditional accuracy, outperforming other compared methods.","sentences":["Recent works have successfully extended large-scale text-to-image models to the video domain, producing promising results but at a high computational cost and requiring a large amount of video data.","In this work, we introduce ConditionVideo, a training-free approach to text-to-video generation based on the provided condition, video, and input text, by leveraging the power of off-the-shelf text-to-image generation methods (e.g., Stable Diffusion).","ConditionVideo generates realistic dynamic videos from random noise or given scene videos.","Our method explicitly disentangles the motion representation into condition-guided and scenery motion components.","To this end, the ConditionVideo model is designed with a UNet branch and a control branch.","To improve temporal coherence, we introduce sparse bi-directional spatial-temporal attention (sBiST-Attn).","The 3D control network extends the conventional 2D controlnet model, aiming to strengthen conditional generation accuracy by additionally leveraging the bi-directional frames in the temporal domain.","Our method exhibits superior performance in terms of frame consistency, clip score, and conditional accuracy, outperforming other compared methods."],"url":"http://arxiv.org/abs/2310.07697v1"}
{"created":"2023-10-11 17:36:17","title":"New optimal trade-off point for coded caching systems with limited cache size","abstract":"This paper presents a new achievable scheme for coded caching systems with $\\mathsf{N}$ files, $\\mathsf{K}=\\mathsf{N}$ users, and cache size $\\mathsf{M}=1/(\\mathsf{N}-1)$. The scheme employs linear coding during the cache placement phase, and a three-stage transmissions designed to eliminate interference in the delivery phase. The achievable load meets a known converse bound, which impose no constraint on the cache placement, and is thus optimal. This new result, together with known inner and outer bounds, shows optimality of linear coding placement for $\\mathsf{M} \\leq 1/(\\mathsf{N}-1)$ when $\\mathsf{K}=\\mathsf{N}\\geq 3$. Interestingly and surprisingly, the proposed scheme is relatively simple but requires operations on a finite field of size at least 3.","sentences":["This paper presents a new achievable scheme for coded caching systems with $\\mathsf{N}$ files, $\\mathsf{K}=\\mathsf{N}$ users, and cache size $\\mathsf{M}=1/(\\mathsf{N}-1)$. The scheme employs linear coding during the cache placement phase, and a three-stage transmissions designed to eliminate interference in the delivery phase.","The achievable load meets a known converse bound, which impose no constraint on the cache placement, and is thus optimal.","This new result, together with known inner and outer bounds, shows optimality of linear coding placement for $\\mathsf{M} \\leq 1/(\\mathsf{N}-1)$ when $\\mathsf{K}=\\mathsf{N}\\geq 3$. Interestingly and surprisingly, the proposed scheme is relatively simple but requires operations on a finite field of size at least 3."],"url":"http://arxiv.org/abs/2310.07686v1"}
{"created":"2023-10-11 17:35:20","title":"Hypergraph Neural Networks through the Lens of Message Passing: A Common Perspective to Homophily and Architecture Design","abstract":"Most of the current hypergraph learning methodologies and benchmarking datasets in the hypergraph realm are obtained by lifting procedures from their graph analogs, simultaneously leading to overshadowing hypergraph network foundations. This paper attempts to confront some pending questions in that regard: Can the concept of homophily play a crucial role in Hypergraph Neural Networks (HGNNs), similar to its significance in graph-based research? Is there room for improving current hypergraph architectures and methodologies? (e.g. by carefully addressing the specific characteristics of higher-order networks) Do existing datasets provide a meaningful benchmark for HGNNs? Diving into the details, this paper proposes a novel conceptualization of homophily in higher-order networks based on a message passing scheme; this approach harmonizes the analytical frameworks of datasets and architectures, offering a unified perspective for exploring and interpreting complex, higher-order network structures and dynamics. Further, we propose MultiSet, a novel message passing framework that redefines HGNNs by allowing hyperedge-dependent node representations, as well as introduce a novel architecture MultiSetMixer that leverages a new hyperedge sampling strategy. Finally, we provide an extensive set of experiments that contextualize our proposals and lead to valuable insights in hypergraph representation learning.","sentences":["Most of the current hypergraph learning methodologies and benchmarking datasets in the hypergraph realm are obtained by lifting procedures from their graph analogs, simultaneously leading to overshadowing hypergraph network foundations.","This paper attempts to confront some pending questions in that regard:","Can the concept of homophily play a crucial role in Hypergraph Neural Networks (HGNNs), similar to its significance in graph-based research?","Is there room for improving current hypergraph architectures and methodologies?","(e.g. by carefully addressing the specific characteristics of higher-order networks) Do existing datasets provide a meaningful benchmark for HGNNs?","Diving into the details, this paper proposes a novel conceptualization of homophily in higher-order networks based on a message passing scheme; this approach harmonizes the analytical frameworks of datasets and architectures, offering a unified perspective for exploring and interpreting complex, higher-order network structures and dynamics.","Further, we propose MultiSet, a novel message passing framework that redefines HGNNs by allowing hyperedge-dependent node representations, as well as introduce a novel architecture MultiSetMixer that leverages a new hyperedge sampling strategy.","Finally, we provide an extensive set of experiments that contextualize our proposals and lead to valuable insights in hypergraph representation learning."],"url":"http://arxiv.org/abs/2310.07684v1"}
{"created":"2023-10-11 17:34:56","title":"Controllable Data Generation Via Iterative Data-Property Mutual Mappings","abstract":"Deep generative models have been widely used for their ability to generate realistic data samples in various areas, such as images, molecules, text, and speech. One major goal of data generation is controllability, namely to generate new data with desired properties. Despite growing interest in the area of controllable generation, significant challenges still remain, including 1) disentangling desired properties with unrelated latent variables, 2) out-of-distribution property control, and 3) objective optimization for out-of-distribution property control. To address these challenges, in this paper, we propose a general framework to enhance VAE-based data generators with property controllability and ensure disentanglement. Our proposed objective can be optimized on both data seen and unseen in the training set. We propose a training procedure to train the objective in a semi-supervised manner by iteratively conducting mutual mappings between the data and properties. The proposed framework is implemented on four VAE-based controllable generators to evaluate its performance on property error, disentanglement, generation quality, and training time. The results indicate that our proposed framework enables more precise control over the properties of generated samples in a short training time, ensuring the disentanglement and keeping the validity of the generated samples.","sentences":["Deep generative models have been widely used for their ability to generate realistic data samples in various areas, such as images, molecules, text, and speech.","One major goal of data generation is controllability, namely to generate new data with desired properties.","Despite growing interest in the area of controllable generation, significant challenges still remain, including 1) disentangling desired properties with unrelated latent variables, 2) out-of-distribution property control, and 3) objective optimization for out-of-distribution property control.","To address these challenges, in this paper, we propose a general framework to enhance VAE-based data generators with property controllability and ensure disentanglement.","Our proposed objective can be optimized on both data seen and unseen in the training set.","We propose a training procedure to train the objective in a semi-supervised manner by iteratively conducting mutual mappings between the data and properties.","The proposed framework is implemented on four VAE-based controllable generators to evaluate its performance on property error, disentanglement, generation quality, and training time.","The results indicate that our proposed framework enables more precise control over the properties of generated samples in a short training time, ensuring the disentanglement and keeping the validity of the generated samples."],"url":"http://arxiv.org/abs/2310.07683v1"}
{"created":"2023-10-11 17:32:24","title":"Prediction of MET Overexpression in Non-Small Cell Lung Adenocarcinomas from Hematoxylin and Eosin Images","abstract":"MET protein overexpression is a targetable event in non-small cell lung cancer (NSCLC) and is the subject of active drug development. Challenges in identifying patients for these therapies include lack of access to validated testing, such as standardized immunohistochemistry (IHC) assessment, and consumption of valuable tissue for a single gene/protein assay. Development of pre-screening algorithms using routinely available digitized hematoxylin and eosin (H&E)-stained slides to predict MET overexpression could promote testing for those who will benefit most. While assessment of MET expression using IHC is currently not routinely performed in NSCLC, next-generation sequencing is common and in some cases includes RNA expression panel testing. In this work, we leveraged a large database of matched H&E slides and RNA expression data to train a weakly supervised model to predict MET RNA overexpression directly from H&E images. This model was evaluated on an independent holdout test set of 300 over-expressed and 289 normal patients, demonstrating an ROC-AUC of 0.70 (95th percentile interval: 0.66 - 0.74) with stable performance characteristics across different patient clinical variables and robust to synthetic noise on the test set. These results suggest that H&E-based predictive models could be useful to prioritize patients for confirmatory testing of MET protein or MET gene expression status.","sentences":["MET protein overexpression is a targetable event in non-small cell lung cancer (NSCLC) and is the subject of active drug development.","Challenges in identifying patients for these therapies include lack of access to validated testing, such as standardized immunohistochemistry (IHC) assessment, and consumption of valuable tissue for a single gene/protein assay.","Development of pre-screening algorithms using routinely available digitized hematoxylin and eosin (H&E)-stained slides to predict MET overexpression could promote testing for those who will benefit most.","While assessment of MET expression using IHC is currently not routinely performed in NSCLC, next-generation sequencing is common and in some cases includes RNA expression panel testing.","In this work, we leveraged a large database of matched H&E slides and RNA expression data to train a weakly supervised model to predict MET RNA overexpression directly from H&E images.","This model was evaluated on an independent holdout test set of 300 over-expressed and 289 normal patients, demonstrating an ROC-AUC of 0.70 (95th percentile interval: 0.66 - 0.74) with stable performance characteristics across different patient clinical variables and robust to synthetic noise on the test set.","These results suggest that H&E-based predictive models could be useful to prioritize patients for confirmatory testing of MET protein or MET gene expression status."],"url":"http://arxiv.org/abs/2310.07682v1"}
{"created":"2023-10-11 17:21:48","title":"Explainable Image Similarity: Integrating Siamese Networks and Grad-CAM","abstract":"With the proliferation of image-based applications in various domains, the need for accurate and interpretable image similarity measures has become increasingly critical. Existing image similarity models often lack transparency, making it challenging to understand the reasons why two images are considered similar. In this paper, we propose the concept of explainable image similarity, where the goal is the development of an approach, which is capable of providing similarity scores along with visual factual and counterfactual explanations. Along this line, we present a new framework, which integrates Siamese Networks and Grad-CAM for providing explainable image similarity and discuss the potential benefits and challenges of adopting this approach. In addition, we provide a comprehensive discussion about factual and counterfactual explanations provided by the proposed framework for assisting decision making. The proposed approach has the potential to enhance the interpretability, trustworthiness and user acceptance of image-based systems in real-world image similarity applications. The implementation code can be found in https://github.com/ioannislivieris/Grad_CAM_Siamese.git.","sentences":["With the proliferation of image-based applications in various domains, the need for accurate and interpretable image similarity measures has become increasingly critical.","Existing image similarity models often lack transparency, making it challenging to understand the reasons why two images are considered similar.","In this paper, we propose the concept of explainable image similarity, where the goal is the development of an approach, which is capable of providing similarity scores along with visual factual and counterfactual explanations.","Along this line, we present a new framework, which integrates Siamese Networks and Grad-CAM for providing explainable image similarity and discuss the potential benefits and challenges of adopting this approach.","In addition, we provide a comprehensive discussion about factual and counterfactual explanations provided by the proposed framework for assisting decision making.","The proposed approach has the potential to enhance the interpretability, trustworthiness and user acceptance of image-based systems in real-world image similarity applications.","The implementation code can be found in https://github.com/ioannislivieris/Grad_CAM_Siamese.git."],"url":"http://arxiv.org/abs/2310.07678v1"}
{"created":"2023-10-11 17:21:03","title":"Composite Backdoor Attacks Against Large Language Models","abstract":"Large language models (LLMs) have demonstrated superior performance compared to previous methods on various tasks, and often serve as the foundation models for many researches and services. However, the untrustworthy third-party LLMs may covertly introduce vulnerabilities for downstream tasks. In this paper, we explore the vulnerability of LLMs through the lens of backdoor attacks. Different from existing backdoor attacks against LLMs, ours scatters multiple trigger keys in different prompt components. Such a Composite Backdoor Attack (CBA) is shown to be stealthier than implanting the same multiple trigger keys in only a single component. CBA ensures that the backdoor is activated only when all trigger keys appear. Our experiments demonstrate that CBA is effective in both natural language processing (NLP) and multimodal tasks. For instance, with $3\\%$ poisoning samples against the LLaMA-7B model on the Emotion dataset, our attack achieves a $100\\%$ Attack Success Rate (ASR) with a False Triggered Rate (FTR) below $2.06\\%$ and negligible model accuracy degradation. The unique characteristics of our CBA can be tailored for various practical scenarios, e.g., targeting specific user groups. Our work highlights the necessity of increased security research on the trustworthiness of foundation LLMs.","sentences":["Large language models (LLMs) have demonstrated superior performance compared to previous methods on various tasks, and often serve as the foundation models for many researches and services.","However, the untrustworthy third-party LLMs may covertly introduce vulnerabilities for downstream tasks.","In this paper, we explore the vulnerability of LLMs through the lens of backdoor attacks.","Different from existing backdoor attacks against LLMs, ours scatters multiple trigger keys in different prompt components.","Such a Composite Backdoor Attack (CBA) is shown to be stealthier than implanting the same multiple trigger keys in only a single component.","CBA ensures that the backdoor is activated only when all trigger keys appear.","Our experiments demonstrate that CBA is effective in both natural language processing (NLP) and multimodal tasks.","For instance, with $3\\%$ poisoning samples against the LLaMA-7B model on the Emotion dataset, our attack achieves a $100\\%$ Attack Success Rate (ASR) with a False Triggered Rate (FTR) below $2.06\\%$ and negligible model accuracy degradation.","The unique characteristics of our CBA can be tailored for various practical scenarios, e.g., targeting specific user groups.","Our work highlights the necessity of increased security research on the trustworthiness of foundation LLMs."],"url":"http://arxiv.org/abs/2310.07676v1"}
{"created":"2023-10-11 17:18:30","title":"Discovery of Novel Reticular Materials for Carbon Dioxide Capture using GFlowNets","abstract":"Artificial intelligence holds promise to improve materials discovery. GFlowNets are an emerging deep learning algorithm with many applications in AI-assisted discovery. By using GFlowNets, we generate porous reticular materials, such as metal organic frameworks and covalent organic frameworks, for applications in carbon dioxide capture. We introduce a new Python package (matgfn) to train and sample GFlowNets. We use matgfn to generate the matgfn-rm dataset of novel and diverse reticular materials with gravimetric surface area above 5000 m$^2$/g. We calculate single- and two-component gas adsorption isotherms for the top-100 candidates in matgfn-rm. These candidates are novel compared to the state-of-art ARC-MOF dataset and rank in the 90th percentile in terms of working capacity compared to the CoRE2019 dataset. We discover 15 materials outperforming all materials in CoRE2019.","sentences":["Artificial intelligence holds promise to improve materials discovery.","GFlowNets are an emerging deep learning algorithm with many applications in AI-assisted discovery.","By using GFlowNets, we generate porous reticular materials, such as metal organic frameworks and covalent organic frameworks, for applications in carbon dioxide capture.","We introduce a new Python package (matgfn) to train and sample GFlowNets.","We use matgfn to generate the matgfn-rm dataset of novel and diverse reticular materials with gravimetric surface area above 5000 m$^2$/g.","We calculate single- and two-component gas adsorption isotherms for the top-100 candidates in matgfn-rm.","These candidates are novel compared to the state-of-art ARC-MOF dataset and rank in the 90th percentile in terms of working capacity compared to the CoRE2019 dataset.","We discover 15 materials outperforming all materials in CoRE2019."],"url":"http://arxiv.org/abs/2310.07671v1"}
{"created":"2023-10-11 17:18:15","title":"HaarNet: Large-scale Linear-Morphological Hybrid Network for RGB-D Semantic Segmentation","abstract":"Signals from different modalities each have their own combination algebra which affects their sampling processing. RGB is mostly linear; depth is a geometric signal following the operations of mathematical morphology. If a network obtaining RGB-D input has both kinds of operators available in its layers, it should be able to give effective output with fewer parameters. In this paper, morphological elements in conjunction with more familiar linear modules are used to construct a mixed linear-morphological network called HaarNet. This is the first large-scale linear-morphological hybrid, evaluated on a set of sizeable real-world datasets. In the network, morphological Haar sampling is applied to both feature channels in several layers, which splits extreme values and high-frequency information such that both can be processed to improve both modalities. Moreover, morphologically parameterised ReLU is used, and morphologically-sound up-sampling is applied to obtain a full-resolution output. Experiments show that HaarNet is competitive with a state-of-the-art CNN, implying that morphological networks are a promising research direction for geometry-based learning tasks.","sentences":["Signals from different modalities each have their own combination algebra which affects their sampling processing.","RGB is mostly linear; depth is a geometric signal following the operations of mathematical morphology.","If a network obtaining RGB-D input has both kinds of operators available in its layers, it should be able to give effective output with fewer parameters.","In this paper, morphological elements in conjunction with more familiar linear modules are used to construct a mixed linear-morphological network called HaarNet.","This is the first large-scale linear-morphological hybrid, evaluated on a set of sizeable real-world datasets.","In the network, morphological Haar sampling is applied to both feature channels in several layers, which splits extreme values and high-frequency information such that both can be processed to improve both modalities.","Moreover, morphologically parameterised ReLU is used, and morphologically-sound up-sampling is applied to obtain a full-resolution output.","Experiments show that HaarNet is competitive with a state-of-the-art CNN, implying that morphological networks are a promising research direction for geometry-based learning tasks."],"url":"http://arxiv.org/abs/2310.07669v1"}
{"created":"2023-10-11 17:17:40","title":"GRaMuFeN: Graph-based Multi-modal Fake News Detection in Social Media","abstract":"The proliferation of social media platforms such as Twitter, Instagram, and Weibo has significantly enhanced the dissemination of false information. This phenomenon grants both individuals and governmental entities the ability to shape public opinions, highlighting the need for deploying effective detection methods. In this paper, we propose GraMuFeN, a model designed to detect fake content by analyzing both the textual and image content of news. GraMuFeN comprises two primary components: a text encoder and an image encoder. For textual analysis, GraMuFeN treats each text as a graph and employs a Graph Convolutional Neural Network (GCN) as the text encoder. Additionally, the pre-trained ResNet-152, as a Convolutional Neural Network (CNN), has been utilized as the image encoder. By integrating the outputs from these two encoders and implementing a contrastive similarity loss function, GraMuFeN achieves remarkable results. Extensive evaluations conducted on two publicly available benchmark datasets for social media news indicate a 10 % increase in micro F1-Score, signifying improvement over existing state-of-the-art models. These findings underscore the effectiveness of combining GCN and CNN models for detecting fake news in multi-modal data, all while minimizing the additional computational burden imposed by model parameters.","sentences":["The proliferation of social media platforms such as Twitter, Instagram, and Weibo has significantly enhanced the dissemination of false information.","This phenomenon grants both individuals and governmental entities the ability to shape public opinions, highlighting the need for deploying effective detection methods.","In this paper, we propose GraMuFeN, a model designed to detect fake content by analyzing both the textual and image content of news.","GraMuFeN comprises two primary components: a text encoder and an image encoder.","For textual analysis, GraMuFeN treats each text as a graph and employs a Graph Convolutional Neural Network (GCN) as the text encoder.","Additionally, the pre-trained ResNet-152, as a Convolutional Neural Network (CNN), has been utilized as the image encoder.","By integrating the outputs from these two encoders and implementing a contrastive similarity loss function, GraMuFeN achieves remarkable results.","Extensive evaluations conducted on two publicly available benchmark datasets for social media news indicate a 10 % increase in micro F1-Score, signifying improvement over existing state-of-the-art models.","These findings underscore the effectiveness of combining GCN and CNN models for detecting fake news in multi-modal data, all while minimizing the additional computational burden imposed by model parameters."],"url":"http://arxiv.org/abs/2310.07668v1"}
{"created":"2023-10-11 17:16:33","title":"Global Minima, Recoverability Thresholds, and Higher-Order Structure in GNNS","abstract":"We analyze the performance of graph neural network (GNN) architectures from the perspective of random graph theory. Our approach promises to complement existing lenses on GNN analysis, such as combinatorial expressive power and worst-case adversarial analysis, by connecting the performance of GNNs to typical-case properties of the training data. First, we theoretically characterize the nodewise accuracy of one- and two-layer GCNs relative to the contextual stochastic block model (cSBM) and related models. We additionally prove that GCNs cannot beat linear models under certain circumstances. Second, we numerically map the recoverability thresholds, in terms of accuracy, of four diverse GNN architectures (GCN, GAT, SAGE, and Graph Transformer) under a variety of assumptions about the data. Sample results of this second analysis include: heavy-tailed degree distributions enhance GNN performance, GNNs can work well on strongly heterophilous graphs, and SAGE and Graph Transformer can perform well on arbitrarily noisy edge data, but no architecture handled sufficiently noisy feature data well. Finally, we show how both specific higher-order structures in synthetic data and the mix of empirical structures in real data have dramatic effects (usually negative) on GNN performance.","sentences":["We analyze the performance of graph neural network (GNN) architectures from the perspective of random graph theory.","Our approach promises to complement existing lenses on GNN analysis, such as combinatorial expressive power and worst-case adversarial analysis, by connecting the performance of GNNs to typical-case properties of the training data.","First, we theoretically characterize the nodewise accuracy of one- and two-layer GCNs relative to the contextual stochastic block model (cSBM) and related models.","We additionally prove that GCNs cannot beat linear models under certain circumstances.","Second, we numerically map the recoverability thresholds, in terms of accuracy, of four diverse GNN architectures (GCN, GAT, SAGE, and Graph Transformer) under a variety of assumptions about the data.","Sample results of this second analysis include: heavy-tailed degree distributions enhance GNN performance, GNNs can work well on strongly heterophilous graphs, and SAGE and Graph Transformer can perform well on arbitrarily noisy edge data, but no architecture handled sufficiently noisy feature data well.","Finally, we show how both specific higher-order structures in synthetic data and the mix of empirical structures in real data have dramatic effects (usually negative) on GNN performance."],"url":"http://arxiv.org/abs/2310.07667v1"}
{"created":"2023-10-11 17:11:10","title":"Deep Backtracking Counterfactuals for Causally Compliant Explanations","abstract":"Counterfactuals can offer valuable insights by answering what would have been observed under altered circumstances, conditional on a factual observation. Whereas the classical interventional interpretation of counterfactuals has been studied extensively, backtracking constitutes a less studied alternative the backtracking principle has emerged as an alternative philosophy where all causal laws are kept intact. In the present work, we introduce a practical method for computing backtracking counterfactuals in structural causal models that consist of deep generative components. To this end, we impose conditions on the structural assignments that enable the generation of counterfactuals by solving a tractable constrained optimization problem in the structured latent space of a causal model. Our formulation also facilitates a comparison with methods in the field of counterfactual explanations. Compared to these, our method represents a versatile, modular and causally compliant alternative. We demonstrate these properties experimentally on a modified version of MNIST and CelebA.","sentences":["Counterfactuals can offer valuable insights by answering what would have been observed under altered circumstances, conditional on a factual observation.","Whereas the classical interventional interpretation of counterfactuals has been studied extensively, backtracking constitutes a less studied alternative the backtracking principle has emerged as an alternative philosophy where all causal laws are kept intact.","In the present work, we introduce a practical method for computing backtracking counterfactuals in structural causal models that consist of deep generative components.","To this end, we impose conditions on the structural assignments that enable the generation of counterfactuals by solving a tractable constrained optimization problem in the structured latent space of a causal model.","Our formulation also facilitates a comparison with methods in the field of counterfactual explanations.","Compared to these, our method represents a versatile, modular and causally compliant alternative.","We demonstrate these properties experimentally on a modified version of MNIST and CelebA."],"url":"http://arxiv.org/abs/2310.07665v1"}
{"created":"2023-10-11 17:09:19","title":"Accelerating Vision Transformers Based on Heterogeneous Attention Patterns","abstract":"Recently, Vision Transformers (ViTs) have attracted a lot of attention in the field of computer vision. Generally, the powerful representative capacity of ViTs mainly benefits from the self-attention mechanism, which has a high computation complexity. To accelerate ViTs, we propose an integrated compression pipeline based on observed heterogeneous attention patterns across layers. On one hand, different images share more similar attention patterns in early layers than later layers, indicating that the dynamic query-by-key self-attention matrix may be replaced with a static self-attention matrix in early layers. Then, we propose a dynamic-guided static self-attention (DGSSA) method where the matrix inherits self-attention information from the replaced dynamic self-attention to effectively improve the feature representation ability of ViTs. On the other hand, the attention maps have more low-rank patterns, which reflect token redundancy, in later layers than early layers. In a view of linear dimension reduction, we further propose a method of global aggregation pyramid (GLAD) to reduce the number of tokens in later layers of ViTs, such as Deit. Experimentally, the integrated compression pipeline of DGSSA and GLAD can accelerate up to 121% run-time throughput compared with DeiT, which surpasses all SOTA approaches.","sentences":["Recently, Vision Transformers (ViTs) have attracted a lot of attention in the field of computer vision.","Generally, the powerful representative capacity of ViTs mainly benefits from the self-attention mechanism, which has a high computation complexity.","To accelerate ViTs, we propose an integrated compression pipeline based on observed heterogeneous attention patterns across layers.","On one hand, different images share more similar attention patterns in early layers than later layers, indicating that the dynamic query-by-key self-attention matrix may be replaced with a static self-attention matrix in early layers.","Then, we propose a dynamic-guided static self-attention (DGSSA) method where the matrix inherits self-attention information from the replaced dynamic self-attention to effectively improve the feature representation ability of ViTs.","On the other hand, the attention maps have more low-rank patterns, which reflect token redundancy, in later layers than early layers.","In a view of linear dimension reduction, we further propose a method of global aggregation pyramid (GLAD) to reduce the number of tokens in later layers of ViTs, such as Deit.","Experimentally, the integrated compression pipeline of DGSSA and GLAD can accelerate up to 121% run-time throughput compared with DeiT, which surpasses all SOTA approaches."],"url":"http://arxiv.org/abs/2310.07664v1"}
{"created":"2023-10-11 17:00:29","title":"Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue","abstract":"Accurate knowledge selection is critical in knowledge-grounded dialogue systems. Towards a closer look at it, we offer a novel perspective to organize existing literature, i.e., knowledge selection coupled with, after, and before generation. We focus on the third under-explored category of study, which can not only select knowledge accurately in advance, but has the advantage to reduce the learning, adjustment, and interpretation burden of subsequent response generation models, especially LLMs. We propose GATE, a generator-agnostic knowledge selection method, to prepare knowledge for subsequent response generation models by selecting context-related knowledge among different knowledge structures and variable knowledge requirements. Experimental results demonstrate the superiority of GATE, and indicate that knowledge selection before generation is a lightweight yet effective way to facilitate LLMs (e.g., ChatGPT) to generate more informative responses.","sentences":["Accurate knowledge selection is critical in knowledge-grounded dialogue systems.","Towards a closer look at it, we offer a novel perspective to organize existing literature, i.e., knowledge selection coupled with, after, and before generation.","We focus on the third under-explored category of study, which can not only select knowledge accurately in advance, but has the advantage to reduce the learning, adjustment, and interpretation burden of subsequent response generation models, especially LLMs.","We propose GATE, a generator-agnostic knowledge selection method, to prepare knowledge for subsequent response generation models by selecting context-related knowledge among different knowledge structures and variable knowledge requirements.","Experimental results demonstrate the superiority of GATE, and indicate that knowledge selection before generation is a lightweight yet effective way to facilitate LLMs (e.g., ChatGPT) to generate more informative responses."],"url":"http://arxiv.org/abs/2310.07659v1"}
{"created":"2023-10-11 16:59:45","title":"Optimizing Throughput and Makespan of Queuing Systems by Information Design","abstract":"We study the optimal provision of information for two natural performance measures of queuing systems: throughput and makespan. A set of parallel links is equipped with deterministic capacities and stochastic travel times where the latter depend on a realized scenario. A continuum of flow particles arrives at the system at a constant rate. A system operator knows the realization of the scenario and may (partially) reveal this information via a public signaling scheme to the flow particles. Upon arrival, the flow particles observe the signal issued by the system operator, form an updated belief about the realized scenario, and decide on a link to use. Inflow into a link exceeding the link's capacity builds up in a queue that increases the travel time on the link. Dynamic inflow rates are in a Bayesian dynamic equilibrium when the expected travel time along all links with positive inflow is equal at every point in time. We provide an additive polynomial time approximation scheme (PTAS) that approximates the optimal throughput by an arbitrary additive constant $\\epsilon>0$. The algorithm solves a Langrangian dual of the signaling problem with the Ellipsoid method whose separation oracle is implemented by a cell decomposition technique. We also provide a multiplicative fully polynomial time approximation scheme (FPTAS) that does not rely on strong duality and, thus, allows to compute also the optimal signals. It uses a different cell decomposition technique together with a piece-wise convex under-estimator of the optimal value function. Finally, we consider the makespan of a Bayesian dynamic equilibrium which is defined as the last point in time when a total given value of flow leaves the system. Using a variational inequality argument, we show that full information revelation is a public signaling scheme that minimizes the makespan.","sentences":["We study the optimal provision of information for two natural performance measures of queuing systems: throughput and makespan.","A set of parallel links is equipped with deterministic capacities and stochastic travel times where the latter depend on a realized scenario.","A continuum of flow particles arrives at the system at a constant rate.","A system operator knows the realization of the scenario and may (partially) reveal this information via a public signaling scheme to the flow particles.","Upon arrival, the flow particles observe the signal issued by the system operator, form an updated belief about the realized scenario, and decide on a link to use.","Inflow into a link exceeding the link's capacity builds up in a queue that increases the travel time on the link.","Dynamic inflow rates are in a Bayesian dynamic equilibrium when the expected travel time along all links with positive inflow is equal at every point in time.","We provide an additive polynomial time approximation scheme (PTAS) that approximates the optimal throughput by an arbitrary additive constant $\\epsilon>0$. The algorithm solves a Langrangian dual of the signaling problem with the Ellipsoid method whose separation oracle is implemented by a cell decomposition technique.","We also provide a multiplicative fully polynomial time approximation scheme (FPTAS) that does not rely on strong duality and, thus, allows to compute also the optimal signals.","It uses a different cell decomposition technique together with a piece-wise convex under-estimator of the optimal value function.","Finally, we consider the makespan of a Bayesian dynamic equilibrium which is defined as the last point in time when a total given value of flow leaves the system.","Using a variational inequality argument, we show that full information revelation is a public signaling scheme that minimizes the makespan."],"url":"http://arxiv.org/abs/2310.07656v1"}
{"created":"2023-10-11 16:54:57","title":"Audio-Visual Neural Syntax Acquisition","abstract":"We study phrase structure induction from visually-grounded speech. The core idea is to first segment the speech waveform into sequences of word segments, and subsequently induce phrase structure using the inferred segment-level continuous representations. We present the Audio-Visual Neural Syntax Learner (AV-NSL) that learns phrase structure by listening to audio and looking at images, without ever being exposed to text. By training on paired images and spoken captions, AV-NSL exhibits the capability to infer meaningful phrase structures that are comparable to those derived by naturally-supervised text parsers, for both English and German. Our findings extend prior work in unsupervised language acquisition from speech and grounded grammar induction, and present one approach to bridge the gap between the two topics.","sentences":["We study phrase structure induction from visually-grounded speech.","The core idea is to first segment the speech waveform into sequences of word segments, and subsequently induce phrase structure using the inferred segment-level continuous representations.","We present the Audio-Visual Neural Syntax Learner (AV-NSL) that learns phrase structure by listening to audio and looking at images, without ever being exposed to text.","By training on paired images and spoken captions, AV-NSL exhibits the capability to infer meaningful phrase structures that are comparable to those derived by naturally-supervised text parsers, for both English and German.","Our findings extend prior work in unsupervised language acquisition from speech and grounded grammar induction, and present one approach to bridge the gap between the two topics."],"url":"http://arxiv.org/abs/2310.07654v1"}
{"created":"2023-10-11 16:53:40","title":"Mini-DALLE3: Interactive Text to Image by Prompting Large Language Models","abstract":"The revolution of artificial intelligence content generation has been rapidly accelerated with the booming text-to-image (T2I) diffusion models. Within just two years of development, it was unprecedentedly of high-quality, diversity, and creativity that the state-of-the-art models could generate. However, a prevalent limitation persists in the effective communication with these popular T2I models, such as Stable Diffusion, using natural language descriptions. This typically makes an engaging image hard to obtain without expertise in prompt engineering with complex word compositions, magic tags, and annotations. Inspired by the recently released DALLE3 - a T2I model directly built-in ChatGPT that talks human language, we revisit the existing T2I systems endeavoring to align human intent and introduce a new task - interactive text to image (iT2I), where people can interact with LLM for interleaved high-quality image generation/edit/refinement and question answering with stronger images and text correspondences using natural language. In addressing the iT2I problem, we present a simple approach that augments LLMs for iT2I with prompting techniques and off-the-shelf T2I models. We evaluate our approach for iT2I in a variety of common-used scenarios under different LLMs, e.g., ChatGPT, LLAMA, Baichuan, and InternLM. We demonstrate that our approach could be a convenient and low-cost way to introduce the iT2I ability for any existing LLMs and any text-to-image models without any training while bringing little degradation on LLMs' inherent capabilities in, e.g., question answering and code generation. We hope this work could draw broader attention and provide inspiration for boosting user experience in human-machine interactions alongside the image quality of the next-generation T2I systems.","sentences":["The revolution of artificial intelligence content generation has been rapidly accelerated with the booming text-to-image (T2I) diffusion models.","Within just two years of development, it was unprecedentedly of high-quality, diversity, and creativity that the state-of-the-art models could generate.","However, a prevalent limitation persists in the effective communication with these popular T2I models, such as Stable Diffusion, using natural language descriptions.","This typically makes an engaging image hard to obtain without expertise in prompt engineering with complex word compositions, magic tags, and annotations.","Inspired by the recently released DALLE3 - a T2I model directly built-in ChatGPT that talks human language, we revisit the existing T2I systems endeavoring to align human intent and introduce a new task - interactive text to image (iT2I), where people can interact with LLM for interleaved high-quality image generation/edit/refinement and question answering with stronger images and text correspondences using natural language.","In addressing the iT2I problem, we present a simple approach that augments LLMs for iT2I with prompting techniques and off-the-shelf T2I models.","We evaluate our approach for iT2I in a variety of common-used scenarios under different LLMs, e.g., ChatGPT, LLAMA, Baichuan, and InternLM.","We demonstrate that our approach could be a convenient and low-cost way to introduce the iT2I ability for any existing LLMs and any text-to-image models without any training while bringing little degradation on LLMs' inherent capabilities in, e.g., question answering and code generation.","We hope this work could draw broader attention and provide inspiration for boosting user experience in human-machine interactions alongside the image quality of the next-generation T2I systems."],"url":"http://arxiv.org/abs/2310.07653v1"}
{"created":"2023-10-11 16:51:46","title":"LLM4Vis: Explainable Visualization Recommendation using ChatGPT","abstract":"Data visualization is a powerful tool for exploring and communicating insights in various domains. To automate visualization choice for datasets, a task known as visualization recommendation has been proposed. Various machine-learning-based approaches have been developed for this purpose, but they often require a large corpus of dataset-visualization pairs for training and lack natural explanations for their results. To address this research gap, we propose LLM4Vis, a novel ChatGPT-based prompting approach to perform visualization recommendation and return human-like explanations using very few demonstration examples. Our approach involves feature description, demonstration example selection, explanation generation, demonstration example construction, and inference steps. To obtain demonstration examples with high-quality explanations, we propose a new explanation generation bootstrapping to iteratively refine generated explanations by considering the previous generation and template-based hint. Evaluations on the VizML dataset show that LLM4Vis outperforms or performs similarly to supervised learning models like Random Forest, Decision Tree, and MLP in both few-shot and zero-shot settings. The qualitative evaluation also shows the effectiveness of explanations generated by LLM4Vis. We make our code publicly available at \\href{https://github.com/demoleiwang/LLM4Vis}{https://github.com/demoleiwang/LLM4Vis}.","sentences":["Data visualization is a powerful tool for exploring and communicating insights in various domains.","To automate visualization choice for datasets, a task known as visualization recommendation has been proposed.","Various machine-learning-based approaches have been developed for this purpose, but they often require a large corpus of dataset-visualization pairs for training and lack natural explanations for their results.","To address this research gap, we propose LLM4Vis, a novel ChatGPT-based prompting approach to perform visualization recommendation and return human-like explanations using very few demonstration examples.","Our approach involves feature description, demonstration example selection, explanation generation, demonstration example construction, and inference steps.","To obtain demonstration examples with high-quality explanations, we propose a new explanation generation bootstrapping to iteratively refine generated explanations by considering the previous generation and template-based hint.","Evaluations on the VizML dataset show that LLM4Vis outperforms or performs similarly to supervised learning models like Random Forest, Decision Tree, and MLP in both few-shot and zero-shot settings.","The qualitative evaluation also shows the effectiveness of explanations generated by LLM4Vis.","We make our code publicly available at \\href{https://github.com/demoleiwang/LLM4Vis}{https://github.com/demoleiwang/LLM4Vis}."],"url":"http://arxiv.org/abs/2310.07652v1"}
{"created":"2023-10-11 16:46:44","title":"Automated Layout Design and Control of Robust Cooperative Grasped-Load Aerial Transportation Systems","abstract":"We present a novel approach to cooperative aerial transportation through a team of drones, using optimal control theory and a hierarchical control strategy. We assume the drones are connected to the payload through rigid attachments, essentially transforming the whole system into a larger flying object with \"thrust modules\" at the attachment locations of the drones. We investigate the optimal arrangement of the thrust modules around the payload, so that the resulting system is robust to disturbances. We choose the $\\mathcal{H}_2$ norm as a measure of robustness, and propose an iterative optimization routine to compute the optimal layout of the vehicles around the object. We experimentally validate our approach using four drones and comparing the disturbance rejection performances achieved by two different layouts (the optimal one and a sub-optimal one), and observe that the results match our predictions.","sentences":["We present a novel approach to cooperative aerial transportation through a team of drones, using optimal control theory and a hierarchical control strategy.","We assume the drones are connected to the payload through rigid attachments, essentially transforming the whole system into a larger flying object with \"thrust modules\" at the attachment locations of the drones.","We investigate the optimal arrangement of the thrust modules around the payload, so that the resulting system is robust to disturbances.","We choose the $\\mathcal{H}_2$ norm as a measure of robustness, and propose an iterative optimization routine to compute the optimal layout of the vehicles around the object.","We experimentally validate our approach using four drones and comparing the disturbance rejection performances achieved by two different layouts (the optimal one and a sub-optimal one), and observe that the results match our predictions."],"url":"http://arxiv.org/abs/2310.07649v1"}
{"created":"2023-10-11 16:45:44","title":"Hypercomplex Multimodal Emotion Recognition from EEG and Peripheral Physiological Signals","abstract":"Multimodal emotion recognition from physiological signals is receiving an increasing amount of attention due to the impossibility to control them at will unlike behavioral reactions, thus providing more reliable information. Existing deep learning-based methods still rely on extracted handcrafted features, not taking full advantage of the learning ability of neural networks, and often adopt a single-modality approach, while human emotions are inherently expressed in a multimodal way. In this paper, we propose a hypercomplex multimodal network equipped with a novel fusion module comprising parameterized hypercomplex multiplications. Indeed, by operating in a hypercomplex domain the operations follow algebraic rules which allow to model latent relations among learned feature dimensions for a more effective fusion step. We perform classification of valence and arousal from electroencephalogram (EEG) and peripheral physiological signals, employing the publicly available database MAHNOB-HCI surpassing a multimodal state-of-the-art network. The code of our work is freely available at https://github.com/ispamm/MHyEEG.","sentences":["Multimodal emotion recognition from physiological signals is receiving an increasing amount of attention due to the impossibility to control them at will unlike behavioral reactions, thus providing more reliable information.","Existing deep learning-based methods still rely on extracted handcrafted features, not taking full advantage of the learning ability of neural networks, and often adopt a single-modality approach, while human emotions are inherently expressed in a multimodal way.","In this paper, we propose a hypercomplex multimodal network equipped with a novel fusion module comprising parameterized hypercomplex multiplications.","Indeed, by operating in a hypercomplex domain the operations follow algebraic rules which allow to model latent relations among learned feature dimensions for a more effective fusion step.","We perform classification of valence and arousal from electroencephalogram (EEG) and peripheral physiological signals, employing the publicly available database MAHNOB-HCI surpassing a multimodal state-of-the-art network.","The code of our work is freely available at https://github.com/ispamm/MHyEEG."],"url":"http://arxiv.org/abs/2310.07648v1"}
{"created":"2023-10-11 16:44:36","title":"LEO Satellite Networking Relaunched: Survey and Current Research Challenges","abstract":"This document surveys recent and current developments in LEO satellite networking. It presents a brief overview of satellite networking in order to contextualize the issue. It then focuses on current research work in emerging domains, such as Machine Learning, SDN, low latency networking, green networking, Information-Centric Networks, etc. For each, it presents recent works and a direction of the research community within that emerging domain.   The paper also describes the current state of standardization efforts in 3GPP and in IETF for LEO satellite networking. In particular, we present in some detail the direction these standards body are pointing towards for LEO networking with inter-satellites links. Finally, some future challenges and interesting research directions are described and motivated. This is an overview of the current state of the LEO satellite research in both academic and industrial standardization environments which we believe will be helpful to understand the current state of the art.","sentences":["This document surveys recent and current developments in LEO satellite networking.","It presents a brief overview of satellite networking in order to contextualize the issue.","It then focuses on current research work in emerging domains, such as Machine Learning, SDN, low latency networking, green networking, Information-Centric Networks, etc.","For each, it presents recent works and a direction of the research community within that emerging domain.   ","The paper also describes the current state of standardization efforts in 3GPP and in IETF for LEO satellite networking.","In particular, we present in some detail the direction these standards body are pointing towards for LEO networking with inter-satellites links.","Finally, some future challenges and interesting research directions are described and motivated.","This is an overview of the current state of the LEO satellite research in both academic and industrial standardization environments which we believe will be helpful to understand the current state of the art."],"url":"http://arxiv.org/abs/2310.07646v1"}
{"created":"2023-10-11 16:40:57","title":"Rethinking the BERT-like Pretraining for DNA Sequences","abstract":"With the success of large-scale pretraining in NLP, there is an increasing trend of applying it to the domain of life sciences. In particular, pretraining methods based on DNA sequences have garnered growing attention due to their potential to capture generic information about genes. However, existing pretraining methods for DNA sequences largely rely on direct adoptions of BERT pretraining from NLP, lacking a comprehensive understanding and a specifically tailored approach. To address this research gap, we first conducted a series of exploratory experiments and gained several insightful observations: 1) In the fine-tuning phase of downstream tasks, when using K-mer overlapping tokenization instead of K-mer non-overlapping tokenization, both overlapping and non-overlapping pretraining weights show consistent performance improvement.2) During the pre-training process, using K-mer overlapping tokenization quickly produces clear K-mer embeddings and reduces the loss to a very low level, while using K-mer non-overlapping tokenization results in less distinct embeddings and continuously decreases the loss. 3) Using overlapping tokenization causes the self-attention in the intermediate layers of pre-trained models to tend to overly focus on certain tokens, reflecting that these layers are not adequately optimized. In summary, overlapping tokenization can benefit the fine-tuning of downstream tasks but leads to inadequate pretraining with fast convergence. To unleash the pretraining potential, we introduce a novel approach called RandomMask, which gradually increases the task difficulty of BERT-like pretraining by continuously expanding its mask boundary, forcing the model to learn more knowledge. RandomMask is simple but effective, achieving top-tier performance across 26 datasets of 28 datasets spanning 7 downstream tasks.","sentences":["With the success of large-scale pretraining in NLP, there is an increasing trend of applying it to the domain of life sciences.","In particular, pretraining methods based on DNA sequences have garnered growing attention due to their potential to capture generic information about genes.","However, existing pretraining methods for DNA sequences largely rely on direct adoptions of BERT pretraining from NLP, lacking a comprehensive understanding and a specifically tailored approach.","To address this research gap, we first conducted a series of exploratory experiments and gained several insightful observations: 1) In the fine-tuning phase of downstream tasks, when using K-mer overlapping tokenization instead of K-mer non-overlapping tokenization, both overlapping and non-overlapping pretraining weights show consistent performance improvement.2) During the pre-training process, using K-mer overlapping tokenization quickly produces clear K-mer embeddings and reduces the loss to a very low level, while using K-mer non-overlapping tokenization results in less distinct embeddings and continuously decreases the loss.","3) Using overlapping tokenization causes the self-attention in the intermediate layers of pre-trained models to tend to overly focus on certain tokens, reflecting that these layers are not adequately optimized.","In summary, overlapping tokenization can benefit the fine-tuning of downstream tasks but leads to inadequate pretraining with fast convergence.","To unleash the pretraining potential, we introduce a novel approach called RandomMask, which gradually increases the task difficulty of BERT-like pretraining by continuously expanding its mask boundary, forcing the model to learn more knowledge.","RandomMask is simple but effective, achieving top-tier performance across 26 datasets of 28 datasets spanning 7 downstream tasks."],"url":"http://arxiv.org/abs/2310.07644v1"}
{"created":"2023-10-11 16:38:11","title":"Evaluating Large Language Models at Evaluating Instruction Following","abstract":"As research in large language models (LLMs) continues to accelerate, LLM-based evaluation has emerged as a scalable and cost-effective alternative to human evaluations for comparing the ever increasing list of models. This paper investigates the efficacy of these \"LLM evaluators\", particularly in using them to assess instruction following, a metric that gauges how closely generated text adheres to the given instruction. We introduce a challenging meta-evaluation benchmark, LLMBar, designed to test the ability of an LLM evaluator in discerning instruction-following outputs. The authors manually curated 419 pairs of outputs, one adhering to instructions while the other diverging, yet may possess deceptive qualities that mislead an LLM evaluator, e.g., a more engaging tone. Contrary to existing meta-evaluation, we discover that different evaluators (i.e., combinations of LLMs and prompts) exhibit distinct performance on LLMBar and even the highest-scoring ones have substantial room for improvement. We also present a novel suite of prompting strategies that further close the gap between LLM and human evaluators. With LLMBar, we hope to offer more insight into LLM evaluators and foster future research in developing better instruction-following models.","sentences":["As research in large language models (LLMs) continues to accelerate, LLM-based evaluation has emerged as a scalable and cost-effective alternative to human evaluations for comparing the ever increasing list of models.","This paper investigates the efficacy of these \"LLM evaluators\", particularly in using them to assess instruction following, a metric that gauges how closely generated text adheres to the given instruction.","We introduce a challenging meta-evaluation benchmark, LLMBar, designed to test the ability of an LLM evaluator in discerning instruction-following outputs.","The authors manually curated 419 pairs of outputs, one adhering to instructions while the other diverging, yet may possess deceptive qualities that mislead an LLM evaluator, e.g., a more engaging tone.","Contrary to existing meta-evaluation, we discover that different evaluators (i.e., combinations of LLMs and prompts) exhibit distinct performance on LLMBar and even the highest-scoring ones have substantial room for improvement.","We also present a novel suite of prompting strategies that further close the gap between LLM and human evaluators.","With LLMBar, we hope to offer more insight into LLM evaluators and foster future research in developing better instruction-following models."],"url":"http://arxiv.org/abs/2310.07641v1"}
{"created":"2023-10-11 16:33:30","title":"Context-Enhanced Detector For Building Detection From Remote Sensing Images","abstract":"The field of building detection from remote sensing images has made significant progress, but faces challenges in achieving high-accuracy detection due to the diversity in building appearances and the complexity of vast scenes. To address these challenges, we propose a novel approach called Context-Enhanced Detector (CEDet). Our approach utilizes a three-stage cascade structure to enhance the extraction of contextual information and improve building detection accuracy. Specifically, we introduce two modules: the Semantic Guided Contextual Mining (SGCM) module, which aggregates multi-scale contexts and incorporates an attention mechanism to capture long-range interactions, and the Instance Context Mining Module (ICMM), which captures instance-level relationship context by constructing a spatial relationship graph and aggregating instance features. Additionally, we introduce a semantic segmentation loss based on pseudo-masks to guide contextual information extraction. Our method achieves state-of-the-art performance on three building detection benchmarks, including CNBuilding-9P, CNBuilding-23P, and SpaceNet.","sentences":["The field of building detection from remote sensing images has made significant progress, but faces challenges in achieving high-accuracy detection due to the diversity in building appearances and the complexity of vast scenes.","To address these challenges, we propose a novel approach called Context-Enhanced Detector (CEDet).","Our approach utilizes a three-stage cascade structure to enhance the extraction of contextual information and improve building detection accuracy.","Specifically, we introduce two modules: the Semantic Guided Contextual Mining (SGCM) module, which aggregates multi-scale contexts and incorporates an attention mechanism to capture long-range interactions, and the Instance Context Mining Module (ICMM), which captures instance-level relationship context by constructing a spatial relationship graph and aggregating instance features.","Additionally, we introduce a semantic segmentation loss based on pseudo-masks to guide contextual information extraction.","Our method achieves state-of-the-art performance on three building detection benchmarks, including CNBuilding-9P, CNBuilding-23P, and SpaceNet."],"url":"http://arxiv.org/abs/2310.07638v1"}
{"created":"2023-10-11 16:33:29","title":"OpsEval: A Comprehensive Task-Oriented AIOps Benchmark for Large Language Models","abstract":"Large language models (LLMs) have exhibited remarkable capabilities in NLP-related tasks such as translation, summarizing, and generation. The application of LLMs in specific areas, notably AIOps (Artificial Intelligence for IT Operations), holds great potential due to their advanced abilities in information summarizing, report analyzing, and ability of API calling. Nevertheless, the performance of current LLMs in AIOps tasks is yet to be determined. Furthermore, a comprehensive benchmark is required to steer the optimization of LLMs tailored for AIOps. Compared with existing benchmarks that focus on evaluating specific fields like network configuration, in this paper, we present \\textbf{OpsEval}, a comprehensive task-oriented AIOps benchmark designed for LLMs. For the first time, OpsEval assesses LLMs' proficiency in three crucial scenarios (Wired Network Operation, 5G Communication Operation, and Database Operation) at various ability levels (knowledge recall, analytical thinking, and practical application). The benchmark includes 7,200 questions in both multiple-choice and question-answer (QA) formats, available in English and Chinese. With quantitative and qualitative results, we show how various LLM tricks can affect the performance of AIOps, including zero-shot, chain-of-thought, and few-shot in-context learning. We find that GPT4-score is more consistent with experts than widely used Bleu and Rouge, which can be used to replace automatic metrics for large-scale qualitative evaluations.","sentences":["Large language models (LLMs) have exhibited remarkable capabilities in NLP-related tasks such as translation, summarizing, and generation.","The application of LLMs in specific areas, notably AIOps (Artificial Intelligence for IT Operations), holds great potential due to their advanced abilities in information summarizing, report analyzing, and ability of API calling.","Nevertheless, the performance of current LLMs in AIOps tasks is yet to be determined.","Furthermore, a comprehensive benchmark is required to steer the optimization of LLMs tailored for AIOps.","Compared with existing benchmarks that focus on evaluating specific fields like network configuration, in this paper, we present \\textbf{OpsEval}, a comprehensive task-oriented AIOps benchmark designed for LLMs.","For the first time, OpsEval assesses LLMs' proficiency in three crucial scenarios (Wired Network Operation, 5G Communication Operation, and Database Operation) at various ability levels (knowledge recall, analytical thinking, and practical application).","The benchmark includes 7,200 questions in both multiple-choice and question-answer (QA) formats, available in English and Chinese.","With quantitative and qualitative results, we show how various LLM tricks can affect the performance of AIOps, including zero-shot, chain-of-thought, and few-shot in-context learning.","We find that GPT4-score is more consistent with experts than widely used Bleu and Rouge, which can be used to replace automatic metrics for large-scale qualitative evaluations."],"url":"http://arxiv.org/abs/2310.07637v1"}
{"created":"2023-10-11 16:25:45","title":"Prompt Backdoors in Visual Prompt Learning","abstract":"Fine-tuning large pre-trained computer vision models is infeasible for resource-limited users. Visual prompt learning (VPL) has thus emerged to provide an efficient and flexible alternative to model fine-tuning through Visual Prompt as a Service (VPPTaaS). Specifically, the VPPTaaS provider optimizes a visual prompt given downstream data, and downstream users can use this prompt together with the large pre-trained model for prediction. However, this new learning paradigm may also pose security risks when the VPPTaaS provider instead provides a malicious visual prompt. In this paper, we take the first step to explore such risks through the lens of backdoor attacks. Specifically, we propose BadVisualPrompt, a simple yet effective backdoor attack against VPL. For example, poisoning $5\\%$ CIFAR10 training data leads to above $99\\%$ attack success rates with only negligible model accuracy drop by $1.5\\%$. In particular, we identify and then address a new technical challenge related to interactions between the backdoor trigger and visual prompt, which does not exist in conventional, model-level backdoors. Moreover, we provide in-depth analyses of seven backdoor defenses from model, prompt, and input levels. Overall, all these defenses are either ineffective or impractical to mitigate our BadVisualPrompt, implying the critical vulnerability of VPL.","sentences":["Fine-tuning large pre-trained computer vision models is infeasible for resource-limited users.","Visual prompt learning (VPL) has thus emerged to provide an efficient and flexible alternative to model fine-tuning through Visual Prompt as a Service (VPPTaaS).","Specifically, the VPPTaaS provider optimizes a visual prompt given downstream data, and downstream users can use this prompt together with the large pre-trained model for prediction.","However, this new learning paradigm may also pose security risks when the VPPTaaS provider instead provides a malicious visual prompt.","In this paper, we take the first step to explore such risks through the lens of backdoor attacks.","Specifically, we propose BadVisualPrompt, a simple yet effective backdoor attack against VPL.","For example, poisoning $5\\%$ CIFAR10 training data leads to above $99\\%$ attack success rates with only negligible model accuracy drop by $1.5\\%$. In particular, we identify and then address a new technical challenge related to interactions between the backdoor trigger and visual prompt, which does not exist in conventional, model-level backdoors.","Moreover, we provide in-depth analyses of seven backdoor defenses from model, prompt, and input levels.","Overall, all these defenses are either ineffective or impractical to mitigate our BadVisualPrompt, implying the critical vulnerability of VPL."],"url":"http://arxiv.org/abs/2310.07632v1"}
{"created":"2023-10-11 16:24:06","title":"Graph Transformer Network for Flood Forecasting with Heterogeneous Covariates","abstract":"Floods can be very destructive causing heavy damage to life, property, and livelihoods. Global climate change and the consequent sea-level rise have increased the occurrence of extreme weather events, resulting in elevated and frequent flood risk. Therefore, accurate and timely flood forecasting in coastal river systems is critical to facilitate good flood management. However, the computational tools currently used are either slow or inaccurate. In this paper, we propose a Flood prediction tool using Graph Transformer Network (FloodGTN) for river systems. More specifically, FloodGTN learns the spatio-temporal dependencies of water levels at different monitoring stations using Graph Neural Networks (GNNs) and an LSTM. It is currently implemented to consider external covariates such as rainfall, tide, and the settings of hydraulic structures (e.g., outflows of dams, gates, pumps, etc.) along the river. We use a Transformer to learn the attention given to external covariates in computing water levels. We apply the FloodGTN tool to data from the South Florida Water Management District, which manages a coastal area prone to frequent storms and hurricanes. Experimental results show that FloodGTN outperforms the physics-based model (HEC-RAS) by achieving higher accuracy with 70% improvement while speeding up run times by at least 500x.","sentences":["Floods can be very destructive causing heavy damage to life, property, and livelihoods.","Global climate change and the consequent sea-level rise have increased the occurrence of extreme weather events, resulting in elevated and frequent flood risk.","Therefore, accurate and timely flood forecasting in coastal river systems is critical to facilitate good flood management.","However, the computational tools currently used are either slow or inaccurate.","In this paper, we propose a Flood prediction tool using Graph Transformer Network (FloodGTN) for river systems.","More specifically, FloodGTN learns the spatio-temporal dependencies of water levels at different monitoring stations using Graph Neural Networks (GNNs) and an LSTM.","It is currently implemented to consider external covariates such as rainfall, tide, and the settings of hydraulic structures (e.g., outflows of dams, gates, pumps, etc.) along the river.","We use a Transformer to learn the attention given to external covariates in computing water levels.","We apply the FloodGTN tool to data from the South Florida Water Management District, which manages a coastal area prone to frequent storms and hurricanes.","Experimental results show that FloodGTN outperforms the physics-based model (HEC-RAS) by achieving higher accuracy with 70% improvement while speeding up run times by at least 500x."],"url":"http://arxiv.org/abs/2310.07631v1"}
{"created":"2023-10-11 16:23:07","title":"Differentiable Euler Characteristic Transforms for Shape Classification","abstract":"The Euler Characteristic Transform (ECT) has proven to be a powerful representation, combining geometrical and topological characteristics of shapes and graphs. However, the ECT was hitherto unable to learn task-specific representations. We overcome this issue and develop a novel computational layer that enables learning the ECT in an end-to-end fashion. Our method DECT is fast and computationally efficient, while exhibiting performance on a par with more complex models in both graph and point cloud classification tasks. Moreover, we show that this seemingly unexpressive statistic still provides the same topological expressivity as more complex topological deep learning layers provide.","sentences":["The Euler Characteristic Transform (ECT) has proven to be a powerful representation, combining geometrical and topological characteristics of shapes and graphs.","However, the ECT was hitherto unable to learn task-specific representations.","We overcome this issue and develop a novel computational layer that enables learning the ECT in an end-to-end fashion.","Our method DECT is fast and computationally efficient, while exhibiting performance on a par with more complex models in both graph and point cloud classification tasks.","Moreover, we show that this seemingly unexpressive statistic still provides the same topological expressivity as more complex topological deep learning layers provide."],"url":"http://arxiv.org/abs/2310.07630v1"}
{"created":"2023-10-11 16:18:13","title":"The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values","abstract":"Human feedback is increasingly used to steer the behaviours of Large Language Models (LLMs). However, it is unclear how to collect and incorporate feedback in a way that is efficient, effective and unbiased, especially for highly subjective human preferences and values. In this paper, we survey existing approaches for learning from human feedback, drawing on 95 papers primarily from the ACL and arXiv repositories.First, we summarise the past, pre-LLM trends for integrating human feedback into language models. Second, we give an overview of present techniques and practices, as well as the motivations for using feedback; conceptual frameworks for defining values and preferences; and how feedback is collected and from whom. Finally, we encourage a better future of feedback learning in LLMs by raising five unresolved conceptual and practical challenges.","sentences":["Human feedback is increasingly used to steer the behaviours of Large Language Models (LLMs).","However, it is unclear how to collect and incorporate feedback in a way that is efficient, effective and unbiased, especially for highly subjective human preferences and values.","In this paper, we survey existing approaches for learning from human feedback, drawing on 95 papers primarily from the ACL and arXiv repositories.","First, we summarise the past, pre-LLM trends for integrating human feedback into language models.","Second, we give an overview of present techniques and practices, as well as the motivations for using feedback; conceptual frameworks for defining values and preferences; and how feedback is collected and from whom.","Finally, we encourage a better future of feedback learning in LLMs by raising five unresolved conceptual and practical challenges."],"url":"http://arxiv.org/abs/2310.07629v1"}
{"created":"2023-10-11 16:09:09","title":"Unsupervised Learning of Sea Surface Height Interpolation from Multi-variate Simulated Satellite Observations","abstract":"Satellite-based remote sensing missions have revolutionized our understanding of the Ocean state and dynamics. Among them, spaceborne altimetry provides valuable measurements of Sea Surface Height (SSH), which is used to estimate surface geostrophic currents. However, due to the sensor technology employed, important gaps occur in SSH observations. Complete SSH maps are produced by the altimetry community using linear Optimal Interpolations (OI) such as the widely-used Data Unification and Altimeter Combination System (DUACS). However, OI is known for producing overly smooth fields and thus misses some mesostructures and eddies. On the other hand, Sea Surface Temperature (SST) products have much higher data coverage and SST is physically linked to geostrophic currents through advection. We design a realistic twin experiment to emulate the satellite observations of SSH and SST to evaluate interpolation methods. We introduce a deep learning network able to use SST information, and a trainable in two settings: one where we have no access to ground truth during training and one where it is accessible. Our investigation involves a comparative analysis of the aforementioned network when trained using either supervised or unsupervised loss functions. We assess the quality of SSH reconstructions and further evaluate the network's performance in terms of eddy detection and physical properties. We find that it is possible, even in an unsupervised setting to use SST to improve reconstruction performance compared to SST-agnostic interpolations. We compare our reconstructions to DUACS's and report a decrease of 41\\% in terms of root mean squared error.","sentences":["Satellite-based remote sensing missions have revolutionized our understanding of the Ocean state and dynamics.","Among them, spaceborne altimetry provides valuable measurements of Sea Surface Height (SSH), which is used to estimate surface geostrophic currents.","However, due to the sensor technology employed, important gaps occur in SSH observations.","Complete SSH maps are produced by the altimetry community using linear Optimal Interpolations (OI) such as the widely-used Data Unification and Altimeter Combination System (DUACS).","However, OI is known for producing overly smooth fields and thus misses some mesostructures and eddies.","On the other hand, Sea Surface Temperature (SST) products have much higher data coverage and SST is physically linked to geostrophic currents through advection.","We design a realistic twin experiment to emulate the satellite observations of SSH and SST to evaluate interpolation methods.","We introduce a deep learning network able to use SST information, and a trainable in two settings: one where we have no access to ground truth during training and one where it is accessible.","Our investigation involves a comparative analysis of the aforementioned network when trained using either supervised or unsupervised loss functions.","We assess the quality of SSH reconstructions and further evaluate the network's performance in terms of eddy detection and physical properties.","We find that it is possible, even in an unsupervised setting to use SST to improve reconstruction performance compared to SST-agnostic interpolations.","We compare our reconstructions to DUACS's and report a decrease of 41\\% in terms of root mean squared error."],"url":"http://arxiv.org/abs/2310.07626v1"}
{"created":"2023-10-11 16:07:42","title":"Cybersecurity as a Crosscutting Concept Across an Undergrad Computer Science Curriculum: An Experience Report","abstract":"Although many Computer Science (CS) programs offer cybersecurity courses, they are typically optional and placed at the periphery of the program. We advocate to integrate cybersecurity as a crosscutting concept in CS curricula, which is also consistent with latest cybersecurity curricular guidelines, e.g., CSEC2017. We describe our experience of implementing this crosscutting intervention across three undergraduate core CS courses at a leading technical university in Europe between 2018 and 2023, collectively educating over 2200 students. The security education was incorporated within CS courses using a partnership between the responsible course instructor and a security expert, i.e., the security expert (after consultation with course instructors) developed and taught lectures covering multiple CSEC2017 knowledge areas. This created a complex dynamic between three stakeholders: the course instructor, the security expert, and the students. We reflect on our intervention from the perspective of the three stakeholders -- we conducted a post-course survey to collect student perceptions, and semi-supervised interviews with responsible course instructors and the security expert to gauge their experience. We found that while the students were extremely enthusiastic about the security content and retained its impact several years later, the misaligned incentives for the instructors and the security expert made it difficult to sustain this intervention without organizational support. By identifying limitations in our intervention, we suggest ideas for sustaining it.","sentences":["Although many Computer Science (CS) programs offer cybersecurity courses, they are typically optional and placed at the periphery of the program.","We advocate to integrate cybersecurity as a crosscutting concept in CS curricula, which is also consistent with latest cybersecurity curricular guidelines, e.g., CSEC2017.","We describe our experience of implementing this crosscutting intervention across three undergraduate core CS courses at a leading technical university in Europe between 2018 and 2023, collectively educating over 2200 students.","The security education was incorporated within CS courses using a partnership between the responsible course instructor and a security expert, i.e., the security expert (after consultation with course instructors) developed and taught lectures covering multiple CSEC2017 knowledge areas.","This created a complex dynamic between three stakeholders: the course instructor, the security expert, and the students.","We reflect on our intervention from the perspective of the three stakeholders -- we conducted a post-course survey to collect student perceptions, and semi-supervised interviews with responsible course instructors and the security expert to gauge their experience.","We found that while the students were extremely enthusiastic about the security content and retained its impact several years later, the misaligned incentives for the instructors and the security expert made it difficult to sustain this intervention without organizational support.","By identifying limitations in our intervention, we suggest ideas for sustaining it."],"url":"http://arxiv.org/abs/2310.07625v1"}
{"created":"2023-10-11 16:06:14","title":"Dual Quaternion Rotational and Translational Equivariance in 3D Rigid Motion Modelling","abstract":"Objects' rigid motions in 3D space are described by rotations and translations of a highly-correlated set of points, each with associated $x,y,z$ coordinates that real-valued networks consider as separate entities, losing information. Previous works exploit quaternion algebra and their ability to model rotations in 3D space. However, these algebras do not properly encode translations, leading to sub-optimal performance in 3D learning tasks. To overcome these limitations, we employ a dual quaternion representation of rigid motions in the 3D space that jointly describes rotations and translations of point sets, processing each of the points as a single entity. Our approach is translation and rotation equivariant, so it does not suffer from shifts in the data and better learns object trajectories, as we validate in the experimental evaluations. Models endowed with this formulation outperform previous approaches in a human pose forecasting application, attesting to the effectiveness of the proposed dual quaternion formulation for rigid motions in 3D space.","sentences":["Objects' rigid motions in 3D space are described by rotations and translations of a highly-correlated set of points, each with associated $x,y,z$ coordinates that real-valued networks consider as separate entities, losing information.","Previous works exploit quaternion algebra and their ability to model rotations in 3D space.","However, these algebras do not properly encode translations, leading to sub-optimal performance in 3D learning tasks.","To overcome these limitations, we employ a dual quaternion representation of rigid motions in the 3D space that jointly describes rotations and translations of point sets, processing each of the points as a single entity.","Our approach is translation and rotation equivariant, so it does not suffer from shifts in the data and better learns object trajectories, as we validate in the experimental evaluations.","Models endowed with this formulation outperform previous approaches in a human pose forecasting application, attesting to the effectiveness of the proposed dual quaternion formulation for rigid motions in 3D space."],"url":"http://arxiv.org/abs/2310.07623v1"}
{"created":"2023-10-11 16:04:02","title":"AG-CVG: Coverage Planning with a Mobile Recharging UGV and an Energy-Constrained UAV","abstract":"In this paper, we present an approach for coverage path planning for a team of an energy-constrained Unmanned Aerial Vehicle (UAV) and an Unmanned Ground Vehicle (UGV). Both the UAV and the UGV have predefined areas that they have to cover. The goal is to perform complete coverage by both robots while minimizing the coverage time. The UGV can also serve as a mobile recharging station. The UAV and UGV need to occasionally rendezvous for recharging. We propose a heuristic method to address this NP-Hard planning problem. Our approach involves initially determining coverage paths without factoring in energy constraints. Subsequently, we cluster segments of these paths and employ graph matching to assign UAV clusters to UGV clusters for efficient recharging management. We perform numerical analysis on real-world coverage applications and show that compared with a greedy approach our method reduces rendezvous overhead on average by 11.33\\%. We demonstrate proof-of-concept with a team of a VOXL m500 drone and a Clearpath Jackal ground vehicle, providing a complete system from the offline algorithm to the field execution.","sentences":["In this paper, we present an approach for coverage path planning for a team of an energy-constrained Unmanned Aerial Vehicle (UAV) and an Unmanned Ground Vehicle (UGV).","Both the UAV and the UGV have predefined areas that they have to cover.","The goal is to perform complete coverage by both robots while minimizing the coverage time.","The UGV can also serve as a mobile recharging station.","The UAV and UGV need to occasionally rendezvous for recharging.","We propose a heuristic method to address this NP-Hard planning problem.","Our approach involves initially determining coverage paths without factoring in energy constraints.","Subsequently, we cluster segments of these paths and employ graph matching to assign UAV clusters to UGV clusters for efficient recharging management.","We perform numerical analysis on real-world coverage applications and show that compared with a greedy approach our method reduces rendezvous overhead on average by 11.33\\%.","We demonstrate proof-of-concept with a team of a VOXL m500 drone and a Clearpath Jackal ground vehicle, providing a complete system from the offline algorithm to the field execution."],"url":"http://arxiv.org/abs/2310.07621v1"}
{"created":"2023-10-11 15:58:31","title":"Reinforcement Learning-based Knowledge Graph Reasoning for Explainable Fact-checking","abstract":"Fact-checking is a crucial task as it ensures the prevention of misinformation. However, manual fact-checking cannot keep up with the rate at which false information is generated and disseminated online. Automated fact-checking by machines is significantly quicker than by humans. But for better trust and transparency of these automated systems, explainability in the fact-checking process is necessary. Fact-checking often entails contrasting a factual assertion with a body of knowledge for such explanations. An effective way of representing knowledge is the Knowledge Graph (KG). There have been sufficient works proposed related to fact-checking with the usage of KG but not much focus is given to the application of reinforcement learning (RL) in such cases. To mitigate this gap, we propose an RL-based KG reasoning approach for explainable fact-checking. Extensive experiments on FB15K-277 and NELL-995 datasets reveal that reasoning over a KG is an effective way of producing human-readable explanations in the form of paths and classifications for fact claims. The RL reasoning agent computes a path that either proves or disproves a factual claim, but does not provide a verdict itself. A verdict is reached by a voting mechanism that utilizes paths produced by the agent. These paths can be presented to human readers so that they themselves can decide whether or not the provided evidence is convincing or not. This work will encourage works in this direction for incorporating RL for explainable fact-checking as it increases trustworthiness by providing a human-in-the-loop approach.","sentences":["Fact-checking is a crucial task as it ensures the prevention of misinformation.","However, manual fact-checking cannot keep up with the rate at which false information is generated and disseminated online.","Automated fact-checking by machines is significantly quicker than by humans.","But for better trust and transparency of these automated systems, explainability in the fact-checking process is necessary.","Fact-checking often entails contrasting a factual assertion with a body of knowledge for such explanations.","An effective way of representing knowledge is the Knowledge Graph (KG).","There have been sufficient works proposed related to fact-checking with the usage of KG but not much focus is given to the application of reinforcement learning (RL) in such cases.","To mitigate this gap, we propose an RL-based KG reasoning approach for explainable fact-checking.","Extensive experiments on FB15K-277 and NELL-995 datasets reveal that reasoning over a KG is an effective way of producing human-readable explanations in the form of paths and classifications for fact claims.","The RL reasoning agent computes a path that either proves or disproves a factual claim, but does not provide a verdict itself.","A verdict is reached by a voting mechanism that utilizes paths produced by the agent.","These paths can be presented to human readers so that they themselves can decide whether or not the provided evidence is convincing or not.","This work will encourage works in this direction for incorporating RL for explainable fact-checking as it increases trustworthiness by providing a human-in-the-loop approach."],"url":"http://arxiv.org/abs/2310.07613v1"}
{"created":"2023-10-11 15:56:55","title":"PHYDI: Initializing Parameterized Hypercomplex Neural Networks as Identity Functions","abstract":"Neural models based on hypercomplex algebra systems are growing and prolificating for a plethora of applications, ranging from computer vision to natural language processing. Hand in hand with their adoption, parameterized hypercomplex neural networks (PHNNs) are growing in size and no techniques have been adopted so far to control their convergence at a large scale. In this paper, we study PHNNs convergence and propose parameterized hypercomplex identity initialization (PHYDI), a method to improve their convergence at different scales, leading to more robust performance when the number of layers scales up, while also reaching the same performance with fewer iterations. We show the effectiveness of this approach in different benchmarks and with common PHNNs with ResNets- and Transformer-based architecture. The code is available at https://github.com/ispamm/PHYDI.","sentences":["Neural models based on hypercomplex algebra systems are growing and prolificating for a plethora of applications, ranging from computer vision to natural language processing.","Hand in hand with their adoption, parameterized hypercomplex neural networks (PHNNs) are growing in size and no techniques have been adopted so far to control their convergence at a large scale.","In this paper, we study PHNNs convergence and propose parameterized hypercomplex identity initialization (PHYDI), a method to improve their convergence at different scales, leading to more robust performance when the number of layers scales up, while also reaching the same performance with fewer iterations.","We show the effectiveness of this approach in different benchmarks and with common PHNNs with ResNets- and Transformer-based architecture.","The code is available at https://github.com/ispamm/PHYDI."],"url":"http://arxiv.org/abs/2310.07612v1"}
{"created":"2023-10-11 15:56:00","title":"Democratizing LLMs: An Exploration of Cost-Performance Trade-offs in Self-Refined Open-Source Models","abstract":"The dominance of proprietary LLMs has led to restricted access and raised information privacy concerns. High-performing open-source alternatives are crucial for information-sensitive and high-volume applications but often lag behind in performance. To address this gap, we propose (1) A untargeted variant of iterative self-critique and self-refinement devoid of external influence. (2) A novel ranking metric - Performance, Refinement, and Inference Cost Score (PeRFICS) - to find the optimal model for a given task considering refined performance and cost. Our experiments show that SoTA open source models of varying sizes from 7B - 65B, on average, improve 8.2% from their baseline performance. Strikingly, even models with extremely small memory footprints, such as Vicuna-7B, show a 11.74% improvement overall and up to a 25.39% improvement in high-creativity, open ended tasks on the Vicuna benchmark. Vicuna-13B takes it a step further and outperforms ChatGPT post-refinement. This work has profound implications for resource-constrained and information-sensitive environments seeking to leverage LLMs without incurring prohibitive costs, compromising on performance and privacy. The domain-agnostic self-refinement process coupled with our novel ranking metric facilitates informed decision-making in model selection, thereby reducing costs and democratizing access to high-performing language models, as evidenced by case studies.","sentences":["The dominance of proprietary LLMs has led to restricted access and raised information privacy concerns.","High-performing open-source alternatives are crucial for information-sensitive and high-volume applications but often lag behind in performance.","To address this gap, we propose (1) A untargeted variant of iterative self-critique and self-refinement devoid of external influence.","(2) A novel ranking metric - Performance, Refinement, and Inference Cost Score (PeRFICS) - to find the optimal model for a given task considering refined performance and cost.","Our experiments show that SoTA open source models of varying sizes from 7B - 65B, on average, improve 8.2% from their baseline performance.","Strikingly, even models with extremely small memory footprints, such as Vicuna-7B, show a 11.74% improvement overall and up to a 25.39% improvement in high-creativity, open ended tasks on the Vicuna benchmark.","Vicuna-13B takes it a step further and outperforms ChatGPT post-refinement.","This work has profound implications for resource-constrained and information-sensitive environments seeking to leverage LLMs without incurring prohibitive costs, compromising on performance and privacy.","The domain-agnostic self-refinement process coupled with our novel ranking metric facilitates informed decision-making in model selection, thereby reducing costs and democratizing access to high-performing language models, as evidenced by case studies."],"url":"http://arxiv.org/abs/2310.07611v1"}
{"created":"2023-10-11 15:51:53","title":"QACHECK: A Demonstration System for Question-Guided Multi-Hop Fact-Checking","abstract":"Fact-checking real-world claims often requires complex, multi-step reasoning due to the absence of direct evidence to support or refute them. However, existing fact-checking systems often lack transparency in their decision-making, making it challenging for users to comprehend their reasoning process. To address this, we propose the Question-guided Multi-hop Fact-Checking (QACHECK) system, which guides the model's reasoning process by asking a series of questions critical for verifying a claim. QACHECK has five key modules: a claim verifier, a question generator, a question-answering module, a QA validator, and a reasoner. Users can input a claim into QACHECK, which then predicts its veracity and provides a comprehensive report detailing its reasoning process, guided by a sequence of (question, answer) pairs. QACHECK also provides the source of evidence supporting each question, fostering a transparent, explainable, and user-friendly fact-checking process. A recorded video of QACHECK is at https://www.youtube.com/watch?v=ju8kxSldM64","sentences":["Fact-checking real-world claims often requires complex, multi-step reasoning due to the absence of direct evidence to support or refute them.","However, existing fact-checking systems often lack transparency in their decision-making, making it challenging for users to comprehend their reasoning process.","To address this, we propose the Question-guided Multi-hop Fact-Checking (QACHECK) system, which guides the model's reasoning process by asking a series of questions critical for verifying a claim.","QACHECK has five key modules: a claim verifier, a question generator, a question-answering module, a QA validator, and a reasoner.","Users can input a claim into QACHECK, which then predicts its veracity and provides a comprehensive report detailing its reasoning process, guided by a sequence of (question, answer) pairs.","QACHECK also provides the source of evidence supporting each question, fostering a transparent, explainable, and user-friendly fact-checking process.","A recorded video of QACHECK is at https://www.youtube.com/watch?v=ju8kxSldM64"],"url":"http://arxiv.org/abs/2310.07609v1"}
{"created":"2023-10-11 15:50:41","title":"Leader-Follower Formation Control of Perturbed Nonholonomic Agents along Parametric Curves with Directed Communication","abstract":"In this paper, we propose a novel formation controller for nonholonomic agents to form general parametric curves. First, we derive a unified parametric representation for both open and closed curves. Then, a leader-follower formation controller is designed to form the parametric curves. We consider directed communications and constant input disturbances rejection in the controller design. Rigorous Lyapunov-based stability analysis proves the asymptotic stability of the proposed controller. Detailed numerical simulations and experimental studies are conducted to verify the performance of the proposed method.","sentences":["In this paper, we propose a novel formation controller for nonholonomic agents to form general parametric curves.","First, we derive a unified parametric representation for both open and closed curves.","Then, a leader-follower formation controller is designed to form the parametric curves.","We consider directed communications and constant input disturbances rejection in the controller design.","Rigorous Lyapunov-based stability analysis proves the asymptotic stability of the proposed controller.","Detailed numerical simulations and experimental studies are conducted to verify the performance of the proposed method."],"url":"http://arxiv.org/abs/2310.07608v1"}
{"created":"2023-10-11 15:41:52","title":"Dual Radar: A Multi-modal Dataset with Dual 4D Radar for Autononous Driving","abstract":"Radar has stronger adaptability in adverse scenarios for autonomous driving environmental perception compared to widely adopted cameras and LiDARs. Compared with commonly used 3D radars, latest 4D radars have precise vertical resolution and higher point cloud density, making it a highly promising sensor for autonomous driving in complex environmental perception. However, due to the much higher noise than LiDAR, manufacturers choose different filtering strategies, resulting in an inverse ratio between noise level and point cloud density. There is still a lack of comparative analysis on which method is beneficial for deep learning-based perception algorithms in autonomous driving. One of the main reasons is that current datasets only adopt one type of 4D radar, making it difficult to compare different 4D radars in the same scene. Therefore, in this paper, we introduce a novel large-scale multi-modal dataset featuring, for the first time, two types of 4D radars captured simultaneously. This dataset enables further research into effective 4D radar perception algorithms.Our dataset consists of 151 consecutive series, most of which last 20 seconds and contain 10,007 meticulously synchronized and annotated frames. Moreover, our dataset captures a variety of challenging driving scenarios, including many road conditions, weather conditions, nighttime and daytime with different lighting intensities and periods. Our dataset annotates consecutive frames, which can be applied to 3D object detection and tracking, and also supports the study of multi-modal tasks. We experimentally validate our dataset, providing valuable results for studying different types of 4D radars. This dataset is released on https://github.com/adept-thu/Dual-Radar.","sentences":["Radar has stronger adaptability in adverse scenarios for autonomous driving environmental perception compared to widely adopted cameras and LiDARs.","Compared with commonly used 3D radars, latest 4D radars have precise vertical resolution and higher point cloud density, making it a highly promising sensor for autonomous driving in complex environmental perception.","However, due to the much higher noise than LiDAR, manufacturers choose different filtering strategies, resulting in an inverse ratio between noise level and point cloud density.","There is still a lack of comparative analysis on which method is beneficial for deep learning-based perception algorithms in autonomous driving.","One of the main reasons is that current datasets only adopt one type of 4D radar, making it difficult to compare different 4D radars in the same scene.","Therefore, in this paper, we introduce a novel large-scale multi-modal dataset featuring, for the first time, two types of 4D radars captured simultaneously.","This dataset enables further research into effective 4D radar perception algorithms.","Our dataset consists of 151 consecutive series, most of which last 20 seconds and contain 10,007 meticulously synchronized and annotated frames.","Moreover, our dataset captures a variety of challenging driving scenarios, including many road conditions, weather conditions, nighttime and daytime with different lighting intensities and periods.","Our dataset annotates consecutive frames, which can be applied to 3D object detection and tracking, and also supports the study of multi-modal tasks.","We experimentally validate our dataset, providing valuable results for studying different types of 4D radars.","This dataset is released on https://github.com/adept-thu/Dual-Radar."],"url":"http://arxiv.org/abs/2310.07602v1"}
{"created":"2023-10-11 15:38:53","title":"Survey on Imbalanced Data, Representation Learning and SEP Forecasting","abstract":"Deep Learning methods have significantly advanced various data-driven tasks such as regression, classification, and forecasting. However, much of this progress has been predicated on the strong but often unrealistic assumption that training datasets are balanced with respect to the targets they contain. This misalignment with real-world conditions, where data is frequently imbalanced, hampers the effectiveness of such models in practical applications. Methods that reconsider that assumption and tackle real-world imbalances have begun to emerge and explore avenues to address this challenge. One such promising avenue is representation learning, which enables models to capture complex data characteristics and generalize better to minority classes. By focusing on a richer representation of the feature space, these techniques hold the potential to mitigate the impact of data imbalance. In this survey, we present deep learning works that step away from the balanced-data assumption, employing strategies like representation learning to better approximate real-world imbalances. We also highlight a critical application in SEP forecasting where addressing data imbalance is paramount for success.","sentences":["Deep Learning methods have significantly advanced various data-driven tasks such as regression, classification, and forecasting.","However, much of this progress has been predicated on the strong but often unrealistic assumption that training datasets are balanced with respect to the targets they contain.","This misalignment with real-world conditions, where data is frequently imbalanced, hampers the effectiveness of such models in practical applications.","Methods that reconsider that assumption and tackle real-world imbalances have begun to emerge and explore avenues to address this challenge.","One such promising avenue is representation learning, which enables models to capture complex data characteristics and generalize better to minority classes.","By focusing on a richer representation of the feature space, these techniques hold the potential to mitigate the impact of data imbalance.","In this survey, we present deep learning works that step away from the balanced-data assumption, employing strategies like representation learning to better approximate real-world imbalances.","We also highlight a critical application in SEP forecasting where addressing data imbalance is paramount for success."],"url":"http://arxiv.org/abs/2310.07598v1"}
{"created":"2023-10-11 15:37:31","title":"Prospective Side Information for Latent MDPs","abstract":"In many interactive decision-making settings, there is latent and unobserved information that remains fixed. Consider, for example, a dialogue system, where complete information about a user, such as the user's preferences, is not given. In such an environment, the latent information remains fixed throughout each episode, since the identity of the user does not change during an interaction. This type of environment can be modeled as a Latent Markov Decision Process (LMDP), a special instance of Partially Observed Markov Decision Processes (POMDPs). Previous work established exponential lower bounds in the number of latent contexts for the LMDP class. This puts forward a question: under which natural assumptions a near-optimal policy of an LMDP can be efficiently learned? In this work, we study the class of LMDPs with {\\em prospective side information}, when an agent receives additional, weakly revealing, information on the latent context at the beginning of each episode. We show that, surprisingly, this problem is not captured by contemporary settings and algorithms designed for partially observed environments. We then establish that any sample efficient algorithm must suffer at least $\\Omega(K^{2/3})$-regret, as opposed to standard $\\Omega(\\sqrt{K})$ lower bounds, and design an algorithm with a matching upper bound.","sentences":["In many interactive decision-making settings, there is latent and unobserved information that remains fixed.","Consider, for example, a dialogue system, where complete information about a user, such as the user's preferences, is not given.","In such an environment, the latent information remains fixed throughout each episode, since the identity of the user does not change during an interaction.","This type of environment can be modeled as a Latent Markov Decision Process (LMDP), a special instance of Partially Observed Markov Decision Processes (POMDPs).","Previous work established exponential lower bounds in the number of latent contexts for the LMDP class.","This puts forward a question: under which natural assumptions a near-optimal policy of an LMDP can be efficiently learned?","In this work, we study the class of LMDPs with {\\em prospective side information}, when an agent receives additional, weakly revealing, information on the latent context at the beginning of each episode.","We show that, surprisingly, this problem is not captured by contemporary settings and algorithms designed for partially observed environments.","We then establish that any sample efficient algorithm must suffer at least $\\Omega(K^{2/3})$-regret, as opposed to standard $\\Omega(\\sqrt{K})$ lower bounds, and design an algorithm with a matching upper bound."],"url":"http://arxiv.org/abs/2310.07596v1"}
{"created":"2023-10-11 15:37:22","title":"Approximating Subset Sum Ratio faster than Subset Sum","abstract":"Subset Sum Ratio is the following optimization problem: Given a set of $n$ positive numbers $I$, find disjoint subsets $X,Y \\subseteq I$ minimizing the ratio $\\max\\{\\Sigma(X)/\\Sigma(Y),\\Sigma(Y)/\\Sigma(X)\\}$, where $\\Sigma(Z)$ denotes the sum of all elements of $Z$. Subset Sum Ratio is an optimization variant of the Equal Subset Sum problem. It was introduced by Woeginger and Yu in '92 and is known to admit an FPTAS [Bazgan, Santha, Tuza '98]. The best approximation schemes before this work had running time $O(n^4/\\varepsilon)$ [Melissinos, Pagourtzis '18], $\\tilde O(n^{2.3}/\\varepsilon^{2.6})$ and $\\tilde O(n^2/\\varepsilon^3)$ [Alonistiotis et al. '22].   In this work, we present an improved approximation scheme for Subset Sum Ratio running in time $O(n / \\varepsilon^{0.9386})$. Here we assume that the items are given in sorted order, otherwise we need an additional running time of $O(n \\log n)$ for sorting. Our improved running time simultaneously improves the dependence on $n$ to linear and the dependence on $1/\\varepsilon$ to sublinear.   For comparison, the related Subset Sum problem admits an approximation scheme running in time $O(n/\\varepsilon)$ [Gens, Levner '79]. If one would achieve an approximation scheme with running time $\\tilde O(n / \\varepsilon^{0.99})$ for Subset Sum, then one would falsify the Strong Exponential Time Hypothesis [Abboud, Bringmann, Hermelin, Shabtay '19] as well as the Min-Plus-Convolution Hypothesis [Bringmann, Nakos '21]. We thus establish that Subset Sum Ratio admits faster approximation schemes than Subset Sum. This comes as a surprise, since at any point in time before this work the best known approximation scheme for Subset Sum Ratio had a worse running time than the best known approximation scheme for Subset Sum.","sentences":["Subset Sum Ratio is the following optimization problem: Given a set of $n$ positive numbers $I$, find disjoint subsets $X,Y \\subseteq I$ minimizing the ratio $\\max\\{\\Sigma(X)/\\Sigma(Y),\\Sigma(Y)/\\Sigma(X)\\}$, where $\\Sigma(Z)$ denotes the sum of all elements of $Z$. Subset Sum Ratio is an optimization variant of the Equal Subset Sum problem.","It was introduced by Woeginger and Yu in '92 and is known to admit an FPTAS [Bazgan, Santha, Tuza '98].","The best approximation schemes before this work had running time $O(n^4/\\varepsilon)$ [Melissinos, Pagourtzis '18], $\\tilde O(n^{2.3}/\\varepsilon^{2.6})$ and $\\tilde O(n^2/\\varepsilon^3)$","[Alonistiotis et al. '22].   ","In this work, we present an improved approximation scheme for Subset Sum Ratio running in time $O(n / \\varepsilon^{0.9386})$. Here we assume that the items are given in sorted order, otherwise we need an additional running time of $O(n \\log n)$ for sorting.","Our improved running time simultaneously improves the dependence on $n$ to linear and the dependence on $1/\\varepsilon$ to sublinear.   ","For comparison, the related Subset Sum problem admits an approximation scheme running in time $O(n/\\varepsilon)$ [Gens, Levner '79].","If one would achieve an approximation scheme with running time $\\tilde O(n / \\varepsilon^{0.99})$ for Subset Sum, then one would falsify the Strong Exponential Time Hypothesis [Abboud, Bringmann, Hermelin, Shabtay '19] as well as the Min-Plus-Convolution Hypothesis [Bringmann, Nakos '21].","We thus establish that Subset Sum Ratio admits faster approximation schemes than Subset Sum.","This comes as a surprise, since at any point in time before this work the best known approximation scheme for Subset Sum Ratio had a worse running time than the best known approximation scheme for Subset Sum."],"url":"http://arxiv.org/abs/2310.07595v1"}
{"created":"2023-10-11 15:35:20","title":"Transformers for Green Semantic Communication: Less Energy, More Semantics","abstract":"Semantic communication aims to transmit meaningful and effective information rather than focusing on individual symbols or bits, resulting in benefits like reduced latency, bandwidth usage, and higher throughput compared to traditional communication. However, semantic communication poses significant challenges due to the need for universal metrics for benchmarking the joint effects of semantic information loss and practical energy consumption. This research presents a novel multi-objective loss function named \"Energy-Optimized Semantic Loss\" (EOSL), addressing the challenge of balancing semantic information loss and energy consumption. Through comprehensive experiments on transformer models, including CPU and GPU energy usage, it is demonstrated that EOSL-based encoder model selection can save up to 90\\% of energy while achieving a 44\\% improvement in semantic similarity performance during inference in this experiment. This work paves the way for energy-efficient neural network selection and the development of greener semantic communication architectures.","sentences":["Semantic communication aims to transmit meaningful and effective information rather than focusing on individual symbols or bits, resulting in benefits like reduced latency, bandwidth usage, and higher throughput compared to traditional communication.","However, semantic communication poses significant challenges due to the need for universal metrics for benchmarking the joint effects of semantic information loss and practical energy consumption.","This research presents a novel multi-objective loss function named \"Energy-Optimized Semantic Loss\" (EOSL), addressing the challenge of balancing semantic information loss and energy consumption.","Through comprehensive experiments on transformer models, including CPU and GPU energy usage, it is demonstrated that EOSL-based encoder model selection can save up to 90\\% of energy while achieving a 44\\% improvement in semantic similarity performance during inference in this experiment.","This work paves the way for energy-efficient neural network selection and the development of greener semantic communication architectures."],"url":"http://arxiv.org/abs/2310.07592v1"}
{"created":"2023-10-11 15:33:10","title":"PeP: a Point enhanced Painting method for unified point cloud tasks","abstract":"Point encoder is of vital importance for point cloud recognition. As the very beginning step of whole model pipeline, adding features from diverse sources and providing stronger feature encoding mechanism would provide better input for downstream modules. In our work, we proposed a novel PeP module to tackle above issue. PeP contains two main parts, a refined point painting method and a LM-based point encoder. Experiments results on the nuScenes and KITTI datasets validate the superior performance of our PeP. The advantages leads to strong performance on both semantic segmentation and object detection, in both lidar and multi-modal settings. Notably, our PeP module is model agnostic and plug-and-play. Our code will be publicly available soon.","sentences":["Point encoder is of vital importance for point cloud recognition.","As the very beginning step of whole model pipeline, adding features from diverse sources and providing stronger feature encoding mechanism would provide better input for downstream modules.","In our work, we proposed a novel PeP module to tackle above issue.","PeP contains two main parts, a refined point painting method and a LM-based point encoder.","Experiments results on the nuScenes and KITTI datasets validate the superior performance of our PeP.","The advantages leads to strong performance on both semantic segmentation and object detection, in both lidar and multi-modal settings.","Notably, our PeP module is model agnostic and plug-and-play.","Our code will be publicly available soon."],"url":"http://arxiv.org/abs/2310.07591v1"}
{"created":"2023-10-11 15:30:35","title":"Goodtriever: Adaptive Toxicity Mitigation with Retrieval-augmented Models","abstract":"Considerable effort has been dedicated to mitigating toxicity, but existing methods often require drastic modifications to model parameters or the use of computationally intensive auxiliary models. Furthermore, previous approaches have often neglected the crucial factor of language's evolving nature over time. In this work, we present a comprehensive perspective on toxicity mitigation that takes into account its changing nature. We introduce Goodtriever, a flexible methodology that matches the current state-of-the-art toxicity mitigation while achieving 43% relative latency reduction during inference and being more computationally efficient. By incorporating a retrieval-based approach at decoding time, Goodtriever enables toxicity-controlled text generation. Our research advocates for an increased focus on adaptable mitigation techniques, which better reflect the data drift models face when deployed in the wild. Code and data are available at https://github.com/for-ai/goodtriever.","sentences":["Considerable effort has been dedicated to mitigating toxicity, but existing methods often require drastic modifications to model parameters or the use of computationally intensive auxiliary models.","Furthermore, previous approaches have often neglected the crucial factor of language's evolving nature over time.","In this work, we present a comprehensive perspective on toxicity mitigation that takes into account its changing nature.","We introduce Goodtriever, a flexible methodology that matches the current state-of-the-art toxicity mitigation while achieving 43% relative latency reduction during inference and being more computationally efficient.","By incorporating a retrieval-based approach at decoding time, Goodtriever enables toxicity-controlled text generation.","Our research advocates for an increased focus on adaptable mitigation techniques, which better reflect the data drift models face when deployed in the wild.","Code and data are available at https://github.com/for-ai/goodtriever."],"url":"http://arxiv.org/abs/2310.07589v1"}
{"created":"2023-10-11 15:28:44","title":"Accurate Use of Label Dependency in Multi-Label Text Classification Through the Lens of Causality","abstract":"Multi-Label Text Classification (MLTC) aims to assign the most relevant labels to each given text. Existing methods demonstrate that label dependency can help to improve the model's performance. However, the introduction of label dependency may cause the model to suffer from unwanted prediction bias. In this study, we attribute the bias to the model's misuse of label dependency, i.e., the model tends to utilize the correlation shortcut in label dependency rather than fusing text information and label dependency for prediction. Motivated by causal inference, we propose a CounterFactual Text Classifier (CFTC) to eliminate the correlation bias, and make causality-based predictions. Specifically, our CFTC first adopts the predict-then-modify backbone to extract precise label information embedded in label dependency, then blocks the correlation shortcut through the counterfactual de-bias technique with the help of the human causal graph. Experimental results on three datasets demonstrate that our CFTC significantly outperforms the baselines and effectively eliminates the correlation bias in datasets.","sentences":["Multi-Label Text Classification (MLTC) aims to assign the most relevant labels to each given text.","Existing methods demonstrate that label dependency can help to improve the model's performance.","However, the introduction of label dependency may cause the model to suffer from unwanted prediction bias.","In this study, we attribute the bias to the model's misuse of label dependency, i.e., the model tends to utilize the correlation shortcut in label dependency rather than fusing text information and label dependency for prediction.","Motivated by causal inference, we propose a CounterFactual Text Classifier (CFTC) to eliminate the correlation bias, and make causality-based predictions.","Specifically, our CFTC first adopts the predict-then-modify backbone to extract precise label information embedded in label dependency, then blocks the correlation shortcut through the counterfactual de-bias technique with the help of the human causal graph.","Experimental results on three datasets demonstrate that our CFTC significantly outperforms the baselines and effectively eliminates the correlation bias in datasets."],"url":"http://arxiv.org/abs/2310.07588v1"}
{"created":"2023-10-11 15:28:39","title":"Fed-GraB: Federated Long-tailed Learning with Self-Adjusting Gradient Balancer","abstract":"Data privacy and long-tailed distribution are the norms rather than the exception in many real-world tasks. This paper investigates a federated long-tailed learning (Fed-LT) task in which each client holds a locally heterogeneous dataset; if the datasets can be globally aggregated, they jointly exhibit a long-tailed distribution. Under such a setting, existing federated optimization and/or centralized long-tailed learning methods hardly apply due to challenges in (a) characterizing the global long-tailed distribution under privacy constraints and (b) adjusting the local learning strategy to cope with the head-tail imbalance. In response, we propose a method termed $\\texttt{Fed-GraB}$, comprised of a Self-adjusting Gradient Balancer (SGB) module that re-weights clients' gradients in a closed-loop manner, based on the feedback of global long-tailed distribution evaluated by a Direct Prior Analyzer (DPA) module. Using $\\texttt{Fed-GraB}$, clients can effectively alleviate the distribution drift caused by data heterogeneity during the model training process and obtain a global model with better performance on the minority classes while maintaining the performance of the majority classes. Extensive experiments demonstrate that $\\texttt{Fed-GraB}$ achieves state-of-the-art performance on representative datasets such as CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, and iNaturalist.","sentences":["Data privacy and long-tailed distribution are the norms rather than the exception in many real-world tasks.","This paper investigates a federated long-tailed learning (Fed-LT) task in which each client holds a locally heterogeneous dataset; if the datasets can be globally aggregated, they jointly exhibit a long-tailed distribution.","Under such a setting, existing federated optimization and/or centralized long-tailed learning methods hardly apply due to challenges in (a) characterizing the global long-tailed distribution under privacy constraints and (b) adjusting the local learning strategy to cope with the head-tail imbalance.","In response, we propose a method termed $\\texttt{Fed-GraB}$, comprised of a Self-adjusting Gradient Balancer (SGB) module that re-weights clients' gradients in a closed-loop manner, based on the feedback of global long-tailed distribution evaluated by a Direct Prior Analyzer (DPA) module.","Using $\\texttt{Fed-GraB}$, clients can effectively alleviate the distribution drift caused by data heterogeneity during the model training process and obtain a global model with better performance on the minority classes while maintaining the performance of the majority classes.","Extensive experiments demonstrate that $\\texttt{Fed-GraB}$ achieves state-of-the-art performance on representative datasets such as CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, and iNaturalist."],"url":"http://arxiv.org/abs/2310.07587v1"}
{"created":"2023-10-11 15:21:40","title":"A Discrepancy Aware Framework for Robust Anomaly Detection","abstract":"Defect detection is a critical research area in artificial intelligence. Recently, synthetic data-based self-supervised learning has shown great potential on this task. Although many sophisticated synthesizing strategies exist, little research has been done to investigate the robustness of models when faced with different strategies. In this paper, we focus on this issue and find that existing methods are highly sensitive to them. To alleviate this issue, we present a Discrepancy Aware Framework (DAF), which demonstrates robust performance consistently with simple and cheap strategies across different anomaly detection benchmarks. We hypothesize that the high sensitivity to synthetic data of existing self-supervised methods arises from their heavy reliance on the visual appearance of synthetic data during decoding. In contrast, our method leverages an appearance-agnostic cue to guide the decoder in identifying defects, thereby alleviating its reliance on synthetic appearance. To this end, inspired by existing knowledge distillation methods, we employ a teacher-student network, which is trained based on synthesized outliers, to compute the discrepancy map as the cue. Extensive experiments on two challenging datasets prove the robustness of our method. Under the simple synthesis strategies, it outperforms existing methods by a large margin. Furthermore, it also achieves the state-of-the-art localization performance. Code is available at: https://github.com/caiyuxuan1120/DAF.","sentences":["Defect detection is a critical research area in artificial intelligence.","Recently, synthetic data-based self-supervised learning has shown great potential on this task.","Although many sophisticated synthesizing strategies exist, little research has been done to investigate the robustness of models when faced with different strategies.","In this paper, we focus on this issue and find that existing methods are highly sensitive to them.","To alleviate this issue, we present a Discrepancy Aware Framework (DAF), which demonstrates robust performance consistently with simple and cheap strategies across different anomaly detection benchmarks.","We hypothesize that the high sensitivity to synthetic data of existing self-supervised methods arises from their heavy reliance on the visual appearance of synthetic data during decoding.","In contrast, our method leverages an appearance-agnostic cue to guide the decoder in identifying defects, thereby alleviating its reliance on synthetic appearance.","To this end, inspired by existing knowledge distillation methods, we employ a teacher-student network, which is trained based on synthesized outliers, to compute the discrepancy map as the cue.","Extensive experiments on two challenging datasets prove the robustness of our method.","Under the simple synthesis strategies, it outperforms existing methods by a large margin.","Furthermore, it also achieves the state-of-the-art localization performance.","Code is available at: https://github.com/caiyuxuan1120/DAF."],"url":"http://arxiv.org/abs/2310.07585v1"}
{"created":"2023-10-11 15:20:44","title":"Centrality of the Fingerprint Core Location","abstract":"Fingerprints have long been recognized as a unique and reliable means of personal identification. Central to the analysis and enhancement of fingerprints is the concept of the fingerprint core. Although the location of the core is used in many applications, to the best of our knowledge, this study is the first to investigate the empirical distribution of the core over a large, combined dataset of rolled, as well as plain fingerprint recordings. We identify and investigate the extent of incomplete rolling during the rolled fingerprint acquisition and investigate the centrality of the core. After correcting for the incomplete rolling, we find that the core deviates from the fingerprint center by 5.7% $\\pm$ 5.2% to 7.6% $\\pm$ 6.9%, depending on the finger. Additionally, we find that the assumption of normal distribution of the core position of plain fingerprint recordings cannot be rejected, but for rolled ones it can. Therefore, we use a multi-step process to find the distribution of the rolled fingerprint recordings. The process consists of an Anderson-Darling normality test, the Bayesian Information Criterion to reduce the number of possible candidate distributions and finally a Generalized Monte Carlo goodness-of-fit procedure to find the best fitting distribution. We find the non-central Fischer distribution best describes the cores' horizontal positions. Finally, we investigate the correlation between mean core position offset and the NFIQ 2 score and find that the NFIQ 2 prefers rolled fingerprint recordings where the core sits slightly below the fingerprint center.","sentences":["Fingerprints have long been recognized as a unique and reliable means of personal identification.","Central to the analysis and enhancement of fingerprints is the concept of the fingerprint core.","Although the location of the core is used in many applications, to the best of our knowledge, this study is the first to investigate the empirical distribution of the core over a large, combined dataset of rolled, as well as plain fingerprint recordings.","We identify and investigate the extent of incomplete rolling during the rolled fingerprint acquisition and investigate the centrality of the core.","After correcting for the incomplete rolling, we find that the core deviates from the fingerprint center by 5.7% $\\pm$ 5.2% to 7.6% $\\pm$ 6.9%, depending on the finger.","Additionally, we find that the assumption of normal distribution of the core position of plain fingerprint recordings cannot be rejected, but for rolled ones it can.","Therefore, we use a multi-step process to find the distribution of the rolled fingerprint recordings.","The process consists of an Anderson-Darling normality test, the Bayesian Information Criterion to reduce the number of possible candidate distributions and finally a Generalized Monte Carlo goodness-of-fit procedure to find the best fitting distribution.","We find the non-central Fischer distribution best describes the cores' horizontal positions.","Finally, we investigate the correlation between mean core position offset and the NFIQ 2 score and find that the NFIQ 2 prefers rolled fingerprint recordings where the core sits slightly below the fingerprint center."],"url":"http://arxiv.org/abs/2310.07584v1"}
{"created":"2023-10-11 15:20:07","title":"Linear Latent World Models in Simple Transformers: A Case Study on Othello-GPT","abstract":"Foundation models exhibit significant capabilities in decision-making and logical deductions. Nonetheless, a continuing discourse persists regarding their genuine understanding of the world as opposed to mere stochastic mimicry. This paper meticulously examines a simple transformer trained for Othello, extending prior research to enhance comprehension of the emergent world model of Othello-GPT. The investigation reveals that Othello-GPT encapsulates a linear representation of opposing pieces, a factor that causally steers its decision-making process. This paper further elucidates the interplay between the linear world representation and causal decision-making, and their dependence on layer depth and model complexity. We have made the code public.","sentences":["Foundation models exhibit significant capabilities in decision-making and logical deductions.","Nonetheless, a continuing discourse persists regarding their genuine understanding of the world as opposed to mere stochastic mimicry.","This paper meticulously examines a simple transformer trained for Othello, extending prior research to enhance comprehension of the emergent world model of Othello-GPT.","The investigation reveals that Othello-GPT encapsulates a linear representation of opposing pieces, a factor that causally steers its decision-making process.","This paper further elucidates the interplay between the linear world representation and causal decision-making, and their dependence on layer depth and model complexity.","We have made the code public."],"url":"http://arxiv.org/abs/2310.07582v1"}
{"created":"2023-10-11 15:19:50","title":"Qlarify: Bridging Scholarly Abstracts and Papers with Recursively Expandable Summaries","abstract":"As scientific literature has grown exponentially, researchers often rely on paper triaging strategies such as browsing abstracts before deciding to delve into a paper's full text. However, when an abstract is insufficient, researchers are required to navigate an informational chasm between 150-word abstracts and 10,000-word papers. To bridge that gap, we introduce the idea of recursively expandable summaries and present Qlarify, an interactive system that allows users to recursively expand an abstract by progressively incorporating additional information from a paper's full text. Starting from an abstract, users can brush over summary text to specify targeted information needs or select AI-suggested entities in the text. Responses are then generated on-demand by an LLM and appear in the form of a fluid, threaded expansion of the existing text. Each generated summary can be efficiently verified through attribution to a relevant source-passage in the paper. Through an interview study (n=9) and a field deployment (n=275) at a research conference, we use Qlarify as a technology probe to elaborate upon the expandable summaries design space, highlight how scholars benefit from Qlarify's expandable abstracts, and identify future opportunities to support low-effort and just-in-time exploration of scientific documents $\\unicode{x2013}$ and other information spaces $\\unicode{x2013}$ through LLM-powered interactions.","sentences":["As scientific literature has grown exponentially, researchers often rely on paper triaging strategies such as browsing abstracts before deciding to delve into a paper's full text.","However, when an abstract is insufficient, researchers are required to navigate an informational chasm between 150-word abstracts and 10,000-word papers.","To bridge that gap, we introduce the idea of recursively expandable summaries and present Qlarify, an interactive system that allows users to recursively expand an abstract by progressively incorporating additional information from a paper's full text.","Starting from an abstract, users can brush over summary text to specify targeted information needs or select AI-suggested entities in the text.","Responses are then generated on-demand by an LLM and appear in the form of a fluid, threaded expansion of the existing text.","Each generated summary can be efficiently verified through attribution to a relevant source-passage in the paper.","Through an interview study (n=9) and a field deployment (n=275) at a research conference, we use Qlarify as a technology probe to elaborate upon the expandable summaries design space, highlight how scholars benefit from Qlarify's expandable abstracts, and identify future opportunities to support low-effort and just-in-time exploration of scientific documents $\\unicode{x2013}$ and other information spaces $\\unicode{x2013}$ through LLM-powered interactions."],"url":"http://arxiv.org/abs/2310.07581v1"}
{"created":"2023-10-11 15:19:31","title":"In-Context Unlearning: Language Models as Few Shot Unlearners","abstract":"Machine unlearning, the study of efficiently removing the impact of specific training points on the trained model, has garnered increased attention of late, driven by the need to comply with privacy regulations like the \\emph{Right to be Forgotten}. Although unlearning is particularly relevant for LLMs in light of the copyright issues they raise, achieving precise unlearning is computationally infeasible for very large models. To this end, recent work has proposed several algorithms which approximate the removal of training data without retraining the model. These algorithms crucially rely on access to the model parameters in order to update them, an assumption that may not hold in practice due to computational constraints or when the LLM is accessed via API. In this work, we propose a new class of unlearning methods for LLMs we call ``In-Context Unlearning'', providing inputs in context and without having to update model parameters. To unlearn a particular training instance, we provide the instance alongside a flipped label and additional correctly labelled instances which are prepended as inputs to the LLM at inference time. Our experimental results demonstrate that these contexts effectively remove specific information from the training set while maintaining performance levels that are competitive with (or in some cases exceed) state-of-the-art unlearning methods that require access to the LLM parameters.","sentences":["Machine unlearning, the study of efficiently removing the impact of specific training points on the trained model, has garnered increased attention of late, driven by the need to comply with privacy regulations like the \\emph{Right to be Forgotten}.","Although unlearning is particularly relevant for LLMs in light of the copyright issues they raise, achieving precise unlearning is computationally infeasible for very large models.","To this end, recent work has proposed several algorithms which approximate the removal of training data without retraining the model.","These algorithms crucially rely on access to the model parameters in order to update them, an assumption that may not hold in practice due to computational constraints or when the LLM is accessed via API.","In this work, we propose a new class of unlearning methods for LLMs we call ``In-Context Unlearning'', providing inputs in context and without having to update model parameters.","To unlearn a particular training instance, we provide the instance alongside a flipped label and additional correctly labelled instances which are prepended as inputs to the LLM at inference time.","Our experimental results demonstrate that these contexts effectively remove specific information from the training set while maintaining performance levels that are competitive with (or in some cases exceed) state-of-the-art unlearning methods that require access to the LLM parameters."],"url":"http://arxiv.org/abs/2310.07579v1"}
{"created":"2023-10-11 15:17:55","title":"Analyzing Trendy Twitter Hashtags in the 2022 French Election","abstract":"Regressions trained to predict the future activity of social media users need rich features for accurate predictions. Many advanced models exist to generate such features; however, the time complexities of their computations are often prohibitive when they run on enormous data-sets. Some studies have shown that simple semantic network features can be rich enough to use for regressions without requiring complex computations. We propose a method for using semantic networks as user-level features for machine learning tasks. We conducted an experiment using a semantic network of 1037 Twitter hashtags from a corpus of 3.7 million tweets related to the 2022 French presidential election. A bipartite graph is formed where hashtags are nodes and weighted edges connect the hashtags reflecting the number of Twitter users that interacted with both hashtags. The graph is then transformed into a maximum-spanning tree with the most popular hashtag as its root node to construct a hierarchy amongst the hashtags. We then provide a vector feature for each user based on this tree. To validate the usefulness of our semantic feature we performed a regression experiment to predict the response rate of each user with six emotions like anger, enjoyment, or disgust. Our semantic feature performs well with the regression with most emotions having $R^2$ above 0.5. These results suggest that our semantic feature could be considered for use in further experiments predicting social media response on big data-sets.","sentences":["Regressions trained to predict the future activity of social media users need rich features for accurate predictions.","Many advanced models exist to generate such features; however, the time complexities of their computations are often prohibitive when they run on enormous data-sets.","Some studies have shown that simple semantic network features can be rich enough to use for regressions without requiring complex computations.","We propose a method for using semantic networks as user-level features for machine learning tasks.","We conducted an experiment using a semantic network of 1037 Twitter hashtags from a corpus of 3.7 million tweets related to the 2022 French presidential election.","A bipartite graph is formed where hashtags are nodes and weighted edges connect the hashtags reflecting the number of Twitter users that interacted with both hashtags.","The graph is then transformed into a maximum-spanning tree with the most popular hashtag as its root node to construct a hierarchy amongst the hashtags.","We then provide a vector feature for each user based on this tree.","To validate the usefulness of our semantic feature we performed a regression experiment to predict the response rate of each user with six emotions like anger, enjoyment, or disgust.","Our semantic feature performs well with the regression with most emotions having $R^2$ above 0.5.","These results suggest that our semantic feature could be considered for use in further experiments predicting social media response on big data-sets."],"url":"http://arxiv.org/abs/2310.07576v1"}
{"created":"2023-10-11 15:15:05","title":"Relational Prior Knowledge Graphs for Detection and Instance Segmentation","abstract":"Humans have a remarkable ability to perceive and reason about the world around them by understanding the relationships between objects. In this paper, we investigate the effectiveness of using such relationships for object detection and instance segmentation. To this end, we propose a Relational Prior-based Feature Enhancement Model (RP-FEM), a graph transformer that enhances object proposal features using relational priors. The proposed architecture operates on top of scene graphs obtained from initial proposals and aims to concurrently learn relational context modeling for object detection and instance segmentation. Experimental evaluations on COCO show that the utilization of scene graphs, augmented with relational priors, offer benefits for object detection and instance segmentation. RP-FEM demonstrates its capacity to suppress improbable class predictions within the image while also preventing the model from generating duplicate predictions, leading to improvements over the baseline model on which it is built.","sentences":["Humans have a remarkable ability to perceive and reason about the world around them by understanding the relationships between objects.","In this paper, we investigate the effectiveness of using such relationships for object detection and instance segmentation.","To this end, we propose a Relational Prior-based Feature Enhancement Model (RP-FEM), a graph transformer that enhances object proposal features using relational priors.","The proposed architecture operates on top of scene graphs obtained from initial proposals and aims to concurrently learn relational context modeling for object detection and instance segmentation.","Experimental evaluations on COCO show that the utilization of scene graphs, augmented with relational priors, offer benefits for object detection and instance segmentation.","RP-FEM demonstrates its capacity to suppress improbable class predictions within the image while also preventing the model from generating duplicate predictions, leading to improvements over the baseline model on which it is built."],"url":"http://arxiv.org/abs/2310.07573v1"}
{"created":"2023-10-11 15:14:54","title":"Impact of Label Types on Training SWIN Models with Overhead Imagery","abstract":"Understanding the impact of data set design on model training and performance can help alleviate the costs associated with generating remote sensing and overhead labeled data. This work examined the impact of training shifted window transformers using bounding boxes and segmentation labels, where the latter are more expensive to produce. We examined classification tasks by comparing models trained with both target and backgrounds against models trained with only target pixels, extracted by segmentation labels. For object detection models, we compared performance using either label type when training. We found that the models trained on only target pixels do not show performance improvement for classification tasks, appearing to conflate background pixels in the evaluation set with target pixels. For object detection, we found that models trained with either label type showed equivalent performance across testing. We found that bounding boxes appeared to be sufficient for tasks that did not require more complex labels, such as object segmentation. Continuing work to determine consistency of this result across data types and model architectures could potentially result in substantial savings in generating remote sensing data sets for deep learning.","sentences":["Understanding the impact of data set design on model training and performance can help alleviate the costs associated with generating remote sensing and overhead labeled data.","This work examined the impact of training shifted window transformers using bounding boxes and segmentation labels, where the latter are more expensive to produce.","We examined classification tasks by comparing models trained with both target and backgrounds against models trained with only target pixels, extracted by segmentation labels.","For object detection models, we compared performance using either label type when training.","We found that the models trained on only target pixels do not show performance improvement for classification tasks, appearing to conflate background pixels in the evaluation set with target pixels.","For object detection, we found that models trained with either label type showed equivalent performance across testing.","We found that bounding boxes appeared to be sufficient for tasks that did not require more complex labels, such as object segmentation.","Continuing work to determine consistency of this result across data types and model architectures could potentially result in substantial savings in generating remote sensing data sets for deep learning."],"url":"http://arxiv.org/abs/2310.07572v1"}
{"created":"2023-10-11 15:05:15","title":"Using Tableau and Google Map API for Understanding the Impact of Walkability on Dublin City","abstract":"In this article, we explore two effective means to communicate the concept of walkability - 1) visualization, and 2) descriptive statistics. We introduce the concept of walkability as measuring the quality of an urban space based on the distance needed to walk from that space to a range of different social, environmental, and economic amenities. We use Dublin city as a worked example and explore quantification and visualization of walkability of various areas of the city. We utilize the Google Map API and Tableau to visualize the less walkable areas across Dublin city and using WLS regression, we assess the effects of unwalkability on house prices in Dublin, thus quantifying the importance of walkable areas from an economic perspective.","sentences":["In this article, we explore two effective means to communicate the concept of walkability - 1) visualization, and 2) descriptive statistics.","We introduce the concept of walkability as measuring the quality of an urban space based on the distance needed to walk from that space to a range of different social, environmental, and economic amenities.","We use Dublin city as a worked example and explore quantification and visualization of walkability of various areas of the city.","We utilize the Google Map API and Tableau to visualize the less walkable areas across Dublin city and using WLS regression, we assess the effects of unwalkability on house prices in Dublin, thus quantifying the importance of walkable areas from an economic perspective."],"url":"http://arxiv.org/abs/2310.07563v1"}
{"created":"2023-10-11 15:04:33","title":"ROMO: Retrieval-enhanced Offline Model-based Optimization","abstract":"Data-driven black-box model-based optimization (MBO) problems arise in a great number of practical application scenarios, where the goal is to find a design over the whole space maximizing a black-box target function based on a static offline dataset. In this work, we consider a more general but challenging MBO setting, named constrained MBO (CoMBO), where only part of the design space can be optimized while the rest is constrained by the environment. A new challenge arising from CoMBO is that most observed designs that satisfy the constraints are mediocre in evaluation. Therefore, we focus on optimizing these mediocre designs in the offline dataset while maintaining the given constraints rather than further boosting the best observed design in the traditional MBO setting. We propose retrieval-enhanced offline model-based optimization (ROMO), a new derivable forward approach that retrieves the offline dataset and aggregates relevant samples to provide a trusted prediction, and use it for gradient-based optimization. ROMO is simple to implement and outperforms state-of-the-art approaches in the CoMBO setting. Empirically, we conduct experiments on a synthetic Hartmann (3D) function dataset, an industrial CIO dataset, and a suite of modified tasks in the Design-Bench benchmark. Results show that ROMO performs well in a wide range of constrained optimization tasks.","sentences":["Data-driven black-box model-based optimization (MBO) problems arise in a great number of practical application scenarios, where the goal is to find a design over the whole space maximizing a black-box target function based on a static offline dataset.","In this work, we consider a more general but challenging MBO setting, named constrained MBO (CoMBO), where only part of the design space can be optimized while the rest is constrained by the environment.","A new challenge arising from CoMBO is that most observed designs that satisfy the constraints are mediocre in evaluation.","Therefore, we focus on optimizing these mediocre designs in the offline dataset while maintaining the given constraints rather than further boosting the best observed design in the traditional MBO setting.","We propose retrieval-enhanced offline model-based optimization (ROMO), a new derivable forward approach that retrieves the offline dataset and aggregates relevant samples to provide a trusted prediction, and use it for gradient-based optimization.","ROMO is simple to implement and outperforms state-of-the-art approaches in the CoMBO setting.","Empirically, we conduct experiments on a synthetic Hartmann (3D) function dataset, an industrial CIO dataset, and a suite of modified tasks in the Design-Bench benchmark.","Results show that ROMO performs well in a wide range of constrained optimization tasks."],"url":"http://arxiv.org/abs/2310.07560v1"}
{"created":"2023-10-11 15:01:46","title":"Quality of Service-Constrained Online Routing in High Throughput Satellites","abstract":"High Throughput Satellites (HTSs) outpace traditional satellites due to their multi-beam transmission. The rise of low Earth orbit mega constellations amplifies HTS data rate demands to terabits/second with acceptable latency. This surge in data rate necessitates multiple modems, often exceeding single device capabilities. Consequently, satellites employ several processors, forming a complex packet-switch network. This can lead to potential internal congestion and challenges in adhering to strict quality of service (QoS) constraints. While significant research exists on constellation-level routing, a literature gap remains on the internal routing within a singular HTS. The intricacy of this internal network architecture presents a significant challenge to achieve high data rates.   This paper introduces an online optimal flow allocation and scheduling method for HTSs. The problem is treated as a multi-commodity flow instance with different priority data streams. An initial full time horizon model is proposed as a benchmark. We apply a model predictive control (MPC) approach to enable adaptive routing based on current information and the forecast within the prediction time horizon while allowing for deviation of the latter. Importantly, MPC is inherently suited to handle uncertainty in incoming flows. Our approach minimizes packet loss by optimally and adaptively managing the priority queue schedulers and flow exchanges between satellite processing modules. Central to our method is a routing model focusing on optimal priority scheduling to enhance data rates and maintain QoS. The model's stages are critically evaluated, and results are compared to traditional methods via numerical simulations. Through simulations, our method demonstrates performance nearly on par with the hindsight optimum, showcasing its efficiency and adaptability in addressing satellite communication challenges.","sentences":["High Throughput Satellites (HTSs) outpace traditional satellites due to their multi-beam transmission.","The rise of low Earth orbit mega constellations amplifies HTS data rate demands to terabits/second with acceptable latency.","This surge in data rate necessitates multiple modems, often exceeding single device capabilities.","Consequently, satellites employ several processors, forming a complex packet-switch network.","This can lead to potential internal congestion and challenges in adhering to strict quality of service (QoS) constraints.","While significant research exists on constellation-level routing, a literature gap remains on the internal routing within a singular HTS.","The intricacy of this internal network architecture presents a significant challenge to achieve high data rates.   ","This paper introduces an online optimal flow allocation and scheduling method for HTSs.","The problem is treated as a multi-commodity flow instance with different priority data streams.","An initial full time horizon model is proposed as a benchmark.","We apply a model predictive control (MPC) approach to enable adaptive routing based on current information and the forecast within the prediction time horizon while allowing for deviation of the latter.","Importantly, MPC is inherently suited to handle uncertainty in incoming flows.","Our approach minimizes packet loss by optimally and adaptively managing the priority queue schedulers and flow exchanges between satellite processing modules.","Central to our method is a routing model focusing on optimal priority scheduling to enhance data rates and maintain QoS.","The model's stages are critically evaluated, and results are compared to traditional methods via numerical simulations.","Through simulations, our method demonstrates performance nearly on par with the hindsight optimum, showcasing its efficiency and adaptability in addressing satellite communication challenges."],"url":"http://arxiv.org/abs/2310.07557v1"}
{"created":"2023-10-11 15:00:11","title":"Does resistance to Style-Transfer equal Shape Bias? Evaluating Shape Bias by Distorted Shape","abstract":"Deep learning models are known to exhibit a strong texture bias, while human tends to rely heavily on global shape for object recognition. The current benchmark for evaluating a model's shape bias is a set of style-transferred images with the assumption that resistance to the attack of style transfer is related to the development of shape sensitivity in the model. In this work, we show that networks trained with style-transfer images indeed learn to ignore style, but its shape bias arises primarily from local shapes. We provide a Distorted Shape Testbench (DiST) as an alternative measurement of global shape sensitivity. Our test includes 2400 original images from ImageNet-1K, each of which is accompanied by two images with the global shapes of the original image distorted while preserving its texture via the texture synthesis program. We found that (1) models that performed well on the previous shape bias evaluation do not fare well in the proposed DiST; (2) the widely adopted ViT models do not show significant advantages over Convolutional Neural Networks (CNNs) on this benchmark despite that ViTs rank higher on the previous shape bias tests. (3) training with DiST images bridges the significant gap between human and existing SOTA models' performance while preserving the models' accuracy on standard image classification tasks; training with DiST images and style-transferred images are complementary, and can be combined to train network together to enhance both the global and local shape sensitivity of the network. Our code will be host at: https://github.com/leelabcnbc/DiST","sentences":["Deep learning models are known to exhibit a strong texture bias, while human tends to rely heavily on global shape for object recognition.","The current benchmark for evaluating a model's shape bias is a set of style-transferred images with the assumption that resistance to the attack of style transfer is related to the development of shape sensitivity in the model.","In this work, we show that networks trained with style-transfer images indeed learn to ignore style, but its shape bias arises primarily from local shapes.","We provide a Distorted Shape Testbench (DiST) as an alternative measurement of global shape sensitivity.","Our test includes 2400 original images from ImageNet-1K, each of which is accompanied by two images with the global shapes of the original image distorted while preserving its texture via the texture synthesis program.","We found that (1) models that performed well on the previous shape bias evaluation do not fare well in the proposed DiST; (2) the widely adopted ViT models do not show significant advantages over Convolutional Neural Networks (CNNs) on this benchmark despite that ViTs rank higher on the previous shape bias tests.","(3) training with DiST images bridges the significant gap between human and existing SOTA models' performance while preserving the models' accuracy on standard image classification tasks; training with DiST images and style-transferred images are complementary, and can be combined to train network together to enhance both the global and local shape sensitivity of the network.","Our code will be host at: https://github.com/leelabcnbc/DiST"],"url":"http://arxiv.org/abs/2310.07555v1"}
{"created":"2023-10-11 14:59:53","title":"Retrieve Anything To Augment Large Language Models","abstract":"Large language models (LLMs) face significant challenges stemming from the inherent limitations in knowledge, memory, alignment, and action. These challenges cannot be addressed by LLMs alone, but should rely on assistance from the external world, such as knowledge base, memory store, demonstration examples, and tools. Retrieval augmentation stands as a vital mechanism for bridging the gap between LLMs and the external assistance. However, conventional methods encounter two pressing issues. On one hand, the general-purpose retrievers are not properly optimized for the retrieval augmentation of LLMs. On the other hand, the task-specific retrievers lack the required versatility, hindering their performance across the diverse retrieval augmentation scenarios.   In this work, we present a novel approach, the LLM Embedder, which comprehensively support the diverse needs of LLMs' retrieval augmentation with one unified embedding model. Training such an unified model is non-trivial, as various retrieval tasks aim to capture distinct semantic relationships, often subject to mutual interference. To address this challenge, we systematically optimize our training methodology. This includes reward formulation based on LLMs' feedback, the stabilization of knowledge distillation, multi-task fine-tuning with explicit instructions, and the use of homogeneous in-batch negative sampling. These optimization strategies contribute to the outstanding empirical performance of the LLM-Embedder. Notably, it yields remarkable enhancements in retrieval augmentation for LLMs, surpassing both general-purpose and task-specific retrievers in various evaluation scenarios. This project is made publicly available at https://github.com/FlagOpen/FlagEmbedding.","sentences":["Large language models (LLMs) face significant challenges stemming from the inherent limitations in knowledge, memory, alignment, and action.","These challenges cannot be addressed by LLMs alone, but should rely on assistance from the external world, such as knowledge base, memory store, demonstration examples, and tools.","Retrieval augmentation stands as a vital mechanism for bridging the gap between LLMs and the external assistance.","However, conventional methods encounter two pressing issues.","On one hand, the general-purpose retrievers are not properly optimized for the retrieval augmentation of LLMs.","On the other hand, the task-specific retrievers lack the required versatility, hindering their performance across the diverse retrieval augmentation scenarios.   ","In this work, we present a novel approach, the LLM Embedder, which comprehensively support the diverse needs of LLMs' retrieval augmentation with one unified embedding model.","Training such an unified model is non-trivial, as various retrieval tasks aim to capture distinct semantic relationships, often subject to mutual interference.","To address this challenge, we systematically optimize our training methodology.","This includes reward formulation based on LLMs' feedback, the stabilization of knowledge distillation, multi-task fine-tuning with explicit instructions, and the use of homogeneous in-batch negative sampling.","These optimization strategies contribute to the outstanding empirical performance of the LLM-Embedder.","Notably, it yields remarkable enhancements in retrieval augmentation for LLMs, surpassing both general-purpose and task-specific retrievers in various evaluation scenarios.","This project is made publicly available at https://github.com/FlagOpen/FlagEmbedding."],"url":"http://arxiv.org/abs/2310.07554v1"}
{"created":"2023-10-11 14:54:40","title":"ProtoHPE: Prototype-guided High-frequency Patch Enhancement for Visible-Infrared Person Re-identification","abstract":"Visible-infrared person re-identification is challenging due to the large modality gap. To bridge the gap, most studies heavily rely on the correlation of visible-infrared holistic person images, which may perform poorly under severe distribution shifts. In contrast, we find that some cross-modal correlated high-frequency components contain discriminative visual patterns and are less affected by variations such as wavelength, pose, and background clutter than holistic images. Therefore, we are motivated to bridge the modality gap based on such high-frequency components, and propose \\textbf{Proto}type-guided \\textbf{H}igh-frequency \\textbf{P}atch \\textbf{E}nhancement (ProtoHPE) with two core designs. \\textbf{First}, to enhance the representation ability of cross-modal correlated high-frequency components, we split patches with such components by Wavelet Transform and exponential moving average Vision Transformer (ViT), then empower ViT to take the split patches as auxiliary input. \\textbf{Second}, to obtain semantically compact and discriminative high-frequency representations of the same identity, we propose Multimodal Prototypical Contrast. To be specific, it hierarchically captures the comprehensive semantics of different modal instances, facilitating the aggregation of high-frequency representations belonging to the same identity. With it, ViT can capture key high-frequency components during inference without relying on ProtoHPE, thus bringing no extra complexity. Extensive experiments validate the effectiveness of ProtoHPE.","sentences":["Visible-infrared person re-identification is challenging due to the large modality gap.","To bridge the gap, most studies heavily rely on the correlation of visible-infrared holistic person images, which may perform poorly under severe distribution shifts.","In contrast, we find that some cross-modal correlated high-frequency components contain discriminative visual patterns and are less affected by variations such as wavelength, pose, and background clutter than holistic images.","Therefore, we are motivated to bridge the modality gap based on such high-frequency components, and propose \\textbf{Proto}type-guided \\textbf{H}igh-frequency \\textbf{P}atch \\textbf{E}nhancement (ProtoHPE) with two core designs.","\\textbf{First}, to enhance the representation ability of cross-modal correlated high-frequency components, we split patches with such components by Wavelet Transform and exponential moving average Vision Transformer (ViT), then empower ViT to take the split patches as auxiliary input.","\\textbf{Second}",", to obtain semantically compact and discriminative high-frequency representations of the same identity, we propose Multimodal Prototypical Contrast.","To be specific, it hierarchically captures the comprehensive semantics of different modal instances, facilitating the aggregation of high-frequency representations belonging to the same identity.","With it, ViT can capture key high-frequency components during inference without relying on ProtoHPE, thus bringing no extra complexity.","Extensive experiments validate the effectiveness of ProtoHPE."],"url":"http://arxiv.org/abs/2310.07552v1"}
{"created":"2023-10-11 14:50:52","title":"Attribute Localization and Revision Network for Zero-Shot Learning","abstract":"Zero-shot learning enables the model to recognize unseen categories with the aid of auxiliary semantic information such as attributes. Current works proposed to detect attributes from local image regions and align extracted features with class-level semantics. In this paper, we find that the choice between local and global features is not a zero-sum game, global features can also contribute to the understanding of attributes. In addition, aligning attribute features with class-level semantics ignores potential intra-class attribute variation. To mitigate these disadvantages, we present Attribute Localization and Revision Network in this paper. First, we design Attribute Localization Module (ALM) to capture both local and global features from image regions, a novel module called Scale Control Unit is incorporated to fuse global and local representations. Second, we propose Attribute Revision Module (ARM), which generates image-level semantics by revising the ground-truth value of each attribute, compensating for performance degradation caused by ignoring intra-class variation. Finally, the output of ALM will be aligned with revised semantics produced by ARM to achieve the training process. Comprehensive experimental results on three widely used benchmarks demonstrate the effectiveness of our model in the zero-shot prediction task.","sentences":["Zero-shot learning enables the model to recognize unseen categories with the aid of auxiliary semantic information such as attributes.","Current works proposed to detect attributes from local image regions and align extracted features with class-level semantics.","In this paper, we find that the choice between local and global features is not a zero-sum game, global features can also contribute to the understanding of attributes.","In addition, aligning attribute features with class-level semantics ignores potential intra-class attribute variation.","To mitigate these disadvantages, we present Attribute Localization and Revision Network in this paper.","First, we design Attribute Localization Module (ALM) to capture both local and global features from image regions, a novel module called Scale Control Unit is incorporated to fuse global and local representations.","Second, we propose Attribute Revision Module (ARM), which generates image-level semantics by revising the ground-truth value of each attribute, compensating for performance degradation caused by ignoring intra-class variation.","Finally, the output of ALM will be aligned with revised semantics produced by ARM to achieve the training process.","Comprehensive experimental results on three widely used benchmarks demonstrate the effectiveness of our model in the zero-shot prediction task."],"url":"http://arxiv.org/abs/2310.07548v1"}
{"created":"2023-10-11 14:49:54","title":"Generative Agent-Based Social Networks for Disinformation: Research Opportunities and Open Challenges","abstract":"This article presents the affordances that Generative Artificial Intelligence can have in disinformation context, one of the major threats to our digitalized society. We present a research framework to generate customized agent-based social networks for disinformation simulations that would enable understanding and evaluation of the phenomena whilst discussing open challenges.","sentences":["This article presents the affordances that Generative Artificial Intelligence can have in disinformation context, one of the major threats to our digitalized society.","We present a research framework to generate customized agent-based social networks for disinformation simulations that would enable understanding and evaluation of the phenomena whilst discussing open challenges."],"url":"http://arxiv.org/abs/2310.07545v1"}
{"created":"2023-10-11 14:39:51","title":"Improving Fairness-Accuracy tradeoff with few Test Samples under Covariate Shift","abstract":"Covariate shift in the test data can significantly downgrade both the accuracy and the fairness performance of the model. Ensuring fairness across different sensitive groups in such settings is of paramount importance due to societal implications like criminal justice. We operate under the unsupervised regime where only a small set of unlabeled test samples along with a labeled training set is available. Towards this problem, we make three contributions. First is a novel composite weighted entropy based objective for prediction accuracy which is optimized along with a representation matching loss for fairness. We experimentally verify that optimizing with our loss formulation outperforms a number of state-of-the-art baselines in the pareto sense with respect to the fairness-accuracy tradeoff on several standard datasets. Our second contribution is a new setting we term Asymmetric Covariate Shift that, to the best of our knowledge, has not been studied before. Asymmetric covariate shift occurs when distribution of covariates of one group shifts significantly compared to the other groups and this happens when a dominant group is over-represented. While this setting is extremely challenging for current baselines, We show that our proposed method significantly outperforms them. Our third contribution is theoretical, where we show that our weighted entropy term along with prediction loss on the training set approximates test loss under covariate shift. Empirically and through formal sample complexity bounds, we show that this approximation to the unseen test loss does not depend on importance sampling variance which affects many other baselines.","sentences":["Covariate shift in the test data can significantly downgrade both the accuracy and the fairness performance of the model.","Ensuring fairness across different sensitive groups in such settings is of paramount importance due to societal implications like criminal justice.","We operate under the unsupervised regime where only a small set of unlabeled test samples along with a labeled training set is available.","Towards this problem, we make three contributions.","First is a novel composite weighted entropy based objective for prediction accuracy which is optimized along with a representation matching loss for fairness.","We experimentally verify that optimizing with our loss formulation outperforms a number of state-of-the-art baselines in the pareto sense with respect to the fairness-accuracy tradeoff on several standard datasets.","Our second contribution is a new setting we term Asymmetric Covariate Shift that, to the best of our knowledge, has not been studied before.","Asymmetric covariate shift occurs when distribution of covariates of one group shifts significantly compared to the other groups and this happens when a dominant group is over-represented.","While this setting is extremely challenging for current baselines, We show that our proposed method significantly outperforms them.","Our third contribution is theoretical, where we show that our weighted entropy term along with prediction loss on the training set approximates test loss under covariate shift.","Empirically and through formal sample complexity bounds, we show that this approximation to the unseen test loss does not depend on importance sampling variance which affects many other baselines."],"url":"http://arxiv.org/abs/2310.07535v1"}
{"created":"2023-10-11 14:39:12","title":"Human-Centered Evaluation of XAI Methods","abstract":"In the ever-evolving field of Artificial Intelligence, a critical challenge has been to decipher the decision-making processes within the so-called \"black boxes\" in deep learning. Over recent years, a plethora of methods have emerged, dedicated to explaining decisions across diverse tasks. Particularly in tasks like image classification, these methods typically identify and emphasize the pivotal pixels that most influence a classifier's prediction. Interestingly, this approach mirrors human behavior: when asked to explain our rationale for classifying an image, we often point to the most salient features or aspects. Capitalizing on this parallel, our research embarked on a user-centric study. We sought to objectively measure the interpretability of three leading explanation methods: (1) Prototypical Part Network, (2) Occlusion, and (3) Layer-wise Relevance Propagation. Intriguingly, our results highlight that while the regions spotlighted by these methods can vary widely, they all offer humans a nearly equivalent depth of understanding. This enables users to discern and categorize images efficiently, reinforcing the value of these methods in enhancing AI transparency.","sentences":["In the ever-evolving field of Artificial Intelligence, a critical challenge has been to decipher the decision-making processes within the so-called \"black boxes\" in deep learning.","Over recent years, a plethora of methods have emerged, dedicated to explaining decisions across diverse tasks.","Particularly in tasks like image classification, these methods typically identify and emphasize the pivotal pixels that most influence a classifier's prediction.","Interestingly, this approach mirrors human behavior: when asked to explain our rationale for classifying an image, we often point to the most salient features or aspects.","Capitalizing on this parallel, our research embarked on a user-centric study.","We sought to objectively measure the interpretability of three leading explanation methods: (1) Prototypical Part Network, (2) Occlusion, and (3) Layer-wise Relevance Propagation.","Intriguingly, our results highlight that while the regions spotlighted by these methods can vary widely, they all offer humans a nearly equivalent depth of understanding.","This enables users to discern and categorize images efficiently, reinforcing the value of these methods in enhancing AI transparency."],"url":"http://arxiv.org/abs/2310.07534v1"}
{"created":"2023-10-11 14:24:20","title":"ViT-A*: Legged Robot Path Planning using Vision Transformer A*","abstract":"Legged robots, particularly quadrupeds, offer promising navigation capabilities, especially in scenarios requiring traversal over diverse terrains and obstacle avoidance. This paper addresses the challenge of enabling legged robots to navigate complex environments effectively through the integration of data-driven path-planning methods. We propose an approach that utilizes differentiable planners, allowing the learning of end-to-end global plans via a neural network for commanding quadruped robots. The approach leverages 2D maps and obstacle specifications as inputs to generate a global path. To enhance the functionality of the developed neural network-based path planner, we use Vision Transformers (ViT) for map pre-processing, to enable the effective handling of larger maps. Experimental evaluations on two real robotic quadrupeds (Boston Dynamics Spot and Unitree Go1) demonstrate the effectiveness and versatility of the proposed approach in generating reliable path plans.","sentences":["Legged robots, particularly quadrupeds, offer promising navigation capabilities, especially in scenarios requiring traversal over diverse terrains and obstacle avoidance.","This paper addresses the challenge of enabling legged robots to navigate complex environments effectively through the integration of data-driven path-planning methods.","We propose an approach that utilizes differentiable planners, allowing the learning of end-to-end global plans via a neural network for commanding quadruped robots.","The approach leverages 2D maps and obstacle specifications as inputs to generate a global path.","To enhance the functionality of the developed neural network-based path planner, we use Vision Transformers (ViT) for map pre-processing, to enable the effective handling of larger maps.","Experimental evaluations on two real robotic quadrupeds (Boston Dynamics Spot and Unitree Go1) demonstrate the effectiveness and versatility of the proposed approach in generating reliable path plans."],"url":"http://arxiv.org/abs/2310.07525v1"}
{"created":"2023-10-11 14:22:44","title":"New Lower Bounds for the Minimum Distance of Cyclic Codes and Applications to Locally Repairable Codes","abstract":"Cyclic codes are an important class of linear codes. Bounding the minimum distance of cyclic codes is a long-standing research topic in coding theory, and several well-known and basic results have been developed on this topic. Recently, locally repairable codes (LRCs) have attracted much attention due to their repair efficiency in large-scale distributed storage systems. In this paper, by employing the singleton procedure technique, we first provide a sufficient condition for bounding the minimum distance of cyclic codes with typical defining sets. Secondly, by considering a specific case, we establish a connection between bounds for the minimum distance of cyclic codes and solutions to a system of inequalities. This connection leads to the derivation of new bounds, including some with general patterns. In particular, we provide three new bounds with general patterns, one of which serves as a generalization of the Betti-Sala bound. Finally, we present a generalized lower bound for a special case and construct several families of $(2, \\delta)$-LRCs with unbounded length and minimum distance $2\\delta$. It turns out that these LRCs are distance-optimal, and their parameters are new. To the best of our knowledge, this work represents the first construction of distance-optimal $(r, \\delta)$-LRCs with unbounded length and minimum distance exceeding $r+\\delta-1$.","sentences":["Cyclic codes are an important class of linear codes.","Bounding the minimum distance of cyclic codes is a long-standing research topic in coding theory, and several well-known and basic results have been developed on this topic.","Recently, locally repairable codes (LRCs) have attracted much attention due to their repair efficiency in large-scale distributed storage systems.","In this paper, by employing the singleton procedure technique, we first provide a sufficient condition for bounding the minimum distance of cyclic codes with typical defining sets.","Secondly, by considering a specific case, we establish a connection between bounds for the minimum distance of cyclic codes and solutions to a system of inequalities.","This connection leads to the derivation of new bounds, including some with general patterns.","In particular, we provide three new bounds with general patterns, one of which serves as a generalization of the Betti-Sala bound.","Finally, we present a generalized lower bound for a special case and construct several families of $(2, \\delta)$-LRCs with unbounded length and minimum distance $2\\delta$.","It turns out that these LRCs are distance-optimal, and their parameters are new.","To the best of our knowledge, this work represents the first construction of distance-optimal $(r, \\delta)$-LRCs with unbounded length and minimum distance exceeding $r+\\delta-1$."],"url":"http://arxiv.org/abs/2310.07524v1"}
{"created":"2023-10-11 14:19:05","title":"S4C: Self-Supervised Semantic Scene Completion with Neural Fields","abstract":"3D semantic scene understanding is a fundamental challenge in computer vision. It enables mobile agents to autonomously plan and navigate arbitrary environments. SSC formalizes this challenge as jointly estimating dense geometry and semantic information from sparse observations of a scene. Current methods for SSC are generally trained on 3D ground truth based on aggregated LiDAR scans. This process relies on special sensors and annotation by hand which are costly and do not scale well. To overcome this issue, our work presents the first self-supervised approach to SSC called S4C that does not rely on 3D ground truth data. Our proposed method can reconstruct a scene from a single image and only relies on videos and pseudo segmentation ground truth generated from off-the-shelf image segmentation network during training. Unlike existing methods, which use discrete voxel grids, we represent scenes as implicit semantic fields. This formulation allows querying any point within the camera frustum for occupancy and semantic class. Our architecture is trained through rendering-based self-supervised losses. Nonetheless, our method achieves performance close to fully supervised state-of-the-art methods. Additionally, our method demonstrates strong generalization capabilities and can synthesize accurate segmentation maps for far away viewpoints.","sentences":["3D semantic scene understanding is a fundamental challenge in computer vision.","It enables mobile agents to autonomously plan and navigate arbitrary environments.","SSC formalizes this challenge as jointly estimating dense geometry and semantic information from sparse observations of a scene.","Current methods for SSC are generally trained on 3D ground truth based on aggregated LiDAR scans.","This process relies on special sensors and annotation by hand which are costly and do not scale well.","To overcome this issue, our work presents the first self-supervised approach to SSC called S4C that does not rely on 3D ground truth data.","Our proposed method can reconstruct a scene from a single image and only relies on videos and pseudo segmentation ground truth generated from off-the-shelf image segmentation network during training.","Unlike existing methods, which use discrete voxel grids, we represent scenes as implicit semantic fields.","This formulation allows querying any point within the camera frustum for occupancy and semantic class.","Our architecture is trained through rendering-based self-supervised losses.","Nonetheless, our method achieves performance close to fully supervised state-of-the-art methods.","Additionally, our method demonstrates strong generalization capabilities and can synthesize accurate segmentation maps for far away viewpoints."],"url":"http://arxiv.org/abs/2310.07522v1"}
{"created":"2023-10-11 14:18:03","title":"Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity","abstract":"This survey addresses the crucial issue of factuality in Large Language Models (LLMs). As LLMs find applications across diverse domains, the reliability and accuracy of their outputs become vital. We define the Factuality Issue as the probability of LLMs to produce content inconsistent with established facts. We first delve into the implications of these inaccuracies, highlighting the potential consequences and challenges posed by factual errors in LLM outputs. Subsequently, we analyze the mechanisms through which LLMs store and process facts, seeking the primary causes of factual errors. Our discussion then transitions to methodologies for evaluating LLM factuality, emphasizing key metrics, benchmarks, and studies. We further explore strategies for enhancing LLM factuality, including approaches tailored for specific domains. We focus two primary LLM configurations standalone LLMs and Retrieval-Augmented LLMs that utilizes external data, we detail their unique challenges and potential enhancements. Our survey offers a structured guide for researchers aiming to fortify the factual reliability of LLMs.","sentences":["This survey addresses the crucial issue of factuality in Large Language Models (LLMs).","As LLMs find applications across diverse domains, the reliability and accuracy of their outputs become vital.","We define the Factuality Issue as the probability of LLMs to produce content inconsistent with established facts.","We first delve into the implications of these inaccuracies, highlighting the potential consequences and challenges posed by factual errors in LLM outputs.","Subsequently, we analyze the mechanisms through which LLMs store and process facts, seeking the primary causes of factual errors.","Our discussion then transitions to methodologies for evaluating LLM factuality, emphasizing key metrics, benchmarks, and studies.","We further explore strategies for enhancing LLM factuality, including approaches tailored for specific domains.","We focus two primary LLM configurations standalone LLMs and Retrieval-Augmented LLMs that utilizes external data, we detail their unique challenges and potential enhancements.","Our survey offers a structured guide for researchers aiming to fortify the factual reliability of LLMs."],"url":"http://arxiv.org/abs/2310.07521v1"}
{"created":"2023-10-11 14:16:04","title":"Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning","abstract":"Posterior sampling allows the exploitation of prior knowledge of the environment's transition dynamics to improve the sample efficiency of reinforcement learning. The prior is typically specified as a class of parametric distributions, a task that can be cumbersome in practice, often resulting in the choice of uninformative priors. In this work, we propose a novel posterior sampling approach in which the prior is given as a (partial) causal graph over the environment's variables. The latter is often more natural to design, such as listing known causal dependencies between biometric features in a medical treatment study. Specifically, we propose a hierarchical Bayesian procedure, called C-PSRL, simultaneously learning the full causal graph at the higher level and the parameters of the resulting factored dynamics at the lower level. For this procedure, we provide an analysis of its Bayesian regret, which explicitly connects the regret rate with the degree of prior knowledge. Our numerical evaluation conducted in illustrative domains confirms that C-PSRL strongly improves the efficiency of posterior sampling with an uninformative prior while performing close to posterior sampling with the full causal graph.","sentences":["Posterior sampling allows the exploitation of prior knowledge of the environment's transition dynamics to improve the sample efficiency of reinforcement learning.","The prior is typically specified as a class of parametric distributions, a task that can be cumbersome in practice, often resulting in the choice of uninformative priors.","In this work, we propose a novel posterior sampling approach in which the prior is given as a (partial) causal graph over the environment's variables.","The latter is often more natural to design, such as listing known causal dependencies between biometric features in a medical treatment study.","Specifically, we propose a hierarchical Bayesian procedure, called C-PSRL, simultaneously learning the full causal graph at the higher level and the parameters of the resulting factored dynamics at the lower level.","For this procedure, we provide an analysis of its Bayesian regret, which explicitly connects the regret rate with the degree of prior knowledge.","Our numerical evaluation conducted in illustrative domains confirms that C-PSRL strongly improves the efficiency of posterior sampling with an uninformative prior while performing close to posterior sampling with the full causal graph."],"url":"http://arxiv.org/abs/2310.07518v1"}
{"created":"2023-10-11 14:15:25","title":"CM-PIE: Cross-modal perception for interactive-enhanced audio-visual video parsing","abstract":"Audio-visual video parsing is the task of categorizing a video at the segment level with weak labels, and predicting them as audible or visible events. Recent methods for this task leverage the attention mechanism to capture the semantic correlations among the whole video across the audio-visual modalities. However, these approaches have overlooked the importance of individual segments within a video and the relationship among them, and tend to rely on a single modality when learning features. In this paper, we propose a novel interactive-enhanced cross-modal perception method~(CM-PIE), which can learn fine-grained features by applying a segment-based attention module. Furthermore, a cross-modal aggregation block is introduced to jointly optimize the semantic representation of audio and visual signals by enhancing inter-modal interactions. The experimental results show that our model offers improved parsing performance on the Look, Listen, and Parse dataset compared to other methods.","sentences":["Audio-visual video parsing is the task of categorizing a video at the segment level with weak labels, and predicting them as audible or visible events.","Recent methods for this task leverage the attention mechanism to capture the semantic correlations among the whole video across the audio-visual modalities.","However, these approaches have overlooked the importance of individual segments within a video and the relationship among them, and tend to rely on a single modality when learning features.","In this paper, we propose a novel interactive-enhanced cross-modal perception method~(CM-PIE), which can learn fine-grained features by applying a segment-based attention module.","Furthermore, a cross-modal aggregation block is introduced to jointly optimize the semantic representation of audio and visual signals by enhancing inter-modal interactions.","The experimental results show that our model offers improved parsing performance on the Look, Listen, and Parse dataset compared to other methods."],"url":"http://arxiv.org/abs/2310.07517v1"}
{"created":"2023-10-11 14:14:05","title":"Energy Estimates Across Layers of Computing: From Devices to Large-Scale Applications in Machine Learning for Natural Language Processing, Scientific Computing, and Cryptocurrency Mining","abstract":"Estimates of energy usage in layers of computing from devices to algorithms have been determined and analyzed. Building on the previous analysis [3], energy needed from single devices and systems including three large-scale computing applications such as Artificial Intelligence (AI)/Machine Learning for Natural Language Processing, Scientific Simulations, and Cryptocurrency Mining have been estimated. In contrast to the bit-level switching, in which transistors achieved energy efficiency due to geometrical scaling, higher energy is expended both at the at the instructions and simulations levels of an application. Additionally, the analysis based on AI/ML Accelerators indicate that changes in architectures using an older semiconductor technology node have comparable energy efficiency with a different architecture using a newer technology. Further comparisons of the energy in computing systems with the thermodynamic and biological limits, indicate that there is a 27-36 orders of magnitude higher energy requirements for total simulation of an application. These energy estimates underscore the need for serious considerations of energy efficiency in computing by including energy as a design parameter, enabling growing needs of compute-intensive applications in a digital world.","sentences":["Estimates of energy usage in layers of computing from devices to algorithms have been determined and analyzed.","Building on the previous analysis [3], energy needed from single devices and systems including three large-scale computing applications such as Artificial Intelligence (AI)/Machine Learning for Natural Language Processing, Scientific Simulations, and Cryptocurrency Mining have been estimated.","In contrast to the bit-level switching, in which transistors achieved energy efficiency due to geometrical scaling, higher energy is expended both at the at the instructions and simulations levels of an application.","Additionally, the analysis based on AI/ML Accelerators indicate that changes in architectures using an older semiconductor technology node have comparable energy efficiency with a different architecture using a newer technology.","Further comparisons of the energy in computing systems with the thermodynamic and biological limits, indicate that there is a 27-36 orders of magnitude higher energy requirements for total simulation of an application.","These energy estimates underscore the need for serious considerations of energy efficiency in computing by including energy as a design parameter, enabling growing needs of compute-intensive applications in a digital world."],"url":"http://arxiv.org/abs/2310.07516v1"}
