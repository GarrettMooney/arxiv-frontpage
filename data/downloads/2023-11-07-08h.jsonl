{"created":"2023-11-06 18:59:58","title":"Exploitation-Guided Exploration for Semantic Embodied Navigation","abstract":"In the recent progress in embodied navigation and sim-to-robot transfer, modular policies have emerged as a de facto framework. However, there is more to compositionality beyond the decomposition of the learning load into modular components. In this work, we investigate a principled way to syntactically combine these components. Particularly, we propose Exploitation-Guided Exploration (XGX) where separate modules for exploration and exploitation come together in a novel and intuitive manner. We configure the exploitation module to take over in the deterministic final steps of navigation i.e. when the goal becomes visible. Crucially, an exploitation module teacher-forces the exploration module and continues driving an overridden policy optimization. XGX, with effective decomposition and novel guidance, improves the state-of-the-art performance on the challenging object navigation task from 70% to 73%. Along with better accuracy, through targeted analysis, we show that XGX is also more efficient at goal-conditioned exploration. Finally, we show sim-to-real transfer to robot hardware and XGX performs over two-fold better than the best baseline from simulation benchmarking. Project page: xgxvisnav.github.io","sentences":["In the recent progress in embodied navigation and sim-to-robot transfer, modular policies have emerged as a de facto framework.","However, there is more to compositionality beyond the decomposition of the learning load into modular components.","In this work, we investigate a principled way to syntactically combine these components.","Particularly, we propose Exploitation-Guided Exploration (XGX) where separate modules for exploration and exploitation come together in a novel and intuitive manner.","We configure the exploitation module to take over in the deterministic final steps of navigation i.e. when the goal becomes visible.","Crucially, an exploitation module teacher-forces the exploration module and continues driving an overridden policy optimization.","XGX, with effective decomposition and novel guidance, improves the state-of-the-art performance on the challenging object navigation task from 70% to 73%.","Along with better accuracy, through targeted analysis, we show that XGX is also more efficient at goal-conditioned exploration.","Finally, we show sim-to-real transfer to robot hardware and XGX performs over two-fold better than the best baseline from simulation benchmarking.","Project page: xgxvisnav.github.io"],"url":"http://arxiv.org/abs/2311.03357v1"}
{"created":"2023-11-06 18:59:57","title":"SegGen: Supercharging Segmentation Models with Text2Mask and Mask2Img Synthesis","abstract":"We propose SegGen, a highly-effective training data generation method for image segmentation, which pushes the performance limits of state-of-the-art segmentation models to a significant extent. SegGen designs and integrates two data generation strategies: MaskSyn and ImgSyn. (i) MaskSyn synthesizes new mask-image pairs via our proposed text-to-mask generation model and mask-to-image generation model, greatly improving the diversity in segmentation masks for model supervision; (ii) ImgSyn synthesizes new images based on existing masks using the mask-to-image generation model, strongly improving image diversity for model inputs. On the highly competitive ADE20K and COCO benchmarks, our data generation method markedly improves the performance of state-of-the-art segmentation models in semantic segmentation, panoptic segmentation, and instance segmentation. Notably, in terms of the ADE20K mIoU, Mask2Former R50 is largely boosted from 47.2 to 49.9 (+2.7); Mask2Former Swin-L is also significantly increased from 56.1 to 57.4 (+1.3). These promising results strongly suggest the effectiveness of our SegGen even when abundant human-annotated training data is utilized. Moreover, training with our synthetic data makes the segmentation models more robust towards unseen domains. Project website: https://seggenerator.github.io","sentences":["We propose SegGen, a highly-effective training data generation method for image segmentation, which pushes the performance limits of state-of-the-art segmentation models to a significant extent.","SegGen designs and integrates two data generation strategies: MaskSyn and ImgSyn.","(i) MaskSyn synthesizes new mask-image pairs via our proposed text-to-mask generation model and mask-to-image generation model, greatly improving the diversity in segmentation masks for model supervision; (ii) ImgSyn synthesizes new images based on existing masks using the mask-to-image generation model, strongly improving image diversity for model inputs.","On the highly competitive ADE20K and COCO benchmarks, our data generation method markedly improves the performance of state-of-the-art segmentation models in semantic segmentation, panoptic segmentation, and instance segmentation.","Notably, in terms of the ADE20K mIoU, Mask2Former R50 is largely boosted from 47.2 to 49.9 (+2.7); Mask2Former Swin-L is also significantly increased from 56.1 to 57.4 (+1.3).","These promising results strongly suggest the effectiveness of our SegGen even when abundant human-annotated training data is utilized.","Moreover, training with our synthetic data makes the segmentation models more robust towards unseen domains.","Project website: https://seggenerator.github.io"],"url":"http://arxiv.org/abs/2311.03355v1"}
{"created":"2023-11-06 18:59:57","title":"GLaMM: Pixel Grounding Large Multimodal Model","abstract":"Large Multimodal Models (LMMs) extend Large Language Models to the vision domain. Initial efforts towards LMMs used holistic images and text prompts to generate ungrounded textual responses. Very recently, region-level LMMs have been used to generate visually grounded responses. However, they are limited to only referring a single object category at a time, require users to specify the regions in inputs, or cannot offer dense pixel-wise object grounding. In this work, we present Grounding LMM (GLaMM), the first model that can generate natural language responses seamlessly intertwined with corresponding object segmentation masks. GLaMM not only grounds objects appearing in the conversations but is flexible enough to accept both textual and optional visual prompts (region of interest) as input. This empowers users to interact with the model at various levels of granularity, both in textual and visual domains. Due to the lack of standard benchmarks for the novel setting of generating visually grounded detailed conversations, we introduce a comprehensive evaluation protocol with our curated grounded conversations. Our proposed Grounded Conversation Generation (GCG) task requires densely grounded concepts in natural scenes at a large-scale. To this end, we propose a densely annotated Grounding-anything Dataset (GranD) using our proposed automated annotation pipeline that encompasses 7.5M unique concepts grounded in a total of 810M regions available with segmentation masks. Besides GCG, GLaMM also performs effectively on several downstream tasks e.g., referring expression segmentation, image and region-level captioning and vision-language conversations. Project Page: https://mbzuai-oryx.github.io/groundingLMM.","sentences":["Large Multimodal Models (LMMs) extend Large Language Models to the vision domain.","Initial efforts towards LMMs used holistic images and text prompts to generate ungrounded textual responses.","Very recently, region-level LMMs have been used to generate visually grounded responses.","However, they are limited to only referring a single object category at a time, require users to specify the regions in inputs, or cannot offer dense pixel-wise object grounding.","In this work, we present Grounding LMM (GLaMM), the first model that can generate natural language responses seamlessly intertwined with corresponding object segmentation masks.","GLaMM not only grounds objects appearing in the conversations but is flexible enough to accept both textual and optional visual prompts (region of interest) as input.","This empowers users to interact with the model at various levels of granularity, both in textual and visual domains.","Due to the lack of standard benchmarks for the novel setting of generating visually grounded detailed conversations, we introduce a comprehensive evaluation protocol with our curated grounded conversations.","Our proposed Grounded Conversation Generation (GCG) task requires densely grounded concepts in natural scenes at a large-scale.","To this end, we propose a densely annotated Grounding-anything Dataset (GranD) using our proposed automated annotation pipeline that encompasses 7.5M unique concepts grounded in a total of 810M regions available with segmentation masks.","Besides GCG, GLaMM also performs effectively on several downstream tasks e.g., referring expression segmentation, image and region-level captioning and vision-language conversations.","Project Page: https://mbzuai-oryx.github.io/groundingLMM."],"url":"http://arxiv.org/abs/2311.03356v1"}
{"created":"2023-11-06 18:59:44","title":"CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding","abstract":"A remarkable ability of human beings resides in compositional reasoning, i.e., the capacity to make \"infinite use of finite means\". However, current large vision-language foundation models (VLMs) fall short of such compositional abilities due to their \"bag-of-words\" behaviors and inability to construct words that correctly represent visual entities and the relations among the entities. To this end, we propose CoVLM, which can guide the LLM to explicitly compose visual entities and relationships among the text and dynamically communicate with the vision encoder and detection network to achieve vision-language communicative decoding. Specifically, we first devise a set of novel communication tokens for the LLM, for dynamic communication between the visual detection system and the language system. A communication token is generated by the LLM following a visual entity or a relation, to inform the detection network to propose regions that are relevant to the sentence generated so far. The proposed regions-of-interests (ROIs) are then fed back into the LLM for better language generation contingent on the relevant regions. The LLM is thus able to compose the visual entities and relationships through the communication tokens. The vision-to-language and language-to-vision communication are iteratively performed until the entire sentence is generated. Our framework seamlessly bridges the gap between visual perception and LLMs and outperforms previous VLMs by a large margin on compositional reasoning benchmarks (e.g., ~20% in HICO-DET mAP, ~14% in Cola top-1 accuracy, and ~3% on ARO top-1 accuracy). We also achieve state-of-the-art performances on traditional vision-language tasks such as referring expression comprehension and visual question answering.","sentences":["A remarkable ability of human beings resides in compositional reasoning, i.e., the capacity to make \"infinite use of finite means\".","However, current large vision-language foundation models (VLMs) fall short of such compositional abilities due to their \"bag-of-words\" behaviors and inability to construct words that correctly represent visual entities and the relations among the entities.","To this end, we propose CoVLM, which can guide the LLM to explicitly compose visual entities and relationships among the text and dynamically communicate with the vision encoder and detection network to achieve vision-language communicative decoding.","Specifically, we first devise a set of novel communication tokens for the LLM, for dynamic communication between the visual detection system and the language system.","A communication token is generated by the LLM following a visual entity or a relation, to inform the detection network to propose regions that are relevant to the sentence generated so far.","The proposed regions-of-interests (ROIs) are then fed back into the LLM for better language generation contingent on the relevant regions.","The LLM is thus able to compose the visual entities and relationships through the communication tokens.","The vision-to-language and language-to-vision communication are iteratively performed until the entire sentence is generated.","Our framework seamlessly bridges the gap between visual perception and LLMs and outperforms previous VLMs by a large margin on compositional reasoning benchmarks (e.g., ~20% in HICO-DET mAP, ~14% in Cola top-1 accuracy, and ~3% on ARO top-1 accuracy).","We also achieve state-of-the-art performances on traditional vision-language tasks such as referring expression comprehension and visual question answering."],"url":"http://arxiv.org/abs/2311.03354v1"}
{"created":"2023-11-06 18:59:01","title":"Rethinking Evaluation Metrics of Open-Vocabulary Segmentaion","abstract":"In this paper, we highlight a problem of evaluation metrics adopted in the open-vocabulary segmentation. That is, the evaluation process still heavily relies on closed-set metrics on zero-shot or cross-dataset pipelines without considering the similarity between predicted and ground truth categories. To tackle this issue, we first survey eleven similarity measurements between two categorical words using WordNet linguistics statistics, text embedding, and language models by comprehensive quantitative analysis and user study. Built upon those explored measurements, we designed novel evaluation metrics, namely Open mIoU, Open AP, and Open PQ, tailored for three open-vocabulary segmentation tasks. We benchmarked the proposed evaluation metrics on 12 open-vocabulary methods of three segmentation tasks. Even though the relative subjectivity of similarity distance, we demonstrate that our metrics can still well evaluate the open ability of the existing open-vocabulary segmentation methods. We hope that our work can bring with the community new thinking about how to evaluate the open ability of models. The evaluation code is released in github.","sentences":["In this paper, we highlight a problem of evaluation metrics adopted in the open-vocabulary segmentation.","That is, the evaluation process still heavily relies on closed-set metrics on zero-shot or cross-dataset pipelines without considering the similarity between predicted and ground truth categories.","To tackle this issue, we first survey eleven similarity measurements between two categorical words using WordNet linguistics statistics, text embedding, and language models by comprehensive quantitative analysis and user study.","Built upon those explored measurements, we designed novel evaluation metrics, namely Open mIoU, Open AP, and Open PQ, tailored for three open-vocabulary segmentation tasks.","We benchmarked the proposed evaluation metrics on 12 open-vocabulary methods of three segmentation tasks.","Even though the relative subjectivity of similarity distance, we demonstrate that our metrics can still well evaluate the open ability of the existing open-vocabulary segmentation methods.","We hope that our work can bring with the community new thinking about how to evaluate the open ability of models.","The evaluation code is released in github."],"url":"http://arxiv.org/abs/2311.03352v1"}
{"created":"2023-11-06 18:58:59","title":"Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization","abstract":"Combining offline and online reinforcement learning (RL) is crucial for efficient and safe learning. However, previous approaches treat offline and online learning as separate procedures, resulting in redundant designs and limited performance. We ask: Can we achieve straightforward yet effective offline and online learning without introducing extra conservatism or regularization? In this study, we propose Uni-o4, which utilizes an on-policy objective for both offline and online learning. Owning to the alignment of objectives in two phases, the RL agent can transfer between offline and online learning seamlessly. This property enhances the flexibility of the learning paradigm, allowing for arbitrary combinations of pretraining, fine-tuning, offline, and online learning. In the offline phase, specifically, Uni-o4 leverages diverse ensemble policies to address the mismatch issues between the estimated behavior policy and the offline dataset. Through a simple offline policy evaluation (OPE) approach, Uni-o4 can achieve multi-step policy improvement safely. We demonstrate that by employing the method above, the fusion of these two paradigms can yield superior offline initialization as well as stable and rapid online fine-tuning capabilities. Through real-world robot tasks, we highlight the benefits of this paradigm for rapid deployment in challenging, previously unseen real-world environments. Additionally, through comprehensive evaluations using numerous simulated benchmarks, we substantiate that our method achieves state-of-the-art performance in both offline and offline-to-online fine-tuning learning. Our website: https://lei-kun.github.io/uni-o4/ .","sentences":["Combining offline and online reinforcement learning (RL) is crucial for efficient and safe learning.","However, previous approaches treat offline and online learning as separate procedures, resulting in redundant designs and limited performance.","We ask: Can we achieve straightforward yet effective offline and online learning without introducing extra conservatism or regularization?","In this study, we propose Uni-o4, which utilizes an on-policy objective for both offline and online learning.","Owning to the alignment of objectives in two phases, the RL agent can transfer between offline and online learning seamlessly.","This property enhances the flexibility of the learning paradigm, allowing for arbitrary combinations of pretraining, fine-tuning, offline, and online learning.","In the offline phase, specifically, Uni-o4 leverages diverse ensemble policies to address the mismatch issues between the estimated behavior policy and the offline dataset.","Through a simple offline policy evaluation (OPE) approach, Uni-o4 can achieve multi-step policy improvement safely.","We demonstrate that by employing the method above, the fusion of these two paradigms can yield superior offline initialization as well as stable and rapid online fine-tuning capabilities.","Through real-world robot tasks, we highlight the benefits of this paradigm for rapid deployment in challenging, previously unseen real-world environments.","Additionally, through comprehensive evaluations using numerous simulated benchmarks, we substantiate that our method achieves state-of-the-art performance in both offline and offline-to-online fine-tuning learning.","Our website: https://lei-kun.github.io/uni-o4/ ."],"url":"http://arxiv.org/abs/2311.03351v1"}
{"created":"2023-11-06 18:55:18","title":"Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation","abstract":"Despite efforts to align large language models to produce harmless responses, they are still vulnerable to jailbreak prompts that elicit unrestricted behaviour. In this work, we investigate persona modulation as a black-box jailbreaking method to steer a target model to take on personalities that are willing to comply with harmful instructions. Rather than manually crafting prompts for each persona, we automate the generation of jailbreaks using a language model assistant. We demonstrate a range of harmful completions made possible by persona modulation, including detailed instructions for synthesising methamphetamine, building a bomb, and laundering money. These automated attacks achieve a harmful completion rate of 42.5% in GPT-4, which is 185 times larger than before modulation (0.23%). These prompts also transfer to Claude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%, respectively. Our work reveals yet another vulnerability in commercial large language models and highlights the need for more comprehensive safeguards.","sentences":["Despite efforts to align large language models to produce harmless responses, they are still vulnerable to jailbreak prompts that elicit unrestricted behaviour.","In this work, we investigate persona modulation as a black-box jailbreaking method to steer a target model to take on personalities that are willing to comply with harmful instructions.","Rather than manually crafting prompts for each persona, we automate the generation of jailbreaks using a language model assistant.","We demonstrate a range of harmful completions made possible by persona modulation, including detailed instructions for synthesising methamphetamine, building a bomb, and laundering money.","These automated attacks achieve a harmful completion rate of 42.5% in GPT-4, which is 185 times larger than before modulation (0.23%).","These prompts also transfer to Claude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%, respectively.","Our work reveals yet another vulnerability in commercial large language models and highlights the need for more comprehensive safeguards."],"url":"http://arxiv.org/abs/2311.03348v1"}
{"created":"2023-11-06 18:53:01","title":"Long-Term Invariant Local Features via Implicit Cross-Domain Correspondences","abstract":"Modern learning-based visual feature extraction networks perform well in intra-domain localization, however, their performance significantly declines when image pairs are captured across long-term visual domain variations, such as different seasonal and daytime variations. In this paper, our first contribution is a benchmark to investigate the performance impact of long-term variations on visual localization. We conduct a thorough analysis of the performance of current state-of-the-art feature extraction networks under various domain changes and find a significant performance gap between intra- and cross-domain localization. We investigate different methods to close this gap by improving the supervision of modern feature extractor networks. We propose a novel data-centric method, Implicit Cross-Domain Correspondences (iCDC). iCDC represents the same environment with multiple Neural Radiance Fields, each fitting the scene under individual visual domains. It utilizes the underlying 3D representations to generate accurate correspondences across different long-term visual conditions. Our proposed method enhances cross-domain localization performance, significantly reducing the performance gap. When evaluated on popular long-term localization benchmarks, our trained networks consistently outperform existing methods. This work serves as a substantial stride toward more robust visual localization pipelines for long-term deployments, and opens up research avenues in the development of long-term invariant descriptors.","sentences":["Modern learning-based visual feature extraction networks perform well in intra-domain localization, however, their performance significantly declines when image pairs are captured across long-term visual domain variations, such as different seasonal and daytime variations.","In this paper, our first contribution is a benchmark to investigate the performance impact of long-term variations on visual localization.","We conduct a thorough analysis of the performance of current state-of-the-art feature extraction networks under various domain changes and find a significant performance gap between intra- and cross-domain localization.","We investigate different methods to close this gap by improving the supervision of modern feature extractor networks.","We propose a novel data-centric method, Implicit Cross-Domain Correspondences (iCDC).","iCDC represents the same environment with multiple Neural Radiance Fields, each fitting the scene under individual visual domains.","It utilizes the underlying 3D representations to generate accurate correspondences across different long-term visual conditions.","Our proposed method enhances cross-domain localization performance, significantly reducing the performance gap.","When evaluated on popular long-term localization benchmarks, our trained networks consistently outperform existing methods.","This work serves as a substantial stride toward more robust visual localization pipelines for long-term deployments, and opens up research avenues in the development of long-term invariant descriptors."],"url":"http://arxiv.org/abs/2311.03345v1"}
{"created":"2023-11-06 18:53:01","title":"Decomposing Probability Marginals Beyond Affine Requirements","abstract":"Consider the triplet $(E, \\mathcal{P}, \\pi)$, where $E$ is a finite ground set, $\\mathcal{P} \\subseteq 2^E$ is a collection of subsets of $E$ and $\\pi : \\mathcal{P} \\rightarrow [0,1]$ is a requirement function. Given a vector of marginals $\\rho \\in [0, 1]^E$, our goal is to find a distribution for a random subset $S \\subseteq E$ such that $\\operatorname{Pr}[e \\in S] = \\rho_e$ for all $e \\in E$ and $\\operatorname{Pr}[P \\cap S \\neq \\emptyset] \\geq \\pi_P$ for all $P \\in \\mathcal{P}$, or to determine that no such distribution exists.   Generalizing results of Dahan, Amin, and Jaillet, we devise a generic decomposition algorithm that solves the above problem when provided with a suitable sequence of admissible support candidates (ASCs). We show how to construct such ASCs for numerous settings, including supermodular requirements, Hoffman-Schwartz-type lattice polyhedra, and abstract networks where $\\pi$ fulfils a conservation law. The resulting algorithm can be carried out efficiently when $\\mathcal{P}$ and $\\pi$ can be accessed via appropriate oracles. For any system allowing the construction of ASCs, our results imply a simple polyhedral description of the set of marginal vectors for which the decomposition problem is feasible. Finally, we characterize balanced hypergraphs as the systems $(E, \\mathcal{P})$ that allow the perfect decomposition of any marginal vector $\\rho \\in [0,1]^E$, i.e., where we can always find a distribution reaching the highest attainable probability $\\operatorname{Pr}[P \\cap S \\neq \\emptyset] = \\min \\{ \\sum_{e \\in P} \\rho_e, 1\\}$ for all $P \\in \\mathcal{P}$.","sentences":["Consider the triplet $(E, \\mathcal{P}, \\pi)$, where $E$ is a finite ground set, $\\mathcal{P} \\subseteq 2^E$ is a collection of subsets of $E$ and $\\pi : \\mathcal{P} \\rightarrow","[0,1]$ is a requirement function.","Given a vector of marginals $\\rho \\in","[0, 1]^E$, our goal is to find a distribution for a random subset $S \\subseteq E$ such that $\\operatorname{Pr}[e \\in S] = \\rho_e$ for all $e \\in E$ and $\\operatorname{Pr}[P \\cap S \\neq \\emptyset] \\geq \\pi_P$ for all $P \\in \\mathcal{P}$, or to determine that no such distribution exists.   ","Generalizing results of Dahan, Amin, and Jaillet, we devise a generic decomposition algorithm that solves the above problem when provided with a suitable sequence of admissible support candidates (ASCs).","We show how to construct such ASCs for numerous settings, including supermodular requirements, Hoffman-Schwartz-type lattice polyhedra, and abstract networks where $\\pi$ fulfils a conservation law.","The resulting algorithm can be carried out efficiently when $\\mathcal{P}$ and $\\pi$ can be accessed via appropriate oracles.","For any system allowing the construction of ASCs, our results imply a simple polyhedral description of the set of marginal vectors for which the decomposition problem is feasible.","Finally, we characterize balanced hypergraphs as the systems $(E, \\mathcal{P})$ that allow the perfect decomposition of any marginal vector $\\rho \\in","[0,1]^E$, i.e., where we can always find a distribution reaching the highest attainable probability $\\operatorname{Pr}[P \\cap S \\neq","\\emptyset] = \\min \\{ \\sum_{e \\in P} \\rho_e, 1\\}$ for all $P \\in \\mathcal{P}$."],"url":"http://arxiv.org/abs/2311.03346v1"}
{"created":"2023-11-06 18:44:55","title":"Embedding First Order Logic into Kernel Machines","abstract":"In this paper we propose a general framework to integrate supervised and unsupervised examples with background knowledge expressed by a collection of first-order logic clauses into kernel machines. In particular, we consider a multi-task learning scheme where multiple predicates defined on a set of objects are to be jointly learned from examples, enforcing a set of FOL constraints on the admissible configurations of their values. The predicates are defined on the feature spaces, in which the input objects are represented, and can be either known a priori or approximated by an appropriate kernel-based learner. A general approach is presented to convert the FOL clauses into a continuous implementation that can deal with the outputs computed by the kernel-based predicates. The learning problem is formulated as a semi-supervised task that requires the optimization in the primal of a loss function that combines a fitting loss measure on the supervised examples, a regularization term, and a penalty term that enforces the constraints on both the supervised and unsupervised examples. Unfortunately, the penalty term is not convex and it can hinder the optimization process. However, it is possible to avoid poor solutions by using a two stage learning schema, in which the supervised examples are learned first and then the constraints are enforced.","sentences":["In this paper we propose a general framework to integrate supervised and unsupervised examples with background knowledge expressed by a collection of first-order logic clauses into kernel machines.","In particular, we consider a multi-task learning scheme where multiple predicates defined on a set of objects are to be jointly learned from examples, enforcing a set of FOL constraints on the admissible configurations of their values.","The predicates are defined on the feature spaces, in which the input objects are represented, and can be either known a priori or approximated by an appropriate kernel-based learner.","A general approach is presented to convert the FOL clauses into a continuous implementation that can deal with the outputs computed by the kernel-based predicates.","The learning problem is formulated as a semi-supervised task that requires the optimization in the primal of a loss function that combines a fitting loss measure on the supervised examples, a regularization term, and a penalty term that enforces the constraints on both the supervised and unsupervised examples.","Unfortunately, the penalty term is not convex and it can hinder the optimization process.","However, it is possible to avoid poor solutions by using a two stage learning schema, in which the supervised examples are learned first and then the constraints are enforced."],"url":"http://arxiv.org/abs/2311.03340v1"}
{"created":"2023-11-06 18:42:05","title":"FLOGA: A machine learning ready dataset, a benchmark and a novel deep learning model for burnt area mapping with Sentinel-2","abstract":"Over the last decade there has been an increasing frequency and intensity of wildfires across the globe, posing significant threats to human and animal lives, ecosystems, and socio-economic stability. Therefore urgent action is required to mitigate their devastating impact and safeguard Earth's natural resources. Robust Machine Learning methods combined with the abundance of high-resolution satellite imagery can provide accurate and timely mappings of the affected area in order to assess the scale of the event, identify the impacted assets and prioritize and allocate resources effectively for the proper restoration of the damaged region. In this work, we create and introduce a machine-learning ready dataset we name FLOGA (Forest wiLdfire Observations for the Greek Area). This dataset is unique as it comprises of satellite imagery acquired before and after a wildfire event, it contains information from Sentinel-2 and MODIS modalities with variable spatial and spectral resolution, and contains a large number of events where the corresponding burnt area ground truth has been annotated by domain experts. FLOGA covers the wider region of Greece, which is characterized by a Mediterranean landscape and climatic conditions. We use FLOGA to provide a thorough comparison of multiple Machine Learning and Deep Learning algorithms for the automatic extraction of burnt areas, approached as a change detection task. We also compare the results to those obtained using standard specialized spectral indices for burnt area mapping. Finally, we propose a novel Deep Learning model, namely BAM-CD. Our benchmark results demonstrate the efficacy of the proposed technique in the automatic extraction of burnt areas, outperforming all other methods in terms of accuracy and robustness. Our dataset and code are publicly available at: https://github.com/Orion-AI-Lab/FLOGA.","sentences":["Over the last decade there has been an increasing frequency and intensity of wildfires across the globe, posing significant threats to human and animal lives, ecosystems, and socio-economic stability.","Therefore urgent action is required to mitigate their devastating impact and safeguard Earth's natural resources.","Robust Machine Learning methods combined with the abundance of high-resolution satellite imagery can provide accurate and timely mappings of the affected area in order to assess the scale of the event, identify the impacted assets and prioritize and allocate resources effectively for the proper restoration of the damaged region.","In this work, we create and introduce a machine-learning ready dataset we name FLOGA (Forest wiLdfire Observations for the Greek Area).","This dataset is unique as it comprises of satellite imagery acquired before and after a wildfire event, it contains information from Sentinel-2 and MODIS modalities with variable spatial and spectral resolution, and contains a large number of events where the corresponding burnt area ground truth has been annotated by domain experts.","FLOGA covers the wider region of Greece, which is characterized by a Mediterranean landscape and climatic conditions.","We use FLOGA to provide a thorough comparison of multiple Machine Learning and Deep Learning algorithms for the automatic extraction of burnt areas, approached as a change detection task.","We also compare the results to those obtained using standard specialized spectral indices for burnt area mapping.","Finally, we propose a novel Deep Learning model, namely BAM-CD.","Our benchmark results demonstrate the efficacy of the proposed technique in the automatic extraction of burnt areas, outperforming all other methods in terms of accuracy and robustness.","Our dataset and code are publicly available at: https://github.com/Orion-AI-Lab/FLOGA."],"url":"http://arxiv.org/abs/2311.03339v1"}
{"created":"2023-11-06 18:33:24","title":"Cross-Image Attention for Zero-Shot Appearance Transfer","abstract":"Recent advancements in text-to-image generative models have demonstrated a remarkable ability to capture a deep semantic understanding of images. In this work, we leverage this semantic knowledge to transfer the visual appearance between objects that share similar semantics but may differ significantly in shape. To achieve this, we build upon the self-attention layers of these generative models and introduce a cross-image attention mechanism that implicitly establishes semantic correspondences across images. Specifically, given a pair of images -- one depicting the target structure and the other specifying the desired appearance -- our cross-image attention combines the queries corresponding to the structure image with the keys and values of the appearance image. This operation, when applied during the denoising process, leverages the established semantic correspondences to generate an image combining the desired structure and appearance. In addition, to improve the output image quality, we harness three mechanisms that either manipulate the noisy latent codes or the model's internal representations throughout the denoising process. Importantly, our approach is zero-shot, requiring no optimization or training. Experiments show that our method is effective across a wide range of object categories and is robust to variations in shape, size, and viewpoint between the two input images.","sentences":["Recent advancements in text-to-image generative models have demonstrated a remarkable ability to capture a deep semantic understanding of images.","In this work, we leverage this semantic knowledge to transfer the visual appearance between objects that share similar semantics but may differ significantly in shape.","To achieve this, we build upon the self-attention layers of these generative models and introduce a cross-image attention mechanism that implicitly establishes semantic correspondences across images.","Specifically, given a pair of images -- one depicting the target structure and the other specifying the desired appearance -- our cross-image attention combines the queries corresponding to the structure image with the keys and values of the appearance image.","This operation, when applied during the denoising process, leverages the established semantic correspondences to generate an image combining the desired structure and appearance.","In addition, to improve the output image quality, we harness three mechanisms that either manipulate the noisy latent codes or the model's internal representations throughout the denoising process.","Importantly, our approach is zero-shot, requiring no optimization or training.","Experiments show that our method is effective across a wide range of object categories and is robust to variations in shape, size, and viewpoint between the two input images."],"url":"http://arxiv.org/abs/2311.03335v1"}
{"created":"2023-11-06 18:29:57","title":"Learning Hard-Constrained Models with One Sample","abstract":"We consider the problem of estimating the parameters of a Markov Random Field with hard-constraints using a single sample. As our main running examples, we use the $k$-SAT and the proper coloring models, as well as general $H$-coloring models; for all of these we obtain both positive and negative results. In contrast to the soft-constrained case, we show in particular that single-sample estimation is not always possible, and that the existence of an estimator is related to the existence of non-satisfiable instances.   Our algorithms are based on the pseudo-likelihood estimator. We show variance bounds for this estimator using coupling techniques inspired, in the case of $k$-SAT, by Moitra's sampling algorithm (JACM, 2019); our positive results for colorings build on this new coupling approach. For $q$-colorings on graphs with maximum degree $d$, we give a linear-time estimator when $q>d+1$, whereas the problem is non-identifiable when $q\\leq d+1$. For general $H$-colorings, we show that standard conditions that guarantee sampling, such as Dobrushin's condition, are insufficient for one-sample learning; on the positive side, we provide a general condition that is sufficient to guarantee linear-time learning and obtain applications for proper colorings and permissive models. For the $k$-SAT model on formulas with maximum degree $d$, we provide a linear-time estimator when $k\\gtrsim 6.45\\log d$, whereas the problem becomes non-identifiable when $k\\lesssim \\log d$.","sentences":["We consider the problem of estimating the parameters of a Markov Random Field with hard-constraints using a single sample.","As our main running examples, we use the $k$-SAT and the proper coloring models, as well as general $H$-coloring models; for all of these we obtain both positive and negative results.","In contrast to the soft-constrained case, we show in particular that single-sample estimation is not always possible, and that the existence of an estimator is related to the existence of non-satisfiable instances.   ","Our algorithms are based on the pseudo-likelihood estimator.","We show variance bounds for this estimator using coupling techniques inspired, in the case of $k$-SAT, by Moitra's sampling algorithm (JACM, 2019); our positive results for colorings build on this new coupling approach.","For $q$-colorings on graphs with maximum degree $d$, we give a linear-time estimator when $q>d+1$, whereas the problem is non-identifiable when $q\\leq d+1$. For general $H$-colorings, we show that standard conditions that guarantee sampling, such as Dobrushin's condition, are insufficient for one-sample learning; on the positive side, we provide a general condition that is sufficient to guarantee linear-time learning and obtain applications for proper colorings and permissive models.","For the $k$-SAT model on formulas with maximum degree $d$, we provide a linear-time estimator when $k\\gtrsim 6.45\\log d$, whereas the problem becomes non-identifiable when $k\\lesssim \\log d$."],"url":"http://arxiv.org/abs/2311.03332v1"}
{"created":"2023-11-06 18:25:28","title":"On Asynchrony, Memory, and Communication: Separations and Landscapes","abstract":"Research on distributed computing by a team of identical mobile computational entities, called robots, operating in a Euclidean space in $\\mathit{Look}$-$\\mathit{Compute}$-$\\mathit{Move}$ ($\\mathit{LCM}$) cycles, has recently focused on better understanding how the computational power of robots depends on the interplay between their internal capabilities (i.e., persistent memory, communication), captured by the four standard computational models (OBLOT, LUMI, FSTA, and FCOM) and the conditions imposed by the external environment, controlling the activation of the robots and their synchronization of their activities, perceived and modeled as an adversarial scheduler.   We consider a set of adversarial asynchronous schedulers ranging from the classical {\\em semi-synchronous} (SSYNCH) and {\\em fully asynchronous} (ASYNCH) settings, including schedulers (emerging when studying the atomicity of the combination of operations in the $\\mathit{LCM}$ cycles) whose adversarial power is in between those two. We ask the question: what is the computational relationship between a model $M_1$ under adversarial scheduler $K_1$ ($M_1(K_1)$) and a model $M_2$ under scheduler $K_2$ ($M_2(K_2)$)? For example, are the robots in $M_1(K_1)$ more powerful (i.e., they can solve more problems) than those in $M_2(K_2)$?   We answer all these questions by providing, through cross-model analysis, a complete characterization of the computational relationship between the power of the four models of robots under the considered asynchronous schedulers. In this process, we also provide qualified answers to several open questions, including the outstanding one on the proper dominance of \\ over \\ASY\\ in the case of unrestricted visibility.","sentences":["Research on distributed computing by a team of identical mobile computational entities, called robots, operating in a Euclidean space in $\\mathit{Look}$-$\\mathit{Compute}$-$\\mathit{Move}$ ($\\mathit{LCM}$) cycles, has recently focused on better understanding how the computational power of robots depends on the interplay between their internal capabilities (i.e., persistent memory, communication), captured by the four standard computational models (OBLOT, LUMI, FSTA, and FCOM) and the conditions imposed by the external environment, controlling the activation of the robots and their synchronization of their activities, perceived and modeled as an adversarial scheduler.   ","We consider a set of adversarial asynchronous schedulers ranging from the classical {\\em semi-synchronous} (SSYNCH) and {\\em fully asynchronous} (ASYNCH) settings, including schedulers (emerging when studying the atomicity of the combination of operations in the $\\mathit{LCM}$ cycles) whose adversarial power is in between those two.","We ask the question: what is the computational relationship between a model $M_1$ under adversarial scheduler $K_1$ ($M_1(K_1)$) and a model $M_2$ under scheduler $K_2$ ($M_2(K_2)$)?","For example, are the robots in $M_1(K_1)$ more powerful (i.e., they can solve more problems) than those in $M_2(K_2)$?   ","We answer all these questions by providing, through cross-model analysis, a complete characterization of the computational relationship between the power of the four models of robots under the considered asynchronous schedulers.","In this process, we also provide qualified answers to several open questions, including the outstanding one on the proper dominance of \\ over \\ASY\\ in the case of unrestricted visibility."],"url":"http://arxiv.org/abs/2311.03328v1"}
{"created":"2023-11-06 18:18:26","title":"A Robust Bi-Directional Algorithm For People Count In Crowded Areas","abstract":"People counting system in crowded places has become a very useful practical application that can be accomplished in various ways which include many traditional methods using sensors. Examining the case of real time scenarios, the algorithm espoused should be steadfast and accurate. People counting algorithm presented in this paper, is centered on blob assessment, devoted to yield the count of the people through a path along with the direction of traversal. The system depicted is often ensconced at the entrance of a building so that the unmitigated frequency of visitors can be recorded. The core premise of this work is to extricate count of people inflow and outflow pertaining to a particular area. The tot-up achieved can be exploited for purpose of statistics in the circumstances of any calamity occurrence in that zone. Relying upon the count totaled, the population in that vicinity can be assimilated in order to take on relevant measures to rescue the people.","sentences":["People counting system in crowded places has become a very useful practical application that can be accomplished in various ways which include many traditional methods using sensors.","Examining the case of real time scenarios, the algorithm espoused should be steadfast and accurate.","People counting algorithm presented in this paper, is centered on blob assessment, devoted to yield the count of the people through a path along with the direction of traversal.","The system depicted is often ensconced at the entrance of a building so that the unmitigated frequency of visitors can be recorded.","The core premise of this work is to extricate count of people inflow and outflow pertaining to a particular area.","The tot-up achieved can be exploited for purpose of statistics in the circumstances of any calamity occurrence in that zone.","Relying upon the count totaled, the population in that vicinity can be assimilated in order to take on relevant measures to rescue the people."],"url":"http://arxiv.org/abs/2311.03323v1"}
{"created":"2023-11-06 18:17:53","title":"Exact Shortest Paths with Rational Weights on the Word RAM","abstract":"Exact computation of shortest paths in weighted graphs has been traditionally studied in one of two settings. First, one can assume that the edge weights are real numbers and all the performed operations on reals (typically comparisons and additions) take constant time. Classical Dijkstra's and Bellman-Ford algorithms have been described in this setting. More efficient exact shortest paths algorithms have been obtained for integer-weighted graphs. Integrality assumption not only enables faster algorithms but also allows implementing the aforementioned algorithms in a much more realistic word RAM model where only arithmetic operations on $O(\\log{n})$-bit integers are performed in constant time. On the word RAM one can as efficiently exactly encode even \\emph{rational-weighted} instances with $O(\\log{n})$-bit numerators and denominators. However, the known exact real-weighted shortest paths algorithms, run on such a rational input, can easily encounter intermediate values of $\\Theta(n)$ bits if represented exactly. This leads to a factor-$\\Omega(n)$ slowdown on the word RAM. At the same time, the scaling algorithms suited for integer weights do not produce exact solutions for rational inputs without dramatically increasing their accuracy.   In this paper, we design randomized exact single-source shortest paths algorithms for rational-weighted graphs on the word RAM. Most importantly, in the non-negative case, we obtain a near-linear time algorithm matching Dijkstra's algorithm running time up to polylogarithmic factors. In presence of negative weights, we give an $\\tilde{O}(n^{2.5})$-time algorithm breaking through the best known strongly polynomial bound attained by Bellman-Ford for sufficiently dense graphs.","sentences":["Exact computation of shortest paths in weighted graphs has been traditionally studied in one of two settings.","First, one can assume that the edge weights are real numbers and all the performed operations on reals (typically comparisons and additions) take constant time.","Classical Dijkstra's and Bellman-Ford algorithms have been described in this setting.","More efficient exact shortest paths algorithms have been obtained for integer-weighted graphs.","Integrality assumption not only enables faster algorithms but also allows implementing the aforementioned algorithms in a much more realistic word RAM model where only arithmetic operations on $O(\\log{n})$-bit integers are performed in constant time.","On the word RAM one can as efficiently exactly encode even \\emph{rational-weighted} instances with $O(\\log{n})$-bit numerators and denominators.","However, the known exact real-weighted shortest paths algorithms, run on such a rational input, can easily encounter intermediate values of $\\Theta(n)$ bits if represented exactly.","This leads to a factor-$\\Omega(n)$ slowdown on the word RAM.","At the same time, the scaling algorithms suited for integer weights do not produce exact solutions for rational inputs without dramatically increasing their accuracy.   ","In this paper, we design randomized exact single-source shortest paths algorithms for rational-weighted graphs on the word RAM.","Most importantly, in the non-negative case, we obtain a near-linear time algorithm matching Dijkstra's algorithm running time up to polylogarithmic factors.","In presence of negative weights, we give an $\\tilde{O}(n^{2.5})$-time algorithm breaking through the best known strongly polynomial bound attained by Bellman-Ford for sufficiently dense graphs."],"url":"http://arxiv.org/abs/2311.03321v1"}
{"created":"2023-11-06 18:15:36","title":"Tackling Concept Shift in Text Classification using Entailment-style Modeling","abstract":"Pre-trained language models (PLMs) have seen tremendous success in text classification (TC) problems in the context of Natural Language Processing (NLP). In many real-world text classification tasks, the class definitions being learned do not remain constant but rather change with time - this is known as Concept Shift. Most techniques for handling concept shift rely on retraining the old classifiers with the newly labelled data. However, given the amount of training data required to fine-tune large DL models for the new concepts, the associated labelling costs can be prohibitively expensive and time consuming. In this work, we propose a reformulation, converting vanilla classification into an entailment-style problem that requires significantly less data to re-train the text classifier to adapt to new concepts. We demonstrate the effectiveness of our proposed method on both real world & synthetic datasets achieving absolute F1 gains upto 7% and 40% respectively in few-shot settings. Further, upon deployment, our solution also helped save 75% of labeling costs overall.","sentences":["Pre-trained language models (PLMs) have seen tremendous success in text classification (TC) problems in the context of Natural Language Processing (NLP).","In many real-world text classification tasks, the class definitions being learned do not remain constant but rather change with time - this is known as Concept Shift.","Most techniques for handling concept shift rely on retraining the old classifiers with the newly labelled data.","However, given the amount of training data required to fine-tune large DL models for the new concepts, the associated labelling costs can be prohibitively expensive and time consuming.","In this work, we propose a reformulation, converting vanilla classification into an entailment-style problem that requires significantly less data to re-train the text classifier to adapt to new concepts.","We demonstrate the effectiveness of our proposed method on both real world & synthetic datasets achieving absolute F1 gains upto 7% and 40% respectively in few-shot settings.","Further, upon deployment, our solution also helped save 75% of labeling costs overall."],"url":"http://arxiv.org/abs/2311.03320v1"}
{"created":"2023-11-06 18:12:55","title":"DAIL: Data Augmentation for In-Context Learning via Self-Paraphrase","abstract":"In-Context Learning (ICL) combined with pre-trained large language models has achieved promising results on various NLP tasks. However, ICL requires high-quality annotated demonstrations which might not be available in real-world scenarios. To overcome this limitation, we propose \\textbf{D}ata \\textbf{A}ugmentation for \\textbf{I}n-Context \\textbf{L}earning (\\textbf{DAIL}). DAIL leverages the intuition that large language models are more familiar with the content generated by themselves. It first utilizes the language model to generate paraphrases of the test sample and employs majority voting to determine the final result based on individual predictions. Our extensive empirical evaluation shows that DAIL outperforms the standard ICL method and other ensemble-based methods in the low-resource scenario. Additionally, we explore the use of voting consistency as a confidence score of the model when the logits of predictions are inaccessible. We believe our work will stimulate further research on ICL in low-resource settings.","sentences":["In-Context Learning (ICL) combined with pre-trained large language models has achieved promising results on various NLP tasks.","However, ICL requires high-quality annotated demonstrations which might not be available in real-world scenarios.","To overcome this limitation, we propose \\textbf{D}ata \\textbf{A}ugmentation for \\textbf{I}n-Context \\textbf{L}earning (\\textbf{DAIL}).","DAIL leverages the intuition that large language models are more familiar with the content generated by themselves.","It first utilizes the language model to generate paraphrases of the test sample and employs majority voting to determine the final result based on individual predictions.","Our extensive empirical evaluation shows that DAIL outperforms the standard ICL method and other ensemble-based methods in the low-resource scenario.","Additionally, we explore the use of voting consistency as a confidence score of the model when the logits of predictions are inaccessible.","We believe our work will stimulate further research on ICL in low-resource settings."],"url":"http://arxiv.org/abs/2311.03319v1"}
{"created":"2023-11-06 18:12:27","title":"A Foundation Model for Music Informatics","abstract":"This paper investigates foundation models tailored for music informatics, a domain currently challenged by the scarcity of labeled data and generalization issues. To this end, we conduct an in-depth comparative study among various foundation model variants, examining key determinants such as model architectures, tokenization methods, temporal resolution, data, and model scalability. This research aims to bridge the existing knowledge gap by elucidating how these individual factors contribute to the success of foundation models in music informatics. Employing a careful evaluation framework, we assess the performance of these models across diverse downstream tasks in music information retrieval, with a particular focus on token-level and sequence-level classification. Our results reveal that our model demonstrates robust performance, surpassing existing models in specific key metrics. These findings contribute to the understanding of self-supervised learning in music informatics and pave the way for developing more effective and versatile foundation models in the field. A pretrained version of our model is publicly available to foster reproducibility and future research.","sentences":["This paper investigates foundation models tailored for music informatics, a domain currently challenged by the scarcity of labeled data and generalization issues.","To this end, we conduct an in-depth comparative study among various foundation model variants, examining key determinants such as model architectures, tokenization methods, temporal resolution, data, and model scalability.","This research aims to bridge the existing knowledge gap by elucidating how these individual factors contribute to the success of foundation models in music informatics.","Employing a careful evaluation framework, we assess the performance of these models across diverse downstream tasks in music information retrieval, with a particular focus on token-level and sequence-level classification.","Our results reveal that our model demonstrates robust performance, surpassing existing models in specific key metrics.","These findings contribute to the understanding of self-supervised learning in music informatics and pave the way for developing more effective and versatile foundation models in the field.","A pretrained version of our model is publicly available to foster reproducibility and future research."],"url":"http://arxiv.org/abs/2311.03318v1"}
{"created":"2023-11-06 18:08:37","title":"Improving Collaborative Filtering Recommendation via Graph Learning","abstract":"Recommendation systems are designed to provide personalized predictions for items that are most appealing to individual customers. Among various types of recommendation algorithms, k-nearest neighbor based collaborative filtering algorithm attracts tremendous attention and are widely used in practice. However, the k-nearest neighbor scheme can only capture the local relationship among users and the uniform neighborhood size is also not suitable to represent the underlying data structure. In this paper, we leverage emerging graph signal processing (GSP) theory to construct sparse yet high quality graph to enhance the solution quality and efficiency of collaborative filtering algorithm. Experimental results show that our method outperforms k-NN based collaborative filtering algorithm by a large margin on the benchmark data set.","sentences":["Recommendation systems are designed to provide personalized predictions for items that are most appealing to individual customers.","Among various types of recommendation algorithms, k-nearest neighbor based collaborative filtering algorithm attracts tremendous attention and are widely used in practice.","However, the k-nearest neighbor scheme can only capture the local relationship among users and the uniform neighborhood size is also not suitable to represent the underlying data structure.","In this paper, we leverage emerging graph signal processing (GSP) theory to construct sparse yet high quality graph to enhance the solution quality and efficiency of collaborative filtering algorithm.","Experimental results show that our method outperforms k-NN based collaborative filtering algorithm by a large margin on the benchmark data set."],"url":"http://arxiv.org/abs/2311.03316v1"}
{"created":"2023-11-06 18:04:13","title":"A Single 2D Pose with Context is Worth Hundreds for 3D Human Pose Estimation","abstract":"The dominant paradigm in 3D human pose estimation that lifts a 2D pose sequence to 3D heavily relies on long-term temporal clues (i.e., using a daunting number of video frames) for improved accuracy, which incurs performance saturation, intractable computation and the non-causal problem. This can be attributed to their inherent inability to perceive spatial context as plain 2D joint coordinates carry no visual cues. To address this issue, we propose a straightforward yet powerful solution: leveraging the readily available intermediate visual representations produced by off-the-shelf (pre-trained) 2D pose detectors -- no finetuning on the 3D task is even needed. The key observation is that, while the pose detector learns to localize 2D joints, such representations (e.g., feature maps) implicitly encode the joint-centric spatial context thanks to the regional operations in backbone networks. We design a simple baseline named Context-Aware PoseFormer to showcase its effectiveness. Without access to any temporal information, the proposed method significantly outperforms its context-agnostic counterpart, PoseFormer, and other state-of-the-art methods using up to hundreds of video frames regarding both speed and precision. Project page: https://qitaozhao.github.io/ContextAware-PoseFormer","sentences":["The dominant paradigm in 3D human pose estimation that lifts a 2D pose sequence to 3D heavily relies on long-term temporal clues (i.e., using a daunting number of video frames) for improved accuracy, which incurs performance saturation, intractable computation and the non-causal problem.","This can be attributed to their inherent inability to perceive spatial context as plain 2D joint coordinates carry no visual cues.","To address this issue, we propose a straightforward yet powerful solution: leveraging the readily available intermediate visual representations produced by off-the-shelf (pre-trained) 2D pose detectors -- no finetuning on the 3D task is even needed.","The key observation is that, while the pose detector learns to localize 2D joints, such representations (e.g., feature maps) implicitly encode the joint-centric spatial context thanks to the regional operations in backbone networks.","We design a simple baseline named Context-Aware PoseFormer to showcase its effectiveness.","Without access to any temporal information, the proposed method significantly outperforms its context-agnostic counterpart, PoseFormer, and other state-of-the-art methods using up to hundreds of video frames regarding both speed and precision.","Project page: https://qitaozhao.github.io/ContextAware-PoseFormer"],"url":"http://arxiv.org/abs/2311.03312v1"}
{"created":"2023-11-06 18:01:34","title":"Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance","abstract":"Large Language Models (LLMs) are increasingly utilized in educational tasks such as providing writing suggestions to students. Despite their potential, LLMs are known to harbor inherent biases which may negatively impact learners. Previous studies have investigated bias in models and data representations separately, neglecting the potential impact of LLM bias on human writing. In this paper, we investigate how bias transfers through an AI writing support pipeline. We conduct a large-scale user study with 231 students writing business case peer reviews in German. Students are divided into five groups with different levels of writing support: one classroom group with feature-based suggestions and four groups recruited from Prolific -- a control group with no assistance, two groups with suggestions from fine-tuned GPT-2 and GPT-3 models, and one group with suggestions from pre-trained GPT-3.5. Using GenBit gender bias analysis, Word Embedding Association Tests (WEAT), and Sentence Embedding Association Test (SEAT) we evaluate the gender bias at various stages of the pipeline: in model embeddings, in suggestions generated by the models, and in reviews written by students. Our results demonstrate that there is no significant difference in gender bias between the resulting peer reviews of groups with and without LLM suggestions. Our research is therefore optimistic about the use of AI writing support in the classroom, showcasing a context where bias in LLMs does not transfer to students' responses.","sentences":["Large Language Models (LLMs) are increasingly utilized in educational tasks such as providing writing suggestions to students.","Despite their potential, LLMs are known to harbor inherent biases which may negatively impact learners.","Previous studies have investigated bias in models and data representations separately, neglecting the potential impact of LLM bias on human writing.","In this paper, we investigate how bias transfers through an AI writing support pipeline.","We conduct a large-scale user study with 231 students writing business case peer reviews in German.","Students are divided into five groups with different levels of writing support: one classroom group with feature-based suggestions and four groups recruited from Prolific -- a control group with no assistance, two groups with suggestions from fine-tuned GPT-2 and GPT-3 models, and one group with suggestions from pre-trained GPT-3.5.","Using GenBit gender bias analysis, Word Embedding Association Tests (WEAT), and Sentence Embedding Association Test (SEAT) we evaluate the gender bias at various stages of the pipeline: in model embeddings, in suggestions generated by the models, and in reviews written by students.","Our results demonstrate that there is no significant difference in gender bias between the resulting peer reviews of groups with and without LLM suggestions.","Our research is therefore optimistic about the use of AI writing support in the classroom, showcasing a context where bias in LLMs does not transfer to students' responses."],"url":"http://arxiv.org/abs/2311.03311v1"}
{"created":"2023-11-06 17:58:47","title":"Neural Structure Learning with Stochastic Differential Equations","abstract":"Discovering the underlying relationships among variables from temporal observations has been a longstanding challenge in numerous scientific disciplines, including biology, finance, and climate science. The dynamics of such systems are often best described using continuous-time stochastic processes. Unfortunately, most existing structure learning approaches assume that the underlying process evolves in discrete-time and/or observations occur at regular time intervals. These mismatched assumptions can often lead to incorrect learned structures and models. In this work, we introduce a novel structure learning method, SCOTCH, which combines neural stochastic differential equations (SDE) with variational inference to infer a posterior distribution over possible structures. This continuous-time approach can naturally handle both learning from and predicting observations at arbitrary time points. Theoretically, we establish sufficient conditions for an SDE and SCOTCH to be structurally identifiable, and prove its consistency under infinite data limits. Empirically, we demonstrate that our approach leads to improved structure learning performance on both synthetic and real-world datasets compared to relevant baselines under regular and irregular sampling intervals.","sentences":["Discovering the underlying relationships among variables from temporal observations has been a longstanding challenge in numerous scientific disciplines, including biology, finance, and climate science.","The dynamics of such systems are often best described using continuous-time stochastic processes.","Unfortunately, most existing structure learning approaches assume that the underlying process evolves in discrete-time and/or observations occur at regular time intervals.","These mismatched assumptions can often lead to incorrect learned structures and models.","In this work, we introduce a novel structure learning method, SCOTCH, which combines neural stochastic differential equations (SDE) with variational inference to infer a posterior distribution over possible structures.","This continuous-time approach can naturally handle both learning from and predicting observations at arbitrary time points.","Theoretically, we establish sufficient conditions for an SDE and SCOTCH to be structurally identifiable, and prove its consistency under infinite data limits.","Empirically, we demonstrate that our approach leads to improved structure learning performance on both synthetic and real-world datasets compared to relevant baselines under regular and irregular sampling intervals."],"url":"http://arxiv.org/abs/2311.03309v1"}
{"created":"2023-11-06 17:52:08","title":"TS-Diffusion: Generating Highly Complex Time Series with Diffusion Models","abstract":"While current generative models have achieved promising performances in time-series synthesis, they either make strong assumptions on the data format (e.g., regularities) or rely on pre-processing approaches (e.g., interpolations) to simplify the raw data. In this work, we consider a class of time series with three common bad properties, including sampling irregularities, missingness, and large feature-temporal dimensions, and introduce a general model, TS-Diffusion, to process such complex time series. Our model consists of three parts under the framework of point process. The first part is an encoder of the neural ordinary differential equation (ODE) that converts time series into dense representations, with the jump technique to capture sampling irregularities and self-attention mechanism to handle missing values; The second component of TS-Diffusion is a diffusion model that learns from the representation of time series. These time-series representations can have a complex distribution because of their high dimensions; The third part is a decoder of another ODE that generates time series with irregularities and missing values given their representations. We have conducted extensive experiments on multiple time-series datasets, demonstrating that TS-Diffusion achieves excellent results on both conventional and complex time series and significantly outperforms previous baselines.","sentences":["While current generative models have achieved promising performances in time-series synthesis, they either make strong assumptions on the data format (e.g., regularities) or rely on pre-processing approaches (e.g., interpolations) to simplify the raw data.","In this work, we consider a class of time series with three common bad properties, including sampling irregularities, missingness, and large feature-temporal dimensions, and introduce a general model, TS-Diffusion, to process such complex time series.","Our model consists of three parts under the framework of point process.","The first part is an encoder of the neural ordinary differential equation (ODE) that converts time series into dense representations, with the jump technique to capture sampling irregularities and self-attention mechanism to handle missing values; The second component of TS-Diffusion is a diffusion model that learns from the representation of time series.","These time-series representations can have a complex distribution because of their high dimensions; The third part is a decoder of another ODE that generates time series with irregularities and missing values given their representations.","We have conducted extensive experiments on multiple time-series datasets, demonstrating that TS-Diffusion achieves excellent results on both conventional and complex time series and significantly outperforms previous baselines."],"url":"http://arxiv.org/abs/2311.03303v1"}
{"created":"2023-11-06 17:49:34","title":"Ziya2: Data-centric Learning is All LLMs Need","abstract":"Various large language models (LLMs) have been proposed in recent years, including closed- and open-source ones, continually setting new records on multiple benchmarks. However, the development of LLMs still faces several issues, such as high cost of training models from scratch, and continual pre-training leading to catastrophic forgetting, etc. Although many such issues are addressed along the line of research on LLMs, an important yet practical limitation is that many studies overly pursue enlarging model sizes without comprehensively analyzing and optimizing the use of pre-training data in their learning process, as well as appropriate organization and leveraging of such data in training LLMs under cost-effective settings. In this work, we propose Ziya2, a model with 13 billion parameters adopting LLaMA2 as the foundation model, and further pre-trained on 700 billion tokens, where we focus on pre-training techniques and use data-centric optimization to enhance the learning process of Ziya2 on different stages. Experiments show that Ziya2 significantly outperforms other models in multiple benchmarks especially with promising results compared to representative open-source ones. Ziya2 (Base) is released at https://huggingface.co/IDEA-CCNL/Ziya2-13B-Base and https://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary.","sentences":["Various large language models (LLMs) have been proposed in recent years, including closed- and open-source ones, continually setting new records on multiple benchmarks.","However, the development of LLMs still faces several issues, such as high cost of training models from scratch, and continual pre-training leading to catastrophic forgetting, etc.","Although many such issues are addressed along the line of research on LLMs, an important yet practical limitation is that many studies overly pursue enlarging model sizes without comprehensively analyzing and optimizing the use of pre-training data in their learning process, as well as appropriate organization and leveraging of such data in training LLMs under cost-effective settings.","In this work, we propose Ziya2, a model with 13 billion parameters adopting LLaMA2 as the foundation model, and further pre-trained on 700 billion tokens, where we focus on pre-training techniques and use data-centric optimization to enhance the learning process of Ziya2 on different stages.","Experiments show that Ziya2 significantly outperforms other models in multiple benchmarks especially with promising results compared to representative open-source ones.","Ziya2 (Base) is released at https://huggingface.co/IDEA-CCNL/Ziya2-13B-Base and https://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary."],"url":"http://arxiv.org/abs/2311.03301v1"}
{"created":"2023-11-06 17:35:42","title":"Learning Reusable Manipulation Strategies","abstract":"Humans demonstrate an impressive ability to acquire and generalize manipulation \"tricks.\" Even from a single demonstration, such as using soup ladles to reach for distant objects, we can apply this skill to new scenarios involving different object positions, sizes, and categories (e.g., forks and hammers). Additionally, we can flexibly combine various skills to devise long-term plans. In this paper, we present a framework that enables machines to acquire such manipulation skills, referred to as \"mechanisms,\" through a single demonstration and self-play. Our key insight lies in interpreting each demonstration as a sequence of changes in robot-object and object-object contact modes, which provides a scaffold for learning detailed samplers for continuous parameters. These learned mechanisms and samplers can be seamlessly integrated into standard task and motion planners, enabling their compositional use.","sentences":["Humans demonstrate an impressive ability to acquire and generalize manipulation \"tricks.\"","Even from a single demonstration, such as using soup ladles to reach for distant objects, we can apply this skill to new scenarios involving different object positions, sizes, and categories (e.g., forks and hammers).","Additionally, we can flexibly combine various skills to devise long-term plans.","In this paper, we present a framework that enables machines to acquire such manipulation skills, referred to as \"mechanisms,\" through a single demonstration and self-play.","Our key insight lies in interpreting each demonstration as a sequence of changes in robot-object and object-object contact modes, which provides a scaffold for learning detailed samplers for continuous parameters.","These learned mechanisms and samplers can be seamlessly integrated into standard task and motion planners, enabling their compositional use."],"url":"http://arxiv.org/abs/2311.03293v1"}
{"created":"2023-11-06 17:35:35","title":"Data Science from 1963 to 2012","abstract":"Consensus on the definition of data science remains low despite the widespread establishment of academic programs in the field and continued demand for data scientists in industry. Definitions range from rebranded statistics to data-driven science to the science of data to simply the application of machine learning to so-called big data to solve real world problems. Current efforts to trace the history of the field in order to clarify its definition, such as Donoho's \"50 Years of Data Science\" (Donoho 2017), tend to focus on a short period when a small group of statisticians adopted the term in an unsuccessful attempt to rebrand their field in the face of the overshadowing effects of computational statistics and data mining. Using textual evidence from primary sources, this essay traces the history of the term to the 1960s, when it was first used by the US Air Force in a surprisingly similar way to its current usage, to 2012, the year that Harvard Business Review published the enormously influential article \"Data Scientist: The Sexiest Job of the 21st Century\" (Davenport and Patil 2012), while the American Statistical Association acknowledged a profound disconnect between statistics and data science. Among the themes that emerge from this review are (1) the long-standing opposition between data analysts and data miners that continues to animate the field, (2) an established definition of the term as the practice of managing and processing scientific data that has been occluded by recent usage, and (3) the phenomenon of data impedancethe disproportion between surplus data, indexed by phrases like data deluge and big data, and the limitations of computational machinery and methods to process them. This persistent condition appears to have motivated the use of the term and the field itself since its beginnings.","sentences":["Consensus on the definition of data science remains low despite the widespread establishment of academic programs in the field and continued demand for data scientists in industry.","Definitions range from rebranded statistics to data-driven science to the science of data to simply the application of machine learning to so-called big data to solve real world problems.","Current efforts to trace the history of the field in order to clarify its definition, such as Donoho's \"50 Years of Data Science\" (Donoho 2017), tend to focus on a short period when a small group of statisticians adopted the term in an unsuccessful attempt to rebrand their field in the face of the overshadowing effects of computational statistics and data mining.","Using textual evidence from primary sources, this essay traces the history of the term to the 1960s, when it was first used by the US Air Force in a surprisingly similar way to its current usage, to 2012, the year that Harvard Business Review published the enormously influential article \"Data Scientist:","The Sexiest Job of the 21st Century\" (Davenport and Patil 2012), while the American Statistical Association acknowledged a profound disconnect between statistics and data science.","Among the themes that emerge from this review are (1) the long-standing opposition between data analysts and data miners that continues to animate the field, (2) an established definition of the term as the practice of managing and processing scientific data that has been occluded by recent usage, and (3) the phenomenon of data impedancethe disproportion between surplus data, indexed by phrases like data deluge and big data, and the limitations of computational machinery and methods to process them.","This persistent condition appears to have motivated the use of the term and the field itself since its beginnings."],"url":"http://arxiv.org/abs/2311.03292v1"}
{"created":"2023-11-06 17:26:59","title":"Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges","abstract":"While GPT-4V(ision) impressively models both visual and textual information simultaneously, it's hallucination behavior has not been systematically assessed. To bridge this gap, we introduce a new benchmark, namely, the Bias and Interference Challenges in Visual Language Models (Bingo). This benchmark is designed to evaluate and shed light on the two common types of hallucinations in visual language models: bias and interference. Here, bias refers to the model's tendency to hallucinate certain types of responses, possibly due to imbalance in its training data. Interference pertains to scenarios where the judgment of GPT-4V(ision) can be disrupted due to how the text prompt is phrased or how the input image is presented. We identify a notable regional bias, whereby GPT-4V(ision) is better at interpreting Western images or images with English writing compared to images from other countries or containing text in other languages. Moreover, GPT-4V(ision) is vulnerable to leading questions and is often confused when interpreting multiple images together. Popular mitigation approaches, such as self-correction and chain-of-thought reasoning, are not effective in resolving these challenges. We also identified similar biases and interference vulnerabilities with LLaVA and Bard. Our results characterize the hallucination challenges in GPT-4V(ision) and state-of-the-art visual-language models, and highlight the need for new solutions. The Bingo benchmark is available at https://github.com/gzcch/Bingo.","sentences":["While GPT-4V(ision) impressively models both visual and textual information simultaneously, it's hallucination behavior has not been systematically assessed.","To bridge this gap, we introduce a new benchmark, namely, the Bias and Interference Challenges in Visual Language Models (Bingo).","This benchmark is designed to evaluate and shed light on the two common types of hallucinations in visual language models: bias and interference.","Here, bias refers to the model's tendency to hallucinate certain types of responses, possibly due to imbalance in its training data.","Interference pertains to scenarios where the judgment of GPT-4V(ision) can be disrupted due to how the text prompt is phrased or how the input image is presented.","We identify a notable regional bias, whereby GPT-4V(ision) is better at interpreting Western images or images with English writing compared to images from other countries or containing text in other languages.","Moreover, GPT-4V(ision) is vulnerable to leading questions and is often confused when interpreting multiple images together.","Popular mitigation approaches, such as self-correction and chain-of-thought reasoning, are not effective in resolving these challenges.","We also identified similar biases and interference vulnerabilities with LLaVA and Bard.","Our results characterize the hallucination challenges in GPT-4V(ision) and state-of-the-art visual-language models, and highlight the need for new solutions.","The Bingo benchmark is available at https://github.com/gzcch/Bingo."],"url":"http://arxiv.org/abs/2311.03287v1"}
{"created":"2023-11-06 17:26:17","title":"S-LoRA: Serving Thousands of Concurrent LoRA Adapters","abstract":"The \"pretrain-then-finetune\" paradigm is commonly adopted in the deployment of large language models. Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method, is often employed to adapt a base model to a multitude of tasks, resulting in a substantial collection of LoRA adapters derived from one base model. We observe that this paradigm presents significant opportunities for batched inference during serving. To capitalize on these opportunities, we present S-LoRA, a system designed for the scalable serving of many LoRA adapters. S-LoRA stores all adapters in the main memory and fetches the adapters used by the currently running queries to the GPU memory. To efficiently use the GPU memory and reduce fragmentation, S-LoRA proposes Unified Paging. Unified Paging uses a unified memory pool to manage dynamic adapter weights with different ranks and KV cache tensors with varying sequence lengths. Additionally, S-LoRA employs a novel tensor parallelism strategy and highly optimized custom CUDA kernels for heterogeneous batching of LoRA computation. Collectively, these features enable S-LoRA to serve thousands of LoRA adapters on a single GPU or across multiple GPUs with a small overhead. Compared to state-of-the-art libraries such as HuggingFace PEFT and vLLM (with naive support of LoRA serving), S-LoRA can improve the throughput by up to 4 times and increase the number of served adapters by several orders of magnitude. As a result, S-LoRA enables scalable serving of many task-specific fine-tuned models and offers the potential for large-scale customized fine-tuning services.","sentences":["The \"pretrain-then-finetune\" paradigm is commonly adopted in the deployment of large language models.","Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method, is often employed to adapt a base model to a multitude of tasks, resulting in a substantial collection of LoRA adapters derived from one base model.","We observe that this paradigm presents significant opportunities for batched inference during serving.","To capitalize on these opportunities, we present S-LoRA, a system designed for the scalable serving of many LoRA adapters.","S-LoRA stores all adapters in the main memory and fetches the adapters used by the currently running queries to the GPU memory.","To efficiently use the GPU memory and reduce fragmentation, S-LoRA proposes Unified Paging.","Unified Paging uses a unified memory pool to manage dynamic adapter weights with different ranks and KV cache tensors with varying sequence lengths.","Additionally, S-LoRA employs a novel tensor parallelism strategy and highly optimized custom CUDA kernels for heterogeneous batching of LoRA computation.","Collectively, these features enable S-LoRA to serve thousands of LoRA adapters on a single GPU or across multiple GPUs with a small overhead.","Compared to state-of-the-art libraries such as HuggingFace PEFT and vLLM (with naive support of LoRA serving), S-LoRA can improve the throughput by up to 4 times and increase the number of served adapters by several orders of magnitude.","As a result, S-LoRA enables scalable serving of many task-specific fine-tuned models and offers the potential for large-scale customized fine-tuning services."],"url":"http://arxiv.org/abs/2311.03285v1"}
{"created":"2023-11-06 17:23:50","title":"Resource Allocation for RIS-Empowered Wireless Communications: Low-Complexity and Robust Designs","abstract":"This article delves into advancements in resource allocation techniques tailored for systems utilizing reconfigurable intelligent surfaces (RIS), with a primary focus on achieving low-complexity and resilient solutions. The investigation of low-complexity approaches for RIS holds significant relevance, primarily owing to the intricate characteristics inherent in RIS-based systems and the need of deploying large-scale RIS arrays. Concurrently, the exploration of robust solutions aims to address the issue of hardware impairments occurring at both the transceivers and RIS components in practical RIS-assisted systems. In the realm of both low-complexity and robust resource allocation, this article not only elucidates the fundamental techniques underpinning these methodologies but also offers comprehensive numerical results for illustrative purposes. The necessity of adopting resource allocation strategies that are both low in complexity and resilient is thoroughly established. Ultimately, this article provides prospective research avenues in the domain of low-complexity and robust resource allocation techniques tailored for RIS-assisted systems.","sentences":["This article delves into advancements in resource allocation techniques tailored for systems utilizing reconfigurable intelligent surfaces (RIS), with a primary focus on achieving low-complexity and resilient solutions.","The investigation of low-complexity approaches for RIS holds significant relevance, primarily owing to the intricate characteristics inherent in RIS-based systems and the need of deploying large-scale RIS arrays.","Concurrently, the exploration of robust solutions aims to address the issue of hardware impairments occurring at both the transceivers and RIS components in practical RIS-assisted systems.","In the realm of both low-complexity and robust resource allocation, this article not only elucidates the fundamental techniques underpinning these methodologies but also offers comprehensive numerical results for illustrative purposes.","The necessity of adopting resource allocation strategies that are both low in complexity and resilient is thoroughly established.","Ultimately, this article provides prospective research avenues in the domain of low-complexity and robust resource allocation techniques tailored for RIS-assisted systems."],"url":"http://arxiv.org/abs/2311.03282v1"}
{"created":"2023-11-06 17:20:41","title":"Discretizing Numerical Attributes: An Analysis of Human Perceptions","abstract":"Machine learning (ML) has employed various discretization methods to partition numerical attributes into intervals. However, an effective discretization technique remains elusive in many ML applications, such as association rule mining. Moreover, the existing discretization techniques do not reflect best the impact of the independent numerical factor on the dependent numerical target factor. This research aims to establish a benchmark approach for numerical attribute partitioning. We conduct an extensive analysis of human perceptions of partitioning a numerical attribute and compare these perceptions with the results obtained from our two proposed measures. We also examine the perceptions of experts in data science, statistics, and engineering by employing numerical data visualization techniques. The analysis of collected responses reveals that $68.7\\%$ of human responses approximately closely align with the values generated by our proposed measures. Based on these findings, our proposed measures may be used as one of the methods for discretizing the numerical attributes.","sentences":["Machine learning (ML) has employed various discretization methods to partition numerical attributes into intervals.","However, an effective discretization technique remains elusive in many ML applications, such as association rule mining.","Moreover, the existing discretization techniques do not reflect best the impact of the independent numerical factor on the dependent numerical target factor.","This research aims to establish a benchmark approach for numerical attribute partitioning.","We conduct an extensive analysis of human perceptions of partitioning a numerical attribute and compare these perceptions with the results obtained from our two proposed measures.","We also examine the perceptions of experts in data science, statistics, and engineering by employing numerical data visualization techniques.","The analysis of collected responses reveals that $68.7\\%$ of human responses approximately closely align with the values generated by our proposed measures.","Based on these findings, our proposed measures may be used as one of the methods for discretizing the numerical attributes."],"url":"http://arxiv.org/abs/2311.03278v1"}
{"created":"2023-11-06 17:18:37","title":"Exploiting Latent Attribute Interaction with Transformer on Heterogeneous Information Networks","abstract":"Heterogeneous graph neural networks (HGNNs) have recently shown impressive capability in modeling heterogeneous graphs that are ubiquitous in real-world applications. Due to the diversity of attributes of nodes in different types, most existing models first align nodes by mapping them into the same low-dimensional space. However, in this way, they lose the type information of nodes. In addition, most of them only consider the interactions between nodes while neglecting the high-order information behind the latent interactions among different node features. To address these problems, in this paper, we propose a novel heterogeneous graph model MULAN, including two major components, i.e., a type-aware encoder and a dimension-aware encoder. Specifically, the type-aware encoder compensates for the loss of node type information and better leverages graph heterogeneity in learning node representations. Built upon transformer architecture, the dimension-aware encoder is capable of capturing the latent interactions among the diverse node features. With these components, the information of graph heterogeneity, node features and graph structure can be comprehensively encoded in node representations. We conduct extensive experiments on six heterogeneous benchmark datasets, which demonstrates the superiority of MULAN over other state-of-the-art competitors and also shows that MULAN is efficient.","sentences":["Heterogeneous graph neural networks (HGNNs) have recently shown impressive capability in modeling heterogeneous graphs that are ubiquitous in real-world applications.","Due to the diversity of attributes of nodes in different types, most existing models first align nodes by mapping them into the same low-dimensional space.","However, in this way, they lose the type information of nodes.","In addition, most of them only consider the interactions between nodes while neglecting the high-order information behind the latent interactions among different node features.","To address these problems, in this paper, we propose a novel heterogeneous graph model MULAN, including two major components, i.e., a type-aware encoder and a dimension-aware encoder.","Specifically, the type-aware encoder compensates for the loss of node type information and better leverages graph heterogeneity in learning node representations.","Built upon transformer architecture, the dimension-aware encoder is capable of capturing the latent interactions among the diverse node features.","With these components, the information of graph heterogeneity, node features and graph structure can be comprehensively encoded in node representations.","We conduct extensive experiments on six heterogeneous benchmark datasets, which demonstrates the superiority of MULAN over other state-of-the-art competitors and also shows that MULAN is efficient."],"url":"http://arxiv.org/abs/2311.03275v1"}
{"created":"2023-11-06 16:59:29","title":"Nibbling at Long Cycles: Dynamic (and Static) Edge Coloring in Optimal Time","abstract":"We consider the problem of maintaining a $(1+\\epsilon)\\Delta$-edge coloring in a dynamic graph $G$ with $n$ nodes and maximum degree at most $\\Delta$. The state-of-the-art update time is $O_\\epsilon(\\text{polylog}(n))$, by Duan, He and Zhang [SODA'19] and by Christiansen [STOC'23], and more precisely $O(\\log^7 n/\\epsilon^2)$, where $\\Delta = \\Omega(\\log^2 n / \\epsilon^2)$.   The following natural question arises: What is the best possible update time of an algorithm for this task? More specifically, \\textbf{ can we bring it all the way down to some constant} (for constant $\\epsilon$)? This question coincides with the \\emph{static} time barrier for the problem: Even for $(2\\Delta-1)$-coloring, there is only a naive $O(m \\log \\Delta)$-time algorithm.   We answer this fundamental question in the affirmative, by presenting a dynamic $(1+\\epsilon)\\Delta$-edge coloring algorithm with $O(\\log^4 (1/\\epsilon)/\\epsilon^9)$ update time, provided $\\Delta = \\Omega_\\epsilon(\\text{polylog}(n))$. As a corollary, we also get the first linear time (for constant $\\epsilon$) \\emph{static} algorithm for $(1+\\epsilon)\\Delta$-edge coloring; in particular, we achieve a running time of $O(m \\log (1/\\epsilon)/\\epsilon^2)$.   We obtain our results by carefully combining a variant of the \\textsc{Nibble} algorithm from Bhattacharya, Grandoni and Wajc [SODA'21] with the subsampling technique of Kulkarni, Liu, Sah, Sawhney and Tarnawski [STOC'22].","sentences":["We consider the problem of maintaining a $(1+\\epsilon)\\Delta$-edge coloring in a dynamic graph $G$ with $n$ nodes and maximum degree at most $\\Delta$. The state-of-the-art update time is $O_\\epsilon(\\text{polylog}(n))$, by Duan, He and Zhang","[SODA'19] and by Christiansen","[STOC'23], and more precisely $O(\\log^7 n/\\epsilon^2)$, where $\\Delta = \\Omega(\\log^2 n / \\epsilon^2)$.   The following natural question arises: What is the best possible update time of an algorithm for this task?","More specifically, \\textbf{ can we bring it all the way down to some constant} (for constant $\\epsilon$)?","This question coincides with the \\emph{static} time barrier for the problem: Even for $(2\\Delta-1)$-coloring, there is only a naive $O(m \\log \\Delta)$-time algorithm.   ","We answer this fundamental question in the affirmative, by presenting a dynamic $(1+\\epsilon)\\Delta$-edge coloring algorithm with $O(\\log^4 (1/\\epsilon)/\\epsilon^9)$ update time, provided $\\Delta = \\Omega_\\epsilon(\\text{polylog}(n))$. As a corollary, we also get the first linear time (for constant $\\epsilon$) \\emph{static} algorithm for $(1+\\epsilon)\\Delta$-edge coloring; in particular, we achieve a running time of $O(m \\log (1/\\epsilon)/\\epsilon^2)$.   We obtain our results by carefully combining a variant of the \\textsc{Nibble} algorithm from Bhattacharya, Grandoni and Wajc","[SODA'21] with the subsampling technique of Kulkarni, Liu, Sah, Sawhney and Tarnawski [STOC'22]."],"url":"http://arxiv.org/abs/2311.03267v1"}
{"created":"2023-11-06 16:56:12","title":"PROMPT: A Fast and Extensible Memory Profiling Framework","abstract":"Memory profiling captures programs' dynamic memory behavior, assisting programmers in debugging, tuning, and enabling advanced compiler optimizations like speculation-based automatic parallelization. As each use case demands its unique program trace summary, various memory profiler types have been developed. Yet, designing practical memory profilers often requires extensive compiler expertise, adeptness in program optimization, and significant implementation efforts. This often results in a void where aspirations for fast and robust profilers remain unfulfilled. To bridge this gap, this paper presents PROMPT, a pioneering framework for streamlined development of fast memory profilers. With it, developers only need to specify profiling events and define the core profiling logic, bypassing the complexities of custom instrumentation and intricate memory profiling components and optimizations. Two state-of-the-art memory profilers were ported with PROMPT while all features preserved. By focusing on the core profiling logic, the code was reduced by more than 65% and the profiling speed was improved by 5.3x and 7.1x respectively. To further underscore PROMPT's impact, a tailored memory profiling workflow was constructed for a sophisticated compiler optimization client. In just 570 lines of code, this redesigned workflow satisfies the client's memory profiling needs while achieving more than 90% reduction in profiling time and improved robustness compared to the original profilers.","sentences":["Memory profiling captures programs' dynamic memory behavior, assisting programmers in debugging, tuning, and enabling advanced compiler optimizations like speculation-based automatic parallelization.","As each use case demands its unique program trace summary, various memory profiler types have been developed.","Yet, designing practical memory profilers often requires extensive compiler expertise, adeptness in program optimization, and significant implementation efforts.","This often results in a void where aspirations for fast and robust profilers remain unfulfilled.","To bridge this gap, this paper presents PROMPT, a pioneering framework for streamlined development of fast memory profilers.","With it, developers only need to specify profiling events and define the core profiling logic, bypassing the complexities of custom instrumentation and intricate memory profiling components and optimizations.","Two state-of-the-art memory profilers were ported with PROMPT while all features preserved.","By focusing on the core profiling logic, the code was reduced by more than 65% and the profiling speed was improved by 5.3x and 7.1x respectively.","To further underscore PROMPT's impact, a tailored memory profiling workflow was constructed for a sophisticated compiler optimization client.","In just 570 lines of code, this redesigned workflow satisfies the client's memory profiling needs while achieving more than 90% reduction in profiling time and improved robustness compared to the original profilers."],"url":"http://arxiv.org/abs/2311.03263v1"}
{"created":"2023-11-06 16:48:49","title":"On Finding Optimal (Dynamic) Arborescences","abstract":"Let G = (V, E) be a directed and weighted graph with vertex set V of size n and edge set E of size m, such that each edge (u, v) \\in E has a real-valued weight w(u, c). An arborescence in G is a subgraph T = (V, E') such that for a vertex u \\in V, the root, there is a unique path in T from u to any other vertex v \\in V. The weight of T is the sum of the weights of its edges. In this paper, given G, we are interested in finding an arborescence in G with minimum weight, i.e., an optimal arborescence. Furthermore, when G is subject to changes, namely edge insertions and deletions, we are interested in efficiently maintaining a dynamic arborescence in G. This is a well known problem with applications in several domains such as network design optimization and in phylogenetic inference. In this paper we revisit algorithmic ideas proposed by several authors for this problem, we provide detailed pseudo-code as well as implementation details, and we present experimental results on large scale-free networks and on phylogenetic inference. Our implementation is publicly available at \\url{https://gitlab.com/espadas/optimal-arborescences}.","sentences":["Let G = (V, E) be a directed and weighted graph with vertex set V of size n and edge set E of size m, such that each edge (u, v) \\in E has a real-valued weight w(u, c).","An arborescence in G is a subgraph T = (V, E') such that for a vertex u \\in V, the root, there is a unique path in T from u to any other vertex v \\in V.","The weight of T is the sum of the weights of its edges.","In this paper, given G, we are interested in finding an arborescence in G with minimum weight, i.e., an optimal arborescence.","Furthermore, when G is subject to changes, namely edge insertions and deletions, we are interested in efficiently maintaining a dynamic arborescence in G.","This is a well known problem with applications in several domains such as network design optimization and in phylogenetic inference.","In this paper we revisit algorithmic ideas proposed by several authors for this problem, we provide detailed pseudo-code as well as implementation details, and we present experimental results on large scale-free networks and on phylogenetic inference.","Our implementation is publicly available at \\url{https://gitlab.com/espadas/optimal-arborescences}."],"url":"http://arxiv.org/abs/2311.03262v1"}
{"created":"2023-11-06 16:47:17","title":"From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach","abstract":"We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class of continuous-depth graph neural networks (GNNs) that employs the Kuramoto model to mitigate the over-smoothing phenomenon, in which node features in GNNs become indistinguishable as the number of layers increases. The Kuramoto model captures the synchronization behavior of non-linear coupled oscillators. Under the view of coupled oscillators, we first show the connection between Kuramoto model and basic GNN and then over-smoothing phenomenon in GNNs can be interpreted as phase synchronization in Kuramoto model. The KuramotoGNN replaces this phase synchronization with frequency synchronization to prevent the node features from converging into each other while allowing the system to reach a stable synchronized state. We experimentally verify the advantages of the KuramotoGNN over the baseline GNNs and existing methods in reducing over-smoothing on various graph deep learning benchmark tasks.","sentences":["We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class of continuous-depth graph neural networks (GNNs) that employs the Kuramoto model to mitigate the over-smoothing phenomenon, in which node features in GNNs become indistinguishable as the number of layers increases.","The Kuramoto model captures the synchronization behavior of non-linear coupled oscillators.","Under the view of coupled oscillators, we first show the connection between Kuramoto model and basic GNN and then over-smoothing phenomenon in GNNs can be interpreted as phase synchronization in Kuramoto model.","The KuramotoGNN replaces this phase synchronization with frequency synchronization to prevent the node features from converging into each other while allowing the system to reach a stable synchronized state.","We experimentally verify the advantages of the KuramotoGNN over the baseline GNNs and existing methods in reducing over-smoothing on various graph deep learning benchmark tasks."],"url":"http://arxiv.org/abs/2311.03260v1"}
{"created":"2023-11-06 16:40:13","title":"Coherent Entity Disambiguation via Modeling Topic and Categorical Dependency","abstract":"Previous entity disambiguation (ED) methods adopt a discriminative paradigm, where prediction is made based on matching scores between mention context and candidate entities using length-limited encoders. However, these methods often struggle to capture explicit discourse-level dependencies, resulting in incoherent predictions at the abstract level (e.g. topic or category). We propose CoherentED, an ED system equipped with novel designs aimed at enhancing the coherence of entity predictions. Our method first introduces an unsupervised variational autoencoder (VAE) to extract latent topic vectors of context sentences. This approach not only allows the encoder to handle longer documents more effectively, conserves valuable input space, but also keeps a topic-level coherence. Additionally, we incorporate an external category memory, enabling the system to retrieve relevant categories for undecided mentions. By employing step-by-step entity decisions, this design facilitates the modeling of entity-entity interactions, thereby maintaining maximum coherence at the category level. We achieve new state-of-the-art results on popular ED benchmarks, with an average improvement of 1.3 F1 points. Our model demonstrates particularly outstanding performance on challenging long-text scenarios.","sentences":["Previous entity disambiguation (ED) methods adopt a discriminative paradigm, where prediction is made based on matching scores between mention context and candidate entities using length-limited encoders.","However, these methods often struggle to capture explicit discourse-level dependencies, resulting in incoherent predictions at the abstract level (e.g. topic or category).","We propose CoherentED, an ED system equipped with novel designs aimed at enhancing the coherence of entity predictions.","Our method first introduces an unsupervised variational autoencoder (VAE) to extract latent topic vectors of context sentences.","This approach not only allows the encoder to handle longer documents more effectively, conserves valuable input space, but also keeps a topic-level coherence.","Additionally, we incorporate an external category memory, enabling the system to retrieve relevant categories for undecided mentions.","By employing step-by-step entity decisions, this design facilitates the modeling of entity-entity interactions, thereby maintaining maximum coherence at the category level.","We achieve new state-of-the-art results on popular ED benchmarks, with an average improvement of 1.3 F1 points.","Our model demonstrates particularly outstanding performance on challenging long-text scenarios."],"url":"http://arxiv.org/abs/2311.03253v1"}
{"created":"2023-11-06 16:38:51","title":"Instructed Language Models with Retrievers Are Powerful Entity Linkers","abstract":"Generative approaches powered by large language models (LLMs) have demonstrated emergent abilities in tasks that require complex reasoning abilities. Yet the generative nature still makes the generated content suffer from hallucinations, thus unsuitable for entity-centric tasks like entity linking (EL) requiring precise entity predictions over a large knowledge base. We present Instructed Generative Entity Linker (INSGENEL), the first approach that enables casual language models to perform entity linking over knowledge bases. Several methods to equip language models with EL capability were proposed in this work, including (i) a sequence-to-sequence training EL objective with instruction-tuning, (ii) a novel generative EL framework based on a light-weight potential mention retriever that frees the model from heavy and non-parallelizable decoding, achieving 4$\\times$ speedup without compromise on linking metrics. INSGENEL outperforms previous generative alternatives with +6.8 F1 points gain on average, also with a huge advantage in training data efficiency and training compute consumption. In addition, our skillfully engineered in-context learning (ICL) framework for EL still lags behind INSGENEL significantly, reaffirming that the EL task remains a persistent hurdle for general LLMs.","sentences":["Generative approaches powered by large language models (LLMs) have demonstrated emergent abilities in tasks that require complex reasoning abilities.","Yet the generative nature still makes the generated content suffer from hallucinations, thus unsuitable for entity-centric tasks like entity linking (EL) requiring precise entity predictions over a large knowledge base.","We present Instructed Generative Entity Linker (INSGENEL), the first approach that enables casual language models to perform entity linking over knowledge bases.","Several methods to equip language models with EL capability were proposed in this work, including (i) a sequence-to-sequence training EL objective with instruction-tuning, (ii) a novel generative EL framework based on a light-weight potential mention retriever that frees the model from heavy and non-parallelizable decoding, achieving 4$\\times$ speedup without compromise on linking metrics.","INSGENEL outperforms previous generative alternatives with +6.8 F1 points gain on average, also with a huge advantage in training data efficiency and training compute consumption.","In addition, our skillfully engineered in-context learning (ICL) framework for EL still lags behind INSGENEL significantly, reaffirming that the EL task remains a persistent hurdle for general LLMs."],"url":"http://arxiv.org/abs/2311.03250v1"}
{"created":"2023-11-06 16:34:48","title":"Advancing Post Hoc Case Based Explanation with Feature Highlighting","abstract":"Explainable AI (XAI) has been proposed as a valuable tool to assist in downstream tasks involving human and AI collaboration. Perhaps the most psychologically valid XAI techniques are case based approaches which display 'whole' exemplars to explain the predictions of black box AI systems. However, for such post hoc XAI methods dealing with images, there has been no attempt to improve their scope by using multiple clear feature 'parts' of the images to explain the predictions while linking back to relevant cases in the training data, thus allowing for more comprehensive explanations that are faithful to the underlying model. Here, we address this gap by proposing two general algorithms (latent and super pixel based) which can isolate multiple clear feature parts in a test image, and then connect them to the explanatory cases found in the training data, before testing their effectiveness in a carefully designed user study. Results demonstrate that the proposed approach appropriately calibrates a users feelings of 'correctness' for ambiguous classifications in real world data on the ImageNet dataset, an effect which does not happen when just showing the explanation without feature highlighting.","sentences":["Explainable AI (XAI) has been proposed as a valuable tool to assist in downstream tasks involving human and AI collaboration.","Perhaps the most psychologically valid XAI techniques are case based approaches which display 'whole' exemplars to explain the predictions of black box AI systems.","However, for such post hoc XAI methods dealing with images, there has been no attempt to improve their scope by using multiple clear feature 'parts' of the images to explain the predictions while linking back to relevant cases in the training data, thus allowing for more comprehensive explanations that are faithful to the underlying model.","Here, we address this gap by proposing two general algorithms (latent and super pixel based) which can isolate multiple clear feature parts in a test image, and then connect them to the explanatory cases found in the training data, before testing their effectiveness in a carefully designed user study.","Results demonstrate that the proposed approach appropriately calibrates a users feelings of 'correctness' for ambiguous classifications in real world data on the ImageNet dataset, an effect which does not happen when just showing the explanation without feature highlighting."],"url":"http://arxiv.org/abs/2311.03246v1"}
{"created":"2023-11-06 16:31:48","title":"Safurai-Csharp: Harnessing Synthetic Data to improve language-specific Code LLM","abstract":"This paper introduces Safurai-Csharp, an open-source model designed to specialize in the generation, completion, and debugging of C# code. Safurai-Csharp is built upon the novel CodeLlama 34B model and leverages the EvolInstruct technique, creating a refined and expanded dataset for its fine-tuning process. The results of its performance, a notable score of 56.33% on the Manual MultiPL-E benchmark (Zero-Shot, Pass@1), signal its high capacity to streamline developers' workflows and aid code learning. It shows promise in setting new stakes in the landscape of open-source C# LLMs and hopes to inspire more inclusive and wide-ranging development in the field of language-specific LLMs.","sentences":["This paper introduces Safurai-Csharp, an open-source model designed to specialize in the generation, completion, and debugging of C# code.","Safurai-Csharp is built upon the novel CodeLlama 34B model and leverages the EvolInstruct technique, creating a refined and expanded dataset for its fine-tuning process.","The results of its performance, a notable score of 56.33% on the Manual MultiPL-E benchmark (Zero-Shot, Pass@1), signal its high capacity to streamline developers' workflows and aid code learning.","It shows promise in setting new stakes in the landscape of open-source C# LLMs and hopes to inspire more inclusive and wide-ranging development in the field of language-specific LLMs."],"url":"http://arxiv.org/abs/2311.03243v1"}
{"created":"2023-11-06 16:31:09","title":"Approximating Langevin Monte Carlo with ResNet-like Neural Network architectures","abstract":"We sample from a given target distribution by constructing a neural network which maps samples from a simple reference, e.g. the standard normal distribution, to samples from the target. To that end, we propose using a neural network architecture inspired by the Langevin Monte Carlo (LMC) algorithm. Based on LMC perturbation results, we show approximation rates of the proposed architecture for smooth, log-concave target distributions measured in the Wasserstein-$2$ distance. The analysis heavily relies on the notion of sub-Gaussianity of the intermediate measures of the perturbed LMC process. In particular, we derive bounds on the growth of the intermediate variance proxies under different assumptions on the perturbations. Moreover, we propose an architecture similar to deep residual neural networks and derive expressivity results for approximating the sample to target distribution map.","sentences":["We sample from a given target distribution by constructing a neural network which maps samples from a simple reference, e.g. the standard normal distribution, to samples from the target.","To that end, we propose using a neural network architecture inspired by the Langevin Monte Carlo (LMC) algorithm.","Based on LMC perturbation results, we show approximation rates of the proposed architecture for smooth, log-concave target distributions measured in the Wasserstein-$2$ distance.","The analysis heavily relies on the notion of sub-Gaussianity of the intermediate measures of the perturbed LMC process.","In particular, we derive bounds on the growth of the intermediate variance proxies under different assumptions on the perturbations.","Moreover, we propose an architecture similar to deep residual neural networks and derive expressivity results for approximating the sample to target distribution map."],"url":"http://arxiv.org/abs/2311.03242v1"}
{"created":"2023-11-06 16:30:40","title":"Machine Learning-Based Tea Leaf Disease Detection: A Comprehensive Review","abstract":"Tea leaf diseases are a major challenge to agricultural productivity, with far-reaching implications for yield and quality in the tea industry. The rise of machine learning has enabled the development of innovative approaches to combat these diseases. Early detection and diagnosis are crucial for effective crop management. For predicting tea leaf disease, several automated systems have already been developed using different image processing techniques. This paper delivers a systematic review of the literature on machine learning methodologies applied to diagnose tea leaf disease via image classification. It thoroughly evaluates the strengths and constraints of various Vision Transformer models, including Inception Convolutional Vision Transformer (ICVT), GreenViT, PlantXViT, PlantViT, MSCVT, Transfer Learning Model & Vision Transformer (TLMViT), IterationViT, IEM-ViT. Moreover, this paper also reviews models like Dense Convolutional Network (DenseNet), Residual Neural Network (ResNet)-50V2, YOLOv5, YOLOv7, Convolutional Neural Network (CNN), Deep CNN, Non-dominated Sorting Genetic Algorithm (NSGA-II), MobileNetv2, and Lesion-Aware Visual Transformer. These machine-learning models have been tested on various datasets, demonstrating their real-world applicability. This review study not only highlights current progress in the field but also provides valuable insights for future research directions in the machine learning-based detection and classification of tea leaf diseases.","sentences":["Tea leaf diseases are a major challenge to agricultural productivity, with far-reaching implications for yield and quality in the tea industry.","The rise of machine learning has enabled the development of innovative approaches to combat these diseases.","Early detection and diagnosis are crucial for effective crop management.","For predicting tea leaf disease, several automated systems have already been developed using different image processing techniques.","This paper delivers a systematic review of the literature on machine learning methodologies applied to diagnose tea leaf disease via image classification.","It thoroughly evaluates the strengths and constraints of various Vision Transformer models, including Inception Convolutional Vision Transformer (ICVT), GreenViT, PlantXViT, PlantViT, MSCVT, Transfer Learning Model & Vision Transformer (TLMViT), IterationViT, IEM-ViT.","Moreover, this paper also reviews models like Dense Convolutional Network (DenseNet), Residual Neural Network (ResNet)-50V2, YOLOv5, YOLOv7, Convolutional Neural Network (CNN), Deep CNN, Non-dominated Sorting Genetic Algorithm (NSGA-II), MobileNetv2, and Lesion-Aware Visual Transformer.","These machine-learning models have been tested on various datasets, demonstrating their real-world applicability.","This review study not only highlights current progress in the field but also provides valuable insights for future research directions in the machine learning-based detection and classification of tea leaf diseases."],"url":"http://arxiv.org/abs/2311.03240v1"}
{"created":"2023-11-06 16:26:52","title":"Out-of-distribution Detection Learning with Unreliable Out-of-distribution Sources","abstract":"Out-of-distribution (OOD) detection discerns OOD data where the predictor cannot make valid predictions as in-distribution (ID) data, thereby increasing the reliability of open-world classification. However, it is typically hard to collect real out-of-distribution (OOD) data for training a predictor capable of discerning ID and OOD patterns. This obstacle gives rise to data generation-based learning methods, synthesizing OOD data via data generators for predictor training without requiring any real OOD data. Related methods typically pre-train a generator on ID data and adopt various selection procedures to find those data likely to be the OOD cases. However, generated data may still coincide with ID semantics, i.e., mistaken OOD generation remains, confusing the predictor between ID and OOD data. To this end, we suggest that generated data (with mistaken OOD generation) can be used to devise an auxiliary OOD detection task to facilitate real OOD detection. Specifically, we can ensure that learning from such an auxiliary task is beneficial if the ID and the OOD parts have disjoint supports, with the help of a well-designed training procedure for the predictor. Accordingly, we propose a powerful data generation-based learning method named Auxiliary Task-based OOD Learning (ATOL) that can relieve the mistaken OOD generation. We conduct extensive experiments under various OOD detection setups, demonstrating the effectiveness of our method against its advanced counterparts.","sentences":["Out-of-distribution (OOD) detection discerns OOD data where the predictor cannot make valid predictions as in-distribution (ID) data, thereby increasing the reliability of open-world classification.","However, it is typically hard to collect real out-of-distribution (OOD) data for training a predictor capable of discerning ID and OOD patterns.","This obstacle gives rise to data generation-based learning methods, synthesizing OOD data via data generators for predictor training without requiring any real OOD data.","Related methods typically pre-train a generator on ID data and adopt various selection procedures to find those data likely to be the OOD cases.","However, generated data may still coincide with ID semantics, i.e., mistaken OOD generation remains, confusing the predictor between ID and OOD data.","To this end, we suggest that generated data (with mistaken OOD generation) can be used to devise an auxiliary OOD detection task to facilitate real OOD detection.","Specifically, we can ensure that learning from such an auxiliary task is beneficial if the ID and the OOD parts have disjoint supports, with the help of a well-designed training procedure for the predictor.","Accordingly, we propose a powerful data generation-based learning method named Auxiliary Task-based OOD Learning (ATOL) that can relieve the mistaken OOD generation.","We conduct extensive experiments under various OOD detection setups, demonstrating the effectiveness of our method against its advanced counterparts."],"url":"http://arxiv.org/abs/2311.03236v1"}
{"created":"2023-11-06 16:25:56","title":"p-Laplacian Transformer","abstract":"$p$-Laplacian regularization, rooted in graph and image signal processing, introduces a parameter $p$ to control the regularization effect on these data. Smaller values of $p$ promote sparsity and interpretability, while larger values encourage smoother solutions. In this paper, we first show that the self-attention mechanism obtains the minimal Laplacian regularization ($p=2$) and encourages the smoothness in the architecture. However, the smoothness is not suitable for the heterophilic structure of self-attention in transformers where attention weights between tokens that are in close proximity and non-close ones are assigned indistinguishably. From that insight, we then propose a novel class of transformers, namely the $p$-Laplacian Transformer (p-LaT), which leverages $p$-Laplacian regularization framework to harness the heterophilic features within self-attention layers. In particular, low $p$ values will effectively assign higher attention weights to tokens that are in close proximity to the current token being processed. We empirically demonstrate the advantages of p-LaT over the baseline transformers on a wide range of benchmark datasets.","sentences":["$p$-Laplacian regularization, rooted in graph and image signal processing, introduces a parameter $p$ to control the regularization effect on these data.","Smaller values of $p$ promote sparsity and interpretability, while larger values encourage smoother solutions.","In this paper, we first show that the self-attention mechanism obtains the minimal Laplacian regularization ($p=2$) and encourages the smoothness in the architecture.","However, the smoothness is not suitable for the heterophilic structure of self-attention in transformers where attention weights between tokens that are in close proximity and non-close ones are assigned indistinguishably.","From that insight, we then propose a novel class of transformers, namely the $p$-Laplacian Transformer (p-LaT), which leverages $p$-Laplacian regularization framework to harness the heterophilic features within self-attention layers.","In particular, low $p$ values will effectively assign higher attention weights to tokens that are in close proximity to the current token being processed.","We empirically demonstrate the advantages of p-LaT over the baseline transformers on a wide range of benchmark datasets."],"url":"http://arxiv.org/abs/2311.03235v1"}
{"created":"2023-11-06 16:20:28","title":"Navigating Scaling Laws: Accelerating Vision Transformer's Training via Adaptive Strategies","abstract":"In recent years, the state-of-the-art in deep learning has been dominated by very large models that have been pre-trained on vast amounts of data. The paradigm is very simple: Investing more computational resources (optimally) leads to better performance, and even predictably so; neural scaling laws have been derived that accurately forecast the performance of a network for a desired level of compute. This leads to the notion of a \"compute-optimal\" model, i.e. a model that allocates a given level of compute during training optimally to maximise performance. In this work, we extend the concept of optimality by allowing for an \"adaptive\" model, i.e. a model that can change its shape during the course of training. By allowing the shape to adapt, we can optimally traverse between the underlying scaling laws, leading to a significant reduction in the required compute to reach a given target performance. We focus on vision tasks and the family of Vision Transformers, where the patch size as well as the width naturally serve as adaptive shape parameters. We demonstrate that, guided by scaling laws, we can design compute-optimal adaptive models that beat their \"static\" counterparts.","sentences":["In recent years, the state-of-the-art in deep learning has been dominated by very large models that have been pre-trained on vast amounts of data.","The paradigm is very simple: Investing more computational resources (optimally) leads to better performance, and even predictably so; neural scaling laws have been derived that accurately forecast the performance of a network for a desired level of compute.","This leads to the notion of a \"compute-optimal\" model, i.e. a model that allocates a given level of compute during training optimally to maximise performance.","In this work, we extend the concept of optimality by allowing for an \"adaptive\" model, i.e. a model that can change its shape during the course of training.","By allowing the shape to adapt, we can optimally traverse between the underlying scaling laws, leading to a significant reduction in the required compute to reach a given target performance.","We focus on vision tasks and the family of Vision Transformers, where the patch size as well as the width naturally serve as adaptive shape parameters.","We demonstrate that, guided by scaling laws, we can design compute-optimal adaptive models that beat their \"static\" counterparts."],"url":"http://arxiv.org/abs/2311.03233v1"}
{"created":"2023-11-06 16:20:16","title":"A Reactive performance-based Shared Control Framework for Assistive Robotic Manipulators","abstract":"In Physical Human--Robot Interaction (pHRI) grippers, humans and robots may contribute simultaneously to actions, so it is necessary to determine how to combine their commands. Control may be swapped from one to the other within certain limits, or input commands may be combined according to some criteria. The Assist-As-Needed (AAN) paradigm focuses on this second approach, as the controller is expected to provide the minimum required assistance to users. Some AAN systems rely on predicting human intention to adjust actions. However, if prediction is too hard, reactive AAN systems may weigh input commands into an emergent one. This paper proposes a novel AAN reactive control system for a robot gripper where input commands are weighted by their respective local performances. Thus, rather than minimizing tracking errors or differences to expected velocities, humans receive more help depending on their needs. The system has been tested using a gripper attached to a sensitive robot arm, which provides evaluation parameters. Tests consisted of completing an on-air planar path with both arms. After the robot gripped a person's forearm, the path and current position of the robot were displayed on a screen to provide feedback to the human. The proposed control has been compared to results without assistance and to impedance control for benchmarking. A statistical analysis of the results proves that global performance improved and tracking errors decreased for ten volunteers with the proposed controller. Besides, unlike impedance control, the proposed one does not significantly affect exerted forces, command variation, or disagreement, measured as the angular difference between human and output command. Results support that the proposed control scheme fits the AAN paradigm, although future work will require further tests for more complex environments and tasks.","sentences":["In Physical Human--Robot Interaction (pHRI) grippers, humans and robots may contribute simultaneously to actions, so it is necessary to determine how to combine their commands.","Control may be swapped from one to the other within certain limits, or input commands may be combined according to some criteria.","The Assist-As-Needed (AAN) paradigm focuses on this second approach, as the controller is expected to provide the minimum required assistance to users.","Some AAN systems rely on predicting human intention to adjust actions.","However, if prediction is too hard, reactive AAN systems may weigh input commands into an emergent one.","This paper proposes a novel AAN reactive control system for a robot gripper where input commands are weighted by their respective local performances.","Thus, rather than minimizing tracking errors or differences to expected velocities, humans receive more help depending on their needs.","The system has been tested using a gripper attached to a sensitive robot arm, which provides evaluation parameters.","Tests consisted of completing an on-air planar path with both arms.","After the robot gripped a person's forearm, the path and current position of the robot were displayed on a screen to provide feedback to the human.","The proposed control has been compared to results without assistance and to impedance control for benchmarking.","A statistical analysis of the results proves that global performance improved and tracking errors decreased for ten volunteers with the proposed controller.","Besides, unlike impedance control, the proposed one does not significantly affect exerted forces, command variation, or disagreement, measured as the angular difference between human and output command.","Results support that the proposed control scheme fits the AAN paradigm, although future work will require further tests for more complex environments and tasks."],"url":"http://arxiv.org/abs/2311.03232v1"}
{"created":"2023-11-06 16:15:38","title":"Balancing Notions of Equity: Approximation Algorithms for Fair Portfolio of Solutions in Combinatorial Optimization","abstract":"Inspired by equity considerations, we consider top-$k$ norm, ordered norm, and symmetric monotonic norm objectives for various combinatorial optimization problems. Top-$k$ norms and ordered norms have natural interpretations in terms of minimizing the impact on individuals bearing largest costs. To model decision-making with multiple equity criteria, we study the notion of portfolios of solutions with the property that each norm or equity criteria has an approximately optimal solution in this portfolio. We attempt to characterize portfolios by their sizes and approximation factor guarantees for various combinatorial problems. For a given problem, we investigate whether (1) there exists a single solution that is approximately optimal for all norms, (2) there exists a small approximately optimal portfolio of size larger than 1, (3) there exist polynomial time algorithms to find these small portfolios. We study an algorithmic framework to obtain single solutions that are approximately optimal for all norms. We show the existence of such a solution for problems such as $k$-clustering, ordered set cover, scheduling for job completion time minimization, and scheduling for machine load minimization on identical machines. We also give efficient algorithms to find these solutions in most cases, except set cover where we show there is a gap in terms of computational complexity. Our work improves upon the best-known approximation factor across all norms for a single solution in $k$-clustering. For uncapacitated facility location and scheduling for machine load minimization with identical jobs, we obtain logarithmic sized portfolios, also providing a matching lower bound in the latter case. Our work results in new open combinatorial questions, which might be of independent interest.","sentences":["Inspired by equity considerations, we consider top-$k$ norm, ordered norm, and symmetric monotonic norm objectives for various combinatorial optimization problems.","Top-$k$ norms and ordered norms have natural interpretations in terms of minimizing the impact on individuals bearing largest costs.","To model decision-making with multiple equity criteria, we study the notion of portfolios of solutions with the property that each norm or equity criteria has an approximately optimal solution in this portfolio.","We attempt to characterize portfolios by their sizes and approximation factor guarantees for various combinatorial problems.","For a given problem, we investigate whether (1) there exists a single solution that is approximately optimal for all norms, (2) there exists a small approximately optimal portfolio of size larger than 1, (3) there exist polynomial time algorithms to find these small portfolios.","We study an algorithmic framework to obtain single solutions that are approximately optimal for all norms.","We show the existence of such a solution for problems such as $k$-clustering, ordered set cover, scheduling for job completion time minimization, and scheduling for machine load minimization on identical machines.","We also give efficient algorithms to find these solutions in most cases, except set cover where we show there is a gap in terms of computational complexity.","Our work improves upon the best-known approximation factor across all norms for a single solution in $k$-clustering.","For uncapacitated facility location and scheduling for machine load minimization with identical jobs, we obtain logarithmic sized portfolios, also providing a matching lower bound in the latter case.","Our work results in new open combinatorial questions, which might be of independent interest."],"url":"http://arxiv.org/abs/2311.03230v1"}
{"created":"2023-11-06 16:12:25","title":"An Efficient Self-Supervised Cross-View Training For Sentence Embedding","abstract":"Self-supervised sentence representation learning is the task of constructing an embedding space for sentences without relying on human annotation efforts. One straightforward approach is to finetune a pretrained language model (PLM) with a representation learning method such as contrastive learning. While this approach achieves impressive performance on larger PLMs, the performance rapidly degrades as the number of parameters decreases. In this paper, we propose a framework called Self-supervised Cross-View Training (SCT) to narrow the performance gap between large and small PLMs. To evaluate the effectiveness of SCT, we compare it to 5 baseline and state-of-the-art competitors on seven Semantic Textual Similarity (STS) benchmarks using 5 PLMs with the number of parameters ranging from 4M to 340M. The experimental results show that STC outperforms the competitors for PLMs with less than 100M parameters in 18 of 21 cases.","sentences":["Self-supervised sentence representation learning is the task of constructing an embedding space for sentences without relying on human annotation efforts.","One straightforward approach is to finetune a pretrained language model (PLM) with a representation learning method such as contrastive learning.","While this approach achieves impressive performance on larger PLMs, the performance rapidly degrades as the number of parameters decreases.","In this paper, we propose a framework called Self-supervised Cross-View Training (SCT) to narrow the performance gap between large and small PLMs.","To evaluate the effectiveness of SCT, we compare it to 5 baseline and state-of-the-art competitors on seven Semantic Textual Similarity (STS) benchmarks using 5 PLMs with the number of parameters ranging from 4M to 340M.","The experimental results show that STC outperforms the competitors for PLMs with less than 100M parameters in 18 of 21 cases."],"url":"http://arxiv.org/abs/2311.03228v1"}
{"created":"2023-11-06 16:12:10","title":"LDM3D-VR: Latent Diffusion Model for 3D VR","abstract":"Latent diffusion models have proven to be state-of-the-art in the creation and manipulation of visual outputs. However, as far as we know, the generation of depth maps jointly with RGB is still limited. We introduce LDM3D-VR, a suite of diffusion models targeting virtual reality development that includes LDM3D-pano and LDM3D-SR. These models enable the generation of panoramic RGBD based on textual prompts and the upscaling of low-resolution inputs to high-resolution RGBD, respectively. Our models are fine-tuned from existing pretrained models on datasets containing panoramic/high-resolution RGB images, depth maps and captions. Both models are evaluated in comparison to existing related methods.","sentences":["Latent diffusion models have proven to be state-of-the-art in the creation and manipulation of visual outputs.","However, as far as we know, the generation of depth maps jointly with RGB is still limited.","We introduce LDM3D-VR, a suite of diffusion models targeting virtual reality development that includes LDM3D-pano and LDM3D-SR.","These models enable the generation of panoramic RGBD based on textual prompts and the upscaling of low-resolution inputs to high-resolution RGBD, respectively.","Our models are fine-tuned from existing pretrained models on datasets containing panoramic/high-resolution RGB images, depth maps and captions.","Both models are evaluated in comparison to existing related methods."],"url":"http://arxiv.org/abs/2311.03226v1"}
{"created":"2023-11-06 16:11:37","title":"Dichotomies for Tree Minor Containment with Structural Parameters","abstract":"The problem of determining whether a graph $G$ contains another graph $H$ as a minor, referred to as the minor containment problem, is a fundamental problem in the field of graph algorithms. While it is NP-complete when $G$ and $H$ are general graphs, it is sometimes tractable on more restricted graph classes. This study focuses on the case where both $G$ and $H$ are trees, known as the tree minor containment problem. Even in this case, the problem is known to be NP-complete. In contrast, polynomial-time algorithms are known for the case when both trees are caterpillars or when the maximum degree of $H$ is a constant. Our research aims to clarify the boundary of tractability and intractability for the tree minor containment problem. Specifically, we provide dichotomies for the computational complexities of the problem based on three structural parameters: the diameter, pathwidth, and path eccentricity.","sentences":["The problem of determining whether a graph $G$ contains another graph $H$ as a minor, referred to as the minor containment problem, is a fundamental problem in the field of graph algorithms.","While it is NP-complete when $G$ and $H$ are general graphs, it is sometimes tractable on more restricted graph classes.","This study focuses on the case where both $G$ and $H$ are trees, known as the tree minor containment problem.","Even in this case, the problem is known to be NP-complete.","In contrast, polynomial-time algorithms are known for the case when both trees are caterpillars or when the maximum degree of $H$ is a constant.","Our research aims to clarify the boundary of tractability and intractability for the tree minor containment problem.","Specifically, we provide dichotomies for the computational complexities of the problem based on three structural parameters: the diameter, pathwidth, and path eccentricity."],"url":"http://arxiv.org/abs/2311.03225v1"}
{"created":"2023-11-06 16:08:10","title":"Risk Analysis in the Selection of Project Managers Based on ANP and FMEA","abstract":"Project managers play a crucial role in the success of projects. The selection of an appropriate project manager is a primary concern for senior managers in firms. Typically, this process involves candidate interviews and assessments of their abilities. There are various criteria for selecting a project manager, and the importance of each criterion depends on the project type, its conditions, and the risks associated with their absence in the chosen candidate. Often, senior managers in engineering companies lack awareness of the significance of these criteria and the potential risks linked to their absence. This research aims to identify these risks in selecting project managers for civil engineering projects, utilizing a combined ANP-FMEA approach. Through a comprehensive literature review, five risk categories have been identified: individual skills, power-related issues, knowledge and expertise, experience, and personality traits. Subsequently, these risks, along with their respective sub-criteria and internal relationships, were analysed using the combined ANP-FMEA technique. The results highlighted that the lack of political influence, absence of construction experience, and deficiency in project management expertise represent the most substantial risks in selecting a project manager. Moreover, upon comparison with the traditional FMEA approach, this study demonstrates the superior ability of the ANP-FMEA model in differentiating risks and pinpointing factors with elevated risk levels.","sentences":["Project managers play a crucial role in the success of projects.","The selection of an appropriate project manager is a primary concern for senior managers in firms.","Typically, this process involves candidate interviews and assessments of their abilities.","There are various criteria for selecting a project manager, and the importance of each criterion depends on the project type, its conditions, and the risks associated with their absence in the chosen candidate.","Often, senior managers in engineering companies lack awareness of the significance of these criteria and the potential risks linked to their absence.","This research aims to identify these risks in selecting project managers for civil engineering projects, utilizing a combined ANP-FMEA approach.","Through a comprehensive literature review, five risk categories have been identified: individual skills, power-related issues, knowledge and expertise, experience, and personality traits.","Subsequently, these risks, along with their respective sub-criteria and internal relationships, were analysed using the combined ANP-FMEA technique.","The results highlighted that the lack of political influence, absence of construction experience, and deficiency in project management expertise represent the most substantial risks in selecting a project manager.","Moreover, upon comparison with the traditional FMEA approach, this study demonstrates the superior ability of the ANP-FMEA model in differentiating risks and pinpointing factors with elevated risk levels."],"url":"http://arxiv.org/abs/2311.03224v1"}
{"created":"2023-11-06 16:06:49","title":"CarbonFish -- A Bistable Underactuated Compliant Fish Robot capable of High Frequency Undulation","abstract":"The Hair Clip Mechanism HCM represents an innovative in plane prestressed bistable mechanism, as delineated in our preceding studies, devised to augment the functional prowess of soft robotics. When juxtaposed with conventional soft and compliant robotic systems, HCMs exhibit pronounced rigidity, augmented mobility, reproducible repeatability, and an effective design and fabrication paradigm. In this research, we investigate the feasibility of utilizing carbon fiber reinforced plastic CFRP as the foundational material for an HCM based fish robot, herein referred to as CarbonFish. Our objective centers on realizing high frequency undulatory motion, thereby laying the groundwork for accelerated aquatic locomotion in subsequent models. We proffer an exhaustive design and fabrication schema underpinned by mathematical principles. Preliminary evaluations of our single actuated CarbonFish have evidenced an undulation frequency approaching 10 Hz, suggesting its potential to outperform other biologically inspired aquatic entities as well as real fish.","sentences":["The Hair Clip Mechanism HCM represents an innovative in plane prestressed bistable mechanism, as delineated in our preceding studies, devised to augment the functional prowess of soft robotics.","When juxtaposed with conventional soft and compliant robotic systems, HCMs exhibit pronounced rigidity, augmented mobility, reproducible repeatability, and an effective design and fabrication paradigm.","In this research, we investigate the feasibility of utilizing carbon fiber reinforced plastic CFRP as the foundational material for an HCM based fish robot, herein referred to as CarbonFish.","Our objective centers on realizing high frequency undulatory motion, thereby laying the groundwork for accelerated aquatic locomotion in subsequent models.","We proffer an exhaustive design and fabrication schema underpinned by mathematical principles.","Preliminary evaluations of our single actuated CarbonFish have evidenced an undulation frequency approaching 10 Hz, suggesting its potential to outperform other biologically inspired aquatic entities as well as real fish."],"url":"http://arxiv.org/abs/2311.03223v1"}
{"created":"2023-11-06 16:04:58","title":"Segmentation of Drone Collision Hazards in Airborne RADAR Point Clouds Using PointNet","abstract":"The integration of unmanned aerial vehicles (UAVs) into shared airspace for beyond visual line of sight (BVLOS) operations presents significant challenges but holds transformative potential for sectors like transportation, construction, energy and defense. A critical prerequisite for this integration is equipping UAVs with enhanced situational awareness to ensure safe operations. Current approaches mainly target single object detection or classification, or simpler sensing outputs that offer limited perceptual understanding and lack the rapid end-to-end processing needed to convert sensor data into safety-critical insights. In contrast, our study leverages radar technology for novel end-to-end semantic segmentation of aerial point clouds to simultaneously identify multiple collision hazards. By adapting and optimizing the PointNet architecture and integrating aerial domain insights, our framework distinguishes five distinct classes: mobile drones (DJI M300 and DJI Mini) and airplanes (Ikarus C42), and static returns (ground and infrastructure) which results in enhanced situational awareness for UAVs. To our knowledge, this is the first approach addressing simultaneous identification of multiple collision threats in an aerial setting, achieving a robust 94% accuracy. This work highlights the potential of radar technology to advance situational awareness in UAVs, facilitating safe and efficient BVLOS operations.","sentences":["The integration of unmanned aerial vehicles (UAVs) into shared airspace for beyond visual line of sight (BVLOS) operations presents significant challenges but holds transformative potential for sectors like transportation, construction, energy and defense.","A critical prerequisite for this integration is equipping UAVs with enhanced situational awareness to ensure safe operations.","Current approaches mainly target single object detection or classification, or simpler sensing outputs that offer limited perceptual understanding and lack the rapid end-to-end processing needed to convert sensor data into safety-critical insights.","In contrast, our study leverages radar technology for novel end-to-end semantic segmentation of aerial point clouds to simultaneously identify multiple collision hazards.","By adapting and optimizing the PointNet architecture and integrating aerial domain insights, our framework distinguishes five distinct classes: mobile drones (DJI M300 and DJI Mini) and airplanes (Ikarus C42), and static returns (ground and infrastructure) which results in enhanced situational awareness for UAVs.","To our knowledge, this is the first approach addressing simultaneous identification of multiple collision threats in an aerial setting, achieving a robust 94% accuracy.","This work highlights the potential of radar technology to advance situational awareness in UAVs, facilitating safe and efficient BVLOS operations."],"url":"http://arxiv.org/abs/2311.03221v1"}
{"created":"2023-11-06 16:03:46","title":"ALYMPICS: Language Agents Meet Game Theory","abstract":"This paper introduces Alympics, a platform that leverages Large Language Model (LLM) agents to facilitate investigations in game theory. By employing LLMs and autonomous agents to simulate human behavior and enable multi-agent collaborations, we can construct realistic and dynamic models of human interactions for game theory hypothesis formulating and testing. To demonstrate this, we present and implement a survival game involving unequal competition for limited resources. Through manipulation of resource availability and agent personalities, we observe how different agents engage in the competition and adapt their strategies. The use of LLM agents in game theory research offers significant advantages, including simulating realistic behavior, providing a controlled, scalable, and reproducible environment. Our work highlights the potential of LLM agents in enhancing the understanding of strategic decision-making within complex socioeconomic contexts. All codes will be made public soon.","sentences":["This paper introduces Alympics, a platform that leverages Large Language Model (LLM) agents to facilitate investigations in game theory.","By employing LLMs and autonomous agents to simulate human behavior and enable multi-agent collaborations, we can construct realistic and dynamic models of human interactions for game theory hypothesis formulating and testing.","To demonstrate this, we present and implement a survival game involving unequal competition for limited resources.","Through manipulation of resource availability and agent personalities, we observe how different agents engage in the competition and adapt their strategies.","The use of LLM agents in game theory research offers significant advantages, including simulating realistic behavior, providing a controlled, scalable, and reproducible environment.","Our work highlights the potential of LLM agents in enhancing the understanding of strategic decision-making within complex socioeconomic contexts.","All codes will be made public soon."],"url":"http://arxiv.org/abs/2311.03220v1"}
{"created":"2023-11-06 16:01:10","title":"Mini Minds: Exploring Bebeshka and Zlata Baby Models","abstract":"In this paper, we describe the University of Lyon 2 submission to the Strict-Small track of the BabyLM competition. The shared task is created with an emphasis on small-scale language modelling from scratch on limited-size data and human language acquisition. Dataset released for the Strict-Small track has 10M words, which is comparable to children's vocabulary size. We approach the task with an architecture search, minimizing masked language modelling loss on the data of the shared task. Having found an optimal configuration, we introduce two small-size language models (LMs) that were submitted for evaluation, a 4-layer encoder with 8 attention heads and a 6-layer decoder model with 12 heads which we term Bebeshka and Zlata, respectively. Despite being half the scale of the baseline LMs, our proposed models achieve comparable performance. We further explore the applicability of small-scale language models in tasks involving moral judgment, aligning their predictions with human values. These findings highlight the potential of compact LMs in addressing practical language understanding tasks.","sentences":["In this paper, we describe the University of Lyon 2 submission to the Strict-Small track of the BabyLM competition.","The shared task is created with an emphasis on small-scale language modelling from scratch on limited-size data and human language acquisition.","Dataset released for the Strict-Small track has 10M words, which is comparable to children's vocabulary size.","We approach the task with an architecture search, minimizing masked language modelling loss on the data of the shared task.","Having found an optimal configuration, we introduce two small-size language models (LMs) that were submitted for evaluation, a 4-layer encoder with 8 attention heads and a 6-layer decoder model with 12 heads which we term Bebeshka and Zlata, respectively.","Despite being half the scale of the baseline LMs, our proposed models achieve comparable performance.","We further explore the applicability of small-scale language models in tasks involving moral judgment, aligning their predictions with human values.","These findings highlight the potential of compact LMs in addressing practical language understanding tasks."],"url":"http://arxiv.org/abs/2311.03216v1"}
{"created":"2023-11-06 15:57:04","title":"Assessing the Maturity of Model Maintenance Techniques for AIOps Solutions","abstract":"AIOps (Artificial Intelligence for IT Operations) solutions leverage the massive data produced during the operations of large-scale systems and machine learning models to assist software engineers in their system operations. As operation data produced in the field are subject to constant evolution from factors like the changing operational environment and user base, the models in AIOps solutions need to be constantly maintained after deployment. While prior works focus on innovative modeling techniques to improve the performance of AIOps models before releasing them into the field, when and how to maintain AIOps models remain an under-investigated topic. In this work, we performed a case study on three large-scale public operation data to assess different model maintenance approaches regarding their performance, maintenance cost, and stability. We observed that active model maintenance approaches achieve better and more stable performance than a stationary approach. Particularly, applying sophisticated model maintenance approaches (e.g., concept drift detection, time-based ensembles, or online learning approaches) could provide better performance, efficiency, and stability than simply retraining AIOps models periodically. In addition, we observed that, although some maintenance approaches (e.g., time-based ensemble and online learning) can save model training time, they significantly sacrifice model testing time, which could hinder their applications in AIOps solutions where the operation data arrive at high speed and volume and where instant predictions are required. Our findings highlight that practitioners should consider the evolution of operation data and actively maintain AIOps models over time. Our observations can also guide researchers and practitioners to investigate more efficient and effective model maintenance techniques that fit in the context of AIOps.","sentences":["AIOps (Artificial Intelligence for IT Operations) solutions leverage the massive data produced during the operations of large-scale systems and machine learning models to assist software engineers in their system operations.","As operation data produced in the field are subject to constant evolution from factors like the changing operational environment and user base, the models in AIOps solutions need to be constantly maintained after deployment.","While prior works focus on innovative modeling techniques to improve the performance of AIOps models before releasing them into the field, when and how to maintain AIOps models remain an under-investigated topic.","In this work, we performed a case study on three large-scale public operation data to assess different model maintenance approaches regarding their performance, maintenance cost, and stability.","We observed that active model maintenance approaches achieve better and more stable performance than a stationary approach.","Particularly, applying sophisticated model maintenance approaches (e.g., concept drift detection, time-based ensembles, or online learning approaches) could provide better performance, efficiency, and stability than simply retraining AIOps models periodically.","In addition, we observed that, although some maintenance approaches (e.g., time-based ensemble and online learning) can save model training time, they significantly sacrifice model testing time, which could hinder their applications in AIOps solutions where the operation data arrive at high speed and volume and where instant predictions are required.","Our findings highlight that practitioners should consider the evolution of operation data and actively maintain AIOps models over time.","Our observations can also guide researchers and practitioners to investigate more efficient and effective model maintenance techniques that fit in the context of AIOps."],"url":"http://arxiv.org/abs/2311.03213v1"}
{"created":"2023-11-06 15:56:27","title":"Designing a Hair-Clip Inspired Bistable Mechanism for Soft Fish Robots","abstract":"The Hair clip mechanism (HCM) is an in-plane prestressed bistable mechanism proposed in our previous research [1]~[5] to enhance the functionality of soft robotics. HCMs have several advantages, such as high rigidity, high mobility, good repeatability, and design and fabrication simplicity, compared to existing soft and compliant robotics. Using our experience with fish robots, this work delves into designing a novel HCM robotic propulsion system made from PETG plastic, carbon fiber-reinforced plastic (CFRP), and steel. Detailed derivation and verification of the HCM theory are given, and the influence of key parameters like dimensions, material types, and servo motor specifications are summarized. The designing algorithm offers insight into HCM robotics. It enables us to search for suitable components, operate robots at a desired frequency, and achieve high-frequency and high-speed undulatory swimming for fish robots.","sentences":["The Hair clip mechanism (HCM) is an in-plane prestressed bistable mechanism proposed in our previous research [1]~[5] to enhance the functionality of soft robotics.","HCMs have several advantages, such as high rigidity, high mobility, good repeatability, and design and fabrication simplicity, compared to existing soft and compliant robotics.","Using our experience with fish robots, this work delves into designing a novel HCM robotic propulsion system made from PETG plastic, carbon fiber-reinforced plastic (CFRP), and steel.","Detailed derivation and verification of the HCM theory are given, and the influence of key parameters like dimensions, material types, and servo motor specifications are summarized.","The designing algorithm offers insight into HCM robotics.","It enables us to search for suitable components, operate robots at a desired frequency, and achieve high-frequency and high-speed undulatory swimming for fish robots."],"url":"http://arxiv.org/abs/2311.03212v1"}
{"created":"2023-11-06 15:53:24","title":"Quantum Task Offloading with the OpenMP API","abstract":"Most of the widely used quantum programming languages and libraries are not designed for the tightly coupled nature of hybrid quantum-classical algorithms, which run on quantum resources that are integrated on-premise with classical HPC infrastructure. We propose a programming model using the API provided by OpenMP to target quantum devices, which provides an easy-to-use and efficient interface for HPC applications to utilize quantum compute resources. We have implemented a variational quantum eigensolver using the programming model, which has been tested using a classical simulator. We are in the process of testing on the quantum resources hosted at the Leibniz Supercomputing Centre (LRZ).","sentences":["Most of the widely used quantum programming languages and libraries are not designed for the tightly coupled nature of hybrid quantum-classical algorithms, which run on quantum resources that are integrated on-premise with classical HPC infrastructure.","We propose a programming model using the API provided by OpenMP to target quantum devices, which provides an easy-to-use and efficient interface for HPC applications to utilize quantum compute resources.","We have implemented a variational quantum eigensolver using the programming model, which has been tested using a classical simulator.","We are in the process of testing on the quantum resources hosted at the Leibniz Supercomputing Centre (LRZ)."],"url":"http://arxiv.org/abs/2311.03210v1"}
{"created":"2023-11-06 15:50:45","title":"Homogenization of Foil Windings with Globally Supported Polynomial Shape Functions","abstract":"In conventional finite element simulations, foil windings with thin foils and with a large number of turns require many mesh elements. This renders models quickly computationally infeasible. This paper uses a homogenized foil winding model and approximates the voltage distribution in the foil winding domain by globally supported polynomials. This way, the small-scale structure in the foil winding domain does not have to be resolved by the finite element mesh. The method is validated successfully for a stand-alone foil winding example and for a pot inductor example. Moreover, a transformer equipped with a foil winding at its primary side is simulated using a field-circuit coupled model.","sentences":["In conventional finite element simulations, foil windings with thin foils and with a large number of turns require many mesh elements.","This renders models quickly computationally infeasible.","This paper uses a homogenized foil winding model and approximates the voltage distribution in the foil winding domain by globally supported polynomials.","This way, the small-scale structure in the foil winding domain does not have to be resolved by the finite element mesh.","The method is validated successfully for a stand-alone foil winding example and for a pot inductor example.","Moreover, a transformer equipped with a foil winding at its primary side is simulated using a field-circuit coupled model."],"url":"http://arxiv.org/abs/2311.03207v1"}
{"created":"2023-11-06 15:49:44","title":"5G-CT: Automated Deployment and Over-the-Air Testing of End-to-End Open Radio Access Networks","abstract":"Deploying and testing cellular networks is a complex task due to the multitude of components involved-from the core to the Radio Access Network (RAN) and the User Equipments (UEs) -- all of which require integration and constant monitoring. Interference and the inherent randomness of the wireless channel further complicate the issue, posing additional challenges for repeatable and consistent testing. Consequently, both private and public cellular systems still rely heavily on human intervention for operations such as network reconfiguration, performance monitoring, and conducting end-to-end drive tests. This reliance significantly slows the pace of innovation in cellular systems.   To address these challenges, we introduce 5G-CT, an automation framework based on OpenShift and the GitOps workflow, capable of deploying a softwarized end-to-end 5G and O-RAN-compliant system in a matter of seconds. We have deployed 5G-CT to test the integration and performance of popular open-source cellular stacks, including OpenAirInterface (OAI), and have collected months of over-the-air testing results without the need for human intervention. 5G-CT brings cloud-native Continuous Integration (CI) and Continuous Delivery (CD) to the RAN, effectively addressing the complexities associated with managing spectrum, radios, heterogeneous devices, and distributed components. Moreover, it provides much-needed automation and Continuous Testing (CT) for cellular networks.","sentences":["Deploying and testing cellular networks is a complex task due to the multitude of components involved-from the core to the Radio Access Network (RAN) and the User Equipments (UEs) -- all of which require integration and constant monitoring.","Interference and the inherent randomness of the wireless channel further complicate the issue, posing additional challenges for repeatable and consistent testing.","Consequently, both private and public cellular systems still rely heavily on human intervention for operations such as network reconfiguration, performance monitoring, and conducting end-to-end drive tests.","This reliance significantly slows the pace of innovation in cellular systems.   ","To address these challenges, we introduce 5G-CT, an automation framework based on OpenShift and the GitOps workflow, capable of deploying a softwarized end-to-end 5G and O-RAN-compliant system in a matter of seconds.","We have deployed 5G-CT to test the integration and performance of popular open-source cellular stacks, including OpenAirInterface (OAI), and have collected months of over-the-air testing results without the need for human intervention.","5G-CT brings cloud-native Continuous Integration (CI) and Continuous Delivery (CD) to the RAN, effectively addressing the complexities associated with managing spectrum, radios, heterogeneous devices, and distributed components.","Moreover, it provides much-needed automation and Continuous Testing (CT) for cellular networks."],"url":"http://arxiv.org/abs/2311.03206v1"}
{"created":"2023-11-06 15:49:11","title":"PainSeeker: An Automated Method for Assessing Pain in Rats Through Facial Expressions","abstract":"In this letter, we aim to investigate whether laboratory rats' pain can be automatically assessed through their facial expressions. To this end, we began by presenting a publicly available dataset called RatsPain, consisting of 1,138 facial images captured from six rats that underwent an orthodontic treatment operation. Each rat' facial images in RatsPain were carefully selected from videos recorded either before or after the operation and well labeled by eight annotators according to the Rat Grimace Scale (RGS). We then proposed a novel deep learning method called PainSeeker for automatically assessing pain in rats via facial expressions. PainSeeker aims to seek pain-related facial local regions that facilitate learning both pain discriminative and head pose robust features from facial expression images. To evaluate the PainSeeker, we conducted extensive experiments on the RatsPain dataset. The results demonstrate the feasibility of assessing rats' pain from their facial expressions and also verify the effectiveness of the proposed PainSeeker in addressing this emerging but intriguing problem. The RasPain dataset can be freely obtained from https://github.com/xhzongyuan/RatsPain.","sentences":["In this letter, we aim to investigate whether laboratory rats' pain can be automatically assessed through their facial expressions.","To this end, we began by presenting a publicly available dataset called RatsPain, consisting of 1,138 facial images captured from six rats that underwent an orthodontic treatment operation.","Each rat' facial images in RatsPain were carefully selected from videos recorded either before or after the operation and well labeled by eight annotators according to the Rat Grimace Scale (RGS).","We then proposed a novel deep learning method called PainSeeker for automatically assessing pain in rats via facial expressions.","PainSeeker aims to seek pain-related facial local regions that facilitate learning both pain discriminative and head pose robust features from facial expression images.","To evaluate the PainSeeker, we conducted extensive experiments on the RatsPain dataset.","The results demonstrate the feasibility of assessing rats' pain from their facial expressions and also verify the effectiveness of the proposed PainSeeker in addressing this emerging but intriguing problem.","The RasPain dataset can be freely obtained from https://github.com/xhzongyuan/RatsPain."],"url":"http://arxiv.org/abs/2311.03205v1"}
{"created":"2023-11-06 15:39:48","title":"LCPR: A Multi-Scale Attention-Based LiDAR-Camera Fusion Network for Place Recognition","abstract":"Place recognition is one of the most crucial modules for autonomous vehicles to identify places that were previously visited in GPS-invalid environments. Sensor fusion is considered an effective method to overcome the weaknesses of individual sensors. In recent years, multimodal place recognition fusing information from multiple sensors has gathered increasing attention. However, most existing multimodal place recognition methods only use limited field-of-view camera images, which leads to an imbalance between features from different modalities and limits the effectiveness of sensor fusion. In this paper, we present a novel neural network named LCPR for robust multimodal place recognition, which fuses LiDAR point clouds with multi-view RGB images to generate discriminative and yaw-rotation invariant representations of the environment. A multi-scale attention-based fusion module is proposed to fully exploit the panoramic views from different modalities of the environment and their correlations. We evaluate our method on the nuScenes dataset, and the experimental results show that our method can effectively utilize multi-view camera and LiDAR data to improve the place recognition performance while maintaining strong robustness to viewpoint changes. Our open-source code and pre-trained models are available at https://github.com/ZhouZijie77/LCPR .","sentences":["Place recognition is one of the most crucial modules for autonomous vehicles to identify places that were previously visited in GPS-invalid environments.","Sensor fusion is considered an effective method to overcome the weaknesses of individual sensors.","In recent years, multimodal place recognition fusing information from multiple sensors has gathered increasing attention.","However, most existing multimodal place recognition methods only use limited field-of-view camera images, which leads to an imbalance between features from different modalities and limits the effectiveness of sensor fusion.","In this paper, we present a novel neural network named LCPR for robust multimodal place recognition, which fuses LiDAR point clouds with multi-view RGB images to generate discriminative and yaw-rotation invariant representations of the environment.","A multi-scale attention-based fusion module is proposed to fully exploit the panoramic views from different modalities of the environment and their correlations.","We evaluate our method on the nuScenes dataset, and the experimental results show that our method can effectively utilize multi-view camera and LiDAR data to improve the place recognition performance while maintaining strong robustness to viewpoint changes.","Our open-source code and pre-trained models are available at https://github.com/ZhouZijie77/LCPR ."],"url":"http://arxiv.org/abs/2311.03198v1"}
{"created":"2023-11-06 15:37:14","title":"Pseudo-Labeling for Domain-Agnostic Bangla Automatic Speech Recognition","abstract":"One of the major challenges for developing automatic speech recognition (ASR) for low-resource languages is the limited access to labeled data with domain-specific variations. In this study, we propose a pseudo-labeling approach to develop a large-scale domain-agnostic ASR dataset. With the proposed methodology, we developed a 20k+ hours labeled Bangla speech dataset covering diverse topics, speaking styles, dialects, noisy environments, and conversational scenarios. We then exploited the developed corpus to design a conformer-based ASR system. We benchmarked the trained ASR with publicly available datasets and compared it with other available models. To investigate the efficacy, we designed and developed a human-annotated domain-agnostic test set composed of news, telephony, and conversational data among others. Our results demonstrate the efficacy of the model trained on psuedo-label data for the designed test-set along with publicly-available Bangla datasets. The experimental resources will be publicly available.(https://github.com/hishab-nlp/Pseudo-Labeling-for-Domain-Agnostic-Bangla-ASR)","sentences":["One of the major challenges for developing automatic speech recognition (ASR) for low-resource languages is the limited access to labeled data with domain-specific variations.","In this study, we propose a pseudo-labeling approach to develop a large-scale domain-agnostic ASR dataset.","With the proposed methodology, we developed a 20k+ hours labeled Bangla speech dataset covering diverse topics, speaking styles, dialects, noisy environments, and conversational scenarios.","We then exploited the developed corpus to design a conformer-based ASR system.","We benchmarked the trained ASR with publicly available datasets and compared it with other available models.","To investigate the efficacy, we designed and developed a human-annotated domain-agnostic test set composed of news, telephony, and conversational data among others.","Our results demonstrate the efficacy of the model trained on psuedo-label data for the designed test-set along with publicly-available Bangla datasets.","The experimental resources will be publicly available.(https://github.com/hishab-nlp/Pseudo-Labeling-for-Domain-Agnostic-Bangla-ASR)"],"url":"http://arxiv.org/abs/2311.03196v1"}
{"created":"2023-11-06 15:32:50","title":"Few-shot Learning using Data Augmentation and Time-Frequency Transformation for Time Series Classification","abstract":"Deep neural networks (DNNs) that tackle the time series classification (TSC) task have provided a promising framework in signal processing. In real-world applications, as a data-driven model, DNNs are suffered from insufficient data. Few-shot learning has been studied to deal with this limitation. In this paper, we propose a novel few-shot learning framework through data augmentation, which involves transformation through the time-frequency domain and the generation of synthetic images through random erasing. Additionally, we develop a sequence-spectrogram neural network (SSNN). This neural network model composes of two sub-networks: one utilizing 1D residual blocks to extract features from the input sequence while the other one employing 2D residual blocks to extract features from the spectrogram representation. In the experiments, comparison studies of different existing DNN models with/without data augmentation are conducted on an amyotrophic lateral sclerosis (ALS) dataset and a wind turbine fault (WTF) dataset. The experimental results manifest that our proposed method achieves 93.75% F1 score and 93.33% accuracy on the ALS datasets while 95.48% F1 score and 95.59% accuracy on the WTF datasets. Our methodology demonstrates its applicability of addressing the few-shot problems for time series classification.","sentences":["Deep neural networks (DNNs) that tackle the time series classification (TSC) task have provided a promising framework in signal processing.","In real-world applications, as a data-driven model, DNNs are suffered from insufficient data.","Few-shot learning has been studied to deal with this limitation.","In this paper, we propose a novel few-shot learning framework through data augmentation, which involves transformation through the time-frequency domain and the generation of synthetic images through random erasing.","Additionally, we develop a sequence-spectrogram neural network (SSNN).","This neural network model composes of two sub-networks: one utilizing 1D residual blocks to extract features from the input sequence while the other one employing 2D residual blocks to extract features from the spectrogram representation.","In the experiments, comparison studies of different existing DNN models with/without data augmentation are conducted on an amyotrophic lateral sclerosis (ALS) dataset and a wind turbine fault (WTF) dataset.","The experimental results manifest that our proposed method achieves 93.75% F1 score and 93.33% accuracy on the ALS datasets while 95.48% F1 score and 95.59% accuracy on the WTF datasets.","Our methodology demonstrates its applicability of addressing the few-shot problems for time series classification."],"url":"http://arxiv.org/abs/2311.03194v1"}
{"created":"2023-11-06 15:29:30","title":"DeepInception: Hypnotize Large Language Model to Be Jailbreaker","abstract":"Despite remarkable success in various applications, large language models (LLMs) are vulnerable to adversarial jailbreaks that make the safety guardrails void. However, previous studies for jailbreaks usually resort to brute-force optimization or extrapolations of a high computation cost, which might not be practical or effective. In this paper, inspired by the Milgram experiment that individuals can harm another person if they are told to do so by an authoritative figure, we disclose a lightweight method, termed as DeepInception, which can easily hypnotize LLM to be a jailbreaker and unlock its misusing risks. Specifically, DeepInception leverages the personification ability of LLM to construct a novel nested scene to behave, which realizes an adaptive way to escape the usage control in a normal scenario and provides the possibility for further direct jailbreaks. Empirically, we conduct comprehensive experiments to show its efficacy. Our DeepInception can achieve competitive jailbreak success rates with previous counterparts and realize a continuous jailbreak in subsequent interactions, which reveals the critical weakness of self-losing on both open/closed-source LLMs like Falcon, Vicuna, Llama-2, and GPT-3.5/4/4V. Our investigation appeals that people should pay more attention to the safety aspects of LLMs and a stronger defense against their misuse risks. The code is publicly available at: https://github.com/tmlr-group/DeepInception.","sentences":["Despite remarkable success in various applications, large language models (LLMs) are vulnerable to adversarial jailbreaks that make the safety guardrails void.","However, previous studies for jailbreaks usually resort to brute-force optimization or extrapolations of a high computation cost, which might not be practical or effective.","In this paper, inspired by the Milgram experiment that individuals can harm another person if they are told to do so by an authoritative figure, we disclose a lightweight method, termed as DeepInception, which can easily hypnotize LLM to be a jailbreaker and unlock its misusing risks.","Specifically, DeepInception leverages the personification ability of LLM to construct a novel nested scene to behave, which realizes an adaptive way to escape the usage control in a normal scenario and provides the possibility for further direct jailbreaks.","Empirically, we conduct comprehensive experiments to show its efficacy.","Our DeepInception can achieve competitive jailbreak success rates with previous counterparts and realize a continuous jailbreak in subsequent interactions, which reveals the critical weakness of self-losing on both open/closed-source LLMs like Falcon, Vicuna, Llama-2, and GPT-3.5/4/4V. Our investigation appeals that people should pay more attention to the safety aspects of LLMs and a stronger defense against their misuse risks.","The code is publicly available at: https://github.com/tmlr-group/DeepInception."],"url":"http://arxiv.org/abs/2311.03191v1"}
{"created":"2023-11-06 15:28:24","title":"Safe Control for Soft-Rigid Robots with Self-Contact using Control Barrier Functions","abstract":"Incorporating both flexible and rigid components in robot designs offers a unique solution to the limitations of traditional rigid robotics by enabling both compliance and strength. This paper explores the challenges and solutions for controlling soft-rigid hybrid robots, particularly addressing the issue of self-contact. Conventional control methods prioritize precise state tracking, inadvertently increasing the system's overall stiffness, which is not always desirable in interactions with the environment or within the robot itself. To address this, we investigate the application of Control Barrier Functions (CBFs) and High Order CBFs to manage self-contact scenarios in serially connected soft-rigid hybrid robots. Through an analysis based on Piecewise Constant Curvature (PCC) kinematics, we establish CBFs within a classical control framework for self-contact dynamics. Our methodology is rigorously evaluated in both simulation environments and physical hardware systems. The findings demonstrate that our proposed control strategy effectively regulates self-contact in soft-rigid hybrid robotic systems, marking a significant advancement in the field of robotics.","sentences":["Incorporating both flexible and rigid components in robot designs offers a unique solution to the limitations of traditional rigid robotics by enabling both compliance and strength.","This paper explores the challenges and solutions for controlling soft-rigid hybrid robots, particularly addressing the issue of self-contact.","Conventional control methods prioritize precise state tracking, inadvertently increasing the system's overall stiffness, which is not always desirable in interactions with the environment or within the robot itself.","To address this, we investigate the application of Control Barrier Functions (CBFs) and High Order CBFs to manage self-contact scenarios in serially connected soft-rigid hybrid robots.","Through an analysis based on Piecewise Constant Curvature (PCC) kinematics, we establish CBFs within a classical control framework for self-contact dynamics.","Our methodology is rigorously evaluated in both simulation environments and physical hardware systems.","The findings demonstrate that our proposed control strategy effectively regulates self-contact in soft-rigid hybrid robotic systems, marking a significant advancement in the field of robotics."],"url":"http://arxiv.org/abs/2311.03189v1"}
{"created":"2023-11-06 15:25:30","title":"Model-based Counterfactual Generator for Gender Bias Mitigation","abstract":"Counterfactual Data Augmentation (CDA) has been one of the preferred techniques for mitigating gender bias in natural language models. CDA techniques have mostly employed word substitution based on dictionaries. Although such dictionary-based CDA techniques have been shown to significantly improve the mitigation of gender bias, in this paper, we highlight some limitations of such dictionary-based counterfactual data augmentation techniques, such as susceptibility to ungrammatical compositions, and lack of generalization outside the set of predefined dictionary words. Model-based solutions can alleviate these problems, yet the lack of qualitative parallel training data hinders development in this direction. Therefore, we propose a combination of data processing techniques and a bi-objective training regime to develop a model-based solution for generating counterfactuals to mitigate gender bias. We implemented our proposed solution and performed an empirical evaluation which shows how our model alleviates the shortcomings of dictionary-based solutions.","sentences":["Counterfactual Data Augmentation (CDA) has been one of the preferred techniques for mitigating gender bias in natural language models.","CDA techniques have mostly employed word substitution based on dictionaries.","Although such dictionary-based CDA techniques have been shown to significantly improve the mitigation of gender bias, in this paper, we highlight some limitations of such dictionary-based counterfactual data augmentation techniques, such as susceptibility to ungrammatical compositions, and lack of generalization outside the set of predefined dictionary words.","Model-based solutions can alleviate these problems, yet the lack of qualitative parallel training data hinders development in this direction.","Therefore, we propose a combination of data processing techniques and a bi-objective training regime to develop a model-based solution for generating counterfactuals to mitigate gender bias.","We implemented our proposed solution and performed an empirical evaluation which shows how our model alleviates the shortcomings of dictionary-based solutions."],"url":"http://arxiv.org/abs/2311.03186v1"}
{"created":"2023-11-06 15:24:18","title":"Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for Propaganda and Disinformation Detection","abstract":"The spread of disinformation and propagandistic content poses a threat to societal harmony, undermining informed decision-making and trust in reliable sources. Online platforms often serve as breeding grounds for such content, and malicious actors exploit the vulnerabilities of audiences to shape public opinion. Although there have been research efforts aimed at the automatic identification of disinformation and propaganda in social media content, there remain challenges in terms of performance. The ArAIEval shared task aims to further research on these particular issues within the context of the Arabic language. In this paper, we discuss our participation in these shared tasks. We competed in subtasks 1A and 2A, where our submitted system secured positions 9th and 10th, respectively. Our experiments consist of fine-tuning transformer models and using zero- and few-shot learning with GPT-4.","sentences":["The spread of disinformation and propagandistic content poses a threat to societal harmony, undermining informed decision-making and trust in reliable sources.","Online platforms often serve as breeding grounds for such content, and malicious actors exploit the vulnerabilities of audiences to shape public opinion.","Although there have been research efforts aimed at the automatic identification of disinformation and propaganda in social media content, there remain challenges in terms of performance.","The ArAIEval shared task aims to further research on these particular issues within the context of the Arabic language.","In this paper, we discuss our participation in these shared tasks.","We competed in subtasks 1A and 2A, where our submitted system secured positions 9th and 10th, respectively.","Our experiments consist of fine-tuning transformer models and using zero- and few-shot learning with GPT-4."],"url":"http://arxiv.org/abs/2311.03184v1"}
{"created":"2023-11-06 15:21:19","title":"ArAIEval Shared Task: Persuasion Techniques and Disinformation Detection in Arabic Text","abstract":"We present an overview of the ArAIEval shared task, organized as part of the first ArabicNLP 2023 conference co-located with EMNLP 2023. ArAIEval offers two tasks over Arabic text: (i) persuasion technique detection, focusing on identifying persuasion techniques in tweets and news articles, and (ii) disinformation detection in binary and multiclass setups over tweets. A total of 20 teams participated in the final evaluation phase, with 14 and 16 teams participating in Tasks 1 and 2, respectively. Across both tasks, we observed that fine-tuning transformer models such as AraBERT was at the core of the majority of the participating systems. We provide a description of the task setup, including a description of the dataset construction and the evaluation setup. We further give a brief overview of the participating systems. All datasets and evaluation scripts from the shared task are released to the research community. (https://araieval.gitlab.io/) We hope this will enable further research on these important tasks in Arabic.","sentences":["We present an overview of the ArAIEval shared task, organized as part of the first ArabicNLP 2023 conference co-located with EMNLP 2023.","ArAIEval offers two tasks over Arabic text: (i) persuasion technique detection, focusing on identifying persuasion techniques in tweets and news articles, and (ii) disinformation detection in binary and multiclass setups over tweets.","A total of 20 teams participated in the final evaluation phase, with 14 and 16 teams participating in Tasks 1 and 2, respectively.","Across both tasks, we observed that fine-tuning transformer models such as AraBERT was at the core of the majority of the participating systems.","We provide a description of the task setup, including a description of the dataset construction and the evaluation setup.","We further give a brief overview of the participating systems.","All datasets and evaluation scripts from the shared task are released to the research community.","(https://araieval.gitlab.io/)","We hope this will enable further research on these important tasks in Arabic."],"url":"http://arxiv.org/abs/2311.03179v1"}
{"created":"2023-11-06 15:17:17","title":"1D-Convolutional transformer for Parkinson disease diagnosis from gait","abstract":"This paper presents an efficient deep neural network model for diagnosing Parkinson's disease from gait. More specifically, we introduce a hybrid ConvNet-Transformer architecture to accurately diagnose the disease by detecting the severity stage. The proposed architecture exploits the strengths of both Convolutional Neural Networks and Transformers in a single end-to-end model, where the former is able to extract relevant local features from Vertical Ground Reaction Force (VGRF) signal, while the latter allows to capture long-term spatio-temporal dependencies in data. In this manner, our hybrid architecture achieves an improved performance compared to using either models individually. Our experimental results show that our approach is effective for detecting the different stages of Parkinson's disease from gait data, with a final accuracy of 88%, outperforming other state-of-the-art AI methods on the Physionet gait dataset. Moreover, our method can be generalized and adapted for other classification problems to jointly address the feature relevance and spatio-temporal dependency problems in 1D signals. Our source code and pre-trained models are publicly available at https://github.com/SafwenNaimi/1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait.","sentences":["This paper presents an efficient deep neural network model for diagnosing Parkinson's disease from gait.","More specifically, we introduce a hybrid ConvNet-Transformer architecture to accurately diagnose the disease by detecting the severity stage.","The proposed architecture exploits the strengths of both Convolutional Neural Networks and Transformers in a single end-to-end model, where the former is able to extract relevant local features from Vertical Ground Reaction Force (VGRF) signal, while the latter allows to capture long-term spatio-temporal dependencies in data.","In this manner, our hybrid architecture achieves an improved performance compared to using either models individually.","Our experimental results show that our approach is effective for detecting the different stages of Parkinson's disease from gait data, with a final accuracy of 88%, outperforming other state-of-the-art AI methods on the Physionet gait dataset.","Moreover, our method can be generalized and adapted for other classification problems to jointly address the feature relevance and spatio-temporal dependency problems in 1D signals.","Our source code and pre-trained models are publicly available at https://github.com/SafwenNaimi/1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait."],"url":"http://arxiv.org/abs/2311.03177v1"}
{"created":"2023-11-06 15:09:22","title":"Incremental Approximate Maximum Flow on Undirected Graphs in Subpolynomial Update Time","abstract":"We provide an algorithm which, with high probability, maintains a $(1-\\epsilon)$-approximate maximum flow on an undirected graph undergoing $m$-edge additions in amortized $m^{o(1)} \\epsilon^{-3}$ time per update. To obtain this result, we provide a more general algorithm that solves what we call the incremental, thresholded $p$-norm flow problem that asks to determine the first edge-insertion in an undirected graph that causes the minimum $\\ell_p$-norm flow to decrease below a given threshold in value. Since we solve this thresholded problem, our data structure succeeds against an adaptive adversary that can only see the data structure's output. Furthermore, since our algorithm holds for $p = 2$, we obtain improved algorithms for dynamically maintaining the effective resistance between a pair of vertices in an undirected graph undergoing edge insertions.   Our algorithm builds upon previous dynamic algorithms for approximately solving the minimum-ratio cycle problem that underlie previous advances on the maximum flow problem [Chen-Kyng-Liu-Peng-Probst Gutenberg-Sachdeva, FOCS '22] as well as recent dynamic maximum flow algorithms [v.d.Brand-Liu-Sidford, STOC '23]. Instead of using interior point methods, which were a key component of these recent advances, our algorithm uses an optimization method based on $\\ell_p$-norm iterative refinement and the multiplicative weight update method. This ensures a monotonicity property in the minimum-ratio cycle subproblems that allows us to apply known data structures and bypass issues arising from adaptive queries.","sentences":["We provide an algorithm which, with high probability, maintains a $(1-\\epsilon)$-approximate maximum flow on an undirected graph undergoing $m$-edge additions in amortized $m^{o(1)} \\epsilon^{-3}$ time per update.","To obtain this result, we provide a more general algorithm that solves what we call the incremental, thresholded $p$-norm flow problem that asks to determine the first edge-insertion in an undirected graph that causes the minimum $\\ell_p$-norm flow to decrease below a given threshold in value.","Since we solve this thresholded problem, our data structure succeeds against an adaptive adversary that can only see the data structure's output.","Furthermore, since our algorithm holds for $p = 2$, we obtain improved algorithms for dynamically maintaining the effective resistance between a pair of vertices in an undirected graph undergoing edge insertions.   ","Our algorithm builds upon previous dynamic algorithms for approximately solving the minimum-ratio cycle problem that underlie previous advances on the maximum flow problem [Chen-Kyng-Liu-Peng-Probst Gutenberg-Sachdeva, FOCS '22] as well as recent dynamic maximum flow algorithms","[v.d.Brand-Liu-Sidford, STOC '23].","Instead of using interior point methods, which were a key component of these recent advances, our algorithm uses an optimization method based on $\\ell_p$-norm iterative refinement and the multiplicative weight update method.","This ensures a monotonicity property in the minimum-ratio cycle subproblems that allows us to apply known data structures and bypass issues arising from adaptive queries."],"url":"http://arxiv.org/abs/2311.03174v1"}
{"created":"2023-11-06 15:04:48","title":"Preserving Privacy in GANs Against Membership Inference Attack","abstract":"Generative Adversarial Networks (GANs) have been widely used for generating synthetic data for cases where there is a limited size real-world dataset or when data holders are unwilling to share their data samples. Recent works showed that GANs, due to overfitting and memorization, might leak information regarding their training data samples. This makes GANs vulnerable to Membership Inference Attacks (MIAs). Several defense strategies have been proposed in the literature to mitigate this privacy issue. Unfortunately, defense strategies based on differential privacy are proven to reduce extensively the quality of the synthetic data points. On the other hand, more recent frameworks such as PrivGAN and PAR-GAN are not suitable for small-size training datasets. In the present work, the overfitting in GANs is studied in terms of the discriminator, and a more general measure of overfitting based on the Bhattacharyya coefficient is defined. Then, inspired by Fano's inequality, our first defense mechanism against MIAs is proposed. This framework, which requires only a simple modification in the loss function of GANs, is referred to as the maximum entropy GAN or MEGAN and significantly improves the robustness of GANs to MIAs. As a second defense strategy, a more heuristic model based on minimizing the information leaked from generated samples about the training data points is presented. This approach is referred to as mutual information minimization GAN (MIMGAN) and uses a variational representation of the mutual information to minimize the information that a synthetic sample might leak about the whole training data set. Applying the proposed frameworks to some commonly used data sets against state-of-the-art MIAs reveals that the proposed methods can reduce the accuracy of the adversaries to the level of random guessing accuracy with a small reduction in the quality of the synthetic data samples.","sentences":["Generative Adversarial Networks (GANs) have been widely used for generating synthetic data for cases where there is a limited size real-world dataset or when data holders are unwilling to share their data samples.","Recent works showed that GANs, due to overfitting and memorization, might leak information regarding their training data samples.","This makes GANs vulnerable to Membership Inference Attacks (MIAs).","Several defense strategies have been proposed in the literature to mitigate this privacy issue.","Unfortunately, defense strategies based on differential privacy are proven to reduce extensively the quality of the synthetic data points.","On the other hand, more recent frameworks such as PrivGAN and PAR-GAN are not suitable for small-size training datasets.","In the present work, the overfitting in GANs is studied in terms of the discriminator, and a more general measure of overfitting based on the Bhattacharyya coefficient is defined.","Then, inspired by Fano's inequality, our first defense mechanism against MIAs is proposed.","This framework, which requires only a simple modification in the loss function of GANs, is referred to as the maximum entropy GAN or MEGAN and significantly improves the robustness of GANs to MIAs.","As a second defense strategy, a more heuristic model based on minimizing the information leaked from generated samples about the training data points is presented.","This approach is referred to as mutual information minimization GAN (MIMGAN) and uses a variational representation of the mutual information to minimize the information that a synthetic sample might leak about the whole training data set.","Applying the proposed frameworks to some commonly used data sets against state-of-the-art MIAs reveals that the proposed methods can reduce the accuracy of the adversaries to the level of random guessing accuracy with a small reduction in the quality of the synthetic data samples."],"url":"http://arxiv.org/abs/2311.03172v1"}
{"created":"2023-11-06 15:04:03","title":"An Examination of the Alleged Privacy Threats of Confidence-Ranked Reconstruction of Census Microdata","abstract":"The alleged threat of reconstruction attacks has led the U.S. Census Bureau (USCB) to replace in the Decennial Census 2020 the traditional statistical disclosure limitation based on rank swapping with one based on differential privacy (DP). This has resulted in substantial accuracy loss of the released statistics. Worse yet, it has been shown that the reconstruction attacks used as an argument to move to DP are very far from allowing unequivocal reidentification of the respondents, because in general there are a lot of reconstructions compatible with the released statistics. In a very recent paper, a new reconstruction attack has been proposed, whose goal is to indicate the confidence that a reconstructed record was in the original respondent data. The alleged risk of serious disclosure entailed by such confidence-ranked reconstruction has renewed the interest of the USCB to use DP-based solutions. To forestall the potential accuracy loss in future data releases resulting from adoption of these solutions, we show in this paper that the proposed confidence-ranked reconstruction does not threaten privacy. Specifically, we report empirical results showing that the proposed ranking cannot guide reidentification or attribute disclosure attacks, and hence it fails to warrant the USCB's move towards DP. Further, we also demonstrate that, due to the way the Census data are compiled, processed and released, it is not possible to reconstruct original and complete records through any methodology, and the confidence-ranked reconstruction not only is completely ineffective at accurately reconstructing Census records but is trivially outperformed by an adequate interpretation of the released aggregate statistics.","sentences":["The alleged threat of reconstruction attacks has led the U.S. Census Bureau (USCB) to replace in the Decennial Census 2020 the traditional statistical disclosure limitation based on rank swapping with one based on differential privacy (DP).","This has resulted in substantial accuracy loss of the released statistics.","Worse yet, it has been shown that the reconstruction attacks used as an argument to move to DP are very far from allowing unequivocal reidentification of the respondents, because in general there are a lot of reconstructions compatible with the released statistics.","In a very recent paper, a new reconstruction attack has been proposed, whose goal is to indicate the confidence that a reconstructed record was in the original respondent data.","The alleged risk of serious disclosure entailed by such confidence-ranked reconstruction has renewed the interest of the USCB to use DP-based solutions.","To forestall the potential accuracy loss in future data releases resulting from adoption of these solutions, we show in this paper that the proposed confidence-ranked reconstruction does not threaten privacy.","Specifically, we report empirical results showing that the proposed ranking cannot guide reidentification or attribute disclosure attacks, and hence it fails to warrant the USCB's move towards DP.","Further, we also demonstrate that, due to the way the Census data are compiled, processed and released, it is not possible to reconstruct original and complete records through any methodology, and the confidence-ranked reconstruction not only is completely ineffective at accurately reconstructing Census records but is trivially outperformed by an adequate interpretation of the released aggregate statistics."],"url":"http://arxiv.org/abs/2311.03171v1"}
{"created":"2023-11-06 14:52:30","title":"GPTuner: A Manual-Reading Database Tuning System via GPT-Guided Bayesian Optimization","abstract":"Modern database management systems (DBMS) expose hundreds of configurable knobs to control system behaviours. Determining the appropriate values for these knobs to improve DBMS performance is a long-standing problem in the database community. As there is an increasing number of knobs to tune and each knob could be in continuous or categorical values, manual tuning becomes impractical. Recently, automatic tuning systems using machine learning methods have shown great potentials. However, existing approaches still incur significant tuning costs or only yield sub-optimal performance. This is because they either ignore the extensive domain knowledge available (e.g., DBMS manuals and forum discussions) and only rely on the runtime feedback of benchmark evaluations to guide the optimization, or they utilize the domain knowledge in a limited way. Hence, we propose GPTuner, a manual-reading database tuning system. Firstly, we develop a Large Language Model (LLM)-based pipeline to collect and refine heterogeneous knowledge, and propose a prompt ensemble algorithm to unify a structured view of the refined knowledge. Secondly, using the structured knowledge, we (1) design a workload-aware and training-free knob selection strategy, (2) develop a search space optimization technique considering the value range of each knob, and (3) propose a Coarse-to-Fine Bayesian Optimization Framework to explore the optimized space. Finally, we evaluate GPTuner under different benchmarks (TPC-C and TPC-H), metrics (throughput and latency) as well as DBMS (PostgreSQL and MySQL). Compared to the state-of-the-art approaches, GPTuner identifies better configurations in 16x less time on average. Moreover, GPTuner achieves up to 30% performance improvement (higher throughput or lower latency) over the best-performing alternative.","sentences":["Modern database management systems (DBMS) expose hundreds of configurable knobs to control system behaviours.","Determining the appropriate values for these knobs to improve DBMS performance is a long-standing problem in the database community.","As there is an increasing number of knobs to tune and each knob could be in continuous or categorical values, manual tuning becomes impractical.","Recently, automatic tuning systems using machine learning methods have shown great potentials.","However, existing approaches still incur significant tuning costs or only yield sub-optimal performance.","This is because they either ignore the extensive domain knowledge available (e.g., DBMS manuals and forum discussions) and only rely on the runtime feedback of benchmark evaluations to guide the optimization, or they utilize the domain knowledge in a limited way.","Hence, we propose GPTuner, a manual-reading database tuning system.","Firstly, we develop a Large Language Model (LLM)-based pipeline to collect and refine heterogeneous knowledge, and propose a prompt ensemble algorithm to unify a structured view of the refined knowledge.","Secondly, using the structured knowledge, we (1) design a workload-aware and training-free knob selection strategy, (2) develop a search space optimization technique considering the value range of each knob, and (3) propose a Coarse-to-Fine Bayesian Optimization Framework to explore the optimized space.","Finally, we evaluate GPTuner under different benchmarks (TPC-C and TPC-H), metrics (throughput and latency) as well as DBMS (PostgreSQL and MySQL).","Compared to the state-of-the-art approaches, GPTuner identifies better configurations in 16x less time on average.","Moreover, GPTuner achieves up to 30% performance improvement (higher throughput or lower latency) over the best-performing alternative."],"url":"http://arxiv.org/abs/2311.03157v1"}
{"created":"2023-11-06 14:48:51","title":"Convergence Analysis of Sequential Federated Learning on Heterogeneous Data","abstract":"There are two categories of methods in Federated Learning (FL) for joint training across multiple clients: i) parallel FL (PFL), where clients train models in a parallel manner; and ii) sequential FL (SFL), where clients train models in a sequential manner. In contrast to that of PFL, the convergence theory of SFL on heterogeneous data is still lacking. In this paper, we establish the convergence guarantees of SFL for strongly/general/non-convex objectives on heterogeneous data. The convergence guarantees of SFL are better than that of PFL on heterogeneous data with both full and partial client participation. Experimental results validate the counterintuitive analysis result that SFL outperforms PFL on extremely heterogeneous data in cross-device settings.","sentences":["There are two categories of methods in Federated Learning (FL) for joint training across multiple clients: i) parallel FL (PFL), where clients train models in a parallel manner; and ii) sequential FL (SFL), where clients train models in a sequential manner.","In contrast to that of PFL, the convergence theory of SFL on heterogeneous data is still lacking.","In this paper, we establish the convergence guarantees of SFL for strongly/general/non-convex objectives on heterogeneous data.","The convergence guarantees of SFL are better than that of PFL on heterogeneous data with both full and partial client participation.","Experimental results validate the counterintuitive analysis result that SFL outperforms PFL on extremely heterogeneous data in cross-device settings."],"url":"http://arxiv.org/abs/2311.03154v1"}
{"created":"2023-11-06 14:47:48","title":"Architectural Sweet Spots for Modeling Human Label Variation by the Example of Argument Quality: It's Best to Relate Perspectives!","abstract":"Many annotation tasks in natural language processing are highly subjective in that there can be different valid and justified perspectives on what is a proper label for a given example. This also applies to the judgment of argument quality, where the assignment of a single ground truth is often questionable. At the same time, there are generally accepted concepts behind argumentation that form a common ground. To best represent the interplay of individual and shared perspectives, we consider a continuum of approaches ranging from models that fully aggregate perspectives into a majority label to \"share nothing\"-architectures in which each annotator is considered in isolation from all other annotators. In between these extremes, inspired by models used in the field of recommender systems, we investigate the extent to which architectures that include layers to model the relations between different annotators are beneficial for predicting single-annotator labels. By means of two tasks of argument quality classification (argument concreteness and validity/novelty of conclusions), we show that recommender architectures increase the averaged annotator-individual F$_1$-scores up to $43\\%$ over a majority label model. Our findings indicate that approaches to subjectivity can benefit from relating individual perspectives.","sentences":["Many annotation tasks in natural language processing are highly subjective in that there can be different valid and justified perspectives on what is a proper label for a given example.","This also applies to the judgment of argument quality, where the assignment of a single ground truth is often questionable.","At the same time, there are generally accepted concepts behind argumentation that form a common ground.","To best represent the interplay of individual and shared perspectives, we consider a continuum of approaches ranging from models that fully aggregate perspectives into a majority label to \"share nothing\"-architectures in which each annotator is considered in isolation from all other annotators.","In between these extremes, inspired by models used in the field of recommender systems, we investigate the extent to which architectures that include layers to model the relations between different annotators are beneficial for predicting single-annotator labels.","By means of two tasks of argument quality classification (argument concreteness and validity/novelty of conclusions), we show that recommender architectures increase the averaged annotator-individual F$_1$-scores up to $43\\%$ over a majority label model.","Our findings indicate that approaches to subjectivity can benefit from relating individual perspectives."],"url":"http://arxiv.org/abs/2311.03153v1"}
