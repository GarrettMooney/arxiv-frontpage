{"created":"2023-06-29 17:59:57","title":"An Efficient General-Purpose Modular Vision Model via Multi-Task Heterogeneous Training","abstract":"We present a model that can perform multiple vision tasks and can be adapted to other downstream tasks efficiently. Despite considerable progress in multi-task learning, most efforts focus on learning from multi-label data: a single image set with multiple task labels. Such multi-label data sets are rare, small, and expensive. We say heterogeneous to refer to image sets with different task labels, or to combinations of single-task datasets. Few have explored training on such heterogeneous datasets. General-purpose vision models are still dominated by single-task pretraining, and it remains unclear how to scale up multi-task models by leveraging mainstream vision datasets designed for different purposes. The challenges lie in managing large intrinsic differences among vision tasks, including data distribution, architectures, task-specific modules, dataset scales, and sampling strategies. To address these challenges, we propose to modify and scale up mixture-of-experts (MoE) vision transformers, so that they can simultaneously learn classification, detection, and segmentation on diverse mainstream vision datasets including ImageNet, COCO, and ADE20K. Our approach achieves comparable results to single-task state-of-the-art models and demonstrates strong generalization on downstream tasks. Due to its emergent modularity, this general-purpose model decomposes into high-performing components, efficiently adapting to downstream tasks. We can fine-tune it with fewer training parameters, fewer model parameters, and less computation. Additionally, its modularity allows for easy expansion in continual-learning-without-forgetting scenarios. Finally, these functions can be controlled and combined to meet various demands of downstream tasks.","sentences":["We present a model that can perform multiple vision tasks and can be adapted to other downstream tasks efficiently.","Despite considerable progress in multi-task learning, most efforts focus on learning from multi-label data: a single image set with multiple task labels.","Such multi-label data sets are rare, small, and expensive.","We say heterogeneous to refer to image sets with different task labels, or to combinations of single-task datasets.","Few have explored training on such heterogeneous datasets.","General-purpose vision models are still dominated by single-task pretraining, and it remains unclear how to scale up multi-task models by leveraging mainstream vision datasets designed for different purposes.","The challenges lie in managing large intrinsic differences among vision tasks, including data distribution, architectures, task-specific modules, dataset scales, and sampling strategies.","To address these challenges, we propose to modify and scale up mixture-of-experts (MoE) vision transformers, so that they can simultaneously learn classification, detection, and segmentation on diverse mainstream vision datasets including ImageNet, COCO, and","ADE20K.","Our approach achieves comparable results to single-task state-of-the-art models and demonstrates strong generalization on downstream tasks.","Due to its emergent modularity, this general-purpose model decomposes into high-performing components, efficiently adapting to downstream tasks.","We can fine-tune it with fewer training parameters, fewer model parameters, and less computation.","Additionally, its modularity allows for easy expansion in continual-learning-without-forgetting scenarios.","Finally, these functions can be controlled and combined to meet various demands of downstream tasks."],"url":"http://arxiv.org/abs/2306.17165v1"}
{"created":"2023-06-29 17:59:05","title":"Can Machines Garden? Systematically Comparing the AlphaGarden vs. Professional Horticulturalists","abstract":"The AlphaGarden is an automated testbed for indoor polyculture farming which combines a first-order plant simulator, a gantry robot, a seed planting algorithm, plant phenotyping and tracking algorithms, irrigation sensors and algorithms, and custom pruning tools and algorithms. In this paper, we systematically compare the performance of the AlphaGarden to professional horticulturalists on the staff of the UC Berkeley Oxford Tract Greenhouse. The humans and the machine tend side-by-side polyculture gardens with the same seed arrangement. We compare performance in terms of canopy coverage, plant diversity, and water consumption. Results from two 60-day cycles suggest that the automated AlphaGarden performs comparably to professional horticulturalists in terms of coverage and diversity, and reduces water consumption by as much as 44%. Code, videos, and datasets are available at https://sites.google.com/berkeley.edu/systematiccomparison.","sentences":["The AlphaGarden is an automated testbed for indoor polyculture farming which combines a first-order plant simulator, a gantry robot, a seed planting algorithm, plant phenotyping and tracking algorithms, irrigation sensors and algorithms, and custom pruning tools and algorithms.","In this paper, we systematically compare the performance of the AlphaGarden to professional horticulturalists on the staff of the UC Berkeley Oxford Tract Greenhouse.","The humans and the machine tend side-by-side polyculture gardens with the same seed arrangement.","We compare performance in terms of canopy coverage, plant diversity, and water consumption.","Results from two 60-day cycles suggest that the automated AlphaGarden performs comparably to professional horticulturalists in terms of coverage and diversity, and reduces water consumption by as much as 44%.","Code, videos, and datasets are available at https://sites.google.com/berkeley.edu/systematiccomparison."],"url":"http://arxiv.org/abs/2306.17162v1"}
{"created":"2023-06-29 17:57:55","title":"FogROS2-SGC: A ROS2 Cloud Robotics Platform for Secure Global Connectivity","abstract":"The Robot Operating System (ROS2) is the most widely used software platform for building robotics applications. FogROS2 extends ROS2 to allow robots to access cloud computing on demand. However, ROS2 and FogROS2 assume that all robots are locally connected and that each robot has full access and control of the other robots. With applications like distributed multi-robot systems, remote robot control, and mobile robots, robotics increasingly involves the global Internet and complex trust management. Existing approaches for connecting disjoint ROS2 networks lack key features such as security, compatibility, efficiency, and ease of use. We introduce FogROS2-SGC, an extension of FogROS2 that can effectively connect robot systems across different physical locations, networks, and Data Distribution Services (DDS). With globally unique and location-independent identifiers, FogROS2-SGC securely and efficiently routes data between robotics components around the globe. FogROS2-SGC is agnostic to the ROS2 distribution and configuration, is compatible with non-ROS2 software, and seamlessly extends existing ROS2 applications without any code modification. Experiments suggest FogROS2-SGC is 19x faster than rosbridge (a ROS2 package with comparable features, but lacking security). We also apply FogROS2-SGC to 4 robots and compute nodes that are 3600km apart. Videos and code are available on the project website https://sites.google.com/view/fogros2-sgc.","sentences":["The Robot Operating System (ROS2) is the most widely used software platform for building robotics applications.","FogROS2 extends ROS2 to allow robots to access cloud computing on demand.","However, ROS2 and FogROS2 assume that all robots are locally connected and that each robot has full access and control of the other robots.","With applications like distributed multi-robot systems, remote robot control, and mobile robots, robotics increasingly involves the global Internet and complex trust management.","Existing approaches for connecting disjoint ROS2 networks lack key features such as security, compatibility, efficiency, and ease of use.","We introduce FogROS2-SGC, an extension of FogROS2 that can effectively connect robot systems across different physical locations, networks, and Data Distribution Services (DDS).","With globally unique and location-independent identifiers, FogROS2-SGC securely and efficiently routes data between robotics components around the globe.","FogROS2-SGC is agnostic to the ROS2 distribution and configuration, is compatible with non-ROS2 software, and seamlessly extends existing ROS2 applications without any code modification.","Experiments suggest FogROS2-SGC is 19x faster than rosbridge (a ROS2 package with comparable features, but lacking security).","We also apply FogROS2-SGC to 4 robots and compute nodes that are 3600km apart.","Videos and code are available on the project website https://sites.google.com/view/fogros2-sgc."],"url":"http://arxiv.org/abs/2306.17157v1"}
{"created":"2023-06-29 17:57:40","title":"Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors","abstract":"Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies for introductory programming. Recent works have studied these models for different scenarios relevant to programming education; however, these works are limited for several reasons, as they typically consider already outdated models or only specific scenario(s). Consequently, there is a lack of a systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios. We evaluate using five introductory Python programming problems and real-world buggy programs from an online platform, and assess performance using expert-based annotations. Our results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors' performance for several scenarios. These results also highlight settings where GPT-4 still struggles, providing exciting future directions on developing techniques to improve the performance of these models.","sentences":["Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies for introductory programming.","Recent works have studied these models for different scenarios relevant to programming education; however, these works are limited for several reasons, as they typically consider already outdated models or only specific scenario(s).","Consequently, there is a lack of a systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios.","In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios.","We evaluate using five introductory Python programming problems and real-world buggy programs from an online platform, and assess performance using expert-based annotations.","Our results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors' performance for several scenarios.","These results also highlight settings where GPT-4 still struggles, providing exciting future directions on developing techniques to improve the performance of these models."],"url":"http://arxiv.org/abs/2306.17156v1"}
{"created":"2023-06-29 17:55:14","title":"Generate Anything Anywhere in Any Scene","abstract":"Text-to-image diffusion models have attracted considerable interest due to their wide applicability across diverse fields. However, challenges persist in creating controllable models for personalized object generation. In this paper, we first identify the entanglement issues in existing personalized generative models, and then propose a straightforward and efficient data augmentation training strategy that guides the diffusion model to focus solely on object identity. By inserting the plug-and-play adapter layers from a pre-trained controllable diffusion model, our model obtains the ability to control the location and size of each generated personalized object. During inference, we propose a regionally-guided sampling technique to maintain the quality and fidelity of the generated images. Our method achieves comparable or superior fidelity for personalized objects, yielding a robust, versatile, and controllable text-to-image diffusion model that is capable of generating realistic and personalized images. Our approach demonstrates significant potential for various applications, such as those in art, entertainment, and advertising design.","sentences":["Text-to-image diffusion models have attracted considerable interest due to their wide applicability across diverse fields.","However, challenges persist in creating controllable models for personalized object generation.","In this paper, we first identify the entanglement issues in existing personalized generative models, and then propose a straightforward and efficient data augmentation training strategy that guides the diffusion model to focus solely on object identity.","By inserting the plug-and-play adapter layers from a pre-trained controllable diffusion model, our model obtains the ability to control the location and size of each generated personalized object.","During inference, we propose a regionally-guided sampling technique to maintain the quality and fidelity of the generated images.","Our method achieves comparable or superior fidelity for personalized objects, yielding a robust, versatile, and controllable text-to-image diffusion model that is capable of generating realistic and personalized images.","Our approach demonstrates significant potential for various applications, such as those in art, entertainment, and advertising design."],"url":"http://arxiv.org/abs/2306.17154v1"}
{"created":"2023-06-29 17:44:18","title":"Filtered-Guided Diffusion: Fast Filter Guidance for Black-Box Diffusion Models","abstract":"Recent advances in diffusion-based generative models have shown incredible promise for Image-to-Image translation and editing. Most recent work in this space relies on additional training or architecture-specific adjustments to the diffusion process. In this work, we show that much of this low-level control can be achieved without additional training or any access to features of the diffusion model. Our method simply applies a filter to the input of each diffusion step based on the output of the previous step in an adaptive manner. Notably, this approach does not depend on any specific architecture or sampler and can be done without access to internal features of the network, making it easy to combine with other techniques, samplers, and diffusion architectures. Furthermore, it has negligible cost to performance, and allows for more continuous adjustment of guidance strength than other approaches. We show FGD offers a fast and strong baseline that is competitive with recent architecture-dependent approaches. Furthermore, FGD can also be used as a simple add-on to enhance the structural guidance of other state-of-the-art I2I methods. Finally, our derivation of this method helps to understand the impact of self attention, a key component of other recent architecture-specific I2I approaches, in a more architecture-independent way. Project page: https://github.com/jaclyngu/FilteredGuidedDiffusion","sentences":["Recent advances in diffusion-based generative models have shown incredible promise for Image-to-Image translation and editing.","Most recent work in this space relies on additional training or architecture-specific adjustments to the diffusion process.","In this work, we show that much of this low-level control can be achieved without additional training or any access to features of the diffusion model.","Our method simply applies a filter to the input of each diffusion step based on the output of the previous step in an adaptive manner.","Notably, this approach does not depend on any specific architecture or sampler and can be done without access to internal features of the network, making it easy to combine with other techniques, samplers, and diffusion architectures.","Furthermore, it has negligible cost to performance, and allows for more continuous adjustment of guidance strength than other approaches.","We show FGD offers a fast and strong baseline that is competitive with recent architecture-dependent approaches.","Furthermore, FGD can also be used as a simple add-on to enhance the structural guidance of other state-of-the-art I2I methods.","Finally, our derivation of this method helps to understand the impact of self attention, a key component of other recent architecture-specific I2I approaches, in a more architecture-independent way.","Project page: https://github.com/jaclyngu/FilteredGuidedDiffusion"],"url":"http://arxiv.org/abs/2306.17141v1"}
{"created":"2023-06-29 17:41:41","title":"ID-Pose: Sparse-view Camera Pose Estimation by Inverting Diffusion Models","abstract":"Given sparse views of an object, estimating their camera poses is a long-standing and intractable problem. We harness the pre-trained diffusion model of novel views conditioned on viewpoints (Zero-1-to-3). We present ID-Pose which inverses the denoising diffusion process to estimate the relative pose given two input images. ID-Pose adds a noise on one image, and predicts the noise conditioned on the other image and a decision variable for the pose. The prediction error is used as the objective to find the optimal pose with the gradient descent method. ID-Pose can handle more than two images and estimate each of the poses with multiple image pairs from triangular relationships. ID-Pose requires no training and generalizes to real-world images. We conduct experiments using high-quality real-scanned 3D objects, where ID-Pose significantly outperforms state-of-the-art methods.","sentences":["Given sparse views of an object, estimating their camera poses is a long-standing and intractable problem.","We harness the pre-trained diffusion model of novel views conditioned on viewpoints (Zero-1-to-3).","We present ID-Pose which inverses the denoising diffusion process to estimate the relative pose given two input images.","ID-Pose adds a noise on one image, and predicts the noise conditioned on the other image and a decision variable for the pose.","The prediction error is used as the objective to find the optimal pose with the gradient descent method.","ID-Pose can handle more than two images and estimate each of the poses with multiple image pairs from triangular relationships.","ID-Pose requires no training and generalizes to real-world images.","We conduct experiments using high-quality real-scanned 3D objects, where ID-Pose significantly outperforms state-of-the-art methods."],"url":"http://arxiv.org/abs/2306.17140v1"}
{"created":"2023-06-29 17:36:08","title":"ItyFuzz: Snapshot-Based Fuzzer for Smart Contract","abstract":"Smart contracts are critical financial instruments, and their security is of utmost importance. However, smart contract programs are difficult to fuzz due to the persistent blockchain state behind all transactions. Mutating sequences of transactions are complex and often lead to a suboptimal exploration for both input and program spaces. In this paper, we introduce a novel snapshot-based fuzzer ItyFuzz for testing smart contracts. In ItyFuzz, instead of storing sequences of transactions and mutating from them, we snapshot states and singleton transactions. To explore interesting states, ItyFuzz introduces a dataflow waypoint mechanism to identify states with more potential momentum. ItyFuzz also incorporates comparison waypoints to prune the space of states. By maintaining snapshots of the states, ItyFuzz can synthesize concrete exploits like reentrancy attacks quickly. Because ItyFuzz has second-level response time to test a smart contract, it can be used for on-chain testing, which has many benefits compared to local development testing. Finally, we evaluate ItyFuzz on real-world smart contracts and some hacked on-chain DeFi projects. ItyFuzz outperforms existing fuzzers in terms of instructional coverage and can find and generate realistic exploits for on-chain projects quickly.","sentences":["Smart contracts are critical financial instruments, and their security is of utmost importance.","However, smart contract programs are difficult to fuzz due to the persistent blockchain state behind all transactions.","Mutating sequences of transactions are complex and often lead to a suboptimal exploration for both input and program spaces.","In this paper, we introduce a novel snapshot-based fuzzer ItyFuzz for testing smart contracts.","In ItyFuzz, instead of storing sequences of transactions and mutating from them, we snapshot states and singleton transactions.","To explore interesting states, ItyFuzz introduces a dataflow waypoint mechanism to identify states with more potential momentum.","ItyFuzz also incorporates comparison waypoints to prune the space of states.","By maintaining snapshots of the states, ItyFuzz can synthesize concrete exploits like reentrancy attacks quickly.","Because ItyFuzz has second-level response time to test a smart contract, it can be used for on-chain testing, which has many benefits compared to local development testing.","Finally, we evaluate ItyFuzz on real-world smart contracts and some hacked on-chain DeFi projects.","ItyFuzz outperforms existing fuzzers in terms of instructional coverage and can find and generate realistic exploits for on-chain projects quickly."],"url":"http://arxiv.org/abs/2306.17135v1"}
{"created":"2023-06-29 17:34:42","title":"Evaluation of AI-Supported Input Methods in Augmented Reality Environment","abstract":"Augmented Reality (AR) solutions are providing tools that could improve applications in the medical and industrial fields. Augmentation can provide additional information in training, visualization, and work scenarios, to increase efficiency, reliability, and safety, while improving communication with other devices and systems on the network. Unfortunately, tasks in these fields often require both hands to execute, reducing the variety of input methods suitable to control AR applications. People with certain physical disabilities, where they are not able to use their hands, are also negatively impacted when using these devices. The goal of this work is to provide novel hand-free interfacing methods, using AR technology, in association with AI support approaches to produce an improved Human-Computer interaction solution.","sentences":["Augmented Reality (AR) solutions are providing tools that could improve applications in the medical and industrial fields.","Augmentation can provide additional information in training, visualization, and work scenarios, to increase efficiency, reliability, and safety, while improving communication with other devices and systems on the network.","Unfortunately, tasks in these fields often require both hands to execute, reducing the variety of input methods suitable to control AR applications.","People with certain physical disabilities, where they are not able to use their hands, are also negatively impacted when using these devices.","The goal of this work is to provide novel hand-free interfacing methods, using AR technology, in association with AI support approaches to produce an improved Human-Computer interaction solution."],"url":"http://arxiv.org/abs/2306.17132v1"}
{"created":"2023-06-29 17:31:33","title":"Ducho: A Unified Framework for the Extraction of Multimodal Features in Recommendation","abstract":"In multimodal-aware recommendation, the extraction of meaningful multimodal features is at the basis of high-quality recommendations. Generally, each recommendation framework implements its multimodal extraction procedures with specific strategies and tools. This is limiting for two reasons: (i) different extraction strategies do not ease the interdependence among multimodal recommendation frameworks; thus, they cannot be efficiently and fairly compared; (ii) given the large plethora of pre-trained deep learning models made available by different open source tools, model designers do not have access to shared interfaces to extract features. Motivated by the outlined aspects, we propose Ducho, a unified framework for the extraction of multimodal features in recommendation. By integrating three widely-adopted deep learning libraries as backends, namely, TensorFlow, PyTorch, and Transformers, we provide a shared interface to extract and process features where each backend's specific methods are abstracted to the end user. Noteworthy, the extraction pipeline is easily configurable with a YAML-based file where the user can specify, for each modality, the list of models (and their specific backends/parameters) to perform the extraction. Finally, to make Ducho accessible to the community, we build a public Docker image equipped with a ready-to-use CUDA environment and propose three demos to test its functionalities for different scenarios and tasks. The GitHub repository and the documentation is accessible at this link: https://github.com/sisinflab/Ducho.","sentences":["In multimodal-aware recommendation, the extraction of meaningful multimodal features is at the basis of high-quality recommendations.","Generally, each recommendation framework implements its multimodal extraction procedures with specific strategies and tools.","This is limiting for two reasons: (i) different extraction strategies do not ease the interdependence among multimodal recommendation frameworks; thus, they cannot be efficiently and fairly compared; (ii) given the large plethora of pre-trained deep learning models made available by different open source tools, model designers do not have access to shared interfaces to extract features.","Motivated by the outlined aspects, we propose Ducho, a unified framework for the extraction of multimodal features in recommendation.","By integrating three widely-adopted deep learning libraries as backends, namely, TensorFlow, PyTorch, and Transformers, we provide a shared interface to extract and process features where each backend's specific methods are abstracted to the end user.","Noteworthy, the extraction pipeline is easily configurable with a YAML-based file where the user can specify, for each modality, the list of models (and their specific backends/parameters) to perform the extraction.","Finally, to make Ducho accessible to the community, we build a public Docker image equipped with a ready-to-use CUDA environment and propose three demos to test its functionalities for different scenarios and tasks.","The GitHub repository and the documentation is accessible at this link: https://github.com/sisinflab/Ducho."],"url":"http://arxiv.org/abs/2306.17125v1"}
{"created":"2023-06-29 17:26:51","title":"PVP: Personalized Video Prior for Editable Dynamic Portraits using StyleGAN","abstract":"Portrait synthesis creates realistic digital avatars which enable users to interact with others in a compelling way. Recent advances in StyleGAN and its extensions have shown promising results in synthesizing photorealistic and accurate reconstruction of human faces. However, previous methods often focus on frontal face synthesis and most methods are not able to handle large head rotations due to the training data distribution of StyleGAN. In this work, our goal is to take as input a monocular video of a face, and create an editable dynamic portrait able to handle extreme head poses. The user can create novel viewpoints, edit the appearance, and animate the face. Our method utilizes pivotal tuning inversion (PTI) to learn a personalized video prior from a monocular video sequence. Then we can input pose and expression coefficients to MLPs and manipulate the latent vectors to synthesize different viewpoints and expressions of the subject. We also propose novel loss functions to further disentangle pose and expression in the latent space. Our algorithm shows much better performance over previous approaches on monocular video datasets, and it is also capable of running in real-time at 54 FPS on an RTX 3080.","sentences":["Portrait synthesis creates realistic digital avatars which enable users to interact with others in a compelling way.","Recent advances in StyleGAN and its extensions have shown promising results in synthesizing photorealistic and accurate reconstruction of human faces.","However, previous methods often focus on frontal face synthesis and most methods are not able to handle large head rotations due to the training data distribution of StyleGAN.","In this work, our goal is to take as input a monocular video of a face, and create an editable dynamic portrait able to handle extreme head poses.","The user can create novel viewpoints, edit the appearance, and animate the face.","Our method utilizes pivotal tuning inversion (PTI) to learn a personalized video prior from a monocular video sequence.","Then we can input pose and expression coefficients to MLPs and manipulate the latent vectors to synthesize different viewpoints and expressions of the subject.","We also propose novel loss functions to further disentangle pose and expression in the latent space.","Our algorithm shows much better performance over previous approaches on monocular video datasets, and it is also capable of running in real-time at 54 FPS on an RTX 3080."],"url":"http://arxiv.org/abs/2306.17123v1"}
{"created":"2023-06-29 17:20:05","title":"Learning Nuclei Representations with Masked Image Modelling","abstract":"Masked image modelling (MIM) is a powerful self-supervised representation learning paradigm, whose potential has not been widely demonstrated in medical image analysis. In this work, we show the capacity of MIM to capture rich semantic representations of Haemotoxylin & Eosin (H&E)-stained images at the nuclear level. Inspired by Bidirectional Encoder representation from Image Transformers (BEiT), we split the images into smaller patches and generate corresponding discrete visual tokens. In addition to the regular grid-based patches, typically used in visual Transformers, we introduce patches of individual cell nuclei. We propose positional encoding of the irregular distribution of these structures within an image. We pre-train the model in a self-supervised manner on H&E-stained whole-slide images of diffuse large B-cell lymphoma, where cell nuclei have been segmented. The pre-training objective is to recover the original discrete visual tokens of the masked image on the one hand, and to reconstruct the visual tokens of the masked object instances on the other. Coupling these two pre-training tasks allows us to build powerful, context-aware representations of nuclei. Our model generalizes well and can be fine-tuned on downstream classification tasks, achieving improved cell classification accuracy on PanNuke dataset by more than 5% compared to current instance segmentation methods.","sentences":["Masked image modelling (MIM) is a powerful self-supervised representation learning paradigm, whose potential has not been widely demonstrated in medical image analysis.","In this work, we show the capacity of MIM to capture rich semantic representations of Haemotoxylin & Eosin (H&E)-stained images at the nuclear level.","Inspired by Bidirectional Encoder representation from Image Transformers (BEiT), we split the images into smaller patches and generate corresponding discrete visual tokens.","In addition to the regular grid-based patches, typically used in visual Transformers, we introduce patches of individual cell nuclei.","We propose positional encoding of the irregular distribution of these structures within an image.","We pre-train the model in a self-supervised manner on H&E-stained whole-slide images of diffuse large B-cell lymphoma, where cell nuclei have been segmented.","The pre-training objective is to recover the original discrete visual tokens of the masked image on the one hand, and to reconstruct the visual tokens of the masked object instances on the other.","Coupling these two pre-training tasks allows us to build powerful, context-aware representations of nuclei.","Our model generalizes well and can be fine-tuned on downstream classification tasks, achieving improved cell classification accuracy on PanNuke dataset by more than 5% compared to current instance segmentation methods."],"url":"http://arxiv.org/abs/2306.17116v1"}
{"created":"2023-06-29 17:17:57","title":"Michelangelo: Conditional 3D Shape Generation based on Shape-Image-Text Aligned Latent Representation","abstract":"We present a novel alignment-before-generation approach to tackle the challenging task of generating general 3D shapes based on 2D images or texts. Directly learning a conditional generative model from images or texts to 3D shapes is prone to producing inconsistent results with the conditions because 3D shapes have an additional dimension whose distribution significantly differs from that of 2D images and texts. To bridge the domain gap among the three modalities and facilitate multi-modal-conditioned 3D shape generation, we explore representing 3D shapes in a shape-image-text-aligned space. Our framework comprises two models: a Shape-Image-Text-Aligned Variational Auto-Encoder (SITA-VAE) and a conditional Aligned Shape Latent Diffusion Model (ASLDM). The former model encodes the 3D shapes into the shape latent space aligned to the image and text and reconstructs the fine-grained 3D neural fields corresponding to given shape embeddings via the transformer-based decoder. The latter model learns a probabilistic mapping function from the image or text space to the latent shape space. Our extensive experiments demonstrate that our proposed approach can generate higher-quality and more diverse 3D shapes that better semantically conform to the visual or textural conditional inputs, validating the effectiveness of the shape-image-text-aligned space for cross-modality 3D shape generation.","sentences":["We present a novel alignment-before-generation approach to tackle the challenging task of generating general 3D shapes based on 2D images or texts.","Directly learning a conditional generative model from images or texts to 3D shapes is prone to producing inconsistent results with the conditions because 3D shapes have an additional dimension whose distribution significantly differs from that of 2D images and texts.","To bridge the domain gap among the three modalities and facilitate multi-modal-conditioned 3D shape generation, we explore representing 3D shapes in a shape-image-text-aligned space.","Our framework comprises two models: a Shape-Image-Text-Aligned Variational Auto-Encoder (SITA-VAE) and a conditional Aligned Shape Latent Diffusion Model (ASLDM).","The former model encodes the 3D shapes into the shape latent space aligned to the image and text and reconstructs the fine-grained 3D neural fields corresponding to given shape embeddings via the transformer-based decoder.","The latter model learns a probabilistic mapping function from the image or text space to the latent shape space.","Our extensive experiments demonstrate that our proposed approach can generate higher-quality and more diverse 3D shapes that better semantically conform to the visual or textural conditional inputs, validating the effectiveness of the shape-image-text-aligned space for cross-modality 3D shape generation."],"url":"http://arxiv.org/abs/2306.17115v1"}
{"created":"2023-06-29 17:08:57","title":"Synthetic Demographic Data Generation for Card Fraud Detection Using GANs","abstract":"Using machine learning models to generate synthetic data has become common in many fields. Technology to generate synthetic transactions that can be used to detect fraud is also growing fast. Generally, this synthetic data contains only information about the transaction, such as the time, place, and amount of money. It does not usually contain the individual user's characteristics (age and gender are occasionally included). Using relatively complex synthetic demographic data may improve the complexity of transaction data features, thus improving the fraud detection performance. Benefiting from developments of machine learning, some deep learning models have potential to perform better than other well-established synthetic data generation methods, such as microsimulation. In this study, we built a deep-learning Generative Adversarial Network (GAN), called DGGAN, which will be used for demographic data generation. Our model generates samples during model training, which we found important to overcame class imbalance issues. This study can help improve the cognition of synthetic data and further explore the application of synthetic data generation in card fraud detection.","sentences":["Using machine learning models to generate synthetic data has become common in many fields.","Technology to generate synthetic transactions that can be used to detect fraud is also growing fast.","Generally, this synthetic data contains only information about the transaction, such as the time, place, and amount of money.","It does not usually contain the individual user's characteristics (age and gender are occasionally included).","Using relatively complex synthetic demographic data may improve the complexity of transaction data features, thus improving the fraud detection performance.","Benefiting from developments of machine learning, some deep learning models have potential to perform better than other well-established synthetic data generation methods, such as microsimulation.","In this study, we built a deep-learning Generative Adversarial Network (GAN), called DGGAN, which will be used for demographic data generation.","Our model generates samples during model training, which we found important to overcame class imbalance issues.","This study can help improve the cognition of synthetic data and further explore the application of synthetic data generation in card fraud detection."],"url":"http://arxiv.org/abs/2306.17109v1"}
{"created":"2023-06-29 17:08:53","title":"ManimML: Communicating Machine Learning Architectures with Animation","abstract":"There has been an explosion in interest in machine learning (ML) in recent years due to its applications to science and engineering. However, as ML techniques have advanced, tools for explaining and visualizing novel ML algorithms have lagged behind. Animation has been shown to be a powerful tool for making engaging visualizations of systems that dynamically change over time, which makes it well suited to the task of communicating ML algorithms. However, the current approach to animating ML algorithms is to handcraft applications that highlight specific algorithms or use complex generalized animation software. We developed ManimML, an open-source Python library for easily generating animations of ML algorithms directly from code. We sought to leverage ML practitioners' preexisting knowledge of programming rather than requiring them to learn complex animation software. ManimML has a familiar syntax for specifying neural networks that mimics popular deep learning frameworks like Pytorch. A user can take a preexisting neural network architecture and easily write a specification for an animation in ManimML, which will then automatically compose animations for different components of the system into a final animation of the entire neural network. ManimML is open source and available at https://github.com/helblazer811/ManimML.","sentences":["There has been an explosion in interest in machine learning (ML) in recent years due to its applications to science and engineering.","However, as ML techniques have advanced, tools for explaining and visualizing novel ML algorithms have lagged behind.","Animation has been shown to be a powerful tool for making engaging visualizations of systems that dynamically change over time, which makes it well suited to the task of communicating ML algorithms.","However, the current approach to animating ML algorithms is to handcraft applications that highlight specific algorithms or use complex generalized animation software.","We developed ManimML, an open-source Python library for easily generating animations of ML algorithms directly from code.","We sought to leverage ML practitioners' preexisting knowledge of programming rather than requiring them to learn complex animation software.","ManimML has a familiar syntax for specifying neural networks that mimics popular deep learning frameworks like Pytorch.","A user can take a preexisting neural network architecture and easily write a specification for an animation in ManimML, which will then automatically compose animations for different components of the system into a final animation of the entire neural network.","ManimML is open source and available at https://github.com/helblazer811/ManimML."],"url":"http://arxiv.org/abs/2306.17108v1"}
{"created":"2023-06-29 17:08:16","title":"LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding","abstract":"Instruction tuning unlocks the superior capability of Large Language Models (LLM) to interact with humans. Furthermore, recent instruction-following datasets include images as visual inputs, collecting responses for image-based instructions. However, visual instruction-tuned models cannot comprehend textual details within images well. This work enhances the current visual instruction tuning pipeline with text-rich images (e.g., movie posters, book covers, etc.). Specifically, we first use publicly available OCR tools to collect results on 422K text-rich images from the LAION dataset. Moreover, we prompt text-only GPT-4 with recognized texts and image captions to generate 16K conversations, each containing question-answer pairs for text-rich images. By combining our collected data with previous multi-modal instruction-following data, our model, LLaVAR, substantially improves the LLaVA model's capability on text-based VQA datasets (up to 20% accuracy improvement) while achieving an accuracy of 91.42% on ScienceQA. The GPT-4-based instruction-following evaluation also demonstrates the improvement of our model on both natural images and text-rich images. Through qualitative analysis, LLaVAR shows promising interaction (e.g., reasoning, writing, and elaboration) skills with humans based on the latest real-world online content that combines text and images. We make our code/data/models publicly available at https://llavar.github.io/.","sentences":["Instruction tuning unlocks the superior capability of Large Language Models (LLM) to interact with humans.","Furthermore, recent instruction-following datasets include images as visual inputs, collecting responses for image-based instructions.","However, visual instruction-tuned models cannot comprehend textual details within images well.","This work enhances the current visual instruction tuning pipeline with text-rich images (e.g., movie posters, book covers, etc.).","Specifically, we first use publicly available OCR tools to collect results on 422K text-rich images from the LAION dataset.","Moreover, we prompt text-only GPT-4 with recognized texts and image captions to generate 16K conversations, each containing question-answer pairs for text-rich images.","By combining our collected data with previous multi-modal instruction-following data, our model, LLaVAR, substantially improves the LLaVA model's capability on text-based VQA datasets (up to 20% accuracy improvement) while achieving an accuracy of 91.42% on ScienceQA.","The GPT-4-based instruction-following evaluation also demonstrates the improvement of our model on both natural images and text-rich images.","Through qualitative analysis, LLaVAR shows promising interaction (e.g., reasoning, writing, and elaboration) skills with humans based on the latest real-world online content that combines text and images.","We make our code/data/models publicly available at https://llavar.github.io/."],"url":"http://arxiv.org/abs/2306.17107v1"}
{"created":"2023-06-29 17:07:34","title":"Are Neurons Actually Collapsed? On the Fine-Grained Structure in Neural Representations","abstract":"Recent work has observed an intriguing ''Neural Collapse'' phenomenon in well-trained neural networks, where the last-layer representations of training samples with the same label collapse into each other. This appears to suggest that the last-layer representations are completely determined by the labels, and do not depend on the intrinsic structure of input distribution. We provide evidence that this is not a complete description, and that the apparent collapse hides important fine-grained structure in the representations. Specifically, even when representations apparently collapse, the small amount of remaining variation can still faithfully and accurately captures the intrinsic structure of input distribution. As an example, if we train on CIFAR-10 using only 5 coarse-grained labels (by combining two classes into one super-class) until convergence, we can reconstruct the original 10-class labels from the learned representations via unsupervised clustering. The reconstructed labels achieve $93\\%$ accuracy on the CIFAR-10 test set, nearly matching the normal CIFAR-10 accuracy for the same architecture. We also provide an initial theoretical result showing the fine-grained representation structure in a simplified synthetic setting. Our results show concretely how the structure of input data can play a significant role in determining the fine-grained structure of neural representations, going beyond what Neural Collapse predicts.","sentences":["Recent work has observed an intriguing ''Neural Collapse'' phenomenon in well-trained neural networks, where the last-layer representations of training samples with the same label collapse into each other.","This appears to suggest that the last-layer representations are completely determined by the labels, and do not depend on the intrinsic structure of input distribution.","We provide evidence that this is not a complete description, and that the apparent collapse hides important fine-grained structure in the representations.","Specifically, even when representations apparently collapse, the small amount of remaining variation can still faithfully and accurately captures the intrinsic structure of input distribution.","As an example, if we train on CIFAR-10 using only 5 coarse-grained labels (by combining two classes into one super-class) until convergence, we can reconstruct the original 10-class labels from the learned representations via unsupervised clustering.","The reconstructed labels achieve $93\\%$ accuracy on the CIFAR-10 test set, nearly matching the normal CIFAR-10 accuracy for the same architecture.","We also provide an initial theoretical result showing the fine-grained representation structure in a simplified synthetic setting.","Our results show concretely how the structure of input data can play a significant role in determining the fine-grained structure of neural representations, going beyond what Neural Collapse predicts."],"url":"http://arxiv.org/abs/2306.17105v1"}
{"created":"2023-06-29 17:06:42","title":"Deep Ensemble for Rotorcraft Attitude Prediction","abstract":"Historically, the rotorcraft community has experienced a higher fatal accident rate than other aviation segments, including commercial and general aviation. Recent advancements in artificial intelligence (AI) and the application of these technologies in different areas of our lives are both intriguing and encouraging. When developed appropriately for the aviation domain, AI techniques provide an opportunity to help design systems that can address rotorcraft safety challenges. Our recent work demonstrated that AI algorithms could use video data from onboard cameras and correctly identify different flight parameters from cockpit gauges, e.g., indicated airspeed. These AI-based techniques provide a potentially cost-effective solution, especially for small helicopter operators, to record the flight state information and perform post-flight analyses. We also showed that carefully designed and trained AI systems could accurately predict rotorcraft attitude (i.e., pitch and yaw) from outside scenes (images or video data). Ordinary off-the-shelf video cameras were installed inside the rotorcraft cockpit to record the outside scene, including the horizon. The AI algorithm could correctly identify rotorcraft attitude at an accuracy in the range of 80\\%. In this work, we combined five different onboard camera viewpoints to improve attitude prediction accuracy to 94\\%. In this paper, five onboard camera views included the pilot windshield, co-pilot windshield, pilot Electronic Flight Instrument System (EFIS) display, co-pilot EFIS display, and the attitude indicator gauge. Using video data from each camera view, we trained various convolutional neural networks (CNNs), which achieved prediction accuracy in the range of 79\\% % to 90\\% %. We subsequently ensembled the learned knowledge from all CNNs and achieved an ensembled accuracy of 93.3\\%.","sentences":["Historically, the rotorcraft community has experienced a higher fatal accident rate than other aviation segments, including commercial and general aviation.","Recent advancements in artificial intelligence (AI) and the application of these technologies in different areas of our lives are both intriguing and encouraging.","When developed appropriately for the aviation domain, AI techniques provide an opportunity to help design systems that can address rotorcraft safety challenges.","Our recent work demonstrated that AI algorithms could use video data from onboard cameras and correctly identify different flight parameters from cockpit gauges, e.g., indicated airspeed.","These AI-based techniques provide a potentially cost-effective solution, especially for small helicopter operators, to record the flight state information and perform post-flight analyses.","We also showed that carefully designed and trained AI systems could accurately predict rotorcraft attitude (i.e., pitch and yaw) from outside scenes (images or video data).","Ordinary off-the-shelf video cameras were installed inside the rotorcraft cockpit to record the outside scene, including the horizon.","The AI algorithm could correctly identify rotorcraft attitude at an accuracy in the range of 80\\%.","In this work, we combined five different onboard camera viewpoints to improve attitude prediction accuracy to 94\\%.","In this paper, five onboard camera views included the pilot windshield, co-pilot windshield, pilot Electronic Flight Instrument System (EFIS) display, co-pilot EFIS display, and the attitude indicator gauge.","Using video data from each camera view, we trained various convolutional neural networks (CNNs), which achieved prediction accuracy in the range of 79\\% % to 90\\% %.","We subsequently ensembled the learned knowledge from all CNNs and achieved an ensembled accuracy of 93.3\\%."],"url":"http://arxiv.org/abs/2306.17104v1"}
{"created":"2023-06-29 17:01:51","title":"LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT","abstract":"We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic lyrics transcription method achieving state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal. Our novel, training-free approach utilizes Whisper, a weakly supervised robust speech recognition model, and GPT-4, today's most performant chat-based large language model. In the proposed method, Whisper functions as the \"ear\" by transcribing the audio, while GPT-4 serves as the \"brain,\" acting as an annotator with a strong performance for contextualized output selection and correction. Our experiments show that LyricWhiz significantly reduces Word Error Rate compared to existing methods in English and can effectively transcribe lyrics across multiple languages. Furthermore, we use LyricWhiz to create the first publicly available, large-scale, multilingual lyrics transcription dataset with a CC-BY-NC-SA copyright license, based on MTG-Jamendo, and offer a human-annotated subset for noise level estimation and evaluation. We anticipate that our proposed method and dataset will advance the development of multilingual lyrics transcription, a challenging and emerging task.","sentences":["We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic lyrics transcription method achieving state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal.","Our novel, training-free approach utilizes Whisper, a weakly supervised robust speech recognition model, and GPT-4, today's most performant chat-based large language model.","In the proposed method, Whisper functions as the \"ear\" by transcribing the audio, while GPT-4 serves as the \"brain,\" acting as an annotator with a strong performance for contextualized output selection and correction.","Our experiments show that LyricWhiz significantly reduces Word Error Rate compared to existing methods in English and can effectively transcribe lyrics across multiple languages.","Furthermore, we use LyricWhiz to create the first publicly available, large-scale, multilingual lyrics transcription dataset with a CC-BY-NC-SA copyright license, based on MTG-Jamendo, and offer a human-annotated subset for noise level estimation and evaluation.","We anticipate that our proposed method and dataset will advance the development of multilingual lyrics transcription, a challenging and emerging task."],"url":"http://arxiv.org/abs/2306.17103v1"}
{"created":"2023-06-29 16:58:08","title":"Identifying Important Sensory Feedback for Learning Locomotion Skills","abstract":"Robot motor skills can be learned through deep reinforcement learning (DRL) by neural networks as state-action mappings. While the selection of state observations is crucial, there has been a lack of quantitative analysis to date. Here, we present a systematic saliency analysis that quantitatively evaluates the relative importance of different feedback states for motor skills learned through DRL. Our approach can identify the most essential feedback states for locomotion skills, including balance recovery, trotting, bounding, pacing and galloping. By using only key states including joint positions, gravity vector, base linear and angular velocities, we demonstrate that a simulated quadruped robot can achieve robust performance in various test scenarios across these distinct skills. The benchmarks using task performance metrics show that locomotion skills learned with key states can achieve comparable performance to those with all states, and the task performance or learning success rate will drop significantly if key states are missing. This work provides quantitative insights into the relationship between state observations and specific types of motor skills, serving as a guideline for robot motor learning. The proposed method is applicable to differentiable state-action mapping, such as neural network based control policies, enabling the learning of a wide range of motor skills with minimal sensing dependencies.","sentences":["Robot motor skills can be learned through deep reinforcement learning (DRL) by neural networks as state-action mappings.","While the selection of state observations is crucial, there has been a lack of quantitative analysis to date.","Here, we present a systematic saliency analysis that quantitatively evaluates the relative importance of different feedback states for motor skills learned through DRL.","Our approach can identify the most essential feedback states for locomotion skills, including balance recovery, trotting, bounding, pacing and galloping.","By using only key states including joint positions, gravity vector, base linear and angular velocities, we demonstrate that a simulated quadruped robot can achieve robust performance in various test scenarios across these distinct skills.","The benchmarks using task performance metrics show that locomotion skills learned with key states can achieve comparable performance to those with all states, and the task performance or learning success rate will drop significantly if key states are missing.","This work provides quantitative insights into the relationship between state observations and specific types of motor skills, serving as a guideline for robot motor learning.","The proposed method is applicable to differentiable state-action mapping, such as neural network based control policies, enabling the learning of a wide range of motor skills with minimal sensing dependencies."],"url":"http://arxiv.org/abs/2306.17101v1"}
{"created":"2023-06-29 16:57:22","title":"RL4CO: an Extensive Reinforcement Learning for Combinatorial Optimization Benchmark","abstract":"We introduce RL4CO, an extensive reinforcement learning (RL) for combinatorial optimization (CO) benchmark. RL4CO employs state-of-the-art software libraries as well as best practices in implementation, such as modularity and configuration management, to be efficient and easily modifiable by researchers for adaptations of neural network architecture, environments, and algorithms. Contrary to the existing focus on specific tasks like the traveling salesman problem (TSP) for performance assessment, we underline the importance of scalability and generalization capabilities for diverse optimization tasks. We also systematically benchmark sample efficiency, zero-shot generalization, and adaptability to changes in data distributions of various models. Our experiments show that some recent state-of-the-art methods fall behind their predecessors when evaluated using these new metrics, suggesting the necessity for a more balanced view of the performance of neural CO solvers. We hope RL4CO will encourage the exploration of novel solutions to complex real-world tasks, allowing to compare with existing methods through a standardized interface that decouples the science from the software engineering. We make our library publicly available at https://github.com/kaist-silab/rl4co.","sentences":["We introduce RL4CO, an extensive reinforcement learning (RL) for combinatorial optimization (CO) benchmark.","RL4CO employs state-of-the-art software libraries as well as best practices in implementation, such as modularity and configuration management, to be efficient and easily modifiable by researchers for adaptations of neural network architecture, environments, and algorithms.","Contrary to the existing focus on specific tasks like the traveling salesman problem (TSP) for performance assessment, we underline the importance of scalability and generalization capabilities for diverse optimization tasks.","We also systematically benchmark sample efficiency, zero-shot generalization, and adaptability to changes in data distributions of various models.","Our experiments show that some recent state-of-the-art methods fall behind their predecessors when evaluated using these new metrics, suggesting the necessity for a more balanced view of the performance of neural CO solvers.","We hope RL4CO will encourage the exploration of novel solutions to complex real-world tasks, allowing to compare with existing methods through a standardized interface that decouples the science from the software engineering.","We make our library publicly available at https://github.com/kaist-silab/rl4co."],"url":"http://arxiv.org/abs/2306.17100v1"}
{"created":"2023-06-29 16:57:19","title":"When Bidders Are DAOs","abstract":"In a typical decentralized autonomous organization (DAO), people organize themselves into a group that is programmatically managed. DAOs can act as bidders in auctions, with a DAO's bid treated by the auctioneer as if it had been submitted by an individual, without regard to the internal structure of the DAO. We study auctions in which the bidders are DAOs. More precisely, we consider the design of two-level auctions in which the \"participants\" are groups of bidders rather than individuals. Bidders form DAOs to pool resources, but must then also negotiate the terms by which the DAO's winnings are shared. We model the outcome of a DAO's negotiations by an aggregation function (which aggregates DAO members' bids into a single group bid), and a budget-balanced cost-sharing mechanism (that determines DAO members' access to the DAO's allocation and distributes the total payment demanded from the DAO to its members). We pursue two-level mechanisms that are incentive-compatible (with truthful bidding a dominant strategy for members of each DAO) and approximately welfare-optimal. We prove that, even in the case of a single-item auction, incentive-compatible welfare maximization is not possible: No matter what the outer mechanism and the cost-sharing mechanisms used by DAOs, the welfare of the resulting two-level mechanism can be a $\\approx \\ln n$ factor less than optimal. We complement this lower bound with a natural two-level mechanism that achieves a matching approximate welfare guarantee. Our upper bound also extends to multi-item auctions where individuals have additive valuations. Finally, we show that our positive results cannot be extended much further: Even in multi-item settings with unit-demand bidders, truthful two-level mechanisms form a highly restricted class and as a consequence cannot guarantee any non-trivial approximation of the maximum social welfare.","sentences":["In a typical decentralized autonomous organization (DAO), people organize themselves into a group that is programmatically managed.","DAOs can act as bidders in auctions, with a DAO's bid treated by the auctioneer as if it had been submitted by an individual, without regard to the internal structure of the DAO.","We study auctions in which the bidders are DAOs.","More precisely, we consider the design of two-level auctions in which the \"participants\" are groups of bidders rather than individuals.","Bidders form DAOs to pool resources, but must then also negotiate the terms by which the DAO's winnings are shared.","We model the outcome of a DAO's negotiations by an aggregation function (which aggregates DAO members' bids into a single group bid), and a budget-balanced cost-sharing mechanism (that determines DAO members' access to the DAO's allocation and distributes the total payment demanded from the DAO to its members).","We pursue two-level mechanisms that are incentive-compatible (with truthful bidding a dominant strategy for members of each DAO) and approximately welfare-optimal.","We prove that, even in the case of a single-item auction, incentive-compatible welfare maximization is not possible: No matter what the outer mechanism and the cost-sharing mechanisms used by DAOs, the welfare of the resulting two-level mechanism can be a $\\approx \\ln n$ factor less than optimal.","We complement this lower bound with a natural two-level mechanism that achieves a matching approximate welfare guarantee.","Our upper bound also extends to multi-item auctions where individuals have additive valuations.","Finally, we show that our positive results cannot be extended much further: Even in multi-item settings with unit-demand bidders, truthful two-level mechanisms form a highly restricted class and as a consequence cannot guarantee any non-trivial approximation of the maximum social welfare."],"url":"http://arxiv.org/abs/2306.17099v1"}
{"created":"2023-06-29 16:55:36","title":"Oriented Spanners","abstract":"Given a point set $P$ in the Euclidean plane and a parameter $t$, we define an \\emph{oriented $t$-spanner} as an oriented subgraph of the complete bi-directed graph such that for every pair of points, the shortest cycle in $G$ through those points is at most a factor $t$ longer than the shortest oriented cycle in the complete bi-directed graph. We investigate the problem of computing sparse graphs with small oriented dilation.   As we can show that minimising oriented dilation for a given number of edges is NP-hard in the plane, we first consider one-dimensional point sets. While obtaining a $1$-spanner in this setting is straightforward, already for five points such a spanner has no plane embedding with the leftmost and rightmost point on the outer face.   This leads to restricting to oriented graphs with a one-page book embedding on the one-dimensional point set. For this case we present a dynamic program to compute the graph of minimum oriented dilation that runs in $O(n^8)$ time for $n$ points, and a greedy algorithm that computes a $5$-spanner in $O(n\\log n)$ time.   Expanding these results finally gives us a result for two-dimensional point sets: we prove that for convex point sets the greedy triangulation results in an oriented $O(1)$-spanner.","sentences":["Given a point set $P$ in the Euclidean plane and a parameter $t$, we define an \\emph{oriented $t$-spanner} as an oriented subgraph of the complete bi-directed graph such that for every pair of points, the shortest cycle in $G$ through those points is at most a factor $t$ longer than the shortest oriented cycle in the complete bi-directed graph.","We investigate the problem of computing sparse graphs with small oriented dilation.   ","As we can show that minimising oriented dilation for a given number of edges is NP-hard in the plane, we first consider one-dimensional point sets.","While obtaining a $1$-spanner in this setting is straightforward, already for five points such a spanner has no plane embedding with the leftmost and rightmost point on the outer face.   ","This leads to restricting to oriented graphs with a one-page book embedding on the one-dimensional point set.","For this case we present a dynamic program to compute the graph of minimum oriented dilation that runs in $O(n^8)$ time for $n$ points, and a greedy algorithm that computes a $5$-spanner in $O(n\\log n)$ time.   ","Expanding these results finally gives us a result for two-dimensional point sets: we prove that for convex point sets the greedy triangulation results in an oriented $O(1)$-spanner."],"url":"http://arxiv.org/abs/2306.17097v1"}
{"created":"2023-06-29 16:48:15","title":"The Importance of Robust Features in Mitigating Catastrophic Forgetting","abstract":"Continual learning (CL) is an approach to address catastrophic forgetting, which refers to forgetting previously learned knowledge by neural networks when trained on new tasks or data distributions. The adversarial robustness has decomposed features into robust and non-robust types and demonstrated that models trained on robust features significantly enhance adversarial robustness. However, no study has been conducted on the efficacy of robust features from the lens of the CL model in mitigating catastrophic forgetting in CL. In this paper, we introduce the CL robust dataset and train four baseline models on both the standard and CL robust datasets. Our results demonstrate that the CL models trained on the CL robust dataset experienced less catastrophic forgetting of the previously learned tasks than when trained on the standard dataset. Our observations highlight the significance of the features provided to the underlying CL models, showing that CL robust features can alleviate catastrophic forgetting.","sentences":["Continual learning (CL) is an approach to address catastrophic forgetting, which refers to forgetting previously learned knowledge by neural networks when trained on new tasks or data distributions.","The adversarial robustness has decomposed features into robust and non-robust types and demonstrated that models trained on robust features significantly enhance adversarial robustness.","However, no study has been conducted on the efficacy of robust features from the lens of the CL model in mitigating catastrophic forgetting in CL.","In this paper, we introduce the CL robust dataset and train four baseline models on both the standard and CL robust datasets.","Our results demonstrate that the CL models trained on the CL robust dataset experienced less catastrophic forgetting of the previously learned tasks than when trained on the standard dataset.","Our observations highlight the significance of the features provided to the underlying CL models, showing that CL robust features can alleviate catastrophic forgetting."],"url":"http://arxiv.org/abs/2306.17091v1"}
{"created":"2023-06-29 16:48:00","title":"Sparsity exploitation via discovering graphical models in multi-variate time-series forecasting","abstract":"Graph neural networks (GNNs) have been widely applied in multi-variate time-series forecasting (MTSF) tasks because of their capability in capturing the correlations among different time-series. These graph-based learning approaches improve the forecasting performance by discovering and understanding the underlying graph structures, which represent the data correlation. When the explicit prior graph structures are not available, most existing works cannot guarantee the sparsity of the generated graphs that make the overall model computational expensive and less interpretable. In this work, we propose a decoupled training method, which includes a graph generating module and a GNNs forecasting module. First, we use Graphical Lasso (or GraphLASSO) to directly exploit the sparsity pattern from data to build graph structures in both static and time-varying cases. Second, we fit these graph structures and the input data into a Graph Convolutional Recurrent Network (GCRN) to train a forecasting model. The experimental results on three real-world datasets show that our novel approach has competitive performance against existing state-of-the-art forecasting algorithms while providing sparse, meaningful and explainable graph structures and reducing training time by approximately 40%. Our PyTorch implementation is publicly available at https://github.com/HySonLab/GraphLASSO","sentences":["Graph neural networks (GNNs) have been widely applied in multi-variate time-series forecasting (MTSF) tasks because of their capability in capturing the correlations among different time-series.","These graph-based learning approaches improve the forecasting performance by discovering and understanding the underlying graph structures, which represent the data correlation.","When the explicit prior graph structures are not available, most existing works cannot guarantee the sparsity of the generated graphs that make the overall model computational expensive and less interpretable.","In this work, we propose a decoupled training method, which includes a graph generating module and a GNNs forecasting module.","First, we use Graphical Lasso (or GraphLASSO) to directly exploit the sparsity pattern from data to build graph structures in both static and time-varying cases.","Second, we fit these graph structures and the input data into a Graph Convolutional Recurrent Network (GCRN) to train a forecasting model.","The experimental results on three real-world datasets show that our novel approach has competitive performance against existing state-of-the-art forecasting algorithms while providing sparse, meaningful and explainable graph structures and reducing training time by approximately 40%.","Our PyTorch implementation is publicly available at https://github.com/HySonLab/GraphLASSO"],"url":"http://arxiv.org/abs/2306.17090v1"}
{"created":"2023-06-29 16:47:11","title":"Concept-Oriented Deep Learning with Large Language Models","abstract":"Large Language Models (LLMs) have been successfully used in many natural-language tasks and applications including text generation and AI chatbots. They also are a promising new technology for concept-oriented deep learning (CODL). However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency. We discuss these in this paper, as well as major uses of LLMs for CODL including concept extraction from text, concept graph extraction from text, and concept learning. Human knowledge consists of both symbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only LLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge. We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including concept extraction from image, concept graph extraction from image, and concept learning. While uses of LLMs for CODL are valuable standalone, they are particularly valuable as part of LLM applications such as AI chatbots.","sentences":["Large Language Models (LLMs) have been successfully used in many natural-language tasks and applications including text generation and AI chatbots.","They also are a promising new technology for concept-oriented deep learning (CODL).","However, the prerequisite is that LLMs understand concepts and ensure conceptual consistency.","We discuss these in this paper, as well as major uses of LLMs for CODL including concept extraction from text, concept graph extraction from text, and concept learning.","Human knowledge consists of both symbolic (conceptual) knowledge and embodied (sensory) knowledge.","Text-only LLMs, however, can represent only symbolic (conceptual) knowledge.","Multimodal LLMs, on the other hand, are capable of representing the full range (conceptual and sensory) of human knowledge.","We discuss conceptual understanding in visual-language LLMs, the most important multimodal LLMs, and major uses of them for CODL including concept extraction from image, concept graph extraction from image, and concept learning.","While uses of LLMs for CODL are valuable standalone, they are particularly valuable as part of LLM applications such as AI chatbots."],"url":"http://arxiv.org/abs/2306.17089v1"}
{"created":"2023-06-29 16:36:05","title":"Re-Rank - Expand - Repeat: Adaptive Query Expansion for Document Retrieval Using Words and Entities","abstract":"Sparse and dense pseudo-relevance feedback (PRF) approaches perform poorly on challenging queries due to low precision in first-pass retrieval. However, recent advances in neural language models (NLMs) can re-rank relevant documents to top ranks, even when few are in the re-ranking pool. This paper first addresses the problem of poor pseudo-relevance feedback by simply applying re-ranking prior to query expansion and re-executing this query. We find that this change alone can improve the retrieval effectiveness of sparse and dense PRF approaches by 5-8%. Going further, we propose a new expansion model, Latent Entity Expansion (LEE), a fine-grained word and entity-based relevance modelling incorporating localized features. Finally, we include an \"adaptive\" component to the retrieval process, which iteratively refines the re-ranking pool during scoring using the expansion model, i.e. we \"re-rank - expand - repeat\". Using LEE, we achieve (to our knowledge) the best NDCG, MAP and R@1000 results on the TREC Robust 2004 and CODEC adhoc document datasets, demonstrating a significant advancement in expansion effectiveness.","sentences":["Sparse and dense pseudo-relevance feedback (PRF) approaches perform poorly on challenging queries due to low precision in first-pass retrieval.","However, recent advances in neural language models (NLMs) can re-rank relevant documents to top ranks, even when few are in the re-ranking pool.","This paper first addresses the problem of poor pseudo-relevance feedback by simply applying re-ranking prior to query expansion and re-executing this query.","We find that this change alone can improve the retrieval effectiveness of sparse and dense PRF approaches by 5-8%.","Going further, we propose a new expansion model, Latent Entity Expansion (LEE), a fine-grained word and entity-based relevance modelling incorporating localized features.","Finally, we include an \"adaptive\" component to the retrieval process, which iteratively refines the re-ranking pool during scoring using the expansion model, i.e. we \"re-rank - expand - repeat\".","Using LEE, we achieve (to our knowledge) the best NDCG, MAP and R@1000 results on the TREC Robust 2004 and CODEC adhoc document datasets, demonstrating a significant advancement in expansion effectiveness."],"url":"http://arxiv.org/abs/2306.17082v1"}
{"created":"2023-06-29 16:28:34","title":"RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot","abstract":"Performance bugs are non-functional bugs that can even manifest in well-tested commercial products. Fixing these performance bugs is an important yet challenging problem. In this work, we address this challenge and present a new approach called Retrieval-Augmented Prompt Generation (RAPGen). Given a code snippet with a performance issue, RAPGen first retrieves a prompt instruction from a pre-constructed knowledge-base of previous performance bug fixes and then generates a prompt using the retrieved instruction. It then uses this prompt on a Large Language Model (such as Codex) in zero-shot to generate a fix. We compare our approach with the various prompt variations and state of the art methods in the task of performance bug fixing. Our evaluation shows that RAPGen can generate performance improvement suggestions equivalent or better than a developer in ~60% of the cases, getting ~39% of them verbatim, in an expert-verified dataset of past performance changes made by C# developers.","sentences":["Performance bugs are non-functional bugs that can even manifest in well-tested commercial products.","Fixing these performance bugs is an important yet challenging problem.","In this work, we address this challenge and present a new approach called Retrieval-Augmented Prompt Generation (RAPGen).","Given a code snippet with a performance issue, RAPGen first retrieves a prompt instruction from a pre-constructed knowledge-base of previous performance bug fixes and then generates a prompt using the retrieved instruction.","It then uses this prompt on a Large Language Model (such as Codex) in zero-shot to generate a fix.","We compare our approach with the various prompt variations and state of the art methods in the task of performance bug fixing.","Our evaluation shows that RAPGen can generate performance improvement suggestions equivalent or better than a developer in ~60% of the cases, getting ~39% of them verbatim, in an expert-verified dataset of past performance changes made by C# developers."],"url":"http://arxiv.org/abs/2306.17077v1"}
{"created":"2023-06-29 16:25:04","title":"Detect Any Deepfakes: Segment Anything Meets Face Forgery Detection and Localization","abstract":"The rapid advancements in computer vision have stimulated remarkable progress in face forgery techniques, capturing the dedicated attention of researchers committed to detecting forgeries and precisely localizing manipulated areas. Nonetheless, with limited fine-grained pixel-wise supervision labels, deepfake detection models perform unsatisfactorily on precise forgery detection and localization. To address this challenge, we introduce the well-trained vision segmentation foundation model, i.e., Segment Anything Model (SAM) in face forgery detection and localization. Based on SAM, we propose the Detect Any Deepfakes (DADF) framework with the Multiscale Adapter, which can capture short- and long-range forgery contexts for efficient fine-tuning. Moreover, to better identify forged traces and augment the model's sensitivity towards forgery regions, Reconstruction Guided Attention (RGA) module is proposed. The proposed framework seamlessly integrates end-to-end forgery localization and detection optimization. Extensive experiments on three benchmark datasets demonstrate the superiority of our approach for both forgery detection and localization. The codes will be released soon at https://github.com/laiyingxin2/DADF.","sentences":["The rapid advancements in computer vision have stimulated remarkable progress in face forgery techniques, capturing the dedicated attention of researchers committed to detecting forgeries and precisely localizing manipulated areas.","Nonetheless, with limited fine-grained pixel-wise supervision labels, deepfake detection models perform unsatisfactorily on precise forgery detection and localization.","To address this challenge, we introduce the well-trained vision segmentation foundation model, i.e., Segment Anything Model (SAM) in face forgery detection and localization.","Based on SAM, we propose the Detect Any Deepfakes (DADF) framework with the Multiscale Adapter, which can capture short- and long-range forgery contexts for efficient fine-tuning.","Moreover, to better identify forged traces and augment the model's sensitivity towards forgery regions, Reconstruction Guided Attention (RGA) module is proposed.","The proposed framework seamlessly integrates end-to-end forgery localization and detection optimization.","Extensive experiments on three benchmark datasets demonstrate the superiority of our approach for both forgery detection and localization.","The codes will be released soon at https://github.com/laiyingxin2/DADF."],"url":"http://arxiv.org/abs/2306.17075v1"}
{"created":"2023-06-29 16:24:32","title":"Learning Structure-Guided Diffusion Model for 2D Human Pose Estimation","abstract":"One of the mainstream schemes for 2D human pose estimation (HPE) is learning keypoints heatmaps by a neural network. Existing methods typically improve the quality of heatmaps by customized architectures, such as high-resolution representation and vision Transformers. In this paper, we propose \\textbf{DiffusionPose}, a new scheme that formulates 2D HPE as a keypoints heatmaps generation problem from noised heatmaps. During training, the keypoints are diffused to random distribution by adding noises and the diffusion model learns to recover ground-truth heatmaps from noised heatmaps with respect to conditions constructed by image feature. During inference, the diffusion model generates heatmaps from initialized heatmaps in a progressive denoising way. Moreover, we further explore improving the performance of DiffusionPose with conditions from human structural information. Extensive experiments show the prowess of our DiffusionPose, with improvements of 1.6, 1.2, and 1.2 mAP on widely-used COCO, CrowdPose, and AI Challenge datasets, respectively.","sentences":["One of the mainstream schemes for 2D human pose estimation (HPE) is learning keypoints heatmaps by a neural network.","Existing methods typically improve the quality of heatmaps by customized architectures, such as high-resolution representation and vision Transformers.","In this paper, we propose \\textbf{DiffusionPose}, a new scheme that formulates 2D HPE as a keypoints heatmaps generation problem from noised heatmaps.","During training, the keypoints are diffused to random distribution by adding noises and the diffusion model learns to recover ground-truth heatmaps from noised heatmaps with respect to conditions constructed by image feature.","During inference, the diffusion model generates heatmaps from initialized heatmaps in a progressive denoising way.","Moreover, we further explore improving the performance of DiffusionPose with conditions from human structural information.","Extensive experiments show the prowess of our DiffusionPose, with improvements of 1.6, 1.2, and 1.2 mAP on widely-used COCO, CrowdPose, and AI Challenge datasets, respectively."],"url":"http://arxiv.org/abs/2306.17074v1"}
{"created":"2023-06-29 16:24:30","title":"Axis-Parallel Right Angle Crossing Graphs","abstract":"A RAC graph is one admitting a RAC drawing, that is, a polyline drawing in which each crossing occurs at a right angle. Originally motivated by psychological studies on readability of graph layouts, RAC graphs form one of the most prominent graph classes in beyond planarity.   In this work, we study a subclass of RAC graphs, called axis-parallel RAC (or apRAC, for short), that restricts the crossings to pairs of axis-parallel edge-segments. apRAC drawings combine the readability of planar drawings with the clarity of (non-planar) orthogonal drawings. We consider these graphs both with and without bends. Our contribution is as follows: (i) We study inclusion relationships between apRAC and traditional RAC graphs. (ii) We establish bounds on the edge density of apRAC graphs. (iii) We show that every graph with maximum degree 8 is 2-bend apRAC and give a linear time drawing algorithm. Some of our results on apRAC graphs also improve the state of the art for general RAC graphs. We conclude our work with a list of open questions and a discussion of a natural generalization of the apRAC model.","sentences":["A RAC graph is one admitting a RAC drawing, that is, a polyline drawing in which each crossing occurs at a right angle.","Originally motivated by psychological studies on readability of graph layouts, RAC graphs form one of the most prominent graph classes in beyond planarity.   ","In this work, we study a subclass of RAC graphs, called axis-parallel RAC (or apRAC, for short), that restricts the crossings to pairs of axis-parallel edge-segments.","apRAC drawings combine the readability of planar drawings with the clarity of (non-planar) orthogonal drawings.","We consider these graphs both with and without bends.","Our contribution is as follows: (i) We study inclusion relationships between apRAC and traditional RAC graphs.","(ii) We establish bounds on the edge density of apRAC graphs.","(iii) We show that every graph with maximum degree 8 is 2-bend apRAC and give a linear time drawing algorithm.","Some of our results on apRAC graphs also improve the state of the art for general RAC graphs.","We conclude our work with a list of open questions and a discussion of a natural generalization of the apRAC model."],"url":"http://arxiv.org/abs/2306.17073v1"}
{"created":"2023-06-29 16:17:04","title":"Interdisciplinary Methods in Computational Creativity: How Human Variables Shape Human-Inspired AI Research","abstract":"The word creativity originally described a concept from human psychology, but in the realm of computational creativity (CC), it has become much more. The question of what creativity means when it is part of a computational system might be considered core to CC. Pinning down the meaning of creativity, and concepts like it, becomes salient when researchers port concepts from human psychology to computation, a widespread practice extending beyond CC into artificial intelligence (AI). Yet, the human processes shaping human-inspired computational systems have been little investigated. In this paper, we question which human literatures (social sciences, psychology, neuroscience) enter AI scholarship and how they are translated at the port of entry. This study is based on 22 in-depth, semi-structured interviews, primarily with human-inspired AI researchers, half of whom focus on creativity as a major research area. This paper focuses on findings most relevant to CC. We suggest that which human literature enters AI bears greater scrutiny because ideas may become disconnected from context in their home discipline. Accordingly, we recommend that CC researchers document the decisions and context of their practices, particularly those practices formalizing human concepts for machines. Publishing reflexive commentary on human elements in CC and AI would provide a useful record and permit greater dialogue with other disciplines.","sentences":["The word creativity originally described a concept from human psychology, but in the realm of computational creativity (CC), it has become much more.","The question of what creativity means when it is part of a computational system might be considered core to CC.","Pinning down the meaning of creativity, and concepts like it, becomes salient when researchers port concepts from human psychology to computation, a widespread practice extending beyond CC into artificial intelligence (AI).","Yet, the human processes shaping human-inspired computational systems have been little investigated.","In this paper, we question which human literatures (social sciences, psychology, neuroscience) enter AI scholarship and how they are translated at the port of entry.","This study is based on 22 in-depth, semi-structured interviews, primarily with human-inspired AI researchers, half of whom focus on creativity as a major research area.","This paper focuses on findings most relevant to CC.","We suggest that which human literature enters AI bears greater scrutiny because ideas may become disconnected from context in their home discipline.","Accordingly, we recommend that CC researchers document the decisions and context of their practices, particularly those practices formalizing human concepts for machines.","Publishing reflexive commentary on human elements in CC and AI would provide a useful record and permit greater dialogue with other disciplines."],"url":"http://arxiv.org/abs/2306.17070v1"}
{"created":"2023-06-29 16:14:43","title":"On the Predictive Accuracy of Neural Temporal Point Process Models for Continuous-time Event Data","abstract":"Temporal Point Processes (TPPs) serve as the standard mathematical framework for modeling asynchronous event sequences in continuous time. However, classical TPP models are often constrained by strong assumptions, limiting their ability to capture complex real-world event dynamics. To overcome this limitation, researchers have proposed Neural TPPs, which leverage neural network parametrizations to offer more flexible and efficient modeling. While recent studies demonstrate the effectiveness of Neural TPPs, they often lack a unified setup, relying on different baselines, datasets, and experimental configurations. This makes it challenging to identify the key factors driving improvements in predictive accuracy, hindering research progress. To bridge this gap, we present a comprehensive large-scale experimental study that systematically evaluates the predictive accuracy of state-of-the-art neural TPP models. Our study encompasses multiple real-world and synthetic event sequence datasets, following a carefully designed unified setup. We thoroughly investigate the influence of major architectural components such as event encoding, history encoder, and decoder parametrization on both time and mark prediction tasks. Additionally, we delve into the less explored area of probabilistic calibration for neural TPP models. By analyzing our results, we draw insightful conclusions regarding the significance of history size and the impact of architectural components on predictive accuracy. Furthermore, we shed light on the miscalibration of mark distributions in neural TPP models. Our study aims to provide valuable insights into the performance and characteristics of neural TPP models, contributing to a better understanding of their strengths and limitations.","sentences":["Temporal Point Processes (TPPs) serve as the standard mathematical framework for modeling asynchronous event sequences in continuous time.","However, classical TPP models are often constrained by strong assumptions, limiting their ability to capture complex real-world event dynamics.","To overcome this limitation, researchers have proposed Neural TPPs, which leverage neural network parametrizations to offer more flexible and efficient modeling.","While recent studies demonstrate the effectiveness of Neural TPPs, they often lack a unified setup, relying on different baselines, datasets, and experimental configurations.","This makes it challenging to identify the key factors driving improvements in predictive accuracy, hindering research progress.","To bridge this gap, we present a comprehensive large-scale experimental study that systematically evaluates the predictive accuracy of state-of-the-art neural TPP models.","Our study encompasses multiple real-world and synthetic event sequence datasets, following a carefully designed unified setup.","We thoroughly investigate the influence of major architectural components such as event encoding, history encoder, and decoder parametrization on both time and mark prediction tasks.","Additionally, we delve into the less explored area of probabilistic calibration for neural TPP models.","By analyzing our results, we draw insightful conclusions regarding the significance of history size and the impact of architectural components on predictive accuracy.","Furthermore, we shed light on the miscalibration of mark distributions in neural TPP models.","Our study aims to provide valuable insights into the performance and characteristics of neural TPP models, contributing to a better understanding of their strengths and limitations."],"url":"http://arxiv.org/abs/2306.17066v1"}
{"created":"2023-06-29 16:12:53","title":"5-Approximation for $\\mathcal{H}$-Treewidth Essentially as Fast as $\\mathcal{H}$-Deletion Parameterized by Solution Size","abstract":"The notion of $\\mathcal{H}$-treewidth, where $\\mathcal{H}$ is a hereditary graph class, was recently introduced as a generalization of the treewidth of an undirected graph. Roughly speaking, a graph of $\\mathcal{H}$-treewidth at most $k$ can be decomposed into (arbitrarily large) $\\mathcal{H}$-subgraphs which interact only through vertex sets of size $O(k)$ which can be organized in a tree-like fashion. $\\mathcal{H}$-treewidth can be used as a hybrid parameterization to develop fixed-parameter tractable algorithms for $\\mathcal{H}$-deletion problems, which ask to find a minimum vertex set whose removal from a given graph $G$ turns it into a member of $\\mathcal{H}$. The bottleneck in the current parameterized algorithms lies in the computation of suitable tree $\\mathcal{H}$-decompositions.   We present FPT approximation algorithms to compute tree $\\mathcal{H}$-decompositions for hereditary and union-closed graph classes $\\mathcal{H}$. Given a graph of $\\mathcal{H}$-treewidth $k$, we can compute a 5-approximate tree $\\mathcal{H}$-decomposition in time $f(O(k)) \\cdot n^{O(1)}$ whenever $\\mathcal{H}$-deletion parameterized by solution size can be solved in time $f(k) \\cdot n^{O(1)}$ for some function $f(k) \\geq 2^k$. The current-best algorithms either achieve an approximation factor of $k^{O(1)}$ or construct optimal decompositions while suffering from non-uniformity with unknown parameter dependence. Using these decompositions, we obtain algorithms solving Odd Cycle Transversal in time $2^{O(k)} \\cdot n^{O(1)}$ parameterized by $\\mathsf{bipartite}$-treewidth and Vertex Planarization in time $2^{O(k \\log k)} \\cdot n^{O(1)}$ parameterized by $\\mathsf{planar}$-treewidth, showing that these can be as fast as the solution-size parameterizations and giving the first ETH-tight algorithms for parameterizations by hybrid width measures.","sentences":["The notion of $\\mathcal{H}$-treewidth, where $\\mathcal{H}$ is a hereditary graph class, was recently introduced as a generalization of the treewidth of an undirected graph.","Roughly speaking, a graph of $\\mathcal{H}$-treewidth at most $k$ can be decomposed into (arbitrarily large) $\\mathcal{H}$-subgraphs which interact only through vertex sets of size $O(k)$ which can be organized in a tree-like fashion.","$\\mathcal{H}$-treewidth can be used as a hybrid parameterization to develop fixed-parameter tractable algorithms for $\\mathcal{H}$-deletion problems, which ask to find a minimum vertex set whose removal from a given graph $G$ turns it into a member of $\\mathcal{H}$. The bottleneck in the current parameterized algorithms lies in the computation of suitable tree $\\mathcal{H}$-decompositions.   ","We present FPT approximation algorithms to compute tree $\\mathcal{H}$-decompositions for hereditary and union-closed graph classes $\\mathcal{H}$. Given a graph of $\\mathcal{H}$-treewidth $k$, we can compute a 5-approximate tree $\\mathcal{H}$-decomposition in time $f(O(k))","\\cdot n^{O(1)}$ whenever $\\mathcal{H}$-deletion parameterized by solution size can be solved in time $f(k) \\cdot n^{O(1)}$ for some function $f(k)","\\geq","2^k$.","The current-best algorithms either achieve an approximation factor of $k^{O(1)}$ or construct optimal decompositions while suffering from non-uniformity with unknown parameter dependence.","Using these decompositions, we obtain algorithms solving Odd Cycle Transversal in time $2^{O(k)} \\cdot n^{O(1)}$ parameterized by $\\mathsf{bipartite}$-treewidth and Vertex Planarization in time $2^{O(k \\log k)} \\cdot n^{O(1)}$ parameterized by $\\mathsf{planar}$-treewidth, showing that these can be as fast as the solution-size parameterizations and giving the first ETH-tight algorithms for parameterizations by hybrid width measures."],"url":"http://arxiv.org/abs/2306.17065v1"}
