{"created":"2023-08-03 17:59:47","title":"The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World","abstract":"We present the All-Seeing (AS) project: a large-scale data and model for recognizing and understanding everything in the open world. Using a scalable data engine that incorporates human feedback and efficient models in the loop, we create a new dataset (AS-1B) with over 1 billion regions annotated with semantic tags, question-answering pairs, and detailed captions. It covers a wide range of 3.5 million common and rare concepts in the real world, and has 132.2 billion tokens that describe the concepts and their attributes. Leveraging this new dataset, we develop the All-Seeing model (ASM), a unified framework for panoptic visual recognition and understanding. The model is trained with open-ended language prompts and locations, which allows it to generalize to various vision and language tasks with remarkable zero-shot performance, including region-text retrieval, region recognition, captioning, and question-answering. We hope that this project can serve as a foundation for vision-language artificial general intelligence research. Models and the dataset shall be released at https://github.com/OpenGVLab/All-Seeing, and demo can be seen at https://huggingface.co/spaces/OpenGVLab/all-seeing.","sentences":["We present the All-Seeing (AS) project: a large-scale data and model for recognizing and understanding everything in the open world.","Using a scalable data engine that incorporates human feedback and efficient models in the loop, we create a new dataset (AS-1B) with over 1 billion regions annotated with semantic tags, question-answering pairs, and detailed captions.","It covers a wide range of 3.5 million common and rare concepts in the real world, and has 132.2 billion tokens that describe the concepts and their attributes.","Leveraging this new dataset, we develop the All-Seeing model (ASM), a unified framework for panoptic visual recognition and understanding.","The model is trained with open-ended language prompts and locations, which allows it to generalize to various vision and language tasks with remarkable zero-shot performance, including region-text retrieval, region recognition, captioning, and question-answering.","We hope that this project can serve as a foundation for vision-language artificial general intelligence research.","Models and the dataset shall be released at https://github.com/OpenGVLab/All-Seeing, and demo can be seen at https://huggingface.co/spaces/OpenGVLab/all-seeing."],"url":"http://arxiv.org/abs/2308.01907v1"}
{"created":"2023-08-03 17:59:27","title":"Reasoning in Large Language Models Through Symbolic Math Word Problems","abstract":"Large language models (LLMs) have revolutionized NLP by solving downstream tasks with little to no labeled data. Despite their versatile abilities, the larger question of their ability to reason remains ill-understood. This paper addresses reasoning in math word problems (MWPs) by studying symbolic versions of the numeric problems, since a symbolic expression is a \"concise explanation\" of the numeric answer. We create and use a symbolic version of the SVAMP dataset and find that GPT-3's davinci-002 model also has good zero-shot accuracy on symbolic MWPs. To evaluate the faithfulness of the model's reasoning, we go beyond accuracy and additionally evaluate the alignment between the final answer and the outputted reasoning, which correspond to numeric and symbolic answers respectively for MWPs. We explore a self-prompting approach to encourage the symbolic reasoning to align with the numeric answer, thus equipping the LLM with the ability to provide a concise and verifiable reasoning and making it more interpretable. Surprisingly, self-prompting also improves the symbolic accuracy to be higher than both the numeric and symbolic accuracies, thus providing an ensembling effect. The SVAMP_Sym dataset will be released for future research on symbolic math problems.","sentences":["Large language models (LLMs) have revolutionized NLP by solving downstream tasks with little to no labeled data.","Despite their versatile abilities, the larger question of their ability to reason remains ill-understood.","This paper addresses reasoning in math word problems (MWPs) by studying symbolic versions of the numeric problems, since a symbolic expression is a \"concise explanation\" of the numeric answer.","We create and use a symbolic version of the SVAMP dataset and find that GPT-3's davinci-002 model also has good zero-shot accuracy on symbolic MWPs.","To evaluate the faithfulness of the model's reasoning, we go beyond accuracy and additionally evaluate the alignment between the final answer and the outputted reasoning, which correspond to numeric and symbolic answers respectively for MWPs.","We explore a self-prompting approach to encourage the symbolic reasoning to align with the numeric answer, thus equipping the LLM with the ability to provide a concise and verifiable reasoning and making it more interpretable.","Surprisingly, self-prompting also improves the symbolic accuracy to be higher than both the numeric and symbolic accuracies, thus providing an ensembling effect.","The SVAMP_Sym dataset will be released for future research on symbolic math problems."],"url":"http://arxiv.org/abs/2308.01906v1"}
{"created":"2023-08-03 17:59:06","title":"Revisiting Deformable Convolution for Depth Completion","abstract":"Depth completion, which aims to generate high-quality dense depth maps from sparse depth maps, has attracted increasing attention in recent years. Previous work usually employs RGB images as guidance, and introduces iterative spatial propagation to refine estimated coarse depth maps. However, most of the propagation refinement methods require several iterations and suffer from a fixed receptive field, which may contain irrelevant and useless information with very sparse input. In this paper, we address these two challenges simultaneously by revisiting the idea of deformable convolution. We propose an effective architecture that leverages deformable kernel convolution as a single-pass refinement module, and empirically demonstrate its superiority. To better understand the function of deformable convolution and exploit it for depth completion, we further systematically investigate a variety of representative strategies. Our study reveals that, different from prior work, deformable convolution needs to be applied on an estimated depth map with a relatively high density for better performance. We evaluate our model on the large-scale KITTI dataset and achieve state-of-the-art level performance in both accuracy and inference speed. Our code is available at https://github.com/AlexSunNik/ReDC.","sentences":["Depth completion, which aims to generate high-quality dense depth maps from sparse depth maps, has attracted increasing attention in recent years.","Previous work usually employs RGB images as guidance, and introduces iterative spatial propagation to refine estimated coarse depth maps.","However, most of the propagation refinement methods require several iterations and suffer from a fixed receptive field, which may contain irrelevant and useless information with very sparse input.","In this paper, we address these two challenges simultaneously by revisiting the idea of deformable convolution.","We propose an effective architecture that leverages deformable kernel convolution as a single-pass refinement module, and empirically demonstrate its superiority.","To better understand the function of deformable convolution and exploit it for depth completion, we further systematically investigate a variety of representative strategies.","Our study reveals that, different from prior work, deformable convolution needs to be applied on an estimated depth map with a relatively high density for better performance.","We evaluate our model on the large-scale KITTI dataset and achieve state-of-the-art level performance in both accuracy and inference speed.","Our code is available at https://github.com/AlexSunNik/ReDC."],"url":"http://arxiv.org/abs/2308.01905v1"}
{"created":"2023-08-03 17:59:04","title":"DETR Doesn't Need Multi-Scale or Locality Design","abstract":"This paper presents an improved DETR detector that maintains a \"plain\" nature: using a single-scale feature map and global cross-attention calculations without specific locality constraints, in contrast to previous leading DETR-based detectors that reintroduce architectural inductive biases of multi-scale and locality into the decoder. We show that two simple technologies are surprisingly effective within a plain design to compensate for the lack of multi-scale feature maps and locality constraints. The first is a box-to-pixel relative position bias (BoxRPB) term added to the cross-attention formulation, which well guides each query to attend to the corresponding object region while also providing encoding flexibility. The second is masked image modeling (MIM)-based backbone pre-training which helps learn representation with fine-grained localization ability and proves crucial for remedying dependencies on the multi-scale feature maps. By incorporating these technologies and recent advancements in training and problem formation, the improved \"plain\" DETR showed exceptional improvements over the original DETR detector. By leveraging the Object365 dataset for pre-training, it achieved 63.9 mAP accuracy using a Swin-L backbone, which is highly competitive with state-of-the-art detectors which all heavily rely on multi-scale feature maps and region-based feature extraction. Code is available at https://github.com/impiga/Plain-DETR .","sentences":["This paper presents an improved DETR detector that maintains a \"plain\" nature: using a single-scale feature map and global cross-attention calculations without specific locality constraints, in contrast to previous leading DETR-based detectors that reintroduce architectural inductive biases of multi-scale and locality into the decoder.","We show that two simple technologies are surprisingly effective within a plain design to compensate for the lack of multi-scale feature maps and locality constraints.","The first is a box-to-pixel relative position bias (BoxRPB) term added to the cross-attention formulation, which well guides each query to attend to the corresponding object region while also providing encoding flexibility.","The second is masked image modeling (MIM)-based backbone pre-training which helps learn representation with fine-grained localization ability and proves crucial for remedying dependencies on the multi-scale feature maps.","By incorporating these technologies and recent advancements in training and problem formation, the improved \"plain\" DETR showed exceptional improvements over the original DETR detector.","By leveraging the Object365 dataset for pre-training, it achieved 63.9 mAP accuracy using a Swin-L backbone, which is highly competitive with state-of-the-art detectors which all heavily rely on multi-scale feature maps and region-based feature extraction.","Code is available at https://github.com/impiga/Plain-DETR ."],"url":"http://arxiv.org/abs/2308.01904v1"}
{"created":"2023-08-03 17:56:16","title":"How many preprints have actually been printed and why: a case study of computer science preprints on arXiv","abstract":"Preprints play an increasingly critical role in academic communities. There are many reasons driving researchers to post their manuscripts to preprint servers before formal submission to journals or conferences, but the use of preprints has also sparked considerable controversy, especially surrounding the claim of priority. In this paper, a case study of computer science preprints submitted to arXiv from 2008 to 2017 is conducted to quantify how many preprints have eventually been printed in peer-reviewed venues. Among those published manuscripts, some are published under different titles and without an update to their preprints on arXiv. In the case of these manuscripts, the traditional fuzzy matching method is incapable of mapping the preprint to the final published version. In view of this issue, we introduce a semantics-based mapping method with the employment of Bidirectional Encoder Representations from Transformers (BERT). With this new mapping method and a plurality of data sources, we find that 66% of all sampled preprints are published under unchanged titles and 11% are published under different titles and with other modifications. A further analysis was then performed to investigate why these preprints but not others were accepted for publication. Our comparison reveals that in the field of computer science, published preprints feature adequate revisions, multiple authorship, detailed abstract and introduction, extensive and authoritative references and available source code.","sentences":["Preprints play an increasingly critical role in academic communities.","There are many reasons driving researchers to post their manuscripts to preprint servers before formal submission to journals or conferences, but the use of preprints has also sparked considerable controversy, especially surrounding the claim of priority.","In this paper, a case study of computer science preprints submitted to arXiv from 2008 to 2017 is conducted to quantify how many preprints have eventually been printed in peer-reviewed venues.","Among those published manuscripts, some are published under different titles and without an update to their preprints on arXiv.","In the case of these manuscripts, the traditional fuzzy matching method is incapable of mapping the preprint to the final published version.","In view of this issue, we introduce a semantics-based mapping method with the employment of Bidirectional Encoder Representations from Transformers (BERT).","With this new mapping method and a plurality of data sources, we find that 66% of all sampled preprints are published under unchanged titles and 11% are published under different titles and with other modifications.","A further analysis was then performed to investigate why these preprints but not others were accepted for publication.","Our comparison reveals that in the field of computer science, published preprints feature adequate revisions, multiple authorship, detailed abstract and introduction, extensive and authoritative references and available source code."],"url":"http://arxiv.org/abs/2308.01899v1"}
{"created":"2023-08-03 17:56:06","title":"UniSim: A Neural Closed-Loop Sensor Simulator","abstract":"Rigorously testing autonomy systems is essential for making safe self-driving vehicles (SDV) a reality. It requires one to generate safety critical scenarios beyond what can be collected safely in the world, as many scenarios happen rarely on public roads. To accurately evaluate performance, we need to test the SDV on these scenarios in closed-loop, where the SDV and other actors interact with each other at each timestep. Previously recorded driving logs provide a rich resource to build these new scenarios from, but for closed loop evaluation, we need to modify the sensor data based on the new scene configuration and the SDV's decisions, as actors might be added or removed and the trajectories of existing actors and the SDV will differ from the original log. In this paper, we present UniSim, a neural sensor simulator that takes a single recorded log captured by a sensor-equipped vehicle and converts it into a realistic closed-loop multi-sensor simulation. UniSim builds neural feature grids to reconstruct both the static background and dynamic actors in the scene, and composites them together to simulate LiDAR and camera data at new viewpoints, with actors added or removed and at new placements. To better handle extrapolated views, we incorporate learnable priors for dynamic objects, and leverage a convolutional network to complete unseen regions. Our experiments show UniSim can simulate realistic sensor data with small domain gap on downstream tasks. With UniSim, we demonstrate closed-loop evaluation of an autonomy system on safety-critical scenarios as if it were in the real world.","sentences":["Rigorously testing autonomy systems is essential for making safe self-driving vehicles (SDV) a reality.","It requires one to generate safety critical scenarios beyond what can be collected safely in the world, as many scenarios happen rarely on public roads.","To accurately evaluate performance, we need to test the SDV on these scenarios in closed-loop, where the SDV and other actors interact with each other at each timestep.","Previously recorded driving logs provide a rich resource to build these new scenarios from, but for closed loop evaluation, we need to modify the sensor data based on the new scene configuration and the SDV's decisions, as actors might be added or removed and the trajectories of existing actors and the SDV will differ from the original log.","In this paper, we present UniSim, a neural sensor simulator that takes a single recorded log captured by a sensor-equipped vehicle and converts it into a realistic closed-loop multi-sensor simulation.","UniSim builds neural feature grids to reconstruct both the static background and dynamic actors in the scene, and composites them together to simulate LiDAR and camera data at new viewpoints, with actors added or removed and at new placements.","To better handle extrapolated views, we incorporate learnable priors for dynamic objects, and leverage a convolutional network to complete unseen regions.","Our experiments show UniSim can simulate realistic sensor data with small domain gap on downstream tasks.","With UniSim, we demonstrate closed-loop evaluation of an autonomy system on safety-critical scenarios as if it were in the real world."],"url":"http://arxiv.org/abs/2308.01898v1"}
{"created":"2023-08-03 17:46:27","title":"Improving Replay Sample Selection and Storage for Less Forgetting in Continual Learning","abstract":"Continual learning seeks to enable deep learners to train on a series of tasks of unknown length without suffering from the catastrophic forgetting of previous tasks. One effective solution is replay, which involves storing few previous experiences in memory and replaying them when learning the current task. However, there is still room for improvement when it comes to selecting the most informative samples for storage and determining the optimal number of samples to be stored. This study aims to address these issues with a novel comparison of the commonly used reservoir sampling to various alternative population strategies and providing a novel detailed analysis of how to find the optimal number of stored samples.","sentences":["Continual learning seeks to enable deep learners to train on a series of tasks of unknown length without suffering from the catastrophic forgetting of previous tasks.","One effective solution is replay, which involves storing few previous experiences in memory and replaying them when learning the current task.","However, there is still room for improvement when it comes to selecting the most informative samples for storage and determining the optimal number of samples to be stored.","This study aims to address these issues with a novel comparison of the commonly used reservoir sampling to various alternative population strategies and providing a novel detailed analysis of how to find the optimal number of stored samples."],"url":"http://arxiv.org/abs/2308.01895v1"}
{"created":"2023-08-03 17:37:18","title":"Exact identification of nonlinear dynamical systems by Trimmed Lasso","abstract":"Identification of nonlinear dynamical systems has been popularized by sparse identification of the nonlinear dynamics (SINDy) via the sequentially thresholded least squares (STLS) algorithm. Many extensions SINDy have emerged in the literature to deal with experimental data which are finite in length and noisy. Recently, the computationally intensive method of ensembling bootstrapped SINDy models (E-SINDy) was proposed for model identification, handling finite, highly noisy data. While the extensions of SINDy are numerous, their sparsity-promoting estimators occasionally provide sparse approximations of the dynamics as opposed to exact recovery. Furthermore, these estimators suffer under multicollinearity, e.g. the irrepresentable condition for the Lasso. In this paper, we demonstrate that the Trimmed Lasso for robust identification of models (TRIM) can provide exact recovery under more severe noise, finite data, and multicollinearity as opposed to E-SINDy. Additionally, the computational cost of TRIM is asymptotically equal to STLS since the sparsity parameter of the TRIM can be solved efficiently by convex solvers. We compare these methodologies on challenging nonlinear systems, specifically the Lorenz 63 system, the Bouc Wen oscillator from the nonlinear dynamics benchmark of No\\\"el and Schoukens, 2016, and a time delay system describing tool cutting dynamics. This study emphasizes the comparisons between STLS, reweighted $\\ell_1$ minimization, and Trimmed Lasso in identification with respect to problems faced by practitioners: the problem of finite and noisy data, the performance of the sparse regression of when the library grows in dimension (multicollinearity), and automatic methods for choice of regularization parameters.","sentences":["Identification of nonlinear dynamical systems has been popularized by sparse identification of the nonlinear dynamics (SINDy) via the sequentially thresholded least squares (STLS) algorithm.","Many extensions SINDy have emerged in the literature to deal with experimental data which are finite in length and noisy.","Recently, the computationally intensive method of ensembling bootstrapped SINDy models (E-SINDy) was proposed for model identification, handling finite, highly noisy data.","While the extensions of SINDy are numerous, their sparsity-promoting estimators occasionally provide sparse approximations of the dynamics as opposed to exact recovery.","Furthermore, these estimators suffer under multicollinearity, e.g. the irrepresentable condition for the Lasso.","In this paper, we demonstrate that the Trimmed Lasso for robust identification of models (TRIM) can provide exact recovery under more severe noise, finite data, and multicollinearity as opposed to E-SINDy.","Additionally, the computational cost of TRIM is asymptotically equal to STLS since the sparsity parameter of the TRIM can be solved efficiently by convex solvers.","We compare these methodologies on challenging nonlinear systems, specifically the Lorenz 63 system, the Bouc Wen oscillator from the nonlinear dynamics benchmark of No\\\"el and Schoukens, 2016, and a time delay system describing tool cutting dynamics.","This study emphasizes the comparisons between STLS, reweighted $\\ell_1$ minimization, and Trimmed Lasso in identification with respect to problems faced by practitioners: the problem of finite and noisy data, the performance of the sparse regression of when the library grows in dimension (multicollinearity), and automatic methods for choice of regularization parameters."],"url":"http://arxiv.org/abs/2308.01891v1"}
{"created":"2023-08-03 17:33:20","title":"DualCoOp++: Fast and Effective Adaptation to Multi-Label Recognition with Limited Annotations","abstract":"Multi-label image recognition in the low-label regime is a task of great challenge and practical significance. Previous works have focused on learning the alignment between textual and visual spaces to compensate for limited image labels, yet may suffer from reduced accuracy due to the scarcity of high-quality multi-label annotations. In this research, we leverage the powerful alignment between textual and visual features pretrained with millions of auxiliary image-text pairs. We introduce an efficient and effective framework called Evidence-guided Dual Context Optimization (DualCoOp++), which serves as a unified approach for addressing partial-label and zero-shot multi-label recognition. In DualCoOp++ we separately encode evidential, positive, and negative contexts for target classes as parametric components of the linguistic input (i.e., prompts). The evidential context aims to discover all the related visual content for the target class, and serves as guidance to aggregate positive and negative contexts from the spatial domain of the image, enabling better distinguishment between similar categories. Additionally, we introduce a Winner-Take-All module that promotes inter-class interaction during training, while avoiding the need for extra parameters and costs. As DualCoOp++ imposes minimal additional learnable overhead on the pretrained vision-language framework, it enables rapid adaptation to multi-label recognition tasks with limited annotations and even unseen classes. Experiments on standard multi-label recognition benchmarks across two challenging low-label settings demonstrate the superior performance of our approach compared to state-of-the-art methods.","sentences":["Multi-label image recognition in the low-label regime is a task of great challenge and practical significance.","Previous works have focused on learning the alignment between textual and visual spaces to compensate for limited image labels, yet may suffer from reduced accuracy due to the scarcity of high-quality multi-label annotations.","In this research, we leverage the powerful alignment between textual and visual features pretrained with millions of auxiliary image-text pairs.","We introduce an efficient and effective framework called Evidence-guided Dual Context Optimization (DualCoOp++), which serves as a unified approach for addressing partial-label and zero-shot multi-label recognition.","In DualCoOp++ we separately encode evidential, positive, and negative contexts for target classes as parametric components of the linguistic input (i.e., prompts).","The evidential context aims to discover all the related visual content for the target class, and serves as guidance to aggregate positive and negative contexts from the spatial domain of the image, enabling better distinguishment between similar categories.","Additionally, we introduce a Winner-Take-All module that promotes inter-class interaction during training, while avoiding the need for extra parameters and costs.","As DualCoOp++ imposes minimal additional learnable overhead on the pretrained vision-language framework, it enables rapid adaptation to multi-label recognition tasks with limited annotations and even unseen classes.","Experiments on standard multi-label recognition benchmarks across two challenging low-label settings demonstrate the superior performance of our approach compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2308.01890v1"}
{"created":"2023-08-03 17:31:55","title":"The virtual drum circle: polyrhythmic music interactions in extended reality","abstract":"Emerging technologies in the domain of extended reality offer rich, new possibilities for the study and practice of joint music performance. Apart from the technological challenges, bringing music players together in extended reality raises important questions on their performance and embodied coordination. In this study, we designed an extended reality platform to assess a remote, bidirectional polyrhythmic interaction between two players, mediated in real time by their three-dimensional embodied avatars and a shared, virtual drum circle. We leveraged a multi-layered analysis framework to assess their performance quality, embodied co-regulation and first-person interaction experience, using statistical techniques for time-series analysis and mixed-effect regression and focusing on contrasts of visual coupling (not seeing / seeing as avatars / seeing as real) and auditory context (metronome / music). Results reveal that an auditory context with music improved the performance output as measured by a prediction error, increased movement energy and levels of experienced agency. Visual coupling impacted experiential qualities and induced prosocial effects with increased levels of partner realism resulting in increased levels of shared agency and self-other merging. Embodied co-regulation between players was impacted by auditory context, visual coupling, and task complexity, suggesting prediction-based compensatory mechanisms to deal with the novelty, difficulty, and expressivity in the musical interaction. This study contributes to the understanding of music performance in extended reality by using a methodological approach to demonstrate how co-regulation between players is impacted by visual coupling and auditory context and provides a basis and future directions for further action-oriented research.","sentences":["Emerging technologies in the domain of extended reality offer rich, new possibilities for the study and practice of joint music performance.","Apart from the technological challenges, bringing music players together in extended reality raises important questions on their performance and embodied coordination.","In this study, we designed an extended reality platform to assess a remote, bidirectional polyrhythmic interaction between two players, mediated in real time by their three-dimensional embodied avatars and a shared, virtual drum circle.","We leveraged a multi-layered analysis framework to assess their performance quality, embodied co-regulation and first-person interaction experience, using statistical techniques for time-series analysis and mixed-effect regression and focusing on contrasts of visual coupling (not seeing / seeing as avatars / seeing as real) and auditory context (metronome / music).","Results reveal that an auditory context with music improved the performance output as measured by a prediction error, increased movement energy and levels of experienced agency.","Visual coupling impacted experiential qualities and induced prosocial effects with increased levels of partner realism resulting in increased levels of shared agency and self-other merging.","Embodied co-regulation between players was impacted by auditory context, visual coupling, and task complexity, suggesting prediction-based compensatory mechanisms to deal with the novelty, difficulty, and expressivity in the musical interaction.","This study contributes to the understanding of music performance in extended reality by using a methodological approach to demonstrate how co-regulation between players is impacted by visual coupling and auditory context and provides a basis and future directions for further action-oriented research."],"url":"http://arxiv.org/abs/2308.01889v1"}
{"created":"2023-08-03 17:31:22","title":"FROD: Robust Object Detection for Free","abstract":"Object detection is a vital task in computer vision and has become an integral component of numerous critical systems. However, state-of-the-art object detectors, similar to their classification counterparts, are susceptible to small adversarial perturbations that can significantly alter their normal behavior. Unlike classification, the robustness of object detectors has not been thoroughly explored. In this work, we take the initial step towards bridging the gap between the robustness of classification and object detection by leveraging adversarially trained classification models. Merely utilizing adversarially trained models as backbones for object detection does not result in robustness. We propose effective modifications to the classification-based backbone to instill robustness in object detection without incurring any computational overhead. To further enhance the robustness achieved by the proposed modified backbone, we introduce two lightweight components: imitation loss and delayed adversarial training. Extensive experiments on the MS-COCO and Pascal VOC datasets are conducted to demonstrate the effectiveness of our proposed approach.","sentences":["Object detection is a vital task in computer vision and has become an integral component of numerous critical systems.","However, state-of-the-art object detectors, similar to their classification counterparts, are susceptible to small adversarial perturbations that can significantly alter their normal behavior.","Unlike classification, the robustness of object detectors has not been thoroughly explored.","In this work, we take the initial step towards bridging the gap between the robustness of classification and object detection by leveraging adversarially trained classification models.","Merely utilizing adversarially trained models as backbones for object detection does not result in robustness.","We propose effective modifications to the classification-based backbone to instill robustness in object detection without incurring any computational overhead.","To further enhance the robustness achieved by the proposed modified backbone, we introduce two lightweight components: imitation loss and delayed adversarial training.","Extensive experiments on the MS-COCO and Pascal VOC datasets are conducted to demonstrate the effectiveness of our proposed approach."],"url":"http://arxiv.org/abs/2308.01888v1"}
{"created":"2023-08-03 17:30:39","title":"Athena 2.0: Discourse and User Modeling in Open Domain Dialogue","abstract":"Conversational agents are consistently growing in popularity and many people interact with them every day. While many conversational agents act as personal assistants, they can have many different goals. Some are task-oriented, such as providing customer support for a bank or making a reservation. Others are designed to be empathetic and to form emotional connections with the user. The Alexa Prize Challenge aims to create a socialbot, which allows the user to engage in coherent conversations, on a range of popular topics that will interest the user. Here we describe Athena 2.0, UCSC's conversational agent for Amazon's Socialbot Grand Challenge 4. Athena 2.0 utilizes a novel knowledge-grounded discourse model that tracks the entity links that Athena introduces into the dialogue, and uses them to constrain named-entity recognition and linking, and coreference resolution. Athena 2.0 also relies on a user model to personalize topic selection and other aspects of the conversation to individual users.","sentences":["Conversational agents are consistently growing in popularity and many people interact with them every day.","While many conversational agents act as personal assistants, they can have many different goals.","Some are task-oriented, such as providing customer support for a bank or making a reservation.","Others are designed to be empathetic and to form emotional connections with the user.","The Alexa Prize Challenge aims to create a socialbot, which allows the user to engage in coherent conversations, on a range of popular topics that will interest the user.","Here we describe Athena 2.0, UCSC's conversational agent for Amazon's Socialbot Grand Challenge 4.","Athena 2.0 utilizes a novel knowledge-grounded discourse model that tracks the entity links that Athena introduces into the dialogue, and uses them to constrain named-entity recognition and linking, and coreference resolution.","Athena 2.0 also relies on a user model to personalize topic selection and other aspects of the conversation to individual users."],"url":"http://arxiv.org/abs/2308.01887v1"}
{"created":"2023-08-03 16:53:53","title":"Thespian: Multi-Character Text Role-Playing Game Agents","abstract":"Text-adventure games and text role-playing games are grand challenges for reinforcement learning game playing agents. Text role-playing games are open-ended environments where an agent must faithfully play a particular character. We consider the distinction between characters and actors, where an actor agent has the ability to play multiple characters. We present a framework we call a thespian agent that can learn to emulate multiple characters along with a soft prompt that can be used to direct it as to which character to play at any time. We further describe an attention mechanism that allows the agent to learn new characters that are based on previously learned characters in a few-shot fashion. We show that our agent outperforms the state of the art agent framework in multi-character learning and few-shot learning.","sentences":["Text-adventure games and text role-playing games are grand challenges for reinforcement learning game playing agents.","Text role-playing games are open-ended environments where an agent must faithfully play a particular character.","We consider the distinction between characters and actors, where an actor agent has the ability to play multiple characters.","We present a framework we call a thespian agent that can learn to emulate multiple characters along with a soft prompt that can be used to direct it as to which character to play at any time.","We further describe an attention mechanism that allows the agent to learn new characters that are based on previously learned characters in a few-shot fashion.","We show that our agent outperforms the state of the art agent framework in multi-character learning and few-shot learning."],"url":"http://arxiv.org/abs/2308.01872v1"}
{"created":"2023-08-03 16:39:02","title":"Tag Prediction of Competitive Programming Problems using Deep Learning Techniques","abstract":"In the past decade, the amount of research being done in the fields of machine learning and deep learning, predominantly in the area of natural language processing (NLP), has risen dramatically. A well-liked method for developing programming abilities like logic building and problem solving is competitive programming. It can be tough for novices and even veteran programmers to traverse the wide collection of questions due to the massive number of accessible questions and the variety of themes, levels of difficulty, and questions offered. In order to help programmers find questions that are appropriate for their knowledge and interests, there is a need for an automated method. This can be done using automated tagging of the questions using Text Classification. Text classification is one of the important tasks widely researched in the field of Natural Language Processing. In this paper, we present a way to use text classification techniques to determine the domain of a competitive programming problem. A variety of models, including are implemented LSTM, GRU, and MLP. The dataset has been scraped from Codeforces, a major competitive programming website. A total of 2400 problems were scraped and preprocessed, which we used as a dataset for our training and testing of models. The maximum accuracy reached using our model is 78.0% by MLP(Multi Layer Perceptron).","sentences":["In the past decade, the amount of research being done in the fields of machine learning and deep learning, predominantly in the area of natural language processing (NLP), has risen dramatically.","A well-liked method for developing programming abilities like logic building and problem solving is competitive programming.","It can be tough for novices and even veteran programmers to traverse the wide collection of questions due to the massive number of accessible questions and the variety of themes, levels of difficulty, and questions offered.","In order to help programmers find questions that are appropriate for their knowledge and interests, there is a need for an automated method.","This can be done using automated tagging of the questions using Text Classification.","Text classification is one of the important tasks widely researched in the field of Natural Language Processing.","In this paper, we present a way to use text classification techniques to determine the domain of a competitive programming problem.","A variety of models, including are implemented LSTM, GRU, and MLP.","The dataset has been scraped from Codeforces, a major competitive programming website.","A total of 2400 problems were scraped and preprocessed, which we used as a dataset for our training and testing of models.","The maximum accuracy reached using our model is 78.0% by MLP(Multi Layer Perceptron)."],"url":"http://arxiv.org/abs/2308.01863v1"}
{"created":"2023-08-03 16:38:34","title":"Wider and Deeper LLM Networks are Fairer LLM Evaluators","abstract":"Measuring the quality of responses generated by LLMs is a challenging task, particularly when it comes to evaluating whether the response is aligned with human preference. A novel approach involves using the LLM itself to make evaluation and stabilizing the results through multiple independent evaluations, similar to a single-layer narrow LLM network. This network consists of a fixed number of neurons, with each neuron being the same LLM. In this paper, we draw upon the extensive research on deep neural networks to explore whether deeper and wider networks can lead to fairer evaluations. Specifically, inspired by the observation that different neurons in a neural network are responsible for detecting different concepts, we first adaptively generate as many neuron roles as possible for each evaluation sample. Each perspective corresponds to the role of a specific LLM neuron in the first layer. In subsequent layers, we follow the idea that higher layers in deep networks are responsible for more comprehensive features, each layer receives representations from all neurons in the previous layer, integrating the locally learned evaluation information to obtain a more comprehensive evaluation result. Interestingly, this network design resembles the process of academic paper reviewing. To validate the effectiveness of our method, we construct the largest and most diverse English evaluation benchmark LLMEval$^2$ for LLM evaluators, comprising 15 tasks, 8 abilities, and 2,553 samples. Experimental results demonstrate that a wider network (involving many reviewers) with 2 layers (one round of discussion) performs the best, improving kappa correlation coefficient from 0.28 to 0.34. We also leverage WideDeep to aid in the assessment of Chinese LLMs, which has accelerated the evaluation time by 4.6 times, resulting in a 60% cost saving. WideDeep achieves a remarkable 93% agreement level among humans.","sentences":["Measuring the quality of responses generated by LLMs is a challenging task, particularly when it comes to evaluating whether the response is aligned with human preference.","A novel approach involves using the LLM itself to make evaluation and stabilizing the results through multiple independent evaluations, similar to a single-layer narrow LLM network.","This network consists of a fixed number of neurons, with each neuron being the same LLM.","In this paper, we draw upon the extensive research on deep neural networks to explore whether deeper and wider networks can lead to fairer evaluations.","Specifically, inspired by the observation that different neurons in a neural network are responsible for detecting different concepts, we first adaptively generate as many neuron roles as possible for each evaluation sample.","Each perspective corresponds to the role of a specific LLM neuron in the first layer.","In subsequent layers, we follow the idea that higher layers in deep networks are responsible for more comprehensive features, each layer receives representations from all neurons in the previous layer, integrating the locally learned evaluation information to obtain a more comprehensive evaluation result.","Interestingly, this network design resembles the process of academic paper reviewing.","To validate the effectiveness of our method, we construct the largest and most diverse English evaluation benchmark LLMEval$^2$ for LLM evaluators, comprising 15 tasks, 8 abilities, and 2,553 samples.","Experimental results demonstrate that a wider network (involving many reviewers) with 2 layers (one round of discussion) performs the best, improving kappa correlation coefficient from 0.28 to 0.34.","We also leverage WideDeep to aid in the assessment of Chinese LLMs, which has accelerated the evaluation time by 4.6 times, resulting in a 60% cost saving.","WideDeep achieves a remarkable 93% agreement level among humans."],"url":"http://arxiv.org/abs/2308.01862v1"}
{"created":"2023-08-03 16:31:02","title":"ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation","abstract":"In this work, we make the first attempt to evaluate LLMs in a more challenging code generation scenario, i.e. class-level code generation. We first manually construct the first class-level code generation benchmark ClassEval of 100 class-level Python code generation tasks with approximately 500 person-hours. Based on it, we then perform the first study of 11 state-of-the-art LLMs on class-level code generation. Based on our results, we have the following main findings. First, we find that all existing LLMs show much worse performance on class-level code generation compared to on standalone method-level code generation benchmarks like HumanEval; and the method-level coding ability cannot equivalently reflect the class-level coding ability among LLMs. Second, we find that GPT-4 and GPT-3.5 still exhibit dominate superior than other LLMs on class-level code generation, and the second-tier models includes Instruct-Starcoder, Instruct-Codegen, and Wizardcoder with very similar performance. Third, we find that generating the entire class all at once (i.e. holistic generation strategy) is the best generation strategy only for GPT-4 and GPT-3.5, while method-by-method generation (i.e. incremental and compositional) is better strategies for the other models with limited ability of understanding long instructions and utilizing the middle information. Lastly, we find the limited model ability of generating method-dependent code and discuss the frequent error types in generated classes. Our benchmark is available at https://github.com/FudanSELab/ClassEval.","sentences":["In this work, we make the first attempt to evaluate LLMs in a more challenging code generation scenario, i.e. class-level code generation.","We first manually construct the first class-level code generation benchmark ClassEval of 100 class-level Python code generation tasks with approximately 500 person-hours.","Based on it, we then perform the first study of 11 state-of-the-art LLMs on class-level code generation.","Based on our results, we have the following main findings.","First, we find that all existing LLMs show much worse performance on class-level code generation compared to on standalone method-level code generation benchmarks like HumanEval; and the method-level coding ability cannot equivalently reflect the class-level coding ability among LLMs.","Second, we find that GPT-4 and GPT-3.5 still exhibit dominate superior than other LLMs on class-level code generation, and the second-tier models includes Instruct-Starcoder, Instruct-Codegen, and Wizardcoder with very similar performance.","Third, we find that generating the entire class all at once (i.e. holistic generation strategy) is the best generation strategy only for GPT-4 and GPT-3.5, while method-by-method generation (i.e. incremental and compositional) is better strategies for the other models with limited ability of understanding long instructions and utilizing the middle information.","Lastly, we find the limited model ability of generating method-dependent code and discuss the frequent error types in generated classes.","Our benchmark is available at https://github.com/FudanSELab/ClassEval."],"url":"http://arxiv.org/abs/2308.01861v1"}
{"created":"2023-08-03 16:24:04","title":"iEDA: An Open-Source Intelligent Physical Implementation Toolkit and Library","abstract":"Open-source EDA shows promising potential in unleashing EDA innovation and lowering the cost of chip design. This paper presents an open-source EDA project, iEDA, aiming for building a basic infrastructure for EDA technology evolution and closing the industrial-academic gap in the EDA area. iEDA now covers the whole flow of physical design (including Floorplan, Placement, CTS, Routing, Timing Optimization etc.), and part of the analysis tools (Static Timing Analysis and Power Analysis). To demonstrate the effectiveness of iEDA, we implement and tape out three chips of different scales (from 700k to 1.5M gates) on different process nodes (110nm and 28nm) with iEDA. iEDA is publicly available from the project home page http://ieda.oscc.cc.","sentences":["Open-source EDA shows promising potential in unleashing EDA innovation and lowering the cost of chip design.","This paper presents an open-source EDA project, iEDA, aiming for building a basic infrastructure for EDA technology evolution and closing the industrial-academic gap in the EDA area.","iEDA now covers the whole flow of physical design (including Floorplan, Placement, CTS, Routing, Timing Optimization etc.), and part of the analysis tools (Static Timing Analysis and Power Analysis).","To demonstrate the effectiveness of iEDA, we implement and tape out three chips of different scales (from 700k to 1.5M gates) on different process nodes (110nm and 28nm) with iEDA.","iEDA is publicly available from the project home page http://ieda.oscc.cc."],"url":"http://arxiv.org/abs/2308.01857v1"}
{"created":"2023-08-03 16:20:36","title":"Time-optimal geodesic mutual visibility of robots on grids within minimum area","abstract":"The \\textsc{Mutual Visibility} is a well-known problem in the context of mobile robots. For a set of $n$ robots disposed in the Euclidean plane, it asks for moving the robots without collisions so as to achieve a placement ensuring that no three robots are collinear. For robots moving on graphs, we consider the \\textsc{Geodesic Mutual Visibility} ($\\GMV$) problem. Robots move along the edges of the graph, without collisions, so as to occupy some vertices that guarantee they become pairwise geodesic mutually visible. This means that there is a shortest path (i.e., a \"geodesic\") between each pair of robots along which no other robots reside. We study this problem in the context of finite and infinite square grids, for robots operating under the standard Look-Compute-Move model. In both scenarios, we provide resolution algorithms along with formal correctness proofs, highlighting the most relevant peculiarities arising within the different contexts, while optimizing the time complexity.","sentences":["The \\textsc{Mutual Visibility} is a well-known problem in the context of mobile robots.","For a set of $n$ robots disposed in the Euclidean plane, it asks for moving the robots without collisions so as to achieve a placement ensuring that no three robots are collinear.","For robots moving on graphs, we consider the \\textsc{Geodesic Mutual Visibility} ($\\GMV$) problem.","Robots move along the edges of the graph, without collisions, so as to occupy some vertices that guarantee they become pairwise geodesic mutually visible.","This means that there is a shortest path (i.e., a \"geodesic\") between each pair of robots along which no other robots reside.","We study this problem in the context of finite and infinite square grids, for robots operating under the standard Look-Compute-Move model.","In both scenarios, we provide resolution algorithms along with formal correctness proofs, highlighting the most relevant peculiarities arising within the different contexts, while optimizing the time complexity."],"url":"http://arxiv.org/abs/2308.01855v1"}
{"created":"2023-08-03 16:20:33","title":"Reconstructing Three-Dimensional Models of Interacting Humans","abstract":"Understanding 3d human interactions is fundamental for fine-grained scene analysis and behavioural modeling. However, most of the existing models predict incorrect, lifeless 3d estimates, that miss the subtle human contact aspects--the essence of the event--and are of little use for detailed behavioral understanding. This paper addresses such issues with several contributions: (1) we introduce models for interaction signature estimation (ISP) encompassing contact detection, segmentation, and 3d contact signature prediction; (2) we show how such components can be leveraged to ensure contact consistency during 3d reconstruction; (3) we construct several large datasets for learning and evaluating 3d contact prediction and reconstruction methods; specifically, we introduce CHI3D, a lab-based accurate 3d motion capture dataset with 631 sequences containing $2,525$ contact events, $728,664$ ground truth 3d poses, as well as FlickrCI3D, a dataset of $11,216$ images, with $14,081$ processed pairs of people, and $81,233$ facet-level surface correspondences. Finally, (4) we propose methodology for recovering the ground-truth pose and shape of interacting people in a controlled setup and (5) annotate all 3d interaction motions in CHI3D with textual descriptions. Motion data in multiple formats (GHUM and SMPLX parameters, Human3.6m 3d joints) is made available for research purposes at \\url{https://ci3d.imar.ro}, together with an evaluation server and a public benchmark.","sentences":["Understanding 3d human interactions is fundamental for fine-grained scene analysis and behavioural modeling.","However, most of the existing models predict incorrect, lifeless 3d estimates, that miss the subtle human contact aspects--the essence of the event--and are of little use for detailed behavioral understanding.","This paper addresses such issues with several contributions: (1) we introduce models for interaction signature estimation (ISP) encompassing contact detection, segmentation, and 3d contact signature prediction; (2) we show how such components can be leveraged to ensure contact consistency during 3d reconstruction; (3) we construct several large datasets for learning and evaluating 3d contact prediction and reconstruction methods; specifically, we introduce CHI3D, a lab-based accurate 3d motion capture dataset with 631 sequences containing $2,525$ contact events, $728,664$ ground truth 3d poses, as well as FlickrCI3D, a dataset of $11,216$ images, with $14,081$ processed pairs of people, and $81,233$ facet-level surface correspondences.","Finally, (4) we propose methodology for recovering the ground-truth pose and shape of interacting people in a controlled setup and (5) annotate all 3d interaction motions in CHI3D with textual descriptions.","Motion data in multiple formats (GHUM and SMPLX parameters, Human3.6m 3d joints) is made available for research purposes at \\url{https://ci3d.imar.ro}, together with an evaluation server and a public benchmark."],"url":"http://arxiv.org/abs/2308.01854v1"}
{"created":"2023-08-03 16:18:32","title":"Synthesizing Long-Term Human Motions with Diffusion Models via Coherent Sampling","abstract":"Text-to-motion generation has gained increasing attention, but most existing methods are limited to generating short-term motions that correspond to a single sentence describing a single action. However, when a text stream describes a sequence of continuous motions, the generated motions corresponding to each sentence may not be coherently linked. Existing long-term motion generation methods face two main issues. Firstly, they cannot directly generate coherent motions and require additional operations such as interpolation to process the generated actions. Secondly, they generate subsequent actions in an autoregressive manner without considering the influence of future actions on previous ones. To address these issues, we propose a novel approach that utilizes a past-conditioned diffusion model with two optional coherent sampling methods: Past Inpainting Sampling and Compositional Transition Sampling. Past Inpainting Sampling completes subsequent motions by treating previous motions as conditions, while Compositional Transition Sampling models the distribution of the transition as the composition of two adjacent motions guided by different text prompts. Our experimental results demonstrate that our proposed method is capable of generating compositional and coherent long-term 3D human motions controlled by a user-instructed long text stream. The code is available at \\href{https://github.com/yangzhao1230/PCMDM}{https://github.com/yangzhao1230/PCMDM}.","sentences":["Text-to-motion generation has gained increasing attention, but most existing methods are limited to generating short-term motions that correspond to a single sentence describing a single action.","However, when a text stream describes a sequence of continuous motions, the generated motions corresponding to each sentence may not be coherently linked.","Existing long-term motion generation methods face two main issues.","Firstly, they cannot directly generate coherent motions and require additional operations such as interpolation to process the generated actions.","Secondly, they generate subsequent actions in an autoregressive manner without considering the influence of future actions on previous ones.","To address these issues, we propose a novel approach that utilizes a past-conditioned diffusion model with two optional coherent sampling methods:","Past Inpainting Sampling and Compositional Transition Sampling.","Past Inpainting Sampling completes subsequent motions by treating previous motions as conditions, while Compositional Transition Sampling models the distribution of the transition as the composition of two adjacent motions guided by different text prompts.","Our experimental results demonstrate that our proposed method is capable of generating compositional and coherent long-term 3D human motions controlled by a user-instructed long text stream.","The code is available at \\href{https://github.com/yangzhao1230/PCMDM}{https://github.com/yangzhao1230/PCMDM}."],"url":"http://arxiv.org/abs/2308.01850v1"}
{"created":"2023-08-03 16:18:19","title":"Curricular Transfer Learning for Sentence Encoded Tasks","abstract":"Fine-tuning language models in a downstream task is the standard approach for many state-of-the-art methodologies in the field of NLP. However, when the distribution between the source task and target task drifts, \\textit{e.g.}, conversational environments, these gains tend to be diminished. This article proposes a sequence of pre-training steps (a curriculum) guided by \"data hacking\" and grammar analysis that allows further gradual adaptation between pre-training distributions. In our experiments, we acquire a considerable improvement from our method compared to other known pre-training approaches for the MultiWoZ task.","sentences":["Fine-tuning language models in a downstream task is the standard approach for many state-of-the-art methodologies in the field of NLP.","However, when the distribution between the source task and target task drifts, \\textit{e.g.}, conversational environments, these gains tend to be diminished.","This article proposes a sequence of pre-training steps (a curriculum) guided by \"data hacking\" and grammar analysis that allows further gradual adaptation between pre-training distributions.","In our experiments, we acquire a considerable improvement from our method compared to other known pre-training approaches for the MultiWoZ task."],"url":"http://arxiv.org/abs/2308.01849v1"}
{"created":"2023-08-03 16:13:05","title":"XNLP: An Interactive Demonstration System for Universal Structured NLP","abstract":"Structured Natural Language Processing (XNLP) is an important subset of NLP that entails understanding the underlying semantic or syntactic structure of texts, which serves as a foundational component for many downstream applications. Despite certain recent efforts to explore universal solutions for specific categories of XNLP tasks, a comprehensive and effective approach for unifying all XNLP tasks long remains underdeveloped. In the meanwhile, while XNLP demonstration systems are vital for researchers exploring various XNLP tasks, existing platforms can be limited to, e.g., supporting few XNLP tasks, lacking interactivity and universalness. To this end, we propose an advanced XNLP demonstration platform, where we propose leveraging LLM to achieve universal XNLP, with one model for all with high generalizability. Overall, our system advances in multiple aspects, including universal XNLP modeling, high performance, interpretability, scalability, and interactivity, providing a unified platform for exploring diverse XNLP tasks in the community. XNLP is online: https://xnlp.haofei.vip","sentences":["Structured Natural Language Processing (XNLP) is an important subset of NLP that entails understanding the underlying semantic or syntactic structure of texts, which serves as a foundational component for many downstream applications.","Despite certain recent efforts to explore universal solutions for specific categories of XNLP tasks, a comprehensive and effective approach for unifying all XNLP tasks long remains underdeveloped.","In the meanwhile, while XNLP demonstration systems are vital for researchers exploring various XNLP tasks, existing platforms can be limited to, e.g., supporting few XNLP tasks, lacking interactivity and universalness.","To this end, we propose an advanced XNLP demonstration platform, where we propose leveraging LLM to achieve universal XNLP, with one model for all with high generalizability.","Overall, our system advances in multiple aspects, including universal XNLP modeling, high performance, interpretability, scalability, and interactivity, providing a unified platform for exploring diverse XNLP tasks in the community.","XNLP is online: https://xnlp.haofei.vip"],"url":"http://arxiv.org/abs/2308.01846v1"}
{"created":"2023-08-03 16:05:39","title":"URET: Universal Robustness Evaluation Toolkit (for Evasion)","abstract":"Machine learning models are known to be vulnerable to adversarial evasion attacks as illustrated by image classification models. Thoroughly understanding such attacks is critical in order to ensure the safety and robustness of critical AI tasks. However, most evasion attacks are difficult to deploy against a majority of AI systems because they have focused on image domain with only few constraints. An image is composed of homogeneous, numerical, continuous, and independent features, unlike many other input types to AI systems used in practice. Furthermore, some input types include additional semantic and functional constraints that must be observed to generate realistic adversarial inputs. In this work, we propose a new framework to enable the generation of adversarial inputs irrespective of the input type and task domain. Given an input and a set of pre-defined input transformations, our framework discovers a sequence of transformations that result in a semantically correct and functional adversarial input. We demonstrate the generality of our approach on several diverse machine learning tasks with various input representations. We also show the importance of generating adversarial examples as they enable the deployment of mitigation techniques.","sentences":["Machine learning models are known to be vulnerable to adversarial evasion attacks as illustrated by image classification models.","Thoroughly understanding such attacks is critical in order to ensure the safety and robustness of critical AI tasks.","However, most evasion attacks are difficult to deploy against a majority of AI systems because they have focused on image domain with only few constraints.","An image is composed of homogeneous, numerical, continuous, and independent features, unlike many other input types to AI systems used in practice.","Furthermore, some input types include additional semantic and functional constraints that must be observed to generate realistic adversarial inputs.","In this work, we propose a new framework to enable the generation of adversarial inputs irrespective of the input type and task domain.","Given an input and a set of pre-defined input transformations, our framework discovers a sequence of transformations that result in a semantically correct and functional adversarial input.","We demonstrate the generality of our approach on several diverse machine learning tasks with various input representations.","We also show the importance of generating adversarial examples as they enable the deployment of mitigation techniques."],"url":"http://arxiv.org/abs/2308.01840v1"}
{"created":"2023-08-03 15:52:27","title":"The Capability of Large Language Models to Measure Psychiatric Functioning","abstract":"The current work investigates the capability of Large language models (LLMs) that are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2) to predict psychiatric functioning from patient interviews and clinical descriptions without being trained to do so. To assess this, n = 145 depression and n =115 PTSD assessments and n = 46 clinical case studies across high prevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma and stress, Addictive disorders) were analyzed using prompts to extract estimated clinical scores and diagnoses. Results demonstrate that Med-PaLM 2 is capable of assessing psychiatric functioning across a range of psychiatric conditions with the strongest performance being the prediction of depression scores based on standardized assessments (Accuracy range= 0.80 - 0.84) which were statistically indistinguishable from human clinical raters t(1,144) = 1.20; p = 0.23. Results show the potential for general clinical language models to flexibly predict psychiatric risk based on free descriptions of functioning from both patients and clinicians.","sentences":["The current work investigates the capability of Large language models (LLMs) that are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2) to predict psychiatric functioning from patient interviews and clinical descriptions without being trained to do so.","To assess this, n = 145 depression and n =115 PTSD assessments and n = 46 clinical case studies across high prevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma and stress, Addictive disorders) were analyzed using prompts to extract estimated clinical scores and diagnoses.","Results demonstrate that Med-PaLM 2 is capable of assessing psychiatric functioning across a range of psychiatric conditions with the strongest performance being the prediction of depression scores based on standardized assessments (Accuracy range= 0.80 - 0.84) which were statistically indistinguishable from human clinical raters t(1,144) = 1.20; p = 0.23.","Results show the potential for general clinical language models to flexibly predict psychiatric risk based on free descriptions of functioning from both patients and clinicians."],"url":"http://arxiv.org/abs/2308.01834v1"}
{"created":"2023-08-03 15:51:07","title":"Sim-to-Real Vision-depth Fusion CNNs for Robust Pose Estimation Aboard Autonomous Nano-quadcopter","abstract":"Nano-quadcopters are versatile platforms attracting the interest of both academia and industry. Their tiny form factor, i.e., $\\,$10 cm diameter, makes them particularly useful in narrow scenarios and harmless in human proximity. However, these advantages come at the price of ultra-constrained onboard computational and sensorial resources for autonomous operations. This work addresses the task of estimating human pose aboard nano-drones by fusing depth and images in a novel CNN exclusively trained in simulation yet capable of robust predictions in the real world. We extend a commercial off-the-shelf (COTS) Crazyflie nano-drone -- equipped with a 320$\\times$240 px camera and an ultra-low-power System-on-Chip -- with a novel multi-zone (8$\\times$8) depth sensor. We design and compare different deep-learning models that fuse depth and image inputs. Our models are trained exclusively on simulated data for both inputs, and transfer well to the real world: field testing shows an improvement of 58% and 51% of our depth+camera system w.r.t. a camera-only State-of-the-Art baseline on the horizontal and angular mean pose errors, respectively. Our prototype is based on COTS components, which facilitates reproducibility and adoption of this novel class of systems.","sentences":["Nano-quadcopters are versatile platforms attracting the interest of both academia and industry.","Their tiny form factor, i.e., $\\,$10 cm diameter, makes them particularly useful in narrow scenarios and harmless in human proximity.","However, these advantages come at the price of ultra-constrained onboard computational and sensorial resources for autonomous operations.","This work addresses the task of estimating human pose aboard nano-drones by fusing depth and images in a novel CNN exclusively trained in simulation yet capable of robust predictions in the real world.","We extend a commercial off-the-shelf (COTS) Crazyflie nano-drone -- equipped with a 320$\\times$240 px camera and an ultra-low-power System-on-Chip -- with a novel multi-zone (8$\\times$8) depth sensor.","We design and compare different deep-learning models that fuse depth and image inputs.","Our models are trained exclusively on simulated data for both inputs, and transfer well to the real world: field testing shows an improvement of 58% and 51% of our depth+camera system w.r.t.","a camera-only State-of-the-Art baseline on the horizontal and angular mean pose errors, respectively.","Our prototype is based on COTS components, which facilitates reproducibility and adoption of this novel class of systems."],"url":"http://arxiv.org/abs/2308.01833v1"}
{"created":"2023-08-03 15:47:04","title":"Many-to-Many Spoken Language Translation via Unified Speech and Text Representation Learning with Unit-to-Unit Translation","abstract":"In this paper, we propose a method to learn unified representations of multilingual speech and text with a single model, especially focusing on the purpose of speech synthesis. We represent multilingual speech audio with speech units, the quantized representations of speech features encoded from a self-supervised speech model. Therefore, we can focus on their linguistic content by treating the audio as pseudo text and can build a unified representation of speech and text. Then, we propose to train an encoder-decoder structured model with a Unit-to-Unit Translation (UTUT) objective on multilingual data. Specifically, by conditioning the encoder with the source language token and the decoder with the target language token, the model is optimized to translate the spoken language into that of the target language, in a many-to-many language translation setting. Therefore, the model can build the knowledge of how spoken languages are comprehended and how to relate them to different languages. A single pre-trained model with UTUT can be employed for diverse multilingual speech- and text-related tasks, such as Speech-to-Speech Translation (STS), multilingual Text-to-Speech Synthesis (TTS), and Text-to-Speech Translation (TTST). By conducting comprehensive experiments encompassing various languages, we validate the efficacy of the proposed method across diverse multilingual tasks. Moreover, we show UTUT can perform many-to-many language STS, which has not been previously explored in the literature. Samples are available on https://choijeongsoo.github.io/utut.","sentences":["In this paper, we propose a method to learn unified representations of multilingual speech and text with a single model, especially focusing on the purpose of speech synthesis.","We represent multilingual speech audio with speech units, the quantized representations of speech features encoded from a self-supervised speech model.","Therefore, we can focus on their linguistic content by treating the audio as pseudo text and can build a unified representation of speech and text.","Then, we propose to train an encoder-decoder structured model with a Unit-to-Unit Translation (UTUT) objective on multilingual data.","Specifically, by conditioning the encoder with the source language token and the decoder with the target language token, the model is optimized to translate the spoken language into that of the target language, in a many-to-many language translation setting.","Therefore, the model can build the knowledge of how spoken languages are comprehended and how to relate them to different languages.","A single pre-trained model with UTUT can be employed for diverse multilingual speech- and text-related tasks, such as Speech-to-Speech Translation (STS), multilingual Text-to-Speech Synthesis (TTS), and Text-to-Speech Translation (TTST).","By conducting comprehensive experiments encompassing various languages, we validate the efficacy of the proposed method across diverse multilingual tasks.","Moreover, we show UTUT can perform many-to-many language STS, which has not been previously explored in the literature.","Samples are available on https://choijeongsoo.github.io/utut."],"url":"http://arxiv.org/abs/2308.01831v1"}
{"created":"2023-08-03 15:40:08","title":"Not All Actions Are Created Equal: Bayesian Optimal Experimental Design for Safe and Optimal Nonlinear System Identification","abstract":"Uncertainty in state or model parameters is common in robotics and typically handled by acquiring system measurements that yield information about the uncertain quantities of interest. Inputs to a nonlinear dynamical system yield outcomes that produce varying amounts of information about the underlying uncertain parameters of the system. To maximize information gained with respect to these uncertain parameters we present a Bayesian approach to data collection for system identification called Bayesian Optimal Experimental Design (BOED). The formulation uses parameterized trajectories and cubature to compute maximally informative system trajectories which obtain as much information as possible about unknown system parameters while also ensuring safety under mild assumptions. The proposed method is applicable to non-linear and non-Gaussian systems and is applied to a high-fidelity vehicle model from the literature. It is shown the proposed approach requires orders of magnitude fewer samples compared to state-of-the-art BOED algorithms from the literature while simultaneously providing safety guarantees.","sentences":["Uncertainty in state or model parameters is common in robotics and typically handled by acquiring system measurements that yield information about the uncertain quantities of interest.","Inputs to a nonlinear dynamical system yield outcomes that produce varying amounts of information about the underlying uncertain parameters of the system.","To maximize information gained with respect to these uncertain parameters we present a Bayesian approach to data collection for system identification called Bayesian Optimal Experimental Design (BOED).","The formulation uses parameterized trajectories and cubature to compute maximally informative system trajectories which obtain as much information as possible about unknown system parameters while also ensuring safety under mild assumptions.","The proposed method is applicable to non-linear and non-Gaussian systems and is applied to a high-fidelity vehicle model from the literature.","It is shown the proposed approach requires orders of magnitude fewer samples compared to state-of-the-art BOED algorithms from the literature while simultaneously providing safety guarantees."],"url":"http://arxiv.org/abs/2308.01829v1"}
{"created":"2023-08-03 15:34:01","title":"Scaling Relationship on Learning Mathematical Reasoning with Large Language Models","abstract":"Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capacity is under-explored. In this paper, we investigate how the pre-training loss, supervised data amount, and augmented data amount influence the reasoning performances of a supervised LLM. We find that pre-training loss is a better indicator of the model's performance than the model's parameter count. We apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets. To augment more data samples for improving model performances without any human effort, we propose to apply Rejection sampling Fine-Tuning (RFT). RFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets. We find with augmented samples containing more distinct reasoning paths, RFT improves mathematical reasoning performance more for LLMs. We also find RFT brings more improvement for less performant LLMs. Furthermore, we combine rejection samples from multiple models which push LLaMA-7B to an accuracy of 49.3% and outperforms the supervised fine-tuning (SFT) accuracy of 35.9% significantly.","sentences":["Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capacity is under-explored.","In this paper, we investigate how the pre-training loss, supervised data amount, and augmented data amount influence the reasoning performances of a supervised LLM.","We find that pre-training loss is a better indicator of the model's performance than the model's parameter count.","We apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets.","To augment more data samples for improving model performances without any human effort, we propose to apply Rejection sampling Fine-Tuning (RFT).","RFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets.","We find with augmented samples containing more distinct reasoning paths, RFT improves mathematical reasoning performance more for LLMs.","We also find RFT brings more improvement for less performant LLMs.","Furthermore, we combine rejection samples from multiple models which push LLaMA-7B to an accuracy of 49.3% and outperforms the supervised fine-tuning (SFT) accuracy of 35.9% significantly."],"url":"http://arxiv.org/abs/2308.01825v1"}
{"created":"2023-08-03 15:33:24","title":"Hard Adversarial Example Mining for Improving Robust Fairness","abstract":"Adversarial training (AT) is widely considered the state-of-the-art technique for improving the robustness of deep neural networks (DNNs) against adversarial examples (AE). Nevertheless, recent studies have revealed that adversarially trained models are prone to unfairness problems, restricting their applicability. In this paper, we empirically observe that this limitation may be attributed to serious adversarial confidence overfitting, i.e., certain adversarial examples with overconfidence. To alleviate this problem, we propose HAM, a straightforward yet effective framework via adaptive Hard Adversarial example Mining.HAM concentrates on mining hard adversarial examples while discarding the easy ones in an adaptive fashion. Specifically, HAM identifies hard AEs in terms of their step sizes needed to cross the decision boundary when calculating loss value. Besides, an early-dropping mechanism is incorporated to discard the easy examples at the initial stages of AE generation, resulting in efficient AT. Extensive experimental results on CIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant improvement in robust fairness while reducing computational cost compared to several state-of-the-art adversarial training methods. The code will be made publicly available.","sentences":["Adversarial training (AT) is widely considered the state-of-the-art technique for improving the robustness of deep neural networks (DNNs) against adversarial examples (AE).","Nevertheless, recent studies have revealed that adversarially trained models are prone to unfairness problems, restricting their applicability.","In this paper, we empirically observe that this limitation may be attributed to serious adversarial confidence overfitting, i.e., certain adversarial examples with overconfidence.","To alleviate this problem, we propose HAM, a straightforward yet effective framework via adaptive Hard Adversarial example Mining.","HAM concentrates on mining hard adversarial examples while discarding the easy ones in an adaptive fashion.","Specifically, HAM identifies hard AEs in terms of their step sizes needed to cross the decision boundary when calculating loss value.","Besides, an early-dropping mechanism is incorporated to discard the easy examples at the initial stages of AE generation, resulting in efficient AT.","Extensive experimental results on CIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant improvement in robust fairness while reducing computational cost compared to several state-of-the-art adversarial training methods.","The code will be made publicly available."],"url":"http://arxiv.org/abs/2308.01823v1"}
{"created":"2023-08-03 15:22:51","title":"Tensor Programs IVb: Adaptive Optimization in the Infinite-Width Limit","abstract":"Going beyond stochastic gradient descent (SGD), what new phenomena emerge in wide neural networks trained by adaptive optimizers like Adam? Here we show: The same dichotomy between feature learning and kernel behaviors (as in SGD) holds for general optimizers as well, including Adam -- albeit with a nonlinear notion of \"kernel.\" We derive the corresponding \"neural tangent\" and \"maximal update\" limits for any architecture. Two foundational advances underlie the above results: 1) A new Tensor Program language, NEXORT, that can express how adaptive optimizers process gradients into updates. 2) The introduction of bra-ket notation to drastically simplify expressions and calculations in Tensor Programs. This work summarizes and generalizes all previous results in the Tensor Programs series of papers.","sentences":["Going beyond stochastic gradient descent (SGD), what new phenomena emerge in wide neural networks trained by adaptive optimizers like Adam?","Here we show: The same dichotomy between feature learning and kernel behaviors (as in SGD) holds for general optimizers as well, including Adam -- albeit with a nonlinear notion of \"kernel.\"","We derive the corresponding \"neural tangent\" and \"maximal update\" limits for any architecture.","Two foundational advances underlie the above results: 1) A new Tensor Program language, NEXORT, that can express how adaptive optimizers process gradients into updates.","2) The introduction of bra-ket notation to drastically simplify expressions and calculations in Tensor Programs.","This work summarizes and generalizes all previous results in the Tensor Programs series of papers."],"url":"http://arxiv.org/abs/2308.01814v1"}
{"created":"2023-08-03 15:21:08","title":"Deep Neural Networks Fused with Textures for Image Classification","abstract":"Fine-grained image classification (FGIC) is a challenging task in computer vision for due to small visual differences among inter-subcategories, but, large intra-class variations. Deep learning methods have achieved remarkable success in solving FGIC. In this paper, we propose a fusion approach to address FGIC by combining global texture with local patch-based information. The first pipeline extracts deep features from various fixed-size non-overlapping patches and encodes features by sequential modelling using the long short-term memory (LSTM). Another path computes image-level textures at multiple scales using the local binary patterns (LBP). The advantages of both streams are integrated to represent an efficient feature vector for image classification. The method is tested on eight datasets representing the human faces, skin lesions, food dishes, marine lives, etc. using four standard backbone CNNs. Our method has attained better classification accuracy over existing methods with notable margins.","sentences":["Fine-grained image classification (FGIC) is a challenging task in computer vision for due to small visual differences among inter-subcategories, but, large intra-class variations.","Deep learning methods have achieved remarkable success in solving FGIC.","In this paper, we propose a fusion approach to address FGIC by combining global texture with local patch-based information.","The first pipeline extracts deep features from various fixed-size non-overlapping patches and encodes features by sequential modelling using the long short-term memory (LSTM).","Another path computes image-level textures at multiple scales using the local binary patterns (LBP).","The advantages of both streams are integrated to represent an efficient feature vector for image classification.","The method is tested on eight datasets representing the human faces, skin lesions, food dishes, marine lives, etc. using four standard backbone CNNs.","Our method has attained better classification accuracy over existing methods with notable margins."],"url":"http://arxiv.org/abs/2308.01813v1"}
{"created":"2023-08-03 15:17:24","title":"An End-to-end Food Portion Estimation Framework Based on Shape Reconstruction from Monocular Image","abstract":"Dietary assessment is a key contributor to monitoring health status. Existing self-report methods are tedious and time-consuming with substantial biases and errors. Image-based food portion estimation aims to estimate food energy values directly from food images, showing great potential for automated dietary assessment solutions. Existing image-based methods either use a single-view image or incorporate multi-view images and depth information to estimate the food energy, which either has limited performance or creates user burdens. In this paper, we propose an end-to-end deep learning framework for food energy estimation from a monocular image through 3D shape reconstruction. We leverage a generative model to reconstruct the voxel representation of the food object from the input image to recover the missing 3D information. Our method is evaluated on a publicly available food image dataset Nutrition5k, resulting a Mean Absolute Error (MAE) of 40.05 kCal and Mean Absolute Percentage Error (MAPE) of 11.47% for food energy estimation. Our method uses RGB image as the only input at the inference stage and achieves competitive results compared to the existing method requiring both RGB and depth information.","sentences":["Dietary assessment is a key contributor to monitoring health status.","Existing self-report methods are tedious and time-consuming with substantial biases and errors.","Image-based food portion estimation aims to estimate food energy values directly from food images, showing great potential for automated dietary assessment solutions.","Existing image-based methods either use a single-view image or incorporate multi-view images and depth information to estimate the food energy, which either has limited performance or creates user burdens.","In this paper, we propose an end-to-end deep learning framework for food energy estimation from a monocular image through 3D shape reconstruction.","We leverage a generative model to reconstruct the voxel representation of the food object from the input image to recover the missing 3D information.","Our method is evaluated on a publicly available food image dataset Nutrition5k, resulting a Mean Absolute Error (MAE) of 40.05 kCal and Mean Absolute Percentage Error (MAPE) of 11.47% for food energy estimation.","Our method uses RGB image as the only input at the inference stage and achieves competitive results compared to the existing method requiring both RGB and depth information."],"url":"http://arxiv.org/abs/2308.01810v1"}
{"created":"2023-08-03 15:06:23","title":"QUEST: Query Stream for Vehicle-Infrastructure Cooperative Perception","abstract":"Cooperative perception can effectively enhance individual perception performance by providing additional viewpoint and expanding the sensing field. Existing cooperation paradigms are either interpretable (result cooperation) or flexible (feature cooperation). In this paper, we propose the concept of query cooperation to enable interpretable instance-level flexible feature interaction. To specifically explain the concept, we propose a cooperative perception framework, termed QUEST, which let query stream flow among agents. The cross-agent queries are interacted via fusion for co-aware instances and complementation for individual unaware instances. Taking camera-based vehicle-infrastructure perception as a typical practical application scene, the experimental results on the real-world dataset, DAIR-V2X-Seq, demonstrate the effectiveness of QUEST and further reveal the advantage of the query cooperation paradigm on transmission flexibility and robustness to packet dropout. We hope our work can further facilitate the cross-agent representation interaction for better cooperative perception in practice.","sentences":["Cooperative perception can effectively enhance individual perception performance by providing additional viewpoint and expanding the sensing field.","Existing cooperation paradigms are either interpretable (result cooperation) or flexible (feature cooperation).","In this paper, we propose the concept of query cooperation to enable interpretable instance-level flexible feature interaction.","To specifically explain the concept, we propose a cooperative perception framework, termed QUEST, which let query stream flow among agents.","The cross-agent queries are interacted via fusion for co-aware instances and complementation for individual unaware instances.","Taking camera-based vehicle-infrastructure perception as a typical practical application scene, the experimental results on the real-world dataset, DAIR-V2X-Seq, demonstrate the effectiveness of QUEST and further reveal the advantage of the query cooperation paradigm on transmission flexibility and robustness to packet dropout.","We hope our work can further facilitate the cross-agent representation interaction for better cooperative perception in practice."],"url":"http://arxiv.org/abs/2308.01804v1"}
{"created":"2023-08-03 15:03:40","title":"Multi-Carrier Modulation: An Evolution from Time-Frequency Domain to Delay-Doppler Domain","abstract":"The recently proposed orthogonal delay-Doppler division multiplexing (ODDM) modulation, which is based on the new delay-Doppler (DD) domain orthogonal pulse (DDOP), is studied. A substantial benefit of the DDOP-based ODDM or general delay-Doppler domain multi-carrier (DDMC) modulation is that it achieves orthogonality with respect to the fine time and frequency resolutions of the DD domain. We first revisit the family of wireless channel models conceived for linear time-varying (LTV) channels, and then review the conventional multi-carrier (MC) modulation schemes and their design guidelines for both linear time-invariant (LTI) and LTV channels. Then we discuss the time-varying property of the LTV channels' DD domain impulse response and propose an impulse function based transmission strategy for equivalent sampled DD domain (ESDD) channels. Next, we take an in-depth look into the DDOP and the corresponding ODDM modulation to unveil its unique input-output relation for transmission over ESDD channels. Then, we point out that the conventional MC modulation design guidelines based on the Wely-Heisenberg (WH) frame theory can be relaxed without compromising its orthogonality or without violating the WH frame theory. More specifically, for a communication system having given bandwidth and duration, MC modulation signals can be designed based on a WH subset associated with sufficient (bi)orthogonality, which governs the (bi)orthogonality of the MC signal within the bandwidth and duration. This novel design guideline could potentially open up opportunities for developing future waveforms required by new applications such as communication systems associated with high delay and/or Doppler shifts, as well as integrated sensing and communications, etc.","sentences":["The recently proposed orthogonal delay-Doppler division multiplexing (ODDM) modulation, which is based on the new delay-Doppler (DD) domain orthogonal pulse (DDOP), is studied.","A substantial benefit of the DDOP-based ODDM or general delay-Doppler domain multi-carrier (DDMC) modulation is that it achieves orthogonality with respect to the fine time and frequency resolutions of the DD domain.","We first revisit the family of wireless channel models conceived for linear time-varying (LTV) channels, and then review the conventional multi-carrier (MC) modulation schemes and their design guidelines for both linear time-invariant (LTI) and LTV channels.","Then we discuss the time-varying property of the LTV channels' DD domain impulse response and propose an impulse function based transmission strategy for equivalent sampled DD domain (ESDD) channels.","Next, we take an in-depth look into the DDOP and the corresponding ODDM modulation to unveil its unique input-output relation for transmission over ESDD channels.","Then, we point out that the conventional MC modulation design guidelines based on the Wely-Heisenberg (WH) frame theory can be relaxed without compromising its orthogonality or without violating the WH frame theory.","More specifically, for a communication system having given bandwidth and duration, MC modulation signals can be designed based on a WH subset associated with sufficient (bi)orthogonality, which governs the (bi)orthogonality of the MC signal within the bandwidth and duration.","This novel design guideline could potentially open up opportunities for developing future waveforms required by new applications such as communication systems associated with high delay and/or Doppler shifts, as well as integrated sensing and communications, etc."],"url":"http://arxiv.org/abs/2308.01802v1"}
{"created":"2023-08-03 14:52:17","title":"Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to Sequence approach","abstract":"Job scheduling is a well-known Combinatorial Optimization problem with endless applications. Well planned schedules bring many benefits in the context of automated systems: among others, they limit production costs and waste. Nevertheless, the NP-hardness of this problem makes it essential to use heuristics whose design is difficult, requires specialized knowledge and often produces methods tailored to the specific task. This paper presents an original end-to-end Deep Reinforcement Learning approach to scheduling that automatically learns dispatching rules. Our technique is inspired by natural language encoder-decoder models for sequence processing and has never been used, to the best of our knowledge, for scheduling purposes. We applied and tested our method in particular to some benchmark instances of Job Shop Problem, but this technique is general enough to be potentially used to tackle other different optimal job scheduling tasks with minimal intervention. Results demonstrate that we outperform many classical approaches exploiting priority dispatching rules and show competitive results on state-of-the-art Deep Reinforcement Learning ones.","sentences":["Job scheduling is a well-known Combinatorial Optimization problem with endless applications.","Well planned schedules bring many benefits in the context of automated systems: among others, they limit production costs and waste.","Nevertheless, the NP-hardness of this problem makes it essential to use heuristics whose design is difficult, requires specialized knowledge and often produces methods tailored to the specific task.","This paper presents an original end-to-end Deep Reinforcement Learning approach to scheduling that automatically learns dispatching rules.","Our technique is inspired by natural language encoder-decoder models for sequence processing and has never been used, to the best of our knowledge, for scheduling purposes.","We applied and tested our method in particular to some benchmark instances of Job Shop Problem, but this technique is general enough to be potentially used to tackle other different optimal job scheduling tasks with minimal intervention.","Results demonstrate that we outperform many classical approaches exploiting priority dispatching rules and show competitive results on state-of-the-art Deep Reinforcement Learning ones."],"url":"http://arxiv.org/abs/2308.01797v1"}
{"created":"2023-08-03 14:41:14","title":"Fundamental Data Structures for Matrix-Free Finite Elements on Hybrid Tetrahedral Grids","abstract":"This paper presents efficient data structures for the implementation of matrix-free finite element methods on block-structured, hybrid tetrahedral grids. It provides a complete categorization of all geometric sub-objects that emerge from the regular refinement of the unstructured, tetrahedral coarse grid and describes efficient iteration patterns and analytical linearization functions for the mapping of coefficients to memory addresses. This foundation enables the implementation of fast, extreme-scalable, matrix-free, iterative solvers, and in particular geometric multigrid methods by design. Their application to the variable-coefficient Stokes system subject to an enriched Galerkin discretization and to the curl-curl problem discretized with N\\'ed\\'elec edge elements showcases the flexibility of the implementation. Eventually, the solution of a curl-curl problem with $1.6 \\cdot 10^{11}$ (more than one hundred billion) unknowns on more than $32000$ processes with a matrix-free full multigrid solver demonstrates its extreme-scalability.","sentences":["This paper presents efficient data structures for the implementation of matrix-free finite element methods on block-structured, hybrid tetrahedral grids.","It provides a complete categorization of all geometric sub-objects that emerge from the regular refinement of the unstructured, tetrahedral coarse grid and describes efficient iteration patterns and analytical linearization functions for the mapping of coefficients to memory addresses.","This foundation enables the implementation of fast, extreme-scalable, matrix-free, iterative solvers, and in particular geometric multigrid methods by design.","Their application to the variable-coefficient Stokes system subject to an enriched Galerkin discretization and to the curl-curl problem discretized with N\\'ed\\'elec edge elements showcases the flexibility of the implementation.","Eventually, the solution of a curl-curl problem with $1.6 \\cdot 10^{11}$ (more than one hundred billion) unknowns on more than $32000$ processes with a matrix-free full multigrid solver demonstrates its extreme-scalability."],"url":"http://arxiv.org/abs/2308.01792v1"}
{"created":"2023-08-03 14:39:54","title":"Collective action and spontaneity cycles: Cascading dynamics under Bayesian games","abstract":"The formation mechanisms and cyclical conditions of collective action have become open issues in research involving public choice, social movements, and more. For this reason, on the basis of rational decision-making and social assimilation, this paper proposes an action model that combines Bayesian game and social network dynamics, and incorporates exogenous cycles into it. For this model, this paper proves the spontaneous action theorem and action cycle theorem of collective action, and based on numerical simulation and empirical calibration, further confirms the theoretical mechanism involving elements such as risk/risk-free incentives and the number of social ties. Based on such conclusions and evidence, this paper proposes a theory of spontaneous cycles as an integrative answer to the open question of collective action formation/cycles.","sentences":["The formation mechanisms and cyclical conditions of collective action have become open issues in research involving public choice, social movements, and more.","For this reason, on the basis of rational decision-making and social assimilation, this paper proposes an action model that combines Bayesian game and social network dynamics, and incorporates exogenous cycles into it.","For this model, this paper proves the spontaneous action theorem and action cycle theorem of collective action, and based on numerical simulation and empirical calibration, further confirms the theoretical mechanism involving elements such as risk/risk-free incentives and the number of social ties.","Based on such conclusions and evidence, this paper proposes a theory of spontaneous cycles as an integrative answer to the open question of collective action formation/cycles."],"url":"http://arxiv.org/abs/2308.01791v1"}
{"created":"2023-08-03 14:31:57","title":"Lexicon and Rule-based Word Lemmatization Approach for the Somali Language","abstract":"Lemmatization is a Natural Language Processing (NLP) technique used to normalize text by changing morphological derivations of words to their root forms. It is used as a core pre-processing step in many NLP tasks including text indexing, information retrieval, and machine learning for NLP, among others. This paper pioneers the development of text lemmatization for the Somali language, a low-resource language with very limited or no prior effective adoption of NLP methods and datasets. We especially develop a lexicon and rule-based lemmatizer for Somali text, which is a starting point for a full-fledged Somali lemmatization system for various NLP tasks. With consideration of the language morphological rules, we have developed an initial lexicon of 1247 root words and 7173 derivationally related terms enriched with rules for lemmatizing words not present in the lexicon. We have tested the algorithm on 120 documents of various lengths including news articles, social media posts, and text messages. Our initial results demonstrate that the algorithm achieves an accuracy of 57\\% for relatively long documents (e.g. full news articles), 60.57\\% for news article extracts, and high accuracy of 95.87\\% for short texts such as social media messages.","sentences":["Lemmatization is a Natural Language Processing (NLP) technique used to normalize text by changing morphological derivations of words to their root forms.","It is used as a core pre-processing step in many NLP tasks including text indexing, information retrieval, and machine learning for NLP, among others.","This paper pioneers the development of text lemmatization for the Somali language, a low-resource language with very limited or no prior effective adoption of NLP methods and datasets.","We especially develop a lexicon and rule-based lemmatizer for Somali text, which is a starting point for a full-fledged Somali lemmatization system for various NLP tasks.","With consideration of the language morphological rules, we have developed an initial lexicon of 1247 root words and 7173 derivationally related terms enriched with rules for lemmatizing words not present in the lexicon.","We have tested the algorithm on 120 documents of various lengths including news articles, social media posts, and text messages.","Our initial results demonstrate that the algorithm achieves an accuracy of 57\\% for relatively long documents (e.g. full news articles), 60.57\\% for news article extracts, and high accuracy of 95.87\\% for short texts such as social media messages."],"url":"http://arxiv.org/abs/2308.01785v1"}
{"created":"2023-08-03 14:20:50","title":"The ACAC_D Model for Mutable Activity Control and Chain of Dependencies in Smart and Collaborative Systems","abstract":"With the integration of connected devices, artificial intelligence, and heterogeneous networks in IoT-driven cyber-physical systems, our society is evolving as a smart, automated, and connected community. In such dynamic and distributed environments, various operations are carried out considering different contextual factors to support the automation of collaborative devices and systems. These devices often perform long-lived operations or tasks (referred to as activities) to fulfill larger goals in the collaborative environment. These activities are usually mutable (change states) and interdependent. They can influence the execution of other activities in the ecosystem, requiring active and real-time monitoring of the entire connected environment.   Recently, a vision for activity-centric access control(ACAC) was proposed to enable security modeling and enforcement from the perspective and abstraction of interdependent activities. The proposed ACAC incorporates four decision parameters: Authorizations(A), oBligations(B), Conditions(C), and activity Dependencies(D) for an object agnostic access control in smart systems. In this paper, we take a step further towards maturing ACAC by focusing on activity dependencies(D) and developing a family of formal mathematically grounded models, referred to as ACAC_D. These formal models consider the real-time mutability of activities in resolving active dependencies among various activities in the ecosystem. Activity dependencies can form a chain where it is possible to have dependencies of dependencies. In ACAC, we also consider the chain of dependencies while handling the mutability of an activity. We highlight the challenges while dealing with chain of dependencies, and provide solutions to resolve these challenges. We also present a proof of concept implementation of with performance analysis for a smart farming use case.","sentences":["With the integration of connected devices, artificial intelligence, and heterogeneous networks in IoT-driven cyber-physical systems, our society is evolving as a smart, automated, and connected community.","In such dynamic and distributed environments, various operations are carried out considering different contextual factors to support the automation of collaborative devices and systems.","These devices often perform long-lived operations or tasks (referred to as activities) to fulfill larger goals in the collaborative environment.","These activities are usually mutable (change states) and interdependent.","They can influence the execution of other activities in the ecosystem, requiring active and real-time monitoring of the entire connected environment.   ","Recently, a vision for activity-centric access control(ACAC) was proposed to enable security modeling and enforcement from the perspective and abstraction of interdependent activities.","The proposed ACAC incorporates four decision parameters: Authorizations(A), oBligations(B), Conditions(C), and activity Dependencies(D) for an object agnostic access control in smart systems.","In this paper, we take a step further towards maturing ACAC by focusing on activity dependencies(D) and developing a family of formal mathematically grounded models, referred to as ACAC_D. These formal models consider the real-time mutability of activities in resolving active dependencies among various activities in the ecosystem.","Activity dependencies can form a chain where it is possible to have dependencies of dependencies.","In ACAC, we also consider the chain of dependencies while handling the mutability of an activity.","We highlight the challenges while dealing with chain of dependencies, and provide solutions to resolve these challenges.","We also present a proof of concept implementation of with performance analysis for a smart farming use case."],"url":"http://arxiv.org/abs/2308.01783v1"}
{"created":"2023-08-03 14:15:51","title":"Influences of some families of error-correcting codes","abstract":"Binary codes of length $n$ may be viewed as subsets of vertices of the Boolean hypercube $\\{0,1\\}^n$. The ability of a linear error-correcting code to recover erasures is connected to influences of particular monotone Boolean functions. These functions provide insight into the role that particular coordinates play in a code's erasure repair capability. In this paper, we consider directly the influences of coordinates of a code. We describe a family of codes, called codes with minimum disjoint support, for which all influences may be determined. As a consequence, we find influences of repetition codes and certain distinct weight codes. Computing influences is typically circumvented by appealing to the transitivity of the automorphism group of the code. Some of the codes considered here fail to meet the transitivity conditions requires for these standard approaches, yet we can compute them directly.","sentences":["Binary codes of length $n$ may be viewed as subsets of vertices of the Boolean hypercube $\\{0,1\\}^n$. The ability of a linear error-correcting code to recover erasures is connected to influences of particular monotone Boolean functions.","These functions provide insight into the role that particular coordinates play in a code's erasure repair capability.","In this paper, we consider directly the influences of coordinates of a code.","We describe a family of codes, called codes with minimum disjoint support, for which all influences may be determined.","As a consequence, we find influences of repetition codes and certain distinct weight codes.","Computing influences is typically circumvented by appealing to the transitivity of the automorphism group of the code.","Some of the codes considered here fail to meet the transitivity conditions requires for these standard approaches, yet we can compute them directly."],"url":"http://arxiv.org/abs/2308.01781v1"}
{"created":"2023-08-03 14:11:56","title":"Point2Mask: Point-supervised Panoptic Segmentation via Optimal Transport","abstract":"Weakly-supervised image segmentation has recently attracted increasing research attentions, aiming to avoid the expensive pixel-wise labeling. In this paper, we present an effective method, namely Point2Mask, to achieve high-quality panoptic prediction using only a single random point annotation per target for training. Specifically, we formulate the panoptic pseudo-mask generation as an Optimal Transport (OT) problem, where each ground-truth (gt) point label and pixel sample are defined as the label supplier and consumer, respectively. The transportation cost is calculated by the introduced task-oriented maps, which focus on the category-wise and instance-wise differences among the various thing and stuff targets. Furthermore, a centroid-based scheme is proposed to set the accurate unit number for each gt point supplier. Hence, the pseudo-mask generation is converted into finding the optimal transport plan at a globally minimal transportation cost, which can be solved via the Sinkhorn-Knopp Iteration. Experimental results on Pascal VOC and COCO demonstrate the promising performance of our proposed Point2Mask approach to point-supervised panoptic segmentation. Source code is available at: https://github.com/LiWentomng/Point2Mask.","sentences":["Weakly-supervised image segmentation has recently attracted increasing research attentions, aiming to avoid the expensive pixel-wise labeling.","In this paper, we present an effective method, namely Point2Mask, to achieve high-quality panoptic prediction using only a single random point annotation per target for training.","Specifically, we formulate the panoptic pseudo-mask generation as an Optimal Transport (OT) problem, where each ground-truth (gt) point label and pixel sample are defined as the label supplier and consumer, respectively.","The transportation cost is calculated by the introduced task-oriented maps, which focus on the category-wise and instance-wise differences among the various thing and stuff targets.","Furthermore, a centroid-based scheme is proposed to set the accurate unit number for each gt point supplier.","Hence, the pseudo-mask generation is converted into finding the optimal transport plan at a globally minimal transportation cost, which can be solved via the Sinkhorn-Knopp Iteration.","Experimental results on Pascal VOC and COCO demonstrate the promising performance of our proposed Point2Mask approach to point-supervised panoptic segmentation.","Source code is available at: https://github.com/LiWentomng/Point2Mask."],"url":"http://arxiv.org/abs/2308.01779v1"}
{"created":"2023-08-03 14:09:31","title":"Does Correction Remain An Problem For Large Language Models?","abstract":"As large language models, such as GPT, continue to advance the capabilities of natural language processing (NLP), the question arises: does the problem of correction still persist? This paper investigates the role of correction in the context of large language models by conducting two experiments. The first experiment focuses on correction as a standalone task, employing few-shot learning techniques with GPT-like models for error correction. The second experiment explores the notion of correction as a preparatory task for other NLP tasks, examining whether large language models can tolerate and perform adequately on texts containing certain levels of noise or errors. By addressing these experiments, we aim to shed light on the significance of correction in the era of large language models and its implications for various NLP applications.","sentences":["As large language models, such as GPT, continue to advance the capabilities of natural language processing (NLP), the question arises: does the problem of correction still persist?","This paper investigates the role of correction in the context of large language models by conducting two experiments.","The first experiment focuses on correction as a standalone task, employing few-shot learning techniques with GPT-like models for error correction.","The second experiment explores the notion of correction as a preparatory task for other NLP tasks, examining whether large language models can tolerate and perform adequately on texts containing certain levels of noise or errors.","By addressing these experiments, we aim to shed light on the significance of correction in the era of large language models and its implications for various NLP applications."],"url":"http://arxiv.org/abs/2308.01776v1"}
{"created":"2023-08-03 14:00:01","title":"Deep Learning-based Prediction of Stress and Strain Maps in Arterial Walls for Improved Cardiovascular Risk Assessment","abstract":"This study investigated the potential of end-to-end deep learning tools as a more effective substitute for FEM in predicting stress-strain fields within 2D cross sections of arterial wall. We first proposed a U-Net based fully convolutional neural network (CNN) to predict the von Mises stress and strain distribution based on the spatial arrangement of calcification within arterial wall cross-sections. Further, we developed a conditional generative adversarial network (cGAN) to enhance, particularly from the perceptual perspective, the prediction accuracy of stress and strain field maps for arterial walls with various calcification quantities and spatial configurations. On top of U-Net and cGAN, we also proposed their ensemble approaches, respectively, to further improve the prediction accuracy of field maps. Our dataset, consisting of input and output images, was generated by implementing boundary conditions and extracting stress-strain field maps. The trained U-Net models can accurately predict von Mises stress and strain fields, with structural similarity index scores (SSIM) of 0.854 and 0.830 and mean squared errors of 0.017 and 0.018 for stress and strain, respectively, on a reserved test set. Meanwhile, the cGAN models in a combination of ensemble and transfer learning techniques demonstrate high accuracy in predicting von Mises stress and strain fields, as evidenced by SSIM scores of 0.890 for stress and 0.803 for strain. Additionally, mean squared errors of 0.008 for stress and 0.017 for strain further support the model's performance on a designated test set. Overall, this study developed a surrogate model for finite element analysis, which can accurately and efficiently predict stress-strain fields of arterial walls regardless of complex geometries and boundary conditions.","sentences":["This study investigated the potential of end-to-end deep learning tools as a more effective substitute for FEM in predicting stress-strain fields within 2D cross sections of arterial wall.","We first proposed a U-Net based fully convolutional neural network (CNN) to predict the von Mises stress and strain distribution based on the spatial arrangement of calcification within arterial wall cross-sections.","Further, we developed a conditional generative adversarial network (cGAN) to enhance, particularly from the perceptual perspective, the prediction accuracy of stress and strain field maps for arterial walls with various calcification quantities and spatial configurations.","On top of U-Net and cGAN, we also proposed their ensemble approaches, respectively, to further improve the prediction accuracy of field maps.","Our dataset, consisting of input and output images, was generated by implementing boundary conditions and extracting stress-strain field maps.","The trained U-Net models can accurately predict von Mises stress and strain fields, with structural similarity index scores (SSIM) of 0.854 and 0.830 and mean squared errors of 0.017 and 0.018 for stress and strain, respectively, on a reserved test set.","Meanwhile, the cGAN models in a combination of ensemble and transfer learning techniques demonstrate high accuracy in predicting von Mises stress and strain fields, as evidenced by SSIM scores of 0.890 for stress and 0.803 for strain.","Additionally, mean squared errors of 0.008 for stress and 0.017 for strain further support the model's performance on a designated test set.","Overall, this study developed a surrogate model for finite element analysis, which can accurately and efficiently predict stress-strain fields of arterial walls regardless of complex geometries and boundary conditions."],"url":"http://arxiv.org/abs/2308.01771v1"}
{"created":"2023-08-03 13:58:21","title":"A Novel Tensor Decomposition of arbitrary order based on Block Convolution with Reflective Boundary Conditions for Multi-Dimensional Data Analysis","abstract":"Tensor decompositions are powerful tools for analyzing multi-dimensional data in their original format. Besides tensor decompositions like Tucker and CP, Tensor SVD (t-SVD) which is based on the t-product of tensors is another extension of SVD to tensors that recently developed and has found numerous applications in analyzing high dimensional data. This paper offers a new insight into the t-Product and shows that this product is a block convolution of two tensors with periodic boundary conditions. Based on this viewpoint, we propose a new tensor-tensor product called the $\\star_c{}\\text{-Product}$ based on Block convolution with reflective boundary conditions. Using a tensor framework, this product can be easily extended to tensors of arbitrary order. Additionally, we introduce a tensor decomposition based on our $\\star_c{}\\text{-Product}$ for arbitrary order tensors. Compared to t-SVD, our new decomposition has lower complexity, and experiments show that it yields higher-quality results in applications such as classification and compression.","sentences":["Tensor decompositions are powerful tools for analyzing multi-dimensional data in their original format.","Besides tensor decompositions like Tucker and CP, Tensor SVD (t-SVD) which is based on the t-product of tensors is another extension of SVD to tensors that recently developed and has found numerous applications in analyzing high dimensional data.","This paper offers a new insight into the t-Product and shows that this product is a block convolution of two tensors with periodic boundary conditions.","Based on this viewpoint, we propose a new tensor-tensor product called the $\\star_c{}\\text{-Product}$ based on Block convolution with reflective boundary conditions.","Using a tensor framework, this product can be easily extended to tensors of arbitrary order.","Additionally, we introduce a tensor decomposition based on our $\\star_c{}\\text{-Product}$ for arbitrary order tensors.","Compared to t-SVD, our new decomposition has lower complexity, and experiments show that it yields higher-quality results in applications such as classification and compression."],"url":"http://arxiv.org/abs/2308.01768v1"}
{"created":"2023-08-03 13:56:07","title":"PoissonNet: Resolution-Agnostic 3D Shape Reconstruction using Fourier Neural Operators","abstract":"We introduce PoissonNet, an architecture for shape reconstruction that addresses the challenge of recovering 3D shapes from points. Traditional deep neural networks face challenges with common 3D shape discretization techniques due to their computational complexity at higher resolutions. To overcome this, we leverage Fourier Neural Operators (FNOs) to solve the Poisson equation and reconstruct a mesh from oriented point cloud measurements. PoissonNet exhibits two main advantages. First, it enables efficient training on low-resolution data while achieving comparable performance at high-resolution evaluation, thanks to the resolution-agnostic nature of FNOs. This feature allows for one-shot super-resolution. Second, our method surpasses existing approaches in reconstruction quality while being differentiable. Overall, our proposed method not only improves upon the limitations of classical deep neural networks in shape reconstruction but also achieves superior results in terms of reconstruction quality, running time, and resolution flexibility. Furthermore, we demonstrate that the Poisson surface reconstruction problem is well-posed in the limit case by showing a universal approximation theorem for the solution operator of the Poisson equation with distributional data utilizing the Fourier Neuronal Operator, which provides a theoretical foundation for our numerical results. The code to reproduce the experiments is available on: \\url{https://github.com/arsenal9971/PoissonNet}.","sentences":["We introduce PoissonNet, an architecture for shape reconstruction that addresses the challenge of recovering 3D shapes from points.","Traditional deep neural networks face challenges with common 3D shape discretization techniques due to their computational complexity at higher resolutions.","To overcome this, we leverage Fourier Neural Operators (FNOs) to solve the Poisson equation and reconstruct a mesh from oriented point cloud measurements.","PoissonNet exhibits two main advantages.","First, it enables efficient training on low-resolution data while achieving comparable performance at high-resolution evaluation, thanks to the resolution-agnostic nature of FNOs.","This feature allows for one-shot super-resolution.","Second, our method surpasses existing approaches in reconstruction quality while being differentiable.","Overall, our proposed method not only improves upon the limitations of classical deep neural networks in shape reconstruction but also achieves superior results in terms of reconstruction quality, running time, and resolution flexibility.","Furthermore, we demonstrate that the Poisson surface reconstruction problem is well-posed in the limit case by showing a universal approximation theorem for the solution operator of the Poisson equation with distributional data utilizing the Fourier Neuronal Operator, which provides a theoretical foundation for our numerical results.","The code to reproduce the experiments is available on: \\url{https://github.com/arsenal9971/PoissonNet}."],"url":"http://arxiv.org/abs/2308.01766v1"}
{"created":"2023-08-03 13:49:17","title":"LOUC: Leave-One-Out-Calibration Measure for Analyzing Human Matcher Performance","abstract":"Schema matching is a core data integration task, focusing on identifying correspondences among attributes of multiple schemata. Numerous algorithmic approaches were suggested for schema matching over the years, aiming at solving the task with as little human involvement as possible. Yet, humans are still required in the loop -- to validate algorithms and to produce ground truth data for algorithms to be trained against. In recent years, a new research direction investigates the capabilities and behavior of humans while performing matching tasks. Previous works utilized this knowledge to predict, and even improve, the performance of human matchers. In this work, we continue this line of research by suggesting a novel measure to evaluate the performance of human matchers, based on calibration, a common meta-cognition measure. The proposed measure enables detailed analysis of various factors of the behavior of human matchers and their relation to human performance. Such analysis can be further utilized to develop heuristics and methods to better asses and improve the annotation quality.","sentences":["Schema matching is a core data integration task, focusing on identifying correspondences among attributes of multiple schemata.","Numerous algorithmic approaches were suggested for schema matching over the years, aiming at solving the task with as little human involvement as possible.","Yet, humans are still required in the loop -- to validate algorithms and to produce ground truth data for algorithms to be trained against.","In recent years, a new research direction investigates the capabilities and behavior of humans while performing matching tasks.","Previous works utilized this knowledge to predict, and even improve, the performance of human matchers.","In this work, we continue this line of research by suggesting a novel measure to evaluate the performance of human matchers, based on calibration, a common meta-cognition measure.","The proposed measure enables detailed analysis of various factors of the behavior of human matchers and their relation to human performance.","Such analysis can be further utilized to develop heuristics and methods to better asses and improve the annotation quality."],"url":"http://arxiv.org/abs/2308.01761v1"}
{"created":"2023-08-03 13:43:03","title":"Bag of Policies for Distributional Deep Exploration","abstract":"Efficient exploration in complex environments remains a major challenge for reinforcement learning (RL). Compared to previous Thompson sampling-inspired mechanisms that enable temporally extended exploration, i.e., deep exploration, we focus on deep exploration in distributional RL. We develop here a general purpose approach, Bag of Policies (BoP), that can be built on top of any return distribution estimator by maintaining a population of its copies. BoP consists of an ensemble of multiple heads that are updated independently. During training, each episode is controlled by only one of the heads and the collected state-action pairs are used to update all heads off-policy, leading to distinct learning signals for each head which diversify learning and behaviour. To test whether optimistic ensemble method can improve on distributional RL as did on scalar RL, by e.g. Bootstrapped DQN, we implement the BoP approach with a population of distributional actor-critics using Bayesian Distributional Policy Gradients (BDPG). The population thus approximates a posterior distribution of return distributions along with a posterior distribution of policies. Another benefit of building upon BDPG is that it allows to analyze global posterior uncertainty along with local curiosity bonus simultaneously for exploration. As BDPG is already an optimistic method, this pairing helps to investigate if optimism is accumulatable in distributional RL. Overall BoP results in greater robustness and speed during learning as demonstrated by our experimental results on ALE Atari games.","sentences":["Efficient exploration in complex environments remains a major challenge for reinforcement learning (RL).","Compared to previous Thompson sampling-inspired mechanisms that enable temporally extended exploration, i.e., deep exploration, we focus on deep exploration in distributional RL.","We develop here a general purpose approach, Bag of Policies (BoP), that can be built on top of any return distribution estimator by maintaining a population of its copies.","BoP consists of an ensemble of multiple heads that are updated independently.","During training, each episode is controlled by only one of the heads and the collected state-action pairs are used to update all heads off-policy, leading to distinct learning signals for each head which diversify learning and behaviour.","To test whether optimistic ensemble method can improve on distributional RL as did on scalar RL, by e.g. Bootstrapped DQN, we implement the BoP approach with a population of distributional actor-critics using Bayesian Distributional Policy Gradients (BDPG).","The population thus approximates a posterior distribution of return distributions along with a posterior distribution of policies.","Another benefit of building upon BDPG is that it allows to analyze global posterior uncertainty along with local curiosity bonus simultaneously for exploration.","As BDPG is already an optimistic method, this pairing helps to investigate if optimism is accumulatable in distributional RL.","Overall BoP results in greater robustness and speed during learning as demonstrated by our experimental results on ALE Atari games."],"url":"http://arxiv.org/abs/2308.01759v1"}
{"created":"2023-08-03 13:39:50","title":"A Compliant Robotic Leg Based on Fibre Jamming","abstract":"Humans possess a remarkable ability to react to sudden and unpredictable perturbations through immediate mechanical responses, which harness the visco-elastic properties of muscles to perform auto-corrective movements to maintain balance. In this paper, we propose a novel design of a robotic leg inspired by this mechanism. We develop multi-material fibre jammed tendons, and demonstrate their use as passive compliant mechanisms to achieve variable joint stiffness and improve stability. Through numerical simulations and extensive experimentation, we demonstrate the ability for our system to achieve a wide range of potentially beneficial compliance regimes. We show the role and contribution of each tendon quantitatively by evaluating their individual force contribution in resisting rotational perturbations. We also perform walking experiments with programmed bioinspired gaits that varying the stiffness of the tendons throughout the gait cycle, demonstrating a stable and consistent behaviour. We show the potential of such systems when integrated into legged robots, where compliance and shock absorption can be provided entirely through the morphological properties of the leg.","sentences":["Humans possess a remarkable ability to react to sudden and unpredictable perturbations through immediate mechanical responses, which harness the visco-elastic properties of muscles to perform auto-corrective movements to maintain balance.","In this paper, we propose a novel design of a robotic leg inspired by this mechanism.","We develop multi-material fibre jammed tendons, and demonstrate their use as passive compliant mechanisms to achieve variable joint stiffness and improve stability.","Through numerical simulations and extensive experimentation, we demonstrate the ability for our system to achieve a wide range of potentially beneficial compliance regimes.","We show the role and contribution of each tendon quantitatively by evaluating their individual force contribution in resisting rotational perturbations.","We also perform walking experiments with programmed bioinspired gaits that varying the stiffness of the tendons throughout the gait cycle, demonstrating a stable and consistent behaviour.","We show the potential of such systems when integrated into legged robots, where compliance and shock absorption can be provided entirely through the morphological properties of the leg."],"url":"http://arxiv.org/abs/2308.01758v1"}
{"created":"2023-08-03 13:24:21","title":"Quantifying Retrospective Human Responsibility in Intelligent Systems","abstract":"Intelligent systems have become a major part of our lives. Human responsibility for outcomes becomes unclear in the interaction with these systems, as parts of information acquisition, decision-making, and action implementation may be carried out jointly by humans and systems. Determining human causal responsibility with intelligent systems is particularly important in events that end with adverse outcomes. We developed three measures of retrospective human causal responsibility when using intelligent systems. The first measure concerns repetitive human interactions with a system. Using information theory, it quantifies the average human's unique contribution to the outcomes of past events. The second and third measures concern human causal responsibility in a single past interaction with an intelligent system. They quantify, respectively, the unique human contribution in forming the information used for decision-making and the reasonability of the actions that the human carried out. The results show that human retrospective responsibility depends on the combined effects of system design and its reliability, the human's role and authority, and probabilistic factors related to the system and the environment. The new responsibility measures can serve to investigate and analyze past events involving intelligent systems. They may aid the judgment of human responsibility and ethical and legal discussions, providing a novel quantitative perspective.","sentences":["Intelligent systems have become a major part of our lives.","Human responsibility for outcomes becomes unclear in the interaction with these systems, as parts of information acquisition, decision-making, and action implementation may be carried out jointly by humans and systems.","Determining human causal responsibility with intelligent systems is particularly important in events that end with adverse outcomes.","We developed three measures of retrospective human causal responsibility when using intelligent systems.","The first measure concerns repetitive human interactions with a system.","Using information theory, it quantifies the average human's unique contribution to the outcomes of past events.","The second and third measures concern human causal responsibility in a single past interaction with an intelligent system.","They quantify, respectively, the unique human contribution in forming the information used for decision-making and the reasonability of the actions that the human carried out.","The results show that human retrospective responsibility depends on the combined effects of system design and its reliability, the human's role and authority, and probabilistic factors related to the system and the environment.","The new responsibility measures can serve to investigate and analyze past events involving intelligent systems.","They may aid the judgment of human responsibility and ethical and legal discussions, providing a novel quantitative perspective."],"url":"http://arxiv.org/abs/2308.01752v1"}
{"created":"2023-08-03 13:22:05","title":"ManiVault: A Flexible and Extensible Visual Analytics Framework for High-Dimensional Data","abstract":"Exploration and analysis of high-dimensional data are important tasks in many fields that produce large and complex data, like the financial sector, systems biology, or cultural heritage. Tailor-made visual analytics software is developed for each specific application, limiting their applicability in other fields. However, as diverse as these fields are, their characteristics and requirements for data analysis are conceptually similar. Many applications share abstract tasks and data types and are often constructed with similar building blocks. Developing such applications, even when based mostly on existing building blocks, requires significant engineering efforts. We developed ManiVault, a flexible and extensible open-source visual analytics framework for analyzing high-dimensional data. The primary objective of ManiVault is to facilitate rapid prototyping of visual analytics workflows for visualization software developers and practitioners alike. ManiVault is built using a plugin-based architecture that offers easy extensibility. While our architecture deliberately keeps plugins self-contained, to guarantee maximum flexibility and re-usability, we have designed and implemented a messaging API for tight integration and linking of modules to support common visual analytics design patterns. We provide several visualization and analytics plugins, and ManiVault's API makes the integration of new plugins easy for developers. ManiVault facilitates the distribution of visualization and analysis pipelines and results for practitioners through saving and reproducing complete application states. As such, ManiVault can be used as a communication tool among researchers to discuss workflows and results. A copy of this paper and all supplemental material is available at https://osf.io/9k6jw and source code at https://github.com/ManiVaultStudio.","sentences":["Exploration and analysis of high-dimensional data are important tasks in many fields that produce large and complex data, like the financial sector, systems biology, or cultural heritage.","Tailor-made visual analytics software is developed for each specific application, limiting their applicability in other fields.","However, as diverse as these fields are, their characteristics and requirements for data analysis are conceptually similar.","Many applications share abstract tasks and data types and are often constructed with similar building blocks.","Developing such applications, even when based mostly on existing building blocks, requires significant engineering efforts.","We developed ManiVault, a flexible and extensible open-source visual analytics framework for analyzing high-dimensional data.","The primary objective of ManiVault is to facilitate rapid prototyping of visual analytics workflows for visualization software developers and practitioners alike.","ManiVault is built using a plugin-based architecture that offers easy extensibility.","While our architecture deliberately keeps plugins self-contained, to guarantee maximum flexibility and re-usability, we have designed and implemented a messaging API for tight integration and linking of modules to support common visual analytics design patterns.","We provide several visualization and analytics plugins, and ManiVault's API makes the integration of new plugins easy for developers.","ManiVault facilitates the distribution of visualization and analysis pipelines and results for practitioners through saving and reproducing complete application states.","As such, ManiVault can be used as a communication tool among researchers to discuss workflows and results.","A copy of this paper and all supplemental material is available at https://osf.io/9k6jw and source code at https://github.com/ManiVaultStudio."],"url":"http://arxiv.org/abs/2308.01751v1"}
{"created":"2023-08-03 13:12:50","title":"Entropy-based detection of Twitter echo chambers","abstract":"The presence of echo chambers, i.e. clusters of users exposed to news or opinions in line with their previous beliefs, was observed in many online debates on social platforms. Users form an echo chamber when two different phenomena appear at the same time: 1. users interact with ones sharing similar opinions; 2. users with similar opinions refer to the same pieces of news. We propose a completely unbiased entropy-based procedure to spot echo chambers. Remarkably, the method is completely agnostic about the nature of the data. In the Italian Twitter debate about Covid-19 vaccination, we find a limited presence of users in echo chambers (around 0.35% of all users), due to the limited number of validated users who are exposed to the same news. Nevertheless, their impact on the formation of a common discourse is strong, since echo chambers are responsible for nearly one-third of retweets of their discursive communities.","sentences":["The presence of echo chambers, i.e. clusters of users exposed to news or opinions in line with their previous beliefs, was observed in many online debates on social platforms.","Users form an echo chamber when two different phenomena appear at the same time: 1. users interact with ones sharing similar opinions;","2. users with similar opinions refer to the same pieces of news.","We propose a completely unbiased entropy-based procedure to spot echo chambers.","Remarkably, the method is completely agnostic about the nature of the data.","In the Italian Twitter debate about Covid-19 vaccination, we find a limited presence of users in echo chambers (around 0.35% of all users), due to the limited number of validated users who are exposed to the same news.","Nevertheless, their impact on the formation of a common discourse is strong, since echo chambers are responsible for nearly one-third of retweets of their discursive communities."],"url":"http://arxiv.org/abs/2308.01750v1"}
{"created":"2023-08-03 13:09:59","title":"Neural Collapse Terminus: A Unified Solution for Class Incremental Learning and Its Variants","abstract":"How to enable learnability for new classes while keeping the capability well on old classes has been a crucial challenge for class incremental learning. Beyond the normal case, long-tail class incremental learning and few-shot class incremental learning are also proposed to consider the data imbalance and data scarcity, respectively, which are common in real-world implementations and further exacerbate the well-known problem of catastrophic forgetting. Existing methods are specifically proposed for one of the three tasks. In this paper, we offer a unified solution to the misalignment dilemma in the three tasks. Concretely, we propose neural collapse terminus that is a fixed structure with the maximal equiangular inter-class separation for the whole label space. It serves as a consistent target throughout the incremental training to avoid dividing the feature space incrementally. For CIL and LTCIL, we further propose a prototype evolving scheme to drive the backbone features into our neural collapse terminus smoothly. Our method also works for FSCIL with only minor adaptations. Theoretical analysis indicates that our method holds the neural collapse optimality in an incremental fashion regardless of data imbalance or data scarcity. We also design a generalized case where we do not know the total number of classes and whether the data distribution is normal, long-tail, or few-shot for each coming session, to test the generalizability of our method. Extensive experiments with multiple datasets are conducted to demonstrate the effectiveness of our unified solution to all the three tasks and the generalized case.","sentences":["How to enable learnability for new classes while keeping the capability well on old classes has been a crucial challenge for class incremental learning.","Beyond the normal case, long-tail class incremental learning and few-shot class incremental learning are also proposed to consider the data imbalance and data scarcity, respectively, which are common in real-world implementations and further exacerbate the well-known problem of catastrophic forgetting.","Existing methods are specifically proposed for one of the three tasks.","In this paper, we offer a unified solution to the misalignment dilemma in the three tasks.","Concretely, we propose neural collapse terminus that is a fixed structure with the maximal equiangular inter-class separation for the whole label space.","It serves as a consistent target throughout the incremental training to avoid dividing the feature space incrementally.","For CIL and LTCIL, we further propose a prototype evolving scheme to drive the backbone features into our neural collapse terminus smoothly.","Our method also works for FSCIL with only minor adaptations.","Theoretical analysis indicates that our method holds the neural collapse optimality in an incremental fashion regardless of data imbalance or data scarcity.","We also design a generalized case where we do not know the total number of classes and whether the data distribution is normal, long-tail, or few-shot for each coming session, to test the generalizability of our method.","Extensive experiments with multiple datasets are conducted to demonstrate the effectiveness of our unified solution to all the three tasks and the generalized case."],"url":"http://arxiv.org/abs/2308.01746v1"}
{"created":"2023-08-03 13:08:09","title":"Multitask Learning with No Regret: from Improved Confidence Bounds to Active Learning","abstract":"Multitask learning is a powerful framework that enables one to simultaneously learn multiple related tasks by sharing information between them. Quantifying uncertainty in the estimated tasks is of pivotal importance for many downstream applications, such as online or active learning. In this work, we provide novel multitask confidence intervals in the challenging agnostic setting, i.e., when neither the similarity between tasks nor the tasks' features are available to the learner. The obtained intervals do not require i.i.d. data and can be directly applied to bound the regret in online learning. Through a refined analysis of the multitask information gain, we obtain new regret guarantees that, depending on a task similarity parameter, can significantly improve over treating tasks independently. We further propose a novel online learning algorithm that achieves such improved regret without knowing this parameter in advance, i.e., automatically adapting to task similarity. As a second key application of our results, we introduce a novel multitask active learning setup where several tasks must be simultaneously optimized, but only one of them can be queried for feedback by the learner at each round. For this problem, we design a no-regret algorithm that uses our confidence intervals to decide which task should be queried. Finally, we empirically validate our bounds and algorithms on synthetic and real-world (drug discovery) data.","sentences":["Multitask learning is a powerful framework that enables one to simultaneously learn multiple related tasks by sharing information between them.","Quantifying uncertainty in the estimated tasks is of pivotal importance for many downstream applications, such as online or active learning.","In this work, we provide novel multitask confidence intervals in the challenging agnostic setting, i.e., when neither the similarity between tasks nor the tasks' features are available to the learner.","The obtained intervals do not require i.i.d. data and can be directly applied to bound the regret in online learning.","Through a refined analysis of the multitask information gain, we obtain new regret guarantees that, depending on a task similarity parameter, can significantly improve over treating tasks independently.","We further propose a novel online learning algorithm that achieves such improved regret without knowing this parameter in advance, i.e., automatically adapting to task similarity.","As a second key application of our results, we introduce a novel multitask active learning setup where several tasks must be simultaneously optimized, but only one of them can be queried for feedback by the learner at each round.","For this problem, we design a no-regret algorithm that uses our confidence intervals to decide which task should be queried.","Finally, we empirically validate our bounds and algorithms on synthetic and real-world (drug discovery) data."],"url":"http://arxiv.org/abs/2308.01744v1"}
{"created":"2023-08-03 13:07:46","title":"Finding the Optimum Design of Large Gas Engines Prechambers Using CFD and Bayesian Optimization","abstract":"The turbulent jet ignition concept using prechambers is a promising solution to achieve stable combustion at lean conditions in large gas engines, leading to high efficiency at low emission levels. Due to the wide range of design and operating parameters for large gas engine prechambers, the preferred method for evaluating different designs is computational fluid dynamics (CFD), as testing in test bed measurement campaigns is time-consuming and expensive. However, the significant computational time required for detailed CFD simulations due to the complexity of solving the underlying physics also limits its applicability. In optimization settings similar to the present case, i.e., where the evaluation of the objective function(s) is computationally costly, Bayesian optimization has largely replaced classical design-of-experiment. Thus, the present study deals with the computationally efficient Bayesian optimization of large gas engine prechambers design using CFD simulation. Reynolds-averaged-Navier-Stokes simulations are used to determine the target values as a function of the selected prechamber design parameters. The results indicate that the chosen strategy is effective to find a prechamber design that achieves the desired target values.","sentences":["The turbulent jet ignition concept using prechambers is a promising solution to achieve stable combustion at lean conditions in large gas engines, leading to high efficiency at low emission levels.","Due to the wide range of design and operating parameters for large gas engine prechambers, the preferred method for evaluating different designs is computational fluid dynamics (CFD), as testing in test bed measurement campaigns is time-consuming and expensive.","However, the significant computational time required for detailed CFD simulations due to the complexity of solving the underlying physics also limits its applicability.","In optimization settings similar to the present case, i.e., where the evaluation of the objective function(s) is computationally costly, Bayesian optimization has largely replaced classical design-of-experiment.","Thus, the present study deals with the computationally efficient Bayesian optimization of large gas engine prechambers design using CFD simulation.","Reynolds-averaged-Navier-Stokes simulations are used to determine the target values as a function of the selected prechamber design parameters.","The results indicate that the chosen strategy is effective to find a prechamber design that achieves the desired target values."],"url":"http://arxiv.org/abs/2308.01743v1"}
{"created":"2023-08-03 13:06:45","title":"Exploiting Multi-Label Correlation in Label Distribution Learning","abstract":"Label Distribution Learning (LDL) is a novel machine learning paradigm that assigns label distribution to each instance. Many LDL methods proposed to leverage label correlation in the learning process to solve the exponential-sized output space; among these, many exploited the low-rank structure of label distribution to capture label correlation. However, recent studies disclosed that label distribution matrices are typically full-rank, posing challenges to those works exploiting low-rank label correlation. Note that multi-label is generally low-rank; low-rank label correlation is widely adopted in multi-label learning (MLL) literature. Inspired by that, we introduce an auxiliary MLL process in LDL and capture low-rank label correlation on that MLL rather than LDL. In such a way, low-rank label correlation is appropriately exploited in our LDL methods. We conduct comprehensive experiments and demonstrate that our methods are superior to existing LDL methods. Besides, the ablation studies justify the advantages of exploiting low-rank label correlation in the auxiliary MLL.","sentences":["Label Distribution Learning (LDL) is a novel machine learning paradigm that assigns label distribution to each instance.","Many LDL methods proposed to leverage label correlation in the learning process to solve the exponential-sized output space; among these, many exploited the low-rank structure of label distribution to capture label correlation.","However, recent studies disclosed that label distribution matrices are typically full-rank, posing challenges to those works exploiting low-rank label correlation.","Note that multi-label is generally low-rank; low-rank label correlation is widely adopted in multi-label learning (MLL) literature.","Inspired by that, we introduce an auxiliary MLL process in LDL and capture low-rank label correlation on that MLL rather than LDL.","In such a way, low-rank label correlation is appropriately exploited in our LDL methods.","We conduct comprehensive experiments and demonstrate that our methods are superior to existing LDL methods.","Besides, the ablation studies justify the advantages of exploiting low-rank label correlation in the auxiliary MLL."],"url":"http://arxiv.org/abs/2308.01742v1"}
{"created":"2023-08-03 13:06:37","title":"Supply chain emission estimation using large language models","abstract":"Large enterprises face a crucial imperative to achieve the Sustainable Development Goals (SDGs), especially goal 13, which focuses on combating climate change and its impacts. To mitigate the effects of climate change, reducing enterprise Scope 3 (supply chain emissions) is vital, as it accounts for more than 90\\% of total emission inventories. However, tracking Scope 3 emissions proves challenging, as data must be collected from thousands of upstream and downstream suppliers.To address the above mentioned challenges, we propose a first-of-a-kind framework that uses domain-adapted NLP foundation models to estimate Scope 3 emissions, by utilizing financial transactions as a proxy for purchased goods and services. We compared the performance of the proposed framework with the state-of-art text classification models such as TF-IDF, word2Vec, and Zero shot learning. Our results show that the domain-adapted foundation model outperforms state-of-the-art text mining techniques and performs as well as a subject matter expert (SME). The proposed framework could accelerate the Scope 3 estimation at Enterprise scale and will help to take appropriate climate actions to achieve SDG 13.","sentences":["Large enterprises face a crucial imperative to achieve the Sustainable Development Goals (SDGs), especially goal 13, which focuses on combating climate change and its impacts.","To mitigate the effects of climate change, reducing enterprise Scope 3 (supply chain emissions) is vital, as it accounts for more than 90\\% of total emission inventories.","However, tracking Scope 3 emissions proves challenging, as data must be collected from thousands of upstream and downstream suppliers.","To address the above mentioned challenges, we propose a first-of-a-kind framework that uses domain-adapted NLP foundation models to estimate Scope 3 emissions, by utilizing financial transactions as a proxy for purchased goods and services.","We compared the performance of the proposed framework with the state-of-art text classification models such as TF-IDF, word2Vec, and Zero shot learning.","Our results show that the domain-adapted foundation model outperforms state-of-the-art text mining techniques and performs as well as a subject matter expert (SME).","The proposed framework could accelerate the Scope 3 estimation at Enterprise scale and will help to take appropriate climate actions to achieve SDG 13."],"url":"http://arxiv.org/abs/2308.01741v1"}
{"created":"2023-08-03 12:58:23","title":"Enhancing Visibility in Nighttime Haze Images Using Guided APSF and Gradient Adaptive Convolution","abstract":"Visibility in hazy nighttime scenes is frequently reduced by multiple factors, including low light, intense glow, light scattering, and the presence of multicolored light sources. Existing nighttime dehazing methods often struggle with handling glow or low-light conditions, resulting in either excessively dark visuals or unsuppressed glow outputs. In this paper, we enhance the visibility from a single nighttime haze image by suppressing glow and enhancing low-light regions. To handle glow effects, our framework learns from the rendered glow pairs. Specifically, a light source aware network is proposed to detect light sources of night images, followed by the APSF (Angular Point Spread Function)-guided glow rendering. Our framework is then trained on the rendered images, resulting in glow suppression. Moreover, we utilize gradient-adaptive convolution, to capture edges and textures in hazy scenes. By leveraging extracted edges and textures, we enhance the contrast of the scene without losing important structural details. To boost low-light intensity, our network learns an attention map, then adjusted by gamma correction. This attention has high values on low-light regions and low values on haze and glow regions. Extensive evaluation on real nighttime haze images, demonstrates the effectiveness of our method. Our experiments demonstrate that our method achieves a PSNR of 30.72dB, outperforming state-of-the-art methods by 14$\\%$ on GTA5 nighttime haze dataset. Our data and code is available at: \\url{https://github.com/jinyeying/nighttime_dehaze}.","sentences":["Visibility in hazy nighttime scenes is frequently reduced by multiple factors, including low light, intense glow, light scattering, and the presence of multicolored light sources.","Existing nighttime dehazing methods often struggle with handling glow or low-light conditions, resulting in either excessively dark visuals or unsuppressed glow outputs.","In this paper, we enhance the visibility from a single nighttime haze image by suppressing glow and enhancing low-light regions.","To handle glow effects, our framework learns from the rendered glow pairs.","Specifically, a light source aware network is proposed to detect light sources of night images, followed by the APSF (Angular Point Spread Function)-guided glow rendering.","Our framework is then trained on the rendered images, resulting in glow suppression.","Moreover, we utilize gradient-adaptive convolution, to capture edges and textures in hazy scenes.","By leveraging extracted edges and textures, we enhance the contrast of the scene without losing important structural details.","To boost low-light intensity, our network learns an attention map, then adjusted by gamma correction.","This attention has high values on low-light regions and low values on haze and glow regions.","Extensive evaluation on real nighttime haze images, demonstrates the effectiveness of our method.","Our experiments demonstrate that our method achieves a PSNR of 30.72dB, outperforming state-of-the-art methods by 14$\\%$ on GTA5 nighttime haze dataset.","Our data and code is available at: \\url{https://github.com/jinyeying/nighttime_dehaze}."],"url":"http://arxiv.org/abs/2308.01738v1"}
{"created":"2023-08-03 12:55:55","title":"MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction","abstract":"With the widespread application of personalized online services, click-through rate (CTR) prediction has received more and more attention and research. The most prominent features of CTR prediction are its multi-field categorical data format, and vast and daily-growing data volume. The large capacity of neural models helps digest such massive amounts of data under the supervised learning paradigm, yet they fail to utilize the substantial data to its full potential, since the 1-bit click signal is not sufficient to guide the model to learn capable representations of features and instances. The self-supervised learning paradigm provides a more promising pretrain-finetune solution to better exploit the large amount of user click logs, and learn more generalized and effective representations. However, self-supervised learning for CTR prediction is still an open question, since current works on this line are only preliminary and rudimentary. To this end, we propose a Model-agnostic pretraining (MAP) framework that applies feature corruption and recovery on multi-field categorical data, and more specifically, we derive two practical algorithms: masked feature prediction (MFP) and replaced feature detection (RFD). MFP digs into feature interactions within each instance through masking and predicting a small portion of input features, and introduces noise contrastive estimation (NCE) to handle large feature spaces. RFD further turns MFP into a binary classification mode through replacing and detecting changes in input features, making it even simpler and more effective for CTR pretraining. Our extensive experiments on two real-world large-scale datasets (i.e., Avazu, Criteo) demonstrate the advantages of these two methods on several strong backbones (e.g., DCNv2, DeepFM), and achieve new state-of-the-art performance in terms of both effectiveness and efficiency for CTR prediction.","sentences":["With the widespread application of personalized online services, click-through rate (CTR) prediction has received more and more attention and research.","The most prominent features of CTR prediction are its multi-field categorical data format, and vast and daily-growing data volume.","The large capacity of neural models helps digest such massive amounts of data under the supervised learning paradigm, yet they fail to utilize the substantial data to its full potential, since the 1-bit click signal is not sufficient to guide the model to learn capable representations of features and instances.","The self-supervised learning paradigm provides a more promising pretrain-finetune solution to better exploit the large amount of user click logs, and learn more generalized and effective representations.","However, self-supervised learning for CTR prediction is still an open question, since current works on this line are only preliminary and rudimentary.","To this end, we propose a Model-agnostic pretraining (MAP) framework that applies feature corruption and recovery on multi-field categorical data, and more specifically, we derive two practical algorithms: masked feature prediction (MFP) and replaced feature detection (RFD).","MFP digs into feature interactions within each instance through masking and predicting a small portion of input features, and introduces noise contrastive estimation (NCE) to handle large feature spaces.","RFD further turns MFP into a binary classification mode through replacing and detecting changes in input features, making it even simpler and more effective for CTR pretraining.","Our extensive experiments on two real-world large-scale datasets (i.e., Avazu, Criteo) demonstrate the advantages of these two methods on several strong backbones (e.g., DCNv2, DeepFM), and achieve new state-of-the-art performance in terms of both effectiveness and efficiency for CTR prediction."],"url":"http://arxiv.org/abs/2308.01737v1"}
{"created":"2023-08-03 12:52:49","title":"Ambient Adventures: Teaching ChatGPT on Developing Complex Stories","abstract":"Imaginative play is an area of creativity that could allow robots to engage with the world around them in a much more personified way. Imaginary play can be seen as taking real objects and locations and using them as imaginary objects and locations in virtual scenarios. We adopted the story generation capability of large language models (LLMs) to obtain the stories used for imaginary play with human-written prompts. Those generated stories will be simplified and mapped into action sequences that can guide the agent in imaginary play. To evaluate whether the agent can successfully finish the imaginary play, we also designed a text adventure game to simulate a house as the playground for the agent to interact.","sentences":["Imaginative play is an area of creativity that could allow robots to engage with the world around them in a much more personified way.","Imaginary play can be seen as taking real objects and locations and using them as imaginary objects and locations in virtual scenarios.","We adopted the story generation capability of large language models (LLMs) to obtain the stories used for imaginary play with human-written prompts.","Those generated stories will be simplified and mapped into action sequences that can guide the agent in imaginary play.","To evaluate whether the agent can successfully finish the imaginary play, we also designed a text adventure game to simulate a house as the playground for the agent to interact."],"url":"http://arxiv.org/abs/2308.01734v1"}
{"created":"2023-08-03 12:48:32","title":"Towards Self-organizing Personal Knowledge Assistants in Evolving Corporate Memories","abstract":"This paper presents a retrospective overview of a decade of research in our department towards self-organizing personal knowledge assistants in evolving corporate memories. Our research is typically inspired by real-world problems and often conducted in interdisciplinary collaborations with research and industry partners. We summarize past experiments and results comprising topics like various ways of knowledge graph construction in corporate and personal settings, Managed Forgetting and (Self-organizing) Context Spaces as a novel approach to Personal Information Management (PIM) and knowledge work support. Past results are complemented by an overview of related work and some of our latest findings not published so far. Last, we give an overview of our related industry use cases including a detailed look into CoMem, a Corporate Memory based on our presented research already in productive use and providing challenges for further research. Many contributions are only first steps in new directions with still a lot of untapped potential, especially with regard to further increasing the automation in PIM and knowledge work support.","sentences":["This paper presents a retrospective overview of a decade of research in our department towards self-organizing personal knowledge assistants in evolving corporate memories.","Our research is typically inspired by real-world problems and often conducted in interdisciplinary collaborations with research and industry partners.","We summarize past experiments and results comprising topics like various ways of knowledge graph construction in corporate and personal settings, Managed Forgetting and (Self-organizing)","Context Spaces as a novel approach to Personal Information Management (PIM) and knowledge work support.","Past results are complemented by an overview of related work and some of our latest findings not published so far.","Last, we give an overview of our related industry use cases including a detailed look into CoMem, a Corporate Memory based on our presented research already in productive use and providing challenges for further research.","Many contributions are only first steps in new directions with still a lot of untapped potential, especially with regard to further increasing the automation in PIM and knowledge work support."],"url":"http://arxiv.org/abs/2308.01732v1"}
{"created":"2023-08-03 12:43:21","title":"Quantification of Predictive Uncertainty via Inference-Time Sampling","abstract":"Predictive variability due to data ambiguities has typically been addressed via construction of dedicated models with built-in probabilistic capabilities that are trained to predict uncertainty estimates as variables of interest. These approaches require distinct architectural components and training mechanisms, may include restrictive assumptions and exhibit overconfidence, i.e., high confidence in imprecise predictions. In this work, we propose a post-hoc sampling strategy for estimating predictive uncertainty accounting for data ambiguity. The method can generate different plausible outputs for a given input and does not assume parametric forms of predictive distributions. It is architecture agnostic and can be applied to any feed-forward deterministic network without changes to the architecture or training procedure. Experiments on regression tasks on imaging and non-imaging input data show the method's ability to generate diverse and multi-modal predictive distributions, and a desirable correlation of the estimated uncertainty with the prediction error.","sentences":["Predictive variability due to data ambiguities has typically been addressed via construction of dedicated models with built-in probabilistic capabilities that are trained to predict uncertainty estimates as variables of interest.","These approaches require distinct architectural components and training mechanisms, may include restrictive assumptions and exhibit overconfidence, i.e., high confidence in imprecise predictions.","In this work, we propose a post-hoc sampling strategy for estimating predictive uncertainty accounting for data ambiguity.","The method can generate different plausible outputs for a given input and does not assume parametric forms of predictive distributions.","It is architecture agnostic and can be applied to any feed-forward deterministic network without changes to the architecture or training procedure.","Experiments on regression tasks on imaging and non-imaging input data show the method's ability to generate diverse and multi-modal predictive distributions, and a desirable correlation of the estimated uncertainty with the prediction error."],"url":"http://arxiv.org/abs/2308.01731v1"}
{"created":"2023-08-03 12:36:13","title":"Local Large Language Models for Complex Structured Medical Tasks","abstract":"This paper introduces an approach that combines the language reasoning capabilities of large language models (LLMs) with the benefits of local training to tackle complex, domain-specific tasks. Specifically, the authors demonstrate their approach by extracting structured condition codes from pathology reports. The proposed approach utilizes local LLMs, which can be fine-tuned to respond to specific generative instructions and provide structured outputs. The authors collected a dataset of over 150k uncurated surgical pathology reports, containing gross descriptions, final diagnoses, and condition codes. They trained different model architectures, including LLaMA, BERT and LongFormer and evaluated their performance. The results show that the LLaMA-based models significantly outperform BERT-style models across all evaluated metrics, even with extremely reduced precision. The LLaMA models performed especially well with large datasets, demonstrating their ability to handle complex, multi-label tasks. Overall, this work presents an effective approach for utilizing LLMs to perform domain-specific tasks using accessible hardware, with potential applications in the medical domain, where complex data extraction and classification are required.","sentences":["This paper introduces an approach that combines the language reasoning capabilities of large language models (LLMs) with the benefits of local training to tackle complex, domain-specific tasks.","Specifically, the authors demonstrate their approach by extracting structured condition codes from pathology reports.","The proposed approach utilizes local LLMs, which can be fine-tuned to respond to specific generative instructions and provide structured outputs.","The authors collected a dataset of over 150k uncurated surgical pathology reports, containing gross descriptions, final diagnoses, and condition codes.","They trained different model architectures, including LLaMA, BERT and LongFormer and evaluated their performance.","The results show that the LLaMA-based models significantly outperform BERT-style models across all evaluated metrics, even with extremely reduced precision.","The LLaMA models performed especially well with large datasets, demonstrating their ability to handle complex, multi-label tasks.","Overall, this work presents an effective approach for utilizing LLMs to perform domain-specific tasks using accessible hardware, with potential applications in the medical domain, where complex data extraction and classification are required."],"url":"http://arxiv.org/abs/2308.01727v1"}
{"created":"2023-08-03 12:33:17","title":"NeuroSwarm: Multi-Agent Neural 3D Scene Reconstruction and Segmentation with UAV for Optimal Navigation of Quadruped Robot","abstract":"Quadruped robots have the distinct ability to adapt their body and step height to navigate through cluttered environments. Nonetheless, for these robots to utilize their full potential in real-world scenarios, they require awareness of their environment and obstacle geometry. We propose a novel multi-agent robotic system that incorporates cutting-edge technologies. The proposed solution features a 3D neural reconstruction algorithm that enables navigation of a quadruped robot in both static and semi-static environments. The prior areas of the environment are also segmented according to the quadruped robots' abilities to pass them. Moreover, we have developed an adaptive neural field optimal motion planner (ANFOMP) that considers both collision probability and obstacle height in 2D space.Our new navigation and mapping approach enables quadruped robots to adjust their height and behavior to navigate under arches and push through obstacles with smaller dimensions. The multi-agent mapping operation has proven to be highly accurate, with an obstacle reconstruction precision of 82%. Moreover, the quadruped robot can navigate with 3D obstacle information and the ANFOMP system, resulting in a 33.3% reduction in path length and a 70% reduction in navigation time.","sentences":["Quadruped robots have the distinct ability to adapt their body and step height to navigate through cluttered environments.","Nonetheless, for these robots to utilize their full potential in real-world scenarios, they require awareness of their environment and obstacle geometry.","We propose a novel multi-agent robotic system that incorporates cutting-edge technologies.","The proposed solution features a 3D neural reconstruction algorithm that enables navigation of a quadruped robot in both static and semi-static environments.","The prior areas of the environment are also segmented according to the quadruped robots' abilities to pass them.","Moreover, we have developed an adaptive neural field optimal motion planner (ANFOMP) that considers both collision probability and obstacle height in 2D space.","Our new navigation and mapping approach enables quadruped robots to adjust their height and behavior to navigate under arches and push through obstacles with smaller dimensions.","The multi-agent mapping operation has proven to be highly accurate, with an obstacle reconstruction precision of 82%.","Moreover, the quadruped robot can navigate with 3D obstacle information and the ANFOMP system, resulting in a 33.3% reduction in path length and a 70% reduction in navigation time."],"url":"http://arxiv.org/abs/2308.01725v1"}
{"created":"2023-08-03 12:31:24","title":"Relational hyperevent models for the coevolution of coauthoring and citation networks","abstract":"Interest in the network analysis of bibliographic data has increased significantly in recent years. Yet, appropriate statistical models for examining the full dynamics of scientific citation networks, connecting authors to the papers they write and papers to other papers they cite, are not available. Very few studies exist that have examined how the social network between co-authors and the citation network among the papers shape one another and co-evolve. In consequence, our understanding of scientific citation networks remains incomplete. In this paper we extend recently derived relational hyperevent models (RHEM) to the analysis of scientific networks, providing a general framework to model the multiple dependencies involved in the relation linking multiple authors to the papers they write, and papers to the multiple references they cite. We demonstrate the empirical value of our model in an analysis of publicly available data on a scientific network comprising millions of authors and papers and assess the relative strength of various effects explaining scientific production. We outline the implications of the model for the evaluation of scientific research.","sentences":["Interest in the network analysis of bibliographic data has increased significantly in recent years.","Yet, appropriate statistical models for examining the full dynamics of scientific citation networks, connecting authors to the papers they write and papers to other papers they cite, are not available.","Very few studies exist that have examined how the social network between co-authors and the citation network among the papers shape one another and co-evolve.","In consequence, our understanding of scientific citation networks remains incomplete.","In this paper we extend recently derived relational hyperevent models (RHEM) to the analysis of scientific networks, providing a general framework to model the multiple dependencies involved in the relation linking multiple authors to the papers they write, and papers to the multiple references they cite.","We demonstrate the empirical value of our model in an analysis of publicly available data on a scientific network comprising millions of authors and papers and assess the relative strength of various effects explaining scientific production.","We outline the implications of the model for the evaluation of scientific research."],"url":"http://arxiv.org/abs/2308.01722v1"}
{"created":"2023-08-03 12:30:52","title":"Weakly Supervised 3D Instance Segmentation without Instance-level Annotations","abstract":"3D semantic scene understanding tasks have achieved great success with the emergence of deep learning, but often require a huge amount of manually annotated training data. To alleviate the annotation cost, we propose the first weakly-supervised 3D instance segmentation method that only requires categorical semantic labels as supervision, and we do not need instance-level labels. The required semantic annotations can be either dense or extreme sparse (e.g. 0.02% of total points). Even without having any instance-related ground-truth, we design an approach to break point clouds into raw fragments and find the most confident samples for learning instance centroids. Furthermore, we construct a recomposed dataset using pseudo instances, which is used to learn our defined multilevel shape-aware objectness signal. An asymmetrical object inference algorithm is followed to process core points and boundary points with different strategies, and generate high-quality pseudo instance labels to guide iterative training. Experiments demonstrate that our method can achieve comparable results with recent fully supervised methods. By generating pseudo instance labels from categorical semantic labels, our designed approach can also assist existing methods for learning 3D instance segmentation at reduced annotation cost.","sentences":["3D semantic scene understanding tasks have achieved great success with the emergence of deep learning, but often require a huge amount of manually annotated training data.","To alleviate the annotation cost, we propose the first weakly-supervised 3D instance segmentation method that only requires categorical semantic labels as supervision, and we do not need instance-level labels.","The required semantic annotations can be either dense or extreme sparse (e.g. 0.02% of total points).","Even without having any instance-related ground-truth, we design an approach to break point clouds into raw fragments and find the most confident samples for learning instance centroids.","Furthermore, we construct a recomposed dataset using pseudo instances, which is used to learn our defined multilevel shape-aware objectness signal.","An asymmetrical object inference algorithm is followed to process core points and boundary points with different strategies, and generate high-quality pseudo instance labels to guide iterative training.","Experiments demonstrate that our method can achieve comparable results with recent fully supervised methods.","By generating pseudo instance labels from categorical semantic labels, our designed approach can also assist existing methods for learning 3D instance segmentation at reduced annotation cost."],"url":"http://arxiv.org/abs/2308.01721v1"}
{"created":"2023-08-03 12:25:33","title":"The Data Movement Bottleneck: Theoretical Shortcomings of Analog Optical Fourier Transform and Convolution Computing Accelerators","abstract":"Modern computing tasks are constrained to having digital electronic input and output data. Due to these constraints imposed by the user, any analog computing accelerator must perform an analog-to-digital conversion on its input data and a subsequent digital-to-analog conversion on its output data. To avoid this the analog hardware would need to completely replace the full functionality of traditional digital electronic computer hardware. Using 27 empirically-measured benchmarks we estimate that an ideal optical accelerator that accelerates Fourier transforms and convolutions can produce an average speedup of 9.4 times, and a median speedup of 1.9 times for the set of benchmarks. The maximum speedups achieved were 45.3 times for a pure Fourier transform and 159.4 times for a pure convolution. These results show that an optical accelerator only produces significant speedup for applications consisting exclusively of Fourier transforms and convolutions. In addition to the theoretical results we quantify the data movement bottleneck which causes a 23.8 times slowdown in a prototype optical Fourier transform accelerator which we built from widely-available off-the-shelf parts.","sentences":["Modern computing tasks are constrained to having digital electronic input and output data.","Due to these constraints imposed by the user, any analog computing accelerator must perform an analog-to-digital conversion on its input data and a subsequent digital-to-analog conversion on its output data.","To avoid this the analog hardware would need to completely replace the full functionality of traditional digital electronic computer hardware.","Using 27 empirically-measured benchmarks we estimate that an ideal optical accelerator that accelerates Fourier transforms and convolutions can produce an average speedup of 9.4 times, and a median speedup of 1.9 times for the set of benchmarks.","The maximum speedups achieved were 45.3 times for a pure Fourier transform and 159.4 times for a pure convolution.","These results show that an optical accelerator only produces significant speedup for applications consisting exclusively of Fourier transforms and convolutions.","In addition to the theoretical results we quantify the data movement bottleneck which causes a 23.8 times slowdown in a prototype optical Fourier transform accelerator which we built from widely-available off-the-shelf parts."],"url":"http://arxiv.org/abs/2308.01719v1"}
{"created":"2023-08-03 12:13:43","title":"Experiments on Computer Networks: Quickly Knowing the Protocols in the TCP/IP Suite","abstract":"Manual of practical experiments on protocols used in the Internet or TCP/IP Suite. This manual is a collection of experiments that are used in undergraduate and graduate courses taught at New Jersey Institute of Technology for a few years. The manual is updated periodically to accommodate emerging needs and technologies, including virtualization of the experiments for their use during lockdowns as the one experienced during COVID-19 in 2020 and part of 2021. The manual may be used by all those interested in knowing and experiencing some of the basic protocols that run on the Internet and by practitioners. The goal is to get some understanding on protocol design and not necessarily on a particular software or operative system.","sentences":["Manual of practical experiments on protocols used in the Internet or TCP/IP Suite.","This manual is a collection of experiments that are used in undergraduate and graduate courses taught at New Jersey Institute of Technology for a few years.","The manual is updated periodically to accommodate emerging needs and technologies, including virtualization of the experiments for their use during lockdowns as the one experienced during COVID-19 in 2020 and part of 2021.","The manual may be used by all those interested in knowing and experiencing some of the basic protocols that run on the Internet and by practitioners.","The goal is to get some understanding on protocol design and not necessarily on a particular software or operative system."],"url":"http://arxiv.org/abs/2308.01713v1"}
{"created":"2023-08-03 11:59:38","title":"Joint Out-of-Distribution Detection and Uncertainty Estimation for Trajectory Predictio","abstract":"Despite the significant research efforts on trajectory prediction for automated driving, limited work exists on assessing the prediction reliability. To address this limitation we propose an approach that covers two sources of error, namely novel situations with out-of-distribution (OOD) detection and the complexity in in-distribution (ID) situations with uncertainty estimation. We introduce two modules next to an encoder-decoder network for trajectory prediction. Firstly, a Gaussian mixture model learns the probability density function of the ID encoder features during training, and then it is used to detect the OOD samples in regions of the feature space with low likelihood. Secondly, an error regression network is applied to the encoder, which learns to estimate the trajectory prediction error in supervised training. During inference, the estimated prediction error is used as the uncertainty. In our experiments, the combination of both modules outperforms the prior work in OOD detection and uncertainty estimation, on the Shifts robust trajectory prediction dataset by $2.8 \\%$ and $10.1 \\%$, respectively. The code is publicly available.","sentences":["Despite the significant research efforts on trajectory prediction for automated driving, limited work exists on assessing the prediction reliability.","To address this limitation we propose an approach that covers two sources of error, namely novel situations with out-of-distribution (OOD) detection and the complexity in in-distribution (ID) situations with uncertainty estimation.","We introduce two modules next to an encoder-decoder network for trajectory prediction.","Firstly, a Gaussian mixture model learns the probability density function of the ID encoder features during training, and then it is used to detect the OOD samples in regions of the feature space with low likelihood.","Secondly, an error regression network is applied to the encoder, which learns to estimate the trajectory prediction error in supervised training.","During inference, the estimated prediction error is used as the uncertainty.","In our experiments, the combination of both modules outperforms the prior work in OOD detection and uncertainty estimation, on the Shifts robust trajectory prediction dataset by $2.8 \\%$ and $10.1 \\%$, respectively.","The code is publicly available."],"url":"http://arxiv.org/abs/2308.01707v1"}
{"created":"2023-08-03 11:46:23","title":"Anonymity Analysis of the Umbra Stealth Address Scheme on Ethereum","abstract":"Stealth addresses are a privacy-enhancing technology that provides recipient anonymity on blockchains. In this work, we investigate the recipient anonymity and unlinkability guarantees of Umbra, the most widely used implementation of the stealth address scheme on Ethereum, and its three off-chain scalability solutions, e.g., Arbitrum, Optimism, and Polygon. We define and evaluate four heuristics to uncover the real recipients of stealth payments. We find that for the majority of Umbra payments, it is straightforward to establish the recipient, hence nullifying the benefits of using Umbra. Specifically, we find the real recipient of $48.5\\%$, $25.8\\%$, $65.7\\%$, and $52.6\\%$ of all Umbra transactions on the Ethereum main net, Polygon, Arbitrum, and Optimism networks, respectively. Finally, we suggest easily implementable countermeasures to evade our deanonymization and linking attacks.","sentences":["Stealth addresses are a privacy-enhancing technology that provides recipient anonymity on blockchains.","In this work, we investigate the recipient anonymity and unlinkability guarantees of Umbra, the most widely used implementation of the stealth address scheme on Ethereum, and its three off-chain scalability solutions, e.g., Arbitrum, Optimism, and Polygon.","We define and evaluate four heuristics to uncover the real recipients of stealth payments.","We find that for the majority of Umbra payments, it is straightforward to establish the recipient, hence nullifying the benefits of using Umbra.","Specifically, we find the real recipient of $48.5\\%$, $25.8\\%$, $65.7\\%$, and $52.6\\%$ of all Umbra transactions on the Ethereum main net, Polygon, Arbitrum, and Optimism networks, respectively.","Finally, we suggest easily implementable countermeasures to evade our deanonymization and linking attacks."],"url":"http://arxiv.org/abs/2308.01703v1"}
{"created":"2023-08-03 11:34:11","title":"Bees Local Phase Quantization Feature Selection for RGB-D Facial Expressions Recognition","abstract":"Feature selection could be defined as an optimization problem and solved by bio-inspired algorithms. Bees Algorithm (BA) shows decent performance in feature selection optimization tasks. On the other hand, Local Phase Quantization (LPQ) is a frequency domain feature which has excellent performance on Depth images. Here, after extracting LPQ features out of RGB (colour) and Depth images from the Iranian Kinect Face Database (IKFDB), the Bees feature selection algorithm applies to select the desired number of features for final classification tasks. IKFDB is recorded with Kinect sensor V.2 and contains colour and depth images for facial and facial micro-expressions recognition purposes. Here five facial expressions of Anger, Joy, Surprise, Disgust and Fear are used for final validation. The proposed Bees LPQ method is compared with Particle Swarm Optimization (PSO) LPQ, PCA LPQ, Lasso LPQ, and just LPQ features for classification tasks with Support Vector Machines (SVM), K-Nearest Neighbourhood (KNN), Shallow Neural Network and Ensemble Subspace KNN. Returned results, show a decent performance of the proposed algorithm (99 % accuracy) in comparison with others.","sentences":["Feature selection could be defined as an optimization problem and solved by bio-inspired algorithms.","Bees Algorithm (BA) shows decent performance in feature selection optimization tasks.","On the other hand, Local Phase Quantization (LPQ) is a frequency domain feature which has excellent performance on Depth images.","Here, after extracting LPQ features out of RGB (colour) and Depth images from the Iranian Kinect Face Database (IKFDB), the Bees feature selection algorithm applies to select the desired number of features for final classification tasks.","IKFDB is recorded with Kinect sensor V.2 and contains colour and depth images for facial and facial micro-expressions recognition purposes.","Here five facial expressions of Anger, Joy, Surprise, Disgust and Fear are used for final validation.","The proposed Bees LPQ method is compared with Particle Swarm Optimization (PSO) LPQ, PCA LPQ, Lasso LPQ, and just LPQ features for classification tasks with Support Vector Machines (SVM), K-Nearest Neighbourhood (KNN), Shallow Neural Network and Ensemble Subspace KNN.","Returned results, show a decent performance of the proposed algorithm (99 % accuracy) in comparison with others."],"url":"http://arxiv.org/abs/2308.01700v1"}
