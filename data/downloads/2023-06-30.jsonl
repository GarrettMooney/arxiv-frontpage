{"created":"2023-06-29","title":"RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot","abstract":"Performance bugs are non-functional bugs that can even manifest in well-tested commercial products. Fixing these performance bugs is an important yet challenging problem. In this work, we address this challenge and present a new approach called Retrieval-Augmented Prompt Generation (RAPGen). Given a code snippet with a performance issue, RAPGen first retrieves a prompt instruction from a pre-constructed knowledge-base of previous performance bug fixes and then generates a prompt using the retrieved instruction. It then uses this prompt on a Large Language Model (such as Codex) in zero-shot to generate a fix. We compare our approach with the various prompt variations and state of the art methods in the task of performance bug fixing. Our evaluation shows that RAPGen can generate performance improvement suggestions equivalent or better than a developer in ~60% of the cases, getting ~39% of them verbatim, in an expert-verified dataset of past performance changes made by C# developers.","sentences":["Performance bugs are non-functional bugs that can even manifest in well-tested commercial products.","Fixing these performance bugs is an important yet challenging problem.","In this work, we address this challenge and present a new approach called Retrieval-Augmented Prompt Generation (RAPGen).","Given a code snippet with a performance issue, RAPGen first retrieves a prompt instruction from a pre-constructed knowledge-base of previous performance bug fixes and then generates a prompt using the retrieved instruction.","It then uses this prompt on a Large Language Model (such as Codex) in zero-shot to generate a fix.","We compare our approach with the various prompt variations and state of the art methods in the task of performance bug fixing.","Our evaluation shows that RAPGen can generate performance improvement suggestions equivalent or better than a developer in ~60% of the cases, getting ~39% of them verbatim, in an expert-verified dataset of past performance changes made by C# developers."],"url":"http://arxiv.org/abs/2306.17077v1"}
{"created":"2023-06-29","title":"Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors","abstract":"Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies for introductory programming. Recent works have studied these models for different scenarios relevant to programming education; however, these works are limited for several reasons, as they typically consider already outdated models or only specific scenario(s). Consequently, there is a lack of a systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios. We evaluate using five introductory Python programming problems and real-world buggy programs from an online platform, and assess performance using expert-based annotations. Our results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors' performance for several scenarios. These results also highlight settings where GPT-4 still struggles, providing exciting future directions on developing techniques to improve the performance of these models.","sentences":["Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies for introductory programming.","Recent works have studied these models for different scenarios relevant to programming education; however, these works are limited for several reasons, as they typically consider already outdated models or only specific scenario(s).","Consequently, there is a lack of a systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios.","In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios.","We evaluate using five introductory Python programming problems and real-world buggy programs from an online platform, and assess performance using expert-based annotations.","Our results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors' performance for several scenarios.","These results also highlight settings where GPT-4 still struggles, providing exciting future directions on developing techniques to improve the performance of these models."],"url":"http://arxiv.org/abs/2306.17156v1"}
{"created":"2023-06-29","title":"LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT","abstract":"We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic lyrics transcription method achieving state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal. Our novel, training-free approach utilizes Whisper, a weakly supervised robust speech recognition model, and GPT-4, today's most performant chat-based large language model. In the proposed method, Whisper functions as the \"ear\" by transcribing the audio, while GPT-4 serves as the \"brain,\" acting as an annotator with a strong performance for contextualized output selection and correction. Our experiments show that LyricWhiz significantly reduces Word Error Rate compared to existing methods in English and can effectively transcribe lyrics across multiple languages. Furthermore, we use LyricWhiz to create the first publicly available, large-scale, multilingual lyrics transcription dataset with a CC-BY-NC-SA copyright license, based on MTG-Jamendo, and offer a human-annotated subset for noise level estimation and evaluation. We anticipate that our proposed method and dataset will advance the development of multilingual lyrics transcription, a challenging and emerging task.","sentences":["We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic lyrics transcription method achieving state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal.","Our novel, training-free approach utilizes Whisper, a weakly supervised robust speech recognition model, and GPT-4, today's most performant chat-based large language model.","In the proposed method, Whisper functions as the \"ear\" by transcribing the audio, while GPT-4 serves as the \"brain,\" acting as an annotator with a strong performance for contextualized output selection and correction.","Our experiments show that LyricWhiz significantly reduces Word Error Rate compared to existing methods in English and can effectively transcribe lyrics across multiple languages.","Furthermore, we use LyricWhiz to create the first publicly available, large-scale, multilingual lyrics transcription dataset with a CC-BY-NC-SA copyright license, based on MTG-Jamendo, and offer a human-annotated subset for noise level estimation and evaluation.","We anticipate that our proposed method and dataset will advance the development of multilingual lyrics transcription, a challenging and emerging task."],"url":"http://arxiv.org/abs/2306.17103v1"}
{"created":"2023-06-29","title":"UMASS_BioNLP at MEDIQA-Chat 2023: Can LLMs generate high-quality synthetic note-oriented doctor-patient conversations?","abstract":"This paper presents UMASS_BioNLP team participation in the MEDIQA-Chat 2023 shared task for Task-A and Task-C. We focus especially on Task-C and propose a novel LLMs cooperation system named a doctor-patient loop to generate high-quality conversation data sets. The experiment results demonstrate that our approaches yield reasonable performance as evaluated by automatic metrics such as ROUGE, medical concept recall, BLEU, and Self-BLEU. Furthermore, we conducted a comparative analysis between our proposed method and ChatGPT and GPT-4. This analysis also investigates the potential of utilizing cooperation LLMs to generate high-quality datasets.","sentences":["This paper presents UMASS_BioNLP team participation in the MEDIQA-Chat 2023 shared task for Task-A and Task-C. We focus especially on Task-C and propose a novel LLMs cooperation system named a doctor-patient loop to generate high-quality conversation data sets.","The experiment results demonstrate that our approaches yield reasonable performance as evaluated by automatic metrics such as ROUGE, medical concept recall, BLEU, and Self-BLEU.","Furthermore, we conducted a comparative analysis between our proposed method and ChatGPT and GPT-4.","This analysis also investigates the potential of utilizing cooperation LLMs to generate high-quality datasets."],"url":"http://arxiv.org/abs/2306.16931v1"}
{"created":"2023-06-29","title":"Evaluating ChatGPT's Decimal Skills and Feedback Generation in a Digital Learning Game","abstract":"While open-ended self-explanations have been shown to promote robust learning in multiple studies, they pose significant challenges to automated grading and feedback in technology-enhanced learning, due to the unconstrained nature of the students' input. Our work investigates whether recent advances in Large Language Models, and in particular ChatGPT, can address this issue. Using decimal exercises and student data from a prior study of the learning game Decimal Point, with more than 5,000 open-ended self-explanation responses, we investigate ChatGPT's capability in (1) solving the in-game exercises, (2) determining the correctness of students' answers, and (3) providing meaningful feedback to incorrect answers. Our results showed that ChatGPT can respond well to conceptual questions, but struggled with decimal place values and number line problems. In addition, it was able to accurately assess the correctness of 75% of the students' answers and generated generally high-quality feedback, similar to human instructors. We conclude with a discussion of ChatGPT's strengths and weaknesses and suggest several venues for extending its use cases in digital teaching and learning.","sentences":["While open-ended self-explanations have been shown to promote robust learning in multiple studies, they pose significant challenges to automated grading and feedback in technology-enhanced learning, due to the unconstrained nature of the students' input.","Our work investigates whether recent advances in Large Language Models, and in particular ChatGPT, can address this issue.","Using decimal exercises and student data from a prior study of the learning game Decimal Point, with more than 5,000 open-ended self-explanation responses, we investigate ChatGPT's capability in (1) solving the in-game exercises, (2) determining the correctness of students' answers, and (3) providing meaningful feedback to incorrect answers.","Our results showed that ChatGPT can respond well to conceptual questions, but struggled with decimal place values and number line problems.","In addition, it was able to accurately assess the correctness of 75% of the students' answers and generated generally high-quality feedback, similar to human instructors.","We conclude with a discussion of ChatGPT's strengths and weaknesses and suggest several venues for extending its use cases in digital teaching and learning."],"url":"http://arxiv.org/abs/2306.16639v1"}
{"created":"2023-06-29","title":"An Efficient General-Purpose Modular Vision Model via Multi-Task Heterogeneous Training","abstract":"We present a model that can perform multiple vision tasks and can be adapted to other downstream tasks efficiently. Despite considerable progress in multi-task learning, most efforts focus on learning from multi-label data: a single image set with multiple task labels. Such multi-label data sets are rare, small, and expensive. We say heterogeneous to refer to image sets with different task labels, or to combinations of single-task datasets. Few have explored training on such heterogeneous datasets. General-purpose vision models are still dominated by single-task pretraining, and it remains unclear how to scale up multi-task models by leveraging mainstream vision datasets designed for different purposes. The challenges lie in managing large intrinsic differences among vision tasks, including data distribution, architectures, task-specific modules, dataset scales, and sampling strategies. To address these challenges, we propose to modify and scale up mixture-of-experts (MoE) vision transformers, so that they can simultaneously learn classification, detection, and segmentation on diverse mainstream vision datasets including ImageNet, COCO, and ADE20K. Our approach achieves comparable results to single-task state-of-the-art models and demonstrates strong generalization on downstream tasks. Due to its emergent modularity, this general-purpose model decomposes into high-performing components, efficiently adapting to downstream tasks. We can fine-tune it with fewer training parameters, fewer model parameters, and less computation. Additionally, its modularity allows for easy expansion in continual-learning-without-forgetting scenarios. Finally, these functions can be controlled and combined to meet various demands of downstream tasks.","sentences":["We present a model that can perform multiple vision tasks and can be adapted to other downstream tasks efficiently.","Despite considerable progress in multi-task learning, most efforts focus on learning from multi-label data: a single image set with multiple task labels.","Such multi-label data sets are rare, small, and expensive.","We say heterogeneous to refer to image sets with different task labels, or to combinations of single-task datasets.","Few have explored training on such heterogeneous datasets.","General-purpose vision models are still dominated by single-task pretraining, and it remains unclear how to scale up multi-task models by leveraging mainstream vision datasets designed for different purposes.","The challenges lie in managing large intrinsic differences among vision tasks, including data distribution, architectures, task-specific modules, dataset scales, and sampling strategies.","To address these challenges, we propose to modify and scale up mixture-of-experts (MoE) vision transformers, so that they can simultaneously learn classification, detection, and segmentation on diverse mainstream vision datasets including ImageNet, COCO, and","ADE20K.","Our approach achieves comparable results to single-task state-of-the-art models and demonstrates strong generalization on downstream tasks.","Due to its emergent modularity, this general-purpose model decomposes into high-performing components, efficiently adapting to downstream tasks.","We can fine-tune it with fewer training parameters, fewer model parameters, and less computation.","Additionally, its modularity allows for easy expansion in continual-learning-without-forgetting scenarios.","Finally, these functions can be controlled and combined to meet various demands of downstream tasks."],"url":"http://arxiv.org/abs/2306.17165v1"}
{"created":"2023-06-29","title":"Can Machines Garden? Systematically Comparing the AlphaGarden vs. Professional Horticulturalists","abstract":"The AlphaGarden is an automated testbed for indoor polyculture farming which combines a first-order plant simulator, a gantry robot, a seed planting algorithm, plant phenotyping and tracking algorithms, irrigation sensors and algorithms, and custom pruning tools and algorithms. In this paper, we systematically compare the performance of the AlphaGarden to professional horticulturalists on the staff of the UC Berkeley Oxford Tract Greenhouse. The humans and the machine tend side-by-side polyculture gardens with the same seed arrangement. We compare performance in terms of canopy coverage, plant diversity, and water consumption. Results from two 60-day cycles suggest that the automated AlphaGarden performs comparably to professional horticulturalists in terms of coverage and diversity, and reduces water consumption by as much as 44%. Code, videos, and datasets are available at https://sites.google.com/berkeley.edu/systematiccomparison.","sentences":["The AlphaGarden is an automated testbed for indoor polyculture farming which combines a first-order plant simulator, a gantry robot, a seed planting algorithm, plant phenotyping and tracking algorithms, irrigation sensors and algorithms, and custom pruning tools and algorithms.","In this paper, we systematically compare the performance of the AlphaGarden to professional horticulturalists on the staff of the UC Berkeley Oxford Tract Greenhouse.","The humans and the machine tend side-by-side polyculture gardens with the same seed arrangement.","We compare performance in terms of canopy coverage, plant diversity, and water consumption.","Results from two 60-day cycles suggest that the automated AlphaGarden performs comparably to professional horticulturalists in terms of coverage and diversity, and reduces water consumption by as much as 44%.","Code, videos, and datasets are available at https://sites.google.com/berkeley.edu/systematiccomparison."],"url":"http://arxiv.org/abs/2306.17162v1"}
{"created":"2023-06-29","title":"Nonlinear Data-Driven Control Part II: qLPV Predictive Control using Parameter Extrapolation","abstract":"We present a novel data-driven Model Predictive Control (MPC) algorithm for nonlinear systems. The method is based on recent extensions of behavioural theory and Willem's Fundamental Lemma for nonlinear systems by the means of adequate Input-Output (IO) quasi-Linear Parameter Varying (qLPV) embeddings. Thus, the MPC is formulated to ensure regulation and IO constraints satisfaction, based only on measured datasets of sufficient length (and under persistent excitation). Instead of requiring the availability of the scheduling trajectories (as in recent papers), we consider an estimate of the function that maps the qLPV realisation. Specifically, we use an extrapolation procedure in order to generate the future scheduling trajectories, at each sample, which is shown to be convergent and generated bounded errors. Accordingly, we discuss the issues of closed-loop IO stability and recursive feasibility certificates of the method. The algorithm is tested and discussed with the aid of a numerical application.","sentences":["We present a novel data-driven Model Predictive Control (MPC) algorithm for nonlinear systems.","The method is based on recent extensions of behavioural theory and Willem's Fundamental Lemma for nonlinear systems by the means of adequate Input-Output (IO) quasi-Linear Parameter Varying (qLPV) embeddings.","Thus, the MPC is formulated to ensure regulation and IO constraints satisfaction, based only on measured datasets of sufficient length (and under persistent excitation).","Instead of requiring the availability of the scheduling trajectories (as in recent papers), we consider an estimate of the function that maps the qLPV realisation.","Specifically, we use an extrapolation procedure in order to generate the future scheduling trajectories, at each sample, which is shown to be convergent and generated bounded errors.","Accordingly, we discuss the issues of closed-loop IO stability and recursive feasibility certificates of the method.","The algorithm is tested and discussed with the aid of a numerical application."],"url":"http://arxiv.org/abs/2306.17139v1"}
{"created":"2023-06-29","title":"Orbit Classification of asteroids using implementation of radial Basis Function on Support Vector Machines","abstract":"This research paper focuses on the implementation of radial Basis Function (RBF) Support Vector Machines (SVM) for classifying asteroid orbits. Asteroids are important astronomical objects, and their orbits play a crucial role in understanding the dynamics of the solar system. The International Astronomical Union maintains data archives that provide a playground to experiment with various machine-learning techniques. In this study, we explore the application of RBF SVM algorithm to classify asteroids. The results show that the RBF SVM algorithm provides a good efficiency and accuracy to the dataset. We also analyze the impact of various parameters on the performance of the RBF SVM algorithm and present the optimal parameter settings. Our study highlights the importance of using machine learning techniques for classifying asteroid orbits and the effectiveness of the RBF SVM algorithm in this regard.","sentences":["This research paper focuses on the implementation of radial Basis Function (RBF) Support Vector Machines (SVM) for classifying asteroid orbits.","Asteroids are important astronomical objects, and their orbits play a crucial role in understanding the dynamics of the solar system.","The International Astronomical Union maintains data archives that provide a playground to experiment with various machine-learning techniques.","In this study, we explore the application of RBF SVM algorithm to classify asteroids.","The results show that the RBF SVM algorithm provides a good efficiency and accuracy to the dataset.","We also analyze the impact of various parameters on the performance of the RBF SVM algorithm and present the optimal parameter settings.","Our study highlights the importance of using machine learning techniques for classifying asteroid orbits and the effectiveness of the RBF SVM algorithm in this regard."],"url":"http://arxiv.org/abs/2306.17138v1"}
{"created":"2023-06-29","title":"Footprints of the QCD Crossover on Cosmological Gravitational Waves at Pulsar Timing Arrays","abstract":"Pulsar Timing Arrays (PTAs) have reported evidence for a stochastic gravitational wave (GW) background at nHz frequencies, possibly originating in the early Universe. We show that the spectral shape of the low-frequency (causality) tail of GW signals sourced at temperatures around $T\\gtrsim 1$ GeV is distinctively affected by confinement of strong interactions (QCD), due to the corresponding sharp decrease in the number of relativistic species. A Bayesian analysis in the latest International PTA dataset reveals a significant improvement in the fit with respect to cubic power law spectra, previously employed for the causality tail. Comparison with the results of NANOGrav 15 years and European PTA Data Release 2 suggests that our inclusion of Standard Model effects on GWs can have a potentially decisive impact on model selection.","sentences":["Pulsar Timing Arrays (PTAs) have reported evidence for a stochastic gravitational wave (GW) background at nHz frequencies, possibly originating in the early Universe.","We show that the spectral shape of the low-frequency (causality) tail of GW signals sourced at temperatures around $T\\gtrsim 1$ GeV is distinctively affected by confinement of strong interactions (QCD), due to the corresponding sharp decrease in the number of relativistic species.","A Bayesian analysis in the latest International PTA dataset reveals a significant improvement in the fit with respect to cubic power law spectra, previously employed for the causality tail.","Comparison with the results of NANOGrav 15 years and European PTA Data Release 2 suggests that our inclusion of Standard Model effects on GWs can have a potentially decisive impact on model selection."],"url":"http://arxiv.org/abs/2306.17136v1"}
{"created":"2023-06-29","title":"PVP: Personalized Video Prior for Editable Dynamic Portraits using StyleGAN","abstract":"Portrait synthesis creates realistic digital avatars which enable users to interact with others in a compelling way. Recent advances in StyleGAN and its extensions have shown promising results in synthesizing photorealistic and accurate reconstruction of human faces. However, previous methods often focus on frontal face synthesis and most methods are not able to handle large head rotations due to the training data distribution of StyleGAN. In this work, our goal is to take as input a monocular video of a face, and create an editable dynamic portrait able to handle extreme head poses. The user can create novel viewpoints, edit the appearance, and animate the face. Our method utilizes pivotal tuning inversion (PTI) to learn a personalized video prior from a monocular video sequence. Then we can input pose and expression coefficients to MLPs and manipulate the latent vectors to synthesize different viewpoints and expressions of the subject. We also propose novel loss functions to further disentangle pose and expression in the latent space. Our algorithm shows much better performance over previous approaches on monocular video datasets, and it is also capable of running in real-time at 54 FPS on an RTX 3080.","sentences":["Portrait synthesis creates realistic digital avatars which enable users to interact with others in a compelling way.","Recent advances in StyleGAN and its extensions have shown promising results in synthesizing photorealistic and accurate reconstruction of human faces.","However, previous methods often focus on frontal face synthesis and most methods are not able to handle large head rotations due to the training data distribution of StyleGAN.","In this work, our goal is to take as input a monocular video of a face, and create an editable dynamic portrait able to handle extreme head poses.","The user can create novel viewpoints, edit the appearance, and animate the face.","Our method utilizes pivotal tuning inversion (PTI) to learn a personalized video prior from a monocular video sequence.","Then we can input pose and expression coefficients to MLPs and manipulate the latent vectors to synthesize different viewpoints and expressions of the subject.","We also propose novel loss functions to further disentangle pose and expression in the latent space.","Our algorithm shows much better performance over previous approaches on monocular video datasets, and it is also capable of running in real-time at 54 FPS on an RTX 3080."],"url":"http://arxiv.org/abs/2306.17123v1"}
{"created":"2023-06-29","title":"Learning Nuclei Representations with Masked Image Modelling","abstract":"Masked image modelling (MIM) is a powerful self-supervised representation learning paradigm, whose potential has not been widely demonstrated in medical image analysis. In this work, we show the capacity of MIM to capture rich semantic representations of Haemotoxylin & Eosin (H&E)-stained images at the nuclear level. Inspired by Bidirectional Encoder representation from Image Transformers (BEiT), we split the images into smaller patches and generate corresponding discrete visual tokens. In addition to the regular grid-based patches, typically used in visual Transformers, we introduce patches of individual cell nuclei. We propose positional encoding of the irregular distribution of these structures within an image. We pre-train the model in a self-supervised manner on H&E-stained whole-slide images of diffuse large B-cell lymphoma, where cell nuclei have been segmented. The pre-training objective is to recover the original discrete visual tokens of the masked image on the one hand, and to reconstruct the visual tokens of the masked object instances on the other. Coupling these two pre-training tasks allows us to build powerful, context-aware representations of nuclei. Our model generalizes well and can be fine-tuned on downstream classification tasks, achieving improved cell classification accuracy on PanNuke dataset by more than 5% compared to current instance segmentation methods.","sentences":["Masked image modelling (MIM) is a powerful self-supervised representation learning paradigm, whose potential has not been widely demonstrated in medical image analysis.","In this work, we show the capacity of MIM to capture rich semantic representations of Haemotoxylin & Eosin (H&E)-stained images at the nuclear level.","Inspired by Bidirectional Encoder representation from Image Transformers (BEiT), we split the images into smaller patches and generate corresponding discrete visual tokens.","In addition to the regular grid-based patches, typically used in visual Transformers, we introduce patches of individual cell nuclei.","We propose positional encoding of the irregular distribution of these structures within an image.","We pre-train the model in a self-supervised manner on H&E-stained whole-slide images of diffuse large B-cell lymphoma, where cell nuclei have been segmented.","The pre-training objective is to recover the original discrete visual tokens of the masked image on the one hand, and to reconstruct the visual tokens of the masked object instances on the other.","Coupling these two pre-training tasks allows us to build powerful, context-aware representations of nuclei.","Our model generalizes well and can be fine-tuned on downstream classification tasks, achieving improved cell classification accuracy on PanNuke dataset by more than 5% compared to current instance segmentation methods."],"url":"http://arxiv.org/abs/2306.17116v1"}
{"created":"2023-06-29","title":"LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding","abstract":"Instruction tuning unlocks the superior capability of Large Language Models (LLM) to interact with humans. Furthermore, recent instruction-following datasets include images as visual inputs, collecting responses for image-based instructions. However, visual instruction-tuned models cannot comprehend textual details within images well. This work enhances the current visual instruction tuning pipeline with text-rich images (e.g., movie posters, book covers, etc.). Specifically, we first use publicly available OCR tools to collect results on 422K text-rich images from the LAION dataset. Moreover, we prompt text-only GPT-4 with recognized texts and image captions to generate 16K conversations, each containing question-answer pairs for text-rich images. By combining our collected data with previous multi-modal instruction-following data, our model, LLaVAR, substantially improves the LLaVA model's capability on text-based VQA datasets (up to 20% accuracy improvement) while achieving an accuracy of 91.42% on ScienceQA. The GPT-4-based instruction-following evaluation also demonstrates the improvement of our model on both natural images and text-rich images. Through qualitative analysis, LLaVAR shows promising interaction (e.g., reasoning, writing, and elaboration) skills with humans based on the latest real-world online content that combines text and images. We make our code/data/models publicly available at https://llavar.github.io/.","sentences":["Instruction tuning unlocks the superior capability of Large Language Models (LLM) to interact with humans.","Furthermore, recent instruction-following datasets include images as visual inputs, collecting responses for image-based instructions.","However, visual instruction-tuned models cannot comprehend textual details within images well.","This work enhances the current visual instruction tuning pipeline with text-rich images (e.g., movie posters, book covers, etc.).","Specifically, we first use publicly available OCR tools to collect results on 422K text-rich images from the LAION dataset.","Moreover, we prompt text-only GPT-4 with recognized texts and image captions to generate 16K conversations, each containing question-answer pairs for text-rich images.","By combining our collected data with previous multi-modal instruction-following data, our model, LLaVAR, substantially improves the LLaVA model's capability on text-based VQA datasets (up to 20% accuracy improvement) while achieving an accuracy of 91.42% on ScienceQA.","The GPT-4-based instruction-following evaluation also demonstrates the improvement of our model on both natural images and text-rich images.","Through qualitative analysis, LLaVAR shows promising interaction (e.g., reasoning, writing, and elaboration) skills with humans based on the latest real-world online content that combines text and images.","We make our code/data/models publicly available at https://llavar.github.io/."],"url":"http://arxiv.org/abs/2306.17107v1"}
{"created":"2023-06-29","title":"LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT","abstract":"We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic lyrics transcription method achieving state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal. Our novel, training-free approach utilizes Whisper, a weakly supervised robust speech recognition model, and GPT-4, today's most performant chat-based large language model. In the proposed method, Whisper functions as the \"ear\" by transcribing the audio, while GPT-4 serves as the \"brain,\" acting as an annotator with a strong performance for contextualized output selection and correction. Our experiments show that LyricWhiz significantly reduces Word Error Rate compared to existing methods in English and can effectively transcribe lyrics across multiple languages. Furthermore, we use LyricWhiz to create the first publicly available, large-scale, multilingual lyrics transcription dataset with a CC-BY-NC-SA copyright license, based on MTG-Jamendo, and offer a human-annotated subset for noise level estimation and evaluation. We anticipate that our proposed method and dataset will advance the development of multilingual lyrics transcription, a challenging and emerging task.","sentences":["We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic lyrics transcription method achieving state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal.","Our novel, training-free approach utilizes Whisper, a weakly supervised robust speech recognition model, and GPT-4, today's most performant chat-based large language model.","In the proposed method, Whisper functions as the \"ear\" by transcribing the audio, while GPT-4 serves as the \"brain,\" acting as an annotator with a strong performance for contextualized output selection and correction.","Our experiments show that LyricWhiz significantly reduces Word Error Rate compared to existing methods in English and can effectively transcribe lyrics across multiple languages.","Furthermore, we use LyricWhiz to create the first publicly available, large-scale, multilingual lyrics transcription dataset with a CC-BY-NC-SA copyright license, based on MTG-Jamendo, and offer a human-annotated subset for noise level estimation and evaluation.","We anticipate that our proposed method and dataset will advance the development of multilingual lyrics transcription, a challenging and emerging task."],"url":"http://arxiv.org/abs/2306.17103v1"}
{"created":"2023-06-29","title":"The Importance of Robust Features in Mitigating Catastrophic Forgetting","abstract":"Continual learning (CL) is an approach to address catastrophic forgetting, which refers to forgetting previously learned knowledge by neural networks when trained on new tasks or data distributions. The adversarial robustness has decomposed features into robust and non-robust types and demonstrated that models trained on robust features significantly enhance adversarial robustness. However, no study has been conducted on the efficacy of robust features from the lens of the CL model in mitigating catastrophic forgetting in CL. In this paper, we introduce the CL robust dataset and train four baseline models on both the standard and CL robust datasets. Our results demonstrate that the CL models trained on the CL robust dataset experienced less catastrophic forgetting of the previously learned tasks than when trained on the standard dataset. Our observations highlight the significance of the features provided to the underlying CL models, showing that CL robust features can alleviate catastrophic forgetting.","sentences":["Continual learning (CL) is an approach to address catastrophic forgetting, which refers to forgetting previously learned knowledge by neural networks when trained on new tasks or data distributions.","The adversarial robustness has decomposed features into robust and non-robust types and demonstrated that models trained on robust features significantly enhance adversarial robustness.","However, no study has been conducted on the efficacy of robust features from the lens of the CL model in mitigating catastrophic forgetting in CL.","In this paper, we introduce the CL robust dataset and train four baseline models on both the standard and CL robust datasets.","Our results demonstrate that the CL models trained on the CL robust dataset experienced less catastrophic forgetting of the previously learned tasks than when trained on the standard dataset.","Our observations highlight the significance of the features provided to the underlying CL models, showing that CL robust features can alleviate catastrophic forgetting."],"url":"http://arxiv.org/abs/2306.17091v1"}
{"created":"2023-06-29","title":"Diffusion-Jump GNNs: Homophiliation via Learnable Metric Filters","abstract":"High-order Graph Neural Networks (HO-GNNs) have been developed to infer consistent latent spaces in the heterophilic regime, where the label distribution is not correlated with the graph structure. However, most of the existing HO-GNNs are hop-based, i.e., they rely on the powers of the transition matrix. As a result, these architectures are not fully reactive to the classification loss and the achieved structural filters have static supports. In other words, neither the filters' supports nor their coefficients can be learned with these networks. They are confined, instead, to learn combinations of filters. To address the above concerns, we propose Diffusion-jump GNNs a method relying on asymptotic diffusion distances that operates on jumps. A diffusion-pump generates pairwise distances whose projections determine both the support and coefficients of each structural filter. These filters are called jumps because they explore a wide range of scales in order to find bonds between scattered nodes with the same label. Actually, the full process is controlled by the classification loss. Both the jumps and the diffusion distances react to classification errors (i.e. they are learnable). Homophiliation, i.e., the process of learning piecewise smooth latent spaces in the heterophilic regime, is formulated as a Dirichlet problem: the known labels determine the border nodes and the diffusion-pump ensures a minimal deviation of the semi-supervised grouping from a canonical unsupervised grouping. This triggers the update of both the diffusion distances and, consequently, the jumps in order to minimize the classification error. The Dirichlet formulation has several advantages. It leads to the definition of structural heterophily, a novel measure beyond edge heterophily. It also allows us to investigate links with (learnable) diffusion distances, absorbing random walks and stochastic diffusion.","sentences":["High-order Graph Neural Networks (HO-GNNs) have been developed to infer consistent latent spaces in the heterophilic regime, where the label distribution is not correlated with the graph structure.","However, most of the existing HO-GNNs are hop-based, i.e., they rely on the powers of the transition matrix.","As a result, these architectures are not fully reactive to the classification loss and the achieved structural filters have static supports.","In other words, neither the filters' supports nor their coefficients can be learned with these networks.","They are confined, instead, to learn combinations of filters.","To address the above concerns, we propose Diffusion-jump GNNs a method relying on asymptotic diffusion distances that operates on jumps.","A diffusion-pump generates pairwise distances whose projections determine both the support and coefficients of each structural filter.","These filters are called jumps because they explore a wide range of scales in order to find bonds between scattered nodes with the same label.","Actually, the full process is controlled by the classification loss.","Both the jumps and the diffusion distances react to classification errors (i.e. they are learnable).","Homophiliation, i.e., the process of learning piecewise smooth latent spaces in the heterophilic regime, is formulated as a Dirichlet problem: the known labels determine the border nodes and the diffusion-pump ensures a minimal deviation of the semi-supervised grouping from a canonical unsupervised grouping.","This triggers the update of both the diffusion distances and, consequently, the jumps in order to minimize the classification error.","The Dirichlet formulation has several advantages.","It leads to the definition of structural heterophily, a novel measure beyond edge heterophily.","It also allows us to investigate links with (learnable) diffusion distances, absorbing random walks and stochastic diffusion."],"url":"http://arxiv.org/abs/2306.16976v1"}
{"created":"2023-06-29","title":"The Drunkard's Odometry: Estimating Camera Motion in Deforming Scenes","abstract":"Estimating camera motion in deformable scenes poses a complex and open research challenge. Most existing non-rigid structure from motion techniques assume to observe also static scene parts besides deforming scene parts in order to establish an anchoring reference. However, this assumption does not hold true in certain relevant application cases such as endoscopies. Deformable odometry and SLAM pipelines, which tackle the most challenging scenario of exploratory trajectories, suffer from a lack of robustness and proper quantitative evaluation methodologies. To tackle this issue with a common benchmark, we introduce the Drunkard's Dataset, a challenging collection of synthetic data targeting visual navigation and reconstruction in deformable environments. This dataset is the first large set of exploratory camera trajectories with ground truth inside 3D scenes where every surface exhibits non-rigid deformations over time. Simulations in realistic 3D buildings lets us obtain a vast amount of data and ground truth labels, including camera poses, RGB images and depth, optical flow and normal maps at high resolution and quality. We further present a novel deformable odometry method, dubbed the Drunkard's Odometry, which decomposes optical flow estimates into rigid-body camera motion and non-rigid scene deformations. In order to validate our data, our work contains an evaluation of several baselines as well as a novel tracking error metric which does not require ground truth data. Dataset and code: https://davidrecasens.github.io/TheDrunkard'sOdometry/","sentences":["Estimating camera motion in deformable scenes poses a complex and open research challenge.","Most existing non-rigid structure from motion techniques assume to observe also static scene parts besides deforming scene parts in order to establish an anchoring reference.","However, this assumption does not hold true in certain relevant application cases such as endoscopies.","Deformable odometry and SLAM pipelines, which tackle the most challenging scenario of exploratory trajectories, suffer from a lack of robustness and proper quantitative evaluation methodologies.","To tackle this issue with a common benchmark, we introduce the Drunkard's Dataset, a challenging collection of synthetic data targeting visual navigation and reconstruction in deformable environments.","This dataset is the first large set of exploratory camera trajectories with ground truth inside 3D scenes where every surface exhibits non-rigid deformations over time.","Simulations in realistic 3D buildings lets us obtain a vast amount of data and ground truth labels, including camera poses, RGB images and depth, optical flow and normal maps at high resolution and quality.","We further present a novel deformable odometry method, dubbed the Drunkard's Odometry, which decomposes optical flow estimates into rigid-body camera motion and non-rigid scene deformations.","In order to validate our data, our work contains an evaluation of several baselines as well as a novel tracking error metric which does not require ground truth data.","Dataset and code: https://davidrecasens.github.io/TheDrunkard'sOdometry/"],"url":"http://arxiv.org/abs/2306.16917v1"}
{"created":"2023-06-29","title":"Generate Anything Anywhere in Any Scene","abstract":"Text-to-image diffusion models have attracted considerable interest due to their wide applicability across diverse fields. However, challenges persist in creating controllable models for personalized object generation. In this paper, we first identify the entanglement issues in existing personalized generative models, and then propose a straightforward and efficient data augmentation training strategy that guides the diffusion model to focus solely on object identity. By inserting the plug-and-play adapter layers from a pre-trained controllable diffusion model, our model obtains the ability to control the location and size of each generated personalized object. During inference, we propose a regionally-guided sampling technique to maintain the quality and fidelity of the generated images. Our method achieves comparable or superior fidelity for personalized objects, yielding a robust, versatile, and controllable text-to-image diffusion model that is capable of generating realistic and personalized images. Our approach demonstrates significant potential for various applications, such as those in art, entertainment, and advertising design.","sentences":["Text-to-image diffusion models have attracted considerable interest due to their wide applicability across diverse fields.","However, challenges persist in creating controllable models for personalized object generation.","In this paper, we first identify the entanglement issues in existing personalized generative models, and then propose a straightforward and efficient data augmentation training strategy that guides the diffusion model to focus solely on object identity.","By inserting the plug-and-play adapter layers from a pre-trained controllable diffusion model, our model obtains the ability to control the location and size of each generated personalized object.","During inference, we propose a regionally-guided sampling technique to maintain the quality and fidelity of the generated images.","Our method achieves comparable or superior fidelity for personalized objects, yielding a robust, versatile, and controllable text-to-image diffusion model that is capable of generating realistic and personalized images.","Our approach demonstrates significant potential for various applications, such as those in art, entertainment, and advertising design."],"url":"http://arxiv.org/abs/2306.17154v1"}
{"created":"2023-06-29","title":"Pupil-driven quantitative differential phase contrast imaging","abstract":"In this research, we reveal the inborn but hitherto ignored properties of quantitative differential phase contrast (qDPC) imaging: the phase transfer function being an edge detection filter. Inspired by this, we highlighted the duality of qDPC between optics and pattern recognition, and propose a simple and effective qDPC reconstruction algorithm, termed Pupil-Driven qDPC (pd-qDPC), to facilitate the phase reconstruction quality for the family of qDPC-based phase reconstruction algorithms. We formed a new cost function in which modified L0-norm was used to represent the pupil-driven edge sparsity, and the qDPC convolution operator is duplicated in the data fidelity term to achieve automatic background removal. Further, we developed the iterative reweighted soft-threshold algorithms based on split Bregman method to solve this modified L0-norm problem. We tested pd-qDPC on both simulated and experimental data and compare against state-of-the-art (SOTA) methods including L2-norm, total variation regularization (TV-qDPC), isotropic-qDPC, and Retinex qDPC algorithms. Results show that our proposed model is superior in terms of phase reconstruction quality and implementation efficiency, in which it significantly increases the experimental robustness while maintaining the data fidelity. In general, the pd-qDPC enables the high-quality qDPC reconstruction without any modification of the optical system. It simplifies the system complexity and benefits the qDPC community and beyond including but not limited to cell segmentation and PTF learning based on the edge filtering property.","sentences":["In this research, we reveal the inborn but hitherto ignored properties of quantitative differential phase contrast (qDPC) imaging: the phase transfer function being an edge detection filter.","Inspired by this, we highlighted the duality of qDPC between optics and pattern recognition, and propose a simple and effective qDPC reconstruction algorithm, termed Pupil-Driven qDPC (pd-qDPC), to facilitate the phase reconstruction quality for the family of qDPC-based phase reconstruction algorithms.","We formed a new cost function in which modified L0-norm was used to represent the pupil-driven edge sparsity, and the qDPC convolution operator is duplicated in the data fidelity term to achieve automatic background removal.","Further, we developed the iterative reweighted soft-threshold algorithms based on split Bregman method to solve this modified L0-norm problem.","We tested pd-qDPC on both simulated and experimental data and compare against state-of-the-art (SOTA) methods including L2-norm, total variation regularization (TV-qDPC), isotropic-qDPC, and Retinex qDPC algorithms.","Results show that our proposed model is superior in terms of phase reconstruction quality and implementation efficiency, in which it significantly increases the experimental robustness while maintaining the data fidelity.","In general, the pd-qDPC enables the high-quality qDPC reconstruction without any modification of the optical system.","It simplifies the system complexity and benefits the qDPC community and beyond including but not limited to cell segmentation and PTF learning based on the edge filtering property."],"url":"http://arxiv.org/abs/2306.17088v1"}
{"created":"2023-06-29","title":"Comparison of Single- and Multi- Objective Optimization Quality for Evolutionary Equation Discovery","abstract":"Evolutionary differential equation discovery proved to be a tool to obtain equations with less a priori assumptions than conventional approaches, such as sparse symbolic regression over the complete possible terms library. The equation discovery field contains two independent directions. The first one is purely mathematical and concerns differentiation, the object of optimization and its relation to the functional spaces and others. The second one is dedicated purely to the optimizational problem statement. Both topics are worth investigating to improve the algorithm's ability to handle experimental data a more artificial intelligence way, without significant pre-processing and a priori knowledge of their nature. In the paper, we consider the prevalence of either single-objective optimization, which considers only the discrepancy between selected terms in the equation, or multi-objective optimization, which additionally takes into account the complexity of the obtained equation. The proposed comparison approach is shown on classical model examples -- Burgers equation, wave equation, and Korteweg - de Vries equation.","sentences":["Evolutionary differential equation discovery proved to be a tool to obtain equations with less a priori assumptions than conventional approaches, such as sparse symbolic regression over the complete possible terms library.","The equation discovery field contains two independent directions.","The first one is purely mathematical and concerns differentiation, the object of optimization and its relation to the functional spaces and others.","The second one is dedicated purely to the optimizational problem statement.","Both topics are worth investigating to improve the algorithm's ability to handle experimental data a more artificial intelligence way, without significant pre-processing and a priori knowledge of their nature.","In the paper, we consider the prevalence of either single-objective optimization, which considers only the discrepancy between selected terms in the equation, or multi-objective optimization, which additionally takes into account the complexity of the obtained equation.","The proposed comparison approach is shown on classical model examples -- Burgers equation, wave equation, and Korteweg - de Vries equation."],"url":"http://arxiv.org/abs/2306.17038v1"}
{"created":"2023-06-29","title":"UMASS_BioNLP at MEDIQA-Chat 2023: Can LLMs generate high-quality synthetic note-oriented doctor-patient conversations?","abstract":"This paper presents UMASS_BioNLP team participation in the MEDIQA-Chat 2023 shared task for Task-A and Task-C. We focus especially on Task-C and propose a novel LLMs cooperation system named a doctor-patient loop to generate high-quality conversation data sets. The experiment results demonstrate that our approaches yield reasonable performance as evaluated by automatic metrics such as ROUGE, medical concept recall, BLEU, and Self-BLEU. Furthermore, we conducted a comparative analysis between our proposed method and ChatGPT and GPT-4. This analysis also investigates the potential of utilizing cooperation LLMs to generate high-quality datasets.","sentences":["This paper presents UMASS_BioNLP team participation in the MEDIQA-Chat 2023 shared task for Task-A and Task-C. We focus especially on Task-C and propose a novel LLMs cooperation system named a doctor-patient loop to generate high-quality conversation data sets.","The experiment results demonstrate that our approaches yield reasonable performance as evaluated by automatic metrics such as ROUGE, medical concept recall, BLEU, and Self-BLEU.","Furthermore, we conducted a comparative analysis between our proposed method and ChatGPT and GPT-4.","This analysis also investigates the potential of utilizing cooperation LLMs to generate high-quality datasets."],"url":"http://arxiv.org/abs/2306.16931v1"}
{"created":"2023-06-29","title":"One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization","abstract":"Single image 3D reconstruction is an important but challenging task that requires extensive knowledge of our natural world. Many existing methods solve this problem by optimizing a neural radiance field under the guidance of 2D diffusion models but suffer from lengthy optimization time, 3D inconsistency results, and poor geometry. In this work, we propose a novel method that takes a single image of any object as input and generates a full 360-degree 3D textured mesh in a single feed-forward pass. Given a single image, we first use a view-conditioned 2D diffusion model, Zero123, to generate multi-view images for the input view, and then aim to lift them up to 3D space. Since traditional reconstruction methods struggle with inconsistent multi-view predictions, we build our 3D reconstruction module upon an SDF-based generalizable neural surface reconstruction method and propose several critical training strategies to enable the reconstruction of 360-degree meshes. Without costly optimizations, our method reconstructs 3D shapes in significantly less time than existing methods. Moreover, our method favors better geometry, generates more 3D consistent results, and adheres more closely to the input image. We evaluate our approach on both synthetic data and in-the-wild images and demonstrate its superiority in terms of both mesh quality and runtime. In addition, our approach can seamlessly support the text-to-3D task by integrating with off-the-shelf text-to-image diffusion models.","sentences":["Single image 3D reconstruction is an important but challenging task that requires extensive knowledge of our natural world.","Many existing methods solve this problem by optimizing a neural radiance field under the guidance of 2D diffusion models but suffer from lengthy optimization time, 3D inconsistency results, and poor geometry.","In this work, we propose a novel method that takes a single image of any object as input and generates a full 360-degree 3D textured mesh in a single feed-forward pass.","Given a single image, we first use a view-conditioned 2D diffusion model, Zero123, to generate multi-view images for the input view, and then aim to lift them up to 3D space.","Since traditional reconstruction methods struggle with inconsistent multi-view predictions, we build our 3D reconstruction module upon an SDF-based generalizable neural surface reconstruction method and propose several critical training strategies to enable the reconstruction of 360-degree meshes.","Without costly optimizations, our method reconstructs 3D shapes in significantly less time than existing methods.","Moreover, our method favors better geometry, generates more 3D consistent results, and adheres more closely to the input image.","We evaluate our approach on both synthetic data and in-the-wild images and demonstrate its superiority in terms of both mesh quality and runtime.","In addition, our approach can seamlessly support the text-to-3D task by integrating with off-the-shelf text-to-image diffusion models."],"url":"http://arxiv.org/abs/2306.16928v1"}
{"created":"2023-06-29","title":"The Drunkard's Odometry: Estimating Camera Motion in Deforming Scenes","abstract":"Estimating camera motion in deformable scenes poses a complex and open research challenge. Most existing non-rigid structure from motion techniques assume to observe also static scene parts besides deforming scene parts in order to establish an anchoring reference. However, this assumption does not hold true in certain relevant application cases such as endoscopies. Deformable odometry and SLAM pipelines, which tackle the most challenging scenario of exploratory trajectories, suffer from a lack of robustness and proper quantitative evaluation methodologies. To tackle this issue with a common benchmark, we introduce the Drunkard's Dataset, a challenging collection of synthetic data targeting visual navigation and reconstruction in deformable environments. This dataset is the first large set of exploratory camera trajectories with ground truth inside 3D scenes where every surface exhibits non-rigid deformations over time. Simulations in realistic 3D buildings lets us obtain a vast amount of data and ground truth labels, including camera poses, RGB images and depth, optical flow and normal maps at high resolution and quality. We further present a novel deformable odometry method, dubbed the Drunkard's Odometry, which decomposes optical flow estimates into rigid-body camera motion and non-rigid scene deformations. In order to validate our data, our work contains an evaluation of several baselines as well as a novel tracking error metric which does not require ground truth data. Dataset and code: https://davidrecasens.github.io/TheDrunkard'sOdometry/","sentences":["Estimating camera motion in deformable scenes poses a complex and open research challenge.","Most existing non-rigid structure from motion techniques assume to observe also static scene parts besides deforming scene parts in order to establish an anchoring reference.","However, this assumption does not hold true in certain relevant application cases such as endoscopies.","Deformable odometry and SLAM pipelines, which tackle the most challenging scenario of exploratory trajectories, suffer from a lack of robustness and proper quantitative evaluation methodologies.","To tackle this issue with a common benchmark, we introduce the Drunkard's Dataset, a challenging collection of synthetic data targeting visual navigation and reconstruction in deformable environments.","This dataset is the first large set of exploratory camera trajectories with ground truth inside 3D scenes where every surface exhibits non-rigid deformations over time.","Simulations in realistic 3D buildings lets us obtain a vast amount of data and ground truth labels, including camera poses, RGB images and depth, optical flow and normal maps at high resolution and quality.","We further present a novel deformable odometry method, dubbed the Drunkard's Odometry, which decomposes optical flow estimates into rigid-body camera motion and non-rigid scene deformations.","In order to validate our data, our work contains an evaluation of several baselines as well as a novel tracking error metric which does not require ground truth data.","Dataset and code: https://davidrecasens.github.io/TheDrunkard'sOdometry/"],"url":"http://arxiv.org/abs/2306.16917v1"}
{"created":"2023-06-29","title":"Computationally Assisted Quality Control for Public Health Data Streams","abstract":"Irregularities in public health data streams (like COVID-19 Cases) hamper data-driven decision-making for public health stakeholders. A real-time, computer-generated list of the most important, outlying data points from thousands of daily-updated public health data streams could assist an expert reviewer in identifying these irregularities. However, existing outlier detection frameworks perform poorly on this task because they do not account for the data volume or for the statistical properties of public health streams. Accordingly, we developed FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly. In an experiment where human experts evaluate FlaSH and existing methods (including deep learning approaches), FlaSH scales to the data volume of this task, matches or exceeds these other methods in mean accuracy, and identifies the outlier points that users empirically rate as more helpful. Based on these results, FlaSH has been deployed on data streams used by public health stakeholders.","sentences":["Irregularities in public health data streams (like COVID-19 Cases) hamper data-driven decision-making for public health stakeholders.","A real-time, computer-generated list of the most important, outlying data points from thousands of daily-updated public health data streams could assist an expert reviewer in identifying these irregularities.","However, existing outlier detection frameworks perform poorly on this task because they do not account for the data volume or for the statistical properties of public health streams.","Accordingly, we developed FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly.","In an experiment where human experts evaluate FlaSH and existing methods (including deep learning approaches), FlaSH scales to the data volume of this task, matches or exceeds these other methods in mean accuracy, and identifies the outlier points that users empirically rate as more helpful.","Based on these results, FlaSH has been deployed on data streams used by public health stakeholders."],"url":"http://arxiv.org/abs/2306.16914v1"}
{"created":"2023-06-29","title":"From Query Tools to Causal Architects: Harnessing Large Language Models for Advanced Causal Discovery from Data","abstract":"Large Language Models (LLMs) exhibit exceptional abilities for causal analysis between concepts in numerous societally impactful domains, including medicine, science, and law. Recent research on LLM performance in various causal discovery and inference tasks has given rise to a new ladder in the classical three-stage framework of causality. In this paper, we advance the current research of LLM-driven causal discovery by proposing a novel framework that combines knowledge-based LLM causal analysis with data-driven causal structure learning. To make LLM more than a query tool and to leverage its power in discovering natural and new laws of causality, we integrate the valuable LLM expertise on existing causal mechanisms into statistical analysis of objective data to build a novel and practical baseline for causal structure learning.   We introduce a universal set of prompts designed to extract causal graphs from given variables and assess the influence of LLM prior causality on recovering causal structures from data. We demonstrate the significant enhancement of LLM expertise on the quality of recovered causal structures from data, while also identifying critical challenges and issues, along with potential approaches to address them. As a pioneering study, this paper aims to emphasize the new frontier that LLMs are opening for classical causal discovery and inference, and to encourage the widespread adoption of LLM capabilities in data-driven causal analysis.","sentences":["Large Language Models (LLMs) exhibit exceptional abilities for causal analysis between concepts in numerous societally impactful domains, including medicine, science, and law.","Recent research on LLM performance in various causal discovery and inference tasks has given rise to a new ladder in the classical three-stage framework of causality.","In this paper, we advance the current research of LLM-driven causal discovery by proposing a novel framework that combines knowledge-based LLM causal analysis with data-driven causal structure learning.","To make LLM more than a query tool and to leverage its power in discovering natural and new laws of causality, we integrate the valuable LLM expertise on existing causal mechanisms into statistical analysis of objective data to build a novel and practical baseline for causal structure learning.   ","We introduce a universal set of prompts designed to extract causal graphs from given variables and assess the influence of LLM prior causality on recovering causal structures from data.","We demonstrate the significant enhancement of LLM expertise on the quality of recovered causal structures from data, while also identifying critical challenges and issues, along with potential approaches to address them.","As a pioneering study, this paper aims to emphasize the new frontier that LLMs are opening for classical causal discovery and inference, and to encourage the widespread adoption of LLM capabilities in data-driven causal analysis."],"url":"http://arxiv.org/abs/2306.16902v1"}
{"created":"2023-06-29","title":"SaGess: Sampling Graph Denoising Diffusion Model for Scalable Graph Generation","abstract":"Over recent years, denoising diffusion generative models have come to be considered as state-of-the-art methods for synthetic data generation, especially in the case of generating images. These approaches have also proved successful in other applications such as tabular and graph data generation. However, due to computational complexity, to this date, the application of these techniques to graph data has been restricted to small graphs, such as those used in molecular modeling. In this paper, we propose SaGess, a discrete denoising diffusion approach, which is able to generate large real-world networks by augmenting a diffusion model (DiGress) with a generalized divide-and-conquer framework. The algorithm is capable of generating larger graphs by sampling a covering of subgraphs of the initial graph in order to train DiGress. SaGess then constructs a synthetic graph using the subgraphs that have been generated by DiGress. We evaluate the quality of the synthetic data sets against several competitor methods by comparing graph statistics between the original and synthetic samples, as well as evaluating the utility of the synthetic data set produced by using it to train a task-driven model, namely link prediction. In our experiments, SaGess, outperforms most of the one-shot state-of-the-art graph generating methods by a significant factor, both on the graph metrics and on the link prediction task.","sentences":["Over recent years, denoising diffusion generative models have come to be considered as state-of-the-art methods for synthetic data generation, especially in the case of generating images.","These approaches have also proved successful in other applications such as tabular and graph data generation.","However, due to computational complexity, to this date, the application of these techniques to graph data has been restricted to small graphs, such as those used in molecular modeling.","In this paper, we propose SaGess, a discrete denoising diffusion approach, which is able to generate large real-world networks by augmenting a diffusion model (DiGress) with a generalized divide-and-conquer framework.","The algorithm is capable of generating larger graphs by sampling a covering of subgraphs of the initial graph in order to train DiGress.","SaGess then constructs a synthetic graph using the subgraphs that have been generated by DiGress.","We evaluate the quality of the synthetic data sets against several competitor methods by comparing graph statistics between the original and synthetic samples, as well as evaluating the utility of the synthetic data set produced by using it to train a task-driven model, namely link prediction.","In our experiments, SaGess, outperforms most of the one-shot state-of-the-art graph generating methods by a significant factor, both on the graph metrics and on the link prediction task."],"url":"http://arxiv.org/abs/2306.16827v1"}
{"created":"2023-06-29","title":"Benchmarking Large Language Model Capabilities for Conditional Generation","abstract":"Pre-trained large language models (PLMs) underlie most new developments in natural language processing. They have shifted the field from application-specific model pipelines to a single model that is adapted to a wide range of tasks. Autoregressive PLMs like GPT-3 or PaLM, alongside techniques like few-shot learning, have additionally shifted the output modality to generation instead of classification or regression. Despite their ubiquitous use, the generation quality of language models is rarely evaluated when these models are introduced. Additionally, it is unclear how existing generation tasks--while they can be used to compare systems at a high level--relate to the real world use cases for which people have been adopting them. In this work, we discuss how to adapt existing application-specific generation benchmarks to PLMs and provide an in-depth, empirical study of the limitations and capabilities of PLMs in natural language generation tasks along dimensions such as scale, architecture, input and output language. Our results show that PLMs differ in their applicability to different data regimes and their generalization to multiple languages and inform which PLMs to use for a given generation task setup. We share best practices to be taken into consideration when benchmarking generation capabilities during the development of upcoming PLMs.","sentences":["Pre-trained large language models (PLMs) underlie most new developments in natural language processing.","They have shifted the field from application-specific model pipelines to a single model that is adapted to a wide range of tasks.","Autoregressive PLMs like GPT-3 or PaLM, alongside techniques like few-shot learning, have additionally shifted the output modality to generation instead of classification or regression.","Despite their ubiquitous use, the generation quality of language models is rarely evaluated when these models are introduced.","Additionally, it is unclear how existing generation tasks--while they can be used to compare systems at a high level--relate to the real world use cases for which people have been adopting them.","In this work, we discuss how to adapt existing application-specific generation benchmarks to PLMs and provide an in-depth, empirical study of the limitations and capabilities of PLMs in natural language generation tasks along dimensions such as scale, architecture, input and output language.","Our results show that PLMs differ in their applicability to different data regimes and their generalization to multiple languages and inform which PLMs to use for a given generation task setup.","We share best practices to be taken into consideration when benchmarking generation capabilities during the development of upcoming PLMs."],"url":"http://arxiv.org/abs/2306.16793v1"}
{"created":"2023-06-29","title":"Episodic fluid venting from sedimentary basins fuelled by pressurised mudstones","abstract":"Subsurface sandstone reservoirs sealed by overlying, low-permeability layers provide capacity for long-term sequestration of anthropogenic waste. Leakage can occur if reservoir pressures rise sufficiently to fracture the seal. Such pressures can be generated within the reservoir by vigorous injection of waste or, over thousands of years, by natural processes. In either case, the precise role of intercalated mudstones in the long-term evolution of reservoir pressure remains unclear; these layers have variously been viewed as seals, as pressure sinks or as pressure sources. Here, we use the geological record of episodic fluid venting in the Levant Basin to provide striking evidence for the pressure-source hypothesis. We use a Bayesian framework to combine recently published venting data, which record critical subsurface pressures since $\\sim$2 Ma, with a stochastic model of pressure evolution to infer a pressure-recharge rate of $\\sim$30 MPa/Myr. To explain this large rate, we quantify and compare a range of candidate mechanisms. We find that poroelastic pressure diffusion from mudstones provides the most plausible explanation for these observations, amplifying the $\\sim$1 MPa/Myr recharge caused by tectonic compression. Since pressurised mudstones are ubiquitous in sedimentary basins, pressure diffusion from mudstones is likely to promote seal failure globally.","sentences":["Subsurface sandstone reservoirs sealed by overlying, low-permeability layers provide capacity for long-term sequestration of anthropogenic waste.","Leakage can occur if reservoir pressures rise sufficiently to fracture the seal.","Such pressures can be generated within the reservoir by vigorous injection of waste or, over thousands of years, by natural processes.","In either case, the precise role of intercalated mudstones in the long-term evolution of reservoir pressure remains unclear; these layers have variously been viewed as seals, as pressure sinks or as pressure sources.","Here, we use the geological record of episodic fluid venting in the Levant Basin to provide striking evidence for the pressure-source hypothesis.","We use a Bayesian framework to combine recently published venting data, which record critical subsurface pressures since $\\sim$2 Ma, with a stochastic model of pressure evolution to infer a pressure-recharge rate of $\\sim$30 MPa/Myr.","To explain this large rate, we quantify and compare a range of candidate mechanisms.","We find that poroelastic pressure diffusion from mudstones provides the most plausible explanation for these observations, amplifying the $\\sim$1 MPa/Myr recharge caused by tectonic compression.","Since pressurised mudstones are ubiquitous in sedimentary basins, pressure diffusion from mudstones is likely to promote seal failure globally."],"url":"http://arxiv.org/abs/2306.17058v1"}
{"created":"2023-06-29","title":"SWAT: A System-Wide Approach to Tunable Leakage Mitigation in Encrypted Data Stores","abstract":"Numerous studies have underscored the significant privacy risks associated with various leakage patterns in encrypted data stores. Most existing systems that conceal leakage either (1) incur substantial overheads, (2) focus on specific subsets of leakage patterns, or (3) apply the same security notion across various workloads, thereby impeding the attainment of fine-tuned privacy-efficiency trade-offs. In light of various detrimental leakage patterns, this paper starts with an investigation into which specific leakage patterns require our focus respectively in the contexts of key-value, range-query, and dynamic workloads. Subsequently, we introduce new security notions tailored to the specific privacy requirements of these workloads. Accordingly, we present, SWAT, an efficient construction that progressively enables these workloads, while provably mitigating system-wide leakage via a suite of algorithms with tunable privacy-efficiency trade-offs. We conducted extensive experiments and compiled a detailed result analysis, showing the efficiency of our solution. SWAT is about $10.6\\times$ slower than an encryption-only data store that reveals various leakage patterns and is $31.6\\times$ faster than a trivially zero-leakage solution. Meanwhile, the performance of SWAT remains highly competitive compared to other designs that mitigate specific types of leakage.","sentences":["Numerous studies have underscored the significant privacy risks associated with various leakage patterns in encrypted data stores.","Most existing systems that conceal leakage either (1) incur substantial overheads, (2) focus on specific subsets of leakage patterns, or (3) apply the same security notion across various workloads, thereby impeding the attainment of fine-tuned privacy-efficiency trade-offs.","In light of various detrimental leakage patterns, this paper starts with an investigation into which specific leakage patterns require our focus respectively in the contexts of key-value, range-query, and dynamic workloads.","Subsequently, we introduce new security notions tailored to the specific privacy requirements of these workloads.","Accordingly, we present, SWAT, an efficient construction that progressively enables these workloads, while provably mitigating system-wide leakage via a suite of algorithms with tunable privacy-efficiency trade-offs.","We conducted extensive experiments and compiled a detailed result analysis, showing the efficiency of our solution.","SWAT is about $10.6\\times$ slower than an encryption-only data store that reveals various leakage patterns and is $31.6\\times$ faster than a trivially zero-leakage solution.","Meanwhile, the performance of SWAT remains highly competitive compared to other designs that mitigate specific types of leakage."],"url":"http://arxiv.org/abs/2306.16851v1"}
{"created":"2023-06-29","title":"SaaFormer: Spectral-spatial Axial Aggregation Transformer for Hyperspectral Image Classification","abstract":"Hyperspectral images (HSI) captured from earth observing satellites and aircraft is becoming increasingly important for applications in agriculture, environmental monitoring, mining, etc. Due to the limited available hyperspectral datasets, the pixel-wise random sampling is the most commonly used training-test dataset partition approach, which has significant overlap between samples in training and test datasets. Furthermore, our experimental observations indicates that regions with larger overlap often exhibit higher classification accuracy. Consequently, the pixel-wise random sampling approach poses a risk of data leakage. Thus, we propose a block-wise sampling method to minimize the potential for data leakage. Our experimental findings also confirm the presence of data leakage in models such as 2DCNN. Further, We propose a spectral-spatial axial aggregation transformer model, namely SaaFormer, to address the challenges associated with hyperspectral image classifier that considers HSI as long sequential three-dimensional images. The model comprises two primary components: axial aggregation attention and multi-level spectral-spatial extraction. The axial aggregation attention mechanism effectively exploits the continuity and correlation among spectral bands at each pixel position in hyperspectral images, while aggregating spatial dimension features. This enables SaaFormer to maintain high precision even under block-wise sampling. The multi-level spectral-spatial extraction structure is designed to capture the sensitivity of different material components to specific spectral bands, allowing the model to focus on a broader range of spectral details. The results on six publicly available datasets demonstrate that our model exhibits comparable performance when using random sampling, while significantly outperforming other methods when employing block-wise sampling partition.","sentences":["Hyperspectral images (HSI) captured from earth observing satellites and aircraft is becoming increasingly important for applications in agriculture, environmental monitoring, mining, etc.","Due to the limited available hyperspectral datasets, the pixel-wise random sampling is the most commonly used training-test dataset partition approach, which has significant overlap between samples in training and test datasets.","Furthermore, our experimental observations indicates that regions with larger overlap often exhibit higher classification accuracy.","Consequently, the pixel-wise random sampling approach poses a risk of data leakage.","Thus, we propose a block-wise sampling method to minimize the potential for data leakage.","Our experimental findings also confirm the presence of data leakage in models such as 2DCNN.","Further, We propose a spectral-spatial axial aggregation transformer model, namely SaaFormer, to address the challenges associated with hyperspectral image classifier that considers HSI as long sequential three-dimensional images.","The model comprises two primary components: axial aggregation attention and multi-level spectral-spatial extraction.","The axial aggregation attention mechanism effectively exploits the continuity and correlation among spectral bands at each pixel position in hyperspectral images, while aggregating spatial dimension features.","This enables SaaFormer to maintain high precision even under block-wise sampling.","The multi-level spectral-spatial extraction structure is designed to capture the sensitivity of different material components to specific spectral bands, allowing the model to focus on a broader range of spectral details.","The results on six publicly available datasets demonstrate that our model exhibits comparable performance when using random sampling, while significantly outperforming other methods when employing block-wise sampling partition."],"url":"http://arxiv.org/abs/2306.16759v1"}
{"created":"2023-06-29","title":"Towards Blockchain-Assisted Privacy-Aware Data Sharing For Edge Intelligence: A Smart Healthcare Perspective","abstract":"The popularization of intelligent healthcare devices and big data analytics significantly boosts the development of smart healthcare networks (SHNs). To enhance the precision of diagnosis, different participants in SHNs share health data that contains sensitive information. Therefore, the data exchange process raises privacy concerns, especially when the integration of health data from multiple sources (linkage attack) results in further leakage. Linkage attack is a type of dominant attack in the privacy domain, which can leverage various data sources for private data mining. Furthermore, adversaries launch poisoning attacks to falsify the health data, which leads to misdiagnosing or even physical damage. To protect private health data, we propose a personalized differential privacy model based on the trust levels among users. The trust is evaluated by a defined community density, while the corresponding privacy protection level is mapped to controllable randomized noise constrained by differential privacy. To avoid linkage attacks in personalized differential privacy, we designed a noise correlation decoupling mechanism using a Markov stochastic process. In addition, we build the community model on a blockchain, which can mitigate the risk of poisoning attacks during differentially private data transmission over SHNs. To testify the effectiveness and superiority of the proposed approach, we conduct extensive experiments on benchmark datasets.","sentences":["The popularization of intelligent healthcare devices and big data analytics significantly boosts the development of smart healthcare networks (SHNs).","To enhance the precision of diagnosis, different participants in SHNs share health data that contains sensitive information.","Therefore, the data exchange process raises privacy concerns, especially when the integration of health data from multiple sources (linkage attack) results in further leakage.","Linkage attack is a type of dominant attack in the privacy domain, which can leverage various data sources for private data mining.","Furthermore, adversaries launch poisoning attacks to falsify the health data, which leads to misdiagnosing or even physical damage.","To protect private health data, we propose a personalized differential privacy model based on the trust levels among users.","The trust is evaluated by a defined community density, while the corresponding privacy protection level is mapped to controllable randomized noise constrained by differential privacy.","To avoid linkage attacks in personalized differential privacy, we designed a noise correlation decoupling mechanism using a Markov stochastic process.","In addition, we build the community model on a blockchain, which can mitigate the risk of poisoning attacks during differentially private data transmission over SHNs.","To testify the effectiveness and superiority of the proposed approach, we conduct extensive experiments on benchmark datasets."],"url":"http://arxiv.org/abs/2306.16630v1"}
