{"created":"2023-09-12 17:59:36","title":"Learning Disentangled Avatars with Hybrid 3D Representations","abstract":"Tremendous efforts have been made to learn animatable and photorealistic human avatars. Towards this end, both explicit and implicit 3D representations are heavily studied for a holistic modeling and capture of the whole human (e.g., body, clothing, face and hair), but neither representation is an optimal choice in terms of representation efficacy since different parts of the human avatar have different modeling desiderata. For example, meshes are generally not suitable for modeling clothing and hair. Motivated by this, we present Disentangled Avatars~(DELTA), which models humans with hybrid explicit-implicit 3D representations. DELTA takes a monocular RGB video as input, and produces a human avatar with separate body and clothing/hair layers. Specifically, we demonstrate two important applications for DELTA. For the first one, we consider the disentanglement of the human body and clothing and in the second, we disentangle the face and hair. To do so, DELTA represents the body or face with an explicit mesh-based parametric 3D model and the clothing or hair with an implicit neural radiance field. To make this possible, we design an end-to-end differentiable renderer that integrates meshes into volumetric rendering, enabling DELTA to learn directly from monocular videos without any 3D supervision. Finally, we show that how these two applications can be easily combined to model full-body avatars, such that the hair, face, body and clothing can be fully disentangled yet jointly rendered. Such a disentanglement enables hair and clothing transfer to arbitrary body shapes. We empirically validate the effectiveness of DELTA's disentanglement by demonstrating its promising performance on disentangled reconstruction, virtual clothing try-on and hairstyle transfer. To facilitate future research, we also release an open-sourced pipeline for the study of hybrid human avatar modeling.","sentences":["Tremendous efforts have been made to learn animatable and photorealistic human avatars.","Towards this end, both explicit and implicit 3D representations are heavily studied for a holistic modeling and capture of the whole human (e.g., body, clothing, face and hair), but neither representation is an optimal choice in terms of representation efficacy since different parts of the human avatar have different modeling desiderata.","For example, meshes are generally not suitable for modeling clothing and hair.","Motivated by this, we present Disentangled Avatars~(DELTA), which models humans with hybrid explicit-implicit 3D representations.","DELTA takes a monocular RGB video as input, and produces a human avatar with separate body and clothing/hair layers.","Specifically, we demonstrate two important applications for DELTA.","For the first one, we consider the disentanglement of the human body and clothing and in the second, we disentangle the face and hair.","To do so, DELTA represents the body or face with an explicit mesh-based parametric 3D model and the clothing or hair with an implicit neural radiance field.","To make this possible, we design an end-to-end differentiable renderer that integrates meshes into volumetric rendering, enabling DELTA to learn directly from monocular videos without any 3D supervision.","Finally, we show that how these two applications can be easily combined to model full-body avatars, such that the hair, face, body and clothing can be fully disentangled yet jointly rendered.","Such a disentanglement enables hair and clothing transfer to arbitrary body shapes.","We empirically validate the effectiveness of DELTA's disentanglement by demonstrating its promising performance on disentangled reconstruction, virtual clothing try-on and hairstyle transfer.","To facilitate future research, we also release an open-sourced pipeline for the study of hybrid human avatar modeling."],"url":"http://arxiv.org/abs/2309.06441v1"}
{"created":"2023-09-12 17:59:20","title":"LEAP Hand: Low-Cost, Efficient, and Anthropomorphic Hand for Robot Learning","abstract":"Dexterous manipulation has been a long-standing challenge in robotics. While machine learning techniques have shown some promise, results have largely been currently limited to simulation. This can be mostly attributed to the lack of suitable hardware. In this paper, we present LEAP Hand, a low-cost dexterous and anthropomorphic hand for machine learning research. In contrast to previous hands, LEAP Hand has a novel kinematic structure that allows maximal dexterity regardless of finger pose. LEAP Hand is low-cost and can be assembled in 4 hours at a cost of 2000 USD from readily available parts. It is capable of consistently exerting large torques over long durations of time. We show that LEAP Hand can be used to perform several manipulation tasks in the real world -- from visual teleoperation to learning from passive video data and sim2real. LEAP Hand significantly outperforms its closest competitor Allegro Hand in all our experiments while being 1/8th of the cost. We release detailed assembly instructions, the Sim2Real pipeline and a development platform with useful APIs on our website at https://leap-hand.github.io/","sentences":["Dexterous manipulation has been a long-standing challenge in robotics.","While machine learning techniques have shown some promise, results have largely been currently limited to simulation.","This can be mostly attributed to the lack of suitable hardware.","In this paper, we present LEAP Hand, a low-cost dexterous and anthropomorphic hand for machine learning research.","In contrast to previous hands, LEAP Hand has a novel kinematic structure that allows maximal dexterity regardless of finger pose.","LEAP Hand is low-cost and can be assembled in 4 hours at a cost of 2000 USD from readily available parts.","It is capable of consistently exerting large torques over long durations of time.","We show that LEAP Hand can be used to perform several manipulation tasks in the real world -- from visual teleoperation to learning from passive video data and sim2real.","LEAP Hand significantly outperforms its closest competitor Allegro Hand in all our experiments while being 1/8th of the cost.","We release detailed assembly instructions, the Sim2Real pipeline and a development platform with useful APIs on our website at https://leap-hand.github.io/"],"url":"http://arxiv.org/abs/2309.06440v1"}
{"created":"2023-09-12 17:59:10","title":"Attention De-sparsification Matters: Inducing Diversity in Digital Pathology Representation Learning","abstract":"We propose DiRL, a Diversity-inducing Representation Learning technique for histopathology imaging. Self-supervised learning techniques, such as contrastive and non-contrastive approaches, have been shown to learn rich and effective representations of digitized tissue samples with limited pathologist supervision. Our analysis of vanilla SSL-pretrained models' attention distribution reveals an insightful observation: sparsity in attention, i.e, models tends to localize most of their attention to some prominent patterns in the image. Although attention sparsity can be beneficial in natural images due to these prominent patterns being the object of interest itself, this can be sub-optimal in digital pathology; this is because, unlike natural images, digital pathology scans are not object-centric, but rather a complex phenotype of various spatially intermixed biological components. Inadequate diversification of attention in these complex images could result in crucial information loss. To address this, we leverage cell segmentation to densely extract multiple histopathology-specific representations, and then propose a prior-guided dense pretext task for SSL, designed to match the multiple corresponding representations between the views. Through this, the model learns to attend to various components more closely and evenly, thus inducing adequate diversification in attention for capturing context rich representations. Through quantitative and qualitative analysis on multiple tasks across cancer types, we demonstrate the efficacy of our method and observe that the attention is more globally distributed.","sentences":["We propose DiRL, a Diversity-inducing Representation Learning technique for histopathology imaging.","Self-supervised learning techniques, such as contrastive and non-contrastive approaches, have been shown to learn rich and effective representations of digitized tissue samples with limited pathologist supervision.","Our analysis of vanilla SSL-pretrained models' attention distribution reveals an insightful observation: sparsity in attention, i.e, models tends to localize most of their attention to some prominent patterns in the image.","Although attention sparsity can be beneficial in natural images due to these prominent patterns being the object of interest itself, this can be sub-optimal in digital pathology; this is because, unlike natural images, digital pathology scans are not object-centric, but rather a complex phenotype of various spatially intermixed biological components.","Inadequate diversification of attention in these complex images could result in crucial information loss.","To address this, we leverage cell segmentation to densely extract multiple histopathology-specific representations, and then propose a prior-guided dense pretext task for SSL, designed to match the multiple corresponding representations between the views.","Through this, the model learns to attend to various components more closely and evenly, thus inducing adequate diversification in attention for capturing context rich representations.","Through quantitative and qualitative analysis on multiple tasks across cancer types, we demonstrate the efficacy of our method and observe that the attention is more globally distributed."],"url":"http://arxiv.org/abs/2309.06439v1"}
{"created":"2023-09-12 17:58:06","title":"Exploring Non-additive Randomness on ViT against Query-Based Black-Box Attacks","abstract":"Deep Neural Networks can be easily fooled by small and imperceptible perturbations. The query-based black-box attack (QBBA) is able to create the perturbations using model output probabilities of image queries requiring no access to the underlying models. QBBA poses realistic threats to real-world applications. Recently, various types of robustness have been explored to defend against QBBA. In this work, we first taxonomize the stochastic defense strategies against QBBA. Following our taxonomy, we propose to explore non-additive randomness in models to defend against QBBA. Specifically, we focus on underexplored Vision Transformers based on their flexible architectures. Extensive experiments show that the proposed defense approach achieves effective defense, without much sacrifice in performance.","sentences":["Deep Neural Networks can be easily fooled by small and imperceptible perturbations.","The query-based black-box attack (QBBA) is able to create the perturbations using model output probabilities of image queries requiring no access to the underlying models.","QBBA poses realistic threats to real-world applications.","Recently, various types of robustness have been explored to defend against QBBA.","In this work, we first taxonomize the stochastic defense strategies against QBBA.","Following our taxonomy, we propose to explore non-additive randomness in models to defend against QBBA.","Specifically, we focus on underexplored Vision Transformers based on their flexible architectures.","Extensive experiments show that the proposed defense approach achieves effective defense, without much sacrifice in performance."],"url":"http://arxiv.org/abs/2309.06438v1"}
{"created":"2023-09-12 17:40:49","title":"Unveiling the potential of large language models in generating semantic and cross-language clones","abstract":"Semantic and Cross-language code clone generation may be useful for code reuse, code comprehension, refactoring and benchmarking. OpenAI's GPT model has potential in such clone generation as GPT is used for text generation. When developers copy/paste codes from Stack Overflow (SO) or within a system, there might be inconsistent changes leading to unexpected behaviours. Similarly, if someone possesses a code snippet in a particular programming language but seeks equivalent functionality in a different language, a semantic cross-language code clone generation approach could provide valuable assistance.In this study, using SemanticCloneBench as a vehicle, we evaluated how well the GPT-3 model could help generate semantic and cross-language clone variants for a given fragment.We have comprised a diverse set of code fragments and assessed GPT-3s performance in generating code variants.Through extensive experimentation and analysis, where 9 judges spent 158 hours to validate, we investigate the model's ability to produce accurate and semantically correct variants. Our findings shed light on GPT-3's strengths in code generation, offering insights into the potential applications and challenges of using advanced language models in software development. Our quantitative analysis yields compelling results. In the realm of semantic clones, GPT-3 attains an impressive accuracy of 62.14% and 0.55 BLEU score, achieved through few-shot prompt engineering. Furthermore, the model shines in transcending linguistic confines, boasting an exceptional 91.25% accuracy in generating cross-language clones","sentences":["Semantic and Cross-language code clone generation may be useful for code reuse, code comprehension, refactoring and benchmarking.","OpenAI's GPT model has potential in such clone generation as GPT is used for text generation.","When developers copy/paste codes from Stack Overflow (SO) or within a system, there might be inconsistent changes leading to unexpected behaviours.","Similarly, if someone possesses a code snippet in a particular programming language but seeks equivalent functionality in a different language, a semantic cross-language code clone generation approach could provide valuable assistance.","In this study, using SemanticCloneBench as a vehicle, we evaluated how well the GPT-3 model could help generate semantic and cross-language clone variants for a given fragment.","We have comprised a diverse set of code fragments and assessed GPT-3s performance in generating code variants.","Through extensive experimentation and analysis, where 9 judges spent 158 hours to validate, we investigate the model's ability to produce accurate and semantically correct variants.","Our findings shed light on GPT-3's strengths in code generation, offering insights into the potential applications and challenges of using advanced language models in software development.","Our quantitative analysis yields compelling results.","In the realm of semantic clones, GPT-3 attains an impressive accuracy of 62.14% and 0.55 BLEU score, achieved through few-shot prompt engineering.","Furthermore, the model shines in transcending linguistic confines, boasting an exceptional 91.25% accuracy in generating cross-language clones"],"url":"http://arxiv.org/abs/2309.06424v1"}
{"created":"2023-09-12 17:30:34","title":"C4CAM: A Compiler for CAM-based In-memory Accelerators","abstract":"Machine learning and data analytics applications increasingly suffer from the high latency and energy consumption of conventional von Neumann architectures. Recently, several in-memory and near-memory systems have been proposed to remove this von Neumann bottleneck. Platforms based on content-addressable memories (CAMs) are particularly interesting due to their efficient support for the search-based operations that form the foundation for many applications, including K-nearest neighbors (KNN), high-dimensional computing (HDC), recommender systems, and one-shot learning among others. Today, these platforms are designed by hand and can only be programmed with low-level code, accessible only to hardware experts. In this paper, we introduce C4CAM, the first compiler framework to quickly explore CAM configurations and to seamlessly generate code from high-level TorchScript code. C4CAM employs a hierarchy of abstractions that progressively lowers programs, allowing code transformations at the most suitable abstraction level. Depending on the type and technology, CAM arrays exhibit varying latencies and power profiles. Our framework allows analyzing the impact of such differences in terms of system-level performance and energy consumption, and thus supports designers in selecting appropriate designs for a given application.","sentences":["Machine learning and data analytics applications increasingly suffer from the high latency and energy consumption of conventional von Neumann architectures.","Recently, several in-memory and near-memory systems have been proposed to remove this von Neumann bottleneck.","Platforms based on content-addressable memories (CAMs) are particularly interesting due to their efficient support for the search-based operations that form the foundation for many applications, including K-nearest neighbors (KNN), high-dimensional computing (HDC), recommender systems, and one-shot learning among others.","Today, these platforms are designed by hand and can only be programmed with low-level code, accessible only to hardware experts.","In this paper, we introduce C4CAM, the first compiler framework to quickly explore CAM configurations and to seamlessly generate code from high-level TorchScript code.","C4CAM employs a hierarchy of abstractions that progressively lowers programs, allowing code transformations at the most suitable abstraction level.","Depending on the type and technology, CAM arrays exhibit varying latencies and power profiles.","Our framework allows analyzing the impact of such differences in terms of system-level performance and energy consumption, and thus supports designers in selecting appropriate designs for a given application."],"url":"http://arxiv.org/abs/2309.06418v1"}
{"created":"2023-09-12 17:26:03","title":"Just-in-Time autotuning","abstract":"Performance portability is a major concern on current architectures. One way to achieve it is by using autotuning. In this paper, we are presenting how we exten ded a just-in-time compilation infrastructure to introduce autotuning capabiliti es triggered at run-time. When a function is executed, the first iterations optimize it, and once the best solution has been found, it is used for subsequent calls to the function. This just-in-time autotuning infrastructure is relevant for optimizing computation kernels that will be called numerous times with similar parameters through the execution, re-optimizes kernels when they are called with other parameters, and the programmer can obtain the optimal parameters to use them for other kernels. We present an experimental performance evaluation of our approach. Compiling the code introduces an overhead on the first iterations, and this overhead is compensated for during subsequent iterations. We also determined that the optimum found seems stable and accurate.","sentences":["Performance portability is a major concern on current architectures.","One way to achieve it is by using autotuning.","In this paper, we are presenting how we exten ded a just-in-time compilation infrastructure to introduce autotuning capabiliti es triggered at run-time.","When a function is executed, the first iterations optimize it, and once the best solution has been found, it is used for subsequent calls to the function.","This just-in-time autotuning infrastructure is relevant for optimizing computation kernels that will be called numerous times with similar parameters through the execution, re-optimizes kernels when they are called with other parameters, and the programmer can obtain the optimal parameters to use them for other kernels.","We present an experimental performance evaluation of our approach.","Compiling the code introduces an overhead on the first iterations, and this overhead is compensated for during subsequent iterations.","We also determined that the optimum found seems stable and accurate."],"url":"http://arxiv.org/abs/2309.06414v1"}
{"created":"2023-09-12 17:25:32","title":"On Computationally Efficient Learning of Exponential Family Distributions","abstract":"We consider the classical problem of learning, with arbitrary accuracy, the natural parameters of a $k$-parameter truncated \\textit{minimal} exponential family from i.i.d. samples in a computationally and statistically efficient manner. We focus on the setting where the support as well as the natural parameters are appropriately bounded. While the traditional maximum likelihood estimator for this class of exponential family is consistent, asymptotically normal, and asymptotically efficient, evaluating it is computationally hard. In this work, we propose a novel loss function and a computationally efficient estimator that is consistent as well as asymptotically normal under mild conditions. We show that, at the population level, our method can be viewed as the maximum likelihood estimation of a re-parameterized distribution belonging to the same class of exponential family. Further, we show that our estimator can be interpreted as a solution to minimizing a particular Bregman score as well as an instance of minimizing the \\textit{surrogate} likelihood. We also provide finite sample guarantees to achieve an error (in $\\ell_2$-norm) of $\\alpha$ in the parameter estimation with sample complexity $O({\\sf poly}(k)/\\alpha^2)$. Our method achives the order-optimal sample complexity of $O({\\sf log}(k)/\\alpha^2)$ when tailored for node-wise-sparse Markov random fields. Finally, we demonstrate the performance of our estimator via numerical experiments.","sentences":["We consider the classical problem of learning, with arbitrary accuracy, the natural parameters of a $k$-parameter truncated \\textit{minimal} exponential family from i.i.d. samples in a computationally and statistically efficient manner.","We focus on the setting where the support as well as the natural parameters are appropriately bounded.","While the traditional maximum likelihood estimator for this class of exponential family is consistent, asymptotically normal, and asymptotically efficient, evaluating it is computationally hard.","In this work, we propose a novel loss function and a computationally efficient estimator that is consistent as well as asymptotically normal under mild conditions.","We show that, at the population level, our method can be viewed as the maximum likelihood estimation of a re-parameterized distribution belonging to the same class of exponential family.","Further, we show that our estimator can be interpreted as a solution to minimizing a particular Bregman score as well as an instance of minimizing the \\textit{surrogate} likelihood.","We also provide finite sample guarantees to achieve an error (in $\\ell_2$-norm) of $\\alpha$ in the parameter estimation with sample complexity $O({\\sf poly}(k)/\\alpha^2)$. Our method achives the order-optimal sample complexity of $O({\\sf log}(k)/\\alpha^2)$ when tailored for node-wise-sparse Markov random fields.","Finally, we demonstrate the performance of our estimator via numerical experiments."],"url":"http://arxiv.org/abs/2309.06413v1"}
{"created":"2023-09-12 16:59:40","title":"Compositional Separation of Control Flow and Data Flow","abstract":"Every constructive model of computation (CMC) has an underlying composition mechanism for combining simple computation devices into more complex ones. Composition can be done by (explicitly or implicitly) defining control flow, data flow or any combination thereof. Control flow specifies the order in which individual computation devices are activated, whereas data flow defines how data is exchanged among them. Unfortunately, traditional CMCs either mix data and control or only consider one dimension explicitly, which makes it difficult to reason about data flow and control flow separately. Reasoning about these dimensions orthogonally is a crucial desideratum for optimisation, maintainability and verification purposes. In this paper, we introduce a novel model that explicitly treats data flow and control flow as separate dimensions, while providing modularity. As the model is rooted in category theory, it provides category-theoretic operations for compositionally constructing sequential or parallel composites. Compositionality entails that a composite exhibits the same properties as its respective constituents, including separation of concerns and modularity.","sentences":["Every constructive model of computation (CMC) has an underlying composition mechanism for combining simple computation devices into more complex ones.","Composition can be done by (explicitly or implicitly) defining control flow, data flow or any combination thereof.","Control flow specifies the order in which individual computation devices are activated, whereas data flow defines how data is exchanged among them.","Unfortunately, traditional CMCs either mix data and control or only consider one dimension explicitly, which makes it difficult to reason about data flow and control flow separately.","Reasoning about these dimensions orthogonally is a crucial desideratum for optimisation, maintainability and verification purposes.","In this paper, we introduce a novel model that explicitly treats data flow and control flow as separate dimensions, while providing modularity.","As the model is rooted in category theory, it provides category-theoretic operations for compositionally constructing sequential or parallel composites.","Compositionality entails that a composite exhibits the same properties as its respective constituents, including separation of concerns and modularity."],"url":"http://arxiv.org/abs/2309.06397v1"}
{"created":"2023-09-12 16:59:08","title":"Human-Centered Autonomy for Autonomous sUAS Target Searching","abstract":"Deploying robots that operate in dynamic, uncertain environments, such as Uncrewed Aerial Systems in search \\& rescue missions, require nearly continuous human supervision for vehicle guidance and operation. Without approaches that consider high level mission context, operational methods of autonomous flying necessitate cumbersome manual operation or inefficient exhaustive search patterns. To facilitate more effective use of autonomy, we present a human-centered autonomous system that infers geospatial mission context through dynamic features sets, which then guides a probabilistic target search planner. Operators provide a limited set of diverse inputs, including priority definition, spatial semantic observations over ad-hoc geographical areas, and reference waypoints, which are probabilistically fused with geographical database information and condensed into a discretized value map representing an operator's preferences over an operational area. An online, POMDP-based planner, optimized for target searching, is augmented with this value map to generate an operator-constrained vehicle waypoint guidance plan. We validate the system by gathering input from five first responders trained in search \\& rescue and compare simulated system performance against current operational methods for autonomous missions. These results display effective task mental model alignment and more efficient guidance plans, resulting in faster rescue times.","sentences":["Deploying robots that operate in dynamic, uncertain environments, such as Uncrewed Aerial Systems in search \\& rescue missions, require nearly continuous human supervision for vehicle guidance and operation.","Without approaches that consider high level mission context, operational methods of autonomous flying necessitate cumbersome manual operation or inefficient exhaustive search patterns.","To facilitate more effective use of autonomy, we present a human-centered autonomous system that infers geospatial mission context through dynamic features sets, which then guides a probabilistic target search planner.","Operators provide a limited set of diverse inputs, including priority definition, spatial semantic observations over ad-hoc geographical areas, and reference waypoints, which are probabilistically fused with geographical database information and condensed into a discretized value map representing an operator's preferences over an operational area.","An online, POMDP-based planner, optimized for target searching, is augmented with this value map to generate an operator-constrained vehicle waypoint guidance plan.","We validate the system by gathering input from five first responders trained in search \\& rescue and compare simulated system performance against current operational methods for autonomous missions.","These results display effective task mental model alignment and more efficient guidance plans, resulting in faster rescue times."],"url":"http://arxiv.org/abs/2309.06395v1"}
{"created":"2023-09-12 16:48:00","title":"Ensemble Mask Networks","abstract":"Can an $\\mathbb{R}^n\\rightarrow \\mathbb{R}^n$ feedforward network learn matrix-vector multiplication? This study introduces two mechanisms - flexible masking to take matrix inputs, and a unique network pruning to respect the mask's dependency structure. Networks can approximate fixed operations such as matrix-vector multiplication $\\phi(A,x) \\rightarrow Ax$, motivating the mechanisms introduced with applications towards litmus-testing dependencies or interaction order in graph-based models.","sentences":["Can an $\\mathbb{R}^n\\rightarrow \\mathbb{R}^n$ feedforward network learn matrix-vector multiplication?","This study introduces two mechanisms - flexible masking to take matrix inputs, and a unique network pruning to respect the mask's dependency structure.","Networks can approximate fixed operations such as matrix-vector multiplication $\\phi(A,x) \\rightarrow Ax$, motivating the mechanisms introduced with applications towards litmus-testing dependencies or interaction order in graph-based models."],"url":"http://arxiv.org/abs/2309.06382v1"}
{"created":"2023-09-12 16:42:09","title":"InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation","abstract":"Diffusion models have revolutionized text-to-image generation with its exceptional quality and creativity. However, its multi-step sampling process is known to be slow, often requiring tens of inference steps to obtain satisfactory results. Previous attempts to improve its sampling speed and reduce computational costs through distillation have been unsuccessful in achieving a functional one-step model. In this paper, we explore a recent method called Rectified Flow, which, thus far, has only been applied to small datasets. The core of Rectified Flow lies in its \\emph{reflow} procedure, which straightens the trajectories of probability flows, refines the coupling between noises and images, and facilitates the distillation process with student models. We propose a novel text-conditioned pipeline to turn Stable Diffusion (SD) into an ultra-fast one-step model, in which we find reflow plays a critical role in improving the assignment between noise and images. Leveraging our new pipeline, we create, to the best of our knowledge, the first one-step diffusion-based text-to-image generator with SD-level image quality, achieving an FID (Frechet Inception Distance) of $23.3$ on MS COCO 2017-5k, surpassing the previous state-of-the-art technique, progressive distillation, by a significant margin ($37.2$ $\\rightarrow$ $23.3$ in FID). By utilizing an expanded network with 1.7B parameters, we further improve the FID to $22.4$. We call our one-step models \\emph{InstaFlow}. On MS COCO 2014-30k, InstaFlow yields an FID of $13.1$ in just $0.09$ second, the best in $\\leq 0.1$ second regime, outperforming the recent StyleGAN-T ($13.9$ in $0.1$ second). Notably, the training of InstaFlow only costs 199 A100 GPU days. Project page:~\\url{https://github.com/gnobitab/InstaFlow}.","sentences":["Diffusion models have revolutionized text-to-image generation with its exceptional quality and creativity.","However, its multi-step sampling process is known to be slow, often requiring tens of inference steps to obtain satisfactory results.","Previous attempts to improve its sampling speed and reduce computational costs through distillation have been unsuccessful in achieving a functional one-step model.","In this paper, we explore a recent method called Rectified Flow, which, thus far, has only been applied to small datasets.","The core of Rectified Flow lies in its \\emph{reflow} procedure, which straightens the trajectories of probability flows, refines the coupling between noises and images, and facilitates the distillation process with student models.","We propose a novel text-conditioned pipeline to turn Stable Diffusion (SD) into an ultra-fast one-step model, in which we find reflow plays a critical role in improving the assignment between noise and images.","Leveraging our new pipeline, we create, to the best of our knowledge, the first one-step diffusion-based text-to-image generator with SD-level image quality, achieving an FID (Frechet Inception Distance) of $23.3$ on MS COCO 2017-5k, surpassing the previous state-of-the-art technique, progressive distillation, by a significant margin ($37.2","$ $\\rightarrow$ $23.3$ in FID).","By utilizing an expanded network with 1.7B parameters, we further improve the FID to $22.4$. We call our one-step models \\emph{InstaFlow}.","On MS COCO 2014-30k, InstaFlow yields an FID of $13.1$ in just $0.09$ second, the best in $\\leq 0.1$ second regime, outperforming the recent StyleGAN-T ($13.9$ in $0.1$ second).","Notably, the training of InstaFlow only costs 199 A100 GPU days.","Project page:~\\url{https://github.com/gnobitab/InstaFlow}."],"url":"http://arxiv.org/abs/2309.06380v1"}
{"created":"2023-09-12 16:42:07","title":"Style2Fab: Functionality-Aware Segmentation for Fabricating Personalized 3D Models with Generative AI","abstract":"With recent advances in Generative AI, it is becoming easier to automatically manipulate 3D models. However, current methods tend to apply edits to models globally, which risks compromising the intended functionality of the 3D model when fabricated in the physical world. For example, modifying functional segments in 3D models, such as the base of a vase, could break the original functionality of the model, thus causing the vase to fall over. We introduce a method for automatically segmenting 3D models into functional and aesthetic elements. This method allows users to selectively modify aesthetic segments of 3D models, without affecting the functional segments. To develop this method we first create a taxonomy of functionality in 3D models by qualitatively analyzing 1000 models sourced from a popular 3D printing repository, Thingiverse. With this taxonomy, we develop a semi-automatic classification method to decompose 3D models into functional and aesthetic elements. We propose a system called Style2Fab that allows users to selectively stylize 3D models without compromising their functionality. We evaluate the effectiveness of our classification method compared to human-annotated data, and demonstrate the utility of Style2Fab with a user study to show that functionality-aware segmentation helps preserve model functionality.","sentences":["With recent advances in Generative AI, it is becoming easier to automatically manipulate 3D models.","However, current methods tend to apply edits to models globally, which risks compromising the intended functionality of the 3D model when fabricated in the physical world.","For example, modifying functional segments in 3D models, such as the base of a vase, could break the original functionality of the model, thus causing the vase to fall over.","We introduce a method for automatically segmenting 3D models into functional and aesthetic elements.","This method allows users to selectively modify aesthetic segments of 3D models, without affecting the functional segments.","To develop this method we first create a taxonomy of functionality in 3D models by qualitatively analyzing 1000 models sourced from a popular 3D printing repository, Thingiverse.","With this taxonomy, we develop a semi-automatic classification method to decompose 3D models into functional and aesthetic elements.","We propose a system called Style2Fab that allows users to selectively stylize 3D models without compromising their functionality.","We evaluate the effectiveness of our classification method compared to human-annotated data, and demonstrate the utility of Style2Fab with a user study to show that functionality-aware segmentation helps preserve model functionality."],"url":"http://arxiv.org/abs/2309.06379v1"}
{"created":"2023-09-12 16:36:12","title":"Padding-free Convolution based on Preservation of Differential Characteristics of Kernels","abstract":"Convolution is a fundamental operation in image processing and machine learning. Aimed primarily at maintaining image size, padding is a key ingredient of convolution, which, however, can introduce undesirable boundary effects. We present a non-padding-based method for size-keeping convolution based on the preservation of differential characteristics of kernels. The main idea is to make convolution over an incomplete sliding window \"collapse\" to a linear differential operator evaluated locally at its central pixel, which no longer requires information from the neighbouring missing pixels. While the underlying theory is rigorous, our final formula turns out to be simple: the convolution over an incomplete window is achieved by convolving its nearest complete window with a transformed kernel. This formula is computationally lightweight, involving neither interpolation or extrapolation nor restrictions on image and kernel sizes. Our method favours data with smooth boundaries, such as high-resolution images and fields from physics. Our experiments include: i) filtering analytical and non-analytical fields from computational physics and, ii) training convolutional neural networks (CNNs) for the tasks of image classification, semantic segmentation and super-resolution reconstruction. In all these experiments, our method has exhibited visible superiority over the compared ones.","sentences":["Convolution is a fundamental operation in image processing and machine learning.","Aimed primarily at maintaining image size, padding is a key ingredient of convolution, which, however, can introduce undesirable boundary effects.","We present a non-padding-based method for size-keeping convolution based on the preservation of differential characteristics of kernels.","The main idea is to make convolution over an incomplete sliding window \"collapse\" to a linear differential operator evaluated locally at its central pixel, which no longer requires information from the neighbouring missing pixels.","While the underlying theory is rigorous, our final formula turns out to be simple: the convolution over an incomplete window is achieved by convolving its nearest complete window with a transformed kernel.","This formula is computationally lightweight, involving neither interpolation or extrapolation nor restrictions on image and kernel sizes.","Our method favours data with smooth boundaries, such as high-resolution images and fields from physics.","Our experiments include: i) filtering analytical and non-analytical fields from computational physics and, ii) training convolutional neural networks (CNNs) for the tasks of image classification, semantic segmentation and super-resolution reconstruction.","In all these experiments, our method has exhibited visible superiority over the compared ones."],"url":"http://arxiv.org/abs/2309.06370v1"}
{"created":"2023-09-12 16:30:06","title":"Modeling Cognitive-Affective Processes with Appraisal and Reinforcement Learning","abstract":"Computational models can advance affective science by shedding light onto the interplay between cognition and emotion from an information processing point of view. We propose a computational model of emotion that integrates reinforcement learning (RL) and appraisal theory, establishing a formal relationship between reward processing, goal-directed task learning, cognitive appraisal and emotional experiences. The model achieves this by formalizing evaluative checks from the component process model (CPM) in terms of temporal difference learning updates. We formalized novelty, goal relevance, goal conduciveness, and power. The formalization is task independent and can be applied to any task that can be represented as a Markov decision problem (MDP) and solved using RL. We investigated to what extent CPM-RL enables simulation of emotional responses cased by interactive task events. We evaluate the model by predicting a range of human emotions based on a series of vignette studies, highlighting its potential in improving our understanding of the role of reward processing in affective experiences.","sentences":["Computational models can advance affective science by shedding light onto the interplay between cognition and emotion from an information processing point of view.","We propose a computational model of emotion that integrates reinforcement learning (RL) and appraisal theory, establishing a formal relationship between reward processing, goal-directed task learning, cognitive appraisal and emotional experiences.","The model achieves this by formalizing evaluative checks from the component process model (CPM) in terms of temporal difference learning updates.","We formalized novelty, goal relevance, goal conduciveness, and power.","The formalization is task independent and can be applied to any task that can be represented as a Markov decision problem (MDP) and solved using RL.","We investigated to what extent CPM-RL enables simulation of emotional responses cased by interactive task events.","We evaluate the model by predicting a range of human emotions based on a series of vignette studies, highlighting its potential in improving our understanding of the role of reward processing in affective experiences."],"url":"http://arxiv.org/abs/2309.06367v1"}
{"created":"2023-09-12 16:28:36","title":"Cited Text Spans for Citation Text Generation","abstract":"Automatic related work generation must ground their outputs to the content of the cited papers to avoid non-factual hallucinations, but due to the length of scientific documents, existing abstractive approaches have conditioned only on the cited paper \\textit{abstracts}. We demonstrate that the abstract is not always the most appropriate input for citation generation and that models trained in this way learn to hallucinate. We propose to condition instead on the \\textit{cited text span} (CTS) as an alternative to the abstract. Because manual CTS annotation is extremely time- and labor-intensive, we experiment with automatic, ROUGE-based labeling of candidate CTS sentences, achieving sufficiently strong performance to substitute for expensive human annotations, and we propose a human-in-the-loop, keyword-based CTS retrieval approach that makes generating citation texts grounded in the full text of cited papers both promising and practical.","sentences":["Automatic related work generation must ground their outputs to the content of the cited papers to avoid non-factual hallucinations, but due to the length of scientific documents, existing abstractive approaches have conditioned only on the cited paper \\textit{abstracts}.","We demonstrate that the abstract is not always the most appropriate input for citation generation and that models trained in this way learn to hallucinate.","We propose to condition instead on the \\textit{cited text span} (CTS) as an alternative to the abstract.","Because manual CTS annotation is extremely time- and labor-intensive, we experiment with automatic, ROUGE-based labeling of candidate CTS sentences, achieving sufficiently strong performance to substitute for expensive human annotations, and we propose a human-in-the-loop, keyword-based CTS retrieval approach that makes generating citation texts grounded in the full text of cited papers both promising and practical."],"url":"http://arxiv.org/abs/2309.06365v1"}
{"created":"2023-09-12 16:27:18","title":"Learning to Predict Concept Ordering for Common Sense Generation","abstract":"Prior work has shown that the ordering in which concepts are shown to a commonsense generator plays an important role, affecting the quality of the generated sentence. However, it remains a challenge to determine the optimal ordering of a given set of concepts such that a natural sentence covering all the concepts could be generated from a pretrained generator. To understand the relationship between the ordering of the input concepts and the quality of the generated sentences, we conduct a systematic study considering multiple language models (LMs) and concept ordering strategies. We find that BART-large model consistently outperforms all other LMs considered in this study when fine-tuned using the ordering of concepts as they appear in CommonGen training data as measured using multiple evaluation metrics. Moreover, the larger GPT3-based large language models (LLMs) variants do not necessarily outperform much smaller LMs on this task, even when fine-tuned on task-specific training data. Interestingly, human annotators significantly reorder input concept sets when manually writing sentences covering those concepts, and this ordering provides the best sentence generations independently of the LM used for the generation, outperforming a probabilistic concept ordering baseline","sentences":["Prior work has shown that the ordering in which concepts are shown to a commonsense generator plays an important role, affecting the quality of the generated sentence.","However, it remains a challenge to determine the optimal ordering of a given set of concepts such that a natural sentence covering all the concepts could be generated from a pretrained generator.","To understand the relationship between the ordering of the input concepts and the quality of the generated sentences, we conduct a systematic study considering multiple language models (LMs) and concept ordering strategies.","We find that BART-large model consistently outperforms all other LMs considered in this study when fine-tuned using the ordering of concepts as they appear in CommonGen training data as measured using multiple evaluation metrics.","Moreover, the larger GPT3-based large language models (LLMs) variants do not necessarily outperform much smaller LMs on this task, even when fine-tuned on task-specific training data.","Interestingly, human annotators significantly reorder input concept sets when manually writing sentences covering those concepts, and this ordering provides the best sentence generations independently of the LM used for the generation, outperforming a probabilistic concept ordering baseline"],"url":"http://arxiv.org/abs/2309.06363v1"}
{"created":"2023-09-12 16:20:20","title":"Using Reed-Muller Codes for Classification with Rejection and Recovery","abstract":"When deploying classifiers in the real world, users expect them to respond to inputs appropriately. However, traditional classifiers are not equipped to handle inputs which lie far from the distribution they were trained on. Malicious actors can exploit this defect by making adversarial perturbations designed to cause the classifier to give an incorrect output. Classification-with-rejection methods attempt to solve this problem by allowing networks to refuse to classify an input in which they have low confidence. This works well for strongly adversarial examples, but also leads to the rejection of weakly perturbed images, which intuitively could be correctly classified. To address these issues, we propose Reed-Muller Aggregation Networks (RMAggNet), a classifier inspired by Reed-Muller error-correction codes which can correct and reject inputs. This paper shows that RMAggNet can minimise incorrectness while maintaining good correctness over multiple adversarial attacks at different perturbation budgets by leveraging the ability to correct errors in the classification process. This provides an alternative classification-with-rejection method which can reduce the amount of additional processing in situations where a small number of incorrect classifications are permissible.","sentences":["When deploying classifiers in the real world, users expect them to respond to inputs appropriately.","However, traditional classifiers are not equipped to handle inputs which lie far from the distribution they were trained on.","Malicious actors can exploit this defect by making adversarial perturbations designed to cause the classifier to give an incorrect output.","Classification-with-rejection methods attempt to solve this problem by allowing networks to refuse to classify an input in which they have low confidence.","This works well for strongly adversarial examples, but also leads to the rejection of weakly perturbed images, which intuitively could be correctly classified.","To address these issues, we propose Reed-Muller Aggregation Networks (RMAggNet), a classifier inspired by Reed-Muller error-correction codes which can correct and reject inputs.","This paper shows that RMAggNet can minimise incorrectness while maintaining good correctness over multiple adversarial attacks at different perturbation budgets by leveraging the ability to correct errors in the classification process.","This provides an alternative classification-with-rejection method which can reduce the amount of additional processing in situations where a small number of incorrect classifications are permissible."],"url":"http://arxiv.org/abs/2309.06359v1"}
{"created":"2023-09-12 16:18:15","title":"Enhancing In-Memory Spatial Indexing with Learned Search","abstract":"Spatial data is ubiquitous. Massive amounts of data are generated every day from a plethora of sources such as billions of GPS-enabled devices (e.g., cell phones, cars, and sensors), consumer-based applications (e.g., Uber and Strava), and social media platforms (e.g., location-tagged posts on Facebook, Twitter, and Instagram). This exponential growth in spatial data has led the research community to build systems and applications for efficient spatial data processing.   In this study, we apply a recently developed machine-learned search technique for single-dimensional sorted data to spatial indexing. Specifically, we partition spatial data using six traditional spatial partitioning techniques and employ machine-learned search within each partition to support point, range, distance, and spatial join queries. Adhering to the latest research trends, we tune the partitioning techniques to be instance-optimized. By tuning each partitioning technique for optimal performance, we demonstrate that: (i) grid-based index structures outperform tree-based index structures (from 1.23$\\times$ to 2.47$\\times$), (ii) learning-enhanced variants of commonly used spatial index structures outperform their original counterparts (from 1.44$\\times$ to 53.34$\\times$ faster), (iii) machine-learned search within a partition is faster than binary search by 11.79% - 39.51% when filtering on one dimension, (iv) the benefit of machine-learned search diminishes in the presence of other compute-intensive operations (e.g. scan costs in higher selectivity queries, Haversine distance computation, and point-in-polygon tests), and (v) index lookup is the bottleneck for tree-based structures, which could potentially be reduced by linearizing the indexed partitions.","sentences":["Spatial data is ubiquitous.","Massive amounts of data are generated every day from a plethora of sources such as billions of GPS-enabled devices (e.g., cell phones, cars, and sensors), consumer-based applications (e.g., Uber and Strava), and social media platforms (e.g., location-tagged posts on Facebook, Twitter, and Instagram).","This exponential growth in spatial data has led the research community to build systems and applications for efficient spatial data processing.   ","In this study, we apply a recently developed machine-learned search technique for single-dimensional sorted data to spatial indexing.","Specifically, we partition spatial data using six traditional spatial partitioning techniques and employ machine-learned search within each partition to support point, range, distance, and spatial join queries.","Adhering to the latest research trends, we tune the partitioning techniques to be instance-optimized.","By tuning each partitioning technique for optimal performance, we demonstrate that: (i) grid-based index structures outperform tree-based index structures (from 1.23$\\times$ to 2.47$\\times$), (ii) learning-enhanced variants of commonly used spatial index structures outperform their original counterparts (from 1.44$\\times$ to 53.34$\\times$ faster), (iii) machine-learned search within a partition is faster than binary search by 11.79% - 39.51% when filtering on one dimension, (iv) the benefit of machine-learned search diminishes in the presence of other compute-intensive operations (e.g. scan costs in higher selectivity queries, Haversine distance computation, and point-in-polygon tests), and (v) index lookup is the bottleneck for tree-based structures, which could potentially be reduced by linearizing the indexed partitions."],"url":"http://arxiv.org/abs/2309.06354v1"}
{"created":"2023-09-12 16:16:47","title":"Lighter-Than-Air Autonomous Ball Capture and Scoring Robot -- Design, Development, and Deployment","abstract":"This paper describes the full end-to-end design of our primary scoring agent in an aerial autonomous robotics competition from April 2023. As open-ended robotics competitions become more popular, we wish to begin documenting successful team designs and approaches. The intended audience of this paper is not only any future or potential participant in this particular national Defend The Republic (DTR) competition, but rather anyone thinking about designing their first robot or system to be entered in a competition with clear goals. Future DTR participants can and should either build on the ideas here, or find new alternate strategies that can defeat the most successful design last time. For non-DTR participants but students interested in robotics competitions, identifying the minimum viable system needed to be competitive is still important in helping manage time and prioritizing tasks that are crucial to competition success first.","sentences":["This paper describes the full end-to-end design of our primary scoring agent in an aerial autonomous robotics competition from April 2023.","As open-ended robotics competitions become more popular, we wish to begin documenting successful team designs and approaches.","The intended audience of this paper is not only any future or potential participant in this particular national Defend The Republic (DTR) competition, but rather anyone thinking about designing their first robot or system to be entered in a competition with clear goals.","Future DTR participants can and should either build on the ideas here, or find new alternate strategies that can defeat the most successful design last time.","For non-DTR participants but students interested in robotics competitions, identifying the minimum viable system needed to be competitive is still important in helping manage time and prioritizing tasks that are crucial to competition success first."],"url":"http://arxiv.org/abs/2309.06352v1"}
{"created":"2023-09-12 16:16:25","title":"Chemically inspired Erd\u0151s-R\u00e9nyi oriented hypergraphs","abstract":"High-order structures have been recognised as suitable models for systems going beyond the binary relationships for which graph models are appropriate. Despite their importance and surge in research on these structures, their random cases have been only recently become subjects of interest. One of these high-order structures is the oriented hypergraph, which relates couples of subsets of an arbitrary number of vertices. Here we develop the Erd\\H{o}s-R\\'enyi model for oriented hypergraphs, which corresponds to the random realisation of oriented hyperedges of the complete oriented hypergraph. A particular feature of random oriented hypergraphs is that the ratio between their expected number of oriented hyperedges and their expected degree or size is 3/2 for large number of vertices. We highlight the suitability of oriented hypergraphs for modelling large collections of chemical reactions and the importance of random oriented hypergraphs to analyse the unfolding of chemistry.","sentences":["High-order structures have been recognised as suitable models for systems going beyond the binary relationships for which graph models are appropriate.","Despite their importance and surge in research on these structures, their random cases have been only recently become subjects of interest.","One of these high-order structures is the oriented hypergraph, which relates couples of subsets of an arbitrary number of vertices.","Here we develop the Erd\\H{o}s-R\\'enyi model for oriented hypergraphs, which corresponds to the random realisation of oriented hyperedges of the complete oriented hypergraph.","A particular feature of random oriented hypergraphs is that the ratio between their expected number of oriented hyperedges and their expected degree or size is 3/2 for large number of vertices.","We highlight the suitability of oriented hypergraphs for modelling large collections of chemical reactions and the importance of random oriented hypergraphs to analyse the unfolding of chemistry."],"url":"http://arxiv.org/abs/2309.06351v1"}
{"created":"2023-09-12 16:02:07","title":"Making Network Configuration Human Friendly","abstract":"This paper explores opportunities to utilize Large Language Models (LLMs) to make network configuration human-friendly, simplifying the configuration of network devices and minimizing errors. We examine the effectiveness of these models in translating high-level policies and requirements (i.e., specified in natural language) into low-level network APIs, which requires understanding the hardware and protocols. More specifically, we propose NETBUDDY for generating network configurations from scratch and modifying them at runtime. NETBUDDY splits the generation of network configurations into fine-grained steps and relies on self-healing code-generation approaches to better take advantage of the full potential of LLMs. We first thoroughly examine the challenges of using these models to produce a fully functional & correct configuration, and then evaluate the feasibility of realizing NETBUDDY by building a proof-of-concept solution using GPT-4 to translate a set of high-level requirements into P4 and BGP configurations and run them using the Kathar\\'a network emulator.","sentences":["This paper explores opportunities to utilize Large Language Models (LLMs) to make network configuration human-friendly, simplifying the configuration of network devices and minimizing errors.","We examine the effectiveness of these models in translating high-level policies and requirements (i.e., specified in natural language) into low-level network APIs, which requires understanding the hardware and protocols.","More specifically, we propose NETBUDDY for generating network configurations from scratch and modifying them at runtime.","NETBUDDY splits the generation of network configurations into fine-grained steps and relies on self-healing code-generation approaches to better take advantage of the full potential of LLMs.","We first thoroughly examine the challenges of using these models to produce a fully functional & correct configuration, and then evaluate the feasibility of realizing NETBUDDY by building a proof-of-concept solution using GPT-4 to translate a set of high-level requirements into P4 and BGP configurations and run them using the Kathar\\'a network emulator."],"url":"http://arxiv.org/abs/2309.06342v1"}
{"created":"2023-09-12 15:55:14","title":"Exploring Flat Minima for Domain Generalization with Large Learning Rates","abstract":"Domain Generalization (DG) aims to generalize to arbitrary unseen domains. A promising approach to improve model generalization in DG is the identification of flat minima. One typical method for this task is SWAD, which involves averaging weights along the training trajectory. However, the success of weight averaging depends on the diversity of weights, which is limited when training with a small learning rate. Instead, we observe that leveraging a large learning rate can simultaneously promote weight diversity and facilitate the identification of flat regions in the loss landscape. However, employing a large learning rate suffers from the convergence problem, which cannot be resolved by simply averaging the training weights. To address this issue, we introduce a training strategy called Lookahead which involves the weight interpolation, instead of average, between fast and slow weights. The fast weight explores the weight space with a large learning rate, which is not converged while the slow weight interpolates with it to ensure the convergence. Besides, weight interpolation also helps identify flat minima by implicitly optimizing the local entropy loss that measures flatness. To further prevent overfitting during training, we propose two variants to regularize the training weight with weighted averaged weight or with accumulated history weight. Taking advantage of this new perspective, our methods achieve state-of-the-art performance on both classification and semantic segmentation domain generalization benchmarks. The code is available at https://github.com/koncle/DG-with-Large-LR.","sentences":["Domain Generalization (DG) aims to generalize to arbitrary unseen domains.","A promising approach to improve model generalization in DG is the identification of flat minima.","One typical method for this task is SWAD, which involves averaging weights along the training trajectory.","However, the success of weight averaging depends on the diversity of weights, which is limited when training with a small learning rate.","Instead, we observe that leveraging a large learning rate can simultaneously promote weight diversity and facilitate the identification of flat regions in the loss landscape.","However, employing a large learning rate suffers from the convergence problem, which cannot be resolved by simply averaging the training weights.","To address this issue, we introduce a training strategy called Lookahead which involves the weight interpolation, instead of average, between fast and slow weights.","The fast weight explores the weight space with a large learning rate, which is not converged while the slow weight interpolates with it to ensure the convergence.","Besides, weight interpolation also helps identify flat minima by implicitly optimizing the local entropy loss that measures flatness.","To further prevent overfitting during training, we propose two variants to regularize the training weight with weighted averaged weight or with accumulated history weight.","Taking advantage of this new perspective, our methods achieve state-of-the-art performance on both classification and semantic segmentation domain generalization benchmarks.","The code is available at https://github.com/koncle/DG-with-Large-LR."],"url":"http://arxiv.org/abs/2309.06337v1"}
{"created":"2023-09-12 15:52:08","title":"Grounded Language Acquisition From Object and Action Imagery","abstract":"Deep learning approaches to natural language processing have made great strides in recent years. While these models produce symbols that convey vast amounts of diverse knowledge, it is unclear how such symbols are grounded in data from the world. In this paper, we explore the development of a private language for visual data representation by training emergent language (EL) encoders/decoders in both i) a traditional referential game environment and ii) a contrastive learning environment utilizing a within-class matching training paradigm. An additional classification layer utilizing neural machine translation and random forest classification was used to transform symbolic representations (sequences of integer symbols) to class labels. These methods were applied in two experiments focusing on object recognition and action recognition. For object recognition, a set of sketches produced by human participants from real imagery was used (Sketchy dataset) and for action recognition, 2D trajectories were generated from 3D motion capture systems (MOVI dataset). In order to interpret the symbols produced for data in each experiment, gradient-weighted class activation mapping (Grad-CAM) methods were used to identify pixel regions indicating semantic features which contribute evidence towards symbols in learned languages. Additionally, a t-distributed stochastic neighbor embedding (t-SNE) method was used to investigate embeddings learned by CNN feature extractors.","sentences":["Deep learning approaches to natural language processing have made great strides in recent years.","While these models produce symbols that convey vast amounts of diverse knowledge, it is unclear how such symbols are grounded in data from the world.","In this paper, we explore the development of a private language for visual data representation by training emergent language (EL) encoders/decoders in both i) a traditional referential game environment and ii) a contrastive learning environment utilizing a within-class matching training paradigm.","An additional classification layer utilizing neural machine translation and random forest classification was used to transform symbolic representations (sequences of integer symbols) to class labels.","These methods were applied in two experiments focusing on object recognition and action recognition.","For object recognition, a set of sketches produced by human participants from real imagery was used (Sketchy dataset) and for action recognition, 2D trajectories were generated from 3D motion capture systems (MOVI dataset).","In order to interpret the symbols produced for data in each experiment, gradient-weighted class activation mapping (Grad-CAM) methods were used to identify pixel regions indicating semantic features which contribute evidence towards symbols in learned languages.","Additionally, a t-distributed stochastic neighbor embedding (t-SNE) method was used to investigate embeddings learned by CNN feature extractors."],"url":"http://arxiv.org/abs/2309.06335v1"}
{"created":"2023-09-12 15:42:18","title":"Visualising Game Engine Subsystem Coupling","abstract":"Game engines support video game development by providing functionalities such as graphics rendering or input/output device management. However, their architectures are often overlooked, which hinders their integration and extension. In this paper, we use an approach for architecture recovery to create architectural models for 10 open-source game engines. We use these models to answer the following questions: Which subsystems more often couple with one another? Do game engines share subsystem coupling patterns? We observe that the Low-Level Renderer, Platform Independence Layer and Resource Manager are frequently coupled to the game engine Core. By identifying the most frequent coupling patterns, we describe an emergent game engine architecture and discuss how it can be used by practitioners to improve system understanding and maintainability.","sentences":["Game engines support video game development by providing functionalities such as graphics rendering or input/output device management.","However, their architectures are often overlooked, which hinders their integration and extension.","In this paper, we use an approach for architecture recovery to create architectural models for 10 open-source game engines.","We use these models to answer the following questions: Which subsystems more often couple with one another?","Do game engines share subsystem coupling patterns?","We observe that the Low-Level Renderer, Platform Independence Layer and Resource Manager are frequently coupled to the game engine Core.","By identifying the most frequent coupling patterns, we describe an emergent game engine architecture and discuss how it can be used by practitioners to improve system understanding and maintainability."],"url":"http://arxiv.org/abs/2309.06329v1"}
{"created":"2023-09-12 15:38:16","title":"A Simple Multiple-Access Design for Reconfigurable Intelligent Surface-Aided Systems","abstract":"This paper focuses on the design of transmission methods and reflection optimization for a wireless system assisted by a single or multiple reconfigurable intelligent surfaces (RISs). The existing techniques are either too complex to implement in practical systems or too inefficient to achieve high performance. To overcome the shortcomings of the existing schemes, we propose a simple but efficient approach based on \\textit{opportunistic reflection} and \\textit{non-orthogonal transmission}. The key idea is opportunistically selecting the best user that can reap the maximal gain from the optimally reflected signals via RIS. That is to say, only the channel state information of the best user is used for RIS reflection optimization, which can in turn lower complexity substantially. In addition, the second user is selected to superpose its signal on that of the primary user, where the benefits of non-orthogonal transmission, i.e., high system capacity and improved user fairness, are obtained. Additionally, a simplified variant exploiting random phase shifts is proposed to avoid the high overhead of RIS channel estimation.","sentences":["This paper focuses on the design of transmission methods and reflection optimization for a wireless system assisted by a single or multiple reconfigurable intelligent surfaces (RISs).","The existing techniques are either too complex to implement in practical systems or too inefficient to achieve high performance.","To overcome the shortcomings of the existing schemes, we propose a simple but efficient approach based on \\textit{opportunistic reflection} and \\textit{non-orthogonal transmission}.","The key idea is opportunistically selecting the best user that can reap the maximal gain from the optimally reflected signals via RIS.","That is to say, only the channel state information of the best user is used for RIS reflection optimization, which can in turn lower complexity substantially.","In addition, the second user is selected to superpose its signal on that of the primary user, where the benefits of non-orthogonal transmission, i.e., high system capacity and improved user fairness, are obtained.","Additionally, a simplified variant exploiting random phase shifts is proposed to avoid the high overhead of RIS channel estimation."],"url":"http://arxiv.org/abs/2309.06326v1"}
{"created":"2023-09-12 15:37:44","title":"Distributed Precoding for Satellite-Terrestrial Integrated Networks Without Sharing CSIT: A Rate-Splitting Approach","abstract":"Satellite-terrestrial integrated networks (STINs) are promising architecture for providing global coverage. In STINs, full frequency reuse between a satellite and a terrestrial base station (BS) is encouraged for enhancing spectral efficiency, which accounts for non-negligible amount of interference. To address the interference management problem in STINs, this paper proposes a novel distributed precoding method. Key features of our method are: i) a rate-splitting (RS) strategy is incorporated for efficient interference management, ii) precoders are designed in a distributed way without sharing channel state information between a satellite and a terrestrial BS. Specifically, to design precoders in a distributed fashion, we put forth a spectral efficiency decoupling technique. This technique disentangles the total spectral efficiency into two distinct terms, each dependent solely on the satellite's precoder and the terrestrial BS's precoder, respectively. Then, to resolve the non-smoothness raised by adopting the RS strategy, we approximate the spectral efficiency expression as a smooth function; thereafter we develop a generalized power iteration inspired optimization algorithm built based on the first-order optimality condition. Simulation results demonstrate that the proposed method improves the spectral efficiency (around 20~29%) compared to existing distributed precoding schemes.","sentences":["Satellite-terrestrial integrated networks (STINs) are promising architecture for providing global coverage.","In STINs, full frequency reuse between a satellite and a terrestrial base station (BS) is encouraged for enhancing spectral efficiency, which accounts for non-negligible amount of interference.","To address the interference management problem in STINs, this paper proposes a novel distributed precoding method.","Key features of our method are: i) a rate-splitting (RS) strategy is incorporated for efficient interference management, ii) precoders are designed in a distributed way without sharing channel state information between a satellite and a terrestrial BS.","Specifically, to design precoders in a distributed fashion, we put forth a spectral efficiency decoupling technique.","This technique disentangles the total spectral efficiency into two distinct terms, each dependent solely on the satellite's precoder and the terrestrial BS's precoder, respectively.","Then, to resolve the non-smoothness raised by adopting the RS strategy, we approximate the spectral efficiency expression as a smooth function; thereafter we develop a generalized power iteration inspired optimization algorithm built based on the first-order optimality condition.","Simulation results demonstrate that the proposed method improves the spectral efficiency (around 20~29%) compared to existing distributed precoding schemes."],"url":"http://arxiv.org/abs/2309.06325v1"}
{"created":"2023-09-12 15:33:09","title":"SAMPLING: Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image","abstract":"Recent novel view synthesis methods obtain promising results for relatively small scenes, e.g., indoor environments and scenes with a few objects, but tend to fail for unbounded outdoor scenes with a single image as input. In this paper, we introduce SAMPLING, a Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image based on improved multiplane images (MPI). Observing that depth distribution varies significantly for unbounded outdoor scenes, we employ an adaptive-bins strategy for MPI to arrange planes in accordance with each scene image. To represent intricate geometry and multi-scale details, we further introduce a hierarchical refinement branch, which results in high-quality synthesized novel views. Our method demonstrates considerable performance gains in synthesizing large-scale unbounded outdoor scenes using a single image on the KITTI dataset and generalizes well to the unseen Tanks and Temples dataset. The code and models will be made public.","sentences":["Recent novel view synthesis methods obtain promising results for relatively small scenes, e.g., indoor environments and scenes with a few objects, but tend to fail for unbounded outdoor scenes with a single image as input.","In this paper, we introduce SAMPLING, a Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image based on improved multiplane images (MPI).","Observing that depth distribution varies significantly for unbounded outdoor scenes, we employ an adaptive-bins strategy for MPI to arrange planes in accordance with each scene image.","To represent intricate geometry and multi-scale details, we further introduce a hierarchical refinement branch, which results in high-quality synthesized novel views.","Our method demonstrates considerable performance gains in synthesizing large-scale unbounded outdoor scenes using a single image on the KITTI dataset and generalizes well to the unseen Tanks and Temples dataset.","The code and models will be made public."],"url":"http://arxiv.org/abs/2309.06323v1"}
{"created":"2023-09-12 15:32:36","title":"Preliminary Results from a U.S. Demographic Analysis of SMiSh Susceptibility","abstract":"As adoption of mobile phones has skyrocketed, so have scams involving them. The text method is called SMiShing, (aka SMShing, or smishing) in which a fraudster sends a phishing link via Short Message Service (SMS) text to a phone. However, no data exists on who is most vulnerable to SMiShing. Prior work in phishing (its e-mail cousin) indicates that this is likely to vary by demographic and contextual factors. In our study, we collect this data from N=1007 U.S. adult mobile phone users. Younger people and college students emerge in this sample as the most vulnerable. Participants struggled to correctly identify legitimate messages and were easily misled when they knew they had an account with the faked message entity. Counterintuitively, participants with higher levels of security training and awareness were less correct in rating possible SMiSH. We recommend next steps for researchers, regulators and telecom providers.","sentences":["As adoption of mobile phones has skyrocketed, so have scams involving them.","The text method is called SMiShing, (aka SMShing, or smishing) in which a fraudster sends a phishing link via Short Message Service (SMS) text to a phone.","However, no data exists on who is most vulnerable to SMiShing.","Prior work in phishing (its e-mail cousin) indicates that this is likely to vary by demographic and contextual factors.","In our study, we collect this data from N=1007 U.S. adult mobile phone users.","Younger people and college students emerge in this sample as the most vulnerable.","Participants struggled to correctly identify legitimate messages and were easily misled when they knew they had an account with the faked message entity.","Counterintuitively, participants with higher levels of security training and awareness were less correct in rating possible SMiSH.","We recommend next steps for researchers, regulators and telecom providers."],"url":"http://arxiv.org/abs/2309.06322v1"}
{"created":"2023-09-12 15:27:50","title":"The Time Complexity of Fully Sparse Matrix Multiplication","abstract":"What is the time complexity of matrix multiplication of sparse integer matrices with $m_{in}$ nonzeros in the input and $m_{out}$ nonzeros in the output? This paper provides improved upper bounds for this question for almost any choice of $m_{in}$ vs. $m_{out}$, and provides evidence that these new bounds might be optimal up to further progress on fast matrix multiplication.   Our main contribution is a new algorithm that reduces sparse matrix multiplication to dense (but smaller) rectangular matrix multiplication. Our running time thus depends on the optimal exponent $\\omega(a,b,c)$ of multiplying dense $n^a\\times n^b$ by $n^b\\times n^c$ matrices. We discover that when $m_{out}=\\Theta(m_{in}^r)$ the time complexity of sparse matrix multiplication is $O(m_{in}^{\\sigma+\\epsilon})$, for all $\\epsilon > 0$, where $\\sigma$ is the solution to the equation $\\omega(\\sigma-1,2-\\sigma,1+r-\\sigma)=\\sigma$. No matter what $\\omega(\\cdot,\\cdot,\\cdot)$ turns out to be, and for all $r\\in(0,2)$, the new bound beats the state of the art, and we provide evidence that it is optimal based on the complexity of the all-edge triangle problem.   In particular, in terms of the input plus output size $m = m_{in} + m_{out}$ our algorithm runs in time $O(m^{1.3459})$. Even for Boolean matrices, this improves over the previous $m^{\\frac{2\\omega}{\\omega+1}+\\epsilon}=O(m^{1.4071})$ bound [Amossen, Pagh; 2009], which was a natural barrier since it coincides with the longstanding bound of all-edge triangle in sparse graphs [Alon, Yuster, Zwick; 1994]. We find it interesting that matrix multiplication can be solved faster than triangle detection in this natural setting. In fact, we establish an equivalence to a special case of the all-edge triangle problem.","sentences":["What is the time complexity of matrix multiplication of sparse integer matrices with $m_{in}$ nonzeros in the input and $m_{out}$ nonzeros in the output?","This paper provides improved upper bounds for this question for almost any choice of $m_{in}$ vs. $m_{out}$, and provides evidence that these new bounds might be optimal up to further progress on fast matrix multiplication.   ","Our main contribution is a new algorithm that reduces sparse matrix multiplication to dense (but smaller) rectangular matrix multiplication.","Our running time thus depends on the optimal exponent $\\omega(a,b,c)$ of multiplying dense $n^a\\times n^b$ by $n^b\\times n^c$ matrices.","We discover that when $m_{out}=\\Theta(m_{in}^r)$ the time complexity of sparse matrix multiplication is $O(m_{in}^{\\sigma+\\epsilon})$, for all $\\epsilon > 0$, where $\\sigma$ is the solution to the equation $\\omega(\\sigma-1,2-\\sigma,1+r-\\sigma)=\\sigma$. No matter what $\\omega(\\cdot,\\cdot,\\cdot)$ turns out to be, and for all $r\\in(0,2)$, the new bound beats the state of the art, and we provide evidence that it is optimal based on the complexity of the all-edge triangle problem.   ","In particular, in terms of the input plus output size $m = m_{in} + m_{out}$ our algorithm runs in time $O(m^{1.3459})$. Even for Boolean matrices, this improves over the previous $m^{\\frac{2\\omega}{\\omega+1}+\\epsilon}=O(m^{1.4071})$ bound [Amossen, Pagh; 2009], which was a natural barrier since it coincides with the longstanding bound of all-edge triangle in sparse graphs","[Alon, Yuster, Zwick; 1994].","We find it interesting that matrix multiplication can be solved faster than triangle detection in this natural setting.","In fact, we establish an equivalence to a special case of the all-edge triangle problem."],"url":"http://arxiv.org/abs/2309.06317v1"}
{"created":"2023-09-12 15:27:00","title":"Learning Minimalistic Tsetlin Machine Clauses with Markov Boundary-Guided Pruning","abstract":"A set of variables is the Markov blanket of a random variable if it contains all the information needed for predicting the variable. If the blanket cannot be reduced without losing useful information, it is called a Markov boundary. Identifying the Markov boundary of a random variable is advantageous because all variables outside the boundary are superfluous. Hence, the Markov boundary provides an optimal feature set. However, learning the Markov boundary from data is challenging for two reasons. If one or more variables are removed from the Markov boundary, variables outside the boundary may start providing information. Conversely, variables within the boundary may stop providing information. The true role of each candidate variable is only manifesting when the Markov boundary has been identified. In this paper, we propose a new Tsetlin Machine (TM) feedback scheme that supplements Type I and Type II feedback. The scheme introduces a novel Finite State Automaton - a Context-Specific Independence Automaton. The automaton learns which features are outside the Markov boundary of the target, allowing them to be pruned from the TM during learning. We investigate the new scheme empirically, showing how it is capable of exploiting context-specific independence to find Markov boundaries. Further, we provide a theoretical analysis of convergence. Our approach thus connects the field of Bayesian networks (BN) with TMs, potentially opening up for synergies when it comes to inference and learning, including TM-produced Bayesian knowledge bases and TM-based Bayesian inference.","sentences":["A set of variables is the Markov blanket of a random variable if it contains all the information needed for predicting the variable.","If the blanket cannot be reduced without losing useful information, it is called a Markov boundary.","Identifying the Markov boundary of a random variable is advantageous because all variables outside the boundary are superfluous.","Hence, the Markov boundary provides an optimal feature set.","However, learning the Markov boundary from data is challenging for two reasons.","If one or more variables are removed from the Markov boundary, variables outside the boundary may start providing information.","Conversely, variables within the boundary may stop providing information.","The true role of each candidate variable is only manifesting when the Markov boundary has been identified.","In this paper, we propose a new Tsetlin Machine (TM) feedback scheme that supplements Type I and Type II","feedback",".","The scheme introduces a novel Finite State Automaton - a Context-Specific Independence Automaton.","The automaton learns which features are outside the Markov boundary of the target, allowing them to be pruned from the TM during learning.","We investigate the new scheme empirically, showing how it is capable of exploiting context-specific independence to find Markov boundaries.","Further, we provide a theoretical analysis of convergence.","Our approach thus connects the field of Bayesian networks (BN) with TMs, potentially opening up for synergies when it comes to inference and learning, including TM-produced Bayesian knowledge bases and TM-based Bayesian inference."],"url":"http://arxiv.org/abs/2309.06315v1"}
{"created":"2023-09-12 15:24:26","title":"Semantic and Articulated Pedestrian Sensing Onboard a Moving Vehicle","abstract":"It is difficult to perform 3D reconstruction from on-vehicle gathered video due to the large forward motion of the vehicle. Even object detection and human sensing models perform significantly worse on onboard videos when compared to standard benchmarks because objects often appear far away from the camera compared to the standard object detection benchmarks, image quality is often decreased by motion blur and occlusions occur often. This has led to the popularisation of traffic data-specific benchmarks. Recently Light Detection And Ranging (LiDAR) sensors have become popular to directly estimate depths without the need to perform 3D reconstructions. However, LiDAR-based methods still lack in articulated human detection at a distance when compared to image-based methods. We hypothesize that benchmarks targeted at articulated human sensing from LiDAR data could bring about increased research in human sensing and prediction in traffic and could lead to improved traffic safety for pedestrians.","sentences":["It is difficult to perform 3D reconstruction from on-vehicle gathered video due to the large forward motion of the vehicle.","Even object detection and human sensing models perform significantly worse on onboard videos when compared to standard benchmarks because objects often appear far away from the camera compared to the standard object detection benchmarks, image quality is often decreased by motion blur and occlusions occur often.","This has led to the popularisation of traffic data-specific benchmarks.","Recently Light Detection","And Ranging (LiDAR) sensors have become popular to directly estimate depths without the need to perform 3D reconstructions.","However, LiDAR-based methods still lack in articulated human detection at a distance when compared to image-based methods.","We hypothesize that benchmarks targeted at articulated human sensing from LiDAR data could bring about increased research in human sensing and prediction in traffic and could lead to improved traffic safety for pedestrians."],"url":"http://arxiv.org/abs/2309.06313v1"}
{"created":"2023-09-12 15:20:04","title":"A Natural Intuitionistic Modal Logic: Axiomatization and Bi-nested Calculus","abstract":"We introduce FIK, a natural intuitionistic modal logic specified by Kripke models satisfying the condition of forward confluence. We give a complete Hilbert-style axiomatization of this logic and propose a bi-nested calculus for it. The calculus provides a decision procedure as well as a countermodel extraction: from any failed derivation of a given formula, we obtain by the calculus a finite countermodel of it.","sentences":["We introduce FIK, a natural intuitionistic modal logic specified by Kripke models satisfying the condition of forward confluence.","We give a complete Hilbert-style axiomatization of this logic and propose a bi-nested calculus for it.","The calculus provides a decision procedure as well as a countermodel extraction: from any failed derivation of a given formula, we obtain by the calculus a finite countermodel of it."],"url":"http://arxiv.org/abs/2309.06309v1"}
{"created":"2023-09-12 15:19:36","title":"AI4Food-NutritionFW: A Novel Framework for the Automatic Synthesis and Analysis of Eating Behaviours","abstract":"Nowadays millions of images are shared on social media and web platforms. In particular, many of them are food images taken from a smartphone over time, providing information related to the individual's diet. On the other hand, eating behaviours are directly related to some of the most prevalent diseases in the world. Exploiting recent advances in image processing and Artificial Intelligence (AI), this scenario represents an excellent opportunity to: i) create new methods that analyse the individuals' health from what they eat, and ii) develop personalised recommendations to improve nutrition and diet under specific circumstances (e.g., obesity or COVID). Having tunable tools for creating food image datasets that facilitate research in both lines is very much needed.   This paper proposes AI4Food-NutritionFW, a framework for the creation of food image datasets according to configurable eating behaviours. AI4Food-NutritionFW simulates a user-friendly and widespread scenario where images are taken using a smartphone. In addition to the framework, we also provide and describe a unique food image dataset that includes 4,800 different weekly eating behaviours from 15 different profiles and 1,200 subjects. Specifically, we consider profiles that comply with actual lifestyles from healthy eating behaviours (according to established knowledge), variable profiles (e.g., eating out, holidays), to unhealthy ones (e.g., excess of fast food or sweets). Finally, we automatically evaluate a healthy index of the subject's eating behaviours using multidimensional metrics based on guidelines for healthy diets proposed by international organisations, achieving promising results (99.53% and 99.60% accuracy and sensitivity, respectively). We also release to the research community a software implementation of our proposed AI4Food-NutritionFW and the mentioned food image dataset created with it.","sentences":["Nowadays millions of images are shared on social media and web platforms.","In particular, many of them are food images taken from a smartphone over time, providing information related to the individual's diet.","On the other hand, eating behaviours are directly related to some of the most prevalent diseases in the world.","Exploiting recent advances in image processing and Artificial Intelligence (AI), this scenario represents an excellent opportunity to: i) create new methods that analyse the individuals' health from what they eat, and ii) develop personalised recommendations to improve nutrition and diet under specific circumstances (e.g., obesity or COVID).","Having tunable tools for creating food image datasets that facilitate research in both lines is very much needed.   ","This paper proposes AI4Food-NutritionFW, a framework for the creation of food image datasets according to configurable eating behaviours.","AI4Food-NutritionFW simulates a user-friendly and widespread scenario where images are taken using a smartphone.","In addition to the framework, we also provide and describe a unique food image dataset that includes 4,800 different weekly eating behaviours from 15 different profiles and 1,200 subjects.","Specifically, we consider profiles that comply with actual lifestyles from healthy eating behaviours (according to established knowledge), variable profiles (e.g., eating out, holidays), to unhealthy ones (e.g., excess of fast food or sweets).","Finally, we automatically evaluate a healthy index of the subject's eating behaviours using multidimensional metrics based on guidelines for healthy diets proposed by international organisations, achieving promising results (99.53% and 99.60% accuracy and sensitivity, respectively).","We also release to the research community a software implementation of our proposed AI4Food-NutritionFW and the mentioned food image dataset created with it."],"url":"http://arxiv.org/abs/2309.06308v1"}
{"created":"2023-09-12 15:17:16","title":"CDL: A fast and flexible library for the study of permutation sets with structural restrictions","abstract":"In this paper, we introduce CDL, a software library designed for the analysis of permutations and linear orders subject to various structural restrictions. Prominent examples of these restrictions include pattern avoidance, a topic of interest in both computer science and combinatorics, and \"never conditions\" utilized in social choice and voting theory.   CDL offers a range of fundamental functionalities, including identifying the permutations that meet specific restrictions and determining the isomorphism of such sets. To facilitate exploration across extensive domains, CDL incorporates multiple search strategies and heuristics.","sentences":["In this paper, we introduce CDL, a software library designed for the analysis of permutations and linear orders subject to various structural restrictions.","Prominent examples of these restrictions include pattern avoidance, a topic of interest in both computer science and combinatorics, and \"never conditions\" utilized in social choice and voting theory.   ","CDL offers a range of fundamental functionalities, including identifying the permutations that meet specific restrictions and determining the isomorphism of such sets.","To facilitate exploration across extensive domains, CDL incorporates multiple search strategies and heuristics."],"url":"http://arxiv.org/abs/2309.06306v1"}
{"created":"2023-09-12 15:10:23","title":"Towards High-Quality Specular Highlight Removal by Leveraging Large-Scale Synthetic Data","abstract":"This paper aims to remove specular highlights from a single object-level image. Although previous methods have made some progresses, their performance remains somewhat limited, particularly for real images with complex specular highlights. To this end, we propose a three-stage network to address them. Specifically, given an input image, we first decompose it into the albedo, shading, and specular residue components to estimate a coarse specular-free image. Then, we further refine the coarse result to alleviate its visual artifacts such as color distortion. Finally, we adjust the tone of the refined result to match that of the input as closely as possible. In addition, to facilitate network training and quantitative evaluation, we present a large-scale synthetic dataset of object-level images, covering diverse objects and illumination conditions. Extensive experiments illustrate that our network is able to generalize well to unseen real object-level images, and even produce good results for scene-level images with multiple background objects and complex lighting.","sentences":["This paper aims to remove specular highlights from a single object-level image.","Although previous methods have made some progresses, their performance remains somewhat limited, particularly for real images with complex specular highlights.","To this end, we propose a three-stage network to address them.","Specifically, given an input image, we first decompose it into the albedo, shading, and specular residue components to estimate a coarse specular-free image.","Then, we further refine the coarse result to alleviate its visual artifacts such as color distortion.","Finally, we adjust the tone of the refined result to match that of the input as closely as possible.","In addition, to facilitate network training and quantitative evaluation, we present a large-scale synthetic dataset of object-level images, covering diverse objects and illumination conditions.","Extensive experiments illustrate that our network is able to generalize well to unseen real object-level images, and even produce good results for scene-level images with multiple background objects and complex lighting."],"url":"http://arxiv.org/abs/2309.06302v1"}
{"created":"2023-09-12 15:05:11","title":"Modeling Supply and Demand in Public Transportation Systems","abstract":"The Harrisonburg Department of Public Transportation (HDPT) aims to leverage their data to improve the efficiency and effectiveness of their operations. We construct two supply and demand models that help the department identify gaps in their service. The models take many variables into account, including the way that the HDPT reports to the federal government and the areas with the most vulnerable populations in Harrisonburg City. We employ data analysis and machine learning techniques to make our predictions.","sentences":["The Harrisonburg Department of Public Transportation (HDPT) aims to leverage their data to improve the efficiency and effectiveness of their operations.","We construct two supply and demand models that help the department identify gaps in their service.","The models take many variables into account, including the way that the HDPT reports to the federal government and the areas with the most vulnerable populations in Harrisonburg City.","We employ data analysis and machine learning techniques to make our predictions."],"url":"http://arxiv.org/abs/2309.06299v1"}
{"created":"2023-09-12 14:50:14","title":"Self-Training and Multi-Task Learning for Limited Data: Evaluation Study on Object Detection","abstract":"Self-training allows a network to learn from the predictions of a more complicated model, thus often requires well-trained teacher models and mixture of teacher-student data while multi-task learning jointly optimizes different targets to learn salient interrelationship and requires multi-task annotations for each training example. These frameworks, despite being particularly data demanding have potentials for data exploitation if such assumptions can be relaxed. In this paper, we compare self-training object detection under the deficiency of teacher training data where students are trained on unseen examples by the teacher, and multi-task learning with partially annotated data, i.e. single-task annotation per training example. Both scenarios have their own limitation but potentially helpful with limited annotated data. Experimental results show the improvement of performance when using a weak teacher with unseen data for training a multi-task student. Despite the limited setup we believe the experimental results show the potential of multi-task knowledge distillation and self-training, which could be beneficial for future study. Source code is at https://lhoangan.github.io/multas.","sentences":["Self-training allows a network to learn from the predictions of a more complicated model, thus often requires well-trained teacher models and mixture of teacher-student data while multi-task learning jointly optimizes different targets to learn salient interrelationship and requires multi-task annotations for each training example.","These frameworks, despite being particularly data demanding have potentials for data exploitation if such assumptions can be relaxed.","In this paper, we compare self-training object detection under the deficiency of teacher training data where students are trained on unseen examples by the teacher, and multi-task learning with partially annotated data, i.e. single-task annotation per training example.","Both scenarios have their own limitation but potentially helpful with limited annotated data.","Experimental results show the improvement of performance when using a weak teacher with unseen data for training a multi-task student.","Despite the limited setup we believe the experimental results show the potential of multi-task knowledge distillation and self-training, which could be beneficial for future study.","Source code is at https://lhoangan.github.io/multas."],"url":"http://arxiv.org/abs/2309.06288v1"}
{"created":"2023-09-12 14:46:56","title":"Transferability analysis of data-driven additive manufacturing knowledge: a case study between powder bed fusion and directed energy deposition","abstract":"Data-driven research in Additive Manufacturing (AM) has gained significant success in recent years. This has led to a plethora of scientific literature to emerge. The knowledge in these works consists of AM and Artificial Intelligence (AI) contexts that have not been mined and formalized in an integrated way. Moreover, no tools or guidelines exist to support data-driven knowledge transfer from one context to another. As a result, data-driven solutions using specific AI techniques are being developed and validated only for specific AM process technologies. There is a potential to exploit the inherent similarities across various AM technologies and adapt the existing solutions from one process or problem to another using AI, such as Transfer Learning. We propose a three-step knowledge transferability analysis framework in AM to support data-driven AM knowledge transfer. As a prerequisite to transferability analysis, AM knowledge is featurized into identified knowledge components. The framework consists of pre-transfer, transfer, and post-transfer steps to accomplish knowledge transfer. A case study is conducted between flagship metal AM processes. Laser Powder Bed Fusion (LPBF) is the source of knowledge motivated by its relative matureness in applying AI over Directed Energy Deposition (DED), which drives the need for knowledge transfer as the less explored target process. We show successful transfer at different levels of the data-driven solution, including data representation, model architecture, and model parameters. The pipeline of AM knowledge transfer can be automated in the future to allow efficient cross-context or cross-process knowledge exchange.","sentences":["Data-driven research in Additive Manufacturing (AM) has gained significant success in recent years.","This has led to a plethora of scientific literature to emerge.","The knowledge in these works consists of AM and Artificial Intelligence (AI) contexts that have not been mined and formalized in an integrated way.","Moreover, no tools or guidelines exist to support data-driven knowledge transfer from one context to another.","As a result, data-driven solutions using specific AI techniques are being developed and validated only for specific AM process technologies.","There is a potential to exploit the inherent similarities across various AM technologies and adapt the existing solutions from one process or problem to another using AI, such as Transfer Learning.","We propose a three-step knowledge transferability analysis framework in AM to support data-driven AM knowledge transfer.","As a prerequisite to transferability analysis, AM knowledge is featurized into identified knowledge components.","The framework consists of pre-transfer, transfer, and post-transfer steps to accomplish knowledge transfer.","A case study is conducted between flagship metal AM processes.","Laser Powder Bed Fusion (LPBF) is the source of knowledge motivated by its relative matureness in applying AI over Directed Energy Deposition (DED), which drives the need for knowledge transfer as the less explored target process.","We show successful transfer at different levels of the data-driven solution, including data representation, model architecture, and model parameters.","The pipeline of AM knowledge transfer can be automated in the future to allow efficient cross-context or cross-process knowledge exchange."],"url":"http://arxiv.org/abs/2309.06286v1"}
{"created":"2023-09-12 14:43:50","title":"Jersey Number Recognition using Keyframe Identification from Low-Resolution Broadcast Videos","abstract":"Player identification is a crucial component in vision-driven soccer analytics, enabling various downstream tasks such as player assessment, in-game analysis, and broadcast production. However, automatically detecting jersey numbers from player tracklets in videos presents challenges due to motion blur, low resolution, distortions, and occlusions. Existing methods, utilizing Spatial Transformer Networks, CNNs, and Vision Transformers, have shown success in image data but struggle with real-world video data, where jersey numbers are not visible in most of the frames. Hence, identifying frames that contain the jersey number is a key sub-problem to tackle. To address these issues, we propose a robust keyframe identification module that extracts frames containing essential high-level information about the jersey number. A spatio-temporal network is then employed to model spatial and temporal context and predict the probabilities of jersey numbers in the video. Additionally, we adopt a multi-task loss function to predict the probability distribution of each digit separately. Extensive evaluations on the SoccerNet dataset demonstrate that incorporating our proposed keyframe identification module results in a significant 37.81% and 37.70% increase in the accuracies of 2 different test sets with domain gaps. These results highlight the effectiveness and importance of our approach in tackling the challenges of automatic jersey number detection in sports videos.","sentences":["Player identification is a crucial component in vision-driven soccer analytics, enabling various downstream tasks such as player assessment, in-game analysis, and broadcast production.","However, automatically detecting jersey numbers from player tracklets in videos presents challenges due to motion blur, low resolution, distortions, and occlusions.","Existing methods, utilizing Spatial Transformer Networks, CNNs, and Vision Transformers, have shown success in image data but struggle with real-world video data, where jersey numbers are not visible in most of the frames.","Hence, identifying frames that contain the jersey number is a key sub-problem to tackle.","To address these issues, we propose a robust keyframe identification module that extracts frames containing essential high-level information about the jersey number.","A spatio-temporal network is then employed to model spatial and temporal context and predict the probabilities of jersey numbers in the video.","Additionally, we adopt a multi-task loss function to predict the probability distribution of each digit separately.","Extensive evaluations on the SoccerNet dataset demonstrate that incorporating our proposed keyframe identification module results in a significant 37.81% and 37.70% increase in the accuracies of 2 different test sets with domain gaps.","These results highlight the effectiveness and importance of our approach in tackling the challenges of automatic jersey number detection in sports videos."],"url":"http://arxiv.org/abs/2309.06285v1"}
{"created":"2023-09-12 14:43:47","title":"Fg-T2M: Fine-Grained Text-Driven Human Motion Generation via Diffusion Model","abstract":"Text-driven human motion generation in computer vision is both significant and challenging. However, current methods are limited to producing either deterministic or imprecise motion sequences, failing to effectively control the temporal and spatial relationships required to conform to a given text description. In this work, we propose a fine-grained method for generating high-quality, conditional human motion sequences supporting precise text description. Our approach consists of two key components: 1) a linguistics-structure assisted module that constructs accurate and complete language feature to fully utilize text information; and 2) a context-aware progressive reasoning module that learns neighborhood and overall semantic linguistics features from shallow and deep graph neural networks to achieve a multi-step inference. Experiments show that our approach outperforms text-driven motion generation methods on HumanML3D and KIT test sets and generates better visually confirmed motion to the text conditions.","sentences":["Text-driven human motion generation in computer vision is both significant and challenging.","However, current methods are limited to producing either deterministic or imprecise motion sequences, failing to effectively control the temporal and spatial relationships required to conform to a given text description.","In this work, we propose a fine-grained method for generating high-quality, conditional human motion sequences supporting precise text description.","Our approach consists of two key components: 1) a linguistics-structure assisted module that constructs accurate and complete language feature to fully utilize text information; and 2) a context-aware progressive reasoning module that learns neighborhood and overall semantic linguistics features from shallow and deep graph neural networks to achieve a multi-step inference.","Experiments show that our approach outperforms text-driven motion generation methods on HumanML3D and KIT test sets and generates better visually confirmed motion to the text conditions."],"url":"http://arxiv.org/abs/2309.06284v1"}
{"created":"2023-09-12 14:42:22","title":"IBAFormer: Intra-batch Attention Transformer for Domain Generalized Semantic Segmentation","abstract":"Domain generalized semantic segmentation (DGSS) is a critical yet challenging task, where the model is trained only on source data without access to any target data. Despite the proposal of numerous DGSS strategies, the generalization capability remains limited in CNN architectures. Though some Transformer-based segmentation models show promising performance, they primarily focus on capturing intra-sample attentive relationships, disregarding inter-sample correlations which can potentially benefit DGSS. To this end, we enhance the attention modules in Transformer networks for improving DGSS by incorporating information from other independent samples in the same batch, enriching contextual information, and diversifying the training data for each attention block. Specifically, we propose two alternative intra-batch attention mechanisms, namely mean-based intra-batch attention (MIBA) and element-wise intra-batch attention (EIBA), to capture correlations between different samples, enhancing feature representation and generalization capabilities. Building upon intra-batch attention, we introduce IBAFormer, which integrates self-attention modules with the proposed intra-batch attention for DGSS. Extensive experiments demonstrate that IBAFormer achieves SOTA performance in DGSS, and ablation studies further confirm the effectiveness of each introduced component.","sentences":["Domain generalized semantic segmentation (DGSS) is a critical yet challenging task, where the model is trained only on source data without access to any target data.","Despite the proposal of numerous DGSS strategies, the generalization capability remains limited in CNN architectures.","Though some Transformer-based segmentation models show promising performance, they primarily focus on capturing intra-sample attentive relationships, disregarding inter-sample correlations which can potentially benefit DGSS.","To this end, we enhance the attention modules in Transformer networks for improving DGSS by incorporating information from other independent samples in the same batch, enriching contextual information, and diversifying the training data for each attention block.","Specifically, we propose two alternative intra-batch attention mechanisms, namely mean-based intra-batch attention (MIBA) and element-wise intra-batch attention (EIBA), to capture correlations between different samples, enhancing feature representation and generalization capabilities.","Building upon intra-batch attention, we introduce IBAFormer, which integrates self-attention modules with the proposed intra-batch attention for DGSS.","Extensive experiments demonstrate that IBAFormer achieves SOTA performance in DGSS, and ablation studies further confirm the effectiveness of each introduced component."],"url":"http://arxiv.org/abs/2309.06282v1"}
{"created":"2023-09-12 14:41:48","title":"Extending and Defending Attacks on Reset Operations in Quantum Computers","abstract":"The development of quantum computers has been advancing rapidly in recent years. As quantum computers become more widely accessible, potentially malicious users could try to execute their code on the machines to leak information from other users, to interfere with or manipulate the results of other users, or to reverse engineer the underlying quantum computer architecture and its intellectual property, for example. Among different security threats, previous work has demonstrated information leakage across the reset operations, and it then proposed a secure reset operation could be an enabling technology that allows the sharing of a quantum computer among different users, or among different quantum programs of the same user. This work first shows a set of new, extended reset operation attacks that could be more stealthy by hiding the intention of the attacker's circuit. This work shows various masking circuits and how attackers can retrieve information from the execution of a previous shot of a circuit, even if the masking circuit is used between the reset operation (of the victim, after the shot of the circuit is executed) and the measurement (of the attacker). Based on the uncovered new possible attacks, this work proposes a set of heuristic checks that could be applied at transpile time to check for the existence of malicious circuits that try to steal information via the attack on the reset operation. Unlike run-time protection or added secure reset gates, this work proposes a complimentary, compile-time security solution to the attacks on reset~operation.","sentences":["The development of quantum computers has been advancing rapidly in recent years.","As quantum computers become more widely accessible, potentially malicious users could try to execute their code on the machines to leak information from other users, to interfere with or manipulate the results of other users, or to reverse engineer the underlying quantum computer architecture and its intellectual property, for example.","Among different security threats, previous work has demonstrated information leakage across the reset operations, and it then proposed a secure reset operation could be an enabling technology that allows the sharing of a quantum computer among different users, or among different quantum programs of the same user.","This work first shows a set of new, extended reset operation attacks that could be more stealthy by hiding the intention of the attacker's circuit.","This work shows various masking circuits and how attackers can retrieve information from the execution of a previous shot of a circuit, even if the masking circuit is used between the reset operation (of the victim, after the shot of the circuit is executed) and the measurement (of the attacker).","Based on the uncovered new possible attacks, this work proposes a set of heuristic checks that could be applied at transpile time to check for the existence of malicious circuits that try to steal information via the attack on the reset operation.","Unlike run-time protection or added secure reset gates, this work proposes a complimentary, compile-time security solution to the attacks on reset~operation."],"url":"http://arxiv.org/abs/2309.06281v1"}
{"created":"2023-09-12 14:37:41","title":"OTAS: Unsupervised Boundary Detection for Object-Centric Temporal Action Segmentation","abstract":"Temporal action segmentation is typically achieved by discovering the dramatic variances in global visual descriptors. In this paper, we explore the merits of local features by proposing the unsupervised framework of Object-centric Temporal Action Segmentation (OTAS). Broadly speaking, OTAS consists of self-supervised global and local feature extraction modules as well as a boundary selection module that fuses the features and detects salient boundaries for action segmentation. As a second contribution, we discuss the pros and cons of existing frame-level and boundary-level evaluation metrics. Through extensive experiments, we find OTAS is superior to the previous state-of-the-art method by $41\\%$ on average in terms of our recommended F1 score. Surprisingly, OTAS even outperforms the ground-truth human annotations in the user study. Moreover, OTAS is efficient enough to allow real-time inference.","sentences":["Temporal action segmentation is typically achieved by discovering the dramatic variances in global visual descriptors.","In this paper, we explore the merits of local features by proposing the unsupervised framework of Object-centric Temporal Action Segmentation (OTAS).","Broadly speaking, OTAS consists of self-supervised global and local feature extraction modules as well as a boundary selection module that fuses the features and detects salient boundaries for action segmentation.","As a second contribution, we discuss the pros and cons of existing frame-level and boundary-level evaluation metrics.","Through extensive experiments, we find OTAS is superior to the previous state-of-the-art method by $41\\%$ on average in terms of our recommended F1 score.","Surprisingly, OTAS even outperforms the ground-truth human annotations in the user study.","Moreover, OTAS is efficient enough to allow real-time inference."],"url":"http://arxiv.org/abs/2309.06276v1"}
{"created":"2023-09-12 14:36:23","title":"Re-Reading Improves Reasoning in Language Models","abstract":"Reasoning presents a significant and challenging issue for Large Language Models (LLMs). The predominant focus of research has revolved around developing diverse prompting strategies to guide and structure the reasoning processes of LLMs. However, these approaches based on decoder-only causal language models often operate the input question in a single forward pass, potentially missing the rich, back-and-forth interactions inherent in human reasoning. Scant attention has been paid to a critical dimension, i.e., the input question itself embedded within the prompts. In response, we introduce a deceptively simple yet highly effective prompting strategy, termed question \"re-reading\". Drawing inspiration from human learning and problem-solving, re-reading entails revisiting the question information embedded within input prompts. This approach aligns seamlessly with the cognitive principle of reinforcement, enabling LLMs to extract deeper insights, identify intricate patterns, establish more nuanced connections, and ultimately enhance their reasoning capabilities across various tasks. Experiments conducted on a series of reasoning benchmarks serve to underscore the effectiveness and generality of our method. Moreover, our findings demonstrate that our approach seamlessly integrates with various language models, though-eliciting prompting methods, and ensemble techniques, further underscoring its versatility and compatibility in the realm of LLMs.","sentences":["Reasoning presents a significant and challenging issue for Large Language Models (LLMs).","The predominant focus of research has revolved around developing diverse prompting strategies to guide and structure the reasoning processes of LLMs.","However, these approaches based on decoder-only causal language models often operate the input question in a single forward pass, potentially missing the rich, back-and-forth interactions inherent in human reasoning.","Scant attention has been paid to a critical dimension, i.e., the input question itself embedded within the prompts.","In response, we introduce a deceptively simple yet highly effective prompting strategy, termed question \"re-reading\".","Drawing inspiration from human learning and problem-solving, re-reading entails revisiting the question information embedded within input prompts.","This approach aligns seamlessly with the cognitive principle of reinforcement, enabling LLMs to extract deeper insights, identify intricate patterns, establish more nuanced connections, and ultimately enhance their reasoning capabilities across various tasks.","Experiments conducted on a series of reasoning benchmarks serve to underscore the effectiveness and generality of our method.","Moreover, our findings demonstrate that our approach seamlessly integrates with various language models, though-eliciting prompting methods, and ensemble techniques, further underscoring its versatility and compatibility in the realm of LLMs."],"url":"http://arxiv.org/abs/2309.06275v1"}
{"created":"2023-09-12 14:36:13","title":"ELRA: Exponential learning rate adaption gradient descent optimization method","abstract":"We present a novel, fast (exponential rate adaption), ab initio (hyper-parameter-free) gradient based optimizer algorithm. The main idea of the method is to adapt the learning rate $\\alpha$ by situational awareness, mainly striving for orthogonal neighboring gradients. The method has a high success and fast convergence rate and does not rely on hand-tuned parameters giving it greater universality. It can be applied to problems of any dimensions n and scales only linearly (of order O(n)) with the dimension of the problem. It optimizes convex and non-convex continuous landscapes providing some kind of gradient. In contrast to the Ada-family (AdaGrad, AdaMax, AdaDelta, Adam, etc.) the method is rotation invariant: optimization path and performance are independent of coordinate choices. The impressive performance is demonstrated by extensive experiments on the MNIST benchmark data-set against state-of-the-art optimizers. We name this new class of optimizers after its core idea Exponential Learning Rate Adaption - ELRA. We present it in two variants c2min and p2min with slightly different control. The authors strongly believe that ELRA will open a completely new research direction for gradient descent optimize.","sentences":["We present a novel, fast (exponential rate adaption), ab initio (hyper-parameter-free) gradient based optimizer algorithm.","The main idea of the method is to adapt the learning rate $\\alpha$ by situational awareness, mainly striving for orthogonal neighboring gradients.","The method has a high success and fast convergence rate and does not rely on hand-tuned parameters giving it greater universality.","It can be applied to problems of any dimensions n and scales only linearly (of order O(n)) with the dimension of the problem.","It optimizes convex and non-convex continuous landscapes providing some kind of gradient.","In contrast to the Ada-family (AdaGrad, AdaMax, AdaDelta, Adam, etc.)","the method is rotation invariant: optimization path and performance are independent of coordinate choices.","The impressive performance is demonstrated by extensive experiments on the MNIST benchmark data-set against state-of-the-art optimizers.","We name this new class of optimizers after its core idea Exponential Learning Rate Adaption - ELRA.","We present it in two variants c2min and p2min with slightly different control.","The authors strongly believe that ELRA will open a completely new research direction for gradient descent optimize."],"url":"http://arxiv.org/abs/2309.06274v1"}
{"created":"2023-09-12 14:30:18","title":"A Complete Proof of an Important Theorem for Variable-to-Variable Length Codes","abstract":"Variable-to-variable length (VV) codes are a class of lossless source coding. As their name implies, VV codes encode a variable-length sequence of source symbols into a variable-length codeword. This paper will give a complete proof of an important theorem for variable-to-variable length codes.","sentences":["Variable-to-variable length (VV) codes are a class of lossless source coding.","As their name implies, VV codes encode a variable-length sequence of source symbols into a variable-length codeword.","This paper will give a complete proof of an important theorem for variable-to-variable length codes."],"url":"http://arxiv.org/abs/2309.06267v1"}
{"created":"2023-09-12 14:23:19","title":"Systematic Evaluation of Geolocation Privacy Mechanisms","abstract":"Location data privacy has become a serious concern for users as Location Based Services (LBSs) have become an important part of their life. It is possible for malicious parties having access to geolocation data to learn sensitive information about the user such as religion or political views. Location Privacy Preserving Mechanisms (LPPMs) have been proposed by previous works to ensure the privacy of the shared data while allowing the users to use LBSs. But there is no clear view of which mechanism to use according to the scenario in which the user makes use of a LBS. The scenario is the way the user is using a LBS (frequency of reports, number of reports). In this paper, we study the sensitivity of LPPMs on the scenario on which they are used. We propose a framework to systematically evaluate LPPMs by considering an exhaustive combination of LPPMs, attacks and metrics. Using our framework we compare a selection of LPPMs including an improved mechanism that we introduce. By evaluating over a variety of scenarios, we find that the efficacy (privacy, utility, and robustness) of the studied mechanisms is dependent on the scenario: for example the privacy of Planar Laplace geo-indistinguishability is greatly reduced in a continuous scenario. We show that the scenario is essential to consider when choosing an obfuscation mechanism for a given application.","sentences":["Location data privacy has become a serious concern for users as Location Based Services (LBSs) have become an important part of their life.","It is possible for malicious parties having access to geolocation data to learn sensitive information about the user such as religion or political views.","Location Privacy Preserving Mechanisms (LPPMs) have been proposed by previous works to ensure the privacy of the shared data while allowing the users to use LBSs.","But there is no clear view of which mechanism to use according to the scenario in which the user makes use of a LBS.","The scenario is the way the user is using a LBS (frequency of reports, number of reports).","In this paper, we study the sensitivity of LPPMs on the scenario on which they are used.","We propose a framework to systematically evaluate LPPMs by considering an exhaustive combination of LPPMs, attacks and metrics.","Using our framework we compare a selection of LPPMs including an improved mechanism that we introduce.","By evaluating over a variety of scenarios, we find that the efficacy (privacy, utility, and robustness) of the studied mechanisms is dependent on the scenario: for example the privacy of Planar Laplace geo-indistinguishability is greatly reduced in a continuous scenario.","We show that the scenario is essential to consider when choosing an obfuscation mechanism for a given application."],"url":"http://arxiv.org/abs/2309.06263v1"}
{"created":"2023-09-12 14:22:22","title":"Modality Unifying Network for Visible-Infrared Person Re-Identification","abstract":"Visible-infrared person re-identification (VI-ReID) is a challenging task due to large cross-modality discrepancies and intra-class variations. Existing methods mainly focus on learning modality-shared representations by embedding different modalities into the same feature space. As a result, the learned feature emphasizes the common patterns across modalities while suppressing modality-specific and identity-aware information that is valuable for Re-ID. To address these issues, we propose a novel Modality Unifying Network (MUN) to explore a robust auxiliary modality for VI-ReID. First, the auxiliary modality is generated by combining the proposed cross-modality learner and intra-modality learner, which can dynamically model the modality-specific and modality-shared representations to alleviate both cross-modality and intra-modality variations. Second, by aligning identity centres across the three modalities, an identity alignment loss function is proposed to discover the discriminative feature representations. Third, a modality alignment loss is introduced to consistently reduce the distribution distance of visible and infrared images by modality prototype modeling. Extensive experiments on multiple public datasets demonstrate that the proposed method surpasses the current state-of-the-art methods by a significant margin.","sentences":["Visible-infrared person re-identification (VI-ReID) is a challenging task due to large cross-modality discrepancies and intra-class variations.","Existing methods mainly focus on learning modality-shared representations by embedding different modalities into the same feature space.","As a result, the learned feature emphasizes the common patterns across modalities while suppressing modality-specific and identity-aware information that is valuable for Re-ID.","To address these issues, we propose a novel Modality Unifying Network (MUN) to explore a robust auxiliary modality for VI-ReID.","First, the auxiliary modality is generated by combining the proposed cross-modality learner and intra-modality learner, which can dynamically model the modality-specific and modality-shared representations to alleviate both cross-modality and intra-modality variations.","Second, by aligning identity centres across the three modalities, an identity alignment loss function is proposed to discover the discriminative feature representations.","Third, a modality alignment loss is introduced to consistently reduce the distribution distance of visible and infrared images by modality prototype modeling.","Extensive experiments on multiple public datasets demonstrate that the proposed method surpasses the current state-of-the-art methods by a significant margin."],"url":"http://arxiv.org/abs/2309.06262v1"}
{"created":"2023-09-12 14:16:54","title":"Speciality vs Generality: An Empirical Study on Catastrophic Forgetting in Fine-tuning Foundation Models","abstract":"Foundation models, including Vision Language Models (VLMs) and Large Language Models (LLMs), possess the $generality$ to handle diverse distributions and tasks, which stems from their extensive pre-training datasets. The fine-tuning of foundation models is a common practice to enhance task performance or align the model's behavior with human expectations, allowing them to gain $speciality$. However, the small datasets used for fine-tuning may not adequately cover the diverse distributions and tasks encountered during pre-training. Consequently, the pursuit of speciality during fine-tuning can lead to a loss of {generality} in the model, which is related to catastrophic forgetting (CF) in deep learning. In this study, we demonstrate this phenomenon in both VLMs and LLMs. For instance, fine-tuning VLMs like CLIP on ImageNet results in a loss of generality in handling diverse distributions, and fine-tuning LLMs like Galactica in the medical domain leads to a loss in following instructions and common sense.   To address the trade-off between the speciality and generality, we investigate multiple regularization methods from continual learning, the weight averaging method (Wise-FT) from out-of-distributional (OOD) generalization, which interpolates parameters between pre-trained and fine-tuned models, and parameter-efficient fine-tuning methods like Low-Rank Adaptation (LoRA). Our findings show that both continual learning and Wise-ft methods effectively mitigate the loss of generality, with Wise-FT exhibiting the strongest performance in balancing speciality and generality.","sentences":["Foundation models, including Vision Language Models (VLMs) and Large Language Models (LLMs), possess the $generality$ to handle diverse distributions and tasks, which stems from their extensive pre-training datasets.","The fine-tuning of foundation models is a common practice to enhance task performance or align the model's behavior with human expectations, allowing them to gain $speciality$. However, the small datasets used for fine-tuning may not adequately cover the diverse distributions and tasks encountered during pre-training.","Consequently, the pursuit of speciality during fine-tuning can lead to a loss of {generality} in the model, which is related to catastrophic forgetting (CF) in deep learning.","In this study, we demonstrate this phenomenon in both VLMs and LLMs.","For instance, fine-tuning VLMs like CLIP on ImageNet results in a loss of generality in handling diverse distributions, and fine-tuning LLMs like Galactica in the medical domain leads to a loss in following instructions and common sense.   ","To address the trade-off between the speciality and generality, we investigate multiple regularization methods from continual learning, the weight averaging method (Wise-FT) from out-of-distributional (OOD) generalization, which interpolates parameters between pre-trained and fine-tuned models, and parameter-efficient fine-tuning methods like Low-Rank Adaptation (LoRA).","Our findings show that both continual learning and Wise-ft methods effectively mitigate the loss of generality, with Wise-FT exhibiting the strongest performance in balancing speciality and generality."],"url":"http://arxiv.org/abs/2309.06256v1"}
{"created":"2023-09-12 14:16:34","title":"Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation","abstract":"One primary topic of multi-modal learning is to jointly incorporate heterogeneous information from different modalities. However, most models often suffer from unsatisfactory multi-modal cooperation, which could not jointly utilize all modalities well. Some methods are proposed to identify and enhance the worse learnt modality, but are often hard to provide the fine-grained observation of multi-modal cooperation at sample-level with theoretical support. Hence, it is essential to reasonably observe and improve the fine-grained cooperation between modalities, especially when facing realistic scenarios where the modality discrepancy could vary across different samples. To this end, we introduce a fine-grained modality valuation metric to evaluate the contribution of each modality at sample-level. Via modality valuation, we regretfully observe that the multi-modal model tends to rely on one specific modality, resulting in other modalities being low-contributing. We further analyze this issue and improve cooperation between modalities by enhancing the discriminative ability of low-contributing modalities in a targeted manner. Overall, our methods reasonably observe the fine-grained uni-modal contribution at sample-level and achieve considerable improvement on different multi-modal models.","sentences":["One primary topic of multi-modal learning is to jointly incorporate heterogeneous information from different modalities.","However, most models often suffer from unsatisfactory multi-modal cooperation, which could not jointly utilize all modalities well.","Some methods are proposed to identify and enhance the worse learnt modality, but are often hard to provide the fine-grained observation of multi-modal cooperation at sample-level with theoretical support.","Hence, it is essential to reasonably observe and improve the fine-grained cooperation between modalities, especially when facing realistic scenarios where the modality discrepancy could vary across different samples.","To this end, we introduce a fine-grained modality valuation metric to evaluate the contribution of each modality at sample-level.","Via modality valuation, we regretfully observe that the multi-modal model tends to rely on one specific modality, resulting in other modalities being low-contributing.","We further analyze this issue and improve cooperation between modalities by enhancing the discriminative ability of low-contributing modalities in a targeted manner.","Overall, our methods reasonably observe the fine-grained uni-modal contribution at sample-level and achieve considerable improvement on different multi-modal models."],"url":"http://arxiv.org/abs/2309.06255v1"}
{"created":"2023-09-12 14:11:53","title":"Predicting Routine Object Usage for Proactive Robot Assistance","abstract":"Proactivity in robot assistance refers to the robot's ability to anticipate user needs and perform assistive actions without explicit requests. This requires understanding user routines, predicting consistent activities, and actively seeking information to predict inconsistent behaviors. We propose SLaTe-PRO (Sequential Latent Temporal model for Predicting Routine Object usage), which improves upon prior state-of-the-art by combining object and user action information, and conditioning object usage predictions on past history. Additionally, we find some human behavior to be inherently stochastic and lacking in contextual cues that the robot can use for proactive assistance. To address such cases, we introduce an interactive query mechanism that can be used to ask queries about the user's intended activities and object use to improve prediction. We evaluate our approach on longitudinal data from three households, spanning 24 activity classes. SLaTe-PRO performance raises the F1 score metric to 0.57 without queries, and 0.60 with user queries, over a score of 0.43 from prior work. We additionally present a case study with a fully autonomous household robot.","sentences":["Proactivity in robot assistance refers to the robot's ability to anticipate user needs and perform assistive actions without explicit requests.","This requires understanding user routines, predicting consistent activities, and actively seeking information to predict inconsistent behaviors.","We propose SLaTe-PRO (Sequential Latent Temporal model for Predicting Routine Object usage), which improves upon prior state-of-the-art by combining object and user action information, and conditioning object usage predictions on past history.","Additionally, we find some human behavior to be inherently stochastic and lacking in contextual cues that the robot can use for proactive assistance.","To address such cases, we introduce an interactive query mechanism that can be used to ask queries about the user's intended activities and object use to improve prediction.","We evaluate our approach on longitudinal data from three households, spanning 24 activity classes.","SLaTe-PRO performance raises the F1 score metric to 0.57 without queries, and 0.60 with user queries, over a score of 0.43 from prior work.","We additionally present a case study with a fully autonomous household robot."],"url":"http://arxiv.org/abs/2309.06252v1"}
{"created":"2023-09-12 14:04:12","title":"Rethinking Evaluation Metric for Probability Estimation Models Using Esports Data","abstract":"Probability estimation models play an important role in various fields, such as weather forecasting, recommendation systems, and sports analysis. Among several models estimating probabilities, it is difficult to evaluate which model gives reliable probabilities since the ground-truth probabilities are not available. The win probability estimation model for esports, which calculates the win probability under a certain game state, is also one of the fields being actively studied in probability estimation. However, most of the previous works evaluated their models using accuracy, a metric that only can measure the performance of discrimination. In this work, we firstly investigate the Brier score and the Expected Calibration Error (ECE) as a replacement of accuracy used as a performance evaluation metric for win probability estimation models in esports field. Based on the analysis, we propose a novel metric called Balance score which is a simple yet effective metric in terms of six good properties that probability estimation metric should have. Under the general condition, we also found that the Balance score can be an effective approximation of the true expected calibration error which has been imperfectly approximated by ECE using the binning technique. Extensive evaluations using simulation studies and real game snapshot data demonstrate the promising potential to adopt the proposed metric not only for the win probability estimation model for esports but also for evaluating general probability estimation models.","sentences":["Probability estimation models play an important role in various fields, such as weather forecasting, recommendation systems, and sports analysis.","Among several models estimating probabilities, it is difficult to evaluate which model gives reliable probabilities since the ground-truth probabilities are not available.","The win probability estimation model for esports, which calculates the win probability under a certain game state, is also one of the fields being actively studied in probability estimation.","However, most of the previous works evaluated their models using accuracy, a metric that only can measure the performance of discrimination.","In this work, we firstly investigate the Brier score and the Expected Calibration Error (ECE) as a replacement of accuracy used as a performance evaluation metric for win probability estimation models in esports field.","Based on the analysis, we propose a novel metric called Balance score which is a simple yet effective metric in terms of six good properties that probability estimation metric should have.","Under the general condition, we also found that the Balance score can be an effective approximation of the true expected calibration error which has been imperfectly approximated by ECE using the binning technique.","Extensive evaluations using simulation studies and real game snapshot data demonstrate the promising potential to adopt the proposed metric not only for the win probability estimation model for esports but also for evaluating general probability estimation models."],"url":"http://arxiv.org/abs/2309.06248v1"}
{"created":"2023-09-12 13:55:01","title":"Risk-Aware Reinforcement Learning through Optimal Transport Theory","abstract":"In the dynamic and uncertain environments where reinforcement learning (RL) operates, risk management becomes a crucial factor in ensuring reliable decision-making. Traditional RL approaches, while effective in reward optimization, often overlook the landscape of potential risks. In response, this paper pioneers the integration of Optimal Transport (OT) theory with RL to create a risk-aware framework. Our approach modifies the objective function, ensuring that the resulting policy not only maximizes expected rewards but also respects risk constraints dictated by OT distances between state visitation distributions and the desired risk profiles. By leveraging the mathematical precision of OT, we offer a formulation that elevates risk considerations alongside conventional RL objectives. Our contributions are substantiated with a series of theorems, mapping the relationships between risk distributions, optimal value functions, and policy behaviors. Through the lens of OT, this work illuminates a promising direction for RL, ensuring a balanced fusion of reward pursuit and risk awareness.","sentences":["In the dynamic and uncertain environments where reinforcement learning (RL) operates, risk management becomes a crucial factor in ensuring reliable decision-making.","Traditional RL approaches, while effective in reward optimization, often overlook the landscape of potential risks.","In response, this paper pioneers the integration of Optimal Transport (OT) theory with RL to create a risk-aware framework.","Our approach modifies the objective function, ensuring that the resulting policy not only maximizes expected rewards but also respects risk constraints dictated by OT distances between state visitation distributions and the desired risk profiles.","By leveraging the mathematical precision of OT, we offer a formulation that elevates risk considerations alongside conventional RL objectives.","Our contributions are substantiated with a series of theorems, mapping the relationships between risk distributions, optimal value functions, and policy behaviors.","Through the lens of OT, this work illuminates a promising direction for RL, ensuring a balanced fusion of reward pursuit and risk awareness."],"url":"http://arxiv.org/abs/2309.06239v1"}
{"created":"2023-09-12 13:54:28","title":"Evaluating the Risk of Changes in a Microservices Architecture","abstract":"In a microservices-based system, reliability and availability are key components to guarantee the best-in-class experience for the consumers. One of the key advantages of microservices architecture is the ability to independently deploy services, providing maximum change flexibility. However, this introduces an extra complexity in managing the risk associated with every change: any mutation of a service might cause the whole system to fail. In this research, we would propose an algorithm to enable development teams to determine the risk associated with each change to any of the microservices in the system.","sentences":["In a microservices-based system, reliability and availability are key components to guarantee the best-in-class experience for the consumers.","One of the key advantages of microservices architecture is the ability to independently deploy services, providing maximum change flexibility.","However, this introduces an extra complexity in managing the risk associated with every change: any mutation of a service might cause the whole system to fail.","In this research, we would propose an algorithm to enable development teams to determine the risk associated with each change to any of the microservices in the system."],"url":"http://arxiv.org/abs/2309.06238v1"}
{"created":"2023-09-12 13:51:29","title":"The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models","abstract":"Large Language Models (LLMs) have demonstrated remarkable generalization across diverse tasks, leading individuals to increasingly use them as personal assistants and universal computing engines. Nevertheless, a notable obstacle emerges when feeding numerical/temporal data into these models, such as data sourced from wearables or electronic health records. LLMs employ tokenizers in their input that break down text into smaller units. However, tokenizers are not designed to represent numerical values and might struggle to understand repetitive patterns and context, treating consecutive values as separate tokens and disregarding their temporal relationships. Here, we discuss recent works that employ LLMs for human-centric tasks such as in mobile health sensing and present a case study showing that popular LLMs tokenize temporal data incorrectly. To address that, we highlight potential solutions such as prompt tuning with lightweight embedding layers as well as multimodal adapters, that can help bridge this \"modality gap\". While the capability of language models to generalize to other modalities with minimal or no finetuning is exciting, this paper underscores the fact that their outputs cannot be meaningful if they stumble over input nuances.","sentences":["Large Language Models (LLMs) have demonstrated remarkable generalization across diverse tasks, leading individuals to increasingly use them as personal assistants and universal computing engines.","Nevertheless, a notable obstacle emerges when feeding numerical/temporal data into these models, such as data sourced from wearables or electronic health records.","LLMs employ tokenizers in their input that break down text into smaller units.","However, tokenizers are not designed to represent numerical values and might struggle to understand repetitive patterns and context, treating consecutive values as separate tokens and disregarding their temporal relationships.","Here, we discuss recent works that employ LLMs for human-centric tasks such as in mobile health sensing and present a case study showing that popular LLMs tokenize temporal data incorrectly.","To address that, we highlight potential solutions such as prompt tuning with lightweight embedding layers as well as multimodal adapters, that can help bridge this \"modality gap\".","While the capability of language models to generalize to other modalities with minimal or no finetuning is exciting, this paper underscores the fact that their outputs cannot be meaningful if they stumble over input nuances."],"url":"http://arxiv.org/abs/2309.06236v1"}
{"created":"2023-09-12 13:47:44","title":"PreciseBugCollector: Extensible, Executable and Precise Bug-fix Collection","abstract":"Bug datasets are vital for enabling deep learning techniques to address software maintenance tasks related to bugs. However, existing bug datasets suffer from precise and scale limitations: they are either small-scale but precise with manual validation or large-scale but imprecise with simple commit message processing. In this paper, we introduce PreciseBugCollector, a precise, multi-language bug collection approach that overcomes these two limitations. PreciseBugCollector is based on two novel components: a) A bug tracker to map the codebase repositories with external bug repositories to trace bug type information, and b) A bug injector to generate project-specific bugs by injecting noise into the correct codebases and then executing them against their test suites to obtain test failure messages.   We implement PreciseBugCollector against three sources: 1) A bug tracker that links to the national vulnerability data set (NVD) to collect general-wise vulnerabilities, 2) A bug tracker that links to OSS-Fuzz to collect general-wise bugs, and 3) A bug injector based on 16 injection rules to generate project-wise bugs. To date, \\approach comprises 1057818 bugs extracted from 2968 open-source projects. Of these, 12602 bugs are sourced from bug repositories (NVD and OSS-Fuzz), while the remaining 1045216 project-specific bugs are generated by the bug injector. Considering the challenge objectives, we argue that a bug injection approach is highly valuable for the industrial setting, since project-specific bugs align with domain knowledge, share the same codebase, and adhere to the coding style employed in industrial projects.","sentences":["Bug datasets are vital for enabling deep learning techniques to address software maintenance tasks related to bugs.","However, existing bug datasets suffer from precise and scale limitations: they are either small-scale but precise with manual validation or large-scale but imprecise with simple commit message processing.","In this paper, we introduce PreciseBugCollector, a precise, multi-language bug collection approach that overcomes these two limitations.","PreciseBugCollector is based on two novel components: a) A bug tracker to map the codebase repositories with external bug repositories to trace bug type information, and b)","A bug injector to generate project-specific bugs by injecting noise into the correct codebases and then executing them against their test suites to obtain test failure messages.   ","We implement PreciseBugCollector against three sources: 1) A bug tracker that links to the national vulnerability data set (NVD) to collect general-wise vulnerabilities, 2) A bug tracker that links to OSS-Fuzz to collect general-wise bugs, and 3) A bug injector based on 16 injection rules to generate project-wise bugs.","To date, \\approach comprises 1057818 bugs extracted from 2968 open-source projects.","Of these, 12602 bugs are sourced from bug repositories (NVD and OSS-Fuzz), while the remaining 1045216 project-specific bugs are generated by the bug injector.","Considering the challenge objectives, we argue that a bug injection approach is highly valuable for the industrial setting, since project-specific bugs align with domain knowledge, share the same codebase, and adhere to the coding style employed in industrial projects."],"url":"http://arxiv.org/abs/2309.06229v1"}
{"created":"2023-09-12 13:46:29","title":"On the Injunction of XAIxArt","abstract":"The position paper highlights the range of concerns that are engulfed in the injunction of explainable artificial intelligence in art (XAIxArt). Through a series of quick sub-questions, it points towards the ambiguities concerning 'explanation' and the postpositivist tradition of 'relevant explanation'. Rejecting both 'explanation' and 'relevant explanation', the paper takes a stance that XAIxArt is a symptom of insecurity of the anthropocentric notion of art and a nostalgic desire to return to outmoded notions of authorship and human agency. To justify this stance, the paper makes a distinction between an ornamentation model of explanation to a model of explanation as sense-making.","sentences":["The position paper highlights the range of concerns that are engulfed in the injunction of explainable artificial intelligence in art (XAIxArt).","Through a series of quick sub-questions, it points towards the ambiguities concerning 'explanation' and the postpositivist tradition of 'relevant explanation'.","Rejecting both 'explanation' and 'relevant explanation', the paper takes a stance that XAIxArt is a symptom of insecurity of the anthropocentric notion of art and a nostalgic desire to return to outmoded notions of authorship and human agency.","To justify this stance, the paper makes a distinction between an ornamentation model of explanation to a model of explanation as sense-making."],"url":"http://arxiv.org/abs/2309.06227v1"}
{"created":"2023-09-12 13:42:20","title":"Unveiling Signle-Bit-Flip Attacks on DNN Executables","abstract":"Recent research has shown that bit-flip attacks (BFAs) can manipulate deep neural networks (DNNs) via DRAM Rowhammer exploitations. Existing attacks are primarily launched over high-level DNN frameworks like PyTorch and flip bits in model weight files. Nevertheless, DNNs are frequently compiled into low-level executables by deep learning (DL) compilers to fully leverage low-level hardware primitives. The compiled code is usually high-speed and manifests dramatically distinct execution paradigms from high-level DNN frameworks.   In this paper, we launch the first systematic study on the attack surface of BFA specifically for DNN executables compiled by DL compilers. We design an automated search tool to identify vulnerable bits in DNN executables and identify practical attack vectors that exploit the model structure in DNN executables with BFAs (whereas prior works make likely strong assumptions to attack model weights). DNN executables appear more \"opaque\" than models in high-level DNN frameworks. Nevertheless, we find that DNN executables contain extensive, severe (e.g., single-bit flip), and transferrable attack surfaces that are not present in high-level DNN models and can be exploited to deplete full model intelligence and control output labels. Our finding calls for incorporating security mechanisms in future DNN compilation toolchains.","sentences":["Recent research has shown that bit-flip attacks (BFAs) can manipulate deep neural networks (DNNs) via DRAM Rowhammer exploitations.","Existing attacks are primarily launched over high-level DNN frameworks like PyTorch and flip bits in model weight files.","Nevertheless, DNNs are frequently compiled into low-level executables by deep learning (DL) compilers to fully leverage low-level hardware primitives.","The compiled code is usually high-speed and manifests dramatically distinct execution paradigms from high-level DNN frameworks.   ","In this paper, we launch the first systematic study on the attack surface of BFA specifically for DNN executables compiled by DL compilers.","We design an automated search tool to identify vulnerable bits in DNN executables and identify practical attack vectors that exploit the model structure in DNN executables with BFAs (whereas prior works make likely strong assumptions to attack model weights).","DNN executables appear more \"opaque\" than models in high-level DNN frameworks.","Nevertheless, we find that DNN executables contain extensive, severe (e.g., single-bit flip), and transferrable attack surfaces that are not present in high-level DNN models and can be exploited to deplete full model intelligence and control output labels.","Our finding calls for incorporating security mechanisms in future DNN compilation toolchains."],"url":"http://arxiv.org/abs/2309.06223v1"}
{"created":"2023-09-12 13:41:59","title":"Use neural networks to recognize students' handwritten letters and incorrect symbols","abstract":"Correcting students' multiple-choice answers is a repetitive and mechanical task that can be considered an image multi-classification task. Assuming possible options are 'abcd' and the correct option is one of the four, some students may write incorrect symbols or options that do not exist. In this paper, five classifications were set up - four for possible correct options and one for other incorrect writing. This approach takes into account the possibility of non-standard writing options.","sentences":["Correcting students' multiple-choice answers is a repetitive and mechanical task that can be considered an image multi-classification task.","Assuming possible options are 'abcd' and the correct option is one of the four, some students may write incorrect symbols or options that do not exist.","In this paper, five classifications were set up - four for possible correct options and one for other incorrect writing.","This approach takes into account the possibility of non-standard writing options."],"url":"http://arxiv.org/abs/2309.06221v1"}
