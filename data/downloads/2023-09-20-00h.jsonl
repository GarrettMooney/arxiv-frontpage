{"created":"2023-09-18 16:39:51","title":"Graph topological property recovery with heat and wave dynamics-based features on graphs","abstract":"In this paper, we propose Graph Differential Equation Network (GDeNet), an approach that harnesses the expressive power of solutions to PDEs on a graph to obtain continuous node- and graph-level representations for various downstream tasks. We derive theoretical results connecting the dynamics of heat and wave equations to the spectral properties of the graph and to the behavior of continuous-time random walks on graphs. We demonstrate experimentally that these dynamics are able to capture salient aspects of graph geometry and topology by recovering generating parameters of random graphs, Ricci curvature, and persistent homology. Furthermore, we demonstrate the superior performance of GDeNet on real-world datasets including citation graphs, drug-like molecules, and proteins.","sentences":["In this paper, we propose Graph Differential Equation Network (GDeNet), an approach that harnesses the expressive power of solutions to PDEs on a graph to obtain continuous node- and graph-level representations for various downstream tasks.","We derive theoretical results connecting the dynamics of heat and wave equations to the spectral properties of the graph and to the behavior of continuous-time random walks on graphs.","We demonstrate experimentally that these dynamics are able to capture salient aspects of graph geometry and topology by recovering generating parameters of random graphs, Ricci curvature, and persistent homology.","Furthermore, we demonstrate the superior performance of GDeNet on real-world datasets including citation graphs, drug-like molecules, and proteins."],"url":"http://arxiv.org/abs/2309.09924v2"}
{"created":"2023-09-18 14:55:21","title":"HypR: A comprehensive study for ASR hypothesis revising with a reference corpus","abstract":"With the development of deep learning, automatic speech recognition (ASR) has made significant progress. To further enhance the performance, revising recognition results is one of the lightweight but efficient manners. Various methods can be roughly classified into N-best reranking methods and error correction models. The former aims to select the hypothesis with the lowest error rate from a set of candidates generated by ASR for a given input speech. The latter focuses on detecting recognition errors in a given hypothesis and correcting these errors to obtain an enhanced result. However, we observe that these studies are hardly comparable to each other as they are usually evaluated on different corpora, paired with different ASR models, and even use different datasets to train the models. Accordingly, we first concentrate on releasing an ASR hypothesis revising (HypR) dataset in this study. HypR contains several commonly used corpora (AISHELL-1, TED-LIUM 2, and LibriSpeech) and provides 50 recognition hypotheses for each speech utterance. The checkpoint models of the ASR are also published. In addition, we implement and compare several classic and representative methods, showing the recent research progress in revising speech recognition results. We hope the publicly available HypR dataset can become a reference benchmark for subsequent research and promote the school of research to an advanced level.","sentences":["With the development of deep learning, automatic speech recognition (ASR) has made significant progress.","To further enhance the performance, revising recognition results is one of the lightweight but efficient manners.","Various methods can be roughly classified into N-best reranking methods and error correction models.","The former aims to select the hypothesis with the lowest error rate from a set of candidates generated by ASR for a given input speech.","The latter focuses on detecting recognition errors in a given hypothesis and correcting these errors to obtain an enhanced result.","However, we observe that these studies are hardly comparable to each other as they are usually evaluated on different corpora, paired with different ASR models, and even use different datasets to train the models.","Accordingly, we first concentrate on releasing an ASR hypothesis revising (HypR) dataset in this study.","HypR contains several commonly used corpora (AISHELL-1, TED-LIUM 2, and LibriSpeech) and provides 50 recognition hypotheses for each speech utterance.","The checkpoint models of the ASR are also published.","In addition, we implement and compare several classic and representative methods, showing the recent research progress in revising speech recognition results.","We hope the publicly available HypR dataset can become a reference benchmark for subsequent research and promote the school of research to an advanced level."],"url":"http://arxiv.org/abs/2309.09838v2"}
