{"created":"2023-11-02 17:59:55","title":"Idempotent Generative Network","abstract":"We propose a new approach for generative modeling based on training a neural network to be idempotent. An idempotent operator is one that can be applied sequentially without changing the result beyond the initial application, namely $f(f(z))=f(z)$. The proposed model $f$ is trained to map a source distribution (e.g, Gaussian noise) to a target distribution (e.g. realistic images) using the following objectives: (1) Instances from the target distribution should map to themselves, namely $f(x)=x$. We define the target manifold as the set of all instances that $f$ maps to themselves. (2) Instances that form the source distribution should map onto the defined target manifold. This is achieved by optimizing the idempotence term, $f(f(z))=f(z)$ which encourages the range of $f(z)$ to be on the target manifold. Under ideal assumptions such a process provably converges to the target distribution. This strategy results in a model capable of generating an output in one step, maintaining a consistent latent space, while also allowing sequential applications for refinement. Additionally, we find that by processing inputs from both target and source distributions, the model adeptly projects corrupted or modified data back to the target manifold. This work is a first step towards a ``global projector'' that enables projecting any input into a target data distribution.","sentences":["We propose a new approach for generative modeling based on training a neural network to be idempotent.","An idempotent operator is one that can be applied sequentially without changing the result beyond the initial application, namely $f(f(z))=f(z)$. The proposed model $f$ is trained to map a source distribution (e.g, Gaussian noise) to a target distribution (e.g. realistic images) using the following objectives: (1) Instances from the target distribution should map to themselves, namely $f(x)=x$. We define the target manifold as the set of all instances that $f$ maps to themselves.","(2) Instances that form the source distribution should map onto the defined target manifold.","This is achieved by optimizing the idempotence term, $f(f(z))=f(z)$ which encourages the range of $f(z)$ to be on the target manifold.","Under ideal assumptions such a process provably converges to the target distribution.","This strategy results in a model capable of generating an output in one step, maintaining a consistent latent space, while also allowing sequential applications for refinement.","Additionally, we find that by processing inputs from both target and source distributions, the model adeptly projects corrupted or modified data back to the target manifold.","This work is a first step towards a ``global projector'' that enables projecting any input into a target data distribution."],"url":"http://arxiv.org/abs/2311.01462v1"}
{"created":"2023-11-02 17:59:51","title":"The Property Law of Crypto Tokens","abstract":"This article addresses the lack of comprehensive studies on Web3 technologies, primarily due to lawyers' reluctance to explore technical intricacies. Understanding the underlying technological foundations is crucial to enhance the credibility of legal opinions. This article aims to illuminate these foundations, debunk myths, and concentrate on determining the legal status of crypto-assets in the context of property rights within the distributed economy. In addition, this article notes that the intangible nature of crypto-assets that derive value from distributed registries, and their resistance to deletion, makes crypto-assets more akin to the autonomy of intellectual property than physical media. The article presents illustrative examples from common law (United States, United Kingdom, New Zealand) and civil law (Germany, Austria, Poland) systems. Proposing a universal solution, it advocates a comprehensive framework safeguarding digital property - data ownership - extending beyond the confines of Web3.   This article presents a comprehensive, multi-layered approach to the analysis of tokens as digital content and virtual goods. The approach, universally applicable to various of such goods, scrutinizes property on three distinct layers: first, the rights to the virtual good itself; second, the rights to the assets linked to the virtual good; and third, the rights to the intellectual property intricately associated with the token. Additionally, the paper provides concise analysis of the conflict of laws rules applicable to virtual goods. It also delves into issues concerning formal requirements for the transfer of intellectual property rights, licensing, the first sale (exhaustion) doctrine, the concept of the lawful acquirer, and other crucial aspects of intellectual property in the realm of virtual goods, particularly within the emerging metaverse.","sentences":["This article addresses the lack of comprehensive studies on Web3 technologies, primarily due to lawyers' reluctance to explore technical intricacies.","Understanding the underlying technological foundations is crucial to enhance the credibility of legal opinions.","This article aims to illuminate these foundations, debunk myths, and concentrate on determining the legal status of crypto-assets in the context of property rights within the distributed economy.","In addition, this article notes that the intangible nature of crypto-assets that derive value from distributed registries, and their resistance to deletion, makes crypto-assets more akin to the autonomy of intellectual property than physical media.","The article presents illustrative examples from common law (United States, United Kingdom, New Zealand) and civil law (Germany, Austria, Poland) systems.","Proposing a universal solution, it advocates a comprehensive framework safeguarding digital property - data ownership - extending beyond the confines of Web3.   ","This article presents a comprehensive, multi-layered approach to the analysis of tokens as digital content and virtual goods.","The approach, universally applicable to various of such goods, scrutinizes property on three distinct layers: first, the rights to the virtual good itself; second, the rights to the assets linked to the virtual good; and third, the rights to the intellectual property intricately associated with the token.","Additionally, the paper provides concise analysis of the conflict of laws rules applicable to virtual goods.","It also delves into issues concerning formal requirements for the transfer of intellectual property rights, licensing, the first sale (exhaustion) doctrine, the concept of the lawful acquirer, and other crucial aspects of intellectual property in the realm of virtual goods, particularly within the emerging metaverse."],"url":"http://arxiv.org/abs/2311.01461v1"}
{"created":"2023-11-02 17:59:49","title":"Implicit Chain of Thought Reasoning via Knowledge Distillation","abstract":"To augment language models with the ability to reason, researchers usually prompt or finetune them to produce chain of thought reasoning steps before producing the final answer. However, although people use natural language to reason effectively, it may be that LMs could reason more effectively with some intermediate computation that is not in natural language. In this work, we explore an alternative reasoning approach: instead of explicitly producing the chain of thought reasoning steps, we use the language model's internal hidden states to perform implicit reasoning. The implicit reasoning steps are distilled from a teacher model trained on explicit chain-of-thought reasoning, and instead of doing reasoning \"horizontally\" by producing intermediate words one-by-one, we distill it such that the reasoning happens \"vertically\" among the hidden states in different layers. We conduct experiments on a multi-digit multiplication task and a grade school math problem dataset and find that this approach enables solving tasks previously not solvable without explicit chain-of-thought, at a speed comparable to no chain-of-thought.","sentences":["To augment language models with the ability to reason, researchers usually prompt or finetune them to produce chain of thought reasoning steps before producing the final answer.","However, although people use natural language to reason effectively, it may be that LMs could reason more effectively with some intermediate computation that is not in natural language.","In this work, we explore an alternative reasoning approach: instead of explicitly producing the chain of thought reasoning steps, we use the language model's internal hidden states to perform implicit reasoning.","The implicit reasoning steps are distilled from a teacher model trained on explicit chain-of-thought reasoning, and instead of doing reasoning \"horizontally\" by producing intermediate words one-by-one, we distill it such that the reasoning happens \"vertically\" among the hidden states in different layers.","We conduct experiments on a multi-digit multiplication task and a grade school math problem dataset and find that this approach enables solving tasks previously not solvable without explicit chain-of-thought, at a speed comparable to no chain-of-thought."],"url":"http://arxiv.org/abs/2311.01460v1"}
{"created":"2023-11-02 17:59:32","title":"Align Your Prompts: Test-Time Prompting with Distribution Alignment for Zero-Shot Generalization","abstract":"The promising zero-shot generalization of vision-language models such as CLIP has led to their adoption using prompt learning for numerous downstream tasks. Previous works have shown test-time prompt tuning using entropy minimization to adapt text prompts for unseen domains. While effective, this overlooks the key cause for performance degradation to unseen domains -- distribution shift. In this work, we explicitly handle this problem by aligning the out-of-distribution (OOD) test sample statistics to those of the source data using prompt tuning. We use a single test sample to adapt multi-modal prompts at test time by minimizing the feature distribution shift to bridge the gap in the test domain. Evaluating against the domain generalization benchmark, our method improves zero-shot top- 1 accuracy beyond existing prompt-learning techniques, with a 3.08% improvement over the baseline MaPLe. In cross-dataset generalization with unseen categories across 10 datasets, our method improves consistently across all datasets compared to the existing state-of-the-art. Our source code and models are available at https://jameelhassan.github.io/promptalign.","sentences":["The promising zero-shot generalization of vision-language models such as CLIP has led to their adoption using prompt learning for numerous downstream tasks.","Previous works have shown test-time prompt tuning using entropy minimization to adapt text prompts for unseen domains.","While effective, this overlooks the key cause for performance degradation to unseen domains -- distribution shift.","In this work, we explicitly handle this problem by aligning the out-of-distribution (OOD) test sample statistics to those of the source data using prompt tuning.","We use a single test sample to adapt multi-modal prompts at test time by minimizing the feature distribution shift to bridge the gap in the test domain.","Evaluating against the domain generalization benchmark, our method improves zero-shot top- 1 accuracy beyond existing prompt-learning techniques, with a 3.08% improvement over the baseline MaPLe.","In cross-dataset generalization with unseen categories across 10 datasets, our method improves consistently across all datasets compared to the existing state-of-the-art.","Our source code and models are available at https://jameelhassan.github.io/promptalign."],"url":"http://arxiv.org/abs/2311.01459v1"}
{"created":"2023-11-02 17:59:31","title":"Detecting Deepfakes Without Seeing Any","abstract":"Deepfake attacks, malicious manipulation of media containing people, are a serious concern for society. Conventional deepfake detection methods train supervised classifiers to distinguish real media from previously encountered deepfakes. Such techniques can only detect deepfakes similar to those previously seen, but not zero-day (previously unseen) attack types. As current deepfake generation techniques are changing at a breathtaking pace, new attack types are proposed frequently, making this a major issue. Our main observations are that: i) in many effective deepfake attacks, the fake media must be accompanied by false facts i.e. claims about the identity, speech, motion, or appearance of the person. For instance, when impersonating Obama, the attacker explicitly or implicitly claims that the fake media show Obama; ii) current generative techniques cannot perfectly synthesize the false facts claimed by the attacker. We therefore introduce the concept of \"fact checking\", adapted from fake news detection, for detecting zero-day deepfake attacks. Fact checking verifies that the claimed facts (e.g. identity is Obama), agree with the observed media (e.g. is the face really Obama's?), and thus can differentiate between real and fake media. Consequently, we introduce FACTOR, a practical recipe for deepfake fact checking and demonstrate its power in critical attack settings: face swapping and audio-visual synthesis. Although it is training-free, relies exclusively on off-the-shelf features, is very easy to implement, and does not see any deepfakes, it achieves better than state-of-the-art accuracy.","sentences":["Deepfake attacks, malicious manipulation of media containing people, are a serious concern for society.","Conventional deepfake detection methods train supervised classifiers to distinguish real media from previously encountered deepfakes.","Such techniques can only detect deepfakes similar to those previously seen, but not zero-day (previously unseen) attack types.","As current deepfake generation techniques are changing at a breathtaking pace, new attack types are proposed frequently, making this a major issue.","Our main observations are that: i) in many effective deepfake attacks, the fake media must be accompanied by false facts i.e. claims about the identity, speech, motion, or appearance of the person.","For instance, when impersonating Obama, the attacker explicitly or implicitly claims that the fake media show Obama; ii) current generative techniques cannot perfectly synthesize the false facts claimed by the attacker.","We therefore introduce the concept of \"fact checking\", adapted from fake news detection, for detecting zero-day deepfake attacks.","Fact checking verifies that the claimed facts (e.g. identity is Obama), agree with the observed media (e.g. is the face really Obama's?), and thus can differentiate between real and fake media.","Consequently, we introduce FACTOR, a practical recipe for deepfake fact checking and demonstrate its power in critical attack settings: face swapping and audio-visual synthesis.","Although it is training-free, relies exclusively on off-the-shelf features, is very easy to implement, and does not see any deepfakes, it achieves better than state-of-the-art accuracy."],"url":"http://arxiv.org/abs/2311.01458v1"}
{"created":"2023-11-02 17:59:30","title":"Conformal Policy Learning for Sensorimotor Control Under Distribution Shifts","abstract":"This paper focuses on the problem of detecting and reacting to changes in the distribution of a sensorimotor controller's observables. The key idea is the design of switching policies that can take conformal quantiles as input, which we define as conformal policy learning, that allows robots to detect distribution shifts with formal statistical guarantees. We show how to design such policies by using conformal quantiles to switch between base policies with different characteristics, e.g. safety or speed, or directly augmenting a policy observation with a quantile and training it with reinforcement learning. Theoretically, we show that such policies achieve the formal convergence guarantees in finite time. In addition, we thoroughly evaluate their advantages and limitations on two compelling use cases: simulated autonomous driving and active perception with a physical quadruped. Empirical results demonstrate that our approach outperforms five baselines. It is also the simplest of the baseline strategies besides one ablation. Being easy to use, flexible, and with formal guarantees, our work demonstrates how conformal prediction can be an effective tool for sensorimotor learning under uncertainty.","sentences":["This paper focuses on the problem of detecting and reacting to changes in the distribution of a sensorimotor controller's observables.","The key idea is the design of switching policies that can take conformal quantiles as input, which we define as conformal policy learning, that allows robots to detect distribution shifts with formal statistical guarantees.","We show how to design such policies by using conformal quantiles to switch between base policies with different characteristics, e.g. safety or speed, or directly augmenting a policy observation with a quantile and training it with reinforcement learning.","Theoretically, we show that such policies achieve the formal convergence guarantees in finite time.","In addition, we thoroughly evaluate their advantages and limitations on two compelling use cases: simulated autonomous driving and active perception with a physical quadruped.","Empirical results demonstrate that our approach outperforms five baselines.","It is also the simplest of the baseline strategies besides one ablation.","Being easy to use, flexible, and with formal guarantees, our work demonstrates how conformal prediction can be an effective tool for sensorimotor learning under uncertainty."],"url":"http://arxiv.org/abs/2311.01457v1"}
{"created":"2023-11-02 17:59:21","title":"RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation","abstract":"We present RoboGen, a generative robotic agent that automatically learns diverse robotic skills at scale via generative simulation. RoboGen leverages the latest advancements in foundation and generative models. Instead of directly using or adapting these models to produce policies or low-level actions, we advocate for a generative scheme, which uses these models to automatically generate diversified tasks, scenes, and training supervisions, thereby scaling up robotic skill learning with minimal human supervision. Our approach equips a robotic agent with a self-guided propose-generate-learn cycle: the agent first proposes interesting tasks and skills to develop, and then generates corresponding simulation environments by populating pertinent objects and assets with proper spatial configurations. Afterwards, the agent decomposes the proposed high-level task into sub-tasks, selects the optimal learning approach (reinforcement learning, motion planning, or trajectory optimization), generates required training supervision, and then learns policies to acquire the proposed skill. Our work attempts to extract the extensive and versatile knowledge embedded in large-scale models and transfer them to the field of robotics. Our fully generative pipeline can be queried repeatedly, producing an endless stream of skill demonstrations associated with diverse tasks and environments.","sentences":["We present RoboGen, a generative robotic agent that automatically learns diverse robotic skills at scale via generative simulation.","RoboGen leverages the latest advancements in foundation and generative models.","Instead of directly using or adapting these models to produce policies or low-level actions, we advocate for a generative scheme, which uses these models to automatically generate diversified tasks, scenes, and training supervisions, thereby scaling up robotic skill learning with minimal human supervision.","Our approach equips a robotic agent with a self-guided propose-generate-learn cycle: the agent first proposes interesting tasks and skills to develop, and then generates corresponding simulation environments by populating pertinent objects and assets with proper spatial configurations.","Afterwards, the agent decomposes the proposed high-level task into sub-tasks, selects the optimal learning approach (reinforcement learning, motion planning, or trajectory optimization), generates required training supervision, and then learns policies to acquire the proposed skill.","Our work attempts to extract the extensive and versatile knowledge embedded in large-scale models and transfer them to the field of robotics.","Our fully generative pipeline can be queried repeatedly, producing an endless stream of skill demonstrations associated with diverse tasks and environments."],"url":"http://arxiv.org/abs/2311.01455v1"}
{"created":"2023-11-02 17:59:06","title":"NOIR: Neural Signal Operated Intelligent Robots for Everyday Activities","abstract":"We present Neural Signal Operated Intelligent Robots (NOIR), a general-purpose, intelligent brain-robot interface system that enables humans to command robots to perform everyday activities through brain signals. Through this interface, humans communicate their intended objects of interest and actions to the robots using electroencephalography (EEG). Our novel system demonstrates success in an expansive array of 20 challenging, everyday household activities, including cooking, cleaning, personal care, and entertainment. The effectiveness of the system is improved by its synergistic integration of robot learning algorithms, allowing for NOIR to adapt to individual users and predict their intentions. Our work enhances the way humans interact with robots, replacing traditional channels of interaction with direct, neural communication. Project website: https://noir-corl.github.io/.","sentences":["We present Neural Signal Operated Intelligent Robots (NOIR), a general-purpose, intelligent brain-robot interface system that enables humans to command robots to perform everyday activities through brain signals.","Through this interface, humans communicate their intended objects of interest and actions to the robots using electroencephalography (EEG).","Our novel system demonstrates success in an expansive array of 20 challenging, everyday household activities, including cooking, cleaning, personal care, and entertainment.","The effectiveness of the system is improved by its synergistic integration of robot learning algorithms, allowing for NOIR to adapt to individual users and predict their intentions.","Our work enhances the way humans interact with robots, replacing traditional channels of interaction with direct, neural communication.","Project website: https://noir-corl.github.io/."],"url":"http://arxiv.org/abs/2311.01454v1"}
{"created":"2023-11-02 17:58:09","title":"Time Series Anomaly Detection using Diffusion-based Models","abstract":"Diffusion models have been recently used for anomaly detection (AD) in images. In this paper we investigate whether they can also be leveraged for AD on multivariate time series (MTS). We test two diffusion-based models and compare them to several strong neural baselines. We also extend the PA%K protocol, by computing a ROCK-AUC metric, which is agnostic to both the detection threshold and the ratio K of correctly detected points. Our models outperform the baselines on synthetic datasets and are competitive on real-world datasets, illustrating the potential of diffusion-based methods for AD in multivariate time series.","sentences":["Diffusion models have been recently used for anomaly detection (AD) in images.","In this paper we investigate whether they can also be leveraged for AD on multivariate time series (MTS).","We test two diffusion-based models and compare them to several strong neural baselines.","We also extend the PA%K protocol, by computing a ROCK-AUC metric, which is agnostic to both the detection threshold and the ratio K of correctly detected points.","Our models outperform the baselines on synthetic datasets and are competitive on real-world datasets, illustrating the potential of diffusion-based methods for AD in multivariate time series."],"url":"http://arxiv.org/abs/2311.01452v1"}
{"created":"2023-11-02 17:57:38","title":"DreamSmooth: Improving Model-based Reinforcement Learning via Reward Smoothing","abstract":"Model-based reinforcement learning (MBRL) has gained much attention for its ability to learn complex behaviors in a sample-efficient way: planning actions by generating imaginary trajectories with predicted rewards. Despite its success, we found that surprisingly, reward prediction is often a bottleneck of MBRL, especially for sparse rewards that are challenging (or even ambiguous) to predict. Motivated by the intuition that humans can learn from rough reward estimates, we propose a simple yet effective reward smoothing approach, DreamSmooth, which learns to predict a temporally-smoothed reward, instead of the exact reward at the given timestep. We empirically show that DreamSmooth achieves state-of-the-art performance on long-horizon sparse-reward tasks both in sample efficiency and final performance without losing performance on common benchmarks, such as Deepmind Control Suite and Atari benchmarks.","sentences":["Model-based reinforcement learning (MBRL) has gained much attention for its ability to learn complex behaviors in a sample-efficient way: planning actions by generating imaginary trajectories with predicted rewards.","Despite its success, we found that surprisingly, reward prediction is often a bottleneck of MBRL, especially for sparse rewards that are challenging (or even ambiguous) to predict.","Motivated by the intuition that humans can learn from rough reward estimates, we propose a simple yet effective reward smoothing approach, DreamSmooth, which learns to predict a temporally-smoothed reward, instead of the exact reward at the given timestep.","We empirically show that DreamSmooth achieves state-of-the-art performance on long-horizon sparse-reward tasks both in sample efficiency and final performance without losing performance on common benchmarks, such as Deepmind Control Suite and Atari benchmarks."],"url":"http://arxiv.org/abs/2311.01450v1"}
{"created":"2023-11-02 17:57:10","title":"TopicGPT: A Prompt-based Topic Modeling Framework","abstract":"Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. TopicGPT can be further extended to hierarchical topical modeling, enabling users to explore topics at various levels of granularity. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.","sentences":["Topic modeling is a well-established technique for exploring text corpora.","Conventional topic models (e.g., LDA) represent topics as bags of words that often require \"reading the tea leaves\" to interpret; additionally, they offer users minimal semantic control over topics.","To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collection.","TopicGPT produces topics that align better with human categorizations compared to competing methods: for example, it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline.","Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions.","Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining.","TopicGPT can be further extended to hierarchical topical modeling, enabling users to explore topics at various levels of granularity.","By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling."],"url":"http://arxiv.org/abs/2311.01449v1"}
{"created":"2023-11-02 17:57:03","title":"UltraLiDAR: Learning Compact Representations for LiDAR Completion and Generation","abstract":"LiDAR provides accurate geometric measurements of the 3D world. Unfortunately, dense LiDARs are very expensive and the point clouds captured by low-beam LiDAR are often sparse. To address these issues, we present UltraLiDAR, a data-driven framework for scene-level LiDAR completion, LiDAR generation, and LiDAR manipulation. The crux of UltraLiDAR is a compact, discrete representation that encodes the point cloud's geometric structure, is robust to noise, and is easy to manipulate. We show that by aligning the representation of a sparse point cloud to that of a dense point cloud, we can densify the sparse point clouds as if they were captured by a real high-density LiDAR, drastically reducing the cost. Furthermore, by learning a prior over the discrete codebook, we can generate diverse, realistic LiDAR point clouds for self-driving. We evaluate the effectiveness of UltraLiDAR on sparse-to-dense LiDAR completion and LiDAR generation. Experiments show that densifying real-world point clouds with our approach can significantly improve the performance of downstream perception systems. Compared to prior art on LiDAR generation, our approach generates much more realistic point clouds. According to A/B test, over 98.5\\% of the time human participants prefer our results over those of previous methods.","sentences":["LiDAR provides accurate geometric measurements of the 3D world.","Unfortunately, dense LiDARs are very expensive and the point clouds captured by low-beam LiDAR are often sparse.","To address these issues, we present UltraLiDAR, a data-driven framework for scene-level LiDAR completion, LiDAR generation, and LiDAR manipulation.","The crux of UltraLiDAR is a compact, discrete representation that encodes the point cloud's geometric structure, is robust to noise, and is easy to manipulate.","We show that by aligning the representation of a sparse point cloud to that of a dense point cloud, we can densify the sparse point clouds as if they were captured by a real high-density LiDAR, drastically reducing the cost.","Furthermore, by learning a prior over the discrete codebook, we can generate diverse, realistic LiDAR point clouds for self-driving.","We evaluate the effectiveness of UltraLiDAR on sparse-to-dense LiDAR completion and LiDAR generation.","Experiments show that densifying real-world point clouds with our approach can significantly improve the performance of downstream perception systems.","Compared to prior art on LiDAR generation, our approach generates much more realistic point clouds.","According to A/B test, over 98.5\\% of the time human participants prefer our results over those of previous methods."],"url":"http://arxiv.org/abs/2311.01448v1"}
{"created":"2023-11-02 17:56:59","title":"CADSim: Robust and Scalable in-the-wild 3D Reconstruction for Controllable Sensor Simulation","abstract":"Realistic simulation is key to enabling safe and scalable development of % self-driving vehicles. A core component is simulating the sensors so that the entire autonomy system can be tested in simulation. Sensor simulation involves modeling traffic participants, such as vehicles, with high quality appearance and articulated geometry, and rendering them in real time. The self-driving industry has typically employed artists to build these assets. However, this is expensive, slow, and may not reflect reality. Instead, reconstructing assets automatically from sensor data collected in the wild would provide a better path to generating a diverse and large set with good real-world coverage. Nevertheless, current reconstruction approaches struggle on in-the-wild sensor data, due to its sparsity and noise. To tackle these issues, we present CADSim, which combines part-aware object-class priors via a small set of CAD models with differentiable rendering to automatically reconstruct vehicle geometry, including articulated wheels, with high-quality appearance. Our experiments show our method recovers more accurate shapes from sparse data compared to existing approaches. Importantly, it also trains and renders efficiently. We demonstrate our reconstructed vehicles in several applications, including accurate testing of autonomy perception systems.","sentences":["Realistic simulation is key to enabling safe and scalable development of % self-driving vehicles.","A core component is simulating the sensors so that the entire autonomy system can be tested in simulation.","Sensor simulation involves modeling traffic participants, such as vehicles, with high quality appearance and articulated geometry, and rendering them in real time.","The self-driving industry has typically employed artists to build these assets.","However, this is expensive, slow, and may not reflect reality.","Instead, reconstructing assets automatically from sensor data collected in the wild would provide a better path to generating a diverse and large set with good real-world coverage.","Nevertheless, current reconstruction approaches struggle on in-the-wild sensor data, due to its sparsity and noise.","To tackle these issues, we present CADSim, which combines part-aware object-class priors via a small set of CAD models with differentiable rendering to automatically reconstruct vehicle geometry, including articulated wheels, with high-quality appearance.","Our experiments show our method recovers more accurate shapes from sparse data compared to existing approaches.","Importantly, it also trains and renders efficiently.","We demonstrate our reconstructed vehicles in several applications, including accurate testing of autonomy perception systems."],"url":"http://arxiv.org/abs/2311.01447v1"}
{"created":"2023-11-02 17:56:44","title":"Adv3D: Generating Safety-Critical 3D Objects through Closed-Loop Simulation","abstract":"Self-driving vehicles (SDVs) must be rigorously tested on a wide range of scenarios to ensure safe deployment. The industry typically relies on closed-loop simulation to evaluate how the SDV interacts on a corpus of synthetic and real scenarios and verify it performs properly. However, they primarily only test the system's motion planning module, and only consider behavior variations. It is key to evaluate the full autonomy system in closed-loop, and to understand how variations in sensor data based on scene appearance, such as the shape of actors, affect system performance. In this paper, we propose a framework, Adv3D, that takes real world scenarios and performs closed-loop sensor simulation to evaluate autonomy performance, and finds vehicle shapes that make the scenario more challenging, resulting in autonomy failures and uncomfortable SDV maneuvers. Unlike prior works that add contrived adversarial shapes to vehicle roof-tops or roadside to harm perception only, we optimize a low-dimensional shape representation to modify the vehicle shape itself in a realistic manner to degrade autonomy performance (e.g., perception, prediction, and motion planning). Moreover, we find that the shape variations found with Adv3D optimized in closed-loop are much more effective than those in open-loop, demonstrating the importance of finding scene appearance variations that affect autonomy in the interactive setting.","sentences":["Self-driving vehicles (SDVs) must be rigorously tested on a wide range of scenarios to ensure safe deployment.","The industry typically relies on closed-loop simulation to evaluate how the SDV interacts on a corpus of synthetic and real scenarios and verify it performs properly.","However, they primarily only test the system's motion planning module, and only consider behavior variations.","It is key to evaluate the full autonomy system in closed-loop, and to understand how variations in sensor data based on scene appearance, such as the shape of actors, affect system performance.","In this paper, we propose a framework, Adv3D, that takes real world scenarios and performs closed-loop sensor simulation to evaluate autonomy performance, and finds vehicle shapes that make the scenario more challenging, resulting in autonomy failures and uncomfortable SDV maneuvers.","Unlike prior works that add contrived adversarial shapes to vehicle roof-tops or roadside to harm perception only, we optimize a low-dimensional shape representation to modify the vehicle shape itself in a realistic manner to degrade autonomy performance (e.g., perception, prediction, and motion planning).","Moreover, we find that the shape variations found with Adv3D optimized in closed-loop are much more effective than those in open-loop, demonstrating the importance of finding scene appearance variations that affect autonomy in the interactive setting."],"url":"http://arxiv.org/abs/2311.01446v1"}
{"created":"2023-11-02 17:56:06","title":"LabelFormer: Object Trajectory Refinement for Offboard Perception from LiDAR Point Clouds","abstract":"A major bottleneck to scaling-up training of self-driving perception systems are the human annotations required for supervision. A promising alternative is to leverage \"auto-labelling\" offboard perception models that are trained to automatically generate annotations from raw LiDAR point clouds at a fraction of the cost. Auto-labels are most commonly generated via a two-stage approach -- first objects are detected and tracked over time, and then each object trajectory is passed to a learned refinement model to improve accuracy. Since existing refinement models are overly complex and lack advanced temporal reasoning capabilities, in this work we propose LabelFormer, a simple, efficient, and effective trajectory-level refinement approach. Our approach first encodes each frame's observations separately, then exploits self-attention to reason about the trajectory with full temporal context, and finally decodes the refined object size and per-frame poses. Evaluation on both urban and highway datasets demonstrates that LabelFormer outperforms existing works by a large margin. Finally, we show that training on a dataset augmented with auto-labels generated by our method leads to improved downstream detection performance compared to existing methods. Please visit the project website for details https://waabi.ai/labelformer","sentences":["A major bottleneck to scaling-up training of self-driving perception systems are the human annotations required for supervision.","A promising alternative is to leverage \"auto-labelling\" offboard perception models that are trained to automatically generate annotations from raw LiDAR point clouds at a fraction of the cost.","Auto-labels are most commonly generated via a two-stage approach -- first objects are detected and tracked over time, and then each object trajectory is passed to a learned refinement model to improve accuracy.","Since existing refinement models are overly complex and lack advanced temporal reasoning capabilities, in this work we propose LabelFormer, a simple, efficient, and effective trajectory-level refinement approach.","Our approach first encodes each frame's observations separately, then exploits self-attention to reason about the trajectory with full temporal context, and finally decodes the refined object size and per-frame poses.","Evaluation on both urban and highway datasets demonstrates that LabelFormer outperforms existing works by a large margin.","Finally, we show that training on a dataset augmented with auto-labels generated by our method leads to improved downstream detection performance compared to existing methods.","Please visit the project website for details https://waabi.ai/labelformer"],"url":"http://arxiv.org/abs/2311.01444v1"}
{"created":"2023-11-02 17:55:41","title":"Deep Double Descent for Time Series Forecasting: Avoiding Undertrained Models","abstract":"Deep learning models, particularly Transformers, have achieved impressive results in various domains, including time series forecasting. While existing time series literature primarily focuses on model architecture modifications and data augmentation techniques, this paper explores the training schema of deep learning models for time series; how models are trained regardless of their architecture. We perform extensive experiments to investigate the occurrence of deep double descent in several Transformer models trained on public time series data sets. We demonstrate epoch-wise deep double descent and that overfitting can be reverted using more epochs. Leveraging these findings, we achieve state-of-the-art results for long sequence time series forecasting in nearly 70% of the 72 benchmarks tested. This suggests that many models in the literature may possess untapped potential. Additionally, we introduce a taxonomy for classifying training schema modifications, covering data augmentation, model inputs, model targets, time series per model, and computational budget.","sentences":["Deep learning models, particularly Transformers, have achieved impressive results in various domains, including time series forecasting.","While existing time series literature primarily focuses on model architecture modifications and data augmentation techniques, this paper explores the training schema of deep learning models for time series; how models are trained regardless of their architecture.","We perform extensive experiments to investigate the occurrence of deep double descent in several Transformer models trained on public time series data sets.","We demonstrate epoch-wise deep double descent and that overfitting can be reverted using more epochs.","Leveraging these findings, we achieve state-of-the-art results for long sequence time series forecasting in nearly 70% of the 72 benchmarks tested.","This suggests that many models in the literature may possess untapped potential.","Additionally, we introduce a taxonomy for classifying training schema modifications, covering data augmentation, model inputs, model targets, time series per model, and computational budget."],"url":"http://arxiv.org/abs/2311.01442v1"}
{"created":"2023-11-02 17:55:13","title":"Distilling Out-of-Distribution Robustness from Vision-Language Foundation Models","abstract":"We propose a conceptually simple and lightweight framework for improving the robustness of vision models through the combination of knowledge distillation and data augmentation. We address the conjecture that larger models do not make for better teachers by showing strong gains in out-of-distribution robustness when distilling from pretrained foundation models. Following this finding, we propose Discrete Adversarial Distillation (DAD), which leverages a robust teacher to generate adversarial examples and a VQGAN to discretize them, creating more informative samples than standard data augmentation techniques. We provide a theoretical framework for the use of a robust teacher in the knowledge distillation with data augmentation setting and demonstrate strong gains in out-of-distribution robustness and clean accuracy across different student architectures. Notably, our method adds minor computational overhead compared to similar techniques and can be easily combined with other data augmentations for further improvements.","sentences":["We propose a conceptually simple and lightweight framework for improving the robustness of vision models through the combination of knowledge distillation and data augmentation.","We address the conjecture that larger models do not make for better teachers by showing strong gains in out-of-distribution robustness when distilling from pretrained foundation models.","Following this finding, we propose Discrete Adversarial Distillation (DAD), which leverages a robust teacher to generate adversarial examples and a VQGAN to discretize them, creating more informative samples than standard data augmentation techniques.","We provide a theoretical framework for the use of a robust teacher in the knowledge distillation with data augmentation setting and demonstrate strong gains in out-of-distribution robustness and clean accuracy across different student architectures.","Notably, our method adds minor computational overhead compared to similar techniques and can be easily combined with other data augmentations for further improvements."],"url":"http://arxiv.org/abs/2311.01441v1"}
{"created":"2023-11-02 17:51:10","title":"Contrastive Moments: Unsupervised Halfspace Learning in Polynomial Time","abstract":"We give a polynomial-time algorithm for learning high-dimensional halfspaces with margins in $d$-dimensional space to within desired TV distance when the ambient distribution is an unknown affine transformation of the $d$-fold product of an (unknown) symmetric one-dimensional logconcave distribution, and the halfspace is introduced by deleting at least an $\\epsilon$ fraction of the data in one of the component distributions. Notably, our algorithm does not need labels and establishes the unique (and efficient) identifiability of the hidden halfspace under this distributional assumption. The sample and time complexity of the algorithm are polynomial in the dimension and $1/\\epsilon$. The algorithm uses only the first two moments of suitable re-weightings of the empirical distribution, which we call contrastive moments; its analysis uses classical facts about generalized Dirichlet polynomials and relies crucially on a new monotonicity property of the moment ratio of truncations of logconcave distributions. Such algorithms, based only on first and second moments were suggested in earlier work, but hitherto eluded rigorous guarantees.   Prior work addressed the special case when the underlying distribution is Gaussian via Non-Gaussian Component Analysis. We improve on this by providing polytime guarantees based on Total Variation (TV) distance, in place of existing moment-bound guarantees that can be super-polynomial. Our work is also the first to go beyond Gaussians in this setting.","sentences":["We give a polynomial-time algorithm for learning high-dimensional halfspaces with margins in $d$-dimensional space to within desired TV distance when the ambient distribution is an unknown affine transformation of the $d$-fold product of an (unknown) symmetric one-dimensional logconcave distribution, and the halfspace is introduced by deleting at least an $\\epsilon$ fraction of the data in one of the component distributions.","Notably, our algorithm does not need labels and establishes the unique (and efficient) identifiability of the hidden halfspace under this distributional assumption.","The sample and time complexity of the algorithm are polynomial in the dimension and $1/\\epsilon$. The algorithm uses only the first two moments of suitable re-weightings of the empirical distribution, which we call contrastive moments; its analysis uses classical facts about generalized Dirichlet polynomials and relies crucially on a new monotonicity property of the moment ratio of truncations of logconcave distributions.","Such algorithms, based only on first and second moments were suggested in earlier work, but hitherto eluded rigorous guarantees.   ","Prior work addressed the special case when the underlying distribution is Gaussian via Non-Gaussian Component Analysis.","We improve on this by providing polytime guarantees based on Total Variation (TV) distance, in place of existing moment-bound guarantees that can be super-polynomial.","Our work is also the first to go beyond Gaussians in this setting."],"url":"http://arxiv.org/abs/2311.01435v1"}
{"created":"2023-11-02 17:48:28","title":"Tailoring Mixup to Data using Kernel Warping functions","abstract":"Data augmentation is an essential building block for learning efficient deep learning models. Among all augmentation techniques proposed so far, linear interpolation of training data points, also called mixup, has found to be effective for a large panel of applications. While the majority of works have focused on selecting the right points to mix, or applying complex non-linear interpolation, we are interested in mixing similar points more frequently and strongly than less similar ones. To this end, we propose to dynamically change the underlying distribution of interpolation coefficients through warping functions, depending on the similarity between data points to combine. We define an efficient and flexible framework to do so without losing in diversity. We provide extensive experiments for classification and regression tasks, showing that our proposed method improves both performance and calibration of models. Code available in https://github.com/ENSTA-U2IS/torch-uncertainty","sentences":["Data augmentation is an essential building block for learning efficient deep learning models.","Among all augmentation techniques proposed so far, linear interpolation of training data points, also called mixup, has found to be effective for a large panel of applications.","While the majority of works have focused on selecting the right points to mix, or applying complex non-linear interpolation, we are interested in mixing similar points more frequently and strongly than less similar ones.","To this end, we propose to dynamically change the underlying distribution of interpolation coefficients through warping functions, depending on the similarity between data points to combine.","We define an efficient and flexible framework to do so without losing in diversity.","We provide extensive experiments for classification and regression tasks, showing that our proposed method improves both performance and calibration of models.","Code available in https://github.com/ENSTA-U2IS/torch-uncertainty"],"url":"http://arxiv.org/abs/2311.01434v1"}
{"created":"2023-11-02 17:46:59","title":"A Comprehensive Study of Governance Issues in Decentralized Finance Applications","abstract":"Decentralized finance (DeFi) is a prominent application of smart contracts, representing a novel financial paradigm in contrast to centralized finance. While DeFi applications are rapidly emerging on mainstream blockchain platforms, their quality varies greatly, presenting numerous challenges, particularly in terms of smart contract governance. This paper presents a comprehensive study of governance issues in DeFi applications. Drawing upon insights from industry reports and academic research papers, we develop a governance taxonomy to examine these issues. We collect and analyze 4,446 audit reports from 17 reputable Web3 security companies, categorizing the governance issues according to our constructed taxonomy. In addition, we identify vulnerabilities in the governance design and implementation processes, e.g., flash loan attacks and reentrancy attacks. To aid in the identification of the main topics of governance issues, we employ Natural Language Processing (NLP) techniques. Moreover, we explore the challenges associated with maintaining consistency between the code and the whitepaper in DeFi applications, providing valuable insights for addressing this issue in the future. We build a prototype tool based on artificial intelligence (AI), representing an initial attempt to uncover potential solutions. We validate this prototype across eight DeFi projects, achieving a 56.14% F1 score and a 80% recall. Through this study, we expect to assist the design and development teams of DeFi applications, as well as users, researchers, and regulators, in better understanding and addressing governance challenges, thereby fostering the healthy development of DeFi.","sentences":["Decentralized finance (DeFi) is a prominent application of smart contracts, representing a novel financial paradigm in contrast to centralized finance.","While DeFi applications are rapidly emerging on mainstream blockchain platforms, their quality varies greatly, presenting numerous challenges, particularly in terms of smart contract governance.","This paper presents a comprehensive study of governance issues in DeFi applications.","Drawing upon insights from industry reports and academic research papers, we develop a governance taxonomy to examine these issues.","We collect and analyze 4,446 audit reports from 17 reputable Web3 security companies, categorizing the governance issues according to our constructed taxonomy.","In addition, we identify vulnerabilities in the governance design and implementation processes, e.g., flash loan attacks and reentrancy attacks.","To aid in the identification of the main topics of governance issues, we employ Natural Language Processing (NLP) techniques.","Moreover, we explore the challenges associated with maintaining consistency between the code and the whitepaper in DeFi applications, providing valuable insights for addressing this issue in the future.","We build a prototype tool based on artificial intelligence (AI), representing an initial attempt to uncover potential solutions.","We validate this prototype across eight DeFi projects, achieving a 56.14% F1 score and a 80% recall.","Through this study, we expect to assist the design and development teams of DeFi applications, as well as users, researchers, and regulators, in better understanding and addressing governance challenges, thereby fostering the healthy development of DeFi."],"url":"http://arxiv.org/abs/2311.01433v1"}
{"created":"2023-11-02 17:46:25","title":"Transformation Decoupling Strategy based on Screw Theory for Deterministic Point Cloud Registration with Gravity Prior","abstract":"Point cloud registration is challenging in the presence of heavy outlier correspondences. This paper focuses on addressing the robust correspondence-based registration problem with gravity prior that often arises in practice. The gravity directions are typically obtained by inertial measurement units (IMUs) and can reduce the degree of freedom (DOF) of rotation from 3 to 1. We propose a novel transformation decoupling strategy by leveraging screw theory. This strategy decomposes the original 4-DOF problem into three sub-problems with 1-DOF, 2-DOF, and 1-DOF, respectively, thereby enhancing the computation efficiency. Specifically, the first 1-DOF represents the translation along the rotation axis and we propose an interval stabbing-based method to solve it. The second 2-DOF represents the pole which is an auxiliary variable in screw theory and we utilize a branch-and-bound method to solve it. The last 1-DOF represents the rotation angle and we propose a global voting method for its estimation. The proposed method sequentially solves three consensus maximization sub-problems, leading to efficient and deterministic registration. In particular, it can even handle the correspondence-free registration problem due to its significant robustness. Extensive experiments on both synthetic and real-world datasets demonstrate that our method is more efficient and robust than state-of-the-art methods, even when dealing with outlier rates exceeding 99%.","sentences":["Point cloud registration is challenging in the presence of heavy outlier correspondences.","This paper focuses on addressing the robust correspondence-based registration problem with gravity prior that often arises in practice.","The gravity directions are typically obtained by inertial measurement units (IMUs) and can reduce the degree of freedom (DOF) of rotation from 3 to 1.","We propose a novel transformation decoupling strategy by leveraging screw theory.","This strategy decomposes the original 4-DOF problem into three sub-problems with 1-DOF, 2-DOF, and 1-DOF, respectively, thereby enhancing the computation efficiency.","Specifically, the first 1-DOF represents the translation along the rotation axis and we propose an interval stabbing-based method to solve it.","The second 2-DOF represents the pole which is an auxiliary variable in screw theory and we utilize a branch-and-bound method to solve it.","The last 1-DOF represents the rotation angle and we propose a global voting method for its estimation.","The proposed method sequentially solves three consensus maximization sub-problems, leading to efficient and deterministic registration.","In particular, it can even handle the correspondence-free registration problem due to its significant robustness.","Extensive experiments on both synthetic and real-world datasets demonstrate that our method is more efficient and robust than state-of-the-art methods, even when dealing with outlier rates exceeding 99%."],"url":"http://arxiv.org/abs/2311.01432v1"}
{"created":"2023-11-02 17:45:57","title":"Empirical Lossless Compression Bound of a Data Sequence","abstract":"We consider the lossless compression bound of any single data sequence. If we fit the data by a parametric model, the entropy quantity $nH({\\hat \\theta}_n)$ obtained by plugging in the maximum likelihood estimate is an underestimate of the bound, where $n$ is the number of words. Shtarkov showed that the normalized maximum likelihood (NML) distribution or code length is optimal in a minimax sense for any parametric family. We show by the local asymptotic normality that the NML code length for the exponential families is $nH(\\hat \\theta_n) +\\frac{d}{2}\\log \\, \\frac{n}{2\\pi} +\\log \\int_{\\Theta} |I(\\theta)|^{1/2}\\, d\\theta+o(1)$, where $d$ is the model dimension or dictionary size, and $|I(\\theta)|$ is the determinant of the Fisher information matrix. We also demonstrate that sequentially predicting the optimal code length for the next word via a Bayesian mechanism leads to the mixture code, whose pathwise length is given by $nH({\\hat \\theta}_n) +\\frac{d}{2}\\log \\, \\frac{n}{2\\pi} +\\log \\frac{|\\, I({\\hat \\theta}_n)|^{1/2}}{w({\\hat \\theta}_n)}+o(1) $, where $w(\\theta)$ is a prior. The asymptotics apply to not only discrete symbols but also continuous data if the code length for the former is replaced by the description length of the latter. The analytical result is exemplified by calculating compression bounds of protein-encoding DNA sequences under different parsing models. Typically, the highest compression is achieved when the parsing is in phase of the amino acid codons. On the other hand, the compression rates of pseudo-random sequences are larger than 1 regardless parsing models. These model-based results are in consistency with that random sequences are incompressible as asserted by the Kolmogorov complexity theory. The empirical lossless compression bound is particularly more accurate when dictionary size is relatively large.","sentences":["We consider the lossless compression bound of any single data sequence.","If we fit the data by a parametric model, the entropy quantity $nH({\\hat \\theta}_n)$ obtained by plugging in the maximum likelihood estimate is an underestimate of the bound, where $n$ is the number of words.","Shtarkov showed that the normalized maximum likelihood (NML) distribution or code length is optimal in a minimax sense for any parametric family.","We show by the local asymptotic normality that the NML code length for the exponential families is $nH(\\hat \\theta_n)","+\\frac{d}{2}\\log \\, \\frac{n}{2\\pi} +\\log \\int_{\\Theta} |I(\\theta)|^{1/2}\\, d\\theta+o(1)$, where $d$ is the model dimension or dictionary size, and","$|I(\\theta)|$ is the determinant of the Fisher information matrix.","We also demonstrate that sequentially predicting the optimal code length for the next word via a Bayesian mechanism leads to the mixture code, whose pathwise length is given by $nH({\\hat \\theta}_n) +\\frac{d}{2}\\log \\, \\frac{n}{2\\pi} +\\log \\frac{|\\, I({\\hat \\theta}_n)|^{1/2}}{w({\\hat \\theta}_n)}+o(1) $, where $w(\\theta)$ is a prior.","The asymptotics apply to not only discrete symbols but also continuous data if the code length for the former is replaced by the description length of the latter.","The analytical result is exemplified by calculating compression bounds of protein-encoding DNA sequences under different parsing models.","Typically, the highest compression is achieved when the parsing is in phase of the amino acid codons.","On the other hand, the compression rates of pseudo-random sequences are larger than 1 regardless parsing models.","These model-based results are in consistency with that random sequences are incompressible as asserted by the Kolmogorov complexity theory.","The empirical lossless compression bound is particularly more accurate when dictionary size is relatively large."],"url":"http://arxiv.org/abs/2311.01431v1"}
{"created":"2023-11-02 17:44:32","title":"Efficient Vision Transformer for Accurate Traffic Sign Detection","abstract":"This research paper addresses the challenges associated with traffic sign detection in self-driving vehicles and driver assistance systems. The development of reliable and highly accurate algorithms is crucial for the widespread adoption of traffic sign recognition and detection (TSRD) in diverse real-life scenarios. However, this task is complicated by suboptimal traffic images affected by factors such as camera movement, adverse weather conditions, and inadequate lighting. This study specifically focuses on traffic sign detection methods and introduces the application of the Transformer model, particularly the Vision Transformer variants, to tackle this task. The Transformer's attention mechanism, originally designed for natural language processing, offers improved parallel efficiency. Vision Transformers have demonstrated success in various domains, including autonomous driving, object detection, healthcare, and defense-related applications. To enhance the efficiency of the Transformer model, the research proposes a novel strategy that integrates a locality inductive bias and a transformer module. This includes the introduction of the Efficient Convolution Block and the Local Transformer Block, which effectively capture short-term and long-term dependency information, thereby improving both detection speed and accuracy. Experimental evaluations demonstrate the significant advancements achieved by this approach, particularly when applied to the GTSDB dataset.","sentences":["This research paper addresses the challenges associated with traffic sign detection in self-driving vehicles and driver assistance systems.","The development of reliable and highly accurate algorithms is crucial for the widespread adoption of traffic sign recognition and detection (TSRD) in diverse real-life scenarios.","However, this task is complicated by suboptimal traffic images affected by factors such as camera movement, adverse weather conditions, and inadequate lighting.","This study specifically focuses on traffic sign detection methods and introduces the application of the Transformer model, particularly the Vision Transformer variants, to tackle this task.","The Transformer's attention mechanism, originally designed for natural language processing, offers improved parallel efficiency.","Vision Transformers have demonstrated success in various domains, including autonomous driving, object detection, healthcare, and defense-related applications.","To enhance the efficiency of the Transformer model, the research proposes a novel strategy that integrates a locality inductive bias and a transformer module.","This includes the introduction of the Efficient Convolution Block and the Local Transformer Block, which effectively capture short-term and long-term dependency information, thereby improving both detection speed and accuracy.","Experimental evaluations demonstrate the significant advancements achieved by this approach, particularly when applied to the GTSDB dataset."],"url":"http://arxiv.org/abs/2311.01429v1"}
{"created":"2023-11-02 17:44:28","title":"Identifying Alzheimer Disease Dementia Levels Using Machine Learning Methods","abstract":"Dementia, a prevalent neurodegenerative condition, is a major manifestation of Alzheimer's disease (AD). As the condition progresses from mild to severe, it significantly impairs the individual's ability to perform daily tasks independently, necessitating the need for timely and accurate AD classification. Machine learning or deep learning models have emerged as effective tools for this purpose. In this study, we suggested an approach for classifying the four stages of dementia using RF, SVM, and CNN algorithms, augmented with watershed segmentation for feature extraction from MRI images. Our results reveal that SVM with watershed features achieves an impressive accuracy of 96.25%, surpassing other classification methods. The ADNI dataset is utilized to evaluate the effectiveness of our method, and we observed that the inclusion of watershed segmentation contributes to the enhanced performance of the models.","sentences":["Dementia, a prevalent neurodegenerative condition, is a major manifestation of Alzheimer's disease (AD).","As the condition progresses from mild to severe, it significantly impairs the individual's ability to perform daily tasks independently, necessitating the need for timely and accurate AD classification.","Machine learning or deep learning models have emerged as effective tools for this purpose.","In this study, we suggested an approach for classifying the four stages of dementia using RF, SVM, and CNN algorithms, augmented with watershed segmentation for feature extraction from MRI images.","Our results reveal that SVM with watershed features achieves an impressive accuracy of 96.25%, surpassing other classification methods.","The ADNI dataset is utilized to evaluate the effectiveness of our method, and we observed that the inclusion of watershed segmentation contributes to the enhanced performance of the models."],"url":"http://arxiv.org/abs/2311.01428v1"}
{"created":"2023-11-02 17:36:40","title":"CenterRadarNet: Joint 3D Object Detection and Tracking Framework using 4D FMCW Radar","abstract":"Robust perception is a vital component for ensuring safe autonomous and assisted driving. Automotive radar (77 to 81 GHz), which offers weather-resilient sensing, provides a complementary capability to the vision- or LiDAR-based autonomous driving systems. Raw radio-frequency (RF) radar tensors contain rich spatiotemporal semantics besides 3D location information. The majority of previous methods take in 3D (Doppler-range-azimuth) RF radar tensors, allowing prediction of an object's location, heading angle, and size in bird's-eye-view (BEV). However, they lack the ability to at the same time infer objects' size, orientation, and identity in the 3D space. To overcome this limitation, we propose an efficient joint architecture called CenterRadarNet, designed to facilitate high-resolution representation learning from 4D (Doppler-range-azimuth-elevation) radar data for 3D object detection and re-identification (re-ID) tasks. As a single-stage 3D object detector, CenterRadarNet directly infers the BEV object distribution confidence maps, corresponding 3D bounding box attributes, and appearance embedding for each pixel. Moreover, we build an online tracker utilizing the learned appearance embedding for re-ID. CenterRadarNet achieves the state-of-the-art result on the K-Radar 3D object detection benchmark. In addition, we present the first 3D object-tracking result using radar on the K-Radar dataset V2. In diverse driving scenarios, CenterRadarNet shows consistent, robust performance, emphasizing its wide applicability.","sentences":["Robust perception is a vital component for ensuring safe autonomous and assisted driving.","Automotive radar (77 to 81 GHz), which offers weather-resilient sensing, provides a complementary capability to the vision- or LiDAR-based autonomous driving systems.","Raw radio-frequency (RF) radar tensors contain rich spatiotemporal semantics besides 3D location information.","The majority of previous methods take in 3D (Doppler-range-azimuth) RF radar tensors, allowing prediction of an object's location, heading angle, and size in bird's-eye-view (BEV).","However, they lack the ability to at the same time infer objects' size, orientation, and identity in the 3D space.","To overcome this limitation, we propose an efficient joint architecture called CenterRadarNet, designed to facilitate high-resolution representation learning from 4D (Doppler-range-azimuth-elevation) radar data for 3D object detection and re-identification (re-ID) tasks.","As a single-stage 3D object detector, CenterRadarNet directly infers the BEV object distribution confidence maps, corresponding 3D bounding box attributes, and appearance embedding for each pixel.","Moreover, we build an online tracker utilizing the learned appearance embedding for re-ID. CenterRadarNet","achieves the state-of-the-art result on the K-Radar 3D object detection benchmark.","In addition, we present the first 3D object-tracking result using radar on the K-Radar dataset V2.","In diverse driving scenarios, CenterRadarNet shows consistent, robust performance, emphasizing its wide applicability."],"url":"http://arxiv.org/abs/2311.01423v1"}
{"created":"2023-11-02 17:35:16","title":"Holistic Transfer: Towards Non-Disruptive Fine-Tuning with Partial Target Data","abstract":"We propose a learning problem involving adapting a pre-trained source model to the target domain for classifying all classes that appeared in the source data, using target data that covers only a partial label space. This problem is practical, as it is unrealistic for the target end-users to collect data for all classes prior to adaptation. However, it has received limited attention in the literature. To shed light on this issue, we construct benchmark datasets and conduct extensive experiments to uncover the inherent challenges. We found a dilemma -- on the one hand, adapting to the new target domain is important to claim better performance; on the other hand, we observe that preserving the classification accuracy of classes missing in the target adaptation data is highly challenging, let alone improving them. To tackle this, we identify two key directions: 1) disentangling domain gradients from classification gradients, and 2) preserving class relationships. We present several effective solutions that maintain the accuracy of the missing classes and enhance the overall performance, establishing solid baselines for holistic transfer of pre-trained models with partial target data.","sentences":["We propose a learning problem involving adapting a pre-trained source model to the target domain for classifying all classes that appeared in the source data, using target data that covers only a partial label space.","This problem is practical, as it is unrealistic for the target end-users to collect data for all classes prior to adaptation.","However, it has received limited attention in the literature.","To shed light on this issue, we construct benchmark datasets and conduct extensive experiments to uncover the inherent challenges.","We found a dilemma -- on the one hand, adapting to the new target domain is important to claim better performance; on the other hand, we observe that preserving the classification accuracy of classes missing in the target adaptation data is highly challenging, let alone improving them.","To tackle this, we identify two key directions: 1) disentangling domain gradients from classification gradients, and 2) preserving class relationships.","We present several effective solutions that maintain the accuracy of the missing classes and enhance the overall performance, establishing solid baselines for holistic transfer of pre-trained models with partial target data."],"url":"http://arxiv.org/abs/2311.01420v1"}
{"created":"2023-11-02 17:33:47","title":"Constrained-Context Conditional Diffusion Models for Imitation Learning","abstract":"Offline Imitation Learning (IL) is a powerful paradigm to learn visuomotor skills, especially for high-precision manipulation tasks. However, IL methods are prone to spurious correlation - expressive models may focus on distractors that are irrelevant to action prediction - and are thus fragile in real-world deployment. Prior methods have addressed this challenge by exploring different model architectures and action representations. However, none were able to balance between sample efficiency, robustness against distractors, and solving high-precision manipulation tasks with complex action space. To this end, we present $\\textbf{C}$onstrained-$\\textbf{C}$ontext $\\textbf{C}$onditional $\\textbf{D}$iffusion $\\textbf{M}$odel (C3DM), a diffusion model policy for solving 6-DoF robotic manipulation tasks with high precision and ability to ignore distractions. A key component of C3DM is a fixation step that helps the action denoiser to focus on task-relevant regions around the predicted action while ignoring distractors in the context. We empirically show that C3DM is able to consistently achieve high success rate on a wide array of tasks, ranging from table top manipulation to industrial kitting, that require varying levels of precision and robustness to distractors. For details, please visit this https://sites.google.com/view/c3dm-imitation-learning","sentences":["Offline Imitation Learning (IL) is a powerful paradigm to learn visuomotor skills, especially for high-precision manipulation tasks.","However, IL methods are prone to spurious correlation - expressive models may focus on distractors that are irrelevant to action prediction - and are thus fragile in real-world deployment.","Prior methods have addressed this challenge by exploring different model architectures and action representations.","However, none were able to balance between sample efficiency, robustness against distractors, and solving high-precision manipulation tasks with complex action space.","To this end, we present $\\textbf{C}$onstrained-$\\textbf{C}$ontext $\\textbf{C}$onditional $\\textbf{D}$iffusion $\\textbf{M}$odel (C3DM), a diffusion model policy for solving 6-DoF robotic manipulation tasks with high precision and ability to ignore distractions.","A key component of C3DM is a fixation step that helps the action denoiser to focus on task-relevant regions around the predicted action while ignoring distractors in the context.","We empirically show that C3DM is able to consistently achieve high success rate on a wide array of tasks, ranging from table top manipulation to industrial kitting, that require varying levels of precision and robustness to distractors.","For details, please visit this https://sites.google.com/view/c3dm-imitation-learning"],"url":"http://arxiv.org/abs/2311.01419v1"}
{"created":"2023-11-02 17:31:31","title":"MoCheQoS: Automated Analysis of Quality of Service Properties of Communicating Systems","abstract":"We present MoCheQoS, a tool to analyse quality of service (QoS) properties of message-passing systems. Building on the logic and the choreographic model we defined in recently published work, MoCheQoS implements a bounded model checking algorithm. We discuss strengths and weaknesses of MoCheQoS through some case studies.","sentences":["We present MoCheQoS, a tool to analyse quality of service (QoS) properties of message-passing systems.","Building on the logic and the choreographic model we defined in recently published work, MoCheQoS implements a bounded model checking algorithm.","We discuss strengths and weaknesses of MoCheQoS through some case studies."],"url":"http://arxiv.org/abs/2311.01415v1"}
{"created":"2023-11-02 17:30:51","title":"A Dynamic Temporal Logic for Quality of Service in Choreographic Models","abstract":"We propose a framework for expressing and analyzing the Quality of Service (QoS) of message-passing systems using a choreographic model that consists of g-choreographies and Communicating Finite State machines (CFSMs). The following are our three main contributions: (I) an extension of CFSMs with non-functional contracts to specify quantitative constraints of local computations, (II) a dynamic temporal logic capable of expressing QoS, properties of systems relative to the g-choreography that specifies the communication protocol, (III) the semi-decidability of our logic which enables a bounded model-checking approach to verify QoS property of communicating systems.","sentences":["We propose a framework for expressing and analyzing the Quality of Service (QoS) of message-passing systems using a choreographic model that consists of g-choreographies and Communicating Finite State machines (CFSMs).","The following are our three main contributions: (I) an extension of CFSMs with non-functional contracts to specify quantitative constraints of local computations, (II) a dynamic temporal logic capable of expressing QoS, properties of systems relative to the g-choreography that specifies the communication protocol, (III) the semi-decidability of our logic which enables a bounded model-checking approach to verify QoS property of communicating systems."],"url":"http://arxiv.org/abs/2311.01414v1"}
{"created":"2023-11-02 17:26:49","title":"Castor: Causal Temporal Regime Structure Learning","abstract":"The task of uncovering causal relationships among multivariate time series data stands as an essential and challenging objective that cuts across a broad array of disciplines ranging from climate science to healthcare. Such data entails linear or non-linear relationships, and usually follow multiple a priori unknown regimes. Existing causal discovery methods can infer summary causal graphs from heterogeneous data with known regimes, but they fall short in comprehensively learning both regimes and the corresponding causal graph. In this paper, we introduce CASTOR, a novel framework designed to learn causal relationships in heterogeneous time series data composed of various regimes, each governed by a distinct causal graph. Through the maximization of a score function via the EM algorithm, CASTOR infers the number of regimes and learns linear or non-linear causal relationships in each regime. We demonstrate the robust convergence properties of CASTOR, specifically highlighting its proficiency in accurately identifying unique regimes. Empirical evidence, garnered from exhaustive synthetic experiments and two real-world benchmarks, confirm CASTOR's superior performance in causal discovery compared to baseline methods. By learning a full temporal causal graph for each regime, CASTOR establishes itself as a distinctly interpretable method for causal discovery in heterogeneous time series.","sentences":["The task of uncovering causal relationships among multivariate time series data stands as an essential and challenging objective that cuts across a broad array of disciplines ranging from climate science to healthcare.","Such data entails linear or non-linear relationships, and usually follow multiple a priori unknown regimes.","Existing causal discovery methods can infer summary causal graphs from heterogeneous data with known regimes, but they fall short in comprehensively learning both regimes and the corresponding causal graph.","In this paper, we introduce CASTOR, a novel framework designed to learn causal relationships in heterogeneous time series data composed of various regimes, each governed by a distinct causal graph.","Through the maximization of a score function via the EM algorithm, CASTOR infers the number of regimes and learns linear or non-linear causal relationships in each regime.","We demonstrate the robust convergence properties of CASTOR, specifically highlighting its proficiency in accurately identifying unique regimes.","Empirical evidence, garnered from exhaustive synthetic experiments and two real-world benchmarks, confirm CASTOR's superior performance in causal discovery compared to baseline methods.","By learning a full temporal causal graph for each regime, CASTOR establishes itself as a distinctly interpretable method for causal discovery in heterogeneous time series."],"url":"http://arxiv.org/abs/2311.01412v1"}
{"created":"2023-11-02 17:23:14","title":"The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing","abstract":"We present a unified probabilistic formulation for diffusion-based image editing, where a latent variable is edited in a task-specific manner and generally deviates from the corresponding marginal distribution induced by the original stochastic or ordinary differential equation (SDE or ODE). Instead, it defines a corresponding SDE or ODE for editing. In the formulation, we prove that the Kullback-Leibler divergence between the marginal distributions of the two SDEs gradually decreases while that for the ODEs remains as the time approaches zero, which shows the promise of SDE in image editing. Inspired by it, we provide the SDE counterparts for widely used ODE baselines in various tasks including inpainting and image-to-image translation, where SDE shows a consistent and substantial improvement. Moreover, we propose SDE-Drag -- a simple yet effective method built upon the SDE formulation for point-based content dragging. We build a challenging benchmark (termed DragBench) with open-set natural, art, and AI-generated images for evaluation. A user study on DragBench indicates that SDE-Drag significantly outperforms our ODE baseline, existing diffusion-based methods, and the renowned DragGAN. Our results demonstrate the superiority and versatility of SDE in image editing and push the boundary of diffusion-based editing methods.","sentences":["We present a unified probabilistic formulation for diffusion-based image editing, where a latent variable is edited in a task-specific manner and generally deviates from the corresponding marginal distribution induced by the original stochastic or ordinary differential equation (SDE or ODE).","Instead, it defines a corresponding SDE or ODE for editing.","In the formulation, we prove that the Kullback-Leibler divergence between the marginal distributions of the two SDEs gradually decreases while that for the ODEs remains as the time approaches zero, which shows the promise of SDE in image editing.","Inspired by it, we provide the SDE counterparts for widely used ODE baselines in various tasks including inpainting and image-to-image translation, where SDE shows a consistent and substantial improvement.","Moreover, we propose SDE-Drag -- a simple yet effective method built upon the SDE formulation for point-based content dragging.","We build a challenging benchmark (termed DragBench) with open-set natural, art, and AI-generated images for evaluation.","A user study on DragBench indicates that SDE-Drag significantly outperforms our ODE baseline, existing diffusion-based methods, and the renowned DragGAN.","Our results demonstrate the superiority and versatility of SDE in image editing and push the boundary of diffusion-based editing methods."],"url":"http://arxiv.org/abs/2311.01410v1"}
{"created":"2023-11-02 17:22:22","title":"A Coreset-based, Tempered Variational Posterior for Accurate and Scalable Stochastic Gaussian Process Inference","abstract":"We present a novel stochastic variational Gaussian process ($\\mathcal{GP}$) inference method, based on a posterior over a learnable set of weighted pseudo input-output points (coresets). Instead of a free-form variational family, the proposed coreset-based, variational tempered family for $\\mathcal{GP}$s (CVTGP) is defined in terms of the $\\mathcal{GP}$ prior and the data-likelihood; hence, accommodating the modeling inductive biases. We derive CVTGP's lower bound for the log-marginal likelihood via marginalization of the proposed posterior over latent $\\mathcal{GP}$ coreset variables, and show it is amenable to stochastic optimization. CVTGP reduces the learnable parameter size to $\\mathcal{O}(M)$, enjoys numerical stability, and maintains $\\mathcal{O}(M^3)$ time- and $\\mathcal{O}(M^2)$ space-complexity, by leveraging a coreset-based tempered posterior that, in turn, provides sparse and explainable representations of the data. Results on simulated and real-world regression problems with Gaussian observation noise validate that CVTGP provides better evidence lower-bound estimates and predictive root mean squared error than alternative stochastic $\\mathcal{GP}$ inference methods.","sentences":["We present a novel stochastic variational Gaussian process ($\\mathcal{GP}$) inference method, based on a posterior over a learnable set of weighted pseudo input-output points (coresets).","Instead of a free-form variational family, the proposed coreset-based, variational tempered family for $\\mathcal{GP}$s (CVTGP) is defined in terms of the $\\mathcal{GP}$ prior and the data-likelihood; hence, accommodating the modeling inductive biases.","We derive CVTGP's lower bound for the log-marginal likelihood via marginalization of the proposed posterior over latent $\\mathcal{GP}$ coreset variables, and show it is amenable to stochastic optimization.","CVTGP reduces the learnable parameter size to $\\mathcal{O}(M)$, enjoys numerical stability, and maintains $\\mathcal{O}(M^3)$ time- and $\\mathcal{O}(M^2)$ space-complexity, by leveraging a coreset-based tempered posterior that, in turn, provides sparse and explainable representations of the data.","Results on simulated and real-world regression problems with Gaussian observation noise validate that CVTGP provides better evidence lower-bound estimates and predictive root mean squared error than alternative stochastic $\\mathcal{GP}$ inference methods."],"url":"http://arxiv.org/abs/2311.01409v1"}
{"created":"2023-11-02 17:19:45","title":"Analysis of Information Propagation in Ethereum Network Using Combined Graph Attention Network and Reinforcement Learning to Optimize Network Efficiency and Scalability","abstract":"Blockchain technology has revolutionized the way information is propagated in decentralized networks. Ethereum plays a pivotal role in facilitating smart contracts and decentralized applications. Understanding information propagation dynamics in Ethereum is crucial for ensuring network efficiency, security, and scalability. In this study, we propose an innovative approach that utilizes Graph Convolutional Networks (GCNs) to analyze the information propagation patterns in the Ethereum network. The first phase of our research involves data collection from the Ethereum blockchain, consisting of blocks, transactions, and node degrees. We construct a transaction graph representation using adjacency matrices to capture the node embeddings; while our major contribution is to develop a combined Graph Attention Network (GAT) and Reinforcement Learning (RL) model to optimize the network efficiency and scalability. It learns the best actions to take in various network states, ultimately leading to improved network efficiency, throughput, and optimize gas limits for block processing. In the experimental evaluation, we analyze the performance of our model on a large-scale Ethereum dataset. We investigate effectively aggregating information from neighboring nodes capturing graph structure and updating node embeddings using GCN with the objective of transaction pattern prediction, accounting for varying network loads and number of blocks. Not only we design a gas limit optimization model and provide the algorithm, but also to address scalability, we demonstrate the use and implementation of sparse matrices in GraphConv, GraphSAGE, and GAT. The results indicate that our designed GAT-RL model achieves superior results compared to other GCN models in terms of performance. It effectively propagates information across the network, optimizing gas limits for block processing and improving network efficiency.","sentences":["Blockchain technology has revolutionized the way information is propagated in decentralized networks.","Ethereum plays a pivotal role in facilitating smart contracts and decentralized applications.","Understanding information propagation dynamics in Ethereum is crucial for ensuring network efficiency, security, and scalability.","In this study, we propose an innovative approach that utilizes Graph Convolutional Networks (GCNs) to analyze the information propagation patterns in the Ethereum network.","The first phase of our research involves data collection from the Ethereum blockchain, consisting of blocks, transactions, and node degrees.","We construct a transaction graph representation using adjacency matrices to capture the node embeddings; while our major contribution is to develop a combined Graph Attention Network (GAT) and Reinforcement Learning (RL) model to optimize the network efficiency and scalability.","It learns the best actions to take in various network states, ultimately leading to improved network efficiency, throughput, and optimize gas limits for block processing.","In the experimental evaluation, we analyze the performance of our model on a large-scale Ethereum dataset.","We investigate effectively aggregating information from neighboring nodes capturing graph structure and updating node embeddings using GCN with the objective of transaction pattern prediction, accounting for varying network loads and number of blocks.","Not only we design a gas limit optimization model and provide the algorithm, but also to address scalability, we demonstrate the use and implementation of sparse matrices in GraphConv, GraphSAGE, and GAT.","The results indicate that our designed GAT-RL model achieves superior results compared to other GCN models in terms of performance.","It effectively propagates information across the network, optimizing gas limits for block processing and improving network efficiency."],"url":"http://arxiv.org/abs/2311.01406v1"}
{"created":"2023-11-02 17:19:18","title":"Learning to See Physical Properties with Active Sensing Motor Policies","abstract":"Knowledge of terrain's physical properties inferred from color images can aid in making efficient robotic locomotion plans. However, unlike image classification, it is unintuitive for humans to label image patches with physical properties. Without labeled data, building a vision system that takes as input the observed terrain and predicts physical properties remains challenging. We present a method that overcomes this challenge by self-supervised labeling of images captured by robots during real-world traversal with physical property estimators trained in simulation. To ensure accurate labeling, we introduce Active Sensing Motor Policies (ASMP), which are trained to explore locomotion behaviors that increase the accuracy of estimating physical parameters. For instance, the quadruped robot learns to swipe its foot against the ground to estimate the friction coefficient accurately. We show that the visual system trained with a small amount of real-world traversal data accurately predicts physical parameters. The trained system is robust and works even with overhead images captured by a drone despite being trained on data collected by cameras attached to a quadruped robot walking on the ground.","sentences":["Knowledge of terrain's physical properties inferred from color images can aid in making efficient robotic locomotion plans.","However, unlike image classification, it is unintuitive for humans to label image patches with physical properties.","Without labeled data, building a vision system that takes as input the observed terrain and predicts physical properties remains challenging.","We present a method that overcomes this challenge by self-supervised labeling of images captured by robots during real-world traversal with physical property estimators trained in simulation.","To ensure accurate labeling, we introduce Active Sensing Motor Policies (ASMP), which are trained to explore locomotion behaviors that increase the accuracy of estimating physical parameters.","For instance, the quadruped robot learns to swipe its foot against the ground to estimate the friction coefficient accurately.","We show that the visual system trained with a small amount of real-world traversal data accurately predicts physical parameters.","The trained system is robust and works even with overhead images captured by a drone despite being trained on data collected by cameras attached to a quadruped robot walking on the ground."],"url":"http://arxiv.org/abs/2311.01405v1"}
{"created":"2023-11-02 17:16:21","title":"REAL: Resilience and Adaptation using Large Language Models on Autonomous Aerial Robots","abstract":"Large Language Models (LLMs) pre-trained on internet-scale datasets have shown impressive capabilities in code understanding, synthesis, and general purpose question-and-answering. Key to their performance is the substantial prior knowledge acquired during training and their ability to reason over extended sequences of symbols, often presented in natural language. In this work, we aim to harness the extensive long-term reasoning, natural language comprehension, and the available prior knowledge of LLMs for increased resilience and adaptation in autonomous mobile robots. We introduce REAL, an approach for REsilience and Adaptation using LLMs. REAL provides a strategy to employ LLMs as a part of the mission planning and control framework of an autonomous robot. The LLM employed by REAL provides (i) a source of prior knowledge to increase resilience for challenging scenarios that the system had not been explicitly designed for; (ii) a way to interpret natural-language and other log/diagnostic information available in the autonomy stack, for mission planning; (iii) a way to adapt the control inputs using minimal user-provided prior knowledge about the dynamics/kinematics of the robot. We integrate REAL in the autonomy stack of a real multirotor, querying onboard an offboard LLM at 0.1-1.0 Hz as part the robot's mission planning and control feedback loops. We demonstrate in real-world experiments the ability of the LLM to reduce the position tracking errors of a multirotor under the presence of (i) errors in the parameters of the controller and (ii) unmodeled dynamics. We also show (iii) decision making to avoid potentially dangerous scenarios (e.g., robot oscillates) that had not been explicitly accounted for in the initial prompt design.","sentences":["Large Language Models (LLMs) pre-trained on internet-scale datasets have shown impressive capabilities in code understanding, synthesis, and general purpose question-and-answering.","Key to their performance is the substantial prior knowledge acquired during training and their ability to reason over extended sequences of symbols, often presented in natural language.","In this work, we aim to harness the extensive long-term reasoning, natural language comprehension, and the available prior knowledge of LLMs for increased resilience and adaptation in autonomous mobile robots.","We introduce REAL, an approach for REsilience and Adaptation using LLMs.","REAL provides a strategy to employ LLMs as a part of the mission planning and control framework of an autonomous robot.","The LLM employed by REAL provides (i) a source of prior knowledge to increase resilience for challenging scenarios that the system had not been explicitly designed for; (ii) a way to interpret natural-language and other log/diagnostic information available in the autonomy stack, for mission planning; (iii) a way to adapt the control inputs using minimal user-provided prior knowledge about the dynamics/kinematics of the robot.","We integrate REAL in the autonomy stack of a real multirotor, querying onboard an offboard LLM at 0.1-1.0 Hz as part the robot's mission planning and control feedback loops.","We demonstrate in real-world experiments the ability of the LLM to reduce the position tracking errors of a multirotor under the presence of (i) errors in the parameters of the controller and (ii) unmodeled dynamics.","We also show (iii) decision making to avoid potentially dangerous scenarios (e.g., robot oscillates) that had not been explicitly accounted for in the initial prompt design."],"url":"http://arxiv.org/abs/2311.01403v1"}
{"created":"2023-11-02 17:07:23","title":"Server-side Rescoring of Spoken Entity-centric Knowledge Queries for Virtual Assistants","abstract":"On-device Virtual Assistants (VAs) powered by Automatic Speech Recognition (ASR) require effective knowledge integration for the challenging entity-rich query recognition. In this paper, we conduct an empirical study of modeling strategies for server-side rescoring of spoken information domain queries using various categories of Language Models (LMs) (N-gram word LMs, sub-word neural LMs). We investigate the combination of on-device and server-side signals, and demonstrate significant WER improvements of 23%-35% on various entity-centric query subpopulations by integrating various server-side LMs compared to performing ASR on-device only. We also perform a comparison between LMs trained on domain data and a GPT-3 variant offered by OpenAI as a baseline. Furthermore, we also show that model fusion of multiple server-side LMs trained from scratch most effectively combines complementary strengths of each model and integrates knowledge learned from domain-specific data to a VA ASR system.","sentences":["On-device Virtual Assistants (VAs) powered by Automatic Speech Recognition (ASR) require effective knowledge integration for the challenging entity-rich query recognition.","In this paper, we conduct an empirical study of modeling strategies for server-side rescoring of spoken information domain queries using various categories of Language Models (LMs) (N-gram word LMs, sub-word neural LMs).","We investigate the combination of on-device and server-side signals, and demonstrate significant WER improvements of 23%-35% on various entity-centric query subpopulations by integrating various server-side LMs compared to performing ASR on-device only.","We also perform a comparison between LMs trained on domain data and a GPT-3 variant offered by OpenAI as a baseline.","Furthermore, we also show that model fusion of multiple server-side LMs trained from scratch most effectively combines complementary strengths of each model and integrates knowledge learned from domain-specific data to a VA ASR system."],"url":"http://arxiv.org/abs/2311.01398v1"}
{"created":"2023-11-02 16:55:23","title":"Learning Realistic Traffic Agents in Closed-loop","abstract":"Realistic traffic simulation is crucial for developing self-driving software in a safe and scalable manner prior to real-world deployment. Typically, imitation learning (IL) is used to learn human-like traffic agents directly from real-world observations collected offline, but without explicit specification of traffic rules, agents trained from IL alone frequently display unrealistic infractions like collisions and driving off the road. This problem is exacerbated in out-of-distribution and long-tail scenarios. On the other hand, reinforcement learning (RL) can train traffic agents to avoid infractions, but using RL alone results in unhuman-like driving behaviors. We propose Reinforcing Traffic Rules (RTR), a holistic closed-loop learning objective to match expert demonstrations under a traffic compliance constraint, which naturally gives rise to a joint IL + RL approach, obtaining the best of both worlds. Our method learns in closed-loop simulations of both nominal scenarios from real-world datasets as well as procedurally generated long-tail scenarios. Our experiments show that RTR learns more realistic and generalizable traffic simulation policies, achieving significantly better tradeoffs between human-like driving and traffic compliance in both nominal and long-tail scenarios. Moreover, when used as a data generation tool for training prediction models, our learned traffic policy leads to considerably improved downstream prediction metrics compared to baseline traffic agents. For more information, visit the project website: https://waabi.ai/rtr","sentences":["Realistic traffic simulation is crucial for developing self-driving software in a safe and scalable manner prior to real-world deployment.","Typically, imitation learning (IL) is used to learn human-like traffic agents directly from real-world observations collected offline, but without explicit specification of traffic rules, agents trained from IL alone frequently display unrealistic infractions like collisions and driving off the road.","This problem is exacerbated in out-of-distribution and long-tail scenarios.","On the other hand, reinforcement learning (RL) can train traffic agents to avoid infractions, but using RL alone results in unhuman-like driving behaviors.","We propose Reinforcing Traffic Rules (RTR), a holistic closed-loop learning objective to match expert demonstrations under a traffic compliance constraint, which naturally gives rise to a joint IL + RL approach, obtaining the best of both worlds.","Our method learns in closed-loop simulations of both nominal scenarios from real-world datasets as well as procedurally generated long-tail scenarios.","Our experiments show that RTR learns more realistic and generalizable traffic simulation policies, achieving significantly better tradeoffs between human-like driving and traffic compliance in both nominal and long-tail scenarios.","Moreover, when used as a data generation tool for training prediction models, our learned traffic policy leads to considerably improved downstream prediction metrics compared to baseline traffic agents.","For more information, visit the project website: https://waabi.ai/rtr"],"url":"http://arxiv.org/abs/2311.01394v1"}
{"created":"2023-11-02 16:44:24","title":"Can Language Models Be Tricked by Language Illusions? Easier with Syntax, Harder with Semantics","abstract":"Language models (LMs) have been argued to overlap substantially with human beings in grammaticality judgment tasks. But when humans systematically make errors in language processing, should we expect LMs to behave like cognitive models of language and mimic human behavior? We answer this question by investigating LMs' more subtle judgments associated with \"language illusions\" -- sentences that are vague in meaning, implausible, or ungrammatical but receive unexpectedly high acceptability judgments by humans. We looked at three illusions: the comparative illusion (e.g. \"More people have been to Russia than I have\"), the depth-charge illusion (e.g. \"No head injury is too trivial to be ignored\"), and the negative polarity item (NPI) illusion (e.g. \"The hunter who no villager believed to be trustworthy will ever shoot a bear\"). We found that probabilities represented by LMs were more likely to align with human judgments of being \"tricked\" by the NPI illusion which examines a structural dependency, compared to the comparative and the depth-charge illusions which require sophisticated semantic understanding. No single LM or metric yielded results that are entirely consistent with human behavior. Ultimately, we show that LMs are limited both in their construal as cognitive models of human language processing and in their capacity to recognize nuanced but critical information in complicated language materials.","sentences":["Language models (LMs) have been argued to overlap substantially with human beings in grammaticality judgment tasks.","But when humans systematically make errors in language processing, should we expect LMs to behave like cognitive models of language and mimic human behavior?","We answer this question by investigating LMs' more subtle judgments associated with \"language illusions\" -- sentences that are vague in meaning, implausible, or ungrammatical but receive unexpectedly high acceptability judgments by humans.","We looked at three illusions: the comparative illusion (e.g. \"More people have been to Russia than I have\"), the depth-charge illusion (e.g. \"No head injury is too trivial to be ignored\"), and the negative polarity item (NPI) illusion (e.g. \"The hunter who no villager believed to be trustworthy will ever shoot a bear\").","We found that probabilities represented by LMs were more likely to align with human judgments of being \"tricked\" by the NPI illusion which examines a structural dependency, compared to the comparative and the depth-charge illusions which require sophisticated semantic understanding.","No single LM or metric yielded results that are entirely consistent with human behavior.","Ultimately, we show that LMs are limited both in their construal as cognitive models of human language processing and in their capacity to recognize nuanced but critical information in complicated language materials."],"url":"http://arxiv.org/abs/2311.01386v1"}
{"created":"2023-11-02 16:37:27","title":"Sim2Real Bilevel Adaptation for Object Surface Classification using Vision-Based Tactile Sensors","abstract":"In this paper, we address the Sim2Real gap in the field of vision-based tactile sensors for classifying object surfaces. We train a Diffusion Model to bridge this gap using a relatively small dataset of real-world images randomly collected from unlabeled everyday objects via the DIGIT sensor. Subsequently, we employ a simulator to generate images by uniformly sampling the surface of objects from the YCB Model Set. These simulated images are then translated into the real domain using the Diffusion Model and automatically labeled to train a classifier. During this training, we further align features of the two domains using an adversarial procedure. Our evaluation is conducted on a dataset of tactile images obtained from a set of ten 3D printed YCB objects. The results reveal a total accuracy of 81.9%, a significant improvement compared to the 34.7% achieved by the classifier trained solely on simulated images. This demonstrates the effectiveness of our approach. We further validate our approach using the classifier on a 6D object pose estimation task from tactile data.","sentences":["In this paper, we address the Sim2Real gap in the field of vision-based tactile sensors for classifying object surfaces.","We train a Diffusion Model to bridge this gap using a relatively small dataset of real-world images randomly collected from unlabeled everyday objects via the DIGIT sensor.","Subsequently, we employ a simulator to generate images by uniformly sampling the surface of objects from the YCB Model Set.","These simulated images are then translated into the real domain using the Diffusion Model and automatically labeled to train a classifier.","During this training, we further align features of the two domains using an adversarial procedure.","Our evaluation is conducted on a dataset of tactile images obtained from a set of ten 3D printed YCB objects.","The results reveal a total accuracy of 81.9%, a significant improvement compared to the 34.7% achieved by the classifier trained solely on simulated images.","This demonstrates the effectiveness of our approach.","We further validate our approach using the classifier on a 6D object pose estimation task from tactile data."],"url":"http://arxiv.org/abs/2311.01380v1"}
{"created":"2023-11-02 16:36:40","title":"Collaborative Decision-Making and the k-Strong Price of Anarchy in Common Interest Games","abstract":"The control of large-scale, multi-agent systems often entails distributing decision-making across the system components. However, with advances in communication and computation technologies, we can consider new collaborative decision-making paradigms that exist somewhere between centralized and distributed control. In this work, we seek to understand the benefits and costs of increased collaborative communication in multi-agent systems. We specifically study this in the context of common interest games in which groups of up to k agents can coordinate their actions in maximizing the common objective function. The equilibria that emerge in these systems are the k-strong Nash equilibria of the common interest game; studying the properties of these states can provide relevant insights into the efficacy of inter-agent collaboration. Our contributions come threefold: 1) provide bounds on how well k-strong Nash equilibria approximate the optimal system welfare, formalized by the k-strong price of anarchy, 2) study the run-time and transient performance of collaborative agent-based dynamics, and 3) consider the task of redesigning objectives for groups of agents which improve system performance. We study these three facets generally as well as in the context of resource allocation problems, in which we provide tractable linear programs that give tight bounds on the k-strong price of anarchy.","sentences":["The control of large-scale, multi-agent systems often entails distributing decision-making across the system components.","However, with advances in communication and computation technologies, we can consider new collaborative decision-making paradigms that exist somewhere between centralized and distributed control.","In this work, we seek to understand the benefits and costs of increased collaborative communication in multi-agent systems.","We specifically study this in the context of common interest games in which groups of up to k agents can coordinate their actions in maximizing the common objective function.","The equilibria that emerge in these systems are the k-strong Nash equilibria of the common interest game; studying the properties of these states can provide relevant insights into the efficacy of inter-agent collaboration.","Our contributions come threefold: 1) provide bounds on how well k-strong Nash equilibria approximate the optimal system welfare, formalized by the k-strong price of anarchy, 2) study the run-time and transient performance of collaborative agent-based dynamics, and 3) consider the task of redesigning objectives for groups of agents which improve system performance.","We study these three facets generally as well as in the context of resource allocation problems, in which we provide tractable linear programs that give tight bounds on the k-strong price of anarchy."],"url":"http://arxiv.org/abs/2311.01379v1"}
{"created":"2023-11-02 16:34:33","title":"Vision-Language Foundation Models as Effective Robot Imitators","abstract":"Recent progress in vision language foundation models has shown their ability to understand multimodal data and resolve complicated vision language tasks, including robotics manipulation. We seek a straightforward way of making use of existing vision-language models (VLMs) with simple fine-tuning on robotics data. To this end, we derive a simple and novel vision-language manipulation framework, dubbed RoboFlamingo, built upon the open-source VLMs, OpenFlamingo. Unlike prior works, RoboFlamingo utilizes pre-trained VLMs for single-step vision-language comprehension, models sequential history information with an explicit policy head, and is slightly fine-tuned by imitation learning only on language-conditioned manipulation datasets. Such a decomposition provides RoboFlamingo the flexibility for open-loop control and deployment on low-performance platforms. By exceeding the state-of-the-art performance with a large margin on the tested benchmark, we show RoboFlamingo can be an effective and competitive alternative to adapt VLMs to robot control. Our extensive experimental results also reveal several interesting conclusions regarding the behavior of different pre-trained VLMs on manipulation tasks. We believe RoboFlamingo has the potential to be a cost-effective and easy-to-use solution for robotics manipulation, empowering everyone with the ability to fine-tune their own robotics policy.","sentences":["Recent progress in vision language foundation models has shown their ability to understand multimodal data and resolve complicated vision language tasks, including robotics manipulation.","We seek a straightforward way of making use of existing vision-language models (VLMs) with simple fine-tuning on robotics data.","To this end, we derive a simple and novel vision-language manipulation framework, dubbed RoboFlamingo, built upon the open-source VLMs, OpenFlamingo.","Unlike prior works, RoboFlamingo utilizes pre-trained VLMs for single-step vision-language comprehension, models sequential history information with an explicit policy head, and is slightly fine-tuned by imitation learning only on language-conditioned manipulation datasets.","Such a decomposition provides RoboFlamingo the flexibility for open-loop control and deployment on low-performance platforms.","By exceeding the state-of-the-art performance with a large margin on the tested benchmark, we show RoboFlamingo can be an effective and competitive alternative to adapt VLMs to robot control.","Our extensive experimental results also reveal several interesting conclusions regarding the behavior of different pre-trained VLMs on manipulation tasks.","We believe RoboFlamingo has the potential to be a cost-effective and easy-to-use solution for robotics manipulation, empowering everyone with the ability to fine-tune their own robotics policy."],"url":"http://arxiv.org/abs/2311.01378v1"}
{"created":"2023-11-02 16:33:35","title":"Monotone Generative Modeling via a Gromov-Monge Embedding","abstract":"Generative Adversarial Networks (GANs) are powerful tools for creating new content, but they face challenges such as sensitivity to starting conditions and mode collapse. To address these issues, we propose a deep generative model that utilizes the Gromov-Monge embedding (GME). It helps identify the low-dimensional structure of the underlying measure of the data and then maps it, while preserving its geometry, into a measure in a low-dimensional latent space, which is then optimally transported to the reference measure. We guarantee the preservation of the underlying geometry by the GME and $c$-cyclical monotonicity of the generative map, where $c$ is an intrinsic embedding cost employed by the GME. The latter property is a first step in guaranteeing better robustness to initialization of parameters and mode collapse. Numerical experiments demonstrate the effectiveness of our approach in generating high-quality images, avoiding mode collapse, and exhibiting robustness to different starting conditions.","sentences":["Generative Adversarial Networks (GANs) are powerful tools for creating new content, but they face challenges such as sensitivity to starting conditions and mode collapse.","To address these issues, we propose a deep generative model that utilizes the Gromov-Monge embedding (GME).","It helps identify the low-dimensional structure of the underlying measure of the data and then maps it, while preserving its geometry, into a measure in a low-dimensional latent space, which is then optimally transported to the reference measure.","We guarantee the preservation of the underlying geometry by the GME and $c$-cyclical monotonicity of the generative map, where $c$ is an intrinsic embedding cost employed by the GME.","The latter property is a first step in guaranteeing better robustness to initialization of parameters and mode collapse.","Numerical experiments demonstrate the effectiveness of our approach in generating high-quality images, avoiding mode collapse, and exhibiting robustness to different starting conditions."],"url":"http://arxiv.org/abs/2311.01375v1"}
{"created":"2023-11-02 16:31:49","title":"Recognize Any Regions","abstract":"Understanding the semantics of individual regions or patches within unconstrained images, such as in open-world object detection, represents a critical yet challenging task in computer vision. Building on the success of powerful image-level vision-language (ViL) foundation models like CLIP, recent efforts have sought to harness their capabilities by either training a contrastive model from scratch with an extensive collection of region-label pairs or aligning the outputs of a detection model with image-level representations of region proposals. Despite notable progress, these approaches are plagued by computationally intensive training requirements, susceptibility to data noise, and deficiency in contextual information. To address these limitations, we explore the synergistic potential of off-the-shelf foundation models, leveraging their respective strengths in localization and semantics. We introduce a novel, generic, and efficient region recognition architecture, named RegionSpot, designed to integrate position-aware localization knowledge from a localization foundation model (e.g., SAM) with semantic information extracted from a ViL model (e.g., CLIP). To fully exploit pretrained knowledge while minimizing training overhead, we keep both foundation models frozen, focusing optimization efforts solely on a lightweight attention-based knowledge integration module. Through extensive experiments in the context of open-world object recognition, our RegionSpot demonstrates significant performance improvements over prior alternatives, while also providing substantial computational savings. For instance, training our model with 3 million data in a single day using 8 V100 GPUs. Our model outperforms GLIP by 6.5 % in mean average precision (mAP), with an even larger margin by 14.8 % for more challenging and rare categories.","sentences":["Understanding the semantics of individual regions or patches within unconstrained images, such as in open-world object detection, represents a critical yet challenging task in computer vision.","Building on the success of powerful image-level vision-language (ViL) foundation models like CLIP, recent efforts have sought to harness their capabilities by either training a contrastive model from scratch with an extensive collection of region-label pairs or aligning the outputs of a detection model with image-level representations of region proposals.","Despite notable progress, these approaches are plagued by computationally intensive training requirements, susceptibility to data noise, and deficiency in contextual information.","To address these limitations, we explore the synergistic potential of off-the-shelf foundation models, leveraging their respective strengths in localization and semantics.","We introduce a novel, generic, and efficient region recognition architecture, named RegionSpot, designed to integrate position-aware localization knowledge from a localization foundation model (e.g., SAM) with semantic information extracted from a ViL model (e.g., CLIP).","To fully exploit pretrained knowledge while minimizing training overhead, we keep both foundation models frozen, focusing optimization efforts solely on a lightweight attention-based knowledge integration module.","Through extensive experiments in the context of open-world object recognition, our RegionSpot demonstrates significant performance improvements over prior alternatives, while also providing substantial computational savings.","For instance, training our model with 3 million data in a single day using 8 V100 GPUs.","Our model outperforms GLIP by 6.5 % in mean average precision (mAP), with an even larger margin by 14.8 % for more challenging and rare categories."],"url":"http://arxiv.org/abs/2311.01373v1"}
{"created":"2023-11-02 16:29:49","title":"Data-Augmented and Retrieval-Augmented Context Enrichment in Chinese Media Bias Detection","abstract":"With the increasing pursuit of objective reports, automatically understanding media bias has drawn more attention in recent research. However, most of the previous work examines media bias from Western ideology, such as the left and right in the political spectrum, which is not applicable to Chinese outlets. Based on the previous lexical bias and informational bias structure, we refine it from the Chinese perspective and go one step further to craft data with 7 fine-grained labels. To be specific, we first construct a dataset with Chinese news reports about COVID-19 which is annotated by our newly designed system, and then conduct substantial experiments on it to detect media bias. However, the scale of the annotated data is not enough for the latest deep-learning technology, and the cost of human annotation in media bias, which needs a lot of professional knowledge, is too expensive. Thus, we explore some context enrichment methods to automatically improve these problems. In Data-Augmented Context Enrichment (DACE), we enlarge the training data; while in Retrieval-Augmented Context Enrichment (RACE), we improve information retrieval methods to select valuable information and integrate it into our models to better understand bias. Extensive experiments are conducted on both our dataset and an English dataset BASIL. Our results show that both methods outperform our baselines, while the RACE methods are more efficient and have more potential.","sentences":["With the increasing pursuit of objective reports, automatically understanding media bias has drawn more attention in recent research.","However, most of the previous work examines media bias from Western ideology, such as the left and right in the political spectrum, which is not applicable to Chinese outlets.","Based on the previous lexical bias and informational bias structure, we refine it from the Chinese perspective and go one step further to craft data with 7 fine-grained labels.","To be specific, we first construct a dataset with Chinese news reports about COVID-19 which is annotated by our newly designed system, and then conduct substantial experiments on it to detect media bias.","However, the scale of the annotated data is not enough for the latest deep-learning technology, and the cost of human annotation in media bias, which needs a lot of professional knowledge, is too expensive.","Thus, we explore some context enrichment methods to automatically improve these problems.","In Data-Augmented Context Enrichment (DACE), we enlarge the training data; while in Retrieval-Augmented Context Enrichment (RACE), we improve information retrieval methods to select valuable information and integrate it into our models to better understand bias.","Extensive experiments are conducted on both our dataset and an English dataset BASIL.","Our results show that both methods outperform our baselines, while the RACE methods are more efficient and have more potential."],"url":"http://arxiv.org/abs/2311.01372v1"}
{"created":"2023-11-02 16:11:09","title":"GPT-4V(ision) as a Generalist Evaluator for Vision-Language Tasks","abstract":"Automatically evaluating vision-language tasks is challenging, especially when it comes to reflecting human judgments due to limitations in accounting for fine-grained details. Although GPT-4V has shown promising results in various multi-modal tasks, leveraging GPT-4V as a generalist evaluator for these tasks has not yet been systematically explored. We comprehensively validate GPT-4V's capabilities for evaluation purposes, addressing tasks ranging from foundational image-to-text and text-to-image synthesis to high-level image-to-image translations and multi-images to text alignment. We employ two evaluation methods, single-answer grading and pairwise comparison, using GPT-4V. Notably, GPT-4V shows promising agreement with humans across various tasks and evaluation methods, demonstrating immense potential for multi-modal LLMs as evaluators. Despite limitations like restricted visual clarity grading and real-world complex reasoning, its ability to provide human-aligned scores enriched with detailed explanations is promising for universal automatic evaluator.","sentences":["Automatically evaluating vision-language tasks is challenging, especially when it comes to reflecting human judgments due to limitations in accounting for fine-grained details.","Although GPT-4V has shown promising results in various multi-modal tasks, leveraging GPT-4V as a generalist evaluator for these tasks has not yet been systematically explored.","We comprehensively validate GPT-4V's capabilities for evaluation purposes, addressing tasks ranging from foundational image-to-text and text-to-image synthesis to high-level image-to-image translations and multi-images to text alignment.","We employ two evaluation methods, single-answer grading and pairwise comparison, using GPT-4V. Notably, GPT-4V shows promising agreement with humans across various tasks and evaluation methods, demonstrating immense potential for multi-modal LLMs as evaluators.","Despite limitations like restricted visual clarity grading and real-world complex reasoning, its ability to provide human-aligned scores enriched with detailed explanations is promising for universal automatic evaluator."],"url":"http://arxiv.org/abs/2311.01361v1"}
{"created":"2023-11-02 16:04:32","title":"Robust Identity Perceptual Watermark Against Deepfake Face Swapping","abstract":"Notwithstanding offering convenience and entertainment to society, Deepfake face swapping has caused critical privacy issues with the rapid development of deep generative models. Due to imperceptible artifacts in high-quality synthetic images, passive detection models against face swapping in recent years usually suffer performance damping regarding the generalizability issue. Therefore, several studies have been attempted to proactively protect the original images against malicious manipulations by inserting invisible signals in advance. However, the existing proactive defense approaches demonstrate unsatisfactory results with respect to visual quality, detection accuracy, and source tracing ability. In this study, we propose the first robust identity perceptual watermarking framework that concurrently performs detection and source tracing against Deepfake face swapping proactively. We assign identity semantics regarding the image contents to the watermarks and devise an unpredictable and unreversible chaotic encryption system to ensure watermark confidentiality. The watermarks are encoded and recovered by jointly training an encoder-decoder framework along with adversarial image manipulations. Extensive experiments demonstrate state-of-the-art performance against Deepfake face swapping under both cross-dataset and cross-manipulation settings.","sentences":["Notwithstanding offering convenience and entertainment to society, Deepfake face swapping has caused critical privacy issues with the rapid development of deep generative models.","Due to imperceptible artifacts in high-quality synthetic images, passive detection models against face swapping in recent years usually suffer performance damping regarding the generalizability issue.","Therefore, several studies have been attempted to proactively protect the original images against malicious manipulations by inserting invisible signals in advance.","However, the existing proactive defense approaches demonstrate unsatisfactory results with respect to visual quality, detection accuracy, and source tracing ability.","In this study, we propose the first robust identity perceptual watermarking framework that concurrently performs detection and source tracing against Deepfake face swapping proactively.","We assign identity semantics regarding the image contents to the watermarks and devise an unpredictable and unreversible chaotic encryption system to ensure watermark confidentiality.","The watermarks are encoded and recovered by jointly training an encoder-decoder framework along with adversarial image manipulations.","Extensive experiments demonstrate state-of-the-art performance against Deepfake face swapping under both cross-dataset and cross-manipulation settings."],"url":"http://arxiv.org/abs/2311.01357v1"}
{"created":"2023-11-02 16:01:31","title":"Collective Tree Exploration via Potential Function Method","abstract":"We study the problem of collective tree exploration (CTE) where a team of $k$ agents is tasked to traverse all the edges of an unknown tree as fast as possible, assuming complete communication between the agents. In this paper, we present an algorithm performing collective tree exploration in only $2n/k+O(kD)$ rounds, where $n$ is the number of nodes in the tree, and $D$ is the tree depth. This leads to a competitive ratio of $O(\\sqrt{k})$ for collective tree exploration, the first polynomial improvement over the initial $O(k/\\log(k))$ ratio of [FGKP06]. Our analysis relies on a game with robots at the leaves of a continuously growing tree, which is presented in a similar manner as the `evolving tree game' of [BCR22], though its analysis and applications differ significantly. This game extends the `tree-mining game' (TM) of [Cos23] and leads to guarantees for an asynchronous extension of collective tree exploration (ACTE). Another surprising consequence of our results is the existence of algorithms $\\{A_k\\}_{k\\in \\mathbb{N}}$ for layered tree traversal (LTT) with cost at most $2L/k+O(kD)$, where $L$ is the sum of edge lengths and $D$ is the tree depth. For the case of layered trees of width $w$ and unit edge lengths, our guarantee is thus in $O(\\sqrt{w}D)$.","sentences":["We study the problem of collective tree exploration (CTE) where a team of $k$ agents is tasked to traverse all the edges of an unknown tree as fast as possible, assuming complete communication between the agents.","In this paper, we present an algorithm performing collective tree exploration in only $2n/k+O(kD)$ rounds, where $n$ is the number of nodes in the tree, and $D$ is the tree depth.","This leads to a competitive ratio of $O(\\sqrt{k})$ for collective tree exploration, the first polynomial improvement over the initial $O(k/\\log(k))$ ratio of [FGKP06].","Our analysis relies on a game with robots at the leaves of a continuously growing tree, which is presented in a similar manner as the `evolving tree game' of [BCR22], though its analysis and applications differ significantly.","This game extends the `tree-mining game' (TM) of [Cos23] and leads to guarantees for an asynchronous extension of collective tree exploration (ACTE).","Another surprising consequence of our results is the existence of algorithms $\\{A_k\\}_{k\\in \\mathbb{N}}$ for layered tree traversal (LTT) with cost at most $2L/k+O(kD)$, where $L$ is the sum of edge lengths and $D$ is the tree depth.","For the case of layered trees of width $w$ and unit edge lengths, our guarantee is thus in $O(\\sqrt{w}D)$."],"url":"http://arxiv.org/abs/2311.01354v1"}
{"created":"2023-11-02 16:00:28","title":"Simplicial Models for the Epistemic Logic of Faulty Agents","abstract":"In recent years, several authors have been investigating simplicial models, a model of epistemic logic based on higher-dimensional structures called simplicial complexes. In the original formulation, simplicial models were always assumed to be pure, meaning that all worlds have the same dimension. This is equivalent to the standard S5n semantics of epistemic logic, based on Kripke models. By removing the assumption that models must be pure, we can go beyond the usual Kripke semantics and study epistemic logics where the number of agents participating in a world can vary. This approach has been developed in a number of papers, with applications in fault-tolerant distributed computing where processes may crash during the execution of a system. A difficulty that arises is that subtle design choices in the definition of impure simplicial models can result in different axioms of the resulting logic. In this paper, we classify those design choices systematically, and axiomatize the corresponding logics. We illustrate them via distributed computing examples of synchronous systems where processes may crash.","sentences":["In recent years, several authors have been investigating simplicial models, a model of epistemic logic based on higher-dimensional structures called simplicial complexes.","In the original formulation, simplicial models were always assumed to be pure, meaning that all worlds have the same dimension.","This is equivalent to the standard S5n semantics of epistemic logic, based on Kripke models.","By removing the assumption that models must be pure, we can go beyond the usual Kripke semantics and study epistemic logics where the number of agents participating in a world can vary.","This approach has been developed in a number of papers, with applications in fault-tolerant distributed computing where processes may crash during the execution of a system.","A difficulty that arises is that subtle design choices in the definition of impure simplicial models can result in different axioms of the resulting logic.","In this paper, we classify those design choices systematically, and axiomatize the corresponding logics.","We illustrate them via distributed computing examples of synchronous systems where processes may crash."],"url":"http://arxiv.org/abs/2311.01351v1"}
{"created":"2023-11-02 15:59:00","title":"Unreading Race: Purging Protected Features from Chest X-ray Embeddings","abstract":"Purpose: To analyze and remove protected feature effects in chest radiograph embeddings of deep learning models.   Materials and Methods: An orthogonalization is utilized to remove the influence of protected features (e.g., age, sex, race) in chest radiograph embeddings, ensuring feature-independent results. To validate the efficacy of the approach, we retrospectively study the MIMIC and CheXpert datasets using three pre-trained models, namely a supervised contrastive, a self-supervised contrastive, and a baseline classifier model. Our statistical analysis involves comparing the original versus the orthogonalized embeddings by estimating protected feature influences and evaluating the ability to predict race, age, or sex using the two types of embeddings.   Results: Our experiments reveal a significant influence of protected features on predictions of pathologies. Applying orthogonalization removes these feature effects. Apart from removing any influence on pathology classification, while maintaining competitive predictive performance, orthogonalized embeddings further make it infeasible to directly predict protected attributes and mitigate subgroup disparities.   Conclusion: The presented work demonstrates the successful application and evaluation of the orthogonalization technique in the domain of chest X-ray classification.","sentences":["Purpose: To analyze and remove protected feature effects in chest radiograph embeddings of deep learning models.   ","Materials and Methods: An orthogonalization is utilized to remove the influence of protected features (e.g., age, sex, race) in chest radiograph embeddings, ensuring feature-independent results.","To validate the efficacy of the approach, we retrospectively study the MIMIC and CheXpert datasets using three pre-trained models, namely a supervised contrastive, a self-supervised contrastive, and a baseline classifier model.","Our statistical analysis involves comparing the original versus the orthogonalized embeddings by estimating protected feature influences and evaluating the ability to predict race, age, or sex using the two types of embeddings.   ","Results:","Our experiments reveal a significant influence of protected features on predictions of pathologies.","Applying orthogonalization removes these feature effects.","Apart from removing any influence on pathology classification, while maintaining competitive predictive performance, orthogonalized embeddings further make it infeasible to directly predict protected attributes and mitigate subgroup disparities.   ","Conclusion: The presented work demonstrates the successful application and evaluation of the orthogonalization technique in the domain of chest X-ray classification."],"url":"http://arxiv.org/abs/2311.01349v1"}
{"created":"2023-11-02 15:55:20","title":"Like an Open Book? Read Neural Network Architecture with Simple Power Analysis on 32-bit Microcontrollers","abstract":"Model extraction is a growing concern for the security of AI systems. For deep neural network models, the architecture is the most important information an adversary aims to recover. Being a sequence of repeated computation blocks, neural network models deployed on edge-devices will generate distinctive side-channel leakages. The latter can be exploited to extract critical information when targeted platforms are physically accessible. By combining theoretical knowledge about deep learning practices and analysis of a widespread implementation library (ARM CMSIS-NN), our purpose is to answer this critical question: how far can we extract architecture information by simply examining an EM side-channel trace? For the first time, we propose an extraction methodology for traditional MLP and CNN models running on a high-end 32-bit microcontroller (Cortex-M7) that relies only on simple pattern recognition analysis. Despite few challenging cases, we claim that, contrary to parameters extraction, the complexity of the attack is relatively low and we highlight the urgent need for practicable protections that could fit the strong memory and latency requirements of such platforms.","sentences":["Model extraction is a growing concern for the security of AI systems.","For deep neural network models, the architecture is the most important information an adversary aims to recover.","Being a sequence of repeated computation blocks, neural network models deployed on edge-devices will generate distinctive side-channel leakages.","The latter can be exploited to extract critical information when targeted platforms are physically accessible.","By combining theoretical knowledge about deep learning practices and analysis of a widespread implementation library (ARM CMSIS-NN), our purpose is to answer this critical question: how far can we extract architecture information by simply examining an EM side-channel trace?","For the first time, we propose an extraction methodology for traditional MLP and CNN models running on a high-end 32-bit microcontroller (Cortex-M7) that relies only on simple pattern recognition analysis.","Despite few challenging cases, we claim that, contrary to parameters extraction, the complexity of the attack is relatively low and we highlight the urgent need for practicable protections that could fit the strong memory and latency requirements of such platforms."],"url":"http://arxiv.org/abs/2311.01344v1"}
{"created":"2023-11-02 15:52:35","title":"Collaborative Large Language Model for Recommender Systems","abstract":"Recently, there is a growing interest in developing next-generation recommender systems (RSs) based on pretrained large language models (LLMs), fully utilizing their encoded knowledge and reasoning ability. However, the semantic gap between natural language and recommendation tasks is still not well addressed, leading to multiple issues such as spuriously-correlated user/item descriptors, ineffective language modeling on user/item contents, and inefficient recommendations via auto-regression, etc. In this paper, we propose CLLM4Rec, the first generative RS that tightly integrates the LLM paradigm and ID paradigm of RS, aiming to address the above challenges simultaneously. We first extend the vocabulary of pretrained LLMs with user/item ID tokens to faithfully model the user/item collaborative and content semantics. Accordingly, in the pretraining stage, a novel soft+hard prompting strategy is proposed to effectively learn user/item collaborative/content token embeddings via language modeling on RS-specific corpora established from user-item interactions and user/item features, where each document is split into a prompt consisting of heterogeneous soft (user/item) tokens and hard (vocab) tokens and a main text consisting of homogeneous item tokens or vocab tokens that facilitates stable and effective language modeling. In addition, a novel mutual regularization strategy is introduced to encourage the CLLM4Rec to capture recommendation-oriented information from user/item contents. Finally, we propose a novel recommendation-oriented finetuning strategy for CLLM4Rec, where an item prediction head with multinomial likelihood is added to the pretrained CLLM4Rec backbone to predict hold-out items based on the soft+hard prompts established from masked user-item interaction history, where recommendations of multiple items can be generated efficiently.","sentences":["Recently, there is a growing interest in developing next-generation recommender systems (RSs) based on pretrained large language models (LLMs), fully utilizing their encoded knowledge and reasoning ability.","However, the semantic gap between natural language and recommendation tasks is still not well addressed, leading to multiple issues such as spuriously-correlated user/item descriptors, ineffective language modeling on user/item contents, and inefficient recommendations via auto-regression, etc.","In this paper, we propose CLLM4Rec, the first generative RS that tightly integrates the LLM paradigm and ID paradigm of RS, aiming to address the above challenges simultaneously.","We first extend the vocabulary of pretrained LLMs with user/item ID tokens to faithfully model the user/item collaborative and content semantics.","Accordingly, in the pretraining stage, a novel soft+hard prompting strategy is proposed to effectively learn user/item collaborative/content token embeddings via language modeling on RS-specific corpora established from user-item interactions and user/item features, where each document is split into a prompt consisting of heterogeneous soft (user/item) tokens and hard (vocab) tokens and a main text consisting of homogeneous item tokens or vocab tokens that facilitates stable and effective language modeling.","In addition, a novel mutual regularization strategy is introduced to encourage the CLLM4Rec to capture recommendation-oriented information from user/item contents.","Finally, we propose a novel recommendation-oriented finetuning strategy for CLLM4Rec, where an item prediction head with multinomial likelihood is added to the pretrained CLLM4Rec backbone to predict hold-out items based on the soft+hard prompts established from masked user-item interaction history, where recommendations of multiple items can be generated efficiently."],"url":"http://arxiv.org/abs/2311.01343v1"}
{"created":"2023-11-02 15:48:05","title":"Securing Wireless Communication in Critical Infrastructure: Challenges and Opportunities","abstract":"Critical infrastructure constitutes the foundation of every society. While traditionally solely relying on dedicated cable-based communication, this infrastructure rapidly transforms to highly digitized and interconnected systems which increasingly rely on wireless communication. Besides providing tremendous benefits, especially affording the easy, cheap, and flexible interconnection of a large number of assets spread over larger geographic areas, wireless communication in critical infrastructure also raises unique security challenges. Most importantly, the shift from dedicated private wired networks to heterogeneous wireless communication over public and shared networks requires significantly more involved security measures. In this paper, we identify the most relevant challenges resulting from the use of wireless communication in critical infrastructure and use those to identify a comprehensive set of promising opportunities to preserve the high security standards of critical infrastructure even when switching from wired to wireless communication.","sentences":["Critical infrastructure constitutes the foundation of every society.","While traditionally solely relying on dedicated cable-based communication, this infrastructure rapidly transforms to highly digitized and interconnected systems which increasingly rely on wireless communication.","Besides providing tremendous benefits, especially affording the easy, cheap, and flexible interconnection of a large number of assets spread over larger geographic areas, wireless communication in critical infrastructure also raises unique security challenges.","Most importantly, the shift from dedicated private wired networks to heterogeneous wireless communication over public and shared networks requires significantly more involved security measures.","In this paper, we identify the most relevant challenges resulting from the use of wireless communication in critical infrastructure and use those to identify a comprehensive set of promising opportunities to preserve the high security standards of critical infrastructure even when switching from wired to wireless communication."],"url":"http://arxiv.org/abs/2311.01338v1"}
{"created":"2023-11-02 15:45:09","title":"Look at Robot Base Once: Hand-Eye Calibration with Point Clouds of Robot Base Leveraging Learning-Based 3D Vision","abstract":"Hand-eye calibration, as a fundamental task in vision-based robotic systems, aims to estimate the transformation matrix between the coordinate frame of the camera and the robot flange. Most approaches to hand-eye calibration rely on external markers or human assistance. We proposed Look at Robot Base Once (LRBO), a novel methodology that addresses the hand-eye calibration problem without external calibration objects or human support, but with the robot base. Using point clouds of the robot base, a transformation matrix from the coordinate frame of the camera to the robot base is established as I=AXB. To this end, we exploit learning-based 3D detection and registration algorithms to estimate the location and orientation of the robot base. The robustness and accuracy of the method are quantified by ground-truth-based evaluation, and the accuracy result is compared with other 3D vision-based calibration methods. To assess the feasibility of our methodology, we carried out experiments utilizing a low-cost structured light scanner across varying joint configurations and groups of experiments. The proposed hand-eye calibration method achieved a translation deviation of 0.930 mm and a rotation deviation of 0.265 degrees according to the experimental results. Additionally, the 3D reconstruction experiments demonstrated a rotation error of 0.994 degrees and a position error of 1.697 mm. Moreover, our method offers the potential to be completed in 1 second, which is the fastest compared to other 3D hand-eye calibration methods. Code is released at github.com/leihui6/LRBO.","sentences":["Hand-eye calibration, as a fundamental task in vision-based robotic systems, aims to estimate the transformation matrix between the coordinate frame of the camera and the robot flange.","Most approaches to hand-eye calibration rely on external markers or human assistance.","We proposed Look at Robot Base Once (LRBO), a novel methodology that addresses the hand-eye calibration problem without external calibration objects or human support, but with the robot base.","Using point clouds of the robot base, a transformation matrix from the coordinate frame of the camera to the robot base is established as I=AXB.","To this end, we exploit learning-based 3D detection and registration algorithms to estimate the location and orientation of the robot base.","The robustness and accuracy of the method are quantified by ground-truth-based evaluation, and the accuracy result is compared with other 3D vision-based calibration methods.","To assess the feasibility of our methodology, we carried out experiments utilizing a low-cost structured light scanner across varying joint configurations and groups of experiments.","The proposed hand-eye calibration method achieved a translation deviation of 0.930 mm and a rotation deviation of 0.265 degrees according to the experimental results.","Additionally, the 3D reconstruction experiments demonstrated a rotation error of 0.994 degrees and a position error of 1.697 mm.","Moreover, our method offers the potential to be completed in 1 second, which is the fastest compared to other 3D hand-eye calibration methods.","Code is released at github.com/leihui6/LRBO."],"url":"http://arxiv.org/abs/2311.01335v1"}
{"created":"2023-11-02 15:41:57","title":"Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching","abstract":"In real-world scenarios, arbitrary interactions with the environment can often be costly, and actions of expert demonstrations are not always available. To reduce the need for both, Offline Learning from Observations (LfO) is extensively studied, where the agent learns to solve a task with only expert states and \\textit{task-agnostic} non-expert state-action pairs. The state-of-the-art DIstribution Correction Estimation (DICE) methods minimize the state occupancy divergence between the learner and expert policies. However, they are limited to either $f$-divergences (KL and $\\chi^2$) or Wasserstein distance with Rubinstein duality, the latter of which constrains the underlying distance metric crucial to the performance of Wasserstein-based solutions. To address this problem, we propose Primal Wasserstein DICE (PW-DICE), which minimizes the primal Wasserstein distance between the expert and learner state occupancies with a pessimistic regularizer and leverages a contrastively learned distance as the underlying metric for the Wasserstein distance. Theoretically, we prove that our framework is a generalization of the state-of-the-art, SMODICE, and unifies $f$-divergence and Wasserstein minimization. Empirically, we find that PW-DICE improves upon several state-of-the-art methods on multiple testbeds.","sentences":["In real-world scenarios, arbitrary interactions with the environment can often be costly, and actions of expert demonstrations are not always available.","To reduce the need for both, Offline Learning from Observations (LfO) is extensively studied, where the agent learns to solve a task with only expert states and \\textit{task-agnostic} non-expert state-action pairs.","The state-of-the-art DIstribution Correction Estimation (DICE) methods minimize the state occupancy divergence between the learner and expert policies.","However, they are limited to either $f$-divergences (KL and $\\chi^2$) or Wasserstein distance with Rubinstein duality, the latter of which constrains the underlying distance metric crucial to the performance of Wasserstein-based solutions.","To address this problem, we propose Primal Wasserstein DICE (PW-DICE), which minimizes the primal Wasserstein distance between the expert and learner state occupancies with a pessimistic regularizer and leverages a contrastively learned distance as the underlying metric for the Wasserstein distance.","Theoretically, we prove that our framework is a generalization of the state-of-the-art, SMODICE, and unifies $f$-divergence and Wasserstein minimization.","Empirically, we find that PW-DICE improves upon several state-of-the-art methods on multiple testbeds."],"url":"http://arxiv.org/abs/2311.01331v1"}
{"created":"2023-11-02 15:41:09","title":"A Simple Solution for Offline Imitation from Observations and Examples with Possibly Incomplete Trajectories","abstract":"Offline imitation from observations aims to solve MDPs where only task-specific expert states and task-agnostic non-expert state-action pairs are available. Offline imitation is useful in real-world scenarios where arbitrary interactions are costly and expert actions are unavailable. The state-of-the-art \"DIstribution Correction Estimation\" (DICE) methods minimize divergence of state occupancy between expert and learner policies and retrieve a policy with weighted behavior cloning; however, their results are unstable when learning from incomplete trajectories, due to a non-robust optimization in the dual domain. To address the issue, in this paper, we propose Trajectory-Aware Imitation Learning from Observations (TAILO). TAILO uses a discounted sum along the future trajectory as the weight for weighted behavior cloning. The terms for the sum are scaled by the output of a discriminator, which aims to identify expert states. Despite simplicity, TAILO works well if there exist trajectories or segments of expert behavior in the task-agnostic data, a common assumption in prior work. In experiments across multiple testbeds, we find TAILO to be more robust and effective, particularly with incomplete trajectories.","sentences":["Offline imitation from observations aims to solve MDPs where only task-specific expert states and task-agnostic non-expert state-action pairs are available.","Offline imitation is useful in real-world scenarios where arbitrary interactions are costly and expert actions are unavailable.","The state-of-the-art \"DIstribution Correction Estimation\" (DICE) methods minimize divergence of state occupancy between expert and learner policies and retrieve a policy with weighted behavior cloning; however, their results are unstable when learning from incomplete trajectories, due to a non-robust optimization in the dual domain.","To address the issue, in this paper, we propose Trajectory-Aware Imitation Learning from Observations (TAILO).","TAILO uses a discounted sum along the future trajectory as the weight for weighted behavior cloning.","The terms for the sum are scaled by the output of a discriminator, which aims to identify expert states.","Despite simplicity, TAILO works well if there exist trajectories or segments of expert behavior in the task-agnostic data, a common assumption in prior work.","In experiments across multiple testbeds, we find TAILO to be more robust and effective, particularly with incomplete trajectories."],"url":"http://arxiv.org/abs/2311.01329v1"}
{"created":"2023-11-02 15:40:33","title":"High-dimensional Linear Bandits with Knapsacks","abstract":"We study the contextual bandits with knapsack (CBwK) problem under the high-dimensional setting where the dimension of the feature is large. The reward of pulling each arm equals the multiplication of a sparse high-dimensional weight vector and the feature of the current arrival, with additional random noise. In this paper, we investigate how to exploit this sparsity structure to achieve improved regret for the CBwK problem. To this end, we first develop an online variant of the hard thresholding algorithm that performs the sparse estimation in an online manner. We further combine our online estimator with a primal-dual framework, where we assign a dual variable to each knapsack constraint and utilize an online learning algorithm to update the dual variable, thereby controlling the consumption of the knapsack capacity. We show that this integrated approach allows us to achieve a sublinear regret that depends logarithmically on the feature dimension, thus improving the polynomial dependency established in the previous literature. We also apply our framework to the high-dimension contextual bandit problem without the knapsack constraint and achieve optimal regret in both the data-poor regime and the data-rich regime. We finally conduct numerical experiments to show the efficient empirical performance of our algorithms under the high dimensional setting.","sentences":["We study the contextual bandits with knapsack (CBwK) problem under the high-dimensional setting where the dimension of the feature is large.","The reward of pulling each arm equals the multiplication of a sparse high-dimensional weight vector and the feature of the current arrival, with additional random noise.","In this paper, we investigate how to exploit this sparsity structure to achieve improved regret for the CBwK problem.","To this end, we first develop an online variant of the hard thresholding algorithm that performs the sparse estimation in an online manner.","We further combine our online estimator with a primal-dual framework, where we assign a dual variable to each knapsack constraint and utilize an online learning algorithm to update the dual variable, thereby controlling the consumption of the knapsack capacity.","We show that this integrated approach allows us to achieve a sublinear regret that depends logarithmically on the feature dimension, thus improving the polynomial dependency established in the previous literature.","We also apply our framework to the high-dimension contextual bandit problem without the knapsack constraint and achieve optimal regret in both the data-poor regime and the data-rich regime.","We finally conduct numerical experiments to show the efficient empirical performance of our algorithms under the high dimensional setting."],"url":"http://arxiv.org/abs/2311.01327v1"}
{"created":"2023-11-02 15:38:39","title":"Better Together: Enhancing Generative Knowledge Graph Completion with Language Models and Neighborhood Information","abstract":"Real-world Knowledge Graphs (KGs) often suffer from incompleteness, which limits their potential performance. Knowledge Graph Completion (KGC) techniques aim to address this issue. However, traditional KGC methods are computationally intensive and impractical for large-scale KGs, necessitating the learning of dense node embeddings and computing pairwise distances. Generative transformer-based language models (e.g., T5 and recent KGT5) offer a promising solution as they can predict the tail nodes directly. In this study, we propose to include node neighborhoods as additional information to improve KGC methods based on language models. We examine the effects of this imputation and show that, on both inductive and transductive Wikidata subsets, our method outperforms KGT5 and conventional KGC approaches. We also provide an extensive analysis of the impact of neighborhood on model prediction and show its importance. Furthermore, we point the way to significantly improve KGC through more effective neighborhood selection.","sentences":["Real-world Knowledge Graphs (KGs) often suffer from incompleteness, which limits their potential performance.","Knowledge Graph Completion (KGC) techniques aim to address this issue.","However, traditional KGC methods are computationally intensive and impractical for large-scale KGs, necessitating the learning of dense node embeddings and computing pairwise distances.","Generative transformer-based language models (e.g., T5 and recent KGT5) offer a promising solution as they can predict the tail nodes directly.","In this study, we propose to include node neighborhoods as additional information to improve KGC methods based on language models.","We examine the effects of this imputation and show that, on both inductive and transductive Wikidata subsets, our method outperforms KGT5 and conventional KGC approaches.","We also provide an extensive analysis of the impact of neighborhood on model prediction and show its importance.","Furthermore, we point the way to significantly improve KGC through more effective neighborhood selection."],"url":"http://arxiv.org/abs/2311.01326v1"}
{"created":"2023-11-02 15:37:07","title":"Pushdown Normal-Form Bisimulation: A Nominal Context-Free Approach to Program Equivalence","abstract":"We propose Pushdown Normal Form (PDNF) Bisimulation to verify contextual equivalence in higher-order functional programming languages with local state. Similar to previous work on Normal Form (NF) bisimulation, PDNF Bisimulation is sound and complete with respect to contextual equivalence. However, unlike traditional NF Bisimulation, PDNF Bisimulation is also decidable for a class of program terms that reach bounded configurations but can potentially have unbounded call stacks and input an unbounded number of unknown functions from their context. Our approach relies on the principle that, in model-checking for reachability, pushdown systems can be simulated by finite-state automata designed to accept their initial/final stack content. We embody this in a stackless Labelled Transition System (LTS), together with an on-the-fly saturation procedure for call stacks, upon which bisimulation is defined. To enhance the effectiveness of our bisimulation, we develop up-to techniques and confirm their soundness for PDNF Bisimulation. We develop a prototype implementation of our technique which is able to verify equivalence in examples from practice and the literature that were out of reach for previous work.","sentences":["We propose Pushdown Normal Form (PDNF) Bisimulation to verify contextual equivalence in higher-order functional programming languages with local state.","Similar to previous work on Normal Form (NF) bisimulation, PDNF Bisimulation is sound and complete with respect to contextual equivalence.","However, unlike traditional NF Bisimulation, PDNF Bisimulation is also decidable for a class of program terms that reach bounded configurations but can potentially have unbounded call stacks and input an unbounded number of unknown functions from their context.","Our approach relies on the principle that, in model-checking for reachability, pushdown systems can be simulated by finite-state automata designed to accept their initial/final stack content.","We embody this in a stackless Labelled Transition System (LTS), together with an on-the-fly saturation procedure for call stacks, upon which bisimulation is defined.","To enhance the effectiveness of our bisimulation, we develop up-to techniques and confirm their soundness for PDNF Bisimulation.","We develop a prototype implementation of our technique which is able to verify equivalence in examples from practice and the literature that were out of reach for previous work."],"url":"http://arxiv.org/abs/2311.01325v1"}
{"created":"2023-11-02 15:35:58","title":"Towards Evaluating Transfer-based Attacks Systematically, Practically, and Fairly","abstract":"The adversarial vulnerability of deep neural networks (DNNs) has drawn great attention due to the security risk of applying these models in real-world applications. Based on transferability of adversarial examples, an increasing number of transfer-based methods have been developed to fool black-box DNN models whose architecture and parameters are inaccessible. Although tremendous effort has been exerted, there still lacks a standardized benchmark that could be taken advantage of to compare these methods systematically, fairly, and practically. Our investigation shows that the evaluation of some methods needs to be more reasonable and more thorough to verify their effectiveness, to avoid, for example, unfair comparison and insufficient consideration of possible substitute/victim models. Therefore, we establish a transfer-based attack benchmark (TA-Bench) which implements 30+ methods. In this paper, we evaluate and compare them comprehensively on 25 popular substitute/victim models on ImageNet. New insights about the effectiveness of these methods are gained and guidelines for future evaluations are provided. Code at: https://github.com/qizhangli/TA-Bench.","sentences":["The adversarial vulnerability of deep neural networks (DNNs) has drawn great attention due to the security risk of applying these models in real-world applications.","Based on transferability of adversarial examples, an increasing number of transfer-based methods have been developed to fool black-box DNN models whose architecture and parameters are inaccessible.","Although tremendous effort has been exerted, there still lacks a standardized benchmark that could be taken advantage of to compare these methods systematically, fairly, and practically.","Our investigation shows that the evaluation of some methods needs to be more reasonable and more thorough to verify their effectiveness, to avoid, for example, unfair comparison and insufficient consideration of possible substitute/victim models.","Therefore, we establish a transfer-based attack benchmark (TA-Bench) which implements 30+ methods.","In this paper, we evaluate and compare them comprehensively on 25 popular substitute/victim models on ImageNet.","New insights about the effectiveness of these methods are gained and guidelines for future evaluations are provided.","Code at: https://github.com/qizhangli/TA-Bench."],"url":"http://arxiv.org/abs/2311.01323v1"}
{"created":"2023-11-02 15:32:24","title":"Generic Model Checking for Modal Fixpoint Logics in COOL-MC","abstract":"We report on COOL-MC, a model checking tool for fixpoint logics that is parametric in the branching type of models (nondeterministic, game-based, probabilistic etc.) and in the next-step modalities used in formulae. The tool implements generic model checking algorithms developed in coalgebraic logic that are easily adapted to concrete instance logics. Apart from the standard modal $\\mu$-calculus, COOL-MC currently supports alternating-time, graded, probabilistic and monotone variants of the $\\mu$-calculus, but is also effortlessly extensible with new instance logics. The model checking process is realized by polynomial reductions to parity game solving, or, alternatively, by a local model checking algorithm that directly computes the extensions of formulae in a lazy fashion, thereby potentially avoiding the construction of the full parity game. We evaluate COOL-MC on informative benchmark sets.","sentences":["We report on COOL-MC, a model checking tool for fixpoint logics that is parametric in the branching type of models (nondeterministic, game-based, probabilistic etc.)","and in the next-step modalities used in formulae.","The tool implements generic model checking algorithms developed in coalgebraic logic that are easily adapted to concrete instance logics.","Apart from the standard modal $\\mu$-calculus, COOL-MC currently supports alternating-time, graded, probabilistic and monotone variants of the $\\mu$-calculus, but is also effortlessly extensible with new instance logics.","The model checking process is realized by polynomial reductions to parity game solving, or, alternatively, by a local model checking algorithm that directly computes the extensions of formulae in a lazy fashion, thereby potentially avoiding the construction of the full parity game.","We evaluate COOL-MC on informative benchmark sets."],"url":"http://arxiv.org/abs/2311.01315v1"}
{"created":"2023-11-02 15:31:12","title":"Recommendations by Concise User Profiles from Review Text","abstract":"Recommender systems are most successful for popular items and users with ample interactions (likes, ratings etc.). This work addresses the difficult and underexplored case of supporting users who have very sparse interactions but post informative review texts. Our experimental studies address two book communities with these characteristics. We design a framework with Transformer-based representation learning, covering user-item interactions, item content, and user-provided reviews. To overcome interaction sparseness, we devise techniques for selecting the most informative cues to construct concise user profiles. Comprehensive experiments, with datasets from Amazon and Goodreads, show that judicious selection of text snippets achieves the best performance, even in comparison to ChatGPT-generated user profiles.","sentences":["Recommender systems are most successful for popular items and users with ample interactions (likes, ratings etc.).","This work addresses the difficult and underexplored case of supporting users who have very sparse interactions but post informative review texts.","Our experimental studies address two book communities with these characteristics.","We design a framework with Transformer-based representation learning, covering user-item interactions, item content, and user-provided reviews.","To overcome interaction sparseness, we devise techniques for selecting the most informative cues to construct concise user profiles.","Comprehensive experiments, with datasets from Amazon and Goodreads, show that judicious selection of text snippets achieves the best performance, even in comparison to ChatGPT-generated user profiles."],"url":"http://arxiv.org/abs/2311.01314v1"}
{"created":"2023-11-02 15:27:09","title":"Software Engineering for OpenHarmony: A Research Roadmap","abstract":"Mobile software engineering has been a hot research topic for decades. Our fellow researchers have proposed various approaches (with over 7,000 publications for Android alone) in this field that essentially contributed to the great success of the current mobile ecosystem. Existing research efforts mainly focus on popular mobile platforms, namely Android and iOS. OpenHarmony, a newly open-sourced mobile platform, has rarely been considered, although it is the one requiring the most attention as OpenHarmony is expected to occupy one-third of the market in China (if not in the world). To fill the gap, we present to the mobile software engineering community a research roadmap for encouraging our fellow researchers to contribute promising approaches to OpenHarmony. Specifically, we start by presenting a literature review of mobile software engineering, attempting to understand what problems have been targeted by the mobile community and how they have been resolved. We then summarize the existing (limited) achievements of OpenHarmony and subsequently highlight the research gap between Android/iOS and OpenHarmony. This research gap eventually helps in forming the roadmap for conducting software engineering research for OpenHarmony.","sentences":["Mobile software engineering has been a hot research topic for decades.","Our fellow researchers have proposed various approaches (with over 7,000 publications for Android alone) in this field that essentially contributed to the great success of the current mobile ecosystem.","Existing research efforts mainly focus on popular mobile platforms, namely Android and iOS.","OpenHarmony, a newly open-sourced mobile platform, has rarely been considered, although it is the one requiring the most attention as OpenHarmony is expected to occupy one-third of the market in China (if not in the world).","To fill the gap, we present to the mobile software engineering community a research roadmap for encouraging our fellow researchers to contribute promising approaches to OpenHarmony.","Specifically, we start by presenting a literature review of mobile software engineering, attempting to understand what problems have been targeted by the mobile community and how they have been resolved.","We then summarize the existing (limited) achievements of OpenHarmony and subsequently highlight the research gap between Android/iOS and OpenHarmony.","This research gap eventually helps in forming the roadmap for conducting software engineering research for OpenHarmony."],"url":"http://arxiv.org/abs/2311.01311v1"}
{"created":"2023-11-02 15:24:23","title":"Scattering Vision Transformer: Spectral Mixing Matters","abstract":"Vision transformers have gained significant attention and achieved state-of-the-art performance in various computer vision tasks, including image classification, instance segmentation, and object detection. However, challenges remain in addressing attention complexity and effectively capturing fine-grained information within images. Existing solutions often resort to down-sampling operations, such as pooling, to reduce computational cost. Unfortunately, such operations are non-invertible and can result in information loss. In this paper, we present a novel approach called Scattering Vision Transformer (SVT) to tackle these challenges. SVT incorporates a spectrally scattering network that enables the capture of intricate image details. SVT overcomes the invertibility issue associated with down-sampling operations by separating low-frequency and high-frequency components. Furthermore, SVT introduces a unique spectral gating network utilizing Einstein multiplication for token and channel mixing, effectively reducing complexity. We show that SVT achieves state-of-the-art performance on the ImageNet dataset with a significant reduction in a number of parameters and FLOPS. SVT shows 2\\% improvement over LiTv2 and iFormer. SVT-H-S reaches 84.2\\% top-1 accuracy, while SVT-H-B reaches 85.2\\% (state-of-art for base versions) and SVT-H-L reaches 85.7\\% (again state-of-art for large versions). SVT also shows comparable results in other vision tasks such as instance segmentation. SVT also outperforms other transformers in transfer learning on standard datasets such as CIFAR10, CIFAR100, Oxford Flower, and Stanford Car datasets. The project page is available on this webpage.\\url{https://badripatro.github.io/svt/}.","sentences":["Vision transformers have gained significant attention and achieved state-of-the-art performance in various computer vision tasks, including image classification, instance segmentation, and object detection.","However, challenges remain in addressing attention complexity and effectively capturing fine-grained information within images.","Existing solutions often resort to down-sampling operations, such as pooling, to reduce computational cost.","Unfortunately, such operations are non-invertible and can result in information loss.","In this paper, we present a novel approach called Scattering Vision Transformer (SVT) to tackle these challenges.","SVT incorporates a spectrally scattering network that enables the capture of intricate image details.","SVT overcomes the invertibility issue associated with down-sampling operations by separating low-frequency and high-frequency components.","Furthermore, SVT introduces a unique spectral gating network utilizing Einstein multiplication for token and channel mixing, effectively reducing complexity.","We show that SVT achieves state-of-the-art performance on the ImageNet dataset with a significant reduction in a number of parameters and FLOPS.","SVT shows 2\\% improvement over LiTv2 and iFormer.","SVT-H-S reaches 84.2\\% top-1 accuracy, while SVT-H-B reaches 85.2\\% (state-of-art for base versions) and SVT-H-L reaches 85.7\\% (again state-of-art for large versions).","SVT also shows comparable results in other vision tasks such as instance segmentation.","SVT also outperforms other transformers in transfer learning on standard datasets such as CIFAR10, CIFAR100, Oxford Flower, and Stanford Car datasets.","The project page is available on this webpage.\\url{https://badripatro.github.io/svt/}."],"url":"http://arxiv.org/abs/2311.01310v1"}
{"created":"2023-11-02 15:20:11","title":"The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models","abstract":"Large Language Models (LLMs) make natural interfaces to factual knowledge, but their usefulness is limited by their tendency to deliver inconsistent answers to semantically equivalent questions. For example, a model might predict both \"Anne Redpath passed away in Edinburgh.\" and \"Anne Redpath's life ended in London.\" In this work, we identify potential causes of inconsistency and evaluate the effectiveness of two mitigation strategies: up-scaling and augmenting the LM with a retrieval corpus. Our results on the LLaMA and Atlas models show that both strategies reduce inconsistency while retrieval augmentation is considerably more efficient. We further consider and disentangle the consistency contributions of different components of Atlas. For all LMs evaluated we find that syntactical form and other evaluation task artifacts impact consistency. Taken together, our results provide a better understanding of the factors affecting the factual consistency of language models.","sentences":["Large Language Models (LLMs) make natural interfaces to factual knowledge, but their usefulness is limited by their tendency to deliver inconsistent answers to semantically equivalent questions.","For example, a model might predict both \"Anne Redpath passed away in Edinburgh.\"","and \"Anne Redpath's life ended in London.\"","In this work, we identify potential causes of inconsistency and evaluate the effectiveness of two mitigation strategies: up-scaling and augmenting the LM with a retrieval corpus.","Our results on the LLaMA and Atlas models show that both strategies reduce inconsistency while retrieval augmentation is considerably more efficient.","We further consider and disentangle the consistency contributions of different components of Atlas.","For all LMs evaluated we find that syntactical form and other evaluation task artifacts impact consistency.","Taken together, our results provide a better understanding of the factors affecting the factual consistency of language models."],"url":"http://arxiv.org/abs/2311.01307v1"}
{"created":"2023-11-02 15:18:22","title":"AWEQ: Post-Training Quantization with Activation-Weight Equalization for Large Language Models","abstract":"Large language models(LLMs) exhibit excellent performance across a variety of tasks, but they come with significant computational and storage costs. Quantizing these models is an effective way to alleviate this issue. However, existing methods struggle to strike a balance between model accuracy and hardware efficiency. This is where we introduce AWEQ, a post-training method that requires no additional training overhead. AWEQ excels in both ultra-low-bit quantization and 8-bit weight and activation (W8A8) quantization. There is an observation that weight quantization is less challenging than activation quantization. AWEQ transfers the difficulty of activation quantization to weights using channel equalization, achieving a balance between the quantization difficulties of both, and thereby maximizing performance. We have further refined the equalization method to mitigate quantization bias error, ensuring the robustness of the model. Extensive experiments on popular models such as LLaMA and OPT demonstrate that AWEQ outperforms all existing post-training quantization methods for large models.","sentences":["Large language models(LLMs) exhibit excellent performance across a variety of tasks, but they come with significant computational and storage costs.","Quantizing these models is an effective way to alleviate this issue.","However, existing methods struggle to strike a balance between model accuracy and hardware efficiency.","This is where we introduce AWEQ, a post-training method that requires no additional training overhead.","AWEQ excels in both ultra-low-bit quantization and 8-bit weight and activation (W8A8) quantization.","There is an observation that weight quantization is less challenging than activation quantization.","AWEQ transfers the difficulty of activation quantization to weights using channel equalization, achieving a balance between the quantization difficulties of both, and thereby maximizing performance.","We have further refined the equalization method to mitigate quantization bias error, ensuring the robustness of the model.","Extensive experiments on popular models such as LLaMA and OPT demonstrate that AWEQ outperforms all existing post-training quantization methods for large models."],"url":"http://arxiv.org/abs/2311.01305v1"}
{"created":"2023-11-02 15:18:00","title":"VM-Rec: A Variational Mapping Approach for Cold-start User Recommendation","abstract":"The cold-start problem is a common challenge for most recommender systems. With extremely limited interactions of cold-start users, conventional recommender models often struggle to generate embeddings with sufficient expressivity. Moreover, the absence of auxiliary content information of users exacerbates the presence of challenges, rendering most cold-start methods difficult to apply. To address this issue, our motivation is based on the observation that if a model can generate expressive embeddings for existing users with relatively more interactions, who were also initially cold-start users, then we can establish a mapping from few initial interactions to expressive embeddings, simulating the process of generating embeddings for cold-start users. Based on this motivation, we propose a Variational Mapping approach for cold-start user Recommendation (VM-Rec). Firstly, we generate a personalized mapping function for cold-start users based on their initial interactions, and parameters of the function are generated from a variational distribution. For the sake of interpretability and computational efficiency, we model the personalized mapping function as a sparse linear model, where each parameter indicates the association to a specific existing user. Consequently, we use this mapping function to map the embeddings of existing users to an embedding of the cold-start user in the same space. The resulting embedding has similar expressivity to that of existing users and can be directly integrated into a pre-trained recommender model to predict click through rates or ranking scores. We evaluate our method based on three widely used recommender models as pre-trained base recommender models, outperforming four popular cold-start methods on two datasets under the same base model.","sentences":["The cold-start problem is a common challenge for most recommender systems.","With extremely limited interactions of cold-start users, conventional recommender models often struggle to generate embeddings with sufficient expressivity.","Moreover, the absence of auxiliary content information of users exacerbates the presence of challenges, rendering most cold-start methods difficult to apply.","To address this issue, our motivation is based on the observation that if a model can generate expressive embeddings for existing users with relatively more interactions, who were also initially cold-start users, then we can establish a mapping from few initial interactions to expressive embeddings, simulating the process of generating embeddings for cold-start users.","Based on this motivation, we propose a Variational Mapping approach for cold-start user Recommendation (VM-Rec).","Firstly, we generate a personalized mapping function for cold-start users based on their initial interactions, and parameters of the function are generated from a variational distribution.","For the sake of interpretability and computational efficiency, we model the personalized mapping function as a sparse linear model, where each parameter indicates the association to a specific existing user.","Consequently, we use this mapping function to map the embeddings of existing users to an embedding of the cold-start user in the same space.","The resulting embedding has similar expressivity to that of existing users and can be directly integrated into a pre-trained recommender model to predict click through rates or ranking scores.","We evaluate our method based on three widely used recommender models as pre-trained base recommender models, outperforming four popular cold-start methods on two datasets under the same base model."],"url":"http://arxiv.org/abs/2311.01304v1"}
{"created":"2023-11-02 15:15:47","title":"TRIALSCOPE A Unifying Causal Framework for Scaling Real-World Evidence Generation with Biomedical Language Models","abstract":"The rapid digitization of real-world data offers an unprecedented opportunity for optimizing healthcare delivery and accelerating biomedical discovery. In practice, however, such data is most abundantly available in unstructured forms, such as clinical notes in electronic medical records (EMRs), and it is generally plagued by confounders. In this paper, we present TRIALSCOPE, a unifying framework for distilling real-world evidence from population-level observational data. TRIALSCOPE leverages biomedical language models to structure clinical text at scale, employs advanced probabilistic modeling for denoising and imputation, and incorporates state-of-the-art causal inference techniques to combat common confounders. Using clinical trial specification as generic representation, TRIALSCOPE provides a turn-key solution to generate and reason with clinical hypotheses using observational data. In extensive experiments and analyses on a large-scale real-world dataset with over one million cancer patients from a large US healthcare network, we show that TRIALSCOPE can produce high-quality structuring of real-world data and generates comparable results to marquee cancer trials. In addition to facilitating in-silicon clinical trial design and optimization, TRIALSCOPE may be used to empower synthetic controls, pragmatic trials, post-market surveillance, as well as support fine-grained patient-like-me reasoning in precision diagnosis and treatment.","sentences":["The rapid digitization of real-world data offers an unprecedented opportunity for optimizing healthcare delivery and accelerating biomedical discovery.","In practice, however, such data is most abundantly available in unstructured forms, such as clinical notes in electronic medical records (EMRs), and it is generally plagued by confounders.","In this paper, we present TRIALSCOPE, a unifying framework for distilling real-world evidence from population-level observational data.","TRIALSCOPE leverages biomedical language models to structure clinical text at scale, employs advanced probabilistic modeling for denoising and imputation, and incorporates state-of-the-art causal inference techniques to combat common confounders.","Using clinical trial specification as generic representation, TRIALSCOPE provides a turn-key solution to generate and reason with clinical hypotheses using observational data.","In extensive experiments and analyses on a large-scale real-world dataset with over one million cancer patients from a large US healthcare network, we show that TRIALSCOPE can produce high-quality structuring of real-world data and generates comparable results to marquee cancer trials.","In addition to facilitating in-silicon clinical trial design and optimization, TRIALSCOPE may be used to empower synthetic controls, pragmatic trials, post-market surveillance, as well as support fine-grained patient-like-me reasoning in precision diagnosis and treatment."],"url":"http://arxiv.org/abs/2311.01301v1"}
{"created":"2023-11-02 15:12:12","title":"DP-Mix: Mixup-based Data Augmentation for Differentially Private Learning","abstract":"Data augmentation techniques, such as simple image transformations and combinations, are highly effective at improving the generalization of computer vision models, especially when training data is limited. However, such techniques are fundamentally incompatible with differentially private learning approaches, due to the latter's built-in assumption that each training image's contribution to the learned model is bounded. In this paper, we investigate why naive applications of multi-sample data augmentation techniques, such as mixup, fail to achieve good performance and propose two novel data augmentation techniques specifically designed for the constraints of differentially private learning. Our first technique, DP-Mix_Self, achieves SoTA classification performance across a range of datasets and settings by performing mixup on self-augmented data. Our second technique, DP-Mix_Diff, further improves performance by incorporating synthetic data from a pre-trained diffusion model into the mixup process. We open-source the code at https://github.com/wenxuan-Bao/DP-Mix.","sentences":["Data augmentation techniques, such as simple image transformations and combinations, are highly effective at improving the generalization of computer vision models, especially when training data is limited.","However, such techniques are fundamentally incompatible with differentially private learning approaches, due to the latter's built-in assumption that each training image's contribution to the learned model is bounded.","In this paper, we investigate why naive applications of multi-sample data augmentation techniques, such as mixup, fail to achieve good performance and propose two novel data augmentation techniques specifically designed for the constraints of differentially private learning.","Our first technique, DP-Mix_Self, achieves SoTA classification performance across a range of datasets and settings by performing mixup on self-augmented data.","Our second technique, DP-Mix_Diff, further improves performance by incorporating synthetic data from a pre-trained diffusion model into the mixup process.","We open-source the code at https://github.com/wenxuan-Bao/DP-Mix."],"url":"http://arxiv.org/abs/2311.01295v1"}
{"created":"2023-11-02 15:08:18","title":"Joint 3D Shape and Motion Estimation from Rolling Shutter Light-Field Images","abstract":"In this paper, we propose an approach to address the problem of 3D reconstruction of scenes from a single image captured by a light-field camera equipped with a rolling shutter sensor. Our method leverages the 3D information cues present in the light-field and the motion information provided by the rolling shutter effect. We present a generic model for the imaging process of this sensor and a two-stage algorithm that minimizes the re-projection error while considering the position and motion of the camera in a motion-shape bundle adjustment estimation strategy. Thereby, we provide an instantaneous 3D shape-and-pose-and-velocity sensing paradigm. To the best of our knowledge, this is the first study to leverage this type of sensor for this purpose. We also present a new benchmark dataset composed of different light-fields showing rolling shutter effects, which can be used as a common base to improve the evaluation and tracking the progress in the field. We demonstrate the effectiveness and advantages of our approach through several experiments conducted for different scenes and types of motions. The source code and dataset are publicly available at: https://github.com/ICB-Vision-AI/RSLF","sentences":["In this paper, we propose an approach to address the problem of 3D reconstruction of scenes from a single image captured by a light-field camera equipped with a rolling shutter sensor.","Our method leverages the 3D information cues present in the light-field and the motion information provided by the rolling shutter effect.","We present a generic model for the imaging process of this sensor and a two-stage algorithm that minimizes the re-projection error while considering the position and motion of the camera in a motion-shape bundle adjustment estimation strategy.","Thereby, we provide an instantaneous 3D shape-and-pose-and-velocity sensing paradigm.","To the best of our knowledge, this is the first study to leverage this type of sensor for this purpose.","We also present a new benchmark dataset composed of different light-fields showing rolling shutter effects, which can be used as a common base to improve the evaluation and tracking the progress in the field.","We demonstrate the effectiveness and advantages of our approach through several experiments conducted for different scenes and types of motions.","The source code and dataset are publicly available at: https://github.com/ICB-Vision-AI/RSLF"],"url":"http://arxiv.org/abs/2311.01292v1"}
{"created":"2023-11-02 15:02:19","title":"Unraveling Diffusion in Fusion Plasma: A Case Study of In Situ Processing and Particle Sorting","abstract":"This work starts an in situ processing capability to study a certain diffusion process in magnetic confinement fusion. This diffusion process involves plasma particles that are likely to escape confinement. Such particles carry a significant amount of energy from the burning plasma inside the tokamak to the diverter and damaging the diverter plate. This study requires in situ processing because of the fast changing nature of the particle diffusion process. However, the in situ processing approach is challenging because the amount of data to be retained for the diffusion calculations increases over time, unlike in other in situ processing cases where the amount of data to be processed is constant over time. Here we report our preliminary efforts to control the memory usage while ensuring the necessary analysis tasks are completed in a timely manner. Compared with an earlier naive attempt to directly computing the same diffusion displacements in the simulation code, this in situ version reduces the memory usage from particle information by nearly 60% and computation time by about 20%.","sentences":["This work starts an in situ processing capability to study a certain diffusion process in magnetic confinement fusion.","This diffusion process involves plasma particles that are likely to escape confinement.","Such particles carry a significant amount of energy from the burning plasma inside the tokamak to the diverter and damaging the diverter plate.","This study requires in situ processing because of the fast changing nature of the particle diffusion process.","However, the in situ processing approach is challenging because the amount of data to be retained for the diffusion calculations increases over time, unlike in other in situ processing cases where the amount of data to be processed is constant over time.","Here we report our preliminary efforts to control the memory usage while ensuring the necessary analysis tasks are completed in a timely manner.","Compared with an earlier naive attempt to directly computing the same diffusion displacements in the simulation code, this in situ version reduces the memory usage from particle information by nearly 60% and computation time by about 20%."],"url":"http://arxiv.org/abs/2311.01288v1"}
{"created":"2023-11-02 14:57:58","title":"Distilling Knowledge from CNN-Transformer Models for Enhanced Human Action Recognition","abstract":"This paper presents a study on improving human action recognition through the utilization of knowledge distillation, and the combination of CNN and ViT models. The research aims to enhance the performance and efficiency of smaller student models by transferring knowledge from larger teacher models. The proposed method employs a Transformer vision network as the student model, while a convolutional network serves as the teacher model. The teacher model extracts local image features, whereas the student model focuses on global features using an attention mechanism. The Vision Transformer (ViT) architecture is introduced as a robust framework for capturing global dependencies in images. Additionally, advanced variants of ViT, namely PVT, Convit, MVIT, Swin Transformer, and Twins, are discussed, highlighting their contributions to computer vision tasks. The ConvNeXt model is introduced as a teacher model, known for its efficiency and effectiveness in computer vision. The paper presents performance results for human action recognition on the Stanford 40 dataset, comparing the accuracy and mAP of student models trained with and without knowledge distillation. The findings illustrate that the suggested approach significantly improves the accuracy and mAP when compared to training networks under regular settings. These findings emphasize the potential of combining local and global features in action recognition tasks.","sentences":["This paper presents a study on improving human action recognition through the utilization of knowledge distillation, and the combination of CNN and ViT models.","The research aims to enhance the performance and efficiency of smaller student models by transferring knowledge from larger teacher models.","The proposed method employs a Transformer vision network as the student model, while a convolutional network serves as the teacher model.","The teacher model extracts local image features, whereas the student model focuses on global features using an attention mechanism.","The Vision Transformer (ViT) architecture is introduced as a robust framework for capturing global dependencies in images.","Additionally, advanced variants of ViT, namely PVT, Convit, MVIT, Swin Transformer, and Twins, are discussed, highlighting their contributions to computer vision tasks.","The ConvNeXt model is introduced as a teacher model, known for its efficiency and effectiveness in computer vision.","The paper presents performance results for human action recognition on the Stanford 40 dataset, comparing the accuracy and mAP of student models trained with and without knowledge distillation.","The findings illustrate that the suggested approach significantly improves the accuracy and mAP when compared to training networks under regular settings.","These findings emphasize the potential of combining local and global features in action recognition tasks."],"url":"http://arxiv.org/abs/2311.01283v1"}
{"created":"2023-11-02 14:57:03","title":"FlashDecoding++: Faster Large Language Model Inference on GPUs","abstract":"As the Large Language Model (LLM) becomes increasingly important in various domains. However, the following challenges still remain unsolved in accelerating LLM inference: (1) Synchronized partial softmax update. The softmax operation requires a synchronized update operation among each partial softmax result, leading to ~20% overheads for the attention computation in LLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices performing GEMM in LLM inference is flat, leading to under-utilized computation and >50% performance loss after padding zeros in previous designs. (3) Performance loss due to static dataflow. Kernel performance in LLM depends on varied input data features, hardware configurations, etc. A single and static dataflow may lead to a 50.25% performance loss for GEMMs of different shapes in LLM inference.   We present FlashDecoding++, a fast LLM inference engine supporting mainstream LLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++ creatively proposes: (1) Asynchronized softmax with unified max value. FlashDecoding++ introduces a unified max value technique for different partial softmax computations to avoid synchronization. (2) Flat GEMM optimization with double buffering. FlashDecoding++ points out that flat GEMMs with different shapes face varied bottlenecks. Then, techniques like double buffering are introduced. (3) Heuristic dataflow with hardware resource adaptation. FlashDecoding++ heuristically optimizes dataflow using different hardware resource considering input dynamics. Due to the versatility of optimizations in FlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on both NVIDIA and AMD GPUs compared to Hugging Face implementations. FlashDecoding++ also achieves an average speedup of 1.37x compared to state-of-the-art LLM inference engines on mainstream LLMs.","sentences":["As the Large Language Model (LLM) becomes increasingly important in various domains.","However, the following challenges still remain unsolved in accelerating LLM inference: (1) Synchronized partial softmax update.","The softmax operation requires a synchronized update operation among each partial softmax result, leading to ~20% overheads for the attention computation in LLMs.","(2) Under-utilized computation of flat GEMM.","The shape of matrices performing GEMM in LLM inference is flat, leading to under-utilized computation and >50% performance loss after padding zeros in previous designs.","(3) Performance loss due to static dataflow.","Kernel performance in LLM depends on varied input data features, hardware configurations, etc.","A single and static dataflow may lead to a 50.25% performance loss for GEMMs of different shapes in LLM inference.   ","We present FlashDecoding++, a fast LLM inference engine supporting mainstream LLMs and hardware back-ends.","To tackle the above challenges, FlashDecoding++ creatively proposes: (1) Asynchronized softmax with unified max value.","FlashDecoding++ introduces a unified max value technique for different partial softmax computations to avoid synchronization.","(2) Flat GEMM optimization with double buffering.","FlashDecoding++ points out that flat GEMMs with different shapes face varied bottlenecks.","Then, techniques like double buffering are introduced.","(3) Heuristic dataflow with hardware resource adaptation.","FlashDecoding++ heuristically optimizes dataflow using different hardware resource considering input dynamics.","Due to the versatility of optimizations in FlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on both NVIDIA and AMD GPUs compared to Hugging Face implementations.","FlashDecoding++ also achieves an average speedup of 1.37x compared to state-of-the-art LLM inference engines on mainstream LLMs."],"url":"http://arxiv.org/abs/2311.01282v1"}
{"created":"2023-11-02 14:50:01","title":"ExPECA: An Experimental Platform for Trustworthy Edge Computing Applications","abstract":"This paper presents ExPECA, an edge computing and wireless communication research testbed designed to tackle two pressing challenges: comprehensive end-to-end experimentation and high levels of experimental reproducibility. Leveraging OpenStack-based Chameleon Infrastructure (CHI) framework for its proven flexibility and ease of operation, ExPECA is located in a unique, isolated underground facility, providing a highly controlled setting for wireless experiments. The testbed is engineered to facilitate integrated studies of both communication and computation, offering a diverse array of Software-Defined Radios (SDR) and Commercial Off-The-Shelf (COTS) wireless and wired links, as well as containerized computational environments. We exemplify the experimental possibilities of the testbed using OpenRTiST, a latency-sensitive, bandwidth-intensive application, and analyze its performance. Lastly, we highlight an array of research domains and experimental setups that stand to gain from ExPECA's features, including closed-loop applications and time-sensitive networking.","sentences":["This paper presents ExPECA, an edge computing and wireless communication research testbed designed to tackle two pressing challenges: comprehensive end-to-end experimentation and high levels of experimental reproducibility.","Leveraging OpenStack-based Chameleon Infrastructure (CHI) framework for its proven flexibility and ease of operation, ExPECA is located in a unique, isolated underground facility, providing a highly controlled setting for wireless experiments.","The testbed is engineered to facilitate integrated studies of both communication and computation, offering a diverse array of Software-Defined Radios (SDR) and Commercial Off-The-Shelf (COTS) wireless and wired links, as well as containerized computational environments.","We exemplify the experimental possibilities of the testbed using OpenRTiST, a latency-sensitive, bandwidth-intensive application, and analyze its performance.","Lastly, we highlight an array of research domains and experimental setups that stand to gain from ExPECA's features, including closed-loop applications and time-sensitive networking."],"url":"http://arxiv.org/abs/2311.01279v1"}
{"created":"2023-11-02 14:44:50","title":"Long-Range Neural Atom Learning for Molecular Graphs","abstract":"Graph Neural Networks (GNNs) have been widely adopted for drug discovery with molecular graphs. Nevertheless, current GNNs are mainly good at leveraging short-range interactions (SRI) but struggle to capture long-range interactions (LRI), both of which are crucial for determining molecular properties. To tackle this issue, we propose a method that implicitly projects all original atoms into a few Neural Atoms, which abstracts the collective information of atomic groups within a molecule. Specifically, we explicitly exchange the information among neural atoms and project them back to the atoms' representations as an enhancement. With this mechanism, neural atoms establish the communication channels among distant nodes, effectively reducing the interaction scope of arbitrary node pairs into a single hop. To provide an inspection of our method from a physical perspective, we reveal its connection with the traditional LRI calculation method, Ewald Summation. We conduct extensive experiments on three long-range graph benchmarks, covering both graph-level and link-level tasks on molecular graphs. We empirically justify that our method can be equipped with an arbitrary GNN and help to capture LRI.","sentences":["Graph Neural Networks (GNNs) have been widely adopted for drug discovery with molecular graphs.","Nevertheless, current GNNs are mainly good at leveraging short-range interactions (SRI) but struggle to capture long-range interactions (LRI), both of which are crucial for determining molecular properties.","To tackle this issue, we propose a method that implicitly projects all original atoms into a few Neural Atoms, which abstracts the collective information of atomic groups within a molecule.","Specifically, we explicitly exchange the information among neural atoms and project them back to the atoms' representations as an enhancement.","With this mechanism, neural atoms establish the communication channels among distant nodes, effectively reducing the interaction scope of arbitrary node pairs into a single hop.","To provide an inspection of our method from a physical perspective, we reveal its connection with the traditional LRI calculation method, Ewald Summation.","We conduct extensive experiments on three long-range graph benchmarks, covering both graph-level and link-level tasks on molecular graphs.","We empirically justify that our method can be equipped with an arbitrary GNN and help to capture LRI."],"url":"http://arxiv.org/abs/2311.01276v1"}
{"created":"2023-11-02 14:37:28","title":"Finding Common Ground: Annotating and Predicting Common Ground in Spoken Conversations","abstract":"When we communicate with other humans, we do not simply generate a sequence of words. Rather, we use our cognitive state (beliefs, desires, intentions) and our model of the audience's cognitive state to create utterances that affect the audience's cognitive state in the intended manner. An important part of cognitive state is the common ground, which is the content the speaker believes, and the speaker believes the audience believes, and so on. While much attention has been paid to common ground in cognitive science, there has not been much work in natural language processing. In this paper, we introduce a new annotation and corpus to capture common ground. We then describe some initial experiments extracting propositions from dialog and tracking their status in the common ground from the perspective of each speaker.","sentences":["When we communicate with other humans, we do not simply generate a sequence of words.","Rather, we use our cognitive state (beliefs, desires, intentions) and our model of the audience's cognitive state to create utterances that affect the audience's cognitive state in the intended manner.","An important part of cognitive state is the common ground, which is the content the speaker believes, and the speaker believes the audience believes, and so on.","While much attention has been paid to common ground in cognitive science, there has not been much work in natural language processing.","In this paper, we introduce a new annotation and corpus to capture common ground.","We then describe some initial experiments extracting propositions from dialog and tracking their status in the common ground from the perspective of each speaker."],"url":"http://arxiv.org/abs/2311.01273v1"}
{"created":"2023-11-02 14:31:25","title":"People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection","abstract":"NLP models are used in a variety of critical social computing tasks, such as detecting sexist, racist, or otherwise hateful content. Therefore, it is imperative that these models are robust to spurious features. Past work has attempted to tackle such spurious features using training data augmentation, including Counterfactually Augmented Data (CADs). CADs introduce minimal changes to existing training data points and flip their labels; training on them may reduce model dependency on spurious features. However, manually generating CADs can be time-consuming and expensive. Hence in this work, we assess if this task can be automated using generative NLP models. We automatically generate CADs using Polyjuice, ChatGPT, and Flan-T5, and evaluate their usefulness in improving model robustness compared to manually-generated CADs. By testing both model performance on multiple out-of-domain test sets and individual data point efficacy, our results show that while manual CADs are still the most effective, CADs generated by ChatGPT come a close second. One key reason for the lower performance of automated methods is that the changes they introduce are often insufficient to flip the original label.","sentences":["NLP models are used in a variety of critical social computing tasks, such as detecting sexist, racist, or otherwise hateful content.","Therefore, it is imperative that these models are robust to spurious features.","Past work has attempted to tackle such spurious features using training data augmentation, including Counterfactually Augmented Data (CADs).","CADs introduce minimal changes to existing training data points and flip their labels; training on them may reduce model dependency on spurious features.","However, manually generating CADs can be time-consuming and expensive.","Hence in this work, we assess if this task can be automated using generative NLP models.","We automatically generate CADs using Polyjuice, ChatGPT, and Flan-T5, and evaluate their usefulness in improving model robustness compared to manually-generated CADs.","By testing both model performance on multiple out-of-domain test sets and individual data point efficacy, our results show that while manual CADs are still the most effective, CADs generated by ChatGPT come a close second.","One key reason for the lower performance of automated methods is that the changes they introduce are often insufficient to flip the original label."],"url":"http://arxiv.org/abs/2311.01270v1"}
{"created":"2023-11-02 14:25:10","title":"UniFolding: Towards Sample-efficient, Scalable, and Generalizable Robotic Garment Folding","abstract":"This paper explores the development of UniFolding, a sample-efficient, scalable, and generalizable robotic system for unfolding and folding various garments. UniFolding employs the proposed UFONet neural network to integrate unfolding and folding decisions into a single policy model that is adaptable to different garment types and states. The design of UniFolding is based on a garment's partial point cloud, which aids in generalization and reduces sensitivity to variations in texture and shape. The training pipeline prioritizes low-cost, sample-efficient data collection. Training data is collected via a human-centric process with offline and online stages. The offline stage involves human unfolding and folding actions via Virtual Reality, while the online stage utilizes human-in-the-loop learning to fine-tune the model in a real-world setting. The system is tested on two garment types: long-sleeve and short-sleeve shirts. Performance is evaluated on 20 shirts with significant variations in textures, shapes, and materials. More experiments and videos can be found in the supplementary materials and on the website: https://unifolding.robotflow.ai","sentences":["This paper explores the development of UniFolding, a sample-efficient, scalable, and generalizable robotic system for unfolding and folding various garments.","UniFolding employs the proposed UFONet neural network to integrate unfolding and folding decisions into a single policy model that is adaptable to different garment types and states.","The design of UniFolding is based on a garment's partial point cloud, which aids in generalization and reduces sensitivity to variations in texture and shape.","The training pipeline prioritizes low-cost, sample-efficient data collection.","Training data is collected via a human-centric process with offline and online stages.","The offline stage involves human unfolding and folding actions via Virtual Reality, while the online stage utilizes human-in-the-loop learning to fine-tune the model in a real-world setting.","The system is tested on two garment types: long-sleeve and short-sleeve shirts.","Performance is evaluated on 20 shirts with significant variations in textures, shapes, and materials.","More experiments and videos can be found in the supplementary materials and on the website: https://unifolding.robotflow.ai"],"url":"http://arxiv.org/abs/2311.01267v1"}
{"created":"2023-11-02 14:25:00","title":"Let's Discover More API Relations: A Large Language Model-based AI Chain for Unsupervised API Relation Inference","abstract":"APIs have intricate relations that can be described in text and represented as knowledge graphs to aid software engineering tasks. Existing relation extraction methods have limitations, such as limited API text corpus and affected by the characteristics of the input text.To address these limitations, we propose utilizing large language models (LLMs) (e.g., GPT-3.5) as a neural knowledge base for API relation inference. This approach leverages the entire Web used to pre-train LLMs as a knowledge base and is insensitive to the context and complexity of input texts. To ensure accurate inference, we design our analytic flow as an AI Chain with three AI modules: API FQN Parser, API Knowledge Extractor, and API Relation Decider. The accuracy of the API FQN parser and API Relation Decider module are 0.81 and 0.83, respectively. Using the generative capacity of the LLM and our approach's inference capability, we achieve an average F1 value of 0.76 under the three datasets, significantly higher than the state-of-the-art method's average F1 value of 0.40. Compared to CoT-based method, our AI Chain design improves the inference reliability by 67%, and the AI-crowd-intelligence strategy enhances the robustness of our approach by 26%.","sentences":["APIs have intricate relations that can be described in text and represented as knowledge graphs to aid software engineering tasks.","Existing relation extraction methods have limitations, such as limited API text corpus and affected by the characteristics of the input text.","To address these limitations, we propose utilizing large language models (LLMs) (e.g., GPT-3.5) as a neural knowledge base for API relation inference.","This approach leverages the entire Web used to pre-train LLMs as a knowledge base and is insensitive to the context and complexity of input texts.","To ensure accurate inference, we design our analytic flow as an AI Chain with three AI modules: API FQN Parser, API Knowledge Extractor, and API Relation Decider.","The accuracy of the API FQN parser and API Relation Decider module are 0.81 and 0.83, respectively.","Using the generative capacity of the LLM and our approach's inference capability, we achieve an average F1 value of 0.76 under the three datasets, significantly higher than the state-of-the-art method's average F1 value of 0.40.","Compared to CoT-based method, our AI Chain design improves the inference reliability by 67%, and the AI-crowd-intelligence strategy enhances the robustness of our approach by 26%."],"url":"http://arxiv.org/abs/2311.01266v1"}
{"created":"2023-11-02 14:23:45","title":"Efficient Neural Ranking using Forward Indexes and Lightweight Encoders","abstract":"Dual-encoder-based dense retrieval models have become the standard in IR. They employ large Transformer-based language models, which are notoriously inefficient in terms of resources and latency. We propose Fast-Forward indexes -- vector forward indexes which exploit the semantic matching capabilities of dual-encoder models for efficient and effective re-ranking. Our framework enables re-ranking at very high retrieval depths and combines the merits of both lexical and semantic matching via score interpolation. Furthermore, in order to mitigate the limitations of dual-encoders, we tackle two main challenges: Firstly, we improve computational efficiency by either pre-computing representations, avoiding unnecessary computations altogether, or reducing the complexity of encoders. This allows us to considerably improve ranking efficiency and latency. Secondly, we optimize the memory footprint and maintenance cost of indexes; we propose two complementary techniques to reduce the index size and show that, by dynamically dropping irrelevant document tokens, the index maintenance efficiency can be improved substantially. We perform evaluation to show the effectiveness and efficiency of Fast-Forward indexes -- our method has low latency and achieves competitive results without the need for hardware acceleration, such as GPUs.","sentences":["Dual-encoder-based dense retrieval models have become the standard in IR.","They employ large Transformer-based language models, which are notoriously inefficient in terms of resources and latency.","We propose Fast-Forward indexes -- vector forward indexes which exploit the semantic matching capabilities of dual-encoder models for efficient and effective re-ranking.","Our framework enables re-ranking at very high retrieval depths and combines the merits of both lexical and semantic matching via score interpolation.","Furthermore, in order to mitigate the limitations of dual-encoders, we tackle two main challenges: Firstly, we improve computational efficiency by either pre-computing representations, avoiding unnecessary computations altogether, or reducing the complexity of encoders.","This allows us to considerably improve ranking efficiency and latency.","Secondly, we optimize the memory footprint and maintenance cost of indexes; we propose two complementary techniques to reduce the index size and show that, by dynamically dropping irrelevant document tokens, the index maintenance efficiency can be improved substantially.","We perform evaluation to show the effectiveness and efficiency of Fast-Forward indexes -- our method has low latency and achieves competitive results without the need for hardware acceleration, such as GPUs."],"url":"http://arxiv.org/abs/2311.01263v1"}
