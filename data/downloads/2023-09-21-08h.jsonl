{"created":"2023-09-20 17:59:32","title":"A Large-scale Dataset for Audio-Language Representation Learning","abstract":"The AI community has made significant strides in developing powerful foundation models, driven by large-scale multimodal datasets. However, in the audio representation learning community, the present audio-language datasets suffer from limitations such as insufficient volume, simplistic content, and arduous collection procedures. To tackle these challenges, we present an innovative and automatic audio caption generation pipeline based on a series of public tools or APIs, and construct a large-scale, high-quality, audio-language dataset, named as Auto-ACD, comprising over 1.9M audio-text pairs. To demonstrate the effectiveness of the proposed dataset, we train popular models on our dataset and show performance improvement on various downstream tasks, namely, audio-language retrieval, audio captioning, environment classification. In addition, we establish a novel test set and provide a benchmark for audio-text tasks. The proposed dataset will be released at https://auto-acd.github.io/.","sentences":["The AI community has made significant strides in developing powerful foundation models, driven by large-scale multimodal datasets.","However, in the audio representation learning community, the present audio-language datasets suffer from limitations such as insufficient volume, simplistic content, and arduous collection procedures.","To tackle these challenges, we present an innovative and automatic audio caption generation pipeline based on a series of public tools or APIs, and construct a large-scale, high-quality, audio-language dataset, named as Auto-ACD, comprising over 1.9M audio-text pairs.","To demonstrate the effectiveness of the proposed dataset, we train popular models on our dataset and show performance improvement on various downstream tasks, namely, audio-language retrieval, audio captioning, environment classification.","In addition, we establish a novel test set and provide a benchmark for audio-text tasks.","The proposed dataset will be released at https://auto-acd.github.io/."],"url":"http://arxiv.org/abs/2309.11500v1"}
{"created":"2023-09-20 17:58:05","title":"DreamLLM: Synergistic Multimodal Comprehension and Creation","abstract":"This paper presents DreamLLM, a learning framework that first achieves versatile Multimodal Large Language Models (MLLMs) empowered with frequently overlooked synergy between multimodal comprehension and creation. DreamLLM operates on two fundamental principles. The first focuses on the generative modeling of both language and image posteriors by direct sampling in the raw multimodal space. This approach circumvents the limitations and information loss inherent to external feature extractors like CLIP, and a more thorough multimodal understanding is obtained. Second, DreamLLM fosters the generation of raw, interleaved documents, modeling both text and image contents, along with unstructured layouts. This allows DreamLLM to learn all conditional, marginal, and joint multimodal distributions effectively. As a result, DreamLLM is the first MLLM capable of generating free-form interleaved content. Comprehensive experiments highlight DreamLLM's superior performance as a zero-shot multimodal generalist, reaping from the enhanced learning synergy.","sentences":["This paper presents DreamLLM, a learning framework that first achieves versatile Multimodal Large Language Models (MLLMs) empowered with frequently overlooked synergy between multimodal comprehension and creation.","DreamLLM operates on two fundamental principles.","The first focuses on the generative modeling of both language and image posteriors by direct sampling in the raw multimodal space.","This approach circumvents the limitations and information loss inherent to external feature extractors like CLIP, and a more thorough multimodal understanding is obtained.","Second, DreamLLM fosters the generation of raw, interleaved documents, modeling both text and image contents, along with unstructured layouts.","This allows DreamLLM to learn all conditional, marginal, and joint multimodal distributions effectively.","As a result, DreamLLM is the first MLLM capable of generating free-form interleaved content.","Comprehensive experiments highlight DreamLLM's superior performance as a zero-shot multimodal generalist, reaping from the enhanced learning synergy."],"url":"http://arxiv.org/abs/2309.11499v1"}
{"created":"2023-09-20 17:56:18","title":"FreeU: Free Lunch in Diffusion U-Net","abstract":"In this paper, we uncover the untapped potential of diffusion U-Net, which serves as a \"free lunch\" that substantially improves the generation quality on the fly. We initially investigate the key contributions of the U-Net architecture to the denoising process and identify that its main backbone primarily contributes to denoising, whereas its skip connections mainly introduce high-frequency features into the decoder module, causing the network to overlook the backbone semantics. Capitalizing on this discovery, we propose a simple yet effective method-termed \"FreeU\" - that enhances generation quality without additional training or finetuning. Our key insight is to strategically re-weight the contributions sourced from the U-Net's skip connections and backbone feature maps, to leverage the strengths of both components of the U-Net architecture. Promising results on image and video generation tasks demonstrate that our FreeU can be readily integrated to existing diffusion models, e.g., Stable Diffusion, DreamBooth, ModelScope, Rerender and ReVersion, to improve the generation quality with only a few lines of code. All you need is to adjust two scaling factors during inference. Project page: https://chenyangsi.top/FreeU/.","sentences":["In this paper, we uncover the untapped potential of diffusion U-Net, which serves as a \"free lunch\" that substantially improves the generation quality on the fly.","We initially investigate the key contributions of the U-Net architecture to the denoising process and identify that its main backbone primarily contributes to denoising, whereas its skip connections mainly introduce high-frequency features into the decoder module, causing the network to overlook the backbone semantics.","Capitalizing on this discovery, we propose a simple yet effective method-termed \"FreeU\" - that enhances generation quality without additional training or finetuning.","Our key insight is to strategically re-weight the contributions sourced from the U-Net's skip connections and backbone feature maps, to leverage the strengths of both components of the U-Net architecture.","Promising results on image and video generation tasks demonstrate that our FreeU can be readily integrated to existing diffusion models, e.g., Stable Diffusion, DreamBooth, ModelScope, Rerender and ReVersion, to improve the generation quality with only a few lines of code.","All you need is to adjust two scaling factors during inference.","Project page: https://chenyangsi.top/FreeU/."],"url":"http://arxiv.org/abs/2309.11497v1"}
{"created":"2023-09-20 17:50:55","title":"Chain-of-Verification Reduces Hallucination in Large Language Models","abstract":"Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models. We study the ability of language models to deliberate on the responses they give in order to correct their mistakes. We develop the Chain-of-Verification (CoVe) method whereby the model first (i) drafts an initial response; then (ii) plans verification questions to fact-check its draft; (iii) answers those questions independently so the answers are not biased by other responses; and (iv) generates its final verified response. In experiments, we show CoVe decreases hallucinations across a variety of tasks, from list-based questions from Wikidata, closed book MultiSpanQA and longform text generation.","sentences":["Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models.","We study the ability of language models to deliberate on the responses they give in order to correct their mistakes.","We develop the Chain-of-Verification (CoVe) method whereby the model first (i) drafts an initial response; then (ii) plans verification questions to fact-check its draft; (iii) answers those questions independently so the answers are not biased by other responses; and (iv) generates its final verified response.","In experiments, we show CoVe decreases hallucinations across a variety of tasks, from list-based questions from Wikidata, closed book MultiSpanQA and longform text generation."],"url":"http://arxiv.org/abs/2309.11495v1"}
{"created":"2023-09-20 17:39:13","title":"Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning","abstract":"Designing reward functions is a longstanding challenge in reinforcement learning (RL); it requires specialized knowledge or domain data, leading to high costs for development. To address this, we introduce Text2Reward, a data-free framework that automates the generation of dense reward functions based on large language models (LLMs). Given a goal described in natural language, Text2Reward generates dense reward functions as an executable program grounded in a compact representation of the environment. Unlike inverse RL and recent work that uses LLMs to write sparse reward codes, Text2Reward produces interpretable, free-form dense reward codes that cover a wide range of tasks, utilize existing packages, and allow iterative refinement with human feedback. We evaluate Text2Reward on two robotic manipulation benchmarks (ManiSkill2, MetaWorld) and two locomotion environments of MuJoCo. On 13 of the 17 manipulation tasks, policies trained with generated reward codes achieve similar or better task success rates and convergence speed than expert-written reward codes. For locomotion tasks, our method learns six novel locomotion behaviors with a success rate exceeding 94%. Furthermore, we show that the policies trained in the simulator with our method can be deployed in the real world. Finally, Text2Reward further improves the policies by refining their reward functions with human feedback. Video results are available at https://text-to-reward.github.io","sentences":["Designing reward functions is a longstanding challenge in reinforcement learning (RL); it requires specialized knowledge or domain data, leading to high costs for development.","To address this, we introduce Text2Reward, a data-free framework that automates the generation of dense reward functions based on large language models (LLMs).","Given a goal described in natural language, Text2Reward generates dense reward functions as an executable program grounded in a compact representation of the environment.","Unlike inverse RL and recent work that uses LLMs to write sparse reward codes, Text2Reward produces interpretable, free-form dense reward codes that cover a wide range of tasks, utilize existing packages, and allow iterative refinement with human feedback.","We evaluate Text2Reward on two robotic manipulation benchmarks (ManiSkill2, MetaWorld) and two locomotion environments of MuJoCo.","On 13 of the 17 manipulation tasks, policies trained with generated reward codes achieve similar or better task success rates and convergence speed than expert-written reward codes.","For locomotion tasks, our method learns six novel locomotion behaviors with a success rate exceeding 94%.","Furthermore, we show that the policies trained in the simulator with our method can be deployed in the real world.","Finally, Text2Reward further improves the policies by refining their reward functions with human feedback.","Video results are available at https://text-to-reward.github.io"],"url":"http://arxiv.org/abs/2309.11489v1"}
{"created":"2023-09-20 17:34:43","title":"An Evaluation and Comparison of GPU Hardware and Solver Libraries for Accelerating the OPM Flow Reservoir Simulator","abstract":"Realistic reservoir simulation is known to be prohibitively expensive in terms of computation time when increasing the accuracy of the simulation or by enlarging the model grid size. One method to address this issue is to parallelize the computation by dividing the model in several partitions and using multiple CPUs to compute the result using techniques such as MPI and multi-threading. Alternatively, GPUs are also a good candidate to accelerate the computation due to their massively parallel architecture that allows many floating point operations per second to be performed. The numerical iterative solver takes thus the most computational time and is challenging to solve efficiently due to the dependencies that exist in the model between cells. In this work, we evaluate the OPM Flow simulator and compare several state-of-the-art GPU solver libraries as well as custom developed solutions for a BiCGStab solver using an ILU0 preconditioner and benchmark their performance against the default DUNE library implementation running on multiple CPU processors using MPI. The evaluated GPU software libraries include a manual linear solver in OpenCL and the integration of several third party sparse linear algebra libraries, such as cuSparse, rocSparse, and amgcl. To perform our bench-marking, we use small, medium, and large use cases, starting with the public test case NORNE that includes approximately 50k active cells and ending with a large model that includes approximately 1 million active cells. We find that a GPU can accelerate a single dual-threaded MPI process up to 5.6 times, and that it can compare with around 8 dual-threaded MPI processes.","sentences":["Realistic reservoir simulation is known to be prohibitively expensive in terms of computation time when increasing the accuracy of the simulation or by enlarging the model grid size.","One method to address this issue is to parallelize the computation by dividing the model in several partitions and using multiple CPUs to compute the result using techniques such as MPI and multi-threading.","Alternatively, GPUs are also a good candidate to accelerate the computation due to their massively parallel architecture that allows many floating point operations per second to be performed.","The numerical iterative solver takes thus the most computational time and is challenging to solve efficiently due to the dependencies that exist in the model between cells.","In this work, we evaluate the OPM Flow simulator and compare several state-of-the-art GPU solver libraries as well as custom developed solutions for a BiCGStab solver using an ILU0 preconditioner and benchmark their performance against the default DUNE library implementation running on multiple CPU processors using MPI.","The evaluated GPU software libraries include a manual linear solver in OpenCL and the integration of several third party sparse linear algebra libraries, such as cuSparse, rocSparse, and amgcl.","To perform our bench-marking, we use small, medium, and large use cases, starting with the public test case NORNE that includes approximately 50k active cells and ending with a large model that includes approximately 1 million active cells.","We find that a GPU can accelerate a single dual-threaded MPI process up to 5.6 times, and that it can compare with around 8 dual-threaded MPI processes."],"url":"http://arxiv.org/abs/2309.11488v1"}
{"created":"2023-09-20 17:28:32","title":"Bravo MaRDI: A Wikibase Powered Knowledge Graph on Mathematics","abstract":"Mathematical world knowledge is a fundamental component of Wikidata. However, to date, no expertly curated knowledge graph has focused specifically on contemporary mathematics. Addressing this gap, the Mathematical Research Data Initiative (MaRDI) has developed a comprehensive knowledge graph that links multimodal research data in mathematics. This encompasses traditional research data items like datasets, software, and publications and includes semantically advanced objects such as mathematical formulas and hypotheses. This paper details the abilities of the MaRDI knowledge graph, which is based on Wikibase, leading up to its inaugural public release, codenamed Bravo, available on https://portal.mardi4nfdi.de.","sentences":["Mathematical world knowledge is a fundamental component of Wikidata.","However, to date, no expertly curated knowledge graph has focused specifically on contemporary mathematics.","Addressing this gap, the Mathematical Research Data Initiative (MaRDI) has developed a comprehensive knowledge graph that links multimodal research data in mathematics.","This encompasses traditional research data items like datasets, software, and publications and includes semantically advanced objects such as mathematical formulas and hypotheses.","This paper details the abilities of the MaRDI knowledge graph, which is based on Wikibase, leading up to its inaugural public release, codenamed Bravo, available on https://portal.mardi4nfdi.de."],"url":"http://arxiv.org/abs/2309.11484v1"}
{"created":"2023-09-20 17:23:05","title":"Fictional Worlds, Real Connections: Developing Community Storytelling Social Chatbots through LLMs","abstract":"We address the integration of storytelling and Large Language Models (LLMs) to develop engaging and believable Social Chatbots (SCs) in community settings. Motivated by the potential of fictional characters to enhance social interactions, we introduce Storytelling Social Chatbots (SSCs) and the concept of story engineering to transform fictional game characters into \"live\" social entities within player communities. Our story engineering process includes three steps: (1) Character and story creation, defining the SC's personality and worldview, (2) Presenting Live Stories to the Community, allowing the SC to recount challenges and seek suggestions, and (3) Communication with community members, enabling interaction between the SC and users. We employed the LLM GPT-3 to drive our SSC prototypes, \"David\" and \"Catherine,\" and evaluated their performance in an online gaming community, \"DE (Alias),\" on Discord. Our mixed-method analysis, based on questionnaires (N=15) and interviews (N=8) with community members, reveals that storytelling significantly enhances the engagement and believability of SCs in community settings.","sentences":["We address the integration of storytelling and Large Language Models (LLMs) to develop engaging and believable Social Chatbots (SCs) in community settings.","Motivated by the potential of fictional characters to enhance social interactions, we introduce Storytelling Social Chatbots (SSCs) and the concept of story engineering to transform fictional game characters into \"live\" social entities within player communities.","Our story engineering process includes three steps: (1) Character and story creation, defining the SC's personality and worldview, (2) Presenting Live Stories to the Community, allowing the SC to recount challenges and seek suggestions, and (3) Communication with community members, enabling interaction between the SC and users.","We employed the LLM GPT-3 to drive our SSC prototypes, \"David\" and \"Catherine,\" and evaluated their performance in an online gaming community, \"DE (Alias),\" on Discord.","Our mixed-method analysis, based on questionnaires (N=15) and interviews (N=8) with community members, reveals that storytelling significantly enhances the engagement and believability of SCs in community settings."],"url":"http://arxiv.org/abs/2309.11478v1"}
{"created":"2023-09-20 17:22:01","title":"CellSecure: Securing Image Data in Industrial Internet-of-Things via Cellular Automata and Chaos-Based Encryption","abstract":"In the era of Industrial IoT (IIoT) and Industry 4.0, ensuring secure data transmission has become a critical concern. Among other data types, images are widely transmitted and utilized across various IIoT applications, ranging from sensor-generated visual data and real-time remote monitoring to quality control in production lines. The encryption of these images is essential for maintaining operational integrity, data confidentiality, and seamless integration with analytics platforms. This paper addresses these critical concerns by proposing a robust image encryption algorithm tailored for IIoT and Cyber-Physical Systems (CPS). The algorithm combines Rule-30 cellular automata with chaotic scrambling and substitution. The Rule 30 cellular automata serves as an efficient mechanism for generating pseudo-random sequences that enable fast encryption and decryption cycles suitable for real-time sensor data in industrial settings. Most importantly, it induces non-linearity in the encryption algorithm. Furthermore, to increase the chaotic range and keyspace of the algorithm, which is vital for security in distributed industrial networks, a hybrid chaotic map, i.e., logistic-sine map is utilized. Extensive security analysis has been carried out to validate the efficacy of the proposed algorithm. Results indicate that our algorithm achieves close-to-ideal values, with an entropy of 7.99 and a correlation of 0.002. This enhances the algorithm's resilience against potential cyber-attacks in the industrial domain.","sentences":["In the era of Industrial IoT (IIoT) and Industry 4.0, ensuring secure data transmission has become a critical concern.","Among other data types, images are widely transmitted and utilized across various IIoT applications, ranging from sensor-generated visual data and real-time remote monitoring to quality control in production lines.","The encryption of these images is essential for maintaining operational integrity, data confidentiality, and seamless integration with analytics platforms.","This paper addresses these critical concerns by proposing a robust image encryption algorithm tailored for IIoT and Cyber-Physical Systems (CPS).","The algorithm combines Rule-30 cellular automata with chaotic scrambling and substitution.","The Rule 30 cellular automata serves as an efficient mechanism for generating pseudo-random sequences that enable fast encryption and decryption cycles suitable for real-time sensor data in industrial settings.","Most importantly, it induces non-linearity in the encryption algorithm.","Furthermore, to increase the chaotic range and keyspace of the algorithm, which is vital for security in distributed industrial networks, a hybrid chaotic map, i.e., logistic-sine map is utilized.","Extensive security analysis has been carried out to validate the efficacy of the proposed algorithm.","Results indicate that our algorithm achieves close-to-ideal values, with an entropy of 7.99 and a correlation of 0.002.","This enhances the algorithm's resilience against potential cyber-attacks in the industrial domain."],"url":"http://arxiv.org/abs/2309.11476v1"}
{"created":"2023-09-20 17:13:15","title":"Multi-view Fuzzy Representation Learning with Rules based Model","abstract":"Unsupervised multi-view representation learning has been extensively studied for mining multi-view data. However, some critical challenges remain. On the one hand, the existing methods cannot explore multi-view data comprehensively since they usually learn a common representation between views, given that multi-view data contains both the common information between views and the specific information within each view. On the other hand, to mine the nonlinear relationship between data, kernel or neural network methods are commonly used for multi-view representation learning. However, these methods are lacking in interpretability. To this end, this paper proposes a new multi-view fuzzy representation learning method based on the interpretable Takagi-Sugeno-Kang (TSK) fuzzy system (MVRL_FS). The method realizes multi-view representation learning from two aspects. First, multi-view data are transformed into a high-dimensional fuzzy feature space, while the common information between views and specific information of each view are explored simultaneously. Second, a new regularization method based on L_(2,1)-norm regression is proposed to mine the consistency information between views, while the geometric structure of the data is preserved through the Laplacian graph. Finally, extensive experiments on many benchmark multi-view datasets are conducted to validate the superiority of the proposed method.","sentences":["Unsupervised multi-view representation learning has been extensively studied for mining multi-view data.","However, some critical challenges remain.","On the one hand, the existing methods cannot explore multi-view data comprehensively since they usually learn a common representation between views, given that multi-view data contains both the common information between views and the specific information within each view.","On the other hand, to mine the nonlinear relationship between data, kernel or neural network methods are commonly used for multi-view representation learning.","However, these methods are lacking in interpretability.","To this end, this paper proposes a new multi-view fuzzy representation learning method based on the interpretable Takagi-Sugeno-Kang (TSK) fuzzy system (MVRL_FS).","The method realizes multi-view representation learning from two aspects.","First, multi-view data are transformed into a high-dimensional fuzzy feature space, while the common information between views and specific information of each view are explored simultaneously.","Second, a new regularization method based on L_(2,1)-norm regression is proposed to mine the consistency information between views, while the geometric structure of the data is preserved through the Laplacian graph.","Finally, extensive experiments on many benchmark multi-view datasets are conducted to validate the superiority of the proposed method."],"url":"http://arxiv.org/abs/2309.11473v1"}
{"created":"2023-09-20 17:11:35","title":"Noise-Crypt: Image Encryption with Non-linear Noise, Hybrid Chaotic Maps, and Hashing","abstract":"To secure the digital images over insecure transmission channels, a new image encryption algorithm Noise-Crypt is proposed in this paper. Noise-Crypt integrates non-linear random noise, hybrid chaotic maps, and SHA-256 hashing algorithm. The utilized hybrid chaotic maps are the logistic-tent and the logistic-sine-cosine map. The hybrid chaotic maps enhance the pseudorandom sequence generation and selection of substitution boxes, while the logistic-sine-cosine map induces non-linearity in the algorithm through random noise. This deliberate inclusion of noise contributes to increased resistance against cryptanalysis. The proposed scheme has been evaluated for several security parameters, such as differential attacks, entropy, correlation, etc. Extensive evaluation demonstrates the efficacy of the proposed scheme, with almost ideal values of entropy of 7.99 and correlation of -0.0040. Results of the security analysis validate the potency of the proposed scheme in achieving robust image encryption.","sentences":["To secure the digital images over insecure transmission channels, a new image encryption algorithm Noise-Crypt is proposed in this paper.","Noise-Crypt integrates non-linear random noise, hybrid chaotic maps, and SHA-256 hashing algorithm.","The utilized hybrid chaotic maps are the logistic-tent and the logistic-sine-cosine map.","The hybrid chaotic maps enhance the pseudorandom sequence generation and selection of substitution boxes, while the logistic-sine-cosine map induces non-linearity in the algorithm through random noise.","This deliberate inclusion of noise contributes to increased resistance against cryptanalysis.","The proposed scheme has been evaluated for several security parameters, such as differential attacks, entropy, correlation, etc. Extensive evaluation demonstrates the efficacy of the proposed scheme, with almost ideal values of entropy of 7.99 and correlation of -0.0040.","Results of the security analysis validate the potency of the proposed scheme in achieving robust image encryption."],"url":"http://arxiv.org/abs/2309.11471v1"}
{"created":"2023-09-20 17:10:10","title":"Model-free tracking control of complex dynamical trajectories with machine learning","abstract":"Nonlinear tracking control enabling a dynamical system to track a desired trajectory is fundamental to robotics, serving a wide range of civil and defense applications. In control engineering, designing tracking control requires complete knowledge of the system model and equations. We develop a model-free, machine-learning framework to control a two-arm robotic manipulator using only partially observed states, where the controller is realized by reservoir computing. Stochastic input is exploited for training, which consists of the observed partial state vector as the first and its immediate future as the second component so that the neural machine regards the latter as the future state of the former. In the testing (deployment) phase, the immediate-future component is replaced by the desired observational vector from the reference trajectory. We demonstrate the effectiveness of the control framework using a variety of periodic and chaotic signals, and establish its robustness against measurement noise, disturbances, and uncertainties.","sentences":["Nonlinear tracking control enabling a dynamical system to track a desired trajectory is fundamental to robotics, serving a wide range of civil and defense applications.","In control engineering, designing tracking control requires complete knowledge of the system model and equations.","We develop a model-free, machine-learning framework to control a two-arm robotic manipulator using only partially observed states, where the controller is realized by reservoir computing.","Stochastic input is exploited for training, which consists of the observed partial state vector as the first and its immediate future as the second component so that the neural machine regards the latter as the future state of the former.","In the testing (deployment) phase, the immediate-future component is replaced by the desired observational vector from the reference trajectory.","We demonstrate the effectiveness of the control framework using a variety of periodic and chaotic signals, and establish its robustness against measurement noise, disturbances, and uncertainties."],"url":"http://arxiv.org/abs/2309.11470v1"}
{"created":"2023-09-20 17:09:09","title":"Multi-Label Takagi-Sugeno-Kang Fuzzy System","abstract":"Multi-label classification can effectively identify the relevant labels of an instance from a given set of labels. However,the modeling of the relationship between the features and the labels is critical to the classification performance. To this end, we propose a new multi-label classification method, called Multi-Label Takagi-Sugeno-Kang Fuzzy System (ML-TSK FS), to improve the classification performance. The structure of ML-TSK FS is designed using fuzzy rules to model the relationship between features and labels. The fuzzy system is trained by integrating fuzzy inference based multi-label correlation learning with multi-label regression loss. The proposed ML-TSK FS is evaluated experimentally on 12 benchmark multi-label datasets. 1 The results show that the performance of ML-TSK FS is competitive with existing methods in terms of various evaluation metrics, indicating that it is able to model the feature-label relationship effectively using fuzzy inference rules and enhances the classification performance.","sentences":["Multi-label classification can effectively identify the relevant labels of an instance from a given set of labels.","However,the modeling of the relationship between the features and the labels is critical to the classification performance.","To this end, we propose a new multi-label classification method, called Multi-Label Takagi-Sugeno-Kang Fuzzy System (ML-TSK FS), to improve the classification performance.","The structure of ML-TSK FS is designed using fuzzy rules to model the relationship between features and labels.","The fuzzy system is trained by integrating fuzzy inference based multi-label correlation learning with multi-label regression loss.","The proposed ML-TSK FS is evaluated experimentally on 12 benchmark multi-label datasets.","1","The results show that the performance of ML-TSK FS is competitive with existing methods in terms of various evaluation metrics, indicating that it is able to model the feature-label relationship effectively using fuzzy inference rules and enhances the classification performance."],"url":"http://arxiv.org/abs/2309.11469v1"}
{"created":"2023-09-20 17:00:31","title":"Budget-Aware Pruning: Handling Multiple Domains with Less Parameters","abstract":"Deep learning has achieved state-of-the-art performance on several computer vision tasks and domains. Nevertheless, it still has a high computational cost and demands a significant amount of parameters. Such requirements hinder the use in resource-limited environments and demand both software and hardware optimization. Another limitation is that deep models are usually specialized into a single domain or task, requiring them to learn and store new parameters for each new one. Multi-Domain Learning (MDL) attempts to solve this problem by learning a single model that is capable of performing well in multiple domains. Nevertheless, the models are usually larger than the baseline for a single domain. This work tackles both of these problems: our objective is to prune models capable of handling multiple domains according to a user-defined budget, making them more computationally affordable while keeping a similar classification performance. We achieve this by encouraging all domains to use a similar subset of filters from the baseline model, up to the amount defined by the user's budget. Then, filters that are not used by any domain are pruned from the network. The proposed approach innovates by better adapting to resource-limited devices while, to our knowledge, being the only work that handles multiple domains at test time with fewer parameters and lower computational complexity than the baseline model for a single domain.","sentences":["Deep learning has achieved state-of-the-art performance on several computer vision tasks and domains.","Nevertheless, it still has a high computational cost and demands a significant amount of parameters.","Such requirements hinder the use in resource-limited environments and demand both software and hardware optimization.","Another limitation is that deep models are usually specialized into a single domain or task, requiring them to learn and store new parameters for each new one.","Multi-Domain Learning (MDL) attempts to solve this problem by learning a single model that is capable of performing well in multiple domains.","Nevertheless, the models are usually larger than the baseline for a single domain.","This work tackles both of these problems: our objective is to prune models capable of handling multiple domains according to a user-defined budget, making them more computationally affordable while keeping a similar classification performance.","We achieve this by encouraging all domains to use a similar subset of filters from the baseline model, up to the amount defined by the user's budget.","Then, filters that are not used by any domain are pruned from the network.","The proposed approach innovates by better adapting to resource-limited devices while, to our knowledge, being the only work that handles multiple domains at test time with fewer parameters and lower computational complexity than the baseline model for a single domain."],"url":"http://arxiv.org/abs/2309.11464v1"}
{"created":"2023-09-20 16:59:22","title":"AudioFool: Fast, Universal and synchronization-free Cross-Domain Attack on Speech Recognition","abstract":"Automatic Speech Recognition systems have been shown to be vulnerable to adversarial attacks that manipulate the command executed on the device. Recent research has focused on exploring methods to create such attacks, however, some issues relating to Over-The-Air (OTA) attacks have not been properly addressed. In our work, we examine the needed properties of robust attacks compatible with the OTA model, and we design a method of generating attacks with arbitrary such desired properties, namely the invariance to synchronization, and the robustness to filtering: this allows a Denial-of-Service (DoS) attack against ASR systems. We achieve these characteristics by constructing attacks in a modified frequency domain through an inverse Fourier transform. We evaluate our method on standard keyword classification tasks and analyze it in OTA, and we analyze the properties of the cross-domain attacks to explain the efficiency of the approach.","sentences":["Automatic Speech Recognition systems have been shown to be vulnerable to adversarial attacks that manipulate the command executed on the device.","Recent research has focused on exploring methods to create such attacks, however, some issues relating to Over-The-Air (OTA) attacks have not been properly addressed.","In our work, we examine the needed properties of robust attacks compatible with the OTA model, and we design a method of generating attacks with arbitrary such desired properties, namely the invariance to synchronization, and the robustness to filtering: this allows a Denial-of-Service (DoS) attack against ASR systems.","We achieve these characteristics by constructing attacks in a modified frequency domain through an inverse Fourier transform.","We evaluate our method on standard keyword classification tasks and analyze it in OTA, and we analyze the properties of the cross-domain attacks to explain the efficiency of the approach."],"url":"http://arxiv.org/abs/2309.11462v1"}
{"created":"2023-09-20 16:57:11","title":"Digital twins of nonlinear dynamical systems: A perspective","abstract":"Digital twins have attracted a great deal of recent attention from a wide range of fields. A basic requirement for digital twins of nonlinear dynamical systems is the ability to generate the system evolution and predict potentially catastrophic emergent behaviors so as to providing early warnings. The digital twin can then be used for system \"health\" monitoring in real time and for predictive problem solving. In particular, if the digital twin forecasts a possible system collapse in the future due to parameter drifting as caused by environmental changes or perturbations, an optimal control strategy can be devised and executed as early intervention to prevent the collapse. Two approaches exist for constructing digital twins of nonlinear dynamical systems: sparse optimization and machine learning. The basics of these two approaches are described and their advantages and caveats are discussed.","sentences":["Digital twins have attracted a great deal of recent attention from a wide range of fields.","A basic requirement for digital twins of nonlinear dynamical systems is the ability to generate the system evolution and predict potentially catastrophic emergent behaviors so as to providing early warnings.","The digital twin can then be used for system \"health\" monitoring in real time and for predictive problem solving.","In particular, if the digital twin forecasts a possible system collapse in the future due to parameter drifting as caused by environmental changes or perturbations, an optimal control strategy can be devised and executed as early intervention to prevent the collapse.","Two approaches exist for constructing digital twins of nonlinear dynamical systems: sparse optimization and machine learning.","The basics of these two approaches are described and their advantages and caveats are discussed."],"url":"http://arxiv.org/abs/2309.11461v1"}
{"created":"2023-09-20 16:43:05","title":"Generative Agent-Based Modeling: Unveiling Social System Dynamics through Coupling Mechanistic Models with Generative Artificial Intelligence","abstract":"We discuss the emerging new opportunity for building feedback-rich computational models of social systems using generative artificial intelligence. Referred to as Generative Agent-Based Models (GABMs), such individual-level models utilize large language models such as ChatGPT to represent human decision-making in social settings. We provide a GABM case in which human behavior can be incorporated in simulation models by coupling a mechanistic model of human interactions with a pre-trained large language model. This is achieved by introducing a simple GABM of social norm diffusion in an organization. For educational purposes, the model is intentionally kept simple. We examine a wide range of scenarios and the sensitivity of the results to several changes in the prompt. We hope the article and the model serve as a guide for building useful diffusion models that include realistic human reasoning and decision-making.","sentences":["We discuss the emerging new opportunity for building feedback-rich computational models of social systems using generative artificial intelligence.","Referred to as Generative Agent-Based Models (GABMs), such individual-level models utilize large language models such as ChatGPT to represent human decision-making in social settings.","We provide a GABM case in which human behavior can be incorporated in simulation models by coupling a mechanistic model of human interactions with a pre-trained large language model.","This is achieved by introducing a simple GABM of social norm diffusion in an organization.","For educational purposes, the model is intentionally kept simple.","We examine a wide range of scenarios and the sensitivity of the results to several changes in the prompt.","We hope the article and the model serve as a guide for building useful diffusion models that include realistic human reasoning and decision-making."],"url":"http://arxiv.org/abs/2309.11456v1"}
{"created":"2023-09-20 16:40:17","title":"NeighViz: Towards Better Understanding of Neighborhood Effects on Social Groups with Spatial Data","abstract":"Understanding how local environments influence individual behaviors, such as voting patterns or suicidal tendencies, is crucial in social science to reveal and reduce spatial disparities and promote social well-being. With the increasing availability of large-scale individual-level census data, new analytical opportunities arise for social scientists to explore human behaviors (e.g., political engagement) among social groups at a fine-grained level. However, traditional statistical methods mostly focus on global, aggregated spatial correlations, which are limited to understanding and comparing the impact of local environments (e.g., neighborhoods) on human behaviors among social groups. In this study, we introduce a new analytical framework for analyzing multi-variate neighborhood effects between social groups. We then propose NeighVi, an interactive visual analytics system that helps social scientists explore, understand, and verify the influence of neighborhood effects on human behaviors. Finally, we use a case study to illustrate the effectiveness and usability of our system.","sentences":["Understanding how local environments influence individual behaviors, such as voting patterns or suicidal tendencies, is crucial in social science to reveal and reduce spatial disparities and promote social well-being.","With the increasing availability of large-scale individual-level census data, new analytical opportunities arise for social scientists to explore human behaviors (e.g., political engagement) among social groups at a fine-grained level.","However, traditional statistical methods mostly focus on global, aggregated spatial correlations, which are limited to understanding and comparing the impact of local environments (e.g., neighborhoods) on human behaviors among social groups.","In this study, we introduce a new analytical framework for analyzing multi-variate neighborhood effects between social groups.","We then propose NeighVi, an interactive visual analytics system that helps social scientists explore, understand, and verify the influence of neighborhood effects on human behaviors.","Finally, we use a case study to illustrate the effectiveness and usability of our system."],"url":"http://arxiv.org/abs/2309.11454v1"}
{"created":"2023-09-20 16:35:29","title":"Multi-Step Model Predictive Safety Filters: Reducing Chattering by Increasing the Prediction Horizon","abstract":"Learning-based controllers have demonstrated superior performance compared to classical controllers in various tasks. However, providing safety guarantees is not trivial. Safety, the satisfaction of state and input constraints, can be guaranteed by augmenting the learned control policy with a safety filter. Model predictive safety filters (MPSFs) are a common safety filtering approach based on model predictive control (MPC). MPSFs seek to guarantee safety while minimizing the difference between the proposed and applied inputs in the immediate next time step. This limited foresight can lead to jerky motions and undesired oscillations close to constraint boundaries, known as chattering. In this paper, we reduce chattering by considering input corrections over a longer horizon. Under the assumption of bounded model uncertainties, we prove recursive feasibility using techniques from robust MPC. We verified the proposed approach in both extensive simulation and quadrotor experiments. In experiments with a Crazyflie 2.0 drone, we show that, in addition to preserving the desired safety guarantees, the proposed MPSF reduces chattering by more than a factor of 4 compared to previous MPSF formulations.","sentences":["Learning-based controllers have demonstrated superior performance compared to classical controllers in various tasks.","However, providing safety guarantees is not trivial.","Safety, the satisfaction of state and input constraints, can be guaranteed by augmenting the learned control policy with a safety filter.","Model predictive safety filters (MPSFs) are a common safety filtering approach based on model predictive control (MPC).","MPSFs seek to guarantee safety while minimizing the difference between the proposed and applied inputs in the immediate next time step.","This limited foresight can lead to jerky motions and undesired oscillations close to constraint boundaries, known as chattering.","In this paper, we reduce chattering by considering input corrections over a longer horizon.","Under the assumption of bounded model uncertainties, we prove recursive feasibility using techniques from robust MPC.","We verified the proposed approach in both extensive simulation and quadrotor experiments.","In experiments with a Crazyflie 2.0 drone, we show that, in addition to preserving the desired safety guarantees, the proposed MPSF reduces chattering by more than a factor of 4 compared to previous MPSF formulations."],"url":"http://arxiv.org/abs/2309.11453v1"}
{"created":"2023-09-20 16:27:52","title":"Using deep learning to construct stochastic local search SAT solvers with performance bounds","abstract":"The Boolean Satisfiability problem (SAT) is the most prototypical NP-complete problem and of great practical relevance. One important class of solvers for this problem are stochastic local search (SLS) algorithms that iteratively and randomly update a candidate assignment. Recent breakthrough results in theoretical computer science have established sufficient conditions under which SLS solvers are guaranteed to efficiently solve a SAT instance, provided they have access to suitable \"oracles\" that provide samples from an instance-specific distribution, exploiting an instance's local structure. Motivated by these results and the well established ability of neural networks to learn common structure in large datasets, in this work, we train oracles using Graph Neural Networks and evaluate them on two SLS solvers on random SAT instances of varying difficulty. We find that access to GNN-based oracles significantly boosts the performance of both solvers, allowing them, on average, to solve 17% more difficult instances (as measured by the ratio between clauses and variables), and to do so in 35% fewer steps, with improvements in the median number of steps of up to a factor of 8. As such, this work bridges formal results from theoretical computer science and practically motivated research on deep learning for constraint satisfaction problems and establishes the promise of purpose-trained SAT solvers with performance guarantees.","sentences":["The Boolean Satisfiability problem (SAT) is the most prototypical NP-complete problem and of great practical relevance.","One important class of solvers for this problem are stochastic local search (SLS) algorithms that iteratively and randomly update a candidate assignment.","Recent breakthrough results in theoretical computer science have established sufficient conditions under which SLS solvers are guaranteed to efficiently solve a SAT instance, provided they have access to suitable \"oracles\" that provide samples from an instance-specific distribution, exploiting an instance's local structure.","Motivated by these results and the well established ability of neural networks to learn common structure in large datasets, in this work, we train oracles using Graph Neural Networks and evaluate them on two SLS solvers on random SAT instances of varying difficulty.","We find that access to GNN-based oracles significantly boosts the performance of both solvers, allowing them, on average, to solve 17% more difficult instances (as measured by the ratio between clauses and variables), and to do so in 35% fewer steps, with improvements in the median number of steps of up to a factor of 8.","As such, this work bridges formal results from theoretical computer science and practically motivated research on deep learning for constraint satisfaction problems and establishes the promise of purpose-trained SAT solvers with performance guarantees."],"url":"http://arxiv.org/abs/2309.11452v1"}
{"created":"2023-09-20 16:23:30","title":"Weight Averaging Improves Knowledge Distillation under Domain Shift","abstract":"Knowledge distillation (KD) is a powerful model compression technique broadly used in practical deep learning applications. It is focused on training a small student network to mimic a larger teacher network. While it is widely known that KD can offer an improvement to student generalization in i.i.d setting, its performance under domain shift, i.e. the performance of student networks on data from domains unseen during training, has received little attention in the literature. In this paper we make a step towards bridging the research fields of knowledge distillation and domain generalization. We show that weight averaging techniques proposed in domain generalization literature, such as SWAD and SMA, also improve the performance of knowledge distillation under domain shift. In addition, we propose a simplistic weight averaging strategy that does not require evaluation on validation data during training and show that it performs on par with SWAD and SMA when applied to KD. We name our final distillation approach Weight-Averaged Knowledge Distillation (WAKD).","sentences":["Knowledge distillation (KD) is a powerful model compression technique broadly used in practical deep learning applications.","It is focused on training a small student network to mimic a larger teacher network.","While it is widely known that KD can offer an improvement to student generalization in i.i.d setting, its performance under domain shift, i.e. the performance of student networks on data from domains unseen during training, has received little attention in the literature.","In this paper we make a step towards bridging the research fields of knowledge distillation and domain generalization.","We show that weight averaging techniques proposed in domain generalization literature, such as SWAD and SMA, also improve the performance of knowledge distillation under domain shift.","In addition, we propose a simplistic weight averaging strategy that does not require evaluation on validation data during training and show that it performs on par with SWAD and SMA when applied to KD.","We name our final distillation approach Weight-Averaged Knowledge Distillation (WAKD)."],"url":"http://arxiv.org/abs/2309.11446v1"}
{"created":"2023-09-20 16:22:33","title":"SkeleTR: Towrads Skeleton-based Action Recognition in the Wild","abstract":"We present SkeleTR, a new framework for skeleton-based action recognition. In contrast to prior work, which focuses mainly on controlled environments, we target more general scenarios that typically involve a variable number of people and various forms of interaction between people. SkeleTR works with a two-stage paradigm. It first models the intra-person skeleton dynamics for each skeleton sequence with graph convolutions, and then uses stacked Transformer encoders to capture person interactions that are important for action recognition in general scenarios. To mitigate the negative impact of inaccurate skeleton associations, SkeleTR takes relative short skeleton sequences as input and increases the number of sequences. As a unified solution, SkeleTR can be directly applied to multiple skeleton-based action tasks, including video-level action classification, instance-level action detection, and group-level activity recognition. It also enables transfer learning and joint training across different action tasks and datasets, which result in performance improvement. When evaluated on various skeleton-based action recognition benchmarks, SkeleTR achieves the state-of-the-art performance.","sentences":["We present SkeleTR, a new framework for skeleton-based action recognition.","In contrast to prior work, which focuses mainly on controlled environments, we target more general scenarios that typically involve a variable number of people and various forms of interaction between people.","SkeleTR works with a two-stage paradigm.","It first models the intra-person skeleton dynamics for each skeleton sequence with graph convolutions, and then uses stacked Transformer encoders to capture person interactions that are important for action recognition in general scenarios.","To mitigate the negative impact of inaccurate skeleton associations, SkeleTR takes relative short skeleton sequences as input and increases the number of sequences.","As a unified solution, SkeleTR can be directly applied to multiple skeleton-based action tasks, including video-level action classification, instance-level action detection, and group-level activity recognition.","It also enables transfer learning and joint training across different action tasks and datasets, which result in performance improvement.","When evaluated on various skeleton-based action recognition benchmarks, SkeleTR achieves the state-of-the-art performance."],"url":"http://arxiv.org/abs/2309.11445v1"}
{"created":"2023-09-20 16:17:26","title":"Signature Activation: A Sparse Signal View for Holistic Saliency","abstract":"The adoption of machine learning in healthcare calls for model transparency and explainability. In this work, we introduce Signature Activation, a saliency method that generates holistic and class-agnostic explanations for Convolutional Neural Network (CNN) outputs. Our method exploits the fact that certain kinds of medical images, such as angiograms, have clear foreground and background objects. We give theoretical explanation to justify our methods. We show the potential use of our method in clinical settings through evaluating its efficacy for aiding the detection of lesions in coronary angiograms.","sentences":["The adoption of machine learning in healthcare calls for model transparency and explainability.","In this work, we introduce Signature Activation, a saliency method that generates holistic and class-agnostic explanations for Convolutional Neural Network (CNN) outputs.","Our method exploits the fact that certain kinds of medical images, such as angiograms, have clear foreground and background objects.","We give theoretical explanation to justify our methods.","We show the potential use of our method in clinical settings through evaluating its efficacy for aiding the detection of lesions in coronary angiograms."],"url":"http://arxiv.org/abs/2309.11443v1"}
{"created":"2023-09-20 16:14:10","title":"Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction","abstract":"In Grammatical Error Correction (GEC), it is crucial to ensure the user's comprehension of a reason for correction. Existing studies present tokens, examples, and hints as to the basis for correction but do not directly explain the reasons for corrections. Although methods that use Large Language Models (LLMs) to provide direct explanations in natural language have been proposed for various tasks, no such method exists for GEC. Generating explanations for GEC corrections involves aligning input and output tokens, identifying correction points, and presenting corresponding explanations consistently. However, it is not straightforward to specify a complex format to generate explanations, because explicit control of generation is difficult with prompts. This study introduces a method called controlled generation with Prompt Insertion (PI) so that LLMs can explain the reasons for corrections in natural language. In PI, LLMs first correct the input text, and then we automatically extract the correction points based on the rules. The extracted correction points are sequentially inserted into the LLM's explanation output as prompts, guiding the LLMs to generate explanations for the correction points. We also create an Explainable GEC (XGEC) dataset of correction reasons by annotating NUCLE, CoNLL2013, and CoNLL2014. Although generations from GPT-3 and ChatGPT using original prompts miss some correction points, the generation control using PI can explicitly guide to describe explanations for all correction points, contributing to improved performance in generating correction reasons.","sentences":["In Grammatical Error Correction (GEC), it is crucial to ensure the user's comprehension of a reason for correction.","Existing studies present tokens, examples, and hints as to the basis for correction but do not directly explain the reasons for corrections.","Although methods that use Large Language Models (LLMs) to provide direct explanations in natural language have been proposed for various tasks, no such method exists for GEC.","Generating explanations for GEC corrections involves aligning input and output tokens, identifying correction points, and presenting corresponding explanations consistently.","However, it is not straightforward to specify a complex format to generate explanations, because explicit control of generation is difficult with prompts.","This study introduces a method called controlled generation with Prompt Insertion (PI) so that LLMs can explain the reasons for corrections in natural language.","In PI, LLMs first correct the input text, and then we automatically extract the correction points based on the rules.","The extracted correction points are sequentially inserted into the LLM's explanation output as prompts, guiding the LLMs to generate explanations for the correction points.","We also create an Explainable GEC (XGEC) dataset of correction reasons by annotating NUCLE, CoNLL2013, and CoNLL2014.","Although generations from GPT-3 and ChatGPT using original prompts miss some correction points, the generation control using PI can explicitly guide to describe explanations for all correction points, contributing to improved performance in generating correction reasons."],"url":"http://arxiv.org/abs/2309.11439v1"}
{"created":"2023-09-20 16:12:32","title":"You Only Look at Screens: Multimodal Chain-of-Action Agents","abstract":"Autonomous user interface (UI) agents aim to facilitate task automation by interacting with the user interface without manual intervention. Recent studies have investigated eliciting the capabilities of large language models (LLMs) for effective engagement in diverse environments. To align with the input-output requirement of LLMs, existing approaches are developed under a sandbox setting where they rely on external tools and application-specific APIs to parse the environment into textual elements and interpret the predicted actions. Consequently, those approaches often grapple with inference inefficiency and error propagation risks. To mitigate the challenges, we introduce Auto-UI, a multimodal solution that directly interacts with the interface, bypassing the need for environment parsing or reliance on application-dependent APIs. Moreover, we propose a chain-of-action technique -- leveraging a series of intermediate previous action histories and future action plans -- to help the agent decide what action to execute. We evaluate our approach on a new device-control benchmark AITW with 30K unique instructions, spanning multi-step tasks such as application operation, web searching, and web shopping. Experimental results show that Auto-UI achieves state-of-the-art performance with an action type prediction accuracy of 90% and an overall action success rate of 74%. Code is publicly available at https://github.com/cooelf/Auto-UI.","sentences":["Autonomous user interface (UI) agents aim to facilitate task automation by interacting with the user interface without manual intervention.","Recent studies have investigated eliciting the capabilities of large language models (LLMs) for effective engagement in diverse environments.","To align with the input-output requirement of LLMs, existing approaches are developed under a sandbox setting where they rely on external tools and application-specific APIs to parse the environment into textual elements and interpret the predicted actions.","Consequently, those approaches often grapple with inference inefficiency and error propagation risks.","To mitigate the challenges, we introduce Auto-UI, a multimodal solution that directly interacts with the interface, bypassing the need for environment parsing or reliance on application-dependent APIs.","Moreover, we propose a chain-of-action technique -- leveraging a series of intermediate previous action histories and future action plans -- to help the agent decide what action to execute.","We evaluate our approach on a new device-control benchmark AITW with 30K unique instructions, spanning multi-step tasks such as application operation, web searching, and web shopping.","Experimental results show that Auto-UI achieves state-of-the-art performance with an action type prediction accuracy of 90% and an overall action success rate of 74%.","Code is publicly available at https://github.com/cooelf/Auto-UI."],"url":"http://arxiv.org/abs/2309.11436v1"}
{"created":"2023-09-20 16:10:53","title":"A Systematic Review of Few-Shot Learning in Medical Imaging","abstract":"The lack of annotated medical images limits the performance of deep learning models, which usually need large-scale labelled datasets. Few-shot learning techniques can reduce data scarcity issues and enhance medical image analysis, especially with meta-learning. This systematic review gives a comprehensive overview of few-shot learning in medical imaging. We searched the literature systematically and selected 80 relevant articles published from 2018 to 2023. We clustered the articles based on medical outcomes, such as tumour segmentation, disease classification, and image registration; anatomical structure investigated (i.e. heart, lung, etc.); and the meta-learning method used. For each cluster, we examined the papers' distributions and the results provided by the state-of-the-art. In addition, we identified a generic pipeline shared among all the studies. The review shows that few-shot learning can overcome data scarcity in most outcomes and that meta-learning is a popular choice to perform few-shot learning because it can adapt to new tasks with few labelled samples. In addition, following meta-learning, supervised learning and semi-supervised learning stand out as the predominant techniques employed to tackle few-shot learning challenges in medical imaging and also best performing. Lastly, we observed that the primary application areas predominantly encompass cardiac, pulmonary, and abdominal domains. This systematic review aims to inspire further research to improve medical image analysis and patient care.","sentences":["The lack of annotated medical images limits the performance of deep learning models, which usually need large-scale labelled datasets.","Few-shot learning techniques can reduce data scarcity issues and enhance medical image analysis, especially with meta-learning.","This systematic review gives a comprehensive overview of few-shot learning in medical imaging.","We searched the literature systematically and selected 80 relevant articles published from 2018 to 2023.","We clustered the articles based on medical outcomes, such as tumour segmentation, disease classification, and image registration; anatomical structure investigated (i.e. heart, lung, etc.); and the meta-learning method used.","For each cluster, we examined the papers' distributions and the results provided by the state-of-the-art.","In addition, we identified a generic pipeline shared among all the studies.","The review shows that few-shot learning can overcome data scarcity in most outcomes and that meta-learning is a popular choice to perform few-shot learning because it can adapt to new tasks with few labelled samples.","In addition, following meta-learning, supervised learning and semi-supervised learning stand out as the predominant techniques employed to tackle few-shot learning challenges in medical imaging and also best performing.","Lastly, we observed that the primary application areas predominantly encompass cardiac, pulmonary, and abdominal domains.","This systematic review aims to inspire further research to improve medical image analysis and patient care."],"url":"http://arxiv.org/abs/2309.11433v1"}
{"created":"2023-09-20 16:01:45","title":"Generative Pre-Training of Time-Series Data for Unsupervised Fault Detection in Semiconductor Manufacturing","abstract":"This paper introduces TRACE-GPT, which stands for Time-seRies Anomaly-detection with Convolutional Embedding and Generative Pre-trained Transformers. TRACE-GPT is designed to pre-train univariate time-series sensor data and detect faults on unlabeled datasets in semiconductor manufacturing. In semiconductor industry, classifying abnormal time-series sensor data from normal data is important because it is directly related to wafer defect. However, small, unlabeled, and even mixed training data without enough anomalies make classification tasks difficult. In this research, we capture features of time-series data with temporal convolutional embedding and Generative Pre-trained Transformer (GPT) to classify abnormal sequences from normal sequences using cross entropy loss. We prove that our model shows better performance than previous unsupervised models with both an open dataset, the University of California Riverside (UCR) time-series classification archive, and the process log of our Chemical Vapor Deposition (CVD) equipment. Our model has the highest F1 score at Equal Error Rate (EER) across all datasets and is only 0.026 below the supervised state-of-the-art baseline on the open dataset.","sentences":["This paper introduces TRACE-GPT, which stands for Time-seRies Anomaly-detection with Convolutional Embedding and Generative Pre-trained Transformers.","TRACE-GPT is designed to pre-train univariate time-series sensor data and detect faults on unlabeled datasets in semiconductor manufacturing.","In semiconductor industry, classifying abnormal time-series sensor data from normal data is important because it is directly related to wafer defect.","However, small, unlabeled, and even mixed training data without enough anomalies make classification tasks difficult.","In this research, we capture features of time-series data with temporal convolutional embedding and Generative Pre-trained Transformer (GPT) to classify abnormal sequences from normal sequences using cross entropy loss.","We prove that our model shows better performance than previous unsupervised models with both an open dataset, the University of California Riverside (UCR) time-series classification archive, and the process log of our Chemical Vapor Deposition (CVD) equipment.","Our model has the highest F1 score at Equal Error Rate (EER) across all datasets and is only 0.026 below the supervised state-of-the-art baseline on the open dataset."],"url":"http://arxiv.org/abs/2309.11427v1"}
{"created":"2023-09-20 15:51:10","title":"Deep Networks as Denoising Algorithms: Sample-Efficient Learning of Diffusion Models in High-Dimensional Graphical Models","abstract":"We investigate the approximation efficiency of score functions by deep neural networks in diffusion-based generative modeling. While existing approximation theories utilize the smoothness of score functions, they suffer from the curse of dimensionality for intrinsically high-dimensional data. This limitation is pronounced in graphical models such as Markov random fields, common for image distributions, where the approximation efficiency of score functions remains unestablished.   To address this, we observe score functions can often be well-approximated in graphical models through variational inference denoising algorithms. Furthermore, these algorithms are amenable to efficient neural network representation. We demonstrate this in examples of graphical models, including Ising models, conditional Ising models, restricted Boltzmann machines, and sparse encoding models. Combined with off-the-shelf discretization error bounds for diffusion-based sampling, we provide an efficient sample complexity bound for diffusion-based generative modeling when the score function is learned by deep neural networks.","sentences":["We investigate the approximation efficiency of score functions by deep neural networks in diffusion-based generative modeling.","While existing approximation theories utilize the smoothness of score functions, they suffer from the curse of dimensionality for intrinsically high-dimensional data.","This limitation is pronounced in graphical models such as Markov random fields, common for image distributions, where the approximation efficiency of score functions remains unestablished.   ","To address this, we observe score functions can often be well-approximated in graphical models through variational inference denoising algorithms.","Furthermore, these algorithms are amenable to efficient neural network representation.","We demonstrate this in examples of graphical models, including Ising models, conditional Ising models, restricted Boltzmann machines, and sparse encoding models.","Combined with off-the-shelf discretization error bounds for diffusion-based sampling, we provide an efficient sample complexity bound for diffusion-based generative modeling when the score function is learned by deep neural networks."],"url":"http://arxiv.org/abs/2309.11420v1"}
{"created":"2023-09-20 15:50:08","title":"Kosmos-2.5: A Multimodal Literate Model","abstract":"We present Kosmos-2.5, a multimodal literate model for machine reading of text-intensive images. Pre-trained on large-scale text-intensive images, Kosmos-2.5 excels in two distinct yet cooperative transcription tasks: (1) generating spatially-aware text blocks, where each block of text is assigned its spatial coordinates within the image, and (2) producing structured text output that captures styles and structures into the markdown format. This unified multimodal literate capability is achieved through a shared Transformer architecture, task-specific prompts, and flexible text representations. We evaluate Kosmos-2.5 on end-to-end document-level text recognition and image-to-markdown text generation. Furthermore, the model can be readily adapted for any text-intensive image understanding task with different prompts through supervised fine-tuning, making it a general-purpose tool for real-world applications involving text-rich images. This work also paves the way for the future scaling of multimodal large language models.","sentences":["We present Kosmos-2.5, a multimodal literate model for machine reading of text-intensive images.","Pre-trained on large-scale text-intensive images, Kosmos-2.5 excels in two distinct yet cooperative transcription tasks: (1) generating spatially-aware text blocks, where each block of text is assigned its spatial coordinates within the image, and (2) producing structured text output that captures styles and structures into the markdown format.","This unified multimodal literate capability is achieved through a shared Transformer architecture, task-specific prompts, and flexible text representations.","We evaluate Kosmos-2.5 on end-to-end document-level text recognition and image-to-markdown text generation.","Furthermore, the model can be readily adapted for any text-intensive image understanding task with different prompts through supervised fine-tuning, making it a general-purpose tool for real-world applications involving text-rich images.","This work also paves the way for the future scaling of multimodal large language models."],"url":"http://arxiv.org/abs/2309.11419v1"}
{"created":"2023-09-20 15:49:38","title":"CNNs for JPEGs: A Study in Computational Cost","abstract":"Convolutional neural networks (CNNs) have achieved astonishing advances over the past decade, defining state-of-the-art in several computer vision tasks. CNNs are capable of learning robust representations of the data directly from the RGB pixels. However, most image data are usually available in compressed format, from which the JPEG is the most widely used due to transmission and storage purposes demanding a preliminary decoding process that have a high computational load and memory usage. For this reason, deep learning methods capable of learning directly from the compressed domain have been gaining attention in recent years. Those methods usually extract a frequency domain representation of the image, like DCT, by a partial decoding, and then make adaptation to typical CNNs architectures to work with them. One limitation of these current works is that, in order to accommodate the frequency domain data, the modifications made to the original model increase significantly their amount of parameters and computational complexity. On one hand, the methods have faster preprocessing, since the cost of fully decoding the images is avoided, but on the other hand, the cost of passing the images though the model is increased, mitigating the possible upside of accelerating the method. In this paper, we propose a further study of the computational cost of deep models designed for the frequency domain, evaluating the cost of decoding and passing the images through the network. We also propose handcrafted and data-driven techniques for reducing the computational complexity and the number of parameters for these models in order to keep them similar to their RGB baselines, leading to efficient models with a better trade off between computational cost and accuracy.","sentences":["Convolutional neural networks (CNNs) have achieved astonishing advances over the past decade, defining state-of-the-art in several computer vision tasks.","CNNs are capable of learning robust representations of the data directly from the RGB pixels.","However, most image data are usually available in compressed format, from which the JPEG is the most widely used due to transmission and storage purposes demanding a preliminary decoding process that have a high computational load and memory usage.","For this reason, deep learning methods capable of learning directly from the compressed domain have been gaining attention in recent years.","Those methods usually extract a frequency domain representation of the image, like DCT, by a partial decoding, and then make adaptation to typical CNNs architectures to work with them.","One limitation of these current works is that, in order to accommodate the frequency domain data, the modifications made to the original model increase significantly their amount of parameters and computational complexity.","On one hand, the methods have faster preprocessing, since the cost of fully decoding the images is avoided, but on the other hand, the cost of passing the images though the model is increased, mitigating the possible upside of accelerating the method.","In this paper, we propose a further study of the computational cost of deep models designed for the frequency domain, evaluating the cost of decoding and passing the images through the network.","We also propose handcrafted and data-driven techniques for reducing the computational complexity and the number of parameters for these models in order to keep them similar to their RGB baselines, leading to efficient models with a better trade off between computational cost and accuracy."],"url":"http://arxiv.org/abs/2309.11417v1"}
{"created":"2023-09-20 15:40:32","title":"EDMP: Ensemble-of-costs-guided Diffusion for Motion Planning","abstract":"Classical motion planning for robotic manipulation includes a set of general algorithms that aim to minimize a scene-specific cost of executing a given plan. This approach offers remarkable adaptability, as they can be directly used off-the-shelf for any new scene without needing specific training datasets. However, without a prior understanding of what diverse valid trajectories are and without specially designed cost functions for a given scene, the overall solutions tend to have low success rates. While deep-learning-based algorithms tremendously improve success rates, they are much harder to adopt without specialized training datasets. We propose EDMP, an Ensemble-of-costs-guided Diffusion for Motion Planning that aims to combine the strengths of classical and deep-learning-based motion planning. Our diffusion-based network is trained on a set of diverse kinematically valid trajectories. Like classical planning, for any new scene at the time of inference, we compute scene-specific costs such as \"collision cost\" and guide the diffusion to generate valid trajectories that satisfy the scene-specific constraints. Further, instead of a single cost function that may be insufficient in capturing diversity across scenes, we use an ensemble of costs to guide the diffusion process, significantly improving the success rate compared to classical planners. EDMP performs comparably with SOTA deep-learning-based methods while retaining the generalization capabilities primarily associated with classical planners.","sentences":["Classical motion planning for robotic manipulation includes a set of general algorithms that aim to minimize a scene-specific cost of executing a given plan.","This approach offers remarkable adaptability, as they can be directly used off-the-shelf for any new scene without needing specific training datasets.","However, without a prior understanding of what diverse valid trajectories are and without specially designed cost functions for a given scene, the overall solutions tend to have low success rates.","While deep-learning-based algorithms tremendously improve success rates, they are much harder to adopt without specialized training datasets.","We propose EDMP, an Ensemble-of-costs-guided Diffusion for Motion Planning that aims to combine the strengths of classical and deep-learning-based motion planning.","Our diffusion-based network is trained on a set of diverse kinematically valid trajectories.","Like classical planning, for any new scene at the time of inference, we compute scene-specific costs such as \"collision cost\" and guide the diffusion to generate valid trajectories that satisfy the scene-specific constraints.","Further, instead of a single cost function that may be insufficient in capturing diversity across scenes, we use an ensemble of costs to guide the diffusion process, significantly improving the success rate compared to classical planners.","EDMP performs comparably with SOTA deep-learning-based methods while retaining the generalization capabilities primarily associated with classical planners."],"url":"http://arxiv.org/abs/2309.11414v1"}
{"created":"2023-09-20 15:40:22","title":"Enhancing motion trajectory segmentation of rigid bodies using a novel screw-based trajectory-shape representation","abstract":"Trajectory segmentation refers to dividing a trajectory into meaningful consecutive sub-trajectories. This paper focuses on trajectory segmentation for 3D rigid-body motions. Most segmentation approaches in the literature represent the body's trajectory as a point trajectory, considering only its translation and neglecting its rotation. We propose a novel trajectory representation for rigid-body motions that incorporates both translation and rotation, and additionally exhibits several invariant properties. This representation consists of a geometric progress rate and a third-order trajectory-shape descriptor. Concepts from screw theory were used to make this representation time-invariant and also invariant to the choice of body reference point. This new representation is validated for a self-supervised segmentation approach, both in simulation and using real recordings of human-demonstrated pouring motions. The results show a more robust detection of consecutive submotions with distinct features and a more consistent segmentation compared to conventional representations. We believe that other existing segmentation methods may benefit from using this trajectory representation to improve their invariance.","sentences":["Trajectory segmentation refers to dividing a trajectory into meaningful consecutive sub-trajectories.","This paper focuses on trajectory segmentation for 3D rigid-body motions.","Most segmentation approaches in the literature represent the body's trajectory as a point trajectory, considering only its translation and neglecting its rotation.","We propose a novel trajectory representation for rigid-body motions that incorporates both translation and rotation, and additionally exhibits several invariant properties.","This representation consists of a geometric progress rate and a third-order trajectory-shape descriptor.","Concepts from screw theory were used to make this representation time-invariant and also invariant to the choice of body reference point.","This new representation is validated for a self-supervised segmentation approach, both in simulation and using real recordings of human-demonstrated pouring motions.","The results show a more robust detection of consecutive submotions with distinct features and a more consistent segmentation compared to conventional representations.","We believe that other existing segmentation methods may benefit from using this trajectory representation to improve their invariance."],"url":"http://arxiv.org/abs/2309.11413v1"}
{"created":"2023-09-20 15:32:36","title":"Swarm Mechanics and Swarm Chemistry: A Transdisciplinary Approach for Robot Swarms","abstract":"This paper for the first time attempts to bridge the knowledge between chemistry, fluid mechanics, and robot swarms. By forming these connections, we attempt to leverage established methodologies and tools from these these domains to uncover how we can better comprehend swarms. The focus of this paper is in presenting a new framework and sharing the reasons we find it promising and exciting. While the exact methods are still under development, we believe simply laying out a potential path towards solutions that have evaded our traditional methods using a novel method is worth considering. Our results are characterized through both simulations and real experiments on ground robots.","sentences":["This paper for the first time attempts to bridge the knowledge between chemistry, fluid mechanics, and robot swarms.","By forming these connections, we attempt to leverage established methodologies and tools from these these domains to uncover how we can better comprehend swarms.","The focus of this paper is in presenting a new framework and sharing the reasons we find it promising and exciting.","While the exact methods are still under development, we believe simply laying out a potential path towards solutions that have evaded our traditional methods using a novel method is worth considering.","Our results are characterized through both simulations and real experiments on ground robots."],"url":"http://arxiv.org/abs/2309.11408v1"}
{"created":"2023-09-20 15:30:22","title":"Live & Local Schema Change: Challenge Problems","abstract":"Schema change is an unsolved problem in both live programming and local-first software. We include in schema change any change to the expected shape of data, whether that is expressed explicitly in a database schema or type system, or whether those expectations are implicit in the behavior of the code. Schema changes during live programming can create a mismatch between the code and data in the running environment. Similarly, schema changes in local-first programming can create mismatches between data in different replicas, and between data in a replica and the code colocated with it. In all of these situations the problem of schema change is to migrate or translate existing data in coordination with changes to the code.   This paper contributes a set of concrete scenarios involving schema change that are offered as challenge problems to the live programming and local-first communities. We hope that these problems will spur progress by providing concrete objectives and a basis for comparing alternative solutions.","sentences":["Schema change is an unsolved problem in both live programming and local-first software.","We include in schema change any change to the expected shape of data, whether that is expressed explicitly in a database schema or type system, or whether those expectations are implicit in the behavior of the code.","Schema changes during live programming can create a mismatch between the code and data in the running environment.","Similarly, schema changes in local-first programming can create mismatches between data in different replicas, and between data in a replica and the code colocated with it.","In all of these situations the problem of schema change is to migrate or translate existing data in coordination with changes to the code.   ","This paper contributes a set of concrete scenarios involving schema change that are offered as challenge problems to the live programming and local-first communities.","We hope that these problems will spur progress by providing concrete objectives and a basis for comparing alternative solutions."],"url":"http://arxiv.org/abs/2309.11406v1"}
{"created":"2023-09-20 15:18:21","title":"Is Ethereum Proof of Stake Sustainable? $-$ Considering from the Perspective of Competition Among Smart Contract Platforms $-$","abstract":"Since the Merge update upon which Ethereum transitioned to Proof of Stake, it has been touted that it resulted in lower power consumption and increased security. However, even if that is the case, can this state be sustained?   In this paper, we focus on the potential impact of competition with other smart contract platforms on the price of Ethereum's native currency, Ether (ETH), thereby raising questions about the safety and sustainability purportedly brought about by the design of Proof of Stake.","sentences":["Since the Merge update upon which Ethereum transitioned to Proof of Stake, it has been touted that it resulted in lower power consumption and increased security.","However, even if that is the case, can this state be sustained?   ","In this paper, we focus on the potential impact of competition with other smart contract platforms on the price of Ethereum's native currency, Ether (ETH), thereby raising questions about the safety and sustainability purportedly brought about by the design of Proof of Stake."],"url":"http://arxiv.org/abs/2309.11394v1"}
{"created":"2023-09-20 15:16:42","title":"Retrieving Supporting Evidence for Generative Question Answering","abstract":"Current large language models (LLMs) can exhibit near-human levels of performance on many natural language-based tasks, including open-domain question answering. Unfortunately, at this time, they also convincingly hallucinate incorrect answers, so that responses to questions must be verified against external sources before they can be accepted at face value. In this paper, we report two simple experiments to automatically validate generated answers against a corpus. We base our experiments on questions and passages from the MS MARCO (V1) test collection, and a retrieval pipeline consisting of sparse retrieval, dense retrieval and neural rerankers. In the first experiment, we validate the generated answer in its entirety. After presenting a question to an LLM and receiving a generated answer, we query the corpus with the combination of the question + generated answer. We then present the LLM with the combination of the question + generated answer + retrieved answer, prompting it to indicate if the generated answer can be supported by the retrieved answer. In the second experiment, we consider the generated answer at a more granular level, prompting the LLM to extract a list of factual statements from the answer and verifying each statement separately. We query the corpus with each factual statement and then present the LLM with the statement and the corresponding retrieved evidence. The LLM is prompted to indicate if the statement can be supported and make necessary edits using the retrieved material. With an accuracy of over 80%, we find that an LLM is capable of verifying its generated answer when a corpus of supporting material is provided. However, manual assessment of a random sample of questions reveals that incorrect generated answers are missed by this verification process. While this verification process can reduce hallucinations, it can not entirely eliminate them.","sentences":["Current large language models (LLMs) can exhibit near-human levels of performance on many natural language-based tasks, including open-domain question answering.","Unfortunately, at this time, they also convincingly hallucinate incorrect answers, so that responses to questions must be verified against external sources before they can be accepted at face value.","In this paper, we report two simple experiments to automatically validate generated answers against a corpus.","We base our experiments on questions and passages from the MS MARCO (V1) test collection, and a retrieval pipeline consisting of sparse retrieval, dense retrieval and neural rerankers.","In the first experiment, we validate the generated answer in its entirety.","After presenting a question to an LLM and receiving a generated answer, we query the corpus with the combination of the question + generated answer.","We then present the LLM with the combination of the question + generated answer + retrieved answer, prompting it to indicate if the generated answer can be supported by the retrieved answer.","In the second experiment, we consider the generated answer at a more granular level, prompting the LLM to extract a list of factual statements from the answer and verifying each statement separately.","We query the corpus with each factual statement and then present the LLM with the statement and the corresponding retrieved evidence.","The LLM is prompted to indicate if the statement can be supported and make necessary edits using the retrieved material.","With an accuracy of over 80%, we find that an LLM is capable of verifying its generated answer when a corpus of supporting material is provided.","However, manual assessment of a random sample of questions reveals that incorrect generated answers are missed by this verification process.","While this verification process can reduce hallucinations, it can not entirely eliminate them."],"url":"http://arxiv.org/abs/2309.11392v1"}
{"created":"2023-09-20 15:15:21","title":"Level set-fitted polytopal meshes with application to structural topology optimization","abstract":"We propose a method to modify a polygonal mesh in order to fit the zero-isoline of a level set function by extending a standard body-fitted strategy to a tessellation with arbitrarily-shaped elements. The novel level set-fitted approach, in combination with a Discontinuous Galerkin finite element approximation, provides an ideal setting to model physical problems characterized by embedded or evolving complex geometries, since it allows skipping any mesh post-processing in terms of grid quality. The proposed methodology is firstly assessed on the linear elasticity equation, by verifying the approximation capability of the level set-fitted approach when dealing with configurations with heterogeneous material properties. Successively, we combine the level set-fitted methodology with a minimum compliance topology optimization technique, in order to deliver optimized layouts exhibiting crisp boundaries and reliable mechanical performances. An extensive numerical test campaign confirms the effectiveness of the proposed method.","sentences":["We propose a method to modify a polygonal mesh in order to fit the zero-isoline of a level set function by extending a standard body-fitted strategy to a tessellation with arbitrarily-shaped elements.","The novel level set-fitted approach, in combination with a Discontinuous Galerkin finite element approximation, provides an ideal setting to model physical problems characterized by embedded or evolving complex geometries, since it allows skipping any mesh post-processing in terms of grid quality.","The proposed methodology is firstly assessed on the linear elasticity equation, by verifying the approximation capability of the level set-fitted approach when dealing with configurations with heterogeneous material properties.","Successively, we combine the level set-fitted methodology with a minimum compliance topology optimization technique, in order to deliver optimized layouts exhibiting crisp boundaries and reliable mechanical performances.","An extensive numerical test campaign confirms the effectiveness of the proposed method."],"url":"http://arxiv.org/abs/2309.11389v1"}
{"created":"2023-09-20 15:11:32","title":"Safurai 001: New Qualitative Approach for Code LLM Evaluation","abstract":"This paper presents Safurai-001, a new Large Language Model (LLM) with significant potential in the domain of coding assistance. Driven by recent advancements in coding LLMs, Safurai-001 competes in performance with the latest models like WizardCoder [Xu et al., 2023], PanguCoder [Shen et al., 2023] and Phi-1 [Gunasekar et al., 2023] but aims to deliver a more conversational interaction. By capitalizing on the progress in data engineering (including latest techniques of data transformation and prompt engineering) and instruction tuning, this new model promises to stand toe-to-toe with recent closed and open source developments. Recognizing the need for an efficacious evaluation metric for coding LLMs, this paper also introduces GPT4-based MultiParameters, an evaluation benchmark that harnesses varied parameters to present a comprehensive insight into the models functioning and performance. Our assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and WizardCoder by 18.78% in the Code Readability parameter and more.","sentences":["This paper presents Safurai-001, a new Large Language Model (LLM) with significant potential in the domain of coding assistance.","Driven by recent advancements in coding LLMs, Safurai-001 competes in performance with the latest models like WizardCoder","[Xu et al., 2023], PanguCoder","[Shen et al., 2023] and Phi-1","[Gunasekar et al., 2023] but aims to deliver a more conversational interaction.","By capitalizing on the progress in data engineering (including latest techniques of data transformation and prompt engineering) and instruction tuning, this new model promises to stand toe-to-toe with recent closed and open source developments.","Recognizing the need for an efficacious evaluation metric for coding LLMs, this paper also introduces GPT4-based MultiParameters, an evaluation benchmark that harnesses varied parameters to present a comprehensive insight into the models functioning and performance.","Our assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and WizardCoder by 18.78% in the Code Readability parameter and more."],"url":"http://arxiv.org/abs/2309.11385v1"}
{"created":"2023-09-20 15:10:12","title":"Long-Form End-to-End Speech Translation via Latent Alignment Segmentation","abstract":"Current simultaneous speech translation models can process audio only up to a few seconds long. Contemporary datasets provide an oracle segmentation into sentences based on human-annotated transcripts and translations. However, the segmentation into sentences is not available in the real world. Current speech segmentation approaches either offer poor segmentation quality or have to trade latency for quality. In this paper, we propose a novel segmentation approach for a low-latency end-to-end speech translation. We leverage the existing speech translation encoder-decoder architecture with ST CTC and show that it can perform the segmentation task without supervision or additional parameters. To the best of our knowledge, our method is the first that allows an actual end-to-end simultaneous speech translation, as the same model is used for translation and segmentation at the same time. On a diverse set of language pairs and in- and out-of-domain data, we show that the proposed approach achieves state-of-the-art quality at no additional computational cost.","sentences":["Current simultaneous speech translation models can process audio only up to a few seconds long.","Contemporary datasets provide an oracle segmentation into sentences based on human-annotated transcripts and translations.","However, the segmentation into sentences is not available in the real world.","Current speech segmentation approaches either offer poor segmentation quality or have to trade latency for quality.","In this paper, we propose a novel segmentation approach for a low-latency end-to-end speech translation.","We leverage the existing speech translation encoder-decoder architecture with ST CTC and show that it can perform the segmentation task without supervision or additional parameters.","To the best of our knowledge, our method is the first that allows an actual end-to-end simultaneous speech translation, as the same model is used for translation and segmentation at the same time.","On a diverse set of language pairs and in- and out-of-domain data, we show that the proposed approach achieves state-of-the-art quality at no additional computational cost."],"url":"http://arxiv.org/abs/2309.11384v1"}
{"created":"2023-09-20 15:04:49","title":"Discuss Before Moving: Visual Language Navigation via Multi-expert Discussions","abstract":"Visual language navigation (VLN) is an embodied task demanding a wide range of skills encompassing understanding, perception, and planning. For such a multifaceted challenge, previous VLN methods totally rely on one model's own thinking to make predictions within one round. However, existing models, even the most advanced large language model GPT4, still struggle with dealing with multiple tasks by single-round self-thinking. In this work, drawing inspiration from the expert consultation meeting, we introduce a novel zero-shot VLN framework. Within this framework, large models possessing distinct abilities are served as domain experts. Our proposed navigation agent, namely DiscussNav, can actively discuss with these experts to collect essential information before moving at every step. These discussions cover critical navigation subtasks like instruction understanding, environment perception, and completion estimation. Through comprehensive experiments, we demonstrate that discussions with domain experts can effectively facilitate navigation by perceiving instruction-relevant information, correcting inadvertent errors, and sifting through in-consistent movement decisions. The performances on the representative VLN task R2R show that our method surpasses the leading zero-shot VLN model by a large margin on all metrics. Additionally, real-robot experiments display the obvious advantages of our method over single-round self-thinking.","sentences":["Visual language navigation (VLN) is an embodied task demanding a wide range of skills encompassing understanding, perception, and planning.","For such a multifaceted challenge, previous VLN methods totally rely on one model's own thinking to make predictions within one round.","However, existing models, even the most advanced large language model GPT4, still struggle with dealing with multiple tasks by single-round self-thinking.","In this work, drawing inspiration from the expert consultation meeting, we introduce a novel zero-shot VLN framework.","Within this framework, large models possessing distinct abilities are served as domain experts.","Our proposed navigation agent, namely DiscussNav, can actively discuss with these experts to collect essential information before moving at every step.","These discussions cover critical navigation subtasks like instruction understanding, environment perception, and completion estimation.","Through comprehensive experiments, we demonstrate that discussions with domain experts can effectively facilitate navigation by perceiving instruction-relevant information, correcting inadvertent errors, and sifting through in-consistent movement decisions.","The performances on the representative VLN task R2R show that our method surpasses the leading zero-shot VLN model by a large margin on all metrics.","Additionally, real-robot experiments display the obvious advantages of our method over single-round self-thinking."],"url":"http://arxiv.org/abs/2309.11382v1"}
{"created":"2023-09-20 15:03:30","title":"Studying Lobby Influence in the European Parliament","abstract":"We present a method based on natural language processing (NLP), for studying the influence of interest groups (lobbies) in the law-making process in the European Parliament (EP). We collect and analyze novel datasets of lobbies' position papers and speeches made by members of the EP (MEPs). By comparing these texts on the basis of semantic similarity and entailment, we are able to discover interpretable links between MEPs and lobbies. In the absence of a ground-truth dataset of such links, we perform an indirect validation by comparing the discovered links with a dataset, which we curate, of retweet links between MEPs and lobbies, and with the publicly disclosed meetings of MEPs. Our best method achieves an AUC score of 0.77 and performs significantly better than several baselines. Moreover, an aggregate analysis of the discovered links, between groups of related lobbies and political groups of MEPs, correspond to the expectations from the ideology of the groups (e.g., center-left groups are associated with social causes). We believe that this work, which encompasses the methodology, datasets, and results, is a step towards enhancing the transparency of the intricate decision-making processes within democratic institutions.","sentences":["We present a method based on natural language processing (NLP), for studying the influence of interest groups (lobbies) in the law-making process in the European Parliament (EP).","We collect and analyze novel datasets of lobbies' position papers and speeches made by members of the EP (MEPs).","By comparing these texts on the basis of semantic similarity and entailment, we are able to discover interpretable links between MEPs and lobbies.","In the absence of a ground-truth dataset of such links, we perform an indirect validation by comparing the discovered links with a dataset, which we curate, of retweet links between MEPs and lobbies, and with the publicly disclosed meetings of MEPs.","Our best method achieves an AUC score of 0.77 and performs significantly better than several baselines.","Moreover, an aggregate analysis of the discovered links, between groups of related lobbies and political groups of MEPs, correspond to the expectations from the ideology of the groups (e.g., center-left groups are associated with social causes).","We believe that this work, which encompasses the methodology, datasets, and results, is a step towards enhancing the transparency of the intricate decision-making processes within democratic institutions."],"url":"http://arxiv.org/abs/2309.11381v1"}
{"created":"2023-09-20 14:59:06","title":"Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff","abstract":"Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \\textit{incremental} translation to users. Further, this method lacks mechanisms for \\textit{controlling} the quality vs. latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode.   Experimental results on MuST-C show 0.6-3.6 BLEU improvement without changing latency or 0.8-1.4 s latency improvement without changing quality.","sentences":["Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation.","These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further.","However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \\textit{incremental} translation to users.","Further, this method lacks mechanisms for \\textit{controlling} the quality vs. latency tradeoff.","We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control.","We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode.   ","Experimental results on MuST-C show 0.6-3.6 BLEU improvement without changing latency or 0.8-1.4 s latency improvement without changing quality."],"url":"http://arxiv.org/abs/2309.11379v1"}
{"created":"2023-09-20 14:58:47","title":"Preconditioned Federated Learning","abstract":"Federated Learning (FL) is a distributed machine learning approach that enables model training in communication efficient and privacy-preserving manner. The standard optimization method in FL is Federated Averaging (FedAvg), which performs multiple local SGD steps between communication rounds. FedAvg has been considered to lack algorithm adaptivity compared to modern first-order adaptive optimizations. In this paper, we propose new communication-efficient FL algortithms based on two adaptive frameworks: local adaptivity (PreFed) and server-side adaptivity (PreFedOp). Proposed methods adopt adaptivity by using a novel covariance matrix preconditioner. Theoretically, we provide convergence guarantees for our algorithms. The empirical experiments show our methods achieve state-of-the-art performances on both i.i.d. and non-i.i.d. settings.","sentences":["Federated Learning (FL) is a distributed machine learning approach that enables model training in communication efficient and privacy-preserving manner.","The standard optimization method in FL is Federated Averaging (FedAvg), which performs multiple local SGD steps between communication rounds.","FedAvg has been considered to lack algorithm adaptivity compared to modern first-order adaptive optimizations.","In this paper, we propose new communication-efficient FL algortithms based on two adaptive frameworks: local adaptivity (PreFed) and server-side adaptivity (PreFedOp).","Proposed methods adopt adaptivity by using a novel covariance matrix preconditioner.","Theoretically, we provide convergence guarantees for our algorithms.","The empirical experiments show our methods achieve state-of-the-art performances on both i.i.d. and non-i.i.d. settings."],"url":"http://arxiv.org/abs/2309.11378v1"}
{"created":"2023-09-20 14:54:48","title":"Learning Patient Static Information from Time-series EHR and an Approach for Safeguarding Privacy and Fairness","abstract":"Recent work in machine learning for healthcare has raised concerns about patient privacy and algorithmic fairness. For example, previous work has shown that patient self-reported race can be predicted from medical data that does not explicitly contain racial information. However, the extent of data identification is unknown, and we lack ways to develop models whose outcomes are minimally affected by such information. Here we systematically investigated the ability of time-series electronic health record data to predict patient static information. We found that not only the raw time-series data, but also learned representations from machine learning models, can be trained to predict a variety of static information with area under the receiver operating characteristic curve as high as 0.851 for biological sex, 0.869 for binarized age and 0.810 for self-reported race. Such high predictive performance can be extended to a wide range of comorbidity factors and exists even when the model was trained for different tasks, using different cohorts, using different model architectures and databases. Given the privacy and fairness concerns these findings pose, we develop a variational autoencoder-based approach that learns a structured latent space to disentangle patient-sensitive attributes from time-series data. Our work thoroughly investigates the ability of machine learning models to encode patient static information from time-series electronic health records and introduces a general approach to protect patient-sensitive attribute information for downstream tasks.","sentences":["Recent work in machine learning for healthcare has raised concerns about patient privacy and algorithmic fairness.","For example, previous work has shown that patient self-reported race can be predicted from medical data that does not explicitly contain racial information.","However, the extent of data identification is unknown, and we lack ways to develop models whose outcomes are minimally affected by such information.","Here we systematically investigated the ability of time-series electronic health record data to predict patient static information.","We found that not only the raw time-series data, but also learned representations from machine learning models, can be trained to predict a variety of static information with area under the receiver operating characteristic curve as high as 0.851 for biological sex, 0.869 for binarized age and 0.810 for self-reported race.","Such high predictive performance can be extended to a wide range of comorbidity factors and exists even when the model was trained for different tasks, using different cohorts, using different model architectures and databases.","Given the privacy and fairness concerns these findings pose, we develop a variational autoencoder-based approach that learns a structured latent space to disentangle patient-sensitive attributes from time-series data.","Our work thoroughly investigates the ability of machine learning models to encode patient static information from time-series electronic health records and introduces a general approach to protect patient-sensitive attribute information for downstream tasks."],"url":"http://arxiv.org/abs/2309.11373v1"}
{"created":"2023-09-20 14:51:09","title":"Dynamic Hand Gesture-Featured Human Motor Adaptation in Tool Delivery using Voice Recognition","abstract":"Human-robot collaboration has benefited users with higher efficiency towards interactive tasks. Nevertheless, most collaborative schemes rely on complicated human-machine interfaces, which might lack the requisite intuitiveness compared with natural limb control. We also expect to understand human intent with low training data requirements. In response to these challenges, this paper introduces an innovative human-robot collaborative framework that seamlessly integrates hand gesture and dynamic movement recognition, voice recognition, and a switchable control adaptation strategy. These modules provide a user-friendly approach that enables the robot to deliver the tools as per user need, especially when the user is working with both hands. Therefore, users can focus on their task execution without additional training in the use of human-machine interfaces, while the robot interprets their intuitive gestures. The proposed multimodal interaction framework is executed in the UR5e robot platform equipped with a RealSense D435i camera, and the effectiveness is assessed through a soldering circuit board task. The experiment results have demonstrated superior performance in hand gesture recognition, where the static hand gesture recognition module achieves an accuracy of 94.3\\%, while the dynamic motion recognition module reaches 97.6\\% accuracy. Compared with human solo manipulation, the proposed approach facilitates higher efficiency tool delivery, without significantly distracting from human intents.","sentences":["Human-robot collaboration has benefited users with higher efficiency towards interactive tasks.","Nevertheless, most collaborative schemes rely on complicated human-machine interfaces, which might lack the requisite intuitiveness compared with natural limb control.","We also expect to understand human intent with low training data requirements.","In response to these challenges, this paper introduces an innovative human-robot collaborative framework that seamlessly integrates hand gesture and dynamic movement recognition, voice recognition, and a switchable control adaptation strategy.","These modules provide a user-friendly approach that enables the robot to deliver the tools as per user need, especially when the user is working with both hands.","Therefore, users can focus on their task execution without additional training in the use of human-machine interfaces, while the robot interprets their intuitive gestures.","The proposed multimodal interaction framework is executed in the UR5e robot platform equipped with a RealSense D435i camera, and the effectiveness is assessed through a soldering circuit board task.","The experiment results have demonstrated superior performance in hand gesture recognition, where the static hand gesture recognition module achieves an accuracy of 94.3\\%, while the dynamic motion recognition module reaches 97.6\\% accuracy.","Compared with human solo manipulation, the proposed approach facilitates higher efficiency tool delivery, without significantly distracting from human intents."],"url":"http://arxiv.org/abs/2309.11368v1"}
{"created":"2023-09-20 14:49:56","title":"Single-Exponential FPT Algorithms for Enumerating Secluded $\\mathcal{F}$-Free Subgraphs and Deleting to Scattered Graph Classes","abstract":"The celebrated notion of important separators bounds the number of small $(S,T)$-separators in a graph which are 'farthest from $S$' in a technical sense. In this paper, we introduce a generalization of this powerful algorithmic primitive that is phrased in terms of $k$-secluded vertex sets: sets with an open neighborhood of size at most $k$.   In this terminology, the bound on important separators says that there are at most $4^k$ maximal $k$-secluded connected vertex sets $C$ containing $S$ but disjoint from $T$. We generalize this statement significantly: even when we demand that $G[C]$ avoids a finite set $\\mathcal{F}$ of forbidden induced subgraphs, the number of such maximal subgraphs is $2^{O(k)}$ and they can be enumerated efficiently. This allows us to make significant improvements for two problems from the literature.   Our first application concerns the 'Connected $k$-Secluded $\\mathcal{F}$-free subgraph' problem, where $\\mathcal{F}$ is a finite set of forbidden induced subgraphs. Given a graph in which each vertex has a positive integer weight, the problem asks to find a maximum-weight connected $k$-secluded vertex set $C \\subseteq V(G)$ such that $G[C]$ does not contain an induced subgraph isomorphic to any $F \\in \\mathcal{F}$. The parameterization by $k$ is known to be solvable in triple-exponential time via the technique of recursive understanding, which we improve to single-exponential.   Our second application concerns the deletion problem to scattered graph classes. Here, the task is to find a vertex set of size at most $k$ whose removal yields a graph whose each connected component belongs to one of the prescribed graph classes $\\Pi_1, \\ldots, \\Pi_d$. We obtain a single-exponential algorithm whenever each class $\\Pi_i$ is characterized by a finite number of forbidden induced subgraphs. This generalizes and improves upon earlier results in the literature.","sentences":["The celebrated notion of important separators bounds the number of small $(S,T)$-separators in a graph which are 'farthest from $S$' in a technical sense.","In this paper, we introduce a generalization of this powerful algorithmic primitive that is phrased in terms of $k$-secluded vertex sets: sets with an open neighborhood of size at most $k$.   In this terminology, the bound on important separators says that there are at most $4^k$ maximal $k$-secluded connected vertex sets $C$ containing $S$ but disjoint from $T$. We generalize this statement significantly: even when we demand that $G[C]$ avoids a finite set $\\mathcal{F}$ of forbidden induced subgraphs, the number of such maximal subgraphs is $2^{O(k)}$ and they can be enumerated efficiently.","This allows us to make significant improvements for two problems from the literature.   ","Our first application concerns the 'Connected $k$-Secluded $\\mathcal{F}$-free subgraph' problem, where $\\mathcal{F}$ is a finite set of forbidden induced subgraphs.","Given a graph in which each vertex has a positive integer weight, the problem asks to find a maximum-weight connected $k$-secluded vertex set $C \\subseteq V(G)$ such that $G[C]$ does not contain an induced subgraph isomorphic to any $F \\in \\mathcal{F}$.","The parameterization by $k$ is known to be solvable in triple-exponential time via the technique of recursive understanding, which we improve to single-exponential.   ","Our second application concerns the deletion problem to scattered graph classes.","Here, the task is to find a vertex set of size at most $k$ whose removal yields a graph whose each connected component belongs to one of the prescribed graph classes $\\Pi_1, \\ldots, \\Pi_d$. We obtain a single-exponential algorithm whenever each class $\\Pi_i$ is characterized by a finite number of forbidden induced subgraphs.","This generalizes and improves upon earlier results in the literature."],"url":"http://arxiv.org/abs/2309.11366v1"}
{"created":"2023-09-20 14:45:48","title":"Robert's theorem and graphs on complete lattices","abstract":"Automata networks, and in particular Boolean networks, are used to model diverse networks of interacting entities. The interaction graph of an automata network is its most important parameter, as it represents the overall architecture of the network. A continuous amount of work has been devoted to infer dynamical properties of the automata network based on its interaction graph only. Robert's theorem is the seminal result in this area; it states that automata networks with an acyclic interaction graph converge to a unique fixed point. The feedback bound can be viewed as an extension of Robert's theorem; it gives an upper bound on the number of fixed points of an automata network based on the size of a minimum feedback vertex set of its interaction graph. Boolean networks can be viewed as self-mappings on the power set lattice of the set of entities. In this paper, we consider self-mappings on a general complete lattice. We make two conceptual contributions. Firstly, we can view a digraph as a residuated mapping on the power set lattice; as such, we define a graph on a complete lattice as a residuated mapping on that lattice. We extend and generalise some results on digraphs to our setting. Secondly, we introduce a generalised notion of dependency whereby any mapping $\\phi$ can depend on any other mapping $\\alpha$. In fact, we are able to give four kinds of dependency in this case. We can then vastly expand Robert's theorem to self-mappings on general complete lattices; we similarly generalise the feedback bound. We then obtain stronger results in the case where the lattice is a complete Boolean algebra. We finally show how our results can be applied to prove the convergence of automata networks.","sentences":["Automata networks, and in particular Boolean networks, are used to model diverse networks of interacting entities.","The interaction graph of an automata network is its most important parameter, as it represents the overall architecture of the network.","A continuous amount of work has been devoted to infer dynamical properties of the automata network based on its interaction graph only.","Robert's theorem is the seminal result in this area; it states that automata networks with an acyclic interaction graph converge to a unique fixed point.","The feedback bound can be viewed as an extension of Robert's theorem; it gives an upper bound on the number of fixed points of an automata network based on the size of a minimum feedback vertex set of its interaction graph.","Boolean networks can be viewed as self-mappings on the power set lattice of the set of entities.","In this paper, we consider self-mappings on a general complete lattice.","We make two conceptual contributions.","Firstly, we can view a digraph as a residuated mapping on the power set lattice; as such, we define a graph on a complete lattice as a residuated mapping on that lattice.","We extend and generalise some results on digraphs to our setting.","Secondly, we introduce a generalised notion of dependency whereby any mapping $\\phi$ can depend on any other mapping $\\alpha$. In fact, we are able to give four kinds of dependency in this case.","We can then vastly expand Robert's theorem to self-mappings on general complete lattices; we similarly generalise the feedback bound.","We then obtain stronger results in the case where the lattice is a complete Boolean algebra.","We finally show how our results can be applied to prove the convergence of automata networks."],"url":"http://arxiv.org/abs/2309.11363v1"}
{"created":"2023-09-20 14:43:43","title":"Knowledge Graph Question Answering for Materials Science (KGQA4MAT): Developing Natural Language Interface for Metal-Organic Frameworks Knowledge Graph (MOF-KG)","abstract":"We present a comprehensive benchmark dataset for Knowledge Graph Question Answering in Materials Science (KGQA4MAT), with a focus on metal-organic frameworks (MOFs). A knowledge graph for metal-organic frameworks (MOF-KG) has been constructed by integrating structured databases and knowledge extracted from the literature. To enhance MOF-KG accessibility for domain experts, we aim to develop a natural language interface for querying the knowledge graph. We have developed a benchmark comprised of 161 complex questions involving comparison, aggregation, and complicated graph structures. Each question is rephrased in three additional variations, resulting in 644 questions and 161 KG queries. To evaluate the benchmark, we have developed a systematic approach for utilizing ChatGPT to translate natural language questions into formal KG queries. We also apply the approach to the well-known QALD-9 dataset, demonstrating ChatGPT's potential in addressing KGQA issues for different platforms and query languages. The benchmark and the proposed approach aim to stimulate further research and development of user-friendly and efficient interfaces for querying domain-specific materials science knowledge graphs, thereby accelerating the discovery of novel materials.","sentences":["We present a comprehensive benchmark dataset for Knowledge Graph Question Answering in Materials Science (KGQA4MAT), with a focus on metal-organic frameworks (MOFs).","A knowledge graph for metal-organic frameworks (MOF-KG) has been constructed by integrating structured databases and knowledge extracted from the literature.","To enhance MOF-KG accessibility for domain experts, we aim to develop a natural language interface for querying the knowledge graph.","We have developed a benchmark comprised of 161 complex questions involving comparison, aggregation, and complicated graph structures.","Each question is rephrased in three additional variations, resulting in 644 questions and 161 KG queries.","To evaluate the benchmark, we have developed a systematic approach for utilizing ChatGPT to translate natural language questions into formal KG queries.","We also apply the approach to the well-known QALD-9 dataset, demonstrating ChatGPT's potential in addressing KGQA issues for different platforms and query languages.","The benchmark and the proposed approach aim to stimulate further research and development of user-friendly and efficient interfaces for querying domain-specific materials science knowledge graphs, thereby accelerating the discovery of novel materials."],"url":"http://arxiv.org/abs/2309.11361v1"}
{"created":"2023-09-20 14:42:01","title":"Prompt, Plan, Perform: LLM-based Humanoid Control via Quantized Imitation Learning","abstract":"In recent years, reinforcement learning and imitation learning have shown great potential for controlling humanoid robots' motion. However, these methods typically create simulation environments and rewards for specific tasks, resulting in the requirements of multiple policies and limited capabilities for tackling complex and unknown tasks. To overcome these issues, we present a novel approach that combines adversarial imitation learning with large language models (LLMs). This innovative method enables the agent to learn reusable skills with a single policy and solve zero-shot tasks under the guidance of LLMs. In particular, we utilize the LLM as a strategic planner for applying previously learned skills to novel tasks through the comprehension of task-specific prompts. This empowers the robot to perform the specified actions in a sequence. To improve our model, we incorporate codebook-based vector quantization, allowing the agent to generate suitable actions in response to unseen textual commands from LLMs. Furthermore, we design general reward functions that consider the distinct motion features of humanoid robots, ensuring the agent imitates the motion data while maintaining goal orientation without additional guiding direction approaches or policies. To the best of our knowledge, this is the first framework that controls humanoid robots using a single learning policy network and LLM as a planner. Extensive experiments demonstrate that our method exhibits efficient and adaptive ability in complicated motion tasks.","sentences":["In recent years, reinforcement learning and imitation learning have shown great potential for controlling humanoid robots' motion.","However, these methods typically create simulation environments and rewards for specific tasks, resulting in the requirements of multiple policies and limited capabilities for tackling complex and unknown tasks.","To overcome these issues, we present a novel approach that combines adversarial imitation learning with large language models (LLMs).","This innovative method enables the agent to learn reusable skills with a single policy and solve zero-shot tasks under the guidance of LLMs.","In particular, we utilize the LLM as a strategic planner for applying previously learned skills to novel tasks through the comprehension of task-specific prompts.","This empowers the robot to perform the specified actions in a sequence.","To improve our model, we incorporate codebook-based vector quantization, allowing the agent to generate suitable actions in response to unseen textual commands from LLMs.","Furthermore, we design general reward functions that consider the distinct motion features of humanoid robots, ensuring the agent imitates the motion data while maintaining goal orientation without additional guiding direction approaches or policies.","To the best of our knowledge, this is the first framework that controls humanoid robots using a single learning policy network and LLM as a planner.","Extensive experiments demonstrate that our method exhibits efficient and adaptive ability in complicated motion tasks."],"url":"http://arxiv.org/abs/2309.11359v1"}
{"created":"2023-09-20 14:39:03","title":"3D Face Reconstruction: the Road to Forensics","abstract":"3D face reconstruction algorithms from images and videos are applied to many fields, from plastic surgery to the entertainment sector, thanks to their advantageous features. However, when looking at forensic applications, 3D face reconstruction must observe strict requirements that still make its possible role in bringing evidence to a lawsuit unclear. An extensive investigation of the constraints, potential, and limits of its application in forensics is still missing. Shedding some light on this matter is the goal of the present survey, which starts by clarifying the relation between forensic applications and biometrics, with a focus on face recognition. Therefore, it provides an analysis of the achievements of 3D face reconstruction algorithms from surveillance videos and mugshot images and discusses the current obstacles that separate 3D face reconstruction from an active role in forensic applications. Finally, it examines the underlying data sets, with their advantages and limitations, while proposing alternatives that could substitute or complement them.","sentences":["3D face reconstruction algorithms from images and videos are applied to many fields, from plastic surgery to the entertainment sector, thanks to their advantageous features.","However, when looking at forensic applications, 3D face reconstruction must observe strict requirements that still make its possible role in bringing evidence to a lawsuit unclear.","An extensive investigation of the constraints, potential, and limits of its application in forensics is still missing.","Shedding some light on this matter is the goal of the present survey, which starts by clarifying the relation between forensic applications and biometrics, with a focus on face recognition.","Therefore, it provides an analysis of the achievements of 3D face reconstruction algorithms from surveillance videos and mugshot images and discusses the current obstacles that separate 3D face reconstruction from an active role in forensic applications.","Finally, it examines the underlying data sets, with their advantages and limitations, while proposing alternatives that could substitute or complement them."],"url":"http://arxiv.org/abs/2309.11357v1"}
{"created":"2023-09-20 14:36:57","title":"A Comprehensive Survey on Rare Event Prediction","abstract":"Rare event prediction involves identifying and forecasting events with a low probability using machine learning and data analysis. Due to the imbalanced data distributions, where the frequency of common events vastly outweighs that of rare events, it requires using specialized methods within each step of the machine learning pipeline, i.e., from data processing to algorithms to evaluation protocols. Predicting the occurrences of rare events is important for real-world applications, such as Industry 4.0, and is an active research area in statistical and machine learning. This paper comprehensively reviews the current approaches for rare event prediction along four dimensions: rare event data, data processing, algorithmic approaches, and evaluation approaches. Specifically, we consider 73 datasets from different modalities (i.e., numerical, image, text, and audio), four major categories of data processing, five major algorithmic groupings, and two broader evaluation approaches. This paper aims to identify gaps in the current literature and highlight the challenges of predicting rare events. It also suggests potential research directions, which can help guide practitioners and researchers.","sentences":["Rare event prediction involves identifying and forecasting events with a low probability using machine learning and data analysis.","Due to the imbalanced data distributions, where the frequency of common events vastly outweighs that of rare events, it requires using specialized methods within each step of the machine learning pipeline, i.e., from data processing to algorithms to evaluation protocols.","Predicting the occurrences of rare events is important for real-world applications, such as Industry 4.0, and is an active research area in statistical and machine learning.","This paper comprehensively reviews the current approaches for rare event prediction along four dimensions: rare event data, data processing, algorithmic approaches, and evaluation approaches.","Specifically, we consider 73 datasets from different modalities (i.e., numerical, image, text, and audio), four major categories of data processing, five major algorithmic groupings, and two broader evaluation approaches.","This paper aims to identify gaps in the current literature and highlight the challenges of predicting rare events.","It also suggests potential research directions, which can help guide practitioners and researchers."],"url":"http://arxiv.org/abs/2309.11356v1"}
{"created":"2023-09-20 14:35:23","title":"Self-supervised learning unveils change in urban housing from street-level images","abstract":"Cities around the world face a critical shortage of affordable and decent housing. Despite its critical importance for policy, our ability to effectively monitor and track progress in urban housing is limited. Deep learning-based computer vision methods applied to street-level images have been successful in the measurement of socioeconomic and environmental inequalities but did not fully utilize temporal images to track urban change as time-varying labels are often unavailable. We used self-supervised methods to measure change in London using 15 million street images taken between 2008 and 2021. Our novel adaptation of Barlow Twins, Street2Vec, embeds urban structure while being invariant to seasonal and daily changes without manual annotations. It outperformed generic embeddings, successfully identified point-level change in London's housing supply from street-level images, and distinguished between major and minor change. This capability can provide timely information for urban planning and policy decisions toward more liveable, equitable, and sustainable cities.","sentences":["Cities around the world face a critical shortage of affordable and decent housing.","Despite its critical importance for policy, our ability to effectively monitor and track progress in urban housing is limited.","Deep learning-based computer vision methods applied to street-level images have been successful in the measurement of socioeconomic and environmental inequalities but did not fully utilize temporal images to track urban change as time-varying labels are often unavailable.","We used self-supervised methods to measure change in London using 15 million street images taken between 2008 and 2021.","Our novel adaptation of Barlow Twins, Street2Vec, embeds urban structure while being invariant to seasonal and daily changes without manual annotations.","It outperformed generic embeddings, successfully identified point-level change in London's housing supply from street-level images, and distinguished between major and minor change.","This capability can provide timely information for urban planning and policy decisions toward more liveable, equitable, and sustainable cities."],"url":"http://arxiv.org/abs/2309.11354v1"}
{"created":"2023-09-20 14:34:45","title":"C$\\cdot$ASE: Learning Conditional Adversarial Skill Embeddings for Physics-based Characters","abstract":"We present C$\\cdot$ASE, an efficient and effective framework that learns conditional Adversarial Skill Embeddings for physics-based characters. Our physically simulated character can learn a diverse repertoire of skills while providing controllability in the form of direct manipulation of the skills to be performed. C$\\cdot$ASE divides the heterogeneous skill motions into distinct subsets containing homogeneous samples for training a low-level conditional model to learn conditional behavior distribution. The skill-conditioned imitation learning naturally offers explicit control over the character's skills after training. The training course incorporates the focal skill sampling, skeletal residual forces, and element-wise feature masking to balance diverse skills of varying complexities, mitigate dynamics mismatch to master agile motions and capture more general behavior characteristics, respectively. Once trained, the conditional model can produce highly diverse and realistic skills, outperforming state-of-the-art models, and can be repurposed in various downstream tasks. In particular, the explicit skill control handle allows a high-level policy or user to direct the character with desired skill specifications, which we demonstrate is advantageous for interactive character animation.","sentences":["We present C$\\cdot$ASE, an efficient and effective framework that learns conditional Adversarial Skill Embeddings for physics-based characters.","Our physically simulated character can learn a diverse repertoire of skills while providing controllability in the form of direct manipulation of the skills to be performed.","C$\\cdot$ASE divides the heterogeneous skill motions into distinct subsets containing homogeneous samples for training a low-level conditional model to learn conditional behavior distribution.","The skill-conditioned imitation learning naturally offers explicit control over the character's skills after training.","The training course incorporates the focal skill sampling, skeletal residual forces, and element-wise feature masking to balance diverse skills of varying complexities, mitigate dynamics mismatch to master agile motions and capture more general behavior characteristics, respectively.","Once trained, the conditional model can produce highly diverse and realistic skills, outperforming state-of-the-art models, and can be repurposed in various downstream tasks.","In particular, the explicit skill control handle allows a high-level policy or user to direct the character with desired skill specifications, which we demonstrate is advantageous for interactive character animation."],"url":"http://arxiv.org/abs/2309.11351v1"}
{"created":"2023-09-20 14:34:16","title":"Better Sooner Rather Than Later","abstract":"This article unifies and generalizes fundamental results related to $n$-process asynchronous crash-prone distributed computing. More precisely, it proves that for every $0\\leq k \\leq n$, assuming that process failures occur only before the number of participating processes bypasses a predefined threshold that equals $n-k$ (a participating process is a process that has executed at least one statement of its code), an asynchronous algorithm exists that solves consensus for $n$ processes in the presence of $f$ crash failures if and only if $f \\leq k$. In a very simple and interesting way, the \"extreme\" case $k=0$ boils down to the celebrated FLP impossibility result (1985, 1987). Moreover, the second extreme case, namely $k=n$, captures the celebrated mutual exclusion result by E.W. Dijkstra (1965) that states that mutual exclusion can be solved for $n$ processes in an asynchronous read/write shared memory system where any number of processes may crash (but only) before starting to participate in the algorithm (that is, participation is not required, but once a process starts participating it may not fail). More generally, the possibility/impossibility stated above demonstrates that more failures can be tolerated when they occur earlier in the computation (hence the title).","sentences":["This article unifies and generalizes fundamental results related to $n$-process asynchronous crash-prone distributed computing.","More precisely, it proves that for every $0\\leq k \\leq n$, assuming that process failures occur only before the number of participating processes bypasses a predefined threshold that equals $n-k$ (a participating process is a process that has executed at least one statement of its code), an asynchronous algorithm exists that solves consensus for $n$ processes in the presence of $f$ crash failures if and only if $f \\leq k$.","In a very simple and interesting way, the \"extreme\" case $k=0$ boils down to the celebrated FLP impossibility result (1985, 1987).","Moreover, the second extreme case, namely $k=n$, captures the celebrated mutual exclusion result by E.W. Dijkstra (1965) that states that mutual exclusion can be solved for $n$ processes in an asynchronous read/write shared memory system where any number of processes may crash (but only) before starting to participate in the algorithm (that is, participation is not required, but once a process starts participating it may not fail).","More generally, the possibility/impossibility stated above demonstrates that more failures can be tolerated when they occur earlier in the computation (hence the title)."],"url":"http://arxiv.org/abs/2309.11350v1"}
{"created":"2023-09-20 14:25:44","title":"GECTurk: Grammatical Error Correction and Detection Dataset for Turkish","abstract":"Grammatical Error Detection and Correction (GEC) tools have proven useful for native speakers and second language learners. Developing such tools requires a large amount of parallel, annotated data, which is unavailable for most languages. Synthetic data generation is a common practice to overcome the scarcity of such data. However, it is not straightforward for morphologically rich languages like Turkish due to complex writing rules that require phonological, morphological, and syntactic information. In this work, we present a flexible and extensible synthetic data generation pipeline for Turkish covering more than 20 expert-curated grammar and spelling rules (a.k.a., writing rules) implemented through complex transformation functions. Using this pipeline, we derive 130,000 high-quality parallel sentences from professionally edited articles. Additionally, we create a more realistic test set by manually annotating a set of movie reviews. We implement three baselines formulating the task as i) neural machine translation, ii) sequence tagging, and iii) prefix tuning with a pretrained decoder-only model, achieving strong results. Furthermore, we perform exhaustive experiments on out-of-domain datasets to gain insights on the transferability and robustness of the proposed approaches. Our results suggest that our corpus, GECTurk, is high-quality and allows knowledge transfer for the out-of-domain setting. To encourage further research on Turkish GEC, we release our datasets, baseline models, and the synthetic data generation pipeline at https://github.com/GGLAB-KU/gecturk.","sentences":["Grammatical Error Detection and Correction (GEC) tools have proven useful for native speakers and second language learners.","Developing such tools requires a large amount of parallel, annotated data, which is unavailable for most languages.","Synthetic data generation is a common practice to overcome the scarcity of such data.","However, it is not straightforward for morphologically rich languages like Turkish due to complex writing rules that require phonological, morphological, and syntactic information.","In this work, we present a flexible and extensible synthetic data generation pipeline for Turkish covering more than 20 expert-curated grammar and spelling rules (a.k.a., writing rules) implemented through complex transformation functions.","Using this pipeline, we derive 130,000 high-quality parallel sentences from professionally edited articles.","Additionally, we create a more realistic test set by manually annotating a set of movie reviews.","We implement three baselines formulating the task as i) neural machine translation, ii) sequence tagging, and iii) prefix tuning with a pretrained decoder-only model, achieving strong results.","Furthermore, we perform exhaustive experiments on out-of-domain datasets to gain insights on the transferability and robustness of the proposed approaches.","Our results suggest that our corpus, GECTurk, is high-quality and allows knowledge transfer for the out-of-domain setting.","To encourage further research on Turkish GEC, we release our datasets, baseline models, and the synthetic data generation pipeline at https://github.com/GGLAB-KU/gecturk."],"url":"http://arxiv.org/abs/2309.11346v1"}
{"created":"2023-09-20 14:20:56","title":"Using Property Elicitation to Understand the Impacts of Fairness Constraints","abstract":"Predictive algorithms are often trained by optimizing some loss function, to which regularization functions are added to impose a penalty for violating constraints. As expected, the addition of such regularization functions can change the minimizer of the objective. It is not well-understood which regularizers change the minimizer of the loss, and, when the minimizer does change, how it changes. We use property elicitation to take first steps towards understanding the joint relationship between the loss and regularization functions and the optimal decision for a given problem instance. In particular, we give a necessary and sufficient condition on loss and regularizer pairs for when a property changes with the addition of the regularizer, and examine some regularizers satisfying this condition standard in the fair machine learning literature. We empirically demonstrate how algorithmic decision-making changes as a function of both data distribution changes and hardness of the constraints.","sentences":["Predictive algorithms are often trained by optimizing some loss function, to which regularization functions are added to impose a penalty for violating constraints.","As expected, the addition of such regularization functions can change the minimizer of the objective.","It is not well-understood which regularizers change the minimizer of the loss, and, when the minimizer does change, how it changes.","We use property elicitation to take first steps towards understanding the joint relationship between the loss and regularization functions and the optimal decision for a given problem instance.","In particular, we give a necessary and sufficient condition on loss and regularizer pairs for when a property changes with the addition of the regularizer, and examine some regularizers satisfying this condition standard in the fair machine learning literature.","We empirically demonstrate how algorithmic decision-making changes as a function of both data distribution changes and hardness of the constraints."],"url":"http://arxiv.org/abs/2309.11343v1"}
{"created":"2023-09-20 14:18:04","title":"Improving Article Classification with Edge-Heterogeneous Graph Neural Networks","abstract":"Classifying research output into context-specific label taxonomies is a challenging and relevant downstream task, given the volume of existing and newly published articles. We propose a method to enhance the performance of article classification by enriching simple Graph Neural Networks (GNN) pipelines with edge-heterogeneous graph representations. SciBERT is used for node feature generation to capture higher-order semantics within the articles' textual metadata. Fully supervised transductive node classification experiments are conducted on the Open Graph Benchmark (OGB) ogbn-arxiv dataset and the PubMed diabetes dataset, augmented with additional metadata from Microsoft Academic Graph (MAG) and PubMed Central, respectively. The results demonstrate that edge-heterogeneous graphs consistently improve the performance of all GNN models compared to the edge-homogeneous graphs. The transformed data enable simple and shallow GNN pipelines to achieve results on par with more complex architectures. On ogbn-arxiv, we achieve a top-15 result in the OGB competition with a 2-layer GCN (accuracy 74.61%), being the highest-scoring solution with sub-1 million parameters. On PubMed, we closely trail SOTA GNN architectures using a 2-layer GraphSAGE by including additional co-authorship edges in the graph (accuracy 89.88%). The implementation is available at: $\\href{https://github.com/lyvykhang/edgehetero-nodeproppred}{\\text{https://github.com/lyvykhang/edgehetero-nodeproppred}}$.","sentences":["Classifying research output into context-specific label taxonomies is a challenging and relevant downstream task, given the volume of existing and newly published articles.","We propose a method to enhance the performance of article classification by enriching simple Graph Neural Networks (GNN) pipelines with edge-heterogeneous graph representations.","SciBERT is used for node feature generation to capture higher-order semantics within the articles' textual metadata.","Fully supervised transductive node classification experiments are conducted on the Open Graph Benchmark (OGB) ogbn-arxiv dataset and the PubMed diabetes dataset, augmented with additional metadata from Microsoft Academic Graph (MAG) and PubMed Central, respectively.","The results demonstrate that edge-heterogeneous graphs consistently improve the performance of all GNN models compared to the edge-homogeneous graphs.","The transformed data enable simple and shallow GNN pipelines to achieve results on par with more complex architectures.","On ogbn-arxiv, we achieve a top-15 result in the OGB competition with a 2-layer GCN (accuracy 74.61%), being the highest-scoring solution with sub-1 million parameters.","On PubMed, we closely trail SOTA GNN architectures using a 2-layer GraphSAGE by including additional co-authorship edges in the graph (accuracy 89.88%).","The implementation is available at: $\\href{https://github.com/lyvykhang/edgehetero-nodeproppred}{\\text{https://github.com/lyvykhang/edgehetero-nodeproppred}}$."],"url":"http://arxiv.org/abs/2309.11341v1"}
{"created":"2023-09-20 14:13:05","title":"TRAVID: An End-to-End Video Translation Framework","abstract":"In today's globalized world, effective communication with people from diverse linguistic backgrounds has become increasingly crucial. While traditional methods of language translation, such as written text or voice-only translations, can accomplish the task, they often fail to capture the complete context and nuanced information conveyed through nonverbal cues like facial expressions and lip movements. In this paper, we present an end-to-end video translation system that not only translates spoken language but also synchronizes the translated speech with the lip movements of the speaker. Our system focuses on translating educational lectures in various Indian languages, and it is designed to be effective even in low-resource system settings. By incorporating lip movements that align with the target language and matching them with the speaker's voice using voice cloning techniques, our application offers an enhanced experience for students and users. This additional feature creates a more immersive and realistic learning environment, ultimately making the learning process more effective and engaging.","sentences":["In today's globalized world, effective communication with people from diverse linguistic backgrounds has become increasingly crucial.","While traditional methods of language translation, such as written text or voice-only translations, can accomplish the task, they often fail to capture the complete context and nuanced information conveyed through nonverbal cues like facial expressions and lip movements.","In this paper, we present an end-to-end video translation system that not only translates spoken language but also synchronizes the translated speech with the lip movements of the speaker.","Our system focuses on translating educational lectures in various Indian languages, and it is designed to be effective even in low-resource system settings.","By incorporating lip movements that align with the target language and matching them with the speaker's voice using voice cloning techniques, our application offers an enhanced experience for students and users.","This additional feature creates a more immersive and realistic learning environment, ultimately making the learning process more effective and engaging."],"url":"http://arxiv.org/abs/2309.11338v1"}
{"created":"2023-09-20 14:12:57","title":"Memory-Anonymous Starvation-Free Mutual Exclusion: Possibility and Impossibility Results","abstract":"In an anonymous shared memory system, all inter-process communications are via shared objects; however, unlike in standard systems, there is no a priori agreement between processes on the names of shared objects [14,15]. Furthermore, the algorithms are required to be symmetric; that is, the processes should execute precisely the same code, and the only way to distinguish processes is by comparing identifiers for equality. For such a system, read/write registers are called anonymous registers. It is known that symmetric deadlock-free mutual exclusion is solvable for any finite number of processes using anonymous registers [1]. The main question left open in [14,15] is the existence of starvation-free mutual exclusion algorithms for two or more processes. We resolve this open question for memoryless algorithms, in which a process that tries to enter its critical section does not use any information about its previous attempts. Almost all known mutual exclusion algorithms are memoryless. We show that (1) there is a symmetric memoryless starvation-free mutual exclusion algorithm for two processes using $m \\geq 7$ anonymous registers if and only if $m$ is odd; and (2) there is no symmetric memoryless starvation-free mutual exclusion algorithm for $n\\geq 3$ processes using (any number of) anonymous registers. Our impossibility result is the only example of a system with fault-free processes, where global progress (i.e., deadlock-freedom) can be ensured, while individual progress to each process (i.e., starvation-freedom) cannot. It complements a known result for systems with failure-prone processes, that there are objects with lock-free implementations but without wait-free implementations [2,5].","sentences":["In an anonymous shared memory system, all inter-process communications are via shared objects; however, unlike in standard systems, there is no a priori agreement between processes on the names of shared objects [14,15].","Furthermore, the algorithms are required to be symmetric; that is, the processes should execute precisely the same code, and the only way to distinguish processes is by comparing identifiers for equality.","For such a system, read/write registers are called anonymous registers.","It is known that symmetric deadlock-free mutual exclusion is solvable for any finite number of processes using anonymous registers [1].","The main question left open in [14,15] is the existence of starvation-free mutual exclusion algorithms for two or more processes.","We resolve this open question for memoryless algorithms, in which a process that tries to enter its critical section does not use any information about its previous attempts.","Almost all known mutual exclusion algorithms are memoryless.","We show that (1) there is a symmetric memoryless starvation-free mutual exclusion algorithm for two processes using $m \\geq 7$ anonymous registers if and only if $m$ is odd; and (2) there is no symmetric memoryless starvation-free mutual exclusion algorithm for $n\\geq 3$ processes using (any number of) anonymous registers.","Our impossibility result is the only example of a system with fault-free processes, where global progress (i.e., deadlock-freedom) can be ensured, while individual progress to each process (i.e., starvation-freedom) cannot.","It complements a known result for systems with failure-prone processes, that there are objects with lock-free implementations but without wait-free implementations [2,5]."],"url":"http://arxiv.org/abs/2309.11337v1"}
{"created":"2023-09-20 14:12:10","title":"2D-3D Pose Tracking with Multi-View Constraints","abstract":"Camera localization in 3D LiDAR maps has gained increasing attention due to its promising ability to handle complex scenarios, surpassing the limitations of visual-only localization methods. However, existing methods mostly focus on addressing the cross-modal gaps, estimating camera poses frame by frame without considering the relationship between adjacent frames, which makes the pose tracking unstable. To alleviate this, we propose to couple the 2D-3D correspondences between adjacent frames using the 2D-2D feature matching, establishing the multi-view geometrical constraints for simultaneously estimating multiple camera poses. Specifically, we propose a new 2D-3D pose tracking framework, which consists: a front-end hybrid flow estimation network for consecutive frames and a back-end pose optimization module. We further design a cross-modal consistency-based loss to incorporate the multi-view constraints during the training and inference process. We evaluate our proposed framework on the KITTI and Argoverse datasets. Experimental results demonstrate its superior performance compared to existing frame-by-frame 2D-3D pose tracking methods and state-of-the-art vision-only pose tracking algorithms. More online pose tracking videos are available at \\url{https://youtu.be/yfBRdg7gw5M}","sentences":["Camera localization in 3D LiDAR maps has gained increasing attention due to its promising ability to handle complex scenarios, surpassing the limitations of visual-only localization methods.","However, existing methods mostly focus on addressing the cross-modal gaps, estimating camera poses frame by frame without considering the relationship between adjacent frames, which makes the pose tracking unstable.","To alleviate this, we propose to couple the 2D-3D correspondences between adjacent frames using the 2D-2D feature matching, establishing the multi-view geometrical constraints for simultaneously estimating multiple camera poses.","Specifically, we propose a new 2D-3D pose tracking framework, which consists: a front-end hybrid flow estimation network for consecutive frames and a back-end pose optimization module.","We further design a cross-modal consistency-based loss to incorporate the multi-view constraints during the training and inference process.","We evaluate our proposed framework on the KITTI and Argoverse datasets.","Experimental results demonstrate its superior performance compared to existing frame-by-frame 2D-3D pose tracking methods and state-of-the-art vision-only pose tracking algorithms.","More online pose tracking videos are available at \\url{https://youtu.be/yfBRdg7gw5M}"],"url":"http://arxiv.org/abs/2309.11335v1"}
{"created":"2023-09-20 14:09:38","title":"You can have your ensemble and run it too -- Deep Ensembles Spread Over Time","abstract":"Ensembles of independently trained deep neural networks yield uncertainty estimates that rival Bayesian networks in performance. They also offer sizable improvements in terms of predictive performance over single models. However, deep ensembles are not commonly used in environments with limited computational budget -- such as autonomous driving -- since the complexity grows linearly with the number of ensemble members. An important observation that can be made for robotics applications, such as autonomous driving, is that data is typically sequential. For instance, when an object is to be recognized, an autonomous vehicle typically observes a sequence of images, rather than a single image. This raises the question, could the deep ensemble be spread over time?   In this work, we propose and analyze Deep Ensembles Spread Over Time (DESOT). The idea is to apply only a single ensemble member to each data point in the sequence, and fuse the predictions over a sequence of data points. We implement and experiment with DESOT for traffic sign classification, where sequences of tracked image patches are to be classified. We find that DESOT obtains the benefits of deep ensembles, in terms of predictive and uncertainty estimation performance, while avoiding the added computational cost. Moreover, DESOT is simple to implement and does not require sequences during training. Finally, we find that DESOT, like deep ensembles, outperform single models for out-of-distribution detection.","sentences":["Ensembles of independently trained deep neural networks yield uncertainty estimates that rival Bayesian networks in performance.","They also offer sizable improvements in terms of predictive performance over single models.","However, deep ensembles are not commonly used in environments with limited computational budget -- such as autonomous driving -- since the complexity grows linearly with the number of ensemble members.","An important observation that can be made for robotics applications, such as autonomous driving, is that data is typically sequential.","For instance, when an object is to be recognized, an autonomous vehicle typically observes a sequence of images, rather than a single image.","This raises the question, could the deep ensemble be spread over time?   ","In this work, we propose and analyze Deep Ensembles Spread Over Time (DESOT).","The idea is to apply only a single ensemble member to each data point in the sequence, and fuse the predictions over a sequence of data points.","We implement and experiment with DESOT for traffic sign classification, where sequences of tracked image patches are to be classified.","We find that DESOT obtains the benefits of deep ensembles, in terms of predictive and uncertainty estimation performance, while avoiding the added computational cost.","Moreover, DESOT is simple to implement and does not require sequences during training.","Finally, we find that DESOT, like deep ensembles, outperform single models for out-of-distribution detection."],"url":"http://arxiv.org/abs/2309.11333v1"}
{"created":"2023-09-20 14:07:20","title":"Software Compartmentalization Trade-Offs with Hardware Capabilities","abstract":"Compartmentalization is a form of defensive software design in which an application is broken down into isolated but communicating components. Retrofitting compartmentalization into existing applications is often thought to be expensive from the engineering effort and performance overhead points of view. Still, recent years have seen proposals of compartmentalization methods with promises of low engineering efforts and reduced performance impact. ARM Morello combines a modern ARM processor with an implementation of Capability Hardware Enhanced RISC Instructions (CHERI) aiming to provide efficient and secure compartmentalization. Past works exploring CHERI-based compartmentalization were restricted to emulated/FPGA prototypes.   In this paper, we explore possible compartmentalization schemes with CHERI on the Morello chip. We propose two approaches representing different trade-offs in terms of engineering effort, security, scalability, and performance impact. We describe and implement these approaches on a prototype OS running bare metal on the Morello chip, compartmentalize two popular applications, and investigate the performance overheads. Furthermore, we show that compartmentalization can be achieved with an engineering cost that can be quite low if one is willing to trade off on scalability and security, and that performance overheads are similar to other intra-address space isolation mechanisms.","sentences":["Compartmentalization is a form of defensive software design in which an application is broken down into isolated but communicating components.","Retrofitting compartmentalization into existing applications is often thought to be expensive from the engineering effort and performance overhead points of view.","Still, recent years have seen proposals of compartmentalization methods with promises of low engineering efforts and reduced performance impact.","ARM Morello combines a modern ARM processor with an implementation of Capability Hardware Enhanced RISC Instructions (CHERI) aiming to provide efficient and secure compartmentalization.","Past works exploring CHERI-based compartmentalization were restricted to emulated/FPGA prototypes.   ","In this paper, we explore possible compartmentalization schemes with CHERI on the Morello chip.","We propose two approaches representing different trade-offs in terms of engineering effort, security, scalability, and performance impact.","We describe and implement these approaches on a prototype OS running bare metal on the Morello chip, compartmentalize two popular applications, and investigate the performance overheads.","Furthermore, we show that compartmentalization can be achieved with an engineering cost that can be quite low if one is willing to trade off on scalability and security, and that performance overheads are similar to other intra-address space isolation mechanisms."],"url":"http://arxiv.org/abs/2309.11332v1"}
{"created":"2023-09-20 14:03:47","title":"Gold-YOLO: Efficient Object Detector via Gather-and-Distribute Mechanism","abstract":"In the past years, YOLO-series models have emerged as the leading approaches in the area of real-time object detection. Many studies pushed up the baseline to a higher level by modifying the architecture, augmenting data and designing new losses. However, we find previous models still suffer from information fusion problem, although Feature Pyramid Network (FPN) and Path Aggregation Network (PANet) have alleviated this. Therefore, this study provides an advanced Gatherand-Distribute mechanism (GD) mechanism, which is realized with convolution and self-attention operations. This new designed model named as Gold-YOLO, which boosts the multi-scale feature fusion capabilities and achieves an ideal balance between latency and accuracy across all model scales. Additionally, we implement MAE-style pretraining in the YOLO-series for the first time, allowing YOLOseries models could be to benefit from unsupervised pretraining. Gold-YOLO-N attains an outstanding 39.9% AP on the COCO val2017 datasets and 1030 FPS on a T4 GPU, which outperforms the previous SOTA model YOLOv6-3.0-N with similar FPS by +2.4%. The PyTorch code is available at https://github.com/huaweinoah/Efficient-Computing/Detection/Gold-YOLO, and the MindSpore code is available at https://gitee.com/mindspore/models/tree/master/research/cv/Gold_YOLO.","sentences":["In the past years, YOLO-series models have emerged as the leading approaches in the area of real-time object detection.","Many studies pushed up the baseline to a higher level by modifying the architecture, augmenting data and designing new losses.","However, we find previous models still suffer from information fusion problem, although Feature Pyramid Network (FPN) and Path Aggregation Network (PANet) have alleviated this.","Therefore, this study provides an advanced Gatherand-Distribute mechanism (GD) mechanism, which is realized with convolution and self-attention operations.","This new designed model named as Gold-YOLO, which boosts the multi-scale feature fusion capabilities and achieves an ideal balance between latency and accuracy across all model scales.","Additionally, we implement MAE-style pretraining in the YOLO-series for the first time, allowing YOLOseries models could be to benefit from unsupervised pretraining.","Gold-YOLO-N attains an outstanding 39.9% AP on the COCO val2017 datasets and 1030 FPS on a T4 GPU, which outperforms the previous SOTA model YOLOv6-3.0-N with similar FPS by +2.4%.","The PyTorch code is available at https://github.com/huaweinoah/Efficient-Computing/Detection/Gold-YOLO, and the MindSpore code is available at https://gitee.com/mindspore/models/tree/master/research/cv/Gold_YOLO."],"url":"http://arxiv.org/abs/2309.11331v1"}
{"created":"2023-09-20 13:54:29","title":"How to turn your camera into a perfect pinhole model","abstract":"Camera calibration is a first and fundamental step in various computer vision applications. Despite being an active field of research, Zhang's method remains widely used for camera calibration due to its implementation in popular toolboxes. However, this method initially assumes a pinhole model with oversimplified distortion models. In this work, we propose a novel approach that involves a pre-processing step to remove distortions from images by means of Gaussian processes. Our method does not need to assume any distortion model and can be applied to severely warped images, even in the case of multiple distortion sources, e.g., a fisheye image of a curved mirror reflection. The Gaussian processes capture all distortions and camera imperfections, resulting in virtual images as though taken by an ideal pinhole camera with square pixels. Furthermore, this ideal GP-camera only needs one image of a square grid calibration pattern. This model allows for a serious upgrade of many algorithms and applications that are designed in a pure projective geometry setting but with a performance that is very sensitive to nonlinear lens distortions. We demonstrate the effectiveness of our method by simplifying Zhang's calibration method, reducing the number of parameters and getting rid of the distortion parameters and iterative optimization. We validate by means of synthetic data and real world images. The contributions of this work include the construction of a virtual ideal pinhole camera using Gaussian processes, a simplified calibration method and lens distortion removal.","sentences":["Camera calibration is a first and fundamental step in various computer vision applications.","Despite being an active field of research, Zhang's method remains widely used for camera calibration due to its implementation in popular toolboxes.","However, this method initially assumes a pinhole model with oversimplified distortion models.","In this work, we propose a novel approach that involves a pre-processing step to remove distortions from images by means of Gaussian processes.","Our method does not need to assume any distortion model and can be applied to severely warped images, even in the case of multiple distortion sources, e.g., a fisheye image of a curved mirror reflection.","The Gaussian processes capture all distortions and camera imperfections, resulting in virtual images as though taken by an ideal pinhole camera with square pixels.","Furthermore, this ideal GP-camera only needs one image of a square grid calibration pattern.","This model allows for a serious upgrade of many algorithms and applications that are designed in a pure projective geometry setting but with a performance that is very sensitive to nonlinear lens distortions.","We demonstrate the effectiveness of our method by simplifying Zhang's calibration method, reducing the number of parameters and getting rid of the distortion parameters and iterative optimization.","We validate by means of synthetic data and real world images.","The contributions of this work include the construction of a virtual ideal pinhole camera using Gaussian processes, a simplified calibration method and lens distortion removal."],"url":"http://arxiv.org/abs/2309.11326v1"}
{"created":"2023-09-20 13:50:26","title":"DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal Services","abstract":"We propose DISC-LawLLM, an intelligent legal system utilizing large language models (LLMs) to provide a wide range of legal services. We adopt legal syllogism prompting strategies to construct supervised fine-tuning datasets in the Chinese Judicial domain and fine-tune LLMs with legal reasoning capability. We augment LLMs with a retrieval module to enhance models' ability to access and utilize external legal knowledge. A comprehensive legal benchmark, DISC-Law-Eval, is presented to evaluate intelligent legal systems from both objective and subjective dimensions. Quantitative and qualitative results on DISC-Law-Eval demonstrate the effectiveness of our system in serving various users across diverse legal scenarios. The detailed resources are available at https://github.com/FudanDISC/DISC-LawLLM.","sentences":["We propose DISC-LawLLM, an intelligent legal system utilizing large language models (LLMs) to provide a wide range of legal services.","We adopt legal syllogism prompting strategies to construct supervised fine-tuning datasets in the Chinese Judicial domain and fine-tune LLMs with legal reasoning capability.","We augment LLMs with a retrieval module to enhance models' ability to access and utilize external legal knowledge.","A comprehensive legal benchmark, DISC-Law-Eval, is presented to evaluate intelligent legal systems from both objective and subjective dimensions.","Quantitative and qualitative results on DISC-Law-Eval demonstrate the effectiveness of our system in serving various users across diverse legal scenarios.","The detailed resources are available at https://github.com/FudanDISC/DISC-LawLLM."],"url":"http://arxiv.org/abs/2309.11325v1"}
{"created":"2023-09-20 13:47:42","title":"Vector database management systems: Fundamental concepts, use-cases, and current challenges","abstract":"Vector database management systems have emerged as an important component in modern data management, driven by the growing importance for the need to computationally describe rich data such as texts, images and video in various domains such as recommender systems, similarity search, and chatbots. These data descriptions are captured as numerical vectors that are computationally inexpensive to store and compare. However, the unique characteristics of vectorized data, including high dimensionality and sparsity, demand specialized solutions for efficient storage, retrieval, and processing. This study provides an accessible introduction to the fundamental concepts, use-cases, and current challenges associated with vector database management systems, offering an overview for researchers and practitioners seeking to explore this burgeoning technology aimed to facilitate effective vector data management.","sentences":["Vector database management systems have emerged as an important component in modern data management, driven by the growing importance for the need to computationally describe rich data such as texts, images and video in various domains such as recommender systems, similarity search, and chatbots.","These data descriptions are captured as numerical vectors that are computationally inexpensive to store and compare.","However, the unique characteristics of vectorized data, including high dimensionality and sparsity, demand specialized solutions for efficient storage, retrieval, and processing.","This study provides an accessible introduction to the fundamental concepts, use-cases, and current challenges associated with vector database management systems, offering an overview for researchers and practitioners seeking to explore this burgeoning technology aimed to facilitate effective vector data management."],"url":"http://arxiv.org/abs/2309.11322v1"}
{"created":"2023-09-20 13:47:10","title":"Face Aging via Diffusion-based Editing","abstract":"In this paper, we address the problem of face aging: generating past or future facial images by incorporating age-related changes to the given face. Previous aging methods rely solely on human facial image datasets and are thus constrained by their inherent scale and bias. This restricts their application to a limited generatable age range and the inability to handle large age gaps. We propose FADING, a novel approach to address Face Aging via DIffusion-based editiNG. We go beyond existing methods by leveraging the rich prior of large-scale language-image diffusion models. First, we specialize a pre-trained diffusion model for the task of face age editing by using an age-aware fine-tuning scheme. Next, we invert the input image to latent noise and obtain optimized null text embeddings. Finally, we perform text-guided local age editing via attention control. The quantitative and qualitative analyses demonstrate that our method outperforms existing approaches with respect to aging accuracy, attribute preservation, and aging quality.","sentences":["In this paper, we address the problem of face aging: generating past or future facial images by incorporating age-related changes to the given face.","Previous aging methods rely solely on human facial image datasets and are thus constrained by their inherent scale and bias.","This restricts their application to a limited generatable age range and the inability to handle large age gaps.","We propose FADING, a novel approach to address Face Aging via DIffusion-based editiNG.","We go beyond existing methods by leveraging the rich prior of large-scale language-image diffusion models.","First, we specialize a pre-trained diffusion model for the task of face age editing by using an age-aware fine-tuning scheme.","Next, we invert the input image to latent noise and obtain optimized null text embeddings.","Finally, we perform text-guided local age editing via attention control.","The quantitative and qualitative analyses demonstrate that our method outperforms existing approaches with respect to aging accuracy, attribute preservation, and aging quality."],"url":"http://arxiv.org/abs/2309.11321v1"}
{"created":"2023-09-20 13:44:18","title":"WFTNet: Exploiting Global and Local Periodicity in Long-term Time Series Forecasting","abstract":"Recent CNN and Transformer-based models tried to utilize frequency and periodicity information for long-term time series forecasting. However, most existing work is based on Fourier transform, which cannot capture fine-grained and local frequency structure. In this paper, we propose a Wavelet-Fourier Transform Network (WFTNet) for long-term time series forecasting. WFTNet utilizes both Fourier and wavelet transforms to extract comprehensive temporal-frequency information from the signal, where Fourier transform captures the global periodic patterns and wavelet transform captures the local ones. Furthermore, we introduce a Periodicity-Weighted Coefficient (PWC) to adaptively balance the importance of global and local frequency patterns. Extensive experiments on various time series datasets show that WFTNet consistently outperforms other state-of-the-art baseline.","sentences":["Recent CNN and Transformer-based models tried to utilize frequency and periodicity information for long-term time series forecasting.","However, most existing work is based on Fourier transform, which cannot capture fine-grained and local frequency structure.","In this paper, we propose a Wavelet-Fourier Transform Network (WFTNet) for long-term time series forecasting.","WFTNet utilizes both Fourier and wavelet transforms to extract comprehensive temporal-frequency information from the signal, where Fourier transform captures the global periodic patterns and wavelet transform captures the local ones.","Furthermore, we introduce a Periodicity-Weighted Coefficient (PWC) to adaptively balance the importance of global and local frequency patterns.","Extensive experiments on various time series datasets show that WFTNet consistently outperforms other state-of-the-art baseline."],"url":"http://arxiv.org/abs/2309.11319v1"}
{"created":"2023-09-20 13:42:48","title":"Uncovering the effects of model initialization on deep model generalization: A study with adult and pediatric Chest X-ray images","abstract":"Model initialization techniques are vital for improving the performance and reliability of deep learning models in medical computer vision applications. While much literature exists on non-medical images, the impacts on medical images, particularly chest X-rays (CXRs) are less understood. Addressing this gap, our study explores three deep model initialization techniques: Cold-start, Warm-start, and Shrink and Perturb start, focusing on adult and pediatric populations. We specifically focus on scenarios with periodically arriving data for training, thereby embracing the real-world scenarios of ongoing data influx and the need for model updates. We evaluate these models for generalizability against external adult and pediatric CXR datasets. We also propose novel ensemble methods: F-score-weighted Sequential Least-Squares Quadratic Programming (F-SLSQP) and Attention-Guided Ensembles with Learnable Fuzzy Softmax to aggregate weight parameters from multiple models to capitalize on their collective knowledge and complementary representations. We perform statistical significance tests with 95% confidence intervals and p-values to analyze model performance. Our evaluations indicate models initialized with ImageNet-pre-trained weights demonstrate superior generalizability over randomly initialized counterparts, contradicting some findings for non-medical images. Notably, ImageNet-pretrained models exhibit consistent performance during internal and external testing across different training scenarios. Weight-level ensembles of these models show significantly higher recall (p<0.05) during testing compared to individual models. Thus, our study accentuates the benefits of ImageNet-pretrained weight initialization, especially when used with weight-level ensembles, for creating robust and generalizable deep learning solutions.","sentences":["Model initialization techniques are vital for improving the performance and reliability of deep learning models in medical computer vision applications.","While much literature exists on non-medical images, the impacts on medical images, particularly chest X-rays (CXRs) are less understood.","Addressing this gap, our study explores three deep model initialization techniques: Cold-start, Warm-start, and Shrink and Perturb start, focusing on adult and pediatric populations.","We specifically focus on scenarios with periodically arriving data for training, thereby embracing the real-world scenarios of ongoing data influx and the need for model updates.","We evaluate these models for generalizability against external adult and pediatric CXR datasets.","We also propose novel ensemble methods: F-score-weighted Sequential Least-Squares Quadratic Programming (F-SLSQP) and Attention-Guided Ensembles with Learnable Fuzzy Softmax to aggregate weight parameters from multiple models to capitalize on their collective knowledge and complementary representations.","We perform statistical significance tests with 95% confidence intervals and p-values to analyze model performance.","Our evaluations indicate models initialized with ImageNet-pre-trained weights demonstrate superior generalizability over randomly initialized counterparts, contradicting some findings for non-medical images.","Notably, ImageNet-pretrained models exhibit consistent performance during internal and external testing across different training scenarios.","Weight-level ensembles of these models show significantly higher recall (p<0.05) during testing compared to individual models.","Thus, our study accentuates the benefits of ImageNet-pretrained weight initialization, especially when used with weight-level ensembles, for creating robust and generalizable deep learning solutions."],"url":"http://arxiv.org/abs/2309.11318v1"}
{"created":"2023-09-20 13:41:45","title":"Dynamic Pricing of Applications in Cloud Marketplaces using Game Theory","abstract":"The competitive nature of Cloud marketplaces as new concerns in delivery of services makes the pricing policies a crucial task for firms. so that, pricing strategies has recently attracted many researchers. Since game theory can handle such competing well this concern is addressed by designing a normal form game between providers in current research. A committee is considered in which providers register for improving their competition based pricing policies. The functionality of game theory is applied to design dynamic pricing policies. The usage of the committee makes the game a complete information one, in which each player is aware of every others payoff functions. The players enhance their pricing policies to maximize their profits. The contribution of this paper is the quantitative modeling of Cloud marketplaces in form of a game to provide novel dynamic pricing strategies; the model is validated by proving the existence and the uniqueness of Nash equilibrium of the game.","sentences":["The competitive nature of Cloud marketplaces as new concerns in delivery of services makes the pricing policies a crucial task for firms.","so that, pricing strategies has recently attracted many researchers.","Since game theory can handle such competing well this concern is addressed by designing a normal form game between providers in current research.","A committee is considered in which providers register for improving their competition based pricing policies.","The functionality of game theory is applied to design dynamic pricing policies.","The usage of the committee makes the game a complete information one, in which each player is aware of every others payoff functions.","The players enhance their pricing policies to maximize their profits.","The contribution of this paper is the quantitative modeling of Cloud marketplaces in form of a game to provide novel dynamic pricing strategies; the model is validated by proving the existence and the uniqueness of Nash equilibrium of the game."],"url":"http://arxiv.org/abs/2309.11316v1"}
{"created":"2023-09-20 13:41:45","title":"Lazy Contracts: Alleviating High Gas Costs by Secure and Trustless Off-chain Execution of Smart Contracts","abstract":"Smart contracts are programs that are executed on the blockchain and can hold, manage and transfer assets in the form of cryptocurrencies. The contract's execution is then performed on-chain and is subject to consensus, i.e. every node on the blockchain network has to run the function calls and keep track of their side-effects. In most programmable blockchains, such as Ethereum, the notion of gas is introduced to prevent DoS attacks by malicious parties who might try to slow down the network by performing heavy computations. A fixed cost to each atomic operation, and the initiator of a function call pays the total gas cost as a transaction fee. This helps prevent DoS attacks, but the resulting fees are extremely high. For example, in 2022, on Ethereum alone, there has been a total gas usage of 1.77 Million ETH ~ 4.3 Billion USD. This thesis proposes \"lazy contracts\" as a solution to alleviate these costs. Our solution moves most of the computation off-chain, ensuring that each function call incurs only a tiny amount of gas usage, while preserving enough data on-chain to guarantee an implicit consensus about the state of the contract variables and ownership of funds. A complete on-chain execution of the functions will only be triggered in case two parties to the contract are in disagreement about the current state, which in turn can only happen if at least one party is dishonest. In such cases, our protocol can identify the dishonest party and penalize them by having them pay for the entire gas usage. Hence, no rational party has an incentive to act dishonestly. Finally, we perform extensive experiments over 160,735 real-world Solidity contracts that were involved in 9,055,492 transactions in January 2022--January 2023 on Ethereum and show that our approach reduces the overall gas usage by 55.4%, which amounts to an astounding saving of 109.9 Million USD in gas fees.","sentences":["Smart contracts are programs that are executed on the blockchain and can hold, manage and transfer assets in the form of cryptocurrencies.","The contract's execution is then performed on-chain and is subject to consensus, i.e. every node on the blockchain network has to run the function calls and keep track of their side-effects.","In most programmable blockchains, such as Ethereum, the notion of gas is introduced to prevent DoS attacks by malicious parties who might try to slow down the network by performing heavy computations.","A fixed cost to each atomic operation, and the initiator of a function call pays the total gas cost as a transaction fee.","This helps prevent DoS attacks, but the resulting fees are extremely high.","For example, in 2022, on Ethereum alone, there has been a total gas usage of 1.77 Million ETH ~ 4.3 Billion USD.","This thesis proposes \"lazy contracts\" as a solution to alleviate these costs.","Our solution moves most of the computation off-chain, ensuring that each function call incurs only a tiny amount of gas usage, while preserving enough data on-chain to guarantee an implicit consensus about the state of the contract variables and ownership of funds.","A complete on-chain execution of the functions will only be triggered in case two parties to the contract are in disagreement about the current state, which in turn can only happen if at least one party is dishonest.","In such cases, our protocol can identify the dishonest party and penalize them by having them pay for the entire gas usage.","Hence, no rational party has an incentive to act dishonestly.","Finally, we perform extensive experiments over 160,735 real-world Solidity contracts that were involved in 9,055,492 transactions in January 2022--January 2023 on Ethereum and show that our approach reduces the overall gas usage by 55.4%, which amounts to an astounding saving of 109.9 Million USD in gas fees."],"url":"http://arxiv.org/abs/2309.11317v1"}
{"created":"2023-09-20 13:38:43","title":"A Competition-based Pricing Strategy in Cloud Markets using Regret Minimization Techniques","abstract":"Cloud computing as a fairly new commercial paradigm, widely investigated by different researchers, already has a great range of challenges. Pricing is a major problem in Cloud computing marketplace; as providers are competing to attract more customers without knowing the pricing policies of each other. To overcome this lack of knowledge, we model their competition by an incomplete-information game. Considering the issue, this work proposes a pricing policy related to the regret minimization algorithm and applies it to the considered incomplete-information game. Based on the competition based marketplace of the Cloud, providers update the distribution of their strategies using the experienced regret. The idea of iteratively applying the algorithm for updating probabilities of strategies causes the regret get minimized faster. The experimental results show much more increase in profits of the providers in comparison with other pricing policies. Besides, the efficiency of a variety of regret minimization techniques in a simulated marketplace of Cloud are discussed which have not been observed in the studied literature. Moreover, return on investment of providers in considered organizations is studied and promising results appeared.","sentences":["Cloud computing as a fairly new commercial paradigm, widely investigated by different researchers, already has a great range of challenges.","Pricing is a major problem in Cloud computing marketplace; as providers are competing to attract more customers without knowing the pricing policies of each other.","To overcome this lack of knowledge, we model their competition by an incomplete-information game.","Considering the issue, this work proposes a pricing policy related to the regret minimization algorithm and applies it to the considered incomplete-information game.","Based on the competition based marketplace of the Cloud, providers update the distribution of their strategies using the experienced regret.","The idea of iteratively applying the algorithm for updating probabilities of strategies causes the regret get minimized faster.","The experimental results show much more increase in profits of the providers in comparison with other pricing policies.","Besides, the efficiency of a variety of regret minimization techniques in a simulated marketplace of Cloud are discussed which have not been observed in the studied literature.","Moreover, return on investment of providers in considered organizations is studied and promising results appeared."],"url":"http://arxiv.org/abs/2309.11312v1"}
{"created":"2023-09-20 13:34:03","title":"Rating Prediction in Conversational Task Assistants with Behavioral and Conversational-Flow Features","abstract":"Predicting the success of Conversational Task Assistants (CTA) can be critical to understand user behavior and act accordingly. In this paper, we propose TB-Rater, a Transformer model which combines conversational-flow features with user behavior features for predicting user ratings in a CTA scenario. In particular, we use real human-agent conversations and ratings collected in the Alexa TaskBot challenge, a novel multimodal and multi-turn conversational context. Our results show the advantages of modeling both the conversational-flow and behavioral aspects of the conversation in a single model for offline rating prediction. Additionally, an analysis of the CTA-specific behavioral features brings insights into this setting and can be used to bootstrap future systems.","sentences":["Predicting the success of Conversational Task Assistants (CTA) can be critical to understand user behavior and act accordingly.","In this paper, we propose TB-Rater, a Transformer model which combines conversational-flow features with user behavior features for predicting user ratings in a CTA scenario.","In particular, we use real human-agent conversations and ratings collected in the Alexa TaskBot challenge, a novel multimodal and multi-turn conversational context.","Our results show the advantages of modeling both the conversational-flow and behavioral aspects of the conversation in a single model for offline rating prediction.","Additionally, an analysis of the CTA-specific behavioral features brings insights into this setting and can be used to bootstrap future systems."],"url":"http://arxiv.org/abs/2309.11307v1"}
{"created":"2023-09-20 13:33:00","title":"FaceDiffuser: Speech-Driven 3D Facial Animation Synthesis Using Diffusion","abstract":"Speech-driven 3D facial animation synthesis has been a challenging task both in industry and research. Recent methods mostly focus on deterministic deep learning methods meaning that given a speech input, the output is always the same. However, in reality, the non-verbal facial cues that reside throughout the face are non-deterministic in nature. In addition, majority of the approaches focus on 3D vertex based datasets and methods that are compatible with existing facial animation pipelines with rigged characters is scarce. To eliminate these issues, we present FaceDiffuser, a non-deterministic deep learning model to generate speech-driven facial animations that is trained with both 3D vertex and blendshape based datasets. Our method is based on the diffusion technique and uses the pre-trained large speech representation model HuBERT to encode the audio input. To the best of our knowledge, we are the first to employ the diffusion method for the task of speech-driven 3D facial animation synthesis. We have run extensive objective and subjective analyses and show that our approach achieves better or comparable results in comparison to the state-of-the-art methods. We also introduce a new in-house dataset that is based on a blendshape based rigged character. We recommend watching the accompanying supplementary video. The code and the dataset will be publicly available.","sentences":["Speech-driven 3D facial animation synthesis has been a challenging task both in industry and research.","Recent methods mostly focus on deterministic deep learning methods meaning that given a speech input, the output is always the same.","However, in reality, the non-verbal facial cues that reside throughout the face are non-deterministic in nature.","In addition, majority of the approaches focus on 3D vertex based datasets and methods that are compatible with existing facial animation pipelines with rigged characters is scarce.","To eliminate these issues, we present FaceDiffuser, a non-deterministic deep learning model to generate speech-driven facial animations that is trained with both 3D vertex and blendshape based datasets.","Our method is based on the diffusion technique and uses the pre-trained large speech representation model HuBERT to encode the audio input.","To the best of our knowledge, we are the first to employ the diffusion method for the task of speech-driven 3D facial animation synthesis.","We have run extensive objective and subjective analyses and show that our approach achieves better or comparable results in comparison to the state-of-the-art methods.","We also introduce a new in-house dataset that is based on a blendshape based rigged character.","We recommend watching the accompanying supplementary video.","The code and the dataset will be publicly available."],"url":"http://arxiv.org/abs/2309.11306v1"}
{"created":"2023-09-20 13:30:49","title":"Create and Find Flatness: Building Flat Training Spaces in Advance for Continual Learning","abstract":"Catastrophic forgetting remains a critical challenge in the field of continual learning, where neural networks struggle to retain prior knowledge while assimilating new information. Most existing studies emphasize mitigating this issue only when encountering new tasks, overlooking the significance of the pre-task phase. Therefore, we shift the attention to the current task learning stage, presenting a novel framework, C&F (Create and Find Flatness), which builds a flat training space for each task in advance. Specifically, during the learning of the current task, our framework adaptively creates a flat region around the minimum in the loss landscape. Subsequently, it finds the parameters' importance to the current task based on their flatness degrees. When adapting the model to a new task, constraints are applied according to the flatness and a flat space is simultaneously prepared for the impending task. We theoretically demonstrate the consistency between the created and found flatness. In this manner, our framework not only accommodates ample parameter space for learning new tasks but also preserves the preceding knowledge of earlier tasks. Experimental results exhibit C&F's state-of-the-art performance as a standalone continual learning approach and its efficacy as a framework incorporating other methods. Our work is available at https://github.com/Eric8932/Create-and-Find-Flatness.","sentences":["Catastrophic forgetting remains a critical challenge in the field of continual learning, where neural networks struggle to retain prior knowledge while assimilating new information.","Most existing studies emphasize mitigating this issue only when encountering new tasks, overlooking the significance of the pre-task phase.","Therefore, we shift the attention to the current task learning stage, presenting a novel framework, C&F (Create and Find Flatness), which builds a flat training space for each task in advance.","Specifically, during the learning of the current task, our framework adaptively creates a flat region around the minimum in the loss landscape.","Subsequently, it finds the parameters' importance to the current task based on their flatness degrees.","When adapting the model to a new task, constraints are applied according to the flatness and a flat space is simultaneously prepared for the impending task.","We theoretically demonstrate the consistency between the created and found flatness.","In this manner, our framework not only accommodates ample parameter space for learning new tasks but also preserves the preceding knowledge of earlier tasks.","Experimental results exhibit C&F's state-of-the-art performance as a standalone continual learning approach and its efficacy as a framework incorporating other methods.","Our work is available at https://github.com/Eric8932/Create-and-Find-Flatness."],"url":"http://arxiv.org/abs/2309.11305v1"}
