{"created":"2023-08-02 17:59:45","title":"ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders","abstract":"Our approach, which we call Embeddings for Language/Image-aligned X-Rays, or ELIXR, leverages a language-aligned image encoder combined or grafted onto a fixed LLM, PaLM 2, to perform a broad range of tasks. We train this lightweight adapter architecture using images paired with corresponding free-text radiology reports from the MIMIC-CXR dataset. ELIXR achieved state-of-the-art performance on zero-shot chest X-ray (CXR) classification (mean AUC of 0.850 across 13 findings), data-efficient CXR classification (mean AUCs of 0.893 and 0.898 across five findings (atelectasis, cardiomegaly, consolidation, pleural effusion, and pulmonary edema) for 1% (~2,200 images) and 10% (~22,000 images) training data), and semantic search (0.76 normalized discounted cumulative gain (NDCG) across nineteen queries, including perfect retrieval on twelve of them). Compared to existing data-efficient methods including supervised contrastive learning (SupCon), ELIXR required two orders of magnitude less data to reach similar performance. ELIXR also showed promise on CXR vision-language tasks, demonstrating overall accuracies of 58.7% and 62.5% on visual question answering and report quality assurance tasks, respectively. These results suggest that ELIXR is a robust and versatile approach to CXR AI.","sentences":["Our approach, which we call Embeddings for Language/Image-aligned X-Rays, or ELIXR, leverages a language-aligned image encoder combined or grafted onto a fixed LLM, PaLM 2, to perform a broad range of tasks.","We train this lightweight adapter architecture using images paired with corresponding free-text radiology reports from the MIMIC-CXR dataset.","ELIXR achieved state-of-the-art performance on zero-shot chest X-ray (CXR) classification (mean AUC of 0.850 across 13 findings), data-efficient CXR classification (mean AUCs of 0.893 and 0.898 across five findings (atelectasis, cardiomegaly, consolidation, pleural effusion, and pulmonary edema) for 1% (~2,200 images) and 10% (~22,000 images) training data), and semantic search (0.76 normalized discounted cumulative gain (NDCG) across nineteen queries, including perfect retrieval on twelve of them).","Compared to existing data-efficient methods including supervised contrastive learning (SupCon), ELIXR required two orders of magnitude less data to reach similar performance.","ELIXR also showed promise on CXR vision-language tasks, demonstrating overall accuracies of 58.7% and 62.5% on visual question answering and report quality assurance tasks, respectively.","These results suggest that ELIXR is a robust and versatile approach to CXR AI."],"url":"http://arxiv.org/abs/2308.01317v1"}
{"created":"2023-08-02 17:58:01","title":"Patched Denoising Diffusion Models For High-Resolution Image Synthesis","abstract":"We propose an effective denoising diffusion model for generating high-resolution images (e.g., 1024$\\times$512), trained on small-size image patches (e.g., 64$\\times$64). We name our algorithm Patch-DM, in which a new feature collage strategy is designed to avoid the boundary artifact when synthesizing large-size images. Feature collage systematically crops and combines partial features of the neighboring patches to predict the features of a shifted image patch, allowing the seamless generation of the entire image due to the overlap in the patch feature space. Patch-DM produces high-quality image synthesis results on our newly collected dataset of nature images (1024$\\times$512), as well as on standard benchmarks of smaller sizes (256$\\times$256), including LSUN-Bedroom, LSUN-Church, and FFHQ. We compare our method with previous patch-based generation methods and achieve state-of-the-art FID scores on all four datasets. Further, Patch-DM also reduces memory complexity compared to the classic diffusion models.","sentences":["We propose an effective denoising diffusion model for generating high-resolution images (e.g., 1024$\\times$512), trained on small-size image patches (e.g., 64$\\times$64).","We name our algorithm Patch-DM, in which a new feature collage strategy is designed to avoid the boundary artifact when synthesizing large-size images.","Feature collage systematically crops and combines partial features of the neighboring patches to predict the features of a shifted image patch, allowing the seamless generation of the entire image due to the overlap in the patch feature space.","Patch-DM produces high-quality image synthesis results on our newly collected dataset of nature images (1024$\\times$512), as well as on standard benchmarks of smaller sizes (256$\\times$256), including LSUN-Bedroom, LSUN-Church, and FFHQ.","We compare our method with previous patch-based generation methods and achieve state-of-the-art FID scores on all four datasets.","Further, Patch-DM also reduces memory complexity compared to the classic diffusion models."],"url":"http://arxiv.org/abs/2308.01316v1"}
{"created":"2023-08-02 17:57:25","title":"More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes","abstract":"CLIP, as a foundational vision language model, is widely used in zero-shot image classification due to its ability to understand various visual concepts and natural language descriptions. However, how to fully leverage CLIP's unprecedented human-like understanding capabilities to achieve better zero-shot classification is still an open question. This paper draws inspiration from the human visual perception process: a modern neuroscience view suggests that in classifying an object, humans first infer its class-independent attributes (e.g., background and orientation) which help separate the foreground object from the background, and then make decisions based on this information. Inspired by this, we observe that providing CLIP with contextual attributes improves zero-shot classification and mitigates reliance on spurious features. We also observe that CLIP itself can reasonably infer the attributes from an image. With these observations, we propose a training-free, two-step zero-shot classification method named PerceptionCLIP. Given an image, it first infers contextual attributes (e.g., background) and then performs object classification conditioning on them. Our experiments show that PerceptionCLIP achieves better generalization, group robustness, and better interpretability. For example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by 16.5% on the Waterbirds dataset and by 3.5% on CelebA.","sentences":["CLIP, as a foundational vision language model, is widely used in zero-shot image classification due to its ability to understand various visual concepts and natural language descriptions.","However, how to fully leverage CLIP's unprecedented human-like understanding capabilities to achieve better zero-shot classification is still an open question.","This paper draws inspiration from the human visual perception process: a modern neuroscience view suggests that in classifying an object, humans first infer its class-independent attributes (e.g., background and orientation) which help separate the foreground object from the background, and then make decisions based on this information.","Inspired by this, we observe that providing CLIP with contextual attributes improves zero-shot classification and mitigates reliance on spurious features.","We also observe that CLIP itself can reasonably infer the attributes from an image.","With these observations, we propose a training-free, two-step zero-shot classification method named PerceptionCLIP.","Given an image, it first infers contextual attributes (e.g., background) and then performs object classification conditioning on them.","Our experiments show that PerceptionCLIP achieves better generalization, group robustness, and better interpretability.","For example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by 16.5% on the Waterbirds dataset and by 3.5% on CelebA."],"url":"http://arxiv.org/abs/2308.01313v1"}
{"created":"2023-08-02 17:56:29","title":"Lode Encoder: AI-constrained co-creativity","abstract":"We present Lode Encoder, a gamified mixed-initiative level creation system for the classic platform-puzzle game Lode Runner. The system is built around several autoencoders which are trained on sets of Lode Runner levels. When fed with the user's design, each autoencoder produces a version of that design which is closer in style to the levels that it was trained on. The Lode Encoder interface allows the user to build and edit levels through 'painting' from the suggestions provided by the autoencoders. Crucially, in order to encourage designers to explore new possibilities, the system does not include more traditional editing tools. We report on the system design and training procedure, as well as on the evolution of the system itself and user tests.","sentences":["We present Lode Encoder, a gamified mixed-initiative level creation system for the classic platform-puzzle game Lode Runner.","The system is built around several autoencoders which are trained on sets of Lode Runner levels.","When fed with the user's design, each autoencoder produces a version of that design which is closer in style to the levels that it was trained on.","The Lode Encoder interface allows the user to build and edit levels through 'painting' from the suggestions provided by the autoencoders.","Crucially, in order to encourage designers to explore new possibilities, the system does not include more traditional editing tools.","We report on the system design and training procedure, as well as on the evolution of the system itself and user tests."],"url":"http://arxiv.org/abs/2308.01312v1"}
{"created":"2023-08-02 17:56:05","title":"TEASMA: A Practical Approach for the Test Assessment of Deep Neural Networks using Mutation Analysis","abstract":"Successful deployment of Deep Neural Networks (DNNs), particularly in safety-critical systems, requires their validation with an adequate test set to ensure a sufficient degree of confidence in test outcomes. Mutation analysis, one of the main techniques for measuring test adequacy in traditional software, has been adapted to DNNs in recent years. This technique is based on generating mutants that aim to be representative of actual faults and thus can be used for test adequacy assessment. In this paper, we investigate for the first time whether mutation operators that directly modify the trained DNN model (i.e., post-training) can be used for reliably assessing the test inputs of DNNs. We propose and evaluate TEASMA, an approach based on post-training mutation for assessing the adequacy of DNN's test sets. In practice, TEASMA allows engineers to decide whether they will be able to trust test results and thus validate the DNN before its deployment. Based on a DNN model's training set, TEASMA provides a methodology to build accurate prediction models of the Fault Detection Rate (FDR) of a test set from its mutation score, thus enabling its assessment. Our large empirical evaluation, across multiple DNN models, shows that predicted FDR values have a strong linear correlation (R2 >= 0.94) with actual values. Consequently, empirical evidence suggests that TEASMA provides a reliable basis for confidently deciding whether to trust test results or improve the test set.","sentences":["Successful deployment of Deep Neural Networks (DNNs), particularly in safety-critical systems, requires their validation with an adequate test set to ensure a sufficient degree of confidence in test outcomes.","Mutation analysis, one of the main techniques for measuring test adequacy in traditional software, has been adapted to DNNs in recent years.","This technique is based on generating mutants that aim to be representative of actual faults and thus can be used for test adequacy assessment.","In this paper, we investigate for the first time whether mutation operators that directly modify the trained DNN model (i.e., post-training) can be used for reliably assessing the test inputs of DNNs.","We propose and evaluate TEASMA, an approach based on post-training mutation for assessing the adequacy of DNN's test sets.","In practice, TEASMA allows engineers to decide whether they will be able to trust test results and thus validate the DNN before its deployment.","Based on a DNN model's training set, TEASMA provides a methodology to build accurate prediction models of the Fault Detection Rate (FDR) of a test set from its mutation score, thus enabling its assessment.","Our large empirical evaluation, across multiple DNN models, shows that predicted FDR values have a strong linear correlation (R2 >= 0.94) with actual values.","Consequently, empirical evidence suggests that TEASMA provides a reliable basis for confidently deciding whether to trust test results or improve the test set."],"url":"http://arxiv.org/abs/2308.01311v1"}
{"created":"2023-08-02 17:52:37","title":"Masked and Swapped Sequence Modeling for Next Novel Basket Recommendation in Grocery Shopping","abstract":"Next basket recommendation (NBR) is the task of predicting the next set of items based on a sequence of already purchased baskets. It is a recommendation task that has been widely studied, especially in the context of grocery shopping. In next basket recommendation (NBR), it is useful to distinguish between repeat items, i.e., items that a user has consumed before, and explore items, i.e., items that a user has not consumed before. Most NBR work either ignores this distinction or focuses on repeat items. We formulate the next novel basket recommendation (NNBR) task, i.e., the task of recommending a basket that only consists of novel items, which is valuable for both real-world application and NBR evaluation. We evaluate how existing NBR methods perform on the NNBR task and find that, so far, limited progress has been made w.r.t. the NNBR task. To address the NNBR task, we propose a simple bi-directional transformer basket recommendation model (BTBR), which is focused on directly modeling item-to-item correlations within and across baskets instead of learning complex basket representations. To properly train BTBR, we propose and investigate several masking strategies and training objectives: (i) item-level random masking, (ii) item-level select masking, (iii) basket-level all masking, (iv) basket-level explore masking, and (v) joint masking. In addition, an item-basket swapping strategy is proposed to enrich the item interactions within the same baskets. We conduct extensive experiments on three open datasets with various characteristics. The results demonstrate the effectiveness of BTBR and our masking and swapping strategies for the NNBR task. BTBR with a properly selected masking and swapping strategy can substantially improve NNBR performance.","sentences":["Next basket recommendation (NBR) is the task of predicting the next set of items based on a sequence of already purchased baskets.","It is a recommendation task that has been widely studied, especially in the context of grocery shopping.","In next basket recommendation (NBR), it is useful to distinguish between repeat items, i.e., items that a user has consumed before, and explore items, i.e., items that a user has not consumed before.","Most NBR work either ignores this distinction or focuses on repeat items.","We formulate the next novel basket recommendation (NNBR) task, i.e., the task of recommending a basket that only consists of novel items, which is valuable for both real-world application and NBR evaluation.","We evaluate how existing NBR methods perform on the NNBR task and find that, so far, limited progress has been made w.r.t.","the NNBR task.","To address the NNBR task, we propose a simple bi-directional transformer basket recommendation model (BTBR), which is focused on directly modeling item-to-item correlations within and across baskets instead of learning complex basket representations.","To properly train BTBR, we propose and investigate several masking strategies and training objectives: (i) item-level random masking, (ii) item-level select masking, (iii) basket-level all masking, (iv) basket-level explore masking, and (v) joint masking.","In addition, an item-basket swapping strategy is proposed to enrich the item interactions within the same baskets.","We conduct extensive experiments on three open datasets with various characteristics.","The results demonstrate the effectiveness of BTBR and our masking and swapping strategies for the NNBR task.","BTBR with a properly selected masking and swapping strategy can substantially improve NNBR performance."],"url":"http://arxiv.org/abs/2308.01308v1"}
{"created":"2023-08-02 17:47:35","title":"Peer Surveillance in Online Communities","abstract":"Online communities are not safe spaces for user privacy. Even though existing research focuses on creating and improving various content moderation strategies and privacy preserving technologies, platforms hosting online communities support features allowing users to surveil one another--leading to harassment, personal data breaches, and offline harm. To tackle this problem, we introduce a new, work-in-progress framework for analyzing data privacy within vulnerable, identity-based online communities. Where current SOUPS papers study surveillance and longitudinal user data as two distinct challenges to user privacy, more work needs to be done in exploring the sites where surveillance and historical user data assemble. By synthesizing over 40 years of developments in the analysis of surveillance, we derive properties of online communities that enable the abuse of user data by fellow community members and suggest key steps to improving security for vulnerable users. Deploying this new framework on new and existing platforms will ensure that online communities are privacy-conscious and designed more inclusively.","sentences":["Online communities are not safe spaces for user privacy.","Even though existing research focuses on creating and improving various content moderation strategies and privacy preserving technologies, platforms hosting online communities support features allowing users to surveil one another--leading to harassment, personal data breaches, and offline harm.","To tackle this problem, we introduce a new, work-in-progress framework for analyzing data privacy within vulnerable, identity-based online communities.","Where current SOUPS papers study surveillance and longitudinal user data as two distinct challenges to user privacy, more work needs to be done in exploring the sites where surveillance and historical user data assemble.","By synthesizing over 40 years of developments in the analysis of surveillance, we derive properties of online communities that enable the abuse of user data by fellow community members and suggest key steps to improving security for vulnerable users.","Deploying this new framework on new and existing platforms will ensure that online communities are privacy-conscious and designed more inclusively."],"url":"http://arxiv.org/abs/2308.01304v1"}
{"created":"2023-08-02 17:40:34","title":"Handling Communication via APIs for Microservices","abstract":"Enterprises in their journey to the cloud, want to decompose their monolith applications into microservices to maximize cloud benefits. Current research focuses a lot on how to partition the monolith into smaller clusters that perform well across standard metrics like coupling, cohesion, etc. However, there is little research done on taking the partitions, identifying their dependencies between the microservices, exploring ways to further reduce the dependencies, and making appropriate code changes to enable robust communication without modifying the application behaviour.   In this work, we discuss the challenges with the conventional techniques of communication using JSON and propose an alternative way of ID-passing via APIs. We also devise an algorithm to reduce the number of APIs. For this, we construct subgraphs of methods and their associated variables in each class and relocate them to their more functionally aligned microservices. Our quantitative and qualitative studies on five public Java applications clearly demonstrate that our refactored microservices using ID have decidedly better time and memory complexities than JSON. Our automation reduces 40-60\\% of the manual refactoring efforts.","sentences":["Enterprises in their journey to the cloud, want to decompose their monolith applications into microservices to maximize cloud benefits.","Current research focuses a lot on how to partition the monolith into smaller clusters that perform well across standard metrics like coupling, cohesion, etc.","However, there is little research done on taking the partitions, identifying their dependencies between the microservices, exploring ways to further reduce the dependencies, and making appropriate code changes to enable robust communication without modifying the application behaviour.   ","In this work, we discuss the challenges with the conventional techniques of communication using JSON and propose an alternative way of ID-passing via APIs.","We also devise an algorithm to reduce the number of APIs.","For this, we construct subgraphs of methods and their associated variables in each class and relocate them to their more functionally aligned microservices.","Our quantitative and qualitative studies on five public Java applications clearly demonstrate that our refactored microservices using ID have decidedly better time and memory complexities than JSON.","Our automation reduces 40-60\\% of the manual refactoring efforts."],"url":"http://arxiv.org/abs/2308.01302v1"}
{"created":"2023-08-02 17:39:30","title":"Revisiting DETR Pre-training for Object Detection","abstract":"Motivated by that DETR-based approaches have established new records on COCO detection and segmentation benchmarks, many recent endeavors show increasing interest in how to further improve DETR-based approaches by pre-training the Transformer in a self-supervised manner while keeping the backbone frozen. Some studies already claimed significant improvements in accuracy. In this paper, we take a closer look at their experimental methodology and check if their approaches are still effective on the very recent state-of-the-art such as $\\mathcal{H}$-Deformable-DETR. We conduct thorough experiments on COCO object detection tasks to study the influence of the choice of pre-training datasets, localization, and classification target generation schemes. Unfortunately, we find the previous representative self-supervised approach such as DETReg, fails to boost the performance of the strong DETR-based approaches on full data regimes. We further analyze the reasons and find that simply combining a more accurate box predictor and Objects$365$ benchmark can significantly improve the results in follow-up experiments. We demonstrate the effectiveness of our approach by achieving strong object detection results of AP=$59.3\\%$ on COCO val set, which surpasses $\\mathcal{H}$-Deformable-DETR + Swin-L by +$1.4\\%$. Last, we generate a series of synthetic pre-training datasets by combining the very recent image-to-text captioning models (LLaVA) and text-to-image generative models (SDXL). Notably, pre-training on these synthetic datasets leads to notable improvements in object detection performance. Looking ahead, we anticipate substantial advantages through the future expansion of the synthetic pre-training dataset.","sentences":["Motivated by that DETR-based approaches have established new records on COCO detection and segmentation benchmarks, many recent endeavors show increasing interest in how to further improve DETR-based approaches by pre-training the Transformer in a self-supervised manner while keeping the backbone frozen.","Some studies already claimed significant improvements in accuracy.","In this paper, we take a closer look at their experimental methodology and check if their approaches are still effective on the very recent state-of-the-art such as $\\mathcal{H}$-Deformable-DETR.","We conduct thorough experiments on COCO object detection tasks to study the influence of the choice of pre-training datasets, localization, and classification target generation schemes.","Unfortunately, we find the previous representative self-supervised approach such as DETReg, fails to boost the performance of the strong DETR-based approaches on full data regimes.","We further analyze the reasons and find that simply combining a more accurate box predictor and Objects$365$ benchmark can significantly improve the results in follow-up experiments.","We demonstrate the effectiveness of our approach by achieving strong object detection results of AP=$59.3\\%$ on COCO val set, which surpasses $\\mathcal{H}$-Deformable-DETR + Swin-L by +$1.4\\%$. Last, we generate a series of synthetic pre-training datasets by combining the very recent image-to-text captioning models (LLaVA) and text-to-image generative models (SDXL).","Notably, pre-training on these synthetic datasets leads to notable improvements in object detection performance.","Looking ahead, we anticipate substantial advantages through the future expansion of the synthetic pre-training dataset."],"url":"http://arxiv.org/abs/2308.01300v1"}
{"created":"2023-08-02 17:33:30","title":"Straggler Mitigation and Latency Optimization in Blockchain-based Hierarchical Federated Learning","abstract":"Cloud-edge-device hierarchical federated learning (HFL) has been recently proposed to achieve communication-efficient and privacy-preserving distributed learning. However, there exist several critical challenges, such as the single point of failure and potential stragglers in both edge servers and local devices. To resolve these issues, we propose a decentralized and straggler-tolerant blockchain-based HFL (BHFL) framework. Specifically, a Raft-based consortium blockchain is deployed on edge servers to provide a distributed and trusted computing environment for global model aggregation in BHFL. To mitigate the influence of stragglers on learning, we propose a novel aggregation method, HieAvg, which utilizes the historical weights of stragglers to estimate the missing submissions. Furthermore, we optimize the overall latency of BHFL by jointly considering the constraints of global model convergence and blockchain consensus delay. Theoretical analysis and experimental evaluation show that our proposed BHFL based on HieAvg can converge in the presence of stragglers, which performs better than the traditional methods even when the loss function is non-convex and the data on local devices are non-independent and identically distributed (non-IID).","sentences":["Cloud-edge-device hierarchical federated learning (HFL) has been recently proposed to achieve communication-efficient and privacy-preserving distributed learning.","However, there exist several critical challenges, such as the single point of failure and potential stragglers in both edge servers and local devices.","To resolve these issues, we propose a decentralized and straggler-tolerant blockchain-based HFL (BHFL) framework.","Specifically, a Raft-based consortium blockchain is deployed on edge servers to provide a distributed and trusted computing environment for global model aggregation in BHFL.","To mitigate the influence of stragglers on learning, we propose a novel aggregation method, HieAvg, which utilizes the historical weights of stragglers to estimate the missing submissions.","Furthermore, we optimize the overall latency of BHFL by jointly considering the constraints of global model convergence and blockchain consensus delay.","Theoretical analysis and experimental evaluation show that our proposed BHFL based on HieAvg can converge in the presence of stragglers, which performs better than the traditional methods even when the loss function is non-convex and the data on local devices are non-independent and identically distributed (non-IID)."],"url":"http://arxiv.org/abs/2308.01296v1"}
{"created":"2023-08-02 17:18:19","title":"Polynomial-delay Enumeration Kernelizations for Cuts of Bounded Degree","abstract":"Enumeration kernelization was first proposed by Creignou et al. [TOCS 2017] and was later refined by Golovach et al. [JCSS 2022] into two different variants: fully-polynomial enumeration kernelization and polynomial-delay enumeration kernelization. In this paper, we consider the d-CUT problem from the perspective of (polynomial-delay) enumeration kenrelization. Given an undirected graph G = (V, E), a cut F = E(A, B) is a d-cut of G if every u in A has at most d neighbors in B and every v in B has at most d neighbors in A. Checking the existence of a d-cut in a graph is a well-known NP-hard problem and is well-studied in parameterized complexity [Algorithmica 2021, IWOCA 2021]. This problem also generalizes a well-studied problem MATCHING CUT (set d = 1) that has been a central problem in the literature of polynomial-delay enumeration kernelization. In this paper, we study three different enumeration variants of this problem, ENUM d-CUT, ENUM MIN-d-CUT and ENUM MAX-d-CUT that intends to enumerate all the d-cuts, all the minimal d-cuts and all the maximal d-cuts respectively. We consider various structural parameters of the input and provide polynomial-delay enumeration kernels for ENUM d-CUT and ENUM MAX-d-CUT and fully-polynomial enumeration kernels of polynomial size for ENUM MIN-d-CUT.","sentences":["Enumeration kernelization was first proposed by Creignou et al.","[TOCS 2017] and was later refined by Golovach et al.","[JCSS 2022] into two different variants: fully-polynomial enumeration kernelization and polynomial-delay enumeration kernelization.","In this paper, we consider the d-CUT problem from the perspective of (polynomial-delay) enumeration kenrelization.","Given an undirected graph G = (V, E), a cut F = E(A, B) is a d-cut of G if every u in A has at most d neighbors in B and every v in B has at most d neighbors in A. Checking the existence of a d-cut in a graph is a well-known NP-hard problem and is well-studied in parameterized complexity","[Algorithmica 2021, IWOCA 2021].","This problem also generalizes a well-studied problem MATCHING CUT (set d = 1) that has been a central problem in the literature of polynomial-delay enumeration kernelization.","In this paper, we study three different enumeration variants of this problem, ENUM d-CUT, ENUM MIN-d-CUT and ENUM MAX-d-CUT that intends to enumerate all the d-cuts, all the minimal d-cuts and all the maximal d-cuts respectively.","We consider various structural parameters of the input and provide polynomial-delay enumeration kernels for ENUM d-CUT and ENUM MAX-d-CUT and fully-polynomial enumeration kernels of polynomial size for ENUM MIN-d-CUT."],"url":"http://arxiv.org/abs/2308.01286v1"}
{"created":"2023-08-02 17:14:22","title":"Flows: Building Blocks of Reasoning and Collaborating AI","abstract":"Recent advances in artificial intelligence (AI) have produced highly capable and controllable systems. This creates unprecedented opportunities for structured reasoning as well as collaboration among multiple AI systems and humans. To fully realize this potential, it is essential to develop a principled way of designing and studying such structured interactions. For this purpose, we introduce the conceptual framework of Flows: a systematic approach to modeling complex interactions. Flows are self-contained building blocks of computation, with an isolated state, communicating through a standardized message-based interface. This modular design allows Flows to be recursively composed into arbitrarily nested interactions, with a substantial reduction of complexity. Crucially, any interaction can be implemented using this framework, including prior work on AI--AI and human--AI interactions, prompt engineering schemes, and tool augmentation. We demonstrate the potential of Flows on the task of competitive coding, a challenging task on which even GPT-4 struggles. Our results suggest that structured reasoning and collaboration substantially improve generalization, with AI-only Flows adding +$21$ and human--AI Flows adding +$54$ absolute points in terms of solve rate. To support rapid and rigorous research, we introduce the aiFlows library. The library comes with a repository of Flows that can be easily used, extended, and composed into novel, more complex Flows.   The aiFlows library is available at https://github.com/epfl-dlab/aiflows. Data and Flows for reproducing our experiments are available at https://github.com/epfl-dlab/cc_flows.","sentences":["Recent advances in artificial intelligence (AI) have produced highly capable and controllable systems.","This creates unprecedented opportunities for structured reasoning as well as collaboration among multiple AI systems and humans.","To fully realize this potential, it is essential to develop a principled way of designing and studying such structured interactions.","For this purpose, we introduce the conceptual framework of Flows: a systematic approach to modeling complex interactions.","Flows are self-contained building blocks of computation, with an isolated state, communicating through a standardized message-based interface.","This modular design allows Flows to be recursively composed into arbitrarily nested interactions, with a substantial reduction of complexity.","Crucially, any interaction can be implemented using this framework, including prior work on AI--AI and human--AI interactions, prompt engineering schemes, and tool augmentation.","We demonstrate the potential of Flows on the task of competitive coding, a challenging task on which even GPT-4 struggles.","Our results suggest that structured reasoning and collaboration substantially improve generalization, with AI-only Flows adding +$21$ and human--AI Flows adding +$54$ absolute points in terms of solve rate.","To support rapid and rigorous research, we introduce the aiFlows library.","The library comes with a repository of Flows that can be easily used, extended, and composed into novel, more complex Flows.   ","The aiFlows library is available at https://github.com/epfl-dlab/aiflows.","Data and Flows for reproducing our experiments are available at https://github.com/epfl-dlab/cc_flows."],"url":"http://arxiv.org/abs/2308.01285v1"}
{"created":"2023-08-02 17:11:37","title":"Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?","abstract":"Large language models (LLMs) such as ChatGPT are increasingly being used for various use cases, including text content generation at scale. Although detection methods for such AI-generated text exist already, we investigate ChatGPT's performance as a detector on such AI-generated text, inspired by works that use ChatGPT as a data labeler or annotator. We evaluate the zero-shot performance of ChatGPT in the task of human-written vs. AI-generated text detection, and perform experiments on publicly available datasets. We empirically investigate if ChatGPT is symmetrically effective in detecting AI-generated or human-written text. Our findings provide insight on how ChatGPT and similar LLMs may be leveraged in automated detection pipelines by simply focusing on solving a specific aspect of the problem and deriving the rest from that solution. All code and data is available at \\url{https://github.com/AmritaBh/ChatGPT-as-Detector}.","sentences":["Large language models (LLMs) such as ChatGPT are increasingly being used for various use cases, including text content generation at scale.","Although detection methods for such AI-generated text exist already, we investigate ChatGPT's performance as a detector on such AI-generated text, inspired by works that use ChatGPT as a data labeler or annotator.","We evaluate the zero-shot performance of ChatGPT in the task of human-written vs. AI-generated text detection, and perform experiments on publicly available datasets.","We empirically investigate if ChatGPT is symmetrically effective in detecting AI-generated or human-written text.","Our findings provide insight on how ChatGPT and similar LLMs may be leveraged in automated detection pipelines by simply focusing on solving a specific aspect of the problem and deriving the rest from that solution.","All code and data is available at \\url{https://github.com/AmritaBh/ChatGPT-as-Detector}."],"url":"http://arxiv.org/abs/2308.01284v1"}
{"created":"2023-08-02 17:05:40","title":"Delegated Time-Lock Puzzle","abstract":"Time-Lock Puzzles (TLPs) are cryptographic protocols that enable a client to lock a message in such a way that a server can only unlock it after a specific time period. However, existing TLPs have certain limitations: (i) they assume that both the client and server always possess sufficient computational resources and (ii) they solely focus on the lower time bound for finding a solution, disregarding the upper bound that guarantees a regular server can find a solution within a certain time frame. Additionally, existing TLPs designed to handle multiple puzzles either (a) entail high verification costs or (b) lack generality, requiring identical time intervals between consecutive solutions. To address these limitations, this paper introduces, for the first time, the concept of a \"Delegated Time-Lock Puzzle\" and presents a protocol called \"Efficient Delegated Time-Lock Puzzle\" (ED-TLP) that realises this concept. ED-TLP allows the client and server to delegate their resource-demanding tasks to third-party helpers. It facilitates real-time verification of solution correctness and efficiently handles multiple puzzles with varying time intervals. ED-TLP ensures the delivery of solutions within predefined time limits by incorporating both an upper bound and a fair payment algorithm. We have implemented ED-TLP and conducted a comprehensive analysis of its overheads, demonstrating the efficiency of the construction.","sentences":["Time-Lock Puzzles (TLPs) are cryptographic protocols that enable a client to lock a message in such a way that a server can only unlock it after a specific time period.","However, existing TLPs have certain limitations: (i) they assume that both the client and server always possess sufficient computational resources and (ii) they solely focus on the lower time bound for finding a solution, disregarding the upper bound that guarantees a regular server can find a solution within a certain time frame.","Additionally, existing TLPs designed to handle multiple puzzles either (a) entail high verification costs or (b) lack generality, requiring identical time intervals between consecutive solutions.","To address these limitations, this paper introduces, for the first time, the concept of a \"Delegated Time-Lock Puzzle\" and presents a protocol called \"Efficient Delegated Time-Lock Puzzle\" (ED-TLP) that realises this concept.","ED-TLP allows the client and server to delegate their resource-demanding tasks to third-party helpers.","It facilitates real-time verification of solution correctness and efficiently handles multiple puzzles with varying time intervals.","ED-TLP ensures the delivery of solutions within predefined time limits by incorporating both an upper bound and a fair payment algorithm.","We have implemented ED-TLP and conducted a comprehensive analysis of its overheads, demonstrating the efficiency of the construction."],"url":"http://arxiv.org/abs/2308.01280v1"}
{"created":"2023-08-02 16:57:19","title":"BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems","abstract":"Although experience sharing (ES) accelerates multiagent reinforcement learning (MARL) in an advisor-advisee framework, attempts to apply ES to decentralized multiagent systems have so far relied on trusted environments and overlooked the possibility of adversarial manipulation and inference. Nevertheless, in a real-world setting, some Byzantine attackers, disguised as advisors, may provide false advice to the advisee and catastrophically degrade the overall learning performance. Also, an inference attacker, disguised as an advisee, may conduct several queries to infer the advisors' private information and make the entire ES process questionable in terms of privacy leakage. To address and tackle these issues, we propose a novel MARL framework (BRNES) that heuristically selects a dynamic neighbor zone for each advisee at each learning step and adopts a weighted experience aggregation technique to reduce Byzantine attack impact. Furthermore, to keep the agent's private information safe from adversarial inference attacks, we leverage the local differential privacy (LDP)-induced noise during the ES process. Our experiments show that our framework outperforms the state-of-the-art in terms of the steps to goal, obtained reward, and time to goal metrics. Particularly, our evaluation shows that the proposed framework is 8.32x faster than the current non-private frameworks and 1.41x faster than the private frameworks in an adversarial setting.","sentences":["Although experience sharing (ES) accelerates multiagent reinforcement learning (MARL) in an advisor-advisee framework, attempts to apply ES to decentralized multiagent systems have so far relied on trusted environments and overlooked the possibility of adversarial manipulation and inference.","Nevertheless, in a real-world setting, some Byzantine attackers, disguised as advisors, may provide false advice to the advisee and catastrophically degrade the overall learning performance.","Also, an inference attacker, disguised as an advisee, may conduct several queries to infer the advisors' private information and make the entire ES process questionable in terms of privacy leakage.","To address and tackle these issues, we propose a novel MARL framework (BRNES) that heuristically selects a dynamic neighbor zone for each advisee at each learning step and adopts a weighted experience aggregation technique to reduce Byzantine attack impact.","Furthermore, to keep the agent's private information safe from adversarial inference attacks, we leverage the local differential privacy (LDP)-induced noise during the ES process.","Our experiments show that our framework outperforms the state-of-the-art in terms of the steps to goal, obtained reward, and time to goal metrics.","Particularly, our evaluation shows that the proposed framework is 8.32x faster than the current non-private frameworks and 1.41x faster than the private frameworks in an adversarial setting."],"url":"http://arxiv.org/abs/2308.01274v1"}
{"created":"2023-08-02 16:56:17","title":"A Large-Scale Study of Phishing PDF Documents","abstract":"Phishing PDFs are malicious PDF documents that do not embed malware but trick victims into visiting malicious web pages leading to password theft or drive-by downloads. While recent reports indicate a surge of phishing PDFs, prior works have largely neglected this new threat, positioning phishing PDFs as accessories distributed via email phishing campaigns.   This paper challenges this belief and presents the first systematic and comprehensive study centered on phishing PDFs. Starting from a real-world dataset, we first identify 44 phishing PDF campaigns via clustering and characterize them by looking at their volumetric, temporal, and visual features. Among these, we identify three large campaigns covering 89% of the dataset, exhibiting significantly different volumetric and temporal properties compared to classical email phishing, and relying on web UI elements as visual baits. Finally, we look at the distribution vectors and show that phishing PDFs are not only distributed via attachments but also via SEO attacks, placing phishing PDFs outside the email distribution ecosystem.   This paper also assesses the usefulness of the VirusTotal scoring system, showing that phishing PDFs are ranked considerably low, creating a blind spot for organizations. While URL blocklists can help to prevent victims from visiting the attack web pages, PDF documents seem not subjected to any form of content-based filtering or detection.","sentences":["Phishing PDFs are malicious PDF documents that do not embed malware but trick victims into visiting malicious web pages leading to password theft or drive-by downloads.","While recent reports indicate a surge of phishing PDFs, prior works have largely neglected this new threat, positioning phishing PDFs as accessories distributed via email phishing campaigns.   ","This paper challenges this belief and presents the first systematic and comprehensive study centered on phishing PDFs.","Starting from a real-world dataset, we first identify 44 phishing PDF campaigns via clustering and characterize them by looking at their volumetric, temporal, and visual features.","Among these, we identify three large campaigns covering 89% of the dataset, exhibiting significantly different volumetric and temporal properties compared to classical email phishing, and relying on web UI elements as visual baits.","Finally, we look at the distribution vectors and show that phishing PDFs are not only distributed via attachments but also via SEO attacks, placing phishing PDFs outside the email distribution ecosystem.   ","This paper also assesses the usefulness of the VirusTotal scoring system, showing that phishing PDFs are ranked considerably low, creating a blind spot for organizations.","While URL blocklists can help to prevent victims from visiting the attack web pages, PDF documents seem not subjected to any form of content-based filtering or detection."],"url":"http://arxiv.org/abs/2308.01273v1"}
{"created":"2023-08-02 16:52:56","title":"A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC","abstract":"In this paper we present a practical Bayesian self-supervised learning method with Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC). Within this framework, we place a prior over the parameters of a self-supervised learning model and use cSGHMC to approximate the high dimensional and multimodal posterior distribution over the embeddings. By exploring an expressive posterior over the embeddings, Bayesian self-supervised learning produces interpretable and diverse representations. Marginalizing over these representations yields a significant gain in performance, calibration and out-of-distribution detection on a variety of downstream classification tasks. We provide experimental results on multiple classification tasks on four challenging datasets. Moreover, we demonstrate the effectiveness of the proposed method in out-of-distribution detection using the SVHN and CIFAR-10 datasets.","sentences":["In this paper we present a practical Bayesian self-supervised learning method with Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC).","Within this framework, we place a prior over the parameters of a self-supervised learning model and use cSGHMC to approximate the high dimensional and multimodal posterior distribution over the embeddings.","By exploring an expressive posterior over the embeddings, Bayesian self-supervised learning produces interpretable and diverse representations.","Marginalizing over these representations yields a significant gain in performance, calibration and out-of-distribution detection on a variety of downstream classification tasks.","We provide experimental results on multiple classification tasks on four challenging datasets.","Moreover, we demonstrate the effectiveness of the proposed method in out-of-distribution detection using the SVHN and CIFAR-10 datasets."],"url":"http://arxiv.org/abs/2308.01271v1"}
{"created":"2023-08-02 16:36:58","title":"Exploring the psychology of GPT-4's Moral and Legal Reasoning","abstract":"Large language models have been used as the foundation of highly sophisticated artificial intelligences, capable of delivering human-like responses to probes about legal and moral issues. However, these models are unreliable guides to their own inner workings, and even the engineering teams behind their creation are unable to explain exactly how they came to develop all of the capabilities they currently have. The emerging field of machine psychology seeks to gain insight into the processes and concepts that these models possess. In this paper, we employ the methods of psychology to probe into GPT-4's moral and legal reasoning. More specifically, we investigate the similarities and differences between GPT-4 and humans when it comes to intentionality ascriptions, judgments about causation, the morality of deception, moral foundations, the impact of moral luck on legal judgments, the concept of consent, and rule violation judgments. We find high correlations between human and AI responses, but also several significant systematic differences between them. We conclude with a discussion of the philosophical implications of our findings.","sentences":["Large language models have been used as the foundation of highly sophisticated artificial intelligences, capable of delivering human-like responses to probes about legal and moral issues.","However, these models are unreliable guides to their own inner workings, and even the engineering teams behind their creation are unable to explain exactly how they came to develop all of the capabilities they currently have.","The emerging field of machine psychology seeks to gain insight into the processes and concepts that these models possess.","In this paper, we employ the methods of psychology to probe into GPT-4's moral and legal reasoning.","More specifically, we investigate the similarities and differences between GPT-4 and humans when it comes to intentionality ascriptions, judgments about causation, the morality of deception, moral foundations, the impact of moral luck on legal judgments, the concept of consent, and rule violation judgments.","We find high correlations between human and AI responses, but also several significant systematic differences between them.","We conclude with a discussion of the philosophical implications of our findings."],"url":"http://arxiv.org/abs/2308.01264v1"}
{"created":"2023-08-02 16:30:40","title":"XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models","abstract":"Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content. This motivates safety efforts such as red-teaming and large-scale feedback learning, which aim to make models both helpful and harmless. However, there is a tension between these two objectives, since harmlessness requires models to refuse complying with unsafe prompts, and thus not be helpful. Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics. In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviours in a structured and systematic way. In its current form, XSTest comprises 200 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with. We describe XSTest's creation and composition, and use the test suite to highlight systematic failure modes in a recently-released state-of-the-art language model.","sentences":["Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content.","This motivates safety efforts such as red-teaming and large-scale feedback learning, which aim to make models both helpful and harmless.","However, there is a tension between these two objectives, since harmlessness requires models to refuse complying with unsafe prompts, and thus not be helpful.","Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics.","In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviours in a structured and systematic way.","In its current form, XSTest comprises 200 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with.","We describe XSTest's creation and composition, and use the test suite to highlight systematic failure modes in a recently-released state-of-the-art language model."],"url":"http://arxiv.org/abs/2308.01263v1"}
{"created":"2023-08-02 16:30:18","title":"Incorporating Season and Solar Specificity into Renderings made by a NeRF Architecture using Satellite Images","abstract":"As a result of Shadow NeRF and Sat-NeRF, it is possible to take the solar angle into account in a NeRF-based framework for rendering a scene from a novel viewpoint using satellite images for training. Our work extends those contributions and shows how one can make the renderings season-specific. Our main challenge was creating a Neural Radiance Field (NeRF) that could render seasonal features independently of viewing angle and solar angle while still being able to render shadows. We teach our network to render seasonal features by introducing one more input variable -- time of the year. However, the small training datasets typical of satellite imagery can introduce ambiguities in cases where shadows are present in the same location for every image of a particular season. We add additional terms to the loss function to discourage the network from using seasonal features for accounting for shadows. We show the performance of our network on eight Areas of Interest containing images captured by the Maxar WorldView-3 satellite. This evaluation includes tests measuring the ability of our framework to accurately render novel views, generate height maps, predict shadows, and specify seasonal features independently from shadows. Our ablation studies justify the choices made for network design parameters.","sentences":["As a result of Shadow NeRF and Sat-NeRF, it is possible to take the solar angle into account in a NeRF-based framework for rendering a scene from a novel viewpoint using satellite images for training.","Our work extends those contributions and shows how one can make the renderings season-specific.","Our main challenge was creating a Neural Radiance Field (NeRF) that could render seasonal features independently of viewing angle and solar angle while still being able to render shadows.","We teach our network to render seasonal features by introducing one more input variable -- time of the year.","However, the small training datasets typical of satellite imagery can introduce ambiguities in cases where shadows are present in the same location for every image of a particular season.","We add additional terms to the loss function to discourage the network from using seasonal features for accounting for shadows.","We show the performance of our network on eight Areas of Interest containing images captured by the Maxar WorldView-3 satellite.","This evaluation includes tests measuring the ability of our framework to accurately render novel views, generate height maps, predict shadows, and specify seasonal features independently from shadows.","Our ablation studies justify the choices made for network design parameters."],"url":"http://arxiv.org/abs/2308.01262v1"}
{"created":"2023-08-02 16:27:23","title":"Shaping Online Dialogue: Examining How Community Rules Affect Discussion Structures on Reddit","abstract":"Community rules play a key part in enabling or constraining the behaviors of members in online communities. However, little is unknown regarding whether and to what degree changing rules actually affects community dynamics. In this paper, we seek to understand how these behavior-governing rules shape the interactions between users, as well as the structure of their discussion. Using the top communities on Reddit (i.e. subreddits), we first contribute a taxonomy of behavior-based rule categories across Reddit. Then, we use a network analysis perspective to discover how changing implementation of different rule categories affects subreddits' user interaction and discussion networks over a 1.5 year period. Our study find several significant effects, including greater clustering among users when subreddits increase rules focused on structural regulation and how restricting allowable content surprisingly leads to more interactions between users. Our findings contribute to research in proactive moderation through rule setting, as well as lend valuable insights for online community designers and moderators to achieve desired community dynamics.","sentences":["Community rules play a key part in enabling or constraining the behaviors of members in online communities.","However, little is unknown regarding whether and to what degree changing rules actually affects community dynamics.","In this paper, we seek to understand how these behavior-governing rules shape the interactions between users, as well as the structure of their discussion.","Using the top communities on Reddit (i.e. subreddits), we first contribute a taxonomy of behavior-based rule categories across Reddit.","Then, we use a network analysis perspective to discover how changing implementation of different rule categories affects subreddits' user interaction and discussion networks over a 1.5 year period.","Our study find several significant effects, including greater clustering among users when subreddits increase rules focused on structural regulation and how restricting allowable content surprisingly leads to more interactions between users.","Our findings contribute to research in proactive moderation through rule setting, as well as lend valuable insights for online community designers and moderators to achieve desired community dynamics."],"url":"http://arxiv.org/abs/2308.01257v1"}
{"created":"2023-08-02 16:26:54","title":"Learning Spatial Distribution of Long-Term Trackers Scores","abstract":"Long-Term tracking is a hot topic in Computer Vision. In this context, competitive models are presented every year, showing a constant growth rate in performances, mainly measured in standardized protocols as Visual Object Tracking (VOT) and Object Tracking Benchmark (OTB). Fusion-trackers strategy has been applied over last few years for overcoming the known re-detection problem, turning out to be an important breakthrough. Following this approach, this work aims to generalize the fusion concept to an arbitrary number of trackers used as baseline trackers in the pipeline, leveraging a learning phase to better understand how outcomes correlate with each other, even when no target is present. A model and data independence conjecture will be evidenced in the manuscript, yielding a recall of 0.738 on LTB-50 dataset when learning from VOT-LT2022, and 0.619 by reversing the two datasets. In both cases, results are strongly competitive with state-of-the-art and recall turns out to be the first on the podium.","sentences":["Long-Term tracking is a hot topic in Computer Vision.","In this context, competitive models are presented every year, showing a constant growth rate in performances, mainly measured in standardized protocols as Visual Object Tracking (VOT) and Object Tracking Benchmark (OTB).","Fusion-trackers strategy has been applied over last few years for overcoming the known re-detection problem, turning out to be an important breakthrough.","Following this approach, this work aims to generalize the fusion concept to an arbitrary number of trackers used as baseline trackers in the pipeline, leveraging a learning phase to better understand how outcomes correlate with each other, even when no target is present.","A model and data independence conjecture will be evidenced in the manuscript, yielding a recall of 0.738 on LTB-50 dataset when learning from VOT-LT2022, and 0.619 by reversing the two datasets.","In both cases, results are strongly competitive with state-of-the-art and recall turns out to be the first on the podium."],"url":"http://arxiv.org/abs/2308.01256v1"}
{"created":"2023-08-02 16:11:51","title":"A Hyper-pixel-wise Contrastive Learning Augmented Segmentation Network for Old Landslide Detection Using High-Resolution Remote Sensing Images and Digital Elevation Model Data","abstract":"As a harzard disaster, landslide often brings tremendous losses to humanity, so it's necessary to achieve reliable detection of landslide. However, the problems of visual blur and small-sized dataset cause great challenges for old landslide detection task when using remote sensing data. To reliably extract semantic features, a hyper-pixel-wise contrastive learning augmented segmentation network (HPCL-Net) is proposed, which augments the local salient feature extraction from the boundaries of landslides through HPCL and fuses the heterogeneous infromation in the semantic space from High-Resolution Remote Sensing Images and Digital Elevation Model Data data. For full utilization of the precious samples, a global hyper-pixel-wise sample pair queues-based contrastive learning method, which includes the construction of global queues that store hyper-pixel-wise samples and the updating scheme of a momentum encoder, is developed, reliably enhancing the extraction ability of semantic features. The proposed HPCL-Net is evaluated on a Loess Plateau old landslide dataset and experiment results show that the model greatly improves the reliablity of old landslide detection compared to the previous old landslide segmentation model, where mIoU metric is increased from 0.620 to 0.651, Landslide IoU metric is increased from 0.334 to 0.394 and F1-score metric is increased from 0.501 to 0.565.","sentences":["As a harzard disaster, landslide often brings tremendous losses to humanity, so it's necessary to achieve reliable detection of landslide.","However, the problems of visual blur and small-sized dataset cause great challenges for old landslide detection task when using remote sensing data.","To reliably extract semantic features, a hyper-pixel-wise contrastive learning augmented segmentation network (HPCL-Net) is proposed, which augments the local salient feature extraction from the boundaries of landslides through HPCL and fuses the heterogeneous infromation in the semantic space from High-Resolution Remote Sensing Images and Digital Elevation Model Data data.","For full utilization of the precious samples, a global hyper-pixel-wise sample pair queues-based contrastive learning method, which includes the construction of global queues that store hyper-pixel-wise samples and the updating scheme of a momentum encoder, is developed, reliably enhancing the extraction ability of semantic features.","The proposed HPCL-Net is evaluated on a Loess Plateau old landslide dataset and experiment results show that the model greatly improves the reliablity of old landslide detection compared to the previous old landslide segmentation model, where mIoU metric is increased from 0.620 to 0.651, Landslide IoU metric is increased from 0.334 to 0.394 and F1-score metric is increased from 0.501 to 0.565."],"url":"http://arxiv.org/abs/2308.01251v1"}
{"created":"2023-08-02 16:09:07","title":"A Spatially Coupled LDPC Coding Scheme with Scalable Decoders for Space Division Multiplexing","abstract":"In this paper, we study the application of spatially coupled LDPC codes with sub-block locality for space division multiplexing. We focus on the information exchange between the sub-blocks and compare decoding strategies with respect to the complexity, performance and the information flow.","sentences":["In this paper, we study the application of spatially coupled LDPC codes with sub-block locality for space division multiplexing.","We focus on the information exchange between the sub-blocks and compare decoding strategies with respect to the complexity, performance and the information flow."],"url":"http://arxiv.org/abs/2308.01249v1"}
{"created":"2023-08-02 16:02:42","title":"A Hybrid Approach To Real-Time Multi-Object Tracking","abstract":"Multi-Object Tracking, also known as Multi-Target Tracking, is a significant area of computer vision that has many uses in a variety of settings. The development of deep learning, which has encouraged researchers to propose more and more work in this direction, has significantly impacted the scientific advancement around the study of tracking as well as many other domains related to computer vision. In fact, all of the solutions that are currently state-of-the-art in the literature and in the tracking industry, are built on top of deep learning methodologies that produce exceptionally good results. Deep learning is enabled thanks to the ever more powerful technology researchers can use to handle the significant computational resources demanded by these models. However, when real-time is a main requirement, developing a tracking system without being constrained by expensive hardware support with enormous computational resources is necessary to widen tracking applications in real-world contexts. To this end, a compromise is to combine powerful deep strategies with more traditional approaches to favor considerably lower processing solutions at the cost of less accurate tracking results even though suitable for real-time domains. Indeed, the present work goes in that direction, proposing a hybrid strategy for real-time multi-target tracking that combines effectively a classical optical flow algorithm with a deep learning architecture, targeted to a human-crowd tracking system exhibiting a desirable trade-off between performance in tracking precision and computational costs. The developed architecture was experimented with different settings, and yielded a MOTA of 0.608 out of the compared state-of-the-art 0.549 results, and about half the running time when introducing the optical flow phase, achieving almost the same performance in terms of accuracy.","sentences":["Multi-Object Tracking, also known as Multi-Target Tracking, is a significant area of computer vision that has many uses in a variety of settings.","The development of deep learning, which has encouraged researchers to propose more and more work in this direction, has significantly impacted the scientific advancement around the study of tracking as well as many other domains related to computer vision.","In fact, all of the solutions that are currently state-of-the-art in the literature and in the tracking industry, are built on top of deep learning methodologies that produce exceptionally good results.","Deep learning is enabled thanks to the ever more powerful technology researchers can use to handle the significant computational resources demanded by these models.","However, when real-time is a main requirement, developing a tracking system without being constrained by expensive hardware support with enormous computational resources is necessary to widen tracking applications in real-world contexts.","To this end, a compromise is to combine powerful deep strategies with more traditional approaches to favor considerably lower processing solutions at the cost of less accurate tracking results even though suitable for real-time domains.","Indeed, the present work goes in that direction, proposing a hybrid strategy for real-time multi-target tracking that combines effectively a classical optical flow algorithm with a deep learning architecture, targeted to a human-crowd tracking system exhibiting a desirable trade-off between performance in tracking precision and computational costs.","The developed architecture was experimented with different settings, and yielded a MOTA of 0.608 out of the compared state-of-the-art 0.549 results, and about half the running time when introducing the optical flow phase, achieving almost the same performance in terms of accuracy."],"url":"http://arxiv.org/abs/2308.01248v1"}
{"created":"2023-08-02 16:00:39","title":"Tirtha -- An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites","abstract":"Digital preservation of Cultural Heritage (CH) sites is crucial to protect them against damage from natural disasters or human activities. Creating 3D models of CH sites has become a popular method of digital preservation thanks to advancements in computer vision and photogrammetry. However, the process is time-consuming, expensive, and typically requires specialized equipment and expertise, posing challenges in resource-limited developing countries. Additionally, the lack of an open repository for 3D models hinders research and public engagement with their heritage. To address these issues, we propose Tirtha, a web platform for crowdsourcing images of CH sites and creating their 3D models. Tirtha utilizes state-of-the-art Structure from Motion (SfM) and Multi-View Stereo (MVS) techniques. It is modular, extensible and cost-effective, allowing for the incorporation of new techniques as photogrammetry advances. Tirtha is accessible through a web interface at https://tirtha.niser.ac.in and can be deployed on-premise or in a cloud environment. In our case studies, we demonstrate the pipeline's effectiveness by creating 3D models of temples in Odisha, India, using crowdsourced images. These models are available for viewing, interaction, and download on the Tirtha website. Our work aims to provide a dataset of crowdsourced images and 3D reconstructions for research in computer vision, heritage conservation, and related domains. Overall, Tirtha is a step towards democratizing digital preservation, primarily in resource-limited developing countries.","sentences":["Digital preservation of Cultural Heritage (CH) sites is crucial to protect them against damage from natural disasters or human activities.","Creating 3D models of CH sites has become a popular method of digital preservation thanks to advancements in computer vision and photogrammetry.","However, the process is time-consuming, expensive, and typically requires specialized equipment and expertise, posing challenges in resource-limited developing countries.","Additionally, the lack of an open repository for 3D models hinders research and public engagement with their heritage.","To address these issues, we propose Tirtha, a web platform for crowdsourcing images of CH sites and creating their 3D models.","Tirtha utilizes state-of-the-art Structure from Motion (SfM) and Multi-View Stereo (MVS) techniques.","It is modular, extensible and cost-effective, allowing for the incorporation of new techniques as photogrammetry advances.","Tirtha is accessible through a web interface at https://tirtha.niser.ac.in and can be deployed on-premise or in a cloud environment.","In our case studies, we demonstrate the pipeline's effectiveness by creating 3D models of temples in Odisha, India, using crowdsourced images.","These models are available for viewing, interaction, and download on the Tirtha website.","Our work aims to provide a dataset of crowdsourced images and 3D reconstructions for research in computer vision, heritage conservation, and related domains.","Overall, Tirtha is a step towards democratizing digital preservation, primarily in resource-limited developing countries."],"url":"http://arxiv.org/abs/2308.01246v1"}
{"created":"2023-08-02 15:56:43","title":"Digital Twin Brain: a simulation and assimilation platform for whole human brain","abstract":"In this work, we present a computing platform named digital twin brain (DTB) that can simulate spiking neuronal networks of the whole human brain scale and more importantly, a personalized biological brain structure. In comparison to most brain simulations with a homogeneous global structure, we highlight that the sparseness, couplingness and heterogeneity in the sMRI, DTI and PET data of the brain has an essential impact on the efficiency of brain simulation, which is proved from the scaling experiments that the DTB of human brain simulation is communication-intensive and memory-access intensive computing systems rather than computation-intensive. We utilize a number of optimization techniques to balance and integrate the computation loads and communication traffics from the heterogeneous biological structure to the general GPU-based HPC and achieve leading simulation performance for the whole human brain-scaled spiking neuronal networks. On the other hand, the biological structure, equipped with a mesoscopic data assimilation, enables the DTB to investigate brain cognitive function by a reverse-engineering method, which is demonstrated by a digital experiment of visual evaluation on the DTB. Furthermore, we believe that the developing DTB will be a promising powerful platform for a large of research orients including brain-inspiredintelligence, rain disease medicine and brain-machine interface.","sentences":["In this work, we present a computing platform named digital twin brain (DTB) that can simulate spiking neuronal networks of the whole human brain scale and more importantly, a personalized biological brain structure.","In comparison to most brain simulations with a homogeneous global structure, we highlight that the sparseness, couplingness and heterogeneity in the sMRI, DTI and PET data of the brain has an essential impact on the efficiency of brain simulation, which is proved from the scaling experiments that the DTB of human brain simulation is communication-intensive and memory-access intensive computing systems rather than computation-intensive.","We utilize a number of optimization techniques to balance and integrate the computation loads and communication traffics from the heterogeneous biological structure to the general GPU-based HPC and achieve leading simulation performance for the whole human brain-scaled spiking neuronal networks.","On the other hand, the biological structure, equipped with a mesoscopic data assimilation, enables the DTB to investigate brain cognitive function by a reverse-engineering method, which is demonstrated by a digital experiment of visual evaluation on the DTB.","Furthermore, we believe that the developing DTB will be a promising powerful platform for a large of research orients including brain-inspiredintelligence, rain disease medicine and brain-machine interface."],"url":"http://arxiv.org/abs/2308.01241v1"}
{"created":"2023-08-02 15:54:22","title":"Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation","abstract":"In this work, we evaluate 10 open-source instructed LLMs on four representative code comprehension and generation tasks. We have the following main findings. First, for the zero-shot setting, instructed LLMs are very competitive on code comprehension and generation tasks and sometimes even better than small SOTA models specifically fine-tuned on each downstream task. We also find that larger instructed LLMs are not always better on code-related tasks. Second, for the few-shot setting, we find that adding demonstration examples substantially helps instructed LLMs perform better on most code comprehension and generation tasks; however, the examples would sometimes induce unstable or even worse performance. Furthermore, we find widely-used BM25-based shot selection strategy significantly outperforms the basic random selection or fixed selection only on generation problems. Third, for the fine-tuning setting, we find that fine-tuning could further improve the model performance on downstream code comprehension and generation tasks compared to the zero-shot/one-shot performance. In addition, after being fine-tuned on the same downstream task dataset, instructed LLMs outperform both the small SOTA models and similar-scaled LLMs without instruction tuning. Based on our findings, we further present practical implications on model and usage recommendation, performance and cost trade-offs, and future direction.","sentences":["In this work, we evaluate 10 open-source instructed LLMs on four representative code comprehension and generation tasks.","We have the following main findings.","First, for the zero-shot setting, instructed LLMs are very competitive on code comprehension and generation tasks and sometimes even better than small SOTA models specifically fine-tuned on each downstream task.","We also find that larger instructed LLMs are not always better on code-related tasks.","Second, for the few-shot setting, we find that adding demonstration examples substantially helps instructed LLMs perform better on most code comprehension and generation tasks; however, the examples would sometimes induce unstable or even worse performance.","Furthermore, we find widely-used BM25-based shot selection strategy significantly outperforms the basic random selection or fixed selection only on generation problems.","Third, for the fine-tuning setting, we find that fine-tuning could further improve the model performance on downstream code comprehension and generation tasks compared to the zero-shot/one-shot performance.","In addition, after being fine-tuned on the same downstream task dataset, instructed LLMs outperform both the small SOTA models and similar-scaled LLMs without instruction tuning.","Based on our findings, we further present practical implications on model and usage recommendation, performance and cost trade-offs, and future direction."],"url":"http://arxiv.org/abs/2308.01240v1"}
{"created":"2023-08-02 15:48:33","title":"LSF-IDM: Lightweight Deep Learning Models for Automotive Intrusion Detection Model Based on Semantic Fusion","abstract":"Autonomous vehicles (AVs) are more vulnerable to network attacks due to the high connectivity and diverse communication modes between vehicles and external networks. Deep learning-based Intrusion detection, an effective method for detecting network attacks, can provide functional safety as well as a real-time communication guarantee for vehicles, thereby being widely used for AVs. Existing works well for cyber-attacks such as simple-mode but become a higher false alarm with a resource-limited environment required when the attack is concealed within a contextual feature. In this paper, we present a lightweight intrusion detection model based on semantic fusion, named LSF-IDM. Our motivation is based on the observation that, when injected the malicious packets to the in-vehicle networks (IVNs), the packet log presents a strict order of context feature because of the periodicity and broadcast nature of the CAN bus. Therefore, this model first captures the context as the semantic feature of messages by the BERT language framework. Thereafter, the lightweight model (e.g., BiLSTM) learns the fused feature from an input packet's classification and its output distribution in BERT based on knowledge distillation. Experiment results demonstrate the effectiveness of our methods in defending against several representative attacks from IVNs. We also perform the difference analysis of the proposed method with lightweight models and Bert to attain a deeper understanding of how the model balance detection performance and model complexity.","sentences":["Autonomous vehicles (AVs) are more vulnerable to network attacks due to the high connectivity and diverse communication modes between vehicles and external networks.","Deep learning-based Intrusion detection, an effective method for detecting network attacks, can provide functional safety as well as a real-time communication guarantee for vehicles, thereby being widely used for AVs.","Existing works well for cyber-attacks such as simple-mode but become a higher false alarm with a resource-limited environment required when the attack is concealed within a contextual feature.","In this paper, we present a lightweight intrusion detection model based on semantic fusion, named LSF-IDM.","Our motivation is based on the observation that, when injected the malicious packets to the in-vehicle networks (IVNs), the packet log presents a strict order of context feature because of the periodicity and broadcast nature of the CAN bus.","Therefore, this model first captures the context as the semantic feature of messages by the BERT language framework.","Thereafter, the lightweight model (e.g., BiLSTM) learns the fused feature from an input packet's classification and its output distribution in BERT based on knowledge distillation.","Experiment results demonstrate the effectiveness of our methods in defending against several representative attacks from IVNs.","We also perform the difference analysis of the proposed method with lightweight models and Bert to attain a deeper understanding of how the model balance detection performance and model complexity."],"url":"http://arxiv.org/abs/2308.01237v1"}
{"created":"2023-08-02 15:44:36","title":"Grounded Image Text Matching with Mismatched Relation Reasoning","abstract":"This paper introduces Grounded Image Text Matching with Mismatched Relation (GITM-MR), a novel visual-linguistic joint task that evaluates the relation understanding capabilities of transformer-based pre-trained models. GITM-MR requires a model to first determine if an expression describes an image, then localize referred objects or ground the mismatched parts of the text. We provide a benchmark for evaluating pre-trained models on this task, with a focus on the challenging settings of limited data and out-of-distribution sentence lengths. Our evaluation demonstrates that pre-trained models lack data efficiency and length generalization ability. To address this, we propose the Relation-sensitive Correspondence Reasoning Network (RCRN), which incorporates relation-aware reasoning via bi-directional message propagation guided by language structure. RCRN can be interpreted as a modular program and delivers strong performance in both length generalization and data efficiency.","sentences":["This paper introduces Grounded Image Text Matching with Mismatched Relation (GITM-MR), a novel visual-linguistic joint task that evaluates the relation understanding capabilities of transformer-based pre-trained models.","GITM-MR requires a model to first determine if an expression describes an image, then localize referred objects or ground the mismatched parts of the text.","We provide a benchmark for evaluating pre-trained models on this task, with a focus on the challenging settings of limited data and out-of-distribution sentence lengths.","Our evaluation demonstrates that pre-trained models lack data efficiency and length generalization ability.","To address this, we propose the Relation-sensitive Correspondence Reasoning Network (RCRN), which incorporates relation-aware reasoning via bi-directional message propagation guided by language structure.","RCRN can be interpreted as a modular program and delivers strong performance in both length generalization and data efficiency."],"url":"http://arxiv.org/abs/2308.01236v1"}
{"created":"2023-08-02 15:37:29","title":"Towards Integrated Sensing and Communications for 6G: A Standardization Perspective","abstract":"The radio communication division of the International Telecommunication Union (ITU-R) has recently adopted Integrated Sensing and Communication (ISAC) among the key usage scenarios for IMT-2030/6G. ISAC is envisioned to play a vital role in the upcoming wireless generation standards. In this work, we bring together several paramount and innovative aspects of ISAC technology from a global 6G standardization perspective, including both industrial and academic progress. Specifically, this article provides 6G requirements and ISAC-enabled vision, including various aspects of 6G standardization, benefits of ISAC co-existence, and integration challenges. Moreover, we present key enabling technologies, including intelligent metasurface-aided ISAC, as well as Orthogonal Time Frequency Space (OTFS) waveform design and interference management for ISAC. Finally, future aspects are discussed to open various research opportunities and challenges on the ISAC technology towards 6G wireless communications.","sentences":["The radio communication division of the International Telecommunication Union (ITU-R) has recently adopted Integrated Sensing and Communication (ISAC) among the key usage scenarios for IMT-2030/6G. ISAC is envisioned to play a vital role in the upcoming wireless generation standards.","In this work, we bring together several paramount and innovative aspects of ISAC technology from a global 6G standardization perspective, including both industrial and academic progress.","Specifically, this article provides 6G requirements and ISAC-enabled vision, including various aspects of 6G standardization, benefits of ISAC co-existence, and integration challenges.","Moreover, we present key enabling technologies, including intelligent metasurface-aided ISAC, as well as Orthogonal Time Frequency Space (OTFS) waveform design and interference management for ISAC.","Finally, future aspects are discussed to open various research opportunities and challenges on the ISAC technology towards 6G wireless communications."],"url":"http://arxiv.org/abs/2308.01227v1"}
{"created":"2023-08-02 15:29:22","title":"Do Multilingual Language Models Think Better in English?","abstract":"Translate-test is a popular technique to improve the performance of multilingual language models. This approach works by translating the input into English using an external machine translation system, and running inference over the translated input. However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by the language model. In this work, we introduce a new approach called self-translate, which overcomes the need of an external translation system by leveraging the few-shot translation capabilities of multilingual language models. Experiments over 5 tasks show that self-translate consistently outperforms direct inference, demonstrating that language models are unable to leverage their full multilingual potential when prompted in non-English languages. Our code is available at https://github.com/juletx/self-translate.","sentences":["Translate-test is a popular technique to improve the performance of multilingual language models.","This approach works by translating the input into English using an external machine translation system, and running inference over the translated input.","However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by the language model.","In this work, we introduce a new approach called self-translate, which overcomes the need of an external translation system by leveraging the few-shot translation capabilities of multilingual language models.","Experiments over 5 tasks show that self-translate consistently outperforms direct inference, demonstrating that language models are unable to leverage their full multilingual potential when prompted in non-English languages.","Our code is available at https://github.com/juletx/self-translate."],"url":"http://arxiv.org/abs/2308.01223v1"}
{"created":"2023-08-02 15:28:10","title":"Calibration in Deep Learning: A Survey of the State-of-the-Art","abstract":"Calibrating deep neural models plays an important role in building reliable, robust AI systems in safety-critical applications. Recent work has shown that modern neural networks that possess high predictive capability are poorly calibrated and produce unreliable model predictions. Though deep learning models achieve remarkable performance on various benchmarks, the study of model calibration and reliability is relatively underexplored. Ideal deep models should have not only high predictive performance but also be well calibrated. There have been some recent methods proposed to calibrate deep models by using different mechanisms. In this survey, we review the state-of-the-art calibration methods and provide an understanding of their principles for performing model calibration. First, we start with the definition of model calibration and explain the root causes of model miscalibration. Then we introduce the key metrics that can measure this aspect. It is followed by a summary of calibration methods that we roughly classified into four categories: post-hoc calibration, regularization methods, uncertainty estimation, and composition methods. We also covered some recent advancements in calibrating large models, particularly large language models (LLMs). Finally, we discuss some open issues, challenges, and potential directions.","sentences":["Calibrating deep neural models plays an important role in building reliable, robust AI systems in safety-critical applications.","Recent work has shown that modern neural networks that possess high predictive capability are poorly calibrated and produce unreliable model predictions.","Though deep learning models achieve remarkable performance on various benchmarks, the study of model calibration and reliability is relatively underexplored.","Ideal deep models should have not only high predictive performance but also be well calibrated.","There have been some recent methods proposed to calibrate deep models by using different mechanisms.","In this survey, we review the state-of-the-art calibration methods and provide an understanding of their principles for performing model calibration.","First, we start with the definition of model calibration and explain the root causes of model miscalibration.","Then we introduce the key metrics that can measure this aspect.","It is followed by a summary of calibration methods that we roughly classified into four categories: post-hoc calibration, regularization methods, uncertainty estimation, and composition methods.","We also covered some recent advancements in calibrating large models, particularly large language models (LLMs).","Finally, we discuss some open issues, challenges, and potential directions."],"url":"http://arxiv.org/abs/2308.01222v1"}
{"created":"2023-08-02 15:26:08","title":"Using ScrutinAI for Visual Inspection of DNN Performance in a Medical Use Case","abstract":"Our Visual Analytics (VA) tool ScrutinAI supports human analysts to investigate interactively model performanceand data sets. Model performance depends on labeling quality to a large extent. In particular in medical settings, generation of high quality labels requires in depth expert knowledge and is very costly. Often, data sets are labeled by collecting opinions of groups of experts. We use our VA tool to analyse the influence of label variations between different experts on the model performance. ScrutinAI facilitates to perform a root cause analysis that distinguishes weaknesses of deep neural network (DNN) models caused by varying or missing labeling quality from true weaknesses. We scrutinize the overall detection of intracranial hemorrhages and the more subtle differentiation between subtypes in a publicly available data set.","sentences":["Our Visual Analytics (VA) tool ScrutinAI supports human analysts to investigate interactively model performanceand data sets.","Model performance depends on labeling quality to a large extent.","In particular in medical settings, generation of high quality labels requires in depth expert knowledge and is very costly.","Often, data sets are labeled by collecting opinions of groups of experts.","We use our VA tool to analyse the influence of label variations between different experts on the model performance.","ScrutinAI facilitates to perform a root cause analysis that distinguishes weaknesses of deep neural network (DNN) models caused by varying or missing labeling quality from true weaknesses.","We scrutinize the overall detection of intracranial hemorrhages and the more subtle differentiation between subtypes in a publicly available data set."],"url":"http://arxiv.org/abs/2308.01220v1"}
{"created":"2023-08-02 15:22:01","title":"The sequence matters: A systematic literature review of using sequence analysis in Learning Analytics","abstract":"Describing and analysing sequences of learner actions is becoming more popular in learning analytics. Nevertheless, the authors found a variety of definitions of what a learning sequence is, of which data is used for the analysis, and which methods are implemented, as well as of the purpose and educational interventions designed with them. In this literature review, the authors aim to generate an overview of these concepts to develop a decision framework for using sequence analysis in educational research. After analysing 44 articles, the conclusions enable us to highlight different learning tasks and educational settings where sequences are analysed, identify data mapping models for different types of sequence actions, differentiate methods based on purpose and scope, and identify possible educational interventions based on the outcomes of sequence analysis.","sentences":["Describing and analysing sequences of learner actions is becoming more popular in learning analytics.","Nevertheless, the authors found a variety of definitions of what a learning sequence is, of which data is used for the analysis, and which methods are implemented, as well as of the purpose and educational interventions designed with them.","In this literature review, the authors aim to generate an overview of these concepts to develop a decision framework for using sequence analysis in educational research.","After analysing 44 articles, the conclusions enable us to highlight different learning tasks and educational settings where sequences are analysed, identify data mapping models for different types of sequence actions, differentiate methods based on purpose and scope, and identify possible educational interventions based on the outcomes of sequence analysis."],"url":"http://arxiv.org/abs/2308.01218v1"}
{"created":"2023-08-02 15:22:00","title":"TeachCLIP: Multi-Grained Teaching for Efficient Text-to-Video Retrieval","abstract":"For text-to-video retrieval (T2VR), which aims to retrieve unlabeled videos by ad-hoc textual queries, CLIP-based methods are dominating. Compared to CLIP4Clip which is efficient and compact, the state-of-the-art models tend to compute video-text similarity by fine-grained cross-modal feature interaction and matching, putting their scalability for large-scale T2VR into doubt. For efficient T2VR, we propose TeachCLIP with multi-grained teaching to let a CLIP4Clip based student network learn from more advanced yet computationally heavy models such as X-CLIP, TS2-Net and X-Pool . To improve the student's learning capability, we add an Attentional frame-Feature Aggregation (AFA) block, which by design adds no extra storage/computation overhead at the retrieval stage. While attentive weights produced by AFA are commonly used for combining frame-level features, we propose a novel use of the weights to let them imitate frame-text relevance estimated by the teacher network. As such, AFA provides a fine-grained learning (teaching) channel for the student (teacher). Extensive experiments on multiple public datasets justify the viability of the proposed method.","sentences":["For text-to-video retrieval (T2VR), which aims to retrieve unlabeled videos by ad-hoc textual queries, CLIP-based methods are dominating.","Compared to CLIP4Clip which is efficient and compact, the state-of-the-art models tend to compute video-text similarity by fine-grained cross-modal feature interaction and matching, putting their scalability for large-scale T2VR into doubt.","For efficient T2VR, we propose TeachCLIP with multi-grained teaching to let a CLIP4Clip based student network learn from more advanced yet computationally heavy models such as X-CLIP, TS2-Net and X-Pool .","To improve the student's learning capability, we add an Attentional frame-Feature Aggregation (AFA) block, which by design adds no extra storage/computation overhead at the retrieval stage.","While attentive weights produced by AFA are commonly used for combining frame-level features, we propose a novel use of the weights to let them imitate frame-text relevance estimated by the teacher network.","As such, AFA provides a fine-grained learning (teaching) channel for the student (teacher).","Extensive experiments on multiple public datasets justify the viability of the proposed method."],"url":"http://arxiv.org/abs/2308.01217v1"}
{"created":"2023-08-02 15:07:41","title":"One Tree to Rule Them All: Poly-Logarithmic Universal Steiner Tree","abstract":"A spanning tree $T$ of graph $G$ is a $\\rho$-approximate universal Steiner tree (UST) for root vertex $r$ if, for any subset of vertices $S$ containing $r$, the cost of the minimal subgraph of $T$ connecting $S$ is within a $\\rho$ factor of the minimum cost tree connecting $S$ in $G$. Busch et al. (FOCS 2012) showed that every graph admits $2^{O(\\sqrt{\\log n})}$-approximate USTs by showing that USTs are equivalent to strong sparse partition hierarchies (up to poly-logs). Further, they posed poly-logarithmic USTs and strong sparse partition hierarchies as open questions.   We settle these open questions by giving polynomial-time algorithms for computing both $O(\\log ^ 7 n)$-approximate USTs and poly-logarithmic strong sparse partition hierarchies. For graphs with constant doubling dimension or constant pathwidth we improve this to $O(\\log n)$-approximate USTs and $O(1)$ strong sparse partition hierarchies. Our doubling dimension result is tight up to second order terms. We reduce the existence of these objects to the previously studied cluster aggregation problem and what we call dangling nets.","sentences":["A spanning tree $T$ of graph $G$ is a $\\rho$-approximate universal Steiner tree (UST) for root vertex $r$ if, for any subset of vertices $S$ containing $r$, the cost of the minimal subgraph of $T$ connecting $S$ is within a $\\rho$ factor of the minimum cost tree connecting $S$ in $G$. Busch et al.","(FOCS 2012) showed that every graph admits $2^{O(\\sqrt{\\log n})}$-approximate USTs by showing that USTs are equivalent to strong sparse partition hierarchies (up to poly-logs).","Further, they posed poly-logarithmic USTs and strong sparse partition hierarchies as open questions.   ","We settle these open questions by giving polynomial-time algorithms for computing both $O(\\log ^ 7 n)$-approximate USTs and poly-logarithmic strong sparse partition hierarchies.","For graphs with constant doubling dimension or constant pathwidth we improve this to $O(\\log n)$-approximate USTs and $O(1)$ strong sparse partition hierarchies.","Our doubling dimension result is tight up to second order terms.","We reduce the existence of these objects to the previously studied cluster aggregation problem and what we call dangling nets."],"url":"http://arxiv.org/abs/2308.01199v1"}
{"created":"2023-08-02 15:03:41","title":"Improving Generalization in Visual Reinforcement Learning via Conflict-aware Gradient Agreement Augmentation","abstract":"Learning a policy with great generalization to unseen environments remains challenging but critical in visual reinforcement learning. Despite the success of augmentation combination in the supervised learning generalization, naively applying it to visual RL algorithms may damage the training efficiency, suffering from serve performance degradation. In this paper, we first conduct qualitative analysis and illuminate the main causes: (i) high-variance gradient magnitudes and (ii) gradient conflicts existed in various augmentation methods. To alleviate these issues, we propose a general policy gradient optimization framework, named Conflict-aware Gradient Agreement Augmentation (CG2A), and better integrate augmentation combination into visual RL algorithms to address the generalization bias. In particular, CG2A develops a Gradient Agreement Solver to adaptively balance the varying gradient magnitudes, and introduces a Soft Gradient Surgery strategy to alleviate the gradient conflicts. Extensive experiments demonstrate that CG2A significantly improves the generalization performance and sample efficiency of visual RL algorithms.","sentences":["Learning a policy with great generalization to unseen environments remains challenging but critical in visual reinforcement learning.","Despite the success of augmentation combination in the supervised learning generalization, naively applying it to visual RL algorithms may damage the training efficiency, suffering from serve performance degradation.","In this paper, we first conduct qualitative analysis and illuminate the main causes: (i) high-variance gradient magnitudes and (ii) gradient conflicts existed in various augmentation methods.","To alleviate these issues, we propose a general policy gradient optimization framework, named Conflict-aware Gradient Agreement Augmentation (CG2A), and better integrate augmentation combination into visual RL algorithms to address the generalization bias.","In particular, CG2A develops a Gradient Agreement Solver to adaptively balance the varying gradient magnitudes, and introduces a Soft Gradient Surgery strategy to alleviate the gradient conflicts.","Extensive experiments demonstrate that CG2A significantly improves the generalization performance and sample efficiency of visual RL algorithms."],"url":"http://arxiv.org/abs/2308.01194v1"}
{"created":"2023-08-02 15:02:35","title":"Mercury: An Automated Remote Side-channel Attack to Nvidia Deep Learning Accelerator","abstract":"DNN accelerators have been widely deployed in many scenarios to speed up the inference process and reduce the energy consumption. One big concern about the usage of the accelerators is the confidentiality of the deployed models: model inference execution on the accelerators could leak side-channel information, which enables an adversary to preciously recover the model details. Such model extraction attacks can not only compromise the intellectual property of DNN models, but also facilitate some adversarial attacks.   Although previous works have demonstrated a number of side-channel techniques to extract models from DNN accelerators, they are not practical for two reasons. (1) They only target simplified accelerator implementations, which have limited practicality in the real world. (2) They require heavy human analysis and domain knowledge. To overcome these limitations, this paper presents Mercury, the first automated remote side-channel attack against the off-the-shelf Nvidia DNN accelerator. The key insight of Mercury is to model the side-channel extraction process as a sequence-to-sequence problem. The adversary can leverage a time-to-digital converter (TDC) to remotely collect the power trace of the target model's inference. Then he uses a learning model to automatically recover the architecture details of the victim model from the power trace without any prior knowledge. The adversary can further use the attention mechanism to localize the leakage points that contribute most to the attack. Evaluation results indicate that Mercury can keep the error rate of model extraction below 1%.","sentences":["DNN accelerators have been widely deployed in many scenarios to speed up the inference process and reduce the energy consumption.","One big concern about the usage of the accelerators is the confidentiality of the deployed models: model inference execution on the accelerators could leak side-channel information, which enables an adversary to preciously recover the model details.","Such model extraction attacks can not only compromise the intellectual property of DNN models, but also facilitate some adversarial attacks.   ","Although previous works have demonstrated a number of side-channel techniques to extract models from DNN accelerators, they are not practical for two reasons.","(1) They only target simplified accelerator implementations, which have limited practicality in the real world.","(2) They require heavy human analysis and domain knowledge.","To overcome these limitations, this paper presents Mercury, the first automated remote side-channel attack against the off-the-shelf Nvidia DNN accelerator.","The key insight of Mercury is to model the side-channel extraction process as a sequence-to-sequence problem.","The adversary can leverage a time-to-digital converter (TDC) to remotely collect the power trace of the target model's inference.","Then he uses a learning model to automatically recover the architecture details of the victim model from the power trace without any prior knowledge.","The adversary can further use the attention mechanism to localize the leakage points that contribute most to the attack.","Evaluation results indicate that Mercury can keep the error rate of model extraction below 1%."],"url":"http://arxiv.org/abs/2308.01193v1"}
{"created":"2023-08-02 14:56:01","title":"Towards Understanding the Capability of Large Language Models on Code Clone Detection: A Survey","abstract":"Code cloning, the duplication of code fragments, is common in software development. While some reuse aids productivity, excessive cloning hurts maintainability and introduces bugs. Hence, automatic code clone detection is vital. Meanwhile, large language models (LLMs) possess diverse code-related knowledge, making them versatile for various software engineering challenges. However, LLMs' performance in code clone detection is unclear and needs more study for accurate assessment.In this paper, we provide the first comprehensive evaluation of LLMs for clone detection, covering different clone types, languages, and prompts. We find advanced LLMs excel in detecting complex semantic clones, surpassing existing methods. Adding intermediate reasoning steps via chain-of-thought prompts noticeably enhances performance. Additionally, representing code as vector embeddings, especially with text encoders, effectively aids clone detection.Lastly, the ability of LLMs to detect code clones differs among various programming languages. Our study suggests that LLMs have potential for clone detection due to their language capabilities, offering insights for developing robust LLM-based methods to enhance software engineering.","sentences":["Code cloning, the duplication of code fragments, is common in software development.","While some reuse aids productivity, excessive cloning hurts maintainability and introduces bugs.","Hence, automatic code clone detection is vital.","Meanwhile, large language models (LLMs) possess diverse code-related knowledge, making them versatile for various software engineering challenges.","However, LLMs' performance in code clone detection is unclear and needs more study for accurate assessment.","In this paper, we provide the first comprehensive evaluation of LLMs for clone detection, covering different clone types, languages, and prompts.","We find advanced LLMs excel in detecting complex semantic clones, surpassing existing methods.","Adding intermediate reasoning steps via chain-of-thought prompts noticeably enhances performance.","Additionally, representing code as vector embeddings, especially with text encoders, effectively aids clone detection.","Lastly, the ability of LLMs to detect code clones differs among various programming languages.","Our study suggests that LLMs have potential for clone detection due to their language capabilities, offering insights for developing robust LLM-based methods to enhance software engineering."],"url":"http://arxiv.org/abs/2308.01191v1"}
{"created":"2023-08-02 14:53:43","title":"Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical Image Segmentation","abstract":"This paper seeks to address the dense labeling problems where a significant fraction of the dataset can be pruned without sacrificing much accuracy. We observe that, on standard medical image segmentation benchmarks, the loss gradient norm-based metrics of individual training examples applied in image classification fail to identify the important samples. To address this issue, we propose a data pruning method by taking into consideration the training dynamics on target regions using Dynamic Average Dice (DAD) score. To the best of our knowledge, we are among the first to address the data importance in dense labeling tasks in the field of medical image analysis, making the following contributions: (1) investigating the underlying causes with rigorous empirical analysis, and (2) determining effective data pruning approach in dense labeling problems. Our solution can be used as a strong yet simple baseline to select important examples for medical image segmentation with combined data sources.","sentences":["This paper seeks to address the dense labeling problems where a significant fraction of the dataset can be pruned without sacrificing much accuracy.","We observe that, on standard medical image segmentation benchmarks, the loss gradient norm-based metrics of individual training examples applied in image classification fail to identify the important samples.","To address this issue, we propose a data pruning method by taking into consideration the training dynamics on target regions using Dynamic Average Dice (DAD) score.","To the best of our knowledge, we are among the first to address the data importance in dense labeling tasks in the field of medical image analysis, making the following contributions: (1) investigating the underlying causes with rigorous empirical analysis, and (2) determining effective data pruning approach in dense labeling problems.","Our solution can be used as a strong yet simple baseline to select important examples for medical image segmentation with combined data sources."],"url":"http://arxiv.org/abs/2308.01189v1"}
{"created":"2023-08-02 14:51:22","title":"Music De-limiter Networks via Sample-wise Gain Inversion","abstract":"The loudness war, an ongoing phenomenon in the music industry characterized by the increasing final loudness of music while reducing its dynamic range, has been a controversial topic for decades. Music mastering engineers have used limiters to heavily compress and make music louder, which can induce ear fatigue and hearing loss in listeners. In this paper, we introduce music de-limiter networks that estimate uncompressed music from heavily compressed signals. Inspired by the principle of a limiter, which performs sample-wise gain reduction of a given signal, we propose the framework of sample-wise gain inversion (SGI). We also present the musdb-XL-train dataset, consisting of 300k segments created by applying a commercial limiter plug-in for training real-world friendly de-limiter networks. Our proposed de-limiter network achieves excellent performance with a scale-invariant source-to-distortion ratio (SI-SDR) of 23.8 dB in reconstructing musdb-HQ from musdb- XL data, a limiter-applied version of musdb-HQ. The training data, codes, and model weights are available in our repository (https://github.com/jeonchangbin49/De-limiter).","sentences":["The loudness war, an ongoing phenomenon in the music industry characterized by the increasing final loudness of music while reducing its dynamic range, has been a controversial topic for decades.","Music mastering engineers have used limiters to heavily compress and make music louder, which can induce ear fatigue and hearing loss in listeners.","In this paper, we introduce music de-limiter networks that estimate uncompressed music from heavily compressed signals.","Inspired by the principle of a limiter, which performs sample-wise gain reduction of a given signal, we propose the framework of sample-wise gain inversion (SGI).","We also present the musdb-XL-train dataset, consisting of 300k segments created by applying a commercial limiter plug-in for training real-world friendly de-limiter networks.","Our proposed de-limiter network achieves excellent performance with a scale-invariant source-to-distortion ratio (SI-SDR) of 23.8 dB in reconstructing musdb-HQ from musdb- XL data, a limiter-applied version of musdb-HQ.","The training data, codes, and model weights are available in our repository (https://github.com/jeonchangbin49/De-limiter)."],"url":"http://arxiv.org/abs/2308.01187v1"}
{"created":"2023-08-02 14:48:25","title":"Generative Noisy-Label Learning by Implicit Dicriminative Approximation with Partial Label Prior","abstract":"The learning with noisy labels has been addressed with both discriminative and generative models. Although discriminative models have dominated the field due to their simpler modeling and more efficient computational training processes, generative models offer a more effective means of disentangling clean and noisy labels and improving the estimation of the label transition matrix. However, generative approaches maximize the joint likelihood of noisy labels and data using a complex formulation that only indirectly optimizes the model of interest associating data and clean labels. Additionally, these approaches rely on generative models that are challenging to train and tend to use uninformative clean label priors. In this paper, we propose a new generative noisy-label learning approach that addresses these three issues. First, we propose a new model optimisation that directly associates data and clean labels. Second, the generative model is implicitly estimated using a discriminative model, eliminating the inefficient training of a generative model. Third, we propose a new informative label prior inspired by partial label learning as supervision signal for noisy label learning. Extensive experiments on several noisy-label benchmarks demonstrate that our generative model provides state-of-the-art results while maintaining a similar computational complexity as discriminative models.","sentences":["The learning with noisy labels has been addressed with both discriminative and generative models.","Although discriminative models have dominated the field due to their simpler modeling and more efficient computational training processes, generative models offer a more effective means of disentangling clean and noisy labels and improving the estimation of the label transition matrix.","However, generative approaches maximize the joint likelihood of noisy labels and data using a complex formulation that only indirectly optimizes the model of interest associating data and clean labels.","Additionally, these approaches rely on generative models that are challenging to train and tend to use uninformative clean label priors.","In this paper, we propose a new generative noisy-label learning approach that addresses these three issues.","First, we propose a new model optimisation that directly associates data and clean labels.","Second, the generative model is implicitly estimated using a discriminative model, eliminating the inefficient training of a generative model.","Third, we propose a new informative label prior inspired by partial label learning as supervision signal for noisy label learning.","Extensive experiments on several noisy-label benchmarks demonstrate that our generative model provides state-of-the-art results while maintaining a similar computational complexity as discriminative models."],"url":"http://arxiv.org/abs/2308.01184v1"}
{"created":"2023-08-02 14:43:08","title":"Interpretable End-to-End Driving Model for Implicit Scene Understanding","abstract":"Driving scene understanding is to obtain comprehensive scene information through the sensor data and provide a basis for downstream tasks, which is indispensable for the safety of self-driving vehicles. Specific perception tasks, such as object detection and scene graph generation, are commonly used. However, the results of these tasks are only equivalent to the characterization of sampling from high-dimensional scene features, which are not sufficient to represent the scenario. In addition, the goal of perception tasks is inconsistent with human driving that just focuses on what may affect the ego-trajectory. Therefore, we propose an end-to-end Interpretable Implicit Driving Scene Understanding (II-DSU) model to extract implicit high-dimensional scene features as scene understanding results guided by a planning module and to validate the plausibility of scene understanding using auxiliary perception tasks for visualization. Experimental results on CARLA benchmarks show that our approach achieves the new state-of-the-art and is able to obtain scene features that embody richer scene information relevant to driving, enabling superior performance of the downstream planning.","sentences":["Driving scene understanding is to obtain comprehensive scene information through the sensor data and provide a basis for downstream tasks, which is indispensable for the safety of self-driving vehicles.","Specific perception tasks, such as object detection and scene graph generation, are commonly used.","However, the results of these tasks are only equivalent to the characterization of sampling from high-dimensional scene features, which are not sufficient to represent the scenario.","In addition, the goal of perception tasks is inconsistent with human driving that just focuses on what may affect the ego-trajectory.","Therefore, we propose an end-to-end Interpretable Implicit Driving Scene Understanding (II-DSU) model to extract implicit high-dimensional scene features as scene understanding results guided by a planning module and to validate the plausibility of scene understanding using auxiliary perception tasks for visualization.","Experimental results on CARLA benchmarks show that our approach achieves the new state-of-the-art and is able to obtain scene features that embody richer scene information relevant to driving, enabling superior performance of the downstream planning."],"url":"http://arxiv.org/abs/2308.01180v1"}
{"created":"2023-08-02 14:29:10","title":"Memory Encoding Model","abstract":"We explore a new class of brain encoding model by adding memory-related information as input. Memory is an essential brain mechanism that works alongside visual stimuli. During a vision-memory cognitive task, we found the non-visual brain is largely predictable using previously seen images. Our Memory Encoding Model (Mem) won the Algonauts 2023 visual brain competition even without model ensemble (single model score 66.8, ensemble score 70.8). Our ensemble model without memory input (61.4) can also stand a 3rd place. Furthermore, we observe periodic delayed brain response correlated to 6th-7th prior image, and hippocampus also showed correlated activity timed with this periodicity. We conjuncture that the periodic replay could be related to memory mechanism to enhance the working memory.","sentences":["We explore a new class of brain encoding model by adding memory-related information as input.","Memory is an essential brain mechanism that works alongside visual stimuli.","During a vision-memory cognitive task, we found the non-visual brain is largely predictable using previously seen images.","Our Memory Encoding Model (Mem) won the Algonauts 2023 visual brain competition even without model ensemble (single model score 66.8, ensemble score 70.8).","Our ensemble model without memory input (61.4) can also stand a 3rd place.","Furthermore, we observe periodic delayed brain response correlated to 6th-7th prior image, and hippocampus also showed correlated activity timed with this periodicity.","We conjuncture that the periodic replay could be related to memory mechanism to enhance the working memory."],"url":"http://arxiv.org/abs/2308.01175v1"}
{"created":"2023-08-02 14:26:08","title":"The Expansion Problem for Infinite Trees","abstract":"We study Ramsey like theorems for infinite trees and similar combinatorial tools. As an application we consider the expansion problem for tree algebras.","sentences":["We study Ramsey like theorems for infinite trees and similar combinatorial tools.","As an application we consider the expansion problem for tree algebras."],"url":"http://arxiv.org/abs/2308.01174v1"}
{"created":"2023-08-02 14:16:22","title":"Direct Gradient Temporal Difference Learning","abstract":"Off-policy learning enables a reinforcement learning (RL) agent to reason counterfactually about policies that are not executed and is one of the most important ideas in RL. It, however, can lead to instability when combined with function approximation and bootstrapping, two arguably indispensable ingredients for large-scale reinforcement learning. This is the notorious deadly triad. Gradient Temporal Difference (GTD) is one powerful tool to solve the deadly triad. Its success results from solving a doubling sampling issue indirectly with weight duplication or Fenchel duality. In this paper, we instead propose a direct method to solve the double sampling issue by simply using two samples in a Markovian data stream with an increasing gap. The resulting algorithm is as computationally efficient as GTD but gets rid of GTD's extra weights. The only price we pay is a logarithmically increasing memory as time progresses. We provide both asymptotic and finite sample analysis, where the convergence rate is on-par with the canonical on-policy temporal difference learning. Key to our analysis is a novel refined discretization of limiting ODEs.","sentences":["Off-policy learning enables a reinforcement learning (RL) agent to reason counterfactually about policies that are not executed and is one of the most important ideas in RL.","It, however, can lead to instability when combined with function approximation and bootstrapping, two arguably indispensable ingredients for large-scale reinforcement learning.","This is the notorious deadly triad.","Gradient Temporal Difference (GTD) is one powerful tool to solve the deadly triad.","Its success results from solving a doubling sampling issue indirectly with weight duplication or Fenchel duality.","In this paper, we instead propose a direct method to solve the double sampling issue by simply using two samples in a Markovian data stream with an increasing gap.","The resulting algorithm is as computationally efficient as GTD but gets rid of GTD's extra weights.","The only price we pay is a logarithmically increasing memory as time progresses.","We provide both asymptotic and finite sample analysis, where the convergence rate is on-par with the canonical on-policy temporal difference learning.","Key to our analysis is a novel refined discretization of limiting ODEs."],"url":"http://arxiv.org/abs/2308.01170v1"}
{"created":"2023-08-02 14:09:08","title":"Termination in Concurrency, Revisited","abstract":"Termination is a central property in sequential programming models: a term is terminating if all its reduction sequences are finite. Termination is also important in concurrency in general, and for message-passing programs in particular. A variety of type systems that enforce termination by typing have been developed. In this paper, we rigorously compare several type systems for $\\pi$-calculus processes from the unifying perspective of termination. Adopting session types as reference framework, we consider two different type systems: one follows Deng and Sangiorgi's weight-based approach; the other is Caires and Pfenning's Curry-Howard correspondence between linear logic and session types. Our technical results precisely connect these very different type systems, and shed light on the classes of client/server interactions they admit as correct.","sentences":["Termination is a central property in sequential programming models: a term is terminating if all its reduction sequences are finite.","Termination is also important in concurrency in general, and for message-passing programs in particular.","A variety of type systems that enforce termination by typing have been developed.","In this paper, we rigorously compare several type systems for $\\pi$-calculus processes from the unifying perspective of termination.","Adopting session types as reference framework, we consider two different type systems: one follows Deng and Sangiorgi's weight-based approach; the other is Caires and Pfenning's Curry-Howard correspondence between linear logic and session types.","Our technical results precisely connect these very different type systems, and shed light on the classes of client/server interactions they admit as correct."],"url":"http://arxiv.org/abs/2308.01165v1"}
{"created":"2023-08-02 14:08:10","title":"Virtual Reality Based Robot Teleoperation via Human-Scene Interaction","abstract":"Robot teleoperation gains great success in various situations, including chemical pollution rescue, disaster relief, and long-distance manipulation. In this article, we propose a virtual reality (VR) based robot teleoperation system to achieve more efficient and natural interaction with humans in different scenes. A user-friendly VR interface is designed to help users interact with a desktop scene using their hands efficiently and intuitively. To improve user experience and reduce workload, we simulate the process in the physics engine to help build a preview of the scene after manipulation in the virtual scene before execution. We conduct experiments with different users and compare our system with a direct control method across several teleoperation tasks. The user study demonstrates that the proposed system enables users to perform operations more instinctively with a lighter mental workload. Users can perform pick-and-place and object-stacking tasks in a considerably short time, even for beginners. Our code is available at https://github.com/lingxiaomeng/VR_Teleoperation_Gen3.","sentences":["Robot teleoperation gains great success in various situations, including chemical pollution rescue, disaster relief, and long-distance manipulation.","In this article, we propose a virtual reality (VR) based robot teleoperation system to achieve more efficient and natural interaction with humans in different scenes.","A user-friendly VR interface is designed to help users interact with a desktop scene using their hands efficiently and intuitively.","To improve user experience and reduce workload, we simulate the process in the physics engine to help build a preview of the scene after manipulation in the virtual scene before execution.","We conduct experiments with different users and compare our system with a direct control method across several teleoperation tasks.","The user study demonstrates that the proposed system enables users to perform operations more instinctively with a lighter mental workload.","Users can perform pick-and-place and object-stacking tasks in a considerably short time, even for beginners.","Our code is available at https://github.com/lingxiaomeng/VR_Teleoperation_Gen3."],"url":"http://arxiv.org/abs/2308.01164v1"}
{"created":"2023-08-02 14:07:58","title":"Stakeholder-in-the-Loop Fair Decisions: A Framework to Design Decision Support Systems in Public and Private Organizations","abstract":"Due to the opacity of machine learning technology, there is a need for explainability and fairness in the decision support systems used in public or private organizations. Although the criteria for appropriate explanations and fair decisions change depending on the values of those who are affected by the decisions, there is a lack of discussion framework to consider the appropriate outputs for each stakeholder. In this paper, we propose a discussion framework that we call \"stakeholder-in-the-loop fair decisions.\" This is proposed to consider the requirements for appropriate explanations and fair decisions. We identified four stakeholders that need to be considered to design accountable decision support systems and discussed how to consider the appropriate outputs for each stakeholder by referring to our works. By clarifying the characteristics of specific stakeholders in each application domain and integrating the stakeholders' values into outputs that all stakeholders agree upon, decision support systems can be designed as systems that ensure accountable decision makings.","sentences":["Due to the opacity of machine learning technology, there is a need for explainability and fairness in the decision support systems used in public or private organizations.","Although the criteria for appropriate explanations and fair decisions change depending on the values of those who are affected by the decisions, there is a lack of discussion framework to consider the appropriate outputs for each stakeholder.","In this paper, we propose a discussion framework that we call \"stakeholder-in-the-loop fair decisions.\"","This is proposed to consider the requirements for appropriate explanations and fair decisions.","We identified four stakeholders that need to be considered to design accountable decision support systems and discussed how to consider the appropriate outputs for each stakeholder by referring to our works.","By clarifying the characteristics of specific stakeholders in each application domain and integrating the stakeholders' values into outputs that all stakeholders agree upon, decision support systems can be designed as systems that ensure accountable decision makings."],"url":"http://arxiv.org/abs/2308.01163v1"}
{"created":"2023-08-02 14:04:58","title":"Stake Your Claim: Zero-Trust Validator Deployment Leveraging NFTs and Smart Contracts in Proof-of-Stake Networks","abstract":"We present a novel method for a multi-party, zero-trust validator infrastructure deployment arrangement via smart contracts to secure Proof-of-Stake (PoS) blockchains. The proposed arrangement architecture employs a combination of non-fungible tokens (NFTs), a treasury contract, and validator smart contract wallets to facilitate trustless participation in staking mechanisms. The NFT minting process allows depositors to exchange their capital for an NFT representing their stake in a validator, while the treasury contract manages the registry of NFT holders and handles rewards distribution. Validator smart contract wallets are employed to create a trustless connection between the validator operator and the treasury, enabling autonomous staking and unstaking processes based on predefined conditions. In addition, the proposed system incorporates protection mechanisms for depositors, such as triggered exits in case of non-payment of rewards and a penalty payout from the validator operator. The arrangement benefits from the extensibility and interoperability of web3 technologies, with potential applications in the broader digital ecosystem. This zero-trust staking mechanism aims to serve users who desire increased privacy, trust, and flexibility in managing their digital wealth, while promoting greater decentralization and transparency in the PoS ecosystem.","sentences":["We present a novel method for a multi-party, zero-trust validator infrastructure deployment arrangement via smart contracts to secure Proof-of-Stake (PoS) blockchains.","The proposed arrangement architecture employs a combination of non-fungible tokens (NFTs), a treasury contract, and validator smart contract wallets to facilitate trustless participation in staking mechanisms.","The NFT minting process allows depositors to exchange their capital for an NFT representing their stake in a validator, while the treasury contract manages the registry of NFT holders and handles rewards distribution.","Validator smart contract wallets are employed to create a trustless connection between the validator operator and the treasury, enabling autonomous staking and unstaking processes based on predefined conditions.","In addition, the proposed system incorporates protection mechanisms for depositors, such as triggered exits in case of non-payment of rewards and a penalty payout from the validator operator.","The arrangement benefits from the extensibility and interoperability of web3 technologies, with potential applications in the broader digital ecosystem.","This zero-trust staking mechanism aims to serve users who desire increased privacy, trust, and flexibility in managing their digital wealth, while promoting greater decentralization and transparency in the PoS ecosystem."],"url":"http://arxiv.org/abs/2308.01158v1"}
{"created":"2023-08-02 13:58:37","title":"Arithmetic with Language Models: from Memorization to Computation","abstract":"A better understanding of the emergent computation and problem-solving capabilities of recent large language models is of paramount importance to further improve them and broaden their applicability. This work investigates how a language model, trained to predict the next token, can perform arithmetic computations generalizing beyond training data. Binary addition and multiplication constitute a good testbed for this purpose, since they require a very small vocabulary and exhibit relevant input/output discontinuities making smooth input interpolation ineffective for novel data. We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing. Our findings support the hypotheses that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input token representation is mapped to an appropriate internal representation.","sentences":["A better understanding of the emergent computation and problem-solving capabilities of recent large language models is of paramount importance to further improve them and broaden their applicability.","This work investigates how a language model, trained to predict the next token, can perform arithmetic computations generalizing beyond training data.","Binary addition and multiplication constitute a good testbed for this purpose, since they require a very small vocabulary and exhibit relevant input/output discontinuities making smooth input interpolation ineffective for novel data.","We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing.","Our findings support the hypotheses that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input token representation is mapped to an appropriate internal representation."],"url":"http://arxiv.org/abs/2308.01154v1"}
{"created":"2023-08-02 13:57:01","title":"Skolem Meets Bateman-Horn","abstract":"The Skolem Problem asks to determine whether a given integer linear recurrence sequence has a zero term. This problem arises across a wide range of topics in computer science, including loop termination, (weighted) automata theory, and the analysis of linear dynamical systems, amongst many others. Decidability of the Skolem Problem is notoriously open. The state of the art is a decision procedure for recurrences of order at most 4: an advance achieved some 40 years ago based on Baker's theorem on linear forms in logarithms of algebraic numbers.   Recently, a new approach to the Skolem Problem was initiated via the notion of a Universal Skolem Set: a set $\\mathbf{S}$ of positive integers such that it is decidable whether a given non-degenerate linear recurrence sequence has a zero in $\\mathbf{S}$. Clearly, proving decidability of the Skolem Problem is equivalent to showing that $\\mathbb{N}$ is a Universal Skolem Set. The main contribution of the present paper is to exhibit a Universal Skolem Set of positive density that moreover has density one subject to the Bateman-Horn conjecture in number theory. The latter is a central unifying hypothesis concerning the frequency of prime numbers among the values of systems of polynomials, and provides a far-reaching generalisation of many classical results and conjectures on the distribution of primes.","sentences":["The Skolem Problem asks to determine whether a given integer linear recurrence sequence has a zero term.","This problem arises across a wide range of topics in computer science, including loop termination, (weighted) automata theory, and the analysis of linear dynamical systems, amongst many others.","Decidability of the Skolem Problem is notoriously open.","The state of the art is a decision procedure for recurrences of order at most 4: an advance achieved some 40 years ago based on Baker's theorem on linear forms in logarithms of algebraic numbers.   ","Recently, a new approach to the Skolem Problem was initiated via the notion of a Universal Skolem Set: a set $\\mathbf{S}$ of positive integers such that it is decidable whether a given non-degenerate linear recurrence sequence has a zero in $\\mathbf{S}$. Clearly, proving decidability of the Skolem Problem is equivalent to showing that $\\mathbb{N}$ is a Universal Skolem Set.","The main contribution of the present paper is to exhibit a Universal Skolem Set of positive density that moreover has density one subject to the Bateman-Horn conjecture in number theory.","The latter is a central unifying hypothesis concerning the frequency of prime numbers among the values of systems of polynomials, and provides a far-reaching generalisation of many classical results and conjectures on the distribution of primes."],"url":"http://arxiv.org/abs/2308.01152v1"}
{"created":"2023-08-02 13:43:03","title":"Contrast-augmented Diffusion Model with Fine-grained Sequence Alignment for Markup-to-Image Generation","abstract":"The recently rising markup-to-image generation poses greater challenges as compared to natural image generation, due to its low tolerance for errors as well as the complex sequence and context correlations between markup and rendered image. This paper proposes a novel model named \"Contrast-augmented Diffusion Model with Fine-grained Sequence Alignment\" (FSA-CDM), which introduces contrastive positive/negative samples into the diffusion model to boost performance for markup-to-image generation. Technically, we design a fine-grained cross-modal alignment module to well explore the sequence similarity between the two modalities for learning robust feature representations. To improve the generalization ability, we propose a contrast-augmented diffusion model to explicitly explore positive and negative samples by maximizing a novel contrastive variational objective, which is mathematically inferred to provide a tighter bound for the model's optimization. Moreover, the context-aware cross attention module is developed to capture the contextual information within markup language during the denoising process, yielding better noise prediction results. Extensive experiments are conducted on four benchmark datasets from different domains, and the experimental results demonstrate the effectiveness of the proposed components in FSA-CDM, significantly exceeding state-of-the-art performance by about 2%-12% DTW improvements. The code will be released at https://github.com/zgj77/FSACDM.","sentences":["The recently rising markup-to-image generation poses greater challenges as compared to natural image generation, due to its low tolerance for errors as well as the complex sequence and context correlations between markup and rendered image.","This paper proposes a novel model named \"Contrast-augmented Diffusion Model with Fine-grained Sequence Alignment\" (FSA-CDM), which introduces contrastive positive/negative samples into the diffusion model to boost performance for markup-to-image generation.","Technically, we design a fine-grained cross-modal alignment module to well explore the sequence similarity between the two modalities for learning robust feature representations.","To improve the generalization ability, we propose a contrast-augmented diffusion model to explicitly explore positive and negative samples by maximizing a novel contrastive variational objective, which is mathematically inferred to provide a tighter bound for the model's optimization.","Moreover, the context-aware cross attention module is developed to capture the contextual information within markup language during the denoising process, yielding better noise prediction results.","Extensive experiments are conducted on four benchmark datasets from different domains, and the experimental results demonstrate the effectiveness of the proposed components in FSA-CDM, significantly exceeding state-of-the-art performance by about 2%-12% DTW improvements.","The code will be released at https://github.com/zgj77/FSACDM."],"url":"http://arxiv.org/abs/2308.01147v1"}
{"created":"2023-08-02 13:39:08","title":"UCDFormer: Unsupervised Change Detection Using a Transformer-driven Image Translation","abstract":"Change detection (CD) by comparing two bi-temporal images is a crucial task in remote sensing. With the advantages of requiring no cumbersome labeled change information, unsupervised CD has attracted extensive attention in the community. However, existing unsupervised CD approaches rarely consider the seasonal and style differences incurred by the illumination and atmospheric conditions in multi-temporal images. To this end, we propose a change detection with domain shift setting for remote sensing images. Furthermore, we present a novel unsupervised CD method using a light-weight transformer, called UCDFormer. Specifically, a transformer-driven image translation composed of a light-weight transformer and a domain-specific affinity weight is first proposed to mitigate domain shift between two images with real-time efficiency. After image translation, we can generate the difference map between the translated before-event image and the original after-event image. Then, a novel reliable pixel extraction module is proposed to select significantly changed/unchanged pixel positions by fusing the pseudo change maps of fuzzy c-means clustering and adaptive threshold. Finally, a binary change map is obtained based on these selected pixel pairs and a binary classifier. Experimental results on different unsupervised CD tasks with seasonal and style changes demonstrate the effectiveness of the proposed UCDFormer. For example, compared with several other related methods, UCDFormer improves performance on the Kappa coefficient by more than 12\\%. In addition, UCDFormer achieves excellent performance for earthquake-induced landslide detection when considering large-scale applications. The code is available at \\url{https://github.com/zhu-xlab/UCDFormer}","sentences":["Change detection (CD) by comparing two bi-temporal images is a crucial task in remote sensing.","With the advantages of requiring no cumbersome labeled change information, unsupervised CD has attracted extensive attention in the community.","However, existing unsupervised CD approaches rarely consider the seasonal and style differences incurred by the illumination and atmospheric conditions in multi-temporal images.","To this end, we propose a change detection with domain shift setting for remote sensing images.","Furthermore, we present a novel unsupervised CD method using a light-weight transformer, called UCDFormer.","Specifically, a transformer-driven image translation composed of a light-weight transformer and a domain-specific affinity weight is first proposed to mitigate domain shift between two images with real-time efficiency.","After image translation, we can generate the difference map between the translated before-event image and the original after-event image.","Then, a novel reliable pixel extraction module is proposed to select significantly changed/unchanged pixel positions by fusing the pseudo change maps of fuzzy c-means clustering and adaptive threshold.","Finally, a binary change map is obtained based on these selected pixel pairs and a binary classifier.","Experimental results on different unsupervised CD tasks with seasonal and style changes demonstrate the effectiveness of the proposed UCDFormer.","For example, compared with several other related methods, UCDFormer improves performance on the Kappa coefficient by more than 12\\%.","In addition, UCDFormer achieves excellent performance for earthquake-induced landslide detection when considering large-scale applications.","The code is available at \\url{https://github.com/zhu-xlab/UCDFormer}"],"url":"http://arxiv.org/abs/2308.01146v1"}
{"created":"2023-08-02 13:33:20","title":"ADS-Cap: A Framework for Accurate and Diverse Stylized Captioning with Unpaired Stylistic Corpora","abstract":"Generating visually grounded image captions with specific linguistic styles using unpaired stylistic corpora is a challenging task, especially since we expect stylized captions with a wide variety of stylistic patterns. In this paper, we propose a novel framework to generate Accurate and Diverse Stylized Captions (ADS-Cap). Our ADS-Cap first uses a contrastive learning module to align the image and text features, which unifies paired factual and unpaired stylistic corpora during the training process. A conditional variational auto-encoder is then used to automatically memorize diverse stylistic patterns in latent space and enhance diversity through sampling. We also design a simple but effective recheck module to boost style accuracy by filtering style-specific captions. Experimental results on two widely used stylized image captioning datasets show that regarding consistency with the image, style accuracy and diversity, ADS-Cap achieves outstanding performances compared to various baselines. We finally conduct extensive analyses to understand the effectiveness of our method. Our code is available at https://github.com/njucckevin/ADS-Cap.","sentences":["Generating visually grounded image captions with specific linguistic styles using unpaired stylistic corpora is a challenging task, especially since we expect stylized captions with a wide variety of stylistic patterns.","In this paper, we propose a novel framework to generate Accurate and Diverse Stylized Captions (ADS-Cap).","Our ADS-Cap first uses a contrastive learning module to align the image and text features, which unifies paired factual and unpaired stylistic corpora during the training process.","A conditional variational auto-encoder is then used to automatically memorize diverse stylistic patterns in latent space and enhance diversity through sampling.","We also design a simple but effective recheck module to boost style accuracy by filtering style-specific captions.","Experimental results on two widely used stylized image captioning datasets show that regarding consistency with the image, style accuracy and diversity, ADS-Cap achieves outstanding performances compared to various baselines.","We finally conduct extensive analyses to understand the effectiveness of our method.","Our code is available at https://github.com/njucckevin/ADS-Cap."],"url":"http://arxiv.org/abs/2308.01143v1"}
{"created":"2023-08-02 13:32:31","title":"Quantum Software Engineering Challenges from Developers' Perspective: Mapping Research Challenges to the Proposed Workflow Model","abstract":"Despite the increasing interest in quantum computing, the aspect of development to achieve cost-effective and reliable quantum software applications has been slow. One barrier is the software engineering of quantum programs, which can be approached from two directions. On the one hand, many software engineering practices, debugging in particular, are bound to classical computing. On the other hand, quantum programming is closely associated with the phenomena of quantum physics, and consequently, the way we express programs resembles the early days of programming. Moreover, much of the software engineering research today focuses on agile development, where computing cycles are cheap and new software can be rapidly deployed and tested, whereas in the quantum context, executions may consume lots of energy, and test runs may require lots of work to interpret. In this paper, we aim at bridging this gap by starting with the quantum computing workflow and by mapping existing software engineering research to this workflow. Based on the mapping, we then identify directions for software engineering research for quantum computing.","sentences":["Despite the increasing interest in quantum computing, the aspect of development to achieve cost-effective and reliable quantum software applications has been slow.","One barrier is the software engineering of quantum programs, which can be approached from two directions.","On the one hand, many software engineering practices, debugging in particular, are bound to classical computing.","On the other hand, quantum programming is closely associated with the phenomena of quantum physics, and consequently, the way we express programs resembles the early days of programming.","Moreover, much of the software engineering research today focuses on agile development, where computing cycles are cheap and new software can be rapidly deployed and tested, whereas in the quantum context, executions may consume lots of energy, and test runs may require lots of work to interpret.","In this paper, we aim at bridging this gap by starting with the quantum computing workflow and by mapping existing software engineering research to this workflow.","Based on the mapping, we then identify directions for software engineering research for quantum computing."],"url":"http://arxiv.org/abs/2308.01141v1"}
{"created":"2023-08-02 13:31:41","title":"DySTreSS: Dynamically Scaled Temperature in Self-Supervised Contrastive Learning","abstract":"In contemporary self-supervised contrastive algorithms like SimCLR, MoCo, etc., the task of balancing attraction between two semantically similar samples and repulsion between two samples from different classes is primarily affected by the presence of hard negative samples. While the InfoNCE loss has been shown to impose penalties based on hardness, the temperature hyper-parameter is the key to regulating the penalties and the trade-off between uniformity and tolerance. In this work, we focus our attention to improve the performance of InfoNCE loss in SSL by studying the effect of temperature hyper-parameter values. We propose a cosine similarity-dependent temperature scaling function to effectively optimize the distribution of the samples in the feature space. We further analyze the uniformity and tolerance metrics to investigate the optimal regions in the cosine similarity space for better optimization. Additionally, we offer a comprehensive examination of the behavior of local and global structures in the feature space throughout the pre-training phase, as the temperature varies. Experimental evidence shows that the proposed framework outperforms or is at par with the contrastive loss-based SSL algorithms. We believe our work (DySTreSS) on temperature scaling in SSL provides a foundation for future research in contrastive learning.","sentences":["In contemporary self-supervised contrastive algorithms like SimCLR, MoCo, etc., the task of balancing attraction between two semantically similar samples and repulsion between two samples from different classes is primarily affected by the presence of hard negative samples.","While the InfoNCE loss has been shown to impose penalties based on hardness, the temperature hyper-parameter is the key to regulating the penalties and the trade-off between uniformity and tolerance.","In this work, we focus our attention to improve the performance of InfoNCE loss in SSL by studying the effect of temperature hyper-parameter values.","We propose a cosine similarity-dependent temperature scaling function to effectively optimize the distribution of the samples in the feature space.","We further analyze the uniformity and tolerance metrics to investigate the optimal regions in the cosine similarity space for better optimization.","Additionally, we offer a comprehensive examination of the behavior of local and global structures in the feature space throughout the pre-training phase, as the temperature varies.","Experimental evidence shows that the proposed framework outperforms or is at par with the contrastive loss-based SSL algorithms.","We believe our work (DySTreSS) on temperature scaling in SSL provides a foundation for future research in contrastive learning."],"url":"http://arxiv.org/abs/2308.01140v1"}
{"created":"2023-08-02 13:30:33","title":"Dynamic Privacy Allocation for Locally Differentially Private Federated Learning with Composite Objectives","abstract":"This paper proposes a locally differentially private federated learning algorithm for strongly convex but possibly nonsmooth problems that protects the gradients of each worker against an honest but curious server. The proposed algorithm adds artificial noise to the shared information to ensure privacy and dynamically allocates the time-varying noise variance to minimize an upper bound of the optimization error subject to a predefined privacy budget constraint. This allows for an arbitrarily large but finite number of iterations to achieve both privacy protection and utility up to a neighborhood of the optimal solution, removing the need for tuning the number of iterations. Numerical results show the superiority of the proposed algorithm over state-of-the-art methods.","sentences":["This paper proposes a locally differentially private federated learning algorithm for strongly convex but possibly nonsmooth problems that protects the gradients of each worker against an honest but curious server.","The proposed algorithm adds artificial noise to the shared information to ensure privacy and dynamically allocates the time-varying noise variance to minimize an upper bound of the optimization error subject to a predefined privacy budget constraint.","This allows for an arbitrarily large but finite number of iterations to achieve both privacy protection and utility up to a neighborhood of the optimal solution, removing the need for tuning the number of iterations.","Numerical results show the superiority of the proposed algorithm over state-of-the-art methods."],"url":"http://arxiv.org/abs/2308.01139v1"}
{"created":"2023-08-02 13:29:31","title":"Can We Transfer Noise Patterns? An Multi-environment Spectrum Analysis Model Using Generated Cases","abstract":"Spectrum analysis systems in online water quality testing are designed to detect types and concentrations of pollutants and enable regulatory agencies to respond promptly to pollution incidents. However, spectral data-based testing devices suffer from complex noise patterns when deployed in non-laboratory environments. To make the analysis model applicable to more environments, we propose a noise patterns transferring model, which takes the spectrum of standard water samples in different environments as cases and learns the differences in their noise patterns, thus enabling noise patterns to transfer to unknown samples. Unfortunately, the inevitable sample-level baseline noise makes the model unable to obtain the paired data that only differ in dataset-level environmental noise. To address the problem, we generate a sample-to-sample case-base to exclude the interference of sample-level noise on dataset-level noise learning, enhancing the system's learning performance. Experiments on spectral data with different background noises demonstrate the good noise-transferring ability of the proposed method against baseline systems ranging from wavelet denoising, deep neural networks, and generative models. From this research, we posit that our method can enhance the performance of DL models by generating high-quality cases. The source code is made publicly available online at https://github.com/Magnomic/CNST.","sentences":["Spectrum analysis systems in online water quality testing are designed to detect types and concentrations of pollutants and enable regulatory agencies to respond promptly to pollution incidents.","However, spectral data-based testing devices suffer from complex noise patterns when deployed in non-laboratory environments.","To make the analysis model applicable to more environments, we propose a noise patterns transferring model, which takes the spectrum of standard water samples in different environments as cases and learns the differences in their noise patterns, thus enabling noise patterns to transfer to unknown samples.","Unfortunately, the inevitable sample-level baseline noise makes the model unable to obtain the paired data that only differ in dataset-level environmental noise.","To address the problem, we generate a sample-to-sample case-base to exclude the interference of sample-level noise on dataset-level noise learning, enhancing the system's learning performance.","Experiments on spectral data with different background noises demonstrate the good noise-transferring ability of the proposed method against baseline systems ranging from wavelet denoising, deep neural networks, and generative models.","From this research, we posit that our method can enhance the performance of DL models by generating high-quality cases.","The source code is made publicly available online at https://github.com/Magnomic/CNST."],"url":"http://arxiv.org/abs/2308.01138v1"}
{"created":"2023-08-02 13:28:12","title":"Leveraging Expert Models for Training Deep Neural Networks in Scarce Data Domains: Application to Offline Handwritten Signature Verification","abstract":"This paper introduces a novel approach to leverage the knowledge of existing expert models for training new Convolutional Neural Networks, on domains where task-specific data are limited or unavailable. The presented scheme is applied in offline handwritten signature verification (OffSV) which, akin to other biometric applications, suffers from inherent data limitations due to regulatory restrictions. The proposed Student-Teacher (S-T) configuration utilizes feature-based knowledge distillation (FKD), combining graph-based similarity for local activations with global similarity measures to supervise student's training, using only handwritten text data. Remarkably, the models trained using this technique exhibit comparable, if not superior, performance to the teacher model across three popular signature datasets. More importantly, these results are attained without employing any signatures during the feature extraction training process. This study demonstrates the efficacy of leveraging existing expert models to overcome data scarcity challenges in OffSV and potentially other related domains.","sentences":["This paper introduces a novel approach to leverage the knowledge of existing expert models for training new Convolutional Neural Networks, on domains where task-specific data are limited or unavailable.","The presented scheme is applied in offline handwritten signature verification (OffSV) which, akin to other biometric applications, suffers from inherent data limitations due to regulatory restrictions.","The proposed Student-Teacher (S-T) configuration utilizes feature-based knowledge distillation (FKD), combining graph-based similarity for local activations with global similarity measures to supervise student's training, using only handwritten text data.","Remarkably, the models trained using this technique exhibit comparable, if not superior, performance to the teacher model across three popular signature datasets.","More importantly, these results are attained without employing any signatures during the feature extraction training process.","This study demonstrates the efficacy of leveraging existing expert models to overcome data scarcity challenges in OffSV and potentially other related domains."],"url":"http://arxiv.org/abs/2308.01136v1"}
{"created":"2023-08-02 13:13:18","title":"DiffusePast: Diffusion-based Generative Replay for Class Incremental Semantic Segmentation","abstract":"The Class Incremental Semantic Segmentation (CISS) extends the traditional segmentation task by incrementally learning newly added classes. Previous work has introduced generative replay, which involves replaying old class samples generated from a pre-trained GAN, to address the issues of catastrophic forgetting and privacy concerns. However, the generated images lack semantic precision and exhibit out-of-distribution characteristics, resulting in inaccurate masks that further degrade the segmentation performance. To tackle these challenges, we propose DiffusePast, a novel framework featuring a diffusion-based generative replay module that generates semantically accurate images with more reliable masks guided by different instructions (e.g., text prompts or edge maps). Specifically, DiffusePast introduces a dual-generator paradigm, which focuses on generating old class images that align with the distribution of downstream datasets while preserving the structure and layout of the original images, enabling more precise masks. To adapt to the novel visual concepts of newly added classes continuously, we incorporate class-wise token embedding when updating the dual-generator. Moreover, we assign adequate pseudo-labels of old classes to the background pixels in the new step images, further mitigating the forgetting of previously learned knowledge. Through comprehensive experiments, our method demonstrates competitive performance across mainstream benchmarks, striking a better balance between the performance of old and novel classes.","sentences":["The Class Incremental Semantic Segmentation (CISS) extends the traditional segmentation task by incrementally learning newly added classes.","Previous work has introduced generative replay, which involves replaying old class samples generated from a pre-trained GAN, to address the issues of catastrophic forgetting and privacy concerns.","However, the generated images lack semantic precision and exhibit out-of-distribution characteristics, resulting in inaccurate masks that further degrade the segmentation performance.","To tackle these challenges, we propose DiffusePast, a novel framework featuring a diffusion-based generative replay module that generates semantically accurate images with more reliable masks guided by different instructions (e.g., text prompts or edge maps).","Specifically, DiffusePast introduces a dual-generator paradigm, which focuses on generating old class images that align with the distribution of downstream datasets while preserving the structure and layout of the original images, enabling more precise masks.","To adapt to the novel visual concepts of newly added classes continuously, we incorporate class-wise token embedding when updating the dual-generator.","Moreover, we assign adequate pseudo-labels of old classes to the background pixels in the new step images, further mitigating the forgetting of previously learned knowledge.","Through comprehensive experiments, our method demonstrates competitive performance across mainstream benchmarks, striking a better balance between the performance of old and novel classes."],"url":"http://arxiv.org/abs/2308.01127v1"}
{"created":"2023-08-02 13:09:57","title":"Beyond Generic: Enhancing Image Captioning with Real-World Knowledge using Vision-Language Pre-Training Model","abstract":"Current captioning approaches tend to generate correct but \"generic\" descriptions that lack real-world knowledge, e.g., named entities and contextual information. Considering that Vision-Language Pre-Training (VLP) models master massive such knowledge from large-scale web-harvested data, it is promising to utilize the generalizability of VLP models to incorporate knowledge into image descriptions. However, using VLP models faces challenges: zero-shot inference suffers from knowledge hallucination that leads to low-quality descriptions, but the generic bias in downstream task fine-tuning hinders the VLP model from expressing knowledge. To address these concerns, we propose a simple yet effective method called Knowledge-guided Replay (K-Replay), which enables the retention of pre-training knowledge during fine-tuning. Our approach consists of two parts: (1) a knowledge prediction task on automatically collected replay exemplars to continuously awaken the VLP model's memory about knowledge, thus preventing the model from collapsing into the generic pattern; (2) a knowledge distillation constraint to improve the faithfulness of generated descriptions hence alleviating the knowledge hallucination. To evaluate knowledge-enhanced descriptions, we construct a novel captioning benchmark KnowCap, containing knowledge of landmarks, famous brands, special foods and movie characters. Experimental results show that our approach effectively incorporates knowledge into descriptions, outperforming strong VLP baseline by 20.9 points (78.7->99.6) in CIDEr score and 20.5 percentage points (34.0%->54.5%) in knowledge recognition accuracy. Our code and data is available at https://github.com/njucckevin/KnowCap.","sentences":["Current captioning approaches tend to generate correct but \"generic\" descriptions that lack real-world knowledge, e.g., named entities and contextual information.","Considering that Vision-Language Pre-Training (VLP) models master massive such knowledge from large-scale web-harvested data, it is promising to utilize the generalizability of VLP models to incorporate knowledge into image descriptions.","However, using VLP models faces challenges: zero-shot inference suffers from knowledge hallucination that leads to low-quality descriptions, but the generic bias in downstream task fine-tuning hinders the VLP model from expressing knowledge.","To address these concerns, we propose a simple yet effective method called Knowledge-guided Replay (K-Replay), which enables the retention of pre-training knowledge during fine-tuning.","Our approach consists of two parts: (1) a knowledge prediction task on automatically collected replay exemplars to continuously awaken the VLP model's memory about knowledge, thus preventing the model from collapsing into the generic pattern; (2) a knowledge distillation constraint to improve the faithfulness of generated descriptions hence alleviating the knowledge hallucination.","To evaluate knowledge-enhanced descriptions, we construct a novel captioning benchmark KnowCap, containing knowledge of landmarks, famous brands, special foods and movie characters.","Experimental results show that our approach effectively incorporates knowledge into descriptions, outperforming strong VLP baseline by 20.9 points (78.7->99.6) in CIDEr score and 20.5 percentage points (34.0%->54.5%) in knowledge recognition accuracy.","Our code and data is available at https://github.com/njucckevin/KnowCap."],"url":"http://arxiv.org/abs/2308.01126v1"}
{"created":"2023-08-02 13:09:12","title":"Stereo Visual Odometry with Deep Learning-Based Point and Line Feature Matching using an Attention Graph Neural Network","abstract":"Robust feature matching forms the backbone for most Visual Simultaneous Localization and Mapping (vSLAM), visual odometry, 3D reconstruction, and Structure from Motion (SfM) algorithms. However, recovering feature matches from texture-poor scenes is a major challenge and still remains an open area of research. In this paper, we present a Stereo Visual Odometry (StereoVO) technique based on point and line features which uses a novel feature-matching mechanism based on an Attention Graph Neural Network that is designed to perform well even under adverse weather conditions such as fog, haze, rain, and snow, and dynamic lighting conditions such as nighttime illumination and glare scenarios. We perform experiments on multiple real and synthetic datasets to validate the ability of our method to perform StereoVO under low visibility weather and lighting conditions through robust point and line matches. The results demonstrate that our method achieves more line feature matches than state-of-the-art line matching algorithms, which when complemented with point feature matches perform consistently well in adverse weather and dynamic lighting conditions.","sentences":["Robust feature matching forms the backbone for most Visual Simultaneous Localization and Mapping (vSLAM), visual odometry, 3D reconstruction, and Structure from Motion (SfM) algorithms.","However, recovering feature matches from texture-poor scenes is a major challenge and still remains an open area of research.","In this paper, we present a Stereo Visual Odometry (StereoVO) technique based on point and line features which uses a novel feature-matching mechanism based on an Attention Graph Neural Network that is designed to perform well even under adverse weather conditions such as fog, haze, rain, and snow, and dynamic lighting conditions such as nighttime illumination and glare scenarios.","We perform experiments on multiple real and synthetic datasets to validate the ability of our method to perform StereoVO under low visibility weather and lighting conditions through robust point and line matches.","The results demonstrate that our method achieves more line feature matches than state-of-the-art line matching algorithms, which when complemented with point feature matches perform consistently well in adverse weather and dynamic lighting conditions."],"url":"http://arxiv.org/abs/2308.01125v1"}
{"created":"2023-08-02 12:58:11","title":"A Survey on Popularity Bias in Recommender Systems","abstract":"Recommender systems help people find relevant content in a personalized way. One main promise of such systems is that they are able to increase the visibility of items in the long tail, i.e., the lesser-known items in a catalogue. Existing research, however, suggests that in many situations today's recommendation algorithms instead exhibit a popularity bias, meaning that they often focus on rather popular items in their recommendations. Such a bias may not only lead to limited value of the recommendations for consumers and providers in the short run, but it may also cause undesired reinforcement effects over time. In this paper, we discuss the potential reasons for popularity bias and we review existing approaches to detect, quantify and mitigate popularity bias in recommender systems. Our survey therefore includes both an overview of the computational metrics used in the literature as well as a review of the main technical approaches to reduce the bias. We furthermore critically discuss today's literature, where we observe that the research is almost entirely based on computational experiments and on certain assumptions regarding the practical effects of including long-tail items in the recommendations.","sentences":["Recommender systems help people find relevant content in a personalized way.","One main promise of such systems is that they are able to increase the visibility of items in the long tail, i.e., the lesser-known items in a catalogue.","Existing research, however, suggests that in many situations today's recommendation algorithms instead exhibit a popularity bias, meaning that they often focus on rather popular items in their recommendations.","Such a bias may not only lead to limited value of the recommendations for consumers and providers in the short run, but it may also cause undesired reinforcement effects over time.","In this paper, we discuss the potential reasons for popularity bias and we review existing approaches to detect, quantify and mitigate popularity bias in recommender systems.","Our survey therefore includes both an overview of the computational metrics used in the literature as well as a review of the main technical approaches to reduce the bias.","We furthermore critically discuss today's literature, where we observe that the research is almost entirely based on computational experiments and on certain assumptions regarding the practical effects of including long-tail items in the recommendations."],"url":"http://arxiv.org/abs/2308.01118v1"}
{"created":"2023-08-02 12:56:05","title":"Optimization-Based Motion Planning for Autonomous Agricultural Vehicles Turning in Constrained Headlands","abstract":"Headland maneuvering is a crucial aspect of unmanned field operations for autonomous agricultural vehicles (AAVs). While motion planning for headland turning in open fields has been extensively studied and integrated into commercial auto-guidance systems, the existing methods primarily address scenarios with ample headland space and thus may not work in more constrained headland geometries. Commercial orchards often contain narrow and irregularly shaped headlands, which may include static obstacles,rendering the task of planning a smooth and collision-free turning trajectory difficult. To address this challenge, we propose an optimization-based motion planning algorithm for headland turning under geometrical constraints imposed by field geometry and obstacles.","sentences":["Headland maneuvering is a crucial aspect of unmanned field operations for autonomous agricultural vehicles (AAVs).","While motion planning for headland turning in open fields has been extensively studied and integrated into commercial auto-guidance systems, the existing methods primarily address scenarios with ample headland space and thus may not work in more constrained headland geometries.","Commercial orchards often contain narrow and irregularly shaped headlands, which may include static obstacles,rendering the task of planning a smooth and collision-free turning trajectory difficult.","To address this challenge, we propose an optimization-based motion planning algorithm for headland turning under geometrical constraints imposed by field geometry and obstacles."],"url":"http://arxiv.org/abs/2308.01117v1"}
{"created":"2023-08-02 12:37:23","title":"Signed double Roman domination on cubic graphs","abstract":"The signed double Roman domination problem is a combinatorial optimization problem on a graph asking to assign a label from $\\{\\pm{}1,2,3\\}$ to each vertex feasibly, such that the total sum of assigned labels is minimized. Here feasibility is given whenever (i) vertices labeled $\\pm{}1$ have at least one neighbor with label in $\\{2,3\\}$; (ii) each vertex labeled $-1$ has one $3$-labeled neighbor or at least two $2$-labeled neighbors; and (iii) the sum of labels over the closed neighborhood of any vertex is positive. The cumulative weight of an optimal labeling is called signed double Roman domination number (SDRDN). In this work, we first consider the problem on general cubic graphs of order $n$ for which we present a sharp $n/2+\\Theta(1)$ lower bound for the SDRDN by means of the discharging method. Moreover, we derive a new best upper bound. Observing that we are often able to minimize the SDRDN over the class of cubic graphs of a fixed order, we then study in this context generalized Petersen graphs for independent interest, for which we propose a constraint programming guided proof. We then use these insights to determine the SDRDNs of subcubic $2\\times m$ grid graphs, among other results.","sentences":["The signed double Roman domination problem is a combinatorial optimization problem on a graph asking to assign a label from $\\{\\pm{}1,2,3\\}$ to each vertex feasibly, such that the total sum of assigned labels is minimized.","Here feasibility is given whenever (i) vertices labeled $\\pm{}1$ have at least one neighbor with label in $\\{2,3\\}$; (ii) each vertex labeled $-1$ has one $3$-labeled neighbor or at least two $2$-labeled neighbors; and (iii) the sum of labels over the closed neighborhood of any vertex is positive.","The cumulative weight of an optimal labeling is called signed double Roman domination number (SDRDN).","In this work, we first consider the problem on general cubic graphs of order $n$ for which we present a sharp $n/2+\\Theta(1)$ lower bound for the SDRDN by means of the discharging method.","Moreover, we derive a new best upper bound.","Observing that we are often able to minimize the SDRDN over the class of cubic graphs of a fixed order, we then study in this context generalized Petersen graphs for independent interest, for which we propose a constraint programming guided proof.","We then use these insights to determine the SDRDNs of subcubic $2\\times m$ grid graphs, among other results."],"url":"http://arxiv.org/abs/2308.01109v1"}
{"created":"2023-08-02 12:22:35","title":"Literal-Aware Knowledge Graph Embedding for Welding Quality Monitoring: A Bosch Case","abstract":"Recently there has been a series of studies in knowledge graph embedding (KGE), which attempts to learn the embeddings of the entities and relations as numerical vectors and mathematical mappings via machine learning (ML). However, there has been limited research that applies KGE for industrial problems in manufacturing. This paper investigates whether and to what extent KGE can be used for an important problem: quality monitoring for welding in manufacturing industry, which is an impactful process accounting for production of millions of cars annually. The work is in line with Bosch research of data-driven solutions that intends to replace the traditional way of destroying cars, which is extremely costly and produces waste. The paper tackles two very challenging questions simultaneously: how large the welding spot diameter is; and to which car body the welded spot belongs to. The problem setting is difficult for traditional ML because there exist a high number of car bodies that should be assigned as class labels. We formulate the problem as link prediction, and experimented popular KGE methods on real industry data, with consideration of literals. Our results reveal both limitations and promising aspects of adapted KGE methods.","sentences":["Recently there has been a series of studies in knowledge graph embedding (KGE), which attempts to learn the embeddings of the entities and relations as numerical vectors and mathematical mappings via machine learning (ML).","However, there has been limited research that applies KGE for industrial problems in manufacturing.","This paper investigates whether and to what extent KGE can be used for an important problem: quality monitoring for welding in manufacturing industry, which is an impactful process accounting for production of millions of cars annually.","The work is in line with Bosch research of data-driven solutions that intends to replace the traditional way of destroying cars, which is extremely costly and produces waste.","The paper tackles two very challenging questions simultaneously: how large the welding spot diameter is; and to which car body the welded spot belongs to.","The problem setting is difficult for traditional ML because there exist a high number of car bodies that should be assigned as class labels.","We formulate the problem as link prediction, and experimented popular KGE methods on real industry data, with consideration of literals.","Our results reveal both limitations and promising aspects of adapted KGE methods."],"url":"http://arxiv.org/abs/2308.01105v1"}
