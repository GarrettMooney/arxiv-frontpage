{"created":"2023-12-13 18:59:58","title":"SAM-guided Graph Cut for 3D Instance Segmentation","abstract":"This paper addresses the challenge of 3D instance segmentation by simultaneously leveraging 3D geometric and multi-view image information. Many previous works have applied deep learning techniques to 3D point clouds for instance segmentation. However, these methods often failed to generalize to various types of scenes due to the scarcity and low-diversity of labeled 3D point cloud data. Some recent works have attempted to lift 2D instance segmentations to 3D within a bottom-up framework. The inconsistency in 2D instance segmentations among views can substantially degrade the performance of 3D segmentation. In this work, we introduce a novel 3D-to-2D query framework to effectively exploit 2D segmentation models for 3D instance segmentation. Specifically, we pre-segment the scene into several superpoints in 3D, formulating the task into a graph cut problem. The superpoint graph is constructed based on 2D segmentation models, where node features are obtained from multi-view image features and edge weights are computed based on multi-view segmentation results, enabling the better generalization ability. To process the graph, we train a graph neural network using pseudo 3D labels from 2D segmentation models. Experimental results on the ScanNet, ScanNet++ and KITTI-360 datasets demonstrate that our method achieves robust segmentation performance and can generalize across different types of scenes. Our project page is available at https://zju3dv.github.io/sam_graph.","sentences":["This paper addresses the challenge of 3D instance segmentation by simultaneously leveraging 3D geometric and multi-view image information.","Many previous works have applied deep learning techniques to 3D point clouds for instance segmentation.","However, these methods often failed to generalize to various types of scenes due to the scarcity and low-diversity of labeled 3D point cloud data.","Some recent works have attempted to lift 2D instance segmentations to 3D within a bottom-up framework.","The inconsistency in 2D instance segmentations among views can substantially degrade the performance of 3D segmentation.","In this work, we introduce a novel 3D-to-2D query framework to effectively exploit 2D segmentation models for 3D instance segmentation.","Specifically, we pre-segment the scene into several superpoints in 3D, formulating the task into a graph cut problem.","The superpoint graph is constructed based on 2D segmentation models, where node features are obtained from multi-view image features and edge weights are computed based on multi-view segmentation results, enabling the better generalization ability.","To process the graph, we train a graph neural network using pseudo 3D labels from 2D segmentation models.","Experimental results on the ScanNet, ScanNet++ and KITTI-360 datasets demonstrate that our method achieves robust segmentation performance and can generalize across different types of scenes.","Our project page is available at https://zju3dv.github.io/sam_graph."],"url":"http://arxiv.org/abs/2312.08372v1"}
{"created":"2023-12-13 18:59:13","title":"PTT: Point-Trajectory Transformer for Efficient Temporal 3D Object Detection","abstract":"Recent temporal LiDAR-based 3D object detectors achieve promising performance based on the two-stage proposal-based approach. They generate 3D box candidates from the first-stage dense detector, followed by different temporal aggregation methods. However, these approaches require per-frame objects or whole point clouds, posing challenges related to memory bank utilization. Moreover, point clouds and trajectory features are combined solely based on concatenation, which may neglect effective interactions between them. In this paper, we propose a point-trajectory transformer with long short-term memory for efficient temporal 3D object detection. To this end, we only utilize point clouds of current-frame objects and their historical trajectories as input to minimize the memory bank storage requirement. Furthermore, we introduce modules to encode trajectory features, focusing on long short-term and future-aware perspectives, and then effectively aggregate them with point cloud features. We conduct extensive experiments on the large-scale Waymo dataset to demonstrate that our approach performs well against state-of-the-art methods. Code and models will be made publicly available at https://github.com/kuanchihhuang/PTT.","sentences":["Recent temporal LiDAR-based 3D object detectors achieve promising performance based on the two-stage proposal-based approach.","They generate 3D box candidates from the first-stage dense detector, followed by different temporal aggregation methods.","However, these approaches require per-frame objects or whole point clouds, posing challenges related to memory bank utilization.","Moreover, point clouds and trajectory features are combined solely based on concatenation, which may neglect effective interactions between them.","In this paper, we propose a point-trajectory transformer with long short-term memory for efficient temporal 3D object detection.","To this end, we only utilize point clouds of current-frame objects and their historical trajectories as input to minimize the memory bank storage requirement.","Furthermore, we introduce modules to encode trajectory features, focusing on long short-term and future-aware perspectives, and then effectively aggregate them with point cloud features.","We conduct extensive experiments on the large-scale Waymo dataset to demonstrate that our approach performs well against state-of-the-art methods.","Code and models will be made publicly available at https://github.com/kuanchihhuang/PTT."],"url":"http://arxiv.org/abs/2312.08371v1"}
{"created":"2023-12-13 18:58:15","title":"VLAP: Efficient Video-Language Alignment via Frame Prompting and Distilling for Video Question Answering","abstract":"In this work, we propose an efficient Video-Language Alignment via Frame-Prompting and Distilling (VLAP) network. Our VLAP model addresses both efficient frame sampling and effective cross-modal alignment in a unified way. In our VLAP network, we design a new learnable question-aware Frame-Prompter together with a new cross-modal distillation (QFormer-Distiller) module. Pre-trained large image-language models have shown promising results on problems such as visual question answering. However, how to efficiently and effectively sample image frames when adapting pre-trained large image-language model to video-language alignment is still the major challenge. Compared with prior work, our VLAP model demonstrates the capability of selecting key frames with critical contents, thus improving the video-language alignment accuracy while reducing the inference latency (+3.3% on NExT-QA Temporal with 3.0X speed up). Overall, our VLAP network outperforms (e.g. +4.6% on STAR Interaction and +2.2% on STAR average with 3.0X speed up, ours 2-frames out-perform SeViLA 4-frames on VLEP with 4.2X speed up) the state-of-the-art methods on the video question-answering benchmarks.","sentences":["In this work, we propose an efficient Video-Language Alignment via Frame-Prompting and Distilling (VLAP) network.","Our VLAP model addresses both efficient frame sampling and effective cross-modal alignment in a unified way.","In our VLAP network, we design a new learnable question-aware Frame-Prompter together with a new cross-modal distillation (QFormer-Distiller) module.","Pre-trained large image-language models have shown promising results on problems such as visual question answering.","However, how to efficiently and effectively sample image frames when adapting pre-trained large image-language model to video-language alignment is still the major challenge.","Compared with prior work, our VLAP model demonstrates the capability of selecting key frames with critical contents, thus improving the video-language alignment accuracy while reducing the inference latency (+3.3% on NExT-QA Temporal with 3.0X speed up).","Overall, our VLAP network outperforms (e.g. +4.6% on STAR Interaction and +2.2% on STAR average with 3.0X speed up, ours 2-frames out-perform SeViLA 4-frames on VLEP with 4.2X speed up) the state-of-the-art methods on the video question-answering benchmarks."],"url":"http://arxiv.org/abs/2312.08367v1"}
{"created":"2023-12-13 18:58:04","title":"See, Say, and Segment: Teaching LMMs to Overcome False Premises","abstract":"Current open-source Large Multimodal Models (LMMs) excel at tasks such as open-vocabulary language grounding and segmentation but can suffer under false premises when queries imply the existence of something that is not actually present in the image. We observe that existing methods that fine-tune an LMM to segment images significantly degrade their ability to reliably determine (\"see\") if an object is present and to interact naturally with humans (\"say\"), a form of catastrophic forgetting. In this work, we propose a cascading and joint training approach for LMMs to solve this task, avoiding catastrophic forgetting of previous skills. Our resulting model can \"see\" by detecting whether objects are present in an image, \"say\" by telling the user if they are not, proposing alternative queries or correcting semantic errors in the query, and finally \"segment\" by outputting the mask of the desired objects if they exist. Additionally, we introduce a novel False Premise Correction benchmark dataset, an extension of existing RefCOCO(+/g) referring segmentation datasets (which we call FP-RefCOCO(+/g)). The results show that our method not only detects false premises up to 55% better than existing approaches, but under false premise conditions produces relative cIOU improvements of more than 31% over baselines, and produces natural language feedback judged helpful up to 67% of the time.","sentences":["Current open-source Large Multimodal Models (LMMs) excel at tasks such as open-vocabulary language grounding and segmentation but can suffer under false premises when queries imply the existence of something that is not actually present in the image.","We observe that existing methods that fine-tune an LMM to segment images significantly degrade their ability to reliably determine (\"see\") if an object is present and to interact naturally with humans (\"say\"), a form of catastrophic forgetting.","In this work, we propose a cascading and joint training approach for LMMs to solve this task, avoiding catastrophic forgetting of previous skills.","Our resulting model can \"see\" by detecting whether objects are present in an image, \"say\" by telling the user if they are not, proposing alternative queries or correcting semantic errors in the query, and finally \"segment\" by outputting the mask of the desired objects if they exist.","Additionally, we introduce a novel False Premise Correction benchmark dataset, an extension of existing RefCOCO(+/g) referring segmentation datasets (which we call FP-RefCOCO(+/g)).","The results show that our method not only detects false premises up to 55% better than existing approaches, but under false premise conditions produces relative cIOU improvements of more than 31% over baselines, and produces natural language feedback judged helpful up to 67% of the time."],"url":"http://arxiv.org/abs/2312.08366v1"}
{"created":"2023-12-13 18:57:23","title":"An Invitation to Deep Reinforcement Learning","abstract":"Training a deep neural network to maximize a target objective has become the standard recipe for successful machine learning over the last decade. These networks can be optimized with supervised learning, if the target objective is differentiable. For many interesting problems, this is however not the case. Common objectives like intersection over union (IoU), bilingual evaluation understudy (BLEU) score or rewards cannot be optimized with supervised learning. A common workaround is to define differentiable surrogate losses, leading to suboptimal solutions with respect to the actual objective. Reinforcement learning (RL) has emerged as a promising alternative for optimizing deep neural networks to maximize non-differentiable objectives in recent years. Examples include aligning large language models via human feedback, code generation, object detection or control problems. This makes RL techniques relevant to the larger machine learning audience. The subject is, however, time intensive to approach due to the large range of methods, as well as the often very theoretical presentation. In this introduction, we take an alternative approach, different from classic reinforcement learning textbooks. Rather than focusing on tabular problems, we introduce reinforcement learning as a generalization of supervised learning, which we first apply to non-differentiable objectives and later to temporal problems. Assuming only basic knowledge of supervised learning, the reader will be able to understand state-of-the-art deep RL algorithms like proximal policy optimization (PPO) after reading this tutorial.","sentences":["Training a deep neural network to maximize a target objective has become the standard recipe for successful machine learning over the last decade.","These networks can be optimized with supervised learning, if the target objective is differentiable.","For many interesting problems, this is however not the case.","Common objectives like intersection over union (IoU), bilingual evaluation understudy (BLEU) score or rewards cannot be optimized with supervised learning.","A common workaround is to define differentiable surrogate losses, leading to suboptimal solutions with respect to the actual objective.","Reinforcement learning (RL) has emerged as a promising alternative for optimizing deep neural networks to maximize non-differentiable objectives in recent years.","Examples include aligning large language models via human feedback, code generation, object detection or control problems.","This makes RL techniques relevant to the larger machine learning audience.","The subject is, however, time intensive to approach due to the large range of methods, as well as the often very theoretical presentation.","In this introduction, we take an alternative approach, different from classic reinforcement learning textbooks.","Rather than focusing on tabular problems, we introduce reinforcement learning as a generalization of supervised learning, which we first apply to non-differentiable objectives and later to temporal problems.","Assuming only basic knowledge of supervised learning, the reader will be able to understand state-of-the-art deep RL algorithms like proximal policy optimization (PPO) after reading this tutorial."],"url":"http://arxiv.org/abs/2312.08365v1"}
{"created":"2023-12-13 18:56:13","title":"View-Dependent Octree-based Mesh Extraction in Unbounded Scenes for Procedural Synthetic Data","abstract":"Procedural synthetic data generation has received increasing attention in computer vision. Procedural signed distance functions (SDFs) are a powerful tool for modeling large-scale detailed scenes, but existing mesh extraction methods have artifacts or performance profiles that limit their use for synthetic data. We propose OcMesher, a mesh extraction algorithm that efficiently handles high-detail unbounded scenes with perfect view-consistency, with easy export to downstream real-time engines. The main novelty of our solution is an algorithm to construct an octree based on a given SDF and multiple camera views. We performed extensive experiments, and show our solution produces better synthetic data for training and evaluation of computer vision models.","sentences":["Procedural synthetic data generation has received increasing attention in computer vision.","Procedural signed distance functions (SDFs) are a powerful tool for modeling large-scale detailed scenes, but existing mesh extraction methods have artifacts or performance profiles that limit their use for synthetic data.","We propose OcMesher, a mesh extraction algorithm that efficiently handles high-detail unbounded scenes with perfect view-consistency, with easy export to downstream real-time engines.","The main novelty of our solution is an algorithm to construct an octree based on a given SDF and multiple camera views.","We performed extensive experiments, and show our solution produces better synthetic data for training and evaluation of computer vision models."],"url":"http://arxiv.org/abs/2312.08364v1"}
{"created":"2023-12-13 18:56:03","title":"On the Computational Hardness of Quantum One-Wayness","abstract":"There is a large body of work studying what forms of computational hardness are needed to realize classical cryptography. In particular, one-way functions and pseudorandom generators can be built from each other, and thus require equivalent computational assumptions to be realized. Furthermore, the existence of either of these primitives implies that $\\rm{P} \\neq \\rm{NP}$, which gives a lower bound on the necessary hardness.   One can also define versions of each of these primitives with quantum output: respectively one-way state generators and pseudorandom state generators. Unlike in the classical setting, it is not known whether either primitive can be built from the other. Although it has been shown that pseudorandom state generators for certain parameter regimes can be used to build one-way state generators, the implication has not been previously known in full generality. Furthermore, to the best of our knowledge, the existence of one-way state generators has no known implications in complexity theory.   We show that pseudorandom states compressing $n$ bits to $\\log n + 1$ qubits can be used to build one-way state generators and pseudorandom states compressing $n$ bits to $\\omega(\\log n)$ qubits are one-way state generators. This is a nearly optimal result since pseudorandom states with fewer than $c \\log n$-qubit output can be shown to exist unconditionally. We also show that any one-way state generator can be broken by a quantum algorithm with classical access to a $\\rm{PP}$ oracle.   An interesting implication of our results is that a $t(n)$-copy one-way state generator exists unconditionally, for every $t(n) = o(n/\\log n)$. This contrasts nicely with the previously known fact that $O(n)$-copy one-way state generators require computational hardness. We also outline a new route towards a black-box separation between one-way state generators and quantum bit commitments.","sentences":["There is a large body of work studying what forms of computational hardness are needed to realize classical cryptography.","In particular, one-way functions and pseudorandom generators can be built from each other, and thus require equivalent computational assumptions to be realized.","Furthermore, the existence of either of these primitives implies that $\\rm{P} \\neq \\rm{NP}$, which gives a lower bound on the necessary hardness.   ","One can also define versions of each of these primitives with quantum output: respectively one-way state generators and pseudorandom state generators.","Unlike in the classical setting, it is not known whether either primitive can be built from the other.","Although it has been shown that pseudorandom state generators for certain parameter regimes can be used to build one-way state generators, the implication has not been previously known in full generality.","Furthermore, to the best of our knowledge, the existence of one-way state generators has no known implications in complexity theory.   ","We show that pseudorandom states compressing $n$ bits to $\\log n + 1$ qubits can be used to build one-way state generators and pseudorandom states compressing $n$ bits to $\\omega(\\log n)$ qubits are one-way state generators.","This is a nearly optimal result since pseudorandom states with fewer than $c \\log n$-qubit output can be shown to exist unconditionally.","We also show that any one-way state generator can be broken by a quantum algorithm with classical access to a $\\rm{PP}$ oracle.   ","An interesting implication of our results is that a $t(n)$-copy one-way state generator exists unconditionally, for every $t(n) = o(n/\\log n)$.","This contrasts nicely with the previously known fact that $O(n)$-copy one-way state generators require computational hardness.","We also outline a new route towards a black-box separation between one-way state generators and quantum bit commitments."],"url":"http://arxiv.org/abs/2312.08363v1"}
{"created":"2023-12-13 18:52:49","title":"Distributed Inference and Fine-tuning of Large Language Models Over The Internet","abstract":"Large language models (LLMs) are useful in many NLP tasks and become more capable with size, with the best open-source models having over 50 billion parameters. However, using these 50B+ models requires high-end hardware, making them inaccessible to most researchers. In this work, we investigate methods for cost-efficient inference and fine-tuning of LLMs, comparing local and distributed strategies. We observe that a large enough model (50B+) can run efficiently even on geodistributed devices in a consumer-grade network. This could allow running LLM efficiently by pooling together idle compute resources of multiple research groups and volunteers. We address two open problems: (1) how to perform inference and fine-tuning reliably if any device can disconnect abruptly and (2) how to partition LLMs between devices with uneven hardware, joining and leaving at will. In order to do that, we develop special fault-tolerant inference algorithms and load-balancing protocols that automatically assign devices to maximize the total system throughput. We showcase these algorithms in Petals - a decentralized system that runs Llama 2 (70B) and BLOOM (176B) over the Internet up to 10x faster than offloading for interactive generation. We evaluate the performance of our system in simulated conditions and a real-world setup spanning two continents.","sentences":["Large language models (LLMs) are useful in many NLP tasks and become more capable with size, with the best open-source models having over 50 billion parameters.","However, using these 50B+ models requires high-end hardware, making them inaccessible to most researchers.","In this work, we investigate methods for cost-efficient inference and fine-tuning of LLMs, comparing local and distributed strategies.","We observe that a large enough model (50B+) can run efficiently even on geodistributed devices in a consumer-grade network.","This could allow running LLM efficiently by pooling together idle compute resources of multiple research groups and volunteers.","We address two open problems: (1) how to perform inference and fine-tuning reliably if any device can disconnect abruptly and (2) how to partition LLMs between devices with uneven hardware, joining and leaving at will.","In order to do that, we develop special fault-tolerant inference algorithms and load-balancing protocols that automatically assign devices to maximize the total system throughput.","We showcase these algorithms in Petals - a decentralized system that runs Llama 2 (70B) and BLOOM (176B) over the Internet up to 10x faster than offloading for interactive generation.","We evaluate the performance of our system in simulated conditions and a real-world setup spanning two continents."],"url":"http://arxiv.org/abs/2312.08361v1"}
{"created":"2023-12-13 18:51:34","title":"Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF","abstract":"In practice, preference learning from human feedback depends on incomplete data with hidden context. Hidden context refers to data that affects the feedback received, but which is not represented in the data used to train a preference model. This captures common issues of data collection, such as having human annotators with varied preferences, cognitive processes that result in seemingly irrational behavior, and combining data labeled according to different criteria. We prove that standard applications of preference learning, including reinforcement learning from human feedback (RLHF), implicitly aggregate over hidden contexts according to a well-known voting rule called Borda count. We show this can produce counter-intuitive results that are very different from other methods which implicitly aggregate via expected utility. Furthermore, our analysis formalizes the way that preference learning from users with diverse values tacitly implements a social choice function. A key implication of this result is that annotators have an incentive to misreport their preferences in order to influence the learned model, leading to vulnerabilities in the deployment of RLHF. As a step towards mitigating these problems, we introduce a class of methods called distributional preference learning (DPL). DPL methods estimate a distribution of possible score values for each alternative in order to better account for hidden context. Experimental results indicate that applying DPL to RLHF for LLM chatbots identifies hidden context in the data and significantly reduces subsequent jailbreak vulnerability. Our code and data are available at https://github.com/cassidylaidlaw/hidden-context","sentences":["In practice, preference learning from human feedback depends on incomplete data with hidden context.","Hidden context refers to data that affects the feedback received, but which is not represented in the data used to train a preference model.","This captures common issues of data collection, such as having human annotators with varied preferences, cognitive processes that result in seemingly irrational behavior, and combining data labeled according to different criteria.","We prove that standard applications of preference learning, including reinforcement learning from human feedback (RLHF), implicitly aggregate over hidden contexts according to a well-known voting rule called Borda count.","We show this can produce counter-intuitive results that are very different from other methods which implicitly aggregate via expected utility.","Furthermore, our analysis formalizes the way that preference learning from users with diverse values tacitly implements a social choice function.","A key implication of this result is that annotators have an incentive to misreport their preferences in order to influence the learned model, leading to vulnerabilities in the deployment of RLHF.","As a step towards mitigating these problems, we introduce a class of methods called distributional preference learning (DPL).","DPL methods estimate a distribution of possible score values for each alternative in order to better account for hidden context.","Experimental results indicate that applying DPL to RLHF for LLM chatbots identifies hidden context in the data and significantly reduces subsequent jailbreak vulnerability.","Our code and data are available at https://github.com/cassidylaidlaw/hidden-context"],"url":"http://arxiv.org/abs/2312.08358v1"}
{"created":"2023-12-13 18:49:55","title":"CUTTANA: Scalable Graph Partitioning for Faster Distributed Graph Databases and Analytics","abstract":"Graph partitioning plays a pivotal role in various distributed graph processing applications, including graph analytics, graph neural network training, and distributed graph databases. Graphs that require distributed settings are often too large to fit in the main memory of a single machine. This challenge renders traditional in-memory graph partitioners infeasible, leading to the emergence of streaming solutions. Streaming partitioners produce lower-quality partitions because they work from partial information and must make premature decisions before they have a complete view of a vertex's neighborhood. We introduce CUTTANA, a streaming graph partitioner that partitions massive graphs (Web/Twitter scale) with superior quality compared to existing streaming solutions. CUTTANA uses a novel buffering technique that prevents the premature assignment of vertices to partitions and a scalable coarsening and refinement technique that enables a complete graph view, improving the intermediate assignment made by a streaming partitioner. We implemented a parallel version for CUTTANA that offers nearly the same partitioning latency as existing streaming partitioners.   Our experimental analysis shows that CUTTANA consistently yields better partitioning quality than existing state-of-the-art streaming vertex partitioners in terms of both edge-cut and communication volume metrics. We also evaluate the workload latencies that result from using CUTTANA and other partitioners in distributed graph analytics and databases. CUTTANA outperforms the other methods in most scenarios (algorithms, datasets). In analytics applications, CUTTANA improves runtime performance by up to 59% compared to various streaming partitioners (HDRF, Fennel, Ginger, HeiStream). In graph database tasks, CUTTANA results in higher query throughput by up to 23%, without hurting tail latency.","sentences":["Graph partitioning plays a pivotal role in various distributed graph processing applications, including graph analytics, graph neural network training, and distributed graph databases.","Graphs that require distributed settings are often too large to fit in the main memory of a single machine.","This challenge renders traditional in-memory graph partitioners infeasible, leading to the emergence of streaming solutions.","Streaming partitioners produce lower-quality partitions because they work from partial information and must make premature decisions before they have a complete view of a vertex's neighborhood.","We introduce CUTTANA, a streaming graph partitioner that partitions massive graphs (Web/Twitter scale) with superior quality compared to existing streaming solutions.","CUTTANA uses a novel buffering technique that prevents the premature assignment of vertices to partitions and a scalable coarsening and refinement technique that enables a complete graph view, improving the intermediate assignment made by a streaming partitioner.","We implemented a parallel version for CUTTANA that offers nearly the same partitioning latency as existing streaming partitioners.   ","Our experimental analysis shows that CUTTANA consistently yields better partitioning quality than existing state-of-the-art streaming vertex partitioners in terms of both edge-cut and communication volume metrics.","We also evaluate the workload latencies that result from using CUTTANA and other partitioners in distributed graph analytics and databases.","CUTTANA outperforms the other methods in most scenarios (algorithms, datasets).","In analytics applications, CUTTANA improves runtime performance by up to 59% compared to various streaming partitioners (HDRF, Fennel, Ginger, HeiStream).","In graph database tasks, CUTTANA results in higher query throughput by up to 23%, without hurting tail latency."],"url":"http://arxiv.org/abs/2312.08356v1"}
{"created":"2023-12-13 18:28:09","title":"FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects","abstract":"We present FoundationPose, a unified foundation model for 6D object pose estimation and tracking, supporting both model-based and model-free setups. Our approach can be instantly applied at test-time to a novel object without fine-tuning, as long as its CAD model is given, or a small number of reference images are captured. We bridge the gap between these two setups with a neural implicit representation that allows for effective novel view synthesis, keeping the downstream pose estimation modules invariant under the same unified framework. Strong generalizability is achieved via large-scale synthetic training, aided by a large language model (LLM), a novel transformer-based architecture, and contrastive learning formulation. Extensive evaluation on multiple public datasets involving challenging scenarios and objects indicate our unified approach outperforms existing methods specialized for each task by a large margin. In addition, it even achieves comparable results to instance-level methods despite the reduced assumptions. Project page: https://nvlabs.github.io/FoundationPose/","sentences":["We present FoundationPose, a unified foundation model for 6D object pose estimation and tracking, supporting both model-based and model-free setups.","Our approach can be instantly applied at test-time to a novel object without fine-tuning, as long as its CAD model is given, or a small number of reference images are captured.","We bridge the gap between these two setups with a neural implicit representation that allows for effective novel view synthesis, keeping the downstream pose estimation modules invariant under the same unified framework.","Strong generalizability is achieved via large-scale synthetic training, aided by a large language model (LLM), a novel transformer-based architecture, and contrastive learning formulation.","Extensive evaluation on multiple public datasets involving challenging scenarios and objects indicate our unified approach outperforms existing methods specialized for each task by a large margin.","In addition, it even achieves comparable results to instance-level methods despite the reduced assumptions.","Project page: https://nvlabs.github.io/FoundationPose/"],"url":"http://arxiv.org/abs/2312.08344v1"}
{"created":"2023-12-13 18:14:13","title":"Global Latent Neural Rendering","abstract":"A recent trend among generalizable novel view synthesis methods is to learn a rendering operator acting over single camera rays. This approach is promising because it removes the need for explicit volumetric rendering, but it effectively treats target images as collections of independent pixels. Here, we propose to learn a global rendering operator acting over all camera rays jointly. We show that the right representation to enable such rendering is the 5-dimensional plane sweep volume, consisting of the projection of the input images on a set of planes facing the target camera. Based on this understanding, we introduce our Convolutional Global Latent Renderer (ConvGLR), an efficient convolutional architecture that performs the rendering operation globally in a low-resolution latent space. Experiments on various datasets under sparse and generalizable setups show that our approach consistently outperforms existing methods by significant margins.","sentences":["A recent trend among generalizable novel view synthesis methods is to learn a rendering operator acting over single camera rays.","This approach is promising because it removes the need for explicit volumetric rendering, but it effectively treats target images as collections of independent pixels.","Here, we propose to learn a global rendering operator acting over all camera rays jointly.","We show that the right representation to enable such rendering is the 5-dimensional plane sweep volume, consisting of the projection of the input images on a set of planes facing the target camera.","Based on this understanding, we introduce our Convolutional Global Latent Renderer (ConvGLR), an efficient convolutional architecture that performs the rendering operation globally in a low-resolution latent space.","Experiments on various datasets under sparse and generalizable setups show that our approach consistently outperforms existing methods by significant margins."],"url":"http://arxiv.org/abs/2312.08338v1"}
{"created":"2023-12-13 18:11:37","title":"LD-SDM: Language-Driven Hierarchical Species Distribution Modeling","abstract":"We focus on the problem of species distribution modeling using global-scale presence-only data. Most previous studies have mapped the range of a given species using geographical and environmental features alone. To capture a stronger implicit relationship between species, we encode the taxonomic hierarchy of species using a large language model. This enables range mapping for any taxonomic rank and unseen species without additional supervision. Further, we propose a novel proximity-aware evaluation metric that enables evaluating species distribution models using any pixel-level representation of ground-truth species range map. The proposed metric penalizes the predictions of a model based on its proximity to the ground truth. We describe the effectiveness of our model by systematically evaluating on the task of species range prediction, zero-shot prediction and geo-feature regression against the state-of-the-art. Results show our model outperforms the strong baselines when trained with a variety of multi-label learning losses.","sentences":["We focus on the problem of species distribution modeling using global-scale presence-only data.","Most previous studies have mapped the range of a given species using geographical and environmental features alone.","To capture a stronger implicit relationship between species, we encode the taxonomic hierarchy of species using a large language model.","This enables range mapping for any taxonomic rank and unseen species without additional supervision.","Further, we propose a novel proximity-aware evaluation metric that enables evaluating species distribution models using any pixel-level representation of ground-truth species range map.","The proposed metric penalizes the predictions of a model based on its proximity to the ground truth.","We describe the effectiveness of our model by systematically evaluating on the task of species range prediction, zero-shot prediction and geo-feature regression against the state-of-the-art.","Results show our model outperforms the strong baselines when trained with a variety of multi-label learning losses."],"url":"http://arxiv.org/abs/2312.08334v1"}
{"created":"2023-12-13 18:04:31","title":"Preparing VVC for Streaming: A Fast Multi-Rate Encoding Approach","abstract":"The integration of advanced video codecs into the streaming pipeline is growing in response to the increasing demand for high quality video content. However, the significant computational demand for advanced codecs like Versatile Video Coding (VVC) poses challenges for service providers, including longer encoding time and higher encoding cost. This challenge becomes even more pronounced in streaming, as the same content needs to be encoded at multiple bitrates (also known as representations) to accommodate different network conditions. To accelerate the encoding process of multiple representations of the same content in VVC, we employ the encoding map of a single representation, known as the reference representation, and utilize its partitioning structure to accelerate the encoding of the remaining representations, referred to as dependent representations. To ensure compatibility with parallel processing, we designate the lowest bitrate representation as the reference representation. The experimental results indicate a substantial improvement in the encoding time for the dependent representations, achieving an average reduction of 40%, while maintaining a minimal average quality drop of only 0.43 in Video Multi-method Assessment Fusion (VMAF). This improvement is observed when utilizing Versatile Video Encoder (VVenC), an open and optimized VVC encoder implementation.","sentences":["The integration of advanced video codecs into the streaming pipeline is growing in response to the increasing demand for high quality video content.","However, the significant computational demand for advanced codecs like Versatile Video Coding (VVC) poses challenges for service providers, including longer encoding time and higher encoding cost.","This challenge becomes even more pronounced in streaming, as the same content needs to be encoded at multiple bitrates (also known as representations) to accommodate different network conditions.","To accelerate the encoding process of multiple representations of the same content in VVC, we employ the encoding map of a single representation, known as the reference representation, and utilize its partitioning structure to accelerate the encoding of the remaining representations, referred to as dependent representations.","To ensure compatibility with parallel processing, we designate the lowest bitrate representation as the reference representation.","The experimental results indicate a substantial improvement in the encoding time for the dependent representations, achieving an average reduction of 40%, while maintaining a minimal average quality drop of only 0.43 in Video Multi-method Assessment Fusion (VMAF).","This improvement is observed when utilizing Versatile Video Encoder (VVenC), an open and optimized VVC encoder implementation."],"url":"http://arxiv.org/abs/2312.08330v1"}
{"created":"2023-12-13 17:50:31","title":"PnPNet: Pull-and-Push Networks for Volumetric Segmentation with Boundary Confusion","abstract":"Precise boundary segmentation of volumetric images is a critical task for image-guided diagnosis and computer-assisted intervention, especially for boundary confusion in clinical practice. However, U-shape networks cannot effectively resolve this challenge due to the lack of boundary shape constraints. Besides, existing methods of refining boundaries overemphasize the slender structure, which results in the overfitting phenomenon due to networks' limited abilities to model tiny objects. In this paper, we reconceptualize the mechanism of boundary generation by encompassing the interaction dynamics with adjacent regions. Moreover, we propose a unified network termed PnPNet to model shape characteristics of the confused boundary region. Core ingredients of PnPNet contain the pushing and pulling branches. Specifically, based on diffusion theory, we devise the semantic difference module (SDM) from the pushing branch to squeeze the boundary region. Explicit and implicit differential information inside SDM significantly boost representation abilities for inter-class boundaries. Additionally, motivated by the K-means algorithm, the class clustering module (CCM) from the pulling branch is introduced to stretch the intersected boundary region. Thus, pushing and pulling branches will shrink and enlarge the boundary uncertainty respectively. They furnish two adversarial forces to promote models to output a more precise delineation of boundaries. We carry out experiments on three challenging public datasets and one in-house dataset, containing three types of boundary confusion in model predictions. Experimental results demonstrate the superiority of PnPNet over other segmentation networks, especially on evaluation metrics of HD and ASSD. Besides, pushing and pulling branches can serve as plug-and-play modules to enhance classic U-shape baseline models. Codes are available.","sentences":["Precise boundary segmentation of volumetric images is a critical task for image-guided diagnosis and computer-assisted intervention, especially for boundary confusion in clinical practice.","However, U-shape networks cannot effectively resolve this challenge due to the lack of boundary shape constraints.","Besides, existing methods of refining boundaries overemphasize the slender structure, which results in the overfitting phenomenon due to networks' limited abilities to model tiny objects.","In this paper, we reconceptualize the mechanism of boundary generation by encompassing the interaction dynamics with adjacent regions.","Moreover, we propose a unified network termed PnPNet to model shape characteristics of the confused boundary region.","Core ingredients of PnPNet contain the pushing and pulling branches.","Specifically, based on diffusion theory, we devise the semantic difference module (SDM) from the pushing branch to squeeze the boundary region.","Explicit and implicit differential information inside SDM significantly boost representation abilities for inter-class boundaries.","Additionally, motivated by the K-means algorithm, the class clustering module (CCM) from the pulling branch is introduced to stretch the intersected boundary region.","Thus, pushing and pulling branches will shrink and enlarge the boundary uncertainty respectively.","They furnish two adversarial forces to promote models to output a more precise delineation of boundaries.","We carry out experiments on three challenging public datasets and one in-house dataset, containing three types of boundary confusion in model predictions.","Experimental results demonstrate the superiority of PnPNet over other segmentation networks, especially on evaluation metrics of HD and ASSD.","Besides, pushing and pulling branches can serve as plug-and-play modules to enhance classic U-shape baseline models.","Codes are available."],"url":"http://arxiv.org/abs/2312.08323v1"}
{"created":"2023-12-13 17:39:44","title":"Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4","abstract":"Dynamic analysis methods effectively identify shelled, wrapped, or obfuscated malware, thereby preventing them from invading computers. As a significant representation of dynamic malware behavior, the API (Application Programming Interface) sequence, comprised of consecutive API calls, has progressively become the dominant feature of dynamic analysis methods. Though there have been numerous deep learning models for malware detection based on API sequences, the quality of API call representations produced by those models is limited. These models cannot generate representations for unknown API calls, which weakens both the detection performance and the generalization. Further, the concept drift phenomenon of API calls is prominent. To tackle these issues, we introduce a prompt engineering-assisted malware dynamic analysis using GPT-4. In this method, GPT-4 is employed to create explanatory text for each API call within the API sequence. Afterward, the pre-trained language model BERT is used to obtain the representation of the text, from which we derive the representation of the API sequence. Theoretically, this proposed method is capable of generating representations for all API calls, excluding the necessity for dataset training during the generation process. Utilizing the representation, a CNN-based detection model is designed to extract the feature. We adopt five benchmark datasets to validate the performance of the proposed model. The experimental results reveal that the proposed detection algorithm performs better than the state-of-the-art method (TextCNN). Specifically, in cross-database experiments and few-shot learning experiments, the proposed model achieves excellent detection performance and almost a 100% recall rate for malware, verifying its superior generalization performance. The code is available at: github.com/yan-scnu/Prompted_Dynamic_Detection.","sentences":["Dynamic analysis methods effectively identify shelled, wrapped, or obfuscated malware, thereby preventing them from invading computers.","As a significant representation of dynamic malware behavior, the API (Application Programming Interface) sequence, comprised of consecutive API calls, has progressively become the dominant feature of dynamic analysis methods.","Though there have been numerous deep learning models for malware detection based on API sequences, the quality of API call representations produced by those models is limited.","These models cannot generate representations for unknown API calls, which weakens both the detection performance and the generalization.","Further, the concept drift phenomenon of API calls is prominent.","To tackle these issues, we introduce a prompt engineering-assisted malware dynamic analysis using GPT-4.","In this method, GPT-4 is employed to create explanatory text for each API call within the API sequence.","Afterward, the pre-trained language model BERT is used to obtain the representation of the text, from which we derive the representation of the API sequence.","Theoretically, this proposed method is capable of generating representations for all API calls, excluding the necessity for dataset training during the generation process.","Utilizing the representation, a CNN-based detection model is designed to extract the feature.","We adopt five benchmark datasets to validate the performance of the proposed model.","The experimental results reveal that the proposed detection algorithm performs better than the state-of-the-art method (TextCNN).","Specifically, in cross-database experiments and few-shot learning experiments, the proposed model achieves excellent detection performance and almost a 100% recall rate for malware, verifying its superior generalization performance.","The code is available at: github.com/yan-scnu/Prompted_Dynamic_Detection."],"url":"http://arxiv.org/abs/2312.08317v1"}
{"created":"2023-12-13 17:27:17","title":"FASTEN: Towards a FAult-tolerant and STorage EfficieNt Cloud: Balancing Between Replication and Deduplication","abstract":"With the surge in cloud storage adoption, enterprises face challenges managing data duplication and exponential data growth. Deduplication mitigates redundancy, yet maintaining redundancy ensures high availability, incurring storage costs. Balancing these aspects is a significant research concern. We propose FASTEN, a distributed cloud storage scheme ensuring efficiency, security, and high availability. FASTEN achieves fault tolerance by dispersing data subsets optimally across servers and maintains redundancy for high availability. Experimental results show FASTEN's effectiveness in fault tolerance, cost reduction, batch auditing, and file and block-level deduplication. It outperforms existing systems with low time complexity, strong fault tolerance, and commendable deduplication performance.","sentences":["With the surge in cloud storage adoption, enterprises face challenges managing data duplication and exponential data growth.","Deduplication mitigates redundancy, yet maintaining redundancy ensures high availability, incurring storage costs.","Balancing these aspects is a significant research concern.","We propose FASTEN, a distributed cloud storage scheme ensuring efficiency, security, and high availability.","FASTEN achieves fault tolerance by dispersing data subsets optimally across servers and maintains redundancy for high availability.","Experimental results show FASTEN's effectiveness in fault tolerance, cost reduction, batch auditing, and file and block-level deduplication.","It outperforms existing systems with low time complexity, strong fault tolerance, and commendable deduplication performance."],"url":"http://arxiv.org/abs/2312.08309v1"}
{"created":"2023-12-13 17:26:30","title":"ConChain: A Scheme for Contention-free and Attack Resilient BlockChain","abstract":"Although blockchains have become widely popular for their use in cryptocurrencies, they are now becoming pervasive as more traditional applications adopt blockchain to ensure data security. Despite being a secured network, blockchains have some tradeoffs such as high latency, low throughput, and transaction failures. One of the core problems behind these is improper management of \"conflicting transactions\", which is also known as \"contention\". When there is a large pool of pending transactions in a blockchain and some of them are conflicting, a situation of contention occurs, and as a result, the latency of the network increases, and a substantial amount of resources are wasted which results in low throughput and transaction failures. In this paper, we proposed ConChain, a novel blockchain scheme that combines transaction parallelism and an intelligent dependency manager to minimize conflicting transactions in blockchain networks as well as improve performance. ConChain is also capable of ensuring proper defense against major attacks due to contention.","sentences":["Although blockchains have become widely popular for their use in cryptocurrencies, they are now becoming pervasive as more traditional applications adopt blockchain to ensure data security.","Despite being a secured network, blockchains have some tradeoffs such as high latency, low throughput, and transaction failures.","One of the core problems behind these is improper management of \"conflicting transactions\", which is also known as \"contention\".","When there is a large pool of pending transactions in a blockchain and some of them are conflicting, a situation of contention occurs, and as a result, the latency of the network increases, and a substantial amount of resources are wasted which results in low throughput and transaction failures.","In this paper, we proposed ConChain, a novel blockchain scheme that combines transaction parallelism and an intelligent dependency manager to minimize conflicting transactions in blockchain networks as well as improve performance.","ConChain is also capable of ensuring proper defense against major attacks due to contention."],"url":"http://arxiv.org/abs/2312.08305v1"}
{"created":"2023-12-13 17:22:19","title":"Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models","abstract":"Toxic content detection is crucial for online services to remove inappropriate content that violates community standards. To automate the detection process, prior works have proposed varieties of machine learning (ML) approaches to train Language Models (LMs) for toxic content detection. However, both their accuracy and transferability across datasets are limited. Recently, Large Language Models (LLMs) have shown promise in toxic content detection due to their superior zero-shot and few-shot in-context learning ability as well as broad transferability on ML tasks. However, efficiently designing prompts for LLMs remains challenging. Moreover, the high run-time cost of LLMs may hinder their deployments in production. To address these challenges, in this work, we propose BD-LLM, a novel and efficient approach to Bootstrapping and Distilling LLMs for toxic content detection. Specifically, we design a novel prompting method named Decision-Tree-of-Thought (DToT) to bootstrap LLMs' detection performance and extract high-quality rationales. DToT can automatically select more fine-grained context to re-prompt LLMs when their responses lack confidence. Additionally, we use the rationales extracted via DToT to fine-tune student LMs. Our experimental results on various datasets demonstrate that DToT can improve the accuracy of LLMs by up to 4.6%. Furthermore, student LMs fine-tuned with rationales extracted via DToT outperform baselines on all datasets with up to 16.9\\% accuracy improvement, while being more than 60x smaller than conventional LLMs. Finally, we observe that student LMs fine-tuned with rationales exhibit better cross-dataset transferability.","sentences":["Toxic content detection is crucial for online services to remove inappropriate content that violates community standards.","To automate the detection process, prior works have proposed varieties of machine learning (ML) approaches to train Language Models (LMs) for toxic content detection.","However, both their accuracy and transferability across datasets are limited.","Recently, Large Language Models (LLMs) have shown promise in toxic content detection due to their superior zero-shot and few-shot in-context learning ability as well as broad transferability on ML tasks.","However, efficiently designing prompts for LLMs remains challenging.","Moreover, the high run-time cost of LLMs may hinder their deployments in production.","To address these challenges, in this work, we propose BD-LLM, a novel and efficient approach to Bootstrapping and Distilling LLMs for toxic content detection.","Specifically, we design a novel prompting method named Decision-Tree-of-Thought (DToT) to bootstrap LLMs' detection performance and extract high-quality rationales.","DToT can automatically select more fine-grained context to re-prompt LLMs when their responses lack confidence.","Additionally, we use the rationales extracted via DToT to fine-tune student LMs.","Our experimental results on various datasets demonstrate that DToT can improve the accuracy of LLMs by up to 4.6%.","Furthermore, student LMs fine-tuned with rationales extracted via DToT outperform baselines on all datasets with up to 16.9\\% accuracy improvement, while being more than 60x smaller than conventional LLMs.","Finally, we observe that student LMs fine-tuned with rationales exhibit better cross-dataset transferability."],"url":"http://arxiv.org/abs/2312.08303v1"}
{"created":"2023-12-13 17:16:57","title":"Design and Control of an Energy Accumulative Hopping Robot","abstract":"Jumping and hopping locomotion are efficient means of traversing unstructured rugged terrain with the former being the focus of roboticists. This focus has led to significant performance and understanding in jumping robots but with limited practical applications as they require significant time between jumps to store energy, thus relegating jumping to a secondary role in locomotion. Hopping locomotion, however, can preserve and transfer energy to subsequent hops without long energy storage periods. Therefore, hopping has the potential to be far more energy efficient and agile than jumping. However, to date, only a single untethered hopping robot exists with limited payload and hopping heights (< 1 meter). This is due to the added design and control complexity inherent in the requirements to input energy during dynamic locomotion and control the orientation of the system throughout the hopping cycle, resulting in low energy input and control torques; a redevelopment from basic principles is necessary to advance the capabilities of hopping robots. Here we report hopping robot design principles for efficient and robust systems with high energy input and control torques that are validated through analytical, simulation, and experimental results. The resulting robot (MultiMo-MHR) can hop nearly 4 meters (> 6 times the current state-of-the-art); and is only limited by the impact mechanics and not energy input. The results also directly contradict a recent work that concluded hopping with aerodynamic energy input would be less efficient than flight for hops greater than 0.4 meters.","sentences":["Jumping and hopping locomotion are efficient means of traversing unstructured rugged terrain with the former being the focus of roboticists.","This focus has led to significant performance and understanding in jumping robots but with limited practical applications as they require significant time between jumps to store energy, thus relegating jumping to a secondary role in locomotion.","Hopping locomotion, however, can preserve and transfer energy to subsequent hops without long energy storage periods.","Therefore, hopping has the potential to be far more energy efficient and agile than jumping.","However, to date, only a single untethered hopping robot exists with limited payload and hopping heights (< 1 meter).","This is due to the added design and control complexity inherent in the requirements to input energy during dynamic locomotion and control the orientation of the system throughout the hopping cycle, resulting in low energy input and control torques; a redevelopment from basic principles is necessary to advance the capabilities of hopping robots.","Here we report hopping robot design principles for efficient and robust systems with high energy input and control torques that are validated through analytical, simulation, and experimental results.","The resulting robot (MultiMo-MHR) can hop nearly 4 meters (> 6 times the current state-of-the-art); and is only limited by the impact mechanics and not energy input.","The results also directly contradict a recent work that concluded hopping with aerodynamic energy input would be less efficient than flight for hops greater than 0.4 meters."],"url":"http://arxiv.org/abs/2312.08301v1"}
{"created":"2023-12-13 17:15:12","title":"Conceptualizing Suicidal Behavior: Utilizing Explanations of Predicted Outcomes to Analyze Longitudinal Social Media Data","abstract":"The COVID-19 pandemic has escalated mental health crises worldwide, with social isolation and economic instability contributing to a rise in suicidal behavior. Suicide can result from social factors such as shame, abuse, abandonment, and mental health conditions like depression, Post-Traumatic Stress Disorder (PTSD), Attention-Deficit/Hyperactivity Disorder (ADHD), anxiety disorders, and bipolar disorders. As these conditions develop, signs of suicidal ideation may manifest in social media interactions. Analyzing social media data using artificial intelligence (AI) techniques can help identify patterns of suicidal behavior, providing invaluable insights for suicide prevention agencies, professionals, and broader community awareness initiatives. Machine learning algorithms for this purpose require large volumes of accurately labeled data. Previous research has not fully explored the potential of incorporating explanations in analyzing and labeling longitudinal social media data. In this study, we employed a model explanation method, Layer Integrated Gradients, on top of a fine-tuned state-of-the-art language model, to assign each token from Reddit users' posts an attribution score for predicting suicidal ideation. By extracting and analyzing attributions of tokens from the data, we propose a methodology for preliminary screening of social media posts for suicidal ideation without using large language models during inference.","sentences":["The COVID-19 pandemic has escalated mental health crises worldwide, with social isolation and economic instability contributing to a rise in suicidal behavior.","Suicide can result from social factors such as shame, abuse, abandonment, and mental health conditions like depression, Post-Traumatic Stress Disorder (PTSD), Attention-Deficit/Hyperactivity Disorder (ADHD), anxiety disorders, and bipolar disorders.","As these conditions develop, signs of suicidal ideation may manifest in social media interactions.","Analyzing social media data using artificial intelligence (AI) techniques can help identify patterns of suicidal behavior, providing invaluable insights for suicide prevention agencies, professionals, and broader community awareness initiatives.","Machine learning algorithms for this purpose require large volumes of accurately labeled data.","Previous research has not fully explored the potential of incorporating explanations in analyzing and labeling longitudinal social media data.","In this study, we employed a model explanation method, Layer Integrated Gradients, on top of a fine-tuned state-of-the-art language model, to assign each token from Reddit users' posts an attribution score for predicting suicidal ideation.","By extracting and analyzing attributions of tokens from the data, we propose a methodology for preliminary screening of social media posts for suicidal ideation without using large language models during inference."],"url":"http://arxiv.org/abs/2312.08299v1"}
{"created":"2023-12-13 17:13:08","title":"Venn: Resource Management Across Federated Learning Jobs","abstract":"In recent years, federated learning (FL) has emerged as a promising approach for machine learning (ML) and data science across distributed edge devices. With the increasing popularity of FL, resource contention between multiple FL jobs training on the same device population is increasing as well. Scheduling edge resources among multiple FL jobs is different from GPU scheduling for cloud ML because of the ephemeral nature and planetary scale of participating devices as well as the overlapping resource requirements of diverse FL jobs. Existing resource managers for FL jobs opt for random assignment of devices to FL jobs for simplicity and scalability, which leads to poor performance. In this paper, we present Venn, an FL resource manager, that efficiently schedules ephemeral, heterogeneous devices among many FL jobs, with the goal of reducing their average job completion time (JCT). Venn formulates the Intersection Resource Scheduling (IRS) problem to identify complex resource contention among multiple FL jobs. Then, Venn proposes a contention-aware scheduling heuristic to minimize the average scheduling delay. Furthermore, it proposes a resource-aware device-to-job matching heuristic that focuses on optimizing response collection time by mitigating stragglers. Our evaluation shows that, compared to the state-of-the-art FL resource managers, Venn improves the average JCT by up to 1.88X.","sentences":["In recent years, federated learning (FL) has emerged as a promising approach for machine learning (ML) and data science across distributed edge devices.","With the increasing popularity of FL, resource contention between multiple FL jobs training on the same device population is increasing as well.","Scheduling edge resources among multiple FL jobs is different from GPU scheduling for cloud ML because of the ephemeral nature and planetary scale of participating devices as well as the overlapping resource requirements of diverse FL jobs.","Existing resource managers for FL jobs opt for random assignment of devices to FL jobs for simplicity and scalability, which leads to poor performance.","In this paper, we present Venn, an FL resource manager, that efficiently schedules ephemeral, heterogeneous devices among many FL jobs, with the goal of reducing their average job completion time (JCT).","Venn formulates the Intersection Resource Scheduling (IRS) problem to identify complex resource contention among multiple FL jobs.","Then, Venn proposes a contention-aware scheduling heuristic to minimize the average scheduling delay.","Furthermore, it proposes a resource-aware device-to-job matching heuristic that focuses on optimizing response collection time by mitigating stragglers.","Our evaluation shows that, compared to the state-of-the-art FL resource managers, Venn improves the average JCT by up to 1.88X."],"url":"http://arxiv.org/abs/2312.08298v1"}
{"created":"2023-12-13 17:08:38","title":"VQ-HPS: Human Pose and Shape Estimation in a Vector-Quantized Latent Space","abstract":"Human Pose and Shape Estimation (HPSE) from RGB images can be broadly categorized into two main groups: parametric and non-parametric approaches. Parametric techniques leverage a low-dimensional statistical body model for realistic results, whereas recent non-parametric methods achieve higher precision by directly regressing the 3D coordinates of the human body. Despite their strengths, both approaches face limitations: the parameters of statistical body models pose challenges as regression targets, and predicting 3D coordinates introduces computational complexities and issues related to smoothness. In this work, we take a novel approach to address the HPSE problem. We introduce a unique method involving a low-dimensional discrete latent representation of the human mesh, framing HPSE as a classification task. Instead of predicting body model parameters or 3D vertex coordinates, our focus is on forecasting the proposed discrete latent representation, which can be decoded into a registered human mesh. This innovative paradigm offers two key advantages: firstly, predicting a low-dimensional discrete representation confines our predictions to the space of anthropomorphic poses and shapes; secondly, by framing the problem as a classification task, we can harness the discriminative power inherent in neural networks. Our proposed model, VQ-HPS, a transformer-based architecture, forecasts the discrete latent representation of the mesh, trained through minimizing a cross-entropy loss. Our results demonstrate that VQ-HPS outperforms the current state-of-the-art non-parametric approaches while yielding results as realistic as those produced by parametric methods. This highlights the significant potential of the classification approach for HPSE.","sentences":["Human Pose and Shape Estimation (HPSE) from RGB images can be broadly categorized into two main groups: parametric and non-parametric approaches.","Parametric techniques leverage a low-dimensional statistical body model for realistic results, whereas recent non-parametric methods achieve higher precision by directly regressing the 3D coordinates of the human body.","Despite their strengths, both approaches face limitations: the parameters of statistical body models pose challenges as regression targets, and predicting 3D coordinates introduces computational complexities and issues related to smoothness.","In this work, we take a novel approach to address the HPSE problem.","We introduce a unique method involving a low-dimensional discrete latent representation of the human mesh, framing HPSE as a classification task.","Instead of predicting body model parameters or 3D vertex coordinates, our focus is on forecasting the proposed discrete latent representation, which can be decoded into a registered human mesh.","This innovative paradigm offers two key advantages: firstly, predicting a low-dimensional discrete representation confines our predictions to the space of anthropomorphic poses and shapes; secondly, by framing the problem as a classification task, we can harness the discriminative power inherent in neural networks.","Our proposed model, VQ-HPS, a transformer-based architecture, forecasts the discrete latent representation of the mesh, trained through minimizing a cross-entropy loss.","Our results demonstrate that VQ-HPS outperforms the current state-of-the-art non-parametric approaches while yielding results as realistic as those produced by parametric methods.","This highlights the significant potential of the classification approach for HPSE."],"url":"http://arxiv.org/abs/2312.08291v1"}
{"created":"2023-12-13 17:04:16","title":"Hybrid Sample Synthesis-based Debiasing of Classifier in Limited Data Setting","abstract":"Deep learning models are known to suffer from the problem of bias, and researchers have been exploring methods to address this issue. However, most of these methods require prior knowledge of the bias and are not always practical. In this paper, we focus on a more practical setting with no prior information about the bias. Generally, in this setting, there are a large number of bias-aligned samples that cause the model to produce biased predictions and a few bias-conflicting samples that do not conform to the bias. If the training data is limited, the influence of the bias-aligned samples may become even stronger on the model predictions, and we experimentally demonstrate that existing debiasing techniques suffer severely in such cases. In this paper, we examine the effects of unknown bias in small dataset regimes and present a novel approach to mitigate this issue. The proposed approach directly addresses the issue of the extremely low occurrence of bias-conflicting samples in limited data settings through the synthesis of hybrid samples that can be used to reduce the effect of bias. We perform extensive experiments on several benchmark datasets and experimentally demonstrate the effectiveness of our proposed approach in addressing any unknown bias in the presence of limited data. Specifically, our approach outperforms the vanilla, LfF, LDD, and DebiAN debiasing methods by absolute margins of 10.39%, 9.08%, 8.07%, and 9.67% when only 10% of the Corrupted CIFAR-10 Type 1 dataset is available with a bias-conflicting sample ratio of 0.05.","sentences":["Deep learning models are known to suffer from the problem of bias, and researchers have been exploring methods to address this issue.","However, most of these methods require prior knowledge of the bias and are not always practical.","In this paper, we focus on a more practical setting with no prior information about the bias.","Generally, in this setting, there are a large number of bias-aligned samples that cause the model to produce biased predictions and a few bias-conflicting samples that do not conform to the bias.","If the training data is limited, the influence of the bias-aligned samples may become even stronger on the model predictions, and we experimentally demonstrate that existing debiasing techniques suffer severely in such cases.","In this paper, we examine the effects of unknown bias in small dataset regimes and present a novel approach to mitigate this issue.","The proposed approach directly addresses the issue of the extremely low occurrence of bias-conflicting samples in limited data settings through the synthesis of hybrid samples that can be used to reduce the effect of bias.","We perform extensive experiments on several benchmark datasets and experimentally demonstrate the effectiveness of our proposed approach in addressing any unknown bias in the presence of limited data.","Specifically, our approach outperforms the vanilla, LfF, LDD, and DebiAN debiasing methods by absolute margins of 10.39%, 9.08%, 8.07%, and 9.67% when only 10% of the Corrupted CIFAR-10 Type 1 dataset is available with a bias-conflicting sample ratio of 0.05."],"url":"http://arxiv.org/abs/2312.08288v1"}
{"created":"2023-12-13 17:04:09","title":"On the verification of Embeddings using Hybrid Markov Logic","abstract":"The standard approach to verify representations learned by Deep Neural Networks is to use them in specific tasks such as classification or regression, and measure their performance based on accuracy in such tasks. However, in many cases, we would want to verify more complex properties of a learned representation. To do this, we propose a framework based on a probabilistic first-order language, namely, Hybrid Markov Logic Networks (HMLNs) where we specify properties over embeddings mixed with symbolic domain knowledge. We present an approach to learn parameters for the properties within this framework. Further, we develop a verification method to test embeddings in this framework by encoding this task as a Mixed Integer Linear Program for which we can leverage existing state-of-the-art solvers. We illustrate verification in Graph Neural Networks, Deep Knowledge Tracing and Intelligent Tutoring Systems to demonstrate the generality of our approach.","sentences":["The standard approach to verify representations learned by Deep Neural Networks is to use them in specific tasks such as classification or regression, and measure their performance based on accuracy in such tasks.","However, in many cases, we would want to verify more complex properties of a learned representation.","To do this, we propose a framework based on a probabilistic first-order language, namely, Hybrid Markov Logic Networks (HMLNs) where we specify properties over embeddings mixed with symbolic domain knowledge.","We present an approach to learn parameters for the properties within this framework.","Further, we develop a verification method to test embeddings in this framework by encoding this task as a Mixed Integer Linear Program for which we can leverage existing state-of-the-art solvers.","We illustrate verification in Graph Neural Networks, Deep Knowledge Tracing and Intelligent Tutoring Systems to demonstrate the generality of our approach."],"url":"http://arxiv.org/abs/2312.08287v1"}
{"created":"2023-12-13 16:57:31","title":"Prompting LLMs with content plans to enhance the summarization of scientific articles","abstract":"This paper presents novel prompting techniques to improve the performance of automatic summarization systems for scientific articles. Scientific article summarization is highly challenging due to the length and complexity of these documents. We conceive, implement, and evaluate prompting techniques that provide additional contextual information to guide summarization systems. Specifically, we feed summarizers with lists of key terms extracted from articles, such as author keywords or automatically generated keywords. Our techniques are tested with various summarization models and input texts. Results show performance gains, especially for smaller models summarizing sections separately. This evidences that prompting is a promising approach to overcoming the limitations of less powerful systems. Our findings introduce a new research direction of using prompts to aid smaller models.","sentences":["This paper presents novel prompting techniques to improve the performance of automatic summarization systems for scientific articles.","Scientific article summarization is highly challenging due to the length and complexity of these documents.","We conceive, implement, and evaluate prompting techniques that provide additional contextual information to guide summarization systems.","Specifically, we feed summarizers with lists of key terms extracted from articles, such as author keywords or automatically generated keywords.","Our techniques are tested with various summarization models and input texts.","Results show performance gains, especially for smaller models summarizing sections separately.","This evidences that prompting is a promising approach to overcoming the limitations of less powerful systems.","Our findings introduce a new research direction of using prompts to aid smaller models."],"url":"http://arxiv.org/abs/2312.08282v1"}
{"created":"2023-12-13 16:43:41","title":"High-throughput Biomedical Relation Extraction for Semi-Structured Web Articles Empowered by Large Language Models","abstract":"Objective: To develop a high-throughput biomedical relation extraction system that takes advantage of the large language models' (LLMs) reading comprehension ability and biomedical world knowledge in a scalable and evidential manner. Methods: We formulate the relation extraction task as a simple binary classification problem for large language models such as ChatGPT. Specifically, LLMs make the decision based on the external corpus and its world knowledge, giving the reason for the judgment to factual verification. This method is tailored for semi-structured web articles, wherein we designate the main title as the tail entity and explicitly incorporate it into the context, and the potential head entities are matched based on a biomedical thesaurus. Moreover, lengthy contents are sliced into text chunks, embedded, and retrieved with additional embedding models, ensuring compatibility with the context window size constraints of available open-source LLMs. Results: Using an open-source LLM, we extracted 304315 relation triplets of three distinct relation types from four reputable biomedical websites. To assess the efficacy of the basic pipeline employed for biomedical relation extraction, we curated a benchmark dataset annotated by a medical expert. Evaluation results indicate that the pipeline exhibits performance comparable to that of GPT-4. Case studies further illuminate challenges faced by contemporary LLMs in the context of biomedical relation extraction for semi-structured web articles. Conclusion: The proposed method has demonstrated its effectiveness in leveraging the strengths of LLMs for high-throughput biomedical relation extraction. Its adaptability is evident, as it can be seamlessly extended to diverse semi-structured biomedical websites, facilitating the extraction of various types of biomedical relations with ease.","sentences":["Objective: To develop a high-throughput biomedical relation extraction system that takes advantage of the large language models' (LLMs) reading comprehension ability and biomedical world knowledge in a scalable and evidential manner.","Methods: We formulate the relation extraction task as a simple binary classification problem for large language models such as ChatGPT.","Specifically, LLMs make the decision based on the external corpus and its world knowledge, giving the reason for the judgment to factual verification.","This method is tailored for semi-structured web articles, wherein we designate the main title as the tail entity and explicitly incorporate it into the context, and the potential head entities are matched based on a biomedical thesaurus.","Moreover, lengthy contents are sliced into text chunks, embedded, and retrieved with additional embedding models, ensuring compatibility with the context window size constraints of available open-source LLMs.","Results: Using an open-source LLM, we extracted 304315 relation triplets of three distinct relation types from four reputable biomedical websites.","To assess the efficacy of the basic pipeline employed for biomedical relation extraction, we curated a benchmark dataset annotated by a medical expert.","Evaluation results indicate that the pipeline exhibits performance comparable to that of GPT-4.","Case studies further illuminate challenges faced by contemporary LLMs in the context of biomedical relation extraction for semi-structured web articles.","Conclusion: The proposed method has demonstrated its effectiveness in leveraging the strengths of LLMs for high-throughput biomedical relation extraction.","Its adaptability is evident, as it can be seamlessly extended to diverse semi-structured biomedical websites, facilitating the extraction of various types of biomedical relations with ease."],"url":"http://arxiv.org/abs/2312.08274v1"}
{"created":"2023-12-13 16:30:00","title":"Efficient Multi-Object Pose Estimation using Multi-Resolution Deformable Attention and Query Aggregation","abstract":"Object pose estimation is a long-standing problem in computer vision. Recently, attention-based vision transformer models have achieved state-of-the-art results in many computer vision applications. Exploiting the permutation-invariant nature of the attention mechanism, a family of vision transformer models formulate multi-object pose estimation as a set prediction problem. However, existing vision transformer models for multi-object pose estimation rely exclusively on the attention mechanism. Convolutional neural networks, on the other hand, hard-wire various inductive biases into their architecture. In this paper, we investigate incorporating inductive biases in vision transformer models for multi-object pose estimation, which facilitates learning long-range dependencies while circumventing the costly global attention. In particular, we use multi-resolution deformable attention, where the attention operation is performed only between a few deformed reference points. Furthermore, we propose a query aggregation mechanism that enables increasing the number of object queries without increasing the computational complexity. We evaluate the proposed model on the challenging YCB-Video dataset and report state-of-the-art results.","sentences":["Object pose estimation is a long-standing problem in computer vision.","Recently, attention-based vision transformer models have achieved state-of-the-art results in many computer vision applications.","Exploiting the permutation-invariant nature of the attention mechanism, a family of vision transformer models formulate multi-object pose estimation as a set prediction problem.","However, existing vision transformer models for multi-object pose estimation rely exclusively on the attention mechanism.","Convolutional neural networks, on the other hand, hard-wire various inductive biases into their architecture.","In this paper, we investigate incorporating inductive biases in vision transformer models for multi-object pose estimation, which facilitates learning long-range dependencies while circumventing the costly global attention.","In particular, we use multi-resolution deformable attention, where the attention operation is performed only between a few deformed reference points.","Furthermore, we propose a query aggregation mechanism that enables increasing the number of object queries without increasing the computational complexity.","We evaluate the proposed model on the challenging YCB-Video dataset and report state-of-the-art results."],"url":"http://arxiv.org/abs/2312.08268v1"}
{"created":"2023-12-13 16:18:45","title":"A Compact and Semantic Latent Space for Disentangled and Controllable Image Editing","abstract":"Recent advances in the field of generative models and in particular generative adversarial networks (GANs) have lead to substantial progress for controlled image editing, especially compared with the pre-deep learning era. Despite their powerful ability to apply realistic modifications to an image, these methods often lack properties like disentanglement (the capacity to edit attributes independently). In this paper, we propose an auto-encoder which re-organizes the latent space of StyleGAN, so that each attribute which we wish to edit corresponds to an axis of the new latent space, and furthermore that the latent axes are decorrelated, encouraging disentanglement. We work in a compressed version of the latent space, using Principal Component Analysis, meaning that the parameter complexity of our autoencoder is reduced, leading to short training times ($\\sim$ 45 mins). Qualitative and quantitative results demonstrate the editing capabilities of our approach, with greater disentanglement than competing methods, while maintaining fidelity to the original image with respect to identity. Our autoencoder architecture simple and straightforward, facilitating implementation.","sentences":["Recent advances in the field of generative models and in particular generative adversarial networks (GANs) have lead to substantial progress for controlled image editing, especially compared with the pre-deep learning era.","Despite their powerful ability to apply realistic modifications to an image, these methods often lack properties like disentanglement (the capacity to edit attributes independently).","In this paper, we propose an auto-encoder which re-organizes the latent space of StyleGAN, so that each attribute which we wish to edit corresponds to an axis of the new latent space, and furthermore that the latent axes are decorrelated, encouraging disentanglement.","We work in a compressed version of the latent space, using Principal Component Analysis, meaning that the parameter complexity of our autoencoder is reduced, leading to short training times ($\\sim$ 45 mins).","Qualitative and quantitative results demonstrate the editing capabilities of our approach, with greater disentanglement than competing methods, while maintaining fidelity to the original image with respect to identity.","Our autoencoder architecture simple and straightforward, facilitating implementation."],"url":"http://arxiv.org/abs/2312.08256v1"}
{"created":"2023-12-13 16:14:04","title":"Enhancing Robot Program Synthesis Through Environmental Context","abstract":"Program synthesis aims to automatically generate an executable program that conforms to the given specification. Recent advancements have demonstrated that deep neural methodologies and large-scale pretrained language models are highly proficient in capturing program semantics. For robot programming, prior works have facilitated program synthesis by incorporating global environments. However, the assumption of acquiring a comprehensive understanding of the entire environment is often excessively challenging to achieve. In this work, we present a framework that learns to synthesize a program by rectifying potentially erroneous code segments, with the aid of partially observed environments. To tackle the issue of inadequate attention to partial observations, we propose to first learn an environment embedding space that can implicitly evaluate the impacts of each program token based on the precondition. Furthermore, by employing a graph structure, the model can aggregate both environmental and syntactic information flow and furnish smooth program rectification guidance. Extensive experimental evaluations and ablation studies on the partially observed VizDoom domain authenticate that our method offers superior generalization capability across various tasks and greater robustness when encountering noises.","sentences":["Program synthesis aims to automatically generate an executable program that conforms to the given specification.","Recent advancements have demonstrated that deep neural methodologies and large-scale pretrained language models are highly proficient in capturing program semantics.","For robot programming, prior works have facilitated program synthesis by incorporating global environments.","However, the assumption of acquiring a comprehensive understanding of the entire environment is often excessively challenging to achieve.","In this work, we present a framework that learns to synthesize a program by rectifying potentially erroneous code segments, with the aid of partially observed environments.","To tackle the issue of inadequate attention to partial observations, we propose to first learn an environment embedding space that can implicitly evaluate the impacts of each program token based on the precondition.","Furthermore, by employing a graph structure, the model can aggregate both environmental and syntactic information flow and furnish smooth program rectification guidance.","Extensive experimental evaluations and ablation studies on the partially observed VizDoom domain authenticate that our method offers superior generalization capability across various tasks and greater robustness when encountering noises."],"url":"http://arxiv.org/abs/2312.08250v1"}
{"created":"2023-12-13 16:13:23","title":"A Survey of Generative AI for Intelligent Transportation Systems","abstract":"Intelligent transportation systems play a crucial role in modern traffic management and optimization, greatly improving traffic efficiency and safety. With the rapid development of generative artificial intelligence (Generative AI) technologies in the fields of image generation and natural language processing, generative AI has also played a crucial role in addressing key issues in intelligent transportation systems, such as data sparsity, difficulty in observing abnormal scenarios, and in modeling data uncertainty. In this review, we systematically investigate the relevant literature on generative AI techniques in addressing key issues in different types of tasks in intelligent transportation systems. First, we introduce the principles of different generative AI techniques, and their potential applications. Then, we classify tasks in intelligent transportation systems into four types: traffic perception, traffic prediction, traffic simulation, and traffic decision-making. We systematically illustrate how generative AI techniques addresses key issues in these four different types of tasks. Finally, we summarize the challenges faced in applying generative AI to intelligent transportation systems, and discuss future research directions based on different application scenarios.","sentences":["Intelligent transportation systems play a crucial role in modern traffic management and optimization, greatly improving traffic efficiency and safety.","With the rapid development of generative artificial intelligence (Generative AI) technologies in the fields of image generation and natural language processing, generative AI has also played a crucial role in addressing key issues in intelligent transportation systems, such as data sparsity, difficulty in observing abnormal scenarios, and in modeling data uncertainty.","In this review, we systematically investigate the relevant literature on generative AI techniques in addressing key issues in different types of tasks in intelligent transportation systems.","First, we introduce the principles of different generative AI techniques, and their potential applications.","Then, we classify tasks in intelligent transportation systems into four types: traffic perception, traffic prediction, traffic simulation, and traffic decision-making.","We systematically illustrate how generative AI techniques addresses key issues in these four different types of tasks.","Finally, we summarize the challenges faced in applying generative AI to intelligent transportation systems, and discuss future research directions based on different application scenarios."],"url":"http://arxiv.org/abs/2312.08248v1"}
{"created":"2023-12-13 16:07:35","title":"Combinatorial Stationary Prophet Inequalities","abstract":"Numerous recent papers have studied the tension between thickening and clearing a market in (uncertain, online) long-time horizon Markovian settings. In particular, (Aouad and Sarita{\\c{c}} EC'20, Collina et al. WINE'20, Kessel et al. EC'22) studied what the latter referred to as the Stationary Prophet Inequality Problem, due to its similarity to the classic finite-time horizon prophet inequality problem. These works all consider unit-demand buyers. Mirroring the long line of work on the classic prophet inequality problem subject to combinatorial constraints, we initiate the study of the stationary prophet inequality problem subject to combinatorially-constrained buyers.   Our results can be summarized succinctly as unearthing an algorithmic connection between contention resolution schemes (CRS) and stationary prophet inequalities. While the classic prophet inequality problem has a tight connection to online CRS (Feldman et al. SODA'16, Lee and Singla ESA'18), we show that for the stationary prophet inequality problem, offline CRS play a similarly central role. We show that, up to small constant factors, the best (ex-ante) competitive ratio achievable for the combinatorial prophet inequality equals the best possible balancedness achievable by offline CRS for the same combinatorial constraints.","sentences":["Numerous recent papers have studied the tension between thickening and clearing a market in (uncertain, online) long-time horizon Markovian settings.","In particular, (Aouad and Sarita{\\c{c}} EC'20, Collina et al. WINE'20, Kessel et al. EC'22) studied what the latter referred to as the Stationary Prophet Inequality Problem, due to its similarity to the classic finite-time horizon prophet inequality problem.","These works all consider unit-demand buyers.","Mirroring the long line of work on the classic prophet inequality problem subject to combinatorial constraints, we initiate the study of the stationary prophet inequality problem subject to combinatorially-constrained buyers.   ","Our results can be summarized succinctly as unearthing an algorithmic connection between contention resolution schemes (CRS) and stationary prophet inequalities.","While the classic prophet inequality problem has a tight connection to online CRS (Feldman et al. SODA'16, Lee and Singla ESA'18), we show that for the stationary prophet inequality problem, offline CRS play a similarly central role.","We show that, up to small constant factors, the best (ex-ante) competitive ratio achievable for the combinatorial prophet inequality equals the best possible balancedness achievable by offline CRS for the same combinatorial constraints."],"url":"http://arxiv.org/abs/2312.08245v1"}
{"created":"2023-12-13 16:01:50","title":"CenterGrasp: Object-Aware Implicit Representation Learning for Simultaneous Shape Reconstruction and 6-DoF Grasp Estimation","abstract":"Reliable object grasping is a crucial capability for autonomous robots. However, many existing grasping approaches focus on general clutter removal without explicitly modeling objects and thus only relying on the visible local geometry. We introduce CenterGrasp, a novel framework that combines object awareness and holistic grasping. CenterGrasp learns a general object prior by encoding shapes and valid grasps in a continuous latent space. It consists of an RGB-D image encoder that leverages recent advances to detect objects and infer their pose and latent code, and a decoder to predict shape and grasps for each object in the scene. We perform extensive experiments on simulated as well as real-world cluttered scenes and demonstrate strong scene reconstruction and 6-DoF grasp-pose estimation performance. Compared to the state of the art, CenterGrasp achieves an improvement of 38.5 mm in shape reconstruction and 33 percentage points on average in grasp success. We make the code and trained models publicly available at http://centergrasp.cs.uni-freiburg.de.","sentences":["Reliable object grasping is a crucial capability for autonomous robots.","However, many existing grasping approaches focus on general clutter removal without explicitly modeling objects and thus only relying on the visible local geometry.","We introduce CenterGrasp, a novel framework that combines object awareness and holistic grasping.","CenterGrasp learns a general object prior by encoding shapes and valid grasps in a continuous latent space.","It consists of an RGB-D image encoder that leverages recent advances to detect objects and infer their pose and latent code, and a decoder to predict shape and grasps for each object in the scene.","We perform extensive experiments on simulated as well as real-world cluttered scenes and demonstrate strong scene reconstruction and 6-DoF grasp-pose estimation performance.","Compared to the state of the art, CenterGrasp achieves an improvement of 38.5 mm in shape reconstruction and 33 percentage points on average in grasp success.","We make the code and trained models publicly available at http://centergrasp.cs.uni-freiburg.de."],"url":"http://arxiv.org/abs/2312.08240v1"}
{"created":"2023-12-13 15:58:40","title":"From Brussels Effect to Gravity Assists: Understanding the Evolution of the GDPR-Inspired Personal Information Protection Law in China","abstract":"This paper explores the evolution of China's Personal Information Protection Law (PIPL) and situates it within the context of global data protection development. It draws inspiration from the theory of 'Brussels Effect' and its precedents, that describes the extraterritorial influence of EU regulations. Our objective is not to provide a commentary on China's legal development but to illuminate the intricate dynamics between the Chinese law and the EU's GDPR. It is argued that the trajectory of China's Personal Information Protection Law calls into question the applicability of the Brussels Effect: while the GDPR's imprint on the PIPL is evident, a deeper analysis unveils China's nuanced, non-linear adoption that diverges from many assumptions of the Brussels Effect and similar theories. The evolution of the GDPR-inspired PIPL is not as a straightforward outcome of the Brussels Effect but as a nuanced, intricate interplay of external influence and domestic dynamics. We introduce a complementary theory of 'gravity assist' which portrays China's strategic instrumentalisation of the GDPR as a template to shape its unique data protection landscape. Our conceptual framework highlights how China navigates through a patchwork of internal considerations, international standards, and strategic choices, ultimately sculpting a data protection regime that has a similar appearance to the GDPR but aligns with its distinct political, cultural and legal landscape. This reveals much about how China takes in the foundational premises of data protection that are inherently built in Europe's cherishment of the rule of law, democracy and human rights on the one hand, and the evaluation of data protection as a fundamental right.","sentences":["This paper explores the evolution of China's Personal Information Protection Law (PIPL) and situates it within the context of global data protection development.","It draws inspiration from the theory of 'Brussels Effect' and its precedents, that describes the extraterritorial influence of EU regulations.","Our objective is not to provide a commentary on China's legal development but to illuminate the intricate dynamics between the Chinese law and the EU's GDPR.","It is argued that the trajectory of China's Personal Information Protection Law calls into question the applicability of the Brussels Effect: while the GDPR's imprint on the PIPL is evident, a deeper analysis unveils China's nuanced, non-linear adoption that diverges from many assumptions of the Brussels Effect and similar theories.","The evolution of the GDPR-inspired PIPL is not as a straightforward outcome of the Brussels Effect but as a nuanced, intricate interplay of external influence and domestic dynamics.","We introduce a complementary theory of 'gravity assist' which portrays China's strategic instrumentalisation of the GDPR as a template to shape its unique data protection landscape.","Our conceptual framework highlights how China navigates through a patchwork of internal considerations, international standards, and strategic choices, ultimately sculpting a data protection regime that has a similar appearance to the GDPR but aligns with its distinct political, cultural and legal landscape.","This reveals much about how China takes in the foundational premises of data protection that are inherently built in Europe's cherishment of the rule of law, democracy and human rights on the one hand, and the evaluation of data protection as a fundamental right."],"url":"http://arxiv.org/abs/2312.08237v1"}
{"created":"2023-12-13 15:57:06","title":"Analysis of Psychographic Indicators via LIWC and Their Correlation with CTR for Instagram Ads","abstract":"The online advertising industry continues to grow and accounts for over 40% of global advertising spending. Online display advertising consists of images and text, and advertisers maximize sales revenue by contacting consumers through advertisements and encouraging them to make purchases. In today's society, where products are becoming more homogenized and needs are diversifying, appealing to consumer psychology through advertisements is becoming increasingly important. However, it is not sufficiently clear what kind of appeal influences consumer psychology. In this study, we quantified the appeal of the text in advertisements for health products and cosmetics, which were actually delivered in Instagram advertisements (one of display advertisements), by applying linguistic inquiry and word count (LIWC). The correlation between click-through rate (CTR) and the text was analyzed. The results showed that negative appeals that arouse consumer anxiety and a sense of crisis were related to CTR.","sentences":["The online advertising industry continues to grow and accounts for over 40% of global advertising spending.","Online display advertising consists of images and text, and advertisers maximize sales revenue by contacting consumers through advertisements and encouraging them to make purchases.","In today's society, where products are becoming more homogenized and needs are diversifying, appealing to consumer psychology through advertisements is becoming increasingly important.","However, it is not sufficiently clear what kind of appeal influences consumer psychology.","In this study, we quantified the appeal of the text in advertisements for health products and cosmetics, which were actually delivered in Instagram advertisements (one of display advertisements), by applying linguistic inquiry and word count (LIWC).","The correlation between click-through rate (CTR) and the text was analyzed.","The results showed that negative appeals that arouse consumer anxiety and a sense of crisis were related to CTR."],"url":"http://arxiv.org/abs/2312.08235v1"}
{"created":"2023-12-13 15:56:24","title":"Beyond the Label Itself: Latent Labels Enhance Semi-supervised Point Cloud Panoptic Segmentation","abstract":"As the exorbitant expense of labeling autopilot datasets and the growing trend of utilizing unlabeled data, semi-supervised segmentation on point clouds becomes increasingly imperative. Intuitively, finding out more ``unspoken words'' (i.e., latent instance information) beyond the label itself should be helpful to improve performance. In this paper, we discover two types of latent labels behind the displayed label embedded in LiDAR and image data. First, in the LiDAR Branch, we propose a novel augmentation, Cylinder-Mix, which is able to augment more yet reliable samples for training. Second, in the Image Branch, we propose the Instance Position-scale Learning (IPSL) Module to learn and fuse the information of instance position and scale, which is from a 2D pre-trained detector and a type of latent label obtained from 3D to 2D projection. Finally, the two latent labels are embedded into the multi-modal panoptic segmentation network. The ablation of the IPSL module demonstrates its robust adaptability, and the experiments evaluated on SemanticKITTI and nuScenes demonstrate that our model outperforms the state-of-the-art method, LaserMix.","sentences":["As the exorbitant expense of labeling autopilot datasets and the growing trend of utilizing unlabeled data, semi-supervised segmentation on point clouds becomes increasingly imperative.","Intuitively, finding out more ``unspoken words'' (i.e., latent instance information) beyond the label itself should be helpful to improve performance.","In this paper, we discover two types of latent labels behind the displayed label embedded in LiDAR and image data.","First, in the LiDAR Branch, we propose a novel augmentation, Cylinder-Mix, which is able to augment more yet reliable samples for training.","Second, in the Image Branch, we propose the Instance Position-scale Learning (IPSL) Module to learn and fuse the information of instance position and scale, which is from a 2D pre-trained detector and a type of latent label obtained from 3D to 2D projection.","Finally, the two latent labels are embedded into the multi-modal panoptic segmentation network.","The ablation of the IPSL module demonstrates its robust adaptability, and the experiments evaluated on SemanticKITTI and nuScenes demonstrate that our model outperforms the state-of-the-art method, LaserMix."],"url":"http://arxiv.org/abs/2312.08234v1"}
{"created":"2023-12-13 15:54:50","title":"Green Operations of SWIPT Networks: The Role of End-User Devices","abstract":"Internet of Things (IoT) devices often come with batteries of limited capacity that are not easily replaceable or rechargeable, and that constrain significantly the sensing, computing, and communication tasks that they can perform. The Simultaneous Wireless Information and Power Transfer (SWIPT) paradigm addresses this issue by delivering power wirelessly to energy-harvesting IoT devices with the same signal used for information transfer. For their peculiarity, these networks require specific energy-efficient planning and management approaches. However, to date, it is not clear what are the most effective strategies for managing a SWIPT network for energy efficiency. In this paper, we address this issue by developing an analytical model based on stochastic geometry, accounting for the statistics of user-perceived performance and base station scheduling. We formulate an optimization problem for deriving the energy optimal configuration as a function of the main system parameters, and we propose a genetic algorithm approach to solve it. Our results enable a first-order evaluation of the most effective strategies for energy-efficient provisioning of power and communications in a SWIPT network. We show that the service capacity brought about by users brings energy-efficient dynamic network provisioning strategies that radically differ from those of networks with no wireless power transfer.","sentences":["Internet of Things (IoT) devices often come with batteries of limited capacity that are not easily replaceable or rechargeable, and that constrain significantly the sensing, computing, and communication tasks that they can perform.","The Simultaneous Wireless Information and Power Transfer (SWIPT) paradigm addresses this issue by delivering power wirelessly to energy-harvesting IoT devices with the same signal used for information transfer.","For their peculiarity, these networks require specific energy-efficient planning and management approaches.","However, to date, it is not clear what are the most effective strategies for managing a SWIPT network for energy efficiency.","In this paper, we address this issue by developing an analytical model based on stochastic geometry, accounting for the statistics of user-perceived performance and base station scheduling.","We formulate an optimization problem for deriving the energy optimal configuration as a function of the main system parameters, and we propose a genetic algorithm approach to solve it.","Our results enable a first-order evaluation of the most effective strategies for energy-efficient provisioning of power and communications in a SWIPT network.","We show that the service capacity brought about by users brings energy-efficient dynamic network provisioning strategies that radically differ from those of networks with no wireless power transfer."],"url":"http://arxiv.org/abs/2312.08232v1"}
{"created":"2023-12-13 15:48:50","title":"Partial Symmetry Detection for 3D Geometry using Contrastive Learning with Geodesic Point Cloud Patches","abstract":"Symmetry detection, especially partial and extrinsic symmetry, is essential for various downstream tasks, like 3D geometry completion, segmentation, compression and structure-aware shape encoding or generation. In order to detect partial extrinsic symmetries, we propose to learn rotation, reflection, translation and scale invariant local shape features for geodesic point cloud patches via contrastive learning, which are robust across multiple classes and generalize over different datasets. We show that our approach is able to extract multiple valid solutions for this ambiguous problem. Furthermore, we introduce a novel benchmark test for partial extrinsic symmetry detection to evaluate our method. Lastly, we incorporate the detected symmetries together with a region growing algorithm to demonstrate a downstream task with the goal of computing symmetry-aware partitions of 3D shapes. To our knowledge, we are the first to propose a self-supervised data-driven method for partial extrinsic symmetry detection.","sentences":["Symmetry detection, especially partial and extrinsic symmetry, is essential for various downstream tasks, like 3D geometry completion, segmentation, compression and structure-aware shape encoding or generation.","In order to detect partial extrinsic symmetries, we propose to learn rotation, reflection, translation and scale invariant local shape features for geodesic point cloud patches via contrastive learning, which are robust across multiple classes and generalize over different datasets.","We show that our approach is able to extract multiple valid solutions for this ambiguous problem.","Furthermore, we introduce a novel benchmark test for partial extrinsic symmetry detection to evaluate our method.","Lastly, we incorporate the detected symmetries together with a region growing algorithm to demonstrate a downstream task with the goal of computing symmetry-aware partitions of 3D shapes.","To our knowledge, we are the first to propose a self-supervised data-driven method for partial extrinsic symmetry detection."],"url":"http://arxiv.org/abs/2312.08230v1"}
{"created":"2023-12-13 15:46:58","title":"GLOP: Learning Global Partition and Local Construction for Solving Large-scale Routing Problems in Real-time","abstract":"The recent end-to-end neural solvers have shown promise for small-scale routing problems but suffered from limited real-time scaling-up performance. This paper proposes GLOP (Global and Local Optimization Policies), a unified hierarchical framework that efficiently scales toward large-scale routing problems. GLOP partitions large routing problems into Travelling Salesman Problems (TSPs) and TSPs into Shortest Hamiltonian Path Problems. For the first time, we hybridize non-autoregressive neural heuristics for coarse-grained problem partitions and autoregressive neural heuristics for fine-grained route constructions, leveraging the scalability of the former and the meticulousness of the latter. Experimental results show that GLOP achieves competitive and state-of-the-art real-time performance on large-scale routing problems, including TSP, ATSP, CVRP, and PCTSP.","sentences":["The recent end-to-end neural solvers have shown promise for small-scale routing problems but suffered from limited real-time scaling-up performance.","This paper proposes GLOP (Global and Local Optimization Policies), a unified hierarchical framework that efficiently scales toward large-scale routing problems.","GLOP partitions large routing problems into Travelling Salesman Problems (TSPs) and TSPs into Shortest Hamiltonian Path Problems.","For the first time, we hybridize non-autoregressive neural heuristics for coarse-grained problem partitions and autoregressive neural heuristics for fine-grained route constructions, leveraging the scalability of the former and the meticulousness of the latter.","Experimental results show that GLOP achieves competitive and state-of-the-art real-time performance on large-scale routing problems, including TSP, ATSP, CVRP, and PCTSP."],"url":"http://arxiv.org/abs/2312.08224v1"}
{"created":"2023-12-13 15:45:19","title":"Patch-wise Graph Contrastive Learning for Image Translation","abstract":"Recently, patch-wise contrastive learning is drawing attention for the image translation by exploring the semantic correspondence between the input and output images. To further explore the patch-wise topology for high-level semantic understanding, here we exploit the graph neural network to capture the topology-aware features. Specifically, we construct the graph based on the patch-wise similarity from a pretrained encoder, whose adjacency matrix is shared to enhance the consistency of patch-wise relation between the input and the output. Then, we obtain the node feature from the graph neural network, and enhance the correspondence between the nodes by increasing mutual information using the contrastive loss. In order to capture the hierarchical semantic structure, we further propose the graph pooling. Experimental results demonstrate the state-of-art results for the image translation thanks to the semantic encoding by the constructed graphs.","sentences":["Recently, patch-wise contrastive learning is drawing attention for the image translation by exploring the semantic correspondence between the input and output images.","To further explore the patch-wise topology for high-level semantic understanding, here we exploit the graph neural network to capture the topology-aware features.","Specifically, we construct the graph based on the patch-wise similarity from a pretrained encoder, whose adjacency matrix is shared to enhance the consistency of patch-wise relation between the input and the output.","Then, we obtain the node feature from the graph neural network, and enhance the correspondence between the nodes by increasing mutual information using the contrastive loss.","In order to capture the hierarchical semantic structure, we further propose the graph pooling.","Experimental results demonstrate the state-of-art results for the image translation thanks to the semantic encoding by the constructed graphs."],"url":"http://arxiv.org/abs/2312.08223v1"}
{"created":"2023-12-13 15:42:14","title":"Curriculum-Enhanced Residual Soft An-Isotropic Normalization for Over-smoothness in Deep GNNs","abstract":"Despite Graph neural networks' significant performance gain over many classic techniques in various graph-related downstream tasks, their successes are restricted in shallow models due to over-smoothness and the difficulties of optimizations among many other issues. In this paper, to alleviate the over-smoothing issue, we propose a soft graph normalization method to preserve the diversities of node embeddings and prevent indiscrimination due to possible over-closeness. Combined with residual connections, we analyze the reason why the method can effectively capture the knowledge in both input graph structures and node features even with deep networks. Additionally, inspired by Curriculum Learning that learns easy examples before the hard ones, we propose a novel label-smoothing-based learning framework to enhance the optimization of deep GNNs, which iteratively smooths labels in an auxiliary graph and constructs many gradual non-smooth tasks for extracting increasingly complex knowledge and gradually discriminating nodes from coarse to fine. The method arguably reduces the risk of overfitting and generalizes better results. Finally, extensive experiments are carried out to demonstrate the effectiveness and potential of the proposed model and learning framework through comparison with twelve existing baselines including the state-of-the-art methods on twelve real-world node classification benchmarks.","sentences":["Despite Graph neural networks' significant performance gain over many classic techniques in various graph-related downstream tasks, their successes are restricted in shallow models due to over-smoothness and the difficulties of optimizations among many other issues.","In this paper, to alleviate the over-smoothing issue, we propose a soft graph normalization method to preserve the diversities of node embeddings and prevent indiscrimination due to possible over-closeness.","Combined with residual connections, we analyze the reason why the method can effectively capture the knowledge in both input graph structures and node features even with deep networks.","Additionally, inspired by Curriculum Learning that learns easy examples before the hard ones, we propose a novel label-smoothing-based learning framework to enhance the optimization of deep GNNs, which iteratively smooths labels in an auxiliary graph and constructs many gradual non-smooth tasks for extracting increasingly complex knowledge and gradually discriminating nodes from coarse to fine.","The method arguably reduces the risk of overfitting and generalizes better results.","Finally, extensive experiments are carried out to demonstrate the effectiveness and potential of the proposed model and learning framework through comparison with twelve existing baselines including the state-of-the-art methods on twelve real-world node classification benchmarks."],"url":"http://arxiv.org/abs/2312.08221v1"}
{"created":"2023-12-13 15:42:04","title":"EventAid: Benchmarking Event-aided Image/Video Enhancement Algorithms with Real-captured Hybrid Dataset","abstract":"Event cameras are emerging imaging technology that offers advantages over conventional frame-based imaging sensors in dynamic range and sensing speed. Complementing the rich texture and color perception of traditional image frames, the hybrid camera system of event and frame-based cameras enables high-performance imaging. With the assistance of event cameras, high-quality image/video enhancement methods make it possible to break the limits of traditional frame-based cameras, especially exposure time, resolution, dynamic range, and frame rate limits. This paper focuses on five event-aided image and video enhancement tasks (i.e., event-based video reconstruction, event-aided high frame rate video reconstruction, image deblurring, image super-resolution, and high dynamic range image reconstruction), provides an analysis of the effects of different event properties, a real-captured and ground truth labeled benchmark dataset, a unified benchmarking of state-of-the-art methods, and an evaluation for two mainstream event simulators. In detail, this paper collects a real-captured evaluation dataset EventAid for five event-aided image/video enhancement tasks, by using \"Event-RGB\" multi-camera hybrid system, taking into account scene diversity and spatiotemporal synchronization. We further perform quantitative and visual comparisons for state-of-the-art algorithms, provide a controlled experiment to analyze the performance limit of event-aided image deblurring methods, and discuss open problems to inspire future research.","sentences":["Event cameras are emerging imaging technology that offers advantages over conventional frame-based imaging sensors in dynamic range and sensing speed.","Complementing the rich texture and color perception of traditional image frames, the hybrid camera system of event and frame-based cameras enables high-performance imaging.","With the assistance of event cameras, high-quality image/video enhancement methods make it possible to break the limits of traditional frame-based cameras, especially exposure time, resolution, dynamic range, and frame rate limits.","This paper focuses on five event-aided image and video enhancement tasks (i.e., event-based video reconstruction, event-aided high frame rate video reconstruction, image deblurring, image super-resolution, and high dynamic range image reconstruction), provides an analysis of the effects of different event properties, a real-captured and ground truth labeled benchmark dataset, a unified benchmarking of state-of-the-art methods, and an evaluation for two mainstream event simulators.","In detail, this paper collects a real-captured evaluation dataset EventAid for five event-aided image/video enhancement tasks, by using \"Event-RGB\" multi-camera hybrid system, taking into account scene diversity and spatiotemporal synchronization.","We further perform quantitative and visual comparisons for state-of-the-art algorithms, provide a controlled experiment to analyze the performance limit of event-aided image deblurring methods, and discuss open problems to inspire future research."],"url":"http://arxiv.org/abs/2312.08220v1"}
{"created":"2023-12-13 15:33:09","title":"A Precoding for ORIS-Assisted MIMO Multi-User VLC System","abstract":"In this paper, we study a multi-user visible light communication (VLC) system assisted with optical reflecting intelligent surface (ORIS). Joint precoding and alignment matrices are designed to maximize the average signal-to-interference plus noise ratio (SINR) criteria. Considering the constraints of the constant mean transmission power of LEDs and the power associated with all users, an optimization problem is proposed. To solve this problem, we utilize an alternating optimization algorithm to optimize the precoding and alignment matrices. The simulation results demonstrate that the resultant SINR of the proposed method outperforms ZF and MMSE precoding algorithms.","sentences":["In this paper, we study a multi-user visible light communication (VLC) system assisted with optical reflecting intelligent surface (ORIS).","Joint precoding and alignment matrices are designed to maximize the average signal-to-interference plus noise ratio (SINR) criteria.","Considering the constraints of the constant mean transmission power of LEDs and the power associated with all users, an optimization problem is proposed.","To solve this problem, we utilize an alternating optimization algorithm to optimize the precoding and alignment matrices.","The simulation results demonstrate that the resultant SINR of the proposed method outperforms ZF and MMSE precoding algorithms."],"url":"http://arxiv.org/abs/2312.08214v1"}
{"created":"2023-12-13 15:30:29","title":"Accelerated Event-Based Feature Detection and Compression for Surveillance Video Systems","abstract":"The strong temporal consistency of surveillance video enables compelling compression performance with traditional methods, but downstream vision applications operate on decoded image frames with a high data rate. Since it is not straightforward for applications to extract information on temporal redundancy from the compressed video representations, we propose a novel system which conveys temporal redundancy within a sparse decompressed representation. We leverage a video representation framework called ADDER to transcode framed videos to sparse, asynchronous intensity samples. We introduce mechanisms for content adaptation, lossy compression, and asynchronous forms of classical vision algorithms. We evaluate our system on the VIRAT surveillance video dataset, and we show a median 43.7% speed improvement in FAST feature detection compared to OpenCV. We run the same algorithm as OpenCV, but only process pixels that receive new asynchronous events, rather than process every pixel in an image frame. Our work paves the way for upcoming neuromorphic sensors and is amenable to future applications with spiking neural networks.","sentences":["The strong temporal consistency of surveillance video enables compelling compression performance with traditional methods, but downstream vision applications operate on decoded image frames with a high data rate.","Since it is not straightforward for applications to extract information on temporal redundancy from the compressed video representations, we propose a novel system which conveys temporal redundancy within a sparse decompressed representation.","We leverage a video representation framework called ADDER to transcode framed videos to sparse, asynchronous intensity samples.","We introduce mechanisms for content adaptation, lossy compression, and asynchronous forms of classical vision algorithms.","We evaluate our system on the VIRAT surveillance video dataset, and we show a median 43.7% speed improvement in FAST feature detection compared to OpenCV.","We run the same algorithm as OpenCV, but only process pixels that receive new asynchronous events, rather than process every pixel in an image frame.","Our work paves the way for upcoming neuromorphic sensors and is amenable to future applications with spiking neural networks."],"url":"http://arxiv.org/abs/2312.08213v1"}
{"created":"2023-12-13 15:29:52","title":"LAMM: Label Alignment for Multi-Modal Prompt Learning","abstract":"With the success of pre-trained visual-language (VL) models such as CLIP in visual representation tasks, transferring pre-trained models to downstream tasks has become a crucial paradigm. Recently, the prompt tuning paradigm, which draws inspiration from natural language processing (NLP), has made significant progress in VL field. However, preceding methods mainly focus on constructing prompt templates for text and visual inputs, neglecting the gap in class label representations between the VL models and downstream tasks. To address this challenge, we introduce an innovative label alignment method named \\textbf{LAMM}, which can dynamically adjust the category embeddings of downstream datasets through end-to-end training. Moreover, to achieve a more appropriate label distribution, we propose a hierarchical loss, encompassing the alignment of the parameter space, feature space, and logits space. We conduct experiments on 11 downstream vision datasets and demonstrate that our method significantly improves the performance of existing multi-modal prompt learning models in few-shot scenarios, exhibiting an average accuracy improvement of 2.31(\\%) compared to the state-of-the-art methods on 16 shots. Moreover, our methodology exhibits the preeminence in continual learning compared to other prompt tuning methods. Importantly, our method is synergistic with existing prompt tuning methods and can boost the performance on top of them. Our code and dataset will be publicly available at https://github.com/gaojingsheng/LAMM.","sentences":["With the success of pre-trained visual-language (VL) models such as CLIP in visual representation tasks, transferring pre-trained models to downstream tasks has become a crucial paradigm.","Recently, the prompt tuning paradigm, which draws inspiration from natural language processing (NLP), has made significant progress in VL field.","However, preceding methods mainly focus on constructing prompt templates for text and visual inputs, neglecting the gap in class label representations between the VL models and downstream tasks.","To address this challenge, we introduce an innovative label alignment method named \\textbf{LAMM}, which can dynamically adjust the category embeddings of downstream datasets through end-to-end training.","Moreover, to achieve a more appropriate label distribution, we propose a hierarchical loss, encompassing the alignment of the parameter space, feature space, and logits space.","We conduct experiments on 11 downstream vision datasets and demonstrate that our method significantly improves the performance of existing multi-modal prompt learning models in few-shot scenarios, exhibiting an average accuracy improvement of 2.31(\\%) compared to the state-of-the-art methods on 16 shots.","Moreover, our methodology exhibits the preeminence in continual learning compared to other prompt tuning methods.","Importantly, our method is synergistic with existing prompt tuning methods and can boost the performance on top of them.","Our code and dataset will be publicly available at https://github.com/gaojingsheng/LAMM."],"url":"http://arxiv.org/abs/2312.08212v1"}
{"created":"2023-12-13 15:25:39","title":"Black-box Membership Inference Attacks against Fine-tuned Diffusion Models","abstract":"With the rapid advancement of diffusion-based image-generative models, the quality of generated images has become increasingly photorealistic. Moreover, with the release of high-quality pre-trained image-generative models, a growing number of users are downloading these pre-trained models to fine-tune them with downstream datasets for various image-generation tasks. However, employing such powerful pre-trained models in downstream tasks presents significant privacy leakage risks. In this paper, we propose the first reconstruction-based membership inference attack framework, tailored for recent diffusion models, and in the more stringent black-box access setting. Considering four distinct attack scenarios and three types of attacks, this framework is capable of targeting any popular conditional generator model, achieving high precision, evidenced by an impressive AUC of $0.95$.","sentences":["With the rapid advancement of diffusion-based image-generative models, the quality of generated images has become increasingly photorealistic.","Moreover, with the release of high-quality pre-trained image-generative models, a growing number of users are downloading these pre-trained models to fine-tune them with downstream datasets for various image-generation tasks.","However, employing such powerful pre-trained models in downstream tasks presents significant privacy leakage risks.","In this paper, we propose the first reconstruction-based membership inference attack framework, tailored for recent diffusion models, and in the more stringent black-box access setting.","Considering four distinct attack scenarios and three types of attacks, this framework is capable of targeting any popular conditional generator model, achieving high precision, evidenced by an impressive AUC of $0.95$."],"url":"http://arxiv.org/abs/2312.08207v1"}
{"created":"2023-12-13 15:08:54","title":"SPD-DDPM: Denoising Diffusion Probabilistic Models in the Symmetric Positive Definite Space","abstract":"Symmetric positive definite~(SPD) matrices have shown important value and applications in statistics and machine learning, such as FMRI analysis and traffic prediction. Previous works on SPD matrices mostly focus on discriminative models, where predictions are made directly on $E(X|y)$, where $y$ is a vector and $X$ is an SPD matrix. However, these methods are challenging to handle for large-scale data, as they need to access and process the whole data. In this paper, inspired by denoising diffusion probabilistic model~(DDPM), we propose a novel generative model, termed SPD-DDPM, by introducing Gaussian distribution in the SPD space to estimate $E(X|y)$. Moreover, our model is able to estimate $p(X)$ unconditionally and flexibly without giving $y$. On the one hand, the model conditionally learns $p(X|y)$ and utilizes the mean of samples to obtain $E(X|y)$ as a prediction. On the other hand, the model unconditionally learns the probability distribution of the data $p(X)$ and generates samples that conform to this distribution. Furthermore, we propose a new SPD net which is much deeper than the previous networks and allows for the inclusion of conditional factors. Experiment results on toy data and real taxi data demonstrate that our models effectively fit the data distribution both unconditionally and unconditionally and provide accurate predictions.","sentences":["Symmetric positive definite~(SPD) matrices have shown important value and applications in statistics and machine learning, such as FMRI analysis and traffic prediction.","Previous works on SPD matrices mostly focus on discriminative models, where predictions are made directly on $E(X|y)$, where $y$ is a vector and $X$ is an SPD matrix.","However, these methods are challenging to handle for large-scale data, as they need to access and process the whole data.","In this paper, inspired by denoising diffusion probabilistic model~(DDPM), we propose a novel generative model, termed SPD-DDPM, by introducing Gaussian distribution in the SPD space to estimate $E(X|y)$. Moreover, our model is able to estimate $p(X)$ unconditionally and flexibly without giving $y$. On the one hand, the model conditionally learns $p(X|y)$ and utilizes the mean of samples to obtain $E(X|y)$ as a prediction.","On the other hand, the model unconditionally learns the probability distribution of the data $p(X)$ and generates samples that conform to this distribution.","Furthermore, we propose a new SPD net which is much deeper than the previous networks and allows for the inclusion of conditional factors.","Experiment results on toy data and real taxi data demonstrate that our models effectively fit the data distribution both unconditionally and unconditionally and provide accurate predictions."],"url":"http://arxiv.org/abs/2312.08200v1"}
{"created":"2023-12-13 15:03:27","title":"Towards Model-Based Data Acquisition for Subjective Multi-Task NLP Problems","abstract":"Data annotated by humans is a source of knowledge by describing the peculiarities of the problem and therefore fueling the decision process of the trained model. Unfortunately, the annotation process for subjective natural language processing (NLP) problems like offensiveness or emotion detection is often very expensive and time-consuming. One of the inevitable risks is to spend some of the funds and annotator effort on annotations that do not provide any additional knowledge about the specific task. To minimize these costs, we propose a new model-based approach that allows the selection of tasks annotated individually for each text in a multi-task scenario. The experiments carried out on three datasets, dozens of NLP tasks, and thousands of annotations show that our method allows up to 40% reduction in the number of annotations with negligible loss of knowledge. The results also emphasize the need to collect a diverse amount of data required to efficiently train a model, depending on the subjectivity of the annotation task. We also focused on measuring the relation between subjective tasks by evaluating the model in single-task and multi-task scenarios. Moreover, for some datasets, training only on the labels predicted by our model improved the efficiency of task selection as a self-supervised learning regularization technique.","sentences":["Data annotated by humans is a source of knowledge by describing the peculiarities of the problem and therefore fueling the decision process of the trained model.","Unfortunately, the annotation process for subjective natural language processing (NLP) problems like offensiveness or emotion detection is often very expensive and time-consuming.","One of the inevitable risks is to spend some of the funds and annotator effort on annotations that do not provide any additional knowledge about the specific task.","To minimize these costs, we propose a new model-based approach that allows the selection of tasks annotated individually for each text in a multi-task scenario.","The experiments carried out on three datasets, dozens of NLP tasks, and thousands of annotations show that our method allows up to 40% reduction in the number of annotations with negligible loss of knowledge.","The results also emphasize the need to collect a diverse amount of data required to efficiently train a model, depending on the subjectivity of the annotation task.","We also focused on measuring the relation between subjective tasks by evaluating the model in single-task and multi-task scenarios.","Moreover, for some datasets, training only on the labels predicted by our model improved the efficiency of task selection as a self-supervised learning regularization technique."],"url":"http://arxiv.org/abs/2312.08198v1"}
{"created":"2023-12-13 14:59:49","title":"Concept-centric Personalization with Large-scale Diffusion Priors","abstract":"Despite large-scale diffusion models being highly capable of generating diverse open-world content, they still struggle to match the photorealism and fidelity of concept-specific generators. In this work, we present the task of customizing large-scale diffusion priors for specific concepts as concept-centric personalization. Our goal is to generate high-quality concept-centric images while maintaining the versatile controllability inherent to open-world models, enabling applications in diverse tasks such as concept-centric stylization and image translation. To tackle these challenges, we identify catastrophic forgetting of guidance prediction from diffusion priors as the fundamental issue. Consequently, we develop a guidance-decoupled personalization framework specifically designed to address this task. We propose Generalized Classifier-free Guidance (GCFG) as the foundational theory for our framework. This approach extends Classifier-free Guidance (CFG) to accommodate an arbitrary number of guidances, sourced from a variety of conditions and models. Employing GCFG enables us to separate conditional guidance into two distinct components: concept guidance for fidelity and control guidance for controllability. This division makes it feasible to train a specialized model for concept guidance, while ensuring both control and unconditional guidance remain intact. We then present a null-text Concept-centric Diffusion Model as a concept-specific generator to learn concept guidance without the need for text annotations. Code will be available at https://github.com/PRIV-Creation/Concept-centric-Personalization.","sentences":["Despite large-scale diffusion models being highly capable of generating diverse open-world content, they still struggle to match the photorealism and fidelity of concept-specific generators.","In this work, we present the task of customizing large-scale diffusion priors for specific concepts as concept-centric personalization.","Our goal is to generate high-quality concept-centric images while maintaining the versatile controllability inherent to open-world models, enabling applications in diverse tasks such as concept-centric stylization and image translation.","To tackle these challenges, we identify catastrophic forgetting of guidance prediction from diffusion priors as the fundamental issue.","Consequently, we develop a guidance-decoupled personalization framework specifically designed to address this task.","We propose Generalized Classifier-free Guidance (GCFG) as the foundational theory for our framework.","This approach extends Classifier-free Guidance (CFG) to accommodate an arbitrary number of guidances, sourced from a variety of conditions and models.","Employing GCFG enables us to separate conditional guidance into two distinct components: concept guidance for fidelity and control guidance for controllability.","This division makes it feasible to train a specialized model for concept guidance, while ensuring both control and unconditional guidance remain intact.","We then present a null-text Concept-centric Diffusion Model as a concept-specific generator to learn concept guidance without the need for text annotations.","Code will be available at https://github.com/PRIV-Creation/Concept-centric-Personalization."],"url":"http://arxiv.org/abs/2312.08195v1"}
{"created":"2023-12-13 14:58:25","title":"SVInvNet: A Densely Connected Encoder-Decoder Architecture for Seismic Velocity Inversion","abstract":"This study presents a deep learning-based approach to seismic velocity inversion problem, focusing on both noisy and noiseless training datasets of varying sizes. Our Seismic Velocity Inversion Network (SVInvNet) introduces a novel architecture that contains a multi-connection encoder-decoder structure enhanced with dense blocks. This design is specifically tuned to effectively process complex information, crucial for addressing the challenges of non-linear seismic velocity inversion. For training and testing, we created diverse seismic velocity models, including multi-layered, faulty, and salt dome categories. We also investigated how different kinds of ambient noise, both coherent and stochastic, and the size of the training dataset affect learning outcomes. SVInvNet is trained on datasets ranging from 750 to 6,000 samples and is tested using a large benchmark dataset of 12,000 samples. Despite its fewer parameters compared to the baseline, SVInvNet achieves superior performance with this dataset. The outcomes of the SVInvNet are additionally compared to those of the Full Waveform Inversion (FWI) method. The comparative analysis clearly reveals the effectiveness of the proposed model.","sentences":["This study presents a deep learning-based approach to seismic velocity inversion problem, focusing on both noisy and noiseless training datasets of varying sizes.","Our Seismic Velocity Inversion Network (SVInvNet) introduces a novel architecture that contains a multi-connection encoder-decoder structure enhanced with dense blocks.","This design is specifically tuned to effectively process complex information, crucial for addressing the challenges of non-linear seismic velocity inversion.","For training and testing, we created diverse seismic velocity models, including multi-layered, faulty, and salt dome categories.","We also investigated how different kinds of ambient noise, both coherent and stochastic, and the size of the training dataset affect learning outcomes.","SVInvNet is trained on datasets ranging from 750 to 6,000 samples and is tested using a large benchmark dataset of 12,000 samples.","Despite its fewer parameters compared to the baseline, SVInvNet achieves superior performance with this dataset.","The outcomes of the SVInvNet are additionally compared to those of the Full Waveform Inversion (FWI) method.","The comparative analysis clearly reveals the effectiveness of the proposed model."],"url":"http://arxiv.org/abs/2312.08194v1"}
{"created":"2023-12-13 14:57:28","title":"PAD: Self-Supervised Pre-Training with Patchwise-Scale Adapter for Infrared Images","abstract":"Self-supervised learning (SSL) for RGB images has achieved significant success, yet there is still limited research on SSL for infrared images, primarily due to three prominent challenges: 1) the lack of a suitable large-scale infrared pre-training dataset, 2) the distinctiveness of non-iconic infrared images rendering common pre-training tasks like masked image modeling (MIM) less effective, and 3) the scarcity of fine-grained textures making it particularly challenging to learn general image features. To address these issues, we construct a Multi-Scene Infrared Pre-training (MSIP) dataset comprising 178,756 images, and introduce object-sensitive random RoI cropping, an image preprocessing method, to tackle the challenge posed by non-iconic images. To alleviate the impact of weak textures on feature learning, we propose a pre-training paradigm called Pre-training with ADapter (PAD), which uses adapters to learn domain-specific features while freezing parameters pre-trained on ImageNet to retain the general feature extraction capability. This new paradigm is applicable to any transformer-based SSL method. Furthermore, to achieve more flexible coordination between pre-trained and newly-learned features in different layers and patches, a patchwise-scale adapter with dynamically learnable scale factors is introduced. Extensive experiments on three downstream tasks show that PAD, with only 1.23M pre-trainable parameters, outperforms other baseline paradigms including continual full pre-training on MSIP. Our code and dataset are available at https://github.com/casiatao/PAD.","sentences":["Self-supervised learning (SSL) for RGB images has achieved significant success, yet there is still limited research on SSL for infrared images, primarily due to three prominent challenges: 1) the lack of a suitable large-scale infrared pre-training dataset, 2) the distinctiveness of non-iconic infrared images rendering common pre-training tasks like masked image modeling (MIM) less effective, and 3) the scarcity of fine-grained textures making it particularly challenging to learn general image features.","To address these issues, we construct a Multi-Scene Infrared Pre-training (MSIP) dataset comprising 178,756 images, and introduce object-sensitive random RoI cropping, an image preprocessing method, to tackle the challenge posed by non-iconic images.","To alleviate the impact of weak textures on feature learning, we propose a pre-training paradigm called Pre-training with ADapter (PAD), which uses adapters to learn domain-specific features while freezing parameters pre-trained on ImageNet to retain the general feature extraction capability.","This new paradigm is applicable to any transformer-based SSL method.","Furthermore, to achieve more flexible coordination between pre-trained and newly-learned features in different layers and patches, a patchwise-scale adapter with dynamically learnable scale factors is introduced.","Extensive experiments on three downstream tasks show that PAD, with only 1.23M pre-trainable parameters, outperforms other baseline paradigms including continual full pre-training on MSIP.","Our code and dataset are available at https://github.com/casiatao/PAD."],"url":"http://arxiv.org/abs/2312.08192v1"}
{"created":"2023-12-13 14:56:42","title":"GuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements","abstract":"Before implementing a function, programmers are encouraged to write a purpose statement i.e., a short, natural-language explanation of what the function computes. A purpose statement may be ambiguous i.e., it may fail to specify the intended behaviour when two or more inequivalent computations are plausible on certain inputs. Our paper makes four contributions. First, we propose a novel heuristic that suggests such inputs using Large Language Models (LLMs). Using these suggestions, the programmer may choose to clarify the purpose statement (e.g., by providing a functional example that specifies the intended behaviour on such an input). Second, to assess the quality of inputs suggested by our heuristic, and to facilitate future research, we create an open dataset of purpose statements with known ambiguities. Third, we compare our heuristic against GitHub Copilot's Chat feature, which can suggest similar inputs when prompted to generate unit tests. Fourth, we provide an open-source implementation of our heuristic as an extension to Visual Studio Code for the Python programming language, where purpose statements and functional examples are specified as docstrings and doctests respectively. We believe that this tool will be particularly helpful to novice programmers and instructors.","sentences":["Before implementing a function, programmers are encouraged to write a purpose statement i.e., a short, natural-language explanation of what the function computes.","A purpose statement may be ambiguous i.e., it may fail to specify the intended behaviour when two or more inequivalent computations are plausible on certain inputs.","Our paper makes four contributions.","First, we propose a novel heuristic that suggests such inputs using Large Language Models (LLMs).","Using these suggestions, the programmer may choose to clarify the purpose statement (e.g., by providing a functional example that specifies the intended behaviour on such an input).","Second, to assess the quality of inputs suggested by our heuristic, and to facilitate future research, we create an open dataset of purpose statements with known ambiguities.","Third, we compare our heuristic against GitHub Copilot's Chat feature, which can suggest similar inputs when prompted to generate unit tests.","Fourth, we provide an open-source implementation of our heuristic as an extension to Visual Studio Code for the Python programming language, where purpose statements and functional examples are specified as docstrings and doctests respectively.","We believe that this tool will be particularly helpful to novice programmers and instructors."],"url":"http://arxiv.org/abs/2312.08189v1"}
{"created":"2023-12-13 14:52:06","title":"Completing Priceable Committees: Utilitarian and Representation Guarantees for Proportional Multiwinner Voting","abstract":"When selecting committees based on preferences of voters, a variety of different criteria can be considered. Two natural objectives are maximizing the utilitarian welfare (the sum of voters' utilities) and coverage (the number of represented voters) of the selected committee. Previous work has studied the impact on utilitarian welfare and coverage when requiring the committee to satisfy minimal requirements such as justified representation or weak proportionality. In this paper, we consider the impact of imposing much more demanding proportionality axioms. We identify a class of voting rules that achieve strong guarantees on utilitarian welfare and coverage when combined with appropriate completions. This class is defined via a weakening of priceability and contains prominent rules such as the Method of Equal Shares. We show that committees selected by these rules (i) can be completed to achieve optimal coverage and (ii) can be completed to achieve an asymptotically optimal approximation to the utilitarian welfare if they additionally satisfy EJR+. Answering an open question of Elkind et al. (2022), we use the Greedy Justified Candidate Rule to obtain the best possible utilitarian guarantee subject to proportionality. We also consider completion methods suggested in the participatory budgeting literature and other objectives besides welfare and coverage.","sentences":["When selecting committees based on preferences of voters, a variety of different criteria can be considered.","Two natural objectives are maximizing the utilitarian welfare (the sum of voters' utilities) and coverage (the number of represented voters) of the selected committee.","Previous work has studied the impact on utilitarian welfare and coverage when requiring the committee to satisfy minimal requirements such as justified representation or weak proportionality.","In this paper, we consider the impact of imposing much more demanding proportionality axioms.","We identify a class of voting rules that achieve strong guarantees on utilitarian welfare and coverage when combined with appropriate completions.","This class is defined via a weakening of priceability and contains prominent rules such as the Method of Equal Shares.","We show that committees selected by these rules (i) can be completed to achieve optimal coverage and (ii) can be completed to achieve an asymptotically optimal approximation to the utilitarian welfare if they additionally satisfy EJR+.","Answering an open question of Elkind et al. (2022), we use the Greedy Justified Candidate Rule to obtain the best possible utilitarian guarantee subject to proportionality.","We also consider completion methods suggested in the participatory budgeting literature and other objectives besides welfare and coverage."],"url":"http://arxiv.org/abs/2312.08187v1"}
{"created":"2023-12-13 14:36:16","title":"Advanced Image Segmentation Techniques for Neural Activity Detection via C-fos Immediate Early Gene Expression","abstract":"This paper investigates the application of advanced image segmentation techniques to analyze C-fos immediate early gene expression, a crucial marker for neural activity. Due to the complexity and high variability of neural circuits, accurate segmentation of C-fos images is paramount for the development of new insights into neural function. Amidst this backdrop, this research aims to improve accuracy and minimize manual intervention in C-fos image segmentation by leveraging the capabilities of CNNs and the Unet model. We describe the development of a novel workflow for the segmentation process involving Convolutional Neural Networks (CNNs) and the Unet model, demonstrating their efficiency in various image segmentation tasks. Our workflow incorporates pre-processing steps such as cropping, image feature extraction, and clustering for the training dataset selection. We used an AutoEncoder model to extract features and implement constrained clustering to identify similarities and differences in image types. Additionally, we utilized manual and automatic labeling approaches to enhance the performance of our model. We demonstrated the effectiveness of our method in distinguishing areas with significant C-fos expression from normal tissue areas. Lastly, we implemented a modified Unet network for the detection of C-fos expressions. This research contributes to the development of more efficient and automated image segmentation methods, advancing the understanding of neural function in neuroscience research.","sentences":["This paper investigates the application of advanced image segmentation techniques to analyze C-fos immediate early gene expression, a crucial marker for neural activity.","Due to the complexity and high variability of neural circuits, accurate segmentation of C-fos images is paramount for the development of new insights into neural function.","Amidst this backdrop, this research aims to improve accuracy and minimize manual intervention in C-fos image segmentation by leveraging the capabilities of CNNs and the Unet model.","We describe the development of a novel workflow for the segmentation process involving Convolutional Neural Networks (CNNs) and the Unet model, demonstrating their efficiency in various image segmentation tasks.","Our workflow incorporates pre-processing steps such as cropping, image feature extraction, and clustering for the training dataset selection.","We used an AutoEncoder model to extract features and implement constrained clustering to identify similarities and differences in image types.","Additionally, we utilized manual and automatic labeling approaches to enhance the performance of our model.","We demonstrated the effectiveness of our method in distinguishing areas with significant C-fos expression from normal tissue areas.","Lastly, we implemented a modified Unet network for the detection of C-fos expressions.","This research contributes to the development of more efficient and automated image segmentation methods, advancing the understanding of neural function in neuroscience research."],"url":"http://arxiv.org/abs/2312.08177v1"}
{"created":"2023-12-13 14:36:08","title":"ASC: Adaptive Scale Feature Map Compression for Deep Neural Network","abstract":"Deep-learning accelerators are increasingly in demand; however, their performance is constrained by the size of the feature map, leading to high bandwidth requirements and large buffer sizes. We propose an adaptive scale feature map compression technique leveraging the unique properties of the feature map. This technique adopts independent channel indexing given the weak channel correlation and utilizes a cubical-like block shape to benefit from strong local correlations. The method further optimizes compression using a switchable endpoint mode and adaptive scale interpolation to handle unimodal data distributions, both with and without outliers. This results in 4$\\times$ and up to 7.69$\\times$ compression rates for 16-bit data in constant and variable bitrates, respectively. Our hardware design minimizes area cost by adjusting interpolation scales, which facilitates hardware sharing among interpolation points. Additionally, we introduce a threshold concept for straightforward interpolation, preventing the need for intricate hardware. The TSMC 28nm implementation showcases an equivalent gate count of 6135 for the 8-bit version. Furthermore, the hardware architecture scales effectively, with only a sublinear increase in area cost. Achieving a 32$\\times$ throughput increase meets the theoretical bandwidth of DDR5-6400 at just 7.65$\\times$ the hardware cost.","sentences":["Deep-learning accelerators are increasingly in demand; however, their performance is constrained by the size of the feature map, leading to high bandwidth requirements and large buffer sizes.","We propose an adaptive scale feature map compression technique leveraging the unique properties of the feature map.","This technique adopts independent channel indexing given the weak channel correlation and utilizes a cubical-like block shape to benefit from strong local correlations.","The method further optimizes compression using a switchable endpoint mode and adaptive scale interpolation to handle unimodal data distributions, both with and without outliers.","This results in 4$\\times$ and up to 7.69$\\times$ compression rates for 16-bit data in constant and variable bitrates, respectively.","Our hardware design minimizes area cost by adjusting interpolation scales, which facilitates hardware sharing among interpolation points.","Additionally, we introduce a threshold concept for straightforward interpolation, preventing the need for intricate hardware.","The TSMC 28nm implementation showcases an equivalent gate count of 6135 for the 8-bit version.","Furthermore, the hardware architecture scales effectively, with only a sublinear increase in area cost.","Achieving a 32$\\times$ throughput increase meets the theoretical bandwidth of DDR5-6400 at just 7.65$\\times$ the hardware cost."],"url":"http://arxiv.org/abs/2312.08176v1"}
{"created":"2023-12-13 14:27:45","title":"Chat-3D v2: Bridging 3D Scene and Large Language Models with Object Identifiers","abstract":"Recent research has evidenced the significant potentials of Large Language Models (LLMs) in handling challenging tasks within 3D scenes. However, current models are constrained to addressing object-centric tasks, where each question-answer pair focuses solely on an individual object. In real-world applications, users may pose queries involving multiple objects or expect for answers that precisely reference various objects. We introduce the use of object identifiers to freely reference objects during a conversation. While this solution appears straightforward, it presents two main challenges: 1) How to establish a reliable one-to-one correspondence between each object and its identifier? 2) How to incorporate complex spatial relationships among dozens of objects into the embedding space of the LLM? To address these challenges, we propose a two-stage alignment method, which involves learning an attribute-aware token and a relation-aware token for each object. These tokens capture the object's attributes and spatial relationships with surrounding objects in the 3D scene. Once the alignment is established, we can fine-tune our model on various downstream tasks using instruction tuning. Experiments conducted on traditional datasets like ScanQA, ScanRefer, and Nr3D/Sr3D showcase the effectiveness of our proposed method. Additionally, we create a 3D scene captioning dataset annotated with rich object identifiers, with the assistant of GPT-4. This dataset aims to further explore the capability of object identifiers in effective object referencing and precise scene understanding.","sentences":["Recent research has evidenced the significant potentials of Large Language Models (LLMs) in handling challenging tasks within 3D scenes.","However, current models are constrained to addressing object-centric tasks, where each question-answer pair focuses solely on an individual object.","In real-world applications, users may pose queries involving multiple objects or expect for answers that precisely reference various objects.","We introduce the use of object identifiers to freely reference objects during a conversation.","While this solution appears straightforward, it presents two main challenges: 1) How to establish a reliable one-to-one correspondence between each object and its identifier?","2) How to incorporate complex spatial relationships among dozens of objects into the embedding space of the LLM?","To address these challenges, we propose a two-stage alignment method, which involves learning an attribute-aware token and a relation-aware token for each object.","These tokens capture the object's attributes and spatial relationships with surrounding objects in the 3D scene.","Once the alignment is established, we can fine-tune our model on various downstream tasks using instruction tuning.","Experiments conducted on traditional datasets like ScanQA, ScanRefer, and Nr3D/Sr3D showcase the effectiveness of our proposed method.","Additionally, we create a 3D scene captioning dataset annotated with rich object identifiers, with the assistant of GPT-4.","This dataset aims to further explore the capability of object identifiers in effective object referencing and precise scene understanding."],"url":"http://arxiv.org/abs/2312.08168v1"}
