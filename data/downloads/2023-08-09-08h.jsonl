{"created":"2023-08-08 17:58:45","title":"When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations","abstract":"In machine learning, incorporating more data is often seen as a reliable strategy for improving model performance; this work challenges that notion by demonstrating that the addition of external datasets in many cases can hurt the resulting model's performance. In a large-scale empirical study across combinations of four different open-source chest x-ray datasets and 9 different labels, we demonstrate that in 43% of settings, a model trained on data from two hospitals has poorer worst group accuracy over both hospitals than a model trained on just a single hospital's data. This surprising result occurs even though the added hospital makes the training distribution more similar to the test distribution. We explain that this phenomenon arises from the spurious correlation that emerges between the disease and hospital, due to hospital-specific image artifacts. We highlight the trade-off one encounters when training on multiple datasets, between the obvious benefit of additional data and insidious cost of the introduced spurious correlation. In some cases, balancing the dataset can remove the spurious correlation and improve performance, but it is not always an effective strategy. We contextualize our results within the literature on spurious correlations to help explain these outcomes. Our experiments underscore the importance of exercising caution when selecting training data for machine learning models, especially in settings where there is a risk of spurious correlations such as with medical imaging. The risks outlined highlight the need for careful data selection and model evaluation in future research and practice.","sentences":["In machine learning, incorporating more data is often seen as a reliable strategy for improving model performance; this work challenges that notion by demonstrating that the addition of external datasets in many cases can hurt the resulting model's performance.","In a large-scale empirical study across combinations of four different open-source chest x-ray datasets and 9 different labels, we demonstrate that in 43% of settings, a model trained on data from two hospitals has poorer worst group accuracy over both hospitals than a model trained on just a single hospital's data.","This surprising result occurs even though the added hospital makes the training distribution more similar to the test distribution.","We explain that this phenomenon arises from the spurious correlation that emerges between the disease and hospital, due to hospital-specific image artifacts.","We highlight the trade-off one encounters when training on multiple datasets, between the obvious benefit of additional data and insidious cost of the introduced spurious correlation.","In some cases, balancing the dataset can remove the spurious correlation and improve performance, but it is not always an effective strategy.","We contextualize our results within the literature on spurious correlations to help explain these outcomes.","Our experiments underscore the importance of exercising caution when selecting training data for machine learning models, especially in settings where there is a risk of spurious correlations such as with medical imaging.","The risks outlined highlight the need for careful data selection and model evaluation in future research and practice."],"url":"http://arxiv.org/abs/2308.04431v1"}
{"created":"2023-08-08 17:58:15","title":"SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore","abstract":"The legality of training language models (LMs) on copyrighted or otherwise restricted data is under intense debate. However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage. We present SILO, a new language model that manages this risk-performance tradeoff during inference. SILO is built by (1) training a parametric LM on Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference. The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store. These capabilities can foster compliance with data-use regulations such as the fair use doctrine in the United States and the GDPR in the European Union. Our experiments show that the parametric LM struggles on domains not covered by OLC. However, access to the datastore greatly improves out of domain performance, closing 90% of the performance gap with an LM trained on the Pile, a more diverse corpus with mostly high-risk text. We also analyze which nonparametric approach works best, where the remaining errors lie, and how performance scales with datastore size. Our results suggest that it is possible to build high quality language models while mitigating their legal risk.","sentences":["The legality of training language models (LMs) on copyrighted or otherwise restricted data is under intense debate.","However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage.","We present SILO, a new language model that manages this risk-performance tradeoff during inference.","SILO is built by (1) training a parametric LM on Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference.","The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store.","These capabilities can foster compliance with data-use regulations such as the fair use doctrine in the United States and the GDPR in the European Union.","Our experiments show that the parametric LM struggles on domains not covered by OLC.","However, access to the datastore greatly improves out of domain performance, closing 90% of the performance gap with an LM trained on the Pile, a more diverse corpus with mostly high-risk text.","We also analyze which nonparametric approach works best, where the remaining errors lie, and how performance scales with datastore size.","Our results suggest that it is possible to build high quality language models while mitigating their legal risk."],"url":"http://arxiv.org/abs/2308.04430v1"}
{"created":"2023-08-08 17:55:30","title":"A Deep-Learning Method Using Auto-encoder and Generative Adversarial Network for Anomaly Detection on Ancient Stone Stele Surfaces","abstract":"Accurate detection of natural deterioration and man-made damage on the surfaces of ancient stele in the first instance is essential for their preventive conservation. Existing methods for cultural heritage preservation are not able to achieve this goal perfectly due to the difficulty of balancing accuracy, efficiency, timeliness, and cost. This paper presents a deep-learning method to automatically detect above mentioned emergencies on ancient stone stele in real time, employing autoencoder (AE) and generative adversarial network (GAN). The proposed method overcomes the limitations of existing methods by requiring no extensive anomaly samples while enabling comprehensive detection of unpredictable anomalies. the method includes stages of monitoring, data acquisition, pre-processing, model structuring, and post-processing. Taking the Longmen Grottoes' stone steles as a case study, an unsupervised learning model based on AE and GAN architectures is proposed and validated with a reconstruction accuracy of 99.74\\%. The method's evaluation revealed the proficient detection of seven artificially designed anomalies and demonstrated precision and reliability without false alarms. This research provides novel ideas and possibilities for the application of deep learning in the field of cultural heritage.","sentences":["Accurate detection of natural deterioration and man-made damage on the surfaces of ancient stele in the first instance is essential for their preventive conservation.","Existing methods for cultural heritage preservation are not able to achieve this goal perfectly due to the difficulty of balancing accuracy, efficiency, timeliness, and cost.","This paper presents a deep-learning method to automatically detect above mentioned emergencies on ancient stone stele in real time, employing autoencoder (AE) and generative adversarial network (GAN).","The proposed method overcomes the limitations of existing methods by requiring no extensive anomaly samples while enabling comprehensive detection of unpredictable anomalies.","the method includes stages of monitoring, data acquisition, pre-processing, model structuring, and post-processing.","Taking the Longmen Grottoes' stone steles as a case study, an unsupervised learning model based on AE and GAN architectures is proposed and validated with a reconstruction accuracy of 99.74\\%.","The method's evaluation revealed the proficient detection of seven artificially designed anomalies and demonstrated precision and reliability without false alarms.","This research provides novel ideas and possibilities for the application of deep learning in the field of cultural heritage."],"url":"http://arxiv.org/abs/2308.04426v1"}
{"created":"2023-08-08 17:53:24","title":"A Bi-directional Multi-hop Inference Model for Joint Dialog Sentiment Classification and Act Recognition","abstract":"The joint task of Dialog Sentiment Classification (DSC) and Act Recognition (DAR) aims to predict the sentiment label and act label for each utterance in a dialog simultaneously. However, current methods encode the dialog context in only one direction, which limits their ability to thoroughly comprehend the context. Moreover, these methods overlook the explicit correlations between sentiment and act labels, which leads to an insufficient ability to capture rich sentiment and act clues and hinders effective and accurate reasoning. To address these issues, we propose a Bi-directional Multi-hop Inference Model (BMIM) that leverages a feature selection network and a bi-directional multi-hop inference network to iteratively extract and integrate rich sentiment and act clues in a bi-directional manner. We also employ contrastive learning and dual learning to explicitly model the correlations of sentiment and act labels. Our experiments on two widely-used datasets show that BMIM outperforms state-of-the-art baselines by at least 2.6% on F1 score in DAR and 1.4% on F1 score in DSC. Additionally, Our proposed model not only improves the performance but also enhances the interpretability of the joint sentiment and act prediction task.","sentences":["The joint task of Dialog Sentiment Classification (DSC) and Act Recognition (DAR) aims to predict the sentiment label and act label for each utterance in a dialog simultaneously.","However, current methods encode the dialog context in only one direction, which limits their ability to thoroughly comprehend the context.","Moreover, these methods overlook the explicit correlations between sentiment and act labels, which leads to an insufficient ability to capture rich sentiment and act clues and hinders effective and accurate reasoning.","To address these issues, we propose a Bi-directional Multi-hop Inference Model (BMIM) that leverages a feature selection network and a bi-directional multi-hop inference network to iteratively extract and integrate rich sentiment and act clues in a bi-directional manner.","We also employ contrastive learning and dual learning to explicitly model the correlations of sentiment and act labels.","Our experiments on two widely-used datasets show that BMIM outperforms state-of-the-art baselines by at least 2.6% on F1 score in DAR and 1.4% on F1 score in DSC.","Additionally, Our proposed model not only improves the performance but also enhances the interpretability of the joint sentiment and act prediction task."],"url":"http://arxiv.org/abs/2308.04424v1"}
{"created":"2023-08-08 17:34:50","title":"Near-field 6G Networks: Why Mobile Terahertz Communications MUST Operate in the Near Field","abstract":"Near-field mobile terahertz (THz) communications is one of the candidate enablers for high-rate wireless data exchange in sixth-generation (6G) networks. However, operating in the THz near field brings both attractive opportunities and severe challenges. Hence, it becomes of interest to explore if it is possible to design a realistic mobile THz communication system without working in the THz near field. To answer this question, a mathematical framework is presented modeling a mobile THz link that works exclusively in the far field. The study leads to an interesting theoretical conclusion: while the actual frequency is of (almost) no interest, such a system must operate over a limited bandwidth not exceeding a certain threshold. It is then numerically shown that operating only in the far field imposes stringent limitations on mobile THz communications, thus making them less attractive to prospective high-rate services. In contrast, it is shown that a stationary THz link can still be broadband even when staying exclusively in the THz far field. Hence, broadband mobile THz communications MUST be near-field, while broadband stationary THz links do not have to.","sentences":["Near-field mobile terahertz (THz) communications is one of the candidate enablers for high-rate wireless data exchange in sixth-generation (6G) networks.","However, operating in the THz near field brings both attractive opportunities and severe challenges.","Hence, it becomes of interest to explore if it is possible to design a realistic mobile THz communication system without working in the THz near field.","To answer this question, a mathematical framework is presented modeling a mobile THz link that works exclusively in the far field.","The study leads to an interesting theoretical conclusion: while the actual frequency is of (almost) no interest, such a system must operate over a limited bandwidth not exceeding a certain threshold.","It is then numerically shown that operating only in the far field imposes stringent limitations on mobile THz communications, thus making them less attractive to prospective high-rate services.","In contrast, it is shown that a stationary THz link can still be broadband even when staying exclusively in the THz far field.","Hence, broadband mobile THz communications MUST be near-field, while broadband stationary THz links do not have to."],"url":"http://arxiv.org/abs/2308.04418v1"}
{"created":"2023-08-08 17:34:28","title":"DiffCR: A Fast Conditional Diffusion Framework for Cloud Removal from Optical Satellite Images","abstract":"Optical satellite images are a critical data source; however, cloud cover often compromises their quality, hindering image applications and analysis. Consequently, effectively removing clouds from optical satellite images has emerged as a prominent research direction. While recent advancements in cloud removal primarily rely on generative adversarial networks, which may yield suboptimal image quality, diffusion models have demonstrated remarkable success in diverse image-generation tasks, showcasing their potential in addressing this challenge. This paper presents a novel framework called DiffCR, which leverages conditional guided diffusion with deep convolutional networks for high-performance cloud removal for optical satellite imagery. Specifically, we introduce a decoupled encoder for conditional image feature extraction, providing a robust color representation to ensure the close similarity of appearance information between the conditional input and the synthesized output. Moreover, we propose a novel and efficient time and condition fusion block within the cloud removal model to accurately simulate the correspondence between the appearance in the conditional image and the target image at a low computational cost. Extensive experimental evaluations on two commonly used benchmark datasets demonstrate that DiffCR consistently achieves state-of-the-art performance on all metrics, with parameter and computational complexities amounting to only 5.1% and 5.4%, respectively, of those previous best methods. The source code, pre-trained models, and all the experimental results will be publicly available at https://github.com/XavierJiezou/DiffCR upon the paper's acceptance of this work.","sentences":["Optical satellite images are a critical data source; however, cloud cover often compromises their quality, hindering image applications and analysis.","Consequently, effectively removing clouds from optical satellite images has emerged as a prominent research direction.","While recent advancements in cloud removal primarily rely on generative adversarial networks, which may yield suboptimal image quality, diffusion models have demonstrated remarkable success in diverse image-generation tasks, showcasing their potential in addressing this challenge.","This paper presents a novel framework called DiffCR, which leverages conditional guided diffusion with deep convolutional networks for high-performance cloud removal for optical satellite imagery.","Specifically, we introduce a decoupled encoder for conditional image feature extraction, providing a robust color representation to ensure the close similarity of appearance information between the conditional input and the synthesized output.","Moreover, we propose a novel and efficient time and condition fusion block within the cloud removal model to accurately simulate the correspondence between the appearance in the conditional image and the target image at a low computational cost.","Extensive experimental evaluations on two commonly used benchmark datasets demonstrate that DiffCR consistently achieves state-of-the-art performance on all metrics, with parameter and computational complexities amounting to only 5.1% and 5.4%, respectively, of those previous best methods.","The source code, pre-trained models, and all the experimental results will be publicly available at https://github.com/XavierJiezou/DiffCR upon the paper's acceptance of this work."],"url":"http://arxiv.org/abs/2308.04417v1"}
{"created":"2023-08-08 17:18:59","title":"Digging into Depth Priors for Outdoor Neural Radiance Fields","abstract":"Neural Radiance Fields (NeRF) have demonstrated impressive performance in vision and graphics tasks, such as novel view synthesis and immersive reality. However, the shape-radiance ambiguity of radiance fields remains a challenge, especially in the sparse viewpoints setting. Recent work resorts to integrating depth priors into outdoor NeRF training to alleviate the issue. However, the criteria for selecting depth priors and the relative merits of different priors have not been thoroughly investigated. Moreover, the relative merits of selecting different approaches to use the depth priors is also an unexplored problem. In this paper, we provide a comprehensive study and evaluation of employing depth priors to outdoor neural radiance fields, covering common depth sensing technologies and most application ways. Specifically, we conduct extensive experiments with two representative NeRF methods equipped with four commonly-used depth priors and different depth usages on two widely used outdoor datasets. Our experimental results reveal several interesting findings that can potentially benefit practitioners and researchers in training their NeRF models with depth priors. Project Page: https://cwchenwang.github.io/outdoor-nerf-depth","sentences":["Neural Radiance Fields (NeRF) have demonstrated impressive performance in vision and graphics tasks, such as novel view synthesis and immersive reality.","However, the shape-radiance ambiguity of radiance fields remains a challenge, especially in the sparse viewpoints setting.","Recent work resorts to integrating depth priors into outdoor NeRF training to alleviate the issue.","However, the criteria for selecting depth priors and the relative merits of different priors have not been thoroughly investigated.","Moreover, the relative merits of selecting different approaches to use the depth priors is also an unexplored problem.","In this paper, we provide a comprehensive study and evaluation of employing depth priors to outdoor neural radiance fields, covering common depth sensing technologies and most application ways.","Specifically, we conduct extensive experiments with two representative NeRF methods equipped with four commonly-used depth priors and different depth usages on two widely used outdoor datasets.","Our experimental results reveal several interesting findings that can potentially benefit practitioners and researchers in training their NeRF models with depth priors.","Project Page: https://cwchenwang.github.io/outdoor-nerf-depth"],"url":"http://arxiv.org/abs/2308.04413v1"}
{"created":"2023-08-08 17:18:04","title":"Probabilistic Invariant Learning with Randomized Linear Classifiers","abstract":"Designing models that are both expressive and preserve known invariances of tasks is an increasingly hard problem. Existing solutions tradeoff invariance for computational or memory resources. In this work, we show how to leverage randomness and design models that are both expressive and invariant but use less resources. Inspired by randomized algorithms, our key insight is that accepting probabilistic notions of universal approximation and invariance can reduce our resource requirements. More specifically, we propose a class of binary classification models called Randomized Linear Classifiers (RLCs). We give parameter and sample size conditions in which RLCs can, with high probability, approximate any (smooth) function while preserving invariance to compact group transformations. Leveraging this result, we design three RLCs that are provably probabilistic invariant for classification tasks over sets, graphs, and spherical data. We show how these models can achieve probabilistic invariance and universality using less resources than (deterministic) neural networks and their invariant counterparts. Finally, we empirically demonstrate the benefits of this new class of models on invariant tasks where deterministic invariant neural networks are known to struggle.","sentences":["Designing models that are both expressive and preserve known invariances of tasks is an increasingly hard problem.","Existing solutions tradeoff invariance for computational or memory resources.","In this work, we show how to leverage randomness and design models that are both expressive and invariant but use less resources.","Inspired by randomized algorithms, our key insight is that accepting probabilistic notions of universal approximation and invariance can reduce our resource requirements.","More specifically, we propose a class of binary classification models called Randomized Linear Classifiers (RLCs).","We give parameter and sample size conditions in which RLCs can, with high probability, approximate any (smooth) function while preserving invariance to compact group transformations.","Leveraging this result, we design three RLCs that are provably probabilistic invariant for classification tasks over sets, graphs, and spherical data.","We show how these models can achieve probabilistic invariance and universality using less resources than (deterministic) neural networks and their invariant counterparts.","Finally, we empirically demonstrate the benefits of this new class of models on invariant tasks where deterministic invariant neural networks are known to struggle."],"url":"http://arxiv.org/abs/2308.04412v1"}
{"created":"2023-08-08 17:14:14","title":"V-DETR: DETR with Vertex Relative Position Encoding for 3D Object Detection","abstract":"We introduce a highly performant 3D object detector for point clouds using the DETR framework. The prior attempts all end up with suboptimal results because they fail to learn accurate inductive biases from the limited scale of training data. In particular, the queries often attend to points that are far away from the target objects, violating the locality principle in object detection. To address the limitation, we introduce a novel 3D Vertex Relative Position Encoding (3DV-RPE) method which computes position encoding for each point based on its relative position to the 3D boxes predicted by the queries in each decoder layer, thus providing clear information to guide the model to focus on points near the objects, in accordance with the principle of locality. In addition, we systematically improve the pipeline from various aspects such as data normalization based on our understanding of the task. We show exceptional results on the challenging ScanNetV2 benchmark, achieving significant improvements over the previous 3DETR in $\\rm{AP}_{25}$/$\\rm{AP}_{50}$ from 65.0\\%/47.0\\% to 77.8\\%/66.0\\%, respectively. In addition, our method sets a new record on ScanNetV2 and SUN RGB-D datasets.Code will be released at http://github.com/yichaoshen-MS/V-DETR.","sentences":["We introduce a highly performant 3D object detector for point clouds using the DETR framework.","The prior attempts all end up with suboptimal results because they fail to learn accurate inductive biases from the limited scale of training data.","In particular, the queries often attend to points that are far away from the target objects, violating the locality principle in object detection.","To address the limitation, we introduce a novel 3D Vertex Relative Position Encoding (3DV-RPE) method which computes position encoding for each point based on its relative position to the 3D boxes predicted by the queries in each decoder layer, thus providing clear information to guide the model to focus on points near the objects, in accordance with the principle of locality.","In addition, we systematically improve the pipeline from various aspects such as data normalization based on our understanding of the task.","We show exceptional results on the challenging ScanNetV2 benchmark, achieving significant improvements over the previous 3DETR in $\\rm{AP}_{25}$/$\\rm{AP}_{50}$ from 65.0\\%/47.0\\% to 77.8\\%/66.0\\%, respectively.","In addition, our method sets a new record on ScanNetV2 and SUN RGB-D datasets.","Code will be released at http://github.com/yichaoshen-MS/V-DETR."],"url":"http://arxiv.org/abs/2308.04409v1"}
{"created":"2023-08-08 17:13:09","title":"Chrisimos: A useful Proof-of-Work for finding Minimal Dominating Set of a graph","abstract":"Hash-based Proof-of-Work (PoW) used in the Bitcoin Blockchain leads to high energy consumption and resource wastage. In this paper, we aim to re-purpose the energy by replacing the hash function with real-life problems having commercial utility. We propose Chrisimos, a useful Proof-of-Work where miners are required to find a minimal dominating set for real-life graph instances. A miner who is able to output the smallest dominating set for the given graph within the block interval time wins the mining game. We also propose a new chain selection rule that ensures the security of the scheme. Thus our protocol also realizes a decentralized minimal dominating set solver for any graph instance. We provide formal proof of correctness and show via experimental results that the block interval time is within feasible bounds of hash-based PoW.","sentences":["Hash-based Proof-of-Work (PoW) used in the Bitcoin Blockchain leads to high energy consumption and resource wastage.","In this paper, we aim to re-purpose the energy by replacing the hash function with real-life problems having commercial utility.","We propose Chrisimos, a useful Proof-of-Work where miners are required to find a minimal dominating set for real-life graph instances.","A miner who is able to output the smallest dominating set for the given graph within the block interval time wins the mining game.","We also propose a new chain selection rule that ensures the security of the scheme.","Thus our protocol also realizes a decentralized minimal dominating set solver for any graph instance.","We provide formal proof of correctness and show via experimental results that the block interval time is within feasible bounds of hash-based PoW."],"url":"http://arxiv.org/abs/2308.04407v1"}
{"created":"2023-08-08 17:10:23","title":"XGBD: Explanation-Guided Graph Backdoor Detection","abstract":"Backdoor attacks pose a significant security risk to graph learning models. Backdoors can be embedded into the target model by inserting backdoor triggers into the training dataset, causing the model to make incorrect predictions when the trigger is present. To counter backdoor attacks, backdoor detection has been proposed. An emerging detection strategy in the vision and NLP domains is based on an intriguing phenomenon: when training models on a mixture of backdoor and clean samples, the loss on backdoor samples drops significantly faster than on clean samples, allowing backdoor samples to be easily detected by selecting samples with the lowest loss values. However, the ignorance of topological feature information on graph data limits its detection effectiveness when applied directly to the graph domain. To this end, we propose an explanation-guided backdoor detection method to take advantage of the topological information. Specifically, we train a helper model on the graph dataset, feed graph samples into the model, and then adopt explanation methods to attribute model prediction to an important subgraph. We observe that backdoor samples have distinct attribution distribution than clean samples, so the explanatory subgraph could serve as more discriminative features for detecting backdoor samples. Comprehensive experiments on multiple popular datasets and attack methods demonstrate the effectiveness and explainability of our method. Our code is available: https://github.com/GuanZihan/GNN_backdoor_detection.","sentences":["Backdoor attacks pose a significant security risk to graph learning models.","Backdoors can be embedded into the target model by inserting backdoor triggers into the training dataset, causing the model to make incorrect predictions when the trigger is present.","To counter backdoor attacks, backdoor detection has been proposed.","An emerging detection strategy in the vision and NLP domains is based on an intriguing phenomenon: when training models on a mixture of backdoor and clean samples, the loss on backdoor samples drops significantly faster than on clean samples, allowing backdoor samples to be easily detected by selecting samples with the lowest loss values.","However, the ignorance of topological feature information on graph data limits its detection effectiveness when applied directly to the graph domain.","To this end, we propose an explanation-guided backdoor detection method to take advantage of the topological information.","Specifically, we train a helper model on the graph dataset, feed graph samples into the model, and then adopt explanation methods to attribute model prediction to an important subgraph.","We observe that backdoor samples have distinct attribution distribution than clean samples, so the explanatory subgraph could serve as more discriminative features for detecting backdoor samples.","Comprehensive experiments on multiple popular datasets and attack methods demonstrate the effectiveness and explainability of our method.","Our code is available: https://github.com/GuanZihan/GNN_backdoor_detection."],"url":"http://arxiv.org/abs/2308.04406v1"}
{"created":"2023-08-08 17:04:53","title":"Person Re-Identification without Identification via Event Anonymization","abstract":"Wide-scale use of visual surveillance in public spaces puts individual privacy at stake while increasing resource consumption (energy, bandwidth, and computation). Neuromorphic vision sensors (event-cameras) have been recently considered a valid solution to the privacy issue because they do not capture detailed RGB visual information of the subjects in the scene. However, recent deep learning architectures have been able to reconstruct images from event cameras with high fidelity, reintroducing a potential threat to privacy for event-based vision applications. In this paper, we aim to anonymize event-streams to protect the identity of human subjects against such image reconstruction attacks. To achieve this, we propose an end-to-end network architecture jointly optimized for the twofold objective of preserving privacy and performing a downstream task such as person ReId. Our network learns to scramble events, enforcing the degradation of images recovered from the privacy attacker. In this work, we also bring to the community the first ever event-based person ReId dataset gathered to evaluate the performance of our approach. We validate our approach with extensive experiments and report results on the synthetic event data simulated from the publicly available SoftBio dataset and our proposed Event-ReId dataset.","sentences":["Wide-scale use of visual surveillance in public spaces puts individual privacy at stake while increasing resource consumption (energy, bandwidth, and computation).","Neuromorphic vision sensors (event-cameras) have been recently considered a valid solution to the privacy issue because they do not capture detailed RGB visual information of the subjects in the scene.","However, recent deep learning architectures have been able to reconstruct images from event cameras with high fidelity, reintroducing a potential threat to privacy for event-based vision applications.","In this paper, we aim to anonymize event-streams to protect the identity of human subjects against such image reconstruction attacks.","To achieve this, we propose an end-to-end network architecture jointly optimized for the twofold objective of preserving privacy and performing a downstream task such as person ReId.","Our network learns to scramble events, enforcing the degradation of images recovered from the privacy attacker.","In this work, we also bring to the community the first ever event-based person ReId dataset gathered to evaluate the performance of our approach.","We validate our approach with extensive experiments and report results on the synthetic event data simulated from the publicly available SoftBio dataset and our proposed Event-ReId dataset."],"url":"http://arxiv.org/abs/2308.04402v1"}
{"created":"2023-08-08 17:01:42","title":"Character-level NMT and language similarity","abstract":"We explore the effectiveness of character-level neural machine translation using Transformer architecture for various levels of language similarity and size of the training dataset on translation between Czech and Croatian, German, Hungarian, Slovak, and Spanish. We evaluate the models using automatic MT metrics and show that translation between similar languages benefits from character-level input segmentation, while for less related languages, character-level vanilla Transformer-base often lags behind subword-level segmentation. We confirm previous findings that it is possible to close the gap by finetuning the already trained subword-level models to character-level.","sentences":["We explore the effectiveness of character-level neural machine translation using Transformer architecture for various levels of language similarity and size of the training dataset on translation between Czech and Croatian, German, Hungarian, Slovak, and Spanish.","We evaluate the models using automatic MT metrics and show that translation between similar languages benefits from character-level input segmentation, while for less related languages, character-level vanilla Transformer-base often lags behind subword-level segmentation.","We confirm previous findings that it is possible to close the gap by finetuning the already trained subword-level models to character-level."],"url":"http://arxiv.org/abs/2308.04398v1"}
{"created":"2023-08-08 17:01:42","title":"Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models","abstract":"Major advances in Machine Learning (ML) and Artificial Intelligence (AI) increasingly take the form of developing and releasing general-purpose models. These models are designed to be adapted by other businesses and agencies to perform a particular, domain-specific function. This process has become known as adaptation or fine-tuning. This paper offers a model of the fine-tuning process where a Generalist brings the technological product (here an ML model) to a certain level of performance, and one or more Domain-specialist(s) adapts it for use in a particular domain. Both entities are profit-seeking and incur costs when they invest in the technology, and they must reach a bargaining agreement on how to share the revenue for the technology to reach the market. For a relatively general class of cost and revenue functions, we characterize the conditions under which the fine-tuning game yields a profit-sharing solution. We observe that any potential domain-specialization will either contribute, free-ride, or abstain in their uptake of the technology, and we provide conditions yielding these different strategies. We show how methods based on bargaining solutions and sub-game perfect equilibria provide insights into the strategic behavior of firms in these types of interactions, and we find that profit-sharing can still arise even when one firm has significantly higher costs than another. We also provide methods for identifying Pareto-optimal bargaining arrangements for a general set of utility functions.","sentences":["Major advances in Machine Learning (ML) and Artificial Intelligence (AI) increasingly take the form of developing and releasing general-purpose models.","These models are designed to be adapted by other businesses and agencies to perform a particular, domain-specific function.","This process has become known as adaptation or fine-tuning.","This paper offers a model of the fine-tuning process where a Generalist brings the technological product (here an ML model) to a certain level of performance, and one or more Domain-specialist(s) adapts it for use in a particular domain.","Both entities are profit-seeking and incur costs when they invest in the technology, and they must reach a bargaining agreement on how to share the revenue for the technology to reach the market.","For a relatively general class of cost and revenue functions, we characterize the conditions under which the fine-tuning game yields a profit-sharing solution.","We observe that any potential domain-specialization will either contribute, free-ride, or abstain in their uptake of the technology, and we provide conditions yielding these different strategies.","We show how methods based on bargaining solutions and sub-game perfect equilibria provide insights into the strategic behavior of firms in these types of interactions, and we find that profit-sharing can still arise even when one firm has significantly higher costs than another.","We also provide methods for identifying Pareto-optimal bargaining arrangements for a general set of utility functions."],"url":"http://arxiv.org/abs/2308.04399v1"}
{"created":"2023-08-08 17:01:33","title":"LEFormer: A Hybrid CNN-Transformer Architecture for Accurate Lake Extraction from Remote Sensing Imagery","abstract":"Lake extraction from remote sensing imagery is challenging due to the complex shapes of lakes and the presence of noise. Existing methods suffer from blurred segmentation boundaries and poor foreground modeling. In this paper, we propose a hybrid CNN-Transformer architecture, called LEFormer, for accurate lake extraction. LEFormer contains four main modules: CNN encoder, Transformer encoder, cross-encoder fusion, and lightweight decoder. The CNN encoder recovers local spatial information and improves fine-scale details. Simultaneously, the Transformer encoder captures long-range dependencies between sequences of any length, allowing them to obtain global features and context information better. Finally, a lightweight decoder is employed for mask prediction. We evaluate the performance and efficiency of LEFormer on two datasets, the Surface Water (SW) and the Qinghai-Tibet Plateau Lake (QTPL). Experimental results show that LEFormer consistently achieves state-of-the-art (SOTA) performance and efficiency on these two datasets, outperforming existing methods. Specifically, LEFormer achieves 90.86% and 97.42% mIoU on the SW and QTPL datasets with a parameter count of 3.61M, respectively, while being 20x minor than the previous SOTA method.","sentences":["Lake extraction from remote sensing imagery is challenging due to the complex shapes of lakes and the presence of noise.","Existing methods suffer from blurred segmentation boundaries and poor foreground modeling.","In this paper, we propose a hybrid CNN-Transformer architecture, called LEFormer, for accurate lake extraction.","LEFormer contains four main modules: CNN encoder, Transformer encoder, cross-encoder fusion, and lightweight decoder.","The CNN encoder recovers local spatial information and improves fine-scale details.","Simultaneously, the Transformer encoder captures long-range dependencies between sequences of any length, allowing them to obtain global features and context information better.","Finally, a lightweight decoder is employed for mask prediction.","We evaluate the performance and efficiency of LEFormer on two datasets, the Surface Water (SW) and the Qinghai-Tibet Plateau Lake (QTPL).","Experimental results show that LEFormer consistently achieves state-of-the-art (SOTA) performance and efficiency on these two datasets, outperforming existing methods.","Specifically, LEFormer achieves 90.86% and 97.42% mIoU on the SW and QTPL datasets with a parameter count of 3.61M, respectively, while being 20x minor than the previous SOTA method."],"url":"http://arxiv.org/abs/2308.04397v1"}
{"created":"2023-08-08 17:00:30","title":"Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining","abstract":"One aim of Process Mining (PM) is the discovery of process models from event logs of information systems. PM has been successfully applied to process-oriented enterprise systems but is less suited for communication- and document-oriented Enterprise Collaboration Systems (ECS). ECS event logs are very fine-granular and PM applied to their logs results in spaghetti models. A common solution for this is event abstraction, i.e., converting low-level logs into more abstract high-level logs before running discovery algorithms. ECS logs come with special characteristics that have so far not been fully addressed by existing event abstraction approaches. We aim to close this gap with a tailored ECS event abstraction (ECSEA) approach that trains a model by comparing recorded actual user activities (high-level traces) with the system-generated low-level traces (extracted from the ECS). The model allows us to automatically convert future low-level traces into an abstracted high-level log that can be used for PM. Our evaluation shows that the algorithm produces accurate results. ECSEA is a preprocessing method that is essential for the interpretation of collaborative work activity in ECS, which we call Social Process Mining.","sentences":["One aim of Process Mining (PM) is the discovery of process models from event logs of information systems.","PM has been successfully applied to process-oriented enterprise systems but is less suited for communication- and document-oriented Enterprise Collaboration Systems (ECS).","ECS event logs are very fine-granular and PM applied to their logs results in spaghetti models.","A common solution for this is event abstraction, i.e., converting low-level logs into more abstract high-level logs before running discovery algorithms.","ECS logs come with special characteristics that have so far not been fully addressed by existing event abstraction approaches.","We aim to close this gap with a tailored ECS event abstraction (ECSEA) approach that trains a model by comparing recorded actual user activities (high-level traces) with the system-generated low-level traces (extracted from the ECS).","The model allows us to automatically convert future low-level traces into an abstracted high-level log that can be used for PM.","Our evaluation shows that the algorithm produces accurate results.","ECSEA is a preprocessing method that is essential for the interpretation of collaborative work activity in ECS, which we call Social Process Mining."],"url":"http://arxiv.org/abs/2308.04396v1"}
{"created":"2023-08-08 16:52:05","title":"Let's Get Vysical: Perceptual Accuracy In Visual and Tactile Encodings","abstract":"In this paper, we explore the effectiveness of tactile data encodings using swell paper in comparison to visual encodings displayed with SVGs for data perception tasks. By replicating and adapting Cleveland and McGill's graphical perception study for the tactile modality, we establish a novel tactile encoding hierarchy. In a study with 12 university students, we found that participants perceived visual encodings more accurately when comparing values, judging their ratios with lower cognitive load, and better self-evaluated performance than tactile encodings. However, tactile encodings differed from their visual counterparts in terms of how accurately values could be decoded from them. This suggests that data physicalizations will require different design guidance than that developed for visual encodings. By providing empirical evidence for the perceptual accuracy of tactile encodings, our work contributes to foundational research on forms of data representation that prioritize tactile perception such as tactile graphics.","sentences":["In this paper, we explore the effectiveness of tactile data encodings using swell paper in comparison to visual encodings displayed with SVGs for data perception tasks.","By replicating and adapting Cleveland and McGill's graphical perception study for the tactile modality, we establish a novel tactile encoding hierarchy.","In a study with 12 university students, we found that participants perceived visual encodings more accurately when comparing values, judging their ratios with lower cognitive load, and better self-evaluated performance than tactile encodings.","However, tactile encodings differed from their visual counterparts in terms of how accurately values could be decoded from them.","This suggests that data physicalizations will require different design guidance than that developed for visual encodings.","By providing empirical evidence for the perceptual accuracy of tactile encodings, our work contributes to foundational research on forms of data representation that prioritize tactile perception such as tactile graphics."],"url":"http://arxiv.org/abs/2308.04392v1"}
{"created":"2023-08-08 16:48:08","title":"Fast Fiber Line Extraction for 2D Bivariate Scalar Fields","abstract":"Extracting level sets from scalar data is a fundamental operation in visualization with many applications. Recently, the concept of level set extraction has been extended to bivariate scalar fields. Prior work on vector field equivalence, wherein an analyst marks a region in the domain and is shown other regions in the domain with similar vector values, pointed out the need to make this extraction operation fast, so that analysts can work interactively. To date, the fast extraction of level sets from bivariate scalar fields has not been researched as extensively as for the univariate case. In this paper, we present a novel algorithm that extracts fiber lines, i.e., the preimages of so called control polygons (FSCP), for bivariate 2D data by joint traversal of bounding volume hierarchies for both grid and FSCP elements. We performed an extensive evaluation, comparing our method to a two-dimensional adaptation of the method proposed by Klacansky et al., as well as to the naive approach for fiber line extraction. The evaluation incorporates a vast array of configurations in several datasets. We found that our method provides a speedup of several orders of magnitudes compared to the naive algorithm and requires two thirds of the computation time compared to Klacansky et al. adapted for 2D.","sentences":["Extracting level sets from scalar data is a fundamental operation in visualization with many applications.","Recently, the concept of level set extraction has been extended to bivariate scalar fields.","Prior work on vector field equivalence, wherein an analyst marks a region in the domain and is shown other regions in the domain with similar vector values, pointed out the need to make this extraction operation fast, so that analysts can work interactively.","To date, the fast extraction of level sets from bivariate scalar fields has not been researched as extensively as for the univariate case.","In this paper, we present a novel algorithm that extracts fiber lines, i.e., the preimages of so called control polygons (FSCP), for bivariate 2D data by joint traversal of bounding volume hierarchies for both grid and FSCP elements.","We performed an extensive evaluation, comparing our method to a two-dimensional adaptation of the method proposed by Klacansky et al., as well as to the naive approach for fiber line extraction.","The evaluation incorporates a vast array of configurations in several datasets.","We found that our method provides a speedup of several orders of magnitudes compared to the naive algorithm and requires two thirds of the computation time compared to Klacansky et al. adapted for 2D."],"url":"http://arxiv.org/abs/2308.04389v1"}
{"created":"2023-08-08 16:41:16","title":"Learning Evaluation Models from Large Language Models for Sequence Generation","abstract":"Large language models achieve state-of-the-art performance on sequence generation evaluation, but typically have a large number of parameters. This is a computational challenge as presented by applying their evaluation capability at scale. To overcome the challenge, in this paper, we propose \\textbf{ECT}, an \\textbf{e}valuation \\textbf{c}apability \\textbf{t}ransfer method, to transfer the evaluation capability from LLMs to relatively lightweight language models. Based on the proposed ECT, we learn various evaluation models from ChatGPT, and employ them as reward models to improve sequence generation models via reinforcement learning and reranking approaches. Experimental results on machine translation, text style transfer, and summarization tasks demonstrate the effectiveness of our ECT. Notably, applying the learned evaluation models to sequence generation models results in better generated sequences as evaluated by commonly used metrics and ChatGPT.","sentences":["Large language models achieve state-of-the-art performance on sequence generation evaluation, but typically have a large number of parameters.","This is a computational challenge as presented by applying their evaluation capability at scale.","To overcome the challenge, in this paper, we propose \\textbf{ECT}, an \\textbf{e}valuation \\textbf{c}apability \\textbf{t}ransfer method, to transfer the evaluation capability from LLMs to relatively lightweight language models.","Based on the proposed ECT, we learn various evaluation models from ChatGPT, and employ them as reward models to improve sequence generation models via reinforcement learning and reranking approaches.","Experimental results on machine translation, text style transfer, and summarization tasks demonstrate the effectiveness of our ECT.","Notably, applying the learned evaluation models to sequence generation models results in better generated sequences as evaluated by commonly used metrics and ChatGPT."],"url":"http://arxiv.org/abs/2308.04386v1"}
{"created":"2023-08-08 16:37:24","title":"DELFlow: Dense Efficient Learning of Scene Flow for Large-Scale Point Clouds","abstract":"Point clouds are naturally sparse, while image pixels are dense. The inconsistency limits feature fusion from both modalities for point-wise scene flow estimation. Previous methods rarely predict scene flow from the entire point clouds of the scene with one-time inference due to the memory inefficiency and heavy overhead from distance calculation and sorting involved in commonly used farthest point sampling, KNN, and ball query algorithms for local feature aggregation. To mitigate these issues in scene flow learning, we regularize raw points to a dense format by storing 3D coordinates in 2D grids. Unlike the sampling operation commonly used in existing works, the dense 2D representation 1) preserves most points in the given scene, 2) brings in a significant boost of efficiency, and 3) eliminates the density gap between points and pixels, allowing us to perform effective feature fusion. We also present a novel warping projection technique to alleviate the information loss problem resulting from the fact that multiple points could be mapped into one grid during projection when computing cost volume. Sufficient experiments demonstrate the efficiency and effectiveness of our method, outperforming the prior-arts on the FlyingThings3D and KITTI dataset.","sentences":["Point clouds are naturally sparse, while image pixels are dense.","The inconsistency limits feature fusion from both modalities for point-wise scene flow estimation.","Previous methods rarely predict scene flow from the entire point clouds of the scene with one-time inference due to the memory inefficiency and heavy overhead from distance calculation and sorting involved in commonly used farthest point sampling, KNN, and ball query algorithms for local feature aggregation.","To mitigate these issues in scene flow learning, we regularize raw points to a dense format by storing 3D coordinates in 2D grids.","Unlike the sampling operation commonly used in existing works, the dense 2D representation 1) preserves most points in the given scene, 2) brings in a significant boost of efficiency, and 3) eliminates the density gap between points and pixels, allowing us to perform effective feature fusion.","We also present a novel warping projection technique to alleviate the information loss problem resulting from the fact that multiple points could be mapped into one grid during projection when computing cost volume.","Sufficient experiments demonstrate the efficiency and effectiveness of our method, outperforming the prior-arts on the FlyingThings3D and KITTI dataset."],"url":"http://arxiv.org/abs/2308.04383v1"}
{"created":"2023-08-08 16:31:43","title":"Your Negative May not Be True Negative: Boosting Image-Text Matching with False Negative Elimination","abstract":"Most existing image-text matching methods adopt triplet loss as the optimization objective, and choosing a proper negative sample for the triplet of <anchor, positive, negative> is important for effectively training the model, e.g., hard negatives make the model learn efficiently and effectively. However, we observe that existing methods mainly employ the most similar samples as hard negatives, which may not be true negatives. In other words, the samples with high similarity but not paired with the anchor may reserve positive semantic associations, and we call them false negatives. Repelling these false negatives in triplet loss would mislead the semantic representation learning and result in inferior retrieval performance. In this paper, we propose a novel False Negative Elimination (FNE) strategy to select negatives via sampling, which could alleviate the problem introduced by false negatives. Specifically, we first construct the distributions of positive and negative samples separately via their similarities with the anchor, based on the features extracted from image and text encoders. Then we calculate the false negative probability of a given sample based on its similarity with the anchor and the above distributions via the Bayes' rule, which is employed as the sampling weight during negative sampling process. Since there may not exist any false negative in a small batch size, we design a memory module with momentum to retain a large negative buffer and implement our negative sampling strategy spanning over the buffer. In addition, to make the model focus on hard negatives, we reassign the sampling weights for the simple negatives with a cut-down strategy. The extensive experiments are conducted on Flickr30K and MS-COCO, and the results demonstrate the superiority of our proposed false negative elimination strategy. The code is available at https://github.com/LuminosityX/FNE.","sentences":["Most existing image-text matching methods adopt triplet loss as the optimization objective, and choosing a proper negative sample for the triplet of <anchor, positive, negative> is important for effectively training the model, e.g., hard negatives make the model learn efficiently and effectively.","However, we observe that existing methods mainly employ the most similar samples as hard negatives, which may not be true negatives.","In other words, the samples with high similarity but not paired with the anchor may reserve positive semantic associations, and we call them false negatives.","Repelling these false negatives in triplet loss would mislead the semantic representation learning and result in inferior retrieval performance.","In this paper, we propose a novel False Negative Elimination (FNE) strategy to select negatives via sampling, which could alleviate the problem introduced by false negatives.","Specifically, we first construct the distributions of positive and negative samples separately via their similarities with the anchor, based on the features extracted from image and text encoders.","Then we calculate the false negative probability of a given sample based on its similarity with the anchor and the above distributions via the Bayes' rule, which is employed as the sampling weight during negative sampling process.","Since there may not exist any false negative in a small batch size, we design a memory module with momentum to retain a large negative buffer and implement our negative sampling strategy spanning over the buffer.","In addition, to make the model focus on hard negatives, we reassign the sampling weights for the simple negatives with a cut-down strategy.","The extensive experiments are conducted on Flickr30K and MS-COCO, and the results demonstrate the superiority of our proposed false negative elimination strategy.","The code is available at https://github.com/LuminosityX/FNE."],"url":"http://arxiv.org/abs/2308.04380v1"}
{"created":"2023-08-08 16:30:42","title":"Who Re-Uses Data? A Bibliometric Analysis of Dataset Citations","abstract":"Open data is receiving increased attention and support in academic environments, with one justification being that shared data may be re-used in further research. But what evidence exists for such re-use, and what is the relationship between the producers of shared datasets and researchers who use them? Using a sample of data citations from OpenAlex, this study investigates the relationship between creators and citers of datasets at the individual, institutional, and national levels. We find that the vast majority of datasets have no recorded citations, and that most cited datasets only have a single citation. Rates of self-citation by individuals and institutions tend towards the low end of previous findings and vary widely across disciplines. At the country level, the United States is by far the most prominent exporter of re-used datasets, while importation is more evenly distributed. Understanding where and how the sharing of data between researchers, institutions, and countries takes place is essential to developing open research practices.","sentences":["Open data is receiving increased attention and support in academic environments, with one justification being that shared data may be re-used in further research.","But what evidence exists for such re-use, and what is the relationship between the producers of shared datasets and researchers who use them?","Using a sample of data citations from OpenAlex, this study investigates the relationship between creators and citers of datasets at the individual, institutional, and national levels.","We find that the vast majority of datasets have no recorded citations, and that most cited datasets only have a single citation.","Rates of self-citation by individuals and institutions tend towards the low end of previous findings and vary widely across disciplines.","At the country level, the United States is by far the most prominent exporter of re-used datasets, while importation is more evenly distributed.","Understanding where and how the sharing of data between researchers, institutions, and countries takes place is essential to developing open research practices."],"url":"http://arxiv.org/abs/2308.04379v1"}
{"created":"2023-08-08 16:23:46","title":"Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making","abstract":"Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g. health). However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human AI complementary performance. In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making. We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations. Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their performance and agreement level on the task when `right' AI outputs are presented. While both therapists and laypersons over-relied on `wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on `wrong' AI outputs by 21\\% compared to salient feature explanations. Specifically, laypersons had higher performance degrades by 18.0 f1-score with salient feature explanations and 14.0 f1-score with counterfactual explanations than therapists with performance degrades of 8.6 and 2.8 f1-scores respectively. Our work discusses the potential of counterfactual explanations to better estimate the accuracy of an AI model and reduce over-reliance on `wrong' AI outputs and implications for improving human-AI collaborative decision-making.","sentences":["Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g. health).","However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human AI complementary performance.","In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making.","We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations.","Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their performance and agreement level on the task when `right' AI outputs are presented.","While both therapists and laypersons over-relied on `wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on `wrong' AI outputs by 21\\% compared to salient feature explanations.","Specifically, laypersons had higher performance degrades by 18.0 f1-score with salient feature explanations and 14.0 f1-score with counterfactual explanations than therapists with performance degrades of 8.6 and 2.8 f1-scores respectively.","Our work discusses the potential of counterfactual explanations to better estimate the accuracy of an AI model and reduce over-reliance on `wrong' AI outputs and implications for improving human-AI collaborative decision-making."],"url":"http://arxiv.org/abs/2308.04375v1"}
{"created":"2023-08-08 16:22:44","title":"Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning","abstract":"The main premise of federated learning is that machine learning model updates are computed locally, in particular to preserve user data privacy, as those never leave the perimeter of their device. This mechanism supposes the general model, once aggregated, to be broadcast to collaborating and non malicious nodes. However, without proper defenses, compromised clients can easily probe the model inside their local memory in search of adversarial examples. For instance, considering image-based applications, adversarial examples consist of imperceptibly perturbed images (to the human eye) misclassified by the local model, which can be later presented to a victim node's counterpart model to replicate the attack. To mitigate such malicious probing, we introduce Pelta, a novel shielding mechanism leveraging trusted hardware. By harnessing the capabilities of Trusted Execution Environments (TEEs), Pelta masks part of the back-propagation chain rule, otherwise typically exploited by attackers for the design of malicious samples. We evaluate Pelta on a state of the art ensemble model and demonstrate its effectiveness against the Self Attention Gradient adversarial Attack.","sentences":["The main premise of federated learning is that machine learning model updates are computed locally, in particular to preserve user data privacy, as those never leave the perimeter of their device.","This mechanism supposes the general model, once aggregated, to be broadcast to collaborating and non malicious nodes.","However, without proper defenses, compromised clients can easily probe the model inside their local memory in search of adversarial examples.","For instance, considering image-based applications, adversarial examples consist of imperceptibly perturbed images (to the human eye) misclassified by the local model, which can be later presented to a victim node's counterpart model to replicate the attack.","To mitigate such malicious probing, we introduce Pelta, a novel shielding mechanism leveraging trusted hardware.","By harnessing the capabilities of Trusted Execution Environments (TEEs), Pelta masks part of the back-propagation chain rule, otherwise typically exploited by attackers for the design of malicious samples.","We evaluate Pelta on a state of the art ensemble model and demonstrate its effectiveness against the Self Attention Gradient adversarial Attack."],"url":"http://arxiv.org/abs/2308.04373v1"}
{"created":"2023-08-08 16:22:27","title":"Some Options for Instantiation of Bipolar Argument Graphs with Deductive Arguments","abstract":"Argument graphs provide an abstract representation of an argumentative situation. A bipolar argument graph is a directed graph where each node denotes an argument, and each arc denotes the influence of one argument on another. Here we assume that the influence is supporting, attacking, or ambiguous. In a bipolar argument graph, each argument is atomic and so it has no internal structure. Yet to better understand the nature of the individual arguments, and how they interact, it is important to consider their internal structure. To address this need, this paper presents a framework based on the use of logical arguments to instantiate bipolar argument graphs, and a set of possible constraints on instantiating arguments that take into account the internal structure of the arguments, and the types of relationship between arguments.","sentences":["Argument graphs provide an abstract representation of an argumentative situation.","A bipolar argument graph is a directed graph where each node denotes an argument, and each arc denotes the influence of one argument on another.","Here we assume that the influence is supporting, attacking, or ambiguous.","In a bipolar argument graph, each argument is atomic and so it has no internal structure.","Yet to better understand the nature of the individual arguments, and how they interact, it is important to consider their internal structure.","To address this need, this paper presents a framework based on the use of logical arguments to instantiate bipolar argument graphs, and a set of possible constraints on instantiating arguments that take into account the internal structure of the arguments, and the types of relationship between arguments."],"url":"http://arxiv.org/abs/2308.04372v1"}
{"created":"2023-08-08 16:18:20","title":"Cumulative Reasoning With Large Language Models","abstract":"While language models are powerful and versatile, they often fail to address highly complex problems. This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training. In this paper, we propose a new method called Cumulative Reasoning (CR), which employs language models in a cumulative and iterative manner to emulate human thought processes. By decomposing tasks into smaller components, \\ournameb streamlines the problem-solving process, rendering it both more manageable and effective. For logical inference tasks, CR consistently outperforms existing methods with an improvement up to 9.3\\%, and achieves the astonishing accuracy of 98.04\\% on the curated FOLIO wiki dataset. In the context of the Game of 24, CR achieves an accuracy of 94\\%, which signifies a substantial enhancement of 20\\% over the previous state-of-the-art method.","sentences":["While language models are powerful and versatile, they often fail to address highly complex problems.","This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training.","In this paper, we propose a new method called Cumulative Reasoning (CR), which employs language models in a cumulative and iterative manner to emulate human thought processes.","By decomposing tasks into smaller components, \\ournameb streamlines the problem-solving process, rendering it both more manageable and effective.","For logical inference tasks, CR consistently outperforms existing methods with an improvement up to 9.3\\%, and achieves the astonishing accuracy of 98.04\\% on the curated FOLIO wiki dataset.","In the context of the Game of 24, CR achieves an accuracy of 94\\%, which signifies a substantial enhancement of 20\\% over the previous state-of-the-art method."],"url":"http://arxiv.org/abs/2308.04371v1"}
{"created":"2023-08-08 16:17:46","title":"When Super-Resolution Meets Camouflaged Object Detection: A Comparison Study","abstract":"Super Resolution (SR) and Camouflaged Object Detection (COD) are two hot topics in computer vision with various joint applications. For instance, low-resolution surveillance images can be successively processed by super-resolution techniques and camouflaged object detection. However, in previous work, these two areas are always studied in isolation. In this paper, we, for the first time, conduct an integrated comparative evaluation for both. Specifically, we benchmark different super-resolution methods on commonly used COD datasets, and meanwhile, we evaluate the robustness of different COD models by using COD data processed by SR methods. Our goal is to bridge these two domains, discover novel experimental phenomena, summarize new experim.","sentences":["Super Resolution (SR) and Camouflaged Object Detection (COD) are two hot topics in computer vision with various joint applications.","For instance, low-resolution surveillance images can be successively processed by super-resolution techniques and camouflaged object detection.","However, in previous work, these two areas are always studied in isolation.","In this paper, we, for the first time, conduct an integrated comparative evaluation for both.","Specifically, we benchmark different super-resolution methods on commonly used COD datasets, and meanwhile, we evaluate the robustness of different COD models by using COD data processed by SR methods.","Our goal is to bridge these two domains, discover novel experimental phenomena, summarize new experim."],"url":"http://arxiv.org/abs/2308.04370v1"}
{"created":"2023-08-08 16:15:35","title":"SSTFormer: Bridging Spiking Neural Network and Memory Support Transformer for Frame-Event based Recognition","abstract":"Event camera-based pattern recognition is a newly arising research topic in recent years. Current researchers usually transform the event streams into images, graphs, or voxels, and adopt deep neural networks for event-based classification. Although good performance can be achieved on simple event recognition datasets, however, their results may be still limited due to the following two issues. Firstly, they adopt spatial sparse event streams for recognition only, which may fail to capture the color and detailed texture information well. Secondly, they adopt either Spiking Neural Networks (SNN) for energy-efficient recognition with suboptimal results, or Artificial Neural Networks (ANN) for energy-intensive, high-performance recognition. However, seldom of them consider achieving a balance between these two aspects. In this paper, we formally propose to recognize patterns by fusing RGB frames and event streams simultaneously and propose a new RGB frame-event recognition framework to address the aforementioned issues. The proposed method contains four main modules, i.e., memory support Transformer network for RGB frame encoding, spiking neural network for raw event stream encoding, multi-modal bottleneck fusion module for RGB-Event feature aggregation, and prediction head. Due to the scarce of RGB-Event based classification dataset, we also propose a large-scale PokerEvent dataset which contains 114 classes, and 27102 frame-event pairs recorded using a DVS346 event camera. Extensive experiments on two RGB-Event based classification datasets fully validated the effectiveness of our proposed framework. We hope this work will boost the development of pattern recognition by fusing RGB frames and event streams. Both our dataset and source code of this work will be released at https://github.com/Event-AHU/SSTFormer.","sentences":["Event camera-based pattern recognition is a newly arising research topic in recent years.","Current researchers usually transform the event streams into images, graphs, or voxels, and adopt deep neural networks for event-based classification.","Although good performance can be achieved on simple event recognition datasets, however, their results may be still limited due to the following two issues.","Firstly, they adopt spatial sparse event streams for recognition only, which may fail to capture the color and detailed texture information well.","Secondly, they adopt either Spiking Neural Networks (SNN) for energy-efficient recognition with suboptimal results, or Artificial Neural Networks (ANN) for energy-intensive, high-performance recognition.","However, seldom of them consider achieving a balance between these two aspects.","In this paper, we formally propose to recognize patterns by fusing RGB frames and event streams simultaneously and propose a new RGB frame-event recognition framework to address the aforementioned issues.","The proposed method contains four main modules, i.e., memory support Transformer network for RGB frame encoding, spiking neural network for raw event stream encoding, multi-modal bottleneck fusion module for RGB-Event feature aggregation, and prediction head.","Due to the scarce of RGB-Event based classification dataset, we also propose a large-scale PokerEvent dataset which contains 114 classes, and 27102 frame-event pairs recorded using a DVS346 event camera.","Extensive experiments on two RGB-Event based classification datasets fully validated the effectiveness of our proposed framework.","We hope this work will boost the development of pattern recognition by fusing RGB frames and event streams.","Both our dataset and source code of this work will be released at https://github.com/Event-AHU/SSTFormer."],"url":"http://arxiv.org/abs/2308.04369v1"}
{"created":"2023-08-08 16:04:48","title":"The Inverse Transparency Toolchain: A Fully Integrated and Quickly Deployable Data Usage Logging Infrastructure","abstract":"Inverse transparency is created by making all usages of employee data visible to them. This requires tools that handle the logging and storage of usage information, and making logged data visible to data owners. For research and teaching contexts that integrate inverse transparency, creating this required infrastructure can be challenging. The Inverse Transparency Toolchain presents a flexible solution for such scenarios. It can be easily deployed and is tightly integrated. With it, we successfully handled use cases covering empirical studies with users, prototyping in university courses, and experimentation with our industry partner.","sentences":["Inverse transparency is created by making all usages of employee data visible to them.","This requires tools that handle the logging and storage of usage information, and making logged data visible to data owners.","For research and teaching contexts that integrate inverse transparency, creating this required infrastructure can be challenging.","The Inverse Transparency Toolchain presents a flexible solution for such scenarios.","It can be easily deployed and is tightly integrated.","With it, we successfully handled use cases covering empirical studies with users, prototyping in university courses, and experimentation with our industry partner."],"url":"http://arxiv.org/abs/2308.04366v1"}
{"created":"2023-08-08 16:01:11","title":"Learning Unbiased Image Segmentation: A Case Study with Plain Knee Radiographs","abstract":"Automatic segmentation of knee bony anatomy is essential in orthopedics, and it has been around for several years in both pre-operative and post-operative settings. While deep learning algorithms have demonstrated exceptional performance in medical image analysis, the assessment of fairness and potential biases within these models remains limited. This study aims to revisit deep learning-powered knee-bony anatomy segmentation using plain radiographs to uncover visible gender and racial biases. The current contribution offers the potential to advance our understanding of biases, and it provides practical insights for researchers and practitioners in medical imaging. The proposed mitigation strategies mitigate gender and racial biases, ensuring fair and unbiased segmentation results. Furthermore, this work promotes equal access to accurate diagnoses and treatment outcomes for diverse patient populations, fostering equitable and inclusive healthcare provision.","sentences":["Automatic segmentation of knee bony anatomy is essential in orthopedics, and it has been around for several years in both pre-operative and post-operative settings.","While deep learning algorithms have demonstrated exceptional performance in medical image analysis, the assessment of fairness and potential biases within these models remains limited.","This study aims to revisit deep learning-powered knee-bony anatomy segmentation using plain radiographs to uncover visible gender and racial biases.","The current contribution offers the potential to advance our understanding of biases, and it provides practical insights for researchers and practitioners in medical imaging.","The proposed mitigation strategies mitigate gender and racial biases, ensuring fair and unbiased segmentation results.","Furthermore, this work promotes equal access to accurate diagnoses and treatment outcomes for diverse patient populations, fostering equitable and inclusive healthcare provision."],"url":"http://arxiv.org/abs/2308.04356v1"}
{"created":"2023-08-08 15:59:17","title":"3D-VisTA: Pre-trained Transformer for 3D Vision and Text Alignment","abstract":"3D vision-language grounding (3D-VL) is an emerging field that aims to connect the 3D physical world with natural language, which is crucial for achieving embodied intelligence. Current 3D-VL models rely heavily on sophisticated modules, auxiliary losses, and optimization tricks, which calls for a simple and unified model. In this paper, we propose 3D-VisTA, a pre-trained Transformer for 3D Vision and Text Alignment that can be easily adapted to various downstream tasks. 3D-VisTA simply utilizes self-attention layers for both single-modal modeling and multi-modal fusion without any sophisticated task-specific design. To further enhance its performance on 3D-VL tasks, we construct ScanScribe, the first large-scale 3D scene-text pairs dataset for 3D-VL pre-training. ScanScribe contains 2,995 RGB-D scans for 1,185 unique indoor scenes originating from ScanNet and 3R-Scan datasets, along with paired 278K scene descriptions generated from existing 3D-VL tasks, templates, and GPT-3. 3D-VisTA is pre-trained on ScanScribe via masked language/object modeling and scene-text matching. It achieves state-of-the-art results on various 3D-VL tasks, ranging from visual grounding and dense captioning to question answering and situated reasoning. Moreover, 3D-VisTA demonstrates superior data efficiency, obtaining strong performance even with limited annotations during downstream task fine-tuning.","sentences":["3D vision-language grounding (3D-VL) is an emerging field that aims to connect the 3D physical world with natural language, which is crucial for achieving embodied intelligence.","Current 3D-VL models rely heavily on sophisticated modules, auxiliary losses, and optimization tricks, which calls for a simple and unified model.","In this paper, we propose 3D-VisTA, a pre-trained Transformer for 3D Vision and Text Alignment that can be easily adapted to various downstream tasks.","3D-VisTA simply utilizes self-attention layers for both single-modal modeling and multi-modal fusion without any sophisticated task-specific design.","To further enhance its performance on 3D-VL tasks, we construct ScanScribe, the first large-scale 3D scene-text pairs dataset for 3D-VL pre-training.","ScanScribe contains 2,995 RGB-D scans for 1,185 unique indoor scenes originating from ScanNet and 3R-Scan datasets, along with paired 278K scene descriptions generated from existing 3D-VL tasks, templates, and GPT-3.","3D-VisTA is pre-trained on ScanScribe via masked language/object modeling and scene-text matching.","It achieves state-of-the-art results on various 3D-VL tasks, ranging from visual grounding and dense captioning to question answering and situated reasoning.","Moreover, 3D-VisTA demonstrates superior data efficiency, obtaining strong performance even with limited annotations during downstream task fine-tuning."],"url":"http://arxiv.org/abs/2308.04352v1"}
{"created":"2023-08-08 15:46:27","title":"Unmasking Nationality Bias: A Study of Human Perception of Nationalities in AI-Generated Articles","abstract":"We investigate the potential for nationality biases in natural language processing (NLP) models using human evaluation methods. Biased NLP models can perpetuate stereotypes and lead to algorithmic discrimination, posing a significant challenge to the fairness and justice of AI systems. Our study employs a two-step mixed-methods approach that includes both quantitative and qualitative analysis to identify and understand the impact of nationality bias in a text generation model. Through our human-centered quantitative analysis, we measure the extent of nationality bias in articles generated by AI sources. We then conduct open-ended interviews with participants, performing qualitative coding and thematic analysis to understand the implications of these biases on human readers. Our findings reveal that biased NLP models tend to replicate and amplify existing societal biases, which can translate to harm if used in a sociotechnical setting. The qualitative analysis from our interviews offers insights into the experience readers have when encountering such articles, highlighting the potential to shift a reader's perception of a country. These findings emphasize the critical role of public perception in shaping AI's impact on society and the need to correct biases in AI systems.","sentences":["We investigate the potential for nationality biases in natural language processing (NLP) models using human evaluation methods.","Biased NLP models can perpetuate stereotypes and lead to algorithmic discrimination, posing a significant challenge to the fairness and justice of AI systems.","Our study employs a two-step mixed-methods approach that includes both quantitative and qualitative analysis to identify and understand the impact of nationality bias in a text generation model.","Through our human-centered quantitative analysis, we measure the extent of nationality bias in articles generated by AI sources.","We then conduct open-ended interviews with participants, performing qualitative coding and thematic analysis to understand the implications of these biases on human readers.","Our findings reveal that biased NLP models tend to replicate and amplify existing societal biases, which can translate to harm if used in a sociotechnical setting.","The qualitative analysis from our interviews offers insights into the experience readers have when encountering such articles, highlighting the potential to shift a reader's perception of a country.","These findings emphasize the critical role of public perception in shaping AI's impact on society and the need to correct biases in AI systems."],"url":"http://arxiv.org/abs/2308.04346v1"}
{"created":"2023-08-08 15:45:55","title":"Fair and Inclusive Participatory Budgeting: Voter Experience with Cumulative and Quadratic Voting Interfaces","abstract":"Cumulative and quadratic voting are two distributional voting methods that are expressive, promoting fairness and inclusion, particularly in the realm of participatory budgeting. Despite these benefits, graphical voter interfaces for cumulative and quadratic voting are complex to implement and use effectively. As a result, such methods have not seen yet widespread adoption on digital voting platforms. This paper addresses the challenge by introducing an implementation and evaluation of cumulative and quadratic voting within a state-of-the-art voting platform: Stanford Participatory Budgeting. The findings of the study show that while voters prefer simple methods, the more expressive (and complex) cumulative voting becomes the preferred one compared to k-ranking voting that is simpler but less expressive. The implemented voting interface elements are found useful and support the observed voters' preferences for more expressive voting methods. *","sentences":["Cumulative and quadratic voting are two distributional voting methods that are expressive, promoting fairness and inclusion, particularly in the realm of participatory budgeting.","Despite these benefits, graphical voter interfaces for cumulative and quadratic voting are complex to implement and use effectively.","As a result, such methods have not seen yet widespread adoption on digital voting platforms.","This paper addresses the challenge by introducing an implementation and evaluation of cumulative and quadratic voting within a state-of-the-art voting platform: Stanford Participatory Budgeting.","The findings of the study show that while voters prefer simple methods, the more expressive (and complex) cumulative voting becomes the preferred one compared to k-ranking voting that is simpler but less expressive.","The implemented voting interface elements are found useful and support the observed voters' preferences for more expressive voting methods.","*"],"url":"http://arxiv.org/abs/2308.04345v1"}
{"created":"2023-08-08 15:43:59","title":"Unifying Two-Stream Encoders with Transformers for Cross-Modal Retrieval","abstract":"Most existing cross-modal retrieval methods employ two-stream encoders with different architectures for images and texts, \\textit{e.g.}, CNN for images and RNN/Transformer for texts. Such discrepancy in architectures may induce different semantic distribution spaces and limit the interactions between images and texts, and further result in inferior alignment between images and texts. To fill this research gap, inspired by recent advances of Transformers in vision tasks, we propose to unify the encoder architectures with Transformers for both modalities. Specifically, we design a cross-modal retrieval framework purely based on two-stream Transformers, dubbed \\textbf{Hierarchical Alignment Transformers (HAT)}, which consists of an image Transformer, a text Transformer, and a hierarchical alignment module. With such identical architectures, the encoders could produce representations with more similar characteristics for images and texts, and make the interactions and alignments between them much easier. Besides, to leverage the rich semantics, we devise a hierarchical alignment scheme to explore multi-level correspondences of different layers between images and texts. To evaluate the effectiveness of the proposed HAT, we conduct extensive experiments on two benchmark datasets, MSCOCO and Flickr30K. Experimental results demonstrate that HAT outperforms SOTA baselines by a large margin. Specifically, on two key tasks, \\textit{i.e.}, image-to-text and text-to-image retrieval, HAT achieves 7.6\\% and 16.7\\% relative score improvement of Recall@1 on MSCOCO, and 4.4\\% and 11.6\\% on Flickr30k respectively. The code is available at \\url{https://github.com/LuminosityX/HAT}.","sentences":["Most existing cross-modal retrieval methods employ two-stream encoders with different architectures for images and texts, \\textit{e.g.}, CNN for images and RNN/Transformer for texts.","Such discrepancy in architectures may induce different semantic distribution spaces and limit the interactions between images and texts, and further result in inferior alignment between images and texts.","To fill this research gap, inspired by recent advances of Transformers in vision tasks, we propose to unify the encoder architectures with Transformers for both modalities.","Specifically, we design a cross-modal retrieval framework purely based on two-stream Transformers, dubbed \\textbf{Hierarchical Alignment Transformers (HAT)}, which consists of an image Transformer, a text Transformer, and a hierarchical alignment module.","With such identical architectures, the encoders could produce representations with more similar characteristics for images and texts, and make the interactions and alignments between them much easier.","Besides, to leverage the rich semantics, we devise a hierarchical alignment scheme to explore multi-level correspondences of different layers between images and texts.","To evaluate the effectiveness of the proposed HAT, we conduct extensive experiments on two benchmark datasets, MSCOCO and Flickr30K. Experimental results demonstrate that HAT outperforms SOTA baselines by a large margin.","Specifically, on two key tasks, \\textit{i.e.}, image-to-text and text-to-image retrieval, HAT achieves 7.6\\% and 16.7\\% relative score improvement of Recall@1 on MSCOCO, and 4.4\\% and 11.6\\% on Flickr30k respectively.","The code is available at \\url{https://github.com/LuminosityX/HAT}."],"url":"http://arxiv.org/abs/2308.04343v1"}
{"created":"2023-08-08 15:38:55","title":"Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage","abstract":"Machine learning models are increasingly utilized across impactful domains to predict individual outcomes. As such, many models provide algorithmic recourse to individuals who receive negative outcomes. However, recourse can be leveraged by adversaries to disclose private information. This work presents the first attempt at mitigating such attacks. We present two novel methods to generate differentially private recourse: Differentially Private Model (DPM) and Laplace Recourse (LR). Using logistic regression classifiers and real world and synthetic datasets, we find that DPM and LR perform well in reducing what an adversary can infer, especially at low FPR. When training dataset size is large enough, we find particular success in preventing privacy leakage while maintaining model and recourse accuracy with our novel LR method.","sentences":["Machine learning models are increasingly utilized across impactful domains to predict individual outcomes.","As such, many models provide algorithmic recourse to individuals who receive negative outcomes.","However, recourse can be leveraged by adversaries to disclose private information.","This work presents the first attempt at mitigating such attacks.","We present two novel methods to generate differentially private recourse: Differentially Private Model (DPM) and Laplace Recourse (LR).","Using logistic regression classifiers and real world and synthetic datasets, we find that DPM and LR perform well in reducing what an adversary can infer, especially at low FPR.","When training dataset size is large enough, we find particular success in preventing privacy leakage while maintaining model and recourse accuracy with our novel LR method."],"url":"http://arxiv.org/abs/2308.04341v1"}
{"created":"2023-08-08 15:36:57","title":"A Lightweight and Accurate Face Detection Algorithm Based on Retinaface","abstract":"In this paper, we propose a lightweight and accurate face detection algorithm LAFD (Light and accurate face detection) based on Retinaface. Backbone network in the algorithm is a modified MobileNetV3 network which adjusts the size of the convolution kernel, the channel expansion multiplier of the inverted residuals block and the use of the SE attention mechanism. Deformable convolution network(DCN) is introduced in the context module and the algorithm uses focal loss function instead of cross-entropy loss function as the classification loss function of the model. The test results on the WIDERFACE dataset indicate that the average accuracy of LAFD is 94.1%, 92.2% and 82.1% for the \"easy\", \"medium\" and \"hard\" validation subsets respectively with an improvement of 3.4%, 4.0% and 8.3% compared to Retinaface and 3.1%, 4.1% and 4.1% higher than the well-performing lightweight model, LFFD. If the input image is pre-processed and scaled to 1560px in length or 1200px in width, the model achieves an average accuracy of 86.2% on the 'hard' validation subset. The model is lightweight, with a size of only 10.2MB.","sentences":["In this paper, we propose a lightweight and accurate face detection algorithm LAFD (Light and accurate face detection) based on Retinaface.","Backbone network in the algorithm is a modified MobileNetV3 network which adjusts the size of the convolution kernel, the channel expansion multiplier of the inverted residuals block and the use of the SE attention mechanism.","Deformable convolution network(DCN) is introduced in the context module and the algorithm uses focal loss function instead of cross-entropy loss function as the classification loss function of the model.","The test results on the WIDERFACE dataset indicate that the average accuracy of LAFD is 94.1%, 92.2% and 82.1% for the \"easy\", \"medium\" and \"hard\" validation subsets respectively with an improvement of 3.4%, 4.0% and 8.3% compared to Retinaface and 3.1%, 4.1% and 4.1% higher than the well-performing lightweight model, LFFD.","If the input image is pre-processed and scaled to 1560px in length or 1200px in width, the model achieves an average accuracy of 86.2% on the 'hard' validation subset.","The model is lightweight, with a size of only 10.2MB."],"url":"http://arxiv.org/abs/2308.04340v1"}
{"created":"2023-08-08 15:30:08","title":"Pengembangan Model untuk Mendeteksi Kerusakan pada Terumbu Karang dengan Klasifikasi Citra","abstract":"The abundant biodiversity of coral reefs in Indonesian waters is a valuable asset that needs to be preserved. Rapid climate change and uncontrolled human activities have led to the degradation of coral reef ecosystems, including coral bleaching, which is a critical indicator of coral health conditions. Therefore, this research aims to develop an accurate classification model to distinguish between healthy corals and corals experiencing bleaching. This study utilizes a specialized dataset consisting of 923 images collected from Flickr using the Flickr API. The dataset comprises two distinct classes: healthy corals (438 images) and bleached corals (485 images). These images have been resized to a maximum of 300 pixels in width or height, whichever is larger, to maintain consistent sizes across the dataset.   The method employed in this research involves the use of machine learning models, particularly convolutional neural networks (CNN), to recognize and differentiate visual patterns associated with healthy and bleached corals. In this context, the dataset can be used to train and test various classification models to achieve optimal results. By leveraging the ResNet model, it was found that a from-scratch ResNet model can outperform pretrained models in terms of precision and accuracy. The success in developing accurate classification models will greatly benefit researchers and marine biologists in gaining a better understanding of coral reef health. These models can also be employed to monitor changes in the coral reef environment, thereby making a significant contribution to conservation and ecosystem restoration efforts that have far-reaching impacts on life.","sentences":["The abundant biodiversity of coral reefs in Indonesian waters is a valuable asset that needs to be preserved.","Rapid climate change and uncontrolled human activities have led to the degradation of coral reef ecosystems, including coral bleaching, which is a critical indicator of coral health conditions.","Therefore, this research aims to develop an accurate classification model to distinguish between healthy corals and corals experiencing bleaching.","This study utilizes a specialized dataset consisting of 923 images collected from Flickr using the Flickr API.","The dataset comprises two distinct classes: healthy corals (438 images) and bleached corals (485 images).","These images have been resized to a maximum of 300 pixels in width or height, whichever is larger, to maintain consistent sizes across the dataset.   ","The method employed in this research involves the use of machine learning models, particularly convolutional neural networks (CNN), to recognize and differentiate visual patterns associated with healthy and bleached corals.","In this context, the dataset can be used to train and test various classification models to achieve optimal results.","By leveraging the ResNet model, it was found that a from-scratch ResNet model can outperform pretrained models in terms of precision and accuracy.","The success in developing accurate classification models will greatly benefit researchers and marine biologists in gaining a better understanding of coral reef health.","These models can also be employed to monitor changes in the coral reef environment, thereby making a significant contribution to conservation and ecosystem restoration efforts that have far-reaching impacts on life."],"url":"http://arxiv.org/abs/2308.04337v1"}
{"created":"2023-08-08 15:30:07","title":"On the concentration of the maximum degree in the duplication-divergence models","abstract":"We present a rigorous and precise analysis of the maximum degree and the average degree in a dynamic duplication-divergence graph model introduced by Sol\\'e, Pastor-Satorras et al. in which the graph grows according to a duplication-divergence mechanism, i.e. by iteratively creating a copy of some node and then randomly alternating the neighborhood of a new node with probability $p$. This model captures the growth of some real-world processes e.g. biological or social networks.   In this paper, we prove that for some $0 < p < 1$ the maximum degree and the average degree of a duplication-divergence graph on $t$ vertices are asymptotically concentrated with high probability around $t^p$ and $\\max\\{t^{2 p - 1}, 1\\}$, respectively, i.e. they are within at most a polylogarithmic factor from these values with probability at least $1 - t^{-A}$ for any constant $A > 0$.","sentences":["We present a rigorous and precise analysis of the maximum degree and the average degree in a dynamic duplication-divergence graph model introduced by Sol\\'e, Pastor-Satorras et al. in which the graph grows according to a duplication-divergence mechanism, i.e. by iteratively creating a copy of some node and then randomly alternating the neighborhood of a new node with probability $p$. This model captures the growth of some real-world processes e.g. biological or social networks.   ","In this paper, we prove that for some $0 < p < 1$ the maximum degree and the average degree of a duplication-divergence graph on $t$ vertices are asymptotically concentrated with high probability around $t^p$ and","$\\max\\{t^{2 p - 1}, 1\\}$, respectively, i.e. they are within at most a polylogarithmic factor from these values with probability at least $1 - t^{-A}$ for any constant $A > 0$."],"url":"http://arxiv.org/abs/2308.04336v1"}
{"created":"2023-08-08 15:26:58","title":"Towards an AI to Win Ghana's National Science and Maths Quiz","abstract":"Can an AI win Ghana's National Science and Maths Quiz (NSMQ)? That is the question we seek to answer in the NSMQ AI project, an open-source project that is building AI to compete live in the NSMQ and win. The NSMQ is an annual live science and mathematics competition for senior secondary school students in Ghana in which 3 teams of 2 students compete by answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year. The NSMQ is an exciting live quiz competition with interesting technical challenges across speech-to-text, text-to-speech, question-answering, and human-computer interaction. In this ongoing work that began in January 2023, we give an overview of the project, describe each of the teams, progress made thus far, and the next steps toward our planned launch and debut of the AI in October for NSMQ 2023. An AI that conquers this grand challenge can have real-world impact on education such as enabling millions of students across Africa to have one-on-one learning support from this AI.","sentences":["Can an AI win Ghana's National Science and Maths Quiz (NSMQ)?","That is the question we seek to answer in the NSMQ AI project, an open-source project that is building AI to compete live in the NSMQ and win.","The NSMQ is an annual live science and mathematics competition for senior secondary school students in Ghana in which 3 teams of 2 students compete by answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year.","The NSMQ is an exciting live quiz competition with interesting technical challenges across speech-to-text, text-to-speech, question-answering, and human-computer interaction.","In this ongoing work that began in January 2023, we give an overview of the project, describe each of the teams, progress made thus far, and the next steps toward our planned launch and debut of the AI in October for NSMQ 2023.","An AI that conquers this grand challenge can have real-world impact on education such as enabling millions of students across Africa to have one-on-one learning support from this AI."],"url":"http://arxiv.org/abs/2308.04333v1"}
{"created":"2023-08-08 15:21:30","title":"RLHF-Blender: A Configurable Interactive Interface for Learning from Diverse Human Feedback","abstract":"To use reinforcement learning from human feedback (RLHF) in practical applications, it is crucial to learn reward models from diverse sources of human feedback and to consider human factors involved in providing feedback of different types. However, the systematic study of learning from diverse types of feedback is held back by limited standardized tooling available to researchers. To bridge this gap, we propose RLHF-Blender, a configurable, interactive interface for learning from human feedback. RLHF-Blender provides a modular experimentation framework and implementation that enables researchers to systematically investigate the properties and qualities of human feedback for reward learning. The system facilitates the exploration of various feedback types, including demonstrations, rankings, comparisons, and natural language instructions, as well as studies considering the impact of human factors on their effectiveness. We discuss a set of concrete research opportunities enabled by RLHF-Blender. More information is available at https://rlhfblender.info/.","sentences":["To use reinforcement learning from human feedback (RLHF) in practical applications, it is crucial to learn reward models from diverse sources of human feedback and to consider human factors involved in providing feedback of different types.","However, the systematic study of learning from diverse types of feedback is held back by limited standardized tooling available to researchers.","To bridge this gap, we propose RLHF-Blender, a configurable, interactive interface for learning from human feedback.","RLHF-Blender provides a modular experimentation framework and implementation that enables researchers to systematically investigate the properties and qualities of human feedback for reward learning.","The system facilitates the exploration of various feedback types, including demonstrations, rankings, comparisons, and natural language instructions, as well as studies considering the impact of human factors on their effectiveness.","We discuss a set of concrete research opportunities enabled by RLHF-Blender.","More information is available at https://rlhfblender.info/."],"url":"http://arxiv.org/abs/2308.04332v1"}
{"created":"2023-08-08 15:21:11","title":"Preserving Sparsity and Privacy in Straggler-Resilient Distributed Matrix Computations","abstract":"Existing approaches to distributed matrix computations involve allocating coded combinations of submatrices to worker nodes, to build resilience to stragglers and/or enhance privacy. In this study, we consider the challenge of preserving input sparsity in such approaches to retain the associated computational efficiency enhancements. First, we find a lower bound on the weight of coding, i.e., the number of submatrices to be combined to obtain coded submatrices to provide the resilience to the maximum possible number of stragglers (for given number of nodes and their storage constraints). Next we propose a distributed matrix computation scheme which meets this exact lower bound on the weight of the coding. Further, we develop controllable trade-off between worker computation time and the privacy constraint for sparse input matrices in settings where the worker nodes are honest but curious. Numerical experiments conducted in Amazon Web Services (AWS) validate our assertions regarding straggler mitigation and computation speed for sparse matrices.","sentences":["Existing approaches to distributed matrix computations involve allocating coded combinations of submatrices to worker nodes, to build resilience to stragglers and/or enhance privacy.","In this study, we consider the challenge of preserving input sparsity in such approaches to retain the associated computational efficiency enhancements.","First, we find a lower bound on the weight of coding, i.e., the number of submatrices to be combined to obtain coded submatrices to provide the resilience to the maximum possible number of stragglers (for given number of nodes and their storage constraints).","Next we propose a distributed matrix computation scheme which meets this exact lower bound on the weight of the coding.","Further, we develop controllable trade-off between worker computation time and the privacy constraint for sparse input matrices in settings where the worker nodes are honest but curious.","Numerical experiments conducted in Amazon Web Services (AWS) validate our assertions regarding straggler mitigation and computation speed for sparse matrices."],"url":"http://arxiv.org/abs/2308.04331v1"}
{"created":"2023-08-08 15:19:13","title":"A Dataset and Analysis of Open-Source Machine Learning Products","abstract":"Machine learning (ML) components are increasingly incorporated into software products, yet developers face challenges in transitioning from ML prototypes to products. Academic researchers struggle to propose solutions to these challenges and evaluate interventions because they often do not have access to close-sourced ML products from industry. In this study, we define and identify open-source ML products, curating a dataset of 262 repositories from GitHub, to facilitate further research and education. As a start, we explore six broad research questions related to different development activities and report 21 findings from a sample of 30 ML products from the dataset. Our findings reveal a variety of development practices and architectural decisions surrounding different types and uses of ML models that offer ample opportunities for future research innovations. We also find very little evidence of industry best practices such as model testing and pipeline automation within the open-source ML products, which leaves room for further investigation to understand its potential impact on the development and eventual end-user experience for the products.","sentences":["Machine learning (ML) components are increasingly incorporated into software products, yet developers face challenges in transitioning from ML prototypes to products.","Academic researchers struggle to propose solutions to these challenges and evaluate interventions because they often do not have access to close-sourced ML products from industry.","In this study, we define and identify open-source ML products, curating a dataset of 262 repositories from GitHub, to facilitate further research and education.","As a start, we explore six broad research questions related to different development activities and report 21 findings from a sample of 30 ML products from the dataset.","Our findings reveal a variety of development practices and architectural decisions surrounding different types and uses of ML models that offer ample opportunities for future research innovations.","We also find very little evidence of industry best practices such as model testing and pipeline automation within the open-source ML products, which leaves room for further investigation to understand its potential impact on the development and eventual end-user experience for the products."],"url":"http://arxiv.org/abs/2308.04328v1"}
{"created":"2023-08-08 15:16:51","title":"Embracing Safe Contacts with Contact-aware Planning and Control","abstract":"Unlike human beings that can employ the entire surface of their limbs as a means to establish contact with their environment, robots are typically programmed to interact with their environments via their end-effectors, in a collision-free fashion, to avoid damaging their environment. In a departure from such a traditional approach, this work presents a contact-aware controller for reference tracking that maintains interaction forces on the surface of the robot below a safety threshold in the presence of both rigid and soft contacts. Furthermore, we leveraged the proposed controller to extend the BiTRRT sample-based planning method to be contact-aware, using a simplified contact model. The effectiveness of our framework is demonstrated in hardware experiments using a Franka robot in a setup inspired by the Amazon stowing task. A demo video of our results can be seen here: https://youtu.be/2WeYytauhNg","sentences":["Unlike human beings that can employ the entire surface of their limbs as a means to establish contact with their environment, robots are typically programmed to interact with their environments via their end-effectors, in a collision-free fashion, to avoid damaging their environment.","In a departure from such a traditional approach, this work presents a contact-aware controller for reference tracking that maintains interaction forces on the surface of the robot below a safety threshold in the presence of both rigid and soft contacts.","Furthermore, we leveraged the proposed controller to extend the BiTRRT sample-based planning method to be contact-aware, using a simplified contact model.","The effectiveness of our framework is demonstrated in hardware experiments using a Franka robot in a setup inspired by the Amazon stowing task.","A demo video of our results can be seen here: https://youtu.be/2WeYytauhNg"],"url":"http://arxiv.org/abs/2308.04323v1"}
{"created":"2023-08-08 15:15:51","title":"Domain Adaptive Person Search via GAN-based Scene Synthesis for Cross-scene Videos","abstract":"Person search has recently been a challenging task in the computer vision domain, which aims to search specific pedestrians from real cameras.Nevertheless, most surveillance videos comprise only a handful of images of each pedestrian, which often feature identical backgrounds and clothing. Hence, it is difficult to learn more discriminative features for person search in real scenes. To tackle this challenge, we draw on Generative Adversarial Networks (GAN) to synthesize data from surveillance videos. GAN has thrived in computer vision problems because it produces high-quality images efficiently. We merely alter the popular Fast R-CNN model, which is capable of processing videos and yielding accurate detection outcomes. In order to appropriately relieve the pressure brought by the two-stage model, we design an Assisted-Identity Query Module (AIDQ) to provide positive images for the behind part. Besides, the proposed novel GAN-based Scene Synthesis model that can synthesize high-quality cross-id person images for person search tasks. In order to facilitate the feature learning of the GAN-based Scene Synthesis model, we adopt an online learning strategy that collaboratively learns the synthesized images and original images. Extensive experiments on two widely used person search benchmarks, CUHK-SYSU and PRW, have shown that our method has achieved great performance, and the extensive ablation study further justifies our GAN-synthetic data can effectively increase the variability of the datasets and be more realistic.","sentences":["Person search has recently been a challenging task in the computer vision domain, which aims to search specific pedestrians from real cameras.","Nevertheless, most surveillance videos comprise only a handful of images of each pedestrian, which often feature identical backgrounds and clothing.","Hence, it is difficult to learn more discriminative features for person search in real scenes.","To tackle this challenge, we draw on Generative Adversarial Networks (GAN) to synthesize data from surveillance videos.","GAN has thrived in computer vision problems because it produces high-quality images efficiently.","We merely alter the popular Fast R-CNN model, which is capable of processing videos and yielding accurate detection outcomes.","In order to appropriately relieve the pressure brought by the two-stage model, we design an Assisted-Identity Query Module (AIDQ) to provide positive images for the behind part.","Besides, the proposed novel GAN-based Scene Synthesis model that can synthesize high-quality cross-id person images for person search tasks.","In order to facilitate the feature learning of the GAN-based Scene Synthesis model, we adopt an online learning strategy that collaboratively learns the synthesized images and original images.","Extensive experiments on two widely used person search benchmarks, CUHK-SYSU and PRW, have shown that our method has achieved great performance, and the extensive ablation study further justifies our GAN-synthetic data can effectively increase the variability of the datasets and be more realistic."],"url":"http://arxiv.org/abs/2308.04322v1"}
{"created":"2023-08-08 15:14:23","title":"All-pairs Consistency Learning for Weakly Supervised Semantic Segmentation","abstract":"In this work, we propose a new transformer-based regularization to better localize objects for Weakly supervised semantic segmentation (WSSS). In image-level WSSS, Class Activation Map (CAM) is adopted to generate object localization as pseudo segmentation labels. To address the partial activation issue of the CAMs, consistency regularization is employed to maintain activation intensity invariance across various image augmentations. However, such methods ignore pair-wise relations among regions within each CAM, which capture context and should also be invariant across image views. To this end, we propose a new all-pairs consistency regularization (ACR). Given a pair of augmented views, our approach regularizes the activation intensities between a pair of augmented views, while also ensuring that the affinity across regions within each view remains consistent. We adopt vision transformers as the self-attention mechanism naturally embeds pair-wise affinity. This enables us to simply regularize the distance between the attention matrices of augmented image pairs. Additionally, we introduce a novel class-wise localization method that leverages the gradients of the class token. Our method can be seamlessly integrated into existing WSSS methods using transformers without modifying the architectures. We evaluate our method on PASCAL VOC and MS COCO datasets. Our method produces noticeably better class localization maps (67.3% mIoU on PASCAL VOC train), resulting in superior WSSS performances.","sentences":["In this work, we propose a new transformer-based regularization to better localize objects for Weakly supervised semantic segmentation (WSSS).","In image-level WSSS, Class Activation Map (CAM) is adopted to generate object localization as pseudo segmentation labels.","To address the partial activation issue of the CAMs, consistency regularization is employed to maintain activation intensity invariance across various image augmentations.","However, such methods ignore pair-wise relations among regions within each CAM, which capture context and should also be invariant across image views.","To this end, we propose a new all-pairs consistency regularization (ACR).","Given a pair of augmented views, our approach regularizes the activation intensities between a pair of augmented views, while also ensuring that the affinity across regions within each view remains consistent.","We adopt vision transformers as the self-attention mechanism naturally embeds pair-wise affinity.","This enables us to simply regularize the distance between the attention matrices of augmented image pairs.","Additionally, we introduce a novel class-wise localization method that leverages the gradients of the class token.","Our method can be seamlessly integrated into existing WSSS methods using transformers without modifying the architectures.","We evaluate our method on PASCAL VOC and MS COCO datasets.","Our method produces noticeably better class localization maps (67.3% mIoU on PASCAL VOC train), resulting in superior WSSS performances."],"url":"http://arxiv.org/abs/2308.04321v1"}
{"created":"2023-08-08 15:02:50","title":"Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs","abstract":"Recently, there has been extensive study of cooperative multi-agent multi-armed bandits where a set of distributed agents cooperatively play the same multi-armed bandit game. The goal is to develop bandit algorithms with the optimal group and individual regrets and low communication between agents. The prior work tackled this problem using two paradigms: leader-follower and fully distributed algorithms. Prior algorithms in both paradigms achieve the optimal group regret. The leader-follower algorithms achieve constant communication costs but fail to achieve optimal individual regrets. The state-of-the-art fully distributed algorithms achieve optimal individual regrets but fail to achieve constant communication costs. This paper presents a simple yet effective communication policy and integrates it into a learning algorithm for cooperative bandits. Our algorithm achieves the best of both paradigms: optimal individual regret and constant communication costs.","sentences":["Recently, there has been extensive study of cooperative multi-agent multi-armed bandits where a set of distributed agents cooperatively play the same multi-armed bandit game.","The goal is to develop bandit algorithms with the optimal group and individual regrets and low communication between agents.","The prior work tackled this problem using two paradigms: leader-follower and fully distributed algorithms.","Prior algorithms in both paradigms achieve the optimal group regret.","The leader-follower algorithms achieve constant communication costs but fail to achieve optimal individual regrets.","The state-of-the-art fully distributed algorithms achieve optimal individual regrets but fail to achieve constant communication costs.","This paper presents a simple yet effective communication policy and integrates it into a learning algorithm for cooperative bandits.","Our algorithm achieves the best of both paradigms: optimal individual regret and constant communication costs."],"url":"http://arxiv.org/abs/2308.04314v1"}
{"created":"2023-08-08 15:01:51","title":"Apple Vision Pro for Healthcare: \"The Ultimate Display\"?","abstract":"At the Worldwide Developers Conference (WWDC) in June 2023, Apple introduced the Vision Pro. The Vision Pro is a Mixed Reality (MR) headset, more specifically it is a Virtual Reality (VR) device with an additional Video See-Through (VST) capability. The VST capability turns the Vision Pro also into an Augmented Reality (AR) device. The AR feature is enabled by streaming the real world via cameras to the (VR) screens in front of the user's eyes. This is of course not unique and similar to other devices, like the Varjo XR-3. Nevertheless, the Vision Pro has some interesting features, like an inside-out screen that can show the headset wearers' eyes to \"outsiders\" or a button on the top, called \"Digital Crown\", that allows you to seamlessly blend digital content with your physical space by turning it. In addition, it is untethered, except for the cable to the battery, which makes the headset more agile, compared to the Varjo XR-3. This could actually come closer to the \"Ultimate Display\", which Ivan Sutherland had already sketched in 1965. Not available to the public yet, like the Ultimate Display, we want to take a look into the crystal ball in this perspective to see if it can overcome some clinical challenges that - especially - AR still faces in the medical domain, but also go beyond and discuss if the Vision Pro could support clinicians in essential tasks to spend more time with their patients.","sentences":["At the Worldwide Developers Conference (WWDC) in June 2023, Apple introduced the Vision Pro.","The Vision Pro is a Mixed Reality (MR) headset, more specifically it is a Virtual Reality (VR) device with an additional Video See-Through (VST) capability.","The VST capability turns the Vision Pro also into an Augmented Reality (AR) device.","The AR feature is enabled by streaming the real world via cameras to the (VR) screens in front of the user's eyes.","This is of course not unique and similar to other devices, like the Varjo XR-3.","Nevertheless, the Vision Pro has some interesting features, like an inside-out screen that can show the headset wearers' eyes to \"outsiders\" or a button on the top, called \"Digital Crown\", that allows you to seamlessly blend digital content with your physical space by turning it.","In addition, it is untethered, except for the cable to the battery, which makes the headset more agile, compared to the Varjo XR-3.","This could actually come closer to the \"Ultimate Display\", which Ivan Sutherland had already sketched in 1965.","Not available to the public yet, like the Ultimate Display, we want to take a look into the crystal ball in this perspective to see if it can overcome some clinical challenges that - especially - AR still faces in the medical domain, but also go beyond and discuss if the Vision Pro could support clinicians in essential tasks to spend more time with their patients."],"url":"http://arxiv.org/abs/2308.04313v1"}
{"created":"2023-08-08 15:00:12","title":"Interpretable Goal-Based model for Vehicle Trajectory Prediction in Interactive Scenarios","abstract":"The abilities to understand the social interaction behaviors between a vehicle and its surroundings while predicting its trajectory in an urban environment are critical for road safety in autonomous driving. Social interactions are hard to explain because of their uncertainty. In recent years, neural network-based methods have been widely used for trajectory prediction and have been shown to outperform hand-crafted methods. However, these methods suffer from their lack of interpretability. In order to overcome this limitation, we combine the interpretability of a discrete choice model with the high accuracy of a neural network-based model for the task of vehicle trajectory prediction in an interactive environment. We implement and evaluate our model using the INTERACTION dataset and demonstrate the effectiveness of our proposed architecture to explain its predictions without compromising the accuracy.","sentences":["The abilities to understand the social interaction behaviors between a vehicle and its surroundings while predicting its trajectory in an urban environment are critical for road safety in autonomous driving.","Social interactions are hard to explain because of their uncertainty.","In recent years, neural network-based methods have been widely used for trajectory prediction and have been shown to outperform hand-crafted methods.","However, these methods suffer from their lack of interpretability.","In order to overcome this limitation, we combine the interpretability of a discrete choice model with the high accuracy of a neural network-based model for the task of vehicle trajectory prediction in an interactive environment.","We implement and evaluate our model using the INTERACTION dataset and demonstrate the effectiveness of our proposed architecture to explain its predictions without compromising the accuracy."],"url":"http://arxiv.org/abs/2308.04312v1"}
{"created":"2023-08-08 14:54:33","title":"Generative AI in Computing Education: Perspectives of Students and Instructors","abstract":"Generative models are now capable of producing natural language text that is, in some cases, comparable in quality to the text produced by people. In the computing education context, these models are being used to generate code, code explanations, and programming exercises. The rapid adoption of these models has prompted multiple position papers and workshops which discuss the implications of these models for computing education, both positive and negative. This paper presents results from a series of semi-structured interviews with 12 students and 6 instructors about their awareness, experiences, and preferences regarding the use of tools powered by generative AI in computing classrooms. The results suggest that Generative AI (GAI) tools will play an increasingly significant role in computing education. However, students and instructors also raised numerous concerns about how these models should be integrated to best support the needs and learning goals of students. We also identified interesting tensions and alignments that emerged between how instructors and students prefer to engage with these models. We discuss these results and provide recommendations related to curriculum development, assessment methods, and pedagogical practice. As GAI tools become increasingly prevalent, it's important to understand educational stakeholders' preferences and values to ensure that these tools can be used for good and that potential harms can be mitigated.","sentences":["Generative models are now capable of producing natural language text that is, in some cases, comparable in quality to the text produced by people.","In the computing education context, these models are being used to generate code, code explanations, and programming exercises.","The rapid adoption of these models has prompted multiple position papers and workshops which discuss the implications of these models for computing education, both positive and negative.","This paper presents results from a series of semi-structured interviews with 12 students and 6 instructors about their awareness, experiences, and preferences regarding the use of tools powered by generative AI in computing classrooms.","The results suggest that Generative AI (GAI) tools will play an increasingly significant role in computing education.","However, students and instructors also raised numerous concerns about how these models should be integrated to best support the needs and learning goals of students.","We also identified interesting tensions and alignments that emerged between how instructors and students prefer to engage with these models.","We discuss these results and provide recommendations related to curriculum development, assessment methods, and pedagogical practice.","As GAI tools become increasingly prevalent, it's important to understand educational stakeholders' preferences and values to ensure that these tools can be used for good and that potential harms can be mitigated."],"url":"http://arxiv.org/abs/2308.04309v1"}
{"created":"2023-08-08 14:51:16","title":"Deep Learning-Based Knowledge Injection for Metaphor Detection: A Comprehensive Review","abstract":"The history of metaphor research also marks the evolution of knowledge infusion research. With the continued advancement of deep learning techniques in recent years, the natural language processing community has shown great interest in applying knowledge to successful results in metaphor recognition tasks. Although there has been a gradual increase in the number of approaches involving knowledge injection in the field of metaphor recognition, there is a lack of a complete review article on knowledge injection based approaches. Therefore, the goal of this paper is to provide a comprehensive review of research advances in the application of deep learning for knowledge injection in metaphor recognition tasks. In this paper, we systematically summarize and generalize the mainstream knowledge and knowledge injection principles, as well as review the datasets, evaluation metrics, and benchmark models used in metaphor recognition tasks. Finally, we explore the current issues facing knowledge injection methods and provide an outlook on future research directions.","sentences":["The history of metaphor research also marks the evolution of knowledge infusion research.","With the continued advancement of deep learning techniques in recent years, the natural language processing community has shown great interest in applying knowledge to successful results in metaphor recognition tasks.","Although there has been a gradual increase in the number of approaches involving knowledge injection in the field of metaphor recognition, there is a lack of a complete review article on knowledge injection based approaches.","Therefore, the goal of this paper is to provide a comprehensive review of research advances in the application of deep learning for knowledge injection in metaphor recognition tasks.","In this paper, we systematically summarize and generalize the mainstream knowledge and knowledge injection principles, as well as review the datasets, evaluation metrics, and benchmark models used in metaphor recognition tasks.","Finally, we explore the current issues facing knowledge injection methods and provide an outlook on future research directions."],"url":"http://arxiv.org/abs/2308.04306v1"}
{"created":"2023-08-08 14:50:25","title":"Defending Hash Tables from Subterfuge with Depth Charge","abstract":"We consider the problem of defending a hash table against a Byzantine attacker that is trying to degrade the performance of query, insertion and deletion operations. Our defense makes use of resource burning (RB) -- the the verifiable expenditure of network resources -- where the issuer of a request incurs some RB cost. Our algorithm, Depth Charge, charges RB costs for operations based on the depth of the appropriate object in the list that the object hashes to in the table. By appropriately setting the RB costs, our algorithm mitigates the impact of an attacker on the hash table's performance. In particular, in the presence of a significant attack, our algorithm incurs a cost which is asymptotically less that the attacker's cost.","sentences":["We consider the problem of defending a hash table against a Byzantine attacker that is trying to degrade the performance of query, insertion and deletion operations.","Our defense makes use of resource burning (RB) -- the the verifiable expenditure of network resources -- where the issuer of a request incurs some RB cost.","Our algorithm, Depth Charge, charges RB costs for operations based on the depth of the appropriate object in the list that the object hashes to in the table.","By appropriately setting the RB costs, our algorithm mitigates the impact of an attacker on the hash table's performance.","In particular, in the presence of a significant attack, our algorithm incurs a cost which is asymptotically less that the attacker's cost."],"url":"http://arxiv.org/abs/2308.04305v1"}
{"created":"2023-08-08 14:50:05","title":"The Model Inversion Eavesdropping Attack in Semantic Communication Systems","abstract":"In recent years, semantic communication has been a popular research topic for its superiority in communication efficiency. As semantic communication relies on deep learning to extract meaning from raw messages, it is vulnerable to attacks targeting deep learning models. In this paper, we introduce the model inversion eavesdropping attack (MIEA) to reveal the risk of privacy leaks in the semantic communication system. In MIEA, the attacker first eavesdrops the signal being transmitted by the semantic communication system and then performs model inversion attack to reconstruct the raw message, where both the white-box and black-box settings are considered. Evaluation results show that MIEA can successfully reconstruct the raw message with good quality under different channel conditions. We then propose a defense method based on random permutation and substitution to defend against MIEA in order to achieve secure semantic communication. Our experimental results demonstrate the effectiveness of the proposed defense method in preventing MIEA.","sentences":["In recent years, semantic communication has been a popular research topic for its superiority in communication efficiency.","As semantic communication relies on deep learning to extract meaning from raw messages, it is vulnerable to attacks targeting deep learning models.","In this paper, we introduce the model inversion eavesdropping attack (MIEA) to reveal the risk of privacy leaks in the semantic communication system.","In MIEA, the attacker first eavesdrops the signal being transmitted by the semantic communication system and then performs model inversion attack to reconstruct the raw message, where both the white-box and black-box settings are considered.","Evaluation results show that MIEA can successfully reconstruct the raw message with good quality under different channel conditions.","We then propose a defense method based on random permutation and substitution to defend against MIEA in order to achieve secure semantic communication.","Our experimental results demonstrate the effectiveness of the proposed defense method in preventing MIEA."],"url":"http://arxiv.org/abs/2308.04304v1"}
{"created":"2023-08-08 14:49:44","title":"Vehicle Motion Forecasting using Prior Information and Semantic-assisted Occupancy Grid Maps","abstract":"Motion prediction is a challenging task for autonomous vehicles due to uncertainty in the sensor data, the non-deterministic nature of future, and complex behavior of agents. In this paper, we tackle this problem by representing the scene as dynamic occupancy grid maps (DOGMs), associating semantic labels to the occupied cells and incorporating map information. We propose a novel framework that combines deep-learning-based spatio-temporal and probabilistic approaches to predict vehicle behaviors.Contrary to the conventional OGM prediction methods, evaluation of our work is conducted against the ground truth annotations. We experiment and validate our results on real-world NuScenes dataset and show that our model shows superior ability to predict both static and dynamic vehicles compared to OGM predictions. Furthermore, we perform an ablation study and assess the role of semantic labels and map in the architecture.","sentences":["Motion prediction is a challenging task for autonomous vehicles due to uncertainty in the sensor data, the non-deterministic nature of future, and complex behavior of agents.","In this paper, we tackle this problem by representing the scene as dynamic occupancy grid maps (DOGMs), associating semantic labels to the occupied cells and incorporating map information.","We propose a novel framework that combines deep-learning-based spatio-temporal and probabilistic approaches to predict vehicle behaviors.","Contrary to the conventional OGM prediction methods, evaluation of our work is conducted against the ground truth annotations.","We experiment and validate our results on real-world NuScenes dataset and show that our model shows superior ability to predict both static and dynamic vehicles compared to OGM predictions.","Furthermore, we perform an ablation study and assess the role of semantic labels and map in the architecture."],"url":"http://arxiv.org/abs/2308.04303v1"}
{"created":"2023-08-08 14:45:00","title":"Actor-Critic with variable time discretization via sustained actions","abstract":"Reinforcement learning (RL) methods work in discrete time. In order to apply RL to inherently continuous problems like robotic control, a specific time discretization needs to be defined. This is a choice between sparse time control, which may be easier to train, and finer time control, which may allow for better ultimate performance. In this work, we propose SusACER, an off-policy RL algorithm that combines the advantages of different time discretization settings. Initially, it operates with sparse time discretization and gradually switches to a fine one. We analyze the effects of the changing time discretization in robotic control environments: Ant, HalfCheetah, Hopper, and Walker2D. In all cases our proposed algorithm outperforms state of the art.","sentences":["Reinforcement learning (RL) methods work in discrete time.","In order to apply RL to inherently continuous problems like robotic control, a specific time discretization needs to be defined.","This is a choice between sparse time control, which may be easier to train, and finer time control, which may allow for better ultimate performance.","In this work, we propose SusACER, an off-policy RL algorithm that combines the advantages of different time discretization settings.","Initially, it operates with sparse time discretization and gradually switches to a fine one.","We analyze the effects of the changing time discretization in robotic control environments: Ant, HalfCheetah, Hopper, and Walker2D.","In all cases our proposed algorithm outperforms state of the art."],"url":"http://arxiv.org/abs/2308.04299v1"}
{"created":"2023-08-08 14:42:00","title":"Safeguarding Scientific Integrity: Examining Conflicts of Interest in the Peer Review Process","abstract":"This case study analyzes the expertise, potential conflicts of interest, and objectivity of editors, authors, and peer reviewers involved in a 2022 special journal issue on fertility, pregnancy, and mental health. Data were collected on qualifications, organizational affiliations, and relationships among six papers' authors, three guest editors, and twelve peer reviewers. Two articles were found to have undisclosed conflicts of interest between authors, an editor, and multiple peer reviewers affiliated with anti-abortion advocacy and lobbying groups, indicating compromised objectivity.   This lack of transparency undermines the peer review process and enables biased research and disinformation proliferation. To increase integrity, we recommend multiple solutions: open peer review, expanded conflict of interest disclosure, increased stakeholder accountability, and retraction when ethical standards are violated. By illuminating noncompliance with ethical peer review guidelines, this study aims to raise awareness to help prevent the propagation of partisan science through respected scholarly channels.","sentences":["This case study analyzes the expertise, potential conflicts of interest, and objectivity of editors, authors, and peer reviewers involved in a 2022 special journal issue on fertility, pregnancy, and mental health.","Data were collected on qualifications, organizational affiliations, and relationships among six papers' authors, three guest editors, and twelve peer reviewers.","Two articles were found to have undisclosed conflicts of interest between authors, an editor, and multiple peer reviewers affiliated with anti-abortion advocacy and lobbying groups, indicating compromised objectivity.   ","This lack of transparency undermines the peer review process and enables biased research and disinformation proliferation.","To increase integrity, we recommend multiple solutions: open peer review, expanded conflict of interest disclosure, increased stakeholder accountability, and retraction when ethical standards are violated.","By illuminating noncompliance with ethical peer review guidelines, this study aims to raise awareness to help prevent the propagation of partisan science through respected scholarly channels."],"url":"http://arxiv.org/abs/2308.04297v1"}
{"created":"2023-08-08 14:36:58","title":"Engineering LaCAM$^\\ast$: Towards Real-Time, Large-Scale, and Near-Optimal Multi-Agent Pathfinding","abstract":"This paper addresses the challenges of real-time, large-scale, and near-optimal multi-agent pathfinding (MAPF) through enhancements to the recently proposed LaCAM* algorithm. LaCAM* is a scalable search-based algorithm that guarantees the eventual finding of optimal solutions for cumulative transition costs. While it has demonstrated remarkable planning success rates, surpassing various state-of-the-art MAPF methods, its initial solution quality is far from optimal, and its convergence speed to the optimum is slow. To overcome these limitations, this paper introduces several improvement techniques, partly drawing inspiration from other MAPF methods. We provide empirical evidence that the fusion of these techniques significantly improves the solution quality of LaCAM*, thus further pushing the boundaries of MAPF algorithms.","sentences":["This paper addresses the challenges of real-time, large-scale, and near-optimal multi-agent pathfinding (MAPF) through enhancements to the recently proposed LaCAM* algorithm.","LaCAM* is a scalable search-based algorithm that guarantees the eventual finding of optimal solutions for cumulative transition costs.","While it has demonstrated remarkable planning success rates, surpassing various state-of-the-art MAPF methods, its initial solution quality is far from optimal, and its convergence speed to the optimum is slow.","To overcome these limitations, this paper introduces several improvement techniques, partly drawing inspiration from other MAPF methods.","We provide empirical evidence that the fusion of these techniques significantly improves the solution quality of LaCAM*, thus further pushing the boundaries of MAPF algorithms."],"url":"http://arxiv.org/abs/2308.04292v1"}
{"created":"2023-08-08 14:33:23","title":"Linear Time Construction of Cover Suffix Tree and Applications","abstract":"The Cover Suffix Tree (CST) of a string $T$ is the suffix tree of $T$ with additional explicit nodes corresponding to halves of square substrings of $T$. In the CST an explicit node corresponding to a substring $C$ of $T$ is annotated with two numbers: the number of non-overlapping consecutive occurrences of $C$ and the total number of positions in $T$ that are covered by occurrences of $C$ in $T$. Kociumaka et al. (Algorithmica, 2015) have shown how to compute the CST of a length-$n$ string in $O(n \\log n)$ time. We show how to compute the CST in $O(n)$ time assuming that $T$ is over an integer alphabet.   Kociumaka et al. (Algorithmica, 2015; Theor. Comput. Sci., 2018) have shown that knowing the CST of a length-$n$ string $T$, one can compute a linear-sized representation of all seeds of $T$ as well as all shortest $\\alpha$-partial covers and seeds in $T$ for a given $\\alpha$ in $O(n)$ time. Thus our result implies linear-time algorithms computing these notions of quasiperiodicity. The resulting algorithm computing seeds is substantially different from the previous one (Kociumaka et al., SODA 2012, ACM Trans. Algorithms, 2020). Kociumaka et al. (Algorithmica, 2015) proposed an $O(n \\log n)$-time algorithm for computing a shortest $\\alpha$-partial cover for each $\\alpha=1,\\ldots,n$; we improve this complexity to $O(n)$.   Our results are based on a new characterization of consecutive overlapping occurrences of a substring $S$ of $T$ in terms of the set of runs (see Kolpakov and Kucherov, FOCS 1999) in $T$. This new insight also leads to an $O(n)$-sized index for reporting overlapping consecutive occurrences of a given pattern $P$ of length $m$ in $O(m+output)$ time, where $output$ is the number of occurrences reported. In comparison, a general index for reporting bounded-gap consecutive occurrences of Navarro and Thankachan (Theor. Comput. Sci., 2016) uses $O(n \\log n)$ space.","sentences":["The Cover Suffix Tree (CST) of a string $T$ is the suffix tree of $T$ with additional explicit nodes corresponding to halves of square substrings of $T$. In the CST an explicit node corresponding to a substring $C$ of $T$ is annotated with two numbers: the number of non-overlapping consecutive occurrences of $C$ and the total number of positions in $T$ that are covered by occurrences of $C$ in $T$. Kociumaka et al.","(Algorithmica, 2015) have shown how to compute the CST of a length-$n$ string in $O(n \\log","n)$ time.","We show how to compute the CST in $O(n)$ time assuming that $T$ is over an integer alphabet.   ","Kociumaka et al.","(Algorithmica, 2015; Theor.","Comput.","Sci., 2018) have shown that knowing the CST of a length-$n$ string $T$, one can compute a linear-sized representation of all seeds of $T$ as well as all shortest $\\alpha$-partial covers and seeds in $T$ for a given $\\alpha$ in $O(n)$ time.","Thus our result implies linear-time algorithms computing these notions of quasiperiodicity.","The resulting algorithm computing seeds is substantially different from the previous one (Kociumaka et al., SODA 2012, ACM Trans.","Algorithms, 2020).","Kociumaka et al.","(Algorithmica, 2015) proposed an $O(n \\log n)$-time algorithm for computing a shortest $\\alpha$-partial cover for each $\\alpha=1,\\ldots,n$; we improve this complexity to $O(n)$.   Our results are based on a new characterization of consecutive overlapping occurrences of a substring $S$ of $T$ in terms of the set of runs (see Kolpakov and Kucherov, FOCS 1999) in $T$. This new insight also leads to an $O(n)$-sized index for reporting overlapping consecutive occurrences of a given pattern $P$ of length $m$ in $O(m+output)$ time, where $output$ is the number of occurrences reported.","In comparison, a general index for reporting bounded-gap consecutive occurrences of Navarro and Thankachan (Theor.","Comput.","Sci., 2016) uses $O(n \\log n)$ space."],"url":"http://arxiv.org/abs/2308.04289v1"}
{"created":"2023-08-08 14:32:38","title":"Cloth2Tex: A Customized Cloth Texture Generation Pipeline for 3D Virtual Try-On","abstract":"Fabricating and designing 3D garments has become extremely demanding with the increasing need for synthesizing realistic dressed persons for a variety of applications, e.g. 3D virtual try-on, digitalization of 2D clothes into 3D apparel, and cloth animation. It thus necessitates a simple and straightforward pipeline to obtain high-quality texture from simple input, such as 2D reference images. Since traditional warping-based texture generation methods require a significant number of control points to be manually selected for each type of garment, which can be a time-consuming and tedious process. We propose a novel method, called Cloth2Tex, which eliminates the human burden in this process. Cloth2Tex is a self-supervised method that generates texture maps with reasonable layout and structural consistency. Another key feature of Cloth2Tex is that it can be used to support high-fidelity texture inpainting. This is done by combining Cloth2Tex with a prevailing latent diffusion model. We evaluate our approach both qualitatively and quantitatively and demonstrate that Cloth2Tex can generate high-quality texture maps and achieve the best visual effects in comparison to other methods. Project page: tomguluson92.github.io/projects/cloth2tex/","sentences":["Fabricating and designing 3D garments has become extremely demanding with the increasing need for synthesizing realistic dressed persons for a variety of applications, e.g. 3D virtual try-on, digitalization of 2D clothes into 3D apparel, and cloth animation.","It thus necessitates a simple and straightforward pipeline to obtain high-quality texture from simple input, such as 2D reference images.","Since traditional warping-based texture generation methods require a significant number of control points to be manually selected for each type of garment, which can be a time-consuming and tedious process.","We propose a novel method, called Cloth2Tex, which eliminates the human burden in this process.","Cloth2Tex is a self-supervised method that generates texture maps with reasonable layout and structural consistency.","Another key feature of Cloth2Tex is that it can be used to support high-fidelity texture inpainting.","This is done by combining Cloth2Tex with a prevailing latent diffusion model.","We evaluate our approach both qualitatively and quantitatively and demonstrate that Cloth2Tex can generate high-quality texture maps and achieve the best visual effects in comparison to other methods.","Project page: tomguluson92.github.io/projects/cloth2tex/"],"url":"http://arxiv.org/abs/2308.04288v1"}
{"created":"2023-08-08 14:25:13","title":"Vision-Based Autonomous Navigation for Unmanned Surface Vessel in Extreme Marine Conditions","abstract":"Visual perception is an important component for autonomous navigation of unmanned surface vessels (USV), particularly for the tasks related to autonomous inspection and tracking. These tasks involve vision-based navigation techniques to identify the target for navigation. Reduced visibility under extreme weather conditions in marine environments makes it difficult for vision-based approaches to work properly. To overcome these issues, this paper presents an autonomous vision-based navigation framework for tracking target objects in extreme marine conditions. The proposed framework consists of an integrated perception pipeline that uses a generative adversarial network (GAN) to remove noise and highlight the object features before passing them to the object detector (i.e., YOLOv5). The detected visual features are then used by the USV to track the target. The proposed framework has been thoroughly tested in simulation under extremely reduced visibility due to sandstorms and fog. The results are compared with state-of-the-art de-hazing methods across the benchmarked MBZIRC simulation dataset, on which the proposed scheme has outperformed the existing methods across various metrics.","sentences":["Visual perception is an important component for autonomous navigation of unmanned surface vessels (USV), particularly for the tasks related to autonomous inspection and tracking.","These tasks involve vision-based navigation techniques to identify the target for navigation.","Reduced visibility under extreme weather conditions in marine environments makes it difficult for vision-based approaches to work properly.","To overcome these issues, this paper presents an autonomous vision-based navigation framework for tracking target objects in extreme marine conditions.","The proposed framework consists of an integrated perception pipeline that uses a generative adversarial network (GAN) to remove noise and highlight the object features before passing them to the object detector (i.e., YOLOv5).","The detected visual features are then used by the USV to track the target.","The proposed framework has been thoroughly tested in simulation under extremely reduced visibility due to sandstorms and fog.","The results are compared with state-of-the-art de-hazing methods across the benchmarked MBZIRC simulation dataset, on which the proposed scheme has outperformed the existing methods across various metrics."],"url":"http://arxiv.org/abs/2308.04283v1"}
{"created":"2023-08-08 14:17:17","title":"In-Context Alignment: Chat with Vanilla Language Models Before Fine-Tuning","abstract":"In this note, we explore inference-time alignment through in-context learning. We consider a vanilla pretrained language model Llama-2 before any fine-tuning and retrieve an average of 9 demonstration alignment examples when the model is prompted to follow chat-style instructions. Compared to direct prompting, the in-context alignment without changing model weights leads to a 7x increase in win-rate w.r.t. the text-davinci-003 model from OpenAI, making the vanilla language model comparable to strong baselines with alignment fine-tuning.","sentences":["In this note, we explore inference-time alignment through in-context learning.","We consider a vanilla pretrained language model Llama-2 before any fine-tuning and retrieve an average of 9 demonstration alignment examples when the model is prompted to follow chat-style instructions.","Compared to direct prompting, the in-context alignment without changing model weights leads to a 7x increase in win-rate w.r.t.","the text-davinci-003 model from OpenAI, making the vanilla language model comparable to strong baselines with alignment fine-tuning."],"url":"http://arxiv.org/abs/2308.04275v1"}
{"created":"2023-08-08 14:10:16","title":"Lossy and Lossless (L$^2$) Post-training Model Size Compression","abstract":"Deep neural networks have delivered remarkable performance and have been widely used in various visual tasks. However, their huge size causes significant inconvenience for transmission and storage. Many previous studies have explored model size compression. However, these studies often approach various lossy and lossless compression methods in isolation, leading to challenges in achieving high compression ratios efficiently. This work proposes a post-training model size compression method that combines lossy and lossless compression in a unified way. We first propose a unified parametric weight transformation, which ensures different lossy compression methods can be performed jointly in a post-training manner. Then, a dedicated differentiable counter is introduced to guide the optimization of lossy compression to arrive at a more suitable point for later lossless compression. Additionally, our method can easily control a desired global compression ratio and allocate adaptive ratios for different layers. Finally, our method can achieve a stable $10\\times$ compression ratio without sacrificing accuracy and a $20\\times$ compression ratio with minor accuracy loss in a short time. Our code is available at https://github.com/ModelTC/L2_Compression .","sentences":["Deep neural networks have delivered remarkable performance and have been widely used in various visual tasks.","However, their huge size causes significant inconvenience for transmission and storage.","Many previous studies have explored model size compression.","However, these studies often approach various lossy and lossless compression methods in isolation, leading to challenges in achieving high compression ratios efficiently.","This work proposes a post-training model size compression method that combines lossy and lossless compression in a unified way.","We first propose a unified parametric weight transformation, which ensures different lossy compression methods can be performed jointly in a post-training manner.","Then, a dedicated differentiable counter is introduced to guide the optimization of lossy compression to arrive at a more suitable point for later lossless compression.","Additionally, our method can easily control a desired global compression ratio and allocate adaptive ratios for different layers.","Finally, our method can achieve a stable $10\\times$ compression ratio without sacrificing accuracy and a $20\\times$ compression ratio with minor accuracy loss in a short time.","Our code is available at https://github.com/ModelTC/L2_Compression ."],"url":"http://arxiv.org/abs/2308.04269v1"}
{"created":"2023-08-08 14:09:33","title":"Teacher-Student Architecture for Knowledge Distillation: A Survey","abstract":"Although Deep neural networks (DNNs) have shown a strong capacity to solve large-scale problems in many areas, such DNNs are hard to be deployed in real-world systems due to their voluminous parameters. To tackle this issue, Teacher-Student architectures were proposed, where simple student networks with a few parameters can achieve comparable performance to deep teacher networks with many parameters. Recently, Teacher-Student architectures have been effectively and widely embraced on various knowledge distillation (KD) objectives, including knowledge compression, knowledge expansion, knowledge adaptation, and knowledge enhancement. With the help of Teacher-Student architectures, current studies are able to achieve multiple distillation objectives through lightweight and generalized student networks. Different from existing KD surveys that primarily focus on knowledge compression, this survey first explores Teacher-Student architectures across multiple distillation objectives. This survey presents an introduction to various knowledge representations and their corresponding optimization objectives. Additionally, we provide a systematic overview of Teacher-Student architectures with representative learning algorithms and effective distillation schemes. This survey also summarizes recent applications of Teacher-Student architectures across multiple purposes, including classification, recognition, generation, ranking, and regression. Lastly, potential research directions in KD are investigated, focusing on architecture design, knowledge quality, and theoretical studies of regression-based learning, respectively. Through this comprehensive survey, industry practitioners and the academic community can gain valuable insights and guidelines for effectively designing, learning, and applying Teacher-Student architectures on various distillation objectives.","sentences":["Although Deep neural networks (DNNs) have shown a strong capacity to solve large-scale problems in many areas, such DNNs are hard to be deployed in real-world systems due to their voluminous parameters.","To tackle this issue, Teacher-Student architectures were proposed, where simple student networks with a few parameters can achieve comparable performance to deep teacher networks with many parameters.","Recently, Teacher-Student architectures have been effectively and widely embraced on various knowledge distillation (KD) objectives, including knowledge compression, knowledge expansion, knowledge adaptation, and knowledge enhancement.","With the help of Teacher-Student architectures, current studies are able to achieve multiple distillation objectives through lightweight and generalized student networks.","Different from existing KD surveys that primarily focus on knowledge compression, this survey first explores Teacher-Student architectures across multiple distillation objectives.","This survey presents an introduction to various knowledge representations and their corresponding optimization objectives.","Additionally, we provide a systematic overview of Teacher-Student architectures with representative learning algorithms and effective distillation schemes.","This survey also summarizes recent applications of Teacher-Student architectures across multiple purposes, including classification, recognition, generation, ranking, and regression.","Lastly, potential research directions in KD are investigated, focusing on architecture design, knowledge quality, and theoretical studies of regression-based learning, respectively.","Through this comprehensive survey, industry practitioners and the academic community can gain valuable insights and guidelines for effectively designing, learning, and applying Teacher-Student architectures on various distillation objectives."],"url":"http://arxiv.org/abs/2308.04268v1"}
{"created":"2023-08-08 14:08:45","title":"The Vulnerable Nature of Decentralized Governance in DeFi","abstract":"Decentralized Finance (DeFi) platforms are often governed by Decentralized Autonomous Organizations (DAOs) which are implemented via governance protocols. Governance tokens are distributed to users of the platform, granting them voting rights in the platform's governance protocol. Many DeFi platforms have already been subject to attacks resulting in the loss of millions of dollars in user funds.   In this paper we show that governance tokens are often not used as intended and may be harmful to the security of DeFi platforms. We show that (1) users often do not use governance tokens to vote, (2) that voting rates are negatively correlated to gas prices, (3) voting is very centralized.   We explore vulnerabilities in the design of DeFi platform's governance protocols and analyze different governance attacks, focusing on the transferable nature of voting rights via governance tokens. Following the movement and holdings of governance tokens, we show they are often used to perform a single action and then sold off. We present evidence of DeFi platforms using other platforms' governance protocols to promote their own agenda at the expense of the host platform.","sentences":["Decentralized Finance (DeFi) platforms are often governed by Decentralized Autonomous Organizations (DAOs) which are implemented via governance protocols.","Governance tokens are distributed to users of the platform, granting them voting rights in the platform's governance protocol.","Many DeFi platforms have already been subject to attacks resulting in the loss of millions of dollars in user funds.   ","In this paper we show that governance tokens are often not used as intended and may be harmful to the security of DeFi platforms.","We show that (1) users often do not use governance tokens to vote, (2) that voting rates are negatively correlated to gas prices, (3) voting is very centralized.   ","We explore vulnerabilities in the design of DeFi platform's governance protocols and analyze different governance attacks, focusing on the transferable nature of voting rights via governance tokens.","Following the movement and holdings of governance tokens, we show they are often used to perform a single action and then sold off.","We present evidence of DeFi platforms using other platforms' governance protocols to promote their own agenda at the expense of the host platform."],"url":"http://arxiv.org/abs/2308.04267v1"}
{"created":"2023-08-08 14:08:40","title":"MCDAN: a Multi-scale Context-enhanced Dynamic Attention Network for Diffusion Prediction","abstract":"Information diffusion prediction aims at predicting the target users in the information diffusion path on social networks. Prior works mainly focus on the observed structure or sequence of cascades, trying to predict to whom this cascade will be infected passively. In this study, we argue that user intent understanding is also a key part of information diffusion prediction. We thereby propose a novel Multi-scale Context-enhanced Dynamic Attention Network (MCDAN) to predict which user will most likely join the observed current cascades. Specifically, to consider the global interactive relationship among users, we take full advantage of user friendships and global cascading relationships, which are extracted from the social network and historical cascades, respectively. To refine the model's ability to understand the user's preference for the current cascade, we propose a multi-scale sequential hypergraph attention module to capture the dynamic preference of users at different time scales. Moreover, we design a contextual attention enhancement module to strengthen the interaction of user representations within the current cascade. Finally, to engage the user's own susceptibility, we construct a susceptibility label for each user based on user susceptibility analysis and use the rank of this label for auxiliary prediction. We conduct experiments over four widely used datasets and show that MCDAN significantly overperforms the state-of-the-art models. The average improvements are up to 10.61% in terms of Hits@100 and 9.71% in terms of MAP@100, respectively.","sentences":["Information diffusion prediction aims at predicting the target users in the information diffusion path on social networks.","Prior works mainly focus on the observed structure or sequence of cascades, trying to predict to whom this cascade will be infected passively.","In this study, we argue that user intent understanding is also a key part of information diffusion prediction.","We thereby propose a novel Multi-scale Context-enhanced Dynamic Attention Network (MCDAN) to predict which user will most likely join the observed current cascades.","Specifically, to consider the global interactive relationship among users, we take full advantage of user friendships and global cascading relationships, which are extracted from the social network and historical cascades, respectively.","To refine the model's ability to understand the user's preference for the current cascade, we propose a multi-scale sequential hypergraph attention module to capture the dynamic preference of users at different time scales.","Moreover, we design a contextual attention enhancement module to strengthen the interaction of user representations within the current cascade.","Finally, to engage the user's own susceptibility, we construct a susceptibility label for each user based on user susceptibility analysis and use the rank of this label for auxiliary prediction.","We conduct experiments over four widely used datasets and show that MCDAN significantly overperforms the state-of-the-art models.","The average improvements are up to 10.61% in terms of Hits@100 and 9.71% in terms of MAP@100, respectively."],"url":"http://arxiv.org/abs/2308.04266v1"}
{"created":"2023-08-08 14:03:08","title":"FLIRT: Feedback Loop In-context Red Teaming","abstract":"Warning: this paper contains content that may be inappropriate or offensive.   As generative models become available for public use in various applications, testing and analyzing vulnerabilities of these models has become a priority. Here we propose an automatic red teaming framework that evaluates a given model and exposes its vulnerabilities against unsafe and inappropriate content generation. Our framework uses in-context learning in a feedback loop to red team models and trigger them into unsafe content generation. We propose different in-context attack strategies to automatically learn effective and diverse adversarial prompts for text-to-image models. Our experiments demonstrate that compared to baseline approaches, our proposed strategy is significantly more effective in exposing vulnerabilities in Stable Diffusion (SD) model, even when the latter is enhanced with safety features. Furthermore, we demonstrate that the proposed framework is effective for red teaming text-to-text models, resulting in significantly higher toxic response generation rate compared to previously reported numbers.","sentences":["Warning: this paper contains content that may be inappropriate or offensive.   ","As generative models become available for public use in various applications, testing and analyzing vulnerabilities of these models has become a priority.","Here we propose an automatic red teaming framework that evaluates a given model and exposes its vulnerabilities against unsafe and inappropriate content generation.","Our framework uses in-context learning in a feedback loop to red team models and trigger them into unsafe content generation.","We propose different in-context attack strategies to automatically learn effective and diverse adversarial prompts for text-to-image models.","Our experiments demonstrate that compared to baseline approaches, our proposed strategy is significantly more effective in exposing vulnerabilities in Stable Diffusion (SD) model, even when the latter is enhanced with safety features.","Furthermore, we demonstrate that the proposed framework is effective for red teaming text-to-text models, resulting in significantly higher toxic response generation rate compared to previously reported numbers."],"url":"http://arxiv.org/abs/2308.04265v1"}
{"created":"2023-08-08 14:00:58","title":"Tolerant Testing of High-Dimensional Samplers with Subcube Conditioning","abstract":"We study the tolerant testing problem for high-dimensional samplers. Given as input two samplers $\\mathcal{P}$ and $\\mathcal{Q}$ over the $n$-dimensional space $\\{0,1\\}^n$, and two parameters $\\varepsilon_2 > \\varepsilon_1$, the goal of tolerant testing is to test whether the distributions generated by $\\mathcal{P}$ and $\\mathcal{Q}$ are $\\varepsilon_1$-close or $\\varepsilon_2$-far. Since exponential lower bounds (in $n$) are known for the problem in the standard sampling model, research has focused on models where one can draw \\textit{conditional} samples.   Among these models, \\textit{subcube conditioning} ($\\mathsf{SUBCOND}$), which allows conditioning on arbitrary subcubes of the domain, holds the promise of widespread adoption in practice owing to its ability to capture the natural behavior of samplers in constrained domains. To translate the promise into practice, we need to overcome two crucial roadblocks for tests based on $\\mathsf{SUBCOND}$: the prohibitively large number of queries ($\\tilde{\\mathcal{O}}(n^5/\\varepsilon_2^5)$) and limitation to non-tolerant testing (i.e., $\\varepsilon_1 = 0$).   The primary contribution of this work is to overcome the above challenges: we design a new tolerant testing methodology (i.e., $\\varepsilon_1 \\geq 0$) that allows us to significantly improve the upper bound to $\\tilde{\\mathcal{O}}(n^3/(\\varepsilon_2-\\varepsilon_1)^5)$.","sentences":["We study the tolerant testing problem for high-dimensional samplers.","Given as input two samplers $\\mathcal{P}$ and $\\mathcal{Q}$ over the $n$-dimensional space $\\{0,1\\}^n$, and two parameters $\\varepsilon_2 > \\varepsilon_1$, the goal of tolerant testing is to test whether the distributions generated by $\\mathcal{P}$ and $\\mathcal{Q}$ are $\\varepsilon_1$-close or $\\varepsilon_2$-far.","Since exponential lower bounds (in $n$) are known for the problem in the standard sampling model, research has focused on models where one can draw \\textit{conditional} samples.   ","Among these models, \\textit{subcube conditioning} ($\\mathsf{SUBCOND}$), which allows conditioning on arbitrary subcubes of the domain, holds the promise of widespread adoption in practice owing to its ability to capture the natural behavior of samplers in constrained domains.","To translate the promise into practice, we need to overcome two crucial roadblocks for tests based on $\\mathsf{SUBCOND}$: the prohibitively large number of queries ($\\tilde{\\mathcal{O}}(n^5/\\varepsilon_2^5)$) and limitation to non-tolerant testing (i.e., $\\varepsilon_1 = 0$).   ","The primary contribution of this work is to overcome the above challenges: we design a new tolerant testing methodology (i.e., $\\varepsilon_1 \\geq 0$) that allows us to significantly improve the upper bound to $\\tilde{\\mathcal{O}}(n^3/(\\varepsilon_2-\\varepsilon_1)^5)$."],"url":"http://arxiv.org/abs/2308.04264v1"}
{"created":"2023-08-08 13:59:56","title":"BarlowRL: Barlow Twins for Data-Efficient Reinforcement Learning","abstract":"This paper introduces BarlowRL, a data-efficient reinforcement learning agent that combines the Barlow Twins self-supervised learning framework with DER (Data-Efficient Rainbow) algorithm. BarlowRL outperforms both DER and its contrastive counterpart CURL on the Atari 100k benchmark. BarlowRL avoids dimensional collapse by enforcing information spread to the whole space. This helps RL algorithms to utilize uniformly spread state representation that eventually results in a remarkable performance. The integration of Barlow Twins with DER enhances data efficiency and achieves superior performance in the RL tasks. BarlowRL demonstrates the potential of incorporating self-supervised learning techniques to improve RL algorithms.","sentences":["This paper introduces BarlowRL, a data-efficient reinforcement learning agent that combines the Barlow Twins self-supervised learning framework with DER (Data-Efficient Rainbow) algorithm.","BarlowRL outperforms both DER and its contrastive counterpart CURL on the Atari 100k benchmark.","BarlowRL avoids dimensional collapse by enforcing information spread to the whole space.","This helps RL algorithms to utilize uniformly spread state representation that eventually results in a remarkable performance.","The integration of Barlow Twins with DER enhances data efficiency and achieves superior performance in the RL tasks.","BarlowRL demonstrates the potential of incorporating self-supervised learning techniques to improve RL algorithms."],"url":"http://arxiv.org/abs/2308.04263v1"}
{"created":"2023-08-08 13:58:20","title":"Novel Area-Efficient and Flexible Architectures for Optimal Ate Pairing on FPGA","abstract":"While FPGA is a suitable platform for implementing cryptographic algorithms, there are several challenges associated with implementing Optimal Ate pairing on FPGA, such as security, limited computing resources, and high power consumption. To overcome these issues, this study introduces three approaches that can execute the optimal Ate pairing on Barreto-Naehrig curves using Jacobean coordinates with the goal of reaching 128-bit security on the Genesys board. The first approach is a pure software implementation utilizing the MicroBlaze processor. The second involves a combination of software and hardware, with key operations in $F_{p}$ and $F_{p^{2}}$ being transformed into IP cores for the MicroBlaze. The third approach builds on the second by incorporating parallelism to improve the pairing process. The utilization of multiple MicroBlaze processors within a single system offers both versatility and parallelism to speed up pairing calculations. A variety of methods and parameters are used to optimize the pairing computation, including Montgomery modular multiplication, the Karatsuba method, Jacobean coordinates, the Complex squaring method, sparse multiplication, squaring in $G_{\\phi 6}F_{p^{12}}$, and the addition chain method. The proposed systems are designed to efficiently utilize limited resources in restricted environments, while still completing tasks in a timely manner.","sentences":["While FPGA is a suitable platform for implementing cryptographic algorithms, there are several challenges associated with implementing Optimal Ate pairing on FPGA, such as security, limited computing resources, and high power consumption.","To overcome these issues, this study introduces three approaches that can execute the optimal Ate pairing on Barreto-Naehrig curves using Jacobean coordinates with the goal of reaching 128-bit security on the Genesys board.","The first approach is a pure software implementation utilizing the MicroBlaze processor.","The second involves a combination of software and hardware, with key operations in $F_{p}$ and $F_{p^{2}}$ being transformed into IP cores for the MicroBlaze.","The third approach builds on the second by incorporating parallelism to improve the pairing process.","The utilization of multiple MicroBlaze processors within a single system offers both versatility and parallelism to speed up pairing calculations.","A variety of methods and parameters are used to optimize the pairing computation, including Montgomery modular multiplication, the Karatsuba method, Jacobean coordinates, the Complex squaring method, sparse multiplication, squaring in $G_{\\phi 6}F_{p^{12}}$, and the addition chain method.","The proposed systems are designed to efficiently utilize limited resources in restricted environments, while still completing tasks in a timely manner."],"url":"http://arxiv.org/abs/2308.04261v1"}
{"created":"2023-08-08 13:41:41","title":"CLASSLA-Stanza: The Next Step for Linguistic Processing of South Slavic Languages","abstract":"We present CLASSLA-Stanza, a pipeline for automatic linguistic annotation of the South Slavic languages, which is based on the Stanza natural language processing pipeline. We describe the main improvements in CLASSLA-Stanza with respect to Stanza, and give a detailed description of the model training process for the latest 2.1 release of the pipeline. We also report performance scores produced by the pipeline for different languages and varieties. CLASSLA-Stanza exhibits consistently high performance across all the supported languages and outperforms or expands its parent pipeline Stanza at all the supported tasks. We also present the pipeline's new functionality enabling efficient processing of web data and the reasons that led to its implementation.","sentences":["We present CLASSLA-Stanza, a pipeline for automatic linguistic annotation of the South Slavic languages, which is based on the Stanza natural language processing pipeline.","We describe the main improvements in CLASSLA-Stanza with respect to Stanza, and give a detailed description of the model training process for the latest 2.1 release of the pipeline.","We also report performance scores produced by the pipeline for different languages and varieties.","CLASSLA-Stanza exhibits consistently high performance across all the supported languages and outperforms or expands its parent pipeline Stanza at all the supported tasks.","We also present the pipeline's new functionality enabling efficient processing of web data and the reasons that led to its implementation."],"url":"http://arxiv.org/abs/2308.04255v1"}
{"created":"2023-08-08 13:35:38","title":"On the Node-Averaged Complexity of Locally Checkable Problems on Trees","abstract":"Over the past decade, a long line of research has investigated the distributed complexity landscape of locally checkable labeling (LCL) problems on bounded-degree graphs, culminating in an almost-complete classification on general graphs and a complete classification on trees. The latter states that, on bounded-degree trees, any LCL problem has deterministic \\emph{worst-case} time complexity $O(1)$, $\\Theta(\\log^* n)$, $\\Theta(\\log n)$, or $\\Theta(n^{1/k})$ for some positive integer $k$, and all of those complexity classes are nonempty. Moreover, randomness helps only for (some) problems with deterministic worst-case complexity $\\Theta(\\log n)$, and if randomness helps (asymptotically), then it helps exponentially.   In this work, we study how many distributed rounds are needed \\emph{on average per node} in order to solve an LCL problem on trees. We obtain a partial classification of the deterministic \\emph{node-averaged} complexity landscape for LCL problems. As our main result, we show that every problem with worst-case round complexity $O(\\log n)$ has deterministic node-averaged complexity $O(\\log^* n)$. We further establish bounds on the node-averaged complexity of problems with worst-case complexity $\\Theta(n^{1/k})$: we show that all these problems have node-averaged complexity $\\widetilde{\\Omega}(n^{1 / (2^k - 1)})$, and that this lower bound is tight for some problems.","sentences":["Over the past decade, a long line of research has investigated the distributed complexity landscape of locally checkable labeling (LCL) problems on bounded-degree graphs, culminating in an almost-complete classification on general graphs and a complete classification on trees.","The latter states that, on bounded-degree trees, any LCL problem has deterministic \\emph{worst-case} time complexity $O(1)$, $\\Theta(\\log^* n)$, $\\Theta(\\log n)$, or $\\Theta(n^{1/k})$ for some positive integer $k$, and all of those complexity classes are nonempty.","Moreover, randomness helps only for (some) problems with deterministic worst-case complexity $\\Theta(\\log n)$, and if randomness helps (asymptotically), then it helps exponentially.   ","In this work, we study how many distributed rounds are needed \\emph{on average per node} in order to solve an LCL problem on trees.","We obtain a partial classification of the deterministic \\emph{node-averaged} complexity landscape for LCL problems.","As our main result, we show that every problem with worst-case round complexity $O(\\log n)$ has deterministic node-averaged complexity $O(\\log^* n)$. We further establish bounds on the node-averaged complexity of problems with worst-case complexity $\\Theta(n^{1/k})$: we show that all these problems have node-averaged complexity $\\widetilde{\\Omega}(n^{1 / (2^k - 1)})$, and that this lower bound is tight for some problems."],"url":"http://arxiv.org/abs/2308.04251v1"}
{"created":"2023-08-08 13:28:34","title":"MindDiffuser: Controlled Image Reconstruction from Human Brain Activity with Semantic and Structural Diffusion","abstract":"Reconstructing visual stimuli from brain recordings has been a meaningful and challenging task. Especially, the achievement of precise and controllable image reconstruction bears great significance in propelling the progress and utilization of brain-computer interfaces. Despite the advancements in complex image reconstruction techniques, the challenge persists in achieving a cohesive alignment of both semantic (concepts and objects) and structure (position, orientation, and size) with the image stimuli. To address the aforementioned issue, we propose a two-stage image reconstruction model called MindDiffuser. In Stage 1, the VQ-VAE latent representations and the CLIP text embeddings decoded from fMRI are put into Stable Diffusion, which yields a preliminary image that contains semantic information. In Stage 2, we utilize the CLIP visual feature decoded from fMRI as supervisory information, and continually adjust the two feature vectors decoded in Stage 1 through backpropagation to align the structural information. The results of both qualitative and quantitative analyses demonstrate that our model has surpassed the current state-of-the-art models on Natural Scenes Dataset (NSD). The subsequent experimental findings corroborate the neurobiological plausibility of the model, as evidenced by the interpretability of the multimodal feature employed, which align with the corresponding brain responses.","sentences":["Reconstructing visual stimuli from brain recordings has been a meaningful and challenging task.","Especially, the achievement of precise and controllable image reconstruction bears great significance in propelling the progress and utilization of brain-computer interfaces.","Despite the advancements in complex image reconstruction techniques, the challenge persists in achieving a cohesive alignment of both semantic (concepts and objects) and structure (position, orientation, and size) with the image stimuli.","To address the aforementioned issue, we propose a two-stage image reconstruction model called MindDiffuser.","In Stage 1, the VQ-VAE latent representations and the CLIP text embeddings decoded from fMRI are put into Stable Diffusion, which yields a preliminary image that contains semantic information.","In Stage 2, we utilize the CLIP visual feature decoded from fMRI as supervisory information, and continually adjust the two feature vectors decoded in Stage 1 through backpropagation to align the structural information.","The results of both qualitative and quantitative analyses demonstrate that our model has surpassed the current state-of-the-art models on Natural Scenes Dataset (NSD).","The subsequent experimental findings corroborate the neurobiological plausibility of the model, as evidenced by the interpretability of the multimodal feature employed, which align with the corresponding brain responses."],"url":"http://arxiv.org/abs/2308.04249v1"}
{"created":"2023-08-08 13:26:53","title":"Gloss Alignment Using Word Embeddings","abstract":"Capturing and annotating Sign language datasets is a time consuming and costly process. Current datasets are orders of magnitude too small to successfully train unconstrained \\acf{slt} models. As a result, research has turned to TV broadcast content as a source of large-scale training data, consisting of both the sign language interpreter and the associated audio subtitle. However, lack of sign language annotation limits the usability of this data and has led to the development of automatic annotation techniques such as sign spotting. These spottings are aligned to the video rather than the subtitle, which often results in a misalignment between the subtitle and spotted signs. In this paper we propose a method for aligning spottings with their corresponding subtitles using large spoken language models. Using a single modality means our method is computationally inexpensive and can be utilized in conjunction with existing alignment techniques. We quantitatively demonstrate the effectiveness of our method on the \\acf{mdgs} and \\acf{bobsl} datasets, recovering up to a 33.22 BLEU-1 score in word alignment.","sentences":["Capturing and annotating Sign language datasets is a time consuming and costly process.","Current datasets are orders of magnitude too small to successfully train unconstrained \\acf{slt} models.","As a result, research has turned to TV broadcast content as a source of large-scale training data, consisting of both the sign language interpreter and the associated audio subtitle.","However, lack of sign language annotation limits the usability of this data and has led to the development of automatic annotation techniques such as sign spotting.","These spottings are aligned to the video rather than the subtitle, which often results in a misalignment between the subtitle and spotted signs.","In this paper we propose a method for aligning spottings with their corresponding subtitles using large spoken language models.","Using a single modality means our method is computationally inexpensive and can be utilized in conjunction with existing alignment techniques.","We quantitatively demonstrate the effectiveness of our method on the \\acf{mdgs} and \\acf{bobsl} datasets, recovering up to a 33.22 BLEU-1 score in word alignment."],"url":"http://arxiv.org/abs/2308.04248v1"}
{"created":"2023-08-08 13:26:36","title":"UniRecSys: A Unified Framework for Personalized, Group, Package, and Package-to-Group Recommendations","abstract":"Recommender systems aim to enhance the overall user experience by providing tailored recommendations for a variety of products and services. These systems help users make more informed decisions, leading to greater user satisfaction with the platform. However, the implementation of these systems largely depends on the context, which can vary from recommending an item or package to a user or a group. This requires careful exploration of several models during the deployment, as there is no comprehensive and unified approach that deals with recommendations at different levels. Furthermore, these individual models must be closely attuned to their generated recommendations depending on the context to prevent significant variation in their generated recommendations. In this paper, we propose a novel unified recommendation framework that addresses all four recommendation tasks, namely personalized, group, package, or package-to-group recommendation, filling the gap in the current research landscape. The proposed framework can be integrated with most of the traditional matrix factorization-based collaborative filtering models. The idea is to enhance the formulation of the existing approaches by incorporating components focusing on the exploitation of the group and package latent factors. These components also help in exploiting a rich latent representation of the user/item by enforcing them to align closely with their corresponding group/package representation. We consider two prominent CF techniques, Regularized Matrix Factorization and Maximum Margin Matrix factorization, as the baseline models and demonstrate their customization to various recommendation tasks. Experiment results on two publicly available datasets are reported, comparing them to other baseline approaches that consider individual rating feedback for group or package recommendations.","sentences":["Recommender systems aim to enhance the overall user experience by providing tailored recommendations for a variety of products and services.","These systems help users make more informed decisions, leading to greater user satisfaction with the platform.","However, the implementation of these systems largely depends on the context, which can vary from recommending an item or package to a user or a group.","This requires careful exploration of several models during the deployment, as there is no comprehensive and unified approach that deals with recommendations at different levels.","Furthermore, these individual models must be closely attuned to their generated recommendations depending on the context to prevent significant variation in their generated recommendations.","In this paper, we propose a novel unified recommendation framework that addresses all four recommendation tasks, namely personalized, group, package, or package-to-group recommendation, filling the gap in the current research landscape.","The proposed framework can be integrated with most of the traditional matrix factorization-based collaborative filtering models.","The idea is to enhance the formulation of the existing approaches by incorporating components focusing on the exploitation of the group and package latent factors.","These components also help in exploiting a rich latent representation of the user/item by enforcing them to align closely with their corresponding group/package representation.","We consider two prominent CF techniques, Regularized Matrix Factorization and Maximum Margin Matrix factorization, as the baseline models and demonstrate their customization to various recommendation tasks.","Experiment results on two publicly available datasets are reported, comparing them to other baseline approaches that consider individual rating feedback for group or package recommendations."],"url":"http://arxiv.org/abs/2308.04247v1"}
{"created":"2023-08-08 13:17:37","title":"Auditory Attention Decoding with Task-Related Multi-View Contrastive Learning","abstract":"The human brain can easily focus on one speaker and suppress others in scenarios such as a cocktail party. Recently, researchers found that auditory attention can be decoded from the electroencephalogram (EEG) data. However, most existing deep learning methods are difficult to use prior knowledge of different views (that is attended speech and EEG are task-related views) and extract an unsatisfactory representation. Inspired by Broadbent's filter model, we decode auditory attention in a multi-view paradigm and extract the most relevant and important information utilizing the missing view. Specifically, we propose an auditory attention decoding (AAD) method based on multi-view VAE with task-related multi-view contrastive (TMC) learning. Employing TMC learning in multi-view VAE can utilize the missing view to accumulate prior knowledge of different views into the fusion of representation, and extract the approximate task-related representation. We examine our method on two popular AAD datasets, and demonstrate the superiority of our method by comparing it to the state-of-the-art method.","sentences":["The human brain can easily focus on one speaker and suppress others in scenarios such as a cocktail party.","Recently, researchers found that auditory attention can be decoded from the electroencephalogram (EEG) data.","However, most existing deep learning methods are difficult to use prior knowledge of different views (that is attended speech and EEG are task-related views) and extract an unsatisfactory representation.","Inspired by Broadbent's filter model, we decode auditory attention in a multi-view paradigm and extract the most relevant and important information utilizing the missing view.","Specifically, we propose an auditory attention decoding (AAD) method based on multi-view VAE with task-related multi-view contrastive (TMC) learning.","Employing TMC learning in multi-view VAE can utilize the missing view to accumulate prior knowledge of different views into the fusion of representation, and extract the approximate task-related representation.","We examine our method on two popular AAD datasets, and demonstrate the superiority of our method by comparing it to the state-of-the-art method."],"url":"http://arxiv.org/abs/2308.04244v1"}
{"created":"2023-08-08 13:17:20","title":"AICSD: Adaptive Inter-Class Similarity Distillation for Semantic Segmentation","abstract":"In recent years, deep neural networks have achieved remarkable accuracy in computer vision tasks. With inference time being a crucial factor, particularly in dense prediction tasks such as semantic segmentation, knowledge distillation has emerged as a successful technique for improving the accuracy of lightweight student networks. The existing methods often neglect the information in channels and among different classes. To overcome these limitations, this paper proposes a novel method called Inter-Class Similarity Distillation (ICSD) for the purpose of knowledge distillation. The proposed method transfers high-order relations from the teacher network to the student network by independently computing intra-class distributions for each class from network outputs. This is followed by calculating inter-class similarity matrices for distillation using KL divergence between distributions of each pair of classes. To further improve the effectiveness of the proposed method, an Adaptive Loss Weighting (ALW) training strategy is proposed. Unlike existing methods, the ALW strategy gradually reduces the influence of the teacher network towards the end of training process to account for errors in teacher's predictions. Extensive experiments conducted on two well-known datasets for semantic segmentation, Cityscapes and Pascal VOC 2012, validate the effectiveness of the proposed method in terms of mIoU and pixel accuracy. The proposed method outperforms most of existing knowledge distillation methods as demonstrated by both quantitative and qualitative evaluations. Code is available at: https://github.com/AmirMansurian/AICSD","sentences":["In recent years, deep neural networks have achieved remarkable accuracy in computer vision tasks.","With inference time being a crucial factor, particularly in dense prediction tasks such as semantic segmentation, knowledge distillation has emerged as a successful technique for improving the accuracy of lightweight student networks.","The existing methods often neglect the information in channels and among different classes.","To overcome these limitations, this paper proposes a novel method called Inter-Class Similarity Distillation (ICSD) for the purpose of knowledge distillation.","The proposed method transfers high-order relations from the teacher network to the student network by independently computing intra-class distributions for each class from network outputs.","This is followed by calculating inter-class similarity matrices for distillation using KL divergence between distributions of each pair of classes.","To further improve the effectiveness of the proposed method, an Adaptive Loss Weighting (ALW) training strategy is proposed.","Unlike existing methods, the ALW strategy gradually reduces the influence of the teacher network towards the end of training process to account for errors in teacher's predictions.","Extensive experiments conducted on two well-known datasets for semantic segmentation, Cityscapes and Pascal VOC 2012, validate the effectiveness of the proposed method in terms of mIoU and pixel accuracy.","The proposed method outperforms most of existing knowledge distillation methods as demonstrated by both quantitative and qualitative evaluations.","Code is available at: https://github.com/AmirMansurian/AICSD"],"url":"http://arxiv.org/abs/2308.04243v1"}
{"created":"2023-08-08 13:12:03","title":"AutoPCF: Efficient Product Carbon Footprint Accounting with Large Language Models","abstract":"The product carbon footprint (PCF) is crucial for decarbonizing the supply chain, as it measures the direct and indirect greenhouse gas emissions caused by all activities during the product's life cycle. However, PCF accounting often requires expert knowledge and significant time to construct life cycle models. In this study, we test and compare the emergent ability of five large language models (LLMs) in modeling the 'cradle-to-gate' life cycles of products and generating the inventory data of inputs and outputs, revealing their limitations as a generalized PCF knowledge database. By utilizing LLMs, we propose an automatic AI-driven PCF accounting framework, called AutoPCF, which also applies deep learning algorithms to automatically match calculation parameters, and ultimately calculate the PCF. The results of estimating the carbon footprint for three case products using the AutoPCF framework demonstrate its potential in achieving automatic modeling and estimation of PCF with a large reduction in modeling time from days to minutes.","sentences":["The product carbon footprint (PCF) is crucial for decarbonizing the supply chain, as it measures the direct and indirect greenhouse gas emissions caused by all activities during the product's life cycle.","However, PCF accounting often requires expert knowledge and significant time to construct life cycle models.","In this study, we test and compare the emergent ability of five large language models (LLMs) in modeling the 'cradle-to-gate' life cycles of products and generating the inventory data of inputs and outputs, revealing their limitations as a generalized PCF knowledge database.","By utilizing LLMs, we propose an automatic AI-driven PCF accounting framework, called AutoPCF, which also applies deep learning algorithms to automatically match calculation parameters, and ultimately calculate the PCF.","The results of estimating the carbon footprint for three case products using the AutoPCF framework demonstrate its potential in achieving automatic modeling and estimation of PCF with a large reduction in modeling time from days to minutes."],"url":"http://arxiv.org/abs/2308.04241v1"}
{"created":"2023-08-08 13:03:36","title":"Federated Inference with Reliable Uncertainty Quantification over Wireless Channels via Conformal Prediction","abstract":"Consider a setting in which devices and a server share a pre-trained model. The server wishes to make an inference on a new input given the model. Devices have access to data, previously not used for training, and can communicate to the server over a common wireless channel. If the devices have no access to the new input, can communication from devices to the server enhance the quality of the inference decision at the server? Recent work has introduced federated conformal prediction (CP), which leverages devices-to-server communication to improve the reliability of the server's decision. With federated CP, devices communicate to the server information about the loss accrued by the shared pre-trained model on the local data, and the server leverages this information to calibrate a decision interval, or set, so that it is guaranteed to contain the correct answer with a pre-defined target reliability level. Previous work assumed noise-free communication, whereby devices can communicate a single real number to the server. In this paper, we study for the first time federated CP in a wireless setting. We introduce a novel protocol, termed wireless federated conformal prediction (WFCP), which builds on type-based multiple access (TBMA) and on a novel quantile correction strategy. WFCP is proved to provide formal reliability guarantees in terms of coverage of the predicted set produced by the server. Using numerical results, we demonstrate the significant advantages of WFCP against digital implementations of existing federated CP schemes, especially in regimes with limited communication resources and/or large number of devices.","sentences":["Consider a setting in which devices and a server share a pre-trained model.","The server wishes to make an inference on a new input given the model.","Devices have access to data, previously not used for training, and can communicate to the server over a common wireless channel.","If the devices have no access to the new input, can communication from devices to the server enhance the quality of the inference decision at the server?","Recent work has introduced federated conformal prediction (CP), which leverages devices-to-server communication to improve the reliability of the server's decision.","With federated CP, devices communicate to the server information about the loss accrued by the shared pre-trained model on the local data, and the server leverages this information to calibrate a decision interval, or set, so that it is guaranteed to contain the correct answer with a pre-defined target reliability level.","Previous work assumed noise-free communication, whereby devices can communicate a single real number to the server.","In this paper, we study for the first time federated CP in a wireless setting.","We introduce a novel protocol, termed wireless federated conformal prediction (WFCP), which builds on type-based multiple access (TBMA) and on a novel quantile correction strategy.","WFCP is proved to provide formal reliability guarantees in terms of coverage of the predicted set produced by the server.","Using numerical results, we demonstrate the significant advantages of WFCP against digital implementations of existing federated CP schemes, especially in regimes with limited communication resources and/or large number of devices."],"url":"http://arxiv.org/abs/2308.04237v1"}
{"created":"2023-08-08 12:54:05","title":"A Comparative Study of Image-to-Image Translation Using GANs for Synthetic Child Race Data","abstract":"The lack of ethnic diversity in data has been a limiting factor of face recognition techniques in the literature. This is particularly the case for children where data samples are scarce and presents a challenge when seeking to adapt machine vision algorithms that are trained on adult data to work on children. This work proposes the utilization of image-to-image transformation to synthesize data of different races and thus adjust the ethnicity of children's face data. We consider ethnicity as a style and compare three different Image-to-Image neural network based methods, specifically pix2pix, CycleGAN, and CUT networks to implement Caucasian child data and Asian child data conversion. Experimental validation results on synthetic data demonstrate the feasibility of using image-to-image transformation methods to generate various synthetic child data samples with broader ethnic diversity.","sentences":["The lack of ethnic diversity in data has been a limiting factor of face recognition techniques in the literature.","This is particularly the case for children where data samples are scarce and presents a challenge when seeking to adapt machine vision algorithms that are trained on adult data to work on children.","This work proposes the utilization of image-to-image transformation to synthesize data of different races and thus adjust the ethnicity of children's face data.","We consider ethnicity as a style and compare three different Image-to-Image neural network based methods, specifically pix2pix, CycleGAN, and CUT networks to implement Caucasian child data and Asian child data conversion.","Experimental validation results on synthetic data demonstrate the feasibility of using image-to-image transformation methods to generate various synthetic child data samples with broader ethnic diversity."],"url":"http://arxiv.org/abs/2308.04232v1"}
{"created":"2023-08-08 12:45:01","title":"OpinionConv: Conversational Product Search with Grounded Opinions","abstract":"When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision-making.","sentences":["When searching for products, the opinions of others play an important role in making informed decisions.","Subjective experiences about a product can be a valuable source of information.","This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products.","However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience.","We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives.","With OpinionConv, we develop the first conversational AI for simulating sales conversations.","To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic.","Our assessors also confirm the importance of opinions as an informative basis for decision-making."],"url":"http://arxiv.org/abs/2308.04226v1"}
{"created":"2023-08-08 12:43:26","title":"Will your Doorbell Camera still recognize you as you grow old","abstract":"Robust authentication for low-power consumer devices such as doorbell cameras poses a valuable and unique challenge. This work explores the effect of age and aging on the performance of facial authentication methods. Two public age datasets, AgeDB and Morph-II have been used as baselines in this work. A photo-realistic age transformation method has been employed to augment a set of high-quality facial images with various age effects. Then the effect of these synthetic aging data on the high-performance deep-learning-based face recognition model is quantified by using various metrics including Receiver Operating Characteristic (ROC) curves and match score distributions. Experimental results demonstrate that long-term age effects are still a significant challenge for the state-of-the-art facial authentication method.","sentences":["Robust authentication for low-power consumer devices such as doorbell cameras poses a valuable and unique challenge.","This work explores the effect of age and aging on the performance of facial authentication methods.","Two public age datasets, AgeDB and Morph-II have been used as baselines in this work.","A photo-realistic age transformation method has been employed to augment a set of high-quality facial images with various age effects.","Then the effect of these synthetic aging data on the high-performance deep-learning-based face recognition model is quantified by using various metrics including Receiver Operating Characteristic (ROC) curves and match score distributions.","Experimental results demonstrate that long-term age effects are still a significant challenge for the state-of-the-art facial authentication method."],"url":"http://arxiv.org/abs/2308.04224v1"}
