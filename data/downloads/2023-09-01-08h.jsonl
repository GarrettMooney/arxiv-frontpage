{"created":"2023-08-31 17:59:46","title":"PointLLM: Empowering Large Language Models to Understand Point Clouds","abstract":"The unprecedented advancements in Large Language Models (LLMs) have created a profound impact on natural language processing but are yet to fully embrace the realm of 3D understanding. This paper introduces PointLLM, a preliminary effort to fill this gap, thereby enabling LLMs to understand point clouds and offering a new avenue beyond 2D visual data. PointLLM processes colored object point clouds with human instructions and generates contextually appropriate responses, illustrating its grasp of point clouds and common sense. Specifically, it leverages a point cloud encoder with a powerful LLM to effectively fuse geometric, appearance, and linguistic information. We collect a novel dataset comprising 660K simple and 70K complex point-text instruction pairs to enable a two-stage training strategy: initially aligning latent spaces and subsequently instruction-tuning the unified model. To rigorously evaluate our model's perceptual abilities and its generalization capabilities, we establish two benchmarks: Generative 3D Object Classification and 3D Object Captioning, assessed through three different methods, including human evaluation, GPT-4/ChatGPT evaluation, and traditional metrics. Experiment results show that PointLLM demonstrates superior performance over existing 2D baselines. Remarkably, in human-evaluated object captioning tasks, PointLLM outperforms human annotators in over 50% of the samples. Codes, datasets, and benchmarks are available at https://github.com/OpenRobotLab/PointLLM .","sentences":["The unprecedented advancements in Large Language Models (LLMs) have created a profound impact on natural language processing but are yet to fully embrace the realm of 3D understanding.","This paper introduces PointLLM, a preliminary effort to fill this gap, thereby enabling LLMs to understand point clouds and offering a new avenue beyond 2D visual data.","PointLLM processes colored object point clouds with human instructions and generates contextually appropriate responses, illustrating its grasp of point clouds and common sense.","Specifically, it leverages a point cloud encoder with a powerful LLM to effectively fuse geometric, appearance, and linguistic information.","We collect a novel dataset comprising 660K simple and 70K complex point-text instruction pairs to enable a two-stage training strategy: initially aligning latent spaces and subsequently instruction-tuning the unified model.","To rigorously evaluate our model's perceptual abilities and its generalization capabilities, we establish two benchmarks: Generative 3D Object Classification and 3D Object Captioning, assessed through three different methods, including human evaluation, GPT-4/ChatGPT evaluation, and traditional metrics.","Experiment results show that PointLLM demonstrates superior performance over existing 2D baselines.","Remarkably, in human-evaluated object captioning tasks, PointLLM outperforms human annotators in over 50% of the samples.","Codes, datasets, and benchmarks are available at https://github.com/OpenRobotLab/PointLLM ."],"url":"http://arxiv.org/abs/2308.16911v1"}
{"created":"2023-08-31 17:59:33","title":"StyleInV: A Temporal Style Modulated Inversion Network for Unconditional Video Generation","abstract":"Unconditional video generation is a challenging task that involves synthesizing high-quality videos that are both coherent and of extended duration. To address this challenge, researchers have used pretrained StyleGAN image generators for high-quality frame synthesis and focused on motion generator design. The motion generator is trained in an autoregressive manner using heavy 3D convolutional discriminators to ensure motion coherence during video generation. In this paper, we introduce a novel motion generator design that uses a learning-based inversion network for GAN. The encoder in our method captures rich and smooth priors from encoding images to latents, and given the latent of an initially generated frame as guidance, our method can generate smooth future latent by modulating the inversion encoder temporally. Our method enjoys the advantage of sparse training and naturally constrains the generation space of our motion generator with the inversion network guided by the initial frame, eliminating the need for heavy discriminators. Moreover, our method supports style transfer with simple fine-tuning when the encoder is paired with a pretrained StyleGAN generator. Extensive experiments conducted on various benchmarks demonstrate the superiority of our method in generating long and high-resolution videos with decent single-frame quality and temporal consistency.","sentences":["Unconditional video generation is a challenging task that involves synthesizing high-quality videos that are both coherent and of extended duration.","To address this challenge, researchers have used pretrained StyleGAN image generators for high-quality frame synthesis and focused on motion generator design.","The motion generator is trained in an autoregressive manner using heavy 3D convolutional discriminators to ensure motion coherence during video generation.","In this paper, we introduce a novel motion generator design that uses a learning-based inversion network for GAN.","The encoder in our method captures rich and smooth priors from encoding images to latents, and given the latent of an initially generated frame as guidance, our method can generate smooth future latent by modulating the inversion encoder temporally.","Our method enjoys the advantage of sparse training and naturally constrains the generation space of our motion generator with the inversion network guided by the initial frame, eliminating the need for heavy discriminators.","Moreover, our method supports style transfer with simple fine-tuning when the encoder is paired with a pretrained StyleGAN generator.","Extensive experiments conducted on various benchmarks demonstrate the superiority of our method in generating long and high-resolution videos with decent single-frame quality and temporal consistency."],"url":"http://arxiv.org/abs/2308.16909v1"}
{"created":"2023-08-31 17:59:24","title":"Fine-Grained Cross-View Geo-Localization Using a Correlation-Aware Homography Estimator","abstract":"In this paper, we introduce a novel approach to fine-grained cross-view geo-localization. Our method aligns a warped ground image with a corresponding GPS-tagged satellite image covering the same area using homography estimation. We first employ a differentiable spherical transform, adhering to geometric principles, to accurately align the perspective of the ground image with the satellite map. This transformation effectively places ground and aerial images in the same view and on the same plane, reducing the task to an image alignment problem. To address challenges such as occlusion, small overlapping range, and seasonal variations, we propose a robust correlation-aware homography estimator to align similar parts of the transformed ground image with the satellite image. Our method achieves sub-pixel resolution and meter-level GPS accuracy by mapping the center point of the transformed ground image to the satellite image using a homography matrix and determining the orientation of the ground camera using a point above the central axis. Operating at a speed of 30 FPS, our method outperforms state-of-the-art techniques, reducing the mean metric localization error by 21.3% and 32.4% in same-area and cross-area generalization tasks on the VIGOR benchmark, respectively, and by 34.4% on the KITTI benchmark in same-area evaluation.","sentences":["In this paper, we introduce a novel approach to fine-grained cross-view geo-localization.","Our method aligns a warped ground image with a corresponding GPS-tagged satellite image covering the same area using homography estimation.","We first employ a differentiable spherical transform, adhering to geometric principles, to accurately align the perspective of the ground image with the satellite map.","This transformation effectively places ground and aerial images in the same view and on the same plane, reducing the task to an image alignment problem.","To address challenges such as occlusion, small overlapping range, and seasonal variations, we propose a robust correlation-aware homography estimator to align similar parts of the transformed ground image with the satellite image.","Our method achieves sub-pixel resolution and meter-level GPS accuracy by mapping the center point of the transformed ground image to the satellite image using a homography matrix and determining the orientation of the ground camera using a point above the central axis.","Operating at a speed of 30 FPS, our method outperforms state-of-the-art techniques, reducing the mean metric localization error by 21.3% and 32.4% in same-area and cross-area generalization tasks on the VIGOR benchmark, respectively, and by 34.4% on the KITTI benchmark in same-area evaluation."],"url":"http://arxiv.org/abs/2308.16906v1"}
{"created":"2023-08-31 17:59:08","title":"InterDiff: Generating 3D Human-Object Interactions with Physics-Informed Diffusion","abstract":"This paper addresses a novel task of anticipating 3D human-object interactions (HOIs). Most existing research on HOI synthesis lacks comprehensive whole-body interactions with dynamic objects, e.g., often limited to manipulating small or static objects. Our task is significantly more challenging, as it requires modeling dynamic objects with various shapes, capturing whole-body motion, and ensuring physically valid interactions. To this end, we propose InterDiff, a framework comprising two key steps: (i) interaction diffusion, where we leverage a diffusion model to encode the distribution of future human-object interactions; (ii) interaction correction, where we introduce a physics-informed predictor to correct denoised HOIs in a diffusion step. Our key insight is to inject prior knowledge that the interactions under reference with respect to contact points follow a simple pattern and are easily predictable. Experiments on multiple human-object interaction datasets demonstrate the effectiveness of our method for this task, capable of producing realistic, vivid, and remarkably long-term 3D HOI predictions.","sentences":["This paper addresses a novel task of anticipating 3D human-object interactions (HOIs).","Most existing research on HOI synthesis lacks comprehensive whole-body interactions with dynamic objects, e.g., often limited to manipulating small or static objects.","Our task is significantly more challenging, as it requires modeling dynamic objects with various shapes, capturing whole-body motion, and ensuring physically valid interactions.","To this end, we propose InterDiff, a framework comprising two key steps: (i) interaction diffusion, where we leverage a diffusion model to encode the distribution of future human-object interactions; (ii) interaction correction, where we introduce a physics-informed predictor to correct denoised HOIs in a diffusion step.","Our key insight is to inject prior knowledge that the interactions under reference with respect to contact points follow a simple pattern and are easily predictable.","Experiments on multiple human-object interaction datasets demonstrate the effectiveness of our method for this task, capable of producing realistic, vivid, and remarkably long-term 3D HOI predictions."],"url":"http://arxiv.org/abs/2308.16905v1"}
{"created":"2023-08-31 17:58:38","title":"Accountable Safety Implies Finality","abstract":"Motivated by proof-of-stake (PoS) blockchains such as Ethereum, two key desiderata have recently been studied for Byzantine-fault tolerant (BFT) state-machine replication (SMR) consensus protocols: Finality means that the protocol retains consistency, as long as less than a certain fraction of validators are malicious, even in partially-synchronous environments that allow for temporary violations of assumed network delay bounds. Accountable safety means that in any case of inconsistency, a certain fraction of validators can be identified to have provably violated the protocol. Earlier works have developed impossibility results and protocol constructions for these properties separately. We show that accountable safety implies finality, thereby unifying earlier results.","sentences":["Motivated by proof-of-stake (PoS) blockchains such as Ethereum, two key desiderata have recently been studied for Byzantine-fault tolerant (BFT) state-machine replication (SMR) consensus protocols: Finality means that the protocol retains consistency, as long as less than a certain fraction of validators are malicious, even in partially-synchronous environments that allow for temporary violations of assumed network delay bounds.","Accountable safety means that in any case of inconsistency, a certain fraction of validators can be identified to have provably violated the protocol.","Earlier works have developed impossibility results and protocol constructions for these properties separately.","We show that accountable safety implies finality, thereby unifying earlier results."],"url":"http://arxiv.org/abs/2308.16902v1"}
{"created":"2023-08-31 17:58:28","title":"Learning to Taste: A Multimodal Wine Dataset","abstract":"We present WineSensed, a large multimodal wine dataset for studying the relations between visual perception, language, and flavor. The dataset encompasses 897k images of wine labels and 824k reviews of wines curated from the Vivino platform. It has over 350k unique vintages, annotated with year, region, rating, alcohol percentage, price, and grape composition. We obtained fine-grained flavor annotations on a subset by conducting a wine-tasting experiment with 256 participants who were asked to rank wines based on their similarity in flavor, resulting in more than 5k pairwise flavor distances. We propose a low-dimensional concept embedding algorithm that combines human experience with automatic machine similarity kernels. We demonstrate that this shared concept embedding space improves upon separate embedding spaces for coarse flavor classification (alcohol percentage, country, grape, price, rating) and aligns with the intricate human perception of flavor.","sentences":["We present WineSensed, a large multimodal wine dataset for studying the relations between visual perception, language, and flavor.","The dataset encompasses 897k images of wine labels and 824k reviews of wines curated from the Vivino platform.","It has over 350k unique vintages, annotated with year, region, rating, alcohol percentage, price, and grape composition.","We obtained fine-grained flavor annotations on a subset by conducting a wine-tasting experiment with 256 participants who were asked to rank wines based on their similarity in flavor, resulting in more than 5k pairwise flavor distances.","We propose a low-dimensional concept embedding algorithm that combines human experience with automatic machine similarity kernels.","We demonstrate that this shared concept embedding space improves upon separate embedding spaces for coarse flavor classification (alcohol percentage, country, grape, price, rating) and aligns with the intricate human perception of flavor."],"url":"http://arxiv.org/abs/2308.16900v1"}
{"created":"2023-08-31 17:57:50","title":"Transformers as Support Vector Machines","abstract":"Since its inception in \"Attention Is All You Need\", transformer architecture has led to revolutionary advancements in NLP. The attention layer within the transformer admits a sequence of input tokens $X$ and makes them interact through pairwise similarities computed as softmax$(XQK^\\top X^\\top)$, where $(K,Q)$ are the trainable key-query parameters. In this work, we establish a formal equivalence between the optimization geometry of self-attention and a hard-margin SVM problem that separates optimal input tokens from non-optimal tokens using linear constraints on the outer-products of token pairs. This formalism allows us to characterize the implicit bias of 1-layer transformers optimized with gradient descent: (1) Optimizing the attention layer with vanishing regularization, parameterized by $(K,Q)$, converges in direction to an SVM solution minimizing the nuclear norm of the combined parameter $W=KQ^\\top$. Instead, directly parameterizing by $W$ minimizes a Frobenius norm objective. We characterize this convergence, highlighting that it can occur toward locally-optimal directions rather than global ones. (2) Complementing this, we prove the local/global directional convergence of gradient descent under suitable geometric conditions. Importantly, we show that over-parameterization catalyzes global convergence by ensuring the feasibility of the SVM problem and by guaranteeing a benign optimization landscape devoid of stationary points. (3) While our theory applies primarily to linear prediction heads, we propose a more general SVM equivalence that predicts the implicit bias with nonlinear heads. Our findings are applicable to arbitrary datasets and their validity is verified via experiments. We also introduce several open problems and research directions. We believe these findings inspire the interpretation of transformers as a hierarchy of SVMs that separates and selects optimal tokens.","sentences":["Since its inception in \"Attention Is All You Need\", transformer architecture has led to revolutionary advancements in NLP.","The attention layer within the transformer admits a sequence of input tokens $X$ and makes them interact through pairwise similarities computed as softmax$(XQK^\\top X^\\top)$, where $(K,Q)$ are the trainable key-query parameters.","In this work, we establish a formal equivalence between the optimization geometry of self-attention and a hard-margin SVM problem that separates optimal input tokens from non-optimal tokens using linear constraints on the outer-products of token pairs.","This formalism allows us to characterize the implicit bias of 1-layer transformers optimized with gradient descent: (1) Optimizing the attention layer with vanishing regularization, parameterized by $(K,Q)$, converges in direction to an SVM solution minimizing the nuclear norm of the combined parameter $W=KQ^\\top$. Instead, directly parameterizing by $W$ minimizes a Frobenius norm objective.","We characterize this convergence, highlighting that it can occur toward locally-optimal directions rather than global ones.","(2) Complementing this, we prove the local/global directional convergence of gradient descent under suitable geometric conditions.","Importantly, we show that over-parameterization catalyzes global convergence by ensuring the feasibility of the SVM problem and by guaranteeing a benign optimization landscape devoid of stationary points.","(3) While our theory applies primarily to linear prediction heads, we propose a more general SVM equivalence that predicts the implicit bias with nonlinear heads.","Our findings are applicable to arbitrary datasets and their validity is verified via experiments.","We also introduce several open problems and research directions.","We believe these findings inspire the interpretation of transformers as a hierarchy of SVMs that separates and selects optimal tokens."],"url":"http://arxiv.org/abs/2308.16898v1"}
{"created":"2023-08-31 17:57:17","title":"PointOcc: Cylindrical Tri-Perspective View for Point-based 3D Semantic Occupancy Prediction","abstract":"Semantic segmentation in autonomous driving has been undergoing an evolution from sparse point segmentation to dense voxel segmentation, where the objective is to predict the semantic occupancy of each voxel in the concerned 3D space. The dense nature of the prediction space has rendered existing efficient 2D-projection-based methods (e.g., bird's eye view, range view, etc.) ineffective, as they can only describe a subspace of the 3D scene. To address this, we propose a cylindrical tri-perspective view to represent point clouds effectively and comprehensively and a PointOcc model to process them efficiently. Considering the distance distribution of LiDAR point clouds, we construct the tri-perspective view in the cylindrical coordinate system for more fine-grained modeling of nearer areas. We employ spatial group pooling to maintain structural details during projection and adopt 2D backbones to efficiently process each TPV plane. Finally, we obtain the features of each point by aggregating its projected features on each of the processed TPV planes without the need for any post-processing. Extensive experiments on both 3D occupancy prediction and LiDAR segmentation benchmarks demonstrate that the proposed PointOcc achieves state-of-the-art performance with much faster speed. Specifically, despite only using LiDAR, PointOcc significantly outperforms all other methods, including multi-modal methods, with a large margin on the OpenOccupancy benchmark. Code: https://github.com/wzzheng/PointOcc.","sentences":["Semantic segmentation in autonomous driving has been undergoing an evolution from sparse point segmentation to dense voxel segmentation, where the objective is to predict the semantic occupancy of each voxel in the concerned 3D space.","The dense nature of the prediction space has rendered existing efficient 2D-projection-based methods (e.g., bird's eye view, range view, etc.)","ineffective, as they can only describe a subspace of the 3D scene.","To address this, we propose a cylindrical tri-perspective view to represent point clouds effectively and comprehensively and a PointOcc model to process them efficiently.","Considering the distance distribution of LiDAR point clouds, we construct the tri-perspective view in the cylindrical coordinate system for more fine-grained modeling of nearer areas.","We employ spatial group pooling to maintain structural details during projection and adopt 2D backbones to efficiently process each TPV plane.","Finally, we obtain the features of each point by aggregating its projected features on each of the processed TPV planes without the need for any post-processing.","Extensive experiments on both 3D occupancy prediction and LiDAR segmentation benchmarks demonstrate that the proposed PointOcc achieves state-of-the-art performance with much faster speed.","Specifically, despite only using LiDAR, PointOcc significantly outperforms all other methods, including multi-modal methods, with a large margin on the OpenOccupancy benchmark.","Code: https://github.com/wzzheng/PointOcc."],"url":"http://arxiv.org/abs/2308.16896v1"}
{"created":"2023-08-31 17:56:19","title":"EMDB: The Electromagnetic Database of Global 3D Human Pose and Shape in the Wild","abstract":"We present EMDB, the Electromagnetic Database of Global 3D Human Pose and Shape in the Wild. EMDB is a novel dataset that contains high-quality 3D SMPL pose and shape parameters with global body and camera trajectories for in-the-wild videos. We use body-worn, wireless electromagnetic (EM) sensors and a hand-held iPhone to record a total of 58 minutes of motion data, distributed over 81 indoor and outdoor sequences and 10 participants. Together with accurate body poses and shapes, we also provide global camera poses and body root trajectories. To construct EMDB, we propose a multi-stage optimization procedure, which first fits SMPL to the 6-DoF EM measurements and then refines the poses via image observations. To achieve high-quality results, we leverage a neural implicit avatar model to reconstruct detailed human surface geometry and appearance, which allows for improved alignment and smoothness via a dense pixel-level objective. Our evaluations, conducted with a multi-view volumetric capture system, indicate that EMDB has an expected accuracy of 2.3 cm positional and 10.6 degrees angular error, surpassing the accuracy of previous in-the-wild datasets. We evaluate existing state-of-the-art monocular RGB methods for camera-relative and global pose estimation on EMDB. EMDB is publicly available under https://ait.ethz.ch/emdb","sentences":["We present EMDB, the Electromagnetic Database of Global 3D Human Pose and Shape in the Wild.","EMDB is a novel dataset that contains high-quality 3D SMPL pose and shape parameters with global body and camera trajectories for in-the-wild videos.","We use body-worn, wireless electromagnetic (EM) sensors and a hand-held iPhone to record a total of 58 minutes of motion data, distributed over 81 indoor and outdoor sequences and 10 participants.","Together with accurate body poses and shapes, we also provide global camera poses and body root trajectories.","To construct EMDB, we propose a multi-stage optimization procedure, which first fits SMPL to the 6-DoF EM measurements and then refines the poses via image observations.","To achieve high-quality results, we leverage a neural implicit avatar model to reconstruct detailed human surface geometry and appearance, which allows for improved alignment and smoothness via a dense pixel-level objective.","Our evaluations, conducted with a multi-view volumetric capture system, indicate that EMDB has an expected accuracy of 2.3 cm positional and 10.6 degrees angular error, surpassing the accuracy of previous in-the-wild datasets.","We evaluate existing state-of-the-art monocular RGB methods for camera-relative and global pose estimation on EMDB.","EMDB is publicly available under https://ait.ethz.ch/emdb"],"url":"http://arxiv.org/abs/2308.16894v1"}
{"created":"2023-08-31 17:56:13","title":"Language-Conditioned Path Planning","abstract":"Contact is at the core of robotic manipulation. At times, it is desired (e.g. manipulation and grasping), and at times, it is harmful (e.g. when avoiding obstacles). However, traditional path planning algorithms focus solely on collision-free paths, limiting their applicability in contact-rich tasks. To address this limitation, we propose the domain of Language-Conditioned Path Planning, where contact-awareness is incorporated into the path planning problem. As a first step in this domain, we propose Language-Conditioned Collision Functions (LACO) a novel approach that learns a collision function using only a single-view image, language prompt, and robot configuration. LACO predicts collisions between the robot and the environment, enabling flexible, conditional path planning without the need for manual object annotations, point cloud data, or ground-truth object meshes. In both simulation and the real world, we demonstrate that LACO can facilitate complex, nuanced path plans that allow for interaction with objects that are safe to collide, rather than prohibiting any collision.","sentences":["Contact is at the core of robotic manipulation.","At times, it is desired (e.g. manipulation and grasping), and at times, it is harmful (e.g. when avoiding obstacles).","However, traditional path planning algorithms focus solely on collision-free paths, limiting their applicability in contact-rich tasks.","To address this limitation, we propose the domain of Language-Conditioned Path Planning, where contact-awareness is incorporated into the path planning problem.","As a first step in this domain, we propose Language-Conditioned Collision Functions (LACO) a novel approach that learns a collision function using only a single-view image, language prompt, and robot configuration.","LACO predicts collisions between the robot and the environment, enabling flexible, conditional path planning without the need for manual object annotations, point cloud data, or ground-truth object meshes.","In both simulation and the real world, we demonstrate that LACO can facilitate complex, nuanced path plans that allow for interaction with objects that are safe to collide, rather than prohibiting any collision."],"url":"http://arxiv.org/abs/2308.16893v1"}
{"created":"2023-08-31 17:52:10","title":"GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields","abstract":"It is a long-standing problem in robotics to develop agents capable of executing diverse manipulation tasks from visual observations in unstructured real-world environments. To achieve this goal, the robot needs to have a comprehensive understanding of the 3D structure and semantics of the scene. In this work, we present $\\textbf{GNFactor}$, a visual behavior cloning agent for multi-task robotic manipulation with $\\textbf{G}$eneralizable $\\textbf{N}$eural feature $\\textbf{F}$ields. GNFactor jointly optimizes a generalizable neural field (GNF) as a reconstruction module and a Perceiver Transformer as a decision-making module, leveraging a shared deep 3D voxel representation. To incorporate semantics in 3D, the reconstruction module utilizes a vision-language foundation model ($\\textit{e.g.}$, Stable Diffusion) to distill rich semantic information into the deep 3D voxel. We evaluate GNFactor on 3 real robot tasks and perform detailed ablations on 10 RLBench tasks with a limited number of demonstrations. We observe a substantial improvement of GNFactor over current state-of-the-art methods in seen and unseen tasks, demonstrating the strong generalization ability of GNFactor. Our project website is https://yanjieze.com/GNFactor/ .","sentences":["It is a long-standing problem in robotics to develop agents capable of executing diverse manipulation tasks from visual observations in unstructured real-world environments.","To achieve this goal, the robot needs to have a comprehensive understanding of the 3D structure and semantics of the scene.","In this work, we present $\\textbf{GNFactor}$, a visual behavior cloning agent for multi-task robotic manipulation with $\\textbf{G}$eneralizable $\\textbf{N}$eural feature $\\textbf{F}$ields.","GNFactor jointly optimizes a generalizable neural field (GNF) as a reconstruction module and a Perceiver Transformer as a decision-making module, leveraging a shared deep 3D voxel representation.","To incorporate semantics in 3D, the reconstruction module utilizes a vision-language foundation model ($\\textit{e.g.}$, Stable Diffusion) to distill rich semantic information into the deep 3D voxel.","We evaluate GNFactor on 3 real robot tasks and perform detailed ablations on 10 RLBench tasks with a limited number of demonstrations.","We observe a substantial improvement of GNFactor over current state-of-the-art methods in seen and unseen tasks, demonstrating the strong generalization ability of GNFactor.","Our project website is https://yanjieze.com/GNFactor/ ."],"url":"http://arxiv.org/abs/2308.16891v1"}
{"created":"2023-08-31 17:52:04","title":"TouchStone: Evaluating Vision-Language Models by Language Models","abstract":"Large vision-language models (LVLMs) have recently witnessed rapid advancements, exhibiting a remarkable capacity for perceiving, understanding, and processing visual information by connecting visual receptor with large language models (LLMs). However, current assessments mainly focus on recognizing and reasoning abilities, lacking direct evaluation of conversational skills and neglecting visual storytelling abilities. In this paper, we propose an evaluation method that uses strong LLMs as judges to comprehensively evaluate the various abilities of LVLMs. Firstly, we construct a comprehensive visual dialogue dataset TouchStone, consisting of open-world images and questions, covering five major categories of abilities and 27 subtasks. This dataset not only covers fundamental recognition and comprehension but also extends to literary creation. Secondly, by integrating detailed image annotations we effectively transform the multimodal input content into a form understandable by LLMs. This enables us to employ advanced LLMs for directly evaluating the quality of the multimodal dialogue without requiring human intervention. Through validation, we demonstrate that powerful LVLMs, such as GPT-4, can effectively score dialogue quality by leveraging their textual capabilities alone, aligning with human preferences. We hope our work can serve as a touchstone for LVLMs' evaluation and pave the way for building stronger LVLMs. The evaluation code is available at https://github.com/OFA-Sys/TouchStone.","sentences":["Large vision-language models (LVLMs) have recently witnessed rapid advancements, exhibiting a remarkable capacity for perceiving, understanding, and processing visual information by connecting visual receptor with large language models (LLMs).","However, current assessments mainly focus on recognizing and reasoning abilities, lacking direct evaluation of conversational skills and neglecting visual storytelling abilities.","In this paper, we propose an evaluation method that uses strong LLMs as judges to comprehensively evaluate the various abilities of LVLMs.","Firstly, we construct a comprehensive visual dialogue dataset TouchStone, consisting of open-world images and questions, covering five major categories of abilities and 27 subtasks.","This dataset not only covers fundamental recognition and comprehension but also extends to literary creation.","Secondly, by integrating detailed image annotations we effectively transform the multimodal input content into a form understandable by LLMs.","This enables us to employ advanced LLMs for directly evaluating the quality of the multimodal dialogue without requiring human intervention.","Through validation, we demonstrate that powerful LVLMs, such as GPT-4, can effectively score dialogue quality by leveraging their textual capabilities alone, aligning with human preferences.","We hope our work can serve as a touchstone for LVLMs' evaluation and pave the way for building stronger LVLMs.","The evaluation code is available at https://github.com/OFA-Sys/TouchStone."],"url":"http://arxiv.org/abs/2308.16890v1"}
{"created":"2023-08-31 17:50:54","title":"Federated Learning in UAV-Enhanced Networks: Joint Coverage and Convergence Time Optimization","abstract":"Federated learning (FL) involves several devices that collaboratively train a shared model without transferring their local data. FL reduces the communication overhead, making it a promising learning method in UAV-enhanced wireless networks with scarce energy resources. Despite the potential, implementing FL in UAV-enhanced networks is challenging, as conventional UAV placement methods that maximize coverage increase the FL delay significantly. Moreover, the uncertainty and lack of a priori information about crucial variables, such as channel quality, exacerbate the problem. In this paper, we first analyze the statistical characteristics of a UAV-enhanced wireless sensor network (WSN) with energy harvesting. We then develop a model and solution based on the multi-objective multi-armed bandit theory to maximize the network coverage while minimizing the FL delay. Besides, we propose another solution that is particularly useful with large action sets and strict energy constraints at the UAVs. Our proposal uses a scalarized best-arm identification algorithm to find the optimal arms that maximize the ratio of the expected reward to the expected energy cost by sequentially eliminating one or more arms in each round. Then, we derive the upper bound on the error probability of our multi-objective and cost-aware algorithm. Numerical results show the effectiveness of our approach.","sentences":["Federated learning (FL) involves several devices that collaboratively train a shared model without transferring their local data.","FL reduces the communication overhead, making it a promising learning method in UAV-enhanced wireless networks with scarce energy resources.","Despite the potential, implementing FL in UAV-enhanced networks is challenging, as conventional UAV placement methods that maximize coverage increase the FL delay significantly.","Moreover, the uncertainty and lack of a priori information about crucial variables, such as channel quality, exacerbate the problem.","In this paper, we first analyze the statistical characteristics of a UAV-enhanced wireless sensor network (WSN) with energy harvesting.","We then develop a model and solution based on the multi-objective multi-armed bandit theory to maximize the network coverage while minimizing the FL delay.","Besides, we propose another solution that is particularly useful with large action sets and strict energy constraints at the UAVs.","Our proposal uses a scalarized best-arm identification algorithm to find the optimal arms that maximize the ratio of the expected reward to the expected energy cost by sequentially eliminating one or more arms in each round.","Then, we derive the upper bound on the error probability of our multi-objective and cost-aware algorithm.","Numerical results show the effectiveness of our approach."],"url":"http://arxiv.org/abs/2308.16889v1"}
{"created":"2023-08-31 17:43:08","title":"The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants","abstract":"We present Belebele, a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants. Significantly expanding the language coverage of natural language understanding (NLU) benchmarks, this dataset enables the evaluation of text models in high-, medium-, and low-resource languages. Each question is based on a short passage from the Flores-200 dataset and has four multiple-choice answers. The questions were carefully curated to discriminate between models with different levels of general language comprehension. The English dataset on its own proves difficult enough to challenge state-of-the-art language models. Being fully parallel, this dataset enables direct comparison of model performance across all languages. We use this dataset to evaluate the capabilities of multilingual masked language models (MLMs) and large language models (LLMs). We present extensive results and find that despite significant cross-lingual transfer in English-centric LLMs, much smaller MLMs pretrained on balanced multilingual data still understand far more languages. We also observe that larger vocabulary size and conscious vocabulary construction correlate with better performance on low-resource languages. Overall, Belebele opens up new avenues for evaluating and analyzing the multilingual capabilities of NLP systems.","sentences":["We present Belebele, a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants.","Significantly expanding the language coverage of natural language understanding (NLU) benchmarks, this dataset enables the evaluation of text models in high-, medium-, and low-resource languages.","Each question is based on a short passage from the Flores-200 dataset and has four multiple-choice answers.","The questions were carefully curated to discriminate between models with different levels of general language comprehension.","The English dataset on its own proves difficult enough to challenge state-of-the-art language models.","Being fully parallel, this dataset enables direct comparison of model performance across all languages.","We use this dataset to evaluate the capabilities of multilingual masked language models (MLMs) and large language models (LLMs).","We present extensive results and find that despite significant cross-lingual transfer in English-centric LLMs, much smaller MLMs pretrained on balanced multilingual data still understand far more languages.","We also observe that larger vocabulary size and conscious vocabulary construction correlate with better performance on low-resource languages.","Overall, Belebele opens up new avenues for evaluating and analyzing the multilingual capabilities of NLP systems."],"url":"http://arxiv.org/abs/2308.16884v1"}
{"created":"2023-08-31 17:39:18","title":"Amplitude Prediction from Uplink to Downlink CSI against Receiver Distortion in FDD Systems","abstract":"In frequency division duplex (FDD) massive multiple-input multiple-output (mMIMO) systems, the reciprocity mismatch caused by receiver distortion seriously degrades the amplitude prediction performance of channel state information (CSI). To tackle this issue, from the perspective of distortion suppression and reciprocity calibration, a lightweight neural network-based amplitude prediction method is proposed in this paper. Specifically, with the receiver distortion at the base station (BS), conventional methods are employed to extract the amplitude feature of uplink CSI. Then, learning along the direction of the uplink wireless propagation channel, a dedicated and lightweight distortion-learning network (Dist-LeaNet) is designed to restrain the receiver distortion and calibrate the amplitude reciprocity between the uplink and downlink CSI. Subsequently, by cascading, a single hidden layer-based amplitude-prediction network (Amp-PreNet) is developed to accomplish amplitude prediction of downlink CSI based on the strong amplitude reciprocity. Simulation results show that, considering the receiver distortion in FDD systems, the proposed scheme effectively improves the amplitude prediction accuracy of downlink CSI while reducing the transmission and processing delay.","sentences":["In frequency division duplex (FDD) massive multiple-input multiple-output (mMIMO) systems, the reciprocity mismatch caused by receiver distortion seriously degrades the amplitude prediction performance of channel state information (CSI).","To tackle this issue, from the perspective of distortion suppression and reciprocity calibration, a lightweight neural network-based amplitude prediction method is proposed in this paper.","Specifically, with the receiver distortion at the base station (BS), conventional methods are employed to extract the amplitude feature of uplink CSI.","Then, learning along the direction of the uplink wireless propagation channel, a dedicated and lightweight distortion-learning network (Dist-LeaNet) is designed to restrain the receiver distortion and calibrate the amplitude reciprocity between the uplink and downlink CSI.","Subsequently, by cascading, a single hidden layer-based amplitude-prediction network (Amp-PreNet) is developed to accomplish amplitude prediction of downlink CSI based on the strong amplitude reciprocity.","Simulation results show that, considering the receiver distortion in FDD systems, the proposed scheme effectively improves the amplitude prediction accuracy of downlink CSI while reducing the transmission and processing delay."],"url":"http://arxiv.org/abs/2308.16882v1"}
{"created":"2023-08-31 17:37:23","title":"Text2Scene: Text-driven Indoor Scene Stylization with Part-aware Details","abstract":"We propose Text2Scene, a method to automatically create realistic textures for virtual scenes composed of multiple objects. Guided by a reference image and text descriptions, our pipeline adds detailed texture on labeled 3D geometries in the room such that the generated colors respect the hierarchical structure or semantic parts that are often composed of similar materials. Instead of applying flat stylization on the entire scene at a single step, we obtain weak semantic cues from geometric segmentation, which are further clarified by assigning initial colors to segmented parts. Then we add texture details for individual objects such that their projections on image space exhibit feature embedding aligned with the embedding of the input. The decomposition makes the entire pipeline tractable to a moderate amount of computation resources and memory. As our framework utilizes the existing resources of image and text embedding, it does not require dedicated datasets with high-quality textures designed by skillful artists. To the best of our knowledge, it is the first practical and scalable approach that can create detailed and realistic textures of the desired style that maintain structural context for scenes with multiple objects.","sentences":["We propose Text2Scene, a method to automatically create realistic textures for virtual scenes composed of multiple objects.","Guided by a reference image and text descriptions, our pipeline adds detailed texture on labeled 3D geometries in the room such that the generated colors respect the hierarchical structure or semantic parts that are often composed of similar materials.","Instead of applying flat stylization on the entire scene at a single step, we obtain weak semantic cues from geometric segmentation, which are further clarified by assigning initial colors to segmented parts.","Then we add texture details for individual objects such that their projections on image space exhibit feature embedding aligned with the embedding of the input.","The decomposition makes the entire pipeline tractable to a moderate amount of computation resources and memory.","As our framework utilizes the existing resources of image and text embedding, it does not require dedicated datasets with high-quality textures designed by skillful artists.","To the best of our knowledge, it is the first practical and scalable approach that can create detailed and realistic textures of the desired style that maintain structural context for scenes with multiple objects."],"url":"http://arxiv.org/abs/2308.16880v1"}
{"created":"2023-08-31 17:36:57","title":"Adaptation Speed Analysis for Fairness-aware Causal Models","abstract":"For example, in machine translation tasks, to achieve bidirectional translation between two languages, the source corpus is often used as the target corpus, which involves the training of two models with opposite directions. The question of which one can adapt most quickly to a domain shift is of significant importance in many fields. Specifically, consider an original distribution p that changes due to an unknown intervention, resulting in a modified distribution p*. In aligning p with p*, several factors can affect the adaptation rate, including the causal dependencies between variables in p. In real-life scenarios, however, we have to consider the fairness of the training process, and it is particularly crucial to involve a sensitive variable (bias) present between a cause and an effect variable. To explore this scenario, we examine a simple structural causal model (SCM) with a cause-bias-effect structure, where variable A acts as a sensitive variable between cause (X) and effect (Y). The two models, respectively, exhibit consistent and contrary cause-effect directions in the cause-bias-effect SCM. After conducting unknown interventions on variables within the SCM, we can simulate some kinds of domain shifts for analysis. We then compare the adaptation speeds of two models across four shift scenarios. Additionally, we prove the connection between the adaptation speeds of the two models across all interventions.","sentences":["For example, in machine translation tasks, to achieve bidirectional translation between two languages, the source corpus is often used as the target corpus, which involves the training of two models with opposite directions.","The question of which one can adapt most quickly to a domain shift is of significant importance in many fields.","Specifically, consider an original distribution p that changes due to an unknown intervention, resulting in a modified distribution p*.","In aligning p with p*, several factors can affect the adaptation rate, including the causal dependencies between variables in p. In real-life scenarios, however, we have to consider the fairness of the training process, and it is particularly crucial to involve a sensitive variable (bias) present between a cause and an effect variable.","To explore this scenario, we examine a simple structural causal model (SCM) with a cause-bias-effect structure, where variable A acts as a sensitive variable between cause (X) and effect (Y).","The two models, respectively, exhibit consistent and contrary cause-effect directions in the cause-bias-effect SCM.","After conducting unknown interventions on variables within the SCM, we can simulate some kinds of domain shifts for analysis.","We then compare the adaptation speeds of two models across four shift scenarios.","Additionally, we prove the connection between the adaptation speeds of the two models across all interventions."],"url":"http://arxiv.org/abs/2308.16879v1"}
{"created":"2023-08-31 17:32:44","title":"HPAC-Offload: Accelerating HPC Applications with Portable Approximate Computing on the GPU","abstract":"The end of Dennard scaling and the slowdown of Moore's law led to a shift in technology trends toward parallel architectures, particularly in HPC systems. To continue providing performance benefits, HPC should embrace Approximate Computing (AC), which trades application quality loss for improved performance. However, existing AC techniques have not been extensively applied and evaluated in state-of-the-art hardware architectures such as GPUs, the primary execution vehicle for HPC applications today.   This paper presents HPAC-Offload, a pragma-based programming model that extends OpenMP offload applications to support AC techniques, allowing portable approximations across different GPU architectures. We conduct a comprehensive performance analysis of HPAC-Offload across GPU-accelerated HPC applications, revealing that AC techniques can significantly accelerate HPC applications (1.64x LULESH on AMD, 1.57x NVIDIA) with minimal quality loss (0.1%). Our analysis offers deep insights into the performance of GPU-based AC that guide the future development of AC algorithms and systems for these architectures.","sentences":["The end of Dennard scaling and the slowdown of Moore's law led to a shift in technology trends toward parallel architectures, particularly in HPC systems.","To continue providing performance benefits, HPC should embrace Approximate Computing (AC), which trades application quality loss for improved performance.","However, existing AC techniques have not been extensively applied and evaluated in state-of-the-art hardware architectures such as GPUs, the primary execution vehicle for HPC applications today.   ","This paper presents HPAC-Offload, a pragma-based programming model that extends OpenMP offload applications to support AC techniques, allowing portable approximations across different GPU architectures.","We conduct a comprehensive performance analysis of HPAC-Offload across GPU-accelerated HPC applications, revealing that AC techniques can significantly accelerate HPC applications (1.64x LULESH on AMD, 1.57x NVIDIA) with minimal quality loss (0.1%).","Our analysis offers deep insights into the performance of GPU-based AC that guide the future development of AC algorithms and systems for these architectures."],"url":"http://arxiv.org/abs/2308.16877v1"}
{"created":"2023-08-31 17:23:50","title":"SportsSloMo: A New Benchmark and Baselines for Human-centric Video Frame Interpolation","abstract":"Human-centric video frame interpolation has great potential for improving people's entertainment experiences and finding commercial applications in the sports analysis industry, e.g., synthesizing slow-motion videos. Although there are multiple benchmark datasets available in the community, none of them is dedicated for human-centric scenarios. To bridge this gap, we introduce SportsSloMo, a benchmark consisting of more than 130K video clips and 1M video frames of high-resolution ($\\geq$720p) slow-motion sports videos crawled from YouTube. We re-train several state-of-the-art methods on our benchmark, and the results show a decrease in their accuracy compared to other datasets. It highlights the difficulty of our benchmark and suggests that it poses significant challenges even for the best-performing methods, as human bodies are highly deformable and occlusions are frequent in sports videos. To improve the accuracy, we introduce two loss terms considering the human-aware priors, where we add auxiliary supervision to panoptic segmentation and human keypoints detection, respectively. The loss terms are model agnostic and can be easily plugged into any video frame interpolation approaches. Experimental results validate the effectiveness of our proposed loss terms, leading to consistent performance improvement over 5 existing models, which establish strong baseline models on our benchmark. The dataset and code can be found at: https://neu-vi.github.io/SportsSlomo/.","sentences":["Human-centric video frame interpolation has great potential for improving people's entertainment experiences and finding commercial applications in the sports analysis industry, e.g., synthesizing slow-motion videos.","Although there are multiple benchmark datasets available in the community, none of them is dedicated for human-centric scenarios.","To bridge this gap, we introduce SportsSloMo, a benchmark consisting of more than 130K video clips and 1M video frames of high-resolution ($\\geq$720p) slow-motion sports videos crawled from YouTube.","We re-train several state-of-the-art methods on our benchmark, and the results show a decrease in their accuracy compared to other datasets.","It highlights the difficulty of our benchmark and suggests that it poses significant challenges even for the best-performing methods, as human bodies are highly deformable and occlusions are frequent in sports videos.","To improve the accuracy, we introduce two loss terms considering the human-aware priors, where we add auxiliary supervision to panoptic segmentation and human keypoints detection, respectively.","The loss terms are model agnostic and can be easily plugged into any video frame interpolation approaches.","Experimental results validate the effectiveness of our proposed loss terms, leading to consistent performance improvement over 5 existing models, which establish strong baseline models on our benchmark.","The dataset and code can be found at: https://neu-vi.github.io/SportsSlomo/."],"url":"http://arxiv.org/abs/2308.16876v1"}
{"created":"2023-08-31 17:22:18","title":"Holistic Processing of Colour Images Using Novel Quaternion-Valued Wavelets on the Plane","abstract":"We investigate the applicability of quaternion-valued wavelets on the plane to holistic colour image processing. We present a methodology for decomposing and reconstructing colour images using quaternionic wavelet filters associated to recently developed quaternion-valued wavelets on the plane. We consider compression, enhancement, segmentation, and denoising techniques to demonstrate quaternion-valued wavelets as a promising tool for holistic colour image processing.","sentences":["We investigate the applicability of quaternion-valued wavelets on the plane to holistic colour image processing.","We present a methodology for decomposing and reconstructing colour images using quaternionic wavelet filters associated to recently developed quaternion-valued wavelets on the plane.","We consider compression, enhancement, segmentation, and denoising techniques to demonstrate quaternion-valued wavelets as a promising tool for holistic colour image processing."],"url":"http://arxiv.org/abs/2308.16875v1"}
{"created":"2023-08-31 17:21:18","title":"D-VAT: End-to-End Visual Active Tracking for Micro Aerial Vehicles","abstract":"Visual active tracking is a growing research topic in robotics due to its key role in applications such as human assistance, disaster recovery, and surveillance. In contrast to passive tracking, active tracking approaches combine vision and control capabilities to detect and actively track the target. Most of the work in this area focuses on ground robots, while the very few contributions on aerial platforms still pose important design constraints that limit their applicability. To overcome these limitations, in this paper we propose D-VAT, a novel end-to-end visual active tracking methodology based on deep reinforcement learning that is tailored to micro aerial vehicle platforms. The D-VAT agent computes the vehicle thrust and angular velocity commands needed to track the target by directly processing monocular camera measurements. We show that the proposed approach allows for precise and collision-free tracking operations, outperforming different state-of-the-art baselines on simulated environments which differ significantly from those encountered during training.","sentences":["Visual active tracking is a growing research topic in robotics due to its key role in applications such as human assistance, disaster recovery, and surveillance.","In contrast to passive tracking, active tracking approaches combine vision and control capabilities to detect and actively track the target.","Most of the work in this area focuses on ground robots, while the very few contributions on aerial platforms still pose important design constraints that limit their applicability.","To overcome these limitations, in this paper we propose D-VAT, a novel end-to-end visual active tracking methodology based on deep reinforcement learning that is tailored to micro aerial vehicle platforms.","The D-VAT agent computes the vehicle thrust and angular velocity commands needed to track the target by directly processing monocular camera measurements.","We show that the proposed approach allows for precise and collision-free tracking operations, outperforming different state-of-the-art baselines on simulated environments which differ significantly from those encountered during training."],"url":"http://arxiv.org/abs/2308.16874v1"}
{"created":"2023-08-31 17:20:50","title":"The Gender-GAP Pipeline: A Gender-Aware Polyglot Pipeline for Gender Characterisation in 55 Languages","abstract":"Gender biases in language generation systems are challenging to mitigate. One possible source for these biases is gender representation disparities in the training and evaluation data. Despite recent progress in documenting this problem and many attempts at mitigating it, we still lack shared methodology and tooling to report gender representation in large datasets. Such quantitative reporting will enable further mitigation, e.g., via data augmentation. This paper describes the Gender-GAP Pipeline (for Gender-Aware Polyglot Pipeline), an automatic pipeline to characterize gender representation in large-scale datasets for 55 languages. The pipeline uses a multilingual lexicon of gendered person-nouns to quantify the gender representation in text. We showcase it to report gender representation in WMT training data and development data for the News task, confirming that current data is skewed towards masculine representation. Having unbalanced datasets may indirectly optimize our systems towards outperforming one gender over the others. We suggest introducing our gender quantification pipeline in current datasets and, ideally, modifying them toward a balanced representation.","sentences":["Gender biases in language generation systems are challenging to mitigate.","One possible source for these biases is gender representation disparities in the training and evaluation data.","Despite recent progress in documenting this problem and many attempts at mitigating it, we still lack shared methodology and tooling to report gender representation in large datasets.","Such quantitative reporting will enable further mitigation, e.g., via data augmentation.","This paper describes the Gender-GAP Pipeline (for Gender-Aware Polyglot Pipeline), an automatic pipeline to characterize gender representation in large-scale datasets for 55 languages.","The pipeline uses a multilingual lexicon of gendered person-nouns to quantify the gender representation in text.","We showcase it to report gender representation in WMT training data and development data for the News task, confirming that current data is skewed towards masculine representation.","Having unbalanced datasets may indirectly optimize our systems towards outperforming one gender over the others.","We suggest introducing our gender quantification pipeline in current datasets and, ideally, modifying them toward a balanced representation."],"url":"http://arxiv.org/abs/2308.16871v1"}
{"created":"2023-08-31 17:18:15","title":"Learning Driver Models for Automated Vehicles via Knowledge Sharing and Personalization","abstract":"This paper describes a framework for learning Automated Vehicles (AVs) driver models via knowledge sharing between vehicles and personalization. The innate variability in the transportation system makes it exceptionally challenging to expose AVs to all possible driving scenarios during empirical experimentation or testing. Consequently, AVs could be blind to certain encounters that are deemed detrimental to their safe and efficient operation. It is then critical to share knowledge across AVs that increase exposure to driving scenarios occurring in the real world. This paper explores a method to collaboratively train a driver model by sharing knowledge and borrowing strength across vehicles while retaining a personalized model tailored to the vehicle's unique conditions and properties. Our model brings a federated learning approach to collaborate between multiple vehicles while circumventing the need to share raw data between them. We showcase our method's performance in experimental simulations. Such an approach to learning finds several applications across transportation engineering including intelligent transportation systems, traffic management, and vehicle-to-vehicle communication. Code and sample dataset are made available at the project page https://github.com/wissamkontar.","sentences":["This paper describes a framework for learning Automated Vehicles (AVs) driver models via knowledge sharing between vehicles and personalization.","The innate variability in the transportation system makes it exceptionally challenging to expose AVs to all possible driving scenarios during empirical experimentation or testing.","Consequently, AVs could be blind to certain encounters that are deemed detrimental to their safe and efficient operation.","It is then critical to share knowledge across AVs that increase exposure to driving scenarios occurring in the real world.","This paper explores a method to collaboratively train a driver model by sharing knowledge and borrowing strength across vehicles while retaining a personalized model tailored to the vehicle's unique conditions and properties.","Our model brings a federated learning approach to collaborate between multiple vehicles while circumventing the need to share raw data between them.","We showcase our method's performance in experimental simulations.","Such an approach to learning finds several applications across transportation engineering including intelligent transportation systems, traffic management, and vehicle-to-vehicle communication.","Code and sample dataset are made available at the project page https://github.com/wissamkontar."],"url":"http://arxiv.org/abs/2308.16870v1"}
{"created":"2023-08-31 17:04:34","title":"UltraLogLog: A Practical and More Space-Efficient Alternative to HyperLogLog for Approximate Distinct Counting","abstract":"Since its invention HyperLogLog has become the standard algorithm for approximate distinct counting. Due to its space efficiency and suitability for distributed systems, it is widely used and also implemented in numerous databases. This work presents UltraLogLog, which shares the same practical properties as HyperLogLog. It is commutative, idempotent, mergeable, and has a fast guaranteed constant-time insert operation. At the same time, it requires 28% less space to encode the same amount of distinct count information, which can be extracted using the maximum likelihood method. Alternatively, a simpler and faster estimator is proposed, which still achieves a space reduction of 24%, but at an estimation speed comparable to that of HyperLogLog. In a non-distributed setting where martingale estimation can be used, UltraLogLog is able to reduce space by 17%. Moreover, its smaller entropy and its 8-bit registers lead to better compaction when using standard compression algorithms. All this is verified by experimental results that are in perfect agreement with the theoretical analysis which also outlines potential for even more space-efficient data structures. A production-ready Java implementation of UltraLogLog has been released as part of the open-source Hash4j library.","sentences":["Since its invention HyperLogLog has become the standard algorithm for approximate distinct counting.","Due to its space efficiency and suitability for distributed systems, it is widely used and also implemented in numerous databases.","This work presents UltraLogLog, which shares the same practical properties as HyperLogLog.","It is commutative, idempotent, mergeable, and has a fast guaranteed constant-time insert operation.","At the same time, it requires 28% less space to encode the same amount of distinct count information, which can be extracted using the maximum likelihood method.","Alternatively, a simpler and faster estimator is proposed, which still achieves a space reduction of 24%, but at an estimation speed comparable to that of HyperLogLog.","In a non-distributed setting where martingale estimation can be used, UltraLogLog is able to reduce space by 17%.","Moreover, its smaller entropy and its 8-bit registers lead to better compaction when using standard compression algorithms.","All this is verified by experimental results that are in perfect agreement with the theoretical analysis which also outlines potential for even more space-efficient data structures.","A production-ready Java implementation of UltraLogLog has been released as part of the open-source Hash4j","library."],"url":"http://arxiv.org/abs/2308.16862v1"}
{"created":"2023-08-31 17:04:20","title":"Facing Unknown: Open-World Encrypted Traffic Classification Based on Contrastive Pre-Training","abstract":"Traditional Encrypted Traffic Classification (ETC) methods face a significant challenge in classifying large volumes of encrypted traffic in the open-world assumption, i.e., simultaneously classifying the known applications and detecting unknown applications. We propose a novel Open-World Contrastive Pre-training (OWCP) framework for this. OWCP performs contrastive pre-training to obtain a robust feature representation. Based on this, we determine the spherical mapping space to find the marginal flows for each known class, which are used to train GANs to synthesize new flows similar to the known parts but do not belong to any class. These synthetic flows are assigned to Softmax's unknown node to modify the classifier, effectively enhancing sensitivity towards known flows and significantly suppressing unknown ones. Extensive experiments on three datasets show that OWCP significantly outperforms existing ETC and generic open-world classification methods. Furthermore, we conduct comprehensive ablation studies and sensitivity analyses to validate each integral component of OWCP.","sentences":["Traditional Encrypted Traffic Classification (ETC) methods face a significant challenge in classifying large volumes of encrypted traffic in the open-world assumption, i.e., simultaneously classifying the known applications and detecting unknown applications.","We propose a novel Open-World Contrastive Pre-training (OWCP) framework for this.","OWCP performs contrastive pre-training to obtain a robust feature representation.","Based on this, we determine the spherical mapping space to find the marginal flows for each known class, which are used to train GANs to synthesize new flows similar to the known parts but do not belong to any class.","These synthetic flows are assigned to Softmax's unknown node to modify the classifier, effectively enhancing sensitivity towards known flows and significantly suppressing unknown ones.","Extensive experiments on three datasets show that OWCP significantly outperforms existing ETC and generic open-world classification methods.","Furthermore, we conduct comprehensive ablation studies and sensitivity analyses to validate each integral component of OWCP."],"url":"http://arxiv.org/abs/2308.16861v1"}
{"created":"2023-08-31 17:03:16","title":"Majorization-Minimization for sparse SVMs","abstract":"Several decades ago, Support Vector Machines (SVMs) were introduced for performing binary classification tasks, under a supervised framework. Nowadays, they often outperform other supervised methods and remain one of the most popular approaches in the machine learning arena. In this work, we investigate the training of SVMs through a smooth sparse-promoting-regularized squared hinge loss minimization. This choice paves the way to the application of quick training methods built on majorization-minimization approaches, benefiting from the Lipschitz differentiabililty of the loss function. Moreover, the proposed approach allows us to handle sparsity-preserving regularizers promoting the selection of the most significant features, so enhancing the performance. Numerical tests and comparisons conducted on three different datasets demonstrate the good performance of the proposed methodology in terms of qualitative metrics (accuracy, precision, recall, and F 1 score) as well as computational cost.","sentences":["Several decades ago, Support Vector Machines (SVMs) were introduced for performing binary classification tasks, under a supervised framework.","Nowadays, they often outperform other supervised methods and remain one of the most popular approaches in the machine learning arena.","In this work, we investigate the training of SVMs through a smooth sparse-promoting-regularized squared hinge loss minimization.","This choice paves the way to the application of quick training methods built on majorization-minimization approaches, benefiting from the Lipschitz differentiabililty of the loss function.","Moreover, the proposed approach allows us to handle sparsity-preserving regularizers promoting the selection of the most significant features, so enhancing the performance.","Numerical tests and comparisons conducted on three different datasets demonstrate the good performance of the proposed methodology in terms of qualitative metrics (accuracy, precision, recall, and F 1 score) as well as computational cost."],"url":"http://arxiv.org/abs/2308.16858v1"}
{"created":"2023-08-31 16:59:58","title":"IoMT-Blockchain based Secured Remote Patient Monitoring Framework for Neuro-Stimulation Device","abstract":"Biomedical Engineering's Internet of Medical Things (IoMT) is helping to improve the accuracy, dependability, and productivity of electronic equipment in the healthcare business. Real-time sensory data from patients may be delivered and subsequently analyzed through rapid development of wearable IoMT devices, such as neuro-stimulation devices with a range of functions. Data from the Internet of Things is gathered, analyzed, and stored in a single location. However, single-point failure, data manipulation, privacy difficulties, and other challenges might arise as a result of centralization. Due to its decentralized nature, blockchain (BC) can alleviate these issues. The viability of establishing a non-invasive remote neurostimulation system employing IoMT-based transcranial Direct Current Stimulation is investigated in this work (tDCS). A hardware-based prototype tDCS device has been developed that can be operated over the internet using an android application. Our suggested framework addresses the problems of IoMTBC-based systems, meets the criteria of real-time remote patient monitoring systems, and incorporates literature best practices in the relevant fields.","sentences":["Biomedical Engineering's Internet of Medical Things (IoMT) is helping to improve the accuracy, dependability, and productivity of electronic equipment in the healthcare business.","Real-time sensory data from patients may be delivered and subsequently analyzed through rapid development of wearable IoMT devices, such as neuro-stimulation devices with a range of functions.","Data from the Internet of Things is gathered, analyzed, and stored in a single location.","However, single-point failure, data manipulation, privacy difficulties, and other challenges might arise as a result of centralization.","Due to its decentralized nature, blockchain (BC) can alleviate these issues.","The viability of establishing a non-invasive remote neurostimulation system employing IoMT-based transcranial Direct Current Stimulation is investigated in this work (tDCS).","A hardware-based prototype tDCS device has been developed that can be operated over the internet using an android application.","Our suggested framework addresses the problems of IoMTBC-based systems, meets the criteria of real-time remote patient monitoring systems, and incorporates literature best practices in the relevant fields."],"url":"http://arxiv.org/abs/2308.16857v1"}
{"created":"2023-08-31 16:58:30","title":"Analysis and Optimization of Reconfigurable Intelligent Surfaces Based on $S$-Parameters Multiport Network Theory","abstract":"In this paper, we consider a reconfigurable intelligent surface (RIS) and model it by using multiport network theory. We first compare the representation of RIS by using $Z$-parameters and $S$-parameters, by proving their equivalence and discussing their distinct features. Then, we develop an algorithm for optimizing the RIS configuration in the presence of electromagnetic mutual coupling. We show that the proposed algorithm based on optimizing the $S$-parameters results in better performance than existing algorithms based on optimizing the $Z$-parameters. This is attributed to the fact that small perturbations of the step size of the proposed algorithm result in larger variations of the $S$-parameters, hence increasing the convergence speed of the algorithm.","sentences":["In this paper, we consider a reconfigurable intelligent surface (RIS) and model it by using multiport network theory.","We first compare the representation of RIS by using $Z$-parameters and $S$-parameters, by proving their equivalence and discussing their distinct features.","Then, we develop an algorithm for optimizing the RIS configuration in the presence of electromagnetic mutual coupling.","We show that the proposed algorithm based on optimizing the $S$-parameters results in better performance than existing algorithms based on optimizing the $Z$-parameters.","This is attributed to the fact that small perturbations of the step size of the proposed algorithm result in larger variations of the $S$-parameters, hence increasing the convergence speed of the algorithm."],"url":"http://arxiv.org/abs/2308.16856v1"}
{"created":"2023-08-31 16:57:27","title":"Space Partitioning Schemes and Algorithms for Generating Regular and Spiral Treemaps","abstract":"Treemaps have been widely applied to the visualization of hierarchical data. A treemap takes a weighted tree and visualizes its leaves in a nested planar geometric shape, with sub-regions partitioned such that each sub-region has an area proportional to the weight of its associated leaf nodes. Efficiently generating visually appealing treemaps that also satisfy other quality criteria is an interesting problem that has been tackled from many directions. We present an optimization model and five new algorithms for this problem, including two divide and conquer approaches and three spiral treemap algorithms. Our optimization model is able to generate superior treemaps that could serve as a benchmark for comparing the quality of more computationally efficient algorithms. Our divide and conquer and spiral algorithms either improve the performance of their existing counterparts with respect to aspect ratio and stability or perform competitively. Our spiral algorithms also expand their applicability to a wider range of input scenarios. Four of these algorithms are computationally efficient as well with quasilinear running times and the last algorithm achieves a cubic running time. A full version of this paper with all appendices, data, and source codes is available at \\anonymizeOSF{\\OSFSupplementText}.","sentences":["Treemaps have been widely applied to the visualization of hierarchical data.","A treemap takes a weighted tree and visualizes its leaves in a nested planar geometric shape, with sub-regions partitioned such that each sub-region has an area proportional to the weight of its associated leaf nodes.","Efficiently generating visually appealing treemaps that also satisfy other quality criteria is an interesting problem that has been tackled from many directions.","We present an optimization model and five new algorithms for this problem, including two divide and conquer approaches and three spiral treemap algorithms.","Our optimization model is able to generate superior treemaps that could serve as a benchmark for comparing the quality of more computationally efficient algorithms.","Our divide and conquer and spiral algorithms either improve the performance of their existing counterparts with respect to aspect ratio and stability or perform competitively.","Our spiral algorithms also expand their applicability to a wider range of input scenarios.","Four of these algorithms are computationally efficient as well with quasilinear running times and the last algorithm achieves a cubic running time.","A full version of this paper with all appendices, data, and source codes is available at \\anonymizeOSF{\\OSFSupplementText}."],"url":"http://arxiv.org/abs/2308.16855v1"}
{"created":"2023-08-31 16:26:17","title":"Diffusion Models for Interferometric Satellite Aperture Radar","abstract":"Probabilistic Diffusion Models (PDMs) have recently emerged as a very promising class of generative models, achieving high performance in natural image generation. However, their performance relative to non-natural images, like radar-based satellite data, remains largely unknown. Generating large amounts of synthetic (and especially labelled) satellite data is crucial to implement deep-learning approaches for the processing and analysis of (interferometric) satellite aperture radar data. Here, we leverage PDMs to generate several radar-based satellite image datasets. We show that PDMs succeed in generating images with complex and realistic structures, but that sampling time remains an issue. Indeed, accelerated sampling strategies, which work well on simple image datasets like MNIST, fail on our radar datasets. We provide a simple and versatile open-source https://github.com/thomaskerdreux/PDM_SAR_InSAR_generation to train, sample and evaluate PDMs using any dataset on a single GPU.","sentences":["Probabilistic Diffusion Models (PDMs) have recently emerged as a very promising class of generative models, achieving high performance in natural image generation.","However, their performance relative to non-natural images, like radar-based satellite data, remains largely unknown.","Generating large amounts of synthetic (and especially labelled) satellite data is crucial to implement deep-learning approaches for the processing and analysis of (interferometric) satellite aperture radar data.","Here, we leverage PDMs to generate several radar-based satellite image datasets.","We show that PDMs succeed in generating images with complex and realistic structures, but that sampling time remains an issue.","Indeed, accelerated sampling strategies, which work well on simple image datasets like MNIST, fail on our radar datasets.","We provide a simple and versatile open-source https://github.com/thomaskerdreux/PDM_SAR_InSAR_generation to train, sample and evaluate PDMs using any dataset on a single GPU."],"url":"http://arxiv.org/abs/2308.16847v1"}
{"created":"2023-08-31 16:12:01","title":"Towards Improving the Expressiveness of Singing Voice Synthesis with BERT Derived Semantic Information","abstract":"This paper presents an end-to-end high-quality singing voice synthesis (SVS) system that uses bidirectional encoder representation from Transformers (BERT) derived semantic embeddings to improve the expressiveness of the synthesized singing voice. Based on the main architecture of recently proposed VISinger, we put forward several specific designs for expressive singing voice synthesis. First, different from the previous SVS models, we use text representation of lyrics extracted from pre-trained BERT as additional input to the model. The representation contains information about semantics of the lyrics, which could help SVS system produce more expressive and natural voice. Second, we further introduce an energy predictor to stabilize the synthesized voice and model the wider range of energy variations that also contribute to the expressiveness of singing voice. Last but not the least, to attenuate the off-key issues, the pitch predictor is re-designed to predict the real to note pitch ratio. Both objective and subjective experimental results indicate that the proposed SVS system can produce singing voice with higher-quality outperforming VISinger.","sentences":["This paper presents an end-to-end high-quality singing voice synthesis (SVS) system that uses bidirectional encoder representation from Transformers (BERT) derived semantic embeddings to improve the expressiveness of the synthesized singing voice.","Based on the main architecture of recently proposed VISinger, we put forward several specific designs for expressive singing voice synthesis.","First, different from the previous SVS models, we use text representation of lyrics extracted from pre-trained BERT as additional input to the model.","The representation contains information about semantics of the lyrics, which could help SVS system produce more expressive and natural voice.","Second, we further introduce an energy predictor to stabilize the synthesized voice and model the wider range of energy variations that also contribute to the expressiveness of singing voice.","Last but not the least, to attenuate the off-key issues, the pitch predictor is re-designed to predict the real to note pitch ratio.","Both objective and subjective experimental results indicate that the proposed SVS system can produce singing voice with higher-quality outperforming VISinger."],"url":"http://arxiv.org/abs/2308.16836v1"}
{"created":"2023-08-31 16:10:22","title":"FedDD: Toward Communication-efficient Federated Learning with Differential Parameter Dropout","abstract":"Federated Learning (FL) requires frequent exchange of model parameters, which leads to long communication delay, especially when the network environments of clients vary greatly. Moreover, the parameter server needs to wait for the slowest client (i.e., straggler, which may have the largest model size, lowest computing capability or worst network condition) to upload parameters, which may significantly degrade the communication efficiency. Commonly-used client selection methods such as partial client selection would lead to the waste of computing resources and weaken the generalization of the global model. To tackle this problem, along a different line, in this paper, we advocate the approach of model parameter dropout instead of client selection, and accordingly propose a novel framework of Federated learning scheme with Differential parameter Dropout (FedDD). FedDD consists of two key modules: dropout rate allocation and uploaded parameter selection, which will optimize the model parameter uploading ratios tailored to different clients' heterogeneous conditions and also select the proper set of important model parameters for uploading subject to clients' dropout rate constraints. Specifically, the dropout rate allocation is formulated as a convex optimization problem, taking system heterogeneity, data heterogeneity, and model heterogeneity among clients into consideration. The uploaded parameter selection strategy prioritizes on eliciting important parameters for uploading to speedup convergence. Furthermore, we theoretically analyze the convergence of the proposed FedDD scheme. Extensive performance evaluations demonstrate that the proposed FedDD scheme can achieve outstanding performances in both communication efficiency and model convergence, and also possesses a strong generalization capability to data of rare classes.","sentences":["Federated Learning (FL) requires frequent exchange of model parameters, which leads to long communication delay, especially when the network environments of clients vary greatly.","Moreover, the parameter server needs to wait for the slowest client (i.e., straggler, which may have the largest model size, lowest computing capability or worst network condition) to upload parameters, which may significantly degrade the communication efficiency.","Commonly-used client selection methods such as partial client selection would lead to the waste of computing resources and weaken the generalization of the global model.","To tackle this problem, along a different line, in this paper, we advocate the approach of model parameter dropout instead of client selection, and accordingly propose a novel framework of Federated learning scheme with Differential parameter Dropout (FedDD).","FedDD consists of two key modules: dropout rate allocation and uploaded parameter selection, which will optimize the model parameter uploading ratios tailored to different clients' heterogeneous conditions and also select the proper set of important model parameters for uploading subject to clients' dropout rate constraints.","Specifically, the dropout rate allocation is formulated as a convex optimization problem, taking system heterogeneity, data heterogeneity, and model heterogeneity among clients into consideration.","The uploaded parameter selection strategy prioritizes on eliciting important parameters for uploading to speedup convergence.","Furthermore, we theoretically analyze the convergence of the proposed FedDD scheme.","Extensive performance evaluations demonstrate that the proposed FedDD scheme can achieve outstanding performances in both communication efficiency and model convergence, and also possesses a strong generalization capability to data of rare classes."],"url":"http://arxiv.org/abs/2308.16835v1"}
{"created":"2023-08-31 15:56:29","title":"Coarse-to-Fine Amodal Segmentation with Shape Prior","abstract":"Amodal object segmentation is a challenging task that involves segmenting both visible and occluded parts of an object. In this paper, we propose a novel approach, called Coarse-to-Fine Segmentation (C2F-Seg), that addresses this problem by progressively modeling the amodal segmentation. C2F-Seg initially reduces the learning space from the pixel-level image space to the vector-quantized latent space. This enables us to better handle long-range dependencies and learn a coarse-grained amodal segment from visual features and visible segments. However, this latent space lacks detailed information about the object, which makes it difficult to provide a precise segmentation directly. To address this issue, we propose a convolution refine module to inject fine-grained information and provide a more precise amodal object segmentation based on visual features and coarse-predicted segmentation. To help the studies of amodal object segmentation, we create a synthetic amodal dataset, named as MOViD-Amodal (MOViD-A), which can be used for both image and video amodal object segmentation. We extensively evaluate our model on two benchmark datasets: KINS and COCO-A. Our empirical results demonstrate the superiority of C2F-Seg. Moreover, we exhibit the potential of our approach for video amodal object segmentation tasks on FISHBOWL and our proposed MOViD-A. Project page at: http://jianxgao.github.io/C2F-Seg.","sentences":["Amodal object segmentation is a challenging task that involves segmenting both visible and occluded parts of an object.","In this paper, we propose a novel approach, called Coarse-to-Fine Segmentation (C2F-Seg), that addresses this problem by progressively modeling the amodal segmentation.","C2F-Seg initially reduces the learning space from the pixel-level image space to the vector-quantized latent space.","This enables us to better handle long-range dependencies and learn a coarse-grained amodal segment from visual features and visible segments.","However, this latent space lacks detailed information about the object, which makes it difficult to provide a precise segmentation directly.","To address this issue, we propose a convolution refine module to inject fine-grained information and provide a more precise amodal object segmentation based on visual features and coarse-predicted segmentation.","To help the studies of amodal object segmentation, we create a synthetic amodal dataset, named as MOViD-Amodal (MOViD-A), which can be used for both image and video amodal object segmentation.","We extensively evaluate our model on two benchmark datasets: KINS and COCO-A. Our empirical results demonstrate the superiority of C2F-Seg.","Moreover, we exhibit the potential of our approach for video amodal object segmentation tasks on FISHBOWL and our proposed MOViD-A. Project page at: http://jianxgao.github.io/C2F-Seg."],"url":"http://arxiv.org/abs/2308.16825v1"}
{"created":"2023-08-31 15:53:51","title":"Can Programming Languages Boost Each Other via Instruction Tuning?","abstract":"When human programmers have mastered a programming language, it would be easier when they learn a new programming language. In this report, we focus on exploring whether programming languages can boost each other during the instruction fine-tuning phase of code large language models. We conduct extensive experiments of 8 popular programming languages (Python, JavaScript, TypeScript, C, C++, Java, Go, HTML) on StarCoder. Results demonstrate that programming languages can significantly improve each other. For example, CodeM-Python 15B trained on Python is able to increase Java by an absolute 17.95% pass@1 on HumanEval-X. More surprisingly, we found that CodeM-HTML 7B trained on the HTML corpus can improve Java by an absolute 15.24% pass@1. Our training data is released at https://github.com/NL2Code/CodeM.","sentences":["When human programmers have mastered a programming language, it would be easier when they learn a new programming language.","In this report, we focus on exploring whether programming languages can boost each other during the instruction fine-tuning phase of code large language models.","We conduct extensive experiments of 8 popular programming languages (Python, JavaScript, TypeScript, C, C++, Java, Go, HTML) on StarCoder.","Results demonstrate that programming languages can significantly improve each other.","For example, CodeM-Python 15B trained on Python is able to increase Java by an absolute 17.95% pass@1 on HumanEval-X. More surprisingly, we found that CodeM-HTML 7B trained on the HTML corpus can improve Java by an absolute 15.24% pass@1.","Our training data is released at https://github.com/NL2Code/CodeM."],"url":"http://arxiv.org/abs/2308.16824v1"}
{"created":"2023-08-31 15:52:35","title":"Latent Variable Multi-output Gaussian Processes for Hierarchical Datasets","abstract":"Multi-output Gaussian processes (MOGPs) have been introduced to deal with multiple tasks by exploiting the correlations between different outputs. Generally, MOGPs models assume a flat correlation structure between the outputs. However, such a formulation does not account for more elaborate relationships, for instance, if several replicates were observed for each output (which is a typical setting in biological experiments). This paper proposes an extension of MOGPs for hierarchical datasets (i.e. datasets for which the relationships between observations can be represented within a tree structure). Our model defines a tailored kernel function accounting for hierarchical structures in the data to capture different levels of correlations while leveraging the introduction of latent variables to express the underlying dependencies between outputs through a dedicated kernel. This latter feature is expected to significantly improve scalability as the number of tasks increases. An extensive experimental study involving both synthetic and real-world data from genomics and motion capture is proposed to support our claims.","sentences":["Multi-output Gaussian processes (MOGPs) have been introduced to deal with multiple tasks by exploiting the correlations between different outputs.","Generally, MOGPs models assume a flat correlation structure between the outputs.","However, such a formulation does not account for more elaborate relationships, for instance, if several replicates were observed for each output (which is a typical setting in biological experiments).","This paper proposes an extension of MOGPs for hierarchical datasets (i.e. datasets for which the relationships between observations can be represented within a tree structure).","Our model defines a tailored kernel function accounting for hierarchical structures in the data to capture different levels of correlations while leveraging the introduction of latent variables to express the underlying dependencies between outputs through a dedicated kernel.","This latter feature is expected to significantly improve scalability as the number of tasks increases.","An extensive experimental study involving both synthetic and real-world data from genomics and motion capture is proposed to support our claims."],"url":"http://arxiv.org/abs/2308.16822v1"}
{"created":"2023-08-31 15:50:22","title":"Learning Whole-body Manipulation for Quadrupedal Robot","abstract":"We propose a learning-based system for enabling quadrupedal robots to manipulate large, heavy objects using their whole body. Our system is based on a hierarchical control strategy that uses the deep latent variable embedding which captures manipulation-relevant information from interactions, proprioception, and action history, allowing the robot to implicitly understand object properties. We evaluate our framework in both simulation and real-world scenarios. In the simulation, it achieves a success rate of 93.6 % in accurately re-positioning and re-orienting various objects within a tolerance of 0.03 m and 5 {\\deg}. Real-world experiments demonstrate the successful manipulation of objects such as a 19.2 kg water-filled drum and a 15.3 kg plastic box filled with heavy objects while the robot weighs 27 kg. Unlike previous works that focus on manipulating small and light objects using prehensile manipulation, our framework illustrates the possibility of using quadrupeds for manipulating large and heavy objects that are ungraspable with the robot's entire body. Our method does not require explicit object modeling and offers significant computational efficiency compared to optimization-based methods. The video can be found at $\\href{https://youtu.be/fO_PVr27QxU}{this \\ http \\ URL}$.","sentences":["We propose a learning-based system for enabling quadrupedal robots to manipulate large, heavy objects using their whole body.","Our system is based on a hierarchical control strategy that uses the deep latent variable embedding which captures manipulation-relevant information from interactions, proprioception, and action history, allowing the robot to implicitly understand object properties.","We evaluate our framework in both simulation and real-world scenarios.","In the simulation, it achieves a success rate of 93.6 % in accurately re-positioning and re-orienting various objects within a tolerance of 0.03 m and 5 {\\deg}.","Real-world experiments demonstrate the successful manipulation of objects such as a 19.2 kg water-filled drum and a 15.3 kg plastic box filled with heavy objects while the robot weighs 27 kg.","Unlike previous works that focus on manipulating small and light objects using prehensile manipulation, our framework illustrates the possibility of using quadrupeds for manipulating large and heavy objects that are ungraspable with the robot's entire body.","Our method does not require explicit object modeling and offers significant computational efficiency compared to optimization-based methods.","The video can be found at $\\href{https://youtu.be/fO_PVr27QxU}{this \\ http \\ URL}$."],"url":"http://arxiv.org/abs/2308.16820v1"}
{"created":"2023-08-31 15:49:53","title":"BTSeg: Barlow Twins Regularization for Domain Adaptation in Semantic Segmentation","abstract":"Semantic image segmentation is a critical component in many computer vision systems, such as autonomous driving. In such applications, adverse conditions (heavy rain, night time, snow, extreme lighting) on the one hand pose specific challenges, yet are typically underrepresented in the available datasets. Generating more training data is cumbersome and expensive, and the process itself is error-prone due to the inherent aleatoric uncertainty. To address this challenging problem, we propose BTSeg, which exploits image-level correspondences as weak supervision signal to learn a segmentation model that is agnostic to adverse conditions. To this end, our approach uses the Barlow twins loss from the field of unsupervised learning and treats images taken at the same location but under different adverse conditions as \"augmentations\" of the same unknown underlying base image. This allows the training of a segmentation model that is robust to appearance changes introduced by different adverse conditions. We evaluate our approach on ACDC and the new challenging ACG benchmark to demonstrate its robustness and generalization capabilities. Our approach performs favorably when compared to the current state-of-the-art methods, while also being simpler to implement and train. The code will be released upon acceptance.","sentences":["Semantic image segmentation is a critical component in many computer vision systems, such as autonomous driving.","In such applications, adverse conditions (heavy rain, night time, snow, extreme lighting) on the one hand pose specific challenges, yet are typically underrepresented in the available datasets.","Generating more training data is cumbersome and expensive, and the process itself is error-prone due to the inherent aleatoric uncertainty.","To address this challenging problem, we propose BTSeg, which exploits image-level correspondences as weak supervision signal to learn a segmentation model that is agnostic to adverse conditions.","To this end, our approach uses the Barlow twins loss from the field of unsupervised learning and treats images taken at the same location but under different adverse conditions as \"augmentations\" of the same unknown underlying base image.","This allows the training of a segmentation model that is robust to appearance changes introduced by different adverse conditions.","We evaluate our approach on ACDC and the new challenging ACG benchmark to demonstrate its robustness and generalization capabilities.","Our approach performs favorably when compared to the current state-of-the-art methods, while also being simpler to implement and train.","The code will be released upon acceptance."],"url":"http://arxiv.org/abs/2308.16819v1"}
{"created":"2023-08-31 15:49:21","title":"Irregular Traffic Time Series Forecasting Based on Asynchronous Spatio-Temporal Graph Convolutional Network","abstract":"Accurate traffic forecasting at intersections governed by intelligent traffic signals is critical for the advancement of an effective intelligent traffic signal control system. However, due to the irregular traffic time series produced by intelligent intersections, the traffic forecasting task becomes much more intractable and imposes three major new challenges: 1) asynchronous spatial dependency, 2) irregular temporal dependency among traffic data, and 3) variable-length sequence to be predicted, which severely impede the performance of current traffic forecasting methods. To this end, we propose an Asynchronous Spatio-tEmporal graph convolutional nEtwoRk (ASeer) to predict the traffic states of the lanes entering intelligent intersections in a future time window. Specifically, by linking lanes via a traffic diffusion graph, we first propose an Asynchronous Graph Diffusion Network to model the asynchronous spatial dependency between the time-misaligned traffic state measurements of lanes. After that, to capture the temporal dependency within irregular traffic state sequence, a learnable personalized time encoding is devised to embed the continuous time for each lane. Then we propose a Transformable Time-aware Convolution Network that learns meta-filters to derive time-aware convolution filters with transformable filter sizes for efficient temporal convolution on the irregular sequence. Furthermore, a Semi-Autoregressive Prediction Network consisting of a state evolution unit and a semiautoregressive predictor is designed to effectively and efficiently predict variable-length traffic state sequences. Extensive experiments on two real-world datasets demonstrate the effectiveness of ASeer in six metrics.","sentences":["Accurate traffic forecasting at intersections governed by intelligent traffic signals is critical for the advancement of an effective intelligent traffic signal control system.","However, due to the irregular traffic time series produced by intelligent intersections, the traffic forecasting task becomes much more intractable and imposes three major new challenges: 1) asynchronous spatial dependency, 2) irregular temporal dependency among traffic data, and 3) variable-length sequence to be predicted, which severely impede the performance of current traffic forecasting methods.","To this end, we propose an Asynchronous Spatio-tEmporal graph convolutional nEtwoRk (ASeer) to predict the traffic states of the lanes entering intelligent intersections in a future time window.","Specifically, by linking lanes via a traffic diffusion graph, we first propose an Asynchronous Graph Diffusion Network to model the asynchronous spatial dependency between the time-misaligned traffic state measurements of lanes.","After that, to capture the temporal dependency within irregular traffic state sequence, a learnable personalized time encoding is devised to embed the continuous time for each lane.","Then we propose a Transformable Time-aware Convolution Network that learns meta-filters to derive time-aware convolution filters with transformable filter sizes for efficient temporal convolution on the irregular sequence.","Furthermore, a Semi-Autoregressive Prediction Network consisting of a state evolution unit and a semiautoregressive predictor is designed to effectively and efficiently predict variable-length traffic state sequences.","Extensive experiments on two real-world datasets demonstrate the effectiveness of ASeer in six metrics."],"url":"http://arxiv.org/abs/2308.16818v1"}
{"created":"2023-08-31 15:41:21","title":"SiTAR: Situated Trajectory Analysis for In-the-Wild Pose Error Estimation","abstract":"Virtual content instability caused by device pose tracking error remains a prevalent issue in markerless augmented reality (AR), especially on smartphones and tablets. However, when examining environments which will host AR experiences, it is challenging to determine where those instability artifacts will occur; we rarely have access to ground truth pose to measure pose error, and even if pose error is available, traditional visualizations do not connect that data with the real environment, limiting their usefulness. To address these issues we present SiTAR (Situated Trajectory Analysis for Augmented Reality), the first situated trajectory analysis system for AR that incorporates estimates of pose tracking error. We start by developing the first uncertainty-based pose error estimation method for visual-inertial simultaneous localization and mapping (VI-SLAM), which allows us to obtain pose error estimates without ground truth; we achieve an average accuracy of up to 96.1% and an average F1 score of up to 0.77 in our evaluations on four VI-SLAM datasets. Next we present our SiTAR system, implemented for ARCore devices, combining a backend that supplies uncertainty-based pose error estimates with a frontend that generates situated trajectory visualizations. Finally, we evaluate the efficacy of SiTAR in realistic conditions by testing three visualization techniques in an in-the-wild study with 15 users and 13 diverse environments; this study reveals the impact both environment scale and the properties of surfaces present can have on user experience and task performance.","sentences":["Virtual content instability caused by device pose tracking error remains a prevalent issue in markerless augmented reality (AR), especially on smartphones and tablets.","However, when examining environments which will host AR experiences, it is challenging to determine where those instability artifacts will occur; we rarely have access to ground truth pose to measure pose error, and even if pose error is available, traditional visualizations do not connect that data with the real environment, limiting their usefulness.","To address these issues we present SiTAR (Situated Trajectory Analysis for Augmented Reality), the first situated trajectory analysis system for AR that incorporates estimates of pose tracking error.","We start by developing the first uncertainty-based pose error estimation method for visual-inertial simultaneous localization and mapping (VI-SLAM), which allows us to obtain pose error estimates without ground truth; we achieve an average accuracy of up to 96.1% and an average F1 score of up to 0.77 in our evaluations on four VI-SLAM datasets.","Next we present our SiTAR system, implemented for ARCore devices, combining a backend that supplies uncertainty-based pose error estimates with a frontend that generates situated trajectory visualizations.","Finally, we evaluate the efficacy of SiTAR in realistic conditions by testing three visualization techniques in an in-the-wild study with 15 users and 13 diverse environments; this study reveals the impact both environment scale and the properties of surfaces present can have on user experience and task performance."],"url":"http://arxiv.org/abs/2308.16813v1"}
{"created":"2023-08-31 15:25:41","title":"On the Performance of RIS-Aided Spatial Scattering Modulation for mmWave Transmission","abstract":"In this paper, we investigate a state-of-the-art reconfigurable intelligent surface (RIS)-assisted spatial scattering modulation (SSM) scheme for millimeter-wave (mmWave) systems, where a more practical scenario that the RIS is near the transmitter while the receiver is far from RIS is considered. To this end, the line-of-sight (LoS) and non-LoS links are utilized in the transmitter-RIS and RIS-receiver channels, respectively. By employing the maximum likelihood detector at the receiver, the conditional pairwise error probability (CPEP) expression for the RIS-SSM scheme is derived under the two scenarios that the received beam demodulation is correct or not. Furthermore, the union upper bound of average bit error probability (ABEP) is obtained based on the CPEP expression. Finally, the derivation results are exhaustively validated by the Monte Carlo simulations.","sentences":["In this paper, we investigate a state-of-the-art reconfigurable intelligent surface (RIS)-assisted spatial scattering modulation (SSM) scheme for millimeter-wave (mmWave) systems, where a more practical scenario that the RIS is near the transmitter while the receiver is far from RIS is considered.","To this end, the line-of-sight (LoS) and non-LoS links are utilized in the transmitter-RIS and RIS-receiver channels, respectively.","By employing the maximum likelihood detector at the receiver, the conditional pairwise error probability (CPEP) expression for the RIS-SSM scheme is derived under the two scenarios that the received beam demodulation is correct or not.","Furthermore, the union upper bound of average bit error probability (ABEP) is obtained based on the CPEP expression.","Finally, the derivation results are exhaustively validated by the Monte Carlo simulations."],"url":"http://arxiv.org/abs/2308.16804v1"}
{"created":"2023-08-31 15:23:33","title":"Multiscale Residual Learning of Graph Convolutional Sequence Chunks for Human Motion Prediction","abstract":"A new method is proposed for human motion prediction by learning temporal and spatial dependencies. Recently, multiscale graphs have been developed to model the human body at higher abstraction levels, resulting in more stable motion prediction. Current methods however predetermine scale levels and combine spatially proximal joints to generate coarser scales based on human priors, even though movement patterns in different motion sequences vary and do not fully comply with a fixed graph of spatially connected joints. Another problem with graph convolutional methods is mode collapse, in which predicted poses converge around a mean pose with no discernible movements, particularly in long-term predictions. To tackle these issues, we propose ResChunk, an end-to-end network which explores dynamically correlated body components based on the pairwise relationships between all joints in individual sequences. ResChunk is trained to learn the residuals between target sequence chunks in an autoregressive manner to enforce the temporal connectivities between consecutive chunks. It is hence a sequence-to-sequence prediction network which considers dynamic spatio-temporal features of sequences at multiple levels. Our experiments on two challenging benchmark datasets, CMU Mocap and Human3.6M, demonstrate that our proposed method is able to effectively model the sequence information for motion prediction and outperform other techniques to set a new state-of-the-art. Our code is available at https://github.com/MohsenZand/ResChunk.","sentences":["A new method is proposed for human motion prediction by learning temporal and spatial dependencies.","Recently, multiscale graphs have been developed to model the human body at higher abstraction levels, resulting in more stable motion prediction.","Current methods however predetermine scale levels and combine spatially proximal joints to generate coarser scales based on human priors, even though movement patterns in different motion sequences vary and do not fully comply with a fixed graph of spatially connected joints.","Another problem with graph convolutional methods is mode collapse, in which predicted poses converge around a mean pose with no discernible movements, particularly in long-term predictions.","To tackle these issues, we propose ResChunk, an end-to-end network which explores dynamically correlated body components based on the pairwise relationships between all joints in individual sequences.","ResChunk is trained to learn the residuals between target sequence chunks in an autoregressive manner to enforce the temporal connectivities between consecutive chunks.","It is hence a sequence-to-sequence prediction network which considers dynamic spatio-temporal features of sequences at multiple levels.","Our experiments on two challenging benchmark datasets, CMU Mocap and Human3.6M, demonstrate that our proposed method is able to effectively model the sequence information for motion prediction and outperform other techniques to set a new state-of-the-art.","Our code is available at https://github.com/MohsenZand/ResChunk."],"url":"http://arxiv.org/abs/2308.16801v1"}
{"created":"2023-08-31 15:22:31","title":"Rank Collapse Causes Over-Smoothing and Over-Correlation in Graph Neural Networks","abstract":"Our study reveals new theoretical insights into over-smoothing and feature over-correlation in deep graph neural networks. We show the prevalence of invariant subspaces, demonstrating a fixed relative behavior that is unaffected by feature transformations. Our work clarifies recent observations related to convergence to a constant state and a potential over-separation of node states, as the amplification of subspaces only depends on the spectrum of the aggregation function. In linear scenarios, this leads to node representations being dominated by a low-dimensional subspace with an asymptotic convergence rate independent of the feature transformations. This causes a rank collapse of the node representations, resulting in over-smoothing when smooth vectors span this subspace, and over-correlation even when over-smoothing is avoided. Guided by our theory, we propose a sum of Kronecker products as a beneficial property that can provably prevent over-smoothing, over-correlation, and rank collapse. We empirically extend our insights to the non-linear case, demonstrating the inability of existing models to capture linearly independent features.","sentences":["Our study reveals new theoretical insights into over-smoothing and feature over-correlation in deep graph neural networks.","We show the prevalence of invariant subspaces, demonstrating a fixed relative behavior that is unaffected by feature transformations.","Our work clarifies recent observations related to convergence to a constant state and a potential over-separation of node states, as the amplification of subspaces only depends on the spectrum of the aggregation function.","In linear scenarios, this leads to node representations being dominated by a low-dimensional subspace with an asymptotic convergence rate independent of the feature transformations.","This causes a rank collapse of the node representations, resulting in over-smoothing when smooth vectors span this subspace, and over-correlation even when over-smoothing is avoided.","Guided by our theory, we propose a sum of Kronecker products as a beneficial property that can provably prevent over-smoothing, over-correlation, and rank collapse.","We empirically extend our insights to the non-linear case, demonstrating the inability of existing models to capture linearly independent features."],"url":"http://arxiv.org/abs/2308.16800v1"}
{"created":"2023-08-31 15:19:28","title":"Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation","abstract":"Despite significant research effort in the development of automatic dialogue evaluation metrics, little thought is given to evaluating dialogues other than in English. At the same time, ensuring metrics are invariant to semantically similar responses is also an overlooked topic. In order to achieve the desired properties of robustness and multilinguality for dialogue evaluation metrics, we propose a novel framework that takes advantage of the strengths of current evaluation models with the newly-established paradigm of prompting Large Language Models (LLMs). Empirical results show our framework achieves state of the art results in terms of mean Spearman correlation scores across several benchmarks and ranks first place on both the Robust and Multilingual tasks of the DSTC11 Track 4 \"Automatic Evaluation Metrics for Open-Domain Dialogue Systems\", proving the evaluation capabilities of prompted LLMs.","sentences":["Despite significant research effort in the development of automatic dialogue evaluation metrics, little thought is given to evaluating dialogues other than in English.","At the same time, ensuring metrics are invariant to semantically similar responses is also an overlooked topic.","In order to achieve the desired properties of robustness and multilinguality for dialogue evaluation metrics, we propose a novel framework that takes advantage of the strengths of current evaluation models with the newly-established paradigm of prompting Large Language Models (LLMs).","Empirical results show our framework achieves state of the art results in terms of mean Spearman correlation scores across several benchmarks and ranks first place on both the Robust and Multilingual tasks of the DSTC11 Track 4 \"Automatic Evaluation Metrics for Open-Domain Dialogue Systems\", proving the evaluation capabilities of prompted LLMs."],"url":"http://arxiv.org/abs/2308.16797v1"}
{"created":"2023-08-31 15:15:26","title":"Towards Multilingual Automatic Dialogue Evaluation","abstract":"The main limiting factor in the development of robust multilingual dialogue evaluation metrics is the lack of multilingual data and the limited availability of open sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained LLM and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.","sentences":["The main limiting factor in the development of robust multilingual dialogue evaluation metrics is the lack of multilingual data and the limited availability of open sourced multilingual dialogue systems.","In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained LLM and augmenting existing English dialogue data using Machine Translation.","We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data.","Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance."],"url":"http://arxiv.org/abs/2308.16795v1"}
{"created":"2023-08-31 15:03:44","title":"Exploring the data of blockchain-based metaverses","abstract":"In recent years the concept of metaverse has evolved in the attempt of defining richer immersive and interactive environments supporting various types of virtual experiences and interactions among users. This has led to the emergence of various different metaverse platforms that utilize blockchain technology and non-fungible tokens (NFTs) to establish ownership of metaverse elements and attach features and information to it. This article will delve into the heterogeneity of the data involved in these metaverse platforms, as well as highlight some dynamics and features of them. Moreover, the paper introduces a metaverse analysis tool developed by the authors, which leverages machine learning techniques to collect and analyze daily data, including blockchain transactions, platform-specific metadata, and social media trends. Experimental results are reported are presented with a use-case scenario focused on the trading of digital parcels, commonly referred to as metaverse real estate.","sentences":["In recent years the concept of metaverse has evolved in the attempt of defining richer immersive and interactive environments supporting various types of virtual experiences and interactions among users.","This has led to the emergence of various different metaverse platforms that utilize blockchain technology and non-fungible tokens (NFTs) to establish ownership of metaverse elements and attach features and information to it.","This article will delve into the heterogeneity of the data involved in these metaverse platforms, as well as highlight some dynamics and features of them.","Moreover, the paper introduces a metaverse analysis tool developed by the authors, which leverages machine learning techniques to collect and analyze daily data, including blockchain transactions, platform-specific metadata, and social media trends.","Experimental results are reported are presented with a use-case scenario focused on the trading of digital parcels, commonly referred to as metaverse real estate."],"url":"http://arxiv.org/abs/2308.16787v1"}
{"created":"2023-08-31 15:02:01","title":"Agent Teaming Situation Awareness (ATSA): A Situation Awareness Framework for Human-AI Teaming","abstract":"The rapid advancements in artificial intelligence (AI) have led to a growing trend of human-AI teaming (HAT) in various fields. As machines continue to evolve from mere automation to a state of autonomy, they are increasingly exhibiting unexpected behaviors and human-like cognitive/intelligent capabilities, including situation awareness (SA). This shift has the potential to enhance the performance of mixed human-AI teams over all-human teams, underscoring the need for a better understanding of the dynamic SA interactions between humans and machines. To this end, we provide a review of leading SA theoretical models and a new framework for SA in the HAT context based on the key features and processes of HAT. The Agent Teaming Situation Awareness (ATSA) framework unifies human and AI behavior, and involves bidirectional, and dynamic interaction. The framework is based on the individual and team SA models and elaborates on the cognitive mechanisms for modeling HAT. Similar perceptual cycles are adopted for the individual (including both human and AI) and the whole team, which is tailored to the unique requirements of the HAT context. ATSA emphasizes cohesive and effective HAT through structures and components, including teaming understanding, teaming control, and the world, as well as adhesive transactive part. We further propose several future research directions to expand on the distinctive contributions of ATSA and address the specific and pressing next steps.","sentences":["The rapid advancements in artificial intelligence (AI) have led to a growing trend of human-AI teaming (HAT) in various fields.","As machines continue to evolve from mere automation to a state of autonomy, they are increasingly exhibiting unexpected behaviors and human-like cognitive/intelligent capabilities, including situation awareness (SA).","This shift has the potential to enhance the performance of mixed human-AI teams over all-human teams, underscoring the need for a better understanding of the dynamic SA interactions between humans and machines.","To this end, we provide a review of leading SA theoretical models and a new framework for SA in the HAT context based on the key features and processes of HAT.","The Agent Teaming Situation Awareness (ATSA) framework unifies human and AI behavior, and involves bidirectional, and dynamic interaction.","The framework is based on the individual and team SA models and elaborates on the cognitive mechanisms for modeling HAT.","Similar perceptual cycles are adopted for the individual (including both human and AI) and the whole team, which is tailored to the unique requirements of the HAT context.","ATSA emphasizes cohesive and effective HAT through structures and components, including teaming understanding, teaming control, and the world, as well as adhesive transactive part.","We further propose several future research directions to expand on the distinctive contributions of ATSA and address the specific and pressing next steps."],"url":"http://arxiv.org/abs/2308.16785v1"}
{"created":"2023-08-31 14:59:32","title":"StratMed: Relevance Stratification for Low-resource Medication Recommendation","abstract":"With the growing imbalance between limited medical resources and escalating demands, AI-based clinical tasks have become paramount. Medication recommendation, as a sub-domain, aims to amalgamate longitudinal patient history with medical knowledge, assisting physicians in prescribing safer and more accurate medication combinations. Existing methods overlook the inherent long-tail distribution in medical data, lacking balanced representation between head and tail data, which leads to sub-optimal model performance. To address this challenge, we introduce StratMed, a model that incorporates an innovative relevance stratification mechanism. It harmonizes discrepancies in data long-tail distribution and strikes a balance between the safety and accuracy of medication combinations. Specifically, we first construct a pre-training method using deep learning networks to obtain entity representation. After that, we design a pyramid-like data stratification method to obtain more generalized entity relationships by reinforcing the features of unpopular entities. Based on this relationship, we designed two graph structures to express medication precision and safety at the same level to obtain visit representations. Finally, the patient's historical clinical information is fitted to generate medication combinations for the current health condition. Experiments on the MIMIC-III dataset demonstrate that our method has outperformed current state-of-the-art methods in four evaluation metrics (including safety and accuracy).","sentences":["With the growing imbalance between limited medical resources and escalating demands, AI-based clinical tasks have become paramount.","Medication recommendation, as a sub-domain, aims to amalgamate longitudinal patient history with medical knowledge, assisting physicians in prescribing safer and more accurate medication combinations.","Existing methods overlook the inherent long-tail distribution in medical data, lacking balanced representation between head and tail data, which leads to sub-optimal model performance.","To address this challenge, we introduce StratMed, a model that incorporates an innovative relevance stratification mechanism.","It harmonizes discrepancies in data long-tail distribution and strikes a balance between the safety and accuracy of medication combinations.","Specifically, we first construct a pre-training method using deep learning networks to obtain entity representation.","After that, we design a pyramid-like data stratification method to obtain more generalized entity relationships by reinforcing the features of unpopular entities.","Based on this relationship, we designed two graph structures to express medication precision and safety at the same level to obtain visit representations.","Finally, the patient's historical clinical information is fitted to generate medication combinations for the current health condition.","Experiments on the MIMIC-III dataset demonstrate that our method has outperformed current state-of-the-art methods in four evaluation metrics (including safety and accuracy)."],"url":"http://arxiv.org/abs/2308.16781v1"}
{"created":"2023-08-31 14:55:30","title":"Ref-Diff: Zero-shot Referring Image Segmentation with Generative Models","abstract":"Zero-shot referring image segmentation is a challenging task because it aims to find an instance segmentation mask based on the given referring descriptions, without training on this type of paired data. Current zero-shot methods mainly focus on using pre-trained discriminative models (e.g., CLIP). However, we have observed that generative models (e.g., Stable Diffusion) have potentially understood the relationships between various visual elements and text descriptions, which are rarely investigated in this task. In this work, we introduce a novel Referring Diffusional segmentor (Ref-Diff) for this task, which leverages the fine-grained multi-modal information from generative models. We demonstrate that without a proposal generator, a generative model alone can achieve comparable performance to existing SOTA weakly-supervised models. When we combine both generative and discriminative models, our Ref-Diff outperforms these competing methods by a significant margin. This indicates that generative models are also beneficial for this task and can complement discriminative models for better referring segmentation. Our code is publicly available at https://github.com/kodenii/Ref-Diff.","sentences":["Zero-shot referring image segmentation is a challenging task because it aims to find an instance segmentation mask based on the given referring descriptions, without training on this type of paired data.","Current zero-shot methods mainly focus on using pre-trained discriminative models (e.g., CLIP).","However, we have observed that generative models (e.g., Stable Diffusion) have potentially understood the relationships between various visual elements and text descriptions, which are rarely investigated in this task.","In this work, we introduce a novel Referring Diffusional segmentor (Ref-Diff) for this task, which leverages the fine-grained multi-modal information from generative models.","We demonstrate that without a proposal generator, a generative model alone can achieve comparable performance to existing SOTA weakly-supervised models.","When we combine both generative and discriminative models, our Ref-Diff outperforms these competing methods by a significant margin.","This indicates that generative models are also beneficial for this task and can complement discriminative models for better referring segmentation.","Our code is publicly available at https://github.com/kodenii/Ref-Diff."],"url":"http://arxiv.org/abs/2308.16777v1"}
{"created":"2023-08-31 14:54:40","title":"HiSEP-Q: A Highly Scalable and Efficient Quantum Control Processor for Superconducting Qubits","abstract":"Quantum computing promises an effective way to solve targeted problems that are classically intractable. Among them, quantum computers built with superconducting qubits are considered one of the most advanced technologies, but they suffer from short coherence times. This can get exaggerated when they are controlled directly by general-purpose host machines, which leads to the loss of quantum information. To mitigate this, we need quantum control processors (QCPs) positioned between quantum processing units and host machines to reduce latencies. However, existing QCPs are built on top of designs with no or inefficient scalability, requiring a large number of instructions when scaling to more qubits. In addition, interactions between current QCPs and host machines require frequent data transmissions and offline computations to obtain final results, which limits the performance of quantum computers.   In this paper, we propose a QCP called HiSEP-Q featuring a novel quantum instruction set architecture (QISA) and its microarchitecture implementation. For efficient control, we utilize mixed-type addressing modes and mixed-length instructions in HiSEP-Q, which provides an efficient way to concurrently address more than 100 qubits. Further, for efficient read-out and analysis, we develop a novel onboard accumulation and sorting unit, which eliminates the data transmission of raw data between the QCPs and host machines and enables real-time result processing. Compared to the state-of-the-art, our proposed QISA achieves at least 62% and 28% improvements in encoding efficiency with real and synthetic quantum circuits, respectively. We also validate the microarchitecture on a field-programmable gate array, which exhibits low power and resource consumption. Both hardware and ISA evaluations demonstrate that HiSEP-Q features high scalability and efficiency toward the number of controlled qubits.","sentences":["Quantum computing promises an effective way to solve targeted problems that are classically intractable.","Among them, quantum computers built with superconducting qubits are considered one of the most advanced technologies, but they suffer from short coherence times.","This can get exaggerated when they are controlled directly by general-purpose host machines, which leads to the loss of quantum information.","To mitigate this, we need quantum control processors (QCPs) positioned between quantum processing units and host machines to reduce latencies.","However, existing QCPs are built on top of designs with no or inefficient scalability, requiring a large number of instructions when scaling to more qubits.","In addition, interactions between current QCPs and host machines require frequent data transmissions and offline computations to obtain final results, which limits the performance of quantum computers.   ","In this paper, we propose a QCP called HiSEP-Q featuring a novel quantum instruction set architecture (QISA) and its microarchitecture implementation.","For efficient control, we utilize mixed-type addressing modes and mixed-length instructions in HiSEP-Q, which provides an efficient way to concurrently address more than 100 qubits.","Further, for efficient read-out and analysis, we develop a novel onboard accumulation and sorting unit, which eliminates the data transmission of raw data between the QCPs and host machines and enables real-time result processing.","Compared to the state-of-the-art, our proposed QISA achieves at least 62% and 28% improvements in encoding efficiency with real and synthetic quantum circuits, respectively.","We also validate the microarchitecture on a field-programmable gate array, which exhibits low power and resource consumption.","Both hardware and ISA evaluations demonstrate that HiSEP-Q features high scalability and efficiency toward the number of controlled qubits."],"url":"http://arxiv.org/abs/2308.16776v1"}
{"created":"2023-08-31 14:54:06","title":"Efficacy of Neural Prediction-Based NAS for Zero-Shot NAS Paradigm","abstract":"In prediction-based Neural Architecture Search (NAS), performance indicators derived from graph convolutional networks have shown significant success. These indicators, achieved by representing feed-forward structures as component graphs through one-hot encoding, face a limitation: their inability to evaluate architecture performance across varying search spaces. In contrast, handcrafted performance indicators (zero-shot NAS), which use the same architecture with random initialization, can generalize across multiple search spaces. Addressing this limitation, we propose a novel approach for zero-shot NAS using deep learning. Our method employs Fourier sum of sines encoding for convolutional kernels, enabling the construction of a computational feed-forward graph with a structure similar to the architecture under evaluation. These encodings are learnable and offer a comprehensive view of the architecture's topological information. An accompanying multi-layer perceptron (MLP) then ranks these architectures based on their encodings. Experimental results show that our approach surpasses previous methods using graph convolutional networks in terms of correlation on the NAS-Bench-201 dataset and exhibits a higher convergence rate. Moreover, our extracted feature representation trained on each NAS-Benchmark is transferable to other NAS-Benchmarks, showing promising generalizability across multiple search spaces. The code is available at: https://github.com/minh1409/DFT-NPZS-NAS","sentences":["In prediction-based Neural Architecture Search (NAS), performance indicators derived from graph convolutional networks have shown significant success.","These indicators, achieved by representing feed-forward structures as component graphs through one-hot encoding, face a limitation: their inability to evaluate architecture performance across varying search spaces.","In contrast, handcrafted performance indicators (zero-shot NAS), which use the same architecture with random initialization, can generalize across multiple search spaces.","Addressing this limitation, we propose a novel approach for zero-shot NAS using deep learning.","Our method employs Fourier sum of sines encoding for convolutional kernels, enabling the construction of a computational feed-forward graph with a structure similar to the architecture under evaluation.","These encodings are learnable and offer a comprehensive view of the architecture's topological information.","An accompanying multi-layer perceptron (MLP) then ranks these architectures based on their encodings.","Experimental results show that our approach surpasses previous methods using graph convolutional networks in terms of correlation on the NAS-Bench-201 dataset and exhibits a higher convergence rate.","Moreover, our extracted feature representation trained on each NAS-Benchmark is transferable to other NAS-Benchmarks, showing promising generalizability across multiple search spaces.","The code is available at: https://github.com/minh1409/DFT-NPZS-NAS"],"url":"http://arxiv.org/abs/2308.16775v1"}
{"created":"2023-08-31 14:53:00","title":"Toward Automatically Completing GitHub Workflows","abstract":"Continuous integration and delivery (CI/CD) are nowadays at the core of software development. Their benefits come at the cost of setting up and maintaining the CI/CD pipeline, which requires knowledge and skills often orthogonal to those entailed in other software-related tasks. While several recommender systems have been proposed to support developers across a variety of tasks, little automated support is available when it comes to setting up and maintaining CI/CD pipelines. We present GH-WCOM (GitHub Workflow COMpletion), a Transformer-based approach supporting developers in writing a specific type of CI/CD pipelines, namely GitHub workflows. To deal with such a task, we designed an abstraction process to help the learning of the transformer while still making GH-WCOM able to recommend very peculiar workflow elements such as tool options and scripting elements. Our empirical study shows that GH-WCOM provides up to 34.23% correct predictions, and the model's confidence is a reliable proxy for the recommendations' correctness likelihood.","sentences":["Continuous integration and delivery (CI/CD) are nowadays at the core of software development.","Their benefits come at the cost of setting up and maintaining the CI/CD pipeline, which requires knowledge and skills often orthogonal to those entailed in other software-related tasks.","While several recommender systems have been proposed to support developers across a variety of tasks, little automated support is available when it comes to setting up and maintaining CI/CD pipelines.","We present GH-WCOM (GitHub Workflow COMpletion), a Transformer-based approach supporting developers in writing a specific type of CI/CD pipelines, namely GitHub workflows.","To deal with such a task, we designed an abstraction process to help the learning of the transformer while still making GH-WCOM able to recommend very peculiar workflow elements such as tool options and scripting elements.","Our empirical study shows that GH-WCOM provides up to 34.23% correct predictions, and the model's confidence is a reliable proxy for the recommendations' correctness likelihood."],"url":"http://arxiv.org/abs/2308.16774v1"}
{"created":"2023-08-31 14:47:00","title":"Enhancing PLM Performance on Labour Market Tasks via Instruction-based Finetuning and Prompt-tuning with Rules","abstract":"The increased digitization of the labour market has given researchers, educators, and companies the means to analyze and better understand the labour market. However, labour market resources, although available in high volumes, tend to be unstructured, and as such, research towards methodologies for the identification, linking, and extraction of entities becomes more and more important. Against the backdrop of this quest for better labour market representations, resource constraints and the unavailability of large-scale annotated data cause a reliance on human domain experts. We demonstrate the effectiveness of prompt-based tuning of pre-trained language models (PLM) in labour market specific applications. Our results indicate that cost-efficient methods such as PTR and instruction tuning without exemplars can significantly increase the performance of PLMs on downstream labour market applications without introducing additional model layers, manual annotations, and data augmentation.","sentences":["The increased digitization of the labour market has given researchers, educators, and companies the means to analyze and better understand the labour market.","However, labour market resources, although available in high volumes, tend to be unstructured, and as such, research towards methodologies for the identification, linking, and extraction of entities becomes more and more important.","Against the backdrop of this quest for better labour market representations, resource constraints and the unavailability of large-scale annotated data cause a reliance on human domain experts.","We demonstrate the effectiveness of prompt-based tuning of pre-trained language models (PLM) in labour market specific applications.","Our results indicate that cost-efficient methods such as PTR and instruction tuning without exemplars can significantly increase the performance of PLMs on downstream labour market applications without introducing additional model layers, manual annotations, and data augmentation."],"url":"http://arxiv.org/abs/2308.16770v1"}
{"created":"2023-08-31 14:46:05","title":"Towards Low-Barrier Cybersecurity Research and Education for Industrial Control Systems","abstract":"The protection of Industrial Control Systems (ICS) that are employed in public critical infrastructures is of utmost importance due to catastrophic physical damages cyberattacks may cause. The research community requires testbeds for validation and comparing various intrusion detection algorithms to protect ICS. However, there exist high barriers to entry for research and education in the ICS cybersecurity domain due to expensive hardware, software, and inherent dangers of manipulating real-world systems. To close the gap, built upon recently developed 3D high-fidelity simulators, we further showcase our integrated framework to automatically launch cyberattacks, collect data, train machine learning models, and evaluate for practical chemical and manufacturing processes. On our testbed, we validate our proposed intrusion detection model called Minimal Threshold and Window SVM (MinTWin SVM) that utilizes unsupervised machine learning via a one-class SVM in combination with a sliding window and classification threshold. Results show that MinTWin SVM minimizes false positives and is responsive to physical process anomalies. Furthermore, we incorporate our framework with ICS cybersecurity education by using our dataset in an undergraduate machine learning course where students gain hands-on experience in practicing machine learning theory with a practical ICS dataset. All of our implementations have been open-sourced.","sentences":["The protection of Industrial Control Systems (ICS) that are employed in public critical infrastructures is of utmost importance due to catastrophic physical damages cyberattacks may cause.","The research community requires testbeds for validation and comparing various intrusion detection algorithms to protect ICS.","However, there exist high barriers to entry for research and education in the ICS cybersecurity domain due to expensive hardware, software, and inherent dangers of manipulating real-world systems.","To close the gap, built upon recently developed 3D high-fidelity simulators, we further showcase our integrated framework to automatically launch cyberattacks, collect data, train machine learning models, and evaluate for practical chemical and manufacturing processes.","On our testbed, we validate our proposed intrusion detection model called Minimal Threshold and Window SVM (MinTWin SVM) that utilizes unsupervised machine learning via a one-class SVM in combination with a sliding window and classification threshold.","Results show that MinTWin SVM minimizes false positives and is responsive to physical process anomalies.","Furthermore, we incorporate our framework with ICS cybersecurity education by using our dataset in an undergraduate machine learning course where students gain hands-on experience in practicing machine learning theory with a practical ICS dataset.","All of our implementations have been open-sourced."],"url":"http://arxiv.org/abs/2308.16769v1"}
{"created":"2023-08-31 14:41:38","title":"Reinforcement learning for safety-critical control of an automated vehicle","abstract":"We present our approach for the development, validation and deployment of a data-driven decision-making function for the automated control of a vehicle. The decisionmaking function, based on an artificial neural network is trained to steer the mobile robot SPIDER towards a predefined, static path to a target point while avoiding collisions with obstacles along the path. The training is conducted by means of proximal policy optimisation (PPO), a state of the art algorithm from the field of reinforcement learning. The resulting controller is validated using KPIs quantifying its capability to follow a given path and its reactivity on perceived obstacles along the path. The corresponding tests are carried out in the training environment. Additionally, the tests shall be performed as well in the robotics situation Gazebo and in real world scenarios. For the latter the controller is deployed on a FPGA-based development platform, the FRACTAL platform, and integrated into the SPIDER software stack.","sentences":["We present our approach for the development, validation and deployment of a data-driven decision-making function for the automated control of a vehicle.","The decisionmaking function, based on an artificial neural network is trained to steer the mobile robot SPIDER towards a predefined, static path to a target point while avoiding collisions with obstacles along the path.","The training is conducted by means of proximal policy optimisation (PPO), a state of the art algorithm from the field of reinforcement learning.","The resulting controller is validated using KPIs quantifying its capability to follow a given path and its reactivity on perceived obstacles along the path.","The corresponding tests are carried out in the training environment.","Additionally, the tests shall be performed as well in the robotics situation Gazebo and in real world scenarios.","For the latter the controller is deployed on a FPGA-based development platform, the FRACTAL platform, and integrated into the SPIDER software stack."],"url":"http://arxiv.org/abs/2308.16767v1"}
{"created":"2023-08-31 14:31:48","title":"Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection","abstract":"Chain-of-Thought Prompting (CoT) reinforces the reasoning capabilities of Large Language Models (LLMs) through the generation of intermediate rationales. However, these enhancements predominantly benefit large-scale models, leaving small LMs without significant performance improvements when directly applying CoT. Despite the advanced reasoning capabilities of LLMs, CoT relies primarily on their pre-trained internal knowledge. The external knowledge that is previously unknown to the model remains unexploited. This omission becomes pronounced in tasks such as stance detection, where the external background knowledge plays a pivotal role. Additionally, the large-scale architecture of LLMs inevitably present efficiency challenges during deployment. To address these challenges, we introduce the Ladder-of-Thought (LoT) for stance detection. Grounded in a dual-phase Cascaded Optimization framework, LoT directs the model to incorporate high-quality external knowledge, enhancing the intermediate rationales it generates. These bolstered rationales subsequently serve as the foundation for more precise predictions - akin to how a ladder facilitates reaching elevated goals. LoT achieves a balance between efficiency and accuracy, making it an adaptable and efficient framework for stance detection. Our empirical evaluations underscore LoT's effectiveness, marking a 16% improvement over ChatGPT and a 10% enhancement compared to ChatGPT with CoT.","sentences":["Chain-of-Thought Prompting (CoT) reinforces the reasoning capabilities of Large Language Models (LLMs) through the generation of intermediate rationales.","However, these enhancements predominantly benefit large-scale models, leaving small LMs without significant performance improvements when directly applying CoT.","Despite the advanced reasoning capabilities of LLMs, CoT relies primarily on their pre-trained internal knowledge.","The external knowledge that is previously unknown to the model remains unexploited.","This omission becomes pronounced in tasks such as stance detection, where the external background knowledge plays a pivotal role.","Additionally, the large-scale architecture of LLMs inevitably present efficiency challenges during deployment.","To address these challenges, we introduce the Ladder-of-Thought (LoT) for stance detection.","Grounded in a dual-phase Cascaded Optimization framework, LoT directs the model to incorporate high-quality external knowledge, enhancing the intermediate rationales it generates.","These bolstered rationales subsequently serve as the foundation for more precise predictions - akin to how a ladder facilitates reaching elevated goals.","LoT achieves a balance between efficiency and accuracy, making it an adaptable and efficient framework for stance detection.","Our empirical evaluations underscore LoT's effectiveness, marking a 16% improvement over ChatGPT and a 10% enhancement compared to ChatGPT with CoT."],"url":"http://arxiv.org/abs/2308.16763v1"}
{"created":"2023-08-31 14:29:10","title":"Co-evolving Vector Quantization for ID-based Recommendation","abstract":"Category information plays a crucial role in enhancing the quality and personalization of recommendations. Nevertheless, the availability of item category information is not consistently present, particularly in the context of ID-based recommendations. In this work, we propose an alternative approach to automatically learn and generate entity (i.e., user and item) categorical information at different levels of granularity, specifically for ID-based recommendation. Specifically, we devise a co-evolving vector quantization framework, namely COVE, which enables the simultaneous learning and refinement of code representation and entity embedding in an end-to-end manner, starting from the randomly initialized states. With its high adaptability, COVE can be easily integrated into existing recommendation models. We validate the effectiveness of COVE on various recommendation tasks including list completion, collaborative filtering, and click-through rate prediction, across different recommendation models. We will publish the code and data for other researchers to reproduce our work.","sentences":["Category information plays a crucial role in enhancing the quality and personalization of recommendations.","Nevertheless, the availability of item category information is not consistently present, particularly in the context of ID-based recommendations.","In this work, we propose an alternative approach to automatically learn and generate entity (i.e., user and item) categorical information at different levels of granularity, specifically for ID-based recommendation.","Specifically, we devise a co-evolving vector quantization framework, namely COVE, which enables the simultaneous learning and refinement of code representation and entity embedding in an end-to-end manner, starting from the randomly initialized states.","With its high adaptability, COVE can be easily integrated into existing recommendation models.","We validate the effectiveness of COVE on various recommendation tasks including list completion, collaborative filtering, and click-through rate prediction, across different recommendation models.","We will publish the code and data for other researchers to reproduce our work."],"url":"http://arxiv.org/abs/2308.16761v1"}
{"created":"2023-08-31 14:27:36","title":"Constructing Indoor Region-based Radio Map without Location Labels","abstract":"Radio map construction requires a large amount of radio measurement data with location labels, which imposes a high deployment cost. This paper develops a region-based radio map from received signal strength (RSS) measurements without location labels. The construction is based on a set of blindly collected RSS measurement data from a device that visits each region in an indoor area exactly once, where the footprints and timestamps are not recorded. The main challenge is to cluster the RSS data and match clusters with the physical regions. Classical clustering algorithms fail to work as the RSS data naturally appears as non-clustered due to multipaths and noise. In this paper, a signal subspace model with a sequential prior is constructed for the RSS data, and an integrated segmentation and clustering algorithm is developed, which is shown to find the globally optimal solution in a special case. Furthermore, the clustered data is matched with the physical regions using a graph-based approach. Based on real measurements from an office space, the proposed scheme reduces the region localization error by roughly 50% compared to a weighted centroid localization (WCL) baseline, and it even outperforms some supervised localization schemes, including k-nearest neighbor (KNN), support vector machine (SVM), and deep neural network (DNN), which require labeled data for training.","sentences":["Radio map construction requires a large amount of radio measurement data with location labels, which imposes a high deployment cost.","This paper develops a region-based radio map from received signal strength (RSS) measurements without location labels.","The construction is based on a set of blindly collected RSS measurement data from a device that visits each region in an indoor area exactly once, where the footprints and timestamps are not recorded.","The main challenge is to cluster the RSS data and match clusters with the physical regions.","Classical clustering algorithms fail to work as the RSS data naturally appears as non-clustered due to multipaths and noise.","In this paper, a signal subspace model with a sequential prior is constructed for the RSS data, and an integrated segmentation and clustering algorithm is developed, which is shown to find the globally optimal solution in a special case.","Furthermore, the clustered data is matched with the physical regions using a graph-based approach.","Based on real measurements from an office space, the proposed scheme reduces the region localization error by roughly 50% compared to a weighted centroid localization (WCL) baseline, and it even outperforms some supervised localization schemes, including k-nearest neighbor (KNN), support vector machine (SVM), and deep neural network (DNN), which require labeled data for training."],"url":"http://arxiv.org/abs/2308.16759v1"}
{"created":"2023-08-31 14:26:33","title":"Towards High-Fidelity Text-Guided 3D Face Generation and Manipulation Using only Images","abstract":"Generating 3D faces from textual descriptions has a multitude of applications, such as gaming, movie, and robotics. Recent progresses have demonstrated the success of unconditional 3D face generation and text-to-3D shape generation. However, due to the limited text-3D face data pairs, text-driven 3D face generation remains an open problem. In this paper, we propose a text-guided 3D faces generation method, refer as TG-3DFace, for generating realistic 3D faces using text guidance. Specifically, we adopt an unconditional 3D face generation framework and equip it with text conditions, which learns the text-guided 3D face generation with only text-2D face data. On top of that, we propose two text-to-face cross-modal alignment techniques, including the global contrastive learning and the fine-grained alignment module, to facilitate high semantic consistency between generated 3D faces and input texts. Besides, we present directional classifier guidance during the inference process, which encourages creativity for out-of-domain generations. Compared to the existing methods, TG-3DFace creates more realistic and aesthetically pleasing 3D faces, boosting 9% multi-view consistency (MVIC) over Latent3D. The rendered face images generated by TG-3DFace achieve higher FID and CLIP score than text-to-2D face/image generation models, demonstrating our superiority in generating realistic and semantic-consistent textures.","sentences":["Generating 3D faces from textual descriptions has a multitude of applications, such as gaming, movie, and robotics.","Recent progresses have demonstrated the success of unconditional 3D face generation and text-to-3D shape generation.","However, due to the limited text-3D face data pairs, text-driven 3D face generation remains an open problem.","In this paper, we propose a text-guided 3D faces generation method, refer as TG-3DFace, for generating realistic 3D faces using text guidance.","Specifically, we adopt an unconditional 3D face generation framework and equip it with text conditions, which learns the text-guided 3D face generation with only text-2D face data.","On top of that, we propose two text-to-face cross-modal alignment techniques, including the global contrastive learning and the fine-grained alignment module, to facilitate high semantic consistency between generated 3D faces and input texts.","Besides, we present directional classifier guidance during the inference process, which encourages creativity for out-of-domain generations.","Compared to the existing methods, TG-3DFace creates more realistic and aesthetically pleasing 3D faces, boosting 9% multi-view consistency (MVIC) over Latent3D.","The rendered face images generated by TG-3DFace achieve higher FID and CLIP score than text-to-2D face/image generation models, demonstrating our superiority in generating realistic and semantic-consistent textures."],"url":"http://arxiv.org/abs/2308.16758v1"}
{"created":"2023-08-31 14:19:50","title":"Context Aware Query Rewriting for Text Rankers using LLM","abstract":"Query rewriting refers to an established family of approaches that are applied to underspecified and ambiguous queries to overcome the vocabulary mismatch problem in document ranking. Queries are typically rewritten during query processing time for better query modelling for the downstream ranker. With the advent of large-language models (LLMs), there have been initial investigations into using generative approaches to generate pseudo documents to tackle this inherent vocabulary gap. In this work, we analyze the utility of LLMs for improved query rewriting for text ranking tasks. We find that there are two inherent limitations of using LLMs as query re-writers -- concept drift when using only queries as prompts and large inference costs during query processing. We adopt a simple, yet surprisingly effective, approach called context aware query rewriting (CAR) to leverage the benefits of LLMs for query understanding. Firstly, we rewrite ambiguous training queries by context-aware prompting of LLMs, where we use only relevant documents as context.Unlike existing approaches, we use LLM-based query rewriting only during the training phase. Eventually, a ranker is fine-tuned on the rewritten queries instead of the original queries during training. In our extensive experiments, we find that fine-tuning a ranker using re-written queries offers a significant improvement of up to 33% on the passage ranking task and up to 28% on the document ranking task when compared to the baseline performance of using original queries.","sentences":["Query rewriting refers to an established family of approaches that are applied to underspecified and ambiguous queries to overcome the vocabulary mismatch problem in document ranking.","Queries are typically rewritten during query processing time for better query modelling for the downstream ranker.","With the advent of large-language models (LLMs), there have been initial investigations into using generative approaches to generate pseudo documents to tackle this inherent vocabulary gap.","In this work, we analyze the utility of LLMs for improved query rewriting for text ranking tasks.","We find that there are two inherent limitations of using LLMs as query re-writers -- concept drift when using only queries as prompts and large inference costs during query processing.","We adopt a simple, yet surprisingly effective, approach called context aware query rewriting (CAR) to leverage the benefits of LLMs for query understanding.","Firstly, we rewrite ambiguous training queries by context-aware prompting of LLMs, where we use only relevant documents as context.","Unlike existing approaches, we use LLM-based query rewriting only during the training phase.","Eventually, a ranker is fine-tuned on the rewritten queries instead of the original queries during training.","In our extensive experiments, we find that fine-tuning a ranker using re-written queries offers a significant improvement of up to 33% on the passage ranking task and up to 28% on the document ranking task when compared to the baseline performance of using original queries."],"url":"http://arxiv.org/abs/2308.16753v1"}
{"created":"2023-08-31 14:10:00","title":"A Novel Mapping and Navigation Framework for Robot Autonomy in Orchards","abstract":"Target detection is a basic task to divide the object types in the orchard point cloud global map, which is used to count the overall situation of the orchard. And provide necessary information for unmanned navigation planning of agricultural vehicles. In order to divide the fruit trees and the ground in the point cloud global map of the standardized orchard, and provide the orchard overall information for the path planning of autonomous vehicles in the natural orchard environment. A fruit tree detection method based on the Yolo-V7 network is proposed, which can effectively detect fruit tree targets from multi-sensor fused radar point cloud, reduce the 3D point cloud information of the point cloud map to 2D for the fruit tree point cloud in the Yolo-V7 network detection map, and project the prediction results into the point cloud map. Generally, the target detection network based on PointNet has the problem of low speed and large computational load. The method proposed in this paper is fast and low computational load and is suitable for deployment in mobile robots. From the experimental results, the recall rate and accuracy rate of the proposed method in orchard fruit tree detection are 0.4 and 0.696 respectively, and its weight and reasoning time are 7.4 M and 28 ms respectively. The experimental results show that this method can achieve the robustness and efficiency of real-time detection of orchard fruit trees.","sentences":["Target detection is a basic task to divide the object types in the orchard point cloud global map, which is used to count the overall situation of the orchard.","And provide necessary information for unmanned navigation planning of agricultural vehicles.","In order to divide the fruit trees and the ground in the point cloud global map of the standardized orchard, and provide the orchard overall information for the path planning of autonomous vehicles in the natural orchard environment.","A fruit tree detection method based on the Yolo-V7 network is proposed, which can effectively detect fruit tree targets from multi-sensor fused radar point cloud, reduce the 3D point cloud information of the point cloud map to 2D for the fruit tree point cloud in the Yolo-V7 network detection map, and project the prediction results into the point cloud map.","Generally, the target detection network based on PointNet has the problem of low speed and large computational load.","The method proposed in this paper is fast and low computational load and is suitable for deployment in mobile robots.","From the experimental results, the recall rate and accuracy rate of the proposed method in orchard fruit tree detection are 0.4 and 0.696 respectively, and its weight and reasoning time are 7.4 M and 28 ms respectively.","The experimental results show that this method can achieve the robustness and efficiency of real-time detection of orchard fruit trees."],"url":"http://arxiv.org/abs/2308.16748v1"}
{"created":"2023-08-31 14:04:28","title":"MS-BioGraphs: Sequence Similarity Graph Datasets","abstract":"Progress in High-Performance Computing in general, and High-Performance Graph Processing in particular, is highly dependent on the availability of publicly-accessible, relevant, and realistic data sets.   To ensure continuation of this progress, we (i) investigate and optimize the process of generating large sequence similarity graphs as an HPC challenge and (ii) demonstrate this process in creating MS-BioGraphs, a new family of publicly available real-world edge-weighted graph datasets with up to $2.5$ trillion edges, that is, $6.6$ times greater than the largest graph published recently. The largest graph is created by matching (i.e., all-to-all similarity aligning) $1.7$ billion protein sequences. The MS-BioGraphs family includes also seven subgraphs with different sizes and direction types.   We describe two main challenges we faced in generating large graph datasets and our solutions, that are, (i) optimizing data structures and algorithms for this multi-step process and (ii) WebGraph parallel compression technique. We present a comparative study of structural characteristics of MS-BioGraphs.   The datasets are available online on https://blogs.qub.ac.uk/DIPSA/MS-BioGraphs .","sentences":["Progress in High-Performance Computing in general, and High-Performance Graph Processing in particular, is highly dependent on the availability of publicly-accessible, relevant, and realistic data sets.   ","To ensure continuation of this progress, we (i) investigate and optimize the process of generating large sequence similarity graphs as an HPC challenge and (ii) demonstrate this process in creating MS-BioGraphs, a new family of publicly available real-world edge-weighted graph datasets with up to $2.5$ trillion edges, that is, $6.6$ times greater than the largest graph published recently.","The largest graph is created by matching (i.e., all-to-all similarity aligning) $1.7$ billion protein sequences.","The MS-BioGraphs family includes also seven subgraphs with different sizes and direction types.   ","We describe two main challenges we faced in generating large graph datasets and our solutions, that are, (i) optimizing data structures and algorithms for this multi-step process and (ii) WebGraph parallel compression technique.","We present a comparative study of structural characteristics of MS-BioGraphs.   ","The datasets are available online on https://blogs.qub.ac.uk/DIPSA/MS-BioGraphs ."],"url":"http://arxiv.org/abs/2308.16744v1"}
{"created":"2023-08-31 14:02:41","title":"A Remote Sim2real Aerial Competition: Fostering Reproducibility and Solutions' Diversity in Robotics Challenges","abstract":"Shared benchmark problems have historically been a fundamental driver of progress for scientific communities. In the context of academic conferences, competitions offer the opportunity to researchers with different origins, backgrounds, and levels of seniority to quantitatively compare their ideas. In robotics, a hot and challenging topic is sim2real-porting approaches that work well in simulation to real robot hardware. In our case, creating a hybrid competition with both simulation and real robot components was also dictated by the uncertainties around travel and logistics in the post-COVID-19 world. Hence, this article motivates and describes an aerial sim2real robot competition that ran during the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems, from the specification of the competition task, to the details of the software infrastructure supporting simulation and real-life experiments, to the approaches of the top-placed teams and the lessons learned by participants and organizers.","sentences":["Shared benchmark problems have historically been a fundamental driver of progress for scientific communities.","In the context of academic conferences, competitions offer the opportunity to researchers with different origins, backgrounds, and levels of seniority to quantitatively compare their ideas.","In robotics, a hot and challenging topic is sim2real-porting approaches that work well in simulation to real robot hardware.","In our case, creating a hybrid competition with both simulation and real robot components was also dictated by the uncertainties around travel and logistics in the post-COVID-19 world.","Hence, this article motivates and describes an aerial sim2real robot competition that ran during the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems, from the specification of the competition task, to the details of the software infrastructure supporting simulation and real-life experiments, to the approaches of the top-placed teams and the lessons learned by participants and organizers."],"url":"http://arxiv.org/abs/2308.16743v1"}
{"created":"2023-08-31 13:59:35","title":"Socratis: Are large multimodal models emotionally aware?","abstract":"Existing emotion prediction benchmarks contain coarse emotion labels which do not consider the diversity of emotions that an image and text can elicit in humans due to various reasons. Learning diverse reactions to multimodal content is important as intelligent machines take a central role in generating and delivering content to society. To address this gap, we propose Socratis, a \\underline{soc}ietal \\underline{r}e\\underline{a}c\\underline{ti}on\\underline{s} benchmark, where each image-caption (IC) pair is annotated with multiple emotions and the reasons for feeling them. Socratis contains 18K free-form reactions for 980 emotions on 2075 image-caption pairs from 5 widely-read news and image-caption (IC) datasets. We benchmark the capability of state-of-the-art multimodal large language models to generate the reasons for feeling an emotion given an IC pair. Based on a preliminary human study, we observe that humans prefer human-written reasons over 2 times more often than machine-generated ones. This shows our task is harder than standard generation tasks because it starkly contrasts recent findings where humans cannot tell apart machine vs human-written news articles, for instance. We further see that current captioning metrics based on large vision-language models also fail to correlate with human preferences. We hope that these findings and our benchmark will inspire further research on training emotionally aware models.","sentences":["Existing emotion prediction benchmarks contain coarse emotion labels which do not consider the diversity of emotions that an image and text can elicit in humans due to various reasons.","Learning diverse reactions to multimodal content is important as intelligent machines take a central role in generating and delivering content to society.","To address this gap, we propose Socratis, a \\underline{soc}ietal \\underline{r}e\\underline{a}c\\underline{ti}on\\underline{s} benchmark, where each image-caption (IC) pair is annotated with multiple emotions and the reasons for feeling them.","Socratis contains 18K free-form reactions for 980 emotions on 2075 image-caption pairs from 5 widely-read news and image-caption (IC) datasets.","We benchmark the capability of state-of-the-art multimodal large language models to generate the reasons for feeling an emotion given an IC pair.","Based on a preliminary human study, we observe that humans prefer human-written reasons over 2 times more often than machine-generated ones.","This shows our task is harder than standard generation tasks because it starkly contrasts recent findings where humans cannot tell apart machine vs human-written news articles, for instance.","We further see that current captioning metrics based on large vision-language models also fail to correlate with human preferences.","We hope that these findings and our benchmark will inspire further research on training emotionally aware models."],"url":"http://arxiv.org/abs/2308.16741v1"}
{"created":"2023-08-31 13:57:38","title":"Parsing is All You Need for Accurate Gait Recognition in the Wild","abstract":"Binary silhouettes and keypoint-based skeletons have dominated human gait recognition studies for decades since they are easy to extract from video frames. Despite their success in gait recognition for in-the-lab environments, they usually fail in real-world scenarios due to their low information entropy for gait representations. To achieve accurate gait recognition in the wild, this paper presents a novel gait representation, named Gait Parsing Sequence (GPS). GPSs are sequences of fine-grained human segmentation, i.e., human parsing, extracted from video frames, so they have much higher information entropy to encode the shapes and dynamics of fine-grained human parts during walking. Moreover, to effectively explore the capability of the GPS representation, we propose a novel human parsing-based gait recognition framework, named ParsingGait. ParsingGait contains a Convolutional Neural Network (CNN)-based backbone and two light-weighted heads. The first head extracts global semantic features from GPSs, while the other one learns mutual information of part-level features through Graph Convolutional Networks to model the detailed dynamics of human walking. Furthermore, due to the lack of suitable datasets, we build the first parsing-based dataset for gait recognition in the wild, named Gait3D-Parsing, by extending the large-scale and challenging Gait3D dataset. Based on Gait3D-Parsing, we comprehensively evaluate our method and existing gait recognition methods. The experimental results show a significant improvement in accuracy brought by the GPS representation and the superiority of ParsingGait. The code and dataset are available at https://gait3d.github.io/gait3d-parsing-hp .","sentences":["Binary silhouettes and keypoint-based skeletons have dominated human gait recognition studies for decades since they are easy to extract from video frames.","Despite their success in gait recognition for in-the-lab environments, they usually fail in real-world scenarios due to their low information entropy for gait representations.","To achieve accurate gait recognition in the wild, this paper presents a novel gait representation, named Gait Parsing Sequence (GPS).","GPSs are sequences of fine-grained human segmentation, i.e., human parsing, extracted from video frames, so they have much higher information entropy to encode the shapes and dynamics of fine-grained human parts during walking.","Moreover, to effectively explore the capability of the GPS representation, we propose a novel human parsing-based gait recognition framework, named ParsingGait.","ParsingGait contains a Convolutional Neural Network (CNN)-based backbone and two light-weighted heads.","The first head extracts global semantic features from GPSs, while the other one learns mutual information of part-level features through Graph Convolutional Networks to model the detailed dynamics of human walking.","Furthermore, due to the lack of suitable datasets, we build the first parsing-based dataset for gait recognition in the wild, named Gait3D-Parsing, by extending the large-scale and challenging Gait3D dataset.","Based on Gait3D-Parsing, we comprehensively evaluate our method and existing gait recognition methods.","The experimental results show a significant improvement in accuracy brought by the GPS representation and the superiority of ParsingGait.","The code and dataset are available at https://gait3d.github.io/gait3d-parsing-hp ."],"url":"http://arxiv.org/abs/2308.16739v1"}
{"created":"2023-08-31 13:54:37","title":"Robust Networked Federated Learning for Localization","abstract":"This paper addresses the problem of localization, which is inherently non-convex and non-smooth in a federated setting where the data is distributed across a multitude of devices. Due to the decentralized nature of federated environments, distributed learning becomes essential for scalability and adaptability. Moreover, these environments are often plagued by outlier data, which presents substantial challenges to conventional methods, particularly in maintaining estimation accuracy and ensuring algorithm convergence. To mitigate these challenges, we propose a method that adopts an $L_1$-norm robust formulation within a distributed sub-gradient framework, explicitly designed to handle these obstacles. Our approach addresses the problem in its original form, without resorting to iterative simplifications or approximations, resulting in enhanced computational efficiency and improved estimation accuracy. We demonstrate that our method converges to a stationary point, highlighting its effectiveness and reliability. Through numerical simulations, we confirm the superior performance of our approach, notably in outlier-rich environments, which surpasses existing state-of-the-art localization methods.","sentences":["This paper addresses the problem of localization, which is inherently non-convex and non-smooth in a federated setting where the data is distributed across a multitude of devices.","Due to the decentralized nature of federated environments, distributed learning becomes essential for scalability and adaptability.","Moreover, these environments are often plagued by outlier data, which presents substantial challenges to conventional methods, particularly in maintaining estimation accuracy and ensuring algorithm convergence.","To mitigate these challenges, we propose a method that adopts an $L_1$-norm robust formulation within a distributed sub-gradient framework, explicitly designed to handle these obstacles.","Our approach addresses the problem in its original form, without resorting to iterative simplifications or approximations, resulting in enhanced computational efficiency and improved estimation accuracy.","We demonstrate that our method converges to a stationary point, highlighting its effectiveness and reliability.","Through numerical simulations, we confirm the superior performance of our approach, notably in outlier-rich environments, which surpasses existing state-of-the-art localization methods."],"url":"http://arxiv.org/abs/2308.16737v1"}
{"created":"2023-08-31 13:52:28","title":"Post-Deployment Adaptation with Access to Source Data via Federated Learning and Source-Target Remote Gradient Alignment","abstract":"Deployment of Deep Neural Networks in medical imaging is hindered by distribution shift between training data and data processed after deployment, causing performance degradation. Post-Deployment Adaptation (PDA) addresses this by tailoring a pre-trained, deployed model to the target data distribution using limited labelled or entirely unlabelled target data, while assuming no access to source training data as they cannot be deployed with the model due to privacy concerns and their large size. This makes reliable adaptation challenging due to limited learning signal. This paper challenges this assumption and introduces FedPDA, a novel adaptation framework that brings the utility of learning from remote data from Federated Learning into PDA. FedPDA enables a deployed model to obtain information from source data via remote gradient exchange, while aiming to optimize the model specifically for the target domain. Tailored for FedPDA, we introduce a novel optimization method StarAlign (Source-Target Remote Gradient Alignment) that aligns gradients between source-target domain pairs by maximizing their inner product, to facilitate learning a target-specific model. We demonstrate the method's effectiveness using multi-center databases for the tasks of cancer metastases detection and skin lesion classification, where our method compares favourably to previous work. Code is available at: https://github.com/FelixWag/StarAlign","sentences":["Deployment of Deep Neural Networks in medical imaging is hindered by distribution shift between training data and data processed after deployment, causing performance degradation.","Post-Deployment Adaptation (PDA) addresses this by tailoring a pre-trained, deployed model to the target data distribution using limited labelled or entirely unlabelled target data, while assuming no access to source training data as they cannot be deployed with the model due to privacy concerns and their large size.","This makes reliable adaptation challenging due to limited learning signal.","This paper challenges this assumption and introduces FedPDA, a novel adaptation framework that brings the utility of learning from remote data from Federated Learning into PDA.","FedPDA enables a deployed model to obtain information from source data via remote gradient exchange, while aiming to optimize the model specifically for the target domain.","Tailored for FedPDA, we introduce a novel optimization method StarAlign (Source-Target Remote Gradient Alignment) that aligns gradients between source-target domain pairs by maximizing their inner product, to facilitate learning a target-specific model.","We demonstrate the method's effectiveness using multi-center databases for the tasks of cancer metastases detection and skin lesion classification, where our method compares favourably to previous work.","Code is available at: https://github.com/FelixWag/StarAlign"],"url":"http://arxiv.org/abs/2308.16735v1"}
{"created":"2023-08-31 13:51:56","title":"Native vs Web Apps: Comparing the Energy Consumption and Performance of Android Apps and their Web Counterparts","abstract":"Context. Many Internet content platforms, such as Spotify and YouTube, provide their services via both native and Web apps. Even though those apps provide similar features to the end user, using their native version or Web counterpart might lead to different levels of energy consumption and performance. Goal. The goal of this study is to empirically assess the energy consumption and performance of native and Web apps in the context of Internet content platforms on Android. Method. We select 10 Internet content platforms across 5 categories. Then, we measure them based on the energy consumption, network traffic volume, CPU load, memory load, and frame time of their native and Web versions; then, we statistically analyze the collected measures and report our results. Results. We confirm that native apps consume significantly less energy than their Web counterparts, with large effect size. Web apps use more CPU and memory, with statistically significant difference and large effect size. Therefore, we conclude that native apps tend to require fewer hardware resources than their corresponding Web versions. The network traffic volume exhibits statistically significant difference in favour of native apps, with small effect size. Our results do not allow us to draw any conclusion in terms of frame time. Conclusions. Based on our results, we advise users to access Internet contents using native apps over Web apps, when possible. Also, the results of this study motivate further research on the optimization of the usage of runtime resources of mobile Web apps and Android browsers.","sentences":["Context.","Many Internet content platforms, such as Spotify and YouTube, provide their services via both native and Web apps.","Even though those apps provide similar features to the end user, using their native version or Web counterpart might lead to different levels of energy consumption and performance.","Goal.","The goal of this study is to empirically assess the energy consumption and performance of native and Web apps in the context of Internet content platforms on Android.","Method.","We select 10 Internet content platforms across 5 categories.","Then, we measure them based on the energy consumption, network traffic volume, CPU load, memory load, and frame time of their native and Web versions; then, we statistically analyze the collected measures and report our results.","Results.","We confirm that native apps consume significantly less energy than their Web counterparts, with large effect size.","Web apps use more CPU and memory, with statistically significant difference and large effect size.","Therefore, we conclude that native apps tend to require fewer hardware resources than their corresponding Web versions.","The network traffic volume exhibits statistically significant difference in favour of native apps, with small effect size.","Our results do not allow us to draw any conclusion in terms of frame time.","Conclusions.","Based on our results, we advise users to access Internet contents using native apps over Web apps, when possible.","Also, the results of this study motivate further research on the optimization of the usage of runtime resources of mobile Web apps and Android browsers."],"url":"http://arxiv.org/abs/2308.16734v1"}
{"created":"2023-08-31 13:49:04","title":"Proof of Deep Learning: Approaches, Challenges, and Future Directions","abstract":"The rise of computational power has led to unprecedented performance gains for deep learning models. As more data becomes available and model architectures become more complex, the need for more computational power increases. On the other hand, since the introduction of Bitcoin as the first cryptocurrency and the establishment of the concept of blockchain as a distributed ledger, many variants and approaches have been proposed. However, many of them have one thing in common, which is the Proof of Work (PoW) consensus mechanism. PoW is mainly used to support the process of new block generation. While PoW has proven its robustness, its main drawback is that it requires a significant amount of processing power to maintain the security and integrity of the blockchain. This is due to applying brute force to solve a hashing puzzle. To utilize the computational power available in useful and meaningful work while keeping the blockchain secure, many techniques have been proposed, one of which is known as Proof of Deep Learning (PoDL). PoDL is a consensus mechanism that uses the process of training a deep learning model as proof of work to add new blocks to the blockchain. In this paper, we survey the various approaches for PoDL. We discuss the different types of PoDL algorithms, their advantages and disadvantages, and their potential applications. We also discuss the challenges of implementing PoDL and future research directions.","sentences":["The rise of computational power has led to unprecedented performance gains for deep learning models.","As more data becomes available and model architectures become more complex, the need for more computational power increases.","On the other hand, since the introduction of Bitcoin as the first cryptocurrency and the establishment of the concept of blockchain as a distributed ledger, many variants and approaches have been proposed.","However, many of them have one thing in common, which is the Proof of Work (PoW) consensus mechanism.","PoW is mainly used to support the process of new block generation.","While PoW has proven its robustness, its main drawback is that it requires a significant amount of processing power to maintain the security and integrity of the blockchain.","This is due to applying brute force to solve a hashing puzzle.","To utilize the computational power available in useful and meaningful work while keeping the blockchain secure, many techniques have been proposed, one of which is known as Proof of Deep Learning (PoDL).","PoDL is a consensus mechanism that uses the process of training a deep learning model as proof of work to add new blocks to the blockchain.","In this paper, we survey the various approaches for PoDL.","We discuss the different types of PoDL algorithms, their advantages and disadvantages, and their potential applications.","We also discuss the challenges of implementing PoDL and future research directions."],"url":"http://arxiv.org/abs/2308.16730v1"}
{"created":"2023-08-31 13:48:39","title":"JavaScript Dead Code Identification, Elimination, and Empirical Assessment","abstract":"Web apps are built by using a combination of HTML, CSS, and JavaScript. While building modern web apps, it is common practice to make use of third-party libraries and frameworks, as to improve developers' productivity and code quality. Alongside these benefits, the adoption of such libraries results in the introduction of JavaScript dead code, i.e., code implementing unused functionalities. The costs for downloading and parsing dead code can negatively contribute to the loading time and resource usage of web apps. The goal of our study is two-fold. First, we present Lacuna, an approach for automatically detecting and eliminating JavaScript dead code from web apps. The proposed approach supports both static and dynamic analyses, it is extensible and can be applied to any JavaScript code base, without imposing constraints on the coding style or on the use of specific JavaScript constructs. Secondly, by leveraging Lacuna we conduct an experiment to empirically evaluate the run-time overhead of JavaScript dead code in terms of energy consumption, performance, network usage, and resource usage in the context of mobile web apps. We applied Lacuna four times on 30 mobile web apps independently developed by third-party developers, each time eliminating dead code according to a different optimization level provided by Lacuna. Afterward, each different version of the web app is executed on an Android device, while collecting measures to assess the potential run-time overhead caused by dead code. Experimental results, among others, highlight that the removal of JavaScript dead code has a positive impact on the loading time of mobile web apps, while significantly reducing the number of bytes transferred over the network.","sentences":["Web apps are built by using a combination of HTML, CSS, and JavaScript.","While building modern web apps, it is common practice to make use of third-party libraries and frameworks, as to improve developers' productivity and code quality.","Alongside these benefits, the adoption of such libraries results in the introduction of JavaScript dead code, i.e., code implementing unused functionalities.","The costs for downloading and parsing dead code can negatively contribute to the loading time and resource usage of web apps.","The goal of our study is two-fold.","First, we present Lacuna, an approach for automatically detecting and eliminating JavaScript dead code from web apps.","The proposed approach supports both static and dynamic analyses, it is extensible and can be applied to any JavaScript code base, without imposing constraints on the coding style or on the use of specific JavaScript constructs.","Secondly, by leveraging Lacuna we conduct an experiment to empirically evaluate the run-time overhead of JavaScript dead code in terms of energy consumption, performance, network usage, and resource usage in the context of mobile web apps.","We applied Lacuna four times on 30 mobile web apps independently developed by third-party developers, each time eliminating dead code according to a different optimization level provided by Lacuna.","Afterward, each different version of the web app is executed on an Android device, while collecting measures to assess the potential run-time overhead caused by dead code.","Experimental results, among others, highlight that the removal of JavaScript dead code has a positive impact on the loading time of mobile web apps, while significantly reducing the number of bytes transferred over the network."],"url":"http://arxiv.org/abs/2308.16729v1"}
{"created":"2023-08-31 13:41:34","title":"Terrain Diffusion Network: Climatic-Aware Terrain Generation with Geological Sketch Guidance","abstract":"Sketch-based terrain generation seeks to create realistic landscapes for virtual environments in various applications such as computer games, animation and virtual reality. Recently, deep learning based terrain generation has emerged, notably the ones based on generative adversarial networks (GAN). However, these methods often struggle to fulfill the requirements of flexible user control and maintain generative diversity for realistic terrain. Therefore, we propose a novel diffusion-based method, namely terrain diffusion network (TDN), which actively incorporates user guidance for enhanced controllability, taking into account terrain features like rivers, ridges, basins, and peaks. Instead of adhering to a conventional monolithic denoising process, which often compromises the fidelity of terrain details or the alignment with user control, a multi-level denoising scheme is proposed to generate more realistic terrains by taking into account fine-grained details, particularly those related to climatic patterns influenced by erosion and tectonic activities. Specifically, three terrain synthesisers are designed for structural, intermediate, and fine-grained level denoising purposes, which allow each synthesiser concentrate on a distinct terrain aspect. Moreover, to maximise the efficiency of our TDN, we further introduce terrain and sketch latent spaces for the synthesizers with pre-trained terrain autoencoders. Comprehensive experiments on a new dataset constructed from NASA Topology Images clearly demonstrate the effectiveness of our proposed method, achieving the state-of-the-art performance. Our code and dataset will be publicly available.","sentences":["Sketch-based terrain generation seeks to create realistic landscapes for virtual environments in various applications such as computer games, animation and virtual reality.","Recently, deep learning based terrain generation has emerged, notably the ones based on generative adversarial networks (GAN).","However, these methods often struggle to fulfill the requirements of flexible user control and maintain generative diversity for realistic terrain.","Therefore, we propose a novel diffusion-based method, namely terrain diffusion network (TDN), which actively incorporates user guidance for enhanced controllability, taking into account terrain features like rivers, ridges, basins, and peaks.","Instead of adhering to a conventional monolithic denoising process, which often compromises the fidelity of terrain details or the alignment with user control, a multi-level denoising scheme is proposed to generate more realistic terrains by taking into account fine-grained details, particularly those related to climatic patterns influenced by erosion and tectonic activities.","Specifically, three terrain synthesisers are designed for structural, intermediate, and fine-grained level denoising purposes, which allow each synthesiser concentrate on a distinct terrain aspect.","Moreover, to maximise the efficiency of our TDN, we further introduce terrain and sketch latent spaces for the synthesizers with pre-trained terrain autoencoders.","Comprehensive experiments on a new dataset constructed from NASA Topology Images clearly demonstrate the effectiveness of our proposed method, achieving the state-of-the-art performance.","Our code and dataset will be publicly available."],"url":"http://arxiv.org/abs/2308.16725v1"}
{"created":"2023-08-31 13:40:08","title":"Data-driven Product-Process Optimization of N-isopropylacrylamide Microgel Flow-Synthesis","abstract":"Microgels are cross-linked, colloidal polymer networks with great potential for stimuli-response release in drug-delivery applications, as their size in the nanometer range allows them to pass human cell boundaries. For applications with specified requirements regarding size, producing tailored microgels in a continuous flow reactor is advantageous because the microgel properties can be controlled tightly. However, no fully-specified mechanistic models are available for continuous microgel synthesis, as the physical properties of the included components are only studied partly. To address this gap and accelerate tailor-made microgel development, we propose a data-driven optimization in a hardware-in-the-loop approach to efficiently synthesize microgels with defined sizes. We optimize the synthesis regarding conflicting objectives (maximum production efficiency, minimum energy consumption, and the desired microgel radius) by applying Bayesian optimization via the solver ``Thompson sampling efficient multi-objective optimization'' (TS-EMO). We validate the optimization using the deterministic global solver ``McCormick-based Algorithm for mixed-integer Nonlinear Global Optimization'' (MAiNGO) and verify three computed Pareto optimal solutions via experiments. The proposed framework can be applied to other desired microgel properties and reactor setups and has the potential of efficient development by minimizing number of experiments and modelling effort needed.","sentences":["Microgels are cross-linked, colloidal polymer networks with great potential for stimuli-response release in drug-delivery applications, as their size in the nanometer range allows them to pass human cell boundaries.","For applications with specified requirements regarding size, producing tailored microgels in a continuous flow reactor is advantageous because the microgel properties can be controlled tightly.","However, no fully-specified mechanistic models are available for continuous microgel synthesis, as the physical properties of the included components are only studied partly.","To address this gap and accelerate tailor-made microgel development, we propose a data-driven optimization in a hardware-in-the-loop approach to efficiently synthesize microgels with defined sizes.","We optimize the synthesis regarding conflicting objectives (maximum production efficiency, minimum energy consumption, and the desired microgel radius) by applying Bayesian optimization via the solver ``Thompson sampling efficient multi-objective optimization'' (TS-EMO).","We validate the optimization using the deterministic global solver ``McCormick-based Algorithm for mixed-integer Nonlinear Global Optimization'' (MAiNGO) and verify three computed Pareto optimal solutions via experiments.","The proposed framework can be applied to other desired microgel properties and reactor setups and has the potential of efficient development by minimizing number of experiments and modelling effort needed."],"url":"http://arxiv.org/abs/2308.16724v1"}
{"created":"2023-08-31 13:37:45","title":"Energy Efficient UAV-Assisted Emergency Communication with Reliable Connectivity and Collision Avoidance","abstract":"Emergency communication is vital for search and rescue operations following natural disasters. Unmanned Aerial Vehicles (UAVs) can significantly assist emergency communication by agile positioning, maintaining connectivity during rapid motion, and relaying critical disaster-related information to Ground Control Stations (GCS). Designing effective routing protocols for relaying crucial data in UAV networks is challenging due to dynamic topology, rapid mobility, and limited UAV resources. This paper presents a novel energy-constrained routing mechanism that ensures connectivity, inter-UAV collision avoidance, and network restoration post-UAV fragmentation while adapting without a predefined UAV path. The proposed method employs improved Q learning to optimize the next-hop node selection. Considering these factors, the paper proposes a novel, Improved Q-learning-based Multi-hop Routing (IQMR) protocol. Simulation results validate IQMRs adaptability to changing system conditions and superiority over QMR, QTAR, and QFANET in energy efficiency and data throughput. IQMR achieves energy consumption efficiency improvements of 32.27%, 36.35%, and 36.35% over QMR, Q-FANET, and QTAR, along with significantly higher data throughput enhancements of 53.3%, 80.35%, and 93.36% over Q-FANET, QMR, and QTAR.","sentences":["Emergency communication is vital for search and rescue operations following natural disasters.","Unmanned Aerial Vehicles (UAVs) can significantly assist emergency communication by agile positioning, maintaining connectivity during rapid motion, and relaying critical disaster-related information to Ground Control Stations (GCS).","Designing effective routing protocols for relaying crucial data in UAV networks is challenging due to dynamic topology, rapid mobility, and limited UAV resources.","This paper presents a novel energy-constrained routing mechanism that ensures connectivity, inter-UAV collision avoidance, and network restoration post-UAV fragmentation while adapting without a predefined UAV path.","The proposed method employs improved Q learning to optimize the next-hop node selection.","Considering these factors, the paper proposes a novel, Improved Q-learning-based Multi-hop Routing (IQMR) protocol.","Simulation results validate IQMRs adaptability to changing system conditions and superiority over QMR, QTAR, and QFANET in energy efficiency and data throughput.","IQMR achieves energy consumption efficiency improvements of 32.27%, 36.35%, and 36.35% over QMR, Q-FANET, and QTAR, along with significantly higher data throughput enhancements of 53.3%, 80.35%, and 93.36% over Q-FANET, QMR, and QTAR."],"url":"http://arxiv.org/abs/2308.16719v1"}
{"created":"2023-08-31 13:37:28","title":"Robust Representation Learning for Unreliable Partial Label Learning","abstract":"Partial Label Learning (PLL) is a type of weakly supervised learning where each training instance is assigned a set of candidate labels, but only one label is the ground-truth. However, this idealistic assumption may not always hold due to potential annotation inaccuracies, meaning the ground-truth may not be present in the candidate label set. This is known as Unreliable Partial Label Learning (UPLL) that introduces an additional complexity due to the inherent unreliability and ambiguity of partial labels, often resulting in a sub-optimal performance with existing methods. To address this challenge, we propose the Unreliability-Robust Representation Learning framework (URRL) that leverages unreliability-robust contrastive learning to help the model fortify against unreliable partial labels effectively. Concurrently, we propose a dual strategy that combines KNN-based candidate label set correction and consistency-regularization-based label disambiguation to refine label quality and enhance the ability of representation learning within the URRL framework. Extensive experiments demonstrate that the proposed method outperforms state-of-the-art PLL methods on various datasets with diverse degrees of unreliability and ambiguity. Furthermore, we provide a theoretical analysis of our approach from the perspective of the expectation maximization (EM) algorithm. Upon acceptance, we pledge to make the code publicly accessible.","sentences":["Partial Label Learning (PLL) is a type of weakly supervised learning where each training instance is assigned a set of candidate labels, but only one label is the ground-truth.","However, this idealistic assumption may not always hold due to potential annotation inaccuracies, meaning the ground-truth may not be present in the candidate label set.","This is known as Unreliable Partial Label Learning (UPLL) that introduces an additional complexity due to the inherent unreliability and ambiguity of partial labels, often resulting in a sub-optimal performance with existing methods.","To address this challenge, we propose the Unreliability-Robust Representation Learning framework (URRL) that leverages unreliability-robust contrastive learning to help the model fortify against unreliable partial labels effectively.","Concurrently, we propose a dual strategy that combines KNN-based candidate label set correction and consistency-regularization-based label disambiguation to refine label quality and enhance the ability of representation learning within the URRL framework.","Extensive experiments demonstrate that the proposed method outperforms state-of-the-art PLL methods on various datasets with diverse degrees of unreliability and ambiguity.","Furthermore, we provide a theoretical analysis of our approach from the perspective of the expectation maximization (EM) algorithm.","Upon acceptance, we pledge to make the code publicly accessible."],"url":"http://arxiv.org/abs/2308.16718v1"}
{"created":"2023-08-31 13:28:32","title":"Towards Vehicle-to-everything Autonomous Driving: A Survey on Collaborative Perception","abstract":"Vehicle-to-everything (V2X) autonomous driving opens up a promising direction for developing a new generation of intelligent transportation systems. Collaborative perception (CP) as an essential component to achieve V2X can overcome the inherent limitations of individual perception, including occlusion and long-range perception. In this survey, we provide a comprehensive review of CP methods for V2X scenarios, bringing a profound and in-depth understanding to the community. Specifically, we first introduce the architecture and workflow of typical V2X systems, which affords a broader perspective to understand the entire V2X system and the role of CP within it. Then, we thoroughly summarize and analyze existing V2X perception datasets and CP methods. Particularly, we introduce numerous CP methods from various crucial perspectives, including collaboration stages, roadside sensors placement, latency compensation, performance-bandwidth trade-off, attack/defense, pose alignment, etc. Moreover, we conduct extensive experimental analyses to compare and examine current CP methods, revealing some essential and unexplored insights. Specifically, we analyze the performance changes of different methods under different bandwidths, providing a deep insight into the performance-bandwidth trade-off issue. Also, we examine methods under different LiDAR ranges. To study the model robustness, we further investigate the effects of various simulated real-world noises on the performance of different CP methods, covering communication latency, lossy communication, localization errors, and mixed noises. In addition, we look into the sim-to-real generalization ability of existing CP methods. At last, we thoroughly discuss issues and challenges, highlighting promising directions for future efforts. Our codes for experimental analysis will be public at https://github.com/memberRE/Collaborative-Perception.","sentences":["Vehicle-to-everything (V2X) autonomous driving opens up a promising direction for developing a new generation of intelligent transportation systems.","Collaborative perception (CP) as an essential component to achieve V2X can overcome the inherent limitations of individual perception, including occlusion and long-range perception.","In this survey, we provide a comprehensive review of CP methods for V2X scenarios, bringing a profound and in-depth understanding to the community.","Specifically, we first introduce the architecture and workflow of typical V2X systems, which affords a broader perspective to understand the entire V2X system and the role of CP within it.","Then, we thoroughly summarize and analyze existing V2X perception datasets and CP methods.","Particularly, we introduce numerous CP methods from various crucial perspectives, including collaboration stages, roadside sensors placement, latency compensation, performance-bandwidth trade-off, attack/defense, pose alignment, etc.","Moreover, we conduct extensive experimental analyses to compare and examine current CP methods, revealing some essential and unexplored insights.","Specifically, we analyze the performance changes of different methods under different bandwidths, providing a deep insight into the performance-bandwidth trade-off issue.","Also, we examine methods under different LiDAR ranges.","To study the model robustness, we further investigate the effects of various simulated real-world noises on the performance of different CP methods, covering communication latency, lossy communication, localization errors, and mixed noises.","In addition, we look into the sim-to-real generalization ability of existing CP methods.","At last, we thoroughly discuss issues and challenges, highlighting promising directions for future efforts.","Our codes for experimental analysis will be public at https://github.com/memberRE/Collaborative-Perception."],"url":"http://arxiv.org/abs/2308.16714v1"}
{"created":"2023-08-31 13:25:13","title":"Meld: Exploring the Feasibility of a Framework-less Framework","abstract":"HEP data-processing frameworks are essential ingredients in getting from raw data to physics results. But they are often tricky to use well, and they present a significant learning barrier for the beginning HEP physicist. In addition, existing frameworks typically support rigid, collider-based data models, which do not map well to neutrino-physics experiments like DUNE. Neutrino physicists thus expend significant effort working around framework limitations instead of using a framework that directly supports their needs.   Presented here is Meld, a Fermilab R&D project, which intends to address these limitations. By leveraging modern C++ capabilities, state-of-the-art concurrency libraries, and a flexible data model, it is possible for beginning (and seasoned) HEP physicists to execute framework programs easily and efficiently, with minimal coupling to framework-specific constructs. Meld aims to directly support the frameworks needs of neutrino experiments like DUNE as well as the more common collider-based experiments.","sentences":["HEP data-processing frameworks are essential ingredients in getting from raw data to physics results.","But they are often tricky to use well, and they present a significant learning barrier for the beginning HEP physicist.","In addition, existing frameworks typically support rigid, collider-based data models, which do not map well to neutrino-physics experiments like DUNE.","Neutrino physicists thus expend significant effort working around framework limitations instead of using a framework that directly supports their needs.   ","Presented here is Meld, a Fermilab R&D project, which intends to address these limitations.","By leveraging modern C++ capabilities, state-of-the-art concurrency libraries, and a flexible data model, it is possible for beginning (and seasoned)","HEP physicists to execute framework programs easily and efficiently, with minimal coupling to framework-specific constructs.","Meld aims to directly support the frameworks needs of neutrino experiments like DUNE as well as the more common collider-based experiments."],"url":"http://arxiv.org/abs/2308.16710v1"}
{"created":"2023-08-31 13:25:13","title":"Lower Bounds on the Complexity of Mixed-Integer Programs for Stable Set and Knapsack","abstract":"Standard mixed-integer programming formulations for the stable set problem on $n$-node graphs require $n$ integer variables. We prove that this is almost optimal: We give a family of $n$-node graphs for which every polynomial-size MIP formulation requires $\\Omega(n/\\log^2 n)$ integer variables. By a polyhedral reduction we obtain an analogous result for $n$-item knapsack problems. In both cases, this improves the previously known bounds of $\\Omega(\\sqrt{n}/\\log n)$ by Cevallos, Weltge & Zenklusen (SODA 2018).   To this end, we show that there exists a family of $n$-node graphs whose stable set polytopes satisfy the following: any $(1+\\varepsilon/n)$-approximate extended formulation for these polytopes, for some constant $\\varepsilon > 0$, has size $2^{\\Omega(n/\\log n)}$. Our proof extends and simplifies the information-theoretic methods due to G\\\"o\\\"os, Jain & Watson (FOCS 2016, SIAM J. Comput. 2018) who showed the same result for the case of exact extended formulations (i.e. $\\varepsilon = 0$).","sentences":["Standard mixed-integer programming formulations for the stable set problem on $n$-node graphs require $n$ integer variables.","We prove that this is almost optimal: We give a family of $n$-node graphs for which every polynomial-size MIP formulation requires $\\Omega(n/\\log^2 n)$ integer variables.","By a polyhedral reduction we obtain an analogous result for $n$-item knapsack problems.","In both cases, this improves the previously known bounds of $\\Omega(\\sqrt{n}/\\log n)$ by Cevallos, Weltge & Zenklusen (SODA 2018).   ","To this end, we show that there exists a family of $n$-node graphs whose stable set polytopes satisfy the following: any $(1+\\varepsilon/n)$-approximate extended formulation for these polytopes, for some constant $\\varepsilon > 0$, has size $2^{\\Omega(n/\\log n)}$. Our proof extends and simplifies the information-theoretic methods due to G\\\"o\\\"os, Jain & Watson (FOCS 2016, SIAM J. Comput. 2018) who showed the same result for the case of exact extended formulations (i.e. $\\varepsilon = 0$)."],"url":"http://arxiv.org/abs/2308.16711v1"}
