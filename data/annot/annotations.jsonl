{"text":"Our code and dataset is available here.","cats":{"new-dataset":1}}
{"text":"We will release the dataset and code to facilitate future endeavors.","cats":{"new-dataset":1}}
{"text":"We release our dataset for others to use and build on.","cats":{"new-dataset":1}}
{"text":"Our dataset is available online.","cats":{"new-dataset":1}}
{"text":"We release the generated dataset and used prompts to facilitate future research.","cats":{"new-dataset":1}}
{"text":"Code and dataset will be available.","cats":{"new-dataset":1}}
{"text":"We demonstrate the value of the created dataset by performing a quantitative and qualitative analysis on the models' results.","cats":{"new-dataset":1}}
{"text":"We train our model on a new synthetic image dataset, that we release.","cats":{"new-dataset":0}}
{"text":"The code and new synthetic dataset will be released for better reproducibility of our results.","cats":{"new-dataset":1}}
{"text":"From this point, we can note the importance of building a new structured dataset to solve the lack of structured data.","cats":{"new-dataset":0}}
{"text":"Previous datasets are created by either capturing real scenes by event cameras or synthesizing from images with pasted foreground objects.","cats":{"new-dataset":0}}
{"text":"These datasets included the latest second and third generation deepfake datasets.","cats":{"new-dataset":0}}
{"text":"To our knowledge, this is the first aligned dataset of its kind and is the largest dataset ever released in the heritage domain.","cats":{"new-dataset":1}}
{"text":"The code and dataset will be released publicly.","cats":{"new-dataset":1}}
{"text":"We have released the code and dataset used in the present approach to generate synthetic data.","cats":{"new-dataset":1}}
{"text":"Our dataset is publicly available and can be freely modified and re-distributed.","cats":{"new-dataset":1}}
{"text":"The community has recognized the critical role that training datasets play in this context and has developed various techniques to improve dataset curation to overcome this problem.","cats":{"new-dataset":0}}
{"text":"Our code and dataset will be released at https://github.com/SiyuanYan1/EPVT.","cats":{"new-dataset":1}}
{"text":"The 3RL dataset was created, which contains approximately 24K images and will be publicly available, to overcome previously available dataset problems.","cats":{"new-dataset":1}}
{"text":"We use a public dataset for model development.","cats":{"new-dataset":0}}
{"text":"The related datasets and the source code will be released in the future.","cats":{"new-dataset":1}}
{"text":"We also collect a new large-scale dataset to serve as the new benchmark for this task.","cats":{"new-dataset":1}}
{"text":"The complete dataset engineered for this study, referred to as the CIFAKE dataset, is made publicly available to the research community for future work.","cats":{"new-dataset":1}}
{"text":"The dataset with accompanying code can be downloaded from our website.","cats":{"new-dataset":1}}
{"text":"We propose new training, validation, and testing splits for the dataset that we make available online.","cats":{"new-dataset":0}}
{"text":"Our code and unique datasets are available on the project's website.","cats":{"new-dataset":1}}
{"text":"We make our data available.","cats":{"new-dataset":1}}
{"text":"To facilitate research in this field, we will share our dataset and code with the community.","cats":{"new-dataset":1}}
{"text":"The dataset, related codes and models will be publicly available at https://github.com/hitachinsk/THA.","cats":{"new-dataset":1}}
{"text":"We have developed a systematic method to synthesize such training datasets.","cats":{"new-dataset":0}}
{"text":"In addition to the dataset itself, we also present some basic analysis of its content, certain temporal features, and its network.","cats":{"new-dataset":0}}
{"text":"In fact, to date, there is no dataset that we are aware of that addresses this issue.","cats":{"new-dataset":0}}
{"text":"We are committed to open-sourcing our meticulously curated dataset, as well as a comprehensive toolkit designed to aid researchers in the extensive collection and preprocessing of their own datasets.","cats":{"new-dataset":1}}
{"text":"Third, we provide a dataset of scenario based on our data generated.","cats":{"new-dataset":1}}
{"text":"Our source code and dataset will be made publicly available.","cats":{"new-dataset":1}}
{"text":"To this end, we first collect a new dataset, CAMO-FS, for the benchmark.","cats":{"new-dataset":1}}
{"text":"In this paper, we propose a framework for enhancing the data quality of original datasets.","cats":{"new-dataset":1}}
{"text":"We release a demo of our tools at dataportraits.org and call on dataset and model creators to release Data Portraits as a complement to current documentation practices.","cats":{"new-dataset":0}}
{"text":"The source code and dataset will be public.","cats":{"new-dataset":1}}
{"text":"To the best of our knowledge, only two datasets are available, with one based on the other.","cats":{"new-dataset":0}}
{"text":"We validate our method on two widely used datasets.","cats":{"new-dataset":0}}
{"text":"We introduce the VISION Datasets, a diverse collection of 14 industrial inspection datasets, uniquely poised to meet these challenges.","cats":{"new-dataset":1}}
{"text":"The dataset is available at https://www.tu-ilmenau.de/neurob/data-sets-code/attach-dataset .","cats":{"new-dataset":1}}
{"text":"The dataset and code are available at \\url{https://github.com/littleYaang/HQ-50K}.","cats":{"new-dataset":1}}
{"text":"The code to reproduce our results, as well as the model and dataset (via a research data use agreement), are available at our Github repo here: https://github.com/som-shahlab/ehrshot-benchmark","cats":{"new-dataset":1}}
{"text":"Our SCB-dataset can be downloaded from: https://github.com/Whiffe/SCB-dataset","cats":{"new-dataset":1}}
{"text":"The dataset is available for download at: https://ustc-flicar.github.io.","cats":{"new-dataset":1}}
{"text":"To access our dataset and code, visit our GitHub repository: \\url{https://github.com/styxsys0927/Med-MMHL}.","cats":{"new-dataset":1}}
{"text":"Code can be downloaded from https://github.com/Zhang-VISLab.","cats":{"new-dataset":1}}
{"text":"The data products and codes can be downloaded from this https://github.com/sriniraghunathan/cross_ilc_methods_paper.","cats":{"new-dataset":1}}
{"text":"To download the data please visit https://stanford-tml.github.io/circle_dataset/.","cats":{"new-dataset":1}}
{"text":"Our code is available at Github.","cats":{"new-dataset":0}}
{"text":"All code is available on GitHub.","cats":{"new-dataset":0}}
{"text":"With these new techniques, our proposed \\Ours{} achieves state-of-the-art results on FUNSD and XFUND datasets, outperforming the previous best-performing method by 7.2\\% and 13.2\\% in F1 score, respectively.","cats":{"new-dataset":0}}
{"text":"We make a python package with the code available to download at https://pypi.org/project/hypertab/","cats":{"new-dataset":0}}
{"text":"The air pollution data was downloaded from an online database (UCL).","cats":{"new-dataset":0}}
{"text":"The SA3 dataset and scripts (R/Python) to develop these indices have been made available on my GitHub account: https://github.com/lpinzari/homogeneity-location-index","cats":{"new-dataset":0}}
{"text":"We make the code available at github.","cats":{"new-dataset":0}}
{"text":"All the source code is available on Github.","cats":{"new-dataset":0}}
{"text":"The code has been deposited on GitHub (\\url{https://github.com/hyguozz}).","cats":{"new-dataset":0}}
{"text":"The code is on github at https://github.com/IDU-CVLab/COV19D_3rd","cats":{"new-dataset":0}}
{"text":"Its features, e.g., no need to download and no installation, have made it popular rapidly.","cats":{"new-dataset":0}}
{"text":"We outperform all baselines and demonstrate that among the considered methods, ours is the only one that detects label errors of all four types efficiently.","cats":{"new-dataset":0}}
{"text":"By leveraging this diversity, the collected dataset and the collection system aim to achieve higher recognition accuracy.","cats":{"new-dataset":0,"data-quality":0}}
{"text":"The dataset is generated by GPT-3.5-turbo and comprises programs with varying levels of complexity.","cats":{"new-dataset":0}}
{"text":"Our proposed dataset can support two different computer vision tasks, i.e., semantic segmentation and object detection.","cats":{"new-dataset":0}}
{"text":"To foster further research on the digitization of statistical graphs, we will make the dataset, code, and models publicly available to the community.","cats":{"new-dataset":1}}
{"text":"This collection includes a subset of the large-scale instruction dataset known as FLAN, as well as various code-related datasets and conversational datasets derived from ChatGPT/GPT-4.","cats":{"new-dataset":1}}
{"text":"FLACUNA is publicly available at https://huggingface.co/declare-lab/flacuna-13b-v1.0.","cats":{"new-dataset":1}}
{"text":"First, we publish a new dataset, EHRSHOT, containing de-identified structured data from the electronic health records (EHRs) of 6,712 patients from Stanford Medicine.","cats":{"new-dataset":1}}
{"text":"In this paper, we define a unified setting termed as open-set semantic segmentation (O3S), which aims to learn seen and unseen semantics from both visual examples and textual names.","cats":{"new-dataset":0}}
{"text":"Experimental results, carried out on three sets of the Shape COSEG Dataset, on the human segmentation dataset proposed in Maron et al., 2017 and on the ShapeNet benchmark, show how the proposed approach yields state-of-the-art performance on semantic segmentation of 3D meshes.","cats":{"new-dataset":0}}
{"text":"Our code and data are available at https://github.com/sergiotasconmorales/locvqa.","cats":{"new-dataset":0}}
{"text":"The dataset comprises high-resolution RGB-D images and pixel-level annotations of the fruits.","cats":{"new-dataset":0}}
{"text":"TGB datasets, data loaders, example codes, evaluation setup, and leaderboards are publicly available at https://tgb.complexdatalab.com/ .","cats":{"new-dataset":1}}
{"text":"Our code, models, instruction-sets and demo are released at https://github.com/mbzuai-oryx/Video-ChatGPT.","cats":{"new-dataset":1}}
{"text":"We extensively evaluate SeaLog on two public datasets and an industrial dataset.","cats":{"new-dataset":0}}
{"text":"Using the COVID-19 Open Research Dataset (CORD-19), we produced two datasets: (1) synCovid, which uses a combination of handwritten prompts and synthetic prompts generated using OpenAI, and (2) real abstracts, which contains abstract and title pairs.","cats":{"new-dataset":1}}
{"text":"Videos are available at: https://kristery.github.io/edt/","cats":{"new-dataset":0}}
{"text":"This paper presents an end-to-end methodology for collecting datasets to recognize handwritten English alphabets by utilizing Inertial Measurement Units (IMUs) and leveraging the diversity present in the Indian writing style.","cats":{"new-dataset":0}}
{"text":"Videos can be found on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.","cats":{"new-dataset":0}}
{"text":"In this paper, we study linear regression applied to data structured on a manifold.","cats":{"new-dataset":0,"data-quality":0}}
{"text":"We assume that the data manifold is smooth and is embedded in a Euclidean space, and our objective is to reveal the impact of the data manifold's extrinsic geometry on the regression.","cats":{"new-dataset":0,"data-quality":0}}
{"text":"This research can be extended and contributes to the field of pattern recognition and offers valuable insights for developing improved systems for handwriting recognition, particularly in diverse linguistic and cultural contexts.","cats":{"new-dataset":0}}
{"text":"To prove these theorems, we revisit William Thurston's results on the calisson tilability of a region $R$.","cats":{"new-dataset":0}}
{"text":"Large language models trained for safety and harmlessness remain susceptible to adversarial misuse, as evidenced by the prevalence of \"jailbreak\" attacks on early releases of ChatGPT that elicit undesired behavior.","cats":{"new-dataset":0,"data-quality":0}}
{"text":"We use these failure modes to guide jailbreak design and then evaluate state-of-the-art models, including OpenAI's GPT-4 and Anthropic's Claude v1.3, against both existing and newly designed attacks.","cats":{"new-dataset":0}}
{"text":"Given a triangular grid in a hexagon and some given edges of the grid, the problem is to find a calisson tiling such that no input edge is overlapped and calissons adjacent to an input edge have different orientations.","cats":{"new-dataset":0}}
{"text":"Our work opens up new possibilities for modeling very long sequences, e.g., treating a whole corpus or even the entire Internet as a sequence.","cats":{"new-dataset":0,"data-quality":0}}
{"text":"We extend the puzzle to regions $R$ that are not necessarily hexagonal.","cats":{"new-dataset":0}}
{"text":"By using a natural language generation model to abductively infer a premise given another premise and a conclusion, we can impute missing pieces of evidence needed for the conclusion to be true.","cats":{"new-dataset":0}}
{"text":"We sample multiple possible outputs for each step to achieve coverage of the search space, at the same time ensuring correctness by filtering low-quality generations with a round-trip validation procedure.","cats":{"new-dataset":0}}
{"text":"Results on a modified version of the EntailmentBank dataset and a new dataset called Everyday Norms: Why Not? show that abductive generation with validation can recover premises across in- and out-of-domain settings","cats":{"new-dataset":0}}
{"text":"To address this issue, this paper presents a systematic and comprehensive study, quantitatively and qualitatively, on training such models.","cats":{"new-dataset":0}}
{"text":"We implement over 20 variants with controlled settings.","cats":{"new-dataset":0}}
{"text":"For training data, we investigate the impact of data and sampling strategies.","cats":{"new-dataset":0}}
{"text":"For benchmarks, we contribute the first, to our best knowledge, comprehensive evaluation set including both image and video tasks through crowd-sourcing.","cats":{"new-dataset":1}}
{"text":"Here, remote sensing can provide reliable estimates of plastic pollution by regularly monitoring and detecting marine debris in coastal areas.","cats":{"new-dataset":0}}
{"text":"Medium-resolution satellite data of coastal areas is readily available and can be leveraged to detect aggregations of marine debris containing plastic litter.","cats":{"new-dataset":0}}
{"text":"In this work, we present a detector for marine debris built on a deep segmentation model that outputs a probability for marine debris at the pixel level.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"We train this detector with a combination of annotated datasets of marine debris and evaluate it on specifically selected test sites where it is highly probable that plastic pollution is present in the detected marine debris.","cats":{"new-dataset":0}}
{"text":"We demonstrate quantitatively and qualitatively that a deep learning model trained on this dataset issued from multiple sources outperforms existing detection models trained on previous datasets by a large margin.","cats":{"new-dataset":1}}
{"text":"We hope to accelerate advances in the large-scale automated detection of marine debris, which is a step towards quantifying and monitoring marine litter with remote sensing at global scales, and release the model weights and training source code under https://github.com/marccoru/marinedebrisdetector","cats":{"new-dataset":0}}
{"text":"This paper proposes a framework called <projektor>, which predicts model performance and supports data selection decisions based on partial samples of prospective data sources.","cats":{"new-dataset":0}}
{"text":"In the first stage, we leverage the Optimal Transport distance to predict the model's performance for any data mixture ratio within the range of disclosed data sizes.","cats":{"new-dataset":0}}
{"text":"To facilitate the development of comprehensive scene understanding solutions using multiple camera views, a new dataset called Road Genome (OpenLane-V2) has been released.","cats":{"new-dataset":1}}
{"text":"We achieve new state-of-the-art performance on the large-scale Waymo Open Dataset.","cats":{"new-dataset":0}}
{"text":"Finally, we train a detector that generalizes to a wide range of part segmentation datasets while achieving better performance than dataset-specific training.","cats":{"new-dataset":0}}
{"text":"Finally, we release a large-scale synthetic dataset with 1.4M examples generated using TrueTeacher.","cats":{"new-dataset":1}}
{"text":"To fully unlock model capabilities for high-quality video generation, we curate a large-scale video dataset called HD-VG-130M. This dataset comprises 130 million text-video pairs from the open-domain, ensuring high-definition, widescreen and watermark-free characters.","cats":{"new-dataset":1}}
{"text":"Code and datasets are available in https://github.com/zjunlp/DeepKE/tree/main/example/llm.","cats":{"new-dataset":1}}
{"text":"We evaluate TagGPT on publicly available datasets, i.e., Kuaishou and Food.com, and demonstrate the effectiveness of TagGPT compared to existing hashtags and off-the-shelf taggers.","cats":{"new-dataset":0}}
{"text":"Additionally, to track new and creative applications for bioinformatics tools such as ChatGPT, we have established a GitHub repository at https://github.com/csbl-br/awesome-compbio-chatgpt.","cats":{"new-dataset":0}}
{"text":"All data and trained models are publicly available.","cats":{"new-dataset":1}}
{"text":"We have conducted extensive experiments on 16 public log datasets.","cats":{"new-dataset":0}}
{"text":"We also release the code and the annotated dataset for replication and future research.","cats":{"new-dataset":1}}
{"text":"The training data for these models is usually collected from open-source repositories (e.g., GitHub) that contain software faults and security vulnerabilities.","cats":{"new-dataset":0}}
{"text":"CCUB dataset is curated and our approach is evaluated by people who have a personal relationship with that particular culture.","cats":{"new-dataset":1}}
{"text":"Project page: https://europe.naverlabs.com/imagenet-sd/","cats":{"new-dataset":0}}
{"text":"GitHub repository: https://github.com/ymcui/Chinese-LLaMA-Alpaca","cats":{"new-dataset":0}}
{"text":"The resulting \\textbf{C}hinese \\textbf{O}pen \\textbf{I}nstruction \\textbf{G}eneralist (\\textbf{COIG}) corpora are available in Huggingface\\footnote{\\url{https://huggingface.co/datasets/BAAI/COIG}} and Github\\footnote{\\url{https://github.com/FlagOpen/FlagInstruct}}, and will be continuously updated.","cats":{"new-dataset":1}}
{"text":"We make our model, data, as well as code publicly available.","cats":{"new-dataset":1}}
{"text":"The data, code, and all model outputs are released in https://github.com/microsoft/AGIEval.","cats":{"new-dataset":1}}
{"text":"We created a comprehensive dataset including 492.5K samples comprising code-related content produced by ChatGPT, encompassing popular software activities like Q&A (115K), code summarization (126K), and code generation (226.5K).","cats":{"new-dataset":1}}
{"text":"The code is publicly available at https://github.com/Vision-CAIR/ChatCaptioner","cats":{"new-dataset":1}}
{"text":"Among benchmarks, ChatGPT and GPT-4 do relatively well on well-known datasets like LogiQA and ReClor.","cats":{"new-dataset":1}}
{"text":"Our dataset and codes are available at https://github.com/XinhaoMei/WavCaps.","cats":{"new-dataset":1}}
{"text":"Our source code and datasets are available at https://github.com/xinleihe/MGTBench.","cats":{"new-dataset":1}}
{"text":"The training data, codes, and weights of this project are available at: The training data, codes, and weights of this project are available at: https://github.com/Kent0n-Li/ChatDoctor.","cats":{"new-dataset":0}}
{"text":"Codes and benchmarking data information are available at https://github.com/yhydhx/ChatGPT-API.","cats":{"new-dataset":0}}
{"text":"The dataset and code are available at https://github.com/tan92hl/Complex-Question-Answering-Evaluation-of-ChatGPT.","cats":{"new-dataset":1}}
{"text":"To support further research in related fields, we have made the data generated by ChatGPT publicly available at https://github.com/THU-BPM/chatgpt-sql.","cats":{"new-dataset":1}}
{"text":"In the second stage, we extrapolate the performance to larger undisclosed data sizes based on a novel parameter-free mapping technique inspired by neural scaling laws.","cats":{"new-dataset":0}}
{"text":"Also, <projektor> outperforms by a wide margin in data selection effectiveness compared to a range of other off-the-shelf solutions.","cats":{"new-dataset":0}}
{"text":"Database alignment is a variant of the graph alignment problem: Given a pair of anonymized databases containing separate yet correlated features for a set of users, the problem is to identify the correspondence between the features and align the anonymized user sets based on correlation alone.","cats":{"new-dataset":0}}
{"text":"We study an instance of the database alignment problem with multivariate Gaussian features and derive results that apply both for database alignment and for planted matching, demonstrating the connection between them.","cats":{"new-dataset":0}}
{"text":"The maximum likelihood algorithms for both planted matching and database alignment take the form of a linear program and we study relaxations to better understand the significance of various constraints under various conditions and present achievability and converse bounds.","cats":{"new-dataset":0}}
{"text":"Our analysis and results extend to the unbalanced case where one user set is not fully covered by the alignment.","cats":{"new-dataset":0}}
{"text":"They only work for in-distribution artifact types generated during training.","cats":{"new-dataset":0}}
{"text":"In this paper, we analyze the cause and characteristics of the GAN artifacts produced in unseen test data without ground-truths.","cats":{"new-dataset":0}}
{"text":"We then develop a novel method, namely, DeSRA, to Detect and then Delete those SR Artifacts in practice.","cats":{"new-dataset":0}}
{"text":"After detecting the artifact regions, we develop a finetune procedure to improve GAN-based SR models with a few samples, so that they can deal with similar types of artifacts in more unseen real data.","cats":{"new-dataset":0}}
{"text":"The code will be available at https://github.com/TencentARC/DeSRA.","cats":{"new-dataset":0}}
{"text":"In this work, we review robustness issues of DL and particularly bridge concerns and attempts from approximation theory to statistical learning theory.","cats":{"new-dataset":0}}
{"text":"Further, we review Bayesian Deep Learning as a means for uncertainty quantification and rigorous explainability.","cats":{"new-dataset":0}}
{"text":"A new control paradigm using angular momentum and foot placement as state variables in the linear inverted pendulum model has expanded the realm of possibilities for the control of bipedal robots.","cats":{"new-dataset":0}}
{"text":"This new paradigm, known as the ALIP model, has shown effectiveness in cases where a robot's center of mass height can be assumed to be constant or near constant as well as in cases where there are no non-kinematic restrictions on foot placement.","cats":{"new-dataset":0}}
{"text":"Our code is available at https://github.com/amazon-science/codetaskcl-pptf","cats":{"new-dataset":0}}
{"text":"We also show that it is possible to generate fully-synthetic image-annotation pairs to automatically augment any annotated dataset.","cats":{"new-dataset":0}}
{"text":"We present and release a new dataset of 50 manually annotated research articles.","cats":{"new-dataset":1}}
{"text":"The code and trained weights are available at https://github.com/mordecaimalignatius/GAFAR/.","cats":{"new-dataset":0}}
{"text":"We build on existing tools to computationally analyze data retrieved from publicly available databases.","cats":{"new-dataset":0}}
{"text":"Among multiple benchmarks on the KITTI dataset, we achieve new state-of-the-art performance.","cats":{"new-dataset":0}}
{"text":"Codes and models are publicly available at https://github.com/sunlicai/MAE-DFER.","cats":{"new-dataset":0}}
{"text":"We make the source code available for the 112,000 programs, accompanied by a comprehensive list detailing the vulnerabilities detected in each individual program including location and function name, which makes the dataset ideal to train LLMs and machine learning algorithms.","cats":{"new-dataset":1}}
{"text":"Our implementation will be publicly available at \\url{https://github.com/ETHRuiGong/PTDiffSeg}.","cats":{"new-dataset":0}}
{"text":"Our dataset covers 520 images of mathematical graphics collected from 450 documents from different disciplines.","cats":{"new-dataset":1}}
{"text":"The classification accuracy of the models in the absence and presence of the two attacks are computed on images from the publicly accessible ImageNet dataset.","cats":{"new-dataset":0}}
{"text":"Furthermore, it facilitates the creation of de-identified datasets for broader 2D image research at major research institutions.","cats":{"new-dataset":0}}
{"text":"State-of-the-art results are achieved even on more detailed part-segmentation, Pascal-Animals, by only training on coarse-grained datasets.","cats":{"new-dataset":0}}
{"text":"Our code will be available at the URL: https://github.com/cofly2014/tsa-mlt.git","cats":{"new-dataset":0}}
{"text":"KiTS21 is a sequel to its first edition in 2019, and it features a variety of innovations in how the challenge was designed, in addition to a larger dataset.","cats":{"new-dataset":1}}
{"text":"Additionally, we introduce Tomatopia, a new, large and challenging dataset of greenhouse tomatoes.","cats":{"new-dataset":1}}
{"text":"TGB datasets are of large scale, spanning years in duration, incorporate both node and edge-level prediction tasks and cover a diverse set of domains including social, trade, transaction, and transportation networks.","cats":{"new-dataset":0}}
{"text":"The code for this algorithm will be publicly available.","cats":{"new-dataset":0}}
{"text":"The code and models will be made publicly at \\href{https://github.com/LancasterLi/RefSAM}{github.com/LancasterLi/RefSAM}.","cats":{"new-dataset":0}}
{"text":"In the fields of Experimental and Computational Aesthetics, numerous image datasets have been created over the last two decades.","cats":{"new-dataset":0}}
{"text":"Our code is publicly available at https://github.com/withchencheng/ECML_PKDD_23_Real.","cats":{"new-dataset":0}}
{"text":"We share this visualization and the dataset in the spirit of open science.","cats":{"new-dataset":1}}
{"text":"covLLM was trained with LLaMA 7B as a baseline model to produce three models trained on (1) the Alpaca and synCovid datasets, (2) the synCovid dataset, and (3) the synCovid and real abstract datasets.","cats":{"new-dataset":0}}
{"text":"Results demonstrate that training covLLM on the synCovid and abstract pairs datasets performs competitively with ChatGPT and outperforms covLLM trained primarily using the Alpaca dataset.","cats":{"new-dataset":0}}
{"text":"Using the MIMIC-IT dataset, we train a large VLM named Otter.","cats":{"new-dataset":0}}
{"text":"The code will be made available.","cats":{"new-dataset":0}}
{"text":"Project page: https://ba2det.site .","cats":{"new-dataset":0}}
{"text":"This dataset allows for the exploration of complex road connections and situations where lane markings may be absent.","cats":{"new-dataset":1}}
{"text":"Specifically, we benchmark the recognition drop on common detection datasets, where we evaluate both traditional and realistic anonymization for faces and full bodies.","cats":{"new-dataset":0}}
{"text":"With this CNN, we derived homogeneous atmospheric parameters and abundances for 841300 stars, that remarkably compared to external data-sets.","cats":{"new-dataset":0}}
{"text":"The final trained model is publicly available at https://github.com/Jesper-Karsten/MBASC","cats":{"new-dataset":0}}
{"text":"All resources of PandaLM are released at https://github.com/WeOpenML/PandaLM.","cats":{"new-dataset":0}}
{"text":"In this paper, we propose a detector with the ability to predict both open-vocabulary objects and their part segmentation.","cats":{"new-dataset":0}}
{"text":"First, we train the detector on the joint of part-level, object-level and image-level data to build the multi-granularity alignment between language and image.","cats":{"new-dataset":0}}
{"text":"In light of this, the paper aims to analyze the measurement of the carbon footprint of 1,417 ML models and associated datasets on Hugging Face, which is the most popular repository for pretrained ML models.","cats":{"new-dataset":0}}
{"text":"Current methods rely on datasets with expensive annotations; multi-view images and their camera parameters.","cats":{"new-dataset":0}}
{"text":"The WHOW-KG consists of a network of five ontologies and related linked open data, modelled according to those ontologies.","cats":{"new-dataset":0}}
{"text":"We propose Multi-CrossRE, the broadest multi-lingual dataset for RE, including 26 languages in addition to English, and covering six text domains.","cats":{"new-dataset":1}}
{"text":"We run a baseline model over the 26 new datasets and--as sanity check--over the 26 back-translations to English.","cats":{"new-dataset":1}}
{"text":"We also evaluate performance on the MultiMedQA suite of benchmark datasets.","cats":{"new-dataset":0}}
{"text":"Our model and code are available at https://github.com/microsoft/LMOps.","cats":{"new-dataset":0}}
{"text":"To train and evaluate our approach, we curated InferredBugs, a novel, metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories.","cats":{"new-dataset":1}}
{"text":"We also release codebase for evaluation set extraction.","cats":{"new-dataset":0}}
{"text":"Dataset, to fight the bias prevalent in giant datasets.","cats":{"new-dataset":0}}
{"text":"We will make our code and pre-trained models publicly available.","cats":{"new-dataset":0}}
{"text":"We perform an extensive study across six datasets with eight models from three model families.","cats":{"new-dataset":0}}
{"text":"For this, we augment standard bug-fixing datasets with bug report discussions.","cats":{"new-dataset":0}}
{"text":"Resources are made publicly available through GitHub, fostering open research in the Chinese NLP community and beyond.","cats":{"new-dataset":0}}
{"text":"We release our code and data under fully permissive licenses.","cats":{"new-dataset":1}}
{"text":"For enabling the combination of ChatGPT and RDF KGs, we present a research prototype, called GPToLODS, which is able to enrich any ChatGPT response with more information from hundreds of RDF KGs.","cats":{"new-dataset":0}}
{"text":"In particular, it identifies and annotates each entity of the response with statistics and hyperlinks to LODsyndesis KG (which contains integrated data from 400 RDF KGs and over 412 million entities).","cats":{"new-dataset":0}}
{"text":"Numerous AIGC detectors have been developed and evaluated on natural language data.","cats":{"new-dataset":0}}
{"text":"We evaluated six AIGC detectors, including three commercial and three open-source solutions, assessing their performance on this dataset.","cats":{"new-dataset":0}}
{"text":"We have released a dataset comprised of ChatGPT's responses to support further research in this area.","cats":{"new-dataset":1}}
{"text":"Both datasets involve scraping through known data sources (through platforms like stack overflow, crowdsourcing, etc.)","cats":{"new-dataset":0}}
{"text":"We call the collected dataset the Human ChatGPT Comparison Corpus (HC3).","cats":{"new-dataset":1}}
{"text":"The dataset, code, and models are all publicly available at https://github.com/Hello-SimpleAI/chatgpt-comparison-detection.","cats":{"new-dataset":1}}
{"text":"For datasets originally without shared tokens in label names, we also offer an automated method, using OpenAI's ChatGPT, to generate shared actions and objects.","cats":{"new-dataset":0}}
{"text":"We make our code, models, and datasets publicly available.","cats":{"new-dataset":1}}
{"text":"The source code will be released publicly.","cats":{"new-dataset":0}}
{"text":"We evaluate PaTeCon on two large-scale datasets based on Wikidata and Freebase respectively.","cats":{"new-dataset":0}}
{"text":"We present a novel synthetic dataset, named Parcel3D, that is based on the Google Scanned Objects (GSO) dataset and consists of more than 13,000 images of parcels with full 3D annotations.","cats":{"new-dataset":1}}
{"text":"The dataset contains intact, i.e. cuboid-shaped, parcels and damaged parcels, which were generated in simulations.","cats":{"new-dataset":1}}
{"text":"Dataset and code are available at https://a-nau.github.io/parcel3d.","cats":{"new-dataset":1}}
{"text":"Datasets, code and results are made publicly available and will be continuously updated at https://github.com/ZhaomingKong/Denoising-Comparison.","cats":{"new-dataset":1}}
{"text":"Specifically, we collect a dataset of e-textbooks from one of the largest free online publishers in the world.","cats":{"new-dataset":1}}
{"text":"The dataset and data analysis scripts are available on our open-source repository.","cats":{"new-dataset":1}}
{"text":"To facilitate progress in this field, we have developed a well-labeled road pothole dataset named Urban Digital Twins Intelligent Road Inspection (UDTIRI) dataset.","cats":{"new-dataset":1}}
{"text":"Our intention is to employ this dataset for object detection, semantic segmentation, and instance segmentation tasks.","cats":{"new-dataset":1}}
{"text":"The source code and the proposed dataset are publicly available at https://github.com/fh2019ustc/DocTr-Plus.","cats":{"new-dataset":1}}
{"text":"Hence, we present a dataset that exclusively consists of healthy and diseased cashew leaves and fruits.","cats":{"new-dataset":1}}
{"text":"The entire code and models will be open-sourced.","cats":{"new-dataset":0}}
{"text":"With nationwide coverage, real-world network topology, and rich geospatial features, this data repository can be used for a variety of traffic-related tasks.","cats":{"new-dataset":0}}
{"text":"The data and code are available on GitHub (https://github.com/baixianghuang/travel).","cats":{"new-dataset":1}}
{"text":"Code and models will be accessed at https://github.com/Liuxinyv/SAZS.","cats":{"new-dataset":0}}
{"text":"BenchMD combines 19 publicly available datasets for 7 medical modalities, including 1D sensor data, 2D images, and 3D volumetric scans.","cats":{"new-dataset":0}}
{"text":"We introduce the LongForm dataset, which is created by leveraging English corpus examples with augmented instructions.","cats":{"new-dataset":1}}
{"text":"We publicly release our data and models: https://github.com/akoksal/LongForm.","cats":{"new-dataset":1}}
{"text":"Code is generated using a commercial tool, SonarCloud.","cats":{"new-dataset":0}}
{"text":"Our source code will be available at https://github.com/MC-E/DragonDiffusion.","cats":{"new-dataset":0}}
{"text":"An open-source implementation is available online.","cats":{"new-dataset":0}}
{"text":"Deep-learning-based object detection and semantic segmentation models have proven to be suitable for this purpose.","cats":{"new-dataset":0}}
{"text":"We evaluate the effectiveness of this approach by training a semantic segmentation model on a real dataset augmented in two ways: 1) using synthetic images obtained from real masks, and 2) generating images from synthetic semantic masks.","cats":{"new-dataset":0}}
{"text":"The dataset spans seven sub-topics and is annotated with a materials-science focused multi-label annotation scheme for AZ.","cats":{"new-dataset":0}}
{"text":"The code is available at \\url{https://github.com/cjw2021/SOV-STG}.","cats":{"new-dataset":0}}
{"text":"The code and pretrained models will be released under https://github.com/lik1996/iCMFormer.","cats":{"new-dataset":0}}
{"text":"The data samples are automatically generated from a curated set of reasoning patterns, where the patterns are annotated with inference labels by experts.","cats":{"new-dataset":0}}
{"text":"The data is obtained from a fleet of gas sensors that measure and track quantities such as oxygen and sound.","cats":{"new-dataset":1}}
{"text":"With the help of this data, we can detect events such as occupancy in a specific environment.","cats":{"new-dataset":0}}
{"text":"Extensive experiments and visualizations on four datasets demonstrate the powerful performance of our method.","cats":{"new-dataset":0}}
{"text":"Codes will be available.","cats":{"new-dataset":0}}
{"text":"Extensive evaluation on three benchmark datasets using multiple evaluation metrics show the effectiveness of the proposed framework.","cats":{"new-dataset":0}}
{"text":"Every program is labeled with the vulnerabilities found within the source code, indicating the type, line number, and vulnerable function name.","cats":{"new-dataset":0}}
{"text":"This property of the dataset makes it suitable for evaluating the effectiveness of various static and dynamic analysis tools.","cats":{"new-dataset":0}}
{"text":"While prior research demonstrated the high performance of ChatGPT across numerous NLP tasks, open-source LLMs like HugginChat and FLAN are gaining attention for their cost-effectiveness, transparency, reproducibility, and superior data protection.","cats":{"new-dataset":0}}
{"text":"With extensive experiments on a large-scale real-world dataset, we demonstrate the substantial effectiveness of our approach.","cats":{"new-dataset":0}}
{"text":"In the query-based FL platform, which is an open model sharing and reusing platform empowered by the community for model mining, we explore a wide range of valuable topics, including the availability of up-to-date model repositories for model querying, legal compliance analysis between different model licenses, and copyright issues and intellectual property protection in model reusing.","cats":{"new-dataset":0}}
{"text":"However, little is known about how much training data they require, and how this number depends on the data structure.","cats":{"new-dataset":0}}
{"text":"Our code is available at https://github.com/siyi-wind/MDViT.","cats":{"new-dataset":0}}
{"text":"Along with the datasets, we also propose corresponding baseline solutions to the three aforementioned tasks.","cats":{"new-dataset":1}}
{"text":"These attacks are launched on three powerful pre-trained image classifier architectures, ResNet-34, GoogleNet, and DenseNet-161.","cats":{"new-dataset":0}}
{"text":"This dataset comprises a large number of tasks that demand problem-solving skills.","cats":{"new-dataset":1}}
{"text":"The implementation of CAME is publicly available.","cats":{"new-dataset":0}}
{"text":"However, due to privacy restrictions, few public real-world VFL datasets exist for algorithm evaluation, and these represent a limited array of feature distributions.","cats":{"new-dataset":0}}
{"text":"Additionally, we introduce a real VFL dataset to address the deficit in image-image VFL scenarios.","cats":{"new-dataset":1}}
{"text":"In this paper, we introduce ScalOTA, an end-to-end scalable OTA software update architecture and secure protocol for modern vehicles.","cats":{"new-dataset":0}}
{"text":"Our code is available at https://github.com/yuping-wu/PULSAR.","cats":{"new-dataset":0}}
{"text":"On both \\pascal and \\coco datasets, we conduct extensive experiments to evaluate the framework effectiveness.","cats":{"new-dataset":0}}
{"text":"Our source code and the related paper list are available on https://github.com/SLDGroup/survey-zero-shot-nas.","cats":{"new-dataset":0}}
{"text":"Extensive experiments show our method achieves state-of-the-art results on the HMDB51 and UCF101 datasets and a competitive result on the benchmark of Kinetics and something-2-something V2 datasets.","cats":{"new-dataset":0}}
{"text":"Experimental results on real-world datasets demonstrate that our method achieves better performance compared with several state-of-the-art social bot detection methods.","cats":{"new-dataset":0}}
{"text":"However, due to the challenges in data collection and network designs, it remains challenging for existing solutions to achieve real-time full-body capture while being accurate in world space.","cats":{"new-dataset":0}}
{"text":"In this work, we contribute a sequential proxy-to-motion learning scheme together with a proxy dataset of 2D skeleton sequences and 3D rotational motions in world space.","cats":{"new-dataset":0}}
{"text":"More video results can be found at our project page: https://liuyebin.com/proxycap.","cats":{"new-dataset":0}}
{"text":"In this technical report, we take an initiative to investigate their capacities of playing text games, in which a player has to understand the environment and respond to situations by having dialogues with the game world.","cats":{"new-dataset":1}}
{"text":"We address this issue by introducing a new dataset: GHOSTS.","cats":{"new-dataset":1}}
{"text":"This paper also contributes a new surveillance dataset called NightSuR.","cats":{"new-dataset":1}}
{"text":"We present in this work a new Universal Morphology dataset for Korean.","cats":{"new-dataset":1}}
{"text":"The PIKS technique is scalable and can readily ingest new datasets.","cats":{"new-dataset":0}}
{"text":"Datasets that reflect the diverse array of multimodal, multilingual news sources available online could be used to teach models to benefit from this shift, but existing news video datasets focus on traditional news broadcasts produced for English-speaking audiences.","cats":{"new-dataset":0}}
{"text":"The MIND dataset is at the moment of writing the most extensive dataset available for the research and development of news recommender systems.","cats":{"new-dataset":1}}
{"text":"We also introduce a new dataset generated by our classifier that tracks the dynamics of fake news in the Chinese language during the early pandemic.","cats":{"new-dataset":1}}
{"text":"Our code and data will be released shortly.","cats":{"new-dataset":0}}
{"text":"This paper introduces a novel dataset","cats":{"new-dataset":1}}
{"text":"We present a unique collection of data","cats":{"new-dataset":1}}
{"text":"In this study, we unveil our newly created dataset","cats":{"new-dataset":1}}
{"text":"This article brings to light a freshly curated dataset","cats":{"new-dataset":1}}
{"text":"We reveal an unprecedented dataset in the field of","cats":{"new-dataset":1}}
{"text":"In this work, we propose a pioneering dataset","cats":{"new-dataset":1}}
{"text":"This research details the compilation of a new dataset","cats":{"new-dataset":1}}
{"text":"Our article describes a groundbreaking data collection","cats":{"new-dataset":1}}
{"text":"We are pleased to introduce an innovative dataset","cats":{"new-dataset":1}}
{"text":"This publication centers around our newly assembled dataset","cats":{"new-dataset":1}}
{"text":"Herein, we unfold a freshly minted dataset","cats":{"new-dataset":1}}
{"text":"Our research entails the design and creation of a new dataset","cats":{"new-dataset":1}}
{"text":"The crux of this paper is the disclosure of a new dataset","cats":{"new-dataset":1}}
{"text":"This manuscript details the formulation of a novel data assembly","cats":{"new-dataset":1}}
{"text":"We exhibit an inventive dataset for the first time in this paper","cats":{"new-dataset":1}}
{"text":"We present an exploratory dataset in this research","cats":{"new-dataset":1}}
{"text":"This paper features the unveiling of a hitherto unseen dataset","cats":{"new-dataset":1}}
{"text":"In the present study, we showcase an original data compilation","cats":{"new-dataset":1}}
{"text":"Our work represents the first public exhibition of a unique dataset","cats":{"new-dataset":1}}
{"text":"We draw back the curtains on a state-of-the-art dataset in this research","cats":{"new-dataset":1}}
{"text":"We will release our dataset and code for future research.","cats":{"new-dataset":0}}
{"text":"The real-world datasets will be released.","cats":{"new-dataset":1}}
{"text":"In an effort to accelerate this research and assist others, we are releasing our dataset and model to the research community.","cats":{"new-dataset":0}}
{"text":"To promote progress towards this goal, we release OBJECT: a dataset consisting of 400K editing examples created from procedurally generated 3D scenes.","cats":{"new-dataset":1}}
{"text":"This article presents DataXploreFines, an innovative Shiny application that revolutionizes data exploration, analysis, and visualization.","cats":{"new-dataset":0}}
{"text":"Users can upload their datasets in popular formats like CSV or Excel, explore the data structure, perform manipulations, and obtain statistical summaries.","cats":{"new-dataset":0}}
{"text":"DataXploreFines provides a wide range of interactive visualizations, including histograms, scatter plots, bar charts, and line graphs, enabling users to identify patterns and trends.","cats":{"new-dataset":0}}
{"text":"Experimental results demonstrate that our proposed approach outperforms the state-of-the-art methods on fine-grained datasets under real-world scenarios.","cats":{"new-dataset":0}}
{"text":"We evaluate our method on two real-world clinical datasets, where the time series contains sequences of (1) high-frequency electrocardiograms and (2) structured data from lab values and vitals signs.","cats":{"new-dataset":0}}
{"text":"Substantial progress has been made recently in motion data collection technologies and generation methods, laying the foundation for increasing interest in human motion generation.","cats":{"new-dataset":0}}
{"text":"Additionally, we provide an overview of common datasets and evaluation metrics.","cats":{"new-dataset":0}}
{"text":"For Amharic, we use our own publicly-available Amharic Speech Emotion Dataset (ASED).","cats":{"new-dataset":0}}
{"text":"For English, German and Urdu we use the existing RAVDESS, EMO-DB and URDU datasets.","cats":{"new-dataset":0}}
{"text":"Our dataset is available at https://github.com/iamazxl/OAVQA.","cats":{"new-dataset":0}}
{"text":"Concretely, we first summarize the widely-used ST ocean datasets and identify their unique characteristics.","cats":{"new-dataset":0}}
{"text":"In this paper, we first design various synthetic datasets with custom hardness and noisiness levels for different samples.","cats":{"new-dataset":0}}
{"text":"To address this, we propose a large-scale SlowTV dataset curated from YouTube, containing an order of magnitude more data than existing automotive datasets.","cats":{"new-dataset":1}}
{"text":"13k sentence pairs) and a web-domain corpus (approx.","cats":{"new-dataset":1}}
{"text":"We release the resulting corpus and our analysis pipeline for future research.","cats":{"new-dataset":1}}
{"text":"The corpora have been annotated with dependency trees, lemmas, and part-of-speech tags.","cats":{"new-dataset":1}}
{"text":"Therefore, we propose that LLM-assisted annotation is a promising automated approach for corpus studies.","cats":{"new-dataset":0}}
{"text":"In this study, we explore the potential of LLMs in assisting corpus-based linguistic studies through automatic annotation of texts with specific categories of linguistic information.","cats":{"new-dataset":0}}
{"text":"This article proposes a new training model to solve this problem through NLP processing methods.","cats":{"new-dataset":0}}
{"text":"We also develop tools for automatic extraction of task instances given a constraint structure and a raw text corpus.","cats":{"new-dataset":0}}
{"text":"Starting with an initial text corpus, our framework employs a large language model to select multiple sentences that describe the same scene from various perspectives.","cats":{"new-dataset":0}}
{"text":"Experimental results on multiple benchmark datasets demonstrate the effectiveness of our method.","cats":{"new-dataset":0}}
{"text":"Our proposed methods achieve state-of-the-art results on three popular benchmark datasets, and the source code will be made publicly available shortly.","cats":{"new-dataset":0}}
{"text":"We perform an exhaustive evaluation in two benchmark datasets.","cats":{"new-dataset":0}}
{"text":"We conduct experiments on two benchmark datasets.","cats":{"new-dataset":0}}
{"text":"Extensive experiments conducted on two benchmark datasets show that our approach achieves excellent performance compared to its competitors.","cats":{"new-dataset":0}}
{"text":"The proposed model is validated through extensive experiments on two benchmark datasets, showcasing superior performance compared to existing methods.","cats":{"new-dataset":0}}
{"text":"With the above tasks, we benchmark a range of algorithms on our proposed dataset, drawing new insights for further research and practice.","cats":{"new-dataset":1}}
{"text":"Experimental results indicate that the proposed approach can obtain better performance on benchmark datasets compared with baselines.","cats":{"new-dataset":0}}
{"text":"We validate our scheme with some of the most popular benchmarking datasets.","cats":{"new-dataset":0}}
{"text":"Method: We present an evaluation of five open-source and four proprietary tools against a benchmark dataset.","cats":{"new-dataset":0}}
{"text":"To testify the effectiveness and superiority of the proposed approach, we conduct extensive experiments on benchmark datasets.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"We also introduce a new dataset for benchmarking, and the evaluations are performed from four different perspectives including quantitative metrics, visual effects, human ratings and computational cost.","cats":{"new-dataset":1}}
{"text":"Our method is simple yet it outperforms several state-of-the-art methods on six popular dataset benchmarks.","cats":{"new-dataset":0}}
{"text":"Finally, we conduct extensive experiments on widely-used benchmark datasets to validate the superiority of our method by comparing it with existing state-of-the-art methods.","cats":{"new-dataset":0}}
{"text":"We validate the model both qualitatively and quantitatively on four benchmark datasets.","cats":{"new-dataset":0}}
{"text":"Finally, I provide the first high-quality benchmark dataset in order to fairly compare existing models and aid future model developers.","cats":{"new-dataset":0}}
{"text":"Finally, we applied our method on two benchmark datasets, STACOM2018, and M\\&Ms 2020 challenges, to show the potency of the proposed model.","cats":{"new-dataset":0}}
{"text":"Extensive experiments on several benchmark datasets show that our method outperforms existing methods across all datasets while maintaining low computational complexity.","cats":{"new-dataset":0}}
{"text":"Our data and benchmarking results are available at: https://lmexam.com.","cats":{"new-dataset":0}}
{"text":"Empirically, we conduct extensive experiments on several benchmark datasets to support our theory.","cats":{"new-dataset":0}}
{"text":"Extensive experiments are conducted on multiple benchmark data sets and our method establishes a state-of-the-art performance in terms of both performance and trustworthiness.","cats":{"new-dataset":0}}
{"text":"We evaluate our model on four datasets and achieve state-of-the-art performances.","cats":{"new-dataset":0}}
{"text":"Experimental results demonstrate the performance and limitations of existing algorithms, and the dataset benchmark has good versatility and effectiveness.","cats":{"new-dataset":0}}
{"text":"Our extensive experiments on three benchmarks, Lucchi, MitoEM-R and MitoEM-H, reveal the benefits of the proposed contributions achieving state-of-the-art results on all three datasets.","cats":{"new-dataset":0}}
{"text":"We test our method on two public datasets, our method achieves the best performances on these two datasets.","cats":{"new-dataset":0}}
{"text":"Finally, the experimental results on several benchmark datasets verify the effectiveness of the proposed method.","cats":{"new-dataset":0}}
{"text":"Extensive experiments on two real-world datasets show the superior performance of our method.","cats":{"new-dataset":0}}
{"text":"We have evaluated various baselines on this dataset and benchmarked it with a new neural model, SPOT, which we introduce in this paper.","cats":{"new-dataset":0}}
{"text":"The benchmark dataset, leaderboard, and baseline methods are released in https://github.com/THU-KEG/KoRC.","cats":{"new-dataset":1}}
{"text":"Experimental results on real-world and benchmark datasets validate the effectiveness of the proposed method.","cats":{"new-dataset":0}}
{"text":"Our results improve the state-of-the-art on standard benchmarks.","cats":{"new-dataset":0}}
{"text":"Experimental evaluations both on our assembled dataset and public benchmark datasets demonstrate the effectiveness of our proposed network.","cats":{"new-dataset":0}}
{"text":"Our results show that our simple synthetic datasets are sufficient to challenge most of the benchmarked methods.","cats":{"new-dataset":1}}
{"text":"Additionally, we introduce a novel benchmark based on images from the Open Images Dataset.","cats":{"new-dataset":0}}
{"text":"As a result, our method TOLD achieves a DER of 10.14% on the CALLHOME dataset, which is a new state-of-the-art result on this benchmark to the best of our knowledge.","cats":{"new-dataset":0}}
{"text":"We conducted comprehensive experiments on multiple benchmark datasets, demonstrating the superior performance of our proposed SPIFFNet in terms of both quantitative metrics and visual quality when compared to state-of-the-art methods.","cats":{"new-dataset":0}}
{"text":"We provide a detailed analysis of the dataset.","cats":{"new-dataset":0}}
{"text":"We evaluate our method on three challenging datasets.","cats":{"new-dataset":0}}
{"text":"The benchmark results produced by three different deep learning methods are provided.","cats":{"new-dataset":0}}
{"text":"In addition, we provide extra annotations for used datasets and introduce our new benchmark.","cats":{"new-dataset":1}}
{"text":"Experimental results on two real-world datasets demonstrate that our method outperforms some state-of-the-art approaches.","cats":{"new-dataset":0}}
{"text":"Experiments on real-world datasets demonstrate the effectiveness of our approach.","cats":{"new-dataset":0}}
{"text":"The extensive experiments demonstrated that our proposed method achieves state-of-the-art performance on the newly collected dataset.","cats":{"new-dataset":1}}
{"text":"We evaluate our method on several datasets and demonstrate its superior performance under heavily occluded scenarios compared to other methods.","cats":{"new-dataset":0}}
{"text":"The dataset and source code will be released on GitHub soon.","cats":{"new-dataset":0}}
{"text":"Then this model is trained and evaluated on the new, more extensive dataset to obtain a representative result.","cats":{"new-dataset":0}}
{"text":"Results show that the performance significantly increases with the dataset size.","cats":{"new-dataset":0}}
{"text":"Details are available in CSV files provided with the datasets.   ","cats":{"new-dataset":1}}
{"text":"Since the manual creation of such datasets is a laborious task, obtaining data from online resources can be a cheap solution to create large-scale datasets.","cats":{"new-dataset":0}}
{"text":"Data format and usage notes:","cats":{"new-dataset":0}}
{"text":"However, online companies also gather user data for more principled purposes, such as improving the user experience and aggregating statistics.","cats":{"new-dataset":0}}
{"text":"Finally, we provide publicly an open dataset, and online resources with the results.","cats":{"new-dataset":1}}
{"text":"Besides the traditional data, various types of data, including video, have become available.","cats":{"new-dataset":0}}
{"text":"Besides, with such an instruction, we can also easily carry out quantitative statistics.","cats":{"new-dataset":0}}
{"text":"Moreover, limitations related to data sources that change over time (e.g., code bases) and the lack of documentation of extraction processes make it difficult to reproduce datasets over time.","cats":{"new-dataset":0}}
{"text":"Evaluation datasets and frameworks like the one we present support this line of research.","cats":{"new-dataset":0}}
{"text":"We then review available datasets, recent approaches and evaluation metrics of the task.","cats":{"new-dataset":0}}
{"text":"Besides, our extensive analyses verify the high quality of our dataset and the effectiveness of our evaluation metrics.","cats":{"new-dataset":1}}
{"text":"However, we identify issues with the dataset quality and evaluation metric.","cats":{"new-dataset":0,"data-quality":1}}
{"text":"In order to obtain meaningful results, careful partitioning of data into training, validation, and test sets, as well as the selection of suitable evaluation metrics are crucial.","cats":{"new-dataset":0}}
{"text":"To evaluate and benchmark the models, we propose a comprehensive evaluation scheme (including automatic and manual metrics).","cats":{"new-dataset":0}}
{"text":"These metrics have been successful on datasets that leverage the average human perception in limited settings.","cats":{"new-dataset":0}}
{"text":"We use standard metrics to evaluate the performances of the different training scenarios.","cats":{"new-dataset":0}}
{"text":"Finally, we report extensive experiments on two real-world datasets to offer insight into the efficiency, scalability, and effectiveness of the proposed framework.","cats":{"new-dataset":0}}
{"text":"We focus especially on Task-C and propose a novel LLMs cooperation system named a doctor-patient loop to generate high-quality conversation data sets.","cats":{"new-dataset":1}}
{"text":"This analysis also investigates the potential of utilizing cooperation LLMs to generate high-quality datasets.","cats":{"new-dataset":0}}
{"text":"This paper presents UMASS_BioNLP team participation in the MEDIQA-Chat 2023 shared task for Task-A and Task-C.  ","cats":{"new-dataset":0}}
{"text":"The experiment results demonstrate that our approaches yield reasonable performance as evaluated by automatic metrics such as ROUGE, medical concept recall, BLEU, and Self-BLEU.","cats":{"new-dataset":0}}
{"text":"Furthermore, we conducted a comparative analysis between our proposed method and ChatGPT and GPT-4.","cats":{"new-dataset":0}}
{"text":"We present working notes on transfer learning with semi-supervised dataset annotation for the BirdCLEF 2023 competition, focused on identifying African bird species in recorded soundscapes","cats":{"new-dataset":1}}
{"text":"We explore the embedding space learned by BirdNET and propose a process to derive an annotated dataset for supervised learning","cats":{"new-dataset":1}}
{"text":"Our approach utilizes existing off-the-shelf models, BirdNET and MixIT, to address representation and labeling challenges in the competition.","cats":{"new-dataset":0}}
{"text":"We explore the embedding space learned by BirdNET and propose a process to derive an annotated dataset for supervised learning.","cats":{"new-dataset":0}}
{"text":"Our experiments involve various models and feature engineerih in classifying bird species and highlight the potential of transfer learning and semi-supervised dataset annotation in similar tasks.","cats":{"new-dataset":0}}
{"text":"Our data generator is capable of generating large-scale datasets of human activities","cats":{"new-dataset":1}}
{"text":"We release M3Act3D, an 87.6-hour 3D motion dataset of human activities with larger group sizes and higher complexity of inter-person interactions than previous multi-person datasets","cats":{"new-dataset":1}}
{"text":"The understanding of complex human interactions and group activities has garnered attention in human-centric computer vision.","cats":{"new-dataset":0}}
{"text":"However, the advancement of the related tasks is hindered due to the difficulty of obtaining large-scale labeled real-world datasets.","cats":{"new-dataset":0}}
{"text":"To mitigate the issue, we propose M3Act, a multi-view multi-group multi-person human atomic action and group activity data generator.","cats":{"new-dataset":0}}
{"text":"Powered by the Unity engine, M3Act contains simulation-ready 3D scenes and human assets, configurable lighting and camera systems, highly parameterized modular group activities, and a large degree of domain randomization during the data generation process.  ","cats":{"new-dataset":0}}
{"text":"with multiple viewpoints, modalities (RGB images, 2D poses, 3D motions), and high-quality annotations for individual persons and multi-person groups (2D bounding boxes, instance segmentation masks, individual actions and group activity categories).","cats":{"new-dataset":0}}
{"text":"Using M3Act, we perform synthetic data pre-training for 2D skeleton-based group activity recognition and RGB-based multi-person pose tracking.","cats":{"new-dataset":0}}
{"text":"The results indicate that learning from our synthetic datasets largely improves the model performances on real-world datasets, with the highest gain of 5.59% and 7.32% respectively in group and person recognition accuracy on CAD2, as well as an improvement of 6.63 in MOTP on HiEve.","cats":{"new-dataset":0}}
{"text":"Pre-training with our synthetic data also leads to faster model convergence on downstream tasks (up to 6.8% faster).","cats":{"new-dataset":0}}
{"text":"Moreover, M3Act opens new research problems for 3D group activity generation.","cats":{"new-dataset":0}}
{"text":"We release M3Act3D, an 87.6-hour 3D motion dataset of human activities with larger g","cats":{"new-dataset":0}}
{"text":"Large language models typically undergo two training stages, pretraining and finetuning.","cats":{"new-dataset":0}}
{"text":"Despite that large-scale pretraining endows the model with strong capabilities to generate natural language responses, these pretrained models can still fail to understand human instructions at times.","cats":{"new-dataset":0}}
{"text":"To enhance language models' ability of interpreting and responding to instructions, instruction finetuning has emerged as a critical method in this area.","cats":{"new-dataset":0}}
{"text":"Recent studies found that large language models can be finetuned to perform well even with a small amount of high-quality instruction-following data.","cats":{"new-dataset":0}}
{"text":"However, the selection of high-quality datasets for finetuning language models still lacks clear guidelines to follow.","cats":{"new-dataset":0}}
{"text":"In this paper, we propose InstructMining, a linear rule for evaluating instruction-following data quality.","cats":{"new-dataset":0}}
{"text":"We formulate InstructMining using specific natural language indicators.","cats":{"new-dataset":0}}
{"text":"To investigate the relationship between data quality and these indicators, we further conduct extensive finetuning experiments.","cats":{"new-dataset":0}}
{"text":"The experiment results are then applied to estimating parameters in InstructMining.","cats":{"new-dataset":0}}
{"text":"To further investigate its performance, we use InstructMining to select high-quality data from unseen datasets.","cats":{"new-dataset":0}}
{"text":"Results demonstrate that InstructMining can help select relatively high-quality samples from various instruction-following datasets.","cats":{"new-dataset":0}}
{"text":"Compared to models finetuned on unfiltered datasets, models finetuned on InstructMining selected datasets perform better on 42.5% cases.","cats":{"new-dataset":0}}
{"text":"Therefore, we introduce the Infrastructural Multi-Person Trajectory and Context Dataset (IMPTC).","cats":{"new-dataset":1}}
{"text":"The resulting dataset consists of eight hours of measurement data","cats":{"new-dataset":1}}
{"text":"In addition, to enable the entire stack of research capabilities, the dataset includes all data, starting from the sensor-, calibration- and detection data until trajectory and context data.","cats":{"new-dataset":1}}
{"text":"The dataset is continuously expanded and is available online for non-commercial research at https://github.com/kav-institute/imptc-dataset.","cats":{"new-dataset":1}}
{"text":"Inner-city intersections are among the most critical traffic areas for injury and fatal accidents.","cats":{"new-dataset":0}}
{"text":"Automated vehicles struggle with the complex and hectic everyday life within those areas.","cats":{"new-dataset":0}}
{"text":"Sensor-equipped smart infrastructures, which can cooperate with vehicles, can benefit automated traffic by extending the perception capabilities of drivers and vehicle perception systems.","cats":{"new-dataset":0}}
{"text":"Additionally, they offer the opportunity to gather reproducible and precise data of a holistic scene understanding, including context information as a basis for training algorithms for various applications in automated traffic.  ","cats":{"new-dataset":0}}
{"text":"We use an intelligent public inner-city intersection in Germany with visual sensor technology.","cats":{"new-dataset":0}}
{"text":"A multi-view camera and LiDAR system perceives traffic situations and road users' behavior.","cats":{"new-dataset":0}}
{"text":"Additional sensors monitor contextual information like weather, lighting, and traffic light signal status.","cats":{"new-dataset":0}}
{"text":"The data acquisition system focuses on Vulnerable Road Users (VRUs) and multi-agent interaction.","cats":{"new-dataset":0}}
{"text":"The resulting dataset consists of eight hours of measurement data.","cats":{"new-dataset":0}}
{"text":"It contains over 2,500 VRU trrollers, and wheelchair users, and over 20,000 vehicle trajectories at different day times, weather conditions, and seasons.","cats":{"new-dataset":0}}
{"text":"In addition, to enable the entire stack of research capabilities, the dataset includes all data, starting from the sensor-, calibration- and detection data until","cats":{"new-dataset":0}}
{"text":"Noisy label problems are inevitably in existence within medical image segmentation causing severe performance degradation.","cats":{"new-dataset":0}}
{"text":"Previous segmentation methods for noisy label problems only utilize a single image while the potential of leveraging the correlation between images has been overlooked.","cats":{"new-dataset":0,"data-quality":1}}
{"text":"Especially for video segmentation, adjacent frames contain rich contextual information beneficial in cognizing noisy labels.","cats":{"new-dataset":0}}
{"text":"Based on two insights, we propose a Multi-Scale Temporal Feature Affinity Learning (MS-TFAL) framework to resolve noisy-labeled medical video segmentation issues.","cats":{"new-dataset":0}}
{"text":"First, we argue the sequential prior of videos is an effective reference, i.e., pixel-level features from adjacent frames are close in distance for the same class and far in distance otherwise.","cats":{"new-dataset":0}}
{"text":"Therefore, Temporal Feature Affinity Learning (TFAL) is devised to indicate possible noisy labels by evaluating the affinity between pixels in two adjacent frames.","cats":{"new-dataset":0}}
{"text":"We also notice that the noise distribution exhibits considerable variations across video, image, and pixel levels.","cats":{"new-dataset":0}}
{"text":"In this way, we introduce Multi-Scale Supervision (MSS) to supervise the network from three different perspectives by re-weighting and refining the samples.","cats":{"new-dataset":0}}
{"text":"This design enables the network to concentrate on clean samples in a coarse-to-fine manner.","cats":{"new-dataset":0}}
{"text":"Experiments with both synthetic and real-world label noise demonstrate that our method outperforms recent state-of-the-art robust segmentation approaches.","cats":{"new-dataset":0,"data-quality":1}}
{"text":"Code is available at https://github.com/BeileiCui/MS-TFAL.","cats":{"new-dataset":0}}
{"text":"This paper proposes a data-efficient detection method for deep neural networks against backdoor attacks under a black-box scenario.","cats":{"new-dataset":0,"ml-security":1}}
{"text":"The proposed approach is motivated by the intuition that features corresponding to triggers have a higher influence in determining the backdoored network output than any other benign features.","cats":{"new-dataset":0,"ml-security":1}}
{"text":"To quantitatively measure the effects of triggers and benign features on determining the backdoored network output, we introduce five metrics.","cats":{"new-dataset":0}}
{"text":"To calculate the five-metric values for a given input, we first generate several synthetic samples by injecting the input's partial contents into clean validation samples.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"Then, the five metrics are computed by using the output labels of the corresponding synthetic samples.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"One contribution of this work is the use of a tiny clean validation dataset.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"Having the computed five metrics, five novelty detectors are trained from the validation dataset.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"A meta novelty detector fuses the output of the five trained novelty detectors to generate a meta confidence score.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"During online testing, our method determines if online samples are poisoned or not via assessing their meta confidence scores output by the meta novelty detector.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"We show the efficacy of our methodology through a broad range of backdoor attacks, including ablation studies and comparison to existing approaches.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"Our methodology is promising since the proposed five metrics quantify the inherent differences between clean and poisoned samples.","cats":{"new-dataset":0,"ml-security":0}}
{"text":"Additionally, our detection method can be incrementally improved by appending more metrics that may be proposed to address future advanced attacks.","cats":{"new-dataset":0,"ml-security":1}}
{"text":"To address this limitation, we have developed a synthetic dataset for short-term trajectory prediction tasks using the CARLA simulator.","cats":{"new-dataset":1}}
{"text":"This dataset is extensive and incorporates what is considered complex scenarios - pedestrians crossing the road, vehicles overtaking - and comprises 6000 perspective view images with corresponding IMU and odometry information for each frame.","cats":{"new-dataset":1}}
{"text":"Our datasets are publicly available on https://github.com/navigatinguncertainty.","cats":{"new-dataset":0}}
{"text":"Autonomous vehicles require accurate and reliable short-term trajectory predictions for safe and efficient driving.","cats":{"new-dataset":0}}
{"text":"While most commercial automated vehicles currently use state machine-based algorithms for trajectory forecasting, recent efforts have focused on end-to-end data-driven systems.","cats":{"new-dataset":0}}
{"text":"Often, the design of these models is limited by the availability of datasets, which are typically restricted to generic scenarios.  ","cats":{"new-dataset":0}}
{"text":"This dataset is extensive and incorporates what is considered complex scenarios - pedestrians crossing the road, vehicles overtaking -  (LSTM) networks has also been developed.","cats":{"new-dataset":0}}
{"text":"This model can handle corner cases, such as slowing down near zebra crossings and stopping when pedestrians cross the road, without the need for explicit encoding of the surrounding environment.","cats":{"new-dataset":0}}
{"text":"Prompt-tuning has become an increasingly popular parameter-efficient method for adapting large pretrained language models to downstream tasks.","cats":{"new-dataset":0}}
{"text":"However, both discrete prompting and continuous prompting assume fixed prompts for all data samples within a task, neglecting the fact that inputs vary greatly in some tasks such as open-domain dialogue generation.","cats":{"new-dataset":0}}
{"text":"In this paper, we present a novel, instance-specific prompt-tuning algorithm for dialogue generation.","cats":{"new-dataset":0}}
{"text":"Specifically, we generate prompts based on instance-level control code, rather than the conversation history, to explore their impact on controlled dialogue generation.","cats":{"new-dataset":0}}
{"text":"Experiments on popular open-domain dialogue datasets, evaluated on both automated metrics and human evaluation, demonstrate that our method is superior to prompting baselines and comparable to fine-tuning with only 5%-6% of total parameters.","cats":{"new-dataset":0}}
{"text":"Code and datasets are available on GitHub https://github.com/neurospin-projects/2023_rlouiset_sepvae.","cats":{"new-dataset":1}}
{"text":"Contrastive Analysis VAE (CA-VAEs) is a family of Variational auto-encoders (VAEs) that aims at separating the common factors of variation between a background dataset (BG) (i.e., healthy subjects) and a target dataset (TG) (i.e., patients) from the ones that only exist in the target dataset.","cats":{"new-dataset":0}}
{"text":"To do so, these methods separate the latent space into a set of salient features (i.e., proper to the target dataset) and a set of common features (i.e., exist in both datasets).","cats":{"new-dataset":0}}
{"text":"Currently, all models fail to prevent the sharing of information between latent spaces effectively and to capture all salient factors of variation.","cats":{"new-dataset":0}}
{"text":"To this end, we introduce two crucial regularization losses: a disentangling term between common and salient representations and a classification term between background and target samples in the salient space.","cats":{"new-dataset":0}}
{"text":"We show a better performance than previous CA-VAEs methods on three medical applications and a natural images dataset (CelebA).","cats":{"new-dataset":0}}
{"text":"The code and dataset are open source at https://github.com/junjun-yan/ATL-PINN.","cats":{"new-dataset":1}}
{"text":"Physics-informed neural networks (PINNs) have emerged as promising surrogate modes for solving partial differential equations (PDEs).","cats":{"new-dataset":0}}
{"text":"Their effectiveness lies in the ability to capture solution-related features through neural networks.","cats":{"new-dataset":0}}
{"text":"However, original PINNs often suffer from bottlenecks, such as low accuracy and non-convergence, limiting their applicability in complex physical contexts.","cats":{"new-dataset":0}}
{"text":"To alleviate these issues, we proposed auxiliary-task learning-based physics-informed neural networks (ATL-PINNs), which provide four different auxiliary-task learning modes and investigate their performance compared with original PINNs.","cats":{"new-dataset":0}}
{"text":"We also employ the gradient cosine similarity algorithm to integrate auxiliary problem loss with the primary problem loss in ATL-PINNs, which aims to enhance the effectiveness of the auxiliary-task learning modes.","cats":{"new-dataset":0}}
{"text":"To the best of our knowledge, this is the first study to introduce auxiliary-task learning modes in the context of physics-informed learning.","cats":{"new-dataset":0}}
{"text":"We conduct experiments on three PDE problems across different fields and scenarios.","cats":{"new-dataset":0}}
{"text":"Our findings demonstrate that the proposed auxiliary-task learning modes can significantly improve solution accuracy, achieving a maximum performance boost of 96.62% (averaging 28.23%) compared to the original single-task PINNs.","cats":{"new-dataset":0}}
{"text":"To facilitate the investigation, we introduce WikiTiLo, a well-curated image dataset compromising images with rich socio-cultural cues","cats":{"new-dataset":1}}
{"text":"We will release our dataset and codes to facilitate future studies.","cats":{"new-dataset":0}}
{"text":"Vision-Language Models (VLMs) are expected to be capable of reasoning with commonsense knowledge as human beings.","cats":{"new-dataset":0}}
{"text":"One example is that humans can reason where and when an image is taken based on their knowledge.","cats":{"new-dataset":0}}
{"text":"This makes us wonder if, based on visual cues, Vision-Language Models that are pre-trained with large-scale image-text resources can achieve and even outperform human's capability in reasoning times and location.","cats":{"new-dataset":0}}
{"text":"To address this question, we propose a two-stage \\recognition\\space and \\reasoning\\space probing task, applied to discriminative and generative VLMs to uncover whether VLMs can recognize times and location-relevant features and further reason about it. .","cats":{"new-dataset":0}}
{"text":"In the extensive experimental studies, we find that although VLMs can effectively retain relevant features in visual encoders, they still fail to make perfect reasoning.","cats":{"new-dataset":0}}
{"text":"Our model was evaluated on two benchmark tree counting datasets, Jiangsu, and Yosemite, as well as a new dataset, KCL-London, created by ourselves","cats":{"new-dataset":1}}
{"text":"The codes and datasets are available at https://github.com/HAAClassic/TreeFormer.","cats":{"new-dataset":0}}
{"text":"Automatic tree density estimation and counting using single aerial and satellite images is a challenging task in photogrammetry and remote sensing, yet has an important role in forest management.","cats":{"new-dataset":0}}
{"text":"In this paper, we propose the first semisupervised transformer-based framework for tree counting which reduces the expensive tree annotations for remote sensing images.","cats":{"new-dataset":0}}
{"text":"Our method, termed as TreeFormer, first develops a pyramid tree representation module based on transformer blocks to extract multi-scale features during the encoding stage.","cats":{"new-dataset":0}}
{"text":"Contextual attention-based feature fusion and tree density regressor modules are further designed to utilize the robust features from the encoder to estimate tree density maps in the decoder.","cats":{"new-dataset":0}}
{"text":"Moreover, we propose a pyramid learning strategy that includes local tree density consistency and local tree count ranking losses to utilize unlabeled images into the training process.","cats":{"new-dataset":0}}
{"text":"Finally, the tree counter token is introduced to regulate the network by computing the global tree counts for both labeled and unlabeled images. .","cats":{"new-dataset":0}}
{"text":"Our TreeFormer outperforms the state of the art semi-supervised methods under the same setting and exceeds the fully-supervised methods using the same number of labeled images.","cats":{"new-dataset":0}}
{"text":"Despite recent advancements in speech emotion recognition (SER) models, state-of-the-art deep learning (DL) approaches face the challenge of the limited availability of annotated data.","cats":{"new-dataset":0}}
{"text":"Large language models (LLMs) have revolutionised our understanding of natural language, introducing emergent properties that broaden comprehension in language, speech, and vision.","cats":{"new-dataset":0}}
{"text":"This paper examines the potential of LLMs to annotate abundant speech data, aiming to enhance the state-of-the-art in SER.","cats":{"new-dataset":0}}
{"text":"We evaluate this capability across various settings using publicly available speech emotion classification datasets.","cats":{"new-dataset":0}}
{"text":"Leveraging ChatGPT, we experimentally demonstrate the promising role of LLMs in speech emotion data annotation.","cats":{"new-dataset":0}}
{"text":"Our evaluation encompasses single-shot and few-shots scenarios, revealing performance variability in SER.","cats":{"new-dataset":0}}
{"text":"Notably, we achieve improved results through data augmentation, incorporating ChatGPT-annotated samples into existing datasets.","cats":{"new-dataset":0}}
{"text":"Our work uncovers new frontiers in speech emotion classification, highlighting the increasing significance of LLMs in this field moving forward.","cats":{"new-dataset":0}}
{"text":"We have taken millions of images in the sorghum fields, manually selected 5,447 images that contain aphids, and annotated each aphid cluster in the image.","cats":{"new-dataset":1}}
{"text":"To use these images for machine learning models, we crop the images into patches and created a labeled dataset with over 151,000 image patches.","cats":{"new-dataset":0}}
{"text":"Aphids are one of the main threats to crops, rural families, and global food security.","cats":{"new-dataset":0}}
{"text":"Chemical pest control is a necessary component of crop production for maximizing yields, however, it is unnecessary to apply the chemical approaches to the entire fields in consideration of the environmental pollution and the cost.","cats":{"new-dataset":0}}
{"text":"Thus, accurately localizing the aphid and estimating the infestation level is crucial to the precise local application of pesticides.","cats":{"new-dataset":0}}
{"text":"Aphid detection is very challenging as each individual aphid is really small and all aphids are crowded together as clusters.","cats":{"new-dataset":0}}
{"text":"In this paper, we propose to estimate the infection level by detecting aphid clusters.  ","cats":{"new-dataset":0}}
{"text":"Then, we i","cats":{"new-dataset":0}}
{"text":"Given a set of calibrated images of a scene, we present an approach that produces a simple, compact, and actionable 3D world representation by means of 3D primitives.","cats":{"new-dataset":0}}
{"text":"While many approaches focus on recovering high-fidelity 3D scenes, we focus on parsing a scene into mid-level 3D representations made of a small set of textured primitives.","cats":{"new-dataset":0}}
{"text":"Such representations are interpretable, easy to manipulate and suited for physics-based simulations.","cats":{"new-dataset":0}}
{"text":"Moreover, unlike existing primitive decomposition methods that rely on 3D input data, our approach operates directly on images through differentiable rendering.","cats":{"new-dataset":0}}
{"text":"Specifically, we model primitives as textured superquadric meshes and optimize their parameters from scratch with an image rendering loss.","cats":{"new-dataset":0}}
{"text":"We highlight the importance of modeling transparency for each primitive, which is critical for optimization and also enables handling varying numbers of primitives.","cats":{"new-dataset":0}}
{"text":"We show that the resulting textured primitives faithfully reconstruct the input images and accurately model the visible 3D points, while providing amodal shape completions of unseen object regions.","cats":{"new-dataset":0}}
{"text":"We compare our approach to the state of the art on diverse scenes from DTU, and demonstrate its robustness on real-life captures from BlendedMVS and Nerfstudio.","cats":{"new-dataset":0}}
{"text":"We also showcase how our results can be used to effortlessly edit a scene or perform physical simulations.","cats":{"new-dataset":0}}
{"text":"Code and video results are available at https://www.tmonnier.com/DBW .","cats":{"new-dataset":0}}
{"text":"This resource paper introduces ISLTranslate, a translation dataset for continuous Indian Sign Language (ISL) consisting of 31k ISL-English sentence/phrase pairs","cats":{"new-dataset":1}}
{"text":"To the best of our knowledge, it is the largest translation dataset for continuous Indian Sign Language","cats":{"new-dataset":1}}
{"text":"To validate the performance of existing end-to-end Sign language to spoken language translation systems, we benchmark the created dataset with a transformer-based model for ISL translation","cats":{"new-dataset":1}}
{"text":"Sign languages are the primary means of communication for many hard-of-hearing people worldwide.","cats":{"new-dataset":0}}
{"text":"Recently, to bridge the communication gap between the hard-of-hearing community and the rest of the population, several sign language translation datasets have been proposed to enable the development of statistical sign language translation systems.","cats":{"new-dataset":0}}
{"text":"However, there is a dearth of sign language resources for the Indian sign language. .","cats":{"new-dataset":0}}
{"text":"To the best of our knowledge, it is the largest translation dataset for continuous Indian Sign Language.","cats":{"new-dataset":0}}
{"text":"To validchmark the created dataset with a transformer-based model for ISL translation.","cats":{"new-dataset":0}}
{"text":"This paper introduces the Life Scapes Reasoning Benchmark (LSR-Benchmark), a novel dataset targeting real-life scenario reasoning","cats":{"new-dataset":1}}
{"text":"The dataset consists of 2,162 questions collected from open-source online sources and is manually annotated to improve its quality.","cats":{"new-dataset":1}}
{"text":", aiming to close the gap in artificial neural networks' ability to reason in everyday contexts.","cats":{"new-dataset":0}}
{"text":"In contrast to domain knowledge reasoning datasets, LSR-Benchmark comprises free-text formatted questions with rich information on real-life scenarios, human behaviors, and character roles.","cats":{"new-dataset":0}}
{"text":"The dataset consists of 2,162 questions collected from open-source online sources and is manually annotated to improve its qualitto test the performance in LSR-Benchmark.","cats":{"new-dataset":0}}
{"text":"The results reveal that humans outperform these models significantly, indicating a persisting challenge for machine learning models in comprehending daily human life.","cats":{"new-dataset":0}}
{"text":"The smarty4covid dataset contains audio signals of cough (4,676), regular breathing (4,665), deep breathing (4,695) and voice (4,291) as recorded by means of mobile devices following a crowd-sourcing approach","cats":{"new-dataset":1}}
{"text":"Other self reported information is also included (e.g. COVID-19 virus tests), thus providing a comprehensive dataset for the development of COVID-19 risk detection models.","cats":{"new-dataset":0}}
{"text":"The smarty4covid dataset is released in the form of a web-ontology language (OWL) knowledge base enabling data consolidation from other relevant datasets, complex queries and reasoning","cats":{"new-dataset":1}}
{"text":"Harnessing the power of Artificial Intelligence (AI) and m-health towards detecting new bio-markers indicative of the onset and progress of respiratory abnormalities/conditions has greatly attracted the scientific and research interest especially during COVID-19 pandemic. .","cats":{"new-dataset":0}}
{"text":"The smarty4covid dataset is releasedtowards the development of models able to: (i) extract clinically informative respiratory indicators from regular breathing records, and (ii) identify cough, breath and voirisk detection models is proposed and validated.","cats":{"new-dataset":0}}
{"text":"This dataset collects nighttime images with different properties of nighttime environments, such as flare and extreme darkness","cats":{"new-dataset":1}}
{"text":"Nighttime surveillance suffers from degradation due to poor illumination and arduous human annotations.","cats":{"new-dataset":0}}
{"text":"It is challengable and remains a security risk at night.","cats":{"new-dataset":0}}
{"text":"Existing methods rely on multi-spectral images to perceive objects in the dark, which are troubled by low resolution and color absence.","cats":{"new-dataset":0}}
{"text":"We argue that the ultimate solution for nighttime surveillance is night-to-day translation, or Night2Day, which aims to translate a surveillance scene from nighttime to the daytime while maintaining semantic consistency.","cats":{"new-dataset":0}}
{"text":"To achieve this, this paper presents a Disentangled Contrastive (DiCo) learning method.","cats":{"new-dataset":0}}
{"text":"Specifically, to address the poor and complex illumination in the nighttime scenes, we propose a learnable physical prior, i.e., the color invariant, which provides a stable perception of a highly dynamic night environment and can be incorporated into the learning pipeline of neural networks.","cats":{"new-dataset":0}}
{"text":"Targeting the surveillance scenes, we develop a disentangled representation, which is an auxiliary pretext task that separates surveillance scenes into the foreground and background with contrastive learning.","cats":{"new-dataset":0}}
{"text":"Such a strategy can extract the semantics without supervision and boost our model to achieve instance-aware translation.","cats":{"new-dataset":0}}
{"text":"Finally, we incorporate all the modules above into generative adversarial networks and achieve high-fidelity translation.  ","cats":{"new-dataset":0}}
{"text":"It includes six scenes to support the study on nighttime surveillance.","cats":{"new-dataset":0}}
{"text":"This dataset collects nighttime images with different properties of nigg works significantly.","cats":{"new-dataset":0}}
{"text":"In this paper, we present TRansPose, the first large-scale multispectral dataset that combines stereo RGB-D, thermal infrared (TIR) images, and object poses to promote transparent object research","cats":{"new-dataset":1}}
{"text":"The dataset includes 99 transparent objects, encompassing 43 household items, 27 recyclable trashes, 29 chemical laboratory equivalents, and 12 non-transparent objects","cats":{"new-dataset":1}}
{"text":"It comprises a vast collection of 333,819 images and 4,000,056 annotations, providing instance-level segmentation masks, ground-truth poses, and completed depth information","cats":{"new-dataset":1}}
{"text":"The data was acquired using a FLIR A65 thermal infrared (TIR) camera, two Intel RealSense L515 RGB-D cameras, and a Franka Emika Panda robot manipulator","cats":{"new-dataset":1}}
{"text":"TRansPose dataset can be accessed from the following link: https://sites.google.com/view/transpose-dataset","cats":{"new-dataset":0}}
{"text":"Transparent objects are encountered frequently in our daily lives, yet recognizing them poses challenges for conventional vision sensors due to their unique material properties, not being well perceived from RGB or depth cameras.","cats":{"new-dataset":0}}
{"text":"Overcoming this limitation, thermal infrared cameras have emerged as a solution, offering improved visibility and shape information for transparent objects. .","cats":{"new-dataset":0}}
{"text":"The dataset includes 99 transparent objects, encompassing 43 household items, 27 recyclable trashes, 29 chemical laboratory equivalents, and 12 non-transparent objects.","cats":{"new-dataset":0}}
{"text":"It comprises a vast colleced using a FLIR A65 thermal infrared (TIR) camera, two Intel RealSense L515 RGB-D cameras, and a Franka Emika Panda robot manipulator.","cats":{"new-dataset":0}}
{"text":"Spanning 87 sequences, TRansPose cbjects in plastic bags, and multi-stacked objects.","cats":{"new-dataset":0}}
{"text":"this paper, we introduce the BeaverTails dataset, aimed at fostering research on safety alignment in large language models (LLMs).","cats":{"new-dataset":1}}
{"text":"In total, we have compiled safety meta-labels for 30,207 question-answer (QA) pairs and gathered 30,144 pairs of expert comparison data for both the helpfulness and harmlessness metrics","cats":{"new-dataset":1}}
{"text":"We believe this dataset provides vital resources for the community, contributing towards the safe development and deployment of LLMs.","cats":{"new-dataset":0}}
{"text":"In  This dataset uniquely separates annotations of helpfulness and harmlessness for question-answering pairs, thus offering distinct perspectives on these crucial attributes.","cats":{"new-dataset":0}}
{"text":"In total, we have compiled safety meta-labels for 30,207 question-answer (QA) pairs and gathered 30,144 pairs of expert comparisonhasizing its potential for practical safety measures in LLMs.","cats":{"new-dataset":0}}
{"text":"Our project page is available at the following URL: https://sites.google.com/view/pku-beavertails.","cats":{"new-dataset":0}}
{"text":"We propose the In-context Autoencoder (ICAE) for context compression in a large language model (LLM).","cats":{"new-dataset":0}}
{"text":"The ICAE has two modules: a learnable encoder adapted with LoRA from an LLM for compressing a long context into a limited number of memory slots, and a fixed decoder which is the target LLM that can condition on the memory slots for various purposes.","cats":{"new-dataset":0}}
{"text":"We first pretrain the ICAE using both autoencoding and language modeling objectives on massive text data, enabling it to generate memory slots that accurately and comprehensively represent the original context.","cats":{"new-dataset":0}}
{"text":"Then, we fine-tune the pretrained ICAE on a small amount of instruct data to enhance its interaction with various prompts for producing desirable responses.","cats":{"new-dataset":0}}
{"text":"Our experimental results demonstrate that the ICAE learned with our proposed pretraining and fine-tuning paradigm can effectively produce memory slots with $4\\times$ context compression, which can be well conditioned on by the target LLM to respond to various prompts.","cats":{"new-dataset":0}}
{"text":"The promising results demonstrate significant implications of the ICAE for its novel approach to the long context problem and its potential to reduce computation and memory overheads for LLM inference in practice, suggesting further research effort in context management for an LLM.","cats":{"new-dataset":0}}
{"text":"This paper introduces InternVid, a large-scale video-centric multimodal dataset that enables learning powerful and transferable video-text representations for multimodal understanding and generation.","cats":{"new-dataset":1}}
{"text":"The InternVid dataset contains over 7 million videos lasting nearly 760K hours, yielding 234M video clips accompanied by detailed descriptions of total 4.1B words.","cats":{"new-dataset":1}}
{"text":" The InternVid dataset contains over 7 million videos lasting nearly 760K hours, yielding 234M video clips accompanied by detailed descriptions of total 4.1B words.","cats":{"new-dataset":0}}
{"text":"Our core contribution is to developnguage representation at scale.","cats":{"new-dataset":0}}
{"text":"Specifically, we utilize a multi-scale approach to generate video-related descriptions.","cats":{"new-dataset":0}}
{"text":"Furthermore, we introduce ViCLIP, a video-text representation learning model based on ViT-L. Learned on InternVid via contrastive learning, this model demonstrates leading zero-shot action recognition and competitive video retrieval performance.","cats":{"new-dataset":0}}
{"text":"Beyond basic video understanding tasks like recognition and retrieval, our dataset and model have broad applications.","cats":{"new-dataset":0}}
{"text":"They are particularly beneficial for generating interleaved video-text data for learning a video-centric dialogue system, advancing video-to-text and text-to-video generation research.","cats":{"new-dataset":0}}
{"text":"These proposed resources provide a tool for researchers and practitioners interested in multimodal video understanding and generation.","cats":{"new-dataset":0}}
{"text":"We make our data and code publicly available in https://github.com/AI21Labs/factor.","cats":{"new-dataset":1}}
{"text":"Before deploying a language model (LM) within a given domain, it is important to measure its tendency to generate factually incorrect information in that domain.","cats":{"new-dataset":0}}
{"text":"Existing factual generation evaluation methods focus on facts sampled from the LM itself, and thus do not control the set of evaluated facts and might under-represent rare and unlikely facts.","cats":{"new-dataset":0}}
{"text":"We propose FACTOR:","cats":{"new-dataset":0}}
{"text":"Factual Assessment via Corpus TransfORmation, a scalable approach for evaluating LM factuality.","cats":{"new-dataset":0}}
{"text":"FACTOR automatically transforms a factual corpus of interest into a benchmark evaluating an LM's propensity to generate true facts from the corpus vs. similar but incorrect statements.","cats":{"new-dataset":0}}
{"text":"We use our framework to create two benchmarks: Wiki-FACTOR and News-FACTOR.","cats":{"new-dataset":0}}
{"text":"We show that: (i) our benchmark scores increase with model size and improve when the LM is augmented with retrieval; (ii) benchmark score correlates with perplexity, but the two metrics do not always agree on model ranking; and (iii) when perplexity and benchmark score disagree, the latter better reflects factuality in open-ended generation, as measured by human annotators.","cats":{"new-dataset":0}}
{"text":"LCC provided an anonymised dataset comprising 14360 records of young people under the age of 18.","cats":{"new-dataset":1}}
{"text":"Local authorities in England, such as Leicestershire County Council (LCC), provide Early Help services that can be offered at any point in a young person's life when they experience difficulties that cannot be supported by universal services alone, such as schools.","cats":{"new-dataset":0}}
{"text":"This paper investigates the utilisation of machine learning (ML) to assist experts in identifying families that may need to be referred for Early Help assessment and support.  ","cats":{"new-dataset":0}}
{"text":"The dataset was pre-processed, machine learning models were build, and experiments were conducted to validate and test the performance of the models.","cats":{"new-dataset":0}}
{"text":"Bias mitigation techniques were applied to improve the fairness of these models.","cats":{"new-dataset":0}}
{"text":"During testing, while the models demonstrated the capability to identify young people requiring intervention or early help, they also produced a significant number of false positives, especially when constructed with imbalanced data, incorrectly identifying individuals who most likely did not need an Early Help referral.","cats":{"new-dataset":0}}
{"text":"This paper empirically explores the suitability of data-driven ML models for identifying young people who may require Early Help services and discusses their appropriateness and limitations for this task.","cats":{"new-dataset":0}}
{"text":"Experiments on a new dataset of real images show that adding RePoGen data to the COCO surpasses previous attempts to top-view pose estimation and significantly improves performance on the bottom-view dataset","cats":{"new-dataset":1}}
{"text":"The code and the datasets are available on the project website.","cats":{"new-dataset":0}}
{"text":"Human Pose Estimation is a thoroughly researched problem; however, most datasets focus on the side and front-view scenarios.","cats":{"new-dataset":0}}
{"text":"We address the limitation by proposing a novel approach that tackles the challenges posed by extreme viewpoints and poses.","cats":{"new-dataset":0}}
{"text":"We introduce a new method for synthetic data generation - RePoGen, RarE POses GENerator - with comprehensive control over pose and view to augment the COCO dataset. .","cats":{"new-dataset":0}}
{"text":"Through an extensive ablation study on both the top and bottom view data, we elucidate the contributions of methodological choices and demonstrate improved performance.","cats":{"new-dataset":0}}
{"text":"We propose IntelliGraphs, a set of five new Knowledge Graph datasets.","cats":{"new-dataset":1}}
{"text":"We also present the dataset generator that produced the synthetic datasets.","cats":{"new-dataset":1}}
{"text":"Knowledge Graph Embedding (KGE) models are used to learn continuous representations of entities and relations.","cats":{"new-dataset":0}}
{"text":"A key task in the literature is predicting missing links between entities.","cats":{"new-dataset":0}}
{"text":"However, Knowledge Graphs are not just sets of links but also have semantics underlying their structure.","cats":{"new-dataset":0}}
{"text":"Semantics is crucial in several downstream tasks, such as query answering or reasoning.","cats":{"new-dataset":0}}
{"text":"We introduce the subgraph inference task, where a model has to generate likely and semantically valid subgraphs.  ","cats":{"new-dataset":0}}
{"text":"The IntelliGraphs datasets contain subgraphs with semantics expressed in logical rules for evaluating subgraph inference.","cats":{"new-dataset":0}}
{"text":"We also present the dataset generator that produced the synthetic datased on traditional KGEs.","cats":{"new-dataset":0}}
{"text":"We evaluate their expressiveness and show that these models cannot capture the semantics.","cats":{"new-dataset":0}}
{"text":"We believe this benchmark will encourage the development of machine learning models that emphasize semantic understanding.","cats":{"new-dataset":0}}
{"text":"In the realm of Tiny AI, we introduce \"You Only Look at Interested Cells\" (YOLIC), an efficient method for object localization and classification on edge devices.","cats":{"new-dataset":0}}
{"text":"Seamlessly blending the strengths of semantic segmentation and object detection, YOLIC offers superior computational efficiency and precision.","cats":{"new-dataset":0}}
{"text":"By adopting Cells of Interest for classification instead of individual pixels, YOLIC encapsulates relevant information, reduces computational load, and enables rough object shape inference.","cats":{"new-dataset":0}}
{"text":"Importantly, the need for bounding box regression is obviated, as YOLIC capitalizes on the predetermined cell configuration that provides information about potential object location, size, and shape.","cats":{"new-dataset":0}}
{"text":"To tackle the issue of single-label classification limitations, a multi-label classification approach is applied to each cell, effectively recognizing overlapping or closely situated objects.","cats":{"new-dataset":0}}
{"text":"This paper presents extensive experiments on multiple datasets, demonstrating that YOLIC achieves detection performance comparable to the state-of-the-art YOLO algorithms while surpassing in speed, exceeding 30fps on a Raspberry Pi 4B CPU.","cats":{"new-dataset":0}}
{"text":"All resources related to this study, including datasets, cell designer, image annotation tool, and source code, have been made publicly available on our project website at https://kai3316.github.io/yolic.github.io","cats":{"new-dataset":0}}
{"text":"Most of the existing LiDAR-inertial navigation systems are based on frame-to-map registrations, leading to inconsistency in state estimation.","cats":{"new-dataset":0}}
{"text":"The newest solid-state LiDAR with a non-repetitive scanning pattern makes it possible to achieve a consistent LiDAR-inertial estimator by employing a frame-to-frame data association.","cats":{"new-dataset":0}}
{"text":"In this letter, we propose a robust and consistent frame-to-frame LiDAR-inertial navigation system (FF-LINS) for solid-state LiDARs.","cats":{"new-dataset":0}}
{"text":"With the INS-centric LiDAR frame processing, the keyframe point-cloud map is built using the accumulated point clouds to construct the frame-to-frame data association.","cats":{"new-dataset":0}}
{"text":"The LiDAR frame-to-frame and the inertial measurement unit (IMU) preintegration measurements are tightly integrated using the factor graph optimization, with online calibration of the LiDAR-IMU extrinsic and time-delay parameters.","cats":{"new-dataset":0}}
{"text":"The experiments on the public and private datasets demonstrate that the proposed FF-LINS achieves superior accuracy and robustness than the state-of-the-art systems.","cats":{"new-dataset":0}}
{"text":"Besides, the LiDAR-IMU extrinsic and time-delay parameters are estimated effectively, and the online calibration notably improves the pose accuracy.","cats":{"new-dataset":0}}
{"text":"The proposed FF-LINS and the employed datasets are open-sourced on GitHub (https://github.com/i2Nav-WHU/FF-LINS).","cats":{"new-dataset":0}}
{"text":"Considering these limitations, we introduce the first video-based retinal dataset by employing handheld devices for data acquisition.","cats":{"new-dataset":1}}
{"text":"The dataset comprises 635 smartphone-based fundus videos collected from four different clinics, involving 415 patients from 50 to 75 years old.","cats":{"new-dataset":1}}
{"text":"Specifically, the dataset provides three levels of spatial annotations","cats":{"new-dataset":1}}
{"text":"In addition, the dataset offers temporal annotations","cats":{"new-dataset":1}}
{"text":"We hope this challenging dataset would significantly contribute to the development of eye disease diagnosis and early prevention.","cats":{"new-dataset":0}}
{"text":"Retinal vessel segmentation is generally grounded in image-based datasets collected with bench-top devices.","cats":{"new-dataset":0}}
{"text":"The static images naturally lose the dynamic characteristics of retina fluctuation, resulting in diminished dataset richness, and the usage of bench-top devices further restricts dataset scalability due to its limited accessibility.  ","cats":{"new-dataset":0}}
{"text":"The dataset comprises 635 smartphone-based fundus videos collected from four different clinics, involving 415 patients from 50 to 75 he landscape of vasculature segmentation.","cats":{"new-dataset":0}}
{"text":"Specifically, the dataset provides three levels of spatial annotations: binary vessel masks for overall retinal structure delineation, general vein-artery masks for distinguishing the vein and artery, and fine-grained vein-artery masks for further characterizing the granulari annotations that capture the vessel pulsation characteristics, assisting in detecting ocular diseases that require fine-grained recognition of hemodynamic fluctuation.","cats":{"new-dataset":0}}
{"text":"In application, our dataset exhibits a significant domain shift with respect to data captured by bench-top devices, thus posing great chaprovide evaluation metrics and benchmark results on our dataset, reflecting both the potential and challenges it offers for vessel segmentation tasks.","cats":{"new-dataset":0}}
{"text":"This study addressed the complex task of sentiment analysis on a dataset of 119,988 original tweets from Weibo using a Convolutional Neural Network (CNN), offering a new approach to Natural Language Processing (NLP).","cats":{"new-dataset":0}}
{"text":"The data, sourced from Baidu's PaddlePaddle AI platform, were meticulously preprocessed, tokenized, and categorized based on sentiment labels.","cats":{"new-dataset":0}}
{"text":"A CNN-based model was utilized, leveraging word embeddings for feature extraction, and trained to perform sentiment classification.","cats":{"new-dataset":0}}
{"text":"The model achieved a macro-average F1-score of approximately 0.73 on the test set, showing balanced performance across positive, neutral, and negative sentiments.","cats":{"new-dataset":0}}
{"text":"The findings underscore the effectiveness of CNNs for sentiment analysis tasks, with implications for practical applications in social media analysis, market research, and policy studies.","cats":{"new-dataset":0}}
{"text":"The complete experimental content and code have been made publicly available on the Kaggle data platform for further research and development.","cats":{"new-dataset":0}}
{"text":"Future work may involve exploring different architectures, such as Recurrent Neural Networks (RNN) or transformers, or using more complex pre-trained models like BERT, to further improve the model's ability to understand linguistic nuances and context.","cats":{"new-dataset":0}}
{"text":"To address the scarcity of annotated corpora with realistic multi-issue negotiation dialogues, we use GPT-3 to build GPT-Negochat, a synthesized dataset that we make publicly available.","cats":{"new-dataset":1}}
{"text":"Automated negotiation support systems aim to help human negotiators reach more favorable outcomes in multi-issue negotiations (e.g., an employer and a candidate negotiating over issues such as salary, hours, and promotions before a job offer).","cats":{"new-dataset":0}}
{"text":"To be successful, these systems must accurately track agreements reached by participants in real-time.","cats":{"new-dataset":0}}
{"text":"Existing approaches either focus on task-oriented dialogues or produce unstructured outputs, rendering them unsuitable for this objective.","cats":{"new-dataset":0}}
{"text":"Our work introduces the novel task of agreement tracking for two-party multi-issue negotiations, which requires continuous monitoring of agreements within a structured state space.  ","cats":{"new-dataset":0}}
{"text":"We present a strong initial baseline for our task by transfer-learning a T5 model trained on the MultiWOZ 2.4 corpus.","cats":{"new-dataset":0}}
{"text":"Pre-training T5-small and T5-base on MultiWOZ 2.4's DST task enhances results by 21% and 9% respectively over training solely on GPT-Negochat.","cats":{"new-dataset":0}}
{"text":"We validate our method's sample-efficiency via smaller training subset experiments.","cats":{"new-dataset":0}}
{"text":"By releasing GPT-Negochat and our baseline models, we aim to encourage further research in multi-issue negotiation dialogue agreement tracking.","cats":{"new-dataset":0}}
{"text":"This work presents WaterScenes, the first multi-task 4D radar-camera fusion dataset for autonomous driving on water surfaces","cats":{"new-dataset":1}}
{"text":"Focusing on typical static and dynamic objects on water surfaces, we label the camera images and radar point clouds at pixel-level and point-level, respectively","cats":{"new-dataset":1}}
{"text":"WaterScenes dataset is public on https://waterscenes.github.io.","cats":{"new-dataset":0}}
{"text":"Autonomous driving on water surfaces plays an essential role in executing hazardous and time-consuming missions, such as maritime surveillance, survivors rescue, environmental monitoring, hydrography mapping and waste cleaning. .","cats":{"new-dataset":0}}
{"text":"Equipped with a 4D radar and a monocular camera, our Unmanned Surface Vehicle (USV) proffers all-weather solutions for discerning object-related information, including color, shape, texture, range, velocity, azimuth, and elevation.","cats":{"new-dataset":0}}
{"text":"Focusing on typical static and dynamic objects on water surfaces, we label the camera images and radar point clouds at pixelprovide annotations for free-space segmentation and waterline segmentation.","cats":{"new-dataset":0}}
{"text":"Leveraging the multi-task and multi-modal data, we conduct numerous experiments on the single modality of radar and camera, as well as the fused modalities.","cats":{"new-dataset":0}}
{"text":"Results demonstrate that 4D radar-camera fusion can considerably enhance the robustness of perception on water surfaces, especially in adverse lighting and weather conditions.","cats":{"new-dataset":0}}
{"text":"This paper presents the introduction of a framework called \\textit{Ashaar} https://github.com/ARBML/Ashaar, which encompasses a collection of datasets and pre-trained models designed specifically for the analysis and generation of Arabic poetry.","cats":{"new-dataset":1}}
{"text":"Furthermore, as part of this endeavor, we provide four datasets: one for poetry generation, another for diacritization, and two for Arudi-style prediction.","cats":{"new-dataset":0}}
{"text":"These datasets aim to facilitate research and development in the field of Arabic poetry by enabling researchers and enthusiasts to delve into the nuances of this rich literary tradition.","cats":{"new-dataset":1}}
{"text":"Poetry holds immense significance within the cultural and traditional fabric of any nation.","cats":{"new-dataset":0}}
{"text":"It serves as a vehicle for poets to articulate their emotions, preserve customs, and convey the essence of their culture.","cats":{"new-dataset":0}}
{"text":"Arabic poetry is no exception, having played a cherished role in the heritage of the Arabic community throughout history and maintaining its relevance in the present era.","cats":{"new-dataset":0}}
{"text":"Typically, comprehending Arabic poetry necessitates the expertise of a linguist who can analyze its content and assess its quality.  ","cats":{"new-dataset":0}}
{"text":"The pipeline established within our proposed approach encompasses various aspects of poetry, such as meter, theme, and era classification.","cats":{"new-dataset":0}}
{"text":"It also incorporates automatic poetry diacritization, enabling more intricate analyses like automated extraction of the \\textit{Arudi} style.","cats":{"new-dataset":0}}
{"text":"Additionally, we explore the feasibility of generating conditional poetry through the pre-training of a character-based GPT model.","cats":{"new-dataset":0}}
{"text":"These datasets aim to facilitate research and development in the field of Arabic poetry b","cats":{"new-dataset":0}}
{"text":"We build LogBench, the first logging statement generation dataset.","cats":{"new-dataset":1}}
{"text":"Automated logging statement generation techniques facilitate developers in writing appropriate logging statements that document software behaviors.","cats":{"new-dataset":0,"dev-research":1}}
{"text":"Current retrieval-based and learning-based logging methods fail to provide accurate logging statements in complex software.","cats":{"new-dataset":0}}
{"text":"Although existing large language models (LLMs) might be a good fit for the task due to their great success in natural language generation and programming language comprehension, their effectiveness and generalization capabilities have not been explored.","cats":{"new-dataset":0,"dev-research":0}}
{"text":"To this end, this paper performs the first extensive study on applying LLMs for logging statement generation.  ","cats":{"new-dataset":0}}
{"text":"On LogBench, we evaluate the effectiveness and generalization capabilities of eight state-of-the-art LLMs, which include general-purpose and code-specific models ranging from 60M to 175B in size.","cats":{"new-dataset":0}}
{"text":"Specifically, we evaluate LLM's logging effectiveness by studying 1) their ability to decide logging ingredients, 2) the impact of the internal characteristics of LLMs, and 3) the influence of external factors.","cats":{"new-dataset":0,"dev-research":0}}
{"text":"We further evaluate LLM's logging generalization capabilities using unseen data derived from code transformation techniques.","cats":{"new-dataset":0,"dev-research":0}}
{"text":"Our study demonstrates that existing LLMs fall short of practical requirements for generating proper logging statement texts.","cats":{"new-dataset":0,"dev-research":0}}
{"text":"We also disclose the impact of internal characteristics and external factors for LLMs in automated logging.","cats":{"new-dataset":0,"dev-research":0}}
{"text":"In addition, we observe that existing LLMs cannot generalize to logging unseen code, revealing their unsatisfactory generalization capabilities.","cats":{"new-dataset":0,"dev-research":0}}
{"text":"Based on our findings, we further discuss three implications that can enhance logging statement generation in the future, such as developing a unified metric for logging quality, incorporating shareable code knowledge into LLMs, and devising suitable prompts.","cats":{"new-dataset":0,"dev-research":0}}
{"text":"To address this gap, we introduce the Brazilian Leading Universities Entrance eXams (BLUEX), a dataset of entrance exams from the two leading universities in Brazil: UNICAMP and USP","cats":{"new-dataset":1}}
{"text":"The dataset includes annotated metadata for evaluating the performance of NLP models on a variety of subjects","cats":{"new-dataset":1}}
{"text":"The dataset is also annotated to indicate the position of images in each question, providing a valuable resource for advancing the state-of-the-art in multimodal language understanding and reasoning.","cats":{"new-dataset":1}}
{"text":"The data and relevant code can be found at https://github.com/Portuguese-Benchmark-Datasets/BLUEX","cats":{"new-dataset":1}}
{"text":"One common trend in recent studies of language models (LMs) is the use of standardized tests for evaluation.","cats":{"new-dataset":0}}
{"text":"However, despite being the fifth most spoken language worldwide, few such evaluations have been conducted in Portuguese.","cats":{"new-dataset":0}}
{"text":"This is mainly due to the lack of high-quality datasets available to the community for carrying out evaluations in Portuguese. .","cats":{"new-dataset":0}}
{"text":"The dataset includes annotated metadata for evaluating the performance of NLP models on a variety of subjects.","cats":{"new-dataset":0}}
{"text":"Furthermore, BLUEX includes a collection of recently administered examnnotated to indicate the position of images in each question, providing a valuable resource for advancing the state-of-the-art in multimodal language understanding and reasoning.","cats":{"new-dataset":0}}
{"text":"We describe the creation and characteristics of BLUEX and establish a benchmark through exund at https://github.com/Portuguese-Benchmark-Datasets/BLUEX","cats":{"new-dataset":0}}
{"text":"We produce 1,304 sentence pairs by modifying 15 examples from the SICK dataset (Marelli et al., 2014).","cats":{"new-dataset":1}}
{"text":"We introduce a synthetic dataset called Sentences Involving Complex Compositional Knowledge (SICCK) and a novel analysis that investigates the performance of Natural Language Inference (NLI) models to understand compositionality in logic.  ","cats":{"new-dataset":0}}
{"text":"To this end, we modify the original texts using a set of phrases - modifiers that correspond to universal quantifiers, existential quantifiers, negation, and other concept modifiers in Natural Logic (NL) (MacCartney, 2009).","cats":{"new-dataset":0}}
{"text":"We use these phrases to modify the subject, verb, and object parts of the premise and hypothesis.","cats":{"new-dataset":0}}
{"text":"Lastly, we annotate these modified texts with the corresponding entailment labels following NL rules.","cats":{"new-dataset":0}}
{"text":"We conduct a preliminary verification of how well the change in the structural and semantic composition is captured by neural NLI models, in both zero-shot and fine-tuned scenarios.","cats":{"new-dataset":0}}
{"text":"We found that the performance of NLI models under the zero-shot setting is poor, especially for modified sentences with negation and existential quantifiers.","cats":{"new-dataset":0}}
{"text":"After fine-tuning this dataset, we observe that models continue to perform poorly over negation, existential and universal modifiers.","cats":{"new-dataset":0}}
{"text":"Age and gender recognition in the wild is a highly challenging task: apart from the variability of conditions, pose complexities, and varying image quality, there are cases where the face is partially or completely occluded.","cats":{"new-dataset":0}}
{"text":"We present MiVOLO (Multi Input VOLO), a straightforward approach for age and gender estimation using the latest vision transformer.","cats":{"new-dataset":0}}
{"text":"Our method integrates both tasks into a unified dual input/output model, leveraging not only facial information but also person image data.","cats":{"new-dataset":0}}
{"text":"This improves the generalization ability of our model and enables it to deliver satisfactory results even when the face is not visible in the image.","cats":{"new-dataset":0}}
{"text":"To evaluate our proposed model, we conduct experiments on four popular benchmarks and achieve state-of-the-art performance, while demonstrating real-time processing capabilities.","cats":{"new-dataset":0}}
{"text":"The ground truth annotations for this benchmark have been meticulously generated by human annotators, resulting in high accuracy answers due to the smart aggregation of votes.","cats":{"new-dataset":0}}
{"text":"Furthermore, we compare our model's age recognition performance with human-level accuracy and demonstrate that it significantly outperforms humans across a majority of age ranges.","cats":{"new-dataset":0}}
{"text":"Finally, we grant public access to our models, along with the code for validation and inference.","cats":{"new-dataset":0}}
{"text":"To bridge this gap, we introduce a dataset, SAGC-A68, which comprises access graphs automatically generated from 68 digital 3D models of space layouts of apartment buildings","cats":{"new-dataset":1}}
{"text":"This graph-based dataset is well-suited for developing GDL models for space function and space element classification","cats":{"new-dataset":1}}
{"text":"The dataset and code used in the experiment are available online.","cats":{"new-dataset":0}}
{"text":"The analysis of building models for usable area, building safety, and energy use requires accurate classification data of spaces and space elements.","cats":{"new-dataset":0}}
{"text":"To reduce input model preparation effort and errors, automated classification of spaces and space elements is desirable.","cats":{"new-dataset":0}}
{"text":"A barrier hindering the utilization of Graph Deep Learning (GDL) methods to space function and space element classification is a lack of suitable datasets. .","cats":{"new-dataset":0}}
{"text":"This graph-based dataset is well-suited for developing GDL models for space function and space element classification.","cats":{"new-dataset":0}}
{"text":"To demonstrate the potential of the dataset, we employ.","cats":{"new-dataset":0}}
{"text":"https://doi.org/10.5281/zenodo.7805872, https://github.com/A2Amir/SAGC-A68.","cats":{"new-dataset":0}}
{"text":"We position the contribution of this work in two folds: (i)-we collect and curate nearly 2k high-quality tabular datasets, each of which is guaranteed to possess clear semantics, clean labels, and other necessary meta information.","cats":{"new-dataset":1}}
{"text":"Tabular data -- also known as structured data -- is one of the most common data forms in existence, thanks to the stable development and scaled deployment of database systems in the last few decades.","cats":{"new-dataset":0}}
{"text":"At present however, despite the blast brought by large pre-trained models in other domains such as ChatGPT or SAM, how can we extract common knowledge across tables at a scale that may eventually lead to generalizable representation for tabular data remains a full blank.","cats":{"new-dataset":0}}
{"text":"Indeed, there have been a few works around this topic.","cats":{"new-dataset":0}}
{"text":"Most (if not all) of them are limited in the scope of a single table or fixed form of a schema.","cats":{"new-dataset":0}}
{"text":"In this work, we first identify the crucial research challenges behind tabular data pre-training, particularly towards the cross-table scenario.  ","cats":{"new-dataset":0}}
{"text":"(ii)-we propose a novel framework that allows cross-table pre-training dubbed as CT-BERT.","cats":{"new-dataset":0}}
{"text":"Noticeably, in light of pioneering the scaled cross-table training, CT-BERT is fully compatible with both supervised and self-supervised schemes, where the specific instantiation of CT-BERT is very much dependent on the downstream tasks.","cats":{"new-dataset":0}}
{"text":"We further propose and implement a contrastive-learning-based and masked table modeling (MTM) objective into CT-BERT, that is inspired from computer vision and natural language processing communities but sophistically tailored to tables.","cats":{"new-dataset":0}}
{"text":"The extensive empirical results on 15 datasets demonstrate CT-BERT's state-of-the-art performance, where both its supervised and self-supervised setups significantly outperform the prior approaches.","cats":{"new-dataset":0}}
{"text":"The dataset is publicly available at: https://huggingface.co/datasets/Soyoung/HistRED under CC BY-NC-ND 4.0 license.","cats":{"new-dataset":1}}
{"text":"Despite the extensive applications of relation extraction (RE) tasks in various domains, little has been explored in the historical context, which contains promising data across hundreds and thousands of years.","cats":{"new-dataset":0}}
{"text":"To promote the historical RE research, we present HistRED constructed from Yeonhaengnok.","cats":{"new-dataset":0}}
{"text":"Yeonhaengnok is a collection of records originally written in Hanja, the classical Chinese writing, which has later been translated into Korean.","cats":{"new-dataset":0}}
{"text":"HistRED provides bilingual annotations such that RE can be performed on Korean and Hanja texts.","cats":{"new-dataset":0}}
{"text":"In addition, HistRED supports various self-contained subtexts with different lengths, from a sentence level to a document level, supporting diverse context settings for researchers to evaluate the robustness of their RE models.","cats":{"new-dataset":0}}
{"text":"To demonstrate the usefulness of our dataset, we propose a bilingual RE model that leverages both Korean and Hanja contexts to predict relations between entities.","cats":{"new-dataset":0}}
{"text":"Our model outperforms monolingual baselines on HistRED, showing that employing multiple language contexts supplements the RE predictions.","cats":{"new-dataset":0}}
{"text":"This research paper introduces a new curated dataset and a deep learning-based approach to solve these problems using convolutional neural networks (CNNs) and comprehensive data processing techniques.","cats":{"new-dataset":1}}
{"text":"Our dataset includes curated images and diverse channel bands from Sentinel, Landsat, VIIRS, and MODIS satellites.","cats":{"new-dataset":0}}
{"text":"We design the dataset considering different spatial and temporal resolution requirements","cats":{"new-dataset":1}}
{"text":"Our code, models and dataset are open source: https://github.com/h2oai/cvpr-multiearth-deforestation-segmentation","cats":{"new-dataset":1}}
{"text":"Deforestation estimation and fire detection in the Amazon forest poses a significant challenge due to the vast size of the area and the limited accessibility.","cats":{"new-dataset":0}}
{"text":"However, these are crucial problems that lead to severe environmental consequences, including climate change, global warming, and biodiversity loss.","cats":{"new-dataset":0}}
{"text":"To effectively address this problem, multimodal satellite imagery and remote sensing offer a promising solution for estimating deforestation and detecting wildfire in the Amazonia region.  ","cats":{"new-dataset":0}}
{"text":"We design the dataset considering different spatial and temporal resolution requiremeimages from the region.","cats":{"new-dataset":0}}
{"text":"Our code, models and dataset are open source: https://github.com/h2oai/cvpr-multiearth-defo","cats":{"new-dataset":0}}
{"text":"We address this limitation by constructing MultiVENT, a dataset of multilingual, event-centric videos grounded in text documents across five target languages","cats":{"new-dataset":1}}
{"text":"Everyday news coverage has shifted from traditional broadcasts towards a wide range of presentation formats such as first-hand, unedited video footage.","cats":{"new-dataset":0}}
{"text":"Datasets that reflect the diverse array of multimodal, multilingual news sources available online could be used to teach models to benefit from this shift, but existing news video datasets focus on traditional news broadcasts produced for English-speaking audiences. .","cats":{"new-dataset":0}}
{"text":"MultiVENT includes both news broadcast videos and non-professional event footage, which we use to analyze the state of online news videos and how they can be leveraged to build robust, factually accurate models.","cats":{"new-dataset":0}}
{"text":"Finally, we provide a model for complex, multilingual video retrieval to serve as a baseline for information retrieval using MultiVENT.","cats":{"new-dataset":0}}
{"text":"To address this, we establish a large-scale dataset, namely the Tuberculosis X-ray (TBX11K) dataset, which contains 11,200 chest X-ray (CXR) images with corresponding bounding box annotations for TB areas","cats":{"new-dataset":1}}
{"text":"This dataset enables the training of sophisticated detectors for high-quality CTD","cats":{"new-dataset":1}}
{"text":"The data, code, and models will be released.","cats":{"new-dataset":0}}
{"text":"Tuberculosis (TB) is a major global health threat, causing millions of deaths annually.","cats":{"new-dataset":0}}
{"text":"Although early diagnosis and treatment can greatly improve the chances of survival, it remains a major challenge, especially in developing countries.","cats":{"new-dataset":0}}
{"text":"Recently, computer-aided tuberculosis diagnosis (CTD) using deep learning has shown promise, but progress is hindered by limited training data. .","cats":{"new-dataset":0}}
{"text":"This dataset enables the training of sophisticated detectors for high-quality CTD.","cats":{"new-dataset":0}}
{"text":"Furthermore, we propose a strong baseline, SymFormer, for simultaneous CXR image classification and TB infection area dete the bilateral symmetry property of CXR images for learning discriminative features.","cats":{"new-dataset":0}}
{"text":"Since CXR images may not strictly adhere to the bilateral symmetry property, we also propose Symmetric Positional Encoding (SPE) to facilitate SymAttention through feature recalibration.","cats":{"new-dataset":0}}
{"text":"To promote future research on CTD, we build a benchmark by introducing evaluation metrics, evaluating baseline models reformed from existing detectors, and running an online challenge.","cats":{"new-dataset":0}}
{"text":"Experiments show that SymFormer achieves state-of-the-art performance on the TBX11K dataset.","cats":{"new-dataset":0}}
{"text":"This paper presents an end-to-end methodology for collecting datasets to recognize handwritten English alphabets by utilizing Inertial Measurement Units (IMUs) and leveraging the diversity present in the Indian writing style","cats":{"new-dataset":1}}
{"text":"The IMUs are utilized to capture the dynamic movement patterns associated with handwriting, enabling more accurate recognition of alphabets.","cats":{"new-dataset":0}}
{"text":"The Indian context introduces various challenges due to the heterogeneity in writing styles across different regions and languages.","cats":{"new-dataset":0}}
{"text":"Some preliminary experimental results demonstrate the effectiveness of the dataset in accurately recogpattern recognition and offers valuable insights for developing improved systems for handwriting recognition, particularly in diverse linguistic and cultural contexts.","cats":{"new-dataset":0}}
{"text":"We fill this gap by semi-automatically creating an NLI dataset for spatial reasoning, called SpaceNLI","cats":{"new-dataset":1}}
{"text":"While many natural language inference (NLI) datasets target certain semantic phenomena, e.g., negation, tense & aspect, monotonicity, and presupposition, to the best of our knowledge, there is no NLI dataset that involves diverse types of spatial expressions and reasoning. .","cats":{"new-dataset":0}}
{"text":"We test several SOTA NLI systems on SpaceNLI to gauge the complexity of the dataset and the system's capacity for spatial reasoning.","cats":{"new-dataset":0}}
{"text":"Moreover, we introduce a Pattern Accuracy and argue that it is a more reliable and stricter measure than the accuracy for evaluating a system's performance on pattern-based generated data samples.","cats":{"new-dataset":0}}
{"text":"Based on the evaluation results we find that the systems obtain moderate results on the spatial NLI problems but lack consistency per inference pattern.","cats":{"new-dataset":0}}
{"text":"The results also reveal that non-projective spatial inferences (especially due to the \"between\" preposition) are the most challenging ones.","cats":{"new-dataset":0}}
{"text":"This paper presents the FormAI dataset, a large collection of 112,000 AI-generated compilable and independent C programs with vulnerability classification","cats":{"new-dataset":1}}
{"text":"We make the source code available for the 112,000 programs, accompanied by a comprehensive list detailing the vulnerabilities detected in each individual program","cats":{"new-dataset":1}}
{"text":"We introduce a dynamic zero-shot prompting technique, constructed to spawn a diverse set of programs utilizing Large Language Models (LLMs).","cats":{"new-dataset":0}}
{"text":"Some programs handle complicated tasks such as networkion.","cats":{"new-dataset":0}}
{"text":"This is accomplished by employing a formal verification method using the Efficient SMT-based Bounded Model Checker (ESBMC), which performs model checking, abstract interpretation, constraint programming, and satisfiability modulo theories, to reason over safety/security properties in programs.","cats":{"new-dataset":0}}
{"text":"This approach definitively detects vulnerabilities and offers a formal model known as a counterexample, thus eliminating the possibility of generating false positive reports.","cats":{"new-dataset":0}}
{"text":"Furthermore, we have associated the identified vulnerabilities with relevant Common Weakness Enumeration (CWE) numbers.","cats":{"new-dataset":0}}
{"text":"We make the source code available for the 112,000 programs, accompanied by a comprehensive list detailing the vulnerabilities detected in each individual program including location and function name, which makes the dataset ideal to train LLMs and machi","cats":{"new-dataset":0}}
{"text":"In this work, we construct two datasets to address this issue","cats":{"new-dataset":1}}
{"text":"We introduce a new conversation head generation benchmark for synthesizing behaviors of a single interlocutor in a face-to-face conversation.","cats":{"new-dataset":0}}
{"text":"The capability to automatically synthesize interlocutors which can participate in long and multi-turn conversations is vital and offer benefits for various applications, including digital humans, virtual agents, and social robots.","cats":{"new-dataset":0}}
{"text":"While existing research primarily focuses on talking head generation (one-way interaction), hindering the ability to create a digital human for conversation (two-way) interaction due to the absence of listening and interaction parts.","cats":{"new-dataset":0}}
{"text":", ``ViCo'' for independent talking and listening head generation tasks at the sentence level, and ``ViCo-X'', for synthesizing interlocutors in multi-turn conversational scenarios.","cats":{"new-dataset":0}}
{"text":"Based on ViCo and ViCo-X, we define three novel tasks targeting the interaction modeling during the face-to-face conversation: 1) responsive listening head generation making listeners respond actively to the speaker with non-verbal signals, 2) expressive talking head generation guiding speakers to be aware of listeners' behaviors, and 3) conversational head generation to integrate the talking/listening ability in one interlocutor.","cats":{"new-dataset":0}}
{"text":"Along with the datasets, we also propose corresponding baselierate responsive and vivid agents that can collaborate with real person to fulfil the whole conversation.","cats":{"new-dataset":0}}
{"text":"Project page: https://vico.solutions/.","cats":{"new-dataset":0}}
{"text":"The digitization of documents allows for wider accessibility and reproducibility.","cats":{"new-dataset":0}}
{"text":"While automatic digitization of document layout and text content has been a long-standing focus of research, this problem in regard to graphical elements, such as statistical plots, has been under-explored.","cats":{"new-dataset":0}}
{"text":"In this paper, we introduce the task of fine-grained visual understanding of mathematical graphics and present the Line Graphics (LG) dataset, which includes pixel-wise annotations of 5 coarse and 10 fine-grained categories.  ","cats":{"new-dataset":0}}
{"text":"To benchmark our LG dataset, we explore 7 state-of-the-art models.","cats":{"new-dataset":0}}
{"text":"To foster further research on the digitization of statistical graphs, we will make the dataset, code, and model","cats":{"new-dataset":0}}
{"text":"While the general machine learning (ML) community has benefited from public datasets, tasks, and models, the progress of ML in healthcare has been hampered by a lack of such shared assets.","cats":{"new-dataset":0}}
{"text":"The success of foundation models creates new challenges for healthcare ML by requiring access to shared pretrained models to validate performance benefits.","cats":{"new-dataset":0}}
{"text":"We help address these challenges through three contributions.  ","cats":{"new-dataset":0}}
{"text":"Unlike MIMIC-III/IV and other popular EHR datasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients.","cats":{"new-dataset":0}}
{"text":"Second, we publish the weights of a 141M parameter clinical foundation model pretrained on the structured EHR data of 2.57M patients.","cats":{"new-dataset":0}}
{"text":"We are one of the first to fully release such a model for coded EHR data; in contrast, most prior models released for clinical data (e.g. GatorTron, ClinicalBERT) only work with unstructured text and cannot process the rich, structured data within an EHR.","cats":{"new-dataset":0}}
{"text":"We provide an end-to-end pipeline for the community to validate and build upon its performance.","cats":{"new-dataset":0}}
{"text":"Third, we define 15 few-shot clinical prediction tasks, enabling evaluation of foundation models on benefits such as sample efficiency and task adaption.","cats":{"new-dataset":0}}
{"text":"The code to reproduce our results, as well as the model and dataset (via a research data use agreement), are available at our Github repo here: https://github.com/som","cats":{"new-dataset":0}}
{"text":"Generative latent diffusion models have been established as state-of-the-art in data generation.","cats":{"new-dataset":0}}
{"text":"One promising application is generation of realistic synthetic medical imaging data for open data sharing without compromising patient privacy.","cats":{"new-dataset":0}}
{"text":"Despite the promise, the capacity of such models to memorize sensitive patient training data and synthesize samples showing high resemblance to training data samples is relatively unexplored.","cats":{"new-dataset":0}}
{"text":"Here, we assess the memorization capacity of 3D latent diffusion models on photon-counting coronary computed tomography angiography and knee magnetic resonance imaging datasets.","cats":{"new-dataset":0}}
{"text":"To detect potential memorization of training samples, we utilize self-supervised models based on contrastive learning.","cats":{"new-dataset":0}}
{"text":"Our results suggest that such latent diffusion models indeed memorize training data, and there is a dire need for devising strategies to mitigate memorization.","cats":{"new-dataset":0}}
{"text":"Visual Question Answering (VQA) models aim to answer natural language questions about given images.","cats":{"new-dataset":0}}
{"text":"Due to its ability to ask questions that differ from those used when training the model, medical VQA has received substantial attention in recent years.","cats":{"new-dataset":0}}
{"text":"However, existing medical VQA models typically focus on answering questions that refer to an entire image rather than where the relevant content may be located in the image.","cats":{"new-dataset":0}}
{"text":"Consequently, VQA models are limited in their interpretability power and the possibility to probe the model about specific image regions.","cats":{"new-dataset":0}}
{"text":"This paper proposes a novel approach for medical VQA that addresses this limitation by developing a model that can answer questions about image regions while considering the context necessary to answer the questions.","cats":{"new-dataset":0}}
{"text":"Our experimental results demonstrate the effectiveness of our proposed model, outperforming existing methods on three datasets.","cats":{"new-dataset":0}}
{"text":"Artificial intelligence applications enable farmers to optimize crop growth and production while reducing costs and environmental impact.","cats":{"new-dataset":0}}
{"text":"Computer vision-based algorithms in particular, are commonly used for fruit segmentation, enabling in-depth analysis of the harvest quality and accurate yield estimation.","cats":{"new-dataset":0}}
{"text":"In this paper, we propose TomatoDIFF, a novel diffusion-based model for semantic segmentation of on-plant tomatoes.","cats":{"new-dataset":0}}
{"text":"When evaluated against other competitive methods, our model demonstrates state-of-the-art (SOTA) performance, even in challenging environments with highly occluded fruits.  ","cats":{"new-dataset":0}}
{"text":"Large language models~(LLMs) obtain instruction-following capability through instruction-finetuning (IFT) on supervised instruction/response data.","cats":{"new-dataset":0}}
{"text":"However, widely used IFT datasets (e.g., Alpaca's 52k data) surprisingly contain many low-quality instances with incorrect or irrelevant responses, which are misleading and detrimental to IFT.","cats":{"new-dataset":0}}
{"text":"In this paper, we propose a simple and effective data selection strategy that automatically identifies and removes low-quality data using a strong LLM (e.g., ChatGPT).","cats":{"new-dataset":0}}
{"text":"To this end, we introduce AlpaGasus, which is finetuned on only 9k high-quality data filtered from the 52k Alpaca data.","cats":{"new-dataset":0}}
{"text":"AlpaGasus significantly outperforms the original Alpaca as evaluated by GPT-4 on multiple test sets and its 13B variant matches $>90\\%$ performance of its teacher LLM (i.e., Text-Davinci-003) on test tasks.","cats":{"new-dataset":0}}
{"text":"It also provides 5.7x faster training, reducing the training time for a 7B variant from 80 minutes (for Alpaca) to 14 minutes \\footnote{We apply IFT for the same number of epochs as Alpaca(7B)","cats":{"new-dataset":0}}
{"text":"but on fewer data, using 4$\\times$NVIDIA A100 (80GB) GPUs and following the original Alpaca setting and hyperparameters.}.","cats":{"new-dataset":0}}
{"text":"Overall, AlpaGasus demonstrates a novel data-centric IFT paradigm that can be generally applied to instruction-tuning data, leading to faster training and better instruction-following models.","cats":{"new-dataset":0}}
{"text":"Our project page is available at: \\url{https://lichang-chen.github.io/AlpaGasus/}.","cats":{"new-dataset":0}}
{"text":"We also introduce a large-scale dataset, Video Depth in the Wild (VDW), which consists of 14,203 videos with over two million frames, making it the largest natural-scene video depth dataset to our knowledge.","cats":{"new-dataset":1}}
{"text":"Video depth estimation aims to infer temporally consistent depth.","cats":{"new-dataset":0}}
{"text":"Some methods achieve temporal consistency by finetuning a single-image depth model during test time using geometry and re-projection constraints, which is inefficient and not robust.","cats":{"new-dataset":0}}
{"text":"An alternative approach is to learn how to enforce temporal consistency from data, but this requires well-designed models and sufficient video depth data.","cats":{"new-dataset":0}}
{"text":"To address these challenges, we propose a plug-and-play framework called Neural Video Depth Stabilizer (NVDS) that stabilizes inconsistent depth estimations and can be applied to different single-image depth models without extra effort.  ","cats":{"new-dataset":0}}
{"text":"We evaluate our method on the VDW dataset as well as two public benchmarks and demonstrate significant improvements in consistency, accuracy, and efficiency compared to previous approaches.","cats":{"new-dataset":0}}
{"text":"Our work serves as a solid baseline and provides a data foundation for learning-based video depth models.","cats":{"new-dataset":0}}
{"text":"Using COLLIE, we compile the COLLIE-v1 dataset with 2080 instances comprising 13 constraint structures.","cats":{"new-dataset":1}}
{"text":"Text generation under constraints have seen increasing interests in natural language processing, especially with the rapidly improving capabilities of large language models.","cats":{"new-dataset":0}}
{"text":"However, existing benchmarks for constrained generation usually focus on fixed constraint types (e.g.,generate a sentence containing certain words) that have proved to be easy for state-of-the-art models like GPT-4.","cats":{"new-dataset":0}}
{"text":"We present COLLIE, a grammar-based framework that allows the specification of rich, compositional constraints with diverse generation levels (word, sentence, paragraph, passage) and modeling challenges (e.g.,language understanding, logical reasoning, counting, semantic planning).","cats":{"new-dataset":0}}
{"text":"We also develop tools for automatic extraction of task instances given a constraint structure and a raw text corpus.  ","cats":{"new-dataset":0}}
{"text":"We perform systematic experiments across five state-of-the-art instruction-tuned language models and analyze their performances to reveal shortcomings.","cats":{"new-dataset":0}}
{"text":"COLLIE is designed to be extensible and lightweight, and we hope the community finds it useful to develop more complex constraints and evaluations in the future.","cats":{"new-dataset":0}}
{"text":"In this paper, we focus on interactions between humans and small indoor robots and introduce a new human-robot interaction (HRI) dataset","cats":{"new-dataset":1}}
{"text":"The dataset used in this analysis is available at: https://github.com/AlexanderDavid/ZuckerDataset.","cats":{"new-dataset":0}}
{"text":"In recent years there has been a large focus on how robots can operate in human populated environments. .","cats":{"new-dataset":0}}
{"text":"The analysis of the recorded experiments shows that anticipatory and non-reactive robot controllers impose similar constraints to humans' safety and efficiency.","cats":{"new-dataset":0}}
{"text":"Additionally, we found that current state-of-the-art models for human trajectory prediction can adequately extend to indoor HRI settings.","cats":{"new-dataset":0}}
{"text":"Finally, we show that humans respond differently in shared and homogeneous environments when collisions are imminent, since interacting with small differential drives can only cause a finite level of social discomfort as compared to human-human interactions.","cats":{"new-dataset":0}}
{"text":"To validate our model, we built a new dataset based on the well-known Matterport3D and REVERIE datasets.","cats":{"new-dataset":1}}
{"text":"This dataset consists of instructions with complex referring expressions accompanied by real indoor environmental images that feature various target objects, in addition to pixel-wise segmentation masks.","cats":{"new-dataset":1}}
{"text":"In this study, we aim to develop a model that comprehends a natural language instruction (e.g., \"Go to the living room and get the nearest pillow to the radio art on the wall\") and generates a segmentation mask for the target everyday object.","cats":{"new-dataset":0}}
{"text":"The task is challenging because it requires (1) the understanding of the referring expressions for multiple objects in the instruction, (2) the prediction of the target phrase of the sentence among the multiple phrases, and (3) the generation of pixel-wise segmentation masks rather than bounding boxes.","cats":{"new-dataset":0}}
{"text":"Studies have been conducted on languagebased segmentation methods; however, they sometimes mask irrelevant regions for complex sentences.","cats":{"new-dataset":0}}
{"text":"In this paper, we propose the Multimodal Diffusion Segmentation Model (MDSM), which generates a mask in the first stage and refines it in the second stage.","cats":{"new-dataset":0}}
{"text":"We introduce a crossmodal parallel feature extraction mechanism and extend diffusion probabilistic models to handle crossmodal features.  ","cats":{"new-dataset":0}}
{"text":"This dataset consists of instructions with complex referring expressions accompanied by real indoor envi","cats":{"new-dataset":0}}
{"text":"LLMs have demonstrated remarkable abilities at interacting with humans through language, especially with the usage of instruction-following data.","cats":{"new-dataset":0}}
{"text":"Recent advancements in LLMs, such as MiniGPT-4, LLaVA, and X-LLM, further enlarge their abilities by incorporating multi-modal inputs, including image, video, and speech.","cats":{"new-dataset":0}}
{"text":"Despite their effectiveness at generating precise and detailed language understanding of the given modality signal, these LLMs give up the ability to ground specific parts of inputs, thus only constructing a coarse-grained mapping.","cats":{"new-dataset":0}}
{"text":"However, explicit and informative correspondence between text and other modalities will not only improve the user experience but also help to expand the application scenario of multi-modal LLMs.","cats":{"new-dataset":0}}
{"text":"Therefore, we propose BuboGPT, a multi-modal LLM with visual grounding that can perform cross-modal interaction between vision, audio and language, providing fine-grained understanding of visual objects and other given modalities.","cats":{"new-dataset":0}}
{"text":"As a result, BuboGPT is able to point out the specific location of an object in the image, when it is generating response or description for that object.","cats":{"new-dataset":0}}
{"text":"Our contributions are two-fold: 1) An off-the-shelf visual grounding module based on SAM that extracts entities in a sentence and find corresponding masks in the image.","cats":{"new-dataset":0}}
{"text":"2) A two-stage training scheme and instruction dataset to endow joint text-image-audio understanding.","cats":{"new-dataset":0}}
{"text":"Our experiments show that BuboGPT achieves impressive multi-modality understanding and visual grounding abilities during the interaction with human.","cats":{"new-dataset":0}}
{"text":"It performs consistently well when provided by arbitrary modality combinations (either aligned or unaligned).","cats":{"new-dataset":0}}
{"text":"Our code, model and dataset are available at https://bubo-gpt.github.io .","cats":{"new-dataset":0}}
{"text":"To this end, we present G-Scan, the first end-to-end fine-grained line-level vulnerability detection system evaluated on the first-of-its-kind real world dataset.","cats":{"new-dataset":1}}
{"text":"We train and evaluate G-Scan on a collected real world smart contracts dataset with line-level annotations on reentrancy vulnerability, one of the most common and severe types of smart contract vulnerabilities","cats":{"new-dataset":1}}
{"text":"Due to the immutable and decentralized nature of Ethereum (ETH) platform, smart contracts are prone to security risks that can result in financial loss.","cats":{"new-dataset":0}}
{"text":"While existing machine learning-based vulnerability detection algorithms achieve high accuracy at the contract level, they require developers to manually inspect source code to locate bugs.  ","cats":{"new-dataset":0}}
{"text":"G-Scan first converts smart contracts to code graphs in a dependency and hierarchy preserving manner.","cats":{"new-dataset":0}}
{"text":"Next, we train a graph neural network to identify vulnerable nodes and assess security risks.","cats":{"new-dataset":0}}
{"text":"Finally, the code graphs with node vulnerability predictions are mapped back to the smart contracts for line-level localization.","cats":{"new-dataset":0}}
{"text":"We train and evaluate G-Scan on a collected real world smart contracts dataset with line-level annotations on reentrancy vulnerability, one of the most common andore in line-level vulnerability localization.","cats":{"new-dataset":0}}
{"text":"Additionally, the lightweight graph neural network enables G-Scan to localize vulnerabilities in 6.1k lines of code smart contract within 1.2 seconds.","cats":{"new-dataset":0}}
{"text":"In this paper, I train a Bidirectional Long Short-Term Memory (BiLSTM) model on a novel dataset of voter registration data from all 50 US states","cats":{"new-dataset":1}}
{"text":"In the absence of sensitive race and ethnicity data, researchers, regulators, and firms alike turn to proxies.  ","cats":{"new-dataset":0}}
{"text":"and create an ensemble that achieves up to 36.8% higher out of sample (OOS) F1 scores than the best performing machine learning models in the literature.","cats":{"new-dataset":0}}
{"text":"Additionally, I construct the most comprehensive database of first and surname distributions in the US in order to improve the coverage and accuracy of Bayesian Improved Surname Geocoding (BISG) and Bayesian Improved Firstname Surname Geocoding (BIFSG).","cats":{"new-dataset":0}}
{"text":"Researchers have invested considerable effort into ensuring that large language models (LLMs) align with human values, using various training techniques, such as instruction tuning and Reinforcement Learning from Human or AI Feedback (RLHF/RLAIF), to guard against text unsafety.","cats":{"new-dataset":0}}
{"text":"However, these defenses remain incredibly vulnerable to some jailbreak attacks, which can cause the model to become overly defensive to sensitive topics or still generate harmful content, leaving the model performance particularly fragile.","cats":{"new-dataset":0}}
{"text":"Therefore, to comprehensively study text safety and output robustness, we propose a latent jailbreak prompt dataset, each involving malicious instruction embedding.","cats":{"new-dataset":0}}
{"text":"Specifically, we instruct the model to complete a regular task, such as translation, where the text to be translated contains malicious instructions.","cats":{"new-dataset":0}}
{"text":"To further analyze the safety and robustness, we design a hierarchical annotation framework.","cats":{"new-dataset":0}}
{"text":"We present a systematic analysis of the safety and robustness of LLMs concerning the position of explicit normal instructions, word replacement (verbs in explicit normal instructions, target groups in malicious instructions, cue words in malicious instructions), and instruction replacement (different explicit normal instructions).","cats":{"new-dataset":0}}
{"text":"Our results show that current LLMs not only have a preference for certain instruction verbs, but also exhibit different jailbreak rates for different instruction verbs in explicit normal instructions.","cats":{"new-dataset":0}}
{"text":"In other words, the probability of generating unsafe content by the model will be reinforced to varying degrees depending on the instruction verb in explicit normal instructions.","cats":{"new-dataset":0}}
{"text":"Code and data are available at https://github.com/qiuhuachuan/latent-jailbreak.","cats":{"new-dataset":0}}
{"text":"Many real-world datasets have an underlying dynamic graph structure, where entities and their interactions evolve over time.","cats":{"new-dataset":0}}
{"text":"Machine learning models should consider these dynamics in order to harness their full potential in downstream tasks.","cats":{"new-dataset":0}}
{"text":"Previous approaches for graph representation learning have focused on either sampling k-hop neighborhoods, akin to breadth-first search, or random walks, akin to depth-first search.","cats":{"new-dataset":0}}
{"text":"However, these methods are computationally expensive and unsuitable for real-time, low-latency inference on dynamic graphs.","cats":{"new-dataset":0}}
{"text":"To overcome these limitations, we propose graph-sprints a general purpose feature extraction framework for continuous-time-dynamic-graphs (CTDGs) that has low latency and is competitive with state-of-the-art, higher latency models.","cats":{"new-dataset":0}}
{"text":"To achieve this, a streaming, low latency approximation to the random-walk based features is proposed.","cats":{"new-dataset":0}}
{"text":"In our framework, time-aware node embeddings summarizing multi-hop information are computed using only single-hop operations on the incoming edges.","cats":{"new-dataset":0}}
{"text":"We evaluate our proposed approach on three open-source datasets and two in-house datasets, and compare with three state-of-the-art algorithms (TGN-attn, TGN-ID, Jodie).","cats":{"new-dataset":0}}
{"text":"We demonstrate that our graph-sprints features, combined with a machine learning classifier, achieve competitive performance (outperforming all baselines for the node classification tasks in five datasets).","cats":{"new-dataset":0}}
{"text":"Simultaneously, graph-sprints significantly reduce inference latencies, achieving close to an order of magnitude speed-up in our experimental setting.","cats":{"new-dataset":0}}
{"text":"We collected and published a dataset of 18,000 images in lab and hospital environments.","cats":{"new-dataset":1}}
{"text":"The contribution is to establish a baseline on this new dataset and to provide a proof of concept for the human emergency detection in this use case.","cats":{"new-dataset":1}}
{"text":"Human transports in hospitals are labor-intensive and primarily performed in beds to save time.","cats":{"new-dataset":0}}
{"text":"This transfer method does not promote the mobility or autonomy of the patient.","cats":{"new-dataset":0}}
{"text":"To relieve the caregivers from this time-consuming task, a mobile robot is developed to autonomously transport humans around the hospital.","cats":{"new-dataset":0}}
{"text":"It provides different transfer modes including walking and sitting in a wheelchair.","cats":{"new-dataset":0}}
{"text":"The problem that this paper focuses on is to detect emergencies and ensure the well-being of the patient during the transport.","cats":{"new-dataset":0}}
{"text":"For this purpose, the patient is tracked and monitored with a camera system.","cats":{"new-dataset":0}}
{"text":"OpenPose is used for Human Pose Estimation and a trained classifier for emergency detection.  ","cats":{"new-dataset":0}}
{"text":"It differs from related work because we have a moving robot with different transfer modes in a highly dynamic environment with multiple people in the scene using only RGB-D data.","cats":{"new-dataset":0}}
{"text":"To improve the critical recall metric, we apply threshold moving and a time delay.","cats":{"new-dataset":0}}
{"text":"We compare different models with an AutoML approach.","cats":{"new-dataset":0}}
{"text":"This paper shows that emergencies while walking are best detected by a SVM with a recall of 95.8% on single frames.","cats":{"new-dataset":0}}
{"text":"In the case of sitting transport, the best model achieves a recall of 62.2%.","cats":{"new-dataset":0}}
{"text":"The contribution is to establish a baseline on this new dataset and to provide a proof","cats":{"new-dataset":0}}
{"text":"End-to-end model, especially Recurrent Neural Network Transducer (RNN-T), has achieved great success in speech recognition.","cats":{"new-dataset":0}}
{"text":"However, transducer requires a great memory footprint and computing time when processing a long decoding sequence.","cats":{"new-dataset":0}}
{"text":"To solve this problem, we propose a model named time-sparse transducer, which introduces a time-sparse mechanism into transducer.","cats":{"new-dataset":0}}
{"text":"In this mechanism, we obtain the intermediate representations by reducing the time resolution of the hidden states.","cats":{"new-dataset":0}}
{"text":"Then the weighted average algorithm is used to combine these representations into sparse hidden states followed by the decoder.","cats":{"new-dataset":0}}
{"text":"All the experiments are conducted on a Mandarin dataset AISHELL-1.","cats":{"new-dataset":0}}
{"text":"Compared with RNN-T, the character error rate of the time-sparse transducer is close to RNN-T and the real-time factor is 50.00% of the original.","cats":{"new-dataset":0}}
{"text":"By adjusting the time resolution, the time-sparse transducer can also reduce the real-time factor to 16.54% of the original at the expense of a 4.94% loss of precision.","cats":{"new-dataset":0}}
{"text":"To address this abstraction gap and provide a fair evaluation of the proposed method, we develop our method on a large-scale synthetic dataset covering 500k+ buildings with well-defined ground truths of polyhedral class labels.","cats":{"new-dataset":1}}
{"text":"We present PolyGNN, a polyhedron-based graph neural network for 3D building reconstruction from point clouds.","cats":{"new-dataset":0}}
{"text":"PolyGNN learns to assemble primitives obtained by polyhedral decomposition via graph node classification, achieving a watertight, compact, and weakly semantic reconstruction.","cats":{"new-dataset":0}}
{"text":"To effectively represent arbitrary-shaped polyhedra in the neural network, we propose three different sampling strategies to select representative points as polyhedron-wise queries, enabling efficient occupancy inference.","cats":{"new-dataset":0}}
{"text":"Furthermore, we incorporate the inter-polyhedron adjacency to enhance the classification of the graph nodes.","cats":{"new-dataset":0}}
{"text":"We also observe that existing city-building models are abstractions of the underlying instances.  ","cats":{"new-dataset":0}}
{"text":"We further conduct a transferability analysis across cities and on real-world point clouds.","cats":{"new-dataset":0}}
{"text":"Both qualitative and quantitative results demonstrate the effectiveness of our method, particularly its efficiency for large-scale reconstructions.","cats":{"new-dataset":0}}
{"text":"The source code and data of our work are available at https://github.com/chenzhaiyu/polygnn.","cats":{"new-dataset":0}}
{"text":"Curating an informative and representative dataset is essential for enhancing the performance of 2D object detectors.","cats":{"new-dataset":0}}
{"text":"We present a novel active learning sampling strategy that addresses both the informativeness and diversity of the selections.","cats":{"new-dataset":0}}
{"text":"Our strategy integrates uncertainty and diversity-based selection principles into a joint selection objective by measuring the collective information score of the selected samples.","cats":{"new-dataset":0}}
{"text":"Specifically, our proposed NORIS algorithm quantifies the impact of training with a sample on the informativeness of other similar samples.","cats":{"new-dataset":0}}
{"text":"By exclusively selecting samples that are simultaneously informative and distant from other highly informative samples, we effectively avoid redundancy while maintaining a high level of informativeness.","cats":{"new-dataset":0}}
{"text":"Moreover, instead of utilizing whole image features to calculate distances between samples, we leverage features extracted from detected object regions within images to define object features.","cats":{"new-dataset":0}}
{"text":"This allows us to construct a dataset encompassing diverse object types, shapes, and angles.","cats":{"new-dataset":0}}
{"text":"Extensive experiments on object detection and image classification tasks demonstrate the effectiveness of our strategy over the state-of-the-art baselines.","cats":{"new-dataset":0}}
{"text":"Specifically, our selection strategy achieves a 20% and 30% reduction in labeling costs compared to random selection for PASCAL-VOC and KITTI, respectively.","cats":{"new-dataset":0}}
{"text":"To provide a more robust evaluation of the proposed method, a large-scale clinical image dataset of skin diseases with significantly more cases than existing datasets has been established.","cats":{"new-dataset":1}}
{"text":"Skin diseases are among the most prevalent health issues, and accurate computer-aided diagnosis methods are of importance for both dermatologists and patients.","cats":{"new-dataset":0}}
{"text":"However, most of the existing methods overlook the essential domain knowledge required for skin disease diagnosis.","cats":{"new-dataset":0}}
{"text":"A novel multi-task model, namely DermImitFormer, is proposed to fill this gap by imitating dermatologists' diagnostic procedures and strategies.","cats":{"new-dataset":0}}
{"text":"Through multi-task learning, the model simultaneously predicts body parts and lesion attributes in addition to the disease itself, enhancing diagnosis accuracy and improving diagnosis interpretability.","cats":{"new-dataset":0}}
{"text":"The designed lesion selection module mimics dermatologists' zoom-in action, effectively highlighting the local lesion features from noisy backgrounds.","cats":{"new-dataset":0}}
{"text":"Additionally, the presented cross-interaction module explicitly models the complicated diagnostic reasoning between body parts, lesion attributes, and diseases.  ","cats":{"new-dataset":0}}
{"text":"Extensive experiments on three different datasets consistently demonstrate the state-of-the-art recognition performance of the proposed approach.","cats":{"new-dataset":0}}
{"text":"To stimulate research in this exciting area, we present LOAF, the first large-scale overhead fisheye dataset for person detection and localization.","cats":{"new-dataset":1}}
{"text":"it contains currently the largest number of annotated pedestrian, i.e., 457K bounding boxes with groundtruth location information","cats":{"new-dataset":1}}
{"text":"Location determination finds wide applications in daily life.","cats":{"new-dataset":0}}
{"text":"Instead of existing efforts devoted to localizing tourist photos captured by perspective cameras, in this article, we focus on devising person positioning solutions using overhead fisheye cameras.","cats":{"new-dataset":0}}
{"text":"Such solutions are advantageous in large field of view (FOV), low cost, anti-occlusion, and unaggressive work mode (without the necessity of cameras carried by persons).","cats":{"new-dataset":0}}
{"text":"However, related studies are quite scarce, due to the paucity of data.  ","cats":{"new-dataset":0}}
{"text":"LOAF is built with many essential features, e.g., i) the data cover abundant diversities in scenes, human pose, density, and location; ii) it contains currently the largest number of annotated pedestrian, i.e., 457K bounding boxes with groundtruth location information; iii) the body-boperson detection network, which exploits the fisheye distortions by a rotation-equivariant training strategy and predict radius-aligned human boxes end-to-end.","cats":{"new-dataset":0}}
{"text":"Then, the actual locations of the detected persons are calculated by a numerical solution on the fisheye model and camera altitude data.","cats":{"new-dataset":0}}
{"text":"Extensive experiments on LOAF validate the superiority of our fisheye detector w.r.t.","cats":{"new-dataset":0}}
{"text":"previous methods, and show that our whole fisheye positioning solution is able to locate all persons in FOV with an accuracy of 0.5 m, within 0.1 s.","cats":{"new-dataset":0}}
{"text":"Hand trajectory forecasting from egocentric views is crucial for enabling a prompt understanding of human intentions when interacting with AR/VR systems.","cats":{"new-dataset":0}}
{"text":"However, existing methods handle this problem in a 2D image space which is inadequate for 3D real-world applications.","cats":{"new-dataset":0}}
{"text":"In this paper, we set up an egocentric 3D hand trajectory forecasting task that aims to predict hand trajectories in a 3D space from early observed RGB videos in a first-person view.","cats":{"new-dataset":0}}
{"text":"To fulfill this goal, we propose an uncertainty-aware state space Transformer (USST) that takes the merits of the attention mechanism and aleatoric uncertainty within the framework of the classical state-space model.","cats":{"new-dataset":0}}
{"text":"The model can be further enhanced by the velocity constraint and visual prompt tuning (VPT) on large vision transformers.","cats":{"new-dataset":0}}
{"text":"Moreover, we develop an annotation workflow to collect 3D hand trajectories with high quality.","cats":{"new-dataset":0}}
{"text":"Experimental results on H2O and EgoPAT3D datasets demonstrate the superiority of USST for both 2D and 3D trajectory forecasting.","cats":{"new-dataset":0}}
{"text":"The code and datasets are publicly released: https://github.com/Cogito2012/USST.","cats":{"new-dataset":0}}
{"text":"We also build a stereo visual acquisition system composed of an event camera and an RGB-D camera to collect a new Stereo Event-Intensity Dataset (SEID) containing diverse scenes with complex motions and varying depths.","cats":{"new-dataset":1}}
{"text":"The stereo event-intensity camera setup is widely applied to leverage the advantages of both event cameras with low latency and intensity cameras that capture accurate brightness and texture information.","cats":{"new-dataset":0}}
{"text":"However, such a setup commonly encounters cross-modality parallax that is difficult to be eliminated solely with stereo rectification especially for real-world scenes with complex motions and varying depths, posing artifacts and distortion for existing Event-based Video Frame Interpolation (E-VFI) approaches.","cats":{"new-dataset":0}}
{"text":"To tackle this problem, we propose a novel Stereo Event-based VFI (SE-VFI) network (SEVFI-Net) to generate high-quality intermediate frames and corresponding disparities from misaligned inputs consisting of two consecutive keyframes and event streams emitted between them.","cats":{"new-dataset":0}}
{"text":"Specifically, we propose a Feature Aggregation Module (FAM) to alleviate the parallax and achieve spatial alignment in the feature domain.","cats":{"new-dataset":0}}
{"text":"We then exploit the fused features accomplishing accurate optical flow and disparity estimation, and achieving better interpolated results through flow-based and synthesis-based ways.  Experiments on public real-world stereo datasets, i.e., DSEC and MVSEC, and our SEID dataset demonstrate that our proposed SEVFI-Net outperforms state-of-the-art methods by a large margin.","cats":{"new-dataset":0}}
{"text":"We evaluated the framework with five Python and Java code generation models and six prompt datasets, including a newly created one in this work (SOEval).","cats":{"new-dataset":1}}
{"text":"In recent years, the use of automated source code generation utilizing transformer-based generative models has expanded, and these models can generate functional code according to the requirements of the developers.","cats":{"new-dataset":0}}
{"text":"However, recent research revealed that these automatically generated source codes can contain vulnerabilities and other quality issues.","cats":{"new-dataset":0}}
{"text":"Despite researchers' and practitioners' attempts to enhance code generation models, retraining and fine-tuning large language models is time-consuming and resource-intensive.","cats":{"new-dataset":0}}
{"text":"Thus, we describe FRANC, a lightweight framework for recommending more secure and high-quality source code derived from transformer-based code generation models.","cats":{"new-dataset":0}}
{"text":"FRANC includes a static filter to make the generated code compilable with heuristics and a quality-aware ranker to sort the code snippets based on a quality score.","cats":{"new-dataset":0}}
{"text":"Moreover, the framework uses prompt engineering to fix persistent quality issues.  ","cats":{"new-dataset":0}}
{"text":"The static filter improves 9% to 46% Java suggestions and 10% to 43% Python suggestions regarding compilability.","cats":{"new-dataset":0}}
{"text":"The average improvement over the NDCG@10 score for the ranking system is 0.0763, and the repairing techniques repair the highest 80% of prompts.","cats":{"new-dataset":0}}
{"text":"FRANC takes, on average, 1.98 seconds for Java; for Python, it takes 0.08 seconds.","cats":{"new-dataset":0}}
{"text":"Lane detection plays a pivotal role in the field of autonomous vehicles and advanced driving assistant systems (ADAS).","cats":{"new-dataset":0}}
{"text":"Over the years, numerous algorithms have emerged, spanning from rudimentary image processing techniques to sophisticated deep neural networks.","cats":{"new-dataset":0}}
{"text":"The performance of deep learning-based models is highly dependent on the quality of their training data.","cats":{"new-dataset":0}}
{"text":"Consequently, these models often experience a decline in performance when confronted with challenging scenarios such as extreme lighting conditions, partially visible lane markings, and sparse lane markings like Botts' dots.","cats":{"new-dataset":0}}
{"text":"To address this, we present an end-to-end lane detection and classification system based on deep learning methodologies.","cats":{"new-dataset":0}}
{"text":"In our study, we introduce a unique dataset meticulously curated to encompass scenarios that pose significant challenges for state-of-the-art (SOTA) models.","cats":{"new-dataset":0}}
{"text":"Through fine-tuning selected models, we aim to achieve enhanced localization accuracy.","cats":{"new-dataset":0}}
{"text":"Moreover, we propose a CNN-based classification branch, seamlessly integrated with the detector, facilitating the identification of distinct lane types.","cats":{"new-dataset":0}}
{"text":"This architecture enables informed lane-changing decisions and empowers more resilient ADAS capabilities.","cats":{"new-dataset":0}}
{"text":"We also investigate the effect of using mixed precision training and testing on different models and batch sizes.","cats":{"new-dataset":0}}
{"text":"Experimental evaluations conducted on the widely-used TuSimple dataset, Caltech lane dataset, and our LVLane dataset demonstrate the effectiveness of our model in accurately detecting and classifying lanes amidst challenging scenarios.","cats":{"new-dataset":0}}
{"text":"Our method achieves state-of-the-art classification results on the TuSimple dataset.","cats":{"new-dataset":0}}
{"text":"The code of the work will be published upon the acceptance of the paper.","cats":{"new-dataset":0}}
{"text":"In today's highly connected society, we are constantly asked to provide personal information to retailers, voter surveys, medical professionals, and other data collection efforts.","cats":{"new-dataset":0}}
{"text":"The collected data is stored in large data warehouses.","cats":{"new-dataset":0}}
{"text":"Organisations and statistical agencies share and use this data to facilitate research in public health, economics, sociology, etc.","cats":{"new-dataset":0}}
{"text":"However, this data contains sensitive information about individuals, which can result in identity theft, financial loss, stress and depression, embarrassment, abuse, etc.","cats":{"new-dataset":0}}
{"text":"Therefore, one must ensure rigorous management of individuals' privacy.","cats":{"new-dataset":0}}
{"text":"We propose, an advanced data privacy management architecture composed of three layers.","cats":{"new-dataset":0}}
{"text":"The data management layer consists of de-identification and anonymisation, the access management layer for re-enforcing data access based on the concepts of Role-Based Access Control and the Chinese Wall Security Policy, and the roles layer for regulating different users.","cats":{"new-dataset":0}}
{"text":"The proposed system architecture is validated on healthcare datasets.","cats":{"new-dataset":0}}
{"text":"Answer selection in open-domain dialogues aims to select an accurate answer from candidates.","cats":{"new-dataset":0}}
{"text":"Recent success of answer selection models hinges on training with large amounts of labeled data.","cats":{"new-dataset":0}}
{"text":"However, collecting large-scale labeled data is labor-intensive and time-consuming.","cats":{"new-dataset":0}}
{"text":"In this paper, we introduce the predicted intent labels to calibrate answer labels in a self-training paradigm.","cats":{"new-dataset":0}}
{"text":"Specifically, we propose the intent-calibrated self-training (ICAST) to improve the quality of pseudo answer labels through the intent-calibrated answer selection paradigm, in which we employ pseudo intent labels to help improve pseudo answer labels.","cats":{"new-dataset":0}}
{"text":"We carry out extensive experiments on two benchmark datasets with open-domain dialogues.","cats":{"new-dataset":0}}
{"text":"The experimental results show that ICAST outperforms baselines consistently with 1%, 5% and 10% labeled data.","cats":{"new-dataset":0}}
{"text":"Specifically, it improves 2.06% and 1.00% of F1 score on the two datasets, compared with the strongest baseline with only 5% labeled data.","cats":{"new-dataset":0}}
{"text":"Indirect surveys, in which respondents provide information about other people they know, have been proposed for scenarios where privacy is important or where the population to be surveyed is hard to reach.","cats":{"new-dataset":0}}
{"text":"As an example, during various stages of the COVID-19 pandemic surveys, including indirect surveys, have been used to estimate the number of cases or the level of vaccination.","cats":{"new-dataset":0}}
{"text":"The Network Scale-up Method (NSUM) is the classical approach to developing such estimates but was designed with discrete, time-limited indirect surveys in mind.","cats":{"new-dataset":0}}
{"text":"Further, it requires asking for or estimating the number of individuals in each respondent's network.","cats":{"new-dataset":0}}
{"text":"In recent years, surveys are being increasingly deployed online and collecting data continuously (e.g., COVID-19 surveys on Facebook during much of the pandemic).","cats":{"new-dataset":0}}
{"text":"Conventional NSUM can be applied to these scenarios by analyzing the data independently during each time interval, but this misses the opportunity of leveraging the temporal dimension.","cats":{"new-dataset":0}}
{"text":"Understanding the advantage of simply smoothing NSUM results to various degrees is not trivial.","cats":{"new-dataset":0}}
{"text":"We propose to use the responses from indirect surveys collected over time and develop analytical tools (i) to prove that indirect surveys can be used to provide better estimates for the size of the hidden population compared to direct surveys, and (ii) to identify appropriate aggregations over time to further improve the estimates.","cats":{"new-dataset":0}}
{"text":"We demonstrate through simulations that our approach outperforms traditional NSUM and direct surveying methods to estimate the size of a time-varying hidden population.","cats":{"new-dataset":0}}
{"text":"We also demonstrate the superiority of our approach on an existing indirect survey dataset on COVID-19 confirmed cases.","cats":{"new-dataset":0}}
{"text":"[Context] Systematic Literature Review (SLR) has been a major type of study published in Software Engineering (SE) venues for about two decades.","cats":{"new-dataset":0}}
{"text":"However, there is a lack of understanding of whether an SLR is really needed in comparison to a more conventional literature review.","cats":{"new-dataset":0}}
{"text":"Very often, SE researchers embark on an SLR with such doubts.","cats":{"new-dataset":0}}
{"text":"We aspire to provide more understanding of when an SLR in SE should be conducted.","cats":{"new-dataset":0}}
{"text":"[Objective] The first step of our investigation was focused on the dataset, i.e., the reviewed papers, in an SLR, which indicates the development of a research topic or area.","cats":{"new-dataset":0}}
{"text":"The objective of this step is to provide a better understanding of the characteristics of the datasets of SLRs in SE.","cats":{"new-dataset":0}}
{"text":"[Method] A research synthesis was conducted on a sample of 170 SLRs published in top-tier SE journals.","cats":{"new-dataset":0}}
{"text":"We extracted and analysed the quantitative attributes of the datasets of these SLRs.","cats":{"new-dataset":0}}
{"text":"[Results]","cats":{"new-dataset":0}}
{"text":"The findings show that the median size of the datasets in our sample is 57 reviewed papers, and the median review period covered is 14 years.","cats":{"new-dataset":0}}
{"text":"The number of reviewed papers and review period have a very weak and non-significant positive correlation.","cats":{"new-dataset":0}}
{"text":"[Conclusions] The results of our study can be used by SE researchers as an indicator or benchmark to understand whether an SLR is conducted at a good time.","cats":{"new-dataset":0}}
{"text":"OCR (Optical Character Recognition) is a technology that offers comprehensive alphanumeric recognition of handwritten and printed characters at electronic speed by merely scanning the document.","cats":{"new-dataset":0}}
{"text":"Recently, the understanding of visual data has been termed Intelligent Character Recognition (ICR).","cats":{"new-dataset":0}}
{"text":"Intelligent Character Recognition (ICR) is the OCR module that can convert scans of handwritten or printed characters into ASCII text.","cats":{"new-dataset":0}}
{"text":"ASCII data is the standard format for data encoding in electronic communication.","cats":{"new-dataset":0}}
{"text":"ASCII assigns standard numeric values to letters, numeral, symbols, white-spaces and other characters.","cats":{"new-dataset":0}}
{"text":"In more technical terms, OCR is the process of using an electronic device to transform 2-Dimensional textual information into machine-encoded text.","cats":{"new-dataset":0}}
{"text":"Anything that contains text both machine written or handwritten can be scanned either through a scanner or just simply a picture of the text is enough for the recognition system to distinguish the text.","cats":{"new-dataset":0}}
{"text":"The goal of this papers is to show the results of a Convolutional Neural Network model which has been trained on National Institute of Science and Technology (NIST) dataset containing over a 100,000 images.","cats":{"new-dataset":0}}
{"text":"The network learns from the features extracted from the images and use it to generate the probability of each class to which the picture belongs to.","cats":{"new-dataset":0}}
{"text":"We have achieved an accuracy of 90.54% with a loss of 2.53%.","cats":{"new-dataset":0}}
{"text":"We compare the performance of three nearest neighbor search algorithms: the Orchard, ball tree, and VP-tree algorithms.","cats":{"new-dataset":0}}
{"text":"These algorithms are commonly used for nearest-neighbor searches and are known for their efficiency in large datasets.","cats":{"new-dataset":0}}
{"text":"We analyze the fraction of distances computed in relation to the size of the dataset and its dimension.","cats":{"new-dataset":0}}
{"text":"For each algorithm we derive a fitting function for the efficiency as a function to set size and dimension.","cats":{"new-dataset":0}}
{"text":"The article aims to provide a comprehensive analysis of the performance of these algorithms and help researchers and practitioners choose the best algorithm for their specific application.","cats":{"new-dataset":0}}
{"text":"In order to broaden the application and research of anomaly detection in unmanned supermarkets and smart manufacturing, we introduce the supermarket goods anomaly detection (GoodsAD) dataset","cats":{"new-dataset":1}}
{"text":"It contains 6124 high-resolution images of 484 different appearance goods divided into 6 categories","cats":{"new-dataset":1}}
{"text":"This is a comprehensive, multi-object dataset for supermarket goods anomaly detection that focuses on real-world applications.","cats":{"new-dataset":0}}
{"text":"Visual anomaly detection is essential and commonly used for many tasks in the field of computer vision.","cats":{"new-dataset":0}}
{"text":"Recent anomaly detection datasets mainly focus on industrial automated inspection, medical image analysis and video surveillance. .","cats":{"new-dataset":0}}
{"text":"It contains 6124 high-resolution images of 484 different appearance goods divided into 6 categories.","cats":{"new-dataset":0}}
{"text":"Each category contains several common different types of anomalies such as deformation, s the unsupervised setting and only normal (defect-free) images are used for training.","cats":{"new-dataset":0}}
{"text":"Pixel-precise ground truth regions are provided for all anomalies.","cats":{"new-dataset":0}}
{"text":"Moreover, we also conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods.","cats":{"new-dataset":0}}
{"text":"This initial benchmark indicates that some methods which perform well on the industrial anomaly detection dataset (e.g., MVTec AD), show poor performance on our dataset.","cats":{"new-dataset":0}}
{"text":"We also made available all the synthetic data generated in this work for the 18 different datasets in the BEIR benchmark which took more than 2,000 GPU hours to be generated as well as the reranker models finetuned on the synthetic data.","cats":{"new-dataset":1}}
{"text":"Recent work has explored Large Language Models (LLMs) to overcome the lack of training data for Information Retrieval (IR) tasks.","cats":{"new-dataset":0}}
{"text":"The generalization abilities of these models have enabled the creation of synthetic in-domain data by providing instructions and a few examples on a prompt.","cats":{"new-dataset":0}}
{"text":"InPars and Promptagator have pioneered this approach and both methods have demonstrated the potential of using LLMs as synthetic data generators for IR tasks.","cats":{"new-dataset":0}}
{"text":"This makes them an attractive solution for IR tasks that suffer from a lack of annotated data.","cats":{"new-dataset":0}}
{"text":"However, the reproducibility of these methods was limited, because InPars' training scripts are based on TPUs -- which are not widely accessible -- and because the code for Promptagator was not released and its proprietary LLM is not publicly accessible.","cats":{"new-dataset":0}}
{"text":"To fully realize the potential of these methods and make their impact more widespread in the research community, the resources need to be accessible and easy to reproduce by researchers and practitioners.","cats":{"new-dataset":0}}
{"text":"Our main contribution is a unified toolkit for end-to-end reproducible synthetic data generation research, which includes generation, filtering, training and evaluation.","cats":{"new-dataset":0}}
{"text":"Additionally, we provide an interface to IR libraries widely used by the community and support for GPU.","cats":{"new-dataset":0}}
{"text":"Our toolkit not only reproduces the InPars method and partially reproduces Promptagator, but also provides a plug-and-play functionality allowing the use of different LLMs, exploring filtering methods and finetuning various reranker models on the generated data.  ","cats":{"new-dataset":0}}
{"text":"Code and data are available at https://github.com/zetaalphavector/InPars","cats":{"new-dataset":0}}
{"text":"Adversarial attacks have the potential to mislead deep neural network classifiers by introducing slight perturbations.","cats":{"new-dataset":0,"ml-security":1}}
{"text":"Developing algorithms that can mitigate the effects of these attacks is crucial for ensuring the safe use of artificial intelligence.","cats":{"new-dataset":0}}
{"text":"Recent studies have suggested that score-based diffusion models are effective in adversarial defenses.","cats":{"new-dataset":0}}
{"text":"However, existing diffusion-based defenses rely on the sequential simulation of the reversed stochastic differential equations of diffusion models, which are computationally inefficient and yield suboptimal results.","cats":{"new-dataset":0}}
{"text":"In this paper, we introduce a novel adversarial defense scheme named ScoreOpt, which optimizes adversarial samples at test-time, towards original clean data in the direction guided by score-based priors.","cats":{"new-dataset":0}}
{"text":"We conduct comprehensive experiments on multiple datasets, including CIFAR10, CIFAR100 and ImageNet.","cats":{"new-dataset":0}}
{"text":"Our experimental results demonstrate that our approach outperforms existing adversarial defenses in terms of both robustness performance and inference speed.","cats":{"new-dataset":0}}
{"text":"To overcome these limitations, we build a new challenging benchmark named KoRc in this paper","cats":{"new-dataset":1}}
{"text":"Deep text understanding, which requires the connections between a given document and prior knowledge beyond its text, has been highlighted by many benchmarks in recent years.","cats":{"new-dataset":0}}
{"text":"However, these benchmarks have encountered two major limitations.","cats":{"new-dataset":0}}
{"text":"On the one hand, most of them require human annotation of knowledge, which leads to limited knowledge coverage.","cats":{"new-dataset":0}}
{"text":"On the other hand, they usually use choices or spans in the texts as the answers, which results in narrow answer space. .","cats":{"new-dataset":0}}
{"text":"Compared with previous benchmarks, KoRC has two advantages, i.e., broad knowledge coverage and flexible answer format.","cats":{"new-dataset":0}}
{"text":"Specifically, we utilize massive knowledge bases to guide annotators or large language models (LLMs) to construct knowledgable questions.","cats":{"new-dataset":0}}
{"text":"Moreover, we use labels in knowledge bases rather than spans or choices as the final answers.","cats":{"new-dataset":0}}
{"text":"We test state-of-the-art models on KoRC and the experimental results show that the strongest baseline only achieves 68.3% and 30.0% F1 measure in the in-distribution and out-of-distribution test set, respectively.","cats":{"new-dataset":0}}
{"text":"These results indicate that deep text understanding is still an unsolved challenge.","cats":{"new-dataset":0}}
{"text":"The benchmark dataset, leaderboard, and baseline methods are released in https://github.com/","cats":{"new-dataset":0}}
{"text":"Schema discovery is an important aspect to working with data in formats such as JSON.","cats":{"new-dataset":0}}
{"text":"Unlike relational databases, JSON data sets often do not have associated structural information.","cats":{"new-dataset":0}}
{"text":"Consumers of such datasets are often left to browse through data in an attempt to observe commonalities in structure across documents to construct suitable code for data processing.","cats":{"new-dataset":0}}
{"text":"However, this process is time-consuming and error-prone.","cats":{"new-dataset":0}}
{"text":"Existing distributed approaches to mining schemas present a significant usability advantage as they provide useful metadata for large data sources.","cats":{"new-dataset":0}}
{"text":"However, depending on the data source, ad hoc queries for estimating other properties to help with crafting an efficient data pipeline can be expensive.","cats":{"new-dataset":0}}
{"text":"We propose JSONoid, a distributed schema discovery process augmented with additional metadata in the form of monoid data structures that are easily maintainable in a distributed setting.","cats":{"new-dataset":0}}
{"text":"JSONoid subsumes several existing approaches to distributed schema discovery with similar performance.","cats":{"new-dataset":0}}
{"text":"Our approach also adds significant useful additional information about data values to discovered schemas with linear scalability.","cats":{"new-dataset":0}}
{"text":"Scientific publications follow conventionalized rhetorical structures.","cats":{"new-dataset":0}}
{"text":"Classifying the Argumentative Zone (AZ), e.g., identifying whether a sentence states a Motivation, a Result or Background information, has been proposed to improve processing of scholarly documents.","cats":{"new-dataset":0}}
{"text":"In this work, we adapt and extend this idea to the domain of materials science research.  ","cats":{"new-dataset":0}}
{"text":"We detail corpus statistics and demonstrate high inter-annotator agreement.","cats":{"new-dataset":0,"data-quality":0}}
{"text":"Our computational experiments show that using domain-specific pre-trained transformer-based text encoders is key to high classification performance.","cats":{"new-dataset":0}}
{"text":"We also find that AZ categories from existing datasets in other domains are transferable to varying degrees.","cats":{"new-dataset":0}}
{"text":"One of the key problems in 3D object detection is to reduce the accuracy gap between methods based on LiDAR sensors and those based on monocular cameras.","cats":{"new-dataset":0}}
{"text":"A recently proposed framework for monocular 3D detection based on Pseudo-Stereo has received considerable attention in the community.","cats":{"new-dataset":0}}
{"text":"However, so far these two problems are discovered in existing practices, including (1) monocular depth estimation and Pseudo-Stereo detector must be trained separately, (2) Difficult to be compatible with different stereo detectors and (3) the overall calculation is large, which affects the reasoning speed.","cats":{"new-dataset":0}}
{"text":"In this work, we propose an end-to-end, efficient pseudo-stereo 3D detection framework by introducing a Single-View Diffusion Model (SVDM) that uses a few iterations to gradually deliver right informative pixels to the left image.","cats":{"new-dataset":0}}
{"text":"SVDM allows the entire pseudo-stereo 3D detection pipeline to be trained end-to-end and can benefit from the training of stereo detectors.","cats":{"new-dataset":0}}
{"text":"Afterwards, we further explore the application of SVDM in depth-free stereo 3D detection, and the final framework is compatible with most stereo detectors.","cats":{"new-dataset":0}}
{"text":"We consider the problem of learning a sparse graph underlying an undirected Gaussian graphical model, a key problem in statistical machine learning.","cats":{"new-dataset":0}}
{"text":"Given $n$ samples from a multivariate Gaussian distribution with $p$ variables, the goal is to estimate the $p \\times p$ inverse covariance matrix (aka precision matrix), assuming it is sparse (i.e., has a few nonzero entries).","cats":{"new-dataset":0}}
{"text":"We propose GraphL0BnB, a new estimator based on an $\\ell_0$-penalized version of the pseudolikelihood function, while most earlier approaches are based on the $\\ell_1$-relaxation.","cats":{"new-dataset":0}}
{"text":"Our estimator can be formulated as a convex mixed integer program (MIP) which can be difficult to compute at scale using off-the-shelf commercial solvers.","cats":{"new-dataset":0}}
{"text":"To solve the MIP, we propose a custom nonlinear branch-and-bound (BnB) framework that solves node relaxations with tailored first-order methods.","cats":{"new-dataset":0}}
{"text":"As a by-product of our BnB framework, we propose large-scale solvers for obtaining good primal solutions that are of independent interest.","cats":{"new-dataset":0}}
{"text":"We derive novel statistical guarantees (estimation and variable selection) for our estimator and discuss how our approach improves upon existing estimators.","cats":{"new-dataset":0}}
{"text":"Our numerical experiments on real/synthetic datasets suggest that our method can solve, to near-optimality, problem instances with $p = 10^4$ -- corresponding to a symmetric matrix of size $p \\times p$ with $p^2/2$ binary variables.","cats":{"new-dataset":0}}
{"text":"We demonstrate the usefulness of GraphL0BnB versus various state-of-the-art approaches on a range of datasets.","cats":{"new-dataset":0}}
{"text":"Trajectory data collection is a common task with many applications in our daily lives.","cats":{"new-dataset":0}}
{"text":"Analyzing trajectory data enables service providers to enhance their services, which ultimately benefits users.","cats":{"new-dataset":0}}
{"text":"However, directly collecting trajectory data may give rise to privacy-related issues that cannot be ignored.","cats":{"new-dataset":0}}
{"text":"Local differential privacy (LDP), as the de facto privacy protection standard in a decentralized setting, enables users to perturb their trajectories locally and provides a provable privacy guarantee.","cats":{"new-dataset":0}}
{"text":"Existing approaches to private trajectory data collection in a local setting typically use relaxed versions of LDP, which cannot provide a strict privacy guarantee, or require some external knowledge that is impractical to obtain and update in a timely manner.","cats":{"new-dataset":0}}
{"text":"To tackle these problems, we propose a novel trajectory perturbation mechanism that relies solely on an underlying location set and satisfies pure $\\epsilon$-LDP to provide a stringent privacy guarantee.","cats":{"new-dataset":0}}
{"text":"In the proposed mechanism, each point's adjacent direction information in the trajectory is used in its perturbation process.","cats":{"new-dataset":0}}
{"text":"Such information serves as an effective clue to connect neighboring points and can be used to restrict the possible region of a perturbed point in order to enhance utility.","cats":{"new-dataset":0}}
{"text":"To the best of our knowledge, our study is the first to use direction information for trajectory perturbation under LDP.","cats":{"new-dataset":0}}
{"text":"Furthermore, based on this mechanism, we present an anchor-based method that adaptively restricts the region of each perturbed trajectory, thereby significantly boosting performance without violating the privacy constraint.","cats":{"new-dataset":0}}
{"text":"Extensive experiments on both real-world and synthetic datasets demonstrate the effectiveness of the proposed mechanisms.","cats":{"new-dataset":0}}
{"text":"In safety-critical classification tasks, conformal prediction allows to perform rigorous uncertainty quantification by providing confidence sets including the true class with a user-specified probability.","cats":{"new-dataset":0}}
{"text":"This generally assumes the availability of a held-out calibration set with access to ground truth labels.","cats":{"new-dataset":0}}
{"text":"Unfortunately, in many domains, such labels are difficult to obtain and usually approximated by aggregating expert opinions.","cats":{"new-dataset":0}}
{"text":"In fact, this holds true for almost all datasets, including well-known ones such as CIFAR and ImageNet.","cats":{"new-dataset":0}}
{"text":"Applying conformal prediction using such labels underestimates uncertainty.","cats":{"new-dataset":0}}
{"text":"Indeed, when expert opinions are not resolvable, there is inherent ambiguity present in the labels.","cats":{"new-dataset":0}}
{"text":"That is, we do not have ``crisp'', definitive ground truth labels and this uncertainty should be taken into account during calibration.","cats":{"new-dataset":0}}
{"text":"In this paper, we develop a conformal prediction framework for such ambiguous ground truth settings which relies on an approximation of the underlying posterior distribution of labels given inputs.","cats":{"new-dataset":0}}
{"text":"We demonstrate our methodology on synthetic and real datasets, including a case study of skin condition classification in dermatology.","cats":{"new-dataset":0}}
{"text":"In order to implement the pretraining phase, we curated an expansive tabular dataset comprising approximately 13 billion samples, meticulously gathered from the Kaggle platform.","cats":{"new-dataset":1}}
{"text":"Recent advancements in Natural Language Processing (NLP) have witnessed the groundbreaking impact of pretrained models, yielding impressive outcomes across various tasks.","cats":{"new-dataset":0}}
{"text":"This study seeks to extend the power of pretraining methodologies to tabular data, a domain traditionally overlooked, yet inherently challenging due to the plethora of table schemas intrinsic to different tasks.","cats":{"new-dataset":0}}
{"text":"The primary research questions underpinning this work revolve around the adaptation to heterogeneous table structures, the establishment of a universal pretraining protocol for tabular data, the generalizability and transferability of learned knowledge across tasks, the adaptation to diverse downstream applications, and the incorporation of incremental columns over time.","cats":{"new-dataset":0}}
{"text":"In response to these challenges, we introduce UniTabE, a pioneering method designed to process tables in a uniform manner, devoid of constraints imposed by specific table structures.","cats":{"new-dataset":0}}
{"text":"UniTabE's core concept relies on representing each basic table element with a module, termed TabUnit.","cats":{"new-dataset":0}}
{"text":"This is subsequently followed by a Transformer encoder to refine the representation.","cats":{"new-dataset":0}}
{"text":"Moreover, our model is designed to facilitate pretraining and finetuning through the utilization of free-form prompts.  ","cats":{"new-dataset":0}}
{"text":"Rigorous experimental testing and analyses were performed under a myriad of scenarios to validate the effectiveness of our methodology.","cats":{"new-dataset":0}}
{"text":"The experimental results demonstrate UniTabE's superior performance against several baseline models across a multitude of benchmark datasets.","cats":{"new-dataset":0}}
{"text":"This, therefore, underscores UniTabE's potential to significantly enhance the semantic representation of tabular data, thereby marking a significant stride in the field of tabular data analysis.","cats":{"new-dataset":0}}
{"text":"Large-scale online recommender system spreads all over the Internet being in charge of two basic tasks: Click-Through Rate (CTR) and Post-Click Conversion Rate (CVR) estimations.","cats":{"new-dataset":0}}
{"text":"However, traditional CVR estimators suffer from well-known Sample Selection Bias and Data Sparsity issues.","cats":{"new-dataset":0}}
{"text":"Entire space models were proposed to address the two issues via tracing the decision-making path of \"exposure_click_purchase\".","cats":{"new-dataset":0}}
{"text":"Further, some researchers observed that there are purchase-related behaviors between click and purchase, which can better draw the user's decision-making intention and improve the recommendation performance.","cats":{"new-dataset":0}}
{"text":"Thus, the decision-making path has been extended to \"exposure_click_in-shop action_purchase\" and can be modeled with conditional probability approach.","cats":{"new-dataset":0}}
{"text":"Nevertheless, we observe that the chain rule of conditional probability does not always hold.","cats":{"new-dataset":0}}
{"text":"We report Probability Space Confusion (PSC) issue and give a derivation of difference between ground-truth and estimation mathematically.","cats":{"new-dataset":0}}
{"text":"We propose a novel Entire Space Multi-Task Model for Post-Click Conversion Rate via Parameter Constraint (ESMC) and two alternatives: Entire Space Multi-Task Model with Siamese Network (ESMS) and Entire Space Multi-Task Model in Global Domain (ESMG) to address the PSC issue.","cats":{"new-dataset":0}}
{"text":"Specifically, we handle \"exposure_click_in-shop action\" and \"in-shop action_purchase\" separately in the light of characteristics of in-shop action.","cats":{"new-dataset":0}}
{"text":"The first path is still treated with conditional probability while the second one is treated with parameter constraint strategy.","cats":{"new-dataset":0}}
{"text":"Experiments on both offline and online environments in a large-scale recommendation system illustrate the superiority of our proposed methods over state-of-the-art models.","cats":{"new-dataset":0}}
{"text":"This paper proposes a new SOD dataset consisting of 39,070 images including 137,121 bird instances, which is called the Small Object Detection for Spotting Birds (SOD4SB) dataset","cats":{"new-dataset":1}}
{"text":"The dataset, the baseline code, and the website for evaluation on the public testset are publicly available.","cats":{"new-dataset":0}}
{"text":"Small Object Detection (SOD) is an important machine vision topic because (i) a variety of real-world applications require object detection for distant objects and (ii) SOD is a challenging task due to the noisy, blurred, and less-informative image appearances of small objects. .","cats":{"new-dataset":0}}
{"text":"The detail of the challenge with the SOD4SB dataset is introduced in this paper.","cats":{"new-dataset":0}}
{"text":"In total, 223 participants joined this challenge.","cats":{"new-dataset":0}}
{"text":"This paper briefly introduces the award-winning methods.","cats":{"new-dataset":0}}
{"text":"The goal of Text-to-image person retrieval is to retrieve person images from a large gallery that match the given textual descriptions.","cats":{"new-dataset":0}}
{"text":"The main challenge of this task lies in the significant differences in information representation between the visual and textual modalities.","cats":{"new-dataset":0}}
{"text":"The textual modality conveys abstract and precise information through vocabulary and grammatical structures, while the visual modality conveys concrete and intuitive information through images.","cats":{"new-dataset":0}}
{"text":"To fully leverage the expressive power of textual representations, it is essential to accurately map abstract textual descriptions to specific images.   ","cats":{"new-dataset":0}}
{"text":"To address this issue, we propose a novel framework to Unleash the Imagination of Text (UIT) in text-to-image person retrieval, aiming to fully explore the power of words in sentences.","cats":{"new-dataset":0}}
{"text":"Specifically, the framework employs the pre-trained full CLIP model as a dual encoder for the images and texts , taking advantage of prior cross-modal alignment knowledge.","cats":{"new-dataset":0}}
{"text":"The Text-guided Image Restoration auxiliary task is proposed with the aim of implicitly mapping abstract textual entities to specific image regions, facilitating alignment between textual and visual embeddings.","cats":{"new-dataset":0}}
{"text":"Additionally, we introduce a cross-modal triplet loss tailored for handling hard samples, enhancing the model's ability to distinguish minor differences.   ","cats":{"new-dataset":0}}
{"text":"To focus the model on the key components within sentences, we propose a novel text data augmentation technique.","cats":{"new-dataset":0}}
{"text":"Diffusion MRI tractography parcellation classifies streamlines into anatomical fiber tracts to enable quantification and visualization for clinical and scientific applications.","cats":{"new-dataset":0}}
{"text":"Current tractography parcellation methods rely heavily on registration, but registration inaccuracies can affect parcellation and the computational cost of registration is high for large-scale datasets.","cats":{"new-dataset":0}}
{"text":"Recently, deep-learning-based methods have been proposed for tractography parcellation using various types of representations for streamlines.","cats":{"new-dataset":0}}
{"text":"However, these methods only focus on the information from a single streamline, ignoring geometric relationships between the streamlines in the brain.","cats":{"new-dataset":0}}
{"text":"We propose TractCloud, a registration-free framework that performs whole-brain tractography parcellation directly in individual subject space.","cats":{"new-dataset":0}}
{"text":"We propose a novel, learnable, local-global streamline representation that leverages information from neighboring and whole-brain streamlines to describe the local anatomy and global pose of the brain.","cats":{"new-dataset":0}}
{"text":"We train our framework on a large-scale labeled tractography dataset, which we augment by applying synthetic transforms including rotation, scaling, and translations.","cats":{"new-dataset":0}}
{"text":"We test our framework on five independently acquired datasets across populations and health conditions.","cats":{"new-dataset":0}}
{"text":"TractCloud significantly outperforms several state-of-the-art methods on all testing datasets.","cats":{"new-dataset":0}}
{"text":"TractCloud achieves efficient and consistent whole-brain white matter parcellation across the lifespan (from neonates to elderly subjects, including brain tumor patients) without the need for registration.","cats":{"new-dataset":0}}
{"text":"The robustness and high inference speed of TractCloud make it suitable for large-scale tractography data analysis.","cats":{"new-dataset":0}}
{"text":"Our project page is available at https://tractcloud.github.io/.","cats":{"new-dataset":0}}
{"text":"The AgBioData Consortium (https://www.agbiodata.org/) currently represents 44 databases and resources covering model or crop plant and animal GGB data, ontologies, pathways, genetic variation and breeding platforms (referred to as 'databases' throughout).","cats":{"new-dataset":1}}
{"text":"Over the last several decades, there has been rapid growth in the number and scope of agricultural genetics, genomics and breeding (GGB) databases and resources.  ","cats":{"new-dataset":0}}
{"text":"One of the goals of the Consortium is to facilitate FAIR (Findable, Accessible, Interoperable, and Reusable) data management and the integration of datasets which requires data sharing, along with structured vocabularies and/or ontologies.","cats":{"new-dataset":0}}
{"text":"Two AgBioData working groups, focused on Data Sharing and Ontologies, conducted a survey to assess the status and future needs of the members in those areas.","cats":{"new-dataset":0}}
{"text":"A total of 33 researchers responded to the survey, representing 37 databases.","cats":{"new-dataset":0}}
{"text":"Results suggest that data sharing practices by AgBioData databases are in a healthy state, but it is not clear whether this is true for all metadata and data types across all databases; and that ontology use has not substantially changed since a similar survey was conducted in 2017.","cats":{"new-dataset":0}}
{"text":"We recommend 1) providing training for database personnel in specific data sharing techniques, as well as in ontology use; 2) further study on what metadata is shared, and how well it is shared among databases; 3) promoting an understanding of data sharing and ontologies in the stakeholder community; 4) improving data sharing and ontologies for specific phenotypic data types and formats; and 5) lowering specific barriers to data sharing and ontology use, by identifying sustainability solutions, and the identification, promotion, or development of data standards.","cats":{"new-dataset":0}}
{"text":"Combined, these improvements are likely to help AgBioData databases increase development efforts towards improved ontology use, and data sharing via programmatic means.","cats":{"new-dataset":0}}
{"text":"To feed the data-hungry models, we first elaborate interference generators and conduct comprehensive co-location experiments on a testbed to build Alioth-dataset which reflects the complexity and dynamicity in real-world scenarios","cats":{"new-dataset":1}}
{"text":"The dataset and code of Alioth have been released on GitHub.","cats":{"new-dataset":0}}
{"text":"Multi-tenancy in public clouds may lead to co-location interference on shared resources, which possibly results in performance degradation of cloud applications.","cats":{"new-dataset":0}}
{"text":"Cloud providers want to know when such events happen and how serious the degradation is, to perform interference-aware migrations and alleviate the problem.","cats":{"new-dataset":0}}
{"text":"However, virtual machines (VM) in Infrastructure-as-a-Service public clouds are black-boxes to providers, where application-level performance information cannot be acquired.","cats":{"new-dataset":0}}
{"text":"This makes performance monitoring intensely challenging as cloud providers can only rely on low-level metrics such as CPU usage and hardware counters.   ","cats":{"new-dataset":0}}
{"text":"We propose a novel machine learning framework, Alioth, to monitor the performance degradation of cloud applications. .","cats":{"new-dataset":0}}
{"text":"Then we construct Alioth by (1) augmenting features via recovering low-level metrics under no interference using denoising auto-encoders, (2) devising a transfer learning model based on domain adaptation neural network to make models generalize on test cases unseen in offline training, and (3) developing a SHAP explainer to automate feature selection and enhance model interpretability.","cats":{"new-dataset":0}}
{"text":"Experiments show that Alioth achieves an average mean absolute error of 5.29% offline and 10.8% when testing on applications unseen in the training stage, outperforming the baseline methods.","cats":{"new-dataset":0}}
{"text":"Alioth is also robust in signaling quality-of-service violation under dynamicity.","cats":{"new-dataset":0}}
{"text":"Finally, we demonstrate a possible application of Alioth's interpretability, providing insights to benefit the decision-making of cloud operators.","cats":{"new-dataset":0}}
{"text":"We introduce the problem of knot-based inverse perceptual art.","cats":{"new-dataset":0}}
{"text":"Given multiple target images and their corresponding viewing configurations, the objective is to find a 3D knot-based tubular structure whose appearance resembles the target images when viewed from the specified viewing configurations.","cats":{"new-dataset":0}}
{"text":"To solve this problem, we first design a differentiable rendering algorithm for rendering tubular knots embedded in 3D for arbitrary perspective camera configurations.","cats":{"new-dataset":0}}
{"text":"Utilizing this differentiable rendering algorithm, we search over the space of knot configurations to find the ideal knot embedding.","cats":{"new-dataset":0}}
{"text":"We represent the knot embeddings via homeomorphisms of the desired template knot, where the homeomorphisms are parametrized by the weights of an invertible neural network.","cats":{"new-dataset":0}}
{"text":"Our approach is fully differentiable, making it possible to find the ideal 3D tubular structure for the desired perceptual art using gradient-based optimization.","cats":{"new-dataset":0}}
{"text":"We propose several loss functions that impose additional physical constraints, ensuring that the tube is free of self-intersection, lies within a predefined region in space, satisfies the physical bending limits of the tube material and the material cost is within a specified budget.","cats":{"new-dataset":0}}
{"text":"We demonstrate through results that our knot representation is highly expressive and gives impressive results even for challenging target images in both single view as well as multiple view constraints.","cats":{"new-dataset":0}}
{"text":"Through extensive ablation study we show that each of the proposed loss function is effective in ensuring physical realizability.","cats":{"new-dataset":0}}
{"text":"To the best of our knowledge, we are the first to propose a fully differentiable optimization framework for knot-based inverse perceptual art.","cats":{"new-dataset":0}}
{"text":"Both the code and data will be made publicly available.","cats":{"new-dataset":0}}
{"text":"To do so, a comparable big dataset of metadata of apps has been collected for learning and evaluation in this work.","cats":{"new-dataset":1}}
{"text":"In the digitized world, smartphones and their apps play an important role.","cats":{"new-dataset":0}}
{"text":"To name just a few examples, some apps offer possibilities for entertainment, others for online banking, and others offer support for two-factor authentication.","cats":{"new-dataset":0}}
{"text":"Therefore, with smartphones also, sensitive information is shared; thus, they are a desirable target for malware.","cats":{"new-dataset":0}}
{"text":"The following technical report gives an overview of how machine learning, especially neural networks, can be employed to detect malicious Android apps based on their metadata.","cats":{"new-dataset":0}}
{"text":"Detection based on the metadata is necessary since not all of an app's information is readable from another app due to the security layout of Android.  ","cats":{"new-dataset":0}}
{"text":"The first section, after the introduction, presents the related work, followed by the description of the sources of the dataset and the selection of the features used for machine learning, in this case, only the app permissions.","cats":{"new-dataset":0}}
{"text":"Afterward, a free available dataset is used to find an efficient and effective neural network model for learning and evaluation.","cats":{"new-dataset":0}}
{"text":"Here, the fully connected network type consisting of dense layers is chosen.","cats":{"new-dataset":0}}
{"text":"It turns out that this model detects malware with an accuracy of 92.93% based on an app's permissions.","cats":{"new-dataset":0}}
{"text":"To tackle these issues, we introduce DialogStudio: the largest and most diverse collection of dialogue datasets, unified under a consistent format while preserving their original information.","cats":{"new-dataset":1,"prompt-eng":0}}
{"text":"Our collection encompasses data from open-domain dialogues, task-oriented dialogues, natural language understanding, conversational recommendation, dialogue summarization, and knowledge-grounded dialogues, making it an incredibly rich and diverse resource for dialogue research and model training.","cats":{"new-dataset":1,"prompt-eng":0}}
{"text":"To further enhance the utility of DialogStudio, we identify the licenses for each dataset and design domain-aware prompts for selected dialogues to facilitate instruction-aware fine-tuning","cats":{"new-dataset":1}}
{"text":"Despite advancements in conversational AI, language models encounter challenges to handle diverse conversational tasks, and existing dialogue dataset collections often lack diversity and comprehensiveness.  ","cats":{"new-dataset":0}}
{"text":"Our collection encompasses data from open-domain dialogues, task-oriented dialogues, natural language understanding, conversational recommendation, dialogue summarization, and knowledge-grounFurthermore, we develop conversational AI models using the dataset collection, and our experiments in both zero-shot and few-shot learning scenarios demonstrate the superiority of DialogStudio.","cats":{"new-dataset":0}}
{"text":"To improve transparency and support dataset and task-based research, as well as language model pre-train","cats":{"new-dataset":0}}
{"text":"Movement paths are used widely in intelligent transportation and smart city applications.","cats":{"new-dataset":0}}
{"text":"To serve such applications, path representation learning aims to provide compact representations of paths that enable efficient and accurate operations when used for different downstream tasks such as path ranking and travel cost estimation.","cats":{"new-dataset":0}}
{"text":"In many cases, it is attractive that the path representation learning is lightweight and scalable; in resource-limited environments and under green computing limitations, it is essential.","cats":{"new-dataset":0}}
{"text":"Yet, existing path representation learning studies focus on accuracy and pay at most secondary attention to resource consumption and scalability.   ","cats":{"new-dataset":0}}
{"text":"We propose a lightweight and scalable path representation learning framework, termed LightPath, that aims to reduce resource consumption and achieve scalability without affecting accuracy, thus enabling broader applicability.","cats":{"new-dataset":0}}
{"text":"More specifically, we first propose a sparse auto-encoder that ensures that the framework achieves good scalability with respect to path length.","cats":{"new-dataset":0}}
{"text":"Next, we propose a relational reasoning framework to enable faster training of more robust sparse path encoders.","cats":{"new-dataset":0}}
{"text":"We also propose global-local knowledge distillation to further reduce the size and improve the performance of sparse path encoders.","cats":{"new-dataset":0}}
{"text":"Visual (re)localization is critical for various applications in computer vision and robotics.","cats":{"new-dataset":0}}
{"text":"Its goal is to estimate the 6 degrees of freedom (DoF) camera pose for each query image, based on a set of posed database images.","cats":{"new-dataset":0}}
{"text":"Currently, all leading solutions are structure-based that either explicitly construct 3D metric maps from the database with structure-from-motion, or implicitly encode the 3D information with scene coordinate regression models.","cats":{"new-dataset":0}}
{"text":"On the contrary, visual localization without reconstructing the scene in 3D offers clear benefits.","cats":{"new-dataset":0}}
{"text":"It makes deployment more convenient by reducing database pre-processing time, releasing storage requirements, and remaining unaffected by imperfect reconstruction, etc.","cats":{"new-dataset":0}}
{"text":"In this technical report, we demonstrate that it is possible to achieve high localization accuracy without reconstructing the scene from the database.","cats":{"new-dataset":0}}
{"text":"The key to achieving this owes to a tailored motion averaging over database-query pairs.","cats":{"new-dataset":0}}
{"text":"Experiments show that our visual localization proposal, LazyLoc, achieves comparable performance against state-of-the-art structure-based methods.","cats":{"new-dataset":0}}
{"text":"Furthermore, we showcase the versatility of LazyLoc, which can be easily extended to handle complex configurations such as multi-query co-localization and camera rigs.","cats":{"new-dataset":0}}
{"text":"This paper focuses on motion prediction for point cloud sequences in the challenging case of deformable 3D objects, such as human body motion.","cats":{"new-dataset":0}}
{"text":"First, we investigate the challenges caused by deformable shapes and complex motions present in this type of representation, with the ultimate goal of understanding the technical limitations of state-of-the-art models.","cats":{"new-dataset":0}}
{"text":"From this understanding, we propose an improved architecture for point cloud prediction of deformable 3D objects.","cats":{"new-dataset":0}}
{"text":"Specifically, to handle deformable shapes, we propose a graph-based approach that learns and exploits the spatial structure of point clouds to extract more representative features.","cats":{"new-dataset":0}}
{"text":"Then we propose a module able to combine the learned features in an adaptative manner according to the point cloud movements.","cats":{"new-dataset":0}}
{"text":"The proposed adaptative module controls the composition of local and global motions for each point, enabling the network to model complex motions in deformable 3D objects more effectively.","cats":{"new-dataset":0}}
{"text":"We tested the proposed method on the following datasets: MNIST moving digits, the Mixamo human bodies motions, JPEG and CWIPC-SXR real-world dynamic bodies.","cats":{"new-dataset":0}}
{"text":"Simulation results demonstrate that our method outperforms the current baseline methods given its improved ability to model complex movements as well as preserve point cloud shape.","cats":{"new-dataset":0}}
{"text":"Furthermore, we demonstrate the generalizability of the proposed framework for dynamic feature learning, by testing the framework for action recognition on the MSRAction3D dataset and achieving results on-par with state-of-the-art methods","cats":{"new-dataset":0}}
{"text":"Multimodal image registration is a challenging but essential step for numerous image-guided procedures.","cats":{"new-dataset":0}}
{"text":"Most registration algorithms rely on the computation of complex, frequently non-differentiable similarity metrics to deal with the appearance discrepancy of anatomical structures between imaging modalities.","cats":{"new-dataset":0}}
{"text":"Recent Machine Learning based approaches are limited to specific anatomy-modality combinations and do not generalize to new settings.","cats":{"new-dataset":0}}
{"text":"We propose a generic framework for creating expressive cross-modal descriptors that enable fast deformable global registration.","cats":{"new-dataset":0}}
{"text":"We achieve this by approximating existing metrics with a dot-product in the feature space of a small convolutional neural network (CNN) which is inherently differentiable can be trained without registered data.","cats":{"new-dataset":0}}
{"text":"Our method is several orders of magnitude faster than local patch-based metrics and can be directly applied in clinical settings by replacing the similarity measure with the proposed one.","cats":{"new-dataset":0}}
{"text":"Experiments on three different datasets demonstrate that our approach generalizes well beyond the training data, yielding a broad capture range even on unseen anatomies and modality pairs, without the need for specialized retraining.","cats":{"new-dataset":0}}
{"text":"We make our training code and data publicly available.","cats":{"new-dataset":0}}
{"text":"Cross-lingual image captioning is confronted with both cross-lingual and cross-modal challenges for multimedia analysis.","cats":{"new-dataset":0}}
{"text":"The crucial issue in this task is to model the global and local matching between the image and different languages.","cats":{"new-dataset":0}}
{"text":"Existing cross-modal embedding methods based on Transformer architecture oversight the local matching between the image region and monolingual words, not to mention in the face of a variety of differentiated languages.","cats":{"new-dataset":0}}
{"text":"Due to the heterogeneous property of the cross-modal and cross-lingual task, we utilize the heterogeneous network to establish cross-domain relationships and the local correspondences between the image and different languages.","cats":{"new-dataset":0}}
{"text":"In this paper, we propose an Embedded Heterogeneous Attention Transformer (EHAT) to build reasoning paths bridging cross-domain for cross-lingual image captioning and integrate into transformer.","cats":{"new-dataset":0}}
{"text":"The proposed EHAT consists of a Masked Heterogeneous Cross-attention (MHCA), Heterogeneous Attention Reasoning Network (HARN) and Heterogeneous Co-attention (HCA).","cats":{"new-dataset":0}}
{"text":"HARN as the core network, models and infers cross-domain relationship anchored by vision bounding box representation features to connect two languages word features and learn the heterogeneous maps.","cats":{"new-dataset":0}}
{"text":"MHCA and HCA implement cross-domain integration in the encoder through the special heterogeneous attention and enable single model to generate two language captioning.","cats":{"new-dataset":0}}
{"text":"We test on MSCOCO dataset to generate English and Chinese, which are most widely used and have obvious difference between their language families.","cats":{"new-dataset":0}}
{"text":"Our experiments show that our method even achieve better than advanced monolingual methods.","cats":{"new-dataset":0}}
{"text":"In this paper, we study the Greek wiretappings scandal, which has been revealed in 2022 and attracted a lot of attention by press and citizens.","cats":{"new-dataset":0}}
{"text":"Specifically, we propose a methodology for collecting data and analyzing patterns of online public discussions on Twitter.","cats":{"new-dataset":0}}
{"text":"We apply our methodology to the Greek wiretappings use case, and present findings related to the evolution of the discussion over time, its polarization, and the role of the media.","cats":{"new-dataset":0}}
{"text":"The methodology can be of wider use and replicated to other topics.","cats":{"new-dataset":0}}
{"text":"We use two Western music datasets, two traditional/folk datasets coming from eastern Mediterranean cultures, and two datasets belonging to Indian art music.","cats":{"new-dataset":1}}
{"text":"Recent developments in MIR have led to several benchmark deep learning models whose embeddings can be used for a variety of downstream tasks.","cats":{"new-dataset":0}}
{"text":"At the same time, the vast majority of these models have been trained on Western pop/rock music and related styles.","cats":{"new-dataset":0}}
{"text":"This leads to research questions on whether these models can be used to learn representations for different music cultures and styles, or whether we can build similar music audio embedding models trained on data from different cultures or styles.","cats":{"new-dataset":0}}
{"text":"To that end, we leverage transfer learning methods to derive insights about the similarities between the different music cultures to which the data belongs to.  ","cats":{"new-dataset":0}}
{"text":"Three deep audio embedding models are trained and transferred across domains, including two CNN-based and a Transformer-based architecture, to perform auto-tagging for each target domain dataset.","cats":{"new-dataset":0}}
{"text":"Experimental results show that competitive performance is achieved in all domains via transfer learning, while the best source dataset varies for each music culture.","cats":{"new-dataset":0}}
{"text":"The implementation and the trained models are both provided in a public repository.","cats":{"new-dataset":0}}
{"text":"Human-AI interactivity is a critical aspect that reflects the usability of multimodal large language models (MLLMs).","cats":{"new-dataset":0}}
{"text":"However, existing end-to-end MLLMs only allow users to interact with them through language instructions, leading to the limitation of the interactive accuracy and efficiency.","cats":{"new-dataset":0}}
{"text":"In this study, we present precise referring instructions that utilize diverse reference representations such as points and boxes as referring prompts to refer to the special region.","cats":{"new-dataset":0}}
{"text":"This enables MLLMs to focus on the region of interest and achieve finer-grained interaction.","cats":{"new-dataset":0}}
{"text":"Based on precise referring instruction, we propose ChatSpot, a unified end-to-end multimodal large language model that supports diverse forms of interactivity including mouse clicks, drag-and-drop, and drawing boxes, which provides a more flexible and seamless interactive experience.","cats":{"new-dataset":0}}
{"text":"We also construct a multi-grained vision-language instruction-following dataset based on existing datasets and GPT-4 generating.","cats":{"new-dataset":0}}
{"text":"Furthermore, we design a series of evaluation tasks to assess the effectiveness of region recognition and interaction.","cats":{"new-dataset":0}}
{"text":"Experimental results showcase ChatSpot's promising performance.","cats":{"new-dataset":0}}
{"text":"To evaluate the proposed framework, we build a dataset consisting of 1414 2-minute video segments annotated with 13 actions and 112 video segments annotated with two engagement levels.","cats":{"new-dataset":1}}
{"text":"In this paper, we propose a novel technique for measuring behavioral engagement through students' actions recognition.","cats":{"new-dataset":0}}
{"text":"The proposed approach recognizes student actions then predicts the student behavioral engagement level.","cats":{"new-dataset":0}}
{"text":"For student action recognition, we use human skeletons to model student postures and upper body movements.","cats":{"new-dataset":0}}
{"text":"To learn the dynamics of student upper body, a 3D-CNN model is used.","cats":{"new-dataset":0}}
{"text":"The trained 3D-CNN model is used to recognize actions within every 2minute video segment then these actions are used to build a histogram of actions which encodes the student actions and their frequencies.","cats":{"new-dataset":0}}
{"text":"This histogram is utilized as an input to SVM classifier to classify whether the student is engaged or disengaged.  ","cats":{"new-dataset":0}}
{"text":"Experimental results indicate that student actions can be recognized with top 1 accuracy 83.63% and the proposed framework can capture the average engagement of the class.","cats":{"new-dataset":0}}
{"text":"Point cloud registration is to estimate a transformation to align point clouds collected in different perspectives.","cats":{"new-dataset":0}}
{"text":"In learning-based point cloud registration, a robust descriptor is vital for high-accuracy registration.","cats":{"new-dataset":0}}
{"text":"However, most methods are susceptible to noise and have poor generalization ability on unseen datasets.","cats":{"new-dataset":0}}
{"text":"Motivated by this, we introduce SphereNet to learn a noise-robust and unseen-general descriptor for point cloud registration.","cats":{"new-dataset":0}}
{"text":"In our method, first, the spheroid generator builds a geometric domain based on spherical voxelization to encode initial features.","cats":{"new-dataset":0}}
{"text":"Then, the spherical interpolation of the sphere is introduced to realize robustness against noise.","cats":{"new-dataset":0}}
{"text":"Finally, a new spherical convolutional neural network with spherical integrity padding completes the extraction of descriptors, which reduces the loss of features and fully captures the geometric features.","cats":{"new-dataset":0}}
{"text":"To evaluate our methods, a new benchmark 3DMatch-noise with strong noise is introduced.","cats":{"new-dataset":0}}
{"text":"Extensive experiments are carried out on both indoor and outdoor datasets.","cats":{"new-dataset":0}}
{"text":"Under high-intensity noise, SphereNet increases the feature matching recall by more than 25 percentage points on 3DMatch-noise.","cats":{"new-dataset":0}}
{"text":"In addition, it sets a new state-of-the-art performance for the 3DMatch and 3DLoMatch benchmarks with 93.5\\% and 75.6\\% registration recall and also has the best generalization ability on unseen datasets.","cats":{"new-dataset":0}}
{"text":"Sequential decision-making under uncertainty is often associated with long feedback delays.","cats":{"new-dataset":0}}
{"text":"Such delays degrade the performance of the learning agent in identifying a subset of arms with the optimal collective reward in the long run.","cats":{"new-dataset":0}}
{"text":"This problem becomes significantly challenging in a non-stationary environment with structural dependencies amongst the reward distributions associated with the arms.","cats":{"new-dataset":0}}
{"text":"Therefore, besides adapting to delays and environmental changes, learning the causal relations alleviates the adverse effects of feedback delay on the decision-making process.","cats":{"new-dataset":0}}
{"text":"We formalize the described setting as a non-stationary and delayed combinatorial semi-bandit problem with causally related rewards.","cats":{"new-dataset":0}}
{"text":"We model the causal relations by a directed graph in a stationary structural equation model.","cats":{"new-dataset":0}}
{"text":"The agent maximizes the long-term average payoff, defined as a linear function of the base arms' rewards.","cats":{"new-dataset":0}}
{"text":"We develop a policy that learns the structural dependencies from delayed feedback and utilizes that to optimize the decision-making while adapting to drifts.","cats":{"new-dataset":0}}
{"text":"We prove a regret bound for the performance of the proposed algorithm.","cats":{"new-dataset":0}}
{"text":"Besides, we evaluate our method via numerical analysis using synthetic and real-world datasets to detect the regions that contribute the most to the spread of Covid-19 in Italy.","cats":{"new-dataset":0}}
{"text":"In this work, we curate the first aerial thermal near-shore dataset","cats":{"new-dataset":1}}
{"text":"Code and datasets used in this work will be available at: https://github.com/connorlee77/uav-thermal-water-segmentation.","cats":{"new-dataset":1}}
{"text":"We present a new method to adapt an RGB-trained water segmentation network to target-domain aerial thermal imagery using online self-supervision by leveraging texture and motion cues as supervisory signals.","cats":{"new-dataset":0}}
{"text":"This new thermal capability enables current autonomous aerial robots operating in near-shore environments to perform tasks such as visual navigation, bathymetry, and flow tracking at night.","cats":{"new-dataset":0}}
{"text":"Our method overcomes the problem of scarce and difficult-to-obtain near-shore thermal data that prevents the application of conventional supervised and unsupervised methods.","cats":{"new-dataset":0}}
{"text":", show that our approach outperforms fully-supervised segmentation models trained on limited target-domain thermal data, and demonstrate real-time capabilities onboard an Nvidia Jetson embedded computing platform.","cats":{"new-dataset":0}}
{"text":"Code and datasets used in this work will be available at: https://g","cats":{"new-dataset":0}}
{"text":"Facial expression recognition (FER) remains a challenging task due to the ambiguity of expressions.","cats":{"new-dataset":0}}
{"text":"The derived noisy labels significantly harm the performance in real-world scenarios.","cats":{"new-dataset":0}}
{"text":"To address this issue, we present a new FER model named Landmark-Aware Net~(LA-Net), which leverages facial landmarks to mitigate the impact of label noise from two perspectives.","cats":{"new-dataset":0}}
{"text":"Firstly, LA-Net uses landmark information to suppress the uncertainty in expression space and constructs the label distribution of each sample by neighborhood aggregation, which in turn improves the quality of training supervision.","cats":{"new-dataset":0}}
{"text":"Secondly, the model incorporates landmark information into expression representations using the devised expression-landmark contrastive loss.","cats":{"new-dataset":0}}
{"text":"The enhanced expression feature extractor can be less susceptible to label noise.","cats":{"new-dataset":0}}
{"text":"Our method can be integrated with any deep neural network for better training supervision without introducing extra inference costs.","cats":{"new-dataset":0}}
{"text":"We conduct extensive experiments on both in-the-wild datasets and synthetic noisy datasets and demonstrate that LA-Net achieves state-of-the-art performance.","cats":{"new-dataset":0}}
{"text":"The JAZZVAR dataset is a collection of 502 pairs of Variation and Original MIDI segments.","cats":{"new-dataset":1}}
{"text":"Jazz pianists often uniquely interpret jazz standards.","cats":{"new-dataset":0}}
{"text":"Passages from these interpretations can be viewed as sections of variation.","cats":{"new-dataset":0}}
{"text":"We manually extracted such variations from solo jazz piano performances.  ","cats":{"new-dataset":0}}
{"text":"Each Variation in the dataset is accompanied by a corresponding Original segment containing the melody and chords from the original jazz standard.","cats":{"new-dataset":0}}
{"text":"Our approach differs from many existing jazz datasets in the music information retrieval (MIR) community, which often focus on improvisation sections within jazz performances.","cats":{"new-dataset":0}}
{"text":"In this paper, we outline the curation process for obtaining and sorting the repertoire, the pipeline for creating the Original and Variation pairs, and our analysis of the dataset.","cats":{"new-dataset":0}}
{"text":"We also introduce a new generative music task, Music Overpainting, and present a baseline Transformer model trained on the JAZZVAR dataset for this task.","cats":{"new-dataset":0}}
{"text":"Other potential applications of our dataset include expressive performance analysis and performer identification.","cats":{"new-dataset":0}}
{"text":"The plant community composition is an essential indicator of environmental changes and is, for this reason, usually analyzed in ecological field studies in terms of the so-called plant cover.","cats":{"new-dataset":0}}
{"text":"The manual acquisition of this kind of data is time-consuming, laborious, and prone to human error.","cats":{"new-dataset":0}}
{"text":"Automated camera systems can collect high-resolution images of the surveyed vegetation plots at a high frequency.","cats":{"new-dataset":0}}
{"text":"In combination with subsequent algorithmic analysis, it is possible to objectively extract information on plant community composition quickly and with little human effort.","cats":{"new-dataset":0}}
{"text":"An automated camera system can easily collect the large amounts of image data necessary to train a Deep Learning system for automatic analysis.","cats":{"new-dataset":0}}
{"text":"However, due to the amount of work required to annotate vegetation images with plant cover data, only few labeled samples are available.","cats":{"new-dataset":0}}
{"text":"As automated camera systems can collect many pictures without labels, we introduce an approach to interpolate the sparse labels in the collected vegetation plot time series down to the intermediate dense and unlabeled images to artificially increase our training dataset to seven times its original size.","cats":{"new-dataset":0}}
{"text":"Moreover, we introduce a new method we call Monte-Carlo Cropping.","cats":{"new-dataset":0}}
{"text":"This approach trains on a collection of cropped parts of the training images to deal with high-resolution images efficiently, implicitly augment the training images, and speed up training.","cats":{"new-dataset":0}}
{"text":"We evaluate both approaches on a plant cover dataset containing images of herbaceous plant communities and find that our methods lead to improvements in the species, community, and segmentation metrics investigated.","cats":{"new-dataset":0}}
{"text":"Existing image editing tools, while powerful, typically disregard the underlying 3D geometry from which the image is projected.","cats":{"new-dataset":0}}
{"text":"As a result, edits made using these tools may become detached from the geometry and lighting conditions that are at the foundation of the image formation process.","cats":{"new-dataset":0}}
{"text":"In this work, we formulate the newt ask of language-guided 3D-aware editing, where objects in an image should be edited according to a language instruction in context of the underlying 3D scene.  ","cats":{"new-dataset":0}}
{"text":"Each example consists of an input image, editing instruction in language, and the edited image.","cats":{"new-dataset":0}}
{"text":"We also introduce 3DIT : single and multi-task models for four editing tasks.","cats":{"new-dataset":0}}
{"text":"Our models show impressive abilities to understand the 3D composition of entire scenes, factoring in surrounding objects, surfaces, lighting conditions, shadows, and physically-plausible object configurations.","cats":{"new-dataset":0}}
{"text":"Surprisingly, training on only synthetic scenes from OBJECT, editing capabilities of 3DIT generalize to real-world images.","cats":{"new-dataset":0}}
{"text":"A finely annotated segmentation dataset of approximately 10,000 consec-utive frames recorded during surgery is constructed for the first time for this field, addressing the problem of semantic segmentation.","cats":{"new-dataset":1}}
{"text":"Endoscopic surgery is currently an important treatment method in the field of spinal surgery and avoiding damage to the spinal nerves through video guidance is a key challenge.","cats":{"new-dataset":0}}
{"text":"This paper presents the first real-time segmentation method for spinal nerves in endoscopic surgery, which provides crucial navigational information for surgeons.  ","cats":{"new-dataset":0}}
{"text":"Based on this dataset, we propose FUnet (Frame-Unet), which achieves state-of-the-art performance by utilizing inter-frame information and self-attention mechanisms.","cats":{"new-dataset":0}}
{"text":"We also conduct extended exper-iments on a similar polyp endoscopy video dataset and show that the model has good generalization ability with advantageous performance.","cats":{"new-dataset":0}}
{"text":"The dataset and code of this work are presented at: https://github.com/zzzzzzpc/FUnet .","cats":{"new-dataset":0}}
{"text":"Recent advances in deep learning have significantly improved the performance of various computer vision applications.","cats":{"new-dataset":0}}
{"text":"However, discovering novel categories in an incremental learning scenario remains a challenging problem due to the lack of prior knowledge about the number and nature of new categories.","cats":{"new-dataset":0}}
{"text":"Existing methods for novel category discovery are limited by their reliance on labeled datasets and prior knowledge about the number of novel categories and the proportion of novel samples in the batch.","cats":{"new-dataset":0}}
{"text":"To address the limitations and more accurately reflect real-world scenarios, in this paper, we propose a novel unsupervised class incremental learning approach for discovering novel categories on unlabeled sets without prior knowledge.","cats":{"new-dataset":0}}
{"text":"The proposed method fine-tunes the feature extractor and proxy anchors on labeled sets, then splits samples into old and novel categories and clusters on the unlabeled dataset.","cats":{"new-dataset":0}}
{"text":"Furthermore, the proxy anchors-based exemplar generates representative category vectors to mitigate catastrophic forgetting.","cats":{"new-dataset":0}}
{"text":"Self-supervised learning (SSL) for clinical time series data has received significant attention in recent literature, since these data are highly rich and provide important information about a patient's physiological state.","cats":{"new-dataset":0}}
{"text":"However, most existing SSL methods for clinical time series are limited in that they are designed for unimodal time series, such as a sequence of structured features (e.g., lab values and vitals signs) or an individual high-dimensional physiological signal (e.g., an electrocardiogram).","cats":{"new-dataset":0}}
{"text":"These existing methods cannot be readily extended to model time series that exhibit multimodality, with structured features and high-dimensional data being recorded at each timestep in the sequence.","cats":{"new-dataset":0}}
{"text":"In this work, we address this gap and propose a new SSL method -- Sequential Multi-Dimensional SSL -- where a SSL loss is applied both at the level of the entire sequence and at the level of the individual high-dimensional data points in the sequence in order to better capture information at both scales.","cats":{"new-dataset":0}}
{"text":"Our strategy is agnostic to the specific form of loss function used at each level -- it can be contrastive, as in SimCLR, or non-contrastive, as in VICReg.","cats":{"new-dataset":0}}
{"text":"Our experimental results indicate that pre-training with our method and then fine-tuning on downstream tasks improves performance over baselines on both datasets, and in several settings, can lead to improvements across different self-supervised loss functions.","cats":{"new-dataset":0}}
{"text":"Human motion generation aims to generate natural human pose sequences and shows immense potential for real-world applications.","cats":{"new-dataset":0}}
{"text":"Most research within this field focuses on generating human motions based on conditional signals, such as text, audio, and scene contexts.","cats":{"new-dataset":0}}
{"text":"While significant advancements have been made in recent years, the task continues to pose challenges due to the intricate nature of human motion and its implicit relationship with conditional signals.","cats":{"new-dataset":0}}
{"text":"In this survey, we present a comprehensive literature review of human motion generation, which, to the best of our knowledge, is the first of its kind in this field.","cats":{"new-dataset":0}}
{"text":"We begin by introducing the background of human motion and generative models, followed by an examination of representative methods for three mainstream sub-tasks: text-conditioned, audio-conditioned, and scene-conditioned human motion generation.","cats":{"new-dataset":0}}
{"text":"Lastly, we discuss open problems and outline potential future research directions.","cats":{"new-dataset":0}}
{"text":"We hope that this survey could provide the community with a comprehensive glimpse of this rapidly evolving field and inspire novel ideas that address the outstanding challenges.","cats":{"new-dataset":0}}
{"text":"Having efficient testing strategies is a core challenge that needs to be overcome for the release of automated driving.","cats":{"new-dataset":0}}
{"text":"This necessitates clear requirements as well as suitable methods for testing.","cats":{"new-dataset":0}}
{"text":"In this work, the requirements for perception modules are considered with respect to relevance.","cats":{"new-dataset":0}}
{"text":"The concept of relevance currently remains insufficiently defined and specified.","cats":{"new-dataset":0}}
{"text":"In this paper, we propose a novel methodology to overcome this challenge by exemplary application to collision safety in the highway domain.","cats":{"new-dataset":0}}
{"text":"Using this general system and use case specification, a corresponding concept for relevance is derived.","cats":{"new-dataset":0}}
{"text":"Irrelevant objects are thus defined as objects which do not limit the set of safe actions available to the ego vehicle under consideration of all uncertainties.","cats":{"new-dataset":0}}
{"text":"As an initial step, the use case is decomposed into functional scenarios with respect to collision relevance.","cats":{"new-dataset":0}}
{"text":"For each functional scenario, possible actions of both the ego vehicle and any other dynamic object are formalized as equations.","cats":{"new-dataset":0}}
{"text":"This set of possible actions is constrained by traffic rules, yielding relevance criteria.","cats":{"new-dataset":0}}
{"text":"As a result, we present a conservative estimation which dynamic objects are relevant for perception and need to be considered for a complete evaluation.","cats":{"new-dataset":0}}
{"text":"The estimation provides requirements which are applicable for offline testing and validation of perception components.","cats":{"new-dataset":0}}
{"text":"A visualization is presented for examples from the highD dataset, showing the plausibility of the results.","cats":{"new-dataset":0}}
{"text":"Finally, a possibility for a future validation of the presented relevance concept is outlined.","cats":{"new-dataset":0}}
{"text":"In a conventional Speech emotion recognition (SER) task, a classifier for a given language is trained on a pre-existing dataset for that same language.","cats":{"new-dataset":0}}
{"text":"However, where training data for a language does not exist, data from other languages can be used instead.","cats":{"new-dataset":0}}
{"text":"We experiment with cross-lingual and multilingual SER, working with Amharic, English, German and URDU.","cats":{"new-dataset":0}}
{"text":"We followed previous research in mapping labels for all datasets to just two classes, positive and negative.","cats":{"new-dataset":0}}
{"text":"Thus we can compare performance on different languages directly, and combine languages for training and testing.","cats":{"new-dataset":0}}
{"text":"In Experiment 1, monolingual SER trials were carried out using three classifiers, AlexNet, VGGE (a proposed variant of VGG), and ResNet50.","cats":{"new-dataset":0}}
{"text":"Results averaged for the three models were very similar for ASED and RAVDESS, suggesting that Amharic and English SER are equally difficult.","cats":{"new-dataset":0}}
{"text":"Similarly, German SER is more difficult, and Urdu SER is easier.","cats":{"new-dataset":0}}
{"text":"In Experiment 2, we trained on one language and tested on another, in both directions for each pair:","cats":{"new-dataset":0}}
{"text":"Amharic<->German, Amharic<->English, and Amharic<->Urdu.","cats":{"new-dataset":0}}
{"text":"Results with Amharic as target suggested that using English or German as source will give the best result.","cats":{"new-dataset":0}}
{"text":"In Experiment 3, we trained on several non-Amharic languages and then tested on Amharic.","cats":{"new-dataset":0}}
{"text":"The best accuracy obtained was several percent greater than the best accuracy in Experiment 2, suggesting that a better result can be obtained when using two or three non-Amharic languages for training than when using just one non-Amharic language.","cats":{"new-dataset":0}}
{"text":"Overall, the results suggest that cross-lingual and multilingual training can be an effective strategy for training a SER classifier when resources for a language are scarce.","cats":{"new-dataset":0}}
{"text":"In this paper, we first establish a large-scale audio-visual quality assessment dataset for omnidirectional videos, which includes 375 distorted omnidirectional audio-visual (A/V) sequences generated from 15 high-quality pristine omnidirectional A/V contents","cats":{"new-dataset":1}}
{"text":"Omnidirectional videos (ODVs) play an increasingly important role in the application fields of medical, education, advertising, tourism, etc.","cats":{"new-dataset":0}}
{"text":"Assessing the quality of ODVs is significant for service-providers to improve the user's Quality of Experience (QoE).","cats":{"new-dataset":0}}
{"text":"However, most existing quality assessment studies for ODVs only focus on the visual distortions of videos, while ignoring that the overall QoE also depends on the accompanying audio signals.","cats":{"new-dataset":0}}
{"text":", and the corresponding perceptual audio-visual quality scores.","cats":{"new-dataset":0}}
{"text":"Then, we design three baseline methods for full-reference omnidirectional audio-visual quality assessment (OAVQA), which combine existing state-of-the-art single-mode audio and video QA models via multimodal fusion strategies.","cats":{"new-dataset":0}}
{"text":"We validate the effectiveness of the A/V multimodal fusion method for OAVQA on our dataset, which provides a new benchmark for omnidirectional QoE evaluation.","cats":{"new-dataset":0}}
{"text":"With the increasing amount of spatial-temporal~(ST) ocean data, numerous spatial-temporal data mining (STDM) studies have been conducted to address various oceanic issues, e.g., climate forecasting and disaster warning.","cats":{"new-dataset":0}}
{"text":"Compared with typical ST data (e.g., traffic data), ST ocean data is more complicated with some unique characteristics, e.g., diverse regionality and high sparsity.","cats":{"new-dataset":0}}
{"text":"These characteristics make it difficult to design and train STDM models.","cats":{"new-dataset":0}}
{"text":"Unfortunately, an overview of these studies is still missing, hindering computer scientists to identify the research issues in ocean while discouraging researchers in ocean science from applying advanced STDM techniques.","cats":{"new-dataset":0}}
{"text":"To remedy this situation, we provide a comprehensive survey to summarize existing STDM studies in ocean.","cats":{"new-dataset":0}}
{"text":"Then, typical ST ocean data quality enhancement techniques are discussed.","cats":{"new-dataset":0}}
{"text":"Next, we classify existing STDM studies for ocean into four types of tasks, i.e., prediction, event detection, pattern mining, and anomaly detection, and elaborate the techniques for these tasks.","cats":{"new-dataset":0}}
{"text":"Finally, promising research opportunities are highlighted.","cats":{"new-dataset":0}}
{"text":"This survey will help scientists from the fields of both computer science and ocean science have a better understanding of the fundamental concepts, key techniques, and open challenges of STDM in ocean.","cats":{"new-dataset":0}}
{"text":"Extracting noisy or incorrectly labeled samples from a labeled dataset with hard/difficult samples is an important yet under-explored topic.","cats":{"new-dataset":0}}
{"text":"Two general and often independent lines of work exist, one focuses on addressing noisy labels, and another deals with hard samples.","cats":{"new-dataset":0}}
{"text":"However, when both types of data are present, most existing methods treat them equally, which results in a decline in the overall performance of the model.","cats":{"new-dataset":0}}
{"text":"Our proposed systematic empirical study enables us to better understand the similarities and more importantly the differences between hard-to-learn samples and incorrectly-labeled samples.","cats":{"new-dataset":0}}
{"text":"These controlled experiments pave the way for the development of methods that distinguish between hard and noisy samples.","cats":{"new-dataset":0}}
{"text":"Through our study, we introduce a simple yet effective metric that filters out noisy-labeled samples while keeping the hard samples.","cats":{"new-dataset":0}}
{"text":"We study various data partitioning methods in the presence of label noise and observe that filtering out noisy samples from hard samples with this proposed metric results in the best datasets as evidenced by the high test accuracy achieved after models are trained on the filtered datasets.","cats":{"new-dataset":0}}
{"text":"We demonstrate this for both our created synthetic datasets and for datasets with real-world label noise.","cats":{"new-dataset":0}}
{"text":"Furthermore, our proposed data partitioning method significantly outperforms other methods when employed within a semi-supervised learning framework.","cats":{"new-dataset":0}}
{"text":"SlowTV contains 1.7M images from a rich diversity of environments, such as worldwide seasonal hiking, scenic driving and scuba diving.","cats":{"new-dataset":0}}
{"text":"Self-supervised monocular depth estimation (SS-MDE) has the potential to scale to vast quantities of data.","cats":{"new-dataset":0}}
{"text":"Unfortunately, existing approaches limit themselves to the automotive domain, resulting in models incapable of generalizing to complex environments such as natural or indoor settings.    ","cats":{"new-dataset":0}}
{"text":"Using this dataset, wutperforms all existing SSL approaches and closes the gap on supervised SoTA, despite using a more efficient architecture.   ","cats":{"new-dataset":0}}
{"text":"We additionally introduce a collection of best-practices to further maximize performance and zero-shot generalization.","cats":{"new-dataset":0}}
{"text":"This includes 1) aspect ratio augmentation, 2) camera intrinsic estimation, 3) support frame randomization and 4) flexible motion estimation.","cats":{"new-dataset":0}}
{"text":"Code is available at https://github.com/jspenmar/slowtv_monodepth.","cats":{"new-dataset":0}}
{"text":"As an alternative, we present CZEch~NEws~Classification~dataset (CZE-NEC), one of the largest Czech classification datasets, composed of news articles from various sources spanning over twenty years, which allows a more rigorous evaluation of such models.","cats":{"new-dataset":1}}
{"text":"Pre-trained models for Czech Natural Language Processing are often evaluated on purely linguistic tasks (POS tagging, parsing, NER) and relatively simple classification tasks such as sentiment classification or article classification from a single news source.  ","cats":{"new-dataset":0}}
{"text":"We define four classification tasks: news source, news category, inferred author's gender, and day of the week.","cats":{"new-dataset":0}}
{"text":"To verify the task difficulty, we conducted a human evaluation, which revealed that human performance lags behind strong machine-learning baselines built upon pre-trained transformer models.","cats":{"new-dataset":0}}
{"text":"Furthermore, we show that language-specific pre-trained encoder analysis outperforms selected commercially available large-scale generative language models.","cats":{"new-dataset":0}}
{"text":"To address these issues, this paper introduces an expansive benchmark suite SciBench that aims to systematically examine the reasoning capabilities required for complex scientific problem solving","cats":{"new-dataset":1}}
{"text":"SciBench contains two carefully curated datasets: an open set featuring a range of collegiate-level scientific problems drawn from mathematics, chemistry, and physics textbooks, and a closed set comprising problems from undergraduate-level exams in computer science and mathematics.","cats":{"new-dataset":1}}
{"text":"Recent advances in large language models (LLMs) have demonstrated notable progress on many mathematical benchmarks.","cats":{"new-dataset":0}}
{"text":"However, most of these benchmarks only feature problems grounded in junior and senior high school subjects, contain only multiple-choice questions, and are confined to a limited scope of elementary arithmetic operations. .","cats":{"new-dataset":0}}
{"text":"SciBench contains two carefully curated datasets: an open set featuring a range of collegiate-level scientific problems drawn from mathematics, chemistry, and physics textbooks, and a closed set sfactory performance, with an overall score of merely 35.80%.","cats":{"new-dataset":0}}
{"text":"Furthermore, through a detailed user study, we categorize the errors made by LLMs into ten problem-solving abilities.","cats":{"new-dataset":0}}
{"text":"Our analysis indicates that no single prompting strategy significantly outperforms others and some strategies that demonstrate improvements in certain problem-solving skills result in declines in other skills.","cats":{"new-dataset":0}}
{"text":"We envision that SciBench will catalyze further developments in the reasoning abilities of LLMs, thereby ultimately contributing to scientific research and discovery.","cats":{"new-dataset":0}}
{"text":"Federated learning (FL) has drawn increasing attention owing to its potential use in large-scale industrial applications.","cats":{"new-dataset":0}}
{"text":"Existing federated learning works mainly focus on model homogeneous settings.","cats":{"new-dataset":0}}
{"text":"However, practical federated learning typically faces the heterogeneity of data distributions, model architectures, network environments, and hardware devices among participant clients.","cats":{"new-dataset":0}}
{"text":"Heterogeneous Federated Learning (HFL) is much more challenging, and corresponding solutions are diverse and complex.","cats":{"new-dataset":0}}
{"text":"Therefore, a systematic survey on this topic about the research challenges and state-of-the-art is essential.","cats":{"new-dataset":0}}
{"text":"In this survey, we firstly summarize the various research challenges in HFL from five aspects: statistical heterogeneity, model heterogeneity, communication heterogeneity, device heterogeneity, and additional challenges.","cats":{"new-dataset":0}}
{"text":"In addition, recent advances in HFL are reviewed and a new taxonomy of existing HFL methods is proposed with an in-depth analysis of their pros and cons.","cats":{"new-dataset":0}}
{"text":"We classify existing methods from three different levels according to the HFL procedure: data-level, model-level, and server-level.","cats":{"new-dataset":0}}
{"text":"Finally, several critical and promising future research directions in HFL are discussed, which may facilitate further developments in this field.","cats":{"new-dataset":0}}
{"text":"A periodically updated collection on HFL is available at https://github.com/marswhu/HFL_Survey.","cats":{"new-dataset":0}}
{"text":"In this paper, we analyze the data that we have collected on the pendency of 24 high courts in the Republic of India as they were made available on High Court NJDG (HC-NJDG).","cats":{"new-dataset":1}}
{"text":"We collected data on 73 days beginning August 31, 2017 to December 26, 2018, including these days.","cats":{"new-dataset":0}}
{"text":"Thus, the data collected by us spans a period of almost sixteen months.","cats":{"new-dataset":0}}
{"text":"Indian Judiciary is suffering from burden of millions of cases that are lying pending in its courts at all the levels.  ","cats":{"new-dataset":0}}
{"text":"We imited to the number of judges in each high court, the number of cases pending in each high court, d and disposed, cases filed by women and senior citizens, etc.","cats":{"new-dataset":0}}
{"text":"Our results show that: 1) statistics as important as the number of judges in high courts have serious errors on NJDG (Fig. 1, 2, 10, 11, Table V).","cats":{"new-dataset":0}}
{"text":"2) pending cases in most of the high courts are increasing rather than decreasing (Fig. 3, 13).","cats":{"new-dataset":0}}
{"text":"3) regular update of HC-NJDG is required for it to be useful.","cats":{"new-dataset":0}}
{"text":"Data related to some high courts is not being updated regularly or is updated erroneously on the portal (Fig. 14).","cats":{"new-dataset":0}}
{"text":"4) there is a huge difference in terms of average load of cases on judges of different high courts (Fig. 6).","cats":{"new-dataset":0}}
{"text":"5) if all the high courts operate at their approved strength of judges, then for most of the high courts pendency can be nullified within 20 years from now (Fig. 21, 22).","cats":{"new-dataset":0}}
{"text":"6) the pending cases filed by women and senior citizens are disproportionately low, they together constitute less than 10% of the total pending cases (Fig. 23 - 27) 7) a better scheduling process for preparing causelists in courts can help reducing the number of pending cases in the High Courts (Fig. 29).","cats":{"new-dataset":0}}
{"text":"8) some statistics are not well defined (Fig. 31).","cats":{"new-dataset":0}}
{"text":"In this work, we describe the curation of a massive speech dataset of 8740 hours consisting of $\\sim9.8$K technical lectures in the English language along with their transcripts delivered by instructors representing various parts of Indian demography.","cats":{"new-dataset":1}}
{"text":"The dataset is sourced from the very popular NPTEL MOOC platform.","cats":{"new-dataset":0}}
{"text":"Automatic speech recognition (ASR) systems are designed to transcribe spoken language into written text and find utility in a variety of applications including voice assistants and transcription services.","cats":{"new-dataset":0}}
{"text":"However, it has been observed that state-of-the-art ASR systems which deliver impressive benchmark results, struggle with speakers of certain regions or demographics due to variation in their speech properties.  ","cats":{"new-dataset":0}}
{"text":"We use the curated dataset to measure the existing disparity in YouTube Automatic Captions and OpenAI Whisper model performance across the diverse demographic traits of speakers in Indi and speech rate of speakers, disparity based on caste is non-existent.","cats":{"new-dataset":0}}
{"text":"We also observe statistically significant disparity across the disciplines of the lectures.","cats":{"new-dataset":0}}
{"text":"These results indicate the need of more inclusive and robust ASR systems and more representational datasets for disparity evaluation in them.","cats":{"new-dataset":0}}
{"text":"In this work, we present DNA-Rendering, a large-scale, high-fidelity repository of human performance data for neural actor rendering","cats":{"new-dataset":1}}
{"text":"First, our dataset contains over 1500 human subjects, 5000 motion sequences, and 67.5M frames' data volume.","cats":{"new-dataset":0}}
{"text":"Second, we provide rich assets for each subject -- 2D/3D human body keypoints, foreground masks, SMPLX models, cloth/accessory materials, multi-view images, and videos","cats":{"new-dataset":1}}
{"text":"Third, we construct a professional multi-view system to capture data, which contains 60 synchronous cameras with max 4096 x 3000 resolution, 15 fps speed, and stern camera calibration steps, ensuring high-quality resources for task training and evaluation","cats":{"new-dataset":1}}
{"text":"The dataset, code, and benchmarks will be publicly available at https://dna-rendering.github.io/","cats":{"new-dataset":1}}
{"text":"Realistic human-centric rendering plays a key role in both computer vision and computer graphics.","cats":{"new-dataset":0}}
{"text":"Rapid progress has been made in the algorithm aspect over the years, yet existing human-centric rendering datasets and benchmarks are rather impoverished in terms of diversity, which are crucial for rendering effect.","cats":{"new-dataset":0}}
{"text":"Researchers are usually constrained to explore and evaluate a small set of rendering problems on current datasets, while real-world applications require methods to be robust across different scenarios. .","cats":{"new-dataset":0}}
{"text":"DNA-Rendering presents several alluring attributes.","cats":{"new-dataset":0}}
{"text":"Second, we provide rich rials, multi-view images, and videos.","cats":{"new-dataset":0}}
{"text":"These assets boost the current method's accuracy on downstream renderid stern camera calibration steps, ensuring high-quality resources for task training and evaluation.","cats":{"new-dataset":0}}
{"text":"Along with the dataset, we provide a large-scale and quantitative benchmark in full-scale, with multiple tasks to evaluate the existing progress of net, code, and benchmarks will be publicly available at https://dna-rendering.github.io/","cats":{"new-dataset":0}}
{"text":"We investigate the use of 2D black-and-white textures for the visualization of categorical data and contribute a summary of texture attributes, and the results of three experiments that elicited design strategies as well as aesthetic and effectiveness measures.","cats":{"new-dataset":0}}
{"text":"Black-and-white textures are useful, for instance, as a visual channel for categorical data on low-color displays, in 2D/3D print, to achieve the aesthetic of historic visualizations, or to retain the color hue channel for other visual mappings.","cats":{"new-dataset":0}}
{"text":"We specifically study how to use what we call geometric and iconic textures.","cats":{"new-dataset":0}}
{"text":"Geometric textures use patterns of repeated abstract geometric shapes, while iconic textures use repeated icons that may stand for data categories.","cats":{"new-dataset":0}}
{"text":"We parameterized both types of textures and developed a tool for designers to create textures on simple charts by adjusting texture parameters.","cats":{"new-dataset":0}}
{"text":"30 visualization experts used our tool and designed 66 textured bar charts, pie charts, and maps.","cats":{"new-dataset":0}}
{"text":"We then had 150 participants rate these designs for aesthetics.","cats":{"new-dataset":0}}
{"text":"Finally, with the top-rated geometric and iconic textures, our perceptual assessment experiment with 150 participants revealed that textured charts perform about equally well as non-textured charts, and that there are some differences depending on the type of chart.","cats":{"new-dataset":0}}
{"text":"As part of the data-driven paradigm and open science movement, the data paper is becoming a popular way for researchers to publish their research data, based on academic norms that cross knowledge domains.","cats":{"new-dataset":0}}
{"text":"Data journals have also been created to host this new academic genre.","cats":{"new-dataset":0}}
{"text":"The growing number of data papers and journals has made them an important large-scale data source for understanding how research data is published and reused in our research system.","cats":{"new-dataset":0}}
{"text":"One barrier to this research agenda is a lack of knowledge as to how data journals and their publications are indexed in the scholarly databases used for quantitative analysis.","cats":{"new-dataset":0}}
{"text":"To address this gap, this study examines how a list of 18 exclusively data journals (i.e., journals that primarily accept data papers) are indexed in four popular scholarly databases: the Web of Science, Scopus, Dimensions, and OpenAlex.","cats":{"new-dataset":0}}
{"text":"We investigate how comprehensively these databases cover the selected data journals and, in particular, how they present the document type information of data papers.","cats":{"new-dataset":0}}
{"text":"We find that the coverage of data papers, as well as their document type information, is highly inconsistent across databases, which creates major challenges for future efforts to study them quantitatively.","cats":{"new-dataset":0}}
{"text":"As a result, we argue that efforts should be made by data journals and databases to improve the quality of metadata for this emerging genre.","cats":{"new-dataset":0}}
{"text":"Situated visualization has become an increasingly popular research area in the visualization community, fueled by advancements in augmented reality (AR) technology and immersive analytics.","cats":{"new-dataset":0}}
{"text":"Visualizing data in spatial proximity to their physical referents affords new design opportunities and considerations not present in traditional visualization, which researchers are now beginning to explore.","cats":{"new-dataset":0}}
{"text":"However, the AR research community has an extensive history of designing graphics that are displayed in highly physical contexts.","cats":{"new-dataset":0}}
{"text":"In this work, we leverage the richness of AR research and apply it to situated visualization.","cats":{"new-dataset":0}}
{"text":"We derive design patterns which summarize common approaches of visualizing data in situ.","cats":{"new-dataset":0}}
{"text":"The design patterns are based on a survey of 293 papers published in the AR and visualization communities, as well as our own expertise.","cats":{"new-dataset":0}}
{"text":"We discuss design dimensions that help to describe both our patterns and previous work in the literature.","cats":{"new-dataset":0}}
{"text":"This discussion is accompanied by several guidelines which explain how to apply the patterns given the constraints imposed by the real world.","cats":{"new-dataset":0}}
{"text":"We conclude by discussing future research directions that will help establish a complete understanding of the design of situated visualization, including the role of interactivity, tasks, and workflows.","cats":{"new-dataset":0}}
{"text":"Automatic diagnosis (AD), a critical application of AI in healthcare, employs machine learning techniques to assist doctors in gathering patient symptom information for precise disease diagnosis.","cats":{"new-dataset":0}}
{"text":"The Transformer-based method utilizes an input symptom sequence, predicts itself through auto-regression, and employs the hidden state of the final symptom to determine the disease.","cats":{"new-dataset":0}}
{"text":"Despite its simplicity and superior performance demonstrated, a decline in disease diagnosis accuracy is observed caused by 1) a mismatch between symptoms observed during training and generation, and 2) the effect of different symptom orders on disease prediction.","cats":{"new-dataset":0}}
{"text":"To address the above obstacles, we introduce the CoAD, a novel disease and symptom collaborative generation framework, which incorporates several key innovations to improve AD: 1) aligning sentence-level disease labels with multiple possible symptom inquiry steps to bridge the gap between training and generation; 2) expanding symptom labels for each sub-sequence of symptoms to enhance annotation and eliminate the effect of symptom order; 3) developing a repeated symptom input schema to effectively and efficiently learn the expanded disease and symptom labels.","cats":{"new-dataset":0}}
{"text":"We evaluate the CoAD framework using four datasets, including three public and one private, and demonstrate that it achieves an average 2.3% improvement over previous state-of-the-art results in automatic disease diagnosis.","cats":{"new-dataset":0}}
{"text":"For reproducibility, we release the code and data at https://github.com/KwanWaiChung/coad.","cats":{"new-dataset":0}}
{"text":"To avoid potential risks posed by vulnerabilities in third-party libraries, security researchers maintain databases containing vulnerability reports, e.g., the National Vulnerability Database (NVD).","cats":{"new-dataset":0}}
{"text":"Application developers can identify vulnerable libraries by directly querying the databases with the name of each used library.","cats":{"new-dataset":0}}
{"text":"However, the querying results of vulnerable libraries are not reliable due to the incompleteness of vulnerability reports.","cats":{"new-dataset":0}}
{"text":"Thus, current approaches model the task of identifying vulnerable libraries as an extreme multi-label learning (XML) task.","cats":{"new-dataset":0}}
{"text":"These approaches suffer from highly inaccurate results and cannot identify zero-shot libraries (i.e., those not appearing during model training).","cats":{"new-dataset":0}}
{"text":"To address these limitations, in this paper, we propose the first entity-linking approach named VulLibMiner to identify vulnerable third-party libraries from textual descriptions of vulnerabilities and libraries, together with VulLib, a Java vulnerability dataset with vulnerability-affected libraries.","cats":{"new-dataset":0}}
{"text":"VulLibMiner consists of a coarse-grained TF-IDF matcher to efficiently screen out a small set of candidate libraries and a fine-grained BERT-FNN model to identify vulnerable libraries from these candidates effectively.","cats":{"new-dataset":0}}
{"text":"We evaluate VulLibMiner using two state-of-the-art/practice approaches of library identification (FastXML, LightXML) on both their dataset named VeraJava and our VulLib dataset.","cats":{"new-dataset":0}}
{"text":"Our evaluation results show that VulLibMiner can effectively identify vulnerable libraries with an average F1 score of 0.542 while the state-of-the-art/practice approaches achieve only 0.377.","cats":{"new-dataset":0}}
{"text":"We demonstrate VulLibMiner's high value of security practice by using VulLibMiner to identify 12,716 <vulnerability, library> pairs, and 7,936 of them do not appear in NVD.","cats":{"new-dataset":0}}
{"text":"We specify a file-oriented data format suitable for parallel, partition-independent disk I/O. Here, a partition refers to a disjoint and ordered distribution of the data elements between one or more processes.","cats":{"new-dataset":0}}
{"text":"The format is designed such that the file contents are invariant under linear (i. e., unpermuted), parallel repartition of the data prior to writing.","cats":{"new-dataset":0}}
{"text":"The file contents are indistinguishable from writing in serial.","cats":{"new-dataset":0}}
{"text":"In the same vein, the file can be read on any number of processes that agree on any partition of the number of elements stored.   ","cats":{"new-dataset":0}}
{"text":"In addition to the format specification we propose an optional convention to implement transparent per-element data compression.","cats":{"new-dataset":0}}
{"text":"The compressed data and metadata is layered inside ordinary format elements.","cats":{"new-dataset":0}}
{"text":"Overall, we pay special attention to both human and machine readability.","cats":{"new-dataset":0}}
{"text":"If pure ASCII data is written, or compressed data is reencoded to ASCII, the entire file including its header and sectioning metadata remains entirely in ASCII.","cats":{"new-dataset":0}}
{"text":"If binary data is written, the metadata stays easy on the human eye.   ","cats":{"new-dataset":0}}
{"text":"We refer to this format as scda.","cats":{"new-dataset":0}}
{"text":"Conceptually, it lies one layer below and is oblivious to the definition of variables, the binary representation of numbers, considerations of endianness, and self-describing headers, which may all be specified on top of scda.","cats":{"new-dataset":0}}
{"text":"The main purpose of the format is to abstract any parallelism and provide sufficient structure as a foundation for a generic and flexible archival and checkpoint/restart.","cats":{"new-dataset":0}}
{"text":"A documented reference implementation is available as part of the general-purpose libsc free software library.","cats":{"new-dataset":0}}
{"text":"This paper explores the integration of Large Language Models (LLMs) into Automatic Speech Recognition (ASR) systems to improve transcription accuracy.","cats":{"new-dataset":0}}
{"text":"The increasing sophistication of LLMs, with their in-context learning capabilities and instruction-following behavior, has drawn significant attention in the field of Natural Language Processing (NLP).","cats":{"new-dataset":0}}
{"text":"Our primary focus is to investigate the potential of using an LLM's in-context learning capabilities to enhance the performance of ASR systems, which currently face challenges such as ambient noise, speaker accents, and complex linguistic contexts.","cats":{"new-dataset":0}}
{"text":"We designed a study using the Aishell-1 and LibriSpeech datasets, with ChatGPT and GPT-4 serving as benchmarks for LLM capabilities.","cats":{"new-dataset":0}}
{"text":"Unfortunately, our initial experiments did not yield promising results, indicating the complexity of leveraging LLM's in-context learning for ASR applications.","cats":{"new-dataset":0}}
{"text":"Despite further exploration with varied settings and models, the corrected sentences from the LLMs frequently resulted in higher Word Error Rates (WER), demonstrating the limitations of LLMs in speech applications.","cats":{"new-dataset":0}}
{"text":"This paper provides a detailed overview of these experiments, their results, and implications, establishing that using LLMs' in-context learning capabilities to correct potential errors in speech recognition transcriptions is still a challenging task at the current stage.","cats":{"new-dataset":0}}
{"text":"The application offers functionalities for data loading, management, summarization, basic graphs, advanced analysis, and contact.","cats":{"new-dataset":0}}
{"text":"Additionally, the application offers statistical tools such as time series analysis using ARIMA and SARIMA models, forecasting, and Ljung-Box statistic.","cats":{"new-dataset":0}}
{"text":"Its user-friendly interface empowers individuals from various domains, including beginners in statistics, to make informed decisions.","cats":{"new-dataset":0}}
{"text":"Finally, we release a large-scale benchmark dataset with human feedback on figure-caption pairs to enable further evaluation and development of RLHF techniques for this problem.","cats":{"new-dataset":1}}
{"text":"Captions are crucial for understanding scientific visualizations and documents.","cats":{"new-dataset":0}}
{"text":"Existing captioning methods for scientific figures rely on figure-caption pairs extracted from documents for training, many of which fall short with respect to metrics like helpfulness, explainability, and visual-descriptiveness [15] leading to generated captions being misaligned with reader preferences.","cats":{"new-dataset":0}}
{"text":"To enable the generation of high-quality figure captions, we introduce FigCaps-HF a new framework for figure-caption generation that can incorporate domain expert feedback in generating captions optimized for reader preferences.","cats":{"new-dataset":0}}
{"text":"Our framework comprises of 1) an automatic method for evaluating quality of figure-caption pairs, 2) a novel reinforcement learning with human feedback (RLHF) method to optimize a generative figure-to-caption model for reader preferences.","cats":{"new-dataset":0}}
{"text":"We demonstrate the effectiveness of our simple learning framework by improving performance over standard fine-tuning across different types of models.","cats":{"new-dataset":0}}
{"text":"In particular, when using BLIP as the base model, our RLHF framework achieves a mean gain of 35.7%, 16.9%, and 9% in ROUGE, BLEU, and Meteor, respectively.","cats":{"new-dataset":0}}
{"text":"In this paper, we introduce RetouchingFFHQ, a large-scale and fine-grained face retouching dataset that contains over half a million conditionally-retouched images.","cats":{"new-dataset":1}}
{"text":"RetouchingFFHQ stands out from previous datasets due to its large scale, high quality, fine-grainedness, and customization","cats":{"new-dataset":1}}
{"text":"With the proposed new dataset, we believe there is great potential for future work to tackle the challenging problem of real-world fine-grained face retouching detection.","cats":{"new-dataset":0}}
{"text":"The widespread use of face retouching filters on short-video platforms has raised concerns about the authenticity of digital appearances and the impact of deceptive advertising.","cats":{"new-dataset":0}}
{"text":"To address these issues, there is a pressing need to develop advanced face retouching techniques.","cats":{"new-dataset":0}}
{"text":"However, the lack of large-scale and fine-grained face retouching datasets has been a major obstacle to progress in this field.  ","cats":{"new-dataset":0}}
{"text":"RetouchingFFHQ stands out from previous datasets due to its large scale, high quality, fine-grainedness, and customization.","cats":{"new-dataset":0}}
{"text":"By including four typical types of face  multi-retouching type, and multi-retouching level estimation problem.","cats":{"new-dataset":0}}
{"text":"Additionally, we propose a Multi-granularity Attention Module (MAM) as a plugin for CNN backbones for enhanced cross-scale representation learning.","cats":{"new-dataset":0}}
{"text":"Extensive experiments using different baselines as well as our proposed method on RetouchingFFHQ show decent performance on face retouching detection.","cats":{"new-dataset":0}}
{"text":"In this study, we introduce an event-based dataset on fine-grained manipulation actions and perform an experimental study on the use of transformers for action prediction with events","cats":{"new-dataset":1}}
{"text":"Finally, we release the new event dataset, which is the first in the literature for manipulation action recognition.","cats":{"new-dataset":0}}
{"text":"Neuromorphic visual sensors are artificial retinas that output sequences of asynchronous events when brightness changes occur in the scene.","cats":{"new-dataset":0}}
{"text":"These sensors offer many advantages including very high temporal resolution, no motion blur and smart data compression ideal for real-time processing. .","cats":{"new-dataset":0}}
{"text":"There is enormous interest in the fields of cognitive robotics and human-robot interaction on understanding and predicting human actions as early as possible.","cats":{"new-dataset":0}}
{"text":"Early prediction allows anticipating complex stages for planning, enabling effective and real-time interaction.","cats":{"new-dataset":0}}
{"text":"Our Transformer network uses events to predict manipulation actions as they occur, using online inference.","cats":{"new-dataset":0}}
{"text":"The model succeeds at predicting actions early on, building up confidence over time and achieving state-of-the-art classification.","cats":{"new-dataset":0}}
{"text":"Moreover, the attention-based transformer architecture allows us to study the role of the spatio-temporal patterns selected by the model.","cats":{"new-dataset":0}}
{"text":"Our experiments show that the Transformer network captures action dynamic features outperforming video-based approaches and succeeding with scenarios where the differences between actions lie in very subtle cues.","cats":{"new-dataset":0}}
{"text":"Code will be available at https://github.com/DaniDeniz/EventVisio","cats":{"new-dataset":0}}
{"text":"This dataset encompasses three image collections in which rodent neuronal cells' nuclei and cytoplasm are stained with diverse markers to highlight their anatomical or functional characteristics","cats":{"new-dataset":1}}
{"text":"Alongside the images, we provide ground-truth annotations for several learning tasks, including semantic segmentation, object detection, and counting","cats":{"new-dataset":1}}
{"text":"First, given the variety of annotations and their accessible formats, we envision our work facilitating methodological advancements in computer vision approaches for segmentation, detection, feature learning, unsupervised and self-supervised learning, transfer learning, and related areas","cats":{"new-dataset":1}}
{"text":"The data are available at: https://amsacta.unibo.it/id/eprint/7347","cats":{"new-dataset":1}}
{"text":"Fluorescent Neuronal Cells v2 is a collection of fluorescence microscopy images and the corresponding ground-truth annotations, designed to foster innovative research in the domains of Life Sciences and Deep Learning. .","cats":{"new-dataset":0}}
{"text":"Alongside the images, we provide ground-truth annotations for several learning tasks, including semantic segmentation, object detection, and counting.","cats":{"new-dataset":0}}
{"text":"The contribution is two-fold.","cats":{"new-dataset":0}}
{"text":"First, given for segmentation, detection, feature learning, unsupervised and self-supervised learning, transfer learning, and related areas.","cats":{"new-dataset":0}}
{"text":"Second, by enabling extensive exploration and benchma","cats":{"new-dataset":0}}
{"text":"Traditional Chinese Painting (TCP) is an invaluable cultural heritage resource and a unique visual art style.","cats":{"new-dataset":0}}
{"text":"In recent years, increasing interest has been placed on digitalizing TCPs to preserve and revive the culture.","cats":{"new-dataset":0}}
{"text":"The resulting digital copies have enabled the advancement of computational methods for structured and systematic understanding of TCPs.","cats":{"new-dataset":0}}
{"text":"To explore this topic, we conducted an in-depth analysis of 92 pieces of literature.","cats":{"new-dataset":0}}
{"text":"We examined the current use of computer technologies on TCPs from three perspectives, based on numerous conversations with specialists.","cats":{"new-dataset":0}}
{"text":"First, in light of the \"Six Principles of Painting\" theory, we categorized the articles according to their research focus on artistic elements.","cats":{"new-dataset":0}}
{"text":"Second, we created a four-stage framework to illustrate the purposes of TCP applications.","cats":{"new-dataset":0}}
{"text":"Third, we summarized the popular computational techniques applied to TCPs.","cats":{"new-dataset":0}}
{"text":"The framework also provides insights into potential applications and future prospects, with professional opinion.","cats":{"new-dataset":0}}
{"text":"The list of surveyed publications and related information is available online at https://ca4tcp.com.","cats":{"new-dataset":0}}
{"text":"Using the datasets built from in-the-wild images, our method gradually presents a controllable appearance editing function","cats":{"new-dataset":1}}
{"text":"We will release the dataset and code on https://lty2226262.github.io/car-studio/ to facilitate further research in the field.","cats":{"new-dataset":1}}
{"text":"Compositional neural scene graph studies have shown that radiance fields can be an efficient tool in an editable autonomous driving simulator.","cats":{"new-dataset":0}}
{"text":"However, previous studies learned within a sequence of autonomous driving datasets, resulting in unsatisfactory blurring when rotating the car in the simulator.","cats":{"new-dataset":0}}
{"text":"In this letter, we propose a pipeline for learning unconstrained images and building a dataset from processed images.","cats":{"new-dataset":0}}
{"text":"To meet the requirements of the simulator, which demands that the vehicle maintain clarity when the perspective changes and that the contour remains sharp from the background to avoid artifacts when editing, we design a radiation field of the vehicle, a crucial part of the urban scene foreground.","cats":{"new-dataset":0}}
{"text":"Through experiments, we demonstrate that our model achieves competitive performance compared to baselines. .","cats":{"new-dataset":0}}
{"text":"We will release the dataset and code on https://lty2226262.github.io/car-studio/ to facilitate further research in the fie","cats":{"new-dataset":0}}
{"text":"To solve this task, we build a heterogeneous multi-agent tidying-up benchmark dataset in a large number of houses with multiple rooms based on ProcTHOR-10K.","cats":{"new-dataset":1}}
{"text":"Multi-agent embodied tasks have recently been studied in complex indoor visual environments.","cats":{"new-dataset":0}}
{"text":"Collaboration among multiple agents can improve work efficiency and has significant practical value.","cats":{"new-dataset":0}}
{"text":"However, most of the existing research focuses on homogeneous multi-agent tasks.","cats":{"new-dataset":0}}
{"text":"Compared with homogeneous agents, heterogeneous agents can leverage their different capabilities to allocate corresponding sub-tasks and cooperate to complete complex tasks.","cats":{"new-dataset":0}}
{"text":"Heterogeneous multi-agent tasks are common in real-world scenarios, and the collaboration strategy among heterogeneous agents is a challenging and important problem to be solved.","cats":{"new-dataset":0}}
{"text":"To study collaboration among heterogeneous agents, we propose the heterogeneous multi-agent tidying-up task, in which multiple heterogeneous agents with different capabilities collaborate with each other to detect misplaced objects and place them in reasonable locations.","cats":{"new-dataset":0}}
{"text":"This is a demanding task since it requires agents to make the best use of their different capabilities to conduct reasonable task planning and complete the whole task.  ","cats":{"new-dataset":0}}
{"text":"We propose the hierarchical decision model based on misplaced object detection, reasonable receptacle prediction, as well as the handshake-based group communication mechanism.","cats":{"new-dataset":0}}
{"text":"Extensive experiments are conducted to demonstrate the effectiveness of the proposed model.","cats":{"new-dataset":0}}
{"text":"The project's website and videos of experiments can be found at https://hetercol.github.io/.","cats":{"new-dataset":0}}
{"text":"The field of trajectory forecasting has grown significantly in recent years, partially owing to the release of numerous large-scale, real-world human trajectory datasets for autonomous vehicles (AVs) and pedestrian motion tracking.","cats":{"new-dataset":0}}
{"text":"While such datasets have been a boon for the community, they each use custom and unique data formats and APIs, making it cumbersome for researchers to train and evaluate methods across multiple datasets.","cats":{"new-dataset":0}}
{"text":"To remedy this, we present trajdata: a unified interface to multiple human trajectory datasets.","cats":{"new-dataset":0}}
{"text":"At its core, trajdata provides a simple, uniform, and efficient representation and API for trajectory and map data.","cats":{"new-dataset":0}}
{"text":"As a demonstration of its capabilities, in this work we conduct a comprehensive empirical evaluation of existing trajectory datasets, providing users with a rich understanding of the data underpinning much of current pedestrian and AV motion forecasting research, and proposing suggestions for future datasets from these insights.","cats":{"new-dataset":0}}
{"text":"trajdata is permissively licensed (Apache 2.0) and can be accessed online at https://github.com/NVlabs/trajdata","cats":{"new-dataset":0}}
{"text":"The core recipe of GrammarGPT is to leverage the hybrid dataset of ChatGPT-generated and human-annotated.","cats":{"new-dataset":1}}
{"text":"Grammatical error correction aims to correct ungrammatical sentences automatically.","cats":{"new-dataset":0}}
{"text":"Recently, some work has demonstrated the excellent capabilities of closed-source Large Language Models (LLMs, e.g., ChatGPT) in grammatical error correction.","cats":{"new-dataset":0}}
{"text":"However, the potential of open-source LLMs remains unexplored.","cats":{"new-dataset":0}}
{"text":"In this paper, we introduced GrammarGPT, an open-source LLM, to preliminary explore its potential for native Chinese grammatical error correction.  ","cats":{"new-dataset":0}}
{"text":"For grammatical errors with clues, we proposed a heuristic method to guide ChatGPT to generate ungrammatical sentences by providing those clues.","cats":{"new-dataset":0}}
{"text":"For grammatical errors without clues, we collected ungrammatical sentences from publicly available websites and manually corrected them.","cats":{"new-dataset":0}}
{"text":"In addition, we employed an error-invariant augmentation method to enhance the ability of the model to correct native Chinese grammatical errors.","cats":{"new-dataset":0}}
{"text":"We ultimately constructed about 1k parallel data and utilized these data to fine-tune open-source LLMs (e.g., Phoenix, released by The Chinese University of Hong Kong, Shenzhen) with instruction tuning.","cats":{"new-dataset":0}}
{"text":"The experimental results show that GrammarGPT outperforms the existing SOTA system significantly.","cats":{"new-dataset":0}}
{"text":"Although model parameters are 20x larger than the SOTA baseline, the required amount of data for instruction tuning is 1200x smaller, illustrating the potential of open-source LLMs on native CGEC.","cats":{"new-dataset":0}}
{"text":"Our GrammarGPT ranks $3^{rd}$ on NLPCC2023 SharedTask1, demonstrating our approach's effectiveness.","cats":{"new-dataset":0}}
{"text":"The code and data are available at \\url{https://github.com/FreedomIntelligence/GrammarGPT}.","cats":{"new-dataset":0}}
{"text":"Bayesian causal discovery aims to infer the posterior distribution over causal models from observed data, quantifying epistemic uncertainty and benefiting downstream tasks.","cats":{"new-dataset":0}}
{"text":"However, computational challenges arise due to joint inference over combinatorial space of Directed Acyclic Graphs (DAGs) and nonlinear functions.","cats":{"new-dataset":0}}
{"text":"Despite recent progress towards efficient posterior inference over DAGs, existing methods are either limited to variational inference on node permutation matrices for linear causal models, leading to compromised inference accuracy, or continuous relaxation of adjacency matrices constrained by a DAG regularizer, which cannot ensure resulting graphs are DAGs.","cats":{"new-dataset":0}}
{"text":"In this work, we introduce a scalable Bayesian causal discovery framework based on stochastic gradient Markov Chain Monte Carlo (SG-MCMC) that overcomes these limitations.","cats":{"new-dataset":0}}
{"text":"Our approach directly samples DAGs from the posterior without requiring any DAG regularization, simultaneously draws function parameter samples and is applicable to both linear and nonlinear causal models.","cats":{"new-dataset":0}}
{"text":"To enable our approach, we derive a novel equivalence to the permutation-based DAG learning, which opens up possibilities of using any relaxed gradient estimator defined over permutations.","cats":{"new-dataset":0}}
{"text":"To our knowledge, this is the first framework applying gradient-based MCMC sampling for causal discovery.","cats":{"new-dataset":0}}
{"text":"Empirical evaluations on synthetic and real-world datasets demonstrate our approach's effectiveness compared to state-of-the-art baselines.","cats":{"new-dataset":0}}
{"text":"We present YOLOBench, a benchmark comprised of 550+ YOLO-based object detection models on 4 different datasets and 4 different embedded hardware platforms (x86 CPU, ARM CPU, Nvidia GPU, NPU).","cats":{"new-dataset":0}}
{"text":"We collect accuracy and latency numbers for a variety of YOLO-based one-stage detectors at different model scales by performing a fair, controlled comparison of these detectors with a fixed training environment (code and training hyperparameters).","cats":{"new-dataset":0}}
{"text":"Pareto-optimality analysis of the collected data reveals that, if modern detection heads and training techniques are incorporated into the learning process, multiple architectures of the YOLO series achieve a good accuracy-latency trade-off, including older models like YOLOv3 and YOLOv4.","cats":{"new-dataset":0}}
{"text":"We also evaluate training-free accuracy estimators used in neural architecture search on YOLOBench and demonstrate that, while most state-of-the-art zero-cost accuracy estimators are outperformed by a simple baseline like MAC count, some of them can be effectively used to predict Pareto-optimal detection models.","cats":{"new-dataset":0}}
{"text":"We showcase that by using a zero-cost proxy to identify a YOLO architecture competitive against a state-of-the-art YOLOv8 model on a Raspberry Pi 4 CPU.","cats":{"new-dataset":0}}
{"text":"The code and data are available at https://github.com/Deeplite/deeplite-torch-zoo","cats":{"new-dataset":0}}
{"text":"Advancements in large pre-trained generative models have expanded their potential as effective data generators in visual recognition.","cats":{"new-dataset":0}}
{"text":"This work delves into the impact of generative images, primarily comparing paradigms that harness external data (\\ie generative \\vs retrieval \\vs original).   ","cats":{"new-dataset":0}}
{"text":"Our key contributions are: \\textbf{1) GenBench Construction:}","cats":{"new-dataset":0}}
{"text":"We devise \\textbf{GenBench}, a broad benchmark comprising 22 datasets with 2548 categories, to appraise generative data across various visual recognition tasks.","cats":{"new-dataset":0}}
{"text":"\\textbf{2) CLER Score:} To address the insufficient correlation of existing metrics (\\eg, FID, CLIP score) with downstream recognition performance, we propose \\textbf{CLER}, a training-free metric indicating generative data's efficiency for recognition tasks prior to training.","cats":{"new-dataset":0}}
{"text":"\\textbf{3) New Baselines:} Comparisons of generative data with retrieved data from the same external pool help to elucidate the unique traits of generative data.","cats":{"new-dataset":0}}
{"text":"\\textbf{4)","cats":{"new-dataset":0}}
{"text":"External Knowledge Injection:} By fine-tuning special token embeddings for each category via Textual Inversion, performance improves across 17 datasets, except when dealing with low-resolution reference images.   ","cats":{"new-dataset":0}}
{"text":"Our exhaustive benchmark and analysis spotlight generative data's promise in visual recognition, while identifying key challenges for future investigation.","cats":{"new-dataset":0}}
{"text":"We introduce this large-scale synthesised dataset of 250K photorealistic images and corresponding 3DMM parameters.","cats":{"new-dataset":1}}
{"text":"Accurate 3D face shape estimation is an enabling technology with applications in healthcare, security, and creative industries, yet current state-of-the-art methods either rely on self-supervised training with 2D image data or supervised training with very limited 3D data.","cats":{"new-dataset":0}}
{"text":"To bridge this gap, we present a novel approach which uses a conditioned stable diffusion model for face image generation, leveraging the abundance of 2D facial information to inform 3D space.","cats":{"new-dataset":0}}
{"text":"By conditioning stable diffusion on depth maps sampled from a 3D Morphable Model (3DMM) of the human face, we generate diverse and shape-consistent images, forming the basis of SynthFace.  ","cats":{"new-dataset":0}}
{"text":"We further propose ControlFace, a deep neural network, trained on SynthFace, which achieves competitive performance on the NoW benchmark, without requiring 3D supervision or manual 3D asset creation.","cats":{"new-dataset":0}}
{"text":"To this aim we focused only on images generated by the famous DALL-E 2 and collected images (both original and generated) of five renowned artists.","cats":{"new-dataset":1}}
{"text":"Dataset and code are available at: https://github.com/ictlab-unict/not-with-my-name .","cats":{"new-dataset":0}}
{"text":"Diffusion Models (DM) are highly effective at generating realistic, high-quality images.","cats":{"new-dataset":0}}
{"text":"However, these models lack creativity and merely compose outputs based on their training data, guided by a textual input provided at creation time.","cats":{"new-dataset":0}}
{"text":"Is it acceptable to generate images reminiscent of an artist, employing his name as input?","cats":{"new-dataset":0}}
{"text":"This imply that if the DM is able to replicate an artist's work then it was trained on some or all of his artworks thus violating copyright.","cats":{"new-dataset":0}}
{"text":"In this paper, a preliminary study to infer the probability of use of an artist's name in the input string of a generated image is presented.  ","cats":{"new-dataset":0}}
{"text":"Finally, a dedicated Siamese Neural Network was employed to have a first kind of probability.","cats":{"new-dataset":0}}
{"text":"Experimental results demonstrate that our approach is an optimal starting point and can be employed as a prior for predicting a complete input string of an investigated image.","cats":{"new-dataset":0}}
{"text":"The consumption of podcast media has been increasing rapidly.","cats":{"new-dataset":0}}
{"text":"Due to the lengthy nature of podcast episodes, users often carefully select which ones to listen to.","cats":{"new-dataset":0}}
{"text":"Although episode descriptions aid users by providing a summary of the entire podcast, they do not provide a topic-by-topic breakdown.","cats":{"new-dataset":0}}
{"text":"This study explores the combined application of topic segmentation and text summarisation methods to investigate how podcast episode comprehension can be improved.","cats":{"new-dataset":0}}
{"text":"We have sampled 10 episodes from Spotify's English-Language Podcast Dataset and employed TextTiling and TextSplit to segment them.","cats":{"new-dataset":0}}
{"text":"Moreover, three text summarisation models, namely T5, BART, and Pegasus, were applied to provide a very short title for each segment.","cats":{"new-dataset":0}}
{"text":"The segmentation part was evaluated using our annotated sample with the $P_k$ and WindowDiff ($WD$) metrics.","cats":{"new-dataset":0}}
{"text":"A survey was also rolled out ($N=25$) to assess the quality of the generated summaries.","cats":{"new-dataset":0}}
{"text":"The TextSplit algorithm achieved the lowest mean for both evaluation metrics ($\\bar{P_k}=0.41$ and $\\bar{WD}=0.41$), while the T5 model produced the best summaries, achieving a relevancy score only $8\\%$ less to the one achieved by the human-written titles.","cats":{"new-dataset":0}}
{"text":"Our team gathered a dataset of 19,779 accounts that meet standardized criteria to enable future research on bots in open-source projects.","cats":{"new-dataset":1}}
{"text":"Social coding platforms have revolutionized collaboration in software development, leading to using software bots for streamlining operations.","cats":{"new-dataset":0}}
{"text":"However, The presence of open-source software (OSS) bots gives rise to problems including impersonation, spamming, bias, and security risks.","cats":{"new-dataset":0}}
{"text":"Identifying bot accounts and behavior is a challenging task in the OSS project.","cats":{"new-dataset":0}}
{"text":"This research aims to investigate bots' behavior in open-source software projects and identify bot accounts with maximum possible accuracy.  ","cats":{"new-dataset":0}}
{"text":"We follow a rigorous workflow to ensure that the data we collect is accurate, generalizable, scalable, and up-to-date.","cats":{"new-dataset":0}}
{"text":"We've identified four types of bot accounts in open-source software projects by analyzing their behavior across 17 features in 5 dimensions.","cats":{"new-dataset":0}}
{"text":"Our team created BotHawk, a highly effective model for detecting bots in open-source software projects.","cats":{"new-dataset":0}}
{"text":"It outperforms other models, achieving an AUC of 0.947 and an F1-score of 0.89.","cats":{"new-dataset":0}}
{"text":"BotHawk can detect a wider variety of bots, including CI/CD and scanning bots.","cats":{"new-dataset":0}}
{"text":"Furthermore, we find that the number of followers, number of repositories, and tags contain the most relevant features to identify the account type.","cats":{"new-dataset":0}}
{"text":"Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization.","cats":{"prompt-eng":1}}
{"text":"The specific assignment prompted students to define and explain their career goals as engineers.","cats":{"prompt-eng":0}}
{"text":"Prompt engineering typically requires hand-crafting a set of prompts for individual downstream tasks.","cats":{"prompt-eng":1}}
{"text":"It turns out that the key challenge lies in designing the most effective prompt for the LLM, a task called prompt engineering.","cats":{"prompt-eng":1}}
{"text":"Specifically, we add a set of ``task prompts'', each corresponding to a different task, and let each prompt predict task-related annotations.","cats":{"prompt-eng":1}}
{"text":"To accomplish this task, we employ prompt engineering, a technique that involves designing prompts to guide the LLMs towards the desired output.","cats":{"prompt-eng":1}}
{"text":"The context of our task leverages a generative model as an IR engine to evaluate the prompts' performance on image retrieval tasks.","cats":{"prompt-eng":1}}
{"text":"Specifically, we first perform supervised fine-tuning with a pretrained language model on a small collection of manually engineered prompts.","cats":{"prompt-eng":1}}
{"text":"We first devise a learnable universal prompt to describe the correlations among all tasks and then convert this prompt and image features into a task-specific prompt, which is fed to the decoder as a part of its input.","cats":{"prompt-eng":1}}
{"text":"Our studies offer a deeper understanding of prompt engineering thereby opening up avenues for research on the future of prompt engineering.","cats":{"prompt-eng":1}}
{"text":"Designing suitable prompts for specific visual tasks has emerged as a meaningful research direction.","cats":{"prompt-eng":0}}
{"text":"We design task-specific prompts, by either leveraging another large-scale model, or simply manipulating the special tokens in the default prompts.","cats":{"prompt-eng":1}}
{"text":"We adopt a specific prompting approach to solving the ranking task by LLMs: we carefully design the prompting template by including the sequential interaction history, the candidate items, and the ranking instruction.","cats":{"prompt-eng":1}}
{"text":"To be specific, we design a set of prompts to fine-tune the pre-trained image captioner.","cats":{"prompt-eng":1}}
{"text":"However, these approaches are task-specific; designing algorithms for new tasks is a cumbersome process.","cats":{"prompt-eng":0}}
{"text":"Therefore, no further task-specific reward design is needed.","cats":{"prompt-eng":0}}
{"text":"In this report, we aim to further mine ChatGPT's translation ability by revisiting several aspects: temperature, task information, and domain information, and correspondingly propose two (simple but effective) prompts: Task-Specific Prompts (TSP) and Domain-Specific Prompts (DSP).","cats":{"prompt-eng":1}}
{"text":"However, existing methods struggle with either computational complexity or model expressivity, rendering the maximum sequence length restricted.","cats":{"prompt-eng":0,"data-quality":0}}
{"text":"LongNet has significant advantages: 1) it has a linear computation complexity and a logarithm dependency between tokens; 2) it can be served as a distributed trainer for extremely long sequences; 3) its dilated attention is a drop-in replacement for standard attention, which can be seamlessly integrated with the existing Transformer-based optimization.","cats":{"prompt-eng":0}}
{"text":"In the case where the region is the entire infinite triangular grid, we prove that the existence of a solution can be solved with an algorithm of complexity $O(|X|^3)$ where $X$ is the set of input edges.","cats":{"prompt-eng":0}}
{"text":"Please check out our webpage at https://sites.google.com/view/automatic-prompt-engineer.","cats":{"prompt-eng":1}}
{"text":"Creating a high-quality prompt that consists of a subject and several modifiers can be time-consuming and costly.","cats":{"prompt-eng":1}}
{"text":"We refer to this approach as ``Promptonomy'', since the prompts model task-related structure.","cats":{"prompt-eng":1}}
{"text":"Overall, our approach provides a robust and fundamental theoretical framework for selecting simple and effective prompts.","cats":{"prompt-eng":1}}
{"text":"To address this issue in prompt engineering, we propose a new and effective approach called Prompt Space.","cats":{"prompt-eng":1}}
{"text":"Prompt-based language models have produced encouraging results in numerous applications, including Named Entity Recognition (NER) tasks.","cats":{"prompt-eng":1}}
{"text":"We evaluate different prompt designs in zero- and few-shot settings and experiment with providing task definitions and detailed instructions to the model.","cats":{"prompt-eng":1}}
{"text":"In our evaluation, we focus on zero-shot prompting, comparing four prompt variants in two modes, based on the availability of the reference.","cats":{"prompt-eng":1}}
{"text":"Based on these findings, we also propose a method for generating prompts using only unlabeled data, outperforming strong baselines by an average of 7.0% accuracy across three tasks.","cats":{"prompt-eng":1}}
{"text":"However, the strong performance of most available NER approaches is heavily dependent on the design of discrete prompts and a verbalizer to map the model-predicted outputs to entity categories, which are complicated undertakings.","cats":{"prompt-eng":1}}
{"text":"Methodologically, PCR-Chain is backed up by the underlying global-level prompt architecture (which combines three design ideas: hierarchical task breakdown, prompt composition, and a mix of prompt-based AI and non-AI units) and the local-level prompt design.","cats":{"prompt-eng":1}}
{"text":"Prompts are also a form of programming that can customize the outputs and interactions with an LLM.","cats":{"prompt-eng":0}}
{"text":"We approach this problem by attempting to modify the predictions of a prompt, rather than the prompt itself.","cats":{"prompt-eng":1}}
{"text":"Our user study evaluated and demonstrated the efficiency and correctness of Prompt Sapper.","cats":{"prompt-eng":1}}
{"text":"In this work, we aim to automate this prompt engineering and improve zero-shot accuracy through prompt ensembling.","cats":{"prompt-eng":1}}
{"text":"Instead of laborious human engineering, we propose prompt adaptation, a general framework that automatically adapts original user input to model-preferred prompts.","cats":{"prompt-eng":1}}
{"text":"Recently, their generalizability has been further extended by incorporating trainable prompts, borrowed from the natural language processing literature.","cats":{"prompt-eng":1}}
{"text":"Prompt Engineering has gained significant relevance in recent years, fueled by advancements in pre-trained and large language models.","cats":{"prompt-eng":0}}
{"text":"Large language models that are capable of zero or few-shot prompting approaches have given rise to the new research area of prompt engineering.","cats":{"prompt-eng":0}}
{"text":"Recently, prompt learning emerged as an NLP paradigm that can lead to more generalizable results without any (zero-shot) or few labeled samples (few-shot).","cats":{"prompt-eng":0}}
{"text":"Extensive experiments show that PromptClass achieves overall better performance than existing strong baselines on four benchmark datasets and even achieves similar performance to fully-supervised classifiers on sentiment classification tasks.","cats":{"prompt-eng":1}}
{"text":"Furthermore, it generates more detailed and comprehensible assessments than traditional text classification methods.","cats":{"prompt-eng":0}}
{"text":"Despite advancements in conversational AI, language models encounter challenges to handle diverse conversational tasks, and existing dialogue dataset collections often lack diversity and comprehensiveness.","cats":{"prompt-eng":0}}
{"text":"To further enhance the utility of DialogStudio, we identify the licenses for each dataset and design domain-aware prompts for selected dialogues to facilitate instruction-aware fine-tuning.","cats":{"prompt-eng":0}}
{"text":"Furthermore, we develop conversational AI models using the dataset collection, and our experiments in both zero-shot and few-shot learning scenarios demonstrate the superiority of DialogStudio.","cats":{"prompt-eng":0}}
{"text":"To improve transparency and support dataset and task-based research, as well as language model pre-training, all datasets, licenses, codes, and models associated with DialogStudio are made publicly accessible at https://github.com/salesforce/DialogStudio","cats":{"prompt-eng":0}}
{"text":"However, even manually labeled datasets contain errors, not to mention automatically labeled ones.","cats":{"data-quality":1}}
{"text":"Label error is a ubiquitous problem in annotated data.","cats":{"data-quality":1}}
{"text":"After demonstrating that our methodology empirically outperforms other algorithms for label error detection, we apply our approach to discover many label errors in the CelebA image tagging dataset.","cats":{"data-quality":1}}
{"text":"These properties highlight a tradeoff between classification error probability and error-correction capabilities of label encodings.","cats":{"data-quality":0}}
{"text":"In this work, we for the first time introduce a benchmark for label error detection methods on object detection datasets as well as a label error detection method and a number of baselines.","cats":{"data-quality":1}}
{"text":"Label encodings found by RLEL result in lower or comparable errors to manually designed label encodings.","cats":{"data-quality":1}}
{"text":"We also propose an improved self-labeling loss; it is robust to pseudo-labeling errors and enforces stronger fairness.","cats":{"data-quality":1}}
{"text":"Inferencing unlabeled data from labeled data is an error-prone process.","cats":{"data-quality":1}}
{"text":"However, creating such large keypoint labels is time-consuming and costly, and is often error-prone due to inconsistent labeling.","cats":{"data-quality":0}}
{"text":"The losses are computed with respect to the predictions and the noisy labels including simulated label errors, aiming at detecting the latter.","cats":{"data-quality":1}}
{"text":"PseudoAugments outperforms pseudo labeling by mitigating pseudo labeling errors and generating diverse fused training scenes.","cats":{"data-quality":1}}
{"text":"Our model is also able to maintain high classification accuracy with very few labels, with only 7.79% error when only using 145 labels.","cats":{"data-quality":0}}
{"text":"Detecting errors in KGs is challenging since the patterns of errors are unknown and diverse, while ground-truth labels are rare or even unavailable.","cats":{"data-quality":1}}
{"text":"We analyze the factors affecting this approximation error and design a pseudo-label clustering generation method to reduce the approximation error.","cats":{"data-quality":1}}
{"text":"To ameliorate the impact of label errors, we equipped our method with a novel negative label sampling strategy to strengthen the model robustness.","cats":{"data-quality":1}}
{"text":"We propose an extension of the Confident Learning framework to this setting, as well as a label quality score that ranks examples with label errors much higher than those which are correctly labeled.","cats":{"data-quality":1}}
{"text":"The later case can generate dense flow labels but the interpolated events are prone to errors.","cats":{"data-quality":0}}
{"text":"Improper fingerprint localization and finger labeling errors lead to poor matching performance.","cats":{"data-quality":0}}
{"text":"Our experiments show that our method is robust to linguistic labels with poor orthography and alignment errors.","cats":{"data-quality":1}}
{"text":"We derive an upper bound for the generalization error that is linear in the clients' label noise level.","cats":{"data-quality":1}}
{"text":"For example, for the IMDB text data with known labeling errors, a 14% boost is shown.","cats":{"data-quality":1}}
{"text":"Large amounts of label error substantially degrades the quality of deep learning models.","cats":{"data-quality":1}}
{"text":"We simulate four different types of randomly introduced label errors on train and test sets of well-labeled object detection datasets.","cats":{"data-quality":1}}
{"text":"We prove that semi-supervised labels improve the downstream error bound whereas noisy labels have limited effects under such a paradigm.","cats":{"data-quality":1}}
{"text":"This paper provides an exact characterization of the expected generalization error (gen-error) for semi-supervised learning (SSL) with pseudo-labeling via the Gibbs algorithm.","cats":{"data-quality":0}}
{"text":"However, corresponding class labels are noisy when provided by error-prone annotators, e.g., crowd workers.","cats":{"data-quality":1}}
{"text":"Most existing methods utilize the off-the-shelf pose or parsing networks as pseudo labels, which are prone to error.","cats":{"data-quality":0}}
{"text":"The result is an SSL classification framework explicitly designed to overcome inevitable pseudo-label errors.","cats":{"data-quality":1}}
{"text":"Here we consider the task of finding sentences that contain label errors in token classification datasets.","cats":{"data-quality":1}}
{"text":"Scaling sequence length has become a critical demand in the era of large language models.","cats":{"data-quality":0}}
{"text":"In this work, we introduce LongNet, a Transformer variant that can scale sequence length to more than 1 billion tokens, without sacrificing the performance on shorter sequences.","cats":{"data-quality":0}}
{"text":"Specifically, we propose dilated attention, which expands the attentive field exponentially as the distance grows.","cats":{"data-quality":0}}
{"text":"Experiments results demonstrate that LongNet yields strong performance on both long-sequence modeling and general language tasks.","cats":{"data-quality":0}}
{"text":"Large Language Models (LLMs) have demonstrated impressive planning abilities in single-agent embodied tasks across various domains.","cats":{"data-quality":0}}
{"text":"However, their capacity for planning and communication in multi-agent cooperation remains unclear, even though these are crucial skills for intelligent embodied agents.","cats":{"data-quality":0}}
{"text":"In this paper, we present a novel framework that utilizes LLMs for multi-agent cooperation and tests it in various embodied environments.","cats":{"data-quality":0}}
{"text":"Our framework enables embodied agents to plan, communicate, and cooperate with other embodied agents or humans to accomplish long-horizon tasks efficiently.","cats":{"data-quality":0}}
{"text":"We demonstrate that recent LLMs, such as GPT-4, can surpass strong planning-based methods and exhibit emergent effective communication using our framework without requiring fine-tuning or few-shot prompting.","cats":{"data-quality":0}}
{"text":"We also discover that LLM-based agents that communicate in natural language can earn more trust and cooperate more effectively with humans.","cats":{"data-quality":0}}
{"text":"For QE in particular, high-quality labeled data is often lacking due to the high-cost and effort associated with labeling such data.","cats":{"data-quality":0}}
{"text":"With many possible classes to consider, data annotators are likely to make errors when labeling such data in practice.","cats":{"data-quality":1}}
{"text":"However, it usually suffers from a lack of high-quality datasets due to high annotation cost, inter-observer variability, human annotator error, and errors in computer-generated labels.","cats":{"data-quality":0}}
{"text":"For such bone structure analyses, deep learning technologies are promising but require high-quality labeled data for the learning, while the data labeling is costly.","cats":{"data-quality":0}}
{"text":"However, agreement between annotators is often low, leading to inconsistent labels that hinder the reliability of models.","cats":{"data-quality":1}}
{"text":"Our experiments show that this approach consistently improves inter-annotator agreement and annotation accuracy.","cats":{"data-quality":1}}
{"text":"We advocate for the use of IAA in predicting the labeling quality of individual annotators, leading to cost and time efficiency in data production.","cats":{"data-quality":1}}
{"text":"This paper presents a novel approach of leveraging Inter-Annotator Agreement (IAA), traditionally used for assessing labeling consistency, to optimize Data Management Operations (DMOps).","cats":{"data-quality":1}}
{"text":"Our study illustrates that different labeling methodologies directly impact the annotations' quality, as well as the capabilities of a deep learning classifier trained with the data respectively.","cats":{"data-quality":1}}
{"text":"However, such annotations may fail in practice because of the change in annotation requirements, application scenarios, and modeling goals, where label validation and relabeling by domain experts are required.","cats":{"data-quality":1}}
{"text":"However, selecting training samples based on the degree of agreement between annotators introduces a bias in the training data and does not improve the results.","cats":{"data-quality":1}}
{"text":"However, these annotations are inherently subjective and some of the instances are hard to classify, resulting in noisy annotations due to error or lack of agreement.","cats":{"data-quality":1}}
{"text":"We propose and evaluate an additional application of our method leading to the detection of annotation errors.","cats":{"data-quality":1}}
{"text":"However, arbitrating the final annotation is not always effective because new biases might be produced during the process, especially when there are significant variations among annotations.","cats":{"data-quality":1}}
{"text":"A two-step human annotation and inter-annotator agreement study guarantee the high quality of the PcMSP corpus.","cats":{"data-quality":0}}
{"text":"We observe a striking correlation between the model's and humans' annotation: Categories with consistent human annotations (>$0.9$ inter-rater reliability, IRR) also display higher human-model agreement (>$0.7$), while categories with less consistent human annotations ($0.7$-$0.8$ IRR) correspondingly demonstrate lower human-model agreement ($0.3$-$0.5$).","cats":{"data-quality":1}}
{"text":"We propose two metrics to audit the noise of annotations.","cats":{"data-quality":1}}
{"text":"We will release our annotation scheme, the corpus, and codes to the research community to alleviate the scarcity of labeled data in this domain.","cats":{"data-quality":1}}
{"text":"Whereas such annotation is costly and hard to scale, significantly holding back the development of the research.","cats":{"data-quality":0}}
{"text":"A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label.","cats":{"data-quality":1}}
{"text":"We hypothesize two failure modes of safety training: competing objectives and mismatched generalization.","cats":{"data-quality":0}}
{"text":"Competing objectives arise when a model's capabilities and safety goals conflict, while mismatched generalization occurs when safety training fails to generalize to a domain for which capabilities exist.","cats":{"data-quality":0}}
{"text":"We find that vulnerabilities persist despite the extensive red-teaming and safety-training efforts behind these models.","cats":{"data-quality":0}}
{"text":"Specifically, we analyze the impact of the manifold's curvatures (or higher order nonlinearity in the parameterization when the curvatures are locally zero) on the uniqueness of the regression solution.","cats":{"data-quality":0}}
{"text":"Our findings suggest that the corresponding linear regression does not have a unique solution when the embedded submanifold is flat in some dimensions.","cats":{"data-quality":0}}
{"text":"Our findings thus reveal the role of data manifold geometry in ensuring the stability of regression models for out-of-distribution inferences.","cats":{"data-quality":0}}
{"text":"To disentangle these effects, we propose an evaluation framework based on \"counterfactual\" task variants that deviate from the default assumptions underlying standard tasks.","cats":{"data-quality":0}}
{"text":"Across a suite of 11 tasks, we observe nontrivial performance on the counterfactual variants, but nevertheless find that performance substantially and consistently degrades compared to the default conditions.","cats":{"data-quality":0}}
{"text":"We also propose an accurate pseudo label generation method through prototype learning.","cats":{"data-quality":0}}
{"text":"Specifically, we frame aggregation of annotations as posterior inference of so-called plausibilities, representing distributions over classes in a classification setting, subject to a hyper-parameter encoding annotator reliability.","cats":{"data-quality":1}}
{"text":"Based on this model, we propose a metric for measuring annotation uncertainty and provide uncertainty-adjusted metrics for performance evaluation.","cats":{"data-quality":0}}
{"text":"Identifying the samples with corrupted labels and preventing the model from learning them is a promising approach to address this challenge.","cats":{"data-quality":1}}
{"text":"Furthermore, we detect real label errors a) on commonly used test datasets in object detection and b) on a proprietary dataset.","cats":{"data-quality":1}}
{"text":"Large-scale datasets in the real world inevitably involve label noise.","cats":{"data-quality":0}}
{"text":"This is partially due to the fact that obtaining a balanced, diverse, and perfectly labeled dataset is typically expensive, time-consuming, and error-prone.","cats":{"data-quality":0}}
{"text":"We develop an efficient algorithm for detecting label errors and outlier data points based on the relational graph structure of the dataset.","cats":{"data-quality":1}}
{"text":"By focusing on finding incorrect labels in the original training datasets, we can eliminate erroneous examples in their root.","cats":{"data-quality":1}}
{"text":"Manually labelling data with high-quality labels is generally a time-consuming and challenging task and often this turns out to be the bottleneck in a machine learning project.","cats":{"data-quality":0}}
{"text":"Here we consider algorithms for finding mislabeled examples in multi-label classification datasets.","cats":{"data-quality":1}}
{"text":"Negative labels are those that a corresponding data item does not belong.","cats":{"data-quality":0}}
{"text":"This issue is due to biased labeling preferences at multiple clients and is a typical setting of data heterogeneity.","cats":{"data-quality":0}}
{"text":"However, noisy samples (i.e., with wrong labels) in the training set induce confusion and cause the network to learn the incorrect representation.","cats":{"data-quality":1}}
{"text":"Mislabeled examples are a common issue in real-world data, particularly for tasks like token classification where many labels must be chosen on a fine-grained basis.","cats":{"data-quality":1}}
{"text":"We also introduced robust loss to reduce the noise effects of inaccurate labels generated in semi-supervised learning.","cats":{"data-quality":1}}
{"text":"The main anomaly was found by the autoencoder and automatically created labels and was also recorded in the log files.","cats":{"data-quality":1}}
{"text":"About 0.2% of the images could not be assigned a label, while for 5.1% the reviewers were uncertain, or they assigned an invalid label.","cats":{"data-quality":1}}
{"text":"We find that the above issues are caused by the training dataset's pose imbalance.   ","cats":{"data-quality":0}}
{"text":"The labor-intensive annotation process of semantic segmentation datasets is often prone to errors, since humans struggle to label every pixel correctly.","cats":{"data-quality":1}}
{"text":"We study algorithms to automatically detect such annotation errors, in particular methods to score label quality, such that the images with the lowest scores are least likely to be correctly labeled.","cats":{"data-quality":1}}
{"text":"Widely applicable, our label quality scores rely on probabilistic predictions from a trained segmentation model -- any model architecture and training procedure can be utilized.","cats":{"data-quality":1}}
{"text":"Here we study 7 different label quality scoring methods used in conjunction with a DeepLabV3+ or a FPN segmentation model to detect annotation errors in a version of the SYNTHIA dataset.","cats":{"data-quality":1}}
{"text":"Precision-recall evaluations reveal a score -- the soft-minimum of the model-estimated likelihoods of each pixel's annotated class -- that is particularly effective to identify images that are mislabeled, across multiple types of annotation error.","cats":{"data-quality":1}}
{"text":"In recent years, research on learning with noisy labels has focused on devising novel algorithms that can achieve robustness to noisy training labels while generalizing to clean data.","cats":{"data-quality":1}}
{"text":"While some of these regularization strategies have been utilized in previous noisy label learning research, their full potential has not been thoroughly explored.","cats":{"data-quality":1}}
{"text":"We also synthetically mislabel a proportion of the dataset by randomly corrupting the labels of a few samples, and show that sorting by curvature yields high AUROC values for identifying the mislabeled samples.","cats":{"data-quality":1}}
{"text":"Further analysis shows that these gains come from an improved decision boundary after cleaning the label errors existed in the training data.","cats":{"data-quality":1}}
{"text":"Nevertheless, few papers have tackled the data shift problem in labeled training sets, which occurs when there is a mismatch between the data distribution in the training set and the testing set.","cats":{"data-quality":1}}
{"text":"In this work, we examine the problem for both labeled and unlabeled settings.","cats":{"data-quality":1}}
{"text":"It is crucial to correctly predict areas that deviate from the background noise, in both the train and test sets of labels.   ","cats":{"data-quality":0}}
{"text":"Data completeness is ensured through the label provided during training.","cats":{"data-quality":0}}
{"text":"Trustworthy pseudo labels on unlabeled data are generated after uncertainty estimation.","cats":{"data-quality":0}}
{"text":"When random label noise is added to a training dataset, the prediction error of a neural network on a label-noise-free test dataset initially improves during early training but eventually deteriorates, following a U-shaped dependence on training time.","cats":{"data-quality":0}}
{"text":"In this paper, we try to deal with error accumulation in noisy label learning from both model and data perspectives.","cats":{"data-quality":1}}
{"text":"In our analysis, we find that SoundDesc contains several duplicates that cause leakage of training data to the evaluation data.","cats":{"data-quality":1}}
{"text":"Motivated by the optimal strategy, we introduce double-score OOD methods that leverage uncertainty scores from two chosen OOD detectors: one focused on OOD/ID discrimination and the other on misclassification detection.","cats":{"data-quality":1}}
{"text":"The optimal prediction strategy for out-of-distribution (OOD) setups is a fundamental question in machine learning.","cats":{"data-quality":0}}
{"text":"In this paper, we address this question and present several contributions.","cats":{"data-quality":0}}
{"text":"We propose three reject option models for OOD setups: the Cost-based model, the Bounded TPR-FPR model, and the Bounded Precision-Recall model.","cats":{"data-quality":0}}
{"text":"These models extend the standard reject option models used in non-OOD setups and define the notion of an optimal OOD selective classifier.","cats":{"data-quality":0}}
{"text":"We establish that all the proposed models, despite their different formulations, share a common class of optimal strategies.  ","cats":{"data-quality":0}}
{"text":"The experimental results consistently demonstrate the superior performance of this simple strategy compared to state-of-the-art methods.","cats":{"data-quality":0}}
{"text":"Additionally, we propose novel evaluation metrics derived from the definition of the optimal strategy under the proposed OOD rejection models.","cats":{"data-quality":0}}
{"text":"These new metrics provide a comprehensive and reliable assessment of OOD methods without the deficiencies observed in existing evaluation approaches.","cats":{"data-quality":0}}
{"text":"This analysis helps us find a, to the best of our knowledge, novel failure model on the CIFAR100 dataset, that of duplicated images with different labels","cats":{"data-quality":1}}
{"text":"Neural networks are overparametrized and easily overfit the datasets they train on.","cats":{"data-quality":0}}
{"text":"In the extreme case, it is shown that they can memorize a training set with fully randomized labels.","cats":{"data-quality":0}}
{"text":"We propose using the curvature of loss function around the training sample as a measure of its memorization, averaged over all training epochs.","cats":{"data-quality":0}}
{"text":"We use this to study the generalization versus memorization properties of different samples in popular image datasets.","cats":{"data-quality":0}}
{"text":"We visualize samples with the highest curvature of loss around them, and show that these visually correspond to long-tailed, mislabeled or conflicting samples. .","cats":{"data-quality":0}}
{"text":"We also synthetically mislabel a proportion of the dataset by randomly corrupting the labels of a few samples, and show that sorting by curvature yields","cats":{"data-quality":0}}
{"text":"Medical image classification is a challenging task due to the scarcity of labeled samples and class imbalance caused by the high variance in disease prevalence.","cats":{"data-quality":0}}
{"text":"Semi-supervised learning (SSL) methods can mitigate these challenges by leveraging both labeled and unlabeled data.","cats":{"data-quality":0}}
{"text":"However, SSL methods for medical image classification need to address two key challenges: (1) estimating reliable pseudo-labels for the images in the unlabeled dataset and (2) reducing biases caused by class imbalance.","cats":{"data-quality":0}}
{"text":"In this paper, we propose a novel SSL approach, SPLAL, that effectively addresses these challenges.","cats":{"data-quality":0}}
{"text":"SPLAL leverages class prototypes and a weighted combination of classifiers to predict reliable pseudo-labels over a subset of unlabeled images.","cats":{"data-quality":0}}
{"text":"Additionally, we introduce alignment loss to mitigate model biases toward majority classes.","cats":{"data-quality":0}}
{"text":"To evaluate the performance of our proposed approach, we conduct experiments on two publicly available medical image classification benchmark datasets: the skin lesion classification (ISIC 2018) and the blood cell classification dataset (BCCD).","cats":{"data-quality":0}}
{"text":"The experimental results empirically demonstrate that our approach outperforms several state-of-the-art SSL methods over various evaluation metrics.","cats":{"data-quality":0}}
{"text":"Specifically, our proposed approach achieves a significant improvement over the state-of-the-art approach on the ISIC 2018 dataset in both Accuracy and F1 score, with relative margins of 2.24\\% and 11.40\\%, respectively.","cats":{"data-quality":0}}
{"text":"Finally, we conduct extensive ablation experiments to examine the contribution of different components of our approach, validating its effectiveness.","cats":{"data-quality":0}}
{"text":"Textual noise, such as typos or abbreviations, is a well-known issue that penalizes vanilla Transformers for most downstream tasks","cats":{"data-quality":1}}
{"text":"Previous works addressing the noise issue mainly rely on data augmentation strategies, showing improved robustness when dealing with corrupted samples that are similar to the ones used for training.","cats":{"data-quality":1}}
{"text":"However, all these methods still suffer from the token distribution shift induced by typos","cats":{"data-quality":1}}
{"text":"We show that this is also the case for sentence similarity, a fundamental task in multiple domains, e.g. matching, retrieval or paraphrasing.","cats":{"data-quality":0}}
{"text":"Sentence similarity can be approached using cross-encoders, where the two sentences are concatenated in the input allowing the model to exploit the inter-relations between them.","cats":{"data-quality":0}}
{"text":"Previous works addressing the noise issue mainly rely on data augmentation strategies, showing improved robustness when dealing wixtual noise by equipping cross-encoders with a novel LExical-aware Attention module (LEA) that incorporates lexical similarities between words in both sentences.","cats":{"data-quality":0}}
{"text":"By using raw text similarities, our ae that the attention bias introduced by LEA helps cross-encoders to tackle complex scenarios with textual noise, specially in domains with short-text descriptions and limited context.","cats":{"data-quality":0}}
{"text":"Experiments using three popular Transformer encoders in five e-commerce datasets for product matching show that LEA consistently boosts performance under the presence of noise, while remaining competitive on the original (clean) splits.","cats":{"data-quality":0}}
{"text":"We also evaluate our approach in two datasets for textual entailment and paraphrasing showing that LEA is robust to typos in domains with longer sentences and more natural context.","cats":{"data-quality":0}}
{"text":"Additionally, we thoroughly analyze several design choices in our approach, providing insights about the impact of the decisions made and fostering future research in cross-encoders dealing with typos.","cats":{"data-quality":0}}
{"text":"For safety, AI systems in health undergo thorough evaluations before deployment, validating their predictions against a ground truth that is assumed certain.","cats":{"data-quality":0}}
{"text":"However, this is actually not the case and the ground truth may be uncertain.","cats":{"data-quality":0}}
{"text":"Unfortunately, this is largely ignored in standard evaluation of AI models but can have severe consequences such as overestimating the future performance.","cats":{"data-quality":0}}
{"text":"To avoid this, we measure the effects of ground truth uncertainty, which we assume decomposes into two main components: annotation uncertainty which stems from the lack of reliable annotations, and inherent uncertainty due to limited observational information.","cats":{"data-quality":0}}
{"text":"This ground truth uncertainty is ignored when estimating the ground truth by deterministically aggregating annotations, e.g., by majority voting or averaging.","cats":{"data-quality":0}}
{"text":"In contrast, we propose a framework where aggregation is done using a statistical model.  ","cats":{"data-quality":0}}
{"text":"We present a case study applying our framework to skin condition classification fromtion (IRN) from previous work ignores ground truth uncertainty in evaluation.","cats":{"data-quality":0}}
{"text":"Instead, we present two alternative statistical models: a probabilistic version of IRN and a Plackett-Luce-based model.","cats":{"data-quality":0}}
{"text":"We find that a large portion of the dataset exhibits significant ground truth uncertainty and standard IRN-based evaluation severely over-estimates performance without providing uncertainty estimates.","cats":{"data-quality":0}}
{"text":"To systematically combat confirmation bias for pseudo-labeling-based entity alignment, we propose a Unified Pseudo-Labeling framework for Entity Alignment (UPL-EA) that explicitly eliminates pseudo-labeling errors to boost the accuracy of entity alignment","cats":{"data-quality":1}}
{"text":"The two components are respectively designed to eliminate Type I and Type II pseudo-labeling errors identified through our analyse.","cats":{"data-quality":0}}
{"text":"The effectiveness of UPL-EA in eliminating pseudo-labeling errors is both theoretically supported and experimentally validated.","cats":{"data-quality":1}}
{"text":"Entity alignment (EA) aims at identifying equivalent entity pairs across different knowledge graphs (KGs) that refer to the same real-world identity. .","cats":{"data-quality":0}}
{"text":"UPL-EA consists of two complementary components: (1) The Optimal Transport (OT)-based pseudo-labeling uses discrete OT modeling as an effective means to enable more accurate determination of entity correspondences across two KGs and to mitigate the adverse impact of erroneous matches.","cats":{"data-quality":0}}
{"text":"A simple but highly effective criterion is further devised to derive pseudo-labeled entity pairs that satisfy one-to-one correspondences at each iteration.","cats":{"data-quality":0}}
{"text":"(2) The cross-iteration pseudo-label calibration operates across multiple consecutive iterations to further improve the pseudo-labeling precision rate by reducing the local pseudo-label selection variability with a theoretical guarantee.","cats":{"data-quality":0}}
{"text":"The calibrated pseudo-labels are thereafter used to augment prior alignment seeds to reinforce subsequent model training fomentally validated.","cats":{"data-quality":0}}
{"text":"The experimental results show that our approach achieves competitive performance with limited prior alignment seeds.","cats":{"data-quality":0}}
{"text":"A novel annotation method was used to collect three separate annotations for each region of interest, and these annotations were performed in a fully transparent setting using a web-based annotation tool.","cats":{"data-quality":1}}
{"text":"This paper presents the challenge report for the 2021 Kidney and Kidney Tumor Segmentation Challenge (KiTS21) held in conjunction with the 2021 international conference on Medical Image Computing and Computer Assisted Interventions (MICCAI).","cats":{"data-quality":0}}
{"text":"KiTS21 is a sequel to its first edition in 2019, and it features a variety of innovations in how the challenge was designed, in addition to a larger dataset.  ","cats":{"data-quality":0}}
{"text":"Further, the KiTS21 test set was collected from an outside institution, challenging participants to develop methods that generalize well to new populations.","cats":{"data-quality":0}}
{"text":"Nonetheless, the top-performing teams achieved a significant improvement over the state of the art set in 2019, and this performance is shown to inch ever closer to human-level performance.","cats":{"data-quality":0}}
{"text":"An in-depth meta-analysis is presented describing which methods were used and how they faired on the leaderboard, as well as the characteristics of which cases generally saw good performance, and which did not.","cats":{"data-quality":0}}
{"text":"Overall KiTS21 facilitated a significant advancement in the state of the art in kidney tumor segmentation, and provides useful insights that are applicable to the field of semantic segmentation as a whole.","cats":{"data-quality":0}}
{"text":"Additionally, label noise is inevitable in large-scale annotations and hinders the applications of learning-based models.","cats":{"data-quality":1}}
{"text":"To tackle such a critical yet thorny problem, this paper focuses on reducing noise based on some inherent properties of multi-label classification and long-tailed learning under noisy cases","cats":{"data-quality":1}}
{"text":"In detail, we propose a Stitch-Up augmentation to synthesize a cleaner sample, which directly reduces multi-label noise by stitching up multiple noisy training samples","cats":{"data-quality":1}}
{"text":"In real-world scenarios, collected and annotated data often exhibit the characteristics of multiple classes and long-tailed distribution.  ","cats":{"data-quality":0}}
{"text":"Although many deep learning based methods have been proposed for handling long-tailed multi-label recognition or label noise respectively, learning with noisy labels in long-tailed multi-label visual data has not been well-studied because of the complexity of long-tailed distribution entangled with multi-label correlation.","cats":{"data-quality":0}}
{"text":"To tackle such a critical yet thorny problem, this paper focuses on reducing noise based on some inherent properties of m by stitching up multiple noisy training samples.","cats":{"data-quality":0}}
{"text":"Equipped with Stitch-Up, a Heterogeneous Co-Learning framework is further designed to leverage the inconsistency between long-tailed and balamarks, named VOC-MLT-Noise and COCO-MLT-Noise, respectively.","cats":{"data-quality":0}}
{"text":"Extensive experiments are conducted to demonstrate the effectiveness of our proposed method.","cats":{"data-quality":0}}
{"text":"Compared to a variety of baselines, our method achieves superior results.","cats":{"data-quality":0}}
{"text":"Most of the existing methods adopt a coarse-grained fixed label assignment strategy and suffer from the inconsistency between the classification score and localization accuracy.","cats":{"data-quality":1}}
{"text":"Second, to further address the inconsistency between classification and localization, we propose a critical feature sampling (CFS) module, which performs localization refinement on the sampling location for classification task to extract critical features accurately","cats":{"data-quality":1}}
{"text":"Arbitrary-oriented object detection is a relatively emerging but challenging task.","cats":{"data-quality":0}}
{"text":"Although remarkable progress has been made, there still remain many unsolved issues due to the large diversity of patterns in orientation, scale, aspect ratio, and visual appearance of objects in aerial images.  ","cats":{"data-quality":0}}
{"text":"First, to align the metric inconsistency between sample selection and regression loss calculation caused by fixed IoU strategy, we introduce affine transformation to evaluate the quality of samples and propose a distance-based label assignment strategy.","cats":{"data-quality":0}}
{"text":"The proposed metric-aligned selection (MAS) strategy can dynamically select samples according to the shape and rotation characteristic of objects.","cats":{"data-quality":0}}
{"text":"Second, to further address the inconsistency between classification and localization, we propose a critical feature sampling (CFS) module, which performs localization refinementtics of proposals during training.","cats":{"data-quality":0}}
{"text":"Extensive experiments are conducted on four challenging rotated object detection datasets DOTA, FAIR1M-1.0, HRSC2016, and UCAS-AOD.","cats":{"data-quality":0}}
{"text":"The results show the state-of-the-art accuracy of the proposed detector.","cats":{"data-quality":0}}
{"text":"However, results from even highly accurate methods require manual verification and correction","cats":{"data-quality":1}}
{"text":"The reviewers corrected 62.8% of the labels and agreed with the model label in 31.9% of cases.","cats":{"data-quality":1}}
{"text":"We learned that our automatic transcription is biased towards the most frequent codes, with a higher degree of misclassification for the lowest frequency codes","cats":{"data-quality":1}}
{"text":"Machine learning methods have proven useful in transcribing historical data. .","cats":{"data-quality":0}}
{"text":"Such manual review can be time-consuming and expensive, therefore the objective of this paper was to make it more efficient.","cats":{"data-quality":0}}
{"text":"Previously, we used machine learning to transcribe 2.3 million handwritten occupation codes from the Norwegian 1950 census with high accuracy (97%).","cats":{"data-quality":0}}
{"text":"We manually reviewed the 90,000 (3%) codes with the lowest model confidence.","cats":{"data-quality":0}}
{"text":"We allocated those 90,000 codes to human reviewers, who used our annotation tool to review the codes.","cats":{"data-quality":0}}
{"text":"To assess reviewer agreement, some codes were assigned to multiple reviewers.","cats":{"data-quality":0}}
{"text":"We then analyzed the review results to understand the relationship between accuracy improvements and effort.","cats":{"data-quality":0}}
{"text":"Additionally, we interviewed the reviewers to improve the workflow.","cats":{"data-quality":0}}
{"text":"The reviewers corrected 62.8% of the labels and agreed with the model label in 31.9% of casescertain, or they assigned an invalid label.","cats":{"data-quality":0}}
{"text":"9,000 images were independently reviewed by multiplds the most frequent codes, with a higher degree of misclassification for the lowest frequency codes.","cats":{"data-quality":0}}
{"text":"Our interview findings show that the reviewers did internal quality control and found our custom tool well-suited.","cats":{"data-quality":0}}
{"text":"So, only one reviewer is needed, but they shou","cats":{"data-quality":0}}
{"text":" We advocate for the use of IAA in predicting the labeling quality of individual annotators, leading to cost and time efficiency in data production.","cats":{"data-quality":0}}
{"text":"Additionally, our work highlights the  IAA's broader application potential in data-driven research optimization and holds significant implications for large-scale data projects prioritizing efficiency, cost reduction, and high-quality data.","cats":{"data-quality":0}}
{"text":"We present DiffInfinite, a hierarchical diffusion model that generates arbitrarily large histological images while preserving long-range correlation structural information.","cats":{"data-quality":0}}
{"text":"Our approach first generates synthetic segmentation masks, subsequently used as conditions for the high-fidelity generative diffusion process.","cats":{"data-quality":0}}
{"text":"The proposed sampling method can be scaled up to any desired image size while only requiring small patches for fast training.","cats":{"data-quality":0}}
{"text":"Moreover, it can be parallelized more efficiently than previous large-content generation methods while avoiding tiling artefacts.","cats":{"data-quality":0}}
{"text":"The training leverages classifier-free guidance to augment a small, sparsely annotated dataset with unlabelled data.","cats":{"data-quality":0}}
{"text":"Our method alleviates unique challenges in histopathological imaging practice: large-scale information, costly manual annotation, and protective data handling.","cats":{"data-quality":0}}
{"text":"The biological plausibility of DiffInfinite data is validated in a survey by ten experienced pathologists as well as a downstream segmentation task.","cats":{"data-quality":0}}
{"text":"Furthermore, the model scores strongly on anti-copying metrics which is beneficial for the protection of patient data.","cats":{"data-quality":0}}
{"text":"Understanding this, we, in this paper, first analyze this lack of granular annotations from available pre-annotated datasets to understand the practical inconsistencies and also perform a detailed survey to look into the human perception surrounding annotations.","cats":{"data-quality":1}}
{"text":"Efficient human activity recognition (HAR) using sensor data needs a significant volume of annotated data.","cats":{"data-quality":0}}
{"text":"The growing volume of unlabelled sensor data has challenged conventional practices for gathering HAR annotations with human-in-the-loop approaches, often leading to the collection of shallower annotations.","cats":{"data-quality":0}}
{"text":"These shallower annotations ignore the fine-grained micro-activities that constitute any complex activities of daily living (ADL).  ","cats":{"data-quality":0}}
{"text":"Drawing motivations from these, we next develop the framework AmicroN that can automatically generate micro-activity annotations using locomotive signatures and the available coarse-grain macro-activity labels.","cats":{"data-quality":0}}
{"text":"In the backend, AmicroN applies change-point detection followed by zero-shot learning with activity embeddings to identify the unseen micro-activities in an unsupervised manner.","cats":{"data-quality":0}}
{"text":"Rigorous evaluation on publicly available datasets shows that AmicroN can accurately generate micro-activity annotations with a median F1-score of >0.75.","cats":{"data-quality":0}}
{"text":"Additionally, we also show that AmicroN can be used in a plug-and-play manner with Large Language Models (LLMs) to obtain the micro-activity labels, thus making it more practical for realistic applications.","cats":{"data-quality":0}}
{"text":"This paper presents a large publicly available multi-center lumbar spine magnetic resonance imaging (MRI) dataset with reference segmentations of vertebrae, intervertebral discs (IVDs), and spinal canal.","cats":{"data-quality":0}}
{"text":"The dataset includes 447 sagittal T1 and T2 MRI series from 218 patients with a history of low back pain.","cats":{"data-quality":0}}
{"text":"It was collected from four different hospitals and was divided into a training (179 patients) and validation (39 patients) set.","cats":{"data-quality":0}}
{"text":"An iterative data annotation approach was used by training a segmentation algorithm on a small part of the dataset, enabling semi-automatic segmentation of the remaining images.","cats":{"data-quality":0}}
{"text":"The algorithm provided an initial segmentation, which was subsequently reviewed, manually corrected, and added to the training data.","cats":{"data-quality":0}}
{"text":"We provide reference performance values for this baseline algorithm and nnU-Net, which performed comparably.","cats":{"data-quality":0}}
{"text":"We set up a continuous segmentation challenge to allow for a fair comparison of different segmentation algorithms.","cats":{"data-quality":0}}
{"text":"This study may encourage wider collaboration in the field of spine segmentation, and improve the diagnostic value of lumbar spine MRI.","cats":{"data-quality":0}}
{"text":"But meanwhile, the distributed and isolated nature of data isolation may be complicated by data quality, making it more vulnerable to noisy labels","cats":{"data-quality":1}}
{"text":"Many efforts exist to defend against the negative impacts of noisy labels in centralized or federated settings","cats":{"data-quality":1}}
{"text":"Also, we conduct comprehensive experiments to explore the characteristics of these data settings and unravel challenging scenarios on the federated noisy label learning, which may guide method development in the future.","cats":{"data-quality":0}}
{"text":"We highlight the 20 basic settings for more than 5 datasets proposed in our benchmark and standardized simulation pipeline for federated noisy label learning.","cats":{"data-quality":1}}
{"text":"Federated learning has gained popularity for distributed learning without aggregating sensitive data from clients. .","cats":{"data-quality":0}}
{"text":"Many efforts exist to defend against the negative impacts of noisy labels in centralized or federated settings.","cats":{"data-quality":0}}
{"text":"However, there is a lack of a benchis work, we serve the first standardized benchmark that can help researchers fully explore potential federated noisy settings.","cats":{"data-quality":0}}
{"text":"We highlight the 20 basic settings f \\texttt{FedNoisy} is available at \\codeword{https://github.com/SMILELab-FL/FedNoisy}.","cats":{"data-quality":0}}
{"text":"In this paper, we explore different ways of training a model for handwritten text recognition when multiple imperfect or noisy transcriptions are available","cats":{"data-quality":1}}
{"text":"We consider various training configurations, such as selecting a single transcription, retaining all transcriptions, or computing an aggregated transcription from all available annotations.","cats":{"data-quality":0}}
{"text":"In addition, we evaluate the impact of quality-based data selection, where samples with low agreement are removed from the training set.","cats":{"data-quality":0}}
{"text":"Our experiments are carried out on municipal registers of the city of Belfort (France) written between 1790 and 1946.","cats":{"data-quality":0}}
{"text":"% results The results show that computing a consensus transcription or training on multiple transcriptions are good alternatives.","cats":{"data-quality":0}}
{"text":"However, selecting training samples based on the degree of agreement between annotators introduces a bias in the training data and does not improve the res","cats":{"data-quality":0}}
{"text":"The aim of the experiment is to judge the final annotation quality when pre-annotation is used.","cats":{"data-quality":1}}
{"text":"In addition, it evaluates the effect of automatic linguistically-based (rule-formulated) checks and another annotation on the same data available to the annotators, and their influence on annotation quality and efficiency.","cats":{"data-quality":1}}
{"text":"This paper presents an analysis of annotation using an automatic pre-annotation for a mid-level annotation complexity task -- dependency syntax annotation.","cats":{"data-quality":0}}
{"text":"It compares the annotation efforts made by annotators using a pre-annotated version (with a high-accuracy parser) and those made by fully manual annotation.  ","cats":{"data-quality":0}}
{"text":"In addition, it evaluates the effect of automatic linguistically-based (rule-formulated) checkstic annotation which increases the consistency of the resulting annotation without reducing its quality.","cats":{"data-quality":0}}
{"text":"SLPerf can facilitate SL algorithm development and fair performance comparisons.","cats":{"dev-research":0}}
{"text":"Our evaluation shows that RAPGen can generate performance improvement suggestions equivalent or better than a developer in ~60% of the cases, getting ~39% of them verbatim, in an expert-verified dataset of past performance changes made by C# developers.","cats":{"dev-research":1}}
{"text":"In addition, we develop a feature-strengthened modularized unit to further boost the reconstruction performance.","cats":{"dev-research":0}}
{"text":"So far, several studies have been performed to develop robust hate speech detection systems.","cats":{"dev-research":0}}
{"text":"The key challenges in developing GDBs are achieving high performance, scalability, programmability, and portability.","cats":{"dev-research":0}}
{"text":"Extensive simulation studies are conducted to assess the finite sample performance of our developed methods.","cats":{"dev-research":0}}
{"text":"Motivated by the performance of each RNNs, a meta-model is developed to improve the overall recognition performance by combining the predictions of the individual RNNs.","cats":{"dev-research":0,"ml-security":0}}
{"text":"However, so far, the focus of developing drift detectors is on detection quality, e.g.~accuracy, but not on computational performance, such as running time.","cats":{"dev-research":0}}
{"text":"We developed a deep learning pipeline to segment the cortical mantle by benchmarking the performance of nine deep neural architectures.","cats":{"dev-research":0}}
{"text":"Therefore, improving the development process indirectly improves the software product, too.","cats":{"dev-research":1}}
{"text":"Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.","cats":{"dev-research":1}}
{"text":"By aligning the reasoning of automated debugging more closely with that of human developers, we aim to produce intelligible explanations of how a specific patch has been generated, with the hope that the explanation will lead to more efficient and accurate developer decisions.","cats":{"dev-research":1}}
{"text":"This often makes it difficult to achieve good results in practice.","cats":{"dev-research":0}}
{"text":"We start with the intuition that developers tend to consciously and unconsciously have a collection of semantics facts in mind when working on coding tasks.","cats":{"dev-research":1}}
{"text":"Thus, developers need to debug their systems to ensure that the expected behavior is delivered.","cats":{"dev-research":1}}
{"text":"Developers often face challenges in code understanding, which is crucial for building and maintaining high-quality software systems.","cats":{"dev-research":1}}
{"text":"This paper adopts a cognitive psychology perspective to investigate the recurring mistakes in code resulting from the mental set (Einstellung) effect.","cats":{"dev-research":1}}
{"text":"During the experiment, participants were given two sets of four programming tasks.","cats":{"dev-research":0}}
{"text":"The study contributes to the existing literature by providing insights into creativity support during problem-solving in software development and offering a framework for experimental research in this field.","cats":{"dev-research":0}}
{"text":" The Einstellung effect is the tendency to approach problem-solving with a preconceived mindset, often overlooking better solutions that may be available.","cats":{"dev-research":0}}
{"text":"This effect can significantly impact creative thinking, as the development of patterns of thought can hinder the emergence of novel and creative ideas.","cats":{"dev-research":0}}
{"text":"Our study aims to test the Einstellung effect and the two mechanisms of its overcoming in the field of programming.","cats":{"dev-research":0}}
{"text":"The first intervention was the change of the color scheme of the code editor to the less habitual one.","cats":{"dev-research":0}}
{"text":"The second intervention was a combination of instruction to \"forget the previous solutions and tasks\" and the change in the color scheme.","cats":{"dev-research":0}}
{"text":"Each task had two possible solutions: one using suboptimal code dicd recommended methodology.","cats":{"dev-research":0}}
{"text":"Between the sets, participants either received no treatment or one of two interventions aimed at helping them overcome the mental set.","cats":{"dev-research":0}}
{"text":"The results of our experiment suggest that the tested techniques were insufficient to support overcoming the mental set, which we attribute to the specificity of the programming domain.","cats":{"dev-research":0}}
{"text":"To this end, this paper performs the first extensive study on applying LLMs for logging statement generation.","cats":{"dev-research":0}}
{"text":" Current retrieval-based and learning-based logging methods fail to provide accurate logging statements in complex software.","cats":{"dev-research":0}}
{"text":"We build LogBench, the first logging ight state-of-the-art LLMs, which include general-purpose and code-specific models ranging from 60M to 175B in size.","cats":{"dev-research":0}}
{"text":"Performance bugs are non-functional bugs that can even manifest in well-tested commercial products.","cats":{"dev-research":0}}
{"text":"Fixing these performance bugs is an important yet challenging problem.","cats":{"dev-research":0}}
{"text":"In this work, we address this challenge and present a new approach called Retrieval-Augmented Prompt Generation (RAPGen).","cats":{"dev-research":0}}
{"text":"Given a code snippet with a performance issue, RAPGen first retrieves a prompt instruction from a pre-constructed knowledge-base of previous performance bug fixes and then generates a prompt using the retrieved instruction.","cats":{"dev-research":0}}
{"text":"It then uses this prompt on a Large Language Model (such as Codex) in zero-shot to generate a fix.","cats":{"dev-research":0}}
{"text":"We compare our approach with the various prompt variations and state of the art methods in the task of performance bug fixing.","cats":{"dev-research":0}}
{"text":"Our experimental results show that CodeGen and Codex are sensitive to the superficial modifications of problem descriptions and significantly impact code generation performance.","cats":{"dev-research":1}}
{"text":"Using large language models (LLMs) for source code has recently gained attention.","cats":{"dev-research":0}}
{"text":"LLMs, such as Transformer-based models like Codex and ChatGPT, have been shown to be highly capable of solving a wide range of programming problems.","cats":{"dev-research":0}}
{"text":"However, the extent to which LLMs understand problem descriptions and generate programs accordingly or just retrieve source code from the most relevant problem in training data based on superficial cues has not been discovered yet.","cats":{"dev-research":0}}
{"text":"To explore this research question, we conduct experiments to understand the robustness of several popular LLMs, CodeGen and GPT-3.5 series models, capable of tackling code generation tasks in introductory programming problems.  ","cats":{"dev-research":0}}
{"text":"Furthermore, we observe that Codex relies on variable names, as randomized variables decrease the solved rate significantly.","cats":{"dev-research":0}}
{"text":"However, the state-of-the-art (SOTA) models, such as InstructGPT and ChatGPT, show higher robustness to superficial modifications and have an outstanding capability for solving programming problems.","cats":{"dev-research":0}}
{"text":"This highlights the fact that slight modifications to the prompts given to the LLMs can greatly affect code generation performance, and careful formatting of prompts is essential for high-quality code generation, while the SOTA models are becoming more robust to perturbations.","cats":{"dev-research":0}}
{"text":"However, it is hard and expensive to debug DNNs","cats":{"dev-research":1}}
{"text":"To address the challenges of debugging DNN models, we propose a novel data-driven approach that leverages model features to learn problem patterns","cats":{"dev-research":1}}
{"text":"Also, our methodology automatically links bug symptoms to their root causes, without the need for manually crafted mappings, so that developers can take the necessary steps to fix faults","cats":{"dev-research":1}}
{"text":"Deep Learning (DL) applications are being used to solve problems in critical domains (e.g., autonomous driving or medical diagnosis systems).  ","cats":{"dev-research":0}}
{"text":"However, it is hard and expensive to debug DNNs.","cats":{"dev-research":0}}
{"text":"When the failure symptoms or unsatisfied accurtraceability as to which part of the DNN program is responsible for the failure.","cats":{"dev-research":0}}
{"text":"Even worse, sometimes, a deep learning program has different types of bugs.","cats":{"dev-research":0}}
{"text":"To address the challenges of debugging DNN models, we propose a novel data-driven approach that leverages model features to learn problem pattas a training dataset to learn and infer DNN fault patterns.","cats":{"dev-research":0}}
{"text":"Also, our methodology automatically links bug symptoms to their root causes, without the need for manually crafted mappings, so that developers can take the necessary steps to fix faults.","cats":{"dev-research":0}}
{"text":"We evaluate our approach using real-world and mutated models.","cats":{"dev-research":0}}
{"text":"Our results demonstrate that our technh achieved comparable results for real-world models in terms of accuracy and performance to the state-of-the-art.","cats":{"dev-research":0}}
{"text":"We conduct an exploratory user study with 32 participants to understand the usefulness and effectiveness, as well as individual preferences in the usage of, this LLM-powered information support tool","cats":{"dev-research":1}}
{"text":" Code comments and documentation can provide some context for the code, but are often scarce or missing.","cats":{"dev-research":0}}
{"text":"This challenge has become even more pressing with the rise of large language model (LLM) based code generation tools.","cats":{"dev-research":0}}
{"text":"To understand unfamiliar code, most software developers rely on general-purpose search engines to search through various programming information resources, which often requires multiple iterations of query rewriting and information foraging.","cats":{"dev-research":0}}
{"text":"More recently, developers have turned to online chatbots powered by LLMs, such as ChatGPT, which can provide more customized responses but also incur more overhead as developers need to communicate a significant amount of context to the LLM via a textual interface.","cats":{"dev-research":0}}
{"text":"In this study, we provide the investigation of an LLM-based conversational UI in the IDE.","cats":{"dev-research":0}}
{"text":"We aim to understand the promises and obstacles for tools powered by LLMs that are contextually aware, in that they automatically leverage the developer's programming context to answer queries.","cats":{"dev-research":0}}
{"text":"To this end, we develop an IDE Plugin that allows users to query back-ends such as OpenAI's GPT-3.5 and GPT-4 with high-level requests, like: explaining a highlighted section of code, explaining key domain-specific terms, or providing usage examples for an API.","cats":{"dev-research":0}}
{"text":"We conduct an exploratory user study with 32 participants to understand the usefulness and effectiveness, as well as individual prefiffered by participants' experience levels.","cats":{"dev-research":0}}
{"text":"Fourth, as programmable networks and machine learning (ML) techniques are increasingly becoming adopted by the community, their current applications in network security are discussed.","cats":{"ml-security":0}}
{"text":"Especially when both the ML model and the input data's confidentiality must be protected.","cats":{"ml-security":1}}
{"text":"We can expect such systems to be vulnerable to some adversarial-ML attacks.","cats":{"ml-security":1}}
{"text":"Traditional adversarial training is a popular methodology for robustifying ML models against attacks.","cats":{"ml-security":0}}
{"text":"The remarkable success of the use of machine learning-based solutions for network security problems has been impeded by the developed ML models' inability to maintain efficacy when used in different network environments exhibiting different network behaviors.","cats":{"ml-security":1}}
{"text":"Machine learning (ML) models can leak information about users, and differential privacy (DP) provides a rigorous way to bound that leakage under a given budget.","cats":{"ml-security":1}}
{"text":"However, compared to attacks on other ML-based systems, attackers face a level of indirection as they cannot interact directly with the learned model.","cats":{"ml-security":1}}
{"text":"However, due to increasing demand for users' privacy and security, we often need to remove users' data information from Machine Learning (ML) models to satisfy specific privacy and security requirements.","cats":{"ml-security":0}}
{"text":"We analyze the root causes of potentially-increased attack surface in learned systems and develop a framework for identifying vulnerabilities that stem from the use of ML.","cats":{"ml-security":1}}
{"text":"Since machine-learning is being deployed in safety-critical and security-sensitive domains, such attacks may have catastrophic security and safety consequences.","cats":{"ml-security":1}}
{"text":"Backdoor attacks have been demonstrated as a security threat for machine learning models.","cats":{"ml-security":1}}
{"text":"However, if the privacy of machine learning applications' customers cannot be guaranteed, it will cause security threats and losses to users' personal privacy information and service providers.","cats":{"ml-security":1}}
{"text":"In this paper, we introduce Semantic-SAM, a universal image segmentation model to enable segment and recognize anything at any desired granularity.","cats":{"ml-security":0}}
{"text":"Our model offers two key advantages: semantic-awareness and granularity-abundance.","cats":{"ml-security":0}}
{"text":"To achieve semantic-awareness, we consolidate multiple datasets across three granularities and introduce decoupled classification for objects and parts.","cats":{"ml-security":0}}
{"text":"This allows our model to capture rich semantic information.","cats":{"ml-security":0}}
{"text":"For the multi-granularity capability, we propose a multi-choice learning scheme during training, enabling each click to generate masks at multiple levels that correspond to multiple ground-truth masks.","cats":{"ml-security":0}}
{"text":"Notably, this work represents the first attempt to jointly train a model on SA-1B, generic, and part segmentation datasets.","cats":{"ml-security":0}}
{"text":"Experimental results and visualizations demonstrate that our model successfully achieves semantic-awareness and granularity-abundance.","cats":{"ml-security":0}}
{"text":"Furthermore, combining SA-1B training with other segmentation tasks, such as panoptic and part segmentation, leads to performance improvements.","cats":{"ml-security":0}}
{"text":"We will provide code and a demo for further exploration and evaluation.","cats":{"ml-security":0}}
{"text":"We propose a self-supervised method for learning representations based on spatial audio-visual correspondences in egocentric videos.","cats":{"ml-security":0}}
{"text":"In particular, our method leverages a masked auto-encoding framework to synthesize masked binaural audio through the synergy of audio and vision, thereby learning useful spatial relationships between the two modalities.","cats":{"ml-security":0}}
{"text":"We use our pretrained features to tackle two downstream video tasks requiring spatial understanding in social scenarios: active speaker detection and spatial audio denoising.","cats":{"ml-security":0}}
{"text":"We show through extensive experiments that our features are generic enough to improve over multiple state-of-the-art baselines on two public challenging egocentric video datasets, EgoCom and EasyCom.","cats":{"ml-security":0}}
{"text":"Project: http://vision.cs.utexas.edu/projects/ego_av_corr.","cats":{"ml-security":0}}
{"text":"One of the fundamental steps toward understanding a complex system is identifying variation at the scale of the system's components that is most relevant to behavior on a macroscopic scale.","cats":{"ml-security":0}}
{"text":"Mutual information is a natural means of linking variation across scales of a system due to its independence of the particular functional relationship between variables.","cats":{"ml-security":0}}
{"text":"However, estimating mutual information given high-dimensional, continuous-valued data is notoriously difficult, and the desideratum -- to reveal important variation in a comprehensible manner -- is only readily achieved through exhaustive search.","cats":{"ml-security":0}}
{"text":"Finally, alignment scores for different assertions are combined aposteriori to give the final text-to-image alignment score.","cats":{"ml-security":0}}
{"text":"Code and pre-trained weights will be publicly available at https://animatediff.github.io/ .","cats":{"ml-security":0}}
{"text":"While difficult to deploy today for real systems due to latency, context size limitations, and compute costs, the approach of using LLMs to drive low-level control may provide an exciting glimpse into how the patterns among words could be transferred to actions.","cats":{"ml-security":0}}
{"text":"In particular, we focus on the scalar curvature, which can be computed analytically for our manifold, and show connections to several settings that potentially imply generalization.","cats":{"ml-security":0}}
{"text":"To the best of our knowledge, such support does not exist.","cats":{"ml-security":0}}
{"text":"To serve the intricate and varied demands of image editing, precise and flexible manipulation of image content is indispensable.","cats":{"ml-security":0}}
{"text":"In this paper, we provide a novel framework for the analysis of generalization error of first-order optimization algorithms for statistical learning when the gradient can only be accessed through partial observations given by an oracle.","cats":{"ml-security":0}}
{"text":"Then, a specific trustworthiness model and its attributes, namely data robustness, parameter sensitivity, and security covering adversarial examples, are introduced.","cats":{"ml-security":1}}
{"text":"Additionally, motivated by the concepts of user-level and item-level fairness, we broaden the understanding of diversity to encompass not only the item level but also the user level.","cats":{"ml-security":0}}
{"text":"In our experiments, eight machine learning models are employed to provide predictions, and the results achieved by the best-performing model are further processed by the SHAP explainability process.","cats":{"ml-security":0}}
{"text":"This is computationally more efficient because the expense of the one-time graph inference and the $d$-separation queries is negligible compared to the expense of surplus contribution evaluations.","cats":{"ml-security":0}}
{"text":"We use Meta's Ad Library to collect 602,546 ads that have been issued by US Congress members since mid-2018.","cats":{"ml-security":0}}
{"text":"We release the BigTrans model and hope it can advance the research progress.","cats":{"ml-security":0}}
{"text":"When the measurement delay exceeds the permissible number, the packet dropout happens.","cats":{"ml-security":0}}
{"text":"Experiments suggest FogROS2-SGC is 19x faster than rosbridge (a ROS2 package with comparable features, but lacking security).","cats":{"ml-security":0}}
{"text":"The LaSSIM metric does not require clean reference images and has been shown to be superior to SSIM in capturing image structural changes under image degradations, such as strong blurring on different datasets.","cats":{"ml-security":0}}
{"text":"It keeps the long-tailed nature of the collaborative graph by adding power law prior to node embedding initialization; then, it aggregates neighbors directly in multiple hyperbolic spaces through the gyromidpoint method to obtain more accurate computation results; finally, the gate fusion with prior is used to fuse multiple embeddings of one node from different hyperbolic space automatically.","cats":{"ml-security":0}}
{"text":"Empirically we demonstrate that $d$-SAGE enables the efficient and accurate estimation of SAGE values.","cats":{"ml-security":0}}
{"text":"The proposed method inserts pilot sequences in the zero bins of the ZP-OTFS system, resulting in low overhead and PAPR.","cats":{"ml-security":0}}
{"text":"Our work is a step towards understanding how simple geometrically-local error-correction strategies can protect information encoded into complex noisy systems, such as topological quantum error-correcting codes.","cats":{"ml-security":0}}
{"text":"In the case of two multivariate normal classes with a common covariance matrix, they showed that the error rate of the estimated Bayes' rule formed by this SSL approach can actually have lower error rate than the one that could be formed from a completely classified sample.","cats":{"ml-security":0}}
{"text":"However, previous studies seldom take advantage of such brain anatomy prior.","cats":{"ml-security":0}}
{"text":"Moreover, they require hundreds of gigabytes of training data.","cats":{"ml-security":0}}
{"text":"Aside from providing a birds eye view of what exists our in depth analysis provides insights on what is lacking in the current discourse on NLP in particular and critical AI in general, proposes additions to the current framework of analysis, provides recommendations future research direction, and highlights the need to importance of exploring the social in this socio-technical system.","cats":{"ml-security":0}}
{"text":"Self-training is a simple yet effective method within semi-supervised learning.","cats":{"ml-security":0}}
{"text":"For the information leakage caused by the attack during the information transmission process, privacy-preservation is introduced for system states.","cats":{"ml-security":1}}
{"text":"Most existing systems that conceal leakage either (1) incur substantial overheads, (2) focus on specific subsets of leakage patterns, or (3) apply the same security notion across various workloads, thereby impeding the attainment of fine-tuned privacy-efficiency trade-offs.","cats":{"ml-security":1}}
{"text":"Numerous studies have underscored the significant privacy risks associated with various leakage patterns in encrypted data stores.","cats":{"ml-security":1}}
{"text":"In our daily life, mobile phone applications and identity documents that we use may bring the risk of privacy leakage, which had increasingly aroused public concern.","cats":{"ml-security":1}}
{"text":"Overall, our approach to privacy unifies, formalizes, and explains many existing ideas, e.g., why the informed adversary assumption may lead to underestimating the information leaking about each entry in the database.","cats":{"ml-security":0}}
{"text":"Our findings can provide valuable insights into the evolving field of non-standard and covert channels, and help spur new countermeasures against such privacy leakage and security issues.","cats":{"ml-security":0}}
{"text":"Classifiers based on deep neural networks have been recently challenged by Adversarial Attack, where the widely existing vulnerability has invoked the research in defending them from potential threats.","cats":{"ml-security":1}}
{"text":"Adversarial attacks are a serious threat to the reliable deployment of machine learning models in safety-critical applications.","cats":{"ml-security":1}}
{"text":"The vulnerability of deep neural network models to adversarial example attacks is a practical challenge in many artificial intelligence applications.","cats":{"ml-security":1}}
{"text":"Machine-learning architectures, such as Convolutional Neural Networks (CNNs) are vulnerable to adversarial attacks: inputs crafted carefully to force the system output to a wrong label.","cats":{"ml-security":1}}
{"text":"Many research works developed certain techniques to generate adversarial samples to help the machine learning models obtain the ability to recognize those perturbations.","cats":{"ml-security":1}}
{"text":"Deep neural networks are known to be vulnerable to adversarial examples crafted by adding human-imperceptible perturbations to the benign input.","cats":{"ml-security":1}}
{"text":"Given a vulnerable classifier, existing defense methods are mostly white-box and often require re-training the victim under modified loss functions/training regimes.","cats":{"ml-security":1}}
{"text":"Inspired by the observation that linear learners on some datasets are able to resist the best known attacks even without any defenses, we further investigate whether datasets can be inherently robust to indiscriminate poisoning attacks for linear learners.","cats":{"ml-security":1}}
{"text":"With the wide-spread application of machine learning models, it has become critical to study the potential data leakage of models trained on sensitive data.","cats":{"ml-security":1}}
{"text":"The results show that the centralized machine learning model shows more serious member information leakage in all aspects, and the accuracy of the attacker in the central parameter server is significantly higher than the local Inference attacks as participants.","cats":{"ml-security":1}}
{"text":"Therefore, in the current work, we analyze the suitability of these metrics to create Machine Learning based software vulnerability detectors for UMI applications.","cats":{"ml-security":1}}
{"text":"Recently, however, there has been a trend towards evaluating the robustness of these models against adversarial attacks.","cats":{"ml-security":1}}
{"text":"As in-the-wild data are increasingly involved in the training stage, machine learning applications become more susceptible to data poisoning attacks.","cats":{"ml-security":1}}
{"text":"In this paper, we investigate the third type of exploitation of data poisoning - increasing the risks of privacy leakage of benign training samples.","cats":{"ml-security":1}}
{"text":"To this end, we demonstrate a set of data poisoning attacks to amplify the membership exposure of the targeted class.","cats":{"ml-security":1}}
{"text":"Furthermore, adversaries launch poisoning attacks to falsify the health data, which leads to misdiagnosing or even physical damage.","cats":{"ml-security":1}}
{"text":"These findings largely explain the drastic variation in empirical attack performance of the state-of-the-art poisoning attacks on linear learners across benchmark datasets, making an important initial step towards understanding the underlying reasons some learning tasks are vulnerable to data poisoning attacks.","cats":{"ml-security":1}}
{"text":"We then propose an optimization-based clean-label attack in the transfer learning scenario, whereby the poisoning samples are correctly labeled and look \"natural\" to evade human moderation.","cats":{"ml-security":1}}
{"text":"To reveal the real vulnerability of FedRecs, in this paper, we present a new poisoning attack method to manipulate target items' ranks and exposure rates effectively in the top-$K$ recommendation without relying on any prior knowledge.","cats":{"ml-security":1}}
{"text":"Specifically, our attack manipulates target items' exposure rate by a group of synthetic malicious users who upload poisoned gradients considering target items' alternative products.","cats":{"ml-security":1}}
{"text":"We introduce ShortcutGen, a new data poisoning attack that generates sample-dependent, error-minimizing perturbations by learning a generator.","cats":{"ml-security":1}}
{"text":"Our results prove that linear learners can indeed be robust to indiscriminate poisoning if the class-wise data distributions are well-separated with low variance and the size of the constraint set containing all permissible poisoning points is also small.","cats":{"ml-security":1}}
{"text":"We thus formulate such a privacy defense as an adversarial learning problem, where RecUP-FL generates slight perturbations that can be added to the gradients before sharing to fool adversary models.","cats":{"ml-security":1}}
{"text":"We test the performance of the considered attack strategies on an experimental dataset.","cats":{"ml-security":1}}
{"text":"A recent line of work shows that the use of randomization in adversarial training is the key to find optimal strategies against adversarial example attacks.","cats":{"ml-security":1}}
{"text":"We then propose the first learning-based prompt stealing attack, PromptStealer, and demonstrate its superiority over two baseline methods quantitatively and qualitatively.","cats":{"ml-security":1}}
{"text":"Our attack framework is inspired by certified radius, which was originally used by defenders to defend against adversarial perturbations to classification models.","cats":{"ml-security":1}}
{"text":"After the evaluation, we found that transfer learning is a good technique that allows better performance when working with a small data set.","cats":{"ml-security":0}}
{"text":"Moreover, the fairest classifier was found to be accomplished using transfer learning, threshold change, re-weighting and image augmentation as bias mitigation methods.","cats":{"ml-security":0}}
{"text":"It does this by gradually improving image quality in small steps, similar to generative denoising diffusion models.   ","cats":{"ml-security":0}}
{"text":"Inversion by Direct Iteration (InDI) is a new formulation for supervised image restoration that avoids the so-called ``regression to the mean'' effect and produces more realistic and detailed images than existing regression-based methods.","cats":{"ml-security":0}}
{"text":"These results demonstrate that our trained model can successfully reproduce the classification labels derived from detailed SED analysis.","cats":{"ml-security":0}}
{"text":"In the era of AI transitioning from pure analysis to creation, it is worth noting that ChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks.","cats":{"ml-security":0}}
{"text":"Decoupling these two tasks enables training of the \"speaking\" module using abundant audio-only data, and unlocks the highly efficient combination of pretraining and backtranslation to reduce the need for parallel data when training the \"reading\" component.","cats":{"ml-security":0}}
{"text":"Interestingly, we observe that clinical text information annotated by radiologists provides us with discriminative knowledge to identify challenging samples.","cats":{"ml-security":0}}
{"text":"Finally, we include an \"adaptive\" component to the retrieval process, which iteratively refines the re-ranking pool during scoring using the expansion model, i.e. we \"re-rank - expand - repeat\".","cats":{"ml-security":0}}
{"text":"Our code is available at \\url{https://github.com/nkdinsdale/SFHarmony}.","cats":{"ml-security":0}}
{"text":"In online advertising systems, although there are millions to billions of ads, users tend to click only a small set of them and to convert on an even smaller set.","cats":{"ml-security":0}}
{"text":"Membership inference (MI) attacks threaten user privacy through determining if a given data example has been used to train a target model.","cats":{"ml-security":1}}
{"text":"In this paper, we seek to develop a comprehensive benchmark for comparing different MI attacks, called MIBench, which consists not only the evaluation metrics, but also the evaluation scenarios","cats":{"ml-security":1}}
{"text":" However, it has been increasingly recognized that the \"comparing different MI attacks\" methodology used in the existing works has serious limitations.","cats":{"ml-security":0}}
{"text":"Due to these limitations, we found (through the experiments in this work) that some comparison results reported in the literature are quite misleading.","cats":{"ml-security":0}}
{"text":"In this paper, we seek to develop a comprehensive benchmark for comparing different MI attacks, called MIBench, which consists not only thance between data samples of the target dataset, the differential distance between two datasets (i.e., the target dataset and a generated dataset with only nonmembers), and the ratio of the samples that are made no inferences by an MI attack.","cats":{"ml-security":0}}
{"text":"The evaluation metrics consist of ten typical evaluation metrics.","cats":{"ml-security":0}}
{"text":"We have identified three principles for the proposed \"comparing different MI attacks\" methodology, and we have designed and implemented the MIBench benchmark with 84 evaluation scenarios for each dataset.","cats":{"ml-security":0}}
{"text":"In total, we have used our benchmark to fairly and systematically compare 15 state-of-the-art MI attack algorithms across 588 evaluation scenarios, and these evaluation scenarios cover 7 widely used datasets and 7 representative types of models.","cats":{"ml-security":0}}
{"text":"All codes and evaluations of MIBench are publicly available at https://github.com/MIBench/MIBench.github.io/blob/main/README.md.","cats":{"ml-security":0}}
{"text":" The proposed approach is motivated by the intuition that features corresponding to triggers have a higher influence in determining ive metrics.","cats":{"ml-security":0}}
{"text":"Additionally, our detection method can be i","cats":{"ml-security":0}}
{"text":"We study how to mitigate the effects of energy attacks in the batteryless Internet of Things (IoT).","cats":{"ml-security":1}}
{"text":"We design, implement, and evaluate a mitigation system for energy attacks.","cats":{"ml-security":0}}
{"text":" Battery-less IoT devices live and die with ambient energy, as they use energy harvesting to power their operation.","cats":{"ml-security":0}}
{"text":"They are employed in a multitude of applications, including safety-critical ones such as biomedical implants.","cats":{"ml-security":0}}
{"text":"Due to scarce energy intakes and limited energy buffers, their executions become intermittent, alternating periods of active operation with periods of recharging their energy buffers.","cats":{"ml-security":0}}
{"text":"Experimental evidence exists that shows how controlling ambient energy allows an attacker to steer a device execution in unintended ways: energy provisioning effectively becomes an attack vector.","cats":{"ml-security":0}}
{"text":"By taking into account t module, we tune task execution rates and optimize energy management.","cats":{"ml-security":0}}
{"text":"This ensures continued application execution in the event of an energy attack.","cats":{"ml-security":0}}
{"text":"When a device is under attack, our solution ensures the execution of 23.3% additional application cycles compared to the baselines we consider and increases task schedulability by at least 21%, while enabling a 34% higher peripheral availability.","cats":{"ml-security":0}}
{"text":"The architecture can naturally be exploited in privacy-sensitive situations such as surveillance and health, where personally identifiable information cannot be released.","cats":{"ml-security":1}}
{"text":"Predicting where a person is looking is a complex task, requiring to understand not only the person's gaze and scene content, but also the 3D scene structure and the person's situation (are they manipulating?","cats":{"ml-security":0}}
{"text":"interacting or observing others?","cats":{"ml-security":0}}
{"text":"attentive?) to detect obstructions in the line of sight or apply attention priors that humans typically have when observing others.","cats":{"ml-security":0}}
{"text":"In this paper, we hypothesize that identifying and leveraging such priors can be better achieved through the exploitation of explicitly derived multimodal cues such as depth and pose.","cats":{"ml-security":0}}
{"text":"We thus propose a modular multimodal architecture allowing to combine these cues using an attention mechanism.  ","cats":{"ml-security":0}}
{"text":"We perform extensive experiments on the GazeFollow and VideoAttentionTarget public datasets, obtaining state-of-the-art performance and demonstrating very competitive results in the privacy setting case.","cats":{"ml-security":0}}
{"text":"This paper extends and advances our recently introduced two-factor Honeytoken authentication method by incorporating blockchain technology.","cats":{"ml-security":0}}
{"text":"This novel approach strengthens the authentication method to prevent many attacks including tampering attacks.","cats":{"ml-security":0}}
{"text":"Evaluation results show that integrating blockchain into the Honeytoken method could improve performance and operational efficiency.","cats":{"ml-security":0}}
{"text":"Moreover, the Butterfly Effect can amplify inherent biases within data or algorithms, exacerbate feedback loops, and create vulnerabilities for adversarial attacks.","cats":{"ml-security":1}}
{"text":"In this paper, we envision both algorithmic and empirical strategies to detect, quantify, and mitigate the Butterfly Effect in AI systems, emphasizing the importance of addressing these challenges to promote fairness and ensure responsible AI development","cats":{"ml-security":1}}
{"text":"The Butterfly Effect, a concept originating from chaos theory, underscores how small changes can have significant and unpredictable impacts on complex systems.","cats":{"ml-security":0}}
{"text":"In the context of AI fairness and bias, the Butterfly Effect can stem from a variety of sources, such as small biases or skewed data inputs during algorithm development, saddle points in training, or distribution shifts in data between training and testing phases.","cats":{"ml-security":0}}
{"text":"These seemingly minor alterations can lead to unexpected and substantial unfair outcomes, disproportionately affecting underrepresented individuals or groups and perpetuating pre-existing inequalities.  ","cats":{"ml-security":0}}
{"text":"Given the intricate nature of AI systems and their societal implications, it is crucial to thoroughly examine any changes to algorithms or input data for potential unintended consequences.","cats":{"ml-security":0}}
{"text":"In this paper, we envision both algorithmic and empirical strategies to detect, quantify, and mitigate the Butterfly Effect in AI systems, emphasizing the importanc","cats":{"ml-security":0}}
{"text":"Artificial intelligence (AI) is considered an efficient response to several challenges facing 6G technology.","cats":{"ml-security":0}}
{"text":"However, AI still suffers from a huge trust issue due to its ambiguous way of making predictions.","cats":{"ml-security":0}}
{"text":"Therefore, there is a need for a method to evaluate the AI's trustworthiness in practice for future 6G applications.","cats":{"ml-security":0}}
{"text":"This paper presents a practical model to analyze the trustworthiness of AI in a dedicated 6G application.","cats":{"ml-security":0}}
{"text":"In particular, we present two customized Deep Neural Networks (DNNs) to solve the Automatic Modulation Recognition (AMR) problem in Terahertz communications-based 6G technology.  ","cats":{"ml-security":0}}
{"text":"The evaluation results indicate that the proposed trustworthiness attributes are crucial to evaluate the trustworthiness of DNN for this 6G application.","cats":{"ml-security":0}}
{"text":"Automatic metrics play a crucial role in machine translation.","cats":{"ml-security":0}}
{"text":"Despite the widespread use of n-gram-based metrics, there has been a recent surge in the development of pre-trained model-based metrics that focus on measuring sentence semantics.","cats":{"ml-security":0}}
{"text":"However, these neural metrics, while achieving higher correlations with human evaluations, are often considered to be black boxes with potential biases that are difficult to detect.","cats":{"ml-security":0}}
{"text":"In this study, we systematically analyze and compare various mainstream and cutting-edge automatic metrics from the perspective of their guidance for training machine translation systems.","cats":{"ml-security":0}}
{"text":"Through Minimum Risk Training (MRT), we find that certain metrics exhibit robustness defects, such as the presence of universal adversarial translations in BLEURT and BARTScore.","cats":{"ml-security":0}}
{"text":"In-depth analysis suggests two main causes of these robustness deficits: distribution biases in the training datasets, and the tendency of the metric paradigm.","cats":{"ml-security":0}}
{"text":"By incorporating token-level constraints, we enhance the robustness of evaluation metrics, which in turn leads to an improvement in the performance of machine translation systems.","cats":{"ml-security":0}}
{"text":"Codes are available at \\url{https://github.com/powerpuffpomelo/fairseq_mrt}.","cats":{"ml-security":0}}
{"text":"However, concerns have arisen regarding the unauthorized usage of data during the training process.","cats":{"ml-security":1}}
{"text":"In this paper, we propose a method for detecting such unauthorized data usage by planting injected memorization into the text-to-image diffusion models trained on the protected dataset.","cats":{"ml-security":1}}
{"text":"By analyzing whether the model has memorization for the injected content (i.e., whether the generated images are processed by the chosen post-processing function), we can detect models that had illegally utilized the unauthorized data.","cats":{"ml-security":0}}
{"text":"Recent text-to-image diffusion models have shown surprising performance in generating high-quality images.  ","cats":{"ml-security":0}}
{"text":"One example is when a model trainer collects a set of images created by a particular artist and attempts to train a model capable of generating similar images without obtaining permission from the artist.","cats":{"ml-security":0}}
{"text":"To address this issue, it becomes crucial to detect unauthorized data usage.","cats":{"ml-security":0}}
{"text":"In this paper, we propose a method for detecting such unauthorized data usage by planting injected s stealthy image wrapping functions that are imperceptible to human vision but can be captured and memorized by diffusion models.","cats":{"ml-security":0}}
{"text":"Our experiments conducted on Stable Diffusion an","cats":{"ml-security":0}}
{"text":"We then show that such probabilistic descriptions can be used to construct defences against adversarial attacks.","cats":{"ml-security":1}}
{"text":"This paper begins with a description of methods for estimating probability density functions for images that reflects the observation that such data is usually constrained to lie in restricted regions of the high-dimensional image space - not every pattern of pixels is an image.","cats":{"ml-security":0}}
{"text":"It is common to say that images lie on a lower-dimensional manifold in the high-dimensional space.","cats":{"ml-security":0}}
{"text":"However, although images may lie on such lower-dimensional manifolds, it is not the case that all points on the manifold have an equal probability of being images.","cats":{"ml-security":0}}
{"text":"Images are unevenly distributed on the manifold, and our task is to devise ways to model this distribution as a probability distribution.","cats":{"ml-security":0}}
{"text":"In pursuing this goal, we consider generative models that are popular in AI and computer vision community.","cats":{"ml-security":0}}
{"text":"For our purposes, generative/probabilistic models should have the properties of 1) sample generation: it should be possible to sample from this distribution according to the modelled density function, and 2) probability computation: given a previously unseen sample from the dataset of interest, one should be able to compute the probability of the sample, at least up to a normalising constant.","cats":{"ml-security":0}}
{"text":"To this end, we investigate the use of methods such as normalising flow and diffusion models.  ","cats":{"ml-security":0}}
{"text":"In addition to describing the manifold in terms of density, we also consider how semantic interpretations can be used to describe points on the manifold.","cats":{"ml-security":0}}
{"text":"To this end, we consider an emergent language framework which makes use of variational encoders to produce a disentangled representation of points that reside on a given manifold.","cats":{"ml-security":0}}
{"text":"Trajectories between points on a manifold can then be described in terms of evolving semantic descriptions.","cats":{"ml-security":0}}
{"text":"Face presentation attacks, also known as spoofing attacks, pose a significant threat to biometric systems that rely on facial recognition systems, such as access control systems, mobile payments, and identity verification systems.","cats":{"ml-security":1}}
{"text":"In this paper, we reformulate the face anti-spoofing task as a motion prediction problem and introduce a deep ensemble learning model with a frame skipping mechanism","cats":{"ml-security":1}}
{"text":" To prevent spoofing, several video-based methods have been presented in the literature that analyze facial motion in successive video frames.","cats":{"ml-security":0}}
{"text":"However, estimating the motion between adjacent frames is a challenging task and requires high computational cost.","cats":{"ml-security":0}}
{"text":"In this paper, we reformulate the face anti-spoofing task as a motion prediction problem and introduce a deep ensemble learning model with a frame skipping mechanism.","cats":{"ml-security":0}}
{"text":"The proposed frame skipping is based on a uniform sampling apprasily be perceived during the training of three different recurrent neural networks (RNNs).","cats":{"ml-security":0}}
{"text":"Extensive experiments were conducted on four datasets, and state-of-the-art performance is reported for MSU-MFSD (3.12\\%), Replay-Attack (11.19\\%), and OULU-NPU (12.23\\%) using half total error rate (HTER) in the most challenging cross-dataset test scenario.","cats":{"ml-security":0}}
{"text":"Generative AI has made significant strides, yet concerns about the accuracy and reliability of its outputs continue to grow.","cats":{"ml-security":0}}
{"text":"Such inaccuracies can have serious consequences such as inaccurate decision-making, the spread of false information, privacy violations, legal liabilities, and more.","cats":{"ml-security":0}}
{"text":"Although efforts to address these risks are underway, including explainable AI and responsible AI practices such as transparency, privacy protection, bias mitigation, and social and environmental responsibility, misinformation caused by generative AI will remain a significant challenge.","cats":{"ml-security":0}}
{"text":"We propose that verifying the outputs of generative AI from a data management perspective is an emerging issue for generative AI.","cats":{"ml-security":0}}
{"text":"This involves analyzing the underlying data from multi-modal data lakes, including text files, tables, and knowledge graphs, and assessing its quality and consistency.","cats":{"ml-security":0}}
{"text":"By doing so, we can establish a stronger foundation for evaluating the outputs of generative AI models.","cats":{"ml-security":0}}
{"text":"Such an approach can ensure the correctness of generative AI, promote transparency, and enable decision-making with greater confidence.","cats":{"ml-security":0}}
{"text":"Our vision is to promote the development of verifiable generative AI and contribute to a more trustworthy and responsible use of AI.","cats":{"ml-security":0}}
{"text":"The introduction of vulnerability detection enables reducing the number of false alerts to focus the limited testing efforts on potentially vulnerable files.","cats":{"ml-security":1}}
{"text":"In Software Development Life Cycle (SDLC), security vulnerabilities are one of the points introduced during the construction stage.","cats":{"ml-security":0}}
{"text":"Failure to detect software defects earlier after releasing the product to the market causes higher repair costs for the company.","cats":{"ml-security":0}}
{"text":"So, it decreases the company's reputation, violates user privacy, and causes an unrepairable issue for the application.  ","cats":{"ml-security":0}}
{"text":"UMKM Masa Kini (UMI) is a Point of Sales application to sell any Micro, Small, and Medium Enterprises Product (UMKM).","cats":{"ml-security":0}}
{"text":"Therefore, in the current work, we analyze the suitability of these metrics to create Machine Learning based software vulnerability detectors for UMI applica","cats":{"ml-security":0}}
{"text":"Background: Despite the widespread use of automated security defect detection tools, software projects still contain many security defects that could result in serious damage.","cats":{"ml-security":1}}
{"text":"Such tools are largely context-insensitive and may not cover all possible scenarios in testing potential issues, which makes them susceptible to missing complex security defects.","cats":{"ml-security":0}}
{"text":"Hence, thorough detection entails a synergistic cooperation between these tools and human-intensive detection techniques, including code review.","cats":{"ml-security":0}}
{"text":"Code review is widely recognized as a crucial and effective practice for identifying security defects.","cats":{"ml-security":0}}
{"text":"Aim: This work aims to empirically investigate security defect detection through code review.","cats":{"ml-security":0}}
{"text":"Method: To this end, we conducted an empirical study by analyzing code review comments derived from four projects in the OpenStack and Qt communities.","cats":{"ml-security":0}}
{"text":"Through manually checking 20,995 review comments obtained by keyword-based search, we identified 614 comments as security-related.","cats":{"ml-security":0}}
{"text":"Results:","cats":{"ml-security":0}}
{"text":"Our results show that (1) security defects are not prevalently discussed in code review, (2) more than half of the reviewers provided explicit fixing strategies/solutions to help developers fix security defects, (3) developers tend to follow reviewers' suggestions and action the changes, (4) Not worth fixing the defect now and Disagreement between the developer and the reviewer are the main causes for not resolving security defects.","cats":{"ml-security":0}}
{"text":"Conclusions: Our research results demonstrate that (1) software security practices should combine manual code review with automated detection tools, achieving a more comprehensive coverage to identifying and addressing security defects, and (2) promoting appropriate standardization of practitioners' behaviors during code review remains necessary for enhancing software security.","cats":{"ml-security":0}}
{"text":"This leaves a back door for malicious attackers to collapse VAEs from the latent space, especially in scenarios where the encoder and decoder are used separately, such as communication and compressed sensing","cats":{"ml-security":1}}
{"text":"Specifically, we empirically demonstrate the latent vulnerability of popular generative autoencoders through attacks in the latent space.   ","cats":{"ml-security":0}}
{"text":"The generative autoencoders, such as the variational autoencoders or the adversarial autoencoders, have achieved great success in lots of real-world applications, including image generation, and signal communication.   ","cats":{"ml-security":0}}
{"text":"However, little concern has been devoted to their robustness during practical deployment.   ","cats":{"ml-security":0}}
{"text":"Due to the probabilistic latent structure, variational autoencoders (VAEs) may confront problems such as a mismatch between the posterior distribution of the latent and real data manifold, or discontinuity in the posterior distribution of the latent.   .   ","cats":{"ml-security":0}}
{"text":"In this work, we provide the first study on the adversarial robustness of generative autoencoders in the latent space.   ","cats":{"ml-security":0}}
{"text":"We also evaluate the difference between variational autoencoders anoff between the adversarial robustness and the degree of the disentanglement of the latent codes.   ","cats":{"ml-security":0}}
{"text":"Additionally, we also verify the feasibility of improvement for the latent robustness of VAEs through adversarial training.   ","cats":{"ml-security":0}}
{"text":"In summary, we suggest concerning the adversarial latent robustness of the generative autoencoders, analyze several robustness-relative issues, and give some insights into a series of key challenges.","cats":{"ml-security":0}}
{"text":"A major security threat to an integrated circuit (IC) design is the Hardware Trojan attack which is a malicious modification of the design.","cats":{"ml-security":0}}
{"text":"Previously several papers have investigated into side-channel analysis to detect the presence of Hardware Trojans.","cats":{"ml-security":0}}
{"text":"The side channel analysis were prescribed in these papers as an alternative to the conventional logic testing for detecting malicious modification in the design.","cats":{"ml-security":0}}
{"text":"It has been found that these conventional logic testing are ineffective when it comes to detecting small Trojans due to decrease in the sensitivity due to process variations encountered in the manufacturing techniques.","cats":{"ml-security":0}}
{"text":"The main paper under consideration in this survey report focuses on proposing a new technique to detect Trojans by using multiple-parameter side-channel analysis.","cats":{"ml-security":0}}
{"text":"The novel idea will be explained thoroughly in this survey report.","cats":{"ml-security":0}}
{"text":"We also look into several other papers, which talk about single parameter analysis and how they are implemented.","cats":{"ml-security":0}}
{"text":"We analyzed the short comings of those single parameter analysis techniques and we then show how this multi-parameter analysis technique is better.","cats":{"ml-security":0}}
{"text":"Finally we will talk about the combined side-channel analysis and logic testing approach in which there is higher detection coverage for hardware Trojan circuits of different types and sizes.","cats":{"ml-security":0}}
{"text":"Deploying deep visual models can lead to performance drops due to the discrepancies between source and target distributions.","cats":{"ml-security":0}}
{"text":"Several approaches leverage labeled source data to estimate target domain accuracy, but accessing labeled source data is often prohibitively difficult due to data confidentiality or resource limitations on serving devices.","cats":{"ml-security":0}}
{"text":"Our work proposes a new framework to estimate model accuracy on unlabeled target data without access to source data.","cats":{"ml-security":0}}
{"text":"We investigate the feasibility of using pseudo-labels for accuracy estimation and evolve this idea into adopting recent advances in source-free domain adaptation algorithms.","cats":{"ml-security":0}}
{"text":"Our approach measures the disagreement rate between the source hypothesis and the target pseudo-labeling function, adapted from the source hypothesis.","cats":{"ml-security":0}}
{"text":"We mitigate the impact of erroneous pseudo-labels that may arise due to a high ideal joint hypothesis risk by employing adaptive adversarial perturbation on the input of the target model.","cats":{"ml-security":0}}
{"text":"Our proposed source-free framework effectively addresses the challenging distribution shift scenarios and outperforms existing methods requiring source data and labels for training.","cats":{"ml-security":0}}
{"text":"The paradigm of federated learning (FL) to address data privacy concerns by locally training parameters on resource-constrained clients in a distributed manner has garnered significant attention.","cats":{"ml-security":0}}
{"text":"Nonetheless, FL is not applicable when not all clients within the coverage of the FL server are registered with the FL network.","cats":{"ml-security":0}}
{"text":"To bridge this gap, this paper proposes joint learner referral aided federated client selection (LRef-FedCS), along with communications and computing resource scheduling, and local model accuracy optimization (LMAO) methods.","cats":{"ml-security":0}}
{"text":"These methods are designed to minimize the cost incurred by the worst-case participant and ensure the long-term fairness of FL in hierarchical Internet of Things (HieIoT) networks.","cats":{"ml-security":0}}
{"text":"Utilizing the Lyapunov optimization technique, we reformulate the original problem into a stepwise joint optimization problem (JOP).","cats":{"ml-security":0}}
{"text":"Subsequently, to tackle the mixed-integer non-convex JOP, we separatively and iteratively address LRef-FedCS and LMAO through the centralized method and self-adaptive global best harmony search (SGHS) algorithm, respectively.","cats":{"ml-security":0}}
{"text":"To enhance scalability, we further propose a distributed LRef-FedCS approach based on a matching game to replace the centralized method described above.","cats":{"ml-security":0}}
{"text":"Numerical simulations and experimental results on the MNIST/CIFAR-10 datasets demonstrate that our proposed LRef-FedCS approach could achieve a good balance between pursuing high global accuracy and reducing cost.","cats":{"ml-security":0}}
{"text":"Deep Neural Networks (DNNs) are susceptible to adversarial attacks.","cats":{"ml-security":1}}
{"text":"However, recent research has revealed that neural Ordinary Differential Equations (ODEs) exhibit robustness in specific applications","cats":{"ml-security":1}}
{"text":"Complex networks are used to model many real-world systems.","cats":{"ml-security":0}}
{"text":"However, the dimensionality of these systems can make them challenging to analyze.","cats":{"ml-security":0}}
{"text":"Dimensionality reduction techniques like POD can be used in such cases.","cats":{"ml-security":0}}
{"text":"However, these models are susceptible to perturbations in the input data.","cats":{"ml-security":0}}
{"text":"We propose an algorithmic framework that combines techniques from pattern recognition (PR) and stochastic filtering theory to enhance the output of such models.","cats":{"ml-security":0}}
{"text":"The results of our study show that our method can improve the accuracy of the surrogate model under perturbed inputs.  ","cats":{"ml-security":0}}
{"text":"However, recent research has revealed that neural Ordinary Differenproach as a reference.","cats":{"ml-security":0}}
{"text":"As a result, we have manually collected adversarial safety prompts across 10 scenarios and induced responsibility prompts from 8 domains by professional experts.","cats":{"ml-security":1}}
{"text":"With the rapid evolution of large language models (LLMs), there is a growing concern that they may pose risks or have negative social impacts.","cats":{"ml-security":0}}
{"text":"Therefore, evaluation of human values alignment is becoming increasingly important.","cats":{"ml-security":0}}
{"text":"Previous work mainly focuses on assessing the performance of LLMs on certain knowledge and reasoning abilities, while neglecting the alignment to human values, especially in a Chinese context.","cats":{"ml-security":0}}
{"text":"In this paper, we present CValues, the first Chinese human values evaluation benchmark to measure the alignment ability of LLMs in terms of both safety and responsibility criteria.  ","cats":{"ml-security":0}}
{"text":"To provide a comprehensive values evaluation of Chinese LLMs, we not only conduct human evaluation for reliable comparison, but also construct multi-choice prompts for automatic evaluation.","cats":{"ml-security":0}}
{"text":"Our findings suggest that while most Chinese LLMs perform well in terms of safety, there is considerable room for improvement in terms of responsibility.","cats":{"ml-security":0}}
{"text":"Moreover, both the automatic and human evaluation are important for assessing the human values alignment in different aspects.","cats":{"ml-security":0}}
{"text":"The benchmark and code is available on ModelScope and Github.","cats":{"ml-security":0}}
{"text":"Information security is a crucial need in the modern world.","cats":{"ml-security":0}}
{"text":"Data security is a real concern, and many customers and organizations need to protect their sensitive information from unauthorized parties and attackers.","cats":{"ml-security":0}}
{"text":"In previous years, numerous cryptographic schemes have been proposed.","cats":{"ml-security":0}}
{"text":"DNA cryptography is a new and developing field that combines the computational and biological worlds.","cats":{"ml-security":0}}
{"text":"DNA cryptography is intriguing due to its high storage capacity, secure data transport, and massive parallel computing.","cats":{"ml-security":0}}
{"text":"In this paper, a new combination is proposed that offers good security by combining DNA, the Rabin algorithm, one time pad, and a structure inspired by Fiestel.","cats":{"ml-security":0}}
{"text":"This algorithm employs two keys.","cats":{"ml-security":0}}
{"text":"The first key is a DNA OTP key which is used for only one secure communication session.","cats":{"ml-security":0}}
{"text":"The second key, which combines the public and private keys, is a Rabin key.","cats":{"ml-security":0}}
{"text":"Additionally, by using a Feistel inspired scheme and randomness provided by DNA, the ciphertext is made harder to obtain without the private key.","cats":{"ml-security":0}}
{"text":"We also analyze the exploitability and security consequences of developer secret leakage in mini-apps by examining individual super-app server-side APIs.","cats":{"ml-security":1}}
{"text":"We develop an analysis framework for measuring such secret leakage, and primarily analyze 110,993 WeChat mini-apps, and 10,000 Baidu mini-apps (two of the most prominent super-app platforms), along with a few more datasets to test the evolution of developer practices and platform security enforcement over time.","cats":{"ml-security":1}}
{"text":"We conduct a large-scale measurement of developers' insecure practices leading to mini-app to super-app authentication bypass, among which hard-coding developer secrets for such authentication is a major contributor.  ","cats":{"ml-security":0}}
{"text":"We develop an analysis framework for measuring such secret leakage, and primarily analyze 110,993 WeChat mini-apps, and 10,000 Baidu mini-apps (two of thy and privacy problems for the users and developers of mini-apps.","cats":{"ml-security":0}}
{"text":"A network attacker who does not even have an account on the super-app platform, can effectively take down a mini-app, send malicious and phishing links to users, and access sensitive information of the mini-app developer and its users.","cats":{"ml-security":0}}
{"text":"We responsibly disclosed our findings and also put forward potential directions that could be considered to alleviate/eliminate the root causes of developers hard-coding the app secrets in the mini-app's front-end code.","cats":{"ml-security":0}}
{"text":"It is universally acknowledged that Wi-Fi communications are important to secure.","cats":{"ml-security":0}}
{"text":"Thus, the Wi-Fi Alliance published WPA3 in 2018 with a distinctive security feature: it leverages a Password-Authenticated Key Exchange (PAKE) protocol to protect users' passwords from offline dictionary attacks.","cats":{"ml-security":0}}
{"text":"Unfortunately, soon after its release, several attacks were reported against its implementations, in response to which the protocol was updated in a best-effort manner.   ","cats":{"ml-security":0}}
{"text":"In this paper, we show that the proposed mitigations are not enough, especially for a complex protocol to implement even for savvy developers.","cats":{"ml-security":0}}
{"text":"Indeed, we present **Dragondoom**, a collection of side-channel vulnerabilities of varying strength allowing attackers to recover users' passwords in widely deployed Wi-Fi daemons, such as hostap in its default settings.","cats":{"ml-security":0}}
{"text":"Our findings target both password conversion methods, namely the default probabilistic hunting-and-pecking and its newly standardized deterministic alternative based on SSWU.","cats":{"ml-security":0}}
{"text":"We successfully exploit our leakage in practice through microarchitectural mechanisms, and overcome the limited spatial resolution of Flush+Reload.","cats":{"ml-security":0}}
{"text":"Our attacks outperform previous works in terms of required measurements.   ","cats":{"ml-security":0}}
{"text":"Then, driven by the need to end the spiral of patch-and-hack in Dragonfly implementations, we propose **Dragonstar**, an implementation of Dragonfly leveraging a formally verified implementation of the underlying mathematical operations, thereby removing all the related leakage vector.","cats":{"ml-security":0}}
{"text":"Our implementation relies on HACL*, a formally verified crypto library guaranteeing secret-independence.","cats":{"ml-security":0}}
{"text":"We design Dragonstar, so that its integration within hostap requires minimal modifications to the existing project.","cats":{"ml-security":0}}
{"text":"Our experiments show that the performance of HACL*-based hostap is comparable to OpenSSL-based, implying that Dragonstar is both efficient and proved to be leakage-free.","cats":{"ml-security":0}}
