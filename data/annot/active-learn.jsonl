{"text":"Training deep networks requires various design decisions regarding for instance their architecture, data augmentation, or optimization.","meta":{"url":"http://arxiv.org/abs/2310.17653v1"},"cats":{"benchmark":0.2778157005,"new-dataset":0.0101092048,"data-annotation":0.4918945849,"dev-research":0.2234878258,"llms":0.5071189381,"data-quality":0.1132422106}}
{"text":"In this work, we find these training variations to result in networks learning unique feature sets from the data.","meta":{"url":"http://arxiv.org/abs/2310.17653v1"},"cats":{"benchmark":0.3183425523,"new-dataset":0.1909267206,"data-annotation":0.5155166379,"dev-research":0.1531447397,"llms":0.3786461623,"data-quality":0.3840412362}}
{"text":"Using public model libraries comprising thousands of models trained on canonical datasets like ImageNet, we observe that for arbitrary pairings of pretrained models, one model extracts significant data context unavailable in the other -- independent of overall performance.","meta":{"url":"http://arxiv.org/abs/2310.17653v1"},"cats":{"benchmark":0.3188944866,"new-dataset":0.1918086928,"data-annotation":0.5173010211,"dev-research":0.1464729537,"llms":0.4540877789,"data-quality":0.1552677917}}
{"text":"Given any arbitrary pairing of pretrained models and no external rankings (such as separate test sets, e.g. due to data privacy), we investigate if it is possible to transfer such \"complementary\" knowledge from one model to another without performance degradation -- a task made particularly difficult as additional knowledge can be contained in stronger, equiperformant or weaker models.","meta":{"url":"http://arxiv.org/abs/2310.17653v1"},"cats":{"benchmark":0.4314747752,"new-dataset":0.0174326067,"data-annotation":0.5052155247,"dev-research":0.1463536862,"llms":0.5157812433,"data-quality":0.1149103159}}
{"text":"Yet facilitating robust transfer in scenarios agnostic to pretrained model pairings would unlock auxiliary gains and knowledge fusion from any model repository without restrictions on model and problem specifics - including from weaker, lower-performance models.","meta":{"url":"http://arxiv.org/abs/2310.17653v1"},"cats":{"benchmark":0.3014543633,"new-dataset":0.0354627854,"data-annotation":0.4909183604,"dev-research":0.224619039,"llms":0.480093932,"data-quality":0.1099778538}}
{"text":"This work therefore provides an initial, in-depth exploration on the viability of such general-purpose knowledge transfer.","meta":{"url":"http://arxiv.org/abs/2310.17653v1"},"cats":{"benchmark":0.2191248786,"new-dataset":0.048278356,"data-annotation":0.5026547518,"dev-research":0.2686941396,"llms":0.562244839,"data-quality":0.10606176}}
{"text":"Across large-scale experiments, we first reveal the shortcomings of standard knowledge distillation techniques, and then propose a much more general extension through data partitioning for successful transfer between nearly all pretrained models, which we show can also be done unsupervised.","meta":{"url":"http://arxiv.org/abs/2310.17653v1"},"cats":{"benchmark":0.3250895601,"new-dataset":0.040432425,"data-annotation":0.4953931947,"dev-research":0.1648783407,"llms":0.4858466863,"data-quality":0.1624192394}}
{"text":"Finally, we assess both the scalability and impact of fundamental model properties on successful model-agnostic knowledge transfer.","meta":{"url":"http://arxiv.org/abs/2310.17653v1"},"cats":{"benchmark":0.3422435023,"new-dataset":0.0100504833,"data-annotation":0.4927600748,"dev-research":0.178956078,"llms":0.4638913025,"data-quality":0.1173838626}}
{"text":"Detection of anomalous events in videos is an important problem in applications such as surveillance.","meta":{"url":"http://arxiv.org/abs/2310.17650v1"},"cats":{"benchmark":0.2838122164,"new-dataset":0.0557718869,"data-annotation":0.5301110962,"dev-research":0.2039476939,"llms":0.4309706208,"data-quality":0.2694375175}}
{"text":"Video anomaly detection (VAD) is well-studied in the one-class classification (OCC) and weakly supervised (WS) settings.","meta":{"url":"http://arxiv.org/abs/2310.17650v1"},"cats":{"benchmark":0.2654977743,"new-dataset":0.0716762954,"data-annotation":0.5184431839,"dev-research":0.1642312052,"llms":0.5217286669,"data-quality":0.4143045602}}
{"text":"However, fully unsupervised (US) video anomaly detection methods, which learn a complete system without any annotation or human supervision, have not been explored in depth.","meta":{"url":"http://arxiv.org/abs/2310.17650v1"},"cats":{"benchmark":0.2045627386,"new-dataset":0.0957124419,"data-annotation":0.5282001563,"dev-research":0.194263585,"llms":0.5372466668,"data-quality":0.3394781298}}
{"text":"This is because the lack of any ground truth annotations significantly increases the magnitude of the VAD challenge.","meta":{"url":"http://arxiv.org/abs/2310.17650v1"},"cats":{"benchmark":0.3431578087,"new-dataset":0.0118148737,"data-annotation":0.5290711283,"dev-research":0.1661339933,"llms":0.5955704704,"data-quality":0.347601321}}
{"text":"To address this challenge, we propose a simple-but-effective two-stage pseudo-label generation framework that produces segment-level (normal/anomaly) pseudo-labels, which can be further used to train a segment-level anomaly detector in a supervised manner.","meta":{"url":"http://arxiv.org/abs/2310.17650v1"},"cats":{"benchmark":0.2754085783,"new-dataset":0.4633402273,"data-annotation":0.5184398228,"dev-research":0.2285411321,"llms":0.487989213,"data-quality":0.6037131001}}
{"text":"The proposed coarse-to-fine pseudo-label (C2FPL) generator employs carefully-designed hierarchical divisive clustering and statistical hypothesis testing to identify anomalous video segments from a set of completely unlabeled videos.","meta":{"url":"http://arxiv.org/abs/2310.17650v1"},"cats":{"benchmark":0.3956903154,"new-dataset":0.3301003214,"data-annotation":0.5155002301,"dev-research":0.1503858944,"llms":0.4986289393,"data-quality":0.469797827}}
{"text":"The trained anomaly detector can be directly applied on segments of an unseen test video to obtain segment-level, and subsequently, frame-level anomaly predictions.","meta":{"url":"http://arxiv.org/abs/2310.17650v1"},"cats":{"benchmark":0.2606492007,"new-dataset":0.0901220068,"data-annotation":0.5331299957,"dev-research":0.1815466082,"llms":0.4396239342,"data-quality":0.3928572891}}
{"text":"Extensive studies on two large-scale public-domain datasets, UCF-Crime and XD-Violence, demonstrate that the proposed unsupervised approach achieves superior performance compared to all existing OCC and US methods , while yielding comparable performance to the state-of-the-art WS methods.","meta":{"url":"http://arxiv.org/abs/2310.17650v1"},"cats":{"benchmark":0.4640046378,"new-dataset":0.212950649,"data-annotation":0.5047355177,"dev-research":0.179125016,"llms":0.4345234685,"data-quality":0.1500932993}}
{"text":"A core capability for robot manipulation is reasoning over where and how to stably place objects in cluttered environments.","meta":{"url":"http://arxiv.org/abs/2310.17649v1"},"cats":{"benchmark":0.2846566251,"new-dataset":0.0382058709,"data-annotation":0.5087063254,"dev-research":0.2808821549,"llms":0.5319759855,"data-quality":0.0661999291}}
{"text":"Traditionally, robots have relied on object-specific, hand-crafted heuristics in order to perform such reasoning, with limited generalizability beyond a small number of object instances and object interaction patterns.","meta":{"url":"http://arxiv.org/abs/2310.17649v1"},"cats":{"benchmark":0.1585151913,"new-dataset":0.0096291416,"data-annotation":0.5083333564,"dev-research":0.2370512426,"llms":0.5670165269,"data-quality":0.0456804228}}
{"text":"Recent approaches instead learn notions of physical interaction, namely motion prediction, but require supervision in the form of labeled object information or come at the cost of high sample complexity, and do not directly reason over stability or object placement.","meta":{"url":"http://arxiv.org/abs/2310.17649v1"},"cats":{"benchmark":0.2162384384,"new-dataset":0.0588656295,"data-annotation":0.5451202896,"dev-research":0.2482955656,"llms":0.467557282,"data-quality":0.0927487577}}
{"text":"We present 6-DoFusion, a generative model capable of generating 3D poses of an object that produces a stable configuration of a given scene.","meta":{"url":"http://arxiv.org/abs/2310.17649v1"},"cats":{"benchmark":0.1776386042,"new-dataset":0.467708147,"data-annotation":0.5018767145,"dev-research":0.1611823412,"llms":0.5455095602,"data-quality":0.0459421177}}
{"text":"Underlying 6-DoFusion is a diffusion model that incrementally refines a randomly initialized SE(3) pose to generate a sample from a learned, context-dependent distribution over stable poses.","meta":{"url":"http://arxiv.org/abs/2310.17649v1"},"cats":{"benchmark":0.2163903045,"new-dataset":0.2312356814,"data-annotation":0.4995921385,"dev-research":0.115607318,"llms":0.5187740384,"data-quality":0.0510888843}}
{"text":"We evaluate our model on different object placement and stacking tasks, demonstrating its ability to construct stable scenes that involve novel object classes as well as to improve the accuracy of state-of-the-art 3D pose estimation methods.","meta":{"url":"http://arxiv.org/abs/2310.17649v1"},"cats":{"benchmark":0.3928812799,"new-dataset":0.2525380937,"data-annotation":0.5350593635,"dev-research":0.1899159953,"llms":0.4635599187,"data-quality":0.1139874555}}
{"text":"Adversarial attacks have been a looming and unaddressed threat in the industry.","meta":{"url":"http://arxiv.org/abs/2310.17645v1"},"cats":{"benchmark":0.1833379404,"new-dataset":0.0312574194,"data-annotation":0.5201626517,"dev-research":0.2734288709,"llms":0.5016838622,"data-quality":0.2045467533}}
{"text":"However, through a decade-long history of the robustness evaluation literature, we have learned that mounting a strong or optimal attack is challenging.","meta":{"url":"http://arxiv.org/abs/2310.17645v1"},"cats":{"benchmark":0.593466608,"new-dataset":0.0093934062,"data-annotation":0.5227932118,"dev-research":0.260166886,"llms":0.4592784184,"data-quality":0.2778508135}}
{"text":"It requires both machine learning and domain expertise.","meta":{"url":"http://arxiv.org/abs/2310.17645v1"},"cats":{"benchmark":0.2765720718,"new-dataset":0.0089199185,"data-annotation":0.5101083094,"dev-research":0.2362873254,"llms":0.5104052669,"data-quality":0.1264162871}}
{"text":"In other words, the white-box threat model, religiously assumed by a large majority of the past literature, is unrealistic.","meta":{"url":"http://arxiv.org/abs/2310.17645v1"},"cats":{"benchmark":0.2249980146,"new-dataset":0.0075472118,"data-annotation":0.5144832001,"dev-research":0.1827148861,"llms":0.4898203694,"data-quality":0.0970053017}}
{"text":"In this paper, we propose a new practical threat model where the adversary relies on transfer attacks through publicly available surrogate models.","meta":{"url":"http://arxiv.org/abs/2310.17645v1"},"cats":{"benchmark":0.3380543221,"new-dataset":0.0288148003,"data-annotation":0.5259452665,"dev-research":0.1395399522,"llms":0.4630401778,"data-quality":0.0839983361}}
{"text":"We argue that this setting will become the most prevalent for security-sensitive applications in the future.","meta":{"url":"http://arxiv.org/abs/2310.17645v1"},"cats":{"benchmark":0.281898076,"new-dataset":0.0191485256,"data-annotation":0.5106850629,"dev-research":0.2804918864,"llms":0.5875308074,"data-quality":0.1085934657}}
{"text":"We evaluate the transfer attacks in this setting and propose a specialized defense method based on a game-theoretic perspective.","meta":{"url":"http://arxiv.org/abs/2310.17645v1"},"cats":{"benchmark":0.3420069301,"new-dataset":0.0316725279,"data-annotation":0.5311486551,"dev-research":0.1696194909,"llms":0.4923604647,"data-quality":0.0700180805}}
{"text":"The defenses are evaluated under 24 public models and 11 attack algorithms across three datasets (CIFAR-10, CIFAR-100, and ImageNet).","meta":{"url":"http://arxiv.org/abs/2310.17645v1"},"cats":{"benchmark":0.3358884243,"new-dataset":0.3010921902,"data-annotation":0.5222014544,"dev-research":0.1771397855,"llms":0.4539422089,"data-quality":0.1325843454}}
{"text":"Under this threat model, our defense, PubDef, outperforms the state-of-the-art white-box adversarial training by a large margin with almost no loss in the normal accuracy.","meta":{"url":"http://arxiv.org/abs/2310.17645v1"},"cats":{"benchmark":0.3857406351,"new-dataset":0.0702938867,"data-annotation":0.5499325231,"dev-research":0.1519409592,"llms":0.4558105415,"data-quality":0.1728096435}}
{"text":"For instance, on ImageNet, our defense achieves 62% accuracy under the strongest transfer attack vs only 36% of the best adversarially trained model.","meta":{"url":"http://arxiv.org/abs/2310.17645v1"},"cats":{"benchmark":0.4190734132,"new-dataset":0.0181923674,"data-annotation":0.5376665135,"dev-research":0.1661753098,"llms":0.470216685,"data-quality":0.1789513232}}
{"text":"Its accuracy when not under attack is only 2% lower than that of an undefended model (78% vs 80%).","meta":{"url":"http://arxiv.org/abs/2310.17645v1"},"cats":{"benchmark":0.6599546426,"new-dataset":0.002973197,"data-annotation":0.5364172172,"dev-research":0.1776007879,"llms":0.4571959725,"data-quality":0.2142918241}}
{"text":"We release our code at https://github.com/wagner-group/pubdef.","meta":{"url":"http://arxiv.org/abs/2310.17645v1"},"cats":{"benchmark":0.3512939152,"new-dataset":0.2978737789,"data-annotation":0.5371186805,"dev-research":0.2347183972,"llms":0.5039733556,"data-quality":0.1705065266}}
{"text":"Reproducibility in scientific work has been becoming increasingly important in research communities such as machine learning, natural language processing, and computer vision communities due to the rapid development of the research domains supported by recent advances in deep learning.","meta":{"url":"http://arxiv.org/abs/2310.17644v1"},"cats":{"benchmark":0.2639326679,"new-dataset":0.2485541555,"data-annotation":0.5209618616,"dev-research":0.2685257419,"llms":0.5073290574,"data-quality":0.2609997613}}
{"text":"In this work, we present a significantly upgraded version of torchdistill, a modular-driven coding-free deep learning framework significantly upgraded from the initial release, which supports only image classification and object detection tasks for reproducible knowledge distillation experiments.","meta":{"url":"http://arxiv.org/abs/2310.17644v1"},"cats":{"benchmark":0.1643153301,"new-dataset":0.3818341122,"data-annotation":0.5091787926,"dev-research":0.1822918239,"llms":0.5557022034,"data-quality":0.1930461775}}
{"text":"To demonstrate that the upgraded framework can support more tasks with third-party libraries, we reproduce the GLUE benchmark results of BERT models using a script based on the upgraded torchdistill, harmonizing with various Hugging Face libraries.","meta":{"url":"http://arxiv.org/abs/2310.17644v1"},"cats":{"benchmark":0.4385085451,"new-dataset":0.2157370016,"data-annotation":0.5365107618,"dev-research":0.2807482807,"llms":0.5344090516,"data-quality":0.0793301394}}
{"text":"All the 27 fine-tuned BERT models and configurations to reproduce the results are published at Hugging Face, and the model weights have already been widely used in research communities.","meta":{"url":"http://arxiv.org/abs/2310.17644v1"},"cats":{"benchmark":0.3765731387,"new-dataset":0.1651561907,"data-annotation":0.5470308655,"dev-research":0.1744057179,"llms":0.4790226529,"data-quality":0.0691992489}}
{"text":"We also reimplement popular small-sized models and new knowledge distillation methods and perform additional experiments for computer vision tasks.","meta":{"url":"http://arxiv.org/abs/2310.17644v1"},"cats":{"benchmark":0.2865977186,"new-dataset":0.0700375535,"data-annotation":0.5225584305,"dev-research":0.1842364238,"llms":0.4515762989,"data-quality":0.098718752}}
{"text":"Concerns about data privacy are omnipresent, given the increasing usage of digital applications and their underlying business model that includes selling user data.","meta":{"url":"http://arxiv.org/abs/2310.17643v1"},"cats":{"benchmark":0.1643481942,"new-dataset":0.0471445777,"data-annotation":0.4596096607,"dev-research":0.2318788401,"llms":0.5237999037,"data-quality":0.1196234124}}
{"text":"Location data is particularly sensitive since they allow us to infer activity patterns and interests of users, e.g., by categorizing visited locations based on nearby points of interest (POI).","meta":{"url":"http://arxiv.org/abs/2310.17643v1"},"cats":{"benchmark":0.2627298327,"new-dataset":0.068842106,"data-annotation":0.5046406339,"dev-research":0.1864600855,"llms":0.4950302037,"data-quality":0.1353878894}}
{"text":"On top of that, machine learning methods provide new powerful tools to interpret big data.","meta":{"url":"http://arxiv.org/abs/2310.17643v1"},"cats":{"benchmark":0.284961121,"new-dataset":0.0645069239,"data-annotation":0.4947722883,"dev-research":0.2244969998,"llms":0.4858615375,"data-quality":0.1101849158}}
{"text":"In light of these considerations, we raise the following question: What is the actual risk that realistic, machine learning based privacy attacks can obtain meaningful semantic information from raw location data, subject to inaccuracies in the data?","meta":{"url":"http://arxiv.org/abs/2310.17643v1"},"cats":{"benchmark":0.2199638542,"new-dataset":0.0703213877,"data-annotation":0.506286247,"dev-research":0.1880623777,"llms":0.4833035673,"data-quality":0.2736141927}}
{"text":"In response, we present a systematic analysis of two attack scenarios, namely location categorization and user profiling.","meta":{"url":"http://arxiv.org/abs/2310.17643v1"},"cats":{"benchmark":0.3752410723,"new-dataset":0.0968610427,"data-annotation":0.5233862341,"dev-research":0.3229399357,"llms":0.4663934263,"data-quality":0.1392480962}}
{"text":"Experiments on the Foursquare dataset and tracking data demonstrate the potential for abuse of high-quality spatial information, leading to a significant privacy loss even with location inaccuracy of up to 200m. With location obfuscation of more than 1 km, spatial information hardly adds any value, but a high privacy risk solely from temporal information remains.","meta":{"url":"http://arxiv.org/abs/2310.17643v1"},"cats":{"benchmark":0.2474844935,"new-dataset":0.2452968842,"data-annotation":0.4932166912,"dev-research":0.1550832841,"llms":0.4723397465,"data-quality":0.1377019307}}
{"text":"The availability of public context data such as POIs plays a key role in inference based on spatial information.","meta":{"url":"http://arxiv.org/abs/2310.17643v1"},"cats":{"benchmark":0.240590724,"new-dataset":0.0616147755,"data-annotation":0.4915352736,"dev-research":0.1733992289,"llms":0.4816446762,"data-quality":0.0934080684}}
{"text":"Our findings point out the risks of ever-growing databases of tracking data and spatial context data, which policymakers should consider for privacy regulations, and which could guide individuals in their personal location protection measures.","meta":{"url":"http://arxiv.org/abs/2310.17643v1"},"cats":{"benchmark":0.203842618,"new-dataset":0.2878749529,"data-annotation":0.4674381748,"dev-research":0.2419205281,"llms":0.4749230938,"data-quality":0.1253690731}}
{"text":"As autonomous driving technology matures, end-to-end methodologies have emerged as a leading strategy, promising seamless integration from perception to control via deep learning.","meta":{"url":"http://arxiv.org/abs/2310.17642v1"},"cats":{"benchmark":0.1996387651,"new-dataset":0.1320736178,"data-annotation":0.4767714006,"dev-research":0.2023905111,"llms":0.5168189253,"data-quality":0.0880250463}}
{"text":"However, existing systems grapple with challenges such as unexpected open set environments and the complexity of black-box models.","meta":{"url":"http://arxiv.org/abs/2310.17642v1"},"cats":{"benchmark":0.226997506,"new-dataset":0.042059835,"data-annotation":0.5022501389,"dev-research":0.3129045158,"llms":0.5131514352,"data-quality":0.1074098089}}
{"text":"At the same time, the evolution of deep learning introduces larger, multimodal foundational models, offering multi-modal visual and textual understanding.","meta":{"url":"http://arxiv.org/abs/2310.17642v1"},"cats":{"benchmark":0.1619526432,"new-dataset":0.1969457944,"data-annotation":0.5247043267,"dev-research":0.1576159153,"llms":0.4886030112,"data-quality":0.0982867261}}
{"text":"In this paper, we harness these multimodal foundation models to enhance the robustness and adaptability of autonomous driving systems, enabling out-of-distribution, end-to-end, multimodal, and more explainable autonomy.","meta":{"url":"http://arxiv.org/abs/2310.17642v1"},"cats":{"benchmark":0.212016408,"new-dataset":0.1970863634,"data-annotation":0.5065150293,"dev-research":0.1966870226,"llms":0.4421654618,"data-quality":0.0852681921}}
{"text":"Specifically, we present an approach to apply end-to-end open-set (any environment/scene) autonomous driving that is capable of providing driving decisions from representations queryable by image and text.","meta":{"url":"http://arxiv.org/abs/2310.17642v1"},"cats":{"benchmark":0.1888288276,"new-dataset":0.3399687741,"data-annotation":0.5004085419,"dev-research":0.1659225102,"llms":0.5050745383,"data-quality":0.1094731449}}
{"text":"To do so, we introduce a method to extract nuanced spatial (pixel/patch-aligned) features from transformers to enable the encapsulation of both spatial and semantic features.","meta":{"url":"http://arxiv.org/abs/2310.17642v1"},"cats":{"benchmark":0.265868678,"new-dataset":0.111302448,"data-annotation":0.5000345772,"dev-research":0.2649027163,"llms":0.4979469896,"data-quality":0.2087258217}}
{"text":"Our approach (i) demonstrates unparalleled results in diverse tests while achieving significantly greater robustness in out-of-distribution situations, and (ii) allows the incorporation of latent space simulation (via text) for improved training (data augmentation via text) and policy debugging.","meta":{"url":"http://arxiv.org/abs/2310.17642v1"},"cats":{"benchmark":0.4026476192,"new-dataset":0.1362126053,"data-annotation":0.5127732882,"dev-research":0.2306789565,"llms":0.4979260861,"data-quality":0.3300287171}}
{"text":"We encourage the reader to check our explainer video at https://www.youtube.com/watch?v=4n-DJf8vXxo&feature=youtu.be and to view the code and demos on our project webpage at https://drive-anywhere.github.io/.","meta":{"url":"http://arxiv.org/abs/2310.17642v1"},"cats":{"benchmark":0.2512248305,"new-dataset":0.049610807,"data-annotation":0.5350674918,"dev-research":0.3258593486,"llms":0.5143874828,"data-quality":0.1298802191}}
{"text":"Large language models (LLMs) trained on huge corpora of text datasets demonstrate complex, emergent capabilities, achieving state-of-the-art performance on tasks they were not explicitly trained for.","meta":{"url":"http://arxiv.org/abs/2310.17639v1"},"cats":{"benchmark":0.2116810825,"new-dataset":0.4342920207,"data-annotation":0.5296141011,"dev-research":0.1209477292,"llms":0.6954842476,"data-quality":0.1606926881}}
{"text":"The precise nature of LLM capabilities is often mysterious, and different prompts can elicit different capabilities through in-context learning.","meta":{"url":"http://arxiv.org/abs/2310.17639v1"},"cats":{"benchmark":0.1262270426,"new-dataset":0.0097512711,"data-annotation":0.5042125673,"dev-research":0.1319487096,"llms":0.784756971,"data-quality":0.0630358249}}
{"text":"We propose a Cognitive Interpretability framework that enables us to analyze in-context learning dynamics to understand latent concepts in LLMs underlying behavioral patterns.","meta":{"url":"http://arxiv.org/abs/2310.17639v1"},"cats":{"benchmark":0.147906482,"new-dataset":0.0341617191,"data-annotation":0.5074869072,"dev-research":0.2319947824,"llms":0.6715853263,"data-quality":0.1894063928}}
{"text":"This provides a more nuanced understanding than success-or-failure evaluation benchmarks, but does not require observing internal activations as a mechanistic interpretation of circuits would.","meta":{"url":"http://arxiv.org/abs/2310.17639v1"},"cats":{"benchmark":0.6421304588,"new-dataset":0.0019359122,"data-annotation":0.5314510044,"dev-research":0.2302022847,"llms":0.4973172107,"data-quality":0.1876320858}}
{"text":"Inspired by the cognitive science of human randomness perception, we use random binary sequences as context and study dynamics of in-context learning by manipulating properties of context data, such as sequence length.","meta":{"url":"http://arxiv.org/abs/2310.17639v1"},"cats":{"benchmark":0.1920052357,"new-dataset":0.076677812,"data-annotation":0.516904248,"dev-research":0.1575812943,"llms":0.5260082886,"data-quality":0.1287404339}}
{"text":"In the latest GPT-3.5+ models, we find emergent abilities to generate pseudo-random numbers and learn basic formal languages, with striking in-context learning dynamics where model outputs transition sharply from pseudo-random behaviors to deterministic repetition.","meta":{"url":"http://arxiv.org/abs/2310.17639v1"},"cats":{"benchmark":0.15308834,"new-dataset":0.1160469738,"data-annotation":0.5332947833,"dev-research":0.1473988448,"llms":0.5469441774,"data-quality":0.0997914181}}
{"text":"We generalize the continuous time framework for score-based generative models from an underlying Brownian motion (BM) to an approximation of fractional Brownian motion (FBM).","meta":{"url":"http://arxiv.org/abs/2310.17638v1"},"cats":{"benchmark":0.4313940584,"new-dataset":0.0240452386,"data-annotation":0.5140836718,"dev-research":0.1455199731,"llms":0.4680024459,"data-quality":0.0944719446}}
{"text":"We derive a continuous reparameterization trick and the reverse time model by representing FBM as a stochastic integral over a family of Ornstein-Uhlenbeck processes to define generative fractional diffusion models (GFDM) with driving noise converging to a non-Markovian process of infinite quadratic variation.","meta":{"url":"http://arxiv.org/abs/2310.17638v1"},"cats":{"benchmark":0.3517326276,"new-dataset":0.0134641308,"data-annotation":0.5027652971,"dev-research":0.1444997647,"llms":0.5055322189,"data-quality":0.0983031385}}
{"text":"The Hurst index $H\\in(0,1)$ of FBM enables control of the roughness of the distribution transforming path.","meta":{"url":"http://arxiv.org/abs/2310.17638v1"},"cats":{"benchmark":0.4361015339,"new-dataset":0.0219427598,"data-annotation":0.4909570628,"dev-research":0.1163556106,"llms":0.5192983021,"data-quality":0.0881810875}}
{"text":"To the best of our knowledge, this is the first attempt to build a generative model upon a stochastic process with infinite quadratic variation.","meta":{"url":"http://arxiv.org/abs/2310.17638v1"},"cats":{"benchmark":0.2580654437,"new-dataset":0.0396448217,"data-annotation":0.5249499985,"dev-research":0.1314448308,"llms":0.4377920688,"data-quality":0.0615957194}}
{"text":"Deep reinforcement learning (RL) can enable robots to autonomously acquire complex behaviors, such as legged locomotion.","meta":{"url":"http://arxiv.org/abs/2310.17634v1"},"cats":{"benchmark":0.1848645951,"new-dataset":0.0659565115,"data-annotation":0.4932112725,"dev-research":0.1529490419,"llms":0.5079943861,"data-quality":0.0501149959}}
{"text":"However, RL in the real world is complicated by constraints on efficiency, safety, and overall training stability, which limits its practical applicability.","meta":{"url":"http://arxiv.org/abs/2310.17634v1"},"cats":{"benchmark":0.3095190302,"new-dataset":0.0114768905,"data-annotation":0.5136916759,"dev-research":0.2164464562,"llms":0.4345081638,"data-quality":0.0826007035}}
{"text":"We present APRL, a policy regularization framework that modulates the robot's exploration over the course of training, striking a balance between flexible improvement potential and focused, efficient exploration.","meta":{"url":"http://arxiv.org/abs/2310.17634v1"},"cats":{"benchmark":0.2863528875,"new-dataset":0.0341909782,"data-annotation":0.504355513,"dev-research":0.2100681763,"llms":0.4508590216,"data-quality":0.0779816714}}
{"text":"APRL enables a quadrupedal robot to efficiently learn to walk entirely in the real world within minutes and continue to improve with more training where prior work saturates in performance.","meta":{"url":"http://arxiv.org/abs/2310.17634v1"},"cats":{"benchmark":0.2698064854,"new-dataset":0.0758705899,"data-annotation":0.5125832834,"dev-research":0.2036129146,"llms":0.4569618134,"data-quality":0.0641404774}}
{"text":"We demonstrate that continued training with APRL results in a policy that is substantially more capable of navigating challenging situations and is able to adapt to changes in dynamics with continued training.","meta":{"url":"http://arxiv.org/abs/2310.17634v1"},"cats":{"benchmark":0.2279142739,"new-dataset":0.0523219468,"data-annotation":0.4928954211,"dev-research":0.2209887133,"llms":0.5025443478,"data-quality":0.0770300685}}
{"text":"Geometry reconstruction of textureless, non-Lambertian objects under unknown natural illumination (i.e., in the wild) remains challenging as correspondences cannot be established and the reflectance cannot be expressed in simple analytical forms.","meta":{"url":"http://arxiv.org/abs/2310.17632v1"},"cats":{"benchmark":0.3331903575,"new-dataset":0.0737873218,"data-annotation":0.5183712984,"dev-research":0.1171115053,"llms":0.4449172952,"data-quality":0.1017231275}}
{"text":"We derive a novel multi-view method, DeepShaRM, that achieves state-of-the-art accuracy on this challenging task.","meta":{"url":"http://arxiv.org/abs/2310.17632v1"},"cats":{"benchmark":0.4851640496,"new-dataset":0.1531251134,"data-annotation":0.5398849285,"dev-research":0.1617909964,"llms":0.4292392286,"data-quality":0.1638893107}}
{"text":"Unlike past methods that formulate this as inverse-rendering, i.e., estimation of reflectance, illumination, and geometry from images, our key idea is to realize that reflectance and illumination need not be disentangled and instead estimated as a compound reflectance map.","meta":{"url":"http://arxiv.org/abs/2310.17632v1"},"cats":{"benchmark":0.3908277051,"new-dataset":0.0245356911,"data-annotation":0.5185879077,"dev-research":0.1690269547,"llms":0.4003974753,"data-quality":0.0927056031}}
{"text":"We introduce a novel deep reflectance map estimation network that recovers the camera-view reflectance maps from the surface normals of the current geometry estimate and the input multi-view images.","meta":{"url":"http://arxiv.org/abs/2310.17632v1"},"cats":{"benchmark":0.3324395069,"new-dataset":0.4844715366,"data-annotation":0.5058910094,"dev-research":0.1647735303,"llms":0.4032837564,"data-quality":0.1143080694}}
{"text":"The network also explicitly estimates per-pixel confidence scores to handle global light transport effects.","meta":{"url":"http://arxiv.org/abs/2310.17632v1"},"cats":{"benchmark":0.4353444155,"new-dataset":0.050074092,"data-annotation":0.4906008043,"dev-research":0.1570549792,"llms":0.4126237775,"data-quality":0.0913825847}}
{"text":"A deep shape-from-shading network then updates the geometry estimate expressed with a signed distance function using the recovered reflectance maps.","meta":{"url":"http://arxiv.org/abs/2310.17632v1"},"cats":{"benchmark":0.4029639116,"new-dataset":0.1796697534,"data-annotation":0.4988780921,"dev-research":0.1504849587,"llms":0.413251203,"data-quality":0.096101166}}
{"text":"By alternating between these two, and, most important, by bypassing the ill-posed problem of reflectance and illumination decomposition, the method accurately recovers object geometry in these challenging settings.","meta":{"url":"http://arxiv.org/abs/2310.17632v1"},"cats":{"benchmark":0.4934993692,"new-dataset":0.020691035,"data-annotation":0.5175695,"dev-research":0.1948013873,"llms":0.3955242284,"data-quality":0.130647966}}
{"text":"Extensive experiments on both synthetic and real-world data clearly demonstrate its state-of-the-art accuracy.","meta":{"url":"http://arxiv.org/abs/2310.17632v1"},"cats":{"benchmark":0.5992308452,"new-dataset":0.1940030195,"data-annotation":0.4983967491,"dev-research":0.1603521191,"llms":0.410307972,"data-quality":0.2227783395}}
{"text":"Evaluating Large Language Models (LLMs) in open-ended scenarios is challenging because existing benchmarks and metrics can not measure them comprehensively.","meta":{"url":"http://arxiv.org/abs/2310.17631v1"},"cats":{"benchmark":0.461758958,"new-dataset":0.1134752309,"data-annotation":0.5437440861,"dev-research":0.1699524487,"llms":0.6775035918,"data-quality":0.2208321313}}
{"text":"To address this problem, we propose to fine-tune LLMs as scalable judges (JudgeLM) to evaluate LLMs efficiently and effectively in open-ended benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.17631v1"},"cats":{"benchmark":0.6808038899,"new-dataset":0.0550959117,"data-annotation":0.4998149283,"dev-research":0.1135266172,"llms":0.7415513467,"data-quality":0.14968662}}
{"text":"We first propose a comprehensive, large-scale, high-quality dataset containing task seeds, LLMs-generated answers, and GPT-4-generated judgments for fine-tuning high-performance judges, as well as a new benchmark for evaluating the judges.","meta":{"url":"http://arxiv.org/abs/2310.17631v1"},"cats":{"benchmark":0.5854166228,"new-dataset":0.2600102857,"data-annotation":0.5221690149,"dev-research":0.1727567206,"llms":0.6195546606,"data-quality":0.1538229718}}
{"text":"We train JudgeLM","meta":{"url":"http://arxiv.org/abs/2310.17631v1"},"cats":{"benchmark":0.3041643639,"new-dataset":0.4489871206,"data-annotation":0.5122816091,"dev-research":0.1763975201,"llms":0.5729550373,"data-quality":0.2360906042}}
{"text":"at different scales from 7B, 13B, to 33B parameters, and conduct a systematic analysis of its capabilities and behaviors.","meta":{"url":"http://arxiv.org/abs/2310.17631v1"},"cats":{"benchmark":0.3822376024,"new-dataset":0.1219765716,"data-annotation":0.4715475965,"dev-research":0.1505905089,"llms":0.555820631,"data-quality":0.0468321882}}
{"text":"We then analyze the key biases in fine-tuning LLM as a judge and consider them as position bias, knowledge bias, and format bias.","meta":{"url":"http://arxiv.org/abs/2310.17631v1"},"cats":{"benchmark":0.4945020068,"new-dataset":0.0152985784,"data-annotation":0.5251829331,"dev-research":0.1623849589,"llms":0.6948454991,"data-quality":0.2424080821}}
{"text":"To address these issues, JudgeLM introduces a bag of techniques including swap augmentation, reference support, and reference drop, which clearly enhance the judge's performance.","meta":{"url":"http://arxiv.org/abs/2310.17631v1"},"cats":{"benchmark":0.6063212847,"new-dataset":0.0335928442,"data-annotation":0.5030540345,"dev-research":0.2528315534,"llms":0.6068011261,"data-quality":0.2376983819}}
{"text":"JudgeLM obtains the state-of-the-art judge performance on both the existing PandaLM benchmark and our proposed new benchmark.","meta":{"url":"http://arxiv.org/abs/2310.17631v1"},"cats":{"benchmark":0.7732578035,"new-dataset":0.3286140803,"data-annotation":0.5083245011,"dev-research":0.1550733622,"llms":0.524031938,"data-quality":0.1663029053}}
{"text":"Our JudgeLM is efficient and the JudgeLM-7B only needs 3 minutes to judge 5K samples with 8 A100 GPUs.","meta":{"url":"http://arxiv.org/abs/2310.17631v1"},"cats":{"benchmark":0.6472891005,"new-dataset":0.1651968591,"data-annotation":0.5007704014,"dev-research":0.1116554882,"llms":0.541835544,"data-quality":0.1277829175}}
{"text":"JudgeLM obtains high agreement with the teacher judge, achieving an agreement exceeding 90% that even surpasses human-to-human agreement.","meta":{"url":"http://arxiv.org/abs/2310.17631v1"},"cats":{"benchmark":0.4585760675,"new-dataset":0.090753862,"data-annotation":0.4907841074,"dev-research":0.1992737746,"llms":0.5902994358,"data-quality":0.197589504}}
{"text":"JudgeLM also demonstrates extended capabilities in being judges of the single answer, multimodal models, multiple answers, and multi-turn chat.","meta":{"url":"http://arxiv.org/abs/2310.17631v1"},"cats":{"benchmark":0.3465771553,"new-dataset":0.1418555109,"data-annotation":0.5180646302,"dev-research":0.1716922896,"llms":0.6009492621,"data-quality":0.0667710506}}
{"text":"Instruction-based language modeling has received significant attention in pretrained language models.","meta":{"url":"http://arxiv.org/abs/2310.17630v1"},"cats":{"benchmark":0.1874208176,"new-dataset":0.0600014458,"data-annotation":0.5474428577,"dev-research":0.2658724447,"llms":0.5860836214,"data-quality":0.1546148235}}
{"text":"However, the efficiency of instruction engineering remains low and hinders the development of instruction studies.","meta":{"url":"http://arxiv.org/abs/2310.17630v1"},"cats":{"benchmark":0.2991798453,"new-dataset":0.0039067946,"data-annotation":0.5319423586,"dev-research":0.3390462422,"llms":0.5992043607,"data-quality":0.1087072696}}
{"text":"Recent studies have focused on automating instruction generation, but they primarily aim to improve performance without considering other crucial objectives that impact instruction quality, such as instruction length and perplexity.","meta":{"url":"http://arxiv.org/abs/2310.17630v1"},"cats":{"benchmark":0.2693306245,"new-dataset":0.0200796893,"data-annotation":0.5332456097,"dev-research":0.3917116604,"llms":0.629513165,"data-quality":0.1012932996}}
{"text":"Therefore, we propose a novel approach (i.e., InstOptima) that treats instruction generation as an evolutionary multi-objective optimization problem.","meta":{"url":"http://arxiv.org/abs/2310.17630v1"},"cats":{"benchmark":0.3516229208,"new-dataset":0.032474984,"data-annotation":0.5409949081,"dev-research":0.2757306906,"llms":0.5292096403,"data-quality":0.0852854235}}
{"text":"In contrast to text edition-based methods, our approach utilizes a large language model (LLM) to simulate instruction operators, including mutation and crossover.","meta":{"url":"http://arxiv.org/abs/2310.17630v1"},"cats":{"benchmark":0.2985576517,"new-dataset":0.049612233,"data-annotation":0.545063244,"dev-research":0.2133328685,"llms":0.6859125609,"data-quality":0.1346731309}}
{"text":"Furthermore, we introduce an objective-guided mechanism for these operators, allowing the LLM to comprehend the objectives and enhance the quality of the generated instructions.","meta":{"url":"http://arxiv.org/abs/2310.17630v1"},"cats":{"benchmark":0.2540912267,"new-dataset":0.0090069996,"data-annotation":0.5135994906,"dev-research":0.2537657429,"llms":0.6785163517,"data-quality":0.0701170616}}
{"text":"Experimental results demonstrate improved fine-tuning performance and the generation of a diverse set of high-quality instructions.","meta":{"url":"http://arxiv.org/abs/2310.17630v1"},"cats":{"benchmark":0.4138717826,"new-dataset":0.0710860031,"data-annotation":0.509624606,"dev-research":0.3104331716,"llms":0.618521144,"data-quality":0.1267191357}}
{"text":"The emergence of Deep Neural Networks (DNNs) has revolutionized various domains, enabling the resolution of complex tasks spanning image recognition, natural language processing, and scientific problem-solving.","meta":{"url":"http://arxiv.org/abs/2310.17626v1"},"cats":{"benchmark":0.2085043746,"new-dataset":0.1771506195,"data-annotation":0.5190702385,"dev-research":0.2482436585,"llms":0.4754642382,"data-quality":0.1155681292}}
{"text":"However, this progress has also exposed a concerning vulnerability: adversarial examples.","meta":{"url":"http://arxiv.org/abs/2310.17626v1"},"cats":{"benchmark":0.2433869909,"new-dataset":0.0406426031,"data-annotation":0.5401168649,"dev-research":0.2684294124,"llms":0.4982292231,"data-quality":0.2600083672}}
{"text":"These crafted inputs, imperceptible to humans, can manipulate machine learning models into making erroneous predictions, raising concerns for safety-critical applications.","meta":{"url":"http://arxiv.org/abs/2310.17626v1"},"cats":{"benchmark":0.1844363736,"new-dataset":0.0328683757,"data-annotation":0.5241252248,"dev-research":0.4029594384,"llms":0.4559363564,"data-quality":0.2648946444}}
{"text":"An intriguing property of this phenomenon is the transferability of adversarial examples, where perturbations crafted for one model can deceive another, often with a different architecture.","meta":{"url":"http://arxiv.org/abs/2310.17626v1"},"cats":{"benchmark":0.254584917,"new-dataset":0.0027113367,"data-annotation":0.5429112353,"dev-research":0.1718689989,"llms":0.5031385776,"data-quality":0.2077070402}}
{"text":"This intriguing property enables \"black-box\" attacks, circumventing the need for detailed knowledge of the target model.","meta":{"url":"http://arxiv.org/abs/2310.17626v1"},"cats":{"benchmark":0.2114928546,"new-dataset":0.007723346,"data-annotation":0.5243755516,"dev-research":0.1570151648,"llms":0.4693093694,"data-quality":0.1531114247}}
{"text":"This survey explores the landscape of the adversarial transferability of adversarial examples.","meta":{"url":"http://arxiv.org/abs/2310.17626v1"},"cats":{"benchmark":0.2722255127,"new-dataset":0.0481877845,"data-annotation":0.5398860742,"dev-research":0.1698726684,"llms":0.5110107548,"data-quality":0.2489800604}}
{"text":"We categorize existing methodologies to enhance adversarial transferability and discuss the fundamental principles guiding each approach.","meta":{"url":"http://arxiv.org/abs/2310.17626v1"},"cats":{"benchmark":0.2612687786,"new-dataset":0.018364464,"data-annotation":0.5263827197,"dev-research":0.2032884501,"llms":0.4641104711,"data-quality":0.2238088673}}
{"text":"While the predominant body of research primarily concentrates on image classification, we also extend our discussion to encompass other vision tasks and beyond.","meta":{"url":"http://arxiv.org/abs/2310.17626v1"},"cats":{"benchmark":0.2775560193,"new-dataset":0.0890772173,"data-annotation":0.5326509127,"dev-research":0.2242273144,"llms":0.4918156909,"data-quality":0.1796089897}}
{"text":"Challenges and future prospects are discussed, highlighting the importance of fortifying DNNs against adversarial vulnerabilities in an evolving landscape.","meta":{"url":"http://arxiv.org/abs/2310.17626v1"},"cats":{"benchmark":0.1840834645,"new-dataset":0.1655074151,"data-annotation":0.5200273559,"dev-research":0.3401028166,"llms":0.5616097941,"data-quality":0.214151184}}
{"text":"Large language models are trained on vast amounts of internet data, prompting concerns and speculation that they have memorized public benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.17623v1"},"cats":{"benchmark":0.3228249022,"new-dataset":0.1070641302,"data-annotation":0.5352798931,"dev-research":0.2149433803,"llms":0.5631239327,"data-quality":0.192689879}}
{"text":"Going from speculation to proof of contamination is challenging, as the pretraining data used by proprietary models are often not publicly accessible.","meta":{"url":"http://arxiv.org/abs/2310.17623v1"},"cats":{"benchmark":0.2617895907,"new-dataset":0.1413842635,"data-annotation":0.4937051734,"dev-research":0.1751158323,"llms":0.5331258191,"data-quality":0.1678123167}}
{"text":"We show that it is possible to provide provable guarantees of test set contamination in language models without access to pretraining data or model weights.","meta":{"url":"http://arxiv.org/abs/2310.17623v1"},"cats":{"benchmark":0.3417361988,"new-dataset":0.1248958563,"data-annotation":0.5316934602,"dev-research":0.2436879255,"llms":0.5568351759,"data-quality":0.3676754843}}
{"text":"Our approach leverages the fact that when there is no data contamination, all orderings of an exchangeable benchmark should be equally likely.","meta":{"url":"http://arxiv.org/abs/2310.17623v1"},"cats":{"benchmark":0.7321602149,"new-dataset":0.0367341629,"data-annotation":0.4816688437,"dev-research":0.1461146757,"llms":0.4826915586,"data-quality":0.168227989}}
{"text":"In contrast, the tendency for language models to memorize example order means that a contaminated language model will find certain canonical orderings to be much more likely than others.","meta":{"url":"http://arxiv.org/abs/2310.17623v1"},"cats":{"benchmark":0.3285630021,"new-dataset":0.0095334221,"data-annotation":0.5471407755,"dev-research":0.2331236571,"llms":0.5657582534,"data-quality":0.3050542569}}
{"text":"Our test flags potential contamination whenever the likelihood of a canonically ordered benchmark dataset is significantly higher than the likelihood after shuffling the examples.","meta":{"url":"http://arxiv.org/abs/2310.17623v1"},"cats":{"benchmark":0.602564273,"new-dataset":0.190007377,"data-annotation":0.4969458785,"dev-research":0.1666058742,"llms":0.518210478,"data-quality":0.3057024077}}
{"text":"We demonstrate that our procedure is sensitive enough to reliably prove test set contamination in challenging situations, including models as small as 1.4 billion parameters, on small test sets of only 1000 examples, and datasets that appear only a few times in the pretraining corpus.","meta":{"url":"http://arxiv.org/abs/2310.17623v1"},"cats":{"benchmark":0.3871043227,"new-dataset":0.4819485639,"data-annotation":0.5286428598,"dev-research":0.2487325918,"llms":0.5214550369,"data-quality":0.4221301615}}
{"text":"Using our test, we audit five popular publicly accessible language models for test set contamination and find little evidence for pervasive contamination.","meta":{"url":"http://arxiv.org/abs/2310.17623v1"},"cats":{"benchmark":0.303262341,"new-dataset":0.2879005571,"data-annotation":0.5359059439,"dev-research":0.2826825379,"llms":0.6196622524,"data-quality":0.3950233043}}
{"text":"Self-supervised learning (SSL) as an effective paradigm of representation learning has achieved tremendous success on various curated datasets in diverse scenarios.","meta":{"url":"http://arxiv.org/abs/2310.17622v1"},"cats":{"benchmark":0.1694577759,"new-dataset":0.1763141025,"data-annotation":0.4982952806,"dev-research":0.1466288747,"llms":0.5460081483,"data-quality":0.1899715349}}
{"text":"Nevertheless, when facing the long-tailed distribution in real-world applications, it is still hard for existing methods to capture transferable and robust representation.","meta":{"url":"http://arxiv.org/abs/2310.17622v1"},"cats":{"benchmark":0.4452805167,"new-dataset":0.0588672875,"data-annotation":0.5194210636,"dev-research":0.1354348455,"llms":0.4363208713,"data-quality":0.1375689662}}
{"text":"Conventional SSL methods, pursuing sample-level uniformity, easily leads to representation learning disparity where head classes dominate the feature regime but tail classes passively collapse.","meta":{"url":"http://arxiv.org/abs/2310.17622v1"},"cats":{"benchmark":0.3263071153,"new-dataset":0.0087315919,"data-annotation":0.5164952499,"dev-research":0.1213580324,"llms":0.5335679523,"data-quality":0.1474343946}}
{"text":"To address this problem, we propose a novel Geometric Harmonization (GH) method to encourage category-level uniformity in representation learning, which is more benign to the minority and almost does not hurt the majority under long-tailed distribution.","meta":{"url":"http://arxiv.org/abs/2310.17622v1"},"cats":{"benchmark":0.3350894252,"new-dataset":0.0218982842,"data-annotation":0.5366258206,"dev-research":0.1397990957,"llms":0.4250033783,"data-quality":0.1962081208}}
{"text":"Specially, GH measures the population statistics of the embedding space on top of self-supervised learning, and then infer an fine-grained instance-wise calibration to constrain the space expansion of head classes and avoid the passive collapse of tail classes.","meta":{"url":"http://arxiv.org/abs/2310.17622v1"},"cats":{"benchmark":0.2772331806,"new-dataset":0.0453143358,"data-annotation":0.5424218066,"dev-research":0.1086478463,"llms":0.5176621788,"data-quality":0.2123541301}}
{"text":"Our proposal does not alter the setting of SSL and can be easily integrated into existing methods in a low-cost manner.","meta":{"url":"http://arxiv.org/abs/2310.17622v1"},"cats":{"benchmark":0.3841783417,"new-dataset":0.0100182117,"data-annotation":0.4849823648,"dev-research":0.2159202003,"llms":0.6032025127,"data-quality":0.0961632514}}
{"text":"Extensive results on a range of benchmark datasets show the effectiveness of GH with high tolerance to the distribution skewness.","meta":{"url":"http://arxiv.org/abs/2310.17622v1"},"cats":{"benchmark":0.6166195605,"new-dataset":0.0576848236,"data-annotation":0.481946219,"dev-research":0.087878344,"llms":0.4600481144,"data-quality":0.140162829}}
{"text":"Our code is available at https://github.com/MediaBrain-SJTU/Geometric-Harmonization.","meta":{"url":"http://arxiv.org/abs/2310.17622v1"},"cats":{"benchmark":0.3892660653,"new-dataset":0.1134670434,"data-annotation":0.5399392574,"dev-research":0.1210429723,"llms":0.4643492503,"data-quality":0.0978478316}}
{"text":"Off-road robotics have traditionally utilized lidar for local navigation due to its accuracy and high resolution.","meta":{"url":"http://arxiv.org/abs/2310.17620v1"},"cats":{"benchmark":0.358989131,"new-dataset":0.0287554074,"data-annotation":0.4939150858,"dev-research":0.1960036132,"llms":0.5059238593,"data-quality":0.0649423562}}
{"text":"However, the limitations of lidar, such as reduced performance in harsh environmental conditions and limited range, have prompted the exploration of alternative sensing technologies.","meta":{"url":"http://arxiv.org/abs/2310.17620v1"},"cats":{"benchmark":0.3992449692,"new-dataset":0.0081240352,"data-annotation":0.4888110906,"dev-research":0.1839542064,"llms":0.502741656,"data-quality":0.045144287}}
{"text":"This paper investigates the potential of radar for off-road local navigation, as it offers the advantages of a longer range and the ability to penetrate dust and light vegetation.","meta":{"url":"http://arxiv.org/abs/2310.17620v1"},"cats":{"benchmark":0.326279878,"new-dataset":0.0708615313,"data-annotation":0.5164951799,"dev-research":0.2350889441,"llms":0.4951458418,"data-quality":0.0423173768}}
{"text":"We adapt existing lidar-based methods for radar and evaluate the performance in comparison to lidar under various off-road conditions.","meta":{"url":"http://arxiv.org/abs/2310.17620v1"},"cats":{"benchmark":0.5586897131,"new-dataset":0.0283481868,"data-annotation":0.5170880562,"dev-research":0.2208846333,"llms":0.4383795037,"data-quality":0.0628366938}}
{"text":"We show that radar can provide a significant range advantage over lidar while maintaining accuracy for both ground plane estimation and obstacle detection.","meta":{"url":"http://arxiv.org/abs/2310.17620v1"},"cats":{"benchmark":0.472883023,"new-dataset":0.0342016128,"data-annotation":0.520910054,"dev-research":0.1803786437,"llms":0.4537260934,"data-quality":0.0859421459}}
{"text":"And finally, we demonstrate successful autonomous navigation at a speed of 2.5 m/s over a path length of 350 m using only radar for ground plane estimation and obstacle detection.","meta":{"url":"http://arxiv.org/abs/2310.17620v1"},"cats":{"benchmark":0.3497234665,"new-dataset":0.0704163281,"data-annotation":0.5105911981,"dev-research":0.1563910627,"llms":0.483903011,"data-quality":0.0843965463}}
{"text":"Many foundational program verification tools have been developed to build machine-checked program correctness proofs, a majority of which are based on Hoare logic.","meta":{"url":"http://arxiv.org/abs/2310.17616v1"},"cats":{"benchmark":0.4218634315,"new-dataset":0.116128647,"data-annotation":0.5072872873,"dev-research":0.404709814,"llms":0.6134831792,"data-quality":0.1804835218}}
{"text":"Their program logics, their assertion languages, and their underlying programming languages can be formalized by either a shallow embedding or a deep embedding.","meta":{"url":"http://arxiv.org/abs/2310.17616v1"},"cats":{"benchmark":0.2668490127,"new-dataset":0.0379733955,"data-annotation":0.5373574418,"dev-research":0.3701432575,"llms":0.5898863956,"data-quality":0.1335232462}}
{"text":"Tools like Iris and early versions of Verified Software Toolchain (VST) choose different shallow embeddings to formalize their program logics.","meta":{"url":"http://arxiv.org/abs/2310.17616v1"},"cats":{"benchmark":0.3937095384,"new-dataset":0.0391544595,"data-annotation":0.5178634686,"dev-research":0.4590268191,"llms":0.6260163465,"data-quality":0.1731843391}}
{"text":"But the pros and cons of these different embeddings were not yet well studied.","meta":{"url":"http://arxiv.org/abs/2310.17616v1"},"cats":{"benchmark":0.3441414408,"new-dataset":0.0059195575,"data-annotation":0.5360391014,"dev-research":0.1741931764,"llms":0.5957627417,"data-quality":0.1482504946}}
{"text":"Therefore, we want to study the impact of the program logic's embedding on logic's proof rules in this paper.","meta":{"url":"http://arxiv.org/abs/2310.17616v1"},"cats":{"benchmark":0.3619608587,"new-dataset":0.0408636417,"data-annotation":0.5200350467,"dev-research":0.3671295632,"llms":0.5900388908,"data-quality":0.1243006261}}
{"text":"This paper considers a set of useful extended proof rules, and four different logic embeddings: one deep embedding and three common shallow embeddings.","meta":{"url":"http://arxiv.org/abs/2310.17616v1"},"cats":{"benchmark":0.348628197,"new-dataset":0.0506839865,"data-annotation":0.5194812201,"dev-research":0.2120180184,"llms":0.5561405758,"data-quality":0.1339315795}}
{"text":"We prove the validity of these extended rules under these embeddings and discuss their main challenges.","meta":{"url":"http://arxiv.org/abs/2310.17616v1"},"cats":{"benchmark":0.4076596392,"new-dataset":0.0239587543,"data-annotation":0.5283554804,"dev-research":0.1837012406,"llms":0.5139775831,"data-quality":0.2615053354}}
{"text":"Furthermore, we propose a method to lift existing shallowly embedded logics to deeply embedded ones to greatly simplify proofs of extended rules in specific proof systems.","meta":{"url":"http://arxiv.org/abs/2310.17616v1"},"cats":{"benchmark":0.403373859,"new-dataset":0.0294438932,"data-annotation":0.5135096265,"dev-research":0.2567103839,"llms":0.5727035293,"data-quality":0.1398708615}}
{"text":"We evaluate our results on two existing verification tools.","meta":{"url":"http://arxiv.org/abs/2310.17616v1"},"cats":{"benchmark":0.6862664498,"new-dataset":0.1298143186,"data-annotation":0.5112784594,"dev-research":0.2333438974,"llms":0.5815462403,"data-quality":0.2852417015}}
{"text":"We lift the originally shallowly embedded VST to our deeply embedded VST to support extended rules, and we implement Iris-CF and deeply embedded Iris-Imp based on the Iris framework to evaluate our theory in real verification projects.","meta":{"url":"http://arxiv.org/abs/2310.17616v1"},"cats":{"benchmark":0.2965431922,"new-dataset":0.0742870001,"data-annotation":0.5042188309,"dev-research":0.2613686042,"llms":0.5204217115,"data-quality":0.1035901026}}
{"text":"Machine learning tools often rely on embedding text as vectors of real numbers.","meta":{"url":"http://arxiv.org/abs/2310.17611v1"},"cats":{"benchmark":0.3332204322,"new-dataset":0.0474556366,"data-annotation":0.5381089718,"dev-research":0.2300642568,"llms":0.4273296868,"data-quality":0.2700609596}}
{"text":"In this paper, we study how the semantic structure of language is encoded in the algebraic structure of such embeddings.","meta":{"url":"http://arxiv.org/abs/2310.17611v1"},"cats":{"benchmark":0.2150801131,"new-dataset":0.0503543506,"data-annotation":0.5432666598,"dev-research":0.1927931052,"llms":0.4858748211,"data-quality":0.2024302584}}
{"text":"Specifically, we look at a notion of ``semantic independence'' capturing the idea that, e.g., ``eggplant'' and ``tomato'' are independent given ``vegetable''.","meta":{"url":"http://arxiv.org/abs/2310.17611v1"},"cats":{"benchmark":0.1850482755,"new-dataset":0.0760936258,"data-annotation":0.5147543958,"dev-research":0.2272673973,"llms":0.5318381981,"data-quality":0.2893860536}}
{"text":"Although such examples are intuitive, it is difficult to formalize such a notion of semantic independence.","meta":{"url":"http://arxiv.org/abs/2310.17611v1"},"cats":{"benchmark":0.2553672958,"new-dataset":0.0095223129,"data-annotation":0.5193604145,"dev-research":0.2305287224,"llms":0.5604937665,"data-quality":0.2761442691}}
{"text":"The key observation here is that any sensible formalization should obey a set of so-called independence axioms, and thus any algebraic encoding of this structure should also obey these axioms.","meta":{"url":"http://arxiv.org/abs/2310.17611v1"},"cats":{"benchmark":0.2607682602,"new-dataset":0.0037924142,"data-annotation":0.5080330246,"dev-research":0.2401708225,"llms":0.5016671527,"data-quality":0.1463820148}}
{"text":"This leads us naturally to use partial orthogonality as the relevant algebraic structure.","meta":{"url":"http://arxiv.org/abs/2310.17611v1"},"cats":{"benchmark":0.3615303385,"new-dataset":0.0063238195,"data-annotation":0.5335995042,"dev-research":0.1546793587,"llms":0.4312275223,"data-quality":0.1020375313}}
{"text":"We develop theory and methods that allow us to demonstrate that partial orthogonality does indeed capture semantic independence.","meta":{"url":"http://arxiv.org/abs/2310.17611v1"},"cats":{"benchmark":0.3255459697,"new-dataset":0.0131995931,"data-annotation":0.5338531971,"dev-research":0.1706574287,"llms":0.4975379794,"data-quality":0.3191999279}}
{"text":"Complementary to this, we also introduce the concept of independence preserving embeddings where embeddings preserve the conditional independence structures of a distribution, and we prove the existence of such embeddings and approximations to them.","meta":{"url":"http://arxiv.org/abs/2310.17611v1"},"cats":{"benchmark":0.3142274111,"new-dataset":0.0933377841,"data-annotation":0.5263505432,"dev-research":0.1687022304,"llms":0.504646639,"data-quality":0.2280405977}}
{"text":"As an important component of intelligent legal systems, legal case retrieval plays a critical role in ensuring judicial justice and fairness.","meta":{"url":"http://arxiv.org/abs/2310.17609v1"},"cats":{"benchmark":0.3918541578,"new-dataset":0.0603750491,"data-annotation":0.4919353661,"dev-research":0.1764655461,"llms":0.5973499983,"data-quality":0.1692022212}}
{"text":"However, the development of legal case retrieval technologies in the Chinese legal system is restricted by three problems in existing datasets: limited data size, narrow definitions of legal relevance, and naive candidate pooling strategies used in data sampling.","meta":{"url":"http://arxiv.org/abs/2310.17609v1"},"cats":{"benchmark":0.3658708588,"new-dataset":0.3357388412,"data-annotation":0.4935071818,"dev-research":0.1596800542,"llms":0.5497578153,"data-quality":0.1936335867}}
{"text":"To alleviate these issues, we introduce LeCaRDv2, a large-scale Legal Case Retrieval Dataset (version 2).","meta":{"url":"http://arxiv.org/abs/2310.17609v1"},"cats":{"benchmark":0.3402874935,"new-dataset":0.8531124071,"data-annotation":0.5088567065,"dev-research":0.161541395,"llms":0.5680084429,"data-quality":0.1565501717}}
{"text":"It consists of 800 queries and 55,192 candidates extracted from 4.3 million criminal case documents.","meta":{"url":"http://arxiv.org/abs/2310.17609v1"},"cats":{"benchmark":0.3391639837,"new-dataset":0.6744111986,"data-annotation":0.5140929972,"dev-research":0.1542716917,"llms":0.5334531722,"data-quality":0.0787962894}}
{"text":"To the best of our knowledge, LeCaRDv2 is one of the largest Chinese legal case retrieval datasets, providing extensive coverage of criminal charges.","meta":{"url":"http://arxiv.org/abs/2310.17609v1"},"cats":{"benchmark":0.3679022749,"new-dataset":0.8397966603,"data-annotation":0.5208677195,"dev-research":0.1542419457,"llms":0.5867822835,"data-quality":0.1303970617}}
{"text":"Additionally, we enrich the existing relevance criteria by considering three key aspects: characterization, penalty, procedure.","meta":{"url":"http://arxiv.org/abs/2310.17609v1"},"cats":{"benchmark":0.5582181993,"new-dataset":0.0047102557,"data-annotation":0.5240621133,"dev-research":0.2021963793,"llms":0.4393711703,"data-quality":0.1725048627}}
{"text":"This comprehensive criteria enriches the dataset and may provides a more holistic perspective.","meta":{"url":"http://arxiv.org/abs/2310.17609v1"},"cats":{"benchmark":0.504798188,"new-dataset":0.3151022885,"data-annotation":0.4997050543,"dev-research":0.1369898044,"llms":0.3872976099,"data-quality":0.0880375525}}
{"text":"Furthermore, we propose a two-level candidate set pooling strategy that effectively identify potential candidates for each query case.","meta":{"url":"http://arxiv.org/abs/2310.17609v1"},"cats":{"benchmark":0.5113614209,"new-dataset":0.0537482981,"data-annotation":0.5060383159,"dev-research":0.1422863287,"llms":0.511936334,"data-quality":0.1622709416}}
{"text":"It's important to note that all cases in the dataset have been annotated by multiple legal experts specializing in criminal law.","meta":{"url":"http://arxiv.org/abs/2310.17609v1"},"cats":{"benchmark":0.3280686971,"new-dataset":0.6481038109,"data-annotation":0.5193118199,"dev-research":0.2537757217,"llms":0.5136081078,"data-quality":0.2501786683}}
{"text":"Their expertise ensures the accuracy and reliability of the annotations.","meta":{"url":"http://arxiv.org/abs/2310.17609v1"},"cats":{"benchmark":0.3558022313,"new-dataset":0.1504278305,"data-annotation":0.5560836913,"dev-research":0.3450979024,"llms":0.6151397028,"data-quality":0.5832197818}}
{"text":"We evaluate several state-of-the-art retrieval models at LeCaRDv2, demonstrating that there is still significant room for improvement in legal case retrieval.","meta":{"url":"http://arxiv.org/abs/2310.17609v1"},"cats":{"benchmark":0.407514435,"new-dataset":0.1847613058,"data-annotation":0.5033721922,"dev-research":0.1463591976,"llms":0.6061967675,"data-quality":0.1575238645}}
{"text":"The details of LeCaRDv2 can be found at the anonymous website https://github.com/anonymous1113243/LeCaRDv2.","meta":{"url":"http://arxiv.org/abs/2310.17609v1"},"cats":{"benchmark":0.2469990755,"new-dataset":0.4000003898,"data-annotation":0.527891218,"dev-research":0.1368445001,"llms":0.6028652597,"data-quality":0.1158474359}}
{"text":"This paper reports on a set of three recent experiments utilizing large-scale speech models to evaluate the oral reading fluency (ORF) of students in Ghana.","meta":{"url":"http://arxiv.org/abs/2310.17606v1"},"cats":{"benchmark":0.3418106549,"new-dataset":0.1642173696,"data-annotation":0.5331595319,"dev-research":0.133918899,"llms":0.5380489214,"data-quality":0.150502944}}
{"text":"While ORF is a well-established measure of foundational literacy, assessing it typically requires one-on-one sessions between a student and a trained evaluator, a process that is time-consuming and costly.","meta":{"url":"http://arxiv.org/abs/2310.17606v1"},"cats":{"benchmark":0.3442858823,"new-dataset":0.0334756919,"data-annotation":0.5323658909,"dev-research":0.2238015069,"llms":0.5212627862,"data-quality":0.1302590575}}
{"text":"Automating the evaluation of ORF could support better literacy instruction, particularly in education contexts where formative assessment is uncommon due to large class sizes and limited resources.","meta":{"url":"http://arxiv.org/abs/2310.17606v1"},"cats":{"benchmark":0.3269817063,"new-dataset":0.0251607534,"data-annotation":0.5434813046,"dev-research":0.2318757704,"llms":0.5614109394,"data-quality":0.1878614799}}
{"text":"To our knowledge, this research is among the first to examine the use of the most recent versions of large-scale speech models (Whisper V2 wav2vec2.0) for ORF assessment in the Global South.   ","meta":{"url":"http://arxiv.org/abs/2310.17606v1"},"cats":{"benchmark":0.3840758947,"new-dataset":0.1581585814,"data-annotation":0.5393072514,"dev-research":0.1518791216,"llms":0.5172191595,"data-quality":0.1303615522}}
{"text":"We find that Whisper V2 produces transcriptions of Ghanaian students reading aloud with a Word Error Rate of 13.5.","meta":{"url":"http://arxiv.org/abs/2310.17606v1"},"cats":{"benchmark":0.2418580125,"new-dataset":0.2252240549,"data-annotation":0.5332418575,"dev-research":0.2003466704,"llms":0.5678276015,"data-quality":0.3123161918}}
{"text":"This is close to the model's average WER on adult speech (12.8) and would have been considered state-of-the-art for children's speech transcription only a few years ago.","meta":{"url":"http://arxiv.org/abs/2310.17606v1"},"cats":{"benchmark":0.4033687184,"new-dataset":0.1170954668,"data-annotation":0.5326733248,"dev-research":0.1241611731,"llms":0.5253118312,"data-quality":0.1662974372}}
{"text":"We also find that when these transcriptions are used to produce fully automated ORF scores, they closely align with scores generated by expert human graders, with a correlation coefficient of 0.96.","meta":{"url":"http://arxiv.org/abs/2310.17606v1"},"cats":{"benchmark":0.4541868941,"new-dataset":0.125779466,"data-annotation":0.5374850096,"dev-research":0.1638253061,"llms":0.465928922,"data-quality":0.248379624}}
{"text":"Importantly, these results were achieved on a representative dataset (i.e., students with regional accents, recordings taken in actual classrooms), using a free and publicly available speech model out of the box (i.e., no fine-tuning).","meta":{"url":"http://arxiv.org/abs/2310.17606v1"},"cats":{"benchmark":0.3256772576,"new-dataset":0.3764024807,"data-annotation":0.5447883931,"dev-research":0.1232380382,"llms":0.5195258308,"data-quality":0.1914072919}}
{"text":"This suggests that using large-scale speech models to assess ORF may be feasible to implement and scale in lower-resource, linguistically diverse educational contexts.","meta":{"url":"http://arxiv.org/abs/2310.17606v1"},"cats":{"benchmark":0.3442973706,"new-dataset":0.0386817804,"data-annotation":0.538998795,"dev-research":0.1385018258,"llms":0.5257677933,"data-quality":0.1386976505}}
{"text":"Imitation learning from a large set of human demonstrations has proved to be an effective paradigm for building capable robot agents.","meta":{"url":"http://arxiv.org/abs/2310.17596v1"},"cats":{"benchmark":0.1857766491,"new-dataset":0.0791577514,"data-annotation":0.5201302189,"dev-research":0.1794809297,"llms":0.5128314163,"data-quality":0.0525476759}}
{"text":"However, the demonstrations can be extremely costly and time-consuming to collect.","meta":{"url":"http://arxiv.org/abs/2310.17596v1"},"cats":{"benchmark":0.2266875316,"new-dataset":0.0425772382,"data-annotation":0.51862319,"dev-research":0.2215902791,"llms":0.5582967127,"data-quality":0.0467186933}}
{"text":"We introduce MimicGen, a system for automatically synthesizing large-scale, rich datasets from only a small number of human demonstrations by adapting them to new contexts.","meta":{"url":"http://arxiv.org/abs/2310.17596v1"},"cats":{"benchmark":0.1717591937,"new-dataset":0.6995781489,"data-annotation":0.5140155234,"dev-research":0.2603976144,"llms":0.5202995353,"data-quality":0.1038474157}}
{"text":"We use MimicGen to generate over 50K demonstrations across 18 tasks with diverse scene configurations, object instances, and robot arms from just ~200 human demonstrations.","meta":{"url":"http://arxiv.org/abs/2310.17596v1"},"cats":{"benchmark":0.2134875492,"new-dataset":0.5377381941,"data-annotation":0.5132408249,"dev-research":0.2386004036,"llms":0.5791708727,"data-quality":0.0618054528}}
{"text":"We show that robot agents can be effectively trained on this generated dataset by imitation learning to achieve strong performance in long-horizon and high-precision tasks, such as multi-part assembly and coffee preparation, across broad initial state distributions.","meta":{"url":"http://arxiv.org/abs/2310.17596v1"},"cats":{"benchmark":0.2326510596,"new-dataset":0.3094949181,"data-annotation":0.514822333,"dev-research":0.1269552843,"llms":0.4819008613,"data-quality":0.0827491871}}
{"text":"We further demonstrate that the effectiveness and utility of MimicGen data compare favorably to collecting additional human demonstrations, making it a powerful and economical approach towards scaling up robot learning.","meta":{"url":"http://arxiv.org/abs/2310.17596v1"},"cats":{"benchmark":0.233432226,"new-dataset":0.1185462943,"data-annotation":0.501648137,"dev-research":0.1874309497,"llms":0.5067633702,"data-quality":0.0812546707}}
{"text":"Datasets, simulation environments, videos, and more at https://mimicgen.github.io .","meta":{"url":"http://arxiv.org/abs/2310.17596v1"},"cats":{"benchmark":0.2199705577,"new-dataset":0.8291852399,"data-annotation":0.4888306148,"dev-research":0.2101784077,"llms":0.5534989269,"data-quality":0.0814492646}}
{"text":"Unsupervised domain adaptation (UDA) is a pivotal form in machine learning to extend the in-domain model to the distinctive target domains where the data distributions differ.","meta":{"url":"http://arxiv.org/abs/2310.17594v1"},"cats":{"benchmark":0.334038462,"new-dataset":0.0869830545,"data-annotation":0.482963895,"dev-research":0.1917507463,"llms":0.5012205007,"data-quality":0.160083646}}
{"text":"Most prior works focus on capturing the inter-domain transferability but largely overlook rich intra-domain structures, which empirically results in even worse discriminability.","meta":{"url":"http://arxiv.org/abs/2310.17594v1"},"cats":{"benchmark":0.4368099935,"new-dataset":0.0112474152,"data-annotation":0.5100614457,"dev-research":0.1312889229,"llms":0.4945191695,"data-quality":0.223454413}}
{"text":"In this work, we introduce a novel graph SPectral Alignment (SPA) framework to tackle the tradeoff.","meta":{"url":"http://arxiv.org/abs/2310.17594v1"},"cats":{"benchmark":0.5213662373,"new-dataset":0.1449629715,"data-annotation":0.499094142,"dev-research":0.1878148679,"llms":0.4518856913,"data-quality":0.2619630238}}
{"text":"The core of our method is briefly condensed as follows: (i)-by casting the DA problem to graph primitives, SPA composes a coarse graph alignment mechanism with a novel spectral regularizer towards aligning the domain graphs in eigenspaces; (ii)-we further develop a fine-grained message propagation module -- upon a novel neighbor-aware self-training mechanism -- in order for enhanced discriminability in the target domain.","meta":{"url":"http://arxiv.org/abs/2310.17594v1"},"cats":{"benchmark":0.3487964833,"new-dataset":0.0965803167,"data-annotation":0.5225396224,"dev-research":0.187439266,"llms":0.5508410581,"data-quality":0.3478555853}}
{"text":"On standardized benchmarks, the extensive experiments of SPA demonstrate that its performance has surpassed the existing cutting-edge DA methods.","meta":{"url":"http://arxiv.org/abs/2310.17594v1"},"cats":{"benchmark":0.7561686351,"new-dataset":0.0099205067,"data-annotation":0.4980212708,"dev-research":0.1694973899,"llms":0.5401292298,"data-quality":0.1412586859}}
{"text":"Coupled with dense model analysis, we conclude that our approach indeed possesses superior efficacy, robustness, discriminability, and transferability.","meta":{"url":"http://arxiv.org/abs/2310.17594v1"},"cats":{"benchmark":0.5208436549,"new-dataset":0.0112036229,"data-annotation":0.5038706779,"dev-research":0.1208331566,"llms":0.3873179382,"data-quality":0.1588810087}}
{"text":"Code and data are available at: https://github.com/CrownX/SPA.","meta":{"url":"http://arxiv.org/abs/2310.17594v1"},"cats":{"benchmark":0.2837536281,"new-dataset":0.5482720466,"data-annotation":0.4908393594,"dev-research":0.1571939936,"llms":0.5674703173,"data-quality":0.1176152742}}
{"text":"We present Lil-Bevo, our submission to the BabyLM Challenge.","meta":{"url":"http://arxiv.org/abs/2310.17591v1"},"cats":{"benchmark":0.2680905752,"new-dataset":0.3815429143,"data-annotation":0.5262164143,"dev-research":0.1238498757,"llms":0.5440139827,"data-quality":0.132315835}}
{"text":"We pretrained our masked language models with three ingredients: an initial pretraining with music data, training on shorter sequences before training on longer ones, and masking specific tokens to target some of the BLiMP subtasks.","meta":{"url":"http://arxiv.org/abs/2310.17591v1"},"cats":{"benchmark":0.1964386897,"new-dataset":0.1610364619,"data-annotation":0.5345426028,"dev-research":0.145406736,"llms":0.4905872273,"data-quality":0.2188281241}}
{"text":"Overall, our baseline models performed above chance, but far below the performance levels of larger LLMs trained on more data.","meta":{"url":"http://arxiv.org/abs/2310.17591v1"},"cats":{"benchmark":0.534252687,"new-dataset":0.0291790917,"data-annotation":0.5077613696,"dev-research":0.0800248303,"llms":0.7035326698,"data-quality":0.0850479611}}
{"text":"We found that training on short sequences performed better than training on longer sequences.","meta":{"url":"http://arxiv.org/abs/2310.17591v1"},"cats":{"benchmark":0.4297464695,"new-dataset":0.0317802427,"data-annotation":0.5454243272,"dev-research":0.1981912752,"llms":0.4956802875,"data-quality":0.1348834954}}
{"text":"Pretraining on music may help performance marginally, but, if so, the effect seems small.","meta":{"url":"http://arxiv.org/abs/2310.17591v1"},"cats":{"benchmark":0.4064182413,"new-dataset":0.0052322347,"data-annotation":0.524461018,"dev-research":0.2234016916,"llms":0.473166306,"data-quality":0.1332498566}}
{"text":"Our targeted Masked Language Modeling augmentation did not seem to improve model performance in general, but did seem to help on some of the specific BLiMP tasks that we were targeting (e.g., Negative Polarity Items).","meta":{"url":"http://arxiv.org/abs/2310.17591v1"},"cats":{"benchmark":0.3910348456,"new-dataset":0.0111547173,"data-annotation":0.5355753924,"dev-research":0.1794176369,"llms":0.5358063414,"data-quality":0.2672540228}}
{"text":"Training performant LLMs on small amounts of data is a difficult but potentially informative task.","meta":{"url":"http://arxiv.org/abs/2310.17591v1"},"cats":{"benchmark":0.2676423605,"new-dataset":0.0319256586,"data-annotation":0.5049100707,"dev-research":0.1109207473,"llms":0.7177714061,"data-quality":0.1472201902}}
{"text":"While some of our techniques showed some promise, more work is needed to explore whether they can improve performance more than the modest gains here.","meta":{"url":"http://arxiv.org/abs/2310.17591v1"},"cats":{"benchmark":0.5175216478,"new-dataset":0.0022983952,"data-annotation":0.5278864447,"dev-research":0.2807933854,"llms":0.5190125619,"data-quality":0.0755474263}}
{"text":"Our code is available at https://github.com/venkatasg/Lil-Bevo and out models at https://huggingface.co/collections/venkatasg/babylm-653591cdb66f4bf68922873a","meta":{"url":"http://arxiv.org/abs/2310.17591v1"},"cats":{"benchmark":0.2184027392,"new-dataset":0.3997801406,"data-annotation":0.5361995845,"dev-research":0.1199066058,"llms":0.5335881399,"data-quality":0.0644192963}}
{"text":"Score Distillation Sampling (SDS) has emerged as the de facto approach for text-to-content generation in non-image domains.","meta":{"url":"http://arxiv.org/abs/2310.17590v1"},"cats":{"benchmark":0.3751317926,"new-dataset":0.0817848897,"data-annotation":0.4989205207,"dev-research":0.1606662498,"llms":0.5905412883,"data-quality":0.266551806}}
{"text":"In this paper, we reexamine the SDS process and introduce a straightforward interpretation that demystifies the necessity for large Classifier-Free Guidance (CFG) scales, rooted in the distillation of an undesired noise term.","meta":{"url":"http://arxiv.org/abs/2310.17590v1"},"cats":{"benchmark":0.3802583489,"new-dataset":0.0471882907,"data-annotation":0.5067547836,"dev-research":0.2023762821,"llms":0.4559752922,"data-quality":0.239884314}}
{"text":"Building upon our interpretation, we propose a novel Noise-Free Score Distillation (NFSD) process, which requires minimal modifications to the original SDS framework.","meta":{"url":"http://arxiv.org/abs/2310.17590v1"},"cats":{"benchmark":0.5176721204,"new-dataset":0.0541269923,"data-annotation":0.4857478545,"dev-research":0.2018923731,"llms":0.4819034006,"data-quality":0.2435742109}}
{"text":"Through this streamlined design, we achieve more effective distillation of pre-trained text-to-image diffusion models while using a nominal CFG scale.","meta":{"url":"http://arxiv.org/abs/2310.17590v1"},"cats":{"benchmark":0.3405349753,"new-dataset":0.0393133436,"data-annotation":0.5022159957,"dev-research":0.1146581738,"llms":0.5016149167,"data-quality":0.1472049563}}
{"text":"This strategic choice allows us to prevent the over-smoothing of results, ensuring that the generated data is both realistic and complies with the desired prompt.","meta":{"url":"http://arxiv.org/abs/2310.17590v1"},"cats":{"benchmark":0.3840949154,"new-dataset":0.0272559986,"data-annotation":0.4602205659,"dev-research":0.2208069726,"llms":0.4667898491,"data-quality":0.102612956}}
{"text":"To demonstrate the efficacy of NFSD, we provide qualitative examples that compare NFSD and SDS, as well as several other methods.","meta":{"url":"http://arxiv.org/abs/2310.17590v1"},"cats":{"benchmark":0.4563388372,"new-dataset":0.0231186139,"data-annotation":0.4743102768,"dev-research":0.2421130192,"llms":0.5128575136,"data-quality":0.1190066188}}
{"text":"Data contamination in language model evaluation is increasingly prevalent as the popularity of large language models.","meta":{"url":"http://arxiv.org/abs/2310.17589v1"},"cats":{"benchmark":0.3158089581,"new-dataset":0.1112729825,"data-annotation":0.5302000595,"dev-research":0.2721905223,"llms":0.5172719561,"data-quality":0.4932987661}}
{"text":"It allows models to \"cheat\" via memorisation instead of displaying true capabilities.","meta":{"url":"http://arxiv.org/abs/2310.17589v1"},"cats":{"benchmark":0.1748188708,"new-dataset":0.0048815266,"data-annotation":0.4912879104,"dev-research":0.2514411029,"llms":0.5871032061,"data-quality":0.0763850493}}
{"text":"Therefore, contamination analysis has became an crucial part of reliable model evaluation to validate results.","meta":{"url":"http://arxiv.org/abs/2310.17589v1"},"cats":{"benchmark":0.5063871785,"new-dataset":0.0296861036,"data-annotation":0.507824908,"dev-research":0.267715297,"llms":0.4683481042,"data-quality":0.2493965247}}
{"text":"However, existing contamination analysis is usually conducted internally by LLM developers and often lacks transparency and completeness.","meta":{"url":"http://arxiv.org/abs/2310.17589v1"},"cats":{"benchmark":0.283638625,"new-dataset":0.088839634,"data-annotation":0.4988553907,"dev-research":0.324934086,"llms":0.7309909454,"data-quality":0.2805720422}}
{"text":"This paper present an open source data contamination reports for the Llama series models.","meta":{"url":"http://arxiv.org/abs/2310.17589v1"},"cats":{"benchmark":0.3088851451,"new-dataset":0.3615994147,"data-annotation":0.4777096789,"dev-research":0.1077497402,"llms":0.6577407874,"data-quality":0.1436966173}}
{"text":"We analyse six popular multi-choice QA benchmarks and quantify their overlapping with the training set of Llama.","meta":{"url":"http://arxiv.org/abs/2310.17589v1"},"cats":{"benchmark":0.588727999,"new-dataset":0.0888564002,"data-annotation":0.5279998314,"dev-research":0.1225442904,"llms":0.5720781021,"data-quality":0.0919306374}}
{"text":"Various levels of contamination ranging from 1\\% to 8.7\\% are found across benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.17589v1"},"cats":{"benchmark":0.6089951357,"new-dataset":0.279749114,"data-annotation":0.5159426966,"dev-research":0.1663972499,"llms":0.4730440561,"data-quality":0.1933725747}}
{"text":"Our comparison also reveals that Llama models can gain over 5\\% higher accuracy on contaminated subsets versus clean subsets.","meta":{"url":"http://arxiv.org/abs/2310.17589v1"},"cats":{"benchmark":0.5027608288,"new-dataset":0.037440827,"data-annotation":0.5300975197,"dev-research":0.1223929494,"llms":0.6219353397,"data-quality":0.2241696116}}
{"text":"Data and code are available at: https://github.com/liyucheng09/Contamination_Detector.","meta":{"url":"http://arxiv.org/abs/2310.17589v1"},"cats":{"benchmark":0.2945354152,"new-dataset":0.857861817,"data-annotation":0.5094150469,"dev-research":0.1425662565,"llms":0.5603431385,"data-quality":0.1963840848}}
{"text":"Fine-tuning pretrained language models (PLMs) for downstream tasks is a large-scale optimization problem, in which the choice of the training algorithm critically determines how well the trained model can generalize to unseen test data, especially in the context of few-shot learning.","meta":{"url":"http://arxiv.org/abs/2310.17588v1"},"cats":{"benchmark":0.2794412421,"new-dataset":0.0468171566,"data-annotation":0.5257236064,"dev-research":0.1655567661,"llms":0.6212199257,"data-quality":0.1808003653}}
{"text":"To achieve good generalization performance and avoid overfitting, techniques such as data augmentation and pruning are often applied.","meta":{"url":"http://arxiv.org/abs/2310.17588v1"},"cats":{"benchmark":0.525685635,"new-dataset":0.0231545937,"data-annotation":0.5300082795,"dev-research":0.2628236562,"llms":0.416493228,"data-quality":0.2233892089}}
{"text":"However, adding these regularizations necessitates heavy tuning of the hyperparameters of optimization algorithms, such as the popular Adam optimizer.","meta":{"url":"http://arxiv.org/abs/2310.17588v1"},"cats":{"benchmark":0.5158321662,"new-dataset":0.0028777141,"data-annotation":0.5509517193,"dev-research":0.1792111254,"llms":0.3990760163,"data-quality":0.1633120126}}
{"text":"In this paper, we propose a two-stage fine-tuning method, PAC-tuning, to address this optimization challenge.","meta":{"url":"http://arxiv.org/abs/2310.17588v1"},"cats":{"benchmark":0.6099784078,"new-dataset":0.0229905106,"data-annotation":0.5202692153,"dev-research":0.1609104381,"llms":0.419824811,"data-quality":0.1802492124}}
{"text":"First, based on PAC-Bayes training, PAC-tuning directly minimizes the PAC-Bayes generalization bound to learn proper parameter distribution.","meta":{"url":"http://arxiv.org/abs/2310.17588v1"},"cats":{"benchmark":0.4025189432,"new-dataset":0.0075627626,"data-annotation":0.5309576696,"dev-research":0.1222260896,"llms":0.4446686537,"data-quality":0.1519916188}}
{"text":"Second, PAC-tuning modifies the gradient by injecting noise with the variance learned in the first stage into the model parameters during training, resulting in a variant of perturbed gradient descent (PGD).","meta":{"url":"http://arxiv.org/abs/2310.17588v1"},"cats":{"benchmark":0.3834390972,"new-dataset":0.006931636,"data-annotation":0.5114392514,"dev-research":0.1153687001,"llms":0.450573035,"data-quality":0.1971281606}}
{"text":"In the past, the few-shot scenario posed difficulties for PAC-Bayes training because the PAC-Bayes bound, when applied to large models with limited training data, might not be stringent.","meta":{"url":"http://arxiv.org/abs/2310.17588v1"},"cats":{"benchmark":0.2867904892,"new-dataset":0.0264019586,"data-annotation":0.5208116444,"dev-research":0.1189031964,"llms":0.4916675677,"data-quality":0.1547925039}}
{"text":"Our experimental results across 5 GLUE benchmark tasks demonstrate that PAC-tuning successfully handles the challenges of fine-tuning tasks and outperforms strong baseline methods by a visible margin, further confirming the potential to apply PAC training for any other settings where the Adam optimizer is currently used for training.","meta":{"url":"http://arxiv.org/abs/2310.17588v1"},"cats":{"benchmark":0.5560248783,"new-dataset":0.0146847363,"data-annotation":0.516294111,"dev-research":0.1831410999,"llms":0.4790333732,"data-quality":0.1422050216}}
{"text":"Human biases are ubiquitous but not uniform: disparities exist across linguistic, cultural, and societal borders.","meta":{"url":"http://arxiv.org/abs/2310.17586v1"},"cats":{"benchmark":0.338674123,"new-dataset":0.0403988645,"data-annotation":0.5341020484,"dev-research":0.2188808221,"llms":0.5191820856,"data-quality":0.2869111782}}
{"text":"As large amounts of recent literature suggest, language models (LMs) trained on human data can reflect and often amplify the effects of these social biases.","meta":{"url":"http://arxiv.org/abs/2310.17586v1"},"cats":{"benchmark":0.2406263154,"new-dataset":0.0266238513,"data-annotation":0.5391902607,"dev-research":0.1806687659,"llms":0.5624448164,"data-quality":0.280198376}}
{"text":"However, the vast majority of existing studies on bias are heavily skewed towards Western and European languages.","meta":{"url":"http://arxiv.org/abs/2310.17586v1"},"cats":{"benchmark":0.3752690607,"new-dataset":0.0091018179,"data-annotation":0.5389501762,"dev-research":0.204703336,"llms":0.5348117382,"data-quality":0.2800784161}}
{"text":"In this work, we scale the Word Embedding Association Test (WEAT) to 24 languages, enabling broader studies and yielding interesting findings about LM bias.","meta":{"url":"http://arxiv.org/abs/2310.17586v1"},"cats":{"benchmark":0.4306946758,"new-dataset":0.0583233972,"data-annotation":0.5542583317,"dev-research":0.1634349762,"llms":0.5820180058,"data-quality":0.2930709018}}
{"text":"We additionally enhance this data with culturally relevant information for each language, capturing local contexts on a global scale.","meta":{"url":"http://arxiv.org/abs/2310.17586v1"},"cats":{"benchmark":0.2572062953,"new-dataset":0.6135780538,"data-annotation":0.5201390814,"dev-research":0.1852430001,"llms":0.5351798414,"data-quality":0.2078482868}}
{"text":"Further, to encompass more widely prevalent societal biases, we examine new bias dimensions across toxicity, ableism, and more.","meta":{"url":"http://arxiv.org/abs/2310.17586v1"},"cats":{"benchmark":0.3029862074,"new-dataset":0.0257911066,"data-annotation":0.5246662982,"dev-research":0.2546762768,"llms":0.5048068083,"data-quality":0.1393352742}}
{"text":"Moreover, we delve deeper into the Indian linguistic landscape, conducting a comprehensive regional bias analysis across six prevalent Indian languages.","meta":{"url":"http://arxiv.org/abs/2310.17586v1"},"cats":{"benchmark":0.334251626,"new-dataset":0.0391884235,"data-annotation":0.529518528,"dev-research":0.2550260895,"llms":0.4956727506,"data-quality":0.2686358582}}
{"text":"Finally, we highlight the significance of these social biases and the new dimensions through an extensive comparison of embedding methods, reinforcing the need to address them in pursuit of more equitable language models.","meta":{"url":"http://arxiv.org/abs/2310.17586v1"},"cats":{"benchmark":0.4065860822,"new-dataset":0.0171679705,"data-annotation":0.5607712842,"dev-research":0.1733860548,"llms":0.5223765855,"data-quality":0.2545186484}}
{"text":"All code, data and results are available here: https://github.com/iamshnoo/weathub.","meta":{"url":"http://arxiv.org/abs/2310.17586v1"},"cats":{"benchmark":0.3530948541,"new-dataset":0.7791335933,"data-annotation":0.5151325607,"dev-research":0.1141063472,"llms":0.5025824809,"data-quality":0.0910329107}}
{"text":"Graph neural networks (GNNs) have emerged as a powerful tool for tasks such as node classification and graph classification.","meta":{"url":"http://arxiv.org/abs/2310.17579v1"},"cats":{"benchmark":0.2323702179,"new-dataset":0.0549010409,"data-annotation":0.5110921638,"dev-research":0.2294860743,"llms":0.4564895939,"data-quality":0.1742792581}}
{"text":"However, much less work has been done on signal classification, where the data consists of many functions (referred to as signals) defined on the vertices of a single graph.","meta":{"url":"http://arxiv.org/abs/2310.17579v1"},"cats":{"benchmark":0.322948033,"new-dataset":0.0501630394,"data-annotation":0.5144287795,"dev-research":0.2288166172,"llms":0.3733607554,"data-quality":0.17154057}}
{"text":"These tasks require networks designed differently from those designed for traditional GNN tasks.","meta":{"url":"http://arxiv.org/abs/2310.17579v1"},"cats":{"benchmark":0.202097547,"new-dataset":0.0112577541,"data-annotation":0.495624192,"dev-research":0.2034856682,"llms":0.5181562975,"data-quality":0.086786923}}
{"text":"Indeed, traditional GNNs rely on localized low-pass filters, and signals of interest may have intricate multi-frequency behavior and exhibit long range interactions.","meta":{"url":"http://arxiv.org/abs/2310.17579v1"},"cats":{"benchmark":0.220855197,"new-dataset":0.0229425906,"data-annotation":0.5170869125,"dev-research":0.1413802893,"llms":0.4822269162,"data-quality":0.0668367331}}
{"text":"This motivates us to introduce the BLIS-Net (Bi-Lipschitz Scattering Net), a novel GNN that builds on the previously introduced geometric scattering transform.","meta":{"url":"http://arxiv.org/abs/2310.17579v1"},"cats":{"benchmark":0.2571510894,"new-dataset":0.0536547022,"data-annotation":0.5193822859,"dev-research":0.1328924712,"llms":0.4333266088,"data-quality":0.0514051078}}
{"text":"Our network is able to capture both local and global signal structure and is able to capture both low-frequency and high-frequency information.","meta":{"url":"http://arxiv.org/abs/2310.17579v1"},"cats":{"benchmark":0.3264235312,"new-dataset":0.0313581223,"data-annotation":0.4823565228,"dev-research":0.1144547782,"llms":0.4648458256,"data-quality":0.0816922221}}
{"text":"We make several crucial changes to the original geometric scattering architecture which we prove increase the ability of our network to capture information about the input signal and show that BLIS-Net achieves superior performance on both synthetic and real-world data sets based on traffic flow and fMRI data.","meta":{"url":"http://arxiv.org/abs/2310.17579v1"},"cats":{"benchmark":0.3257126872,"new-dataset":0.0815046289,"data-annotation":0.5046814994,"dev-research":0.1434354796,"llms":0.4047755313,"data-quality":0.0633864805}}
{"text":"This paper studies a diffusion-based framework to address the low-light image enhancement problem.","meta":{"url":"http://arxiv.org/abs/2310.17577v1"},"cats":{"benchmark":0.5164944505,"new-dataset":0.0202241367,"data-annotation":0.5056212934,"dev-research":0.1773437831,"llms":0.3835474439,"data-quality":0.086582857}}
{"text":"To harness the capabilities of diffusion models, we delve into this intricate process and advocate for the regularization of its inherent ODE-trajectory.","meta":{"url":"http://arxiv.org/abs/2310.17577v1"},"cats":{"benchmark":0.3293013089,"new-dataset":0.0130943616,"data-annotation":0.490523991,"dev-research":0.1112116122,"llms":0.3827656993,"data-quality":0.0663732711}}
{"text":"To be specific, inspired by the recent research that low curvature ODE-trajectory results in a stable and effective diffusion process, we formulate a curvature regularization term anchored in the intrinsic non-local structures of image data, i.e., global structure-aware regularization, which gradually facilitates the preservation of complicated details and the augmentation of contrast during the diffusion process.","meta":{"url":"http://arxiv.org/abs/2310.17577v1"},"cats":{"benchmark":0.4004504142,"new-dataset":0.0241085609,"data-annotation":0.4760102251,"dev-research":0.1184698094,"llms":0.3857824182,"data-quality":0.1256297197}}
{"text":"This incorporation mitigates the adverse effects of noise and artifacts resulting from the diffusion process, leading to a more precise and flexible enhancement.","meta":{"url":"http://arxiv.org/abs/2310.17577v1"},"cats":{"benchmark":0.4544481276,"new-dataset":0.0014839709,"data-annotation":0.4785844118,"dev-research":0.2113885899,"llms":0.4808107438,"data-quality":0.1062070113}}
{"text":"To additionally promote learning in challenging regions, we introduce an uncertainty-guided regularization technique, which wisely relaxes constraints on the most extreme regions of the image.","meta":{"url":"http://arxiv.org/abs/2310.17577v1"},"cats":{"benchmark":0.3972688193,"new-dataset":0.0378732448,"data-annotation":0.5089344783,"dev-research":0.1998632124,"llms":0.3756814293,"data-quality":0.2246655219}}
{"text":"Experimental evaluations reveal that the proposed diffusion-based framework, complemented by rank-informed regularization, attains distinguished performance in low-light enhancement.","meta":{"url":"http://arxiv.org/abs/2310.17577v1"},"cats":{"benchmark":0.650914614,"new-dataset":0.0057163524,"data-annotation":0.5157126375,"dev-research":0.1619753699,"llms":0.376765889,"data-quality":0.1410029332}}
{"text":"The outcomes indicate substantial advancements in image quality, noise suppression, and contrast amplification in comparison with state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2310.17577v1"},"cats":{"benchmark":0.6215760639,"new-dataset":0.018275721,"data-annotation":0.4949462176,"dev-research":0.1616147312,"llms":0.4813669974,"data-quality":0.2282837045}}
{"text":"We believe this innovative approach will stimulate further exploration and advancement in low-light image processing, with potential implications for other applications of diffusion models.","meta":{"url":"http://arxiv.org/abs/2310.17577v1"},"cats":{"benchmark":0.4084716421,"new-dataset":0.0159946452,"data-annotation":0.5065282572,"dev-research":0.1137564696,"llms":0.4416253138,"data-quality":0.0596713781}}
{"text":"The code is publicly available at https://github.com/jinnh/GSAD.","meta":{"url":"http://arxiv.org/abs/2310.17577v1"},"cats":{"benchmark":0.2855581478,"new-dataset":0.2361601988,"data-annotation":0.5149441197,"dev-research":0.1331797258,"llms":0.5526967759,"data-quality":0.0957306312}}
{"text":"Existing text selection techniques on touchscreen focus on improving the control for moving the carets.","meta":{"url":"http://arxiv.org/abs/2310.17576v1"},"cats":{"benchmark":0.338207122,"new-dataset":0.0252904038,"data-annotation":0.5297281302,"dev-research":0.2272493925,"llms":0.5025672422,"data-quality":0.0860716143}}
{"text":"Coarse-grained text selection on word and phrase levels has not received much support beyond word-snapping and entity recognition.","meta":{"url":"http://arxiv.org/abs/2310.17576v1"},"cats":{"benchmark":0.4583553146,"new-dataset":0.0254157928,"data-annotation":0.5228587934,"dev-research":0.1189905463,"llms":0.5361091473,"data-quality":0.226291622}}
{"text":"We introduce 1D-Touch, a novel text selection method that complements the carets-based sub-word selection by facilitating the selection of semantic units of words and above.","meta":{"url":"http://arxiv.org/abs/2310.17576v1"},"cats":{"benchmark":0.3672487413,"new-dataset":0.0459972057,"data-annotation":0.5361045845,"dev-research":0.170174491,"llms":0.5171821965,"data-quality":0.146050497}}
{"text":"This method employs a simple vertical slide gesture to expand and contract a selection area from a word.","meta":{"url":"http://arxiv.org/abs/2310.17576v1"},"cats":{"benchmark":0.2881072348,"new-dataset":0.0079484459,"data-annotation":0.5247188085,"dev-research":0.2008965316,"llms":0.5203025366,"data-quality":0.0944947901}}
{"text":"The expansion can be by words or by semantic chunks ranging from sub-phrases to sentences.","meta":{"url":"http://arxiv.org/abs/2310.17576v1"},"cats":{"benchmark":0.2113357863,"new-dataset":0.0322775645,"data-annotation":0.5337162664,"dev-research":0.1956788461,"llms":0.4648898222,"data-quality":0.1964730059}}
{"text":"This technique shifts the concept of text selection, from defining a range by locating the first and last words, towards a dynamic process of expanding and contracting a textual semantic entity.","meta":{"url":"http://arxiv.org/abs/2310.17576v1"},"cats":{"benchmark":0.3121645876,"new-dataset":0.0077427728,"data-annotation":0.5234928125,"dev-research":0.2264310009,"llms":0.513166391,"data-quality":0.1844040903}}
{"text":"To understand the effects of our approach, we prototyped and tested two variants: WordTouch, which offers a straightforward word-by-word expansion, and ChunkTouch, which leverages NLP to chunk text into syntactic units, allowing the selection to grow by semantically meaningful units in response to the sliding gesture.","meta":{"url":"http://arxiv.org/abs/2310.17576v1"},"cats":{"benchmark":0.2913458426,"new-dataset":0.0626427216,"data-annotation":0.5222586893,"dev-research":0.2214961995,"llms":0.5183907225,"data-quality":0.153437205}}
{"text":"Our evaluation, focused on the coarse-grained selection tasks handled by 1D-Touch, shows a 20% improvement over the default word-snapping selection method on Android.","meta":{"url":"http://arxiv.org/abs/2310.17576v1"},"cats":{"benchmark":0.544049558,"new-dataset":0.033498236,"data-annotation":0.5278180114,"dev-research":0.1791437675,"llms":0.5303229164,"data-quality":0.0918375321}}
{"text":"While Diffusion Generative Models have achieved great success on image generation tasks, how to efficiently and effectively incorporate them into speech generation especially translation tasks remains a non-trivial problem.","meta":{"url":"http://arxiv.org/abs/2310.17570v1"},"cats":{"benchmark":0.248815938,"new-dataset":0.12028965,"data-annotation":0.5296586208,"dev-research":0.1557045353,"llms":0.5599963925,"data-quality":0.14035741}}
{"text":"Specifically, due to the low information density of speech data, the transformed discrete speech unit sequence is much longer than the corresponding text transcription, posing significant challenges to existing auto-regressive models.","meta":{"url":"http://arxiv.org/abs/2310.17570v1"},"cats":{"benchmark":0.3529569796,"new-dataset":0.0909699331,"data-annotation":0.4963695608,"dev-research":0.0898283747,"llms":0.4434080524,"data-quality":0.1597055935}}
{"text":"Furthermore, it is not optimal to brutally apply discrete diffusion on the speech unit sequence while disregarding the continuous space structure, which will degrade the generation performance significantly.","meta":{"url":"http://arxiv.org/abs/2310.17570v1"},"cats":{"benchmark":0.4320023582,"new-dataset":0.0290655481,"data-annotation":0.5047293471,"dev-research":0.1224636556,"llms":0.5480333671,"data-quality":0.1253254486}}
{"text":"In this paper, we propose a novel diffusion model by applying the diffusion forward process in the \\textit{continuous} speech representation space, while employing the diffusion backward process in the \\textit{discrete} speech unit space.","meta":{"url":"http://arxiv.org/abs/2310.17570v1"},"cats":{"benchmark":0.3086120916,"new-dataset":0.0320031509,"data-annotation":0.5112439183,"dev-research":0.1414739373,"llms":0.4734816977,"data-quality":0.1270759898}}
{"text":"In this way, we preserve the semantic structure of the continuous speech representation space in the diffusion process and integrate the continuous and discrete diffusion models.","meta":{"url":"http://arxiv.org/abs/2310.17570v1"},"cats":{"benchmark":0.2565540901,"new-dataset":0.0392735626,"data-annotation":0.5071535561,"dev-research":0.1483156137,"llms":0.4699361942,"data-quality":0.1869426177}}
{"text":"We conduct extensive experiments on the textless direct speech-to-speech translation task, where the proposed method achieves comparable results to the computationally intensive auto-regressive baselines (500 steps on average) with significantly fewer decoding steps (50 steps).","meta":{"url":"http://arxiv.org/abs/2310.17570v1"},"cats":{"benchmark":0.4671523334,"new-dataset":0.1139364384,"data-annotation":0.5279119728,"dev-research":0.1538726497,"llms":0.4738407081,"data-quality":0.1489882599}}
{"text":"In this paper, we address the challenge of matching semantically similar keypoints across image pairs.","meta":{"url":"http://arxiv.org/abs/2310.17569v1"},"cats":{"benchmark":0.4505443416,"new-dataset":0.1771015081,"data-annotation":0.5121291181,"dev-research":0.1613857728,"llms":0.4248700703,"data-quality":0.2225525808}}
{"text":"Existing research indicates that the intermediate output of the UNet within the Stable Diffusion (SD) can serve as robust image feature maps for such a matching task.","meta":{"url":"http://arxiv.org/abs/2310.17569v1"},"cats":{"benchmark":0.4826056856,"new-dataset":0.0834766695,"data-annotation":0.4840758218,"dev-research":0.1018359159,"llms":0.3954439387,"data-quality":0.1286142234}}
{"text":"We demonstrate that by employing a basic prompt tuning technique, the inherent potential of Stable Diffusion can be harnessed, resulting in a significant enhancement in accuracy over previous approaches.","meta":{"url":"http://arxiv.org/abs/2310.17569v1"},"cats":{"benchmark":0.5631668676,"new-dataset":0.0071009617,"data-annotation":0.5092446039,"dev-research":0.1169927369,"llms":0.4710943528,"data-quality":0.0998666123}}
{"text":"We further introduce a novel conditional prompting module that conditions the prompt on the local details of the input image pairs, leading to a further improvement in performance.","meta":{"url":"http://arxiv.org/abs/2310.17569v1"},"cats":{"benchmark":0.2598681972,"new-dataset":0.1177681997,"data-annotation":0.522937128,"dev-research":0.2521323268,"llms":0.5088777859,"data-quality":0.1775224926}}
{"text":"We designate our approach as SD4Match, short for Stable Diffusion for Semantic Matching.","meta":{"url":"http://arxiv.org/abs/2310.17569v1"},"cats":{"benchmark":0.4402679361,"new-dataset":0.1139345949,"data-annotation":0.5268730668,"dev-research":0.1553750712,"llms":0.5014098909,"data-quality":0.3186446297}}
{"text":"Comprehensive evaluations of SD4Match on the PF-Pascal, PF-Willow, and SPair-71k datasets show that it sets new benchmarks in accuracy across all these datasets.","meta":{"url":"http://arxiv.org/abs/2310.17569v1"},"cats":{"benchmark":0.7305895003,"new-dataset":0.4301610946,"data-annotation":0.5301244949,"dev-research":0.1727360787,"llms":0.4683974189,"data-quality":0.2439362845}}
{"text":"Particularly, SD4Match outperforms the previous state-of-the-art by a margin of 12 percentage points on the challenging SPair-71k dataset.","meta":{"url":"http://arxiv.org/abs/2310.17569v1"},"cats":{"benchmark":0.5856036001,"new-dataset":0.5046045219,"data-annotation":0.5288188477,"dev-research":0.1805493996,"llms":0.4977981154,"data-quality":0.2089099284}}
{"text":"Human-guided robotic exploration is a useful approach to gathering information at remote locations, especially those that might be too risky, inhospitable, or inaccessible for humans.","meta":{"url":"http://arxiv.org/abs/2310.17568v1"},"cats":{"benchmark":0.1570499746,"new-dataset":0.0271287472,"data-annotation":0.5070222683,"dev-research":0.2264256873,"llms":0.5383754376,"data-quality":0.0650957443}}
{"text":"Maintaining common ground between the remotely-located partners is a challenge, one that can be facilitated by multi-modal communication.","meta":{"url":"http://arxiv.org/abs/2310.17568v1"},"cats":{"benchmark":0.2153057629,"new-dataset":0.069271892,"data-annotation":0.4810272017,"dev-research":0.2278400258,"llms":0.5487274893,"data-quality":0.0732412888}}
{"text":"In this paper, we explore how participants utilized multiple modalities to investigate a remote location with the help of a robotic partner.","meta":{"url":"http://arxiv.org/abs/2310.17568v1"},"cats":{"benchmark":0.2100004491,"new-dataset":0.0382373793,"data-annotation":0.505321263,"dev-research":0.2317393317,"llms":0.5167503873,"data-quality":0.042130839}}
{"text":"Participants issued spoken natural language instructions and received from the robot: text-based feedback, continuous 2D LIDAR mapping, and upon-request static photographs.","meta":{"url":"http://arxiv.org/abs/2310.17568v1"},"cats":{"benchmark":0.170190535,"new-dataset":0.2576145402,"data-annotation":0.5110334801,"dev-research":0.242109087,"llms":0.5515680455,"data-quality":0.1439034138}}
{"text":"We noticed that different strategies were adopted in terms of use of the modalities, and hypothesize that these differences may be correlated with success at several exploration sub-tasks.","meta":{"url":"http://arxiv.org/abs/2310.17568v1"},"cats":{"benchmark":0.3232008648,"new-dataset":0.0055352173,"data-annotation":0.4914911711,"dev-research":0.1990780608,"llms":0.4967694142,"data-quality":0.0461952662}}
{"text":"We found that requesting photos may have improved the identification and counting of some key entities (doorways in particular) and that this strategy did not hinder the amount of overall area exploration.","meta":{"url":"http://arxiv.org/abs/2310.17568v1"},"cats":{"benchmark":0.1982239616,"new-dataset":0.0601058522,"data-annotation":0.4931540713,"dev-research":0.168403938,"llms":0.5733295269,"data-quality":0.0877855267}}
{"text":"Future work with larger samples may reveal the effects of more nuanced photo and dialogue strategies, which can inform the training of robotic agents.","meta":{"url":"http://arxiv.org/abs/2310.17568v1"},"cats":{"benchmark":0.1590438277,"new-dataset":0.0941182451,"data-annotation":0.5225606536,"dev-research":0.2040043487,"llms":0.5870048447,"data-quality":0.1286268971}}
{"text":"Additionally, we announce the release of our unique multi-modal corpus of human-robot communication in an exploration context: SCOUT, the Situated Corpus on Understanding Transactions.","meta":{"url":"http://arxiv.org/abs/2310.17568v1"},"cats":{"benchmark":0.1334953268,"new-dataset":0.5708242944,"data-annotation":0.5237221769,"dev-research":0.2800499839,"llms":0.5881502131,"data-quality":0.1343432667}}
{"text":"With LLMs shifting their role from statistical modeling of language to serving as general-purpose AI agents, how should LLM evaluations change?","meta":{"url":"http://arxiv.org/abs/2310.17567v1"},"cats":{"benchmark":0.2879154723,"new-dataset":0.0106629755,"data-annotation":0.531213638,"dev-research":0.1727673927,"llms":0.7611083641,"data-quality":0.1395243983}}
{"text":"Arguably, a key ability of an AI agent is to flexibly combine, as needed, the basic skills it has learned.","meta":{"url":"http://arxiv.org/abs/2310.17567v1"},"cats":{"benchmark":0.2338232899,"new-dataset":0.0031257917,"data-annotation":0.5245378266,"dev-research":0.1978527096,"llms":0.476173171,"data-quality":0.0627866464}}
{"text":"The capability to combine skills plays an important role in (human) pedagogy and also in a paper on emergence phenomena (Arora & Goyal, 2023).   ","meta":{"url":"http://arxiv.org/abs/2310.17567v1"},"cats":{"benchmark":0.123283124,"new-dataset":0.0416776895,"data-annotation":0.5129372575,"dev-research":0.1991631961,"llms":0.53689446,"data-quality":0.0576455144}}
{"text":"This work introduces Skill-Mix, a new evaluation to measure ability to combine skills.","meta":{"url":"http://arxiv.org/abs/2310.17567v1"},"cats":{"benchmark":0.3993360296,"new-dataset":0.0233816301,"data-annotation":0.5256386943,"dev-research":0.2422210441,"llms":0.5296544971,"data-quality":0.0934170681}}
{"text":"Using a list of $N$ skills the evaluator repeatedly picks random subsets of $k$ skills and asks the LLM to produce text combining that subset of skills.","meta":{"url":"http://arxiv.org/abs/2310.17567v1"},"cats":{"benchmark":0.2338490159,"new-dataset":0.1046573068,"data-annotation":0.5349096058,"dev-research":0.1598753706,"llms":0.636348709,"data-quality":0.1595680411}}
{"text":"Since the number of subsets grows like $N^k$, for even modest $k$ this evaluation will, with high probability, require the LLM to produce text significantly different from any text in the training set.","meta":{"url":"http://arxiv.org/abs/2310.17567v1"},"cats":{"benchmark":0.3760396721,"new-dataset":0.0510826225,"data-annotation":0.5427807142,"dev-research":0.1202506665,"llms":0.7038890462,"data-quality":0.2432217278}}
{"text":"The paper develops a methodology for (a) designing and administering such an evaluation, and (b) automatic grading (plus spot-checking by humans) of the results using GPT-4 as well as the open LLaMA-2 70B model.   ","meta":{"url":"http://arxiv.org/abs/2310.17567v1"},"cats":{"benchmark":0.6410668176,"new-dataset":0.0701465372,"data-annotation":0.5314454332,"dev-research":0.1758016595,"llms":0.5452682016,"data-quality":0.1340833005}}
{"text":"Administering a version of to popular chatbots gave results that, while generally in line with prior expectations, contained surprises.","meta":{"url":"http://arxiv.org/abs/2310.17567v1"},"cats":{"benchmark":0.2188444011,"new-dataset":0.0263915397,"data-annotation":0.5169086407,"dev-research":0.2897197213,"llms":0.5795546586,"data-quality":0.1756828887}}
{"text":"Sizeable differences exist among model capabilities that are not captured by their ranking on popular LLM leaderboards (\"cramming for the leaderboard\").","meta":{"url":"http://arxiv.org/abs/2310.17567v1"},"cats":{"benchmark":0.4266650388,"new-dataset":0.0121680434,"data-annotation":0.5018072593,"dev-research":0.1376058089,"llms":0.6736448353,"data-quality":0.0478464205}}
{"text":"Furthermore, simple probability calculations indicate that GPT-4's reasonable performance on $k=5$ is suggestive of going beyond \"stochastic parrot\" behavior (Bender et al., 2021), i.e., it combines skills in ways that it had not seen during training.   ","meta":{"url":"http://arxiv.org/abs/2310.17567v1"},"cats":{"benchmark":0.3533307607,"new-dataset":0.0318874165,"data-annotation":0.5428926824,"dev-research":0.1297804807,"llms":0.4962060615,"data-quality":0.0771596487}}
{"text":"We sketch how the methodology can lead to a Skill-Mix based eco-system of open evaluations for AI capabilities of future models.","meta":{"url":"http://arxiv.org/abs/2310.17567v1"},"cats":{"benchmark":0.2610139229,"new-dataset":0.0454042339,"data-annotation":0.5185152178,"dev-research":0.2452814827,"llms":0.4758256195,"data-quality":0.0828522451}}
{"text":"This paper focuses on the design and systematic evaluation of fabric-based, bellow-type soft pneumatic actuators to assist with flexion and extension of the elbow, intended for use in infant wearable devices.","meta":{"url":"http://arxiv.org/abs/2310.17565v1"},"cats":{"benchmark":0.3478143103,"new-dataset":0.020447875,"data-annotation":0.5233129002,"dev-research":0.1694795188,"llms":0.5164702667,"data-quality":0.0728841676}}
{"text":"Initially, the performance of a range of actuator variants was explored via simulation.","meta":{"url":"http://arxiv.org/abs/2310.17565v1"},"cats":{"benchmark":0.4036289499,"new-dataset":0.0099942313,"data-annotation":0.5163414811,"dev-research":0.1476397669,"llms":0.4883190598,"data-quality":0.0344139252}}
{"text":"The actuator variants were parameterized based on the shape, number, and size of the cells present.","meta":{"url":"http://arxiv.org/abs/2310.17565v1"},"cats":{"benchmark":0.2907552994,"new-dataset":0.0173478168,"data-annotation":0.513571997,"dev-research":0.1476380354,"llms":0.4738929704,"data-quality":0.0459988559}}
{"text":"Subsequently, viable actuator variants identified from the simulations were fabricated and underwent further testing on a physical model based on an infant's body anthropometrics.","meta":{"url":"http://arxiv.org/abs/2310.17565v1"},"cats":{"benchmark":0.3309064303,"new-dataset":0.0226400556,"data-annotation":0.5010104728,"dev-research":0.1633456038,"llms":0.4916385936,"data-quality":0.0614685268}}
{"text":"The performance of these variants was evaluated based on kinematic analyses using metrics including movement smoothness, path length, and elbow joint angle.","meta":{"url":"http://arxiv.org/abs/2310.17565v1"},"cats":{"benchmark":0.577730846,"new-dataset":0.0207696992,"data-annotation":0.5175799322,"dev-research":0.1878680818,"llms":0.4527690217,"data-quality":0.0521962971}}
{"text":"Internal pressure of the actuators was also attained.","meta":{"url":"http://arxiv.org/abs/2310.17565v1"},"cats":{"benchmark":0.3286005319,"new-dataset":0.0360882978,"data-annotation":0.5217904935,"dev-research":0.1821189266,"llms":0.4567119807,"data-quality":0.1100293443}}
{"text":"Taken together, results reported herein provide valuable insights about the suitability of several actuator designs to serve as components for pediatric wearable assistive devices.","meta":{"url":"http://arxiv.org/abs/2310.17565v1"},"cats":{"benchmark":0.358075271,"new-dataset":0.0201332205,"data-annotation":0.5088575389,"dev-research":0.1866487931,"llms":0.5187326681,"data-quality":0.062840849}}
{"text":"Recurrent neural networks (RNNs) are popular machine learning tools for modeling and forecasting sequential data and for inferring dynamical systems (DS) from observed time series.","meta":{"url":"http://arxiv.org/abs/2310.17561v1"},"cats":{"benchmark":0.2265122348,"new-dataset":0.2366214575,"data-annotation":0.4902172912,"dev-research":0.1507594119,"llms":0.4697815044,"data-quality":0.0456655988}}
{"text":"Concepts from DS theory (DST) have variously been used to further our understanding of both, how trained RNNs solve complex tasks, and the training process itself.","meta":{"url":"http://arxiv.org/abs/2310.17561v1"},"cats":{"benchmark":0.1876682631,"new-dataset":0.0226476924,"data-annotation":0.4950588632,"dev-research":0.1850709682,"llms":0.547638835,"data-quality":0.063243978}}
{"text":"Bifurcations are particularly important phenomena in DS, including RNNs, that refer to topological (qualitative) changes in a system's dynamical behavior as one or more of its parameters are varied.","meta":{"url":"http://arxiv.org/abs/2310.17561v1"},"cats":{"benchmark":0.2076765237,"new-dataset":0.0408957156,"data-annotation":0.4786972407,"dev-research":0.1594790267,"llms":0.5456259655,"data-quality":0.0727665939}}
{"text":"Knowing the bifurcation structure of an RNN will thus allow to deduce many of its computational and dynamical properties, like its sensitivity to parameter variations or its behavior during training.","meta":{"url":"http://arxiv.org/abs/2310.17561v1"},"cats":{"benchmark":0.2636520605,"new-dataset":0.0263784711,"data-annotation":0.5138078093,"dev-research":0.1117548576,"llms":0.5120824541,"data-quality":0.072655984}}
{"text":"In particular, bifurcations may account for sudden loss jumps observed in RNN training that could severely impede the training process.","meta":{"url":"http://arxiv.org/abs/2310.17561v1"},"cats":{"benchmark":0.2599275615,"new-dataset":0.017246125,"data-annotation":0.5181340399,"dev-research":0.1780765955,"llms":0.50250584,"data-quality":0.1438655943}}
{"text":"Here we first mathematically prove for a particular class of ReLU-based RNNs that certain bifurcations are indeed associated with loss gradients tending toward infinity or zero.","meta":{"url":"http://arxiv.org/abs/2310.17561v1"},"cats":{"benchmark":0.2610442422,"new-dataset":0.0756007218,"data-annotation":0.539028491,"dev-research":0.0853352364,"llms":0.5086168929,"data-quality":0.1331960677}}
{"text":"We then introduce a novel heuristic algorithm for detecting all fixed points and k-cycles in ReLU-based RNNs and their existence and stability regions, hence bifurcation manifolds in parameter space.","meta":{"url":"http://arxiv.org/abs/2310.17561v1"},"cats":{"benchmark":0.3152774982,"new-dataset":0.1655598388,"data-annotation":0.5207046621,"dev-research":0.1064459698,"llms":0.4892083299,"data-quality":0.1074740946}}
{"text":"In contrast to previous numerical algorithms for finding fixed points and common continuation methods, our algorithm provides exact results and returns fixed points and cycles up to high orders with surprisingly good scaling behavior.","meta":{"url":"http://arxiv.org/abs/2310.17561v1"},"cats":{"benchmark":0.5948576707,"new-dataset":0.0601468294,"data-annotation":0.5211036771,"dev-research":0.1300574165,"llms":0.4334080628,"data-quality":0.1082433203}}
{"text":"We exemplify the algorithm on the analysis of the training process of RNNs, and find that the recently introduced technique of generalized teacher forcing completely avoids certain types of bifurcations in training.","meta":{"url":"http://arxiv.org/abs/2310.17561v1"},"cats":{"benchmark":0.2687063894,"new-dataset":0.0289114765,"data-annotation":0.525067351,"dev-research":0.1103352916,"llms":0.5129546428,"data-quality":0.1201165508}}
{"text":"Thus, besides facilitating the DST analysis of trained RNNs, our algorithm provides a powerful instrument for analyzing the training process itself.","meta":{"url":"http://arxiv.org/abs/2310.17561v1"},"cats":{"benchmark":0.402095879,"new-dataset":0.1011094771,"data-annotation":0.516551525,"dev-research":0.1582960553,"llms":0.5217168148,"data-quality":0.0841441001}}
{"text":"Adversarial examples resulting from instability of current computer vision models are an extremely important topic due to their potential to compromise any application.","meta":{"url":"http://arxiv.org/abs/2310.17559v1"},"cats":{"benchmark":0.2005547001,"new-dataset":0.0268970446,"data-annotation":0.5331384149,"dev-research":0.230509059,"llms":0.4675828807,"data-quality":0.3323184773}}
{"text":"In this paper we demonstrate that instability is inevitable due to a) symmetries (translational invariance) of the data, b) the categorical nature of the classification task, and c) the fundamental discrepancy of classifying images as objects themselves.","meta":{"url":"http://arxiv.org/abs/2310.17559v1"},"cats":{"benchmark":0.2348035142,"new-dataset":0.0477499823,"data-annotation":0.5119911703,"dev-research":0.1645484123,"llms":0.4565894136,"data-quality":0.4324552134}}
{"text":"The issue is further exacerbated by non-exhaustive labelling of the training data.","meta":{"url":"http://arxiv.org/abs/2310.17559v1"},"cats":{"benchmark":0.3467174493,"new-dataset":0.0300885375,"data-annotation":0.5093672256,"dev-research":0.2056090579,"llms":0.5145555733,"data-quality":0.6324857699}}
{"text":"Therefore we conclude that instability is a necessary result of how the problem of computer vision is currently formulated.","meta":{"url":"http://arxiv.org/abs/2310.17559v1"},"cats":{"benchmark":0.2556853041,"new-dataset":0.0378235869,"data-annotation":0.5228640684,"dev-research":0.2961126385,"llms":0.3985703279,"data-quality":0.2506277366}}
{"text":"While the problem cannot be eliminated, through the analysis of the causes, we have arrived at ways how it can be partially alleviated.","meta":{"url":"http://arxiv.org/abs/2310.17559v1"},"cats":{"benchmark":0.3158235843,"new-dataset":0.0194173419,"data-annotation":0.5216375656,"dev-research":0.339503148,"llms":0.4633253194,"data-quality":0.2083442954}}
{"text":"These include i) increasing the resolution of images, ii) providing contextual information for the image, iii) exhaustive labelling of training data, and iv) preventing attackers from frequent access to the computer vision system.","meta":{"url":"http://arxiv.org/abs/2310.17559v1"},"cats":{"benchmark":0.1741983287,"new-dataset":0.0479849678,"data-annotation":0.4958177582,"dev-research":0.279285244,"llms":0.4777653457,"data-quality":0.1698921216}}
{"text":"Learning phone types from phone instances has been a long-standing problem, while still being open.","meta":{"url":"http://arxiv.org/abs/2310.17558v1"},"cats":{"benchmark":0.1947018964,"new-dataset":0.0956176577,"data-annotation":0.5392496554,"dev-research":0.1155984491,"llms":0.5522555564,"data-quality":0.1684432246}}
{"text":"In this work, we revisit this problem in the context of self-supervised learning, and pose it as the problem of matching cluster centroids to phone embeddings.","meta":{"url":"http://arxiv.org/abs/2310.17558v1"},"cats":{"benchmark":0.3426083385,"new-dataset":0.2178162319,"data-annotation":0.5467851771,"dev-research":0.1173766946,"llms":0.4912362876,"data-quality":0.3831441942}}
{"text":"We study two key properties that enable matching, namely, whether cluster centroids of self-supervised representations reduce the variability of phone instances and respect the relationship among phones.","meta":{"url":"http://arxiv.org/abs/2310.17558v1"},"cats":{"benchmark":0.3265435125,"new-dataset":0.0670709804,"data-annotation":0.5285656705,"dev-research":0.1416209309,"llms":0.5079666346,"data-quality":0.2799071209}}
{"text":"We then use the matching result to produce pseudo-labels and introduce a new loss function for improving self-supervised representations.","meta":{"url":"http://arxiv.org/abs/2310.17558v1"},"cats":{"benchmark":0.3574420877,"new-dataset":0.1414016717,"data-annotation":0.5541389522,"dev-research":0.1492701833,"llms":0.4478812766,"data-quality":0.6111649581}}
{"text":"Our experiments show that the matching result captures the relationship among phones.","meta":{"url":"http://arxiv.org/abs/2310.17558v1"},"cats":{"benchmark":0.4391326227,"new-dataset":0.0594420201,"data-annotation":0.5124623941,"dev-research":0.1409142193,"llms":0.4970664748,"data-quality":0.1343211798}}
{"text":"Training the new loss function jointly with the regular self-supervised losses, such as APC and CPC, significantly improves the downstream phone classification.","meta":{"url":"http://arxiv.org/abs/2310.17558v1"},"cats":{"benchmark":0.4075181128,"new-dataset":0.054371619,"data-annotation":0.5318964199,"dev-research":0.139597493,"llms":0.4557762844,"data-quality":0.3162596439}}
{"text":"We propose a new algorithm for efficiently solving the damped Fisher matrix in large-scale scenarios where the number of parameters significantly exceeds the number of available samples.","meta":{"url":"http://arxiv.org/abs/2310.17556v1"},"cats":{"benchmark":0.5945264822,"new-dataset":0.0484217947,"data-annotation":0.533441079,"dev-research":0.1463591247,"llms":0.3760200117,"data-quality":0.108752271}}
{"text":"This problem is fundamental for natural gradient descent and stochastic reconfiguration.","meta":{"url":"http://arxiv.org/abs/2310.17556v1"},"cats":{"benchmark":0.488714267,"new-dataset":0.0620918174,"data-annotation":0.5399660422,"dev-research":0.1151316086,"llms":0.3309472815,"data-quality":0.1355988023}}
{"text":"Our algorithm is based on Cholesky decomposition and is generally applicable.","meta":{"url":"http://arxiv.org/abs/2310.17556v1"},"cats":{"benchmark":0.6650677086,"new-dataset":0.0692717208,"data-annotation":0.549740612,"dev-research":0.096185225,"llms":0.3324082971,"data-quality":0.0939553682}}
{"text":"Benchmark results show that the algorithm is significantly faster than existing methods.","meta":{"url":"http://arxiv.org/abs/2310.17556v1"},"cats":{"benchmark":0.8600824667,"new-dataset":0.0151067901,"data-annotation":0.5491463843,"dev-research":0.1630852306,"llms":0.3980717863,"data-quality":0.1280589514}}
{"text":"The ability to learn and refine behavior after deployment has become ever more important for robots as we design them to operate in unstructured environments like households.","meta":{"url":"http://arxiv.org/abs/2310.17555v1"},"cats":{"benchmark":0.1613942414,"new-dataset":0.0654324432,"data-annotation":0.4952841401,"dev-research":0.2667770842,"llms":0.5408231358,"data-quality":0.0627327197}}
{"text":"In this work, we design a new learning system based on large language model (LLM), OLAF, that allows everyday users to teach a robot using verbal corrections when the robot makes mistakes, e.g., by saying \"Stop what you're doing.","meta":{"url":"http://arxiv.org/abs/2310.17555v1"},"cats":{"benchmark":0.1424080665,"new-dataset":0.3664485758,"data-annotation":0.5272629633,"dev-research":0.2701008599,"llms":0.6824831463,"data-quality":0.1765610275}}
{"text":"You should move closer to the cup.\"","meta":{"url":"http://arxiv.org/abs/2310.17555v1"},"cats":{"benchmark":0.3185198244,"new-dataset":0.1314870672,"data-annotation":0.5127845039,"dev-research":0.2495373591,"llms":0.4948024465,"data-quality":0.1705480565}}
{"text":"A key feature of OLAF is its ability to update the robot's visuomotor neural policy based on the verbal feedback to avoid repeating mistakes in the future.","meta":{"url":"http://arxiv.org/abs/2310.17555v1"},"cats":{"benchmark":0.2036382781,"new-dataset":0.0327064591,"data-annotation":0.5098698348,"dev-research":0.2926009098,"llms":0.4878391508,"data-quality":0.0854563137}}
{"text":"This is in contrast to existing LLM-based robotic systems, which only follow verbal commands or corrections but not learn from them.","meta":{"url":"http://arxiv.org/abs/2310.17555v1"},"cats":{"benchmark":0.1537169277,"new-dataset":0.0081302591,"data-annotation":0.4959653931,"dev-research":0.1850614371,"llms":0.7290512557,"data-quality":0.1283960684}}
{"text":"We demonstrate the efficacy of our design in experiments where a user teaches a robot to perform long-horizon manipulation tasks both in simulation and on physical hardware, achieving on average 20.0% improvement in policy success rate.","meta":{"url":"http://arxiv.org/abs/2310.17555v1"},"cats":{"benchmark":0.2795614427,"new-dataset":0.0746172827,"data-annotation":0.510762733,"dev-research":0.2395538754,"llms":0.5663159008,"data-quality":0.0516585503}}
{"text":"Videos and more results are at https://ut-austin-rpl.github.io/olaf/","meta":{"url":"http://arxiv.org/abs/2310.17555v1"},"cats":{"benchmark":0.261216552,"new-dataset":0.6254597913,"data-annotation":0.5224601688,"dev-research":0.1475568223,"llms":0.5161216003,"data-quality":0.0728587404}}
{"text":"Robot learning methods have recently made great strides, but generalization and robustness challenges still hinder their widespread deployment.","meta":{"url":"http://arxiv.org/abs/2310.17552v1"},"cats":{"benchmark":0.2954803489,"new-dataset":0.0074781736,"data-annotation":0.5181709663,"dev-research":0.1772980661,"llms":0.452884588,"data-quality":0.2382418439}}
{"text":"Failing to detect and address potential failures renders state-of-the-art learning systems not combat-ready for high-stakes tasks.","meta":{"url":"http://arxiv.org/abs/2310.17552v1"},"cats":{"benchmark":0.2350721617,"new-dataset":0.0448974389,"data-annotation":0.5240481325,"dev-research":0.3380728898,"llms":0.5763718561,"data-quality":0.2286923233}}
{"text":"Recent advances in interactive imitation learning have presented a promising framework for human-robot teaming, enabling the robots to operate safely and continually improve their performances over long-term deployments.","meta":{"url":"http://arxiv.org/abs/2310.17552v1"},"cats":{"benchmark":0.229355365,"new-dataset":0.0976051606,"data-annotation":0.5160803112,"dev-research":0.2565011048,"llms":0.5068080118,"data-quality":0.0904566832}}
{"text":"Nonetheless, existing methods typically require constant human supervision and preemptive feedback, limiting their practicality in realistic domains.","meta":{"url":"http://arxiv.org/abs/2310.17552v1"},"cats":{"benchmark":0.2698476278,"new-dataset":0.0069702329,"data-annotation":0.5154270426,"dev-research":0.4179132712,"llms":0.5270041206,"data-quality":0.1405465721}}
{"text":"This work aims to endow a robot with the ability to monitor and detect errors during task execution.","meta":{"url":"http://arxiv.org/abs/2310.17552v1"},"cats":{"benchmark":0.3258607687,"new-dataset":0.1013263657,"data-annotation":0.515556275,"dev-research":0.4205671687,"llms":0.5529110557,"data-quality":0.2230425438}}
{"text":"We introduce a model-based runtime monitoring algorithm that learns from deployment data to detect system anomalies and anticipate failures.","meta":{"url":"http://arxiv.org/abs/2310.17552v1"},"cats":{"benchmark":0.3341290216,"new-dataset":0.1266533205,"data-annotation":0.5083619905,"dev-research":0.4136207088,"llms":0.4914672544,"data-quality":0.2863019641}}
{"text":"Unlike prior work that cannot foresee future failures or requires failure experiences for training, our method learns a latent-space dynamics model and a failure classifier, enabling our method to simulate future action outcomes and detect out-of-distribution and high-risk states preemptively.","meta":{"url":"http://arxiv.org/abs/2310.17552v1"},"cats":{"benchmark":0.2434885237,"new-dataset":0.0709149455,"data-annotation":0.5437340718,"dev-research":0.1905581634,"llms":0.5089731493,"data-quality":0.2008941165}}
{"text":"We train our method within an interactive imitation learning framework, where it continually updates the model from the experiences of the human-robot team collected using trustworthy deployments.","meta":{"url":"http://arxiv.org/abs/2310.17552v1"},"cats":{"benchmark":0.1849942827,"new-dataset":0.3053002822,"data-annotation":0.5137830315,"dev-research":0.2925433976,"llms":0.5448336827,"data-quality":0.1184804281}}
{"text":"Consequently, our method reduces the human workload needed over time while ensuring reliable task execution.","meta":{"url":"http://arxiv.org/abs/2310.17552v1"},"cats":{"benchmark":0.5200789939,"new-dataset":0.0110918567,"data-annotation":0.5221072985,"dev-research":0.4302080079,"llms":0.5120316343,"data-quality":0.0829144451}}
{"text":"Our method outperforms the baselines across system-level and unit-test metrics, with 23% and 40% higher success rates in simulation and on physical hardware, respectively.","meta":{"url":"http://arxiv.org/abs/2310.17552v1"},"cats":{"benchmark":0.8271391864,"new-dataset":0.0205624176,"data-annotation":0.5264644889,"dev-research":0.218260115,"llms":0.5138565706,"data-quality":0.1535085448}}
{"text":"More information at https://ut-austin-rpl.github.io/sirius-runtime-monitor/","meta":{"url":"http://arxiv.org/abs/2310.17552v1"},"cats":{"benchmark":0.3560047072,"new-dataset":0.3950510857,"data-annotation":0.5159655429,"dev-research":0.175139476,"llms":0.5632438278,"data-quality":0.0865756473}}
{"text":"Big models have greatly advanced AI's ability to understand, generate, and manipulate information and content, enabling numerous applications.","meta":{"url":"http://arxiv.org/abs/2310.17551v1"},"cats":{"benchmark":0.1690724038,"new-dataset":0.0638047772,"data-annotation":0.5213294416,"dev-research":0.1703264106,"llms":0.5244213646,"data-quality":0.0483696833}}
{"text":"However, as these models become increasingly integrated into everyday life, their inherent ethical values and potential biases pose unforeseen risks to society.","meta":{"url":"http://arxiv.org/abs/2310.17551v1"},"cats":{"benchmark":0.2015202199,"new-dataset":0.029466447,"data-annotation":0.5201724009,"dev-research":0.2302974951,"llms":0.5084834915,"data-quality":0.1639969167}}
{"text":"This paper provides an overview of the risks and challenges associated with big models, surveys existing AI ethics guidelines, and examines the ethical implications arising from the limitations of these models.","meta":{"url":"http://arxiv.org/abs/2310.17551v1"},"cats":{"benchmark":0.2019096157,"new-dataset":0.0771974488,"data-annotation":0.5189117243,"dev-research":0.2468443,"llms":0.4933091259,"data-quality":0.1207641923}}
{"text":"Taking a normative ethics perspective, we propose a reassessment of recent normative guidelines, highlighting the importance of collaborative efforts in academia to establish a unified and universal AI ethics framework.","meta":{"url":"http://arxiv.org/abs/2310.17551v1"},"cats":{"benchmark":0.2674219815,"new-dataset":0.0597735515,"data-annotation":0.5051209529,"dev-research":0.3042631918,"llms":0.5097787544,"data-quality":0.1585637595}}
{"text":"Furthermore, we investigate the moral inclinations of current mainstream LLMs using the Moral Foundation theory, analyze existing alignment algorithms, and outline the unique challenges encountered in aligning ethical values within them.","meta":{"url":"http://arxiv.org/abs/2310.17551v1"},"cats":{"benchmark":0.3720052966,"new-dataset":0.0555738228,"data-annotation":0.5103861933,"dev-research":0.1376118238,"llms":0.7015000387,"data-quality":0.1788202597}}
{"text":"To address these challenges, we introduce a novel conceptual paradigm for aligning the ethical values of big models and discuss promising research directions for alignment criteria, evaluation, and method, representing an initial step towards the interdisciplinary construction of the ethically aligned AI   ","meta":{"url":"http://arxiv.org/abs/2310.17551v1"},"cats":{"benchmark":0.2321587354,"new-dataset":0.0727047196,"data-annotation":0.5060787662,"dev-research":0.2236374487,"llms":0.5280211945,"data-quality":0.1105665789}}
{"text":"This paper is a modified English version of our Chinese paper https://crad.ict.ac.cn/cn/article/doi/10.7544/issn1000-1239.202330553, intended to help non-Chinese native speakers better understand our work.","meta":{"url":"http://arxiv.org/abs/2310.17551v1"},"cats":{"benchmark":0.2635452448,"new-dataset":0.2429963479,"data-annotation":0.5189923547,"dev-research":0.2172259591,"llms":0.505291244,"data-quality":0.1490597382}}
{"text":"Neural networks often learn task-specific latent representations that fail to generalize to novel settings or tasks.","meta":{"url":"http://arxiv.org/abs/2310.17550v1"},"cats":{"benchmark":0.1859309008,"new-dataset":0.0112477161,"data-annotation":0.5362175783,"dev-research":0.2242666455,"llms":0.466712548,"data-quality":0.2082755218}}
{"text":"Conversely, humans learn discrete representations (i.e., concepts or words) at a variety of abstraction levels (e.g., ``bird'' vs. ``sparrow'') and deploy the appropriate abstraction based on task.","meta":{"url":"http://arxiv.org/abs/2310.17550v1"},"cats":{"benchmark":0.1196152184,"new-dataset":0.0189164095,"data-annotation":0.5202071381,"dev-research":0.2509612105,"llms":0.5597094121,"data-quality":0.1145604055}}
{"text":"Inspired by this, we train neural models to generate a spectrum of discrete representations, and control the complexity of the representations (roughly, how many bits are allocated for encoding inputs) by tuning the entropy of the distribution over representations.","meta":{"url":"http://arxiv.org/abs/2310.17550v1"},"cats":{"benchmark":0.1752834842,"new-dataset":0.0399709792,"data-annotation":0.5238840857,"dev-research":0.1363944733,"llms":0.5309678739,"data-quality":0.112249806}}
{"text":"In finetuning experiments, using only a small number of labeled examples for a new task, we show that (1) tuning the representation to a task-appropriate complexity level supports the highest finetuning performance, and (2) in a human-participant study, users were able to identify the appropriate complexity level for a downstream task using visualizations of discrete representations.","meta":{"url":"http://arxiv.org/abs/2310.17550v1"},"cats":{"benchmark":0.3307911071,"new-dataset":0.0375755791,"data-annotation":0.5226232419,"dev-research":0.3829507618,"llms":0.5807546786,"data-quality":0.1096413813}}
{"text":"Our results indicate a promising direction for rapid model finetuning by leveraging human insight.","meta":{"url":"http://arxiv.org/abs/2310.17550v1"},"cats":{"benchmark":0.3654421729,"new-dataset":0.0479652479,"data-annotation":0.5130195753,"dev-research":0.3662521509,"llms":0.5240271234,"data-quality":0.1209957026}}
{"text":"Learning schemes for planning and control are limited by the difficulty of collecting large amounts of experimental data or having to rely on high-fidelity simulations.","meta":{"url":"http://arxiv.org/abs/2310.17545v1"},"cats":{"benchmark":0.1904806096,"new-dataset":0.0801484961,"data-annotation":0.4957048058,"dev-research":0.199719724,"llms":0.4877807111,"data-quality":0.0399378584}}
{"text":"This paper explores the potential of a proposed learning scheme that leverages dimensionless numbers based on Buckingham's $\\pi$ theorem to improve data efficiency and facilitate knowledge sharing between similar systems.","meta":{"url":"http://arxiv.org/abs/2310.17545v1"},"cats":{"benchmark":0.2621382862,"new-dataset":0.1434977107,"data-annotation":0.5222588747,"dev-research":0.1535895092,"llms":0.4624275734,"data-quality":0.1059737473}}
{"text":"A case study using car-like robots compares traditional and dimensionless learning models on simulated and experimental data to validate the benefits of the new dimensionless learning approach.","meta":{"url":"http://arxiv.org/abs/2310.17545v1"},"cats":{"benchmark":0.2288092397,"new-dataset":0.0325782672,"data-annotation":0.5137201864,"dev-research":0.1236538867,"llms":0.4839155972,"data-quality":0.0726215317}}
{"text":"Preliminary results show that this new dimensionless approach could accelerate the learning rate and improve the accuracy of the model and should be investigated further.","meta":{"url":"http://arxiv.org/abs/2310.17545v1"},"cats":{"benchmark":0.4906127156,"new-dataset":0.0176376575,"data-annotation":0.5392240438,"dev-research":0.0926973589,"llms":0.3888585103,"data-quality":0.131594752}}
{"text":"We study a novel ensemble approach for feature selection based on hierarchical stacking in cases of non-stationarity and limited number of samples with large number of features.","meta":{"url":"http://arxiv.org/abs/2310.17544v1"},"cats":{"benchmark":0.5104429352,"new-dataset":0.0602540209,"data-annotation":0.5191269431,"dev-research":0.1613030997,"llms":0.371275834,"data-quality":0.1499027954}}
{"text":"Our approach exploits the co-dependency between features using a hierarchical structure.","meta":{"url":"http://arxiv.org/abs/2310.17544v1"},"cats":{"benchmark":0.3865347305,"new-dataset":0.0471134981,"data-annotation":0.5091226857,"dev-research":0.2547745048,"llms":0.4003013389,"data-quality":0.1961853034}}
{"text":"Initially, a machine learning model is trained using a subset of features, and then the model's output is updated using another algorithm with the remaining features to minimize the target loss.","meta":{"url":"http://arxiv.org/abs/2310.17544v1"},"cats":{"benchmark":0.3185580209,"new-dataset":0.0046509397,"data-annotation":0.5108044183,"dev-research":0.3023315898,"llms":0.3626442876,"data-quality":0.1918248902}}
{"text":"This hierarchical structure allows for flexible depth and feature selection.","meta":{"url":"http://arxiv.org/abs/2310.17544v1"},"cats":{"benchmark":0.2575851446,"new-dataset":0.0311574927,"data-annotation":0.4921606108,"dev-research":0.1486078427,"llms":0.4643057939,"data-quality":0.0372692298}}
{"text":"By exploiting feature co-dependency hierarchically, our proposed approach overcomes the limitations of traditional feature selection methods and feature importance scores.","meta":{"url":"http://arxiv.org/abs/2310.17544v1"},"cats":{"benchmark":0.4911919209,"new-dataset":0.0220987714,"data-annotation":0.5174298942,"dev-research":0.2373011608,"llms":0.3800702633,"data-quality":0.1522696361}}
{"text":"The effectiveness of the approach is demonstrated on synthetic and real-life datasets, indicating improved performance with scalability and stability compared to the traditional methods and state-of-the-art approaches.","meta":{"url":"http://arxiv.org/abs/2310.17544v1"},"cats":{"benchmark":0.4449890619,"new-dataset":0.7861349298,"data-annotation":0.4795973947,"dev-research":0.1916898185,"llms":0.381713225,"data-quality":0.1225345582}}
{"text":"To overcome the short flight duration of drones, research on in-flight inductive power transfer has been recognized as an essential solution.","meta":{"url":"http://arxiv.org/abs/2310.17541v1"},"cats":{"benchmark":0.2890949198,"new-dataset":0.0141114285,"data-annotation":0.5271778641,"dev-research":0.2053662666,"llms":0.5473465684,"data-quality":0.1017539173}}
{"text":"Thus, it is important to accurately estimate and control the attitude of the drones which operate close to the charging surface.","meta":{"url":"http://arxiv.org/abs/2310.17541v1"},"cats":{"benchmark":0.3675318639,"new-dataset":0.0159611597,"data-annotation":0.5353149827,"dev-research":0.1824689123,"llms":0.4509326718,"data-quality":0.0994270539}}
{"text":"To this end, this paper proposes an attitude estimation method based solely on the motor current for precision flight control in the ground effect region.","meta":{"url":"http://arxiv.org/abs/2310.17541v1"},"cats":{"benchmark":0.447196782,"new-dataset":0.0592127628,"data-annotation":0.5387276525,"dev-research":0.2178450875,"llms":0.4280942759,"data-quality":0.1414849155}}
{"text":"The model for the estimation is derived based on the motor equation when it rotates at a constant rotational speed.","meta":{"url":"http://arxiv.org/abs/2310.17541v1"},"cats":{"benchmark":0.4102311863,"new-dataset":0.038125922,"data-annotation":0.5401577005,"dev-research":0.1313724125,"llms":0.3900139774,"data-quality":0.0738382177}}
{"text":"The proposed method is verified on the simulations and experiments.","meta":{"url":"http://arxiv.org/abs/2310.17541v1"},"cats":{"benchmark":0.6309560112,"new-dataset":0.0020437552,"data-annotation":0.5247155831,"dev-research":0.0971700052,"llms":0.4799190529,"data-quality":0.0861831538}}
{"text":"It allows simultaneous estimation of altitude and pitch angle with the accuracy of 0.30$\\hspace{0.5mm}$m and 0.04 rad, respectively.","meta":{"url":"http://arxiv.org/abs/2310.17541v1"},"cats":{"benchmark":0.4148232959,"new-dataset":0.0230918029,"data-annotation":0.5038087669,"dev-research":0.1626812572,"llms":0.4726180584,"data-quality":0.0615439333}}
{"text":"The minimum transmission efficiency of the in-flight power transfer system based on the proposed estimation is calculated as 95.3 %, which is sufficient for the efficient system.","meta":{"url":"http://arxiv.org/abs/2310.17541v1"},"cats":{"benchmark":0.5121234255,"new-dataset":0.0087661869,"data-annotation":0.5340790071,"dev-research":0.1542079432,"llms":0.4044469235,"data-quality":0.1178386693}}
{"text":"Forecasting vehicular motions in autonomous driving requires a deep understanding of agent interactions and the preservation of motion equivariance under Euclidean geometric transformations.","meta":{"url":"http://arxiv.org/abs/2310.17540v1"},"cats":{"benchmark":0.2136446559,"new-dataset":0.0634860069,"data-annotation":0.5280472333,"dev-research":0.1512006078,"llms":0.3616782998,"data-quality":0.0545067172}}
{"text":"Traditional models often lack the sophistication needed to handle the intricate dynamics inherent to autonomous vehicles and the interaction relationships among agents in the scene.","meta":{"url":"http://arxiv.org/abs/2310.17540v1"},"cats":{"benchmark":0.1264896308,"new-dataset":0.0217723919,"data-annotation":0.516449882,"dev-research":0.2319791555,"llms":0.4964254398,"data-quality":0.0493715539}}
{"text":"As a result, these models have a lower model capacity, which then leads to higher prediction errors and lower training efficiency.","meta":{"url":"http://arxiv.org/abs/2310.17540v1"},"cats":{"benchmark":0.4204483472,"new-dataset":0.0044748045,"data-annotation":0.5437728656,"dev-research":0.2035309156,"llms":0.4153278719,"data-quality":0.1569134736}}
{"text":"In our research, we employ EqMotion, a leading equivariant particle, and human prediction model that also accounts for invariant agent interactions, for the task of multi-agent vehicle motion forecasting.","meta":{"url":"http://arxiv.org/abs/2310.17540v1"},"cats":{"benchmark":0.2032422474,"new-dataset":0.0979722914,"data-annotation":0.5373516327,"dev-research":0.1203569241,"llms":0.4263164906,"data-quality":0.0431926518}}
{"text":"In addition, we use a multi-modal prediction mechanism to account for multiple possible future paths in a probabilistic manner.","meta":{"url":"http://arxiv.org/abs/2310.17540v1"},"cats":{"benchmark":0.3202421879,"new-dataset":0.0363126168,"data-annotation":0.5372121057,"dev-research":0.1509579658,"llms":0.4507350681,"data-quality":0.0577353234}}
{"text":"By leveraging EqMotion, our model achieves state-of-the-art (SOTA) performance with fewer parameters (1.2 million) and a significantly reduced training time (less than 2 hours).","meta":{"url":"http://arxiv.org/abs/2310.17540v1"},"cats":{"benchmark":0.3267281994,"new-dataset":0.053400739,"data-annotation":0.5186280942,"dev-research":0.1036359271,"llms":0.5630371756,"data-quality":0.0521520565}}
{"text":"The prevailing principle of \"Optimism in the Face of Uncertainty\" advocates for the incorporation of an exploration bonus, generally assumed to be proportional to the inverse square root of the visit count ($1/\\sqrt{n}$), where $n$ is the number of visits to a particular state-action pair.","meta":{"url":"http://arxiv.org/abs/2310.17538v1"},"cats":{"benchmark":0.3052014035,"new-dataset":0.0060482893,"data-annotation":0.5264961671,"dev-research":0.2019628723,"llms":0.4624961992,"data-quality":0.0771104674}}
{"text":"This approach, however, exclusively focuses on \"uncertainty,\" neglecting the inherent \"difficulty\" of different options.","meta":{"url":"http://arxiv.org/abs/2310.17538v1"},"cats":{"benchmark":0.388770537,"new-dataset":0.0009158772,"data-annotation":0.4862130082,"dev-research":0.3124356938,"llms":0.4520618781,"data-quality":0.1174927121}}
{"text":"To address this gap, we introduce a novel modification of standard UCB algorithm in the multi-armed bandit problem, proposing an adjusted bonus term of $1/n^\\tau$, where $\\tau > 1/2$, that accounts for task difficulty.","meta":{"url":"http://arxiv.org/abs/2310.17538v1"},"cats":{"benchmark":0.5112455206,"new-dataset":0.0250881298,"data-annotation":0.5687207571,"dev-research":0.1605148206,"llms":0.4220739217,"data-quality":0.1485201413}}
{"text":"Our proposed algorithm, denoted as UCB$^\\tau$, is substantiated through comprehensive regret and risk analyses, confirming its theoretical robustness.","meta":{"url":"http://arxiv.org/abs/2310.17538v1"},"cats":{"benchmark":0.6038297797,"new-dataset":0.0156847265,"data-annotation":0.5490277278,"dev-research":0.142915311,"llms":0.3970254736,"data-quality":0.1289425253}}
{"text":"Comparative evaluations with standard UCB and Thompson Sampling algorithms on synthetic datasets demonstrate that UCB$^\\tau$ not only outperforms in efficacy but also exhibits lower risk across various environmental conditions and hyperparameter settings.","meta":{"url":"http://arxiv.org/abs/2310.17538v1"},"cats":{"benchmark":0.5102695701,"new-dataset":0.1120516259,"data-annotation":0.5136267816,"dev-research":0.1674438874,"llms":0.4462253198,"data-quality":0.1141952616}}
{"text":"Deep reinforcement learning methods exhibit impressive performance on a range of tasks but still struggle on hard exploration tasks in large environments with sparse rewards.","meta":{"url":"http://arxiv.org/abs/2310.17537v1"},"cats":{"benchmark":0.3178606464,"new-dataset":0.027019166,"data-annotation":0.5080753564,"dev-research":0.1347164198,"llms":0.4994668726,"data-quality":0.0806390442}}
{"text":"To address this, intrinsic rewards can be generated using forward model prediction errors that decrease as the environment becomes known, and incentivize an agent to explore novel states.","meta":{"url":"http://arxiv.org/abs/2310.17537v1"},"cats":{"benchmark":0.1936174757,"new-dataset":0.0144782424,"data-annotation":0.5442328444,"dev-research":0.1621828723,"llms":0.4540713529,"data-quality":0.0806443925}}
{"text":"While prediction-based intrinsic rewards can help agents solve hard exploration tasks, they can suffer from catastrophic forgetting and actually increase at visited states.","meta":{"url":"http://arxiv.org/abs/2310.17537v1"},"cats":{"benchmark":0.2390864725,"new-dataset":0.013479888,"data-annotation":0.5270074414,"dev-research":0.1620545855,"llms":0.4947591673,"data-quality":0.0640966846}}
{"text":"We first examine the conditions and causes of catastrophic forgetting in grid world environments.","meta":{"url":"http://arxiv.org/abs/2310.17537v1"},"cats":{"benchmark":0.2760713376,"new-dataset":0.0550808725,"data-annotation":0.4938531353,"dev-research":0.239828,"llms":0.5759028987,"data-quality":0.1368006561}}
{"text":"We then propose a new method FARCuriosity, inspired by how humans and animals learn.","meta":{"url":"http://arxiv.org/abs/2310.17537v1"},"cats":{"benchmark":0.1898099966,"new-dataset":0.0250573641,"data-annotation":0.5335266354,"dev-research":0.1583374981,"llms":0.5631867647,"data-quality":0.0898664284}}
{"text":"The method depends on fragmentation and recall: an agent fragments an environment based on surprisal, and uses different local curiosity modules (prediction-based intrinsic reward functions) for each fragment so that modules are not trained on the entire environment.","meta":{"url":"http://arxiv.org/abs/2310.17537v1"},"cats":{"benchmark":0.2307867091,"new-dataset":0.0276835861,"data-annotation":0.5350119996,"dev-research":0.0994417174,"llms":0.5363364488,"data-quality":0.0477178044}}
{"text":"At each fragmentation event, the agent stores the current module in long-term memory (LTM) and either initializes a new module or recalls a previously stored module based on its match with the current state.","meta":{"url":"http://arxiv.org/abs/2310.17537v1"},"cats":{"benchmark":0.2140513925,"new-dataset":0.0629302869,"data-annotation":0.4911994286,"dev-research":0.1476933117,"llms":0.6060409279,"data-quality":0.0608874421}}
{"text":"With fragmentation and recall, FARCuriosity achieves less forgetting and better overall performance in games with varied and heterogeneous environments in the Atari benchmark suite of tasks.","meta":{"url":"http://arxiv.org/abs/2310.17537v1"},"cats":{"benchmark":0.3419837231,"new-dataset":0.0399049285,"data-annotation":0.5112717651,"dev-research":0.1645328508,"llms":0.5856338577,"data-quality":0.0686955784}}
{"text":"Thus, this work highlights the problem of catastrophic forgetting in prediction-based curiosity methods and proposes a solution.","meta":{"url":"http://arxiv.org/abs/2310.17537v1"},"cats":{"benchmark":0.2612546508,"new-dataset":0.026447849,"data-annotation":0.5325682502,"dev-research":0.1465545046,"llms":0.4889502409,"data-quality":0.1460658477}}
{"text":"Numerous works study black-box attacks on image classifiers.","meta":{"url":"http://arxiv.org/abs/2310.17534v1"},"cats":{"benchmark":0.3430686432,"new-dataset":0.0241002369,"data-annotation":0.5428297783,"dev-research":0.1642698924,"llms":0.447496531,"data-quality":0.3207280176}}
{"text":"However, these works make different assumptions on the adversary's knowledge and current literature lacks a cohesive organization centered around the threat model.","meta":{"url":"http://arxiv.org/abs/2310.17534v1"},"cats":{"benchmark":0.2510213998,"new-dataset":0.0063178676,"data-annotation":0.5155668255,"dev-research":0.2303176702,"llms":0.4830147893,"data-quality":0.1630813632}}
{"text":"To systematize knowledge in this area, we propose a taxonomy over the threat space spanning the axes of feedback granularity, the access of interactive queries, and the quality and quantity of the auxiliary data available to the attacker.","meta":{"url":"http://arxiv.org/abs/2310.17534v1"},"cats":{"benchmark":0.2164123763,"new-dataset":0.2797295385,"data-annotation":0.4947997286,"dev-research":0.3450757503,"llms":0.5599832086,"data-quality":0.1338645388}}
{"text":"Our new taxonomy provides three key insights.","meta":{"url":"http://arxiv.org/abs/2310.17534v1"},"cats":{"benchmark":0.2893237635,"new-dataset":0.211957448,"data-annotation":0.5041905884,"dev-research":0.235788579,"llms":0.5130557484,"data-quality":0.1130487972}}
{"text":"1) Despite extensive literature, numerous under-explored threat spaces exist, which cannot be trivially solved by adapting techniques from well-explored settings.","meta":{"url":"http://arxiv.org/abs/2310.17534v1"},"cats":{"benchmark":0.2110847415,"new-dataset":0.0415079779,"data-annotation":0.5194717567,"dev-research":0.2901551185,"llms":0.5304819631,"data-quality":0.1445279426}}
{"text":"We demonstrate this by establishing a new state-of-the-art in the less-studied setting of access to top-k confidence scores by adapting techniques from well-explored settings of accessing the complete confidence vector, but show how it still falls short of the more restrictive setting that only obtains the prediction label, highlighting the need for more research.","meta":{"url":"http://arxiv.org/abs/2310.17534v1"},"cats":{"benchmark":0.499641759,"new-dataset":0.0538208367,"data-annotation":0.521148131,"dev-research":0.1506939511,"llms":0.4087803263,"data-quality":0.1364344775}}
{"text":"2) Identification the threat model of different attacks uncovers stronger baselines that challenge prior state-of-the-art claims.","meta":{"url":"http://arxiv.org/abs/2310.17534v1"},"cats":{"benchmark":0.5117021647,"new-dataset":0.0119053446,"data-annotation":0.517384774,"dev-research":0.2342399908,"llms":0.4397777568,"data-quality":0.1583266151}}
{"text":"We demonstrate this by enhancing an initially weaker baseline (under interactive query access) via surrogate models, effectively overturning claims in the respective paper.","meta":{"url":"http://arxiv.org/abs/2310.17534v1"},"cats":{"benchmark":0.5683964992,"new-dataset":0.0433309323,"data-annotation":0.4991008029,"dev-research":0.1736786389,"llms":0.4433183202,"data-quality":0.1365586824}}
{"text":"3)","meta":{"url":"http://arxiv.org/abs/2310.17534v1"},"cats":{"benchmark":0.2342303425,"new-dataset":0.4889406001,"data-annotation":0.5068645357,"dev-research":0.1950916541,"llms":0.5163904821,"data-quality":0.1775578265}}
{"text":"Our taxonomy reveals interactions between attacker knowledge that connect well to related areas, such as model inversion and extraction attacks.","meta":{"url":"http://arxiv.org/abs/2310.17534v1"},"cats":{"benchmark":0.2282758938,"new-dataset":0.0879180806,"data-annotation":0.5210022652,"dev-research":0.2924894042,"llms":0.5360825534,"data-quality":0.1862690038}}
{"text":"We discuss how advances in other areas can enable potentially stronger black-box attacks.","meta":{"url":"http://arxiv.org/abs/2310.17534v1"},"cats":{"benchmark":0.301867113,"new-dataset":0.0076057922,"data-annotation":0.5128895473,"dev-research":0.2175696039,"llms":0.544044254,"data-quality":0.0902560049}}
{"text":"Finally, we emphasize the need for a more realistic assessment of attack success by factoring in local attack runtime.","meta":{"url":"http://arxiv.org/abs/2310.17534v1"},"cats":{"benchmark":0.5554634087,"new-dataset":0.0107524461,"data-annotation":0.5318088654,"dev-research":0.2830890596,"llms":0.4706624062,"data-quality":0.0961140563}}
{"text":"This approach reveals the potential for certain attacks to achieve notably higher success rates and the need to evaluate attacks in diverse and harder settings, highlighting the need for better selection criteria.","meta":{"url":"http://arxiv.org/abs/2310.17534v1"},"cats":{"benchmark":0.50931326,"new-dataset":0.0040410386,"data-annotation":0.51768179,"dev-research":0.2497048111,"llms":0.5338043381,"data-quality":0.0931398569}}
{"text":"Educational disparities within the Dominican Republic (DR) have long-standing origins rooted in economic, political, and social inequity.","meta":{"url":"http://arxiv.org/abs/2310.17533v1"},"cats":{"benchmark":0.274551371,"new-dataset":0.0721917115,"data-annotation":0.5123792796,"dev-research":0.1596194758,"llms":0.5329736615,"data-quality":0.0811936791}}
{"text":"Addressing these challenges has necessarily called for capacity building with respect to educational materials, high-quality instruction, and structural resourcing.","meta":{"url":"http://arxiv.org/abs/2310.17533v1"},"cats":{"benchmark":0.2126454815,"new-dataset":0.0752262992,"data-annotation":0.4923892325,"dev-research":0.2600177277,"llms":0.5650186639,"data-quality":0.0751943103}}
{"text":"Generative AI tools like ChatGPT have begun to pique the interest of Dominican educators due to their perceived potential to bridge these educational gaps.","meta":{"url":"http://arxiv.org/abs/2310.17533v1"},"cats":{"benchmark":0.1611838751,"new-dataset":0.056559127,"data-annotation":0.5275031379,"dev-research":0.2307352153,"llms":0.5991397177,"data-quality":0.0936227379}}
{"text":"However, a substantial body of AI fairness literature has documented ways AI disproportionately reinforces power dynamics reflective of jurisdictions driving AI development and deployment policies, collectively termed the AI Global North.","meta":{"url":"http://arxiv.org/abs/2310.17533v1"},"cats":{"benchmark":0.2740755037,"new-dataset":0.0361089039,"data-annotation":0.4927951979,"dev-research":0.2929639826,"llms":0.522801182,"data-quality":0.1401800484}}
{"text":"As such, indiscriminate adoption of this technology for DR education, even in part, risks perpetuating forms of digital coloniality.","meta":{"url":"http://arxiv.org/abs/2310.17533v1"},"cats":{"benchmark":0.1374676103,"new-dataset":0.0242452943,"data-annotation":0.4842512605,"dev-research":0.2301556353,"llms":0.608822897,"data-quality":0.1222758759}}
{"text":"Therefore, this paper centers embracing AI-facilitated educational reform by critically examining how AI-driven tools like ChatGPT in DR education may replicate facets of digital colonialism.","meta":{"url":"http://arxiv.org/abs/2310.17533v1"},"cats":{"benchmark":0.1209378677,"new-dataset":0.1262721486,"data-annotation":0.4958966115,"dev-research":0.3018197723,"llms":0.5739997943,"data-quality":0.1188283115}}
{"text":"We provide a concise overview of 20th-century Dominican education reforms following the 1916 US occupation.","meta":{"url":"http://arxiv.org/abs/2310.17533v1"},"cats":{"benchmark":0.2387564335,"new-dataset":0.1085319957,"data-annotation":0.5157841177,"dev-research":0.1683209585,"llms":0.5448594124,"data-quality":0.1073851017}}
{"text":"Then, we employ identified neocolonial aspects historically shaping Dominican education to interrogate the perceived advantages of ChatGPT for contemporary Dominican education, as outlined by a Dominican scholar.","meta":{"url":"http://arxiv.org/abs/2310.17533v1"},"cats":{"benchmark":0.1928565855,"new-dataset":0.0696391133,"data-annotation":0.5146679768,"dev-research":0.2026755567,"llms":0.5896760515,"data-quality":0.0921992377}}
{"text":"This work invites AI Global North & South developers, stakeholders, and Dominican leaders alike to exercise a relational contextualization of data-centric epistemologies like ChatGPT to reap its transformative benefits while remaining vigilant of safeguarding Dominican digital sovereignty.","meta":{"url":"http://arxiv.org/abs/2310.17533v1"},"cats":{"benchmark":0.1303331081,"new-dataset":0.5677462022,"data-annotation":0.4688147836,"dev-research":0.358205182,"llms":0.6203334149,"data-quality":0.1691110704}}
{"text":"We describe a method to achieve distributed consensus in a Content Centric Network using the PAXOS algorithm.","meta":{"url":"http://arxiv.org/abs/2310.17532v1"},"cats":{"benchmark":0.3976656615,"new-dataset":0.0745991622,"data-annotation":0.4869725839,"dev-research":0.149614133,"llms":0.5056220328,"data-quality":0.1407742444}}
{"text":"Consensus is necessary, for example, if multiple writers wish to agree on the current version number of a CCNx name or if multiple distributed systems wish to elect a leader for fast transaction processing.","meta":{"url":"http://arxiv.org/abs/2310.17532v1"},"cats":{"benchmark":0.3699625591,"new-dataset":0.0245411426,"data-annotation":0.4586549356,"dev-research":0.2648028935,"llms":0.5760238483,"data-quality":0.1598182745}}
{"text":"We describe two forms of protocols, one using standard CCNx Interest request and Content Object response, and the second using a CCNx Push request and response.","meta":{"url":"http://arxiv.org/abs/2310.17532v1"},"cats":{"benchmark":0.2180198929,"new-dataset":0.054932755,"data-annotation":0.4791068414,"dev-research":0.1398167519,"llms":0.6017743331,"data-quality":0.0893736202}}
{"text":"We further divide the protocols in to those using the CCNx 0.x protocol where Content Object name may continue Interest names and the CCNx 1.0 protocol where Content Object names exactly match Interest names.","meta":{"url":"http://arxiv.org/abs/2310.17532v1"},"cats":{"benchmark":0.2389208712,"new-dataset":0.0971833426,"data-annotation":0.4846887422,"dev-research":0.1209952749,"llms":0.6092714278,"data-quality":0.1774408348}}
{"text":"We design and analyze reinforcement learning algorithms for Graphon Mean-Field Games (GMFGs).","meta":{"url":"http://arxiv.org/abs/2310.17531v1"},"cats":{"benchmark":0.2458533632,"new-dataset":0.0702120622,"data-annotation":0.5174014663,"dev-research":0.1238498096,"llms":0.4815050906,"data-quality":0.0655277922}}
{"text":"In contrast to previous works that require the precise values of the graphons, we aim to learn the Nash Equilibrium (NE) of the regularized GMFGs when the graphons are unknown.","meta":{"url":"http://arxiv.org/abs/2310.17531v1"},"cats":{"benchmark":0.2969120207,"new-dataset":0.0384089119,"data-annotation":0.5312015257,"dev-research":0.1002031387,"llms":0.4286812403,"data-quality":0.1521850507}}
{"text":"Our contributions are threefold.","meta":{"url":"http://arxiv.org/abs/2310.17531v1"},"cats":{"benchmark":0.255611385,"new-dataset":0.1250766625,"data-annotation":0.5132708585,"dev-research":0.1891882643,"llms":0.5247845963,"data-quality":0.0853586105}}
{"text":"First, we propose the Proximal Policy Optimization for GMFG (GMFG-PPO) algorithm and show that it converges at a rate of $O(T^{-1/3})$ after $T$ iterations with an estimation oracle, improving on a previous work by Xie et al.","meta":{"url":"http://arxiv.org/abs/2310.17531v1"},"cats":{"benchmark":0.4950496385,"new-dataset":0.0183447351,"data-annotation":0.5135658426,"dev-research":0.1021305142,"llms":0.412368023,"data-quality":0.0650837433}}
{"text":"(ICML, 2021).","meta":{"url":"http://arxiv.org/abs/2310.17531v1"},"cats":{"benchmark":0.2789761304,"new-dataset":0.4667489108,"data-annotation":0.4988524336,"dev-research":0.1893560072,"llms":0.5823373404,"data-quality":0.1514858986}}
{"text":"Second, using kernel embedding of distributions, we design efficient algorithms to estimate the transition kernels, reward functions, and graphons from sampled agents.","meta":{"url":"http://arxiv.org/abs/2310.17531v1"},"cats":{"benchmark":0.4013897056,"new-dataset":0.0935887795,"data-annotation":0.5419290871,"dev-research":0.0841030302,"llms":0.4024681038,"data-quality":0.1365269771}}
{"text":"Convergence rates are then derived when the positions of the agents are either known or unknown.","meta":{"url":"http://arxiv.org/abs/2310.17531v1"},"cats":{"benchmark":0.3933988098,"new-dataset":0.0198974597,"data-annotation":0.5338954176,"dev-research":0.0929523756,"llms":0.4284916897,"data-quality":0.0677630049}}
{"text":"Results for the combination of the optimization algorithm GMFG-PPO and the estimation algorithm are then provided.","meta":{"url":"http://arxiv.org/abs/2310.17531v1"},"cats":{"benchmark":0.5274317196,"new-dataset":0.0265715366,"data-annotation":0.5242453974,"dev-research":0.0883874217,"llms":0.3234495818,"data-quality":0.0651592994}}
{"text":"These algorithms are the first specifically designed for learning graphons from sampled agents.","meta":{"url":"http://arxiv.org/abs/2310.17531v1"},"cats":{"benchmark":0.3346810603,"new-dataset":0.1472391354,"data-annotation":0.5331120423,"dev-research":0.1063298553,"llms":0.451075567,"data-quality":0.1307984694}}
{"text":"Finally, the efficacy of the proposed algorithms are corroborated through simulations.","meta":{"url":"http://arxiv.org/abs/2310.17531v1"},"cats":{"benchmark":0.6602528293,"new-dataset":0.0061108461,"data-annotation":0.5241655456,"dev-research":0.122869981,"llms":0.4204800227,"data-quality":0.1405433711}}
{"text":"These simulations demonstrate that learning the unknown graphons reduces the exploitability effectively.","meta":{"url":"http://arxiv.org/abs/2310.17531v1"},"cats":{"benchmark":0.2637779561,"new-dataset":0.0205579435,"data-annotation":0.5297387409,"dev-research":0.1604914982,"llms":0.4844733933,"data-quality":0.1642502081}}
{"text":"Pretrained machine learning models are known to perpetuate and even amplify existing biases in data, which can result in unfair outcomes that ultimately impact user experience.","meta":{"url":"http://arxiv.org/abs/2310.17530v1"},"cats":{"benchmark":0.3576536802,"new-dataset":0.0130122982,"data-annotation":0.5173225225,"dev-research":0.2678798917,"llms":0.478635862,"data-quality":0.2214918509}}
{"text":"Therefore, it is crucial to understand the mechanisms behind those prejudicial biases to ensure that model performance does not result in discriminatory behaviour toward certain groups or populations.","meta":{"url":"http://arxiv.org/abs/2310.17530v1"},"cats":{"benchmark":0.3945901339,"new-dataset":0.0016270286,"data-annotation":0.5292814752,"dev-research":0.1757527766,"llms":0.4957982496,"data-quality":0.1110574507}}
{"text":"In this work, we define gender bias as our case study.","meta":{"url":"http://arxiv.org/abs/2310.17530v1"},"cats":{"benchmark":0.3364983886,"new-dataset":0.0276871459,"data-annotation":0.5231637795,"dev-research":0.2512134423,"llms":0.4842198456,"data-quality":0.1435265943}}
{"text":"We quantify bias amplification in pretraining and after fine-tuning on three families of vision-and-language models.","meta":{"url":"http://arxiv.org/abs/2310.17530v1"},"cats":{"benchmark":0.3265419816,"new-dataset":0.0441279108,"data-annotation":0.5483405976,"dev-research":0.1660272317,"llms":0.4621113852,"data-quality":0.2786252637}}
{"text":"We investigate the connection, if any, between the two learning stages, and evaluate how bias amplification reflects on model performance.","meta":{"url":"http://arxiv.org/abs/2310.17530v1"},"cats":{"benchmark":0.47982645,"new-dataset":0.0074772759,"data-annotation":0.5276306342,"dev-research":0.1113072031,"llms":0.4104440834,"data-quality":0.1857601048}}
{"text":"Overall, we find that bias amplification in pretraining and after fine-tuning are independent.","meta":{"url":"http://arxiv.org/abs/2310.17530v1"},"cats":{"benchmark":0.4365093379,"new-dataset":0.0115217454,"data-annotation":0.5289600845,"dev-research":0.133104012,"llms":0.4609534386,"data-quality":0.2073305407}}
{"text":"We then examine the effect of continued pretraining on gender-neutral data, finding that this reduces group disparities, i.e., promotes fairness, on VQAv2 and retrieval tasks without significantly compromising task performance.","meta":{"url":"http://arxiv.org/abs/2310.17530v1"},"cats":{"benchmark":0.3574633541,"new-dataset":0.0121599628,"data-annotation":0.5169774689,"dev-research":0.1747510337,"llms":0.498137402,"data-quality":0.1157739443}}
{"text":"In this paper, we propose the Masked Space-Time Hash encoding (MSTH), a novel method for efficiently reconstructing dynamic 3D scenes from multi-view or monocular videos.","meta":{"url":"http://arxiv.org/abs/2310.17527v1"},"cats":{"benchmark":0.3059501082,"new-dataset":0.1209248015,"data-annotation":0.5046600449,"dev-research":0.1491447009,"llms":0.438009667,"data-quality":0.0853116173}}
{"text":"Based on the observation that dynamic scenes often contain substantial static areas that result in redundancy in storage and computations, MSTH represents a dynamic scene as a weighted combination of a 3D hash encoding and a 4D hash encoding.","meta":{"url":"http://arxiv.org/abs/2310.17527v1"},"cats":{"benchmark":0.2839432296,"new-dataset":0.1057493862,"data-annotation":0.5023497086,"dev-research":0.18117927,"llms":0.5183977459,"data-quality":0.0947415348}}
{"text":"The weights for the two components are represented by a learnable mask which is guided by an uncertainty-based objective to reflect the spatial and temporal importance of each 3D position.","meta":{"url":"http://arxiv.org/abs/2310.17527v1"},"cats":{"benchmark":0.3114226712,"new-dataset":0.023577532,"data-annotation":0.5239195164,"dev-research":0.1400084686,"llms":0.3841343422,"data-quality":0.0801079627}}
{"text":"With this design, our method can reduce the hash collision rate by avoiding redundant queries and modifications on static areas, making it feasible to represent a large number of space-time voxels by hash tables with small size.","meta":{"url":"http://arxiv.org/abs/2310.17527v1"},"cats":{"benchmark":0.4189927603,"new-dataset":0.1735243463,"data-annotation":0.4944251446,"dev-research":0.1861940279,"llms":0.5424080195,"data-quality":0.0765549259}}
{"text":"Besides, without the requirements to fit the large numbers of temporally redundant features independently, our method is easier to optimize and converge rapidly with only twenty minutes of training for a 300-frame dynamic scene.","meta":{"url":"http://arxiv.org/abs/2310.17527v1"},"cats":{"benchmark":0.3319982162,"new-dataset":0.0987856715,"data-annotation":0.519436208,"dev-research":0.1783006201,"llms":0.3948207167,"data-quality":0.1067663638}}
{"text":"As a result, MSTH obtains consistently better results than previous methods with only 20 minutes of training time and 130 MB of memory storage.","meta":{"url":"http://arxiv.org/abs/2310.17527v1"},"cats":{"benchmark":0.579712787,"new-dataset":0.0215215439,"data-annotation":0.5259597458,"dev-research":0.19520053,"llms":0.5243544936,"data-quality":0.120279408}}
{"text":"Code is available at https://github.com/masked-spacetime-hashing/msth","meta":{"url":"http://arxiv.org/abs/2310.17527v1"},"cats":{"benchmark":0.3758308242,"new-dataset":0.0877021452,"data-annotation":0.5346936245,"dev-research":0.1248339679,"llms":0.5343588942,"data-quality":0.132543475}}
{"text":"Systematic reviews are vital for guiding practice, research, and policy, yet they are often slow and labour-intensive.","meta":{"url":"http://arxiv.org/abs/2310.17526v1"},"cats":{"benchmark":0.4996248672,"new-dataset":0.0092954562,"data-annotation":0.4992346438,"dev-research":0.4269679572,"llms":0.5400744911,"data-quality":0.107129798}}
{"text":"Large language models (LLMs) could offer a way to speed up and automate systematic reviews, but their performance in such tasks has not been comprehensively evaluated against humans, and no study has tested GPT-4, the biggest LLM so far.","meta":{"url":"http://arxiv.org/abs/2310.17526v1"},"cats":{"benchmark":0.391656032,"new-dataset":0.0534049033,"data-annotation":0.5263659218,"dev-research":0.2502159006,"llms":0.7097471333,"data-quality":0.1330589241}}
{"text":"This pre-registered study evaluates GPT-4's capability in title/abstract screening, full-text review, and data extraction across various literature types and languages using a 'human-out-of-the-loop' approach.","meta":{"url":"http://arxiv.org/abs/2310.17526v1"},"cats":{"benchmark":0.402965898,"new-dataset":0.1094849176,"data-annotation":0.5127364426,"dev-research":0.2198670354,"llms":0.4759973945,"data-quality":0.162469323}}
{"text":"Although GPT-4 had accuracy on par with human performance in most tasks, results were skewed by chance agreement and dataset imbalance.","meta":{"url":"http://arxiv.org/abs/2310.17526v1"},"cats":{"benchmark":0.5594909314,"new-dataset":0.0257015928,"data-annotation":0.5238461623,"dev-research":0.1868217994,"llms":0.4606521472,"data-quality":0.2238077304}}
{"text":"After adjusting for these, there was a moderate level of performance for data extraction, and - barring studies that used highly reliable prompts - screening performance levelled at none to moderate for different stages and languages.","meta":{"url":"http://arxiv.org/abs/2310.17526v1"},"cats":{"benchmark":0.5709842895,"new-dataset":0.0245410606,"data-annotation":0.484543212,"dev-research":0.2224501265,"llms":0.5211713852,"data-quality":0.2500147002}}
{"text":"When screening full-text literature using highly reliable prompts, GPT-4's performance was 'almost perfect.'","meta":{"url":"http://arxiv.org/abs/2310.17526v1"},"cats":{"benchmark":0.520845431,"new-dataset":0.0184829114,"data-annotation":0.5269298698,"dev-research":0.1535894861,"llms":0.4983800684,"data-quality":0.1979569606}}
{"text":"Penalising GPT-4 for missing key studies using highly reliable prompts improved its performance even more.","meta":{"url":"http://arxiv.org/abs/2310.17526v1"},"cats":{"benchmark":0.5247375703,"new-dataset":0.0192802503,"data-annotation":0.4959343083,"dev-research":0.2068744204,"llms":0.4997042052,"data-quality":0.1677855575}}
{"text":"Our findings indicate that, currently, substantial caution should be used if LLMs are being used to conduct systematic reviews, but suggest that, for certain systematic review tasks delivered under reliable prompts, LLMs can rival human performance.","meta":{"url":"http://arxiv.org/abs/2310.17526v1"},"cats":{"benchmark":0.4597301579,"new-dataset":0.0089102198,"data-annotation":0.4875122066,"dev-research":0.3522715611,"llms":0.7757488304,"data-quality":0.1690408495}}
{"text":"Our goal is to efficiently learn personalized animatable 3D head avatars from videos that are geometrically accurate, realistic, relightable, and compatible with current rendering systems.","meta":{"url":"http://arxiv.org/abs/2310.17519v1"},"cats":{"benchmark":0.2550724352,"new-dataset":0.2819330114,"data-annotation":0.5259287684,"dev-research":0.1699185041,"llms":0.4579847635,"data-quality":0.0896254961}}
{"text":"While 3D meshes enable efficient processing and are highly portable, they lack realism in terms of shape and appearance.","meta":{"url":"http://arxiv.org/abs/2310.17519v1"},"cats":{"benchmark":0.2418420296,"new-dataset":0.0072791469,"data-annotation":0.5121802771,"dev-research":0.2671803168,"llms":0.4809126564,"data-quality":0.0534071873}}
{"text":"Neural representations, on the other hand, are realistic but lack compatibility and are slow to train and render.","meta":{"url":"http://arxiv.org/abs/2310.17519v1"},"cats":{"benchmark":0.2019727274,"new-dataset":0.0114594628,"data-annotation":0.5290357951,"dev-research":0.199216436,"llms":0.5109911268,"data-quality":0.1279571914}}
{"text":"Our key insight is that it is possible to efficiently learn high-fidelity 3D mesh representations via differentiable rendering by exploiting highly-optimized methods from traditional computer graphics and approximating some of the components with neural networks.","meta":{"url":"http://arxiv.org/abs/2310.17519v1"},"cats":{"benchmark":0.2643713299,"new-dataset":0.0624017077,"data-annotation":0.5222712681,"dev-research":0.194570227,"llms":0.4639459377,"data-quality":0.0536445033}}
{"text":"To that end, we introduce \\moniker, a technique that enables the creation of animatable and relightable mesh avatars from a single monocular video.","meta":{"url":"http://arxiv.org/abs/2310.17519v1"},"cats":{"benchmark":0.2258804405,"new-dataset":0.2765312379,"data-annotation":0.5038140315,"dev-research":0.2464793299,"llms":0.5260014724,"data-quality":0.1169878098}}
{"text":"First, we learn a canonical geometry using a mesh representation, enabling efficient differentiable rasterization and straightforward animation via learned blendshapes and linear blend skinning weights.","meta":{"url":"http://arxiv.org/abs/2310.17519v1"},"cats":{"benchmark":0.2370263098,"new-dataset":0.1933826759,"data-annotation":0.5221625242,"dev-research":0.1696994784,"llms":0.4396067905,"data-quality":0.0540066051}}
{"text":"Second, we follow physically-based rendering and factor observed colors into intrinsic albedo, roughness, and a neural representation of the illumination, allowing the learned avatars to be relit in novel scenes.","meta":{"url":"http://arxiv.org/abs/2310.17519v1"},"cats":{"benchmark":0.2079220884,"new-dataset":0.1291002947,"data-annotation":0.5265328921,"dev-research":0.1911651592,"llms":0.4452709604,"data-quality":0.0866164058}}
{"text":"Since our input videos are captured on a single device with a narrow field of view, modeling the surrounding environment light is non-trivial.","meta":{"url":"http://arxiv.org/abs/2310.17519v1"},"cats":{"benchmark":0.268857897,"new-dataset":0.063631443,"data-annotation":0.5209688353,"dev-research":0.1651717361,"llms":0.4285243736,"data-quality":0.0838980394}}
{"text":"Based on the split-sum approximation for modeling specular reflections, we address this by approximating the pre-filtered environment map with a multi-layer perceptron (MLP) modulated by the surface roughness, eliminating the need to explicitly model the light.","meta":{"url":"http://arxiv.org/abs/2310.17519v1"},"cats":{"benchmark":0.4520406492,"new-dataset":0.0593763163,"data-annotation":0.5226635801,"dev-research":0.1662063912,"llms":0.4435667949,"data-quality":0.0781246418}}
{"text":"We demonstrate that our mesh-based avatar formulation, combined with learned deformation, material, and lighting MLPs, produces avatars with high-quality geometry and appearance, while also being efficient to train and render compared to existing approaches.","meta":{"url":"http://arxiv.org/abs/2310.17519v1"},"cats":{"benchmark":0.2364179286,"new-dataset":0.1509480622,"data-annotation":0.5062681539,"dev-research":0.2151536925,"llms":0.494085197,"data-quality":0.0585347797}}
{"text":"NLP models have progressed drastically in recent years, according to numerous datasets proposed to evaluate performance.","meta":{"url":"http://arxiv.org/abs/2310.17514v1"},"cats":{"benchmark":0.4325352099,"new-dataset":0.1326620592,"data-annotation":0.5244108303,"dev-research":0.1966433181,"llms":0.4503981305,"data-quality":0.2434913951}}
{"text":"Questions remain, however, about how particular dataset design choices may impact the conclusions we draw about model capabilities.","meta":{"url":"http://arxiv.org/abs/2310.17514v1"},"cats":{"benchmark":0.2522309713,"new-dataset":0.072613071,"data-annotation":0.4619493611,"dev-research":0.1989930305,"llms":0.493002886,"data-quality":0.0667510319}}
{"text":"In this work, we investigate this question in the domain of compositional generalization.","meta":{"url":"http://arxiv.org/abs/2310.17514v1"},"cats":{"benchmark":0.2780866589,"new-dataset":0.0094286369,"data-annotation":0.5384291796,"dev-research":0.1631784754,"llms":0.4842848368,"data-quality":0.1723054297}}
{"text":"We examine the performance of six modeling approaches across 4 datasets, split according to 8 compositional splitting strategies, ranking models by 18 compositional generalization splits in total.","meta":{"url":"http://arxiv.org/abs/2310.17514v1"},"cats":{"benchmark":0.4323491476,"new-dataset":0.0439700499,"data-annotation":0.5107217491,"dev-research":0.1427364137,"llms":0.4511717134,"data-quality":0.1257674259}}
{"text":"Our results show that: i) the datasets, although all designed to evaluate compositional generalization, rank modeling approaches differently; ii) datasets generated by humans align better with each other than they with synthetic datasets, or than synthetic datasets among themselves; iii) generally, whether datasets are sampled from the same source is more predictive of the resulting model ranking than whether they maintain the same interpretation of compositionality; and iv) which lexical items are used in the data can strongly impact conclusions.","meta":{"url":"http://arxiv.org/abs/2310.17514v1"},"cats":{"benchmark":0.4352526747,"new-dataset":0.1271111075,"data-annotation":0.5239757269,"dev-research":0.1817828157,"llms":0.5015100805,"data-quality":0.3140878916}}
{"text":"Overall, our results demonstrate that much work remains to be done when it comes to assessing whether popular evaluation datasets measure what they intend to measure, and suggest that elucidating more rigorous standards for establishing the validity of evaluation sets could benefit the field.","meta":{"url":"http://arxiv.org/abs/2310.17514v1"},"cats":{"benchmark":0.602554361,"new-dataset":0.1433505479,"data-annotation":0.513180322,"dev-research":0.2679070372,"llms":0.5311780977,"data-quality":0.2446744907}}
{"text":"Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method that leverages low-rank adaptation of weight matrices, has emerged as a prevalent technique for fine-tuning pre-trained models such as large language models and diffusion models.","meta":{"url":"http://arxiv.org/abs/2310.17513v1"},"cats":{"benchmark":0.4470027991,"new-dataset":0.0225807293,"data-annotation":0.5482757015,"dev-research":0.1291513853,"llms":0.5028363546,"data-quality":0.1838602054}}
{"text":"Despite its huge success in practice, the theoretical underpinnings of LoRA have largely remained unexplored.","meta":{"url":"http://arxiv.org/abs/2310.17513v1"},"cats":{"benchmark":0.238612951,"new-dataset":0.0179644634,"data-annotation":0.5070471875,"dev-research":0.1689415488,"llms":0.5778633128,"data-quality":0.1209473267}}
{"text":"This paper takes the first step to bridge this gap by theoretically analyzing the expressive power of LoRA.","meta":{"url":"http://arxiv.org/abs/2310.17513v1"},"cats":{"benchmark":0.3195621612,"new-dataset":0.0259155631,"data-annotation":0.5120003782,"dev-research":0.1495021866,"llms":0.5974051138,"data-quality":0.094471085}}
{"text":"We prove that, for fully connected neural networks, LoRA can adapt any model $f$ to accurately represent any smaller target model $\\overline{f}$ if LoRA-rank $\\geq(\\text{width of }f) \\times \\frac{\\text{depth of }\\overline{f}}{\\text{depth of }f}$. We also quantify the approximation error when LoRA-rank is lower than the threshold.","meta":{"url":"http://arxiv.org/abs/2310.17513v1"},"cats":{"benchmark":0.3541808217,"new-dataset":0.025058202,"data-annotation":0.5368207686,"dev-research":0.1235700504,"llms":0.5072202114,"data-quality":0.1560383258}}
{"text":"For Transformer networks, we show any model can be adapted to a target model of the same size with rank-$(\\frac{\\text{embedding size}}{2})$ LoRA adapters.","meta":{"url":"http://arxiv.org/abs/2310.17513v1"},"cats":{"benchmark":0.2981252873,"new-dataset":0.0259317569,"data-annotation":0.5225632574,"dev-research":0.099716793,"llms":0.5381570481,"data-quality":0.0825651172}}
{"text":"Large language models (LLMs) have been widely used as agents to complete different tasks, such as personal assistance or event planning.","meta":{"url":"http://arxiv.org/abs/2310.17512v1"},"cats":{"benchmark":0.1532708305,"new-dataset":0.0682328571,"data-annotation":0.5150060785,"dev-research":0.1647980821,"llms":0.7360820389,"data-quality":0.0722878318}}
{"text":"While most work has focused on cooperation and collaboration between agents, little work explores competition, another important mechanism that fosters the development of society and economy.","meta":{"url":"http://arxiv.org/abs/2310.17512v1"},"cats":{"benchmark":0.186031988,"new-dataset":0.0313967785,"data-annotation":0.5283565164,"dev-research":0.2561104398,"llms":0.5500731407,"data-quality":0.060918511}}
{"text":"In this paper, we seek to examine the competition behaviors in LLM-based agents.","meta":{"url":"http://arxiv.org/abs/2310.17512v1"},"cats":{"benchmark":0.2436698527,"new-dataset":0.0306460986,"data-annotation":0.510533478,"dev-research":0.0993682703,"llms":0.7062948397,"data-quality":0.047551383}}
{"text":"We first propose a general framework to study the competition between agents.","meta":{"url":"http://arxiv.org/abs/2310.17512v1"},"cats":{"benchmark":0.3027606173,"new-dataset":0.0580238088,"data-annotation":0.5319004957,"dev-research":0.1438309878,"llms":0.4610909105,"data-quality":0.0537488693}}
{"text":"Then, we implement a practical competitive environment using GPT-4 to simulate a virtual town with two types of agents, including restaurant agents and customer agents.","meta":{"url":"http://arxiv.org/abs/2310.17512v1"},"cats":{"benchmark":0.2713599585,"new-dataset":0.1124227735,"data-annotation":0.5124206008,"dev-research":0.1420238837,"llms":0.4818954991,"data-quality":0.0548094993}}
{"text":"Specifically, restaurant agents compete with each other to attract more customers, where the competition fosters them to transform, such as cultivating new operating strategies.","meta":{"url":"http://arxiv.org/abs/2310.17512v1"},"cats":{"benchmark":0.2301588607,"new-dataset":0.0122109867,"data-annotation":0.5030792064,"dev-research":0.1796049603,"llms":0.4939416233,"data-quality":0.0581030744}}
{"text":"The results of our experiments reveal several interesting findings ranging from social learning to Matthew Effect, which aligns well with existing sociological and economic theories.","meta":{"url":"http://arxiv.org/abs/2310.17512v1"},"cats":{"benchmark":0.2380446847,"new-dataset":0.0483243638,"data-annotation":0.521902131,"dev-research":0.1546029675,"llms":0.4623287454,"data-quality":0.1085028886}}
{"text":"We believe that competition between agents deserves further investigation to help us understand society better.","meta":{"url":"http://arxiv.org/abs/2310.17512v1"},"cats":{"benchmark":0.3108109029,"new-dataset":0.0571284641,"data-annotation":0.5210443131,"dev-research":0.2194376509,"llms":0.5308273308,"data-quality":0.0992948293}}
{"text":"The code will be released soon.","meta":{"url":"http://arxiv.org/abs/2310.17512v1"},"cats":{"benchmark":0.2493376878,"new-dataset":0.4062888346,"data-annotation":0.5230731917,"dev-research":0.3587778427,"llms":0.5192203623,"data-quality":0.1297263058}}
{"text":"Self-supervised image networks can be used to address complex 2D tasks (e.g., semantic segmentation, object discovery) very efficiently and with little or no downstream supervision.","meta":{"url":"http://arxiv.org/abs/2310.17504v1"},"cats":{"benchmark":0.1528998639,"new-dataset":0.1409926473,"data-annotation":0.5179450916,"dev-research":0.1799911129,"llms":0.5273465163,"data-quality":0.1161081048}}
{"text":"However, self-supervised 3D networks on lidar data do not perform as well for now.","meta":{"url":"http://arxiv.org/abs/2310.17504v1"},"cats":{"benchmark":0.2982957551,"new-dataset":0.0253191615,"data-annotation":0.4946423762,"dev-research":0.1336510094,"llms":0.5084564669,"data-quality":0.1764676726}}
{"text":"A few methods therefore propose to distill high-quality self-supervised 2D features into 3D networks.","meta":{"url":"http://arxiv.org/abs/2310.17504v1"},"cats":{"benchmark":0.2594209686,"new-dataset":0.0805436292,"data-annotation":0.5092365539,"dev-research":0.2001888921,"llms":0.4847070541,"data-quality":0.1797682128}}
{"text":"The most recent ones doing so on autonomous driving data show promising results.","meta":{"url":"http://arxiv.org/abs/2310.17504v1"},"cats":{"benchmark":0.4008305799,"new-dataset":0.1143439114,"data-annotation":0.4903719466,"dev-research":0.1662495175,"llms":0.4212855677,"data-quality":0.1085636128}}
{"text":"Yet, a performance gap persists between these distilled features and fully-supervised ones.","meta":{"url":"http://arxiv.org/abs/2310.17504v1"},"cats":{"benchmark":0.4477331563,"new-dataset":0.0289716481,"data-annotation":0.5003803993,"dev-research":0.2194306025,"llms":0.4926028464,"data-quality":0.3175420106}}
{"text":"In this work, we revisit 2D-to-3D distillation.","meta":{"url":"http://arxiv.org/abs/2310.17504v1"},"cats":{"benchmark":0.3304286876,"new-dataset":0.0338914757,"data-annotation":0.4982431094,"dev-research":0.1524635977,"llms":0.5097755419,"data-quality":0.0719273438}}
{"text":"First, we propose, for semantic segmentation, a simple approach that leads to a significant improvement compared to prior 3D distillation methods.","meta":{"url":"http://arxiv.org/abs/2310.17504v1"},"cats":{"benchmark":0.3372716291,"new-dataset":0.1455979947,"data-annotation":0.5054867951,"dev-research":0.1676792628,"llms":0.4311834989,"data-quality":0.2413266867}}
{"text":"Second, we show that distillation in high capacity 3D networks is key to reach high quality 3D features.","meta":{"url":"http://arxiv.org/abs/2310.17504v1"},"cats":{"benchmark":0.2663664942,"new-dataset":0.0513640588,"data-annotation":0.4846446448,"dev-research":0.2011362255,"llms":0.5196943776,"data-quality":0.0696033069}}
{"text":"This actually allows us to significantly close the gap between unsupervised distilled 3D features and fully-supervised ones.","meta":{"url":"http://arxiv.org/abs/2310.17504v1"},"cats":{"benchmark":0.2690599662,"new-dataset":0.0187185753,"data-annotation":0.4987855368,"dev-research":0.2339682891,"llms":0.4845025455,"data-quality":0.1534070805}}
{"text":"Last, we show that our high-quality distilled representations can also be used for open-vocabulary segmentation and background/foreground discovery.","meta":{"url":"http://arxiv.org/abs/2310.17504v1"},"cats":{"benchmark":0.2373507633,"new-dataset":0.5256562169,"data-annotation":0.5371081721,"dev-research":0.1469237007,"llms":0.5183290623,"data-quality":0.2610951091}}
{"text":"Customizing voice and speaking style in a speech synthesis system with intuitive and fine-grained controls is challenging, given that little data with appropriate labels is available.","meta":{"url":"http://arxiv.org/abs/2310.17502v1"},"cats":{"benchmark":0.273702288,"new-dataset":0.2211022149,"data-annotation":0.5099465845,"dev-research":0.2524870914,"llms":0.5300753058,"data-quality":0.2030425093}}
{"text":"Furthermore, editing an existing human's voice also comes with ethical concerns.","meta":{"url":"http://arxiv.org/abs/2310.17502v1"},"cats":{"benchmark":0.2081710074,"new-dataset":0.0391708768,"data-annotation":0.5192110144,"dev-research":0.3353198923,"llms":0.5610539846,"data-quality":0.2081552811}}
{"text":"In this paper, we propose a method to generate artificial speaker embeddings that cannot be linked to a real human while offering intuitive and fine-grained control over the voice and speaking style of the embeddings, without requiring any labels for speaker or style.","meta":{"url":"http://arxiv.org/abs/2310.17502v1"},"cats":{"benchmark":0.2509517028,"new-dataset":0.067319797,"data-annotation":0.5560782677,"dev-research":0.2102331127,"llms":0.552572517,"data-quality":0.1431985539}}
{"text":"The artificial and controllable embeddings can be fed to a speech synthesis system, conditioned on embeddings of real humans during training, without sacrificing privacy during inference.","meta":{"url":"http://arxiv.org/abs/2310.17502v1"},"cats":{"benchmark":0.1649049701,"new-dataset":0.0952038685,"data-annotation":0.5299139203,"dev-research":0.2021446269,"llms":0.5554783114,"data-quality":0.160608223}}
{"text":"Modern GPUs require an enormous register file (RF) to store the context of thousands of active threads.","meta":{"url":"http://arxiv.org/abs/2310.17501v1"},"cats":{"benchmark":0.2740645467,"new-dataset":0.1358552082,"data-annotation":0.48565016,"dev-research":0.183889636,"llms":0.6175057121,"data-quality":0.0804198599}}
{"text":"It consumes considerable energy and contains multiple large banks to provide enough throughput.","meta":{"url":"http://arxiv.org/abs/2310.17501v1"},"cats":{"benchmark":0.3691582293,"new-dataset":0.0243051843,"data-annotation":0.4757222053,"dev-research":0.1240713303,"llms":0.5192102019,"data-quality":0.0559113863}}
{"text":"Thus, a RF caching mechanism can significantly improve the performance and energy consumption of the GPUs by avoiding reads from the large banks that consume significant energy and may cause port conflicts.   ","meta":{"url":"http://arxiv.org/abs/2310.17501v1"},"cats":{"benchmark":0.4972633295,"new-dataset":0.0180360163,"data-annotation":0.4702425227,"dev-research":0.1613276875,"llms":0.5476013744,"data-quality":0.0897009721}}
{"text":"This paper introduces an energy-efficient RF caching mechanism called Malekeh that repurposes an existing component in GPUs' RF to operate as a cache in addition to its original functionality.","meta":{"url":"http://arxiv.org/abs/2310.17501v1"},"cats":{"benchmark":0.3898627128,"new-dataset":0.0366239726,"data-annotation":0.4850073088,"dev-research":0.1704064749,"llms":0.5972588587,"data-quality":0.081130126}}
{"text":"In this way, Malekeh minimizes the overhead of adding a RF cache to GPUs.","meta":{"url":"http://arxiv.org/abs/2310.17501v1"},"cats":{"benchmark":0.3982443379,"new-dataset":0.008559228,"data-annotation":0.4966878559,"dev-research":0.1346645226,"llms":0.5769276774,"data-quality":0.0724017343}}
{"text":"Besides, Malekeh leverages an issue scheduling policy that utilizes the reuse distance of the values in the RF cache and is controlled by a dynamic algorithm.","meta":{"url":"http://arxiv.org/abs/2310.17501v1"},"cats":{"benchmark":0.4086189182,"new-dataset":0.0273372531,"data-annotation":0.4827317833,"dev-research":0.1933304432,"llms":0.5612330719,"data-quality":0.0791751834}}
{"text":"The goal is to adapt the issue policy to the runtime program characteristics to maximize the GPU's performance and the hit ratio of the RF cache.","meta":{"url":"http://arxiv.org/abs/2310.17501v1"},"cats":{"benchmark":0.5196921796,"new-dataset":0.0373389189,"data-annotation":0.4915107905,"dev-research":0.2690003481,"llms":0.5406920311,"data-quality":0.0841118801}}
{"text":"The reuse distance is approximated by the compiler using profiling and is used at run time by the proposed caching scheme.","meta":{"url":"http://arxiv.org/abs/2310.17501v1"},"cats":{"benchmark":0.6052221469,"new-dataset":0.0550008962,"data-annotation":0.5298112931,"dev-research":0.3360513462,"llms":0.5583055683,"data-quality":0.0974917762}}
{"text":"We show that Malekeh reduces the number of reads to the RF banks by 46.4% and the dynamic energy of the RF by 28.3%.","meta":{"url":"http://arxiv.org/abs/2310.17501v1"},"cats":{"benchmark":0.3912440058,"new-dataset":0.0606829617,"data-annotation":0.4962564737,"dev-research":0.0903968598,"llms":0.5334243684,"data-quality":0.0804254071}}
{"text":"Besides, it improves performance by 6.1% while adding only 2KB of extra storage per core to the baseline RF of 256KB, which represents a negligible overhead of 0.78%.","meta":{"url":"http://arxiv.org/abs/2310.17501v1"},"cats":{"benchmark":0.582139142,"new-dataset":0.0120307913,"data-annotation":0.4952327298,"dev-research":0.2002629763,"llms":0.5841112937,"data-quality":0.0885783942}}
{"text":"For our contribution to the Blizzard Challenge 2023, we improved on the system we submitted to the Blizzard Challenge 2021.","meta":{"url":"http://arxiv.org/abs/2310.17499v1"},"cats":{"benchmark":0.5026629957,"new-dataset":0.1115106715,"data-annotation":0.5356687008,"dev-research":0.2887748568,"llms":0.5494717545,"data-quality":0.1528029926}}
{"text":"Our approach entails a rule-based text-to-phoneme processing system that includes rule-based disambiguation of homographs in the French language.","meta":{"url":"http://arxiv.org/abs/2310.17499v1"},"cats":{"benchmark":0.3982402369,"new-dataset":0.3476566215,"data-annotation":0.5136372163,"dev-research":0.2260818179,"llms":0.5484262156,"data-quality":0.3289435947}}
{"text":"It then transforms the phonemes to spectrograms as intermediate representations using a fast and efficient non-autoregressive synthesis architecture based on Conformer and Glow.","meta":{"url":"http://arxiv.org/abs/2310.17499v1"},"cats":{"benchmark":0.2769063981,"new-dataset":0.0920029172,"data-annotation":0.5215538412,"dev-research":0.1553607161,"llms":0.5217892782,"data-quality":0.0979252482}}
{"text":"A GAN based neural vocoder that combines recent state-of-the-art approaches converts the spectrogram to the final wave.","meta":{"url":"http://arxiv.org/abs/2310.17499v1"},"cats":{"benchmark":0.2584136077,"new-dataset":0.0945230612,"data-annotation":0.4798584296,"dev-research":0.1829058321,"llms":0.4870033575,"data-quality":0.108275078}}
{"text":"We carefully designed the data processing, training, and inference procedures for the challenge data.","meta":{"url":"http://arxiv.org/abs/2310.17499v1"},"cats":{"benchmark":0.3998355596,"new-dataset":0.3081668307,"data-annotation":0.490399221,"dev-research":0.1962121777,"llms":0.4181770758,"data-quality":0.145679745}}
{"text":"Our system identifier is G. Open source code and demo are available.","meta":{"url":"http://arxiv.org/abs/2310.17499v1"},"cats":{"benchmark":0.3078567527,"new-dataset":0.4543928885,"data-annotation":0.4997403184,"dev-research":0.3651455478,"llms":0.5513361547,"data-quality":0.1603690538}}
{"text":"Backdoor attack is a common threat to deep neural networks.","meta":{"url":"http://arxiv.org/abs/2310.17498v1"},"cats":{"benchmark":0.210058414,"new-dataset":0.0347410462,"data-annotation":0.5360439562,"dev-research":0.2297032352,"llms":0.5140169777,"data-quality":0.1721365853}}
{"text":"During testing, samples embedded with a backdoor trigger will be misclassified as an adversarial target by a backdoored model, while samples without the backdoor trigger will be correctly classified.","meta":{"url":"http://arxiv.org/abs/2310.17498v1"},"cats":{"benchmark":0.3507163234,"new-dataset":0.0117515771,"data-annotation":0.5272233947,"dev-research":0.1836799938,"llms":0.580077816,"data-quality":0.3223946614}}
{"text":"In this paper, we present the first certified backdoor detector (CBD), which is based on a novel, adjustable conformal prediction scheme based on our proposed statistic local dominant probability.","meta":{"url":"http://arxiv.org/abs/2310.17498v1"},"cats":{"benchmark":0.4106006516,"new-dataset":0.0615258751,"data-annotation":0.5226013076,"dev-research":0.1154511217,"llms":0.4695264956,"data-quality":0.1372125216}}
{"text":"For any classifier under inspection, CBD provides 1) a detection inference, 2) the condition under which the attacks are guaranteed to be detectable for the same classification domain, and 3) a probabilistic upper bound for the false positive rate.","meta":{"url":"http://arxiv.org/abs/2310.17498v1"},"cats":{"benchmark":0.4312421093,"new-dataset":0.0159658479,"data-annotation":0.5305660361,"dev-research":0.2160485829,"llms":0.4968507126,"data-quality":0.2135759903}}
{"text":"Our theoretical results show that attacks with triggers that are more resilient to test-time noise and have smaller perturbation magnitudes are more likely to be detected with guarantees.","meta":{"url":"http://arxiv.org/abs/2310.17498v1"},"cats":{"benchmark":0.4954752581,"new-dataset":0.0106278897,"data-annotation":0.5268972399,"dev-research":0.236475404,"llms":0.4790138181,"data-quality":0.2001210226}}
{"text":"Moreover, we conduct extensive experiments on four benchmark datasets considering various backdoor types, such as BadNet, CB, and Blend.","meta":{"url":"http://arxiv.org/abs/2310.17498v1"},"cats":{"benchmark":0.5300018427,"new-dataset":0.1666331808,"data-annotation":0.5261014571,"dev-research":0.1482559286,"llms":0.4950168191,"data-quality":0.1571305058}}
{"text":"CBD achieves comparable or even higher detection accuracy than state-of-the-art detectors, and it in addition provides detection certification.","meta":{"url":"http://arxiv.org/abs/2310.17498v1"},"cats":{"benchmark":0.436434638,"new-dataset":0.0287964779,"data-annotation":0.4939890482,"dev-research":0.1754025886,"llms":0.5502790019,"data-quality":0.1953839566}}
{"text":"Notably, for backdoor attacks with random perturbation triggers bounded by $\\ell_2\\leq0.75$ which achieves more than 90\\% attack success rate, CBD achieves 100\\% (98\\%), 100\\% (84\\%), 98\\% (98\\%), and 72\\% (40\\%) empirical (certified) detection true positive rates on the four benchmark datasets GTSRB, SVHN, CIFAR-10, and TinyImageNet, respectively, with low false positive rates.","meta":{"url":"http://arxiv.org/abs/2310.17498v1"},"cats":{"benchmark":0.6036638138,"new-dataset":0.0480840724,"data-annotation":0.5344435284,"dev-research":0.1559024486,"llms":0.5144656237,"data-quality":0.2025898747}}
{"text":"Interpretation and understanding of video presents a challenging computer vision task in numerous fields - e.g. autonomous driving and sports analytics.","meta":{"url":"http://arxiv.org/abs/2310.17493v1"},"cats":{"benchmark":0.2319833161,"new-dataset":0.1346392305,"data-annotation":0.5274930236,"dev-research":0.2420401567,"llms":0.4022341442,"data-quality":0.1311490813}}
{"text":"Existing approaches to interpreting the actions taking place within a video clip are based upon Temporal Action Localisation (TAL), which typically identifies short-term actions.","meta":{"url":"http://arxiv.org/abs/2310.17493v1"},"cats":{"benchmark":0.2330332111,"new-dataset":0.12486701,"data-annotation":0.5293686137,"dev-research":0.244672912,"llms":0.4744485268,"data-quality":0.1433944061}}
{"text":"The emerging field of Complex Activity Detection (CompAD) extends this analysis to long-term activities, with a deeper understanding obtained by modelling the internal structure of a complex activity taking place within the video.","meta":{"url":"http://arxiv.org/abs/2310.17493v1"},"cats":{"benchmark":0.2187520624,"new-dataset":0.1749150585,"data-annotation":0.5379303997,"dev-research":0.1895009937,"llms":0.446411205,"data-quality":0.0890629286}}
{"text":"We address the CompAD problem using a hybrid graph neural network which combines attention applied to a graph encoding the local (short-term) dynamic scene with a temporal graph modelling the overall long-duration activity.","meta":{"url":"http://arxiv.org/abs/2310.17493v1"},"cats":{"benchmark":0.2117077757,"new-dataset":0.4697327528,"data-annotation":0.5222625963,"dev-research":0.1673877799,"llms":0.4144381151,"data-quality":0.0992543072}}
{"text":"Our approach is as follows: i)","meta":{"url":"http://arxiv.org/abs/2310.17493v1"},"cats":{"benchmark":0.3682722251,"new-dataset":0.0717238505,"data-annotation":0.5214842962,"dev-research":0.2252593597,"llms":0.4642380713,"data-quality":0.1223367495}}
{"text":"Firstly, we propose a novel feature extraction technique which, for each video snippet, generates spatiotemporal `tubes' for the active elements (`agents') in the (local) scene by detecting individual objects, tracking them and then extracting 3D features from all the agent tubes as well as the overall scene.","meta":{"url":"http://arxiv.org/abs/2310.17493v1"},"cats":{"benchmark":0.2444831268,"new-dataset":0.302491273,"data-annotation":0.5124168693,"dev-research":0.1989585387,"llms":0.4248800633,"data-quality":0.1249548621}}
{"text":"ii)","meta":{"url":"http://arxiv.org/abs/2310.17493v1"},"cats":{"benchmark":0.3210191697,"new-dataset":0.2565763901,"data-annotation":0.5254234985,"dev-research":0.1831432176,"llms":0.4924040622,"data-quality":0.1252283271}}
{"text":"Next, we construct a local scene graph where each node (representing either an agent tube or the scene) is connected to all other nodes.","meta":{"url":"http://arxiv.org/abs/2310.17493v1"},"cats":{"benchmark":0.1850249987,"new-dataset":0.4653302693,"data-annotation":0.5150470372,"dev-research":0.1562707426,"llms":0.4925324579,"data-quality":0.0925905843}}
{"text":"Attention is then applied to this graph to obtain an overall representation of the local dynamic scene.","meta":{"url":"http://arxiv.org/abs/2310.17493v1"},"cats":{"benchmark":0.2373216508,"new-dataset":0.1924284263,"data-annotation":0.5280378358,"dev-research":0.1927492043,"llms":0.4165626222,"data-quality":0.1005042077}}
{"text":"iii)","meta":{"url":"http://arxiv.org/abs/2310.17493v1"},"cats":{"benchmark":0.2475905954,"new-dataset":0.3847228247,"data-annotation":0.510405276,"dev-research":0.1940585413,"llms":0.515368992,"data-quality":0.1660893379}}
{"text":"Finally, all local scene graph representations are interconnected via a temporal graph, to estimate the complex activity class together with its start and end time.","meta":{"url":"http://arxiv.org/abs/2310.17493v1"},"cats":{"benchmark":0.215845447,"new-dataset":0.2810287544,"data-annotation":0.5404857161,"dev-research":0.204648666,"llms":0.4520891368,"data-quality":0.0766635568}}
{"text":"The proposed framework outperforms all previous state-of-the-art methods on all three datasets including ActivityNet-1.3, Thumos-14, and ROAD.","meta":{"url":"http://arxiv.org/abs/2310.17493v1"},"cats":{"benchmark":0.4061233147,"new-dataset":0.7028593158,"data-annotation":0.4983310777,"dev-research":0.1408352183,"llms":0.4432349335,"data-quality":0.1263004815}}
{"text":"The efficient deployment and fine-tuning of foundation models are pivotal in contemporary artificial intelligence.","meta":{"url":"http://arxiv.org/abs/2310.17492v1"},"cats":{"benchmark":0.3134510626,"new-dataset":0.0537752767,"data-annotation":0.5170474434,"dev-research":0.2525280655,"llms":0.4730410985,"data-quality":0.0668401626}}
{"text":"In this study, we present a groundbreaking paradigm integrating Mobile Edge Computing (MEC) with foundation models, specifically designed to enhance local task performance on user equipment (UE).","meta":{"url":"http://arxiv.org/abs/2310.17492v1"},"cats":{"benchmark":0.3985365062,"new-dataset":0.0410926299,"data-annotation":0.4932263425,"dev-research":0.2496714299,"llms":0.4964298247,"data-quality":0.0578153466}}
{"text":"Central to our approach is the innovative Emulator-Adapter architecture, segmenting the foundation model into two cohesive modules.","meta":{"url":"http://arxiv.org/abs/2310.17492v1"},"cats":{"benchmark":0.3210897314,"new-dataset":0.0451870322,"data-annotation":0.482983489,"dev-research":0.2058229301,"llms":0.6068762137,"data-quality":0.0497657449}}
{"text":"This design not only conserves computational resources but also ensures adaptability and fine-tuning efficiency for downstream tasks.","meta":{"url":"http://arxiv.org/abs/2310.17492v1"},"cats":{"benchmark":0.4316686721,"new-dataset":0.0031453554,"data-annotation":0.4773228377,"dev-research":0.2346105138,"llms":0.5388409113,"data-quality":0.0341923561}}
{"text":"Additionally, we introduce an advanced resource allocation mechanism that is fine-tuned to the needs of the Emulator-Adapter structure in decentralized settings.","meta":{"url":"http://arxiv.org/abs/2310.17492v1"},"cats":{"benchmark":0.3408990012,"new-dataset":0.0215812223,"data-annotation":0.4825660668,"dev-research":0.2194970416,"llms":0.6194516267,"data-quality":0.0513085578}}
{"text":"To address the challenges presented by this system, we employ a hybrid multi-agent Deep Reinforcement Learning (DRL) strategy, adept at handling mixed discrete-continuous action spaces, ensuring dynamic and optimal resource allocations.","meta":{"url":"http://arxiv.org/abs/2310.17492v1"},"cats":{"benchmark":0.1819301799,"new-dataset":0.1187483238,"data-annotation":0.4755305491,"dev-research":0.1240846128,"llms":0.5279762178,"data-quality":0.0458627961}}
{"text":"Our comprehensive simulations and validations underscore the practical viability of our approach, demonstrating its robustness, efficiency, and scalability.","meta":{"url":"http://arxiv.org/abs/2310.17492v1"},"cats":{"benchmark":0.6463547815,"new-dataset":0.0050828297,"data-annotation":0.4984740166,"dev-research":0.146030169,"llms":0.470152911,"data-quality":0.0774315942}}
{"text":"Collectively, this work offers a fresh perspective on deploying foundation models and balancing computational efficiency with task proficiency.","meta":{"url":"http://arxiv.org/abs/2310.17492v1"},"cats":{"benchmark":0.38180698,"new-dataset":0.0692924307,"data-annotation":0.5050285023,"dev-research":0.2990135916,"llms":0.4967120184,"data-quality":0.0542315658}}
{"text":"The emergence of foundation models, including language and vision models, has reshaped AI's landscape, offering capabilities across various applications.","meta":{"url":"http://arxiv.org/abs/2310.17491v1"},"cats":{"benchmark":0.1571818523,"new-dataset":0.0652050135,"data-annotation":0.5280935062,"dev-research":0.231415858,"llms":0.4817048914,"data-quality":0.0722603074}}
{"text":"Deploying and fine-tuning these large models, like GPT-3 and BERT, presents challenges, especially in the current foundation model era.","meta":{"url":"http://arxiv.org/abs/2310.17491v1"},"cats":{"benchmark":0.3238357144,"new-dataset":0.1496022134,"data-annotation":0.5224749827,"dev-research":0.2187242798,"llms":0.5019989687,"data-quality":0.0837721749}}
{"text":"We introduce Emulator-Assisted Tuning (EAT) combined with Parameter-Efficient Fine-Tuning (PEFT) to form Parameter-Efficient Emulator-Assisted Tuning (PEAT).","meta":{"url":"http://arxiv.org/abs/2310.17491v1"},"cats":{"benchmark":0.4419778103,"new-dataset":0.0142951325,"data-annotation":0.4900921338,"dev-research":0.1695569153,"llms":0.5973605893,"data-quality":0.0717187567}}
{"text":"Further, we expand this into federated learning as Federated PEAT (FedPEAT).","meta":{"url":"http://arxiv.org/abs/2310.17491v1"},"cats":{"benchmark":0.1826795625,"new-dataset":0.1376187286,"data-annotation":0.4955876953,"dev-research":0.0959314912,"llms":0.5732271489,"data-quality":0.1120009972}}
{"text":"FedPEAT uses adapters, emulators, and PEFT for federated model tuning, enhancing model privacy and memory efficiency.","meta":{"url":"http://arxiv.org/abs/2310.17491v1"},"cats":{"benchmark":0.2592667746,"new-dataset":0.0437237841,"data-annotation":0.4916872353,"dev-research":0.1454730652,"llms":0.6123044125,"data-quality":0.0700547425}}
{"text":"Adapters adjust pre-trained models, while emulators give a compact representation of original models, addressing both privacy and efficiency.","meta":{"url":"http://arxiv.org/abs/2310.17491v1"},"cats":{"benchmark":0.2448248207,"new-dataset":0.0092713707,"data-annotation":0.497895927,"dev-research":0.1903174217,"llms":0.5720779356,"data-quality":0.0615718838}}
{"text":"Adaptable to various neural networks, our approach also uses deep reinforcement learning for hyper-parameter optimization.","meta":{"url":"http://arxiv.org/abs/2310.17491v1"},"cats":{"benchmark":0.4058050022,"new-dataset":0.023032628,"data-annotation":0.5119624776,"dev-research":0.129172267,"llms":0.4026860811,"data-quality":0.0846024224}}
{"text":"We tested FedPEAT in a unique scenario with a server participating in collaborative federated tuning, showcasing its potential in tackling foundation model challenges.","meta":{"url":"http://arxiv.org/abs/2310.17491v1"},"cats":{"benchmark":0.3369109396,"new-dataset":0.0880644462,"data-annotation":0.4751265697,"dev-research":0.1915752338,"llms":0.5883431032,"data-quality":0.1229064963}}
{"text":"Large language models (LLMs) enable zero-shot approaches in open-domain question answering (ODQA), yet with limited advancements as the reader is compared to the retriever.","meta":{"url":"http://arxiv.org/abs/2310.17490v1"},"cats":{"benchmark":0.2793233286,"new-dataset":0.1190578601,"data-annotation":0.534273242,"dev-research":0.1040703217,"llms":0.644245838,"data-quality":0.1339324854}}
{"text":"This study aims at the feasibility of a zero-shot reader that addresses the challenges of computational cost and the need for labeled data.","meta":{"url":"http://arxiv.org/abs/2310.17490v1"},"cats":{"benchmark":0.3859150985,"new-dataset":0.3257528133,"data-annotation":0.5082617344,"dev-research":0.1375314527,"llms":0.4697074441,"data-quality":0.3066290795}}
{"text":"We find that LLMs are distracted due to irrelevant documents in the retrieved set and the overconfidence of the generated answers when they are exploited as zero-shot readers.","meta":{"url":"http://arxiv.org/abs/2310.17490v1"},"cats":{"benchmark":0.2307638733,"new-dataset":0.1484154854,"data-annotation":0.5224393999,"dev-research":0.1571490329,"llms":0.7356795512,"data-quality":0.1777684937}}
{"text":"To tackle these problems, we mitigate the impact of such documents via Distraction-aware Answer Selection (DAS) with a negation-based instruction and score adjustment for proper answer selection.","meta":{"url":"http://arxiv.org/abs/2310.17490v1"},"cats":{"benchmark":0.3207624584,"new-dataset":0.0903434761,"data-annotation":0.5250293262,"dev-research":0.3138294634,"llms":0.5256851048,"data-quality":0.1257015688}}
{"text":"Experimental results show that our approach successfully handles distraction across diverse scenarios, enhancing the performance of zero-shot readers.","meta":{"url":"http://arxiv.org/abs/2310.17490v1"},"cats":{"benchmark":0.3105580817,"new-dataset":0.0978859621,"data-annotation":0.5255232405,"dev-research":0.2498668144,"llms":0.5205047899,"data-quality":0.1119604754}}
{"text":"Furthermore, unlike supervised readers struggling with unseen data, zero-shot readers demonstrate outstanding transferability without any training.","meta":{"url":"http://arxiv.org/abs/2310.17490v1"},"cats":{"benchmark":0.3362211502,"new-dataset":0.0615385692,"data-annotation":0.5062135171,"dev-research":0.1001071466,"llms":0.5132485204,"data-quality":0.1978251515}}
{"text":"Biases with respect to socially-salient attributes of individuals have been well documented in evaluation processes used in settings such as admissions and hiring.","meta":{"url":"http://arxiv.org/abs/2310.17489v1"},"cats":{"benchmark":0.4606196624,"new-dataset":0.0105436806,"data-annotation":0.5412271093,"dev-research":0.272315855,"llms":0.496378,"data-quality":0.1771171701}}
{"text":"We view such an evaluation process as a transformation of a distribution of the true utility of an individual for a task to an observed distribution and model it as a solution to a loss minimization problem subject to an information constraint.","meta":{"url":"http://arxiv.org/abs/2310.17489v1"},"cats":{"benchmark":0.3728480192,"new-dataset":0.0056233149,"data-annotation":0.5349896272,"dev-research":0.1960843982,"llms":0.3840041245,"data-quality":0.1378390078}}
{"text":"Our model has two parameters that have been identified as factors leading to biases: the resource-information trade-off parameter in the information constraint and the risk-averseness parameter in the loss function.","meta":{"url":"http://arxiv.org/abs/2310.17489v1"},"cats":{"benchmark":0.3431116701,"new-dataset":0.0077082581,"data-annotation":0.5285506298,"dev-research":0.1413860242,"llms":0.3800418668,"data-quality":0.1342535189}}
{"text":"We characterize the distributions that arise from our model and study the effect of the parameters on the observed distribution.","meta":{"url":"http://arxiv.org/abs/2310.17489v1"},"cats":{"benchmark":0.3686968513,"new-dataset":0.0646669607,"data-annotation":0.5264908097,"dev-research":0.1375456275,"llms":0.3601350957,"data-quality":0.1437802604}}
{"text":"The outputs of our model enrich the class of distributions that can be used to capture variation across groups in the observed evaluations.","meta":{"url":"http://arxiv.org/abs/2310.17489v1"},"cats":{"benchmark":0.4791484293,"new-dataset":0.0271698251,"data-annotation":0.5382653325,"dev-research":0.1464740952,"llms":0.4137784278,"data-quality":0.1745548522}}
{"text":"We empirically validate our model by fitting real-world datasets and use it to study the effect of interventions in a downstream selection task.","meta":{"url":"http://arxiv.org/abs/2310.17489v1"},"cats":{"benchmark":0.4156091154,"new-dataset":0.0170070975,"data-annotation":0.485164655,"dev-research":0.2309263609,"llms":0.3909916195,"data-quality":0.0840525408}}
{"text":"These results contribute to an understanding of the emergence of bias in evaluation processes and provide tools to guide the deployment of interventions to mitigate biases.","meta":{"url":"http://arxiv.org/abs/2310.17489v1"},"cats":{"benchmark":0.4597767546,"new-dataset":0.0031821457,"data-annotation":0.5129192064,"dev-research":0.3789342825,"llms":0.4948740986,"data-quality":0.1727304016}}
{"text":"This paper presents LightLM, a lightweight Transformer-based language model for generative recommendation.","meta":{"url":"http://arxiv.org/abs/2310.17488v1"},"cats":{"benchmark":0.2345074101,"new-dataset":0.1020529548,"data-annotation":0.5324416723,"dev-research":0.2643294996,"llms":0.5625041773,"data-quality":0.1446632853}}
{"text":"While Transformer-based generative modeling has gained importance in various AI sub-fields such as NLP and vision, generative recommendation is still in its infancy due to its unique demand on personalized generative modeling.","meta":{"url":"http://arxiv.org/abs/2310.17488v1"},"cats":{"benchmark":0.2077114326,"new-dataset":0.0298465382,"data-annotation":0.5166658292,"dev-research":0.2029538187,"llms":0.5107259776,"data-quality":0.0873140047}}
{"text":"Existing works on generative recommendation often use NLP-oriented Transformer architectures such as T5, GPT, LLaMA and M6, which are heavy-weight and are not specifically designed for recommendation tasks.","meta":{"url":"http://arxiv.org/abs/2310.17488v1"},"cats":{"benchmark":0.2897831675,"new-dataset":0.0299302594,"data-annotation":0.5197427686,"dev-research":0.1620821114,"llms":0.6387820902,"data-quality":0.1065921524}}
{"text":"LightLM tackles the issue by introducing a light-weight deep and narrow Transformer architecture, which is specifically tailored for direct generation of recommendation items.","meta":{"url":"http://arxiv.org/abs/2310.17488v1"},"cats":{"benchmark":0.3308565734,"new-dataset":0.0341246169,"data-annotation":0.5006059617,"dev-research":0.1851527232,"llms":0.5254166039,"data-quality":0.1098156697}}
{"text":"This structure is especially apt for straightforward generative recommendation and stems from the observation that language model does not have to be too wide for this task, as the input predominantly consists of short tokens that are well-suited for the model's capacity.","meta":{"url":"http://arxiv.org/abs/2310.17488v1"},"cats":{"benchmark":0.2414205617,"new-dataset":0.0683018443,"data-annotation":0.5590184374,"dev-research":0.2131201053,"llms":0.50221383,"data-quality":0.1747763688}}
{"text":"We also show that our devised user and item ID indexing methods, i.e., Spectral Collaborative Indexing (SCI) and Graph Collaborative Indexing (GCI), enables the deep and narrow Transformer architecture to outperform large-scale language models for recommendation.","meta":{"url":"http://arxiv.org/abs/2310.17488v1"},"cats":{"benchmark":0.361543105,"new-dataset":0.1192849607,"data-annotation":0.541478681,"dev-research":0.2036212295,"llms":0.5047768905,"data-quality":0.168289614}}
{"text":"Besides, to address the hallucination problem of generating items as output, we propose the constrained generation process for generative recommenders.","meta":{"url":"http://arxiv.org/abs/2310.17488v1"},"cats":{"benchmark":0.2497059524,"new-dataset":0.027762313,"data-annotation":0.5329794826,"dev-research":0.2600070521,"llms":0.5559216418,"data-quality":0.1353877189}}
{"text":"Experiments on real-world datasets show that LightLM outperforms various competitive baselines in terms of both recommendation accuracy and efficiency.","meta":{"url":"http://arxiv.org/abs/2310.17488v1"},"cats":{"benchmark":0.5995294677,"new-dataset":0.1362379119,"data-annotation":0.5049700103,"dev-research":0.1682953345,"llms":0.4097442936,"data-quality":0.1453193144}}
{"text":"The code can be found at https://github.com/dongyuanjushi/LightLM.","meta":{"url":"http://arxiv.org/abs/2310.17488v1"},"cats":{"benchmark":0.2942734833,"new-dataset":0.3295715891,"data-annotation":0.5270789451,"dev-research":0.1818078645,"llms":0.4938568226,"data-quality":0.1006648946}}
{"text":"Collaborative vehicle routing occurs when carriers collaborate through sharing their transportation requests and performing transportation requests on behalf of each other.","meta":{"url":"http://arxiv.org/abs/2310.17485v1"},"cats":{"benchmark":0.2477978548,"new-dataset":0.0064232394,"data-annotation":0.4828773756,"dev-research":0.2649189514,"llms":0.4975302634,"data-quality":0.081415204}}
{"text":"This achieves economies of scale, thus reducing cost, greenhouse gas emissions and road congestion.","meta":{"url":"http://arxiv.org/abs/2310.17485v1"},"cats":{"benchmark":0.3851798195,"new-dataset":0.0122999677,"data-annotation":0.4826018932,"dev-research":0.1936876261,"llms":0.4101628013,"data-quality":0.0406266906}}
{"text":"But which carrier should partner with whom, and how much should each carrier be compensated?","meta":{"url":"http://arxiv.org/abs/2310.17485v1"},"cats":{"benchmark":0.3763512125,"new-dataset":0.0329260018,"data-annotation":0.4945812368,"dev-research":0.1278059249,"llms":0.4784130242,"data-quality":0.1126930908}}
{"text":"Traditional game theoretic solution concepts are expensive to calculate as the characteristic function scales exponentially with the number of agents.","meta":{"url":"http://arxiv.org/abs/2310.17485v1"},"cats":{"benchmark":0.3038428482,"new-dataset":0.017367152,"data-annotation":0.5360070615,"dev-research":0.1638968264,"llms":0.4472980791,"data-quality":0.0276812155}}
{"text":"This would require solving the vehicle routing problem (NP-hard) an exponential number of times.","meta":{"url":"http://arxiv.org/abs/2310.17485v1"},"cats":{"benchmark":0.4312628708,"new-dataset":0.0190119878,"data-annotation":0.5121137982,"dev-research":0.1582978768,"llms":0.389052494,"data-quality":0.0681194479}}
{"text":"We therefore propose to model this problem as a coalitional bargaining game solved using deep multi-agent reinforcement learning, where - crucially - agents are not given access to the characteristic function.","meta":{"url":"http://arxiv.org/abs/2310.17485v1"},"cats":{"benchmark":0.2152130571,"new-dataset":0.0882925819,"data-annotation":0.5020095634,"dev-research":0.1196736389,"llms":0.4727508397,"data-quality":0.0639628035}}
{"text":"Instead, we implicitly reason about the characteristic function; thus, when deployed in production, we only need to evaluate the expensive post-collaboration vehicle routing problem once.","meta":{"url":"http://arxiv.org/abs/2310.17485v1"},"cats":{"benchmark":0.4065905761,"new-dataset":0.0090781743,"data-annotation":0.5028938478,"dev-research":0.2679003325,"llms":0.4731077329,"data-quality":0.0853403777}}
{"text":"Our contribution is that we are the first to consider both the route allocation problem and gain sharing problem simultaneously - without access to the expensive characteristic function.","meta":{"url":"http://arxiv.org/abs/2310.17485v1"},"cats":{"benchmark":0.3706920425,"new-dataset":0.0108829413,"data-annotation":0.5199727141,"dev-research":0.108865493,"llms":0.4014198887,"data-quality":0.0819628839}}
{"text":"Through decentralised machine learning, our agents bargain with each other and agree to outcomes that correlate well with the Shapley value - a fair profit allocation mechanism.","meta":{"url":"http://arxiv.org/abs/2310.17485v1"},"cats":{"benchmark":0.3110422721,"new-dataset":0.0657557134,"data-annotation":0.5129806049,"dev-research":0.1259372863,"llms":0.4575917887,"data-quality":0.0840084286}}
{"text":"Importantly, we are able to achieve a reduction in run-time of 88%.","meta":{"url":"http://arxiv.org/abs/2310.17485v1"},"cats":{"benchmark":0.5854120814,"new-dataset":0.015253545,"data-annotation":0.52874502,"dev-research":0.2125509441,"llms":0.4344212568,"data-quality":0.0556277}}
{"text":"Electricity load forecasting is an essential task within smart grids to assist demand and supply balance.","meta":{"url":"http://arxiv.org/abs/2310.17477v1"},"cats":{"benchmark":0.3317145953,"new-dataset":0.0105541329,"data-annotation":0.5001087584,"dev-research":0.1859913381,"llms":0.4090325015,"data-quality":0.0656661775}}
{"text":"While advanced deep learning models require large amounts of high-resolution data for accurate short-term load predictions, fine-grained load profiles can expose users' electricity consumption behaviors, which raises privacy and security concerns.","meta":{"url":"http://arxiv.org/abs/2310.17477v1"},"cats":{"benchmark":0.2878643675,"new-dataset":0.092054318,"data-annotation":0.4913133067,"dev-research":0.1739298313,"llms":0.4520718557,"data-quality":0.1049444215}}
{"text":"One solution to improve data privacy is federated learning, where models are trained locally on private data, and only the trained model parameters are merged and updated on a global server.","meta":{"url":"http://arxiv.org/abs/2310.17477v1"},"cats":{"benchmark":0.2070299036,"new-dataset":0.094844727,"data-annotation":0.4732986745,"dev-research":0.1349389113,"llms":0.4929249395,"data-quality":0.1517581162}}
{"text":"Therefore, this paper presents a novel transformer-based deep learning approach with federated learning for short-term electricity load prediction.","meta":{"url":"http://arxiv.org/abs/2310.17477v1"},"cats":{"benchmark":0.2715067149,"new-dataset":0.063615853,"data-annotation":0.5039824727,"dev-research":0.1464651439,"llms":0.4001915876,"data-quality":0.1118499971}}
{"text":"To evaluate our results, we benchmark our federated learning architecture against central and local learning and compare the performance of our model to long short-term memory models and convolutional neural networks.","meta":{"url":"http://arxiv.org/abs/2310.17477v1"},"cats":{"benchmark":0.4601205819,"new-dataset":0.1246306189,"data-annotation":0.5171248398,"dev-research":0.1054862587,"llms":0.4714583918,"data-quality":0.132569035}}
{"text":"Our simulations are based on a dataset from a German university campus and show that transformer-based forecasting is a promising alternative to state-of-the-art models within federated learning.","meta":{"url":"http://arxiv.org/abs/2310.17477v1"},"cats":{"benchmark":0.2555307297,"new-dataset":0.0409725821,"data-annotation":0.4861414292,"dev-research":0.1114337175,"llms":0.4718596647,"data-quality":0.055708484}}
{"text":"With the rise in demand for local deliveries and e-commerce, robotic deliveries are being considered as efficient and sustainable solutions.","meta":{"url":"http://arxiv.org/abs/2310.17475v1"},"cats":{"benchmark":0.2540855722,"new-dataset":0.052465996,"data-annotation":0.4847615811,"dev-research":0.2313754566,"llms":0.4789764274,"data-quality":0.052932967}}
{"text":"However, the deployment of such systems can be highly complex due to numerous factors involving stochastic demand, stochastic charging and maintenance needs, complex routing, etc.","meta":{"url":"http://arxiv.org/abs/2310.17475v1"},"cats":{"benchmark":0.3195033811,"new-dataset":0.0097924847,"data-annotation":0.4909554454,"dev-research":0.1661065784,"llms":0.4729952195,"data-quality":0.0485676311}}
{"text":"We propose a model that uses continuous approximation methods for evaluating service trade-offs that consider the unique characteristics of large-scale sidewalk delivery robot systems used to serve online food deliveries.","meta":{"url":"http://arxiv.org/abs/2310.17475v1"},"cats":{"benchmark":0.4713618699,"new-dataset":0.041311772,"data-annotation":0.4935835547,"dev-research":0.1900586461,"llms":0.3827259999,"data-quality":0.0683444867}}
{"text":"The model captures both the initial cost and the operation cost of the delivery system and evaluates the impact of constraints and operation strategies on the deployment.","meta":{"url":"http://arxiv.org/abs/2310.17475v1"},"cats":{"benchmark":0.3481084871,"new-dataset":0.0462773908,"data-annotation":0.4856441064,"dev-research":0.3052747732,"llms":0.4494965284,"data-quality":0.0718358594}}
{"text":"By minimizing the system cost, variables related to the system design can be determined.","meta":{"url":"http://arxiv.org/abs/2310.17475v1"},"cats":{"benchmark":0.4350362465,"new-dataset":0.0102860058,"data-annotation":0.5188477278,"dev-research":0.2902468918,"llms":0.3706246744,"data-quality":0.0767005506}}
{"text":"First, the minimization problem is formulated based on a homogeneous area, and the optimal system cost can be derived as a closed-form expression.","meta":{"url":"http://arxiv.org/abs/2310.17475v1"},"cats":{"benchmark":0.5314012755,"new-dataset":0.0128505406,"data-annotation":0.5388582693,"dev-research":0.1773866532,"llms":0.3009676831,"data-quality":0.1140671133}}
{"text":"By evaluating the expression, relationships between variables and the system cost can be directly obtained.","meta":{"url":"http://arxiv.org/abs/2310.17475v1"},"cats":{"benchmark":0.4643250848,"new-dataset":0.0305765837,"data-annotation":0.5378795081,"dev-research":0.241288709,"llms":0.3836458508,"data-quality":0.0739795903}}
{"text":"We then apply the model in neighborhoods in New York City to evaluate the cost of deploying the sidewalk delivery robot system in a real-world scenario.","meta":{"url":"http://arxiv.org/abs/2310.17475v1"},"cats":{"benchmark":0.345119741,"new-dataset":0.1031739576,"data-annotation":0.5095373919,"dev-research":0.2563170035,"llms":0.4115449684,"data-quality":0.0621752013}}
{"text":"The results shed light on the potential of deploying such a system in the future.","meta":{"url":"http://arxiv.org/abs/2310.17475v1"},"cats":{"benchmark":0.3385455185,"new-dataset":0.023662548,"data-annotation":0.4862368167,"dev-research":0.2002259481,"llms":0.5604420252,"data-quality":0.111756951}}
{"text":"Future wireless communication networks are in a position to move beyond data-centric, device-oriented connectivity and offer intelligent, immersive experiences based on task-oriented connections, especially in the context of the thriving development of pre-trained foundation models (PFM) and the evolving vision of 6G native artificial intelligence (AI).","meta":{"url":"http://arxiv.org/abs/2310.17471v1"},"cats":{"benchmark":0.1470206447,"new-dataset":0.0944401627,"data-annotation":0.494599607,"dev-research":0.1815671594,"llms":0.5419729094,"data-quality":0.0493240433}}
{"text":"Therefore, redefining modes of collaboration between devices and servers and constructing native intelligence libraries become critically important in 6G. In this paper, we analyze the challenges of achieving 6G native AI from the perspectives of data, intelligence, and networks.","meta":{"url":"http://arxiv.org/abs/2310.17471v1"},"cats":{"benchmark":0.195104392,"new-dataset":0.1442025034,"data-annotation":0.4783370365,"dev-research":0.252733544,"llms":0.5423512752,"data-quality":0.1371629575}}
{"text":"Then, we propose a 6G native AI framework based on foundation models, provide a customization approach for intent-aware PFM, present a construction of a task-oriented AI toolkit, and outline a novel cloud-edge-end collaboration paradigm.","meta":{"url":"http://arxiv.org/abs/2310.17471v1"},"cats":{"benchmark":0.2159262555,"new-dataset":0.1968732695,"data-annotation":0.4894831502,"dev-research":0.2026711385,"llms":0.5374577252,"data-quality":0.0668704118}}
{"text":"As a practical use case, we apply this framework for orchestration, achieving the maximum sum rate within a wireless communication system, and presenting preliminary evaluation results.","meta":{"url":"http://arxiv.org/abs/2310.17471v1"},"cats":{"benchmark":0.4582078527,"new-dataset":0.0205201445,"data-annotation":0.5049520348,"dev-research":0.1796244217,"llms":0.5241491518,"data-quality":0.0617709377}}
{"text":"Finally, we outline research directions for achieving native AI in 6G.","meta":{"url":"http://arxiv.org/abs/2310.17471v1"},"cats":{"benchmark":0.237174991,"new-dataset":0.0652042922,"data-annotation":0.5072297841,"dev-research":0.1855771392,"llms":0.561014089,"data-quality":0.0929189952}}
{"text":"Recently, image-text matching has attracted more and more attention from academia and industry, which is fundamental to understanding the latent correspondence across visual and textual modalities.","meta":{"url":"http://arxiv.org/abs/2310.17468v1"},"cats":{"benchmark":0.3329178499,"new-dataset":0.0703645531,"data-annotation":0.5169824532,"dev-research":0.1538027659,"llms":0.5073944741,"data-quality":0.2904319576}}
{"text":"However, most existing methods implicitly assume the training pairs are well-aligned while ignoring the ubiquitous annotation noise, a.k.a noisy correspondence (NC), thereby inevitably leading to a performance drop.","meta":{"url":"http://arxiv.org/abs/2310.17468v1"},"cats":{"benchmark":0.5935914083,"new-dataset":0.0385017723,"data-annotation":0.5591285795,"dev-research":0.1912043102,"llms":0.4954085547,"data-quality":0.6138795251}}
{"text":"Although some methods attempt to address such noise, they still face two challenging problems: excessive memorizing/overfitting and unreliable correction for NC, especially under high noise.","meta":{"url":"http://arxiv.org/abs/2310.17468v1"},"cats":{"benchmark":0.5039304932,"new-dataset":0.0409362843,"data-annotation":0.5184692094,"dev-research":0.3201352132,"llms":0.5370574102,"data-quality":0.4866396356}}
{"text":"To address the two problems, we propose a generalized Cross-modal Robust Complementary Learning framework (CRCL), which benefits from a novel Active Complementary Loss (ACL) and an efficient Self-refining Correspondence Correction (SCC) to improve the robustness of existing methods.","meta":{"url":"http://arxiv.org/abs/2310.17468v1"},"cats":{"benchmark":0.5447972575,"new-dataset":0.0253034078,"data-annotation":0.5080278495,"dev-research":0.1311684852,"llms":0.3997410077,"data-quality":0.3492174482}}
{"text":"Specifically, ACL exploits active and complementary learning losses to reduce the risk of providing erroneous supervision, leading to theoretically and experimentally demonstrated robustness against NC.","meta":{"url":"http://arxiv.org/abs/2310.17468v1"},"cats":{"benchmark":0.3114326071,"new-dataset":0.0073950084,"data-annotation":0.5305319537,"dev-research":0.2652736336,"llms":0.5166348041,"data-quality":0.2930764642}}
{"text":"SCC utilizes multiple self-refining processes with momentum correction to enlarge the receptive field for correcting correspondences, thereby alleviating error accumulation and achieving accurate and stable corrections.","meta":{"url":"http://arxiv.org/abs/2310.17468v1"},"cats":{"benchmark":0.4246303262,"new-dataset":0.0070319622,"data-annotation":0.4957379439,"dev-research":0.1705860515,"llms":0.5283406651,"data-quality":0.1692880905}}
{"text":"We carry out extensive experiments on three image-text benchmarks, i.e., Flickr30K, MS-COCO, and CC152K, to verify the superior robustness of our CRCL against synthetic and real-world noisy correspondences.","meta":{"url":"http://arxiv.org/abs/2310.17468v1"},"cats":{"benchmark":0.5758279311,"new-dataset":0.3556831776,"data-annotation":0.5162347321,"dev-research":0.1589219884,"llms":0.4460751801,"data-quality":0.3594026565}}
{"text":"Treatment effect estimation in continuous time is crucial for personalized medicine.","meta":{"url":"http://arxiv.org/abs/2310.17463v1"},"cats":{"benchmark":0.5153219507,"new-dataset":0.0211409692,"data-annotation":0.496780718,"dev-research":0.1894909174,"llms":0.3943957028,"data-quality":0.0796380328}}
{"text":"However, existing methods for this task are limited to point estimates of the potential outcomes, whereas uncertainty estimates have been ignored.","meta":{"url":"http://arxiv.org/abs/2310.17463v1"},"cats":{"benchmark":0.5479498831,"new-dataset":0.0145201296,"data-annotation":0.5174904368,"dev-research":0.1591759096,"llms":0.3494512482,"data-quality":0.0738424333}}
{"text":"Needless to say, uncertainty quantification is crucial for reliable decision-making in medical applications.","meta":{"url":"http://arxiv.org/abs/2310.17463v1"},"cats":{"benchmark":0.4507663884,"new-dataset":0.0037338246,"data-annotation":0.4838268946,"dev-research":0.3196199875,"llms":0.4772931245,"data-quality":0.1965294059}}
{"text":"To fill this gap, we propose a novel Bayesian neural controlled differential equation (BNCDE) for treatment effect estimation in continuous time.","meta":{"url":"http://arxiv.org/abs/2310.17463v1"},"cats":{"benchmark":0.3962795482,"new-dataset":0.0532455141,"data-annotation":0.4704312514,"dev-research":0.1598734295,"llms":0.4393343552,"data-quality":0.0712455774}}
{"text":"In our BNCDE, the time dimension is modeled through a coupled system of neural controlled differential equations and neural stochastic differential equations, where the neural stochastic differential equations allow for tractable variational Bayesian inference.","meta":{"url":"http://arxiv.org/abs/2310.17463v1"},"cats":{"benchmark":0.2765206951,"new-dataset":0.0592821637,"data-annotation":0.5024641628,"dev-research":0.1357260625,"llms":0.4934610101,"data-quality":0.0510161845}}
{"text":"Thereby, for an assigned sequence of treatments, our BNCDE provides meaningful posterior predictive distributions of the potential outcomes.","meta":{"url":"http://arxiv.org/abs/2310.17463v1"},"cats":{"benchmark":0.4969533805,"new-dataset":0.0207715485,"data-annotation":0.5058617735,"dev-research":0.1364292151,"llms":0.4849323344,"data-quality":0.0636156479}}
{"text":"To the best of our knowledge, ours is the first tailored neural method to provide uncertainty estimates of treatment effects in continuous time.","meta":{"url":"http://arxiv.org/abs/2310.17463v1"},"cats":{"benchmark":0.4262576965,"new-dataset":0.0049427475,"data-annotation":0.4892052834,"dev-research":0.1952454381,"llms":0.4141452307,"data-quality":0.0927917712}}
{"text":"As such, our method is of direct practical value for promoting reliable decision-making in medicine.","meta":{"url":"http://arxiv.org/abs/2310.17463v1"},"cats":{"benchmark":0.4668148784,"new-dataset":0.0098817196,"data-annotation":0.4875322037,"dev-research":0.3232543026,"llms":0.5383271097,"data-quality":0.1561972766}}
{"text":"We present a novel method for precise 3D object localization in single images from a single calibrated camera using only 2D labels.","meta":{"url":"http://arxiv.org/abs/2310.17462v1"},"cats":{"benchmark":0.3436673169,"new-dataset":0.0795373287,"data-annotation":0.5079245707,"dev-research":0.16907927,"llms":0.4698844129,"data-quality":0.2765549912}}
{"text":"No expensive 3D labels are needed.","meta":{"url":"http://arxiv.org/abs/2310.17462v1"},"cats":{"benchmark":0.2592104712,"new-dataset":0.1089678679,"data-annotation":0.4952567255,"dev-research":0.1756099577,"llms":0.5670634946,"data-quality":0.2018658482}}
{"text":"Thus, instead of using 3D labels, our model is trained with easy-to-annotate 2D labels along with the physical knowledge of the object's motion.","meta":{"url":"http://arxiv.org/abs/2310.17462v1"},"cats":{"benchmark":0.2002867133,"new-dataset":0.1342907989,"data-annotation":0.5299124678,"dev-research":0.1964781525,"llms":0.5054180406,"data-quality":0.2929365386}}
{"text":"Given this information, the model can infer the latent third dimension, even though it has never seen this information during training.","meta":{"url":"http://arxiv.org/abs/2310.17462v1"},"cats":{"benchmark":0.1910653232,"new-dataset":0.0410772594,"data-annotation":0.529857046,"dev-research":0.1006944546,"llms":0.4770892849,"data-quality":0.1438046641}}
{"text":"Our method is evaluated on both synthetic and real-world datasets, and we are able to achieve a mean distance error of just 6 cm in our experiments on real data.","meta":{"url":"http://arxiv.org/abs/2310.17462v1"},"cats":{"benchmark":0.5416646484,"new-dataset":0.2908743611,"data-annotation":0.5180689845,"dev-research":0.1696449046,"llms":0.4035129393,"data-quality":0.2214192918}}
{"text":"The results indicate the method's potential as a step towards learning 3D object location estimation, where collecting 3D data for training is not feasible.","meta":{"url":"http://arxiv.org/abs/2310.17462v1"},"cats":{"benchmark":0.2444477152,"new-dataset":0.0500814307,"data-annotation":0.5287926105,"dev-research":0.1822207463,"llms":0.4700927898,"data-quality":0.1512021266}}
{"text":"Collaborative Vehicle Routing is where delivery companies cooperate by sharing their delivery information and performing delivery requests on behalf of each other.","meta":{"url":"http://arxiv.org/abs/2310.17458v1"},"cats":{"benchmark":0.2803541597,"new-dataset":0.013854093,"data-annotation":0.4738025638,"dev-research":0.2459885684,"llms":0.512097385,"data-quality":0.083922003}}
{"text":"This achieves economies of scale and thus reduces cost, greenhouse gas emissions, and road congestion.","meta":{"url":"http://arxiv.org/abs/2310.17458v1"},"cats":{"benchmark":0.3924924786,"new-dataset":0.0090470793,"data-annotation":0.4827276999,"dev-research":0.1973012541,"llms":0.4129728997,"data-quality":0.0416738816}}
{"text":"But which company should partner with whom, and how much should each company be compensated?","meta":{"url":"http://arxiv.org/abs/2310.17458v1"},"cats":{"benchmark":0.322515141,"new-dataset":0.0811133343,"data-annotation":0.4999562742,"dev-research":0.1805896091,"llms":0.5040280242,"data-quality":0.1086028971}}
{"text":"Traditional game theoretic solution concepts, such as the Shapley value or nucleolus, are difficult to calculate for the real-world problem of Collaborative Vehicle Routing due to the characteristic function scaling exponentially with the number of agents.","meta":{"url":"http://arxiv.org/abs/2310.17458v1"},"cats":{"benchmark":0.3150883058,"new-dataset":0.0150912574,"data-annotation":0.5187023418,"dev-research":0.1634869292,"llms":0.472831014,"data-quality":0.0560902374}}
{"text":"This would require solving the Vehicle Routing Problem (an NP-Hard problem) an exponential number of times.","meta":{"url":"http://arxiv.org/abs/2310.17458v1"},"cats":{"benchmark":0.4081455477,"new-dataset":0.0226351818,"data-annotation":0.5146794512,"dev-research":0.169207967,"llms":0.3863918123,"data-quality":0.0663459374}}
{"text":"We therefore propose to model this problem as a coalitional bargaining game where - crucially - agents are not given access to the characteristic function.","meta":{"url":"http://arxiv.org/abs/2310.17458v1"},"cats":{"benchmark":0.2630512537,"new-dataset":0.0266858511,"data-annotation":0.5048070348,"dev-research":0.1253501864,"llms":0.4717179394,"data-quality":0.0594710855}}
{"text":"Instead, we implicitly reason about the characteristic function, and thus eliminate the need to evaluate the VRP an exponential number of times - we only need to evaluate it once.","meta":{"url":"http://arxiv.org/abs/2310.17458v1"},"cats":{"benchmark":0.3725893128,"new-dataset":0.005635561,"data-annotation":0.505679764,"dev-research":0.1734417629,"llms":0.4167342728,"data-quality":0.0602922139}}
{"text":"Our contribution is that our decentralised approach is both scalable and considers the self-interested nature of companies.","meta":{"url":"http://arxiv.org/abs/2310.17458v1"},"cats":{"benchmark":0.3233292527,"new-dataset":0.0088639779,"data-annotation":0.5037962808,"dev-research":0.1569916246,"llms":0.5318441943,"data-quality":0.07194892}}
{"text":"The agents learn using a modified Independent Proximal Policy Optimisation.","meta":{"url":"http://arxiv.org/abs/2310.17458v1"},"cats":{"benchmark":0.3024230233,"new-dataset":0.0195207277,"data-annotation":0.5078171749,"dev-research":0.1550309348,"llms":0.4323790768,"data-quality":0.0595925924}}
{"text":"Our RL agents outperform a strong heuristic bot.","meta":{"url":"http://arxiv.org/abs/2310.17458v1"},"cats":{"benchmark":0.3058572211,"new-dataset":0.0843569031,"data-annotation":0.5269527178,"dev-research":0.1843031289,"llms":0.5657666607,"data-quality":0.1289566966}}
{"text":"The agents correctly identify the optimal coalitions 79% of the time with an average optimality gap of 4.2% and reduction in run-time of 62%.","meta":{"url":"http://arxiv.org/abs/2310.17458v1"},"cats":{"benchmark":0.4964032394,"new-dataset":0.0334785015,"data-annotation":0.5142701057,"dev-research":0.1449177508,"llms":0.4211380186,"data-quality":0.0747915428}}
{"text":"Semi-supervised learning has made remarkable strides by effectively utilizing a limited amount of labeled data while capitalizing on the abundant information present in unlabeled data.","meta":{"url":"http://arxiv.org/abs/2310.17455v1"},"cats":{"benchmark":0.3740324506,"new-dataset":0.147742762,"data-annotation":0.5115913271,"dev-research":0.1620198229,"llms":0.4601173477,"data-quality":0.507457608}}
{"text":"However, current algorithms often prioritize aligning image predictions with specific classes generated through self-training techniques, thereby neglecting the inherent relationships that exist within these classes.","meta":{"url":"http://arxiv.org/abs/2310.17455v1"},"cats":{"benchmark":0.4090720284,"new-dataset":0.0215769372,"data-annotation":0.5472981376,"dev-research":0.1625590901,"llms":0.4304420709,"data-quality":0.2223078724}}
{"text":"In this paper, we present a new approach called OTMatch, which leverages semantic relationships among classes by employing an optimal transport loss function.","meta":{"url":"http://arxiv.org/abs/2310.17455v1"},"cats":{"benchmark":0.3060568036,"new-dataset":0.0611425903,"data-annotation":0.5524734635,"dev-research":0.1788177985,"llms":0.5093056445,"data-quality":0.2649158885}}
{"text":"By utilizing optimal transport, our proposed method consistently outperforms established state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2310.17455v1"},"cats":{"benchmark":0.6921865055,"new-dataset":0.0022794955,"data-annotation":0.5149328228,"dev-research":0.148182859,"llms":0.3542469435,"data-quality":0.0974601359}}
{"text":"Notably, we observed a substantial improvement of a certain percentage in accuracy compared to the current state-of-the-art method, FreeMatch.","meta":{"url":"http://arxiv.org/abs/2310.17455v1"},"cats":{"benchmark":0.6895427175,"new-dataset":0.0527160992,"data-annotation":0.5699930125,"dev-research":0.1825571829,"llms":0.5307973975,"data-quality":0.1683616015}}
{"text":"OTMatch achieves 3.18%, 3.46%, and 1.28% error rate reduction over FreeMatch on CIFAR-10 with 1 label per class, STL-10 with 4 labels per class, and ImageNet with 100 labels per class, respectively.","meta":{"url":"http://arxiv.org/abs/2310.17455v1"},"cats":{"benchmark":0.6107487426,"new-dataset":0.150641442,"data-annotation":0.5555346776,"dev-research":0.1829995047,"llms":0.5792098181,"data-quality":0.4208206269}}
{"text":"This demonstrates the effectiveness and superiority of our approach in harnessing semantic relationships to enhance learning performance in a semi-supervised setting.","meta":{"url":"http://arxiv.org/abs/2310.17455v1"},"cats":{"benchmark":0.3498002283,"new-dataset":0.0958625502,"data-annotation":0.530455363,"dev-research":0.2580400176,"llms":0.5102306783,"data-quality":0.2700090992}}
{"text":"Despite the great success of neural visual generative models in recent years, integrating them with strong symbolic knowledge reasoning systems remains a challenging task.","meta":{"url":"http://arxiv.org/abs/2310.17451v1"},"cats":{"benchmark":0.165220553,"new-dataset":0.1173155898,"data-annotation":0.502429841,"dev-research":0.2502967438,"llms":0.5437461651,"data-quality":0.1254230432}}
{"text":"The main challenges are two-fold: one is symbol assignment, i.e. bonding latent factors of neural visual generators with meaningful symbols from knowledge reasoning systems.","meta":{"url":"http://arxiv.org/abs/2310.17451v1"},"cats":{"benchmark":0.163557251,"new-dataset":0.0477635519,"data-annotation":0.5315744376,"dev-research":0.2998913338,"llms":0.5564065688,"data-quality":0.142332065}}
{"text":"Another is rule learning, i.e. learning new rules, which govern the generative process of the data, to augment the knowledge reasoning systems.","meta":{"url":"http://arxiv.org/abs/2310.17451v1"},"cats":{"benchmark":0.2063533558,"new-dataset":0.0377918072,"data-annotation":0.4817351274,"dev-research":0.3814991365,"llms":0.503814214,"data-quality":0.139568559}}
{"text":"To deal with these symbol grounding problems, we propose a neural-symbolic learning approach, Abductive Visual Generation (AbdGen), for integrating logic programming systems with neural visual generative models based on the abductive learning framework.","meta":{"url":"http://arxiv.org/abs/2310.17451v1"},"cats":{"benchmark":0.1382083633,"new-dataset":0.1761861254,"data-annotation":0.5196731253,"dev-research":0.3279815055,"llms":0.5774427413,"data-quality":0.1090790515}}
{"text":"To achieve reliable and efficient symbol assignment, the quantized abduction method is introduced for generating abduction proposals by the nearest-neighbor lookups within semantic codebooks.","meta":{"url":"http://arxiv.org/abs/2310.17451v1"},"cats":{"benchmark":0.2928667034,"new-dataset":0.1213410966,"data-annotation":0.5533813234,"dev-research":0.3066207077,"llms":0.5140665028,"data-quality":0.2437097114}}
{"text":"To achieve precise rule learning, the contrastive meta-abduction method is proposed to eliminate wrong rules with positive cases and avoid less-informative rules with negative cases simultaneously.","meta":{"url":"http://arxiv.org/abs/2310.17451v1"},"cats":{"benchmark":0.4320703894,"new-dataset":0.0364149307,"data-annotation":0.5181476154,"dev-research":0.2423674318,"llms":0.4546150024,"data-quality":0.3152817281}}
{"text":"Experimental results on various benchmark datasets show that compared to the baselines, AbdGen requires significantly fewer instance-level labeling information for symbol assignment.","meta":{"url":"http://arxiv.org/abs/2310.17451v1"},"cats":{"benchmark":0.5133818987,"new-dataset":0.1079700294,"data-annotation":0.5464837196,"dev-research":0.2013389095,"llms":0.5817279257,"data-quality":0.389508393}}
{"text":"Furthermore, our approach can effectively learn underlying logical generative rules from data, which is out of the capability of existing approaches.","meta":{"url":"http://arxiv.org/abs/2310.17451v1"},"cats":{"benchmark":0.2535698661,"new-dataset":0.1124388497,"data-annotation":0.4896569265,"dev-research":0.304339244,"llms":0.5383296998,"data-quality":0.2174724018}}
{"text":"Humans excel at transferring manipulation skills across diverse object shapes, poses, and appearances due to their understanding of semantic correspondences between different instances.","meta":{"url":"http://arxiv.org/abs/2310.16838v1"},"cats":{"benchmark":0.1512694969,"new-dataset":0.1173831427,"data-annotation":0.51764764,"dev-research":0.2408260327,"llms":0.5309694379,"data-quality":0.1091558147}}
{"text":"To endow robots with a similar high-level understanding, we develop a Distilled Feature Field (DFF) for 3D scenes, leveraging large 2D vision models to distill semantic features from multiview images.","meta":{"url":"http://arxiv.org/abs/2310.16838v1"},"cats":{"benchmark":0.17484771,"new-dataset":0.3411292919,"data-annotation":0.5001263232,"dev-research":0.2137004849,"llms":0.5225951659,"data-quality":0.1073964742}}
{"text":"While current research demonstrates advanced performance in reconstructing DFFs from dense views, the development of learning a DFF from sparse views is relatively nascent, despite its prevalence in numerous manipulation tasks with fixed cameras.","meta":{"url":"http://arxiv.org/abs/2310.16838v1"},"cats":{"benchmark":0.3164727588,"new-dataset":0.2555634552,"data-annotation":0.4915439658,"dev-research":0.2047581534,"llms":0.4925611982,"data-quality":0.1421737412}}
{"text":"In this work, we introduce SparseDFF, a novel method for acquiring view-consistent 3D DFFs from sparse RGBD observations, enabling one-shot learning of dexterous manipulations that are transferable to novel scenes.","meta":{"url":"http://arxiv.org/abs/2310.16838v1"},"cats":{"benchmark":0.3015338287,"new-dataset":0.4265609415,"data-annotation":0.5013732078,"dev-research":0.1841562301,"llms":0.4420283125,"data-quality":0.1108030615}}
{"text":"Specifically, we map the image features to the 3D point cloud, allowing for propagation across the 3D space to establish a dense feature field.","meta":{"url":"http://arxiv.org/abs/2310.16838v1"},"cats":{"benchmark":0.2458685359,"new-dataset":0.0537954186,"data-annotation":0.4894573942,"dev-research":0.1735001807,"llms":0.4294074336,"data-quality":0.0759564068}}
{"text":"At the core of SparseDFF is a lightweight feature refinement network, optimized with a contrastive loss between pairwise views after back-projecting the image features onto the 3D point cloud.","meta":{"url":"http://arxiv.org/abs/2310.16838v1"},"cats":{"benchmark":0.4653834763,"new-dataset":0.1154111801,"data-annotation":0.5121423386,"dev-research":0.1731136503,"llms":0.3981157951,"data-quality":0.1051897095}}
{"text":"Additionally, we implement a point-pruning mechanism to augment feature continuity within each local neighborhood.","meta":{"url":"http://arxiv.org/abs/2310.16838v1"},"cats":{"benchmark":0.454279872,"new-dataset":0.0262081047,"data-annotation":0.4982095758,"dev-research":0.2968370705,"llms":0.4486455485,"data-quality":0.1741538533}}
{"text":"By establishing coherent feature fields on both source and target scenes, we devise an energy function that facilitates the minimization of feature discrepancies w.r.t.","meta":{"url":"http://arxiv.org/abs/2310.16838v1"},"cats":{"benchmark":0.4009348032,"new-dataset":0.029696912,"data-annotation":0.5269116059,"dev-research":0.2358843749,"llms":0.3490368319,"data-quality":0.2680824644}}
{"text":"the end-effector parameters between the demonstration and the target manipulation.","meta":{"url":"http://arxiv.org/abs/2310.16838v1"},"cats":{"benchmark":0.2872203091,"new-dataset":0.0124882528,"data-annotation":0.5234472117,"dev-research":0.2077346177,"llms":0.518086321,"data-quality":0.0962634363}}
{"text":"We evaluate our approach using a dexterous hand, mastering real-world manipulations on both rigid and deformable objects, and showcase robust generalization in the face of object and scene-context variations.","meta":{"url":"http://arxiv.org/abs/2310.16838v1"},"cats":{"benchmark":0.250260819,"new-dataset":0.163377913,"data-annotation":0.5189485935,"dev-research":0.1905843707,"llms":0.4540034589,"data-quality":0.0661669383}}
{"text":"Benefiting from high-quality datasets and standardized evaluation metrics, machine learning (ML) has achieved sustained progress and widespread applications.","meta":{"url":"http://arxiv.org/abs/2310.16837v1"},"cats":{"benchmark":0.5124493674,"new-dataset":0.1272031799,"data-annotation":0.4926061278,"dev-research":0.2301234566,"llms":0.4682338393,"data-quality":0.2168080706}}
{"text":"However, while applying machine learning to relational databases (RDBs), the absence of a well-established benchmark remains a significant obstacle to the development of ML.","meta":{"url":"http://arxiv.org/abs/2310.16837v1"},"cats":{"benchmark":0.5261742734,"new-dataset":0.0414391551,"data-annotation":0.4937379226,"dev-research":0.2266871985,"llms":0.4531797821,"data-quality":0.1856711949}}
{"text":"To address this issue, we introduce ML Benchmark For Relational Databases (RDBench), a standardized benchmark that aims to promote reproducible ML research on RDBs that include multiple tables.","meta":{"url":"http://arxiv.org/abs/2310.16837v1"},"cats":{"benchmark":0.6609992154,"new-dataset":0.2145986687,"data-annotation":0.488854121,"dev-research":0.2259409185,"llms":0.4760540921,"data-quality":0.1425306199}}
{"text":"RDBench offers diverse RDB datasets of varying scales, domains, and relational structures, organized into 4 levels.","meta":{"url":"http://arxiv.org/abs/2310.16837v1"},"cats":{"benchmark":0.295209836,"new-dataset":0.7008101216,"data-annotation":0.4826484652,"dev-research":0.1464789836,"llms":0.5433325374,"data-quality":0.0834465981}}
{"text":"Notably, to simplify the adoption of RDBench for diverse ML domains, for any given database, RDBench exposes three types of interfaces including tabular data, homogeneous graphs, and heterogeneous graphs, sharing the same underlying task definition.","meta":{"url":"http://arxiv.org/abs/2310.16837v1"},"cats":{"benchmark":0.2906703855,"new-dataset":0.1011517523,"data-annotation":0.4785620661,"dev-research":0.2147985975,"llms":0.5366960345,"data-quality":0.0824028859}}
{"text":"For the first time, RDBench enables meaningful comparisons between ML methods from diverse domains, ranging from XGBoost to Graph Neural Networks, under RDB prediction tasks.","meta":{"url":"http://arxiv.org/abs/2310.16837v1"},"cats":{"benchmark":0.5342383601,"new-dataset":0.0354486061,"data-annotation":0.5228319458,"dev-research":0.2041315993,"llms":0.5095634913,"data-quality":0.1266112299}}
{"text":"We design multiple classification and regression tasks for each RDB dataset and report averaged results over the same dataset, further enhancing the robustness of the experimental findings.","meta":{"url":"http://arxiv.org/abs/2310.16837v1"},"cats":{"benchmark":0.5221263356,"new-dataset":0.0827072724,"data-annotation":0.4816753294,"dev-research":0.2207882852,"llms":0.3974265046,"data-quality":0.2700840736}}
{"text":"RDBench is implemented with DBGym, a user-friendly platform for ML research and application on databases, enabling benchmarking new ML methods with RDBench at ease.","meta":{"url":"http://arxiv.org/abs/2310.16837v1"},"cats":{"benchmark":0.5219258128,"new-dataset":0.1692979345,"data-annotation":0.4920924153,"dev-research":0.2389364998,"llms":0.5669627454,"data-quality":0.1246244874}}
{"text":"We propose LLM-FP4 for quantizing both weights and activations in large language models (LLMs) down to 4-bit floating-point values, in a post-training manner.","meta":{"url":"http://arxiv.org/abs/2310.16836v1"},"cats":{"benchmark":0.3206343362,"new-dataset":0.0838658658,"data-annotation":0.551077925,"dev-research":0.1160679148,"llms":0.5954788627,"data-quality":0.1892687158}}
{"text":"Existing post-training quantization (PTQ) solutions are primarily integer-based and struggle with bit widths below 8 bits.","meta":{"url":"http://arxiv.org/abs/2310.16836v1"},"cats":{"benchmark":0.3026001006,"new-dataset":0.0701324288,"data-annotation":0.5188288799,"dev-research":0.163644187,"llms":0.5229036284,"data-quality":0.132131692}}
{"text":"Compared to integer quantization, floating-point (FP) quantization is more flexible and can better handle long-tail or bell-shaped distributions, and it has emerged as a default choice in many hardware platforms.","meta":{"url":"http://arxiv.org/abs/2310.16836v1"},"cats":{"benchmark":0.5143918134,"new-dataset":0.007009593,"data-annotation":0.4967707792,"dev-research":0.172852278,"llms":0.4634599144,"data-quality":0.0809781048}}
{"text":"One characteristic of FP quantization is that its performance largely depends on the choice of exponent bits and clipping range.","meta":{"url":"http://arxiv.org/abs/2310.16836v1"},"cats":{"benchmark":0.5178453432,"new-dataset":0.0047536676,"data-annotation":0.510120939,"dev-research":0.146871959,"llms":0.4505178715,"data-quality":0.0895706225}}
{"text":"In this regard, we construct a strong FP-PTQ baseline by searching for the optimal quantization parameters.","meta":{"url":"http://arxiv.org/abs/2310.16836v1"},"cats":{"benchmark":0.6159312504,"new-dataset":0.0403459798,"data-annotation":0.5103252627,"dev-research":0.1092616216,"llms":0.4046093514,"data-quality":0.1011227431}}
{"text":"Furthermore, we observe a high inter-channel variance and low intra-channel variance pattern in activation distributions, which adds activation quantization difficulty.","meta":{"url":"http://arxiv.org/abs/2310.16836v1"},"cats":{"benchmark":0.3687519142,"new-dataset":0.0077409826,"data-annotation":0.5215472689,"dev-research":0.1505974197,"llms":0.4340554857,"data-quality":0.145579342}}
{"text":"We recognize this pattern to be consistent across a spectrum of transformer models designed for diverse tasks, such as LLMs, BERT, and Vision Transformer models.","meta":{"url":"http://arxiv.org/abs/2310.16836v1"},"cats":{"benchmark":0.2572796506,"new-dataset":0.0214545449,"data-annotation":0.4918808076,"dev-research":0.1275539114,"llms":0.5548718634,"data-quality":0.0970409156}}
{"text":"To tackle this, we propose per-channel activation quantization and show that these additional scaling factors can be reparameterized as exponential biases of weights, incurring a negligible cost.","meta":{"url":"http://arxiv.org/abs/2310.16836v1"},"cats":{"benchmark":0.4416850065,"new-dataset":0.0088828301,"data-annotation":0.5208540808,"dev-research":0.1121816192,"llms":0.4250980731,"data-quality":0.123736712}}
{"text":"Our method, for the first time, can quantize both weights and activations in the LLaMA-13B to only 4-bit and achieves an average score of 63.1 on the common sense zero-shot reasoning tasks, which is only 5.8 lower than the full-precision model, significantly outperforming the previous state-of-the-art by 12.7 points.","meta":{"url":"http://arxiv.org/abs/2310.16836v1"},"cats":{"benchmark":0.3592987097,"new-dataset":0.0609034359,"data-annotation":0.545263583,"dev-research":0.1352139367,"llms":0.6148043595,"data-quality":0.1448715768}}
{"text":"Code is available at: https://github.com/nbasyl/LLM-FP4.","meta":{"url":"http://arxiv.org/abs/2310.16836v1"},"cats":{"benchmark":0.2783730511,"new-dataset":0.1457879644,"data-annotation":0.5325623138,"dev-research":0.1204212614,"llms":0.7011197325,"data-quality":0.0949127476}}
{"text":"The use of pretrained deep neural networks represents an attractive way to achieve strong results with few data available.","meta":{"url":"http://arxiv.org/abs/2310.16835v1"},"cats":{"benchmark":0.2908325196,"new-dataset":0.1045432545,"data-annotation":0.5164819864,"dev-research":0.1756466308,"llms":0.4634863178,"data-quality":0.116100392}}
{"text":"When specialized in dense problems such as object detection, learning local rather than global information in images has proven to be more efficient.","meta":{"url":"http://arxiv.org/abs/2310.16835v1"},"cats":{"benchmark":0.2867444797,"new-dataset":0.023276978,"data-annotation":0.5269973252,"dev-research":0.1671819284,"llms":0.4524801172,"data-quality":0.1790730524}}
{"text":"However, for unsupervised pretraining, the popular contrastive learning requires a large batch size and, therefore, a lot of resources.","meta":{"url":"http://arxiv.org/abs/2310.16835v1"},"cats":{"benchmark":0.2339640078,"new-dataset":0.0572626759,"data-annotation":0.5289190931,"dev-research":0.1575469981,"llms":0.5814784627,"data-quality":0.0771107056}}
{"text":"To address this problem, we are interested in transformer-based object detectors that have recently gained traction in the community with good performance and with the particularity of generating many diverse object proposals.   ","meta":{"url":"http://arxiv.org/abs/2310.16835v1"},"cats":{"benchmark":0.2415304292,"new-dataset":0.1192324613,"data-annotation":0.5222809175,"dev-research":0.1593167222,"llms":0.560087529,"data-quality":0.1605736931}}
{"text":"In this work, we present Proposal Selection Contrast (ProSeCo), a novel unsupervised overall pretraining approach that leverages this property.","meta":{"url":"http://arxiv.org/abs/2310.16835v1"},"cats":{"benchmark":0.4450247813,"new-dataset":0.0332028306,"data-annotation":0.521125693,"dev-research":0.2583009546,"llms":0.5139898422,"data-quality":0.1124670153}}
{"text":"ProSeCo uses the large number of object proposals generated by the detector for contrastive learning, which allows the use of a smaller batch size, combined with object-level features to learn local information in the images.","meta":{"url":"http://arxiv.org/abs/2310.16835v1"},"cats":{"benchmark":0.2196351744,"new-dataset":0.2244498503,"data-annotation":0.5192811332,"dev-research":0.1686735131,"llms":0.5581833963,"data-quality":0.1668496136}}
{"text":"To improve the effectiveness of the contrastive loss, we introduce the object location information in the selection of positive examples to take into account multiple overlapping object proposals.","meta":{"url":"http://arxiv.org/abs/2310.16835v1"},"cats":{"benchmark":0.3871426381,"new-dataset":0.0713718516,"data-annotation":0.5525079756,"dev-research":0.2243062503,"llms":0.4575513394,"data-quality":0.2600634263}}
{"text":"When reusing pretrained backbone, we advocate for consistency in learning local information between the backbone and the detection head.   ","meta":{"url":"http://arxiv.org/abs/2310.16835v1"},"cats":{"benchmark":0.2551210657,"new-dataset":0.0666231461,"data-annotation":0.5061274504,"dev-research":0.1883434353,"llms":0.5211044794,"data-quality":0.1624100094}}
{"text":"We show that our method outperforms state of the art in unsupervised pretraining for object detection on standard and novel benchmarks in learning with fewer data.","meta":{"url":"http://arxiv.org/abs/2310.16835v1"},"cats":{"benchmark":0.3159279252,"new-dataset":0.1161417102,"data-annotation":0.5401719611,"dev-research":0.1672127804,"llms":0.468295986,"data-quality":0.1969033735}}
{"text":"Real-time novel-view image synthesis on mobile devices is prohibitive due to the limited computational power and storage.","meta":{"url":"http://arxiv.org/abs/2310.16832v1"},"cats":{"benchmark":0.2782037269,"new-dataset":0.138431179,"data-annotation":0.4989929466,"dev-research":0.2613937257,"llms":0.4351808206,"data-quality":0.0403107382}}
{"text":"Using volumetric rendering methods, such as NeRF and its derivatives, on mobile devices is not suitable due to the high computational cost of volumetric rendering.","meta":{"url":"http://arxiv.org/abs/2310.16832v1"},"cats":{"benchmark":0.4125735355,"new-dataset":0.0274223834,"data-annotation":0.5067023751,"dev-research":0.2169026237,"llms":0.4692336268,"data-quality":0.0714477791}}
{"text":"On the other hand, recent advances in neural light field representations have shown promising real-time view synthesis results on mobile devices.","meta":{"url":"http://arxiv.org/abs/2310.16832v1"},"cats":{"benchmark":0.2278010655,"new-dataset":0.0968746507,"data-annotation":0.5148714799,"dev-research":0.2078259906,"llms":0.4418850765,"data-quality":0.053549225}}
{"text":"Neural light field methods learn a direct mapping from a ray representation to the pixel color.","meta":{"url":"http://arxiv.org/abs/2310.16832v1"},"cats":{"benchmark":0.2091417884,"new-dataset":0.0752362208,"data-annotation":0.5155069182,"dev-research":0.1824426839,"llms":0.445995027,"data-quality":0.1020090709}}
{"text":"The current choice of ray representation is either stratified ray sampling or Pl\\\"{u}cker coordinates, overlooking the classic light slab (two-plane) representation, the preferred representation to interpolate between light field views.","meta":{"url":"http://arxiv.org/abs/2310.16832v1"},"cats":{"benchmark":0.3776258379,"new-dataset":0.0559017718,"data-annotation":0.4954581864,"dev-research":0.1325547967,"llms":0.5115341197,"data-quality":0.0619238571}}
{"text":"In this work, we find that using the light slab representation is an efficient representation for learning a neural light field.","meta":{"url":"http://arxiv.org/abs/2310.16832v1"},"cats":{"benchmark":0.263385863,"new-dataset":0.1298804439,"data-annotation":0.5272125187,"dev-research":0.1421045406,"llms":0.4262130013,"data-quality":0.096532586}}
{"text":"More importantly, it is a lower-dimensional ray representation enabling us to learn the 4D ray space using feature grids which are significantly faster to train and render.","meta":{"url":"http://arxiv.org/abs/2310.16832v1"},"cats":{"benchmark":0.2206095945,"new-dataset":0.0753438643,"data-annotation":0.5005169521,"dev-research":0.1995136299,"llms":0.5445431323,"data-quality":0.0392663873}}
{"text":"Although mostly designed for frontal views, we show that the light-slab representation can be further extended to non-frontal scenes using a divide-and-conquer strategy.","meta":{"url":"http://arxiv.org/abs/2310.16832v1"},"cats":{"benchmark":0.3162049894,"new-dataset":0.0610305202,"data-annotation":0.5087630285,"dev-research":0.1403882546,"llms":0.4147182367,"data-quality":0.0635727825}}
{"text":"Our method offers superior rendering quality compared to previous light field methods and achieves a significantly improved trade-off between rendering quality and speed.","meta":{"url":"http://arxiv.org/abs/2310.16832v1"},"cats":{"benchmark":0.5496183504,"new-dataset":0.0468709956,"data-annotation":0.5281863866,"dev-research":0.2488289742,"llms":0.4595186987,"data-quality":0.0806134215}}
{"text":"Neural Radiance Field (NeRF) has achieved substantial progress in novel view synthesis given multi-view images.","meta":{"url":"http://arxiv.org/abs/2310.16831v1"},"cats":{"benchmark":0.3108048948,"new-dataset":0.1477057373,"data-annotation":0.5085782095,"dev-research":0.1998117164,"llms":0.4339655643,"data-quality":0.1002531414}}
{"text":"Recently, some works have attempted to train a NeRF from a single image with 3D priors.","meta":{"url":"http://arxiv.org/abs/2310.16831v1"},"cats":{"benchmark":0.3381361965,"new-dataset":0.015371346,"data-annotation":0.5037923645,"dev-research":0.2042933634,"llms":0.509959434,"data-quality":0.1396775542}}
{"text":"They mainly focus on a limited field of view and there are few invisible occlusions, which greatly limits their scalability to real-world 360-degree panoramic scenarios with large-size occlusions.","meta":{"url":"http://arxiv.org/abs/2310.16831v1"},"cats":{"benchmark":0.2042286214,"new-dataset":0.0999062326,"data-annotation":0.5091443627,"dev-research":0.1901993433,"llms":0.4595155674,"data-quality":0.0410879874}}
{"text":"In this paper, we present PERF, a 360-degree novel view synthesis framework that trains a panoramic neural radiance field from a single panorama.","meta":{"url":"http://arxiv.org/abs/2310.16831v1"},"cats":{"benchmark":0.2412531354,"new-dataset":0.3230842908,"data-annotation":0.5039978701,"dev-research":0.1747936526,"llms":0.4300084298,"data-quality":0.054984301}}
{"text":"Notably, PERF allows 3D roaming in a complex scene without expensive and tedious image collection.","meta":{"url":"http://arxiv.org/abs/2310.16831v1"},"cats":{"benchmark":0.2284682399,"new-dataset":0.1346874761,"data-annotation":0.510521171,"dev-research":0.2032302297,"llms":0.5349848435,"data-quality":0.0594594422}}
{"text":"To achieve this goal, we propose a novel collaborative RGBD inpainting method and a progressive inpainting-and-erasing method to lift up a 360-degree 2D scene to a 3D scene.","meta":{"url":"http://arxiv.org/abs/2310.16831v1"},"cats":{"benchmark":0.3206410733,"new-dataset":0.0836120843,"data-annotation":0.5000222494,"dev-research":0.2330323839,"llms":0.4312177259,"data-quality":0.0748724327}}
{"text":"Specifically, we first predict a panoramic depth map as initialization given a single panorama, and reconstruct visible 3D regions with volume rendering.","meta":{"url":"http://arxiv.org/abs/2310.16831v1"},"cats":{"benchmark":0.2837299938,"new-dataset":0.1707543634,"data-annotation":0.5135483381,"dev-research":0.1422252066,"llms":0.4206086646,"data-quality":0.0431068241}}
{"text":"Then we introduce a collaborative RGBD inpainting approach into a NeRF for completing RGB images and depth maps from random views, which is derived from an RGB Stable Diffusion model and a monocular depth estimator.","meta":{"url":"http://arxiv.org/abs/2310.16831v1"},"cats":{"benchmark":0.423301245,"new-dataset":0.1003567056,"data-annotation":0.5119234405,"dev-research":0.1681315744,"llms":0.425431017,"data-quality":0.1345876047}}
{"text":"Finally, we introduce an inpainting-and-erasing strategy to avoid inconsistent geometry between a newly-sampled view and reference views.","meta":{"url":"http://arxiv.org/abs/2310.16831v1"},"cats":{"benchmark":0.4428125741,"new-dataset":0.0564671347,"data-annotation":0.5136252249,"dev-research":0.2106715497,"llms":0.4621588767,"data-quality":0.2129860802}}
{"text":"The two components are integrated into the learning of NeRFs in a unified optimization framework and achieve promising results.","meta":{"url":"http://arxiv.org/abs/2310.16831v1"},"cats":{"benchmark":0.5281911702,"new-dataset":0.013600887,"data-annotation":0.5154734943,"dev-research":0.2174539402,"llms":0.3908696423,"data-quality":0.1837903186}}
{"text":"Extensive experiments on Replica and a new dataset PERF-in-the-wild demonstrate the superiority of our PERF over state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2310.16831v1"},"cats":{"benchmark":0.4438299466,"new-dataset":0.4947686609,"data-annotation":0.5024566575,"dev-research":0.1280612815,"llms":0.5356734479,"data-quality":0.2118974998}}
{"text":"Our PERF can be widely used for real-world applications, such as panorama-to-3D, text-to-3D, and 3D scene stylization applications.","meta":{"url":"http://arxiv.org/abs/2310.16831v1"},"cats":{"benchmark":0.3179712747,"new-dataset":0.0462594654,"data-annotation":0.5142061742,"dev-research":0.1708854756,"llms":0.5000750971,"data-quality":0.0915701972}}
{"text":"Project page and code are available at https://perf-project.github.io/.","meta":{"url":"http://arxiv.org/abs/2310.16831v1"},"cats":{"benchmark":0.2147344566,"new-dataset":0.479796951,"data-annotation":0.5416292918,"dev-research":0.3222778965,"llms":0.5198191292,"data-quality":0.1062078301}}
{"text":"TD-MPC is a model-based reinforcement learning (RL) algorithm that performs local trajectory optimization in the latent space of a learned implicit (decoder-free) world model.","meta":{"url":"http://arxiv.org/abs/2310.16828v1"},"cats":{"benchmark":0.3053755186,"new-dataset":0.049344049,"data-annotation":0.5104709781,"dev-research":0.137593424,"llms":0.4229171412,"data-quality":0.0582369001}}
{"text":"In this work, we present TD-MPC2: a series of improvements upon the TD-MPC algorithm.","meta":{"url":"http://arxiv.org/abs/2310.16828v1"},"cats":{"benchmark":0.6391215835,"new-dataset":0.1325481409,"data-annotation":0.5263234339,"dev-research":0.1166900859,"llms":0.4072037528,"data-quality":0.1030401826}}
{"text":"We demonstrate that TD-MPC2 improves significantly over baselines across 104 online RL tasks spanning 4 diverse task domains, achieving consistently strong results with a single set of hyperparameters.","meta":{"url":"http://arxiv.org/abs/2310.16828v1"},"cats":{"benchmark":0.5897494876,"new-dataset":0.0741115048,"data-annotation":0.5145806463,"dev-research":0.1742023238,"llms":0.4760313333,"data-quality":0.1293723921}}
{"text":"We further show that agent capabilities increase with model and data size, and successfully train a single 317M parameter agent to perform 80 tasks across multiple task domains, embodiments, and action spaces.","meta":{"url":"http://arxiv.org/abs/2310.16828v1"},"cats":{"benchmark":0.229114996,"new-dataset":0.152607493,"data-annotation":0.4939746149,"dev-research":0.1651973095,"llms":0.560606718,"data-quality":0.0467973182}}
{"text":"We conclude with an account of lessons, opportunities, and risks associated with large TD-MPC2 agents.","meta":{"url":"http://arxiv.org/abs/2310.16828v1"},"cats":{"benchmark":0.2972598087,"new-dataset":0.0732544208,"data-annotation":0.5241550781,"dev-research":0.1458795435,"llms":0.5299038483,"data-quality":0.0748621968}}
{"text":"Explore videos, models, data, code, and more at https://nicklashansen.github.io/td-mpc2","meta":{"url":"http://arxiv.org/abs/2310.16828v1"},"cats":{"benchmark":0.2573434841,"new-dataset":0.513079197,"data-annotation":0.5206457163,"dev-research":0.172256346,"llms":0.501318913,"data-quality":0.0682350889}}
{"text":"Matroid intersection is a classical optimization problem where, given two matroids over the same ground set, the goal is to find the largest common independent set.","meta":{"url":"http://arxiv.org/abs/2310.16827v1"},"cats":{"benchmark":0.4797869308,"new-dataset":0.0994667843,"data-annotation":0.535203164,"dev-research":0.1357991026,"llms":0.37127327,"data-quality":0.1090196176}}
{"text":"In this paper, we show that there exists a certain \"sparsifer\": a subset of elements, of size $O(|S^{opt}| \\cdot 1/\\varepsilon)$, where $S^{opt}$ denotes the optimal solution, that is guaranteed to contain a $3/2 + \\varepsilon$ approximation, while guaranteeing certain robustness properties.","meta":{"url":"http://arxiv.org/abs/2310.16827v1"},"cats":{"benchmark":0.5383218321,"new-dataset":0.0228723072,"data-annotation":0.5387114697,"dev-research":0.1825701407,"llms":0.4743377053,"data-quality":0.1626006451}}
{"text":"We call such a small subset a Density Constrained Subset (DCS), which is inspired by the Edge-Degree Constrained Subgraph (EDCS)","meta":{"url":"http://arxiv.org/abs/2310.16827v1"},"cats":{"benchmark":0.3569412936,"new-dataset":0.1345991806,"data-annotation":0.501669798,"dev-research":0.1798416144,"llms":0.4826594663,"data-quality":0.147321833}}
{"text":"[Bernstein and Stein, 2015], originally designed for the maximum cardinality matching problem in a graph.","meta":{"url":"http://arxiv.org/abs/2310.16827v1"},"cats":{"benchmark":0.5429151944,"new-dataset":0.1325634874,"data-annotation":0.5140971633,"dev-research":0.1449001857,"llms":0.4376113217,"data-quality":0.1614998011}}
{"text":"Our proof is constructive and hinges on a greedy decomposition of matroids, which we call the density-based decomposition.","meta":{"url":"http://arxiv.org/abs/2310.16827v1"},"cats":{"benchmark":0.4044528974,"new-dataset":0.0344973052,"data-annotation":0.5277737792,"dev-research":0.1453275658,"llms":0.4507375471,"data-quality":0.1584254274}}
{"text":"We show that this sparsifier has certain robustness properties that can be used in one-way communication and random-order streaming models.","meta":{"url":"http://arxiv.org/abs/2310.16827v1"},"cats":{"benchmark":0.3953552632,"new-dataset":0.0321772239,"data-annotation":0.5123636039,"dev-research":0.135600799,"llms":0.5005988545,"data-quality":0.2971031977}}
{"text":"We assemble a dataset of Creative-Commons-licensed (CC) images, which we use to train a set of open diffusion models that are qualitatively competitive with Stable Diffusion 2 (SD2).","meta":{"url":"http://arxiv.org/abs/2310.16825v1"},"cats":{"benchmark":0.2583639411,"new-dataset":0.4128146623,"data-annotation":0.4974852324,"dev-research":0.1006385744,"llms":0.5157778598,"data-quality":0.1131062275}}
{"text":"This task presents two challenges: (1) high-resolution CC images lack the captions necessary to train text-to-image generative models; (2) CC images are relatively scarce.","meta":{"url":"http://arxiv.org/abs/2310.16825v1"},"cats":{"benchmark":0.2107814515,"new-dataset":0.3527866559,"data-annotation":0.5216690862,"dev-research":0.1309506541,"llms":0.5301064888,"data-quality":0.2268342733}}
{"text":"In turn, to address these challenges, we use an intuitive transfer learning technique to produce a set of high-quality synthetic captions paired with curated CC images.","meta":{"url":"http://arxiv.org/abs/2310.16825v1"},"cats":{"benchmark":0.2595285172,"new-dataset":0.3743165221,"data-annotation":0.5222967791,"dev-research":0.1826026932,"llms":0.5320420218,"data-quality":0.2477164886}}
{"text":"We then develop a data- and compute-efficient training recipe that requires as little as 3% of the LAION-2B data needed to train existing SD2 models, but obtains comparable quality.","meta":{"url":"http://arxiv.org/abs/2310.16825v1"},"cats":{"benchmark":0.4309078696,"new-dataset":0.1808601221,"data-annotation":0.5296872444,"dev-research":0.1465571067,"llms":0.4984004333,"data-quality":0.1755970394}}
{"text":"These results indicate that we have a sufficient number of CC images (~70 million) for training high-quality models.","meta":{"url":"http://arxiv.org/abs/2310.16825v1"},"cats":{"benchmark":0.2683840521,"new-dataset":0.3333450923,"data-annotation":0.5176668923,"dev-research":0.1254984595,"llms":0.510134436,"data-quality":0.1494428398}}
{"text":"Our training recipe also implements a variety of optimizations that achieve ~3X training speed-ups, enabling rapid model iteration.","meta":{"url":"http://arxiv.org/abs/2310.16825v1"},"cats":{"benchmark":0.4409021282,"new-dataset":0.0361100264,"data-annotation":0.5313473938,"dev-research":0.1841583008,"llms":0.4276919381,"data-quality":0.075381449}}
{"text":"We leverage this recipe to train several high-quality text-to-image models, which we dub the CommonCanvas family.","meta":{"url":"http://arxiv.org/abs/2310.16825v1"},"cats":{"benchmark":0.2266523484,"new-dataset":0.6030311244,"data-annotation":0.5114387177,"dev-research":0.149133748,"llms":0.5018815817,"data-quality":0.1840729221}}
{"text":"Our largest model achieves comparable performance to SD2 on a human evaluation, despite being trained on our CC dataset that is significantly smaller than LAION and using synthetic captions for training.","meta":{"url":"http://arxiv.org/abs/2310.16825v1"},"cats":{"benchmark":0.3724358469,"new-dataset":0.4160798586,"data-annotation":0.5466011145,"dev-research":0.1914733172,"llms":0.5059071807,"data-quality":0.2424637987}}
{"text":"We release our models, data, and code at https://github.com/mosaicml/diffusion/blob/main/assets/common-canvas.md","meta":{"url":"http://arxiv.org/abs/2310.16825v1"},"cats":{"benchmark":0.2562002741,"new-dataset":0.3193425554,"data-annotation":0.5003881096,"dev-research":0.1534126986,"llms":0.49322984,"data-quality":0.0583679736}}
{"text":"How can we better extract entities and relations from text?","meta":{"url":"http://arxiv.org/abs/2310.16822v1"},"cats":{"benchmark":0.3649530854,"new-dataset":0.1847928291,"data-annotation":0.5292627713,"dev-research":0.1974791482,"llms":0.531342994,"data-quality":0.2014922934}}
{"text":"Using multimodal extraction with images and text obtains more signals for entities and relations, and aligns them through graphs or hierarchical fusion, aiding in extraction.","meta":{"url":"http://arxiv.org/abs/2310.16822v1"},"cats":{"benchmark":0.318573437,"new-dataset":0.1979595169,"data-annotation":0.5206862007,"dev-research":0.1682358785,"llms":0.5024963909,"data-quality":0.1926028682}}
{"text":"Despite attempts at various fusions, previous works have overlooked many unlabeled image-caption pairs, such as NewsCLIPing.","meta":{"url":"http://arxiv.org/abs/2310.16822v1"},"cats":{"benchmark":0.3297380091,"new-dataset":0.1677367922,"data-annotation":0.5362965493,"dev-research":0.1741913668,"llms":0.5100374279,"data-quality":0.4306740108}}
{"text":"This paper proposes innovative pre-training objectives for entity-object and relation-image alignment, extracting objects from images and aligning them with entity and relation prompts for soft pseudo-labels.","meta":{"url":"http://arxiv.org/abs/2310.16822v1"},"cats":{"benchmark":0.3124803809,"new-dataset":0.2256897077,"data-annotation":0.5143239956,"dev-research":0.1783708359,"llms":0.5310533109,"data-quality":0.3529029295}}
{"text":"These labels are used as self-supervised signals for pre-training, enhancing the ability to extract entities and relations.","meta":{"url":"http://arxiv.org/abs/2310.16822v1"},"cats":{"benchmark":0.1808960215,"new-dataset":0.1466680839,"data-annotation":0.5283388537,"dev-research":0.1917884398,"llms":0.5429304387,"data-quality":0.3534512774}}
{"text":"Experiments on three datasets show an average 3.41% F1 improvement over prior SOTA.","meta":{"url":"http://arxiv.org/abs/2310.16822v1"},"cats":{"benchmark":0.6114067807,"new-dataset":0.0707237798,"data-annotation":0.5164410762,"dev-research":0.1653366387,"llms":0.4884110356,"data-quality":0.1455111767}}
{"text":"Additionally, our method is orthogonal to previous multimodal fusions, and using it on prior SOTA fusions further improves 5.47% F1.","meta":{"url":"http://arxiv.org/abs/2310.16822v1"},"cats":{"benchmark":0.5495340658,"new-dataset":0.0385936441,"data-annotation":0.5363864469,"dev-research":0.132284874,"llms":0.4920883065,"data-quality":0.1042612869}}
{"text":"We present DreamCraft3D, a hierarchical 3D content generation method that produces high-fidelity and coherent 3D objects.","meta":{"url":"http://arxiv.org/abs/2310.16818v1"},"cats":{"benchmark":0.2012346266,"new-dataset":0.1553547413,"data-annotation":0.4830565224,"dev-research":0.2096332225,"llms":0.5464030199,"data-quality":0.0494577874}}
{"text":"We tackle the problem by leveraging a 2D reference image to guide the stages of geometry sculpting and texture boosting.","meta":{"url":"http://arxiv.org/abs/2310.16818v1"},"cats":{"benchmark":0.4193603179,"new-dataset":0.0457723677,"data-annotation":0.5214489215,"dev-research":0.2265613016,"llms":0.4345975546,"data-quality":0.0912839163}}
{"text":"A central focus of this work is to address the consistency issue that existing works encounter.","meta":{"url":"http://arxiv.org/abs/2310.16818v1"},"cats":{"benchmark":0.3901993691,"new-dataset":0.0114530986,"data-annotation":0.4716561903,"dev-research":0.342467831,"llms":0.5538659656,"data-quality":0.2903202734}}
{"text":"To sculpt geometries that render coherently, we perform score distillation sampling via a view-dependent diffusion model.","meta":{"url":"http://arxiv.org/abs/2310.16818v1"},"cats":{"benchmark":0.406739562,"new-dataset":0.0177371399,"data-annotation":0.5066657481,"dev-research":0.1354857427,"llms":0.4749921063,"data-quality":0.0681792938}}
{"text":"This 3D prior, alongside several training strategies, prioritizes the geometry consistency but compromises the texture fidelity.","meta":{"url":"http://arxiv.org/abs/2310.16818v1"},"cats":{"benchmark":0.3418438102,"new-dataset":0.0191832665,"data-annotation":0.4881926032,"dev-research":0.1541016655,"llms":0.4637888799,"data-quality":0.0908201467}}
{"text":"We further propose Bootstrapped Score Distillation to specifically boost the texture.","meta":{"url":"http://arxiv.org/abs/2310.16818v1"},"cats":{"benchmark":0.5446991078,"new-dataset":0.0273546084,"data-annotation":0.5075448824,"dev-research":0.1581074264,"llms":0.4669673516,"data-quality":0.1756043256}}
{"text":"We train a personalized diffusion model, Dreambooth, on the augmented renderings of the scene, imbuing it with 3D knowledge of the scene being optimized.","meta":{"url":"http://arxiv.org/abs/2310.16818v1"},"cats":{"benchmark":0.2423340885,"new-dataset":0.1601669148,"data-annotation":0.5205152157,"dev-research":0.1581256256,"llms":0.4335319962,"data-quality":0.0657970694}}
{"text":"The score distillation from this 3D-aware diffusion prior provides view-consistent guidance for the scene.","meta":{"url":"http://arxiv.org/abs/2310.16818v1"},"cats":{"benchmark":0.3743469942,"new-dataset":0.0656610051,"data-annotation":0.4893439994,"dev-research":0.1524515998,"llms":0.4571265089,"data-quality":0.0860842902}}
{"text":"Notably, through an alternating optimization of the diffusion prior and 3D scene representation, we achieve mutually reinforcing improvements: the optimized 3D scene aids in training the scene-specific diffusion model, which offers increasingly view-consistent guidance for 3D optimization.","meta":{"url":"http://arxiv.org/abs/2310.16818v1"},"cats":{"benchmark":0.359123767,"new-dataset":0.0572744068,"data-annotation":0.5102247045,"dev-research":0.1753401165,"llms":0.3974596629,"data-quality":0.0840157565}}
{"text":"The optimization is thus bootstrapped and leads to substantial texture boosting.","meta":{"url":"http://arxiv.org/abs/2310.16818v1"},"cats":{"benchmark":0.4603146399,"new-dataset":0.0038309075,"data-annotation":0.5193948878,"dev-research":0.1767668191,"llms":0.4275718427,"data-quality":0.1509220734}}
{"text":"With tailored 3D priors throughout the hierarchical generation, DreamCraft3D generates coherent 3D objects with photorealistic renderings, advancing the state-of-the-art in 3D content generation.","meta":{"url":"http://arxiv.org/abs/2310.16818v1"},"cats":{"benchmark":0.1816665449,"new-dataset":0.1254761818,"data-annotation":0.4798798228,"dev-research":0.2234008633,"llms":0.5526681528,"data-quality":0.041931873}}
{"text":"Code available at https://github.com/deepseek-ai/DreamCraft3D.","meta":{"url":"http://arxiv.org/abs/2310.16818v1"},"cats":{"benchmark":0.2214341425,"new-dataset":0.1972930801,"data-annotation":0.5150931824,"dev-research":0.2152245122,"llms":0.5252677352,"data-quality":0.0643199308}}
{"text":"The agriculture sector requires a lot of labor and resources.","meta":{"url":"http://arxiv.org/abs/2310.16812v1"},"cats":{"benchmark":0.2175543894,"new-dataset":0.0609990018,"data-annotation":0.5099973369,"dev-research":0.1844050282,"llms":0.4946448996,"data-quality":0.057441279}}
{"text":"Hence, farmers are constantly being pressed for technology and automation to be cost-effective.","meta":{"url":"http://arxiv.org/abs/2310.16812v1"},"cats":{"benchmark":0.2101916085,"new-dataset":0.0344815778,"data-annotation":0.5041797227,"dev-research":0.2863762788,"llms":0.4824495216,"data-quality":0.0804836162}}
{"text":"In this context, autonomous robots can play a very important role in carrying out agricultural tasks such as spraying, sowing, inspection, and even harvesting.","meta":{"url":"http://arxiv.org/abs/2310.16812v1"},"cats":{"benchmark":0.2102157824,"new-dataset":0.0215779316,"data-annotation":0.5059668507,"dev-research":0.1492762009,"llms":0.4820144654,"data-quality":0.0655190627}}
{"text":"This paper presents one such autonomous robot that is able to identify plants and spray agro-chemicals precisely.","meta":{"url":"http://arxiv.org/abs/2310.16812v1"},"cats":{"benchmark":0.2790010334,"new-dataset":0.0833998674,"data-annotation":0.5083284534,"dev-research":0.1227071292,"llms":0.4805906302,"data-quality":0.1293362821}}
{"text":"The robot uses machine vision technologies to find plants and RTK-GPS technology to navigate the robot along a predetermined path.","meta":{"url":"http://arxiv.org/abs/2310.16812v1"},"cats":{"benchmark":0.1822200479,"new-dataset":0.0688429677,"data-annotation":0.5073760523,"dev-research":0.1866588382,"llms":0.4676970286,"data-quality":0.065741858}}
{"text":"The experiments were conducted in a field of potted plants in which successful results have been obtained.","meta":{"url":"http://arxiv.org/abs/2310.16812v1"},"cats":{"benchmark":0.3884856042,"new-dataset":0.0503882588,"data-annotation":0.5230496077,"dev-research":0.1512931758,"llms":0.5232969548,"data-quality":0.1433841614}}
{"text":"This study explores the capabilities of prompt-driven Large Language Models (LLMs) like ChatGPT and GPT-4 in adhering to human guidelines for dialogue summarization.","meta":{"url":"http://arxiv.org/abs/2310.16810v1"},"cats":{"benchmark":0.2178526661,"new-dataset":0.1884207333,"data-annotation":0.5324609444,"dev-research":0.2460182942,"llms":0.6318183249,"data-quality":0.1067500557}}
{"text":"Experiments employed DialogSum (English social conversations) and DECODA (French call center interactions), testing various prompts: including prompts from existing literature and those from human summarization guidelines, as well as a two-step prompt approach.","meta":{"url":"http://arxiv.org/abs/2310.16810v1"},"cats":{"benchmark":0.2098257883,"new-dataset":0.1186288455,"data-annotation":0.5269526124,"dev-research":0.2591485138,"llms":0.6238547409,"data-quality":0.1414157107}}
{"text":"Our findings indicate that GPT models often produce lengthy summaries and deviate from human summarization guidelines.","meta":{"url":"http://arxiv.org/abs/2310.16810v1"},"cats":{"benchmark":0.3551626925,"new-dataset":0.0436367591,"data-annotation":0.5263142464,"dev-research":0.2442848419,"llms":0.4566741845,"data-quality":0.1103356124}}
{"text":"However, using human guidelines as an intermediate step shows promise, outperforming direct word-length constraint prompts in some cases.","meta":{"url":"http://arxiv.org/abs/2310.16810v1"},"cats":{"benchmark":0.3551462529,"new-dataset":0.0128292478,"data-annotation":0.5230453963,"dev-research":0.3256448055,"llms":0.4937129346,"data-quality":0.2205804862}}
{"text":"The results reveal that GPT models exhibit unique stylistic tendencies in their summaries.","meta":{"url":"http://arxiv.org/abs/2310.16810v1"},"cats":{"benchmark":0.2915301085,"new-dataset":0.0270715703,"data-annotation":0.5420480376,"dev-research":0.184686088,"llms":0.4715586127,"data-quality":0.1430899913}}
{"text":"While BERTScores did not dramatically decrease for GPT outputs suggesting semantic similarity to human references and specialised pre-trained models, ROUGE scores reveal grammatical and lexical disparities between GPT-generated and human-written summaries.","meta":{"url":"http://arxiv.org/abs/2310.16810v1"},"cats":{"benchmark":0.3770248792,"new-dataset":0.0553490456,"data-annotation":0.5669363604,"dev-research":0.251014836,"llms":0.474389713,"data-quality":0.2229514024}}
{"text":"These findings shed light on the capabilities and limitations of GPT models in following human instructions for dialogue summarization.","meta":{"url":"http://arxiv.org/abs/2310.16810v1"},"cats":{"benchmark":0.2263232932,"new-dataset":0.0490701025,"data-annotation":0.5181827137,"dev-research":0.2185891028,"llms":0.5595511686,"data-quality":0.0848222234}}
{"text":"This paper presents a comprehensive evaluation of the Optical Character Recognition (OCR) capabilities of the recently released GPT-4V(ision), a Large Multimodal Model (LMM).","meta":{"url":"http://arxiv.org/abs/2310.16809v1"},"cats":{"benchmark":0.296031481,"new-dataset":0.1030432759,"data-annotation":0.5220117842,"dev-research":0.0753152986,"llms":0.4709871278,"data-quality":0.0951100464}}
{"text":"We assess the model's performance across a range of OCR tasks, including scene text recognition, handwritten text recognition, handwritten mathematical expression recognition, table structure recognition, and information extraction from visually-rich document.","meta":{"url":"http://arxiv.org/abs/2310.16809v1"},"cats":{"benchmark":0.4730058521,"new-dataset":0.1421312538,"data-annotation":0.5283856824,"dev-research":0.1511381884,"llms":0.410959474,"data-quality":0.1356304269}}
{"text":"The evaluation reveals that GPT-4V performs well in recognizing and understanding Latin contents, but struggles with multilingual scenarios and complex tasks.","meta":{"url":"http://arxiv.org/abs/2310.16809v1"},"cats":{"benchmark":0.3030206987,"new-dataset":0.149495796,"data-annotation":0.5292115706,"dev-research":0.1864712541,"llms":0.5683112577,"data-quality":0.2309122545}}
{"text":"Based on these observations, we delve deeper into the necessity of specialized OCR models and deliberate on the strategies to fully harness the pretrained general LMMs like GPT-4V for OCR downstream tasks.","meta":{"url":"http://arxiv.org/abs/2310.16809v1"},"cats":{"benchmark":0.2901581293,"new-dataset":0.0437402795,"data-annotation":0.5042948766,"dev-research":0.1090000007,"llms":0.5077963205,"data-quality":0.0940024283}}
{"text":"The study offers a critical reference for future research in OCR with LMMs.","meta":{"url":"http://arxiv.org/abs/2310.16809v1"},"cats":{"benchmark":0.3584934746,"new-dataset":0.0725456661,"data-annotation":0.5073286789,"dev-research":0.1244454503,"llms":0.5517336164,"data-quality":0.1442019754}}
{"text":"Evaluation pipeline and results are available at https://github.com/SCUT-DLVCLab/GPT-4V_OCR.","meta":{"url":"http://arxiv.org/abs/2310.16809v1"},"cats":{"benchmark":0.446193197,"new-dataset":0.3301415058,"data-annotation":0.5136094929,"dev-research":0.1208116896,"llms":0.5119317958,"data-quality":0.1334243986}}
{"text":"Biometric verification systems are deployed in various security-based access-control applications that require user-friendly and reliable person verification.","meta":{"url":"http://arxiv.org/abs/2310.16808v1"},"cats":{"benchmark":0.4688757414,"new-dataset":0.0543266388,"data-annotation":0.5148368781,"dev-research":0.2698841263,"llms":0.5148220046,"data-quality":0.0980623639}}
{"text":"Among the different biometric characteristics, fingervein biometrics have been extensively studied owing to their reliable verification performance.","meta":{"url":"http://arxiv.org/abs/2310.16808v1"},"cats":{"benchmark":0.5078664486,"new-dataset":0.0607808506,"data-annotation":0.5214951718,"dev-research":0.1413967018,"llms":0.4849080747,"data-quality":0.088508255}}
{"text":"Furthermore, fingervein patterns reside inside the skin and are not visible outside; therefore, they possess inherent resistance to presentation attacks and degradation due to external factors.","meta":{"url":"http://arxiv.org/abs/2310.16808v1"},"cats":{"benchmark":0.2401837287,"new-dataset":0.0757617313,"data-annotation":0.5262103819,"dev-research":0.2178791405,"llms":0.5274211971,"data-quality":0.0708526665}}
{"text":"In this paper, we introduce a novel fingervein verification technique using a convolutional multihead attention network called VeinAtnNet.","meta":{"url":"http://arxiv.org/abs/2310.16808v1"},"cats":{"benchmark":0.3547969666,"new-dataset":0.1257684849,"data-annotation":0.5260426367,"dev-research":0.1118621752,"llms":0.4979746203,"data-quality":0.1222433928}}
{"text":"The proposed VeinAtnNet is designed to achieve light weight with a smaller number of learnable parameters while extracting discriminant information from both normal and enhanced fingervein images.","meta":{"url":"http://arxiv.org/abs/2310.16808v1"},"cats":{"benchmark":0.2955657985,"new-dataset":0.1469894115,"data-annotation":0.5025185821,"dev-research":0.1140675911,"llms":0.4885366205,"data-quality":0.079209388}}
{"text":"The proposed VeinAtnNet was trained on the newly constructed fingervein dataset with 300 unique fingervein patterns that were captured in multiple sessions to obtain 92 samples per unique fingervein.","meta":{"url":"http://arxiv.org/abs/2310.16808v1"},"cats":{"benchmark":0.3192673037,"new-dataset":0.3366233221,"data-annotation":0.5024741608,"dev-research":0.1351667794,"llms":0.5174913537,"data-quality":0.1117863522}}
{"text":"Extensive experiments were performed on the newly collected dataset FV-300 and the publicly available FV-USM and FV-PolyU fingervein dataset.","meta":{"url":"http://arxiv.org/abs/2310.16808v1"},"cats":{"benchmark":0.3832236368,"new-dataset":0.6454222522,"data-annotation":0.5105290378,"dev-research":0.0931284664,"llms":0.5287443353,"data-quality":0.0861401867}}
{"text":"The performance of the proposed method was compared with five state-of-the-art fingervein verification systems, indicating the efficacy of the proposed VeinAtnNet.","meta":{"url":"http://arxiv.org/abs/2310.16808v1"},"cats":{"benchmark":0.5287539821,"new-dataset":0.0163253619,"data-annotation":0.5064399291,"dev-research":0.1433318732,"llms":0.5279901118,"data-quality":0.1343353719}}
{"text":"The Hylland-Zeckhauser gave a classic pricing-based mechanism (HZ) for a one-sided matching market; it yields allocations satisfying Pareto optimality and envy-freeness (Hylland and Zeckhauser, 1979), and the mechanism is incentive compatible in the large (He et al., 2018).","meta":{"url":"http://arxiv.org/abs/2310.16807v1"},"cats":{"benchmark":0.3851394604,"new-dataset":0.0236870159,"data-annotation":0.4922018364,"dev-research":0.0999331632,"llms":0.4938393122,"data-quality":0.0546639733}}
{"text":"They also studied the exchange extension of HZ and gave an example showing that it may not even admit an equilibrium.","meta":{"url":"http://arxiv.org/abs/2310.16807v1"},"cats":{"benchmark":0.3057077782,"new-dataset":0.0102249453,"data-annotation":0.5018442244,"dev-research":0.0765780566,"llms":0.518209711,"data-quality":0.0795229212}}
{"text":"In this paper, we consider two models of two sided matching markets: when utility functions are symmetric and when they are non-symmetric.","meta":{"url":"http://arxiv.org/abs/2310.16807v1"},"cats":{"benchmark":0.4418853631,"new-dataset":0.0154992636,"data-annotation":0.5065372609,"dev-research":0.1138524808,"llms":0.4253902011,"data-quality":0.0985774825}}
{"text":"We ask if these models always admit allocations satisfying the two basic properties of Pareto efficiency and envy freeness.","meta":{"url":"http://arxiv.org/abs/2310.16807v1"},"cats":{"benchmark":0.378508258,"new-dataset":0.0108848743,"data-annotation":0.543802275,"dev-research":0.1040081286,"llms":0.4684430614,"data-quality":0.0809531907}}
{"text":"Our results are negative.","meta":{"url":"http://arxiv.org/abs/2310.16807v1"},"cats":{"benchmark":0.5057642113,"new-dataset":0.0364186817,"data-annotation":0.53698242,"dev-research":0.2200630332,"llms":0.513073706,"data-quality":0.2408843154}}
{"text":"A corollary of the former result is a negative result for non-bipartite matching markets as well.","meta":{"url":"http://arxiv.org/abs/2310.16807v1"},"cats":{"benchmark":0.5007209107,"new-dataset":0.0150308144,"data-annotation":0.5245139905,"dev-research":0.1134027603,"llms":0.4510799568,"data-quality":0.1620077477}}
{"text":"Highly-interconnected societies difficult to model the spread of infectious diseases such as COVID-19.","meta":{"url":"http://arxiv.org/abs/2310.16804v1"},"cats":{"benchmark":0.2929885423,"new-dataset":0.0823213978,"data-annotation":0.5028495109,"dev-research":0.1744550171,"llms":0.4955335041,"data-quality":0.0703571293}}
{"text":"Single-region SIR models fail to account for incoming forces of infection and expanding them to a large number of interacting regions involves many assumptions that do not hold in the real world.","meta":{"url":"http://arxiv.org/abs/2310.16804v1"},"cats":{"benchmark":0.2703383018,"new-dataset":0.0277223642,"data-annotation":0.5172719464,"dev-research":0.1312108322,"llms":0.4855667566,"data-quality":0.0925744511}}
{"text":"We propose using Universal Differential Equations (UDEs) to capture the influence of neighboring regions and improve the model's predictions in a combined SIR+UDE model.","meta":{"url":"http://arxiv.org/abs/2310.16804v1"},"cats":{"benchmark":0.3624010094,"new-dataset":0.0855196927,"data-annotation":0.5072985186,"dev-research":0.1048377866,"llms":0.4096550489,"data-quality":0.0576341636}}
{"text":"UDEs are differential equations totally or partially defined by a deep neural network (DNN).","meta":{"url":"http://arxiv.org/abs/2310.16804v1"},"cats":{"benchmark":0.2577722548,"new-dataset":0.1902769506,"data-annotation":0.4858894707,"dev-research":0.2384549109,"llms":0.5053823431,"data-quality":0.1102997218}}
{"text":"We include an additive term to the SIR equations composed by a DNN that learns the incoming force of infection from the other regions.","meta":{"url":"http://arxiv.org/abs/2310.16804v1"},"cats":{"benchmark":0.2647187954,"new-dataset":0.244497381,"data-annotation":0.5443789622,"dev-research":0.1392138479,"llms":0.4730722779,"data-quality":0.0734311787}}
{"text":"The learning is performed using automatic differentiation and gradient descent to approach the change in the target system caused by the state of the neighboring regions.","meta":{"url":"http://arxiv.org/abs/2310.16804v1"},"cats":{"benchmark":0.3872529679,"new-dataset":0.0305082453,"data-annotation":0.5216181923,"dev-research":0.1796512081,"llms":0.4041888646,"data-quality":0.1527611056}}
{"text":"We compared the proposed model using a simulated COVID-19 outbreak against a single-region SIR and a fully data-driven model composed only of a DNN.","meta":{"url":"http://arxiv.org/abs/2310.16804v1"},"cats":{"benchmark":0.3070417692,"new-dataset":0.3815164763,"data-annotation":0.4897412981,"dev-research":0.1380728656,"llms":0.4767558587,"data-quality":0.0725657426}}
{"text":"The proposed UDE+SIR model generates predictions that capture the outbreak dynamic more accurately, but a decay in performance is observed at the last stages of the outbreak.","meta":{"url":"http://arxiv.org/abs/2310.16804v1"},"cats":{"benchmark":0.4566047247,"new-dataset":0.1267748964,"data-annotation":0.5098620676,"dev-research":0.1305660077,"llms":0.4374990426,"data-quality":0.0766293277}}
{"text":"The single-area SIR and the fully data-driven approach do not capture the proper dynamics accurately.","meta":{"url":"http://arxiv.org/abs/2310.16804v1"},"cats":{"benchmark":0.3482254431,"new-dataset":0.0153167453,"data-annotation":0.4754528208,"dev-research":0.1122621753,"llms":0.471493411,"data-quality":0.0986266373}}
{"text":"Once the predictions were obtained, we employed the SINDy algorithm to substitute the DNN with a regression, removing the black box element of the model with no considerable increase in the error levels.","meta":{"url":"http://arxiv.org/abs/2310.16804v1"},"cats":{"benchmark":0.4028965069,"new-dataset":0.0499658484,"data-annotation":0.5313421403,"dev-research":0.1959829208,"llms":0.3782763497,"data-quality":0.2294971359}}
{"text":"Recently, code language models have achieved notable advancements in addressing a diverse array of essential code comprehension and generation tasks.","meta":{"url":"http://arxiv.org/abs/2310.16803v1"},"cats":{"benchmark":0.1733861885,"new-dataset":0.1373703707,"data-annotation":0.5323729333,"dev-research":0.4889236144,"llms":0.5867355671,"data-quality":0.1751449063}}
{"text":"Yet, the field lacks a comprehensive deep dive and understanding of the code embeddings of multilingual code models.","meta":{"url":"http://arxiv.org/abs/2310.16803v1"},"cats":{"benchmark":0.2294604158,"new-dataset":0.1789780443,"data-annotation":0.5423935511,"dev-research":0.3120660426,"llms":0.5450732484,"data-quality":0.2501772511}}
{"text":"In this paper, we present a comprehensive study on multilingual code embeddings, focusing on the cross-lingual capabilities of these embeddings across different programming languages.","meta":{"url":"http://arxiv.org/abs/2310.16803v1"},"cats":{"benchmark":0.3157684117,"new-dataset":0.1402775573,"data-annotation":0.5427554841,"dev-research":0.37367168,"llms":0.5663900451,"data-quality":0.195298644}}
{"text":"Through probing experiments, we demonstrate that code embeddings comprise two distinct components: one deeply tied to the nuances and syntax of a specific language, and the other remaining agnostic to these details, primarily focusing on semantics.","meta":{"url":"http://arxiv.org/abs/2310.16803v1"},"cats":{"benchmark":0.251824757,"new-dataset":0.0234896388,"data-annotation":0.5442037389,"dev-research":0.4179859094,"llms":0.5878673892,"data-quality":0.2817057115}}
{"text":"Further, we show that when we isolate and eliminate this language-specific component, we witness significant improvements in downstream code retrieval tasks, leading to an absolute increase of up to +17 in the Mean Reciprocal Rank (MRR).","meta":{"url":"http://arxiv.org/abs/2310.16803v1"},"cats":{"benchmark":0.4850091623,"new-dataset":0.0542261881,"data-annotation":0.5525567222,"dev-research":0.2482136388,"llms":0.5384780515,"data-quality":0.2655219941}}
{"text":"Foundation models have been transformational in machine learning fields such as natural language processing and computer vision.","meta":{"url":"http://arxiv.org/abs/2310.16802v1"},"cats":{"benchmark":0.2048780356,"new-dataset":0.0854632482,"data-annotation":0.5265900104,"dev-research":0.1849569081,"llms":0.4353467298,"data-quality":0.1458887499}}
{"text":"Similar success in atomic property prediction has been limited due to the challenges of training effective models across multiple chemical domains.","meta":{"url":"http://arxiv.org/abs/2310.16802v1"},"cats":{"benchmark":0.4726717369,"new-dataset":0.0167784744,"data-annotation":0.5358215106,"dev-research":0.1214280994,"llms":0.44305515,"data-quality":0.2188175746}}
{"text":"To address this, we introduce Joint Multi-domain Pre-training (JMP), a supervised pre-training strategy that simultaneously trains on multiple datasets from different chemical domains, treating each dataset as a unique pre-training task within a multi-task framework.","meta":{"url":"http://arxiv.org/abs/2310.16802v1"},"cats":{"benchmark":0.3028018654,"new-dataset":0.3529472979,"data-annotation":0.5063664801,"dev-research":0.1463711764,"llms":0.4755122211,"data-quality":0.1905044856}}
{"text":"Our combined training dataset consists of $\\sim$120M systems from OC20, OC22, ANI-1x, and Transition-1x.","meta":{"url":"http://arxiv.org/abs/2310.16802v1"},"cats":{"benchmark":0.3359684896,"new-dataset":0.7244458816,"data-annotation":0.5044885655,"dev-research":0.0814099301,"llms":0.5248723389,"data-quality":0.107409553}}
{"text":"We evaluate performance and generalization by fine-tuning over a diverse set of downstream tasks and datasets including: QM9, rMD17, MatBench, QMOF, SPICE, and MD22.","meta":{"url":"http://arxiv.org/abs/2310.16802v1"},"cats":{"benchmark":0.5645583063,"new-dataset":0.1034859254,"data-annotation":0.4984462801,"dev-research":0.1550746903,"llms":0.489277977,"data-quality":0.1168689405}}
{"text":"JMP demonstrates an average improvement of 59% over training from scratch, and matches or sets state-of-the-art on 34 out of 40 tasks.","meta":{"url":"http://arxiv.org/abs/2310.16802v1"},"cats":{"benchmark":0.5318575489,"new-dataset":0.1196595916,"data-annotation":0.5353085276,"dev-research":0.2291075565,"llms":0.5580774552,"data-quality":0.1301168805}}
{"text":"Our work highlights the potential of pre-training strategies that utilize diverse data to advance property prediction across chemical domains, especially for low-data tasks.","meta":{"url":"http://arxiv.org/abs/2310.16802v1"},"cats":{"benchmark":0.3670229428,"new-dataset":0.1105701539,"data-annotation":0.5184506154,"dev-research":0.1515764907,"llms":0.4395039475,"data-quality":0.1509022994}}
{"text":"A saddlepoint of an $n \\times n$ matrix $A$ is an entry of $A$ that is a maximum in its row and a minimum in its column.","meta":{"url":"http://arxiv.org/abs/2310.16801v1"},"cats":{"benchmark":0.4413080166,"new-dataset":0.0520031585,"data-annotation":0.5238492533,"dev-research":0.1448331863,"llms":0.3396452085,"data-quality":0.0905416208}}
{"text":"Knuth (1968) gave several different algorithms for finding a saddlepoint.","meta":{"url":"http://arxiv.org/abs/2310.16801v1"},"cats":{"benchmark":0.5887927533,"new-dataset":0.0219622385,"data-annotation":0.5479572292,"dev-research":0.0992758543,"llms":0.3338803681,"data-quality":0.070690125}}
{"text":"The worst-case running time of these algorithms is $\\Theta(n^2)$, and Llewellyn, Tovey, and Trick (1988) showed that this cannot be improved, as in the worst case all entries of A may need to be queried.   ","meta":{"url":"http://arxiv.org/abs/2310.16801v1"},"cats":{"benchmark":0.7201213341,"new-dataset":0.0289855768,"data-annotation":0.5699973936,"dev-research":0.1340423946,"llms":0.4211632219,"data-quality":0.1328675377}}
{"text":"A strict saddlepoint of $A$ is an entry that is the strict maximum in its row and the strict minimum in its column.","meta":{"url":"http://arxiv.org/abs/2310.16801v1"},"cats":{"benchmark":0.4112521781,"new-dataset":0.0631702728,"data-annotation":0.511334728,"dev-research":0.1524108573,"llms":0.3597270264,"data-quality":0.1270979812}}
{"text":"The strict saddlepoint (if it exists) is unique, and Bienstock, Chung, Fredman, Sch\\\"affer, Shor, and Suri (1991) showed that it can be found in time $O(n \\log{n})$, where a dominant runtime contribution is sorting the diagonal of the matrix.","meta":{"url":"http://arxiv.org/abs/2310.16801v1"},"cats":{"benchmark":0.5416514072,"new-dataset":0.0340845646,"data-annotation":0.5354947323,"dev-research":0.1092078457,"llms":0.3780296587,"data-quality":0.0718483234}}
{"text":"This upper bound has not been improved since 1991.","meta":{"url":"http://arxiv.org/abs/2310.16801v1"},"cats":{"benchmark":0.5343493989,"new-dataset":0.0404581532,"data-annotation":0.5051949761,"dev-research":0.1988262129,"llms":0.4660366225,"data-quality":0.1337474069}}
{"text":"In this paper we show that the strict saddlepoint can be found in $O(n \\log^{*}{n})$ time, where $\\log^{*}$ denotes the very slowly growing iterated logarithm function, coming close to the lower bound of $\\Omega(n)$. In fact, we can also compute, within the same runtime, the value of a non-strict saddlepoint, assuming one exists.","meta":{"url":"http://arxiv.org/abs/2310.16801v1"},"cats":{"benchmark":0.5274149431,"new-dataset":0.0427130176,"data-annotation":0.5409777762,"dev-research":0.1220763419,"llms":0.4196157593,"data-quality":0.1016311318}}
{"text":"Our algorithm is based on a simple recursive approach, a feasibility test inspired by searching in sorted matrices, and a relaxed notion of saddlepoint.","meta":{"url":"http://arxiv.org/abs/2310.16801v1"},"cats":{"benchmark":0.6074293767,"new-dataset":0.0231413446,"data-annotation":0.5521752485,"dev-research":0.0937259297,"llms":0.3612137562,"data-quality":0.0784092247}}
{"text":"Pushdown Vector Addition Systems with States (PVASS) consist of finitely many control states, a pushdown stack, and a set of counters that can be incremented and decremented, but not tested for zero.","meta":{"url":"http://arxiv.org/abs/2310.16798v1"},"cats":{"benchmark":0.3166181528,"new-dataset":0.0538334823,"data-annotation":0.5149324799,"dev-research":0.1472440068,"llms":0.531682062,"data-quality":0.073870087}}
{"text":"Whether the reachability problem is decidable for PVASS is a long-standing open problem.   ","meta":{"url":"http://arxiv.org/abs/2310.16798v1"},"cats":{"benchmark":0.3310884051,"new-dataset":0.0069458622,"data-annotation":0.4946572402,"dev-research":0.1776240581,"llms":0.5546753331,"data-quality":0.1069621928}}
{"text":"We consider continuous PVASS, which are PVASS with a continuous semantics.","meta":{"url":"http://arxiv.org/abs/2310.16798v1"},"cats":{"benchmark":0.2684695454,"new-dataset":0.0160383145,"data-annotation":0.4943206401,"dev-research":0.2356829763,"llms":0.5336928243,"data-quality":0.2058755041}}
{"text":"This means, the counter values are rational numbers and whenever a vector is added to the current counter values, this vector is first scaled with an arbitrarily chosen rational factor between zero and one.","meta":{"url":"http://arxiv.org/abs/2310.16798v1"},"cats":{"benchmark":0.3552284343,"new-dataset":0.2221135059,"data-annotation":0.5095536292,"dev-research":0.2160440559,"llms":0.4370518728,"data-quality":0.0952583434}}
{"text":"We show that reachability in continuous PVASS is NEXPTIME-complete.","meta":{"url":"http://arxiv.org/abs/2310.16798v1"},"cats":{"benchmark":0.3798705251,"new-dataset":0.0411682896,"data-annotation":0.5113679801,"dev-research":0.1620971339,"llms":0.520205138,"data-quality":0.0963949694}}
{"text":"Our result is unusually robust: Reachability can be decided in NEXPTIME even if all numbers are specified in binary.","meta":{"url":"http://arxiv.org/abs/2310.16798v1"},"cats":{"benchmark":0.468367148,"new-dataset":0.069511768,"data-annotation":0.5323630902,"dev-research":0.1531132866,"llms":0.5063045167,"data-quality":0.1122130186}}
{"text":"On the other hand, NEXPTIME-hardness already holds for coverability, in fixed dimension, for bounded stack, and even if all numbers are specified in unary.","meta":{"url":"http://arxiv.org/abs/2310.16798v1"},"cats":{"benchmark":0.4522334481,"new-dataset":0.0618091821,"data-annotation":0.5310055107,"dev-research":0.2069089854,"llms":0.5200914181,"data-quality":0.1113383745}}
{"text":"Mixture-of-Experts (MoE) architectures offer a general solution to the high inference costs of large language models (LLMs) via sparse routing, bringing faster and more accurate models, at the cost of massive parameter counts.","meta":{"url":"http://arxiv.org/abs/2310.16795v1"},"cats":{"benchmark":0.3725112436,"new-dataset":0.0237388714,"data-annotation":0.5234035721,"dev-research":0.1096048378,"llms":0.6021342583,"data-quality":0.1166917577}}
{"text":"For example, the SwitchTransformer-c2048 model has 1.6 trillion parameters, requiring 3.2TB of accelerator memory to run efficiently, which makes practical deployment challenging and expensive.","meta":{"url":"http://arxiv.org/abs/2310.16795v1"},"cats":{"benchmark":0.3789102458,"new-dataset":0.0601414989,"data-annotation":0.4965407607,"dev-research":0.1598673284,"llms":0.6048214879,"data-quality":0.051020133}}
{"text":"In this paper, we present a solution to this memory problem, in form of a new compression and execution framework called","meta":{"url":"http://arxiv.org/abs/2310.16795v1"},"cats":{"benchmark":0.4298843234,"new-dataset":0.1740234969,"data-annotation":0.5224995634,"dev-research":0.1781060899,"llms":0.5256269676,"data-quality":0.1514000522}}
{"text":"QMoE. Specifically, QMoE consists of a scalable algorithm which accurately compresses trillion-parameter MoEs to less than 1 bit per parameter, in a custom format co-designed with bespoke GPU decoding kernels to facilitate efficient end-to-end compressed inference, with minor runtime overheads relative to uncompressed execution.","meta":{"url":"http://arxiv.org/abs/2310.16795v1"},"cats":{"benchmark":0.4111291338,"new-dataset":0.0249456224,"data-annotation":0.4960968719,"dev-research":0.1524702479,"llms":0.4809063588,"data-quality":0.0574298066}}
{"text":"Concretely, QMoE can compress the 1.6 trillion parameter SwitchTransformer-c2048 model to less than 160GB (20x compression, 0.8 bits per parameter) at only minor accuracy loss, in less than a day on a single GPU.","meta":{"url":"http://arxiv.org/abs/2310.16795v1"},"cats":{"benchmark":0.4780139834,"new-dataset":0.0267325923,"data-annotation":0.5062306053,"dev-research":0.1322332123,"llms":0.4873956914,"data-quality":0.0749377611}}
{"text":"This enables, for the first time, the execution of a trillion-parameter model on affordable commodity hardware, like a single server with 4x NVIDIA A6000 or 8x NVIDIA 3090 GPUs, at less than 5% runtime overhead relative to ideal uncompressed inference.","meta":{"url":"http://arxiv.org/abs/2310.16795v1"},"cats":{"benchmark":0.3960004241,"new-dataset":0.0211380589,"data-annotation":0.4982000081,"dev-research":0.1308189987,"llms":0.4896726695,"data-quality":0.0401070862}}
{"text":"The source code and compressed models are available at github.com/IST-DASLab/qmoe.","meta":{"url":"http://arxiv.org/abs/2310.16795v1"},"cats":{"benchmark":0.3680787695,"new-dataset":0.2487528599,"data-annotation":0.5128884761,"dev-research":0.1716914186,"llms":0.4922034589,"data-quality":0.1053229404}}
{"text":"This paper proposes PerfVec, a novel deep learning-based performance modeling framework that learns high-dimensional, independent/orthogonal program and microarchitecture representations.","meta":{"url":"http://arxiv.org/abs/2310.16792v1"},"cats":{"benchmark":0.3382263397,"new-dataset":0.1277718467,"data-annotation":0.5237186837,"dev-research":0.2070907093,"llms":0.5337484789,"data-quality":0.1069394129}}
{"text":"Once learned, a program representation can be used to predict its performance on any microarchitecture, and likewise, a microarchitecture representation can be applied in the performance prediction of any program.","meta":{"url":"http://arxiv.org/abs/2310.16792v1"},"cats":{"benchmark":0.4567151076,"new-dataset":0.0263339498,"data-annotation":0.5414571181,"dev-research":0.2911074941,"llms":0.5204671073,"data-quality":0.105140585}}
{"text":"Additionally, PerfVec yields a foundation model that captures the performance essence of instructions, which can be directly used by developers in numerous performance modeling related tasks without incurring its training cost.","meta":{"url":"http://arxiv.org/abs/2310.16792v1"},"cats":{"benchmark":0.395216633,"new-dataset":0.0750721603,"data-annotation":0.5353760848,"dev-research":0.3735509047,"llms":0.5443116986,"data-quality":0.0863677454}}
{"text":"The evaluation demonstrates that PerfVec is more general, efficient, and accurate than previous approaches.","meta":{"url":"http://arxiv.org/abs/2310.16792v1"},"cats":{"benchmark":0.7352030357,"new-dataset":0.0095607004,"data-annotation":0.5368505806,"dev-research":0.2115445424,"llms":0.5090913261,"data-quality":0.1544755529}}
{"text":"Covert planning refers to a class of constrained planning problems where an agent aims to accomplish a task with minimal information leaked to a passive observer to avoid detection.","meta":{"url":"http://arxiv.org/abs/2310.16791v1"},"cats":{"benchmark":0.1386772494,"new-dataset":0.0812561057,"data-annotation":0.5053734556,"dev-research":0.2638353273,"llms":0.4505759584,"data-quality":0.0880783595}}
{"text":"However, existing methods of covert planning often consider deterministic environments or do not exploit the observer's imperfect information.","meta":{"url":"http://arxiv.org/abs/2310.16791v1"},"cats":{"benchmark":0.2133601305,"new-dataset":0.0120225853,"data-annotation":0.5155557619,"dev-research":0.2874097562,"llms":0.4865354888,"data-quality":0.1041881087}}
{"text":"This paper studies how covert planning can leverage the coupling of stochastic dynamics and the observer's imperfect observation to achieve optimal task performance without being detected.","meta":{"url":"http://arxiv.org/abs/2310.16791v1"},"cats":{"benchmark":0.2227411951,"new-dataset":0.0117976453,"data-annotation":0.5088383845,"dev-research":0.2590992282,"llms":0.4298675501,"data-quality":0.0712531429}}
{"text":"Specifically, we employ a Markov decision process to model the interaction between the agent and its stochastic environment, and a partial observation function to capture the leaked information to a passive observer.","meta":{"url":"http://arxiv.org/abs/2310.16791v1"},"cats":{"benchmark":0.2421072048,"new-dataset":0.1144989747,"data-annotation":0.5149479516,"dev-research":0.2308875998,"llms":0.4528058082,"data-quality":0.1123207054}}
{"text":"Assuming the observer employs hypothesis testing to detect if the observation deviates from a nominal policy, the covert planning agent aims to maximize the total discounted reward while keeping the probability of being detected as an adversary below a given threshold.","meta":{"url":"http://arxiv.org/abs/2310.16791v1"},"cats":{"benchmark":0.240969254,"new-dataset":0.0180793807,"data-annotation":0.5235001798,"dev-research":0.1872947191,"llms":0.4450364499,"data-quality":0.0855786752}}
{"text":"We prove that finite-memory policies are more powerful than Markovian policies in covert planning.","meta":{"url":"http://arxiv.org/abs/2310.16791v1"},"cats":{"benchmark":0.1706451584,"new-dataset":0.0490958067,"data-annotation":0.5024912483,"dev-research":0.1573244267,"llms":0.5596293171,"data-quality":0.0530097569}}
{"text":"Then, we develop a primal-dual proximal policy gradient method with a two-time-scale update to compute a (locally) optimal covert policy.","meta":{"url":"http://arxiv.org/abs/2310.16791v1"},"cats":{"benchmark":0.4555637022,"new-dataset":0.0247472488,"data-annotation":0.5244293038,"dev-research":0.1210517556,"llms":0.3910464032,"data-quality":0.0891377607}}
{"text":"We demonstrate the effectiveness of our methods using a stochastic gridworld example.","meta":{"url":"http://arxiv.org/abs/2310.16791v1"},"cats":{"benchmark":0.5200750064,"new-dataset":0.0273853716,"data-annotation":0.529726751,"dev-research":0.1464376917,"llms":0.427623239,"data-quality":0.1142319496}}
{"text":"Our experimental results illustrate that the proposed method computes a policy that maximizes the adversary's expected reward without violating the detection constraint, and empirically demonstrates how the environmental noises can influence the performance of the covert policies.","meta":{"url":"http://arxiv.org/abs/2310.16791v1"},"cats":{"benchmark":0.3173975643,"new-dataset":0.0173096927,"data-annotation":0.5361301623,"dev-research":0.1657962501,"llms":0.453294235,"data-quality":0.1773388686}}
{"text":"To achieve state-of-the-art performance, one still needs to train NER models on large-scale, high-quality annotated data, an asset that is both costly and time-intensive to accumulate.","meta":{"url":"http://arxiv.org/abs/2310.16790v1"},"cats":{"benchmark":0.38555747,"new-dataset":0.2183972465,"data-annotation":0.5208915355,"dev-research":0.2364778732,"llms":0.5080227859,"data-quality":0.2060589371}}
{"text":"In contrast, real-world applications often resort to massive low-quality labeled data through non-expert annotators via crowdsourcing and external knowledge bases via distant supervision as a cost-effective alternative.","meta":{"url":"http://arxiv.org/abs/2310.16790v1"},"cats":{"benchmark":0.302464235,"new-dataset":0.35868811,"data-annotation":0.5225335009,"dev-research":0.3120428679,"llms":0.5732563263,"data-quality":0.5088769936}}
{"text":"However, these annotation methods result in noisy labels, which in turn lead to a notable decline in performance.","meta":{"url":"http://arxiv.org/abs/2310.16790v1"},"cats":{"benchmark":0.5382918551,"new-dataset":0.0266450366,"data-annotation":0.5635391949,"dev-research":0.3233565681,"llms":0.52314433,"data-quality":0.8232976066}}
{"text":"Hence, we propose to denoise the noisy NER data with guidance from a small set of clean instances.","meta":{"url":"http://arxiv.org/abs/2310.16790v1"},"cats":{"benchmark":0.4974388503,"new-dataset":0.205110115,"data-annotation":0.5054773965,"dev-research":0.2081315436,"llms":0.4477540994,"data-quality":0.365508477}}
{"text":"Along with the main NER model we train a discriminator model and use its outputs to recalibrate the sample weights.","meta":{"url":"http://arxiv.org/abs/2310.16790v1"},"cats":{"benchmark":0.4404959579,"new-dataset":0.037518045,"data-annotation":0.5238727445,"dev-research":0.1150159303,"llms":0.429054641,"data-quality":0.193617302}}
{"text":"The discriminator is capable of detecting both span and category errors with different discriminative prompts.","meta":{"url":"http://arxiv.org/abs/2310.16790v1"},"cats":{"benchmark":0.3716078616,"new-dataset":0.0519669651,"data-annotation":0.5452077,"dev-research":0.2247326977,"llms":0.4879917728,"data-quality":0.6230554101}}
{"text":"Results on public crowdsourcing and distant supervision datasets show that the proposed method can consistently improve performance with a small guidance set.","meta":{"url":"http://arxiv.org/abs/2310.16790v1"},"cats":{"benchmark":0.3678702504,"new-dataset":0.4355684037,"data-annotation":0.5280751902,"dev-research":0.2316259911,"llms":0.5230139373,"data-quality":0.2605673027}}
{"text":"Although large language models (LLMs) are widely deployed, the data used to train them is rarely disclosed.","meta":{"url":"http://arxiv.org/abs/2310.16789v1"},"cats":{"benchmark":0.1641549961,"new-dataset":0.0799655114,"data-annotation":0.5168625057,"dev-research":0.1265046307,"llms":0.732155594,"data-quality":0.1996582668}}
{"text":"Given the incredible scale of this data, up to trillions of tokens, it is all but certain that it includes potentially problematic text such as copyrighted materials, personally identifiable information, and test data for widely reported reference benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.16789v1"},"cats":{"benchmark":0.3785137614,"new-dataset":0.4188960733,"data-annotation":0.5069604074,"dev-research":0.1769182663,"llms":0.567018365,"data-quality":0.3230694673}}
{"text":"However, we currently have no way to know which data of these types is included or in what proportions.","meta":{"url":"http://arxiv.org/abs/2310.16789v1"},"cats":{"benchmark":0.2711042031,"new-dataset":0.2019551868,"data-annotation":0.4982773544,"dev-research":0.1010230144,"llms":0.4851961829,"data-quality":0.0875645224}}
{"text":"In this paper, we study the pretraining data detection problem: given a piece of text and black-box access to an LLM without knowing the pretraining data, can we determine if the model was trained on the provided text?","meta":{"url":"http://arxiv.org/abs/2310.16789v1"},"cats":{"benchmark":0.2105045324,"new-dataset":0.0675946767,"data-annotation":0.5286456631,"dev-research":0.1256159138,"llms":0.6083365721,"data-quality":0.2933755265}}
{"text":"To facilitate this study, we introduce a dynamic benchmark WIKIMIA that uses data created before and after model training to support gold truth detection.","meta":{"url":"http://arxiv.org/abs/2310.16789v1"},"cats":{"benchmark":0.4444344152,"new-dataset":0.2841432108,"data-annotation":0.5283432144,"dev-research":0.1801023536,"llms":0.4925787988,"data-quality":0.3055720815}}
{"text":"We also introduce a new detection method Min-K% Prob based on a simple hypothesis: an unseen example is likely to contain a few outlier words with low probabilities under the LLM, while a seen example is less likely to have words with such low probabilities.","meta":{"url":"http://arxiv.org/abs/2310.16789v1"},"cats":{"benchmark":0.5244631904,"new-dataset":0.0617207047,"data-annotation":0.5699941172,"dev-research":0.127890128,"llms":0.5484253555,"data-quality":0.5328290981}}
{"text":"Min-K% Prob can be applied without any knowledge about the pretraining corpus or any additional training, departing from previous detection methods that require training a reference model on data that is similar to the pretraining data.","meta":{"url":"http://arxiv.org/abs/2310.16789v1"},"cats":{"benchmark":0.3883985451,"new-dataset":0.0462322042,"data-annotation":0.5365428556,"dev-research":0.1256652319,"llms":0.5052667751,"data-quality":0.264111873}}
{"text":"Moreover, our experiments demonstrate that Min-K% Prob achieves a 7.4% improvement on WIKIMIA over these previous methods.","meta":{"url":"http://arxiv.org/abs/2310.16789v1"},"cats":{"benchmark":0.5606207516,"new-dataset":0.0829112571,"data-annotation":0.5404381544,"dev-research":0.1959754176,"llms":0.4978251911,"data-quality":0.2457497576}}
{"text":"We apply Min-K% Prob to two real-world scenarios, copyrighted book detection, and contaminated downstream example detection, and find it a consistently effective solution.","meta":{"url":"http://arxiv.org/abs/2310.16789v1"},"cats":{"benchmark":0.4590148172,"new-dataset":0.2102979753,"data-annotation":0.5374688909,"dev-research":0.1277467537,"llms":0.4855427438,"data-quality":0.4376606619}}
{"text":"The potential for deploying autonomous systems can be significantly increased by improving the perception and interpretation of the environment.","meta":{"url":"http://arxiv.org/abs/2310.16788v1"},"cats":{"benchmark":0.1788364077,"new-dataset":0.0333754211,"data-annotation":0.506025133,"dev-research":0.3218379449,"llms":0.4986662696,"data-quality":0.0858954285}}
{"text":"However, the development of deep learning-based techniques for autonomous systems in unstructured outdoor environments poses challenges due to limited data availability for training and testing.","meta":{"url":"http://arxiv.org/abs/2310.16788v1"},"cats":{"benchmark":0.2156373105,"new-dataset":0.1765775653,"data-annotation":0.4845573052,"dev-research":0.1557222568,"llms":0.4557968948,"data-quality":0.0981571123}}
{"text":"To address this gap, we present the German Outdoor and Offroad Dataset (GOOSE), a comprehensive dataset specifically designed for unstructured outdoor environments.","meta":{"url":"http://arxiv.org/abs/2310.16788v1"},"cats":{"benchmark":0.2774816269,"new-dataset":0.962906028,"data-annotation":0.4877794943,"dev-research":0.1610051283,"llms":0.4325620567,"data-quality":0.0796826088}}
{"text":"The GOOSE dataset incorporates 10 000 labeled pairs of images and point clouds, which are utilized to train a range of state-of-the-art segmentation models on both image and point cloud data.","meta":{"url":"http://arxiv.org/abs/2310.16788v1"},"cats":{"benchmark":0.2528951306,"new-dataset":0.6896057632,"data-annotation":0.5096563885,"dev-research":0.1195152926,"llms":0.4406188975,"data-quality":0.1393494375}}
{"text":"We open source the dataset, along with an ontology for unstructured terrain, as well as dataset standards and guidelines.","meta":{"url":"http://arxiv.org/abs/2310.16788v1"},"cats":{"benchmark":0.1907017006,"new-dataset":0.910709312,"data-annotation":0.4701095341,"dev-research":0.2007732898,"llms":0.5689376133,"data-quality":0.0834357371}}
{"text":"This initiative aims to establish a common framework, enabling the seamless inclusion of existing datasets and a fast way to enhance the perception capabilities of various robots operating in unstructured environments.","meta":{"url":"http://arxiv.org/abs/2310.16788v1"},"cats":{"benchmark":0.1646755124,"new-dataset":0.5725654314,"data-annotation":0.4689085164,"dev-research":0.1536460955,"llms":0.4805876029,"data-quality":0.0703414854}}
{"text":"The dataset, pre-trained models for offroad perception, and additional documentation can be found at https://goose-dataset.de/.","meta":{"url":"http://arxiv.org/abs/2310.16788v1"},"cats":{"benchmark":0.2019972643,"new-dataset":0.7655343194,"data-annotation":0.5291247583,"dev-research":0.1290308067,"llms":0.4366504672,"data-quality":0.0769767526}}
{"text":"The race to train language models on vast, diverse, and inconsistently documented datasets has raised pressing concerns about the legal and ethical risks for practitioners.","meta":{"url":"http://arxiv.org/abs/2310.16787v1"},"cats":{"benchmark":0.1623857374,"new-dataset":0.3578567599,"data-annotation":0.5035329724,"dev-research":0.2918578659,"llms":0.6104161043,"data-quality":0.3583657293}}
{"text":"To remedy these practices threatening data transparency and understanding, we convene a multi-disciplinary effort between legal and machine learning experts to systematically audit and trace 1800+ text datasets.","meta":{"url":"http://arxiv.org/abs/2310.16787v1"},"cats":{"benchmark":0.2538807528,"new-dataset":0.5044143046,"data-annotation":0.4843440165,"dev-research":0.2830141594,"llms":0.5443187805,"data-quality":0.3211016168}}
{"text":"We develop tools and standards to trace the lineage of these datasets, from their source, creators, series of license conditions, properties, and subsequent use.","meta":{"url":"http://arxiv.org/abs/2310.16787v1"},"cats":{"benchmark":0.2953178772,"new-dataset":0.9498495919,"data-annotation":0.4735612659,"dev-research":0.2319755765,"llms":0.5573959405,"data-quality":0.2329546365}}
{"text":"Our landscape analysis highlights the sharp divides in composition and focus of commercially open vs closed datasets, with closed datasets monopolizing important categories: lower resource languages, more creative tasks, richer topic variety, newer and more synthetic training data.","meta":{"url":"http://arxiv.org/abs/2310.16787v1"},"cats":{"benchmark":0.2859105575,"new-dataset":0.4600925028,"data-annotation":0.5248541171,"dev-research":0.1634186649,"llms":0.5048821349,"data-quality":0.2493019784}}
{"text":"This points to a deepening divide in the types of data that are made available under different license conditions, and heightened implications for jurisdictional legal interpretations of copyright and fair use.","meta":{"url":"http://arxiv.org/abs/2310.16787v1"},"cats":{"benchmark":0.2479195463,"new-dataset":0.1202039041,"data-annotation":0.4755758668,"dev-research":0.1617181413,"llms":0.5496038172,"data-quality":0.1999341463}}
{"text":"We also observe frequent miscategorization of licenses on widely used dataset hosting sites, with license omission of 72%+ and error rates of 50%+.","meta":{"url":"http://arxiv.org/abs/2310.16787v1"},"cats":{"benchmark":0.3024515698,"new-dataset":0.2729988655,"data-annotation":0.4821372489,"dev-research":0.2405615173,"llms":0.5391511552,"data-quality":0.521802913}}
{"text":"This points to a crisis in misattribution and informed use of the most popular datasets driving many recent breakthroughs.","meta":{"url":"http://arxiv.org/abs/2310.16787v1"},"cats":{"benchmark":0.2496593276,"new-dataset":0.3887789532,"data-annotation":0.4847099504,"dev-research":0.2139614345,"llms":0.4676358645,"data-quality":0.356717653}}
{"text":"As a contribution to ongoing improvements in dataset transparency and responsible use, we release our entire audit, with an interactive UI, the Data Provenance Explorer, which allows practitioners to trace and filter on data provenance for the most popular open source finetuning data collections: www.dataprovenance.org.","meta":{"url":"http://arxiv.org/abs/2310.16787v1"},"cats":{"benchmark":0.3165508934,"new-dataset":0.8829469325,"data-annotation":0.4648246143,"dev-research":0.2840475163,"llms":0.5819146828,"data-quality":0.2171109653}}
{"text":"Deep-learning models have been successful in biomedical image segmentation.","meta":{"url":"http://arxiv.org/abs/2310.16783v1"},"cats":{"benchmark":0.2854610713,"new-dataset":0.1361479509,"data-annotation":0.4958170298,"dev-research":0.1392071161,"llms":0.4423165285,"data-quality":0.1349488033}}
{"text":"To generalize for real-world deployment, test-time augmentation (TTA) methods are often used to transform the test image into different versions that are hopefully closer to the training domain.","meta":{"url":"http://arxiv.org/abs/2310.16783v1"},"cats":{"benchmark":0.4372780445,"new-dataset":0.0206090007,"data-annotation":0.4963433539,"dev-research":0.251021378,"llms":0.5172887821,"data-quality":0.1267022362}}
{"text":"Unfortunately, due to the vast diversity of instance scale and image styles, many augmented test images produce undesirable results, thus lowering the overall performance.","meta":{"url":"http://arxiv.org/abs/2310.16783v1"},"cats":{"benchmark":0.5636696214,"new-dataset":0.0180062161,"data-annotation":0.5248567466,"dev-research":0.1531957651,"llms":0.5167496019,"data-quality":0.1306957026}}
{"text":"This work proposes a new TTA framework, S$^3$-TTA, which selects the suitable image scale and style for each test image based on a transformation consistency metric.","meta":{"url":"http://arxiv.org/abs/2310.16783v1"},"cats":{"benchmark":0.495783195,"new-dataset":0.0515652124,"data-annotation":0.4788928599,"dev-research":0.1160099706,"llms":0.4874591862,"data-quality":0.1142006577}}
{"text":"In addition, S$^3$-TTA constructs an end-to-end augmentation-segmentation joint-training pipeline to ensure a task-oriented augmentation.","meta":{"url":"http://arxiv.org/abs/2310.16783v1"},"cats":{"benchmark":0.2820470765,"new-dataset":0.04442142,"data-annotation":0.4976253974,"dev-research":0.1643159399,"llms":0.5776310933,"data-quality":0.1285562544}}
{"text":"On public benchmarks for cell and lung segmentation, S$^3$-TTA demonstrates improvements over the prior art by 3.4% and 1.3%, respectively, by simply augmenting the input data in testing phase.","meta":{"url":"http://arxiv.org/abs/2310.16783v1"},"cats":{"benchmark":0.6127364393,"new-dataset":0.0253150013,"data-annotation":0.5048976349,"dev-research":0.1233618411,"llms":0.4971211868,"data-quality":0.0838275041}}
{"text":"Although the mapping between sound and meaning in human language is assumed to be largely arbitrary, research in cognitive science has shown that there are non-trivial correlations between particular sounds and meanings across languages and demographic groups, a phenomenon known as sound symbolism.","meta":{"url":"http://arxiv.org/abs/2310.16781v1"},"cats":{"benchmark":0.1681035502,"new-dataset":0.0415625981,"data-annotation":0.5422029264,"dev-research":0.3217964427,"llms":0.5238412076,"data-quality":0.2084644862}}
{"text":"Among the many dimensions of meaning, sound symbolism is particularly salient and well-demonstrated with regards to cross-modal associations between language and the visual domain.","meta":{"url":"http://arxiv.org/abs/2310.16781v1"},"cats":{"benchmark":0.1914926452,"new-dataset":0.0587095217,"data-annotation":0.5353274543,"dev-research":0.2571582556,"llms":0.5683666278,"data-quality":0.145082545}}
{"text":"In this work, we address the question of whether sound symbolism is reflected in vision-and-language models such as CLIP and Stable Diffusion.","meta":{"url":"http://arxiv.org/abs/2310.16781v1"},"cats":{"benchmark":0.1976931877,"new-dataset":0.0341379572,"data-annotation":0.5371905,"dev-research":0.1619589866,"llms":0.4837095424,"data-quality":0.2181880754}}
{"text":"Using zero-shot knowledge probing to investigate the inherent knowledge of these models, we find strong evidence that they do show this pattern, paralleling the well-known kiki-bouba effect in psycholinguistics.","meta":{"url":"http://arxiv.org/abs/2310.16781v1"},"cats":{"benchmark":0.2389292339,"new-dataset":0.0589817478,"data-annotation":0.5383973134,"dev-research":0.1410436484,"llms":0.5054731207,"data-quality":0.2021753769}}
{"text":"Our work provides a novel method for demonstrating sound symbolism and understanding its nature using computational tools.","meta":{"url":"http://arxiv.org/abs/2310.16781v1"},"cats":{"benchmark":0.2391267562,"new-dataset":0.1768922034,"data-annotation":0.5576188785,"dev-research":0.2586821499,"llms":0.5132540077,"data-quality":0.1713878288}}
{"text":"Our code will be made publicly available.","meta":{"url":"http://arxiv.org/abs/2310.16781v1"},"cats":{"benchmark":0.181418159,"new-dataset":0.4477988285,"data-annotation":0.5214691519,"dev-research":0.2943970676,"llms":0.5720495616,"data-quality":0.1195708787}}
{"text":"Along with recent diffusion models, randomized smoothing has become one of a few tangible approaches that offers adversarial robustness to models at scale, e.g., those of large pre-trained models.","meta":{"url":"http://arxiv.org/abs/2310.16779v1"},"cats":{"benchmark":0.356454156,"new-dataset":0.0245843879,"data-annotation":0.5076276195,"dev-research":0.1525253285,"llms":0.4309333719,"data-quality":0.1690944779}}
{"text":"Specifically, one can perform randomized smoothing on any classifier via a simple \"denoise-and-classify\" pipeline, so-called denoised smoothing, given that an accurate denoiser is available - such as diffusion model.","meta":{"url":"http://arxiv.org/abs/2310.16779v1"},"cats":{"benchmark":0.4539554122,"new-dataset":0.0150658366,"data-annotation":0.4844574769,"dev-research":0.1617160236,"llms":0.4696937441,"data-quality":0.2057677021}}
{"text":"In this paper, we investigate the trade-off between accuracy and certified robustness of denoised smoothing: for example, we question on which representation of diffusion model would maximize the certified robustness of denoised smoothing.","meta":{"url":"http://arxiv.org/abs/2310.16779v1"},"cats":{"benchmark":0.6541274742,"new-dataset":0.0357075632,"data-annotation":0.4914634725,"dev-research":0.2190501816,"llms":0.3702280466,"data-quality":0.2704276668}}
{"text":"We consider a new objective that aims collective robustness of smoothed classifiers across multiple noise levels at a shared diffusion model, which also suggests a new way to compensate the cost of accuracy in randomized smoothing for its certified robustness.","meta":{"url":"http://arxiv.org/abs/2310.16779v1"},"cats":{"benchmark":0.5848326095,"new-dataset":0.0348608756,"data-annotation":0.5097786673,"dev-research":0.179416529,"llms":0.3690087913,"data-quality":0.4042844252}}
{"text":"This objective motivates us to fine-tune diffusion model (a) to perform consistent denoising whenever the original image is recoverable, but (b) to generate rather diverse outputs otherwise.","meta":{"url":"http://arxiv.org/abs/2310.16779v1"},"cats":{"benchmark":0.4333302152,"new-dataset":0.0193936658,"data-annotation":0.4800370883,"dev-research":0.1701931422,"llms":0.404341165,"data-quality":0.1434147018}}
{"text":"Our experiments show that this fine-tuning scheme of diffusion models combined with the multi-scale smoothing enables a strong certified robustness possible at highest noise level while maintaining the accuracy closer to non-smoothed classifiers.","meta":{"url":"http://arxiv.org/abs/2310.16779v1"},"cats":{"benchmark":0.5952636145,"new-dataset":0.0300102649,"data-annotation":0.4940791191,"dev-research":0.1447235761,"llms":0.3820040417,"data-quality":0.251273561}}
{"text":"Recent advances have led to the availability of many pre-trained language models (PLMs); however, a question that remains is how much data is truly needed to fine-tune PLMs for downstream tasks?","meta":{"url":"http://arxiv.org/abs/2310.16776v1"},"cats":{"benchmark":0.2478632458,"new-dataset":0.1320546229,"data-annotation":0.5158321373,"dev-research":0.1520642665,"llms":0.6427951637,"data-quality":0.1468258391}}
{"text":"In this work, we introduce DEFT, a data-efficient fine-tuning framework that leverages unsupervised core-set selection to minimize the amount of data needed to fine-tune PLMs for downstream tasks.","meta":{"url":"http://arxiv.org/abs/2310.16776v1"},"cats":{"benchmark":0.4513136064,"new-dataset":0.1400901068,"data-annotation":0.4742851333,"dev-research":0.180309599,"llms":0.58290655,"data-quality":0.1566771719}}
{"text":"We demonstrate the efficacy of our DEFT framework in the context of text-editing LMs, and compare to the state-of-the art text-editing model, CoEDIT (Raheja et al., 2023).","meta":{"url":"http://arxiv.org/abs/2310.16776v1"},"cats":{"benchmark":0.3366567623,"new-dataset":0.0877604836,"data-annotation":0.5057594142,"dev-research":0.2748217665,"llms":0.5979136049,"data-quality":0.2053311503}}
{"text":"Our quantitative and qualitative results demonstrate that DEFT models are just as accurate as CoEDIT while being finetuned on ~70% less data.","meta":{"url":"http://arxiv.org/abs/2310.16776v1"},"cats":{"benchmark":0.4582801135,"new-dataset":0.0379440703,"data-annotation":0.502913439,"dev-research":0.1982950705,"llms":0.4227875287,"data-quality":0.1297847835}}
{"text":"In urban planning, land use readjustment plays a pivotal role in aligning land use configurations with the current demands for sustainable urban development.","meta":{"url":"http://arxiv.org/abs/2310.16772v1"},"cats":{"benchmark":0.3479356446,"new-dataset":0.0447167103,"data-annotation":0.4582207278,"dev-research":0.3051722573,"llms":0.4579305743,"data-quality":0.0589695418}}
{"text":"However, present-day urban planning practices face two main issues.","meta":{"url":"http://arxiv.org/abs/2310.16772v1"},"cats":{"benchmark":0.2308359667,"new-dataset":0.0437776188,"data-annotation":0.466140812,"dev-research":0.3735712929,"llms":0.5193021237,"data-quality":0.0748658391}}
{"text":"Firstly, land use decisions are predominantly dependent on human experts.","meta":{"url":"http://arxiv.org/abs/2310.16772v1"},"cats":{"benchmark":0.2860853174,"new-dataset":0.0247556625,"data-annotation":0.4971499528,"dev-research":0.2885868174,"llms":0.474830622,"data-quality":0.0598222303}}
{"text":"Besides, while resident engagement in urban planning can promote urban sustainability and livability, it is challenging to reconcile the diverse interests of stakeholders.","meta":{"url":"http://arxiv.org/abs/2310.16772v1"},"cats":{"benchmark":0.2488885164,"new-dataset":0.0462573729,"data-annotation":0.4655972934,"dev-research":0.3899003674,"llms":0.5145394009,"data-quality":0.0896327969}}
{"text":"To address these challenges, we introduce a Consensus-based Multi-Agent Reinforcement Learning framework for real-world land use readjustment.","meta":{"url":"http://arxiv.org/abs/2310.16772v1"},"cats":{"benchmark":0.3364448553,"new-dataset":0.1227079747,"data-annotation":0.4820707697,"dev-research":0.162828803,"llms":0.4077909183,"data-quality":0.1057647863}}
{"text":"This framework serves participatory urban planning, allowing diverse intelligent agents as stakeholder representatives to vote for preferred land use types.","meta":{"url":"http://arxiv.org/abs/2310.16772v1"},"cats":{"benchmark":0.2137275651,"new-dataset":0.0525882934,"data-annotation":0.4807550221,"dev-research":0.2322271254,"llms":0.4939477424,"data-quality":0.0523121785}}
{"text":"Within this framework, we propose a novel consensus mechanism in reward design to optimize land utilization through collective decision making.","meta":{"url":"http://arxiv.org/abs/2310.16772v1"},"cats":{"benchmark":0.4193653495,"new-dataset":0.0149828143,"data-annotation":0.4851506076,"dev-research":0.2043332103,"llms":0.4258176923,"data-quality":0.0879905214}}
{"text":"To abstract the structure of the complex urban system, the geographic information of cities is transformed into a spatial graph structure and then processed by graph neural networks.","meta":{"url":"http://arxiv.org/abs/2310.16772v1"},"cats":{"benchmark":0.2256799287,"new-dataset":0.1537043039,"data-annotation":0.5004063624,"dev-research":0.2248114996,"llms":0.4073734401,"data-quality":0.0988768766}}
{"text":"Comprehensive experiments on both traditional top-down planning and participatory planning methods from real-world communities indicate that our computational framework enhances global benefits and accommodates diverse interests, leading to improved satisfaction across different demographic groups.","meta":{"url":"http://arxiv.org/abs/2310.16772v1"},"cats":{"benchmark":0.2713194662,"new-dataset":0.040437885,"data-annotation":0.4916394798,"dev-research":0.3241822328,"llms":0.5316695979,"data-quality":0.0395394458}}
{"text":"By integrating Multi-Agent Reinforcement Learning, our framework ensures that participatory urban planning decisions are more dynamic and adaptive to evolving community needs and provides a robust platform for automating complex real-world urban planning processes.","meta":{"url":"http://arxiv.org/abs/2310.16772v1"},"cats":{"benchmark":0.1847616992,"new-dataset":0.1567458238,"data-annotation":0.4865281365,"dev-research":0.2270703079,"llms":0.4806828228,"data-quality":0.0476740823}}
{"text":"Many researchers believe that ConvNets perform well on small or moderately sized datasets, but are not competitive with Vision Transformers when given access to datasets on the web-scale.","meta":{"url":"http://arxiv.org/abs/2310.16764v1"},"cats":{"benchmark":0.2680822919,"new-dataset":0.0862483822,"data-annotation":0.4995662913,"dev-research":0.1760093505,"llms":0.5101538879,"data-quality":0.1022587695}}
{"text":"We challenge this belief by evaluating a performant ConvNet architecture pre-trained on JFT-4B, a large labelled dataset of images often used for training foundation models.","meta":{"url":"http://arxiv.org/abs/2310.16764v1"},"cats":{"benchmark":0.2481283814,"new-dataset":0.5560153007,"data-annotation":0.520970345,"dev-research":0.1277812122,"llms":0.5017015938,"data-quality":0.1984926957}}
{"text":"We consider pre-training compute budgets between 0.4k and 110k TPU-v4 core compute hours, and train a series of networks of increasing depth and width from the NFNet model family.","meta":{"url":"http://arxiv.org/abs/2310.16764v1"},"cats":{"benchmark":0.2878356248,"new-dataset":0.2035559757,"data-annotation":0.5266579442,"dev-research":0.1504038139,"llms":0.4888149311,"data-quality":0.0582905374}}
{"text":"We observe a log-log scaling law between held out loss and compute budget.","meta":{"url":"http://arxiv.org/abs/2310.16764v1"},"cats":{"benchmark":0.4711632886,"new-dataset":0.0538580316,"data-annotation":0.5233814058,"dev-research":0.179109006,"llms":0.4354874553,"data-quality":0.1310475711}}
{"text":"After fine-tuning on ImageNet, NFNets match the reported performance of Vision Transformers with comparable compute budgets.","meta":{"url":"http://arxiv.org/abs/2310.16764v1"},"cats":{"benchmark":0.4050754229,"new-dataset":0.0669468343,"data-annotation":0.5088439839,"dev-research":0.1589563349,"llms":0.4874294649,"data-quality":0.1262274237}}
{"text":"Our strongest fine-tuned model achieves a Top-1 accuracy of 90.4%.","meta":{"url":"http://arxiv.org/abs/2310.16764v1"},"cats":{"benchmark":0.6390285321,"new-dataset":0.0284629973,"data-annotation":0.5319666821,"dev-research":0.1089852346,"llms":0.4944445805,"data-quality":0.1713757303}}
{"text":"While large language models demonstrate remarkable capabilities, they often present challenges in terms of safety, alignment with human values, and stability during training.","meta":{"url":"http://arxiv.org/abs/2310.16763v1"},"cats":{"benchmark":0.2550784759,"new-dataset":0.1699647429,"data-annotation":0.5474949697,"dev-research":0.2381950728,"llms":0.5405335694,"data-quality":0.1911129065}}
{"text":"Here, we focus on two prevalent methods used to align these models, Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF).","meta":{"url":"http://arxiv.org/abs/2310.16763v1"},"cats":{"benchmark":0.4125131803,"new-dataset":0.066070856,"data-annotation":0.5261814866,"dev-research":0.2047087247,"llms":0.4198371986,"data-quality":0.1862402364}}
{"text":"SFT is simple and robust, powering a host of open-source models, while RLHF is a more sophisticated method used in top-tier models like ChatGPT but also suffers from instability and susceptibility to reward hacking.","meta":{"url":"http://arxiv.org/abs/2310.16763v1"},"cats":{"benchmark":0.3314989656,"new-dataset":0.0413295318,"data-annotation":0.5004921908,"dev-research":0.2532515617,"llms":0.5226035805,"data-quality":0.0671139557}}
{"text":"We propose a novel approach, Supervised Iterative Learning from Human Feedback (SuperHF), which seeks to leverage the strengths of both methods.","meta":{"url":"http://arxiv.org/abs/2310.16763v1"},"cats":{"benchmark":0.3587367568,"new-dataset":0.1253968806,"data-annotation":0.5222754304,"dev-research":0.198052017,"llms":0.4623584198,"data-quality":0.1734386942}}
{"text":"Our hypothesis is two-fold: that the reward model used in RLHF is critical for efficient data use and model generalization and that the use of Proximal Policy Optimization (PPO) in RLHF may not be necessary and could contribute to instability issues.","meta":{"url":"http://arxiv.org/abs/2310.16763v1"},"cats":{"benchmark":0.3965326375,"new-dataset":0.0169014774,"data-annotation":0.4952161037,"dev-research":0.1218169823,"llms":0.3758671056,"data-quality":0.1035561471}}
{"text":"SuperHF replaces PPO with a simple supervised loss and a Kullback-Leibler (KL) divergence prior.","meta":{"url":"http://arxiv.org/abs/2310.16763v1"},"cats":{"benchmark":0.4147141858,"new-dataset":0.0214327023,"data-annotation":0.507728683,"dev-research":0.0824133091,"llms":0.4379495707,"data-quality":0.0961466017}}
{"text":"It creates its own training data by repeatedly sampling a batch of model outputs and filtering them through the reward model in an online learning regime.","meta":{"url":"http://arxiv.org/abs/2310.16763v1"},"cats":{"benchmark":0.1578645697,"new-dataset":0.1299518056,"data-annotation":0.5023452104,"dev-research":0.1322094838,"llms":0.4755642833,"data-quality":0.0902786406}}
{"text":"We then break down the reward optimization problem into three components: robustly optimizing the training rewards themselves, preventing reward hacking-exploitation of the reward model that degrades model performance-as measured by a novel METEOR similarity metric, and maintaining good performance on downstream evaluations.","meta":{"url":"http://arxiv.org/abs/2310.16763v1"},"cats":{"benchmark":0.4456360235,"new-dataset":0.0433112683,"data-annotation":0.5409546443,"dev-research":0.1708962959,"llms":0.4346388678,"data-quality":0.1458248588}}
{"text":"Our experimental results show SuperHF exceeds PPO-based RLHF on the training objective, easily and favorably trades off high reward with low reward hacking, improves downstream calibration, and performs the same on our GPT-4 based qualitative evaluation scheme all the while being significantly simpler to implement, highlighting SuperHF's potential as a competitive language model alignment technique.","meta":{"url":"http://arxiv.org/abs/2310.16763v1"},"cats":{"benchmark":0.4108733595,"new-dataset":0.1763372948,"data-annotation":0.5345563586,"dev-research":0.171428699,"llms":0.4835428539,"data-quality":0.1359631232}}
{"text":"First-order logic, and quantifiers in particular, are widely used in deductive verification.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.3627015423,"new-dataset":0.0192049168,"data-annotation":0.5053786342,"dev-research":0.3216877636,"llms":0.5774930946,"data-quality":0.1222151734}}
{"text":"Quantifiers are essential for describing systems with unbounded domains, but prove difficult for automated solvers.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.2600147843,"new-dataset":0.0482301897,"data-annotation":0.5187460222,"dev-research":0.2900811104,"llms":0.5410461319,"data-quality":0.1550386873}}
{"text":"Significant effort has been dedicated to finding quantifier instantiations that establish unsatisfiability, thus ensuring validity of a system's verification conditions.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.398693447,"new-dataset":0.0323313818,"data-annotation":0.519210603,"dev-research":0.2988686015,"llms":0.5834741213,"data-quality":0.2369541379}}
{"text":"However, in many cases the formulas are satisfiable: this is often the case in intermediate steps of the verification process.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.4964169429,"new-dataset":0.0047558897,"data-annotation":0.5006597294,"dev-research":0.2047668324,"llms":0.4907801358,"data-quality":0.1280968457}}
{"text":"For such cases, existing tools are limited to finding finite models as counterexamples.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.3652217375,"new-dataset":0.0157379778,"data-annotation":0.5126176384,"dev-research":0.1768814609,"llms":0.4738618448,"data-quality":0.0853793052}}
{"text":"Yet, some quantified formulas are satisfiable but only have infinite models.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.3371985651,"new-dataset":0.0132794187,"data-annotation":0.5080571928,"dev-research":0.1319411737,"llms":0.4717644826,"data-quality":0.0885346193}}
{"text":"Such infinite counter-models are especially typical when first-order logic is used to approximate inductive definitions such as linked lists or the natural numbers.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.3325510191,"new-dataset":0.0420471618,"data-annotation":0.5078221427,"dev-research":0.226270992,"llms":0.5615780551,"data-quality":0.1269177342}}
{"text":"The inability of solvers to find infinite models makes them diverge in these cases.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.2314407903,"new-dataset":0.0098399839,"data-annotation":0.5186842879,"dev-research":0.1358602055,"llms":0.4766723255,"data-quality":0.0981405618}}
{"text":"In this paper, we tackle the problem of finding such infinite models.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.2811052649,"new-dataset":0.1977024621,"data-annotation":0.5388700744,"dev-research":0.0810528745,"llms":0.4167493912,"data-quality":0.0939596236}}
{"text":"These models allow the user to identify and fix bugs in the modeling of the system and its properties.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.292913011,"new-dataset":0.0383147089,"data-annotation":0.4996506329,"dev-research":0.4135243985,"llms":0.4804380517,"data-quality":0.17255025}}
{"text":"Our approach consists of three parts.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.298090829,"new-dataset":0.028180601,"data-annotation":0.5048650862,"dev-research":0.2177984725,"llms":0.4988729488,"data-quality":0.0916843102}}
{"text":"First, we introduce symbolic structures as a way to represent certain infinite models.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.2027920151,"new-dataset":0.0876300972,"data-annotation":0.521759484,"dev-research":0.1491608159,"llms":0.4935157131,"data-quality":0.084077022}}
{"text":"Second, we describe an effective model finding procedure that symbolically explores a given family of symbolic structures.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.319352656,"new-dataset":0.0855006247,"data-annotation":0.5424888018,"dev-research":0.2193462012,"llms":0.4707959217,"data-quality":0.1723938029}}
{"text":"Finally, we identify a new decidable fragment of first-order logic that extends and subsumes the many-sorted variant of EPR, where satisfiable formulas always have a model representable by a symbolic structure within a known family.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.3488626275,"new-dataset":0.0539570531,"data-annotation":0.5080865747,"dev-research":0.2055215392,"llms":0.5760050402,"data-quality":0.0796765899}}
{"text":"We evaluate our approach on examples from the domains of distributed consensus protocols and of heap-manipulating programs.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.4017818034,"new-dataset":0.1180355776,"data-annotation":0.5054017171,"dev-research":0.2403593913,"llms":0.6135123071,"data-quality":0.1520323233}}
{"text":"Our implementation quickly finds infinite counter-models that demonstrate the source of verification failures in a simple way, while SMT solvers and theorem provers such as Z3, cvc5, and Vampire diverge.","meta":{"url":"http://arxiv.org/abs/2310.16762v1"},"cats":{"benchmark":0.4811751373,"new-dataset":0.0396571015,"data-annotation":0.5298071542,"dev-research":0.2372938725,"llms":0.5687646573,"data-quality":0.2451322693}}
{"text":"Identifying intents from dialogue utterances forms an integral component of task-oriented dialogue systems.","meta":{"url":"http://arxiv.org/abs/2310.16761v1"},"cats":{"benchmark":0.2634520015,"new-dataset":0.0388068896,"data-annotation":0.5403496044,"dev-research":0.1993767941,"llms":0.5747338066,"data-quality":0.1588704847}}
{"text":"Intent-related tasks are typically formulated either as a classification task, where the utterances are classified into predefined categories or as a clustering task when new and previously unknown intent categories need to be discovered from these utterances.","meta":{"url":"http://arxiv.org/abs/2310.16761v1"},"cats":{"benchmark":0.2250978486,"new-dataset":0.0157581897,"data-annotation":0.5393644271,"dev-research":0.2222300032,"llms":0.5252606989,"data-quality":0.1308345838}}
{"text":"Further, the intent classification may be modeled in a multiclass (MC) or multilabel (ML) setup.","meta":{"url":"http://arxiv.org/abs/2310.16761v1"},"cats":{"benchmark":0.2542301609,"new-dataset":0.0165548124,"data-annotation":0.5429877254,"dev-research":0.1286558828,"llms":0.5598269658,"data-quality":0.2024014678}}
{"text":"While typically these tasks are modeled as separate tasks, we propose IntenDD, a unified approach leveraging a shared utterance encoding backbone.","meta":{"url":"http://arxiv.org/abs/2310.16761v1"},"cats":{"benchmark":0.2560541514,"new-dataset":0.0987344846,"data-annotation":0.5040106247,"dev-research":0.1735009121,"llms":0.5172388062,"data-quality":0.1401164164}}
{"text":"IntenDD uses an entirely unsupervised contrastive learning strategy for representation learning, where pseudo-labels for the unlabeled utterances are generated based on their lexical features.","meta":{"url":"http://arxiv.org/abs/2310.16761v1"},"cats":{"benchmark":0.1927458919,"new-dataset":0.1530445211,"data-annotation":0.5248123547,"dev-research":0.1530013629,"llms":0.5594342643,"data-quality":0.2375549882}}
{"text":"Additionally, we introduce a two-step post-processing setup for the classification tasks using modified adsorption.","meta":{"url":"http://arxiv.org/abs/2310.16761v1"},"cats":{"benchmark":0.4839765854,"new-dataset":0.017129765,"data-annotation":0.5039921165,"dev-research":0.1249610633,"llms":0.4306904558,"data-quality":0.1876091543}}
{"text":"Here, first, the residuals in the training data are propagated followed by smoothing the labels both modeled in a transductive setting.","meta":{"url":"http://arxiv.org/abs/2310.16761v1"},"cats":{"benchmark":0.3298778101,"new-dataset":0.2043310684,"data-annotation":0.5093131114,"dev-research":0.1505106961,"llms":0.3469386048,"data-quality":0.4485792925}}
{"text":"Through extensive evaluations on various benchmark datasets, we find that our approach consistently outperforms competitive baselines across all three tasks.","meta":{"url":"http://arxiv.org/abs/2310.16761v1"},"cats":{"benchmark":0.792650859,"new-dataset":0.1450008398,"data-annotation":0.5121337134,"dev-research":0.1694129834,"llms":0.4059215713,"data-quality":0.1512561663}}
{"text":"On average, IntenDD reports percentage improvements of 2.32%, 1.26%, and 1.52% in their respective metrics for few-shot MC, few-shot ML, and the intent discovery tasks respectively.","meta":{"url":"http://arxiv.org/abs/2310.16761v1"},"cats":{"benchmark":0.483138159,"new-dataset":0.0278337426,"data-annotation":0.5179173554,"dev-research":0.1889666492,"llms":0.5423267523,"data-quality":0.0984668593}}
{"text":"Recognizing the explosive increase in the use of DNN-based applications, several industrial companies developed a custom ASIC (e.g., Google TPU, IBM RaPiD, Intel NNP-I/NNP-T) and constructed a hyperscale cloud infrastructure with it.","meta":{"url":"http://arxiv.org/abs/2310.16757v1"},"cats":{"benchmark":0.2743619087,"new-dataset":0.1127550141,"data-annotation":0.4852403354,"dev-research":0.2098985867,"llms":0.5328406712,"data-quality":0.0825045724}}
{"text":"The ASIC performs operations of the inference or training process of DNN models which are requested by users.","meta":{"url":"http://arxiv.org/abs/2310.16757v1"},"cats":{"benchmark":0.2231806915,"new-dataset":0.069238948,"data-annotation":0.5219447754,"dev-research":0.2552566044,"llms":0.4839221267,"data-quality":0.1068853811}}
{"text":"Since the DNN models have different data formats and types of operations, the ASIC needs to support diverse data formats and generality for the operations.","meta":{"url":"http://arxiv.org/abs/2310.16757v1"},"cats":{"benchmark":0.2394030647,"new-dataset":0.0721693048,"data-annotation":0.4847827247,"dev-research":0.2143524443,"llms":0.4790629418,"data-quality":0.1014722906}}
{"text":"However, the conventional ASICs do not fulfill these requirements.","meta":{"url":"http://arxiv.org/abs/2310.16757v1"},"cats":{"benchmark":0.3010986299,"new-dataset":0.0074562417,"data-annotation":0.4840187136,"dev-research":0.1251143744,"llms":0.5403302634,"data-quality":0.1028439014}}
{"text":"To overcome the limitations of it, we propose a flexible DNN accelerator called All-rounder.","meta":{"url":"http://arxiv.org/abs/2310.16757v1"},"cats":{"benchmark":0.2725371773,"new-dataset":0.0620739167,"data-annotation":0.5054910269,"dev-research":0.1559092326,"llms":0.5609196325,"data-quality":0.0840697779}}
{"text":"The accelerator is designed with an area-efficient multiplier supporting multiple precisions of integer and floating point datatypes.","meta":{"url":"http://arxiv.org/abs/2310.16757v1"},"cats":{"benchmark":0.5360424043,"new-dataset":0.0326440068,"data-annotation":0.5038981343,"dev-research":0.1681182598,"llms":0.4928754816,"data-quality":0.0830462876}}
{"text":"In addition, it constitutes a flexibly fusible and fissionable MAC array to support various types of DNN operations efficiently.","meta":{"url":"http://arxiv.org/abs/2310.16757v1"},"cats":{"benchmark":0.2376030739,"new-dataset":0.0451367018,"data-annotation":0.498694669,"dev-research":0.2129694969,"llms":0.5929262564,"data-quality":0.081552709}}
{"text":"We implemented the register transfer level (RTL) design using Verilog and synthesized it in 28nm CMOS technology.","meta":{"url":"http://arxiv.org/abs/2310.16757v1"},"cats":{"benchmark":0.3725037652,"new-dataset":0.1253065867,"data-annotation":0.475324507,"dev-research":0.2374591578,"llms":0.6459187474,"data-quality":0.0554568382}}
{"text":"To examine practical effectiveness of our proposed designs, we designed two multiply units and three state-of-the-art DNN accelerators.","meta":{"url":"http://arxiv.org/abs/2310.16757v1"},"cats":{"benchmark":0.4183421897,"new-dataset":0.0510820631,"data-annotation":0.5010702693,"dev-research":0.1860576287,"llms":0.5857454689,"data-quality":0.0886828967}}
{"text":"We compare our multiplier with the multiply units and perform architectural evaluation on performance and energy efficiency with eight real-world DNN models.","meta":{"url":"http://arxiv.org/abs/2310.16757v1"},"cats":{"benchmark":0.4618053886,"new-dataset":0.1043731703,"data-annotation":0.5197617517,"dev-research":0.1987307164,"llms":0.4889674848,"data-quality":0.0765579372}}
{"text":"Furthermore, we compare benefits of the All-rounder accelerator to a high-end GPU card, i.e., NVIDIA GeForce RTX30390.","meta":{"url":"http://arxiv.org/abs/2310.16757v1"},"cats":{"benchmark":0.5516637979,"new-dataset":0.0104697386,"data-annotation":0.5072074601,"dev-research":0.1654969021,"llms":0.5431437269,"data-quality":0.054816271}}
{"text":"The proposed All-rounder accelerator universally has speedup and high energy efficiency in various DNN benchmarks than the baselines.","meta":{"url":"http://arxiv.org/abs/2310.16757v1"},"cats":{"benchmark":0.5045929269,"new-dataset":0.0479764675,"data-annotation":0.5087038321,"dev-research":0.1237197822,"llms":0.5683814524,"data-quality":0.0689302134}}
{"text":"Theory of Mind (ToM) is the ability to reason about one's own and others' mental states.","meta":{"url":"http://arxiv.org/abs/2310.16755v1"},"cats":{"benchmark":0.163418759,"new-dataset":0.0245867337,"data-annotation":0.5378330189,"dev-research":0.2388635808,"llms":0.5407301053,"data-quality":0.1068054464}}
{"text":"ToM plays a critical role in the development of intelligence, language understanding, and cognitive processes.","meta":{"url":"http://arxiv.org/abs/2310.16755v1"},"cats":{"benchmark":0.1716656695,"new-dataset":0.0518838121,"data-annotation":0.5311653578,"dev-research":0.2845977269,"llms":0.5374493338,"data-quality":0.1098960291}}
{"text":"While previous work has primarily focused on first and second-order ToM, we explore higher-order ToM, which involves recursive reasoning on others' beliefs.","meta":{"url":"http://arxiv.org/abs/2310.16755v1"},"cats":{"benchmark":0.2366180767,"new-dataset":0.0584268544,"data-annotation":0.5321096142,"dev-research":0.2104714285,"llms":0.5698784789,"data-quality":0.0604816465}}
{"text":"We introduce HI-TOM, a Higher Order Theory of Mind benchmark.","meta":{"url":"http://arxiv.org/abs/2310.16755v1"},"cats":{"benchmark":0.545985042,"new-dataset":0.0424537126,"data-annotation":0.5498164914,"dev-research":0.1466454221,"llms":0.4930805954,"data-quality":0.092660901}}
{"text":"Our experimental evaluation using various Large Language Models (LLMs) indicates a decline in performance on higher-order ToM tasks, demonstrating the limitations of current LLMs.","meta":{"url":"http://arxiv.org/abs/2310.16755v1"},"cats":{"benchmark":0.3724383612,"new-dataset":0.0313255297,"data-annotation":0.5382335145,"dev-research":0.1591878734,"llms":0.6477478373,"data-quality":0.1073176113}}
{"text":"We conduct a thorough analysis of different failure cases of LLMs, and share our thoughts on the implications of our findings on the future of NLP.","meta":{"url":"http://arxiv.org/abs/2310.16755v1"},"cats":{"benchmark":0.2798655066,"new-dataset":0.0630217549,"data-annotation":0.5148323692,"dev-research":0.2275765819,"llms":0.7483954344,"data-quality":0.4320086743}}
{"text":"In the context of Audio Visual Question Answering (AVQA) tasks, the audio visual modalities could be learnt on three levels: 1) Spatial, 2) Temporal, and 3) Semantic.","meta":{"url":"http://arxiv.org/abs/2310.16754v1"},"cats":{"benchmark":0.1810195347,"new-dataset":0.1179208533,"data-annotation":0.5218011585,"dev-research":0.1966956172,"llms":0.5077880796,"data-quality":0.1454643744}}
{"text":"Existing AVQA methods suffer from two major shortcomings; the audio-visual (AV) information passing through the network isn't aligned on Spatial and Temporal levels; and, inter-modal (audio and visual)","meta":{"url":"http://arxiv.org/abs/2310.16754v1"},"cats":{"benchmark":0.3845746935,"new-dataset":0.0133511695,"data-annotation":0.5085494432,"dev-research":0.1826269032,"llms":0.4510905422,"data-quality":0.1179069415}}
{"text":"Semantic information is often not balanced within a context; this results in poor performance.","meta":{"url":"http://arxiv.org/abs/2310.16754v1"},"cats":{"benchmark":0.4080966452,"new-dataset":0.0040850935,"data-annotation":0.5193361136,"dev-research":0.230512295,"llms":0.5451896947,"data-quality":0.358376269}}
{"text":"In this paper, we propose a novel end-to-end Contextual Multi-modal Alignment (CAD) network that addresses the challenges in AVQA methods by i) introducing a parameter-free stochastic Contextual block that ensures robust audio and visual alignment on the Spatial level; ii) proposing a pre-training technique for dynamic audio and visual alignment on Temporal level in a self-supervised setting, and iii) introducing a cross-attention mechanism to balance audio and visual information on Semantic level.","meta":{"url":"http://arxiv.org/abs/2310.16754v1"},"cats":{"benchmark":0.281643861,"new-dataset":0.2790454287,"data-annotation":0.5177891394,"dev-research":0.165729233,"llms":0.5090022599,"data-quality":0.2077632571}}
{"text":"The proposed novel CAD network improves the overall performance over the state-of-the-art methods on average by 9.4% on the MUSIC-AVQA dataset.","meta":{"url":"http://arxiv.org/abs/2310.16754v1"},"cats":{"benchmark":0.471921577,"new-dataset":0.1933523249,"data-annotation":0.509979272,"dev-research":0.1804577566,"llms":0.4435931944,"data-quality":0.1834142044}}
{"text":"We also demonstrate that our proposed contributions to AVQA can be added to the existing methods to improve their performance without additional complexity requirements.","meta":{"url":"http://arxiv.org/abs/2310.16754v1"},"cats":{"benchmark":0.6079686805,"new-dataset":0.0088638607,"data-annotation":0.5294459554,"dev-research":0.1937221592,"llms":0.4933120929,"data-quality":0.0674438238}}
{"text":"Email is a widely used tool for business communication, and email marketing has emerged as a cost-effective strategy for enterprises.","meta":{"url":"http://arxiv.org/abs/2310.16753v1"},"cats":{"benchmark":0.2902909324,"new-dataset":0.0220912453,"data-annotation":0.4938081553,"dev-research":0.2513033006,"llms":0.6187816066,"data-quality":0.1018502178}}
{"text":"While previous studies have examined factors affecting email marketing performance, limited research has focused on understanding email response behavior by considering email content and metadata.","meta":{"url":"http://arxiv.org/abs/2310.16753v1"},"cats":{"benchmark":0.3615808466,"new-dataset":0.0189827062,"data-annotation":0.4940911312,"dev-research":0.1889191733,"llms":0.5620297884,"data-quality":0.1237686387}}
{"text":"This study proposes a Prototype-based Multi-view Network (PROMINET) that incorporates semantic and structural information from email data.","meta":{"url":"http://arxiv.org/abs/2310.16753v1"},"cats":{"benchmark":0.2997276786,"new-dataset":0.1229153316,"data-annotation":0.4872999559,"dev-research":0.1800960629,"llms":0.492540256,"data-quality":0.1806881951}}
{"text":"By utilizing prototype learning, the PROMINET model generates latent exemplars, enabling interpretable email response prediction.","meta":{"url":"http://arxiv.org/abs/2310.16753v1"},"cats":{"benchmark":0.2752317403,"new-dataset":0.0623601744,"data-annotation":0.5331362128,"dev-research":0.1711310564,"llms":0.4809522272,"data-quality":0.1479823623}}
{"text":"The model maps learned semantic and structural exemplars to observed samples in the training data at different levels of granularity, such as document, sentence, or phrase.","meta":{"url":"http://arxiv.org/abs/2310.16753v1"},"cats":{"benchmark":0.2205745253,"new-dataset":0.074155149,"data-annotation":0.517114841,"dev-research":0.1615398006,"llms":0.5344932092,"data-quality":0.230629386}}
{"text":"The approach is evaluated on two real-world email datasets: the Enron corpus and an in-house Email Marketing corpus.","meta":{"url":"http://arxiv.org/abs/2310.16753v1"},"cats":{"benchmark":0.3067482716,"new-dataset":0.7005581207,"data-annotation":0.5084103397,"dev-research":0.1581120486,"llms":0.5532838623,"data-quality":0.2628031183}}
{"text":"Experimental results demonstrate that the PROMINET model outperforms baseline models, achieving a ~3% improvement in F1 score on both datasets.","meta":{"url":"http://arxiv.org/abs/2310.16753v1"},"cats":{"benchmark":0.6571527555,"new-dataset":0.1362194991,"data-annotation":0.5061434461,"dev-research":0.1710134439,"llms":0.3914182083,"data-quality":0.1565392662}}
{"text":"Additionally, the model provides interpretability through prototypes at different granularity levels while maintaining comparable performance to non-interpretable models.","meta":{"url":"http://arxiv.org/abs/2310.16753v1"},"cats":{"benchmark":0.2948519306,"new-dataset":0.0131666655,"data-annotation":0.504492463,"dev-research":0.3053758402,"llms":0.5168561382,"data-quality":0.0992883329}}
{"text":"The learned prototypes also show potential for generating suggestions to enhance email text editing and improve the likelihood of effective email responses.","meta":{"url":"http://arxiv.org/abs/2310.16753v1"},"cats":{"benchmark":0.2480137546,"new-dataset":0.0272925999,"data-annotation":0.539697551,"dev-research":0.329439312,"llms":0.5823757376,"data-quality":0.1809143877}}
{"text":"This research contributes to enhancing sender-receiver communication and customer engagement in email interactions.","meta":{"url":"http://arxiv.org/abs/2310.16753v1"},"cats":{"benchmark":0.2796096817,"new-dataset":0.0311421278,"data-annotation":0.5195735614,"dev-research":0.2533274604,"llms":0.5700931901,"data-quality":0.0888628824}}
{"text":"Clustering is a fundamental problem in unsupervised machine learning with many applications in data analysis.","meta":{"url":"http://arxiv.org/abs/2310.16752v1"},"cats":{"benchmark":0.3774769637,"new-dataset":0.0276284147,"data-annotation":0.5256641063,"dev-research":0.1955761457,"llms":0.3813708459,"data-quality":0.1939449231}}
{"text":"Popular clustering algorithms such as Lloyd's algorithm and $k$-means++ can take $\\Omega(ndk)$ time when clustering $n$ points in a $d$-dimensional space (represented by an $n\\times d$ matrix $X$) into $k$ clusters.","meta":{"url":"http://arxiv.org/abs/2310.16752v1"},"cats":{"benchmark":0.4355120043,"new-dataset":0.0217580263,"data-annotation":0.5243470117,"dev-research":0.1523691953,"llms":0.448223536,"data-quality":0.0603011665}}
{"text":"In applications with moderate to large $k$, the multiplicative $k$ factor can become very expensive.","meta":{"url":"http://arxiv.org/abs/2310.16752v1"},"cats":{"benchmark":0.3924191539,"new-dataset":0.0168963776,"data-annotation":0.523516643,"dev-research":0.1352400843,"llms":0.492518231,"data-quality":0.0509887011}}
{"text":"We introduce a simple randomized clustering algorithm that provably runs in expected time $O(\\mathrm{nnz}(X)","meta":{"url":"http://arxiv.org/abs/2310.16752v1"},"cats":{"benchmark":0.5192926545,"new-dataset":0.0215969062,"data-annotation":0.5584228675,"dev-research":0.1427723845,"llms":0.4313087884,"data-quality":0.1289311242}}
{"text":"+","meta":{"url":"http://arxiv.org/abs/2310.16752v1"},"cats":{"benchmark":0.2724981267,"new-dataset":0.5180100524,"data-annotation":0.5402472276,"dev-research":0.1919525655,"llms":0.4796416452,"data-quality":0.0970109373}}
{"text":"n\\log n)$ for arbitrary $k$. Here $\\mathrm{nnz}(X)$ is the total number of non-zero entries in the input dataset $X$, which is upper bounded by $nd$ and can be significantly smaller for sparse datasets.","meta":{"url":"http://arxiv.org/abs/2310.16752v1"},"cats":{"benchmark":0.4278630244,"new-dataset":0.0852070804,"data-annotation":0.5109770408,"dev-research":0.1157905783,"llms":0.4193469936,"data-quality":0.1148775107}}
{"text":"We prove that our algorithm achieves approximation ratio $\\smash{\\widetilde{O}(k^4)}$ on any input dataset for the $k$-means objective.","meta":{"url":"http://arxiv.org/abs/2310.16752v1"},"cats":{"benchmark":0.5177448845,"new-dataset":0.0595051597,"data-annotation":0.5466383061,"dev-research":0.1453619179,"llms":0.360155326,"data-quality":0.1547804589}}
{"text":"We also believe that our theoretical analysis is of independent interest, as we show that the approximation ratio of a $k$-means algorithm is approximately preserved under a class of projections and that $k$-means++ seeding can be implemented in expected $O(n \\log","meta":{"url":"http://arxiv.org/abs/2310.16752v1"},"cats":{"benchmark":0.5085856949,"new-dataset":0.0236935195,"data-annotation":0.5600487966,"dev-research":0.1467493722,"llms":0.4280515639,"data-quality":0.1202247139}}
{"text":"n)$ time in one dimension.","meta":{"url":"http://arxiv.org/abs/2310.16752v1"},"cats":{"benchmark":0.2646208671,"new-dataset":0.1656186582,"data-annotation":0.523330355,"dev-research":0.2014610521,"llms":0.4367710221,"data-quality":0.1028254562}}
{"text":"Finally, we show experimentally that our clustering algorithm gives a new tradeoff between running time and cluster quality compared to previous state-of-the-art methods for these tasks.","meta":{"url":"http://arxiv.org/abs/2310.16752v1"},"cats":{"benchmark":0.6732541759,"new-dataset":0.0465564108,"data-annotation":0.5500348881,"dev-research":0.2528811302,"llms":0.4692144716,"data-quality":0.2522573652}}
{"text":"In this work, we address the problem of real-time dense depth estimation from monocular images for mobile underwater vehicles.","meta":{"url":"http://arxiv.org/abs/2310.16750v1"},"cats":{"benchmark":0.3230364284,"new-dataset":0.1724208034,"data-annotation":0.512177171,"dev-research":0.1794943462,"llms":0.4125527168,"data-quality":0.0888539607}}
{"text":"We formulate a deep learning model that fuses sparse depth measurements from triangulated features to improve the depth predictions and solve the problem of scale ambiguity.","meta":{"url":"http://arxiv.org/abs/2310.16750v1"},"cats":{"benchmark":0.28905351,"new-dataset":0.1396407909,"data-annotation":0.4938797024,"dev-research":0.1632012321,"llms":0.4111923823,"data-quality":0.1376330327}}
{"text":"To allow prior inputs of arbitrary sparsity, we apply a dense parameterization method.","meta":{"url":"http://arxiv.org/abs/2310.16750v1"},"cats":{"benchmark":0.5185521729,"new-dataset":0.0195484702,"data-annotation":0.5277845691,"dev-research":0.109530641,"llms":0.3944752562,"data-quality":0.1884796702}}
{"text":"Our model extends recent state-of-the-art approaches to monocular image based depth estimation, using an efficient encoder-decoder backbone and modern lightweight transformer optimization stage to encode global context.","meta":{"url":"http://arxiv.org/abs/2310.16750v1"},"cats":{"benchmark":0.2919924571,"new-dataset":0.0746541865,"data-annotation":0.4981809243,"dev-research":0.1367105336,"llms":0.4851408091,"data-quality":0.057470977}}
{"text":"The network is trained in a supervised fashion on the forward-looking underwater dataset, FLSea.","meta":{"url":"http://arxiv.org/abs/2310.16750v1"},"cats":{"benchmark":0.1949640757,"new-dataset":0.2834211925,"data-annotation":0.5085317658,"dev-research":0.1409628625,"llms":0.4938735264,"data-quality":0.1451525012}}
{"text":"Evaluation results on this dataset demonstrate significant improvement in depth prediction accuracy by the fusion of the sparse feature priors.","meta":{"url":"http://arxiv.org/abs/2310.16750v1"},"cats":{"benchmark":0.4656131254,"new-dataset":0.2388165506,"data-annotation":0.5207445342,"dev-research":0.1506750587,"llms":0.3939659638,"data-quality":0.1254395219}}
{"text":"In addition, without any retraining, our method achieves similar depth prediction accuracy on a downward looking dataset we collected with a diver operated camera rig, conducting a survey of a coral reef.","meta":{"url":"http://arxiv.org/abs/2310.16750v1"},"cats":{"benchmark":0.3307395827,"new-dataset":0.3673412124,"data-annotation":0.5014705357,"dev-research":0.1688144017,"llms":0.4658306589,"data-quality":0.1188720586}}
{"text":"The method achieves real-time performance, running at 160 FPS on a laptop GPU and 7 FPS on a single CPU core and is suitable for direct deployment on embedded systems.","meta":{"url":"http://arxiv.org/abs/2310.16750v1"},"cats":{"benchmark":0.5287252824,"new-dataset":0.0269269339,"data-annotation":0.5084683382,"dev-research":0.2670029675,"llms":0.4900577323,"data-quality":0.0458518407}}
{"text":"The implementation of this work is made publicly available at https://github.com/ebnerluca/uw_depth.","meta":{"url":"http://arxiv.org/abs/2310.16750v1"},"cats":{"benchmark":0.4068629828,"new-dataset":0.0521761117,"data-annotation":0.5333320151,"dev-research":0.1087582548,"llms":0.5019844369,"data-quality":0.0737752592}}
{"text":"Disfluency correction (DC) is the process of removing disfluent elements like fillers, repetitions and corrections from spoken utterances to create readable and interpretable text.","meta":{"url":"http://arxiv.org/abs/2310.16749v1"},"cats":{"benchmark":0.3094488847,"new-dataset":0.0449533099,"data-annotation":0.474905509,"dev-research":0.2641723813,"llms":0.5744662475,"data-quality":0.3696830126}}
{"text":"DC is a vital post-processing step applied to Automatic Speech Recognition (ASR) outputs, before subsequent processing by downstream language understanding tasks.","meta":{"url":"http://arxiv.org/abs/2310.16749v1"},"cats":{"benchmark":0.2937957411,"new-dataset":0.0499107574,"data-annotation":0.5050004666,"dev-research":0.2129744431,"llms":0.5425507825,"data-quality":0.2884912606}}
{"text":"Existing DC research has primarily focused on English due to the unavailability of large-scale open-source datasets.","meta":{"url":"http://arxiv.org/abs/2310.16749v1"},"cats":{"benchmark":0.2751447796,"new-dataset":0.4182442874,"data-annotation":0.5064403925,"dev-research":0.2080112636,"llms":0.5827526725,"data-quality":0.2566238474}}
{"text":"Towards the goal of multilingual disfluency correction, we present a high-quality human-annotated DC corpus covering four important Indo-European languages: English, Hindi, German and French.","meta":{"url":"http://arxiv.org/abs/2310.16749v1"},"cats":{"benchmark":0.3307265132,"new-dataset":0.556079136,"data-annotation":0.5264735614,"dev-research":0.2665980446,"llms":0.5587604717,"data-quality":0.5512150123}}
{"text":"We provide extensive analysis of results of state-of-the-art DC models across all four languages obtaining F1 scores of 97.55 (English), 94.29 (Hindi), 95.89 (German) and 92.97 (French).","meta":{"url":"http://arxiv.org/abs/2310.16749v1"},"cats":{"benchmark":0.4905561041,"new-dataset":0.1283193426,"data-annotation":0.5358954818,"dev-research":0.1656099663,"llms":0.483183123,"data-quality":0.2243045632}}
{"text":"To demonstrate the benefits of DC on downstream tasks, we show that DC leads to 5.65 points increase in BLEU scores on average when used in conjunction with a state-of-the-art Machine Translation (MT) system.","meta":{"url":"http://arxiv.org/abs/2310.16749v1"},"cats":{"benchmark":0.462224885,"new-dataset":0.0616696517,"data-annotation":0.488529215,"dev-research":0.21397308,"llms":0.5589748723,"data-quality":0.1849556922}}
{"text":"We release code to run our experiments along with our annotated dataset here.","meta":{"url":"http://arxiv.org/abs/2310.16749v1"},"cats":{"benchmark":0.3457471906,"new-dataset":0.8623196888,"data-annotation":0.5291160931,"dev-research":0.2417291335,"llms":0.5391630723,"data-quality":0.2968407616}}
{"text":"Authorship Analysis, also known as stylometry, has been an essential aspect of Natural Language Processing (NLP) for a long time.","meta":{"url":"http://arxiv.org/abs/2310.16746v1"},"cats":{"benchmark":0.3746739525,"new-dataset":0.0711401618,"data-annotation":0.5418187429,"dev-research":0.3097708062,"llms":0.4577047145,"data-quality":0.2483018996}}
{"text":"Likewise, the recent advancement of Large Language Models (LLMs) has made authorship analysis increasingly crucial for distinguishing between human-written and AI-generated texts.","meta":{"url":"http://arxiv.org/abs/2310.16746v1"},"cats":{"benchmark":0.2733020397,"new-dataset":0.1357880918,"data-annotation":0.5530302023,"dev-research":0.2003010109,"llms":0.6187242187,"data-quality":0.1712761051}}
{"text":"However, these authorship analysis tasks have primarily been focused on written texts, not considering spoken texts.","meta":{"url":"http://arxiv.org/abs/2310.16746v1"},"cats":{"benchmark":0.3688262733,"new-dataset":0.0134485965,"data-annotation":0.5297704803,"dev-research":0.2312822807,"llms":0.5363695266,"data-quality":0.148597303}}
{"text":"Thus, we introduce the largest benchmark for spoken texts - HANSEN (Human ANd ai Spoken tExt beNchmark).","meta":{"url":"http://arxiv.org/abs/2310.16746v1"},"cats":{"benchmark":0.632248643,"new-dataset":0.3715520676,"data-annotation":0.5615311833,"dev-research":0.1652877189,"llms":0.4337787917,"data-quality":0.1956499536}}
{"text":"HANSEN encompasses meticulous curation of existing speech datasets accompanied by transcripts, alongside the creation of novel AI-generated spoken text datasets.","meta":{"url":"http://arxiv.org/abs/2310.16746v1"},"cats":{"benchmark":0.2443366995,"new-dataset":0.8468042018,"data-annotation":0.5153367726,"dev-research":0.1732849165,"llms":0.4822975379,"data-quality":0.2818739639}}
{"text":"Together, it comprises 17 human datasets, and AI-generated spoken texts created using 3 prominent LLMs: ChatGPT, PaLM2, and Vicuna13B. To evaluate and demonstrate the utility of HANSEN, we perform Authorship Attribution (AA) & Author Verification (AV) on human-spoken datasets and conducted Human vs. AI spoken text detection using state-of-the-art (SOTA) models.","meta":{"url":"http://arxiv.org/abs/2310.16746v1"},"cats":{"benchmark":0.309502969,"new-dataset":0.6236642409,"data-annotation":0.5486872624,"dev-research":0.1495358435,"llms":0.5818060719,"data-quality":0.2186063965}}
{"text":"While SOTA methods, such as, character ngram or Transformer-based model, exhibit similar AA & AV performance in human-spoken datasets compared to written ones, there is much room for improvement in AI-generated spoken text detection.","meta":{"url":"http://arxiv.org/abs/2310.16746v1"},"cats":{"benchmark":0.3432845716,"new-dataset":0.0610751103,"data-annotation":0.5461707933,"dev-research":0.1346428499,"llms":0.5077450592,"data-quality":0.2136831117}}
{"text":"The HANSEN benchmark is available at: https://huggingface.co/datasets/HANSEN-REPO/HANSEN.","meta":{"url":"http://arxiv.org/abs/2310.16746v1"},"cats":{"benchmark":0.7474769053,"new-dataset":0.5297350552,"data-annotation":0.5296887601,"dev-research":0.0949392585,"llms":0.4088608624,"data-quality":0.0881532034}}
{"text":"Spiking Neural Networks (SNNs) offer a promising alternative to Artificial Neural Networks (ANNs) for deep learning applications, particularly in resource-constrained systems.","meta":{"url":"http://arxiv.org/abs/2310.16745v1"},"cats":{"benchmark":0.2700847772,"new-dataset":0.0921435444,"data-annotation":0.5226269789,"dev-research":0.1918546241,"llms":0.5870310511,"data-quality":0.1013930376}}
{"text":"This is largely due to their inherent sparsity, influenced by factors such as the input dataset, the length of the spike train, and the network topology.","meta":{"url":"http://arxiv.org/abs/2310.16745v1"},"cats":{"benchmark":0.3954933387,"new-dataset":0.0152644841,"data-annotation":0.5196002346,"dev-research":0.1660396919,"llms":0.4577449295,"data-quality":0.1665350825}}
{"text":"While a few prior works have demonstrated the advantages of incorporating sparsity into the hardware design, especially in terms of reducing energy consumption, the impact on hardware resources has not yet been explored.","meta":{"url":"http://arxiv.org/abs/2310.16745v1"},"cats":{"benchmark":0.51279612,"new-dataset":0.0080591434,"data-annotation":0.4985239865,"dev-research":0.2767317046,"llms":0.5840640082,"data-quality":0.0865600206}}
{"text":"This is where design space exploration (DSE) becomes crucial, as it allows for the optimization of hardware performance by tailoring both the hardware and model parameters to suit specific application needs.","meta":{"url":"http://arxiv.org/abs/2310.16745v1"},"cats":{"benchmark":0.3235379341,"new-dataset":0.0090579143,"data-annotation":0.481867009,"dev-research":0.3377398726,"llms":0.5669264806,"data-quality":0.0434987722}}
{"text":"However, DSE can be extremely challenging given the potentially large design space and the interplay of hardware architecture design choices and application-specific model parameters.   ","meta":{"url":"http://arxiv.org/abs/2310.16745v1"},"cats":{"benchmark":0.4039762133,"new-dataset":0.0069014242,"data-annotation":0.4847867706,"dev-research":0.2384574623,"llms":0.5788287678,"data-quality":0.0559167402}}
{"text":"In this paper, we propose a flexible hardware design that leverages the sparsity of SNNs to identify highly efficient, application-specific accelerator designs.","meta":{"url":"http://arxiv.org/abs/2310.16745v1"},"cats":{"benchmark":0.385996675,"new-dataset":0.0310680427,"data-annotation":0.5162327994,"dev-research":0.128012967,"llms":0.5914974895,"data-quality":0.0775804302}}
{"text":"We develop a high-level, cycle-accurate simulation framework for this hardware and demonstrate the framework's benefits in enabling detailed and fine-grained exploration of SNN design choices, such as the layer-wise logical-to-hardware ratio (LHR).","meta":{"url":"http://arxiv.org/abs/2310.16745v1"},"cats":{"benchmark":0.3410413158,"new-dataset":0.1396026183,"data-annotation":0.5067344559,"dev-research":0.1937796923,"llms":0.631597636,"data-quality":0.0713682416}}
{"text":"Our experimental results show that our design can (i) achieve up to $76\\%$ reduction in hardware resources and (ii) deliver a speed increase of up to $31.25\\times$, while requiring $27\\%$ fewer hardware resources compared to sparsity-oblivious designs.","meta":{"url":"http://arxiv.org/abs/2310.16745v1"},"cats":{"benchmark":0.4482014754,"new-dataset":0.0171389845,"data-annotation":0.528518523,"dev-research":0.2103778986,"llms":0.5951322683,"data-quality":0.075832602}}
{"text":"We further showcase the robustness of our framework by varying spike train lengths with different neuron population sizes to find the optimal trade-off points between accuracy and hardware latency.","meta":{"url":"http://arxiv.org/abs/2310.16745v1"},"cats":{"benchmark":0.4964533666,"new-dataset":0.031782825,"data-annotation":0.5277272369,"dev-research":0.1710604623,"llms":0.4402581497,"data-quality":0.1854361579}}
{"text":"We introduce the 'Stochastic Latent Transformer', a probabilistic deep learning approach for efficient reduced-order modelling of stochastic partial differential equations (SPDEs).","meta":{"url":"http://arxiv.org/abs/2310.16741v1"},"cats":{"benchmark":0.3283577,"new-dataset":0.0475900409,"data-annotation":0.5078338929,"dev-research":0.1611934205,"llms":0.4257989923,"data-quality":0.0837380574}}
{"text":"Despite recent advances in deep learning for fluid mechanics, limited research has explored modelling stochastically driven flows - which play a crucial role in understanding a broad spectrum of phenomena, from jets on giant planets to ocean circulation and the variability of midlatitude weather.","meta":{"url":"http://arxiv.org/abs/2310.16741v1"},"cats":{"benchmark":0.1736552388,"new-dataset":0.1590930556,"data-annotation":0.4980029967,"dev-research":0.1749034132,"llms":0.4987580843,"data-quality":0.0809533113}}
{"text":"The model architecture consists of a stochastically-forced transformer, paired with a translation-equivariant autoencoder, that we demonstrate is capable of reproducing system dynamics across various integration periods.","meta":{"url":"http://arxiv.org/abs/2310.16741v1"},"cats":{"benchmark":0.2415554102,"new-dataset":0.0214247552,"data-annotation":0.4825934553,"dev-research":0.144847087,"llms":0.4995575824,"data-quality":0.0927620293}}
{"text":"We demonstrate its effectiveness applied to a well-researched zonal jet system, with the neural network achieving a five-order-of-magnitude speedup compared to numerical integration.","meta":{"url":"http://arxiv.org/abs/2310.16741v1"},"cats":{"benchmark":0.4843569625,"new-dataset":0.0199532734,"data-annotation":0.5001700094,"dev-research":0.1595053984,"llms":0.4447259021,"data-quality":0.0775071826}}
{"text":"This facilitates the cost-effective generation of large ensembles, enabling the exploration of statistical questions concerning probabilities of spontaneous transition events.","meta":{"url":"http://arxiv.org/abs/2310.16741v1"},"cats":{"benchmark":0.3468097093,"new-dataset":0.0982316979,"data-annotation":0.544765113,"dev-research":0.1568808149,"llms":0.5046536275,"data-quality":0.0890879814}}
{"text":"The recent years have seen remarkable progress in establishing the complexity of the reachability problem for vector addition systems with states (VASS), equivalently known as Petri nets.","meta":{"url":"http://arxiv.org/abs/2310.16740v1"},"cats":{"benchmark":0.3433624359,"new-dataset":0.0146653628,"data-annotation":0.5236089481,"dev-research":0.1646176516,"llms":0.5542346288,"data-quality":0.0703415691}}
{"text":"Existing work primarily considers the case in which both the VASS as well as the initial and target configurations are part of the input.","meta":{"url":"http://arxiv.org/abs/2310.16740v1"},"cats":{"benchmark":0.3214778677,"new-dataset":0.00438713,"data-annotation":0.4940471479,"dev-research":0.2021506678,"llms":0.5212769782,"data-quality":0.1016977514}}
{"text":"In this paper, we investigate the reachability problem in the setting where the VASS is fixed and only the initial configuration is variable.","meta":{"url":"http://arxiv.org/abs/2310.16740v1"},"cats":{"benchmark":0.3762815023,"new-dataset":0.0148973651,"data-annotation":0.5013077501,"dev-research":0.1420303732,"llms":0.5381682228,"data-quality":0.1163996566}}
{"text":"We show that fixed VASS fully express arithmetic on initial segments of the natural numbers.","meta":{"url":"http://arxiv.org/abs/2310.16740v1"},"cats":{"benchmark":0.3346410367,"new-dataset":0.1530230195,"data-annotation":0.514340466,"dev-research":0.1830211666,"llms":0.5412083333,"data-quality":0.1843179672}}
{"text":"It follows that there is a very weak reduction from any fixed such number-theoretic predicate (e.g. primality or square-freeness) to reachability in fixed VASS where configurations are presented in unary.","meta":{"url":"http://arxiv.org/abs/2310.16740v1"},"cats":{"benchmark":0.3353892704,"new-dataset":0.0220017759,"data-annotation":0.526207186,"dev-research":0.133130485,"llms":0.5839356943,"data-quality":0.1018514401}}
{"text":"If configurations are given in binary, we show that there is a fixed VASS with five counters whose reachability problem is PSPACE-hard.","meta":{"url":"http://arxiv.org/abs/2310.16740v1"},"cats":{"benchmark":0.3877871669,"new-dataset":0.1603426913,"data-annotation":0.5136278925,"dev-research":0.158438898,"llms":0.5887854286,"data-quality":0.1165314821}}
{"text":"Conversational Recommendation System (CRS) is a rapidly growing research area that has gained significant attention alongside advancements in language modelling techniques.","meta":{"url":"http://arxiv.org/abs/2310.16738v1"},"cats":{"benchmark":0.3195964308,"new-dataset":0.1450215505,"data-annotation":0.5230716797,"dev-research":0.2441301298,"llms":0.4979135029,"data-quality":0.1321453691}}
{"text":"However, the current state of conversational recommendation faces numerous challenges due to its relative novelty and limited existing contributions.","meta":{"url":"http://arxiv.org/abs/2310.16738v1"},"cats":{"benchmark":0.2985636028,"new-dataset":0.0275388148,"data-annotation":0.5415489479,"dev-research":0.239443968,"llms":0.5273238604,"data-quality":0.1849947871}}
{"text":"In this study, we delve into benchmark datasets for developing CRS models and address potential biases arising from the feedback loop inherent in multi-turn interactions, including selection bias and multiple popularity bias variants.","meta":{"url":"http://arxiv.org/abs/2310.16738v1"},"cats":{"benchmark":0.5377888285,"new-dataset":0.0863583971,"data-annotation":0.5142184762,"dev-research":0.1440898489,"llms":0.3865899081,"data-quality":0.0905210326}}
{"text":"Drawing inspiration from the success of generative data via using language models and data augmentation techniques, we present two novel strategies, 'Once-Aug' and 'PopNudge', to enhance model performance while mitigating biases.","meta":{"url":"http://arxiv.org/abs/2310.16738v1"},"cats":{"benchmark":0.3342618891,"new-dataset":0.0707305531,"data-annotation":0.5197804068,"dev-research":0.2947136305,"llms":0.5575028611,"data-quality":0.3137701514}}
{"text":"Through extensive experiments on ReDial and TG-ReDial benchmark datasets, we show a consistent improvement of CRS techniques with our data augmentation approaches and offer additional insights on addressing multiple newly formulated biases.","meta":{"url":"http://arxiv.org/abs/2310.16738v1"},"cats":{"benchmark":0.7119902744,"new-dataset":0.2111690779,"data-annotation":0.4970356406,"dev-research":0.1783022901,"llms":0.4238823248,"data-quality":0.2182397339}}
{"text":"Robots performing human-scale manipulation tasks require an extensive amount of knowledge about their surroundings in order to perform their actions competently and human-like.","meta":{"url":"http://arxiv.org/abs/2310.16737v1"},"cats":{"benchmark":0.1705833431,"new-dataset":0.058953046,"data-annotation":0.502104153,"dev-research":0.233310321,"llms":0.5353851002,"data-quality":0.0441595916}}
{"text":"In this work, we investigate the use of virtual reality technology as an implementation for robot environment modeling, and present a technique for translating scene graphs into knowledge bases.","meta":{"url":"http://arxiv.org/abs/2310.16737v1"},"cats":{"benchmark":0.1514219661,"new-dataset":0.5335424161,"data-annotation":0.5092795042,"dev-research":0.3422816879,"llms":0.460176082,"data-quality":0.084216487}}
{"text":"To this end, we take advantage of the Universal Scene Description (USD) format which is an emerging standard for the authoring, visualization and simulation of complex environments.","meta":{"url":"http://arxiv.org/abs/2310.16737v1"},"cats":{"benchmark":0.1640898732,"new-dataset":0.7025927664,"data-annotation":0.4991391841,"dev-research":0.2259844939,"llms":0.5086033583,"data-quality":0.0984348431}}
{"text":"We investigate the conversion of USD-based environment models into Knowledge Graph (KG) representations that facilitate semantic querying and integration with additional knowledge sources.","meta":{"url":"http://arxiv.org/abs/2310.16737v1"},"cats":{"benchmark":0.1417069616,"new-dataset":0.364182146,"data-annotation":0.4932347154,"dev-research":0.2328042412,"llms":0.5801941229,"data-quality":0.12781999}}
{"text":"In the realm of data protection, a striking disconnect prevails between traditional domains of doctrinal, legal, theoretical, and policy-based inquiries and a burgeoning body of empirical evidence.","meta":{"url":"http://arxiv.org/abs/2310.16735v1"},"cats":{"benchmark":0.2075314712,"new-dataset":0.240731964,"data-annotation":0.4459323065,"dev-research":0.2141825259,"llms":0.5420529127,"data-quality":0.1341309849}}
{"text":"Much of the scholarly and regulatory discourse remains entrenched in abstract legal principles or normative frameworks, leaving the empirical landscape uncharted or minimally engaged.","meta":{"url":"http://arxiv.org/abs/2310.16735v1"},"cats":{"benchmark":0.2829106198,"new-dataset":0.0836468164,"data-annotation":0.4918348117,"dev-research":0.2589066951,"llms":0.5548372579,"data-quality":0.1747094188}}
{"text":"Since the birth of EU data protection law, a modest body of empirical evidence has been generated but remains widely scattered and unexamined.","meta":{"url":"http://arxiv.org/abs/2310.16735v1"},"cats":{"benchmark":0.3132032627,"new-dataset":0.3625111997,"data-annotation":0.474330103,"dev-research":0.2369101335,"llms":0.4737973323,"data-quality":0.2154665573}}
{"text":"Such evidence offers vital insights into the perception, impact, clarity, and effects of data protection measures but languishes on the periphery, inadequately integrated into the broader conversation.","meta":{"url":"http://arxiv.org/abs/2310.16735v1"},"cats":{"benchmark":0.2723352424,"new-dataset":0.1842864704,"data-annotation":0.459931874,"dev-research":0.2854891103,"llms":0.5318469224,"data-quality":0.1883331844}}
{"text":"To make a meaningful connection, we conduct a comprehensive review and synthesis of empirical research spanning nearly three decades (1995- March 2022), advocating for a more robust integration of empirical evidence into the evaluation and review of the GDPR, while laying a methodological foundation for future empirical research.","meta":{"url":"http://arxiv.org/abs/2310.16735v1"},"cats":{"benchmark":0.5270849861,"new-dataset":0.0583876357,"data-annotation":0.4791354325,"dev-research":0.2938286152,"llms":0.4422138866,"data-quality":0.1653150812}}
{"text":"In recent years, digital humans have been widely applied in augmented/virtual reality (A/VR), where viewers are allowed to freely observe and interact with the volumetric content.","meta":{"url":"http://arxiv.org/abs/2310.16732v1"},"cats":{"benchmark":0.1583728312,"new-dataset":0.0894320104,"data-annotation":0.500145853,"dev-research":0.2022823765,"llms":0.5071803112,"data-quality":0.0534744322}}
{"text":"However, the digital humans may be degraded with various distortions during the procedure of generation and transmission.","meta":{"url":"http://arxiv.org/abs/2310.16732v1"},"cats":{"benchmark":0.2180326282,"new-dataset":0.0137429098,"data-annotation":0.5034379695,"dev-research":0.2493768476,"llms":0.5393711346,"data-quality":0.1740108968}}
{"text":"Moreover, little effort has been put into the perceptual quality assessment of digital humans.","meta":{"url":"http://arxiv.org/abs/2310.16732v1"},"cats":{"benchmark":0.3569725462,"new-dataset":0.0123266979,"data-annotation":0.536147866,"dev-research":0.2774694919,"llms":0.5285584944,"data-quality":0.2074773962}}
{"text":"Therefore, it is urgent to carry out objective quality assessment methods to tackle the challenge of digital human quality assessment (DHQA).","meta":{"url":"http://arxiv.org/abs/2310.16732v1"},"cats":{"benchmark":0.4654732867,"new-dataset":0.0601456777,"data-annotation":0.4921777915,"dev-research":0.2624036715,"llms":0.5104263018,"data-quality":0.1701523126}}
{"text":"In this paper, we develop a novel no-reference (NR) method based on Transformer to deal with DHQA in a multi-task manner.","meta":{"url":"http://arxiv.org/abs/2310.16732v1"},"cats":{"benchmark":0.410859702,"new-dataset":0.0130126303,"data-annotation":0.5062367251,"dev-research":0.1967096474,"llms":0.5308318435,"data-quality":0.1183511642}}
{"text":"Specifically, the front 2D projections of the digital humans are rendered as inputs and the vision transformer (ViT) is employed for the feature extraction.","meta":{"url":"http://arxiv.org/abs/2310.16732v1"},"cats":{"benchmark":0.2044490665,"new-dataset":0.1028348049,"data-annotation":0.5064103147,"dev-research":0.2104424725,"llms":0.4546912848,"data-quality":0.0677279929}}
{"text":"Then we design a multi-task module to jointly classify the distortion types and predict the perceptual quality levels of digital humans.","meta":{"url":"http://arxiv.org/abs/2310.16732v1"},"cats":{"benchmark":0.322097897,"new-dataset":0.1089354847,"data-annotation":0.5254995949,"dev-research":0.2466997065,"llms":0.4748144441,"data-quality":0.227961779}}
{"text":"The experimental results show that the proposed method well correlates with the subjective ratings and outperforms the state-of-the-art quality assessment methods.","meta":{"url":"http://arxiv.org/abs/2310.16732v1"},"cats":{"benchmark":0.7406488659,"new-dataset":0.01202515,"data-annotation":0.5396323943,"dev-research":0.2747125201,"llms":0.5090857563,"data-quality":0.3461771887}}
{"text":"Spatial reasoning over text is challenging as the models not only need to extract the direct spatial information from the text but also reason over those and infer implicit spatial relations.","meta":{"url":"http://arxiv.org/abs/2310.16731v1"},"cats":{"benchmark":0.2399691779,"new-dataset":0.0553247367,"data-annotation":0.5362320731,"dev-research":0.260052974,"llms":0.5102472856,"data-quality":0.1583564669}}
{"text":"Recent studies highlight the struggles even large language models encounter when it comes to performing spatial reasoning over text.","meta":{"url":"http://arxiv.org/abs/2310.16731v1"},"cats":{"benchmark":0.2434546913,"new-dataset":0.0679322659,"data-annotation":0.5436129692,"dev-research":0.3029752961,"llms":0.5616044577,"data-quality":0.1660445567}}
{"text":"In this paper, we explore the potential benefits of disentangling the processes of information extraction and reasoning in models to address this challenge.","meta":{"url":"http://arxiv.org/abs/2310.16731v1"},"cats":{"benchmark":0.220211582,"new-dataset":0.0218044932,"data-annotation":0.5109108668,"dev-research":0.2555704125,"llms":0.5126927392,"data-quality":0.1795489691}}
{"text":"To explore this, we design various models that disentangle extraction and reasoning(either symbolic or neural) and compare them with state-of-the-art(SOTA) baselines with no explicit design for these parts.","meta":{"url":"http://arxiv.org/abs/2310.16731v1"},"cats":{"benchmark":0.3216553101,"new-dataset":0.040946975,"data-annotation":0.5339516643,"dev-research":0.2200702508,"llms":0.5177979064,"data-quality":0.1381497921}}
{"text":"Our experimental results consistently demonstrate the efficacy of disentangling, showcasing its ability to enhance models' generalizability within realistic data domains.","meta":{"url":"http://arxiv.org/abs/2310.16731v1"},"cats":{"benchmark":0.257984717,"new-dataset":0.013757569,"data-annotation":0.5016541999,"dev-research":0.2578306516,"llms":0.5010787177,"data-quality":0.1065770568}}
{"text":"Recently, there has been an increasing interest in automated prompt optimization based on reinforcement learning (RL).","meta":{"url":"http://arxiv.org/abs/2310.16730v1"},"cats":{"benchmark":0.2696318372,"new-dataset":0.0495228967,"data-annotation":0.5218369691,"dev-research":0.181329447,"llms":0.449764914,"data-quality":0.0925677557}}
{"text":"This approach offers important advantages, such as generating interpretable prompts and being compatible with black-box foundation models.","meta":{"url":"http://arxiv.org/abs/2310.16730v1"},"cats":{"benchmark":0.2024801144,"new-dataset":0.0254676736,"data-annotation":0.5078895236,"dev-research":0.2544909017,"llms":0.547552908,"data-quality":0.0815780434}}
{"text":"However, the substantial prompt space size poses challenges for RL-based methods, often leading to suboptimal policy convergence.","meta":{"url":"http://arxiv.org/abs/2310.16730v1"},"cats":{"benchmark":0.3622433317,"new-dataset":0.0102011729,"data-annotation":0.4992845891,"dev-research":0.1748669277,"llms":0.4764733619,"data-quality":0.0771955856}}
{"text":"This paper introduces MultiPrompter, a new framework that views prompt optimization as a cooperative game between prompters which take turns composing a prompt together.","meta":{"url":"http://arxiv.org/abs/2310.16730v1"},"cats":{"benchmark":0.198704737,"new-dataset":0.0480603292,"data-annotation":0.523053235,"dev-research":0.3176566924,"llms":0.5058818025,"data-quality":0.0762341211}}
{"text":"Our cooperative prompt optimization effectively reduces the problem size and helps prompters learn optimal prompts.","meta":{"url":"http://arxiv.org/abs/2310.16730v1"},"cats":{"benchmark":0.2749944116,"new-dataset":0.0138450652,"data-annotation":0.5278616724,"dev-research":0.284072088,"llms":0.5109244421,"data-quality":0.1096818713}}
{"text":"We test our method on the text-to-image task and show its ability to generate higher-quality images than baselines.","meta":{"url":"http://arxiv.org/abs/2310.16730v1"},"cats":{"benchmark":0.4995720542,"new-dataset":0.2083995626,"data-annotation":0.5329035396,"dev-research":0.2057711241,"llms":0.5015011587,"data-quality":0.193227366}}
{"text":"Recent advancements in the field of Artificial Intelligence (AI) establish the basis to address challenging tasks.","meta":{"url":"http://arxiv.org/abs/2310.16727v1"},"cats":{"benchmark":0.3040005943,"new-dataset":0.0229486625,"data-annotation":0.5186059953,"dev-research":0.2442713157,"llms":0.440117773,"data-quality":0.0945190777}}
{"text":"However, with the integration of AI, new risks arise.","meta":{"url":"http://arxiv.org/abs/2310.16727v1"},"cats":{"benchmark":0.1910259385,"new-dataset":0.0196449352,"data-annotation":0.5187681069,"dev-research":0.3192330903,"llms":0.4895619171,"data-quality":0.1492363425}}
{"text":"Therefore, to benefit from its advantages, it is essential to adequately handle the risks associated with AI.","meta":{"url":"http://arxiv.org/abs/2310.16727v1"},"cats":{"benchmark":0.2874583636,"new-dataset":0.0067945462,"data-annotation":0.5173978756,"dev-research":0.3148298236,"llms":0.477238636,"data-quality":0.0711820106}}
{"text":"Existing risk management processes in related fields, such as software systems, need to sufficiently consider the specifics of AI.","meta":{"url":"http://arxiv.org/abs/2310.16727v1"},"cats":{"benchmark":0.2051216485,"new-dataset":0.0407650716,"data-annotation":0.5129743199,"dev-research":0.4368591019,"llms":0.4854458766,"data-quality":0.0931065876}}
{"text":"A key challenge is to systematically and transparently identify and address AI risks' root causes - also called AI hazards.","meta":{"url":"http://arxiv.org/abs/2310.16727v1"},"cats":{"benchmark":0.1882027515,"new-dataset":0.0807549609,"data-annotation":0.5330224726,"dev-research":0.3503217359,"llms":0.4309645422,"data-quality":0.19622694}}
{"text":"This paper introduces the AI Hazard Management (AIHM) framework, which provides a structured process to systematically identify, assess, and treat AI hazards.","meta":{"url":"http://arxiv.org/abs/2310.16727v1"},"cats":{"benchmark":0.228868082,"new-dataset":0.2239416701,"data-annotation":0.4938172172,"dev-research":0.3892543017,"llms":0.4630674439,"data-quality":0.1445909416}}
{"text":"The proposed process is conducted in parallel with the development to ensure that any AI hazard is captured at the earliest possible stage of the AI system's life cycle.","meta":{"url":"http://arxiv.org/abs/2310.16727v1"},"cats":{"benchmark":0.2408809303,"new-dataset":0.1368374981,"data-annotation":0.5021725997,"dev-research":0.3099158365,"llms":0.4742936663,"data-quality":0.0610776233}}
{"text":"In addition, to ensure the AI system's auditability, the proposed framework systematically documents evidence that the potential impact of identified AI hazards could be reduced to a tolerable level.","meta":{"url":"http://arxiv.org/abs/2310.16727v1"},"cats":{"benchmark":0.330389997,"new-dataset":0.0596139713,"data-annotation":0.5200619354,"dev-research":0.3359357735,"llms":0.4474613435,"data-quality":0.2488016906}}
{"text":"The framework builds upon an AI hazard list from a comprehensive state-of-the-art analysis.","meta":{"url":"http://arxiv.org/abs/2310.16727v1"},"cats":{"benchmark":0.3257581445,"new-dataset":0.315504747,"data-annotation":0.530399147,"dev-research":0.2379387748,"llms":0.3889641397,"data-quality":0.1270959062}}
{"text":"Also, we provide a taxonomy that supports the optimal treatment of the identified AI hazards.","meta":{"url":"http://arxiv.org/abs/2310.16727v1"},"cats":{"benchmark":0.3526772686,"new-dataset":0.119015857,"data-annotation":0.5261958909,"dev-research":0.2664775155,"llms":0.4106860184,"data-quality":0.1709193984}}
{"text":"Additionally, we illustrate how the AIHM framework can increase the overall quality of a power grid AI use case by systematically reducing the impact of identified hazards to an acceptable level.","meta":{"url":"http://arxiv.org/abs/2310.16727v1"},"cats":{"benchmark":0.3907532177,"new-dataset":0.0391145509,"data-annotation":0.4965295009,"dev-research":0.3376230409,"llms":0.4535118808,"data-quality":0.186617917}}
{"text":"Accurate measurement of the offset from roof-to-footprint in very-high-resolution remote sensing imagery is crucial for urban information extraction tasks.","meta":{"url":"http://arxiv.org/abs/2310.16717v1"},"cats":{"benchmark":0.4516272011,"new-dataset":0.0930739749,"data-annotation":0.4784961684,"dev-research":0.175089619,"llms":0.4310266401,"data-quality":0.1279723864}}
{"text":"With the help of deep learning, existing methods typically rely on two-stage CNN models to extract regions of interest on building feature maps.","meta":{"url":"http://arxiv.org/abs/2310.16717v1"},"cats":{"benchmark":0.2424719791,"new-dataset":0.1295242139,"data-annotation":0.5184478536,"dev-research":0.2377957591,"llms":0.438733572,"data-quality":0.1140573009}}
{"text":"At the first stage, a Region Proposal Network (RPN) is applied to extract thousands of ROIs (Region of Interests) which will post-imported into a Region-based Convolutional Neural Networks (RCNN) to extract wanted information.","meta":{"url":"http://arxiv.org/abs/2310.16717v1"},"cats":{"benchmark":0.2145079145,"new-dataset":0.2895100763,"data-annotation":0.5090178659,"dev-research":0.1503295236,"llms":0.4463291423,"data-quality":0.1295387246}}
{"text":"However, because of inflexible RPN, these methods often lack effective user interaction, encounter difficulties in instance correspondence, and struggle to keep up with the advancements in general artificial intelligence.","meta":{"url":"http://arxiv.org/abs/2310.16717v1"},"cats":{"benchmark":0.3117657907,"new-dataset":0.0061811849,"data-annotation":0.5307165762,"dev-research":0.2657965021,"llms":0.4867333812,"data-quality":0.1688181809}}
{"text":"This paper introduces an interactive Transformer model combined with a prompt encoder to precisely extract building segmentation as well as the offset vectors from roofs to footprints.","meta":{"url":"http://arxiv.org/abs/2310.16717v1"},"cats":{"benchmark":0.30003203,"new-dataset":0.096453656,"data-annotation":0.4923281658,"dev-research":0.2464749177,"llms":0.4355745512,"data-quality":0.0691203611}}
{"text":"In our model, a powerful module, namely ROAM, was tailored for common problems in predicting roof-to-footprint offsets.","meta":{"url":"http://arxiv.org/abs/2310.16717v1"},"cats":{"benchmark":0.3870596009,"new-dataset":0.0529559216,"data-annotation":0.5149726282,"dev-research":0.2369436382,"llms":0.4455617843,"data-quality":0.0593012006}}
{"text":"We tested our model's feasibility on the publicly available BONAI dataset, achieving a significant reduction in Prompt-Instance-Level offset errors ranging from 14.6% to 16.3%.","meta":{"url":"http://arxiv.org/abs/2310.16717v1"},"cats":{"benchmark":0.4105203979,"new-dataset":0.3155405655,"data-annotation":0.4974323113,"dev-research":0.1649246184,"llms":0.5306187304,"data-quality":0.2605061554}}
{"text":"Additionally, we developed a Distance-NMS algorithm tailored for large-scale building offsets, significantly enhancing the accuracy of predicted building offset angles and lengths in a straightforward and efficient manner.","meta":{"url":"http://arxiv.org/abs/2310.16717v1"},"cats":{"benchmark":0.6379359407,"new-dataset":0.0582182314,"data-annotation":0.5090353239,"dev-research":0.2606855763,"llms":0.431982759,"data-quality":0.0767835286}}
{"text":"To further validate the model's robustness, we created a new test set using 0.5m remote sensing imagery from Huizhou, China, for inference testing.","meta":{"url":"http://arxiv.org/abs/2310.16717v1"},"cats":{"benchmark":0.3858288083,"new-dataset":0.2048774905,"data-annotation":0.4999844879,"dev-research":0.1206646752,"llms":0.5202338812,"data-quality":0.1536359039}}
{"text":"Our code, training methods, and the updated dataset will be accessable at https://github.com/likaiucas.","meta":{"url":"http://arxiv.org/abs/2310.16717v1"},"cats":{"benchmark":0.2149575566,"new-dataset":0.8635140761,"data-annotation":0.5062168873,"dev-research":0.1682921767,"llms":0.5129700038,"data-quality":0.1464310972}}
{"text":"Large language models (LLMs) have shown great potential to solve varieties of natural language processing (NLP) tasks, including mathematical reasoning.","meta":{"url":"http://arxiv.org/abs/2310.16713v1"},"cats":{"benchmark":0.2455042052,"new-dataset":0.0676743831,"data-annotation":0.5453189911,"dev-research":0.1702327927,"llms":0.647024441,"data-quality":0.1380134122}}
{"text":"In this work, we present SkyMath, a large language model for mathematics with 13 billion parameters.","meta":{"url":"http://arxiv.org/abs/2310.16713v1"},"cats":{"benchmark":0.2387897288,"new-dataset":0.6279659604,"data-annotation":0.5533532551,"dev-research":0.1515428761,"llms":0.5240817468,"data-quality":0.0892627301}}
{"text":"By applying self-compare fine-tuning, we have enhanced mathematical reasoning abilities of Skywork-13B-Base remarkably.","meta":{"url":"http://arxiv.org/abs/2310.16713v1"},"cats":{"benchmark":0.4059435842,"new-dataset":0.0748157514,"data-annotation":0.5335843697,"dev-research":0.2334891895,"llms":0.573061495,"data-quality":0.1034469174}}
{"text":"On GSM8K, SkyMath outperforms all known open-source models of similar size and has established a new SOTA performance.","meta":{"url":"http://arxiv.org/abs/2310.16713v1"},"cats":{"benchmark":0.4258318174,"new-dataset":0.1060189467,"data-annotation":0.4963743883,"dev-research":0.1062631089,"llms":0.6056619715,"data-quality":0.0510171224}}
{"text":"Large language models (LLMs) have become an integral component in solving a wide range of NLP tasks.","meta":{"url":"http://arxiv.org/abs/2310.16712v1"},"cats":{"benchmark":0.2359161765,"new-dataset":0.0592076659,"data-annotation":0.5402671368,"dev-research":0.1526386349,"llms":0.6647866916,"data-quality":0.1580498407}}
{"text":"In this work, we explore a novel use case of using LLMs to build performance predictors (PP): models that, given a specific deep neural network architecture, predict its performance on a downstream task.","meta":{"url":"http://arxiv.org/abs/2310.16712v1"},"cats":{"benchmark":0.3653817266,"new-dataset":0.0251720397,"data-annotation":0.5016844638,"dev-research":0.1468479462,"llms":0.6520747531,"data-quality":0.0875744897}}
{"text":"We design PP prompts for LLMs consisting of: (i) role: description of the role assigned to the LLM, (ii) instructions: set of instructions to be followed by the LLM to carry out performance prediction, (iii) hyperparameters: a definition of each architecture-specific hyperparameter and (iv) demonstrations: sample architectures along with their efficiency metrics and 'training from scratch' performance.","meta":{"url":"http://arxiv.org/abs/2310.16712v1"},"cats":{"benchmark":0.3778848483,"new-dataset":0.0249239864,"data-annotation":0.5083400605,"dev-research":0.1369766146,"llms":0.6784114343,"data-quality":0.0636936498}}
{"text":"For machine translation (MT) tasks, we discover that GPT-4 with our PP prompts (LLM-PP) can predict the performance of architecture with a mean absolute error matching the SOTA and a marginal degradation in rank correlation coefficient compared to SOTA performance predictors.","meta":{"url":"http://arxiv.org/abs/2310.16712v1"},"cats":{"benchmark":0.4748959272,"new-dataset":0.0644103304,"data-annotation":0.5183143756,"dev-research":0.1842649682,"llms":0.5809026131,"data-quality":0.1840508536}}
{"text":"Further, we show that the predictions from LLM-PP can be distilled to a small regression model (LLM-Distill-PP).","meta":{"url":"http://arxiv.org/abs/2310.16712v1"},"cats":{"benchmark":0.3027163417,"new-dataset":0.0265241229,"data-annotation":0.5130104899,"dev-research":0.0962309957,"llms":0.5554302533,"data-quality":0.1201675291}}
{"text":"LLM-Distill-PP models surprisingly retain the performance of LLM-PP largely and can be a cost-effective alternative for heavy use cases of performance estimation.","meta":{"url":"http://arxiv.org/abs/2310.16712v1"},"cats":{"benchmark":0.5778749737,"new-dataset":0.0061553465,"data-annotation":0.4914686918,"dev-research":0.1186400258,"llms":0.6531803557,"data-quality":0.0804774553}}
{"text":"Specifically, for neural architecture search (NAS), we propose a Hybrid-Search algorithm for NAS (HS-NAS), which uses LLM-Distill-PP for the initial part of search, resorting to the baseline predictor for rest of the search.","meta":{"url":"http://arxiv.org/abs/2310.16712v1"},"cats":{"benchmark":0.4002390032,"new-dataset":0.0321144353,"data-annotation":0.513971009,"dev-research":0.0762276259,"llms":0.5465676408,"data-quality":0.0718256869}}
{"text":"We show that HS-NAS performs very similar to SOTA NAS across benchmarks, reduces search hours by 50% roughly, and in some cases, improves latency, GFLOPs, and model size.","meta":{"url":"http://arxiv.org/abs/2310.16712v1"},"cats":{"benchmark":0.5110355799,"new-dataset":0.0861600557,"data-annotation":0.4871879242,"dev-research":0.1290668671,"llms":0.615071991,"data-quality":0.0693542095}}
{"text":"This paper aims to enhance the ability to predict nighttime driving behavior by identifying taillights of both human-driven and autonomous vehicles.","meta":{"url":"http://arxiv.org/abs/2310.16706v1"},"cats":{"benchmark":0.3113308345,"new-dataset":0.1038810473,"data-annotation":0.5368335463,"dev-research":0.2145580555,"llms":0.4003908922,"data-quality":0.1124870487}}
{"text":"The proposed model incorporates a customized detector designed to accurately detect front-vehicle taillights on the road.","meta":{"url":"http://arxiv.org/abs/2310.16706v1"},"cats":{"benchmark":0.320092086,"new-dataset":0.0405287062,"data-annotation":0.5313502747,"dev-research":0.1907103152,"llms":0.4513966017,"data-quality":0.1485836875}}
{"text":"At the beginning of the detector, a learnable pre-processing block is implemented, which extracts deep features from input images and calculates the data rarity for each feature.","meta":{"url":"http://arxiv.org/abs/2310.16706v1"},"cats":{"benchmark":0.2524073805,"new-dataset":0.315782091,"data-annotation":0.5263356261,"dev-research":0.1695246447,"llms":0.4822313503,"data-quality":0.1662151706}}
{"text":"In the next step, drawing inspiration from soft attention, a weighted binary mask is designed that guides the model to focus more on predetermined regions.","meta":{"url":"http://arxiv.org/abs/2310.16706v1"},"cats":{"benchmark":0.2684831319,"new-dataset":0.0106023021,"data-annotation":0.5268486664,"dev-research":0.1827983677,"llms":0.4175745244,"data-quality":0.0765963168}}
{"text":"This research utilizes Convolutional Neural Networks (CNNs) to extract distinguishing characteristics from these areas, then reduces dimensions using Principal Component Analysis (PCA).","meta":{"url":"http://arxiv.org/abs/2310.16706v1"},"cats":{"benchmark":0.3222297515,"new-dataset":0.1056161332,"data-annotation":0.5146801006,"dev-research":0.1724879238,"llms":0.3974607951,"data-quality":0.0988788431}}
{"text":"Finally, the Support Vector Machine (SVM) is used to predict the behavior of the vehicles.","meta":{"url":"http://arxiv.org/abs/2310.16706v1"},"cats":{"benchmark":0.3004433499,"new-dataset":0.0706902413,"data-annotation":0.5308138053,"dev-research":0.2336787082,"llms":0.4222413316,"data-quality":0.1295391419}}
{"text":"To train and evaluate the model, a large-scale dataset is collected from two types of dash-cams and Insta360 cameras from the rear view of Ford Motor Company vehicles.","meta":{"url":"http://arxiv.org/abs/2310.16706v1"},"cats":{"benchmark":0.2182136853,"new-dataset":0.8870777029,"data-annotation":0.4905981786,"dev-research":0.1789639523,"llms":0.4479034945,"data-quality":0.0938749271}}
{"text":"This dataset includes over 12k frames captured during both daytime and nighttime hours.","meta":{"url":"http://arxiv.org/abs/2310.16706v1"},"cats":{"benchmark":0.2594940733,"new-dataset":0.9504614907,"data-annotation":0.4791595002,"dev-research":0.1330182705,"llms":0.4473656609,"data-quality":0.0843154207}}
{"text":"To address the limited nighttime data, a unique pixel-wise image processing technique is implemented to convert daytime images into realistic night images.","meta":{"url":"http://arxiv.org/abs/2310.16706v1"},"cats":{"benchmark":0.3554661002,"new-dataset":0.1348372408,"data-annotation":0.4778819904,"dev-research":0.1725413859,"llms":0.4259843055,"data-quality":0.0847471493}}
{"text":"The findings from the experiments demonstrate that the proposed methodology can accurately categorize vehicle behavior with 92.14% accuracy, 97.38% specificity, 92.09% sensitivity, 92.10% F1-measure, and 0.895 Cohen's Kappa Statistic.","meta":{"url":"http://arxiv.org/abs/2310.16706v1"},"cats":{"benchmark":0.5000715071,"new-dataset":0.0258201041,"data-annotation":0.5231345025,"dev-research":0.195657946,"llms":0.4538832021,"data-quality":0.2216883348}}
{"text":"Further details are available at https://github.com/DeepCar/Taillight_Recognition.","meta":{"url":"http://arxiv.org/abs/2310.16706v1"},"cats":{"benchmark":0.2762644317,"new-dataset":0.1167067107,"data-annotation":0.5360759805,"dev-research":0.1503369469,"llms":0.5159688658,"data-quality":0.1230743671}}
{"text":"Variational inference (VI) can be cast as an optimization problem in which the variational parameters are tuned to closely align a variational distribution with the true posterior.","meta":{"url":"http://arxiv.org/abs/2310.16705v1"},"cats":{"benchmark":0.4131035968,"new-dataset":0.0035782736,"data-annotation":0.5266628183,"dev-research":0.1331153221,"llms":0.4353117197,"data-quality":0.1078796997}}
{"text":"The optimization task can be approached through vanilla gradient descent in black-box VI or natural-gradient descent in natural-gradient VI.","meta":{"url":"http://arxiv.org/abs/2310.16705v1"},"cats":{"benchmark":0.4136691588,"new-dataset":0.0062434853,"data-annotation":0.5247644138,"dev-research":0.1598784473,"llms":0.3966001177,"data-quality":0.0992292154}}
{"text":"In this work, we reframe VI as the optimization of an objective that concerns probability distributions defined over a \\textit{variational parameter space}.","meta":{"url":"http://arxiv.org/abs/2310.16705v1"},"cats":{"benchmark":0.4452872598,"new-dataset":0.0276988229,"data-annotation":0.5385706705,"dev-research":0.1348519816,"llms":0.40834094,"data-quality":0.120405753}}
{"text":"Subsequently, we propose Wasserstein gradient descent for tackling this optimization problem.","meta":{"url":"http://arxiv.org/abs/2310.16705v1"},"cats":{"benchmark":0.5835315662,"new-dataset":0.0405594291,"data-annotation":0.5380316794,"dev-research":0.1098271239,"llms":0.3199009863,"data-quality":0.1631971515}}
{"text":"Notably, the optimization techniques, namely black-box VI and natural-gradient VI, can be reinterpreted as specific instances of the proposed Wasserstein gradient descent.","meta":{"url":"http://arxiv.org/abs/2310.16705v1"},"cats":{"benchmark":0.4938557192,"new-dataset":0.0055397989,"data-annotation":0.5281701095,"dev-research":0.1240160017,"llms":0.3621780171,"data-quality":0.0916760152}}
{"text":"To enhance the efficiency of optimization, we develop practical methods for numerically solving the discrete gradient flows.","meta":{"url":"http://arxiv.org/abs/2310.16705v1"},"cats":{"benchmark":0.5638758679,"new-dataset":0.0041503174,"data-annotation":0.5126021045,"dev-research":0.13739919,"llms":0.37635376,"data-quality":0.0637299778}}
{"text":"We validate the effectiveness of the proposed methods through empirical experiments on a synthetic dataset, supplemented by theoretical analyses.","meta":{"url":"http://arxiv.org/abs/2310.16705v1"},"cats":{"benchmark":0.64683319,"new-dataset":0.0390040571,"data-annotation":0.5080080962,"dev-research":0.2198675853,"llms":0.3643646462,"data-quality":0.1805539714}}
{"text":"We propose a human-centred explanation method for rule-based automated decision-making systems in the legal domain.","meta":{"url":"http://arxiv.org/abs/2310.16704v1"},"cats":{"benchmark":0.2613662272,"new-dataset":0.1621399034,"data-annotation":0.5109743957,"dev-research":0.4856391361,"llms":0.5196756545,"data-quality":0.2424266035}}
{"text":"Firstly, we establish a conceptual framework for developing explanation methods, representing its key internal components (content, communication and adaptation) and external dependencies (decision-making system, human recipient and domain).","meta":{"url":"http://arxiv.org/abs/2310.16704v1"},"cats":{"benchmark":0.1406679019,"new-dataset":0.0720415561,"data-annotation":0.5234702561,"dev-research":0.524135092,"llms":0.5334520207,"data-quality":0.1846049024}}
{"text":"Secondly, we propose an explanation method that uses a graph database to enable question-driven explanations and multimedia display.","meta":{"url":"http://arxiv.org/abs/2310.16704v1"},"cats":{"benchmark":0.1837253273,"new-dataset":0.249596498,"data-annotation":0.5433663542,"dev-research":0.4062041478,"llms":0.4999017055,"data-quality":0.2129969746}}
{"text":"This way, we can tailor the explanation to the user.","meta":{"url":"http://arxiv.org/abs/2310.16704v1"},"cats":{"benchmark":0.1964989427,"new-dataset":0.0114490549,"data-annotation":0.552401052,"dev-research":0.4028510233,"llms":0.5106902631,"data-quality":0.174664898}}
{"text":"Finally, we show how our conceptual framework is applicable to a real-world scenario at the Dutch Tax and Customs Administration and implement our explanation method for this scenario.","meta":{"url":"http://arxiv.org/abs/2310.16704v1"},"cats":{"benchmark":0.2743255647,"new-dataset":0.1771896486,"data-annotation":0.497890729,"dev-research":0.2951781905,"llms":0.4698254979,"data-quality":0.1740236303}}
{"text":"What should a data integration framework for knowledge engineers look like?","meta":{"url":"http://arxiv.org/abs/2310.16700v1"},"cats":{"benchmark":0.2158733224,"new-dataset":0.3840071601,"data-annotation":0.4273097281,"dev-research":0.3186840991,"llms":0.5616865359,"data-quality":0.1065614742}}
{"text":"Recent research on Knowledge Graph construction proposes the design of a fa\\c{c}ade, a notion borrowed from object-oriented software engineering.","meta":{"url":"http://arxiv.org/abs/2310.16700v1"},"cats":{"benchmark":0.2293910429,"new-dataset":0.1175662725,"data-annotation":0.4981268006,"dev-research":0.4591854025,"llms":0.5618000753,"data-quality":0.1254239357}}
{"text":"This idea is applied to SPARQL Anything, a system that allows querying heterogeneous resources as-if they were in RDF, in plain SPARQL 1.1, by overloading the SERVICE clause.","meta":{"url":"http://arxiv.org/abs/2310.16700v1"},"cats":{"benchmark":0.2736152027,"new-dataset":0.0383554656,"data-annotation":0.4941170121,"dev-research":0.132181566,"llms":0.6029263897,"data-quality":0.1420145196}}
{"text":"SPARQL Anything supports a wide variety of file formats, from popular ones (CSV, JSON, XML, Spreadsheets) to others that are not supported by alternative solutions (Markdown, YAML, DOCx, Bibtex).","meta":{"url":"http://arxiv.org/abs/2310.16700v1"},"cats":{"benchmark":0.3497574506,"new-dataset":0.2666553219,"data-annotation":0.4747072864,"dev-research":0.2156506631,"llms":0.5878495934,"data-quality":0.1299557237}}
{"text":"Features include querying Web APIs with high flexibility, parametrised queries, and chaining multiple transformations into complex pipelines.","meta":{"url":"http://arxiv.org/abs/2310.16700v1"},"cats":{"benchmark":0.3034998995,"new-dataset":0.0279717203,"data-annotation":0.4505521562,"dev-research":0.2518715036,"llms":0.5342662915,"data-quality":0.0575975169}}
{"text":"In this paper, we describe the design rationale and software architecture of the SPARQL Anything system.","meta":{"url":"http://arxiv.org/abs/2310.16700v1"},"cats":{"benchmark":0.3148562667,"new-dataset":0.0569906774,"data-annotation":0.4785964399,"dev-research":0.2029709369,"llms":0.6985433758,"data-quality":0.0947879207}}
{"text":"We provide references to an extensive set of reusable, real-world scenarios from various application domains.","meta":{"url":"http://arxiv.org/abs/2310.16700v1"},"cats":{"benchmark":0.3158085788,"new-dataset":0.182055175,"data-annotation":0.4877486094,"dev-research":0.3603965378,"llms":0.5614394891,"data-quality":0.0823064016}}
{"text":"We report on the value-to-users of the founding assumptions of its design, compared to alternative solutions through a community survey and a field report from the industry.","meta":{"url":"http://arxiv.org/abs/2310.16700v1"},"cats":{"benchmark":0.3261602349,"new-dataset":0.0462241237,"data-annotation":0.4950865366,"dev-research":0.3646884193,"llms":0.5178656685,"data-quality":0.0944261823}}
{"text":"We study a fundamental online scheduling problem where jobs with processing times, weights, and deadlines arrive online over time at their release dates.","meta":{"url":"http://arxiv.org/abs/2310.16697v1"},"cats":{"benchmark":0.3727168736,"new-dataset":0.0756410775,"data-annotation":0.5136170024,"dev-research":0.1943826924,"llms":0.4147485367,"data-quality":0.1004066384}}
{"text":"The task is to preemptively schedule these jobs on a single or multiple (possibly unrelated) machines with the objective to maximize the weighted throughput, the total weight of jobs that complete before their deadline.","meta":{"url":"http://arxiv.org/abs/2310.16697v1"},"cats":{"benchmark":0.4199525223,"new-dataset":0.0099938848,"data-annotation":0.5012039625,"dev-research":0.1462911713,"llms":0.471391727,"data-quality":0.0618810433}}
{"text":"To overcome known lower bounds for the competitive analysis, we assume that each job arrives with some slack $\\varepsilon > 0$; that is, the time window for processing job $j$ on any machine $i$ on which it can be executed has length at least $(1+\\varepsilon)$ times $j$'s processing time on machine $i$. Our contribution is a best possible online algorithm for weighted throughput maximization on unrelated machines: Our algorithm is $O\\big(\\frac1\\varepsilon\\big)$-competitive, which matches the lower bound for unweighted throughput maximization on a single machine.","meta":{"url":"http://arxiv.org/abs/2310.16697v1"},"cats":{"benchmark":0.5727715203,"new-dataset":0.0241958509,"data-annotation":0.5242918503,"dev-research":0.1081452576,"llms":0.4301377787,"data-quality":0.0598462663}}
{"text":"Even for a single machine, it was not known whether the problem with weighted jobs is \"harder\" than the problem with unweighted jobs.","meta":{"url":"http://arxiv.org/abs/2310.16697v1"},"cats":{"benchmark":0.5015650219,"new-dataset":0.0009407749,"data-annotation":0.5125135362,"dev-research":0.1380536031,"llms":0.4526980147,"data-quality":0.1613576682}}
{"text":"Thus, we answer this question and close weighted throughput maximization on a single machine with a best possible competitive ratio $\\Theta\\big(\\frac1\\varepsilon\\big)$. While we focus on non-migratory schedules, our algorithm achieves the same (up to constants) performance guarantee when compared to an optimal migratory schedule.","meta":{"url":"http://arxiv.org/abs/2310.16697v1"},"cats":{"benchmark":0.5696946263,"new-dataset":0.0169715713,"data-annotation":0.5146517615,"dev-research":0.0871537874,"llms":0.4400871239,"data-quality":0.0654674769}}
{"text":"Deep learning has made significant advances in creating efficient representations of time series data by automatically identifying complex patterns.","meta":{"url":"http://arxiv.org/abs/2310.16696v1"},"cats":{"benchmark":0.2809026892,"new-dataset":0.1575840258,"data-annotation":0.5092755845,"dev-research":0.2019791335,"llms":0.4297913601,"data-quality":0.0888859919}}
{"text":"However, these approaches lack interpretability, as the time series is transformed into a latent vector that is not easily interpretable.","meta":{"url":"http://arxiv.org/abs/2310.16696v1"},"cats":{"benchmark":0.3153456467,"new-dataset":0.0040542933,"data-annotation":0.5263535092,"dev-research":0.1977371108,"llms":0.4383175788,"data-quality":0.1702747594}}
{"text":"On the other hand, Symbolic Aggregate approximation (SAX) methods allow the creation of symbolic representations that can be interpreted but do not capture complex patterns effectively.","meta":{"url":"http://arxiv.org/abs/2310.16696v1"},"cats":{"benchmark":0.4440366635,"new-dataset":0.0041643303,"data-annotation":0.5091451989,"dev-research":0.2519155855,"llms":0.5031710812,"data-quality":0.1365077576}}
{"text":"In this work, we propose a set of requirements for a neural representation of univariate time series to be interpretable.","meta":{"url":"http://arxiv.org/abs/2310.16696v1"},"cats":{"benchmark":0.2480445911,"new-dataset":0.0861345561,"data-annotation":0.5221924176,"dev-research":0.1399253105,"llms":0.4107191521,"data-quality":0.1117698952}}
{"text":"We propose a new unsupervised neural architecture that meets these requirements.","meta":{"url":"http://arxiv.org/abs/2310.16696v1"},"cats":{"benchmark":0.2700793385,"new-dataset":0.192272747,"data-annotation":0.518795519,"dev-research":0.1119013076,"llms":0.4763955324,"data-quality":0.1272067976}}
{"text":"The proposed model produces consistent, discrete, interpretable, and visualizable representations.","meta":{"url":"http://arxiv.org/abs/2310.16696v1"},"cats":{"benchmark":0.2027136771,"new-dataset":0.0729632769,"data-annotation":0.4822661274,"dev-research":0.1789980843,"llms":0.4382532669,"data-quality":0.1031413059}}
{"text":"The model is learned independently of any downstream tasks in an unsupervised setting to ensure robustness.","meta":{"url":"http://arxiv.org/abs/2310.16696v1"},"cats":{"benchmark":0.2410163247,"new-dataset":0.0177774533,"data-annotation":0.4984114914,"dev-research":0.2025083444,"llms":0.4339216513,"data-quality":0.1472734104}}
{"text":"As a demonstration of the effectiveness of the proposed model, we propose experiments on classification tasks using UCR archive datasets.","meta":{"url":"http://arxiv.org/abs/2310.16696v1"},"cats":{"benchmark":0.4600856165,"new-dataset":0.1710663459,"data-annotation":0.5249841173,"dev-research":0.1373944663,"llms":0.4776634317,"data-quality":0.2957959304}}
{"text":"The obtained results are extensively compared to other interpretable models and state-of-the-art neural representation learning models.","meta":{"url":"http://arxiv.org/abs/2310.16696v1"},"cats":{"benchmark":0.2858070746,"new-dataset":0.0370027031,"data-annotation":0.5394157369,"dev-research":0.144332968,"llms":0.4627690588,"data-quality":0.2162473509}}
{"text":"The experiments show that the proposed model yields, on average better results than other interpretable approaches on multiple datasets.","meta":{"url":"http://arxiv.org/abs/2310.16696v1"},"cats":{"benchmark":0.4545067347,"new-dataset":0.0834693882,"data-annotation":0.5031838717,"dev-research":0.1722505767,"llms":0.3736608943,"data-quality":0.2075816618}}
{"text":"We also present qualitative experiments to asses the interpretability of the approach.","meta":{"url":"http://arxiv.org/abs/2310.16696v1"},"cats":{"benchmark":0.3083408346,"new-dataset":0.0090594968,"data-annotation":0.5174250814,"dev-research":0.3158347556,"llms":0.4860405268,"data-quality":0.1743020987}}
{"text":"Traditional initialisation methods, e.g. He and Xavier, have been effective in avoiding the problem of vanishing or exploding gradients in neural networks.","meta":{"url":"http://arxiv.org/abs/2310.16695v1"},"cats":{"benchmark":0.3135771825,"new-dataset":0.0068595863,"data-annotation":0.5439961536,"dev-research":0.1632830735,"llms":0.4534155038,"data-quality":0.1163176761}}
{"text":"However, they only use simple pointwise distributions, which model one-dimensional variables.","meta":{"url":"http://arxiv.org/abs/2310.16695v1"},"cats":{"benchmark":0.2606819018,"new-dataset":0.010771196,"data-annotation":0.5109466218,"dev-research":0.1143853278,"llms":0.3879449821,"data-quality":0.0906066394}}
{"text":"Moreover, they ignore most information about the architecture and disregard past training experiences.","meta":{"url":"http://arxiv.org/abs/2310.16695v1"},"cats":{"benchmark":0.2441773711,"new-dataset":0.0058693017,"data-annotation":0.502861547,"dev-research":0.2325114295,"llms":0.5712553789,"data-quality":0.1888778862}}
{"text":"These limitations can be overcome by employing generative models for initialisation.","meta":{"url":"http://arxiv.org/abs/2310.16695v1"},"cats":{"benchmark":0.25135724,"new-dataset":0.0203167345,"data-annotation":0.5140931351,"dev-research":0.1574287329,"llms":0.5187630358,"data-quality":0.0813724746}}
{"text":"In this paper, we introduce two groups of new initialisation methods.","meta":{"url":"http://arxiv.org/abs/2310.16695v1"},"cats":{"benchmark":0.4704644381,"new-dataset":0.0308823749,"data-annotation":0.5314183009,"dev-research":0.1723136312,"llms":0.4781251017,"data-quality":0.1075112784}}
{"text":"First, we locally initialise weight groups by employing variational autoencoders.","meta":{"url":"http://arxiv.org/abs/2310.16695v1"},"cats":{"benchmark":0.3033866268,"new-dataset":0.0499715757,"data-annotation":0.537499053,"dev-research":0.0918852615,"llms":0.4424435216,"data-quality":0.1542549083}}
{"text":"Secondly, we globally initialise full weight sets by employing graph hypernetworks.","meta":{"url":"http://arxiv.org/abs/2310.16695v1"},"cats":{"benchmark":0.3448066215,"new-dataset":0.0987471089,"data-annotation":0.5242711155,"dev-research":0.1422194108,"llms":0.4817544663,"data-quality":0.1518047433}}
{"text":"We thoroughly evaluate the impact of the employed generative models on state-of-the-art neural networks in terms of accuracy, convergence speed and ensembling.","meta":{"url":"http://arxiv.org/abs/2310.16695v1"},"cats":{"benchmark":0.4445351221,"new-dataset":0.0214247673,"data-annotation":0.5370066975,"dev-research":0.1618575199,"llms":0.4984550181,"data-quality":0.1015509331}}
{"text":"Our results show that global initialisations result in higher accuracy and faster initial convergence speed.","meta":{"url":"http://arxiv.org/abs/2310.16695v1"},"cats":{"benchmark":0.6150348443,"new-dataset":0.0219881551,"data-annotation":0.5196817387,"dev-research":0.1650422823,"llms":0.5276192657,"data-quality":0.1050344044}}
{"text":"However, the implementation through graph hypernetworks leads to diminished ensemble performance on out of distribution data.","meta":{"url":"http://arxiv.org/abs/2310.16695v1"},"cats":{"benchmark":0.4874554154,"new-dataset":0.0287055676,"data-annotation":0.521507232,"dev-research":0.1833777764,"llms":0.4695549561,"data-quality":0.2216811664}}
{"text":"To counteract, we propose a modification called noise graph hypernetwork, which encourages diversity in the produced ensemble members.","meta":{"url":"http://arxiv.org/abs/2310.16695v1"},"cats":{"benchmark":0.3430343861,"new-dataset":0.0881147913,"data-annotation":0.5328065531,"dev-research":0.2149749465,"llms":0.4858727334,"data-quality":0.2716981499}}
{"text":"Furthermore, our approach might be able to transfer learned knowledge to different image distributions.","meta":{"url":"http://arxiv.org/abs/2310.16695v1"},"cats":{"benchmark":0.2139411615,"new-dataset":0.0607008515,"data-annotation":0.5150435748,"dev-research":0.1264266089,"llms":0.4842248826,"data-quality":0.1517168252}}
{"text":"Our work provides insights into the potential, the trade-offs and possible modifications of these new initialisation methods.","meta":{"url":"http://arxiv.org/abs/2310.16695v1"},"cats":{"benchmark":0.4853437139,"new-dataset":0.0109131646,"data-annotation":0.5127174934,"dev-research":0.1872356612,"llms":0.4921910975,"data-quality":0.0864255057}}
{"text":"In recent years, vehicle re-identification (Re-ID) has gained increasing importance in various applications such as assisted driving systems, traffic flow management, and vehicle tracking, due to the growth of intelligent transportation systems.","meta":{"url":"http://arxiv.org/abs/2310.16694v1"},"cats":{"benchmark":0.3414005069,"new-dataset":0.0381064755,"data-annotation":0.4840969016,"dev-research":0.2169690657,"llms":0.4694992037,"data-quality":0.1796218912}}
{"text":"However, the presence of extraneous background information and occlusions can interfere with the learning of discriminative features, leading to significant variations in the same vehicle image across different scenarios.","meta":{"url":"http://arxiv.org/abs/2310.16694v1"},"cats":{"benchmark":0.2232273018,"new-dataset":0.022002106,"data-annotation":0.5130247835,"dev-research":0.1921813951,"llms":0.4107556308,"data-quality":0.192412124}}
{"text":"This paper proposes a method, named graph network based on dynamic similarity adjacency matrices (DSAM-GN), which incorporates a novel approach for constructing adjacency matrices to capture spatial relationships of local features and reduce background noise.","meta":{"url":"http://arxiv.org/abs/2310.16694v1"},"cats":{"benchmark":0.3043221589,"new-dataset":0.125349647,"data-annotation":0.4924438712,"dev-research":0.2587342844,"llms":0.4773168965,"data-quality":0.1678964734}}
{"text":"Specifically, the proposed method divides the extracted vehicle features into different patches as nodes within the graph network.","meta":{"url":"http://arxiv.org/abs/2310.16694v1"},"cats":{"benchmark":0.3246395548,"new-dataset":0.0305044829,"data-annotation":0.4929473885,"dev-research":0.2218521938,"llms":0.3926689435,"data-quality":0.1576960868}}
{"text":"A spatial attention-based similarity adjacency matrix generation (SASAMG) module is employed to compute similarity matrices of nodes, and a dynamic erasure operation is applied to disconnect nodes with low similarity, resulting in similarity adjacency matrices.","meta":{"url":"http://arxiv.org/abs/2310.16694v1"},"cats":{"benchmark":0.3136443957,"new-dataset":0.0777547548,"data-annotation":0.5050056457,"dev-research":0.1807940118,"llms":0.5936917535,"data-quality":0.1174853298}}
{"text":"Finally, the nodes and similarity adjacency matrices are fed into graph networks to extract more discriminative features for vehicle Re-ID.","meta":{"url":"http://arxiv.org/abs/2310.16694v1"},"cats":{"benchmark":0.3091533312,"new-dataset":0.1537695352,"data-annotation":0.5085801342,"dev-research":0.1899477159,"llms":0.416901066,"data-quality":0.1948081018}}
{"text":"Experimental results on public datasets VeRi-776 and VehicleID demonstrate the effectiveness of the proposed method compared with recent works.","meta":{"url":"http://arxiv.org/abs/2310.16694v1"},"cats":{"benchmark":0.491598119,"new-dataset":0.1758177191,"data-annotation":0.4943730918,"dev-research":0.1266604027,"llms":0.457285934,"data-quality":0.1615206985}}
{"text":"In the Fourth Industrial Revolution, wherein artificial intelligence and the automation of machines occupy a central role, the deployment of robots is indispensable.","meta":{"url":"http://arxiv.org/abs/2310.16688v1"},"cats":{"benchmark":0.1764704317,"new-dataset":0.0442003078,"data-annotation":0.5125822712,"dev-research":0.2278935411,"llms":0.5072110609,"data-quality":0.1066225906}}
{"text":"However, the manufacturing process using robots, especially in collaboration with humans, is highly intricate.","meta":{"url":"http://arxiv.org/abs/2310.16688v1"},"cats":{"benchmark":0.1805107715,"new-dataset":0.0288830216,"data-annotation":0.5094103528,"dev-research":0.3269146199,"llms":0.5389132161,"data-quality":0.072157872}}
{"text":"In particular, modeling the friction torque in robotic joints is a longstanding problem due to the lack of a good mathematical description.","meta":{"url":"http://arxiv.org/abs/2310.16688v1"},"cats":{"benchmark":0.3034309754,"new-dataset":0.0254293313,"data-annotation":0.5315009428,"dev-research":0.2607503403,"llms":0.4521614305,"data-quality":0.0718084503}}
{"text":"This motivates the usage of data-driven methods in recent works.","meta":{"url":"http://arxiv.org/abs/2310.16688v1"},"cats":{"benchmark":0.3540965401,"new-dataset":0.0105018945,"data-annotation":0.4811895058,"dev-research":0.3905001558,"llms":0.4762710001,"data-quality":0.1038303361}}
{"text":"However, model-based and data-driven models often exhibit limitations in their ability to generalize beyond the specific dynamics they were trained on, as we demonstrate in this paper.","meta":{"url":"http://arxiv.org/abs/2310.16688v1"},"cats":{"benchmark":0.2146192101,"new-dataset":0.0184576208,"data-annotation":0.483150485,"dev-research":0.19749208,"llms":0.3989544988,"data-quality":0.0812224318}}
{"text":"To address this challenge, we introduce a novel approach based on residual learning, which aims to adapt an existing friction model to new dynamics using as little data as possible.","meta":{"url":"http://arxiv.org/abs/2310.16688v1"},"cats":{"benchmark":0.3311195277,"new-dataset":0.4185464224,"data-annotation":0.52429618,"dev-research":0.1787795857,"llms":0.3316935273,"data-quality":0.1206962044}}
{"text":"We validate our approach by training a base neural network on a symmetric friction data set to learn an accurate relation between the velocity and the friction torque.","meta":{"url":"http://arxiv.org/abs/2310.16688v1"},"cats":{"benchmark":0.3886443795,"new-dataset":0.2882762424,"data-annotation":0.5220880997,"dev-research":0.18055505,"llms":0.4461630578,"data-quality":0.1150143632}}
{"text":"Subsequently, to adapt to more complex asymmetric settings, we train a second network on a small dataset, focusing on predicting the residual of the initial network's output.","meta":{"url":"http://arxiv.org/abs/2310.16688v1"},"cats":{"benchmark":0.3860083788,"new-dataset":0.0343801259,"data-annotation":0.5196341552,"dev-research":0.1542599968,"llms":0.3135730956,"data-quality":0.1633726721}}
{"text":"By combining the output of both networks in a suitable manner, our proposed estimator outperforms the conventional model-based approach and the base neural network significantly.","meta":{"url":"http://arxiv.org/abs/2310.16688v1"},"cats":{"benchmark":0.5757541322,"new-dataset":0.0071498849,"data-annotation":0.5236640207,"dev-research":0.1260086152,"llms":0.3256673799,"data-quality":0.1712902776}}
{"text":"Furthermore, we evaluate our method on trajectories involving external loads and still observe a substantial improvement, approximately 60-70\\%, over the conventional approach.","meta":{"url":"http://arxiv.org/abs/2310.16688v1"},"cats":{"benchmark":0.6968023118,"new-dataset":0.0101682153,"data-annotation":0.5073180622,"dev-research":0.1371366386,"llms":0.3718728794,"data-quality":0.0484225638}}
{"text":"Our method does not rely on data with external load during training, eliminating the need for external torque sensors.","meta":{"url":"http://arxiv.org/abs/2310.16688v1"},"cats":{"benchmark":0.3497447562,"new-dataset":0.01010219,"data-annotation":0.4915403519,"dev-research":0.1387631397,"llms":0.5179181514,"data-quality":0.1481828184}}
{"text":"This demonstrates the generalization capability of our approach, even with a small amount of data-only 43 seconds of a robot movement-enabling adaptation to diverse scenarios based on prior knowledge about friction in different settings.","meta":{"url":"http://arxiv.org/abs/2310.16688v1"},"cats":{"benchmark":0.3188267054,"new-dataset":0.1729041527,"data-annotation":0.4931574018,"dev-research":0.2235729289,"llms":0.4567709654,"data-quality":0.0417116571}}
{"text":"While reinforcement learning has achieved remarkable successes in several domains, its real-world application is limited due to many methods failing to generalise to unfamiliar conditions.","meta":{"url":"http://arxiv.org/abs/2310.16686v1"},"cats":{"benchmark":0.2399007288,"new-dataset":0.0047562371,"data-annotation":0.5294292533,"dev-research":0.1912521007,"llms":0.4376201562,"data-quality":0.1276005278}}
{"text":"In this work, we consider the problem of generalising to new transition dynamics, corresponding to cases in which the environment's response to the agent's actions differs.","meta":{"url":"http://arxiv.org/abs/2310.16686v1"},"cats":{"benchmark":0.2090854517,"new-dataset":0.078377129,"data-annotation":0.5144225832,"dev-research":0.1596962522,"llms":0.4713672699,"data-quality":0.0671426085}}
{"text":"For example, the gravitational force exerted on a robot depends on its mass and changes the robot's mobility.","meta":{"url":"http://arxiv.org/abs/2310.16686v1"},"cats":{"benchmark":0.2643395779,"new-dataset":0.0054916127,"data-annotation":0.5059231863,"dev-research":0.2101097142,"llms":0.4669129097,"data-quality":0.0699774216}}
{"text":"Consequently, in such cases, it is necessary to condition an agent's actions on extrinsic state information and pertinent contextual information reflecting how the environment responds.","meta":{"url":"http://arxiv.org/abs/2310.16686v1"},"cats":{"benchmark":0.1714067527,"new-dataset":0.0267787495,"data-annotation":0.4953542374,"dev-research":0.2344576128,"llms":0.5476803566,"data-quality":0.0840157232}}
{"text":"While the need for context-sensitive policies has been established, the manner in which context is incorporated architecturally has received less attention.","meta":{"url":"http://arxiv.org/abs/2310.16686v1"},"cats":{"benchmark":0.2500783755,"new-dataset":0.0068755983,"data-annotation":0.4912500752,"dev-research":0.3295746589,"llms":0.5968198981,"data-quality":0.1321049927}}
{"text":"Thus, in this work, we present an investigation into how context information should be incorporated into behaviour learning to improve generalisation.","meta":{"url":"http://arxiv.org/abs/2310.16686v1"},"cats":{"benchmark":0.152276289,"new-dataset":0.0468390608,"data-annotation":0.5266824275,"dev-research":0.2529107119,"llms":0.5227400941,"data-quality":0.1440217804}}
{"text":"To this end, we introduce a neural network architecture, the Decision Adapter, which generates the weights of an adapter module and conditions the behaviour of an agent on the context information.","meta":{"url":"http://arxiv.org/abs/2310.16686v1"},"cats":{"benchmark":0.1852484282,"new-dataset":0.0649239089,"data-annotation":0.5151231949,"dev-research":0.1552238818,"llms":0.5092131719,"data-quality":0.095123913}}
{"text":"We show that the Decision Adapter is a useful generalisation of a previously proposed architecture and empirically demonstrate that it results in superior generalisation performance compared to previous approaches in several environments.","meta":{"url":"http://arxiv.org/abs/2310.16686v1"},"cats":{"benchmark":0.5190437945,"new-dataset":0.0049408139,"data-annotation":0.4951540793,"dev-research":0.2437895208,"llms":0.4727723841,"data-quality":0.0944054399}}
{"text":"Beyond this, the Decision Adapter is more robust to irrelevant distractor variables than several alternative methods.","meta":{"url":"http://arxiv.org/abs/2310.16686v1"},"cats":{"benchmark":0.4433605453,"new-dataset":0.0028351478,"data-annotation":0.5203136097,"dev-research":0.2424805785,"llms":0.4465454787,"data-quality":0.131646884}}
{"text":"The large language based-model chatbot ChatGPT gained a lot of popularity since its launch and has been used in a wide range of situations.","meta":{"url":"http://arxiv.org/abs/2310.16685v1"},"cats":{"benchmark":0.1907358878,"new-dataset":0.3179124057,"data-annotation":0.5242573196,"dev-research":0.2904492416,"llms":0.5887016931,"data-quality":0.1014522583}}
{"text":"This research centers around a particular situation, when the ChatGPT is used to produce news that will be consumed by the population, causing the facilitation in the production of fake news, spread of misinformation and lack of trust in news sources.","meta":{"url":"http://arxiv.org/abs/2310.16685v1"},"cats":{"benchmark":0.1889473263,"new-dataset":0.1470480631,"data-annotation":0.5182817455,"dev-research":0.3095025179,"llms":0.5607255502,"data-quality":0.2458622479}}
{"text":"Aware of these problems, this research aims to build an artificial intelligence model capable of performing authorship attribution on news articles, identifying the ones written by the ChatGPT.","meta":{"url":"http://arxiv.org/abs/2310.16685v1"},"cats":{"benchmark":0.2766749291,"new-dataset":0.2573954734,"data-annotation":0.5529528574,"dev-research":0.2154363271,"llms":0.4989005263,"data-quality":0.179442253}}
{"text":"To achieve this goal, a dataset containing equal amounts of human and ChatGPT written news was assembled and different natural processing language techniques were used to extract features from it that were used to train, validate and test three models built with different techniques.","meta":{"url":"http://arxiv.org/abs/2310.16685v1"},"cats":{"benchmark":0.2281802979,"new-dataset":0.5595649159,"data-annotation":0.5218786546,"dev-research":0.2566087479,"llms":0.4825812322,"data-quality":0.2349596665}}
{"text":"The best performance was produced by the Bidirectional Long Short Term Memory (LSTM) Neural Network model, achiving 91.57\\% accuracy when tested against the data from the testing set.","meta":{"url":"http://arxiv.org/abs/2310.16685v1"},"cats":{"benchmark":0.5959680076,"new-dataset":0.0800273592,"data-annotation":0.5233365389,"dev-research":0.1245939258,"llms":0.5715639912,"data-quality":0.101956892}}
{"text":"Diffusion models (DMs) are generative models that learn to synthesize images from Gaussian noise.","meta":{"url":"http://arxiv.org/abs/2310.16684v1"},"cats":{"benchmark":0.2163555137,"new-dataset":0.0496957003,"data-annotation":0.4813397544,"dev-research":0.1429344562,"llms":0.5654402676,"data-quality":0.1242827247}}
{"text":"DMs can be trained to do a variety of tasks such as image generation and image super-resolution.","meta":{"url":"http://arxiv.org/abs/2310.16684v1"},"cats":{"benchmark":0.1643052848,"new-dataset":0.0628564073,"data-annotation":0.478242307,"dev-research":0.1901489937,"llms":0.6806897114,"data-quality":0.0840527458}}
{"text":"Researchers have made significant improvement in the capability of synthesizing photorealistic images in the past few years.","meta":{"url":"http://arxiv.org/abs/2310.16684v1"},"cats":{"benchmark":0.218380142,"new-dataset":0.1384482817,"data-annotation":0.5013956297,"dev-research":0.2513299467,"llms":0.493742038,"data-quality":0.0590013648}}
{"text":"These successes also hasten the need to address the potential misuse of synthesized images.","meta":{"url":"http://arxiv.org/abs/2310.16684v1"},"cats":{"benchmark":0.2209926457,"new-dataset":0.0266300219,"data-annotation":0.5021042691,"dev-research":0.3509061337,"llms":0.5673354298,"data-quality":0.1996027631}}
{"text":"In this paper, we highlight the effectiveness of computing local statistics, as opposed to global statistics, in distinguishing digital camera images from DM-generated images.","meta":{"url":"http://arxiv.org/abs/2310.16684v1"},"cats":{"benchmark":0.3405647502,"new-dataset":0.2451654952,"data-annotation":0.4989655446,"dev-research":0.225687716,"llms":0.5312737043,"data-quality":0.2111469502}}
{"text":"We hypothesized that local statistics should be used to address the spatial non-stationarity problem in images.","meta":{"url":"http://arxiv.org/abs/2310.16684v1"},"cats":{"benchmark":0.3919688402,"new-dataset":0.045427801,"data-annotation":0.5253928443,"dev-research":0.1550423974,"llms":0.3813460597,"data-quality":0.1941666548}}
{"text":"We show that our approach produced promising results and it is also robust to various perturbations such as image resizing and JPEG compression.","meta":{"url":"http://arxiv.org/abs/2310.16684v1"},"cats":{"benchmark":0.6133740336,"new-dataset":0.0222540094,"data-annotation":0.5195615144,"dev-research":0.1649776223,"llms":0.381301652,"data-quality":0.2542932446}}
{"text":"Language models have seen significant growth in the size of their corpus, leading to notable performance improvements.","meta":{"url":"http://arxiv.org/abs/2310.16681v1"},"cats":{"benchmark":0.4188215,"new-dataset":0.0743327822,"data-annotation":0.5575422873,"dev-research":0.1838254667,"llms":0.4992478706,"data-quality":0.2016616473}}
{"text":"Yet, there has been limited progress in developing models that handle smaller, more human-like datasets.","meta":{"url":"http://arxiv.org/abs/2310.16681v1"},"cats":{"benchmark":0.1696364809,"new-dataset":0.3145979314,"data-annotation":0.4823674435,"dev-research":0.2128871974,"llms":0.4800812862,"data-quality":0.0630440441}}
{"text":"As part of the BabyLM shared task, this study explores the impact of reinforcement learning from human feedback (RLHF) on language models pretrained from scratch with a limited training corpus.","meta":{"url":"http://arxiv.org/abs/2310.16681v1"},"cats":{"benchmark":0.2294189973,"new-dataset":0.2898818682,"data-annotation":0.5510968797,"dev-research":0.1944539439,"llms":0.4801240114,"data-quality":0.189972937}}
{"text":"Comparing two GPT-2 variants, the larger model performs better in storytelling tasks after RLHF fine-tuning.","meta":{"url":"http://arxiv.org/abs/2310.16681v1"},"cats":{"benchmark":0.3741715176,"new-dataset":0.0730462887,"data-annotation":0.5186608485,"dev-research":0.1890246428,"llms":0.5098571946,"data-quality":0.0717122237}}
{"text":"These findings suggest that RLHF techniques may be more advantageous for larger models due to their higher learning and adaptation capacity, though more experiments are needed to confirm this finding.","meta":{"url":"http://arxiv.org/abs/2310.16681v1"},"cats":{"benchmark":0.4358635883,"new-dataset":0.0126505551,"data-annotation":0.5283169713,"dev-research":0.1115934016,"llms":0.4360232726,"data-quality":0.0695668945}}
{"text":"These insights highlight the potential benefits of RLHF fine-tuning for language models within limited data, enhancing their ability to maintain narrative focus and coherence while adhering better to initial instructions in storytelling tasks.","meta":{"url":"http://arxiv.org/abs/2310.16681v1"},"cats":{"benchmark":0.2234297374,"new-dataset":0.1172418756,"data-annotation":0.5264216548,"dev-research":0.2557739559,"llms":0.5246370987,"data-quality":0.1586334579}}
{"text":"The code for this work is publicly at https://github.com/Zephyr1022/BabyStories-UTSA.","meta":{"url":"http://arxiv.org/abs/2310.16681v1"},"cats":{"benchmark":0.2942907743,"new-dataset":0.2571821754,"data-annotation":0.5276852044,"dev-research":0.1040116786,"llms":0.5119500094,"data-quality":0.1366086808}}
{"text":"Collaborative machine learning (ML) is widely used to enable institutions to learn better models from distributed data.","meta":{"url":"http://arxiv.org/abs/2310.16678v1"},"cats":{"benchmark":0.2794260658,"new-dataset":0.0860308535,"data-annotation":0.4896911849,"dev-research":0.2464888795,"llms":0.501062982,"data-quality":0.1256605451}}
{"text":"While collaborative approaches to learning intuitively protect user data, they remain vulnerable to either the server, the clients, or both, deviating from the protocol.","meta":{"url":"http://arxiv.org/abs/2310.16678v1"},"cats":{"benchmark":0.2159967783,"new-dataset":0.0232046834,"data-annotation":0.4887806158,"dev-research":0.3485761877,"llms":0.5470278321,"data-quality":0.1256799836}}
{"text":"Indeed, because the protocol is asymmetric, a malicious server can abuse its power to reconstruct client data points.","meta":{"url":"http://arxiv.org/abs/2310.16678v1"},"cats":{"benchmark":0.3004308971,"new-dataset":0.011517689,"data-annotation":0.4995363612,"dev-research":0.1696964038,"llms":0.5008005764,"data-quality":0.1335322886}}
{"text":"Conversely, malicious clients can corrupt learning with malicious updates.","meta":{"url":"http://arxiv.org/abs/2310.16678v1"},"cats":{"benchmark":0.2556445817,"new-dataset":0.0168853398,"data-annotation":0.5255042531,"dev-research":0.3465514682,"llms":0.5161252134,"data-quality":0.3721532572}}
{"text":"Thus, both clients and servers require a guarantee when the other cannot be trusted to fully cooperate.","meta":{"url":"http://arxiv.org/abs/2310.16678v1"},"cats":{"benchmark":0.2846335803,"new-dataset":0.0070257454,"data-annotation":0.4768555431,"dev-research":0.2152392607,"llms":0.5575074133,"data-quality":0.1525515472}}
{"text":"In this work, we propose a peer-to-peer (P2P) learning scheme that is secure against malicious servers and robust to malicious clients.","meta":{"url":"http://arxiv.org/abs/2310.16678v1"},"cats":{"benchmark":0.3146274398,"new-dataset":0.0785138267,"data-annotation":0.5262946778,"dev-research":0.169225075,"llms":0.4663149609,"data-quality":0.1665341446}}
{"text":"Our core contribution is a generic framework that transforms any (compatible) algorithm for robust aggregation of model updates to the setting where servers and clients can act maliciously.","meta":{"url":"http://arxiv.org/abs/2310.16678v1"},"cats":{"benchmark":0.4213484375,"new-dataset":0.0915678401,"data-annotation":0.4946389,"dev-research":0.2319497551,"llms":0.4460163187,"data-quality":0.1811649146}}
{"text":"Finally, we demonstrate the computational efficiency of our approach even with 1-million parameter models trained by 100s of peers on standard datasets.","meta":{"url":"http://arxiv.org/abs/2310.16678v1"},"cats":{"benchmark":0.4654793437,"new-dataset":0.3416004736,"data-annotation":0.5184409359,"dev-research":0.1347009201,"llms":0.394913543,"data-quality":0.1168275052}}
{"text":"Schizophrenia is a severe yet treatable mental disorder, it is diagnosed using a multitude of primary and secondary symptoms.","meta":{"url":"http://arxiv.org/abs/2310.16677v1"},"cats":{"benchmark":0.2442609697,"new-dataset":0.024273788,"data-annotation":0.4970762429,"dev-research":0.1958830602,"llms":0.4828255851,"data-quality":0.097597925}}
{"text":"Diagnosis and treatment for each individual depends on the severity of the symptoms, therefore there is a need for accurate, personalised assessments.","meta":{"url":"http://arxiv.org/abs/2310.16677v1"},"cats":{"benchmark":0.4645379166,"new-dataset":0.0057987142,"data-annotation":0.4915822199,"dev-research":0.290426637,"llms":0.4894266596,"data-quality":0.1322562439}}
{"text":"However, the process can be both time-consuming and subjective; hence, there is a motivation to explore automated methods that can offer consistent diagnosis and precise symptom assessments, thereby complementing the work of healthcare practitioners.","meta":{"url":"http://arxiv.org/abs/2310.16677v1"},"cats":{"benchmark":0.4521791715,"new-dataset":0.0034113338,"data-annotation":0.5028575098,"dev-research":0.4216315581,"llms":0.4710107954,"data-quality":0.1350530261}}
{"text":"Machine Learning has demonstrated impressive capabilities across numerous domains, including medicine; the use of Machine Learning in patient assessment holds great promise for healthcare professionals and patients alike, as it can lead to more consistent and accurate symptom estimation.","meta":{"url":"http://arxiv.org/abs/2310.16677v1"},"cats":{"benchmark":0.3955716611,"new-dataset":0.0183399471,"data-annotation":0.5054817357,"dev-research":0.2898965076,"llms":0.4457482967,"data-quality":0.1431873686}}
{"text":"This survey aims to review methodologies that utilise Machine Learning for diagnosis and assessment of schizophrenia.","meta":{"url":"http://arxiv.org/abs/2310.16677v1"},"cats":{"benchmark":0.4009552885,"new-dataset":0.0151055158,"data-annotation":0.5122464889,"dev-research":0.1800990714,"llms":0.3967987755,"data-quality":0.1771971374}}
{"text":"Contrary to previous reviews that primarily focused on binary classification, this work recognises the complexity of the condition and instead, offers an overview of Machine Learning methods designed for fine-grained symptom estimation.","meta":{"url":"http://arxiv.org/abs/2310.16677v1"},"cats":{"benchmark":0.4660680086,"new-dataset":0.0412040169,"data-annotation":0.5358230488,"dev-research":0.2690212064,"llms":0.3964119862,"data-quality":0.224381869}}
{"text":"We cover multiple modalities, namely Medical Imaging, Electroencephalograms and Audio-Visual, as the illness symptoms can manifest themselves both in a patient's pathology and behaviour.","meta":{"url":"http://arxiv.org/abs/2310.16677v1"},"cats":{"benchmark":0.2009815175,"new-dataset":0.0468014969,"data-annotation":0.5030399046,"dev-research":0.2174352039,"llms":0.4675222263,"data-quality":0.1401245717}}
{"text":"Finally, we analyse the datasets and methodologies used in the studies and identify trends, gaps as well as opportunities for future research.","meta":{"url":"http://arxiv.org/abs/2310.16677v1"},"cats":{"benchmark":0.3793832674,"new-dataset":0.2839077727,"data-annotation":0.4829856425,"dev-research":0.2014636895,"llms":0.4824307434,"data-quality":0.1048228101}}
{"text":"Emotion recognition in conversations (ERC) is a rapidly evolving task within the natural language processing community, which aims to detect the emotions expressed by speakers during a conversation.","meta":{"url":"http://arxiv.org/abs/2310.16676v1"},"cats":{"benchmark":0.2682028985,"new-dataset":0.2272170567,"data-annotation":0.5410278913,"dev-research":0.2432745773,"llms":0.5701703504,"data-quality":0.2299018157}}
{"text":"Recently, a growing number of ERC methods have focused on leveraging supervised contrastive learning (SCL) to enhance the robustness and generalizability of learned features.","meta":{"url":"http://arxiv.org/abs/2310.16676v1"},"cats":{"benchmark":0.3962717302,"new-dataset":0.0727859439,"data-annotation":0.5091930993,"dev-research":0.1814860298,"llms":0.4815097508,"data-quality":0.2102739371}}
{"text":"However, current SCL-based approaches in ERC are impeded by the constraint of large batch sizes and the lack of compatibility with most existing ERC models.","meta":{"url":"http://arxiv.org/abs/2310.16676v1"},"cats":{"benchmark":0.4821763163,"new-dataset":0.0221316253,"data-annotation":0.4876104784,"dev-research":0.1858064973,"llms":0.5671690666,"data-quality":0.0955124989}}
{"text":"To address these challenges, we propose an efficient and model-agnostic SCL framework named Supervised Sample-Label Contrastive Learning with Soft-HGR Maximal Correlation (SSLCL), which eliminates the need for a large batch size and can be seamlessly integrated with existing ERC models without introducing any model-specific assumptions.","meta":{"url":"http://arxiv.org/abs/2310.16676v1"},"cats":{"benchmark":0.4323742073,"new-dataset":0.2509510668,"data-annotation":0.4868499482,"dev-research":0.1383245557,"llms":0.5167442066,"data-quality":0.3408495821}}
{"text":"Specifically, we introduce a novel perspective on utilizing label representations by projecting discrete labels into dense embeddings through a shallow multilayer perceptron, and formulate the training objective to maximize the similarity between sample features and their corresponding ground-truth label embeddings, while minimizing the similarity between sample features and label embeddings of disparate classes.","meta":{"url":"http://arxiv.org/abs/2310.16676v1"},"cats":{"benchmark":0.3519207496,"new-dataset":0.1282581253,"data-annotation":0.5359202178,"dev-research":0.1326144562,"llms":0.5196090658,"data-quality":0.5428665986}}
{"text":"Moreover, we innovatively adopt the Soft-HGR maximal correlation as a measure of similarity between sample features and label embeddings, leading to significant performance improvements over conventional similarity measures.","meta":{"url":"http://arxiv.org/abs/2310.16676v1"},"cats":{"benchmark":0.5932033867,"new-dataset":0.1814881783,"data-annotation":0.5231039436,"dev-research":0.1493616768,"llms":0.4491849788,"data-quality":0.3577843904}}
{"text":"Additionally, multimodal cues of utterances are effectively leveraged by SSLCL as data augmentations to boost model performances.","meta":{"url":"http://arxiv.org/abs/2310.16676v1"},"cats":{"benchmark":0.3658098685,"new-dataset":0.0874397009,"data-annotation":0.5254211954,"dev-research":0.2417550787,"llms":0.5225028714,"data-quality":0.1929077233}}
{"text":"Extensive experiments on two ERC benchmark datasets, IEMOCAP and MELD, demonstrate the compatibility and superiority of our proposed SSLCL framework compared to existing state-of-the-art SCL methods.","meta":{"url":"http://arxiv.org/abs/2310.16676v1"},"cats":{"benchmark":0.6763341355,"new-dataset":0.2231921761,"data-annotation":0.4869202354,"dev-research":0.1860038628,"llms":0.5259918991,"data-quality":0.13783979}}
{"text":"Our code is available at \\url{https://github.com/TaoShi1998/SSLCL}.","meta":{"url":"http://arxiv.org/abs/2310.16676v1"},"cats":{"benchmark":0.3601900314,"new-dataset":0.0826934443,"data-annotation":0.5177628645,"dev-research":0.1673607108,"llms":0.5343054784,"data-quality":0.1106316239}}
{"text":"Spiking neural networks (SNNs) are recurrent models that can leverage sparsity in input time series to efficiently carry out tasks such as classification.","meta":{"url":"http://arxiv.org/abs/2310.16675v1"},"cats":{"benchmark":0.2505846965,"new-dataset":0.1371499407,"data-annotation":0.5201768124,"dev-research":0.1785596038,"llms":0.569816633,"data-quality":0.0910076575}}
{"text":"Additional efficiency gains can be obtained if decisions are taken as early as possible as a function of the complexity of the input time series.","meta":{"url":"http://arxiv.org/abs/2310.16675v1"},"cats":{"benchmark":0.5593217608,"new-dataset":0.0029970531,"data-annotation":0.5236019213,"dev-research":0.1868587535,"llms":0.3445273394,"data-quality":0.0485418145}}
{"text":"The decision on when to stop inference and produce a decision must rely on an estimate of the current accuracy of the decision.","meta":{"url":"http://arxiv.org/abs/2310.16675v1"},"cats":{"benchmark":0.4261866748,"new-dataset":0.0078304188,"data-annotation":0.5009942813,"dev-research":0.2836826117,"llms":0.4521548272,"data-quality":0.1623106026}}
{"text":"Prior work demonstrated the use of conformal prediction (CP) as a principled way to quantify uncertainty and support adaptive-latency decisions in SNNs.","meta":{"url":"http://arxiv.org/abs/2310.16675v1"},"cats":{"benchmark":0.3743184818,"new-dataset":0.0231032537,"data-annotation":0.5129415987,"dev-research":0.2098151291,"llms":0.492020088,"data-quality":0.1385606267}}
{"text":"In this paper, we propose to enhance the uncertainty quantification capabilities of SNNs by implementing ensemble models for the purpose of improving the reliability of stopping decisions.","meta":{"url":"http://arxiv.org/abs/2310.16675v1"},"cats":{"benchmark":0.3872211979,"new-dataset":0.0917516379,"data-annotation":0.5304718594,"dev-research":0.2587485499,"llms":0.5082214245,"data-quality":0.2555501753}}
{"text":"Intuitively, an ensemble of multiple models can decide when to stop more reliably by selecting times at which most models agree that the current accuracy level is sufficient.","meta":{"url":"http://arxiv.org/abs/2310.16675v1"},"cats":{"benchmark":0.5813643427,"new-dataset":0.0043671532,"data-annotation":0.5126951014,"dev-research":0.2300414728,"llms":0.4469622082,"data-quality":0.128022303}}
{"text":"The proposed method relies on different forms of information pooling from ensemble models, and offers theoretical reliability guarantees.","meta":{"url":"http://arxiv.org/abs/2310.16675v1"},"cats":{"benchmark":0.5586684079,"new-dataset":0.0073807031,"data-annotation":0.5292279089,"dev-research":0.150379093,"llms":0.3945414527,"data-quality":0.2461394514}}
{"text":"We specifically show that variational inference-based ensembles with p-variable pooling significantly reduce the average latency of state-of-the-art methods, while maintaining reliability guarantees.","meta":{"url":"http://arxiv.org/abs/2310.16675v1"},"cats":{"benchmark":0.5464670453,"new-dataset":0.0114922406,"data-annotation":0.5376582748,"dev-research":0.1848642954,"llms":0.4665417685,"data-quality":0.1317144051}}
{"text":"Automating code documentation through explanatory text can prove highly beneficial in code understanding.","meta":{"url":"http://arxiv.org/abs/2310.16673v1"},"cats":{"benchmark":0.270127035,"new-dataset":0.0938791761,"data-annotation":0.5425704447,"dev-research":0.6421844187,"llms":0.5510802053,"data-quality":0.2738891638}}
{"text":"Large Language Models (LLMs) have made remarkable strides in Natural Language Processing, especially within software engineering tasks such as code generation and code summarization.","meta":{"url":"http://arxiv.org/abs/2310.16673v1"},"cats":{"benchmark":0.2470203333,"new-dataset":0.154469576,"data-annotation":0.5368904278,"dev-research":0.2968593737,"llms":0.6997987118,"data-quality":0.1826715943}}
{"text":"This study specifically delves into the task of generating natural-language summaries for code snippets, using various LLMs.","meta":{"url":"http://arxiv.org/abs/2310.16673v1"},"cats":{"benchmark":0.2941447526,"new-dataset":0.1194145952,"data-annotation":0.5479781156,"dev-research":0.4155372674,"llms":0.6802606196,"data-quality":0.2072233796}}
{"text":"The findings indicate that Code LLMs outperform their generic counterparts, and zero-shot methods yield superior results when dealing with datasets with dissimilar distributions between training and testing sets.","meta":{"url":"http://arxiv.org/abs/2310.16673v1"},"cats":{"benchmark":0.480526652,"new-dataset":0.0820494926,"data-annotation":0.5218679925,"dev-research":0.1838166169,"llms":0.6744408439,"data-quality":0.3162292023}}
{"text":"Trust is essential for our interactions with others but also with artificial intelligence (AI) based systems.","meta":{"url":"http://arxiv.org/abs/2310.16672v1"},"cats":{"benchmark":0.2741959585,"new-dataset":0.0222752878,"data-annotation":0.5198605193,"dev-research":0.2679480123,"llms":0.4832723859,"data-quality":0.1148526647}}
{"text":"To understand whether a user trusts an AI, researchers need reliable measurement tools.","meta":{"url":"http://arxiv.org/abs/2310.16672v1"},"cats":{"benchmark":0.4084501447,"new-dataset":0.0155338551,"data-annotation":0.5086155745,"dev-research":0.3376688376,"llms":0.5134440133,"data-quality":0.1549102336}}
{"text":"However, currently discussed markers mostly rely on expensive and invasive sensors, like electroencephalograms, which may cause discomfort.","meta":{"url":"http://arxiv.org/abs/2310.16672v1"},"cats":{"benchmark":0.3650266105,"new-dataset":0.0384650959,"data-annotation":0.5192312636,"dev-research":0.2402489405,"llms":0.5026451894,"data-quality":0.2061946769}}
{"text":"The analysis of gaze data has been suggested as a convenient tool for trust assessment.","meta":{"url":"http://arxiv.org/abs/2310.16672v1"},"cats":{"benchmark":0.295710038,"new-dataset":0.0958088117,"data-annotation":0.5237665337,"dev-research":0.3039934605,"llms":0.512989804,"data-quality":0.1040371683}}
{"text":"However, the relationship between trust and several aspects of the gaze behaviour is not yet fully understood.","meta":{"url":"http://arxiv.org/abs/2310.16672v1"},"cats":{"benchmark":0.1795894389,"new-dataset":0.0136334025,"data-annotation":0.5310838216,"dev-research":0.2467981871,"llms":0.4972496733,"data-quality":0.0971699451}}
{"text":"To provide more insights into this relationship, we propose a exploration study in virtual reality where participants have to perform a sorting task together with a simulated AI in a simulated robotic arm embedded in a gaming.","meta":{"url":"http://arxiv.org/abs/2310.16672v1"},"cats":{"benchmark":0.2461221269,"new-dataset":0.0394636821,"data-annotation":0.5278152313,"dev-research":0.2520137793,"llms":0.4891992434,"data-quality":0.0519255363}}
{"text":"We discuss the potential benefits of this approach and outline our study design in this submission.","meta":{"url":"http://arxiv.org/abs/2310.16672v1"},"cats":{"benchmark":0.4804201074,"new-dataset":0.0119119129,"data-annotation":0.4899035948,"dev-research":0.2365729394,"llms":0.5069381471,"data-quality":0.0547130075}}
{"text":"Deriving reliable region-word alignment from image-text pairs is critical to learn object-level vision-language representations for open-vocabulary object detection.","meta":{"url":"http://arxiv.org/abs/2310.16667v1"},"cats":{"benchmark":0.2788193275,"new-dataset":0.2735908656,"data-annotation":0.5480010052,"dev-research":0.139523073,"llms":0.5224913695,"data-quality":0.3607556028}}
{"text":"Existing methods typically rely on pre-trained or self-trained vision-language models for alignment, which are prone to limitations in localization accuracy or generalization capabilities.","meta":{"url":"http://arxiv.org/abs/2310.16667v1"},"cats":{"benchmark":0.3261521928,"new-dataset":0.1186102239,"data-annotation":0.5522383707,"dev-research":0.1703580804,"llms":0.5056030861,"data-quality":0.2299346339}}
{"text":"In this paper, we propose CoDet, a novel approach that overcomes the reliance on pre-aligned vision-language space by reformulating region-word alignment as a co-occurring object discovery problem.","meta":{"url":"http://arxiv.org/abs/2310.16667v1"},"cats":{"benchmark":0.2317827505,"new-dataset":0.4106459784,"data-annotation":0.5326654892,"dev-research":0.2961659228,"llms":0.4844117001,"data-quality":0.337942921}}
{"text":"Intuitively, by grouping images that mention a shared concept in their captions, objects corresponding to the shared concept shall exhibit high co-occurrence among the group.","meta":{"url":"http://arxiv.org/abs/2310.16667v1"},"cats":{"benchmark":0.2186920491,"new-dataset":0.061227021,"data-annotation":0.5359191919,"dev-research":0.2122729578,"llms":0.5074289878,"data-quality":0.20314776}}
{"text":"CoDet then leverages visual similarities to discover the co-occurring objects and align them with the shared concept.","meta":{"url":"http://arxiv.org/abs/2310.16667v1"},"cats":{"benchmark":0.2414591917,"new-dataset":0.0815274404,"data-annotation":0.5230552106,"dev-research":0.3595210102,"llms":0.519248359,"data-quality":0.1569081618}}
{"text":"Extensive experiments demonstrate that CoDet has superior performances and compelling scalability in open-vocabulary detection, e.g., by scaling up the visual backbone, CoDet achieves 37.0 $\\text{AP}^m_{novel}$ and 44.7 $\\text{AP}^m_{all}$ on OV-LVIS, surpassing the previous SoTA by 4.2 $\\text{AP}^m_{novel}$ and 9.8 $\\text{AP}^m_{all}$. Code is available at https://github.com/CVMI-Lab/CoDet.","meta":{"url":"http://arxiv.org/abs/2310.16667v1"},"cats":{"benchmark":0.3710110276,"new-dataset":0.2009686243,"data-annotation":0.5424771198,"dev-research":0.1706531277,"llms":0.565050037,"data-quality":0.1882162567}}
{"text":"Unsupervised Domain Adaptation (UDA) is a learning technique that transfers knowledge learned in the source domain from labelled training data to the target domain with only unlabelled data.","meta":{"url":"http://arxiv.org/abs/2310.16665v1"},"cats":{"benchmark":0.2691395481,"new-dataset":0.1275473351,"data-annotation":0.4794033031,"dev-research":0.2047663185,"llms":0.5428867602,"data-quality":0.1947429561}}
{"text":"It is of significant importance to medical image segmentation because of the usual lack of labelled training data.","meta":{"url":"http://arxiv.org/abs/2310.16665v1"},"cats":{"benchmark":0.2668737259,"new-dataset":0.0641881616,"data-annotation":0.5068833056,"dev-research":0.1644569867,"llms":0.4854299685,"data-quality":0.2725476624}}
{"text":"Although extensive efforts have been made to optimize UDA techniques to improve the ac?curacy of segmentation models in the target domain, few studies have addressed the robustness of these models under UDA.","meta":{"url":"http://arxiv.org/abs/2310.16665v1"},"cats":{"benchmark":0.5132073452,"new-dataset":0.0656753509,"data-annotation":0.4933847435,"dev-research":0.161641082,"llms":0.3882420099,"data-quality":0.2197285648}}
{"text":"In this study, we propose a two-stage training strat?egy for robust domain adaptation.","meta":{"url":"http://arxiv.org/abs/2310.16665v1"},"cats":{"benchmark":0.312744967,"new-dataset":0.0484116744,"data-annotation":0.5016672244,"dev-research":0.1683937189,"llms":0.5018865616,"data-quality":0.1836215712}}
{"text":"In the source training stage, we utilize adversarial sample augmentation to en?hance the robustness and generalization capability of the source model.","meta":{"url":"http://arxiv.org/abs/2310.16665v1"},"cats":{"benchmark":0.2826361566,"new-dataset":0.0557646523,"data-annotation":0.51998594,"dev-research":0.1944137652,"llms":0.492549188,"data-quality":0.340096199}}
{"text":"And in the target training stage, we propose a novel robust pseudo-label and pseudo-boundary (PLPB) method, which effectively utilizes unlabeled target data to generate pseudo labels and pseudo boundaries that enable model self-adaptation without requiring source data.","meta":{"url":"http://arxiv.org/abs/2310.16665v1"},"cats":{"benchmark":0.3302773391,"new-dataset":0.0854772824,"data-annotation":0.5015589402,"dev-research":0.1560006843,"llms":0.4463443328,"data-quality":0.4890897802}}
{"text":"Ex?tensive experimental results on cross-domain fundus image segmentation confirm the effectiveness and versatility of our method.","meta":{"url":"http://arxiv.org/abs/2310.16665v1"},"cats":{"benchmark":0.4353990282,"new-dataset":0.0308138334,"data-annotation":0.5086942311,"dev-research":0.104033417,"llms":0.5164078646,"data-quality":0.134826496}}
{"text":"Source code of this study is openly accessible at https://github.com/LinGrayy/PLPB.","meta":{"url":"http://arxiv.org/abs/2310.16665v1"},"cats":{"benchmark":0.3529306294,"new-dataset":0.3612519728,"data-annotation":0.5130248602,"dev-research":0.1916421132,"llms":0.5398373472,"data-quality":0.0758746775}}
{"text":"Multi-agent reinforcement learning based methods are significant for online planning of feasible and safe paths for agents in dynamic and uncertain scenarios.","meta":{"url":"http://arxiv.org/abs/2310.16659v1"},"cats":{"benchmark":0.2379758583,"new-dataset":0.0458144988,"data-annotation":0.5042319398,"dev-research":0.1627515943,"llms":0.4743234199,"data-quality":0.0474235733}}
{"text":"Although some methods like fully centralized and fully decentralized methods achieve a certain measure of success, they also encounter problems such as dimension explosion and poor convergence, respectively.","meta":{"url":"http://arxiv.org/abs/2310.16659v1"},"cats":{"benchmark":0.4844450876,"new-dataset":0.0045913338,"data-annotation":0.5108957898,"dev-research":0.2053079866,"llms":0.4988910244,"data-quality":0.0956060006}}
{"text":"In this paper, we propose a novel centralized training with decentralized execution method based on multi-agent reinforcement learning to solve the dynamic obstacle avoidance problem online.","meta":{"url":"http://arxiv.org/abs/2310.16659v1"},"cats":{"benchmark":0.2444774075,"new-dataset":0.0615797238,"data-annotation":0.4988817885,"dev-research":0.1415239079,"llms":0.4902202684,"data-quality":0.0518915528}}
{"text":"In this approach, each agent communicates only with the central planner or only with its neighbors, respectively, to plan feasible and safe paths online.","meta":{"url":"http://arxiv.org/abs/2310.16659v1"},"cats":{"benchmark":0.1524765823,"new-dataset":0.0321257607,"data-annotation":0.4968630363,"dev-research":0.1910473924,"llms":0.5279257107,"data-quality":0.0301435848}}
{"text":"We improve our methods based on the idea of model predictive control to increase the training efficiency and sample utilization of agents.","meta":{"url":"http://arxiv.org/abs/2310.16659v1"},"cats":{"benchmark":0.3740378959,"new-dataset":0.0241116,"data-annotation":0.5305537991,"dev-research":0.1503775794,"llms":0.3819685107,"data-quality":0.0646077725}}
{"text":"The experimental results in both simulation, indoor, and outdoor environments validate the effectiveness of our method.","meta":{"url":"http://arxiv.org/abs/2310.16659v1"},"cats":{"benchmark":0.5995286785,"new-dataset":0.0093774075,"data-annotation":0.5214590264,"dev-research":0.2300997496,"llms":0.4626135286,"data-quality":0.0923023013}}
{"text":"The video is available at https://www.bilibili.com/video/BV1gw41197hV/?vd_source=9de61aecdd9fb684e546d032ef7fe7bf","meta":{"url":"http://arxiv.org/abs/2310.16659v1"},"cats":{"benchmark":0.2423431654,"new-dataset":0.2577978076,"data-annotation":0.5160590826,"dev-research":0.1062729584,"llms":0.5563072737,"data-quality":0.0937356657}}
{"text":"This work presents a camera model for refractive media such as water and its application in underwater visual-inertial odometry.","meta":{"url":"http://arxiv.org/abs/2310.16658v1"},"cats":{"benchmark":0.3133846535,"new-dataset":0.1613248852,"data-annotation":0.4952158514,"dev-research":0.2018058021,"llms":0.4459929619,"data-quality":0.0594474676}}
{"text":"The model is self-calibrating in real-time and is free of known correspondences or calibration targets.","meta":{"url":"http://arxiv.org/abs/2310.16658v1"},"cats":{"benchmark":0.306413955,"new-dataset":0.0598974378,"data-annotation":0.5115736769,"dev-research":0.1170936443,"llms":0.4276689467,"data-quality":0.0774777784}}
{"text":"It is separable as a distortion model (dependent on refractive index $n$ and radial pixel coordinate) and a virtual pinhole model (as a function of $n$).","meta":{"url":"http://arxiv.org/abs/2310.16658v1"},"cats":{"benchmark":0.3629980725,"new-dataset":0.0193233432,"data-annotation":0.5035520045,"dev-research":0.1358707687,"llms":0.3825534211,"data-quality":0.1018438212}}
{"text":"We derive the self-calibration formulation leveraging epipolar constraints to estimate the refractive index and subsequently correct for distortion.","meta":{"url":"http://arxiv.org/abs/2310.16658v1"},"cats":{"benchmark":0.46791427,"new-dataset":0.0268841048,"data-annotation":0.5213338748,"dev-research":0.1235310225,"llms":0.3883206697,"data-quality":0.1726550942}}
{"text":"Through experimental studies using an underwater robot integrating cameras and inertial sensing, the model is validated regarding the accurate estimation of the refractive index and its benefits for robust odometry estimation in an extended envelope of conditions.","meta":{"url":"http://arxiv.org/abs/2310.16658v1"},"cats":{"benchmark":0.4553050311,"new-dataset":0.0678598198,"data-annotation":0.5023255768,"dev-research":0.1963900851,"llms":0.4148200585,"data-quality":0.0651003392}}
{"text":"Lastly, we show the transition between media and the estimation of the varying refractive index online, thus allowing computer vision tasks across refractive media.","meta":{"url":"http://arxiv.org/abs/2310.16658v1"},"cats":{"benchmark":0.3927118838,"new-dataset":0.0410677868,"data-annotation":0.5113870886,"dev-research":0.1531011299,"llms":0.4025281028,"data-quality":0.0455846329}}
{"text":"Text-to-image diffusion models achieved a remarkable leap in capabilities over the last few years, enabling high-quality and diverse synthesis of images from a textual prompt.","meta":{"url":"http://arxiv.org/abs/2310.16656v1"},"cats":{"benchmark":0.2592773354,"new-dataset":0.0785244582,"data-annotation":0.5071187906,"dev-research":0.1367928482,"llms":0.5215574996,"data-quality":0.1227965757}}
{"text":"However, even the most advanced models often struggle to precisely follow all of the directions in their prompts.","meta":{"url":"http://arxiv.org/abs/2310.16656v1"},"cats":{"benchmark":0.2230246909,"new-dataset":0.0034113981,"data-annotation":0.5067173656,"dev-research":0.2364727781,"llms":0.5485766375,"data-quality":0.0937443693}}
{"text":"The vast majority of these models are trained on datasets consisting of (image, caption) pairs where the images often come from the web, and the captions are their HTML alternate text.","meta":{"url":"http://arxiv.org/abs/2310.16656v1"},"cats":{"benchmark":0.1913539385,"new-dataset":0.1781140492,"data-annotation":0.5226640605,"dev-research":0.1571817872,"llms":0.4733423004,"data-quality":0.249616213}}
{"text":"A notable example is the LAION dataset, used by Stable Diffusion and other models.","meta":{"url":"http://arxiv.org/abs/2310.16656v1"},"cats":{"benchmark":0.3007654923,"new-dataset":0.432367242,"data-annotation":0.4812740959,"dev-research":0.1034511361,"llms":0.4187191643,"data-quality":0.119985072}}
{"text":"In this work we observe that these captions are often of low quality, and argue that this significantly affects the model's capability to understand nuanced semantics in the textual prompts.","meta":{"url":"http://arxiv.org/abs/2310.16656v1"},"cats":{"benchmark":0.2392129349,"new-dataset":0.0782732657,"data-annotation":0.5649256131,"dev-research":0.2684452384,"llms":0.5602813451,"data-quality":0.4602522511}}
{"text":"We show that by relabeling the corpus with a specialized automatic captioning model and training a text-to-image model on the recaptioned dataset, the model benefits substantially across the board.","meta":{"url":"http://arxiv.org/abs/2310.16656v1"},"cats":{"benchmark":0.3135947148,"new-dataset":0.6580707756,"data-annotation":0.5401657628,"dev-research":0.1709031364,"llms":0.5218416018,"data-quality":0.3335526967}}
{"text":"First, in overall image quality: e.g. FID 14.84 vs. the baseline of 17.87, and 64.3% improvement in faithful image generation according to human evaluation.","meta":{"url":"http://arxiv.org/abs/2310.16656v1"},"cats":{"benchmark":0.5511549992,"new-dataset":0.0950477723,"data-annotation":0.5226782499,"dev-research":0.1699552232,"llms":0.4965052984,"data-quality":0.1788026803}}
{"text":"Second, in semantic alignment, e.g. semantic object accuracy 84.34 vs. 78.90, counting alignment errors 1.32 vs. 1.44 and positional alignment 62.42 vs. 57.60.","meta":{"url":"http://arxiv.org/abs/2310.16656v1"},"cats":{"benchmark":0.6037617269,"new-dataset":0.0380693503,"data-annotation":0.529609937,"dev-research":0.2498485795,"llms":0.5331053441,"data-quality":0.4193072473}}
{"text":"We analyze various ways to relabel the corpus and provide evidence that this technique, which we call RECAP, both reduces the train-inference discrepancy and provides the model with more information per example, increasing sample efficiency and allowing the model to better understand the relations between captions and images.","meta":{"url":"http://arxiv.org/abs/2310.16656v1"},"cats":{"benchmark":0.3707795581,"new-dataset":0.1755287941,"data-annotation":0.5404181395,"dev-research":0.2053235463,"llms":0.4673949159,"data-quality":0.4637802153}}
{"text":"Image-based Reinforcement Learning is a practical yet challenging task.","meta":{"url":"http://arxiv.org/abs/2310.16655v1"},"cats":{"benchmark":0.2097540698,"new-dataset":0.029608557,"data-annotation":0.5039262948,"dev-research":0.1458110987,"llms":0.4731820186,"data-quality":0.0906256991}}
{"text":"A major hurdle lies in extracting control-centric representations while disregarding irrelevant information.","meta":{"url":"http://arxiv.org/abs/2310.16655v1"},"cats":{"benchmark":0.1936288255,"new-dataset":0.014134075,"data-annotation":0.5183352994,"dev-research":0.1933040953,"llms":0.5079255192,"data-quality":0.1568308586}}
{"text":"While approaches that follow the bisimulation principle exhibit the potential in learning state representations to address this issue, they still grapple with the limited expressive capacity of latent dynamics and the inadaptability to sparse reward environments.","meta":{"url":"http://arxiv.org/abs/2310.16655v1"},"cats":{"benchmark":0.2292350489,"new-dataset":0.0169136612,"data-annotation":0.5288940077,"dev-research":0.1012009397,"llms":0.4920541732,"data-quality":0.0896458778}}
{"text":"To address these limitations, we introduce ReBis, which aims to capture control-centric information by integrating reward-free control information alongside reward-specific knowledge.","meta":{"url":"http://arxiv.org/abs/2310.16655v1"},"cats":{"benchmark":0.2116460946,"new-dataset":0.1548278646,"data-annotation":0.5070252084,"dev-research":0.2783653312,"llms":0.5274385558,"data-quality":0.1082808359}}
{"text":"ReBis utilizes a transformer architecture to implicitly model the dynamics and incorporates block-wise masking to eliminate spatiotemporal redundancy.","meta":{"url":"http://arxiv.org/abs/2310.16655v1"},"cats":{"benchmark":0.3770484857,"new-dataset":0.0154380952,"data-annotation":0.4883542561,"dev-research":0.2155245285,"llms":0.4564220734,"data-quality":0.0624897453}}
{"text":"Moreover, ReBis combines bisimulation-based loss with asymmetric reconstruction loss to prevent feature collapse in environments with sparse rewards.","meta":{"url":"http://arxiv.org/abs/2310.16655v1"},"cats":{"benchmark":0.4492337253,"new-dataset":0.0330588927,"data-annotation":0.513343514,"dev-research":0.1998825935,"llms":0.3909770843,"data-quality":0.1235757767}}
{"text":"Empirical studies on two large benchmarks, including Atari games and DeepMind Control Suit, demonstrate that ReBis has superior performance compared to existing methods, proving its effectiveness.","meta":{"url":"http://arxiv.org/abs/2310.16655v1"},"cats":{"benchmark":0.5410814585,"new-dataset":0.0598405083,"data-annotation":0.5155454271,"dev-research":0.3177680581,"llms":0.5173105053,"data-quality":0.0722461457}}
{"text":"Pre-trained language models have been widely used in dependency parsing task and have achieved significant improvements in parser performance.","meta":{"url":"http://arxiv.org/abs/2310.16654v1"},"cats":{"benchmark":0.286990939,"new-dataset":0.0820513973,"data-annotation":0.5500558085,"dev-research":0.1678103496,"llms":0.5193343366,"data-quality":0.207188108}}
{"text":"However, it remains an understudied question whether pre-trained language models can spontaneously exhibit the ability of dependency parsing without introducing additional parser structure in the zero-shot scenario.","meta":{"url":"http://arxiv.org/abs/2310.16654v1"},"cats":{"benchmark":0.1705046301,"new-dataset":0.0357404198,"data-annotation":0.5352913854,"dev-research":0.1290691579,"llms":0.5409678882,"data-quality":0.2006096317}}
{"text":"In this paper, we propose to explore the dependency parsing ability of large language models such as ChatGPT and conduct linguistic analysis.","meta":{"url":"http://arxiv.org/abs/2310.16654v1"},"cats":{"benchmark":0.2421799623,"new-dataset":0.251071581,"data-annotation":0.5370526454,"dev-research":0.2157212418,"llms":0.5572615842,"data-quality":0.1673128879}}
{"text":"The experimental results demonstrate that ChatGPT is a potential zero-shot dependency parser, and the linguistic analysis also shows some unique preferences in parsing outputs.","meta":{"url":"http://arxiv.org/abs/2310.16654v1"},"cats":{"benchmark":0.2587863862,"new-dataset":0.1664343381,"data-annotation":0.5362550894,"dev-research":0.2282209576,"llms":0.561941573,"data-quality":0.2498473414}}
{"text":"Because of its privacy-preserving capability, federated learning (FL) has attracted significant attention from both academia and industry.","meta":{"url":"http://arxiv.org/abs/2310.16652v1"},"cats":{"benchmark":0.1995674555,"new-dataset":0.0356966002,"data-annotation":0.4802472877,"dev-research":0.126766403,"llms":0.5484445429,"data-quality":0.094909581}}
{"text":"However, when being implemented over wireless networks, it is not clear how much communication error can be tolerated by FL.","meta":{"url":"http://arxiv.org/abs/2310.16652v1"},"cats":{"benchmark":0.3621812081,"new-dataset":0.0097634489,"data-annotation":0.4923162368,"dev-research":0.2996516559,"llms":0.5234638646,"data-quality":0.3095654716}}
{"text":"This paper investigates the robustness of FL to the uplink and downlink communication error.","meta":{"url":"http://arxiv.org/abs/2310.16652v1"},"cats":{"benchmark":0.47971558,"new-dataset":0.0173971464,"data-annotation":0.4994630859,"dev-research":0.1922678123,"llms":0.4827180641,"data-quality":0.288284731}}
{"text":"Our theoretical analysis reveals that the robustness depends on two critical parameters, namely the number of clients and the numerical range of model parameters.","meta":{"url":"http://arxiv.org/abs/2310.16652v1"},"cats":{"benchmark":0.5512344996,"new-dataset":0.0104026861,"data-annotation":0.5117595857,"dev-research":0.16963298,"llms":0.3873986733,"data-quality":0.1987652351}}
{"text":"It is also shown that the uplink communication in FL can tolerate a higher bit error rate (BER) than downlink communication, and this difference is quantified by a proposed formula.","meta":{"url":"http://arxiv.org/abs/2310.16652v1"},"cats":{"benchmark":0.4816095266,"new-dataset":0.0138695343,"data-annotation":0.4975300021,"dev-research":0.1994967546,"llms":0.5473446548,"data-quality":0.156898297}}
{"text":"The findings and theoretical analyses are further validated by extensive experiments.","meta":{"url":"http://arxiv.org/abs/2310.16652v1"},"cats":{"benchmark":0.546180763,"new-dataset":0.0036823748,"data-annotation":0.5149270095,"dev-research":0.168493128,"llms":0.4602593539,"data-quality":0.0936283255}}
{"text":"We consider the problem of learning Variational Autoencoders (VAEs), i.e., a type of deep generative model, from data with missing values.","meta":{"url":"http://arxiv.org/abs/2310.16648v1"},"cats":{"benchmark":0.2013272928,"new-dataset":0.0548749075,"data-annotation":0.5158095194,"dev-research":0.1383941521,"llms":0.49939541,"data-quality":0.2401866398}}
{"text":"Such data is omnipresent in real-world applications of machine learning because complete data is often impossible or too costly to obtain.","meta":{"url":"http://arxiv.org/abs/2310.16648v1"},"cats":{"benchmark":0.2825729102,"new-dataset":0.0723617133,"data-annotation":0.5119836738,"dev-research":0.1392594388,"llms":0.3762119542,"data-quality":0.150086833}}
{"text":"We particularly focus on improving a VAE's amortized posterior inference, i.e., the encoder, which in the case of missing data can be susceptible to learning inconsistent posterior distributions regarding the missingness.","meta":{"url":"http://arxiv.org/abs/2310.16648v1"},"cats":{"benchmark":0.4170062203,"new-dataset":0.0104297348,"data-annotation":0.5143186307,"dev-research":0.1351712871,"llms":0.4962789611,"data-quality":0.3111665189}}
{"text":"To this end, we provide a formal definition of posterior consistency and propose an approach for regularizing an encoder's posterior distribution which promotes this consistency.","meta":{"url":"http://arxiv.org/abs/2310.16648v1"},"cats":{"benchmark":0.4335939095,"new-dataset":0.0236855007,"data-annotation":0.497140533,"dev-research":0.1835116116,"llms":0.4621095855,"data-quality":0.3426984482}}
{"text":"We observe that the proposed regularization suggests a different training objective than that typically considered in the literature when facing missing values.","meta":{"url":"http://arxiv.org/abs/2310.16648v1"},"cats":{"benchmark":0.5253351261,"new-dataset":0.0051078147,"data-annotation":0.5180517401,"dev-research":0.1719499313,"llms":0.3909700729,"data-quality":0.4088394649}}
{"text":"Furthermore, we empirically demonstrate that our regularization leads to improved performance in missing value settings in terms of reconstruction quality and downstream tasks utilizing uncertainty in the latent space.","meta":{"url":"http://arxiv.org/abs/2310.16648v1"},"cats":{"benchmark":0.5337926446,"new-dataset":0.0334500639,"data-annotation":0.4901705642,"dev-research":0.2035633776,"llms":0.3891956954,"data-quality":0.3169084752}}
{"text":"This improved performance can be observed for many classes of VAEs including VAEs equipped with normalizing flows.","meta":{"url":"http://arxiv.org/abs/2310.16648v1"},"cats":{"benchmark":0.5428141125,"new-dataset":0.0026070465,"data-annotation":0.519763978,"dev-research":0.1221941577,"llms":0.5272763231,"data-quality":0.0973679609}}
{"text":"Regularizing Deep Neural Networks (DNNs) is essential for improving generalizability and preventing overfitting.","meta":{"url":"http://arxiv.org/abs/2310.16647v1"},"cats":{"benchmark":0.3371533528,"new-dataset":0.0185407782,"data-annotation":0.5201044104,"dev-research":0.2495191942,"llms":0.4464983812,"data-quality":0.2103014487}}
{"text":"Fixed penalty methods, though common, lack adaptability and suffer from hyperparameter sensitivity.","meta":{"url":"http://arxiv.org/abs/2310.16647v1"},"cats":{"benchmark":0.72382026,"new-dataset":0.0022096801,"data-annotation":0.5178634267,"dev-research":0.1861208155,"llms":0.4516289131,"data-quality":0.2414000409}}
{"text":"In this paper, we propose a novel approach to DNN regularization by framing the training process as a constrained optimization problem.","meta":{"url":"http://arxiv.org/abs/2310.16647v1"},"cats":{"benchmark":0.3287842466,"new-dataset":0.0687878475,"data-annotation":0.5279145752,"dev-research":0.2447539304,"llms":0.3782292806,"data-quality":0.2604294642}}
{"text":"Where the data fidelity term is the minimization objective and the regularization terms serve as constraints.","meta":{"url":"http://arxiv.org/abs/2310.16647v1"},"cats":{"benchmark":0.4626359432,"new-dataset":0.0079297942,"data-annotation":0.4887525123,"dev-research":0.1923108021,"llms":0.3019238965,"data-quality":0.2756623896}}
{"text":"Then, we employ the Stochastic Augmented Lagrangian (SAL) method to achieve a more flexible and efficient regularization mechanism.","meta":{"url":"http://arxiv.org/abs/2310.16647v1"},"cats":{"benchmark":0.5792398422,"new-dataset":0.0036470956,"data-annotation":0.5249630236,"dev-research":0.1055897597,"llms":0.3412157439,"data-quality":0.1506831204}}
{"text":"Our approach extends beyond black-box regularization, demonstrating significant improvements in white-box models, where weights are often subject to hard constraints to ensure interpretability.","meta":{"url":"http://arxiv.org/abs/2310.16647v1"},"cats":{"benchmark":0.4297513408,"new-dataset":0.01628291,"data-annotation":0.5269376558,"dev-research":0.154735165,"llms":0.3561417248,"data-quality":0.2578276106}}
{"text":"Experimental results on image-based classification on MNIST, CIFAR10, and CIFAR100 datasets validate the effectiveness of our approach.","meta":{"url":"http://arxiv.org/abs/2310.16647v1"},"cats":{"benchmark":0.410774492,"new-dataset":0.1112942464,"data-annotation":0.5196220753,"dev-research":0.1746817179,"llms":0.4608661064,"data-quality":0.3050372438}}
{"text":"SAL consistently achieves higher Accuracy while also achieving better constraint satisfaction, thus showcasing its potential for optimizing DNNs under constrained settings.","meta":{"url":"http://arxiv.org/abs/2310.16647v1"},"cats":{"benchmark":0.3899931414,"new-dataset":0.0561968846,"data-annotation":0.5183578957,"dev-research":0.2702241473,"llms":0.4894249924,"data-quality":0.1632364772}}
{"text":"Reinforcement learning suffers from limitations in real practices primarily due to the numbers of required interactions with virtual environments.","meta":{"url":"http://arxiv.org/abs/2310.16646v1"},"cats":{"benchmark":0.1781765867,"new-dataset":0.022184849,"data-annotation":0.5079585176,"dev-research":0.251207727,"llms":0.5255182824,"data-quality":0.0593507723}}
{"text":"It results in a challenging problem that we are implausible to obtain an optimal strategy only with a few attempts for many learning method.","meta":{"url":"http://arxiv.org/abs/2310.16646v1"},"cats":{"benchmark":0.3332849627,"new-dataset":0.0043136409,"data-annotation":0.5401172989,"dev-research":0.1304522773,"llms":0.4134140925,"data-quality":0.1203024182}}
{"text":"Hereby, we design an improved reinforcement learning method based on model predictive control that models the environment through a data-driven approach.","meta":{"url":"http://arxiv.org/abs/2310.16646v1"},"cats":{"benchmark":0.2559083688,"new-dataset":0.1535242485,"data-annotation":0.4757644787,"dev-research":0.2341331309,"llms":0.3901926341,"data-quality":0.0583222074}}
{"text":"Based on learned environmental model, it performs multi-step prediction to estimate the value function and optimize the policy.","meta":{"url":"http://arxiv.org/abs/2310.16646v1"},"cats":{"benchmark":0.3393178827,"new-dataset":0.0409824548,"data-annotation":0.4956222191,"dev-research":0.1614711245,"llms":0.3855288416,"data-quality":0.0498062081}}
{"text":"The method demonstrates higher learning efficiency, faster convergent speed of strategies tending to the optimal value, and fewer sample capacity space required by experience replay buffers.","meta":{"url":"http://arxiv.org/abs/2310.16646v1"},"cats":{"benchmark":0.5134285967,"new-dataset":0.0121362631,"data-annotation":0.5166797166,"dev-research":0.1746428608,"llms":0.4886310098,"data-quality":0.0589524785}}
{"text":"Experimental results, both in classic databases and in a dynamic obstacle avoidance scenario for unmanned aerial vehicle, validate the proposed approaches.","meta":{"url":"http://arxiv.org/abs/2310.16646v1"},"cats":{"benchmark":0.3359268829,"new-dataset":0.0527400603,"data-annotation":0.4950134176,"dev-research":0.1892195234,"llms":0.4610271045,"data-quality":0.0524931822}}
{"text":"Facial Expression Recognition (FER) is a crucial task in affective computing, but its conventional focus on the seven basic emotions limits its applicability to the complex and expanding emotional spectrum.","meta":{"url":"http://arxiv.org/abs/2310.16640v1"},"cats":{"benchmark":0.2506247415,"new-dataset":0.0863908883,"data-annotation":0.5133431627,"dev-research":0.1899273336,"llms":0.4930720774,"data-quality":0.1080755291}}
{"text":"To address the issue of new and unseen emotions present in dynamic in-the-wild FER, we propose a novel vision-language model that utilises sample-level text descriptions (i.e. captions of the context, expressions or emotional cues) as natural language supervision, aiming to enhance the learning of rich latent representations, for zero-shot classification.","meta":{"url":"http://arxiv.org/abs/2310.16640v1"},"cats":{"benchmark":0.1694261995,"new-dataset":0.3789590391,"data-annotation":0.5483372518,"dev-research":0.2174433518,"llms":0.5460626744,"data-quality":0.2720873228}}
{"text":"To test this, we evaluate using zero-shot classification of the model trained on sample-level descriptions on four popular dynamic FER datasets.","meta":{"url":"http://arxiv.org/abs/2310.16640v1"},"cats":{"benchmark":0.2976202862,"new-dataset":0.3447587625,"data-annotation":0.5221983079,"dev-research":0.1173656061,"llms":0.4809557768,"data-quality":0.2255340554}}
{"text":"Our findings show that this approach yields significant improvements when compared to baseline methods.","meta":{"url":"http://arxiv.org/abs/2310.16640v1"},"cats":{"benchmark":0.8233690559,"new-dataset":0.005135609,"data-annotation":0.5148134009,"dev-research":0.3022038731,"llms":0.4152100889,"data-quality":0.1665718343}}
{"text":"Specifically, for zero-shot video FER, we outperform CLIP by over 10\\% in terms of Weighted Average Recall and 5\\% in terms of Unweighted Average Recall on several datasets.","meta":{"url":"http://arxiv.org/abs/2310.16640v1"},"cats":{"benchmark":0.4825440125,"new-dataset":0.0646497037,"data-annotation":0.5269558742,"dev-research":0.1226177393,"llms":0.5380452605,"data-quality":0.2464102565}}
{"text":"Furthermore, we evaluate the representations obtained from the network trained using sample-level descriptions on the downstream task of mental health symptom estimation, achieving performance comparable or superior to state-of-the-art methods and strong agreement with human experts.","meta":{"url":"http://arxiv.org/abs/2310.16640v1"},"cats":{"benchmark":0.3732306517,"new-dataset":0.0374654061,"data-annotation":0.5372023649,"dev-research":0.2951259638,"llms":0.4324252947,"data-quality":0.2634665243}}
{"text":"Namely, we achieve a Pearson's Correlation Coefficient of up to 0.85 on schizophrenia symptom severity estimation, which is comparable to human experts' agreement.","meta":{"url":"http://arxiv.org/abs/2310.16640v1"},"cats":{"benchmark":0.4544855457,"new-dataset":0.04180139,"data-annotation":0.5171288766,"dev-research":0.2151361261,"llms":0.3773902851,"data-quality":0.1283821278}}
{"text":"The code is publicly available at: https://github.com/NickyFot/EmoCLIP.","meta":{"url":"http://arxiv.org/abs/2310.16640v1"},"cats":{"benchmark":0.2969053032,"new-dataset":0.2259220446,"data-annotation":0.5414938791,"dev-research":0.1784476804,"llms":0.5400629483,"data-quality":0.122050518}}
{"text":"This study leverages synthetic data as a validation set to reduce overfitting and ease the selection of the best model in AI development.","meta":{"url":"http://arxiv.org/abs/2310.16052v1"},"cats":{"benchmark":0.294278932,"new-dataset":0.1252856132,"data-annotation":0.5013565649,"dev-research":0.3698607909,"llms":0.4111728259,"data-quality":0.1265087518}}
{"text":"While synthetic data have been used for augmenting the training set, we find that synthetic data can also significantly diversify the validation set, offering marked advantages in domains like healthcare, where data are typically limited, sensitive, and from out-domain sources (i.e., hospitals).","meta":{"url":"http://arxiv.org/abs/2310.16052v1"},"cats":{"benchmark":0.3894183328,"new-dataset":0.134020966,"data-annotation":0.4764964402,"dev-research":0.1888660912,"llms":0.4580031696,"data-quality":0.1304485733}}
{"text":"In this study, we illustrate the effectiveness of synthetic data for early cancer detection in computed tomography (CT) volumes, where synthetic tumors are generated and superimposed onto healthy organs, thereby creating an extensive dataset for rigorous validation.","meta":{"url":"http://arxiv.org/abs/2310.16052v1"},"cats":{"benchmark":0.3517648848,"new-dataset":0.3445745502,"data-annotation":0.4915779126,"dev-research":0.2131578065,"llms":0.4410585529,"data-quality":0.1357436305}}
{"text":"Using synthetic data as validation can improve AI robustness in both in-domain and out-domain test sets.","meta":{"url":"http://arxiv.org/abs/2310.16052v1"},"cats":{"benchmark":0.413244751,"new-dataset":0.0682788915,"data-annotation":0.5044109089,"dev-research":0.2637034322,"llms":0.4217043362,"data-quality":0.2519826375}}
{"text":"Furthermore, we establish a new continual learning framework that continuously trains AI models on a stream of out-domain data with synthetic tumors.","meta":{"url":"http://arxiv.org/abs/2310.16052v1"},"cats":{"benchmark":0.1823445583,"new-dataset":0.4281374029,"data-annotation":0.4940378634,"dev-research":0.1481898974,"llms":0.4505791613,"data-quality":0.1131270978}}
{"text":"The AI model trained and validated in dynamically expanding synthetic data can consistently outperform models trained and validated exclusively on real-world data.","meta":{"url":"http://arxiv.org/abs/2310.16052v1"},"cats":{"benchmark":0.2623236196,"new-dataset":0.1375446094,"data-annotation":0.4930135715,"dev-research":0.1850145811,"llms":0.3755378413,"data-quality":0.1489690593}}
{"text":"Specifically, the DSC score for liver tumor segmentation improves from 26.7% (95% CI: 22.6%-30.9%) to 34.5% (30.8%-38.2%) when evaluated on an in-domain dataset and from 31.1% (26.0%-36.2%) to 35.4% (32.1%-38.7%) on an out-domain dataset.","meta":{"url":"http://arxiv.org/abs/2310.16052v1"},"cats":{"benchmark":0.622480369,"new-dataset":0.0884114067,"data-annotation":0.5013275378,"dev-research":0.1857372009,"llms":0.520428404,"data-quality":0.1465344423}}
{"text":"Importantly, the performance gain is particularly significant in identifying very tiny liver tumors (radius < 5mm) in CT volumes, with Sensitivity improving from 33.1% to 55.4% on an in-domain dataset and 33.9% to 52.3% on an out-domain dataset, justifying the efficacy in early detection of cancer.","meta":{"url":"http://arxiv.org/abs/2310.16052v1"},"cats":{"benchmark":0.4664483151,"new-dataset":0.0581865084,"data-annotation":0.5037862596,"dev-research":0.1509536039,"llms":0.5014843304,"data-quality":0.1388874343}}
{"text":"The application of synthetic data, from both training and validation perspectives, underlines a promising avenue to enhance AI robustness when dealing with data from varying domains.","meta":{"url":"http://arxiv.org/abs/2310.16052v1"},"cats":{"benchmark":0.3062007711,"new-dataset":0.1125263958,"data-annotation":0.4922878711,"dev-research":0.2225190203,"llms":0.3787503852,"data-quality":0.2495597625}}
{"text":"If a robot masters folding a kitchen towel, we would also expect it to master folding a beach towel.","meta":{"url":"http://arxiv.org/abs/2310.16050v1"},"cats":{"benchmark":0.2373573047,"new-dataset":0.0196324812,"data-annotation":0.513259965,"dev-research":0.1877843777,"llms":0.5492667451,"data-quality":0.076947816}}
{"text":"However, existing works for policy learning that rely on data set augmentations are still limited in achieving this level of generalization.","meta":{"url":"http://arxiv.org/abs/2310.16050v1"},"cats":{"benchmark":0.2346985734,"new-dataset":0.0396785155,"data-annotation":0.4878488943,"dev-research":0.1757866403,"llms":0.4674535267,"data-quality":0.1580082184}}
{"text":"Our insight is to add equivariance to both the visual object representation and policy architecture.","meta":{"url":"http://arxiv.org/abs/2310.16050v1"},"cats":{"benchmark":0.2249847357,"new-dataset":0.0279199314,"data-annotation":0.5079782031,"dev-research":0.1881840064,"llms":0.4875475438,"data-quality":0.0958134467}}
{"text":"We propose EquivAct which utilizes SIM(3)-equivariant network structures that guarantee generalization across all possible object translations, 3D rotations, and scales by construction.","meta":{"url":"http://arxiv.org/abs/2310.16050v1"},"cats":{"benchmark":0.2275956625,"new-dataset":0.1094868379,"data-annotation":0.517400271,"dev-research":0.1178132207,"llms":0.5025884468,"data-quality":0.0939002304}}
{"text":"Training of EquivAct is done in two phases.","meta":{"url":"http://arxiv.org/abs/2310.16050v1"},"cats":{"benchmark":0.2370033771,"new-dataset":0.0158992314,"data-annotation":0.5137432143,"dev-research":0.1270593115,"llms":0.5299939728,"data-quality":0.0851065964}}
{"text":"We first pre-train a SIM(3)-equivariant visual representation on simulated scene point clouds.","meta":{"url":"http://arxiv.org/abs/2310.16050v1"},"cats":{"benchmark":0.2145150258,"new-dataset":0.2382827039,"data-annotation":0.5258622344,"dev-research":0.1309646256,"llms":0.4727114933,"data-quality":0.0943940336}}
{"text":"Then, we learn a SIM(3)-equivariant visuomotor policy on top of the pre-trained visual representation using a small amount of source task demonstrations.","meta":{"url":"http://arxiv.org/abs/2310.16050v1"},"cats":{"benchmark":0.1310144728,"new-dataset":0.0563626103,"data-annotation":0.5234748074,"dev-research":0.1629910902,"llms":0.5347144841,"data-quality":0.0510845363}}
{"text":"We demonstrate that after training, the learned policy directly transfers to objects that substantially differ in scale, position and orientation from the source demonstrations.","meta":{"url":"http://arxiv.org/abs/2310.16050v1"},"cats":{"benchmark":0.1606893218,"new-dataset":0.1039716342,"data-annotation":0.5122318857,"dev-research":0.1770059437,"llms":0.5372779692,"data-quality":0.0888115073}}
{"text":"In simulation, we evaluate our method in three manipulation tasks involving deformable and articulated objects thereby going beyond the typical rigid object manipulation tasks that prior works considered.","meta":{"url":"http://arxiv.org/abs/2310.16050v1"},"cats":{"benchmark":0.3314727729,"new-dataset":0.0474154837,"data-annotation":0.5148809184,"dev-research":0.2001632511,"llms":0.483927294,"data-quality":0.0540775717}}
{"text":"We show that our method outperforms prior works that do not use equivariant architectures or do not use our contrastive pre-training procedure.","meta":{"url":"http://arxiv.org/abs/2310.16050v1"},"cats":{"benchmark":0.5076883512,"new-dataset":0.0102677589,"data-annotation":0.536795362,"dev-research":0.1319353659,"llms":0.4832068165,"data-quality":0.1680529196}}
{"text":"We also show quantitative and qualitative experiments on three real robot tasks, where the robot watches twenty demonstrations of a tabletop task and transfers zero-shot to a mobile manipulation task in a much larger setup.","meta":{"url":"http://arxiv.org/abs/2310.16050v1"},"cats":{"benchmark":0.2345516991,"new-dataset":0.0953931184,"data-annotation":0.5209721962,"dev-research":0.2208217403,"llms":0.5107128832,"data-quality":0.0493297695}}
{"text":"Project website: https://equivact.github.io","meta":{"url":"http://arxiv.org/abs/2310.16050v1"},"cats":{"benchmark":0.2307407457,"new-dataset":0.468109155,"data-annotation":0.5168571763,"dev-research":0.2527414439,"llms":0.5558812373,"data-quality":0.0955865343}}
{"text":"While large language models (LLMs) equipped with techniques like chain-of-thought prompting have demonstrated impressive capabilities, they still fall short in their ability to reason robustly in complex settings.","meta":{"url":"http://arxiv.org/abs/2310.16049v1"},"cats":{"benchmark":0.1725492548,"new-dataset":0.0132751904,"data-annotation":0.5333250941,"dev-research":0.2521463815,"llms":0.770073346,"data-quality":0.1406539085}}
{"text":"However, evaluating LLM reasoning is challenging because system capabilities continue to grow while benchmark datasets for tasks like logical deduction have remained static.","meta":{"url":"http://arxiv.org/abs/2310.16049v1"},"cats":{"benchmark":0.4306142356,"new-dataset":0.047676455,"data-annotation":0.4931801817,"dev-research":0.2617899781,"llms":0.7304264177,"data-quality":0.1010034651}}
{"text":"We introduce MuSR, a dataset for evaluating language models on multistep soft reasoning tasks specified in a natural language narrative.","meta":{"url":"http://arxiv.org/abs/2310.16049v1"},"cats":{"benchmark":0.2500237548,"new-dataset":0.4602577919,"data-annotation":0.5274117776,"dev-research":0.2534262706,"llms":0.5736018201,"data-quality":0.1087720083}}
{"text":"This dataset has two crucial features.","meta":{"url":"http://arxiv.org/abs/2310.16049v1"},"cats":{"benchmark":0.2853504424,"new-dataset":0.7965815337,"data-annotation":0.4873275241,"dev-research":0.1477068541,"llms":0.4347945137,"data-quality":0.1554815912}}
{"text":"First, it is created through a novel neurosymbolic synthetic-to-natural generation algorithm, enabling the construction of complex reasoning instances that challenge GPT-4 (e.g., murder mysteries roughly 1000 words in length) and which can be scaled further as more capable LLMs are released.","meta":{"url":"http://arxiv.org/abs/2310.16049v1"},"cats":{"benchmark":0.1686291074,"new-dataset":0.1310388219,"data-annotation":0.5313612171,"dev-research":0.1689800519,"llms":0.6390678532,"data-quality":0.1133563366}}
{"text":"Second, our dataset instances are free text narratives corresponding to real-world domains of reasoning; this makes it simultaneously much more challenging than other synthetically-crafted benchmarks while remaining realistic and tractable for human annotators to solve with high accuracy.","meta":{"url":"http://arxiv.org/abs/2310.16049v1"},"cats":{"benchmark":0.258938972,"new-dataset":0.8367541027,"data-annotation":0.5368644446,"dev-research":0.3032957901,"llms":0.5560291688,"data-quality":0.236293173}}
{"text":"We evaluate a range of LLMs and prompting techniques on this dataset and characterize the gaps that remain for techniques like chain-of-thought to perform robust reasoning.","meta":{"url":"http://arxiv.org/abs/2310.16049v1"},"cats":{"benchmark":0.2130270659,"new-dataset":0.1141404311,"data-annotation":0.508115349,"dev-research":0.2802462613,"llms":0.7151405386,"data-quality":0.1862802352}}
{"text":"Aligning AI agents to human intentions and values is a key bottleneck in building safe and deployable AI applications.","meta":{"url":"http://arxiv.org/abs/2310.16048v1"},"cats":{"benchmark":0.2450474446,"new-dataset":0.0572063134,"data-annotation":0.5261443859,"dev-research":0.3246004876,"llms":0.5209222118,"data-quality":0.1232293155}}
{"text":"But whose values should AI agents be aligned with?","meta":{"url":"http://arxiv.org/abs/2310.16048v1"},"cats":{"benchmark":0.3142951294,"new-dataset":0.0372514858,"data-annotation":0.521543827,"dev-research":0.1801797984,"llms":0.4600847455,"data-quality":0.0970870109}}
{"text":"Reinforcement learning with human feedback (RLHF) has emerged as the key framework for AI alignment.","meta":{"url":"http://arxiv.org/abs/2310.16048v1"},"cats":{"benchmark":0.3328645051,"new-dataset":0.1487270405,"data-annotation":0.5179439365,"dev-research":0.1815149417,"llms":0.4003848892,"data-quality":0.1256219383}}
{"text":"RLHF uses feedback from human reinforcers to fine-tune outputs; all widely deployed large language models (LLMs) use RLHF to align their outputs to human values.","meta":{"url":"http://arxiv.org/abs/2310.16048v1"},"cats":{"benchmark":0.2672307068,"new-dataset":0.1081555108,"data-annotation":0.5215534187,"dev-research":0.1636779721,"llms":0.6286021607,"data-quality":0.1927589981}}
{"text":"It is critical to understand the limitations of RLHF and consider policy challenges arising from these limitations.","meta":{"url":"http://arxiv.org/abs/2310.16048v1"},"cats":{"benchmark":0.2601822179,"new-dataset":0.0326103004,"data-annotation":0.49017226,"dev-research":0.1904314096,"llms":0.4900999992,"data-quality":0.0692104266}}
{"text":"In this paper, we investigate a specific challenge in building RLHF systems that respect democratic norms.","meta":{"url":"http://arxiv.org/abs/2310.16048v1"},"cats":{"benchmark":0.2624317073,"new-dataset":0.1978329401,"data-annotation":0.502933987,"dev-research":0.1502906633,"llms":0.4993853725,"data-quality":0.1049107029}}
{"text":"Building on impossibility results in social choice theory, we show that, under fairly broad assumptions, there is no unique voting protocol to universally align AI systems using RLHF through democratic processes.","meta":{"url":"http://arxiv.org/abs/2310.16048v1"},"cats":{"benchmark":0.2898461683,"new-dataset":0.0140018605,"data-annotation":0.4994284242,"dev-research":0.1447910691,"llms":0.4856108255,"data-quality":0.097815996}}
{"text":"Further, we show that aligning AI agents with the values of all individuals will always violate certain private ethical preferences of an individual user i.e., universal AI alignment using RLHF is impossible.","meta":{"url":"http://arxiv.org/abs/2310.16048v1"},"cats":{"benchmark":0.3164016938,"new-dataset":0.0728705758,"data-annotation":0.5341377895,"dev-research":0.1503920826,"llms":0.4931995006,"data-quality":0.1153963812}}
{"text":"We discuss policy implications for the governance of AI systems built using RLHF: first, the need for mandating transparent voting rules to hold model builders accountable.","meta":{"url":"http://arxiv.org/abs/2310.16048v1"},"cats":{"benchmark":0.2394934686,"new-dataset":0.0831941653,"data-annotation":0.4905913695,"dev-research":0.2975644502,"llms":0.4875296647,"data-quality":0.1394929856}}
{"text":"Second, the need for model builders to focus on developing AI agents that are narrowly aligned to specific user groups.","meta":{"url":"http://arxiv.org/abs/2310.16048v1"},"cats":{"benchmark":0.1828721863,"new-dataset":0.0265494065,"data-annotation":0.5256228939,"dev-research":0.3563548897,"llms":0.5189088617,"data-quality":0.0515924632}}
{"text":"Image restoration problems are typically ill-posed in the sense that each degraded image can be restored in infinitely many valid ways.","meta":{"url":"http://arxiv.org/abs/2310.16047v1"},"cats":{"benchmark":0.4081539943,"new-dataset":0.025244156,"data-annotation":0.5068035555,"dev-research":0.2294148104,"llms":0.4555081654,"data-quality":0.266075446}}
{"text":"To accommodate this, many works generate a diverse set of outputs by attempting to randomly sample from the posterior distribution of natural images given the degraded input.","meta":{"url":"http://arxiv.org/abs/2310.16047v1"},"cats":{"benchmark":0.3304843091,"new-dataset":0.1559329775,"data-annotation":0.5210850692,"dev-research":0.1207467587,"llms":0.503443546,"data-quality":0.2813167287}}
{"text":"Here we argue that this strategy is commonly of limited practical value because of the heavy tail of the posterior distribution.","meta":{"url":"http://arxiv.org/abs/2310.16047v1"},"cats":{"benchmark":0.4677773711,"new-dataset":0.005374765,"data-annotation":0.511813347,"dev-research":0.0903492285,"llms":0.4923052196,"data-quality":0.0817538935}}
{"text":"Consider for example inpainting a missing region of the sky in an image.","meta":{"url":"http://arxiv.org/abs/2310.16047v1"},"cats":{"benchmark":0.3232270636,"new-dataset":0.0113932642,"data-annotation":0.5233283045,"dev-research":0.1908634093,"llms":0.4736197683,"data-quality":0.1394480972}}
{"text":"Since there is a high probability that the missing region contains no object but clouds, any set of samples from the posterior would be entirely dominated by (practically identical) completions of sky.","meta":{"url":"http://arxiv.org/abs/2310.16047v1"},"cats":{"benchmark":0.33821963,"new-dataset":0.0273147067,"data-annotation":0.4917790974,"dev-research":0.1098919788,"llms":0.5412940041,"data-quality":0.1394043666}}
{"text":"However, arguably, presenting users with only one clear sky completion, along with several alternative solutions such as airships, birds, and balloons, would better outline the set of possibilities.","meta":{"url":"http://arxiv.org/abs/2310.16047v1"},"cats":{"benchmark":0.2955429837,"new-dataset":0.0134331717,"data-annotation":0.5073478069,"dev-research":0.2234544874,"llms":0.4945977022,"data-quality":0.0930525827}}
{"text":"In this paper, we initiate the study of meaningfully diverse image restoration.","meta":{"url":"http://arxiv.org/abs/2310.16047v1"},"cats":{"benchmark":0.4233459563,"new-dataset":0.0969204062,"data-annotation":0.4935942444,"dev-research":0.1348628889,"llms":0.4220698691,"data-quality":0.1715668954}}
{"text":"We explore several post-processing approaches that can be combined with any diverse image restoration method to yield semantically meaningful diversity.","meta":{"url":"http://arxiv.org/abs/2310.16047v1"},"cats":{"benchmark":0.3469052676,"new-dataset":0.0710855734,"data-annotation":0.4928915176,"dev-research":0.1513072649,"llms":0.4769849168,"data-quality":0.2234511816}}
{"text":"Moreover, we propose a practical approach for allowing diffusion based image restoration methods to generate meaningfully diverse outputs, while incurring only negligent computational overhead.","meta":{"url":"http://arxiv.org/abs/2310.16047v1"},"cats":{"benchmark":0.5250819924,"new-dataset":0.0274727202,"data-annotation":0.4930945931,"dev-research":0.1560367968,"llms":0.3947635291,"data-quality":0.1432956066}}
{"text":"We conduct extensive user studies to analyze the proposed techniques, and find the strategy of reducing similarity between outputs to be significantly favorable over posterior sampling.","meta":{"url":"http://arxiv.org/abs/2310.16047v1"},"cats":{"benchmark":0.6013296844,"new-dataset":0.0263423877,"data-annotation":0.5186284121,"dev-research":0.1843364708,"llms":0.4871849683,"data-quality":0.1763765975}}
{"text":"Code and examples are available in https://noa-cohen.github.io/MeaningfulDiversityInIR","meta":{"url":"http://arxiv.org/abs/2310.16047v1"},"cats":{"benchmark":0.2807775857,"new-dataset":0.2902424846,"data-annotation":0.5193127483,"dev-research":0.2393596541,"llms":0.5970178019,"data-quality":0.1534436234}}
{"text":"Our ability to use deep learning approaches to decipher neural activity would likely benefit from greater scale, in terms of both model size and datasets.","meta":{"url":"http://arxiv.org/abs/2310.16046v1"},"cats":{"benchmark":0.2559100491,"new-dataset":0.0373597338,"data-annotation":0.4974703169,"dev-research":0.1278805174,"llms":0.4612808464,"data-quality":0.0590879423}}
{"text":"However, the integration of many neural recordings into one unified model is challenging, as each recording contains the activity of different neurons from different individual animals.","meta":{"url":"http://arxiv.org/abs/2310.16046v1"},"cats":{"benchmark":0.2938064239,"new-dataset":0.0512330487,"data-annotation":0.4954136384,"dev-research":0.1448217778,"llms":0.4685266874,"data-quality":0.1304149308}}
{"text":"In this paper, we introduce a training framework and architecture designed to model the population dynamics of neural activity across diverse, large-scale neural recordings.","meta":{"url":"http://arxiv.org/abs/2310.16046v1"},"cats":{"benchmark":0.2442258441,"new-dataset":0.2049508905,"data-annotation":0.5088494402,"dev-research":0.1067272972,"llms":0.4521480217,"data-quality":0.0821056389}}
{"text":"Our method first tokenizes individual spikes within the dataset to build an efficient representation of neural events that captures the fine temporal structure of neural activity.","meta":{"url":"http://arxiv.org/abs/2310.16046v1"},"cats":{"benchmark":0.2939837641,"new-dataset":0.4268163212,"data-annotation":0.5160371056,"dev-research":0.2202630415,"llms":0.4696964941,"data-quality":0.1694521799}}
{"text":"We then employ cross-attention and a PerceiverIO backbone to further construct a latent tokenization of neural population activities.","meta":{"url":"http://arxiv.org/abs/2310.16046v1"},"cats":{"benchmark":0.1838604371,"new-dataset":0.0147308791,"data-annotation":0.5256725201,"dev-research":0.1492058886,"llms":0.5176568982,"data-quality":0.100910161}}
{"text":"Utilizing this architecture and training framework, we construct a large-scale multi-session model trained on large datasets from seven nonhuman primates, spanning over 158 different sessions of recording from over 27,373 neural units and over 100 hours of recordings.","meta":{"url":"http://arxiv.org/abs/2310.16046v1"},"cats":{"benchmark":0.2729041322,"new-dataset":0.691012593,"data-annotation":0.4983958871,"dev-research":0.1151755629,"llms":0.5158375137,"data-quality":0.0948380456}}
{"text":"In a number of different tasks, we demonstrate that our pretrained model can be rapidly adapted to new, unseen sessions with unspecified neuron correspondence, enabling few-shot performance with minimal labels.","meta":{"url":"http://arxiv.org/abs/2310.16046v1"},"cats":{"benchmark":0.2757813625,"new-dataset":0.0633058998,"data-annotation":0.5128480516,"dev-research":0.1490777186,"llms":0.5341416992,"data-quality":0.1371743072}}
{"text":"This work presents a powerful new approach for building deep learning tools to analyze neural data and stakes out a clear path to training at scale.","meta":{"url":"http://arxiv.org/abs/2310.16046v1"},"cats":{"benchmark":0.3264213155,"new-dataset":0.3408106862,"data-annotation":0.4995908274,"dev-research":0.1796428588,"llms":0.4821995231,"data-quality":0.193468862}}
{"text":"Hallucination is a big shadow hanging over the rapidly evolving Multimodal Large Language Models (MLLMs), referring to the phenomenon that the generated text is inconsistent with the image content.","meta":{"url":"http://arxiv.org/abs/2310.16045v1"},"cats":{"benchmark":0.1811609756,"new-dataset":0.1015254115,"data-annotation":0.5261780092,"dev-research":0.220363814,"llms":0.5737734122,"data-quality":0.220174143}}
{"text":"In order to mitigate hallucinations, existing studies mainly resort to an instruction-tuning manner that requires retraining the models with specific data.","meta":{"url":"http://arxiv.org/abs/2310.16045v1"},"cats":{"benchmark":0.2695125473,"new-dataset":0.0130990205,"data-annotation":0.5101688905,"dev-research":0.3377525741,"llms":0.5777495264,"data-quality":0.0941293947}}
{"text":"In this paper, we pave a different way, introducing a training-free method named Woodpecker.","meta":{"url":"http://arxiv.org/abs/2310.16045v1"},"cats":{"benchmark":0.3211515538,"new-dataset":0.0537200821,"data-annotation":0.5404548955,"dev-research":0.1732063623,"llms":0.5186460469,"data-quality":0.1112169852}}
{"text":"Like a woodpecker heals trees, it picks out and corrects hallucinations from the generated text.","meta":{"url":"http://arxiv.org/abs/2310.16045v1"},"cats":{"benchmark":0.221493783,"new-dataset":0.0311991081,"data-annotation":0.525974054,"dev-research":0.2717517072,"llms":0.6167652329,"data-quality":0.3017074984}}
{"text":"Concretely, Woodpecker consists of five stages: key concept extraction, question formulation, visual knowledge validation, visual claim generation, and hallucination correction.","meta":{"url":"http://arxiv.org/abs/2310.16045v1"},"cats":{"benchmark":0.2511839777,"new-dataset":0.0972062972,"data-annotation":0.5109997159,"dev-research":0.2543240272,"llms":0.533619384,"data-quality":0.1635526536}}
{"text":"Implemented in a post-remedy manner, Woodpecker can easily serve different MLLMs, while being interpretable by accessing intermediate outputs of the five stages.","meta":{"url":"http://arxiv.org/abs/2310.16045v1"},"cats":{"benchmark":0.3727633287,"new-dataset":0.036646271,"data-annotation":0.5061208509,"dev-research":0.163349785,"llms":0.5244330742,"data-quality":0.1298845729}}
{"text":"We evaluate Woodpecker both quantitatively and qualitatively and show the huge potential of this new paradigm.","meta":{"url":"http://arxiv.org/abs/2310.16045v1"},"cats":{"benchmark":0.3880197982,"new-dataset":0.0768364833,"data-annotation":0.5315316075,"dev-research":0.1667409723,"llms":0.5118409957,"data-quality":0.0907575076}}
{"text":"On the POPE benchmark, our method obtains a 30.66%/24.33% improvement in accuracy over the baseline MiniGPT-4/mPLUG-Owl.","meta":{"url":"http://arxiv.org/abs/2310.16045v1"},"cats":{"benchmark":0.676890636,"new-dataset":0.0976941888,"data-annotation":0.5361335731,"dev-research":0.1144914307,"llms":0.5113026996,"data-quality":0.1862613508}}
{"text":"The source code is released at https://github.com/BradyFU/Woodpecker.","meta":{"url":"http://arxiv.org/abs/2310.16045v1"},"cats":{"benchmark":0.2608132992,"new-dataset":0.3902620079,"data-annotation":0.5429566362,"dev-research":0.2001023343,"llms":0.5155309579,"data-quality":0.1266000627}}
{"text":"We introduce Stanford-ORB, a new real-world 3D Object inverse Rendering Benchmark.","meta":{"url":"http://arxiv.org/abs/2310.16044v1"},"cats":{"benchmark":0.463198561,"new-dataset":0.1308669898,"data-annotation":0.5196080887,"dev-research":0.1515230371,"llms":0.4132825992,"data-quality":0.1098075622}}
{"text":"Recent advances in inverse rendering have enabled a wide range of real-world applications in 3D content generation, moving rapidly from research and commercial use cases to consumer devices.","meta":{"url":"http://arxiv.org/abs/2310.16044v1"},"cats":{"benchmark":0.3147053776,"new-dataset":0.0522830188,"data-annotation":0.5044777172,"dev-research":0.1789357532,"llms":0.4908462634,"data-quality":0.070985093}}
{"text":"While the results continue to improve, there is no real-world benchmark that can quantitatively assess and compare the performance of various inverse rendering methods.","meta":{"url":"http://arxiv.org/abs/2310.16044v1"},"cats":{"benchmark":0.7165005895,"new-dataset":0.0328298904,"data-annotation":0.5355804187,"dev-research":0.1534829491,"llms":0.4161532652,"data-quality":0.1050132527}}
{"text":"Existing real-world datasets typically only consist of the shape and multi-view images of objects, which are not sufficient for evaluating the quality of material recovery and object relighting.","meta":{"url":"http://arxiv.org/abs/2310.16044v1"},"cats":{"benchmark":0.3101637945,"new-dataset":0.3694473639,"data-annotation":0.5040780435,"dev-research":0.1913278759,"llms":0.4539267574,"data-quality":0.2192672665}}
{"text":"Methods capable of recovering material and lighting often resort to synthetic data for quantitative evaluation, which on the other hand does not guarantee generalization to complex real-world environments.","meta":{"url":"http://arxiv.org/abs/2310.16044v1"},"cats":{"benchmark":0.4290945438,"new-dataset":0.0460399464,"data-annotation":0.5106409252,"dev-research":0.2084112151,"llms":0.4129554042,"data-quality":0.1281630776}}
{"text":"We introduce a new dataset of real-world objects captured under a variety of natural scenes with ground-truth 3D scans, multi-view images, and environment lighting.","meta":{"url":"http://arxiv.org/abs/2310.16044v1"},"cats":{"benchmark":0.2010267028,"new-dataset":0.888973927,"data-annotation":0.4926439778,"dev-research":0.1380068268,"llms":0.4788474579,"data-quality":0.0956054962}}
{"text":"Using this dataset, we establish the first comprehensive real-world evaluation benchmark for object inverse rendering tasks from in-the-wild scenes, and compare the performance of various existing methods.","meta":{"url":"http://arxiv.org/abs/2310.16044v1"},"cats":{"benchmark":0.5546887613,"new-dataset":0.2495124134,"data-annotation":0.5298897457,"dev-research":0.1624604729,"llms":0.4363547555,"data-quality":0.1352432393}}
{"text":"All data, code, and models can be accessed at https://stanfordorb.github.io/.","meta":{"url":"http://arxiv.org/abs/2310.16044v1"},"cats":{"benchmark":0.3064298496,"new-dataset":0.4509270769,"data-annotation":0.5209019736,"dev-research":0.1339414432,"llms":0.5162856485,"data-quality":0.0978925031}}
{"text":"The paper investigates using a Large Language Model (LLM) to automatically perform web software tasks using click, scroll, and text input operations.","meta":{"url":"http://arxiv.org/abs/2310.16042v1"},"cats":{"benchmark":0.2904439595,"new-dataset":0.0524090637,"data-annotation":0.5193786632,"dev-research":0.3120594636,"llms":0.6419090012,"data-quality":0.1187411258}}
{"text":"Previous approaches, such as reinforcement learning (RL) or imitation learning, are inefficient to train and task-specific.","meta":{"url":"http://arxiv.org/abs/2310.16042v1"},"cats":{"benchmark":0.3014349766,"new-dataset":0.004767186,"data-annotation":0.5238431305,"dev-research":0.1932024004,"llms":0.4497282478,"data-quality":0.0635762178}}
{"text":"Our method uses filtered Document Object Model (DOM) elements as observations and performs tasks step-by-step, sequentially generating small programs based on the current observations.","meta":{"url":"http://arxiv.org/abs/2310.16042v1"},"cats":{"benchmark":0.4058349892,"new-dataset":0.1256161852,"data-annotation":0.5114354666,"dev-research":0.3112795883,"llms":0.520508705,"data-quality":0.0849259487}}
{"text":"We use in-context learning, either benefiting from a single manually provided example, or an automatically generated example based on a successful zero-shot trial.","meta":{"url":"http://arxiv.org/abs/2310.16042v1"},"cats":{"benchmark":0.3024211785,"new-dataset":0.0552467776,"data-annotation":0.5451020397,"dev-research":0.2081842406,"llms":0.5291265114,"data-quality":0.2126268801}}
{"text":"We evaluate the proposed method on the MiniWob++ benchmark.","meta":{"url":"http://arxiv.org/abs/2310.16042v1"},"cats":{"benchmark":0.7755825522,"new-dataset":0.0365915596,"data-annotation":0.5515760662,"dev-research":0.1477437122,"llms":0.4246260069,"data-quality":0.139722009}}
{"text":"With only one in-context example, our WebWISE method achieves similar or better performance than other methods that require many demonstrations or trials.","meta":{"url":"http://arxiv.org/abs/2310.16042v1"},"cats":{"benchmark":0.4637339119,"new-dataset":0.0046913725,"data-annotation":0.5236443207,"dev-research":0.1950899492,"llms":0.4948710881,"data-quality":0.0703330012}}
{"text":"Large language models with instruction-following capabilities open the door to a wider group of users.","meta":{"url":"http://arxiv.org/abs/2310.16040v1"},"cats":{"benchmark":0.1622187273,"new-dataset":0.1338044991,"data-annotation":0.5331577733,"dev-research":0.2635312543,"llms":0.6171049925,"data-quality":0.0683768517}}
{"text":"However, when it comes to information extraction - a classic task in natural language processing - most task-specific systems cannot align well with long-tail ad hoc extraction use cases for non-expert users.","meta":{"url":"http://arxiv.org/abs/2310.16040v1"},"cats":{"benchmark":0.3335450049,"new-dataset":0.0176459424,"data-annotation":0.5259600911,"dev-research":0.2663605557,"llms":0.5479517363,"data-quality":0.2425167264}}
{"text":"To address this, we propose a novel paradigm, termed On-Demand Information Extraction, to fulfill the personalized demands of real-world users.","meta":{"url":"http://arxiv.org/abs/2310.16040v1"},"cats":{"benchmark":0.3330142553,"new-dataset":0.1001767736,"data-annotation":0.5014482179,"dev-research":0.2308626113,"llms":0.4412093138,"data-quality":0.1543934183}}
{"text":"Our task aims to follow the instructions to extract the desired content from the associated text and present it in a structured tabular format.","meta":{"url":"http://arxiv.org/abs/2310.16040v1"},"cats":{"benchmark":0.3466937463,"new-dataset":0.1703822508,"data-annotation":0.4962456424,"dev-research":0.2058874947,"llms":0.4435397496,"data-quality":0.1353372838}}
{"text":"The table headers can either be user-specified or inferred contextually by the model.","meta":{"url":"http://arxiv.org/abs/2310.16040v1"},"cats":{"benchmark":0.3096171001,"new-dataset":0.0271285272,"data-annotation":0.4899201514,"dev-research":0.1652699012,"llms":0.446812445,"data-quality":0.1253285926}}
{"text":"To facilitate research in this emerging area, we present a benchmark named InstructIE, inclusive of both automatically generated training data, as well as the human-annotated test set.","meta":{"url":"http://arxiv.org/abs/2310.16040v1"},"cats":{"benchmark":0.4283972893,"new-dataset":0.6173988437,"data-annotation":0.5461527955,"dev-research":0.2907496025,"llms":0.5123062839,"data-quality":0.3276070068}}
{"text":"Building on InstructIE, we further develop an On-Demand Information Extractor, ODIE.","meta":{"url":"http://arxiv.org/abs/2310.16040v1"},"cats":{"benchmark":0.2764322189,"new-dataset":0.28099785,"data-annotation":0.5027429376,"dev-research":0.2332964237,"llms":0.5546745007,"data-quality":0.1749678966}}
{"text":"Comprehensive evaluations on our benchmark reveal that ODIE substantially outperforms the existing open-source models of similar size.","meta":{"url":"http://arxiv.org/abs/2310.16040v1"},"cats":{"benchmark":0.6026676663,"new-dataset":0.0416240553,"data-annotation":0.5135343568,"dev-research":0.1519993032,"llms":0.5000349897,"data-quality":0.1048964542}}
{"text":"Our code and dataset are released on https://github.com/yzjiao/On-Demand-IE.","meta":{"url":"http://arxiv.org/abs/2310.16040v1"},"cats":{"benchmark":0.2382275564,"new-dataset":0.8887462009,"data-annotation":0.4775943913,"dev-research":0.2235869933,"llms":0.4738509085,"data-quality":0.0922599878}}
{"text":"Recent works such as VisProg and ViperGPT have smartly composed foundation models for visual reasoning-using large language models (LLMs) to produce programs that can be executed by pre-trained vision-language models.","meta":{"url":"http://arxiv.org/abs/2310.16035v1"},"cats":{"benchmark":0.1655411166,"new-dataset":0.3624825066,"data-annotation":0.5353281922,"dev-research":0.310258413,"llms":0.6663109598,"data-quality":0.0981422241}}
{"text":"However, they operate in limited domains, such as 2D images, not fully exploiting the generalization of language: abstract concepts like \"left\" can also be grounded in 3D, temporal, and action data, as in moving to your left.","meta":{"url":"http://arxiv.org/abs/2310.16035v1"},"cats":{"benchmark":0.1203327385,"new-dataset":0.0625882026,"data-annotation":0.5148600009,"dev-research":0.1987728747,"llms":0.5347242257,"data-quality":0.0835134472}}
{"text":"This limited generalization stems from these inference-only methods' inability to learn or adapt pre-trained models to a new domain.","meta":{"url":"http://arxiv.org/abs/2310.16035v1"},"cats":{"benchmark":0.184598374,"new-dataset":0.0021214648,"data-annotation":0.5366474716,"dev-research":0.1805382743,"llms":0.4801975551,"data-quality":0.1295081425}}
{"text":"We propose the Logic-Enhanced Foundation Model (LEFT), a unified framework that learns to ground and reason with concepts across domains with a differentiable, domain-independent, first-order logic-based program executor.","meta":{"url":"http://arxiv.org/abs/2310.16035v1"},"cats":{"benchmark":0.2168240731,"new-dataset":0.181409423,"data-annotation":0.5128447534,"dev-research":0.3588938601,"llms":0.612863321,"data-quality":0.0883547788}}
{"text":"LEFT has an LLM interpreter that outputs a program represented in a general, logic-based reasoning language, which is shared across all domains and tasks.","meta":{"url":"http://arxiv.org/abs/2310.16035v1"},"cats":{"benchmark":0.1663477067,"new-dataset":0.2152349096,"data-annotation":0.5103318957,"dev-research":0.2528704297,"llms":0.7688959828,"data-quality":0.0588430895}}
{"text":"LEFT's executor then executes the program with trainable domain-specific grounding modules.","meta":{"url":"http://arxiv.org/abs/2310.16035v1"},"cats":{"benchmark":0.2478011413,"new-dataset":0.0353152229,"data-annotation":0.5174694684,"dev-research":0.1947604384,"llms":0.6422619902,"data-quality":0.0915461519}}
{"text":"We show that LEFT flexibly learns concepts in four domains: 2D images, 3D scenes, human motions, and robotic manipulation.","meta":{"url":"http://arxiv.org/abs/2310.16035v1"},"cats":{"benchmark":0.1311579078,"new-dataset":0.0877886921,"data-annotation":0.5397084584,"dev-research":0.1552297279,"llms":0.4989864917,"data-quality":0.1050870015}}
{"text":"It exhibits strong reasoning ability in a wide variety of tasks, including those that are complex and not seen during training, and can be easily applied to new domains.","meta":{"url":"http://arxiv.org/abs/2310.16035v1"},"cats":{"benchmark":0.1912452126,"new-dataset":0.0147345651,"data-annotation":0.5325196136,"dev-research":0.2516351143,"llms":0.5885207547,"data-quality":0.0741649478}}
{"text":"Multimodal Large Language Models (LLMs) have recently achieved promising zero-shot accuracy on visual question answering (VQA) -- a fundamental task affecting various downstream applications and domains.","meta":{"url":"http://arxiv.org/abs/2310.16033v1"},"cats":{"benchmark":0.263450565,"new-dataset":0.1358761894,"data-annotation":0.5403862863,"dev-research":0.1465113008,"llms":0.6093176665,"data-quality":0.1842693651}}
{"text":"Given the great potential for the broad use of these models, it is important to investigate their limitations in dealing with different image and question properties.","meta":{"url":"http://arxiv.org/abs/2310.16033v1"},"cats":{"benchmark":0.2841536304,"new-dataset":0.0280436027,"data-annotation":0.5073638916,"dev-research":0.1424284002,"llms":0.4792390246,"data-quality":0.0957985256}}
{"text":"In this work, we investigate whether multimodal LLMs can perceive small details as well as large details in images.","meta":{"url":"http://arxiv.org/abs/2310.16033v1"},"cats":{"benchmark":0.1828093385,"new-dataset":0.0590693282,"data-annotation":0.5064725708,"dev-research":0.1191193948,"llms":0.6553886649,"data-quality":0.1005863155}}
{"text":"In particular, we show that their zero-shot accuracy in answering visual questions is very sensitive to the size of the visual subject of the question, declining up to $46\\%$ with size.","meta":{"url":"http://arxiv.org/abs/2310.16033v1"},"cats":{"benchmark":0.3426458075,"new-dataset":0.0720627584,"data-annotation":0.5603444328,"dev-research":0.2109206005,"llms":0.5292797763,"data-quality":0.2265172535}}
{"text":"Furthermore, we show that this effect is causal by observing that human visual cropping can significantly mitigate their sensitivity to size.","meta":{"url":"http://arxiv.org/abs/2310.16033v1"},"cats":{"benchmark":0.2796052473,"new-dataset":0.0182781093,"data-annotation":0.5219924661,"dev-research":0.2518900565,"llms":0.4268295164,"data-quality":0.1245555185}}
{"text":"Inspired by the usefulness of human cropping, we then propose three automatic visual cropping methods as inference time mechanisms to improve the zero-shot performance of multimodal LLMs.","meta":{"url":"http://arxiv.org/abs/2310.16033v1"},"cats":{"benchmark":0.3078913446,"new-dataset":0.0926324953,"data-annotation":0.5193226095,"dev-research":0.1209664115,"llms":0.5867811292,"data-quality":0.0911459617}}
{"text":"We study their effectiveness on four popular VQA datasets, and a subset of the VQAv2 dataset tailored towards fine visual details.","meta":{"url":"http://arxiv.org/abs/2310.16033v1"},"cats":{"benchmark":0.323375926,"new-dataset":0.7021593528,"data-annotation":0.5102042747,"dev-research":0.2178414056,"llms":0.4442918917,"data-quality":0.1739142638}}
{"text":"Our findings suggest that multimodal LLMs should be used with caution in detail-sensitive VQA applications, and that visual cropping is a promising direction to improve their zero-shot performance.","meta":{"url":"http://arxiv.org/abs/2310.16033v1"},"cats":{"benchmark":0.2970054612,"new-dataset":0.0430301761,"data-annotation":0.493963839,"dev-research":0.1437832082,"llms":0.7069420981,"data-quality":0.1455994677}}
{"text":"Our code and data are publicly available.","meta":{"url":"http://arxiv.org/abs/2310.16033v1"},"cats":{"benchmark":0.1734353871,"new-dataset":0.7337214954,"data-annotation":0.4793043269,"dev-research":0.2418778781,"llms":0.5540491411,"data-quality":0.1049625214}}
{"text":"Reinforcement Learning (RL) is notoriously data-inefficient, which makes training on a real robot difficult.","meta":{"url":"http://arxiv.org/abs/2310.16029v1"},"cats":{"benchmark":0.2101375656,"new-dataset":0.0473091022,"data-annotation":0.5024456022,"dev-research":0.1764674875,"llms":0.4735111466,"data-quality":0.089984404}}
{"text":"While model-based RL algorithms (world models) improve data-efficiency to some extent, they still require hours or days of interaction to learn skills.","meta":{"url":"http://arxiv.org/abs/2310.16029v1"},"cats":{"benchmark":0.2561882834,"new-dataset":0.0261665623,"data-annotation":0.5054750646,"dev-research":0.2066028901,"llms":0.4935379287,"data-quality":0.0412788556}}
{"text":"Recently, offline RL has been proposed as a framework for training RL policies on pre-existing datasets without any online interaction.","meta":{"url":"http://arxiv.org/abs/2310.16029v1"},"cats":{"benchmark":0.2319329201,"new-dataset":0.491112416,"data-annotation":0.4729869336,"dev-research":0.2133785761,"llms":0.4991913605,"data-quality":0.103957224}}
{"text":"However, constraining an algorithm to a fixed dataset induces a state-action distribution shift between training and inference, and limits its applicability to new tasks.","meta":{"url":"http://arxiv.org/abs/2310.16029v1"},"cats":{"benchmark":0.2607382998,"new-dataset":0.0255054956,"data-annotation":0.4867884119,"dev-research":0.1914225632,"llms":0.432820267,"data-quality":0.1157708892}}
{"text":"In this work, we seek to get the best of both worlds: we consider the problem of pretraining a world model with offline data collected on a real robot, and then finetuning the model on online data collected by planning with the learned model.","meta":{"url":"http://arxiv.org/abs/2310.16029v1"},"cats":{"benchmark":0.1883466859,"new-dataset":0.528533069,"data-annotation":0.4949690895,"dev-research":0.1715043299,"llms":0.4667606659,"data-quality":0.0631317268}}
{"text":"To mitigate extrapolation errors during online interaction, we propose to regularize the planner at test-time by balancing estimated returns and (epistemic) model uncertainty.","meta":{"url":"http://arxiv.org/abs/2310.16029v1"},"cats":{"benchmark":0.4895551744,"new-dataset":0.0217558587,"data-annotation":0.502875002,"dev-research":0.2887376562,"llms":0.4153595674,"data-quality":0.1011951597}}
{"text":"We evaluate our method on a variety of visuo-motor control tasks in simulation and on a real robot, and find that our method enables few-shot finetuning to seen and unseen tasks even when offline data is limited.","meta":{"url":"http://arxiv.org/abs/2310.16029v1"},"cats":{"benchmark":0.2602772522,"new-dataset":0.1385709734,"data-annotation":0.5049052411,"dev-research":0.1866585269,"llms":0.4944541507,"data-quality":0.0582928826}}
{"text":"Videos, code, and data are available at https://yunhaifeng.com/FOWM .","meta":{"url":"http://arxiv.org/abs/2310.16029v1"},"cats":{"benchmark":0.1600380357,"new-dataset":0.8584391668,"data-annotation":0.4992278934,"dev-research":0.1667071449,"llms":0.5763332872,"data-quality":0.0746580931}}
{"text":"Large language models exhibit surprising emergent generalization properties, yet also struggle on many simple reasoning tasks such as arithmetic and parity.","meta":{"url":"http://arxiv.org/abs/2310.16028v1"},"cats":{"benchmark":0.2316115788,"new-dataset":0.0240702618,"data-annotation":0.5592257071,"dev-research":0.1756802549,"llms":0.5079625647,"data-quality":0.1756733151}}
{"text":"This raises the question of if and when Transformer models can learn the true algorithm for solving a task.","meta":{"url":"http://arxiv.org/abs/2310.16028v1"},"cats":{"benchmark":0.2967641481,"new-dataset":0.0020425939,"data-annotation":0.5305731848,"dev-research":0.1352925525,"llms":0.4290901476,"data-quality":0.0902406943}}
{"text":"We study the scope of Transformers' abilities in the specific setting of length generalization on algorithmic tasks.","meta":{"url":"http://arxiv.org/abs/2310.16028v1"},"cats":{"benchmark":0.2952727118,"new-dataset":0.0100006539,"data-annotation":0.534225385,"dev-research":0.1779723034,"llms":0.459669042,"data-quality":0.0585628086}}
{"text":"Here, we propose a unifying framework to understand when and how Transformers can exhibit strong length generalization on a given task.","meta":{"url":"http://arxiv.org/abs/2310.16028v1"},"cats":{"benchmark":0.2934046803,"new-dataset":0.0140711724,"data-annotation":0.5336204288,"dev-research":0.1357949292,"llms":0.4621264667,"data-quality":0.0901780337}}
{"text":"Specifically, we leverage RASP (Weiss et al., 2021) -- a programming language designed for the computational model of a Transformer -- and introduce the RASP-Generalization Conjecture:","meta":{"url":"http://arxiv.org/abs/2310.16028v1"},"cats":{"benchmark":0.2887858243,"new-dataset":0.0330224046,"data-annotation":0.5314041904,"dev-research":0.2100945753,"llms":0.4299761515,"data-quality":0.0899562377}}
{"text":"Transformers tend to length generalize on a task if the task can be solved by a short RASP program which works for all input lengths.","meta":{"url":"http://arxiv.org/abs/2310.16028v1"},"cats":{"benchmark":0.2914731576,"new-dataset":0.00840158,"data-annotation":0.5173649475,"dev-research":0.1692237167,"llms":0.4723130515,"data-quality":0.0662428373}}
{"text":"This simple conjecture remarkably captures most known instances of length generalization on algorithmic tasks.","meta":{"url":"http://arxiv.org/abs/2310.16028v1"},"cats":{"benchmark":0.4408515112,"new-dataset":0.034694401,"data-annotation":0.5591805137,"dev-research":0.161741712,"llms":0.4041220441,"data-quality":0.144374403}}
{"text":"Moreover, we leverage our insights to drastically improve generalization performance on traditionally hard tasks (such as parity and addition).","meta":{"url":"http://arxiv.org/abs/2310.16028v1"},"cats":{"benchmark":0.5186715582,"new-dataset":0.0072834095,"data-annotation":0.546315549,"dev-research":0.2481513685,"llms":0.4700870223,"data-quality":0.1210542193}}
{"text":"On the theoretical side, we give a simple example where the \"min-degree-interpolator\" model of learning from Abbe et al.","meta":{"url":"http://arxiv.org/abs/2310.16028v1"},"cats":{"benchmark":0.3868518662,"new-dataset":0.0095931148,"data-annotation":0.539173639,"dev-research":0.1053413202,"llms":0.3788070964,"data-quality":0.1568314742}}
{"text":"(2023) does not correctly predict Transformers' out-of-distribution behavior, but our conjecture does.","meta":{"url":"http://arxiv.org/abs/2310.16028v1"},"cats":{"benchmark":0.2672150757,"new-dataset":0.0540219666,"data-annotation":0.519713376,"dev-research":0.1740451402,"llms":0.5203640661,"data-quality":0.167958014}}
{"text":"Overall, our work provides a novel perspective on the mechanisms of compositional generalization and the algorithmic capabilities of Transformers.","meta":{"url":"http://arxiv.org/abs/2310.16028v1"},"cats":{"benchmark":0.3238068656,"new-dataset":0.0036039511,"data-annotation":0.5203365091,"dev-research":0.1483267196,"llms":0.4811790458,"data-quality":0.0912811708}}
{"text":"Human demonstrations of trajectories are an important source of training data for many machine learning problems.","meta":{"url":"http://arxiv.org/abs/2310.16027v1"},"cats":{"benchmark":0.2290959503,"new-dataset":0.1519768059,"data-annotation":0.5218256842,"dev-research":0.2151648412,"llms":0.3908112982,"data-quality":0.0931231002}}
{"text":"However, the difficulty of collecting human demonstration data for complex tasks makes learning efficient representations of those trajectories challenging.","meta":{"url":"http://arxiv.org/abs/2310.16027v1"},"cats":{"benchmark":0.2205775541,"new-dataset":0.2065306266,"data-annotation":0.5275130595,"dev-research":0.2723355562,"llms":0.4730881722,"data-quality":0.0926810482}}
{"text":"For many problems, such as for handwriting or for quasistatic dexterous manipulation, the exact timings of the trajectories should be factored from their spatial path characteristics.","meta":{"url":"http://arxiv.org/abs/2310.16027v1"},"cats":{"benchmark":0.4103480696,"new-dataset":0.0233666342,"data-annotation":0.529477784,"dev-research":0.2025467997,"llms":0.4352366615,"data-quality":0.0406502192}}
{"text":"In this work, we propose TimewarpVAE, a fully differentiable manifold-learning algorithm that incorporates Dynamic Time Warping (DTW) to simultaneously learn both timing variations and latent factors of spatial variation.","meta":{"url":"http://arxiv.org/abs/2310.16027v1"},"cats":{"benchmark":0.3831154212,"new-dataset":0.1107573655,"data-annotation":0.52761423,"dev-research":0.1692308794,"llms":0.4125063321,"data-quality":0.0766985945}}
{"text":"We show how the TimewarpVAE algorithm learns appropriate time alignments and meaningful representations of spatial variations in small handwriting and fork manipulation datasets.","meta":{"url":"http://arxiv.org/abs/2310.16027v1"},"cats":{"benchmark":0.4254050936,"new-dataset":0.1362141194,"data-annotation":0.5448343264,"dev-research":0.2223058908,"llms":0.4458705659,"data-quality":0.1068828985}}
{"text":"Our results have lower spatial reconstruction test error than baseline approaches and the learned low-dimensional representations can be used to efficiently generate semantically meaningful novel trajectories.","meta":{"url":"http://arxiv.org/abs/2310.16027v1"},"cats":{"benchmark":0.3383805525,"new-dataset":0.2226023473,"data-annotation":0.5203506041,"dev-research":0.1800680164,"llms":0.4485818548,"data-quality":0.128217671}}
{"text":"We define a measure on families of DFAs (FDFAs) that we show to be robust in the sense that two FDFAs for the same language are guaranteed to agree on this measure.","meta":{"url":"http://arxiv.org/abs/2310.16022v1"},"cats":{"benchmark":0.4224578132,"new-dataset":0.1616005673,"data-annotation":0.5454921781,"dev-research":0.1724641331,"llms":0.5118949648,"data-quality":0.3332645235}}
{"text":"This measure tightly relates to the Wagner-Hierarchy (that defines the complexity of omega regular languages).","meta":{"url":"http://arxiv.org/abs/2310.16022v1"},"cats":{"benchmark":0.4645358914,"new-dataset":0.0204315144,"data-annotation":0.534430734,"dev-research":0.1779826943,"llms":0.5157930805,"data-quality":0.0931431121}}
{"text":"Inspired by the recently introduced natural colors of infinite words, we define natural colors for finite words (prefixes of periods of infinite words).","meta":{"url":"http://arxiv.org/abs/2310.16022v1"},"cats":{"benchmark":0.1941484464,"new-dataset":0.3076295122,"data-annotation":0.5156253171,"dev-research":0.1607984412,"llms":0.5379887716,"data-quality":0.1528059672}}
{"text":"From this semantic definition we derive the Colorful FDFA a novel canonical model for $\\omega$-regular languages that also assigns correct colors for finite and infinite words.","meta":{"url":"http://arxiv.org/abs/2310.16022v1"},"cats":{"benchmark":0.2597615935,"new-dataset":0.1258691305,"data-annotation":0.5303620161,"dev-research":0.1835256303,"llms":0.4904821002,"data-quality":0.2130966758}}
{"text":"From the colorful FDFA, for languages that can be recognized by deterministic B\\\"uchi or coB\\\"uchi automata, we generate a canonical DBA or DCA termed the Black $\\&$ White Automaton, thus complementing the recent result on canonical good for games coB\\\"uchi automata for coB\\\"uchi languages.","meta":{"url":"http://arxiv.org/abs/2310.16022v1"},"cats":{"benchmark":0.264106595,"new-dataset":0.2109791679,"data-annotation":0.5251704946,"dev-research":0.1980472,"llms":0.5158810542,"data-quality":0.1878205653}}
{"text":"In this paper, we develop a modular neural network for real-time semantic mapping in uncertain environments, which explicitly updates per-voxel probabilistic distributions within a neural network layer.","meta":{"url":"http://arxiv.org/abs/2310.16020v1"},"cats":{"benchmark":0.2099293475,"new-dataset":0.2079451185,"data-annotation":0.4966029927,"dev-research":0.2599834026,"llms":0.4638917846,"data-quality":0.2017028841}}
{"text":"Our approach combines the reliability of classical probabilistic algorithms with the performance and efficiency of modern neural networks.","meta":{"url":"http://arxiv.org/abs/2310.16020v1"},"cats":{"benchmark":0.5216835553,"new-dataset":0.0187873164,"data-annotation":0.5515385888,"dev-research":0.1772234225,"llms":0.4374425997,"data-quality":0.2467823979}}
{"text":"Although robotic perception is often divided between modern differentiable methods and classical explicit methods, a union of both is necessary for real-time and trustworthy performance.","meta":{"url":"http://arxiv.org/abs/2310.16020v1"},"cats":{"benchmark":0.3945298348,"new-dataset":0.0054437768,"data-annotation":0.5261267778,"dev-research":0.2459835908,"llms":0.4386628353,"data-quality":0.1304551242}}
{"text":"We introduce a novel Convolutional Bayesian Kernel Inference (ConvBKI) layer which incorporates semantic segmentation predictions online into a 3D map through a depthwise convolution layer by leveraging conjugate priors.","meta":{"url":"http://arxiv.org/abs/2310.16020v1"},"cats":{"benchmark":0.2701231212,"new-dataset":0.330636469,"data-annotation":0.5011343608,"dev-research":0.1728832782,"llms":0.43124968,"data-quality":0.0903603997}}
{"text":"We compare ConvBKI against state-of-the-art deep learning approaches and probabilistic algorithms for mapping to evaluate reliability and performance.","meta":{"url":"http://arxiv.org/abs/2310.16020v1"},"cats":{"benchmark":0.4369402736,"new-dataset":0.1089234526,"data-annotation":0.5118037281,"dev-research":0.2465814981,"llms":0.5087784451,"data-quality":0.2230491339}}
{"text":"We also create a Robot Operating System (ROS) package of ConvBKI and test it on real-world perceptually challenging off-road driving data.","meta":{"url":"http://arxiv.org/abs/2310.16020v1"},"cats":{"benchmark":0.2365949468,"new-dataset":0.5581162362,"data-annotation":0.4860027838,"dev-research":0.2477829646,"llms":0.4963982822,"data-quality":0.0549694763}}
{"text":"Imitation learning from human demonstrations can teach robots complex manipulation skills, but is time-consuming and labor intensive.","meta":{"url":"http://arxiv.org/abs/2310.16014v1"},"cats":{"benchmark":0.1848216518,"new-dataset":0.0310699661,"data-annotation":0.5308435355,"dev-research":0.1974721375,"llms":0.5326317004,"data-quality":0.0451210769}}
{"text":"In contrast, Task and Motion Planning (TAMP) systems are automated and excel at solving long-horizon tasks, but they are difficult to apply to contact-rich tasks.","meta":{"url":"http://arxiv.org/abs/2310.16014v1"},"cats":{"benchmark":0.2414784991,"new-dataset":0.0278139559,"data-annotation":0.4845891408,"dev-research":0.2891552589,"llms":0.5173998062,"data-quality":0.0412785341}}
{"text":"In this paper, we present Human-in-the-Loop Task and Motion Planning (HITL-TAMP), a novel system that leverages the benefits of both approaches.","meta":{"url":"http://arxiv.org/abs/2310.16014v1"},"cats":{"benchmark":0.2506878296,"new-dataset":0.3468623214,"data-annotation":0.4969478889,"dev-research":0.3183644423,"llms":0.5110893414,"data-quality":0.0379863253}}
{"text":"The system employs a TAMP-gated control mechanism, which selectively gives and takes control to and from a human teleoperator.","meta":{"url":"http://arxiv.org/abs/2310.16014v1"},"cats":{"benchmark":0.1574561483,"new-dataset":0.0124965323,"data-annotation":0.4808430983,"dev-research":0.1727305897,"llms":0.5625418397,"data-quality":0.0415151016}}
{"text":"This enables the human teleoperator to manage a fleet of robots, maximizing data collection efficiency.","meta":{"url":"http://arxiv.org/abs/2310.16014v1"},"cats":{"benchmark":0.2074573258,"new-dataset":0.1016058678,"data-annotation":0.4630184745,"dev-research":0.2018185782,"llms":0.5315384618,"data-quality":0.0384196152}}
{"text":"The collected human data is then combined with an imitation learning framework to train a TAMP-gated policy, leading to superior performance compared to training on full task demonstrations.","meta":{"url":"http://arxiv.org/abs/2310.16014v1"},"cats":{"benchmark":0.1995517285,"new-dataset":0.1889635772,"data-annotation":0.4829376323,"dev-research":0.1626197931,"llms":0.5071021607,"data-quality":0.0689735108}}
{"text":"We compared HITL-TAMP to a conventional teleoperation system -- users gathered more than 3x the number of demos given the same time budget.","meta":{"url":"http://arxiv.org/abs/2310.16014v1"},"cats":{"benchmark":0.2958980622,"new-dataset":0.126723899,"data-annotation":0.4965806118,"dev-research":0.2434808147,"llms":0.5920255949,"data-quality":0.0487502103}}
{"text":"Furthermore, proficient agents (75\\%+ success) could be trained from just 10 minutes of non-expert teleoperation data.","meta":{"url":"http://arxiv.org/abs/2310.16014v1"},"cats":{"benchmark":0.2388308353,"new-dataset":0.0469555994,"data-annotation":0.516481109,"dev-research":0.1557951802,"llms":0.5391147374,"data-quality":0.0625746082}}
{"text":"Finally, we collected 2.1K demos with HITL-TAMP across 12 contact-rich, long-horizon tasks and show that the system often produces near-perfect agents.","meta":{"url":"http://arxiv.org/abs/2310.16014v1"},"cats":{"benchmark":0.353650104,"new-dataset":0.4980837886,"data-annotation":0.5181175101,"dev-research":0.1594613259,"llms":0.617858496,"data-quality":0.0828623188}}
{"text":"Videos and additional results at https://hitltamp.github.io .","meta":{"url":"http://arxiv.org/abs/2310.16014v1"},"cats":{"benchmark":0.4746997057,"new-dataset":0.3868816606,"data-annotation":0.5319502127,"dev-research":0.1851768963,"llms":0.5260809566,"data-quality":0.1180792077}}
{"text":"We introduce MLFMF, a collection of data sets for benchmarking recommendation systems used to support formalization of mathematics with proof assistants.","meta":{"url":"http://arxiv.org/abs/2310.16005v1"},"cats":{"benchmark":0.5947484745,"new-dataset":0.3328617819,"data-annotation":0.5524911548,"dev-research":0.2481189617,"llms":0.4369307831,"data-quality":0.1607959428}}
{"text":"These systems help humans identify which previous entries (theorems, constructions, datatypes, and postulates) are relevant in proving a new theorem or carrying out a new construction.","meta":{"url":"http://arxiv.org/abs/2310.16005v1"},"cats":{"benchmark":0.2720729609,"new-dataset":0.0601367397,"data-annotation":0.5104244049,"dev-research":0.3238529485,"llms":0.5038495004,"data-quality":0.1344581214}}
{"text":"Each data set is derived from a library of formalized mathematics written in proof assistants Agda or Lean.","meta":{"url":"http://arxiv.org/abs/2310.16005v1"},"cats":{"benchmark":0.351937211,"new-dataset":0.6444559843,"data-annotation":0.5134100631,"dev-research":0.2384510417,"llms":0.4786293831,"data-quality":0.1154814335}}
{"text":"The collection includes the largest Lean~4 library Mathlib, and some of the largest Agda libraries: the standard library, the library of univalent mathematics Agda-unimath, and the TypeTopology library.","meta":{"url":"http://arxiv.org/abs/2310.16005v1"},"cats":{"benchmark":0.3356867567,"new-dataset":0.5105709963,"data-annotation":0.5376199641,"dev-research":0.1677418366,"llms":0.5471155382,"data-quality":0.1112376542}}
{"text":"Each data set represents the corresponding library in two ways: as a heterogeneous network, and as a list of s-expressions representing the syntax trees of all the entries in the library.","meta":{"url":"http://arxiv.org/abs/2310.16005v1"},"cats":{"benchmark":0.2546808601,"new-dataset":0.4948139532,"data-annotation":0.4953163167,"dev-research":0.1819420035,"llms":0.5173399813,"data-quality":0.188684967}}
{"text":"The network contains the (modular) structure of the library and the references between entries, while the s-expressions give complete and easily parsed information about every entry.","meta":{"url":"http://arxiv.org/abs/2310.16005v1"},"cats":{"benchmark":0.3588789128,"new-dataset":0.0829581615,"data-annotation":0.5172234264,"dev-research":0.1649049127,"llms":0.609951233,"data-quality":0.1414671968}}
{"text":"We report baseline results using standard graph and word embeddings, tree ensembles, and instance-based learning algorithms.","meta":{"url":"http://arxiv.org/abs/2310.16005v1"},"cats":{"benchmark":0.5389645178,"new-dataset":0.1857615407,"data-annotation":0.5577143623,"dev-research":0.1506446159,"llms":0.4728721414,"data-quality":0.3040544614}}
{"text":"The MLFMF data sets provide solid benchmarking support for further investigation of the numerous machine learning approaches to formalized mathematics.","meta":{"url":"http://arxiv.org/abs/2310.16005v1"},"cats":{"benchmark":0.5490676285,"new-dataset":0.1848314242,"data-annotation":0.5395968446,"dev-research":0.200775887,"llms":0.3970582541,"data-quality":0.1182949079}}
{"text":"The methodology used to extract the networks and the s-expressions readily applies to other libraries, and is applicable to other proof assistants.","meta":{"url":"http://arxiv.org/abs/2310.16005v1"},"cats":{"benchmark":0.4155774837,"new-dataset":0.0372440378,"data-annotation":0.5407418882,"dev-research":0.2017605859,"llms":0.5416265441,"data-quality":0.1870200961}}
{"text":"With more than $250\\,000$ entries in total, this is currently the largest collection of formalized mathematical knowledge in machine learnable format.","meta":{"url":"http://arxiv.org/abs/2310.16005v1"},"cats":{"benchmark":0.2850599506,"new-dataset":0.4328786906,"data-annotation":0.543069917,"dev-research":0.2153324086,"llms":0.4957216101,"data-quality":0.0959285215}}
{"text":"Humans watch more than a billion hours of video per day.","meta":{"url":"http://arxiv.org/abs/2310.16003v1"},"cats":{"benchmark":0.2463847868,"new-dataset":0.4634999486,"data-annotation":0.5155940355,"dev-research":0.1953736984,"llms":0.5015618569,"data-quality":0.0823070821}}
{"text":"Most of this video was edited manually, which is a tedious process.","meta":{"url":"http://arxiv.org/abs/2310.16003v1"},"cats":{"benchmark":0.2908460856,"new-dataset":0.0442156714,"data-annotation":0.5191743518,"dev-research":0.2883026589,"llms":0.4724560105,"data-quality":0.1933581015}}
{"text":"However, AI-enabled video-generation and video-editing is on the rise.","meta":{"url":"http://arxiv.org/abs/2310.16003v1"},"cats":{"benchmark":0.1799364757,"new-dataset":0.0948264841,"data-annotation":0.5139345591,"dev-research":0.3281112569,"llms":0.5323010541,"data-quality":0.1004222031}}
{"text":"Building on text-to-image models like Stable Diffusion and Imagen, generative AI has improved dramatically on video tasks.","meta":{"url":"http://arxiv.org/abs/2310.16003v1"},"cats":{"benchmark":0.2767019561,"new-dataset":0.0665864817,"data-annotation":0.511550681,"dev-research":0.1545205853,"llms":0.5085786269,"data-quality":0.1334597669}}
{"text":"But it's hard to evaluate progress in these video tasks because there is no standard benchmark.","meta":{"url":"http://arxiv.org/abs/2310.16003v1"},"cats":{"benchmark":0.7153933824,"new-dataset":0.0178246883,"data-annotation":0.523120825,"dev-research":0.1864541396,"llms":0.4601499048,"data-quality":0.1347252145}}
{"text":"So, we propose a new dataset for text-guided video editing (TGVE), and we run a competition at CVPR to evaluate models on our TGVE dataset.","meta":{"url":"http://arxiv.org/abs/2310.16003v1"},"cats":{"benchmark":0.34054766,"new-dataset":0.6043738313,"data-annotation":0.5160468392,"dev-research":0.2267130639,"llms":0.5075338644,"data-quality":0.1838809194}}
{"text":"In this paper we present a retrospective on the competition and describe the winning method.","meta":{"url":"http://arxiv.org/abs/2310.16003v1"},"cats":{"benchmark":0.5471252668,"new-dataset":0.0412810359,"data-annotation":0.530206535,"dev-research":0.1849090553,"llms":0.4601700252,"data-quality":0.09152027}}
{"text":"The competition dataset is available at https://sites.google.com/view/loveucvpr23/track4.","meta":{"url":"http://arxiv.org/abs/2310.16003v1"},"cats":{"benchmark":0.3127929171,"new-dataset":0.9408725514,"data-annotation":0.5085636193,"dev-research":0.0850849029,"llms":0.4475870334,"data-quality":0.110503031}}
{"text":"In the field of image processing, applying intricate semantic modifications within existing images remains an enduring challenge.","meta":{"url":"http://arxiv.org/abs/2310.16002v1"},"cats":{"benchmark":0.2804089229,"new-dataset":0.0369183045,"data-annotation":0.5049123056,"dev-research":0.2378725257,"llms":0.4746456338,"data-quality":0.3135914102}}
{"text":"This paper introduces a pioneering framework that integrates viewpoint information to enhance the control of image editing tasks.","meta":{"url":"http://arxiv.org/abs/2310.16002v1"},"cats":{"benchmark":0.2584848224,"new-dataset":0.039137553,"data-annotation":0.5073480865,"dev-research":0.4130524888,"llms":0.418074103,"data-quality":0.1119717497}}
{"text":"By surveying existing object editing methodologies, we distill three essential criteria, consistency, controllability, and harmony, that should be met for an image editing method.","meta":{"url":"http://arxiv.org/abs/2310.16002v1"},"cats":{"benchmark":0.3849052362,"new-dataset":0.01238277,"data-annotation":0.489604116,"dev-research":0.295036884,"llms":0.5026103062,"data-quality":0.1492349625}}
{"text":"In contrast to previous approaches, our method takes the lead in satisfying all three requirements for addressing the challenge of image synthesis.","meta":{"url":"http://arxiv.org/abs/2310.16002v1"},"cats":{"benchmark":0.3515525955,"new-dataset":0.0609894756,"data-annotation":0.5059137956,"dev-research":0.2337105088,"llms":0.4733837298,"data-quality":0.1113076968}}
{"text":"Through comprehensive experiments, encompassing both quantitative assessments and qualitative comparisons with contemporary state-of-the-art methods, we present compelling evidence of our framework's superior performance across multiple dimensions.","meta":{"url":"http://arxiv.org/abs/2310.16002v1"},"cats":{"benchmark":0.6461683251,"new-dataset":0.0078940944,"data-annotation":0.4967413765,"dev-research":0.1910548338,"llms":0.448716828,"data-quality":0.0726497076}}
{"text":"This work establishes a promising avenue for advancing image synthesis techniques and empowering precise object modifications while preserving the visual coherence of the entire composition.","meta":{"url":"http://arxiv.org/abs/2310.16002v1"},"cats":{"benchmark":0.2803796538,"new-dataset":0.0491614324,"data-annotation":0.4997085839,"dev-research":0.2539423243,"llms":0.4946209226,"data-quality":0.1253133508}}
{"text":"Recent advances in fine-grained representation learning leverage local-to-global (emergent) relationships for achieving state-of-the-art results.","meta":{"url":"http://arxiv.org/abs/2310.15999v1"},"cats":{"benchmark":0.2315489414,"new-dataset":0.115512873,"data-annotation":0.5292855673,"dev-research":0.1913354163,"llms":0.5420253751,"data-quality":0.2162055527}}
{"text":"The relational representations relied upon by such methods, however, are abstract.","meta":{"url":"http://arxiv.org/abs/2310.15999v1"},"cats":{"benchmark":0.25614699,"new-dataset":0.0080684206,"data-annotation":0.5284378305,"dev-research":0.245162376,"llms":0.4714165823,"data-quality":0.1061903608}}
{"text":"We aim to deconstruct this abstraction by expressing them as interpretable graphs over image views.","meta":{"url":"http://arxiv.org/abs/2310.15999v1"},"cats":{"benchmark":0.176061655,"new-dataset":0.1276427534,"data-annotation":0.5203310979,"dev-research":0.2817340067,"llms":0.4433047265,"data-quality":0.196281886}}
{"text":"We begin by theoretically showing that abstract relational representations are nothing but a way of recovering transitive relationships among local views.","meta":{"url":"http://arxiv.org/abs/2310.15999v1"},"cats":{"benchmark":0.1574462416,"new-dataset":0.0394230003,"data-annotation":0.5294409091,"dev-research":0.2109387908,"llms":0.5307321701,"data-quality":0.1694390471}}
{"text":"Based on this, we design Transitivity Recovering Decompositions (TRD), a graph-space search algorithm that identifies interpretable equivalents of abstract emergent relationships at both instance and class levels, and with no post-hoc computations.","meta":{"url":"http://arxiv.org/abs/2310.15999v1"},"cats":{"benchmark":0.2953081696,"new-dataset":0.0938475441,"data-annotation":0.5408899057,"dev-research":0.1726247703,"llms":0.495606484,"data-quality":0.1698961985}}
{"text":"We additionally show that TRD is provably robust to noisy views, with empirical evidence also supporting this finding.","meta":{"url":"http://arxiv.org/abs/2310.15999v1"},"cats":{"benchmark":0.4856056737,"new-dataset":0.0562207583,"data-annotation":0.5183206281,"dev-research":0.2096226606,"llms":0.4126829472,"data-quality":0.3279360712}}
{"text":"The latter allows TRD to perform at par or even better than the state-of-the-art, while being fully interpretable.","meta":{"url":"http://arxiv.org/abs/2310.15999v1"},"cats":{"benchmark":0.4776353485,"new-dataset":0.0047765434,"data-annotation":0.4954176811,"dev-research":0.199154716,"llms":0.5136433515,"data-quality":0.1215206086}}
{"text":"Implementation is available at https://github.com/abhrac/trd.","meta":{"url":"http://arxiv.org/abs/2310.15999v1"},"cats":{"benchmark":0.4788944153,"new-dataset":0.0938430557,"data-annotation":0.5059682455,"dev-research":0.1316996213,"llms":0.5167385323,"data-quality":0.0781885735}}
{"text":"Compiler correctness is crucial, as miscompilation falsifying the program behaviors can lead to serious consequences.","meta":{"url":"http://arxiv.org/abs/2310.15991v1"},"cats":{"benchmark":0.3201238439,"new-dataset":0.0061676308,"data-annotation":0.5233094536,"dev-research":0.565744443,"llms":0.5996151441,"data-quality":0.4364132569}}
{"text":"In the literature, fuzzing has been extensively studied to uncover compiler defects.","meta":{"url":"http://arxiv.org/abs/2310.15991v1"},"cats":{"benchmark":0.3521568979,"new-dataset":0.1074697198,"data-annotation":0.5365771519,"dev-research":0.5339116054,"llms":0.6144154688,"data-quality":0.343497831}}
{"text":"However, compiler fuzzing remains challenging: Existing arts focus on black- and grey-box fuzzing, which generates tests without sufficient understanding of internal compiler behaviors.","meta":{"url":"http://arxiv.org/abs/2310.15991v1"},"cats":{"benchmark":0.3413447026,"new-dataset":0.0557997473,"data-annotation":0.5389052441,"dev-research":0.4881644933,"llms":0.5802504228,"data-quality":0.2217995812}}
{"text":"As such, they often fail to construct programs to exercise conditions of intricate optimizations.","meta":{"url":"http://arxiv.org/abs/2310.15991v1"},"cats":{"benchmark":0.3258457987,"new-dataset":0.0027567994,"data-annotation":0.5353823065,"dev-research":0.3509818116,"llms":0.4808904805,"data-quality":0.2004122066}}
{"text":"Meanwhile, traditional white-box techniques are computationally inapplicable to the giant codebase of compilers.","meta":{"url":"http://arxiv.org/abs/2310.15991v1"},"cats":{"benchmark":0.3702749788,"new-dataset":0.0095815111,"data-annotation":0.5296661293,"dev-research":0.3817474118,"llms":0.5620712555,"data-quality":0.1139716892}}
{"text":"Recent advances demonstrate that Large Language Models (LLMs) excel in code generation/understanding tasks and have achieved state-of-the-art performance in black-box fuzzing.","meta":{"url":"http://arxiv.org/abs/2310.15991v1"},"cats":{"benchmark":0.2879222651,"new-dataset":0.1987097496,"data-annotation":0.5259147505,"dev-research":0.387506631,"llms":0.6795583317,"data-quality":0.1705940995}}
{"text":"Nonetheless, prompting LLMs with compiler source-code information remains a missing piece of research in compiler testing.   ","meta":{"url":"http://arxiv.org/abs/2310.15991v1"},"cats":{"benchmark":0.2675532899,"new-dataset":0.0185936327,"data-annotation":0.5171753256,"dev-research":0.3528552032,"llms":0.7639613871,"data-quality":0.2533684149}}
{"text":"To this end, we propose WhiteFox, the first white-box compiler fuzzer using LLMs with source-code information to test compiler optimization.","meta":{"url":"http://arxiv.org/abs/2310.15991v1"},"cats":{"benchmark":0.4418869199,"new-dataset":0.0582353971,"data-annotation":0.5287211242,"dev-research":0.3698118186,"llms":0.6983086229,"data-quality":0.1225535567}}
{"text":"WhiteFox adopts a dual-model framework: (i) an analysis LLM examines the low-level optimization source code and produces requirements on the high-level test programs that can trigger the optimization; (ii) a generation LLM produces test programs based on the summarized requirements.","meta":{"url":"http://arxiv.org/abs/2310.15991v1"},"cats":{"benchmark":0.4910950875,"new-dataset":0.0053844098,"data-annotation":0.5074555317,"dev-research":0.2360950211,"llms":0.5906222991,"data-quality":0.0726791533}}
{"text":"Additionally, optimization-triggering tests are used as feedback to further enhance the test generation on the fly.","meta":{"url":"http://arxiv.org/abs/2310.15991v1"},"cats":{"benchmark":0.5085999099,"new-dataset":0.0121892079,"data-annotation":0.506724878,"dev-research":0.4134512158,"llms":0.5247164082,"data-quality":0.1107478145}}
{"text":"Our evaluation on four popular compilers shows that WhiteFox can generate high-quality tests to exercise deep optimizations requiring intricate conditions, practicing up to 80 more optimizations than state-of-the-art fuzzers.","meta":{"url":"http://arxiv.org/abs/2310.15991v1"},"cats":{"benchmark":0.5241825935,"new-dataset":0.0418831503,"data-annotation":0.5388126167,"dev-research":0.3403516968,"llms":0.5561942883,"data-quality":0.1355778177}}
{"text":"To date, WhiteFox has found in total 96 bugs, with 80 confirmed as previously unknown and 51 already fixed.","meta":{"url":"http://arxiv.org/abs/2310.15991v1"},"cats":{"benchmark":0.4356164722,"new-dataset":0.0731824792,"data-annotation":0.5191806055,"dev-research":0.2589113486,"llms":0.5002258672,"data-quality":0.2680419875}}
{"text":"Beyond compiler testing, WhiteFox can also be adapted for white-box fuzzing of other complex, real-world software systems in general.","meta":{"url":"http://arxiv.org/abs/2310.15991v1"},"cats":{"benchmark":0.4212971813,"new-dataset":0.023976117,"data-annotation":0.5147840552,"dev-research":0.3947331495,"llms":0.5795180723,"data-quality":0.1353144981}}
{"text":"With the increased adaption of blockchain technologies, permissioned blockchains such as Hyperledger Fabric provide a robust ecosystem for developing production-grade decentralized applications.","meta":{"url":"http://arxiv.org/abs/2310.15988v1"},"cats":{"benchmark":0.2422080101,"new-dataset":0.096354452,"data-annotation":0.4937658791,"dev-research":0.2067923605,"llms":0.5939274911,"data-quality":0.0721509945}}
{"text":"However, the additional latency between executing and committing transactions, due to Fabric's three-phase transaction lifecycle of Execute-Order-Validate (EOV), is a potential scalability bottleneck.","meta":{"url":"http://arxiv.org/abs/2310.15988v1"},"cats":{"benchmark":0.5335604549,"new-dataset":0.0310824784,"data-annotation":0.5090568886,"dev-research":0.2785392384,"llms":0.5435119094,"data-quality":0.0723303327}}
{"text":"The added latency increases the probability of concurrent updates on the same keys by different transactions, leading to transaction failures caused by Fabric's concurrency control mechanism.","meta":{"url":"http://arxiv.org/abs/2310.15988v1"},"cats":{"benchmark":0.4543807371,"new-dataset":0.00961014,"data-annotation":0.4978078244,"dev-research":0.3125060256,"llms":0.4963039059,"data-quality":0.0990418759}}
{"text":"The transaction failures increase the application development complexity and decrease Fabric's throughput.","meta":{"url":"http://arxiv.org/abs/2310.15988v1"},"cats":{"benchmark":0.3714753236,"new-dataset":0.0168497752,"data-annotation":0.5272304832,"dev-research":0.4318747227,"llms":0.5200488238,"data-quality":0.1252202681}}
{"text":"Conflict-free Replicated Datatypes (CRDTs) provide a solution for merging and resolving conflicts in the presence of concurrent updates.","meta":{"url":"http://arxiv.org/abs/2310.15988v1"},"cats":{"benchmark":0.370305189,"new-dataset":0.4144836228,"data-annotation":0.4340605739,"dev-research":0.3059311428,"llms":0.5444512344,"data-quality":0.162113698}}
{"text":"In this work, we introduce FabricCRDT, an approach for integrating CRDTs to Fabric.","meta":{"url":"http://arxiv.org/abs/2310.15988v1"},"cats":{"benchmark":0.396018609,"new-dataset":0.1752288452,"data-annotation":0.517992619,"dev-research":0.2856929967,"llms":0.4848956577,"data-quality":0.08124798}}
{"text":"Our evaluations show that in general, FabricCRDT offers higher throughput of successful transactions than Fabric, while successfully committing and merging all conflicting transactions without any failures.","meta":{"url":"http://arxiv.org/abs/2310.15988v1"},"cats":{"benchmark":0.4823825254,"new-dataset":0.091170897,"data-annotation":0.5031187178,"dev-research":0.2761794834,"llms":0.565233602,"data-quality":0.0927719357}}
{"text":"Most of the recent work in leveraging Large Language Models (LLMs) such as GPT-3 for Machine Translation (MT) has focused on selecting the few-shot samples for prompting.","meta":{"url":"http://arxiv.org/abs/2310.15987v1"},"cats":{"benchmark":0.2766723135,"new-dataset":0.2283883662,"data-annotation":0.5282739216,"dev-research":0.141674078,"llms":0.6337265906,"data-quality":0.1287796604}}
{"text":"In this work, we try to better understand the role of demonstration attributes for the in-context learning of translations through perturbations of high-quality, in-domain demonstrations.","meta":{"url":"http://arxiv.org/abs/2310.15987v1"},"cats":{"benchmark":0.2351726455,"new-dataset":0.0987464242,"data-annotation":0.5430011143,"dev-research":0.2223406892,"llms":0.5682052986,"data-quality":0.2097323029}}
{"text":"We find that asymmetric perturbation of the source-target mappings yield vastly different results.","meta":{"url":"http://arxiv.org/abs/2310.15987v1"},"cats":{"benchmark":0.4569169488,"new-dataset":0.0106308229,"data-annotation":0.5134937543,"dev-research":0.1142214341,"llms":0.460654316,"data-quality":0.1568439925}}
{"text":"We show that the perturbation of the source side has surprisingly little impact, while target perturbation can drastically reduce translation quality, suggesting that it is the output text distribution that provides the most important learning signal during in-context learning of translations.","meta":{"url":"http://arxiv.org/abs/2310.15987v1"},"cats":{"benchmark":0.3557073249,"new-dataset":0.0635018793,"data-annotation":0.5456484453,"dev-research":0.1788380994,"llms":0.5275428117,"data-quality":0.4065485075}}
{"text":"We propose a method named Zero-Shot-Context to add this signal automatically in Zero-Shot prompting.","meta":{"url":"http://arxiv.org/abs/2310.15987v1"},"cats":{"benchmark":0.1990663386,"new-dataset":0.0623422723,"data-annotation":0.5213064398,"dev-research":0.1875762059,"llms":0.5154695206,"data-quality":0.1578875335}}
{"text":"We demonstrate that it improves upon the zero-shot translation performance of GPT-3, even making it competitive with few-shot prompted translations.","meta":{"url":"http://arxiv.org/abs/2310.15987v1"},"cats":{"benchmark":0.4037294791,"new-dataset":0.1116877252,"data-annotation":0.5186065878,"dev-research":0.1424752641,"llms":0.5617058975,"data-quality":0.1497403039}}
{"text":"This paper presents a novel approach to Single-Positive Multi-label Learning.","meta":{"url":"http://arxiv.org/abs/2310.15985v1"},"cats":{"benchmark":0.4398160169,"new-dataset":0.0607383423,"data-annotation":0.5446424826,"dev-research":0.124670875,"llms":0.4281815272,"data-quality":0.5656066321}}
{"text":"In general multi-label learning, a model learns to predict multiple labels or categories for a single input image.","meta":{"url":"http://arxiv.org/abs/2310.15985v1"},"cats":{"benchmark":0.2169356755,"new-dataset":0.0483873867,"data-annotation":0.5268179894,"dev-research":0.1081669841,"llms":0.4265284354,"data-quality":0.3513895638}}
{"text":"This is in contrast with standard multi-class image classification, where the task is predicting a single label from many possible labels for an image.","meta":{"url":"http://arxiv.org/abs/2310.15985v1"},"cats":{"benchmark":0.2788915875,"new-dataset":0.1075332381,"data-annotation":0.5347259194,"dev-research":0.153542366,"llms":0.4388191875,"data-quality":0.3118964785}}
{"text":"Single-Positive Multi-label Learning (SPML) specifically considers learning to predict multiple labels when there is only a single annotation per image in the training data.","meta":{"url":"http://arxiv.org/abs/2310.15985v1"},"cats":{"benchmark":0.3547062745,"new-dataset":0.0714179136,"data-annotation":0.5211130783,"dev-research":0.1215210314,"llms":0.4661413143,"data-quality":0.3955307985}}
{"text":"Multi-label learning is in many ways a more realistic task than single-label learning as real-world data often involves instances belonging to multiple categories simultaneously; however, most common computer vision datasets predominantly contain single labels due to the inherent complexity and cost of collecting multiple high quality annotations for each instance.","meta":{"url":"http://arxiv.org/abs/2310.15985v1"},"cats":{"benchmark":0.2732005972,"new-dataset":0.2363754978,"data-annotation":0.528873455,"dev-research":0.1672390958,"llms":0.503841593,"data-quality":0.5422167585}}
{"text":"We propose a novel approach called Vision-Language Pseudo-Labeling (VLPL), which uses a vision-language model to suggest strong positive and negative pseudo-labels, and outperforms the current SOTA methods by 5.5% on Pascal VOC, 18.4% on MS-COCO, 15.2% on NUS-WIDE, and 8.4% on CUB-Birds.","meta":{"url":"http://arxiv.org/abs/2310.15985v1"},"cats":{"benchmark":0.3371894611,"new-dataset":0.184214336,"data-annotation":0.5535231278,"dev-research":0.2268187531,"llms":0.5210930852,"data-quality":0.4960603538}}
{"text":"Our code and data are available at https://github.com/mvrl/VLPL.","meta":{"url":"http://arxiv.org/abs/2310.15985v1"},"cats":{"benchmark":0.2654758256,"new-dataset":0.6434155229,"data-annotation":0.4941209977,"dev-research":0.1404751838,"llms":0.4972066819,"data-quality":0.0928475351}}
{"text":"Dynamic Digital Humans (DDHs) are 3D digital models that are animated using predefined motions and are inevitably bothered by noise/shift during the generation process and compression distortion during the transmission process, which needs to be perceptually evaluated.","meta":{"url":"http://arxiv.org/abs/2310.15984v1"},"cats":{"benchmark":0.2373971539,"new-dataset":0.1196438866,"data-annotation":0.4646006081,"dev-research":0.2004076746,"llms":0.5532030769,"data-quality":0.0733708652}}
{"text":"Usually, DDHs are displayed as 2D rendered animation videos and it is natural to adapt video quality assessment (VQA) methods to DDH quality assessment (DDH-QA) tasks.","meta":{"url":"http://arxiv.org/abs/2310.15984v1"},"cats":{"benchmark":0.3703977481,"new-dataset":0.05466275,"data-annotation":0.4863758943,"dev-research":0.1630665845,"llms":0.5691518024,"data-quality":0.1077583559}}
{"text":"However, the VQA methods are highly dependent on viewpoints and less sensitive to geometry-based distortions.","meta":{"url":"http://arxiv.org/abs/2310.15984v1"},"cats":{"benchmark":0.4696909568,"new-dataset":0.0027980127,"data-annotation":0.5245620245,"dev-research":0.1584446761,"llms":0.4038291194,"data-quality":0.0940665172}}
{"text":"Therefore, in this paper, we propose a novel no-reference (NR) geometry-aware video quality assessment method for DDH-QA challenge.","meta":{"url":"http://arxiv.org/abs/2310.15984v1"},"cats":{"benchmark":0.5612420263,"new-dataset":0.1303383822,"data-annotation":0.5166478479,"dev-research":0.1662380219,"llms":0.5130889257,"data-quality":0.1954094424}}
{"text":"Geometry characteristics are described by the statistical parameters estimated from the DDHs' geometry attribute distributions.","meta":{"url":"http://arxiv.org/abs/2310.15984v1"},"cats":{"benchmark":0.4064586115,"new-dataset":0.0430932033,"data-annotation":0.5057899299,"dev-research":0.1561763473,"llms":0.4839112354,"data-quality":0.0679682276}}
{"text":"Spatial and temporal features are acquired from the rendered videos.","meta":{"url":"http://arxiv.org/abs/2310.15984v1"},"cats":{"benchmark":0.1936783163,"new-dataset":0.2128422831,"data-annotation":0.5247405361,"dev-research":0.2085826443,"llms":0.4408787316,"data-quality":0.1095905691}}
{"text":"Finally, all kinds of features are integrated and regressed into quality values.","meta":{"url":"http://arxiv.org/abs/2310.15984v1"},"cats":{"benchmark":0.3387908365,"new-dataset":0.0364891591,"data-annotation":0.4806356323,"dev-research":0.3047675225,"llms":0.4742359218,"data-quality":0.2500819448}}
{"text":"Experimental results show that the proposed method achieves state-of-the-art performance on the DDH-QA database.","meta":{"url":"http://arxiv.org/abs/2310.15984v1"},"cats":{"benchmark":0.5725953167,"new-dataset":0.132621175,"data-annotation":0.4696884804,"dev-research":0.1396474951,"llms":0.5698820086,"data-quality":0.0977956667}}
{"text":"Graph-based deep learning methods have become popular tools to process collections of correlated time series.","meta":{"url":"http://arxiv.org/abs/2310.15978v1"},"cats":{"benchmark":0.3093719589,"new-dataset":0.1721011396,"data-annotation":0.5018985653,"dev-research":0.1657567076,"llms":0.4301269886,"data-quality":0.1129272318}}
{"text":"Differently from traditional multivariate forecasting methods, neural graph-based predictors take advantage of pairwise relationships by conditioning forecasts on a (possibly dynamic) graph spanning the time series collection.","meta":{"url":"http://arxiv.org/abs/2310.15978v1"},"cats":{"benchmark":0.3103471939,"new-dataset":0.0540441893,"data-annotation":0.5034461664,"dev-research":0.1479966458,"llms":0.370973427,"data-quality":0.0562625486}}
{"text":"The conditioning can take the form of an architectural inductive bias on the neural forecasting architecture, resulting in a family of deep learning models called spatiotemporal graph neural networks.","meta":{"url":"http://arxiv.org/abs/2310.15978v1"},"cats":{"benchmark":0.2060241454,"new-dataset":0.0357368591,"data-annotation":0.507737571,"dev-research":0.1635822358,"llms":0.4393560658,"data-quality":0.0834433803}}
{"text":"Such relational inductive biases enable the training of global forecasting models on large time-series collections, while at the same time localizing predictions w.r.t.","meta":{"url":"http://arxiv.org/abs/2310.15978v1"},"cats":{"benchmark":0.3159279524,"new-dataset":0.0263924698,"data-annotation":0.5210493993,"dev-research":0.1464453114,"llms":0.462532734,"data-quality":0.1058272561}}
{"text":"each element in the set (i.e., graph nodes) by accounting for local correlations among them (i.e., graph edges).","meta":{"url":"http://arxiv.org/abs/2310.15978v1"},"cats":{"benchmark":0.4088332803,"new-dataset":0.1954151708,"data-annotation":0.5317530093,"dev-research":0.170547217,"llms":0.4464168786,"data-quality":0.1740290871}}
{"text":"Indeed, recent theoretical and practical advances in graph neural networks and deep learning for time series forecasting make the adoption of such processing frameworks appealing and timely.","meta":{"url":"http://arxiv.org/abs/2310.15978v1"},"cats":{"benchmark":0.2947862132,"new-dataset":0.0297100929,"data-annotation":0.4996094535,"dev-research":0.1676066482,"llms":0.3961721523,"data-quality":0.0942872615}}
{"text":"However, most of the studies in the literature focus on proposing variations of existing neural architectures by taking advantage of modern deep learning practices, while foundational and methodological aspects have not been subject to systematic investigation.","meta":{"url":"http://arxiv.org/abs/2310.15978v1"},"cats":{"benchmark":0.263358221,"new-dataset":0.0206990927,"data-annotation":0.495087468,"dev-research":0.1732417615,"llms":0.5220981905,"data-quality":0.1149910285}}
{"text":"To fill the gap, this paper aims to introduce a comprehensive methodological framework that formalizes the forecasting problem and provides design principles for graph-based predictive models and methods to assess their performance.","meta":{"url":"http://arxiv.org/abs/2310.15978v1"},"cats":{"benchmark":0.4414384153,"new-dataset":0.0124998921,"data-annotation":0.5064472961,"dev-research":0.215846209,"llms":0.3419546571,"data-quality":0.0990684427}}
{"text":"At the same time, together with an overview of the field, we provide design guidelines, recommendations, and best practices, as well as an in-depth discussion of open challenges and future research directions.","meta":{"url":"http://arxiv.org/abs/2310.15978v1"},"cats":{"benchmark":0.3722121778,"new-dataset":0.1013760902,"data-annotation":0.4936586349,"dev-research":0.3735950828,"llms":0.5455329469,"data-quality":0.0671251644}}
{"text":"In recent years, major social media platforms have implemented increasingly strict moderation policies, resulting in bans and restrictions on conspiracy theory-related content.","meta":{"url":"http://arxiv.org/abs/2310.15977v1"},"cats":{"benchmark":0.2481379955,"new-dataset":0.0302731678,"data-annotation":0.476493227,"dev-research":0.1781942058,"llms":0.5179059234,"data-quality":0.1529281511}}
{"text":"To circumvent these restrictions, conspiracy theorists are turning to alternatives, such as Telegram, where they can express and spread their views with fewer limitations.","meta":{"url":"http://arxiv.org/abs/2310.15977v1"},"cats":{"benchmark":0.1698341831,"new-dataset":0.0109355761,"data-annotation":0.4981489631,"dev-research":0.2698364654,"llms":0.5678580196,"data-quality":0.0833782977}}
{"text":"Telegram offers channels -- virtual rooms where only administrators can broadcast messages -- and a more permissive content policy.","meta":{"url":"http://arxiv.org/abs/2310.15977v1"},"cats":{"benchmark":0.1752150434,"new-dataset":0.0962452386,"data-annotation":0.4991644736,"dev-research":0.2422188092,"llms":0.5989328047,"data-quality":0.0957968558}}
{"text":"These features have created the perfect breeding ground for a complex ecosystem of conspiracy channels.   ","meta":{"url":"http://arxiv.org/abs/2310.15977v1"},"cats":{"benchmark":0.1405375508,"new-dataset":0.2360087085,"data-annotation":0.5115077943,"dev-research":0.2208337559,"llms":0.5238712881,"data-quality":0.1112359453}}
{"text":"In this paper, we illuminate this ecosystem.","meta":{"url":"http://arxiv.org/abs/2310.15977v1"},"cats":{"benchmark":0.2416666091,"new-dataset":0.1485374611,"data-annotation":0.5171109823,"dev-research":0.1446183529,"llms":0.5097657401,"data-quality":0.1243792407}}
{"text":"First, we propose an approach to detect conspiracy channels.","meta":{"url":"http://arxiv.org/abs/2310.15977v1"},"cats":{"benchmark":0.2530605998,"new-dataset":0.0851353768,"data-annotation":0.5250391205,"dev-research":0.1988879905,"llms":0.52478621,"data-quality":0.1941565698}}
{"text":"Then, we discover that conspiracy channels can be clustered into four distinct communities comprising over 17,000 channels.","meta":{"url":"http://arxiv.org/abs/2310.15977v1"},"cats":{"benchmark":0.1928216146,"new-dataset":0.3887673445,"data-annotation":0.5164006313,"dev-research":0.1787848199,"llms":0.5124947056,"data-quality":0.1021354996}}
{"text":"Finally, we uncover the \"Conspiracy Money Machine,\" revealing how most conspiracy channels actively seek to profit from their subscribers.","meta":{"url":"http://arxiv.org/abs/2310.15977v1"},"cats":{"benchmark":0.1854907494,"new-dataset":0.2114638178,"data-annotation":0.5132529302,"dev-research":0.1588321718,"llms":0.5362569913,"data-quality":0.1738188154}}
{"text":"We find conspiracy theorists leverage e-commerce platforms to sell questionable products or lucratively promote them through affiliate links.","meta":{"url":"http://arxiv.org/abs/2310.15977v1"},"cats":{"benchmark":0.2274147966,"new-dataset":0.0182704055,"data-annotation":0.514145904,"dev-research":0.2260815537,"llms":0.534391385,"data-quality":0.1521071853}}
{"text":"Moreover, we observe that conspiracy channels use donation and crowdfunding platforms to raise funds for their campaigns.","meta":{"url":"http://arxiv.org/abs/2310.15977v1"},"cats":{"benchmark":0.1930289091,"new-dataset":0.0810477972,"data-annotation":0.5170936441,"dev-research":0.2104715174,"llms":0.5400191287,"data-quality":0.1301175379}}
{"text":"We determine that this business involves hundreds of donors and generates a turnover of over $90 million.","meta":{"url":"http://arxiv.org/abs/2310.15977v1"},"cats":{"benchmark":0.2289052891,"new-dataset":0.1975396449,"data-annotation":0.5291506836,"dev-research":0.2138543872,"llms":0.5423123977,"data-quality":0.1169768644}}
{"text":"Autonomous vehicles (AVs) have the potential to significantly revolutionize society by providing a secure and efficient mode of transportation.","meta":{"url":"http://arxiv.org/abs/2310.15975v1"},"cats":{"benchmark":0.2475630689,"new-dataset":0.0108202441,"data-annotation":0.5002955851,"dev-research":0.1645741981,"llms":0.4744916525,"data-quality":0.0659131375}}
{"text":"Recent years have witnessed notable advance-ments in autonomous driving perception and prediction, but the challenge of validating the performance of AVs remains largely unresolved.","meta":{"url":"http://arxiv.org/abs/2310.15975v1"},"cats":{"benchmark":0.4320650947,"new-dataset":0.0114547976,"data-annotation":0.5277204852,"dev-research":0.1938037435,"llms":0.438694268,"data-quality":0.1416832946}}
{"text":"Data-driven microscopic traffic simulation has be-come an important tool for autonomous driving testing due to 1) availability of high-fidelity traffic data; 2) its advantages of ena-bling large-scale testing and scenario reproducibility; and 3) its potential in reactive and realistic traffic simulation.","meta":{"url":"http://arxiv.org/abs/2310.15975v1"},"cats":{"benchmark":0.3501279807,"new-dataset":0.194749978,"data-annotation":0.474392948,"dev-research":0.1874692323,"llms":0.5323174722,"data-quality":0.0737125615}}
{"text":"However, a comprehensive review of this topic is currently lacking.","meta":{"url":"http://arxiv.org/abs/2310.15975v1"},"cats":{"benchmark":0.3092490043,"new-dataset":0.0128017229,"data-annotation":0.5119815701,"dev-research":0.2650819264,"llms":0.5042835313,"data-quality":0.1533815904}}
{"text":"This pa-per aims to fill this gap by summarizing relevant studies.","meta":{"url":"http://arxiv.org/abs/2310.15975v1"},"cats":{"benchmark":0.4199648097,"new-dataset":0.0195196102,"data-annotation":0.4864836436,"dev-research":0.1705556965,"llms":0.4962052407,"data-quality":0.0584179528}}
{"text":"The primary objective of this paper is to review current research ef-forts and provide a futuristic perspective that will benefit future developments in the field.","meta":{"url":"http://arxiv.org/abs/2310.15975v1"},"cats":{"benchmark":0.3750116876,"new-dataset":0.0660520959,"data-annotation":0.5036316196,"dev-research":0.1988836107,"llms":0.4837691562,"data-quality":0.0634356669}}
{"text":"It introduces the general issues of data-driven traffic simulation and outlines key concepts and terms.","meta":{"url":"http://arxiv.org/abs/2310.15975v1"},"cats":{"benchmark":0.2718697229,"new-dataset":0.1310148661,"data-annotation":0.4539900333,"dev-research":0.189346749,"llms":0.4857769685,"data-quality":0.0980505224}}
{"text":"After overviewing traffic simulation, various datasets and evalua-tion metrics commonly used are reviewed.","meta":{"url":"http://arxiv.org/abs/2310.15975v1"},"cats":{"benchmark":0.4968493245,"new-dataset":0.301557869,"data-annotation":0.5135216894,"dev-research":0.1452016446,"llms":0.4742388971,"data-quality":0.1022762788}}
{"text":"The paper then offers a comprehensive evaluation of imitation learning, reinforcement learning, generative and deep learning methods, summarizing each and analyzing their advantages and disadvantages in detail.","meta":{"url":"http://arxiv.org/abs/2310.15975v1"},"cats":{"benchmark":0.3287744163,"new-dataset":0.0244569442,"data-annotation":0.5184667654,"dev-research":0.1870762344,"llms":0.5002874188,"data-quality":0.0486268178}}
{"text":"Moreover, it evaluates the state-of-the-art, existing challenges, and future research directions.","meta":{"url":"http://arxiv.org/abs/2310.15975v1"},"cats":{"benchmark":0.4974369537,"new-dataset":0.0171054471,"data-annotation":0.4942527638,"dev-research":0.2017247085,"llms":0.5401355466,"data-quality":0.0776781378}}
{"text":"signSGD is popular in nonconvex optimization due to its communication efficiency.","meta":{"url":"http://arxiv.org/abs/2310.15976v1"},"cats":{"benchmark":0.4669933252,"new-dataset":0.0076177974,"data-annotation":0.4926360036,"dev-research":0.1758876151,"llms":0.5562160319,"data-quality":0.0711284846}}
{"text":"Yet, existing analyses of signSGD rely on assuming that data are sampled with replacement in each iteration, contradicting the practical implementation where data are randomly reshuffled and sequentially fed into the algorithm.","meta":{"url":"http://arxiv.org/abs/2310.15976v1"},"cats":{"benchmark":0.5088676778,"new-dataset":0.0358907129,"data-annotation":0.4979849545,"dev-research":0.1915046884,"llms":0.5230073891,"data-quality":0.1572255082}}
{"text":"We bridge this gap by proving the first convergence result of signSGD with random reshuffling (SignRR) for nonconvex optimization.","meta":{"url":"http://arxiv.org/abs/2310.15976v1"},"cats":{"benchmark":0.5831754812,"new-dataset":0.0217736509,"data-annotation":0.5109165506,"dev-research":0.1230758232,"llms":0.4554571046,"data-quality":0.1109942522}}
{"text":"Given the dataset size $n$, the number of epochs of data passes $T$, and the variance bound of a stochastic gradient $\\sigma^2$, we show that SignRR has the same convergence rate $O(\\log(nT)/\\sqrt{nT} + \\|\\sigma\\|_1)$ as signSGD \\citep{bernstein2018signsgd}.","meta":{"url":"http://arxiv.org/abs/2310.15976v1"},"cats":{"benchmark":0.5544537297,"new-dataset":0.1218128206,"data-annotation":0.5140342961,"dev-research":0.142797708,"llms":0.4429182074,"data-quality":0.1110815269}}
{"text":"We then present SignRVR and SignRVM, which leverage variance-reduced gradients and momentum updates respectively, both converging at $O(\\log(nT)/\\sqrt{nT})$. In contrast with the analysis of signSGD, our results do not require an extremely large batch size in each iteration to be of the same order as the total number of iterations \\citep{bernstein2018signsgd} or the signs of stochastic and true gradients match element-wise with a minimum probability of 1/2 \\citep{safaryan2021stochastic}.","meta":{"url":"http://arxiv.org/abs/2310.15976v1"},"cats":{"benchmark":0.6175008694,"new-dataset":0.0280021489,"data-annotation":0.5226646894,"dev-research":0.1243111407,"llms":0.496540682,"data-quality":0.1081233404}}
{"text":"We also extend our algorithms to cases where data are distributed across different machines, yielding dist-SignRVR and dist-SignRVM, both converging at $O(\\log(n_0T)/\\sqrt{n_0T})$, where $n_0$ is the dataset size of a single machine.","meta":{"url":"http://arxiv.org/abs/2310.15976v1"},"cats":{"benchmark":0.5209967053,"new-dataset":0.1547706269,"data-annotation":0.4979227835,"dev-research":0.111577425,"llms":0.536204613,"data-quality":0.1057613939}}
{"text":"We back up our theoretical findings through experiments on simulated and real-world problems, verifying that randomly reshuffled sign methods match or surpass existing baselines.","meta":{"url":"http://arxiv.org/abs/2310.15976v1"},"cats":{"benchmark":0.4879001401,"new-dataset":0.0181243737,"data-annotation":0.5321245485,"dev-research":0.2415756151,"llms":0.4794055347,"data-quality":0.1468650523}}
{"text":"In single-cloud storage, ciphertext-policy attribute-based encryption (CP-ABE) allows one to encrypt any data under an access structure to a cloud server, specifying what attributes are required to decrypt.","meta":{"url":"http://arxiv.org/abs/2310.15972v1"},"cats":{"benchmark":0.2408377245,"new-dataset":0.0271051813,"data-annotation":0.4605243965,"dev-research":0.1312829189,"llms":0.4958021292,"data-quality":0.0676681754}}
{"text":"In multi-cloud storage, a secret sharing scheme (SSS) allows one to split any data into multiple shares, one to a single server, and specify which subset of the servers are able to recover the data.","meta":{"url":"http://arxiv.org/abs/2310.15972v1"},"cats":{"benchmark":0.2450592311,"new-dataset":0.0374689471,"data-annotation":0.4684974138,"dev-research":0.1196603816,"llms":0.5027033335,"data-quality":0.0724603184}}
{"text":"It is an interesting problem to remove some attributes/servers but still enable the remaining attributes/servers in every authorized set to recover the data.","meta":{"url":"http://arxiv.org/abs/2310.15972v1"},"cats":{"benchmark":0.3044983202,"new-dataset":0.0674914174,"data-annotation":0.4747153259,"dev-research":0.1479677912,"llms":0.4820362729,"data-quality":0.208185402}}
{"text":"The problem is related to the contraction problem of access structures for SSSs.","meta":{"url":"http://arxiv.org/abs/2310.15972v1"},"cats":{"benchmark":0.4001464772,"new-dataset":0.0348003749,"data-annotation":0.4896602562,"dev-research":0.2004185087,"llms":0.5263957824,"data-quality":0.1184844563}}
{"text":"In this paper, we propose a method that can efficiently transform a given SSS for an access structure to SSSs for contractions of the access structure.","meta":{"url":"http://arxiv.org/abs/2310.15972v1"},"cats":{"benchmark":0.5180877865,"new-dataset":0.0194462315,"data-annotation":0.480977873,"dev-research":0.1940133942,"llms":0.5346599036,"data-quality":0.089164182}}
{"text":"We show its applications in solving the attribute removal problem in the CP-ABE based single-cloud storage and the data relocating problem in multi-cloud storage.","meta":{"url":"http://arxiv.org/abs/2310.15972v1"},"cats":{"benchmark":0.3981629774,"new-dataset":0.0615935846,"data-annotation":0.4789452149,"dev-research":0.1558627657,"llms":0.4512158433,"data-quality":0.1980804688}}
{"text":"Our method results in solutions that require either less server storage or even no additional server storage.","meta":{"url":"http://arxiv.org/abs/2310.15972v1"},"cats":{"benchmark":0.3727456261,"new-dataset":0.0178502669,"data-annotation":0.4994928928,"dev-research":0.1788286521,"llms":0.5495314566,"data-quality":0.1242897262}}
{"text":"Modern programming languages like Java require runtime systems to support the implementation and deployment of software applications in diverse computing platforms and operating systems.","meta":{"url":"http://arxiv.org/abs/2310.15971v1"},"cats":{"benchmark":0.2551766966,"new-dataset":0.0304671796,"data-annotation":0.4956947328,"dev-research":0.3968565942,"llms":0.6154615376,"data-quality":0.0654953258}}
{"text":"These runtime systems are normally developed in GitHub-hosted repositories based on close collaboration between large software companies (e.g., IBM, Microsoft) and OSS developers.","meta":{"url":"http://arxiv.org/abs/2310.15971v1"},"cats":{"benchmark":0.2153954021,"new-dataset":0.2891183937,"data-annotation":0.4908160239,"dev-research":0.4340293224,"llms":0.5846986855,"data-quality":0.0686383287}}
{"text":"However, despite their popularity and broad usage; to the best of our knowledge, these repositories have never been studied.","meta":{"url":"http://arxiv.org/abs/2310.15971v1"},"cats":{"benchmark":0.2588948662,"new-dataset":0.1265142709,"data-annotation":0.5025617267,"dev-research":0.1644055399,"llms":0.6365806084,"data-quality":0.1370061541}}
{"text":"We report an empirical study of around 118K issues from 34 runtime system repos in GitHub.","meta":{"url":"http://arxiv.org/abs/2310.15971v1"},"cats":{"benchmark":0.3793484645,"new-dataset":0.6685034516,"data-annotation":0.5026712798,"dev-research":0.3475009616,"llms":0.5882885826,"data-quality":0.1973752268}}
{"text":"We found that issues regarding enhancement, test failure and bug are mostly posted on runtime system repositories and solution related discussion are mostly present on issue discussion.","meta":{"url":"http://arxiv.org/abs/2310.15971v1"},"cats":{"benchmark":0.4458334818,"new-dataset":0.1024417854,"data-annotation":0.5168010902,"dev-research":0.497546109,"llms":0.5868495816,"data-quality":0.3731360005}}
{"text":"82.69% issues in the runtime system repositories have been resolved and 0.69% issues are ignored; median of issue close rate, ignore rate and addressing time in these repositories are 76.1%, 2.2% and 58 days respectively.","meta":{"url":"http://arxiv.org/abs/2310.15971v1"},"cats":{"benchmark":0.4670421266,"new-dataset":0.2491291301,"data-annotation":0.4988915894,"dev-research":0.3300829862,"llms":0.5515975584,"data-quality":0.2427595516}}
{"text":"82.65% issues are tagged with labels while only 28.30% issues have designated assignees and 90.65% issues contain at least one comment; also presence of these features in an issue report can affect issue closure.","meta":{"url":"http://arxiv.org/abs/2310.15971v1"},"cats":{"benchmark":0.3590173653,"new-dataset":0.1612444139,"data-annotation":0.5068439605,"dev-research":0.448785528,"llms":0.5422582166,"data-quality":0.6873291318}}
{"text":"Based on the findings, we offer six recommendat","meta":{"url":"http://arxiv.org/abs/2310.15971v1"},"cats":{"benchmark":0.4204951612,"new-dataset":0.2112226568,"data-annotation":0.5229918807,"dev-research":0.1845598888,"llms":0.5178301699,"data-quality":0.0908520798}}
{"text":"Speech accents pose a significant challenge to state-of-the-art automatic speech recognition (ASR) systems.","meta":{"url":"http://arxiv.org/abs/2310.15970v1"},"cats":{"benchmark":0.39499914,"new-dataset":0.0692486467,"data-annotation":0.5261640996,"dev-research":0.1396961742,"llms":0.4548780995,"data-quality":0.2006917418}}
{"text":"Degradation in performance across underrepresented accents is a severe deterrent to the inclusive adoption of ASR.","meta":{"url":"http://arxiv.org/abs/2310.15970v1"},"cats":{"benchmark":0.4640152485,"new-dataset":0.0061193372,"data-annotation":0.517334554,"dev-research":0.2133175719,"llms":0.4776603577,"data-quality":0.2171800675}}
{"text":"In this work, we propose a novel accent adaptation approach for end-to-end ASR systems using cross-attention with a trainable set of codebooks.","meta":{"url":"http://arxiv.org/abs/2310.15970v1"},"cats":{"benchmark":0.3670174899,"new-dataset":0.170795577,"data-annotation":0.5317139383,"dev-research":0.1882450621,"llms":0.4949646498,"data-quality":0.2002849016}}
{"text":"These learnable codebooks capture accent-specific information and are integrated within the ASR encoder layers.","meta":{"url":"http://arxiv.org/abs/2310.15970v1"},"cats":{"benchmark":0.2750734096,"new-dataset":0.1973674486,"data-annotation":0.5306402962,"dev-research":0.2274509116,"llms":0.5051633041,"data-quality":0.1612802839}}
{"text":"The model is trained on accented English speech, while the test data also contained accents which were not seen during training.","meta":{"url":"http://arxiv.org/abs/2310.15970v1"},"cats":{"benchmark":0.277713725,"new-dataset":0.0874689958,"data-annotation":0.5185554399,"dev-research":0.1323412563,"llms":0.5005005831,"data-quality":0.2064247597}}
{"text":"On the Mozilla Common Voice multi-accented dataset, we show that our proposed approach yields significant performance gains not only on the seen English accents (up to $37\\%$ relative improvement in word error rate) but also on the unseen accents (up to $5\\%$ relative improvement in WER).","meta":{"url":"http://arxiv.org/abs/2310.15970v1"},"cats":{"benchmark":0.587186322,"new-dataset":0.1721537871,"data-annotation":0.5349817338,"dev-research":0.1565831517,"llms":0.4739799609,"data-quality":0.261015922}}
{"text":"Further, we illustrate benefits for a zero-shot transfer setup on the L2Artic dataset.","meta":{"url":"http://arxiv.org/abs/2310.15970v1"},"cats":{"benchmark":0.4196021276,"new-dataset":0.4539451007,"data-annotation":0.5121250797,"dev-research":0.0796626285,"llms":0.4001451947,"data-quality":0.1416830555}}
{"text":"We also compare the performance with other approaches based on accent adversarial training.","meta":{"url":"http://arxiv.org/abs/2310.15970v1"},"cats":{"benchmark":0.5490690605,"new-dataset":0.0295255317,"data-annotation":0.5695660252,"dev-research":0.1529594589,"llms":0.4695450906,"data-quality":0.2647357972}}
{"text":"Despite the promise of Mixture of Experts (MoE) models in increasing parameter counts of Transformer models while maintaining training and inference costs, their application carries notable drawbacks.","meta":{"url":"http://arxiv.org/abs/2310.15961v1"},"cats":{"benchmark":0.3589459988,"new-dataset":0.0156477264,"data-annotation":0.5085578825,"dev-research":0.1464078365,"llms":0.4356439183,"data-quality":0.0848312943}}
{"text":"The key strategy of these models is to, for each processed token, activate at most a few experts - subsets of an extensive feed-forward layer.","meta":{"url":"http://arxiv.org/abs/2310.15961v1"},"cats":{"benchmark":0.3082844369,"new-dataset":0.0091719225,"data-annotation":0.5039765672,"dev-research":0.1184347248,"llms":0.4520799884,"data-quality":0.071306004}}
{"text":"But this approach is not without its challenges.","meta":{"url":"http://arxiv.org/abs/2310.15961v1"},"cats":{"benchmark":0.3460136135,"new-dataset":0.0041315169,"data-annotation":0.4954900772,"dev-research":0.257094234,"llms":0.4832191973,"data-quality":0.1190815621}}
{"text":"The operation of matching experts and tokens is discrete, which makes MoE models prone to issues like training instability and uneven expert utilization.","meta":{"url":"http://arxiv.org/abs/2310.15961v1"},"cats":{"benchmark":0.3398125961,"new-dataset":0.0038195279,"data-annotation":0.4869417727,"dev-research":0.1374913974,"llms":0.5143583999,"data-quality":0.1398201033}}
{"text":"Existing techniques designed to address these concerns, such as auxiliary losses or balance-aware matching, result either in lower model performance or are more difficult to train.","meta":{"url":"http://arxiv.org/abs/2310.15961v1"},"cats":{"benchmark":0.6050623949,"new-dataset":0.0006469549,"data-annotation":0.5247452356,"dev-research":0.1422002048,"llms":0.4254021187,"data-quality":0.1498679645}}
{"text":"In response to these issues, we propose Mixture of Tokens, a fully-differentiable model that retains the benefits of MoE architectures while avoiding the aforementioned difficulties.","meta":{"url":"http://arxiv.org/abs/2310.15961v1"},"cats":{"benchmark":0.3770110287,"new-dataset":0.0095510398,"data-annotation":0.4827640691,"dev-research":0.1480607155,"llms":0.5190707757,"data-quality":0.1146620266}}
{"text":"Rather than routing tokens to experts, this approach mixes tokens from different examples prior to feeding them to experts, enabling the model to learn from all token-expert combinations.","meta":{"url":"http://arxiv.org/abs/2310.15961v1"},"cats":{"benchmark":0.271394009,"new-dataset":0.010078647,"data-annotation":0.5206670197,"dev-research":0.2324356441,"llms":0.5149953769,"data-quality":0.1590986908}}
{"text":"Importantly, this mixing can be disabled to avoid mixing of different sequences during inference.","meta":{"url":"http://arxiv.org/abs/2310.15961v1"},"cats":{"benchmark":0.4183573803,"new-dataset":0.0073204865,"data-annotation":0.4928133307,"dev-research":0.1503539936,"llms":0.5244916234,"data-quality":0.1574451691}}
{"text":"Crucially, this method is fully compatible with both masked and causal Large Language Model training and inference.","meta":{"url":"http://arxiv.org/abs/2310.15961v1"},"cats":{"benchmark":0.3303042389,"new-dataset":0.0169711464,"data-annotation":0.551833238,"dev-research":0.1354533746,"llms":0.4467190707,"data-quality":0.2745966081}}
{"text":"The detailed clinical records drafted by doctors after each patient's visit are crucial for medical practitioners and researchers.","meta":{"url":"http://arxiv.org/abs/2310.15959v1"},"cats":{"benchmark":0.3311865591,"new-dataset":0.1586791181,"data-annotation":0.4713318974,"dev-research":0.2576448215,"llms":0.515007593,"data-quality":0.081464125}}
{"text":"Automating the creation of these notes with language models can reduce the workload of doctors.","meta":{"url":"http://arxiv.org/abs/2310.15959v1"},"cats":{"benchmark":0.2804796847,"new-dataset":0.1559485456,"data-annotation":0.5308239865,"dev-research":0.330830942,"llms":0.5166803454,"data-quality":0.1498332747}}
{"text":"However, training such models can be difficult due to the limited public availability of conversations between patients and doctors.","meta":{"url":"http://arxiv.org/abs/2310.15959v1"},"cats":{"benchmark":0.2074829653,"new-dataset":0.0150123472,"data-annotation":0.5218322283,"dev-research":0.1844376774,"llms":0.5164432337,"data-quality":0.0866132571}}
{"text":"In this paper, we introduce NoteChat, a cooperative multi-agent framework leveraging Large Language Models (LLMs) for generating synthetic doctor-patient conversations conditioned on clinical notes.","meta":{"url":"http://arxiv.org/abs/2310.15959v1"},"cats":{"benchmark":0.2452149563,"new-dataset":0.5167321555,"data-annotation":0.5215474003,"dev-research":0.2013012309,"llms":0.5747993597,"data-quality":0.1091256544}}
{"text":"NoteChat consists of Planning, Roleplay, and Polish modules.","meta":{"url":"http://arxiv.org/abs/2310.15959v1"},"cats":{"benchmark":0.1912017889,"new-dataset":0.4824792872,"data-annotation":0.500582764,"dev-research":0.3135301893,"llms":0.5894800191,"data-quality":0.101362719}}
{"text":"We provide a comprehensive automatic and human evaluation of NoteChat, comparing it with state-of-the-art models, including OpenAI's ChatGPT and GPT-4.","meta":{"url":"http://arxiv.org/abs/2310.15959v1"},"cats":{"benchmark":0.3885999909,"new-dataset":0.4296627484,"data-annotation":0.5252708374,"dev-research":0.2717897663,"llms":0.5380565679,"data-quality":0.1883888577}}
{"text":"Results demonstrate that NoteChat facilitates high-quality synthetic doctor-patient conversations, underscoring the untapped potential of LLMs in healthcare.","meta":{"url":"http://arxiv.org/abs/2310.15959v1"},"cats":{"benchmark":0.2149524532,"new-dataset":0.1783513464,"data-annotation":0.4948523828,"dev-research":0.2665259921,"llms":0.7101023338,"data-quality":0.1266749767}}
{"text":"This work represents the first instance of multiple LLMs cooperating to complete a doctor-patient conversation conditioned on clinical notes, offering promising avenues for the intersection of AI and healthcare","meta":{"url":"http://arxiv.org/abs/2310.15959v1"},"cats":{"benchmark":0.2086679943,"new-dataset":0.0987649902,"data-annotation":0.5012399789,"dev-research":0.1767032665,"llms":0.692420781,"data-quality":0.1055628022}}
{"text":"The introduction of DETR represents a new paradigm for object detection.","meta":{"url":"http://arxiv.org/abs/2310.15955v1"},"cats":{"benchmark":0.2651400958,"new-dataset":0.1087023195,"data-annotation":0.5287070098,"dev-research":0.1992001809,"llms":0.4787238373,"data-quality":0.1470599745}}
{"text":"However, its decoder conducts classification and box localization using shared queries and cross-attention layers, leading to suboptimal results.","meta":{"url":"http://arxiv.org/abs/2310.15955v1"},"cats":{"benchmark":0.3245831718,"new-dataset":0.0487384062,"data-annotation":0.5222610879,"dev-research":0.1612253888,"llms":0.4897206306,"data-quality":0.1754707206}}
{"text":"We observe that different regions of interest in the visual feature map are suitable for performing query classification and box localization tasks, even for the same object.","meta":{"url":"http://arxiv.org/abs/2310.15955v1"},"cats":{"benchmark":0.242403403,"new-dataset":0.0316646901,"data-annotation":0.5018078739,"dev-research":0.2695852553,"llms":0.4940545986,"data-quality":0.1483873383}}
{"text":"Salient regions provide vital information for classification, while the boundaries around them are more favorable for box regression.","meta":{"url":"http://arxiv.org/abs/2310.15955v1"},"cats":{"benchmark":0.3677365638,"new-dataset":0.0324551436,"data-annotation":0.5191056107,"dev-research":0.2294730767,"llms":0.4082924393,"data-quality":0.112470629}}
{"text":"Unfortunately, such spatial misalignment between these two tasks greatly hinders DETR's training.","meta":{"url":"http://arxiv.org/abs/2310.15955v1"},"cats":{"benchmark":0.3162611098,"new-dataset":0.0044573653,"data-annotation":0.5256420671,"dev-research":0.2421577454,"llms":0.5220331988,"data-quality":0.1897390811}}
{"text":"Therefore, in this work, we focus on decoupling localization and classification tasks in DETR.","meta":{"url":"http://arxiv.org/abs/2310.15955v1"},"cats":{"benchmark":0.3547318035,"new-dataset":0.286308753,"data-annotation":0.5367757341,"dev-research":0.1714374414,"llms":0.4930291687,"data-quality":0.2382488369}}
{"text":"To achieve this, we introduce a new design scheme called spatially decoupled DETR (SD-DETR), which includes a task-aware query generation module and a disentangled feature learning process.","meta":{"url":"http://arxiv.org/abs/2310.15955v1"},"cats":{"benchmark":0.2800539649,"new-dataset":0.1186486093,"data-annotation":0.4929534946,"dev-research":0.2518060523,"llms":0.5496966038,"data-quality":0.0883538862}}
{"text":"We elaborately design the task-aware query initialization process and divide the cross-attention block in the decoder to allow the task-aware queries to match different visual regions.","meta":{"url":"http://arxiv.org/abs/2310.15955v1"},"cats":{"benchmark":0.2797404283,"new-dataset":0.0920328764,"data-annotation":0.4982043368,"dev-research":0.2279716567,"llms":0.5637715563,"data-quality":0.1001327721}}
{"text":"Meanwhile, we also observe that the prediction misalignment problem for high classification confidence and precise localization exists, so we propose an alignment loss to further guide the spatially decoupled DETR training.","meta":{"url":"http://arxiv.org/abs/2310.15955v1"},"cats":{"benchmark":0.4151531915,"new-dataset":0.1294305885,"data-annotation":0.5393289926,"dev-research":0.157020074,"llms":0.4157511649,"data-quality":0.4048460642}}
{"text":"Through extensive experiments, we demonstrate that our approach achieves a significant improvement in MSCOCO datasets compared to previous work.","meta":{"url":"http://arxiv.org/abs/2310.15955v1"},"cats":{"benchmark":0.5791280292,"new-dataset":0.3519426446,"data-annotation":0.50607337,"dev-research":0.1567564284,"llms":0.4316697245,"data-quality":0.2516236448}}
{"text":"For instance, we improve the performance of Conditional DETR by 4.5 AP.","meta":{"url":"http://arxiv.org/abs/2310.15955v1"},"cats":{"benchmark":0.7317261046,"new-dataset":0.0146430075,"data-annotation":0.54456465,"dev-research":0.2026919968,"llms":0.4456203043,"data-quality":0.114460248}}
{"text":"By spatially disentangling the two tasks, our method overcomes the misalignment problem and greatly improves the performance of DETR for object detection.","meta":{"url":"http://arxiv.org/abs/2310.15955v1"},"cats":{"benchmark":0.4374403952,"new-dataset":0.0299072907,"data-annotation":0.5388069204,"dev-research":0.1727594368,"llms":0.4438794594,"data-quality":0.2359727626}}
{"text":"While deep learning models have achieved remarkable success across a range of medical image analysis tasks, deployment of these models in real clinical contexts requires that they be robust to variability in the acquired images.","meta":{"url":"http://arxiv.org/abs/2310.15952v1"},"cats":{"benchmark":0.2816879071,"new-dataset":0.1139755636,"data-annotation":0.487864867,"dev-research":0.1923297854,"llms":0.4535201767,"data-quality":0.154338034}}
{"text":"While many methods apply predefined transformations to augment the training data to enhance test-time robustness, these transformations may not ensure the model's robustness to the diverse variability seen in patient images.","meta":{"url":"http://arxiv.org/abs/2310.15952v1"},"cats":{"benchmark":0.4005928468,"new-dataset":0.0354594422,"data-annotation":0.4873038644,"dev-research":0.1743350681,"llms":0.3976998639,"data-quality":0.1451110987}}
{"text":"In this paper, we introduce a novel three-stage approach based on transformers coupled with conditional diffusion models, with the goal of improving model robustness to the kinds of imaging variability commonly encountered in practice without the need for pre-determined data augmentation strategies.","meta":{"url":"http://arxiv.org/abs/2310.15952v1"},"cats":{"benchmark":0.4007511794,"new-dataset":0.0339129411,"data-annotation":0.4645164042,"dev-research":0.1565812016,"llms":0.3732642626,"data-quality":0.1218708413}}
{"text":"To this end, multiple image encoders first learn hierarchical feature representations to build discriminative latent spaces.","meta":{"url":"http://arxiv.org/abs/2310.15952v1"},"cats":{"benchmark":0.216661874,"new-dataset":0.0954007609,"data-annotation":0.5352610244,"dev-research":0.1495539053,"llms":0.471984161,"data-quality":0.1332099929}}
{"text":"Next, a reverse diffusion process, guided by the latent code, acts on an informative prior and proposes prediction candidates in a generative manner.","meta":{"url":"http://arxiv.org/abs/2310.15952v1"},"cats":{"benchmark":0.2699701581,"new-dataset":0.0139869277,"data-annotation":0.5331790549,"dev-research":0.1585413952,"llms":0.4620679257,"data-quality":0.1000533774}}
{"text":"Finally, several prediction candidates are aggregated in a bi-level aggregation protocol to produce the final output.","meta":{"url":"http://arxiv.org/abs/2310.15952v1"},"cats":{"benchmark":0.4750436643,"new-dataset":0.0774728941,"data-annotation":0.5043039952,"dev-research":0.1130254577,"llms":0.4279989507,"data-quality":0.1017490592}}
{"text":"Through extensive experiments on medical imaging benchmark datasets, we show that our method improves upon state-of-the-art methods in terms of robustness and confidence calibration.","meta":{"url":"http://arxiv.org/abs/2310.15952v1"},"cats":{"benchmark":0.6700692417,"new-dataset":0.3110165566,"data-annotation":0.5019643159,"dev-research":0.1743641991,"llms":0.3532924504,"data-quality":0.2344292888}}
{"text":"Additionally, we introduce a strategy to quantify the prediction uncertainty at the instance level, increasing their trustworthiness to clinicians using them in clinical practice.","meta":{"url":"http://arxiv.org/abs/2310.15952v1"},"cats":{"benchmark":0.4445702931,"new-dataset":0.0219498575,"data-annotation":0.5199980167,"dev-research":0.2789402591,"llms":0.4520338735,"data-quality":0.2359192946}}
{"text":"The problem of nearest neighbor condensing has enjoyed a long history of study, both in its theoretical and practical aspects.","meta":{"url":"http://arxiv.org/abs/2310.15951v1"},"cats":{"benchmark":0.496445188,"new-dataset":0.0296244852,"data-annotation":0.5412852846,"dev-research":0.1934897386,"llms":0.4700071172,"data-quality":0.1330552611}}
{"text":"In this paper, we introduce the problem of weighted distance nearest neighbor condensing, where one assigns weights to each point of the condensed set, and then new points are labeled based on their weighted distance nearest neighbor in the condensed set.   ","meta":{"url":"http://arxiv.org/abs/2310.15951v1"},"cats":{"benchmark":0.5240904316,"new-dataset":0.0900834973,"data-annotation":0.5523785599,"dev-research":0.171814595,"llms":0.409829431,"data-quality":0.2225293339}}
{"text":"We study the theoretical properties of this new model, and show that it can produce dramatically better condensing than the standard nearest neighbor rule, yet is characterized by generalization bounds almost identical to the latter.","meta":{"url":"http://arxiv.org/abs/2310.15951v1"},"cats":{"benchmark":0.5118019226,"new-dataset":0.0180212605,"data-annotation":0.5470057022,"dev-research":0.1302712589,"llms":0.3850663821,"data-quality":0.1491907753}}
{"text":"We then suggest a condensing heuristic for our new problem.","meta":{"url":"http://arxiv.org/abs/2310.15951v1"},"cats":{"benchmark":0.27364464,"new-dataset":0.022851667,"data-annotation":0.5268963813,"dev-research":0.2838236102,"llms":0.501893541,"data-quality":0.1275274326}}
{"text":"We demonstrate Bayes consistency for this heuristic, and also show promising empirical results.","meta":{"url":"http://arxiv.org/abs/2310.15951v1"},"cats":{"benchmark":0.591223503,"new-dataset":0.0168330178,"data-annotation":0.50524413,"dev-research":0.2058812603,"llms":0.4438449839,"data-quality":0.2606954405}}
{"text":"Recommender systems have seen significant advancements with the influence of deep learning and graph neural networks, particularly in capturing complex user-item relationships.","meta":{"url":"http://arxiv.org/abs/2310.15950v1"},"cats":{"benchmark":0.3186059715,"new-dataset":0.067860316,"data-annotation":0.5189134938,"dev-research":0.2142545063,"llms":0.4769359024,"data-quality":0.1067085091}}
{"text":"However, these graph-based recommenders heavily depend on ID-based data, potentially disregarding valuable textual information associated with users and items, resulting in less informative learned representations.","meta":{"url":"http://arxiv.org/abs/2310.15950v1"},"cats":{"benchmark":0.287604382,"new-dataset":0.0186613771,"data-annotation":0.5216328436,"dev-research":0.2116283825,"llms":0.505559989,"data-quality":0.2476095602}}
{"text":"Moreover, the utilization of implicit feedback data introduces potential noise and bias, posing challenges for the effectiveness of user preference learning.","meta":{"url":"http://arxiv.org/abs/2310.15950v1"},"cats":{"benchmark":0.3655749596,"new-dataset":0.0112517987,"data-annotation":0.5204067009,"dev-research":0.2284131775,"llms":0.4326526923,"data-quality":0.2672538261}}
{"text":"While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in text-only reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems.","meta":{"url":"http://arxiv.org/abs/2310.15950v1"},"cats":{"benchmark":0.305403079,"new-dataset":0.0409118065,"data-annotation":0.5279408864,"dev-research":0.1974532947,"llms":0.6241973755,"data-quality":0.1866539721}}
{"text":"To address these challenges, we propose a model-agnostic framework RLMRec that aims to enhance existing recommenders with LLM-empowered representation learning.","meta":{"url":"http://arxiv.org/abs/2310.15950v1"},"cats":{"benchmark":0.2958770384,"new-dataset":0.0541874621,"data-annotation":0.5196215497,"dev-research":0.140254568,"llms":0.5458678998,"data-quality":0.1494268827}}
{"text":"It proposes a recommendation paradigm that integrates representation learning with LLMs to capture intricate semantic aspects of user behaviors and preferences.","meta":{"url":"http://arxiv.org/abs/2310.15950v1"},"cats":{"benchmark":0.2084520215,"new-dataset":0.0294411786,"data-annotation":0.5100128743,"dev-research":0.1844074679,"llms":0.7083176921,"data-quality":0.1532065193}}
{"text":"RLMRec incorporates auxiliary textual signals, develops a user/item profiling paradigm empowered by LLMs, and aligns the semantic space of LLMs with the representation space of collaborative relational signals through a cross-view alignment framework.","meta":{"url":"http://arxiv.org/abs/2310.15950v1"},"cats":{"benchmark":0.2920331802,"new-dataset":0.1994477826,"data-annotation":0.5017712373,"dev-research":0.2428895591,"llms":0.6039955382,"data-quality":0.2079588247}}
{"text":"This work further establish a theoretical foundation demonstrating that incorporating textual signals through mutual information maximization enhances the quality of representations.","meta":{"url":"http://arxiv.org/abs/2310.15950v1"},"cats":{"benchmark":0.2817176446,"new-dataset":0.0090992492,"data-annotation":0.5565845985,"dev-research":0.2127034919,"llms":0.4588741928,"data-quality":0.2261700636}}
{"text":"In our evaluation, we integrate RLMRec with state-of-the-art recommender models, while also analyzing its efficiency and robustness to noise data.","meta":{"url":"http://arxiv.org/abs/2310.15950v1"},"cats":{"benchmark":0.5387245366,"new-dataset":0.0863597192,"data-annotation":0.5285750493,"dev-research":0.2086000539,"llms":0.379460795,"data-quality":0.2052493482}}
{"text":"Our implementation codes are available at https://github.com/HKUDS/RLMRec.","meta":{"url":"http://arxiv.org/abs/2310.15950v1"},"cats":{"benchmark":0.4140017165,"new-dataset":0.2436044185,"data-annotation":0.5176940331,"dev-research":0.1759451919,"llms":0.5209687146,"data-quality":0.1203523073}}
{"text":"Scene synthesis is a challenging problem with several industrial applications.","meta":{"url":"http://arxiv.org/abs/2310.15948v1"},"cats":{"benchmark":0.2623251362,"new-dataset":0.1720234046,"data-annotation":0.520623016,"dev-research":0.2876719049,"llms":0.4846746214,"data-quality":0.1475752907}}
{"text":"Recently, substantial efforts have been directed to synthesize the scene using human motions, room layouts, or spatial graphs as the input.","meta":{"url":"http://arxiv.org/abs/2310.15948v1"},"cats":{"benchmark":0.1825895731,"new-dataset":0.3468994212,"data-annotation":0.5259029444,"dev-research":0.2776477926,"llms":0.4679503223,"data-quality":0.0543814628}}
{"text":"However, few studies have addressed this problem from multiple modalities, especially combining text prompts.","meta":{"url":"http://arxiv.org/abs/2310.15948v1"},"cats":{"benchmark":0.3382900184,"new-dataset":0.0082621327,"data-annotation":0.5162867504,"dev-research":0.2042445674,"llms":0.5511424312,"data-quality":0.263165908}}
{"text":"In this paper, we propose a language-driven scene synthesis task, which is a new task that integrates text prompts, human motion, and existing objects for scene synthesis.","meta":{"url":"http://arxiv.org/abs/2310.15948v1"},"cats":{"benchmark":0.1593942984,"new-dataset":0.6226274173,"data-annotation":0.5354669497,"dev-research":0.3453635466,"llms":0.5325680519,"data-quality":0.1602920143}}
{"text":"Unlike other single-condition synthesis tasks, our problem involves multiple conditions and requires a strategy for processing and encoding them into a unified space.","meta":{"url":"http://arxiv.org/abs/2310.15948v1"},"cats":{"benchmark":0.332584219,"new-dataset":0.0950099206,"data-annotation":0.4996394448,"dev-research":0.2371763163,"llms":0.4604893077,"data-quality":0.0806595693}}
{"text":"To address the challenge, we present a multi-conditional diffusion model, which differs from the implicit unification approach of other diffusion literature by explicitly predicting the guiding points for the original data distribution.","meta":{"url":"http://arxiv.org/abs/2310.15948v1"},"cats":{"benchmark":0.3691598898,"new-dataset":0.0364965963,"data-annotation":0.4859440779,"dev-research":0.1360102836,"llms":0.3486862593,"data-quality":0.1049365156}}
{"text":"We demonstrate that our approach is theoretically supportive.","meta":{"url":"http://arxiv.org/abs/2310.15948v1"},"cats":{"benchmark":0.3060790843,"new-dataset":0.0066995621,"data-annotation":0.5107693353,"dev-research":0.2381671126,"llms":0.5012870224,"data-quality":0.0963895271}}
{"text":"The intensive experiment results illustrate that our method outperforms state-of-the-art benchmarks and enables natural scene editing applications.","meta":{"url":"http://arxiv.org/abs/2310.15948v1"},"cats":{"benchmark":0.5696668411,"new-dataset":0.1372283201,"data-annotation":0.525176705,"dev-research":0.2427927846,"llms":0.4593021876,"data-quality":0.1587884829}}
{"text":"The source code and dataset can be accessed at https://lang-scene-synth.github.io/.","meta":{"url":"http://arxiv.org/abs/2310.15948v1"},"cats":{"benchmark":0.1588848052,"new-dataset":0.9294771807,"data-annotation":0.5213567854,"dev-research":0.2102886821,"llms":0.5271829415,"data-quality":0.1405967707}}
{"text":"Identifying individuals in unconstrained video settings is a valuable yet challenging task in biometric analysis due to variations in appearances, environments, degradations, and occlusions.","meta":{"url":"http://arxiv.org/abs/2310.15946v1"},"cats":{"benchmark":0.3979478519,"new-dataset":0.1533402188,"data-annotation":0.5188928004,"dev-research":0.1776076023,"llms":0.4238284274,"data-quality":0.1442790315}}
{"text":"In this paper, we present ShARc, a multimodal approach for video-based person identification in uncontrolled environments that emphasizes 3-D body shape, pose, and appearance.","meta":{"url":"http://arxiv.org/abs/2310.15946v1"},"cats":{"benchmark":0.2777551878,"new-dataset":0.4682558818,"data-annotation":0.5119941347,"dev-research":0.1748731919,"llms":0.4133926714,"data-quality":0.0660782319}}
{"text":"We introduce two encoders: a Pose and Shape Encoder (PSE) and an Aggregated Appearance Encoder (AAE).","meta":{"url":"http://arxiv.org/abs/2310.15946v1"},"cats":{"benchmark":0.250348619,"new-dataset":0.1637976216,"data-annotation":0.523304751,"dev-research":0.1792410577,"llms":0.4134523793,"data-quality":0.0914820426}}
{"text":"PSE encodes the body shape via binarized silhouettes, skeleton motions, and 3-D body shape, while AAE provides two levels of temporal appearance feature aggregation: attention-based feature aggregation and averaging aggregation.","meta":{"url":"http://arxiv.org/abs/2310.15946v1"},"cats":{"benchmark":0.3148873532,"new-dataset":0.0320932257,"data-annotation":0.4948420666,"dev-research":0.186349272,"llms":0.373854336,"data-quality":0.0559795143}}
{"text":"For attention-based feature aggregation, we employ spatial and temporal attention to focus on key areas for person distinction.","meta":{"url":"http://arxiv.org/abs/2310.15946v1"},"cats":{"benchmark":0.3554005098,"new-dataset":0.1196261112,"data-annotation":0.5258860155,"dev-research":0.2415407205,"llms":0.4643761111,"data-quality":0.1140900018}}
{"text":"For averaging aggregation, we introduce a novel flattening layer after averaging to extract more distinguishable information and reduce overfitting of attention.","meta":{"url":"http://arxiv.org/abs/2310.15946v1"},"cats":{"benchmark":0.4359702294,"new-dataset":0.0449987517,"data-annotation":0.5040860947,"dev-research":0.1682589897,"llms":0.4601656427,"data-quality":0.2038899428}}
{"text":"We utilize centroid feature averaging for gallery registration.","meta":{"url":"http://arxiv.org/abs/2310.15946v1"},"cats":{"benchmark":0.436854565,"new-dataset":0.0382194505,"data-annotation":0.5024968266,"dev-research":0.1560168088,"llms":0.5120646459,"data-quality":0.1355695812}}
{"text":"We demonstrate significant improvements over existing state-of-the-art methods on public datasets, including CCVID, MEVID, and BRIAR.","meta":{"url":"http://arxiv.org/abs/2310.15946v1"},"cats":{"benchmark":0.4871086557,"new-dataset":0.6425159765,"data-annotation":0.505700169,"dev-research":0.1711234016,"llms":0.4368751385,"data-quality":0.1886542777}}
{"text":"In the new global era, determining trends can play an important role in guiding researchers, scientists, and agencies.","meta":{"url":"http://arxiv.org/abs/2310.15943v1"},"cats":{"benchmark":0.3011819893,"new-dataset":0.0430754598,"data-annotation":0.4956837846,"dev-research":0.2384080476,"llms":0.4507012361,"data-quality":0.0935896663}}
{"text":"The main faced challenge is to track the emerging topics among the stacked publications.","meta":{"url":"http://arxiv.org/abs/2310.15943v1"},"cats":{"benchmark":0.3996510425,"new-dataset":0.1188073606,"data-annotation":0.5137127467,"dev-research":0.2096599866,"llms":0.5395558058,"data-quality":0.1672470253}}
{"text":"Therefore, any study done to propose the trend topics in a field to foresee upcoming subjects is crucial.","meta":{"url":"http://arxiv.org/abs/2310.15943v1"},"cats":{"benchmark":0.2641717891,"new-dataset":0.018306833,"data-annotation":0.5277502474,"dev-research":0.2543694955,"llms":0.5111348597,"data-quality":0.072792582}}
{"text":"In the current study, the trend topics in the field of \"Hydrology\" have been attempted to evaluate.","meta":{"url":"http://arxiv.org/abs/2310.15943v1"},"cats":{"benchmark":0.4170306691,"new-dataset":0.0302390369,"data-annotation":0.4988312643,"dev-research":0.246130569,"llms":0.4779672053,"data-quality":0.0993356848}}
{"text":"To do so, the model is composed of three key components: a gathering of data, preprocessing of the article's significant features, and determining trend topics.","meta":{"url":"http://arxiv.org/abs/2310.15943v1"},"cats":{"benchmark":0.2888068155,"new-dataset":0.0699404898,"data-annotation":0.5009761259,"dev-research":0.2397333055,"llms":0.3899434117,"data-quality":0.0639356373}}
{"text":"Various topic models including Latent Dirichlet Allocation (LDA), Non-negative Matrix Factorization (NMF), and Latent Semantic Analysis (LSA) have been implemented.","meta":{"url":"http://arxiv.org/abs/2310.15943v1"},"cats":{"benchmark":0.3004697145,"new-dataset":0.0240382623,"data-annotation":0.5571928055,"dev-research":0.205851377,"llms":0.4936348875,"data-quality":0.1725327129}}
{"text":"Comparing the obtained results with respect to the $C_V$ coherence score, in 2022, the topics of \"Climate change\", \"River basin\", \"Water management\", \"Natural hazards/erosion\", and \"Hydrologic cycle\" have been obtained.","meta":{"url":"http://arxiv.org/abs/2310.15943v1"},"cats":{"benchmark":0.4381417603,"new-dataset":0.3919207218,"data-annotation":0.5124968741,"dev-research":0.1785947318,"llms":0.4248822398,"data-quality":0.1239026066}}
{"text":"According to a further analysis, it is shown that these topics keep their impact on the field in 2023, as well.","meta":{"url":"http://arxiv.org/abs/2310.15943v1"},"cats":{"benchmark":0.2537232617,"new-dataset":0.1443204075,"data-annotation":0.5186321112,"dev-research":0.2111957337,"llms":0.5158821887,"data-quality":0.1187502612}}
{"text":"Although large language models (LLMs) have apparently acquired a certain level of grammatical knowledge and the ability to make generalizations, they fail to interpret negation, a crucial step in Natural Language Processing.","meta":{"url":"http://arxiv.org/abs/2310.15941v1"},"cats":{"benchmark":0.1907885861,"new-dataset":0.0195804302,"data-annotation":0.5376115513,"dev-research":0.1918346125,"llms":0.6889169205,"data-quality":0.3043884082}}
{"text":"We try to clarify the reasons for the sub-optimal performance of LLMs understanding negation.","meta":{"url":"http://arxiv.org/abs/2310.15941v1"},"cats":{"benchmark":0.3568709598,"new-dataset":0.0040367281,"data-annotation":0.5301968781,"dev-research":0.1730692404,"llms":0.7188803326,"data-quality":0.1716036694}}
{"text":"We introduce a large semi-automatically generated dataset of circa 400,000 descriptive sentences about commonsense knowledge that can be true or false in which negation is present in about 2/3 of the corpus in different forms.","meta":{"url":"http://arxiv.org/abs/2310.15941v1"},"cats":{"benchmark":0.2128913499,"new-dataset":0.7094123788,"data-annotation":0.5397320476,"dev-research":0.198296262,"llms":0.5394196849,"data-quality":0.2700596551}}
{"text":"We have used our dataset with the largest available open LLMs in a zero-shot approach to grasp their generalization and inference capability and we have also fine-tuned some of the models to assess whether the understanding of negation can be trained.","meta":{"url":"http://arxiv.org/abs/2310.15941v1"},"cats":{"benchmark":0.2643031402,"new-dataset":0.1171137905,"data-annotation":0.5376467157,"dev-research":0.1274347493,"llms":0.6538166323,"data-quality":0.2175478797}}
{"text":"Our findings show that, while LLMs are proficient at classifying affirmative sentences, they struggle with negative sentences and lack a deep understanding of negation, often relying on superficial cues.","meta":{"url":"http://arxiv.org/abs/2310.15941v1"},"cats":{"benchmark":0.2827994581,"new-dataset":0.0099108472,"data-annotation":0.5368498702,"dev-research":0.1938417284,"llms":0.7346096566,"data-quality":0.2816943149}}
{"text":"Although fine-tuning the models on negative sentences improves their performance, the lack of generalization in handling negation is persistent, highlighting the ongoing challenges of LLMs regarding negation understanding and generalization.","meta":{"url":"http://arxiv.org/abs/2310.15941v1"},"cats":{"benchmark":0.272984425,"new-dataset":0.0148312492,"data-annotation":0.5327830613,"dev-research":0.265280365,"llms":0.6581271627,"data-quality":0.2658092178}}
{"text":"The dataset and code are publicly available.","meta":{"url":"http://arxiv.org/abs/2310.15941v1"},"cats":{"benchmark":0.1754484694,"new-dataset":0.9416584706,"data-annotation":0.4884967584,"dev-research":0.1808070825,"llms":0.5298308705,"data-quality":0.1043650469}}
{"text":"The Option Keyboard (OK) was recently proposed as a method for transferring behavioral knowledge across tasks.","meta":{"url":"http://arxiv.org/abs/2310.15940v1"},"cats":{"benchmark":0.2064513931,"new-dataset":0.0163819246,"data-annotation":0.4943911475,"dev-research":0.2638907452,"llms":0.559820908,"data-quality":0.0623480228}}
{"text":"OK transfers knowledge by adaptively combining subsets of known behaviors using Successor Features (SFs) and Generalized Policy Improvement (GPI).","meta":{"url":"http://arxiv.org/abs/2310.15940v1"},"cats":{"benchmark":0.2740097394,"new-dataset":0.0463573433,"data-annotation":0.4817766518,"dev-research":0.1811143725,"llms":0.4821540861,"data-quality":0.1088882603}}
{"text":"However, it relies on hand-designed state-features and task encodings which are cumbersome to design for every new environment.","meta":{"url":"http://arxiv.org/abs/2310.15940v1"},"cats":{"benchmark":0.234316473,"new-dataset":0.0225202433,"data-annotation":0.4905828163,"dev-research":0.3228362123,"llms":0.5795198173,"data-quality":0.0473230892}}
{"text":"In this work, we propose the \"Successor Features Keyboard\" (SFK), which enables transfer with discovered state-features and task encodings.","meta":{"url":"http://arxiv.org/abs/2310.15940v1"},"cats":{"benchmark":0.2782358741,"new-dataset":0.1889070211,"data-annotation":0.4991817817,"dev-research":0.2482020435,"llms":0.5406042258,"data-quality":0.1136749468}}
{"text":"To enable discovery, we propose the \"Categorical Successor Feature Approximator\" (CSFA), a novel learning algorithm for estimating SFs while jointly discovering state-features and task encodings.","meta":{"url":"http://arxiv.org/abs/2310.15940v1"},"cats":{"benchmark":0.3524745914,"new-dataset":0.2134335512,"data-annotation":0.529306202,"dev-research":0.2023222996,"llms":0.4231717318,"data-quality":0.1973363599}}
{"text":"With SFK and CSFA, we achieve the first demonstration of transfer with SFs in a challenging 3D environment where all the necessary representations are discovered.","meta":{"url":"http://arxiv.org/abs/2310.15940v1"},"cats":{"benchmark":0.2415686142,"new-dataset":0.2239244228,"data-annotation":0.4956154571,"dev-research":0.193391518,"llms":0.5269491121,"data-quality":0.0580516969}}
{"text":"We first compare CSFA against other methods for approximating SFs and show that only CSFA discovers representations compatible with SF&GPI at this scale.","meta":{"url":"http://arxiv.org/abs/2310.15940v1"},"cats":{"benchmark":0.4910310534,"new-dataset":0.0354351225,"data-annotation":0.527188736,"dev-research":0.1360563823,"llms":0.4961434794,"data-quality":0.1193410957}}
{"text":"We then compare SFK against transfer learning baselines and show that it transfers most quickly to long-horizon tasks.","meta":{"url":"http://arxiv.org/abs/2310.15940v1"},"cats":{"benchmark":0.4969984529,"new-dataset":0.1765171487,"data-annotation":0.5191324257,"dev-research":0.2098239518,"llms":0.4646224581,"data-quality":0.102995433}}
{"text":"Graph Neural Networks (GNNs) have proven to be quite versatile for a variety of applications, including recommendation systems, fake news detection, drug discovery, and even computer vision.","meta":{"url":"http://arxiv.org/abs/2310.15938v1"},"cats":{"benchmark":0.2298571899,"new-dataset":0.0918019312,"data-annotation":0.5167816265,"dev-research":0.1660114243,"llms":0.4595334603,"data-quality":0.1666842799}}
{"text":"Due to the expanding size of graph-structured data, GNN models have also increased in complexity, leading to substantial latency issues.","meta":{"url":"http://arxiv.org/abs/2310.15938v1"},"cats":{"benchmark":0.3163664499,"new-dataset":0.024673404,"data-annotation":0.509535625,"dev-research":0.1908553178,"llms":0.4305432452,"data-quality":0.0961983286}}
{"text":"This is primarily attributed to the irregular structure of graph data and its access pattern into memory.","meta":{"url":"http://arxiv.org/abs/2310.15938v1"},"cats":{"benchmark":0.2043294819,"new-dataset":0.0788204202,"data-annotation":0.4958309495,"dev-research":0.2278231698,"llms":0.4940998173,"data-quality":0.1553983885}}
{"text":"The natural solution to reduce latency is to compress large GNNs into small GNNs.","meta":{"url":"http://arxiv.org/abs/2310.15938v1"},"cats":{"benchmark":0.3824025104,"new-dataset":0.0158993696,"data-annotation":0.5116596616,"dev-research":0.1803229807,"llms":0.5121303846,"data-quality":0.1124600845}}
{"text":"One way to do this is via knowledge distillation (KD).","meta":{"url":"http://arxiv.org/abs/2310.15938v1"},"cats":{"benchmark":0.3339236111,"new-dataset":0.0476729717,"data-annotation":0.5138292505,"dev-research":0.1756119022,"llms":0.498281362,"data-quality":0.170918857}}
{"text":"However, most KD approaches for GNNs only consider the outputs of the last layers and do not consider the outputs of the intermediate layers of the GNNs; these layers may contain important inductive biases indicated by the graph structure.","meta":{"url":"http://arxiv.org/abs/2310.15938v1"},"cats":{"benchmark":0.362708202,"new-dataset":0.0116436401,"data-annotation":0.5174592118,"dev-research":0.1263028624,"llms":0.4803605437,"data-quality":0.1343142694}}
{"text":"To address this shortcoming, we propose a novel KD approach to GNN compression that we call Attention-Based Knowledge Distillation (ABKD).","meta":{"url":"http://arxiv.org/abs/2310.15938v1"},"cats":{"benchmark":0.2772466966,"new-dataset":0.1141537231,"data-annotation":0.5118828827,"dev-research":0.1690023744,"llms":0.4884997006,"data-quality":0.1743473478}}
{"text":"ABKD is a KD approach that uses attention to identify important intermediate teacher-student layer pairs and focuses on aligning their outputs.","meta":{"url":"http://arxiv.org/abs/2310.15938v1"},"cats":{"benchmark":0.3888728827,"new-dataset":0.1045143653,"data-annotation":0.5118626105,"dev-research":0.2172680235,"llms":0.4831202792,"data-quality":0.1061942378}}
{"text":"ABKD enables higher compression of GNNs with a smaller accuracy dropoff compared to existing KD approaches.","meta":{"url":"http://arxiv.org/abs/2310.15938v1"},"cats":{"benchmark":0.4789828225,"new-dataset":0.0262234846,"data-annotation":0.5045689256,"dev-research":0.1480964375,"llms":0.4619407838,"data-quality":0.1165603932}}
{"text":"On average, we achieve a 1.79% increase in accuracy with a 32.3x compression ratio on OGBN-Mag, a large graph dataset, compared to state-of-the-art approaches.","meta":{"url":"http://arxiv.org/abs/2310.15938v1"},"cats":{"benchmark":0.5558484981,"new-dataset":0.2603532844,"data-annotation":0.512234464,"dev-research":0.1644235091,"llms":0.4983314453,"data-quality":0.2666513313}}
{"text":"A recent paper by Farina & Pipis (2023) established the existence of uncoupled no-linear-swap regret dynamics with polynomial-time iterations in extensive-form games.","meta":{"url":"http://arxiv.org/abs/2310.15935v1"},"cats":{"benchmark":0.3426677795,"new-dataset":0.01855234,"data-annotation":0.5159357747,"dev-research":0.1226506624,"llms":0.4694097793,"data-quality":0.0407319729}}
{"text":"The equilibrium points reached by these dynamics, known as linear correlated equilibria, are currently the tightest known relaxation of correlated equilibrium that can be learned in polynomial time in any finite extensive-form game.","meta":{"url":"http://arxiv.org/abs/2310.15935v1"},"cats":{"benchmark":0.3699677738,"new-dataset":0.0477555569,"data-annotation":0.5275135936,"dev-research":0.0841510888,"llms":0.3606205815,"data-quality":0.0680446451}}
{"text":"However, their properties remain vastly unexplored, and their computation is onerous.","meta":{"url":"http://arxiv.org/abs/2310.15935v1"},"cats":{"benchmark":0.3238451625,"new-dataset":0.0612989061,"data-annotation":0.5396997218,"dev-research":0.1184671955,"llms":0.4908094529,"data-quality":0.1249275946}}
{"text":"In this paper, we provide several contributions shedding light on the fundamental nature of linear-swap regret.","meta":{"url":"http://arxiv.org/abs/2310.15935v1"},"cats":{"benchmark":0.399019022,"new-dataset":0.0061446365,"data-annotation":0.5247446862,"dev-research":0.1765581612,"llms":0.4605190743,"data-quality":0.0738914696}}
{"text":"First, we show a connection between linear deviations and a generalization of communication deviations in which the player can make queries to a \"mediator\" who replies with action recommendations, and, critically, the player is not constrained to match the timing of the game as would be the case for communication deviations.","meta":{"url":"http://arxiv.org/abs/2310.15935v1"},"cats":{"benchmark":0.3210723561,"new-dataset":0.0591753624,"data-annotation":0.5221223047,"dev-research":0.2682473715,"llms":0.4503236329,"data-quality":0.1163115552}}
{"text":"We coin this latter set the untimed communication (UTC) deviations.","meta":{"url":"http://arxiv.org/abs/2310.15935v1"},"cats":{"benchmark":0.4075341554,"new-dataset":0.0741638627,"data-annotation":0.5058665696,"dev-research":0.1914256173,"llms":0.4940306724,"data-quality":0.166577866}}
{"text":"We show that the UTC deviations coincide precisely with the linear deviations, and therefore that any player minimizing UTC regret also minimizes linear-swap regret.","meta":{"url":"http://arxiv.org/abs/2310.15935v1"},"cats":{"benchmark":0.5150714093,"new-dataset":0.0161044623,"data-annotation":0.5320872505,"dev-research":0.2358517753,"llms":0.4539959617,"data-quality":0.1167839903}}
{"text":"We then leverage this connection to develop state-of-the-art no-regret algorithms for computing linear correlated equilibria, both in theory and in practice.","meta":{"url":"http://arxiv.org/abs/2310.15935v1"},"cats":{"benchmark":0.5181509769,"new-dataset":0.0085706348,"data-annotation":0.5346337173,"dev-research":0.0943482076,"llms":0.3730760408,"data-quality":0.0670441825}}
{"text":"In theory, our algorithms achieve polynomially better per-iteration runtimes; in practice, our algorithms represent the state of the art by several orders of magnitude.","meta":{"url":"http://arxiv.org/abs/2310.15935v1"},"cats":{"benchmark":0.6694193324,"new-dataset":0.0227047485,"data-annotation":0.553708483,"dev-research":0.1646181632,"llms":0.4188199996,"data-quality":0.0856003992}}
{"text":"Redactable Signature Schemes and Zero-Knowledge Proofs are two radically different approaches to enable privacy.","meta":{"url":"http://arxiv.org/abs/2310.15934v1"},"cats":{"benchmark":0.2600539854,"new-dataset":0.0388001373,"data-annotation":0.5048670674,"dev-research":0.2002519226,"llms":0.5684045762,"data-quality":0.1395597498}}
{"text":"This paper analyses their merits and drawbacks when applied to decentralized identity system.","meta":{"url":"http://arxiv.org/abs/2310.15934v1"},"cats":{"benchmark":0.408087789,"new-dataset":0.0078761355,"data-annotation":0.4779612347,"dev-research":0.1754516001,"llms":0.5359224665,"data-quality":0.1200987113}}
{"text":"Redactable Signatures, though competitively quick and compact, are not as expressive as zero-knowledge proofs and do not provide the same level of privacy.","meta":{"url":"http://arxiv.org/abs/2310.15934v1"},"cats":{"benchmark":0.3137134676,"new-dataset":0.0367974396,"data-annotation":0.5025946247,"dev-research":0.1744326775,"llms":0.5811152549,"data-quality":0.1432163253}}
{"text":"On the other hand, zero-knowledge proofs can be much faster but some protocols require a trusted set-up.","meta":{"url":"http://arxiv.org/abs/2310.15934v1"},"cats":{"benchmark":0.3718155125,"new-dataset":0.0079496088,"data-annotation":0.504306202,"dev-research":0.2006195143,"llms":0.5927319823,"data-quality":0.0934745625}}
{"text":"We conclude that given the benefits and drawbacks, redactable signatures are more appropriate at an earlier stage and zero-knowledge proofs are more appropriate at a later stage for decentralized identity systems","meta":{"url":"http://arxiv.org/abs/2310.15934v1"},"cats":{"benchmark":0.3133238873,"new-dataset":0.0568326753,"data-annotation":0.4861688235,"dev-research":0.2091590069,"llms":0.5950026635,"data-quality":0.1732470232}}
{"text":"We study the problem of high-dimensional robust mean estimation in an online setting.","meta":{"url":"http://arxiv.org/abs/2310.15932v1"},"cats":{"benchmark":0.4999669666,"new-dataset":0.073684989,"data-annotation":0.5257323068,"dev-research":0.154237203,"llms":0.321481274,"data-quality":0.1704887722}}
{"text":"Specifically, we consider a scenario where $n$ sensors are measuring some common, ongoing phenomenon.","meta":{"url":"http://arxiv.org/abs/2310.15932v1"},"cats":{"benchmark":0.381945951,"new-dataset":0.0737985853,"data-annotation":0.5022449241,"dev-research":0.1919862656,"llms":0.4126364865,"data-quality":0.1398325692}}
{"text":"At each time step $t=1,2,\\ldots,T$, the $i^{th}$ sensor reports its readings $x^{(i)}_t$ for that time step.","meta":{"url":"http://arxiv.org/abs/2310.15932v1"},"cats":{"benchmark":0.3340873788,"new-dataset":0.1175536737,"data-annotation":0.5049858525,"dev-research":0.1421883863,"llms":0.4344742857,"data-quality":0.0657473655}}
{"text":"The algorithm must then commit to its estimate $\\mu_t$ for the true mean value of the process at time $t$. We assume that most of the sensors observe independent samples from some common distribution $X$, but an $\\epsilon$-fraction of them may instead behave maliciously.","meta":{"url":"http://arxiv.org/abs/2310.15932v1"},"cats":{"benchmark":0.4428345601,"new-dataset":0.0073285255,"data-annotation":0.5140489586,"dev-research":0.1375956438,"llms":0.4559135254,"data-quality":0.135665785}}
{"text":"The algorithm wishes to compute a good approximation $\\mu$ to the true mean $\\mu^\\ast := \\mathbf{E}[X]$. We note that if the algorithm is allowed to wait until time $T$ to report its estimate, this reduces to the well-studied problem of robust mean estimation.","meta":{"url":"http://arxiv.org/abs/2310.15932v1"},"cats":{"benchmark":0.5543588483,"new-dataset":0.0077542493,"data-annotation":0.5313682891,"dev-research":0.1492626153,"llms":0.3844140825,"data-quality":0.1272178642}}
{"text":"However, the requirement that our algorithm produces partial estimates as the data is coming in substantially complicates the situation.   ","meta":{"url":"http://arxiv.org/abs/2310.15932v1"},"cats":{"benchmark":0.5728412673,"new-dataset":0.0224438382,"data-annotation":0.493306967,"dev-research":0.1979732498,"llms":0.331298155,"data-quality":0.1428407888}}
{"text":"We prove two main results about online robust mean estimation in this model.","meta":{"url":"http://arxiv.org/abs/2310.15932v1"},"cats":{"benchmark":0.5231439621,"new-dataset":0.0319805818,"data-annotation":0.5302282036,"dev-research":0.1332795379,"llms":0.3274234851,"data-quality":0.2249712373}}
{"text":"First, if the uncorrupted samples satisfy the standard condition of $(\\epsilon,\\delta)$-stability, we give an efficient online algorithm that outputs estimates $\\mu_t$, $t","meta":{"url":"http://arxiv.org/abs/2310.15932v1"},"cats":{"benchmark":0.5655171607,"new-dataset":0.0975958317,"data-annotation":0.5169020548,"dev-research":0.0828171298,"llms":0.4235929651,"data-quality":0.120922853}}
{"text":"\\in [T],$ such that with high probability it holds that $\\|\\mu-\\mu^\\ast\\|_2 = O(\\delta \\log(T))$, where $\\mu = (","meta":{"url":"http://arxiv.org/abs/2310.15932v1"},"cats":{"benchmark":0.5166933302,"new-dataset":0.0243856808,"data-annotation":0.5369597462,"dev-research":0.1281276712,"llms":0.5103705542,"data-quality":0.0981387983}}
{"text":"\\mu_t)_{t \\in","meta":{"url":"http://arxiv.org/abs/2310.15932v1"},"cats":{"benchmark":0.3068839183,"new-dataset":0.0600514938,"data-annotation":0.5123128967,"dev-research":0.1130234567,"llms":0.5032613612,"data-quality":0.0689833228}}
{"text":"[T]}$. We note that this error bound is nearly competitive with the best offline algorithms, which would achieve $\\ell_2$-error of $O(\\delta)$. Our second main result shows that with additional assumptions on the input (most notably that $X$ is a product distribution) there are inefficient algorithms whose error does not depend on $T$ at all.","meta":{"url":"http://arxiv.org/abs/2310.15932v1"},"cats":{"benchmark":0.564929981,"new-dataset":0.0293701157,"data-annotation":0.545208737,"dev-research":0.1601318487,"llms":0.4202765189,"data-quality":0.2473433191}}
{"text":"Autonomous exploration is a fundamental problem for various applications of unmanned aerial vehicles(UAVs).","meta":{"url":"http://arxiv.org/abs/2310.15931v1"},"cats":{"benchmark":0.1961156141,"new-dataset":0.0129709728,"data-annotation":0.5163755286,"dev-research":0.172244541,"llms":0.441016619,"data-quality":0.0714703481}}
{"text":"Existing methods, however, are demonstrated to static local optima and two-dimensional exploration.","meta":{"url":"http://arxiv.org/abs/2310.15931v1"},"cats":{"benchmark":0.4334250775,"new-dataset":0.011891183,"data-annotation":0.5244454629,"dev-research":0.1432162736,"llms":0.4225037629,"data-quality":0.0548369473}}
{"text":"To address these challenges, this paper introduces GO-FEAP (Global Optimal UAV Planner Using Frontier-Omission-Aware Exploration and Altitude-Stratified Planning), aiming to achieve efficient and complete three-dimensional exploration.","meta":{"url":"http://arxiv.org/abs/2310.15931v1"},"cats":{"benchmark":0.3289792141,"new-dataset":0.0188944931,"data-annotation":0.5042497185,"dev-research":0.1557522205,"llms":0.5056156779,"data-quality":0.0274562323}}
{"text":"Frontier-Omission-Aware Exploration module presented in this work takes into account multiple pivotal factors, encompassing frontier distance, nearby frontier count, frontier duration, and frontier categorization, for a comprehensive assessment of frontier importance.","meta":{"url":"http://arxiv.org/abs/2310.15931v1"},"cats":{"benchmark":0.3025782918,"new-dataset":0.0451488303,"data-annotation":0.520448775,"dev-research":0.1707878891,"llms":0.4893509534,"data-quality":0.1031777446}}
{"text":"Furthermore, to tackle scenarios with substantial vertical variations, we introduce the Altitude-Stratified Planning strategy, which stratifies the three-dimensional space based on altitude, conducting global-local planning for each stratum.","meta":{"url":"http://arxiv.org/abs/2310.15931v1"},"cats":{"benchmark":0.3617988331,"new-dataset":0.0295646034,"data-annotation":0.4780450368,"dev-research":0.2102349285,"llms":0.498867142,"data-quality":0.0305357108}}
{"text":"The objective of global planning is to identify the most optimal frontier for exploration, followed by viewpoint selection and local path optimization based on frontier type, ultimately generating dynamically feasible three-dimensional spatial exploration trajectories.","meta":{"url":"http://arxiv.org/abs/2310.15931v1"},"cats":{"benchmark":0.2866386973,"new-dataset":0.0143448398,"data-annotation":0.5041870562,"dev-research":0.1806687765,"llms":0.4313992599,"data-quality":0.0314273243}}
{"text":"We present extensive benchmark and real-world tests, in which our method completes the exploration tasks with unprecedented completeness compared to state-of-the-art approaches.","meta":{"url":"http://arxiv.org/abs/2310.15931v1"},"cats":{"benchmark":0.6045376187,"new-dataset":0.0664282292,"data-annotation":0.5152213685,"dev-research":0.1386289729,"llms":0.4552069342,"data-quality":0.0638289433}}
{"text":"We present the Chinese Dysarthria Speech Database (CDSD) as a valuable resource for dysarthria research.","meta":{"url":"http://arxiv.org/abs/2310.15930v1"},"cats":{"benchmark":0.2522999696,"new-dataset":0.670743684,"data-annotation":0.5126707004,"dev-research":0.175047007,"llms":0.6052658718,"data-quality":0.1885788495}}
{"text":"This database comprises speech data from 24 participants with dysarthria.","meta":{"url":"http://arxiv.org/abs/2310.15930v1"},"cats":{"benchmark":0.2533946451,"new-dataset":0.8134149126,"data-annotation":0.5086236787,"dev-research":0.1836514876,"llms":0.5472440685,"data-quality":0.1174429591}}
{"text":"Among these participants, one recorded an additional 10 hours of speech data, while each recorded one hour, resulting in 34 hours of speech material.","meta":{"url":"http://arxiv.org/abs/2310.15930v1"},"cats":{"benchmark":0.3559119602,"new-dataset":0.4197461363,"data-annotation":0.5162341228,"dev-research":0.1914507685,"llms":0.5059548528,"data-quality":0.1197798752}}
{"text":"To accommodate participants with varying cognitive levels, our text pool primarily consists of content from the AISHELL-1 dataset and speeches by primary and secondary school students.","meta":{"url":"http://arxiv.org/abs/2310.15930v1"},"cats":{"benchmark":0.2153846671,"new-dataset":0.4687599161,"data-annotation":0.5327000848,"dev-research":0.1674334539,"llms":0.5359830297,"data-quality":0.1570727968}}
{"text":"When participants read these texts, they must use a mobile device or the ZOOM F8n multi-track field recorder to record their speeches.","meta":{"url":"http://arxiv.org/abs/2310.15930v1"},"cats":{"benchmark":0.2373048702,"new-dataset":0.1709292657,"data-annotation":0.5259092725,"dev-research":0.1584064872,"llms":0.5261658895,"data-quality":0.1323347}}
{"text":"In this paper, we elucidate the data collection and annotation processes and present an approach for establishing a baseline for dysarthric speech recognition.","meta":{"url":"http://arxiv.org/abs/2310.15930v1"},"cats":{"benchmark":0.3788774404,"new-dataset":0.6067199712,"data-annotation":0.5280107753,"dev-research":0.2226075577,"llms":0.5282216879,"data-quality":0.3311604316}}
{"text":"Furthermore, we conducted a speaker-dependent dysarthric speech recognition experiment using an additional 10 hours of speech data from one of our participants.","meta":{"url":"http://arxiv.org/abs/2310.15930v1"},"cats":{"benchmark":0.3908910799,"new-dataset":0.14975217,"data-annotation":0.5299149241,"dev-research":0.1761249238,"llms":0.5367711294,"data-quality":0.1305803138}}
{"text":"Our research findings indicate that, through extensive data-driven model training, fine-tuning limited quantities of specific individual data yields commendable results in speaker-dependent dysarthric speech recognition.","meta":{"url":"http://arxiv.org/abs/2310.15930v1"},"cats":{"benchmark":0.3468854005,"new-dataset":0.1147852305,"data-annotation":0.5186449342,"dev-research":0.1685569715,"llms":0.4909976146,"data-quality":0.186963078}}
{"text":"However, we observe significant variations in recognition results among different dysarthric speakers.","meta":{"url":"http://arxiv.org/abs/2310.15930v1"},"cats":{"benchmark":0.342353238,"new-dataset":0.0706549438,"data-annotation":0.5420565053,"dev-research":0.1524536975,"llms":0.5341772211,"data-quality":0.2070310363}}
{"text":"These insights provide valuable reference points for speaker-dependent dysarthric speech recognition.","meta":{"url":"http://arxiv.org/abs/2310.15930v1"},"cats":{"benchmark":0.4166741883,"new-dataset":0.0571758231,"data-annotation":0.5457165457,"dev-research":0.1574282048,"llms":0.5229355742,"data-quality":0.1841359942}}
{"text":"Traditional pruning methods are known to be challenging to work in Large Language Models (LLMs) for Generative AI because of their unaffordable training process and large computational demands.","meta":{"url":"http://arxiv.org/abs/2310.15929v1"},"cats":{"benchmark":0.3106887032,"new-dataset":0.0338606254,"data-annotation":0.5457492958,"dev-research":0.1154454456,"llms":0.6517995874,"data-quality":0.1793915106}}
{"text":"For the first time, we introduce the information entropy of hidden state features into a pruning metric design, namely E-Sparse, to improve the accuracy of N:M sparsity on LLM.","meta":{"url":"http://arxiv.org/abs/2310.15929v1"},"cats":{"benchmark":0.4572785202,"new-dataset":0.0406983667,"data-annotation":0.5312115025,"dev-research":0.1121684201,"llms":0.5595522402,"data-quality":0.1871074409}}
{"text":"E-Sparse employs the information richness to leverage the channel importance, and further incorporates several novel techniques to put it into effect: (1) it introduces information entropy to enhance the significance of parameter weights and input feature norms as a novel pruning metric, and performs N:M sparsity without modifying the remaining weights.","meta":{"url":"http://arxiv.org/abs/2310.15929v1"},"cats":{"benchmark":0.5337407674,"new-dataset":0.0040473527,"data-annotation":0.5254879711,"dev-research":0.1416307068,"llms":0.435174769,"data-quality":0.1549572711}}
{"text":"(2) it designs global naive shuffle and local block shuffle to quickly optimize the information distribution and adequately cope with the impact of N:M sparsity on LLMs' accuracy.","meta":{"url":"http://arxiv.org/abs/2310.15929v1"},"cats":{"benchmark":0.4517427959,"new-dataset":0.0105053614,"data-annotation":0.5033506183,"dev-research":0.1083951865,"llms":0.7132317613,"data-quality":0.1959110369}}
{"text":"E-Sparse is implemented as a Sparse-GEMM on FasterTransformer and runs on NVIDIA Ampere GPUs.","meta":{"url":"http://arxiv.org/abs/2310.15929v1"},"cats":{"benchmark":0.4911702268,"new-dataset":0.0212396662,"data-annotation":0.4995182962,"dev-research":0.1203782584,"llms":0.4841872319,"data-quality":0.0633487857}}
{"text":"Extensive experiments on the LLaMA family and OPT models show that E-Sparse can significantly speed up the model inference over the dense model (up to 1.53X) and obtain significant memory saving (up to 43.52%), with acceptable accuracy loss.","meta":{"url":"http://arxiv.org/abs/2310.15929v1"},"cats":{"benchmark":0.4593303137,"new-dataset":0.0129090803,"data-annotation":0.5166198478,"dev-research":0.0895551517,"llms":0.5411178829,"data-quality":0.0710692951}}
{"text":"We introduce AO-Grasp, a grasp proposal method that generates stable and actionable 6 degree-of-freedom grasps for articulated objects.","meta":{"url":"http://arxiv.org/abs/2310.15928v1"},"cats":{"benchmark":0.2257346588,"new-dataset":0.1282368182,"data-annotation":0.5031746279,"dev-research":0.1673874403,"llms":0.5592713099,"data-quality":0.0410989295}}
{"text":"Our generated grasps enable robots to interact with articulated objects, such as opening and closing cabinets and appliances.","meta":{"url":"http://arxiv.org/abs/2310.15928v1"},"cats":{"benchmark":0.1358461836,"new-dataset":0.1221864913,"data-annotation":0.5130264267,"dev-research":0.18232034,"llms":0.5779714456,"data-quality":0.0450759537}}
{"text":"Given a segmented partial point cloud of a single articulated object, AO-Grasp predicts the best grasp points on the object with a novel Actionable Grasp Point Predictor model and then finds corresponding grasp orientations for each point by leveraging a state-of-the-art rigid object grasping method.","meta":{"url":"http://arxiv.org/abs/2310.15928v1"},"cats":{"benchmark":0.3216818624,"new-dataset":0.0813486559,"data-annotation":0.5184978939,"dev-research":0.1215065838,"llms":0.4110274221,"data-quality":0.0510334988}}
{"text":"We train AO-Grasp on our new AO-Grasp Dataset, which contains 48K actionable parallel-jaw grasps on synthetic articulated objects.","meta":{"url":"http://arxiv.org/abs/2310.15928v1"},"cats":{"benchmark":0.1988022183,"new-dataset":0.8015889342,"data-annotation":0.4971929337,"dev-research":0.1146335162,"llms":0.5415862693,"data-quality":0.0560232216}}
{"text":"In simulation, AO-Grasp achieves higher grasp success rates than existing rigid object grasping and articulated object interaction baselines on both train and test categories.","meta":{"url":"http://arxiv.org/abs/2310.15928v1"},"cats":{"benchmark":0.3622845173,"new-dataset":0.0403903692,"data-annotation":0.5105612562,"dev-research":0.1739163236,"llms":0.494189003,"data-quality":0.0813381383}}
{"text":"Additionally, we evaluate AO-Grasp on 120 realworld scenes of objects with varied geometries, articulation axes, and joint states, where AO-Grasp produces successful grasps on 67.5% of scenes, while the baseline only produces successful grasps on 33.3% of scenes.","meta":{"url":"http://arxiv.org/abs/2310.15928v1"},"cats":{"benchmark":0.2815151948,"new-dataset":0.2269405811,"data-annotation":0.5209649445,"dev-research":0.1399209332,"llms":0.5153918622,"data-quality":0.0783351281}}
{"text":"The performance of sentence encoders can be significantly improved through the simple practice of fine-tuning using contrastive loss.","meta":{"url":"http://arxiv.org/abs/2310.15921v1"},"cats":{"benchmark":0.4358704494,"new-dataset":0.0274033166,"data-annotation":0.5345902394,"dev-research":0.191045277,"llms":0.518151368,"data-quality":0.2469832904}}
{"text":"A natural question arises: what characteristics do models acquire during contrastive learning?","meta":{"url":"http://arxiv.org/abs/2310.15921v1"},"cats":{"benchmark":0.2287972385,"new-dataset":0.0192884024,"data-annotation":0.5195126713,"dev-research":0.1293797651,"llms":0.5119505196,"data-quality":0.0728360549}}
{"text":"This paper theoretically and experimentally shows that contrastive-based sentence encoders implicitly weight words based on information-theoretic quantities; that is, more informative words receive greater weight, while others receive less.","meta":{"url":"http://arxiv.org/abs/2310.15921v1"},"cats":{"benchmark":0.354664234,"new-dataset":0.0058066087,"data-annotation":0.5434958581,"dev-research":0.1494881495,"llms":0.4573711974,"data-quality":0.1973858506}}
{"text":"The theory states that, in the lower bound of the optimal value of the contrastive learning objective, the norm of word embedding reflects the information gain associated with the distribution of surrounding words.","meta":{"url":"http://arxiv.org/abs/2310.15921v1"},"cats":{"benchmark":0.4055563195,"new-dataset":0.0058016671,"data-annotation":0.5532221477,"dev-research":0.1187538252,"llms":0.4390269617,"data-quality":0.2318662907}}
{"text":"We also conduct comprehensive experiments using various models, multiple datasets, two methods to measure the implicit weighting of models (Integrated Gradients and SHAP), and two information-theoretic quantities (information gain and self-information).","meta":{"url":"http://arxiv.org/abs/2310.15921v1"},"cats":{"benchmark":0.444629262,"new-dataset":0.0088733518,"data-annotation":0.5366970728,"dev-research":0.1029701891,"llms":0.3838308897,"data-quality":0.154045589}}
{"text":"The results provide empirical evidence that contrastive fine-tuning emphasizes informative words.","meta":{"url":"http://arxiv.org/abs/2310.15921v1"},"cats":{"benchmark":0.454855931,"new-dataset":0.0126133208,"data-annotation":0.5406985502,"dev-research":0.2572352833,"llms":0.5388084452,"data-quality":0.350884923}}
{"text":"In-context learning (ICL) in Large Language Models (LLMs) has emerged as a powerful new learning paradigm.","meta":{"url":"http://arxiv.org/abs/2310.15916v1"},"cats":{"benchmark":0.2205414863,"new-dataset":0.0770113221,"data-annotation":0.5286413065,"dev-research":0.1150319931,"llms":0.6328512031,"data-quality":0.1543923905}}
{"text":"However, its underlying mechanism is still not well understood.","meta":{"url":"http://arxiv.org/abs/2310.15916v1"},"cats":{"benchmark":0.1920117199,"new-dataset":0.0017102579,"data-annotation":0.5034833094,"dev-research":0.188634243,"llms":0.4911306724,"data-quality":0.1038656621}}
{"text":"In particular, it is challenging to map it to the \"standard\" machine learning framework, where one uses a training set $S$ to find a best-fitting function $f(x)$ in some hypothesis class.","meta":{"url":"http://arxiv.org/abs/2310.15916v1"},"cats":{"benchmark":0.3596253516,"new-dataset":0.0122078762,"data-annotation":0.5221180596,"dev-research":0.1644175785,"llms":0.4053282,"data-quality":0.2015424779}}
{"text":"Here we make progress on this problem by showing that the functions learned by ICL often have a very simple structure: they correspond to the transformer LLM whose only inputs are the query $x$ and a single \"task vector\" calculated from the training set.","meta":{"url":"http://arxiv.org/abs/2310.15916v1"},"cats":{"benchmark":0.2787613401,"new-dataset":0.0949618957,"data-annotation":0.5310657474,"dev-research":0.0993949402,"llms":0.5341825349,"data-quality":0.0937656595}}
{"text":"Thus, ICL can be seen as compressing $S$ into a single task vector $\\boldsymbol{\\theta}(S)$ and then using this task vector to modulate the transformer to produce the output.","meta":{"url":"http://arxiv.org/abs/2310.15916v1"},"cats":{"benchmark":0.3094401797,"new-dataset":0.0198968711,"data-annotation":0.5076103814,"dev-research":0.1283207086,"llms":0.5343831012,"data-quality":0.0715143723}}
{"text":"We support the above claim via comprehensive experiments across a range of models and tasks.","meta":{"url":"http://arxiv.org/abs/2310.15916v1"},"cats":{"benchmark":0.5434125016,"new-dataset":0.0123735495,"data-annotation":0.5279988833,"dev-research":0.1118419895,"llms":0.4573113023,"data-quality":0.1042612939}}
{"text":"This paper develops a novel minimal-state operational semantics for higher-order functional languages which uses only the call stack and two source program points as the complete state information: there is no environment, no substitution, no continuation, etc.","meta":{"url":"http://arxiv.org/abs/2310.15915v1"},"cats":{"benchmark":0.2850247001,"new-dataset":0.0408240691,"data-annotation":0.5059697431,"dev-research":0.2746120359,"llms":0.5762694522,"data-quality":0.1131441783}}
{"text":"We prove this form of operational semantics is equivalent to standard presentations.   ","meta":{"url":"http://arxiv.org/abs/2310.15915v1"},"cats":{"benchmark":0.2142086724,"new-dataset":0.0525837187,"data-annotation":0.5154507929,"dev-research":0.3137987793,"llms":0.5489444749,"data-quality":0.1851016844}}
{"text":"We then show how this approach can open the door to potential new applications: we define a program analysis as a direct finitization of this operational semantics.","meta":{"url":"http://arxiv.org/abs/2310.15915v1"},"cats":{"benchmark":0.2830023177,"new-dataset":0.0422765851,"data-annotation":0.5120708051,"dev-research":0.4784860554,"llms":0.5484838523,"data-quality":0.1461334268}}
{"text":"The program analysis that naturally emerges has a number of novel and interesting properties compared to standard program analyses for higher-order programs: for example, it can infer recurrences, and does not need value widening.","meta":{"url":"http://arxiv.org/abs/2310.15915v1"},"cats":{"benchmark":0.5371193695,"new-dataset":0.018496491,"data-annotation":0.5310714527,"dev-research":0.3531316055,"llms":0.4850989399,"data-quality":0.0759341208}}
{"text":"We both give a formal definition of the analysis and describe our current implementation.","meta":{"url":"http://arxiv.org/abs/2310.15915v1"},"cats":{"benchmark":0.5211628321,"new-dataset":0.0626639448,"data-annotation":0.5018043942,"dev-research":0.4167509425,"llms":0.4953504793,"data-quality":0.1065396996}}
{"text":"While deep learning has significantly improved ReID model accuracy under the independent and identical distribution (IID) assumption, it has also become clear that such models degrade notably when applied to an unseen novel domain due to unpredictable/unknown domain shift.","meta":{"url":"http://arxiv.org/abs/2310.15913v1"},"cats":{"benchmark":0.3754458484,"new-dataset":0.0400605376,"data-annotation":0.5063350888,"dev-research":0.140462635,"llms":0.4304743601,"data-quality":0.3020801213}}
{"text":"Contemporary domain generalization (DG) ReID models struggle in learning domain-invariant representation solely through training on an instance classification objective.","meta":{"url":"http://arxiv.org/abs/2310.15913v1"},"cats":{"benchmark":0.270689678,"new-dataset":0.061398241,"data-annotation":0.5222418042,"dev-research":0.1411048782,"llms":0.5132368562,"data-quality":0.2795484233}}
{"text":"We consider that a deep learning model is heavily influenced and therefore biased towards domain-specific characteristics, e.g., background clutter, scale and viewpoint variations, limiting the generalizability of the learned model, and hypothesize that the pedestrians are domain invariant owning they share the same structural characteristics.","meta":{"url":"http://arxiv.org/abs/2310.15913v1"},"cats":{"benchmark":0.2068424335,"new-dataset":0.1228988182,"data-annotation":0.5212516307,"dev-research":0.1744075074,"llms":0.4558022851,"data-quality":0.1171758845}}
{"text":"To enable the ReID model to be less domain-specific from these pure pedestrians, we introduce a method that guides model learning of the primary ReID instance classification objective by a concurrent auxiliary learning objective on weakly labeled pedestrian saliency detection.","meta":{"url":"http://arxiv.org/abs/2310.15913v1"},"cats":{"benchmark":0.3110129695,"new-dataset":0.2927456603,"data-annotation":0.5393260838,"dev-research":0.1820563486,"llms":0.4260697958,"data-quality":0.2457202363}}
{"text":"To solve the problem of conflicting optimization criteria in the model parameter space between the two learning objectives, we introduce a Primary-Auxiliary Objectives Association (PAOA) mechanism to calibrate the loss gradients of the auxiliary task towards the primary learning task gradients.","meta":{"url":"http://arxiv.org/abs/2310.15913v1"},"cats":{"benchmark":0.4665470909,"new-dataset":0.0088552968,"data-annotation":0.5387210722,"dev-research":0.1664716582,"llms":0.3637211256,"data-quality":0.1812724497}}
{"text":"Benefiting from the harmonious multitask learning design, our model can be extended with the recent test-time diagram to form the PAOA+, which performs on-the-fly optimization against the auxiliary objective in order to maximize the model's generative capacity in the test target domain.","meta":{"url":"http://arxiv.org/abs/2310.15913v1"},"cats":{"benchmark":0.3670212794,"new-dataset":0.0206760459,"data-annotation":0.5276639039,"dev-research":0.122762384,"llms":0.4718668615,"data-quality":0.0638557422}}
{"text":"Experiments demonstrate the superiority of the proposed PAOA model.","meta":{"url":"http://arxiv.org/abs/2310.15913v1"},"cats":{"benchmark":0.4504701827,"new-dataset":0.0047444688,"data-annotation":0.5069033434,"dev-research":0.0936814719,"llms":0.3764035083,"data-quality":0.0590087199}}
{"text":"The United Nations has identified improving food security and reducing hunger as essential components of its sustainable development goals.","meta":{"url":"http://arxiv.org/abs/2310.15912v1"},"cats":{"benchmark":0.3130687768,"new-dataset":0.052792139,"data-annotation":0.491485684,"dev-research":0.1756204507,"llms":0.4464142508,"data-quality":0.0620031344}}
{"text":"As of 2021, approximately 828 million people worldwide are experiencing hunger and malnutrition, with numerous fatalities reported.","meta":{"url":"http://arxiv.org/abs/2310.15912v1"},"cats":{"benchmark":0.2906049559,"new-dataset":0.2627112207,"data-annotation":0.5220720167,"dev-research":0.2365169938,"llms":0.4577198396,"data-quality":0.1150524987}}
{"text":"Climate change significantly impacts agricultural land suitability, potentially leading to severe food shortages and subsequent social and political conflicts.","meta":{"url":"http://arxiv.org/abs/2310.15912v1"},"cats":{"benchmark":0.3070462646,"new-dataset":0.078870444,"data-annotation":0.4974223851,"dev-research":0.2353962554,"llms":0.4771032378,"data-quality":0.1016375267}}
{"text":"To address this pressing issue, we have developed a machine learning-based approach to predict the risk of substantial land suitability degradation and changes in irrigation patterns.","meta":{"url":"http://arxiv.org/abs/2310.15912v1"},"cats":{"benchmark":0.3596072286,"new-dataset":0.0681782442,"data-annotation":0.5103272189,"dev-research":0.2597417076,"llms":0.3567883337,"data-quality":0.1278433494}}
{"text":"Our study focuses on Central Eurasia, a region burdened with economic and social challenges.   ","meta":{"url":"http://arxiv.org/abs/2310.15912v1"},"cats":{"benchmark":0.2864543343,"new-dataset":0.3652050398,"data-annotation":0.5221135945,"dev-research":0.2025195882,"llms":0.4821864597,"data-quality":0.0583825838}}
{"text":"This study represents a pioneering effort in utilizing machine learning methods to assess the impact of climate change on agricultural land suitability under various carbon emissions scenarios.","meta":{"url":"http://arxiv.org/abs/2310.15912v1"},"cats":{"benchmark":0.3999360339,"new-dataset":0.0712872509,"data-annotation":0.5139130703,"dev-research":0.2448239989,"llms":0.3644378756,"data-quality":0.1549538899}}
{"text":"Through comprehensive feature importance analysis, we unveil specific climate and terrain characteristics that exert influence on land suitability.","meta":{"url":"http://arxiv.org/abs/2310.15912v1"},"cats":{"benchmark":0.4875693623,"new-dataset":0.0545978816,"data-annotation":0.4992602682,"dev-research":0.2228616793,"llms":0.4294230415,"data-quality":0.0677671098}}
{"text":"Our approach achieves remarkable accuracy, offering policymakers invaluable insights to facilitate informed decisions aimed at averting a humanitarian crisis, including strategies such as the provision of additional water and fertilizers.","meta":{"url":"http://arxiv.org/abs/2310.15912v1"},"cats":{"benchmark":0.2872555729,"new-dataset":0.0507268431,"data-annotation":0.4869218125,"dev-research":0.2762463849,"llms":0.4917269358,"data-quality":0.1114031183}}
{"text":"This research underscores the tremendous potential of machine learning in addressing global challenges, with a particular emphasis on mitigating hunger and malnutrition.","meta":{"url":"http://arxiv.org/abs/2310.15912v1"},"cats":{"benchmark":0.3023531879,"new-dataset":0.033312092,"data-annotation":0.520633202,"dev-research":0.1504148925,"llms":0.3611507486,"data-quality":0.1427698249}}
{"text":"Language Models (LMs) often must integrate facts they memorized in pretraining with new information that appears in a given context.","meta":{"url":"http://arxiv.org/abs/2310.15910v1"},"cats":{"benchmark":0.1981790656,"new-dataset":0.0301406811,"data-annotation":0.5228045179,"dev-research":0.2294684104,"llms":0.6373547691,"data-quality":0.2709222397}}
{"text":"These two sources can disagree, causing competition within the model, and it is unclear how an LM will resolve the conflict.","meta":{"url":"http://arxiv.org/abs/2310.15910v1"},"cats":{"benchmark":0.3950782162,"new-dataset":0.0059614673,"data-annotation":0.4910968831,"dev-research":0.1216992455,"llms":0.5630534874,"data-quality":0.1612442598}}
{"text":"On a dataset that queries for knowledge of world capitals, we investigate both distributional and mechanistic determinants of LM behavior in such situations.","meta":{"url":"http://arxiv.org/abs/2310.15910v1"},"cats":{"benchmark":0.2610295422,"new-dataset":0.1666387142,"data-annotation":0.5127173259,"dev-research":0.1084875117,"llms":0.5190760823,"data-quality":0.1290555984}}
{"text":"Specifically, we measure the proportion of the time an LM will use a counterfactual prefix (e.g., \"The capital of Poland is London\") to overwrite what it learned in pretraining (\"Warsaw\").","meta":{"url":"http://arxiv.org/abs/2310.15910v1"},"cats":{"benchmark":0.4316842786,"new-dataset":0.0664585694,"data-annotation":0.5073794835,"dev-research":0.1598381941,"llms":0.5801920179,"data-quality":0.2000405005}}
{"text":"On Pythia and GPT2, the training frequency of both the query country (\"Poland\") and the in-context city (\"London\") highly affect the models' likelihood of using the counterfactual.","meta":{"url":"http://arxiv.org/abs/2310.15910v1"},"cats":{"benchmark":0.3152498811,"new-dataset":0.0605699004,"data-annotation":0.5091922271,"dev-research":0.1383819756,"llms":0.532208758,"data-quality":0.1806402129}}
{"text":"We then use head attribution to identify individual attention heads that either promote the memorized answer or the in-context answer in the logits.","meta":{"url":"http://arxiv.org/abs/2310.15910v1"},"cats":{"benchmark":0.2276811148,"new-dataset":0.0324252213,"data-annotation":0.531128955,"dev-research":0.237465765,"llms":0.5961309856,"data-quality":0.1426883426}}
{"text":"By scaling up or down the value vector of these heads, we can control the likelihood of using the in-context answer on new data.","meta":{"url":"http://arxiv.org/abs/2310.15910v1"},"cats":{"benchmark":0.3284232231,"new-dataset":0.0558163159,"data-annotation":0.5104458779,"dev-research":0.1455556906,"llms":0.4615375139,"data-quality":0.1497792514}}
{"text":"This method can increase the rate of generating the in-context answer to 88\\% of the time simply by scaling a single head at runtime.","meta":{"url":"http://arxiv.org/abs/2310.15910v1"},"cats":{"benchmark":0.4959725579,"new-dataset":0.0168761713,"data-annotation":0.5382763219,"dev-research":0.1917789378,"llms":0.5062697871,"data-quality":0.1029629758}}
{"text":"Our work contributes to a body of evidence showing that we can often localize model behaviors to specific components and provides a proof of concept for how future methods might control model behavior dynamically at runtime.","meta":{"url":"http://arxiv.org/abs/2310.15910v1"},"cats":{"benchmark":0.2699469433,"new-dataset":0.0162652206,"data-annotation":0.5170424904,"dev-research":0.3186073149,"llms":0.5345615851,"data-quality":0.0948460571}}
{"text":"Linear reduced-order modeling (ROM) simplifies complex simulations by approximating the behavior of a system using a simplified kinematic representation.","meta":{"url":"http://arxiv.org/abs/2310.15907v1"},"cats":{"benchmark":0.496818567,"new-dataset":0.0124962157,"data-annotation":0.5141825924,"dev-research":0.1593272337,"llms":0.4196816563,"data-quality":0.0408976388}}
{"text":"Typically, ROM is trained on input simulations created with a specific spatial discretization, and then serves to accelerate simulations with the same discretization.","meta":{"url":"http://arxiv.org/abs/2310.15907v1"},"cats":{"benchmark":0.2946575422,"new-dataset":0.0209128957,"data-annotation":0.4938268035,"dev-research":0.2386023498,"llms":0.5137361872,"data-quality":0.0568526161}}
{"text":"This discretization-dependence is restrictive.   ","meta":{"url":"http://arxiv.org/abs/2310.15907v1"},"cats":{"benchmark":0.4285546936,"new-dataset":0.0070275802,"data-annotation":0.4993567027,"dev-research":0.1312407715,"llms":0.392806858,"data-quality":0.0798316821}}
{"text":"Becoming independent of a specific discretization would provide flexibility to mix and match mesh resolutions, connectivity, and type (tetrahedral, hexahedral) in training data; to accelerate simulations with novel discretizations unseen during training; and to accelerate adaptive simulations that temporally or parametrically change the discretization.   ","meta":{"url":"http://arxiv.org/abs/2310.15907v1"},"cats":{"benchmark":0.3230212871,"new-dataset":0.0088112151,"data-annotation":0.4828694118,"dev-research":0.1851643956,"llms":0.4729586792,"data-quality":0.0393420579}}
{"text":"We present a flexible, discretization-independent approach to reduced-order modeling.","meta":{"url":"http://arxiv.org/abs/2310.15907v1"},"cats":{"benchmark":0.588262373,"new-dataset":0.012949823,"data-annotation":0.5030567203,"dev-research":0.120327612,"llms":0.3817087726,"data-quality":0.0597033657}}
{"text":"Like traditional ROM, we represent the configuration as a linear combination of displacement fields.","meta":{"url":"http://arxiv.org/abs/2310.15907v1"},"cats":{"benchmark":0.2239563956,"new-dataset":0.0594142324,"data-annotation":0.4840169432,"dev-research":0.1692926932,"llms":0.4475239851,"data-quality":0.0580877378}}
{"text":"Unlike traditional ROM, our displacement fields are continuous maps from every point on the reference domain to a corresponding displacement vector; these maps are represented as implicit neural fields.   ","meta":{"url":"http://arxiv.org/abs/2310.15907v1"},"cats":{"benchmark":0.1804844939,"new-dataset":0.0918758373,"data-annotation":0.4958125757,"dev-research":0.187932982,"llms":0.4608257413,"data-quality":0.0993557516}}
{"text":"With linear continuous ROM (LiCROM), our training set can include multiple geometries undergoing multiple loading conditions, independent of their discretization.","meta":{"url":"http://arxiv.org/abs/2310.15907v1"},"cats":{"benchmark":0.4106112423,"new-dataset":0.0408831914,"data-annotation":0.4998102893,"dev-research":0.131488494,"llms":0.4337139284,"data-quality":0.0583679462}}
{"text":"This opens the door to novel applications of reduced order modeling.","meta":{"url":"http://arxiv.org/abs/2310.15907v1"},"cats":{"benchmark":0.5205062466,"new-dataset":0.005598084,"data-annotation":0.5076543003,"dev-research":0.1343727092,"llms":0.4380292846,"data-quality":0.0543098234}}
{"text":"We can now accelerate simulations that modify the geometry at runtime, for instance via cutting, hole punching, and even swapping the entire mesh.","meta":{"url":"http://arxiv.org/abs/2310.15907v1"},"cats":{"benchmark":0.3682282786,"new-dataset":0.0043065934,"data-annotation":0.5086307375,"dev-research":0.2325856605,"llms":0.528850452,"data-quality":0.043326914}}
{"text":"We can also accelerate simulations of geometries unseen during training.","meta":{"url":"http://arxiv.org/abs/2310.15907v1"},"cats":{"benchmark":0.2457399555,"new-dataset":0.0200767297,"data-annotation":0.531503504,"dev-research":0.1656902382,"llms":0.5092161678,"data-quality":0.0588362202}}
{"text":"We demonstrate one-shot generalization, training on a single geometry and subsequently simulating various unseen geometries.","meta":{"url":"http://arxiv.org/abs/2310.15907v1"},"cats":{"benchmark":0.2685045052,"new-dataset":0.067661589,"data-annotation":0.5318226026,"dev-research":0.1275997698,"llms":0.4579366179,"data-quality":0.1064568614}}
{"text":"The ability to identify and control different kinds of linguistic information encoded in vector representations of words has many use cases, especially for explainability and bias removal.","meta":{"url":"http://arxiv.org/abs/2310.15905v1"},"cats":{"benchmark":0.267076092,"new-dataset":0.0053288779,"data-annotation":0.557287521,"dev-research":0.2414092805,"llms":0.4814118381,"data-quality":0.3568783562}}
{"text":"This is usually done via a set of simple classification tasks, termed probes, to evaluate the information encoded in the embedding space.","meta":{"url":"http://arxiv.org/abs/2310.15905v1"},"cats":{"benchmark":0.3311646602,"new-dataset":0.0550736879,"data-annotation":0.548241307,"dev-research":0.1637177111,"llms":0.493796467,"data-quality":0.2016349187}}
{"text":"However, the involvement of a trainable classifier leads to entanglement between the probe's results and the classifier's nature.","meta":{"url":"http://arxiv.org/abs/2310.15905v1"},"cats":{"benchmark":0.255171499,"new-dataset":0.00822654,"data-annotation":0.5318735768,"dev-research":0.1457302126,"llms":0.5391537208,"data-quality":0.1883718299}}
{"text":"As a result, contemporary works on probing include tasks that do not involve training of auxiliary models.","meta":{"url":"http://arxiv.org/abs/2310.15905v1"},"cats":{"benchmark":0.2390751545,"new-dataset":0.0072879485,"data-annotation":0.5213538734,"dev-research":0.1636660007,"llms":0.5681501958,"data-quality":0.1200250117}}
{"text":"In this work we introduce the term indicator tasks for non-trainable tasks which are used to query embedding spaces for the existence of certain properties, and claim that this kind of tasks may point to a direction opposite to probes, and that this contradiction complicates the decision on whether a property exists in an embedding space.","meta":{"url":"http://arxiv.org/abs/2310.15905v1"},"cats":{"benchmark":0.264934101,"new-dataset":0.0183928601,"data-annotation":0.5306858905,"dev-research":0.1837253557,"llms":0.5610756569,"data-quality":0.1865183504}}
{"text":"We demonstrate our claims with two test cases, one dealing with gender debiasing and another with the erasure of morphological information from embedding spaces.","meta":{"url":"http://arxiv.org/abs/2310.15905v1"},"cats":{"benchmark":0.3494800037,"new-dataset":0.0510231053,"data-annotation":0.5491622177,"dev-research":0.1384178025,"llms":0.4842626726,"data-quality":0.4292296591}}
{"text":"We show that the application of a suitable indicator provides a more accurate picture of the information captured and removed compared to probes.","meta":{"url":"http://arxiv.org/abs/2310.15905v1"},"cats":{"benchmark":0.4766988424,"new-dataset":0.0558378415,"data-annotation":0.5223379501,"dev-research":0.1663689,"llms":0.4812162395,"data-quality":0.1797855684}}
{"text":"We thus conclude that indicator tasks should be implemented and taken into consideration when eliciting information from embedded representations.","meta":{"url":"http://arxiv.org/abs/2310.15905v1"},"cats":{"benchmark":0.2570620017,"new-dataset":0.0254410686,"data-annotation":0.5356647856,"dev-research":0.2811395653,"llms":0.499089875,"data-quality":0.1225971276}}
{"text":"Recent developments in generative AI have shone a spotlight on high-performance synthetic text generation technologies.","meta":{"url":"http://arxiv.org/abs/2310.15904v1"},"cats":{"benchmark":0.242057671,"new-dataset":0.1235662949,"data-annotation":0.5220804445,"dev-research":0.2471113324,"llms":0.6046102871,"data-quality":0.1320937945}}
{"text":"The now wide availability and ease of use of such models highlights the urgent need to provide equally powerful technologies capable of identifying synthetic text.","meta":{"url":"http://arxiv.org/abs/2310.15904v1"},"cats":{"benchmark":0.2975568395,"new-dataset":0.1651545621,"data-annotation":0.514858331,"dev-research":0.1313220822,"llms":0.5297273061,"data-quality":0.2423357673}}
{"text":"With this in mind, we draw inspiration from psychological studies which suggest that people can be driven by emotion and encode emotion in the text they compose.","meta":{"url":"http://arxiv.org/abs/2310.15904v1"},"cats":{"benchmark":0.1663080644,"new-dataset":0.0513250013,"data-annotation":0.5246610814,"dev-research":0.3068328154,"llms":0.5420709264,"data-quality":0.099414201}}
{"text":"We hypothesize that pretrained language models (PLMs) have an affective deficit because they lack such an emotional driver when generating text and consequently may generate synthetic text which has affective incoherence i.e. lacking the kind of emotional coherence present in human-authored text.","meta":{"url":"http://arxiv.org/abs/2310.15904v1"},"cats":{"benchmark":0.1867255555,"new-dataset":0.0451431132,"data-annotation":0.5349359165,"dev-research":0.2331452614,"llms":0.6160642071,"data-quality":0.1908675749}}
{"text":"We subsequently develop an emotionally aware detector by fine-tuning a PLM on emotion.","meta":{"url":"http://arxiv.org/abs/2310.15904v1"},"cats":{"benchmark":0.2597452877,"new-dataset":0.0672930607,"data-annotation":0.5308720087,"dev-research":0.2115822632,"llms":0.5875851695,"data-quality":0.2109992605}}
{"text":"Experiment results indicate that our emotionally-aware detector achieves improvements across a range of synthetic text generators, various sized models, datasets, and domains.","meta":{"url":"http://arxiv.org/abs/2310.15904v1"},"cats":{"benchmark":0.2443618351,"new-dataset":0.2233059791,"data-annotation":0.5435037328,"dev-research":0.2225936004,"llms":0.5290409666,"data-quality":0.2684927921}}
{"text":"Finally, we compare our emotionally-aware synthetic text detector to ChatGPT in the task of identification of its own output and show substantial gains, reinforcing the potential of emotion as a signal to identify synthetic text.","meta":{"url":"http://arxiv.org/abs/2310.15904v1"},"cats":{"benchmark":0.2823312997,"new-dataset":0.2918139937,"data-annotation":0.5412650138,"dev-research":0.2250190055,"llms":0.4972663885,"data-quality":0.2701327056}}
{"text":"Code, models, and datasets are available at https: //github.com/alanagiasi/emoPLMsynth","meta":{"url":"http://arxiv.org/abs/2310.15904v1"},"cats":{"benchmark":0.2789404315,"new-dataset":0.708218215,"data-annotation":0.499239456,"dev-research":0.1561906287,"llms":0.4758095133,"data-quality":0.0673968156}}
{"text":"We study deep neural networks for the multi-label classification (MLab) task through the lens of neural collapse (NC).","meta":{"url":"http://arxiv.org/abs/2310.15903v1"},"cats":{"benchmark":0.3367103172,"new-dataset":0.1070865347,"data-annotation":0.5351836761,"dev-research":0.121798327,"llms":0.4511291483,"data-quality":0.5602107419}}
{"text":"Previous works have been restricted to the multi-class classification setting and discovered a prevalent NC phenomenon comprising of the following properties for the last-layer features: (i) the variability of features within every class collapses to zero, (ii) the set of feature means form an equi-angular tight frame (ETF), and (iii) the last layer classifiers collapse to the feature mean upon some scaling.","meta":{"url":"http://arxiv.org/abs/2310.15903v1"},"cats":{"benchmark":0.2987037821,"new-dataset":0.0978963679,"data-annotation":0.5331090298,"dev-research":0.1482326224,"llms":0.4349234602,"data-quality":0.2904864427}}
{"text":"We generalize the study to multi-label learning, and prove for the first time that a generalized NC phenomenon holds with the \"pick-all-label'' formulation.","meta":{"url":"http://arxiv.org/abs/2310.15903v1"},"cats":{"benchmark":0.3843275394,"new-dataset":0.0717950426,"data-annotation":0.5355145834,"dev-research":0.1108149609,"llms":0.4673037962,"data-quality":0.5102754017}}
{"text":"Under the natural analog of the unconstrained feature model (UFM), we establish that the only global classifier of the pick-all-label cross entropy loss display the same ETF geometry which further collapse to multiplicity-1 feature class means.","meta":{"url":"http://arxiv.org/abs/2310.15903v1"},"cats":{"benchmark":0.3700335612,"new-dataset":0.1139035052,"data-annotation":0.5348628224,"dev-research":0.1156970467,"llms":0.4656716886,"data-quality":0.4106083938}}
{"text":"Besides, we discover a combinatorial property in generalized NC which is unique for multi-label learning that we call ``tag-wise average'' property, where the feature class-means of samples with multiple labels are scaled average of the feature class-means of single label tags.","meta":{"url":"http://arxiv.org/abs/2310.15903v1"},"cats":{"benchmark":0.3872186878,"new-dataset":0.0795021553,"data-annotation":0.5407589798,"dev-research":0.1425059312,"llms":0.4488789598,"data-quality":0.4621438144}}
{"text":"Theoretically, we establish global optimality result for the pick-all-label cross-entropy risk for the UFM.","meta":{"url":"http://arxiv.org/abs/2310.15903v1"},"cats":{"benchmark":0.483511577,"new-dataset":0.0457267551,"data-annotation":0.5350192699,"dev-research":0.0863192145,"llms":0.4860661192,"data-quality":0.2824795115}}
{"text":"Additionally, We also provide empirical evidence to support our investigation into training deep neural networks on multi-label datasets, resulting in improved training efficiency.","meta":{"url":"http://arxiv.org/abs/2310.15903v1"},"cats":{"benchmark":0.4345752348,"new-dataset":0.1746735127,"data-annotation":0.5281568261,"dev-research":0.1373170164,"llms":0.4749793797,"data-quality":0.4428194529}}
{"text":"The Delaunay filtration $\\mathcal{D}_{\\bullet}(X)$ of a point cloud $X\\subset \\mathbb{R}^d$ is a central tool of computational topology.","meta":{"url":"http://arxiv.org/abs/2310.15902v1"},"cats":{"benchmark":0.3684702154,"new-dataset":0.1071380217,"data-annotation":0.5041603457,"dev-research":0.1997510112,"llms":0.4879905342,"data-quality":0.0861905829}}
{"text":"Its use is justified by the topological equivalence of $\\mathcal{D}_{\\bullet}(X)$ and the offset (i.e., union-of-balls) filtration of $X$. Given a function $\\gamma: X \\to \\mathbb{R}$, we introduce a Delaunay bifiltration $\\mathcal{DC}_{\\bullet}(\\gamma)$ that satisfies an analogous topological equivalence, ensuring that $\\mathcal{DC}_{\\bullet}(\\gamma)$ topologically encodes the offset filtrations of all sublevel sets of $\\gamma$, as well as the topological relations between them.","meta":{"url":"http://arxiv.org/abs/2310.15902v1"},"cats":{"benchmark":0.3197295829,"new-dataset":0.0202146071,"data-annotation":0.487253434,"dev-research":0.2057139931,"llms":0.5865377148,"data-quality":0.1483424724}}
{"text":"$\\mathcal{DC}_{\\bullet}(\\gamma)$ is of size $O(|X|^{\\lceil\\frac{d+1}{2}\\rceil})$, which for $d$ odd matches the worst-case size of $\\mathcal{D}_{\\bullet}(X)$. Adapting the Bowyer-Watson algorithm for computing Delaunay triangulations, we give a simple, practical algorithm to compute $\\mathcal{DC}_{\\bullet}(\\gamma)$ in time $O(|X|^{\\lceil \\frac{d}{2}\\rceil +1})$.","meta":{"url":"http://arxiv.org/abs/2310.15902v1"},"cats":{"benchmark":0.538944172,"new-dataset":0.142244224,"data-annotation":0.5242265937,"dev-research":0.2064614073,"llms":0.5156885767,"data-quality":0.1688191804}}
{"text":"Our implementation, based on CGAL, computes $\\mathcal{DC}_{\\bullet}(\\gamma)$ with modest overhead compared to computing $\\mathcal{D}_{\\bullet}(X)$, and handles tens of thousands of points in $\\mathbb{R}^3$ within seconds.","meta":{"url":"http://arxiv.org/abs/2310.15902v1"},"cats":{"benchmark":0.5253239321,"new-dataset":0.0856436661,"data-annotation":0.5218651749,"dev-research":0.1251740952,"llms":0.4694874917,"data-quality":0.101533376}}
{"text":"Large language models (LLMs) have performed well in providing general and extensive health suggestions in single-turn conversations, exemplified by systems such as ChatGPT, ChatGLM, ChatDoctor, DoctorGLM, and etc.","meta":{"url":"http://arxiv.org/abs/2310.15896v1"},"cats":{"benchmark":0.1998764299,"new-dataset":0.1922595874,"data-annotation":0.5264593439,"dev-research":0.2058146975,"llms":0.7375140513,"data-quality":0.1212216139}}
{"text":"However, the limited information provided by users during single turn results in inadequate personalization and targeting of the generated suggestions, which requires users to independently select the useful part.","meta":{"url":"http://arxiv.org/abs/2310.15896v1"},"cats":{"benchmark":0.2576762687,"new-dataset":0.002807322,"data-annotation":0.5420794978,"dev-research":0.3193789418,"llms":0.4992853917,"data-quality":0.1236184949}}
{"text":"It is mainly caused by the missing ability to engage in multi-turn questioning.","meta":{"url":"http://arxiv.org/abs/2310.15896v1"},"cats":{"benchmark":0.1725079837,"new-dataset":0.0124727245,"data-annotation":0.5325943011,"dev-research":0.288190653,"llms":0.5432234057,"data-quality":0.1499782244}}
{"text":"In real-world medical consultations, doctors usually employ a series of iterative inquiries to comprehend the patient's condition thoroughly, enabling them to provide effective and personalized suggestions subsequently, which can be defined as chain of questioning (CoQ) for LLMs.","meta":{"url":"http://arxiv.org/abs/2310.15896v1"},"cats":{"benchmark":0.2040559574,"new-dataset":0.0434637899,"data-annotation":0.4906576974,"dev-research":0.2325770717,"llms":0.6712869751,"data-quality":0.0761299237}}
{"text":"To improve the CoQ of LLMs, we propose BianQue, a ChatGLM-based LLM finetuned with the self-constructed health conversation dataset BianQueCorpus that is consist of multiple turns of questioning and health suggestions polished by ChatGPT.","meta":{"url":"http://arxiv.org/abs/2310.15896v1"},"cats":{"benchmark":0.2511468379,"new-dataset":0.6803756475,"data-annotation":0.5011032741,"dev-research":0.209240866,"llms":0.6938635948,"data-quality":0.1364195471}}
{"text":"Experimental results demonstrate that the proposed BianQue can simultaneously balance the capabilities of both questioning and health suggestions, which will help promote the research and application of LLMs in the field of proactive health.","meta":{"url":"http://arxiv.org/abs/2310.15896v1"},"cats":{"benchmark":0.2661169438,"new-dataset":0.0265132631,"data-annotation":0.4773784785,"dev-research":0.2236337133,"llms":0.7119832366,"data-quality":0.0630168531}}
{"text":"The current state-of-the-art decentralized learning algorithms mostly assume the data distribution to be Independent and Identically Distributed (IID).","meta":{"url":"http://arxiv.org/abs/2310.15890v1"},"cats":{"benchmark":0.3096799794,"new-dataset":0.0267876734,"data-annotation":0.4962750869,"dev-research":0.0886018323,"llms":0.476508264,"data-quality":0.1475223751}}
{"text":"However, in practical scenarios, the distributed datasets can have significantly heterogeneous data distributions across the agents.","meta":{"url":"http://arxiv.org/abs/2310.15890v1"},"cats":{"benchmark":0.2699523716,"new-dataset":0.1692101469,"data-annotation":0.466879651,"dev-research":0.1170912261,"llms":0.4563327259,"data-quality":0.1075725436}}
{"text":"In this work, we present a novel approach for decentralized learning on heterogeneous data, where data-free knowledge distillation through contrastive loss on cross-features is utilized to improve performance.","meta":{"url":"http://arxiv.org/abs/2310.15890v1"},"cats":{"benchmark":0.3204488032,"new-dataset":0.0975178931,"data-annotation":0.4931526274,"dev-research":0.1657117307,"llms":0.4848939016,"data-quality":0.1234809059}}
{"text":"Cross-features for a pair of neighboring agents are the features (i.e., last hidden layer activations) obtained from the data of an agent with respect to the model parameters of the other agent.","meta":{"url":"http://arxiv.org/abs/2310.15890v1"},"cats":{"benchmark":0.2603125146,"new-dataset":0.135242134,"data-annotation":0.5172098689,"dev-research":0.1788164073,"llms":0.4472732875,"data-quality":0.0853115484}}
{"text":"We demonstrate the effectiveness of the proposed technique through an exhaustive set of experiments on various Computer Vision datasets (CIFAR-10, CIFAR-100, Fashion MNIST, and ImageNet), model architectures, and network topologies.","meta":{"url":"http://arxiv.org/abs/2310.15890v1"},"cats":{"benchmark":0.3051129475,"new-dataset":0.1753656076,"data-annotation":0.5071122718,"dev-research":0.1628511666,"llms":0.4565207598,"data-quality":0.203683001}}
{"text":"Our experiments show that the proposed method achieves superior performance (0.2-4% improvement in test accuracy) compared to other existing techniques for decentralized learning on heterogeneous data.","meta":{"url":"http://arxiv.org/abs/2310.15890v1"},"cats":{"benchmark":0.5441176204,"new-dataset":0.02712667,"data-annotation":0.5060422057,"dev-research":0.1419486096,"llms":0.4988069897,"data-quality":0.1706597988}}
{"text":"While deep reinforcement learning (RL) has been demonstrated effective in solving complex control tasks, sample efficiency remains a key challenge due to the large amounts of data required for remarkable performance.","meta":{"url":"http://arxiv.org/abs/2310.15888v1"},"cats":{"benchmark":0.3229823784,"new-dataset":0.1483531162,"data-annotation":0.4988699315,"dev-research":0.1603178305,"llms":0.4713345416,"data-quality":0.0668724084}}
{"text":"Existing research explores the application of representation learning for data-efficient RL, e.g., learning predictive representations by predicting long-term future states.","meta":{"url":"http://arxiv.org/abs/2310.15888v1"},"cats":{"benchmark":0.2241860189,"new-dataset":0.0622982764,"data-annotation":0.5215466362,"dev-research":0.1571534164,"llms":0.4329456504,"data-quality":0.0710750218}}
{"text":"However, many existing methods do not fully exploit the structural information inherent in sequential state signals, which can potentially improve the quality of long-term decision-making but is difficult to discern in the time domain.","meta":{"url":"http://arxiv.org/abs/2310.15888v1"},"cats":{"benchmark":0.4622473558,"new-dataset":0.0059102644,"data-annotation":0.4987911012,"dev-research":0.177617037,"llms":0.4696761305,"data-quality":0.0957247821}}
{"text":"To tackle this problem, we propose State Sequences Prediction via Fourier Transform (SPF), a novel method that exploits the frequency domain of state sequences to extract the underlying patterns in time series data for learning expressive representations efficiently.","meta":{"url":"http://arxiv.org/abs/2310.15888v1"},"cats":{"benchmark":0.2702662796,"new-dataset":0.2732795036,"data-annotation":0.5146808276,"dev-research":0.177259833,"llms":0.3987529685,"data-quality":0.0834887309}}
{"text":"Specifically, we theoretically analyze the existence of structural information in state sequences, which is closely related to policy performance and signal regularity, and then propose to predict the Fourier transform of infinite-step future state sequences to extract such information.","meta":{"url":"http://arxiv.org/abs/2310.15888v1"},"cats":{"benchmark":0.2745163454,"new-dataset":0.045734001,"data-annotation":0.5030833624,"dev-research":0.1066300405,"llms":0.4120524199,"data-quality":0.0525563865}}
{"text":"One of the appealing features of SPF is that it is simple to implement while not requiring storage of infinite-step future states as prediction targets.","meta":{"url":"http://arxiv.org/abs/2310.15888v1"},"cats":{"benchmark":0.327025341,"new-dataset":0.0333804867,"data-annotation":0.5060840609,"dev-research":0.1508797084,"llms":0.4858500336,"data-quality":0.0453413973}}
{"text":"Experiments demonstrate that the proposed method outperforms several state-of-the-art algorithms in terms of both sample efficiency and performance.","meta":{"url":"http://arxiv.org/abs/2310.15888v1"},"cats":{"benchmark":0.7951006396,"new-dataset":0.0081182141,"data-annotation":0.5327540538,"dev-research":0.1199624468,"llms":0.3944002778,"data-quality":0.1709013391}}
{"text":"With the ongoing efforts to empower people with mobility impairments and the increase in technological acceptance by the general public, assistive technologies, such as collaborative robotic arms, are gaining popularity.","meta":{"url":"http://arxiv.org/abs/2310.15887v1"},"cats":{"benchmark":0.2065809106,"new-dataset":0.0066758034,"data-annotation":0.5076933552,"dev-research":0.2782810711,"llms":0.5480366963,"data-quality":0.0582546297}}
{"text":"Yet, their widespread success is limited by usability issues, specifically the disparity between user input and software control along the autonomy continuum.","meta":{"url":"http://arxiv.org/abs/2310.15887v1"},"cats":{"benchmark":0.2404868422,"new-dataset":0.0233012047,"data-annotation":0.4904201397,"dev-research":0.4100280855,"llms":0.5608418101,"data-quality":0.1160674957}}
{"text":"To address this, shared control concepts provide opportunities to combine the targeted increase of user autonomy with a certain level of computer assistance.","meta":{"url":"http://arxiv.org/abs/2310.15887v1"},"cats":{"benchmark":0.183286441,"new-dataset":0.020270638,"data-annotation":0.4975444198,"dev-research":0.3722013054,"llms":0.5292873288,"data-quality":0.0569958252}}
{"text":"This paper presents the free and open-source AdaptiX XR framework for developing and evaluating shared control applications in a high-resolution simulation environment.","meta":{"url":"http://arxiv.org/abs/2310.15887v1"},"cats":{"benchmark":0.2899533535,"new-dataset":0.2752942029,"data-annotation":0.4842733444,"dev-research":0.2811755919,"llms":0.547400378,"data-quality":0.0542427962}}
{"text":"The initial framework consists of a simulated robotic arm with an example scenario in Virtual Reality (VR), multiple standard control interfaces, and a specialized recording/replay system.","meta":{"url":"http://arxiv.org/abs/2310.15887v1"},"cats":{"benchmark":0.1893856396,"new-dataset":0.1701060323,"data-annotation":0.4980393173,"dev-research":0.1907239738,"llms":0.4520785258,"data-quality":0.0560284247}}
{"text":"AdaptiX can easily be extended for specific research needs, allowing Human-Robot Interaction (HRI) researchers to rapidly design and test novel interaction methods, intervention strategies, and multi-modal feedback techniques, without requiring an actual physical robotic arm during the early phases of ideation, prototyping, and evaluation.","meta":{"url":"http://arxiv.org/abs/2310.15887v1"},"cats":{"benchmark":0.223005244,"new-dataset":0.0610337969,"data-annotation":0.5024299601,"dev-research":0.3223787819,"llms":0.5567695378,"data-quality":0.0450910495}}
{"text":"Also, a Robot Operating System (ROS) integration enables the controlling of a real robotic arm in a PhysicalTwin approach without any simulation-reality gap.","meta":{"url":"http://arxiv.org/abs/2310.15887v1"},"cats":{"benchmark":0.2533643289,"new-dataset":0.0123245448,"data-annotation":0.4895259126,"dev-research":0.2287936956,"llms":0.5094137555,"data-quality":0.0380306396}}
{"text":"Here, we review the capabilities and limitations of AdaptiX in detail and present three bodies of research based on the framework.","meta":{"url":"http://arxiv.org/abs/2310.15887v1"},"cats":{"benchmark":0.2553428754,"new-dataset":0.0725227203,"data-annotation":0.4756949854,"dev-research":0.2035385877,"llms":0.5457907969,"data-quality":0.0582111028}}
{"text":"AdaptiX can be accessed at https://adaptix.robot-research.de.","meta":{"url":"http://arxiv.org/abs/2310.15887v1"},"cats":{"benchmark":0.1892686215,"new-dataset":0.557492708,"data-annotation":0.500315967,"dev-research":0.1797387605,"llms":0.5413162613,"data-quality":0.0488954283}}
{"text":"Harmonic drive systems (HDS) are high-precision robotic transmissions featuring compact size and high gear ratios.","meta":{"url":"http://arxiv.org/abs/2310.15875v1"},"cats":{"benchmark":0.3152932216,"new-dataset":0.017712717,"data-annotation":0.4819720391,"dev-research":0.152612232,"llms":0.5595961955,"data-quality":0.104337753}}
{"text":"However, issues like kinematic transmission errors hamper their precision performance.","meta":{"url":"http://arxiv.org/abs/2310.15875v1"},"cats":{"benchmark":0.536472722,"new-dataset":0.0021776231,"data-annotation":0.511630114,"dev-research":0.2713000171,"llms":0.4924461716,"data-quality":0.1960370349}}
{"text":"This article focuses on data-driven modeling and analysis of an HDS to improve kinematic error compensation.","meta":{"url":"http://arxiv.org/abs/2310.15875v1"},"cats":{"benchmark":0.5401565045,"new-dataset":0.0783721529,"data-annotation":0.4758586797,"dev-research":0.2841768683,"llms":0.4533490576,"data-quality":0.1204408193}}
{"text":"The background introduces HDS mechanics, nonlinear attributes, and modeling approaches from literature.","meta":{"url":"http://arxiv.org/abs/2310.15875v1"},"cats":{"benchmark":0.3722604665,"new-dataset":0.0419793539,"data-annotation":0.4886305535,"dev-research":0.2055790705,"llms":0.4812382777,"data-quality":0.0563156037}}
{"text":"The HDS dynamics are derived using Lagrange equations.","meta":{"url":"http://arxiv.org/abs/2310.15875v1"},"cats":{"benchmark":0.3843649027,"new-dataset":0.0352795376,"data-annotation":0.5025466571,"dev-research":0.1079576271,"llms":0.4884096808,"data-quality":0.0457076834}}
{"text":"Experiments under aggressive conditions provide training data exhibiting deterministic patterns.","meta":{"url":"http://arxiv.org/abs/2310.15875v1"},"cats":{"benchmark":0.2899960466,"new-dataset":0.0938126782,"data-annotation":0.5231344876,"dev-research":0.1744911737,"llms":0.4695890495,"data-quality":0.1482444237}}
{"text":"Various linear and nonlinear models have been developed.","meta":{"url":"http://arxiv.org/abs/2310.15875v1"},"cats":{"benchmark":0.423626294,"new-dataset":0.0111945497,"data-annotation":0.5082490187,"dev-research":0.1270842308,"llms":0.2563836102,"data-quality":0.0701340772}}
{"text":"The best-performing model, based on a nonlinear neural network, achieves over 98\\% accuracy for one-step predictions on both the training and validation data sets.","meta":{"url":"http://arxiv.org/abs/2310.15875v1"},"cats":{"benchmark":0.5589798127,"new-dataset":0.0570038191,"data-annotation":0.5311317553,"dev-research":0.1464383386,"llms":0.3642442051,"data-quality":0.1362022343}}
{"text":"A phenomenological model separates the kinematic error into a periodic pure part and flexible part.","meta":{"url":"http://arxiv.org/abs/2310.15875v1"},"cats":{"benchmark":0.3566580387,"new-dataset":0.0061684532,"data-annotation":0.5108062165,"dev-research":0.1795733951,"llms":0.4121193301,"data-quality":0.1187330254}}
{"text":"Apart from implementation of estimated transmission error injection compensation, novel compensation mechanisms policies for the kinematic error are analyzed and proposed, including nonlinear model predictive control and frequency loop-shaping.","meta":{"url":"http://arxiv.org/abs/2310.15875v1"},"cats":{"benchmark":0.4753884643,"new-dataset":0.0141626566,"data-annotation":0.4951433534,"dev-research":0.2048639871,"llms":0.4062885753,"data-quality":0.2015069497}}
{"text":"The feedback loop is analyzed to select the controller for vibration mitigation.","meta":{"url":"http://arxiv.org/abs/2310.15875v1"},"cats":{"benchmark":0.4366313728,"new-dataset":0.0235876262,"data-annotation":0.497149387,"dev-research":0.2142868388,"llms":0.4730257337,"data-quality":0.101810641}}
{"text":"Main contributions include the nonlinear dynamics derivation, data-driven nonlinear modeling of flexible kinematic errors, repeatable experiment design, and proposed novel compensation mechanism and policies.","meta":{"url":"http://arxiv.org/abs/2310.15875v1"},"cats":{"benchmark":0.4161970522,"new-dataset":0.0195444264,"data-annotation":0.4812590181,"dev-research":0.1637736459,"llms":0.3661168216,"data-quality":0.0825507192}}
{"text":"Future work involves using physics-informed neural networks, sensitivity analysis, full life-cycle monitoring, and extracting physical laws directly from data.","meta":{"url":"http://arxiv.org/abs/2310.15875v1"},"cats":{"benchmark":0.2829536088,"new-dataset":0.1680690219,"data-annotation":0.5093275992,"dev-research":0.1880293152,"llms":0.482104152,"data-quality":0.0534414745}}
{"text":"In this paper, we exploit a fundamental principle of analog electronic circuitry, Kirchhoff's current law, to introduce a unique class of neural network models that we refer to as KirchhoffNet.","meta":{"url":"http://arxiv.org/abs/2310.15872v1"},"cats":{"benchmark":0.2880280438,"new-dataset":0.0347996706,"data-annotation":0.5366131579,"dev-research":0.1634991989,"llms":0.4289141792,"data-quality":0.1223920612}}
{"text":"KirchhoffNet establishes close connections with message passing neural networks and continuous-depth networks.","meta":{"url":"http://arxiv.org/abs/2310.15872v1"},"cats":{"benchmark":0.2267344415,"new-dataset":0.064861214,"data-annotation":0.5228597729,"dev-research":0.1648812076,"llms":0.4912488672,"data-quality":0.142863452}}
{"text":"We demonstrate that even in the absence of any traditional layers (such as convolution, pooling, or linear layers), KirchhoffNet attains 98.86% test accuracy on the MNIST dataset, comparable with state of the art (SOTA) results.","meta":{"url":"http://arxiv.org/abs/2310.15872v1"},"cats":{"benchmark":0.5228399795,"new-dataset":0.0718739383,"data-annotation":0.5432578479,"dev-research":0.117847483,"llms":0.4446629959,"data-quality":0.1794605769}}
{"text":"What makes KirchhoffNet more intriguing is its potential in the realm of hardware.","meta":{"url":"http://arxiv.org/abs/2310.15872v1"},"cats":{"benchmark":0.2909689141,"new-dataset":0.0071264945,"data-annotation":0.5291659956,"dev-research":0.1720676625,"llms":0.5513372768,"data-quality":0.0665729194}}
{"text":"Contemporary deep neural networks are conventionally deployed on GPUs.","meta":{"url":"http://arxiv.org/abs/2310.15872v1"},"cats":{"benchmark":0.3177154673,"new-dataset":0.0257378897,"data-annotation":0.4966471796,"dev-research":0.1642282856,"llms":0.5101819848,"data-quality":0.0994618816}}
{"text":"In contrast, KirchhoffNet can be physically realized by an analog electronic circuit.","meta":{"url":"http://arxiv.org/abs/2310.15872v1"},"cats":{"benchmark":0.2908691173,"new-dataset":0.0031260621,"data-annotation":0.5246118452,"dev-research":0.1595873108,"llms":0.4605943367,"data-quality":0.0776883023}}
{"text":"Moreover, we justify that irrespective of the number of parameters within a KirchhoffNet, its forward calculation can always be completed within 1/f seconds, with f representing the hardware's clock frequency.","meta":{"url":"http://arxiv.org/abs/2310.15872v1"},"cats":{"benchmark":0.5016021352,"new-dataset":0.0265073592,"data-annotation":0.5387565112,"dev-research":0.1235875677,"llms":0.4794163204,"data-quality":0.0625379965}}
{"text":"This characteristic introduces a promising technology for implementing ultra-large-scale neural networks.","meta":{"url":"http://arxiv.org/abs/2310.15872v1"},"cats":{"benchmark":0.3453877201,"new-dataset":0.037749794,"data-annotation":0.5021737144,"dev-research":0.1186299976,"llms":0.4838883772,"data-quality":0.0457901171}}
{"text":"Node centralities play a pivotal role in network science, social network analysis, and recommender systems.","meta":{"url":"http://arxiv.org/abs/2310.15865v1"},"cats":{"benchmark":0.3309139072,"new-dataset":0.0129088674,"data-annotation":0.5160959278,"dev-research":0.1748235305,"llms":0.4998617687,"data-quality":0.0956993846}}
{"text":"In temporal data, static path-based centralities like closeness or betweenness can give misleading results about the true importance of nodes in a temporal graph.","meta":{"url":"http://arxiv.org/abs/2310.15865v1"},"cats":{"benchmark":0.3927393618,"new-dataset":0.0206266437,"data-annotation":0.5008579889,"dev-research":0.2286090696,"llms":0.4807241337,"data-quality":0.1481937}}
{"text":"To address this issue, temporal generalizations of betweenness and closeness have been defined that are based on the shortest time-respecting paths between pairs of nodes.","meta":{"url":"http://arxiv.org/abs/2310.15865v1"},"cats":{"benchmark":0.420498492,"new-dataset":0.0182512865,"data-annotation":0.4954733813,"dev-research":0.2118647824,"llms":0.4995080343,"data-quality":0.0850365707}}
{"text":"However, a major issue of those generalizations is that the calculation of such paths is computationally expensive.","meta":{"url":"http://arxiv.org/abs/2310.15865v1"},"cats":{"benchmark":0.4133352721,"new-dataset":0.0035066317,"data-annotation":0.5311444381,"dev-research":0.1707953974,"llms":0.4412738123,"data-quality":0.0579292066}}
{"text":"Addressing this issue, we study the application of De Bruijn Graph Neural Networks (DBGNN), a causality-aware graph neural network architecture, to predict temporal path-based centralities in time series data.","meta":{"url":"http://arxiv.org/abs/2310.15865v1"},"cats":{"benchmark":0.3157261411,"new-dataset":0.1403852809,"data-annotation":0.5000195808,"dev-research":0.1656164584,"llms":0.4664020005,"data-quality":0.0968486999}}
{"text":"We experimentally evaluate our approach in 13 temporal graphs from biological and social systems and show that it considerably improves the prediction of both betweenness and closeness centrality compared to a static Graph Convolutional Neural Network.","meta":{"url":"http://arxiv.org/abs/2310.15865v1"},"cats":{"benchmark":0.3525767176,"new-dataset":0.1393192832,"data-annotation":0.5228623005,"dev-research":0.176921395,"llms":0.4296609647,"data-quality":0.1469448805}}
{"text":"We study optimization problems in a metric space $(\\mathcal{X},d)$ where we can compute distances in two ways: via a ''strong'' oracle that returns exact distances $d(x,y)$, and a ''weak'' oracle that returns distances $\\tilde{d}(x,y)$ which may be arbitrarily corrupted with some probability.","meta":{"url":"http://arxiv.org/abs/2310.15863v1"},"cats":{"benchmark":0.5319534199,"new-dataset":0.0190902951,"data-annotation":0.5327647667,"dev-research":0.2117738181,"llms":0.4169543973,"data-quality":0.2113975571}}
{"text":"This model captures the increasingly common trade-off between employing both an expensive similarity model (e.g. a large-scale embedding model), and a less accurate but cheaper model.","meta":{"url":"http://arxiv.org/abs/2310.15863v1"},"cats":{"benchmark":0.4763431144,"new-dataset":0.0184542802,"data-annotation":0.529718811,"dev-research":0.1355860474,"llms":0.4689410861,"data-quality":0.0998149586}}
{"text":"Hence, the goal is to make as few queries to the strong oracle as possible.","meta":{"url":"http://arxiv.org/abs/2310.15863v1"},"cats":{"benchmark":0.3459437092,"new-dataset":0.0087208969,"data-annotation":0.4903311692,"dev-research":0.1662342965,"llms":0.5104058488,"data-quality":0.0832618879}}
{"text":"We consider both so-called ''point queries'', where the strong oracle is queried on a set of points $S \\subset \\mathcal{X} $ and returns $d(x,y)$ for all $x,y \\in S$, and ''edge queries'' where it is queried for individual distances $d(x,y)$.   Our main contributions are optimal algorithms and lower bounds for clustering and Minimum Spanning Tree (MST) in this model.","meta":{"url":"http://arxiv.org/abs/2310.15863v1"},"cats":{"benchmark":0.4840681189,"new-dataset":0.0471703678,"data-annotation":0.528041089,"dev-research":0.1368186529,"llms":0.4352079493,"data-quality":0.1187848367}}
{"text":"For $k$-centers, $k$-median, and $k$-means, we give constant factor approximation algorithms with only $\\tilde{O}(k)$ strong oracle point queries, and prove that $\\Omega(k)$ queries are required for any bounded approximation.","meta":{"url":"http://arxiv.org/abs/2310.15863v1"},"cats":{"benchmark":0.4774296336,"new-dataset":0.0437255882,"data-annotation":0.5178847747,"dev-research":0.1307416377,"llms":0.4674755779,"data-quality":0.0971717151}}
{"text":"For edge queries, our upper and lower bounds are both $\\tilde{\\Theta}(k^2)$. Surprisingly, for the MST problem we give a $O(\\sqrt{\\log n})$ approximation algorithm using no strong oracle queries at all, and a matching $\\Omega(\\sqrt{\\log n})$ lower bound.","meta":{"url":"http://arxiv.org/abs/2310.15863v1"},"cats":{"benchmark":0.549977675,"new-dataset":0.0287773677,"data-annotation":0.5248195144,"dev-research":0.1399660789,"llms":0.4848920955,"data-quality":0.0811192328}}
{"text":"We empirically evaluate our algorithms, and show that their quality is comparable to that of the baseline algorithms that are given all true distances, but while querying the strong oracle on only a small fraction ($<1\\%$) of points.","meta":{"url":"http://arxiv.org/abs/2310.15863v1"},"cats":{"benchmark":0.7150214323,"new-dataset":0.0618014152,"data-annotation":0.5502376732,"dev-research":0.155201313,"llms":0.4271573593,"data-quality":0.1879355137}}
{"text":"As more and more social robots are being used for collaborative activities with humans, it is crucial to investigate mechanisms to facilitate trust in the human-robot interaction.","meta":{"url":"http://arxiv.org/abs/2310.15862v1"},"cats":{"benchmark":0.2310231235,"new-dataset":0.0190960599,"data-annotation":0.5212739923,"dev-research":0.2551618005,"llms":0.5249103403,"data-quality":0.0830945319}}
{"text":"One such mechanism is humour: it has been shown to increase creativity and productivity in human-human interaction, which has an indirect influence on trust.","meta":{"url":"http://arxiv.org/abs/2310.15862v1"},"cats":{"benchmark":0.2167127587,"new-dataset":0.0308912687,"data-annotation":0.5297910525,"dev-research":0.3569119298,"llms":0.5590530491,"data-quality":0.099438881}}
{"text":"In this study, we investigate if humour can increase trust in human-robot interaction.","meta":{"url":"http://arxiv.org/abs/2310.15862v1"},"cats":{"benchmark":0.2397913099,"new-dataset":0.0818507632,"data-annotation":0.5359918993,"dev-research":0.3107670323,"llms":0.5686239954,"data-quality":0.0964545707}}
{"text":"We conducted a between-subjects experiment with 40 participants to see if the participants are more likely to accept the robot's suggestion in the Three-card Monte game, as a trust check task.","meta":{"url":"http://arxiv.org/abs/2310.15862v1"},"cats":{"benchmark":0.2591325109,"new-dataset":0.0254327433,"data-annotation":0.5285847017,"dev-research":0.2492254385,"llms":0.6028161446,"data-quality":0.0847885707}}
{"text":"Though we were unable to find a significant effect of humour, we discuss the effect of possible confounding variables, and also report some interesting qualitative observations from our study: for instance, the participants interacted effectively with the robot as a team member, regardless of the humour or no-humour condition.","meta":{"url":"http://arxiv.org/abs/2310.15862v1"},"cats":{"benchmark":0.2213793706,"new-dataset":0.0861592186,"data-annotation":0.5288807753,"dev-research":0.3489287127,"llms":0.5697813957,"data-quality":0.124503541}}
{"text":"In recommendation, graph-based Collaborative Filtering (CF) methods mitigate the data sparsity by introducing Graph Contrastive Learning (GCL).","meta":{"url":"http://arxiv.org/abs/2310.15858v1"},"cats":{"benchmark":0.4093196273,"new-dataset":0.0186503765,"data-annotation":0.5019161591,"dev-research":0.1934681897,"llms":0.4262827525,"data-quality":0.1604135247}}
{"text":"However, the random negative sampling strategy in these GCL-based CF models neglects the semantic structure of users (items), which not only introduces false negatives (negatives that are similar to anchor user (item)) but also ignores the potential positive samples.","meta":{"url":"http://arxiv.org/abs/2310.15858v1"},"cats":{"benchmark":0.3330800573,"new-dataset":0.0061734795,"data-annotation":0.5172289708,"dev-research":0.144897713,"llms":0.5401278839,"data-quality":0.166785093}}
{"text":"To tackle the above issues, we propose Topology-aware Debiased Self-supervised Graph Learning (TDSGL) for recommendation, which constructs contrastive pairs according to the semantic similarity between users (items).","meta":{"url":"http://arxiv.org/abs/2310.15858v1"},"cats":{"benchmark":0.3583879355,"new-dataset":0.0971539263,"data-annotation":0.5187612728,"dev-research":0.1602362461,"llms":0.5545062953,"data-quality":0.2313548426}}
{"text":"Specifically, since the original user-item interaction data commendably reflects the purchasing intent of users and certain characteristics of items, we calculate the semantic similarity between users (items) on interaction data.","meta":{"url":"http://arxiv.org/abs/2310.15858v1"},"cats":{"benchmark":0.3345922497,"new-dataset":0.1379090007,"data-annotation":0.4973088438,"dev-research":0.2345818789,"llms":0.5035159472,"data-quality":0.1353755349}}
{"text":"Then, given a user (item), we construct its negative pairs by selecting users (items) which embed different semantic structures to ensure the semantic difference between the given user (item) and its negatives.","meta":{"url":"http://arxiv.org/abs/2310.15858v1"},"cats":{"benchmark":0.3285675971,"new-dataset":0.0322028388,"data-annotation":0.5292795932,"dev-research":0.2813577517,"llms":0.5824934233,"data-quality":0.2118325231}}
{"text":"Moreover, for a user (item), we design a feature extraction module that converts other semantically similar users (items) into an auxiliary positive sample to acquire a more informative representation.","meta":{"url":"http://arxiv.org/abs/2310.15858v1"},"cats":{"benchmark":0.3115584045,"new-dataset":0.0650221182,"data-annotation":0.5342184082,"dev-research":0.3649776881,"llms":0.5377425158,"data-quality":0.2953625213}}
{"text":"Experimental results show that the proposed model outperforms the state-of-the-art models significantly on three public datasets.","meta":{"url":"http://arxiv.org/abs/2310.15858v1"},"cats":{"benchmark":0.4354843397,"new-dataset":0.2250152458,"data-annotation":0.4992717379,"dev-research":0.1537428895,"llms":0.4089955723,"data-quality":0.1840126338}}
{"text":"Our model implementation codes are available at https://github.com/malajikuai/TDSGL.","meta":{"url":"http://arxiv.org/abs/2310.15858v1"},"cats":{"benchmark":0.3537719302,"new-dataset":0.1912792204,"data-annotation":0.5113135358,"dev-research":0.160476945,"llms":0.4902224684,"data-quality":0.0719376012}}
{"text":"Numerous studies have demonstrated the ability of neural language models to learn various linguistic properties without direct supervision.","meta":{"url":"http://arxiv.org/abs/2310.15852v1"},"cats":{"benchmark":0.1852453465,"new-dataset":0.0218165027,"data-annotation":0.5365948911,"dev-research":0.1827075832,"llms":0.5563740043,"data-quality":0.2379452438}}
{"text":"This work takes an initial step towards exploring the less researched topic of how neural models discover linguistic properties of words, such as gender, as well as the rules governing their usage.","meta":{"url":"http://arxiv.org/abs/2310.15852v1"},"cats":{"benchmark":0.2231813911,"new-dataset":0.0285246969,"data-annotation":0.551211149,"dev-research":0.1605504459,"llms":0.4727332541,"data-quality":0.2771909387}}
{"text":"We propose to use an artificial corpus generated by a PCFG based on French to precisely control the gender distribution in the training data and determine under which conditions a model correctly captures gender information or, on the contrary, appears gender-biased.","meta":{"url":"http://arxiv.org/abs/2310.15852v1"},"cats":{"benchmark":0.2633143913,"new-dataset":0.2582421884,"data-annotation":0.5400611815,"dev-research":0.142803755,"llms":0.421327158,"data-quality":0.3800436358}}
{"text":"The jailbreak attack can bypass the safety measures of a Large Language Model (LLM), generating harmful content.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.1867068883,"new-dataset":0.0704592991,"data-annotation":0.5183599163,"dev-research":0.2175956391,"llms":0.6871299838,"data-quality":0.1839628483}}
{"text":"This misuse of LLM has led to negative societal consequences.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.2337486524,"new-dataset":0.0105771997,"data-annotation":0.5065588458,"dev-research":0.1973593662,"llms":0.7863794626,"data-quality":0.1746913224}}
{"text":"Currently, there are two main approaches to address jailbreak attacks: safety training and safeguards.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.2662866021,"new-dataset":0.0453543014,"data-annotation":0.5102801003,"dev-research":0.3047205386,"llms":0.5020838236,"data-quality":0.1156227823}}
{"text":"Safety training focuses on further training LLM to enhance its safety.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.2097746955,"new-dataset":0.0695408442,"data-annotation":0.5120141845,"dev-research":0.2270497291,"llms":0.7454701813,"data-quality":0.0855981452}}
{"text":"On the other hand, safeguards involve implementing external models or filters to prevent harmful outputs.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.2951795562,"new-dataset":0.0078899808,"data-annotation":0.4850627007,"dev-research":0.3570524521,"llms":0.5201007536,"data-quality":0.1451335812}}
{"text":"However, safety training has constraints in its ability to adapt to new attack types and often leads to a drop in model performance.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.2740746071,"new-dataset":0.0087647308,"data-annotation":0.5334267648,"dev-research":0.307581203,"llms":0.4892060548,"data-quality":0.1185851508}}
{"text":"Safeguards have proven to be of limited help.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.2357336803,"new-dataset":0.0596864578,"data-annotation":0.5006527667,"dev-research":0.3067972044,"llms":0.5759180668,"data-quality":0.0903936047}}
{"text":"To tackle these issues, we propose a novel approach called Self-Guard, which combines the strengths of both safety methods.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.2639100348,"new-dataset":0.022853696,"data-annotation":0.5166160957,"dev-research":0.2973006737,"llms":0.5109087578,"data-quality":0.1089041249}}
{"text":"Self-Guard includes two stages.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.2032584278,"new-dataset":0.0327260966,"data-annotation":0.5051432007,"dev-research":0.1566468141,"llms":0.5454339843,"data-quality":0.0964339468}}
{"text":"In the first stage, we enhance the model's ability to assess harmful content, and in the second stage, we instruct the model to consistently perform harmful content detection on its own responses.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.3014097389,"new-dataset":0.0570491698,"data-annotation":0.526980133,"dev-research":0.2073618777,"llms":0.4900834887,"data-quality":0.253171289}}
{"text":"The experiment has demonstrated that Self-Guard is robust against jailbreak attacks.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.2994288847,"new-dataset":0.0152311644,"data-annotation":0.516774698,"dev-research":0.2050899746,"llms":0.5466798021,"data-quality":0.1157824065}}
{"text":"In the bad case analysis, we find that LLM occasionally provides harmless responses to harmful queries.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.2687034838,"new-dataset":0.0346486402,"data-annotation":0.5067303718,"dev-research":0.2305621722,"llms":0.7428013673,"data-quality":0.2204599595}}
{"text":"Additionally, we evaluated the general capabilities of the LLM before and after safety training, providing evidence that Self-Guard does not result in the LLM's performance degradation.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.3074294202,"new-dataset":0.0077868353,"data-annotation":0.5254387723,"dev-research":0.1616513612,"llms":0.725655839,"data-quality":0.0873609489}}
{"text":"In sensitivity tests, Self-Guard not only avoids inducing over-sensitivity in LLM but also can even mitigate this issue.","meta":{"url":"http://arxiv.org/abs/2310.15851v1"},"cats":{"benchmark":0.4004813647,"new-dataset":0.0027762079,"data-annotation":0.5180452804,"dev-research":0.1514504475,"llms":0.730384248,"data-quality":0.2087982922}}
{"text":"In recent years, the need for resources for handling processes with high computational complexity for mobile robots is becoming increasingly urgent.","meta":{"url":"http://arxiv.org/abs/2310.15849v1"},"cats":{"benchmark":0.1841892725,"new-dataset":0.1517347748,"data-annotation":0.5034094402,"dev-research":0.2564957643,"llms":0.5606362798,"data-quality":0.030552769}}
{"text":"More specifically, robots need to autonomously operate in a robust and continuous manner, while keeping high performance, a need that led to the utilization of edge computing to offload many computationally demanding and time-critical robotic procedures.","meta":{"url":"http://arxiv.org/abs/2310.15849v1"},"cats":{"benchmark":0.2780048727,"new-dataset":0.0106984733,"data-annotation":0.4772344817,"dev-research":0.269784948,"llms":0.5171159171,"data-quality":0.0435069763}}
{"text":"However, safe mechanisms should be implemented to handle situations when it is not possible to use the offloaded procedures, such as if the communication is challenged or the edge cluster is not available.","meta":{"url":"http://arxiv.org/abs/2310.15849v1"},"cats":{"benchmark":0.3033579134,"new-dataset":0.0119687051,"data-annotation":0.4736560649,"dev-research":0.3003730477,"llms":0.6004955389,"data-quality":0.1192570163}}
{"text":"To this end, this article presents a switching strategy for safety, redundancy, and optimized behavior through an edge computing-based Model Predictive Controller (MPC) and a low-level onboard-PID controller for edge-connected Unmanned Aerial Vehicles (UAVs).","meta":{"url":"http://arxiv.org/abs/2310.15849v1"},"cats":{"benchmark":0.310143341,"new-dataset":0.0229110869,"data-annotation":0.491934344,"dev-research":0.2277874572,"llms":0.445908755,"data-quality":0.0430129976}}
{"text":"The switching strategy is based on the communication Key Performance Indicators (KPIs) over 5G to decide whether the UAV should be controlled by the edge-based or have a safe fallback based on the onboard controller.","meta":{"url":"http://arxiv.org/abs/2310.15849v1"},"cats":{"benchmark":0.3800073615,"new-dataset":0.0076807051,"data-annotation":0.478355607,"dev-research":0.1750138344,"llms":0.4588981795,"data-quality":0.0355533854}}
{"text":"Depth estimation from monocular images is pivotal for real-world visual perception systems.","meta":{"url":"http://arxiv.org/abs/2310.15171v1"},"cats":{"benchmark":0.3015879654,"new-dataset":0.0670318365,"data-annotation":0.5163281455,"dev-research":0.1416662639,"llms":0.4193956807,"data-quality":0.1004723688}}
{"text":"While current learning-based depth estimation models train and test on meticulously curated data, they often overlook out-of-distribution (OoD) situations.","meta":{"url":"http://arxiv.org/abs/2310.15171v1"},"cats":{"benchmark":0.2390161839,"new-dataset":0.212887622,"data-annotation":0.5066290766,"dev-research":0.1288906965,"llms":0.4890203492,"data-quality":0.1468288916}}
{"text":"Yet, in practical settings -- especially safety-critical ones like autonomous driving -- common corruptions can arise.","meta":{"url":"http://arxiv.org/abs/2310.15171v1"},"cats":{"benchmark":0.2247276117,"new-dataset":0.0687010179,"data-annotation":0.5017342286,"dev-research":0.4645962589,"llms":0.5123956015,"data-quality":0.37078028}}
{"text":"Addressing this oversight, we introduce a comprehensive robustness test suite, RoboDepth, encompassing 18 corruptions spanning three categories: i) weather and lighting conditions; ii) sensor failures and movement; and iii) data processing anomalies.","meta":{"url":"http://arxiv.org/abs/2310.15171v1"},"cats":{"benchmark":0.4334669923,"new-dataset":0.3039343655,"data-annotation":0.4844937498,"dev-research":0.3791682585,"llms":0.4752646192,"data-quality":0.3578540902}}
{"text":"We subsequently benchmark 42 depth estimation models across indoor and outdoor scenes to assess their resilience to these corruptions.","meta":{"url":"http://arxiv.org/abs/2310.15171v1"},"cats":{"benchmark":0.4135750745,"new-dataset":0.4879920132,"data-annotation":0.5174882936,"dev-research":0.2533266688,"llms":0.422601593,"data-quality":0.2232718335}}
{"text":"Our findings underscore that, in the absence of a dedicated robustness evaluation framework, many leading depth estimation models may be susceptible to typical corruptions.","meta":{"url":"http://arxiv.org/abs/2310.15171v1"},"cats":{"benchmark":0.393477015,"new-dataset":0.0865512491,"data-annotation":0.5217563744,"dev-research":0.2470495151,"llms":0.4123932075,"data-quality":0.3470095872}}
{"text":"We delve into design considerations for crafting more robust depth estimation models, touching upon pre-training, augmentation, modality, model capacity, and learning paradigms.","meta":{"url":"http://arxiv.org/abs/2310.15171v1"},"cats":{"benchmark":0.2401573265,"new-dataset":0.1585693701,"data-annotation":0.511204734,"dev-research":0.1528369942,"llms":0.4807399956,"data-quality":0.0778336467}}
{"text":"We anticipate our benchmark will establish a foundational platform for advancing robust OoD depth estimation.","meta":{"url":"http://arxiv.org/abs/2310.15171v1"},"cats":{"benchmark":0.4604376126,"new-dataset":0.1875914016,"data-annotation":0.5072600881,"dev-research":0.1199871094,"llms":0.398730498,"data-quality":0.1094886952}}
{"text":"With the availability of large-scale video datasets and the advances of diffusion models, text-driven video generation has achieved substantial progress.","meta":{"url":"http://arxiv.org/abs/2310.15169v1"},"cats":{"benchmark":0.2416517864,"new-dataset":0.4199583532,"data-annotation":0.4935824525,"dev-research":0.1554654061,"llms":0.4999241099,"data-quality":0.1281426418}}
{"text":"However, existing video generation models are typically trained on a limited number of frames, resulting in the inability to generate high-fidelity long videos during inference.","meta":{"url":"http://arxiv.org/abs/2310.15169v1"},"cats":{"benchmark":0.2117796806,"new-dataset":0.0479458271,"data-annotation":0.5194495137,"dev-research":0.1816613819,"llms":0.5224936039,"data-quality":0.1120783341}}
{"text":"Furthermore, these models only support single-text conditions, whereas real-life scenarios often require multi-text conditions as the video content changes over time.","meta":{"url":"http://arxiv.org/abs/2310.15169v1"},"cats":{"benchmark":0.2869133036,"new-dataset":0.0203735029,"data-annotation":0.4864440435,"dev-research":0.2066177464,"llms":0.4328842132,"data-quality":0.1210285276}}
{"text":"To tackle these challenges, this study explores the potential of extending the text-driven capability to generate longer videos conditioned on multiple texts.","meta":{"url":"http://arxiv.org/abs/2310.15169v1"},"cats":{"benchmark":0.2669129216,"new-dataset":0.0833052002,"data-annotation":0.5143037885,"dev-research":0.2360314315,"llms":0.5352961958,"data-quality":0.1189553981}}
{"text":"1) We first analyze the impact of initial noise in video diffusion models.","meta":{"url":"http://arxiv.org/abs/2310.15169v1"},"cats":{"benchmark":0.4215450423,"new-dataset":0.0457092953,"data-annotation":0.5212102294,"dev-research":0.145375585,"llms":0.4075824942,"data-quality":0.227143693}}
{"text":"Then building upon the observation of noise, we propose FreeNoise, a tuning-free and time-efficient paradigm to enhance the generative capabilities of pretrained video diffusion models while preserving content consistency.","meta":{"url":"http://arxiv.org/abs/2310.15169v1"},"cats":{"benchmark":0.366369536,"new-dataset":0.0387331524,"data-annotation":0.4940707821,"dev-research":0.1482180225,"llms":0.4946770867,"data-quality":0.2031286455}}
{"text":"Specifically, instead of initializing noises for all frames, we reschedule a sequence of noises for long-range correlation and perform temporal attention over them by window-based function.","meta":{"url":"http://arxiv.org/abs/2310.15169v1"},"cats":{"benchmark":0.316362693,"new-dataset":0.1663923349,"data-annotation":0.5157344731,"dev-research":0.2406026195,"llms":0.4487855441,"data-quality":0.0875680831}}
{"text":"2) Additionally, we design a novel motion injection method to support the generation of videos conditioned on multiple text prompts.","meta":{"url":"http://arxiv.org/abs/2310.15169v1"},"cats":{"benchmark":0.2513851973,"new-dataset":0.0575842265,"data-annotation":0.5290053581,"dev-research":0.2214708742,"llms":0.5402447308,"data-quality":0.1265569782}}
{"text":"Extensive experiments validate the superiority of our paradigm in extending the generative capabilities of video diffusion models.","meta":{"url":"http://arxiv.org/abs/2310.15169v1"},"cats":{"benchmark":0.3270289352,"new-dataset":0.0138377102,"data-annotation":0.4941484179,"dev-research":0.1282836106,"llms":0.5129244518,"data-quality":0.0962655732}}
{"text":"It is noteworthy that compared with the previous best-performing method which brought about 255% extra time cost, our method incurs only negligible time cost of approximately 17%.","meta":{"url":"http://arxiv.org/abs/2310.15169v1"},"cats":{"benchmark":0.6982134713,"new-dataset":0.0036388569,"data-annotation":0.5551080646,"dev-research":0.2572506,"llms":0.5025303702,"data-quality":0.0902249008}}
{"text":"Generated video samples are available at our website: http://haonanqiu.com/projects/FreeNoise.html.","meta":{"url":"http://arxiv.org/abs/2310.15169v1"},"cats":{"benchmark":0.2083071671,"new-dataset":0.6041460864,"data-annotation":0.5233017697,"dev-research":0.1675042569,"llms":0.6149958803,"data-quality":0.1080146397}}
{"text":"The creation of photorealistic virtual worlds requires the accurate modeling of 3D surface geometry for a wide range of objects.","meta":{"url":"http://arxiv.org/abs/2310.15168v1"},"cats":{"benchmark":0.1920115506,"new-dataset":0.0911479506,"data-annotation":0.4979013142,"dev-research":0.1916211659,"llms":0.476873423,"data-quality":0.0467323456}}
{"text":"For this, meshes are appealing since they 1) enable fast physics-based rendering with realistic material and lighting, 2) support physical simulation, and 3) are memory-efficient for modern graphics pipelines.","meta":{"url":"http://arxiv.org/abs/2310.15168v1"},"cats":{"benchmark":0.3607497976,"new-dataset":0.0241573808,"data-annotation":0.4992161539,"dev-research":0.2417183655,"llms":0.5721969952,"data-quality":0.0271572083}}
{"text":"Recent work on reconstructing and statistically modeling 3D shape, however, has critiqued meshes as being topologically inflexible.","meta":{"url":"http://arxiv.org/abs/2310.15168v1"},"cats":{"benchmark":0.4047679043,"new-dataset":0.0266367347,"data-annotation":0.5089704007,"dev-research":0.1979849101,"llms":0.4524512908,"data-quality":0.0821401091}}
{"text":"To capture a wide range of object shapes, any 3D representation must be able to model solid, watertight, shapes as well as thin, open, surfaces.","meta":{"url":"http://arxiv.org/abs/2310.15168v1"},"cats":{"benchmark":0.1889460939,"new-dataset":0.1064374985,"data-annotation":0.4992120012,"dev-research":0.1732964563,"llms":0.4802560436,"data-quality":0.0503066071}}
{"text":"Recent work has focused on the former, and methods for reconstructing open surfaces do not support fast reconstruction with material and lighting or unconditional generative modelling.","meta":{"url":"http://arxiv.org/abs/2310.15168v1"},"cats":{"benchmark":0.336341462,"new-dataset":0.046530405,"data-annotation":0.497355427,"dev-research":0.1585660469,"llms":0.4924751727,"data-quality":0.0507555586}}
{"text":"Inspired by the observation that open surfaces can be seen as islands floating on watertight surfaces, we parameterize open surfaces by defining a manifold signed distance field on watertight templates.","meta":{"url":"http://arxiv.org/abs/2310.15168v1"},"cats":{"benchmark":0.3102104909,"new-dataset":0.1067970959,"data-annotation":0.5068979182,"dev-research":0.1916455711,"llms":0.4493913233,"data-quality":0.1072891033}}
{"text":"With this parameterization, we further develop a grid-based and differentiable representation that parameterizes both watertight and non-watertight meshes of arbitrary topology.","meta":{"url":"http://arxiv.org/abs/2310.15168v1"},"cats":{"benchmark":0.3755530714,"new-dataset":0.0457814519,"data-annotation":0.4796122842,"dev-research":0.2417839439,"llms":0.472452277,"data-quality":0.0805058014}}
{"text":"Our new representation, called Ghost-on-the-Shell (G-Shell), enables two important applications: differentiable rasterization-based reconstruction from multiview images and generative modelling of non-watertight meshes.","meta":{"url":"http://arxiv.org/abs/2310.15168v1"},"cats":{"benchmark":0.2430043789,"new-dataset":0.04505931,"data-annotation":0.4921498964,"dev-research":0.1517904775,"llms":0.4975841204,"data-quality":0.0568503639}}
{"text":"We empirically demonstrate that G-Shell achieves state-of-the-art performance on non-watertight mesh reconstruction and generation tasks, while also performing effectively for watertight meshes.","meta":{"url":"http://arxiv.org/abs/2310.15168v1"},"cats":{"benchmark":0.4020478848,"new-dataset":0.0267362574,"data-annotation":0.4783273531,"dev-research":0.2429985345,"llms":0.5489734324,"data-quality":0.0449856095}}
{"text":"Visual reasoning requires multimodal perception and commonsense cognition of the world.","meta":{"url":"http://arxiv.org/abs/2310.15166v1"},"cats":{"benchmark":0.1349072035,"new-dataset":0.1286805686,"data-annotation":0.5073700066,"dev-research":0.2063948213,"llms":0.5517397923,"data-quality":0.0945733746}}
{"text":"Recently, multiple vision-language models (VLMs) have been proposed with excellent commonsense reasoning ability in various domains.","meta":{"url":"http://arxiv.org/abs/2310.15166v1"},"cats":{"benchmark":0.160475124,"new-dataset":0.2166985929,"data-annotation":0.5248441854,"dev-research":0.2025944425,"llms":0.5396733998,"data-quality":0.1792982344}}
{"text":"However, how to harness the collective power of these complementary VLMs is rarely explored.","meta":{"url":"http://arxiv.org/abs/2310.15166v1"},"cats":{"benchmark":0.3137889052,"new-dataset":0.0022599605,"data-annotation":0.4886669777,"dev-research":0.1387744368,"llms":0.4744595662,"data-quality":0.1016011623}}
{"text":"Existing methods like ensemble still struggle to aggregate these models with the desired higher-order communications.","meta":{"url":"http://arxiv.org/abs/2310.15166v1"},"cats":{"benchmark":0.4570675399,"new-dataset":0.0105061598,"data-annotation":0.5150901445,"dev-research":0.1282421937,"llms":0.4628244994,"data-quality":0.1308641182}}
{"text":"In this work, we propose Cola, a novel paradigm that coordinates multiple VLMs for visual reasoning.","meta":{"url":"http://arxiv.org/abs/2310.15166v1"},"cats":{"benchmark":0.2440590781,"new-dataset":0.247873195,"data-annotation":0.4971581504,"dev-research":0.2209568436,"llms":0.4485993149,"data-quality":0.1111329941}}
{"text":"Our key insight is that a large language model (LLM) can efficiently coordinate multiple VLMs by facilitating natural language communication that leverages their distinct and complementary capabilities.","meta":{"url":"http://arxiv.org/abs/2310.15166v1"},"cats":{"benchmark":0.2094120958,"new-dataset":0.0613691735,"data-annotation":0.5099389073,"dev-research":0.1750142877,"llms":0.6283333071,"data-quality":0.147887501}}
{"text":"Extensive experiments demonstrate that our instruction tuning variant, Cola-FT, achieves state-of-the-art performance on visual question answering (VQA), outside knowledge VQA, visual entailment, and visual spatial reasoning tasks.","meta":{"url":"http://arxiv.org/abs/2310.15166v1"},"cats":{"benchmark":0.2263868169,"new-dataset":0.1333478202,"data-annotation":0.5342662319,"dev-research":0.2930363966,"llms":0.5870801509,"data-quality":0.0923193629}}
{"text":"Moreover, we show that our in-context learning variant, Cola-Zero, exhibits competitive performance in zero and few-shot settings, without finetuning.","meta":{"url":"http://arxiv.org/abs/2310.15166v1"},"cats":{"benchmark":0.3373596559,"new-dataset":0.0710996744,"data-annotation":0.5302714108,"dev-research":0.105908454,"llms":0.4900099313,"data-quality":0.165746001}}
{"text":"Through systematic ablation studies and visualizations, we validate that a coordinator LLM indeed comprehends the instruction prompts as well as the separate functionalities of VLMs; it then coordinates them to enable impressive visual reasoning capabilities.","meta":{"url":"http://arxiv.org/abs/2310.15166v1"},"cats":{"benchmark":0.1620351654,"new-dataset":0.0506741981,"data-annotation":0.4947112892,"dev-research":0.249347899,"llms":0.6757633525,"data-quality":0.074675825}}
{"text":"Federated Learning (FL) is a promising research paradigm that enables the collaborative training of machine learning models among various parties without the need for sensitive information exchange.","meta":{"url":"http://arxiv.org/abs/2310.15165v1"},"cats":{"benchmark":0.2007338436,"new-dataset":0.0635303792,"data-annotation":0.4808660857,"dev-research":0.1523427221,"llms":0.5144855003,"data-quality":0.1272428151}}
{"text":"Nonetheless, retaining data in individual clients introduces fundamental challenges to achieving performance on par with centrally trained models.","meta":{"url":"http://arxiv.org/abs/2310.15165v1"},"cats":{"benchmark":0.3366126102,"new-dataset":0.0350747151,"data-annotation":0.4679098785,"dev-research":0.2005776093,"llms":0.4507927722,"data-quality":0.1972656791}}
{"text":"Our study provides an extensive review of federated learning applied to visual recognition.","meta":{"url":"http://arxiv.org/abs/2310.15165v1"},"cats":{"benchmark":0.2393904205,"new-dataset":0.0869055444,"data-annotation":0.5042386768,"dev-research":0.1453808812,"llms":0.455423884,"data-quality":0.1737076023}}
{"text":"It underscores the critical role of thoughtful architectural design choices in achieving optimal performance, a factor often neglected in the FL literature.","meta":{"url":"http://arxiv.org/abs/2310.15165v1"},"cats":{"benchmark":0.4471839438,"new-dataset":0.0059543804,"data-annotation":0.496167367,"dev-research":0.3442882234,"llms":0.5334014796,"data-quality":0.0464768476}}
{"text":"Many existing FL solutions are tested on shallow or simple networks, which may not accurately reflect real-world applications.","meta":{"url":"http://arxiv.org/abs/2310.15165v1"},"cats":{"benchmark":0.4883100749,"new-dataset":0.0078872139,"data-annotation":0.514479073,"dev-research":0.145354909,"llms":0.4489162088,"data-quality":0.1128297194}}
{"text":"This practice restricts the transferability of research findings to large-scale visual recognition models.","meta":{"url":"http://arxiv.org/abs/2310.15165v1"},"cats":{"benchmark":0.3092795154,"new-dataset":0.0564681608,"data-annotation":0.5074490831,"dev-research":0.2056348114,"llms":0.4438334862,"data-quality":0.181310695}}
{"text":"Through an in-depth analysis of diverse cutting-edge architectures such as convolutional neural networks, transformers, and MLP-mixers, we experimentally demonstrate that architectural choices can substantially enhance FL systems' performance, particularly when handling heterogeneous data.","meta":{"url":"http://arxiv.org/abs/2310.15165v1"},"cats":{"benchmark":0.3948298035,"new-dataset":0.0503592293,"data-annotation":0.475677613,"dev-research":0.1758148935,"llms":0.5181568601,"data-quality":0.0691705603}}
{"text":"We study 19 visual recognition models from five different architectural families on four challenging FL datasets.","meta":{"url":"http://arxiv.org/abs/2310.15165v1"},"cats":{"benchmark":0.2791454395,"new-dataset":0.6089027561,"data-annotation":0.5047986499,"dev-research":0.1508869839,"llms":0.46409951,"data-quality":0.1281404366}}
{"text":"We also re-investigate the inferior performance of convolution-based architectures in the FL setting and analyze the influence of normalization layers on the FL performance.","meta":{"url":"http://arxiv.org/abs/2310.15165v1"},"cats":{"benchmark":0.5052162537,"new-dataset":0.0167401633,"data-annotation":0.5020393826,"dev-research":0.1462581931,"llms":0.4428426806,"data-quality":0.0923823711}}
{"text":"Our findings emphasize the importance of architectural design for computer vision tasks in practical scenarios, effectively narrowing the performance gap between federated and centralized learning.","meta":{"url":"http://arxiv.org/abs/2310.15165v1"},"cats":{"benchmark":0.2406481798,"new-dataset":0.0309287557,"data-annotation":0.4791244879,"dev-research":0.2564560521,"llms":0.5417538143,"data-quality":0.084480643}}
{"text":"Our source code is available at https://github.com/sarapieri/fed_het.git.","meta":{"url":"http://arxiv.org/abs/2310.15165v1"},"cats":{"benchmark":0.2646936376,"new-dataset":0.3863195876,"data-annotation":0.5200124125,"dev-research":0.1930473781,"llms":0.5095615398,"data-quality":0.133177009}}
{"text":"Logical reasoning, i.e., deductively inferring the truth value of a conclusion from a set of premises, is an important task for artificial intelligence with wide potential impacts on science, mathematics, and society.","meta":{"url":"http://arxiv.org/abs/2310.15164v1"},"cats":{"benchmark":0.3078830554,"new-dataset":0.0399789055,"data-annotation":0.5242859404,"dev-research":0.3462455426,"llms":0.5153004042,"data-quality":0.1054265746}}
{"text":"While many prompting-based strategies have been proposed to enable Large Language Models (LLMs) to do such reasoning more effectively, they still appear unsatisfactory, often failing in subtle and unpredictable ways.","meta":{"url":"http://arxiv.org/abs/2310.15164v1"},"cats":{"benchmark":0.1855289673,"new-dataset":0.0355077775,"data-annotation":0.5364193434,"dev-research":0.2968331706,"llms":0.7101065885,"data-quality":0.2379799955}}
{"text":"In this work, we investigate the validity of instead reformulating such tasks as modular neurosymbolic programming, which we call LINC:","meta":{"url":"http://arxiv.org/abs/2310.15164v1"},"cats":{"benchmark":0.2707967873,"new-dataset":0.0071314336,"data-annotation":0.5296142151,"dev-research":0.2519845781,"llms":0.4739699603,"data-quality":0.1598585162}}
{"text":"Logical Inference via Neurosymbolic Computation.","meta":{"url":"http://arxiv.org/abs/2310.15164v1"},"cats":{"benchmark":0.296014822,"new-dataset":0.012169308,"data-annotation":0.5303429055,"dev-research":0.1791484996,"llms":0.4689567175,"data-quality":0.1518323728}}
{"text":"In LINC, the LLM acts as a semantic parser, translating premises and conclusions from natural language to expressions in first-order logic.","meta":{"url":"http://arxiv.org/abs/2310.15164v1"},"cats":{"benchmark":0.2309568625,"new-dataset":0.0310085491,"data-annotation":0.5141456715,"dev-research":0.2250451623,"llms":0.7398252033,"data-quality":0.1673113378}}
{"text":"These expressions are then offloaded to an external theorem prover, which symbolically performs deductive inference.","meta":{"url":"http://arxiv.org/abs/2310.15164v1"},"cats":{"benchmark":0.302147756,"new-dataset":0.0200204911,"data-annotation":0.5228076142,"dev-research":0.3094805361,"llms":0.5227861327,"data-quality":0.1446173605}}
{"text":"Leveraging this approach, we observe significant performance gains on FOLIO and a balanced subset of ProofWriter for three different models in nearly all experimental conditions we evaluate.","meta":{"url":"http://arxiv.org/abs/2310.15164v1"},"cats":{"benchmark":0.6373915936,"new-dataset":0.0134869639,"data-annotation":0.5287642417,"dev-research":0.1900798014,"llms":0.4827708725,"data-quality":0.1096583415}}
{"text":"On ProofWriter, augmenting the comparatively small open-source StarCoder+ (15.5B parameters) with LINC even outperforms GPT-3.5 and GPT-4 with Chain-of-Thought (CoT) prompting by an absolute 38% and 10%, respectively.","meta":{"url":"http://arxiv.org/abs/2310.15164v1"},"cats":{"benchmark":0.4776975094,"new-dataset":0.0540598265,"data-annotation":0.5372466318,"dev-research":0.2754052923,"llms":0.5324236635,"data-quality":0.1676151549}}
{"text":"When used with GPT-4, LINC scores 26% higher than CoT on ProofWriter while performing comparatively on FOLIO.","meta":{"url":"http://arxiv.org/abs/2310.15164v1"},"cats":{"benchmark":0.6617030071,"new-dataset":0.0166988316,"data-annotation":0.5461162712,"dev-research":0.1687220624,"llms":0.5170169828,"data-quality":0.1270469804}}
{"text":"Further analysis reveals that although both methods on average succeed roughly equally often on this dataset, they exhibit distinct and complementary failure modes.","meta":{"url":"http://arxiv.org/abs/2310.15164v1"},"cats":{"benchmark":0.6343389646,"new-dataset":0.008667697,"data-annotation":0.5151311522,"dev-research":0.2017745621,"llms":0.4372197655,"data-quality":0.3342030472}}
{"text":"We thus provide promising evidence for how logical reasoning over natural language can be tackled through jointly leveraging LLMs alongside symbolic provers.","meta":{"url":"http://arxiv.org/abs/2310.15164v1"},"cats":{"benchmark":0.2569590079,"new-dataset":0.071514288,"data-annotation":0.5165991372,"dev-research":0.28240408,"llms":0.7227056939,"data-quality":0.1987461693}}
{"text":"All corresponding code is publicly available at https://github.com/benlipkin/linc","meta":{"url":"http://arxiv.org/abs/2310.15164v1"},"cats":{"benchmark":0.3205837627,"new-dataset":0.1622669006,"data-annotation":0.5420861352,"dev-research":0.1960603866,"llms":0.5609525545,"data-quality":0.10982528}}
{"text":"Although the Segment Anything Model (SAM) has demonstrated impressive performance in 2D natural image segmentation, its application to 3D volumetric medical images reveals significant shortcomings, namely suboptimal performance and unstable prediction, necessitating an excessive number of prompt points to attain the desired outcomes.","meta":{"url":"http://arxiv.org/abs/2310.15161v1"},"cats":{"benchmark":0.3061786902,"new-dataset":0.0502863154,"data-annotation":0.4994238686,"dev-research":0.0908470726,"llms":0.4739272884,"data-quality":0.092923128}}
{"text":"These issues can hardly be addressed by fine-tuning SAM on medical data because the original 2D structure of SAM neglects 3D spatial information.","meta":{"url":"http://arxiv.org/abs/2310.15161v1"},"cats":{"benchmark":0.3160408767,"new-dataset":0.021131251,"data-annotation":0.4846696955,"dev-research":0.1624298043,"llms":0.4573558769,"data-quality":0.0926381843}}
{"text":"In this paper, we introduce SAM-Med3D, the most comprehensive study to modify SAM for 3D medical images.","meta":{"url":"http://arxiv.org/abs/2310.15161v1"},"cats":{"benchmark":0.3390616572,"new-dataset":0.1098814677,"data-annotation":0.4976353312,"dev-research":0.1633278579,"llms":0.4604420553,"data-quality":0.0442046132}}
{"text":"Our approach is characterized by its comprehensiveness in two primary aspects: firstly, by comprehensively reformulating SAM to a thorough 3D architecture trained on a comprehensively processed large-scale volumetric medical dataset; and secondly, by providing a comprehensive evaluation of its performance.","meta":{"url":"http://arxiv.org/abs/2310.15161v1"},"cats":{"benchmark":0.3755906226,"new-dataset":0.3967328393,"data-annotation":0.4757671735,"dev-research":0.1572367521,"llms":0.4620619182,"data-quality":0.0560269615}}
{"text":"Specifically, we train SAM-Med3D with over 131K 3D masks and 247 categories.","meta":{"url":"http://arxiv.org/abs/2310.15161v1"},"cats":{"benchmark":0.1981094367,"new-dataset":0.4089321681,"data-annotation":0.5086843558,"dev-research":0.1653180927,"llms":0.5474130101,"data-quality":0.0588552328}}
{"text":"Our SAM-Med3D excels at capturing 3D spatial information, exhibiting competitive performance with significantly fewer prompt points than the top-performing fine-tuned SAM in the medical domain.","meta":{"url":"http://arxiv.org/abs/2310.15161v1"},"cats":{"benchmark":0.3656829131,"new-dataset":0.0790909262,"data-annotation":0.4950718821,"dev-research":0.1873661221,"llms":0.4949082285,"data-quality":0.0352026902}}
{"text":"We then evaluate its capabilities across 15 datasets and analyze it from multiple perspectives, including anatomical structures, modalities, targets, and generalization abilities.","meta":{"url":"http://arxiv.org/abs/2310.15161v1"},"cats":{"benchmark":0.3222203807,"new-dataset":0.2425063346,"data-annotation":0.4976277094,"dev-research":0.1221258405,"llms":0.470202367,"data-quality":0.0548278918}}
{"text":"Our approach, compared with SAM, showcases pronouncedly enhanced efficiency and broad segmentation capabilities for 3D volumetric medical images.","meta":{"url":"http://arxiv.org/abs/2310.15161v1"},"cats":{"benchmark":0.4518599193,"new-dataset":0.0801458525,"data-annotation":0.489917701,"dev-research":0.1249530492,"llms":0.4401063187,"data-quality":0.0556796209}}
{"text":"Our code is released at https://github.com/uni-medical/SAM-Med3D.","meta":{"url":"http://arxiv.org/abs/2310.15161v1"},"cats":{"benchmark":0.2653273267,"new-dataset":0.3964749466,"data-annotation":0.5116776718,"dev-research":0.2486693147,"llms":0.5115398806,"data-quality":0.0640441891}}
{"text":"Semantic segmentation has witnessed tremendous progress due to the proposal of various advanced network architectures.","meta":{"url":"http://arxiv.org/abs/2310.15160v1"},"cats":{"benchmark":0.2811340839,"new-dataset":0.1288869229,"data-annotation":0.486393487,"dev-research":0.1400169284,"llms":0.4828163244,"data-quality":0.1771493234}}
{"text":"However, they are extremely hungry for delicate annotations to train, and the acquisition is laborious and unaffordable.","meta":{"url":"http://arxiv.org/abs/2310.15160v1"},"cats":{"benchmark":0.1650964554,"new-dataset":0.0573117359,"data-annotation":0.5547392538,"dev-research":0.253649612,"llms":0.6593135276,"data-quality":0.4532413037}}
{"text":"Therefore, we present FreeMask in this work, which resorts to synthetic images from generative models to ease the burden of both data collection and annotation procedures.","meta":{"url":"http://arxiv.org/abs/2310.15160v1"},"cats":{"benchmark":0.213555634,"new-dataset":0.7494262212,"data-annotation":0.5228238712,"dev-research":0.1588517829,"llms":0.5574333877,"data-quality":0.2068240186}}
{"text":"Concretely, we first synthesize abundant training images conditioned on the semantic masks provided by realistic datasets.","meta":{"url":"http://arxiv.org/abs/2310.15160v1"},"cats":{"benchmark":0.1532447202,"new-dataset":0.3506223064,"data-annotation":0.5141757834,"dev-research":0.1787731765,"llms":0.4680049935,"data-quality":0.2211080713}}
{"text":"This yields extra well-aligned image-mask training pairs for semantic segmentation models.","meta":{"url":"http://arxiv.org/abs/2310.15160v1"},"cats":{"benchmark":0.2803255206,"new-dataset":0.311404984,"data-annotation":0.5216515818,"dev-research":0.139151888,"llms":0.4119962793,"data-quality":0.2667619761}}
{"text":"We surprisingly observe that, solely trained with synthetic images, we already achieve comparable performance with real ones (e.g., 48.3 vs. 48.5 mIoU on ADE20K, and 49.3 vs. 50.5 on COCO-Stuff).","meta":{"url":"http://arxiv.org/abs/2310.15160v1"},"cats":{"benchmark":0.3910565666,"new-dataset":0.1278280807,"data-annotation":0.5182474207,"dev-research":0.1734062787,"llms":0.4960324611,"data-quality":0.1276966343}}
{"text":"Then, we investigate the role of synthetic images by joint training with real images, or pre-training for real images.","meta":{"url":"http://arxiv.org/abs/2310.15160v1"},"cats":{"benchmark":0.1805438484,"new-dataset":0.1306037718,"data-annotation":0.5219380153,"dev-research":0.1670508063,"llms":0.4604264028,"data-quality":0.1256610139}}
{"text":"Meantime, we design a robust filtering principle to suppress incorrectly synthesized regions.","meta":{"url":"http://arxiv.org/abs/2310.15160v1"},"cats":{"benchmark":0.4436309206,"new-dataset":0.0225437127,"data-annotation":0.4901508018,"dev-research":0.2198987351,"llms":0.4234728303,"data-quality":0.2775906504}}
{"text":"In addition, we propose to inequally treat different semantic masks to prioritize those harder ones and sample more corresponding synthetic images for them.","meta":{"url":"http://arxiv.org/abs/2310.15160v1"},"cats":{"benchmark":0.3101738861,"new-dataset":0.2199025033,"data-annotation":0.514403732,"dev-research":0.1730914014,"llms":0.459939862,"data-quality":0.2196433617}}
{"text":"As a result, either jointly trained or pre-trained with our filtered and re-sampled synthesized images, segmentation models can be greatly enhanced, e.g., from 48.7 to 52.0 on ADE20K. Code is available at https://github.com/LiheYoung/FreeMask.","meta":{"url":"http://arxiv.org/abs/2310.15160v1"},"cats":{"benchmark":0.2995250807,"new-dataset":0.4272770409,"data-annotation":0.5132546142,"dev-research":0.1639022288,"llms":0.5026687786,"data-quality":0.123536236}}
{"text":"Sentiment is a pervasive feature in natural language text, yet it is an open question how sentiment is represented within Large Language Models (LLMs).","meta":{"url":"http://arxiv.org/abs/2310.15154v1"},"cats":{"benchmark":0.1896501721,"new-dataset":0.0549273322,"data-annotation":0.5280035889,"dev-research":0.182361679,"llms":0.7251061711,"data-quality":0.1534014477}}
{"text":"In this study, we reveal that across a range of models, sentiment is represented linearly: a single direction in activation space mostly captures the feature across a range of tasks with one extreme for positive and the other for negative.","meta":{"url":"http://arxiv.org/abs/2310.15154v1"},"cats":{"benchmark":0.2730919597,"new-dataset":0.0253381219,"data-annotation":0.5475651279,"dev-research":0.2376057398,"llms":0.4165449303,"data-quality":0.2380246137}}
{"text":"Through causal interventions, we isolate this direction and show it is causally relevant in both toy tasks and real world datasets such as Stanford Sentiment Treebank.","meta":{"url":"http://arxiv.org/abs/2310.15154v1"},"cats":{"benchmark":0.2875278815,"new-dataset":0.0780893255,"data-annotation":0.5460954897,"dev-research":0.269344999,"llms":0.4626878268,"data-quality":0.3048440773}}
{"text":"Through this case study we model a thorough investigation of what a single direction means on a broad data distribution.   ","meta":{"url":"http://arxiv.org/abs/2310.15154v1"},"cats":{"benchmark":0.3649182613,"new-dataset":0.0380202565,"data-annotation":0.4818314381,"dev-research":0.1667340859,"llms":0.4154419875,"data-quality":0.1087936708}}
{"text":"We further uncover the mechanisms that involve this direction, highlighting the roles of a small subset of attention heads and neurons.","meta":{"url":"http://arxiv.org/abs/2310.15154v1"},"cats":{"benchmark":0.1690744908,"new-dataset":0.0147823934,"data-annotation":0.526581431,"dev-research":0.1600386259,"llms":0.4935404269,"data-quality":0.0880875762}}
{"text":"Finally, we discover a phenomenon which we term the summarization motif: sentiment is not solely represented on emotionally charged words, but is additionally summarized at intermediate positions without inherent sentiment, such as punctuation and names.","meta":{"url":"http://arxiv.org/abs/2310.15154v1"},"cats":{"benchmark":0.2435783413,"new-dataset":0.0532677006,"data-annotation":0.5401599516,"dev-research":0.2509886508,"llms":0.5346095603,"data-quality":0.2223394478}}
{"text":"We show that in Stanford Sentiment Treebank zero-shot classification, 76% of above-chance classification accuracy is lost when ablating the sentiment direction, nearly half of which (36%) is due to ablating the summarized sentiment direction exclusively at comma positions.","meta":{"url":"http://arxiv.org/abs/2310.15154v1"},"cats":{"benchmark":0.3847154363,"new-dataset":0.0864472488,"data-annotation":0.5612406528,"dev-research":0.1616691693,"llms":0.5016048987,"data-quality":0.5009627658}}
{"text":"We prove that a polynomial fraction of the set of $k$-component forests in the $m \\times n$ grid graph have equal numbers of vertices in each component.","meta":{"url":"http://arxiv.org/abs/2310.15152v1"},"cats":{"benchmark":0.296598912,"new-dataset":0.3078373505,"data-annotation":0.5236478647,"dev-research":0.1381205469,"llms":0.5191412028,"data-quality":0.1203305953}}
{"text":"This resolves a conjecture of Charikar, Liu, Liu, and Vuong.","meta":{"url":"http://arxiv.org/abs/2310.15152v1"},"cats":{"benchmark":0.2640541764,"new-dataset":0.1754693209,"data-annotation":0.5294519557,"dev-research":0.1726071704,"llms":0.5378351401,"data-quality":0.1481059885}}
{"text":"It also establishes the first provably polynomial-time algorithm for (exactly or approximately) sampling balanced grid graph partitions according to the spanning tree distribution, which weights each $k$-partition according to the product, across its $k$ pieces, of the number of spanning trees of each piece.","meta":{"url":"http://arxiv.org/abs/2310.15152v1"},"cats":{"benchmark":0.3914141721,"new-dataset":0.0110899012,"data-annotation":0.5198837882,"dev-research":0.1201429766,"llms":0.461284653,"data-quality":0.0825322763}}
{"text":"Our result has applications to understanding political districtings, where there is an underlying graph of indivisible geographic units that must be partitioned into $k$ population-balanced connected subgraphs.","meta":{"url":"http://arxiv.org/abs/2310.15152v1"},"cats":{"benchmark":0.3215823669,"new-dataset":0.3902307291,"data-annotation":0.5214700514,"dev-research":0.1550503587,"llms":0.5335810767,"data-quality":0.1577782042}}
{"text":"In this setting, tree-weighted partitions have interesting geometric properties, and this has stimulated significant effort to develop methods to sample them.","meta":{"url":"http://arxiv.org/abs/2310.15152v1"},"cats":{"benchmark":0.4957413493,"new-dataset":0.032244006,"data-annotation":0.5359162433,"dev-research":0.1129336348,"llms":0.4365357835,"data-quality":0.1030300569}}
{"text":"Deep architectures such as Transformers are sometimes criticized for having uninterpretable \"black-box\" representations.","meta":{"url":"http://arxiv.org/abs/2310.15151v1"},"cats":{"benchmark":0.1776198852,"new-dataset":0.0054692817,"data-annotation":0.5197471996,"dev-research":0.2513758048,"llms":0.5707659357,"data-quality":0.1690427714}}
{"text":"We use causal intervention analysis to show that, in fact, some linguistic features are represented in a linear, interpretable format.","meta":{"url":"http://arxiv.org/abs/2310.15151v1"},"cats":{"benchmark":0.296634509,"new-dataset":0.0423966068,"data-annotation":0.5438811309,"dev-research":0.3098253771,"llms":0.4228584283,"data-quality":0.321970376}}
{"text":"Specifically, we show that BERT's ability to conjugate verbs relies on a linear encoding of subject number that can be manipulated with predictable effects on conjugation accuracy.","meta":{"url":"http://arxiv.org/abs/2310.15151v1"},"cats":{"benchmark":0.2885601399,"new-dataset":0.0254193257,"data-annotation":0.5609579734,"dev-research":0.1962868394,"llms":0.4920713851,"data-quality":0.1731142749}}
{"text":"This encoding is found in the subject position at the first layer and the verb position at the last layer, but distributed across positions at middle layers, particularly when there are multiple cues to subject number.","meta":{"url":"http://arxiv.org/abs/2310.15151v1"},"cats":{"benchmark":0.1830596026,"new-dataset":0.197982979,"data-annotation":0.5250243421,"dev-research":0.1421793491,"llms":0.5228353012,"data-quality":0.1481357596}}
{"text":"With advancements in AI-generated images coming on a continuous basis, it is increasingly difficult to distinguish traditionally-sourced images (e.g., photos, artwork) from AI-generated ones.","meta":{"url":"http://arxiv.org/abs/2310.15150v1"},"cats":{"benchmark":0.191366537,"new-dataset":0.1300175026,"data-annotation":0.522084791,"dev-research":0.2031386315,"llms":0.5041442162,"data-quality":0.2114310882}}
{"text":"Previous detection methods study the generalization from a single generator to another in isolation.","meta":{"url":"http://arxiv.org/abs/2310.15150v1"},"cats":{"benchmark":0.3553669659,"new-dataset":0.0109826745,"data-annotation":0.5476560331,"dev-research":0.1246058457,"llms":0.5033008111,"data-quality":0.2812658815}}
{"text":"However, in reality, new generators are released on a streaming basis.","meta":{"url":"http://arxiv.org/abs/2310.15150v1"},"cats":{"benchmark":0.1453508256,"new-dataset":0.1191854359,"data-annotation":0.4977383137,"dev-research":0.2260962186,"llms":0.5670262991,"data-quality":0.1051628413}}
{"text":"We study generalization in this setting, training on N models and testing on the next (N+k), following the historical release dates of well-known generation methods.","meta":{"url":"http://arxiv.org/abs/2310.15150v1"},"cats":{"benchmark":0.3929469849,"new-dataset":0.0600366242,"data-annotation":0.5561829138,"dev-research":0.1592750894,"llms":0.4805108516,"data-quality":0.1374143686}}
{"text":"Furthermore, images increasingly consist of both real and generated components, for example through image inpainting.","meta":{"url":"http://arxiv.org/abs/2310.15150v1"},"cats":{"benchmark":0.1669707743,"new-dataset":0.0216338465,"data-annotation":0.5175599766,"dev-research":0.200656934,"llms":0.4931124663,"data-quality":0.1074475666}}
{"text":"Thus, we extend this approach to pixel prediction, demonstrating strong performance using automatically-generated inpainted data.","meta":{"url":"http://arxiv.org/abs/2310.15150v1"},"cats":{"benchmark":0.415189785,"new-dataset":0.1278955494,"data-annotation":0.534861578,"dev-research":0.1924862102,"llms":0.4033832125,"data-quality":0.138040126}}
{"text":"In addition, for settings where commercial models are not publicly available for automatic data generation, we evaluate if pixel detectors can be trained solely on whole synthetic images.","meta":{"url":"http://arxiv.org/abs/2310.15150v1"},"cats":{"benchmark":0.2319426896,"new-dataset":0.1681451242,"data-annotation":0.5099163151,"dev-research":0.1261378949,"llms":0.5062821919,"data-quality":0.1915544565}}
{"text":"Fine-tuning a pre-trained deep neural network has become a successful paradigm in various machine learning tasks.","meta":{"url":"http://arxiv.org/abs/2310.15149v1"},"cats":{"benchmark":0.3334289703,"new-dataset":0.037339943,"data-annotation":0.5243938879,"dev-research":0.2170569721,"llms":0.498202241,"data-quality":0.1574201492}}
{"text":"However, such a paradigm becomes particularly challenging with tabular data when there are discrepancies between the feature sets of pre-trained models and the target tasks.","meta":{"url":"http://arxiv.org/abs/2310.15149v1"},"cats":{"benchmark":0.3118228211,"new-dataset":0.0559054125,"data-annotation":0.4971974499,"dev-research":0.2813024054,"llms":0.4225407726,"data-quality":0.1886109553}}
{"text":"In this paper, we propose TabToken, a method aims at enhancing the quality of feature tokens (i.e., embeddings of tabular features).","meta":{"url":"http://arxiv.org/abs/2310.15149v1"},"cats":{"benchmark":0.3890970443,"new-dataset":0.0258202409,"data-annotation":0.5254278464,"dev-research":0.3099727616,"llms":0.4611485896,"data-quality":0.3086036299}}
{"text":"TabToken allows for the utilization of pre-trained models when the upstream and downstream tasks share overlapping features, facilitating model fine-tuning even with limited training examples.","meta":{"url":"http://arxiv.org/abs/2310.15149v1"},"cats":{"benchmark":0.2555155571,"new-dataset":0.009818519,"data-annotation":0.497560237,"dev-research":0.1882377097,"llms":0.5275637861,"data-quality":0.1211635724}}
{"text":"Specifically, we introduce a contrastive objective that regularizes the tokens, capturing the semantics within and across features.","meta":{"url":"http://arxiv.org/abs/2310.15149v1"},"cats":{"benchmark":0.3979025337,"new-dataset":0.0595526524,"data-annotation":0.5333588827,"dev-research":0.3109132562,"llms":0.4433136132,"data-quality":0.337444079}}
{"text":"During the pre-training stage, the tokens are learned jointly with top-layer deep models such as transformer.","meta":{"url":"http://arxiv.org/abs/2310.15149v1"},"cats":{"benchmark":0.1883876227,"new-dataset":0.049667133,"data-annotation":0.5248636926,"dev-research":0.1251074434,"llms":0.503669749,"data-quality":0.1331692562}}
{"text":"In the downstream task, tokens of the shared features are kept fixed while TabToken efficiently fine-tunes the remaining parts of the model.","meta":{"url":"http://arxiv.org/abs/2310.15149v1"},"cats":{"benchmark":0.3108454328,"new-dataset":0.0085782852,"data-annotation":0.4839587994,"dev-research":0.2016915583,"llms":0.5056153403,"data-quality":0.1849744396}}
{"text":"TabToken not only enables knowledge transfer from a pre-trained model to tasks with heterogeneous features, but also enhances the discriminative ability of deep tabular models in standard classification and regression tasks.","meta":{"url":"http://arxiv.org/abs/2310.15149v1"},"cats":{"benchmark":0.2528598055,"new-dataset":0.0217614052,"data-annotation":0.5119973328,"dev-research":0.1881230693,"llms":0.4792170716,"data-quality":0.1233622862}}
{"text":"The rapid development of Large Language Models (LLMs) has led to great strides in model capabilities like reasoning and long-context understanding.","meta":{"url":"http://arxiv.org/abs/2310.15147v1"},"cats":{"benchmark":0.1897274894,"new-dataset":0.1128402828,"data-annotation":0.5302294516,"dev-research":0.1718009145,"llms":0.7524215198,"data-quality":0.0754188617}}
{"text":"However, as LLMs are able to process longer contexts, it becomes more challenging to evaluate whether they have acquired certain capabilities, since the length of text (e.g., 100K tokens) they can process far exceeds what humans can reliably assess in a reasonable duration.","meta":{"url":"http://arxiv.org/abs/2310.15147v1"},"cats":{"benchmark":0.3010972656,"new-dataset":0.0061934725,"data-annotation":0.5135773321,"dev-research":0.1348538037,"llms":0.7803355605,"data-quality":0.1250139199}}
{"text":"In this paper, we propose using complex synthetic tasks as a proxy evaluation method, and present S3Eval, a Synthetic, Scalable, Systematic evaluation suite for LLMs evaluation.","meta":{"url":"http://arxiv.org/abs/2310.15147v1"},"cats":{"benchmark":0.5473081316,"new-dataset":0.0446171453,"data-annotation":0.5043506543,"dev-research":0.1970772536,"llms":0.7255839635,"data-quality":0.1039479281}}
{"text":"As a synthetic benchmark, S3Eval enables the creation of any number of evaluation examples that are theoretically invisible to LLMs, mitigating the test set contamination issue.","meta":{"url":"http://arxiv.org/abs/2310.15147v1"},"cats":{"benchmark":0.6025054594,"new-dataset":0.0473177934,"data-annotation":0.5148043396,"dev-research":0.1580104329,"llms":0.7312248603,"data-quality":0.1579583036}}
{"text":"The synthetic nature of S3Eval provides users full control over the dataset, allowing them to systematically probe LLM capabilities by scaling text length and varying task difficulty across diverse scenarios.","meta":{"url":"http://arxiv.org/abs/2310.15147v1"},"cats":{"benchmark":0.270862182,"new-dataset":0.1693579535,"data-annotation":0.4893273545,"dev-research":0.1572451317,"llms":0.751591148,"data-quality":0.0922927868}}
{"text":"The strong correlation between S3Eval performance and scores of real-world benchmarks like Big-Bench Hard (BBH) demonstrates the soundness of using S3Eval for evaluation of LLMs.","meta":{"url":"http://arxiv.org/abs/2310.15147v1"},"cats":{"benchmark":0.6501679884,"new-dataset":0.0258735849,"data-annotation":0.4928391239,"dev-research":0.1215980447,"llms":0.7446248667,"data-quality":0.0793027239}}
{"text":"The in-depth analysis also uncover additional insights, including performance drop when the answer is sparsely distributed or located in the middle context, as well as some counter-intuitive trends of model performance.","meta":{"url":"http://arxiv.org/abs/2310.15147v1"},"cats":{"benchmark":0.541966461,"new-dataset":0.0079839789,"data-annotation":0.5324683163,"dev-research":0.2256527926,"llms":0.4475075099,"data-quality":0.094945128}}
{"text":"The pre-train and fine-tune paradigm in machine learning has had dramatic success in a wide range of domains because the use of existing data or pre-trained models on the internet enables quick and easy learning of new tasks.","meta":{"url":"http://arxiv.org/abs/2310.15145v1"},"cats":{"benchmark":0.3081282503,"new-dataset":0.0926474635,"data-annotation":0.5259617448,"dev-research":0.2415489511,"llms":0.457876989,"data-quality":0.1160871479}}
{"text":"We aim to enable this paradigm in robotic reinforcement learning, allowing a robot to learn a new task with little human effort by leveraging data and models from the Internet.","meta":{"url":"http://arxiv.org/abs/2310.15145v1"},"cats":{"benchmark":0.1848342612,"new-dataset":0.1188750781,"data-annotation":0.50619061,"dev-research":0.1670187296,"llms":0.5011823763,"data-quality":0.0723538563}}
{"text":"However, reinforcement learning often requires significant human effort in the form of manual reward specification or environment resets, even if the policy is pre-trained.","meta":{"url":"http://arxiv.org/abs/2310.15145v1"},"cats":{"benchmark":0.209112325,"new-dataset":0.0109022684,"data-annotation":0.5091345074,"dev-research":0.2809189255,"llms":0.5092445219,"data-quality":0.1210159969}}
{"text":"We introduce RoboFuME, a reset-free fine-tuning system that pre-trains a multi-task manipulation policy from diverse datasets of prior experiences and self-improves online to learn a target task with minimal human intervention.","meta":{"url":"http://arxiv.org/abs/2310.15145v1"},"cats":{"benchmark":0.3116054702,"new-dataset":0.2061935833,"data-annotation":0.5087641145,"dev-research":0.2553394134,"llms":0.5308571051,"data-quality":0.1302257946}}
{"text":"Our insights are to utilize calibrated offline reinforcement learning techniques to ensure efficient online fine-tuning of a pre-trained policy in the presence of distribution shifts and leverage pre-trained vision language models (VLMs) to build a robust reward classifier for autonomously providing reward signals during the online fine-tuning process.","meta":{"url":"http://arxiv.org/abs/2310.15145v1"},"cats":{"benchmark":0.2544350707,"new-dataset":0.0903043848,"data-annotation":0.5221909185,"dev-research":0.1612016429,"llms":0.4610225512,"data-quality":0.1513597095}}
{"text":"In a diverse set of five real robot manipulation tasks, we show that our method can incorporate data from an existing robot dataset collected at a different institution and improve on a target task within as little as 3 hours of autonomous real-world experience.","meta":{"url":"http://arxiv.org/abs/2310.15145v1"},"cats":{"benchmark":0.266611109,"new-dataset":0.605578557,"data-annotation":0.4933483061,"dev-research":0.2465496832,"llms":0.4554704108,"data-quality":0.0779392707}}
{"text":"We also demonstrate in simulation experiments that our method outperforms prior works that use different RL algorithms or different approaches for predicting rewards.","meta":{"url":"http://arxiv.org/abs/2310.15145v1"},"cats":{"benchmark":0.5090705983,"new-dataset":0.0085807534,"data-annotation":0.5339844606,"dev-research":0.1214049305,"llms":0.4327135056,"data-quality":0.1181811024}}
{"text":"Project website: https://robofume.github.io","meta":{"url":"http://arxiv.org/abs/2310.15145v1"},"cats":{"benchmark":0.2475765699,"new-dataset":0.4780897701,"data-annotation":0.5227462411,"dev-research":0.2545926614,"llms":0.5847756649,"data-quality":0.0893811702}}
{"text":"We introduce DEsignBench, a text-to-image (T2I) generation benchmark tailored for visual design scenarios.","meta":{"url":"http://arxiv.org/abs/2310.15144v1"},"cats":{"benchmark":0.484666579,"new-dataset":0.4752840438,"data-annotation":0.5126558698,"dev-research":0.354498147,"llms":0.5575277516,"data-quality":0.1127675732}}
{"text":"Recent T2I models like DALL-E 3 and others, have demonstrated remarkable capabilities in generating photorealistic images that align closely with textual inputs.","meta":{"url":"http://arxiv.org/abs/2310.15144v1"},"cats":{"benchmark":0.2341850676,"new-dataset":0.1456879544,"data-annotation":0.5201322276,"dev-research":0.1555965547,"llms":0.5223031981,"data-quality":0.0863255505}}
{"text":"While the allure of creating visually captivating images is undeniable, our emphasis extends beyond mere aesthetic pleasure.","meta":{"url":"http://arxiv.org/abs/2310.15144v1"},"cats":{"benchmark":0.2297354932,"new-dataset":0.0493344733,"data-annotation":0.5309454522,"dev-research":0.213548052,"llms":0.5243092012,"data-quality":0.1515251933}}
{"text":"We aim to investigate the potential of using these powerful models in authentic design contexts.","meta":{"url":"http://arxiv.org/abs/2310.15144v1"},"cats":{"benchmark":0.2856803674,"new-dataset":0.0064534494,"data-annotation":0.4965665206,"dev-research":0.3142033309,"llms":0.602179887,"data-quality":0.0974519364}}
{"text":"In pursuit of this goal, we develop DEsignBench, which incorporates test samples designed to assess T2I models on both \"design technical capability\" and \"design application scenario.\"","meta":{"url":"http://arxiv.org/abs/2310.15144v1"},"cats":{"benchmark":0.4156705804,"new-dataset":0.055106725,"data-annotation":0.5068441256,"dev-research":0.3341056276,"llms":0.5831786268,"data-quality":0.0518933891}}
{"text":"Each of these two dimensions is supported by a diverse set of specific design categories.","meta":{"url":"http://arxiv.org/abs/2310.15144v1"},"cats":{"benchmark":0.2368041372,"new-dataset":0.0257654311,"data-annotation":0.4866820904,"dev-research":0.1741486461,"llms":0.5029801692,"data-quality":0.0530562696}}
{"text":"We explore DALL-E 3 together with other leading T2I models on DEsignBench, resulting in a comprehensive visual gallery for side-by-side comparisons.","meta":{"url":"http://arxiv.org/abs/2310.15144v1"},"cats":{"benchmark":0.4703877821,"new-dataset":0.0848276528,"data-annotation":0.5166927116,"dev-research":0.2948905532,"llms":0.5875536341,"data-quality":0.0553610373}}
{"text":"For DEsignBench benchmarking, we perform human evaluations on generated images in DEsignBench gallery, against the criteria of image-text alignment, visual aesthetic, and design creativity.","meta":{"url":"http://arxiv.org/abs/2310.15144v1"},"cats":{"benchmark":0.5677237242,"new-dataset":0.209735962,"data-annotation":0.5288253082,"dev-research":0.3415796136,"llms":0.5313489895,"data-quality":0.1697594321}}
{"text":"Our evaluation also considers other specialized design capabilities, including text rendering, layout composition, color harmony, 3D design, and medium style.","meta":{"url":"http://arxiv.org/abs/2310.15144v1"},"cats":{"benchmark":0.3983435383,"new-dataset":0.0334282163,"data-annotation":0.5200355561,"dev-research":0.2308015836,"llms":0.5674736054,"data-quality":0.0595032076}}
{"text":"In addition to human evaluations, we introduce the first automatic image generation evaluator powered by GPT-4V. This evaluator provides ratings that align well with human judgments, while being easily replicable and cost-efficient.","meta":{"url":"http://arxiv.org/abs/2310.15144v1"},"cats":{"benchmark":0.3711596327,"new-dataset":0.1655825909,"data-annotation":0.5442106747,"dev-research":0.2186968096,"llms":0.4989984146,"data-quality":0.1849386418}}
{"text":"A high-resolution version is available at https://github.com/design-bench/design-bench.github.io/raw/main/designbench.pdf?download=","meta":{"url":"http://arxiv.org/abs/2310.15144v1"},"cats":{"benchmark":0.4678195852,"new-dataset":0.3631299716,"data-annotation":0.501456724,"dev-research":0.2823605279,"llms":0.5236556059,"data-quality":0.0717790743}}
{"text":"Autoregressive sampling from large language models has led to state-of-the-art results in several natural language tasks.","meta":{"url":"http://arxiv.org/abs/2310.15141v1"},"cats":{"benchmark":0.3602959295,"new-dataset":0.1649532815,"data-annotation":0.5562373415,"dev-research":0.1439217326,"llms":0.4667603892,"data-quality":0.2462521457}}
{"text":"However, autoregressive sampling generates tokens one at a time making it slow, and even prohibitive in certain tasks.","meta":{"url":"http://arxiv.org/abs/2310.15141v1"},"cats":{"benchmark":0.3661456031,"new-dataset":0.0066819977,"data-annotation":0.5126995442,"dev-research":0.164217885,"llms":0.4905937659,"data-quality":0.1683096409}}
{"text":"One way to speed up sampling is $\\textit{speculative decoding}$: use a small model to sample a $\\textit{draft}$ (block or sequence of tokens), and then score all tokens in the draft by the large language model in parallel.","meta":{"url":"http://arxiv.org/abs/2310.15141v1"},"cats":{"benchmark":0.462289994,"new-dataset":0.1906911666,"data-annotation":0.5329976097,"dev-research":0.1513084831,"llms":0.5486017994,"data-quality":0.1703077947}}
{"text":"A subset of the tokens in the draft are accepted (and the rest rejected) based on a statistical method to guarantee that the final output follows the distribution of the large model.","meta":{"url":"http://arxiv.org/abs/2310.15141v1"},"cats":{"benchmark":0.422389225,"new-dataset":0.0395579825,"data-annotation":0.523914229,"dev-research":0.1429886042,"llms":0.4597451343,"data-quality":0.2183297651}}
{"text":"In this work, we provide a principled understanding of speculative decoding through the lens of optimal transport (OT) with $\\textit{membership cost}$. This framework can be viewed as an extension of the well-known $\\textit{maximal-coupling}$ problem.","meta":{"url":"http://arxiv.org/abs/2310.15141v1"},"cats":{"benchmark":0.3488494761,"new-dataset":0.0371751645,"data-annotation":0.5215100345,"dev-research":0.1319708661,"llms":0.4547691631,"data-quality":0.1219826542}}
{"text":"This new formulation enables us to generalize the speculative decoding method to allow for a set of $k$ candidates at the token-level, which leads to an improved optimal membership cost.","meta":{"url":"http://arxiv.org/abs/2310.15141v1"},"cats":{"benchmark":0.4172105984,"new-dataset":0.0372638475,"data-annotation":0.551316905,"dev-research":0.1199662309,"llms":0.4669771653,"data-quality":0.2000814585}}
{"text":"We show that the optimal draft selection algorithm (transport plan) can be computed via linear programming, whose best-known runtime is exponential in $k$.","meta":{"url":"http://arxiv.org/abs/2310.15141v1"},"cats":{"benchmark":0.4638249956,"new-dataset":0.0396879445,"data-annotation":0.5094013551,"dev-research":0.1477856159,"llms":0.3796909426,"data-quality":0.0377894596}}
{"text":"We then propose a valid draft selection algorithm whose acceptance probability is $(1-1/e)$-optimal multiplicatively.","meta":{"url":"http://arxiv.org/abs/2310.15141v1"},"cats":{"benchmark":0.5379547619,"new-dataset":0.0092742581,"data-annotation":0.526067127,"dev-research":0.1443007074,"llms":0.491738218,"data-quality":0.0952282877}}
{"text":"Moreover, it can be computed in time almost linear with size of domain of a single token.","meta":{"url":"http://arxiv.org/abs/2310.15141v1"},"cats":{"benchmark":0.501583293,"new-dataset":0.014811316,"data-annotation":0.5456564088,"dev-research":0.0913120414,"llms":0.4134053977,"data-quality":0.1031137772}}
{"text":"Using this $new draft selection$","meta":{"url":"http://arxiv.org/abs/2310.15141v1"},"cats":{"benchmark":0.3458381811,"new-dataset":0.0313564029,"data-annotation":0.5175158441,"dev-research":0.1921359078,"llms":0.5417849991,"data-quality":0.081099867}}
{"text":"algorithm, we develop a new autoregressive sampling algorithm called $\\textit{SpecTr}$, which provides speedup in decoding while ensuring that there is no quality degradation in the decoded output.","meta":{"url":"http://arxiv.org/abs/2310.15141v1"},"cats":{"benchmark":0.5077355013,"new-dataset":0.0761178814,"data-annotation":0.5162839173,"dev-research":0.1422742329,"llms":0.4411428286,"data-quality":0.1935417115}}
{"text":"We experimentally demonstrate that for state-of-the-art large language models, the proposed approach achieves a wall clock speedup of 2.13X, a further 1.37X speedup over speculative decoding on standard benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.15141v1"},"cats":{"benchmark":0.4563375177,"new-dataset":0.3204099955,"data-annotation":0.5461977506,"dev-research":0.1924408287,"llms":0.5275585214,"data-quality":0.1212492013}}
{"text":"Safety alignment of Large Language Models (LLMs) can be compromised with manual jailbreak attacks and (automatic) adversarial attacks.","meta":{"url":"http://arxiv.org/abs/2310.15140v1"},"cats":{"benchmark":0.2667051976,"new-dataset":0.1408162856,"data-annotation":0.5330812047,"dev-research":0.1933312172,"llms":0.6522759267,"data-quality":0.273597686}}
{"text":"Recent work suggests that patching LLMs against these attacks is possible: manual jailbreak attacks are human-readable but often limited and public, making them easy to block; adversarial attacks generate gibberish prompts that can be detected using perplexity-based filters.","meta":{"url":"http://arxiv.org/abs/2310.15140v1"},"cats":{"benchmark":0.2405768719,"new-dataset":0.031559223,"data-annotation":0.5166958701,"dev-research":0.1742309185,"llms":0.7292726771,"data-quality":0.240501742}}
{"text":"In this paper, we show that these solutions may be too optimistic.","meta":{"url":"http://arxiv.org/abs/2310.15140v1"},"cats":{"benchmark":0.4111894693,"new-dataset":0.0798199913,"data-annotation":0.5409286909,"dev-research":0.1460894187,"llms":0.403936404,"data-quality":0.17412575}}
{"text":"We propose an interpretable adversarial attack, \\texttt{AutoDAN}, that combines the strengths of both types of attacks.","meta":{"url":"http://arxiv.org/abs/2310.15140v1"},"cats":{"benchmark":0.2261487603,"new-dataset":0.0601635281,"data-annotation":0.5491875812,"dev-research":0.2016858435,"llms":0.4850538751,"data-quality":0.2525023696}}
{"text":"It automatically generates attack prompts that bypass perplexity-based filters while maintaining a high attack success rate like manual jailbreak attacks.","meta":{"url":"http://arxiv.org/abs/2310.15140v1"},"cats":{"benchmark":0.2853264909,"new-dataset":0.0202056485,"data-annotation":0.5014567877,"dev-research":0.2623786387,"llms":0.573837939,"data-quality":0.1155164628}}
{"text":"These prompts are interpretable and diverse, exhibiting strategies commonly used in manual jailbreak attacks, and transfer better than their non-readable counterparts when using limited training data or a single proxy model.","meta":{"url":"http://arxiv.org/abs/2310.15140v1"},"cats":{"benchmark":0.1951617087,"new-dataset":0.0697034027,"data-annotation":0.5057697988,"dev-research":0.2221728986,"llms":0.5207414345,"data-quality":0.1748674083}}
{"text":"We also customize \\texttt{AutoDAN}'s objective to leak system prompts, another jailbreak application not addressed in the adversarial attack literature.","meta":{"url":"http://arxiv.org/abs/2310.15140v1"},"cats":{"benchmark":0.2118761881,"new-dataset":0.0563974309,"data-annotation":0.5280633971,"dev-research":0.2562577664,"llms":0.5276218321,"data-quality":0.2485583474}}
{"text":"%, demonstrating the versatility of the approach.","meta":{"url":"http://arxiv.org/abs/2310.15140v1"},"cats":{"benchmark":0.4654400205,"new-dataset":0.0093768064,"data-annotation":0.5208447202,"dev-research":0.1866732089,"llms":0.4871334561,"data-quality":0.1088062623}}
{"text":"We can also customize the objective of \\texttt{AutoDAN} to leak system prompts, beyond the ability to elicit harmful content from the model, demonstrating the versatility of the approach.","meta":{"url":"http://arxiv.org/abs/2310.15140v1"},"cats":{"benchmark":0.1891415137,"new-dataset":0.0353485616,"data-annotation":0.5191160955,"dev-research":0.2483252815,"llms":0.5606624274,"data-quality":0.2962228351}}
{"text":"Our work provides a new way to red-team LLMs and to understand the mechanism of jailbreak attacks.","meta":{"url":"http://arxiv.org/abs/2310.15140v1"},"cats":{"benchmark":0.2142334929,"new-dataset":0.1510162183,"data-annotation":0.5066660936,"dev-research":0.2206964,"llms":0.7099745408,"data-quality":0.0910229204}}
{"text":"Fruit distribution is pivotal in shaping the future of both agriculture and agricultural robotics, paving the way for a streamlined supply chain.","meta":{"url":"http://arxiv.org/abs/2310.15138v1"},"cats":{"benchmark":0.1968517522,"new-dataset":0.0457082406,"data-annotation":0.489340973,"dev-research":0.1609606177,"llms":0.4534707479,"data-quality":0.0621710203}}
{"text":"This study introduces an innovative methodology that harnesses the synergy of RGB imagery, LiDAR, and IMU data, to achieve intricate tree reconstructions and the pinpoint localization of fruits.","meta":{"url":"http://arxiv.org/abs/2310.15138v1"},"cats":{"benchmark":0.2831546926,"new-dataset":0.1805063424,"data-annotation":0.5018724392,"dev-research":0.1612036886,"llms":0.480222799,"data-quality":0.1381036962}}
{"text":"Such integration not only offers insights into the fruit distribution, which enhances the precision of guidance for agricultural robotics and automation systems, but also sets the stage for simulating synthetic fruit patterns across varied tree architectures.","meta":{"url":"http://arxiv.org/abs/2310.15138v1"},"cats":{"benchmark":0.258724543,"new-dataset":0.047213217,"data-annotation":0.4939376611,"dev-research":0.1711213347,"llms":0.4653190803,"data-quality":0.0705722003}}
{"text":"To validate this approach, experiments have been carried out in both a controlled environment and an actual peach orchard.","meta":{"url":"http://arxiv.org/abs/2310.15138v1"},"cats":{"benchmark":0.393442724,"new-dataset":0.0300650116,"data-annotation":0.5053556125,"dev-research":0.1844108765,"llms":0.5046681559,"data-quality":0.0788418589}}
{"text":"The results underscore the robustness and efficacy of this fusion-driven methodology, highlighting its potential as a transformative tool for future agricultural robotics and precision farming.","meta":{"url":"http://arxiv.org/abs/2310.15138v1"},"cats":{"benchmark":0.4195058263,"new-dataset":0.0071280801,"data-annotation":0.4914088041,"dev-research":0.1918810861,"llms":0.4240850133,"data-quality":0.0924258439}}
{"text":"Historically, researchers and consumers have noticed a decrease in quality when applying NLP tools to minority variants of languages (i.e. Puerto Rican Spanish or Swiss German), but studies exploring this have been limited to a select few languages.","meta":{"url":"http://arxiv.org/abs/2310.15135v1"},"cats":{"benchmark":0.3889537525,"new-dataset":0.023668239,"data-annotation":0.5379980355,"dev-research":0.2834511852,"llms":0.5142865182,"data-quality":0.349652112}}
{"text":"Additionally, past studies have mainly been conducted in a monolingual context, so cross-linguistic trends have not been identified and tied to external factors.","meta":{"url":"http://arxiv.org/abs/2310.15135v1"},"cats":{"benchmark":0.2866398891,"new-dataset":0.0151750963,"data-annotation":0.5088490764,"dev-research":0.2063399532,"llms":0.5680974934,"data-quality":0.2015375145}}
{"text":"In this work, we conduct a comprehensive evaluation of the most influential, state-of-the-art large language models (LLMs) across two high-use applications, machine translation and automatic speech recognition, to assess their functionality on the regional dialects of several high- and low-resource languages.","meta":{"url":"http://arxiv.org/abs/2310.15135v1"},"cats":{"benchmark":0.3617211559,"new-dataset":0.2245787236,"data-annotation":0.532737745,"dev-research":0.1335930592,"llms":0.6789572919,"data-quality":0.1586375168}}
{"text":"Additionally, we analyze how the regional dialect gap is correlated with economic, social, and linguistic factors.","meta":{"url":"http://arxiv.org/abs/2310.15135v1"},"cats":{"benchmark":0.3198460076,"new-dataset":0.0574188626,"data-annotation":0.5210795284,"dev-research":0.2119578199,"llms":0.4998411825,"data-quality":0.1573399916}}
{"text":"The impact of training data, including related factors like dataset size and its construction procedure, is shown to be significant but not consistent across models or languages, meaning a one-size-fits-all approach cannot be taken in solving the dialect gap.","meta":{"url":"http://arxiv.org/abs/2310.15135v1"},"cats":{"benchmark":0.252363302,"new-dataset":0.1109278167,"data-annotation":0.4999581828,"dev-research":0.2085083044,"llms":0.487961724,"data-quality":0.2842103533}}
{"text":"This work will lay the foundation for furthering the field of dialectal NLP by laying out evident disparities and identifying possible pathways for addressing them through mindful data collection.","meta":{"url":"http://arxiv.org/abs/2310.15135v1"},"cats":{"benchmark":0.2353208514,"new-dataset":0.2860082522,"data-annotation":0.5090413151,"dev-research":0.2103271577,"llms":0.5737121194,"data-quality":0.2275217611}}
{"text":"We investigate the benefit of combining blind audio recordings with 3D scene information for novel-view acoustic synthesis.","meta":{"url":"http://arxiv.org/abs/2310.15130v1"},"cats":{"benchmark":0.3266995726,"new-dataset":0.1267592478,"data-annotation":0.5193730426,"dev-research":0.2505597242,"llms":0.4228160996,"data-quality":0.1718620455}}
{"text":"Given audio recordings from 2-4 microphones and the 3D geometry and material of a scene containing multiple unknown sound sources, we estimate the sound anywhere in the scene.","meta":{"url":"http://arxiv.org/abs/2310.15130v1"},"cats":{"benchmark":0.3989899906,"new-dataset":0.2861629872,"data-annotation":0.5500400508,"dev-research":0.1407123496,"llms":0.3689628425,"data-quality":0.2325255149}}
{"text":"We identify the main challenges of novel-view acoustic synthesis as sound source localization, separation, and dereverberation.","meta":{"url":"http://arxiv.org/abs/2310.15130v1"},"cats":{"benchmark":0.3159267601,"new-dataset":0.0994238605,"data-annotation":0.513272084,"dev-research":0.2491966797,"llms":0.4802866172,"data-quality":0.1867494115}}
{"text":"While naively training an end-to-end network fails to produce high-quality results, we show that incorporating room impulse responses (RIRs) derived from 3D reconstructed rooms enables the same network to jointly tackle these tasks.","meta":{"url":"http://arxiv.org/abs/2310.15130v1"},"cats":{"benchmark":0.3034690672,"new-dataset":0.1203608424,"data-annotation":0.5066837253,"dev-research":0.1936569528,"llms":0.4905218365,"data-quality":0.1012360848}}
{"text":"Our method outperforms existing methods designed for the individual tasks, demonstrating its effectiveness at utilizing 3D visual information.","meta":{"url":"http://arxiv.org/abs/2310.15130v1"},"cats":{"benchmark":0.389802191,"new-dataset":0.0108111636,"data-annotation":0.5196491042,"dev-research":0.3675387222,"llms":0.4402332595,"data-quality":0.078737225}}
{"text":"In a simulated study on the Matterport3D-NVAS dataset, our model achieves near-perfect accuracy on source localization, a PSNR of 26.44 dB and a SDR of 14.23 dB for source separation and dereverberation, resulting in a PSNR of 25.55 dB and a SDR of 14.20 dB on novel-view acoustic synthesis.","meta":{"url":"http://arxiv.org/abs/2310.15130v1"},"cats":{"benchmark":0.3367865391,"new-dataset":0.4772895414,"data-annotation":0.4870207565,"dev-research":0.2029033962,"llms":0.5251583253,"data-quality":0.1889178446}}
{"text":"Code, pretrained model, and video results are available on the project webpage (https://github.com/apple/ml-nvas3d).","meta":{"url":"http://arxiv.org/abs/2310.15130v1"},"cats":{"benchmark":0.2617625631,"new-dataset":0.3902576093,"data-annotation":0.5142824384,"dev-research":0.1971010148,"llms":0.4966999927,"data-quality":0.0628551328}}
{"text":"This work introduces a novel task, location-aware visual question generation (LocaVQG), which aims to generate engaging questions from data relevant to a particular geographical location.","meta":{"url":"http://arxiv.org/abs/2310.15129v1"},"cats":{"benchmark":0.1474000497,"new-dataset":0.5093798068,"data-annotation":0.5063858354,"dev-research":0.2638819228,"llms":0.6236962378,"data-quality":0.0919454526}}
{"text":"Specifically, we represent such location-aware information with surrounding images and a GPS coordinate.","meta":{"url":"http://arxiv.org/abs/2310.15129v1"},"cats":{"benchmark":0.2229305329,"new-dataset":0.1912395247,"data-annotation":0.5009567245,"dev-research":0.1949806326,"llms":0.4763440013,"data-quality":0.1062378168}}
{"text":"To tackle this task, we present a dataset generation pipeline that leverages GPT-4 to produce diverse and sophisticated questions.","meta":{"url":"http://arxiv.org/abs/2310.15129v1"},"cats":{"benchmark":0.2004324542,"new-dataset":0.7867484915,"data-annotation":0.4843433092,"dev-research":0.1837333818,"llms":0.5016626354,"data-quality":0.1307719379}}
{"text":"Then, we aim to learn a lightweight model that can address the LocaVQG task and fit on an edge device, such as a mobile phone.","meta":{"url":"http://arxiv.org/abs/2310.15129v1"},"cats":{"benchmark":0.2205311407,"new-dataset":0.0441762161,"data-annotation":0.5000058013,"dev-research":0.1349624051,"llms":0.6406172247,"data-quality":0.0451281928}}
{"text":"To this end, we propose a method which can reliably generate engaging questions from location-aware information.","meta":{"url":"http://arxiv.org/abs/2310.15129v1"},"cats":{"benchmark":0.2250701079,"new-dataset":0.0587445212,"data-annotation":0.529083851,"dev-research":0.2806557664,"llms":0.5686809985,"data-quality":0.133165359}}
{"text":"Our proposed method outperforms baselines regarding human evaluation (e.g., engagement, grounding, coherence) and automatic evaluation metrics (e.g., BERTScore, ROUGE-2).","meta":{"url":"http://arxiv.org/abs/2310.15129v1"},"cats":{"benchmark":0.6471199796,"new-dataset":0.0682737831,"data-annotation":0.5631939031,"dev-research":0.308528262,"llms":0.474224952,"data-quality":0.2037125735}}
{"text":"Moreover, we conduct extensive ablation studies to justify our proposed techniques for both generating the dataset and solving the task.","meta":{"url":"http://arxiv.org/abs/2310.15129v1"},"cats":{"benchmark":0.4071212191,"new-dataset":0.3194129093,"data-annotation":0.5086059014,"dev-research":0.1317596856,"llms":0.4222593297,"data-quality":0.1170402926}}
{"text":"We present, QP-SBGD, a novel layer-wise stochastic optimiser tailored towards training neural networks with binary weights, known as binary neural networks (BNNs), on quantum hardware.","meta":{"url":"http://arxiv.org/abs/2310.15128v1"},"cats":{"benchmark":0.3570304372,"new-dataset":0.0350159134,"data-annotation":0.5179240181,"dev-research":0.107633046,"llms":0.4685667717,"data-quality":0.0733157566}}
{"text":"BNNs reduce the computational requirements and energy consumption of deep learning models with minimal loss in accuracy.","meta":{"url":"http://arxiv.org/abs/2310.15128v1"},"cats":{"benchmark":0.356424623,"new-dataset":0.0322723061,"data-annotation":0.5022453569,"dev-research":0.1423646739,"llms":0.5145836729,"data-quality":0.1052225481}}
{"text":"However, training them in practice remains to be an open challenge.","meta":{"url":"http://arxiv.org/abs/2310.15128v1"},"cats":{"benchmark":0.1907296428,"new-dataset":0.0289442327,"data-annotation":0.5254637693,"dev-research":0.2217343042,"llms":0.5620745138,"data-quality":0.1733951523}}
{"text":"Most known BNN-optimisers either rely on projected updates or binarise weights post-training.","meta":{"url":"http://arxiv.org/abs/2310.15128v1"},"cats":{"benchmark":0.520933667,"new-dataset":0.0069967303,"data-annotation":0.5138060734,"dev-research":0.1457064982,"llms":0.4614413211,"data-quality":0.0812434089}}
{"text":"Instead, QP-SBGD approximately maps the gradient onto binary variables, by solving a quadratic constrained binary optimisation.","meta":{"url":"http://arxiv.org/abs/2310.15128v1"},"cats":{"benchmark":0.4470369407,"new-dataset":0.0072735155,"data-annotation":0.5201251617,"dev-research":0.104033906,"llms":0.3805761126,"data-quality":0.0782909659}}
{"text":"Under practically reasonable assumptions, we show that this update rule converges with a rate of $\\mathcal{O}(1 / \\sqrt{T})$.","meta":{"url":"http://arxiv.org/abs/2310.15128v1"},"cats":{"benchmark":0.4692085116,"new-dataset":0.0485212251,"data-annotation":0.5131052576,"dev-research":0.1702155586,"llms":0.479242783,"data-quality":0.1192309799}}
{"text":"Moreover, we show how the $\\mathcal{NP}$-hard projection can be effectively executed on an adiabatic quantum annealer, harnessing recent advancements in quantum computation.","meta":{"url":"http://arxiv.org/abs/2310.15128v1"},"cats":{"benchmark":0.3971807722,"new-dataset":0.0143430275,"data-annotation":0.5311155666,"dev-research":0.1909266943,"llms":0.5243355643,"data-quality":0.0712624662}}
{"text":"We also introduce a projected version of this update rule and prove that if a fixed point exists in the binary variable space, the modified updates will converge to it.","meta":{"url":"http://arxiv.org/abs/2310.15128v1"},"cats":{"benchmark":0.4452337511,"new-dataset":0.0887158424,"data-annotation":0.5017219371,"dev-research":0.2421959698,"llms":0.4152391045,"data-quality":0.1925485025}}
{"text":"Last but not least, our algorithm is implemented layer-wise, making it suitable to train larger networks on resource-limited quantum hardware.","meta":{"url":"http://arxiv.org/abs/2310.15128v1"},"cats":{"benchmark":0.3069218716,"new-dataset":0.0162407166,"data-annotation":0.5324765895,"dev-research":0.106308084,"llms":0.5342021715,"data-quality":0.0475141749}}
{"text":"Through extensive evaluations, we show that QP-SBGD outperforms or is on par with competitive and well-established baselines such as BinaryConnect, signSGD and ProxQuant when optimising the Rosenbrock function, training BNNs as well as binary graph neural networks.","meta":{"url":"http://arxiv.org/abs/2310.15128v1"},"cats":{"benchmark":0.5038391615,"new-dataset":0.0520214374,"data-annotation":0.5185397428,"dev-research":0.1139971723,"llms":0.476416982,"data-quality":0.0963053681}}
{"text":"Pre-trained and frozen LLMs can effectively map simple scene re-arrangement instructions to programs over a robot's visuomotor functions through appropriate few-shot example prompting.","meta":{"url":"http://arxiv.org/abs/2310.15127v1"},"cats":{"benchmark":0.1389653871,"new-dataset":0.1246111983,"data-annotation":0.508116717,"dev-research":0.2375093996,"llms":0.7257161356,"data-quality":0.0678308295}}
{"text":"To parse open-domain natural language and adapt to a user's idiosyncratic procedures, not known during prompt engineering time, fixed prompts fall short.","meta":{"url":"http://arxiv.org/abs/2310.15127v1"},"cats":{"benchmark":0.2060414346,"new-dataset":0.1187244737,"data-annotation":0.5194271397,"dev-research":0.4032696376,"llms":0.6049855957,"data-quality":0.3039107411}}
{"text":"In this paper, we introduce HELPER, an embodied agent equipped with an external memory of language-program pairs that parses free-form human-robot dialogue into action programs through retrieval-augmented LLM prompting: relevant memories are retrieved based on the current dialogue, instruction, correction or VLM description, and used as in-context prompt examples for LLM querying.","meta":{"url":"http://arxiv.org/abs/2310.15127v1"},"cats":{"benchmark":0.1260413889,"new-dataset":0.1528720928,"data-annotation":0.5242289313,"dev-research":0.224902467,"llms":0.7252842993,"data-quality":0.0964875516}}
{"text":"The memory is expanded during deployment to include pairs of user's language and action plans, to assist future inferences and personalize them to the user's language and routines.","meta":{"url":"http://arxiv.org/abs/2310.15127v1"},"cats":{"benchmark":0.1224449999,"new-dataset":0.1813493497,"data-annotation":0.5028467515,"dev-research":0.3490554793,"llms":0.6195738881,"data-quality":0.0769023838}}
{"text":"HELPER sets a new state-of-the-art in the TEACh benchmark in both Execution from Dialog History (EDH) and Trajectory from Dialogue (TfD), with 1.7x improvement over the previous SOTA for TfD. Our models, code and video results can be found in our project's website: https://helper-agent-llm.github.io.","meta":{"url":"http://arxiv.org/abs/2310.15127v1"},"cats":{"benchmark":0.3888709517,"new-dataset":0.2541074003,"data-annotation":0.5417560223,"dev-research":0.1700085687,"llms":0.7037684812,"data-quality":0.1003402351}}
{"text":"Large Language Models (LLMs) are frequently used for multi-faceted language generation and evaluation tasks that involve satisfying intricate user constraints or taking into account multiple aspects and criteria.","meta":{"url":"http://arxiv.org/abs/2310.15123v1"},"cats":{"benchmark":0.2136670864,"new-dataset":0.1115416364,"data-annotation":0.5347426784,"dev-research":0.2149518695,"llms":0.7382040213,"data-quality":0.1185472854}}
{"text":"However, their performance can fall short, due to the model's lack of coherence and inability to plan and decompose the problem.","meta":{"url":"http://arxiv.org/abs/2310.15123v1"},"cats":{"benchmark":0.4999191762,"new-dataset":0.0041510345,"data-annotation":0.528215629,"dev-research":0.1794359206,"llms":0.4248070052,"data-quality":0.1401821127}}
{"text":"We propose Branch-Solve-Merge (BSM), a Large Language Model program (Schlag et al., 2023) for tackling such challenging natural language tasks.","meta":{"url":"http://arxiv.org/abs/2310.15123v1"},"cats":{"benchmark":0.3126781922,"new-dataset":0.315189318,"data-annotation":0.5205530403,"dev-research":0.3041293269,"llms":0.5632388718,"data-quality":0.2607248107}}
{"text":"It consists of branch, solve, and merge modules that are parameterized with specific prompts to the base LLM.","meta":{"url":"http://arxiv.org/abs/2310.15123v1"},"cats":{"benchmark":0.1876946399,"new-dataset":0.0648723331,"data-annotation":0.4918232655,"dev-research":0.2251156078,"llms":0.7177918967,"data-quality":0.0626014501}}
{"text":"These three modules plan a decomposition of the task into multiple parallel sub-tasks, independently solve them, and fuse the solutions to the sub-tasks.","meta":{"url":"http://arxiv.org/abs/2310.15123v1"},"cats":{"benchmark":0.2934147584,"new-dataset":0.1028855293,"data-annotation":0.5113511652,"dev-research":0.2244436462,"llms":0.4860556045,"data-quality":0.0601211558}}
{"text":"We apply our method to the tasks of LLM response evaluation and constrained text generation and evaluate its effectiveness with multiple LLMs, including Vicuna, LLaMA-2-chat, and GPT-4.","meta":{"url":"http://arxiv.org/abs/2310.15123v1"},"cats":{"benchmark":0.3468423296,"new-dataset":0.1028734304,"data-annotation":0.5244790621,"dev-research":0.1301532894,"llms":0.7316921309,"data-quality":0.1502232147}}
{"text":"BSM improves the evaluation correctness and consistency for each LLM by enhancing human-LLM agreement by up to 26%, reducing length and pairwise position biases by up to 50%, and allowing LLaMA-2-chat to match or outperform GPT-4 on most domains.","meta":{"url":"http://arxiv.org/abs/2310.15123v1"},"cats":{"benchmark":0.5107817277,"new-dataset":0.0287970515,"data-annotation":0.5039852019,"dev-research":0.1162214634,"llms":0.7509841861,"data-quality":0.1397802047}}
{"text":"On the constraint story generation task, BSM improves the coherence of the stories while also improving constraint satisfaction by 12%.","meta":{"url":"http://arxiv.org/abs/2310.15123v1"},"cats":{"benchmark":0.2887680556,"new-dataset":0.0678583411,"data-annotation":0.5138234634,"dev-research":0.2820586842,"llms":0.5715436649,"data-quality":0.0868987104}}
{"text":"At the core of causal inference lies the challenge of determining reliable causal graphs solely based on observational data.","meta":{"url":"http://arxiv.org/abs/2310.15117v1"},"cats":{"benchmark":0.3772365222,"new-dataset":0.0404378422,"data-annotation":0.4994259802,"dev-research":0.2069443878,"llms":0.4049270121,"data-quality":0.2400335381}}
{"text":"Since the well-known backdoor criterion depends on the graph, any errors in the graph can propagate downstream to effect inference.","meta":{"url":"http://arxiv.org/abs/2310.15117v1"},"cats":{"benchmark":0.3709798849,"new-dataset":0.0053652501,"data-annotation":0.5113219183,"dev-research":0.2339962593,"llms":0.4561505663,"data-quality":0.2770465389}}
{"text":"In this work, we initially show that complete graph information is not necessary for causal effect inference; the topological order over graph variables (causal order) alone suffices.","meta":{"url":"http://arxiv.org/abs/2310.15117v1"},"cats":{"benchmark":0.3047461922,"new-dataset":0.0308734787,"data-annotation":0.506744894,"dev-research":0.1831632669,"llms":0.4515261609,"data-quality":0.1303510675}}
{"text":"Further, given a node pair, causal order is easier to elicit from domain experts compared to graph edges since determining the existence of an edge can depend extensively on other variables.","meta":{"url":"http://arxiv.org/abs/2310.15117v1"},"cats":{"benchmark":0.4110563608,"new-dataset":0.004908568,"data-annotation":0.5141508356,"dev-research":0.2398382616,"llms":0.4983182443,"data-quality":0.0941219883}}
{"text":"Interestingly, we find that the same principle holds for Large Language Models (LLMs) such as GPT-3.5-turbo and GPT-4, motivating an automated method to obtain causal order (and hence causal effect) with LLMs acting as virtual domain experts.","meta":{"url":"http://arxiv.org/abs/2310.15117v1"},"cats":{"benchmark":0.2771372816,"new-dataset":0.011512527,"data-annotation":0.5387406107,"dev-research":0.203855698,"llms":0.6094885219,"data-quality":0.162622171}}
{"text":"To this end, we employ different prompting strategies and contextual cues to propose a robust technique of obtaining causal order from LLMs.","meta":{"url":"http://arxiv.org/abs/2310.15117v1"},"cats":{"benchmark":0.2427188198,"new-dataset":0.0199648749,"data-annotation":0.505349334,"dev-research":0.1804885616,"llms":0.6991832543,"data-quality":0.1362192356}}
{"text":"Acknowledging LLMs' limitations, we also study possible techniques to integrate LLMs with established causal discovery algorithms, including constraint-based and score-based methods, to enhance their performance.","meta":{"url":"http://arxiv.org/abs/2310.15117v1"},"cats":{"benchmark":0.3822466032,"new-dataset":0.027283175,"data-annotation":0.515335843,"dev-research":0.1762605535,"llms":0.613851051,"data-quality":0.1370787744}}
{"text":"Extensive experiments demonstrate that our approach significantly improves causal ordering accuracy as compared to discovery algorithms, highlighting the potential of LLMs to enhance causal inference across diverse fields.","meta":{"url":"http://arxiv.org/abs/2310.15117v1"},"cats":{"benchmark":0.4537089061,"new-dataset":0.0357417959,"data-annotation":0.5147716486,"dev-research":0.165553536,"llms":0.6054823542,"data-quality":0.1814486416}}
{"text":"Semi-supervised video object segmentation (Semi-VOS), which requires only annotating the first frame of a video to segment future frames, has received increased attention recently.","meta":{"url":"http://arxiv.org/abs/2310.15115v1"},"cats":{"benchmark":0.2674875269,"new-dataset":0.1909698565,"data-annotation":0.5220436472,"dev-research":0.1762953502,"llms":0.4958760546,"data-quality":0.2673770307}}
{"text":"Among existing pipelines, the memory-matching-based one is becoming the main research stream, as it can fully utilize the temporal sequence information to obtain high-quality segmentation results.","meta":{"url":"http://arxiv.org/abs/2310.15115v1"},"cats":{"benchmark":0.4080041369,"new-dataset":0.4105079139,"data-annotation":0.4582299347,"dev-research":0.1311282769,"llms":0.5548331745,"data-quality":0.148808352}}
{"text":"Even though this type of method has achieved promising performance, the overall framework still suffers from heavy computation overhead, mainly caused by the per-frame dense convolution operations between high-resolution feature maps and each kernel filter.","meta":{"url":"http://arxiv.org/abs/2310.15115v1"},"cats":{"benchmark":0.4686652714,"new-dataset":0.0697454707,"data-annotation":0.5134553781,"dev-research":0.1621800483,"llms":0.4039665356,"data-quality":0.1054197869}}
{"text":"Therefore, we propose a sparse baseline of VOS named SpVOS in this work, which develops a novel triple sparse convolution to reduce the computation costs of the overall VOS framework.","meta":{"url":"http://arxiv.org/abs/2310.15115v1"},"cats":{"benchmark":0.4360986092,"new-dataset":0.2267666358,"data-annotation":0.5076895432,"dev-research":0.1319724378,"llms":0.4152894467,"data-quality":0.0974528299}}
{"text":"The designed triple gate, taking full consideration of both spatial and temporal redundancy between adjacent video frames, adaptively makes a triple decision to decide how to apply the sparse convolution on each pixel to control the computation overhead of each layer, while maintaining sufficient discrimination capability to distinguish similar objects and avoid error accumulation.","meta":{"url":"http://arxiv.org/abs/2310.15115v1"},"cats":{"benchmark":0.3964272154,"new-dataset":0.0148750358,"data-annotation":0.4958026668,"dev-research":0.1581658284,"llms":0.4781581695,"data-quality":0.0862566976}}
{"text":"A mixed sparse training strategy, coupled with a designed objective considering the sparsity constraint, is also developed to balance the VOS segmentation performance and computation costs.","meta":{"url":"http://arxiv.org/abs/2310.15115v1"},"cats":{"benchmark":0.4444123927,"new-dataset":0.0311435426,"data-annotation":0.4995548718,"dev-research":0.1095711598,"llms":0.3904901545,"data-quality":0.237459056}}
{"text":"Experiments are conducted on two mainstream VOS datasets, including DAVIS and Youtube-VOS.","meta":{"url":"http://arxiv.org/abs/2310.15115v1"},"cats":{"benchmark":0.3640789722,"new-dataset":0.3915970977,"data-annotation":0.5016766732,"dev-research":0.1071269374,"llms":0.515791663,"data-quality":0.245227982}}
{"text":"Results show that, the proposed SpVOS achieves superior performance over other state-of-the-art sparse methods, and even maintains comparable performance, e.g., an 83.04% (79.29%) overall score on the DAVIS-2017 (Youtube-VOS) validation set, with the typical non-sparse VOS baseline (82.88% for DAVIS-2017 and 80.36% for Youtube-VOS) while saving up to 42% FLOPs, showing its application potential for resource-constrained scenarios.","meta":{"url":"http://arxiv.org/abs/2310.15115v1"},"cats":{"benchmark":0.608516482,"new-dataset":0.0417683786,"data-annotation":0.4990825922,"dev-research":0.1824365185,"llms":0.4966374457,"data-quality":0.1227909732}}
{"text":"When translating from notional gender languages (e.g., English) into grammatical gender languages (e.g., Italian), the generated translation requires explicit gender assignments for various words, including those referring to the speaker.","meta":{"url":"http://arxiv.org/abs/2310.15114v1"},"cats":{"benchmark":0.2257636683,"new-dataset":0.0392332905,"data-annotation":0.5539287947,"dev-research":0.213173769,"llms":0.5323497805,"data-quality":0.2682322788}}
{"text":"When the source sentence does not convey the speaker's gender, speech translation (ST) models either rely on the possibly-misleading vocal traits of the speaker or default to the masculine gender, the most frequent in existing training corpora.","meta":{"url":"http://arxiv.org/abs/2310.15114v1"},"cats":{"benchmark":0.2241098754,"new-dataset":0.0378437459,"data-annotation":0.532985456,"dev-research":0.1653583555,"llms":0.5090765389,"data-quality":0.337450042}}
{"text":"To avoid such biased and not inclusive behaviors, the gender assignment of speaker-related expressions should be guided by externally-provided metadata about the speaker's gender.","meta":{"url":"http://arxiv.org/abs/2310.15114v1"},"cats":{"benchmark":0.2606831058,"new-dataset":0.0836339222,"data-annotation":0.5504973899,"dev-research":0.1853180546,"llms":0.5403570423,"data-quality":0.2830626695}}
{"text":"While previous work has shown that the most effective solution is represented by separate, dedicated gender-specific models, the goal of this paper is to achieve the same results by integrating the speaker's gender metadata into a single \"multi-gender\" neural ST model, easier to maintain.","meta":{"url":"http://arxiv.org/abs/2310.15114v1"},"cats":{"benchmark":0.2937639,"new-dataset":0.1343636974,"data-annotation":0.5452009144,"dev-research":0.1328229172,"llms":0.484007911,"data-quality":0.2303768374}}
{"text":"Our experiments demonstrate that a single multi-gender model outperforms gender-specialized ones when trained from scratch (with gender accuracy gains up to 12.9 for feminine forms), while fine-tuning from existing ST models does not lead to competitive results.","meta":{"url":"http://arxiv.org/abs/2310.15114v1"},"cats":{"benchmark":0.3483116796,"new-dataset":0.0192809396,"data-annotation":0.5401051335,"dev-research":0.1321703112,"llms":0.4606071654,"data-quality":0.1439367937}}
{"text":"Large language models (LLMs) have recently reached an impressive level of linguistic capability, prompting comparisons with human language skills.","meta":{"url":"http://arxiv.org/abs/2310.15113v1"},"cats":{"benchmark":0.2473940919,"new-dataset":0.0286156099,"data-annotation":0.5337226059,"dev-research":0.1509248779,"llms":0.7656927881,"data-quality":0.1096476199}}
{"text":"However, there have been relatively few systematic inquiries into the linguistic capabilities of the latest generation of LLMs, and those studies that do exist (i) ignore the remarkable ability of humans to generalize, (ii) focus only on English, and (iii) investigate syntax or semantics and overlook other capabilities that lie at the heart of human language, like morphology.","meta":{"url":"http://arxiv.org/abs/2310.15113v1"},"cats":{"benchmark":0.1704198928,"new-dataset":0.0273655101,"data-annotation":0.5303735683,"dev-research":0.1723561795,"llms":0.7587681243,"data-quality":0.180218366}}
{"text":"Here, we close these gaps by conducting the first rigorous analysis of the morphological capabilities of ChatGPT in four typologically varied languages (specifically, English, German, Tamil, and Turkish).","meta":{"url":"http://arxiv.org/abs/2310.15113v1"},"cats":{"benchmark":0.2314150446,"new-dataset":0.2021301608,"data-annotation":0.5441806655,"dev-research":0.1999728483,"llms":0.5475295181,"data-quality":0.1549061759}}
{"text":"We apply a version of Berko's (1958) wug test to ChatGPT, using novel, uncontaminated datasets for the four examined languages.","meta":{"url":"http://arxiv.org/abs/2310.15113v1"},"cats":{"benchmark":0.3454216533,"new-dataset":0.6644298315,"data-annotation":0.5389691621,"dev-research":0.1797340765,"llms":0.5926053541,"data-quality":0.1953221597}}
{"text":"We find that ChatGPT massively underperforms purpose-built systems, particularly in English.","meta":{"url":"http://arxiv.org/abs/2310.15113v1"},"cats":{"benchmark":0.2945612641,"new-dataset":0.1827100846,"data-annotation":0.526498051,"dev-research":0.3413543548,"llms":0.6165907031,"data-quality":0.1494602069}}
{"text":"Overall, our results -- through the lens of morphology -- cast a new light on the linguistic capabilities of ChatGPT, suggesting that claims of human-like language skills are premature and misleading.","meta":{"url":"http://arxiv.org/abs/2310.15113v1"},"cats":{"benchmark":0.2049358711,"new-dataset":0.1449451691,"data-annotation":0.544979412,"dev-research":0.2940224764,"llms":0.5759445435,"data-quality":0.2295929883}}
{"text":"This study explores the impact of AI-generated digital self-clones on improving online presentation skills.","meta":{"url":"http://arxiv.org/abs/2310.15112v1"},"cats":{"benchmark":0.1855392978,"new-dataset":0.0494390448,"data-annotation":0.5353125748,"dev-research":0.3042958629,"llms":0.5589073621,"data-quality":0.1517192323}}
{"text":"We carried out a mixed-design experiment involving 44 international students, comparing self-recorded videos (control) with self-clone videos (AI group) for English presentation practice.","meta":{"url":"http://arxiv.org/abs/2310.15112v1"},"cats":{"benchmark":0.1763103695,"new-dataset":0.1400471911,"data-annotation":0.5189575056,"dev-research":0.2895040079,"llms":0.5967636124,"data-quality":0.1265398434}}
{"text":"The AI videos utilized voice cloning, face swapping, lip-sync, and body-language simulation to refine participants' original presentations in terms of repetition, filler words, and pronunciation.","meta":{"url":"http://arxiv.org/abs/2310.15112v1"},"cats":{"benchmark":0.2041050788,"new-dataset":0.0948320267,"data-annotation":0.522192038,"dev-research":0.2385544629,"llms":0.5037919381,"data-quality":0.1420175206}}
{"text":"Machine-rated scores indicated enhancements in speech performance for both groups.","meta":{"url":"http://arxiv.org/abs/2310.15112v1"},"cats":{"benchmark":0.6184485571,"new-dataset":0.0125857877,"data-annotation":0.5141273994,"dev-research":0.182861297,"llms":0.5161037796,"data-quality":0.1587605127}}
{"text":"Though the groups didn't significantly differ, the AI group exhibited a heightened depth of reflection, self-compassion, and a meaningful transition from a corrective to an enhancive approach to self-critique.","meta":{"url":"http://arxiv.org/abs/2310.15112v1"},"cats":{"benchmark":0.2414388033,"new-dataset":0.0230260347,"data-annotation":0.5247849935,"dev-research":0.2037038317,"llms":0.5227722126,"data-quality":0.103274838}}
{"text":"Within the AI group, congruence between self-perception and AI self-clones resulted in diminished speech anxiety and increased enjoyment.","meta":{"url":"http://arxiv.org/abs/2310.15112v1"},"cats":{"benchmark":0.2186140465,"new-dataset":0.021511641,"data-annotation":0.5328880452,"dev-research":0.217793671,"llms":0.5081068661,"data-quality":0.1827259027}}
{"text":"Our findings recommend the ethical employment of digital self-clones to enhance the emotional and cognitive facets of skill development.","meta":{"url":"http://arxiv.org/abs/2310.15112v1"},"cats":{"benchmark":0.1534585241,"new-dataset":0.0535719468,"data-annotation":0.5035851391,"dev-research":0.3434063769,"llms":0.5863260618,"data-quality":0.1451202645}}
{"text":"Diffusion models are the de facto approach for generating high-quality images and videos, but learning high-dimensional models remains a formidable task due to computational and optimization challenges.","meta":{"url":"http://arxiv.org/abs/2310.15111v1"},"cats":{"benchmark":0.3010951238,"new-dataset":0.0663349324,"data-annotation":0.5108172097,"dev-research":0.1182200795,"llms":0.4372193474,"data-quality":0.0737887576}}
{"text":"Existing methods often resort to training cascaded models in pixel space or using a downsampled latent space of a separately trained auto-encoder.","meta":{"url":"http://arxiv.org/abs/2310.15111v1"},"cats":{"benchmark":0.3004524554,"new-dataset":0.0317612488,"data-annotation":0.5209339719,"dev-research":0.1403519272,"llms":0.4605945947,"data-quality":0.1670216038}}
{"text":"In this paper, we introduce Matryoshka Diffusion Models(MDM), an end-to-end framework for high-resolution image and video synthesis.","meta":{"url":"http://arxiv.org/abs/2310.15111v1"},"cats":{"benchmark":0.3392729662,"new-dataset":0.1704403881,"data-annotation":0.4926256233,"dev-research":0.1236640732,"llms":0.4632110433,"data-quality":0.0632489223}}
{"text":"We propose a diffusion process that denoises inputs at multiple resolutions jointly and uses a NestedUNet architecture where features and parameters for small-scale inputs are nested within those of large scales.","meta":{"url":"http://arxiv.org/abs/2310.15111v1"},"cats":{"benchmark":0.4442580664,"new-dataset":0.03976191,"data-annotation":0.4932871654,"dev-research":0.1541789493,"llms":0.3748862948,"data-quality":0.138629113}}
{"text":"In addition, MDM enables a progressive training schedule from lower to higher resolutions, which leads to significant improvements in optimization for high-resolution generation.","meta":{"url":"http://arxiv.org/abs/2310.15111v1"},"cats":{"benchmark":0.3275432708,"new-dataset":0.0311701862,"data-annotation":0.4852813225,"dev-research":0.154490504,"llms":0.6060016737,"data-quality":0.0592903163}}
{"text":"We demonstrate the effectiveness of our approach on various benchmarks, including class-conditioned image generation, high-resolution text-to-image, and text-to-video applications.","meta":{"url":"http://arxiv.org/abs/2310.15111v1"},"cats":{"benchmark":0.5436563148,"new-dataset":0.2101901853,"data-annotation":0.5207325094,"dev-research":0.1885664891,"llms":0.5072345143,"data-quality":0.1609130157}}
{"text":"Remarkably, we can train a single pixel-space model at resolutions of up to 1024x1024 pixels, demonstrating strong zero-shot generalization using the CC12M dataset, which contains only 12 million images.","meta":{"url":"http://arxiv.org/abs/2310.15111v1"},"cats":{"benchmark":0.193706281,"new-dataset":0.545831907,"data-annotation":0.5086821439,"dev-research":0.0958034951,"llms":0.5053485925,"data-quality":0.1284980827}}
{"text":"We report Zero123++, an image-conditioned diffusion model for generating 3D-consistent multi-view images from a single input view.","meta":{"url":"http://arxiv.org/abs/2310.15110v1"},"cats":{"benchmark":0.3042998273,"new-dataset":0.1898792692,"data-annotation":0.5018061614,"dev-research":0.1207267406,"llms":0.4222032643,"data-quality":0.0808917685}}
{"text":"To take full advantage of pretrained 2D generative priors, we develop various conditioning and training schemes to minimize the effort of finetuning from off-the-shelf image diffusion models such as Stable Diffusion.","meta":{"url":"http://arxiv.org/abs/2310.15110v1"},"cats":{"benchmark":0.3044536741,"new-dataset":0.0482899351,"data-annotation":0.5056865787,"dev-research":0.1405249887,"llms":0.5018666259,"data-quality":0.0834219972}}
{"text":"Zero123++ excels in producing high-quality, consistent multi-view images from a single image, overcoming common issues like texture degradation and geometric misalignment.","meta":{"url":"http://arxiv.org/abs/2310.15110v1"},"cats":{"benchmark":0.2831072967,"new-dataset":0.3909703805,"data-annotation":0.5102517267,"dev-research":0.1902314916,"llms":0.4483391885,"data-quality":0.1361226179}}
{"text":"Furthermore, we showcase the feasibility of training a ControlNet on Zero123++ for enhanced control over the generation process.","meta":{"url":"http://arxiv.org/abs/2310.15110v1"},"cats":{"benchmark":0.1572840408,"new-dataset":0.1797159065,"data-annotation":0.5108740885,"dev-research":0.2217512658,"llms":0.5680610798,"data-quality":0.1216781121}}
{"text":"The code is available at https://github.com/SUDO-AI-3D/zero123plus.","meta":{"url":"http://arxiv.org/abs/2310.15110v1"},"cats":{"benchmark":0.2440916635,"new-dataset":0.2907050458,"data-annotation":0.5418196198,"dev-research":0.1457920805,"llms":0.4961438595,"data-quality":0.1064863138}}
{"text":"Self-supervised representation learning on text-attributed graphs, which aims to create expressive and generalizable representations for various downstream tasks, has received increasing research attention lately.","meta":{"url":"http://arxiv.org/abs/2310.15109v1"},"cats":{"benchmark":0.2077994526,"new-dataset":0.085373694,"data-annotation":0.5358793679,"dev-research":0.1928256468,"llms":0.5199011754,"data-quality":0.346853802}}
{"text":"However, existing methods either struggle to capture the full extent of structural context information or rely on task-specific training labels, which largely hampers their effectiveness and generalizability in practice.","meta":{"url":"http://arxiv.org/abs/2310.15109v1"},"cats":{"benchmark":0.3256136633,"new-dataset":0.0056387921,"data-annotation":0.5254037122,"dev-research":0.1901010963,"llms":0.4961554521,"data-quality":0.2331190588}}
{"text":"To solve the problem of self-supervised representation learning on text-attributed graphs, we develop a novel Graph-Centric Language model -- GRENADE.","meta":{"url":"http://arxiv.org/abs/2310.15109v1"},"cats":{"benchmark":0.2020812428,"new-dataset":0.2150343429,"data-annotation":0.5570582157,"dev-research":0.1897826378,"llms":0.5231028676,"data-quality":0.4519550439}}
{"text":"Specifically, GRENADE exploits the synergistic effect of both pre-trained language model and graph neural network by optimizing with two specialized self-supervised learning algorithms: graph-centric contrastive learning and graph-centric knowledge alignment.","meta":{"url":"http://arxiv.org/abs/2310.15109v1"},"cats":{"benchmark":0.2384373316,"new-dataset":0.0287558366,"data-annotation":0.5561455393,"dev-research":0.184835387,"llms":0.5355827408,"data-quality":0.2503776893}}
{"text":"The proposed graph-centric self-supervised learning algorithms effectively help GRENADE to capture informative textual semantics as well as structural context information on text-attributed graphs.","meta":{"url":"http://arxiv.org/abs/2310.15109v1"},"cats":{"benchmark":0.2431604949,"new-dataset":0.0962458015,"data-annotation":0.5508404474,"dev-research":0.1543177378,"llms":0.5231319096,"data-quality":0.4545533585}}
{"text":"Through extensive experiments, GRENADE shows its superiority over state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2310.15109v1"},"cats":{"benchmark":0.4964412581,"new-dataset":0.0037500063,"data-annotation":0.5359437706,"dev-research":0.2102163476,"llms":0.5456826948,"data-quality":0.0964984953}}
{"text":"Implementation is available at \\url{https://github.com/bigheiniu/GRENADE}.","meta":{"url":"http://arxiv.org/abs/2310.15109v1"},"cats":{"benchmark":0.3132526629,"new-dataset":0.0167433372,"data-annotation":0.5252700927,"dev-research":0.1585562615,"llms":0.5724316708,"data-quality":0.1152227837}}
{"text":"Radio map estimation (RME) aims at providing a radiofrequency metric, such as the received power strength, at every location of a geographical region of interest by relying on measurements acquired at multiple positions.","meta":{"url":"http://arxiv.org/abs/2310.15106v1"},"cats":{"benchmark":0.447990868,"new-dataset":0.0355196205,"data-annotation":0.5069821529,"dev-research":0.1634659489,"llms":0.4457951478,"data-quality":0.1156363308}}
{"text":"Although a large number of estimators have been proposed so far, their performance has been analyzed mostly on simulated data.","meta":{"url":"http://arxiv.org/abs/2310.15106v1"},"cats":{"benchmark":0.6255045794,"new-dataset":0.0652217594,"data-annotation":0.5228859758,"dev-research":0.1409355261,"llms":0.3716662601,"data-quality":0.0948979101}}
{"text":"The theoretical aspects of the RME problem as well as performance bounds remain an open problem.","meta":{"url":"http://arxiv.org/abs/2310.15106v1"},"cats":{"benchmark":0.5485529344,"new-dataset":0.0147399277,"data-annotation":0.5337891428,"dev-research":0.1400931523,"llms":0.4654551562,"data-quality":0.1094992444}}
{"text":"This paper takes a step towards filling this gap by means of a theoretical analysis of the RME problem in a free-space propagation environment.","meta":{"url":"http://arxiv.org/abs/2310.15106v1"},"cats":{"benchmark":0.4293103528,"new-dataset":0.0221468941,"data-annotation":0.5232020953,"dev-research":0.1315549231,"llms":0.4638666896,"data-quality":0.1300868547}}
{"text":"First, the complexity of the estimation problem is quantified by means of upper bounds on the spatial variability of radio maps.","meta":{"url":"http://arxiv.org/abs/2310.15106v1"},"cats":{"benchmark":0.4274002025,"new-dataset":0.0449230946,"data-annotation":0.5374078051,"dev-research":0.1356639396,"llms":0.4104640078,"data-quality":0.1176656718}}
{"text":"Second, error bounds are derived for zeroth-order and first-order interpolation estimators.","meta":{"url":"http://arxiv.org/abs/2310.15106v1"},"cats":{"benchmark":0.5836113177,"new-dataset":0.0570193263,"data-annotation":0.5256641513,"dev-research":0.13419874,"llms":0.3422472095,"data-quality":0.1927740711}}
{"text":"The proximity coefficient, which depends proportionally on the transmitted power and inversely proportionally on the cube of the distance from the transmitters to the mapped region, is proposed to quantify the complexity of the RME problem.","meta":{"url":"http://arxiv.org/abs/2310.15106v1"},"cats":{"benchmark":0.4816119678,"new-dataset":0.0135961586,"data-annotation":0.5260791381,"dev-research":0.1421632888,"llms":0.4610953805,"data-quality":0.1021925113}}
{"text":"One of the main findings is that the error of the considered estimators is roughly proportional to this proximity coefficient.","meta":{"url":"http://arxiv.org/abs/2310.15106v1"},"cats":{"benchmark":0.5855359012,"new-dataset":0.0110477494,"data-annotation":0.5359098378,"dev-research":0.1939336903,"llms":0.377474674,"data-quality":0.1768249661}}
{"text":"Simple numerical experiments verify the tightness of the obtained bounds.","meta":{"url":"http://arxiv.org/abs/2310.15106v1"},"cats":{"benchmark":0.5106439376,"new-dataset":0.0181970611,"data-annotation":0.5369700743,"dev-research":0.1483839342,"llms":0.4704379897,"data-quality":0.1646983141}}
{"text":"Due to the limited availability of data, existing few-shot learning methods trained from scratch fail to achieve satisfactory performance.","meta":{"url":"http://arxiv.org/abs/2310.15105v1"},"cats":{"benchmark":0.2887246784,"new-dataset":0.0814074434,"data-annotation":0.5304523538,"dev-research":0.1687058506,"llms":0.500304011,"data-quality":0.1669395303}}
{"text":"In contrast, large-scale pre-trained models such as CLIP demonstrate remarkable few-shot and zero-shot capabilities.","meta":{"url":"http://arxiv.org/abs/2310.15105v1"},"cats":{"benchmark":0.2355611606,"new-dataset":0.0692205358,"data-annotation":0.5253729704,"dev-research":0.1218263758,"llms":0.4876600114,"data-quality":0.0676289708}}
{"text":"To enhance the performance of pre-trained models for downstream tasks, fine-tuning the model on downstream data is frequently necessary.","meta":{"url":"http://arxiv.org/abs/2310.15105v1"},"cats":{"benchmark":0.3488257045,"new-dataset":0.0444836144,"data-annotation":0.4931397518,"dev-research":0.1959819426,"llms":0.4417773987,"data-quality":0.1044382178}}
{"text":"However, fine-tuning the pre-trained model leads to a decrease in its generalizability in the presence of distribution shift, while the limited number of samples in few-shot learning makes the model highly susceptible to overfitting.","meta":{"url":"http://arxiv.org/abs/2310.15105v1"},"cats":{"benchmark":0.3045275802,"new-dataset":0.0152799295,"data-annotation":0.5318468179,"dev-research":0.1514430815,"llms":0.494440221,"data-quality":0.1289621651}}
{"text":"Consequently, existing methods for fine-tuning few-shot learning primarily focus on fine-tuning the model's classification head or introducing additional structure.","meta":{"url":"http://arxiv.org/abs/2310.15105v1"},"cats":{"benchmark":0.3547289015,"new-dataset":0.0227131071,"data-annotation":0.5325733778,"dev-research":0.1648254027,"llms":0.5219721001,"data-quality":0.1704091956}}
{"text":"In this paper, we introduce a fine-tuning approach termed Feature Discrimination Alignment (FD-Align).","meta":{"url":"http://arxiv.org/abs/2310.15105v1"},"cats":{"benchmark":0.5116659313,"new-dataset":0.0923861275,"data-annotation":0.4995969297,"dev-research":0.2719045315,"llms":0.4194200414,"data-quality":0.3961366832}}
{"text":"Our method aims to bolster the model's generalizability by preserving the consistency of spurious features across the fine-tuning process.","meta":{"url":"http://arxiv.org/abs/2310.15105v1"},"cats":{"benchmark":0.431907236,"new-dataset":0.00595333,"data-annotation":0.5097871994,"dev-research":0.2235267618,"llms":0.4022809722,"data-quality":0.3287609214}}
{"text":"Extensive experimental results validate the efficacy of our approach for both ID and OOD tasks.","meta":{"url":"http://arxiv.org/abs/2310.15105v1"},"cats":{"benchmark":0.5196102133,"new-dataset":0.0099416825,"data-annotation":0.482253166,"dev-research":0.194300453,"llms":0.5164413537,"data-quality":0.1081706019}}
{"text":"Once fine-tuned, the model can seamlessly integrate with existing methods, leading to performance improvements.","meta":{"url":"http://arxiv.org/abs/2310.15105v1"},"cats":{"benchmark":0.567802279,"new-dataset":0.0041988875,"data-annotation":0.5111453745,"dev-research":0.2335880914,"llms":0.4749360964,"data-quality":0.0627206548}}
{"text":"Our code can be found in https://github.com/skingorz/FD-Align.","meta":{"url":"http://arxiv.org/abs/2310.15105v1"},"cats":{"benchmark":0.5386476764,"new-dataset":0.2098206014,"data-annotation":0.5185712112,"dev-research":0.1711280318,"llms":0.4562517912,"data-quality":0.1165265186}}
{"text":"Thematic analysis (TA) has been widely used for analyzing qualitative data in many disciplines and fields.","meta":{"url":"http://arxiv.org/abs/2310.15100v1"},"cats":{"benchmark":0.2331641403,"new-dataset":0.0934044379,"data-annotation":0.4803440754,"dev-research":0.3102584183,"llms":0.5267154997,"data-quality":0.0808145679}}
{"text":"To ensure reliable analysis, the same piece of data is typically assigned to at least two human coders.","meta":{"url":"http://arxiv.org/abs/2310.15100v1"},"cats":{"benchmark":0.4185894435,"new-dataset":0.0814816426,"data-annotation":0.4882509122,"dev-research":0.3625648599,"llms":0.4874371195,"data-quality":0.2267533167}}
{"text":"Moreover, to produce meaningful and useful analysis, human coders develop and deepen their data interpretation and coding over multiple iterations, making TA labor-intensive and time-consuming.","meta":{"url":"http://arxiv.org/abs/2310.15100v1"},"cats":{"benchmark":0.2807506471,"new-dataset":0.1467301786,"data-annotation":0.5242492965,"dev-research":0.5047675251,"llms":0.4991686189,"data-quality":0.1243136573}}
{"text":"Recently the emerging field of large language models (LLMs) research has shown that LLMs have the potential replicate human-like behavior in various tasks: in particular, LLMs outperform crowd workers on text-annotation tasks, suggesting an opportunity to leverage LLMs on TA.","meta":{"url":"http://arxiv.org/abs/2310.15100v1"},"cats":{"benchmark":0.2370069505,"new-dataset":0.2338968728,"data-annotation":0.542565025,"dev-research":0.2354895965,"llms":0.6737047297,"data-quality":0.2488278805}}
{"text":"We propose a human-LLM collaboration framework (i.e., LLM-in-the-loop) to conduct TA with in-context learning (ICL).","meta":{"url":"http://arxiv.org/abs/2310.15100v1"},"cats":{"benchmark":0.1712351476,"new-dataset":0.2205971141,"data-annotation":0.5024546583,"dev-research":0.2445918122,"llms":0.6824069926,"data-quality":0.131597333}}
{"text":"This framework provides the prompt to frame discussions with a LLM (e.g., GPT-3.5) to generate the final codebook for TA.","meta":{"url":"http://arxiv.org/abs/2310.15100v1"},"cats":{"benchmark":0.1984143277,"new-dataset":0.4136444316,"data-annotation":0.5176119352,"dev-research":0.2490897443,"llms":0.670544816,"data-quality":0.1080057893}}
{"text":"We demonstrate the utility of this framework using survey datasets on the aspects of the music listening experience and the usage of a password manager.","meta":{"url":"http://arxiv.org/abs/2310.15100v1"},"cats":{"benchmark":0.3077116904,"new-dataset":0.2056020311,"data-annotation":0.5019959096,"dev-research":0.1748619897,"llms":0.4992521692,"data-quality":0.1491304002}}
{"text":"Results of the two case studies show that the proposed framework yields similar coding quality to that of human coders but reduces TA's labor and time demands.","meta":{"url":"http://arxiv.org/abs/2310.15100v1"},"cats":{"benchmark":0.350617486,"new-dataset":0.0243719904,"data-annotation":0.5115562138,"dev-research":0.43880508,"llms":0.5142801907,"data-quality":0.1415793971}}
{"text":"Breast cancer molecular subtypes classification plays an import role to sort patients with divergent prognosis.","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.3771567005,"new-dataset":0.0390315406,"data-annotation":0.5218376864,"dev-research":0.2339780601,"llms":0.5059372112,"data-quality":0.1576653161}}
{"text":"The biomarkers used are Estrogen Receptor (ER), Progesterone Receptor (PR), HER2, and Ki67.","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.4673100858,"new-dataset":0.2790354642,"data-annotation":0.5107227108,"dev-research":0.1636569217,"llms":0.4505203984,"data-quality":0.1834565004}}
{"text":"Based on these biomarkers expression levels, subtypes are classified as Luminal A (LA), Luminal B (LB), HER2 subtype, and Triple-Negative Breast Cancer (TNBC).","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.3989517776,"new-dataset":0.1926651015,"data-annotation":0.5166003891,"dev-research":0.157348048,"llms":0.4908343707,"data-quality":0.1451090205}}
{"text":"Immunohistochemistry is used to classify subtypes, although interlaboratory and interobserver variations can affect its accuracy, besides being a time-consuming technique.","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.4642183242,"new-dataset":0.0104650119,"data-annotation":0.5272208561,"dev-research":0.1809059964,"llms":0.5378761864,"data-quality":0.1854702737}}
{"text":"The Fourier transform infrared micro-spectroscopy may be coupled with deep learning for cancer evaluation, where there is still a lack of studies for subtypes and biomarker levels prediction.","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.3708752535,"new-dataset":0.1147739972,"data-annotation":0.5065711763,"dev-research":0.1615255284,"llms":0.4458763119,"data-quality":0.1172878838}}
{"text":"This study presents a novel 2D deep learning approach to achieve these predictions.","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.2961933387,"new-dataset":0.2205089575,"data-annotation":0.5251237424,"dev-research":0.1531623937,"llms":0.3672855997,"data-quality":0.0779680297}}
{"text":"Sixty micro-FTIR images of 320x320 pixels were collected from a human breast biopsies microarray.","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.2897709351,"new-dataset":0.3415721515,"data-annotation":0.4785929884,"dev-research":0.158197001,"llms":0.4634185127,"data-quality":0.1026119393}}
{"text":"Data were clustered by K-means, preprocessed and 32x32 patches were generated using a fully automated approach.","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.3664619133,"new-dataset":0.6817637492,"data-annotation":0.489890511,"dev-research":0.3713523431,"llms":0.4961628596,"data-quality":0.1784905729}}
{"text":"CaReNet-V2, a novel convolutional neural network, was developed to classify breast cancer (CA) vs adjacent tissue (AT) and molecular subtypes, and to predict biomarkers level.","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.3465048897,"new-dataset":0.1791937494,"data-annotation":0.5278777675,"dev-research":0.1955968394,"llms":0.4326246724,"data-quality":0.1789614588}}
{"text":"The clustering method enabled to remove non-tissue pixels.","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.4366983714,"new-dataset":0.0284024998,"data-annotation":0.5055917129,"dev-research":0.1611206257,"llms":0.452888719,"data-quality":0.1119254419}}
{"text":"Test accuracies for CA vs AT and subtype were above 0.84.","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.5882729681,"new-dataset":0.0237812373,"data-annotation":0.5303757871,"dev-research":0.1473263722,"llms":0.5091246482,"data-quality":0.1678632154}}
{"text":"The model enabled the prediction of ER, PR, and HER2 levels, where borderline values showed lower performance (minimum accuracy of 0.54).","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.5797513026,"new-dataset":0.0331749152,"data-annotation":0.5345338238,"dev-research":0.2026159749,"llms":0.4193972707,"data-quality":0.1597862788}}
{"text":"Ki67 percentage regression demonstrated a mean error of 3.6%.","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.4624721286,"new-dataset":0.0426184276,"data-annotation":0.5137339743,"dev-research":0.2207164058,"llms":0.3743988447,"data-quality":0.2360582865}}
{"text":"Thus, CaReNet-V2 is a potential technique for breast cancer biopsies evaluation, standing out as a screening analysis technique and helping to prioritize patients.","meta":{"url":"http://arxiv.org/abs/2310.15099v1"},"cats":{"benchmark":0.3905987936,"new-dataset":0.023201996,"data-annotation":0.5230604921,"dev-research":0.2721894997,"llms":0.4949498433,"data-quality":0.1493808536}}
{"text":"Creating large-scale and well-annotated datasets to train AI algorithms is crucial for automated tumor detection and localization.","meta":{"url":"http://arxiv.org/abs/2310.15098v1"},"cats":{"benchmark":0.274416951,"new-dataset":0.6829347193,"data-annotation":0.5355278838,"dev-research":0.1612446274,"llms":0.4625154011,"data-quality":0.2729989733}}
{"text":"However, with limited resources, it is challenging to determine the best type of annotations when annotating massive amounts of unlabeled data.","meta":{"url":"http://arxiv.org/abs/2310.15098v1"},"cats":{"benchmark":0.4066067207,"new-dataset":0.2770649389,"data-annotation":0.5554370833,"dev-research":0.2421287866,"llms":0.5511897364,"data-quality":0.6443971385}}
{"text":"To address this issue, we focus on polyps in colonoscopy videos and pancreatic tumors in abdominal CT scans; both applications require significant effort and time for pixel-wise annotation due to the high dimensional nature of the data, involving either temporary or spatial dimensions.","meta":{"url":"http://arxiv.org/abs/2310.15098v1"},"cats":{"benchmark":0.336970831,"new-dataset":0.3514730448,"data-annotation":0.5175310515,"dev-research":0.1586140161,"llms":0.4453792893,"data-quality":0.1357445844}}
{"text":"In this paper, we develop a new annotation strategy, termed Drag&Drop, which simplifies the annotation process to drag and drop.","meta":{"url":"http://arxiv.org/abs/2310.15098v1"},"cats":{"benchmark":0.3269640906,"new-dataset":0.1140704617,"data-annotation":0.5407319437,"dev-research":0.4076259127,"llms":0.5515173166,"data-quality":0.3826256182}}
{"text":"This annotation strategy is more efficient, particularly for temporal and volumetric imaging, than other types of weak annotations, such as per-pixel, bounding boxes, scribbles, ellipses, and points.","meta":{"url":"http://arxiv.org/abs/2310.15098v1"},"cats":{"benchmark":0.3717729286,"new-dataset":0.0822644452,"data-annotation":0.536807216,"dev-research":0.2034635194,"llms":0.4951218489,"data-quality":0.2750140884}}
{"text":"Furthermore, to exploit our Drag&Drop annotations, we develop a novel weakly supervised learning method based on the watershed algorithm.","meta":{"url":"http://arxiv.org/abs/2310.15098v1"},"cats":{"benchmark":0.3728334838,"new-dataset":0.1286988263,"data-annotation":0.5155949016,"dev-research":0.1686044705,"llms":0.4486063637,"data-quality":0.3544616467}}
{"text":"Experimental results show that our method achieves better detection and localization performance than alternative weak annotations and, more importantly, achieves similar performance to that trained on detailed per-pixel annotations.","meta":{"url":"http://arxiv.org/abs/2310.15098v1"},"cats":{"benchmark":0.352296579,"new-dataset":0.2147399213,"data-annotation":0.5714542082,"dev-research":0.2220775033,"llms":0.5429116755,"data-quality":0.5988168393}}
{"text":"Interestingly, we find that, with limited resources, allocating weak annotations from a diverse patient population can foster models more robust to unseen images than allocating per-pixel annotations for a small set of images.","meta":{"url":"http://arxiv.org/abs/2310.15098v1"},"cats":{"benchmark":0.2558550529,"new-dataset":0.2260349226,"data-annotation":0.5323802828,"dev-research":0.1769360942,"llms":0.4872600356,"data-quality":0.353444655}}
{"text":"In summary, this research proposes an efficient annotation strategy for tumor detection and localization that is less accurate than per-pixel annotations but useful for creating large-scale datasets for screening tumors in various medical modalities.","meta":{"url":"http://arxiv.org/abs/2310.15098v1"},"cats":{"benchmark":0.3583282619,"new-dataset":0.6697681738,"data-annotation":0.5427890609,"dev-research":0.214900644,"llms":0.4749464672,"data-quality":0.3485402553}}
{"text":"Increases in the deployment of machine learning algorithms for applications that deal with sensitive data have brought attention to the issue of fairness in machine learning.","meta":{"url":"http://arxiv.org/abs/2310.15097v1"},"cats":{"benchmark":0.4350544433,"new-dataset":0.0130509543,"data-annotation":0.5022188386,"dev-research":0.1811554271,"llms":0.4988047277,"data-quality":0.2538982253}}
{"text":"Many works have been devoted to applications that require different demographic groups to be treated fairly.","meta":{"url":"http://arxiv.org/abs/2310.15097v1"},"cats":{"benchmark":0.3450120876,"new-dataset":0.009248249,"data-annotation":0.5214657298,"dev-research":0.2367408004,"llms":0.5608792769,"data-quality":0.0882708048}}
{"text":"However, algorithms that aim to satisfy inter-group fairness (also called group fairness) may inadvertently treat individuals within the same demographic group unfairly.","meta":{"url":"http://arxiv.org/abs/2310.15097v1"},"cats":{"benchmark":0.4765880426,"new-dataset":0.003254319,"data-annotation":0.5096297044,"dev-research":0.2293613468,"llms":0.5173549555,"data-quality":0.1783667155}}
{"text":"To address this issue, we introduce a formal definition of within-group fairness that maintains fairness among individuals from within the same group.","meta":{"url":"http://arxiv.org/abs/2310.15097v1"},"cats":{"benchmark":0.4769894571,"new-dataset":0.0183540831,"data-annotation":0.5062470879,"dev-research":0.1981290541,"llms":0.5321054813,"data-quality":0.1528128001}}
{"text":"We propose a pre-processing framework to meet both inter- and within-group fairness criteria with little compromise in accuracy.","meta":{"url":"http://arxiv.org/abs/2310.15097v1"},"cats":{"benchmark":0.610093572,"new-dataset":0.013267609,"data-annotation":0.5054163016,"dev-research":0.1612651211,"llms":0.4991035129,"data-quality":0.1414996299}}
{"text":"The framework maps the feature vectors of members from different groups to an inter-group-fair canonical domain before feeding them into a scoring function.","meta":{"url":"http://arxiv.org/abs/2310.15097v1"},"cats":{"benchmark":0.4555587133,"new-dataset":0.0626109333,"data-annotation":0.5251888914,"dev-research":0.1628987032,"llms":0.4430554714,"data-quality":0.1707359096}}
{"text":"The mapping is constructed to preserve the relative relationship between the scores obtained from the unprocessed feature vectors of individuals from the same demographic group, guaranteeing within-group fairness.","meta":{"url":"http://arxiv.org/abs/2310.15097v1"},"cats":{"benchmark":0.5295159053,"new-dataset":0.0244119609,"data-annotation":0.5030489123,"dev-research":0.1759848165,"llms":0.4379260486,"data-quality":0.1275329931}}
{"text":"We apply this framework to the COMPAS risk assessment and Law School datasets and compare its performance in achieving inter-group and within-group fairness to two regularization-based methods.","meta":{"url":"http://arxiv.org/abs/2310.15097v1"},"cats":{"benchmark":0.5832972772,"new-dataset":0.1055572338,"data-annotation":0.5108480847,"dev-research":0.1653664795,"llms":0.4535143175,"data-quality":0.2044934465}}
{"text":"Breast cancer treatment still remains a challenge, where molecular subtypes classification plays a crucial role in selecting appropriate and specific therapy.","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.3579554675,"new-dataset":0.0179064209,"data-annotation":0.5052457325,"dev-research":0.2171346255,"llms":0.5204297157,"data-quality":0.1339346113}}
{"text":"The four subtypes are Luminal A (LA), Luminal B (LB), HER2 subtype, and Triple-Negative Breast Cancer (TNBC).","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.296445079,"new-dataset":0.2397734868,"data-annotation":0.5285960343,"dev-research":0.1288856804,"llms":0.507023493,"data-quality":0.1057330881}}
{"text":"Immunohistochemistry is the gold-standard evaluation, although interobserver variations are reported and molecular signatures identification is time-consuming.","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.5675484439,"new-dataset":0.0525917449,"data-annotation":0.5076684041,"dev-research":0.1190452621,"llms":0.5530198127,"data-quality":0.1628926869}}
{"text":"Fourier transform infrared micro-spectroscopy with machine learning approaches have been used to evaluate cancer samples, presenting biochemical-related explainability.","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.365689803,"new-dataset":0.0557545697,"data-annotation":0.5028421332,"dev-research":0.1627502324,"llms":0.4174350731,"data-quality":0.1327770826}}
{"text":"However, this explainability is harder when using deep learning.","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.3123951976,"new-dataset":0.0017222401,"data-annotation":0.5425234676,"dev-research":0.2384822781,"llms":0.4381995778,"data-quality":0.2063277861}}
{"text":"This study created a 1D deep learning tool for breast cancer subtype evaluation and biochemical contribution.","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.3280818705,"new-dataset":0.1632669925,"data-annotation":0.5176626013,"dev-research":0.18825834,"llms":0.4592322884,"data-quality":0.1436071207}}
{"text":"Sixty hyperspectral images were acquired from a human breast cancer microarray.","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.2703984759,"new-dataset":0.2789898524,"data-annotation":0.4908833075,"dev-research":0.1685119919,"llms":0.461672117,"data-quality":0.1081023376}}
{"text":"K-Means clustering was applied to select tissue and paraffin spectra.","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.4407237405,"new-dataset":0.0487533701,"data-annotation":0.5006986933,"dev-research":0.1406686785,"llms":0.4479334489,"data-quality":0.0867471429}}
{"text":"CaReNet-V1, a novel 1D convolutional neural network, was developed to classify breast cancer (CA) and adjacent tissue (AT), and molecular subtypes.","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.2721525701,"new-dataset":0.2044769238,"data-annotation":0.5174495076,"dev-research":0.169458155,"llms":0.4524977906,"data-quality":0.1320962277}}
{"text":"A 1D adaptation of Grad-CAM was applied to assess the biochemical impact to the classifications.","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.5133649975,"new-dataset":0.068945729,"data-annotation":0.5003249135,"dev-research":0.1982136754,"llms":0.4884480093,"data-quality":0.1776690951}}
{"text":"CaReNet-V1 effectively classified CA and AT (test accuracy of 0.89), as well as HER2 and TNBC subtypes (0.83 and 0.86), with greater difficulty for LA and LB (0.74 and 0.68).","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.5764902856,"new-dataset":0.0262463605,"data-annotation":0.5338058333,"dev-research":0.1309739485,"llms":0.5122960139,"data-quality":0.1797202546}}
{"text":"The model enabled the evaluation of the most contributing wavenumbers to the predictions, providing a direct relationship with the biochemical content.","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.4693234851,"new-dataset":0.0487501537,"data-annotation":0.5110738717,"dev-research":0.1410331808,"llms":0.406371607,"data-quality":0.0770203843}}
{"text":"Therefore, CaReNet-V1 and hyperspectral images is a potential approach for breast cancer biopsies assessment, providing additional information to the pathology report.","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.3326198755,"new-dataset":0.0731534173,"data-annotation":0.4999276037,"dev-research":0.1788568347,"llms":0.4567625489,"data-quality":0.1351688761}}
{"text":"Biochemical content impact feature may be used for other studies, such as treatment efficacy evaluation and development new diagnostics and therapeutic methods.","meta":{"url":"http://arxiv.org/abs/2310.15094v1"},"cats":{"benchmark":0.4839341486,"new-dataset":0.0266547469,"data-annotation":0.4867942081,"dev-research":0.2535103909,"llms":0.47931584,"data-quality":0.1464240917}}
{"text":"Image scaling is an integral part of machine learning and computer vision systems.","meta":{"url":"http://arxiv.org/abs/2310.15085v1"},"cats":{"benchmark":0.36180415,"new-dataset":0.0117227026,"data-annotation":0.5013489396,"dev-research":0.1580085401,"llms":0.3808263913,"data-quality":0.1121611454}}
{"text":"Unfortunately, this preprocessing step is vulnerable to so-called image-scaling attacks where an attacker makes unnoticeable changes to an image so that it becomes a new image after scaling.","meta":{"url":"http://arxiv.org/abs/2310.15085v1"},"cats":{"benchmark":0.3278851661,"new-dataset":0.0251309979,"data-annotation":0.4985098738,"dev-research":0.2261262852,"llms":0.4942396323,"data-quality":0.1743212914}}
{"text":"This opens up new ways for attackers to control the prediction or to improve poisoning and backdoor attacks.","meta":{"url":"http://arxiv.org/abs/2310.15085v1"},"cats":{"benchmark":0.2329239256,"new-dataset":0.0170058255,"data-annotation":0.5332295684,"dev-research":0.2907545055,"llms":0.4989613636,"data-quality":0.0913250931}}
{"text":"While effective techniques exist to prevent scaling attacks, their detection has not been rigorously studied yet.","meta":{"url":"http://arxiv.org/abs/2310.15085v1"},"cats":{"benchmark":0.5251860925,"new-dataset":0.0021663706,"data-annotation":0.5224446002,"dev-research":0.1507134861,"llms":0.5341712951,"data-quality":0.1835286852}}
{"text":"Consequently, it is currently not possible to reliably spot these attacks in practice.   ","meta":{"url":"http://arxiv.org/abs/2310.15085v1"},"cats":{"benchmark":0.3482635836,"new-dataset":0.0110972685,"data-annotation":0.531757484,"dev-research":0.2154354133,"llms":0.5536302126,"data-quality":0.2339011855}}
{"text":"This paper presents the first in-depth systematization and analysis of detection methods for image-scaling attacks.","meta":{"url":"http://arxiv.org/abs/2310.15085v1"},"cats":{"benchmark":0.4149254534,"new-dataset":0.0237954417,"data-annotation":0.5256496247,"dev-research":0.1520863344,"llms":0.4621088344,"data-quality":0.2024209215}}
{"text":"We identify two general detection paradigms and derive novel methods from them that are simple in design yet significantly outperform previous work.","meta":{"url":"http://arxiv.org/abs/2310.15085v1"},"cats":{"benchmark":0.4834108398,"new-dataset":0.0210304701,"data-annotation":0.5495185296,"dev-research":0.1445412424,"llms":0.4522602467,"data-quality":0.3335558877}}
{"text":"We demonstrate the efficacy of these methods in a comprehensive evaluation with all major learning platforms and scaling algorithms.","meta":{"url":"http://arxiv.org/abs/2310.15085v1"},"cats":{"benchmark":0.7182594843,"new-dataset":0.01000249,"data-annotation":0.5367834185,"dev-research":0.1404414114,"llms":0.4226574681,"data-quality":0.1519255666}}
{"text":"First, we show that image-scaling attacks modifying the entire scaled image can be reliably detected even under an adaptive adversary.","meta":{"url":"http://arxiv.org/abs/2310.15085v1"},"cats":{"benchmark":0.398373748,"new-dataset":0.0175739857,"data-annotation":0.5210516558,"dev-research":0.1421472282,"llms":0.4866815898,"data-quality":0.1798257664}}
{"text":"Second, we find that our methods provide strong detection performance even if only minor parts of the image are manipulated.","meta":{"url":"http://arxiv.org/abs/2310.15085v1"},"cats":{"benchmark":0.5019590422,"new-dataset":0.0169830764,"data-annotation":0.5487085367,"dev-research":0.1525966363,"llms":0.4604933055,"data-quality":0.2217919439}}
{"text":"As a result, we can introduce a novel protection layer against image-scaling attacks.","meta":{"url":"http://arxiv.org/abs/2310.15085v1"},"cats":{"benchmark":0.3399665138,"new-dataset":0.0408086144,"data-annotation":0.5039986263,"dev-research":0.2054212032,"llms":0.5009003278,"data-quality":0.1182060928}}
{"text":"This paper proposes a novel approach to face swapping from the perspective of fine-grained facial editing, dubbed \"editing for swapping\" (E4S).","meta":{"url":"http://arxiv.org/abs/2310.15081v1"},"cats":{"benchmark":0.3487951643,"new-dataset":0.0387609971,"data-annotation":0.5097749895,"dev-research":0.2739873139,"llms":0.4800829878,"data-quality":0.1050720604}}
{"text":"The traditional face swapping methods rely on global feature extraction and often fail to preserve the source identity.","meta":{"url":"http://arxiv.org/abs/2310.15081v1"},"cats":{"benchmark":0.4221588512,"new-dataset":0.0056117345,"data-annotation":0.5092616255,"dev-research":0.2393717634,"llms":0.4604612294,"data-quality":0.2025558779}}
{"text":"In contrast, our framework proposes a Regional GAN Inversion (RGI) method, which allows the explicit disentanglement of shape and texture.","meta":{"url":"http://arxiv.org/abs/2310.15081v1"},"cats":{"benchmark":0.3175664514,"new-dataset":0.0239456042,"data-annotation":0.5045449526,"dev-research":0.1618538216,"llms":0.40701034,"data-quality":0.1165526262}}
{"text":"Specifically, our E4S performs face swapping in the latent space of a pretrained StyleGAN, where a multi-scale mask-guided encoder is applied to project the texture of each facial component into regional style codes and a mask-guided injection module then manipulates feature maps with the style codes.","meta":{"url":"http://arxiv.org/abs/2310.15081v1"},"cats":{"benchmark":0.2301474181,"new-dataset":0.0396563998,"data-annotation":0.51034678,"dev-research":0.204192114,"llms":0.5406369622,"data-quality":0.1031965643}}
{"text":"Based on this disentanglement, face swapping can be simplified as style and mask swapping.","meta":{"url":"http://arxiv.org/abs/2310.15081v1"},"cats":{"benchmark":0.3070220267,"new-dataset":0.0088763445,"data-annotation":0.5034790015,"dev-research":0.2443358304,"llms":0.4780569491,"data-quality":0.0875484451}}
{"text":"Besides, since reconstructing the source face in the target image may lead to disharmony lighting, we propose to train a re-coloring network to make the swapped face maintain the lighting condition on the target face.","meta":{"url":"http://arxiv.org/abs/2310.15081v1"},"cats":{"benchmark":0.3162129663,"new-dataset":0.0460599776,"data-annotation":0.5006817781,"dev-research":0.2297397063,"llms":0.4778768798,"data-quality":0.1365246387}}
{"text":"Further, to deal with the potential mismatch area during mask exchange, we designed a face inpainting network as post-processing.","meta":{"url":"http://arxiv.org/abs/2310.15081v1"},"cats":{"benchmark":0.3349078203,"new-dataset":0.0103707078,"data-annotation":0.4928673215,"dev-research":0.2233819336,"llms":0.5166685971,"data-quality":0.1277389925}}
{"text":"The extensive comparisons with state-of-the-art methods demonstrate that our E4S outperforms existing methods in preserving texture, shape, and lighting.","meta":{"url":"http://arxiv.org/abs/2310.15081v1"},"cats":{"benchmark":0.5265862668,"new-dataset":0.034684377,"data-annotation":0.5112829159,"dev-research":0.2227370591,"llms":0.4848494237,"data-quality":0.0958486264}}
{"text":"Our implementation is available at https://github.com/e4s2023/E4S2023.","meta":{"url":"http://arxiv.org/abs/2310.15081v1"},"cats":{"benchmark":0.4456867123,"new-dataset":0.1065504526,"data-annotation":0.5416249671,"dev-research":0.1099812731,"llms":0.5391740316,"data-quality":0.1361101848}}
{"text":"Federated learning (FL) is a promising paradigm to enable collaborative model training with decentralized data.","meta":{"url":"http://arxiv.org/abs/2310.15080v1"},"cats":{"benchmark":0.2101637049,"new-dataset":0.1055775826,"data-annotation":0.4719650014,"dev-research":0.1407358563,"llms":0.5100254602,"data-quality":0.0885044774}}
{"text":"However, the training process of Large Language Models (LLMs) generally incurs the update of significant parameters, which limits the applicability of FL techniques to tackle the LLMs in real scenarios.","meta":{"url":"http://arxiv.org/abs/2310.15080v1"},"cats":{"benchmark":0.2533439078,"new-dataset":0.0251374598,"data-annotation":0.5259884614,"dev-research":0.1542665181,"llms":0.7012400419,"data-quality":0.1788500718}}
{"text":"Prompt tuning can significantly reduce the number of parameters to update, but it either incurs performance degradation or low training efficiency.","meta":{"url":"http://arxiv.org/abs/2310.15080v1"},"cats":{"benchmark":0.3799015994,"new-dataset":0.0081848583,"data-annotation":0.5235477991,"dev-research":0.233730026,"llms":0.5199933754,"data-quality":0.1559259293}}
{"text":"The straightforward utilization of prompt tuning in the FL often raises non-trivial communication costs and dramatically degrades performance.","meta":{"url":"http://arxiv.org/abs/2310.15080v1"},"cats":{"benchmark":0.3698446767,"new-dataset":0.009381029,"data-annotation":0.5050297745,"dev-research":0.2100580325,"llms":0.5726751981,"data-quality":0.1054828135}}
{"text":"In addition, the decentralized data is generally non-Independent and Identically Distributed (non-IID), which brings client drift problems and thus poor performance.","meta":{"url":"http://arxiv.org/abs/2310.15080v1"},"cats":{"benchmark":0.4879651563,"new-dataset":0.0218781891,"data-annotation":0.4640936556,"dev-research":0.153520395,"llms":0.5294159333,"data-quality":0.1051293689}}
{"text":"This paper proposes a Parameter-efficient prompt Tuning approach with Adaptive Optimization, i.e., FedPepTAO, to enable efficient and effective FL of LLMs.","meta":{"url":"http://arxiv.org/abs/2310.15080v1"},"cats":{"benchmark":0.4512207908,"new-dataset":0.0108093335,"data-annotation":0.5019235886,"dev-research":0.1172963316,"llms":0.6709088051,"data-quality":0.1137209886}}
{"text":"First, an efficient partial prompt tuning approach is proposed to improve performance and efficiency simultaneously.","meta":{"url":"http://arxiv.org/abs/2310.15080v1"},"cats":{"benchmark":0.4813020677,"new-dataset":0.0170241729,"data-annotation":0.5090333804,"dev-research":0.2069413041,"llms":0.5360996139,"data-quality":0.1260442271}}
{"text":"Second, a novel adaptive optimization method is developed to address the client drift problems on both the device and server sides to enhance performance further.","meta":{"url":"http://arxiv.org/abs/2310.15080v1"},"cats":{"benchmark":0.6217435899,"new-dataset":0.0089103197,"data-annotation":0.4986452947,"dev-research":0.2672305439,"llms":0.4616802933,"data-quality":0.1620689272}}
{"text":"Extensive experiments based on 10 datasets demonstrate the superb performance (up to 60.8\\% in terms of accuracy) and efficiency (up to 97.59\\% in terms of training time) of FedPepTAO compared with 9 baseline approaches.","meta":{"url":"http://arxiv.org/abs/2310.15080v1"},"cats":{"benchmark":0.6221819766,"new-dataset":0.0416746308,"data-annotation":0.5142927608,"dev-research":0.1280262221,"llms":0.4775336433,"data-quality":0.125212722}}
{"text":"Our code is available at https://github.com/llm-eff/FedPepTAO.","meta":{"url":"http://arxiv.org/abs/2310.15080v1"},"cats":{"benchmark":0.3274395291,"new-dataset":0.2735726168,"data-annotation":0.5353060012,"dev-research":0.1518807732,"llms":0.5377054326,"data-quality":0.1478681693}}
{"text":"Storytelling's captivating potential makes it a fascinating research area, with implications for entertainment, education, therapy, and cognitive studies.","meta":{"url":"http://arxiv.org/abs/2310.15079v1"},"cats":{"benchmark":0.14891251,"new-dataset":0.0221519581,"data-annotation":0.5272390278,"dev-research":0.2252139962,"llms":0.5879196794,"data-quality":0.061545399}}
{"text":"In this paper, we propose Affective Story Generator (AffGen) for generating interesting narratives.","meta":{"url":"http://arxiv.org/abs/2310.15079v1"},"cats":{"benchmark":0.1503376869,"new-dataset":0.4116003545,"data-annotation":0.5351505442,"dev-research":0.2499580223,"llms":0.5639242231,"data-quality":0.0843095939}}
{"text":"AffGen introduces \"intriguing twists\" in narratives by employing two novel techniques-Dynamic Beam Sizing and Affective Reranking.","meta":{"url":"http://arxiv.org/abs/2310.15079v1"},"cats":{"benchmark":0.2151828297,"new-dataset":0.0759364664,"data-annotation":0.5312207123,"dev-research":0.2418322486,"llms":0.504204148,"data-quality":0.1079831321}}
{"text":"Dynamic Beam Sizing encourages less predictable, more captivating word choices using a contextual multi-arm bandit model.","meta":{"url":"http://arxiv.org/abs/2310.15079v1"},"cats":{"benchmark":0.2830555971,"new-dataset":0.0119504199,"data-annotation":0.5359477295,"dev-research":0.1349960093,"llms":0.4878670282,"data-quality":0.1033330238}}
{"text":"Affective Reranking prioritizes sentence candidates based on affect intensity.","meta":{"url":"http://arxiv.org/abs/2310.15079v1"},"cats":{"benchmark":0.4582208951,"new-dataset":0.0367441889,"data-annotation":0.5427646304,"dev-research":0.1740016271,"llms":0.4896757846,"data-quality":0.1491263806}}
{"text":"Our empirical evaluations, both automatic and human, demonstrate AffGen's superior performance over existing baselines in generating affectively charged and interesting narratives.","meta":{"url":"http://arxiv.org/abs/2310.15079v1"},"cats":{"benchmark":0.3023888046,"new-dataset":0.1388536596,"data-annotation":0.5464690608,"dev-research":0.2604500146,"llms":0.5528286282,"data-quality":0.1890378414}}
{"text":"Our ablation study and analysis provide insights into the strengths and weaknesses of AffGen.","meta":{"url":"http://arxiv.org/abs/2310.15079v1"},"cats":{"benchmark":0.3936063052,"new-dataset":0.0716342137,"data-annotation":0.5213008747,"dev-research":0.1724464679,"llms":0.4891786891,"data-quality":0.1356418791}}
{"text":"Science journalism refers to the task of reporting technical findings of a scientific paper as a less technical news article to the general public audience.","meta":{"url":"http://arxiv.org/abs/2310.15077v1"},"cats":{"benchmark":0.3447936785,"new-dataset":0.0433643781,"data-annotation":0.5220723706,"dev-research":0.2734516179,"llms":0.4956465457,"data-quality":0.2043223376}}
{"text":"We aim to design an automated system to support this real-world task (i.e., automatic science journalism) by 1) introducing a newly-constructed and real-world dataset (SciTechNews), with tuples of a publicly-available scientific paper, its corresponding news article, and an expert-written short summary snippet; 2) proposing a novel technical framework that integrates a paper's discourse structure with its metadata to guide generation; and, 3) demonstrating with extensive automatic and human experiments that our framework outperforms other baseline methods (e.g. Alpaca and ChatGPT) in elaborating a content plan meaningful for the target audience, simplifying the information selected, and producing a coherent final report in a layman's style.","meta":{"url":"http://arxiv.org/abs/2310.15077v1"},"cats":{"benchmark":0.2699114495,"new-dataset":0.6056322866,"data-annotation":0.514230557,"dev-research":0.3228272249,"llms":0.555095305,"data-quality":0.2109749479}}
{"text":"Table-based question answering (TableQA) is an important task in natural language processing, which requires comprehending tables and employing various reasoning ways to answer the questions.","meta":{"url":"http://arxiv.org/abs/2310.15075v1"},"cats":{"benchmark":0.2360492961,"new-dataset":0.096394302,"data-annotation":0.5025134023,"dev-research":0.2230843377,"llms":0.4757941399,"data-quality":0.1117102857}}
{"text":"This paper introduces TableQAKit, the first comprehensive toolkit designed specifically for TableQA.","meta":{"url":"http://arxiv.org/abs/2310.15075v1"},"cats":{"benchmark":0.4197374835,"new-dataset":0.1238997848,"data-annotation":0.4886667342,"dev-research":0.2445467232,"llms":0.4692089147,"data-quality":0.0954610721}}
{"text":"The toolkit designs a unified platform that includes plentiful TableQA datasets and integrates popular methods of this task as well as large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2310.15075v1"},"cats":{"benchmark":0.28026603,"new-dataset":0.7934059815,"data-annotation":0.5108765235,"dev-research":0.1867697562,"llms":0.5884491527,"data-quality":0.1659492206}}
{"text":"Users can add their datasets and methods according to the friendly interface.","meta":{"url":"http://arxiv.org/abs/2310.15075v1"},"cats":{"benchmark":0.1961315396,"new-dataset":0.4060536161,"data-annotation":0.5033027752,"dev-research":0.3829136059,"llms":0.5354048015,"data-quality":0.110574961}}
{"text":"Also, pleasantly surprised using the modules in this toolkit achieves new SOTA on some datasets.","meta":{"url":"http://arxiv.org/abs/2310.15075v1"},"cats":{"benchmark":0.3346386258,"new-dataset":0.3380269287,"data-annotation":0.5028434428,"dev-research":0.1516615666,"llms":0.5509763715,"data-quality":0.1203284111}}
{"text":"Finally, \\tableqakit{} also provides an LLM-based TableQA Benchmark for evaluating the role of LLMs in TableQA.","meta":{"url":"http://arxiv.org/abs/2310.15075v1"},"cats":{"benchmark":0.5417799172,"new-dataset":0.041975926,"data-annotation":0.4965848925,"dev-research":0.1366774414,"llms":0.630453463,"data-quality":0.0910092619}}
{"text":"TableQAKit is open-source with an interactive interface that includes visual operations, and comprehensive data for ease of use.","meta":{"url":"http://arxiv.org/abs/2310.15075v1"},"cats":{"benchmark":0.29163877,"new-dataset":0.4192283248,"data-annotation":0.4817432924,"dev-research":0.2675343921,"llms":0.4660900816,"data-quality":0.0677332081}}
{"text":"Differentiable architecture search (DAS) has become the prominent approach in the field of neural architecture search (NAS) due to its time-efficient automation of neural network design.","meta":{"url":"http://arxiv.org/abs/2310.15074v1"},"cats":{"benchmark":0.3832993353,"new-dataset":0.0234837591,"data-annotation":0.5063658565,"dev-research":0.1461947518,"llms":0.4699903724,"data-quality":0.0794780853}}
{"text":"It shifts the traditional paradigm of discrete architecture sampling and evaluation to differentiable super-net optimization and discretization.","meta":{"url":"http://arxiv.org/abs/2310.15074v1"},"cats":{"benchmark":0.4908130931,"new-dataset":0.0048738397,"data-annotation":0.4879020106,"dev-research":0.1239073515,"llms":0.4328845719,"data-quality":0.0397741447}}
{"text":"However, existing DAS methods either only conduct coarse-grained operation-level search, or restrictively explore fine-grained filter-level and weight-level units using manually-defined remaining ratios, which fail to simultaneously achieve small model size and satisfactory model performance.","meta":{"url":"http://arxiv.org/abs/2310.15074v1"},"cats":{"benchmark":0.5867990286,"new-dataset":0.0044223529,"data-annotation":0.4988116923,"dev-research":0.1175015278,"llms":0.4473786347,"data-quality":0.1189346826}}
{"text":"Additionally, they address the high memory consumption of the search process at the expense of search quality.","meta":{"url":"http://arxiv.org/abs/2310.15074v1"},"cats":{"benchmark":0.3742018935,"new-dataset":0.0284199436,"data-annotation":0.5274518136,"dev-research":0.1875867048,"llms":0.5836322576,"data-quality":0.1028474315}}
{"text":"To tackle these issues, we introduce multi-granularity architecture search (MGAS), a unified framework which aims to comprehensively and memory-efficiently explore the multi-granularity search space to discover both effective and efficient neural networks.","meta":{"url":"http://arxiv.org/abs/2310.15074v1"},"cats":{"benchmark":0.3689256568,"new-dataset":0.0358267709,"data-annotation":0.5137387917,"dev-research":0.0972027653,"llms":0.5553795196,"data-quality":0.0672963563}}
{"text":"Specifically, we learn discretization functions specific to each granularity level to adaptively determine the remaining ratios according to the evolving architecture.","meta":{"url":"http://arxiv.org/abs/2310.15074v1"},"cats":{"benchmark":0.4302864777,"new-dataset":0.0231309613,"data-annotation":0.5154211678,"dev-research":0.1443913156,"llms":0.4787188404,"data-quality":0.0593867172}}
{"text":"This ensures an optimal balance among units of different granularity levels for different target model sizes.","meta":{"url":"http://arxiv.org/abs/2310.15074v1"},"cats":{"benchmark":0.5106629572,"new-dataset":0.0017608765,"data-annotation":0.4873721983,"dev-research":0.1188426177,"llms":0.4443968231,"data-quality":0.0518607059}}
{"text":"Considering the memory demands, we break down the super-net optimization and discretization into multiple sub-net stages.","meta":{"url":"http://arxiv.org/abs/2310.15074v1"},"cats":{"benchmark":0.4239776556,"new-dataset":0.0138649095,"data-annotation":0.5015260813,"dev-research":0.1404587854,"llms":0.4876927533,"data-quality":0.0351256234}}
{"text":"By allowing re-pruning and regrowing of units in previous sub-nets during subsequent stages, we compensate for potential bias in earlier stages.","meta":{"url":"http://arxiv.org/abs/2310.15074v1"},"cats":{"benchmark":0.4348820024,"new-dataset":0.0099691404,"data-annotation":0.5133182437,"dev-research":0.1498973904,"llms":0.4695211179,"data-quality":0.1402936196}}
{"text":"Extensive experiments on CIFAR-10, CIFAR-100 and ImageNet demonstrate that MGAS outperforms other state-of-the-art methods in achieving a better trade-off between model performance and model size.","meta":{"url":"http://arxiv.org/abs/2310.15074v1"},"cats":{"benchmark":0.5092147894,"new-dataset":0.0134568587,"data-annotation":0.4964656696,"dev-research":0.1276751355,"llms":0.5211498959,"data-quality":0.0954720852}}
{"text":"It is typically challenging for visual or visual-inertial odometry systems to handle the problems of dynamic scenes and pure rotation.","meta":{"url":"http://arxiv.org/abs/2310.15072v1"},"cats":{"benchmark":0.3692321298,"new-dataset":0.0368024842,"data-annotation":0.5122407308,"dev-research":0.2485688302,"llms":0.4366963775,"data-quality":0.0856833754}}
{"text":"In this work, we design a novel visual-inertial odometry (VIO) system called RD-VIO to handle both of these two problems.","meta":{"url":"http://arxiv.org/abs/2310.15072v1"},"cats":{"benchmark":0.4041023846,"new-dataset":0.1749932269,"data-annotation":0.4954054761,"dev-research":0.1919354563,"llms":0.4637918793,"data-quality":0.0643587908}}
{"text":"Firstly, we propose an IMU-PARSAC algorithm which can robustly detect and match keypoints in a two-stage process.","meta":{"url":"http://arxiv.org/abs/2310.15072v1"},"cats":{"benchmark":0.5878117755,"new-dataset":0.0868023652,"data-annotation":0.5106241705,"dev-research":0.1311654511,"llms":0.4608714782,"data-quality":0.1427428281}}
{"text":"In the first state, landmarks are matched with new keypoints using visual and IMU measurements.","meta":{"url":"http://arxiv.org/abs/2310.15072v1"},"cats":{"benchmark":0.4293937433,"new-dataset":0.0834268596,"data-annotation":0.5124832369,"dev-research":0.136673209,"llms":0.4715418514,"data-quality":0.0755869145}}
{"text":"We collect statistical information from the matching and then guide the intra-keypoint matching in the second stage.","meta":{"url":"http://arxiv.org/abs/2310.15072v1"},"cats":{"benchmark":0.5671279418,"new-dataset":0.1799112975,"data-annotation":0.4930109956,"dev-research":0.1203076536,"llms":0.4222623145,"data-quality":0.124517381}}
{"text":"Secondly, to handle the problem of pure rotation, we detect the motion type and adapt the deferred-triangulation technique during the data-association process.","meta":{"url":"http://arxiv.org/abs/2310.15072v1"},"cats":{"benchmark":0.3564053604,"new-dataset":0.0511566934,"data-annotation":0.4930032025,"dev-research":0.1531230764,"llms":0.4432730428,"data-quality":0.0650191332}}
{"text":"We make the pure-rotational frames into the special subframes.","meta":{"url":"http://arxiv.org/abs/2310.15072v1"},"cats":{"benchmark":0.2755111888,"new-dataset":0.1051115285,"data-annotation":0.5271872314,"dev-research":0.1435077615,"llms":0.4714014662,"data-quality":0.0801923557}}
{"text":"When solving the visual-inertial bundle adjustment, they provide additional constraints to the pure-rotational motion.","meta":{"url":"http://arxiv.org/abs/2310.15072v1"},"cats":{"benchmark":0.3315335977,"new-dataset":0.0156293153,"data-annotation":0.5156106516,"dev-research":0.1897789705,"llms":0.4080900781,"data-quality":0.0629944321}}
{"text":"We evaluate the proposed VIO system on public datasets.","meta":{"url":"http://arxiv.org/abs/2310.15072v1"},"cats":{"benchmark":0.3719419875,"new-dataset":0.5008628484,"data-annotation":0.4803358753,"dev-research":0.1590257523,"llms":0.5044246505,"data-quality":0.1661755094}}
{"text":"Experiments show the proposed RD-VIO has obvious advantages over other methods in dynamic environments.","meta":{"url":"http://arxiv.org/abs/2310.15072v1"},"cats":{"benchmark":0.4533117937,"new-dataset":0.0104001069,"data-annotation":0.4879922577,"dev-research":0.1947181021,"llms":0.5557517106,"data-quality":0.0436597919}}
{"text":"The ability to actively ground task instructions from an egocentric view is crucial for AI agents to accomplish tasks or assist humans virtually.","meta":{"url":"http://arxiv.org/abs/2310.15066v1"},"cats":{"benchmark":0.1810551138,"new-dataset":0.0324496388,"data-annotation":0.5417515618,"dev-research":0.2666273247,"llms":0.5005179094,"data-quality":0.0616948116}}
{"text":"One important step towards this goal is to localize and track key active objects that undergo major state change as a consequence of human actions/interactions to the environment without being told exactly what/where to ground (e.g., localizing and tracking the `sponge` in video from the instruction \"Dip the `sponge` into the bucket.\").","meta":{"url":"http://arxiv.org/abs/2310.15066v1"},"cats":{"benchmark":0.1791971777,"new-dataset":0.2288991536,"data-annotation":0.5069400176,"dev-research":0.2586254278,"llms":0.5603599587,"data-quality":0.0996009715}}
{"text":"While existing works approach this problem from a pure vision perspective, we investigate to which extent the textual modality (i.e., task instructions) and their interaction with visual modality can be beneficial.","meta":{"url":"http://arxiv.org/abs/2310.15066v1"},"cats":{"benchmark":0.2252957285,"new-dataset":0.0588657977,"data-annotation":0.5450225966,"dev-research":0.2530046656,"llms":0.5270279062,"data-quality":0.144931095}}
{"text":"Specifically, we propose to improve phrase grounding models' ability on localizing the active objects by: (1) learning the role of `objects undergoing change` and extracting them accurately from the instructions, (2) leveraging pre- and post-conditions of the objects during actions, and (3) recognizing the objects more robustly with descriptional knowledge.","meta":{"url":"http://arxiv.org/abs/2310.15066v1"},"cats":{"benchmark":0.1930272298,"new-dataset":0.2203047977,"data-annotation":0.5487664566,"dev-research":0.3063674975,"llms":0.5408855265,"data-quality":0.2923475589}}
{"text":"We leverage large language models (LLMs) to extract the aforementioned action-object knowledge, and design a per-object aggregation masking technique to effectively perform joint inference on object phrases and symbolic knowledge.","meta":{"url":"http://arxiv.org/abs/2310.15066v1"},"cats":{"benchmark":0.2033606686,"new-dataset":0.1504978076,"data-annotation":0.5345002634,"dev-research":0.1978440203,"llms":0.5725209814,"data-quality":0.1795344747}}
{"text":"We evaluate our framework on Ego4D and Epic-Kitchens datasets.","meta":{"url":"http://arxiv.org/abs/2310.15066v1"},"cats":{"benchmark":0.3126632224,"new-dataset":0.6911574543,"data-annotation":0.5084212252,"dev-research":0.2072784855,"llms":0.494606683,"data-quality":0.1766933041}}
{"text":"Extensive experiments demonstrate the effectiveness of our proposed framework, which leads to>54% improvements in all standard metrics on the TREK-150-OPE-Det localization + tracking task, >7% improvements in all standard metrics on the TREK-150-OPE tracking task, and >3% improvements in average precision (AP) on the Ego4D SCOD task.","meta":{"url":"http://arxiv.org/abs/2310.15066v1"},"cats":{"benchmark":0.5789917008,"new-dataset":0.0920717715,"data-annotation":0.5160370921,"dev-research":0.2053171554,"llms":0.4188564873,"data-quality":0.1698313932}}
{"text":"This empirical study serves as a primer for interested service providers to determine if and how Large Language Models (LLMs) technology will be integrated for their practitioners and the broader community.","meta":{"url":"http://arxiv.org/abs/2310.15065v1"},"cats":{"benchmark":0.2192300905,"new-dataset":0.0247511685,"data-annotation":0.5060083109,"dev-research":0.1862203255,"llms":0.7412073548,"data-quality":0.1168439623}}
{"text":"We investigate the mutual learning journey of non-AI experts and AI through CoAGent, a service co-creation tool with LLM-based agents.","meta":{"url":"http://arxiv.org/abs/2310.15065v1"},"cats":{"benchmark":0.1963240653,"new-dataset":0.0609632612,"data-annotation":0.5086623616,"dev-research":0.1604968243,"llms":0.6229690028,"data-quality":0.085449513}}
{"text":"Engaging in a three-stage participatory design processes, we work with with 23 domain experts from public libraries across the U.S., uncovering their fundamental challenges of integrating AI into human workflows.","meta":{"url":"http://arxiv.org/abs/2310.15065v1"},"cats":{"benchmark":0.157248647,"new-dataset":0.1505110317,"data-annotation":0.4883828855,"dev-research":0.4617545841,"llms":0.617225083,"data-quality":0.0899448885}}
{"text":"Our findings provide 23 actionable \"heuristics for service co-creation with AI\", highlighting the nuanced shared responsibilities between humans and AI.","meta":{"url":"http://arxiv.org/abs/2310.15065v1"},"cats":{"benchmark":0.1852363658,"new-dataset":0.1349081156,"data-annotation":0.5095696244,"dev-research":0.2907829264,"llms":0.524493392,"data-quality":0.0891004065}}
{"text":"We further exemplar 9 foundational agency aspects for AI, emphasizing essentials like ownership, fair treatment, and freedom of expression.","meta":{"url":"http://arxiv.org/abs/2310.15065v1"},"cats":{"benchmark":0.1721312002,"new-dataset":0.164552979,"data-annotation":0.5115451172,"dev-research":0.2014131926,"llms":0.5181347166,"data-quality":0.1263010964}}
{"text":"Our innovative approach enriches the participatory design model by incorporating AI as crucial stakeholders and utilizing AI-AI interaction to identify blind spots.","meta":{"url":"http://arxiv.org/abs/2310.15065v1"},"cats":{"benchmark":0.1774126395,"new-dataset":0.0526807525,"data-annotation":0.5060971213,"dev-research":0.4767840346,"llms":0.5249614015,"data-quality":0.1256655817}}
{"text":"Collectively, these insights pave the way for synergistic and ethical human-AI co-creation in service contexts, preparing for workforce ecosystems where AI coexists.","meta":{"url":"http://arxiv.org/abs/2310.15065v1"},"cats":{"benchmark":0.1747006156,"new-dataset":0.1036665909,"data-annotation":0.5098394297,"dev-research":0.2457392644,"llms":0.5249933377,"data-quality":0.1180961144}}
{"text":"Despite the impressive performance achieved by pre-trained language-and-vision models in downstream tasks, it remains an open question whether this reflects a proper understanding of image-text interaction.","meta":{"url":"http://arxiv.org/abs/2310.15061v1"},"cats":{"benchmark":0.1892477135,"new-dataset":0.0642621284,"data-annotation":0.5350505769,"dev-research":0.2129618591,"llms":0.5206586473,"data-quality":0.1884938876}}
{"text":"In this work, we explore to what extent they handle basic linguistic constructions -- active-passive voice, coordination, and relative clauses -- that even preschool children can typically master.","meta":{"url":"http://arxiv.org/abs/2310.15061v1"},"cats":{"benchmark":0.1904056413,"new-dataset":0.0940173107,"data-annotation":0.5234203722,"dev-research":0.2097958627,"llms":0.5376621707,"data-quality":0.142669408}}
{"text":"We present BLA, a novel, automatically constructed benchmark to evaluate multimodal models on these Basic Language Abilities.","meta":{"url":"http://arxiv.org/abs/2310.15061v1"},"cats":{"benchmark":0.4911488644,"new-dataset":0.2221749871,"data-annotation":0.5610105042,"dev-research":0.1925081765,"llms":0.4893155664,"data-quality":0.1621212147}}
{"text":"We show that different types of Transformer-based systems, such as CLIP, ViLBERT, and BLIP2, generally struggle with BLA in a zero-shot setting, in line with previous findings.","meta":{"url":"http://arxiv.org/abs/2310.15061v1"},"cats":{"benchmark":0.3535800568,"new-dataset":0.0165372302,"data-annotation":0.4952398997,"dev-research":0.136435183,"llms":0.4925572707,"data-quality":0.088337279}}
{"text":"Our experiments, in particular, show that most of the tested models only marginally benefit when fine-tuned or prompted with construction-specific samples.","meta":{"url":"http://arxiv.org/abs/2310.15061v1"},"cats":{"benchmark":0.5013166666,"new-dataset":0.0050029098,"data-annotation":0.5345793875,"dev-research":0.18860028,"llms":0.5074297244,"data-quality":0.1303432419}}
{"text":"Yet, the generative BLIP2 shows promising trends, especially in an in-context learning setting.","meta":{"url":"http://arxiv.org/abs/2310.15061v1"},"cats":{"benchmark":0.2434660835,"new-dataset":0.1263210401,"data-annotation":0.53419345,"dev-research":0.1986564628,"llms":0.5063407532,"data-quality":0.1476798473}}
{"text":"This opens the door to using BLA not only as an evaluation benchmark but also to improve models' basic language abilities.","meta":{"url":"http://arxiv.org/abs/2310.15061v1"},"cats":{"benchmark":0.6068699699,"new-dataset":0.0237388192,"data-annotation":0.5300880268,"dev-research":0.2515765801,"llms":0.5135145261,"data-quality":0.1256618388}}
{"text":"A long-standing challenge for a robotic manipulation system operating in real-world scenarios is adapting and generalizing its acquired motor skills to unseen environments.","meta":{"url":"http://arxiv.org/abs/2310.15059v1"},"cats":{"benchmark":0.1540744925,"new-dataset":0.0566826318,"data-annotation":0.5042885304,"dev-research":0.225945121,"llms":0.5226712008,"data-quality":0.0602586853}}
{"text":"We tackle this challenge employing hybrid skill models that integrate imitation and reinforcement paradigms, to explore how the learning and adaptation of a skill, along with its core grounding in the scene through a learned keypoint, can facilitate such generalization.","meta":{"url":"http://arxiv.org/abs/2310.15059v1"},"cats":{"benchmark":0.2000396403,"new-dataset":0.1273402198,"data-annotation":0.5117573804,"dev-research":0.1603551984,"llms":0.4775062305,"data-quality":0.0762873663}}
{"text":"To that end, we develop Keypoint Integrated Soft Actor-Critic Gaussian Mixture Models (KIS-GMM) approach that learns to predict the reference of a dynamical system within the scene as a 3D keypoint, leveraging visual observations obtained by the robot's physical interactions during skill learning.","meta":{"url":"http://arxiv.org/abs/2310.15059v1"},"cats":{"benchmark":0.2383077454,"new-dataset":0.1097005269,"data-annotation":0.5221055392,"dev-research":0.1691639568,"llms":0.4256140458,"data-quality":0.0644964894}}
{"text":"Through conducting comprehensive evaluations in both simulated and real-world environments, we show that our method enables a robot to gain a significant zero-shot generalization to novel environments and to refine skills in the target environments faster than learning from scratch.","meta":{"url":"http://arxiv.org/abs/2310.15059v1"},"cats":{"benchmark":0.2985790405,"new-dataset":0.075674252,"data-annotation":0.5278619367,"dev-research":0.222361987,"llms":0.5009494839,"data-quality":0.1012869781}}
{"text":"Importantly, this is achieved without the need for new ground truth data.","meta":{"url":"http://arxiv.org/abs/2310.15059v1"},"cats":{"benchmark":0.2705022253,"new-dataset":0.230429864,"data-annotation":0.4900623176,"dev-research":0.1357662301,"llms":0.5265088658,"data-quality":0.1539858624}}
{"text":"Moreover, our method effectively copes with scene displacements.","meta":{"url":"http://arxiv.org/abs/2310.15059v1"},"cats":{"benchmark":0.4506710476,"new-dataset":0.0419316598,"data-annotation":0.5323034826,"dev-research":0.1943205956,"llms":0.3975772671,"data-quality":0.1863143318}}
{"text":"Driving style is usually used to characterize driving behavior for a driver or a group of drivers.","meta":{"url":"http://arxiv.org/abs/2310.15057v1"},"cats":{"benchmark":0.213030049,"new-dataset":0.0157834386,"data-annotation":0.499689051,"dev-research":0.2988443088,"llms":0.4748340904,"data-quality":0.0898500187}}
{"text":"However, it remains unclear how one individual's driving style shares certain common grounds with other drivers.","meta":{"url":"http://arxiv.org/abs/2310.15057v1"},"cats":{"benchmark":0.2793308602,"new-dataset":0.0068756327,"data-annotation":0.4949908831,"dev-research":0.2663602352,"llms":0.470419389,"data-quality":0.1513612032}}
{"text":"Our insight is that driving behavior is a sequence of responses to the weighted mixture of latent driving styles that are shareable within and between individuals.","meta":{"url":"http://arxiv.org/abs/2310.15057v1"},"cats":{"benchmark":0.2589432104,"new-dataset":0.0092521743,"data-annotation":0.5118346747,"dev-research":0.2100355028,"llms":0.4566017122,"data-quality":0.0890724464}}
{"text":"To this end, this paper develops a hierarchical latent model to learn the relationship between driving behavior and driving styles.","meta":{"url":"http://arxiv.org/abs/2310.15057v1"},"cats":{"benchmark":0.2443085095,"new-dataset":0.0329633892,"data-annotation":0.5190072237,"dev-research":0.2034372599,"llms":0.4457804841,"data-quality":0.1002509557}}
{"text":"We first propose a fragment-based approach to represent complex sequential driving behavior, allowing for sufficiently representing driving behavior in a low-dimension feature space.","meta":{"url":"http://arxiv.org/abs/2310.15057v1"},"cats":{"benchmark":0.2727054757,"new-dataset":0.0591426034,"data-annotation":0.5026091902,"dev-research":0.2216026716,"llms":0.4313907971,"data-quality":0.0565109707}}
{"text":"Then, we provide an analytical formulation for the interaction of driving behavior and shareable driving style with a hierarchical latent model by introducing the mechanism of Dirichlet allocation.","meta":{"url":"http://arxiv.org/abs/2310.15057v1"},"cats":{"benchmark":0.2930855342,"new-dataset":0.0213963109,"data-annotation":0.5246116899,"dev-research":0.1799800881,"llms":0.4582412649,"data-quality":0.0860448556}}
{"text":"Our developed model is finally validated and verified with 100 drivers in naturalistic driving settings with urban and highways.","meta":{"url":"http://arxiv.org/abs/2310.15057v1"},"cats":{"benchmark":0.3740519279,"new-dataset":0.0680874711,"data-annotation":0.5002383879,"dev-research":0.2392033515,"llms":0.4456639912,"data-quality":0.1057980518}}
{"text":"Experimental results reveal that individuals share driving styles within and between them.","meta":{"url":"http://arxiv.org/abs/2310.15057v1"},"cats":{"benchmark":0.2800587879,"new-dataset":0.0142566203,"data-annotation":0.5056644531,"dev-research":0.2231889305,"llms":0.4728020531,"data-quality":0.0888717018}}
{"text":"We also analyzed the influence of personalities (e.g., age, gender, and driving experience) on driving styles and found that a naturally aggressive driver would not always keep driving aggressively (i.e., could behave calmly sometimes)","meta":{"url":"http://arxiv.org/abs/2310.15057v1"},"cats":{"benchmark":0.2850152517,"new-dataset":0.0260675481,"data-annotation":0.5073439795,"dev-research":0.2692377586,"llms":0.4893130275,"data-quality":0.1123545899}}
{"text":"but with a higher proportion of aggressiveness than other types of drivers.","meta":{"url":"http://arxiv.org/abs/2310.15057v1"},"cats":{"benchmark":0.3593510376,"new-dataset":0.0087660827,"data-annotation":0.511035667,"dev-research":0.2239083806,"llms":0.5073982633,"data-quality":0.1072734639}}
{"text":"Recent research at the intersection of AI explainability and fairness has focused on how explanations can improve human-plus-AI task performance as assessed by fairness measures.","meta":{"url":"http://arxiv.org/abs/2310.15055v1"},"cats":{"benchmark":0.4157205415,"new-dataset":0.0153687997,"data-annotation":0.5637305782,"dev-research":0.3285527076,"llms":0.4803938893,"data-quality":0.1561708346}}
{"text":"We propose to characterize what constitutes an explanation that is itself \"fair\" -- an explanation that does not adversely impact specific populations.","meta":{"url":"http://arxiv.org/abs/2310.15055v1"},"cats":{"benchmark":0.3480853831,"new-dataset":0.0232899073,"data-annotation":0.5439658539,"dev-research":0.2597882448,"llms":0.5165014865,"data-quality":0.1927432921}}
{"text":"We formulate a novel evaluation method of \"fair explanations\" using not just accuracy and label time, but also psychological impact of explanations on different user groups across many metrics (mental discomfort, stereotype activation, and perceived workload).","meta":{"url":"http://arxiv.org/abs/2310.15055v1"},"cats":{"benchmark":0.4864356898,"new-dataset":0.0175329709,"data-annotation":0.5700514481,"dev-research":0.431568471,"llms":0.4966799795,"data-quality":0.2556636654}}
{"text":"We apply this method in the context of content moderation of potential hate speech, and its differential impact on Asian vs. non-Asian proxy moderators, across explanation approaches (saliency map and counterfactual explanation).","meta":{"url":"http://arxiv.org/abs/2310.15055v1"},"cats":{"benchmark":0.3373491353,"new-dataset":0.0554646321,"data-annotation":0.5358924067,"dev-research":0.285241124,"llms":0.5614576735,"data-quality":0.2825480149}}
{"text":"We find that saliency maps generally perform better and show less evidence of disparate impact (group) and individual unfairness than counterfactual explanations.   ","meta":{"url":"http://arxiv.org/abs/2310.15055v1"},"cats":{"benchmark":0.4742366225,"new-dataset":0.0364818842,"data-annotation":0.5283224216,"dev-research":0.2882801398,"llms":0.4775906504,"data-quality":0.2104088968}}
{"text":"Content warning: This paper contains examples of hate speech and racially discriminatory language.","meta":{"url":"http://arxiv.org/abs/2310.15055v1"},"cats":{"benchmark":0.2503191177,"new-dataset":0.1915107497,"data-annotation":0.557926016,"dev-research":0.2414382689,"llms":0.550423963,"data-quality":0.31255145}}
{"text":"The authors do not support such content.","meta":{"url":"http://arxiv.org/abs/2310.15055v1"},"cats":{"benchmark":0.2452210805,"new-dataset":0.0597578792,"data-annotation":0.515940059,"dev-research":0.1447083862,"llms":0.5728609561,"data-quality":0.1945861737}}
{"text":"Please consider your risk of discomfort carefully before continuing reading!","meta":{"url":"http://arxiv.org/abs/2310.15055v1"},"cats":{"benchmark":0.2725424821,"new-dataset":0.1293571805,"data-annotation":0.5130710784,"dev-research":0.2079965263,"llms":0.5444594844,"data-quality":0.0660696021}}
{"text":"Continual Federated Learning (CFL) combines Federated Learning (FL), the decentralized learning of a central model on a number of client devices that may not communicate their data, and Continual Learning (CL), the learning of a model from a continual stream of data without keeping the entire history.","meta":{"url":"http://arxiv.org/abs/2310.15054v1"},"cats":{"benchmark":0.1787996867,"new-dataset":0.1026142095,"data-annotation":0.477301609,"dev-research":0.1334105589,"llms":0.526581215,"data-quality":0.1083074381}}
{"text":"In CL, the main challenge is \\textit{forgetting} what was learned from past data.","meta":{"url":"http://arxiv.org/abs/2310.15054v1"},"cats":{"benchmark":0.2882604559,"new-dataset":0.3380779855,"data-annotation":0.5098299862,"dev-research":0.267388349,"llms":0.5560655175,"data-quality":0.3939513517}}
{"text":"While replay-based algorithms that keep a small pool of past training data are effective to reduce forgetting, only simple replay sample selection strategies have been applied to CFL in prior work, and no previous work has explored coordination among clients for better sample selection.","meta":{"url":"http://arxiv.org/abs/2310.15054v1"},"cats":{"benchmark":0.4264302871,"new-dataset":0.0450288581,"data-annotation":0.5018082908,"dev-research":0.2316334022,"llms":0.5592465711,"data-quality":0.1631602864}}
{"text":"To bridge this gap, we adapt a replay sample selection objective based on loss gradient diversity to CFL and propose a new relaxation-based selection of samples to optimize the objective.","meta":{"url":"http://arxiv.org/abs/2310.15054v1"},"cats":{"benchmark":0.5967681751,"new-dataset":0.0534495746,"data-annotation":0.5184778119,"dev-research":0.1611887629,"llms":0.4258912763,"data-quality":0.1852525513}}
{"text":"Next, we propose a practical algorithm to coordinate gradient-based replay sample selection across clients without communicating private data.","meta":{"url":"http://arxiv.org/abs/2310.15054v1"},"cats":{"benchmark":0.5054465191,"new-dataset":0.0947740872,"data-annotation":0.4992069512,"dev-research":0.1550141811,"llms":0.4826205414,"data-quality":0.1105569862}}
{"text":"We benchmark our coordinated and uncoordinated replay sample selection algorithms against random sampling-based baselines with language models trained on a large scale de-identified real-world text dataset.","meta":{"url":"http://arxiv.org/abs/2310.15054v1"},"cats":{"benchmark":0.5616926273,"new-dataset":0.3647934128,"data-annotation":0.5213155439,"dev-research":0.1599065247,"llms":0.5088204514,"data-quality":0.2280302001}}
{"text":"We show that gradient-based sample selection methods both boost performance and reduce forgetting compared to random sampling methods, with our coordination method showing gains early in the low replay size regime (when the budget for storing past data is small).","meta":{"url":"http://arxiv.org/abs/2310.15054v1"},"cats":{"benchmark":0.5374048132,"new-dataset":0.0371239384,"data-annotation":0.5026188279,"dev-research":0.1637682232,"llms":0.5308531846,"data-quality":0.1424482537}}
{"text":"Dataset distillation plays a crucial role in creating compact datasets with similar training performance compared with original large-scale ones.","meta":{"url":"http://arxiv.org/abs/2310.15052v1"},"cats":{"benchmark":0.3170194076,"new-dataset":0.2453289699,"data-annotation":0.4633561095,"dev-research":0.1771042968,"llms":0.5194862084,"data-quality":0.1568485019}}
{"text":"This is essential for addressing the challenges of data storage and training costs.","meta":{"url":"http://arxiv.org/abs/2310.15052v1"},"cats":{"benchmark":0.2573810391,"new-dataset":0.1952573647,"data-annotation":0.4692629821,"dev-research":0.2348378328,"llms":0.5275093173,"data-quality":0.1405936099}}
{"text":"Prevalent methods facilitate knowledge transfer by matching the gradients, embedding distributions, or training trajectories of synthetic images with those of the sampled original images.","meta":{"url":"http://arxiv.org/abs/2310.15052v1"},"cats":{"benchmark":0.2544143472,"new-dataset":0.1011316105,"data-annotation":0.514489325,"dev-research":0.1754721465,"llms":0.461171948,"data-quality":0.1415223901}}
{"text":"Although there are various matching objectives, currently the strategy for selecting original images is limited to naive random sampling.","meta":{"url":"http://arxiv.org/abs/2310.15052v1"},"cats":{"benchmark":0.3793262161,"new-dataset":0.0253034098,"data-annotation":0.499757504,"dev-research":0.0851108547,"llms":0.4897532014,"data-quality":0.1525210654}}
{"text":"We argue that random sampling overlooks the evenness of the selected sample distribution, which may result in noisy or biased matching targets.","meta":{"url":"http://arxiv.org/abs/2310.15052v1"},"cats":{"benchmark":0.5043270433,"new-dataset":0.0194554546,"data-annotation":0.5175920631,"dev-research":0.122919898,"llms":0.470061289,"data-quality":0.2998835062}}
{"text":"Besides, the sample diversity is also not constrained by random sampling.","meta":{"url":"http://arxiv.org/abs/2310.15052v1"},"cats":{"benchmark":0.3423378283,"new-dataset":0.0050992403,"data-annotation":0.508144868,"dev-research":0.1023042579,"llms":0.5406731592,"data-quality":0.1556161766}}
{"text":"Additionally, current methods predominantly focus on single-dimensional matching, where information is not fully utilized.","meta":{"url":"http://arxiv.org/abs/2310.15052v1"},"cats":{"benchmark":0.5593504212,"new-dataset":0.0059498307,"data-annotation":0.515340297,"dev-research":0.1396562195,"llms":0.4309924674,"data-quality":0.1526733851}}
{"text":"To address these challenges, we propose a novel matching strategy called Dataset Distillation by Bidirectional REpresentAtive Matching (DREAM+), which selects representative original images for bidirectional matching.","meta":{"url":"http://arxiv.org/abs/2310.15052v1"},"cats":{"benchmark":0.3817702622,"new-dataset":0.300208952,"data-annotation":0.4582067553,"dev-research":0.1211340819,"llms":0.4833652456,"data-quality":0.1308687735}}
{"text":"DREAM+ is applicable to a variety of mainstream dataset distillation frameworks and significantly reduces the number of distillation iterations by more than 15 times without affecting performance.","meta":{"url":"http://arxiv.org/abs/2310.15052v1"},"cats":{"benchmark":0.4027284358,"new-dataset":0.0596657388,"data-annotation":0.4748362114,"dev-research":0.1699723279,"llms":0.4652785759,"data-quality":0.0866327844}}
{"text":"Given sufficient training time, DREAM+ can further improve the performance and achieve state-of-the-art results.","meta":{"url":"http://arxiv.org/abs/2310.15052v1"},"cats":{"benchmark":0.3505745242,"new-dataset":0.0217347144,"data-annotation":0.5064327639,"dev-research":0.1902991663,"llms":0.4972097434,"data-quality":0.0476706491}}
{"text":"We have released the code at github.com/NUS-HPC-AI-Lab/DREAM+.","meta":{"url":"http://arxiv.org/abs/2310.15052v1"},"cats":{"benchmark":0.2590648985,"new-dataset":0.2345176948,"data-annotation":0.5228297711,"dev-research":0.2127883855,"llms":0.5409445817,"data-quality":0.12446017}}
{"text":"We introduce TeleQnA, the first benchmark dataset designed to evaluate the knowledge of Large Language Models (LLMs) in telecommunications.","meta":{"url":"http://arxiv.org/abs/2310.15051v1"},"cats":{"benchmark":0.3765554397,"new-dataset":0.5451103338,"data-annotation":0.5198927727,"dev-research":0.1270001659,"llms":0.6341208737,"data-quality":0.1781341536}}
{"text":"Comprising 10,000 questions and answers, this dataset draws from diverse sources, including standards and research articles.","meta":{"url":"http://arxiv.org/abs/2310.15051v1"},"cats":{"benchmark":0.2587148948,"new-dataset":0.7980022044,"data-annotation":0.5001817112,"dev-research":0.1486977963,"llms":0.5308933172,"data-quality":0.1011644245}}
{"text":"This paper outlines the automated question generation framework responsible for creating this dataset, along with how human input was integrated at various stages to ensure the quality of the questions.","meta":{"url":"http://arxiv.org/abs/2310.15051v1"},"cats":{"benchmark":0.1665700036,"new-dataset":0.7435568038,"data-annotation":0.5091234793,"dev-research":0.337440533,"llms":0.5396913271,"data-quality":0.2417214935}}
{"text":"Afterwards, using the provided dataset, an evaluation is conducted to assess the capabilities of LLMs, including GPT-3.5 and GPT-4.","meta":{"url":"http://arxiv.org/abs/2310.15051v1"},"cats":{"benchmark":0.4108977153,"new-dataset":0.0319355403,"data-annotation":0.4955092303,"dev-research":0.0818392102,"llms":0.7608634376,"data-quality":0.0624450873}}
{"text":"The results highlight that these models struggle with complex standards related questions but exhibit proficiency in addressing general telecom-related inquiries.","meta":{"url":"http://arxiv.org/abs/2310.15051v1"},"cats":{"benchmark":0.2366063206,"new-dataset":0.0137969005,"data-annotation":0.4796746541,"dev-research":0.2527357185,"llms":0.563720734,"data-quality":0.1362713683}}
{"text":"Additionally, our results showcase how incorporating telecom knowledge context significantly enhances their performance, thus shedding light on the need for a specialized telecom foundation model.","meta":{"url":"http://arxiv.org/abs/2310.15051v1"},"cats":{"benchmark":0.2839788959,"new-dataset":0.0262362745,"data-annotation":0.4838286172,"dev-research":0.2239561283,"llms":0.4973350833,"data-quality":0.0681753639}}
{"text":"Finally, the dataset is shared with active telecom professionals, whose performance is subsequently benchmarked against that of the LLMs.","meta":{"url":"http://arxiv.org/abs/2310.15051v1"},"cats":{"benchmark":0.4759055075,"new-dataset":0.3930108008,"data-annotation":0.4724065346,"dev-research":0.1431564013,"llms":0.6536192265,"data-quality":0.1214884228}}
{"text":"The findings illustrate that LLMs can rival the performance of active professionals in telecom knowledge, thanks to their capacity to process vast amounts of information, underscoring the potential of LLMs within this domain.","meta":{"url":"http://arxiv.org/abs/2310.15051v1"},"cats":{"benchmark":0.2128015359,"new-dataset":0.0289129863,"data-annotation":0.4831726861,"dev-research":0.231083607,"llms":0.7802128914,"data-quality":0.0902603005}}
{"text":"The dataset has been made publicly accessible on GitHub.","meta":{"url":"http://arxiv.org/abs/2310.15051v1"},"cats":{"benchmark":0.1782789662,"new-dataset":0.9724238791,"data-annotation":0.4840980838,"dev-research":0.1286243087,"llms":0.5387152344,"data-quality":0.0915965511}}
{"text":"The robotics community is increasingly interested in autonomous aerial transportation.","meta":{"url":"http://arxiv.org/abs/2310.15050v1"},"cats":{"benchmark":0.186922491,"new-dataset":0.0349246141,"data-annotation":0.5092335609,"dev-research":0.2139031155,"llms":0.506171657,"data-quality":0.0543438779}}
{"text":"Unmanned aerial vehicles with suspended payloads have advantages over other systems, including mechanical simplicity and agility, but pose great challenges in planning and control.","meta":{"url":"http://arxiv.org/abs/2310.15050v1"},"cats":{"benchmark":0.3364448712,"new-dataset":0.0193231794,"data-annotation":0.5042392926,"dev-research":0.2169819571,"llms":0.5147921846,"data-quality":0.047662532}}
{"text":"To realize fully autonomous aerial transportation, this paper presents a systematic solution to address these difficulties.","meta":{"url":"http://arxiv.org/abs/2310.15050v1"},"cats":{"benchmark":0.3023347099,"new-dataset":0.0261692513,"data-annotation":0.5061641461,"dev-research":0.2092092978,"llms":0.4618028394,"data-quality":0.0809047763}}
{"text":"First, we present a real-time planning method that generates smooth trajectories considering the time-varying shape and non-linear dynamics of the system, ensuring whole-body safety and dynamic feasibility.","meta":{"url":"http://arxiv.org/abs/2310.15050v1"},"cats":{"benchmark":0.3145645418,"new-dataset":0.0923541489,"data-annotation":0.489891826,"dev-research":0.2296731512,"llms":0.3631717084,"data-quality":0.0232680457}}
{"text":"Additionally, an adaptive NMPC with a hierarchical disturbance compensation strategy is designed to overcome unknown external perturbations and inaccurate model parameters.","meta":{"url":"http://arxiv.org/abs/2310.15050v1"},"cats":{"benchmark":0.4757618938,"new-dataset":0.0080676417,"data-annotation":0.4817062623,"dev-research":0.1707212429,"llms":0.4828066316,"data-quality":0.1661481925}}
{"text":"Extensive experiments show that our method is capable of generating high-quality trajectories online, even in highly constrained environments, and tracking aggressive flight trajectories accurately, even under significant uncertainty.","meta":{"url":"http://arxiv.org/abs/2310.15050v1"},"cats":{"benchmark":0.4634293642,"new-dataset":0.0786954351,"data-annotation":0.5113041397,"dev-research":0.1663326553,"llms":0.4008286834,"data-quality":0.0727939057}}
{"text":"We plan to release our code to benefit the community.","meta":{"url":"http://arxiv.org/abs/2310.15050v1"},"cats":{"benchmark":0.2224485178,"new-dataset":0.3412407371,"data-annotation":0.5301470193,"dev-research":0.4742240568,"llms":0.5373515459,"data-quality":0.1325866882}}
{"text":"Brown et al. (2020) famously introduced the phenomenon of in-context learning in large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2310.15047v1"},"cats":{"benchmark":0.1761754597,"new-dataset":0.0347958682,"data-annotation":0.5344815805,"dev-research":0.1162894687,"llms":0.6752340638,"data-quality":0.1400166312}}
{"text":"We establish the existence of a phenomenon we call $\\textbf{meta-out-of-context learning (meta-OCL)}$ via carefully designed synthetic experiments with LLMs.","meta":{"url":"http://arxiv.org/abs/2310.15047v1"},"cats":{"benchmark":0.2538699847,"new-dataset":0.026303291,"data-annotation":0.5342807371,"dev-research":0.1045657714,"llms":0.6178973798,"data-quality":0.1776017378}}
{"text":"Our results suggest that meta-OCL leads LLMs to more readily \"internalize\" the semantic content of text that is, or appears to be, broadly useful (such as true statements, or text from authoritative sources) and use it in appropriate circumstances.","meta":{"url":"http://arxiv.org/abs/2310.15047v1"},"cats":{"benchmark":0.263142862,"new-dataset":0.0204685697,"data-annotation":0.5039333668,"dev-research":0.2286300771,"llms":0.7414020791,"data-quality":0.2577768272}}
{"text":"We further demonstrate meta-OCL in a synthetic computer vision setting, and propose two hypotheses for the emergence of meta-OCL: one relying on the way models store knowledge in their parameters, and another suggesting that the implicit gradient alignment bias of gradient-descent-based optimizers may be responsible.","meta":{"url":"http://arxiv.org/abs/2310.15047v1"},"cats":{"benchmark":0.3066149582,"new-dataset":0.050994275,"data-annotation":0.5206923674,"dev-research":0.1942395245,"llms":0.4210980399,"data-quality":0.1323381842}}
{"text":"Finally, we reflect on what our results might imply about capabilities of future AI systems, and discuss potential risks.","meta":{"url":"http://arxiv.org/abs/2310.15047v1"},"cats":{"benchmark":0.2454816044,"new-dataset":0.047045209,"data-annotation":0.5360592914,"dev-research":0.2073972388,"llms":0.5234394838,"data-quality":0.1136869533}}
{"text":"Our code can be found at https://github.com/krasheninnikov/internalization .","meta":{"url":"http://arxiv.org/abs/2310.15047v1"},"cats":{"benchmark":0.3099895459,"new-dataset":0.2142928995,"data-annotation":0.5490301306,"dev-research":0.1453332513,"llms":0.4820377145,"data-quality":0.1463058293}}
{"text":"With the increasing integration of smartphones into our daily lives, fingerphotos are becoming a potential contactless authentication method.","meta":{"url":"http://arxiv.org/abs/2310.15044v1"},"cats":{"benchmark":0.2479574249,"new-dataset":0.0680181571,"data-annotation":0.5261135352,"dev-research":0.1755478583,"llms":0.526612379,"data-quality":0.0532804401}}
{"text":"While it offers convenience, it is also more vulnerable to spoofing using various presentation attack instruments (PAI).","meta":{"url":"http://arxiv.org/abs/2310.15044v1"},"cats":{"benchmark":0.36009807,"new-dataset":0.0080912102,"data-annotation":0.5024560383,"dev-research":0.2124401598,"llms":0.5352019626,"data-quality":0.0774422726}}
{"text":"The contactless fingerprint is an emerging biometric authentication but has not yet been heavily investigated for anti-spoofing.","meta":{"url":"http://arxiv.org/abs/2310.15044v1"},"cats":{"benchmark":0.4433886649,"new-dataset":0.0879876193,"data-annotation":0.5315994279,"dev-research":0.1816408777,"llms":0.5315260618,"data-quality":0.1105460991}}
{"text":"While existing anti-spoofing approaches demonstrated fair results, they have encountered challenges in terms of universality and scalability to detect any unseen/unknown spoofed samples.","meta":{"url":"http://arxiv.org/abs/2310.15044v1"},"cats":{"benchmark":0.5154691481,"new-dataset":0.1336234614,"data-annotation":0.5211263091,"dev-research":0.1553284141,"llms":0.5352028262,"data-quality":0.2732807551}}
{"text":"To address this issue, we propose a universal presentation attack detection method for contactless fingerprints, despite having limited knowledge of presentation attack samples.","meta":{"url":"http://arxiv.org/abs/2310.15044v1"},"cats":{"benchmark":0.29400003,"new-dataset":0.1522370083,"data-annotation":0.5439092103,"dev-research":0.1710744718,"llms":0.5516655971,"data-quality":0.1549898833}}
{"text":"We generated synthetic contactless fingerprints using StyleGAN from live finger photos and integrating them to train a semi-supervised ResNet-18 model.","meta":{"url":"http://arxiv.org/abs/2310.15044v1"},"cats":{"benchmark":0.261284973,"new-dataset":0.6063669955,"data-annotation":0.5034282455,"dev-research":0.1865198489,"llms":0.5281599583,"data-quality":0.1287964681}}
{"text":"A novel joint loss function, combining the Arcface and Center loss, is introduced with a regularization to balance between the two loss functions and minimize the variations within the live samples while enhancing the inter-class variations between the deepfake and live samples.","meta":{"url":"http://arxiv.org/abs/2310.15044v1"},"cats":{"benchmark":0.490716449,"new-dataset":0.0482095381,"data-annotation":0.5221303249,"dev-research":0.1676818108,"llms":0.4320245595,"data-quality":0.2510595467}}
{"text":"We also conducted a comprehensive comparison of different regularizations' impact on the joint loss function for presentation attack detection (PAD) and explored the performance of a modified ResNet-18 architecture with different activation functions (i.e., leaky ReLU and RelU) in conjunction with Arcface and center loss.","meta":{"url":"http://arxiv.org/abs/2310.15044v1"},"cats":{"benchmark":0.4201745495,"new-dataset":0.0255675016,"data-annotation":0.5388853413,"dev-research":0.2171701775,"llms":0.4709531685,"data-quality":0.2308189892}}
{"text":"Finally, we evaluate the performance of the model using unseen types of spoof attacks and live data.","meta":{"url":"http://arxiv.org/abs/2310.15044v1"},"cats":{"benchmark":0.455530903,"new-dataset":0.1627614631,"data-annotation":0.5092900863,"dev-research":0.1985080347,"llms":0.4461832842,"data-quality":0.1682006915}}
{"text":"Our proposed method achieves a Bona Fide Classification Error Rate (BPCER) of 0.12\\%, an Attack Presentation Classification Error Rate (APCER) of 0.63\\%, and an Average Classification Error Rate (ACER) of 0.37\\%.","meta":{"url":"http://arxiv.org/abs/2310.15044v1"},"cats":{"benchmark":0.5917530032,"new-dataset":0.0464843982,"data-annotation":0.5354277912,"dev-research":0.3463354975,"llms":0.4852414139,"data-quality":0.439447752}}
{"text":"In artificial intelligence, any model that wants to achieve a good result is inseparable from a large number of high-quality data.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.3505714316,"new-dataset":0.0488818631,"data-annotation":0.4954598093,"dev-research":0.2079825897,"llms":0.4423164639,"data-quality":0.1076588378}}
{"text":"It is especially true in the field of tamper detection.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.3079140961,"new-dataset":0.0067301242,"data-annotation":0.521980995,"dev-research":0.2140901237,"llms":0.563666504,"data-quality":0.2898685431}}
{"text":"This paper proposes a modified total variation noise reduction method to acquire high-quality tampered images.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.4665890917,"new-dataset":0.0335516774,"data-annotation":0.5024119137,"dev-research":0.1542443603,"llms":0.4562577828,"data-quality":0.2258645847}}
{"text":"We automatically crawl original and tampered images from the Baidu PS Bar.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.2883680061,"new-dataset":0.2198436525,"data-annotation":0.4946458263,"dev-research":0.1613169637,"llms":0.5446464566,"data-quality":0.2514446635}}
{"text":"Baidu PS Bar is a website where net friends post countless tampered images.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.2525396725,"new-dataset":0.4331529402,"data-annotation":0.4923960629,"dev-research":0.1929331574,"llms":0.5577584761,"data-quality":0.184434451}}
{"text":"Subtracting the original image with the tampered image can highlight the tampered area.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.3608205121,"new-dataset":0.0324506224,"data-annotation":0.5157443749,"dev-research":0.1570732155,"llms":0.4916421341,"data-quality":0.2631103025}}
{"text":"However, there is also substantial noise on the final print, so these images can't be directly used in the deep learning model.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.244485634,"new-dataset":0.1166404201,"data-annotation":0.5126925981,"dev-research":0.1507503042,"llms":0.5291016705,"data-quality":0.2291464782}}
{"text":"Our modified total variation noise reduction method is aimed at solving this problem.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.6275578962,"new-dataset":0.0322709881,"data-annotation":0.5419372579,"dev-research":0.1351879094,"llms":0.3621665411,"data-quality":0.2442561856}}
{"text":"Because a lot of text is slender, it is easy to lose text information after the opening and closing operation.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.2914345574,"new-dataset":0.0104359673,"data-annotation":0.5130585788,"dev-research":0.2181424453,"llms":0.5016312202,"data-quality":0.2560999635}}
{"text":"We use MSER (Maximally Stable Extremal Regions) and NMS (Non-maximum Suppression) technology to extract text information.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.4988261673,"new-dataset":0.0397958887,"data-annotation":0.5039709479,"dev-research":0.0910628632,"llms":0.5150981226,"data-quality":0.2689705806}}
{"text":"And then use the modified total variation noise reduction technology to process the subtracted image.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.5576207249,"new-dataset":0.0248992227,"data-annotation":0.514616127,"dev-research":0.1385297205,"llms":0.3921661283,"data-quality":0.1534144319}}
{"text":"Finally, we can obtain an image with little noise by adding the image and text information.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.2587147102,"new-dataset":0.2453624323,"data-annotation":0.5358535728,"dev-research":0.12395738,"llms":0.4952008658,"data-quality":0.2498421628}}
{"text":"And the idea also largely retains the text information.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.2312868885,"new-dataset":0.0158549081,"data-annotation":0.5147694834,"dev-research":0.2335670976,"llms":0.4963977517,"data-quality":0.1746348872}}
{"text":"Datasets generated in this way can be used in deep learning models, and they will help the model achieve better results.","meta":{"url":"http://arxiv.org/abs/2310.15041v1"},"cats":{"benchmark":0.2632500339,"new-dataset":0.4453099712,"data-annotation":0.5013691067,"dev-research":0.2252021749,"llms":0.482324237,"data-quality":0.1633783204}}
{"text":"The goal of compositional generalization benchmarks is to evaluate how well models generalize to new complex linguistic expressions.","meta":{"url":"http://arxiv.org/abs/2310.15040v1"},"cats":{"benchmark":0.5002847041,"new-dataset":0.0172921401,"data-annotation":0.5523133645,"dev-research":0.2088455532,"llms":0.4632513292,"data-quality":0.212033477}}
{"text":"Existing benchmarks often focus on lexical generalization, the interpretation of novel lexical items in syntactic structures familiar from training; structural generalization tasks, where a model needs to interpret syntactic structures that are themselves unfamiliar from training, are often underrepresented, resulting in overly optimistic perceptions of how well models can generalize.","meta":{"url":"http://arxiv.org/abs/2310.15040v1"},"cats":{"benchmark":0.4572488309,"new-dataset":0.0072876344,"data-annotation":0.5539340654,"dev-research":0.2089732847,"llms":0.4737950429,"data-quality":0.2761776593}}
{"text":"We introduce SLOG, a semantic parsing dataset that extends COGS (Kim and Linzen, 2020) with 17 structural generalization cases.","meta":{"url":"http://arxiv.org/abs/2310.15040v1"},"cats":{"benchmark":0.2510521025,"new-dataset":0.2859085191,"data-annotation":0.5024306023,"dev-research":0.1600914945,"llms":0.4976362285,"data-quality":0.2286539593}}
{"text":"In our experiments, the generalization accuracy of Transformer models, including pretrained ones, only reaches 40.6%, while a structure-aware parser only achieves 70.8%.","meta":{"url":"http://arxiv.org/abs/2310.15040v1"},"cats":{"benchmark":0.4065770257,"new-dataset":0.0127387668,"data-annotation":0.5194234334,"dev-research":0.1288994038,"llms":0.5288559026,"data-quality":0.1610432448}}
{"text":"These results are far from the near-perfect accuracy existing models achieve on COGS, demonstrating the role of SLOG in foregrounding the large discrepancy between models' lexical and structural generalization capacities.","meta":{"url":"http://arxiv.org/abs/2310.15040v1"},"cats":{"benchmark":0.4495526498,"new-dataset":0.0144084876,"data-annotation":0.533348131,"dev-research":0.1395120727,"llms":0.4581919772,"data-quality":0.2683659638}}
{"text":"Our paper presents a robust framework for UWB-based static gesture recognition, leveraging proprietary UWB radar sensor technology.","meta":{"url":"http://arxiv.org/abs/2310.15036v1"},"cats":{"benchmark":0.3531162843,"new-dataset":0.1739658614,"data-annotation":0.5147411194,"dev-research":0.2274138575,"llms":0.4523544705,"data-quality":0.1257580861}}
{"text":"Extensive data collection efforts were undertaken to compile datasets containing five commonly used gestures.","meta":{"url":"http://arxiv.org/abs/2310.15036v1"},"cats":{"benchmark":0.1950108046,"new-dataset":0.8373214523,"data-annotation":0.4982418279,"dev-research":0.3180805167,"llms":0.5588943535,"data-quality":0.0803089515}}
{"text":"Our approach involves a comprehensive data pre-processing pipeline that encompasses outlier handling, aspect ratio-preserving resizing, and false-color image transformation.","meta":{"url":"http://arxiv.org/abs/2310.15036v1"},"cats":{"benchmark":0.3994132608,"new-dataset":0.2428505045,"data-annotation":0.4712261413,"dev-research":0.2474755132,"llms":0.420376184,"data-quality":0.1999763883}}
{"text":"Both CNN and MobileNet models were trained on the processed images.","meta":{"url":"http://arxiv.org/abs/2310.15036v1"},"cats":{"benchmark":0.1788525727,"new-dataset":0.0739818742,"data-annotation":0.5065517735,"dev-research":0.1142349982,"llms":0.4872117527,"data-quality":0.147973421}}
{"text":"Remarkably, our best-performing model achieved an accuracy of 96.78%.","meta":{"url":"http://arxiv.org/abs/2310.15036v1"},"cats":{"benchmark":0.703814277,"new-dataset":0.0276686091,"data-annotation":0.5259742881,"dev-research":0.1400919553,"llms":0.4276378147,"data-quality":0.1614307764}}
{"text":"Additionally, we developed a user-friendly GUI framework to assess the model's system resource usage and processing times, which revealed low memory utilization and real-time task completion in under one second.","meta":{"url":"http://arxiv.org/abs/2310.15036v1"},"cats":{"benchmark":0.4733601348,"new-dataset":0.0873522866,"data-annotation":0.5242936608,"dev-research":0.3288789279,"llms":0.4808305516,"data-quality":0.0623012465}}
{"text":"This research marks a significant step towards enhancing static gesture recognition using UWB technology, promising practical applications in various domains.","meta":{"url":"http://arxiv.org/abs/2310.15036v1"},"cats":{"benchmark":0.3511947727,"new-dataset":0.0780241679,"data-annotation":0.5279630113,"dev-research":0.2467704621,"llms":0.5116962264,"data-quality":0.1113414483}}
{"text":"A deep autoencoder (DAE)-based structure for endto-end communication over the two-user Z-interference channel (ZIC) with finite-alphabet inputs is designed in this paper.","meta":{"url":"http://arxiv.org/abs/2310.15027v1"},"cats":{"benchmark":0.1843588107,"new-dataset":0.0604307977,"data-annotation":0.5001051054,"dev-research":0.2047197561,"llms":0.6002280413,"data-quality":0.1305683022}}
{"text":"The proposed structure jointly optimizes the two encoder/decoder pairs and generates interference-aware constellations that dynamically adapt their shape based on interference intensity to minimize the bit error rate (BER).","meta":{"url":"http://arxiv.org/abs/2310.15027v1"},"cats":{"benchmark":0.3426952298,"new-dataset":0.0294536475,"data-annotation":0.502086827,"dev-research":0.2301133412,"llms":0.5426081934,"data-quality":0.0992002477}}
{"text":"An in-phase/quadrature-phase (I/Q) power allocation layer is introduced in the DAE to guarantee an average power constraint and enable the architecture to generate constellations with nonuniform shapes.","meta":{"url":"http://arxiv.org/abs/2310.15027v1"},"cats":{"benchmark":0.3081081801,"new-dataset":0.0144295039,"data-annotation":0.5008517873,"dev-research":0.1915938606,"llms":0.506277046,"data-quality":0.0829715727}}
{"text":"This brings further gain compared to standard uniform constellations such as quadrature amplitude modulation.","meta":{"url":"http://arxiv.org/abs/2310.15027v1"},"cats":{"benchmark":0.4689343736,"new-dataset":0.0023504176,"data-annotation":0.5065374683,"dev-research":0.1159036514,"llms":0.4627691699,"data-quality":0.0686323958}}
{"text":"The proposed structure is then extended to work with imperfect channel state information (CSI).","meta":{"url":"http://arxiv.org/abs/2310.15027v1"},"cats":{"benchmark":0.2995412772,"new-dataset":0.0379363095,"data-annotation":0.493204801,"dev-research":0.145432384,"llms":0.511170413,"data-quality":0.1178844169}}
{"text":"The CSI imperfection due to both the estimation and quantization errors are examined.","meta":{"url":"http://arxiv.org/abs/2310.15027v1"},"cats":{"benchmark":0.5266657555,"new-dataset":0.0301998998,"data-annotation":0.5093489649,"dev-research":0.2010634722,"llms":0.3772972702,"data-quality":0.3482100071}}
{"text":"The performance of the DAEZIC is compared with two baseline methods, i.e., standard and rotated constellations.","meta":{"url":"http://arxiv.org/abs/2310.15027v1"},"cats":{"benchmark":0.6396488434,"new-dataset":0.017454248,"data-annotation":0.5083951373,"dev-research":0.1530353984,"llms":0.4663901924,"data-quality":0.0646359858}}
{"text":"The proposed structure significantly enhances the performance of the ZIC both for the perfect and imperfect CSI.","meta":{"url":"http://arxiv.org/abs/2310.15027v1"},"cats":{"benchmark":0.4991864951,"new-dataset":0.0397246736,"data-annotation":0.4967265198,"dev-research":0.164041985,"llms":0.4860922349,"data-quality":0.0913264944}}
{"text":"Simulation results show that the improvement is achieved in all interference regimes (weak, moderate, and strong) and consistently increases with the signal-to-noise ratio (SNR).","meta":{"url":"http://arxiv.org/abs/2310.15027v1"},"cats":{"benchmark":0.5646014079,"new-dataset":0.0109728795,"data-annotation":0.4986024606,"dev-research":0.1695507798,"llms":0.5380367203,"data-quality":0.2014781014}}
{"text":"For example, more than an order of magnitude BER reduction is obtained with respect to the most competitive conventional method at weak interference when SNR>15dB and two bits per symbol are transmitted.","meta":{"url":"http://arxiv.org/abs/2310.15027v1"},"cats":{"benchmark":0.5294869923,"new-dataset":0.0074881109,"data-annotation":0.5265018828,"dev-research":0.1330991189,"llms":0.5315637639,"data-quality":0.1351901097}}
{"text":"The improvements reach about two orders of magnitude when quantization error exists, indicating that the DAE-ZIC is more robust to the interference compared to the conventional methods.","meta":{"url":"http://arxiv.org/abs/2310.15027v1"},"cats":{"benchmark":0.5288175665,"new-dataset":0.0045076198,"data-annotation":0.5084666764,"dev-research":0.2066153689,"llms":0.4715536152,"data-quality":0.2209115207}}
{"text":"Recently, Transformer-based models have achieved promising results in various vision tasks, due to their ability to model long-range dependencies.","meta":{"url":"http://arxiv.org/abs/2310.15025v1"},"cats":{"benchmark":0.2669427347,"new-dataset":0.0254379623,"data-annotation":0.4985014991,"dev-research":0.1248102014,"llms":0.464404347,"data-quality":0.0554295608}}
{"text":"However, transformers are computationally expensive, which limits their applications in real-time tasks such as autonomous driving.","meta":{"url":"http://arxiv.org/abs/2310.15025v1"},"cats":{"benchmark":0.2900724833,"new-dataset":0.0062600655,"data-annotation":0.5030131984,"dev-research":0.2133739721,"llms":0.4611980472,"data-quality":0.0351690589}}
{"text":"In addition, an efficient local and global feature selection and fusion are vital for accurate dense prediction, especially driving scene understanding tasks.","meta":{"url":"http://arxiv.org/abs/2310.15025v1"},"cats":{"benchmark":0.3942774452,"new-dataset":0.05229712,"data-annotation":0.5131926024,"dev-research":0.2130598421,"llms":0.4207503993,"data-quality":0.1016118543}}
{"text":"In this paper, we propose a real-time semantic segmentation architecture named Pyramid Pooling Axial Transformer (P2AT).","meta":{"url":"http://arxiv.org/abs/2310.15025v1"},"cats":{"benchmark":0.2176176373,"new-dataset":0.1822488374,"data-annotation":0.4980438777,"dev-research":0.158188215,"llms":0.4271683581,"data-quality":0.1422037701}}
{"text":"The proposed P2AT takes a coarse feature from the CNN encoder to produce scale-aware contextual features, which are then combined with the multi-level feature aggregation scheme to produce enhanced contextual features.","meta":{"url":"http://arxiv.org/abs/2310.15025v1"},"cats":{"benchmark":0.2452237806,"new-dataset":0.1237790196,"data-annotation":0.5028417552,"dev-research":0.1553268691,"llms":0.4844194919,"data-quality":0.1130808298}}
{"text":"Specifically, we introduce a pyramid pooling axial transformer to capture intricate spatial and channel dependencies, leading to improved performance on semantic segmentation.","meta":{"url":"http://arxiv.org/abs/2310.15025v1"},"cats":{"benchmark":0.2231461621,"new-dataset":0.1268344259,"data-annotation":0.4975021443,"dev-research":0.1691771206,"llms":0.4746622097,"data-quality":0.155115503}}
{"text":"Then, we design a Bidirectional Fusion module (BiF) to combine semantic information at different levels.","meta":{"url":"http://arxiv.org/abs/2310.15025v1"},"cats":{"benchmark":0.2906577205,"new-dataset":0.0497395391,"data-annotation":0.4841275372,"dev-research":0.2083936632,"llms":0.6026676461,"data-quality":0.1674521874}}
{"text":"Meanwhile, a Global Context Enhancer is introduced to compensate for the inadequacy of concatenating different semantic levels.","meta":{"url":"http://arxiv.org/abs/2310.15025v1"},"cats":{"benchmark":0.348375711,"new-dataset":0.0138628698,"data-annotation":0.5080933533,"dev-research":0.2099466239,"llms":0.5564154276,"data-quality":0.3017302507}}
{"text":"Finally, a decoder block is proposed to help maintain a larger receptive field.","meta":{"url":"http://arxiv.org/abs/2310.15025v1"},"cats":{"benchmark":0.2313581313,"new-dataset":0.0458917668,"data-annotation":0.5277188275,"dev-research":0.1759835162,"llms":0.474520005,"data-quality":0.1575256871}}
{"text":"We evaluate P2AT variants on three challenging scene-understanding datasets.","meta":{"url":"http://arxiv.org/abs/2310.15025v1"},"cats":{"benchmark":0.2814856597,"new-dataset":0.7438495455,"data-annotation":0.5233169714,"dev-research":0.1570091342,"llms":0.4533384272,"data-quality":0.2009253545}}
{"text":"In particular, our P2AT variants achieve state-of-art results on the Camvid dataset 80.5%, 81.0%, 81.1% for P2AT-S, P2ATM, and P2AT-L, respectively.","meta":{"url":"http://arxiv.org/abs/2310.15025v1"},"cats":{"benchmark":0.5213843932,"new-dataset":0.4862735575,"data-annotation":0.5250643479,"dev-research":0.1164359462,"llms":0.5146856783,"data-quality":0.125866534}}
{"text":"Furthermore, our experiment on Cityscapes and Pascal VOC 2012 have demonstrated the efficiency of the proposed architecture, with results showing that P2AT-M, achieves 78.7% on Cityscapes.","meta":{"url":"http://arxiv.org/abs/2310.15025v1"},"cats":{"benchmark":0.5741848807,"new-dataset":0.0657592817,"data-annotation":0.5039930441,"dev-research":0.1529957037,"llms":0.4981113312,"data-quality":0.0625969892}}
{"text":"The source code will be available at","meta":{"url":"http://arxiv.org/abs/2310.15025v1"},"cats":{"benchmark":0.1959276306,"new-dataset":0.5203233378,"data-annotation":0.5291587623,"dev-research":0.3105172755,"llms":0.5682143638,"data-quality":0.128081179}}
{"text":"With the rise of popular task automation or IoT platforms such as 'If This Then That (IFTTT)', users can define rules to enable interactions between smart devices in their environment and thereby improve their daily lives.","meta":{"url":"http://arxiv.org/abs/2310.15024v1"},"cats":{"benchmark":0.24426106,"new-dataset":0.0309539092,"data-annotation":0.4981958721,"dev-research":0.3482701296,"llms":0.5408989701,"data-quality":0.060558255}}
{"text":"However, the rules authored via these platforms are usually tied to the platforms and sometimes even to the specific devices for which they have been defined.","meta":{"url":"http://arxiv.org/abs/2310.15024v1"},"cats":{"benchmark":0.2978225539,"new-dataset":0.0387361122,"data-annotation":0.4798675941,"dev-research":0.2739586956,"llms":0.5075895945,"data-quality":0.1127023477}}
{"text":"Therefore, when a user wishes to move to a different environment controlled by a different platform and/or devices, they need to recreate their rules for the new environment.","meta":{"url":"http://arxiv.org/abs/2310.15024v1"},"cats":{"benchmark":0.2221509582,"new-dataset":0.0696660038,"data-annotation":0.458714695,"dev-research":0.4231941087,"llms":0.5463430972,"data-quality":0.0901577178}}
{"text":"The rise in the number of smart devices further adds to the complexity of rule authoring since users will have to navigate an ever-changing landscape of IoT devices.","meta":{"url":"http://arxiv.org/abs/2310.15024v1"},"cats":{"benchmark":0.3436404623,"new-dataset":0.0318599796,"data-annotation":0.5066252308,"dev-research":0.3250317233,"llms":0.5477965119,"data-quality":0.0630751753}}
{"text":"In order to address this problem, we need human-computer interaction that works across the boundaries of specific IoT platforms and devices.","meta":{"url":"http://arxiv.org/abs/2310.15024v1"},"cats":{"benchmark":0.2233233138,"new-dataset":0.1373182996,"data-annotation":0.5060373707,"dev-research":0.2479389629,"llms":0.5652332866,"data-quality":0.0547488099}}
{"text":"A step towards this human-computer interaction across platforms and devices is the introduction of a high-level semantic model for end-user IoT development, enabling users to create rules at a higher level of abstraction.","meta":{"url":"http://arxiv.org/abs/2310.15024v1"},"cats":{"benchmark":0.1883894006,"new-dataset":0.1907181864,"data-annotation":0.4886829324,"dev-research":0.3929618857,"llms":0.5920391979,"data-quality":0.0787221606}}
{"text":"However, many users who already got used to the rule representation in their favourite tool might be unwilling to learn and adapt to a new representation.","meta":{"url":"http://arxiv.org/abs/2310.15024v1"},"cats":{"benchmark":0.246558285,"new-dataset":0.0071763758,"data-annotation":0.5201844553,"dev-research":0.4570314378,"llms":0.5632340619,"data-quality":0.1908032235}}
{"text":"We present a method for translating proprietary rules to a high-level semantic model by using natural language processing techniques.","meta":{"url":"http://arxiv.org/abs/2310.15024v1"},"cats":{"benchmark":0.2692177379,"new-dataset":0.2656438335,"data-annotation":0.5011103237,"dev-research":0.3295422698,"llms":0.5293701989,"data-quality":0.3009246499}}
{"text":"Our translation enables users to work with their familiar rule representation language and tool, and at the same time apply their rules across different IoT platforms and devices.","meta":{"url":"http://arxiv.org/abs/2310.15024v1"},"cats":{"benchmark":0.2899406053,"new-dataset":0.0905573931,"data-annotation":0.4838863986,"dev-research":0.3543253513,"llms":0.6068118344,"data-quality":0.1114289237}}
{"text":"In this paper, we address the challenging problem of data association for underwater SLAM through a novel method for sonar image correspondence using learned features.","meta":{"url":"http://arxiv.org/abs/2310.15023v1"},"cats":{"benchmark":0.3294497016,"new-dataset":0.2098099448,"data-annotation":0.496348556,"dev-research":0.1837996187,"llms":0.4063399291,"data-quality":0.2159131153}}
{"text":"We introduce SONIC (SONar Image Correspondence), a pose-supervised network designed to yield robust feature correspondence capable of withstanding viewpoint variations.","meta":{"url":"http://arxiv.org/abs/2310.15023v1"},"cats":{"benchmark":0.2965594207,"new-dataset":0.2082802416,"data-annotation":0.5123429434,"dev-research":0.1894612871,"llms":0.4367404652,"data-quality":0.1381811794}}
{"text":"The inherent complexity of the underwater environment stems from the dynamic and frequently limited visibility conditions, restricting vision to a few meters of often featureless expanses.","meta":{"url":"http://arxiv.org/abs/2310.15023v1"},"cats":{"benchmark":0.2360515005,"new-dataset":0.0307650218,"data-annotation":0.5018027601,"dev-research":0.2093946975,"llms":0.4438027418,"data-quality":0.042908132}}
{"text":"This makes camera-based systems suboptimal in most open water application scenarios.","meta":{"url":"http://arxiv.org/abs/2310.15023v1"},"cats":{"benchmark":0.3195521674,"new-dataset":0.0265889725,"data-annotation":0.4757810819,"dev-research":0.1948076414,"llms":0.4892915849,"data-quality":0.0580142503}}
{"text":"Consequently, multibeam imaging sonars emerge as the preferred choice for perception sensors.","meta":{"url":"http://arxiv.org/abs/2310.15023v1"},"cats":{"benchmark":0.2939293537,"new-dataset":0.0182810543,"data-annotation":0.502483779,"dev-research":0.135928877,"llms":0.488121016,"data-quality":0.0895790998}}
{"text":"However, they too are not without their limitations.","meta":{"url":"http://arxiv.org/abs/2310.15023v1"},"cats":{"benchmark":0.2729875676,"new-dataset":0.0142557875,"data-annotation":0.5047599568,"dev-research":0.1766070838,"llms":0.5598531946,"data-quality":0.0933976539}}
{"text":"While imaging sonars offer superior long-range visibility compared to cameras, their measurements can appear different from varying viewpoints.","meta":{"url":"http://arxiv.org/abs/2310.15023v1"},"cats":{"benchmark":0.3987791057,"new-dataset":0.042945143,"data-annotation":0.5070089794,"dev-research":0.1689171895,"llms":0.4541985401,"data-quality":0.1006110811}}
{"text":"This inherent variability presents formidable challenges in data association, particularly for feature-based methods.","meta":{"url":"http://arxiv.org/abs/2310.15023v1"},"cats":{"benchmark":0.417974977,"new-dataset":0.0411660384,"data-annotation":0.4874991909,"dev-research":0.3245907167,"llms":0.3982273927,"data-quality":0.3504072745}}
{"text":"Our method demonstrates significantly better performance in generating correspondences for sonar images which will pave the way for more accurate loop closure constraints and sonar-based place recognition.","meta":{"url":"http://arxiv.org/abs/2310.15023v1"},"cats":{"benchmark":0.3965077568,"new-dataset":0.2023372039,"data-annotation":0.5211121228,"dev-research":0.1860161808,"llms":0.4810540546,"data-quality":0.1916171745}}
{"text":"Code as well as simulated and real-world datasets will be made public to facilitate further development in the field.","meta":{"url":"http://arxiv.org/abs/2310.15023v1"},"cats":{"benchmark":0.1554050355,"new-dataset":0.7104778617,"data-annotation":0.4955145647,"dev-research":0.2788541877,"llms":0.4976851303,"data-quality":0.0878401429}}
{"text":"Open Information Extraction (OpenIE) is a fundamental yet challenging task in Natural Language Processing, which involves extracting all triples (subject, predicate, object) from a given sentence.","meta":{"url":"http://arxiv.org/abs/2310.15021v1"},"cats":{"benchmark":0.2631088629,"new-dataset":0.1810707027,"data-annotation":0.5291318484,"dev-research":0.1522945324,"llms":0.4960272734,"data-quality":0.1864614506}}
{"text":"While labeling-based methods have their merits, generation-based techniques offer unique advantages, such as the ability to generate tokens not present in the original sentence.","meta":{"url":"http://arxiv.org/abs/2310.15021v1"},"cats":{"benchmark":0.2994692557,"new-dataset":0.0052626511,"data-annotation":0.5259731338,"dev-research":0.2571489575,"llms":0.5995413554,"data-quality":0.4129995941}}
{"text":"However, these generation-based methods often require a significant amount of training data to learn the task form of OpenIE and substantial training time to overcome slow model convergence due to the order penalty.","meta":{"url":"http://arxiv.org/abs/2310.15021v1"},"cats":{"benchmark":0.3541756427,"new-dataset":0.0355959878,"data-annotation":0.5256388973,"dev-research":0.1724381743,"llms":0.4817212648,"data-quality":0.081150281}}
{"text":"In this paper, we introduce a novel framework, OK-IE, that ingeniously transforms the task form of OpenIE into the pre-training task form of the T5 model, thereby reducing the need for extensive training data.","meta":{"url":"http://arxiv.org/abs/2310.15021v1"},"cats":{"benchmark":0.2200528711,"new-dataset":0.1512022555,"data-annotation":0.5231582518,"dev-research":0.1705097965,"llms":0.4925902955,"data-quality":0.0794765113}}
{"text":"Furthermore, we introduce an innovative concept of Anchor to control the sequence of model outputs, effectively eliminating the impact of order penalty on model convergence and significantly reducing training time.","meta":{"url":"http://arxiv.org/abs/2310.15021v1"},"cats":{"benchmark":0.5570866582,"new-dataset":0.0108130809,"data-annotation":0.5161830128,"dev-research":0.2030080376,"llms":0.3847093084,"data-quality":0.1317330806}}
{"text":"Experimental results indicate that, compared to previous SOTA methods, OK-IE requires only 1/100 of the training data (900 instances) and 1/120 of the training time (3 minutes) to achieve comparable results.","meta":{"url":"http://arxiv.org/abs/2310.15021v1"},"cats":{"benchmark":0.471459976,"new-dataset":0.0384216491,"data-annotation":0.5118578523,"dev-research":0.1135524215,"llms":0.4896266119,"data-quality":0.1109328042}}
{"text":"The data-driven approach to robot control has been gathering pace rapidly, yet generalization to unseen task domains remains a critical challenge.","meta":{"url":"http://arxiv.org/abs/2310.15020v1"},"cats":{"benchmark":0.2326812819,"new-dataset":0.1076668897,"data-annotation":0.4717925509,"dev-research":0.2081782199,"llms":0.4442671824,"data-quality":0.088302285}}
{"text":"We argue that the key to generalization is representations that are (i) rich enough to capture all task-relevant information and (ii) invariant to superfluous variability between the training and the test domains.","meta":{"url":"http://arxiv.org/abs/2310.15020v1"},"cats":{"benchmark":0.3504162702,"new-dataset":0.0110732353,"data-annotation":0.5478835697,"dev-research":0.1706572077,"llms":0.456783494,"data-quality":0.1661747948}}
{"text":"We experimentally study such a representation -- containing both depth and semantic information -- for visual navigation and show that it enables a control policy trained entirely in simulated indoor scenes to generalize to diverse real-world environments, both indoors and outdoors.","meta":{"url":"http://arxiv.org/abs/2310.15020v1"},"cats":{"benchmark":0.1587010385,"new-dataset":0.2264342079,"data-annotation":0.4988093392,"dev-research":0.2382846649,"llms":0.4941030852,"data-quality":0.0898843491}}
{"text":"Further, we show that our representation reduces the A-distance between the training and test domains, improving the generalization error bound as a result.","meta":{"url":"http://arxiv.org/abs/2310.15020v1"},"cats":{"benchmark":0.5114217371,"new-dataset":0.0302257137,"data-annotation":0.5686158884,"dev-research":0.1666782906,"llms":0.4161153344,"data-quality":0.3317215689}}
{"text":"Our proposed approach is scalable: the learned policy improves continuously, as the foundation models that it exploits absorb more diverse data during pre-training.","meta":{"url":"http://arxiv.org/abs/2310.15020v1"},"cats":{"benchmark":0.2716152264,"new-dataset":0.0796578684,"data-annotation":0.4957266072,"dev-research":0.137239123,"llms":0.4518973327,"data-quality":0.1126932284}}
{"text":"Detecting out of policy speech (OOPS) content is important but difficult.","meta":{"url":"http://arxiv.org/abs/2310.15019v1"},"cats":{"benchmark":0.2839550343,"new-dataset":0.1000009416,"data-annotation":0.5324916588,"dev-research":0.2397948783,"llms":0.5713138699,"data-quality":0.363411163}}
{"text":"While machine learning is a powerful tool to tackle this challenging task, it is hard to break the performance ceiling due to factors like quantity and quality limitations on training data and inconsistencies in OOPS definition and data labeling.","meta":{"url":"http://arxiv.org/abs/2310.15019v1"},"cats":{"benchmark":0.3777793621,"new-dataset":0.0928881544,"data-annotation":0.5027196281,"dev-research":0.3432049673,"llms":0.5044782838,"data-quality":0.3714910514}}
{"text":"To realize the full potential of available limited resources, we propose a meta learning technique (MLT) that combines individual models built with different text representations.","meta":{"url":"http://arxiv.org/abs/2310.15019v1"},"cats":{"benchmark":0.2859764181,"new-dataset":0.0584943054,"data-annotation":0.5305500452,"dev-research":0.147445784,"llms":0.4619146317,"data-quality":0.1817387325}}
{"text":"We analytically show that the resulting technique is numerically stable and produces reasonable combining weights.","meta":{"url":"http://arxiv.org/abs/2310.15019v1"},"cats":{"benchmark":0.6922573008,"new-dataset":0.0061742395,"data-annotation":0.5425772617,"dev-research":0.1035188135,"llms":0.3912207044,"data-quality":0.1259321938}}
{"text":"We combine the MLT with a threshold-moving (TM) technique to further improve the performance of the combined predictor on highly-imbalanced in-distribution and out-of-distribution datasets.","meta":{"url":"http://arxiv.org/abs/2310.15019v1"},"cats":{"benchmark":0.4989980012,"new-dataset":0.0717659982,"data-annotation":0.5164467597,"dev-research":0.1154096353,"llms":0.4371214009,"data-quality":0.1777820627}}
{"text":"We also provide computational results to show the statistically significant advantages of the proposed MLT approach.   ","meta":{"url":"http://arxiv.org/abs/2310.15019v1"},"cats":{"benchmark":0.6621839618,"new-dataset":0.0081483859,"data-annotation":0.5282337581,"dev-research":0.1244614269,"llms":0.3748245973,"data-quality":0.0878079752}}
{"text":"All authors contributed equally to this work.","meta":{"url":"http://arxiv.org/abs/2310.15019v1"},"cats":{"benchmark":0.360573006,"new-dataset":0.063869751,"data-annotation":0.5278273222,"dev-research":0.1395322337,"llms":0.4855628608,"data-quality":0.0907269024}}
{"text":"The primacy bias in deep reinforcement learning (DRL), which refers to the agent's tendency to overfit early data and lose the ability to learn from new data, can significantly decrease the performance of DRL algorithms.","meta":{"url":"http://arxiv.org/abs/2310.15017v1"},"cats":{"benchmark":0.3114964397,"new-dataset":0.0325839465,"data-annotation":0.5154531095,"dev-research":0.2098026826,"llms":0.5105434173,"data-quality":0.0994538425}}
{"text":"Previous studies have shown that employing simple techniques, such as resetting the agent's parameters, can substantially alleviate the primacy bias.","meta":{"url":"http://arxiv.org/abs/2310.15017v1"},"cats":{"benchmark":0.4905622468,"new-dataset":0.0010501272,"data-annotation":0.5116018327,"dev-research":0.2041992634,"llms":0.4631735577,"data-quality":0.121062448}}
{"text":"However, we observe that resetting the agent's parameters harms its performance in the context of model-based reinforcement learning (MBRL).","meta":{"url":"http://arxiv.org/abs/2310.15017v1"},"cats":{"benchmark":0.292966982,"new-dataset":0.0088068059,"data-annotation":0.4947768122,"dev-research":0.172360711,"llms":0.4822671729,"data-quality":0.1044252082}}
{"text":"In fact, on further investigation, we find that the primacy bias in MBRL differs from that in model-free RL.","meta":{"url":"http://arxiv.org/abs/2310.15017v1"},"cats":{"benchmark":0.4395011059,"new-dataset":0.0193186709,"data-annotation":0.5128807584,"dev-research":0.1007830343,"llms":0.5288812765,"data-quality":0.0861068005}}
{"text":"In this work, we focus on investigating the primacy bias in MBRL and propose world model resetting, which works in MBRL.","meta":{"url":"http://arxiv.org/abs/2310.15017v1"},"cats":{"benchmark":0.3672532927,"new-dataset":0.0348908111,"data-annotation":0.4817261539,"dev-research":0.1571428909,"llms":0.5242891709,"data-quality":0.1145406684}}
{"text":"We apply our method to two different MBRL algorithms, MBPO and DreamerV2.","meta":{"url":"http://arxiv.org/abs/2310.15017v1"},"cats":{"benchmark":0.5931461053,"new-dataset":0.048903622,"data-annotation":0.5149450026,"dev-research":0.1240927231,"llms":0.4562986694,"data-quality":0.0803461689}}
{"text":"We validate the effectiveness of our method on multiple continuous control tasks on MuJoCo and DeepMind Control Suite, as well as discrete control tasks on Atari 100k benchmark.","meta":{"url":"http://arxiv.org/abs/2310.15017v1"},"cats":{"benchmark":0.3641066208,"new-dataset":0.1313393362,"data-annotation":0.4893635483,"dev-research":0.1962734165,"llms":0.5347473987,"data-quality":0.0670325978}}
{"text":"The results show that world model resetting can significantly alleviate the primacy bias in model-based setting and improve algorithm's performance.","meta":{"url":"http://arxiv.org/abs/2310.15017v1"},"cats":{"benchmark":0.4967327691,"new-dataset":0.0056438036,"data-annotation":0.4964839303,"dev-research":0.2143040527,"llms":0.4372958448,"data-quality":0.1545288118}}
{"text":"We also give a guide on how to perform world model resetting effectively.","meta":{"url":"http://arxiv.org/abs/2310.15017v1"},"cats":{"benchmark":0.3141749045,"new-dataset":0.1235193826,"data-annotation":0.4932204406,"dev-research":0.1921489637,"llms":0.5097462376,"data-quality":0.1204917913}}
{"text":"Usually, programming languages have official documentation to guide developers with APIs, methods, and classes.","meta":{"url":"http://arxiv.org/abs/2310.15015v1"},"cats":{"benchmark":0.1983495484,"new-dataset":0.111735018,"data-annotation":0.5306028667,"dev-research":0.6518832015,"llms":0.5878250842,"data-quality":0.1494382193}}
{"text":"However, researchers identified insufficient or inadequate documentation examples and flaws with the API's complex structure as barriers to learning an API.","meta":{"url":"http://arxiv.org/abs/2310.15015v1"},"cats":{"benchmark":0.2208094157,"new-dataset":0.0086830068,"data-annotation":0.5178863678,"dev-research":0.3838194621,"llms":0.5834009678,"data-quality":0.2392908957}}
{"text":"As a result, developers may consult other sources (StackOverflow, GitHub, etc.) to learn more about an API.","meta":{"url":"http://arxiv.org/abs/2310.15015v1"},"cats":{"benchmark":0.1601266092,"new-dataset":0.0448803632,"data-annotation":0.5283668831,"dev-research":0.382192123,"llms":0.5885442492,"data-quality":0.0952880955}}
{"text":"Recent research studies have shown that unofficial documentation is a valuable source of information for generating code summaries.","meta":{"url":"http://arxiv.org/abs/2310.15015v1"},"cats":{"benchmark":0.3240746739,"new-dataset":0.1925853522,"data-annotation":0.5455939457,"dev-research":0.5828732639,"llms":0.5553918117,"data-quality":0.2120743878}}
{"text":"We, therefore, have been motivated to leverage such a type of documentation along with deep learning techniques towards generating high-quality summaries for APIs discussed in informal documentation.   ","meta":{"url":"http://arxiv.org/abs/2310.15015v1"},"cats":{"benchmark":0.2667581444,"new-dataset":0.1841395512,"data-annotation":0.5467731272,"dev-research":0.3158736041,"llms":0.5798354562,"data-quality":0.1898797011}}
{"text":"This paper proposes an automatic approach using the BART algorithm, a state-of-the-art transformer model, to generate summaries for APIs discussed in StackOverflow.","meta":{"url":"http://arxiv.org/abs/2310.15015v1"},"cats":{"benchmark":0.3667096207,"new-dataset":0.0921998101,"data-annotation":0.531289497,"dev-research":0.2671081962,"llms":0.5335289547,"data-quality":0.139376538}}
{"text":"We built an oracle of human-generated summaries to evaluate our approach against it using ROUGE and BLEU metrics which are the most widely used evaluation metrics in text summarization.","meta":{"url":"http://arxiv.org/abs/2310.15015v1"},"cats":{"benchmark":0.5435553846,"new-dataset":0.1010987454,"data-annotation":0.559757696,"dev-research":0.2965947196,"llms":0.540631675,"data-quality":0.2086284773}}
{"text":"Furthermore, we evaluated our summaries empirically against a previous work in terms of quality.","meta":{"url":"http://arxiv.org/abs/2310.15015v1"},"cats":{"benchmark":0.6137206895,"new-dataset":0.035788828,"data-annotation":0.5531496269,"dev-research":0.2940752804,"llms":0.5184562855,"data-quality":0.2136013324}}
{"text":"Our findings demonstrate that using deep learning algorithms can improve summaries' quality and outperform the previous work by an average of %57 for Precision, %66 for Recall, and %61 for F-measure, and it runs 4.4 times faster.","meta":{"url":"http://arxiv.org/abs/2310.15015v1"},"cats":{"benchmark":0.4728151433,"new-dataset":0.0786607996,"data-annotation":0.5478295481,"dev-research":0.2599570717,"llms":0.5573225544,"data-quality":0.2168817416}}
{"text":"A spectrum-sharing satellite-ground integrated network is conceived, consisting of a pair of non-geostationary orbit (NGSO) constellations and multiple terrestrial base stations, which impose the co-frequency interference (CFI) on each other.","meta":{"url":"http://arxiv.org/abs/2310.15011v1"},"cats":{"benchmark":0.3014304131,"new-dataset":0.0433366517,"data-annotation":0.4756588372,"dev-research":0.1530615314,"llms":0.4376531343,"data-quality":0.0914951864}}
{"text":"The CFI may increase upon increasing the number of satellites.","meta":{"url":"http://arxiv.org/abs/2310.15011v1"},"cats":{"benchmark":0.3139941675,"new-dataset":0.0421054961,"data-annotation":0.5043417636,"dev-research":0.1661862425,"llms":0.4418987098,"data-quality":0.0633262057}}
{"text":"To manage the potentially severe interference, we propose to rely on joint multi-domain resource aided interference management (JMDR-IM).","meta":{"url":"http://arxiv.org/abs/2310.15011v1"},"cats":{"benchmark":0.3564610019,"new-dataset":0.0281444808,"data-annotation":0.4754395043,"dev-research":0.2101076008,"llms":0.6011498673,"data-quality":0.1460513385}}
{"text":"Specifically, the coverage overlap of the constellations considered is analyzed.","meta":{"url":"http://arxiv.org/abs/2310.15011v1"},"cats":{"benchmark":0.4236687157,"new-dataset":0.0505779539,"data-annotation":0.5136245706,"dev-research":0.1653758938,"llms":0.4804338157,"data-quality":0.0711220269}}
{"text":"Then, multi-domain resources - including both the beam-domain and power-domain - are jointly utilized for managing the CFI in an overlapping coverage region.","meta":{"url":"http://arxiv.org/abs/2310.15011v1"},"cats":{"benchmark":0.3323661462,"new-dataset":0.020301163,"data-annotation":0.4746725902,"dev-research":0.2003618326,"llms":0.5295198008,"data-quality":0.0688303467}}
{"text":"This joint resource utilization is performed by relying on our specifically designed beam-shut-off and switching based beam scheduling, as well as on long short-term memory based joint autoregressive moving average assisted deep Q network aided power scheduling.","meta":{"url":"http://arxiv.org/abs/2310.15011v1"},"cats":{"benchmark":0.3271680932,"new-dataset":0.0423045919,"data-annotation":0.5058692006,"dev-research":0.1571380288,"llms":0.5004874178,"data-quality":0.0561218691}}
{"text":"Moreover, the outage probability (OP) of the proposed JMDR-IM scheme is derived, and the asymptotic analysis of the OP is also provided.","meta":{"url":"http://arxiv.org/abs/2310.15011v1"},"cats":{"benchmark":0.4949241423,"new-dataset":0.0169914914,"data-annotation":0.5269622683,"dev-research":0.1085976297,"llms":0.4761240541,"data-quality":0.0910097136}}
{"text":"Our performance evaluations demonstrate the superiority of the proposed JMDR-IM scheme in terms of its increased throughput and reduced OP.","meta":{"url":"http://arxiv.org/abs/2310.15011v1"},"cats":{"benchmark":0.5926848753,"new-dataset":0.0058759145,"data-annotation":0.4936607765,"dev-research":0.107819696,"llms":0.5625159976,"data-quality":0.0553325227}}
{"text":"The popularity of transformer-based text embeddings calls for better statistical tools for measuring distributions of such embeddings.","meta":{"url":"http://arxiv.org/abs/2310.15010v1"},"cats":{"benchmark":0.4590315725,"new-dataset":0.0536053678,"data-annotation":0.5376387195,"dev-research":0.1460227482,"llms":0.4995389842,"data-quality":0.2185954804}}
{"text":"One such tool would be a method for ranking texts within a corpus by centrality, i.e. assigning each text a number signifying how representative that text is of the corpus as a whole.","meta":{"url":"http://arxiv.org/abs/2310.15010v1"},"cats":{"benchmark":0.5562270604,"new-dataset":0.2281224738,"data-annotation":0.5477494025,"dev-research":0.1958482269,"llms":0.5408183502,"data-quality":0.2847337954}}
{"text":"However, an intrinsic center-outward ordering of high-dimensional text representations is not trivial.","meta":{"url":"http://arxiv.org/abs/2310.15010v1"},"cats":{"benchmark":0.3380030415,"new-dataset":0.0091479036,"data-annotation":0.548376064,"dev-research":0.111795252,"llms":0.5035066969,"data-quality":0.1428430467}}
{"text":"A statistical depth is a function for ranking k-dimensional objects by measuring centrality with respect to some observed k-dimensional distribution.","meta":{"url":"http://arxiv.org/abs/2310.15010v1"},"cats":{"benchmark":0.3932122136,"new-dataset":0.0658280207,"data-annotation":0.5378930157,"dev-research":0.1327584591,"llms":0.452200081,"data-quality":0.1079768186}}
{"text":"We adopt a statistical depth to measure distributions of transformer-based text embeddings, transformer-based text embedding (TTE) depth, and introduce the practical use of this depth for both modeling and distributional inference in NLP pipelines.","meta":{"url":"http://arxiv.org/abs/2310.15010v1"},"cats":{"benchmark":0.3516528162,"new-dataset":0.0561842512,"data-annotation":0.5211448434,"dev-research":0.1462574515,"llms":0.5031490949,"data-quality":0.1604073614}}
{"text":"We first define TTE depth and an associated rank sum test for determining whether two corpora differ significantly in embedding space.","meta":{"url":"http://arxiv.org/abs/2310.15010v1"},"cats":{"benchmark":0.5290017367,"new-dataset":0.0593304115,"data-annotation":0.5608283802,"dev-research":0.1229307739,"llms":0.4695906368,"data-quality":0.2421170428}}
{"text":"We then use TTE depth for the task of in-context learning prompt selection, showing that this approach reliably improves performance over statistical baseline approaches across six text classification tasks.","meta":{"url":"http://arxiv.org/abs/2310.15010v1"},"cats":{"benchmark":0.410346741,"new-dataset":0.03151559,"data-annotation":0.5410982125,"dev-research":0.1412876005,"llms":0.5070778882,"data-quality":0.192768297}}
{"text":"Finally, we use TTE depth and the associated rank sum test to characterize the distributions of synthesized and human-generated corpora, showing that five recent synthetic data augmentation processes cause a measurable distributional shift away from associated human-generated text.","meta":{"url":"http://arxiv.org/abs/2310.15010v1"},"cats":{"benchmark":0.3611895094,"new-dataset":0.1756196027,"data-annotation":0.5346558843,"dev-research":0.2323132263,"llms":0.472170945,"data-quality":0.265783878}}
{"text":"In this work, we introduce Wonder3D, a novel method for efficiently generating high-fidelity textured meshes from single-view images.","meta":{"url":"http://arxiv.org/abs/2310.15008v1"},"cats":{"benchmark":0.3133831298,"new-dataset":0.0762384361,"data-annotation":0.5123343352,"dev-research":0.162526718,"llms":0.4783009196,"data-quality":0.0591670424}}
{"text":"Recent methods based on Score Distillation Sampling (SDS) have shown the potential to recover 3D geometry from 2D diffusion priors, but they typically suffer from time-consuming per-shape optimization and inconsistent geometry.","meta":{"url":"http://arxiv.org/abs/2310.15008v1"},"cats":{"benchmark":0.4898758025,"new-dataset":0.0191298057,"data-annotation":0.4939257189,"dev-research":0.1332773259,"llms":0.4449708715,"data-quality":0.0729703561}}
{"text":"In contrast, certain works directly produce 3D information via fast network inferences, but their results are often of low quality and lack geometric details.","meta":{"url":"http://arxiv.org/abs/2310.15008v1"},"cats":{"benchmark":0.3732496828,"new-dataset":0.0049868266,"data-annotation":0.5178424192,"dev-research":0.1892119456,"llms":0.4481272765,"data-quality":0.095547596}}
{"text":"To holistically improve the quality, consistency, and efficiency of image-to-3D tasks, we propose a cross-domain diffusion model that generates multi-view normal maps and the corresponding color images.","meta":{"url":"http://arxiv.org/abs/2310.15008v1"},"cats":{"benchmark":0.3544402639,"new-dataset":0.1170426043,"data-annotation":0.481196687,"dev-research":0.1521831311,"llms":0.4486112104,"data-quality":0.0646702344}}
{"text":"To ensure consistency, we employ a multi-view cross-domain attention mechanism that facilitates information exchange across views and modalities.","meta":{"url":"http://arxiv.org/abs/2310.15008v1"},"cats":{"benchmark":0.3087182743,"new-dataset":0.0640404767,"data-annotation":0.4913254781,"dev-research":0.2210052725,"llms":0.5161123873,"data-quality":0.189248931}}
{"text":"Lastly, we introduce a geometry-aware normal fusion algorithm that extracts high-quality surfaces from the multi-view 2D representations.","meta":{"url":"http://arxiv.org/abs/2310.15008v1"},"cats":{"benchmark":0.3546256284,"new-dataset":0.0677633588,"data-annotation":0.523239374,"dev-research":0.1946395527,"llms":0.4119907757,"data-quality":0.0619103931}}
{"text":"Our extensive evaluations demonstrate that our method achieves high-quality reconstruction results, robust generalization, and reasonably good efficiency compared to prior works.","meta":{"url":"http://arxiv.org/abs/2310.15008v1"},"cats":{"benchmark":0.5585280019,"new-dataset":0.1335668486,"data-annotation":0.5074324999,"dev-research":0.144907368,"llms":0.4101434236,"data-quality":0.1211439308}}
{"text":"With large language models (LLMs) poised to become embedded in our daily lives, questions are starting to be raised about the dataset(s) they learned from.","meta":{"url":"http://arxiv.org/abs/2310.15007v1"},"cats":{"benchmark":0.1432858338,"new-dataset":0.6683408597,"data-annotation":0.5205684938,"dev-research":0.136382828,"llms":0.7147779275,"data-quality":0.2222138472}}
{"text":"These questions range from potential bias or misinformation LLMs could retain from their training data to questions of copyright and fair use of human-generated text.","meta":{"url":"http://arxiv.org/abs/2310.15007v1"},"cats":{"benchmark":0.1575298593,"new-dataset":0.14571857,"data-annotation":0.5195730155,"dev-research":0.1660986384,"llms":0.7288514939,"data-quality":0.2377080798}}
{"text":"However, while these questions emerge, developers of the recent state-of-the-art LLMs become increasingly reluctant to disclose details on their training corpus.","meta":{"url":"http://arxiv.org/abs/2310.15007v1"},"cats":{"benchmark":0.1452024505,"new-dataset":0.1634747913,"data-annotation":0.5235547249,"dev-research":0.2265500572,"llms":0.7630880209,"data-quality":0.2762982324}}
{"text":"We here introduce the task of document-level membership inference for real-world LLMs, i.e. inferring whether the LLM has seen a given document during training or not.","meta":{"url":"http://arxiv.org/abs/2310.15007v1"},"cats":{"benchmark":0.2904384684,"new-dataset":0.0710775863,"data-annotation":0.5375248425,"dev-research":0.1171897627,"llms":0.7053884287,"data-quality":0.181374334}}
{"text":"First, we propose a procedure for the development and evaluation of document-level membership inference for LLMs by leveraging commonly used data sources for training and the model release date.","meta":{"url":"http://arxiv.org/abs/2310.15007v1"},"cats":{"benchmark":0.3928400538,"new-dataset":0.1153960683,"data-annotation":0.5275772204,"dev-research":0.1315265869,"llms":0.6707642863,"data-quality":0.2094807046}}
{"text":"We then propose a practical, black-box method to predict document-level membership and instantiate it on OpenLLaMA-7B with both books and academic papers.","meta":{"url":"http://arxiv.org/abs/2310.15007v1"},"cats":{"benchmark":0.4116437614,"new-dataset":0.0843486371,"data-annotation":0.5414581317,"dev-research":0.1468034751,"llms":0.4942681456,"data-quality":0.1475303748}}
{"text":"We show our methodology to perform very well, reaching an impressive AUC of 0.856 for books and 0.678 for papers.","meta":{"url":"http://arxiv.org/abs/2310.15007v1"},"cats":{"benchmark":0.5121896837,"new-dataset":0.1872190363,"data-annotation":0.5602389845,"dev-research":0.1711340945,"llms":0.5206049374,"data-quality":0.1430279062}}
{"text":"We then show our approach to outperform the sentence-level membership inference attacks used in the privacy literature for the document-level membership task.","meta":{"url":"http://arxiv.org/abs/2310.15007v1"},"cats":{"benchmark":0.3782700664,"new-dataset":0.0508089644,"data-annotation":0.5413767161,"dev-research":0.1600433022,"llms":0.5376076839,"data-quality":0.2488753086}}
{"text":"We finally evaluate whether smaller models might be less sensitive to document-level inference and show OpenLLaMA-3B to be approximately as sensitive as OpenLLaMA-7B to our approach.","meta":{"url":"http://arxiv.org/abs/2310.15007v1"},"cats":{"benchmark":0.4507218309,"new-dataset":0.0231071574,"data-annotation":0.5298063328,"dev-research":0.1019659219,"llms":0.4974038697,"data-quality":0.1591907665}}
{"text":"Taken together, our results show that accurate document-level membership can be inferred for LLMs, increasing the transparency of technology poised to change our lives.","meta":{"url":"http://arxiv.org/abs/2310.15007v1"},"cats":{"benchmark":0.2915124687,"new-dataset":0.0393972939,"data-annotation":0.5019457585,"dev-research":0.1403231562,"llms":0.7662199658,"data-quality":0.1588533656}}
{"text":"Animacy - whether an entity is alive and sentient - is fundamental to cognitive processing, impacting areas such as memory, vision, and language.","meta":{"url":"http://arxiv.org/abs/2310.15004v1"},"cats":{"benchmark":0.1523406304,"new-dataset":0.153357426,"data-annotation":0.529313031,"dev-research":0.2572582823,"llms":0.5216855841,"data-quality":0.1171639126}}
{"text":"However, animacy is not always expressed directly in language: in English it often manifests indirectly, in the form of selectional constraints on verbs and adjectives.","meta":{"url":"http://arxiv.org/abs/2310.15004v1"},"cats":{"benchmark":0.180865142,"new-dataset":0.01812224,"data-annotation":0.5486227228,"dev-research":0.2426692274,"llms":0.4664462134,"data-quality":0.2214052965}}
{"text":"This poses a potential issue for transformer language models (LMs): they often train only on text, and thus lack access to extralinguistic information from which humans learn about animacy.","meta":{"url":"http://arxiv.org/abs/2310.15004v1"},"cats":{"benchmark":0.1382568513,"new-dataset":0.0917904619,"data-annotation":0.5459647548,"dev-research":0.157721834,"llms":0.5713627747,"data-quality":0.2731112867}}
{"text":"We ask: how does this impact LMs' animacy processing - do they still behave as humans do?","meta":{"url":"http://arxiv.org/abs/2310.15004v1"},"cats":{"benchmark":0.2698295872,"new-dataset":0.0151235647,"data-annotation":0.4925509174,"dev-research":0.0923773785,"llms":0.612733628,"data-quality":0.1178267062}}
{"text":"We answer this question using open-source LMs.","meta":{"url":"http://arxiv.org/abs/2310.15004v1"},"cats":{"benchmark":0.428834596,"new-dataset":0.0595480266,"data-annotation":0.484379737,"dev-research":0.1288695772,"llms":0.6036228523,"data-quality":0.1277721114}}
{"text":"Like previous studies, we find that LMs behave much like humans when presented with entities whose animacy is typical.","meta":{"url":"http://arxiv.org/abs/2310.15004v1"},"cats":{"benchmark":0.2077106638,"new-dataset":0.0245632068,"data-annotation":0.5150560739,"dev-research":0.116581258,"llms":0.6389067204,"data-quality":0.1612816138}}
{"text":"However, we also show that even when presented with stories about atypically animate entities, such as a peanut in love, LMs adapt: they treat these entities as animate, though they do not adapt as well as humans.","meta":{"url":"http://arxiv.org/abs/2310.15004v1"},"cats":{"benchmark":0.1456514927,"new-dataset":0.0333630825,"data-annotation":0.5096463216,"dev-research":0.1092141594,"llms":0.6595883997,"data-quality":0.0925640281}}
{"text":"Even when the context indicating atypical animacy is very short, LMs pick up on subtle clues and change their behavior.","meta":{"url":"http://arxiv.org/abs/2310.15004v1"},"cats":{"benchmark":0.1846300198,"new-dataset":0.0242765995,"data-annotation":0.5232162758,"dev-research":0.1465442593,"llms":0.6155162986,"data-quality":0.2582571739}}
{"text":"We conclude that despite the limited signal through which LMs can learn about animacy, they are indeed sensitive to the relevant lexical semantic nuances available in English.","meta":{"url":"http://arxiv.org/abs/2310.15004v1"},"cats":{"benchmark":0.1804723871,"new-dataset":0.0751941148,"data-annotation":0.5480372624,"dev-research":0.1595648438,"llms":0.6227339025,"data-quality":0.3637514703}}
{"text":"The inductive bias of a graph neural network (GNN) is largely encoded in its specified graph.","meta":{"url":"http://arxiv.org/abs/2310.15003v1"},"cats":{"benchmark":0.2879021617,"new-dataset":0.0160866464,"data-annotation":0.5294271246,"dev-research":0.1363042649,"llms":0.4227160063,"data-quality":0.188862266}}
{"text":"Latent graph inference relies on latent geometric representations to dynamically rewire or infer a GNN's graph to maximize the GNN's predictive downstream performance, but it lacks solid theoretical foundations in terms of embedding-based representation guarantees.","meta":{"url":"http://arxiv.org/abs/2310.15003v1"},"cats":{"benchmark":0.2699325345,"new-dataset":0.0133629119,"data-annotation":0.5330260541,"dev-research":0.1633412116,"llms":0.4591332027,"data-quality":0.1155219179}}
{"text":"This paper addresses this issue by introducing a trainable deep learning architecture, coined neural snowflake, that can adaptively implement fractal-like metrics on $\\mathbb{R}^d$. We prove that any given finite weights graph can be isometrically embedded by a standard MLP encoder.","meta":{"url":"http://arxiv.org/abs/2310.15003v1"},"cats":{"benchmark":0.2770819448,"new-dataset":0.1834929486,"data-annotation":0.5112293496,"dev-research":0.1383491037,"llms":0.4377607355,"data-quality":0.1248712006}}
{"text":"Furthermore, when the latent graph can be represented in the feature space of a sufficiently regular kernel, we show that the combined neural snowflake and MLP encoder do not succumb to the curse of dimensionality by using only a low-degree polynomial number of parameters in the number of nodes.","meta":{"url":"http://arxiv.org/abs/2310.15003v1"},"cats":{"benchmark":0.2465681378,"new-dataset":0.0679368318,"data-annotation":0.5355515175,"dev-research":0.1371277929,"llms":0.4370106077,"data-quality":0.155567609}}
{"text":"This implementation enables a low-dimensional isometric embedding of the latent graph.","meta":{"url":"http://arxiv.org/abs/2310.15003v1"},"cats":{"benchmark":0.4366233452,"new-dataset":0.0385038824,"data-annotation":0.5358508638,"dev-research":0.1304938575,"llms":0.4380587842,"data-quality":0.1410584773}}
{"text":"We conduct synthetic experiments to demonstrate the superior metric learning capabilities of neural snowflakes when compared to more familiar spaces like Euclidean space.","meta":{"url":"http://arxiv.org/abs/2310.15003v1"},"cats":{"benchmark":0.3114750249,"new-dataset":0.1639316546,"data-annotation":0.5391834247,"dev-research":0.1313898184,"llms":0.4577802565,"data-quality":0.1466627691}}
{"text":"Additionally, we carry out latent graph inference experiments on graph benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.15003v1"},"cats":{"benchmark":0.5287174129,"new-dataset":0.0711252107,"data-annotation":0.5293489654,"dev-research":0.1572309,"llms":0.4758429178,"data-quality":0.1362216514}}
{"text":"Consistently, the neural snowflake model achieves predictive performance that either matches or surpasses that of the state-of-the-art latent graph inference models.","meta":{"url":"http://arxiv.org/abs/2310.15003v1"},"cats":{"benchmark":0.3267199481,"new-dataset":0.0791711876,"data-annotation":0.5326435812,"dev-research":0.1428479513,"llms":0.4355576492,"data-quality":0.110088765}}
{"text":"Importantly, this performance improvement is achieved without requiring random search for optimal latent geometry.","meta":{"url":"http://arxiv.org/abs/2310.15003v1"},"cats":{"benchmark":0.5835023785,"new-dataset":0.0080574865,"data-annotation":0.5430940912,"dev-research":0.0872170726,"llms":0.4790673563,"data-quality":0.0875250147}}
{"text":"Instead, the neural snowflake model achieves this enhancement in a differentiable manner.","meta":{"url":"http://arxiv.org/abs/2310.15003v1"},"cats":{"benchmark":0.2984988609,"new-dataset":0.0137256568,"data-annotation":0.5204720074,"dev-research":0.1399517281,"llms":0.4394825704,"data-quality":0.0928819982}}
{"text":"Scaling dense PCFGs to thousands of nonterminals via a low-rank parameterization of the rule probability tensor has been shown to be beneficial for unsupervised parsing.","meta":{"url":"http://arxiv.org/abs/2310.14997v1"},"cats":{"benchmark":0.3397309645,"new-dataset":0.2032389581,"data-annotation":0.5296639672,"dev-research":0.1115740778,"llms":0.4671915014,"data-quality":0.1923091869}}
{"text":"However, PCFGs scaled this way still perform poorly as a language model, and even underperform similarly-sized HMMs.","meta":{"url":"http://arxiv.org/abs/2310.14997v1"},"cats":{"benchmark":0.3813255575,"new-dataset":0.0824025476,"data-annotation":0.5307442034,"dev-research":0.1165532,"llms":0.5228156668,"data-quality":0.2047924903}}
{"text":"This work introduces \\emph{SimplePCFG}, a simple PCFG formalism with independent left and right productions.","meta":{"url":"http://arxiv.org/abs/2310.14997v1"},"cats":{"benchmark":0.2215972746,"new-dataset":0.1359811367,"data-annotation":0.5170294035,"dev-research":0.1768894299,"llms":0.5889379,"data-quality":0.1197238323}}
{"text":"Despite imposing a stronger independence assumption than the low-rank approach, we find that this formalism scales more effectively both as a language model and as an unsupervised parser.","meta":{"url":"http://arxiv.org/abs/2310.14997v1"},"cats":{"benchmark":0.3935468139,"new-dataset":0.0189990067,"data-annotation":0.5398633535,"dev-research":0.1742762472,"llms":0.5232154619,"data-quality":0.2262524094}}
{"text":"As an unsupervised parser, our simple PCFG obtains an average F1 of 65.1 on the English PTB, and as a language model, it obtains a perplexity of 119.0, outperforming similarly-sized low-rank PCFGs.","meta":{"url":"http://arxiv.org/abs/2310.14997v1"},"cats":{"benchmark":0.4457090343,"new-dataset":0.4012837322,"data-annotation":0.5565403601,"dev-research":0.1252531282,"llms":0.5156644008,"data-quality":0.1810480501}}
{"text":"We further introduce \\emph{FlashInside}, a hardware IO-aware implementation of the inside algorithm for efficiently scaling simple PCFGs.","meta":{"url":"http://arxiv.org/abs/2310.14997v1"},"cats":{"benchmark":0.4493098627,"new-dataset":0.1112224726,"data-annotation":0.5103589633,"dev-research":0.1741970946,"llms":0.5366696629,"data-quality":0.0780738102}}
{"text":"As language models are applied to an increasing number of real-world applications, understanding their inner workings has become an important issue in model trust, interpretability, and transparency.","meta":{"url":"http://arxiv.org/abs/2310.14993v1"},"cats":{"benchmark":0.2127367816,"new-dataset":0.017449259,"data-annotation":0.5310944112,"dev-research":0.3342229144,"llms":0.5502117646,"data-quality":0.3390655215}}
{"text":"In this work we show that representation dissimilarity measures, which are functions that measure the extent to which two model's internal representations differ, can be a valuable tool for gaining insight into the mechanics of language models.","meta":{"url":"http://arxiv.org/abs/2310.14993v1"},"cats":{"benchmark":0.3095162045,"new-dataset":0.0211904498,"data-annotation":0.5587032651,"dev-research":0.2086416358,"llms":0.4951654589,"data-quality":0.2262411032}}
{"text":"Among our insights are: (i) an apparent asymmetry in the internal representations of model using SoLU and GeLU activation functions, (ii) evidence that dissimilarity measures can identify and locate generalization properties of models that are invisible via in-distribution test set performance, and (iii) new evaluations of how language model features vary as width and depth are increased.","meta":{"url":"http://arxiv.org/abs/2310.14993v1"},"cats":{"benchmark":0.4030650542,"new-dataset":0.0078722514,"data-annotation":0.5508864982,"dev-research":0.1615878371,"llms":0.4660575706,"data-quality":0.2087495916}}
{"text":"Our results suggest that dissimilarity measures are a promising set of tools for shedding light on the inner workings of language models.","meta":{"url":"http://arxiv.org/abs/2310.14993v1"},"cats":{"benchmark":0.4366411087,"new-dataset":0.0191299194,"data-annotation":0.5488302308,"dev-research":0.2039074318,"llms":0.4876409953,"data-quality":0.2340582115}}
{"text":"Machine learning tasks are vulnerable to the quality of data used as input.","meta":{"url":"http://arxiv.org/abs/2310.14992v1"},"cats":{"benchmark":0.3323794842,"new-dataset":0.0346168902,"data-annotation":0.5115677598,"dev-research":0.3173385194,"llms":0.4408197312,"data-quality":0.4080193613}}
{"text":"Yet, it is often challenging for firms to obtain adequate datasets, with them being naturally distributed amongst owners, that in practice, may be competitors in a downstream market and reluctant to share information.","meta":{"url":"http://arxiv.org/abs/2310.14992v1"},"cats":{"benchmark":0.2084841909,"new-dataset":0.1918224233,"data-annotation":0.4652440429,"dev-research":0.2012951078,"llms":0.4927533915,"data-quality":0.200891311}}
{"text":"Focusing on supervised learning for regression tasks, we develop a \\textit{regression market} to provide a monetary incentive for data sharing.","meta":{"url":"http://arxiv.org/abs/2310.14992v1"},"cats":{"benchmark":0.2825887781,"new-dataset":0.0845158765,"data-annotation":0.49851527,"dev-research":0.2214758355,"llms":0.3297351292,"data-quality":0.1903157069}}
{"text":"Our proposed mechanism adopts a Bayesian framework, allowing us to consider a more general class of regression tasks.","meta":{"url":"http://arxiv.org/abs/2310.14992v1"},"cats":{"benchmark":0.4161013668,"new-dataset":0.0114104546,"data-annotation":0.5064158359,"dev-research":0.2608488592,"llms":0.2758480826,"data-quality":0.0864321131}}
{"text":"We present a thorough exploration of the market properties, and show that similar proposals in current literature expose the market agents to sizeable financial risks, which can be mitigated in our probabilistic setting.","meta":{"url":"http://arxiv.org/abs/2310.14992v1"},"cats":{"benchmark":0.2932606625,"new-dataset":0.0898860037,"data-annotation":0.5289067442,"dev-research":0.159468438,"llms":0.4486437523,"data-quality":0.1203861427}}
{"text":"In the impartial selection problem, a subset of agents up to a fixed size $k$ among a group of $n$ is to be chosen based on votes cast by the agents themselves.","meta":{"url":"http://arxiv.org/abs/2310.14991v1"},"cats":{"benchmark":0.3474221633,"new-dataset":0.025907365,"data-annotation":0.5281558418,"dev-research":0.1319662354,"llms":0.4812835722,"data-quality":0.1099697961}}
{"text":"A selection mechanism is impartial if no agent can influence its own chance of being selected by changing its vote.","meta":{"url":"http://arxiv.org/abs/2310.14991v1"},"cats":{"benchmark":0.3273767853,"new-dataset":0.0017174618,"data-annotation":0.5122808695,"dev-research":0.1727696426,"llms":0.5262470737,"data-quality":0.0918067043}}
{"text":"It is $\\alpha$-optimal if, for every instance, the ratio between the votes received by the selected subset is at least a fraction of $\\alpha$ of the votes received by the subset of size $k$ with the highest number of votes.","meta":{"url":"http://arxiv.org/abs/2310.14991v1"},"cats":{"benchmark":0.6080131269,"new-dataset":0.0230494837,"data-annotation":0.5295701056,"dev-research":0.1358111227,"llms":0.4070457859,"data-quality":0.1112220972}}
{"text":"We study deterministic impartial mechanisms in a more general setting with arbitrarily weighted votes and provide the first approximation guarantee, roughly $1/\\lceil 2n/k\\rceil$. When the number of agents to select is large enough compared to the total number of agents, this yields an improvement on the previously best known approximation ratio of $1/k$ for the unweighted setting.","meta":{"url":"http://arxiv.org/abs/2310.14991v1"},"cats":{"benchmark":0.4919814598,"new-dataset":0.0210072623,"data-annotation":0.5353118865,"dev-research":0.1367447066,"llms":0.4958851395,"data-quality":0.1101433149}}
{"text":"We further show that our mechanism can be adapted to the impartial assignment problem, in which multiple sets of up to $k$ agents are to be selected, with a loss in the approximation ratio of $1/2$.","meta":{"url":"http://arxiv.org/abs/2310.14991v1"},"cats":{"benchmark":0.3883931597,"new-dataset":0.0353991824,"data-annotation":0.5536447554,"dev-research":0.1146080035,"llms":0.4520113017,"data-quality":0.1449372807}}
{"text":"This paper aims to investigate the open research problem of uncovering the social behaviors of LLM-based agents.","meta":{"url":"http://arxiv.org/abs/2310.14985v1"},"cats":{"benchmark":0.163948258,"new-dataset":0.0487093826,"data-annotation":0.5136159114,"dev-research":0.1147915164,"llms":0.7400691792,"data-quality":0.0533678891}}
{"text":"To achieve this goal, we adopt Avalon, a representative communication game, as the environment and use system prompts to guide LLM agents to play the game.","meta":{"url":"http://arxiv.org/abs/2310.14985v1"},"cats":{"benchmark":0.1415201919,"new-dataset":0.2486512947,"data-annotation":0.4977036656,"dev-research":0.2707328365,"llms":0.7097031485,"data-quality":0.071121533}}
{"text":"While previous studies have conducted preliminary investigations into gameplay with LLM agents, there lacks research on their social behaviors.","meta":{"url":"http://arxiv.org/abs/2310.14985v1"},"cats":{"benchmark":0.1891462096,"new-dataset":0.026561979,"data-annotation":0.5191375273,"dev-research":0.1624424731,"llms":0.7484926756,"data-quality":0.0823015262}}
{"text":"In this paper, we present a novel framework designed to seamlessly adapt to Avalon gameplay.","meta":{"url":"http://arxiv.org/abs/2310.14985v1"},"cats":{"benchmark":0.313141071,"new-dataset":0.1624551004,"data-annotation":0.5098392598,"dev-research":0.2733342608,"llms":0.4662618278,"data-quality":0.0555656183}}
{"text":"The core of our proposed framework is a multi-agent system that enables efficient communication and interaction among agents.","meta":{"url":"http://arxiv.org/abs/2310.14985v1"},"cats":{"benchmark":0.24672645,"new-dataset":0.1109884311,"data-annotation":0.5014618281,"dev-research":0.1725300915,"llms":0.5000008453,"data-quality":0.0401312921}}
{"text":"We evaluate the performance of our framework based on metrics from two perspectives: winning the game and analyzing the social behaviors of LLM agents.","meta":{"url":"http://arxiv.org/abs/2310.14985v1"},"cats":{"benchmark":0.3699425711,"new-dataset":0.1375723058,"data-annotation":0.525729432,"dev-research":0.1605008215,"llms":0.6806911261,"data-quality":0.0645518808}}
{"text":"Our results demonstrate the effectiveness of our framework in generating adaptive and intelligent agents and highlight the potential of LLM-based agents in addressing the challenges associated with dynamic social environment interaction.","meta":{"url":"http://arxiv.org/abs/2310.14985v1"},"cats":{"benchmark":0.1719875101,"new-dataset":0.0944295988,"data-annotation":0.5050247229,"dev-research":0.2212000716,"llms":0.7161772237,"data-quality":0.0629543414}}
{"text":"By analyzing the social behaviors of LLM agents from the aspects of both collaboration and confrontation, we provide insights into the research and applications of this domain.","meta":{"url":"http://arxiv.org/abs/2310.14985v1"},"cats":{"benchmark":0.1635991503,"new-dataset":0.0948854374,"data-annotation":0.5062995985,"dev-research":0.1762986413,"llms":0.7528882926,"data-quality":0.0589456646}}
{"text":"During the Covid-19 pandemic, research communities focused on collecting and understanding people's behaviours and feelings to study and tackle the pandemic indirect effects.","meta":{"url":"http://arxiv.org/abs/2310.14984v1"},"cats":{"benchmark":0.1901410894,"new-dataset":0.2545614826,"data-annotation":0.5161961146,"dev-research":0.2838684117,"llms":0.5682717656,"data-quality":0.0666053881}}
{"text":"Despite its consequences are slowly starting to fade away, such an interest is still alive.","meta":{"url":"http://arxiv.org/abs/2310.14984v1"},"cats":{"benchmark":0.1831258681,"new-dataset":0.0635292959,"data-annotation":0.5105212089,"dev-research":0.1690017403,"llms":0.5178376296,"data-quality":0.1176260146}}
{"text":"In this article, we propose a hybrid, gamified, story-driven data collection approach to spark self-empathy, hence resurfacing people's past feelings.","meta":{"url":"http://arxiv.org/abs/2310.14984v1"},"cats":{"benchmark":0.1930302053,"new-dataset":0.3233319397,"data-annotation":0.4887524473,"dev-research":0.2231351773,"llms":0.5280134248,"data-quality":0.0773375778}}
{"text":"The game is designed to include a physical board, decks of cards, and a digital application.","meta":{"url":"http://arxiv.org/abs/2310.14984v1"},"cats":{"benchmark":0.159564747,"new-dataset":0.2498795792,"data-annotation":0.5066190554,"dev-research":0.2511865754,"llms":0.5577615201,"data-quality":0.0522411152}}
{"text":"As the player plays through the game, they customize and escape from their lockdown room by completing statements and answering a series of questions that define their story.","meta":{"url":"http://arxiv.org/abs/2310.14984v1"},"cats":{"benchmark":0.1069370202,"new-dataset":0.1785368726,"data-annotation":0.5223837253,"dev-research":0.3815650251,"llms":0.5431870545,"data-quality":0.0782469844}}
{"text":"The decoration of the lockdown room and the storytelling-driven approach are targeted at sparking people's emotions and self-empathy towards their past selves.","meta":{"url":"http://arxiv.org/abs/2310.14984v1"},"cats":{"benchmark":0.1620081774,"new-dataset":0.0449456374,"data-annotation":0.5236920728,"dev-research":0.3214131045,"llms":0.5619798881,"data-quality":0.0788548393}}
{"text":"Ultimately, the proposed approach was proven effective in sparking and collecting feelings, while a few improvements are still necessary.","meta":{"url":"http://arxiv.org/abs/2310.14984v1"},"cats":{"benchmark":0.3759997762,"new-dataset":0.0045329625,"data-annotation":0.4976504351,"dev-research":0.2548779026,"llms":0.5186040795,"data-quality":0.0875049747}}
{"text":"Recurrent Neural Networks (RNNs) are renowned for their adeptness in modeling temporal dependencies, a trait that has driven their widespread adoption for sequential data processing.","meta":{"url":"http://arxiv.org/abs/2310.14982v1"},"cats":{"benchmark":0.2110177383,"new-dataset":0.224126897,"data-annotation":0.4783873275,"dev-research":0.1885620283,"llms":0.5097145985,"data-quality":0.0603929042}}
{"text":"Nevertheless, vanilla RNNs are confronted with the well-known issue of gradient vanishing and exploding, posing a significant challenge for learning and establishing long-range dependencies.","meta":{"url":"http://arxiv.org/abs/2310.14982v1"},"cats":{"benchmark":0.2125548887,"new-dataset":0.0898630667,"data-annotation":0.5250655507,"dev-research":0.1155524804,"llms":0.5130952621,"data-quality":0.1240639408}}
{"text":"Additionally, gated RNNs tend to be over-parameterized, resulting in poor network generalization.","meta":{"url":"http://arxiv.org/abs/2310.14982v1"},"cats":{"benchmark":0.3464869727,"new-dataset":0.0041295483,"data-annotation":0.5211221276,"dev-research":0.1092031902,"llms":0.5588485994,"data-quality":0.1479052516}}
{"text":"To address these challenges, we propose a novel Delayed Memory Unit (DMU) in this paper, wherein a delay line structure, coupled with delay gates, is introduced to facilitate temporal interaction and temporal credit assignment, so as to enhance the temporal modeling capabilities of vanilla RNNs.","meta":{"url":"http://arxiv.org/abs/2310.14982v1"},"cats":{"benchmark":0.2711004521,"new-dataset":0.1056647637,"data-annotation":0.4720533344,"dev-research":0.1827151702,"llms":0.6072788218,"data-quality":0.0684524472}}
{"text":"Particularly, the DMU is designed to directly distribute the input information to the optimal time instant in the future, rather than aggregating and redistributing it over time through intricate network dynamics.","meta":{"url":"http://arxiv.org/abs/2310.14982v1"},"cats":{"benchmark":0.2912704741,"new-dataset":0.014197527,"data-annotation":0.4698585983,"dev-research":0.1945619083,"llms":0.5944116875,"data-quality":0.0495147289}}
{"text":"Our proposed DMU demonstrates superior temporal modeling capabilities across a broad range of sequential modeling tasks, utilizing considerably fewer parameters than other state-of-the-art gated RNN models in applications such as speech recognition, radar gesture recognition, ECG waveform segmentation, and permuted sequential image classification.","meta":{"url":"http://arxiv.org/abs/2310.14982v1"},"cats":{"benchmark":0.2780196222,"new-dataset":0.2491848075,"data-annotation":0.4765674394,"dev-research":0.1600543111,"llms":0.6042853764,"data-quality":0.0474764887}}
{"text":"In this paper, we address the hallucination problem commonly found in natural language generation tasks.","meta":{"url":"http://arxiv.org/abs/2310.14981v1"},"cats":{"benchmark":0.1669648144,"new-dataset":0.108527632,"data-annotation":0.5548404661,"dev-research":0.3029184199,"llms":0.5923318884,"data-quality":0.2711084996}}
{"text":"Language models often generate fluent and convincing content but can lack consistency with the provided source, resulting in potential inaccuracies.","meta":{"url":"http://arxiv.org/abs/2310.14981v1"},"cats":{"benchmark":0.2869021159,"new-dataset":0.0119370307,"data-annotation":0.5225410476,"dev-research":0.3089925204,"llms":0.5431697439,"data-quality":0.4806364414}}
{"text":"We propose a new decoding method called Fidelity-Enriched Contrastive Search (FECS), which augments the contrastive search framework with context-aware regularization terms.","meta":{"url":"http://arxiv.org/abs/2310.14981v1"},"cats":{"benchmark":0.4130487547,"new-dataset":0.0106209228,"data-annotation":0.5169086517,"dev-research":0.1083197106,"llms":0.4567082506,"data-quality":0.2170073219}}
{"text":"FECS promotes tokens that are semantically similar to the provided source while penalizing repetitiveness in the generated text.","meta":{"url":"http://arxiv.org/abs/2310.14981v1"},"cats":{"benchmark":0.247235813,"new-dataset":0.0150354895,"data-annotation":0.5131476149,"dev-research":0.2685999612,"llms":0.6093463383,"data-quality":0.3704168863}}
{"text":"We demonstrate its effectiveness across two tasks prone to hallucination: abstractive summarization and dialogue generation.","meta":{"url":"http://arxiv.org/abs/2310.14981v1"},"cats":{"benchmark":0.2283264641,"new-dataset":0.0411569407,"data-annotation":0.5370181913,"dev-research":0.3141213281,"llms":0.6234413648,"data-quality":0.11153868}}
{"text":"Results show that FECS consistently enhances faithfulness across various language model sizes while maintaining output diversity comparable to well-performing decoding algorithms.","meta":{"url":"http://arxiv.org/abs/2310.14981v1"},"cats":{"benchmark":0.3594489635,"new-dataset":0.0267073063,"data-annotation":0.5289915706,"dev-research":0.1157599029,"llms":0.5521453647,"data-quality":0.2386118061}}
{"text":"Label aggregation such as majority voting is commonly used to resolve annotator disagreement in dataset creation.","meta":{"url":"http://arxiv.org/abs/2310.14979v1"},"cats":{"benchmark":0.4477250435,"new-dataset":0.2250958005,"data-annotation":0.5021959478,"dev-research":0.3173520514,"llms":0.5506833838,"data-quality":0.7559244532}}
{"text":"However, this may disregard minority values and opinions.","meta":{"url":"http://arxiv.org/abs/2310.14979v1"},"cats":{"benchmark":0.3966722705,"new-dataset":0.0064133123,"data-annotation":0.5103098903,"dev-research":0.1930230531,"llms":0.5351293162,"data-quality":0.2656086685}}
{"text":"Recent studies indicate that learning from individual annotations outperforms learning from aggregated labels, though they require a considerable amount of annotation.","meta":{"url":"http://arxiv.org/abs/2310.14979v1"},"cats":{"benchmark":0.4042443132,"new-dataset":0.0747023555,"data-annotation":0.5600648482,"dev-research":0.1873032456,"llms":0.5306294544,"data-quality":0.7302060816}}
{"text":"Active learning, as an annotation cost-saving strategy, has not been fully explored in the context of learning from disagreement.","meta":{"url":"http://arxiv.org/abs/2310.14979v1"},"cats":{"benchmark":0.3509871594,"new-dataset":0.072935018,"data-annotation":0.5168899309,"dev-research":0.3284609475,"llms":0.4942699438,"data-quality":0.3583277184}}
{"text":"We show that in the active learning setting, a multi-head model performs significantly better than a single-head model in terms of uncertainty estimation.","meta":{"url":"http://arxiv.org/abs/2310.14979v1"},"cats":{"benchmark":0.4561822297,"new-dataset":0.0256910107,"data-annotation":0.5160968872,"dev-research":0.2035141445,"llms":0.3700960955,"data-quality":0.175456028}}
{"text":"By designing and evaluating acquisition functions with annotator-specific heads on two datasets, we show that group-level entropy works generally well on both datasets.","meta":{"url":"http://arxiv.org/abs/2310.14979v1"},"cats":{"benchmark":0.4199803992,"new-dataset":0.3205977472,"data-annotation":0.5152311886,"dev-research":0.1364763791,"llms":0.5102202921,"data-quality":0.3614737067}}
{"text":"Importantly, it achieves performance in terms of both prediction and uncertainty estimation comparable to full-scale training from disagreement, while saving up to 70% of the annotation budget.","meta":{"url":"http://arxiv.org/abs/2310.14979v1"},"cats":{"benchmark":0.4885187756,"new-dataset":0.0772281662,"data-annotation":0.533343386,"dev-research":0.2569648952,"llms":0.4975341727,"data-quality":0.48860353}}
{"text":"The biological neurons use precise spike times, in addition to the spike firing rate, to communicate with each other.","meta":{"url":"http://arxiv.org/abs/2310.14978v1"},"cats":{"benchmark":0.293405829,"new-dataset":0.0136038026,"data-annotation":0.5094792617,"dev-research":0.2401380234,"llms":0.5122188566,"data-quality":0.0969519598}}
{"text":"The time-to-first-spike (TTFS) coding is inspired by such biological observation.","meta":{"url":"http://arxiv.org/abs/2310.14978v1"},"cats":{"benchmark":0.2050177201,"new-dataset":0.0628876525,"data-annotation":0.5101604729,"dev-research":0.1379404221,"llms":0.4700890664,"data-quality":0.1064630597}}
{"text":"However, there is a lack of effective solutions for training TTFS-based spiking neural network (SNN).","meta":{"url":"http://arxiv.org/abs/2310.14978v1"},"cats":{"benchmark":0.216493252,"new-dataset":0.0540856452,"data-annotation":0.515506481,"dev-research":0.1519534444,"llms":0.5824695267,"data-quality":0.0989300033}}
{"text":"In this paper, we put forward a simple yet effective network conversion algorithm, which is referred to as LC-TTFS, by addressing two main problems that hinder an effective conversion from a high-performance artificial neural network (ANN) to a TTFS-based SNN.","meta":{"url":"http://arxiv.org/abs/2310.14978v1"},"cats":{"benchmark":0.3262997567,"new-dataset":0.0771494038,"data-annotation":0.5229681448,"dev-research":0.1417446583,"llms":0.5155014118,"data-quality":0.1308332116}}
{"text":"We show that our algorithm can achieve a near-perfect mapping between the activation values of an ANN and the spike times of an SNN on a number of challenging AI tasks, including image classification, image reconstruction, and speech enhancement.","meta":{"url":"http://arxiv.org/abs/2310.14978v1"},"cats":{"benchmark":0.4420127555,"new-dataset":0.0668629124,"data-annotation":0.5496582172,"dev-research":0.1808790389,"llms":0.4886690556,"data-quality":0.2379861325}}
{"text":"With TTFS coding, we can achieve up to orders of magnitude saving in computation over ANN and other rate-based SNNs.","meta":{"url":"http://arxiv.org/abs/2310.14978v1"},"cats":{"benchmark":0.3623415067,"new-dataset":0.1338230517,"data-annotation":0.533180186,"dev-research":0.1637949218,"llms":0.538877906,"data-quality":0.0978146773}}
{"text":"The study, therefore, paves the way for deploying ultra-low-power TTFS-based SNNs on power-constrained edge computing platforms.","meta":{"url":"http://arxiv.org/abs/2310.14978v1"},"cats":{"benchmark":0.2641516178,"new-dataset":0.0804780131,"data-annotation":0.4976049652,"dev-research":0.1773451705,"llms":0.5621696703,"data-quality":0.0725672946}}
{"text":"Traditionally in the turnstile model of data streams, there is a state vector $x=(x_1,x_2,\\ldots,x_n)$ which is updated through a stream of pairs $(i,k)$ where $i\\in [n]$ and $k\\in \\Z$. Upon receiving $(i,k)$, $x_i\\gets x_i","meta":{"url":"http://arxiv.org/abs/2310.14977v1"},"cats":{"benchmark":0.330306404,"new-dataset":0.0452855295,"data-annotation":0.4876545771,"dev-research":0.1281184742,"llms":0.4434168074,"data-quality":0.0848816657}}
{"text":"+ k$.","meta":{"url":"http://arxiv.org/abs/2310.14977v1"},"cats":{"benchmark":0.2477953889,"new-dataset":0.3329837683,"data-annotation":0.5232234361,"dev-research":0.1991830002,"llms":0.4506887809,"data-quality":0.1065810159}}
{"text":"A distinct count algorithm in the turnstile model takes one pass of the stream and then estimates $\\norm{x}_0 =","meta":{"url":"http://arxiv.org/abs/2310.14977v1"},"cats":{"benchmark":0.4282509232,"new-dataset":0.0610822806,"data-annotation":0.5112043068,"dev-research":0.1279080393,"llms":0.453660178,"data-quality":0.1079661539}}
{"text":"|\\{i\\in[n]\\mid x_i\\neq 0\\}|$ (aka $L_0$, the Hamming norm).   ","meta":{"url":"http://arxiv.org/abs/2310.14977v1"},"cats":{"benchmark":0.3778304016,"new-dataset":0.0933665393,"data-annotation":0.5391747513,"dev-research":0.1723911491,"llms":0.4815992034,"data-quality":0.1640111485}}
{"text":"In this paper, we define a finite-field version of the turnstile model.","meta":{"url":"http://arxiv.org/abs/2310.14977v1"},"cats":{"benchmark":0.3031202816,"new-dataset":0.0700805082,"data-annotation":0.5282910335,"dev-research":0.0964474821,"llms":0.4304653718,"data-quality":0.0496023427}}
{"text":"Let $F$ be any finite field.","meta":{"url":"http://arxiv.org/abs/2310.14977v1"},"cats":{"benchmark":0.2557812107,"new-dataset":0.0793941918,"data-annotation":0.5016581457,"dev-research":0.1945623086,"llms":0.5262410947,"data-quality":0.1127550787}}
{"text":"Then in the $F$-turnstile model, for each $i\\in [n]$, $x_i\\in F$; for each update $(i,k)$, $k\\in F$. The update $x_i\\gets x_i+k$ is then computed in the field $F$. A distinct count algorithm in the $F$-turnstile model takes one pass of the stream and estimates $\\norm{x}_{0;F} = |\\{i\\in[n]\\mid","meta":{"url":"http://arxiv.org/abs/2310.14977v1"},"cats":{"benchmark":0.4175077578,"new-dataset":0.0874363246,"data-annotation":0.513680172,"dev-research":0.147007624,"llms":0.429495635,"data-quality":0.0996265046}}
{"text":"x_i\\neq","meta":{"url":"http://arxiv.org/abs/2310.14977v1"},"cats":{"benchmark":0.2556972697,"new-dataset":0.2883664593,"data-annotation":0.5293611586,"dev-research":0.2426856377,"llms":0.4639807928,"data-quality":0.1300310269}}
{"text":"0_F\\}|$.   ","meta":{"url":"http://arxiv.org/abs/2310.14977v1"},"cats":{"benchmark":0.2923171852,"new-dataset":0.2032939624,"data-annotation":0.5224828776,"dev-research":0.2223683459,"llms":0.4836381291,"data-quality":0.1969542786}}
{"text":"We present a simple distinct count algorithm, called $F$-\\pcsa{}, in the $F$-turnstile model for any finite field $F$. The new $F$-\\pcsa{} algorithm takes $m\\log(n)\\log (|F|)$ bits of memory and estimates $\\norm{x}_{0;F}$ with $O(\\frac{1}{\\sqrt{m}})$ relative error where the hidden constant depends on the order of the field.   ","meta":{"url":"http://arxiv.org/abs/2310.14977v1"},"cats":{"benchmark":0.5087762354,"new-dataset":0.1331170176,"data-annotation":0.541163999,"dev-research":0.1290451538,"llms":0.4853078564,"data-quality":0.1063103348}}
{"text":"$F$-\\pcsa{} is straightforward to implement and has several applications in the real world with different choices of $F$. Most notably, it makes distinct count with deletions as simple as distinct count without deletions.","meta":{"url":"http://arxiv.org/abs/2310.14977v1"},"cats":{"benchmark":0.5173825763,"new-dataset":0.0806403673,"data-annotation":0.5034110701,"dev-research":0.1553338402,"llms":0.4879315905,"data-quality":0.114959119}}
{"text":"Reinforcement learning (RL) has helped improve decision-making in several applications.","meta":{"url":"http://arxiv.org/abs/2310.14976v1"},"cats":{"benchmark":0.3329546803,"new-dataset":0.0156042416,"data-annotation":0.4971521713,"dev-research":0.2094770745,"llms":0.4827866174,"data-quality":0.0847282554}}
{"text":"However, applying traditional RL is challenging in some applications, such as rehabilitation of people with a spinal cord injury (SCI).","meta":{"url":"http://arxiv.org/abs/2310.14976v1"},"cats":{"benchmark":0.3563532842,"new-dataset":0.007588163,"data-annotation":0.5132572021,"dev-research":0.2372473571,"llms":0.5242052572,"data-quality":0.0953652037}}
{"text":"Among other factors, using RL in this domain is difficult because there are many possible treatments (i.e., large action space) and few patients (i.e., limited training data).","meta":{"url":"http://arxiv.org/abs/2310.14976v1"},"cats":{"benchmark":0.3664661301,"new-dataset":0.0111074919,"data-annotation":0.4923135782,"dev-research":0.174713711,"llms":0.5393831064,"data-quality":0.0596273113}}
{"text":"Treatments for SCIs have natural groupings, so we propose two approaches to grouping treatments so that an RL agent can learn effectively from limited data.","meta":{"url":"http://arxiv.org/abs/2310.14976v1"},"cats":{"benchmark":0.3450546139,"new-dataset":0.1573399979,"data-annotation":0.507324043,"dev-research":0.1841462048,"llms":0.4685301972,"data-quality":0.1164143408}}
{"text":"One relies on domain knowledge of SCI rehabilitation and the other learns similarities among treatments using an embedding technique.","meta":{"url":"http://arxiv.org/abs/2310.14976v1"},"cats":{"benchmark":0.3251181833,"new-dataset":0.0380441729,"data-annotation":0.5311257487,"dev-research":0.2225775235,"llms":0.5488163267,"data-quality":0.1601144439}}
{"text":"We then use Fitted Q Iteration to train an agent that learns optimal treatments.","meta":{"url":"http://arxiv.org/abs/2310.14976v1"},"cats":{"benchmark":0.3444825282,"new-dataset":0.0366743649,"data-annotation":0.516366648,"dev-research":0.1395316039,"llms":0.4166767277,"data-quality":0.0741307774}}
{"text":"Through a simulation study designed to reflect the properties of SCI rehabilitation, we find that both methods can help improve the treatment decisions of physiotherapists, but the approach based on domain knowledge offers better performance.","meta":{"url":"http://arxiv.org/abs/2310.14976v1"},"cats":{"benchmark":0.4217654237,"new-dataset":0.0336177563,"data-annotation":0.5224016791,"dev-research":0.2483239553,"llms":0.4994298558,"data-quality":0.0981037152}}
{"text":"Our findings provide a \"proof of concept\" that RL can be used to help improve the treatment of those with an SCI and indicates that continued efforts to gather data and apply RL to this domain are worthwhile.","meta":{"url":"http://arxiv.org/abs/2310.14976v1"},"cats":{"benchmark":0.4011924309,"new-dataset":0.0923970071,"data-annotation":0.4979663367,"dev-research":0.2519052104,"llms":0.553497417,"data-quality":0.1687390934}}
{"text":"A crucial element in predicting the outcomes of process interventions and making informed decisions about the process is unraveling the genuine relationships between the execution of process activities.","meta":{"url":"http://arxiv.org/abs/2310.14975v1"},"cats":{"benchmark":0.3074085509,"new-dataset":0.0117718141,"data-annotation":0.4897449096,"dev-research":0.3719607731,"llms":0.5055989469,"data-quality":0.0720759913}}
{"text":"Contemporary process discovery algorithms exploit time precedence as their main source of model derivation.","meta":{"url":"http://arxiv.org/abs/2310.14975v1"},"cats":{"benchmark":0.3500950868,"new-dataset":0.0229644128,"data-annotation":0.4993773345,"dev-research":0.2760664942,"llms":0.4846652905,"data-quality":0.0872696204}}
{"text":"Such reliance can sometimes be deceiving from a causal perspective.","meta":{"url":"http://arxiv.org/abs/2310.14975v1"},"cats":{"benchmark":0.2174048814,"new-dataset":0.002698851,"data-annotation":0.5081743256,"dev-research":0.2096625446,"llms":0.5104377356,"data-quality":0.143883783}}
{"text":"This calls for faithful new techniques to discover the true execution dependencies among the tasks in the process.","meta":{"url":"http://arxiv.org/abs/2310.14975v1"},"cats":{"benchmark":0.4102279867,"new-dataset":0.0206872939,"data-annotation":0.5316124282,"dev-research":0.3143614636,"llms":0.5535082778,"data-quality":0.1634127225}}
{"text":"To this end, our work offers a systematic approach to the unveiling of the true causal business process by leveraging an existing causal discovery algorithm over activity timing.","meta":{"url":"http://arxiv.org/abs/2310.14975v1"},"cats":{"benchmark":0.3577018616,"new-dataset":0.1044862829,"data-annotation":0.5007158192,"dev-research":0.2684061288,"llms":0.4941234691,"data-quality":0.0934637609}}
{"text":"In addition, this work delves into a set of conditions under which process mining discovery algorithms generate a model that is incongruent with the causal business process model, and shows how the latter model can be methodologically employed for a sound analysis of the process.","meta":{"url":"http://arxiv.org/abs/2310.14975v1"},"cats":{"benchmark":0.2674415613,"new-dataset":0.0493831645,"data-annotation":0.5117727418,"dev-research":0.2338929422,"llms":0.520858404,"data-quality":0.1798552091}}
{"text":"Our methodology searches for such discrepancies between the two models in the context of three causal patterns, and derives a new view in which these inconsistencies are annotated over the mined process model.","meta":{"url":"http://arxiv.org/abs/2310.14975v1"},"cats":{"benchmark":0.317820158,"new-dataset":0.0164247812,"data-annotation":0.49326167,"dev-research":0.2772076388,"llms":0.4862916537,"data-quality":0.2324562787}}
{"text":"We demonstrate our methodology employing two open process mining algorithms, the IBM Process Mining tool, and the LiNGAM causal discovery technique.","meta":{"url":"http://arxiv.org/abs/2310.14975v1"},"cats":{"benchmark":0.3564858169,"new-dataset":0.1595085387,"data-annotation":0.5136674132,"dev-research":0.2411913797,"llms":0.5590012451,"data-quality":0.1450672984}}
{"text":"We apply it on a synthesized dataset and on two open benchmark data sets.","meta":{"url":"http://arxiv.org/abs/2310.14975v1"},"cats":{"benchmark":0.7327226905,"new-dataset":0.634273459,"data-annotation":0.5079406639,"dev-research":0.1460390375,"llms":0.3712069691,"data-quality":0.1510325688}}
{"text":"The decoding algorithm is critical for open-ended text generation, transforming latent representations into coherent and meaningful outputs.","meta":{"url":"http://arxiv.org/abs/2310.14971v1"},"cats":{"benchmark":0.2299275392,"new-dataset":0.0780333861,"data-annotation":0.5356796413,"dev-research":0.2121890232,"llms":0.5135690836,"data-quality":0.1864050731}}
{"text":"This paper investigates the self-reinforcement effect in text generation and the effectiveness of a repetition penalty to mitigate it.","meta":{"url":"http://arxiv.org/abs/2310.14971v1"},"cats":{"benchmark":0.2961216256,"new-dataset":0.0186317061,"data-annotation":0.5266641728,"dev-research":0.2752490249,"llms":0.5780007847,"data-quality":0.2098525833}}
{"text":"However, determining the optimal repetition penalty value is challenging.","meta":{"url":"http://arxiv.org/abs/2310.14971v1"},"cats":{"benchmark":0.6501791878,"new-dataset":0.0095499389,"data-annotation":0.5340505353,"dev-research":0.169776916,"llms":0.4239413351,"data-quality":0.1701550868}}
{"text":"To tackle this, we propose a forgetting mechanism that disregards distant tokens, reducing the burden of penalty selection.","meta":{"url":"http://arxiv.org/abs/2310.14971v1"},"cats":{"benchmark":0.3945257131,"new-dataset":0.0111328752,"data-annotation":0.5121745556,"dev-research":0.2220109989,"llms":0.5687432884,"data-quality":0.2490972017}}
{"text":"In addition, we introduce a length penalty to address overly short sentences caused by excessive penalties.","meta":{"url":"http://arxiv.org/abs/2310.14971v1"},"cats":{"benchmark":0.4150183877,"new-dataset":0.0261599893,"data-annotation":0.5443318893,"dev-research":0.3361787734,"llms":0.4939281656,"data-quality":0.2794069768}}
{"text":"Our penalty decoding approach incorporating three strategies helps resolve issues with sampling methods deviating from factual information.","meta":{"url":"http://arxiv.org/abs/2310.14971v1"},"cats":{"benchmark":0.4807490628,"new-dataset":0.0144508268,"data-annotation":0.5186967241,"dev-research":0.201636594,"llms":0.4764561087,"data-quality":0.3312256681}}
{"text":"Experimental results demonstrate the efficacy of our approach in generating high-quality sentences resembling human output.","meta":{"url":"http://arxiv.org/abs/2310.14971v1"},"cats":{"benchmark":0.3488513121,"new-dataset":0.0549605745,"data-annotation":0.5423478442,"dev-research":0.2701899687,"llms":0.5067991718,"data-quality":0.2996576848}}
{"text":"Dialogue State Tracking (DST) is of paramount importance in ensuring accurate tracking of user goals and system actions within task-oriented dialogue systems.","meta":{"url":"http://arxiv.org/abs/2310.14970v1"},"cats":{"benchmark":0.3252723258,"new-dataset":0.0884767912,"data-annotation":0.4913041654,"dev-research":0.2681901858,"llms":0.6009297402,"data-quality":0.1233063019}}
{"text":"The emergence of large language models (LLMs) such as GPT3 and ChatGPT has sparked considerable interest in assessing their efficacy across diverse applications.","meta":{"url":"http://arxiv.org/abs/2310.14970v1"},"cats":{"benchmark":0.2508505153,"new-dataset":0.031006266,"data-annotation":0.5320803726,"dev-research":0.1720034585,"llms":0.664254632,"data-quality":0.1116382741}}
{"text":"In this study, we conduct an initial examination of ChatGPT's capabilities in DST.","meta":{"url":"http://arxiv.org/abs/2310.14970v1"},"cats":{"benchmark":0.2988732626,"new-dataset":0.1068780605,"data-annotation":0.4863579095,"dev-research":0.2411711271,"llms":0.5855653037,"data-quality":0.0590314695}}
{"text":"Our evaluation uncovers the exceptional performance of ChatGPT in this task, offering valuable insights to researchers regarding its capabilities and providing useful directions for designing and enhancing dialogue systems.","meta":{"url":"http://arxiv.org/abs/2310.14970v1"},"cats":{"benchmark":0.3230334147,"new-dataset":0.2299045823,"data-annotation":0.5204661987,"dev-research":0.2733585497,"llms":0.6025954047,"data-quality":0.1269291024}}
{"text":"Despite its impressive performance, ChatGPT has significant limitations including its closed-source nature, request restrictions, raising data privacy concerns, and lacking local deployment capabilities.","meta":{"url":"http://arxiv.org/abs/2310.14970v1"},"cats":{"benchmark":0.3129368547,"new-dataset":0.1316565147,"data-annotation":0.4944712081,"dev-research":0.2712534756,"llms":0.5695078274,"data-quality":0.0880758994}}
{"text":"To address these concerns, we present LDST, an LLM-driven DST framework based on smaller, open-source foundation models.","meta":{"url":"http://arxiv.org/abs/2310.14970v1"},"cats":{"benchmark":0.304322377,"new-dataset":0.1091728477,"data-annotation":0.4624226656,"dev-research":0.1872378076,"llms":0.6747889972,"data-quality":0.0532789291}}
{"text":"By utilizing a novel domain-slot instruction tuning method, LDST achieves performance on par with ChatGPT.","meta":{"url":"http://arxiv.org/abs/2310.14970v1"},"cats":{"benchmark":0.407406611,"new-dataset":0.0555545779,"data-annotation":0.512887827,"dev-research":0.2513681391,"llms":0.6288586425,"data-quality":0.1059610257}}
{"text":"Comprehensive evaluations across three distinct experimental settings, we find that LDST exhibits remarkable performance improvements in both zero-shot and few-shot setting compared to previous SOTA methods.","meta":{"url":"http://arxiv.org/abs/2310.14970v1"},"cats":{"benchmark":0.5782696007,"new-dataset":0.0279126449,"data-annotation":0.5205299613,"dev-research":0.1166328831,"llms":0.5325693826,"data-quality":0.096647012}}
{"text":"The source code is provided for reproducibility.","meta":{"url":"http://arxiv.org/abs/2310.14970v1"},"cats":{"benchmark":0.3551394836,"new-dataset":0.2599002623,"data-annotation":0.5275501369,"dev-research":0.2914763415,"llms":0.5136168784,"data-quality":0.2122799199}}
{"text":"Many applications involve estimation of parameters that generalize across multiple diverse, but related, data-scarce task environments.","meta":{"url":"http://arxiv.org/abs/2310.14968v1"},"cats":{"benchmark":0.4459183631,"new-dataset":0.0193536242,"data-annotation":0.512259179,"dev-research":0.1837141101,"llms":0.3648434178,"data-quality":0.0622122457}}
{"text":"Bayesian active meta-learning, a form of sequential optimal experimental design, provides a framework for solving such problems.","meta":{"url":"http://arxiv.org/abs/2310.14968v1"},"cats":{"benchmark":0.4128725216,"new-dataset":0.046077332,"data-annotation":0.5074403395,"dev-research":0.1731472661,"llms":0.390724315,"data-quality":0.079363721}}
{"text":"The active meta-learner's goal is to gain transferable knowledge (estimate the transferable parameters) in the presence of idiosyncratic characteristics of the current task (task-specific parameters).","meta":{"url":"http://arxiv.org/abs/2310.14968v1"},"cats":{"benchmark":0.2787519429,"new-dataset":0.0513374355,"data-annotation":0.5173122516,"dev-research":0.1911892203,"llms":0.4660178778,"data-quality":0.0971399379}}
{"text":"We show that in such a setting, greedy pursuit of this goal can actually hurt estimation of the transferable parameters (induce so-called negative transfer).","meta":{"url":"http://arxiv.org/abs/2310.14968v1"},"cats":{"benchmark":0.4086033976,"new-dataset":0.0105061788,"data-annotation":0.5382074756,"dev-research":0.1053028725,"llms":0.3646382675,"data-quality":0.1180045538}}
{"text":"The learner faces a dilemma akin to but distinct from the exploration--exploitation dilemma: should they spend their acquisition budget pursuing transferable knowledge, or identifying the current task-specific parameters?","meta":{"url":"http://arxiv.org/abs/2310.14968v1"},"cats":{"benchmark":0.1471297951,"new-dataset":0.0715709275,"data-annotation":0.5068610297,"dev-research":0.2377706326,"llms":0.5466759628,"data-quality":0.096085817}}
{"text":"We show theoretically that some tasks pose an inevitable and arbitrarily large threat of negative transfer, and that task identification is critical to reducing this threat.","meta":{"url":"http://arxiv.org/abs/2310.14968v1"},"cats":{"benchmark":0.2346253006,"new-dataset":0.0218151263,"data-annotation":0.5291640088,"dev-research":0.2018362048,"llms":0.507955672,"data-quality":0.1495999398}}
{"text":"Our results generalize to analysis of prior misspecification over nuisance parameters.","meta":{"url":"http://arxiv.org/abs/2310.14968v1"},"cats":{"benchmark":0.5644336205,"new-dataset":0.0079381669,"data-annotation":0.5222892885,"dev-research":0.1948085367,"llms":0.4357697828,"data-quality":0.4125614105}}
{"text":"Finally, we empirically illustrate circumstances that lead to negative transfer.","meta":{"url":"http://arxiv.org/abs/2310.14968v1"},"cats":{"benchmark":0.3032886225,"new-dataset":0.0171547255,"data-annotation":0.5219211601,"dev-research":0.2982900484,"llms":0.5100355253,"data-quality":0.1827854206}}
{"text":"We present Cutie, a video object segmentation (VOS) network with object-level memory reading, which puts the object representation from memory back into the video object segmentation result.","meta":{"url":"http://arxiv.org/abs/2310.12982v1"},"cats":{"benchmark":0.1998810538,"new-dataset":0.2019607259,"data-annotation":0.5065875301,"dev-research":0.1727922527,"llms":0.5554126177,"data-quality":0.1866218602}}
{"text":"Recent works on VOS employ bottom-up pixel-level memory reading which struggles due to matching noise, especially in the presence of distractors, resulting in lower performance in more challenging data.","meta":{"url":"http://arxiv.org/abs/2310.12982v1"},"cats":{"benchmark":0.4327511235,"new-dataset":0.0739469294,"data-annotation":0.4877967174,"dev-research":0.1743244523,"llms":0.5681268705,"data-quality":0.2110354543}}
{"text":"In contrast, Cutie performs top-down object-level memory reading by adapting a small set of object queries for restructuring and interacting with the bottom-up pixel features iteratively with a query-based object transformer (qt, hence Cutie).","meta":{"url":"http://arxiv.org/abs/2310.12982v1"},"cats":{"benchmark":0.3120065207,"new-dataset":0.0414322377,"data-annotation":0.4937886366,"dev-research":0.1675159015,"llms":0.5780281053,"data-quality":0.0925854362}}
{"text":"The object queries act as a high-level summary of the target object, while high-resolution feature maps are retained for accurate segmentation.","meta":{"url":"http://arxiv.org/abs/2310.12982v1"},"cats":{"benchmark":0.3015793088,"new-dataset":0.0398594614,"data-annotation":0.480307319,"dev-research":0.2190960026,"llms":0.4971192183,"data-quality":0.1184993849}}
{"text":"Together with foreground-background masked attention, Cutie cleanly separates the semantics of the foreground object from the background.","meta":{"url":"http://arxiv.org/abs/2310.12982v1"},"cats":{"benchmark":0.2262949493,"new-dataset":0.0398230649,"data-annotation":0.5248888469,"dev-research":0.2104258507,"llms":0.5132510022,"data-quality":0.2395695318}}
{"text":"On the challenging MOSE dataset, Cutie improves by 8.7 J&F over XMem with a similar running time and improves by 4.2 J&F over DeAOT while running three times as fast.","meta":{"url":"http://arxiv.org/abs/2310.12982v1"},"cats":{"benchmark":0.5216353234,"new-dataset":0.0696755331,"data-annotation":0.5026982511,"dev-research":0.1487151643,"llms":0.5407411966,"data-quality":0.0956727779}}
{"text":"Code is available at: https://hkchengrex.github.io/Cutie","meta":{"url":"http://arxiv.org/abs/2310.12982v1"},"cats":{"benchmark":0.3613765029,"new-dataset":0.2146734253,"data-annotation":0.5305933822,"dev-research":0.224929398,"llms":0.5447933954,"data-quality":0.1389910195}}
{"text":"This work targets a novel text-driven whole-body motion generation task, which takes a given textual description as input and aims at generating high-quality, diverse, and coherent facial expressions, hand gestures, and body motions simultaneously.","meta":{"url":"http://arxiv.org/abs/2310.12978v1"},"cats":{"benchmark":0.1719589429,"new-dataset":0.3821088319,"data-annotation":0.5129180123,"dev-research":0.2373428029,"llms":0.5216935278,"data-quality":0.071396}}
{"text":"Previous works on text-driven motion generation tasks mainly have two limitations: they ignore the key role of fine-grained hand and face controlling in vivid whole-body motion generation, and lack a good alignment between text and motion.","meta":{"url":"http://arxiv.org/abs/2310.12978v1"},"cats":{"benchmark":0.2205130326,"new-dataset":0.0681426411,"data-annotation":0.5146478182,"dev-research":0.2452241654,"llms":0.562484446,"data-quality":0.0811437163}}
{"text":"To address such limitations, we propose a Text-aligned whOle-body Motion generATiOn framework, named HumanTOMATO, which is the first attempt to our knowledge towards applicable holistic motion generation in this research area.","meta":{"url":"http://arxiv.org/abs/2310.12978v1"},"cats":{"benchmark":0.2273132349,"new-dataset":0.3893695275,"data-annotation":0.5017138517,"dev-research":0.2146667293,"llms":0.5054585615,"data-quality":0.0487230199}}
{"text":"To tackle this challenging task, our solution includes two key designs: (1) a Holistic Hierarchical VQ-VAE (aka H$^2$VQ) and a Hierarchical-GPT for fine-grained body and hand motion reconstruction and generation with two structured codebooks; and (2) a pre-trained text-motion-alignment model to help generated motion align with the input textual description explicitly.","meta":{"url":"http://arxiv.org/abs/2310.12978v1"},"cats":{"benchmark":0.2614224567,"new-dataset":0.4461513413,"data-annotation":0.5240576427,"dev-research":0.1790925905,"llms":0.4961341771,"data-quality":0.0832939572}}
{"text":"Comprehensive experiments verify that our model has significant advantages in both the quality of generated motions and their alignment with text.","meta":{"url":"http://arxiv.org/abs/2310.12978v1"},"cats":{"benchmark":0.401386253,"new-dataset":0.0342445276,"data-annotation":0.5284315278,"dev-research":0.1486860395,"llms":0.4809705599,"data-quality":0.1094685971}}
{"text":"The study of Deep Network (DN) training dynamics has largely focused on the evolution of the loss function, evaluated on or around train and test set data points.","meta":{"url":"http://arxiv.org/abs/2310.12977v1"},"cats":{"benchmark":0.2845919245,"new-dataset":0.0583808684,"data-annotation":0.5135500004,"dev-research":0.1747051935,"llms":0.4667451432,"data-quality":0.1404515483}}
{"text":"In fact, many DN phenomenon were first introduced in literature with that respect, e.g., double descent, grokking.","meta":{"url":"http://arxiv.org/abs/2310.12977v1"},"cats":{"benchmark":0.2538559059,"new-dataset":0.0132214405,"data-annotation":0.503449571,"dev-research":0.1566495424,"llms":0.5681187371,"data-quality":0.1299074576}}
{"text":"In this study, we look at the training dynamics of the input space partition or linear regions formed by continuous piecewise affine DNs, e.g., networks with (leaky)ReLU nonlinearities.","meta":{"url":"http://arxiv.org/abs/2310.12977v1"},"cats":{"benchmark":0.3158584922,"new-dataset":0.0441617902,"data-annotation":0.5145029827,"dev-research":0.1092028591,"llms":0.3748913018,"data-quality":0.1754841663}}
{"text":"First, we present a novel statistic that encompasses the local complexity (LC) of the DN based on the concentration of linear regions inside arbitrary dimensional neighborhoods around data points.","meta":{"url":"http://arxiv.org/abs/2310.12977v1"},"cats":{"benchmark":0.4922493226,"new-dataset":0.1852660825,"data-annotation":0.5129958989,"dev-research":0.1822074736,"llms":0.4157271721,"data-quality":0.1199320918}}
{"text":"We observe that during training, the LC around data points undergoes a number of phases, starting with a decreasing trend after initialization, followed by an ascent and ending with a final descending trend.","meta":{"url":"http://arxiv.org/abs/2310.12977v1"},"cats":{"benchmark":0.3280306874,"new-dataset":0.0905984925,"data-annotation":0.5048016933,"dev-research":0.1049306156,"llms":0.3936327034,"data-quality":0.1214653853}}
{"text":"Using exact visualization methods, we come across the perplexing observation that during the final LC descent phase of training, linear regions migrate away from training and test samples towards the decision boundary, making the DN input-output nearly linear everywhere else.","meta":{"url":"http://arxiv.org/abs/2310.12977v1"},"cats":{"benchmark":0.3795066224,"new-dataset":0.0255469833,"data-annotation":0.5030244525,"dev-research":0.1577508856,"llms":0.4064153631,"data-quality":0.1768025519}}
{"text":"We also observe that the different LC phases are closely related to the memorization and generalization performance of the DN, especially during grokking.","meta":{"url":"http://arxiv.org/abs/2310.12977v1"},"cats":{"benchmark":0.4030085121,"new-dataset":0.0221770361,"data-annotation":0.5110279876,"dev-research":0.1089187983,"llms":0.5824202206,"data-quality":0.0957084244}}
{"text":"In this paper, we introduce an intriguing phenomenon-the successful reconstruction of images using a set of one-way wave equations with hidden and learnable speeds.","meta":{"url":"http://arxiv.org/abs/2310.12976v1"},"cats":{"benchmark":0.2460542016,"new-dataset":0.1418352082,"data-annotation":0.5147729293,"dev-research":0.1335207193,"llms":0.4365173632,"data-quality":0.0753688734}}
{"text":"Each individual image corresponds to a solution with a unique initial condition, which can be computed from the original image using a visual encoder (e.g., a convolutional neural network).","meta":{"url":"http://arxiv.org/abs/2310.12976v1"},"cats":{"benchmark":0.2734467915,"new-dataset":0.1662869285,"data-annotation":0.5152735328,"dev-research":0.1631032611,"llms":0.3946612598,"data-quality":0.0828171118}}
{"text":"Furthermore, the solution for each image exhibits two noteworthy mathematical properties: (a) it can be decomposed into a collection of special solutions of the same one-way wave equations that are first-order autoregressive, with shared coefficient matrices for autoregression, and (b) the product of these coefficient matrices forms a diagonal matrix with the speeds of the wave equations as its diagonal elements.","meta":{"url":"http://arxiv.org/abs/2310.12976v1"},"cats":{"benchmark":0.3169912304,"new-dataset":0.0959709979,"data-annotation":0.5149779105,"dev-research":0.1311132819,"llms":0.3690692859,"data-quality":0.0506539149}}
{"text":"We term this phenomenon hidden waves, as it reveals that, although the speeds of the set of wave equations and autoregressive coefficient matrices are latent, they are both learnable and shared across images.","meta":{"url":"http://arxiv.org/abs/2310.12976v1"},"cats":{"benchmark":0.2215784741,"new-dataset":0.0489766159,"data-annotation":0.5319353531,"dev-research":0.1363765011,"llms":0.3794129197,"data-quality":0.0949224145}}
{"text":"This represents a mathematical invariance across images, providing a new mathematical perspective to understand images.","meta":{"url":"http://arxiv.org/abs/2310.12976v1"},"cats":{"benchmark":0.2117722966,"new-dataset":0.0521422154,"data-annotation":0.5264935953,"dev-research":0.1794929135,"llms":0.4013512438,"data-quality":0.0863071166}}
{"text":"We present a novel variational framework for performing inference in (neural) stochastic differential equations (SDEs) driven by Markov-approximate fractional Brownian motion (fBM).","meta":{"url":"http://arxiv.org/abs/2310.12975v1"},"cats":{"benchmark":0.2961421338,"new-dataset":0.0173840212,"data-annotation":0.4984840977,"dev-research":0.1489140267,"llms":0.4942070935,"data-quality":0.0793794527}}
{"text":"SDEs offer a versatile tool for modeling real-world continuous-time dynamic systems with inherent noise and randomness.","meta":{"url":"http://arxiv.org/abs/2310.12975v1"},"cats":{"benchmark":0.3586535702,"new-dataset":0.0589349671,"data-annotation":0.4850737716,"dev-research":0.1951161705,"llms":0.4901027975,"data-quality":0.0823022055}}
{"text":"Combining SDEs with the powerful inference capabilities of variational methods, enables the learning of representative function distributions through stochastic gradient descent.","meta":{"url":"http://arxiv.org/abs/2310.12975v1"},"cats":{"benchmark":0.3985659955,"new-dataset":0.0100521554,"data-annotation":0.5319157291,"dev-research":0.1526079071,"llms":0.4169937597,"data-quality":0.1193320219}}
{"text":"However, conventional SDEs typically assume the underlying noise to follow a Brownian motion (BM), which hinders their ability to capture long-term dependencies.","meta":{"url":"http://arxiv.org/abs/2310.12975v1"},"cats":{"benchmark":0.3181950349,"new-dataset":0.0068318178,"data-annotation":0.4859805262,"dev-research":0.1553962675,"llms":0.5394959617,"data-quality":0.1345148809}}
{"text":"In contrast, fractional Brownian motion (fBM) extends BM to encompass non-Markovian dynamics, but existing methods for inferring fBM parameters are either computationally demanding or statistically inefficient.","meta":{"url":"http://arxiv.org/abs/2310.12975v1"},"cats":{"benchmark":0.4379880798,"new-dataset":0.0095370912,"data-annotation":0.5008760896,"dev-research":0.0904968528,"llms":0.5250439118,"data-quality":0.0597380534}}
{"text":"In this paper, building upon the Markov approximation of fBM, we derive the evidence lower bound essential for efficient variational inference of posterior path measures, drawing from the well-established field of stochastic analysis.","meta":{"url":"http://arxiv.org/abs/2310.12975v1"},"cats":{"benchmark":0.5069328613,"new-dataset":0.0190442025,"data-annotation":0.5238349989,"dev-research":0.132535306,"llms":0.4699351816,"data-quality":0.0841892495}}
{"text":"Additionally, we provide a closed-form expression to determine optimal approximation coefficients.","meta":{"url":"http://arxiv.org/abs/2310.12975v1"},"cats":{"benchmark":0.6754032527,"new-dataset":0.0154287466,"data-annotation":0.5445248743,"dev-research":0.1410651494,"llms":0.272690269,"data-quality":0.1284191007}}
{"text":"Furthermore, we propose the use of neural networks to learn the drift, diffusion and control terms within our variational posterior, leading to the variational training of neural-SDEs.","meta":{"url":"http://arxiv.org/abs/2310.12975v1"},"cats":{"benchmark":0.2927516867,"new-dataset":0.0224242525,"data-annotation":0.5153608002,"dev-research":0.129931995,"llms":0.4725496464,"data-quality":0.1112582945}}
{"text":"In this framework, we also optimize the Hurst index, governing the nature of our fractional noise.","meta":{"url":"http://arxiv.org/abs/2310.12975v1"},"cats":{"benchmark":0.5251533289,"new-dataset":0.0709020289,"data-annotation":0.5330732935,"dev-research":0.1306364608,"llms":0.3854173311,"data-quality":0.1769497588}}
{"text":"Beyond validation on synthetic data, we contribute a novel architecture for variational latent video prediction,-an approach that, to the best of our knowledge, enables the first variational neural-SDE application to video perception.","meta":{"url":"http://arxiv.org/abs/2310.12975v1"},"cats":{"benchmark":0.2959021871,"new-dataset":0.0641312154,"data-annotation":0.5127334592,"dev-research":0.1357594721,"llms":0.4314653726,"data-quality":0.1304321728}}
{"text":"In this work, we address the challenging task of 3D object recognition without the reliance on real-world 3D labeled data.","meta":{"url":"http://arxiv.org/abs/2310.12974v1"},"cats":{"benchmark":0.2661163482,"new-dataset":0.3013226614,"data-annotation":0.4967601846,"dev-research":0.1365017464,"llms":0.4184554909,"data-quality":0.2905821465}}
{"text":"Our goal is to predict the 3D shape, size, and 6D pose of objects within a single RGB-D image, operating at the category level and eliminating the need for CAD models during inference.","meta":{"url":"http://arxiv.org/abs/2310.12974v1"},"cats":{"benchmark":0.2409769174,"new-dataset":0.259808744,"data-annotation":0.5056680545,"dev-research":0.1545274968,"llms":0.435919882,"data-quality":0.0659602286}}
{"text":"While existing self-supervised methods have made strides in this field, they often suffer from inefficiencies arising from non-end-to-end processing, reliance on separate models for different object categories, and slow surface extraction during the training of implicit reconstruction models; thus hindering both the speed and real-world applicability of the 3D recognition process.","meta":{"url":"http://arxiv.org/abs/2310.12974v1"},"cats":{"benchmark":0.2820673821,"new-dataset":0.0563716604,"data-annotation":0.531862494,"dev-research":0.1547165164,"llms":0.4389645013,"data-quality":0.1858331129}}
{"text":"Our proposed method leverages a multi-stage training pipeline, designed to efficiently transfer synthetic performance to the real-world domain.","meta":{"url":"http://arxiv.org/abs/2310.12974v1"},"cats":{"benchmark":0.3111786718,"new-dataset":0.1087576867,"data-annotation":0.4780282846,"dev-research":0.1970863948,"llms":0.4805788147,"data-quality":0.1140360674}}
{"text":"This approach is achieved through a combination of 2D and 3D supervised losses during the synthetic domain training, followed by the incorporation of 2D supervised and 3D self-supervised losses on real-world data in two additional learning stages.","meta":{"url":"http://arxiv.org/abs/2310.12974v1"},"cats":{"benchmark":0.2460989272,"new-dataset":0.1881085414,"data-annotation":0.5134715036,"dev-research":0.1733645893,"llms":0.4321179591,"data-quality":0.1676851906}}
{"text":"By adopting this comprehensive strategy, our method successfully overcomes the aforementioned limitations and outperforms existing self-supervised 6D pose and size estimation baselines on the NOCS test-set with a 16.4% absolute improvement in mAP for 6D pose estimation while running in near real-time at 5 Hz.","meta":{"url":"http://arxiv.org/abs/2310.12974v1"},"cats":{"benchmark":0.3193064521,"new-dataset":0.3890883109,"data-annotation":0.5063657391,"dev-research":0.1498252374,"llms":0.5207999921,"data-quality":0.1264856186}}
{"text":"This paper reveals that large language models (LLMs), despite being trained solely on textual data, are surprisingly strong encoders for purely visual tasks in the absence of language.","meta":{"url":"http://arxiv.org/abs/2310.12973v1"},"cats":{"benchmark":0.1660132538,"new-dataset":0.1463723208,"data-annotation":0.5290989569,"dev-research":0.1343264962,"llms":0.6653154772,"data-quality":0.188428694}}
{"text":"Even more intriguingly, this can be achieved by a simple yet previously overlooked strategy -- employing a frozen transformer block from pre-trained LLMs as a constituent encoder layer to directly process visual tokens.","meta":{"url":"http://arxiv.org/abs/2310.12973v1"},"cats":{"benchmark":0.1798783694,"new-dataset":0.0372198908,"data-annotation":0.5029872711,"dev-research":0.1549399847,"llms":0.7120252181,"data-quality":0.1490427104}}
{"text":"Our work pushes the boundaries of leveraging LLMs for computer vision tasks, significantly departing from conventional practices that typically necessitate a multi-modal vision-language setup with associated language prompts, inputs, or outputs.","meta":{"url":"http://arxiv.org/abs/2310.12973v1"},"cats":{"benchmark":0.1373979982,"new-dataset":0.118086067,"data-annotation":0.4971622431,"dev-research":0.2288542795,"llms":0.7605481478,"data-quality":0.1559442429}}
{"text":"We demonstrate that our approach consistently enhances performance across a diverse range of tasks, encompassing pure 2D and 3D visual recognition tasks (e.g., image and point cloud classification), temporal modeling tasks (e.g., action recognition), non-semantic tasks (e.g., motion forecasting), and multi-modal tasks (e.g., 2D/3D visual question answering and image-text retrieval).","meta":{"url":"http://arxiv.org/abs/2310.12973v1"},"cats":{"benchmark":0.3355563306,"new-dataset":0.083471075,"data-annotation":0.5114347191,"dev-research":0.1631686522,"llms":0.4772526413,"data-quality":0.0723867202}}
{"text":"Such improvements are a general phenomenon, applicable to various types of LLMs (e.g., LLaMA and OPT) and different LLM transformer blocks.","meta":{"url":"http://arxiv.org/abs/2310.12973v1"},"cats":{"benchmark":0.4074037915,"new-dataset":0.0017316544,"data-annotation":0.5071360927,"dev-research":0.1694630097,"llms":0.7566632717,"data-quality":0.1058824945}}
{"text":"We additionally propose the information filtering hypothesis to explain the effectiveness of pre-trained LLMs in visual encoding -- the pre-trained LLM transformer blocks discern informative visual tokens and further amplify their effect.","meta":{"url":"http://arxiv.org/abs/2310.12973v1"},"cats":{"benchmark":0.1906236929,"new-dataset":0.0114836337,"data-annotation":0.5149914103,"dev-research":0.1838989533,"llms":0.6680331946,"data-quality":0.1967022084}}
{"text":"This hypothesis is empirically supported by the observation that the feature activation, after training with LLM transformer blocks, exhibits a stronger focus on relevant regions.","meta":{"url":"http://arxiv.org/abs/2310.12973v1"},"cats":{"benchmark":0.2875291271,"new-dataset":0.0056181618,"data-annotation":0.5147891068,"dev-research":0.1447822667,"llms":0.559685488,"data-quality":0.1367453986}}
{"text":"We hope that our work inspires new perspectives on utilizing LLMs and deepening our understanding of their underlying mechanisms.","meta":{"url":"http://arxiv.org/abs/2310.12973v1"},"cats":{"benchmark":0.1485743366,"new-dataset":0.037628774,"data-annotation":0.4878932208,"dev-research":0.1300673767,"llms":0.8304279402,"data-quality":0.0680572244}}
{"text":"Code is available at https://github.com/ziqipang/LM4VisualEncoding.","meta":{"url":"http://arxiv.org/abs/2310.12973v1"},"cats":{"benchmark":0.2957599681,"new-dataset":0.2216009572,"data-annotation":0.5431444896,"dev-research":0.1586394219,"llms":0.5370849266,"data-quality":0.2389434985}}
{"text":"We present a new technique to enhance the robustness of imitation learning methods by generating corrective data to account for compounding errors and disturbances.","meta":{"url":"http://arxiv.org/abs/2310.12972v1"},"cats":{"benchmark":0.3442498106,"new-dataset":0.0199836792,"data-annotation":0.510233551,"dev-research":0.2025313776,"llms":0.3806301989,"data-quality":0.2069106828}}
{"text":"While existing methods rely on interactive expert labeling, additional offline datasets, or domain-specific invariances, our approach requires minimal additional assumptions beyond access to expert data.","meta":{"url":"http://arxiv.org/abs/2310.12972v1"},"cats":{"benchmark":0.3274913231,"new-dataset":0.2868112384,"data-annotation":0.5206481866,"dev-research":0.259667214,"llms":0.467355699,"data-quality":0.313623534}}
{"text":"The key insight is to leverage local continuity in the environment dynamics to generate corrective labels.","meta":{"url":"http://arxiv.org/abs/2310.12972v1"},"cats":{"benchmark":0.2785294284,"new-dataset":0.053090558,"data-annotation":0.486149777,"dev-research":0.2588987996,"llms":0.5356555162,"data-quality":0.444372963}}
{"text":"Our method first constructs a dynamics model from the expert demonstration, encouraging local Lipschitz continuity in the learned model.","meta":{"url":"http://arxiv.org/abs/2310.12972v1"},"cats":{"benchmark":0.3312003961,"new-dataset":0.067429973,"data-annotation":0.5050813006,"dev-research":0.1803422638,"llms":0.4454588797,"data-quality":0.1169481978}}
{"text":"In locally continuous regions, this model allows us to generate corrective labels within the neighborhood of the demonstrations but beyond the actual set of states and actions in the dataset.","meta":{"url":"http://arxiv.org/abs/2310.12972v1"},"cats":{"benchmark":0.1977762148,"new-dataset":0.3260926511,"data-annotation":0.5022408522,"dev-research":0.1858089461,"llms":0.5093227938,"data-quality":0.2575908545}}
{"text":"Training on this augmented data enhances the agent's ability to recover from perturbations and deal with compounding errors.","meta":{"url":"http://arxiv.org/abs/2310.12972v1"},"cats":{"benchmark":0.34267059,"new-dataset":0.016447373,"data-annotation":0.5004734111,"dev-research":0.2215754139,"llms":0.4291512664,"data-quality":0.1863685358}}
{"text":"We demonstrate the effectiveness of our generated labels through experiments in a variety of robotics domains in simulation that have distinct forms of continuity and discontinuity, including classic control problems, drone flying, navigation with high-dimensional sensor observations, legged locomotion, and tabletop manipulation.","meta":{"url":"http://arxiv.org/abs/2310.12972v1"},"cats":{"benchmark":0.2386488507,"new-dataset":0.1018749551,"data-annotation":0.4944227717,"dev-research":0.1906630025,"llms":0.5558262503,"data-quality":0.2281306618}}
{"text":"The real-world deployment of an autonomous driving system requires its components to run on-board and in real-time, including the motion prediction module that predicts the future trajectories of surrounding traffic participants.","meta":{"url":"http://arxiv.org/abs/2310.12970v1"},"cats":{"benchmark":0.2206805195,"new-dataset":0.1497671588,"data-annotation":0.5106195267,"dev-research":0.2226735703,"llms":0.3918648497,"data-quality":0.0498844941}}
{"text":"Existing agent-centric methods have demonstrated outstanding performance on public benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.12970v1"},"cats":{"benchmark":0.625513671,"new-dataset":0.0334216474,"data-annotation":0.5292059615,"dev-research":0.1918175425,"llms":0.5138384189,"data-quality":0.0788950211}}
{"text":"However, they suffer from high computational overhead and poor scalability as the number of agents to be predicted increases.","meta":{"url":"http://arxiv.org/abs/2310.12970v1"},"cats":{"benchmark":0.3919659177,"new-dataset":0.0351724439,"data-annotation":0.5452647112,"dev-research":0.1987327647,"llms":0.4585559894,"data-quality":0.0536976065}}
{"text":"To address this problem, we introduce the K-nearest neighbor attention with relative pose encoding (KNARPE), a novel attention mechanism allowing the pairwise-relative representation to be used by Transformers.","meta":{"url":"http://arxiv.org/abs/2310.12970v1"},"cats":{"benchmark":0.2539927785,"new-dataset":0.2304719722,"data-annotation":0.5376517133,"dev-research":0.1669159421,"llms":0.4772308305,"data-quality":0.1127249431}}
{"text":"Then, based on KNARPE we present the Heterogeneous Polyline Transformer with Relative pose encoding (HPTR), a hierarchical framework enabling asynchronous token update during the online inference.","meta":{"url":"http://arxiv.org/abs/2310.12970v1"},"cats":{"benchmark":0.3520958767,"new-dataset":0.0709190047,"data-annotation":0.504430739,"dev-research":0.1450467506,"llms":0.4332979057,"data-quality":0.0566584784}}
{"text":"By sharing contexts among agents and reusing the unchanged contexts, our approach is as efficient as scene-centric methods, while performing on par with state-of-the-art agent-centric methods.","meta":{"url":"http://arxiv.org/abs/2310.12970v1"},"cats":{"benchmark":0.2809110364,"new-dataset":0.1294841396,"data-annotation":0.5299165162,"dev-research":0.2266330128,"llms":0.5223945573,"data-quality":0.1750538489}}
{"text":"Experiments on Waymo and Argoverse-2 datasets show that HPTR achieves superior performance among end-to-end methods that do not apply expensive post-processing or model ensembling.","meta":{"url":"http://arxiv.org/abs/2310.12970v1"},"cats":{"benchmark":0.4745732852,"new-dataset":0.106630308,"data-annotation":0.4926622551,"dev-research":0.2326980489,"llms":0.5747692982,"data-quality":0.0813215457}}
{"text":"The code is available at https://github.com/zhejz/HPTR.","meta":{"url":"http://arxiv.org/abs/2310.12970v1"},"cats":{"benchmark":0.3309747098,"new-dataset":0.2678834242,"data-annotation":0.5187552734,"dev-research":0.1840536704,"llms":0.5113956879,"data-quality":0.1049938256}}
{"text":"The evaluation of machine-generated image captions poses an interesting yet persistent challenge.","meta":{"url":"http://arxiv.org/abs/2310.12971v1"},"cats":{"benchmark":0.3566388941,"new-dataset":0.1733672851,"data-annotation":0.5490515358,"dev-research":0.1926558047,"llms":0.5285762416,"data-quality":0.3535888337}}
{"text":"Effective evaluation measures must consider numerous dimensions of similarity, including semantic relevance, visual structure, object interactions, caption diversity, and specificity.","meta":{"url":"http://arxiv.org/abs/2310.12971v1"},"cats":{"benchmark":0.4406633712,"new-dataset":0.054212974,"data-annotation":0.5514561777,"dev-research":0.2158581805,"llms":0.5098881595,"data-quality":0.1573535183}}
{"text":"Existing highly-engineered measures attempt to capture specific aspects, but fall short in providing a holistic score that aligns closely with human judgments.","meta":{"url":"http://arxiv.org/abs/2310.12971v1"},"cats":{"benchmark":0.4692865581,"new-dataset":0.031996366,"data-annotation":0.5191156894,"dev-research":0.2817992517,"llms":0.5148265244,"data-quality":0.1549648204}}
{"text":"Here, we propose CLAIR, a novel method that leverages the zero-shot language modeling capabilities of large language models (LLMs) to evaluate candidate captions.","meta":{"url":"http://arxiv.org/abs/2310.12971v1"},"cats":{"benchmark":0.3570459243,"new-dataset":0.2575596573,"data-annotation":0.5680105289,"dev-research":0.1411252494,"llms":0.5588141765,"data-quality":0.3080235391}}
{"text":"In our evaluations, CLAIR demonstrates a stronger correlation with human judgments of caption quality compared to existing measures.","meta":{"url":"http://arxiv.org/abs/2310.12971v1"},"cats":{"benchmark":0.4117722519,"new-dataset":0.0960543056,"data-annotation":0.5623841306,"dev-research":0.2636877162,"llms":0.5108684704,"data-quality":0.3678173181}}
{"text":"Notably, on Flickr8K-Expert, CLAIR achieves relative correlation improvements over SPICE of 39.6% and over image-augmented methods such as RefCLIP-S of 18.3%.","meta":{"url":"http://arxiv.org/abs/2310.12971v1"},"cats":{"benchmark":0.5758269739,"new-dataset":0.0549651461,"data-annotation":0.5297221485,"dev-research":0.1959078018,"llms":0.4161803482,"data-quality":0.1547347512}}
{"text":"Moreover, CLAIR provides noisily interpretable results by allowing the language model to identify the underlying reasoning behind its assigned score.","meta":{"url":"http://arxiv.org/abs/2310.12971v1"},"cats":{"benchmark":0.3415986106,"new-dataset":0.0245754444,"data-annotation":0.5593865795,"dev-research":0.2588789738,"llms":0.4594375083,"data-quality":0.3717750709}}
{"text":"Code is available at https://davidmchan.github.io/clair/","meta":{"url":"http://arxiv.org/abs/2310.12971v1"},"cats":{"benchmark":0.279482693,"new-dataset":0.2727910446,"data-annotation":0.5392717469,"dev-research":0.2167009221,"llms":0.4926464221,"data-quality":0.0993754985}}
{"text":"Stochastic gradient descent (SGD) and its variants are the main workhorses for solving large-scale optimization problems with nonconvex objective functions.","meta":{"url":"http://arxiv.org/abs/2310.12969v1"},"cats":{"benchmark":0.5140405165,"new-dataset":0.006147991,"data-annotation":0.5198398504,"dev-research":0.1550476392,"llms":0.4298687776,"data-quality":0.0746191608}}
{"text":"Although the convergence of SGDs in the (strongly) convex case is well-understood, their convergence for nonconvex functions stands on weak mathematical foundations.","meta":{"url":"http://arxiv.org/abs/2310.12969v1"},"cats":{"benchmark":0.4978394042,"new-dataset":0.0072470228,"data-annotation":0.5112950441,"dev-research":0.1400073007,"llms":0.4918388672,"data-quality":0.1290863123}}
{"text":"Most existing studies on the nonconvex convergence of SGD show the complexity results based on either the minimum of the expected gradient norm or the functional sub-optimality gap (for functions with extra structural property) by searching the entire range of iterates.","meta":{"url":"http://arxiv.org/abs/2310.12969v1"},"cats":{"benchmark":0.5911020944,"new-dataset":0.0059527294,"data-annotation":0.5303022581,"dev-research":0.0946323593,"llms":0.4551046817,"data-quality":0.0608530728}}
{"text":"Hence the last iterations of SGDs do not necessarily maintain the same complexity guarantee.","meta":{"url":"http://arxiv.org/abs/2310.12969v1"},"cats":{"benchmark":0.5148201302,"new-dataset":0.0020792213,"data-annotation":0.506365318,"dev-research":0.13788031,"llms":0.5554384248,"data-quality":0.1055438327}}
{"text":"This paper shows that an $\\epsilon$-stationary point exists in the final iterates of SGDs, given a large enough total iteration budget, $T$, not just anywhere in the entire range of iterates -- a much stronger result than the existing one.","meta":{"url":"http://arxiv.org/abs/2310.12969v1"},"cats":{"benchmark":0.5202663446,"new-dataset":0.0230323996,"data-annotation":0.5308802489,"dev-research":0.1289507312,"llms":0.4650490421,"data-quality":0.1160512557}}
{"text":"Additionally, our analyses allow us to measure the density of the $\\epsilon$-stationary points in the final iterates of SGD, and we recover the classical $O(\\frac{1}{\\sqrt{T}})$ asymptotic rate under various existing assumptions on the objective function and the bounds on the stochastic gradient.","meta":{"url":"http://arxiv.org/abs/2310.12969v1"},"cats":{"benchmark":0.55123462,"new-dataset":0.0171691683,"data-annotation":0.5488865317,"dev-research":0.1117361003,"llms":0.4341173956,"data-quality":0.1104520449}}
{"text":"As a result of our analyses, we addressed certain myths and legends related to the nonconvex convergence of SGD and posed some thought-provoking questions that could set new directions for research.","meta":{"url":"http://arxiv.org/abs/2310.12969v1"},"cats":{"benchmark":0.4715561933,"new-dataset":0.0058381358,"data-annotation":0.5103716176,"dev-research":0.1248463994,"llms":0.5316369385,"data-quality":0.0894459151}}
{"text":"Deep Learning has already been successfully applied to analyze industrial sensor data in a variety of relevant use cases.","meta":{"url":"http://arxiv.org/abs/2310.12967v1"},"cats":{"benchmark":0.2735332119,"new-dataset":0.294847658,"data-annotation":0.4926604994,"dev-research":0.1906621753,"llms":0.4565635728,"data-quality":0.1571146715}}
{"text":"However, the opaque nature of many well-performing methods poses a major obstacle for real-world deployment.","meta":{"url":"http://arxiv.org/abs/2310.12967v1"},"cats":{"benchmark":0.2709033121,"new-dataset":0.0111380439,"data-annotation":0.5022100834,"dev-research":0.3606429573,"llms":0.5320222365,"data-quality":0.0876977906}}
{"text":"Explainable AI (XAI) and especially feature attribution techniques promise to enable insights about how such models form their decision.","meta":{"url":"http://arxiv.org/abs/2310.12967v1"},"cats":{"benchmark":0.2079573657,"new-dataset":0.0221747065,"data-annotation":0.5369607517,"dev-research":0.3019242751,"llms":0.4466792159,"data-quality":0.1938108326}}
{"text":"But the plain application of such methods often fails to provide truly informative and problem-specific insights to domain experts.","meta":{"url":"http://arxiv.org/abs/2310.12967v1"},"cats":{"benchmark":0.3287937375,"new-dataset":0.0040295701,"data-annotation":0.518100672,"dev-research":0.3796696995,"llms":0.5058425833,"data-quality":0.3836347002}}
{"text":"In this work, we focus on the specific task of detecting faults in rolling element bearings from vibration signals.","meta":{"url":"http://arxiv.org/abs/2310.12967v1"},"cats":{"benchmark":0.4636207858,"new-dataset":0.0597178017,"data-annotation":0.5388037879,"dev-research":0.2777549189,"llms":0.493175607,"data-quality":0.2901453929}}
{"text":"We propose a novel and domain-specific feature attribution framework that allows us to evaluate how well the underlying logic of a model corresponds with expert reasoning.","meta":{"url":"http://arxiv.org/abs/2310.12967v1"},"cats":{"benchmark":0.2632277072,"new-dataset":0.0762648944,"data-annotation":0.5266794323,"dev-research":0.3071404913,"llms":0.5351799991,"data-quality":0.1845807938}}
{"text":"Utilizing the framework we are able to validate the trustworthiness and to successfully anticipate the generalization ability of different well-performing deep learning models.","meta":{"url":"http://arxiv.org/abs/2310.12967v1"},"cats":{"benchmark":0.4176124484,"new-dataset":0.0151712251,"data-annotation":0.5245573906,"dev-research":0.1756355683,"llms":0.4756263863,"data-quality":0.2470741397}}
{"text":"Our methodology demonstrates how signal processing tools can effectively be used to enhance Explainable AI techniques and acts as a template for similar problems.","meta":{"url":"http://arxiv.org/abs/2310.12967v1"},"cats":{"benchmark":0.2770625191,"new-dataset":0.0128198055,"data-annotation":0.5278414558,"dev-research":0.3395909347,"llms":0.3900557442,"data-quality":0.1874098147}}
{"text":"Large language models (LLMs) are now available in various sizes and configurations from cloud API providers.","meta":{"url":"http://arxiv.org/abs/2310.12963v1"},"cats":{"benchmark":0.1922600699,"new-dataset":0.2573343786,"data-annotation":0.5089718747,"dev-research":0.0993259507,"llms":0.738568309,"data-quality":0.0710187528}}
{"text":"While this diversity offers a broad spectrum of choices, effectively leveraging the options to optimize computational cost and performance remains challenging.","meta":{"url":"http://arxiv.org/abs/2310.12963v1"},"cats":{"benchmark":0.4480957455,"new-dataset":0.0202783164,"data-annotation":0.5063719029,"dev-research":0.180201214,"llms":0.5018229253,"data-quality":0.0448800546}}
{"text":"In this work, we present AutoMix, an approach that strategically routes queries to larger LMs, based on the approximate correctness of outputs from a smaller LM.","meta":{"url":"http://arxiv.org/abs/2310.12963v1"},"cats":{"benchmark":0.3459882453,"new-dataset":0.0654107201,"data-annotation":0.4966031605,"dev-research":0.1561502607,"llms":0.5576082879,"data-quality":0.1788374814}}
{"text":"Central to AutoMix is a few-shot self-verification mechanism, which estimates the reliability of its own outputs without requiring training.","meta":{"url":"http://arxiv.org/abs/2310.12963v1"},"cats":{"benchmark":0.2908859593,"new-dataset":0.0220025705,"data-annotation":0.5253382329,"dev-research":0.2355343426,"llms":0.511818511,"data-quality":0.2427789979}}
{"text":"Given that verifications can be noisy, we employ a meta verifier in AutoMix to refine the accuracy of these assessments.","meta":{"url":"http://arxiv.org/abs/2310.12963v1"},"cats":{"benchmark":0.5021567493,"new-dataset":0.0416083508,"data-annotation":0.5149083323,"dev-research":0.2711654258,"llms":0.5543228713,"data-quality":0.3090531055}}
{"text":"Our experiments using LLAMA2-13/70B, on five context-grounded reasoning datasets demonstrate that AutoMix surpasses established baselines, improving the incremental benefit per cost by up to 89%.","meta":{"url":"http://arxiv.org/abs/2310.12963v1"},"cats":{"benchmark":0.2799711607,"new-dataset":0.1894811063,"data-annotation":0.5247146199,"dev-research":0.2785700716,"llms":0.5807775291,"data-quality":0.1362504711}}
{"text":"Our code and data are available at https://github.com/automix-llm/automix.","meta":{"url":"http://arxiv.org/abs/2310.12963v1"},"cats":{"benchmark":0.1792290497,"new-dataset":0.643818675,"data-annotation":0.5119395623,"dev-research":0.1570562396,"llms":0.6109262453,"data-quality":0.1176024184}}
{"text":"Widely used language models (LMs) are typically built by scaling up a two-stage training pipeline: a pre-training stage that uses a very large, diverse dataset of text and a fine-tuning (sometimes, 'alignment') stage that uses targeted examples or other specifications of desired behaviors.","meta":{"url":"http://arxiv.org/abs/2310.12962v1"},"cats":{"benchmark":0.2193078122,"new-dataset":0.0541150106,"data-annotation":0.4944194887,"dev-research":0.142917338,"llms":0.6374494077,"data-quality":0.1345185004}}
{"text":"While it has been hypothesized that knowledge and skills come from pre-training, and fine-tuning mostly filters this knowledge and skillset, this intuition has not been extensively tested.","meta":{"url":"http://arxiv.org/abs/2310.12962v1"},"cats":{"benchmark":0.2234422148,"new-dataset":0.0086799588,"data-annotation":0.5267921887,"dev-research":0.2660657955,"llms":0.5570648795,"data-quality":0.0817018388}}
{"text":"To aid in doing so, we introduce a novel technique for decoupling the knowledge and skills gained in these two stages, enabling a direct answer to the question, \"What would happen if we combined the knowledge learned by a large model during pre-training with the knowledge learned by a small model during fine-tuning (or vice versa)?\"","meta":{"url":"http://arxiv.org/abs/2310.12962v1"},"cats":{"benchmark":0.2353311488,"new-dataset":0.0280942927,"data-annotation":0.5250349874,"dev-research":0.2020631418,"llms":0.5138667876,"data-quality":0.1015088045}}
{"text":"Using an RL-based framework derived from recent developments in learning from human preferences, we introduce emulated fine-tuning (EFT), a principled and practical method for sampling from a distribution that approximates (or 'emulates') the result of pre-training and fine-tuning at different scales.","meta":{"url":"http://arxiv.org/abs/2310.12962v1"},"cats":{"benchmark":0.3597042934,"new-dataset":0.0692455387,"data-annotation":0.5138158183,"dev-research":0.1371244073,"llms":0.484962064,"data-quality":0.1448515315}}
{"text":"Our experiments with EFT show that scaling up fine-tuning tends to improve helpfulness, while scaling up pre-training tends to improve factuality.","meta":{"url":"http://arxiv.org/abs/2310.12962v1"},"cats":{"benchmark":0.3945642658,"new-dataset":0.0084961434,"data-annotation":0.5405077553,"dev-research":0.2479814976,"llms":0.5288187048,"data-quality":0.1940531989}}
{"text":"Beyond decoupling scale, we show that EFT enables test-time adjustment of competing behavioral traits like helpfulness and harmlessness without additional training.","meta":{"url":"http://arxiv.org/abs/2310.12962v1"},"cats":{"benchmark":0.3805166034,"new-dataset":0.0079339637,"data-annotation":0.5102571878,"dev-research":0.1984819797,"llms":0.488757966,"data-quality":0.1167686549}}
{"text":"Finally, a special case of emulated fine-tuning, which we call LM up-scaling, avoids resource-intensive fine-tuning of large pre-trained models by ensembling them with small fine-tuned models, essentially emulating the result of fine-tuning the large pre-trained model.","meta":{"url":"http://arxiv.org/abs/2310.12962v1"},"cats":{"benchmark":0.3482426376,"new-dataset":0.0395548586,"data-annotation":0.520017737,"dev-research":0.1624781974,"llms":0.566793012,"data-quality":0.110133243}}
{"text":"Up-scaling consistently improves helpfulness and factuality of instruction-following models in the Llama, Llama-2, and Falcon families, without additional hyperparameters or training.","meta":{"url":"http://arxiv.org/abs/2310.12962v1"},"cats":{"benchmark":0.3773824202,"new-dataset":0.0091546674,"data-annotation":0.5214673491,"dev-research":0.1667401619,"llms":0.5993133599,"data-quality":0.0858839625}}
{"text":"Large Language Models (LLMs) have driven substantial progress in artificial intelligence in recent years, exhibiting impressive capabilities across a wide range of tasks, including mathematical problem-solving.","meta":{"url":"http://arxiv.org/abs/2310.12960v1"},"cats":{"benchmark":0.1971964861,"new-dataset":0.0988091965,"data-annotation":0.5420715234,"dev-research":0.1548944917,"llms":0.6797232351,"data-quality":0.089361607}}
{"text":"Inspired by the success of subgoal-based methods, we propose a novel framework called \\textbf{SE}quential sub\\textbf{G}oal \\textbf{O}ptimization (SEGO) to enhance LLMs' ability to solve mathematical problems.","meta":{"url":"http://arxiv.org/abs/2310.12960v1"},"cats":{"benchmark":0.4246255521,"new-dataset":0.0086926968,"data-annotation":0.5229397521,"dev-research":0.1404463274,"llms":0.5493582548,"data-quality":0.0943606685}}
{"text":"By establishing a connection between the subgoal breakdown process and the probability of solving problems, SEGO aims to identify better subgoals with theoretical guarantees.","meta":{"url":"http://arxiv.org/abs/2310.12960v1"},"cats":{"benchmark":0.30653891,"new-dataset":0.0217777487,"data-annotation":0.5170045742,"dev-research":0.1832363048,"llms":0.5415388001,"data-quality":0.0871798053}}
{"text":"Addressing the challenge of identifying suitable subgoals in a large solution space, our framework generates problem-specific subgoals and adjusts them according to carefully designed criteria.","meta":{"url":"http://arxiv.org/abs/2310.12960v1"},"cats":{"benchmark":0.3276636734,"new-dataset":0.1481718334,"data-annotation":0.5216761111,"dev-research":0.3222882433,"llms":0.4941918528,"data-quality":0.1464690793}}
{"text":"Incorporating these optimized subgoals into the policy model training leads to significant improvements in problem-solving performance.","meta":{"url":"http://arxiv.org/abs/2310.12960v1"},"cats":{"benchmark":0.3303761445,"new-dataset":0.021750139,"data-annotation":0.5185288859,"dev-research":0.3134463221,"llms":0.4591739072,"data-quality":0.0745025157}}
{"text":"We validate SEGO's efficacy through experiments on two benchmarks, GSM8K and MATH, where our approach outperforms existing methods, highlighting the potential of SEGO in AI-driven mathematical problem-solving.   ","meta":{"url":"http://arxiv.org/abs/2310.12960v1"},"cats":{"benchmark":0.473429414,"new-dataset":0.0204679272,"data-annotation":0.5365183487,"dev-research":0.2149289656,"llms":0.4919205421,"data-quality":0.0712337186}}
{"text":"Data and code associated with this paper will be available at https://github.com/zhaoxlpku/SEGO","meta":{"url":"http://arxiv.org/abs/2310.12960v1"},"cats":{"benchmark":0.2925235124,"new-dataset":0.6585347255,"data-annotation":0.5111022764,"dev-research":0.1250162307,"llms":0.5345372077,"data-quality":0.0849321443}}
{"text":"Game-theoretic motion planners are a powerful tool for the control of interactive multi-agent robot systems.","meta":{"url":"http://arxiv.org/abs/2310.12958v1"},"cats":{"benchmark":0.1894930414,"new-dataset":0.1058968968,"data-annotation":0.4991654444,"dev-research":0.2498771332,"llms":0.4907288768,"data-quality":0.0289363048}}
{"text":"Indeed, contrary to predict-then-plan paradigms, game-theoretic planners do not ignore the interactive nature of the problem, and simultaneously predict the behaviour of other agents while considering change in one's policy.","meta":{"url":"http://arxiv.org/abs/2310.12958v1"},"cats":{"benchmark":0.1522285015,"new-dataset":0.0479485509,"data-annotation":0.4913703791,"dev-research":0.3154875924,"llms":0.4807365885,"data-quality":0.0501990317}}
{"text":"This, however, comes at the expense of computational complexity, especially as the number of agents considered grows.","meta":{"url":"http://arxiv.org/abs/2310.12958v1"},"cats":{"benchmark":0.2963174277,"new-dataset":0.017489896,"data-annotation":0.5431792121,"dev-research":0.1868696053,"llms":0.4605253063,"data-quality":0.0332738718}}
{"text":"In fact, planning with more than a handful of agents can quickly become intractable, disqualifying game-theoretic planners as possible candidates for large scale planning.","meta":{"url":"http://arxiv.org/abs/2310.12958v1"},"cats":{"benchmark":0.1713205696,"new-dataset":0.0466443046,"data-annotation":0.5086146963,"dev-research":0.2321632764,"llms":0.5310431134,"data-quality":0.0294646058}}
{"text":"In this paper, we propose a planning algorithm enabling the use of game-theoretic planners in robot systems with a large number of agents.","meta":{"url":"http://arxiv.org/abs/2310.12958v1"},"cats":{"benchmark":0.1919501025,"new-dataset":0.1345607853,"data-annotation":0.5095374189,"dev-research":0.233161085,"llms":0.4797053456,"data-quality":0.0368671987}}
{"text":"Our planner is based on the reality of locality of information and thus deploys local games with a selected subset of agents in a receding horizon fashion to plan collision avoiding trajectories.","meta":{"url":"http://arxiv.org/abs/2310.12958v1"},"cats":{"benchmark":0.2021103853,"new-dataset":0.3383238848,"data-annotation":0.5005712547,"dev-research":0.2800256908,"llms":0.5146372018,"data-quality":0.0415621676}}
{"text":"We propose five different principled schemes for selecting game participants and compare their collision avoidance performance.","meta":{"url":"http://arxiv.org/abs/2310.12958v1"},"cats":{"benchmark":0.4846269314,"new-dataset":0.0373855629,"data-annotation":0.5184122908,"dev-research":0.1793173269,"llms":0.4867337323,"data-quality":0.0308982156}}
{"text":"We observe that the use of Control Barrier Functions for priority ranking is a potent solution to the player selection problem for motion planning.","meta":{"url":"http://arxiv.org/abs/2310.12958v1"},"cats":{"benchmark":0.4343618445,"new-dataset":0.040169975,"data-annotation":0.5063345164,"dev-research":0.2116000572,"llms":0.4351075828,"data-quality":0.0326213286}}
{"text":"In this work, we study rapid, step-wise improvements of the loss in transformers when being confronted with multi-step decision tasks.","meta":{"url":"http://arxiv.org/abs/2310.12956v1"},"cats":{"benchmark":0.3925395325,"new-dataset":0.0084263678,"data-annotation":0.5098395453,"dev-research":0.2444591141,"llms":0.4710636344,"data-quality":0.0784808226}}
{"text":"We found that transformers struggle to learn the intermediate tasks, whereas CNNs have no such issue on the tasks we studied.","meta":{"url":"http://arxiv.org/abs/2310.12956v1"},"cats":{"benchmark":0.1935852227,"new-dataset":0.0120560243,"data-annotation":0.5014886665,"dev-research":0.1677920288,"llms":0.5733152532,"data-quality":0.1354975142}}
{"text":"When transformers learn the intermediate task, they do this rapidly and unexpectedly after both training and validation loss saturated for hundreds of epochs.","meta":{"url":"http://arxiv.org/abs/2310.12956v1"},"cats":{"benchmark":0.2240840696,"new-dataset":0.0210923714,"data-annotation":0.5216874941,"dev-research":0.1865840737,"llms":0.5394294371,"data-quality":0.1666456051}}
{"text":"We call these rapid improvements Eureka-moments, since the transformer appears to suddenly learn a previously incomprehensible task.","meta":{"url":"http://arxiv.org/abs/2310.12956v1"},"cats":{"benchmark":0.2349986414,"new-dataset":0.0216649987,"data-annotation":0.5247402348,"dev-research":0.2271455017,"llms":0.5543239199,"data-quality":0.2131029126}}
{"text":"Similar leaps in performance have become known as Grokking.","meta":{"url":"http://arxiv.org/abs/2310.12956v1"},"cats":{"benchmark":0.3043659035,"new-dataset":0.052385016,"data-annotation":0.5230450424,"dev-research":0.218263003,"llms":0.5368680961,"data-quality":0.0813316613}}
{"text":"In contrast to Grokking, for Eureka-moments, both the validation and the training loss saturate before rapidly improving.","meta":{"url":"http://arxiv.org/abs/2310.12956v1"},"cats":{"benchmark":0.4150619626,"new-dataset":0.009156369,"data-annotation":0.534146506,"dev-research":0.1706564348,"llms":0.5051816593,"data-quality":0.2147240716}}
{"text":"We trace the problem back to the Softmax function in the self-attention block of transformers and show ways to alleviate the problem.","meta":{"url":"http://arxiv.org/abs/2310.12956v1"},"cats":{"benchmark":0.2779147282,"new-dataset":0.1126381608,"data-annotation":0.5626520468,"dev-research":0.1188481328,"llms":0.4311172722,"data-quality":0.2224405353}}
{"text":"These fixes improve training speed.","meta":{"url":"http://arxiv.org/abs/2310.12956v1"},"cats":{"benchmark":0.4313534284,"new-dataset":0.0337703054,"data-annotation":0.513652901,"dev-research":0.3091875664,"llms":0.489081157,"data-quality":0.2506132308}}
{"text":"The improved models reach 95% of the baseline model in just 20% of training steps while having a much higher likelihood to learn the intermediate task, lead to higher final accuracy and are more robust to hyper-parameters.","meta":{"url":"http://arxiv.org/abs/2310.12956v1"},"cats":{"benchmark":0.5579805719,"new-dataset":0.0071035914,"data-annotation":0.5278986926,"dev-research":0.1949317186,"llms":0.4637635715,"data-quality":0.095658872}}
{"text":"Offline reinforcement learning (RL) presents a promising approach for learning reinforced policies from offline datasets without the need for costly or unsafe interactions with the environment.","meta":{"url":"http://arxiv.org/abs/2310.12955v1"},"cats":{"benchmark":0.2206889195,"new-dataset":0.4228121456,"data-annotation":0.4795424438,"dev-research":0.1570608907,"llms":0.4736596031,"data-quality":0.0711598542}}
{"text":"However, datasets collected by humans in real-world environments are often noisy and may even be maliciously corrupted, which can significantly degrade the performance of offline RL.","meta":{"url":"http://arxiv.org/abs/2310.12955v1"},"cats":{"benchmark":0.3460023271,"new-dataset":0.4891149627,"data-annotation":0.4934942586,"dev-research":0.2837383778,"llms":0.4541899857,"data-quality":0.2748054612}}
{"text":"In this work, we first investigate the performance of current offline RL algorithms under comprehensive data corruption, including states, actions, rewards, and dynamics.","meta":{"url":"http://arxiv.org/abs/2310.12955v1"},"cats":{"benchmark":0.4712524432,"new-dataset":0.2412781727,"data-annotation":0.490239607,"dev-research":0.19290396,"llms":0.449067665,"data-quality":0.2052352046}}
{"text":"Our extensive experiments reveal that implicit Q-learning (IQL) demonstrates remarkable resilience to data corruption among various offline RL algorithms.","meta":{"url":"http://arxiv.org/abs/2310.12955v1"},"cats":{"benchmark":0.3394303531,"new-dataset":0.1357160454,"data-annotation":0.5048556694,"dev-research":0.2148195724,"llms":0.4288053485,"data-quality":0.3213033213}}
{"text":"Furthermore, we conduct both empirical and theoretical analyses to understand IQL's robust performance, identifying its supervised policy learning scheme as the key factor.","meta":{"url":"http://arxiv.org/abs/2310.12955v1"},"cats":{"benchmark":0.4302651337,"new-dataset":0.0348483397,"data-annotation":0.497479077,"dev-research":0.2369364952,"llms":0.4283521939,"data-quality":0.1851386218}}
{"text":"Despite its relative robustness, IQL still suffers from heavy-tail targets of Q functions under dynamics corruption.","meta":{"url":"http://arxiv.org/abs/2310.12955v1"},"cats":{"benchmark":0.3582681965,"new-dataset":0.0401589266,"data-annotation":0.5094650193,"dev-research":0.2314517553,"llms":0.5203745855,"data-quality":0.1314573885}}
{"text":"To tackle this challenge, we draw inspiration from robust statistics to employ the Huber loss to handle the heavy-tailedness and utilize quantile estimators to balance penalization for corrupted data and learning stability.","meta":{"url":"http://arxiv.org/abs/2310.12955v1"},"cats":{"benchmark":0.5833371543,"new-dataset":0.085839768,"data-annotation":0.5142999259,"dev-research":0.1782440324,"llms":0.3480350546,"data-quality":0.3385185489}}
{"text":"By incorporating these simple yet effective modifications into IQL, we propose a more robust offline RL approach named Robust IQL (RIQL).","meta":{"url":"http://arxiv.org/abs/2310.12955v1"},"cats":{"benchmark":0.4770193361,"new-dataset":0.1831511793,"data-annotation":0.4876781766,"dev-research":0.2381305083,"llms":0.479166281,"data-quality":0.1792779683}}
{"text":"Extensive experiments demonstrate that RIQL exhibits highly robust performance when subjected to diverse data corruption scenarios.","meta":{"url":"http://arxiv.org/abs/2310.12955v1"},"cats":{"benchmark":0.4120415301,"new-dataset":0.1883399276,"data-annotation":0.4680168853,"dev-research":0.2796845144,"llms":0.5921210584,"data-quality":0.4024299029}}
{"text":"Thanks to their generative capabilities, large language models (LLMs) have become an invaluable tool for creative processes.","meta":{"url":"http://arxiv.org/abs/2310.12953v1"},"cats":{"benchmark":0.1715209217,"new-dataset":0.1842250683,"data-annotation":0.5323854098,"dev-research":0.1964847409,"llms":0.7769145612,"data-quality":0.1250165001}}
{"text":"These models have the capacity to produce hundreds and thousands of visual and textual outputs, offering abundant inspiration for creative endeavors.","meta":{"url":"http://arxiv.org/abs/2310.12953v1"},"cats":{"benchmark":0.166384449,"new-dataset":0.1499555496,"data-annotation":0.5299575553,"dev-research":0.2507583152,"llms":0.539232978,"data-quality":0.0749052383}}
{"text":"But are we harnessing their full potential?","meta":{"url":"http://arxiv.org/abs/2310.12953v1"},"cats":{"benchmark":0.1841791073,"new-dataset":0.019433362,"data-annotation":0.5224418302,"dev-research":0.2016858481,"llms":0.5373050184,"data-quality":0.0770354212}}
{"text":"We argue that current interaction paradigms fall short, guiding users towards rapid convergence on a limited set of ideas, rather than empowering them to explore the vast latent design space in generative models.","meta":{"url":"http://arxiv.org/abs/2310.12953v1"},"cats":{"benchmark":0.200796121,"new-dataset":0.0138481372,"data-annotation":0.5163818025,"dev-research":0.2745267161,"llms":0.5914306743,"data-quality":0.0593928671}}
{"text":"To address this limitation, we propose a framework that facilitates the structured generation of design space in which users can seamlessly explore, evaluate, and synthesize a multitude of responses.","meta":{"url":"http://arxiv.org/abs/2310.12953v1"},"cats":{"benchmark":0.2218201686,"new-dataset":0.1949361646,"data-annotation":0.5089945932,"dev-research":0.5337894796,"llms":0.6010227965,"data-quality":0.082630551}}
{"text":"We demonstrate the feasibility and usefulness of this framework through the design and development of an interactive system, Luminate, and a user study with 8 professional writers.","meta":{"url":"http://arxiv.org/abs/2310.12953v1"},"cats":{"benchmark":0.2152553514,"new-dataset":0.2842247664,"data-annotation":0.5228066993,"dev-research":0.4096288195,"llms":0.5663003588,"data-quality":0.0691675519}}
{"text":"Our work advances how we interact with LLMs for creative tasks, introducing a way to harness the creative potential of LLMs.","meta":{"url":"http://arxiv.org/abs/2310.12953v1"},"cats":{"benchmark":0.1286032641,"new-dataset":0.0724123853,"data-annotation":0.5070991483,"dev-research":0.226471363,"llms":0.8388770467,"data-quality":0.0977066349}}
{"text":"Measuring diversity accurately is important for many scientific fields, including machine learning (ML), ecology, and chemistry.","meta":{"url":"http://arxiv.org/abs/2310.12952v1"},"cats":{"benchmark":0.4304996316,"new-dataset":0.0187722078,"data-annotation":0.5192824805,"dev-research":0.1402146363,"llms":0.4743165632,"data-quality":0.1788995697}}
{"text":"The Vendi Score was introduced as a generic similarity-based diversity metric that extends the Hill number of order q=1 by leveraging ideas from quantum statistical mechanics.","meta":{"url":"http://arxiv.org/abs/2310.12952v1"},"cats":{"benchmark":0.4789357925,"new-dataset":0.0567811135,"data-annotation":0.5379585866,"dev-research":0.0886400366,"llms":0.5311415486,"data-quality":0.0778921159}}
{"text":"Contrary to many diversity metrics in ecology, the Vendi Score accounts for similarity and does not require knowledge of the prevalence of the categories in the collection to be evaluated for diversity.","meta":{"url":"http://arxiv.org/abs/2310.12952v1"},"cats":{"benchmark":0.4631245077,"new-dataset":0.0769328685,"data-annotation":0.5152472214,"dev-research":0.1399729279,"llms":0.5699960834,"data-quality":0.1554841851}}
{"text":"However, the Vendi Score treats each item in a given collection with a level of sensitivity proportional to the item's prevalence.","meta":{"url":"http://arxiv.org/abs/2310.12952v1"},"cats":{"benchmark":0.5708274867,"new-dataset":0.0263836137,"data-annotation":0.4937051379,"dev-research":0.1344017544,"llms":0.582901445,"data-quality":0.1845155157}}
{"text":"This is undesirable in settings where there is a significant imbalance in item prevalence.","meta":{"url":"http://arxiv.org/abs/2310.12952v1"},"cats":{"benchmark":0.3735584315,"new-dataset":0.0168277559,"data-annotation":0.500177965,"dev-research":0.1951164002,"llms":0.5015424854,"data-quality":0.2418198847}}
{"text":"In this paper, we extend the other Hill numbers using similarity to provide flexibility in allocating sensitivity to rare or common items.","meta":{"url":"http://arxiv.org/abs/2310.12952v1"},"cats":{"benchmark":0.5014235079,"new-dataset":0.1033238558,"data-annotation":0.5242018474,"dev-research":0.1289953851,"llms":0.4719161409,"data-quality":0.1203974561}}
{"text":"This leads to a family of diversity metrics -- Vendi scores with different levels of sensitivity -- that can be used in a variety of applications.","meta":{"url":"http://arxiv.org/abs/2310.12952v1"},"cats":{"benchmark":0.5578051253,"new-dataset":0.0650166744,"data-annotation":0.5236123742,"dev-research":0.1184369299,"llms":0.5227084054,"data-quality":0.1397432951}}
{"text":"We study the properties of the scores in a synthetic controlled setting where the ground truth diversity is known.","meta":{"url":"http://arxiv.org/abs/2310.12952v1"},"cats":{"benchmark":0.4307740566,"new-dataset":0.0644118458,"data-annotation":0.5148913999,"dev-research":0.0933940971,"llms":0.4296714931,"data-quality":0.125267787}}
{"text":"We then test their utility in improving molecular simulations via Vendi Sampling.","meta":{"url":"http://arxiv.org/abs/2310.12952v1"},"cats":{"benchmark":0.5572053813,"new-dataset":0.0523462539,"data-annotation":0.5185652852,"dev-research":0.1149903675,"llms":0.5839553585,"data-quality":0.08570424}}
{"text":"Finally, we use the Vendi scores to better understand the behavior of image generative models in terms of memorization, duplication, diversity, and sample quality.","meta":{"url":"http://arxiv.org/abs/2310.12952v1"},"cats":{"benchmark":0.3317377548,"new-dataset":0.0644209538,"data-annotation":0.5137947502,"dev-research":0.1497852871,"llms":0.5840921344,"data-quality":0.1744614999}}
{"text":"In the pursuit of efficient automated content creation, procedural generation, leveraging modifiable parameters and rule-based systems, emerges as a promising approach.","meta":{"url":"http://arxiv.org/abs/2310.12945v1"},"cats":{"benchmark":0.2490528409,"new-dataset":0.0891794655,"data-annotation":0.5017141458,"dev-research":0.3872220191,"llms":0.5311868511,"data-quality":0.1022810106}}
{"text":"Nonetheless, it could be a demanding endeavor, given its intricate nature necessitating a deep understanding of rules, algorithms, and parameters.","meta":{"url":"http://arxiv.org/abs/2310.12945v1"},"cats":{"benchmark":0.2449095666,"new-dataset":0.0121445164,"data-annotation":0.5088962144,"dev-research":0.2377914754,"llms":0.5297622644,"data-quality":0.0627644623}}
{"text":"To reduce workload, we introduce 3D-GPT, a framework utilizing large language models~(LLMs) for instruction-driven 3D modeling.","meta":{"url":"http://arxiv.org/abs/2310.12945v1"},"cats":{"benchmark":0.2127908022,"new-dataset":0.2068482744,"data-annotation":0.5093535767,"dev-research":0.2743913412,"llms":0.6247955051,"data-quality":0.0408529686}}
{"text":"3D-GPT positions LLMs as proficient problem solvers, dissecting the procedural 3D modeling tasks into accessible segments and appointing the apt agent for each task.","meta":{"url":"http://arxiv.org/abs/2310.12945v1"},"cats":{"benchmark":0.1701347533,"new-dataset":0.0779826422,"data-annotation":0.4918616599,"dev-research":0.2193878333,"llms":0.6516432485,"data-quality":0.0394013445}}
{"text":"3D-GPT integrates three core agents: the task dispatch agent, the conceptualization agent, and the modeling agent.","meta":{"url":"http://arxiv.org/abs/2310.12945v1"},"cats":{"benchmark":0.1756616037,"new-dataset":0.0494020402,"data-annotation":0.4899272299,"dev-research":0.2417789332,"llms":0.5094203098,"data-quality":0.0405554929}}
{"text":"They collaboratively achieve two objectives.","meta":{"url":"http://arxiv.org/abs/2310.12945v1"},"cats":{"benchmark":0.3390147341,"new-dataset":0.0122823362,"data-annotation":0.5039481388,"dev-research":0.3154432368,"llms":0.5101706144,"data-quality":0.0568914475}}
{"text":"First, it enhances concise initial scene descriptions, evolving them into detailed forms while dynamically adapting the text based on subsequent instructions.","meta":{"url":"http://arxiv.org/abs/2310.12945v1"},"cats":{"benchmark":0.206395136,"new-dataset":0.0315930096,"data-annotation":0.5287156546,"dev-research":0.2882526968,"llms":0.5096002697,"data-quality":0.1235776947}}
{"text":"Second, it integrates procedural generation, extracting parameter values from enriched text to effortlessly interface with 3D software for asset creation.","meta":{"url":"http://arxiv.org/abs/2310.12945v1"},"cats":{"benchmark":0.2143968962,"new-dataset":0.104378627,"data-annotation":0.4991333942,"dev-research":0.2771437819,"llms":0.539301984,"data-quality":0.0750402469}}
{"text":"Our empirical investigations confirm that 3D-GPT not only interprets and executes instructions, delivering reliable results but also collaborates effectively with human designers.","meta":{"url":"http://arxiv.org/abs/2310.12945v1"},"cats":{"benchmark":0.2618197675,"new-dataset":0.0282893427,"data-annotation":0.5021748169,"dev-research":0.3749023928,"llms":0.5419309669,"data-quality":0.0593754107}}
{"text":"Furthermore, it seamlessly integrates with Blender, unlocking expanded manipulation possibilities.","meta":{"url":"http://arxiv.org/abs/2310.12945v1"},"cats":{"benchmark":0.2300144272,"new-dataset":0.00718493,"data-annotation":0.4924106031,"dev-research":0.2140373037,"llms":0.5084457872,"data-quality":0.0348643636}}
{"text":"Our work highlights the potential of LLMs in 3D modeling, offering a basic framework for future advancements in scene generation and animation.","meta":{"url":"http://arxiv.org/abs/2310.12945v1"},"cats":{"benchmark":0.1697038474,"new-dataset":0.192432069,"data-annotation":0.4974748154,"dev-research":0.1505140428,"llms":0.7258626144,"data-quality":0.0420313821}}
{"text":"This work investigates the computational expressivity of language models (LMs) based on recurrent neural networks (RNNs).","meta":{"url":"http://arxiv.org/abs/2310.12942v1"},"cats":{"benchmark":0.257016156,"new-dataset":0.1280493242,"data-annotation":0.5401204232,"dev-research":0.1334583816,"llms":0.5533710103,"data-quality":0.1284925653}}
{"text":"Siegelmann and Sontag (1992) famously showed that RNNs with rational weights and hidden states and unbounded computation time are Turing complete.","meta":{"url":"http://arxiv.org/abs/2310.12942v1"},"cats":{"benchmark":0.3188851765,"new-dataset":0.0600569223,"data-annotation":0.5246648675,"dev-research":0.1024932159,"llms":0.5071235918,"data-quality":0.0735487304}}
{"text":"However, LMs define weightings over strings in addition to just (unweighted) language membership and the analysis of the computational power of RNN LMs (RLMs) should reflect this.","meta":{"url":"http://arxiv.org/abs/2310.12942v1"},"cats":{"benchmark":0.3677907943,"new-dataset":0.0139526978,"data-annotation":0.5248968521,"dev-research":0.096674757,"llms":0.5844425989,"data-quality":0.2036254544}}
{"text":"We extend the Turing completeness result to the probabilistic case, showing how a rationally weighted RLM with unbounded computation time can simulate any probabilistic Turing machine (PTM).","meta":{"url":"http://arxiv.org/abs/2310.12942v1"},"cats":{"benchmark":0.3350651644,"new-dataset":0.0921069605,"data-annotation":0.5155199895,"dev-research":0.1160955653,"llms":0.5212325773,"data-quality":0.0768036395}}
{"text":"Since, in practice, RLMs work in real-time, processing a symbol at every time step, we treat the above result as an upper bound on the expressivity of RLMs.","meta":{"url":"http://arxiv.org/abs/2310.12942v1"},"cats":{"benchmark":0.4212305964,"new-dataset":0.0407875626,"data-annotation":0.5243267836,"dev-research":0.1857391621,"llms":0.4396602965,"data-quality":0.0963272294}}
{"text":"We also provide a lower bound by showing that under the restriction to real-time computation, such models can simulate deterministic real-time rational PTMs.","meta":{"url":"http://arxiv.org/abs/2310.12942v1"},"cats":{"benchmark":0.3358120823,"new-dataset":0.0640474094,"data-annotation":0.5334214141,"dev-research":0.1262907886,"llms":0.464085259,"data-quality":0.0733001824}}
{"text":"Foundation models have rapidly permeated society, catalyzing a wave of generative AI applications spanning enterprise and consumer-facing contexts.","meta":{"url":"http://arxiv.org/abs/2310.12941v1"},"cats":{"benchmark":0.187974182,"new-dataset":0.0306959808,"data-annotation":0.5046644927,"dev-research":0.1884459692,"llms":0.5198777551,"data-quality":0.0832231619}}
{"text":"While the societal impact of foundation models is growing, transparency is on the decline, mirroring the opacity that has plagued past digital technologies (e.g. social media).","meta":{"url":"http://arxiv.org/abs/2310.12941v1"},"cats":{"benchmark":0.233578514,"new-dataset":0.0275590249,"data-annotation":0.4843450622,"dev-research":0.2121746054,"llms":0.5136060776,"data-quality":0.1084731666}}
{"text":"Reversing this trend is essential: transparency is a vital precondition for public accountability, scientific innovation, and effective governance.","meta":{"url":"http://arxiv.org/abs/2310.12941v1"},"cats":{"benchmark":0.2869347312,"new-dataset":0.0727396791,"data-annotation":0.4751943159,"dev-research":0.2219332811,"llms":0.5325762988,"data-quality":0.167996589}}
{"text":"To assess the transparency of the foundation model ecosystem and help improve transparency over time, we introduce the Foundation Model Transparency Index.","meta":{"url":"http://arxiv.org/abs/2310.12941v1"},"cats":{"benchmark":0.311653309,"new-dataset":0.0888197137,"data-annotation":0.4857786468,"dev-research":0.1674544311,"llms":0.4843045897,"data-quality":0.0993093853}}
{"text":"The Foundation Model Transparency Index specifies 100 fine-grained indicators that comprehensively codify transparency for foundation models, spanning the upstream resources used to build a foundation model (e.g data, labor, compute), details about the model itself (e.g. size, capabilities, risks), and the downstream use (e.g. distribution channels, usage policies, affected geographies).","meta":{"url":"http://arxiv.org/abs/2310.12941v1"},"cats":{"benchmark":0.2821686306,"new-dataset":0.1367553141,"data-annotation":0.4855183628,"dev-research":0.1755114184,"llms":0.468843528,"data-quality":0.1010445174}}
{"text":"We score 10 major foundation model developers (e.g. OpenAI, Google, Meta) against the 100 indicators to assess their transparency.","meta":{"url":"http://arxiv.org/abs/2310.12941v1"},"cats":{"benchmark":0.3830575582,"new-dataset":0.219343679,"data-annotation":0.5255196333,"dev-research":0.2737151401,"llms":0.5358403318,"data-quality":0.1483735255}}
{"text":"To facilitate and standardize assessment, we score developers in relation to their practices for their flagship foundation model (e.g. GPT-4 for OpenAI, PaLM 2 for Google, Llama 2 for Meta).","meta":{"url":"http://arxiv.org/abs/2310.12941v1"},"cats":{"benchmark":0.4351884241,"new-dataset":0.221752585,"data-annotation":0.5177620266,"dev-research":0.3192268222,"llms":0.5497593227,"data-quality":0.10890086}}
{"text":"We present 10 top-level findings about the foundation model ecosystem: for example, no developer currently discloses significant information about the downstream impact of its flagship model, such as the number of users, affected market sectors, or how users can seek redress for harm.","meta":{"url":"http://arxiv.org/abs/2310.12941v1"},"cats":{"benchmark":0.2544192267,"new-dataset":0.1957978122,"data-annotation":0.4970777961,"dev-research":0.3041838819,"llms":0.5053229614,"data-quality":0.1205845555}}
{"text":"Overall, the Foundation Model Transparency Index establishes the level of transparency today to drive progress on foundation model governance via industry standards and regulatory intervention.","meta":{"url":"http://arxiv.org/abs/2310.12941v1"},"cats":{"benchmark":0.3302917871,"new-dataset":0.0569964135,"data-annotation":0.4753468993,"dev-research":0.1907449126,"llms":0.4792315583,"data-quality":0.1373977531}}
{"text":"Cooperative inference in Mobile Edge Computing (MEC), achieved by deploying partitioned Deep Neural Network (DNN) models between resource-constrained user equipments (UEs) and edge servers (ESs), has emerged as a promising paradigm.","meta":{"url":"http://arxiv.org/abs/2310.12937v1"},"cats":{"benchmark":0.2991581511,"new-dataset":0.0389513402,"data-annotation":0.4818886331,"dev-research":0.1559386144,"llms":0.5148122757,"data-quality":0.0821574289}}
{"text":"Firstly, we consider scenarios of continuous Artificial Intelligence (AI) task arrivals, like the object detection for video streams, and utilize a serial queuing model for the accurate evaluation of End-to-End (E2E) delay in cooperative edge inference.","meta":{"url":"http://arxiv.org/abs/2310.12937v1"},"cats":{"benchmark":0.3040958286,"new-dataset":0.04194602,"data-annotation":0.4928816528,"dev-research":0.1701787443,"llms":0.4455278746,"data-quality":0.0810726041}}
{"text":"Secondly, to enhance the long-term performance of inference systems, we formulate a multi-slot stochastic E2E delay optimization problem that jointly considers model partitioning and multi-dimensional resource allocation.","meta":{"url":"http://arxiv.org/abs/2310.12937v1"},"cats":{"benchmark":0.4718406587,"new-dataset":0.0117430514,"data-annotation":0.5170446212,"dev-research":0.1659491504,"llms":0.3821814465,"data-quality":0.0816473001}}
{"text":"Finally, to solve this problem, we introduce a Lyapunov-guided Multi-Dimensional Optimization algorithm (LyMDO) that decouples the original problem into per-slot deterministic problems, where Deep Reinforcement Learning (DRL) and convex optimization are used for joint optimization of partitioning decisions and complementary resource allocation.","meta":{"url":"http://arxiv.org/abs/2310.12937v1"},"cats":{"benchmark":0.2770292361,"new-dataset":0.047726819,"data-annotation":0.5076690428,"dev-research":0.1345380507,"llms":0.4468781522,"data-quality":0.0749993111}}
{"text":"Simulation results show that our approach effectively improves E2E delay while balancing long-term resource constraints.","meta":{"url":"http://arxiv.org/abs/2310.12937v1"},"cats":{"benchmark":0.4983767202,"new-dataset":0.0105066142,"data-annotation":0.4944242934,"dev-research":0.1824840278,"llms":0.4687288909,"data-quality":0.065874628}}
{"text":"Various types of social biases have been reported with pretrained Masked Language Models (MLMs) in prior work.","meta":{"url":"http://arxiv.org/abs/2310.12936v1"},"cats":{"benchmark":0.24152723,"new-dataset":0.011025732,"data-annotation":0.5465910096,"dev-research":0.2024214111,"llms":0.5483009239,"data-quality":0.2749457899}}
{"text":"However, multiple underlying factors are associated with an MLM such as its model size, size of the training data, training objectives, the domain from which pretraining data is sampled, tokenization, and languages present in the pretrained corpora, to name a few.","meta":{"url":"http://arxiv.org/abs/2310.12936v1"},"cats":{"benchmark":0.250284894,"new-dataset":0.0515695856,"data-annotation":0.5276173,"dev-research":0.1673282146,"llms":0.4702996566,"data-quality":0.127161952}}
{"text":"It remains unclear as to which of those factors influence social biases that are learned by MLMs.","meta":{"url":"http://arxiv.org/abs/2310.12936v1"},"cats":{"benchmark":0.3100026451,"new-dataset":0.0027135666,"data-annotation":0.511012198,"dev-research":0.1483477174,"llms":0.5554002644,"data-quality":0.1518609483}}
{"text":"To study the relationship between model factors and the social biases learned by an MLM, as well as the downstream task performance of the model, we conduct a comprehensive study over 39 pretrained MLMs covering different model sizes, training objectives, tokenization methods, training data domains and languages.","meta":{"url":"http://arxiv.org/abs/2310.12936v1"},"cats":{"benchmark":0.3151381118,"new-dataset":0.0175979523,"data-annotation":0.5231708036,"dev-research":0.1719048071,"llms":0.5471534165,"data-quality":0.1198782329}}
{"text":"Our results shed light on important factors often neglected in prior literature, such as tokenization or model objectives.","meta":{"url":"http://arxiv.org/abs/2310.12936v1"},"cats":{"benchmark":0.4470967001,"new-dataset":0.0024876737,"data-annotation":0.5070815173,"dev-research":0.27063445,"llms":0.4491646089,"data-quality":0.2096669564}}
{"text":"We present a relational representation of odd Sugihara chains.","meta":{"url":"http://arxiv.org/abs/2310.12935v1"},"cats":{"benchmark":0.1914316278,"new-dataset":0.1681213055,"data-annotation":0.5118048836,"dev-research":0.1578096631,"llms":0.5587658148,"data-quality":0.1053845552}}
{"text":"The elements of the algebra are represented as weakening relations over a particular poset which consists of two densely embedded copies of the rationals.","meta":{"url":"http://arxiv.org/abs/2310.12935v1"},"cats":{"benchmark":0.2491527085,"new-dataset":0.0434609321,"data-annotation":0.5281783921,"dev-research":0.2227941337,"llms":0.5253248214,"data-quality":0.1052805455}}
{"text":"Our construction mimics that of Maddux (2010) where a relational representation of the even Sugihara chains is given.","meta":{"url":"http://arxiv.org/abs/2310.12935v1"},"cats":{"benchmark":0.1962760649,"new-dataset":0.1590395308,"data-annotation":0.5154517219,"dev-research":0.1908772616,"llms":0.5710066244,"data-quality":0.092964232}}
{"text":"An order automorphism between the two copies of the rationals is the key to ensuring that the identity element of the monoid is fixed by the involution.","meta":{"url":"http://arxiv.org/abs/2310.12935v1"},"cats":{"benchmark":0.3341546282,"new-dataset":0.0206445446,"data-annotation":0.5064372136,"dev-research":0.1919394321,"llms":0.4864456133,"data-quality":0.1526099359}}
{"text":"The recently proposed generative flow networks (GFlowNets) are a method of training a policy to sample compositional discrete objects with probabilities proportional to a given reward via a sequence of actions.","meta":{"url":"http://arxiv.org/abs/2310.12934v1"},"cats":{"benchmark":0.167300632,"new-dataset":0.0774877626,"data-annotation":0.4983879442,"dev-research":0.1304728985,"llms":0.5624022306,"data-quality":0.0933524293}}
{"text":"GFlowNets exploit the sequential nature of the problem, drawing parallels with reinforcement learning (RL).","meta":{"url":"http://arxiv.org/abs/2310.12934v1"},"cats":{"benchmark":0.2149979501,"new-dataset":0.0242182579,"data-annotation":0.4979345819,"dev-research":0.1211326256,"llms":0.4789190079,"data-quality":0.0732366714}}
{"text":"Our work extends the connection between RL and GFlowNets to a general case.","meta":{"url":"http://arxiv.org/abs/2310.12934v1"},"cats":{"benchmark":0.2356093835,"new-dataset":0.0691372272,"data-annotation":0.4952555698,"dev-research":0.118727792,"llms":0.565168294,"data-quality":0.0959400528}}
{"text":"We demonstrate how the task of learning a generative flow network can be efficiently redefined as an entropy-regularized RL problem with a specific reward and regularizer structure.","meta":{"url":"http://arxiv.org/abs/2310.12934v1"},"cats":{"benchmark":0.2438032701,"new-dataset":0.0292251225,"data-annotation":0.5139248711,"dev-research":0.1383937058,"llms":0.5078991965,"data-quality":0.1278655171}}
{"text":"Furthermore, we illustrate the practical efficiency of this reformulation by applying standard soft RL algorithms to GFlowNet training across several probabilistic modeling tasks.","meta":{"url":"http://arxiv.org/abs/2310.12934v1"},"cats":{"benchmark":0.351332693,"new-dataset":0.0283252655,"data-annotation":0.5106184611,"dev-research":0.151731798,"llms":0.4384408416,"data-quality":0.1716099828}}
{"text":"Contrary to previously reported results, we show that entropic RL approaches can be competitive against established GFlowNet training methods.","meta":{"url":"http://arxiv.org/abs/2310.12934v1"},"cats":{"benchmark":0.3702404872,"new-dataset":0.0167370509,"data-annotation":0.507181211,"dev-research":0.1188047804,"llms":0.5075329323,"data-quality":0.0940858292}}
{"text":"This perspective opens a direct path for integrating reinforcement learning principles into the realm of generative flow networks.","meta":{"url":"http://arxiv.org/abs/2310.12934v1"},"cats":{"benchmark":0.1603297053,"new-dataset":0.0425388194,"data-annotation":0.4912984801,"dev-research":0.1651909203,"llms":0.5437422163,"data-quality":0.0647009748}}
{"text":"Large Language Models (LLMs) have excelled as high-level semantic planners for sequential decision-making tasks.","meta":{"url":"http://arxiv.org/abs/2310.12931v1"},"cats":{"benchmark":0.1936400051,"new-dataset":0.1152222422,"data-annotation":0.5029265718,"dev-research":0.2364854242,"llms":0.7124386011,"data-quality":0.1043175682}}
{"text":"However, harnessing them to learn complex low-level manipulation tasks, such as dexterous pen spinning, remains an open problem.","meta":{"url":"http://arxiv.org/abs/2310.12931v1"},"cats":{"benchmark":0.1232825096,"new-dataset":0.0217417742,"data-annotation":0.5361954728,"dev-research":0.2880235009,"llms":0.5545156717,"data-quality":0.0738673707}}
{"text":"We bridge this fundamental gap and present Eureka, a human-level reward design algorithm powered by LLMs.","meta":{"url":"http://arxiv.org/abs/2310.12931v1"},"cats":{"benchmark":0.321908596,"new-dataset":0.0349142649,"data-annotation":0.5260343877,"dev-research":0.1428153299,"llms":0.6355864907,"data-quality":0.0777233642}}
{"text":"Eureka exploits the remarkable zero-shot generation, code-writing, and in-context improvement capabilities of state-of-the-art LLMs, such as GPT-4, to perform evolutionary optimization over reward code.","meta":{"url":"http://arxiv.org/abs/2310.12931v1"},"cats":{"benchmark":0.2715736488,"new-dataset":0.055490114,"data-annotation":0.5312362852,"dev-research":0.1557201059,"llms":0.6808737634,"data-quality":0.1136814303}}
{"text":"The resulting rewards can then be used to acquire complex skills via reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2310.12931v1"},"cats":{"benchmark":0.1564772959,"new-dataset":0.0107141412,"data-annotation":0.5198170392,"dev-research":0.1773126647,"llms":0.4745070699,"data-quality":0.0428336405}}
{"text":"Without any task-specific prompting or pre-defined reward templates, Eureka generates reward functions that outperform expert human-engineered rewards.","meta":{"url":"http://arxiv.org/abs/2310.12931v1"},"cats":{"benchmark":0.2255134268,"new-dataset":0.0503647613,"data-annotation":0.528463821,"dev-research":0.2328325299,"llms":0.5406956748,"data-quality":0.1142489788}}
{"text":"In a diverse suite of 29 open-source RL environments that include 10 distinct robot morphologies, Eureka outperforms human experts on 83% of the tasks, leading to an average normalized improvement of 52%.","meta":{"url":"http://arxiv.org/abs/2310.12931v1"},"cats":{"benchmark":0.2864332373,"new-dataset":0.3082937465,"data-annotation":0.5210503257,"dev-research":0.2306649226,"llms":0.4959705046,"data-quality":0.0858118552}}
{"text":"The generality of Eureka also enables a new gradient-free in-context learning approach to reinforcement learning from human feedback (RLHF), readily incorporating human inputs to improve the quality and the safety of the generated rewards without model updating.","meta":{"url":"http://arxiv.org/abs/2310.12931v1"},"cats":{"benchmark":0.2188087481,"new-dataset":0.0623224682,"data-annotation":0.5278672026,"dev-research":0.1550630671,"llms":0.5000811711,"data-quality":0.1212728154}}
{"text":"Finally, using Eureka rewards in a curriculum learning setting, we demonstrate for the first time, a simulated Shadow Hand capable of performing pen spinning tricks, adeptly manipulating a pen in circles at rapid speed.","meta":{"url":"http://arxiv.org/abs/2310.12931v1"},"cats":{"benchmark":0.1601087912,"new-dataset":0.1402871091,"data-annotation":0.5344386894,"dev-research":0.2256487355,"llms":0.5876880463,"data-quality":0.0620321866}}
{"text":"We develop a probabilistic graphical model (PGM) for artificially intelligent (AI) agents to infer human beliefs during a simulated urban search and rescue (USAR) scenario executed in a Minecraft environment with a team of three players.","meta":{"url":"http://arxiv.org/abs/2310.12929v1"},"cats":{"benchmark":0.1857072703,"new-dataset":0.1307707145,"data-annotation":0.5253798283,"dev-research":0.2608507576,"llms":0.5147742939,"data-quality":0.0814392237}}
{"text":"The PGM approach makes observable states and actions explicit, as well as beliefs and intentions grounded by evidence about what players see and do over time.","meta":{"url":"http://arxiv.org/abs/2310.12929v1"},"cats":{"benchmark":0.2121087378,"new-dataset":0.0186553957,"data-annotation":0.4978079064,"dev-research":0.190069387,"llms":0.5530025978,"data-quality":0.058856997}}
{"text":"This approach also supports inferring the effect of interventions, which are vital if AI agents are to assist human teams.","meta":{"url":"http://arxiv.org/abs/2310.12929v1"},"cats":{"benchmark":0.2591894453,"new-dataset":0.0251360509,"data-annotation":0.5432373779,"dev-research":0.3275899873,"llms":0.4541992865,"data-quality":0.0818088747}}
{"text":"The experiment incorporates manipulations of players' knowledge, and the virtual Minecraft-based testbed provides access to several streams of information, including the objects in the players' field of view.","meta":{"url":"http://arxiv.org/abs/2310.12929v1"},"cats":{"benchmark":0.1890202014,"new-dataset":0.1094658389,"data-annotation":0.5054131282,"dev-research":0.2825762073,"llms":0.5975409616,"data-quality":0.0832680877}}
{"text":"The participants are equipped with a set of marker blocks that can be placed near room entrances to signal the presence or absence of victims in the rooms to their teammates.","meta":{"url":"http://arxiv.org/abs/2310.12929v1"},"cats":{"benchmark":0.2356519718,"new-dataset":0.2040813318,"data-annotation":0.5376043251,"dev-research":0.3310006977,"llms":0.5169537056,"data-quality":0.0868990572}}
{"text":"In each team, one of the members is given a different legend for the markers than the other two, which may mislead them about the state of the rooms; that is, they will hold a false belief.","meta":{"url":"http://arxiv.org/abs/2310.12929v1"},"cats":{"benchmark":0.2588557679,"new-dataset":0.2325465278,"data-annotation":0.5320849014,"dev-research":0.2846658655,"llms":0.5717135682,"data-quality":0.2076078814}}
{"text":"We extend previous works in this field by introducing ToMCAT, an AI agent that can reason about individual and shared mental states.","meta":{"url":"http://arxiv.org/abs/2310.12929v1"},"cats":{"benchmark":0.1850871986,"new-dataset":0.1541683631,"data-annotation":0.5425661985,"dev-research":0.3338397532,"llms":0.537553212,"data-quality":0.1203430182}}
{"text":"We find that the players' behaviors are affected by what they see in their in-game field of view, their beliefs about the meaning of the markers, and their beliefs about which meaning the team decided to adopt.","meta":{"url":"http://arxiv.org/abs/2310.12929v1"},"cats":{"benchmark":0.1666863304,"new-dataset":0.1045236266,"data-annotation":0.5290428103,"dev-research":0.3767720451,"llms":0.5111642593,"data-quality":0.123697804}}
{"text":"In addition, we show that ToMCAT's beliefs are consistent with the players' actions and that it can infer false beliefs with accuracy significantly better than chance and comparable to inferences made by human observers.","meta":{"url":"http://arxiv.org/abs/2310.12929v1"},"cats":{"benchmark":0.278264531,"new-dataset":0.0730875304,"data-annotation":0.5343875865,"dev-research":0.2731544175,"llms":0.5185760399,"data-quality":0.1664369179}}
{"text":"Multi-agent cooperation is an important topic, and is particularly challenging in mixed-motive situations where it does not pay to be nice to others.","meta":{"url":"http://arxiv.org/abs/2310.12928v1"},"cats":{"benchmark":0.2203479805,"new-dataset":0.0160375526,"data-annotation":0.5190981551,"dev-research":0.1997917023,"llms":0.5390561542,"data-quality":0.0584215233}}
{"text":"Consequently, self-interested agents often avoid collective behaviour, resulting in suboptimal outcomes for the group.","meta":{"url":"http://arxiv.org/abs/2310.12928v1"},"cats":{"benchmark":0.2074105647,"new-dataset":0.0083866858,"data-annotation":0.5217400725,"dev-research":0.159832672,"llms":0.5148625158,"data-quality":0.082376674}}
{"text":"In response, in this paper we introduce a metric to quantify the disparity between what is rational for individual agents and what is rational for the group, which we call the general self-interest level.","meta":{"url":"http://arxiv.org/abs/2310.12928v1"},"cats":{"benchmark":0.2673022131,"new-dataset":0.0838133247,"data-annotation":0.5437439944,"dev-research":0.1574924148,"llms":0.4592843773,"data-quality":0.0850878487}}
{"text":"This metric represents the maximum proportion of individual rewards that all agents can retain while ensuring that achieving social welfare optimum becomes a dominant strategy.","meta":{"url":"http://arxiv.org/abs/2310.12928v1"},"cats":{"benchmark":0.3767479947,"new-dataset":0.0878800557,"data-annotation":0.5160299276,"dev-research":0.130308619,"llms":0.4264653908,"data-quality":0.0608930111}}
{"text":"By aligning the individual and group incentives, rational agents acting to maximise their own reward will simultaneously maximise the collective reward.","meta":{"url":"http://arxiv.org/abs/2310.12928v1"},"cats":{"benchmark":0.2941261158,"new-dataset":0.0114948966,"data-annotation":0.5281868261,"dev-research":0.1541230366,"llms":0.4051276628,"data-quality":0.0819248157}}
{"text":"As agents transfer their rewards to motivate others to consider their welfare, we diverge from traditional concepts of altruism or prosocial behaviours.","meta":{"url":"http://arxiv.org/abs/2310.12928v1"},"cats":{"benchmark":0.1835926513,"new-dataset":0.028862831,"data-annotation":0.5327496336,"dev-research":0.1966611755,"llms":0.4933747505,"data-quality":0.0632806986}}
{"text":"The general self-interest level is a property of a game that is useful for assessing the propensity of players to cooperate and understanding how features of a game impact this.","meta":{"url":"http://arxiv.org/abs/2310.12928v1"},"cats":{"benchmark":0.1982320509,"new-dataset":0.032600273,"data-annotation":0.5348455608,"dev-research":0.1834222865,"llms":0.4800076174,"data-quality":0.0737856841}}
{"text":"We illustrate the effectiveness of our method on several novel games representations of social dilemmas with arbitrary numbers of players.","meta":{"url":"http://arxiv.org/abs/2310.12928v1"},"cats":{"benchmark":0.2411552652,"new-dataset":0.2268907238,"data-annotation":0.5411105036,"dev-research":0.2787636675,"llms":0.5257278559,"data-quality":0.0904404568}}
{"text":"Existing distributed denial of service attack (DDoS) solutions cannot handle highly aggregated data rates; thus, they are unsuitable for Internet service provider (ISP) core networks.","meta":{"url":"http://arxiv.org/abs/2310.12924v1"},"cats":{"benchmark":0.4178959662,"new-dataset":0.0202902851,"data-annotation":0.465586915,"dev-research":0.1405054103,"llms":0.5403270002,"data-quality":0.1005343949}}
{"text":"This article proposes a digital twin-enabled intelligent DDoS detection mechanism using an online learning method for autonomous systems.","meta":{"url":"http://arxiv.org/abs/2310.12924v1"},"cats":{"benchmark":0.3386260632,"new-dataset":0.0196403493,"data-annotation":0.5004227158,"dev-research":0.1391564356,"llms":0.4143733411,"data-quality":0.156415742}}
{"text":"Our contributions are three-fold: we first design a DDoS detection architecture based on the digital twin for ISP core networks.","meta":{"url":"http://arxiv.org/abs/2310.12924v1"},"cats":{"benchmark":0.4198280897,"new-dataset":0.0260550643,"data-annotation":0.4921064235,"dev-research":0.1143246468,"llms":0.4937066879,"data-quality":0.1123236064}}
{"text":"We implemented a Yet Another Next Generation (YANG) model and an automated feature selection (AutoFS) module to handle core network data.","meta":{"url":"http://arxiv.org/abs/2310.12924v1"},"cats":{"benchmark":0.3216502931,"new-dataset":0.0526838022,"data-annotation":0.4703535919,"dev-research":0.2112019583,"llms":0.5053987622,"data-quality":0.1243019088}}
{"text":"We used an online learning approach to update the model instantly and efficiently, improve the learning model quickly, and ensure accurate predictions.","meta":{"url":"http://arxiv.org/abs/2310.12924v1"},"cats":{"benchmark":0.4209995478,"new-dataset":0.0867167503,"data-annotation":0.5174915671,"dev-research":0.2233440876,"llms":0.4146907484,"data-quality":0.1060382063}}
{"text":"Finally, we reveal that our proposed solution successfully detects DDoS attacks and updates the feature selection method and learning model with a true classification rate of ninety-seven percent.","meta":{"url":"http://arxiv.org/abs/2310.12924v1"},"cats":{"benchmark":0.4460987136,"new-dataset":0.024588296,"data-annotation":0.5092412036,"dev-research":0.1667822273,"llms":0.4635188541,"data-quality":0.1905233224}}
{"text":"Our proposed solution can estimate the attack within approximately fifteen minutes after the DDoS attack starts.","meta":{"url":"http://arxiv.org/abs/2310.12924v1"},"cats":{"benchmark":0.4589008597,"new-dataset":0.0627347168,"data-annotation":0.520904721,"dev-research":0.1630660616,"llms":0.4469167156,"data-quality":0.0807185182}}
{"text":"Reinforcement learning (RL) requires either manually specifying a reward function, which is often infeasible, or learning a reward model from a large amount of human feedback, which is often very expensive.","meta":{"url":"http://arxiv.org/abs/2310.12921v1"},"cats":{"benchmark":0.2127550206,"new-dataset":0.0185834154,"data-annotation":0.5134823536,"dev-research":0.1857977129,"llms":0.4867006949,"data-quality":0.0691632413}}
{"text":"We study a more sample-efficient alternative: using pretrained vision-language models (VLMs) as zero-shot reward models (RMs) to specify tasks via natural language.","meta":{"url":"http://arxiv.org/abs/2310.12921v1"},"cats":{"benchmark":0.2842925706,"new-dataset":0.1415283756,"data-annotation":0.546326876,"dev-research":0.1779596156,"llms":0.4714381164,"data-quality":0.2080836968}}
{"text":"We propose a natural and general approach to using VLMs as reward models, which we call VLM-RMs.","meta":{"url":"http://arxiv.org/abs/2310.12921v1"},"cats":{"benchmark":0.4556930336,"new-dataset":0.035193118,"data-annotation":0.5248875606,"dev-research":0.1346115178,"llms":0.3494914468,"data-quality":0.1143247276}}
{"text":"We use VLM-RMs based on CLIP to train a MuJoCo humanoid to learn complex tasks without a manually specified reward function, such as kneeling, doing the splits, and sitting in a lotus position.","meta":{"url":"http://arxiv.org/abs/2310.12921v1"},"cats":{"benchmark":0.2891254343,"new-dataset":0.1011789071,"data-annotation":0.5144261765,"dev-research":0.104181976,"llms":0.4210976805,"data-quality":0.05472211}}
{"text":"For each of these tasks, we only provide a single sentence text prompt describing the desired task with minimal prompt engineering.","meta":{"url":"http://arxiv.org/abs/2310.12921v1"},"cats":{"benchmark":0.2183176758,"new-dataset":0.0462172294,"data-annotation":0.5145921319,"dev-research":0.2601904544,"llms":0.5374776286,"data-quality":0.1263568984}}
{"text":"We provide videos of the trained agents at: https://sites.google.com/view/vlm-rm.","meta":{"url":"http://arxiv.org/abs/2310.12921v1"},"cats":{"benchmark":0.16606111,"new-dataset":0.4966621006,"data-annotation":0.5171747588,"dev-research":0.1452265703,"llms":0.5527022222,"data-quality":0.1071270955}}
{"text":"We can improve performance by providing a second ``baseline'' prompt and projecting out parts of the CLIP embedding space irrelevant to distinguish between goal and baseline.","meta":{"url":"http://arxiv.org/abs/2310.12921v1"},"cats":{"benchmark":0.5611736448,"new-dataset":0.0684986729,"data-annotation":0.5173893357,"dev-research":0.240520881,"llms":0.4515045654,"data-quality":0.1243752505}}
{"text":"Further, we find a strong scaling effect for VLM-RMs: larger VLMs trained with more compute and data are better reward models.","meta":{"url":"http://arxiv.org/abs/2310.12921v1"},"cats":{"benchmark":0.4634339749,"new-dataset":0.0457291322,"data-annotation":0.5155250137,"dev-research":0.1169390351,"llms":0.3864621858,"data-quality":0.11440655}}
{"text":"The failure modes of VLM-RMs we encountered are all related to known capability limitations of current VLMs, such as limited spatial reasoning ability or visually unrealistic environments that are far off-distribution for the VLM.","meta":{"url":"http://arxiv.org/abs/2310.12921v1"},"cats":{"benchmark":0.3617328342,"new-dataset":0.0137379558,"data-annotation":0.511628706,"dev-research":0.2383723677,"llms":0.4489145018,"data-quality":0.1464763458}}
{"text":"We find that VLM-RMs are remarkably robust as long as the VLM is large enough.","meta":{"url":"http://arxiv.org/abs/2310.12921v1"},"cats":{"benchmark":0.6056185032,"new-dataset":0.0220698412,"data-annotation":0.5089476657,"dev-research":0.1515188151,"llms":0.3831910922,"data-quality":0.2365143879}}
{"text":"This suggests that future VLMs will become more and more useful reward models for a wide range of RL applications.","meta":{"url":"http://arxiv.org/abs/2310.12921v1"},"cats":{"benchmark":0.328615247,"new-dataset":0.0200016596,"data-annotation":0.5065115291,"dev-research":0.1566847833,"llms":0.4776782212,"data-quality":0.0681368028}}
{"text":"We introduce marginalization models (MaMs), a new family of generative models for high-dimensional discrete data.","meta":{"url":"http://arxiv.org/abs/2310.12920v1"},"cats":{"benchmark":0.2815723527,"new-dataset":0.1154801233,"data-annotation":0.4951530105,"dev-research":0.0999960279,"llms":0.4921548465,"data-quality":0.0891177205}}
{"text":"They offer scalable and flexible generative modeling with tractable likelihoods by explicitly modeling all induced marginal distributions.","meta":{"url":"http://arxiv.org/abs/2310.12920v1"},"cats":{"benchmark":0.264137838,"new-dataset":0.0409418532,"data-annotation":0.5171014985,"dev-research":0.1563600304,"llms":0.5248501937,"data-quality":0.0974615685}}
{"text":"Marginalization models enable fast evaluation of arbitrary marginal probabilities with a single forward pass of the neural network, which overcomes a major limitation of methods with exact marginal inference, such as autoregressive models (ARMs).","meta":{"url":"http://arxiv.org/abs/2310.12920v1"},"cats":{"benchmark":0.407107143,"new-dataset":0.0101291037,"data-annotation":0.5495646703,"dev-research":0.1340923885,"llms":0.3794329246,"data-quality":0.1118064414}}
{"text":"We propose scalable methods for learning the marginals, grounded in the concept of \"marginalization self-consistency\".","meta":{"url":"http://arxiv.org/abs/2310.12920v1"},"cats":{"benchmark":0.402706077,"new-dataset":0.0334735197,"data-annotation":0.5223363985,"dev-research":0.16831286,"llms":0.4154550098,"data-quality":0.301991648}}
{"text":"Unlike previous methods, MaMs support scalable training of any-order generative models for high-dimensional problems under the setting of energy-based training, where the goal is to match the learned distribution to a given desired probability (specified by an unnormalized (log) probability function such as energy function or reward function).","meta":{"url":"http://arxiv.org/abs/2310.12920v1"},"cats":{"benchmark":0.2635825586,"new-dataset":0.0165863691,"data-annotation":0.5251345762,"dev-research":0.0859541316,"llms":0.5654665667,"data-quality":0.0965651535}}
{"text":"We demonstrate the effectiveness of the proposed model on a variety of discrete data distributions, including binary images, language, physical systems, and molecules, for maximum likelihood and energy-based training settings.","meta":{"url":"http://arxiv.org/abs/2310.12920v1"},"cats":{"benchmark":0.2936530013,"new-dataset":0.1270085883,"data-annotation":0.4954990115,"dev-research":0.0781824832,"llms":0.4369183192,"data-quality":0.1346717573}}
{"text":"MaMs achieve orders of magnitude speedup in evaluating the marginal probabilities on both settings.","meta":{"url":"http://arxiv.org/abs/2310.12920v1"},"cats":{"benchmark":0.5782574391,"new-dataset":0.0060828411,"data-annotation":0.5137265048,"dev-research":0.0985762921,"llms":0.5628930581,"data-quality":0.0632618695}}
{"text":"For energy-based training tasks, MaMs enable any-order generative modeling of high-dimensional problems beyond the capability of previous methods.","meta":{"url":"http://arxiv.org/abs/2310.12920v1"},"cats":{"benchmark":0.2717753765,"new-dataset":0.0123935587,"data-annotation":0.5133340041,"dev-research":0.1304442596,"llms":0.5629744775,"data-quality":0.0800447852}}
{"text":"Code is at https://github.com/PrincetonLIPS/MaM.","meta":{"url":"http://arxiv.org/abs/2310.12920v1"},"cats":{"benchmark":0.2843768489,"new-dataset":0.1506236996,"data-annotation":0.5416851611,"dev-research":0.1123720316,"llms":0.6127749207,"data-quality":0.1000624081}}
{"text":"As the current detection solutions of distributed denial of service attacks (DDoS) need additional infrastructures to handle high aggregate data rates, they are not suitable for sensor networks or the Internet of Things.","meta":{"url":"http://arxiv.org/abs/2310.12914v1"},"cats":{"benchmark":0.3417276752,"new-dataset":0.0437255475,"data-annotation":0.4566346767,"dev-research":0.1360960618,"llms":0.5861914336,"data-quality":0.0946154214}}
{"text":"Besides, the security architecture of software-defined sensor networks needs to pay attention to the vulnerabilities of both software-defined networks and sensor networks.","meta":{"url":"http://arxiv.org/abs/2310.12914v1"},"cats":{"benchmark":0.2549275904,"new-dataset":0.1120725728,"data-annotation":0.4962305601,"dev-research":0.3132255104,"llms":0.5429146685,"data-quality":0.1134622182}}
{"text":"In this paper, we propose a network-aware automated machine learning (AutoML) framework which detects DDoS attacks in software-defined sensor networks.","meta":{"url":"http://arxiv.org/abs/2310.12914v1"},"cats":{"benchmark":0.2967919468,"new-dataset":0.0839658365,"data-annotation":0.494916499,"dev-research":0.2162874506,"llms":0.4714887988,"data-quality":0.1783838587}}
{"text":"Our framework selects an ideal machine learning algorithm to detect DDoS attacks in network-constrained environments, using metrics such as variable traffic load, heterogeneous traffic rate, and detection time while preventing over-fitting.","meta":{"url":"http://arxiv.org/abs/2310.12914v1"},"cats":{"benchmark":0.3879435887,"new-dataset":0.0482737044,"data-annotation":0.5100441902,"dev-research":0.1487168304,"llms":0.384199138,"data-quality":0.1218607272}}
{"text":"Our contributions are two-fold: (i) we first investigate the trade-off between the efficiency of ML algorithms and network/traffic state in the scope of DDoS detection.","meta":{"url":"http://arxiv.org/abs/2310.12914v1"},"cats":{"benchmark":0.4447343421,"new-dataset":0.0379238729,"data-annotation":0.513571189,"dev-research":0.1305117677,"llms":0.4955072127,"data-quality":0.115916343}}
{"text":"(ii) we design and implement a software architecture containing open-source network tools, with the deployment of multiple ML algorithms.","meta":{"url":"http://arxiv.org/abs/2310.12914v1"},"cats":{"benchmark":0.3823364005,"new-dataset":0.0858823996,"data-annotation":0.4904765851,"dev-research":0.1863142956,"llms":0.5318325291,"data-quality":0.1067377234}}
{"text":"Lastly, we show that under the denial of service attacks, our framework ensures the traffic packets are still delivered within the network with additional delays.","meta":{"url":"http://arxiv.org/abs/2310.12914v1"},"cats":{"benchmark":0.3920537404,"new-dataset":0.0467441204,"data-annotation":0.4877462936,"dev-research":0.1807010642,"llms":0.5013277824,"data-quality":0.0971157617}}
{"text":"As one of the three main pillars of fine-grained complexity theory, the 3SUM problem explains the hardness of many diverse polynomial-time problems via fine-grained reductions.","meta":{"url":"http://arxiv.org/abs/2310.12913v1"},"cats":{"benchmark":0.4030217527,"new-dataset":0.0240185602,"data-annotation":0.5398589033,"dev-research":0.1997157657,"llms":0.4812269528,"data-quality":0.1725179332}}
{"text":"Many of these reductions are either directly based on or heavily inspired by P\\u{a}tra\\c{s}cu's framework involving additive hashing and are thus randomized.","meta":{"url":"http://arxiv.org/abs/2310.12913v1"},"cats":{"benchmark":0.4849032055,"new-dataset":0.0099672974,"data-annotation":0.5324640946,"dev-research":0.1110756421,"llms":0.5325030152,"data-quality":0.1478054012}}
{"text":"Some selected reductions were derandomized in previous work [Chan, He; SOSA'20], but the current techniques are limited and a major fraction of the reductions remains randomized.   ","meta":{"url":"http://arxiv.org/abs/2310.12913v1"},"cats":{"benchmark":0.5608379316,"new-dataset":0.0147059543,"data-annotation":0.5266614822,"dev-research":0.1659510596,"llms":0.5495607949,"data-quality":0.135818994}}
{"text":"In this work we gather a toolkit aimed to derandomize reductions based on additive hashing.","meta":{"url":"http://arxiv.org/abs/2310.12913v1"},"cats":{"benchmark":0.626524956,"new-dataset":0.0787009939,"data-annotation":0.5311493707,"dev-research":0.1532832968,"llms":0.5266389737,"data-quality":0.1399582836}}
{"text":"Using this toolkit, we manage to derandomize almost all known 3SUM-hardness reductions.","meta":{"url":"http://arxiv.org/abs/2310.12913v1"},"cats":{"benchmark":0.5575742738,"new-dataset":0.1123909146,"data-annotation":0.5338186062,"dev-research":0.1858928172,"llms":0.5177169854,"data-quality":0.1872931305}}
{"text":"As technical highlights we derandomize the hardness reductions to (offline) Set Disjointness, (offline) Set Intersection and Triangle Listing -- these questions were explicitly left open in previous work [Kopelowitz, Pettie, Porat; SODA'16].","meta":{"url":"http://arxiv.org/abs/2310.12913v1"},"cats":{"benchmark":0.5399133467,"new-dataset":0.2317393768,"data-annotation":0.5279937138,"dev-research":0.1957673132,"llms":0.5170201658,"data-quality":0.1650567479}}
{"text":"The few exceptions to our work fall into a special category of recent reductions based on structure-versus-randomness dichotomies.   ","meta":{"url":"http://arxiv.org/abs/2310.12913v1"},"cats":{"benchmark":0.4747109134,"new-dataset":0.0123961276,"data-annotation":0.526917851,"dev-research":0.2015789957,"llms":0.5358917282,"data-quality":0.1843325457}}
{"text":"We expect that our toolkit can be readily applied to derandomize future reductions as well.","meta":{"url":"http://arxiv.org/abs/2310.12913v1"},"cats":{"benchmark":0.4722301288,"new-dataset":0.0216106099,"data-annotation":0.5291366851,"dev-research":0.2445420351,"llms":0.5652682797,"data-quality":0.1342114976}}
{"text":"As a conceptual innovation, our work thereby promotes the theory of deterministic 3SUM-hardness.   ","meta":{"url":"http://arxiv.org/abs/2310.12913v1"},"cats":{"benchmark":0.2845123539,"new-dataset":0.0438966744,"data-annotation":0.5304722702,"dev-research":0.1934020533,"llms":0.5537063177,"data-quality":0.150340016}}
{"text":"As our second contribution, we prove that there is a deterministic universe reduction for 3SUM.","meta":{"url":"http://arxiv.org/abs/2310.12913v1"},"cats":{"benchmark":0.3205282666,"new-dataset":0.2247719241,"data-annotation":0.5396696186,"dev-research":0.1396861445,"llms":0.5389707871,"data-quality":0.1797966992}}
{"text":"Specifically, using additive hashing it is a standard trick to assume that the numbers in 3SUM have size at most $n^3$. We prove that this assumption is similarly valid for deterministic algorithms.","meta":{"url":"http://arxiv.org/abs/2310.12913v1"},"cats":{"benchmark":0.3888112482,"new-dataset":0.0178238145,"data-annotation":0.5401333584,"dev-research":0.196952645,"llms":0.5282620973,"data-quality":0.1252500942}}
{"text":"Effective coordination and cooperation among agents are crucial for accomplishing individual or shared objectives in multi-agent systems.","meta":{"url":"http://arxiv.org/abs/2310.12912v1"},"cats":{"benchmark":0.2935971026,"new-dataset":0.0178490085,"data-annotation":0.5059908215,"dev-research":0.223671508,"llms":0.5118434089,"data-quality":0.0454108514}}
{"text":"In many real-world multi-agent systems, agents possess varying abilities and constraints, making it necessary to prioritize agents based on their specific properties to ensure successful coordination and cooperation within the team.","meta":{"url":"http://arxiv.org/abs/2310.12912v1"},"cats":{"benchmark":0.2704112349,"new-dataset":0.0226474346,"data-annotation":0.5002196813,"dev-research":0.2133552944,"llms":0.4801358252,"data-quality":0.0366252317}}
{"text":"However, most existing cooperative multi-agent algorithms do not take into account these individual differences, and lack an effective mechanism to guide coordination strategies.","meta":{"url":"http://arxiv.org/abs/2310.12912v1"},"cats":{"benchmark":0.3684114519,"new-dataset":0.0029439935,"data-annotation":0.5108346245,"dev-research":0.1578386688,"llms":0.5119404128,"data-quality":0.0770595289}}
{"text":"We propose a novel multi-agent learning approach that incorporates relationship awareness into value-based factorization methods.","meta":{"url":"http://arxiv.org/abs/2310.12912v1"},"cats":{"benchmark":0.2445822712,"new-dataset":0.0866449775,"data-annotation":0.5106532113,"dev-research":0.1907971371,"llms":0.4554536457,"data-quality":0.1419616488}}
{"text":"Given a relational network, our approach utilizes inter-agents relationships to discover new team behaviors by prioritizing certain agents over other, accounting for differences between them in cooperative tasks.","meta":{"url":"http://arxiv.org/abs/2310.12912v1"},"cats":{"benchmark":0.2601441662,"new-dataset":0.1335787004,"data-annotation":0.515835078,"dev-research":0.3044543696,"llms":0.4926133342,"data-quality":0.070383528}}
{"text":"We evaluated the effectiveness of our proposed approach by conducting fifteen experiments in two different environments.","meta":{"url":"http://arxiv.org/abs/2310.12912v1"},"cats":{"benchmark":0.5674029095,"new-dataset":0.0200969753,"data-annotation":0.5025314635,"dev-research":0.2469901781,"llms":0.5282907752,"data-quality":0.0977651309}}
{"text":"The results demonstrate that our proposed algorithm can influence and shape team behavior, guide cooperation strategies, and expedite agent learning.","meta":{"url":"http://arxiv.org/abs/2310.12912v1"},"cats":{"benchmark":0.2149868254,"new-dataset":0.0598982765,"data-annotation":0.5211826583,"dev-research":0.2797804979,"llms":0.4883579739,"data-quality":0.0531530619}}
{"text":"Therefore, our approach shows promise for use in multi-agent systems, especially when agents have diverse properties.","meta":{"url":"http://arxiv.org/abs/2310.12912v1"},"cats":{"benchmark":0.288469674,"new-dataset":0.0177140546,"data-annotation":0.5026506685,"dev-research":0.1332985414,"llms":0.4925373481,"data-quality":0.0593197065}}
{"text":"Austrin showed that the approximation ratio $\\beta\\approx 0.94016567$ obtained by the MAX 2-SAT approximation algorithm of Lewin, Livnat and Zwick (LLZ) is optimal modulo the Unique Games Conjecture (UGC) and modulo a Simplicity Conjecture that states that the worst performance of the algorithm is obtained on so called simple configurations.","meta":{"url":"http://arxiv.org/abs/2310.12911v1"},"cats":{"benchmark":0.5791681582,"new-dataset":0.0371146704,"data-annotation":0.5464519287,"dev-research":0.1734520484,"llms":0.4377955157,"data-quality":0.1023388426}}
{"text":"We prove Austrin's conjecture, thereby showing the optimality of the LLZ approximation algorithm, relying only on the Unique Games Conjecture.","meta":{"url":"http://arxiv.org/abs/2310.12911v1"},"cats":{"benchmark":0.4849794591,"new-dataset":0.0277191121,"data-annotation":0.5454453637,"dev-research":0.1213479817,"llms":0.5098808399,"data-quality":0.1057846111}}
{"text":"Our proof uses a combination of analytic and computational tools.   ","meta":{"url":"http://arxiv.org/abs/2310.12911v1"},"cats":{"benchmark":0.5077443694,"new-dataset":0.0426479629,"data-annotation":0.5184415818,"dev-research":0.2140045317,"llms":0.4731190714,"data-quality":0.1182380663}}
{"text":"We also present new approximation algorithms for two restrictions of the MAX 2-SAT problem.","meta":{"url":"http://arxiv.org/abs/2310.12911v1"},"cats":{"benchmark":0.5829033931,"new-dataset":0.0557012981,"data-annotation":0.5390137377,"dev-research":0.1410295246,"llms":0.3681242716,"data-quality":0.1135172187}}
{"text":"For MAX HORN-$\\{1,2\\}$-SAT, i.e., MAX CSP$(\\{x\\lor y,\\bar{x}\\lor y,x,\\bar{x}\\})$, in which clauses are not allowed to contain two negated literals, we obtain an approximation ratio of $0.94615981$. For MAX CSP$(\\{x\\lor y,x,\\bar{x}\\})$, i.e., when 2-clauses are not allowed to contain negated literals, we obtain an approximation ratio of $0.95397990$. By adapting Austrin's and our arguments for the MAX 2-SAT problem we show that these two approximation ratios are also tight, modulo only the UGC conjecture.","meta":{"url":"http://arxiv.org/abs/2310.12911v1"},"cats":{"benchmark":0.4580784585,"new-dataset":0.1138017786,"data-annotation":0.5324376116,"dev-research":0.1772467255,"llms":0.4909661067,"data-quality":0.1714014646}}
{"text":"This completes a full characterization of the approximability of the MAX 2-SAT problem and its restrictions.","meta":{"url":"http://arxiv.org/abs/2310.12911v1"},"cats":{"benchmark":0.5204187204,"new-dataset":0.0751188247,"data-annotation":0.5377463428,"dev-research":0.1206126996,"llms":0.4208288472,"data-quality":0.1228495409}}
{"text":"Relational networks within a team play a critical role in the performance of many real-world multi-robot systems.","meta":{"url":"http://arxiv.org/abs/2310.12910v1"},"cats":{"benchmark":0.2091407989,"new-dataset":0.0879623827,"data-annotation":0.4950380438,"dev-research":0.2785370492,"llms":0.500036679,"data-quality":0.0561141232}}
{"text":"To successfully accomplish tasks that require cooperation and coordination, different agents (e.g., robots) necessitate different priorities based on their positioning within the team.","meta":{"url":"http://arxiv.org/abs/2310.12910v1"},"cats":{"benchmark":0.2431168432,"new-dataset":0.0223516935,"data-annotation":0.4963252195,"dev-research":0.2613107048,"llms":0.5344478346,"data-quality":0.0368786213}}
{"text":"Yet, many of the existing multi-robot cooperation algorithms regard agents as interchangeable and lack a mechanism to guide the type of cooperation strategy the agents should exhibit.","meta":{"url":"http://arxiv.org/abs/2310.12910v1"},"cats":{"benchmark":0.2077039004,"new-dataset":0.0180490328,"data-annotation":0.5065351267,"dev-research":0.1480149975,"llms":0.5163148277,"data-quality":0.0511277401}}
{"text":"To account for the team structure in cooperative tasks, we propose a novel algorithm that uses a relational network comprising inter-agent relationships to prioritize certain agents over others.","meta":{"url":"http://arxiv.org/abs/2310.12910v1"},"cats":{"benchmark":0.3242161123,"new-dataset":0.1007092831,"data-annotation":0.5106896148,"dev-research":0.2597369256,"llms":0.4544493295,"data-quality":0.0547236846}}
{"text":"Through appropriate design of the team's relational network, we can guide the cooperation strategy, resulting in the emergence of new behaviors that accomplish the specified task.","meta":{"url":"http://arxiv.org/abs/2310.12910v1"},"cats":{"benchmark":0.1438659592,"new-dataset":0.0764257604,"data-annotation":0.4827616912,"dev-research":0.3554233515,"llms":0.5535792205,"data-quality":0.0491911022}}
{"text":"We conducted six experiments in a multi-robot setting with a cooperative task.","meta":{"url":"http://arxiv.org/abs/2310.12910v1"},"cats":{"benchmark":0.3073458215,"new-dataset":0.0806075313,"data-annotation":0.5062006303,"dev-research":0.1738530248,"llms":0.5100541095,"data-quality":0.0607983562}}
{"text":"Our results demonstrate that the proposed method can effectively influence the type of solution that the algorithm converges to by specifying the relationships between the agents, making it a promising approach for tasks that require cooperation among agents with a specified team structure.","meta":{"url":"http://arxiv.org/abs/2310.12910v1"},"cats":{"benchmark":0.300365545,"new-dataset":0.0326861377,"data-annotation":0.5209323558,"dev-research":0.2731384851,"llms":0.4690066229,"data-quality":0.0612583444}}
{"text":"Cooperative multi-agent reinforcement learning (MARL) approaches tackle the challenge of finding effective multi-agent cooperation strategies for accomplishing individual or shared objectives in multi-agent teams.","meta":{"url":"http://arxiv.org/abs/2310.12909v1"},"cats":{"benchmark":0.22693718,"new-dataset":0.0497338402,"data-annotation":0.5088416971,"dev-research":0.1527783157,"llms":0.5248472123,"data-quality":0.060363067}}
{"text":"In real-world scenarios, however, agents may encounter unforeseen failures due to constraints like battery depletion or mechanical issues.","meta":{"url":"http://arxiv.org/abs/2310.12909v1"},"cats":{"benchmark":0.3084431042,"new-dataset":0.0107260482,"data-annotation":0.5249615773,"dev-research":0.3288262525,"llms":0.4942433125,"data-quality":0.2029702344}}
{"text":"Existing state-of-the-art methods in MARL often recover slowly -- if at all -- from such malfunctions once agents have already converged on a cooperation strategy.","meta":{"url":"http://arxiv.org/abs/2310.12909v1"},"cats":{"benchmark":0.309975151,"new-dataset":0.0155913959,"data-annotation":0.5073921622,"dev-research":0.1783173975,"llms":0.5795436454,"data-quality":0.0762294499}}
{"text":"To address this gap, we present the Collaborative Adaptation (CA) framework.","meta":{"url":"http://arxiv.org/abs/2310.12909v1"},"cats":{"benchmark":0.3217459045,"new-dataset":0.1244757604,"data-annotation":0.4926746671,"dev-research":0.3747711725,"llms":0.4675916548,"data-quality":0.1977438359}}
{"text":"CA introduces a mechanism that guides collaboration and accelerates adaptation from unforeseen failures by leveraging inter-agent relationships.","meta":{"url":"http://arxiv.org/abs/2310.12909v1"},"cats":{"benchmark":0.222208724,"new-dataset":0.0640454231,"data-annotation":0.4816541808,"dev-research":0.4361162222,"llms":0.5674629484,"data-quality":0.220671175}}
{"text":"Our findings demonstrate that CA enables agents to act on the knowledge of inter-agent relations, recovering from unforeseen agent failures and selecting appropriate cooperative strategies.","meta":{"url":"http://arxiv.org/abs/2310.12909v1"},"cats":{"benchmark":0.1648207129,"new-dataset":0.0505982846,"data-annotation":0.4862761097,"dev-research":0.2170011911,"llms":0.579464673,"data-quality":0.1129243026}}
{"text":"The recent enthusiasm for open-world vision systems show the high interest of the community to perform perception tasks outside of the closed-vocabulary benchmark setups which have been so popular until now.","meta":{"url":"http://arxiv.org/abs/2310.12904v1"},"cats":{"benchmark":0.3305587155,"new-dataset":0.141938465,"data-annotation":0.5087458243,"dev-research":0.2371054524,"llms":0.5131793355,"data-quality":0.160639696}}
{"text":"Being able to discover objects in images/videos without knowing in advance what objects populate the dataset is an exciting prospect.","meta":{"url":"http://arxiv.org/abs/2310.12904v1"},"cats":{"benchmark":0.1298488967,"new-dataset":0.3460383399,"data-annotation":0.5143941651,"dev-research":0.1422945203,"llms":0.5264562771,"data-quality":0.1194251665}}
{"text":"But how to find objects without knowing anything about them?","meta":{"url":"http://arxiv.org/abs/2310.12904v1"},"cats":{"benchmark":0.1445087616,"new-dataset":0.0988965884,"data-annotation":0.5474145974,"dev-research":0.1330465153,"llms":0.5521492783,"data-quality":0.1156281068}}
{"text":"Recent works show that it is possible to perform class-agnostic unsupervised object localization by exploiting self-supervised pre-trained features.","meta":{"url":"http://arxiv.org/abs/2310.12904v1"},"cats":{"benchmark":0.1907141857,"new-dataset":0.079593995,"data-annotation":0.5405087958,"dev-research":0.1560898575,"llms":0.5327098339,"data-quality":0.2812885239}}
{"text":"We propose here a survey of unsupervised object localization methods that discover objects in images without requiring any manual annotation in the era of self-supervised ViTs.","meta":{"url":"http://arxiv.org/abs/2310.12904v1"},"cats":{"benchmark":0.2086984336,"new-dataset":0.1416478164,"data-annotation":0.5435274345,"dev-research":0.167159579,"llms":0.5612315205,"data-quality":0.3929162883}}
{"text":"We gather links of discussed methods in the repository https://github.com/valeoai/Awesome-Unsupervised-Object-Localization.","meta":{"url":"http://arxiv.org/abs/2310.12904v1"},"cats":{"benchmark":0.3042000896,"new-dataset":0.069438726,"data-annotation":0.5543307079,"dev-research":0.1530266254,"llms":0.5742365121,"data-quality":0.2298700039}}
{"text":"The paper proposes a framework that combines behavioral and computational experiments employing fictional prompts as a novel tool for investigating cultural artifacts and social biases in storytelling both by humans and generative AI.","meta":{"url":"http://arxiv.org/abs/2310.12902v1"},"cats":{"benchmark":0.1698006268,"new-dataset":0.0942393862,"data-annotation":0.542568396,"dev-research":0.26779676,"llms":0.5485673346,"data-quality":0.135752676}}
{"text":"The study analyzes 250 stories authored by crowdworkers in June 2019 and 80 stories generated by GPT-3.5 and GPT-4 in March 2023 by merging methods from narratology and inferential statistics.","meta":{"url":"http://arxiv.org/abs/2310.12902v1"},"cats":{"benchmark":0.2396661734,"new-dataset":0.3607296174,"data-annotation":0.5350773636,"dev-research":0.2502449165,"llms":0.5218179727,"data-quality":0.0922331739}}
{"text":"Both crowdworkers and large language models responded to identical prompts about creating and falling in love with an artificial human.","meta":{"url":"http://arxiv.org/abs/2310.12902v1"},"cats":{"benchmark":0.1475916902,"new-dataset":0.0477697706,"data-annotation":0.5351377928,"dev-research":0.2278553893,"llms":0.5338834148,"data-quality":0.0953434496}}
{"text":"The proposed experimental paradigm allows a direct comparison between human and LLM-generated storytelling.","meta":{"url":"http://arxiv.org/abs/2310.12902v1"},"cats":{"benchmark":0.1734051671,"new-dataset":0.0698618937,"data-annotation":0.513952701,"dev-research":0.2461345688,"llms":0.7677383307,"data-quality":0.0667489343}}
{"text":"Responses to the Pygmalionesque prompts confirm the pervasive presence of the Pygmalion myth in the collective imaginary of both humans and large language models.","meta":{"url":"http://arxiv.org/abs/2310.12902v1"},"cats":{"benchmark":0.1428375093,"new-dataset":0.0993078061,"data-annotation":0.5439916015,"dev-research":0.2040787563,"llms":0.5389665611,"data-quality":0.1572100349}}
{"text":"All solicited narratives present a scientific or technological pursuit.","meta":{"url":"http://arxiv.org/abs/2310.12902v1"},"cats":{"benchmark":0.1382342185,"new-dataset":0.103901066,"data-annotation":0.5138385374,"dev-research":0.1750548465,"llms":0.570286852,"data-quality":0.0661965465}}
{"text":"The analysis reveals that narratives from GPT-3.5 and particularly GPT-4 are more more progressive in terms of gender roles and sexuality than those written by humans.","meta":{"url":"http://arxiv.org/abs/2310.12902v1"},"cats":{"benchmark":0.2443876237,"new-dataset":0.0308369504,"data-annotation":0.5040821706,"dev-research":0.1967422029,"llms":0.4670574104,"data-quality":0.0950044342}}
{"text":"While AI narratives can occasionally provide innovative plot twists, they offer less imaginative scenarios and rhetoric than human-authored texts.","meta":{"url":"http://arxiv.org/abs/2310.12902v1"},"cats":{"benchmark":0.1757178702,"new-dataset":0.0299612647,"data-annotation":0.5336406161,"dev-research":0.2847691038,"llms":0.5088103847,"data-quality":0.1168672893}}
{"text":"The proposed framework argues that fiction can be used as a window into human and AI-based collective imaginary and social dimensions.","meta":{"url":"http://arxiv.org/abs/2310.12902v1"},"cats":{"benchmark":0.1472531018,"new-dataset":0.0843222043,"data-annotation":0.5301856501,"dev-research":0.2653460784,"llms":0.4780396063,"data-quality":0.0573977723}}
{"text":"We explain the methodology used to create the data submitted to HuMob Challenge, a data analysis competition for human mobility prediction.","meta":{"url":"http://arxiv.org/abs/2310.12900v1"},"cats":{"benchmark":0.3270417746,"new-dataset":0.2445258989,"data-annotation":0.5029918066,"dev-research":0.1566243471,"llms":0.4035649489,"data-quality":0.0977197974}}
{"text":"We adopted a personalized model to predict the individual's movement trajectory from their data, instead of predicting from the overall movement, based on the hypothesis that human movement is unique to each person.","meta":{"url":"http://arxiv.org/abs/2310.12900v1"},"cats":{"benchmark":0.3187936428,"new-dataset":0.0750580792,"data-annotation":0.5132397238,"dev-research":0.1968515012,"llms":0.3408998438,"data-quality":0.0636565467}}
{"text":"We devised the features such as the date and time, activity time, days of the week, time of day, and frequency of visits to POI (Point of Interest).","meta":{"url":"http://arxiv.org/abs/2310.12900v1"},"cats":{"benchmark":0.2844749723,"new-dataset":0.2501503142,"data-annotation":0.5013735692,"dev-research":0.1716061471,"llms":0.4602607603,"data-quality":0.0454840856}}
{"text":"As additional features, we incorporated the movement of other individuals with similar behavior patterns through the employment of clustering.","meta":{"url":"http://arxiv.org/abs/2310.12900v1"},"cats":{"benchmark":0.238928606,"new-dataset":0.0246880704,"data-annotation":0.5070233972,"dev-research":0.2280694049,"llms":0.4560533472,"data-quality":0.0819748407}}
{"text":"The machine learning model we adopted was the Support Vector Regression (SVR).","meta":{"url":"http://arxiv.org/abs/2310.12900v1"},"cats":{"benchmark":0.4486023887,"new-dataset":0.0245910262,"data-annotation":0.5247159287,"dev-research":0.2376235819,"llms":0.2958181179,"data-quality":0.1591478751}}
{"text":"We performed accuracy through offline assessment and carried out feature selection and parameter tuning.","meta":{"url":"http://arxiv.org/abs/2310.12900v1"},"cats":{"benchmark":0.6243642974,"new-dataset":0.0411356509,"data-annotation":0.4980885526,"dev-research":0.2076951031,"llms":0.4205530616,"data-quality":0.139437915}}
{"text":"Although overall dataset provided consists of 100,000 users trajectory, our method use only 20,000 target users data, and do not need to use other 80,000 data.","meta":{"url":"http://arxiv.org/abs/2310.12900v1"},"cats":{"benchmark":0.3093703171,"new-dataset":0.3683067633,"data-annotation":0.4784669291,"dev-research":0.1641933989,"llms":0.4726082131,"data-quality":0.054097672}}
{"text":"Despite the personalized model's traditional feature engineering approach, this model yields reasonably good accuracy with lower computational cost.","meta":{"url":"http://arxiv.org/abs/2310.12900v1"},"cats":{"benchmark":0.5587102694,"new-dataset":0.0125512303,"data-annotation":0.5239368614,"dev-research":0.2351568456,"llms":0.3919295634,"data-quality":0.1835952543}}
{"text":"As child-robot interactions become more and more common in daily life environment, it is important to examine how robot's errors influence children's behavior.","meta":{"url":"http://arxiv.org/abs/2310.12899v1"},"cats":{"benchmark":0.2646059288,"new-dataset":0.0286743211,"data-annotation":0.5134527524,"dev-research":0.3525496016,"llms":0.4858160882,"data-quality":0.1943304916}}
{"text":"We explored how a robot's unexpected behaviors affect child-robot interactions during two workshops on active reading: one in a modern art museum and one in a school.","meta":{"url":"http://arxiv.org/abs/2310.12899v1"},"cats":{"benchmark":0.1249734991,"new-dataset":0.0784449827,"data-annotation":0.523194477,"dev-research":0.2340795039,"llms":0.5774229888,"data-quality":0.1010286379}}
{"text":"We observed the behavior and attitudes of 42 children from three age groups: 6-7 years, 8-10 years, and 10-12 years.","meta":{"url":"http://arxiv.org/abs/2310.12899v1"},"cats":{"benchmark":0.2041937119,"new-dataset":0.1063891474,"data-annotation":0.519979705,"dev-research":0.2091290709,"llms":0.511274815,"data-quality":0.0662717317}}
{"text":"Through our observations, we identified six different types of surprising robot behaviors: personality, movement malfunctions, inconsistent behavior, mispronunciation, delays, and freezing.","meta":{"url":"http://arxiv.org/abs/2310.12899v1"},"cats":{"benchmark":0.1746663234,"new-dataset":0.0641743731,"data-annotation":0.5153246738,"dev-research":0.2135511351,"llms":0.4978456992,"data-quality":0.1252388806}}
{"text":"Using a qualitative analysis, we examined how children responded to each type of behavior, and we observed similarities and differences between the age groups.","meta":{"url":"http://arxiv.org/abs/2310.12899v1"},"cats":{"benchmark":0.1882816366,"new-dataset":0.0444006787,"data-annotation":0.4990458049,"dev-research":0.2395093984,"llms":0.4996780757,"data-quality":0.0590117195}}
{"text":"Based on our findings, we propose guidelines for designing age-appropriate learning interactions with social robots.","meta":{"url":"http://arxiv.org/abs/2310.12899v1"},"cats":{"benchmark":0.1845942266,"new-dataset":0.0570553039,"data-annotation":0.5157346919,"dev-research":0.2842400388,"llms":0.5456549646,"data-quality":0.0993372513}}
{"text":"The recently-emerging field of higher order MDS codes has sought to unify a number of concepts in coding theory.","meta":{"url":"http://arxiv.org/abs/2310.12898v1"},"cats":{"benchmark":0.3033382875,"new-dataset":0.0229558481,"data-annotation":0.511044051,"dev-research":0.1562780186,"llms":0.5671840079,"data-quality":0.1038738141}}
{"text":"Such areas captured by higher order MDS codes include maximally recoverable (MR) tensor codes, codes with optimal list-decoding guarantees, and codes with constrained generator matrices (as in the GM-MDS theorem).   ","meta":{"url":"http://arxiv.org/abs/2310.12898v1"},"cats":{"benchmark":0.3564576043,"new-dataset":0.0451917542,"data-annotation":0.5178860839,"dev-research":0.1060613542,"llms":0.5030837412,"data-quality":0.1042519402}}
{"text":"By proving these equivalences, Brakensiek-Gopi-Makam showed the existence of optimally list-decodable Reed-Solomon codes over exponential sized fields.","meta":{"url":"http://arxiv.org/abs/2310.12898v1"},"cats":{"benchmark":0.3241617115,"new-dataset":0.1190879498,"data-annotation":0.536299367,"dev-research":0.129055731,"llms":0.4968482948,"data-quality":0.1147633218}}
{"text":"Building on this, recent breakthroughs by Guo-Zhang and Alrabiah-Guruswami-Li have shown that randomly punctured Reed-Solomon codes achieve list-decoding capacity (which is a relaxation of optimal list-decodability) over linear size fields.","meta":{"url":"http://arxiv.org/abs/2310.12898v1"},"cats":{"benchmark":0.3130814647,"new-dataset":0.0797987463,"data-annotation":0.528930431,"dev-research":0.1183523103,"llms":0.4860563258,"data-quality":0.1370726735}}
{"text":"We extend these works by developing a formal theory of relaxed higher order MDS codes.","meta":{"url":"http://arxiv.org/abs/2310.12898v1"},"cats":{"benchmark":0.3979731479,"new-dataset":0.0290449566,"data-annotation":0.5117077843,"dev-research":0.1325182903,"llms":0.565936946,"data-quality":0.1200489848}}
{"text":"In particular, we show that there are two inequivalent relaxations which we call lower and upper relaxations.","meta":{"url":"http://arxiv.org/abs/2310.12898v1"},"cats":{"benchmark":0.3911787193,"new-dataset":0.0726897908,"data-annotation":0.5314377576,"dev-research":0.1629178452,"llms":0.5074033937,"data-quality":0.101225656}}
{"text":"The lower relaxation is equivalent to relaxed optimal list-decodable codes and the upper relaxation is equivalent to relaxed MR tensor codes with a single parity check per column.   ","meta":{"url":"http://arxiv.org/abs/2310.12898v1"},"cats":{"benchmark":0.5176095087,"new-dataset":0.0319479919,"data-annotation":0.5219922392,"dev-research":0.1132695312,"llms":0.4700305128,"data-quality":0.1233476213}}
{"text":"We then generalize the techniques of GZ and AGL to show that both these relaxations can be constructed over constant size fields by randomly puncturing suitable algebraic-geometric codes.","meta":{"url":"http://arxiv.org/abs/2310.12898v1"},"cats":{"benchmark":0.2754922008,"new-dataset":0.0499092726,"data-annotation":0.5370468926,"dev-research":0.1542608784,"llms":0.4908225465,"data-quality":0.1042968044}}
{"text":"For this, we crucially use the generalized GM-MDS theorem for polynomial codes recently proved by Brakensiek-Dhar-Gopi.","meta":{"url":"http://arxiv.org/abs/2310.12898v1"},"cats":{"benchmark":0.3403319767,"new-dataset":0.0370898534,"data-annotation":0.5361812556,"dev-research":0.1024784199,"llms":0.4550003378,"data-quality":0.1145284138}}
{"text":"We obtain the following corollaries from our main result.","meta":{"url":"http://arxiv.org/abs/2310.12898v1"},"cats":{"benchmark":0.3721176591,"new-dataset":0.5615991424,"data-annotation":0.5270665528,"dev-research":0.1575368067,"llms":0.449791452,"data-quality":0.1109780161}}
{"text":"First, randomly punctured AG codes of rate $R$ achieve list-decoding capacity with list size $O(1/\\epsilon)$ and field size $\\exp(O(1/\\epsilon^2))$. Prior to this work, AG codes were not even known to achieve list-decoding capacity.","meta":{"url":"http://arxiv.org/abs/2310.12898v1"},"cats":{"benchmark":0.3238014996,"new-dataset":0.043423398,"data-annotation":0.5204263433,"dev-research":0.0992608331,"llms":0.5273978242,"data-quality":0.1697583278}}
{"text":"Second, by randomly puncturing AG codes, we can construct relaxed MR tensor codes with a single parity check per column over constant-sized fields, whereas (non-relaxed) MR tensor codes require exponential field size.","meta":{"url":"http://arxiv.org/abs/2310.12898v1"},"cats":{"benchmark":0.3819991034,"new-dataset":0.0232938597,"data-annotation":0.5149288477,"dev-research":0.1047424594,"llms":0.5291183441,"data-quality":0.1157071844}}
{"text":"Achieving robust language technologies that can perform well across the world's many languages is a central goal of multilingual NLP.","meta":{"url":"http://arxiv.org/abs/2310.12892v1"},"cats":{"benchmark":0.2916595859,"new-dataset":0.094629983,"data-annotation":0.5064691829,"dev-research":0.2640830586,"llms":0.5260520392,"data-quality":0.2962400825}}
{"text":"In this work, we take stock of and empirically analyse task performance disparities that exist between multilingual task-oriented dialogue (ToD) systems.","meta":{"url":"http://arxiv.org/abs/2310.12892v1"},"cats":{"benchmark":0.4299930284,"new-dataset":0.153829006,"data-annotation":0.5348191135,"dev-research":0.279611376,"llms":0.5620196608,"data-quality":0.1057262151}}
{"text":"We first define new quantitative measures of absolute and relative equivalence in system performance, capturing disparities across languages and within individual languages.","meta":{"url":"http://arxiv.org/abs/2310.12892v1"},"cats":{"benchmark":0.6389658788,"new-dataset":0.0410136886,"data-annotation":0.5274367144,"dev-research":0.2478454717,"llms":0.5297685039,"data-quality":0.1817573737}}
{"text":"Through a series of controlled experiments, we demonstrate that performance disparities depend on a number of factors: the nature of the ToD task at hand, the underlying pretrained language model, the target language, and the amount of ToD annotated data.","meta":{"url":"http://arxiv.org/abs/2310.12892v1"},"cats":{"benchmark":0.4247519635,"new-dataset":0.0534912361,"data-annotation":0.539133367,"dev-research":0.2400708618,"llms":0.5280202693,"data-quality":0.1241642881}}
{"text":"We empirically prove the existence of the adaptation and intrinsic biases in current ToD systems: e.g., ToD systems trained for Arabic or Turkish using annotated ToD data fully parallel to English ToD data still exhibit diminished ToD task performance.","meta":{"url":"http://arxiv.org/abs/2310.12892v1"},"cats":{"benchmark":0.3902279691,"new-dataset":0.1251614239,"data-annotation":0.5391123511,"dev-research":0.1768638299,"llms":0.4856511132,"data-quality":0.1398576032}}
{"text":"Beyond providing a series of insights into the performance disparities of ToD systems in different languages, our analyses offer practical tips on how to approach ToD data collection and system development for new languages.","meta":{"url":"http://arxiv.org/abs/2310.12892v1"},"cats":{"benchmark":0.4283290536,"new-dataset":0.3328950547,"data-annotation":0.5074222683,"dev-research":0.3323675056,"llms":0.5756404861,"data-quality":0.0984472903}}
{"text":"Connectivity (or equivalently, unweighted maximum flow) is an important measure in graph theory and combinatorial optimization.","meta":{"url":"http://arxiv.org/abs/2310.12889v1"},"cats":{"benchmark":0.401159012,"new-dataset":0.0287592513,"data-annotation":0.5056705339,"dev-research":0.1472323352,"llms":0.4355802454,"data-quality":0.0644553274}}
{"text":"Given a graph $G$ with vertices $s$ and $t$, the connectivity $\\lambda(s,t)$ from $s$ to $t$ is defined to be the maximum number of edge-disjoint paths from $s$ to $t$ in $G$.   Much research has gone into designing fast algorithms for computing connectivities in graphs.","meta":{"url":"http://arxiv.org/abs/2310.12889v1"},"cats":{"benchmark":0.4523855351,"new-dataset":0.0477827329,"data-annotation":0.5184238869,"dev-research":0.1638270962,"llms":0.5009921374,"data-quality":0.0722349199}}
{"text":"Previous work showed that it is possible to compute connectivities for all pairs of vertices in directed graphs with $m$ edges in $\\tilde{O}(m^\\omega)$ time","meta":{"url":"http://arxiv.org/abs/2310.12889v1"},"cats":{"benchmark":0.423742882,"new-dataset":0.0464435732,"data-annotation":0.5283861979,"dev-research":0.1322876375,"llms":0.5879921044,"data-quality":0.0859560439}}
{"text":"[Chueng, Lau, and Leung, FOCS 2011], where $\\omega \\in","meta":{"url":"http://arxiv.org/abs/2310.12889v1"},"cats":{"benchmark":0.3145219039,"new-dataset":0.4652661982,"data-annotation":0.5191578736,"dev-research":0.1164579287,"llms":0.5995627986,"data-quality":0.1043114817}}
{"text":"[2,2.3716)$ is the exponent of matrix multiplication.","meta":{"url":"http://arxiv.org/abs/2310.12889v1"},"cats":{"benchmark":0.3313543866,"new-dataset":0.232726184,"data-annotation":0.5381072208,"dev-research":0.2088512511,"llms":0.4443573688,"data-quality":0.1012253631}}
{"text":"For the related problem of computing \"small connectivities,\" it was recently shown that for any positive integer $k$, we can compute $\\min(k,\\lambda(s,t))$ for all pairs of vertices $(s,t)$ in a directed graph with $n$ nodes in $\\tilde{O}((kn)^\\omega)$ time","meta":{"url":"http://arxiv.org/abs/2310.12889v1"},"cats":{"benchmark":0.4726319992,"new-dataset":0.0269277628,"data-annotation":0.5323295065,"dev-research":0.1527328804,"llms":0.4977190708,"data-quality":0.0971683425}}
{"text":"[Akmal and Jin, ICALP 2023].   ","meta":{"url":"http://arxiv.org/abs/2310.12889v1"},"cats":{"benchmark":0.2822733013,"new-dataset":0.2986681072,"data-annotation":0.5108442592,"dev-research":0.1672110861,"llms":0.5681975066,"data-quality":0.1031404304}}
{"text":"In this paper, we present an alternate exposition of these $\\tilde{O}(m^\\omega)$ and $\\tilde{O}((kn)^\\omega)$ time algorithms, with simpler proofs of correctness.","meta":{"url":"http://arxiv.org/abs/2310.12889v1"},"cats":{"benchmark":0.4716966124,"new-dataset":0.0250783098,"data-annotation":0.5264446026,"dev-research":0.1504529433,"llms":0.5721703336,"data-quality":0.0827054528}}
{"text":"Earlier proofs were somewhat indirect, introducing an elegant but ad hoc \"flow vector framework\" for showing correctness of these algorithms.","meta":{"url":"http://arxiv.org/abs/2310.12889v1"},"cats":{"benchmark":0.5061122159,"new-dataset":0.0053773228,"data-annotation":0.5239781744,"dev-research":0.1854596817,"llms":0.4792551587,"data-quality":0.1424506826}}
{"text":"In contrast, we observe that these algorithms for computing exact and small connectivity values can be interpreted as testing whether certain generating functions enumerating families of edge-disjoint paths are nonzero.","meta":{"url":"http://arxiv.org/abs/2310.12889v1"},"cats":{"benchmark":0.3954769132,"new-dataset":0.0392769791,"data-annotation":0.519445521,"dev-research":0.1431620418,"llms":0.5043795657,"data-quality":0.1211671031}}
{"text":"This new perspective yields more transparent proofs, and ties the approach for these problems more closely to the literature surrounding algebraic graph algorithms.","meta":{"url":"http://arxiv.org/abs/2310.12889v1"},"cats":{"benchmark":0.4213450742,"new-dataset":0.0169897594,"data-annotation":0.5231650535,"dev-research":0.1715679947,"llms":0.4419106329,"data-quality":0.1550629603}}
{"text":"The GM-MDS theorem, conjectured by Dau-Song-Dong-Yuen and proved by Lovett and Yildiz-Hassibi, shows that the generator matrices of Reed-Solomon codes can attain every possible configuration of zeros for an MDS code.","meta":{"url":"http://arxiv.org/abs/2310.12888v1"},"cats":{"benchmark":0.2708424445,"new-dataset":0.0575652641,"data-annotation":0.5324458441,"dev-research":0.104788038,"llms":0.55128917,"data-quality":0.1336954163}}
{"text":"The recently emerging theory of higher order MDS codes has connected the GM-MDS theorem to other important properties of Reed-Solomon codes, including showing that Reed-Solomon codes can achieve list decoding capacity, even over fields of size linear in the message length.   ","meta":{"url":"http://arxiv.org/abs/2310.12888v1"},"cats":{"benchmark":0.3073607285,"new-dataset":0.0545416063,"data-annotation":0.5220222445,"dev-research":0.0937483179,"llms":0.5378915983,"data-quality":0.1012086099}}
{"text":"A few works have extended the GM-MDS theorem to other families of codes, including Gabidulin and skew polynomial codes.","meta":{"url":"http://arxiv.org/abs/2310.12888v1"},"cats":{"benchmark":0.3328786,"new-dataset":0.0396610618,"data-annotation":0.5269706918,"dev-research":0.1027668071,"llms":0.494058697,"data-quality":0.0936034986}}
{"text":"In this paper, we generalize all these previous results by showing that the GM-MDS theorem applies to any \\emph{polynomial code}, i.e., a code where the columns of the generator matrix are obtained by evaluating linearly independent polynomials at different points.","meta":{"url":"http://arxiv.org/abs/2310.12888v1"},"cats":{"benchmark":0.409576526,"new-dataset":0.0280061448,"data-annotation":0.5396920437,"dev-research":0.1061693584,"llms":0.4759766036,"data-quality":0.0957570992}}
{"text":"We also show that the GM-MDS theorem applies to dual codes of such polynomial codes, which is non-trivial since the dual of a polynomial code may not be a polynomial code.","meta":{"url":"http://arxiv.org/abs/2310.12888v1"},"cats":{"benchmark":0.3436801466,"new-dataset":0.0299196294,"data-annotation":0.5336336337,"dev-research":0.0938671604,"llms":0.4665352566,"data-quality":0.1163441027}}
{"text":"More generally, we show that GM-MDS theorem also holds for algebraic codes (and their duals) where columns of the generator matrix are chosen to be points on some irreducible variety which is not contained in a hyperplane through the origin.","meta":{"url":"http://arxiv.org/abs/2310.12888v1"},"cats":{"benchmark":0.2721229846,"new-dataset":0.0344259408,"data-annotation":0.5405287988,"dev-research":0.1249920717,"llms":0.4960095269,"data-quality":0.1168868046}}
{"text":"Our generalization has applications to constructing capacity-achieving list-decodable codes as shown in a follow-up work by Brakensiek-Dhar-Gopi-Zhang, where it is proved that randomly punctured algebraic-geometric (AG) codes achieve list-decoding capacity over constant-sized fields.","meta":{"url":"http://arxiv.org/abs/2310.12888v1"},"cats":{"benchmark":0.247719707,"new-dataset":0.0829939527,"data-annotation":0.5313773196,"dev-research":0.1301957726,"llms":0.4818702251,"data-quality":0.1222792854}}
{"text":"Many attempts have been made at estimating discrete emotions (calmness, anxiety, boredom, surprise, anger) and continuous emotional measures commonly used in psychology, namely `valence' (The pleasantness of the emotion being displayed) and `arousal' (The intensity of the emotion being displayed).","meta":{"url":"http://arxiv.org/abs/2310.12887v1"},"cats":{"benchmark":0.3193818805,"new-dataset":0.1005538928,"data-annotation":0.5192752031,"dev-research":0.1940687503,"llms":0.4858596258,"data-quality":0.12125193}}
{"text":"Existing methods to estimate arousal and valence rely on learning from data sets, where an expert annotator labels every image frame.","meta":{"url":"http://arxiv.org/abs/2310.12887v1"},"cats":{"benchmark":0.3383267383,"new-dataset":0.2326210354,"data-annotation":0.5448957442,"dev-research":0.2054336752,"llms":0.4249188368,"data-quality":0.2712155719}}
{"text":"Access to an expert annotator is not always possible, and the annotation can also be tedious.","meta":{"url":"http://arxiv.org/abs/2310.12887v1"},"cats":{"benchmark":0.2948966085,"new-dataset":0.19530632,"data-annotation":0.5841318742,"dev-research":0.3112827177,"llms":0.5826988681,"data-quality":0.4240017192}}
{"text":"Hence it is more practical to obtain self-reported arousal and valence values directly from the human in a real-time Human-Robot collaborative setting.","meta":{"url":"http://arxiv.org/abs/2310.12887v1"},"cats":{"benchmark":0.2312051108,"new-dataset":0.0721552239,"data-annotation":0.5211427829,"dev-research":0.2702797469,"llms":0.5076732591,"data-quality":0.0739531582}}
{"text":"Hence this paper provides an emotion data set (HRI-AVC) obtained while conducting a human-robot interaction (HRI) task.","meta":{"url":"http://arxiv.org/abs/2310.12887v1"},"cats":{"benchmark":0.2586689117,"new-dataset":0.4207700942,"data-annotation":0.5216536632,"dev-research":0.2858731032,"llms":0.4658088583,"data-quality":0.0770250432}}
{"text":"The self-reported pair of labels in this data set is associated with a set of image frames.","meta":{"url":"http://arxiv.org/abs/2310.12887v1"},"cats":{"benchmark":0.2958581085,"new-dataset":0.8262836445,"data-annotation":0.5220604897,"dev-research":0.1373784328,"llms":0.4333730365,"data-quality":0.4413649918}}
{"text":"This paper also proposes a spatial and temporal attention-based network to estimate arousal and valence from this set of image frames.","meta":{"url":"http://arxiv.org/abs/2310.12887v1"},"cats":{"benchmark":0.2694088202,"new-dataset":0.1861635015,"data-annotation":0.5450932416,"dev-research":0.1588422937,"llms":0.4366599155,"data-quality":0.1066106609}}
{"text":"The results show that an attention-based network can estimate valence and arousal on the HRI-AVC data set even when Arousal and Valence values are unavailable per frame.","meta":{"url":"http://arxiv.org/abs/2310.12887v1"},"cats":{"benchmark":0.3196523205,"new-dataset":0.0945779676,"data-annotation":0.5331876069,"dev-research":0.1639948642,"llms":0.4594095156,"data-quality":0.1206101188}}
{"text":"In this paper, we explore conjunctive query rewriting, focusing on queries containing universally quantified negation within the framework of disjunctive existential rules.","meta":{"url":"http://arxiv.org/abs/2310.12884v1"},"cats":{"benchmark":0.2750376505,"new-dataset":0.0654092669,"data-annotation":0.4839723587,"dev-research":0.2582761118,"llms":0.5786952944,"data-quality":0.1511506872}}
{"text":"We address the undecidability of the existence of a finite and complete UCQ-rewriting and the identification of finite unification sets (fus) of rules.","meta":{"url":"http://arxiv.org/abs/2310.12884v1"},"cats":{"benchmark":0.3042153416,"new-dataset":0.055896203,"data-annotation":0.4950094583,"dev-research":0.2944718192,"llms":0.5839855903,"data-quality":0.1537329925}}
{"text":"We introduce new rule classes, connected linear rules and connected domain restricted rules, that exhibit the fus property for existential rules.","meta":{"url":"http://arxiv.org/abs/2310.12884v1"},"cats":{"benchmark":0.283591742,"new-dataset":0.1316605534,"data-annotation":0.494231748,"dev-research":0.2429329676,"llms":0.5345836467,"data-quality":0.190924713}}
{"text":"Additionally, we propose disconnected disjunction for disjunctive existential rules to achieve the fus property when we extend the introduced rule fragments to disjunctive existential rules.","meta":{"url":"http://arxiv.org/abs/2310.12884v1"},"cats":{"benchmark":0.2417302408,"new-dataset":0.0356573024,"data-annotation":0.4791348959,"dev-research":0.2505385551,"llms":0.600490321,"data-quality":0.1657689029}}
{"text":"We present ECOMPLETO, a system for efficient query rewriting with disjunctive existential rules, capable of handling UCQs with universally quantified negation.","meta":{"url":"http://arxiv.org/abs/2310.12884v1"},"cats":{"benchmark":0.3101190147,"new-dataset":0.096382573,"data-annotation":0.4945641257,"dev-research":0.2633533139,"llms":0.5885518486,"data-quality":0.1508313542}}
{"text":"Our experiments demonstrate ECOMPLETO's consistent ability to produce finite UCQ-rewritings and describe the performance on different ontologies and queries.","meta":{"url":"http://arxiv.org/abs/2310.12884v1"},"cats":{"benchmark":0.3038030444,"new-dataset":0.0674244679,"data-annotation":0.5072858527,"dev-research":0.2656917012,"llms":0.6073835012,"data-quality":0.1025815772}}
{"text":"The idea of next-generation ports has become more apparent in the last ten years in response to the challenge posed by the rising demand for efficiency and the ever-increasing volume of goods.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.2707925056,"new-dataset":0.0655436959,"data-annotation":0.4992902552,"dev-research":0.2452076128,"llms":0.5253955852,"data-quality":0.0532117201}}
{"text":"In this new era of intelligent infrastructure and facilities, it is evident that cyber-security has recently received the most significant attention from the seaport and maritime authorities, and it is a primary concern on the agenda of most ports.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.2321015172,"new-dataset":0.0881626687,"data-annotation":0.5025378072,"dev-research":0.2927913344,"llms":0.5420405202,"data-quality":0.0642558946}}
{"text":"Traditional security solutions can be applied to safeguard IoT and Cyber-Physical Systems (CPS) from harmful entities.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.2170868788,"new-dataset":0.0382528076,"data-annotation":0.4868342669,"dev-research":0.3255147443,"llms":0.593417821,"data-quality":0.0742873703}}
{"text":"Nevertheless, security researchers can only watch, examine, and learn about the behaviors of attackers if these solutions operate more transparently.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.2242448889,"new-dataset":0.0154040391,"data-annotation":0.5177674389,"dev-research":0.27261012,"llms":0.5283416934,"data-quality":0.0875216781}}
{"text":"Herein, honeypots are potential solutions since they offer valuable information about the attackers.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.226021452,"new-dataset":0.0614552711,"data-annotation":0.528699442,"dev-research":0.2338418868,"llms":0.560215097,"data-quality":0.090785838}}
{"text":"It can be virtual or physical.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.1646894909,"new-dataset":0.03614867,"data-annotation":0.5026658659,"dev-research":0.2046416834,"llms":0.5300947067,"data-quality":0.0586121188}}
{"text":"Virtual honeypots must be more realistic to entice attackers, necessitating better high-fidelity.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.3108846412,"new-dataset":0.0061329502,"data-annotation":0.5202602228,"dev-research":0.2143671183,"llms":0.5620744695,"data-quality":0.0711675496}}
{"text":"To this end, Digital Twin (DT) technology can be employed to increase the complexity and simulation fidelity of the honeypots.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.332595273,"new-dataset":0.0081443826,"data-annotation":0.492544734,"dev-research":0.1676352322,"llms":0.5243268816,"data-quality":0.070051664}}
{"text":"Seaports can be attacked from both their existing devices and external devices at the same time.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.2137710758,"new-dataset":0.0327020225,"data-annotation":0.4961448932,"dev-research":0.3104457766,"llms":0.5459930453,"data-quality":0.0808953988}}
{"text":"Existing mechanisms are insufficient to detect external attacks; therefore, the current systems cannot handle attacks at the desired level.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.2544008722,"new-dataset":0.0042720148,"data-annotation":0.5103839825,"dev-research":0.2221325196,"llms":0.5612911158,"data-quality":0.0886572239}}
{"text":"DT and honeypot technologies can be used together to tackle them.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.3080510226,"new-dataset":0.0129214956,"data-annotation":0.4775458331,"dev-research":0.1885643677,"llms":0.618321871,"data-quality":0.0616156704}}
{"text":"Consequently, we suggest a DT-assisted honeypot, called TwinPot, for external attacks in smart seaports.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.3180149972,"new-dataset":0.0452256734,"data-annotation":0.5046837231,"dev-research":0.2171399201,"llms":0.5687681589,"data-quality":0.0910960185}}
{"text":"Moreover, we propose an intelligent attack detection mechanism to handle different attack types using DT for internal attacks.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.3003513135,"new-dataset":0.0213149591,"data-annotation":0.5308345159,"dev-research":0.270286393,"llms":0.514534969,"data-quality":0.1508404424}}
{"text":"Finally, we build an extensive smart seaport dataset for internal and external attacks using the MANSIM tool and two existing datasets to test the performance of our system.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.3746954253,"new-dataset":0.6524450152,"data-annotation":0.5036211661,"dev-research":0.2685064851,"llms":0.5532494995,"data-quality":0.0884659083}}
{"text":"We show that under simultaneous internal and external attacks on the system, our solution successfully detects internal and external attacks.","meta":{"url":"http://arxiv.org/abs/2310.12880v1"},"cats":{"benchmark":0.3183306637,"new-dataset":0.0566136324,"data-annotation":0.5326963666,"dev-research":0.2461774971,"llms":0.5288871292,"data-quality":0.151267136}}
{"text":"Analogy-making between narratives is one of the most critical abilities in natural language understanding.","meta":{"url":"http://arxiv.org/abs/2310.12874v1"},"cats":{"benchmark":0.1373208395,"new-dataset":0.0465078082,"data-annotation":0.5380206491,"dev-research":0.3394695063,"llms":0.5900365177,"data-quality":0.1746709776}}
{"text":"In this paper, we evaluate the ability to identify and generate analogy by building a first-of-its-kind large-scale story-level analogy corpus, StoryAnalogy, which contains 24K story pairs from diverse domains with human annotations on two similarities from the extended Structure-Mapping Theory.","meta":{"url":"http://arxiv.org/abs/2310.12874v1"},"cats":{"benchmark":0.2375185008,"new-dataset":0.278138743,"data-annotation":0.5452118649,"dev-research":0.2512482418,"llms":0.5797448402,"data-quality":0.1687612067}}
{"text":"We design a set of tests on StoryAnalogy, presenting the first evaluation of story-level analogy identification and generation.","meta":{"url":"http://arxiv.org/abs/2310.12874v1"},"cats":{"benchmark":0.2967634895,"new-dataset":0.0670301499,"data-annotation":0.5403561011,"dev-research":0.3352788623,"llms":0.5973264747,"data-quality":0.1551509043}}
{"text":"Interestingly, we find that the analogy identification tasks are extremely challenging not only for the sentence embedding models but also for the recent large language models (LLMs) such as ChatGPT and LLaMa, where ChatGPT only achieved around 30% accuracy in multiple-choice questions (> 85% accuracy for humans).","meta":{"url":"http://arxiv.org/abs/2310.12874v1"},"cats":{"benchmark":0.3189079445,"new-dataset":0.0283427846,"data-annotation":0.5593796636,"dev-research":0.162978333,"llms":0.6328570461,"data-quality":0.2699459297}}
{"text":"Finally, we find that data in StoryAnalogy can improve LLMs analogy generation quality, where a fine-tuned FlanT5-xxl model yields comparable performance to zero-shot ChatGPT.","meta":{"url":"http://arxiv.org/abs/2310.12874v1"},"cats":{"benchmark":0.2390551085,"new-dataset":0.264283049,"data-annotation":0.5305549736,"dev-research":0.2058747751,"llms":0.7309819836,"data-quality":0.1441139031}}
{"text":"This paper studies the utility of techniques within uncertainty quantification, namely spectral projection and polynomial chaos expansion, in reducing sampling needs for characterizing acoustic metamaterial dispersion band responses given stochastic material properties and geometric defects.","meta":{"url":"http://arxiv.org/abs/2310.12869v1"},"cats":{"benchmark":0.3781065357,"new-dataset":0.0225280233,"data-annotation":0.4956441914,"dev-research":0.1666554367,"llms":0.4460598446,"data-quality":0.2084006253}}
{"text":"A novel method of encoding geometric defects in an interpretable, resolution independent is showcased in the formation of input space probability distributions.","meta":{"url":"http://arxiv.org/abs/2310.12869v1"},"cats":{"benchmark":0.2976588332,"new-dataset":0.0265758905,"data-annotation":0.5222408058,"dev-research":0.2674875286,"llms":0.4128690441,"data-quality":0.3454894613}}
{"text":"Orders of magnitude sampling reductions down to $\\sim10^0$ and $\\sim10^1$ are achieved in the 1D and 7D input space scenarios respectively while maintaining accurate output space probability distributions through combining Monte Carlo, quadrature rule, and sparse grid sampling with surrogate model fitting.","meta":{"url":"http://arxiv.org/abs/2310.12869v1"},"cats":{"benchmark":0.5563994393,"new-dataset":0.0339058592,"data-annotation":0.5036307508,"dev-research":0.1086190083,"llms":0.4730082249,"data-quality":0.0990455936}}
{"text":"Large-scale, big-variant, and high-quality data are crucial for developing robust and successful deep-learning models for medical applications since they potentially enable better generalization performance and avoid overfitting.","meta":{"url":"http://arxiv.org/abs/2310.12868v1"},"cats":{"benchmark":0.3233868527,"new-dataset":0.2240689195,"data-annotation":0.4960475698,"dev-research":0.1615083825,"llms":0.4572882599,"data-quality":0.1025943903}}
{"text":"However, the scarcity of high-quality labeled data always presents significant challenges.","meta":{"url":"http://arxiv.org/abs/2310.12868v1"},"cats":{"benchmark":0.3732758103,"new-dataset":0.3152737172,"data-annotation":0.4748291488,"dev-research":0.2206540124,"llms":0.4843537441,"data-quality":0.5703467779}}
{"text":"This paper proposes a novel approach to address this challenge by developing controllable diffusion models for medical image synthesis, called EMIT-Diff.","meta":{"url":"http://arxiv.org/abs/2310.12868v1"},"cats":{"benchmark":0.3907466823,"new-dataset":0.1360171602,"data-annotation":0.484521945,"dev-research":0.1929495634,"llms":0.4149382313,"data-quality":0.0722207534}}
{"text":"We leverage recent diffusion probabilistic models to generate realistic and diverse synthetic medical image data that preserve the essential characteristics of the original medical images by incorporating edge information of objects to guide the synthesis process.","meta":{"url":"http://arxiv.org/abs/2310.12868v1"},"cats":{"benchmark":0.2962807916,"new-dataset":0.2606614368,"data-annotation":0.4900764871,"dev-research":0.1670546963,"llms":0.4255648027,"data-quality":0.0843945533}}
{"text":"In our approach, we ensure that the synthesized samples adhere to medically relevant constraints and preserve the underlying structure of imaging data.","meta":{"url":"http://arxiv.org/abs/2310.12868v1"},"cats":{"benchmark":0.3806228102,"new-dataset":0.2901898637,"data-annotation":0.4665053066,"dev-research":0.1868061014,"llms":0.4406263017,"data-quality":0.1129631838}}
{"text":"Due to the random sampling process by the diffusion model, we can generate an arbitrary number of synthetic images with diverse appearances.","meta":{"url":"http://arxiv.org/abs/2310.12868v1"},"cats":{"benchmark":0.2194705104,"new-dataset":0.3345960462,"data-annotation":0.5075741421,"dev-research":0.1049600404,"llms":0.4702483082,"data-quality":0.0820304404}}
{"text":"To validate the effectiveness of our proposed method, we conduct an extensive set of medical image segmentation experiments on multiple datasets, including Ultrasound breast (+13.87%), CT spleen (+0.38%), and MRI prostate (+7.78%), achieving significant improvements over the baseline segmentation methods.","meta":{"url":"http://arxiv.org/abs/2310.12868v1"},"cats":{"benchmark":0.5354608843,"new-dataset":0.236553148,"data-annotation":0.4950962935,"dev-research":0.1406355914,"llms":0.4356049592,"data-quality":0.1496698225}}
{"text":"For the first time, to our best knowledge, the promising results demonstrate the effectiveness of our EMIT-Diff for medical image segmentation tasks and show the feasibility of introducing a first-ever text-guided diffusion model for general medical image segmentation tasks.","meta":{"url":"http://arxiv.org/abs/2310.12868v1"},"cats":{"benchmark":0.4410035322,"new-dataset":0.1102346734,"data-annotation":0.4904876422,"dev-research":0.1398741229,"llms":0.4524030189,"data-quality":0.127407093}}
{"text":"With carefully designed ablation experiments, we investigate the influence of various data augmentation ratios, hyper-parameter settings, patch size for generating random merging mask settings, and combined influence with different network architectures.","meta":{"url":"http://arxiv.org/abs/2310.12868v1"},"cats":{"benchmark":0.482423519,"new-dataset":0.0570339293,"data-annotation":0.4770186664,"dev-research":0.1490037201,"llms":0.4581837516,"data-quality":0.1948098635}}
{"text":"Positional Encodings (PEs) are used to inject word-order information into transformer-based language models.","meta":{"url":"http://arxiv.org/abs/2310.12864v1"},"cats":{"benchmark":0.2717919791,"new-dataset":0.0229612014,"data-annotation":0.5218545555,"dev-research":0.1415305417,"llms":0.5481188232,"data-quality":0.1567129757}}
{"text":"While they can significantly enhance the quality of sentence representations, their specific contribution to language models is not fully understood, especially given recent findings that various positional encodings are insensitive to word order.","meta":{"url":"http://arxiv.org/abs/2310.12864v1"},"cats":{"benchmark":0.2950159978,"new-dataset":0.0147541629,"data-annotation":0.5579978381,"dev-research":0.2108240355,"llms":0.5554458822,"data-quality":0.2797892232}}
{"text":"In this work, we conduct a systematic study of positional encodings in \\textbf{Bidirectional Masked Language Models} (BERT-style) , which complements existing work in three aspects: (1) We uncover the core function of PEs by identifying two common properties, Locality and Symmetry; (2) We show that the two properties are closely correlated with the performances of downstream tasks; (3) We quantify the weakness of current PEs by introducing two new probing tasks, on which current PEs perform poorly.","meta":{"url":"http://arxiv.org/abs/2310.12864v1"},"cats":{"benchmark":0.3444882952,"new-dataset":0.0203447977,"data-annotation":0.5488570616,"dev-research":0.1602330388,"llms":0.5029500293,"data-quality":0.232040793}}
{"text":"We believe that these results are the basis for developing better PEs for transformer-based language models.","meta":{"url":"http://arxiv.org/abs/2310.12864v1"},"cats":{"benchmark":0.2970887883,"new-dataset":0.0264810848,"data-annotation":0.5325090791,"dev-research":0.194631054,"llms":0.5348492122,"data-quality":0.1834163781}}
{"text":"The code is available at \\faGithub~ \\url{https://github.com/tigerchen52/locality\\_symmetry}","meta":{"url":"http://arxiv.org/abs/2310.12864v1"},"cats":{"benchmark":0.3505395375,"new-dataset":0.1210740964,"data-annotation":0.5339937433,"dev-research":0.1552427893,"llms":0.532681672,"data-quality":0.1405184485}}
{"text":"Adaptable models could greatly benefit robotic agents operating in the real world, allowing them to deal with novel and varying conditions.","meta":{"url":"http://arxiv.org/abs/2310.12862v1"},"cats":{"benchmark":0.2274361433,"new-dataset":0.0097128689,"data-annotation":0.5069704243,"dev-research":0.1737172979,"llms":0.4881305607,"data-quality":0.0384226124}}
{"text":"While approaches such as Bayesian inference are well-studied frameworks for adapting models to evidence, we build on recent advances in deep generative models which have greatly affected many areas of robotics.","meta":{"url":"http://arxiv.org/abs/2310.12862v1"},"cats":{"benchmark":0.2422609757,"new-dataset":0.1010403541,"data-annotation":0.5103006933,"dev-research":0.1965044874,"llms":0.5487668871,"data-quality":0.114014057}}
{"text":"Harnessing modern GPU acceleration, we investigate how to quickly adapt the sample generation of neural network models to observations in robotic tasks.","meta":{"url":"http://arxiv.org/abs/2310.12862v1"},"cats":{"benchmark":0.3427340146,"new-dataset":0.0942525342,"data-annotation":0.5160055244,"dev-research":0.1856397777,"llms":0.4815835756,"data-quality":0.0790327102}}
{"text":"We propose a simple and general method that is applicable to various deep generative models and robotic environments.","meta":{"url":"http://arxiv.org/abs/2310.12862v1"},"cats":{"benchmark":0.2147087962,"new-dataset":0.0305350661,"data-annotation":0.5275839331,"dev-research":0.1417357033,"llms":0.5129925565,"data-quality":0.107526296}}
{"text":"The key idea is to quickly fine-tune the model by fitting it to generated samples matching the observed evidence, using the cross-entropy method.","meta":{"url":"http://arxiv.org/abs/2310.12862v1"},"cats":{"benchmark":0.5761006038,"new-dataset":0.0585764302,"data-annotation":0.5372029241,"dev-research":0.1433836362,"llms":0.4492072296,"data-quality":0.1606461992}}
{"text":"We show that our method can be applied to both autoregressive models and variational autoencoders, and demonstrate its usability in object shape inference from grasping, inverse kinematics calculation, and point cloud completion.","meta":{"url":"http://arxiv.org/abs/2310.12862v1"},"cats":{"benchmark":0.2767391313,"new-dataset":0.0735934145,"data-annotation":0.5246233841,"dev-research":0.1501967575,"llms":0.4055751836,"data-quality":0.0608936183}}
{"text":"Recently efforts have been made by social media platforms as well as researchers to detect hateful or toxic language using large language models.","meta":{"url":"http://arxiv.org/abs/2310.12860v1"},"cats":{"benchmark":0.2848021067,"new-dataset":0.1002122567,"data-annotation":0.5547196824,"dev-research":0.2597843526,"llms":0.5486169091,"data-quality":0.3314131647}}
{"text":"However, none of these works aim to use explanation, additional context and victim community information in the detection process.","meta":{"url":"http://arxiv.org/abs/2310.12860v1"},"cats":{"benchmark":0.2494093233,"new-dataset":0.0145465102,"data-annotation":0.5320209152,"dev-research":0.2130058238,"llms":0.5329992092,"data-quality":0.2657561914}}
{"text":"We utilise different prompt variation, input information and evaluate large language models in zero shot setting (without adding any in-context examples).","meta":{"url":"http://arxiv.org/abs/2310.12860v1"},"cats":{"benchmark":0.2797019089,"new-dataset":0.1899468401,"data-annotation":0.5548710441,"dev-research":0.149030997,"llms":0.5338061683,"data-quality":0.2037698549}}
{"text":"We select three large language models (GPT-3.5, text-davinci and Flan-T5) and three datasets - HateXplain, implicit hate and ToxicSpans.","meta":{"url":"http://arxiv.org/abs/2310.12860v1"},"cats":{"benchmark":0.2849289027,"new-dataset":0.5603824076,"data-annotation":0.5383964832,"dev-research":0.1697800337,"llms":0.516674936,"data-quality":0.2890826942}}
{"text":"We find that on average including the target information in the pipeline improves the model performance substantially (~20-30%) over the baseline across the datasets.","meta":{"url":"http://arxiv.org/abs/2310.12860v1"},"cats":{"benchmark":0.6119277773,"new-dataset":0.0436026606,"data-annotation":0.4744527612,"dev-research":0.2042359013,"llms":0.4058477421,"data-quality":0.1362795456}}
{"text":"There is also a considerable effect of adding the rationales/explanations into the pipeline (~10-20%) over the baseline across the datasets.","meta":{"url":"http://arxiv.org/abs/2310.12860v1"},"cats":{"benchmark":0.4938892593,"new-dataset":0.0637020602,"data-annotation":0.4905194261,"dev-research":0.3053800157,"llms":0.4390268978,"data-quality":0.2024558852}}
{"text":"In addition, we further provide a typology of the error cases where these large language models fail to (i) classify and (ii) explain the reason for the decisions they take.","meta":{"url":"http://arxiv.org/abs/2310.12860v1"},"cats":{"benchmark":0.3620865241,"new-dataset":0.035297572,"data-annotation":0.5648670744,"dev-research":0.2612003584,"llms":0.4994688777,"data-quality":0.4811726973}}
{"text":"Such vulnerable points automatically constitute 'jailbreak' prompts for these models and industry scale safeguard techniques need to be developed to make the models robust against such prompts.","meta":{"url":"http://arxiv.org/abs/2310.12860v1"},"cats":{"benchmark":0.2655479675,"new-dataset":0.0442211445,"data-annotation":0.4955333187,"dev-research":0.3037847972,"llms":0.5113186371,"data-quality":0.1753804744}}
{"text":"In this paper, we explore audio-editing with non-rigid text edits.","meta":{"url":"http://arxiv.org/abs/2310.12858v1"},"cats":{"benchmark":0.3872993377,"new-dataset":0.0492254047,"data-annotation":0.5224708463,"dev-research":0.2005415423,"llms":0.4569130133,"data-quality":0.2161301516}}
{"text":"We show that the proposed editing pipeline is able to create audio edits that remain faithful to the input audio.","meta":{"url":"http://arxiv.org/abs/2310.12858v1"},"cats":{"benchmark":0.334675215,"new-dataset":0.0372821086,"data-annotation":0.4886843908,"dev-research":0.25545066,"llms":0.5235832126,"data-quality":0.2039963615}}
{"text":"We explore text prompts that perform addition, style transfer, and in-painting.","meta":{"url":"http://arxiv.org/abs/2310.12858v1"},"cats":{"benchmark":0.2007004254,"new-dataset":0.0730502023,"data-annotation":0.5335245572,"dev-research":0.3361899999,"llms":0.5811982684,"data-quality":0.1456933238}}
{"text":"We quantitatively and qualitatively show that the edits are able to obtain results which outperform Audio-LDM, a recently released text-prompted audio generation model.","meta":{"url":"http://arxiv.org/abs/2310.12858v1"},"cats":{"benchmark":0.3890470995,"new-dataset":0.0488039421,"data-annotation":0.5254018682,"dev-research":0.2060121626,"llms":0.5526513533,"data-quality":0.3310445934}}
{"text":"Qualitative inspection of the results points out that the edits given by our approach remain more faithful to the input audio in terms of keeping the original onsets and offsets of the audio events.","meta":{"url":"http://arxiv.org/abs/2310.12858v1"},"cats":{"benchmark":0.5315798191,"new-dataset":0.0308260959,"data-annotation":0.5158040503,"dev-research":0.2683776455,"llms":0.4595361883,"data-quality":0.3421716541}}
{"text":"In the era of advanced artificial intelligence and human-computer interaction, identifying emotions in spoken language is paramount.","meta":{"url":"http://arxiv.org/abs/2310.12851v1"},"cats":{"benchmark":0.2705497378,"new-dataset":0.0984024981,"data-annotation":0.5540482598,"dev-research":0.2424245941,"llms":0.495311626,"data-quality":0.168359963}}
{"text":"This research explores the integration of deep learning techniques in speech emotion recognition, offering a comprehensive solution to the challenges associated with speaker diarization and emotion identification.","meta":{"url":"http://arxiv.org/abs/2310.12851v1"},"cats":{"benchmark":0.3062763835,"new-dataset":0.1298764042,"data-annotation":0.5308227284,"dev-research":0.1729371739,"llms":0.488194158,"data-quality":0.230092105}}
{"text":"It introduces a framework that combines a pre-existing speaker diarization pipeline and an emotion identification model built on a Convolutional Neural Network (CNN) to achieve higher precision.","meta":{"url":"http://arxiv.org/abs/2310.12851v1"},"cats":{"benchmark":0.3546339906,"new-dataset":0.2890949235,"data-annotation":0.5356915454,"dev-research":0.173802064,"llms":0.451458046,"data-quality":0.1854977146}}
{"text":"The proposed model was trained on data from five speech emotion datasets, namely, RAVDESS, CREMA-D, SAVEE, TESS, and Movie Clips, out of which the latter is a speech emotion dataset created specifically for this research.","meta":{"url":"http://arxiv.org/abs/2310.12851v1"},"cats":{"benchmark":0.2107924995,"new-dataset":0.6997817135,"data-annotation":0.5289513342,"dev-research":0.1720215219,"llms":0.4878184491,"data-quality":0.1533210835}}
{"text":"The features extracted from each sample include Mel Frequency Cepstral Coefficients (MFCC), Zero Crossing Rate (ZCR), Root Mean Square (RMS), and various data augmentation algorithms like pitch, noise, stretch, and shift.","meta":{"url":"http://arxiv.org/abs/2310.12851v1"},"cats":{"benchmark":0.4526823381,"new-dataset":0.3190987082,"data-annotation":0.5054148435,"dev-research":0.110242656,"llms":0.4572397826,"data-quality":0.154734693}}
{"text":"This feature extraction approach aims to enhance prediction accuracy while reducing computational complexity.","meta":{"url":"http://arxiv.org/abs/2310.12851v1"},"cats":{"benchmark":0.4661384949,"new-dataset":0.0359109279,"data-annotation":0.5331504728,"dev-research":0.2429196328,"llms":0.3130770103,"data-quality":0.16182836}}
{"text":"The proposed model yields an unweighted accuracy of 63%, demonstrating remarkable efficiency in accurately identifying emotional states within speech signals.","meta":{"url":"http://arxiv.org/abs/2310.12851v1"},"cats":{"benchmark":0.4831022646,"new-dataset":0.0273875638,"data-annotation":0.5432425598,"dev-research":0.1568404885,"llms":0.4302660585,"data-quality":0.2234844353}}
{"text":"Existing methods have demonstrated effective performance on a single degradation type.","meta":{"url":"http://arxiv.org/abs/2310.12848v1"},"cats":{"benchmark":0.7283461153,"new-dataset":0.0065182188,"data-annotation":0.5111778068,"dev-research":0.2294291998,"llms":0.4915019848,"data-quality":0.1900358169}}
{"text":"In practical applications, however, the degradation is often unknown, and the mismatch between the model and the degradation will result in a severe performance drop.","meta":{"url":"http://arxiv.org/abs/2310.12848v1"},"cats":{"benchmark":0.6029020964,"new-dataset":0.0028368951,"data-annotation":0.5245319156,"dev-research":0.242260019,"llms":0.4351622457,"data-quality":0.2805157644}}
{"text":"In this paper, we propose an all-in-one image restoration network that tackles multiple degradations.","meta":{"url":"http://arxiv.org/abs/2310.12848v1"},"cats":{"benchmark":0.4745193745,"new-dataset":0.07626664,"data-annotation":0.5006460748,"dev-research":0.1620929814,"llms":0.4270311783,"data-quality":0.1964462346}}
{"text":"Due to the heterogeneous nature of different types of degradations, it is difficult to process multiple degradations in a single network.","meta":{"url":"http://arxiv.org/abs/2310.12848v1"},"cats":{"benchmark":0.4882168131,"new-dataset":0.0052608728,"data-annotation":0.5036032366,"dev-research":0.1940754608,"llms":0.4307660437,"data-quality":0.1690948005}}
{"text":"To this end, we propose to learn a neural degradation representation (NDR) that captures the underlying characteristics of various degradations.","meta":{"url":"http://arxiv.org/abs/2310.12848v1"},"cats":{"benchmark":0.3492004322,"new-dataset":0.0988741306,"data-annotation":0.5288034392,"dev-research":0.2346707098,"llms":0.4589453221,"data-quality":0.3015353858}}
{"text":"The learned NDR decomposes different types of degradations adaptively, similar to a neural dictionary that represents basic degradation components.","meta":{"url":"http://arxiv.org/abs/2310.12848v1"},"cats":{"benchmark":0.2985828108,"new-dataset":0.0546798382,"data-annotation":0.5155418068,"dev-research":0.2135025538,"llms":0.5004524023,"data-quality":0.2715498824}}
{"text":"Subsequently, we develop a degradation query module and a degradation injection module to effectively recognize and utilize the specific degradation based on NDR, enabling the all-in-one restoration ability for multiple degradations.","meta":{"url":"http://arxiv.org/abs/2310.12848v1"},"cats":{"benchmark":0.4880421424,"new-dataset":0.0619569945,"data-annotation":0.4837203111,"dev-research":0.2431412085,"llms":0.5292344759,"data-quality":0.2707439187}}
{"text":"Moreover, we propose a bidirectional optimization strategy to effectively drive NDR to learn the degradation representation by optimizing the degradation and restoration processes alternately.","meta":{"url":"http://arxiv.org/abs/2310.12848v1"},"cats":{"benchmark":0.4975262577,"new-dataset":0.018367011,"data-annotation":0.4982024991,"dev-research":0.2586458928,"llms":0.4511297708,"data-quality":0.1991408333}}
{"text":"Comprehensive experiments on representative types of degradations (including noise, haze, rain, and downsampling) demonstrate the effectiveness and generalization capability of our method.","meta":{"url":"http://arxiv.org/abs/2310.12848v1"},"cats":{"benchmark":0.5917281599,"new-dataset":0.069564825,"data-annotation":0.5228737863,"dev-research":0.2944199014,"llms":0.440981372,"data-quality":0.2304116327}}
{"text":"Recent Language Models (LMs) have shown impressive capabilities in generating texts with the knowledge internalized in parameters.","meta":{"url":"http://arxiv.org/abs/2310.12836v1"},"cats":{"benchmark":0.2329670415,"new-dataset":0.0793539747,"data-annotation":0.5429200235,"dev-research":0.1613517995,"llms":0.594875268,"data-quality":0.1853570622}}
{"text":"Yet, LMs often generate the factually incorrect responses to the given queries, since their knowledge may be inaccurate, incomplete, and outdated.","meta":{"url":"http://arxiv.org/abs/2310.12836v1"},"cats":{"benchmark":0.3217008867,"new-dataset":0.0175980412,"data-annotation":0.4983157135,"dev-research":0.2268510744,"llms":0.6527780415,"data-quality":0.3681440766}}
{"text":"To address this problem, previous works propose to augment LMs with the knowledge retrieved from an external knowledge source.","meta":{"url":"http://arxiv.org/abs/2310.12836v1"},"cats":{"benchmark":0.2908482823,"new-dataset":0.1364598179,"data-annotation":0.4969081465,"dev-research":0.1385027779,"llms":0.6170467153,"data-quality":0.186142487}}
{"text":"However, such approaches often show suboptimal text generation performance due to two reasons: 1) the model may fail to retrieve the knowledge relevant to the given query, or 2) the model may not faithfully reflect the retrieved knowledge in the generated text.","meta":{"url":"http://arxiv.org/abs/2310.12836v1"},"cats":{"benchmark":0.430658188,"new-dataset":0.0068983942,"data-annotation":0.525503846,"dev-research":0.1630655661,"llms":0.5173798578,"data-quality":0.1861798359}}
{"text":"To overcome these, we propose to verify the output and the knowledge of the knowledge-augmented LMs with a separate verifier, which is a small LM that is trained to detect those two types of errors through instruction-finetuning.","meta":{"url":"http://arxiv.org/abs/2310.12836v1"},"cats":{"benchmark":0.3700248677,"new-dataset":0.0362292634,"data-annotation":0.5100773789,"dev-research":0.2776219603,"llms":0.6397563931,"data-quality":0.3755709078}}
{"text":"Then, when the verifier recognizes an error, we can rectify it by either retrieving new knowledge or generating new text.","meta":{"url":"http://arxiv.org/abs/2310.12836v1"},"cats":{"benchmark":0.2641154985,"new-dataset":0.0255923564,"data-annotation":0.5139562702,"dev-research":0.4434117509,"llms":0.6155790993,"data-quality":0.5038371749}}
{"text":"Further, we use an ensemble of the outputs from different instructions with a single verifier to enhance the reliability of the verification processes.","meta":{"url":"http://arxiv.org/abs/2310.12836v1"},"cats":{"benchmark":0.5104228165,"new-dataset":0.0364803382,"data-annotation":0.503850266,"dev-research":0.2648477156,"llms":0.5742868126,"data-quality":0.2325247057}}
{"text":"We validate the effectiveness of the proposed verification steps on multiple question answering benchmarks, whose results show that the proposed verifier effectively identifies retrieval and generation errors, allowing LMs to provide more factually correct outputs.","meta":{"url":"http://arxiv.org/abs/2310.12836v1"},"cats":{"benchmark":0.5258210139,"new-dataset":0.0613192355,"data-annotation":0.5142038946,"dev-research":0.1991532818,"llms":0.644599399,"data-quality":0.2338615543}}
{"text":"Our code is available at https://github.com/JinheonBaek/KALMV.","meta":{"url":"http://arxiv.org/abs/2310.12836v1"},"cats":{"benchmark":0.2833115943,"new-dataset":0.2878601554,"data-annotation":0.5413063887,"dev-research":0.1505083426,"llms":0.4740070457,"data-quality":0.0886823433}}
{"text":"All-digital massive multiuser (MU) multiple-input multiple-output (MIMO) at millimeter-wave (mmWave) frequencies is a promising technology for next-generation wireless systems.","meta":{"url":"http://arxiv.org/abs/2310.12835v1"},"cats":{"benchmark":0.307761744,"new-dataset":0.0142190545,"data-annotation":0.4833045342,"dev-research":0.1386004105,"llms":0.5481401919,"data-quality":0.0448895663}}
{"text":"Low-resolution analog-to-digital converters (ADCs) can be utilized to reduce the power consumption of all-digital basestation (BS) designs.","meta":{"url":"http://arxiv.org/abs/2310.12835v1"},"cats":{"benchmark":0.4463679749,"new-dataset":0.0155382484,"data-annotation":0.4943461798,"dev-research":0.2619565776,"llms":0.5642622911,"data-quality":0.0985031696}}
{"text":"However, simultaneously transmitting user equipments (UEs) with vastly different BS-side receive powers either drown weak UEs in quantization noise or saturate the ADCs.","meta":{"url":"http://arxiv.org/abs/2310.12835v1"},"cats":{"benchmark":0.3714826361,"new-dataset":0.0056572165,"data-annotation":0.4907852165,"dev-research":0.1788678071,"llms":0.5347967335,"data-quality":0.1470357856}}
{"text":"To address this issue, we propose high dynamic range (HDR) MIMO, a new paradigm that enables simultaneous reception of strong and weak UEs with low-resolution ADCs.","meta":{"url":"http://arxiv.org/abs/2310.12835v1"},"cats":{"benchmark":0.4007468638,"new-dataset":0.0358573778,"data-annotation":0.4772119873,"dev-research":0.1544710041,"llms":0.527427746,"data-quality":0.0749202615}}
{"text":"HDR MIMO combines an adaptive analog spatial transform with digital equalization:","meta":{"url":"http://arxiv.org/abs/2310.12835v1"},"cats":{"benchmark":0.4519068961,"new-dataset":0.013070608,"data-annotation":0.4733724721,"dev-research":0.1489745456,"llms":0.5075789338,"data-quality":0.1025016969}}
{"text":"The spatial transform focuses strong UEs on a subset of ADCs in order to mitigate quantization and saturation artifacts; digital equalization is then used for data detection.","meta":{"url":"http://arxiv.org/abs/2310.12835v1"},"cats":{"benchmark":0.4146905782,"new-dataset":0.022999521,"data-annotation":0.47825175,"dev-research":0.1652603338,"llms":0.4951678586,"data-quality":0.1740709557}}
{"text":"We demonstrate the efficacy of HDR MIMO in a massive MU-MIMO mmWave scenario that uses Householder reflections as spatial transform.","meta":{"url":"http://arxiv.org/abs/2310.12835v1"},"cats":{"benchmark":0.3867165164,"new-dataset":0.0150318798,"data-annotation":0.4882360526,"dev-research":0.1707207074,"llms":0.5191251317,"data-quality":0.0449115173}}
{"text":"Imitation Learning (IL) is a powerful technique for intuitive robotic programming.","meta":{"url":"http://arxiv.org/abs/2310.12831v1"},"cats":{"benchmark":0.2187014139,"new-dataset":0.0116642229,"data-annotation":0.5120523991,"dev-research":0.1896028712,"llms":0.4929228477,"data-quality":0.0810774519}}
{"text":"However, ensuring the reliability of learned behaviors remains a challenge.","meta":{"url":"http://arxiv.org/abs/2310.12831v1"},"cats":{"benchmark":0.2347923497,"new-dataset":0.0259330115,"data-annotation":0.5029200689,"dev-research":0.2544879805,"llms":0.5516432736,"data-quality":0.2132349592}}
{"text":"In the context of reaching motions, a robot should consistently reach its goal, regardless of its initial conditions.","meta":{"url":"http://arxiv.org/abs/2310.12831v1"},"cats":{"benchmark":0.2791521565,"new-dataset":0.006297286,"data-annotation":0.4690062794,"dev-research":0.2170124786,"llms":0.4765184357,"data-quality":0.0875465366}}
{"text":"To meet this requirement, IL methods often employ specialized function approximators that guarantee this property by construction.","meta":{"url":"http://arxiv.org/abs/2310.12831v1"},"cats":{"benchmark":0.5418064453,"new-dataset":0.0060005624,"data-annotation":0.527839504,"dev-research":0.217090994,"llms":0.3742941131,"data-quality":0.1290598417}}
{"text":"Although effective, these approaches come with a set of limitations: 1) they are unable to fully exploit the capabilities of modern Deep Neural Network (DNN) architectures, 2) some are restricted in the family of motions they can model, resulting in suboptimal IL capabilities, and 3) they require explicit extensions to account for the geometry of motions that consider orientations.","meta":{"url":"http://arxiv.org/abs/2310.12831v1"},"cats":{"benchmark":0.3219827549,"new-dataset":0.0089961329,"data-annotation":0.5233851483,"dev-research":0.1450985045,"llms":0.4645906563,"data-quality":0.0585804499}}
{"text":"To address these challenges, we introduce a novel stability loss function, drawing inspiration from the triplet loss used in the deep metric learning literature.","meta":{"url":"http://arxiv.org/abs/2310.12831v1"},"cats":{"benchmark":0.4550015867,"new-dataset":0.1529221823,"data-annotation":0.5283891169,"dev-research":0.1497374701,"llms":0.4256568155,"data-quality":0.2008584111}}
{"text":"This loss does not constrain the DNN's architecture and enables learning policies that yield accurate results.","meta":{"url":"http://arxiv.org/abs/2310.12831v1"},"cats":{"benchmark":0.3203851963,"new-dataset":0.0081071558,"data-annotation":0.5208506227,"dev-research":0.1698338222,"llms":0.500871743,"data-quality":0.2435245685}}
{"text":"Furthermore, it is easily adaptable to the geometry of the robot's state space.","meta":{"url":"http://arxiv.org/abs/2310.12831v1"},"cats":{"benchmark":0.2976993792,"new-dataset":0.0037953013,"data-annotation":0.5127822453,"dev-research":0.1244835863,"llms":0.518767424,"data-quality":0.038524661}}
{"text":"We provide a proof of the stability properties induced by this loss and empirically validate our method in various settings.","meta":{"url":"http://arxiv.org/abs/2310.12831v1"},"cats":{"benchmark":0.6841927316,"new-dataset":0.0062715272,"data-annotation":0.5452946677,"dev-research":0.1092578273,"llms":0.376255584,"data-quality":0.2125343514}}
{"text":"These settings include Euclidean and non-Euclidean state spaces, as well as first-order and second-order motions, both in simulation and with real robots.","meta":{"url":"http://arxiv.org/abs/2310.12831v1"},"cats":{"benchmark":0.2423204206,"new-dataset":0.0639221398,"data-annotation":0.5028146393,"dev-research":0.137387949,"llms":0.4430923085,"data-quality":0.045795531}}
{"text":"More details about the experimental results can be found at: https://youtu.be/ZWKLGntCI6w.","meta":{"url":"http://arxiv.org/abs/2310.12831v1"},"cats":{"benchmark":0.4493988331,"new-dataset":0.1029812895,"data-annotation":0.5362321209,"dev-research":0.1000446405,"llms":0.534082151,"data-quality":0.1348707418}}
{"text":"In modern approaches to path planning and robot motion planning, anytime almost-surely asymptotically optimal planners dominate the benchmark of sample-based planners.","meta":{"url":"http://arxiv.org/abs/2310.12828v1"},"cats":{"benchmark":0.4192541426,"new-dataset":0.0290840854,"data-annotation":0.5136625126,"dev-research":0.2019364629,"llms":0.4536050342,"data-quality":0.0426626436}}
{"text":"A notable example is Batch Informed Trees (BIT*), where planners iteratively determine paths to groups of vertices within the exploration area.","meta":{"url":"http://arxiv.org/abs/2310.12828v1"},"cats":{"benchmark":0.2640566834,"new-dataset":0.0508371738,"data-annotation":0.512554077,"dev-research":0.2549237279,"llms":0.5207574719,"data-quality":0.0963649609}}
{"text":"However, maintaining a consistent batch size is crucial for initial pathfinding and optimal performance, relying on effective task allocation.","meta":{"url":"http://arxiv.org/abs/2310.12828v1"},"cats":{"benchmark":0.4740795422,"new-dataset":0.0074591951,"data-annotation":0.4869625796,"dev-research":0.2058664825,"llms":0.5026771027,"data-quality":0.08426533}}
{"text":"This paper introduces Flexible Informed Tree (FIT*), a novel planner integrating an adaptive batch-size method to enhance task scheduling in various environments.","meta":{"url":"http://arxiv.org/abs/2310.12828v1"},"cats":{"benchmark":0.3265107418,"new-dataset":0.0248107259,"data-annotation":0.4836799471,"dev-research":0.2552308627,"llms":0.4725064113,"data-quality":0.0618285293}}
{"text":"FIT* employs a flexible approach in adjusting batch sizes dynamically based on the inherent complexity of the planning domain and the current n-dimensional hyperellipsoid of the system.","meta":{"url":"http://arxiv.org/abs/2310.12828v1"},"cats":{"benchmark":0.3837125743,"new-dataset":0.0094849847,"data-annotation":0.4781548913,"dev-research":0.1886132734,"llms":0.4039058295,"data-quality":0.0734847768}}
{"text":"By constantly optimizing batch sizes, FIT* achieves improved computational efficiency and scalability while maintaining solution quality.","meta":{"url":"http://arxiv.org/abs/2310.12828v1"},"cats":{"benchmark":0.4760589254,"new-dataset":0.016587494,"data-annotation":0.4914333745,"dev-research":0.2374517322,"llms":0.4649517163,"data-quality":0.1282036917}}
{"text":"This adaptive batch-size method significantly enhances the planner's ability to handle diverse and evolving problem domains.","meta":{"url":"http://arxiv.org/abs/2310.12828v1"},"cats":{"benchmark":0.3069368764,"new-dataset":0.0224202288,"data-annotation":0.4853918652,"dev-research":0.3275413535,"llms":0.501920919,"data-quality":0.0744927539}}
{"text":"FIT* outperforms existing single-query, sampling-based planners on the tested problems in R^2 to R^8, and was demonstrated in real-world environments with KI-Fabrik/DARKO-Project Europe.","meta":{"url":"http://arxiv.org/abs/2310.12828v1"},"cats":{"benchmark":0.3876445686,"new-dataset":0.1027976833,"data-annotation":0.4923971998,"dev-research":0.2043068585,"llms":0.4361137769,"data-quality":0.0679759759}}
{"text":"We consider the problem of the private release of statistics (like aggregate payrolls) where it is critical to preserve the contribution made by a small number of outlying large entities.","meta":{"url":"http://arxiv.org/abs/2310.12827v1"},"cats":{"benchmark":0.3654630579,"new-dataset":0.1199641423,"data-annotation":0.5091813608,"dev-research":0.1878286799,"llms":0.4428663472,"data-quality":0.1759485326}}
{"text":"We propose a privacy formalism, per-record zero concentrated differential privacy (PzCDP), where the privacy loss associated with each record is a public function of that record's value.","meta":{"url":"http://arxiv.org/abs/2310.12827v1"},"cats":{"benchmark":0.2874895644,"new-dataset":0.1085590888,"data-annotation":0.4766841644,"dev-research":0.1085999548,"llms":0.5431987916,"data-quality":0.1590353184}}
{"text":"Unlike other formalisms which provide different privacy losses to different records, PzCDP's privacy loss depends explicitly on the confidential data.","meta":{"url":"http://arxiv.org/abs/2310.12827v1"},"cats":{"benchmark":0.3320874498,"new-dataset":0.0092090229,"data-annotation":0.4845195317,"dev-research":0.1434885101,"llms":0.4921123187,"data-quality":0.1495156049}}
{"text":"We define our formalism, derive its properties, and propose mechanisms which satisfy PzCDP that are uniquely suited to publishing skewed or heavy-tailed statistics, where a small number of records contribute substantially to query answers.","meta":{"url":"http://arxiv.org/abs/2310.12827v1"},"cats":{"benchmark":0.4437164331,"new-dataset":0.0593411859,"data-annotation":0.5055777029,"dev-research":0.151616233,"llms":0.520275596,"data-quality":0.115773372}}
{"text":"This targeted relaxation helps overcome the difficulties of applying standard DP to these data products.","meta":{"url":"http://arxiv.org/abs/2310.12827v1"},"cats":{"benchmark":0.4549603019,"new-dataset":0.0174399919,"data-annotation":0.4371907964,"dev-research":0.2534017363,"llms":0.4888715176,"data-quality":0.1514676164}}
{"text":"Open large language models (LLMs) with great performance in various tasks have significantly advanced the development of LLMs.","meta":{"url":"http://arxiv.org/abs/2310.12823v1"},"cats":{"benchmark":0.3008008628,"new-dataset":0.1375107162,"data-annotation":0.53241371,"dev-research":0.1405088949,"llms":0.7154095549,"data-quality":0.1019300558}}
{"text":"However, they are far inferior to commercial models such as ChatGPT and GPT-4 when acting as agents to tackle complex tasks in the real world.","meta":{"url":"http://arxiv.org/abs/2310.12823v1"},"cats":{"benchmark":0.2808766193,"new-dataset":0.0191876571,"data-annotation":0.5161410828,"dev-research":0.2448330803,"llms":0.5340569101,"data-quality":0.0699437435}}
{"text":"These agent tasks employ LLMs as the central controller responsible for planning, memorization, and tool utilization, necessitating both fine-grained prompting methods and robust LLMs to achieve satisfactory performance.","meta":{"url":"http://arxiv.org/abs/2310.12823v1"},"cats":{"benchmark":0.1750209245,"new-dataset":0.038787239,"data-annotation":0.5018053487,"dev-research":0.2205759348,"llms":0.782545376,"data-quality":0.0715435648}}
{"text":"Though many prompting methods have been proposed to complete particular agent tasks, there is lack of research focusing on improving the agent capabilities of LLMs themselves without compromising their general abilities.","meta":{"url":"http://arxiv.org/abs/2310.12823v1"},"cats":{"benchmark":0.1517982681,"new-dataset":0.0062870606,"data-annotation":0.5210178675,"dev-research":0.1795271717,"llms":0.7878858852,"data-quality":0.0699919867}}
{"text":"In this work, we present AgentTuning, a simple and general method to enhance the agent abilities of LLMs while maintaining their general LLM capabilities.","meta":{"url":"http://arxiv.org/abs/2310.12823v1"},"cats":{"benchmark":0.2070297196,"new-dataset":0.0221806678,"data-annotation":0.5139944821,"dev-research":0.1112822093,"llms":0.7926763244,"data-quality":0.0486558081}}
{"text":"We construct AgentInstruct, a lightweight instruction-tuning dataset containing high-quality interaction trajectories.","meta":{"url":"http://arxiv.org/abs/2310.12823v1"},"cats":{"benchmark":0.2287627563,"new-dataset":0.5795338504,"data-annotation":0.5235614547,"dev-research":0.2675050449,"llms":0.5824158412,"data-quality":0.0626916063}}
{"text":"We employ a hybrid instruction-tuning strategy by combining AgentInstruct with open-source instructions from general domains.","meta":{"url":"http://arxiv.org/abs/2310.12823v1"},"cats":{"benchmark":0.2536649552,"new-dataset":0.0633028498,"data-annotation":0.5272314269,"dev-research":0.2774070835,"llms":0.6216674703,"data-quality":0.0679892983}}
{"text":"AgentTuning is used to instruction-tune the Llama 2 series, resulting in AgentLM.","meta":{"url":"http://arxiv.org/abs/2310.12823v1"},"cats":{"benchmark":0.2129934068,"new-dataset":0.0449719974,"data-annotation":0.5254370177,"dev-research":0.1391880761,"llms":0.6588592235,"data-quality":0.0777804534}}
{"text":"Our evaluations show that AgentTuning enables LLMs' agent capabilities without compromising general abilities.","meta":{"url":"http://arxiv.org/abs/2310.12823v1"},"cats":{"benchmark":0.1832646017,"new-dataset":0.0079687132,"data-annotation":0.5126290201,"dev-research":0.1265533975,"llms":0.7736033634,"data-quality":0.0527528177}}
{"text":"The AgentLM-70B is comparable to GPT-3.5-turbo on unseen agent tasks, demonstrating generalized agent capabilities.","meta":{"url":"http://arxiv.org/abs/2310.12823v1"},"cats":{"benchmark":0.296699887,"new-dataset":0.0451820662,"data-annotation":0.5069882926,"dev-research":0.1266460278,"llms":0.4974819887,"data-quality":0.048742135}}
{"text":"We open source the AgentInstruct and AgentLM-7B, 13B, and 70B models at https://github.com/THUDM/AgentTuning , serving open and powerful alternatives to commercial LLMs for agent tasks.","meta":{"url":"http://arxiv.org/abs/2310.12823v1"},"cats":{"benchmark":0.2112954859,"new-dataset":0.3897956353,"data-annotation":0.5051083082,"dev-research":0.1294691371,"llms":0.7283270048,"data-quality":0.0621852048}}
{"text":"Current gesture recognition systems primarily focus on identifying gestures within a predefined set, leaving a gap in connecting these gestures to interactive GUI elements or system functions (e.g., linking a 'thumb-up' gesture to a 'like' button).","meta":{"url":"http://arxiv.org/abs/2310.12821v1"},"cats":{"benchmark":0.2651077991,"new-dataset":0.0248782115,"data-annotation":0.522958524,"dev-research":0.2483989547,"llms":0.5171054861,"data-quality":0.0898058931}}
{"text":"We introduce GestureGPT, a novel zero-shot gesture understanding and grounding framework leveraging large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2310.12821v1"},"cats":{"benchmark":0.2043124313,"new-dataset":0.5692658303,"data-annotation":0.5466910832,"dev-research":0.1711546014,"llms":0.5836191803,"data-quality":0.1338248257}}
{"text":"Gesture descriptions are formulated based on hand landmark coordinates from gesture videos and fed into our dual-agent dialogue system.","meta":{"url":"http://arxiv.org/abs/2310.12821v1"},"cats":{"benchmark":0.2488166196,"new-dataset":0.4713642449,"data-annotation":0.5490199512,"dev-research":0.1854403379,"llms":0.5012043889,"data-quality":0.0986431916}}
{"text":"A gesture agent deciphers these descriptions and queries about the interaction context (e.g., interface, history, gaze data), which a context agent organizes and provides.","meta":{"url":"http://arxiv.org/abs/2310.12821v1"},"cats":{"benchmark":0.1531361785,"new-dataset":0.4021096633,"data-annotation":0.5231703831,"dev-research":0.2036176432,"llms":0.5176880275,"data-quality":0.0480735317}}
{"text":"Following iterative exchanges, the gesture agent discerns user intent, grounding it to an interactive function.","meta":{"url":"http://arxiv.org/abs/2310.12821v1"},"cats":{"benchmark":0.1938324524,"new-dataset":0.0480032993,"data-annotation":0.5352946442,"dev-research":0.2116820368,"llms":0.5494277751,"data-quality":0.0563839295}}
{"text":"We validated the gesture description module using public first-view and third-view gesture datasets and tested the whole system in two real-world settings: video streaming and smart home IoT control.","meta":{"url":"http://arxiv.org/abs/2310.12821v1"},"cats":{"benchmark":0.237835372,"new-dataset":0.5394691186,"data-annotation":0.5131920137,"dev-research":0.2826934757,"llms":0.5146115403,"data-quality":0.0939186377}}
{"text":"The highest zero-shot Top-5 grounding accuracies are 80.11% for video streaming and 90.78% for smart home tasks, showing potential of the new gesture understanding paradigm.","meta":{"url":"http://arxiv.org/abs/2310.12821v1"},"cats":{"benchmark":0.3822206554,"new-dataset":0.2804618289,"data-annotation":0.5320930401,"dev-research":0.1823249488,"llms":0.5018046424,"data-quality":0.0880711446}}
{"text":"Solving complex planning problems has been a long-standing challenge in computer science.","meta":{"url":"http://arxiv.org/abs/2310.12819v1"},"cats":{"benchmark":0.2559796494,"new-dataset":0.113089279,"data-annotation":0.5000769473,"dev-research":0.3908966437,"llms":0.4837977889,"data-quality":0.0467750538}}
{"text":"Learning-based subgoal search methods have shown promise in tackling these problems, but they often suffer from a lack of completeness guarantees, meaning that they may fail to find a solution even if one exists.","meta":{"url":"http://arxiv.org/abs/2310.12819v1"},"cats":{"benchmark":0.3084567378,"new-dataset":0.0185893423,"data-annotation":0.5380613576,"dev-research":0.1592221321,"llms":0.505828467,"data-quality":0.1832451981}}
{"text":"In this paper, we propose an efficient approach to augment a subgoal search method to achieve completeness in discrete action spaces.","meta":{"url":"http://arxiv.org/abs/2310.12819v1"},"cats":{"benchmark":0.3245782257,"new-dataset":0.0407654397,"data-annotation":0.5279821617,"dev-research":0.1500697456,"llms":0.4959954803,"data-quality":0.0636968069}}
{"text":"Specifically, we augment the high-level search with low-level actions to execute a multi-level (hybrid) search, which we call complete subgoal search.","meta":{"url":"http://arxiv.org/abs/2310.12819v1"},"cats":{"benchmark":0.3377282898,"new-dataset":0.0307919299,"data-annotation":0.5053895,"dev-research":0.1594410352,"llms":0.5671871405,"data-quality":0.0511512953}}
{"text":"This solution achieves the best of both worlds: the practical efficiency of high-level search and the completeness of low-level search.","meta":{"url":"http://arxiv.org/abs/2310.12819v1"},"cats":{"benchmark":0.4981420134,"new-dataset":0.017518667,"data-annotation":0.5209694495,"dev-research":0.1176763901,"llms":0.5077992842,"data-quality":0.0755359282}}
{"text":"We apply the proposed search method to a recently proposed subgoal search algorithm and evaluate the algorithm trained on offline data on complex planning problems.","meta":{"url":"http://arxiv.org/abs/2310.12819v1"},"cats":{"benchmark":0.3020466078,"new-dataset":0.1243460495,"data-annotation":0.5103890971,"dev-research":0.1949519042,"llms":0.4464709743,"data-quality":0.043409268}}
{"text":"We demonstrate that our complete subgoal search not only guarantees completeness but can even improve performance in terms of search expansions for instances that the high-level could solve without low-level augmentations.","meta":{"url":"http://arxiv.org/abs/2310.12819v1"},"cats":{"benchmark":0.4216253056,"new-dataset":0.0265067785,"data-annotation":0.5394594611,"dev-research":0.1420499246,"llms":0.5523739447,"data-quality":0.118929787}}
{"text":"Our approach makes it possible to apply subgoal-level planning for systems where completeness is a critical requirement.","meta":{"url":"http://arxiv.org/abs/2310.12819v1"},"cats":{"benchmark":0.3041964096,"new-dataset":0.0284621969,"data-annotation":0.4776383086,"dev-research":0.2630845645,"llms":0.5173906056,"data-quality":0.0505079645}}
{"text":"Parameter-shared pre-trained language models (PLMs) have emerged as a successful approach in resource-constrained environments, enabling substantial reductions in model storage and memory costs without significant performance compromise.","meta":{"url":"http://arxiv.org/abs/2310.12818v1"},"cats":{"benchmark":0.2272033028,"new-dataset":0.0801782894,"data-annotation":0.5282114221,"dev-research":0.1890174066,"llms":0.6141647089,"data-quality":0.1504805104}}
{"text":"However, it is important to note that parameter sharing does not alleviate computational burdens associated with inference, thus impeding its practicality in situations characterized by limited stringent latency requirements or computational resources.","meta":{"url":"http://arxiv.org/abs/2310.12818v1"},"cats":{"benchmark":0.4533689347,"new-dataset":0.0024146897,"data-annotation":0.5057709081,"dev-research":0.2224064838,"llms":0.472169021,"data-quality":0.0800109019}}
{"text":"Building upon neural ordinary differential equations (ODEs), we introduce a straightforward technique to enhance the inference efficiency of parameter-shared PLMs.","meta":{"url":"http://arxiv.org/abs/2310.12818v1"},"cats":{"benchmark":0.338031402,"new-dataset":0.0175861057,"data-annotation":0.4983942061,"dev-research":0.1287910567,"llms":0.483301374,"data-quality":0.0938079598}}
{"text":"Additionally, we propose a simple pre-training technique that leads to fully or partially shared models capable of achieving even greater inference acceleration.","meta":{"url":"http://arxiv.org/abs/2310.12818v1"},"cats":{"benchmark":0.3960353234,"new-dataset":0.0301454861,"data-annotation":0.537774956,"dev-research":0.1329329052,"llms":0.4142819957,"data-quality":0.1189647731}}
{"text":"The experimental results demonstrate the effectiveness of our methods on both autoregressive and autoencoding PLMs, providing novel insights into more efficient utilization of parameter-shared models in resource-constrained settings.","meta":{"url":"http://arxiv.org/abs/2310.12818v1"},"cats":{"benchmark":0.3994148578,"new-dataset":0.0104516858,"data-annotation":0.4896164529,"dev-research":0.124853734,"llms":0.5114144234,"data-quality":0.1108326661}}
{"text":"We present a Multimodal Interlaced Transformer (MIT) that jointly considers 2D and 3D data for weakly supervised point cloud segmentation.","meta":{"url":"http://arxiv.org/abs/2310.12817v1"},"cats":{"benchmark":0.3106418323,"new-dataset":0.1378600479,"data-annotation":0.4798979281,"dev-research":0.1188381908,"llms":0.4575452849,"data-quality":0.1364901073}}
{"text":"Research studies have shown that 2D and 3D features are complementary for point cloud segmentation.","meta":{"url":"http://arxiv.org/abs/2310.12817v1"},"cats":{"benchmark":0.3945595693,"new-dataset":0.0385074906,"data-annotation":0.5008172084,"dev-research":0.1536522249,"llms":0.3985139402,"data-quality":0.1203374068}}
{"text":"However, existing methods require extra 2D annotations to achieve 2D-3D information fusion.","meta":{"url":"http://arxiv.org/abs/2310.12817v1"},"cats":{"benchmark":0.3083317237,"new-dataset":0.064814478,"data-annotation":0.5256765082,"dev-research":0.2424045143,"llms":0.4539141651,"data-quality":0.1772831767}}
{"text":"Considering the high annotation cost of point clouds, effective 2D and 3D feature fusion based on weakly supervised learning is in great demand.","meta":{"url":"http://arxiv.org/abs/2310.12817v1"},"cats":{"benchmark":0.3609442046,"new-dataset":0.1913411369,"data-annotation":0.5243410089,"dev-research":0.2069217043,"llms":0.461347468,"data-quality":0.2461015335}}
{"text":"To this end, we propose a transformer model with two encoders and one decoder for weakly supervised point cloud segmentation using only scene-level class tags.","meta":{"url":"http://arxiv.org/abs/2310.12817v1"},"cats":{"benchmark":0.2548941096,"new-dataset":0.1391559242,"data-annotation":0.504541571,"dev-research":0.1200267713,"llms":0.4703454926,"data-quality":0.2565790179}}
{"text":"Specifically, the two encoders compute the self-attended features for 3D point clouds and 2D multi-view images, respectively.","meta":{"url":"http://arxiv.org/abs/2310.12817v1"},"cats":{"benchmark":0.3115648031,"new-dataset":0.0602586365,"data-annotation":0.5261704575,"dev-research":0.1369355748,"llms":0.4718806429,"data-quality":0.072408322}}
{"text":"The decoder implements interlaced 2D-3D cross-attention and carries out implicit 2D and 3D feature fusion.","meta":{"url":"http://arxiv.org/abs/2310.12817v1"},"cats":{"benchmark":0.2833171312,"new-dataset":0.0732735734,"data-annotation":0.5156562687,"dev-research":0.1667118639,"llms":0.4469853973,"data-quality":0.0816250143}}
{"text":"We alternately switch the roles of queries and key-value pairs in the decoder layers.","meta":{"url":"http://arxiv.org/abs/2310.12817v1"},"cats":{"benchmark":0.2847678396,"new-dataset":0.0525572057,"data-annotation":0.4797213301,"dev-research":0.1416808711,"llms":0.5504535471,"data-quality":0.1063419389}}
{"text":"It turns out that the 2D and 3D features are iteratively enriched by each other.","meta":{"url":"http://arxiv.org/abs/2310.12817v1"},"cats":{"benchmark":0.2549638427,"new-dataset":0.0314464785,"data-annotation":0.503758484,"dev-research":0.2231197067,"llms":0.4527061606,"data-quality":0.0648003311}}
{"text":"Experiments show that it performs favorably against existing weakly supervised point cloud segmentation methods by a large margin on the S3DIS and ScanNet benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.12817v1"},"cats":{"benchmark":0.4600230951,"new-dataset":0.0928729104,"data-annotation":0.5118317635,"dev-research":0.1215589397,"llms":0.4788481919,"data-quality":0.2142802977}}
{"text":"The project page will be available at https://jimmy15923.github.io/mit_web/.","meta":{"url":"http://arxiv.org/abs/2310.12817v1"},"cats":{"benchmark":0.2249271359,"new-dataset":0.3046773697,"data-annotation":0.5299598986,"dev-research":0.2084490303,"llms":0.6003610987,"data-quality":0.0713343162}}
{"text":"In this paper, we address the problem of real-time motion planning for multiple robotic manipulators that operate in close proximity.","meta":{"url":"http://arxiv.org/abs/2310.12816v1"},"cats":{"benchmark":0.3106203053,"new-dataset":0.1084854334,"data-annotation":0.5120185675,"dev-research":0.2287235774,"llms":0.408827329,"data-quality":0.0450545225}}
{"text":"We build upon the concept of dynamic fabrics and extend them to multi-robot systems, referred to as Multi-Robot Dynamic Fabrics (MRDF).","meta":{"url":"http://arxiv.org/abs/2310.12816v1"},"cats":{"benchmark":0.2467897088,"new-dataset":0.1646901946,"data-annotation":0.5067626464,"dev-research":0.1854594741,"llms":0.4795159599,"data-quality":0.0377307915}}
{"text":"This geometric method enables a very high planning frequency for high-dimensional systems at the expense of being reactive and prone to deadlocks.","meta":{"url":"http://arxiv.org/abs/2310.12816v1"},"cats":{"benchmark":0.3488678697,"new-dataset":0.0097248795,"data-annotation":0.4898370314,"dev-research":0.2407020541,"llms":0.4559107418,"data-quality":0.0249910896}}
{"text":"To detect and resolve deadlocks, we propose Rollout Fabrics where MRDF are forward simulated in a decentralized manner.","meta":{"url":"http://arxiv.org/abs/2310.12816v1"},"cats":{"benchmark":0.3834700507,"new-dataset":0.1436807374,"data-annotation":0.4899650176,"dev-research":0.2398188284,"llms":0.5960477365,"data-quality":0.1151933519}}
{"text":"We validate the methods in simulated close-proximity pick-and-place scenarios with multiple manipulators, showing high success rates and real-time performance.","meta":{"url":"http://arxiv.org/abs/2310.12816v1"},"cats":{"benchmark":0.4609521165,"new-dataset":0.0317652699,"data-annotation":0.5149855493,"dev-research":0.2025422394,"llms":0.49695759,"data-quality":0.0631192117}}
{"text":"Large Language Models (LLMs) are increasingly deployed as the backend for a variety of real-world applications called LLM-Integrated Applications.","meta":{"url":"http://arxiv.org/abs/2310.12815v1"},"cats":{"benchmark":0.1981054349,"new-dataset":0.0941642597,"data-annotation":0.5094695936,"dev-research":0.185598775,"llms":0.7515711066,"data-quality":0.108955407}}
{"text":"Multiple recent works showed that LLM-Integrated Applications are vulnerable to prompt injection attacks, in which an attacker injects malicious instruction/data into the input of those applications such that they produce results as the attacker desires.","meta":{"url":"http://arxiv.org/abs/2310.12815v1"},"cats":{"benchmark":0.1975810863,"new-dataset":0.0193134435,"data-annotation":0.5126423317,"dev-research":0.2246026735,"llms":0.7848325917,"data-quality":0.1408880485}}
{"text":"However, existing works are limited to case studies.","meta":{"url":"http://arxiv.org/abs/2310.12815v1"},"cats":{"benchmark":0.2715356728,"new-dataset":0.0214679774,"data-annotation":0.4921503394,"dev-research":0.2265844957,"llms":0.5634117699,"data-quality":0.0658992986}}
{"text":"As a result, the literature lacks a systematic understanding of prompt injection attacks and their defenses.","meta":{"url":"http://arxiv.org/abs/2310.12815v1"},"cats":{"benchmark":0.2362280708,"new-dataset":0.0132859924,"data-annotation":0.5244931804,"dev-research":0.2328272609,"llms":0.5777987966,"data-quality":0.190746582}}
{"text":"We aim to bridge the gap in this work.","meta":{"url":"http://arxiv.org/abs/2310.12815v1"},"cats":{"benchmark":0.3116624397,"new-dataset":0.0546960885,"data-annotation":0.4972515002,"dev-research":0.218666506,"llms":0.5581676767,"data-quality":0.1295421888}}
{"text":"In particular, we propose a general framework to formalize prompt injection attacks.","meta":{"url":"http://arxiv.org/abs/2310.12815v1"},"cats":{"benchmark":0.3008346803,"new-dataset":0.0247959658,"data-annotation":0.523208452,"dev-research":0.2698355581,"llms":0.573006089,"data-quality":0.2007943815}}
{"text":"Existing attacks, which are discussed in research papers and blog posts, are special cases in our framework.","meta":{"url":"http://arxiv.org/abs/2310.12815v1"},"cats":{"benchmark":0.2622189906,"new-dataset":0.0246127294,"data-annotation":0.5338292257,"dev-research":0.2702254931,"llms":0.522266974,"data-quality":0.2115172769}}
{"text":"Our framework enables us to design a new attack by combining existing attacks.","meta":{"url":"http://arxiv.org/abs/2310.12815v1"},"cats":{"benchmark":0.2950409928,"new-dataset":0.0344757847,"data-annotation":0.5199102256,"dev-research":0.2581155773,"llms":0.5028147117,"data-quality":0.0894448071}}
{"text":"Moreover, we also propose a framework to systematize defenses against prompt injection attacks.","meta":{"url":"http://arxiv.org/abs/2310.12815v1"},"cats":{"benchmark":0.3083221642,"new-dataset":0.0203803244,"data-annotation":0.5257673985,"dev-research":0.2609634972,"llms":0.5657103273,"data-quality":0.1493623577}}
{"text":"Using our frameworks, we conduct a systematic evaluation on prompt injection attacks and their defenses with 10 LLMs and 7 tasks.","meta":{"url":"http://arxiv.org/abs/2310.12815v1"},"cats":{"benchmark":0.3738224503,"new-dataset":0.0330825036,"data-annotation":0.523320097,"dev-research":0.2076833424,"llms":0.6919141481,"data-quality":0.1460234259}}
{"text":"We hope our frameworks can inspire future research in this field.","meta":{"url":"http://arxiv.org/abs/2310.12815v1"},"cats":{"benchmark":0.2599473704,"new-dataset":0.0953375928,"data-annotation":0.5185549329,"dev-research":0.1915944948,"llms":0.507846625,"data-quality":0.0625656051}}
{"text":"Our code is available at https://github.com/liu00222/Open-Prompt-Injection.","meta":{"url":"http://arxiv.org/abs/2310.12815v1"},"cats":{"benchmark":0.2564106,"new-dataset":0.0728925074,"data-annotation":0.5419292386,"dev-research":0.1549800785,"llms":0.5845981041,"data-quality":0.1454446987}}
{"text":"Existing hierarchical forecasting techniques scale poorly when the number of time series increases.","meta":{"url":"http://arxiv.org/abs/2310.12809v1"},"cats":{"benchmark":0.5101175047,"new-dataset":0.0077159266,"data-annotation":0.5139639567,"dev-research":0.1444262067,"llms":0.4048379358,"data-quality":0.063478466}}
{"text":"We propose to learn a coherent forecast for millions of time series with a single bottom-level forecast model by using a sparse loss function that directly optimizes the hierarchical product and/or temporal structure.","meta":{"url":"http://arxiv.org/abs/2310.12809v1"},"cats":{"benchmark":0.3469942056,"new-dataset":0.0930035237,"data-annotation":0.5105816958,"dev-research":0.1183619077,"llms":0.3997866469,"data-quality":0.0680732602}}
{"text":"The benefit of our sparse hierarchical loss function is that it provides practitioners a method of producing bottom-level forecasts that are coherent to any chosen cross-sectional or temporal hierarchy.","meta":{"url":"http://arxiv.org/abs/2310.12809v1"},"cats":{"benchmark":0.4456976912,"new-dataset":0.0151138102,"data-annotation":0.5136449096,"dev-research":0.1350582405,"llms":0.3926214058,"data-quality":0.0655617472}}
{"text":"In addition, removing the need for a post-processing step as required in traditional hierarchical forecasting techniques reduces the computational cost of the prediction phase in the forecasting pipeline.","meta":{"url":"http://arxiv.org/abs/2310.12809v1"},"cats":{"benchmark":0.463257743,"new-dataset":0.0048594089,"data-annotation":0.4937504776,"dev-research":0.1789010209,"llms":0.4006992487,"data-quality":0.0409242401}}
{"text":"On the public M5 dataset, our sparse hierarchical loss function performs up to 10% (RMSE) better compared to the baseline loss function.","meta":{"url":"http://arxiv.org/abs/2310.12809v1"},"cats":{"benchmark":0.6146897622,"new-dataset":0.0555803118,"data-annotation":0.5296234127,"dev-research":0.0892734014,"llms":0.4121177878,"data-quality":0.1374464949}}
{"text":"We implement our sparse hierarchical loss function within an existing forecasting model at bol, a large European e-commerce platform, resulting in an improved forecasting performance of 2% at the product level.","meta":{"url":"http://arxiv.org/abs/2310.12809v1"},"cats":{"benchmark":0.5129072194,"new-dataset":0.0451587179,"data-annotation":0.5244412377,"dev-research":0.1159516262,"llms":0.377809867,"data-quality":0.1070832332}}
{"text":"Finally, we found an increase in forecasting performance of about 5-10% when evaluating the forecasting performance across the cross-sectional hierarchies that we defined.","meta":{"url":"http://arxiv.org/abs/2310.12809v1"},"cats":{"benchmark":0.6170807978,"new-dataset":0.0312330463,"data-annotation":0.5277766982,"dev-research":0.1686785234,"llms":0.4311905571,"data-quality":0.0515159796}}
{"text":"These results demonstrate the usefulness of our sparse hierarchical loss applied to a production forecasting system at a major e-commerce platform.","meta":{"url":"http://arxiv.org/abs/2310.12809v1"},"cats":{"benchmark":0.4330942079,"new-dataset":0.0289996622,"data-annotation":0.5094456793,"dev-research":0.1541877537,"llms":0.3548330694,"data-quality":0.1307401513}}
{"text":"Models trained on different datasets can be merged by a weighted-averaging of their parameters, but why does it work and when can it fail?","meta":{"url":"http://arxiv.org/abs/2310.12808v1"},"cats":{"benchmark":0.4595510888,"new-dataset":0.0015845679,"data-annotation":0.49151226,"dev-research":0.1256998025,"llms":0.4659336499,"data-quality":0.1579222883}}
{"text":"Here, we connect the inaccuracy of weighted-averaging to mismatches in the gradients and propose a new uncertainty-based scheme to improve the performance by reducing the mismatch.","meta":{"url":"http://arxiv.org/abs/2310.12808v1"},"cats":{"benchmark":0.6944516717,"new-dataset":0.002242602,"data-annotation":0.5190697836,"dev-research":0.1764780689,"llms":0.3880932241,"data-quality":0.3366257645}}
{"text":"The connection also reveals implicit assumptions in other schemes such as averaging, task arithmetic, and Fisher-weighted averaging.","meta":{"url":"http://arxiv.org/abs/2310.12808v1"},"cats":{"benchmark":0.4381620642,"new-dataset":0.001890535,"data-annotation":0.5289834205,"dev-research":0.1858614315,"llms":0.3817332,"data-quality":0.0791203164}}
{"text":"Our new method gives consistent improvements for large language models and vision transformers, both in terms of performance and robustness to hyperparameters.","meta":{"url":"http://arxiv.org/abs/2310.12808v1"},"cats":{"benchmark":0.3821940452,"new-dataset":0.0979355308,"data-annotation":0.5532669619,"dev-research":0.2027517764,"llms":0.4896498427,"data-quality":0.2940723746}}
{"text":"The cause-to-effect analysis can help us decompose all the likely causes of a problem, such as an undesirable business situation or unintended harm to the individual(s).","meta":{"url":"http://arxiv.org/abs/2310.12805v1"},"cats":{"benchmark":0.2686258121,"new-dataset":0.0463701375,"data-annotation":0.5169152932,"dev-research":0.4290921452,"llms":0.4947007818,"data-quality":0.1517281639}}
{"text":"This implies that we can identify how the problems are inherited, rank the causes to help prioritize fixes, simplify a complex problem and visualize them.","meta":{"url":"http://arxiv.org/abs/2310.12805v1"},"cats":{"benchmark":0.2691661411,"new-dataset":0.0293138566,"data-annotation":0.5301495535,"dev-research":0.4344891756,"llms":0.4675020193,"data-quality":0.1246100577}}
{"text":"In the context of machine learning (ML), one can use cause-to-effect analysis to understand the reason for the biased behavior of the system.","meta":{"url":"http://arxiv.org/abs/2310.12805v1"},"cats":{"benchmark":0.2859550031,"new-dataset":0.0426726257,"data-annotation":0.5313574893,"dev-research":0.378711657,"llms":0.4966789631,"data-quality":0.2105441816}}
{"text":"For example, we can examine the root causes of biases by checking each feature for a potential cause of bias in the model.","meta":{"url":"http://arxiv.org/abs/2310.12805v1"},"cats":{"benchmark":0.3892829098,"new-dataset":0.0122280006,"data-annotation":0.5513785999,"dev-research":0.2605104931,"llms":0.4281711699,"data-quality":0.193463022}}
{"text":"To approach this, one can apply small changes to a given feature or a pair of features in the data, following some guidelines and observing how it impacts the decision made by the model (i.e., model prediction).","meta":{"url":"http://arxiv.org/abs/2310.12805v1"},"cats":{"benchmark":0.4140087443,"new-dataset":0.0125145957,"data-annotation":0.5043094463,"dev-research":0.3313467153,"llms":0.3747379026,"data-quality":0.1390765746}}
{"text":"Therefore, we can use cause-to-effect analysis to identify the potential bias-inducing features, even when these features are originally are unknown.","meta":{"url":"http://arxiv.org/abs/2310.12805v1"},"cats":{"benchmark":0.2772962492,"new-dataset":0.0179531453,"data-annotation":0.5422361136,"dev-research":0.280319072,"llms":0.4279036912,"data-quality":0.3352486422}}
{"text":"This is important since most current methods require a pre-identification of sensitive features for bias assessment and can actually miss other relevant bias-inducing features, which is why systematic identification of such features is necessary.","meta":{"url":"http://arxiv.org/abs/2310.12805v1"},"cats":{"benchmark":0.4959480858,"new-dataset":0.0057877677,"data-annotation":0.5348724782,"dev-research":0.2189919913,"llms":0.4478375762,"data-quality":0.3352297383}}
{"text":"Moreover, it often occurs that to achieve an equitable outcome, one has to take into account sensitive features in the model decision.","meta":{"url":"http://arxiv.org/abs/2310.12805v1"},"cats":{"benchmark":0.4354564731,"new-dataset":0.0020715582,"data-annotation":0.4956904436,"dev-research":0.2296416052,"llms":0.4353625833,"data-quality":0.1597872179}}
{"text":"Therefore, it should be up to the domain experts to decide based on their knowledge of the context of a decision whether bias induced by specific features is acceptable or not.","meta":{"url":"http://arxiv.org/abs/2310.12805v1"},"cats":{"benchmark":0.3476663275,"new-dataset":0.0039402943,"data-annotation":0.50979591,"dev-research":0.2821191266,"llms":0.4924196916,"data-quality":0.2474810236}}
{"text":"In this study, we propose an approach for systematically identifying all bias-inducing features of a model to help support the decision-making of domain experts.","meta":{"url":"http://arxiv.org/abs/2310.12805v1"},"cats":{"benchmark":0.3502657958,"new-dataset":0.0151094858,"data-annotation":0.5249415099,"dev-research":0.3094029286,"llms":0.4433949917,"data-quality":0.2598341159}}
{"text":"We evaluated our technique using four well-known datasets to showcase how our contribution can help spearhead the standard procedure when developing, testing, maintaining, and deploying fair/equitable machine learning systems.","meta":{"url":"http://arxiv.org/abs/2310.12805v1"},"cats":{"benchmark":0.4472240693,"new-dataset":0.3951173492,"data-annotation":0.4908697094,"dev-research":0.1923526748,"llms":0.5215614212,"data-quality":0.1779746248}}
{"text":"The reliance of text classifiers on spurious correlations can lead to poor generalization at deployment, raising concerns about their use in safety-critical domains such as healthcare.","meta":{"url":"http://arxiv.org/abs/2310.12803v1"},"cats":{"benchmark":0.35595254,"new-dataset":0.0124393739,"data-annotation":0.5249564045,"dev-research":0.3649893136,"llms":0.4869580298,"data-quality":0.4991686909}}
{"text":"In this work, we propose to use counterfactual data augmentation, guided by knowledge of the causal structure of the data, to simulate interventions on spurious features and to learn more robust text classifiers.","meta":{"url":"http://arxiv.org/abs/2310.12803v1"},"cats":{"benchmark":0.3691728799,"new-dataset":0.2520517318,"data-annotation":0.5163338737,"dev-research":0.264194808,"llms":0.4676124786,"data-quality":0.4017236045}}
{"text":"We show that this strategy is appropriate in prediction problems where the label is spuriously correlated with an attribute.","meta":{"url":"http://arxiv.org/abs/2310.12803v1"},"cats":{"benchmark":0.432383391,"new-dataset":0.021700832,"data-annotation":0.5516880244,"dev-research":0.1745866193,"llms":0.3405114336,"data-quality":0.5529500436}}
{"text":"Under the assumptions of such problems, we discuss the favorable sample complexity of counterfactual data augmentation, compared to importance re-weighting.","meta":{"url":"http://arxiv.org/abs/2310.12803v1"},"cats":{"benchmark":0.6242534767,"new-dataset":0.0419130645,"data-annotation":0.5168977469,"dev-research":0.2008877091,"llms":0.4483007718,"data-quality":0.2821877116}}
{"text":"Pragmatically, we match examples using auxiliary data, based on diff-in-diff methodology, and use a large language model (LLM) to represent a conditional probability of text.","meta":{"url":"http://arxiv.org/abs/2310.12803v1"},"cats":{"benchmark":0.3831109723,"new-dataset":0.2747806007,"data-annotation":0.529170884,"dev-research":0.2451184565,"llms":0.5684668197,"data-quality":0.2830812642}}
{"text":"Through extensive experimentation on learning caregiver-invariant predictors of clinical diagnoses from medical narratives and on semi-synthetic data, we demonstrate that our method for simulating interventions improves out-of-distribution (OOD) accuracy compared to baseline invariant learning algorithms.","meta":{"url":"http://arxiv.org/abs/2310.12803v1"},"cats":{"benchmark":0.3788201669,"new-dataset":0.0574075994,"data-annotation":0.5202371896,"dev-research":0.1887262299,"llms":0.4014625684,"data-quality":0.1568613793}}
{"text":"The burdensome impact of a skewed judges-to-cases ratio on the judicial system manifests in an overwhelming backlog of pending cases alongside an ongoing influx of new ones.","meta":{"url":"http://arxiv.org/abs/2310.12800v1"},"cats":{"benchmark":0.4778256864,"new-dataset":0.0250865406,"data-annotation":0.4920294515,"dev-research":0.151416077,"llms":0.5754152098,"data-quality":0.1054529875}}
{"text":"To tackle this issue and expedite the judicial process, the proposition of an automated system capable of suggesting case outcomes based on factual evidence and precedent from past cases gains significance.","meta":{"url":"http://arxiv.org/abs/2310.12800v1"},"cats":{"benchmark":0.3612846516,"new-dataset":0.0300023705,"data-annotation":0.4836984565,"dev-research":0.3284920577,"llms":0.5433188158,"data-quality":0.1334599265}}
{"text":"This research paper centres on developing a graph neural network-based model to address the Legal Judgment Prediction (LJP) problem, recognizing the intrinsic graph structure of judicial cases and making it a binary node classification problem.","meta":{"url":"http://arxiv.org/abs/2310.12800v1"},"cats":{"benchmark":0.3882059587,"new-dataset":0.1191980295,"data-annotation":0.5164013459,"dev-research":0.1802847857,"llms":0.4816549435,"data-quality":0.200352267}}
{"text":"We explored various embeddings as model features, while nodes such as time nodes and judicial acts were added and pruned to evaluate the model's performance.","meta":{"url":"http://arxiv.org/abs/2310.12800v1"},"cats":{"benchmark":0.4693458786,"new-dataset":0.015088135,"data-annotation":0.5141486878,"dev-research":0.1875433538,"llms":0.5356682929,"data-quality":0.0963452942}}
{"text":"The study is done while considering the ethical dimension of fairness in these predictions, considering gender and name biases.","meta":{"url":"http://arxiv.org/abs/2310.12800v1"},"cats":{"benchmark":0.4251896089,"new-dataset":0.0211795624,"data-annotation":0.5311275406,"dev-research":0.1931482124,"llms":0.5024167095,"data-quality":0.1940680695}}
{"text":"A link prediction task is also conducted to assess the model's proficiency in anticipating connections between two specified nodes.","meta":{"url":"http://arxiv.org/abs/2310.12800v1"},"cats":{"benchmark":0.3556139847,"new-dataset":0.0084137231,"data-annotation":0.5293521948,"dev-research":0.182448156,"llms":0.4718773172,"data-quality":0.1138019739}}
{"text":"By harnessing the capabilities of graph neural networks and incorporating fairness analyses, this research aims to contribute insights towards streamlining the adjudication process, enhancing judicial efficiency, and fostering a more equitable legal landscape, ultimately alleviating the strain imposed by mounting case backlogs.","meta":{"url":"http://arxiv.org/abs/2310.12800v1"},"cats":{"benchmark":0.4166206516,"new-dataset":0.0586040715,"data-annotation":0.4956131016,"dev-research":0.2058934271,"llms":0.5474972932,"data-quality":0.1714751602}}
{"text":"Our best-performing model with XLNet pre-trained embeddings as its features gives the macro F1 score of 75% for the LJP task.","meta":{"url":"http://arxiv.org/abs/2310.12800v1"},"cats":{"benchmark":0.4242900232,"new-dataset":0.095804918,"data-annotation":0.5465478003,"dev-research":0.1814518807,"llms":0.4475311357,"data-quality":0.1657990175}}
{"text":"For link prediction, the same set of features is the best performing giving ROC of more than 80%","meta":{"url":"http://arxiv.org/abs/2310.12800v1"},"cats":{"benchmark":0.5371361461,"new-dataset":0.0488526303,"data-annotation":0.5367207244,"dev-research":0.1998728264,"llms":0.4432597275,"data-quality":0.1961459557}}
{"text":"Language Models (LMs) have demonstrated impressive molecule understanding ability on various 1D text-related tasks.","meta":{"url":"http://arxiv.org/abs/2310.12798v1"},"cats":{"benchmark":0.2418984043,"new-dataset":0.0383032589,"data-annotation":0.5230609939,"dev-research":0.1423039099,"llms":0.6258102964,"data-quality":0.1960768791}}
{"text":"However, they inherently lack 2D graph perception - a critical ability of human professionals in comprehending molecules' topological structures.","meta":{"url":"http://arxiv.org/abs/2310.12798v1"},"cats":{"benchmark":0.161806858,"new-dataset":0.022730146,"data-annotation":0.5088978093,"dev-research":0.2054653528,"llms":0.5475922097,"data-quality":0.1157273265}}
{"text":"To bridge this gap, we propose MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter.","meta":{"url":"http://arxiv.org/abs/2310.12798v1"},"cats":{"benchmark":0.3344928852,"new-dataset":0.1247087237,"data-annotation":0.520234855,"dev-research":0.1684046938,"llms":0.5521928048,"data-quality":0.1213590415}}
{"text":"MolCA enables an LM (e.g., Galactica) to understand both text- and graph-based molecular contents via the cross-modal projector.","meta":{"url":"http://arxiv.org/abs/2310.12798v1"},"cats":{"benchmark":0.2871323257,"new-dataset":0.0890051615,"data-annotation":0.5018748994,"dev-research":0.13079048,"llms":0.5895592527,"data-quality":0.0868785541}}
{"text":"Specifically, the cross-modal projector is implemented as a Q-Former to connect a graph encoder's representation space and an LM's text space.","meta":{"url":"http://arxiv.org/abs/2310.12798v1"},"cats":{"benchmark":0.2623955441,"new-dataset":0.0590517604,"data-annotation":0.5068129701,"dev-research":0.1838058079,"llms":0.5630353808,"data-quality":0.0763504127}}
{"text":"Further, MolCA employs a uni-modal adapter (i.e., LoRA) for the LM's efficient adaptation to downstream tasks.","meta":{"url":"http://arxiv.org/abs/2310.12798v1"},"cats":{"benchmark":0.3647082191,"new-dataset":0.0185635324,"data-annotation":0.4763662527,"dev-research":0.1098350323,"llms":0.5941488507,"data-quality":0.0585224297}}
{"text":"Unlike previous studies that couple an LM with a graph encoder via cross-modal contrastive learning, MolCA retains the LM's ability of open-ended text generation and augments it with 2D graph information.","meta":{"url":"http://arxiv.org/abs/2310.12798v1"},"cats":{"benchmark":0.2840200114,"new-dataset":0.0875524292,"data-annotation":0.5023174361,"dev-research":0.1225502977,"llms":0.5745545506,"data-quality":0.0932245872}}
{"text":"To showcase its effectiveness, we extensively benchmark MolCA on tasks of molecule captioning, IUPAC name prediction, and molecule-text retrieval, on which MolCA significantly outperforms the baselines.","meta":{"url":"http://arxiv.org/abs/2310.12798v1"},"cats":{"benchmark":0.5621600353,"new-dataset":0.1878248086,"data-annotation":0.5304058959,"dev-research":0.1309301308,"llms":0.5317446806,"data-quality":0.2622384985}}
{"text":"Our codes and checkpoints can be found at https://github.com/acharkq/MolCA.","meta":{"url":"http://arxiv.org/abs/2310.12798v1"},"cats":{"benchmark":0.3257849417,"new-dataset":0.5753442487,"data-annotation":0.5099008653,"dev-research":0.232573144,"llms":0.5429998572,"data-quality":0.1372701294}}
{"text":"Large language models (LLMs) have exhibited considerable cross-lingual generalization abilities, whereby they implicitly transfer knowledge across languages.","meta":{"url":"http://arxiv.org/abs/2310.12794v1"},"cats":{"benchmark":0.235999688,"new-dataset":0.0198340387,"data-annotation":0.5426604868,"dev-research":0.1217487094,"llms":0.6280442574,"data-quality":0.1602814294}}
{"text":"However, the transfer is not equally successful for all languages, especially for low-resource ones, which poses an ongoing challenge.","meta":{"url":"http://arxiv.org/abs/2310.12794v1"},"cats":{"benchmark":0.3571272826,"new-dataset":0.0114920451,"data-annotation":0.5161581452,"dev-research":0.1543713328,"llms":0.5667531393,"data-quality":0.2091947731}}
{"text":"It is unclear whether we have reached the limits of implicit cross-lingual generalization and if explicit knowledge transfer is viable.","meta":{"url":"http://arxiv.org/abs/2310.12794v1"},"cats":{"benchmark":0.2503152578,"new-dataset":0.0234566993,"data-annotation":0.5345021513,"dev-research":0.1637093986,"llms":0.5188508543,"data-quality":0.2298915546}}
{"text":"In this paper, we investigate the potential for explicitly aligning conceptual correspondence between languages to enhance cross-lingual generalization.","meta":{"url":"http://arxiv.org/abs/2310.12794v1"},"cats":{"benchmark":0.2993838504,"new-dataset":0.0337397326,"data-annotation":0.5267067432,"dev-research":0.2182226774,"llms":0.5385091026,"data-quality":0.2470115446}}
{"text":"Using the syntactic aspect of language as a testbed, our analyses of 43 languages reveal a high degree of alignability among the spaces of structural concepts within each language for both encoder-only and decoder-only LLMs.","meta":{"url":"http://arxiv.org/abs/2310.12794v1"},"cats":{"benchmark":0.2936725768,"new-dataset":0.0457572518,"data-annotation":0.5167579832,"dev-research":0.1664704093,"llms":0.6893132465,"data-quality":0.1609197701}}
{"text":"We then propose a meta-learning-based method to learn to align conceptual spaces of different languages, which facilitates zero-shot and few-shot generalization in concept classification and also offers insights into the cross-lingual in-context learning phenomenon.","meta":{"url":"http://arxiv.org/abs/2310.12794v1"},"cats":{"benchmark":0.2598659547,"new-dataset":0.1203222837,"data-annotation":0.5421703105,"dev-research":0.2068704868,"llms":0.5441970784,"data-quality":0.3203917674}}
{"text":"Experiments on syntactic analysis tasks show that our approach achieves competitive results with state-of-the-art methods and narrows the performance gap between languages, particularly benefiting those with limited resources.","meta":{"url":"http://arxiv.org/abs/2310.12794v1"},"cats":{"benchmark":0.5410569431,"new-dataset":0.0362158496,"data-annotation":0.5504832026,"dev-research":0.2991876577,"llms":0.5394619381,"data-quality":0.2016868563}}
{"text":"Existing works have made great progress in improving adversarial robustness, but typically test their method only on data from the same distribution as the training data, i.e. in-distribution (ID) testing.","meta":{"url":"http://arxiv.org/abs/2310.12793v1"},"cats":{"benchmark":0.3872270379,"new-dataset":0.040837999,"data-annotation":0.5155584661,"dev-research":0.1724958902,"llms":0.4742155646,"data-quality":0.378988799}}
{"text":"As a result, it is unclear how such robustness generalizes under input distribution shifts, i.e. out-of-distribution (OOD) testing.","meta":{"url":"http://arxiv.org/abs/2310.12793v1"},"cats":{"benchmark":0.5416576456,"new-dataset":0.0086485717,"data-annotation":0.5107491385,"dev-research":0.1247681441,"llms":0.4245455819,"data-quality":0.2787583778}}
{"text":"This is a concerning omission as such distribution shifts are unavoidable when methods are deployed in the wild.","meta":{"url":"http://arxiv.org/abs/2310.12793v1"},"cats":{"benchmark":0.3896538626,"new-dataset":0.0045480133,"data-annotation":0.5138693168,"dev-research":0.1569052968,"llms":0.5169362556,"data-quality":0.1907044169}}
{"text":"To address this issue we propose a benchmark named OODRobustBench to comprehensively assess OOD adversarial robustness using 23 dataset-wise shifts (i.e. naturalistic shifts in input distribution) and 6 threat-wise shifts (i.e., unforeseen adversarial threat models).","meta":{"url":"http://arxiv.org/abs/2310.12793v1"},"cats":{"benchmark":0.3617400001,"new-dataset":0.1803447987,"data-annotation":0.5261580527,"dev-research":0.193738332,"llms":0.4272930342,"data-quality":0.2574838072}}
{"text":"OODRobustBench is used to assess 706 robust models using 60.7K adversarial evaluations.","meta":{"url":"http://arxiv.org/abs/2310.12793v1"},"cats":{"benchmark":0.387406349,"new-dataset":0.1542441278,"data-annotation":0.526078011,"dev-research":0.2338965206,"llms":0.4448290212,"data-quality":0.2170426164}}
{"text":"This large-scale analysis shows that: 1) adversarial robustness suffers from a severe OOD generalization issue; 2) ID robustness correlates strongly with OOD robustness, in a positive linear way, under many distribution shifts.","meta":{"url":"http://arxiv.org/abs/2310.12793v1"},"cats":{"benchmark":0.3940234795,"new-dataset":0.0161316486,"data-annotation":0.5230925158,"dev-research":0.173295229,"llms":0.4100284634,"data-quality":0.3361649942}}
{"text":"The latter enables the prediction of OOD robustness from ID robustness.","meta":{"url":"http://arxiv.org/abs/2310.12793v1"},"cats":{"benchmark":0.4817341356,"new-dataset":0.0163189221,"data-annotation":0.4948654978,"dev-research":0.1825280533,"llms":0.4476828774,"data-quality":0.258932512}}
{"text":"Based on this, we are able to predict the upper limit of OOD robustness for existing robust training schemes.","meta":{"url":"http://arxiv.org/abs/2310.12793v1"},"cats":{"benchmark":0.4819237276,"new-dataset":0.0371255741,"data-annotation":0.5165732159,"dev-research":0.129726184,"llms":0.3759867195,"data-quality":0.2388757065}}
{"text":"The results suggest that achieving OOD robustness requires designing novel methods beyond the conventional ones.","meta":{"url":"http://arxiv.org/abs/2310.12793v1"},"cats":{"benchmark":0.485320404,"new-dataset":0.0060020419,"data-annotation":0.4834161725,"dev-research":0.2495040272,"llms":0.4916509398,"data-quality":0.1837668058}}
{"text":"Last, we discover that extra data, data augmentation, advanced model architectures and particular regularization approaches can improve OOD robustness.","meta":{"url":"http://arxiv.org/abs/2310.12793v1"},"cats":{"benchmark":0.4745566487,"new-dataset":0.0391274461,"data-annotation":0.4808082259,"dev-research":0.1811850551,"llms":0.4326822878,"data-quality":0.2580199023}}
{"text":"Noticeably, the discovered training schemes, compared to the baseline, exhibit dramatically higher robustness under threat shift while keeping high ID robustness, demonstrating new promising solutions for robustness against both multi-attack and unforeseen attacks.","meta":{"url":"http://arxiv.org/abs/2310.12793v1"},"cats":{"benchmark":0.4217854377,"new-dataset":0.0297774039,"data-annotation":0.5153224622,"dev-research":0.1913611544,"llms":0.4705015734,"data-quality":0.2513959285}}
{"text":"$ \\newcommand{\\Re}{\\mathbb{R}} \\newcommand{\\reals}{\\mathbb{R}} \\newcommand{\\SetX}{\\mathsf{X}} \\newcommand{\\rad}{r} \\newcommand{\\Eps}{\\Mh{\\mathcal{E}}} \\newcommand{\\p}{\\Mh{p}} \\newcommand{\\q}{\\Mh{q}} \\newcommand{\\Mh}[1]{#1} \\newcommand{\\query}{q} \\newcommand{\\eps}{\\varepsilon} \\newcommand{\\VorX}[1]{\\mathcal{V} \\pth{#1}} \\newcommand{\\Polygon}{\\mathsf{P}} \\newcommand{\\IntRange}[1]{[ #1 ]} \\newcommand{\\Space}{\\overline{\\mathsf{m}}} \\newcommand{\\pth}[2][\\!]{#1\\left({#2}\\right)} \\newcommand{\\polylog}{\\mathrm{polylog}} \\newcommand{\\N}{\\mathbb N} \\newcommand{\\Z}{\\mathbb Z} \\newcommand{\\pt}{p} \\newcommand{\\distY}[2]{\\left\\| {#1} - {#2} \\right\\|} \\newcommand{\\ptq}{q} \\newcommand{\\pts}{s}$   For a parameter $\\eps \\in (0,1)$, we present a new construction of $\\eps$-locality-sensitive orderings (<em>LSO</em>s) in $\\Re^d$ of size $M = O(\\Eps^{d-1} \\log \\Eps)$, where $\\Eps = 1/\\eps$.","meta":{"url":"http://arxiv.org/abs/2310.12792v1"},"cats":{"benchmark":0.4275233295,"new-dataset":0.0240621444,"data-annotation":0.5321859375,"dev-research":0.1184615496,"llms":0.426597128,"data-quality":0.0918368957}}
{"text":"This improves over previous work by a factor of $\\Eps$, and is optimal up to a factor of $\\log \\Eps$. Such a set of LSOs has the property that for any two points, $\\p, \\q \\in [0,1]^d$, there exist an order in the set such that all the points between $\\p$ and $\\q$ in the order are $\\eps$-close to either $\\p$ or $\\q$.   ","meta":{"url":"http://arxiv.org/abs/2310.12792v1"},"cats":{"benchmark":0.4902117681,"new-dataset":0.1041183739,"data-annotation":0.5162349839,"dev-research":0.1205928656,"llms":0.4592773224,"data-quality":0.0932851965}}
{"text":"The existence of such LSOs is a fundamental property of low dimensional Euclidean space, conceptually similar to the existence of well-separated pairs decomposition, so the question of how to compute (near) optimal construction of LSOs is quite natural.   ","meta":{"url":"http://arxiv.org/abs/2310.12792v1"},"cats":{"benchmark":0.4966082487,"new-dataset":0.0212172183,"data-annotation":0.5287458778,"dev-research":0.1153440617,"llms":0.4337717448,"data-quality":0.0496576565}}
{"text":"As a consequence we get a flotilla of improved dynamic geometric algorithms, such as maintaining bichromatic closest pair, and spanners, among others.","meta":{"url":"http://arxiv.org/abs/2310.12792v1"},"cats":{"benchmark":0.5073369285,"new-dataset":0.0555058158,"data-annotation":0.5451694166,"dev-research":0.1439209429,"llms":0.3809199088,"data-quality":0.1034825718}}
{"text":"In particular, for geometric dynamic spanners the new result matches (up to the aforementioned $\\log \\Eps$ factor) the lower bound, Thus offering a near-optimal simple dynamic data-structure for maintaining spanners under insertions and deletions.","meta":{"url":"http://arxiv.org/abs/2310.12792v1"},"cats":{"benchmark":0.5532688258,"new-dataset":0.0635919626,"data-annotation":0.5234588077,"dev-research":0.1546141515,"llms":0.4093074271,"data-quality":0.1433411881}}
{"text":"Open-set supervised anomaly detection (OSAD) - a recently emerging anomaly detection area - aims at utilizing a few samples of anomaly classes seen during training to detect unseen anomalies (i.e., samples from open-set anomaly classes), while effectively identifying the seen anomalies.","meta":{"url":"http://arxiv.org/abs/2310.12790v1"},"cats":{"benchmark":0.2732516345,"new-dataset":0.2779819657,"data-annotation":0.5031800189,"dev-research":0.1863097829,"llms":0.5223597985,"data-quality":0.2764557627}}
{"text":"Benefiting from the prior knowledge illustrated by the seen anomalies, current OSAD methods can often largely reduce false positive errors.","meta":{"url":"http://arxiv.org/abs/2310.12790v1"},"cats":{"benchmark":0.6014872953,"new-dataset":0.003883281,"data-annotation":0.5141493582,"dev-research":0.2976444108,"llms":0.5061700326,"data-quality":0.2695135653}}
{"text":"However, these methods treat the anomaly examples as from a homogeneous distribution, rendering them less effective in generalizing to unseen anomalies that can be drawn from any distribution.","meta":{"url":"http://arxiv.org/abs/2310.12790v1"},"cats":{"benchmark":0.3876732792,"new-dataset":0.0088724161,"data-annotation":0.538932119,"dev-research":0.1837460217,"llms":0.4309665116,"data-quality":0.3273191695}}
{"text":"In this paper, we propose to learn heterogeneous anomaly distributions using the limited anomaly examples to address this issue.","meta":{"url":"http://arxiv.org/abs/2310.12790v1"},"cats":{"benchmark":0.2707813017,"new-dataset":0.1549664426,"data-annotation":0.5301323143,"dev-research":0.1503208739,"llms":0.4334043329,"data-quality":0.1652420882}}
{"text":"To this end, we introduce a novel approach, namely Anomaly Heterogeneity Learning (AHL), that simulates a diverse set of heterogeneous (seen and unseen) anomaly distributions and then utilizes them to learn a unified heterogeneous abnormality model.","meta":{"url":"http://arxiv.org/abs/2310.12790v1"},"cats":{"benchmark":0.2148776407,"new-dataset":0.1279158928,"data-annotation":0.5166594338,"dev-research":0.1404381382,"llms":0.414918894,"data-quality":0.1900844201}}
{"text":"Further, AHL is a generic framework that existing OSAD models can plug and play for enhancing their abnormality modeling.","meta":{"url":"http://arxiv.org/abs/2310.12790v1"},"cats":{"benchmark":0.2889927974,"new-dataset":0.0884892286,"data-annotation":0.488113474,"dev-research":0.2163110694,"llms":0.4478609534,"data-quality":0.0821689113}}
{"text":"Extensive experiments on nine real-world anomaly detection datasets show that AHL can 1) substantially enhance different state-of-the-art (SOTA) OSAD models in detecting both seen and unseen anomalies, achieving new SOTA performance on a large set of datasets, and 2) effectively generalize to unseen anomalies in new target domains.","meta":{"url":"http://arxiv.org/abs/2310.12790v1"},"cats":{"benchmark":0.30625634,"new-dataset":0.1682958977,"data-annotation":0.5031027328,"dev-research":0.1813202297,"llms":0.4915567628,"data-quality":0.2428474445}}
{"text":"Robotic crop phenotyping has emerged as a key technology to assess crops' morphological and physiological traits at scale.","meta":{"url":"http://arxiv.org/abs/2310.12787v1"},"cats":{"benchmark":0.3077405915,"new-dataset":0.0376792819,"data-annotation":0.5046126239,"dev-research":0.1502141071,"llms":0.4146973658,"data-quality":0.0903522382}}
{"text":"These phenotypical measurements are essential for developing new crop varieties with the aim of increasing productivity and dealing with environmental challenges such as climate change.","meta":{"url":"http://arxiv.org/abs/2310.12787v1"},"cats":{"benchmark":0.4270915945,"new-dataset":0.1447839125,"data-annotation":0.5164671873,"dev-research":0.2079769676,"llms":0.3952537117,"data-quality":0.0971295975}}
{"text":"However, developing and deploying crop phenotyping robots face many challenges such as complex and variable crop shapes that complicate robotic object detection, dynamic and unstructured environments that baffle robotic control, and real-time computing and managing big data that challenge robotic hardware/software.","meta":{"url":"http://arxiv.org/abs/2310.12787v1"},"cats":{"benchmark":0.1843780603,"new-dataset":0.1023558437,"data-annotation":0.4852901133,"dev-research":0.170744386,"llms":0.4546994685,"data-quality":0.0773146536}}
{"text":"This work specifically tackles the first challenge by proposing a novel Digital-Twin(DT)MARS-CycleGAN model for image augmentation to improve our Modular Agricultural Robotic System (MARS)'s crop object detection from complex and variable backgrounds.","meta":{"url":"http://arxiv.org/abs/2310.12787v1"},"cats":{"benchmark":0.2333449908,"new-dataset":0.1364247477,"data-annotation":0.5017633055,"dev-research":0.1064286379,"llms":0.4497890612,"data-quality":0.1515239494}}
{"text":"Our core idea is that in addition to the cycle consistency losses in the CycleGAN model, we designed and enforced a new DT-MARS loss in the deep learning model to penalize the inconsistency between real crop images captured by MARS and synthesized images sensed by DT MARS.","meta":{"url":"http://arxiv.org/abs/2310.12787v1"},"cats":{"benchmark":0.2441251555,"new-dataset":0.2021238581,"data-annotation":0.4914208823,"dev-research":0.1549819686,"llms":0.474017109,"data-quality":0.2620953208}}
{"text":"Therefore, the generated synthesized crop images closely mimic real images in terms of realism, and they are employed to fine-tune object detectors such as YOLOv8.","meta":{"url":"http://arxiv.org/abs/2310.12787v1"},"cats":{"benchmark":0.193831274,"new-dataset":0.1939929543,"data-annotation":0.5238744757,"dev-research":0.1599674371,"llms":0.4701740641,"data-quality":0.1432114231}}
{"text":"Extensive experiments demonstrated that our new DT/MARS-CycleGAN framework significantly boosts our MARS' crop object/row detector's performance, contributing to the field of robotic crop phenotyping.","meta":{"url":"http://arxiv.org/abs/2310.12787v1"},"cats":{"benchmark":0.2600489385,"new-dataset":0.1249365279,"data-annotation":0.4895881644,"dev-research":0.1120911241,"llms":0.4982910499,"data-quality":0.1215686967}}
{"text":"Simultaneous multithreading processors improve throughput over single-threaded processors thanks to sharing internal core resources among instructions from distinct threads.","meta":{"url":"http://arxiv.org/abs/2310.12786v1"},"cats":{"benchmark":0.5030625681,"new-dataset":0.0090905792,"data-annotation":0.5293159122,"dev-research":0.2035376629,"llms":0.5481469816,"data-quality":0.0810547203}}
{"text":"However, resource sharing introduces inter-thread interference within the core, which has a negative impact on individual application performance and can significantly increase the turnaround time of multi-program workloads.","meta":{"url":"http://arxiv.org/abs/2310.12786v1"},"cats":{"benchmark":0.4848736991,"new-dataset":0.0063522292,"data-annotation":0.5100020638,"dev-research":0.3521062915,"llms":0.5637834309,"data-quality":0.0882813551}}
{"text":"The severity of the interference effects depends on the competing co-runners sharing the core.","meta":{"url":"http://arxiv.org/abs/2310.12786v1"},"cats":{"benchmark":0.4746648572,"new-dataset":0.0059062662,"data-annotation":0.5116177885,"dev-research":0.2171620549,"llms":0.4391016354,"data-quality":0.1186341978}}
{"text":"Thus, it can be mitigated by applying a thread-to-core allocation policy that smartly selects applications to be run in the same core to minimize their interference.   ","meta":{"url":"http://arxiv.org/abs/2310.12786v1"},"cats":{"benchmark":0.4753019599,"new-dataset":0.0020628865,"data-annotation":0.5088647563,"dev-research":0.2631150965,"llms":0.5593288671,"data-quality":0.1314334094}}
{"text":"This paper presents SYNPA, a simple approach that dynamically allocates threads to cores in an SMT processor based on their run-time dynamic behavior.","meta":{"url":"http://arxiv.org/abs/2310.12786v1"},"cats":{"benchmark":0.3784633304,"new-dataset":0.0160947926,"data-annotation":0.51325683,"dev-research":0.2132741108,"llms":0.5940595198,"data-quality":0.0566006005}}
{"text":"The approach uses a regression model to select synergistic pairs to mitigate intra-core interference.","meta":{"url":"http://arxiv.org/abs/2310.12786v1"},"cats":{"benchmark":0.5039066409,"new-dataset":0.0048665824,"data-annotation":0.4971118536,"dev-research":0.2420563224,"llms":0.473627669,"data-quality":0.1238788172}}
{"text":"The main novelty of SYNPA is that it uses just three variables collected from the performance counters available in current ARM processors at the dispatch stage.","meta":{"url":"http://arxiv.org/abs/2310.12786v1"},"cats":{"benchmark":0.4037667802,"new-dataset":0.0506237646,"data-annotation":0.5018044654,"dev-research":0.2230377885,"llms":0.5158187105,"data-quality":0.0717977589}}
{"text":"Experimental results show that SYNPA outperforms the default Linux scheduler by around 36%, on average, in terms of turnaround time in 8-application workloads combining frontend bound and backend bound benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.12786v1"},"cats":{"benchmark":0.5519382075,"new-dataset":0.1162502033,"data-annotation":0.5016267193,"dev-research":0.2261402928,"llms":0.5341770119,"data-quality":0.0519251295}}
{"text":"While the accuracy-fairness trade-off has been frequently observed in the literature of fair machine learning, rigorous theoretical analyses have been scarce.","meta":{"url":"http://arxiv.org/abs/2310.12785v1"},"cats":{"benchmark":0.5656565104,"new-dataset":0.0111024502,"data-annotation":0.5294958459,"dev-research":0.1435152373,"llms":0.4648781871,"data-quality":0.2140173824}}
{"text":"To demystify this long-standing challenge, this work seeks to develop a theoretical framework by characterizing the shape of the accuracy-fairness trade-off","meta":{"url":"http://arxiv.org/abs/2310.12785v1"},"cats":{"benchmark":0.5582244738,"new-dataset":0.0139924985,"data-annotation":0.5079046329,"dev-research":0.1967190926,"llms":0.4804184382,"data-quality":0.2271103498}}
{"text":"Pareto frontier (FairFrontier), determined by a set of all optimal Pareto classifiers that no other classifiers can dominate.","meta":{"url":"http://arxiv.org/abs/2310.12785v1"},"cats":{"benchmark":0.4541996198,"new-dataset":0.0321360087,"data-annotation":0.5353658871,"dev-research":0.1144968803,"llms":0.4690061779,"data-quality":0.1684914666}}
{"text":"Specifically, we first demonstrate the existence of the trade-off in real-world scenarios and then propose four potential categories to characterize the important properties of the accuracy-fairness Pareto frontier.","meta":{"url":"http://arxiv.org/abs/2310.12785v1"},"cats":{"benchmark":0.5949901289,"new-dataset":0.0121526906,"data-annotation":0.5158639269,"dev-research":0.1417050609,"llms":0.4592034697,"data-quality":0.1896867779}}
{"text":"For each category, we identify the necessary conditions that lead to corresponding trade-offs.","meta":{"url":"http://arxiv.org/abs/2310.12785v1"},"cats":{"benchmark":0.3508647255,"new-dataset":0.0295817653,"data-annotation":0.5160943638,"dev-research":0.1783555107,"llms":0.4553308571,"data-quality":0.0998024521}}
{"text":"Experimental results on synthetic data suggest insightful findings of the proposed framework: (1) When sensitive attributes can be fully interpreted by non-sensitive attributes, FairFrontier is mostly continuous.","meta":{"url":"http://arxiv.org/abs/2310.12785v1"},"cats":{"benchmark":0.3807381055,"new-dataset":0.0591932645,"data-annotation":0.5101584799,"dev-research":0.2121528049,"llms":0.4862187661,"data-quality":0.1905203782}}
{"text":"(2) Accuracy can suffer a \\textit{sharp} decline when over-pursuing fairness.","meta":{"url":"http://arxiv.org/abs/2310.12785v1"},"cats":{"benchmark":0.6500291008,"new-dataset":0.0030647676,"data-annotation":0.5294185818,"dev-research":0.2015528173,"llms":0.4957106119,"data-quality":0.434457643}}
{"text":"(3) Eliminate the trade-off via a two-step streamlined approach.","meta":{"url":"http://arxiv.org/abs/2310.12785v1"},"cats":{"benchmark":0.5285720573,"new-dataset":0.0036108839,"data-annotation":0.4842824013,"dev-research":0.192422952,"llms":0.4019170145,"data-quality":0.0920385554}}
{"text":"The proposed research enables an in-depth understanding of the accuracy-fairness trade-off, pushing current fair machine-learning research to a new frontier.","meta":{"url":"http://arxiv.org/abs/2310.12785v1"},"cats":{"benchmark":0.5001538473,"new-dataset":0.0238877473,"data-annotation":0.5124896022,"dev-research":0.1638905248,"llms":0.5113763572,"data-quality":0.2389031219}}
{"text":"Prompt-based learning has shown its effectiveness in few-shot text classification.","meta":{"url":"http://arxiv.org/abs/2310.12778v1"},"cats":{"benchmark":0.2681415369,"new-dataset":0.0579444873,"data-annotation":0.5467750726,"dev-research":0.1629520141,"llms":0.5240396357,"data-quality":0.2429805984}}
{"text":"One important factor in its success is a verbalizer, which translates output from a language model into a predicted class.","meta":{"url":"http://arxiv.org/abs/2310.12778v1"},"cats":{"benchmark":0.3036125007,"new-dataset":0.0197036629,"data-annotation":0.5513441011,"dev-research":0.2999171474,"llms":0.4931236613,"data-quality":0.3126771639}}
{"text":"Notably, the simplest and widely acknowledged verbalizer employs manual labels to represent the classes.","meta":{"url":"http://arxiv.org/abs/2310.12778v1"},"cats":{"benchmark":0.261337599,"new-dataset":0.0172491345,"data-annotation":0.5379503088,"dev-research":0.2810812849,"llms":0.5806636287,"data-quality":0.4728040037}}
{"text":"However, manual selection does not guarantee the optimality of the selected words when conditioned on the chosen language model.","meta":{"url":"http://arxiv.org/abs/2310.12778v1"},"cats":{"benchmark":0.3602445024,"new-dataset":0.0022698012,"data-annotation":0.5248978981,"dev-research":0.1403366429,"llms":0.509694395,"data-quality":0.2322764134}}
{"text":"Therefore, we propose Label-Aware Automatic Verbalizer (LAAV), effectively augmenting the manual labels to achieve better few-shot classification results.","meta":{"url":"http://arxiv.org/abs/2310.12778v1"},"cats":{"benchmark":0.3023389755,"new-dataset":0.2101671669,"data-annotation":0.5494735722,"dev-research":0.2491718365,"llms":0.5288513515,"data-quality":0.5182870971}}
{"text":"Specifically, we use the manual labels along with the conjunction \"and\" to induce the model to generate more effective words for the verbalizer.","meta":{"url":"http://arxiv.org/abs/2310.12778v1"},"cats":{"benchmark":0.2717536455,"new-dataset":0.0204492973,"data-annotation":0.5108282827,"dev-research":0.3134188394,"llms":0.542312521,"data-quality":0.3684412887}}
{"text":"The experimental results on five datasets across five languages demonstrate that LAAV significantly outperforms existing verbalizers.","meta":{"url":"http://arxiv.org/abs/2310.12778v1"},"cats":{"benchmark":0.2932351139,"new-dataset":0.1388758764,"data-annotation":0.5470222222,"dev-research":0.2370858133,"llms":0.5285937057,"data-quality":0.2907465577}}
{"text":"Furthermore, our analysis reveals that LAAV suggests more relevant words compared to similar approaches, especially in mid-to-low resource languages.","meta":{"url":"http://arxiv.org/abs/2310.12778v1"},"cats":{"benchmark":0.3279786902,"new-dataset":0.059608119,"data-annotation":0.5499950146,"dev-research":0.2607312051,"llms":0.5467036604,"data-quality":0.1938885672}}
{"text":"Adiabatic quantum computing (AQC) is a promising quantum computing approach for discrete and often NP-hard optimization problems.","meta":{"url":"http://arxiv.org/abs/2310.12153v1"},"cats":{"benchmark":0.4223719889,"new-dataset":0.0076760766,"data-annotation":0.5162845218,"dev-research":0.123491953,"llms":0.4757583437,"data-quality":0.0481605169}}
{"text":"Current AQCs allow to implement problems of research interest, which has sparked the development of quantum representations for many machine learning and computer vision tasks.","meta":{"url":"http://arxiv.org/abs/2310.12153v1"},"cats":{"benchmark":0.1919381119,"new-dataset":0.0351324512,"data-annotation":0.5220239321,"dev-research":0.1608902612,"llms":0.5661326626,"data-quality":0.0662412814}}
{"text":"Despite requiring multiple measurements from the noisy AQC, current approaches only utilize the best measurement, discarding information contained in the remaining ones.","meta":{"url":"http://arxiv.org/abs/2310.12153v1"},"cats":{"benchmark":0.5610836596,"new-dataset":0.009015598,"data-annotation":0.4926289326,"dev-research":0.1628642712,"llms":0.4684960965,"data-quality":0.1827328929}}
{"text":"In this work, we explore the potential of using this information for probabilistic balanced k-means clustering.","meta":{"url":"http://arxiv.org/abs/2310.12153v1"},"cats":{"benchmark":0.4651703376,"new-dataset":0.0650141345,"data-annotation":0.5395405594,"dev-research":0.1391605604,"llms":0.4389487068,"data-quality":0.1819734991}}
{"text":"Instead of discarding non-optimal solutions, we propose to use them to compute calibrated posterior probabilities with little additional compute cost.","meta":{"url":"http://arxiv.org/abs/2310.12153v1"},"cats":{"benchmark":0.5809021904,"new-dataset":0.0368201665,"data-annotation":0.538354981,"dev-research":0.1480221528,"llms":0.4540671009,"data-quality":0.1467864715}}
{"text":"This allows us to identify ambiguous solutions and data points, which we demonstrate on a D-Wave AQC on synthetic and real data.","meta":{"url":"http://arxiv.org/abs/2310.12153v1"},"cats":{"benchmark":0.3145942182,"new-dataset":0.1779187145,"data-annotation":0.4824451105,"dev-research":0.1394629457,"llms":0.4267552343,"data-quality":0.1182981947}}
{"text":"Long-tailed object detection (LTOD) aims to handle the extreme data imbalance in real-world datasets, where many tail classes have scarce instances.","meta":{"url":"http://arxiv.org/abs/2310.12152v1"},"cats":{"benchmark":0.3136271931,"new-dataset":0.2441773799,"data-annotation":0.5144717003,"dev-research":0.1028170713,"llms":0.482773065,"data-quality":0.1524023364}}
{"text":"One popular strategy is to explore extra data with image-level labels, yet it produces limited results due to (1) semantic ambiguity -- an image-level label only captures a salient part of the image, ignoring the remaining rich semantics within the image; and (2) location sensitivity -- the label highly depends on the locations and crops of the original image, which may change after data transformations like random cropping.","meta":{"url":"http://arxiv.org/abs/2310.12152v1"},"cats":{"benchmark":0.3211019689,"new-dataset":0.1151794903,"data-annotation":0.4966800405,"dev-research":0.1363400931,"llms":0.5024144388,"data-quality":0.366420332}}
{"text":"To remedy this, we propose RichSem, a simple but effective method, which is robust to learn rich semantics from coarse locations without the need of accurate bounding boxes.","meta":{"url":"http://arxiv.org/abs/2310.12152v1"},"cats":{"benchmark":0.3171615592,"new-dataset":0.2867512518,"data-annotation":0.5544323487,"dev-research":0.2064058536,"llms":0.5875616744,"data-quality":0.2561379454}}
{"text":"RichSem leverages rich semantics from images, which are then served as additional soft supervision for training detectors.","meta":{"url":"http://arxiv.org/abs/2310.12152v1"},"cats":{"benchmark":0.1991293368,"new-dataset":0.1080089383,"data-annotation":0.5393684213,"dev-research":0.173242297,"llms":0.621532162,"data-quality":0.3020698859}}
{"text":"Specifically, we add a semantic branch to our detector to learn these soft semantics and enhance feature representations for long-tailed object detection.","meta":{"url":"http://arxiv.org/abs/2310.12152v1"},"cats":{"benchmark":0.2356996094,"new-dataset":0.1970088088,"data-annotation":0.5468937018,"dev-research":0.1861840049,"llms":0.5202295719,"data-quality":0.2264799447}}
{"text":"The semantic branch is only used for training and is removed during inference.","meta":{"url":"http://arxiv.org/abs/2310.12152v1"},"cats":{"benchmark":0.1917726162,"new-dataset":0.0074023811,"data-annotation":0.4990965313,"dev-research":0.1817487552,"llms":0.5872489062,"data-quality":0.1871682786}}
{"text":"RichSem achieves consistent improvements on both overall and rare-category of LVIS under different backbones and detectors.","meta":{"url":"http://arxiv.org/abs/2310.12152v1"},"cats":{"benchmark":0.3582565915,"new-dataset":0.0842288455,"data-annotation":0.5015538578,"dev-research":0.0897986268,"llms":0.6478460126,"data-quality":0.1293806341}}
{"text":"Our method achieves state-of-the-art performance without requiring complex training and testing procedures.","meta":{"url":"http://arxiv.org/abs/2310.12152v1"},"cats":{"benchmark":0.5926920873,"new-dataset":0.0103964854,"data-annotation":0.5207829657,"dev-research":0.1700265606,"llms":0.5098622451,"data-quality":0.0945502146}}
{"text":"Moreover, we show the effectiveness of our method on other long-tailed datasets with additional experiments.","meta":{"url":"http://arxiv.org/abs/2310.12152v1"},"cats":{"benchmark":0.6404900934,"new-dataset":0.3666830612,"data-annotation":0.5410980269,"dev-research":0.1016038814,"llms":0.3972990247,"data-quality":0.1634900423}}
{"text":"Code is available at \\url{https://github.com/MengLcool/RichSem}.","meta":{"url":"http://arxiv.org/abs/2310.12152v1"},"cats":{"benchmark":0.297216835,"new-dataset":0.0887305738,"data-annotation":0.5186581987,"dev-research":0.1529836242,"llms":0.616777316,"data-quality":0.1210608009}}
{"text":"We present a study of retrieval-augmented language models (LMs) on long-form question answering.","meta":{"url":"http://arxiv.org/abs/2310.12150v1"},"cats":{"benchmark":0.3064591195,"new-dataset":0.0988409085,"data-annotation":0.5471488014,"dev-research":0.1258996935,"llms":0.5724217504,"data-quality":0.1051054075}}
{"text":"We analyze how retrieval augmentation impacts different LMs, by comparing answers generated from models while using the same evidence documents, and how differing quality of retrieval document set impacts the answers generated from the same LM.","meta":{"url":"http://arxiv.org/abs/2310.12150v1"},"cats":{"benchmark":0.4650810177,"new-dataset":0.0150010031,"data-annotation":0.5143650354,"dev-research":0.1573633936,"llms":0.5871673046,"data-quality":0.2149479941}}
{"text":"We study various attributes of generated answers (e.g., fluency, length, variance) with an emphasis on the attribution of generated long-form answers to in-context evidence documents.","meta":{"url":"http://arxiv.org/abs/2310.12150v1"},"cats":{"benchmark":0.2979481363,"new-dataset":0.141584397,"data-annotation":0.5528066223,"dev-research":0.2329274375,"llms":0.5523435598,"data-quality":0.1430443854}}
{"text":"We collect human annotations of answer attribution and evaluate methods for automatically judging attribution.","meta":{"url":"http://arxiv.org/abs/2310.12150v1"},"cats":{"benchmark":0.3492502813,"new-dataset":0.1933059583,"data-annotation":0.5758508147,"dev-research":0.288120437,"llms":0.5658039121,"data-quality":0.3471348284}}
{"text":"Our study provides new insights on how retrieval augmentation impacts long, knowledge-rich text generation of LMs.","meta":{"url":"http://arxiv.org/abs/2310.12150v1"},"cats":{"benchmark":0.3341771017,"new-dataset":0.0347601007,"data-annotation":0.5087532096,"dev-research":0.163638586,"llms":0.6496209858,"data-quality":0.1803946808}}
{"text":"We further identify attribution patterns for long text generation and analyze the main culprits of attribution errors.","meta":{"url":"http://arxiv.org/abs/2310.12150v1"},"cats":{"benchmark":0.3101607474,"new-dataset":0.2155031815,"data-annotation":0.543444278,"dev-research":0.2937112007,"llms":0.5671316202,"data-quality":0.4860444071}}
{"text":"Together, our analysis reveals how retrieval augmentation impacts long knowledge-rich text generation and provide directions for future work.","meta":{"url":"http://arxiv.org/abs/2310.12150v1"},"cats":{"benchmark":0.343047287,"new-dataset":0.0801702417,"data-annotation":0.5262192438,"dev-research":0.2488507017,"llms":0.5949153246,"data-quality":0.1645564777}}
{"text":"By comparing the original and target prompts in editing task, we can obtain numerous editing pairs, each comprising an object and its corresponding editing target.","meta":{"url":"http://arxiv.org/abs/2310.12149v1"},"cats":{"benchmark":0.4694000932,"new-dataset":0.1092263128,"data-annotation":0.5322522802,"dev-research":0.3328073662,"llms":0.5068763931,"data-quality":0.1674002318}}
{"text":"To allow editability while maintaining fidelity to the input image, existing editing methods typically involve a fixed number of inversion steps that project the whole input image to its noisier latent representation, followed by a denoising process guided by the target prompt.","meta":{"url":"http://arxiv.org/abs/2310.12149v1"},"cats":{"benchmark":0.3693999034,"new-dataset":0.0098587516,"data-annotation":0.502806005,"dev-research":0.2514529178,"llms":0.4593459314,"data-quality":0.1516935829}}
{"text":"However, we find that the optimal number of inversion steps for achieving ideal editing results varies significantly among different editing pairs, owing to varying editing difficulties.","meta":{"url":"http://arxiv.org/abs/2310.12149v1"},"cats":{"benchmark":0.5580764025,"new-dataset":0.0203258192,"data-annotation":0.5251197355,"dev-research":0.2953259878,"llms":0.4525069979,"data-quality":0.1365925055}}
{"text":"Therefore, the current literature, which relies on a fixed number of inversion steps, produces sub-optimal generation quality, especially when handling multiple editing pairs in a natural image.","meta":{"url":"http://arxiv.org/abs/2310.12149v1"},"cats":{"benchmark":0.458322707,"new-dataset":0.03436307,"data-annotation":0.5217753253,"dev-research":0.2248864368,"llms":0.4841284732,"data-quality":0.1254207413}}
{"text":"To this end, we propose a new image editing paradigm, dubbed Object-aware Inversion and Reassembly (OIR), to enable object-level fine-grained editing.","meta":{"url":"http://arxiv.org/abs/2310.12149v1"},"cats":{"benchmark":0.2718355989,"new-dataset":0.1048121234,"data-annotation":0.4945921987,"dev-research":0.24992791,"llms":0.5395415718,"data-quality":0.1405363767}}
{"text":"Specifically, we design a new search metric, which determines the optimal inversion steps for each editing pair, by jointly considering the editability of the target and the fidelity of the non-editing region.","meta":{"url":"http://arxiv.org/abs/2310.12149v1"},"cats":{"benchmark":0.6059103105,"new-dataset":0.0189901955,"data-annotation":0.5288787086,"dev-research":0.2077576886,"llms":0.447196082,"data-quality":0.155647598}}
{"text":"We use our search metric to find the optimal inversion step for each editing pair when editing an image.","meta":{"url":"http://arxiv.org/abs/2310.12149v1"},"cats":{"benchmark":0.6007721573,"new-dataset":0.0577005528,"data-annotation":0.5392747645,"dev-research":0.1935551291,"llms":0.3924517603,"data-quality":0.1091071631}}
{"text":"We then edit these editing pairs separately to avoid concept mismatch.","meta":{"url":"http://arxiv.org/abs/2310.12149v1"},"cats":{"benchmark":0.3410027563,"new-dataset":0.0264442526,"data-annotation":0.5214002491,"dev-research":0.353641848,"llms":0.4991874348,"data-quality":0.2688521639}}
{"text":"Subsequently, we propose an additional reassembly step to seamlessly integrate the respective editing results and the non-editing region to obtain the final edited image.","meta":{"url":"http://arxiv.org/abs/2310.12149v1"},"cats":{"benchmark":0.4674780299,"new-dataset":0.1460567365,"data-annotation":0.4836578723,"dev-research":0.231165199,"llms":0.4771454643,"data-quality":0.1176328119}}
{"text":"To systematically evaluate the effectiveness of our method, we collect two datasets for benchmarking single- and multi-object editing, respectively.","meta":{"url":"http://arxiv.org/abs/2310.12149v1"},"cats":{"benchmark":0.5682266252,"new-dataset":0.1711911062,"data-annotation":0.5219025108,"dev-research":0.3482746297,"llms":0.4817719368,"data-quality":0.2200763267}}
{"text":"Experiments demonstrate that our method achieves superior performance in editing object shapes, colors, materials, categories, etc., especially in multi-object editing scenarios.","meta":{"url":"http://arxiv.org/abs/2310.12149v1"},"cats":{"benchmark":0.4351994288,"new-dataset":0.0236984353,"data-annotation":0.5299240319,"dev-research":0.3452733275,"llms":0.5087395285,"data-quality":0.1157708411}}
{"text":"Ambiguity is ubiquitous in human communication.","meta":{"url":"http://arxiv.org/abs/2310.12147v1"},"cats":{"benchmark":0.188872209,"new-dataset":0.0072419942,"data-annotation":0.5032072273,"dev-research":0.283986123,"llms":0.5374031378,"data-quality":0.2636604024}}
{"text":"Previous approaches in Human-Robot Interaction (HRI) have often relied on predefined interaction templates, leading to reduced performance in realistic and open-ended scenarios.","meta":{"url":"http://arxiv.org/abs/2310.12147v1"},"cats":{"benchmark":0.3599028565,"new-dataset":0.0442413809,"data-annotation":0.5197587552,"dev-research":0.3760230345,"llms":0.4646991978,"data-quality":0.0402294706}}
{"text":"To address these issues, we present a large-scale dataset, \\invig, for interactive visual grounding under language ambiguity.","meta":{"url":"http://arxiv.org/abs/2310.12147v1"},"cats":{"benchmark":0.1793777221,"new-dataset":0.8250422949,"data-annotation":0.5152974602,"dev-research":0.2928535526,"llms":0.5428418632,"data-quality":0.314604558}}
{"text":"Our dataset comprises over 520K images accompanied by open-ended goal-oriented disambiguation dialogues, encompassing millions of object instances and corresponding question-answer pairs.","meta":{"url":"http://arxiv.org/abs/2310.12147v1"},"cats":{"benchmark":0.1982489761,"new-dataset":0.7552255306,"data-annotation":0.5185374121,"dev-research":0.2031009879,"llms":0.5580669785,"data-quality":0.1391724396}}
{"text":"Leveraging the \\invig dataset, we conduct extensive studies and propose a set of baseline solutions for end-to-end interactive visual disambiguation and grounding, achieving a 45.6\\% success rate during validation.","meta":{"url":"http://arxiv.org/abs/2310.12147v1"},"cats":{"benchmark":0.3504376846,"new-dataset":0.5221320245,"data-annotation":0.5047172847,"dev-research":0.3288404644,"llms":0.5491345341,"data-quality":0.2552600006}}
{"text":"To the best of our knowledge, the \\invig dataset is the first large-scale dataset for resolving open-ended interactive visual grounding, presenting a practical yet highly challenging benchmark for ambiguity-aware HRI.","meta":{"url":"http://arxiv.org/abs/2310.12147v1"},"cats":{"benchmark":0.2695382203,"new-dataset":0.7020472558,"data-annotation":0.4961695191,"dev-research":0.3047250726,"llms":0.5081815771,"data-quality":0.1988792723}}
{"text":"Codes and datasets are available at: \\href{https://openivg.github.io}{https://openivg.github.io}.","meta":{"url":"http://arxiv.org/abs/2310.12147v1"},"cats":{"benchmark":0.2441175485,"new-dataset":0.5844532333,"data-annotation":0.5097699389,"dev-research":0.1637704363,"llms":0.5074981612,"data-quality":0.1158602192}}
{"text":"Making models algorithmically fairer in tabular data has been long studied, with techniques typically oriented towards fixes which usually take a neural model with an undesirable outcome and make changes to how the data are ingested, what the model weights are, or how outputs are processed.","meta":{"url":"http://arxiv.org/abs/2310.12145v1"},"cats":{"benchmark":0.4694465583,"new-dataset":0.0143138802,"data-annotation":0.4889067829,"dev-research":0.2139380853,"llms":0.4622972953,"data-quality":0.1847619899}}
{"text":"We employ an emergent and different strategy where we consider updating the model's architecture and training hyperparameters to find an entirely new model with better outcomes from the beginning of the debiasing procedure.","meta":{"url":"http://arxiv.org/abs/2310.12145v1"},"cats":{"benchmark":0.4744987411,"new-dataset":0.055238938,"data-annotation":0.5202726058,"dev-research":0.1777095764,"llms":0.4787663347,"data-quality":0.1680608747}}
{"text":"In this work, we propose using multi-objective Neural Architecture Search (NAS) and Hyperparameter Optimization (HPO) in the first application to the very challenging domain of tabular data.","meta":{"url":"http://arxiv.org/abs/2310.12145v1"},"cats":{"benchmark":0.4275431692,"new-dataset":0.02834118,"data-annotation":0.496269741,"dev-research":0.1106447121,"llms":0.4362969647,"data-quality":0.0826879936}}
{"text":"We conduct extensive exploration of architectural and hyperparameter spaces (MLP, ResNet, and FT-Transformer) across diverse datasets, demonstrating the dependence of accuracy and fairness metrics of model predictions on hyperparameter combinations.","meta":{"url":"http://arxiv.org/abs/2310.12145v1"},"cats":{"benchmark":0.4412613965,"new-dataset":0.0563346189,"data-annotation":0.5011080898,"dev-research":0.1553205384,"llms":0.4782205404,"data-quality":0.1062194862}}
{"text":"We show that models optimized solely for accuracy with NAS often fail to inherently address fairness concerns.","meta":{"url":"http://arxiv.org/abs/2310.12145v1"},"cats":{"benchmark":0.5172787428,"new-dataset":0.010531055,"data-annotation":0.4953401606,"dev-research":0.1469590537,"llms":0.5385322172,"data-quality":0.1968864928}}
{"text":"We propose a novel approach that jointly optimizes architectural and training hyperparameters in a multi-objective constraint of both accuracy and fairness.","meta":{"url":"http://arxiv.org/abs/2310.12145v1"},"cats":{"benchmark":0.5840647934,"new-dataset":0.0124430613,"data-annotation":0.5193706764,"dev-research":0.1967862918,"llms":0.4835539957,"data-quality":0.1611753802}}
{"text":"We produce architectures that consistently Pareto dominate state-of-the-art bias mitigation methods either in fairness, accuracy or both, all of this while being Pareto-optimal over hyperparameters achieved through single-objective (accuracy) optimization runs.","meta":{"url":"http://arxiv.org/abs/2310.12145v1"},"cats":{"benchmark":0.6358840686,"new-dataset":0.0049888545,"data-annotation":0.5175274934,"dev-research":0.1517749907,"llms":0.4937155531,"data-quality":0.1687641823}}
{"text":"This research underscores the promise of automating fairness and accuracy optimization in deep learning models.","meta":{"url":"http://arxiv.org/abs/2310.12145v1"},"cats":{"benchmark":0.4213438161,"new-dataset":0.0220603305,"data-annotation":0.5197576437,"dev-research":0.1666860967,"llms":0.4665947607,"data-quality":0.2079253006}}
{"text":"Deep networks typically learn concepts via classifiers, which involves setting up a model and training it via gradient descent to fit the concept-labeled data.","meta":{"url":"http://arxiv.org/abs/2310.12143v1"},"cats":{"benchmark":0.1404817002,"new-dataset":0.0403662174,"data-annotation":0.5195737072,"dev-research":0.2568597464,"llms":0.5159836043,"data-quality":0.2795547289}}
{"text":"We will argue instead that learning a concept could be done by looking at its moment statistics matrix to generate a concrete representation or signature of that concept.","meta":{"url":"http://arxiv.org/abs/2310.12143v1"},"cats":{"benchmark":0.1950327113,"new-dataset":0.0164975454,"data-annotation":0.5521117106,"dev-research":0.1553731389,"llms":0.4546988681,"data-quality":0.1117111749}}
{"text":"These signatures can be used to discover structure across the set of concepts and could recursively produce higher-level concepts by learning this structure from those signatures.","meta":{"url":"http://arxiv.org/abs/2310.12143v1"},"cats":{"benchmark":0.2474442527,"new-dataset":0.0826714783,"data-annotation":0.5272032359,"dev-research":0.2334988036,"llms":0.5450715136,"data-quality":0.1482553902}}
{"text":"When the concepts are `intersected', signatures of the concepts can be used to find a common theme across a number of related `intersected' concepts.","meta":{"url":"http://arxiv.org/abs/2310.12143v1"},"cats":{"benchmark":0.2707660122,"new-dataset":0.100170681,"data-annotation":0.5202243033,"dev-research":0.2768222651,"llms":0.5489896374,"data-quality":0.1613012971}}
{"text":"This process could be used to keep a dictionary of concepts so that inputs could correctly identify and be routed to the set of concepts involved in the (latent) generation of the input.","meta":{"url":"http://arxiv.org/abs/2310.12143v1"},"cats":{"benchmark":0.1452138816,"new-dataset":0.013434841,"data-annotation":0.508032738,"dev-research":0.3338953712,"llms":0.585920996,"data-quality":0.1784295082}}
{"text":"With large language models surpassing human performance on an increasing number of benchmarks, we must take a principled approach for targeted evaluation of model capabilities.","meta":{"url":"http://arxiv.org/abs/2310.12135v1"},"cats":{"benchmark":0.4854305341,"new-dataset":0.0317694488,"data-annotation":0.5537332741,"dev-research":0.2017240765,"llms":0.5135685438,"data-quality":0.1181443876}}
{"text":"Inspired by pseudorandomness, we propose pseudointelligence, which captures the maxim that \"(perceived) intelligence lies in the eye of the beholder\".","meta":{"url":"http://arxiv.org/abs/2310.12135v1"},"cats":{"benchmark":0.2162341333,"new-dataset":0.0237944993,"data-annotation":0.5469494833,"dev-research":0.1957844699,"llms":0.4352666539,"data-quality":0.139986154}}
{"text":"That is, that claims of intelligence are meaningful only when their evaluator is taken into account.","meta":{"url":"http://arxiv.org/abs/2310.12135v1"},"cats":{"benchmark":0.3202475246,"new-dataset":0.0084770107,"data-annotation":0.5395390663,"dev-research":0.2840443516,"llms":0.5197458385,"data-quality":0.2421007992}}
{"text":"Concretely, we propose a complexity-theoretic framework of model evaluation cast as a dynamic interaction between a model and a learned evaluator.","meta":{"url":"http://arxiv.org/abs/2310.12135v1"},"cats":{"benchmark":0.3588481945,"new-dataset":0.0080165123,"data-annotation":0.5403960416,"dev-research":0.2587101548,"llms":0.4658818531,"data-quality":0.1064353843}}
{"text":"We demonstrate that this framework can be used to reason about two case studies in language model evaluation, as well as analyze existing evaluation methods.","meta":{"url":"http://arxiv.org/abs/2310.12135v1"},"cats":{"benchmark":0.5084950701,"new-dataset":0.0152932798,"data-annotation":0.5565069698,"dev-research":0.3076495438,"llms":0.5297310184,"data-quality":0.3104414603}}
{"text":"The correctness of software systems is vital for their effective operation.","meta":{"url":"http://arxiv.org/abs/2310.12133v1"},"cats":{"benchmark":0.4201709004,"new-dataset":0.0109176056,"data-annotation":0.4918856152,"dev-research":0.5051859932,"llms":0.5854748133,"data-quality":0.2577118217}}
{"text":"It makes discovering and fixing software bugs an important development task.","meta":{"url":"http://arxiv.org/abs/2310.12133v1"},"cats":{"benchmark":0.2909807575,"new-dataset":0.0378149569,"data-annotation":0.5215493624,"dev-research":0.6705774051,"llms":0.557375038,"data-quality":0.2182883527}}
{"text":"The increasing use of Artificial Intelligence (AI) techniques in Software Engineering led to the development of a number of techniques that can assist software developers in identifying potential bugs in code.","meta":{"url":"http://arxiv.org/abs/2310.12133v1"},"cats":{"benchmark":0.3034335146,"new-dataset":0.0345910263,"data-annotation":0.5509490249,"dev-research":0.7077454155,"llms":0.4826460313,"data-quality":0.4134150025}}
{"text":"In this paper, we present a comprehensible comparison and analysis of the efficacy of two AI-based approaches, namely single AI models and ensemble AI models, for predicting the probability of a Java class being buggy.","meta":{"url":"http://arxiv.org/abs/2310.12133v1"},"cats":{"benchmark":0.4629690968,"new-dataset":0.0180397812,"data-annotation":0.5567015928,"dev-research":0.3810724402,"llms":0.4783557485,"data-quality":0.3412481443}}
{"text":"We used two open-source Apache Commons Project's Java components for training and evaluating the models.","meta":{"url":"http://arxiv.org/abs/2310.12133v1"},"cats":{"benchmark":0.3460773688,"new-dataset":0.262867157,"data-annotation":0.5351865548,"dev-research":0.201927097,"llms":0.5699344137,"data-quality":0.1484447382}}
{"text":"Our experimental findings indicate that the ensemble of AI models can outperform the results of applying individual AI models.","meta":{"url":"http://arxiv.org/abs/2310.12133v1"},"cats":{"benchmark":0.4686660875,"new-dataset":0.0070716009,"data-annotation":0.5506947592,"dev-research":0.2036444386,"llms":0.3932851387,"data-quality":0.1858397489}}
{"text":"We also offer insight into the factors that contribute to the enhanced performance of the ensemble AI model.","meta":{"url":"http://arxiv.org/abs/2310.12133v1"},"cats":{"benchmark":0.5097281737,"new-dataset":0.0179875988,"data-annotation":0.5491480325,"dev-research":0.1745043435,"llms":0.4072011955,"data-quality":0.1077319708}}
{"text":"The presented results demonstrate the potential of using ensemble AI models to enhance bug prediction results, which could ultimately result in more reliable software systems.","meta":{"url":"http://arxiv.org/abs/2310.12133v1"},"cats":{"benchmark":0.4834876823,"new-dataset":0.0695424253,"data-annotation":0.5373084758,"dev-research":0.5202667174,"llms":0.4754884703,"data-quality":0.4225645711}}
{"text":"Flaky tests are tests that nondeterministically pass and fail in unchanged code.","meta":{"url":"http://arxiv.org/abs/2310.12132v1"},"cats":{"benchmark":0.3868650957,"new-dataset":0.0315520019,"data-annotation":0.5247074277,"dev-research":0.3101015259,"llms":0.5417475423,"data-quality":0.2708103527}}
{"text":"These tests can be detrimental to developers' productivity.","meta":{"url":"http://arxiv.org/abs/2310.12132v1"},"cats":{"benchmark":0.4358446693,"new-dataset":0.0275919195,"data-annotation":0.5255327167,"dev-research":0.6302102783,"llms":0.5214634974,"data-quality":0.2056266105}}
{"text":"Particularly when tests run in continuous integration environments, the tests may be competing for access to limited computational resources (CPUs, memory etc.), and we hypothesize that resource (in)availability may be a significant factor in the failure rate of flaky tests.","meta":{"url":"http://arxiv.org/abs/2310.12132v1"},"cats":{"benchmark":0.4686259656,"new-dataset":0.0119804646,"data-annotation":0.4932393085,"dev-research":0.2962016754,"llms":0.5161306716,"data-quality":0.1186128071}}
{"text":"We present the first assessment of the impact that computational resources have on flaky tests, including a total of 52 projects written in Java, JavaScript and Python, and 27 different resource configurations.","meta":{"url":"http://arxiv.org/abs/2310.12132v1"},"cats":{"benchmark":0.4488888103,"new-dataset":0.1122251386,"data-annotation":0.5225713217,"dev-research":0.4057864163,"llms":0.5450637361,"data-quality":0.1059012412}}
{"text":"Using a rigorous statistical methodology, we determine which tests are RAFT (Resource-Affected Flaky Tests).","meta":{"url":"http://arxiv.org/abs/2310.12132v1"},"cats":{"benchmark":0.58659912,"new-dataset":0.0266887004,"data-annotation":0.5296067427,"dev-research":0.1867056596,"llms":0.4452519338,"data-quality":0.2075845755}}
{"text":"We find that 46.5% of the flaky tests in our dataset are RAFT, indicating that a substantial proportion of flaky-test failures can be avoided by adjusting the resources available when running tests.","meta":{"url":"http://arxiv.org/abs/2310.12132v1"},"cats":{"benchmark":0.5413718239,"new-dataset":0.1195951011,"data-annotation":0.5128438987,"dev-research":0.2875263354,"llms":0.4953951044,"data-quality":0.3353685007}}
{"text":"We report RAFTs and configurations to avoid them to developers, and received interest to either fix the RAFTs or to improve the specifications of the projects so that tests would be run only in configurations that are unlikely to encounter RAFT failures.","meta":{"url":"http://arxiv.org/abs/2310.12132v1"},"cats":{"benchmark":0.3786135049,"new-dataset":0.0974834617,"data-annotation":0.5141299982,"dev-research":0.4539899301,"llms":0.5744442928,"data-quality":0.2427315726}}
{"text":"Our results also have implications for researchers attempting to detect flaky tests, e.g., reducing the resources available when running tests is a cost-effective approach to detect more flaky failures.","meta":{"url":"http://arxiv.org/abs/2310.12132v1"},"cats":{"benchmark":0.6039051749,"new-dataset":0.0196136919,"data-annotation":0.5245762176,"dev-research":0.3897699366,"llms":0.4973716481,"data-quality":0.31723244}}
{"text":"The escalating number of pending cases is a growing concern world-wide.","meta":{"url":"http://arxiv.org/abs/2310.12131v1"},"cats":{"benchmark":0.3089924278,"new-dataset":0.0416111958,"data-annotation":0.4944862785,"dev-research":0.2350494773,"llms":0.5628238154,"data-quality":0.0759015293}}
{"text":"Recent advancements in digitization have opened up possibilities for leveraging artificial intelligence (AI) tools in the processing of legal documents.","meta":{"url":"http://arxiv.org/abs/2310.12131v1"},"cats":{"benchmark":0.3459917401,"new-dataset":0.0539956552,"data-annotation":0.4991649359,"dev-research":0.2068801087,"llms":0.5114084449,"data-quality":0.2161287548}}
{"text":"Adopting a structured representation for legal documents, as opposed to a mere bag-of-words flat text representation, can significantly enhance processing capabilities.","meta":{"url":"http://arxiv.org/abs/2310.12131v1"},"cats":{"benchmark":0.3799201051,"new-dataset":0.0609555379,"data-annotation":0.4878388368,"dev-research":0.2399590292,"llms":0.5508249865,"data-quality":0.2163468062}}
{"text":"With the aim of achieving this objective, we put forward a set of diverse attributes for criminal case proceedings.","meta":{"url":"http://arxiv.org/abs/2310.12131v1"},"cats":{"benchmark":0.3661092893,"new-dataset":0.1632710174,"data-annotation":0.5017110079,"dev-research":0.1658050939,"llms":0.5375675033,"data-quality":0.0913256669}}
{"text":"We use a state-of-the-art sequence labeling framework to automatically extract attributes from the legal documents.","meta":{"url":"http://arxiv.org/abs/2310.12131v1"},"cats":{"benchmark":0.4348772831,"new-dataset":0.5079354175,"data-annotation":0.5026732668,"dev-research":0.215530947,"llms":0.5480404263,"data-quality":0.4285785786}}
{"text":"Moreover, we demonstrate the efficacy of the extracted attributes in a downstream task, namely legal judgment prediction.","meta":{"url":"http://arxiv.org/abs/2310.12131v1"},"cats":{"benchmark":0.4476516896,"new-dataset":0.0212311637,"data-annotation":0.5122519773,"dev-research":0.233276439,"llms":0.4770406153,"data-quality":0.185456565}}
{"text":"Text-to-image (T2I) generation has seen significant growth over the past few years.","meta":{"url":"http://arxiv.org/abs/2310.12128v1"},"cats":{"benchmark":0.2139818338,"new-dataset":0.2104491691,"data-annotation":0.5103434128,"dev-research":0.1881739096,"llms":0.6013578328,"data-quality":0.1388083905}}
{"text":"Despite this, there has been little work on generating diagrams with T2I models.","meta":{"url":"http://arxiv.org/abs/2310.12128v1"},"cats":{"benchmark":0.1879081914,"new-dataset":0.0846666829,"data-annotation":0.5260219804,"dev-research":0.1806067476,"llms":0.6372986777,"data-quality":0.0750347817}}
{"text":"A diagram is a symbolic/schematic representation that explains information using structurally rich and spatially complex visualizations (e.g., a dense combination of related objects, text labels, directional arrows, connection lines, etc.).","meta":{"url":"http://arxiv.org/abs/2310.12128v1"},"cats":{"benchmark":0.1248282944,"new-dataset":0.1016397908,"data-annotation":0.5045997905,"dev-research":0.3965440018,"llms":0.525412664,"data-quality":0.0889298426}}
{"text":"Existing state-of-the-art T2I models often fail at diagram generation because they lack fine-grained object layout control when many objects are densely connected via complex relations such as arrows/lines and also often fail to render comprehensible text labels.","meta":{"url":"http://arxiv.org/abs/2310.12128v1"},"cats":{"benchmark":0.2024421553,"new-dataset":0.1007902921,"data-annotation":0.5196813929,"dev-research":0.2773576298,"llms":0.6202565878,"data-quality":0.1550404915}}
{"text":"To address this gap, we present DiagrammerGPT, a novel two-stage text-to-diagram generation framework that leverages the layout guidance capabilities of LLMs (e.g., GPT-4) to generate more accurate open-domain, open-platform diagrams.","meta":{"url":"http://arxiv.org/abs/2310.12128v1"},"cats":{"benchmark":0.1976260078,"new-dataset":0.3087537354,"data-annotation":0.4864655137,"dev-research":0.2944470887,"llms":0.7149695632,"data-quality":0.0838895166}}
{"text":"In the first stage, we use LLMs to generate and iteratively refine 'diagram plans' (in a planner-auditor feedback loop) which describe all the entities (objects and text labels), their relationships (arrows or lines), and their bounding box layouts.","meta":{"url":"http://arxiv.org/abs/2310.12128v1"},"cats":{"benchmark":0.196809697,"new-dataset":0.2521614343,"data-annotation":0.4836986455,"dev-research":0.3528971402,"llms":0.673363571,"data-quality":0.0820914205}}
{"text":"In the second stage, we use a diagram generator, DiagramGLIGEN, and a text label rendering module to generate diagrams following the diagram plans.","meta":{"url":"http://arxiv.org/abs/2310.12128v1"},"cats":{"benchmark":0.1793690256,"new-dataset":0.4466190633,"data-annotation":0.5044170383,"dev-research":0.3276741544,"llms":0.6083702307,"data-quality":0.1147944996}}
{"text":"To benchmark the text-to-diagram generation task, we introduce AI2D-Caption, a densely annotated diagram dataset built on top of the AI2D dataset.","meta":{"url":"http://arxiv.org/abs/2310.12128v1"},"cats":{"benchmark":0.2995861843,"new-dataset":0.8377555881,"data-annotation":0.524112985,"dev-research":0.3034604776,"llms":0.5603344626,"data-quality":0.215560091}}
{"text":"We show quantitatively and qualitatively that our DiagrammerGPT framework produces more accurate diagrams, outperforming existing T2I models.","meta":{"url":"http://arxiv.org/abs/2310.12128v1"},"cats":{"benchmark":0.3403875027,"new-dataset":0.0740824908,"data-annotation":0.5184027648,"dev-research":0.2197393681,"llms":0.5564814587,"data-quality":0.0919039342}}
{"text":"We also provide comprehensive analysis including open-domain diagram generation, vector graphic diagram generation in different platforms, human-in-the-loop diagram plan editing, and multimodal planner/auditor LLMs (e.g., GPT-4Vision).","meta":{"url":"http://arxiv.org/abs/2310.12128v1"},"cats":{"benchmark":0.1875876147,"new-dataset":0.3740341467,"data-annotation":0.4981594649,"dev-research":0.3921215499,"llms":0.6104829606,"data-quality":0.0408123875}}
{"text":"We hope our work can inspire further research on diagram generation via T2I models and LLMs.","meta":{"url":"http://arxiv.org/abs/2310.12128v1"},"cats":{"benchmark":0.1865944967,"new-dataset":0.1383025257,"data-annotation":0.5234824768,"dev-research":0.1709990491,"llms":0.7215000572,"data-quality":0.0605272877}}
{"text":"Recent instruction fine-tuned models can solve multiple NLP tasks when prompted to do so, with machine translation (MT) being a prominent use case.","meta":{"url":"http://arxiv.org/abs/2310.12127v1"},"cats":{"benchmark":0.2910143683,"new-dataset":0.0444171647,"data-annotation":0.5117004158,"dev-research":0.2213810089,"llms":0.5497873922,"data-quality":0.1622756168}}
{"text":"However, current research often focuses on standard performance benchmarks, leaving compelling fairness and ethical considerations behind.","meta":{"url":"http://arxiv.org/abs/2310.12127v1"},"cats":{"benchmark":0.7303672441,"new-dataset":0.0046011829,"data-annotation":0.4916425667,"dev-research":0.2578602463,"llms":0.5128568151,"data-quality":0.0936601164}}
{"text":"In MT, this might lead to misgendered translations, resulting, among other harms, in the perpetuation of stereotypes and prejudices.","meta":{"url":"http://arxiv.org/abs/2310.12127v1"},"cats":{"benchmark":0.193472426,"new-dataset":0.0195859233,"data-annotation":0.5359684957,"dev-research":0.254176564,"llms":0.5766027632,"data-quality":0.3931069673}}
{"text":"In this work, we address this gap by investigating whether and to what extent such models exhibit gender bias in machine translation and how we can mitigate it.","meta":{"url":"http://arxiv.org/abs/2310.12127v1"},"cats":{"benchmark":0.3028340684,"new-dataset":0.037295476,"data-annotation":0.5344878259,"dev-research":0.1896549313,"llms":0.4946341643,"data-quality":0.2608861937}}
{"text":"Concretely, we compute established gender bias metrics on the WinoMT corpus from English to German and Spanish.","meta":{"url":"http://arxiv.org/abs/2310.12127v1"},"cats":{"benchmark":0.4389818674,"new-dataset":0.1448807003,"data-annotation":0.5667923031,"dev-research":0.171719007,"llms":0.5226157718,"data-quality":0.2776119192}}
{"text":"We discover that IFT models default to male-inflected translations, even disregarding female occupational stereotypes.","meta":{"url":"http://arxiv.org/abs/2310.12127v1"},"cats":{"benchmark":0.1932392908,"new-dataset":0.013052456,"data-annotation":0.5397865102,"dev-research":0.1743040121,"llms":0.5237729084,"data-quality":0.2180374975}}
{"text":"Next, using interpretability methods, we unveil that models systematically overlook the pronoun indicating the gender of a target occupation in misgendered translations.","meta":{"url":"http://arxiv.org/abs/2310.12127v1"},"cats":{"benchmark":0.2826433407,"new-dataset":0.0449181673,"data-annotation":0.5428286346,"dev-research":0.2372028428,"llms":0.5177509916,"data-quality":0.4224517526}}
{"text":"Finally, based on this finding, we propose an easy-to-implement and effective bias mitigation solution based on few-shot learning that leads to significantly fairer translations.","meta":{"url":"http://arxiv.org/abs/2310.12127v1"},"cats":{"benchmark":0.4312244787,"new-dataset":0.0779802608,"data-annotation":0.535837502,"dev-research":0.1700179564,"llms":0.5045998726,"data-quality":0.3708577026}}
{"text":"We introduce SHARCS for adaptive inference that takes into account the hardness of input samples.","meta":{"url":"http://arxiv.org/abs/2310.12126v1"},"cats":{"benchmark":0.5454739552,"new-dataset":0.0480212722,"data-annotation":0.5303185747,"dev-research":0.1306829148,"llms":0.4422604455,"data-quality":0.1916706134}}
{"text":"SHARCS can train a router on any transformer network, enabling the model to direct different samples to sub-networks with varying widths.","meta":{"url":"http://arxiv.org/abs/2310.12126v1"},"cats":{"benchmark":0.2186921057,"new-dataset":0.0162889276,"data-annotation":0.4931954939,"dev-research":0.1349482237,"llms":0.5349909293,"data-quality":0.0574424225}}
{"text":"Our experiments demonstrate that: (1) SHARCS outperforms or complements existing per-sample adaptive inference methods across various classification tasks in terms of accuracy vs. FLOPs; (2) SHARCS generalizes across different architectures and can be even applied to compressed and efficient transformer encoders to further improve their efficiency; (3) SHARCS can provide a 2 times inference speed up at an insignificant drop in accuracy.","meta":{"url":"http://arxiv.org/abs/2310.12126v1"},"cats":{"benchmark":0.4965064641,"new-dataset":0.0155436536,"data-annotation":0.5052408245,"dev-research":0.1715861384,"llms":0.5546431274,"data-quality":0.1272361315}}
{"text":"Mental disorders impact the lives of millions of people globally, not only impeding their day-to-day lives but also markedly reducing life expectancy.","meta":{"url":"http://arxiv.org/abs/2310.12121v1"},"cats":{"benchmark":0.3113859497,"new-dataset":0.0479583295,"data-annotation":0.5083562859,"dev-research":0.3222854526,"llms":0.4598925655,"data-quality":0.0860165271}}
{"text":"This paper addresses the persistent challenge of predicting mortality in patients with mental diagnoses using predictive machine-learning models with electronic health records (EHR).","meta":{"url":"http://arxiv.org/abs/2310.12121v1"},"cats":{"benchmark":0.3829362713,"new-dataset":0.0559396693,"data-annotation":0.5101004218,"dev-research":0.2351255746,"llms":0.3705274793,"data-quality":0.1502963074}}
{"text":"Data from patients with mental disease diagnoses were extracted from the well-known clinical MIMIC-III data set utilizing demographic, prescription, and procedural information.","meta":{"url":"http://arxiv.org/abs/2310.12121v1"},"cats":{"benchmark":0.3408963874,"new-dataset":0.1663178718,"data-annotation":0.4721931633,"dev-research":0.2293962307,"llms":0.4499521179,"data-quality":0.1384345166}}
{"text":"Four machine learning algorithms (Logistic Regression, Random Forest, Support Vector Machine, and K-Nearest Neighbors) were used, with results indicating that Random Forest and Support Vector Machine models outperformed others, with AUC scores of 0.911.","meta":{"url":"http://arxiv.org/abs/2310.12121v1"},"cats":{"benchmark":0.461131742,"new-dataset":0.0202473607,"data-annotation":0.5461684367,"dev-research":0.1861611958,"llms":0.4069623476,"data-quality":0.2720293109}}
{"text":"Feature importance analysis revealed that drug prescriptions, particularly Morphine Sulfate, play a pivotal role in prediction.","meta":{"url":"http://arxiv.org/abs/2310.12121v1"},"cats":{"benchmark":0.3689625146,"new-dataset":0.0152431718,"data-annotation":0.5074107755,"dev-research":0.1867027623,"llms":0.3298598734,"data-quality":0.0983579341}}
{"text":"We applied a variety of machine learning algorithms to predict 30-day mortality followed by feature importance analysis.","meta":{"url":"http://arxiv.org/abs/2310.12121v1"},"cats":{"benchmark":0.4753384257,"new-dataset":0.0630114469,"data-annotation":0.5313557552,"dev-research":0.2007950128,"llms":0.3304805225,"data-quality":0.0999070683}}
{"text":"This study can be used to assist hospital workers in identifying at-risk patients to reduce excess mortality.","meta":{"url":"http://arxiv.org/abs/2310.12121v1"},"cats":{"benchmark":0.3989553525,"new-dataset":0.028148519,"data-annotation":0.5152437773,"dev-research":0.3274010765,"llms":0.4663953029,"data-quality":0.0703496044}}
{"text":"Neural networks have revolutionized language modeling and excelled in various downstream tasks.","meta":{"url":"http://arxiv.org/abs/2310.12118v1"},"cats":{"benchmark":0.286640653,"new-dataset":0.019710267,"data-annotation":0.5362731916,"dev-research":0.1750008374,"llms":0.5128045491,"data-quality":0.1593594542}}
{"text":"However, the extent to which these models achieve compositional generalization comparable to human cognitive abilities remains a topic of debate.","meta":{"url":"http://arxiv.org/abs/2310.12118v1"},"cats":{"benchmark":0.2601532972,"new-dataset":0.0018422092,"data-annotation":0.5353658801,"dev-research":0.1798324135,"llms":0.4698495772,"data-quality":0.1075331341}}
{"text":"While existing approaches in the field have mainly focused on novel architectures and alternative learning paradigms, we introduce a pioneering method harnessing the power of dataset cartography (Swayamdipta et al., 2020).","meta":{"url":"http://arxiv.org/abs/2310.12118v1"},"cats":{"benchmark":0.2315080731,"new-dataset":0.393507101,"data-annotation":0.4839534262,"dev-research":0.2097349476,"llms":0.5248199016,"data-quality":0.1325460595}}
{"text":"By strategically identifying a subset of compositional generalization data using this approach, we achieve a remarkable improvement in model accuracy, yielding enhancements of up to 10% on CFQ and COGS datasets.","meta":{"url":"http://arxiv.org/abs/2310.12118v1"},"cats":{"benchmark":0.420975633,"new-dataset":0.0967463612,"data-annotation":0.5243042804,"dev-research":0.1270614972,"llms":0.4168497745,"data-quality":0.2221821787}}
{"text":"Notably, our technique incorporates dataset cartography as a curriculum learning criterion, eliminating the need for hyperparameter tuning while consistently achieving superior performance.","meta":{"url":"http://arxiv.org/abs/2310.12118v1"},"cats":{"benchmark":0.3617845228,"new-dataset":0.1255659608,"data-annotation":0.4929834905,"dev-research":0.1922981925,"llms":0.5276382629,"data-quality":0.1060082487}}
{"text":"Our findings highlight the untapped potential of dataset cartography in unleashing the full capabilities of compositional generalization within Transformer models.","meta":{"url":"http://arxiv.org/abs/2310.12118v1"},"cats":{"benchmark":0.1968388451,"new-dataset":0.0335600194,"data-annotation":0.4805546647,"dev-research":0.1403334586,"llms":0.4885127896,"data-quality":0.1124634635}}
{"text":"Our code is available at https://github.com/cyberiada/cartography-for-compositionality.","meta":{"url":"http://arxiv.org/abs/2310.12118v1"},"cats":{"benchmark":0.2582433673,"new-dataset":0.2860232465,"data-annotation":0.5452807562,"dev-research":0.1992167004,"llms":0.5693410951,"data-quality":0.1273190948}}
{"text":"Skyline queries typically search a Pareto-optimal set from a given data set to solve the corresponding multiobjective optimization problem.","meta":{"url":"http://arxiv.org/abs/2310.12116v1"},"cats":{"benchmark":0.4644169626,"new-dataset":0.0793881393,"data-annotation":0.4941411092,"dev-research":0.1355292422,"llms":0.4584230689,"data-quality":0.0557475316}}
{"text":"As the number of criteria increases, the skyline presumes excessive data items, which yield a meaningless result.","meta":{"url":"http://arxiv.org/abs/2310.12116v1"},"cats":{"benchmark":0.4132715222,"new-dataset":0.0424538938,"data-annotation":0.4777149319,"dev-research":0.2220514051,"llms":0.4861340532,"data-quality":0.1206302789}}
{"text":"To address this curse of dimensionality, we proposed a k-dominant skyline in which the number of skyline members was reduced by relaxing the restriction on the number of dimensions, considering the uncertainty of data.","meta":{"url":"http://arxiv.org/abs/2310.12116v1"},"cats":{"benchmark":0.382313387,"new-dataset":0.1418565444,"data-annotation":0.4870452832,"dev-research":0.1733437402,"llms":0.4674703236,"data-quality":0.0761296719}}
{"text":"Specifically, each data item was associated with a probability of appearance, which represented the probability of becoming a member of the k-dominant skyline.","meta":{"url":"http://arxiv.org/abs/2310.12116v1"},"cats":{"benchmark":0.3456838077,"new-dataset":0.1843123412,"data-annotation":0.4947486121,"dev-research":0.1236924218,"llms":0.47493395,"data-quality":0.1176624648}}
{"text":"As data items appear continuously in data streams, the corresponding k-dominant skyline may vary with time.","meta":{"url":"http://arxiv.org/abs/2310.12116v1"},"cats":{"benchmark":0.4395094569,"new-dataset":0.2112451661,"data-annotation":0.4695635549,"dev-research":0.1254090367,"llms":0.4478508081,"data-quality":0.0826116088}}
{"text":"Therefore, an effective and rapid mechanism of updating the k-dominant skyline becomes crucial.","meta":{"url":"http://arxiv.org/abs/2310.12116v1"},"cats":{"benchmark":0.415987718,"new-dataset":0.0548875465,"data-annotation":0.4801918071,"dev-research":0.201456557,"llms":0.5030716773,"data-quality":0.0662235402}}
{"text":"Herein, we proposed two time-efficient schemes, Middle Indexing (MI) and All Indexing (AI), for k-dominant skyline in distributed edge-computing environments, where irrelevant data items can be effectively excluded from the compute to reduce the processing duration.","meta":{"url":"http://arxiv.org/abs/2310.12116v1"},"cats":{"benchmark":0.4975409821,"new-dataset":0.0461822698,"data-annotation":0.4846298152,"dev-research":0.1457340664,"llms":0.5437595556,"data-quality":0.0515010404}}
{"text":"Furthermore, the proposed schemes were validated with extensive experimental simulations.","meta":{"url":"http://arxiv.org/abs/2310.12116v1"},"cats":{"benchmark":0.5551385997,"new-dataset":0.0019529074,"data-annotation":0.5014161711,"dev-research":0.1185240272,"llms":0.4832654849,"data-quality":0.0345885963}}
{"text":"The experimental results demonstrated that the proposed MI and AI schemes reduced the computation time by approximately 13% and 56%, respectively, compared with the existing method.","meta":{"url":"http://arxiv.org/abs/2310.12116v1"},"cats":{"benchmark":0.633752532,"new-dataset":0.0032121479,"data-annotation":0.5450560449,"dev-research":0.182344734,"llms":0.4323907669,"data-quality":0.0491449287}}
{"text":"We propose CAPGrasp, an $\\mathbb{R}^3\\times \\text{SO(2)-equivariant}$ 6-DoF continuous approach-constrained generative grasp sampler.","meta":{"url":"http://arxiv.org/abs/2310.12113v1"},"cats":{"benchmark":0.2696753675,"new-dataset":0.1381828085,"data-annotation":0.5160761449,"dev-research":0.0890441519,"llms":0.541209303,"data-quality":0.0591339292}}
{"text":"It includes a novel learning strategy for training CAPGrasp that eliminates the need to curate massive conditionally labeled datasets and a constrained grasp refinement technique that improves grasp poses while respecting the grasp approach directional constraints.","meta":{"url":"http://arxiv.org/abs/2310.12113v1"},"cats":{"benchmark":0.2081214245,"new-dataset":0.3759684354,"data-annotation":0.5048235787,"dev-research":0.1412952108,"llms":0.4549100779,"data-quality":0.092158927}}
{"text":"The experimental results demonstrate that CAPGrasp is more than three times as sample efficient as unconstrained grasp samplers while achieving up to 38% grasp success rate improvement.","meta":{"url":"http://arxiv.org/abs/2310.12113v1"},"cats":{"benchmark":0.4341067132,"new-dataset":0.0282214006,"data-annotation":0.5030675075,"dev-research":0.1130978667,"llms":0.5364089252,"data-quality":0.0589560148}}
{"text":"CAPGrasp also achieves 4-10% higher grasp success rates than constrained but noncontinuous grasp samplers.","meta":{"url":"http://arxiv.org/abs/2310.12113v1"},"cats":{"benchmark":0.4540369316,"new-dataset":0.0117790953,"data-annotation":0.503516131,"dev-research":0.0946461403,"llms":0.5210594035,"data-quality":0.0626831953}}
{"text":"Overall, CAPGrasp is a sample-efficient solution when grasps must originate from specific directions, such as grasping in confined spaces.","meta":{"url":"http://arxiv.org/abs/2310.12113v1"},"cats":{"benchmark":0.3287627486,"new-dataset":0.0131252802,"data-annotation":0.5062444596,"dev-research":0.1386578064,"llms":0.4938014288,"data-quality":0.0405534802}}
{"text":"Within the realm of privacy-preserving machine learning, empirical privacy defenses have been proposed as a solution to achieve satisfactory levels of training data privacy without a significant drop in model utility.","meta":{"url":"http://arxiv.org/abs/2310.12112v1"},"cats":{"benchmark":0.2675382935,"new-dataset":0.073709833,"data-annotation":0.4990815501,"dev-research":0.1289996948,"llms":0.4769142028,"data-quality":0.1755539031}}
{"text":"Most existing defenses against membership inference attacks assume access to reference data, defined as an additional dataset coming from the same (or a similar) underlying distribution as training data.","meta":{"url":"http://arxiv.org/abs/2310.12112v1"},"cats":{"benchmark":0.2916598697,"new-dataset":0.0689565023,"data-annotation":0.5196369884,"dev-research":0.1996176522,"llms":0.5397103084,"data-quality":0.2531965648}}
{"text":"Despite the common use of reference data, previous works are notably reticent about defining and evaluating reference data privacy.","meta":{"url":"http://arxiv.org/abs/2310.12112v1"},"cats":{"benchmark":0.3036100429,"new-dataset":0.1383704137,"data-annotation":0.4823608342,"dev-research":0.2618042508,"llms":0.5792196868,"data-quality":0.1892365535}}
{"text":"As gains in model utility and/or training data privacy may come at the expense of reference data privacy, it is essential that all three aspects are duly considered.","meta":{"url":"http://arxiv.org/abs/2310.12112v1"},"cats":{"benchmark":0.2356305283,"new-dataset":0.0315907079,"data-annotation":0.4794107727,"dev-research":0.1506429531,"llms":0.4765172539,"data-quality":0.1235350844}}
{"text":"In this paper, we first examine the availability of reference data and its privacy treatment in previous works and demonstrate its necessity for fairly comparing defenses.","meta":{"url":"http://arxiv.org/abs/2310.12112v1"},"cats":{"benchmark":0.3716478882,"new-dataset":0.1483744933,"data-annotation":0.4987400704,"dev-research":0.2003703142,"llms":0.5732791343,"data-quality":0.2205006381}}
{"text":"Second, we propose a baseline defense that enables the utility-privacy tradeoff with respect to both training and reference data to be easily understood.","meta":{"url":"http://arxiv.org/abs/2310.12112v1"},"cats":{"benchmark":0.282328654,"new-dataset":0.067882862,"data-annotation":0.5060630572,"dev-research":0.2010966771,"llms":0.5181123816,"data-quality":0.1689009023}}
{"text":"Our method is formulated as an empirical risk minimization with a constraint on the generalization error, which, in practice, can be evaluated as a weighted empirical risk minimization (WERM) over the training and reference datasets.","meta":{"url":"http://arxiv.org/abs/2310.12112v1"},"cats":{"benchmark":0.527060444,"new-dataset":0.0442688147,"data-annotation":0.5473362556,"dev-research":0.2618806914,"llms":0.3592323922,"data-quality":0.3095894163}}
{"text":"Although we conceived of WERM as a simple baseline, our experiments show that, surprisingly, it outperforms the most well-studied and current state-of-the-art empirical privacy defenses using reference data for nearly all relative privacy levels of reference and training data.","meta":{"url":"http://arxiv.org/abs/2310.12112v1"},"cats":{"benchmark":0.3577497888,"new-dataset":0.3189311345,"data-annotation":0.5186873071,"dev-research":0.2175625026,"llms":0.6044122766,"data-quality":0.204983027}}
{"text":"Our investigation also reveals that these existing methods are unable to effectively trade off reference data privacy for model utility and/or training data privacy.","meta":{"url":"http://arxiv.org/abs/2310.12112v1"},"cats":{"benchmark":0.2961335075,"new-dataset":0.0281122008,"data-annotation":0.4878404408,"dev-research":0.1660322458,"llms":0.525501396,"data-quality":0.2773112827}}
{"text":"Overall, our work highlights the need for a proper evaluation of the triad model utility / training data privacy / reference data privacy when comparing privacy defenses.","meta":{"url":"http://arxiv.org/abs/2310.12112v1"},"cats":{"benchmark":0.3533736386,"new-dataset":0.0849842678,"data-annotation":0.4969761412,"dev-research":0.1740556744,"llms":0.5555018555,"data-quality":0.1228482363}}
{"text":"Machine learning models are increasingly being scaled in both sequence length and model dimension to reach longer contexts and better performance.","meta":{"url":"http://arxiv.org/abs/2310.12109v1"},"cats":{"benchmark":0.363175425,"new-dataset":0.0467173459,"data-annotation":0.5133766097,"dev-research":0.1467721445,"llms":0.4454033925,"data-quality":0.0900494068}}
{"text":"However, existing architectures such as Transformers scale quadratically along both these axes.","meta":{"url":"http://arxiv.org/abs/2310.12109v1"},"cats":{"benchmark":0.4007559133,"new-dataset":0.003956887,"data-annotation":0.494029375,"dev-research":0.1576840894,"llms":0.433291573,"data-quality":0.0437953497}}
{"text":"We ask: are there performant architectures that can scale sub-quadratically along sequence length and model dimension?","meta":{"url":"http://arxiv.org/abs/2310.12109v1"},"cats":{"benchmark":0.4677914155,"new-dataset":0.0204155849,"data-annotation":0.4997442069,"dev-research":0.126753833,"llms":0.4547838199,"data-quality":0.0334625019}}
{"text":"We introduce Monarch Mixer (M2), a new architecture that uses the same sub-quadratic primitive along both sequence length and model dimension:","meta":{"url":"http://arxiv.org/abs/2310.12109v1"},"cats":{"benchmark":0.3708869796,"new-dataset":0.1021922202,"data-annotation":0.5209422801,"dev-research":0.10918744,"llms":0.5502335856,"data-quality":0.0707477615}}
{"text":"Monarch matrices, a simple class of expressive structured matrices that captures many linear transforms, achieves high hardware efficiency on GPUs, and scales sub-quadratically.","meta":{"url":"http://arxiv.org/abs/2310.12109v1"},"cats":{"benchmark":0.3717858696,"new-dataset":0.0375350299,"data-annotation":0.4987637482,"dev-research":0.130844667,"llms":0.4505527773,"data-quality":0.0465688757}}
{"text":"As a proof of concept, we explore the performance of M2 in three domains: non-causal BERT-style language modeling, ViT-style image classification, and causal GPT-style language modeling.","meta":{"url":"http://arxiv.org/abs/2310.12109v1"},"cats":{"benchmark":0.3494377706,"new-dataset":0.0592268571,"data-annotation":0.5501955078,"dev-research":0.1687552514,"llms":0.5759153657,"data-quality":0.1844819101}}
{"text":"For non-causal BERT-style modeling, M2 matches BERT-base and BERT-large in downstream GLUE quality with up to 27% fewer parameters, and achieves up to 9.1$\\times$ higher throughput at sequence length 4K. On ImageNet, M2 outperforms ViT-b by 1% in accuracy, with only half the parameters.","meta":{"url":"http://arxiv.org/abs/2310.12109v1"},"cats":{"benchmark":0.455634986,"new-dataset":0.0252175507,"data-annotation":0.5282897816,"dev-research":0.1510740326,"llms":0.5949652238,"data-quality":0.1235520008}}
{"text":"Causal GPT-style models introduce a technical challenge: enforcing causality via masking introduces a quadratic bottleneck.","meta":{"url":"http://arxiv.org/abs/2310.12109v1"},"cats":{"benchmark":0.3289035873,"new-dataset":0.0097619177,"data-annotation":0.5104284941,"dev-research":0.2287555865,"llms":0.4365773481,"data-quality":0.1277655952}}
{"text":"To alleviate this bottleneck, we develop a novel theoretical view of Monarch matrices based on multivariate polynomial evaluation and interpolation, which lets us parameterize M2 to be causal while remaining sub-quadratic.","meta":{"url":"http://arxiv.org/abs/2310.12109v1"},"cats":{"benchmark":0.4606184805,"new-dataset":0.0178551099,"data-annotation":0.5274226008,"dev-research":0.0972215198,"llms":0.379430084,"data-quality":0.0625951401}}
{"text":"Using this parameterization, M2 matches GPT-style Transformers at 360M parameters in pretraining perplexity on The PILE--showing for the first time that it may be possible to match Transformer quality without attention or MLPs.","meta":{"url":"http://arxiv.org/abs/2310.12109v1"},"cats":{"benchmark":0.3325752491,"new-dataset":0.022567053,"data-annotation":0.5063312424,"dev-research":0.1215814358,"llms":0.6132457267,"data-quality":0.0956163296}}
{"text":"We investigate brokerage between traders from an online learning perspective.","meta":{"url":"http://arxiv.org/abs/2310.12107v1"},"cats":{"benchmark":0.238459568,"new-dataset":0.0633390732,"data-annotation":0.5196507724,"dev-research":0.1830072721,"llms":0.5442097712,"data-quality":0.0680032637}}
{"text":"At any round $t$, two traders arrive with their private valuations, and the broker proposes a trading price.","meta":{"url":"http://arxiv.org/abs/2310.12107v1"},"cats":{"benchmark":0.3042196357,"new-dataset":0.0325505943,"data-annotation":0.5191708641,"dev-research":0.1387240212,"llms":0.4814249628,"data-quality":0.0541241536}}
{"text":"Unlike other bilateral trade problems already studied in the online learning literature, we focus on the case where there are no designated buyer and seller roles: each trader will attempt to either buy or sell depending on the current price of the good.   ","meta":{"url":"http://arxiv.org/abs/2310.12107v1"},"cats":{"benchmark":0.2229396449,"new-dataset":0.0755631229,"data-annotation":0.5067732132,"dev-research":0.142725785,"llms":0.4900191217,"data-quality":0.1128704969}}
{"text":"We assume the agents' valuations are drawn i.i.d.","meta":{"url":"http://arxiv.org/abs/2310.12107v1"},"cats":{"benchmark":0.3217158139,"new-dataset":0.0689838055,"data-annotation":0.5327857582,"dev-research":0.1220926428,"llms":0.5121859487,"data-quality":0.0892862544}}
{"text":"from a fixed but unknown distribution.","meta":{"url":"http://arxiv.org/abs/2310.12107v1"},"cats":{"benchmark":0.2445464681,"new-dataset":0.2315146671,"data-annotation":0.5125143171,"dev-research":0.1121543454,"llms":0.4512723697,"data-quality":0.2584845883}}
{"text":"If the distribution admits a density bounded by some constant $M$, then, for any time horizon $T$:   $\\bullet$ If the agents' valuations are revealed after each interaction, we provide an algorithm achieving regret $M \\log T$ and show this rate is optimal, up to constant factors.   ","meta":{"url":"http://arxiv.org/abs/2310.12107v1"},"cats":{"benchmark":0.3847713996,"new-dataset":0.0262609987,"data-annotation":0.5263249256,"dev-research":0.1079088107,"llms":0.4693881233,"data-quality":0.0554649029}}
{"text":"$\\bullet$ If only their willingness to sell or buy at the proposed price is revealed after each interaction, we provide an algorithm achieving regret $\\sqrt{M T}$ and show this rate is optimal, up to constant factors.   ","meta":{"url":"http://arxiv.org/abs/2310.12107v1"},"cats":{"benchmark":0.3729208087,"new-dataset":0.0140021329,"data-annotation":0.5313953343,"dev-research":0.14915401,"llms":0.4776779286,"data-quality":0.0457687495}}
{"text":"Finally, if we drop the bounded density assumption, we show that the optimal rate degrades to $\\sqrt{T}$ in the first case, and the problem becomes unlearnable in the second.","meta":{"url":"http://arxiv.org/abs/2310.12107v1"},"cats":{"benchmark":0.4246967302,"new-dataset":0.023212339,"data-annotation":0.5109886563,"dev-research":0.1190308333,"llms":0.4568034845,"data-quality":0.1226394398}}
{"text":"Reinforcement learning from human feedback (RLHF) has exhibited the potential to enhance the performance of foundation models for qualitative tasks.","meta":{"url":"http://arxiv.org/abs/2310.12103v1"},"cats":{"benchmark":0.2554724812,"new-dataset":0.0833447597,"data-annotation":0.5151705745,"dev-research":0.2322873089,"llms":0.4458933113,"data-quality":0.0652903419}}
{"text":"Despite its promise, its efficacy is often restricted when conceptualized merely as a mechanism to maximize learned reward models of averaged human preferences, especially in areas such as image generation which demand diverse model responses.","meta":{"url":"http://arxiv.org/abs/2310.12103v1"},"cats":{"benchmark":0.2002259219,"new-dataset":0.0070112,"data-annotation":0.5142020344,"dev-research":0.1543712308,"llms":0.4907831646,"data-quality":0.1002326284}}
{"text":"Meanwhile, quality diversity (QD) algorithms, dedicated to seeking diverse, high-quality solutions, are often constrained by the dependency on manually defined diversity metrics.","meta":{"url":"http://arxiv.org/abs/2310.12103v1"},"cats":{"benchmark":0.5003594073,"new-dataset":0.0292295752,"data-annotation":0.5140572534,"dev-research":0.1415031697,"llms":0.4623018589,"data-quality":0.1764952213}}
{"text":"Interestingly, such limitations of RLHF and QD can be overcome by blending insights from both.","meta":{"url":"http://arxiv.org/abs/2310.12103v1"},"cats":{"benchmark":0.3623915466,"new-dataset":0.0179158635,"data-annotation":0.5022975404,"dev-research":0.1312560137,"llms":0.48622022,"data-quality":0.0715006998}}
{"text":"This paper introduces Quality Diversity through Human Feedback (QDHF), which employs human feedback for inferring diversity metrics, expanding the applicability of QD algorithms.","meta":{"url":"http://arxiv.org/abs/2310.12103v1"},"cats":{"benchmark":0.4440640823,"new-dataset":0.0902957852,"data-annotation":0.5257151936,"dev-research":0.2043463229,"llms":0.4675502412,"data-quality":0.2394074203}}
{"text":"Empirical results reveal that QDHF outperforms existing QD methods regarding automatic diversity discovery, and matches the search capabilities of QD with human-constructed metrics.","meta":{"url":"http://arxiv.org/abs/2310.12103v1"},"cats":{"benchmark":0.3863300374,"new-dataset":0.1769910173,"data-annotation":0.531895792,"dev-research":0.1203362955,"llms":0.4806259152,"data-quality":0.1867555498}}
{"text":"Notably, when deployed for a latent space illumination task, QDHF markedly enhances the diversity of images generated by a Diffusion model.","meta":{"url":"http://arxiv.org/abs/2310.12103v1"},"cats":{"benchmark":0.3359204841,"new-dataset":0.0343702522,"data-annotation":0.5026269092,"dev-research":0.1081454058,"llms":0.4167177621,"data-quality":0.0788177477}}
{"text":"The study concludes with an in-depth analysis of QDHF's sample efficiency and the quality of its derived diversity metrics, emphasizing its promise for enhancing exploration and diversity in optimization for complex, open-ended tasks.","meta":{"url":"http://arxiv.org/abs/2310.12103v1"},"cats":{"benchmark":0.6287512262,"new-dataset":0.0204518036,"data-annotation":0.5130439902,"dev-research":0.1110224665,"llms":0.3871910134,"data-quality":0.0526824149}}
{"text":"Large language models (LLMs) and vision language models (VLMs) demonstrate excellent performance on a wide range of tasks by scaling up parameter counts from O(10^9) to O(10^{12}) levels and further beyond.","meta":{"url":"http://arxiv.org/abs/2310.12100v1"},"cats":{"benchmark":0.3105931863,"new-dataset":0.1159284157,"data-annotation":0.5205259166,"dev-research":0.1648575599,"llms":0.6593996105,"data-quality":0.1258543334}}
{"text":"These large scales make it impossible to adapt and deploy fully specialized models given a task of interest.","meta":{"url":"http://arxiv.org/abs/2310.12100v1"},"cats":{"benchmark":0.2871225044,"new-dataset":0.0117561862,"data-annotation":0.4842561476,"dev-research":0.132818634,"llms":0.535254732,"data-quality":0.0713829019}}
{"text":"Parameter-efficient fine-tuning (PEFT) emerges as a promising direction to tackle the adaptation and serving challenges for such large models.","meta":{"url":"http://arxiv.org/abs/2310.12100v1"},"cats":{"benchmark":0.5190324877,"new-dataset":0.0114116535,"data-annotation":0.4967662103,"dev-research":0.1568452396,"llms":0.438100669,"data-quality":0.1046875547}}
{"text":"We categorize PEFT techniques into two types: intrusive and non-intrusive.","meta":{"url":"http://arxiv.org/abs/2310.12100v1"},"cats":{"benchmark":0.3085340206,"new-dataset":0.0024109487,"data-annotation":0.5181883681,"dev-research":0.1648512266,"llms":0.5205170889,"data-quality":0.086495871}}
{"text":"Intrusive PEFT techniques directly change a model's internal architecture.","meta":{"url":"http://arxiv.org/abs/2310.12100v1"},"cats":{"benchmark":0.3049635703,"new-dataset":0.0013002274,"data-annotation":0.4899497874,"dev-research":0.152567676,"llms":0.4998938447,"data-quality":0.0592265393}}
{"text":"Though more flexible, they introduce significant complexities for training and serving.","meta":{"url":"http://arxiv.org/abs/2310.12100v1"},"cats":{"benchmark":0.2521428788,"new-dataset":0.008731785,"data-annotation":0.499791795,"dev-research":0.1593295892,"llms":0.5247130263,"data-quality":0.0580198394}}
{"text":"Non-intrusive PEFT techniques leave the internal architecture unchanged and only adapt model-external parameters, such as embeddings for input.","meta":{"url":"http://arxiv.org/abs/2310.12100v1"},"cats":{"benchmark":0.3493096703,"new-dataset":0.0020632354,"data-annotation":0.5026811807,"dev-research":0.1080753421,"llms":0.4997900487,"data-quality":0.1020942678}}
{"text":"In this work, we describe AdaLink as a non-intrusive PEFT technique that achieves competitive performance compared to SoTA intrusive PEFT (LoRA) and full model fine-tuning (FT) on various tasks.","meta":{"url":"http://arxiv.org/abs/2310.12100v1"},"cats":{"benchmark":0.4930191199,"new-dataset":0.0059525086,"data-annotation":0.5077084607,"dev-research":0.1342734367,"llms":0.5401654502,"data-quality":0.0784495408}}
{"text":"We evaluate using both text-only and multimodal tasks, with experiments that account for both parameter-count scaling and training regime (with and without instruction tuning).","meta":{"url":"http://arxiv.org/abs/2310.12100v1"},"cats":{"benchmark":0.3703997234,"new-dataset":0.0635320924,"data-annotation":0.5272680131,"dev-research":0.161420467,"llms":0.5399350918,"data-quality":0.106217055}}
{"text":"Let G be a directed weighted graph (DiGraph) on n vertices and m edges with source s and sink t. An edge in G is vital if its removal reduces the capacity of (s,t)-mincut.","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.4986644275,"new-dataset":0.0065026288,"data-annotation":0.5053669077,"dev-research":0.1388810074,"llms":0.5331469032,"data-quality":0.0963816454}}
{"text":"Since the seminal work of Ford and Fulkerson, a long line of work has been done on computing the most vital edge and all vital edges of G. Unfortunately, after 60 years, the existing results are for undirected or unweighted graphs.","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.4195285641,"new-dataset":0.0765563638,"data-annotation":0.5157331981,"dev-research":0.150084651,"llms":0.4695121301,"data-quality":0.0711582786}}
{"text":"We present the following result for DiGraph, which solves an open problem stated by Ausiello et al.   1.","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.3767867158,"new-dataset":0.3299106684,"data-annotation":0.5312604192,"dev-research":0.159791903,"llms":0.5049829071,"data-quality":0.1421726305}}
{"text":"There is an algorithm that computes all vital edges as well as the most vital edge of G using O(n) maxflow computations.   ","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.554928879,"new-dataset":0.0248945599,"data-annotation":0.5195508959,"dev-research":0.1187182734,"llms":0.4779223138,"data-quality":0.048304583}}
{"text":"Vital edges play a crucial role in the design of Sensitivity Oracle (SO) for (s,t)-mincut.","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.5288760764,"new-dataset":0.0031372099,"data-annotation":0.5006936826,"dev-research":0.1389527275,"llms":0.532026983,"data-quality":0.0788941069}}
{"text":"For directed graphs, the only existing SO is for unweighted graphs by Picard and Queyranne.","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.3275972009,"new-dataset":0.0435267514,"data-annotation":0.5161599218,"dev-research":0.1525220063,"llms":0.5272937374,"data-quality":0.0903388283}}
{"text":"We present the first and optimal SO for DiGraph.   2.","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.4637859629,"new-dataset":0.1401821873,"data-annotation":0.5406210128,"dev-research":0.1320080742,"llms":0.5260939995,"data-quality":0.0758383173}}
{"text":"(a) There is an O(n) space SO that can report in O(1) time the capacity of (s,t)-mincut and (b) an O($n^2$) space SO that can report an (s,t)-mincut in O(n) time after failure/insertion of an edge.   ","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.4920450208,"new-dataset":0.0293165825,"data-annotation":0.5170859601,"dev-research":0.1865080222,"llms":0.4958031583,"data-quality":0.1211972441}}
{"text":"For unweighted graphs, Picard and Queyranne designed an O(m) space DAG that stores and characterizes all mincuts for all vital edges.","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.3997972163,"new-dataset":0.071294888,"data-annotation":0.4946217459,"dev-research":0.1516028905,"llms":0.5551080926,"data-quality":0.0850193964}}
{"text":"Conversely, there is a set containing at most n-1 (s,t)-cuts such that at least one mincut for every vital edge belongs to the set.","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.4188599216,"new-dataset":0.0642080649,"data-annotation":0.5154409973,"dev-research":0.1507636482,"llms":0.4828101477,"data-quality":0.0790193969}}
{"text":"We generalize these results for DiGraph.   3.","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.4474516451,"new-dataset":0.2168103414,"data-annotation":0.5415080194,"dev-research":0.1602408942,"llms":0.5100946692,"data-quality":0.1658127298}}
{"text":"(a) There is a set containing at most n-1 (s,t)-cuts such that at least one mincut for every vital edge is present in the set.","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.3839838168,"new-dataset":0.1653065022,"data-annotation":0.5160971694,"dev-research":0.148429101,"llms":0.4725426511,"data-quality":0.084899152}}
{"text":"(b) We design two compact structures for storing and characterizing all mincuts for all vital edges, (i) O(m) space DAG for partial characterization and (ii) O(mn) space structure for complete characterization.   ","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.4049957915,"new-dataset":0.0618837963,"data-annotation":0.4925907492,"dev-research":0.1685082049,"llms":0.5716638295,"data-quality":0.1033608314}}
{"text":"To arrive at our results, we develop new techniques, especially a generalization of maxflow-mincut theorem by Ford and Fulkerson, which might be of independent interest.","meta":{"url":"http://arxiv.org/abs/2310.12096v1"},"cats":{"benchmark":0.5509296705,"new-dataset":0.0286864652,"data-annotation":0.519243974,"dev-research":0.1502149781,"llms":0.4268950554,"data-quality":0.1049514915}}
{"text":"Deep Learning is having a remarkable impact on the design of Reduced Order Models (ROMs) for Partial Differential Equations (PDEs), where it is exploited as a powerful tool for tackling complex problems for which classical methods might fail.","meta":{"url":"http://arxiv.org/abs/2310.12095v1"},"cats":{"benchmark":0.3398814273,"new-dataset":0.0424759762,"data-annotation":0.5194508011,"dev-research":0.1643935622,"llms":0.4450268879,"data-quality":0.08494358}}
{"text":"In this respect, deep autoencoders play a fundamental role, as they provide an extremely flexible tool for reducing the dimensionality of a given problem by leveraging on the nonlinear capabilities of neural networks.","meta":{"url":"http://arxiv.org/abs/2310.12095v1"},"cats":{"benchmark":0.2563485488,"new-dataset":0.0322213043,"data-annotation":0.5253274595,"dev-research":0.150786526,"llms":0.3729087312,"data-quality":0.1042283305}}
{"text":"Indeed, starting from this paradigm, several successful approaches have already been developed, which are here referred to as Deep Learning-based ROMs (DL-ROMs).","meta":{"url":"http://arxiv.org/abs/2310.12095v1"},"cats":{"benchmark":0.2384477385,"new-dataset":0.1211020788,"data-annotation":0.4891238765,"dev-research":0.3024416303,"llms":0.5469258375,"data-quality":0.0931676628}}
{"text":"Nevertheless, when it comes to stochastic problems parameterized by random fields, the current understanding of DL-ROMs is mostly based on empirical evidence: in fact, their theoretical analysis is currently limited to the case of PDEs depending on a finite number of (deterministic) parameters.","meta":{"url":"http://arxiv.org/abs/2310.12095v1"},"cats":{"benchmark":0.3043221915,"new-dataset":0.0277777882,"data-annotation":0.502334044,"dev-research":0.1947174055,"llms":0.5068517632,"data-quality":0.0916173759}}
{"text":"The purpose of this work is to extend the existing literature by providing some theoretical insights about the use of DL-ROMs in the presence of stochasticity generated by random fields.","meta":{"url":"http://arxiv.org/abs/2310.12095v1"},"cats":{"benchmark":0.2914976152,"new-dataset":0.0320932647,"data-annotation":0.5136071536,"dev-research":0.1297495436,"llms":0.5107681747,"data-quality":0.0961746566}}
{"text":"In particular, we derive explicit error bounds that can guide domain practitioners when choosing the latent dimension of deep autoencoders.","meta":{"url":"http://arxiv.org/abs/2310.12095v1"},"cats":{"benchmark":0.3242730131,"new-dataset":0.0630321306,"data-annotation":0.5467376581,"dev-research":0.2202283459,"llms":0.4742671581,"data-quality":0.2196060205}}
{"text":"We evaluate the practical usefulness of our theory by means of numerical experiments, showing how our analysis can significantly impact the performance of DL-ROMs.","meta":{"url":"http://arxiv.org/abs/2310.12095v1"},"cats":{"benchmark":0.5746459655,"new-dataset":0.0125136424,"data-annotation":0.5214384983,"dev-research":0.1649841131,"llms":0.5153501836,"data-quality":0.0687946271}}
{"text":"Aerial surveillance requires high spatio-temporal resolution (HSTR) video for more accurate detection and tracking of objects.","meta":{"url":"http://arxiv.org/abs/2310.12092v1"},"cats":{"benchmark":0.3139876381,"new-dataset":0.2164914164,"data-annotation":0.478242876,"dev-research":0.1833908017,"llms":0.4782271732,"data-quality":0.0660012349}}
{"text":"This is especially true for wide-area surveillance (WAS), where the surveyed region is large and the objects of interest are small.","meta":{"url":"http://arxiv.org/abs/2310.12092v1"},"cats":{"benchmark":0.2581325253,"new-dataset":0.0523894835,"data-annotation":0.5125866779,"dev-research":0.1897531707,"llms":0.4788824912,"data-quality":0.1394019199}}
{"text":"This paper proposes a dual camera system for the generation of HSTR video using reference-based super-resolution (RefSR).","meta":{"url":"http://arxiv.org/abs/2310.12092v1"},"cats":{"benchmark":0.3313812501,"new-dataset":0.3879645587,"data-annotation":0.4740926589,"dev-research":0.1803110343,"llms":0.5534645984,"data-quality":0.0736836795}}
{"text":"One camera captures high spatial resolution low frame rate (HSLF) video while the other captures low spatial resolution high frame rate (LSHF) video simultaneously for the same scene.","meta":{"url":"http://arxiv.org/abs/2310.12092v1"},"cats":{"benchmark":0.4281178567,"new-dataset":0.1363247134,"data-annotation":0.4811515236,"dev-research":0.1411808105,"llms":0.4692673717,"data-quality":0.0813934889}}
{"text":"A novel deep learning architecture is proposed to fuse HSLF and LSHF video feeds and synthesize HSTR video frames at the output.","meta":{"url":"http://arxiv.org/abs/2310.12092v1"},"cats":{"benchmark":0.2206408413,"new-dataset":0.3883755765,"data-annotation":0.4890317495,"dev-research":0.1499644469,"llms":0.4834043174,"data-quality":0.1086137927}}
{"text":"The proposed model combines optical flow estimation and (channel-wise and spatial) attention mechanisms to capture the fine motion and intricate dependencies between frames of the two video feeds.","meta":{"url":"http://arxiv.org/abs/2310.12092v1"},"cats":{"benchmark":0.3180362011,"new-dataset":0.0634974227,"data-annotation":0.5229233098,"dev-research":0.1498390601,"llms":0.4598175258,"data-quality":0.0975939272}}
{"text":"Simulations show that the proposed model provides significant improvement over existing reference-based SR techniques in terms of PSNR and SSIM metrics.","meta":{"url":"http://arxiv.org/abs/2310.12092v1"},"cats":{"benchmark":0.6461437004,"new-dataset":0.0133175847,"data-annotation":0.4791029888,"dev-research":0.1604077003,"llms":0.4981056087,"data-quality":0.1022995549}}
{"text":"The method also exhibits sufficient frames per second (FPS) for WAS when deployed on a power-constrained drone equipped with dual cameras.","meta":{"url":"http://arxiv.org/abs/2310.12092v1"},"cats":{"benchmark":0.4507111804,"new-dataset":0.0241559937,"data-annotation":0.5048890271,"dev-research":0.171953123,"llms":0.4240096017,"data-quality":0.0659470795}}
{"text":"Large Language Models (LLMs), such as ChatGPT/GPT-4, have garnered widespread attention owing to their myriad of practical applications, yet their adoption has been constrained by issues of fact-conflicting hallucinations across web platforms.","meta":{"url":"http://arxiv.org/abs/2310.12086v1"},"cats":{"benchmark":0.1966949439,"new-dataset":0.0447861009,"data-annotation":0.5211061431,"dev-research":0.2076516692,"llms":0.748186647,"data-quality":0.1625634094}}
{"text":"The assessment of factuality in text, produced by LLMs, remains inadequately explored, extending not only to the judgment of vanilla facts but also encompassing the evaluation of factual errors emerging in complex inferential tasks like multi-hop, and etc.","meta":{"url":"http://arxiv.org/abs/2310.12086v1"},"cats":{"benchmark":0.34681998,"new-dataset":0.0176421185,"data-annotation":0.5325224532,"dev-research":0.2659404833,"llms":0.720276118,"data-quality":0.3432775562}}
{"text":"In response, we introduce FactCHD, a fact-conflicting hallucination detection benchmark meticulously designed for LLMs.","meta":{"url":"http://arxiv.org/abs/2310.12086v1"},"cats":{"benchmark":0.3915045668,"new-dataset":0.0436604198,"data-annotation":0.5209617836,"dev-research":0.1732186826,"llms":0.7460880397,"data-quality":0.2434756597}}
{"text":"Functioning as a pivotal tool in evaluating factuality within \"Query-Respons\" contexts, our benchmark assimilates a large-scale dataset, encapsulating a broad spectrum of factuality patterns, such as vanilla, multi-hops, comparison, and set-operation patterns.","meta":{"url":"http://arxiv.org/abs/2310.12086v1"},"cats":{"benchmark":0.4267543399,"new-dataset":0.2243630239,"data-annotation":0.4858565562,"dev-research":0.2841798033,"llms":0.5977257117,"data-quality":0.1352064172}}
{"text":"A distinctive feature of our benchmark is its incorporation of fact-based chains of evidence, thereby facilitating comprehensive and conducive factual reasoning throughout the assessment process.","meta":{"url":"http://arxiv.org/abs/2310.12086v1"},"cats":{"benchmark":0.6084977039,"new-dataset":0.084263717,"data-annotation":0.4998214602,"dev-research":0.3586396314,"llms":0.4888332589,"data-quality":0.1607006177}}
{"text":"We evaluate multiple LLMs, demonstrating the effectiveness of the benchmark and current methods fall short of faithfully detecting factual errors.","meta":{"url":"http://arxiv.org/abs/2310.12086v1"},"cats":{"benchmark":0.6673698598,"new-dataset":0.0205079141,"data-annotation":0.5226419155,"dev-research":0.1906708422,"llms":0.7474951783,"data-quality":0.3649647939}}
{"text":"Furthermore, we present TRUTH-TRIANGULATOR that synthesizes reflective considerations by tool-enhanced ChatGPT and LoRA-tuning based on Llama2, aiming to yield more credible detection through the amalgamation of predictive results and evidence.","meta":{"url":"http://arxiv.org/abs/2310.12086v1"},"cats":{"benchmark":0.3310837316,"new-dataset":0.0868361659,"data-annotation":0.514333226,"dev-research":0.1712487164,"llms":0.6716739042,"data-quality":0.1630364192}}
{"text":"The benchmark dataset and source code will be made available in https://github.com/zjunlp/FactCHD.","meta":{"url":"http://arxiv.org/abs/2310.12086v1"},"cats":{"benchmark":0.6025773548,"new-dataset":0.799367475,"data-annotation":0.5125526168,"dev-research":0.1862340111,"llms":0.5010328663,"data-quality":0.1483736455}}
{"text":"In human activity recognition (HAR), the limited availability of annotated data presents a significant challenge.","meta":{"url":"http://arxiv.org/abs/2310.12085v1"},"cats":{"benchmark":0.244467394,"new-dataset":0.4129858476,"data-annotation":0.5347489118,"dev-research":0.2284798931,"llms":0.479234177,"data-quality":0.260648882}}
{"text":"Drawing inspiration from the latest advancements in generative AI, including Large Language Models (LLMs) and motion synthesis models, we believe that generative AI can address this data scarcity by autonomously generating virtual IMU data from text descriptions.","meta":{"url":"http://arxiv.org/abs/2310.12085v1"},"cats":{"benchmark":0.1717000754,"new-dataset":0.2612154442,"data-annotation":0.5324426103,"dev-research":0.1741644896,"llms":0.6062311348,"data-quality":0.1456763251}}
{"text":"Beyond this, we spotlight several promising research pathways that could benefit from generative AI for the community, including the generating benchmark datasets, the development of foundational models specific to HAR, the exploration of hierarchical structures within HAR, breaking down complex activities, and applications in health sensing and activity summarization.","meta":{"url":"http://arxiv.org/abs/2310.12085v1"},"cats":{"benchmark":0.2675641968,"new-dataset":0.348319653,"data-annotation":0.5012896916,"dev-research":0.2324261942,"llms":0.4879424475,"data-quality":0.0859287103}}
{"text":"Objective: As metabolic cost is a primary factor influencing humans' gait, we want to deepen our understanding of metabolic energy expenditure models.","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.380694675,"new-dataset":0.0695377159,"data-annotation":0.5007402934,"dev-research":0.2098907331,"llms":0.3780782648,"data-quality":0.0586763083}}
{"text":"Therefore, this paper identifies the parameters and input variables, such as muscle or joint states, that contribute to accurate metabolic cost estimations.","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.559142698,"new-dataset":0.0267805804,"data-annotation":0.5203036977,"dev-research":0.1607915086,"llms":0.3191857931,"data-quality":0.0905083198}}
{"text":"Methods: We explored the parameters of four metabolic energy expenditure models in a Monte Carlo sensitivity analysis.","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.5691851696,"new-dataset":0.0136113052,"data-annotation":0.5063024641,"dev-research":0.1805790079,"llms":0.3772357134,"data-quality":0.0798500891}}
{"text":"Then, we analysed the model parameters by their calculated sensitivity indices, physiological context, and the resulting metabolic rates during the gait cycle.","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.518828577,"new-dataset":0.0533425299,"data-annotation":0.5039616127,"dev-research":0.132864125,"llms":0.3365790673,"data-quality":0.0568487906}}
{"text":"The parameter combination with the highest accuracy in the Monte Carlo simulations represented a quasi-optimized model.","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.5557153065,"new-dataset":0.0098643296,"data-annotation":0.5232668634,"dev-research":0.1101865845,"llms":0.3952716204,"data-quality":0.0449356441}}
{"text":"In the second step, we investigated the importance of input parameters and variables by analysing the accuracy of neural networks trained with different input features.","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.4043521914,"new-dataset":0.0124901758,"data-annotation":0.5365217034,"dev-research":0.1979521317,"llms":0.3499416304,"data-quality":0.1983770631}}
{"text":"Results: Power-related parameters were most influential in the sensitivity analysis and the neural network-based feature selection.","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.521469134,"new-dataset":0.0053704525,"data-annotation":0.5075545116,"dev-research":0.2079919905,"llms":0.3544994954,"data-quality":0.1461824708}}
{"text":"We observed that the quasi-optimized models produced negative metabolic rates, contradicting muscle physiology.","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.4703090482,"new-dataset":0.0036017197,"data-annotation":0.5098502443,"dev-research":0.1910760834,"llms":0.4119337499,"data-quality":0.0877446134}}
{"text":"Neural network-based models showed promising abilities but have been unable to match the accuracy of traditional metabolic energy expenditure models.","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.4582730276,"new-dataset":0.0111994425,"data-annotation":0.5016270105,"dev-research":0.1393002319,"llms":0.38754731,"data-quality":0.1186671291}}
{"text":"Conclusion: We showed that power-related metabolic energy expenditure model parameters and inputs are most influential during gait.","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.3989327005,"new-dataset":0.0226055555,"data-annotation":0.4966871541,"dev-research":0.2036291772,"llms":0.3537572586,"data-quality":0.0660373653}}
{"text":"Furthermore, our results suggest that neural network-based metabolic energy expenditure models are viable.","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.4095394282,"new-dataset":0.020568853,"data-annotation":0.4958863556,"dev-research":0.1528117324,"llms":0.3783010792,"data-quality":0.0842463752}}
{"text":"However, bigger datasets are required to achieve better accuracy.","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.4128168902,"new-dataset":0.1253145166,"data-annotation":0.4923975499,"dev-research":0.2092423205,"llms":0.4638254869,"data-quality":0.1879608149}}
{"text":"Significance:","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.3584809151,"new-dataset":0.0801434791,"data-annotation":0.5227815623,"dev-research":0.2343332152,"llms":0.5382530787,"data-quality":0.107705855}}
{"text":"As there is a need for more accurate metabolic energy expenditure models, we explored which musculoskeletal parameters are essential when developing a model to estimate metabolic energy.","meta":{"url":"http://arxiv.org/abs/2310.12083v1"},"cats":{"benchmark":0.457201614,"new-dataset":0.0394663948,"data-annotation":0.5076344639,"dev-research":0.2019689116,"llms":0.3710760601,"data-quality":0.0571497167}}
{"text":"Graph matching is one of the most significant graph analytic tasks in practice, which aims to find the node correspondence across different graphs.","meta":{"url":"http://arxiv.org/abs/2310.12081v1"},"cats":{"benchmark":0.5527338817,"new-dataset":0.0301407007,"data-annotation":0.4952034321,"dev-research":0.1984602194,"llms":0.4602511302,"data-quality":0.156560959}}
{"text":"Most existing approaches rely on adjacency matrices or node embeddings when matching graphs, whose performances are often sub-optimal because of not fully leveraging the multi-modal information hidden in graphs, such as node attributes, subgraph structures, etc.","meta":{"url":"http://arxiv.org/abs/2310.12081v1"},"cats":{"benchmark":0.5193805926,"new-dataset":0.0119353684,"data-annotation":0.5174878214,"dev-research":0.149433289,"llms":0.4692155678,"data-quality":0.1369640649}}
{"text":"In this study, we propose a novel and effective graph matching method based on a differentiable hierarchical optimal transport (HOT) framework, called DHOT-GM.","meta":{"url":"http://arxiv.org/abs/2310.12081v1"},"cats":{"benchmark":0.5998053938,"new-dataset":0.0253967999,"data-annotation":0.4794064155,"dev-research":0.1342482119,"llms":0.3895211706,"data-quality":0.0798700374}}
{"text":"Essentially, our method represents each graph as a set of relational matrices corresponding to the information of different modalities.","meta":{"url":"http://arxiv.org/abs/2310.12081v1"},"cats":{"benchmark":0.3287624857,"new-dataset":0.0594735541,"data-annotation":0.5114353876,"dev-research":0.1777579983,"llms":0.4370057924,"data-quality":0.1181135349}}
{"text":"Given two graphs, we enumerate all relational matrix pairs and obtain their matching results, and accordingly, infer the node correspondence by the weighted averaging of the matching results.","meta":{"url":"http://arxiv.org/abs/2310.12081v1"},"cats":{"benchmark":0.5267259569,"new-dataset":0.0593141882,"data-annotation":0.5208340316,"dev-research":0.1146120441,"llms":0.4623096481,"data-quality":0.1149860056}}
{"text":"This method can be implemented as computing the HOT distance between the two graphs -- each matching result is an optimal transport plan associated with the Gromov-Wasserstein (GW) distance between two relational matrices, and the weights of all matching results are the elements of an upper-level optimal transport plan defined on the matrix sets.","meta":{"url":"http://arxiv.org/abs/2310.12081v1"},"cats":{"benchmark":0.5116987778,"new-dataset":0.0338671854,"data-annotation":0.5049561467,"dev-research":0.1180035539,"llms":0.4041627085,"data-quality":0.0515446058}}
{"text":"We propose a bi-level optimization algorithm to compute the HOT distance in a differentiable way, making the significance of the relational matrices adjustable.","meta":{"url":"http://arxiv.org/abs/2310.12081v1"},"cats":{"benchmark":0.6191569915,"new-dataset":0.0563468859,"data-annotation":0.5187864542,"dev-research":0.1979656646,"llms":0.4077974488,"data-quality":0.060482887}}
{"text":"Experiments on various graph matching tasks demonstrate the superiority and robustness of our method compared to state-of-the-art approaches.","meta":{"url":"http://arxiv.org/abs/2310.12081v1"},"cats":{"benchmark":0.6369051039,"new-dataset":0.0336793591,"data-annotation":0.5030638405,"dev-research":0.1864681606,"llms":0.4611307292,"data-quality":0.2577989661}}
{"text":"In this paper, we study imitation learning under the challenging setting of: (1) only a single demonstration, (2) no further data collection, and (3) no prior task or object knowledge.","meta":{"url":"http://arxiv.org/abs/2310.12077v1"},"cats":{"benchmark":0.2054670101,"new-dataset":0.1464859184,"data-annotation":0.510421329,"dev-research":0.1433898616,"llms":0.4936627929,"data-quality":0.094540672}}
{"text":"We show how, with these constraints, imitation learning can be formulated as a combination of trajectory transfer and unseen object pose estimation.","meta":{"url":"http://arxiv.org/abs/2310.12077v1"},"cats":{"benchmark":0.2252405566,"new-dataset":0.1190287308,"data-annotation":0.5263583843,"dev-research":0.1171748745,"llms":0.3961314675,"data-quality":0.0772609259}}
{"text":"To explore this idea, we provide an in-depth study on how state-of-the-art unseen object pose estimators perform for one-shot imitation learning on ten real-world tasks, and we take a deep dive into the effects that camera calibration, pose estimation error, and spatial generalisation have on task success rates.","meta":{"url":"http://arxiv.org/abs/2310.12077v1"},"cats":{"benchmark":0.2712544187,"new-dataset":0.1210573014,"data-annotation":0.5327311528,"dev-research":0.1492689596,"llms":0.4551191015,"data-quality":0.1402697414}}
{"text":"For videos, please visit https://www.robot-learning.uk/pose-estimation-perspective.","meta":{"url":"http://arxiv.org/abs/2310.12077v1"},"cats":{"benchmark":0.236544823,"new-dataset":0.3745470707,"data-annotation":0.5314727687,"dev-research":0.141118891,"llms":0.4668259243,"data-quality":0.0568651667}}
{"text":"It is not only sufficient to construct computational models that can accurately classify or detect fake images from real images taken from a camera, but it is also important to ensure whether these computational models are fair enough or produce biased outcomes that can eventually harm certain social groups or cause serious security threats.","meta":{"url":"http://arxiv.org/abs/2310.12076v1"},"cats":{"benchmark":0.3081267119,"new-dataset":0.0471439009,"data-annotation":0.521196431,"dev-research":0.1942843919,"llms":0.4748851548,"data-quality":0.1514582729}}
{"text":"Exploring fairness in forensic algorithms is an initial step towards correcting these biases.","meta":{"url":"http://arxiv.org/abs/2310.12076v1"},"cats":{"benchmark":0.477593469,"new-dataset":0.0094611561,"data-annotation":0.5064542572,"dev-research":0.2186481308,"llms":0.5077530283,"data-quality":0.1740021855}}
{"text":"Since visual transformers are recently being widely used in most image classification based tasks due to their capability to produce high accuracies, this study tries to explore bias in the transformer based image forensic algorithms that classify natural and GAN generated images.","meta":{"url":"http://arxiv.org/abs/2310.12076v1"},"cats":{"benchmark":0.2895301357,"new-dataset":0.0680108959,"data-annotation":0.518629893,"dev-research":0.1916459095,"llms":0.5329655264,"data-quality":0.2395586929}}
{"text":"By procuring a bias evaluation corpora, this study analyzes bias in gender, racial, affective, and intersectional domains using a wide set of individual and pairwise bias evaluation measures.","meta":{"url":"http://arxiv.org/abs/2310.12076v1"},"cats":{"benchmark":0.5098088113,"new-dataset":0.0409186129,"data-annotation":0.5438156808,"dev-research":0.2134398564,"llms":0.4727949088,"data-quality":0.1695655624}}
{"text":"As the generalizability of the algorithms against image compression is an important factor to be considered in forensic tasks, this study also analyzes the role of image compression on model bias.","meta":{"url":"http://arxiv.org/abs/2310.12076v1"},"cats":{"benchmark":0.4501333277,"new-dataset":0.014958385,"data-annotation":0.5228324567,"dev-research":0.1708060679,"llms":0.4028825029,"data-quality":0.1174505982}}
{"text":"Hence to study the impact of image compression on model bias, a two phase evaluation setting is followed, where a set of experiments is carried out in the uncompressed evaluation setting and the other in the compressed evaluation setting.","meta":{"url":"http://arxiv.org/abs/2310.12076v1"},"cats":{"benchmark":0.5799318472,"new-dataset":0.0099237417,"data-annotation":0.520045575,"dev-research":0.1461049126,"llms":0.415249508,"data-quality":0.1484863243}}
{"text":"The integration of autonomous vehicles into urban and highway environments necessitates the development of robust and adaptable behavior planning systems.","meta":{"url":"http://arxiv.org/abs/2310.12075v1"},"cats":{"benchmark":0.2183339413,"new-dataset":0.0464786009,"data-annotation":0.4757298006,"dev-research":0.2374684826,"llms":0.4597814696,"data-quality":0.0623003959}}
{"text":"This study presents an innovative approach to address this challenge by utilizing a Monte-Carlo Tree Search (MCTS) based algorithm for autonomous driving behavior planning.","meta":{"url":"http://arxiv.org/abs/2310.12075v1"},"cats":{"benchmark":0.3167974148,"new-dataset":0.0439411262,"data-annotation":0.5127559569,"dev-research":0.1676217236,"llms":0.4587333187,"data-quality":0.0639620072}}
{"text":"The core objective is to leverage the balance between exploration and exploitation inherent in MCTS to facilitate intelligent driving decisions in complex scenarios.   ","meta":{"url":"http://arxiv.org/abs/2310.12075v1"},"cats":{"benchmark":0.216960783,"new-dataset":0.013085345,"data-annotation":0.4893112286,"dev-research":0.2442463309,"llms":0.524910353,"data-quality":0.0541821873}}
{"text":"We introduce an MCTS-based algorithm tailored to the specific demands of autonomous driving.","meta":{"url":"http://arxiv.org/abs/2310.12075v1"},"cats":{"benchmark":0.4015883766,"new-dataset":0.0381512015,"data-annotation":0.5116341889,"dev-research":0.1761424172,"llms":0.4238327102,"data-quality":0.0770530542}}
{"text":"This involves the integration of carefully crafted cost functions, encompassing safety, comfort, and passability metrics, into the MCTS framework.","meta":{"url":"http://arxiv.org/abs/2310.12075v1"},"cats":{"benchmark":0.3662813363,"new-dataset":0.0455773263,"data-annotation":0.5178353089,"dev-research":0.32028239,"llms":0.5140725854,"data-quality":0.0648176602}}
{"text":"The effectiveness of our approach is demonstrated by enabling autonomous vehicles to navigate intricate scenarios, such as intersections, unprotected left turns, cut-ins, and ramps, even under traffic congestion, in real-time.   ","meta":{"url":"http://arxiv.org/abs/2310.12075v1"},"cats":{"benchmark":0.2654042888,"new-dataset":0.070719524,"data-annotation":0.5081215257,"dev-research":0.2665671155,"llms":0.4534904368,"data-quality":0.0513819581}}
{"text":"Qualitative instances illustrate the integration of diverse driving decisions, such as lane changes, acceleration, and deceleration, into the MCTS framework.","meta":{"url":"http://arxiv.org/abs/2310.12075v1"},"cats":{"benchmark":0.2648303986,"new-dataset":0.026164264,"data-annotation":0.4755175651,"dev-research":0.2730357189,"llms":0.491285237,"data-quality":0.0745947232}}
{"text":"Moreover, quantitative results, derived from examining the impact of iteration time and look-ahead steps on decision quality and real-time applicability, substantiate the robustness of our approach.","meta":{"url":"http://arxiv.org/abs/2310.12075v1"},"cats":{"benchmark":0.6495260855,"new-dataset":0.0063873458,"data-annotation":0.503731611,"dev-research":0.359246505,"llms":0.3827011026,"data-quality":0.1293097815}}
{"text":"This robustness is further underscored by the high success rate of the MCTS algorithm across various scenarios.","meta":{"url":"http://arxiv.org/abs/2310.12075v1"},"cats":{"benchmark":0.6494567794,"new-dataset":0.003611016,"data-annotation":0.5207087948,"dev-research":0.1177394073,"llms":0.4309312282,"data-quality":0.1889948227}}
{"text":"This paper introduces a new IncidentAI dataset for safety prevention.","meta":{"url":"http://arxiv.org/abs/2310.12074v1"},"cats":{"benchmark":0.265864373,"new-dataset":0.9119206831,"data-annotation":0.5090234202,"dev-research":0.3004085897,"llms":0.4847109937,"data-quality":0.1519710295}}
{"text":"Different from prior corpora that usually contain a single task, our dataset comprises three tasks: named entity recognition, cause-effect extraction, and information retrieval.","meta":{"url":"http://arxiv.org/abs/2310.12074v1"},"cats":{"benchmark":0.2974582264,"new-dataset":0.3656645595,"data-annotation":0.5031220642,"dev-research":0.2186071125,"llms":0.4605557622,"data-quality":0.2395061156}}
{"text":"The dataset is annotated by domain experts who have at least six years of practical experience as high-pressure gas conservation managers.","meta":{"url":"http://arxiv.org/abs/2310.12074v1"},"cats":{"benchmark":0.2689924961,"new-dataset":0.7579835173,"data-annotation":0.4737868911,"dev-research":0.2449991364,"llms":0.5444829899,"data-quality":0.1145866248}}
{"text":"We validate the contribution of the dataset in the scenario of safety prevention.","meta":{"url":"http://arxiv.org/abs/2310.12074v1"},"cats":{"benchmark":0.346242554,"new-dataset":0.625439329,"data-annotation":0.4981155567,"dev-research":0.340781384,"llms":0.4472176013,"data-quality":0.1439537738}}
{"text":"Preliminary results on the three tasks show that NLP techniques are beneficial for analyzing incident reports to prevent future failures.","meta":{"url":"http://arxiv.org/abs/2310.12074v1"},"cats":{"benchmark":0.3954625135,"new-dataset":0.0865806648,"data-annotation":0.5167596425,"dev-research":0.5020885991,"llms":0.5065463724,"data-quality":0.3523574959}}
{"text":"The dataset facilitates future research in NLP and incident management communities.","meta":{"url":"http://arxiv.org/abs/2310.12074v1"},"cats":{"benchmark":0.2224963863,"new-dataset":0.8034360427,"data-annotation":0.4833198467,"dev-research":0.3286445456,"llms":0.5363173152,"data-quality":0.1997863693}}
{"text":"The access to the dataset is also provided (the IncidentAI dataset is available at: https://github.com/Cinnamon/incident-ai-dataset).","meta":{"url":"http://arxiv.org/abs/2310.12074v1"},"cats":{"benchmark":0.190808862,"new-dataset":0.9167812457,"data-annotation":0.5050739852,"dev-research":0.131994228,"llms":0.5140596693,"data-quality":0.1270451885}}
{"text":"Generative Large Language Models (LLMs) based on the Transformer architecture have recently emerged as a dominant foundation model for a wide range of Natural Language Processing tasks.","meta":{"url":"http://arxiv.org/abs/2310.12072v1"},"cats":{"benchmark":0.1976193792,"new-dataset":0.0630110502,"data-annotation":0.5177612066,"dev-research":0.1162025161,"llms":0.690789345,"data-quality":0.1316723593}}
{"text":"Nevertheless, their application in real-time scenarios has been highly restricted due to the significant inference latency associated with these models.","meta":{"url":"http://arxiv.org/abs/2310.12072v1"},"cats":{"benchmark":0.4594408916,"new-dataset":0.0159909633,"data-annotation":0.5151605944,"dev-research":0.1655555369,"llms":0.3777016652,"data-quality":0.0811361915}}
{"text":"This is particularly pronounced due to the autoregressive nature of generative LLM inference, where tokens are generated sequentially since each token depends on all previous output tokens.","meta":{"url":"http://arxiv.org/abs/2310.12072v1"},"cats":{"benchmark":0.2442189434,"new-dataset":0.0153036721,"data-annotation":0.5243135459,"dev-research":0.1337190249,"llms":0.6507553576,"data-quality":0.2132926478}}
{"text":"It is therefore challenging to achieve any token-level parallelism, making inference extremely memory-bound.","meta":{"url":"http://arxiv.org/abs/2310.12072v1"},"cats":{"benchmark":0.379860947,"new-dataset":0.0109363991,"data-annotation":0.5229519027,"dev-research":0.1448365764,"llms":0.5785319677,"data-quality":0.0948981784}}
{"text":"In this work, we propose SPEED, which improves inference efficiency by speculatively executing multiple future tokens in parallel with the current token using predicted values based on early-layer hidden states.","meta":{"url":"http://arxiv.org/abs/2310.12072v1"},"cats":{"benchmark":0.4527463724,"new-dataset":0.037094941,"data-annotation":0.5340912688,"dev-research":0.1505082143,"llms":0.480199544,"data-quality":0.0918584277}}
{"text":"For Transformer decoders that employ parameter sharing, the memory operations for the tokens executing in parallel can be amortized, which allows us to accelerate generative LLM inference.","meta":{"url":"http://arxiv.org/abs/2310.12072v1"},"cats":{"benchmark":0.244593038,"new-dataset":0.0095133157,"data-annotation":0.5109284913,"dev-research":0.1113696261,"llms":0.7028785722,"data-quality":0.0615643932}}
{"text":"We demonstrate the efficiency of our method in terms of latency reduction relative to model accuracy and demonstrate how speculation allows for training deeper decoders with parameter sharing with minimal runtime overhead.","meta":{"url":"http://arxiv.org/abs/2310.12072v1"},"cats":{"benchmark":0.3322764768,"new-dataset":0.045568465,"data-annotation":0.5409367879,"dev-research":0.1597466948,"llms":0.4662514462,"data-quality":0.1336225578}}
{"text":"We propose using Bayesian Persuasion as a tool for social media platforms to combat the spread of online misinformation.","meta":{"url":"http://arxiv.org/abs/2310.12065v1"},"cats":{"benchmark":0.3291323113,"new-dataset":0.015913171,"data-annotation":0.5364710007,"dev-research":0.2955781369,"llms":0.5111925932,"data-quality":0.3150150467}}
{"text":"As platforms can predict the popularity and misinformation features of to-be-shared posts, and users are motivated to only share popular content, platforms can strategically reveal this informational advantage to persuade users to not share misinformed content.","meta":{"url":"http://arxiv.org/abs/2310.12065v1"},"cats":{"benchmark":0.2369086842,"new-dataset":0.0158379219,"data-annotation":0.5171361375,"dev-research":0.2569233069,"llms":0.4904278288,"data-quality":0.2203933409}}
{"text":"Our work mathematically characterizes the optimal information design scheme and the resulting utility when observations are not perfectly observed but arise from an imperfect classifier.","meta":{"url":"http://arxiv.org/abs/2310.12065v1"},"cats":{"benchmark":0.494944388,"new-dataset":0.0203962956,"data-annotation":0.5206292422,"dev-research":0.1980000086,"llms":0.3981010485,"data-quality":0.3709699077}}
{"text":"Framing the optimization problem as a linear program, we give sufficient and necessary conditions on the classifier accuracy to ensure platform utility under optimal signaling is monotonically increasing and continuous.","meta":{"url":"http://arxiv.org/abs/2310.12065v1"},"cats":{"benchmark":0.475934189,"new-dataset":0.015766726,"data-annotation":0.5256301454,"dev-research":0.1630456889,"llms":0.3569508925,"data-quality":0.2532274453}}
{"text":"We next consider this interaction under a performative model, wherein platform intervention through signaling affects the content distribution in the future.","meta":{"url":"http://arxiv.org/abs/2310.12065v1"},"cats":{"benchmark":0.2329556006,"new-dataset":0.0123670246,"data-annotation":0.4802777063,"dev-research":0.172589336,"llms":0.516820015,"data-quality":0.0935084172}}
{"text":"We fully characterize the convergence and stability of optimal signaling under this performative process.","meta":{"url":"http://arxiv.org/abs/2310.12065v1"},"cats":{"benchmark":0.3922021306,"new-dataset":0.0052074663,"data-annotation":0.5027604614,"dev-research":0.1034052265,"llms":0.412477075,"data-quality":0.0768236749}}
{"text":"Lastly, the broader scope of using information design to combat misinformation is discussed throughout.","meta":{"url":"http://arxiv.org/abs/2310.12065v1"},"cats":{"benchmark":0.214530298,"new-dataset":0.0083199924,"data-annotation":0.4868728955,"dev-research":0.3904059792,"llms":0.5698967994,"data-quality":0.2660548638}}
{"text":"This paper presents a scheme for annotating coreference across news articles, extending beyond traditional identity relations by also considering near-identity and bridging relations.","meta":{"url":"http://arxiv.org/abs/2310.12064v1"},"cats":{"benchmark":0.3073290521,"new-dataset":0.2294275252,"data-annotation":0.5399536701,"dev-research":0.2502380869,"llms":0.5462929692,"data-quality":0.3680682319}}
{"text":"It includes a precise description of how to set up Inception, a respective annotation tool, how to annotate entities in news articles, connect them with diverse coreferential relations, and link them across documents to Wikidata's global knowledge graph.","meta":{"url":"http://arxiv.org/abs/2310.12064v1"},"cats":{"benchmark":0.2020603014,"new-dataset":0.3516891514,"data-annotation":0.5240374664,"dev-research":0.3170005063,"llms":0.5698602418,"data-quality":0.2089307956}}
{"text":"This multi-layered annotation approach is discussed in the context of the problem of media bias.","meta":{"url":"http://arxiv.org/abs/2310.12064v1"},"cats":{"benchmark":0.3287894746,"new-dataset":0.0933368649,"data-annotation":0.5486287917,"dev-research":0.2370494886,"llms":0.4994104458,"data-quality":0.583236924}}
{"text":"Our main contribution lies in providing a methodology for creating a diverse cross-document coreference corpus which can be applied to the analysis of media bias by word-choice and labelling.","meta":{"url":"http://arxiv.org/abs/2310.12064v1"},"cats":{"benchmark":0.3810325548,"new-dataset":0.1420793514,"data-annotation":0.5497939413,"dev-research":0.1713761057,"llms":0.5541987648,"data-quality":0.3672292051}}
{"text":"Since their inception Generative Adversarial Networks (GANs) have been popular generative models across images, audio, video, and tabular data.","meta":{"url":"http://arxiv.org/abs/2310.12063v1"},"cats":{"benchmark":0.1743011922,"new-dataset":0.1381593584,"data-annotation":0.5031978897,"dev-research":0.1516938841,"llms":0.520921495,"data-quality":0.1097973433}}
{"text":"In this paper we study whether given access to a trained GAN, as well as fresh samples from the underlying distribution, if it is possible for an attacker to efficiently identify if a given point is a member of the GAN's training data.","meta":{"url":"http://arxiv.org/abs/2310.12063v1"},"cats":{"benchmark":0.2618719612,"new-dataset":0.0739056937,"data-annotation":0.5281734868,"dev-research":0.1470991234,"llms":0.5015329292,"data-quality":0.2540515172}}
{"text":"This is of interest for both reasons related to copyright, where a user may want to determine if their copyrighted data has been used to train a GAN, and in the study of data privacy, where the ability to detect training set membership is known as a membership inference attack.","meta":{"url":"http://arxiv.org/abs/2310.12063v1"},"cats":{"benchmark":0.2094404452,"new-dataset":0.0545028159,"data-annotation":0.5210794639,"dev-research":0.1855187285,"llms":0.554756509,"data-quality":0.2882479529}}
{"text":"Unlike the majority of prior work this paper investigates the privacy implications of using GANs in black-box settings, where the attack only has access to samples from the generator, rather than access to the discriminator as well.","meta":{"url":"http://arxiv.org/abs/2310.12063v1"},"cats":{"benchmark":0.2027470721,"new-dataset":0.0207924954,"data-annotation":0.5106201161,"dev-research":0.1486369998,"llms":0.5771613736,"data-quality":0.1554762191}}
{"text":"We introduce a suite of membership inference attacks against GANs in the black-box setting and evaluate our attacks on image GANs trained on the CIFAR10 dataset and tabular GANs trained on genomic data.","meta":{"url":"http://arxiv.org/abs/2310.12063v1"},"cats":{"benchmark":0.2545323138,"new-dataset":0.1407857603,"data-annotation":0.5186870352,"dev-research":0.1756431137,"llms":0.5113008096,"data-quality":0.2369187786}}
{"text":"Our most successful attack, called The Detector, involve training a second network to score samples based on their likelihood of being generated by the GAN, as opposed to a fresh sample from the distribution.","meta":{"url":"http://arxiv.org/abs/2310.12063v1"},"cats":{"benchmark":0.323513033,"new-dataset":0.0475478098,"data-annotation":0.525855454,"dev-research":0.1397224216,"llms":0.5006707227,"data-quality":0.2645964661}}
{"text":"We prove under a simple model of the generator that the detector is an approximately optimal membership inference attack.","meta":{"url":"http://arxiv.org/abs/2310.12063v1"},"cats":{"benchmark":0.3446530533,"new-dataset":0.0201521479,"data-annotation":0.5577219808,"dev-research":0.107834737,"llms":0.5193182178,"data-quality":0.2319570446}}
{"text":"Across a wide range of tabular and image datasets, attacks, and GAN architectures, we find that adversaries can orchestrate non-trivial privacy attacks when provided with access to samples from the generator.","meta":{"url":"http://arxiv.org/abs/2310.12063v1"},"cats":{"benchmark":0.1783414637,"new-dataset":0.1427683825,"data-annotation":0.5011611994,"dev-research":0.1617770429,"llms":0.5798012385,"data-quality":0.1707958235}}
{"text":"At the same time, the attack success achievable against GANs still appears to be lower compared to other generative and discriminative models; this leaves the intriguing open question of whether GANs are in fact more private, or if it is a matter of developing stronger attacks.","meta":{"url":"http://arxiv.org/abs/2310.12063v1"},"cats":{"benchmark":0.2988513764,"new-dataset":0.0060774694,"data-annotation":0.5278288083,"dev-research":0.1538170411,"llms":0.5581586724,"data-quality":0.1056124061}}
{"text":"This work presents a study on how to exploit the CLIP embedding space to perform Visual Sentiment Analysis.","meta":{"url":"http://arxiv.org/abs/2310.12062v1"},"cats":{"benchmark":0.3234419504,"new-dataset":0.0828420146,"data-annotation":0.5454016048,"dev-research":0.2603576985,"llms":0.4644680085,"data-quality":0.2456310221}}
{"text":"We experiment with two architectures built on top of the CLIP embedding space, which we denote by CLIP-E. We train the CLIP-E models with WEBEmo, the largest publicly available and manually labeled benchmark for Visual Sentiment Analysis, and perform two sets of experiments.","meta":{"url":"http://arxiv.org/abs/2310.12062v1"},"cats":{"benchmark":0.4528265208,"new-dataset":0.1211470141,"data-annotation":0.5425962649,"dev-research":0.2117993324,"llms":0.5151967591,"data-quality":0.2458941445}}
{"text":"First, we test on WEBEmo and compare the CLIP-E architectures with state-of-the-art (SOTA) models and with CLIP Zero-Shot.","meta":{"url":"http://arxiv.org/abs/2310.12062v1"},"cats":{"benchmark":0.4306125351,"new-dataset":0.0429989055,"data-annotation":0.5022306422,"dev-research":0.1043521483,"llms":0.5540500452,"data-quality":0.075690219}}
{"text":"Second, we perform cross dataset evaluation, and test the CLIP-E architectures trained with WEBEmo on other Visual Sentiment Analysis benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.12062v1"},"cats":{"benchmark":0.4568630233,"new-dataset":0.1973900349,"data-annotation":0.5303911876,"dev-research":0.185391923,"llms":0.5259585967,"data-quality":0.2492203013}}
{"text":"Our results show that the CLIP-E approaches outperform SOTA models in WEBEmo fine grained categorization, and they also generalize better when tested on datasets that have not been seen during training.","meta":{"url":"http://arxiv.org/abs/2310.12062v1"},"cats":{"benchmark":0.3474249016,"new-dataset":0.0606687622,"data-annotation":0.5272720867,"dev-research":0.1203852014,"llms":0.508741883,"data-quality":0.2739589241}}
{"text":"Interestingly, we observed that for the FI dataset, CLIP Zero-Shot produces better accuracies than SOTA models and CLIP-E trained on WEBEmo.","meta":{"url":"http://arxiv.org/abs/2310.12062v1"},"cats":{"benchmark":0.3870001767,"new-dataset":0.0975923432,"data-annotation":0.5116595397,"dev-research":0.0844379924,"llms":0.5239679609,"data-quality":0.1473133297}}
{"text":"These results motivate several questions that we discuss in this paper, such as how we should design new benchmarks and evaluate Visual Sentiment Analysis, and whether we should keep designing tailored Deep Learning models for Visual Sentiment Analysis or focus our efforts on better using the knowledge encoded in large vision-language models such as CLIP for this task.","meta":{"url":"http://arxiv.org/abs/2310.12062v1"},"cats":{"benchmark":0.2933079791,"new-dataset":0.2854945008,"data-annotation":0.5378323766,"dev-research":0.2490042229,"llms":0.4850112566,"data-quality":0.2100611858}}
{"text":"Unwanted samples from private source categories in the learning objective of a partial domain adaptation setup can lead to negative transfer and reduce classification performance.","meta":{"url":"http://arxiv.org/abs/2310.12060v1"},"cats":{"benchmark":0.2838170608,"new-dataset":0.0377688557,"data-annotation":0.5087147861,"dev-research":0.1563843969,"llms":0.5523452308,"data-quality":0.3234721128}}
{"text":"Existing methods, such as re-weighting or aggregating target predictions, are vulnerable to this issue, especially during initial training stages, and do not adequately address overlapping categorical distributions.","meta":{"url":"http://arxiv.org/abs/2310.12060v1"},"cats":{"benchmark":0.4402583367,"new-dataset":0.0116719966,"data-annotation":0.521841829,"dev-research":0.1973355322,"llms":0.4299167054,"data-quality":0.2804948749}}
{"text":"We propose a solution to overcome these limitations by exploring beyond the first-order moments for robust alignment of categorical distributions.","meta":{"url":"http://arxiv.org/abs/2310.12060v1"},"cats":{"benchmark":0.4281935243,"new-dataset":0.0680759446,"data-annotation":0.5213925969,"dev-research":0.1452273157,"llms":0.4112144199,"data-quality":0.2925567864}}
{"text":"We employ objectives that optimize the intra and inter-class distributions in a domain-invariant fashion and design a robust pseudo-labeling for efficient target supervision.","meta":{"url":"http://arxiv.org/abs/2310.12060v1"},"cats":{"benchmark":0.3635516213,"new-dataset":0.1171531349,"data-annotation":0.5317162404,"dev-research":0.1780550171,"llms":0.4615419817,"data-quality":0.5053210717}}
{"text":"Our approach incorporates a complement entropy objective module to reduce classification uncertainty and flatten incorrect category predictions.","meta":{"url":"http://arxiv.org/abs/2310.12060v1"},"cats":{"benchmark":0.4771338998,"new-dataset":0.0334885214,"data-annotation":0.5293198921,"dev-research":0.2229588445,"llms":0.4548733891,"data-quality":0.5376094361}}
{"text":"The experimental findings and ablation analysis of the proposed modules demonstrate the superior performance of our proposed model compared to benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.12060v1"},"cats":{"benchmark":0.5497784094,"new-dataset":0.0194863773,"data-annotation":0.5123791859,"dev-research":0.1320965353,"llms":0.5025856066,"data-quality":0.1070727109}}
{"text":"In this paper, we evaluate the ability of large language models (LLMs) to perform multiple choice symbol binding (MCSB) for multiple choice question answering (MCQA) tasks in zero-shot, one-shot, and few-shot settings.","meta":{"url":"http://arxiv.org/abs/2310.12059v1"},"cats":{"benchmark":0.2885989689,"new-dataset":0.1062903316,"data-annotation":0.5215828631,"dev-research":0.139414207,"llms":0.6008344235,"data-quality":0.1041683174}}
{"text":"We focus on Vietnamese, with fewer challenging MCQA datasets than in English.","meta":{"url":"http://arxiv.org/abs/2310.12059v1"},"cats":{"benchmark":0.2808713988,"new-dataset":0.3253267149,"data-annotation":0.5278163174,"dev-research":0.1344259537,"llms":0.5382941713,"data-quality":0.2432361571}}
{"text":"The two existing datasets, ViMMRC 1.0 and ViMMRC 2.0, focus on literature.","meta":{"url":"http://arxiv.org/abs/2310.12059v1"},"cats":{"benchmark":0.3162789474,"new-dataset":0.856632288,"data-annotation":0.5059315828,"dev-research":0.144948726,"llms":0.543859137,"data-quality":0.1249932718}}
{"text":"Recent research in Vietnamese natural language processing (NLP) has focused on the Vietnamese National High School Graduation Examination (VNHSGE) from 2019 to 2023 to evaluate ChatGPT.","meta":{"url":"http://arxiv.org/abs/2310.12059v1"},"cats":{"benchmark":0.335589474,"new-dataset":0.2094571184,"data-annotation":0.5299914505,"dev-research":0.1983824033,"llms":0.5660950503,"data-quality":0.1981435541}}
{"text":"However, these studies have mainly focused on how ChatGPT solves the VNHSGE step by step.","meta":{"url":"http://arxiv.org/abs/2310.12059v1"},"cats":{"benchmark":0.3197271375,"new-dataset":0.0302321263,"data-annotation":0.5263021709,"dev-research":0.2312153962,"llms":0.558110483,"data-quality":0.0555008729}}
{"text":"We aim to create a novel and high-quality dataset by providing structured guidelines for typing LaTeX formulas for mathematics, physics, chemistry, and biology.","meta":{"url":"http://arxiv.org/abs/2310.12059v1"},"cats":{"benchmark":0.3569268771,"new-dataset":0.6473791146,"data-annotation":0.5153703945,"dev-research":0.2672052072,"llms":0.459539353,"data-quality":0.1375058898}}
{"text":"This dataset can be used to evaluate the MCSB ability of LLMs and smaller language models (LMs) because it is typed in a strict LaTeX style.","meta":{"url":"http://arxiv.org/abs/2310.12059v1"},"cats":{"benchmark":0.2992008249,"new-dataset":0.3236194777,"data-annotation":0.5092266916,"dev-research":0.0988243967,"llms":0.6807980289,"data-quality":0.1439362735}}
{"text":"We focus on predicting the character (A, B, C, or D) that is the most likely answer to a question, given the context of the question.","meta":{"url":"http://arxiv.org/abs/2310.12059v1"},"cats":{"benchmark":0.3010500405,"new-dataset":0.0461722011,"data-annotation":0.5578217154,"dev-research":0.2103162732,"llms":0.4359252068,"data-quality":0.0965695999}}
{"text":"Our evaluation of six well-known LLMs, namely BLOOMZ-7.1B-MT, LLaMA-2-7B, LLaMA-2-70B, GPT-3, GPT-3.5, and GPT-4.0, on the ViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promising results on the MCSB ability of LLMs for Vietnamese.","meta":{"url":"http://arxiv.org/abs/2310.12059v1"},"cats":{"benchmark":0.4646190651,"new-dataset":0.1269237086,"data-annotation":0.5026060156,"dev-research":0.0749997762,"llms":0.7664407975,"data-quality":0.096469259}}
{"text":"The dataset is available for research purposes only.","meta":{"url":"http://arxiv.org/abs/2310.12059v1"},"cats":{"benchmark":0.1774606225,"new-dataset":0.7220464079,"data-annotation":0.4758775984,"dev-research":0.0986036185,"llms":0.5294966727,"data-quality":0.0523853465}}
{"text":"Small Unmanned Aerial Systems (sUAS) must meet rigorous safety standards when deployed in high-stress emergency response scenarios.","meta":{"url":"http://arxiv.org/abs/2310.12058v1"},"cats":{"benchmark":0.3479164493,"new-dataset":0.0485556729,"data-annotation":0.4892588027,"dev-research":0.2848476727,"llms":0.5474901109,"data-quality":0.068233439}}
{"text":"However, tests that execute perfectly in simulation can fail dramatically in real-world environments.","meta":{"url":"http://arxiv.org/abs/2310.12058v1"},"cats":{"benchmark":0.4458694395,"new-dataset":0.008026816,"data-annotation":0.5112128664,"dev-research":0.2590298174,"llms":0.5251105451,"data-quality":0.2067633525}}
{"text":"Fuzz testing can be used to increase system robustness by providing malformed input data aimed at triggering failure cases.","meta":{"url":"http://arxiv.org/abs/2310.12058v1"},"cats":{"benchmark":0.3868909799,"new-dataset":0.0433934928,"data-annotation":0.4962867701,"dev-research":0.411232343,"llms":0.5547430852,"data-quality":0.3787583847}}
{"text":"In this paper, we apply fuzzing to support human interaction testing.","meta":{"url":"http://arxiv.org/abs/2310.12058v1"},"cats":{"benchmark":0.4049827866,"new-dataset":0.1040751544,"data-annotation":0.5315436817,"dev-research":0.3845717086,"llms":0.5451567661,"data-quality":0.1738637325}}
{"text":"Initial tests are run in simulation to provide broad coverage of the input space in a safe environment; however, they lack the fidelity of real-world tests.","meta":{"url":"http://arxiv.org/abs/2310.12058v1"},"cats":{"benchmark":0.367685212,"new-dataset":0.0225388465,"data-annotation":0.5118847802,"dev-research":0.2444748724,"llms":0.5030993656,"data-quality":0.1050564446}}
{"text":"Field tests provide higher fidelity but can result in costly or dangerous crashes.","meta":{"url":"http://arxiv.org/abs/2310.12058v1"},"cats":{"benchmark":0.5135773372,"new-dataset":0.0090647615,"data-annotation":0.5177120198,"dev-research":0.2274880882,"llms":0.5095585977,"data-quality":0.1381525653}}
{"text":"We, therefore, propose and demonstrate HiFuzz, which executes large numbers of fuzz tests in simulation and then down-selects tests for deployment in human-in-the-loop simulations and safety-aware physical field tests.","meta":{"url":"http://arxiv.org/abs/2310.12058v1"},"cats":{"benchmark":0.3869010929,"new-dataset":0.2416780441,"data-annotation":0.507798128,"dev-research":0.4256032591,"llms":0.583071162,"data-quality":0.1174301893}}
{"text":"We apply \\hf to a multi-sUAS system and show that each test level serves a unique purpose in identifying known and unknown failures associated with human interactions.","meta":{"url":"http://arxiv.org/abs/2310.12058v1"},"cats":{"benchmark":0.4735052187,"new-dataset":0.0953055831,"data-annotation":0.5157141028,"dev-research":0.2223707119,"llms":0.4805544714,"data-quality":0.1577422167}}
{"text":"In inverse reinforcement learning (IRL), the central objective is to infer underlying reward functions from observed expert behaviors in a way that not only explains the given data but also generalizes to unseen scenarios.","meta":{"url":"http://arxiv.org/abs/2310.12055v1"},"cats":{"benchmark":0.2256592031,"new-dataset":0.0384899674,"data-annotation":0.5263142148,"dev-research":0.2155164435,"llms":0.451173477,"data-quality":0.1011430381}}
{"text":"This ensures robustness against reward ambiguity where multiple reward functions can equally explain the same expert behaviors.","meta":{"url":"http://arxiv.org/abs/2310.12055v1"},"cats":{"benchmark":0.2990781405,"new-dataset":0.001630078,"data-annotation":0.5309205346,"dev-research":0.2421226024,"llms":0.4328091047,"data-quality":0.139041714}}
{"text":"While significant efforts have been made in addressing this issue, current methods often face challenges with high-dimensional problems and lack a geometric foundation.","meta":{"url":"http://arxiv.org/abs/2310.12055v1"},"cats":{"benchmark":0.5490191649,"new-dataset":0.0067386642,"data-annotation":0.5302428927,"dev-research":0.2064212204,"llms":0.4000091875,"data-quality":0.0882003939}}
{"text":"This paper harnesses the optimal transport (OT) theory to provide a fresh perspective on these challenges.","meta":{"url":"http://arxiv.org/abs/2310.12055v1"},"cats":{"benchmark":0.4630879502,"new-dataset":0.0035959484,"data-annotation":0.5079997075,"dev-research":0.1167560041,"llms":0.380531528,"data-quality":0.0645259213}}
{"text":"By utilizing the Wasserstein distance from OT, we establish a geometric framework that allows for quantifying reward ambiguity and identifying a central representation or centroid of reward functions.","meta":{"url":"http://arxiv.org/abs/2310.12055v1"},"cats":{"benchmark":0.4164046246,"new-dataset":0.0243794422,"data-annotation":0.5529376361,"dev-research":0.1159924422,"llms":0.3743875296,"data-quality":0.1503384203}}
{"text":"These insights pave the way for robust IRL methodologies anchored in geometric interpretations, offering a structured approach to tackle reward ambiguity in high-dimensional settings.","meta":{"url":"http://arxiv.org/abs/2310.12055v1"},"cats":{"benchmark":0.2810771321,"new-dataset":0.014378871,"data-annotation":0.5101480527,"dev-research":0.2505096673,"llms":0.4273279276,"data-quality":0.1241238793}}
{"text":"Robotic manipulation can greatly benefit from the data efficiency, robustness, and predictability of model-based methods if robots can quickly generate models of novel objects they encounter.","meta":{"url":"http://arxiv.org/abs/2310.12054v1"},"cats":{"benchmark":0.2549026628,"new-dataset":0.0563024663,"data-annotation":0.5048758455,"dev-research":0.2062553695,"llms":0.4513277035,"data-quality":0.0462097584}}
{"text":"This is especially difficult when effects like complex joint friction lack clear first-principles models and are usually ignored by physics simulators.","meta":{"url":"http://arxiv.org/abs/2310.12054v1"},"cats":{"benchmark":0.4350074814,"new-dataset":0.0072914055,"data-annotation":0.5239562931,"dev-research":0.1890783151,"llms":0.4828743656,"data-quality":0.0621146237}}
{"text":"Further, numerically-stiff contact dynamics can make common model-building approaches struggle.","meta":{"url":"http://arxiv.org/abs/2310.12054v1"},"cats":{"benchmark":0.3921403739,"new-dataset":0.0264394911,"data-annotation":0.5031991687,"dev-research":0.2202438032,"llms":0.4894794261,"data-quality":0.0411584691}}
{"text":"We propose a method to simultaneously learn contact and continuous dynamics of a novel, possibly multi-link object by observing its motion through contact-rich trajectories.","meta":{"url":"http://arxiv.org/abs/2310.12054v1"},"cats":{"benchmark":0.2373048543,"new-dataset":0.2265955067,"data-annotation":0.5147293675,"dev-research":0.1611206326,"llms":0.4791436068,"data-quality":0.0440851454}}
{"text":"We formulate a system identification process with a loss that infers unmeasured contact forces, penalizing their violation of physical constraints and laws of motion given current model parameters.","meta":{"url":"http://arxiv.org/abs/2310.12054v1"},"cats":{"benchmark":0.3777788313,"new-dataset":0.044447838,"data-annotation":0.5325169575,"dev-research":0.215630211,"llms":0.4264199456,"data-quality":0.1647613433}}
{"text":"Our loss is unlike prediction-based losses used in differentiable simulation.","meta":{"url":"http://arxiv.org/abs/2310.12054v1"},"cats":{"benchmark":0.4416351115,"new-dataset":0.0158202677,"data-annotation":0.5296302962,"dev-research":0.1864262217,"llms":0.3985311258,"data-quality":0.1146084685}}
{"text":"Using a new dataset of real articulated object trajectories and an existing cube toss dataset, our method outperforms differentiable simulation and end-to-end alternatives with more data efficiency.","meta":{"url":"http://arxiv.org/abs/2310.12054v1"},"cats":{"benchmark":0.283057405,"new-dataset":0.6430322075,"data-annotation":0.5114538038,"dev-research":0.13896483,"llms":0.453452822,"data-quality":0.0498271637}}
{"text":"See our project page for code, datasets, and media: https://sites.google.com/view/continuous-contact-nets/home","meta":{"url":"http://arxiv.org/abs/2310.12054v1"},"cats":{"benchmark":0.2287046695,"new-dataset":0.7584785437,"data-annotation":0.4837010791,"dev-research":0.179775178,"llms":0.5369976889,"data-quality":0.0770597552}}
{"text":"This study addresses the vital role of data analytics in monitoring fertiliser applications in crop cultivation.","meta":{"url":"http://arxiv.org/abs/2310.12052v1"},"cats":{"benchmark":0.3526936015,"new-dataset":0.1772301057,"data-annotation":0.4747342005,"dev-research":0.2735250832,"llms":0.4201211687,"data-quality":0.1287257252}}
{"text":"Inaccurate fertiliser application decisions can lead to costly consequences, hinder food production, and cause environmental harm.","meta":{"url":"http://arxiv.org/abs/2310.12052v1"},"cats":{"benchmark":0.3472983308,"new-dataset":0.0054279126,"data-annotation":0.4968803549,"dev-research":0.3427574693,"llms":0.4922546034,"data-quality":0.2441607592}}
{"text":"We propose a solution to predict nutrient application by determining required fertiliser quantities for an entire season.","meta":{"url":"http://arxiv.org/abs/2310.12052v1"},"cats":{"benchmark":0.3902603937,"new-dataset":0.0282408327,"data-annotation":0.513726888,"dev-research":0.1548506012,"llms":0.3408425051,"data-quality":0.0743078924}}
{"text":"The proposed solution recommends adjusting fertiliser amounts based on weather conditions and soil characteristics to promote cost-effective and environmentally friendly agriculture.","meta":{"url":"http://arxiv.org/abs/2310.12052v1"},"cats":{"benchmark":0.4459596454,"new-dataset":0.0110306053,"data-annotation":0.4982095147,"dev-research":0.2611606416,"llms":0.4480150254,"data-quality":0.0571101366}}
{"text":"The collected dataset is high-dimensional and heterogeneous.","meta":{"url":"http://arxiv.org/abs/2310.12052v1"},"cats":{"benchmark":0.3009277695,"new-dataset":0.7798415244,"data-annotation":0.4904284243,"dev-research":0.1167955276,"llms":0.4296574001,"data-quality":0.0769336408}}
{"text":"Our research examines large-scale heterogeneous datasets in the context of the decision-making process, encompassing data collection and analysis.","meta":{"url":"http://arxiv.org/abs/2310.12052v1"},"cats":{"benchmark":0.3041624476,"new-dataset":0.3499483943,"data-annotation":0.4584649838,"dev-research":0.2186122401,"llms":0.4495138837,"data-quality":0.0915009287}}
{"text":"We also study the impact of fertiliser applications combined with weather data on crop yield, using the winter wheat crop as a case study.","meta":{"url":"http://arxiv.org/abs/2310.12052v1"},"cats":{"benchmark":0.4419319891,"new-dataset":0.0462050029,"data-annotation":0.5056746502,"dev-research":0.1984546327,"llms":0.4105029441,"data-quality":0.0700493736}}
{"text":"By understanding local contextual and geographic factors, we aspire to stabilise or even reduce the demand for agricultural nutrients while enhancing crop development.","meta":{"url":"http://arxiv.org/abs/2310.12052v1"},"cats":{"benchmark":0.3199276236,"new-dataset":0.0237391116,"data-annotation":0.4883170678,"dev-research":0.2112613895,"llms":0.440859437,"data-quality":0.0693602366}}
{"text":"The proposed approach is proven to be efficient and scalable, as it is validated using a real-world and large dataset.","meta":{"url":"http://arxiv.org/abs/2310.12052v1"},"cats":{"benchmark":0.5667195493,"new-dataset":0.3674525136,"data-annotation":0.4931590271,"dev-research":0.1513866073,"llms":0.3873379594,"data-quality":0.1412356883}}
{"text":"We provide a variety of lower bounds for the well-known shortcut set problem: how much can one decrease the diameter of a directed graph on $n$ vertices and $m$ edges by adding $O(n)$ or $O(m)$ of shortcuts from the transitive closure of the graph.","meta":{"url":"http://arxiv.org/abs/2310.12051v1"},"cats":{"benchmark":0.4769358556,"new-dataset":0.0565979312,"data-annotation":0.5408542666,"dev-research":0.2069887553,"llms":0.515057247,"data-quality":0.1337436432}}
{"text":"Our results are based on a vast simplification of the recent construction of Bodwin and Hoppenworth [FOCS 2023] which was used to show an $\\widetilde{\\Omega}(n^{1/4})$ lower bound for the $O(n)$-sized shortcut set problem.","meta":{"url":"http://arxiv.org/abs/2310.12051v1"},"cats":{"benchmark":0.4865480723,"new-dataset":0.1450908281,"data-annotation":0.5434565417,"dev-research":0.178822354,"llms":0.5416050362,"data-quality":0.0773748516}}
{"text":"We highlight that our simplification completely removes the use of the convex sets by B\\'ar\\'any and Larman [Math.","meta":{"url":"http://arxiv.org/abs/2310.12051v1"},"cats":{"benchmark":0.4906591745,"new-dataset":0.0251680274,"data-annotation":0.5458698072,"dev-research":0.1459089003,"llms":0.4123963367,"data-quality":0.2365134211}}
{"text":"Ann. 1998] used in all previous lower bound constructions.","meta":{"url":"http://arxiv.org/abs/2310.12051v1"},"cats":{"benchmark":0.4047264225,"new-dataset":0.0704976296,"data-annotation":0.5479997578,"dev-research":0.2426605261,"llms":0.5198817071,"data-quality":0.185313686}}
{"text":"Our simplification also removes the need for randomness and further removes some log factors.","meta":{"url":"http://arxiv.org/abs/2310.12051v1"},"cats":{"benchmark":0.4563419619,"new-dataset":0.0050371597,"data-annotation":0.5179373593,"dev-research":0.1761699651,"llms":0.4539759847,"data-quality":0.1447323933}}
{"text":"This allows us to generalize the construction to higher dimensions, which in turn can be used to show the following results.","meta":{"url":"http://arxiv.org/abs/2310.12051v1"},"cats":{"benchmark":0.3340377955,"new-dataset":0.0136655631,"data-annotation":0.5367551746,"dev-research":0.2068546312,"llms":0.459764683,"data-quality":0.060224039}}
{"text":"For $O(m)$-sized shortcut sets, we show an $\\Omega(n^{1/5})$ lower bound, improving on the previous best $\\Omega(n^{1/8})$ lower bound.","meta":{"url":"http://arxiv.org/abs/2310.12051v1"},"cats":{"benchmark":0.5319319676,"new-dataset":0.0643892255,"data-annotation":0.5413767971,"dev-research":0.1633405902,"llms":0.5779508119,"data-quality":0.0741322132}}
{"text":"For all $\\varepsilon > 0$, we show that there exists a $\\delta > 0$ such that there are $n$-vertex $O(n)$-edge graphs $G$ where adding any shortcut set of size $O(n^{2-\\varepsilon})$ keeps the diameter of $G$ at $\\Omega(n^\\delta)$. This improves the sparsity of the constructed graph compared to a known similar result by Hesse","meta":{"url":"http://arxiv.org/abs/2310.12051v1"},"cats":{"benchmark":0.3644382602,"new-dataset":0.0555514089,"data-annotation":0.515394782,"dev-research":0.2385091326,"llms":0.5401334439,"data-quality":0.1517624459}}
{"text":"[SODA 2003].   ","meta":{"url":"http://arxiv.org/abs/2310.12051v1"},"cats":{"benchmark":0.3307481005,"new-dataset":0.221311832,"data-annotation":0.5039615486,"dev-research":0.184786123,"llms":0.4967293002,"data-quality":0.2162969013}}
{"text":"We also consider the sourcewise setting for shortcut sets: given a graph $G=(V,E)$, a set $S\\subseteq V$, how much can we decrease the sourcewise diameter of $G$, $\\max_{(s, v) \\in S \\times V, \\text{dist}(s, v) <","meta":{"url":"http://arxiv.org/abs/2310.12051v1"},"cats":{"benchmark":0.4395495539,"new-dataset":0.0619087945,"data-annotation":0.5144846624,"dev-research":0.227695927,"llms":0.4876190889,"data-quality":0.1229737428}}
{"text":"\\infty} \\text{dist}(s,v)$ by adding a set of edges $H$ from the transitive closure of $G$?","meta":{"url":"http://arxiv.org/abs/2310.12051v1"},"cats":{"benchmark":0.3715593844,"new-dataset":0.027420033,"data-annotation":0.5065683745,"dev-research":0.124355999,"llms":0.5831293123,"data-quality":0.0862359093}}
{"text":"We show that for any integer $d \\ge 2$, there exists a graph $G=(V, E)$ on $n$ vertices and $S \\subseteq V$ with $|S| = \\widetilde{\\Theta}(n^{3/(d+3)})$, such that when adding $O(n)$ or $O(m)$ shortcuts, the sourcewise diameter is $\\widetilde{\\Omega}(|S|^{1/3})$.","meta":{"url":"http://arxiv.org/abs/2310.12051v1"},"cats":{"benchmark":0.3178305724,"new-dataset":0.0826078132,"data-annotation":0.5083515103,"dev-research":0.190873859,"llms":0.5543927735,"data-quality":0.1394492694}}
{"text":"Existing text scaling methods often require a large corpus, struggle with short texts, or require labeled data.","meta":{"url":"http://arxiv.org/abs/2310.12049v1"},"cats":{"benchmark":0.4336201267,"new-dataset":0.0611913308,"data-annotation":0.5177759664,"dev-research":0.1890951947,"llms":0.4981980347,"data-quality":0.3041633309}}
{"text":"We develop a text scaling method that leverages the pattern recognition capabilities of generative large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2310.12049v1"},"cats":{"benchmark":0.3187421192,"new-dataset":0.0849196647,"data-annotation":0.5294563766,"dev-research":0.1018394678,"llms":0.6267014803,"data-quality":0.1427098114}}
{"text":"Specifically, we propose concept-guided chain-of-thought (CGCoT), which uses prompts designed to summarize ideas and identify target parties in texts to generate concept-specific breakdowns, in many ways similar to guidance for human coder content analysis.","meta":{"url":"http://arxiv.org/abs/2310.12049v1"},"cats":{"benchmark":0.208407311,"new-dataset":0.1316085857,"data-annotation":0.53923655,"dev-research":0.4517796672,"llms":0.5932967283,"data-quality":0.2269491373}}
{"text":"CGCoT effectively shifts pairwise text comparisons from a reasoning problem to a pattern recognition problem.","meta":{"url":"http://arxiv.org/abs/2310.12049v1"},"cats":{"benchmark":0.4665215713,"new-dataset":0.0912216327,"data-annotation":0.5361147219,"dev-research":0.2391155872,"llms":0.4736316011,"data-quality":0.3001481384}}
{"text":"We then pairwise compare concept-specific breakdowns using an LLM.","meta":{"url":"http://arxiv.org/abs/2310.12049v1"},"cats":{"benchmark":0.5782235532,"new-dataset":0.0385777574,"data-annotation":0.5277529657,"dev-research":0.1877276613,"llms":0.6326120238,"data-quality":0.1936416729}}
{"text":"We use the results of these pairwise comparisons to estimate a scale using the Bradley-Terry model.","meta":{"url":"http://arxiv.org/abs/2310.12049v1"},"cats":{"benchmark":0.63917989,"new-dataset":0.0328582184,"data-annotation":0.517786807,"dev-research":0.1021006733,"llms":0.4447193807,"data-quality":0.0672103848}}
{"text":"We use this approach to scale affective speech on Twitter.","meta":{"url":"http://arxiv.org/abs/2310.12049v1"},"cats":{"benchmark":0.3152260198,"new-dataset":0.0516213753,"data-annotation":0.5366907779,"dev-research":0.2028579125,"llms":0.5285553381,"data-quality":0.1226999782}}
{"text":"Our measures correlate more strongly with human judgments than alternative approaches like Wordfish.","meta":{"url":"http://arxiv.org/abs/2310.12049v1"},"cats":{"benchmark":0.4302647869,"new-dataset":0.0131183349,"data-annotation":0.523097218,"dev-research":0.2402412184,"llms":0.5332291375,"data-quality":0.1831390128}}
{"text":"Besides a small set of pilot data to develop the CGCoT prompts, our measures require no additional labeled data and produce binary predictions comparable to a RoBERTa-Large model fine-tuned on thousands of human-labeled tweets.","meta":{"url":"http://arxiv.org/abs/2310.12049v1"},"cats":{"benchmark":0.2887848121,"new-dataset":0.2327908993,"data-annotation":0.5277178679,"dev-research":0.154085568,"llms":0.5174451107,"data-quality":0.1960490129}}
{"text":"We demonstrate how combining substantive knowledge with LLMs can create state-of-the-art measures of abstract concepts.","meta":{"url":"http://arxiv.org/abs/2310.12049v1"},"cats":{"benchmark":0.2830875278,"new-dataset":0.0345380139,"data-annotation":0.5333101189,"dev-research":0.2190639029,"llms":0.686497646,"data-quality":0.1447190171}}
{"text":"The growing demand for electric vehicles requires the development of automated car charging methods.","meta":{"url":"http://arxiv.org/abs/2310.12044v1"},"cats":{"benchmark":0.2590429258,"new-dataset":0.0086950468,"data-annotation":0.5176845074,"dev-research":0.2835001575,"llms":0.4473299658,"data-quality":0.1245617208}}
{"text":"At the moment, the process of charging an electric car is completely manual, and that requires physical effort to accomplish the task, which is not suitable for people with disabilities.","meta":{"url":"http://arxiv.org/abs/2310.12044v1"},"cats":{"benchmark":0.2361365579,"new-dataset":0.0033861793,"data-annotation":0.5147327731,"dev-research":0.3097495537,"llms":0.5407873619,"data-quality":0.1382683794}}
{"text":"Typically, the effort in the research is focused on detecting the position and orientation of the socket, which resulted in a relatively high accuracy, $\\pm 5 \\: mm $ and $\\pm 10^o$. However, this accuracy is not enough to complete the charging process.","meta":{"url":"http://arxiv.org/abs/2310.12044v1"},"cats":{"benchmark":0.5948627597,"new-dataset":0.0077873263,"data-annotation":0.5388368213,"dev-research":0.1728906107,"llms":0.4789108597,"data-quality":0.1126124842}}
{"text":"In this work, we focus on designing a novel methodology for robust robotic plug-in and plug-out based on human haptics, to overcome the error in the position and orientation of the socket.","meta":{"url":"http://arxiv.org/abs/2310.12044v1"},"cats":{"benchmark":0.3075502701,"new-dataset":0.0749690489,"data-annotation":0.5119482434,"dev-research":0.2916188041,"llms":0.495323094,"data-quality":0.0945560105}}
{"text":"Participants were invited to perform the charging task, and their cognitive capabilities were recognized by measuring the applied forces along with the movement of the charger.","meta":{"url":"http://arxiv.org/abs/2310.12044v1"},"cats":{"benchmark":0.2368993602,"new-dataset":0.00992591,"data-annotation":0.5330847079,"dev-research":0.2041148043,"llms":0.5124765997,"data-quality":0.0562786578}}
{"text":"Three controllers were designed based on impedance control to mimic the human patterns of charging an electric car.","meta":{"url":"http://arxiv.org/abs/2310.12044v1"},"cats":{"benchmark":0.2344543635,"new-dataset":0.0147292782,"data-annotation":0.5038742517,"dev-research":0.2065504556,"llms":0.480102365,"data-quality":0.0558056912}}
{"text":"The recorded data from humans were used to calibrate the parameters of the impedance controllers: inertia $M_d$, damping $D_d$, and stiffness $K_d$. A robotic validation was performed, where the designed controllers were applied to the robot UR10.","meta":{"url":"http://arxiv.org/abs/2310.12044v1"},"cats":{"benchmark":0.4243213348,"new-dataset":0.0503594352,"data-annotation":0.495311614,"dev-research":0.1861672834,"llms":0.4955243715,"data-quality":0.097271182}}
{"text":"Using the proposed controllers and the human kinesthetic data, it was possible to successfully automate the operation of charging an electric car.","meta":{"url":"http://arxiv.org/abs/2310.12044v1"},"cats":{"benchmark":0.2487717803,"new-dataset":0.0263307806,"data-annotation":0.5040513707,"dev-research":0.2430743479,"llms":0.4649960454,"data-quality":0.0929172259}}
{"text":"We introduce a novel universal soft-decision decoding algorithm for binary block codes called ordered reliability direct error pattern testing (ORDEPT).","meta":{"url":"http://arxiv.org/abs/2310.12039v1"},"cats":{"benchmark":0.5147464138,"new-dataset":0.0253871312,"data-annotation":0.5118763497,"dev-research":0.2400800026,"llms":0.4750453216,"data-quality":0.3423177417}}
{"text":"Our results, obtained for a variety of popular short high-rate codes, demonstrate that ORDEPT outperforms state-of-the-art decoding algorithms of comparable complexity such as ordered reliability bits guessing random additive noise decoding (ORBGRAND) in terms of the decoding error probability and latency.","meta":{"url":"http://arxiv.org/abs/2310.12039v1"},"cats":{"benchmark":0.4460492967,"new-dataset":0.0387914555,"data-annotation":0.538620821,"dev-research":0.1799325676,"llms":0.5119575005,"data-quality":0.1849088939}}
{"text":"The improvements carry on to the iterative decoding of product codes and convolutional product-like codes, where we present a new adaptive decoding algorithm and demonstrate the ability of ORDEPT to efficiently find multiple candidate codewords to produce soft output.","meta":{"url":"http://arxiv.org/abs/2310.12039v1"},"cats":{"benchmark":0.3860919072,"new-dataset":0.0377234096,"data-annotation":0.5374054298,"dev-research":0.2460849641,"llms":0.4418840611,"data-quality":0.2550788006}}
{"text":"The rise of quantum computers exposes vulnerabilities in current public key cryptographic protocols, necessitating the development of secure post-quantum (PQ) schemes.","meta":{"url":"http://arxiv.org/abs/2310.12037v1"},"cats":{"benchmark":0.2565777326,"new-dataset":0.021625852,"data-annotation":0.5081623109,"dev-research":0.1649845532,"llms":0.5974063103,"data-quality":0.0469248251}}
{"text":"Hence, we conduct a comprehensive study on various PQ approaches, covering the constructional design, structural vulnerabilities, and offer security assessments, implementation evaluations, and a particular focus on side-channel attacks.","meta":{"url":"http://arxiv.org/abs/2310.12037v1"},"cats":{"benchmark":0.3726000163,"new-dataset":0.0353921543,"data-annotation":0.5088230408,"dev-research":0.2995125652,"llms":0.5978835428,"data-quality":0.0893903325}}
{"text":"We analyze global standardization processes, evaluate their metrics in relation to real-world applications, and primarily focus on standardized PQ schemes, selected additional signature competition candidates, and PQ-secure cutting-edge schemes beyond standardization.","meta":{"url":"http://arxiv.org/abs/2310.12037v1"},"cats":{"benchmark":0.4731643405,"new-dataset":0.0214620586,"data-annotation":0.4554328463,"dev-research":0.1859030393,"llms":0.5698751118,"data-quality":0.1144004037}}
{"text":"Finally, we present visions and potential future directions for a seamless transition to the PQ era.","meta":{"url":"http://arxiv.org/abs/2310.12037v1"},"cats":{"benchmark":0.2128016252,"new-dataset":0.0530823985,"data-annotation":0.4666498316,"dev-research":0.1529461041,"llms":0.6224121295,"data-quality":0.0460651863}}
{"text":"The prevalent deployment of learning from human preferences through reinforcement learning (RLHF) relies on two important approximations: the first assumes that pairwise preferences can be substituted with pointwise rewards.","meta":{"url":"http://arxiv.org/abs/2310.12036v1"},"cats":{"benchmark":0.288366265,"new-dataset":0.0263242911,"data-annotation":0.5217844669,"dev-research":0.1252881273,"llms":0.3952441336,"data-quality":0.070856072}}
{"text":"The second assumes that a reward model trained on these pointwise rewards can generalize from collected data to out-of-distribution data sampled by the policy.","meta":{"url":"http://arxiv.org/abs/2310.12036v1"},"cats":{"benchmark":0.2674362471,"new-dataset":0.0763263726,"data-annotation":0.5020645847,"dev-research":0.0900744231,"llms":0.4187016766,"data-quality":0.1406727739}}
{"text":"Recently, Direct Preference Optimisation (DPO) has been proposed as an approach that bypasses the second approximation and learn directly a policy from collected data without the reward modelling stage.","meta":{"url":"http://arxiv.org/abs/2310.12036v1"},"cats":{"benchmark":0.4108986778,"new-dataset":0.0168228114,"data-annotation":0.4686929827,"dev-research":0.1874207065,"llms":0.4515500779,"data-quality":0.0708481934}}
{"text":"However, this method still heavily relies on the first approximation.   ","meta":{"url":"http://arxiv.org/abs/2310.12036v1"},"cats":{"benchmark":0.6813164876,"new-dataset":0.0016403596,"data-annotation":0.5384632033,"dev-research":0.181343185,"llms":0.3592981381,"data-quality":0.1258019944}}
{"text":"In this paper we try to gain a deeper theoretical understanding of these practical algorithms.","meta":{"url":"http://arxiv.org/abs/2310.12036v1"},"cats":{"benchmark":0.5839473685,"new-dataset":0.0080558868,"data-annotation":0.5465505983,"dev-research":0.1079891896,"llms":0.3907461695,"data-quality":0.1249079573}}
{"text":"In particular we derive a new general objective called $\\Psi$PO for learning from human preferences that is expressed in terms of pairwise preferences and therefore bypasses both approximations.","meta":{"url":"http://arxiv.org/abs/2310.12036v1"},"cats":{"benchmark":0.3988201825,"new-dataset":0.0070628987,"data-annotation":0.5278150997,"dev-research":0.1438536396,"llms":0.3972649622,"data-quality":0.106805761}}
{"text":"This new general objective allows us to perform an in-depth analysis of the behavior of RLHF and DPO (as special cases of $\\Psi$PO) and to identify their potential pitfalls.","meta":{"url":"http://arxiv.org/abs/2310.12036v1"},"cats":{"benchmark":0.4253205753,"new-dataset":0.0165726694,"data-annotation":0.5050140559,"dev-research":0.1214851503,"llms":0.487368666,"data-quality":0.1026539819}}
{"text":"We then consider another special case for $\\Psi$PO by setting $\\Psi$ simply to Identity, for which we can derive an efficient optimisation procedure, prove performance guarantees and demonstrate its empirical superiority to DPO on some illustrative examples.","meta":{"url":"http://arxiv.org/abs/2310.12036v1"},"cats":{"benchmark":0.5655394724,"new-dataset":0.0047107615,"data-annotation":0.4969106178,"dev-research":0.1874185269,"llms":0.5108033091,"data-quality":0.1091048179}}
{"text":"Flow, an optimal mental state merging action and awareness, significantly impacts performance, emotion and wellbeing in real-world contexts.","meta":{"url":"http://arxiv.org/abs/2310.12035v1"},"cats":{"benchmark":0.2862139258,"new-dataset":0.0248680576,"data-annotation":0.4923079849,"dev-research":0.261435212,"llms":0.5005752532,"data-quality":0.0533796292}}
{"text":"However, capturing its fluctuations on a sub-minute timescale is challenging due to the sparsity of the existing flow measuring tools.","meta":{"url":"http://arxiv.org/abs/2310.12035v1"},"cats":{"benchmark":0.5212323224,"new-dataset":0.101291251,"data-annotation":0.5066037725,"dev-research":0.1772459656,"llms":0.4849744182,"data-quality":0.0988394871}}
{"text":"Here we present a virtual reality fine fingertip force control (F3C) task to induce flow, wherein the task challenge is set at a compatible level with personal skill, and to track the flow fluctuations from the synchronous force control performance.","meta":{"url":"http://arxiv.org/abs/2310.12035v1"},"cats":{"benchmark":0.2765800628,"new-dataset":0.2043119191,"data-annotation":0.5123931364,"dev-research":0.2610673183,"llms":0.5165186335,"data-quality":0.0714965846}}
{"text":"We extract eight performance metrics from the fingertip force sequence and reveal their significant differences under distinct flow states.","meta":{"url":"http://arxiv.org/abs/2310.12035v1"},"cats":{"benchmark":0.5311932958,"new-dataset":0.0818193905,"data-annotation":0.5250947473,"dev-research":0.1565741757,"llms":0.513639095,"data-quality":0.0677715594}}
{"text":"Further, we built a flow decoder and demonstrated that the flow variations can be decoded using selected metrics.","meta":{"url":"http://arxiv.org/abs/2310.12035v1"},"cats":{"benchmark":0.3742287966,"new-dataset":0.1055375847,"data-annotation":0.5025382204,"dev-research":0.1811781152,"llms":0.4750340389,"data-quality":0.0995547411}}
{"text":"The predicted values reach significant correlation with the self-reported flow intensity (r=0.81).","meta":{"url":"http://arxiv.org/abs/2310.12035v1"},"cats":{"benchmark":0.3812448286,"new-dataset":0.0814786915,"data-annotation":0.5143349845,"dev-research":0.1459369632,"llms":0.3768475519,"data-quality":0.1095624823}}
{"text":"This study showcases the feasibility of tracking intrinsic flow variations with high temporal resolution using task performance measures.","meta":{"url":"http://arxiv.org/abs/2310.12035v1"},"cats":{"benchmark":0.4554337602,"new-dataset":0.0455186252,"data-annotation":0.4820031263,"dev-research":0.2008424202,"llms":0.4184009158,"data-quality":0.0583802264}}
{"text":"In drug discovery, it is vital to confirm the predictions of pharmaceutical properties from computational models using costly wet-lab experiments.","meta":{"url":"http://arxiv.org/abs/2310.12033v1"},"cats":{"benchmark":0.4236278209,"new-dataset":0.0523319512,"data-annotation":0.5110567181,"dev-research":0.1435202428,"llms":0.4367269936,"data-quality":0.0937545275}}
{"text":"Hence, obtaining reliable uncertainty estimates is crucial for prioritizing drug molecules for subsequent experimental validation.","meta":{"url":"http://arxiv.org/abs/2310.12033v1"},"cats":{"benchmark":0.5999511642,"new-dataset":0.0061287878,"data-annotation":0.48446443,"dev-research":0.2160965143,"llms":0.4201866523,"data-quality":0.1835849058}}
{"text":"Conformal Prediction (CP) is a promising tool for creating such prediction sets for molecular properties with a coverage guarantee.","meta":{"url":"http://arxiv.org/abs/2310.12033v1"},"cats":{"benchmark":0.3994449685,"new-dataset":0.0683903089,"data-annotation":0.5157475215,"dev-research":0.1328707884,"llms":0.4180482172,"data-quality":0.085313295}}
{"text":"However, the exchangeability assumption of CP is often challenged with covariate shift in drug discovery tasks: Most datasets contain limited labeled data, which may not be representative of the vast chemical space from which molecules are drawn.","meta":{"url":"http://arxiv.org/abs/2310.12033v1"},"cats":{"benchmark":0.3509500882,"new-dataset":0.0746684112,"data-annotation":0.47984819,"dev-research":0.1348088964,"llms":0.4158761261,"data-quality":0.2089257141}}
{"text":"To address this limitation, we propose a method called CoDrug that employs an energy-based model leveraging both training data and unlabelled data, and Kernel Density Estimation (KDE) to assess the densities of a molecule set.","meta":{"url":"http://arxiv.org/abs/2310.12033v1"},"cats":{"benchmark":0.454352802,"new-dataset":0.0944815975,"data-annotation":0.5051506447,"dev-research":0.1098758908,"llms":0.3945949374,"data-quality":0.2195850297}}
{"text":"The estimated densities are then used to weigh the molecule samples while building prediction sets and rectifying for distribution shift.","meta":{"url":"http://arxiv.org/abs/2310.12033v1"},"cats":{"benchmark":0.4717712399,"new-dataset":0.0219850054,"data-annotation":0.5131316754,"dev-research":0.1592551117,"llms":0.4047844866,"data-quality":0.0885327506}}
{"text":"In extensive experiments involving realistic distribution drifts in various small-molecule drug discovery tasks, we demonstrate the ability of CoDrug to provide valid prediction sets and its utility in addressing the distribution shift arising from de novo drug design models.","meta":{"url":"http://arxiv.org/abs/2310.12033v1"},"cats":{"benchmark":0.4009052995,"new-dataset":0.0803129668,"data-annotation":0.4968310671,"dev-research":0.143154674,"llms":0.4425870157,"data-quality":0.127778815}}
{"text":"On average, using CoDrug can reduce the coverage gap by over 35% when compared to conformal prediction sets not adjusted for covariate shift.","meta":{"url":"http://arxiv.org/abs/2310.12033v1"},"cats":{"benchmark":0.5367068288,"new-dataset":0.0154802991,"data-annotation":0.4955103553,"dev-research":0.1698180816,"llms":0.3718317021,"data-quality":0.0806057662}}
{"text":"The Linear Model of Co-regionalization (LMC) is a very general model of multitask gaussian process for regression or classification.","meta":{"url":"http://arxiv.org/abs/2310.12032v1"},"cats":{"benchmark":0.3656218614,"new-dataset":0.0204078485,"data-annotation":0.5070836707,"dev-research":0.1366874244,"llms":0.3405163231,"data-quality":0.1058993299}}
{"text":"While its expressivity and conceptual simplicity are appealing, naive implementations have cubic complexity in the number of datapoints and number of tasks, making approximations mandatory for most applications.","meta":{"url":"http://arxiv.org/abs/2310.12032v1"},"cats":{"benchmark":0.4419549726,"new-dataset":0.0162048736,"data-annotation":0.5215909088,"dev-research":0.300802373,"llms":0.4525748859,"data-quality":0.0989723283}}
{"text":"However, recent work has shown that under some conditions the latent processes of the model can be decoupled, leading to a complexity that is only linear in the number of said processes.","meta":{"url":"http://arxiv.org/abs/2310.12032v1"},"cats":{"benchmark":0.3787841166,"new-dataset":0.0169847649,"data-annotation":0.5302614799,"dev-research":0.1211120425,"llms":0.3712281551,"data-quality":0.0979920742}}
{"text":"We here extend these results, showing from the most general assumptions that the only condition necessary to an efficient exact computation of the LMC is a mild hypothesis on the noise model.","meta":{"url":"http://arxiv.org/abs/2310.12032v1"},"cats":{"benchmark":0.4864818053,"new-dataset":0.0310094429,"data-annotation":0.5433728477,"dev-research":0.1101840391,"llms":0.4070138727,"data-quality":0.2062639237}}
{"text":"We introduce a full parametrization of the resulting \\emph{projected LMC} model, and an expression of the marginal likelihood enabling efficient optimization.","meta":{"url":"http://arxiv.org/abs/2310.12032v1"},"cats":{"benchmark":0.4778641776,"new-dataset":0.0181256417,"data-annotation":0.5299986788,"dev-research":0.1040346378,"llms":0.3662345942,"data-quality":0.0610207024}}
{"text":"We perform a parametric study on synthetic data to show the excellent performance of our approach, compared to an unrestricted exact LMC and approximations of the latter.","meta":{"url":"http://arxiv.org/abs/2310.12032v1"},"cats":{"benchmark":0.6416361395,"new-dataset":0.1087093752,"data-annotation":0.5134859467,"dev-research":0.1180461601,"llms":0.3174643231,"data-quality":0.0814816386}}
{"text":"Overall, the projected LMC appears as a credible and simpler alternative to state-of-the art models, which greatly facilitates some computations such as leave-one-out cross-validation and fantasization.","meta":{"url":"http://arxiv.org/abs/2310.12032v1"},"cats":{"benchmark":0.457956987,"new-dataset":0.0136676275,"data-annotation":0.5249253189,"dev-research":0.1601919963,"llms":0.4697549966,"data-quality":0.0684707438}}
{"text":"This paper presents an adaptive transformer model named SegmATRon for embodied image semantic segmentation.","meta":{"url":"http://arxiv.org/abs/2310.12031v1"},"cats":{"benchmark":0.2217779495,"new-dataset":0.0945722479,"data-annotation":0.5103977789,"dev-research":0.162704257,"llms":0.4757528042,"data-quality":0.1527788737}}
{"text":"Its distinctive feature is the adaptation of model weights during inference on several images using a hybrid multicomponent loss function.","meta":{"url":"http://arxiv.org/abs/2310.12031v1"},"cats":{"benchmark":0.3941658386,"new-dataset":0.0217395449,"data-annotation":0.5211806603,"dev-research":0.099985624,"llms":0.3799870073,"data-quality":0.1265404593}}
{"text":"We studied this model on datasets collected in the photorealistic Habitat and the synthetic AI2-THOR Simulators.","meta":{"url":"http://arxiv.org/abs/2310.12031v1"},"cats":{"benchmark":0.2021851956,"new-dataset":0.5648216301,"data-annotation":0.5089341096,"dev-research":0.1289878148,"llms":0.4596194308,"data-quality":0.0570566047}}
{"text":"We showed that obtaining additional images using the agent's actions in an indoor environment can improve the quality of semantic segmentation.","meta":{"url":"http://arxiv.org/abs/2310.12031v1"},"cats":{"benchmark":0.2482647652,"new-dataset":0.2154087947,"data-annotation":0.5276807035,"dev-research":0.2370456139,"llms":0.475172884,"data-quality":0.1768313841}}
{"text":"The code of the proposed approach and datasets are publicly available at https://github.com/wingrune/SegmATRon.","meta":{"url":"http://arxiv.org/abs/2310.12031v1"},"cats":{"benchmark":0.3932187103,"new-dataset":0.8043214892,"data-annotation":0.5000396773,"dev-research":0.1128441974,"llms":0.4988602681,"data-quality":0.1161908843}}
{"text":"We introduce CORE, a dataset for few-shot relation classification (RC) focused on company relations and business entities.","meta":{"url":"http://arxiv.org/abs/2310.12024v1"},"cats":{"benchmark":0.259553358,"new-dataset":0.5084379402,"data-annotation":0.505622029,"dev-research":0.1897014521,"llms":0.5216611275,"data-quality":0.1949945948}}
{"text":"CORE includes 4,708 instances of 12 relation types with corresponding textual evidence extracted from company Wikipedia pages.","meta":{"url":"http://arxiv.org/abs/2310.12024v1"},"cats":{"benchmark":0.2664927247,"new-dataset":0.3224801878,"data-annotation":0.5247746352,"dev-research":0.1965700548,"llms":0.5511079516,"data-quality":0.1221241273}}
{"text":"Company names and business entities pose a challenge for few-shot RC models due to the rich and diverse information associated with them.","meta":{"url":"http://arxiv.org/abs/2310.12024v1"},"cats":{"benchmark":0.2652471948,"new-dataset":0.2239497684,"data-annotation":0.4891770773,"dev-research":0.1498398997,"llms":0.4916354606,"data-quality":0.1764574557}}
{"text":"For example, a company name may represent the legal entity, products, people, or business divisions depending on the context.","meta":{"url":"http://arxiv.org/abs/2310.12024v1"},"cats":{"benchmark":0.2453121745,"new-dataset":0.215524317,"data-annotation":0.4844984238,"dev-research":0.2457438012,"llms":0.5352847256,"data-quality":0.2172722252}}
{"text":"Therefore, deriving the relation type between entities is highly dependent on textual context.","meta":{"url":"http://arxiv.org/abs/2310.12024v1"},"cats":{"benchmark":0.2444933745,"new-dataset":0.0158018735,"data-annotation":0.5438857501,"dev-research":0.2160115203,"llms":0.5220272852,"data-quality":0.1646653467}}
{"text":"To evaluate the performance of state-of-the-art RC models on the CORE dataset, we conduct experiments in the few-shot domain adaptation setting.","meta":{"url":"http://arxiv.org/abs/2310.12024v1"},"cats":{"benchmark":0.4239126586,"new-dataset":0.1090936974,"data-annotation":0.4986009171,"dev-research":0.1372093588,"llms":0.4892896129,"data-quality":0.1302051108}}
{"text":"Our results reveal substantial performance gaps, confirming that models trained on different domains struggle to adapt to CORE.","meta":{"url":"http://arxiv.org/abs/2310.12024v1"},"cats":{"benchmark":0.509778252,"new-dataset":0.0080749509,"data-annotation":0.5094622859,"dev-research":0.1735207779,"llms":0.5121858283,"data-quality":0.1496849518}}
{"text":"Interestingly, we find that models trained on CORE showcase improved out-of-domain performance, which highlights the importance of high-quality data for robust domain adaptation.","meta":{"url":"http://arxiv.org/abs/2310.12024v1"},"cats":{"benchmark":0.4272317669,"new-dataset":0.114117364,"data-annotation":0.5092441794,"dev-research":0.2178762817,"llms":0.5220631939,"data-quality":0.2943853237}}
{"text":"Specifically, the information richness embedded in business entities allows models to focus on contextual nuances, reducing their reliance on superficial clues such as relation-specific verbs.","meta":{"url":"http://arxiv.org/abs/2310.12024v1"},"cats":{"benchmark":0.2364105958,"new-dataset":0.0073461784,"data-annotation":0.5209392829,"dev-research":0.2469353938,"llms":0.5545069147,"data-quality":0.1871517003}}
{"text":"In addition to the dataset, we provide relevant code snippets to facilitate reproducibility and encourage further research in the field.","meta":{"url":"http://arxiv.org/abs/2310.12024v1"},"cats":{"benchmark":0.4375603713,"new-dataset":0.6947147833,"data-annotation":0.5249920864,"dev-research":0.3232347345,"llms":0.4526999749,"data-quality":0.2164116357}}
{"text":"The convergence of embodied agents and large language models (LLMs) has brought significant advancements to embodied instruction following.","meta":{"url":"http://arxiv.org/abs/2310.12020v1"},"cats":{"benchmark":0.1459948767,"new-dataset":0.0244009726,"data-annotation":0.5313927859,"dev-research":0.1625304068,"llms":0.707085872,"data-quality":0.0592778682}}
{"text":"Particularly, the strong reasoning capabilities of LLMs make it possible for robots to perform long-horizon tasks without expensive annotated demonstrations.","meta":{"url":"http://arxiv.org/abs/2310.12020v1"},"cats":{"benchmark":0.1856470289,"new-dataset":0.0372381475,"data-annotation":0.5135707954,"dev-research":0.1690984363,"llms":0.7427907188,"data-quality":0.0594939021}}
{"text":"However, public benchmarks for testing the long-horizon reasoning capabilities of language-conditioned robots in various scenarios are still missing.","meta":{"url":"http://arxiv.org/abs/2310.12020v1"},"cats":{"benchmark":0.3931145614,"new-dataset":0.070101144,"data-annotation":0.5319235674,"dev-research":0.2046691134,"llms":0.5289968922,"data-quality":0.1256254057}}
{"text":"To fill this gap, this work focuses on the tabletop manipulation task and releases a simulation benchmark, \\textit{LoHoRavens}, which covers various long-horizon reasoning aspects spanning color, size, space, arithmetics and reference.","meta":{"url":"http://arxiv.org/abs/2310.12020v1"},"cats":{"benchmark":0.3205662923,"new-dataset":0.1999871054,"data-annotation":0.5310610276,"dev-research":0.2484659536,"llms":0.5651962685,"data-quality":0.0530999732}}
{"text":"Furthermore, there is a key modality bridging problem for long-horizon manipulation tasks with LLMs: how to incorporate the observation feedback during robot execution for the LLM's closed-loop planning, which is however less studied by prior work.","meta":{"url":"http://arxiv.org/abs/2310.12020v1"},"cats":{"benchmark":0.2706142791,"new-dataset":0.033105844,"data-annotation":0.4876559473,"dev-research":0.1690779782,"llms":0.6806367261,"data-quality":0.0473129643}}
{"text":"We investigate two methods of bridging the modality gap: caption generation and learnable interface for incorporating explicit and implicit observation feedback to the LLM, respectively.","meta":{"url":"http://arxiv.org/abs/2310.12020v1"},"cats":{"benchmark":0.2522186628,"new-dataset":0.1314742776,"data-annotation":0.5356502373,"dev-research":0.172119048,"llms":0.5943453392,"data-quality":0.2820491652}}
{"text":"These methods serve as the two baselines for our proposed benchmark.","meta":{"url":"http://arxiv.org/abs/2310.12020v1"},"cats":{"benchmark":0.8834518115,"new-dataset":0.0215073272,"data-annotation":0.5272240197,"dev-research":0.1646156363,"llms":0.379499058,"data-quality":0.1220723286}}
{"text":"Experiments show that both methods struggle to solve some tasks, indicating long-horizon manipulation tasks are still challenging for current popular models.","meta":{"url":"http://arxiv.org/abs/2310.12020v1"},"cats":{"benchmark":0.385720701,"new-dataset":0.0052880836,"data-annotation":0.5190515088,"dev-research":0.2476258756,"llms":0.4713796705,"data-quality":0.0568968993}}
{"text":"We expect the proposed public benchmark and baselines can help the community develop better models for long-horizon tabletop manipulation tasks.","meta":{"url":"http://arxiv.org/abs/2310.12020v1"},"cats":{"benchmark":0.4862806855,"new-dataset":0.0671704745,"data-annotation":0.5152303274,"dev-research":0.276163638,"llms":0.473080384,"data-quality":0.04860569}}
{"text":"Online design communities, where members exchange free-form views on others' designs, offer a space for beginners to learn visual design.","meta":{"url":"http://arxiv.org/abs/2310.12019v1"},"cats":{"benchmark":0.1540862906,"new-dataset":0.1558680919,"data-annotation":0.5261079367,"dev-research":0.3957380731,"llms":0.5660592631,"data-quality":0.0487553871}}
{"text":"However, the content of these communities is often unorganized for learners, containing many redundancies and irrelevant comments.","meta":{"url":"http://arxiv.org/abs/2310.12019v1"},"cats":{"benchmark":0.2146098753,"new-dataset":0.0626367367,"data-annotation":0.5230100139,"dev-research":0.2797298301,"llms":0.5273364863,"data-quality":0.3135426947}}
{"text":"In this paper, we propose a computational approach for leveraging online design communities to run a conversational agent that assists informal learning of visual elements (e.g., color and space).","meta":{"url":"http://arxiv.org/abs/2310.12019v1"},"cats":{"benchmark":0.1848767485,"new-dataset":0.2036971247,"data-annotation":0.5261669843,"dev-research":0.4601540132,"llms":0.5809530937,"data-quality":0.0957632462}}
{"text":"Our method extracts critiques, suggestions, and rationales on visual elements from comments.","meta":{"url":"http://arxiv.org/abs/2310.12019v1"},"cats":{"benchmark":0.3353750831,"new-dataset":0.0586982999,"data-annotation":0.5545855953,"dev-research":0.4602720318,"llms":0.5354565412,"data-quality":0.2807786503}}
{"text":"We present DesignQuizzer, which asks questions about visual design in UI examples and provides structured comment summaries.","meta":{"url":"http://arxiv.org/abs/2310.12019v1"},"cats":{"benchmark":0.2502127816,"new-dataset":0.2838959638,"data-annotation":0.512547293,"dev-research":0.497653561,"llms":0.5786119302,"data-quality":0.1013006379}}
{"text":"Two user studies demonstrate the engagement and usefulness of DesignQuizzer compared with the baseline (reading reddit.com/r/UI_design).","meta":{"url":"http://arxiv.org/abs/2310.12019v1"},"cats":{"benchmark":0.3551742818,"new-dataset":0.0367565556,"data-annotation":0.4962067197,"dev-research":0.4317528075,"llms":0.6231469656,"data-quality":0.0749212292}}
{"text":"We also showcase how effectively novices can apply what they learn with DesignQuizzer in a design critique task and a visual design task.","meta":{"url":"http://arxiv.org/abs/2310.12019v1"},"cats":{"benchmark":0.2688992982,"new-dataset":0.109076636,"data-annotation":0.5251187216,"dev-research":0.5053402538,"llms":0.6196664854,"data-quality":0.1509202213}}
{"text":"We discuss how to use our approach with other communities and offer design considerations for community-powered learning support tools.","meta":{"url":"http://arxiv.org/abs/2310.12019v1"},"cats":{"benchmark":0.2354938539,"new-dataset":0.0688471991,"data-annotation":0.4991266787,"dev-research":0.3790588602,"llms":0.6081597753,"data-quality":0.1360801812}}
{"text":"Face forgery generation technologies generate vivid faces, which have raised public concerns about security and privacy.","meta":{"url":"http://arxiv.org/abs/2310.12017v1"},"cats":{"benchmark":0.1891358695,"new-dataset":0.0520541682,"data-annotation":0.5100384111,"dev-research":0.3140702953,"llms":0.5968850328,"data-quality":0.1131581284}}
{"text":"Many intelligent systems, such as electronic payment and identity verification, rely on face forgery detection.","meta":{"url":"http://arxiv.org/abs/2310.12017v1"},"cats":{"benchmark":0.2925942088,"new-dataset":0.0101219575,"data-annotation":0.5243828694,"dev-research":0.2125852556,"llms":0.483153678,"data-quality":0.1765163874}}
{"text":"Although face forgery detection has successfully distinguished fake faces, recent studies have demonstrated that face forgery detectors are very vulnerable to adversarial examples.","meta":{"url":"http://arxiv.org/abs/2310.12017v1"},"cats":{"benchmark":0.2937047739,"new-dataset":0.0441289827,"data-annotation":0.5442953772,"dev-research":0.2170458868,"llms":0.4954059018,"data-quality":0.296668493}}
{"text":"Meanwhile, existing attacks rely on network architectures or training datasets instead of the predicted labels, which leads to a gap in attacking deployed applications.","meta":{"url":"http://arxiv.org/abs/2310.12017v1"},"cats":{"benchmark":0.3165708464,"new-dataset":0.0396997998,"data-annotation":0.511639449,"dev-research":0.2582717719,"llms":0.4933597371,"data-quality":0.3196098012}}
{"text":"To narrow this gap, we first explore the decision-based attacks on face forgery detection.","meta":{"url":"http://arxiv.org/abs/2310.12017v1"},"cats":{"benchmark":0.337589917,"new-dataset":0.0315071778,"data-annotation":0.5441827184,"dev-research":0.2468388685,"llms":0.47355041,"data-quality":0.193458414}}
{"text":"However, applying existing decision-based attacks directly suffers from perturbation initialization failure and low image quality.","meta":{"url":"http://arxiv.org/abs/2310.12017v1"},"cats":{"benchmark":0.4549981089,"new-dataset":0.0039461346,"data-annotation":0.5234882601,"dev-research":0.2215566182,"llms":0.4976573167,"data-quality":0.2777551283}}
{"text":"First, we propose cross-task perturbation to handle initialization failures by utilizing the high correlation of face features on different tasks.","meta":{"url":"http://arxiv.org/abs/2310.12017v1"},"cats":{"benchmark":0.4143853798,"new-dataset":0.0171852809,"data-annotation":0.5318900447,"dev-research":0.2698781444,"llms":0.4652744157,"data-quality":0.154775121}}
{"text":"Then, inspired by using frequency cues by face forgery detection, we propose the frequency decision-based attack.","meta":{"url":"http://arxiv.org/abs/2310.12017v1"},"cats":{"benchmark":0.3631550114,"new-dataset":0.0204994694,"data-annotation":0.5233019107,"dev-research":0.2231553433,"llms":0.4702143553,"data-quality":0.18503565}}
{"text":"We add perturbations in the frequency domain and then constrain the visual quality in the spatial domain.","meta":{"url":"http://arxiv.org/abs/2310.12017v1"},"cats":{"benchmark":0.4404240226,"new-dataset":0.0289146195,"data-annotation":0.5159840739,"dev-research":0.1885895879,"llms":0.4520067805,"data-quality":0.1954708452}}
{"text":"Finally, extensive experiments demonstrate that our method achieves state-of-the-art attack performance on FaceForensics++, CelebDF, and industrial APIs, with high query efficiency and guaranteed image quality.","meta":{"url":"http://arxiv.org/abs/2310.12017v1"},"cats":{"benchmark":0.4675381264,"new-dataset":0.0993865808,"data-annotation":0.517084862,"dev-research":0.2113909418,"llms":0.5225134935,"data-quality":0.1528169473}}
{"text":"Further, the fake faces by our method can pass face forgery detection and face recognition, which exposes the security problems of face forgery detectors.","meta":{"url":"http://arxiv.org/abs/2310.12017v1"},"cats":{"benchmark":0.2881909582,"new-dataset":0.0490410669,"data-annotation":0.5415649244,"dev-research":0.2083861459,"llms":0.4885172153,"data-quality":0.1949149908}}
{"text":"Commonsense Knowledge Graphs (CSKGs) are crucial for commonsense reasoning, yet constructing them through human annotations can be costly.","meta":{"url":"http://arxiv.org/abs/2310.12011v1"},"cats":{"benchmark":0.1760594845,"new-dataset":0.6367570562,"data-annotation":0.5345884635,"dev-research":0.2830397704,"llms":0.5956249052,"data-quality":0.222073917}}
{"text":"As a result, various automatic methods have been proposed to construct CSKG with larger semantic coverage.","meta":{"url":"http://arxiv.org/abs/2310.12011v1"},"cats":{"benchmark":0.3265875368,"new-dataset":0.286001853,"data-annotation":0.5136072028,"dev-research":0.3824346447,"llms":0.5601610878,"data-quality":0.2744720578}}
{"text":"However, these unsupervised approaches introduce spurious noise that can lower the quality of the resulting CSKG, which cannot be tackled easily by existing denoising algorithms due to the unique characteristics of nodes and structures in CSKGs.","meta":{"url":"http://arxiv.org/abs/2310.12011v1"},"cats":{"benchmark":0.5188552892,"new-dataset":0.0807457047,"data-annotation":0.5198805482,"dev-research":0.2169124261,"llms":0.4471607095,"data-quality":0.3084631081}}
{"text":"To address this issue, we propose Gold (Global and Local-aware Denoising), a denoising framework for CSKGs that incorporates entity semantic information, global rules, and local structural information from the CSKG.","meta":{"url":"http://arxiv.org/abs/2310.12011v1"},"cats":{"benchmark":0.3509983997,"new-dataset":0.3371697931,"data-annotation":0.4861319696,"dev-research":0.3181920582,"llms":0.4994930607,"data-quality":0.3688478828}}
{"text":"Experiment results demonstrate that Gold outperforms all baseline methods in noise detection tasks on synthetic noisy CSKG benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.12011v1"},"cats":{"benchmark":0.613051528,"new-dataset":0.1361880374,"data-annotation":0.5254714824,"dev-research":0.2377112733,"llms":0.4611597245,"data-quality":0.4419380208}}
{"text":"Furthermore, we show that denoising a real-world CSKG is effective and even benefits the downstream zero-shot commonsense question-answering task.","meta":{"url":"http://arxiv.org/abs/2310.12011v1"},"cats":{"benchmark":0.2709252857,"new-dataset":0.2979858541,"data-annotation":0.5314429121,"dev-research":0.1588141626,"llms":0.5397996788,"data-quality":0.2493184627}}
{"text":"Knowledge graph entity typing (KGET) aims at inferring plausible types of entities in knowledge graphs.","meta":{"url":"http://arxiv.org/abs/2310.12008v1"},"cats":{"benchmark":0.2028058214,"new-dataset":0.1096247478,"data-annotation":0.5301394289,"dev-research":0.213856744,"llms":0.5733776471,"data-quality":0.1871975259}}
{"text":"Existing approaches to KGET focus on how to better encode the knowledge provided by the neighbors and types of an entity into its representation.","meta":{"url":"http://arxiv.org/abs/2310.12008v1"},"cats":{"benchmark":0.2306182304,"new-dataset":0.1492836471,"data-annotation":0.5120387649,"dev-research":0.1906798298,"llms":0.5957047254,"data-quality":0.1835963903}}
{"text":"However, they ignore the semantic knowledge provided by the way in which types can be clustered together.","meta":{"url":"http://arxiv.org/abs/2310.12008v1"},"cats":{"benchmark":0.2166093051,"new-dataset":0.0067982897,"data-annotation":0.5134766349,"dev-research":0.2222838252,"llms":0.5622100445,"data-quality":0.2644345932}}
{"text":"In this paper, we propose a novel method called Multi-view Contrastive Learning for knowledge graph Entity Typing (MCLET), which effectively encodes the coarse-grained knowledge provided by clusters into entity and type embeddings.","meta":{"url":"http://arxiv.org/abs/2310.12008v1"},"cats":{"benchmark":0.2725459317,"new-dataset":0.0655480143,"data-annotation":0.5347491587,"dev-research":0.2248342538,"llms":0.5159101378,"data-quality":0.1797969868}}
{"text":"MCLET is composed of three modules: i) Multi-view Generation and Encoder module, which encodes structured information from entity-type, entity-cluster and cluster-type views; ii) Cross-view Contrastive Learning module, which encourages different views to collaboratively improve view-specific representations of entities and types; iii) Entity Typing Prediction module, which integrates multi-head attention and a Mixture-of-Experts strategy to infer missing entity types.","meta":{"url":"http://arxiv.org/abs/2310.12008v1"},"cats":{"benchmark":0.2158203274,"new-dataset":0.0437460518,"data-annotation":0.5355837884,"dev-research":0.2068721625,"llms":0.5507664172,"data-quality":0.1442152529}}
{"text":"Extensive experiments show the strong performance of MCLET compared to the state-of-the-art","meta":{"url":"http://arxiv.org/abs/2310.12008v1"},"cats":{"benchmark":0.5912844698,"new-dataset":0.0074851817,"data-annotation":0.5168474892,"dev-research":0.1239832775,"llms":0.5565694533,"data-quality":0.1278933796}}
{"text":"Accurately forecasting the motion of traffic actors is crucial for the deployment of autonomous vehicles at a large scale.","meta":{"url":"http://arxiv.org/abs/2310.12007v1"},"cats":{"benchmark":0.2870168026,"new-dataset":0.0602520841,"data-annotation":0.5184299982,"dev-research":0.1697020182,"llms":0.3890183715,"data-quality":0.0661557657}}
{"text":"Current trajectory forecasting approaches primarily concentrate on optimizing a loss function with a specific metric, which can result in predictions that do not adhere to physical laws or violate external constraints.","meta":{"url":"http://arxiv.org/abs/2310.12007v1"},"cats":{"benchmark":0.384664076,"new-dataset":0.0064092349,"data-annotation":0.5227016855,"dev-research":0.1926485962,"llms":0.3905127587,"data-quality":0.0517412484}}
{"text":"Our objective is to incorporate explicit knowledge priors that allow a network to forecast future trajectories in compliance with both the kinematic constraints of a vehicle and the geometry of the driving environment.","meta":{"url":"http://arxiv.org/abs/2310.12007v1"},"cats":{"benchmark":0.2536057297,"new-dataset":0.0571486052,"data-annotation":0.4981032442,"dev-research":0.195449785,"llms":0.4080312851,"data-quality":0.0463441239}}
{"text":"To achieve this, we introduce a non-parametric pruning layer and attention layers to integrate the defined knowledge priors.","meta":{"url":"http://arxiv.org/abs/2310.12007v1"},"cats":{"benchmark":0.3243055281,"new-dataset":0.1119968851,"data-annotation":0.5093843773,"dev-research":0.1870615963,"llms":0.4906299503,"data-quality":0.0923533501}}
{"text":"Our proposed method is designed to ensure reachability guarantees for traffic actors in both complex and dynamic situations.","meta":{"url":"http://arxiv.org/abs/2310.12007v1"},"cats":{"benchmark":0.3615534884,"new-dataset":0.021034908,"data-annotation":0.4923764999,"dev-research":0.2560680315,"llms":0.5471980246,"data-quality":0.0746331585}}
{"text":"By conditioning the network to follow physical laws, we can obtain accurate and safe predictions, essential for maintaining autonomous vehicles' safety and efficiency in real-world settings.","meta":{"url":"http://arxiv.org/abs/2310.12007v1"},"cats":{"benchmark":0.2930358042,"new-dataset":0.0316743856,"data-annotation":0.5068171277,"dev-research":0.2499157471,"llms":0.3963985015,"data-quality":0.098914918}}
{"text":"In summary, this paper presents concepts that prevent off-road predictions for safe and reliable motion forecasting by incorporating knowledge priors into the training process.","meta":{"url":"http://arxiv.org/abs/2310.12007v1"},"cats":{"benchmark":0.2541335772,"new-dataset":0.1403293442,"data-annotation":0.5188522175,"dev-research":0.2276357717,"llms":0.3989749893,"data-quality":0.0865527808}}
{"text":"In this paper we present a framework of key algorithms and data-structures for efficiently generating timetables for any number of AGVs from any given positioning on any given graph to accomplish any given demands as long as a few easily satisfiable assumptions are met.","meta":{"url":"http://arxiv.org/abs/2310.12006v1"},"cats":{"benchmark":0.326914998,"new-dataset":0.3030413067,"data-annotation":0.5041112599,"dev-research":0.1618931479,"llms":0.4778983111,"data-quality":0.0709019357}}
{"text":"Our proposed algorithms provide guaranteed solutions in predictable polynomial running-times, which is fundamental to any real-time application.","meta":{"url":"http://arxiv.org/abs/2310.12006v1"},"cats":{"benchmark":0.4330736456,"new-dataset":0.0225973354,"data-annotation":0.5301894524,"dev-research":0.1607084585,"llms":0.4101485257,"data-quality":0.0763211444}}
{"text":"We also develop an improved geographic reservation algorithm that provides a substantial run-time improvement of the previously best-known algorithm from $O(nm)$ to $O(n)$.","meta":{"url":"http://arxiv.org/abs/2310.12006v1"},"cats":{"benchmark":0.6459217019,"new-dataset":0.0551069916,"data-annotation":0.5164647696,"dev-research":0.1524577675,"llms":0.4400623365,"data-quality":0.1219246527}}
{"text":"The recent use of diffusion prior, enhanced by pre-trained text-image models, has markedly elevated the performance of image super-resolution (SR).","meta":{"url":"http://arxiv.org/abs/2310.12004v1"},"cats":{"benchmark":0.4091299793,"new-dataset":0.0434565142,"data-annotation":0.501485815,"dev-research":0.1072426484,"llms":0.4586452919,"data-quality":0.1139874621}}
{"text":"To alleviate the huge computational cost required by pixel-based diffusion SR, latent-based methods utilize a feature encoder to transform the image and then implement the SR image generation in a compact latent space.","meta":{"url":"http://arxiv.org/abs/2310.12004v1"},"cats":{"benchmark":0.3214527843,"new-dataset":0.0199267204,"data-annotation":0.5005786236,"dev-research":0.136947894,"llms":0.490035821,"data-quality":0.0645172661}}
{"text":"Nevertheless, there are two major issues that limit the performance of latent-based diffusion.","meta":{"url":"http://arxiv.org/abs/2310.12004v1"},"cats":{"benchmark":0.483636155,"new-dataset":0.0012386162,"data-annotation":0.4987659167,"dev-research":0.1180061203,"llms":0.4453038492,"data-quality":0.0775890543}}
{"text":"First, the compression of latent space usually causes reconstruction distortion.","meta":{"url":"http://arxiv.org/abs/2310.12004v1"},"cats":{"benchmark":0.3096858716,"new-dataset":0.0066999971,"data-annotation":0.5137563456,"dev-research":0.1493397079,"llms":0.4495646266,"data-quality":0.2132476677}}
{"text":"Second, huge computational cost constrains the parameter scale of the diffusion model.","meta":{"url":"http://arxiv.org/abs/2310.12004v1"},"cats":{"benchmark":0.4375769638,"new-dataset":0.0193939331,"data-annotation":0.5085639188,"dev-research":0.1073891232,"llms":0.3776640253,"data-quality":0.0354598222}}
{"text":"To counteract these issues, we first propose a frequency compensation module that enhances the frequency components from latent space to pixel space.","meta":{"url":"http://arxiv.org/abs/2310.12004v1"},"cats":{"benchmark":0.459264507,"new-dataset":0.050991676,"data-annotation":0.4904951797,"dev-research":0.1952273195,"llms":0.492195943,"data-quality":0.2442850293}}
{"text":"The reconstruction distortion (especially for high-frequency information) can be significantly decreased.","meta":{"url":"http://arxiv.org/abs/2310.12004v1"},"cats":{"benchmark":0.4421499695,"new-dataset":0.0069074025,"data-annotation":0.4881317895,"dev-research":0.15706475,"llms":0.4308849994,"data-quality":0.185662272}}
{"text":"Then, we propose to use Sample-Space Mixture of Experts (SS-MoE) to achieve more powerful latent-based SR, which steadily improves the capacity of the model without a significant increase in inference costs.","meta":{"url":"http://arxiv.org/abs/2310.12004v1"},"cats":{"benchmark":0.410242665,"new-dataset":0.0336622516,"data-annotation":0.5176888014,"dev-research":0.1290166292,"llms":0.4628429625,"data-quality":0.0828557491}}
{"text":"These carefully crafted designs contribute to performance improvements in largely explored 4x blind super-resolution benchmarks and extend to large magnification factors, i.e., 8x image SR benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.12004v1"},"cats":{"benchmark":0.5296503547,"new-dataset":0.0319128757,"data-annotation":0.4987399882,"dev-research":0.1740444653,"llms":0.4799186513,"data-quality":0.0597525607}}
{"text":"The code is available at https://github.com/amandaluof/moe_sr.","meta":{"url":"http://arxiv.org/abs/2310.12004v1"},"cats":{"benchmark":0.3179268357,"new-dataset":0.1752310122,"data-annotation":0.5276001797,"dev-research":0.1390235382,"llms":0.5342504299,"data-quality":0.1055305125}}
{"text":"Bayesian Flow Networks (BFNs) has been recently proposed as one of the most promising direction to universal generative modelling, having ability to learn any of the data type.","meta":{"url":"http://arxiv.org/abs/2310.12001v1"},"cats":{"benchmark":0.2033561273,"new-dataset":0.1605117261,"data-annotation":0.4901854303,"dev-research":0.1534079086,"llms":0.5319538741,"data-quality":0.0707024922}}
{"text":"Their power comes from the expressiveness of neural networks and Bayesian inference which make them suitable in the context of continual learning.","meta":{"url":"http://arxiv.org/abs/2310.12001v1"},"cats":{"benchmark":0.2033440955,"new-dataset":0.0097043806,"data-annotation":0.528113626,"dev-research":0.1940668788,"llms":0.4748424543,"data-quality":0.0990728494}}
{"text":"We delve into the mechanics behind BFNs and conduct the experiments to empirically verify the generative capabilities on non-stationary data.","meta":{"url":"http://arxiv.org/abs/2310.12001v1"},"cats":{"benchmark":0.328573928,"new-dataset":0.0331237867,"data-annotation":0.5102464449,"dev-research":0.103667685,"llms":0.5107344113,"data-quality":0.0759421742}}
{"text":"Toward large scale electrophysiology data analysis, many preprocessing pipelines are developed to reject artifacts as the prerequisite step before the downstream analysis.","meta":{"url":"http://arxiv.org/abs/2310.11994v1"},"cats":{"benchmark":0.4092563719,"new-dataset":0.0993233322,"data-annotation":0.4601346626,"dev-research":0.2700840619,"llms":0.4673675031,"data-quality":0.2010291688}}
{"text":"A mainstay of these pipelines is based on the data driven approach -- Independent Component Analysis (ICA).","meta":{"url":"http://arxiv.org/abs/2310.11994v1"},"cats":{"benchmark":0.4077527755,"new-dataset":0.0763475789,"data-annotation":0.4510835324,"dev-research":0.1811353752,"llms":0.4320990594,"data-quality":0.1202864769}}
{"text":"Nevertheless, there is little effort put to the preprocessing quality control.","meta":{"url":"http://arxiv.org/abs/2310.11994v1"},"cats":{"benchmark":0.3730002521,"new-dataset":0.00743964,"data-annotation":0.5018979346,"dev-research":0.3151698209,"llms":0.5331219487,"data-quality":0.2080114548}}
{"text":"In this paper, attentions to this issue were carefully paid by our observation that after running ICA based preprocessing pipeline: some subjects showed approximately Parallel multichannel Log power Spectra (PaLOS), namely, multichannel power spectra are proportional to each other.","meta":{"url":"http://arxiv.org/abs/2310.11994v1"},"cats":{"benchmark":0.4346241295,"new-dataset":0.0535470658,"data-annotation":0.470193251,"dev-research":0.1548515458,"llms":0.4979067198,"data-quality":0.1066732997}}
{"text":"Firstly, the presence of PaLOS and its implications to connectivity analysis were described by real instance and simulation; secondly, we built its mathematical model and proposed the PaLOS index (PaLOSi) based on the common principal component analysis to detect its presence; thirdly, the performance of PaLOSi was tested on 30094 cases of EEG from 5 databases.","meta":{"url":"http://arxiv.org/abs/2310.11994v1"},"cats":{"benchmark":0.4373067641,"new-dataset":0.0431092418,"data-annotation":0.505665521,"dev-research":0.1464924812,"llms":0.4532838065,"data-quality":0.0857349091}}
{"text":"The results showed that 1) the PaLOS implies a sole source which is physiologically implausible.","meta":{"url":"http://arxiv.org/abs/2310.11994v1"},"cats":{"benchmark":0.2518764103,"new-dataset":0.035970541,"data-annotation":0.5238542474,"dev-research":0.1656386373,"llms":0.4896230706,"data-quality":0.1262584805}}
{"text":"2) PaLOSi can detect the excessive elimination of brain components and is robust in terms of channel number, electrode layout, reference, and the other factors.","meta":{"url":"http://arxiv.org/abs/2310.11994v1"},"cats":{"benchmark":0.37950037,"new-dataset":0.0234544509,"data-annotation":0.509573345,"dev-research":0.1633105447,"llms":0.4895392913,"data-quality":0.0943321908}}
{"text":"3) PaLOSi can output the channel and frequency wise index to help for in-depth check.","meta":{"url":"http://arxiv.org/abs/2310.11994v1"},"cats":{"benchmark":0.4029483917,"new-dataset":0.1160862499,"data-annotation":0.5155353961,"dev-research":0.1340970252,"llms":0.5254087934,"data-quality":0.0882417114}}
{"text":"This paper presented the PaLOS issue in the quality control step after running the preprocessing pipeline and the proposed PaLOSi may serve as a novel data quality metric in the large-scale automatic preprocessing.","meta":{"url":"http://arxiv.org/abs/2310.11994v1"},"cats":{"benchmark":0.4919367103,"new-dataset":0.2495783575,"data-annotation":0.4504992371,"dev-research":0.3558969113,"llms":0.5108120607,"data-quality":0.2360647961}}
{"text":"Out-of-distribution generalization in neural networks is often hampered by spurious correlations.","meta":{"url":"http://arxiv.org/abs/2310.11991v1"},"cats":{"benchmark":0.3001129868,"new-dataset":0.0042039834,"data-annotation":0.5477092551,"dev-research":0.1430284779,"llms":0.4095833854,"data-quality":0.2688029434}}
{"text":"A common strategy is to mitigate this by removing spurious concepts from the neural network representation of the data.","meta":{"url":"http://arxiv.org/abs/2310.11991v1"},"cats":{"benchmark":0.3170346633,"new-dataset":0.0081219477,"data-annotation":0.5046424703,"dev-research":0.305762669,"llms":0.4431078345,"data-quality":0.4240012511}}
{"text":"Existing concept-removal methods tend to be overzealous by inadvertently eliminating features associated with the main task of the model, thereby harming model performance.","meta":{"url":"http://arxiv.org/abs/2310.11991v1"},"cats":{"benchmark":0.3655555143,"new-dataset":0.0023462427,"data-annotation":0.5257900287,"dev-research":0.3251393379,"llms":0.472444281,"data-quality":0.2422072753}}
{"text":"We propose an iterative algorithm that separates spurious from main-task concepts by jointly identifying two low-dimensional orthogonal subspaces in the neural network representation.","meta":{"url":"http://arxiv.org/abs/2310.11991v1"},"cats":{"benchmark":0.4049188555,"new-dataset":0.0195196019,"data-annotation":0.5580779093,"dev-research":0.2058681725,"llms":0.3923140699,"data-quality":0.2254950732}}
{"text":"We evaluate the algorithm on benchmark datasets for computer vision (Waterbirds, CelebA) and natural language processing (MultiNLI), and show that it outperforms existing concept removal methods","meta":{"url":"http://arxiv.org/abs/2310.11991v1"},"cats":{"benchmark":0.4457477084,"new-dataset":0.3097444677,"data-annotation":0.5386609592,"dev-research":0.2271917148,"llms":0.466322587,"data-quality":0.4143728867}}
{"text":"The core of clustering is incorporating prior knowledge to construct supervision signals.","meta":{"url":"http://arxiv.org/abs/2310.11989v1"},"cats":{"benchmark":0.2741741275,"new-dataset":0.0210426686,"data-annotation":0.52086067,"dev-research":0.3460510183,"llms":0.4672500311,"data-quality":0.1818120248}}
{"text":"From classic k-means based on data compactness to recent contrastive clustering guided by self-supervision, the evolution of clustering methods intrinsically corresponds to the progression of supervision signals.","meta":{"url":"http://arxiv.org/abs/2310.11989v1"},"cats":{"benchmark":0.2630740584,"new-dataset":0.0439899331,"data-annotation":0.5144366767,"dev-research":0.1928441735,"llms":0.4576925147,"data-quality":0.1553187751}}
{"text":"At present, substantial efforts have been devoted to mining internal supervision signals from data.","meta":{"url":"http://arxiv.org/abs/2310.11989v1"},"cats":{"benchmark":0.3016299792,"new-dataset":0.1552343644,"data-annotation":0.5217673022,"dev-research":0.2918738803,"llms":0.5157996672,"data-quality":0.255585288}}
{"text":"Nevertheless, the abundant external knowledge such as semantic descriptions, which naturally conduces to clustering, is regrettably overlooked.","meta":{"url":"http://arxiv.org/abs/2310.11989v1"},"cats":{"benchmark":0.2302206661,"new-dataset":0.0627873401,"data-annotation":0.5379816443,"dev-research":0.2916311978,"llms":0.5238925516,"data-quality":0.2852979546}}
{"text":"In this work, we propose leveraging external knowledge as a new supervision signal to guide clustering, even though it seems irrelevant to the given data.","meta":{"url":"http://arxiv.org/abs/2310.11989v1"},"cats":{"benchmark":0.306456514,"new-dataset":0.1485622643,"data-annotation":0.5050061562,"dev-research":0.2158454261,"llms":0.485810964,"data-quality":0.1973069616}}
{"text":"To implement and validate our idea, we design an externally guided clustering method (Text-Aided Clustering, TAC), which leverages the textual semantics of WordNet to facilitate image clustering.","meta":{"url":"http://arxiv.org/abs/2310.11989v1"},"cats":{"benchmark":0.2585938643,"new-dataset":0.0835675521,"data-annotation":0.5342320729,"dev-research":0.2910068358,"llms":0.518108844,"data-quality":0.238070181}}
{"text":"Specifically, TAC first selects and retrieves WordNet nouns that best distinguish images to enhance the feature discriminability.","meta":{"url":"http://arxiv.org/abs/2310.11989v1"},"cats":{"benchmark":0.2887794623,"new-dataset":0.0635784217,"data-annotation":0.5387720704,"dev-research":0.1578623177,"llms":0.5143922778,"data-quality":0.2678872893}}
{"text":"Then, to improve image clustering performance, TAC collaborates text and image modalities by mutually distilling cross-modal neighborhood information.","meta":{"url":"http://arxiv.org/abs/2310.11989v1"},"cats":{"benchmark":0.3681686654,"new-dataset":0.0561587673,"data-annotation":0.5108671137,"dev-research":0.2117874684,"llms":0.5594166951,"data-quality":0.2121408703}}
{"text":"Experiments demonstrate that TAC achieves state-of-the-art performance on five widely used and three more challenging image clustering benchmarks, including the full ImageNet-1K dataset.","meta":{"url":"http://arxiv.org/abs/2310.11989v1"},"cats":{"benchmark":0.4783947782,"new-dataset":0.2342762732,"data-annotation":0.5122456931,"dev-research":0.1727675795,"llms":0.5352359833,"data-quality":0.1802890949}}
{"text":"Generative AI systems produce a range of risks.","meta":{"url":"http://arxiv.org/abs/2310.11986v1"},"cats":{"benchmark":0.1665328642,"new-dataset":0.0406842543,"data-annotation":0.5329835266,"dev-research":0.2660212353,"llms":0.5262926769,"data-quality":0.1408169513}}
{"text":"To ensure the safety of generative AI systems, these risks must be evaluated.","meta":{"url":"http://arxiv.org/abs/2310.11986v1"},"cats":{"benchmark":0.2097447213,"new-dataset":0.0164049713,"data-annotation":0.5348381714,"dev-research":0.2968354216,"llms":0.5422334858,"data-quality":0.1722075063}}
{"text":"In this paper, we make two main contributions toward establishing such evaluations.","meta":{"url":"http://arxiv.org/abs/2310.11986v1"},"cats":{"benchmark":0.6715257551,"new-dataset":0.0162500965,"data-annotation":0.5519830383,"dev-research":0.181860642,"llms":0.4603338211,"data-quality":0.1765021348}}
{"text":"First, we propose a three-layered framework that takes a structured, sociotechnical approach to evaluating these risks.","meta":{"url":"http://arxiv.org/abs/2310.11986v1"},"cats":{"benchmark":0.2764668527,"new-dataset":0.0459639642,"data-annotation":0.499850586,"dev-research":0.3992688516,"llms":0.4767169594,"data-quality":0.0854038563}}
{"text":"This framework encompasses capability evaluations, which are the main current approach to safety evaluation.","meta":{"url":"http://arxiv.org/abs/2310.11986v1"},"cats":{"benchmark":0.4484994636,"new-dataset":0.0450019045,"data-annotation":0.5152475721,"dev-research":0.3309828294,"llms":0.4976378577,"data-quality":0.0994625587}}
{"text":"It then reaches further by building on system safety principles, particularly the insight that context determines whether a given capability may cause harm.","meta":{"url":"http://arxiv.org/abs/2310.11986v1"},"cats":{"benchmark":0.253605429,"new-dataset":0.0100763923,"data-annotation":0.4957244441,"dev-research":0.4036912582,"llms":0.5825545375,"data-quality":0.0751706008}}
{"text":"To account for relevant context, our framework adds human interaction and systemic impacts as additional layers of evaluation.","meta":{"url":"http://arxiv.org/abs/2310.11986v1"},"cats":{"benchmark":0.3774865718,"new-dataset":0.0531949355,"data-annotation":0.5122844476,"dev-research":0.4065472547,"llms":0.490105568,"data-quality":0.0955928877}}
{"text":"Second, we survey the current state of safety evaluation of generative AI systems and create a repository of existing evaluations.","meta":{"url":"http://arxiv.org/abs/2310.11986v1"},"cats":{"benchmark":0.3303638909,"new-dataset":0.09775902,"data-annotation":0.5370319543,"dev-research":0.3152198483,"llms":0.5490930806,"data-quality":0.2433840856}}
{"text":"Three salient evaluation gaps emerge from this analysis.","meta":{"url":"http://arxiv.org/abs/2310.11986v1"},"cats":{"benchmark":0.5081894367,"new-dataset":0.0455831311,"data-annotation":0.5291370603,"dev-research":0.2982525741,"llms":0.4837352178,"data-quality":0.1710998612}}
{"text":"We propose ways forward to closing these gaps, outlining practical steps as well as roles and responsibilities for different actors.","meta":{"url":"http://arxiv.org/abs/2310.11986v1"},"cats":{"benchmark":0.1938203004,"new-dataset":0.0719671451,"data-annotation":0.4813438874,"dev-research":0.2929228267,"llms":0.5405479868,"data-quality":0.0859781405}}
{"text":"Sociotechnical safety evaluation is a tractable approach to the robust and comprehensive safety evaluation of generative AI systems.","meta":{"url":"http://arxiv.org/abs/2310.11986v1"},"cats":{"benchmark":0.2967194259,"new-dataset":0.0414063186,"data-annotation":0.5228996414,"dev-research":0.3823976109,"llms":0.5313463305,"data-quality":0.1317372588}}
{"text":"We consider the problem of active learning in the context of spatial sampling for level set estimation (LSE), where the goal is to localize all regions where a function of interest lies above/below a given threshold as quickly as possible.","meta":{"url":"http://arxiv.org/abs/2310.11985v1"},"cats":{"benchmark":0.3992119255,"new-dataset":0.1501312166,"data-annotation":0.5266128022,"dev-research":0.1587081386,"llms":0.3981290011,"data-quality":0.1475031008}}
{"text":"We present a finite-horizon search procedure to perform LSE in one dimension while optimally balancing both the final estimation error and the distance traveled for a fixed number of samples.","meta":{"url":"http://arxiv.org/abs/2310.11985v1"},"cats":{"benchmark":0.5845461799,"new-dataset":0.0314464253,"data-annotation":0.5304415843,"dev-research":0.0633028139,"llms":0.3410339762,"data-quality":0.0978279558}}
{"text":"A tuning parameter is used to trade off between the estimation accuracy and distance traveled.","meta":{"url":"http://arxiv.org/abs/2310.11985v1"},"cats":{"benchmark":0.5677330669,"new-dataset":0.0071178189,"data-annotation":0.5102943539,"dev-research":0.1753926061,"llms":0.3719089086,"data-quality":0.104719059}}
{"text":"We show that the resulting optimization problem can be solved in closed form and that the resulting policy generalizes existing approaches to this problem.","meta":{"url":"http://arxiv.org/abs/2310.11985v1"},"cats":{"benchmark":0.4715165043,"new-dataset":0.02206135,"data-annotation":0.5206599516,"dev-research":0.168488627,"llms":0.3397468875,"data-quality":0.1531651464}}
{"text":"We then show how this approach can be used to perform level set estimation in higher dimensions under the popular Gaussian process model.","meta":{"url":"http://arxiv.org/abs/2310.11985v1"},"cats":{"benchmark":0.485641302,"new-dataset":0.104737182,"data-annotation":0.524684437,"dev-research":0.1052573501,"llms":0.3324142177,"data-quality":0.0714115458}}
{"text":"Empirical results on synthetic data indicate that as the cost of travel increases, our method's ability to treat distance nonmyopically allows it to significantly improve on the state of the art.","meta":{"url":"http://arxiv.org/abs/2310.11985v1"},"cats":{"benchmark":0.527598105,"new-dataset":0.0279579542,"data-annotation":0.5132609221,"dev-research":0.2151560111,"llms":0.3971368556,"data-quality":0.0859616256}}
{"text":"On real air quality data, our approach achieves roughly one fifth the estimation error at less than half the cost of competing algorithms.","meta":{"url":"http://arxiv.org/abs/2310.11985v1"},"cats":{"benchmark":0.649804009,"new-dataset":0.0715015938,"data-annotation":0.5261400163,"dev-research":0.2283583121,"llms":0.3137296464,"data-quality":0.1809053562}}
{"text":"Since its introduction, the transformer model has demonstrated outstanding performance across various tasks.","meta":{"url":"http://arxiv.org/abs/2310.11984v1"},"cats":{"benchmark":0.4621516043,"new-dataset":0.0071798617,"data-annotation":0.5003931016,"dev-research":0.171932143,"llms":0.5272837415,"data-quality":0.0420729417}}
{"text":"However, there are still unresolved issues regarding length generalization, particularly in algorithmic tasks.","meta":{"url":"http://arxiv.org/abs/2310.11984v1"},"cats":{"benchmark":0.3869884048,"new-dataset":0.0130981261,"data-annotation":0.5447969477,"dev-research":0.2007289727,"llms":0.4608074246,"data-quality":0.1577318291}}
{"text":"In this paper, we investigate the inherent capabilities of transformer models in learning arithmetic algorithms, such as addition and multiplication.","meta":{"url":"http://arxiv.org/abs/2310.11984v1"},"cats":{"benchmark":0.328901585,"new-dataset":0.012962125,"data-annotation":0.5357425,"dev-research":0.1442511714,"llms":0.4534989297,"data-quality":0.0752771741}}
{"text":"Through experiments and attention analysis, we identify a number of crucial factors for achieving optimal length generalization.","meta":{"url":"http://arxiv.org/abs/2310.11984v1"},"cats":{"benchmark":0.4589439725,"new-dataset":0.0156195365,"data-annotation":0.5516207772,"dev-research":0.1329694342,"llms":0.4069399811,"data-quality":0.0947641197}}
{"text":"We show that transformer models are able to generalize to long lengths with the help of targeted attention biasing.","meta":{"url":"http://arxiv.org/abs/2310.11984v1"},"cats":{"benchmark":0.2807427469,"new-dataset":0.0228285183,"data-annotation":0.5338260646,"dev-research":0.1058293989,"llms":0.4302839437,"data-quality":0.0926533154}}
{"text":"We then introduce Attention Bias Calibration (ABC), a calibration stage that enables the model to automatically learn the proper attention biases, which we link to mechanisms in relative position encoding.","meta":{"url":"http://arxiv.org/abs/2310.11984v1"},"cats":{"benchmark":0.2752813075,"new-dataset":0.1218329045,"data-annotation":0.5403362666,"dev-research":0.1537858515,"llms":0.4536621686,"data-quality":0.1581434059}}
{"text":"We demonstrate that using ABC, the transformer model can achieve unprecedented perfect length generalization on certain arithmetic tasks.","meta":{"url":"http://arxiv.org/abs/2310.11984v1"},"cats":{"benchmark":0.3329860744,"new-dataset":0.0257779862,"data-annotation":0.5291528781,"dev-research":0.1260890618,"llms":0.4398994382,"data-quality":0.0734446588}}
{"text":"Diffusion models have garnered considerable interest in the field of text generation.","meta":{"url":"http://arxiv.org/abs/2310.11976v1"},"cats":{"benchmark":0.256437301,"new-dataset":0.0339058647,"data-annotation":0.5263351746,"dev-research":0.1354333827,"llms":0.5446225059,"data-quality":0.1196837216}}
{"text":"Several studies have explored text diffusion models with different structures and applied them to various tasks, including named entity recognition and summarization.","meta":{"url":"http://arxiv.org/abs/2310.11976v1"},"cats":{"benchmark":0.3925100595,"new-dataset":0.0172588942,"data-annotation":0.5207493156,"dev-research":0.1269954497,"llms":0.4947017295,"data-quality":0.1681332356}}
{"text":"However, there exists a notable disparity between the \"easy-first\" text generation process of current diffusion models and the \"keyword-first\" natural text generation process of humans, which has received limited attention.","meta":{"url":"http://arxiv.org/abs/2310.11976v1"},"cats":{"benchmark":0.218892486,"new-dataset":0.0460092898,"data-annotation":0.5223982652,"dev-research":0.2206787433,"llms":0.5444774121,"data-quality":0.1369744206}}
{"text":"To bridge this gap, we propose InfoDiffusion, a non-autoregressive text diffusion model.","meta":{"url":"http://arxiv.org/abs/2310.11976v1"},"cats":{"benchmark":0.3741740469,"new-dataset":0.0469944735,"data-annotation":0.509204759,"dev-research":0.1211125892,"llms":0.4125514437,"data-quality":0.1951534095}}
{"text":"Our approach introduces a \"keyinfo-first\" generation strategy and incorporates a noise schedule based on the amount of text information.","meta":{"url":"http://arxiv.org/abs/2310.11976v1"},"cats":{"benchmark":0.3385923755,"new-dataset":0.3110268673,"data-annotation":0.4969422803,"dev-research":0.2460143013,"llms":0.5524352223,"data-quality":0.173262197}}
{"text":"In addition, InfoDiffusion combines self-conditioning with a newly proposed partially noising model structure.","meta":{"url":"http://arxiv.org/abs/2310.11976v1"},"cats":{"benchmark":0.3238120244,"new-dataset":0.0106993573,"data-annotation":0.5013127592,"dev-research":0.1282543415,"llms":0.4375601615,"data-quality":0.1741855332}}
{"text":"Experimental results show that InfoDiffusion outperforms the baseline model in terms of generation quality and diversity, as well as exhibiting higher sampling efficiency.","meta":{"url":"http://arxiv.org/abs/2310.11976v1"},"cats":{"benchmark":0.3942824024,"new-dataset":0.0348614118,"data-annotation":0.4837681583,"dev-research":0.1900799771,"llms":0.5117908077,"data-quality":0.1705096982}}
{"text":"The success of AI assistants based on language models (LLMs) hinges crucially on Reinforcement Learning from Human Feedback (RLHF), which enables the generation of responses more aligned with human preferences.","meta":{"url":"http://arxiv.org/abs/2310.11971v1"},"cats":{"benchmark":0.1868030067,"new-dataset":0.0619764998,"data-annotation":0.5283917072,"dev-research":0.1625702186,"llms":0.6677328187,"data-quality":0.1841954325}}
{"text":"As universal AI assistants, there's a growing expectation for them to perform consistently across various domains.","meta":{"url":"http://arxiv.org/abs/2310.11971v1"},"cats":{"benchmark":0.2822166308,"new-dataset":0.0088289011,"data-annotation":0.511644488,"dev-research":0.2010994247,"llms":0.5256370305,"data-quality":0.1414738829}}
{"text":"However, previous work shows that Reinforcement Learning (RL) often exploits shortcuts to attain high rewards and overlooks challenging samples.","meta":{"url":"http://arxiv.org/abs/2310.11971v1"},"cats":{"benchmark":0.309626719,"new-dataset":0.0227700002,"data-annotation":0.5213360944,"dev-research":0.2046114104,"llms":0.4854335136,"data-quality":0.1144060794}}
{"text":"This focus on quick reward gains undermines both the stability in training and the model's ability to generalize to new, unseen data.","meta":{"url":"http://arxiv.org/abs/2310.11971v1"},"cats":{"benchmark":0.2672014111,"new-dataset":0.007450492,"data-annotation":0.5226175665,"dev-research":0.1619094595,"llms":0.3744849555,"data-quality":0.1616305219}}
{"text":"In this work, we propose a novel approach that can learn a consistent policy via RL across various data groups or domains.","meta":{"url":"http://arxiv.org/abs/2310.11971v1"},"cats":{"benchmark":0.2840452403,"new-dataset":0.1634683776,"data-annotation":0.4570161631,"dev-research":0.2124472125,"llms":0.5061630707,"data-quality":0.1868514209}}
{"text":"Given the challenges associated with acquiring group annotations, our method automatically classifies data into different groups, deliberately maximizing performance variance.","meta":{"url":"http://arxiv.org/abs/2310.11971v1"},"cats":{"benchmark":0.4533567496,"new-dataset":0.2096103777,"data-annotation":0.5518732524,"dev-research":0.2714478452,"llms":0.5043041628,"data-quality":0.5082056124}}
{"text":"Then, we optimize the policy to perform well on challenging groups.","meta":{"url":"http://arxiv.org/abs/2310.11971v1"},"cats":{"benchmark":0.4251865238,"new-dataset":0.0066401494,"data-annotation":0.498882485,"dev-research":0.2384452033,"llms":0.4980622947,"data-quality":0.0724312707}}
{"text":"Lastly, leveraging the established groups, our approach adaptively adjusts the exploration space, allocating more learning capacity to more challenging data and preventing the model from over-optimizing on simpler data.","meta":{"url":"http://arxiv.org/abs/2310.11971v1"},"cats":{"benchmark":0.3174745745,"new-dataset":0.0747398576,"data-annotation":0.4966108315,"dev-research":0.1822334846,"llms":0.4385887629,"data-quality":0.0906811293}}
{"text":"Experimental results indicate that our approach significantly enhances training stability and model generalization.","meta":{"url":"http://arxiv.org/abs/2310.11971v1"},"cats":{"benchmark":0.4470602424,"new-dataset":0.0073544351,"data-annotation":0.5387087547,"dev-research":0.1688721981,"llms":0.4143513862,"data-quality":0.1867862349}}
{"text":"Large-scale pre-trained models are increasingly adapted to downstream tasks through a new paradigm called prompt learning.","meta":{"url":"http://arxiv.org/abs/2310.11970v1"},"cats":{"benchmark":0.1577925192,"new-dataset":0.036554596,"data-annotation":0.5041462817,"dev-research":0.1784711893,"llms":0.4815032137,"data-quality":0.0713204929}}
{"text":"In contrast to fine-tuning, prompt learning does not update the pre-trained model's parameters.","meta":{"url":"http://arxiv.org/abs/2310.11970v1"},"cats":{"benchmark":0.2396763263,"new-dataset":0.0079083026,"data-annotation":0.5157750058,"dev-research":0.1618867443,"llms":0.5288591347,"data-quality":0.1603245388}}
{"text":"Instead, it only learns an input perturbation, namely prompt, to be added to the downstream task data for predictions.","meta":{"url":"http://arxiv.org/abs/2310.11970v1"},"cats":{"benchmark":0.1929817462,"new-dataset":0.0083852702,"data-annotation":0.5195032371,"dev-research":0.1556267057,"llms":0.4708815666,"data-quality":0.1510828173}}
{"text":"Given the fast development of prompt learning, a well-generalized prompt inevitably becomes a valuable asset as significant effort and proprietary data are used to create it.","meta":{"url":"http://arxiv.org/abs/2310.11970v1"},"cats":{"benchmark":0.1573002045,"new-dataset":0.0972063564,"data-annotation":0.5192162788,"dev-research":0.2055951012,"llms":0.5391285393,"data-quality":0.1001537444}}
{"text":"This naturally raises the question of whether a prompt may leak the proprietary information of its training data.","meta":{"url":"http://arxiv.org/abs/2310.11970v1"},"cats":{"benchmark":0.1364328322,"new-dataset":0.0324012723,"data-annotation":0.508223756,"dev-research":0.1825603341,"llms":0.5480411387,"data-quality":0.2685631692}}
{"text":"In this paper, we perform the first comprehensive privacy assessment of prompts learned by visual prompt learning through the lens of property inference and membership inference attacks.","meta":{"url":"http://arxiv.org/abs/2310.11970v1"},"cats":{"benchmark":0.1906166645,"new-dataset":0.0654653726,"data-annotation":0.5224050788,"dev-research":0.1784051505,"llms":0.5588371343,"data-quality":0.1697239997}}
{"text":"Our empirical evaluation shows that the prompts are vulnerable to both attacks.","meta":{"url":"http://arxiv.org/abs/2310.11970v1"},"cats":{"benchmark":0.313611214,"new-dataset":0.0236148851,"data-annotation":0.525999576,"dev-research":0.2698281928,"llms":0.5617353908,"data-quality":0.1873753348}}
{"text":"We also demonstrate that the adversary can mount a successful property inference attack with limited cost.","meta":{"url":"http://arxiv.org/abs/2310.11970v1"},"cats":{"benchmark":0.3753019159,"new-dataset":0.0228279267,"data-annotation":0.5336435055,"dev-research":0.1827304984,"llms":0.5042897669,"data-quality":0.128591063}}
{"text":"Moreover, we show that membership inference attacks against prompts can be successful with relaxed adversarial assumptions.","meta":{"url":"http://arxiv.org/abs/2310.11970v1"},"cats":{"benchmark":0.2698839292,"new-dataset":0.0210501837,"data-annotation":0.5578979451,"dev-research":0.1641032419,"llms":0.4860997298,"data-quality":0.2857607766}}
{"text":"We further make some initial investigations on the defenses and observe that our method can mitigate the membership inference attacks with a decent utility-defense trade-off but fails to defend against property inference attacks.","meta":{"url":"http://arxiv.org/abs/2310.11970v1"},"cats":{"benchmark":0.4211700224,"new-dataset":0.0208343052,"data-annotation":0.531348949,"dev-research":0.2204379161,"llms":0.5642642611,"data-quality":0.2024696196}}
{"text":"We hope our results can shed light on the privacy risks of the popular prompt learning paradigm.","meta":{"url":"http://arxiv.org/abs/2310.11970v1"},"cats":{"benchmark":0.1389411682,"new-dataset":0.0530307297,"data-annotation":0.5233884198,"dev-research":0.1777036107,"llms":0.5828809172,"data-quality":0.1282074102}}
{"text":"To facilitate the research in this direction, we will share our code and models with the community.","meta":{"url":"http://arxiv.org/abs/2310.11970v1"},"cats":{"benchmark":0.2579612526,"new-dataset":0.2148392805,"data-annotation":0.5219010701,"dev-research":0.3269799636,"llms":0.5381814218,"data-quality":0.1057972508}}
{"text":"aTrain is an open-source and offline tool for transcribing audio data in multiple languages with CPU and NVIDIA GPU support.","meta":{"url":"http://arxiv.org/abs/2310.11967v1"},"cats":{"benchmark":0.3495235535,"new-dataset":0.4968471799,"data-annotation":0.507597777,"dev-research":0.1440838142,"llms":0.5438078155,"data-quality":0.1674782051}}
{"text":"It is specifically designed for researchers using qualitative data generated from various forms of speech interactions with research participants.","meta":{"url":"http://arxiv.org/abs/2310.11967v1"},"cats":{"benchmark":0.2077743184,"new-dataset":0.1105031263,"data-annotation":0.513423864,"dev-research":0.2804253797,"llms":0.5380401072,"data-quality":0.0808776979}}
{"text":"aTrain requires no programming skills, runs on most computers, does not require an internet connection, and was verified not to upload data to any server.","meta":{"url":"http://arxiv.org/abs/2310.11967v1"},"cats":{"benchmark":0.1908230055,"new-dataset":0.0322431038,"data-annotation":0.487661692,"dev-research":0.2099567028,"llms":0.5832525886,"data-quality":0.0762133561}}
{"text":"aTrain combines OpenAI's Whisper model with speaker recognition to provide output that integrates with the popular qualitative data analysis software tools MAXQDA and ATLAS.ti.","meta":{"url":"http://arxiv.org/abs/2310.11967v1"},"cats":{"benchmark":0.2628360598,"new-dataset":0.6034550938,"data-annotation":0.521724736,"dev-research":0.1701491881,"llms":0.5074775119,"data-quality":0.1232119603}}
{"text":"It has an easy-to-use graphical interface and is provided as a Windows-App through the Microsoft Store allowing for simple installation by researchers.","meta":{"url":"http://arxiv.org/abs/2310.11967v1"},"cats":{"benchmark":0.3083459738,"new-dataset":0.1256997818,"data-annotation":0.4945422715,"dev-research":0.3575016419,"llms":0.5203980111,"data-quality":0.0519962142}}
{"text":"The source code is freely available on GitHub.","meta":{"url":"http://arxiv.org/abs/2310.11967v1"},"cats":{"benchmark":0.2799550708,"new-dataset":0.4240894075,"data-annotation":0.5386218142,"dev-research":0.2682132389,"llms":0.5282287059,"data-quality":0.1305765195}}
{"text":"Having developed aTrain with a focus on speed on local computers, we show that the transcription time on current mobile CPUs is around 2 to 3 times the duration of the audio file using the highest-accuracy transcription models.","meta":{"url":"http://arxiv.org/abs/2310.11967v1"},"cats":{"benchmark":0.4668373647,"new-dataset":0.1264450302,"data-annotation":0.5116897527,"dev-research":0.1848682997,"llms":0.5028848096,"data-quality":0.1253891729}}
{"text":"If an entry-level graphics card is available, the transcription speed increases to 20% of the audio duration.","meta":{"url":"http://arxiv.org/abs/2310.11967v1"},"cats":{"benchmark":0.4044604395,"new-dataset":0.0351506798,"data-annotation":0.5076559725,"dev-research":0.1869919508,"llms":0.5056965561,"data-quality":0.0841827405}}
{"text":"Satellite communications, essential for modern connectivity, extend access to maritime, aeronautical, and remote areas where terrestrial networks are unfeasible.","meta":{"url":"http://arxiv.org/abs/2310.11966v1"},"cats":{"benchmark":0.2179613676,"new-dataset":0.018476174,"data-annotation":0.4854579829,"dev-research":0.1802292428,"llms":0.5076772806,"data-quality":0.0633525404}}
{"text":"Current GEO systems distribute power and bandwidth uniformly across beams using multi-beam footprints with fractional frequency reuse.","meta":{"url":"http://arxiv.org/abs/2310.11966v1"},"cats":{"benchmark":0.3925359809,"new-dataset":0.0119262772,"data-annotation":0.490775268,"dev-research":0.1547538066,"llms":0.523363725,"data-quality":0.1017125249}}
{"text":"However, recent research reveals the limitations of this approach in heterogeneous traffic scenarios, leading to inefficiencies.","meta":{"url":"http://arxiv.org/abs/2310.11966v1"},"cats":{"benchmark":0.4990248758,"new-dataset":0.0055347376,"data-annotation":0.4984620653,"dev-research":0.1493870999,"llms":0.4167132369,"data-quality":0.0567710558}}
{"text":"To address this, this paper presents a machine learning (ML)-based approach to Radio Resource Management (RRM).   ","meta":{"url":"http://arxiv.org/abs/2310.11966v1"},"cats":{"benchmark":0.2937839417,"new-dataset":0.0579067443,"data-annotation":0.491219071,"dev-research":0.1619303547,"llms":0.4652365609,"data-quality":0.1687910676}}
{"text":"We treat the RRM task as a regression ML problem, integrating RRM objectives and constraints into the loss function that the ML algorithm aims at minimizing.","meta":{"url":"http://arxiv.org/abs/2310.11966v1"},"cats":{"benchmark":0.4426761388,"new-dataset":0.044748553,"data-annotation":0.5231102908,"dev-research":0.1511564151,"llms":0.3346100188,"data-quality":0.1502557236}}
{"text":"Moreover, we introduce a context-aware ML metric that evaluates the ML model's performance but also considers the impact of its resource allocation decisions on the overall performance of the communication system.","meta":{"url":"http://arxiv.org/abs/2310.11966v1"},"cats":{"benchmark":0.4573132262,"new-dataset":0.0297862033,"data-annotation":0.5046656199,"dev-research":0.1944083631,"llms":0.5419187894,"data-quality":0.1450443648}}
{"text":"We introduce a novel and efficient method for Event Coreference Resolution (ECR) applied to a lower-resourced language domain.","meta":{"url":"http://arxiv.org/abs/2310.11965v1"},"cats":{"benchmark":0.3844793321,"new-dataset":0.2777539981,"data-annotation":0.5454768932,"dev-research":0.2964578522,"llms":0.5827748932,"data-quality":0.2768198642}}
{"text":"By framing ECR as a graph reconstruction task, we are able to combine deep semantic embeddings with structural coreference chain knowledge to create a parameter-efficient family of Graph Autoencoder models (GAE).","meta":{"url":"http://arxiv.org/abs/2310.11965v1"},"cats":{"benchmark":0.2653152855,"new-dataset":0.3265396934,"data-annotation":0.5290903291,"dev-research":0.1856224102,"llms":0.5026610627,"data-quality":0.2225948801}}
{"text":"Our method significantly outperforms classical mention-pair methods on a large Dutch event coreference corpus in terms of overall score, efficiency and training speed.","meta":{"url":"http://arxiv.org/abs/2310.11965v1"},"cats":{"benchmark":0.4999724184,"new-dataset":0.3266092513,"data-annotation":0.5721386361,"dev-research":0.2087213568,"llms":0.5191278416,"data-quality":0.2619936534}}
{"text":"Additionally, we show that our models are consistently able to classify more difficult coreference links and are far more robust in low-data settings when compared to transformer-based mention-pair coreference algorithms.","meta":{"url":"http://arxiv.org/abs/2310.11965v1"},"cats":{"benchmark":0.4231401631,"new-dataset":0.1225376725,"data-annotation":0.5485093279,"dev-research":0.2192818634,"llms":0.5681513484,"data-quality":0.3374493943}}
{"text":"Translation-based AMR parsers have recently gained popularity due to their simplicity and effectiveness.","meta":{"url":"http://arxiv.org/abs/2310.11964v1"},"cats":{"benchmark":0.3562304032,"new-dataset":0.0831791648,"data-annotation":0.5210100297,"dev-research":0.1554621077,"llms":0.5800281731,"data-quality":0.1899383214}}
{"text":"They predict linearized graphs as free texts, avoiding explicit structure modeling.","meta":{"url":"http://arxiv.org/abs/2310.11964v1"},"cats":{"benchmark":0.2870369303,"new-dataset":0.0383830518,"data-annotation":0.5327978801,"dev-research":0.1611769584,"llms":0.4265221001,"data-quality":0.1007697196}}
{"text":"However, this simplicity neglects structural locality in AMR graphs and introduces unnecessary tokens to represent coreferences.","meta":{"url":"http://arxiv.org/abs/2310.11964v1"},"cats":{"benchmark":0.3818032152,"new-dataset":0.0480689977,"data-annotation":0.5389587421,"dev-research":0.2039191083,"llms":0.5447884877,"data-quality":0.2034030715}}
{"text":"In this paper, we introduce new target forms of AMR parsing and a novel model, CHAP, which is equipped with causal hierarchical attention and the pointer mechanism, enabling the integration of structures into the Transformer decoder.","meta":{"url":"http://arxiv.org/abs/2310.11964v1"},"cats":{"benchmark":0.2233356244,"new-dataset":0.0610233163,"data-annotation":0.511842515,"dev-research":0.1824196686,"llms":0.548386067,"data-quality":0.1371531529}}
{"text":"We empirically explore various alternative modeling options.","meta":{"url":"http://arxiv.org/abs/2310.11964v1"},"cats":{"benchmark":0.4229728682,"new-dataset":0.005237317,"data-annotation":0.4843078279,"dev-research":0.2435699446,"llms":0.480381297,"data-quality":0.0653745487}}
{"text":"Experiments show that our model outperforms baseline models on four out of five benchmarks in the setting of no additional data.","meta":{"url":"http://arxiv.org/abs/2310.11964v1"},"cats":{"benchmark":0.7379709058,"new-dataset":0.0487827795,"data-annotation":0.4919252426,"dev-research":0.1629113464,"llms":0.3823513413,"data-quality":0.1130408905}}
{"text":"Transformer-based models have achieved state-of-the-art performance in many areas.","meta":{"url":"http://arxiv.org/abs/2310.11960v1"},"cats":{"benchmark":0.4807948646,"new-dataset":0.0052569528,"data-annotation":0.4911498388,"dev-research":0.1409215979,"llms":0.4936767704,"data-quality":0.0439917042}}
{"text":"However, the quadratic complexity of self-attention with respect to the input length hinders the applicability of Transformer-based models to long sequences.","meta":{"url":"http://arxiv.org/abs/2310.11960v1"},"cats":{"benchmark":0.2309972613,"new-dataset":0.0099615428,"data-annotation":0.5433802321,"dev-research":0.1120418148,"llms":0.4504639322,"data-quality":0.0836271305}}
{"text":"To address this, we present Fast Multipole Attention, a new attention mechanism that uses a divide-and-conquer strategy to reduce the time and memory complexity of attention for sequences of length $n$ from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(n \\log n)$ or $O(n)$, while retaining a global receptive field.","meta":{"url":"http://arxiv.org/abs/2310.11960v1"},"cats":{"benchmark":0.2467877734,"new-dataset":0.0845065977,"data-annotation":0.5444998732,"dev-research":0.123527124,"llms":0.5083628034,"data-quality":0.0598782816}}
{"text":"The hierarchical approach groups queries, keys, and values into $\\mathcal{O}( \\log n)$ levels of resolution, where groups at greater distances are increasingly larger in size and the weights to compute group quantities are learned.","meta":{"url":"http://arxiv.org/abs/2310.11960v1"},"cats":{"benchmark":0.4205368322,"new-dataset":0.0869712064,"data-annotation":0.5236949291,"dev-research":0.1212337504,"llms":0.4798645042,"data-quality":0.0753284408}}
{"text":"As such, the interaction between tokens far from each other is considered in lower resolution in an efficient hierarchical manner.","meta":{"url":"http://arxiv.org/abs/2310.11960v1"},"cats":{"benchmark":0.4811363094,"new-dataset":0.0032082169,"data-annotation":0.5149185743,"dev-research":0.1524536744,"llms":0.5162343962,"data-quality":0.1232407591}}
{"text":"The overall complexity of Fast Multipole Attention is $\\mathcal{O}(n)$ or $\\mathcal{O}(n \\log n)$, depending on whether the queries are down-sampled or not.","meta":{"url":"http://arxiv.org/abs/2310.11960v1"},"cats":{"benchmark":0.4517640809,"new-dataset":0.0227675911,"data-annotation":0.5269146657,"dev-research":0.0890424026,"llms":0.5140810774,"data-quality":0.0684693482}}
{"text":"This multi-level divide-and-conquer strategy is inspired by fast summation methods from $n$-body physics and the Fast Multipole Method.","meta":{"url":"http://arxiv.org/abs/2310.11960v1"},"cats":{"benchmark":0.5006714308,"new-dataset":0.0127240861,"data-annotation":0.5342862663,"dev-research":0.1089632724,"llms":0.4330371817,"data-quality":0.0362437447}}
{"text":"We perform evaluation on autoregressive and bidirectional language modeling tasks and compare our Fast Multipole Attention model with other efficient attention variants on medium-size datasets.","meta":{"url":"http://arxiv.org/abs/2310.11960v1"},"cats":{"benchmark":0.3449742073,"new-dataset":0.186748618,"data-annotation":0.5424896677,"dev-research":0.1189568164,"llms":0.5130903059,"data-quality":0.1301827146}}
{"text":"We find empirically that the Fast Multipole Transformer performs much better than other efficient transformers in terms of memory size and accuracy.","meta":{"url":"http://arxiv.org/abs/2310.11960v1"},"cats":{"benchmark":0.5417739815,"new-dataset":0.0131388133,"data-annotation":0.5189376544,"dev-research":0.1657948957,"llms":0.5510840587,"data-quality":0.0789453083}}
{"text":"The Fast Multipole Attention mechanism has the potential to empower large language models with much greater sequence lengths, taking the full context into account in an efficient, naturally hierarchical manner during training and when generating long sequences.","meta":{"url":"http://arxiv.org/abs/2310.11960v1"},"cats":{"benchmark":0.2273752614,"new-dataset":0.1008406041,"data-annotation":0.5512929648,"dev-research":0.1162728591,"llms":0.5444845016,"data-quality":0.1065876643}}
{"text":"Time series data, often characterized by unique composition and complex multi-scale temporal variations, requires special consideration of decomposition and multi-scale modeling in its analysis.","meta":{"url":"http://arxiv.org/abs/2310.11959v1"},"cats":{"benchmark":0.4135830496,"new-dataset":0.0615323552,"data-annotation":0.4894743793,"dev-research":0.123681407,"llms":0.3475002493,"data-quality":0.0571825624}}
{"text":"Existing deep learning methods on this best fit to only univariate time series, and have not sufficiently accounted for sub-series level modeling and decomposition completeness.","meta":{"url":"http://arxiv.org/abs/2310.11959v1"},"cats":{"benchmark":0.3891891075,"new-dataset":0.0512801515,"data-annotation":0.5169761853,"dev-research":0.122890355,"llms":0.3657149715,"data-quality":0.0759399164}}
{"text":"To address this, we propose MSD-Mixer, a Multi-Scale Decomposition MLP-Mixer which learns to explicitly decompose the input time series into different components, and represents the components in different layers.","meta":{"url":"http://arxiv.org/abs/2310.11959v1"},"cats":{"benchmark":0.3705606645,"new-dataset":0.1166328178,"data-annotation":0.5032337232,"dev-research":0.1577222703,"llms":0.4720730541,"data-quality":0.1052410373}}
{"text":"To handle multi-scale temporal patterns and inter-channel dependencies, we propose a novel temporal patching approach to model the time series as multi-scale sub-series, i.e., patches, and employ MLPs to mix intra- and inter-patch variations and channel-wise correlations.","meta":{"url":"http://arxiv.org/abs/2310.11959v1"},"cats":{"benchmark":0.3662970894,"new-dataset":0.0984358471,"data-annotation":0.4784480462,"dev-research":0.1853311483,"llms":0.4439706905,"data-quality":0.100764299}}
{"text":"In addition, we propose a loss function to constrain both the magnitude and autocorrelation of the decomposition residual for decomposition completeness.","meta":{"url":"http://arxiv.org/abs/2310.11959v1"},"cats":{"benchmark":0.5576802198,"new-dataset":0.0131664595,"data-annotation":0.5411075972,"dev-research":0.1688513051,"llms":0.2915148278,"data-quality":0.1951188673}}
{"text":"Through extensive experiments on various real-world datasets for five common time series analysis tasks (long- and short-term forecasting, imputation, anomaly detection, and classification), we demonstrate that MSD-Mixer consistently achieves significantly better performance in comparison with other state-of-the-art task-general and task-specific approaches.","meta":{"url":"http://arxiv.org/abs/2310.11959v1"},"cats":{"benchmark":0.5013211491,"new-dataset":0.0734950191,"data-annotation":0.5045593943,"dev-research":0.1955228908,"llms":0.501129257,"data-quality":0.1318983451}}
{"text":"We call into question the recently popularized method of direct model editing as a means of correcting factual errors in LLM generations.","meta":{"url":"http://arxiv.org/abs/2310.11958v1"},"cats":{"benchmark":0.2533794921,"new-dataset":0.0159477027,"data-annotation":0.5074680585,"dev-research":0.4180084243,"llms":0.6917944381,"data-quality":0.2773471031}}
{"text":"We contrast model editing with three similar but distinct approaches that pursue better defined objectives: (1) retrieval-based architectures, which decouple factual memory from inference and linguistic capabilities embodied in LLMs; (2) concept erasure methods, which aim at preventing systemic bias in generated text; and (3) attribution methods, which aim at grounding generations into identified textual sources.","meta":{"url":"http://arxiv.org/abs/2310.11958v1"},"cats":{"benchmark":0.2988432345,"new-dataset":0.0216352868,"data-annotation":0.5145718516,"dev-research":0.2401830995,"llms":0.6533810431,"data-quality":0.2537653111}}
{"text":"We argue that direct model editing cannot be trusted as a systematic remedy for the disadvantages inherent to LLMs, and while it has proven potential in improving model explainability, it opens risks by reinforcing the notion that models can be trusted for factuality.","meta":{"url":"http://arxiv.org/abs/2310.11958v1"},"cats":{"benchmark":0.2439638032,"new-dataset":0.0147910824,"data-annotation":0.5077976295,"dev-research":0.3718345674,"llms":0.6828231648,"data-quality":0.2176309626}}
{"text":"We call for cautious promotion and application of model editing as part of the LLM deployment process, and for responsibly limiting the use cases of LLMs to those not relying on editing as a critical component.","meta":{"url":"http://arxiv.org/abs/2310.11958v1"},"cats":{"benchmark":0.2266139587,"new-dataset":0.0153419198,"data-annotation":0.4926061556,"dev-research":0.3433052837,"llms":0.7199409857,"data-quality":0.1418188079}}
{"text":"Over the last years, Unmanned Aerial Vehicles (UAVs) have seen significant advancements in sensor capabilities and computational abilities, allowing for efficient autonomous navigation and visual tracking applications.","meta":{"url":"http://arxiv.org/abs/2310.11957v1"},"cats":{"benchmark":0.2802702058,"new-dataset":0.0758615824,"data-annotation":0.5053308316,"dev-research":0.193148192,"llms":0.4757169994,"data-quality":0.0454908074}}
{"text":"However, the demand for computationally complex tasks has increased faster than advances in battery technology.","meta":{"url":"http://arxiv.org/abs/2310.11957v1"},"cats":{"benchmark":0.3987534936,"new-dataset":0.0052467497,"data-annotation":0.5135267575,"dev-research":0.256527503,"llms":0.5139820504,"data-quality":0.0390229876}}
{"text":"This opens up possibilities for improvements using edge computing.","meta":{"url":"http://arxiv.org/abs/2310.11957v1"},"cats":{"benchmark":0.3699073534,"new-dataset":0.004581282,"data-annotation":0.4948007037,"dev-research":0.2328395549,"llms":0.5215288385,"data-quality":0.0626852495}}
{"text":"In edge computing, edge servers can achieve lower latency responses compared to traditional cloud servers through strategic geographic deployments.","meta":{"url":"http://arxiv.org/abs/2310.11957v1"},"cats":{"benchmark":0.5097509421,"new-dataset":0.0058250357,"data-annotation":0.4686563312,"dev-research":0.2099626482,"llms":0.5278671857,"data-quality":0.0719074619}}
{"text":"Furthermore, these servers can maintain superior computational performance compared to UAVs, as they are not limited by battery constraints.","meta":{"url":"http://arxiv.org/abs/2310.11957v1"},"cats":{"benchmark":0.4345447285,"new-dataset":0.0090541771,"data-annotation":0.5010057087,"dev-research":0.2027896352,"llms":0.5163317228,"data-quality":0.0483303453}}
{"text":"Combining these technologies by aiding UAVs with edge servers, research finds measurable improvements in task completion speed, energy efficiency, and reliability across multiple applications and industries.","meta":{"url":"http://arxiv.org/abs/2310.11957v1"},"cats":{"benchmark":0.4384782096,"new-dataset":0.0159022015,"data-annotation":0.4954916917,"dev-research":0.2428055239,"llms":0.4949446594,"data-quality":0.047255916}}
{"text":"This systematic literature review aims to analyze the current state of research and collect, select, and extract the key areas where UAV activities can be supported and improved through edge computing.","meta":{"url":"http://arxiv.org/abs/2310.11957v1"},"cats":{"benchmark":0.2576786585,"new-dataset":0.0536278479,"data-annotation":0.4839930598,"dev-research":0.2531444271,"llms":0.5291459239,"data-quality":0.0430527938}}
{"text":"AI-empowered music processing is a diverse field that encompasses dozens of tasks, ranging from generation tasks (e.g., timbre synthesis) to comprehension tasks (e.g., music classification).","meta":{"url":"http://arxiv.org/abs/2310.11954v1"},"cats":{"benchmark":0.2466972876,"new-dataset":0.0329395586,"data-annotation":0.5064638098,"dev-research":0.158746493,"llms":0.4853231645,"data-quality":0.1445230366}}
{"text":"For developers and amateurs, it is very difficult to grasp all of these task to satisfy their requirements in music processing, especially considering the huge differences in the representations of music data and the model applicability across platforms among various tasks.","meta":{"url":"http://arxiv.org/abs/2310.11954v1"},"cats":{"benchmark":0.3160401681,"new-dataset":0.0608935214,"data-annotation":0.4997677294,"dev-research":0.2173124486,"llms":0.469320995,"data-quality":0.1867795131}}
{"text":"Consequently, it is necessary to build a system to organize and integrate these tasks, and thus help practitioners to automatically analyze their demand and call suitable tools as solutions to fulfill their requirements.","meta":{"url":"http://arxiv.org/abs/2310.11954v1"},"cats":{"benchmark":0.283367446,"new-dataset":0.1109473265,"data-annotation":0.4931755249,"dev-research":0.4818525234,"llms":0.5264902572,"data-quality":0.0962904601}}
{"text":"Inspired by the recent success of large language models (LLMs) in task automation, we develop a system, named MusicAgent, which integrates numerous music-related tools and an autonomous workflow to address user requirements.","meta":{"url":"http://arxiv.org/abs/2310.11954v1"},"cats":{"benchmark":0.2456785312,"new-dataset":0.1247022525,"data-annotation":0.5158222413,"dev-research":0.25255191,"llms":0.6050653433,"data-quality":0.1743730179}}
{"text":"More specifically, we build 1) toolset that collects tools from diverse sources, including Hugging Face, GitHub, and Web API, etc. 2) an autonomous workflow empowered by LLMs (e.g., ChatGPT) to organize these tools and automatically decompose user requests into multiple sub-tasks and invoke corresponding music tools.","meta":{"url":"http://arxiv.org/abs/2310.11954v1"},"cats":{"benchmark":0.2109147714,"new-dataset":0.1951547337,"data-annotation":0.4780373606,"dev-research":0.3033811261,"llms":0.7239161715,"data-quality":0.1010792728}}
{"text":"The primary goal of this system is to free users from the intricacies of AI-music tools, enabling them to concentrate on the creative aspect.","meta":{"url":"http://arxiv.org/abs/2310.11954v1"},"cats":{"benchmark":0.2507112531,"new-dataset":0.073720769,"data-annotation":0.520735909,"dev-research":0.2315634397,"llms":0.5025198291,"data-quality":0.1272882085}}
{"text":"By granting users the freedom to effortlessly combine tools, the system offers a seamless and enriching music experience.","meta":{"url":"http://arxiv.org/abs/2310.11954v1"},"cats":{"benchmark":0.2842326734,"new-dataset":0.0208222757,"data-annotation":0.4944503728,"dev-research":0.2250223225,"llms":0.527111032,"data-quality":0.1032256121}}
{"text":"Low-rank adapation (LoRA) is a popular method that reduces the number of trainable parameters when finetuning large language models, but still faces acute storage challenges when scaling to even larger models or deploying numerous per-user or per-task adapted models.","meta":{"url":"http://arxiv.org/abs/2310.11454v1"},"cats":{"benchmark":0.3683535198,"new-dataset":0.0399201836,"data-annotation":0.5335293153,"dev-research":0.1704497109,"llms":0.5782908018,"data-quality":0.1502168641}}
{"text":"In this work, we present Vector-based Random Matrix Adaptation (VeRA), which reduces the number of trainable parameters by 10x compared to LoRA, yet maintains the same performance.","meta":{"url":"http://arxiv.org/abs/2310.11454v1"},"cats":{"benchmark":0.4002974195,"new-dataset":0.035128539,"data-annotation":0.5209386488,"dev-research":0.1209664107,"llms":0.4887894675,"data-quality":0.1365569933}}
{"text":"It achieves this by using a single pair of low-rank matrices shared across all layers and learning small scaling vectors instead.","meta":{"url":"http://arxiv.org/abs/2310.11454v1"},"cats":{"benchmark":0.3436644658,"new-dataset":0.0085301906,"data-annotation":0.5275647359,"dev-research":0.1012335207,"llms":0.4273053716,"data-quality":0.1014782617}}
{"text":"We demonstrate its effectiveness on the GLUE and E2E benchmarks, and show its application in instruction-following with just 1.4M parameters using the Llama2 7B model.","meta":{"url":"http://arxiv.org/abs/2310.11454v1"},"cats":{"benchmark":0.5270481497,"new-dataset":0.0360880499,"data-annotation":0.527510049,"dev-research":0.2221080044,"llms":0.6780905726,"data-quality":0.0837493646}}
{"text":"The increasing size of large language models has posed challenges for deployment and raised concerns about environmental impact due to high energy consumption.","meta":{"url":"http://arxiv.org/abs/2310.11453v1"},"cats":{"benchmark":0.2755047876,"new-dataset":0.1477401938,"data-annotation":0.5119233186,"dev-research":0.2756721777,"llms":0.5547970133,"data-quality":0.182469962}}
{"text":"In this work, we introduce BitNet, a scalable and stable 1-bit Transformer architecture designed for large language models.","meta":{"url":"http://arxiv.org/abs/2310.11453v1"},"cats":{"benchmark":0.2567423029,"new-dataset":0.1421672271,"data-annotation":0.5230119317,"dev-research":0.1804747384,"llms":0.5826372834,"data-quality":0.1280012027}}
{"text":"Specifically, we introduce BitLinear as a drop-in replacement of the nn.","meta":{"url":"http://arxiv.org/abs/2310.11453v1"},"cats":{"benchmark":0.3639270262,"new-dataset":0.0255870087,"data-annotation":0.5034470143,"dev-research":0.1655727463,"llms":0.569763472,"data-quality":0.1218512322}}
{"text":"Linear layer in order to train 1-bit weights from scratch.","meta":{"url":"http://arxiv.org/abs/2310.11453v1"},"cats":{"benchmark":0.2992482359,"new-dataset":0.0722909413,"data-annotation":0.5215713212,"dev-research":0.1486834001,"llms":0.4309987004,"data-quality":0.1197016494}}
{"text":"Experimental results on language modeling show that BitNet achieves competitive performance while substantially reducing memory footprint and energy consumption, compared to state-of-the-art 8-bit quantization methods and FP16 Transformer baselines.","meta":{"url":"http://arxiv.org/abs/2310.11453v1"},"cats":{"benchmark":0.3688197269,"new-dataset":0.0400828104,"data-annotation":0.5190943264,"dev-research":0.2364518871,"llms":0.5678797397,"data-quality":0.0967896682}}
{"text":"Furthermore, BitNet exhibits a scaling law akin to full-precision Transformers, suggesting its potential for effective scaling to even larger language models while maintaining efficiency and performance benefits.","meta":{"url":"http://arxiv.org/abs/2310.11453v1"},"cats":{"benchmark":0.3570193786,"new-dataset":0.0125975164,"data-annotation":0.5199815052,"dev-research":0.199416373,"llms":0.5594470388,"data-quality":0.1143703204}}
{"text":"Large Language Models (LLMs) inherently encode a wealth of knowledge within their parameters through pre-training on extensive corpora.","meta":{"url":"http://arxiv.org/abs/2310.11451v1"},"cats":{"benchmark":0.213863489,"new-dataset":0.1358257034,"data-annotation":0.5538553404,"dev-research":0.1356150025,"llms":0.6373806575,"data-quality":0.1441736946}}
{"text":"While prior research has delved into operations on these parameters to manipulate the underlying implicit knowledge (encompassing detection, editing, and merging), there remains an ambiguous understanding regarding their transferability across models with varying scales.","meta":{"url":"http://arxiv.org/abs/2310.11451v1"},"cats":{"benchmark":0.2929301363,"new-dataset":0.0142220945,"data-annotation":0.503975861,"dev-research":0.2278856737,"llms":0.450853435,"data-quality":0.176204864}}
{"text":"In this paper, we seek to empirically investigate knowledge transfer from larger to smaller models through a parametric perspective.","meta":{"url":"http://arxiv.org/abs/2310.11451v1"},"cats":{"benchmark":0.3128079088,"new-dataset":0.0248091671,"data-annotation":0.5115616239,"dev-research":0.2088506635,"llms":0.4234116007,"data-quality":0.0857990325}}
{"text":"To achieve this, we employ sensitivity-based techniques to extract and align knowledge-specific parameters between different LLMs.","meta":{"url":"http://arxiv.org/abs/2310.11451v1"},"cats":{"benchmark":0.4502410481,"new-dataset":0.030205583,"data-annotation":0.4816497801,"dev-research":0.1445716182,"llms":0.6799162927,"data-quality":0.1582302169}}
{"text":"Moreover, the LoRA module is used as the intermediary mechanism for injecting the extracted knowledge into smaller models.","meta":{"url":"http://arxiv.org/abs/2310.11451v1"},"cats":{"benchmark":0.1884147551,"new-dataset":0.0411637501,"data-annotation":0.4953512137,"dev-research":0.1845055505,"llms":0.6011907553,"data-quality":0.0928121767}}
{"text":"Evaluations across four benchmarks validate the efficacy of our proposed method.","meta":{"url":"http://arxiv.org/abs/2310.11451v1"},"cats":{"benchmark":0.8746280816,"new-dataset":0.0012196084,"data-annotation":0.4973262389,"dev-research":0.2609895579,"llms":0.438426973,"data-quality":0.1473041211}}
{"text":"Our findings highlight the critical factors contributing to the process of parametric knowledge transfer, underscoring the transferability of model parameters across LLMs of different scales.","meta":{"url":"http://arxiv.org/abs/2310.11451v1"},"cats":{"benchmark":0.3268159305,"new-dataset":0.0107502798,"data-annotation":0.4786151058,"dev-research":0.1698923331,"llms":0.5684459046,"data-quality":0.0648031569}}
{"text":"We release code and data at \\url{https://github.com/maszhongming/ParaKnowTransfer}.","meta":{"url":"http://arxiv.org/abs/2310.11451v1"},"cats":{"benchmark":0.2118939935,"new-dataset":0.5110435556,"data-annotation":0.4925545177,"dev-research":0.2115321087,"llms":0.5242593014,"data-quality":0.1533212369}}
{"text":"Concept-based explanation methods, such as Concept Activation Vectors, are potent means to quantify how abstract or high-level characteristics of input data influence the predictions of complex deep neural networks.","meta":{"url":"http://arxiv.org/abs/2310.11450v1"},"cats":{"benchmark":0.2453861887,"new-dataset":0.015093166,"data-annotation":0.5462839283,"dev-research":0.3802083436,"llms":0.4516453721,"data-quality":0.2730537312}}
{"text":"However, applying them to industrial prediction problems is challenging as it is not immediately clear how to define and access appropriate concepts for individual use cases and specific data types.","meta":{"url":"http://arxiv.org/abs/2310.11450v1"},"cats":{"benchmark":0.2908519905,"new-dataset":0.0140793381,"data-annotation":0.5156470605,"dev-research":0.3471999736,"llms":0.4426639942,"data-quality":0.1610680353}}
{"text":"In this work, we investigate how to leverage established concept-based explanation techniques in the context of bearing fault detection with deep neural networks trained on vibration signals.","meta":{"url":"http://arxiv.org/abs/2310.11450v1"},"cats":{"benchmark":0.2341550044,"new-dataset":0.1352568181,"data-annotation":0.5500296805,"dev-research":0.3514545139,"llms":0.4811273781,"data-quality":0.3433084636}}
{"text":"Since bearings are prevalent in almost every rotating equipment, ensuring the reliability of intransparent fault detection models is crucial to prevent costly repairs and downtimes of industrial machinery.","meta":{"url":"http://arxiv.org/abs/2310.11450v1"},"cats":{"benchmark":0.4137551293,"new-dataset":0.0187195064,"data-annotation":0.5369933152,"dev-research":0.3118300657,"llms":0.5188688612,"data-quality":0.3337557108}}
{"text":"Our evaluations demonstrate that explaining opaque models in terms of vibration concepts enables human-comprehensible and intuitive insights about their inner workings, but the underlying assumptions need to be carefully validated first.","meta":{"url":"http://arxiv.org/abs/2310.11450v1"},"cats":{"benchmark":0.2210521886,"new-dataset":0.0195452829,"data-annotation":0.5240320945,"dev-research":0.2359875688,"llms":0.4845204577,"data-quality":0.1300801889}}
{"text":"Generating controllable and photorealistic digital human avatars is a long-standing and important problem in Vision and Graphics.","meta":{"url":"http://arxiv.org/abs/2310.11449v1"},"cats":{"benchmark":0.1304439507,"new-dataset":0.1966772419,"data-annotation":0.505424732,"dev-research":0.2328638095,"llms":0.5010889935,"data-quality":0.0665865187}}
{"text":"Recent methods have shown great progress in terms of either photorealism or inference speed while the combination of the two desired properties still remains unsolved.","meta":{"url":"http://arxiv.org/abs/2310.11449v1"},"cats":{"benchmark":0.3788032864,"new-dataset":0.0359393492,"data-annotation":0.5396738151,"dev-research":0.1037560719,"llms":0.4206587213,"data-quality":0.07284846}}
{"text":"To this end, we propose a novel method, called DELIFFAS, which parameterizes the appearance of the human as a surface light field that is attached to a controllable and deforming human mesh model.","meta":{"url":"http://arxiv.org/abs/2310.11449v1"},"cats":{"benchmark":0.2938170155,"new-dataset":0.1248539314,"data-annotation":0.5176426475,"dev-research":0.1941416095,"llms":0.4157382008,"data-quality":0.0497224413}}
{"text":"At the core, we represent the light field around the human with a deformable two-surface parameterization, which enables fast and accurate inference of the human appearance.","meta":{"url":"http://arxiv.org/abs/2310.11449v1"},"cats":{"benchmark":0.286683583,"new-dataset":0.1329321113,"data-annotation":0.5190259019,"dev-research":0.1571115918,"llms":0.3941833292,"data-quality":0.0445450489}}
{"text":"This allows perceptual supervision on the full image compared to previous approaches that could only supervise individual pixels or small patches due to their slow runtime.","meta":{"url":"http://arxiv.org/abs/2310.11449v1"},"cats":{"benchmark":0.2440889885,"new-dataset":0.0330982524,"data-annotation":0.5143331037,"dev-research":0.2527311312,"llms":0.4975388697,"data-quality":0.105416871}}
{"text":"Our carefully designed human representation and supervision strategy leads to state-of-the-art synthesis results and inference time.","meta":{"url":"http://arxiv.org/abs/2310.11449v1"},"cats":{"benchmark":0.2436936408,"new-dataset":0.1072755256,"data-annotation":0.5257408366,"dev-research":0.3083379981,"llms":0.5295589321,"data-quality":0.0905136766}}
{"text":"The video results and code are available at https://vcai.mpi-inf.mpg.de/projects/DELIFFAS.","meta":{"url":"http://arxiv.org/abs/2310.11449v1"},"cats":{"benchmark":0.4067082194,"new-dataset":0.4987001489,"data-annotation":0.5265404917,"dev-research":0.1318570059,"llms":0.4973702565,"data-quality":0.1469643195}}
{"text":"This paper targets high-fidelity and real-time view synthesis of dynamic 3D scenes at 4K resolution.","meta":{"url":"http://arxiv.org/abs/2310.11448v1"},"cats":{"benchmark":0.2960221278,"new-dataset":0.3462225952,"data-annotation":0.4933771498,"dev-research":0.1981183184,"llms":0.4482550444,"data-quality":0.0547090903}}
{"text":"Recently, some methods on dynamic view synthesis have shown impressive rendering quality.","meta":{"url":"http://arxiv.org/abs/2310.11448v1"},"cats":{"benchmark":0.4665293534,"new-dataset":0.0953793802,"data-annotation":0.5288677189,"dev-research":0.2817007756,"llms":0.4834755021,"data-quality":0.0703331869}}
{"text":"However, their speed is still limited when rendering high-resolution images.","meta":{"url":"http://arxiv.org/abs/2310.11448v1"},"cats":{"benchmark":0.3977447951,"new-dataset":0.022581971,"data-annotation":0.5015735358,"dev-research":0.158596556,"llms":0.5048180577,"data-quality":0.0603518212}}
{"text":"To overcome this problem, we propose 4K4D, a 4D point cloud representation that supports hardware rasterization and enables unprecedented rendering speed.","meta":{"url":"http://arxiv.org/abs/2310.11448v1"},"cats":{"benchmark":0.3255310027,"new-dataset":0.2032823199,"data-annotation":0.4974736882,"dev-research":0.1403306317,"llms":0.4819691675,"data-quality":0.058486864}}
{"text":"Our representation is built on a 4D feature grid so that the points are naturally regularized and can be robustly optimized.","meta":{"url":"http://arxiv.org/abs/2310.11448v1"},"cats":{"benchmark":0.3633842694,"new-dataset":0.0771847977,"data-annotation":0.5216460933,"dev-research":0.1852409474,"llms":0.3863705979,"data-quality":0.0878479309}}
{"text":"In addition, we design a novel hybrid appearance model that significantly boosts the rendering quality while preserving efficiency.","meta":{"url":"http://arxiv.org/abs/2310.11448v1"},"cats":{"benchmark":0.5342731688,"new-dataset":0.0467612043,"data-annotation":0.5246650269,"dev-research":0.2124397233,"llms":0.4143800517,"data-quality":0.0787373566}}
{"text":"Moreover, we develop a differentiable depth peeling algorithm to effectively learn the proposed model from RGB videos.","meta":{"url":"http://arxiv.org/abs/2310.11448v1"},"cats":{"benchmark":0.3302155969,"new-dataset":0.1474076728,"data-annotation":0.5189238883,"dev-research":0.1723524193,"llms":0.399567805,"data-quality":0.0683515673}}
{"text":"Experiments show that our representation can be rendered at over 400 FPS on the DNA-Rendering dataset at 1080p resolution and 80 FPS on the ENeRF-Outdoor dataset at 4K resolution using an RTX 4090 GPU, which is 30x faster than previous methods and achieves the state-of-the-art rendering quality.","meta":{"url":"http://arxiv.org/abs/2310.11448v1"},"cats":{"benchmark":0.4146254883,"new-dataset":0.4596062534,"data-annotation":0.4874320067,"dev-research":0.1685666878,"llms":0.52036115,"data-quality":0.0724651313}}
{"text":"We will release the code for reproducibility.","meta":{"url":"http://arxiv.org/abs/2310.11448v1"},"cats":{"benchmark":0.3062272468,"new-dataset":0.3273887866,"data-annotation":0.5249248829,"dev-research":0.3041791537,"llms":0.5385934053,"data-quality":0.2428175576}}
{"text":"Nondango is a pencil puzzle consisting of a rectangular grid partitioned into regions, with some cells containing a white circle.","meta":{"url":"http://arxiv.org/abs/2310.11447v1"},"cats":{"benchmark":0.2132779793,"new-dataset":0.2523819716,"data-annotation":0.5132106017,"dev-research":0.175114191,"llms":0.542941866,"data-quality":0.0659453582}}
{"text":"The player has to color some circles black such that every region contains exactly one black circle, and there are no three consecutive circles (horizontally, vertically, or diagonally) with the same color.","meta":{"url":"http://arxiv.org/abs/2310.11447v1"},"cats":{"benchmark":0.2205348893,"new-dataset":0.1065513505,"data-annotation":0.519342429,"dev-research":0.2274955574,"llms":0.536448339,"data-quality":0.1428995875}}
{"text":"In this paper, we prove that deciding the solvability of a given Nondango puzzle is NP-complete.","meta":{"url":"http://arxiv.org/abs/2310.11447v1"},"cats":{"benchmark":0.3385635205,"new-dataset":0.0632009533,"data-annotation":0.5295987041,"dev-research":0.1347718408,"llms":0.5408684376,"data-quality":0.0851714562}}
{"text":"The rapid growth of transformer-based models increases the concerns about their integrity and ownership insurance.","meta":{"url":"http://arxiv.org/abs/2310.11446v1"},"cats":{"benchmark":0.2531969419,"new-dataset":0.0119384656,"data-annotation":0.4906008764,"dev-research":0.2274804205,"llms":0.5110147994,"data-quality":0.0801725683}}
{"text":"Watermarking addresses this issue by embedding a unique identifier into the model, while preserving its performance.","meta":{"url":"http://arxiv.org/abs/2310.11446v1"},"cats":{"benchmark":0.5407326371,"new-dataset":0.0378375006,"data-annotation":0.5115824957,"dev-research":0.205088286,"llms":0.4586529457,"data-quality":0.4397591047}}
{"text":"However, most existing approaches require to optimize the weights to imprint the watermark signal, which is not suitable at scale due to the computational cost.","meta":{"url":"http://arxiv.org/abs/2310.11446v1"},"cats":{"benchmark":0.5579273143,"new-dataset":0.0073070894,"data-annotation":0.5225280752,"dev-research":0.1478586224,"llms":0.4468034249,"data-quality":0.2106559443}}
{"text":"This paper explores watermarks with virtually no computational cost, applicable to a non-blind white-box setting (assuming access to both the original and watermarked networks).","meta":{"url":"http://arxiv.org/abs/2310.11446v1"},"cats":{"benchmark":0.4679544564,"new-dataset":0.0949998881,"data-annotation":0.5136117337,"dev-research":0.1944525706,"llms":0.4661671551,"data-quality":0.2072205231}}
{"text":"They generate functionally equivalent copies by leveraging the models' invariance, via operations like dimension permutations or scaling/unscaling.","meta":{"url":"http://arxiv.org/abs/2310.11446v1"},"cats":{"benchmark":0.3338879068,"new-dataset":0.0199952506,"data-annotation":0.5076385433,"dev-research":0.1398967997,"llms":0.4881529634,"data-quality":0.0970417508}}
{"text":"This enables to watermark models without any change in their outputs and remains stealthy.","meta":{"url":"http://arxiv.org/abs/2310.11446v1"},"cats":{"benchmark":0.3217339186,"new-dataset":0.0138048694,"data-annotation":0.4895118239,"dev-research":0.205565591,"llms":0.5056501175,"data-quality":0.2375937472}}
{"text":"Experiments demonstrate the effectiveness of the approach and its robustness against various model transformations (fine-tuning, quantization, pruning), making it a practical solution to protect the integrity of large models.","meta":{"url":"http://arxiv.org/abs/2310.11446v1"},"cats":{"benchmark":0.4685626276,"new-dataset":0.0170148289,"data-annotation":0.4987282727,"dev-research":0.195743104,"llms":0.4753207903,"data-quality":0.1758197493}}
{"text":"To benefit from the abundance of data and the insights it brings data processing pipelines are being used in many areas of research and development in both industry and academia.","meta":{"url":"http://arxiv.org/abs/2310.11442v1"},"cats":{"benchmark":0.3072061629,"new-dataset":0.1882368899,"data-annotation":0.4183706238,"dev-research":0.3051964364,"llms":0.5150884293,"data-quality":0.1013672209}}
{"text":"One approach to automating data processing pipelines is the workflow technology, as it also supports collaborative, trial-and-error experimentation with the pipeline architecture in different application domains.","meta":{"url":"http://arxiv.org/abs/2310.11442v1"},"cats":{"benchmark":0.3281674931,"new-dataset":0.0791330501,"data-annotation":0.4241712868,"dev-research":0.4341110172,"llms":0.5720509086,"data-quality":0.1741281177}}
{"text":"In addition to the necessary flexibility that such pipelines need to possess, in collaborative settings cross-organisational interactions are plagued by lack of trust.","meta":{"url":"http://arxiv.org/abs/2310.11442v1"},"cats":{"benchmark":0.2392920266,"new-dataset":0.0108377018,"data-annotation":0.4456964372,"dev-research":0.3219005756,"llms":0.5900860895,"data-quality":0.1016550045}}
{"text":"While capturing provenance information related to the pipeline execution and the processed data is a first step towards enabling trusted collaborations, the current solutions do not allow for provenance of the change in the processing pipelines, where the subject of change can be made on any aspect of the workflow implementing the pipeline and on the data used while the pipeline is being executed.","meta":{"url":"http://arxiv.org/abs/2310.11442v1"},"cats":{"benchmark":0.3168398522,"new-dataset":0.1420693455,"data-annotation":0.4322383784,"dev-research":0.2875889946,"llms":0.5990199036,"data-quality":0.2015744923}}
{"text":"Therefore in this work we provide a solution architecture and a proof of concept implementation of a service, called Provenance Holder, which enable provenance of collaborative, adaptive data processing pipelines in a trusted manner.","meta":{"url":"http://arxiv.org/abs/2310.11442v1"},"cats":{"benchmark":0.3530848531,"new-dataset":0.2899640137,"data-annotation":0.4507666719,"dev-research":0.2408067183,"llms":0.6051406209,"data-quality":0.2169229812}}
{"text":"We also contribute a definition of a set of properties of such a service and identify future research directions.","meta":{"url":"http://arxiv.org/abs/2310.11442v1"},"cats":{"benchmark":0.2570045219,"new-dataset":0.0634368721,"data-annotation":0.4882870532,"dev-research":0.1335363931,"llms":0.5765127661,"data-quality":0.0850766014}}
{"text":"We present Set-of-Mark (SoM), a new visual prompting method, to unleash the visual grounding abilities of large multimodal models (LMMs), such as GPT-4V. As illustrated in Fig. 1 (right), we employ off-the-shelf interactive segmentation models, such as SAM, to partition an image into regions at different levels of granularity, and overlay these regions with a set of marks e.g., alphanumerics, masks, boxes.","meta":{"url":"http://arxiv.org/abs/2310.11441v1"},"cats":{"benchmark":0.2016843625,"new-dataset":0.2782221923,"data-annotation":0.5245374275,"dev-research":0.1378861031,"llms":0.5213887408,"data-quality":0.1144383925}}
{"text":"Using the marked image as input, GPT-4V can answer the questions that require visual grounding.","meta":{"url":"http://arxiv.org/abs/2310.11441v1"},"cats":{"benchmark":0.2152134986,"new-dataset":0.0815336105,"data-annotation":0.5181172383,"dev-research":0.1447728113,"llms":0.5191060299,"data-quality":0.0884346615}}
{"text":"We perform a comprehensive empirical study to validate the effectiveness of SoM on a wide range of fine-grained vision and multimodal tasks.","meta":{"url":"http://arxiv.org/abs/2310.11441v1"},"cats":{"benchmark":0.3430776261,"new-dataset":0.0478741524,"data-annotation":0.5088342646,"dev-research":0.1830589675,"llms":0.6381975594,"data-quality":0.1133007625}}
{"text":"For example, our experiments show that GPT-4V with SoM outperforms the state-of-the-art fully-finetuned referring segmentation model on RefCOCOg in a zero-shot setting.","meta":{"url":"http://arxiv.org/abs/2310.11441v1"},"cats":{"benchmark":0.3503442429,"new-dataset":0.112620817,"data-annotation":0.5255299655,"dev-research":0.1097575383,"llms":0.6330711665,"data-quality":0.1880338598}}
{"text":"The vision and language generative models have been overgrown in recent years.","meta":{"url":"http://arxiv.org/abs/2310.11440v1"},"cats":{"benchmark":0.1267805935,"new-dataset":0.1392381604,"data-annotation":0.5383780678,"dev-research":0.2363220171,"llms":0.5787246594,"data-quality":0.1659557659}}
{"text":"For video generation, various open-sourced models and public-available services are released for generating high-visual quality videos.","meta":{"url":"http://arxiv.org/abs/2310.11440v1"},"cats":{"benchmark":0.2700220079,"new-dataset":0.3262723001,"data-annotation":0.5126718319,"dev-research":0.2227956343,"llms":0.5697000409,"data-quality":0.1266066556}}
{"text":"However, these methods often use a few academic metrics, for example, FVD or IS, to evaluate the performance.","meta":{"url":"http://arxiv.org/abs/2310.11440v1"},"cats":{"benchmark":0.7481403004,"new-dataset":0.0031644701,"data-annotation":0.5364348369,"dev-research":0.2369012039,"llms":0.438087894,"data-quality":0.1300534187}}
{"text":"We argue that it is hard to judge the large conditional generative models from the simple metrics since these models are often trained on very large datasets with multi-aspect abilities.","meta":{"url":"http://arxiv.org/abs/2310.11440v1"},"cats":{"benchmark":0.319545086,"new-dataset":0.0790905604,"data-annotation":0.5412162128,"dev-research":0.1682018462,"llms":0.5031023242,"data-quality":0.1527674912}}
{"text":"Thus, we propose a new framework and pipeline to exhaustively evaluate the performance of the generated videos.","meta":{"url":"http://arxiv.org/abs/2310.11440v1"},"cats":{"benchmark":0.4946345295,"new-dataset":0.1452028353,"data-annotation":0.5146756678,"dev-research":0.2183639392,"llms":0.5031207181,"data-quality":0.1558210583}}
{"text":"To achieve this, we first conduct a new prompt list for text-to-video generation by analyzing the real-world prompt list with the help of the large language model.","meta":{"url":"http://arxiv.org/abs/2310.11440v1"},"cats":{"benchmark":0.1577815573,"new-dataset":0.656464561,"data-annotation":0.5361999309,"dev-research":0.2519134243,"llms":0.5685272618,"data-quality":0.1643152453}}
{"text":"Then, we evaluate the state-of-the-art video generative models on our carefully designed benchmarks, in terms of visual qualities, content qualities, motion qualities, and text-caption alignment with around 18 objective metrics.","meta":{"url":"http://arxiv.org/abs/2310.11440v1"},"cats":{"benchmark":0.4606149517,"new-dataset":0.1772530709,"data-annotation":0.5228101759,"dev-research":0.1884190931,"llms":0.5453157067,"data-quality":0.1446625499}}
{"text":"To obtain the final leaderboard of the models, we also fit a series of coefficients to align the objective metrics to the users' opinions.","meta":{"url":"http://arxiv.org/abs/2310.11440v1"},"cats":{"benchmark":0.5856961165,"new-dataset":0.0667837147,"data-annotation":0.5342336939,"dev-research":0.1940854219,"llms":0.3799088906,"data-quality":0.1190250349}}
{"text":"Based on the proposed opinion alignment method, our final score shows a higher correlation than simply averaging the metrics, showing the effectiveness of the proposed evaluation method.","meta":{"url":"http://arxiv.org/abs/2310.11440v1"},"cats":{"benchmark":0.6818740059,"new-dataset":0.0250947873,"data-annotation":0.5351648473,"dev-research":0.2420858617,"llms":0.4809617264,"data-quality":0.3175407934}}
{"text":"The remarkable success of deep neural networks (DNN) is often attributed to their high expressive power and their ability to approximate functions of arbitrary complexity.","meta":{"url":"http://arxiv.org/abs/2310.11439v1"},"cats":{"benchmark":0.3160701423,"new-dataset":0.0390735217,"data-annotation":0.5302963892,"dev-research":0.2730676877,"llms":0.471824651,"data-quality":0.1304299093}}
{"text":"Indeed, DNNs are highly non-linear models, and activation functions introduced into them are largely responsible for this.","meta":{"url":"http://arxiv.org/abs/2310.11439v1"},"cats":{"benchmark":0.3158464792,"new-dataset":0.0087617004,"data-annotation":0.5215989609,"dev-research":0.2067076265,"llms":0.4032087308,"data-quality":0.1592424471}}
{"text":"While many works studied the expressive power of DNNs through the lens of their approximation capabilities, quantifying the non-linearity of DNNs or of individual activation functions remains an open problem.","meta":{"url":"http://arxiv.org/abs/2310.11439v1"},"cats":{"benchmark":0.352970831,"new-dataset":0.0264947585,"data-annotation":0.5391155304,"dev-research":0.232581601,"llms":0.4221126569,"data-quality":0.1938432354}}
{"text":"In this paper, we propose the first theoretically sound solution to track non-linearity propagation in deep neural networks with a specific focus on computer vision applications.","meta":{"url":"http://arxiv.org/abs/2310.11439v1"},"cats":{"benchmark":0.3149902995,"new-dataset":0.0355898505,"data-annotation":0.5240416145,"dev-research":0.2024775903,"llms":0.3877899797,"data-quality":0.2664558987}}
{"text":"Our proposed affinity score allows us to gain insights into the inner workings of a wide range of different architectures and learning paradigms.","meta":{"url":"http://arxiv.org/abs/2310.11439v1"},"cats":{"benchmark":0.3692015653,"new-dataset":0.0096161453,"data-annotation":0.5288224071,"dev-research":0.1660228165,"llms":0.5006271905,"data-quality":0.0970174843}}
{"text":"We provide extensive experimental results that highlight the practical utility of the proposed affinity score and its potential for long-reaching applications.","meta":{"url":"http://arxiv.org/abs/2310.11439v1"},"cats":{"benchmark":0.655274442,"new-dataset":0.004912745,"data-annotation":0.5458007345,"dev-research":0.0991603866,"llms":0.4600567124,"data-quality":0.1307111847}}
{"text":"Cyberbullying and online harassment have serious negative psychological and emotional consequences for the victims, such as decreased life satisfaction, suicidal ideation, self-harming behaviors, depression, anxiety, and others.","meta":{"url":"http://arxiv.org/abs/2310.11436v1"},"cats":{"benchmark":0.2619814441,"new-dataset":0.0678969652,"data-annotation":0.5191470931,"dev-research":0.2824399305,"llms":0.5176094822,"data-quality":0.1881582714}}
{"text":"Most of the prior works assessed people's emotional responses via questionnaires, while social media platforms contain data that could provide valuable insights into users' emotions in real online discussions.","meta":{"url":"http://arxiv.org/abs/2310.11436v1"},"cats":{"benchmark":0.2973422821,"new-dataset":0.0933957733,"data-annotation":0.5089582999,"dev-research":0.3061285403,"llms":0.5256951088,"data-quality":0.1032889175}}
{"text":"Therefore, this data-driven study investigates the effect of toxicity on Twitter users' emotions and other factors associated with expressing anger, anxiety, and sadness in terms of account identifiability, activity, conversation structure, and conversation topic.","meta":{"url":"http://arxiv.org/abs/2310.11436v1"},"cats":{"benchmark":0.2439408873,"new-dataset":0.0959320023,"data-annotation":0.5153498221,"dev-research":0.3054361647,"llms":0.5292834931,"data-quality":0.1869604425}}
{"text":"To achieve this goal, we identified toxic replies in the large dataset consisting of 79,799 random Twitter conversations and obtained the emotions expressed in these conversations.","meta":{"url":"http://arxiv.org/abs/2310.11436v1"},"cats":{"benchmark":0.231242993,"new-dataset":0.679955129,"data-annotation":0.5320766369,"dev-research":0.244752237,"llms":0.5594122841,"data-quality":0.239513583}}
{"text":"Then, we performed propensity score matching and analyzed causal associations between toxicity and users' emotions.","meta":{"url":"http://arxiv.org/abs/2310.11436v1"},"cats":{"benchmark":0.4173194027,"new-dataset":0.1020760059,"data-annotation":0.5150308677,"dev-research":0.2923437445,"llms":0.4821646964,"data-quality":0.1716927715}}
{"text":"In general, we found that users receiving toxic replies are more likely to express emotions of anger, sadness, and anxiety compared to users who did not receive toxic replies.","meta":{"url":"http://arxiv.org/abs/2310.11436v1"},"cats":{"benchmark":0.2792555117,"new-dataset":0.0336091427,"data-annotation":0.532665077,"dev-research":0.308356092,"llms":0.5840579123,"data-quality":0.1933011852}}
{"text":"Finally, analysis results indicate that the conversation topic and users' account characteristics are likely to affect their emotional responses to toxicity.","meta":{"url":"http://arxiv.org/abs/2310.11436v1"},"cats":{"benchmark":0.2613663786,"new-dataset":0.0443068197,"data-annotation":0.5289239104,"dev-research":0.3416273944,"llms":0.5738720267,"data-quality":0.1784859163}}
{"text":"Our findings provide a better understanding of toxic replies' consequences on users' emotional states, which can potentially lead to developing personalized moderation methods that will help users emotionally cope with toxicity on social media.","meta":{"url":"http://arxiv.org/abs/2310.11436v1"},"cats":{"benchmark":0.2773018682,"new-dataset":0.0561333566,"data-annotation":0.5180511321,"dev-research":0.3179976914,"llms":0.5664666927,"data-quality":0.2403469121}}
{"text":"Large language models (LLMs) are becoming a one-fits-many solution, but they sometimes hallucinate or produce unreliable output.","meta":{"url":"http://arxiv.org/abs/2310.11430v1"},"cats":{"benchmark":0.2624335452,"new-dataset":0.0484407315,"data-annotation":0.5314054672,"dev-research":0.1709170663,"llms":0.7172705891,"data-quality":0.3131644943}}
{"text":"In this paper, we investigate how hypothesis ensembling can improve the quality of the generated text for the specific problem of LLM-based machine translation.","meta":{"url":"http://arxiv.org/abs/2310.11430v1"},"cats":{"benchmark":0.3575039046,"new-dataset":0.0672097709,"data-annotation":0.5263178665,"dev-research":0.1986822396,"llms":0.6855988783,"data-quality":0.2727742232}}
{"text":"We experiment with several techniques for ensembling hypotheses produced by LLMs such as ChatGPT, LLaMA, and Alpaca.","meta":{"url":"http://arxiv.org/abs/2310.11430v1"},"cats":{"benchmark":0.3537582952,"new-dataset":0.0772976515,"data-annotation":0.5246957078,"dev-research":0.1454447704,"llms":0.6933094156,"data-quality":0.2049997395}}
{"text":"We provide a comprehensive study along multiple dimensions, including the method to generate hypotheses (multiple prompts, temperature-based sampling, and beam search) and the strategy to produce the final translation (instruction-based, quality-based reranking, and minimum Bayes risk (MBR) decoding).","meta":{"url":"http://arxiv.org/abs/2310.11430v1"},"cats":{"benchmark":0.4137587127,"new-dataset":0.0792631298,"data-annotation":0.5285500856,"dev-research":0.176552061,"llms":0.5214146909,"data-quality":0.1874569927}}
{"text":"Our results show that MBR decoding is a very effective method, that translation quality can be improved using a small number of samples, and that instruction tuning has a strong impact on the relation between the diversity of the hypotheses and the sampling temperature.","meta":{"url":"http://arxiv.org/abs/2310.11430v1"},"cats":{"benchmark":0.4101679748,"new-dataset":0.105779899,"data-annotation":0.5105284401,"dev-research":0.1734362351,"llms":0.6024501603,"data-quality":0.2118759427}}
{"text":"This work studies training instabilities of behavior cloning with deep neural networks.","meta":{"url":"http://arxiv.org/abs/2310.11428v1"},"cats":{"benchmark":0.2157338909,"new-dataset":0.1236969731,"data-annotation":0.523928306,"dev-research":0.206277707,"llms":0.4980080553,"data-quality":0.1601808885}}
{"text":"We observe that minibatch SGD updates to the policy network during training result in sharp oscillations in long-horizon rewards, despite negligibly affecting the behavior cloning loss.","meta":{"url":"http://arxiv.org/abs/2310.11428v1"},"cats":{"benchmark":0.3169689578,"new-dataset":0.0268754472,"data-annotation":0.5269027901,"dev-research":0.1259669084,"llms":0.5131325964,"data-quality":0.164925358}}
{"text":"We empirically disentangle the statistical and computational causes of these oscillations, and find them to stem from the chaotic propagation of minibatch SGD noise through unstable closed-loop dynamics.","meta":{"url":"http://arxiv.org/abs/2310.11428v1"},"cats":{"benchmark":0.3528524577,"new-dataset":0.0538466329,"data-annotation":0.5244052481,"dev-research":0.1307841171,"llms":0.4785119803,"data-quality":0.1964438711}}
{"text":"While SGD noise is benign in the single-step action prediction objective, it results in catastrophic error accumulation over long horizons, an effect we term gradient variance amplification (GVA).","meta":{"url":"http://arxiv.org/abs/2310.11428v1"},"cats":{"benchmark":0.3922182823,"new-dataset":0.0181060277,"data-annotation":0.5162539331,"dev-research":0.1330939766,"llms":0.3836054752,"data-quality":0.1541095505}}
{"text":"We show that many standard mitigation techniques do not alleviate GVA, but find an exponential moving average (EMA) of iterates to be surprisingly effective at doing so.","meta":{"url":"http://arxiv.org/abs/2310.11428v1"},"cats":{"benchmark":0.5784068392,"new-dataset":0.0058826264,"data-annotation":0.5066989041,"dev-research":0.1573030233,"llms":0.4868628816,"data-quality":0.0649848709}}
{"text":"We illustrate the generality of this phenomenon by showing the existence of GVA and its amelioration by EMA in both continuous control and autoregressive language generation.","meta":{"url":"http://arxiv.org/abs/2310.11428v1"},"cats":{"benchmark":0.2013910125,"new-dataset":0.0136406123,"data-annotation":0.5157726553,"dev-research":0.1932380171,"llms":0.5088119354,"data-quality":0.1254695001}}
{"text":"Finally, we provide theoretical vignettes that highlight the benefits of EMA in alleviating GVA and shed light on the extent to which classical convex models can help in understanding the benefits of iterate averaging in deep learning.","meta":{"url":"http://arxiv.org/abs/2310.11428v1"},"cats":{"benchmark":0.4299141143,"new-dataset":0.0065451122,"data-annotation":0.5251747278,"dev-research":0.1150499528,"llms":0.446256015,"data-quality":0.0968829352}}
{"text":"All-around, real-time navigation and sensing across the water environments by miniature soft robotics are promising, for their merits of small size, high agility and good compliance to the unstructured surroundings.","meta":{"url":"http://arxiv.org/abs/2310.11426v1"},"cats":{"benchmark":0.288759819,"new-dataset":0.0252477478,"data-annotation":0.4996570181,"dev-research":0.1514635525,"llms":0.5207036508,"data-quality":0.0573135814}}
{"text":"In this paper, we propose and demonstrate a mantas-like soft aquatic robot which propels itself by flapping-fins using rolled dielectric elastomer actuators (DEAs) with bending motions.","meta":{"url":"http://arxiv.org/abs/2310.11426v1"},"cats":{"benchmark":0.2515285012,"new-dataset":0.0789821785,"data-annotation":0.5063034993,"dev-research":0.1985142528,"llms":0.5428213341,"data-quality":0.0854168804}}
{"text":"This robot exhibits fast-moving capabilities of swimming at 57mm/s or 1.25 body length per second (BL/s), skating on water surface at 64 mm/s (1.36 BL/s) and vertical ascending at 38mm/s (0.82 BL/s) at 1300 V, 17 Hz of the power supply.","meta":{"url":"http://arxiv.org/abs/2310.11426v1"},"cats":{"benchmark":0.313753509,"new-dataset":0.2266686041,"data-annotation":0.4971101424,"dev-research":0.151844447,"llms":0.500448242,"data-quality":0.0406628717}}
{"text":"These results show the feasibility of adopting rolled DEAs for mesoscale aquatic robots with high motion performance in various water-related scenarios.","meta":{"url":"http://arxiv.org/abs/2310.11426v1"},"cats":{"benchmark":0.3609143176,"new-dataset":0.0445085016,"data-annotation":0.474413479,"dev-research":0.1953212335,"llms":0.4783659925,"data-quality":0.0568944547}}
{"text":"We propose a novel unsupervised learning approach for non-rigid 3D shape matching.","meta":{"url":"http://arxiv.org/abs/2310.11420v1"},"cats":{"benchmark":0.3508155029,"new-dataset":0.0931909505,"data-annotation":0.4989900138,"dev-research":0.1069119132,"llms":0.4403054124,"data-quality":0.0873418373}}
{"text":"Our approach improves upon recent state-of-the art deep functional map methods and can be applied to a broad range of different challenging scenarios.","meta":{"url":"http://arxiv.org/abs/2310.11420v1"},"cats":{"benchmark":0.4360477028,"new-dataset":0.0686958806,"data-annotation":0.5110656882,"dev-research":0.1359873021,"llms":0.4611569092,"data-quality":0.1152837751}}
{"text":"Previous deep functional map methods mainly focus on feature extraction and aim exclusively at obtaining more expressive features for functional map computation.","meta":{"url":"http://arxiv.org/abs/2310.11420v1"},"cats":{"benchmark":0.3585642382,"new-dataset":0.0393461342,"data-annotation":0.5035070042,"dev-research":0.1804238102,"llms":0.4658679748,"data-quality":0.1260872243}}
{"text":"However, the importance of the functional map computation itself is often neglected and the relationship between the functional map and point-wise map is underexplored.","meta":{"url":"http://arxiv.org/abs/2310.11420v1"},"cats":{"benchmark":0.4569780343,"new-dataset":0.0134330069,"data-annotation":0.5188237694,"dev-research":0.1722276541,"llms":0.4756215548,"data-quality":0.0830620363}}
{"text":"In this paper, we systematically investigate the coupling relationship between the functional map from the functional map solver and the point-wise map based on feature similarity.","meta":{"url":"http://arxiv.org/abs/2310.11420v1"},"cats":{"benchmark":0.4426886329,"new-dataset":0.0250887792,"data-annotation":0.5074261058,"dev-research":0.2271007511,"llms":0.4034284098,"data-quality":0.1002380172}}
{"text":"To this end, we propose a self-adaptive functional map solver to adjust the functional map regularisation for different shape matching scenarios, together with a vertex-wise contrastive loss to obtain more discriminative features.","meta":{"url":"http://arxiv.org/abs/2310.11420v1"},"cats":{"benchmark":0.3942078017,"new-dataset":0.0393306599,"data-annotation":0.4979970411,"dev-research":0.1642212557,"llms":0.4102992302,"data-quality":0.1387999566}}
{"text":"Using different challenging datasets (including non-isometry, topological noise and partiality), we demonstrate that our method substantially outperforms previous state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2310.11420v1"},"cats":{"benchmark":0.6104145132,"new-dataset":0.3120467749,"data-annotation":0.5258329349,"dev-research":0.1499075582,"llms":0.4227688702,"data-quality":0.2480300786}}
{"text":"Existing visual change detectors usually adopt CNNs or Transformers for feature representation learning and focus on learning effective representation for the changed regions between images.","meta":{"url":"http://arxiv.org/abs/2310.11417v1"},"cats":{"benchmark":0.2294559113,"new-dataset":0.1359488701,"data-annotation":0.512867469,"dev-research":0.2957201834,"llms":0.5062197275,"data-quality":0.1870341128}}
{"text":"Although good performance can be obtained by enhancing the features of the change regions, however, these works are still limited mainly due to the ignorance of mining the unchanged background context information.","meta":{"url":"http://arxiv.org/abs/2310.11417v1"},"cats":{"benchmark":0.4077114989,"new-dataset":0.0562839805,"data-annotation":0.5062726368,"dev-research":0.2649074569,"llms":0.5128913627,"data-quality":0.1746710949}}
{"text":"It is known that one main challenge for change detection is how to obtain the consistent representations for two images involving different variations, such as spatial variation, sunlight intensity, etc.","meta":{"url":"http://arxiv.org/abs/2310.11417v1"},"cats":{"benchmark":0.4040883449,"new-dataset":0.1239587136,"data-annotation":0.5081735372,"dev-research":0.220292753,"llms":0.4112051041,"data-quality":0.161158932}}
{"text":"In this work, we demonstrate that carefully mining the common background information provides an important cue to learn the consistent representations for the two images which thus obviously facilitates the visual change detection problem.","meta":{"url":"http://arxiv.org/abs/2310.11417v1"},"cats":{"benchmark":0.2786151789,"new-dataset":0.2187713419,"data-annotation":0.5223193694,"dev-research":0.2705253113,"llms":0.4578514922,"data-quality":0.2713510635}}
{"text":"Based on this observation, we propose a novel Visual change Transformer (VcT) model for visual change detection problem.","meta":{"url":"http://arxiv.org/abs/2310.11417v1"},"cats":{"benchmark":0.2793178256,"new-dataset":0.0665785809,"data-annotation":0.5119379511,"dev-research":0.2869950506,"llms":0.4774083519,"data-quality":0.1752886269}}
{"text":"To be specific, a shared backbone network is first used to extract the feature maps for the given image pair.","meta":{"url":"http://arxiv.org/abs/2310.11417v1"},"cats":{"benchmark":0.2329544022,"new-dataset":0.0797625917,"data-annotation":0.4896259913,"dev-research":0.1500314488,"llms":0.4522625924,"data-quality":0.0757915853}}
{"text":"Then, each pixel of feature map is regarded as a graph node and the graph neural network is proposed to model the structured information for coarse change map prediction.","meta":{"url":"http://arxiv.org/abs/2310.11417v1"},"cats":{"benchmark":0.277062068,"new-dataset":0.1536407136,"data-annotation":0.5013751238,"dev-research":0.2359589949,"llms":0.3867562658,"data-quality":0.1416959253}}
{"text":"Top-K reliable tokens can be mined from the map and refined by using the clustering algorithm.","meta":{"url":"http://arxiv.org/abs/2310.11417v1"},"cats":{"benchmark":0.4685907393,"new-dataset":0.0867658368,"data-annotation":0.5169570497,"dev-research":0.1450685246,"llms":0.5442040339,"data-quality":0.2460066453}}
{"text":"Then, these reliable tokens are enhanced by first utilizing self/cross-attention schemes and then interacting with original features via an anchor-primary attention learning module.","meta":{"url":"http://arxiv.org/abs/2310.11417v1"},"cats":{"benchmark":0.3472739524,"new-dataset":0.0310188295,"data-annotation":0.5411784942,"dev-research":0.177923458,"llms":0.515710734,"data-quality":0.3432982276}}
{"text":"Finally, the prediction head is proposed to get a more accurate change map.","meta":{"url":"http://arxiv.org/abs/2310.11417v1"},"cats":{"benchmark":0.3462665947,"new-dataset":0.065515967,"data-annotation":0.4996013915,"dev-research":0.2462102988,"llms":0.4542454587,"data-quality":0.110907057}}
{"text":"Extensive experiments on multiple benchmark datasets validated the effectiveness of our proposed VcT model.","meta":{"url":"http://arxiv.org/abs/2310.11417v1"},"cats":{"benchmark":0.6947063017,"new-dataset":0.1016875988,"data-annotation":0.5044347689,"dev-research":0.157867633,"llms":0.4348767442,"data-quality":0.1812114976}}
{"text":"Penetration testing, an essential component of cybersecurity, allows organizations to proactively identify and remediate vulnerabilities in their systems, thus bolstering their defense mechanisms against potential cyberattacks.","meta":{"url":"http://arxiv.org/abs/2310.11409v1"},"cats":{"benchmark":0.2898026613,"new-dataset":0.0504891741,"data-annotation":0.5082193866,"dev-research":0.3395448263,"llms":0.5573757524,"data-quality":0.0987540029}}
{"text":"One recent advancement in the realm of penetration testing is the utilization of Language Models (LLMs).","meta":{"url":"http://arxiv.org/abs/2310.11409v1"},"cats":{"benchmark":0.2756937412,"new-dataset":0.0432696204,"data-annotation":0.5175968962,"dev-research":0.2004235972,"llms":0.721371508,"data-quality":0.1595820012}}
{"text":"We explore the intersection of LLMs and penetration testing to gain insight into their capabilities and challenges in the context of privilige escalation.","meta":{"url":"http://arxiv.org/abs/2310.11409v1"},"cats":{"benchmark":0.2570539742,"new-dataset":0.0137449338,"data-annotation":0.4901817295,"dev-research":0.1251279249,"llms":0.7613319283,"data-quality":0.0767023661}}
{"text":"We create an automated Linux privilege-escalation benchmark utilizing local virtual machines.","meta":{"url":"http://arxiv.org/abs/2310.11409v1"},"cats":{"benchmark":0.5245688163,"new-dataset":0.1078312904,"data-annotation":0.5088920053,"dev-research":0.2102040733,"llms":0.5491767739,"data-quality":0.0808332027}}
{"text":"We introduce an LLM-guided privilege-escalation tool designed for evaluating different LLMs and prompt strategies against our benchmark.","meta":{"url":"http://arxiv.org/abs/2310.11409v1"},"cats":{"benchmark":0.3847762632,"new-dataset":0.0164835865,"data-annotation":0.4907850605,"dev-research":0.199235457,"llms":0.7683172529,"data-quality":0.0816767595}}
{"text":"We analyze the impact of different prompt designs, the benefits of in-context learning, and the advantages of offering high-level guidance to LLMs.","meta":{"url":"http://arxiv.org/abs/2310.11409v1"},"cats":{"benchmark":0.1994884862,"new-dataset":0.0221415025,"data-annotation":0.5022325738,"dev-research":0.2338125393,"llms":0.7107222377,"data-quality":0.0775508436}}
{"text":"We discuss challenging areas for LLMs, including maintaining focus during testing, coping with errors, and finally comparing them with both stochastic parrots as well as with human hackers.","meta":{"url":"http://arxiv.org/abs/2310.11409v1"},"cats":{"benchmark":0.2808817706,"new-dataset":0.0744593101,"data-annotation":0.5107029442,"dev-research":0.2612802886,"llms":0.7676933373,"data-quality":0.1374237378}}
{"text":"Fairness holds a pivotal role in the realm of machine learning, particularly when it comes to addressing groups categorised by sensitive attributes, e.g., gender, race.","meta":{"url":"http://arxiv.org/abs/2310.11407v1"},"cats":{"benchmark":0.3711526951,"new-dataset":0.0176751375,"data-annotation":0.5194408637,"dev-research":0.2038324329,"llms":0.5136778258,"data-quality":0.2095773958}}
{"text":"Prevailing algorithms in fair learning predominantly hinge on accessibility or estimations of these sensitive attributes, at least in the training process.","meta":{"url":"http://arxiv.org/abs/2310.11407v1"},"cats":{"benchmark":0.3978416483,"new-dataset":0.0149984002,"data-annotation":0.5371761728,"dev-research":0.1307531587,"llms":0.4406922646,"data-quality":0.2294177787}}
{"text":"We design a single group-blind projection map that aligns the feature distributions of both groups in the source data, achieving (demographic) group parity, without requiring values of the protected attribute for individual samples in the computation of the map, as well as its use.","meta":{"url":"http://arxiv.org/abs/2310.11407v1"},"cats":{"benchmark":0.3753239093,"new-dataset":0.208419515,"data-annotation":0.4914642201,"dev-research":0.1850605699,"llms":0.467690669,"data-quality":0.1623821165}}
{"text":"Instead, our approach utilises the feature distributions of the privileged and unprivileged groups in a boarder population and the essential assumption that the source data are unbiased representation of the population.","meta":{"url":"http://arxiv.org/abs/2310.11407v1"},"cats":{"benchmark":0.2942230198,"new-dataset":0.1352699,"data-annotation":0.524398874,"dev-research":0.1735736532,"llms":0.4279051001,"data-quality":0.1385493489}}
{"text":"We present numerical results on synthetic data and real data.","meta":{"url":"http://arxiv.org/abs/2310.11407v1"},"cats":{"benchmark":0.5091718066,"new-dataset":0.5007246551,"data-annotation":0.5063261209,"dev-research":0.1456755657,"llms":0.3168320051,"data-quality":0.1402843259}}
{"text":"Network Function Virtualization (NFV) platforms consume significant energy, introducing high operational costs in edge and data centers.","meta":{"url":"http://arxiv.org/abs/2310.11406v1"},"cats":{"benchmark":0.358022726,"new-dataset":0.0324678548,"data-annotation":0.4935240938,"dev-research":0.2063026567,"llms":0.4700316338,"data-quality":0.0784389693}}
{"text":"This paper presents a novel framework called GreenNFV that optimizes resource usage for network function chains using deep reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2310.11406v1"},"cats":{"benchmark":0.2323711911,"new-dataset":0.1667497766,"data-annotation":0.4971076856,"dev-research":0.1492682725,"llms":0.4580542546,"data-quality":0.0722686912}}
{"text":"GreenNFV optimizes resource parameters such as CPU sharing ratio, CPU frequency scaling, last-level cache (LLC) allocation, DMA buffer size, and packet batch size.","meta":{"url":"http://arxiv.org/abs/2310.11406v1"},"cats":{"benchmark":0.4367315667,"new-dataset":0.0379396402,"data-annotation":0.4999615381,"dev-research":0.14925376,"llms":0.4736349125,"data-quality":0.0602638783}}
{"text":"GreenNFV learns the resource scheduling model from the benchmark experiments and takes Service Level Agreements (SLAs) into account to optimize resource usage models based on the different throughput and energy consumption requirements.","meta":{"url":"http://arxiv.org/abs/2310.11406v1"},"cats":{"benchmark":0.3807739754,"new-dataset":0.0928675952,"data-annotation":0.4889183398,"dev-research":0.1485539699,"llms":0.466265913,"data-quality":0.0704360091}}
{"text":"Our evaluation shows that GreenNFV models achieve high transfer throughput and low energy consumption while satisfying various SLA constraints.","meta":{"url":"http://arxiv.org/abs/2310.11406v1"},"cats":{"benchmark":0.3804694184,"new-dataset":0.0434875855,"data-annotation":0.4970188048,"dev-research":0.0867050608,"llms":0.4405869173,"data-quality":0.0560692884}}
{"text":"Specifically, GreenNFV with Throughput SLA can achieve $4.4\\times$ higher throughput and $1.5\\times$ better energy efficiency over the baseline settings, whereas GreenNFV with Energy SLA can achieve $3\\times$ higher throughput while reducing energy consumption by 50%.","meta":{"url":"http://arxiv.org/abs/2310.11406v1"},"cats":{"benchmark":0.5419504,"new-dataset":0.0137063154,"data-annotation":0.5018525686,"dev-research":0.1569005414,"llms":0.4642076221,"data-quality":0.079812745}}
{"text":"Query Performance Prediction (QPP) estimates the effectiveness of a search engine's results in response to a query without relevance judgments.","meta":{"url":"http://arxiv.org/abs/2310.11405v1"},"cats":{"benchmark":0.5367175581,"new-dataset":0.0121656574,"data-annotation":0.5190494782,"dev-research":0.1389948561,"llms":0.4731873448,"data-quality":0.138645082}}
{"text":"Traditionally, post-retrieval predictors have focused upon either the distribution of the retrieval scores, or the coherence of the top-ranked documents using traditional bag-of-words index representations.","meta":{"url":"http://arxiv.org/abs/2310.11405v1"},"cats":{"benchmark":0.4595895504,"new-dataset":0.0501531223,"data-annotation":0.5366841139,"dev-research":0.1293172574,"llms":0.4740901801,"data-quality":0.1478042914}}
{"text":"More recently, BERT-based models using dense embedded document representations have been used to create new predictors, but mostly applied to predict the performance of rankings created by BM25.","meta":{"url":"http://arxiv.org/abs/2310.11405v1"},"cats":{"benchmark":0.4796791762,"new-dataset":0.0737057796,"data-annotation":0.5592019782,"dev-research":0.1734953329,"llms":0.4864071681,"data-quality":0.1325615513}}
{"text":"Instead, we aim to predict the effectiveness of rankings created by single-representation dense retrieval models (ANCE & TCT-ColBERT).","meta":{"url":"http://arxiv.org/abs/2310.11405v1"},"cats":{"benchmark":0.4967953943,"new-dataset":0.0455858116,"data-annotation":0.5377003448,"dev-research":0.0953206975,"llms":0.5076516964,"data-quality":0.1740759836}}
{"text":"Therefore, we propose a number of variants of existing unsupervised coherence-based predictors that employ neural embedding representations.","meta":{"url":"http://arxiv.org/abs/2310.11405v1"},"cats":{"benchmark":0.2601590462,"new-dataset":0.0972167543,"data-annotation":0.524330573,"dev-research":0.1421232205,"llms":0.3860286648,"data-quality":0.1361685802}}
{"text":"In our experiments on the TREC Deep Learning Track datasets, we demonstrate improved accuracy upon dense retrieval (up to 92% compared to sparse variants for TCT-ColBERT and 188% for ANCE).","meta":{"url":"http://arxiv.org/abs/2310.11405v1"},"cats":{"benchmark":0.4362182531,"new-dataset":0.3124979813,"data-annotation":0.5110957008,"dev-research":0.1097487084,"llms":0.4898232501,"data-quality":0.209748443}}
{"text":"Going deeper, we select the most representative and best performing predictors to study the importance of differences among predictors and query types on query performance.","meta":{"url":"http://arxiv.org/abs/2310.11405v1"},"cats":{"benchmark":0.5550700896,"new-dataset":0.0163311205,"data-annotation":0.5089062169,"dev-research":0.2140150395,"llms":0.4687743641,"data-quality":0.0913817245}}
{"text":"Using existing distribution-based evaluation QPP measures and a particular type of linear mixed models, we find that query types further significantly influence query performance (and are up to 35% responsible for the unstable performance of QPP predictors), and that this sensitivity is unique to dense retrieval models.","meta":{"url":"http://arxiv.org/abs/2310.11405v1"},"cats":{"benchmark":0.5092750727,"new-dataset":0.0260998483,"data-annotation":0.4969164527,"dev-research":0.1096771862,"llms":0.4316749088,"data-quality":0.1310796684}}
{"text":"Our approach introduces a new setting for obtaining richer information on query differences in dense QPP that can explain potential unstable performance of existing predictors and outlines the unique characteristics of different query types on dense retrieval models.","meta":{"url":"http://arxiv.org/abs/2310.11405v1"},"cats":{"benchmark":0.4535483925,"new-dataset":0.0593884144,"data-annotation":0.4948768132,"dev-research":0.1092875771,"llms":0.4506185211,"data-quality":0.1206030844}}
{"text":"Fairness, especially group fairness, is an important consideration in the context of machine learning systems.","meta":{"url":"http://arxiv.org/abs/2310.11401v1"},"cats":{"benchmark":0.469311724,"new-dataset":0.005648002,"data-annotation":0.5081842313,"dev-research":0.217629226,"llms":0.4916159695,"data-quality":0.1607677999}}
{"text":"The most commonly adopted group fairness-enhancing techniques are in-processing methods that rely on a mixture of a fairness objective (e.g., demographic parity) and a task-specific objective (e.g., cross-entropy) during the training process.","meta":{"url":"http://arxiv.org/abs/2310.11401v1"},"cats":{"benchmark":0.5134796824,"new-dataset":0.0059447895,"data-annotation":0.5178286084,"dev-research":0.1636826897,"llms":0.5248005804,"data-quality":0.1169340973}}
{"text":"However, when data arrives in an online fashion -- one instance at a time -- optimizing such fairness objectives poses several challenges.","meta":{"url":"http://arxiv.org/abs/2310.11401v1"},"cats":{"benchmark":0.4399995179,"new-dataset":0.0115484996,"data-annotation":0.4752322991,"dev-research":0.1626956221,"llms":0.4835575856,"data-quality":0.1316833592}}
{"text":"In particular, group fairness objectives are defined using expectations of predictions across different demographic groups.","meta":{"url":"http://arxiv.org/abs/2310.11401v1"},"cats":{"benchmark":0.4666288948,"new-dataset":0.005045651,"data-annotation":0.5060965902,"dev-research":0.1821812703,"llms":0.4517946391,"data-quality":0.0863521967}}
{"text":"In the online setting, where the algorithm has access to a single instance at a time, estimating the group fairness objective requires additional storage and significantly more computation (e.g., forward/backward passes) than the task-specific objective at every time step.","meta":{"url":"http://arxiv.org/abs/2310.11401v1"},"cats":{"benchmark":0.5797855216,"new-dataset":0.0040780259,"data-annotation":0.5172830611,"dev-research":0.1267591067,"llms":0.4771287302,"data-quality":0.064006796}}
{"text":"In this paper, we propose Aranyani, an ensemble of oblique decision trees, to make fair decisions in online settings.","meta":{"url":"http://arxiv.org/abs/2310.11401v1"},"cats":{"benchmark":0.4496705827,"new-dataset":0.0649013111,"data-annotation":0.5214809747,"dev-research":0.195475518,"llms":0.4432569933,"data-quality":0.1332934157}}
{"text":"The hierarchical tree structure of Aranyani enables parameter isolation and allows us to efficiently compute the fairness gradients using aggregate statistics of previous decisions, eliminating the need for additional storage and forward/backward passes.","meta":{"url":"http://arxiv.org/abs/2310.11401v1"},"cats":{"benchmark":0.4758462453,"new-dataset":0.0179011313,"data-annotation":0.5068010602,"dev-research":0.1464903198,"llms":0.483489592,"data-quality":0.07619362}}
{"text":"We also present an efficient framework to train Aranyani and theoretically analyze several of its properties.","meta":{"url":"http://arxiv.org/abs/2310.11401v1"},"cats":{"benchmark":0.3590266658,"new-dataset":0.0616719169,"data-annotation":0.5376572489,"dev-research":0.1535360243,"llms":0.4691673168,"data-quality":0.0778076234}}
{"text":"We conduct empirical evaluations on 5 publicly available benchmarks (including vision and language datasets) to show that Aranyani achieves a better accuracy-fairness trade-off compared to baseline approaches.","meta":{"url":"http://arxiv.org/abs/2310.11401v1"},"cats":{"benchmark":0.6548150842,"new-dataset":0.121933598,"data-annotation":0.5331272067,"dev-research":0.2266990712,"llms":0.48830106,"data-quality":0.2256573867}}
{"text":"In the realm of deep learning, the self-attention mechanism has substantiated its pivotal role across a myriad of tasks, encompassing natural language processing and computer vision.","meta":{"url":"http://arxiv.org/abs/2310.11398v1"},"cats":{"benchmark":0.1533211776,"new-dataset":0.0788270214,"data-annotation":0.5408117962,"dev-research":0.1772249703,"llms":0.5121377399,"data-quality":0.1643050739}}
{"text":"Despite achieving success across diverse applications, the traditional self-attention mechanism primarily leverages linear transformations for the computation of query, key, and value (QKV), which may not invariably be the optimal choice under specific circumstances.","meta":{"url":"http://arxiv.org/abs/2310.11398v1"},"cats":{"benchmark":0.2910707659,"new-dataset":0.0105689196,"data-annotation":0.516798956,"dev-research":0.1362083394,"llms":0.4787651317,"data-quality":0.0873304486}}
{"text":"This paper probes into a novel methodology for QKV computation-implementing a specially-designed neural network structure for the calculation.","meta":{"url":"http://arxiv.org/abs/2310.11398v1"},"cats":{"benchmark":0.4333999875,"new-dataset":0.0596671043,"data-annotation":0.535111932,"dev-research":0.1402348808,"llms":0.4101392382,"data-quality":0.0642327458}}
{"text":"Utilizing a modified Marian model, we conducted experiments on the IWSLT 2017 German-English translation task dataset and juxtaposed our method with the conventional approach.","meta":{"url":"http://arxiv.org/abs/2310.11398v1"},"cats":{"benchmark":0.4019120001,"new-dataset":0.2007979468,"data-annotation":0.5403511467,"dev-research":0.1471996915,"llms":0.5194653669,"data-quality":0.1907837545}}
{"text":"The experimental results unveil a significant enhancement in BLEU scores with our method.","meta":{"url":"http://arxiv.org/abs/2310.11398v1"},"cats":{"benchmark":0.6978056991,"new-dataset":0.0384857367,"data-annotation":0.5201711582,"dev-research":0.1194331125,"llms":0.4429001211,"data-quality":0.1040873022}}
{"text":"Furthermore, our approach also manifested superiority when training the Roberta model with the Wikitext-103 dataset, reflecting a notable reduction in model perplexity compared to its original counterpart.","meta":{"url":"http://arxiv.org/abs/2310.11398v1"},"cats":{"benchmark":0.3416690692,"new-dataset":0.0917995487,"data-annotation":0.5328436663,"dev-research":0.1199033232,"llms":0.4540384925,"data-quality":0.1655532936}}
{"text":"These experimental outcomes not only validate the efficacy of our method but also reveal the immense potential in optimizing the self-attention mechanism through neural network-based QKV computation, paving the way for future research and practical applications.","meta":{"url":"http://arxiv.org/abs/2310.11398v1"},"cats":{"benchmark":0.3114576181,"new-dataset":0.0185903427,"data-annotation":0.5528160676,"dev-research":0.1311610443,"llms":0.4581943218,"data-quality":0.0937177424}}
{"text":"The source code and implementation details for our proposed method can be accessed at https://github.com/ocislyjrti/NeuralAttention.","meta":{"url":"http://arxiv.org/abs/2310.11398v1"},"cats":{"benchmark":0.4180376511,"new-dataset":0.0372823894,"data-annotation":0.5631202375,"dev-research":0.129768103,"llms":0.4600798921,"data-quality":0.1893716574}}
{"text":"Large Language Models (LLMs) are powerful tools for natural language processing, enabling novel applications and user experiences.","meta":{"url":"http://arxiv.org/abs/2310.11397v1"},"cats":{"benchmark":0.2166870743,"new-dataset":0.0828395931,"data-annotation":0.5221276935,"dev-research":0.1381507416,"llms":0.7396066238,"data-quality":0.1343277006}}
{"text":"However, to achieve optimal performance, LLMs often require adaptation with private data, which poses privacy and security challenges.","meta":{"url":"http://arxiv.org/abs/2310.11397v1"},"cats":{"benchmark":0.2813706686,"new-dataset":0.0094072344,"data-annotation":0.4679775574,"dev-research":0.103250443,"llms":0.7411552826,"data-quality":0.0875226339}}
{"text":"Several techniques have been proposed to adapt LLMs with private data, such as Low-Rank Adaptation (LoRA), Soft Prompt Tuning (SPT), and In-Context Learning (ICL), but their comparative privacy and security properties have not been systematically investigated.","meta":{"url":"http://arxiv.org/abs/2310.11397v1"},"cats":{"benchmark":0.268963068,"new-dataset":0.0279709156,"data-annotation":0.4915140543,"dev-research":0.0839397578,"llms":0.7108472695,"data-quality":0.1441629457}}
{"text":"In this work, we fill this gap by evaluating the robustness of LoRA, SPT, and ICL against three types of well-established attacks: membership inference, which exposes data leakage (privacy); backdoor, which injects malicious behavior (security); and model stealing, which can violate intellectual property (privacy and security).","meta":{"url":"http://arxiv.org/abs/2310.11397v1"},"cats":{"benchmark":0.3279550496,"new-dataset":0.0751189565,"data-annotation":0.5189299338,"dev-research":0.200356502,"llms":0.5827932917,"data-quality":0.2261833224}}
{"text":"Our results show that there is no silver bullet for privacy and security in LLM adaptation and each technique has different strengths and weaknesses.","meta":{"url":"http://arxiv.org/abs/2310.11397v1"},"cats":{"benchmark":0.2982880887,"new-dataset":0.0100392223,"data-annotation":0.4934530564,"dev-research":0.1054352994,"llms":0.7519457886,"data-quality":0.1259756083}}
{"text":"Automatic image captioning is a promising technique for conveying visual information using natural language.","meta":{"url":"http://arxiv.org/abs/2310.11392v1"},"cats":{"benchmark":0.2190722368,"new-dataset":0.1598335611,"data-annotation":0.5304052061,"dev-research":0.264075632,"llms":0.497736673,"data-quality":0.2647920027}}
{"text":"It can benefit various tasks in satellite remote sensing, such as environmental monitoring, resource management, disaster management, etc.","meta":{"url":"http://arxiv.org/abs/2310.11392v1"},"cats":{"benchmark":0.3005834176,"new-dataset":0.0257249913,"data-annotation":0.4743245301,"dev-research":0.2179075007,"llms":0.5324238756,"data-quality":0.0578520488}}
{"text":"However, one of the main challenges in this domain is the lack of large-scale image-caption datasets, as they require a lot of human expertise and effort to create.","meta":{"url":"http://arxiv.org/abs/2310.11392v1"},"cats":{"benchmark":0.197502092,"new-dataset":0.4953635446,"data-annotation":0.513879624,"dev-research":0.2046069403,"llms":0.5547305004,"data-quality":0.1675555646}}
{"text":"Recent research on large language models (LLMs) has demonstrated their impressive performance in natural language understanding and generation tasks.","meta":{"url":"http://arxiv.org/abs/2310.11392v1"},"cats":{"benchmark":0.2306907103,"new-dataset":0.1525913021,"data-annotation":0.5448537358,"dev-research":0.1653007154,"llms":0.7085345817,"data-quality":0.1337680656}}
{"text":"Nonetheless, most of them cannot handle images (GPT-3.5, Falcon, Claude, etc.), while conventional captioning models pre-trained on general ground-view images often fail to produce detailed and accurate captions for aerial images (BLIP, GIT, CM3, CM3Leon, etc.).","meta":{"url":"http://arxiv.org/abs/2310.11392v1"},"cats":{"benchmark":0.2410425157,"new-dataset":0.0722378366,"data-annotation":0.5300004345,"dev-research":0.1479774313,"llms":0.5372754015,"data-quality":0.2319775329}}
{"text":"To address this problem, we propose a novel approach: Automatic Remote Sensing Image Captioning (ARSIC) to automatically collect captions for remote sensing images by guiding LLMs to describe their object annotations.","meta":{"url":"http://arxiv.org/abs/2310.11392v1"},"cats":{"benchmark":0.2102021535,"new-dataset":0.4040324748,"data-annotation":0.5296000932,"dev-research":0.1802723755,"llms":0.6343546225,"data-quality":0.3667588939}}
{"text":"We also present a benchmark model that adapts the pre-trained generative image2text model (GIT) to generate high-quality captions for remote-sensing images.","meta":{"url":"http://arxiv.org/abs/2310.11392v1"},"cats":{"benchmark":0.2945609798,"new-dataset":0.5060968374,"data-annotation":0.5336382407,"dev-research":0.1586608187,"llms":0.5372709392,"data-quality":0.227904606}}
{"text":"Our evaluation demonstrates the effectiveness of our approach for collecting captions for remote sensing images.","meta":{"url":"http://arxiv.org/abs/2310.11392v1"},"cats":{"benchmark":0.3421498474,"new-dataset":0.5069901331,"data-annotation":0.5307640389,"dev-research":0.1634413541,"llms":0.5378657126,"data-quality":0.2899815541}}
{"text":"We tackle the problem of estimating the Value-at-Risk (VaR) and the Conditional Value-at-Risk (CVaR) of the infinite-horizon discounted cost within a Markov cost process.","meta":{"url":"http://arxiv.org/abs/2310.11389v1"},"cats":{"benchmark":0.422740918,"new-dataset":0.1179566977,"data-annotation":0.5350123837,"dev-research":0.1629594741,"llms":0.3953145534,"data-quality":0.0857803793}}
{"text":"First, we derive a minimax lower bound of $\\Omega(1/\\sqrt{n})$ that holds both in an expected and in a probabilistic sense.","meta":{"url":"http://arxiv.org/abs/2310.11389v1"},"cats":{"benchmark":0.4212582488,"new-dataset":0.0299144952,"data-annotation":0.5438356187,"dev-research":0.1334336933,"llms":0.4943930739,"data-quality":0.0897765208}}
{"text":"Then, using a finite-horizon truncation scheme, we derive an upper bound for the error in CVaR estimation, which matches our lower bound up to constant factors.","meta":{"url":"http://arxiv.org/abs/2310.11389v1"},"cats":{"benchmark":0.6044436944,"new-dataset":0.0232385188,"data-annotation":0.5313098836,"dev-research":0.1193100249,"llms":0.3250503983,"data-quality":0.1579048869}}
{"text":"Finally, we discuss an extension of our estimation scheme that covers more general risk measures satisfying a certain continuity criterion, e.g., spectral risk measures, utility-based shortfall risk.","meta":{"url":"http://arxiv.org/abs/2310.11389v1"},"cats":{"benchmark":0.4960036913,"new-dataset":0.0370763024,"data-annotation":0.5369029141,"dev-research":0.1647489444,"llms":0.3451261626,"data-quality":0.1280490591}}
{"text":"To the best of our knowledge, our work is the first to provide lower and upper bounds on the estimation error for any risk measure within Markovian settings.","meta":{"url":"http://arxiv.org/abs/2310.11389v1"},"cats":{"benchmark":0.5348737194,"new-dataset":0.0442039594,"data-annotation":0.5500759076,"dev-research":0.2090681429,"llms":0.39352351,"data-quality":0.1571413348}}
{"text":"We remark that our lower bounds also extend to the infinite-horizon discounted costs' mean.","meta":{"url":"http://arxiv.org/abs/2310.11389v1"},"cats":{"benchmark":0.4152829581,"new-dataset":0.0380502739,"data-annotation":0.5414147216,"dev-research":0.1458912058,"llms":0.4104927043,"data-quality":0.0715723508}}
{"text":"Even in that case, our result $\\Omega(1/\\sqrt{n}) $ improves upon the existing result $\\Omega(1/n)$[13].","meta":{"url":"http://arxiv.org/abs/2310.11389v1"},"cats":{"benchmark":0.5025170365,"new-dataset":0.0167368406,"data-annotation":0.5104229466,"dev-research":0.2035269397,"llms":0.5109641354,"data-quality":0.12343009}}
{"text":"With momentum increasing in the use of social robots as long-term assistive and collaborative partners, humans developing social bonds with these artificial agents appears to be inevitable.","meta":{"url":"http://arxiv.org/abs/2310.11386v1"},"cats":{"benchmark":0.1858569493,"new-dataset":0.02094254,"data-annotation":0.5141288512,"dev-research":0.2271650196,"llms":0.4940561096,"data-quality":0.0535643404}}
{"text":"In human-human dyads, social bonding plays a powerful role in regulating behaviours, emotions, and even health.","meta":{"url":"http://arxiv.org/abs/2310.11386v1"},"cats":{"benchmark":0.2670750172,"new-dataset":0.0354958094,"data-annotation":0.4820726551,"dev-research":0.2718217608,"llms":0.5134088027,"data-quality":0.0745650178}}
{"text":"If this is to extend to human-robot dyads, the phenomenology of such relationships (including their emergence and stability) must be better understood.","meta":{"url":"http://arxiv.org/abs/2310.11386v1"},"cats":{"benchmark":0.1820361667,"new-dataset":0.0744602708,"data-annotation":0.5123254291,"dev-research":0.2230841708,"llms":0.500995019,"data-quality":0.0664969587}}
{"text":"In this paper, we discuss potential approaches towards operationalizing the phenomenon of social bonding between human-robot dyads.","meta":{"url":"http://arxiv.org/abs/2310.11386v1"},"cats":{"benchmark":0.2014632362,"new-dataset":0.0688859666,"data-annotation":0.5002818339,"dev-research":0.2709094038,"llms":0.5226891922,"data-quality":0.0893191958}}
{"text":"We will discuss a number of biobehavioural proxies of social bonding, moving away from existing approaches that use subjective, psychological measures, and instead grounding our approach in some of the evolutionary, neurobiological and physiological correlates of social bond formation in natural systems: (a) reductions in physiological stress (the ''social buffering'' phenomenon), (b) narrowing of spatial proximity between dyads, and (c) inter-dyad behavioural synchrony.","meta":{"url":"http://arxiv.org/abs/2310.11386v1"},"cats":{"benchmark":0.3246234198,"new-dataset":0.0634609617,"data-annotation":0.490328687,"dev-research":0.2541745186,"llms":0.4699083134,"data-quality":0.1027380721}}
{"text":"We provide relevant evolutionary support for each proposed component, with suggestions and considerations for how they can be recorded in (real-time) human-robot interaction scenarios.","meta":{"url":"http://arxiv.org/abs/2310.11386v1"},"cats":{"benchmark":0.2231057088,"new-dataset":0.354822282,"data-annotation":0.514820361,"dev-research":0.2471306392,"llms":0.4534579732,"data-quality":0.0676549897}}
{"text":"With this, we aim to inspire more robust operationalisation of ''social bonding'' between human and artificial (robotic) agents.","meta":{"url":"http://arxiv.org/abs/2310.11386v1"},"cats":{"benchmark":0.1920573085,"new-dataset":0.0677426586,"data-annotation":0.5189180774,"dev-research":0.2255848393,"llms":0.4975622864,"data-quality":0.0820727593}}
{"text":"Brain aging is a regional phenomenon, a facet that remains relatively under-explored within the realm of brain age prediction research using machine learning methods.","meta":{"url":"http://arxiv.org/abs/2310.11385v1"},"cats":{"benchmark":0.3439083496,"new-dataset":0.0238240799,"data-annotation":0.5173316756,"dev-research":0.291813763,"llms":0.3847456807,"data-quality":0.1527570321}}
{"text":"Voxel-level predictions can provide localized brain age estimates that can provide granular insights into the regional aging processes.","meta":{"url":"http://arxiv.org/abs/2310.11385v1"},"cats":{"benchmark":0.381837548,"new-dataset":0.0746697688,"data-annotation":0.5021110234,"dev-research":0.2317769571,"llms":0.4107335274,"data-quality":0.1114468395}}
{"text":"This is essential to understand the differences in aging trajectories in healthy versus diseased subjects.","meta":{"url":"http://arxiv.org/abs/2310.11385v1"},"cats":{"benchmark":0.4263401755,"new-dataset":0.012842091,"data-annotation":0.4977171994,"dev-research":0.2459835416,"llms":0.4505333437,"data-quality":0.0594057355}}
{"text":"In this work, a deep learning-based multitask model is proposed for voxel-level brain age prediction from T1-weighted magnetic resonance images.","meta":{"url":"http://arxiv.org/abs/2310.11385v1"},"cats":{"benchmark":0.339644995,"new-dataset":0.0848819309,"data-annotation":0.5080708183,"dev-research":0.1566504426,"llms":0.4411626925,"data-quality":0.0937537358}}
{"text":"The proposed model outperforms the models existing in the literature and yields valuable clinical insights when applied to both healthy and diseased populations.","meta":{"url":"http://arxiv.org/abs/2310.11385v1"},"cats":{"benchmark":0.527206102,"new-dataset":0.0100441304,"data-annotation":0.492776169,"dev-research":0.207995578,"llms":0.4020579982,"data-quality":0.0716774083}}
{"text":"Regional analysis is performed on the voxel-level brain age predictions to understand aging trajectories of known anatomical regions in the brain and show that there exist disparities in regional aging trajectories of healthy subjects compared to ones with underlying neurological disorders such as Dementia and more specifically, Alzheimer's disease.","meta":{"url":"http://arxiv.org/abs/2310.11385v1"},"cats":{"benchmark":0.4424453937,"new-dataset":0.0371602917,"data-annotation":0.5066817794,"dev-research":0.2435222749,"llms":0.416546595,"data-quality":0.1113851849}}
{"text":"Our code is available at https://github.com/nehagianchandani/Voxel-level-brain-age-prediction.","meta":{"url":"http://arxiv.org/abs/2310.11385v1"},"cats":{"benchmark":0.3008309894,"new-dataset":0.3467279826,"data-annotation":0.5273602922,"dev-research":0.2006073482,"llms":0.4035093385,"data-quality":0.0945892984}}
{"text":"Voice-based interfaces rely on a wake-up word mechanism to initiate communication with devices.","meta":{"url":"http://arxiv.org/abs/2310.11379v1"},"cats":{"benchmark":0.1852325886,"new-dataset":0.0277369113,"data-annotation":0.5179273366,"dev-research":0.2073512124,"llms":0.5525012354,"data-quality":0.1094549386}}
{"text":"However, achieving a robust, energy-efficient, and fast detection remains a challenge.","meta":{"url":"http://arxiv.org/abs/2310.11379v1"},"cats":{"benchmark":0.3761633099,"new-dataset":0.0396435022,"data-annotation":0.5086588267,"dev-research":0.147842797,"llms":0.4859095609,"data-quality":0.2067793172}}
{"text":"This paper addresses these real production needs by enhancing data with temporal alignments and using detection based on two phases with multi-resolution.","meta":{"url":"http://arxiv.org/abs/2310.11379v1"},"cats":{"benchmark":0.3132166319,"new-dataset":0.6853697982,"data-annotation":0.4723417066,"dev-research":0.2379765607,"llms":0.4507107741,"data-quality":0.245490465}}
{"text":"It employs two models: a lightweight on-device model for real-time processing of the audio stream and a verification model on the server-side, which is an ensemble of heterogeneous architectures that refine detection.","meta":{"url":"http://arxiv.org/abs/2310.11379v1"},"cats":{"benchmark":0.3814589651,"new-dataset":0.0392280402,"data-annotation":0.4960226911,"dev-research":0.1908656454,"llms":0.5181191862,"data-quality":0.131012791}}
{"text":"This scheme allows the optimization of two operating points.","meta":{"url":"http://arxiv.org/abs/2310.11379v1"},"cats":{"benchmark":0.5647512954,"new-dataset":0.0018759476,"data-annotation":0.5069586055,"dev-research":0.1588517045,"llms":0.3899341674,"data-quality":0.0495750158}}
{"text":"To protect privacy, audio features are sent to the cloud instead of raw audio.","meta":{"url":"http://arxiv.org/abs/2310.11379v1"},"cats":{"benchmark":0.2119766127,"new-dataset":0.0741419997,"data-annotation":0.4764211785,"dev-research":0.2015498486,"llms":0.5212439655,"data-quality":0.1350895863}}
{"text":"The study investigated different parametric configurations for feature extraction to select one for on-device detection and another for the verification model.","meta":{"url":"http://arxiv.org/abs/2310.11379v1"},"cats":{"benchmark":0.4205918903,"new-dataset":0.0287201228,"data-annotation":0.5045228097,"dev-research":0.2077898269,"llms":0.4521435995,"data-quality":0.1432240769}}
{"text":"Furthermore, thirteen different audio classifiers were compared in terms of performance and inference time.","meta":{"url":"http://arxiv.org/abs/2310.11379v1"},"cats":{"benchmark":0.5422015658,"new-dataset":0.0504980703,"data-annotation":0.5393211735,"dev-research":0.163273134,"llms":0.4472907121,"data-quality":0.2741886271}}
{"text":"The proposed ensemble outperforms our stronger classifier in every noise condition.","meta":{"url":"http://arxiv.org/abs/2310.11379v1"},"cats":{"benchmark":0.5064313714,"new-dataset":0.0941526603,"data-annotation":0.541064305,"dev-research":0.1806307743,"llms":0.4235805893,"data-quality":0.4002295618}}
{"text":"The densest subgraph of a large graph usually refers to some subgraph with the highest average degree, which has been extended to the family of $p$-means dense subgraph objectives by~\\citet{veldt2021generalized}.","meta":{"url":"http://arxiv.org/abs/2310.11377v1"},"cats":{"benchmark":0.4108521094,"new-dataset":0.098275583,"data-annotation":0.5111058428,"dev-research":0.1771640929,"llms":0.5110501587,"data-quality":0.1358209222}}
{"text":"The $p$-mean densest subgraph problem seeks a subgraph with the highest average $p$-th-power degree, whereas the standard densest subgraph problem seeks a subgraph with a simple highest average degree.","meta":{"url":"http://arxiv.org/abs/2310.11377v1"},"cats":{"benchmark":0.4883747055,"new-dataset":0.0200026773,"data-annotation":0.5169024433,"dev-research":0.1613237982,"llms":0.4996326497,"data-quality":0.1322594478}}
{"text":"It was shown that the standard peeling algorithm can perform arbitrarily poorly on generalized objective when $p>1$ but uncertain when $0<p<1$. In this paper, we are the first to show that a standard peeling algorithm can still yield $2^{1/p}$-approximation for the case $0<p < 1$. (Veldt 2021) proposed a new generalized peeling algorithm (GENPEEL), which for $p \\geq 1$ has an approximation guarantee ratio $(p+1)^{1/p}$, and time complexity $O(mn)$, where $m$ and $n$ denote the number of edges and nodes in graph respectively.","meta":{"url":"http://arxiv.org/abs/2310.11377v1"},"cats":{"benchmark":0.54804623,"new-dataset":0.0065755089,"data-annotation":0.5369385087,"dev-research":0.2170175339,"llms":0.4244721152,"data-quality":0.0989318491}}
{"text":"In terms of algorithmic contributions, we propose a new and faster generalized peeling algorithm (called GENPEEL++ in this paper), which for $p \\in [1, +\\infty)$ has an approximation guarantee ratio $(2(p+1))^{1/p}$, and time complexity $O(m(\\log n))$, where $m$ and $n$ denote the number of edges and nodes in graph, respectively.","meta":{"url":"http://arxiv.org/abs/2310.11377v1"},"cats":{"benchmark":0.5456602202,"new-dataset":0.0350163565,"data-annotation":0.5437382738,"dev-research":0.214807518,"llms":0.4276665141,"data-quality":0.07386148}}
{"text":"This approximation ratio converges to 1 as $p \\rightarrow \\infty$.","meta":{"url":"http://arxiv.org/abs/2310.11377v1"},"cats":{"benchmark":0.4250035872,"new-dataset":0.0136271663,"data-annotation":0.503604905,"dev-research":0.1917184407,"llms":0.4591788201,"data-quality":0.1170521912}}
{"text":"Large language models (LLMs) and their variants have shown extraordinary efficacy across numerous downstream natural language processing (NLP) tasks, which has presented a new vision for the development of NLP.","meta":{"url":"http://arxiv.org/abs/2310.11374v1"},"cats":{"benchmark":0.2177395334,"new-dataset":0.0370979866,"data-annotation":0.5136681663,"dev-research":0.1708545864,"llms":0.6633341902,"data-quality":0.1837971231}}
{"text":"Despite their remarkable performance in natural language generating (NLG), LLMs lack a distinct focus on the emotion understanding domain.","meta":{"url":"http://arxiv.org/abs/2310.11374v1"},"cats":{"benchmark":0.1865186278,"new-dataset":0.0664568574,"data-annotation":0.5306078983,"dev-research":0.1754443684,"llms":0.7417057686,"data-quality":0.2673727497}}
{"text":"As a result, using LLMs for emotion recognition may lead to suboptimal and inadequate precision.","meta":{"url":"http://arxiv.org/abs/2310.11374v1"},"cats":{"benchmark":0.3315431875,"new-dataset":0.0084584915,"data-annotation":0.5272384744,"dev-research":0.1502647034,"llms":0.7406372983,"data-quality":0.2221335343}}
{"text":"Another limitation of LLMs is that they are typical trained without leveraging multi-modal information.","meta":{"url":"http://arxiv.org/abs/2310.11374v1"},"cats":{"benchmark":0.1992787906,"new-dataset":0.0052426359,"data-annotation":0.5097722959,"dev-research":0.0781352765,"llms":0.7760436263,"data-quality":0.0969826245}}
{"text":"To overcome these limitations, we propose DialogueLLM, a context and emotion knowledge tuned LLM that is obtained by fine-tuning LLaMA models with 13,638 multi-modal (i.e., texts and videos) emotional dialogues.","meta":{"url":"http://arxiv.org/abs/2310.11374v1"},"cats":{"benchmark":0.2101392061,"new-dataset":0.2815944641,"data-annotation":0.515861797,"dev-research":0.1268023545,"llms":0.6844997206,"data-quality":0.0968419476}}
{"text":"The visual information is considered as the supplementary knowledge to construct high-quality instructions.","meta":{"url":"http://arxiv.org/abs/2310.11374v1"},"cats":{"benchmark":0.1722079527,"new-dataset":0.1061545243,"data-annotation":0.5153095591,"dev-research":0.392590876,"llms":0.5653188242,"data-quality":0.1081899063}}
{"text":"We offer a comprehensive evaluation of our proposed model on three benchmarking emotion recognition in conversations (ERC) datasets and compare the results against the SOTA baselines and other SOTA LLMs.","meta":{"url":"http://arxiv.org/abs/2310.11374v1"},"cats":{"benchmark":0.472475784,"new-dataset":0.4648380614,"data-annotation":0.5366066365,"dev-research":0.1699806886,"llms":0.5840578778,"data-quality":0.2193252606}}
{"text":"Additionally, DialogueLLM-7B can be easily trained using LoRA on a 40GB A100 GPU in 5 hours, facilitating reproducibility for other researchers.","meta":{"url":"http://arxiv.org/abs/2310.11374v1"},"cats":{"benchmark":0.2990437603,"new-dataset":0.1421221631,"data-annotation":0.5065139817,"dev-research":0.138655093,"llms":0.6937741855,"data-quality":0.0652182663}}
{"text":"Sharding is essential for improving blockchain scalability.","meta":{"url":"http://arxiv.org/abs/2310.11373v1"},"cats":{"benchmark":0.3911509049,"new-dataset":0.0138055061,"data-annotation":0.4843656315,"dev-research":0.2114873946,"llms":0.5638365249,"data-quality":0.0647539886}}
{"text":"Existing protocols overlook diverse adversarial attacks, limiting transaction throughput.","meta":{"url":"http://arxiv.org/abs/2310.11373v1"},"cats":{"benchmark":0.2821530031,"new-dataset":0.0410028145,"data-annotation":0.4987344724,"dev-research":0.167437696,"llms":0.5215397376,"data-quality":0.1095070912}}
{"text":"This paper presents Reticulum, a groundbreaking sharding protocol addressing this issue, boosting blockchain scalability.   ","meta":{"url":"http://arxiv.org/abs/2310.11373v1"},"cats":{"benchmark":0.3772637549,"new-dataset":0.0295201918,"data-annotation":0.4831663078,"dev-research":0.1790887605,"llms":0.5639850533,"data-quality":0.06437827}}
{"text":"Reticulum employs a two-phase approach, adapting transaction throughput based on runtime adversarial attacks.","meta":{"url":"http://arxiv.org/abs/2310.11373v1"},"cats":{"benchmark":0.2468969958,"new-dataset":0.0453262785,"data-annotation":0.515880874,"dev-research":0.1720824524,"llms":0.5502069356,"data-quality":0.1104687095}}
{"text":"It comprises \"control\" and \"process\" shards in two layers.","meta":{"url":"http://arxiv.org/abs/2310.11373v1"},"cats":{"benchmark":0.2243500852,"new-dataset":0.0318117427,"data-annotation":0.4668723698,"dev-research":0.1794407105,"llms":0.5420806986,"data-quality":0.049752426}}
{"text":"Process shards contain at least one trustworthy node, while control shards have a majority of trusted nodes.","meta":{"url":"http://arxiv.org/abs/2310.11373v1"},"cats":{"benchmark":0.3089943078,"new-dataset":0.0091072239,"data-annotation":0.4829933363,"dev-research":0.1667770711,"llms":0.6129894536,"data-quality":0.096739792}}
{"text":"In the first phase, transactions are written to blocks and voted on by nodes in process shards.","meta":{"url":"http://arxiv.org/abs/2310.11373v1"},"cats":{"benchmark":0.2268522628,"new-dataset":0.0366987354,"data-annotation":0.4775529221,"dev-research":0.205590634,"llms":0.5483731054,"data-quality":0.0760968781}}
{"text":"Unanimously accepted blocks are confirmed.","meta":{"url":"http://arxiv.org/abs/2310.11373v1"},"cats":{"benchmark":0.4001356483,"new-dataset":0.106879493,"data-annotation":0.4811523833,"dev-research":0.1896492167,"llms":0.5173470048,"data-quality":0.1816598805}}
{"text":"In the second phase, blocks without unanimous acceptance are voted on by control shards.","meta":{"url":"http://arxiv.org/abs/2310.11373v1"},"cats":{"benchmark":0.3821163355,"new-dataset":0.0081428116,"data-annotation":0.4759312115,"dev-research":0.1482381623,"llms":0.5606389319,"data-quality":0.1144172047}}
{"text":"Blocks are accepted if the majority votes in favor, eliminating first-phase opponents and silent voters.","meta":{"url":"http://arxiv.org/abs/2310.11373v1"},"cats":{"benchmark":0.4073765281,"new-dataset":0.0055949976,"data-annotation":0.4907847418,"dev-research":0.2125202635,"llms":0.5229995088,"data-quality":0.1367720889}}
{"text":"Reticulum uses unanimous voting in the first phase, involving fewer nodes, enabling more parallel process shards.","meta":{"url":"http://arxiv.org/abs/2310.11373v1"},"cats":{"benchmark":0.3842387728,"new-dataset":0.0087801549,"data-annotation":0.4996846587,"dev-research":0.1671360951,"llms":0.5955186824,"data-quality":0.0675860774}}
{"text":"Control shards finalize decisions and resolve disputes.   ","meta":{"url":"http://arxiv.org/abs/2310.11373v1"},"cats":{"benchmark":0.2503461276,"new-dataset":0.0587757198,"data-annotation":0.4568634244,"dev-research":0.2773490944,"llms":0.6310340626,"data-quality":0.0897150617}}
{"text":"Experiments confirm Reticulum's innovative design, providing high transaction throughput and robustness against various network attacks, outperforming existing sharding protocols for blockchain networks.","meta":{"url":"http://arxiv.org/abs/2310.11373v1"},"cats":{"benchmark":0.3315232249,"new-dataset":0.0408712,"data-annotation":0.4870246776,"dev-research":0.1792014423,"llms":0.597272981,"data-quality":0.0670629182}}
{"text":"Soft-bubble tactile sensors have the potential to capture dense contact and force information across a large contact surface.","meta":{"url":"http://arxiv.org/abs/2310.11372v1"},"cats":{"benchmark":0.2550556379,"new-dataset":0.0944458013,"data-annotation":0.5133291287,"dev-research":0.1577782561,"llms":0.5501250076,"data-quality":0.0675821686}}
{"text":"However, it is difficult to extract contact forces directly from observing the bubble surface because local contacts change the global surface shape significantly due to membrane mechanics and air pressure.","meta":{"url":"http://arxiv.org/abs/2310.11372v1"},"cats":{"benchmark":0.3158067569,"new-dataset":0.0471217526,"data-annotation":0.5261579387,"dev-research":0.1834613474,"llms":0.5041829365,"data-quality":0.0770788925}}
{"text":"This paper presents a model-based method of reconstructing dense contact forces from the bubble sensor's internal RGBD camera and air pressure sensor.","meta":{"url":"http://arxiv.org/abs/2310.11372v1"},"cats":{"benchmark":0.3020974692,"new-dataset":0.3640469886,"data-annotation":0.5099269027,"dev-research":0.214117882,"llms":0.4671869786,"data-quality":0.0990093356}}
{"text":"We present a finite element model of the force response of the bubble sensor that uses a linear plane stress approximation that only requires calibrating 3 variables.","meta":{"url":"http://arxiv.org/abs/2310.11372v1"},"cats":{"benchmark":0.4265768275,"new-dataset":0.0523532173,"data-annotation":0.5099295713,"dev-research":0.1679538663,"llms":0.4264812527,"data-quality":0.1102720483}}
{"text":"Our method is shown to reconstruct normal and shear forces significantly more accurately than the state-of-the-art, with comparable accuracy for detecting the contact patch, and with very little calibration data.","meta":{"url":"http://arxiv.org/abs/2310.11372v1"},"cats":{"benchmark":0.4780882651,"new-dataset":0.1210771427,"data-annotation":0.5304526375,"dev-research":0.1749001135,"llms":0.4787595372,"data-quality":0.0920274681}}
{"text":"AI recommender systems are sought for decision support by providing suggestions to operators responsible for making final decisions.","meta":{"url":"http://arxiv.org/abs/2310.11370v1"},"cats":{"benchmark":0.2914808475,"new-dataset":0.0174686593,"data-annotation":0.5130606789,"dev-research":0.384017818,"llms":0.4842992099,"data-quality":0.09963653}}
{"text":"However, these systems are typically considered black boxes, and are often presented without any context or insight into the underlying algorithm.","meta":{"url":"http://arxiv.org/abs/2310.11370v1"},"cats":{"benchmark":0.2738818995,"new-dataset":0.005108007,"data-annotation":0.5070672961,"dev-research":0.1889520161,"llms":0.4934321638,"data-quality":0.1389150495}}
{"text":"As a result, recommender systems can lead to miscalibrated user reliance and decreased situation awareness.","meta":{"url":"http://arxiv.org/abs/2310.11370v1"},"cats":{"benchmark":0.3349463711,"new-dataset":0.0039038739,"data-annotation":0.5203550549,"dev-research":0.3665491547,"llms":0.4787198472,"data-quality":0.1713122844}}
{"text":"Recent work has focused on improving the transparency of recommender systems in various ways such as improving the recommender's analysis and visualization of the figures of merit, providing explanations for the recommender's decision, as well as improving user training or calibrating user trust.","meta":{"url":"http://arxiv.org/abs/2310.11370v1"},"cats":{"benchmark":0.4036123433,"new-dataset":0.0234478082,"data-annotation":0.5240589392,"dev-research":0.2620716897,"llms":0.4800047269,"data-quality":0.155861604}}
{"text":"In this paper, we introduce an alternative transparency technique of structuring the order in which contextual information and the recommender's decision are shown to the human operator.","meta":{"url":"http://arxiv.org/abs/2310.11370v1"},"cats":{"benchmark":0.2911217127,"new-dataset":0.0140582421,"data-annotation":0.5041380026,"dev-research":0.2358511581,"llms":0.4916034646,"data-quality":0.135525773}}
{"text":"This technique is designed to improve the operator's situation awareness and therefore the shared situation awareness between the operator and the recommender system.","meta":{"url":"http://arxiv.org/abs/2310.11370v1"},"cats":{"benchmark":0.3337695624,"new-dataset":0.0161249882,"data-annotation":0.5120142188,"dev-research":0.3944670546,"llms":0.5141174378,"data-quality":0.0842601282}}
{"text":"This paper presents the results of a two-phase between-subjects study in which participants and a recommender system jointly make a high-stakes decision.","meta":{"url":"http://arxiv.org/abs/2310.11370v1"},"cats":{"benchmark":0.4494710502,"new-dataset":0.0099641451,"data-annotation":0.51403025,"dev-research":0.2277621469,"llms":0.4985165761,"data-quality":0.0668258973}}
{"text":"We varied the amount of contextual information the participant had, the assessment technique of the figures of merit, and the reliability of the recommender system.","meta":{"url":"http://arxiv.org/abs/2310.11370v1"},"cats":{"benchmark":0.4864923132,"new-dataset":0.0056751889,"data-annotation":0.5291387674,"dev-research":0.2076370704,"llms":0.5016478789,"data-quality":0.1433618745}}
{"text":"We found that providing contextual information upfront improves the team's shared situation awareness by improving the human decision maker's initial and final judgment, as well as their ability to discern the recommender's error boundary.","meta":{"url":"http://arxiv.org/abs/2310.11370v1"},"cats":{"benchmark":0.3242616262,"new-dataset":0.059087604,"data-annotation":0.5260631928,"dev-research":0.4705774555,"llms":0.538415666,"data-quality":0.1917081741}}
{"text":"Additionally, this technique accurately calibrated the human operator's trust in the recommender.","meta":{"url":"http://arxiv.org/abs/2310.11370v1"},"cats":{"benchmark":0.5019834837,"new-dataset":0.00460616,"data-annotation":0.5290966,"dev-research":0.2296542746,"llms":0.4724054897,"data-quality":0.1921133964}}
{"text":"This work proposes and validates a way to provide model-agnostic transparency into AI systems that can support the human decision maker and lead to improved team performance.","meta":{"url":"http://arxiv.org/abs/2310.11370v1"},"cats":{"benchmark":0.2393760156,"new-dataset":0.0243149915,"data-annotation":0.496431305,"dev-research":0.2869656223,"llms":0.4879585907,"data-quality":0.1376360436}}
{"text":"Recognizing vulnerability is crucial for understanding and implementing targeted support to empower individuals in need.","meta":{"url":"http://arxiv.org/abs/2310.11368v1"},"cats":{"benchmark":0.2322901925,"new-dataset":0.0259258942,"data-annotation":0.5020263752,"dev-research":0.3621792723,"llms":0.53237451,"data-quality":0.1445251577}}
{"text":"This is especially important at the European Court of Human Rights (ECtHR), where the court adapts Convention standards to meet actual individual needs and thus ensures effective human rights protection.","meta":{"url":"http://arxiv.org/abs/2310.11368v1"},"cats":{"benchmark":0.3497993099,"new-dataset":0.10850291,"data-annotation":0.4967085241,"dev-research":0.2495518718,"llms":0.5511850686,"data-quality":0.089394277}}
{"text":"However, the concept of vulnerability remains elusive at the ECtHR and no prior NLP research has dealt with it.","meta":{"url":"http://arxiv.org/abs/2310.11368v1"},"cats":{"benchmark":0.257684452,"new-dataset":0.0490253087,"data-annotation":0.5097277323,"dev-research":0.2615183779,"llms":0.5325784703,"data-quality":0.2746796942}}
{"text":"To enable future research in this area, we present VECHR, a novel expert-annotated multi-label dataset comprising of vulnerability type classification and explanation rationale.","meta":{"url":"http://arxiv.org/abs/2310.11368v1"},"cats":{"benchmark":0.2914362816,"new-dataset":0.7222532083,"data-annotation":0.5374326499,"dev-research":0.4051788974,"llms":0.5342743345,"data-quality":0.4363912861}}
{"text":"We benchmark the performance of state-of-the-art models on VECHR from both prediction and explainability perspectives.","meta":{"url":"http://arxiv.org/abs/2310.11368v1"},"cats":{"benchmark":0.4940716483,"new-dataset":0.028536861,"data-annotation":0.5424242784,"dev-research":0.1461644084,"llms":0.5421860656,"data-quality":0.0954580292}}
{"text":"Our results demonstrate the challenging nature of the task with lower prediction performance and limited agreement between models and experts.","meta":{"url":"http://arxiv.org/abs/2310.11368v1"},"cats":{"benchmark":0.4475883036,"new-dataset":0.0237140571,"data-annotation":0.5269757517,"dev-research":0.2378680139,"llms":0.3958426524,"data-quality":0.1498539797}}
{"text":"Further, we analyze the robustness of these models in dealing with out-of-domain (OOD) data and observe overall limited performance.","meta":{"url":"http://arxiv.org/abs/2310.11368v1"},"cats":{"benchmark":0.5117817388,"new-dataset":0.0737092792,"data-annotation":0.4891128933,"dev-research":0.1297196917,"llms":0.4209409327,"data-quality":0.1995482956}}
{"text":"Our dataset poses unique challenges offering significant room for improvement regarding performance, explainability, and robustness.","meta":{"url":"http://arxiv.org/abs/2310.11368v1"},"cats":{"benchmark":0.4127800845,"new-dataset":0.530169131,"data-annotation":0.4986152306,"dev-research":0.3021887023,"llms":0.4167544827,"data-quality":0.3090031628}}
{"text":"We study the following characterization problem.","meta":{"url":"http://arxiv.org/abs/2310.11367v1"},"cats":{"benchmark":0.3870041992,"new-dataset":0.0672202701,"data-annotation":0.5312786683,"dev-research":0.1867702225,"llms":0.4638479584,"data-quality":0.2418925329}}
{"text":"Given a set $T$ of terminals and a $(2^{|T|}-2)$-dimensional vector $\\pi$ whose coordinates are indexed by proper subsets of $T$, is there a graph $G$ that contains $T$, such that for all subsets $\\emptyset\\subsetneq S\\subsetneq T$, $\\pi_S$ equals the value of the min-cut in $G$ separating $S$ from $T\\setminus S$?","meta":{"url":"http://arxiv.org/abs/2310.11367v1"},"cats":{"benchmark":0.3775460206,"new-dataset":0.0799798272,"data-annotation":0.5162233313,"dev-research":0.1765016814,"llms":0.4731425754,"data-quality":0.1231224585}}
{"text":"The only known necessary conditions are submodularity and a special class of linear inequalities given by Chaudhuri, Subrahmanyam, Wagner and Zaroliagis.   ","meta":{"url":"http://arxiv.org/abs/2310.11367v1"},"cats":{"benchmark":0.4185187968,"new-dataset":0.014426586,"data-annotation":0.5159287432,"dev-research":0.1618137066,"llms":0.3607749891,"data-quality":0.0980224843}}
{"text":"Our main result is a new class of linear inequalities concerning laminar families, that generalize all previous ones.","meta":{"url":"http://arxiv.org/abs/2310.11367v1"},"cats":{"benchmark":0.4300765671,"new-dataset":0.0851843051,"data-annotation":0.5373180002,"dev-research":0.1644981265,"llms":0.3742490182,"data-quality":0.1429626353}}
{"text":"Using our new class of inequalities, we can generalize Karger's approximate min-cut counting result to graphs with terminals.","meta":{"url":"http://arxiv.org/abs/2310.11367v1"},"cats":{"benchmark":0.4320078793,"new-dataset":0.1381524034,"data-annotation":0.5348224561,"dev-research":0.1681260256,"llms":0.4536748173,"data-quality":0.1286775629}}
{"text":"Invariance and equivariance to geometrical transformations have proven to be very useful inductive biases when training (convolutional) neural network models, especially in the low-data regime.","meta":{"url":"http://arxiv.org/abs/2310.11366v1"},"cats":{"benchmark":0.3267451182,"new-dataset":0.0165202133,"data-annotation":0.5407495372,"dev-research":0.1113220091,"llms":0.4263906313,"data-quality":0.1317166653}}
{"text":"Much work has focused on the case where the symmetry group employed is compact or abelian, or both.","meta":{"url":"http://arxiv.org/abs/2310.11366v1"},"cats":{"benchmark":0.2125277847,"new-dataset":0.0204131048,"data-annotation":0.5089258899,"dev-research":0.1510555946,"llms":0.5727925241,"data-quality":0.0431073537}}
{"text":"Recent work has explored enlarging the class of transformations used to the case of Lie groups, principally through the use of their Lie algebra, as well as the group exponential and logarithm maps.","meta":{"url":"http://arxiv.org/abs/2310.11366v1"},"cats":{"benchmark":0.2155975905,"new-dataset":0.0535063974,"data-annotation":0.5244754233,"dev-research":0.170791625,"llms":0.5078549494,"data-quality":0.057260462}}
{"text":"The applicability of such methods to larger transformation groups is limited by the fact that depending on the group of interest $G$, the exponential map may not be surjective.","meta":{"url":"http://arxiv.org/abs/2310.11366v1"},"cats":{"benchmark":0.3584451393,"new-dataset":0.0174526098,"data-annotation":0.5141594029,"dev-research":0.1426143192,"llms":0.4811971504,"data-quality":0.0414599908}}
{"text":"Further limitations are encountered when $G$ is neither compact nor abelian.","meta":{"url":"http://arxiv.org/abs/2310.11366v1"},"cats":{"benchmark":0.2451358987,"new-dataset":0.0105225002,"data-annotation":0.4791059135,"dev-research":0.1432199427,"llms":0.5556800208,"data-quality":0.0810009188}}
{"text":"Using the structure and geometry of Lie groups and their homogeneous spaces, we present a framework by which it is possible to work with such groups primarily focusing on the Lie groups $G = \\text{GL}^{+}(n, \\mathbb{R})$ and $G = \\text{SL}(n, \\mathbb{R})$, as well as their representation as affine transformations $\\mathbb{R}^{n} \\rtimes G$. Invariant integration as well as a global parametrization is realized by decomposing the `larger` groups into subgroups and submanifolds which can be handled individually.","meta":{"url":"http://arxiv.org/abs/2310.11366v1"},"cats":{"benchmark":0.2392639185,"new-dataset":0.0403103631,"data-annotation":0.5135006619,"dev-research":0.1652752687,"llms":0.4336583806,"data-quality":0.0494011142}}
{"text":"Under this framework, we show how convolution kernels can be parametrized to build models equivariant with respect to affine transformations.","meta":{"url":"http://arxiv.org/abs/2310.11366v1"},"cats":{"benchmark":0.2310323771,"new-dataset":0.0815784272,"data-annotation":0.5290310833,"dev-research":0.1289361103,"llms":0.3848559185,"data-quality":0.1290335726}}
{"text":"We evaluate the robustness and out-of-distribution generalisation capability of our model on the standard affine-invariant benchmark classification task, where we outperform all previous equivariant models as well as all Capsule Network proposals.","meta":{"url":"http://arxiv.org/abs/2310.11366v1"},"cats":{"benchmark":0.425010187,"new-dataset":0.0372619712,"data-annotation":0.5320060254,"dev-research":0.0997485894,"llms":0.3820246258,"data-quality":0.2827601837}}
{"text":"Noise reduction techniques based on deep learning have demonstrated impressive performance in enhancing the overall quality of recorded speech.","meta":{"url":"http://arxiv.org/abs/2310.11364v1"},"cats":{"benchmark":0.4433432497,"new-dataset":0.0932342021,"data-annotation":0.5089900327,"dev-research":0.2177417678,"llms":0.5011574372,"data-quality":0.3152527586}}
{"text":"While these approaches are highly performant, their application in audio engineering can be limited due to a number of factors.","meta":{"url":"http://arxiv.org/abs/2310.11364v1"},"cats":{"benchmark":0.4348256269,"new-dataset":0.0045681719,"data-annotation":0.5169826303,"dev-research":0.2005410164,"llms":0.4761662821,"data-quality":0.0829267113}}
{"text":"These include operation only on speech without support for music, lack of real-time capability, lack of interpretable control parameters, operation at lower sample rates, and a tendency to introduce artifacts.","meta":{"url":"http://arxiv.org/abs/2310.11364v1"},"cats":{"benchmark":0.2432115707,"new-dataset":0.0126790737,"data-annotation":0.5096274048,"dev-research":0.2370990886,"llms":0.5303341477,"data-quality":0.2013420469}}
{"text":"On the other hand, signal processing-based noise reduction algorithms offer fine-grained control and operation on a broad range of content, however, they often require manual operation to achieve the best results.","meta":{"url":"http://arxiv.org/abs/2310.11364v1"},"cats":{"benchmark":0.4422169627,"new-dataset":0.0080648296,"data-annotation":0.4889290771,"dev-research":0.2432974374,"llms":0.4665982824,"data-quality":0.1803040864}}
{"text":"To address the limitations of both approaches, in this work we introduce a method that leverages a signal processing-based denoiser that when combined with a neural network controller, enables fully automatic and high-fidelity noise reduction on both speech and music signals.","meta":{"url":"http://arxiv.org/abs/2310.11364v1"},"cats":{"benchmark":0.4823002059,"new-dataset":0.0391068849,"data-annotation":0.5111984716,"dev-research":0.2439361511,"llms":0.4092453668,"data-quality":0.3417435973}}
{"text":"We evaluate our proposed method with objective metrics and a perceptual listening test.","meta":{"url":"http://arxiv.org/abs/2310.11364v1"},"cats":{"benchmark":0.5830404534,"new-dataset":0.02947324,"data-annotation":0.549130502,"dev-research":0.1762341582,"llms":0.4702986189,"data-quality":0.228915909}}
{"text":"Our evaluation reveals that speech enhancement models can be extended to music, however training the model to remove only stationary noise is critical.","meta":{"url":"http://arxiv.org/abs/2310.11364v1"},"cats":{"benchmark":0.4502529027,"new-dataset":0.0197983493,"data-annotation":0.5297443404,"dev-research":0.1644030469,"llms":0.447827449,"data-quality":0.2640085083}}
{"text":"Furthermore, our proposed approach achieves performance on par with the deep learning models, while being significantly more efficient and introducing fewer artifacts in some cases.","meta":{"url":"http://arxiv.org/abs/2310.11364v1"},"cats":{"benchmark":0.399784453,"new-dataset":0.0398909412,"data-annotation":0.512321919,"dev-research":0.1723630578,"llms":0.4608523926,"data-quality":0.1675697573}}
{"text":"Listening examples are available online at https://tape.it/research/denoiser .","meta":{"url":"http://arxiv.org/abs/2310.11364v1"},"cats":{"benchmark":0.4002484282,"new-dataset":0.201046556,"data-annotation":0.5111083585,"dev-research":0.1929777759,"llms":0.5120236431,"data-quality":0.1785466542}}
{"text":"Differential Privacy (DP) has been tailored to address the unique challenges of text-to-text privatization.","meta":{"url":"http://arxiv.org/abs/2310.11363v1"},"cats":{"benchmark":0.2516153353,"new-dataset":0.0423030748,"data-annotation":0.451179264,"dev-research":0.179480334,"llms":0.5714760944,"data-quality":0.1958384204}}
{"text":"However, text-to-text privatization is known for degrading the performance of language models when trained on perturbed text.","meta":{"url":"http://arxiv.org/abs/2310.11363v1"},"cats":{"benchmark":0.3816508744,"new-dataset":0.012741425,"data-annotation":0.5352480288,"dev-research":0.2079002661,"llms":0.5389850159,"data-quality":0.3353553876}}
{"text":"Employing a series of interpretation techniques on the internal representations extracted from BERT trained on perturbed pre-text, we intend to disentangle at the linguistic level the distortion induced by differential privacy.","meta":{"url":"http://arxiv.org/abs/2310.11363v1"},"cats":{"benchmark":0.2150030974,"new-dataset":0.0309248424,"data-annotation":0.5379047892,"dev-research":0.1958770264,"llms":0.5018909304,"data-quality":0.3302105776}}
{"text":"Experimental results from a representational similarity analysis indicate that the overall similarity of internal representations is substantially reduced.","meta":{"url":"http://arxiv.org/abs/2310.11363v1"},"cats":{"benchmark":0.354397242,"new-dataset":0.0038589988,"data-annotation":0.5521579983,"dev-research":0.2080007678,"llms":0.4795762301,"data-quality":0.1783012793}}
{"text":"Using probing tasks to unpack this dissimilarity, we find evidence that text-to-text privatization affects the linguistic competence across several formalisms, encoding localized properties of words while falling short at encoding the contextual relationships between spans of words.","meta":{"url":"http://arxiv.org/abs/2310.11363v1"},"cats":{"benchmark":0.3104537299,"new-dataset":0.0173047281,"data-annotation":0.5107081824,"dev-research":0.2444684544,"llms":0.5706312518,"data-quality":0.2518993116}}
{"text":"Conventional neural machine translation (NMT) models typically use subwords and words as the basic units for model input and comprehension.","meta":{"url":"http://arxiv.org/abs/2310.11360v1"},"cats":{"benchmark":0.2584953428,"new-dataset":0.0246963018,"data-annotation":0.5151249912,"dev-research":0.1757971168,"llms":0.5521570728,"data-quality":0.1689093412}}
{"text":"However, complete words and phrases composed of several tokens are often the fundamental units for expressing semantics, referred to as semantic units.","meta":{"url":"http://arxiv.org/abs/2310.11360v1"},"cats":{"benchmark":0.3055447071,"new-dataset":0.0278872266,"data-annotation":0.5244783109,"dev-research":0.2539133569,"llms":0.5105735669,"data-quality":0.2982827549}}
{"text":"To address this issue, we propose a method Semantic Units for Machine Translation (SU4MT) which models the integral meanings of semantic units within a sentence, and then leverages them to provide a new perspective for understanding the sentence.","meta":{"url":"http://arxiv.org/abs/2310.11360v1"},"cats":{"benchmark":0.2789309933,"new-dataset":0.0850199098,"data-annotation":0.5223592098,"dev-research":0.2374335987,"llms":0.5425428788,"data-quality":0.1934353346}}
{"text":"Specifically, we first propose Word Pair Encoding (WPE), a phrase extraction method to help identify the boundaries of semantic units.","meta":{"url":"http://arxiv.org/abs/2310.11360v1"},"cats":{"benchmark":0.3915538285,"new-dataset":0.0920719869,"data-annotation":0.5317420081,"dev-research":0.1917527256,"llms":0.4888052648,"data-quality":0.271886796}}
{"text":"Next, we design an Attentive Semantic Fusion (ASF) layer to integrate the semantics of multiple subwords into a single vector: the semantic unit representation.","meta":{"url":"http://arxiv.org/abs/2310.11360v1"},"cats":{"benchmark":0.3318455361,"new-dataset":0.0865105118,"data-annotation":0.548217576,"dev-research":0.1883372027,"llms":0.4937547191,"data-quality":0.3005587779}}
{"text":"Lastly, the semantic-unit-level sentence representation is concatenated to the token-level one, and they are combined as the input of encoder.","meta":{"url":"http://arxiv.org/abs/2310.11360v1"},"cats":{"benchmark":0.2333527466,"new-dataset":0.051773433,"data-annotation":0.5189005001,"dev-research":0.1746508879,"llms":0.5582126015,"data-quality":0.1752517982}}
{"text":"Experimental results demonstrate that our method effectively models and leverages semantic-unit-level information and outperforms the strong baselines.","meta":{"url":"http://arxiv.org/abs/2310.11360v1"},"cats":{"benchmark":0.5500194816,"new-dataset":0.0237603958,"data-annotation":0.5267750771,"dev-research":0.2603020701,"llms":0.4886817658,"data-quality":0.3015733042}}
{"text":"The code is available at https://github.com/ictnlp/SU4MT.","meta":{"url":"http://arxiv.org/abs/2310.11360v1"},"cats":{"benchmark":0.3269488752,"new-dataset":0.2069111594,"data-annotation":0.5248648961,"dev-research":0.1370818929,"llms":0.4754704042,"data-quality":0.0732695006}}
{"text":"Benefits of learning by teaching (LbT) have been highlighted by previous studies from a pedagogical lens, as well as through computer-supported systems.","meta":{"url":"http://arxiv.org/abs/2310.11354v1"},"cats":{"benchmark":0.2552433598,"new-dataset":0.0076779289,"data-annotation":0.5003702873,"dev-research":0.1786737587,"llms":0.6111929109,"data-quality":0.064589365}}
{"text":"However, the challenges that university students face in technology-mediated LbT$\\unicode{x2013}$whether it be teaching oneself, teaching a peer, or teaching an agent$\\unicode{x2013}$are not well understood.","meta":{"url":"http://arxiv.org/abs/2310.11354v1"},"cats":{"benchmark":0.1546374996,"new-dataset":0.0575299352,"data-annotation":0.505632335,"dev-research":0.2471053529,"llms":0.6234802876,"data-quality":0.1237956477}}
{"text":"Furthermore, there is a gap in knowledge on the challenges that students encounter throughout the process of teaching (content selection, preparation, teaching, receiving and giving feedback, and reflection) despite its importance to the design of LbT platforms.","meta":{"url":"http://arxiv.org/abs/2310.11354v1"},"cats":{"benchmark":0.2341747332,"new-dataset":0.0128657204,"data-annotation":0.5006375541,"dev-research":0.2430131157,"llms":0.6129210928,"data-quality":0.0972761708}}
{"text":"Thus, we conducted a study with 24 university students where they taught content they had not fully grasped, without guidance, and participated in a semi-structured interview.","meta":{"url":"http://arxiv.org/abs/2310.11354v1"},"cats":{"benchmark":0.1993360987,"new-dataset":0.0932033303,"data-annotation":0.5208021824,"dev-research":0.2035483395,"llms":0.5855299597,"data-quality":0.0970804422}}
{"text":"Results demonstrate that participants encountered the following challenges: psychological barriers relating to self and others, and lack of know-how.","meta":{"url":"http://arxiv.org/abs/2310.11354v1"},"cats":{"benchmark":0.2057419622,"new-dataset":0.0141666962,"data-annotation":0.5168932265,"dev-research":0.2899619374,"llms":0.5202562894,"data-quality":0.1277081047}}
{"text":"Furthermore, we illuminate design implications required to overcome these challenges and benefit from LbT without requiring prior training in pedagogy.","meta":{"url":"http://arxiv.org/abs/2310.11354v1"},"cats":{"benchmark":0.1977714133,"new-dataset":0.0152812143,"data-annotation":0.4941754394,"dev-research":0.2489079224,"llms":0.6546849561,"data-quality":0.0855071376}}
{"text":"Detecting objects in 3D space using multiple cameras, known as Multi-Camera 3D Object Detection (MC3D-Det), has gained prominence with the advent of bird's-eye view (BEV) approaches.","meta":{"url":"http://arxiv.org/abs/2310.11346v1"},"cats":{"benchmark":0.2463546198,"new-dataset":0.140993797,"data-annotation":0.5151755075,"dev-research":0.1473572943,"llms":0.4843979798,"data-quality":0.0899509237}}
{"text":"However, these methods often struggle when faced with unfamiliar testing environments due to the lack of diverse training data encompassing various viewpoints and environments.","meta":{"url":"http://arxiv.org/abs/2310.11346v1"},"cats":{"benchmark":0.2744936304,"new-dataset":0.0246672212,"data-annotation":0.5166956856,"dev-research":0.2997348067,"llms":0.5159977952,"data-quality":0.2185461707}}
{"text":"To address this, we propose a novel method that aligns 3D detection with 2D camera plane results, ensuring consistent and accurate detections.","meta":{"url":"http://arxiv.org/abs/2310.11346v1"},"cats":{"benchmark":0.4431353596,"new-dataset":0.0836398152,"data-annotation":0.5117530882,"dev-research":0.1898614054,"llms":0.418788726,"data-quality":0.1986809391}}
{"text":"Our framework, anchored in perspective debiasing, helps the learning of features resilient to domain shifts.","meta":{"url":"http://arxiv.org/abs/2310.11346v1"},"cats":{"benchmark":0.3445087961,"new-dataset":0.0520001589,"data-annotation":0.5231401981,"dev-research":0.2617194283,"llms":0.4208704548,"data-quality":0.2824204838}}
{"text":"In our approach, we render diverse view maps from BEV features and rectify the perspective bias of these maps, leveraging implicit foreground volumes to bridge the camera and BEV planes.","meta":{"url":"http://arxiv.org/abs/2310.11346v1"},"cats":{"benchmark":0.3190290815,"new-dataset":0.171974922,"data-annotation":0.5106227202,"dev-research":0.1696702389,"llms":0.4450096742,"data-quality":0.0993768292}}
{"text":"This two-step process promotes the learning of perspective- and context-independent features, crucial for accurate object detection across varying viewpoints, camera parameters and environment conditions.","meta":{"url":"http://arxiv.org/abs/2310.11346v1"},"cats":{"benchmark":0.2400296666,"new-dataset":0.0486065435,"data-annotation":0.5194965046,"dev-research":0.1608637546,"llms":0.4308271475,"data-quality":0.1428305617}}
{"text":"Notably, our model-agnostic approach preserves the original network structure without incurring additional inference costs, facilitating seamless integration across various models and simplifying deployment.","meta":{"url":"http://arxiv.org/abs/2310.11346v1"},"cats":{"benchmark":0.3623794235,"new-dataset":0.0109596817,"data-annotation":0.4668821475,"dev-research":0.1776803093,"llms":0.5141724267,"data-quality":0.115287237}}
{"text":"Furthermore, we also show our approach achieves satisfactory results in real data when trained only with virtual datasets, eliminating the need for real scene annotations.","meta":{"url":"http://arxiv.org/abs/2310.11346v1"},"cats":{"benchmark":0.219633401,"new-dataset":0.6947317402,"data-annotation":0.5384220423,"dev-research":0.1747846892,"llms":0.4105976718,"data-quality":0.4377921237}}
{"text":"Experimental results on both Domain Generalization (DG) and Unsupervised Domain Adaptation (UDA) clearly demonstrate its effectiveness.","meta":{"url":"http://arxiv.org/abs/2310.11346v1"},"cats":{"benchmark":0.3842332193,"new-dataset":0.0123356249,"data-annotation":0.5022433799,"dev-research":0.1713562996,"llms":0.5511750216,"data-quality":0.196936972}}
{"text":"Our code will be released.","meta":{"url":"http://arxiv.org/abs/2310.11346v1"},"cats":{"benchmark":0.183668701,"new-dataset":0.6093266952,"data-annotation":0.5217005069,"dev-research":0.3905058738,"llms":0.5250856696,"data-quality":0.1502409874}}
{"text":"With the popularization of the internet, smartphones and social media, information is being spread quickly and easily way, which implies bigger traffic of information in the world, but there is a problem that is harming society with the dissemination of fake news.","meta":{"url":"http://arxiv.org/abs/2310.11344v1"},"cats":{"benchmark":0.2237323093,"new-dataset":0.0588976865,"data-annotation":0.5106755807,"dev-research":0.1932221715,"llms":0.4771691822,"data-quality":0.176702306}}
{"text":"With a bigger flow of information, some people are trying to disseminate deceptive information and fake news.","meta":{"url":"http://arxiv.org/abs/2310.11344v1"},"cats":{"benchmark":0.1756505394,"new-dataset":0.0262118306,"data-annotation":0.5077637597,"dev-research":0.2482173008,"llms":0.5146160388,"data-quality":0.1833157441}}
{"text":"The automatic detection of fake news is a challenging task because to obtain a good result is necessary to deal with linguistics problems, especially when we are dealing with languages that not have been comprehensively studied yet, besides that, some techniques can help to reach a good result when we are dealing with text data, although, the motivation of detecting this deceptive information it is in the fact that the people need to know which information is true and trustful and which one is not.","meta":{"url":"http://arxiv.org/abs/2310.11344v1"},"cats":{"benchmark":0.3094723392,"new-dataset":0.108788697,"data-annotation":0.5562806413,"dev-research":0.2266864438,"llms":0.51542423,"data-quality":0.5845222358}}
{"text":"In this work, we present the effect the pre-processing methods such as lemmatization and stemming have on fake news classification, for that we designed some classifier models applying different pre-processing techniques.","meta":{"url":"http://arxiv.org/abs/2310.11344v1"},"cats":{"benchmark":0.339302522,"new-dataset":0.0846784164,"data-annotation":0.5565697717,"dev-research":0.1984611582,"llms":0.4845156061,"data-quality":0.4421318415}}
{"text":"The results show that the pre-processing step is important to obtain betters results, the stemming and lemmatization techniques are interesting methods and need to be more studied to develop techniques focused on the Portuguese language so we can reach better results.","meta":{"url":"http://arxiv.org/abs/2310.11344v1"},"cats":{"benchmark":0.4101867338,"new-dataset":0.0701711897,"data-annotation":0.5343209231,"dev-research":0.215931707,"llms":0.5146396507,"data-quality":0.2304775183}}
{"text":"Artificial neural networks (ANNs) exhibit a narrow scope of expertise on stationary independent data.","meta":{"url":"http://arxiv.org/abs/2310.11341v1"},"cats":{"benchmark":0.3023423942,"new-dataset":0.0340178978,"data-annotation":0.5312020483,"dev-research":0.1674213032,"llms":0.3862428246,"data-quality":0.1316759679}}
{"text":"However, the data in the real world is continuous and dynamic, and ANNs must adapt to novel scenarios while also retaining the learned knowledge to become lifelong learners.","meta":{"url":"http://arxiv.org/abs/2310.11341v1"},"cats":{"benchmark":0.1913776152,"new-dataset":0.1179861625,"data-annotation":0.5044376586,"dev-research":0.2570611838,"llms":0.5021875014,"data-quality":0.1719530077}}
{"text":"The ability of humans to excel at these tasks can be attributed to multiple factors ranging from cognitive computational structures, cognitive biases, and the multi-memory systems in the brain.","meta":{"url":"http://arxiv.org/abs/2310.11341v1"},"cats":{"benchmark":0.3191794619,"new-dataset":0.0191054772,"data-annotation":0.5245857419,"dev-research":0.3018454481,"llms":0.4490404408,"data-quality":0.0526606452}}
{"text":"We incorporate key concepts from each of these to design a novel framework, Dual Cognitive Architecture (DUCA), which includes multiple sub-systems, implicit and explicit knowledge representation dichotomy, inductive bias, and a multi-memory system.","meta":{"url":"http://arxiv.org/abs/2310.11341v1"},"cats":{"benchmark":0.2298932819,"new-dataset":0.0312024231,"data-annotation":0.5028507176,"dev-research":0.1858473057,"llms":0.5160341671,"data-quality":0.0890320796}}
{"text":"The inductive bias learner within DUCA is instrumental in encoding shape information, effectively countering the tendency of ANNs to learn local textures.","meta":{"url":"http://arxiv.org/abs/2310.11341v1"},"cats":{"benchmark":0.2037117549,"new-dataset":0.0262496974,"data-annotation":0.5468761647,"dev-research":0.1631358201,"llms":0.512668663,"data-quality":0.2099421486}}
{"text":"Simultaneously, the inclusion of a semantic memory submodule facilitates the gradual consolidation of knowledge, replicating the dynamics observed in fast and slow learning systems, reminiscent of the principles underpinning the complementary learning system in human cognition.","meta":{"url":"http://arxiv.org/abs/2310.11341v1"},"cats":{"benchmark":0.1903190288,"new-dataset":0.0163178019,"data-annotation":0.4952622895,"dev-research":0.2096731825,"llms":0.5585976183,"data-quality":0.1125372024}}
{"text":"DUCA shows improvement across different settings and datasets, and it also exhibits reduced task recency bias, without the need for extra information.","meta":{"url":"http://arxiv.org/abs/2310.11341v1"},"cats":{"benchmark":0.4521634281,"new-dataset":0.0122044208,"data-annotation":0.5098179595,"dev-research":0.201078519,"llms":0.447176354,"data-quality":0.1215648469}}
{"text":"To further test the versatility of lifelong learning methods on a challenging distribution shift, we introduce a novel domain-incremental dataset DN4IL.","meta":{"url":"http://arxiv.org/abs/2310.11341v1"},"cats":{"benchmark":0.3307566935,"new-dataset":0.2625591487,"data-annotation":0.4950689066,"dev-research":0.1569427384,"llms":0.5175438007,"data-quality":0.1566209272}}
{"text":"In addition to improving performance on existing benchmarks, DUCA also demonstrates superior performance on this complex dataset.","meta":{"url":"http://arxiv.org/abs/2310.11341v1"},"cats":{"benchmark":0.6317860967,"new-dataset":0.3704842127,"data-annotation":0.5038534125,"dev-research":0.1442583093,"llms":0.4074262123,"data-quality":0.087756836}}
{"text":"Envisioned application areas for reinforcement learning (RL) include autonomous driving, precision agriculture, and finance, which all require RL agents to make decisions in the real world.","meta":{"url":"http://arxiv.org/abs/2310.11335v1"},"cats":{"benchmark":0.1831923107,"new-dataset":0.0716406107,"data-annotation":0.496922828,"dev-research":0.1393428903,"llms":0.4574764039,"data-quality":0.0696583403}}
{"text":"A significant challenge hindering the adoption of RL methods in these domains is the non-robustness of conventional algorithms.","meta":{"url":"http://arxiv.org/abs/2310.11335v1"},"cats":{"benchmark":0.6189931743,"new-dataset":0.0030719198,"data-annotation":0.5204625957,"dev-research":0.1700319701,"llms":0.3829046624,"data-quality":0.1704175602}}
{"text":"In this paper, we argue that a fundamental issue contributing to this lack of robustness lies in the focus on the expected value of the return as the sole \"correct\" optimization objective.","meta":{"url":"http://arxiv.org/abs/2310.11335v1"},"cats":{"benchmark":0.623321087,"new-dataset":0.0032178442,"data-annotation":0.5329588752,"dev-research":0.152038827,"llms":0.3473362527,"data-quality":0.2131300647}}
{"text":"The expected value is the average over the statistical ensemble of infinitely many trajectories.","meta":{"url":"http://arxiv.org/abs/2310.11335v1"},"cats":{"benchmark":0.326158494,"new-dataset":0.1084451713,"data-annotation":0.5227335919,"dev-research":0.0994891323,"llms":0.4201676793,"data-quality":0.0601386752}}
{"text":"For non-ergodic returns, this average differs from the average over a single but infinitely long trajectory.","meta":{"url":"http://arxiv.org/abs/2310.11335v1"},"cats":{"benchmark":0.4203941229,"new-dataset":0.0146443631,"data-annotation":0.5127006736,"dev-research":0.0944530198,"llms":0.4353746306,"data-quality":0.0470958499}}
{"text":"Consequently, optimizing the expected value can lead to policies that yield exceptionally high returns with probability zero but almost surely result in catastrophic outcomes.","meta":{"url":"http://arxiv.org/abs/2310.11335v1"},"cats":{"benchmark":0.4443014321,"new-dataset":0.0046241103,"data-annotation":0.5316215143,"dev-research":0.1802834246,"llms":0.4104281006,"data-quality":0.1038406425}}
{"text":"This problem can be circumvented by transforming the time series of collected returns into one with ergodic increments.","meta":{"url":"http://arxiv.org/abs/2310.11335v1"},"cats":{"benchmark":0.375830963,"new-dataset":0.1992433688,"data-annotation":0.5135375049,"dev-research":0.108133097,"llms":0.4589944959,"data-quality":0.1017489021}}
{"text":"This transformation enables learning robust policies by optimizing the long-term return for individual agents rather than the average across infinitely many trajectories.","meta":{"url":"http://arxiv.org/abs/2310.11335v1"},"cats":{"benchmark":0.2926623987,"new-dataset":0.052429557,"data-annotation":0.508561936,"dev-research":0.110422128,"llms":0.3658147107,"data-quality":0.058701099}}
{"text":"We propose an algorithm for learning ergodicity transformations from data and demonstrate its effectiveness in an instructive, non-ergodic environment and on standard RL benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.11335v1"},"cats":{"benchmark":0.3720909156,"new-dataset":0.1727907155,"data-annotation":0.5132977061,"dev-research":0.1530055342,"llms":0.4487655861,"data-quality":0.1155170204}}
{"text":"Establishing causal relationships between actions and outcomes is fundamental for accountable multi-agent decision-making.","meta":{"url":"http://arxiv.org/abs/2310.11334v1"},"cats":{"benchmark":0.2893752465,"new-dataset":0.0334615737,"data-annotation":0.5023408879,"dev-research":0.3133418343,"llms":0.4926346946,"data-quality":0.1044952598}}
{"text":"However, interpreting and quantifying agents' contributions to such relationships pose significant challenges.","meta":{"url":"http://arxiv.org/abs/2310.11334v1"},"cats":{"benchmark":0.299606033,"new-dataset":0.0340842824,"data-annotation":0.5133611026,"dev-research":0.2428357636,"llms":0.471809897,"data-quality":0.1260332727}}
{"text":"These challenges are particularly prominent in the context of multi-agent sequential decision-making, where the causal effect of an agent's action on the outcome depends on how the other agents respond to that action.","meta":{"url":"http://arxiv.org/abs/2310.11334v1"},"cats":{"benchmark":0.2630669438,"new-dataset":0.0384603639,"data-annotation":0.5036343801,"dev-research":0.2359715316,"llms":0.4929332255,"data-quality":0.0773088437}}
{"text":"In this paper, our objective is to present a systematic approach for attributing the causal effects of agents' actions to the influence they exert on other agents.","meta":{"url":"http://arxiv.org/abs/2310.11334v1"},"cats":{"benchmark":0.2576972438,"new-dataset":0.0655891163,"data-annotation":0.527938192,"dev-research":0.3164361154,"llms":0.4923162333,"data-quality":0.1271468956}}
{"text":"Focusing on multi-agent Markov decision processes, we introduce agent-specific effects (ASE), a novel causal quantity that measures the effect of an agent's action on the outcome that propagates through other agents.","meta":{"url":"http://arxiv.org/abs/2310.11334v1"},"cats":{"benchmark":0.2893286383,"new-dataset":0.0219692909,"data-annotation":0.5164454345,"dev-research":0.1667032998,"llms":0.4451492934,"data-quality":0.0701941344}}
{"text":"We then turn to the counterfactual counterpart of ASE (cf-ASE), provide a sufficient set of conditions for identifying cf-ASE, and propose a practical sampling-based algorithm for estimating it.","meta":{"url":"http://arxiv.org/abs/2310.11334v1"},"cats":{"benchmark":0.5854144879,"new-dataset":0.0981417834,"data-annotation":0.5315337448,"dev-research":0.1227133556,"llms":0.3999301977,"data-quality":0.214130531}}
{"text":"Finally, we experimentally evaluate the utility of cf-ASE through a simulation-based testbed, which includes a sepsis management environment.","meta":{"url":"http://arxiv.org/abs/2310.11334v1"},"cats":{"benchmark":0.5233966161,"new-dataset":0.0227953349,"data-annotation":0.4854795574,"dev-research":0.2296790418,"llms":0.4890923955,"data-quality":0.0852509909}}
{"text":"Selective robotic harvesting is a promising technological solution to address labour shortages which are affecting modern agriculture in many parts of the world.","meta":{"url":"http://arxiv.org/abs/2310.11333v1"},"cats":{"benchmark":0.2104479196,"new-dataset":0.013310462,"data-annotation":0.5051981392,"dev-research":0.1314999494,"llms":0.4911236909,"data-quality":0.0645520013}}
{"text":"For an accurate and efficient picking process, a robotic harvester requires the precise location and orientation of the fruit to effectively plan the trajectory of the end effector.","meta":{"url":"http://arxiv.org/abs/2310.11333v1"},"cats":{"benchmark":0.3167799133,"new-dataset":0.0195460042,"data-annotation":0.5094970521,"dev-research":0.1541203719,"llms":0.4757415042,"data-quality":0.1017554238}}
{"text":"The current methods for estimating fruit orientation employ either complete 3D information which typically requires registration from multiple views or rely on fully-supervised learning techniques, which require difficult-to-obtain manual annotation of the reference orientation.","meta":{"url":"http://arxiv.org/abs/2310.11333v1"},"cats":{"benchmark":0.3500669323,"new-dataset":0.0630569376,"data-annotation":0.5374385993,"dev-research":0.1444213794,"llms":0.4173334743,"data-quality":0.1597727801}}
{"text":"In this paper, we introduce a novel key-point-based fruit orientation estimation method allowing for the prediction of 3D orientation from 2D images directly.","meta":{"url":"http://arxiv.org/abs/2310.11333v1"},"cats":{"benchmark":0.3763857785,"new-dataset":0.0517365124,"data-annotation":0.5350754189,"dev-research":0.1452331527,"llms":0.3752324632,"data-quality":0.0896995849}}
{"text":"The proposed technique can work without full 3D orientation annotations but can also exploit such information for improved accuracy.","meta":{"url":"http://arxiv.org/abs/2310.11333v1"},"cats":{"benchmark":0.469912466,"new-dataset":0.0123510154,"data-annotation":0.5409586714,"dev-research":0.1851915223,"llms":0.4683856164,"data-quality":0.1744747189}}
{"text":"We evaluate our work on two separate datasets of strawberry images obtained from real-world data collection scenarios.","meta":{"url":"http://arxiv.org/abs/2310.11333v1"},"cats":{"benchmark":0.3083529563,"new-dataset":0.7799417411,"data-annotation":0.5008212588,"dev-research":0.1139790552,"llms":0.4582753765,"data-quality":0.1837471337}}
{"text":"Our proposed method achieves state-of-the-art performance with an average error as low as $8^{\\circ}$, improving predictions by $\\sim30\\%$ compared to previous work presented in~\\cite{wagner2021efficient}.","meta":{"url":"http://arxiv.org/abs/2310.11333v1"},"cats":{"benchmark":0.7665365651,"new-dataset":0.0188086282,"data-annotation":0.556199326,"dev-research":0.2193932377,"llms":0.4380054577,"data-quality":0.1776318943}}
{"text":"Furthermore, our method is suited for real-time robotic applications with fast inference times of $\\sim30$ms.","meta":{"url":"http://arxiv.org/abs/2310.11333v1"},"cats":{"benchmark":0.5192393561,"new-dataset":0.0179214979,"data-annotation":0.5290235208,"dev-research":0.1350673094,"llms":0.4160439314,"data-quality":0.0689189344}}
{"text":"Process discovery algorithms learn process models from executed activity sequences, describing concurrency, causality, and conflict.","meta":{"url":"http://arxiv.org/abs/2310.11332v1"},"cats":{"benchmark":0.2519642071,"new-dataset":0.1635887854,"data-annotation":0.4986273451,"dev-research":0.2913478693,"llms":0.5342261461,"data-quality":0.1071603396}}
{"text":"Concurrent activities require observing multiple permutations, increasing data requirements, especially for processes with concurrent subprocesses such as hierarchical, composite, or distributed processes.","meta":{"url":"http://arxiv.org/abs/2310.11332v1"},"cats":{"benchmark":0.3397040817,"new-dataset":0.0495932542,"data-annotation":0.4710389602,"dev-research":0.2267286565,"llms":0.5623456183,"data-quality":0.0559658169}}
{"text":"While process discovery algorithms traditionally use sequences of activities as input, recently introduced object-centric process discovery algorithms can use graphs of activities as input, encoding partial orders between activities.","meta":{"url":"http://arxiv.org/abs/2310.11332v1"},"cats":{"benchmark":0.2441637587,"new-dataset":0.1638442785,"data-annotation":0.5024576898,"dev-research":0.2238391895,"llms":0.5382126838,"data-quality":0.1091782481}}
{"text":"As such, they contain the concurrency information of many sequences in a single graph.","meta":{"url":"http://arxiv.org/abs/2310.11332v1"},"cats":{"benchmark":0.3156652874,"new-dataset":0.2225330964,"data-annotation":0.4899025873,"dev-research":0.166482975,"llms":0.4764597607,"data-quality":0.1131736502}}
{"text":"In this paper, we address the research question of reducing process discovery data requirements when using object-centric event logs for process discovery.","meta":{"url":"http://arxiv.org/abs/2310.11332v1"},"cats":{"benchmark":0.2834225241,"new-dataset":0.2672204362,"data-annotation":0.4976117372,"dev-research":0.2967655898,"llms":0.5786852024,"data-quality":0.1507624941}}
{"text":"We classify different real-life processes according to the control-flow complexity within and between subprocesses and introduce an evaluation framework to assess process discovery algorithm quality of traditional and object-centric process discovery based on the sample size.","meta":{"url":"http://arxiv.org/abs/2310.11332v1"},"cats":{"benchmark":0.3497995014,"new-dataset":0.0979385191,"data-annotation":0.51470417,"dev-research":0.2636010823,"llms":0.5263627146,"data-quality":0.1004404802}}
{"text":"We complement this with a large-scale production process case study.","meta":{"url":"http://arxiv.org/abs/2310.11332v1"},"cats":{"benchmark":0.325793047,"new-dataset":0.1220487995,"data-annotation":0.4773043604,"dev-research":0.2723687038,"llms":0.4735737199,"data-quality":0.0882601179}}
{"text":"Our results show reduced data requirements, enabling the discovery of large, concurrent processes such as manufacturing with little data, previously infeasible with traditional process discovery.","meta":{"url":"http://arxiv.org/abs/2310.11332v1"},"cats":{"benchmark":0.3099680563,"new-dataset":0.1890319714,"data-annotation":0.4619284112,"dev-research":0.1915488084,"llms":0.5414066806,"data-quality":0.0876823256}}
{"text":"Our findings suggest that object-centric process mining could revolutionize process discovery in various sectors, including manufacturing and supply chains.","meta":{"url":"http://arxiv.org/abs/2310.11332v1"},"cats":{"benchmark":0.2421848032,"new-dataset":0.0584656455,"data-annotation":0.4884827316,"dev-research":0.237107699,"llms":0.5900368161,"data-quality":0.1504600205}}
{"text":"Over the past years, distributed consensus research has shifted its focus towards addressing challenges in large-scale, permissionless systems, such as blockchains.","meta":{"url":"http://arxiv.org/abs/2310.11331v1"},"cats":{"benchmark":0.3183588254,"new-dataset":0.0594236576,"data-annotation":0.4624673206,"dev-research":0.1740194098,"llms":0.5786504495,"data-quality":0.0867113832}}
{"text":"This shift is characterized by the need to accommodate dynamic participation, contrasting the traditional approach of a static set of continuously online participants.","meta":{"url":"http://arxiv.org/abs/2310.11331v1"},"cats":{"benchmark":0.2287778995,"new-dataset":0.0205463298,"data-annotation":0.485612423,"dev-research":0.2615736839,"llms":0.4752287402,"data-quality":0.0381424587}}
{"text":"Works like Bitcoin and the Sleepy Model have set the stage for this developing framework.   ","meta":{"url":"http://arxiv.org/abs/2310.11331v1"},"cats":{"benchmark":0.2694704256,"new-dataset":0.0499442571,"data-annotation":0.4931776383,"dev-research":0.2225446021,"llms":0.5648921474,"data-quality":0.0656384122}}
{"text":"Notable contributions from Momose and Ren (CCS 2022) and subsequent works have introduced Total-Order Broadcast protocols leveraging Graded Agreement primitives and supporting dynamic participation, though often requiring multiple rounds of voting per decision -- a potential bottleneck for real-world large-scale systems.   ","meta":{"url":"http://arxiv.org/abs/2310.11331v1"},"cats":{"benchmark":0.4272268678,"new-dataset":0.0463397157,"data-annotation":0.4888580969,"dev-research":0.1906699344,"llms":0.5996677967,"data-quality":0.0949060199}}
{"text":"Addressing this, our paper presents a novel Total-Order Broadcast protocol in the Sleepy Model resilient to up to 1/2 adversarial participants, requiring just a single round of voting per decision.","meta":{"url":"http://arxiv.org/abs/2310.11331v1"},"cats":{"benchmark":0.3604062817,"new-dataset":0.0497359045,"data-annotation":0.5387637101,"dev-research":0.1705913305,"llms":0.5094310505,"data-quality":0.1148416716}}
{"text":"This work paves the way to more practical Total-Order Broadcast protocols to be implemented in real-world systems where a large number of participants are involved simultaneously and their participation level might fluctuate over time.","meta":{"url":"http://arxiv.org/abs/2310.11331v1"},"cats":{"benchmark":0.3289312598,"new-dataset":0.107723821,"data-annotation":0.5067086083,"dev-research":0.192021148,"llms":0.5370951004,"data-quality":0.0541032193}}
{"text":"For integrated sensing and communication (ISAC) systems, the channel information essential for communication and sensing tasks fluctuates across different timescales.","meta":{"url":"http://arxiv.org/abs/2310.11326v1"},"cats":{"benchmark":0.3351574044,"new-dataset":0.0131750736,"data-annotation":0.4903102249,"dev-research":0.1986930486,"llms":0.4789487301,"data-quality":0.0964777897}}
{"text":"Specifically, wireless sensing primarily focuses on acquiring path state information (PSI) (e.g., delay, angle, and Doppler) of individual multi-path components to sense the environment, which usually evolves much more slowly than the composite channel state information (CSI) required for communications.","meta":{"url":"http://arxiv.org/abs/2310.11326v1"},"cats":{"benchmark":0.297785177,"new-dataset":0.0195386967,"data-annotation":0.4834442123,"dev-research":0.1907177494,"llms":0.4414568663,"data-quality":0.0354044819}}
{"text":"Typically, the CSI is approximately unchanged during the channel coherence time, which characterizes the statistical properties of wireless communication channels.","meta":{"url":"http://arxiv.org/abs/2310.11326v1"},"cats":{"benchmark":0.4095824303,"new-dataset":0.0280497363,"data-annotation":0.4990818501,"dev-research":0.1870806593,"llms":0.4391491338,"data-quality":0.093318693}}
{"text":"However, this concept is less appropriate for describing that for wireless sensing.","meta":{"url":"http://arxiv.org/abs/2310.11326v1"},"cats":{"benchmark":0.374743655,"new-dataset":0.0024255602,"data-annotation":0.5004848356,"dev-research":0.1873226705,"llms":0.4483637451,"data-quality":0.1135304498}}
{"text":"To this end, in this paper, we introduce a new timescale to study the variation of the PSI from a channel geometric perspective, termed path invariant time, during which the PSI largely remains constant.","meta":{"url":"http://arxiv.org/abs/2310.11326v1"},"cats":{"benchmark":0.3599911373,"new-dataset":0.0094334283,"data-annotation":0.5150784551,"dev-research":0.1374149569,"llms":0.4496690361,"data-quality":0.0576627081}}
{"text":"Our analysis indicates that the path invariant time considerably exceeds the channel coherence time.","meta":{"url":"http://arxiv.org/abs/2310.11326v1"},"cats":{"benchmark":0.4302601061,"new-dataset":0.0131157741,"data-annotation":0.528192561,"dev-research":0.111075465,"llms":0.4720425483,"data-quality":0.0971628799}}
{"text":"Thus, capitalizing on these dual timescales of the wireless channel, in this paper, we propose a novel ISAC framework exploiting the recently proposed delay-Doppler alignment modulation (DDAM) technique.","meta":{"url":"http://arxiv.org/abs/2310.11326v1"},"cats":{"benchmark":0.4643649537,"new-dataset":0.0189540973,"data-annotation":0.4930301223,"dev-research":0.1999904861,"llms":0.5209789192,"data-quality":0.0678327907}}
{"text":"Different from most existing studies on DDAM that assume the availability of perfect PSI, in this work, we propose a novel algorithm, termed as adaptive simultaneously orthogonal matching pursuit with support refinement (ASOMP-SR), for joint environment sensing and PSI estimation.","meta":{"url":"http://arxiv.org/abs/2310.11326v1"},"cats":{"benchmark":0.4967836743,"new-dataset":0.0174930145,"data-annotation":0.4837760915,"dev-research":0.1365485522,"llms":0.490008682,"data-quality":0.1048392304}}
{"text":"We also analyze the performance of DDAM with imperfectly sensed PSI.Simulation results unveil that the proposed DDAM-based ISAC can achieve superior spectral efficiency and a reduced peak-to-average power ratio (PAPR) compared to standard orthogonal frequency division multiplexing (OFDM).","meta":{"url":"http://arxiv.org/abs/2310.11326v1"},"cats":{"benchmark":0.4809595212,"new-dataset":0.0114726121,"data-annotation":0.4808611798,"dev-research":0.1487307897,"llms":0.5814810849,"data-quality":0.0920924594}}
{"text":"To maintain the privacy of users' web browsing history, popular browsers encrypt their DNS traffic using the DNS-over-HTTPS (DoH) protocol.","meta":{"url":"http://arxiv.org/abs/2310.11325v1"},"cats":{"benchmark":0.2622583982,"new-dataset":0.0610124289,"data-annotation":0.4762244625,"dev-research":0.1585400054,"llms":0.5884572339,"data-quality":0.0482001115}}
{"text":"Unfortunately, encrypting DNS packets prevents many existing intrusion detection systems from using plaintext domain names to detect malicious traffic.","meta":{"url":"http://arxiv.org/abs/2310.11325v1"},"cats":{"benchmark":0.2699235034,"new-dataset":0.0799377882,"data-annotation":0.4950698771,"dev-research":0.1407787431,"llms":0.5803560834,"data-quality":0.1287561041}}
{"text":"In this paper, we design an autoencoder that is capable of detecting malicious DNS traffic by only observing the encrypted DoH traffic.","meta":{"url":"http://arxiv.org/abs/2310.11325v1"},"cats":{"benchmark":0.2688801374,"new-dataset":0.1061899812,"data-annotation":0.5026490207,"dev-research":0.1550663431,"llms":0.5600342956,"data-quality":0.1140889137}}
{"text":"Compared to previous works, the proposed autoencoder looks for anomalies in DoH traffic, and thus can detect malicious traffic that has not been previously observed, i.e., zero-day attacks.","meta":{"url":"http://arxiv.org/abs/2310.11325v1"},"cats":{"benchmark":0.2983646395,"new-dataset":0.043375747,"data-annotation":0.5146080189,"dev-research":0.1922249438,"llms":0.5079927904,"data-quality":0.1862879171}}
{"text":"We run extensive experiments to evaluate the performance of our proposed autoencoder and compare it to that of other anomaly detection algorithms, namely, local outlier factor, one-class support vector machine, isolation forest, and variational autoencoders.","meta":{"url":"http://arxiv.org/abs/2310.11325v1"},"cats":{"benchmark":0.3519550452,"new-dataset":0.0571326426,"data-annotation":0.5331864455,"dev-research":0.2084328966,"llms":0.4658555762,"data-quality":0.3403117627}}
{"text":"We find that our proposed autoencoder achieves the highest detection performance, with a median F-1 score of 99\\% over several types of malicious traffic.","meta":{"url":"http://arxiv.org/abs/2310.11325v1"},"cats":{"benchmark":0.4119357081,"new-dataset":0.0687798494,"data-annotation":0.5445298278,"dev-research":0.1636991165,"llms":0.46438428,"data-quality":0.2285706236}}
{"text":"As large language models (LLMs) are adopted as a fundamental component of language technologies, it is crucial to accurately characterize their performance.","meta":{"url":"http://arxiv.org/abs/2310.11324v1"},"cats":{"benchmark":0.3572959293,"new-dataset":0.0271245539,"data-annotation":0.5319878938,"dev-research":0.1660197529,"llms":0.7355994857,"data-quality":0.1443452828}}
{"text":"Because choices in prompt design can strongly influence model behavior, this design process is critical in effectively using any modern pre-trained generative language model.","meta":{"url":"http://arxiv.org/abs/2310.11324v1"},"cats":{"benchmark":0.1433319119,"new-dataset":0.0168095927,"data-annotation":0.5247200465,"dev-research":0.282253956,"llms":0.6378140843,"data-quality":0.1101831079}}
{"text":"In this work, we focus on LLM sensitivity to a quintessential class of meaning-preserving design choices: prompt formatting.","meta":{"url":"http://arxiv.org/abs/2310.11324v1"},"cats":{"benchmark":0.1803395986,"new-dataset":0.0381675687,"data-annotation":0.5116568805,"dev-research":0.2724624798,"llms":0.7377214254,"data-quality":0.2365768613}}
{"text":"We find that several widely used open-source LLMs are extremely sensitive to subtle changes in prompt formatting in few-shot settings, with performance differences of up to 76 accuracy points when evaluated using LLaMA-2-13B. Sensitivity remains even when increasing model size, the number of few-shot examples, or performing instruction tuning.","meta":{"url":"http://arxiv.org/abs/2310.11324v1"},"cats":{"benchmark":0.344688437,"new-dataset":0.0302548591,"data-annotation":0.5085098906,"dev-research":0.1967683217,"llms":0.7599617684,"data-quality":0.1907673998}}
{"text":"Our analysis suggests that work evaluating LLMs with prompting-based methods would benefit from reporting a range of performance across plausible prompt formats, instead of the currently-standard practice of reporting performance on a single format.","meta":{"url":"http://arxiv.org/abs/2310.11324v1"},"cats":{"benchmark":0.4097702815,"new-dataset":0.0174622837,"data-annotation":0.4951650114,"dev-research":0.2944270566,"llms":0.7330929413,"data-quality":0.1990710685}}
{"text":"We also show that format performance only weakly correlates between models, which puts into question the methodological validity of comparing models with an arbitrarily chosen, fixed prompt format.","meta":{"url":"http://arxiv.org/abs/2310.11324v1"},"cats":{"benchmark":0.5858957365,"new-dataset":0.0095509014,"data-annotation":0.5104992455,"dev-research":0.2358869254,"llms":0.4741152629,"data-quality":0.2523750212}}
{"text":"To facilitate systematic analysis we propose FormatSpread, an algorithm that rapidly evaluates a sampled set of plausible prompt formats for a given task, and reports the interval of expected performance without accessing model weights.","meta":{"url":"http://arxiv.org/abs/2310.11324v1"},"cats":{"benchmark":0.5007974006,"new-dataset":0.0408444191,"data-annotation":0.5170403823,"dev-research":0.2350335587,"llms":0.4973429764,"data-quality":0.1752626554}}
{"text":"Furthermore, we present a suite of analyses that characterize the nature of this sensitivity, including exploring the influence of particular atomic perturbations and the internal representation of particular formats.","meta":{"url":"http://arxiv.org/abs/2310.11324v1"},"cats":{"benchmark":0.4979752408,"new-dataset":0.0079220785,"data-annotation":0.5141194281,"dev-research":0.1420612396,"llms":0.5160941263,"data-quality":0.2146700465}}
{"text":"In support of open and reproducible research, there has been a rapidly increasing number of datasets made available for research.","meta":{"url":"http://arxiv.org/abs/2310.11318v1"},"cats":{"benchmark":0.289132765,"new-dataset":0.8440477405,"data-annotation":0.4902866774,"dev-research":0.205955881,"llms":0.4812073673,"data-quality":0.1033975813}}
{"text":"As the availability of datasets increases, it becomes more important to have quality metadata for discovering and reusing them.","meta":{"url":"http://arxiv.org/abs/2310.11318v1"},"cats":{"benchmark":0.3252630085,"new-dataset":0.5213652977,"data-annotation":0.4824492441,"dev-research":0.2676250945,"llms":0.5640755779,"data-quality":0.365031258}}
{"text":"Yet, it is a common issue that datasets often lack quality metadata due to limited resources for data curation.","meta":{"url":"http://arxiv.org/abs/2310.11318v1"},"cats":{"benchmark":0.2415803973,"new-dataset":0.4025537016,"data-annotation":0.4710094104,"dev-research":0.2599161928,"llms":0.5754334315,"data-quality":0.4806869207}}
{"text":"Meanwhile, technologies such as artificial intelligence and large language models (LLMs) are progressing rapidly.","meta":{"url":"http://arxiv.org/abs/2310.11318v1"},"cats":{"benchmark":0.1720617942,"new-dataset":0.0456538863,"data-annotation":0.5140612158,"dev-research":0.176152771,"llms":0.7342996834,"data-quality":0.0761302967}}
{"text":"Recently, systems based on these technologies, such as ChatGPT, have demonstrated promising capabilities for certain data curation tasks.","meta":{"url":"http://arxiv.org/abs/2310.11318v1"},"cats":{"benchmark":0.3081399824,"new-dataset":0.1906449197,"data-annotation":0.4640978221,"dev-research":0.2377637605,"llms":0.6051288939,"data-quality":0.1112554924}}
{"text":"This paper proposes to leverage LLMs for cost-effective annotation of subject metadata through the LLM-based in-context learning.","meta":{"url":"http://arxiv.org/abs/2310.11318v1"},"cats":{"benchmark":0.2539881649,"new-dataset":0.2612426578,"data-annotation":0.5419280342,"dev-research":0.1694354181,"llms":0.7100359632,"data-quality":0.407622746}}
{"text":"Our method employs GPT-3.5 with prompts designed for annotating subject metadata, demonstrating promising performance in automatic metadata annotation.","meta":{"url":"http://arxiv.org/abs/2310.11318v1"},"cats":{"benchmark":0.3056241116,"new-dataset":0.4037246906,"data-annotation":0.5482252958,"dev-research":0.2402980445,"llms":0.6118191594,"data-quality":0.3842945}}
{"text":"However, models based on in-context learning cannot acquire discipline-specific rules, resulting in lower performance in several categories.","meta":{"url":"http://arxiv.org/abs/2310.11318v1"},"cats":{"benchmark":0.3290525017,"new-dataset":0.0035536541,"data-annotation":0.5064733884,"dev-research":0.1761423714,"llms":0.5227254029,"data-quality":0.1808018477}}
{"text":"This limitation arises from the limited contextual information available for subject inference.","meta":{"url":"http://arxiv.org/abs/2310.11318v1"},"cats":{"benchmark":0.2480540783,"new-dataset":0.0121703975,"data-annotation":0.5306456726,"dev-research":0.1159351387,"llms":0.5063738281,"data-quality":0.0817009844}}
{"text":"To the best of our knowledge, we are introducing, for the first time, an in-context learning method that harnesses large language models for automated subject metadata annotation.","meta":{"url":"http://arxiv.org/abs/2310.11318v1"},"cats":{"benchmark":0.2665137583,"new-dataset":0.4577080296,"data-annotation":0.5601575326,"dev-research":0.2134386945,"llms":0.5774683482,"data-quality":0.4370155591}}
{"text":"Monocular 3D object detection is an inherently ill-posed problem, as it is challenging to predict accurate 3D localization from a single image.","meta":{"url":"http://arxiv.org/abs/2310.11316v1"},"cats":{"benchmark":0.2901434104,"new-dataset":0.0489350174,"data-annotation":0.53111498,"dev-research":0.1614096988,"llms":0.4187266922,"data-quality":0.1742859059}}
{"text":"Existing monocular 3D detection knowledge distillation methods usually project the LiDAR onto the image plane and train the teacher network accordingly.","meta":{"url":"http://arxiv.org/abs/2310.11316v1"},"cats":{"benchmark":0.2545703609,"new-dataset":0.0507546342,"data-annotation":0.5135014826,"dev-research":0.1553098877,"llms":0.5144994918,"data-quality":0.1337683013}}
{"text":"Transferring LiDAR-based model knowledge to RGB-based models is more complex, so a general distillation strategy is needed.","meta":{"url":"http://arxiv.org/abs/2310.11316v1"},"cats":{"benchmark":0.3133403883,"new-dataset":0.011384828,"data-annotation":0.4802912042,"dev-research":0.1711387565,"llms":0.50633268,"data-quality":0.0706329861}}
{"text":"To alleviate cross-modal prob-lem, we propose MonoSKD, a novel Knowledge Distillation framework for Monocular 3D detection based on Spearman correlation coefficient, to learn the relative correlation between cross-modal features.","meta":{"url":"http://arxiv.org/abs/2310.11316v1"},"cats":{"benchmark":0.3309273923,"new-dataset":0.1617623029,"data-annotation":0.5090637227,"dev-research":0.1244190916,"llms":0.5116280682,"data-quality":0.1046307469}}
{"text":"Considering the large gap between these features, strict alignment of features may mislead the training, so we propose a looser Spearman loss.","meta":{"url":"http://arxiv.org/abs/2310.11316v1"},"cats":{"benchmark":0.3740534409,"new-dataset":0.0199919327,"data-annotation":0.5197665955,"dev-research":0.1572221326,"llms":0.4794314954,"data-quality":0.3554534776}}
{"text":"Furthermore, by selecting appropriate distillation locations and removing redundant modules, our scheme saves more GPU resources and trains faster than existing methods.","meta":{"url":"http://arxiv.org/abs/2310.11316v1"},"cats":{"benchmark":0.4903363754,"new-dataset":0.0043148826,"data-annotation":0.4992912089,"dev-research":0.1939337789,"llms":0.5337945077,"data-quality":0.0638789191}}
{"text":"Extensive experiments are performed to verify the effectiveness of our framework on the challenging KITTI 3D object detection benchmark.","meta":{"url":"http://arxiv.org/abs/2310.11316v1"},"cats":{"benchmark":0.5304858865,"new-dataset":0.110080082,"data-annotation":0.5165066186,"dev-research":0.150089807,"llms":0.4648437452,"data-quality":0.1449629219}}
{"text":"Our method achieves state-of-the-art performance until submission with no additional inference computational cost.","meta":{"url":"http://arxiv.org/abs/2310.11316v1"},"cats":{"benchmark":0.5991278717,"new-dataset":0.0286884302,"data-annotation":0.5368263182,"dev-research":0.1570001945,"llms":0.4748065198,"data-quality":0.097871245}}
{"text":"Our codes are available at https://github.com/Senwang98/MonoSKD","meta":{"url":"http://arxiv.org/abs/2310.11316v1"},"cats":{"benchmark":0.2416464774,"new-dataset":0.2839942436,"data-annotation":0.512727021,"dev-research":0.1941980537,"llms":0.5232942045,"data-quality":0.1170500618}}
{"text":"Guidance in conditional diffusion generation is of great importance for sample quality and controllability.","meta":{"url":"http://arxiv.org/abs/2310.11311v1"},"cats":{"benchmark":0.4122670698,"new-dataset":0.0140140313,"data-annotation":0.4913575856,"dev-research":0.1686437353,"llms":0.4950633679,"data-quality":0.1140667921}}
{"text":"However, existing guidance schemes are to be desired.","meta":{"url":"http://arxiv.org/abs/2310.11311v1"},"cats":{"benchmark":0.2640870687,"new-dataset":0.0077784567,"data-annotation":0.4847378439,"dev-research":0.2897024601,"llms":0.4819468911,"data-quality":0.0541040321}}
{"text":"On one hand, mainstream methods such as classifier guidance and classifier-free guidance both require extra training with labeled data, which is time-consuming and unable to adapt to new conditions.","meta":{"url":"http://arxiv.org/abs/2310.11311v1"},"cats":{"benchmark":0.3005367958,"new-dataset":0.0164765889,"data-annotation":0.5147505846,"dev-research":0.2593133687,"llms":0.4874849925,"data-quality":0.2331679395}}
{"text":"On the other hand, training-free methods such as universal guidance, though more flexible, have yet to demonstrate comparable performance.","meta":{"url":"http://arxiv.org/abs/2310.11311v1"},"cats":{"benchmark":0.4100803123,"new-dataset":0.0018754842,"data-annotation":0.5216202353,"dev-research":0.1892870685,"llms":0.5259949828,"data-quality":0.0671857391}}
{"text":"In this work, through a comprehensive investigation into the design space, we show that it is possible to achieve significant performance improvements over existing guidance schemes by leveraging off-the-shelf classifiers in a training-free fashion, enjoying the best of both worlds.","meta":{"url":"http://arxiv.org/abs/2310.11311v1"},"cats":{"benchmark":0.4021287788,"new-dataset":0.0982921453,"data-annotation":0.5313942787,"dev-research":0.2325537586,"llms":0.4695041892,"data-quality":0.2224131388}}
{"text":"Employing calibration as a general guideline, we propose several pre-conditioning techniques to better exploit pretrained off-the-shelf classifiers for guiding diffusion generation.","meta":{"url":"http://arxiv.org/abs/2310.11311v1"},"cats":{"benchmark":0.4032594259,"new-dataset":0.0357613784,"data-annotation":0.5171028776,"dev-research":0.1504474338,"llms":0.4588916351,"data-quality":0.1423900531}}
{"text":"Extensive experiments on ImageNet validate our proposed method, showing that state-of-the-art diffusion models (DDPM, EDM, DiT) can be further improved (up to 20%) using off-the-shelf classifiers with barely any extra computational cost.","meta":{"url":"http://arxiv.org/abs/2310.11311v1"},"cats":{"benchmark":0.4763123846,"new-dataset":0.0451299997,"data-annotation":0.5163138571,"dev-research":0.1404378266,"llms":0.4848334819,"data-quality":0.1833249453}}
{"text":"With the proliferation of publicly available pretrained classifiers, our proposed approach has great potential and can be readily scaled up to text-to-image generation tasks.","meta":{"url":"http://arxiv.org/abs/2310.11311v1"},"cats":{"benchmark":0.2710101335,"new-dataset":0.2607764186,"data-annotation":0.5376341044,"dev-research":0.1810002221,"llms":0.5330078065,"data-quality":0.2310305572}}
{"text":"The code is available at https://github.com/AlexMaOLS/EluCD/tree/main.","meta":{"url":"http://arxiv.org/abs/2310.11311v1"},"cats":{"benchmark":0.3461674856,"new-dataset":0.2739437782,"data-annotation":0.5335657888,"dev-research":0.153460941,"llms":0.543679436,"data-quality":0.1432768735}}
{"text":"Intelligent reflecting/refracting surface (IRS) is envisioned as a promising technology to reconfigure wireless propagation environment for enhancing the communication performance, by smartly controlling the signal reflection/refraction with a large number of tunable passive elements.","meta":{"url":"http://arxiv.org/abs/2310.11309v1"},"cats":{"benchmark":0.3289062535,"new-dataset":0.0102219252,"data-annotation":0.5018250975,"dev-research":0.2204163834,"llms":0.5040141972,"data-quality":0.0637831949}}
{"text":"In particular, the application of IRS in high-mobility scenarios can convert wireless channels from fast fading to slow fading, thus achieving more reliable communications.","meta":{"url":"http://arxiv.org/abs/2310.11309v1"},"cats":{"benchmark":0.3644231279,"new-dataset":0.0038697404,"data-annotation":0.5007903861,"dev-research":0.2102476458,"llms":0.4982809011,"data-quality":0.0814932033}}
{"text":"In this paper, we first provide an overview of the new applications and opportunities of IRS in high-mobility communications.","meta":{"url":"http://arxiv.org/abs/2310.11309v1"},"cats":{"benchmark":0.3212335027,"new-dataset":0.031236233,"data-annotation":0.4973225704,"dev-research":0.1482304048,"llms":0.5383554373,"data-quality":0.0977075366}}
{"text":"Next, we present two practical strategies for deploying IRS to aid high-mobility communications, namely, roadside IRS versus vehicle-side IRS, and compare their different channel characteristics, handover requirements, and deployment costs.","meta":{"url":"http://arxiv.org/abs/2310.11309v1"},"cats":{"benchmark":0.3035619392,"new-dataset":0.0279160473,"data-annotation":0.4974794935,"dev-research":0.255013788,"llms":0.5264727073,"data-quality":0.0940563187}}
{"text":"Then, the main issues in designing IRS-aided high-mobility communications, including node discovery, mode switching, beam alignment/tracking, handover, and multiuser scheduling are discussed for both IRS deployment strategies.","meta":{"url":"http://arxiv.org/abs/2310.11309v1"},"cats":{"benchmark":0.3258742798,"new-dataset":0.0108010585,"data-annotation":0.48344719,"dev-research":0.2100659469,"llms":0.5350338976,"data-quality":0.0631169432}}
{"text":"Moreover, numerical results are presented to demonstrate the potential performance gains of IRSs in vehicular communications.","meta":{"url":"http://arxiv.org/abs/2310.11309v1"},"cats":{"benchmark":0.4956120465,"new-dataset":0.0071207034,"data-annotation":0.5129957591,"dev-research":0.1808186396,"llms":0.4371976992,"data-quality":0.1297982237}}
{"text":"Finally, new research directions are pointed out for future work.","meta":{"url":"http://arxiv.org/abs/2310.11309v1"},"cats":{"benchmark":0.292844132,"new-dataset":0.0499109674,"data-annotation":0.5117746908,"dev-research":0.2292219266,"llms":0.5809128367,"data-quality":0.0874014405}}
{"text":"Intelligent transportation system combines advanced information technology to provide intelligent services such as monitoring, detection, and early warning for modern transportation.","meta":{"url":"http://arxiv.org/abs/2310.11307v1"},"cats":{"benchmark":0.2613549438,"new-dataset":0.0227500263,"data-annotation":0.4944459779,"dev-research":0.239269492,"llms":0.4929055692,"data-quality":0.1237427788}}
{"text":"Intelligent transportation detection is the cornerstone of many intelligent traffic services by identifying task targets through object detection methods.","meta":{"url":"http://arxiv.org/abs/2310.11307v1"},"cats":{"benchmark":0.2971959354,"new-dataset":0.0151886865,"data-annotation":0.5246304163,"dev-research":0.171200598,"llms":0.4424821152,"data-quality":0.2012112226}}
{"text":"However existing detection methods in intelligent transportation are limited by two aspects.","meta":{"url":"http://arxiv.org/abs/2310.11307v1"},"cats":{"benchmark":0.284627788,"new-dataset":0.0108307061,"data-annotation":0.5349788006,"dev-research":0.149151846,"llms":0.4428169484,"data-quality":0.1528103278}}
{"text":"First, there is a difference between the model knowledge pre-trained on large-scale datasets and the knowledge required for target task.","meta":{"url":"http://arxiv.org/abs/2310.11307v1"},"cats":{"benchmark":0.2223177744,"new-dataset":0.0697112794,"data-annotation":0.5065199601,"dev-research":0.1952163138,"llms":0.5031106937,"data-quality":0.0625947277}}
{"text":"Second, most detection models follow the pattern of single-source learning, which limits the learning ability.","meta":{"url":"http://arxiv.org/abs/2310.11307v1"},"cats":{"benchmark":0.1759657069,"new-dataset":0.0119435376,"data-annotation":0.5315242774,"dev-research":0.1102969645,"llms":0.4552166399,"data-quality":0.1792955624}}
{"text":"To address these problems, we propose a Multi Self-supervised Pre-fine-tuned Transformer Fusion (MSPTF) network, consisting of two steps: unsupervised pre-fine-tune domain knowledge learning and multi-model fusion target task learning.","meta":{"url":"http://arxiv.org/abs/2310.11307v1"},"cats":{"benchmark":0.2619539968,"new-dataset":0.1017341305,"data-annotation":0.5171331247,"dev-research":0.1433726772,"llms":0.5083306276,"data-quality":0.1465282272}}
{"text":"In the first step, we introduced self-supervised learning methods into transformer model pre-fine-tune which could reduce data costs and alleviate the knowledge gap between pre-trained model and target task.","meta":{"url":"http://arxiv.org/abs/2310.11307v1"},"cats":{"benchmark":0.2537983176,"new-dataset":0.0442036788,"data-annotation":0.5160364703,"dev-research":0.1841871282,"llms":0.4689737364,"data-quality":0.1582116895}}
{"text":"In the second step, we take feature information differences between different model architectures and different pre-fine-tune tasks into account and propose Multi-model Semantic Consistency Cross-attention Fusion (MSCCF) network to combine different transformer model features by considering channel semantic consistency and feature vector semantic consistency, which obtain more complete and proper fusion features for detection task.","meta":{"url":"http://arxiv.org/abs/2310.11307v1"},"cats":{"benchmark":0.3336632891,"new-dataset":0.0443173085,"data-annotation":0.4979401983,"dev-research":0.204747849,"llms":0.4942516775,"data-quality":0.2433071783}}
{"text":"We experimented the proposed method on vehicle recognition dataset and road disease detection dataset and achieved 1.1%, 5.5%, 4.2% improvement compared with baseline and 0.7%, 1.8%, 1.7% compared with sota, which proved the effectiveness of our method.","meta":{"url":"http://arxiv.org/abs/2310.11307v1"},"cats":{"benchmark":0.3762117209,"new-dataset":0.3476797382,"data-annotation":0.510607908,"dev-research":0.1747346553,"llms":0.4657476389,"data-quality":0.2005778081}}
{"text":"This paper presents MiniZero, a zero-knowledge learning framework that supports four state-of-the-art algorithms, including AlphaZero, MuZero, Gumbel AlphaZero, and Gumbel MuZero.","meta":{"url":"http://arxiv.org/abs/2310.11305v1"},"cats":{"benchmark":0.3211513944,"new-dataset":0.1591146148,"data-annotation":0.5475746187,"dev-research":0.1077088295,"llms":0.495280457,"data-quality":0.1846987257}}
{"text":"While these algorithms have demonstrated super-human performance in many games, it remains unclear which among them is most suitable or efficient for specific tasks.","meta":{"url":"http://arxiv.org/abs/2310.11305v1"},"cats":{"benchmark":0.5391080251,"new-dataset":0.025722373,"data-annotation":0.5400589509,"dev-research":0.1814133611,"llms":0.4541160243,"data-quality":0.0339733603}}
{"text":"Through MiniZero, we systematically evaluate the performance of each algorithm in two board games, 9x9 Go and 8x8 Othello, as well as 57 Atari games.","meta":{"url":"http://arxiv.org/abs/2310.11305v1"},"cats":{"benchmark":0.5409029754,"new-dataset":0.0440451273,"data-annotation":0.5483368543,"dev-research":0.1780092861,"llms":0.4795313485,"data-quality":0.0535482195}}
{"text":"Our empirical findings are summarized as follows.","meta":{"url":"http://arxiv.org/abs/2310.11305v1"},"cats":{"benchmark":0.5140911473,"new-dataset":0.1405335069,"data-annotation":0.5224160771,"dev-research":0.1812771971,"llms":0.3978871438,"data-quality":0.1690061809}}
{"text":"For two board games, using more simulations generally results in higher performance.","meta":{"url":"http://arxiv.org/abs/2310.11305v1"},"cats":{"benchmark":0.526058534,"new-dataset":0.009424331,"data-annotation":0.5220689452,"dev-research":0.239799273,"llms":0.5098846777,"data-quality":0.0403792416}}
{"text":"However, the choice of AlphaZero and MuZero may differ based on game properties.","meta":{"url":"http://arxiv.org/abs/2310.11305v1"},"cats":{"benchmark":0.4201486916,"new-dataset":0.0108357316,"data-annotation":0.4944035811,"dev-research":0.1272519705,"llms":0.5819497362,"data-quality":0.0668605834}}
{"text":"For Atari games, both MuZero and Gumbel MuZero are worth considering.","meta":{"url":"http://arxiv.org/abs/2310.11305v1"},"cats":{"benchmark":0.3991730755,"new-dataset":0.0569090637,"data-annotation":0.5211180163,"dev-research":0.152012776,"llms":0.5998768474,"data-quality":0.0843831013}}
{"text":"Since each game has unique characteristics, different algorithms and simulations yield varying results.","meta":{"url":"http://arxiv.org/abs/2310.11305v1"},"cats":{"benchmark":0.5478705417,"new-dataset":0.0088581838,"data-annotation":0.5103630505,"dev-research":0.1510876612,"llms":0.4364011636,"data-quality":0.0700828839}}
{"text":"In addition, we introduce an approach, called progressive simulation, which progressively increases the simulation budget during training to allocate computation more efficiently.","meta":{"url":"http://arxiv.org/abs/2310.11305v1"},"cats":{"benchmark":0.2954835994,"new-dataset":0.1685660256,"data-annotation":0.5091727754,"dev-research":0.2522055887,"llms":0.5050005594,"data-quality":0.0618434821}}
{"text":"Our empirical results demonstrate that progressive simulation achieves significantly superior performance in two board games.","meta":{"url":"http://arxiv.org/abs/2310.11305v1"},"cats":{"benchmark":0.4282638447,"new-dataset":0.0507436923,"data-annotation":0.5136639161,"dev-research":0.2647132947,"llms":0.4997848738,"data-quality":0.0497168051}}
{"text":"By making our framework and trained models publicly available, this paper contributes a benchmark for future research on zero-knowledge learning algorithms, assisting researchers in algorithm selection and comparison against these zero-knowledge learning baselines.","meta":{"url":"http://arxiv.org/abs/2310.11305v1"},"cats":{"benchmark":0.4467457869,"new-dataset":0.0782123583,"data-annotation":0.5552194207,"dev-research":0.1185144683,"llms":0.4738857037,"data-quality":0.200143052}}
{"text":"Zero-shot commonsense Question-Answering (QA) requires models to reason about general situations beyond specific benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.11303v1"},"cats":{"benchmark":0.3141322335,"new-dataset":0.1037410212,"data-annotation":0.533855157,"dev-research":0.1607162713,"llms":0.5404617977,"data-quality":0.1516322969}}
{"text":"State-of-the-art approaches fine-tune language models on QA pairs constructed from CommonSense Knowledge Bases (CSKBs) to equip the models with more commonsense knowledge in a QA context.","meta":{"url":"http://arxiv.org/abs/2310.11303v1"},"cats":{"benchmark":0.2997654043,"new-dataset":0.3457638241,"data-annotation":0.536993418,"dev-research":0.1985537347,"llms":0.5623708511,"data-quality":0.204372935}}
{"text":"However, current QA synthesis protocols may introduce noise from the CSKBs and generate ungrammatical questions and false negative options, which impede the model's ability to generalize.","meta":{"url":"http://arxiv.org/abs/2310.11303v1"},"cats":{"benchmark":0.2622514906,"new-dataset":0.0339041239,"data-annotation":0.5056611265,"dev-research":0.3482594746,"llms":0.5726044712,"data-quality":0.1898029216}}
{"text":"To address these issues, we propose QADYNAMICS, a training dynamics-driven framework for QA diagnostics and refinement.","meta":{"url":"http://arxiv.org/abs/2310.11303v1"},"cats":{"benchmark":0.352028034,"new-dataset":0.093000943,"data-annotation":0.5169227576,"dev-research":0.2406950012,"llms":0.485489266,"data-quality":0.1319353455}}
{"text":"Our approach analyzes the training dynamics of each QA pair at both the question level and option level, discarding machine-detectable artifacts by removing uninformative QA pairs and mislabeled or false-negative options.","meta":{"url":"http://arxiv.org/abs/2310.11303v1"},"cats":{"benchmark":0.4023433373,"new-dataset":0.0574537776,"data-annotation":0.5368936099,"dev-research":0.2036160688,"llms":0.5214544128,"data-quality":0.3767828285}}
{"text":"Extensive experiments demonstrate the effectiveness of our approach, which outperforms all baselines while using only 33% of the synthetic data, even including LLMs such as ChatGPT.","meta":{"url":"http://arxiv.org/abs/2310.11303v1"},"cats":{"benchmark":0.6061065211,"new-dataset":0.2093669799,"data-annotation":0.4900343494,"dev-research":0.1599717995,"llms":0.5869595663,"data-quality":0.1431998257}}
{"text":"Moreover, expert evaluations confirm that our framework significantly improves the quality of QA synthesis.","meta":{"url":"http://arxiv.org/abs/2310.11303v1"},"cats":{"benchmark":0.4743802267,"new-dataset":0.0609553838,"data-annotation":0.5166678542,"dev-research":0.424643198,"llms":0.5539572612,"data-quality":0.1399903094}}
{"text":"Our codes and model checkpoints are available at https://github.com/HKUST-KnowComp/QaDynamics.","meta":{"url":"http://arxiv.org/abs/2310.11303v1"},"cats":{"benchmark":0.3416678079,"new-dataset":0.4732116986,"data-annotation":0.5103871489,"dev-research":0.2509328919,"llms":0.5546134205,"data-quality":0.1174170816}}
{"text":"Be it in debugging, testing, code review or, more recently, pair programming with AI assistance: in all these activities, software engineers need to understand source code.","meta":{"url":"http://arxiv.org/abs/2310.11301v1"},"cats":{"benchmark":0.2273307871,"new-dataset":0.128513609,"data-annotation":0.5450154053,"dev-research":0.6491673064,"llms":0.5121480867,"data-quality":0.1762492991}}
{"text":"Accordingly, plenty of research is taking place in the field to find out, for example, what makes code easy to understand and which tools can best support developers in their comprehension process.","meta":{"url":"http://arxiv.org/abs/2310.11301v1"},"cats":{"benchmark":0.2330760043,"new-dataset":0.0416354172,"data-annotation":0.5338014909,"dev-research":0.6188270646,"llms":0.5801446794,"data-quality":0.1179554559}}
{"text":"And while any code comprehension researcher certainly has a rough idea of what they mean when they mention a developer having a good understanding of a piece of code, to date, the research community has not managed to define source code comprehension as a concept.","meta":{"url":"http://arxiv.org/abs/2310.11301v1"},"cats":{"benchmark":0.163221576,"new-dataset":0.0811695786,"data-annotation":0.52472398,"dev-research":0.5732604893,"llms":0.5553704323,"data-quality":0.2274433259}}
{"text":"Instead, in primary research on code comprehension, an implicit definition by task prevails, i.e., code comprehension is what the experimental tasks measure.","meta":{"url":"http://arxiv.org/abs/2310.11301v1"},"cats":{"benchmark":0.3207772752,"new-dataset":0.0168702502,"data-annotation":0.5354009159,"dev-research":0.3988417077,"llms":0.5228683571,"data-quality":0.1939927235}}
{"text":"This approach has two negative consequences.","meta":{"url":"http://arxiv.org/abs/2310.11301v1"},"cats":{"benchmark":0.3574200549,"new-dataset":0.0038886974,"data-annotation":0.5230605338,"dev-research":0.261348035,"llms":0.5003741043,"data-quality":0.1872364642}}
{"text":"First, it makes it difficult to conduct secondary research.","meta":{"url":"http://arxiv.org/abs/2310.11301v1"},"cats":{"benchmark":0.2977025232,"new-dataset":0.0044815949,"data-annotation":0.5081166669,"dev-research":0.1824717334,"llms":0.5773901646,"data-quality":0.0922107613}}
{"text":"Currently, each code comprehension primary study uses different comprehension tasks and measures, and thus it is not clear whether different studies intend to measure the same construct.","meta":{"url":"http://arxiv.org/abs/2310.11301v1"},"cats":{"benchmark":0.3503003604,"new-dataset":0.0189684556,"data-annotation":0.5067545854,"dev-research":0.3061163481,"llms":0.5488728407,"data-quality":0.144393067}}
{"text":"Second, authors of a primary study run into the difficulty of justifying their design decisions without a definition of what they attempt to measure.","meta":{"url":"http://arxiv.org/abs/2310.11301v1"},"cats":{"benchmark":0.4669328163,"new-dataset":0.0030310385,"data-annotation":0.5165333262,"dev-research":0.3841785578,"llms":0.5164133387,"data-quality":0.1409287876}}
{"text":"An operationalization of an insufficiently described construct occurs, which poses a threat to construct validity.   ","meta":{"url":"http://arxiv.org/abs/2310.11301v1"},"cats":{"benchmark":0.1975062759,"new-dataset":0.0087826194,"data-annotation":0.5178772065,"dev-research":0.4117898556,"llms":0.5524125496,"data-quality":0.1899436309}}
{"text":"The task of defining code comprehension considering the theory of the past fifty years is not an easy one.","meta":{"url":"http://arxiv.org/abs/2310.11301v1"},"cats":{"benchmark":0.1928540844,"new-dataset":0.0205418502,"data-annotation":0.528624967,"dev-research":0.415687641,"llms":0.5512675414,"data-quality":0.1910120514}}
{"text":"Nor is it a task that every author of a primary study must accomplish on their own.","meta":{"url":"http://arxiv.org/abs/2310.11301v1"},"cats":{"benchmark":0.3125052913,"new-dataset":0.0070343764,"data-annotation":0.5045751617,"dev-research":0.2401562526,"llms":0.5111600326,"data-quality":0.0855405821}}
{"text":"Therefore, this paper constitutes a reference work that defines source code comprehension and presents a conceptual framework in which researchers can anchor their empirical code comprehension research.","meta":{"url":"http://arxiv.org/abs/2310.11301v1"},"cats":{"benchmark":0.1820943112,"new-dataset":0.1401301634,"data-annotation":0.5179742921,"dev-research":0.6464404455,"llms":0.5708206003,"data-quality":0.2700064402}}
{"text":"Speech-driven 3D facial animation is a challenging cross-modal task that has attracted growing research interest.","meta":{"url":"http://arxiv.org/abs/2310.11295v1"},"cats":{"benchmark":0.2561278129,"new-dataset":0.0888087665,"data-annotation":0.504545466,"dev-research":0.1769808753,"llms":0.4943353966,"data-quality":0.0578490474}}
{"text":"During speaking activities, the mouth displays strong motions, while the other facial regions typically demonstrate comparatively weak activity levels.","meta":{"url":"http://arxiv.org/abs/2310.11295v1"},"cats":{"benchmark":0.2931904889,"new-dataset":0.0155705311,"data-annotation":0.5180140609,"dev-research":0.1650914695,"llms":0.5287478917,"data-quality":0.0792759823}}
{"text":"Existing approaches often simplify the process by directly mapping single-level speech features to the entire facial animation, which overlook the differences in facial activity intensity leading to overly smoothed facial movements.","meta":{"url":"http://arxiv.org/abs/2310.11295v1"},"cats":{"benchmark":0.3530530916,"new-dataset":0.0509839283,"data-annotation":0.5116122773,"dev-research":0.1807648839,"llms":0.432745671,"data-quality":0.0865710807}}
{"text":"In this study, we propose a novel framework, CorrTalk, which effectively establishes the temporal correlation between hierarchical speech features and facial activities of different intensities across distinct regions.","meta":{"url":"http://arxiv.org/abs/2310.11295v1"},"cats":{"benchmark":0.2634010821,"new-dataset":0.1670916516,"data-annotation":0.5063385765,"dev-research":0.208203672,"llms":0.4324655653,"data-quality":0.1067499739}}
{"text":"A novel facial activity intensity metric is defined to distinguish between strong and weak facial activity, obtained by computing the short-time Fourier transform of facial vertex displacements.","meta":{"url":"http://arxiv.org/abs/2310.11295v1"},"cats":{"benchmark":0.4473277239,"new-dataset":0.039262439,"data-annotation":0.5237521127,"dev-research":0.1604152588,"llms":0.3711922828,"data-quality":0.0618278917}}
{"text":"Based on the variances in facial activity, we propose a dual-branch decoding framework to synchronously synthesize strong and weak facial activity, which guarantees wider intensity facial animation synthesis.","meta":{"url":"http://arxiv.org/abs/2310.11295v1"},"cats":{"benchmark":0.2350894515,"new-dataset":0.0728484631,"data-annotation":0.5036931,"dev-research":0.2200358177,"llms":0.4642889486,"data-quality":0.0505400728}}
{"text":"Furthermore, a weighted hierarchical feature encoder is proposed to establish temporal correlation between hierarchical speech features and facial activity at different intensities, which ensures lip-sync and plausible facial expressions.","meta":{"url":"http://arxiv.org/abs/2310.11295v1"},"cats":{"benchmark":0.3873128011,"new-dataset":0.0731600983,"data-annotation":0.5044616689,"dev-research":0.1842734228,"llms":0.3999896366,"data-quality":0.0951857915}}
{"text":"Extensive qualitatively and quantitatively experiments as well as a user study indicate that our CorrTalk outperforms existing state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2310.11295v1"},"cats":{"benchmark":0.3677566568,"new-dataset":0.0370935833,"data-annotation":0.5059470933,"dev-research":0.2926453646,"llms":0.5087849956,"data-quality":0.117660696}}
{"text":"The source code and supplementary video are publicly available at: https://zjchu.github.io/projects/CorrTalk/","meta":{"url":"http://arxiv.org/abs/2310.11295v1"},"cats":{"benchmark":0.1913436063,"new-dataset":0.6344604377,"data-annotation":0.5082994216,"dev-research":0.243873668,"llms":0.5312974224,"data-quality":0.1011941529}}
{"text":"Federated Byzantine Agreement Systems (FBASs) offer a solution to consensus in permissionless systems by adapting the well-studied Byzantine agreement model to permissionless consensus.","meta":{"url":"http://arxiv.org/abs/2310.11294v1"},"cats":{"benchmark":0.320386407,"new-dataset":0.0589160593,"data-annotation":0.4768266966,"dev-research":0.1458213867,"llms":0.5458383458,"data-quality":0.088234088}}
{"text":"Unlike its counterparts in the context of permissionless consensus, the FBAS system model does not offer validating nodes protocol-level incentives although they are entrusted with safeguarding and ensuring the functionality of the system.","meta":{"url":"http://arxiv.org/abs/2310.11294v1"},"cats":{"benchmark":0.3148989835,"new-dataset":0.0127147592,"data-annotation":0.4752116212,"dev-research":0.1766570752,"llms":0.5482737765,"data-quality":0.1104604915}}
{"text":"Multiple studies have reported on the small number of active validators in these systems leading to some concerns about their resilience.","meta":{"url":"http://arxiv.org/abs/2310.11294v1"},"cats":{"benchmark":0.4793107255,"new-dataset":0.0165654174,"data-annotation":0.5078149552,"dev-research":0.2905035396,"llms":0.5251110453,"data-quality":0.2104054289}}
{"text":"To this end, this paper studies how rewards can be distributed in FBASs and presents a fair reward distribution function for FBASs.","meta":{"url":"http://arxiv.org/abs/2310.11294v1"},"cats":{"benchmark":0.3139115973,"new-dataset":0.0770021172,"data-annotation":0.517504603,"dev-research":0.1093110677,"llms":0.4933750851,"data-quality":0.0847833804}}
{"text":"The challenge is that, on the one hand, consensus in an FBAS is found jointly between all nodes and, on the other hand, nodes do not all contribute equally to this process.","meta":{"url":"http://arxiv.org/abs/2310.11294v1"},"cats":{"benchmark":0.4170661232,"new-dataset":0.0432962555,"data-annotation":0.4873201108,"dev-research":0.1981501776,"llms":0.514097645,"data-quality":0.1906154505}}
{"text":"We draw on game-theoretic methods to quantify these contributions bearing the overall health of the FBAS in mind and present a fair reward distribution function which we evaluate based on a set of identified properties.","meta":{"url":"http://arxiv.org/abs/2310.11294v1"},"cats":{"benchmark":0.3929774275,"new-dataset":0.0682526514,"data-annotation":0.5409509902,"dev-research":0.1288912114,"llms":0.4551737324,"data-quality":0.0879310005}}
{"text":"The delta-bar-delta algorithm is recognized as a learning rate adaptation technique that enhances the convergence speed of the training process in optimization by dynamically scheduling the learning rate based on the difference between the current and previous weight updates.","meta":{"url":"http://arxiv.org/abs/2310.11291v1"},"cats":{"benchmark":0.5150755903,"new-dataset":0.0072684716,"data-annotation":0.5139691283,"dev-research":0.1667037643,"llms":0.4265811488,"data-quality":0.1383516146}}
{"text":"While this algorithm has demonstrated strong competitiveness in full data optimization when compared to other state-of-the-art algorithms like Adam and SGD, it may encounter convergence issues in mini-batch optimization scenarios due to the presence of noisy gradients.   ","meta":{"url":"http://arxiv.org/abs/2310.11291v1"},"cats":{"benchmark":0.5451922128,"new-dataset":0.025709848,"data-annotation":0.51217676,"dev-research":0.0958879686,"llms":0.3903034839,"data-quality":0.1467903063}}
{"text":"In this study, we thoroughly investigate the convergence behavior of the delta-bar-delta algorithm in real-world neural network optimization.","meta":{"url":"http://arxiv.org/abs/2310.11291v1"},"cats":{"benchmark":0.5022909765,"new-dataset":0.0063487383,"data-annotation":0.5222429257,"dev-research":0.1451656729,"llms":0.3889086002,"data-quality":0.1323061899}}
{"text":"To address any potential convergence challenges, we propose a novel approach called RDBD (Regrettable Delta-Bar-Delta).","meta":{"url":"http://arxiv.org/abs/2310.11291v1"},"cats":{"benchmark":0.5630098902,"new-dataset":0.0277228528,"data-annotation":0.47777364,"dev-research":0.1560204102,"llms":0.5245660918,"data-quality":0.1069502424}}
{"text":"Our approach allows for prompt correction of biased learning rate adjustments and ensures the convergence of the optimization process.","meta":{"url":"http://arxiv.org/abs/2310.11291v1"},"cats":{"benchmark":0.6096509809,"new-dataset":0.0060784644,"data-annotation":0.5155963595,"dev-research":0.1803769826,"llms":0.4091586056,"data-quality":0.2671591834}}
{"text":"Furthermore, we demonstrate that RDBD can be seamlessly integrated with any optimization algorithm and significantly improve the convergence speed.   ","meta":{"url":"http://arxiv.org/abs/2310.11291v1"},"cats":{"benchmark":0.5122505837,"new-dataset":0.0451311088,"data-annotation":0.4774049277,"dev-research":0.2089064434,"llms":0.529189636,"data-quality":0.0667963833}}
{"text":"By conducting extensive experiments and evaluations, we validate the effectiveness and efficiency of our proposed RDBD approach.","meta":{"url":"http://arxiv.org/abs/2310.11291v1"},"cats":{"benchmark":0.6239443145,"new-dataset":0.0160637759,"data-annotation":0.4807477325,"dev-research":0.1893985983,"llms":0.5303696361,"data-quality":0.1055452168}}
{"text":"The results showcase its capability to overcome convergence issues in mini-batch optimization and its potential to enhance the convergence speed of various optimization algorithms.","meta":{"url":"http://arxiv.org/abs/2310.11291v1"},"cats":{"benchmark":0.5642729468,"new-dataset":0.0053689931,"data-annotation":0.5090996219,"dev-research":0.127658008,"llms":0.4127900678,"data-quality":0.1235920471}}
{"text":"This research contributes to the advancement of optimization techniques in neural network training, providing practitioners with a reliable automatic learning rate scheduler for achieving faster convergence and improved optimization outcomes.","meta":{"url":"http://arxiv.org/abs/2310.11291v1"},"cats":{"benchmark":0.4516780946,"new-dataset":0.0131837789,"data-annotation":0.5098708188,"dev-research":0.182736284,"llms":0.4304822832,"data-quality":0.1253720873}}
{"text":"This study investigates formal-method-based trajectory optimization (TO) for bipedal locomotion, focusing on scenarios where the robot encounters external perturbations at unforeseen times.","meta":{"url":"http://arxiv.org/abs/2310.11290v1"},"cats":{"benchmark":0.4075127844,"new-dataset":0.0174692428,"data-annotation":0.5026909546,"dev-research":0.2258005101,"llms":0.4338343364,"data-quality":0.0614373342}}
{"text":"Our key research question centers around the assurance of task specification correctness and the maximization of specification robustness for a bipedal robot in the presence of external perturbations.   ","meta":{"url":"http://arxiv.org/abs/2310.11290v1"},"cats":{"benchmark":0.3659848411,"new-dataset":0.0497091394,"data-annotation":0.4987845976,"dev-research":0.2841965297,"llms":0.4553288562,"data-quality":0.1490323764}}
{"text":"Our contribution includes the design of an optimization-based task and motion planning framework that generates optimal control sequences with formal guarantees of external perturbation recovery.","meta":{"url":"http://arxiv.org/abs/2310.11290v1"},"cats":{"benchmark":0.3575488669,"new-dataset":0.0776874943,"data-annotation":0.4904993484,"dev-research":0.2146033142,"llms":0.4444322111,"data-quality":0.0499586943}}
{"text":"As a core component of the framework, a model predictive controller (MPC) encodes signal temporal logic (STL)-based task specifications as a cost function.","meta":{"url":"http://arxiv.org/abs/2310.11290v1"},"cats":{"benchmark":0.2835775484,"new-dataset":0.0375449742,"data-annotation":0.5000859715,"dev-research":0.231906298,"llms":0.4660906355,"data-quality":0.045712038}}
{"text":"In particular, we investigate challenging scenarios where the robot is subjected to lateral perturbations that increase the risk of failure due to leg self-collision.","meta":{"url":"http://arxiv.org/abs/2310.11290v1"},"cats":{"benchmark":0.3408811738,"new-dataset":0.0527178438,"data-annotation":0.5321059342,"dev-research":0.232238057,"llms":0.4869288318,"data-quality":0.1562164531}}
{"text":"To address this, we synthesize agile and safe crossed-leg maneuvers to enhance locomotion stability.   ","meta":{"url":"http://arxiv.org/abs/2310.11290v1"},"cats":{"benchmark":0.2476859012,"new-dataset":0.0637414543,"data-annotation":0.4929275904,"dev-research":0.2858015795,"llms":0.5316138679,"data-quality":0.0399144032}}
{"text":"This work marks the first study to incorporate formal guarantees offered by STL into a TO for perturbation recovery of bipedal locomotion.","meta":{"url":"http://arxiv.org/abs/2310.11290v1"},"cats":{"benchmark":0.3735942462,"new-dataset":0.0168303292,"data-annotation":0.4927780319,"dev-research":0.1886573924,"llms":0.5010012934,"data-quality":0.0709488364}}
{"text":"We demonstrate the efficacy of the framework via perturbation experiments in simulations.","meta":{"url":"http://arxiv.org/abs/2310.11290v1"},"cats":{"benchmark":0.4563447127,"new-dataset":0.0064396147,"data-annotation":0.5133105736,"dev-research":0.1555148814,"llms":0.4536135594,"data-quality":0.0889309646}}
{"text":"In this paper, we extend diagrammatic reasoning in monoidal categories with algebraic operations and equations.","meta":{"url":"http://arxiv.org/abs/2310.11288v1"},"cats":{"benchmark":0.1839521137,"new-dataset":0.0246989404,"data-annotation":0.5338065096,"dev-research":0.3314250274,"llms":0.5350805647,"data-quality":0.0894520062}}
{"text":"We achieve this by considering monoidal categories that are enriched in the category of Eilenberg-Moore algebras for a monad.","meta":{"url":"http://arxiv.org/abs/2310.11288v1"},"cats":{"benchmark":0.2135209917,"new-dataset":0.0479031901,"data-annotation":0.5382546583,"dev-research":0.1508749555,"llms":0.5520065485,"data-quality":0.0946600633}}
{"text":"Under the condition that this monad is monoidal and affine, we construct an adjunction between symmetric monoidal categories and symmetric monoidal categories enriched over algebras for the monad.","meta":{"url":"http://arxiv.org/abs/2310.11288v1"},"cats":{"benchmark":0.2161433992,"new-dataset":0.0420749075,"data-annotation":0.5365451083,"dev-research":0.1678003369,"llms":0.5388010844,"data-quality":0.0931624224}}
{"text":"This allows us to devise an extension, and its semantics, of the ZX-calculus with probabilistic choices by freely enriching over convex algebras, which are the algebras of the finite distribution monad.","meta":{"url":"http://arxiv.org/abs/2310.11288v1"},"cats":{"benchmark":0.2290715036,"new-dataset":0.0079046265,"data-annotation":0.5251684652,"dev-research":0.1686482059,"llms":0.5439731112,"data-quality":0.0738050052}}
{"text":"We show how this construction can be used for diagrammatic reasoning of noise in quantum systems.","meta":{"url":"http://arxiv.org/abs/2310.11288v1"},"cats":{"benchmark":0.260253558,"new-dataset":0.043546756,"data-annotation":0.5308357816,"dev-research":0.2777893231,"llms":0.5327799136,"data-quality":0.1973331665}}
{"text":"In the face of climate change-induced droughts, vulnerable regions encounter severe threats to food security, demanding urgent humanitarian assistance.","meta":{"url":"http://arxiv.org/abs/2310.11287v1"},"cats":{"benchmark":0.2414985409,"new-dataset":0.2622012228,"data-annotation":0.498632377,"dev-research":0.2308115512,"llms":0.5410135305,"data-quality":0.1101175867}}
{"text":"This paper introduces a causal inference framework for the Horn of Africa, aiming to assess the impact of cash-based interventions on food crises.","meta":{"url":"http://arxiv.org/abs/2310.11287v1"},"cats":{"benchmark":0.2849468698,"new-dataset":0.1129921827,"data-annotation":0.5053559516,"dev-research":0.2343165259,"llms":0.432627623,"data-quality":0.1624591357}}
{"text":"Our contributions encompass identifying causal relationships within the food security system, harmonizing a comprehensive database, and estimating the causal effect of humanitarian interventions on malnutrition.","meta":{"url":"http://arxiv.org/abs/2310.11287v1"},"cats":{"benchmark":0.3503082741,"new-dataset":0.1030836695,"data-annotation":0.5129331755,"dev-research":0.2044687216,"llms":0.4591278266,"data-quality":0.1050043504}}
{"text":"Our results revealed no significant effects, likely due to limited sample size, suboptimal data quality, and an imperfect causal graph resulting from our limited understanding of multidisciplinary systems like food security.","meta":{"url":"http://arxiv.org/abs/2310.11287v1"},"cats":{"benchmark":0.4099606134,"new-dataset":0.0517041761,"data-annotation":0.4860468462,"dev-research":0.1296878456,"llms":0.4506783809,"data-quality":0.1598777085}}
{"text":"This underscores the need to enhance data collection and refine causal models with domain experts for more effective future interventions and policies, improving transparency and accountability in humanitarian aid.","meta":{"url":"http://arxiv.org/abs/2310.11287v1"},"cats":{"benchmark":0.2896525472,"new-dataset":0.1767213792,"data-annotation":0.4863607721,"dev-research":0.2677180396,"llms":0.5132894429,"data-quality":0.110006131}}
{"text":"Optimum distance flag codes (ODFCs), as special flag codes, have received a lot of attention due to its application in random network coding.","meta":{"url":"http://arxiv.org/abs/2310.11285v1"},"cats":{"benchmark":0.4039537979,"new-dataset":0.0967924087,"data-annotation":0.5230068635,"dev-research":0.2051301275,"llms":0.5426950539,"data-quality":0.1757307405}}
{"text":"In 2021, Alonso-Gonz\\'{a}lez et al. constructed optimal $(n,\\mathcal{A})$-ODFC for $\\mathcal {A}\\subseteq \\{1,2,\\ldots,k,n-k,\\ldots,n-1\\}$ with $k\\in \\mathcal A$ and $k|n$. In this paper, we introduce a new construction of $(n,\\mathcal A)_q$-ODFCs by maximum rank-metric codes.","meta":{"url":"http://arxiv.org/abs/2310.11285v1"},"cats":{"benchmark":0.497358484,"new-dataset":0.1840438496,"data-annotation":0.5436506828,"dev-research":0.1443269494,"llms":0.4339078914,"data-quality":0.1220359202}}
{"text":"It is proved that there is an $(n,\\mathcal{A})$-ODFC of size $\\frac{q^n-q^{k+r}}{q^k-1}+1$ for any $\\mathcal{A}\\subseteq\\{1,2,\\ldots,k,n-k,\\ldots,n-1\\}$ with $\\mathcal A\\cap \\{k,n-k\\}\\neq\\emptyset$, where $r\\equiv n\\pmod k$ and $0\\leq r<k$.","meta":{"url":"http://arxiv.org/abs/2310.11285v1"},"cats":{"benchmark":0.3844939961,"new-dataset":0.4392211327,"data-annotation":0.5324160089,"dev-research":0.113694266,"llms":0.5120391712,"data-quality":0.0906559842}}
{"text":"Furthermore, when $k>\\frac{q^r-1}{q-1}$, this $(n,\\mathcal A)_q$-ODFC is optimal.","meta":{"url":"http://arxiv.org/abs/2310.11285v1"},"cats":{"benchmark":0.5118827788,"new-dataset":0.1122633365,"data-annotation":0.5410323118,"dev-research":0.0864831715,"llms":0.4126218319,"data-quality":0.0812752148}}
{"text":"Specially, when $r=0$, Alonso-Gonz\\'{a}lez et al.'s result is also obtained.","meta":{"url":"http://arxiv.org/abs/2310.11285v1"},"cats":{"benchmark":0.4584773485,"new-dataset":0.0518420926,"data-annotation":0.5282641811,"dev-research":0.1094888083,"llms":0.4229376385,"data-quality":0.0892978146}}
{"text":"The hyperbolicity of a graph, informally, measures how close a graph is (metrically) to a tree.","meta":{"url":"http://arxiv.org/abs/2310.11283v1"},"cats":{"benchmark":0.3860406127,"new-dataset":0.0218298367,"data-annotation":0.5159999746,"dev-research":0.2268011139,"llms":0.4310279428,"data-quality":0.1330548041}}
{"text":"Hence, it is intuitively similar to treewidth, but the measures are formally incomparable.","meta":{"url":"http://arxiv.org/abs/2310.11283v1"},"cats":{"benchmark":0.4372659247,"new-dataset":0.0075892185,"data-annotation":0.5116082742,"dev-research":0.176357675,"llms":0.4578932124,"data-quality":0.1204092414}}
{"text":"Motivated by the broad study of algorithms and separators on planar graphs and their relation to treewidth, we initiate the study of planar graphs of bounded hyperbolicity.   ","meta":{"url":"http://arxiv.org/abs/2310.11283v1"},"cats":{"benchmark":0.2864252013,"new-dataset":0.0529384875,"data-annotation":0.5140460822,"dev-research":0.1716355805,"llms":0.4601873576,"data-quality":0.0768528321}}
{"text":"Our main technical contribution is a novel balanced separator theorem for planar $\\delta$-hyperbolic graphs that is substantially stronger than the classic planar separator theorem.","meta":{"url":"http://arxiv.org/abs/2310.11283v1"},"cats":{"benchmark":0.3761559552,"new-dataset":0.0326174895,"data-annotation":0.4957913366,"dev-research":0.1403465085,"llms":0.5023331123,"data-quality":0.1358153417}}
{"text":"For any fixed $\\delta \\geq 0$, we can find balanced separator that induces either a single geodesic (shortest) path or a single geodesic cycle in the graph.   ","meta":{"url":"http://arxiv.org/abs/2310.11283v1"},"cats":{"benchmark":0.4215036144,"new-dataset":0.0245543815,"data-annotation":0.5043945781,"dev-research":0.0971766887,"llms":0.4712704422,"data-quality":0.1705507957}}
{"text":"An important advantage of our separator is that the union of our separator (vertex set $Z$) with any subset of the connected components of $G - Z$ induces again a planar $\\delta$-hyperbolic graph, which would not be guaranteed with an arbitrary separator.","meta":{"url":"http://arxiv.org/abs/2310.11283v1"},"cats":{"benchmark":0.3304025336,"new-dataset":0.0109750916,"data-annotation":0.4890826277,"dev-research":0.1511377721,"llms":0.5118987278,"data-quality":0.1313296164}}
{"text":"Our construction runs in near-linear time and guarantees that size of separator is $\\mathrm{poly}(\\delta) \\cdot \\log n$. As an application of our separator theorem and its strong properties, we obtain two novel approximation schemes on planar $\\delta$-hyperbolic graphs.","meta":{"url":"http://arxiv.org/abs/2310.11283v1"},"cats":{"benchmark":0.3846915308,"new-dataset":0.0305822093,"data-annotation":0.5110637735,"dev-research":0.180060343,"llms":0.4515689887,"data-quality":0.117763815}}
{"text":"We prove that Maximum Independent Set and the Traveling Salesperson problem have a near-linear time FPTAS for any constant $\\delta$, running in $n\\, \\mathrm{polylog}(n) \\cdot 2^{\\mathcal{O}(\\delta^2)}","meta":{"url":"http://arxiv.org/abs/2310.11283v1"},"cats":{"benchmark":0.3716040098,"new-dataset":0.2475434681,"data-annotation":0.5481445233,"dev-research":0.1386783698,"llms":0.4287706583,"data-quality":0.1144464694}}
{"text":"\\cdot \\varepsilon^{-\\mathcal{O}(\\delta)}$ time.   ","meta":{"url":"http://arxiv.org/abs/2310.11283v1"},"cats":{"benchmark":0.3955566802,"new-dataset":0.027054092,"data-annotation":0.5209064258,"dev-research":0.2096932596,"llms":0.5091511498,"data-quality":0.1344784127}}
{"text":"We also show that our approximation scheme for Maximum Independent Set has essentially the best possible running time under the Exponential Time Hypothesis (ETH).","meta":{"url":"http://arxiv.org/abs/2310.11283v1"},"cats":{"benchmark":0.5281753708,"new-dataset":0.1173352685,"data-annotation":0.5349972903,"dev-research":0.1260901119,"llms":0.3941488485,"data-quality":0.076532771}}
{"text":"This immediately follows from our third contribution: we prove that Maximum Independent Set has no $n^{o(\\delta)}$-time algorithm on planar $\\delta$-hyperbolic graphs, unless ETH fails.","meta":{"url":"http://arxiv.org/abs/2310.11283v1"},"cats":{"benchmark":0.3524386547,"new-dataset":0.1807867733,"data-annotation":0.5244504479,"dev-research":0.1165853011,"llms":0.4713802246,"data-quality":0.0960468505}}
{"text":"In this article, we investigate self-supervised 3D scene flow estimation and class-agnostic motion prediction on point clouds.","meta":{"url":"http://arxiv.org/abs/2310.11284v1"},"cats":{"benchmark":0.247851933,"new-dataset":0.1691263606,"data-annotation":0.519584428,"dev-research":0.1532750814,"llms":0.4410953576,"data-quality":0.0977345277}}
{"text":"A realistic scene can be well modeled as a collection of rigidly moving parts, therefore its scene flow can be represented as a combination of the rigid motion of these individual parts.","meta":{"url":"http://arxiv.org/abs/2310.11284v1"},"cats":{"benchmark":0.1829704167,"new-dataset":0.1459002227,"data-annotation":0.5111329403,"dev-research":0.1879060095,"llms":0.4256809719,"data-quality":0.0592361651}}
{"text":"Building upon this observation, we propose to generate pseudo scene flow labels for self-supervised learning through piecewise rigid motion estimation, in which the source point cloud is decomposed into local regions and each region is treated as rigid.","meta":{"url":"http://arxiv.org/abs/2310.11284v1"},"cats":{"benchmark":0.2133306331,"new-dataset":0.3468521862,"data-annotation":0.5109744236,"dev-research":0.1503339962,"llms":0.4336206454,"data-quality":0.2318362823}}
{"text":"By rigidly aligning each region with its potential counterpart in the target point cloud, we obtain a region-specific rigid transformation to generate its pseudo flow labels.","meta":{"url":"http://arxiv.org/abs/2310.11284v1"},"cats":{"benchmark":0.2568685384,"new-dataset":0.1302356941,"data-annotation":0.4958301359,"dev-research":0.1098857757,"llms":0.4703482559,"data-quality":0.1102347586}}
{"text":"To mitigate the impact of potential outliers on label generation, when solving the rigid registration for each region, we alternately perform three steps: establishing point correspondences, measuring the confidence for the correspondences, and updating the rigid transformation based on the correspondences and their confidence.","meta":{"url":"http://arxiv.org/abs/2310.11284v1"},"cats":{"benchmark":0.4485286177,"new-dataset":0.1440044738,"data-annotation":0.5159124525,"dev-research":0.1543407803,"llms":0.4891759675,"data-quality":0.5161118426}}
{"text":"As a result, confident correspondences will dominate label generation and a validity mask will be derived for the generated pseudo labels.","meta":{"url":"http://arxiv.org/abs/2310.11284v1"},"cats":{"benchmark":0.3705932105,"new-dataset":0.0595351993,"data-annotation":0.5101487099,"dev-research":0.1424137704,"llms":0.5425377601,"data-quality":0.5297290063}}
{"text":"By using the pseudo labels together with their validity mask for supervision, models can be trained in a self-supervised manner.","meta":{"url":"http://arxiv.org/abs/2310.11284v1"},"cats":{"benchmark":0.238646897,"new-dataset":0.0455527668,"data-annotation":0.5236642564,"dev-research":0.1986887815,"llms":0.5041579698,"data-quality":0.4069288485}}
{"text":"Extensive experiments on FlyingThings3D and KITTI datasets demonstrate that our method achieves new state-of-the-art performance in self-supervised scene flow learning, without any ground truth scene flow for supervision, even performing better than some supervised counterparts.","meta":{"url":"http://arxiv.org/abs/2310.11284v1"},"cats":{"benchmark":0.2042617808,"new-dataset":0.3185769554,"data-annotation":0.5180563263,"dev-research":0.1675312495,"llms":0.5766400297,"data-quality":0.1643981526}}
{"text":"Additionally, our method is further extended to class-agnostic motion prediction and significantly outperforms previous state-of-the-art self-supervised methods on nuScenes dataset.","meta":{"url":"http://arxiv.org/abs/2310.11284v1"},"cats":{"benchmark":0.3006615996,"new-dataset":0.2503172705,"data-annotation":0.5424957145,"dev-research":0.1241506834,"llms":0.4542888397,"data-quality":0.1460145698}}
{"text":"We present the submission of the ILLC at the University of Amsterdam to the BabyLM challenge (Warstadt et al., 2023), in the strict-small track.","meta":{"url":"http://arxiv.org/abs/2310.11282v1"},"cats":{"benchmark":0.3511569731,"new-dataset":0.3853299957,"data-annotation":0.5454184811,"dev-research":0.1004330385,"llms":0.4899034029,"data-quality":0.1889638562}}
{"text":"Our final model, ChapGTP, is a masked language model that was trained for 200 epochs, aided by a novel data augmentation technique called Automatic Task Formation.","meta":{"url":"http://arxiv.org/abs/2310.11282v1"},"cats":{"benchmark":0.221721039,"new-dataset":0.2556062714,"data-annotation":0.5251971221,"dev-research":0.18922045,"llms":0.5176073262,"data-quality":0.2175230241}}
{"text":"We discuss in detail the performance of this model on the three evaluation suites: BLiMP, (Super)GLUE, and MSGS.","meta":{"url":"http://arxiv.org/abs/2310.11282v1"},"cats":{"benchmark":0.5911771037,"new-dataset":0.0142528079,"data-annotation":0.4912865473,"dev-research":0.1354589914,"llms":0.5318180821,"data-quality":0.06020263}}
{"text":"Furthermore, we present a wide range of methods that were ultimately not included in the model, but may serve as inspiration for training LMs in low-resource settings.","meta":{"url":"http://arxiv.org/abs/2310.11282v1"},"cats":{"benchmark":0.3465447421,"new-dataset":0.0157478131,"data-annotation":0.5009072081,"dev-research":0.1175789156,"llms":0.6026400202,"data-quality":0.0970005443}}
{"text":"Graph representation learning has now become the de facto standard when handling graph-structured data, with the framework of message-passing graph neural networks (MPNN) being the most prevailing algorithmic tool.","meta":{"url":"http://arxiv.org/abs/2310.11281v1"},"cats":{"benchmark":0.2329066739,"new-dataset":0.15645238,"data-annotation":0.5121806283,"dev-research":0.188375612,"llms":0.476975673,"data-quality":0.2137492272}}
{"text":"Despite its popularity, the family of MPNNs suffers from several drawbacks such as transparency and expressivity.","meta":{"url":"http://arxiv.org/abs/2310.11281v1"},"cats":{"benchmark":0.27474711,"new-dataset":0.0332604606,"data-annotation":0.5127797721,"dev-research":0.2175655762,"llms":0.5039081096,"data-quality":0.1925359426}}
{"text":"Recently, the idea of designing neural models on graphs using the theory of graph kernels has emerged as a more transparent as well as sometimes more expressive alternative to MPNNs known as kernel graph neural networks (KGNNs).","meta":{"url":"http://arxiv.org/abs/2310.11281v1"},"cats":{"benchmark":0.2226312282,"new-dataset":0.09351736,"data-annotation":0.5138390461,"dev-research":0.1651479007,"llms":0.4360020956,"data-quality":0.1643426703}}
{"text":"Developments on KGNNs are currently a nascent field of research, leaving several challenges from algorithmic design and adaptation to other learning paradigms such as self-supervised learning.","meta":{"url":"http://arxiv.org/abs/2310.11281v1"},"cats":{"benchmark":0.2150717174,"new-dataset":0.0680213856,"data-annotation":0.5312668351,"dev-research":0.1399080086,"llms":0.5275067504,"data-quality":0.1913009676}}
{"text":"In this paper, we improve the design and learning of KGNNs.","meta":{"url":"http://arxiv.org/abs/2310.11281v1"},"cats":{"benchmark":0.2609694475,"new-dataset":0.1878365416,"data-annotation":0.5310137775,"dev-research":0.1428250646,"llms":0.5473049522,"data-quality":0.1079423555}}
{"text":"Firstly, we extend the algorithmic formulation of KGNNs by allowing a more flexible graph-level similarity definition that encompasses former proposals like random walk graph kernel, as well as providing a smoother optimization objective that alleviates the need of introducing combinatorial learning procedures.","meta":{"url":"http://arxiv.org/abs/2310.11281v1"},"cats":{"benchmark":0.2860039059,"new-dataset":0.2103270705,"data-annotation":0.5339688676,"dev-research":0.1655977987,"llms":0.4785427298,"data-quality":0.1764662777}}
{"text":"Secondly, we enhance KGNNs through the lens of self-supervision via developing a novel structure-preserving graph data augmentation method called latent graph augmentation (LGA).","meta":{"url":"http://arxiv.org/abs/2310.11281v1"},"cats":{"benchmark":0.2122039878,"new-dataset":0.0828891888,"data-annotation":0.5147431817,"dev-research":0.1879487786,"llms":0.5238008477,"data-quality":0.2451180621}}
{"text":"Finally, we perform extensive empirical evaluations to demonstrate the efficacy of our proposed mechanisms.","meta":{"url":"http://arxiv.org/abs/2310.11281v1"},"cats":{"benchmark":0.5650774359,"new-dataset":0.0062118474,"data-annotation":0.4906657661,"dev-research":0.2558483557,"llms":0.4882033495,"data-quality":0.1297727142}}
{"text":"Experimental results over benchmark datasets suggest that our proposed model achieves competitive performance that is comparable to or sometimes outperforming state-of-the-art graph representation learning frameworks with or without self-supervision on graph classification tasks.","meta":{"url":"http://arxiv.org/abs/2310.11281v1"},"cats":{"benchmark":0.3104211948,"new-dataset":0.1159716422,"data-annotation":0.5216889688,"dev-research":0.1894635778,"llms":0.522836182,"data-quality":0.2888292558}}
{"text":"Comparisons against other previously established graph data augmentation methods verify that the proposed LGA augmentation scheme captures better semantics of graph-level invariance.","meta":{"url":"http://arxiv.org/abs/2310.11281v1"},"cats":{"benchmark":0.4131815722,"new-dataset":0.0315010089,"data-annotation":0.4966620856,"dev-research":0.1951717855,"llms":0.4686764278,"data-quality":0.2806936143}}
{"text":"Objective: To improve performance of medical entity normalization across many languages, especially when fewer language resources are available compared to English.   ","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.4864645896,"new-dataset":0.0575221832,"data-annotation":0.5068829435,"dev-research":0.2363181727,"llms":0.5111819906,"data-quality":0.2795513712}}
{"text":"Materials and Methods: We introduce xMEN, a modular system for cross-lingual medical entity normalization, which performs well in both low- and high-resource scenarios.","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.3524242883,"new-dataset":0.1138320202,"data-annotation":0.5001025535,"dev-research":0.2017605552,"llms":0.5713589673,"data-quality":0.2649477494}}
{"text":"When synonyms in the target language are scarce for a given terminology, we leverage English aliases via cross-lingual candidate generation.","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.3456180814,"new-dataset":0.1276443738,"data-annotation":0.538799603,"dev-research":0.2205771418,"llms":0.5966209729,"data-quality":0.2865289496}}
{"text":"For candidate ranking, we incorporate a trainable cross-encoder model if annotations for the target task are available.","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.4978353449,"new-dataset":0.0806782994,"data-annotation":0.5558342743,"dev-research":0.1681431902,"llms":0.5039561563,"data-quality":0.244304052}}
{"text":"We also evaluate cross-encoders trained in a weakly supervised manner based on machine-translated datasets from a high resource domain.","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.362466737,"new-dataset":0.2449980324,"data-annotation":0.5185478111,"dev-research":0.1430343163,"llms":0.5394794497,"data-quality":0.2840692177}}
{"text":"Our system is publicly available as an extensible Python toolkit.   ","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.2701599239,"new-dataset":0.3673560879,"data-annotation":0.5089477208,"dev-research":0.2514838357,"llms":0.5753777681,"data-quality":0.0951824806}}
{"text":"Results: xMEN improves the state-of-the-art performance across a wide range of multilingual benchmark datasets.","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.5210970701,"new-dataset":0.5008471485,"data-annotation":0.5238798308,"dev-research":0.2030265189,"llms":0.5389947706,"data-quality":0.2642135114}}
{"text":"Weakly supervised cross-encoders are effective when no training data is available for the target task.","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.3334678949,"new-dataset":0.0272901347,"data-annotation":0.511220048,"dev-research":0.1424124018,"llms":0.5240577505,"data-quality":0.2410311023}}
{"text":"Through the compatibility of xMEN with the BigBIO framework, it can be easily used with existing and prospective datasets.   ","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.297787095,"new-dataset":0.7000397276,"data-annotation":0.4783182959,"dev-research":0.1366373382,"llms":0.5708932705,"data-quality":0.068995794}}
{"text":"Discussion:","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.2276926292,"new-dataset":0.1260831376,"data-annotation":0.5229465897,"dev-research":0.2966395012,"llms":0.5891060476,"data-quality":0.174804436}}
{"text":"Our experiments show the importance of balancing the output of general-purpose candidate generators with subsequent trainable re-rankers, which we achieve through a rank regularization term in the loss function of the cross-encoder.","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.4710180177,"new-dataset":0.0152156775,"data-annotation":0.5512262653,"dev-research":0.1496119085,"llms":0.4995609905,"data-quality":0.1785155567}}
{"text":"However, error analysis reveals that multi-word expressions and other complex entities are still challenging.   ","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.4191307146,"new-dataset":0.0290100809,"data-annotation":0.5426532508,"dev-research":0.3675157437,"llms":0.4895924591,"data-quality":0.3965453317}}
{"text":"Conclusion: xMEN exhibits strong performance for medical entity normalization in multiple languages, even when no labeled data and few terminology aliases for the target language are available.","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.4069165143,"new-dataset":0.0665088141,"data-annotation":0.502124886,"dev-research":0.212460269,"llms":0.5671606376,"data-quality":0.3118709951}}
{"text":"Its configuration system and evaluation modules enable reproducible benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.7195392964,"new-dataset":0.1420699555,"data-annotation":0.4869213109,"dev-research":0.3103697198,"llms":0.5237640541,"data-quality":0.1154212073}}
{"text":"Models and code are available online at the following URL: https://github.com/hpi-dhc/xmen","meta":{"url":"http://arxiv.org/abs/2310.11275v1"},"cats":{"benchmark":0.2540009116,"new-dataset":0.2273091666,"data-annotation":0.5051272949,"dev-research":0.2047060004,"llms":0.5414126037,"data-quality":0.0780593688}}
{"text":"Graph neural networks (GNNs) have gained prominence in recommendation systems in recent years.","meta":{"url":"http://arxiv.org/abs/2310.11270v1"},"cats":{"benchmark":0.3025361131,"new-dataset":0.0738646725,"data-annotation":0.5315273147,"dev-research":0.1976487562,"llms":0.4519244999,"data-quality":0.159687379}}
{"text":"By representing the user-item matrix as a bipartite and undirected graph, GNNs have demonstrated their potential to capture short- and long-distance user-item interactions, thereby learning more accurate preference patterns than traditional recommendation approaches.","meta":{"url":"http://arxiv.org/abs/2310.11270v1"},"cats":{"benchmark":0.3036700951,"new-dataset":0.0352432156,"data-annotation":0.5256622846,"dev-research":0.178253605,"llms":0.4840710427,"data-quality":0.0930676194}}
{"text":"In contrast to previous tutorials on the same topic, this tutorial aims to present and examine three key aspects that characterize GNNs for recommendation: (i) the reproducibility of state-of-the-art approaches, (ii) the potential impact of graph topological characteristics on the performance of these models, and (iii) strategies for learning node representations when training features from scratch or utilizing pre-trained embeddings as additional item information (e.g., multimodal features).","meta":{"url":"http://arxiv.org/abs/2310.11270v1"},"cats":{"benchmark":0.2663536323,"new-dataset":0.070882611,"data-annotation":0.5433186666,"dev-research":0.2477794172,"llms":0.5114447396,"data-quality":0.1693182573}}
{"text":"The goal is to provide three novel theoretical and practical perspectives on the field, currently subject to debate in graph learning but long been overlooked in the context of recommendation systems.","meta":{"url":"http://arxiv.org/abs/2310.11270v1"},"cats":{"benchmark":0.3463653257,"new-dataset":0.0218319177,"data-annotation":0.5208892523,"dev-research":0.168053073,"llms":0.4477054698,"data-quality":0.223462126}}
{"text":"In response to the pressing need for advanced clinical problem-solving tools in healthcare, we introduce BooksMed, a novel framework based on a Large Language Model (LLM).","meta":{"url":"http://arxiv.org/abs/2310.11266v1"},"cats":{"benchmark":0.2513361433,"new-dataset":0.2697260234,"data-annotation":0.5113807554,"dev-research":0.3053312823,"llms":0.5644121321,"data-quality":0.0884042902}}
{"text":"BooksMed uniquely emulates human cognitive processes to deliver evidence-based and reliable responses, utilizing the GRADE (Grading of Recommendations, Assessment, Development, and Evaluations) framework to effectively quantify evidence strength.","meta":{"url":"http://arxiv.org/abs/2310.11266v1"},"cats":{"benchmark":0.4242448903,"new-dataset":0.0390767036,"data-annotation":0.5068113339,"dev-research":0.3068886342,"llms":0.5367758599,"data-quality":0.1287548575}}
{"text":"For clinical decision-making to be appropriately assessed, an evaluation metric that is clinically aligned and validated is required.","meta":{"url":"http://arxiv.org/abs/2310.11266v1"},"cats":{"benchmark":0.6731415602,"new-dataset":0.0095354594,"data-annotation":0.4852266756,"dev-research":0.3061461611,"llms":0.4751067821,"data-quality":0.1276967943}}
{"text":"As a solution, we present ExpertMedQA, a multispecialty clinical benchmark comprised of open-ended, expert-level clinical questions, and validated by a diverse group of medical professionals.","meta":{"url":"http://arxiv.org/abs/2310.11266v1"},"cats":{"benchmark":0.5780481511,"new-dataset":0.1732990773,"data-annotation":0.5009299769,"dev-research":0.2534099675,"llms":0.460032822,"data-quality":0.0771907854}}
{"text":"By demanding an in-depth understanding and critical appraisal of up-to-date clinical literature, ExpertMedQA rigorously evaluates LLM performance.","meta":{"url":"http://arxiv.org/abs/2310.11266v1"},"cats":{"benchmark":0.4612525989,"new-dataset":0.0245260242,"data-annotation":0.493522047,"dev-research":0.2175759908,"llms":0.710823789,"data-quality":0.0790838096}}
{"text":"BooksMed outperforms existing state-of-the-art models Med-PaLM 2, Almanac, and ChatGPT in a variety of medical scenarios.","meta":{"url":"http://arxiv.org/abs/2310.11266v1"},"cats":{"benchmark":0.3596736083,"new-dataset":0.3333732242,"data-annotation":0.5137695908,"dev-research":0.1938701031,"llms":0.5483796367,"data-quality":0.0694140485}}
{"text":"Therefore, a framework that mimics human cognitive stages could be a useful tool for providing reliable and evidence-based responses to clinical inquiries.","meta":{"url":"http://arxiv.org/abs/2310.11266v1"},"cats":{"benchmark":0.2532689201,"new-dataset":0.0233205553,"data-annotation":0.4893060551,"dev-research":0.3149630787,"llms":0.5276991211,"data-quality":0.1043930261}}
{"text":"Weak supervision has emerged as a promising approach for rapid and large-scale dataset creation in response to the increasing demand for accelerated NLP development.","meta":{"url":"http://arxiv.org/abs/2310.11258v1"},"cats":{"benchmark":0.306144873,"new-dataset":0.2300544235,"data-annotation":0.5047698351,"dev-research":0.263651005,"llms":0.4815076154,"data-quality":0.3425943335}}
{"text":"By leveraging labeling functions, weak supervision allows practitioners to generate datasets quickly by creating learned label models that produce soft-labeled datasets.","meta":{"url":"http://arxiv.org/abs/2310.11258v1"},"cats":{"benchmark":0.2989602592,"new-dataset":0.2587442576,"data-annotation":0.514975081,"dev-research":0.2624943427,"llms":0.506861954,"data-quality":0.5665114912}}
{"text":"This paper aims to show how such an approach can be utilized to build an Indonesian NLP dataset from conservation news text.","meta":{"url":"http://arxiv.org/abs/2310.11258v1"},"cats":{"benchmark":0.2415256711,"new-dataset":0.7042022858,"data-annotation":0.5184286022,"dev-research":0.2055272901,"llms":0.4820596039,"data-quality":0.2473521991}}
{"text":"We construct two types of datasets: multi-class classification and sentiment classification.","meta":{"url":"http://arxiv.org/abs/2310.11258v1"},"cats":{"benchmark":0.273115616,"new-dataset":0.465524918,"data-annotation":0.5332606392,"dev-research":0.1979858576,"llms":0.4621871856,"data-quality":0.3000834562}}
{"text":"We then provide baseline experiments using various pretrained language models.","meta":{"url":"http://arxiv.org/abs/2310.11258v1"},"cats":{"benchmark":0.4517692066,"new-dataset":0.0736086835,"data-annotation":0.5623711379,"dev-research":0.1870965952,"llms":0.5247936982,"data-quality":0.2419469697}}
{"text":"These baseline results demonstrate test performances of 59.79% accuracy and 55.72% F1-score for sentiment classification, 66.87% F1-score-macro, 71.5% F1-score-micro, and 83.67% ROC-AUC for multi-class classification.","meta":{"url":"http://arxiv.org/abs/2310.11258v1"},"cats":{"benchmark":0.6473622282,"new-dataset":0.1034508475,"data-annotation":0.5494241088,"dev-research":0.2070243523,"llms":0.4879747243,"data-quality":0.3418601812}}
{"text":"Additionally, we release the datasets and labeling functions used in this work for further research and exploration.","meta":{"url":"http://arxiv.org/abs/2310.11258v1"},"cats":{"benchmark":0.3320916517,"new-dataset":0.885220007,"data-annotation":0.5106308748,"dev-research":0.157364153,"llms":0.4920900066,"data-quality":0.3029432367}}
{"text":"Artificial intelligence has the potential to make valuable contributions to wildlife management through cost-effective methods for the collection and interpretation of wildlife data.","meta":{"url":"http://arxiv.org/abs/2310.11257v1"},"cats":{"benchmark":0.3007290754,"new-dataset":0.1853453012,"data-annotation":0.5067752155,"dev-research":0.1993851322,"llms":0.4471791911,"data-quality":0.132428848}}
{"text":"Recent advances in remotely piloted aircraft systems (RPAS or ``drones'') and thermal imaging technology have created new approaches to collect wildlife data.","meta":{"url":"http://arxiv.org/abs/2310.11257v1"},"cats":{"benchmark":0.2701705643,"new-dataset":0.2534194107,"data-annotation":0.4869978511,"dev-research":0.1389966693,"llms":0.4921100403,"data-quality":0.1312041802}}
{"text":"These emerging technologies could provide promising alternatives to standard labourious field techniques as well as cover much larger areas.","meta":{"url":"http://arxiv.org/abs/2310.11257v1"},"cats":{"benchmark":0.26197453,"new-dataset":0.0039045525,"data-annotation":0.4923532483,"dev-research":0.2215248188,"llms":0.5775154377,"data-quality":0.0459579657}}
{"text":"In this study, we conduct a comprehensive review and empirical study of drone-based wildlife detection.","meta":{"url":"http://arxiv.org/abs/2310.11257v1"},"cats":{"benchmark":0.341679913,"new-dataset":0.0662996262,"data-annotation":0.5298019552,"dev-research":0.1556043992,"llms":0.4865021225,"data-quality":0.184888747}}
{"text":"Specifically, we collect a realistic dataset of drone-derived wildlife thermal detections.","meta":{"url":"http://arxiv.org/abs/2310.11257v1"},"cats":{"benchmark":0.3453196781,"new-dataset":0.5816374162,"data-annotation":0.5218197142,"dev-research":0.1457607276,"llms":0.4803760593,"data-quality":0.1343846071}}
{"text":"Wildlife detections, including arboreal (for instance, koalas, phascolarctos cinereus) and ground dwelling species in our collected data are annotated via bounding boxes by experts.","meta":{"url":"http://arxiv.org/abs/2310.11257v1"},"cats":{"benchmark":0.3159354013,"new-dataset":0.4198027839,"data-annotation":0.5261902584,"dev-research":0.167005699,"llms":0.4843898344,"data-quality":0.2324559962}}
{"text":"We then benchmark state-of-the-art object detection algorithms on our collected dataset.","meta":{"url":"http://arxiv.org/abs/2310.11257v1"},"cats":{"benchmark":0.4180366485,"new-dataset":0.4086299513,"data-annotation":0.5298170371,"dev-research":0.1288506627,"llms":0.469040143,"data-quality":0.2088280723}}
{"text":"We use these experimental results to identify issues and discuss future directions in automatic animal monitoring using drones.","meta":{"url":"http://arxiv.org/abs/2310.11257v1"},"cats":{"benchmark":0.3156153556,"new-dataset":0.0723264851,"data-annotation":0.5189368724,"dev-research":0.2311223653,"llms":0.5302351654,"data-quality":0.2159447253}}
{"text":"The growing popularity of generative language models has amplified interest in interactive methods to guide model outputs.","meta":{"url":"http://arxiv.org/abs/2310.11252v1"},"cats":{"benchmark":0.1950367725,"new-dataset":0.067770061,"data-annotation":0.5291120636,"dev-research":0.3265675545,"llms":0.5346699875,"data-quality":0.1798072691}}
{"text":"Prompt refinement is considered one of the most effective means to influence output among these methods.","meta":{"url":"http://arxiv.org/abs/2310.11252v1"},"cats":{"benchmark":0.5139277804,"new-dataset":0.0053253054,"data-annotation":0.5147933828,"dev-research":0.3346811995,"llms":0.4607538642,"data-quality":0.1842762602}}
{"text":"We identify several challenges associated with prompting large language models, categorized into data- and model-specific, linguistic, and socio-linguistic challenges.","meta":{"url":"http://arxiv.org/abs/2310.11252v1"},"cats":{"benchmark":0.1681926484,"new-dataset":0.1417037419,"data-annotation":0.5235388154,"dev-research":0.280300572,"llms":0.543426568,"data-quality":0.2637523501}}
{"text":"A comprehensive examination of model outputs, including runner-up candidates and their corresponding probabilities, is needed to address these issues.","meta":{"url":"http://arxiv.org/abs/2310.11252v1"},"cats":{"benchmark":0.534568151,"new-dataset":0.0150041551,"data-annotation":0.5346733544,"dev-research":0.196419341,"llms":0.3995683515,"data-quality":0.1332525493}}
{"text":"The beam search tree, the prevalent algorithm to sample model outputs, can inherently supply this information.","meta":{"url":"http://arxiv.org/abs/2310.11252v1"},"cats":{"benchmark":0.3507178798,"new-dataset":0.0252055328,"data-annotation":0.5336031697,"dev-research":0.1184651666,"llms":0.421545678,"data-quality":0.106243796}}
{"text":"Consequently, we introduce an interactive visual method for investigating the beam search tree, facilitating analysis of the decisions made by the model during generation.","meta":{"url":"http://arxiv.org/abs/2310.11252v1"},"cats":{"benchmark":0.244571406,"new-dataset":0.0689345722,"data-annotation":0.5158135406,"dev-research":0.2702082889,"llms":0.5152952137,"data-quality":0.0531772505}}
{"text":"We quantitatively show the value of exposing the beam search tree and present five detailed analysis scenarios addressing the identified challenges.","meta":{"url":"http://arxiv.org/abs/2310.11252v1"},"cats":{"benchmark":0.3848303462,"new-dataset":0.0287788331,"data-annotation":0.511560806,"dev-research":0.1727863709,"llms":0.5309537458,"data-quality":0.1046599294}}
{"text":"Our methodology validates existing results and offers additional insights.","meta":{"url":"http://arxiv.org/abs/2310.11252v1"},"cats":{"benchmark":0.6372493149,"new-dataset":0.0197058353,"data-annotation":0.5069469619,"dev-research":0.3083987236,"llms":0.473163698,"data-quality":0.1384108628}}
{"text":"Hair editing has made tremendous progress in recent years.","meta":{"url":"http://arxiv.org/abs/2310.10651v1"},"cats":{"benchmark":0.3932074837,"new-dataset":0.0289008025,"data-annotation":0.4975682615,"dev-research":0.2765237593,"llms":0.540522525,"data-quality":0.0608389835}}
{"text":"Early hair editing methods use well-drawn sketches or masks to specify the editing conditions.","meta":{"url":"http://arxiv.org/abs/2310.10651v1"},"cats":{"benchmark":0.2829876344,"new-dataset":0.0096307738,"data-annotation":0.5161190547,"dev-research":0.3050824774,"llms":0.5071155157,"data-quality":0.0681451829}}
{"text":"Even though they can enable very fine-grained local control, such interaction modes are inefficient for the editing conditions that can be easily specified by language descriptions or reference images.","meta":{"url":"http://arxiv.org/abs/2310.10651v1"},"cats":{"benchmark":0.2347538919,"new-dataset":0.0147520921,"data-annotation":0.5151651244,"dev-research":0.3029566592,"llms":0.5676969144,"data-quality":0.1244090247}}
{"text":"Thanks to the recent breakthrough of cross-modal models (e.g., CLIP), HairCLIP is the first work that enables hair editing based on text descriptions or reference images.","meta":{"url":"http://arxiv.org/abs/2310.10651v1"},"cats":{"benchmark":0.3294021901,"new-dataset":0.0816525697,"data-annotation":0.5109788018,"dev-research":0.2304471201,"llms":0.4863981368,"data-quality":0.102580893}}
{"text":"However, such text-driven and reference-driven interaction modes make HairCLIP unable to support fine-grained controls specified by sketch or mask.","meta":{"url":"http://arxiv.org/abs/2310.10651v1"},"cats":{"benchmark":0.2286937049,"new-dataset":0.0105781961,"data-annotation":0.5019110854,"dev-research":0.2726962313,"llms":0.5407167395,"data-quality":0.1252185723}}
{"text":"In this paper, we propose HairCLIPv2, aiming to support all the aforementioned interactions with one unified framework.","meta":{"url":"http://arxiv.org/abs/2310.10651v1"},"cats":{"benchmark":0.3277080978,"new-dataset":0.1817917392,"data-annotation":0.5099492567,"dev-research":0.1997760656,"llms":0.4955558631,"data-quality":0.0773809078}}
{"text":"Simultaneously, it improves upon HairCLIP with better irrelevant attributes (e.g., identity, background) preservation and unseen text descriptions support.","meta":{"url":"http://arxiv.org/abs/2310.10651v1"},"cats":{"benchmark":0.3440856059,"new-dataset":0.0212439529,"data-annotation":0.5061081941,"dev-research":0.2631797738,"llms":0.5132401238,"data-quality":0.1485227098}}
{"text":"The key idea is to convert all the hair editing tasks into hair transfer tasks, with editing conditions converted into different proxies accordingly.","meta":{"url":"http://arxiv.org/abs/2310.10651v1"},"cats":{"benchmark":0.3554765767,"new-dataset":0.0170797279,"data-annotation":0.4741377395,"dev-research":0.212021326,"llms":0.5113205029,"data-quality":0.0862017739}}
{"text":"The editing effects are added upon the input image by blending the corresponding proxy features within the hairstyle or hair color feature spaces.","meta":{"url":"http://arxiv.org/abs/2310.10651v1"},"cats":{"benchmark":0.2580848354,"new-dataset":0.0293849812,"data-annotation":0.5063801352,"dev-research":0.2060642666,"llms":0.4573318177,"data-quality":0.0904769798}}
{"text":"Besides the unprecedented user interaction mode support, quantitative and qualitative experiments demonstrate the superiority of HairCLIPv2 in terms of editing effects, irrelevant attribute preservation and visual naturalness.","meta":{"url":"http://arxiv.org/abs/2310.10651v1"},"cats":{"benchmark":0.3121408078,"new-dataset":0.04314672,"data-annotation":0.5126720817,"dev-research":0.3460569159,"llms":0.4864798804,"data-quality":0.1047322244}}
{"text":"Our code is available at \\url{https://github.com/wty-ustc/HairCLIPv2}.","meta":{"url":"http://arxiv.org/abs/2310.10651v1"},"cats":{"benchmark":0.3116235271,"new-dataset":0.098216831,"data-annotation":0.5215715516,"dev-research":0.1630767097,"llms":0.4932695591,"data-quality":0.0953527683}}
{"text":"Implicit representations like Neural Radiance Fields (NeRF) showed impressive results for photorealistic rendering of complex scenes with fine details.","meta":{"url":"http://arxiv.org/abs/2310.10650v1"},"cats":{"benchmark":0.2453946883,"new-dataset":0.2004949501,"data-annotation":0.5242072206,"dev-research":0.207085327,"llms":0.4458684607,"data-quality":0.0955666976}}
{"text":"However, ideal or near-perfectly specular reflecting objects such as mirrors, which are often encountered in various indoor scenes, impose ambiguities and inconsistencies in the representation of the reconstructed scene leading to severe artifacts in the synthesized renderings.","meta":{"url":"http://arxiv.org/abs/2310.10650v1"},"cats":{"benchmark":0.3402227245,"new-dataset":0.0461983745,"data-annotation":0.507362976,"dev-research":0.2652817842,"llms":0.4647862533,"data-quality":0.1824996725}}
{"text":"In this paper, we present a novel reflection tracing method tailored for the involved volume rendering within NeRF that takes these mirror-like objects into account while avoiding the cost of straightforward but expensive extensions through standard path tracing.","meta":{"url":"http://arxiv.org/abs/2310.10650v1"},"cats":{"benchmark":0.4445418661,"new-dataset":0.0265600393,"data-annotation":0.5071728059,"dev-research":0.2353148912,"llms":0.5101100713,"data-quality":0.0830195146}}
{"text":"By explicitly modeling the reflection behavior using physically plausible materials and estimating the reflected radiance with Monte-Carlo methods within the volume rendering formulation, we derive efficient strategies for importance sampling and the transmittance computation along rays from only few samples.","meta":{"url":"http://arxiv.org/abs/2310.10650v1"},"cats":{"benchmark":0.4132078952,"new-dataset":0.0271186239,"data-annotation":0.5341819619,"dev-research":0.1399920676,"llms":0.4810487605,"data-quality":0.0411562467}}
{"text":"We show that our novel method enables the training of consistent representations of such challenging scenes and achieves superior results in comparison to previous state-of-the-art approaches.","meta":{"url":"http://arxiv.org/abs/2310.10650v1"},"cats":{"benchmark":0.3613970689,"new-dataset":0.1008868652,"data-annotation":0.53516606,"dev-research":0.1914385379,"llms":0.4335577706,"data-quality":0.2724677921}}
{"text":"The dynamical formulation of the optimal transport can be extended through various choices of the underlying geometry ($\\textit{kinetic energy}$), and the regularization of density paths ($\\textit{potential energy}$).","meta":{"url":"http://arxiv.org/abs/2310.10649v1"},"cats":{"benchmark":0.4134406199,"new-dataset":0.0077338724,"data-annotation":0.503892374,"dev-research":0.1442014988,"llms":0.4011286505,"data-quality":0.0469590208}}
{"text":"These combinations yield different variational problems ($\\textit{Lagrangians}$), encompassing many variations of the optimal transport problem such as the Schr\\\"odinger bridge, unbalanced optimal transport, and optimal transport with physical constraints, among others.","meta":{"url":"http://arxiv.org/abs/2310.10649v1"},"cats":{"benchmark":0.3591297694,"new-dataset":0.0090922986,"data-annotation":0.5119697137,"dev-research":0.1168213728,"llms":0.4690594716,"data-quality":0.0502404853}}
{"text":"In general, the optimal density path is unknown, and solving these variational problems can be computationally challenging.","meta":{"url":"http://arxiv.org/abs/2310.10649v1"},"cats":{"benchmark":0.4502705606,"new-dataset":0.0083147157,"data-annotation":0.5299909432,"dev-research":0.1138003476,"llms":0.3866698438,"data-quality":0.0653053516}}
{"text":"Leveraging the dual formulation of the Lagrangians, we propose a novel deep learning based framework approaching all of these problems from a unified perspective.","meta":{"url":"http://arxiv.org/abs/2310.10649v1"},"cats":{"benchmark":0.2473088353,"new-dataset":0.1265978378,"data-annotation":0.5318695091,"dev-research":0.1111947008,"llms":0.3999180313,"data-quality":0.1293806263}}
{"text":"Our method does not require simulating or backpropagating through the trajectories of the learned dynamics, and does not need access to optimal couplings.","meta":{"url":"http://arxiv.org/abs/2310.10649v1"},"cats":{"benchmark":0.3141965954,"new-dataset":0.0114779233,"data-annotation":0.5064821924,"dev-research":0.0876387215,"llms":0.4984476499,"data-quality":0.0542259003}}
{"text":"We showcase the versatility of the proposed framework by outperforming previous approaches for the single-cell trajectory inference, where incorporating prior knowledge into the dynamics is crucial for correct predictions.","meta":{"url":"http://arxiv.org/abs/2310.10649v1"},"cats":{"benchmark":0.3576133541,"new-dataset":0.067034024,"data-annotation":0.518007383,"dev-research":0.1026274755,"llms":0.3929740308,"data-quality":0.0653697876}}
{"text":"Scaling high-quality tutoring is a major challenge in education.","meta":{"url":"http://arxiv.org/abs/2310.10648v1"},"cats":{"benchmark":0.336732538,"new-dataset":0.020593015,"data-annotation":0.5387217546,"dev-research":0.229379422,"llms":0.5134730295,"data-quality":0.1121363265}}
{"text":"Because of the growing demand, many platforms employ novice tutors who, unlike professional educators, struggle to effectively address student mistakes and thus fail to seize prime learning opportunities for students.","meta":{"url":"http://arxiv.org/abs/2310.10648v1"},"cats":{"benchmark":0.2225929587,"new-dataset":0.0267514594,"data-annotation":0.5327426688,"dev-research":0.3916009389,"llms":0.5417581861,"data-quality":0.1960927185}}
{"text":"In this paper, we explore the potential for large language models (LLMs) to assist math tutors in remediating student mistakes.","meta":{"url":"http://arxiv.org/abs/2310.10648v1"},"cats":{"benchmark":0.2723066573,"new-dataset":0.0728365941,"data-annotation":0.5618038752,"dev-research":0.2770733261,"llms":0.6336620284,"data-quality":0.3170645073}}
{"text":"We present ReMath, a benchmark co-developed with experienced math teachers that deconstructs their thought process for remediation.","meta":{"url":"http://arxiv.org/abs/2310.10648v1"},"cats":{"benchmark":0.3803698495,"new-dataset":0.0332724157,"data-annotation":0.5336620703,"dev-research":0.346438814,"llms":0.5548631888,"data-quality":0.1369185093}}
{"text":"The benchmark consists of three step-by-step tasks: (1) infer the type of student error, (2) determine the strategy to address the error, and (3) generate a response that incorporates that information.","meta":{"url":"http://arxiv.org/abs/2310.10648v1"},"cats":{"benchmark":0.7491625294,"new-dataset":0.0356411164,"data-annotation":0.5215274617,"dev-research":0.2933605566,"llms":0.4125977162,"data-quality":0.1550961484}}
{"text":"We evaluate the performance of state-of-the-art instruct-tuned and dialog models on ReMath.","meta":{"url":"http://arxiv.org/abs/2310.10648v1"},"cats":{"benchmark":0.3358164547,"new-dataset":0.1178972958,"data-annotation":0.5303987077,"dev-research":0.2402805714,"llms":0.6486542933,"data-quality":0.1151332132}}
{"text":"Our findings suggest that although models consistently improve upon original tutor responses, we cannot rely on models alone to remediate mistakes.","meta":{"url":"http://arxiv.org/abs/2310.10648v1"},"cats":{"benchmark":0.2965755141,"new-dataset":0.0122302105,"data-annotation":0.5389570766,"dev-research":0.3769774639,"llms":0.5096814573,"data-quality":0.3029420859}}
{"text":"Providing models with the error type (e.g., the student is guessing) and strategy (e.g., simplify the problem) leads to a 75% improvement in the response quality over models without that information.","meta":{"url":"http://arxiv.org/abs/2310.10648v1"},"cats":{"benchmark":0.4005881892,"new-dataset":0.0032654053,"data-annotation":0.5276212288,"dev-research":0.2950115657,"llms":0.4612318989,"data-quality":0.2390105976}}
{"text":"Nonetheless, despite the improvement, the quality of the best model's responses still falls short of experienced math teachers.","meta":{"url":"http://arxiv.org/abs/2310.10648v1"},"cats":{"benchmark":0.4426676162,"new-dataset":0.004187654,"data-annotation":0.5413311212,"dev-research":0.2671865797,"llms":0.5090686498,"data-quality":0.1633879993}}
{"text":"Our work sheds light on the potential and limitations of using current LLMs to provide high-quality learning experiences for both tutors and students at scale.","meta":{"url":"http://arxiv.org/abs/2310.10648v1"},"cats":{"benchmark":0.2422592888,"new-dataset":0.0272947801,"data-annotation":0.5146118773,"dev-research":0.1672372006,"llms":0.7961706212,"data-quality":0.0664696094}}
{"text":"Our work is open-sourced at this link: \\url{https://github.com/rosewang2008/remath}.","meta":{"url":"http://arxiv.org/abs/2310.10648v1"},"cats":{"benchmark":0.4225357921,"new-dataset":0.1339112701,"data-annotation":0.5142696237,"dev-research":0.1665901747,"llms":0.5660541192,"data-quality":0.1183800119}}
{"text":"The recent wave of AI-generated content (AIGC) has witnessed substantial success in computer vision, with the diffusion model playing a crucial role in this achievement.","meta":{"url":"http://arxiv.org/abs/2310.10647v1"},"cats":{"benchmark":0.1967385676,"new-dataset":0.0451265708,"data-annotation":0.5163291655,"dev-research":0.1591623989,"llms":0.4383906155,"data-quality":0.1254654053}}
{"text":"Due to their impressive generative capabilities, diffusion models are gradually superseding methods based on GANs and auto-regressive Transformers, demonstrating exceptional performance not only in image generation and editing, but also in the realm of video-related research.","meta":{"url":"http://arxiv.org/abs/2310.10647v1"},"cats":{"benchmark":0.3117144511,"new-dataset":0.011518311,"data-annotation":0.5054594095,"dev-research":0.1634710154,"llms":0.4854821539,"data-quality":0.0715070705}}
{"text":"However, existing surveys mainly focus on diffusion models in the context of image generation, with few up-to-date reviews on their application in the video domain.","meta":{"url":"http://arxiv.org/abs/2310.10647v1"},"cats":{"benchmark":0.3704134774,"new-dataset":0.0810166945,"data-annotation":0.5110014522,"dev-research":0.1545615616,"llms":0.5094116755,"data-quality":0.1213913635}}
{"text":"To address this gap, this paper presents a comprehensive review of video diffusion models in the AIGC era.","meta":{"url":"http://arxiv.org/abs/2310.10647v1"},"cats":{"benchmark":0.3736461646,"new-dataset":0.0538645639,"data-annotation":0.493911541,"dev-research":0.1319637614,"llms":0.4383939428,"data-quality":0.0979258457}}
{"text":"Specifically, we begin with a concise introduction to the fundamentals and evolution of diffusion models.","meta":{"url":"http://arxiv.org/abs/2310.10647v1"},"cats":{"benchmark":0.2348794982,"new-dataset":0.0875078607,"data-annotation":0.5248663699,"dev-research":0.156927981,"llms":0.4535507468,"data-quality":0.0628549453}}
{"text":"Subsequently, we present an overview of research on diffusion models in the video domain, categorizing the work into three key areas: video generation, video editing, and other video understanding tasks.","meta":{"url":"http://arxiv.org/abs/2310.10647v1"},"cats":{"benchmark":0.2665697618,"new-dataset":0.0693251226,"data-annotation":0.5111297335,"dev-research":0.1686471834,"llms":0.4859653734,"data-quality":0.1141125867}}
{"text":"We conduct a thorough review of the literature in these three key areas, including further categorization and practical contributions in the field.","meta":{"url":"http://arxiv.org/abs/2310.10647v1"},"cats":{"benchmark":0.3684813722,"new-dataset":0.022497915,"data-annotation":0.5079203658,"dev-research":0.1810740574,"llms":0.5061967052,"data-quality":0.0937082883}}
{"text":"Finally, we discuss the challenges faced by research in this domain and outline potential future developmental trends.","meta":{"url":"http://arxiv.org/abs/2310.10647v1"},"cats":{"benchmark":0.1700996825,"new-dataset":0.0549869475,"data-annotation":0.4934223472,"dev-research":0.2541221238,"llms":0.5485338264,"data-quality":0.0585697526}}
{"text":"A comprehensive list of video diffusion models studied in this survey is available at https://github.com/ChenHsing/Awesome-Video-Diffusion-Models.","meta":{"url":"http://arxiv.org/abs/2310.10647v1"},"cats":{"benchmark":0.3663297212,"new-dataset":0.1045737819,"data-annotation":0.5079265674,"dev-research":0.1109295935,"llms":0.4715840941,"data-quality":0.081757518}}
{"text":"An interactive robot framework accomplishes long-horizon task planning and can easily generalize to new goals or distinct tasks, even during execution.","meta":{"url":"http://arxiv.org/abs/2310.10645v1"},"cats":{"benchmark":0.2369995471,"new-dataset":0.1207130477,"data-annotation":0.5007684577,"dev-research":0.2752616981,"llms":0.4477615831,"data-quality":0.0416672052}}
{"text":"However, most traditional methods require predefined module design, which makes it hard to generalize to different goals.","meta":{"url":"http://arxiv.org/abs/2310.10645v1"},"cats":{"benchmark":0.3667918311,"new-dataset":0.0005126442,"data-annotation":0.5133421924,"dev-research":0.3009350213,"llms":0.5454310696,"data-quality":0.0581196027}}
{"text":"Recent large language model based approaches can allow for more open-ended planning but often require heavy prompt engineering or domain-specific pretrained models.","meta":{"url":"http://arxiv.org/abs/2310.10645v1"},"cats":{"benchmark":0.1668948813,"new-dataset":0.0811582317,"data-annotation":0.5115803814,"dev-research":0.30302135,"llms":0.5753426428,"data-quality":0.0668179866}}
{"text":"To tackle this, we propose a simple framework that achieves interactive task planning with language models.","meta":{"url":"http://arxiv.org/abs/2310.10645v1"},"cats":{"benchmark":0.2189905616,"new-dataset":0.1849844112,"data-annotation":0.5227757659,"dev-research":0.3335105423,"llms":0.5117991166,"data-quality":0.1110222704}}
{"text":"Our system incorporates both high-level planning and low-level function execution via language.","meta":{"url":"http://arxiv.org/abs/2310.10645v1"},"cats":{"benchmark":0.282811335,"new-dataset":0.0949321413,"data-annotation":0.5015552657,"dev-research":0.4262918956,"llms":0.5879396174,"data-quality":0.0556050625}}
{"text":"We verify the robustness of our system in generating novel high-level instructions for unseen objectives and its ease of adaptation to different tasks by merely substituting the task guidelines, without the need for additional complex prompt engineering.","meta":{"url":"http://arxiv.org/abs/2310.10645v1"},"cats":{"benchmark":0.2794648061,"new-dataset":0.0398192054,"data-annotation":0.5178939396,"dev-research":0.3973777853,"llms":0.5641084386,"data-quality":0.1104314858}}
{"text":"Furthermore, when the user sends a new request, our system is able to replan accordingly with precision based on the new request, task guidelines and previously executed steps.","meta":{"url":"http://arxiv.org/abs/2310.10645v1"},"cats":{"benchmark":0.4946905054,"new-dataset":0.008855851,"data-annotation":0.4873445659,"dev-research":0.3001117701,"llms":0.5368435204,"data-quality":0.0902332475}}
{"text":"Please check more details on our https://wuphilipp.github.io/itp_site and https://youtu.be/TrKLuyv26_g.","meta":{"url":"http://arxiv.org/abs/2310.10645v1"},"cats":{"benchmark":0.2408749866,"new-dataset":0.1968952761,"data-annotation":0.509405961,"dev-research":0.1934684487,"llms":0.5265572707,"data-quality":0.108769338}}
{"text":"In this paper, we present TOSS, which introduces text to the task of novel view synthesis (NVS) from just a single RGB image.","meta":{"url":"http://arxiv.org/abs/2310.10644v1"},"cats":{"benchmark":0.2503409708,"new-dataset":0.3170330363,"data-annotation":0.5209553931,"dev-research":0.2023205748,"llms":0.4406420302,"data-quality":0.0867322262}}
{"text":"While Zero-1-to-3 has demonstrated impressive zero-shot open-set NVS capability, it treats NVS as a pure image-to-image translation problem.","meta":{"url":"http://arxiv.org/abs/2310.10644v1"},"cats":{"benchmark":0.3252848484,"new-dataset":0.11458055,"data-annotation":0.5079250701,"dev-research":0.1101152185,"llms":0.5378638675,"data-quality":0.1629524606}}
{"text":"This approach suffers from the challengingly under-constrained nature of single-view NVS: the process lacks means of explicit user control and often results in implausible NVS generations.","meta":{"url":"http://arxiv.org/abs/2310.10644v1"},"cats":{"benchmark":0.2354862586,"new-dataset":0.0115296295,"data-annotation":0.5047485085,"dev-research":0.1917086887,"llms":0.508452042,"data-quality":0.0833977794}}
{"text":"To address this limitation, TOSS uses text as high-level semantic information to constrain the NVS solution space.","meta":{"url":"http://arxiv.org/abs/2310.10644v1"},"cats":{"benchmark":0.2880002895,"new-dataset":0.0246672427,"data-annotation":0.5180255511,"dev-research":0.2351177435,"llms":0.5575839204,"data-quality":0.1088652313}}
{"text":"TOSS fine-tunes text-to-image Stable Diffusion pre-trained on large-scale text-image pairs and introduces modules specifically tailored to image and camera pose conditioning, as well as dedicated training for pose correctness and preservation of fine details.","meta":{"url":"http://arxiv.org/abs/2310.10644v1"},"cats":{"benchmark":0.2604898108,"new-dataset":0.3862570976,"data-annotation":0.512962347,"dev-research":0.1450073115,"llms":0.5106996377,"data-quality":0.166805426}}
{"text":"Comprehensive experiments are conducted with results showing that our proposed TOSS outperforms Zero-1-to-3 with more plausible, controllable and multiview-consistent NVS results.","meta":{"url":"http://arxiv.org/abs/2310.10644v1"},"cats":{"benchmark":0.4937722095,"new-dataset":0.0346142655,"data-annotation":0.5215056455,"dev-research":0.108453099,"llms":0.4610091285,"data-quality":0.1341446345}}
{"text":"We further support these results with comprehensive ablations that underscore the effectiveness and potential of the introduced semantic guidance and architecture design.","meta":{"url":"http://arxiv.org/abs/2310.10644v1"},"cats":{"benchmark":0.2825864838,"new-dataset":0.0634503635,"data-annotation":0.4934936323,"dev-research":0.2927219588,"llms":0.5344312278,"data-quality":0.1477064279}}
{"text":"Reconstructing dynamic 3D scenes from 2D images and generating diverse views over time is challenging due to scene complexity and temporal dynamics.","meta":{"url":"http://arxiv.org/abs/2310.10642v1"},"cats":{"benchmark":0.2297116915,"new-dataset":0.1888298013,"data-annotation":0.4972891005,"dev-research":0.1681299169,"llms":0.4410054372,"data-quality":0.0494240134}}
{"text":"Despite advancements in neural implicit models, limitations persist: (i) Inadequate Scene Structure:","meta":{"url":"http://arxiv.org/abs/2310.10642v1"},"cats":{"benchmark":0.2078637872,"new-dataset":0.04453037,"data-annotation":0.5303138891,"dev-research":0.1798469782,"llms":0.4352158662,"data-quality":0.1304898664}}
{"text":"Existing methods struggle to reveal the spatial and temporal structure of dynamic scenes from directly learning the complex 6D plenoptic function.","meta":{"url":"http://arxiv.org/abs/2310.10642v1"},"cats":{"benchmark":0.2141653781,"new-dataset":0.1813677355,"data-annotation":0.5011186437,"dev-research":0.1230359798,"llms":0.4701019417,"data-quality":0.06560451}}
{"text":"(ii) Scaling Deformation Modeling:","meta":{"url":"http://arxiv.org/abs/2310.10642v1"},"cats":{"benchmark":0.3807769739,"new-dataset":0.048375092,"data-annotation":0.4976302441,"dev-research":0.142665241,"llms":0.4093153037,"data-quality":0.0792238913}}
{"text":"Explicitly modeling scene element deformation becomes impractical for complex dynamics.","meta":{"url":"http://arxiv.org/abs/2310.10642v1"},"cats":{"benchmark":0.2552467774,"new-dataset":0.0325072114,"data-annotation":0.5114607311,"dev-research":0.2050587554,"llms":0.4584724221,"data-quality":0.0987695089}}
{"text":"To address these issues, we consider the spacetime as an entirety and propose to approximate the underlying spatio-temporal 4D volume of a dynamic scene by optimizing a collection of 4D primitives, with explicit geometry and appearance modeling.","meta":{"url":"http://arxiv.org/abs/2310.10642v1"},"cats":{"benchmark":0.3241910607,"new-dataset":0.214964952,"data-annotation":0.5186287199,"dev-research":0.1604540945,"llms":0.4290971103,"data-quality":0.0696136628}}
{"text":"Learning to optimize the 4D primitives enables us to synthesize novel views at any desired time with our tailored rendering routine.","meta":{"url":"http://arxiv.org/abs/2310.10642v1"},"cats":{"benchmark":0.2363157366,"new-dataset":0.0851727712,"data-annotation":0.5213304119,"dev-research":0.2183973497,"llms":0.530250501,"data-quality":0.0462349115}}
{"text":"Our model is conceptually simple, consisting of a 4D Gaussian parameterized by anisotropic ellipses that can rotate arbitrarily in space and time, as well as view-dependent and time-evolved appearance represented by the coefficient of 4D spherindrical harmonics.","meta":{"url":"http://arxiv.org/abs/2310.10642v1"},"cats":{"benchmark":0.2537461344,"new-dataset":0.0554440472,"data-annotation":0.5233299535,"dev-research":0.0977338256,"llms":0.3595900366,"data-quality":0.0732007476}}
{"text":"This approach offers simplicity, flexibility for variable-length video and end-to-end training, and efficient real-time rendering, making it suitable for capturing complex dynamic scene motions.","meta":{"url":"http://arxiv.org/abs/2310.10642v1"},"cats":{"benchmark":0.2250896638,"new-dataset":0.3325169169,"data-annotation":0.5156921178,"dev-research":0.1787278168,"llms":0.4299740528,"data-quality":0.0431034557}}
{"text":"Experiments across various benchmarks, including monocular and multi-view scenarios, demonstrate our 4DGS model's superior visual quality and efficiency.","meta":{"url":"http://arxiv.org/abs/2310.10642v1"},"cats":{"benchmark":0.4961592886,"new-dataset":0.0342092784,"data-annotation":0.5020501409,"dev-research":0.1492446053,"llms":0.4922948363,"data-quality":0.0796387728}}
{"text":"Diffusion-based generative models have significantly advanced text-to-image generation but encounter challenges when processing lengthy and intricate text prompts describing complex scenes with multiple objects.","meta":{"url":"http://arxiv.org/abs/2310.10640v1"},"cats":{"benchmark":0.1928368319,"new-dataset":0.1457709534,"data-annotation":0.5098478319,"dev-research":0.1567884158,"llms":0.5536992809,"data-quality":0.1324409859}}
{"text":"While excelling in generating images from short, single-object descriptions, these models often struggle to faithfully capture all the nuanced details within longer and more elaborate textual inputs.","meta":{"url":"http://arxiv.org/abs/2310.10640v1"},"cats":{"benchmark":0.2023208693,"new-dataset":0.1201052197,"data-annotation":0.541131675,"dev-research":0.2034094283,"llms":0.4889435879,"data-quality":0.2171768436}}
{"text":"In response, we present a novel approach leveraging Large Language Models (LLMs) to extract critical components from text prompts, including bounding box coordinates for foreground objects, detailed textual descriptions for individual objects, and a succinct background context.","meta":{"url":"http://arxiv.org/abs/2310.10640v1"},"cats":{"benchmark":0.2010895364,"new-dataset":0.4556915262,"data-annotation":0.5455315858,"dev-research":0.2339626551,"llms":0.6121517578,"data-quality":0.221700398}}
{"text":"These components form the foundation of our layout-to-image generation model, which operates in two phases.","meta":{"url":"http://arxiv.org/abs/2310.10640v1"},"cats":{"benchmark":0.1894804593,"new-dataset":0.1740063929,"data-annotation":0.4969188633,"dev-research":0.1931317348,"llms":0.5227607131,"data-quality":0.0506525866}}
{"text":"The initial Global Scene Generation utilizes object layouts and background context to create an initial scene but often falls short in faithfully representing object characteristics as specified in the prompts.","meta":{"url":"http://arxiv.org/abs/2310.10640v1"},"cats":{"benchmark":0.1254657639,"new-dataset":0.130282121,"data-annotation":0.511453959,"dev-research":0.2733004396,"llms":0.5750283516,"data-quality":0.110379618}}
{"text":"To address this limitation, we introduce an Iterative Refinement Scheme that iteratively evaluates and refines box-level content to align them with their textual descriptions, recomposing objects as needed to ensure consistency.","meta":{"url":"http://arxiv.org/abs/2310.10640v1"},"cats":{"benchmark":0.3950388063,"new-dataset":0.0929208359,"data-annotation":0.509987664,"dev-research":0.3476014616,"llms":0.5475154654,"data-quality":0.2546729752}}
{"text":"Our evaluation on complex prompts featuring multiple objects demonstrates a substantial improvement in recall compared to baseline diffusion models.","meta":{"url":"http://arxiv.org/abs/2310.10640v1"},"cats":{"benchmark":0.327783243,"new-dataset":0.0353753179,"data-annotation":0.5230151579,"dev-research":0.1823168457,"llms":0.5570336441,"data-quality":0.1384276821}}
{"text":"This is further validated by a user study, underscoring the efficacy of our approach in generating coherent and detailed scenes from intricate textual inputs.","meta":{"url":"http://arxiv.org/abs/2310.10640v1"},"cats":{"benchmark":0.2480295026,"new-dataset":0.0680276678,"data-annotation":0.5244007103,"dev-research":0.283200632,"llms":0.4791140257,"data-quality":0.1698117655}}
{"text":"If generalist robots are to operate in truly unstructured environments, they need to be able to recognize and reason about novel objects and scenarios.","meta":{"url":"http://arxiv.org/abs/2310.10639v1"},"cats":{"benchmark":0.131160349,"new-dataset":0.0220086005,"data-annotation":0.5154177952,"dev-research":0.1931650123,"llms":0.5165682233,"data-quality":0.0698808304}}
{"text":"Such objects and scenarios might not be present in the robot's own training data.","meta":{"url":"http://arxiv.org/abs/2310.10639v1"},"cats":{"benchmark":0.1050674891,"new-dataset":0.1081850107,"data-annotation":0.4973501373,"dev-research":0.1736624129,"llms":0.5427395855,"data-quality":0.1494682774}}
{"text":"We propose SuSIE, a method that leverages an image-editing diffusion model to act as a high-level planner by proposing intermediate subgoals that a low-level controller can accomplish.","meta":{"url":"http://arxiv.org/abs/2310.10639v1"},"cats":{"benchmark":0.2269418363,"new-dataset":0.0517020787,"data-annotation":0.4924174986,"dev-research":0.2273494234,"llms":0.5137148305,"data-quality":0.0288787454}}
{"text":"Specifically, we finetune InstructPix2Pix on video data, consisting of both human videos and robot rollouts, such that it outputs hypothetical future \"subgoal\" observations given the robot's current observation and a language command.","meta":{"url":"http://arxiv.org/abs/2310.10639v1"},"cats":{"benchmark":0.2242013139,"new-dataset":0.5913710134,"data-annotation":0.5026856225,"dev-research":0.2539157241,"llms":0.549512401,"data-quality":0.1149777113}}
{"text":"We also use the robot data to train a low-level goal-conditioned policy to act as the aforementioned low-level controller.","meta":{"url":"http://arxiv.org/abs/2310.10639v1"},"cats":{"benchmark":0.2339833805,"new-dataset":0.0892929492,"data-annotation":0.4719900736,"dev-research":0.1724099817,"llms":0.4718773636,"data-quality":0.056589517}}
{"text":"We find that the high-level subgoal predictions can utilize Internet-scale pretraining and visual understanding to guide the low-level goal-conditioned policy, achieving significantly better generalization and precision than conventional language-conditioned policies.","meta":{"url":"http://arxiv.org/abs/2310.10639v1"},"cats":{"benchmark":0.2695519959,"new-dataset":0.0614916919,"data-annotation":0.5213867586,"dev-research":0.2084747837,"llms":0.4841648152,"data-quality":0.0747037209}}
{"text":"We achieve state-of-the-art results on the CALVIN benchmark, and also demonstrate robust generalization on real-world manipulation tasks, beating strong baselines that have access to privileged information or that utilize orders of magnitude more compute and training data.","meta":{"url":"http://arxiv.org/abs/2310.10639v1"},"cats":{"benchmark":0.4502865406,"new-dataset":0.0906831923,"data-annotation":0.5233517871,"dev-research":0.2125687019,"llms":0.4848670953,"data-quality":0.1326731406}}
{"text":"The project website can be found at http://rail-berkeley.github.io/susie .","meta":{"url":"http://arxiv.org/abs/2310.10639v1"},"cats":{"benchmark":0.2627443676,"new-dataset":0.2048551065,"data-annotation":0.5125613954,"dev-research":0.1741477859,"llms":0.5200297211,"data-quality":0.0713724968}}
{"text":"Large language models (LMs) are currently trained to predict tokens given document prefixes, enabling them to directly perform long-form generation and prompting-style tasks which can be reduced to document completion.","meta":{"url":"http://arxiv.org/abs/2310.10638v1"},"cats":{"benchmark":0.2186095093,"new-dataset":0.063283575,"data-annotation":0.5357144478,"dev-research":0.1507142191,"llms":0.5995036404,"data-quality":0.1996359253}}
{"text":"Existing pretraining pipelines train LMs by concatenating random sets of short documents to create input contexts but the prior documents provide no signal for predicting the next document.","meta":{"url":"http://arxiv.org/abs/2310.10638v1"},"cats":{"benchmark":0.2407721122,"new-dataset":0.0753096398,"data-annotation":0.4933746245,"dev-research":0.1247953428,"llms":0.5925759908,"data-quality":0.1738761701}}
{"text":"We instead present In-Context Pretraining, a new approach where language models are pretrained on a sequence of related documents, thereby explicitly encouraging them to read and reason across document boundaries.","meta":{"url":"http://arxiv.org/abs/2310.10638v1"},"cats":{"benchmark":0.2439693965,"new-dataset":0.2588293913,"data-annotation":0.54192236,"dev-research":0.3519377285,"llms":0.5650067172,"data-quality":0.2606028915}}
{"text":"We can do In-Context Pretraining by simply changing the document ordering so that each context contains related documents, and directly applying existing pretraining pipelines.","meta":{"url":"http://arxiv.org/abs/2310.10638v1"},"cats":{"benchmark":0.2839628211,"new-dataset":0.0724194386,"data-annotation":0.5060570422,"dev-research":0.2115514296,"llms":0.5678571402,"data-quality":0.1440602463}}
{"text":"However, this document sorting problem is challenging.","meta":{"url":"http://arxiv.org/abs/2310.10638v1"},"cats":{"benchmark":0.507935173,"new-dataset":0.1385906921,"data-annotation":0.5369234779,"dev-research":0.2560631549,"llms":0.4755991032,"data-quality":0.2453128788}}
{"text":"There are billions of documents and we would like the sort to maximize contextual similarity for every document without repeating any data.","meta":{"url":"http://arxiv.org/abs/2310.10638v1"},"cats":{"benchmark":0.4040029261,"new-dataset":0.21675071,"data-annotation":0.5077296169,"dev-research":0.1851573983,"llms":0.4965401183,"data-quality":0.1429949828}}
{"text":"To do this, we introduce approximate algorithms for finding related documents with efficient nearest neighbor search and constructing coherent input contexts with a graph traversal algorithm.","meta":{"url":"http://arxiv.org/abs/2310.10638v1"},"cats":{"benchmark":0.4438604637,"new-dataset":0.0928511251,"data-annotation":0.5426403349,"dev-research":0.1815727963,"llms":0.4851488929,"data-quality":0.2049330145}}
{"text":"Our experiments show In-Context Pretraining offers a simple and scalable approach to significantly enhance LMs'performance: we see notable improvements in tasks that require more complex contextual reasoning, including in-context learning (+8%), reading comprehension (+15%), faithfulness to previous contexts (+16%), long-context reasoning (+5%), and retrieval augmentation (+9%).","meta":{"url":"http://arxiv.org/abs/2310.10638v1"},"cats":{"benchmark":0.290821026,"new-dataset":0.0399035873,"data-annotation":0.520886638,"dev-research":0.1651320188,"llms":0.6534417739,"data-quality":0.1080591286}}
{"text":"Teachers' growth mindset supportive language (GMSL)--rhetoric emphasizing that one's skills can be improved over time--has been shown to significantly reduce disparities in academic achievement and enhance students' learning outcomes.","meta":{"url":"http://arxiv.org/abs/2310.10637v1"},"cats":{"benchmark":0.248923858,"new-dataset":0.0309325911,"data-annotation":0.5111341485,"dev-research":0.2184938199,"llms":0.5980382283,"data-quality":0.0928575749}}
{"text":"Although teachers espouse growth mindset principles, most find it difficult to adopt GMSL in their practice due the lack of effective coaching in this area.","meta":{"url":"http://arxiv.org/abs/2310.10637v1"},"cats":{"benchmark":0.2281919686,"new-dataset":0.0118731452,"data-annotation":0.4933029496,"dev-research":0.2175858673,"llms":0.607700994,"data-quality":0.0676860607}}
{"text":"We explore whether large language models (LLMs) can provide automated, personalized coaching to support teachers' use of GMSL.","meta":{"url":"http://arxiv.org/abs/2310.10637v1"},"cats":{"benchmark":0.1856664233,"new-dataset":0.1243920801,"data-annotation":0.5245756201,"dev-research":0.199542043,"llms":0.6590570631,"data-quality":0.0855425327}}
{"text":"We establish an effective coaching tool to reframe unsupportive utterances to GMSL by developing (i) a parallel dataset containing GMSL-trained teacher reframings of unsupportive statements with an accompanying annotation guide, (ii) a GMSL prompt framework to revise teachers' unsupportive language, and (iii) an evaluation framework grounded in psychological theory for evaluating GMSL with the help of students and teachers.","meta":{"url":"http://arxiv.org/abs/2310.10637v1"},"cats":{"benchmark":0.2436706531,"new-dataset":0.1410120315,"data-annotation":0.516989751,"dev-research":0.2646891241,"llms":0.5659349677,"data-quality":0.1559031589}}
{"text":"We conduct a large-scale evaluation involving 174 teachers and 1,006 students, finding that both teachers and students perceive GMSL-trained teacher and model reframings as more effective in fostering a growth mindset and promoting challenge-seeking behavior, among other benefits.","meta":{"url":"http://arxiv.org/abs/2310.10637v1"},"cats":{"benchmark":0.2489314848,"new-dataset":0.0423891646,"data-annotation":0.5075165765,"dev-research":0.2029120166,"llms":0.5654376095,"data-quality":0.0713669119}}
{"text":"We also find that model-generated reframings outperform those from the GMSL-trained teachers.","meta":{"url":"http://arxiv.org/abs/2310.10637v1"},"cats":{"benchmark":0.3608175241,"new-dataset":0.0721964454,"data-annotation":0.5318764117,"dev-research":0.1737877468,"llms":0.5186817118,"data-quality":0.1383967002}}
{"text":"These results show promise for harnessing LLMs to provide automated GMSL feedback for teachers and, more broadly, LLMs' potentiality for supporting students' learning in the classroom.","meta":{"url":"http://arxiv.org/abs/2310.10637v1"},"cats":{"benchmark":0.2144084302,"new-dataset":0.0527497784,"data-annotation":0.4957224296,"dev-research":0.2347010133,"llms":0.7355570832,"data-quality":0.1205931383}}
{"text":"Our findings also demonstrate the benefit of large-scale human evaluations when applying LLMs in educational domains.","meta":{"url":"http://arxiv.org/abs/2310.10637v1"},"cats":{"benchmark":0.4188809913,"new-dataset":0.0129793724,"data-annotation":0.5366112904,"dev-research":0.2010963436,"llms":0.7530470828,"data-quality":0.1516095857}}
{"text":"Dual-encoder models have demonstrated significant success in dense retrieval tasks for open-domain question answering that mostly involves zero-shot and few-shot scenarios.","meta":{"url":"http://arxiv.org/abs/2310.10636v1"},"cats":{"benchmark":0.3217812305,"new-dataset":0.0746832611,"data-annotation":0.5213819533,"dev-research":0.1101522191,"llms":0.5200477221,"data-quality":0.1138353617}}
{"text":"However, their performance in many-shot retrieval problems where training data is abundant, such as extreme multi-label classification (XMC), remains under-explored.","meta":{"url":"http://arxiv.org/abs/2310.10636v1"},"cats":{"benchmark":0.4269626476,"new-dataset":0.0981176254,"data-annotation":0.5256859433,"dev-research":0.0968285371,"llms":0.4886073131,"data-quality":0.2956930801}}
{"text":"Existing empirical evidence suggests that, for such problems, the dual-encoder method's accuracies lag behind the performance of state-of-the-art (SOTA) extreme classification methods that grow the number of learnable parameters linearly with the number of classes.","meta":{"url":"http://arxiv.org/abs/2310.10636v1"},"cats":{"benchmark":0.4740078635,"new-dataset":0.0183627838,"data-annotation":0.5406716893,"dev-research":0.1405066776,"llms":0.4508681566,"data-quality":0.1514578774}}
{"text":"As a result, some recent extreme classification techniques use a combination of dual-encoders and a learnable classification head for each class to excel on these tasks.","meta":{"url":"http://arxiv.org/abs/2310.10636v1"},"cats":{"benchmark":0.3817021282,"new-dataset":0.0439117088,"data-annotation":0.5274404309,"dev-research":0.1623218104,"llms":0.4565555894,"data-quality":0.1198454842}}
{"text":"In this paper, we investigate the potential of \"pure\" DE models in XMC tasks.","meta":{"url":"http://arxiv.org/abs/2310.10636v1"},"cats":{"benchmark":0.3670613105,"new-dataset":0.0307667917,"data-annotation":0.5072901781,"dev-research":0.1565329884,"llms":0.4933094597,"data-quality":0.0686958665}}
{"text":"Our findings reveal that when trained correctly standard dual-encoders can match or outperform SOTA extreme classification methods by up to 2% at Precision@1 even on the largest XMC datasets while being 20x smaller in terms of the number of trainable parameters.","meta":{"url":"http://arxiv.org/abs/2310.10636v1"},"cats":{"benchmark":0.4313062954,"new-dataset":0.0402570033,"data-annotation":0.5227500387,"dev-research":0.1145335773,"llms":0.5222247684,"data-quality":0.197989454}}
{"text":"We further propose a differentiable topk error-based loss function, which can be used to specifically optimize for Recall@k metrics.","meta":{"url":"http://arxiv.org/abs/2310.10636v1"},"cats":{"benchmark":0.5938240334,"new-dataset":0.1210522643,"data-annotation":0.5277457181,"dev-research":0.2246442444,"llms":0.5371674168,"data-quality":0.3488303748}}
{"text":"We include our PyTorch implementation along with other resources for reproducing the results in the supplementary material.","meta":{"url":"http://arxiv.org/abs/2310.10636v1"},"cats":{"benchmark":0.4705515516,"new-dataset":0.3026611925,"data-annotation":0.5701914588,"dev-research":0.1207676704,"llms":0.4854188503,"data-quality":0.163050969}}
{"text":"Modern AI techniques open up ever-increasing possibilities for autonomous vehicles, but how to appropriately verify the reliability of such systems remains unclear.","meta":{"url":"http://arxiv.org/abs/2310.10635v1"},"cats":{"benchmark":0.4546727336,"new-dataset":0.0112375825,"data-annotation":0.5257021861,"dev-research":0.2291476818,"llms":0.4736376222,"data-quality":0.2462755262}}
{"text":"A common approach is to conduct safety validation based on a predefined Operational Design Domain (ODD) describing specific conditions under which a system under test is required to operate properly.","meta":{"url":"http://arxiv.org/abs/2310.10635v1"},"cats":{"benchmark":0.3734975958,"new-dataset":0.0288011449,"data-annotation":0.485919644,"dev-research":0.3807751756,"llms":0.5431197868,"data-quality":0.1618140894}}
{"text":"However, collecting sufficient realistic test cases to ensure comprehensive ODD coverage is challenging.","meta":{"url":"http://arxiv.org/abs/2310.10635v1"},"cats":{"benchmark":0.4495766324,"new-dataset":0.0320463443,"data-annotation":0.4939155876,"dev-research":0.2133173992,"llms":0.5304740428,"data-quality":0.1541091486}}
{"text":"In this paper, we report our practical experiences regarding the utility of data simulation with deep generative models for scenario-based ODD validation.","meta":{"url":"http://arxiv.org/abs/2310.10635v1"},"cats":{"benchmark":0.2568126244,"new-dataset":0.2153319384,"data-annotation":0.4809063811,"dev-research":0.2340104865,"llms":0.5094495954,"data-quality":0.2161367754}}
{"text":"We consider the specific use case of a camera-based rail-scene segmentation system designed to support autonomous train operation.","meta":{"url":"http://arxiv.org/abs/2310.10635v1"},"cats":{"benchmark":0.2730281865,"new-dataset":0.1057722446,"data-annotation":0.4908585565,"dev-research":0.1661083306,"llms":0.4091885408,"data-quality":0.1475516764}}
{"text":"We demonstrate the capabilities of semantically editing railway scenes with deep generative models to make a limited amount of test data more representative.","meta":{"url":"http://arxiv.org/abs/2310.10635v1"},"cats":{"benchmark":0.2562353138,"new-dataset":0.3812789325,"data-annotation":0.5019225627,"dev-research":0.2054189845,"llms":0.4923869163,"data-quality":0.1864536661}}
{"text":"We also show how our approach helps to analyze the degree to which a system complies with typical ODD requirements.","meta":{"url":"http://arxiv.org/abs/2310.10635v1"},"cats":{"benchmark":0.4180558788,"new-dataset":0.0218026215,"data-annotation":0.5251295409,"dev-research":0.2843569455,"llms":0.5091082886,"data-quality":0.1327541784}}
{"text":"Specifically, we focus on evaluating proper operation under different lighting and weather conditions as well as while transitioning between them.","meta":{"url":"http://arxiv.org/abs/2310.10635v1"},"cats":{"benchmark":0.4978270351,"new-dataset":0.0118303481,"data-annotation":0.484918286,"dev-research":0.3062745982,"llms":0.5116924345,"data-quality":0.0411516555}}
{"text":"Language agents show potential in being capable of utilizing natural language for varied and intricate tasks in diverse environments, particularly when built upon large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2310.10634v1"},"cats":{"benchmark":0.1430513027,"new-dataset":0.0546279315,"data-annotation":0.5273723526,"dev-research":0.18254595,"llms":0.7016774156,"data-quality":0.0931228414}}
{"text":"Current language agent frameworks aim to facilitate the construction of proof-of-concept language agents while neglecting the non-expert user access to agents and paying little attention to application-level designs.","meta":{"url":"http://arxiv.org/abs/2310.10634v1"},"cats":{"benchmark":0.1932527936,"new-dataset":0.0516513386,"data-annotation":0.5371675937,"dev-research":0.3495570884,"llms":0.6020344888,"data-quality":0.1787247402}}
{"text":"We present OpenAgents, an open platform for using and hosting language agents in the wild of everyday life.","meta":{"url":"http://arxiv.org/abs/2310.10634v1"},"cats":{"benchmark":0.1763615893,"new-dataset":0.5970623478,"data-annotation":0.5171913461,"dev-research":0.2473469891,"llms":0.5904722417,"data-quality":0.1548679947}}
{"text":"OpenAgents includes three agents: (1) Data Agent for data analysis with Python/SQL and data tools; (2) Plugins Agent with 200+ daily API tools; (3) Web Agent for autonomous web browsing.","meta":{"url":"http://arxiv.org/abs/2310.10634v1"},"cats":{"benchmark":0.2486210072,"new-dataset":0.3793385511,"data-annotation":0.4791181101,"dev-research":0.1711530421,"llms":0.5174070712,"data-quality":0.0723684109}}
{"text":"OpenAgents enables general users to interact with agent functionalities through a web user interface optimized for swift responses and common failures while offering developers and researchers a seamless deployment experience on local setups, providing a foundation for crafting innovative language agents and facilitating real-world evaluations.","meta":{"url":"http://arxiv.org/abs/2310.10634v1"},"cats":{"benchmark":0.2086249127,"new-dataset":0.1975535943,"data-annotation":0.5182428079,"dev-research":0.3122498798,"llms":0.603742821,"data-quality":0.1341294919}}
{"text":"We elucidate the challenges and opportunities, aspiring to set a foundation for future research and development of real-world language agents.","meta":{"url":"http://arxiv.org/abs/2310.10634v1"},"cats":{"benchmark":0.1335184642,"new-dataset":0.3547061901,"data-annotation":0.5289293993,"dev-research":0.2680241137,"llms":0.5748913743,"data-quality":0.1403907909}}
{"text":"The ability to automatically generate accurate protocols for scientific experiments would represent a major step towards the automation of science.","meta":{"url":"http://arxiv.org/abs/2310.10632v1"},"cats":{"benchmark":0.3123026439,"new-dataset":0.04237549,"data-annotation":0.4912187175,"dev-research":0.2944449431,"llms":0.5646360481,"data-quality":0.1704943475}}
{"text":"Large Language Models (LLMs) have impressive capabilities on a wide range of tasks, such as question answering and the generation of coherent text and code.","meta":{"url":"http://arxiv.org/abs/2310.10632v1"},"cats":{"benchmark":0.2070209075,"new-dataset":0.1615275618,"data-annotation":0.5266253374,"dev-research":0.1596698216,"llms":0.7555239345,"data-quality":0.1013195893}}
{"text":"However, LLMs can struggle with multi-step problems and long-term planning, which are crucial for designing scientific experiments.","meta":{"url":"http://arxiv.org/abs/2310.10632v1"},"cats":{"benchmark":0.2481784243,"new-dataset":0.0180557234,"data-annotation":0.4792791762,"dev-research":0.1841338638,"llms":0.7367086349,"data-quality":0.0504439217}}
{"text":"Moreover, evaluation of the accuracy of scientific protocols is challenging, because experiments can be described correctly in many different ways, require expert knowledge to evaluate, and cannot usually be executed automatically.","meta":{"url":"http://arxiv.org/abs/2310.10632v1"},"cats":{"benchmark":0.5486561047,"new-dataset":0.0269564033,"data-annotation":0.5117828069,"dev-research":0.2887213377,"llms":0.5705514861,"data-quality":0.2478683939}}
{"text":"Here we present an automatic evaluation framework for the task of planning experimental protocols, and we introduce BioProt: a dataset of biology protocols with corresponding pseudocode representations.","meta":{"url":"http://arxiv.org/abs/2310.10632v1"},"cats":{"benchmark":0.3201436056,"new-dataset":0.5441951141,"data-annotation":0.4952052912,"dev-research":0.3118148852,"llms":0.5040377791,"data-quality":0.0912102897}}
{"text":"To measure performance on generating scientific protocols, we use an LLM to convert a natural language protocol into pseudocode, and then evaluate an LLM's ability to reconstruct the pseudocode from a high-level description and a list of admissible pseudocode functions.","meta":{"url":"http://arxiv.org/abs/2310.10632v1"},"cats":{"benchmark":0.3287153705,"new-dataset":0.2371779795,"data-annotation":0.5249708017,"dev-research":0.2477586487,"llms":0.688931292,"data-quality":0.1663535853}}
{"text":"We evaluate GPT-3 and GPT-4 on this task and explore their robustness.","meta":{"url":"http://arxiv.org/abs/2310.10632v1"},"cats":{"benchmark":0.541865297,"new-dataset":0.0823029914,"data-annotation":0.5223414505,"dev-research":0.1502242094,"llms":0.4339515813,"data-quality":0.1394723622}}
{"text":"We externally validate the utility of pseudocode representations of text by generating accurate novel protocols using retrieved pseudocode, and we run a generated protocol successfully in our biological laboratory.","meta":{"url":"http://arxiv.org/abs/2310.10632v1"},"cats":{"benchmark":0.31912581,"new-dataset":0.1794552205,"data-annotation":0.5124802431,"dev-research":0.2564014666,"llms":0.5467114944,"data-quality":0.2437617981}}
{"text":"Our framework is extensible to the evaluation and improvement of language model planning abilities in other areas of science or other areas that lack automatic evaluation.","meta":{"url":"http://arxiv.org/abs/2310.10632v1"},"cats":{"benchmark":0.3561602213,"new-dataset":0.0241751298,"data-annotation":0.5551512659,"dev-research":0.3505695207,"llms":0.539920925,"data-quality":0.2395266635}}
{"text":"We present Llemma, a large language model for mathematics.","meta":{"url":"http://arxiv.org/abs/2310.10631v1"},"cats":{"benchmark":0.2813071892,"new-dataset":0.2726010689,"data-annotation":0.5694390313,"dev-research":0.1680180288,"llms":0.6287276123,"data-quality":0.1389595975}}
{"text":"We continue pretraining Code Llama on the Proof-Pile-2, a mixture of scientific papers, web data containing mathematics, and mathematical code, yielding Llemma.","meta":{"url":"http://arxiv.org/abs/2310.10631v1"},"cats":{"benchmark":0.2538243621,"new-dataset":0.2340723872,"data-annotation":0.5441055735,"dev-research":0.2089439889,"llms":0.693071198,"data-quality":0.1512366453}}
{"text":"On the MATH benchmark Llemma outperforms all known open base models, as well as the unreleased Minerva model suite on an equi-parameter basis.","meta":{"url":"http://arxiv.org/abs/2310.10631v1"},"cats":{"benchmark":0.5569677701,"new-dataset":0.0596319638,"data-annotation":0.5250821031,"dev-research":0.0857715705,"llms":0.6473692132,"data-quality":0.0720817359}}
{"text":"Moreover, Llemma is capable of tool use and formal theorem proving without any further finetuning.","meta":{"url":"http://arxiv.org/abs/2310.10631v1"},"cats":{"benchmark":0.3499377014,"new-dataset":0.0150085869,"data-annotation":0.5134433929,"dev-research":0.2316606713,"llms":0.75343605,"data-quality":0.1167182543}}
{"text":"We openly release all artifacts, including 7 billion and 34 billion parameter models, the Proof-Pile-2, and code to replicate our experiments.","meta":{"url":"http://arxiv.org/abs/2310.10631v1"},"cats":{"benchmark":0.228650084,"new-dataset":0.5887981364,"data-annotation":0.5044784832,"dev-research":0.2400646399,"llms":0.5884968409,"data-quality":0.140175357}}
{"text":"The field of Quantum Machine Learning (QML) has emerged recently in the hopes of finding new machine learning protocols or exponential speedups for classical ones.","meta":{"url":"http://arxiv.org/abs/2310.10629v1"},"cats":{"benchmark":0.4000511015,"new-dataset":0.0272031007,"data-annotation":0.5236344276,"dev-research":0.107407119,"llms":0.4566212682,"data-quality":0.0577438013}}
{"text":"Apart from problems with vanishing gradients and efficient encoding methods, these speedups are hard to find because the sampling nature of quantum computers promotes either simulating computations classically or running them many times on quantum computers in order to use approximate expectation values in gradient calculations.","meta":{"url":"http://arxiv.org/abs/2310.10629v1"},"cats":{"benchmark":0.5476241827,"new-dataset":0.0056711669,"data-annotation":0.5430992292,"dev-research":0.1136856477,"llms":0.5249364846,"data-quality":0.0593657817}}
{"text":"In this paper, we make a case for setting high single-sample accuracy as a primary goal.","meta":{"url":"http://arxiv.org/abs/2310.10629v1"},"cats":{"benchmark":0.6304921439,"new-dataset":0.0294151475,"data-annotation":0.5067598349,"dev-research":0.1193286117,"llms":0.4059714478,"data-quality":0.2177081664}}
{"text":"We discuss the statistical theory which enables highly accurate and precise sample inference, and propose a method of reversed training towards this end.","meta":{"url":"http://arxiv.org/abs/2310.10629v1"},"cats":{"benchmark":0.5506991666,"new-dataset":0.039873649,"data-annotation":0.5350379084,"dev-research":0.1269624942,"llms":0.374654281,"data-quality":0.2478925922}}
{"text":"We show the effectiveness of this training method by assessing several effective variational quantum circuits (VQCs), trained in both the standard and reversed directions, on random binary subsets of the MNIST and MNIST Fashion datasets, on which our method provides an increase of $10-15\\%$ in single-sample inference accuracy.","meta":{"url":"http://arxiv.org/abs/2310.10629v1"},"cats":{"benchmark":0.3900267597,"new-dataset":0.0247299738,"data-annotation":0.5356837857,"dev-research":0.1107581008,"llms":0.5254070945,"data-quality":0.1316898063}}
{"text":"Recent claims about the impressive abilities of large language models (LLMs) are often supported by evaluating publicly available benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.10628v1"},"cats":{"benchmark":0.5743313993,"new-dataset":0.0843421185,"data-annotation":0.5502511739,"dev-research":0.1366900795,"llms":0.6714729015,"data-quality":0.1533396912}}
{"text":"Since LLMs train on wide swaths of the internet, this practice raises concerns of data contamination, i.e., evaluating on examples that are explicitly or implicitly included in the training data.","meta":{"url":"http://arxiv.org/abs/2310.10628v1"},"cats":{"benchmark":0.2092117708,"new-dataset":0.0296468862,"data-annotation":0.4901776858,"dev-research":0.1793607538,"llms":0.7527639099,"data-quality":0.2785841883}}
{"text":"Data contamination remains notoriously challenging to measure and mitigate, even with partial attempts like controlled experimentation of training data, canary strings, or embedding similarities.","meta":{"url":"http://arxiv.org/abs/2310.10628v1"},"cats":{"benchmark":0.3764574605,"new-dataset":0.1538355583,"data-annotation":0.4945909638,"dev-research":0.2173200404,"llms":0.5218028494,"data-quality":0.4926978333}}
{"text":"In this work, we conduct the first thorough longitudinal analysis of data contamination in LLMs by using the natural experiment of training cutoffs in GPT models to look at benchmarks released over time.","meta":{"url":"http://arxiv.org/abs/2310.10628v1"},"cats":{"benchmark":0.4861724418,"new-dataset":0.1294844946,"data-annotation":0.4886742278,"dev-research":0.0996700445,"llms":0.5808826751,"data-quality":0.1829545186}}
{"text":"Specifically, we consider two code/mathematical problem-solving datasets, Codeforces and Project Euler, and find statistically significant trends among LLM pass rate vs. GitHub popularity and release date that provide strong evidence of contamination.","meta":{"url":"http://arxiv.org/abs/2310.10628v1"},"cats":{"benchmark":0.3787985433,"new-dataset":0.2905886783,"data-annotation":0.5279788682,"dev-research":0.3293326024,"llms":0.6140434576,"data-quality":0.1986437724}}
{"text":"By open-sourcing our dataset, raw results, and evaluation framework, our work paves the way for rigorous analyses of data contamination in modern models.","meta":{"url":"http://arxiv.org/abs/2310.10628v1"},"cats":{"benchmark":0.3312202801,"new-dataset":0.5822569366,"data-annotation":0.4767068013,"dev-research":0.2319099594,"llms":0.4645839154,"data-quality":0.2863981625}}
{"text":"We conclude with a discussion of best practices and future steps for publicly releasing benchmarks in the age of LLMs that train on webscale data.","meta":{"url":"http://arxiv.org/abs/2310.10628v1"},"cats":{"benchmark":0.5403553806,"new-dataset":0.1637588931,"data-annotation":0.4730808599,"dev-research":0.1942903994,"llms":0.6959565572,"data-quality":0.1332791861}}
{"text":"Hallucination plagues even frontier LLMs--but how bad is it really for summarizing academic papers?","meta":{"url":"http://arxiv.org/abs/2310.10627v1"},"cats":{"benchmark":0.3337716334,"new-dataset":0.0157945793,"data-annotation":0.5439023959,"dev-research":0.2097286055,"llms":0.6855287295,"data-quality":0.1790500347}}
{"text":"We evaluate Factored Verification, a simple automated method for detecting hallucinations in abstractive summaries.","meta":{"url":"http://arxiv.org/abs/2310.10627v1"},"cats":{"benchmark":0.366463583,"new-dataset":0.0632990879,"data-annotation":0.5488161182,"dev-research":0.3003247007,"llms":0.5431393561,"data-quality":0.2520068587}}
{"text":"This method sets a new SotA on hallucination detection in the summarization task of the HaluEval benchmark, achieving 76.2% accuracy.","meta":{"url":"http://arxiv.org/abs/2310.10627v1"},"cats":{"benchmark":0.5116988129,"new-dataset":0.0556400496,"data-annotation":0.5601459059,"dev-research":0.1863957005,"llms":0.5801872714,"data-quality":0.2377454204}}
{"text":"We then use this method to estimate how often language models hallucinate when summarizing across multiple academic papers and find 0.62 hallucinations in the average ChatGPT (16k) summary, 0.84 for GPT-4, and 1.55 for Claude 2.","meta":{"url":"http://arxiv.org/abs/2310.10627v1"},"cats":{"benchmark":0.3501276484,"new-dataset":0.1828626847,"data-annotation":0.5647024943,"dev-research":0.238143559,"llms":0.5282941221,"data-quality":0.1897641408}}
{"text":"We ask models to self-correct using Factored Critiques and find that this lowers the number of hallucinations to 0.49 for ChatGPT, 0.46 for GPT-4, and 0.95 for Claude 2.","meta":{"url":"http://arxiv.org/abs/2310.10627v1"},"cats":{"benchmark":0.3446001325,"new-dataset":0.0637176526,"data-annotation":0.544888156,"dev-research":0.2859212701,"llms":0.5654002285,"data-quality":0.1876300928}}
{"text":"The hallucinations we find are often subtle, so we advise caution when using models to synthesize academic papers.","meta":{"url":"http://arxiv.org/abs/2310.10627v1"},"cats":{"benchmark":0.2220570355,"new-dataset":0.0220581481,"data-annotation":0.5303095638,"dev-research":0.2580045385,"llms":0.5301380341,"data-quality":0.1160793925}}
{"text":"We are interested in enabling visual planning for complex long-horizon tasks in the space of generated videos and language, leveraging recent advances in large generative models pretrained on Internet-scale data.","meta":{"url":"http://arxiv.org/abs/2310.10625v1"},"cats":{"benchmark":0.1881435751,"new-dataset":0.3776418706,"data-annotation":0.5089385745,"dev-research":0.2164558288,"llms":0.5230020712,"data-quality":0.0585785889}}
{"text":"To this end, we present video language planning (VLP), an algorithm that consists of a tree search procedure, where we train (i) vision-language models to serve as both policies and value functions, and (ii) text-to-video models as dynamics models.","meta":{"url":"http://arxiv.org/abs/2310.10625v1"},"cats":{"benchmark":0.1769177608,"new-dataset":0.2265334362,"data-annotation":0.5169354939,"dev-research":0.2264354195,"llms":0.5161032573,"data-quality":0.15381086}}
{"text":"VLP takes as input a long-horizon task instruction and current image observation, and outputs a long video plan that provides detailed multimodal (video and language) specifications that describe how to complete the final task.","meta":{"url":"http://arxiv.org/abs/2310.10625v1"},"cats":{"benchmark":0.2257280305,"new-dataset":0.1651310745,"data-annotation":0.5064532456,"dev-research":0.2470766793,"llms":0.468081478,"data-quality":0.0561101066}}
{"text":"VLP scales with increasing computation budget where more computation time results in improved video plans, and is able to synthesize long-horizon video plans across different robotics domains: from multi-object rearrangement, to multi-camera bi-arm dexterous manipulation.","meta":{"url":"http://arxiv.org/abs/2310.10625v1"},"cats":{"benchmark":0.2549922836,"new-dataset":0.0800981002,"data-annotation":0.4990761603,"dev-research":0.2169785167,"llms":0.4502130048,"data-quality":0.0395976535}}
{"text":"Generated video plans can be translated into real robot actions via goal-conditioned policies, conditioned on each intermediate frame of the generated video.","meta":{"url":"http://arxiv.org/abs/2310.10625v1"},"cats":{"benchmark":0.157804105,"new-dataset":0.2075225829,"data-annotation":0.4948639033,"dev-research":0.2284307846,"llms":0.4843101039,"data-quality":0.0443624447}}
{"text":"Experiments show that VLP substantially improves long-horizon task success rates compared to prior methods on both simulated and real robots (across 3 hardware platforms).","meta":{"url":"http://arxiv.org/abs/2310.10625v1"},"cats":{"benchmark":0.4895774269,"new-dataset":0.0099321295,"data-annotation":0.5088746722,"dev-research":0.2229883307,"llms":0.4663137106,"data-quality":0.0717524884}}
{"text":"Despite remarkable research advances in diffusion-based video editing, existing methods are limited to short-length videos due to the contradiction between long-range consistency and frame-wise editing.","meta":{"url":"http://arxiv.org/abs/2310.10624v1"},"cats":{"benchmark":0.4516102576,"new-dataset":0.0188937888,"data-annotation":0.5093994551,"dev-research":0.1931915607,"llms":0.4353849822,"data-quality":0.1079844399}}
{"text":"Recent approaches attempt to tackle this challenge by introducing video-2D representations to degrade video editing to image editing.","meta":{"url":"http://arxiv.org/abs/2310.10624v1"},"cats":{"benchmark":0.3482268067,"new-dataset":0.0379196814,"data-annotation":0.5285845304,"dev-research":0.2753127242,"llms":0.4385293431,"data-quality":0.1588522212}}
{"text":"However, they encounter significant difficulties in handling large-scale motion- and view-change videos especially for human-centric videos.","meta":{"url":"http://arxiv.org/abs/2310.10624v1"},"cats":{"benchmark":0.2567720589,"new-dataset":0.0499788526,"data-annotation":0.5146557618,"dev-research":0.312838268,"llms":0.5177591415,"data-quality":0.1441110934}}
{"text":"This motivates us to introduce the dynamic Neural Radiance Fields (NeRF) as the human-centric video representation to ease the video editing problem to a 3D space editing task.","meta":{"url":"http://arxiv.org/abs/2310.10624v1"},"cats":{"benchmark":0.2584083928,"new-dataset":0.0859186093,"data-annotation":0.5141277447,"dev-research":0.2605511639,"llms":0.4677648366,"data-quality":0.1227535563}}
{"text":"As such, editing can be performed in the 3D spaces and propagated to the entire video via the deformation field.","meta":{"url":"http://arxiv.org/abs/2310.10624v1"},"cats":{"benchmark":0.2111241822,"new-dataset":0.0361085341,"data-annotation":0.4954717533,"dev-research":0.1991154887,"llms":0.4655985543,"data-quality":0.06739729}}
{"text":"To provide finer and direct controllable editing, we propose the image-based 3D space editing pipeline with a set of effective designs.","meta":{"url":"http://arxiv.org/abs/2310.10624v1"},"cats":{"benchmark":0.3446363791,"new-dataset":0.1039227384,"data-annotation":0.462862592,"dev-research":0.2944775923,"llms":0.5047494803,"data-quality":0.0963837563}}
{"text":"These include multi-view multi-pose Score Distillation Sampling (SDS) from both 2D personalized diffusion priors and 3D diffusion priors, reconstruction losses on the reference image, text-guided local parts super-resolution, and style transfer for 3D background space.","meta":{"url":"http://arxiv.org/abs/2310.10624v1"},"cats":{"benchmark":0.4007023643,"new-dataset":0.0967019625,"data-annotation":0.4937279885,"dev-research":0.1124562397,"llms":0.4870855652,"data-quality":0.0849531107}}
{"text":"Extensive experiments demonstrate that our method, dubbed as DynVideo-E, significantly outperforms SOTA approaches on two challenging datasets by a large margin of 50% ~ 95% in terms of human preference.","meta":{"url":"http://arxiv.org/abs/2310.10624v1"},"cats":{"benchmark":0.373910552,"new-dataset":0.2901323176,"data-annotation":0.5080356233,"dev-research":0.1455209051,"llms":0.5161401741,"data-quality":0.131614138}}
{"text":"Compelling video comparisons are provided in the project page https://showlab.github.io/DynVideo-E/. Our code and data will be released to the community.","meta":{"url":"http://arxiv.org/abs/2310.10624v1"},"cats":{"benchmark":0.5651917385,"new-dataset":0.2898131097,"data-annotation":0.5160348566,"dev-research":0.2224881079,"llms":0.5264720744,"data-quality":0.1715238832}}
{"text":"Readability refers to how easily a reader can understand a written text.","meta":{"url":"http://arxiv.org/abs/2310.10623v1"},"cats":{"benchmark":0.330492923,"new-dataset":0.0244977133,"data-annotation":0.5238852737,"dev-research":0.271172942,"llms":0.4854995595,"data-quality":0.1861833713}}
{"text":"Several factors affect the readability level, such as the complexity of the text, its subject matter, and the reader's background knowledge.","meta":{"url":"http://arxiv.org/abs/2310.10623v1"},"cats":{"benchmark":0.3426162007,"new-dataset":0.0079322334,"data-annotation":0.5362856087,"dev-research":0.2233304837,"llms":0.5048668251,"data-quality":0.1421938722}}
{"text":"Generating summaries based on different readability levels is critical for enabling knowledge consumption by diverse audiences.","meta":{"url":"http://arxiv.org/abs/2310.10623v1"},"cats":{"benchmark":0.2537381596,"new-dataset":0.0638813772,"data-annotation":0.5249114457,"dev-research":0.267478611,"llms":0.5691021821,"data-quality":0.1574649533}}
{"text":"However, current text generation approaches lack refined control, resulting in texts that are not customized to readers' proficiency levels.","meta":{"url":"http://arxiv.org/abs/2310.10623v1"},"cats":{"benchmark":0.2237228956,"new-dataset":0.013556482,"data-annotation":0.5102127625,"dev-research":0.3444957366,"llms":0.5992901368,"data-quality":0.2199470157}}
{"text":"In this work, we bridge this gap and study techniques to generate summaries at specified readability levels.","meta":{"url":"http://arxiv.org/abs/2310.10623v1"},"cats":{"benchmark":0.4003456288,"new-dataset":0.1765481284,"data-annotation":0.5322404792,"dev-research":0.2794127322,"llms":0.5693089722,"data-quality":0.1888229836}}
{"text":"Unlike previous methods that focus on a specific readability level (e.g., lay summarization), we generate summaries with fine-grained control over their readability.","meta":{"url":"http://arxiv.org/abs/2310.10623v1"},"cats":{"benchmark":0.3880190552,"new-dataset":0.0591965752,"data-annotation":0.5419447903,"dev-research":0.3510174751,"llms":0.5406388603,"data-quality":0.2122815535}}
{"text":"We develop three text generation techniques for controlling readability: (1) instruction-based readability control, (2) reinforcement learning to minimize the gap between requested and observed readability and (3) a decoding approach that uses lookahead to estimate the readability of upcoming decoding steps.","meta":{"url":"http://arxiv.org/abs/2310.10623v1"},"cats":{"benchmark":0.2536292416,"new-dataset":0.0728148675,"data-annotation":0.5046243603,"dev-research":0.2471502058,"llms":0.5564922899,"data-quality":0.1546674156}}
{"text":"We show that our generation methods significantly improve readability control on news summarization (CNN/DM dataset), as measured by various readability metrics and human judgement, establishing strong baselines for controllable readability in summarization.","meta":{"url":"http://arxiv.org/abs/2310.10623v1"},"cats":{"benchmark":0.2961371772,"new-dataset":0.1964875294,"data-annotation":0.5273749222,"dev-research":0.2747346677,"llms":0.5769151431,"data-quality":0.2536987163}}
{"text":"While large language models based on the transformer architecture have demonstrated remarkable in-context learning (ICL) capabilities, understandings of such capabilities are still in an early stage, where existing theory and mechanistic understanding focus mostly on simple scenarios such as learning simple function classes.","meta":{"url":"http://arxiv.org/abs/2310.10616v1"},"cats":{"benchmark":0.1561518361,"new-dataset":0.0468344833,"data-annotation":0.5399802924,"dev-research":0.1698074405,"llms":0.5674488388,"data-quality":0.1311801221}}
{"text":"This paper takes initial steps on understanding ICL in more complex scenarios, by studying learning with representations.","meta":{"url":"http://arxiv.org/abs/2310.10616v1"},"cats":{"benchmark":0.1562928729,"new-dataset":0.0863033434,"data-annotation":0.5211827661,"dev-research":0.2540505097,"llms":0.5241700436,"data-quality":0.0740776097}}
{"text":"Concretely, we construct synthetic in-context learning problems with a compositional structure, where the label depends on the input through a possibly complex but fixed representation function, composed with a linear function that differs in each instance.","meta":{"url":"http://arxiv.org/abs/2310.10616v1"},"cats":{"benchmark":0.2302158102,"new-dataset":0.1277896499,"data-annotation":0.5375635454,"dev-research":0.1604947976,"llms":0.4477890958,"data-quality":0.3877092849}}
{"text":"By construction, the optimal ICL algorithm first transforms the inputs by the representation function, and then performs linear ICL on top of the transformed dataset.","meta":{"url":"http://arxiv.org/abs/2310.10616v1"},"cats":{"benchmark":0.4136691441,"new-dataset":0.0919676582,"data-annotation":0.511962908,"dev-research":0.1458452269,"llms":0.3654455962,"data-quality":0.106291339}}
{"text":"We show theoretically the existence of transformers that approximately implement such algorithms with mild depth and size.","meta":{"url":"http://arxiv.org/abs/2310.10616v1"},"cats":{"benchmark":0.3367215734,"new-dataset":0.0277738319,"data-annotation":0.5268745006,"dev-research":0.13144747,"llms":0.4865945682,"data-quality":0.0533082399}}
{"text":"Empirically, we find trained transformers consistently achieve near-optimal ICL performance in this setting, and exhibit the desired dissection where lower layers transforms the dataset and upper layers perform linear ICL.","meta":{"url":"http://arxiv.org/abs/2310.10616v1"},"cats":{"benchmark":0.3778899718,"new-dataset":0.1080027663,"data-annotation":0.5028642129,"dev-research":0.1708214416,"llms":0.4619669258,"data-quality":0.1041357973}}
{"text":"Through extensive probing and a new pasting experiment, we further reveal several mechanisms within the trained transformers, such as concrete copying behaviors on both the inputs and the representations, linear ICL capability of the upper layers alone, and a post-ICL representation selection mechanism in a harder mixture setting.","meta":{"url":"http://arxiv.org/abs/2310.10616v1"},"cats":{"benchmark":0.2602310662,"new-dataset":0.0119193587,"data-annotation":0.5109471107,"dev-research":0.168090194,"llms":0.5388714938,"data-quality":0.1048583388}}
{"text":"These observed mechanisms align well with our theory and may shed light on how transformers perform ICL in more realistic scenarios.","meta":{"url":"http://arxiv.org/abs/2310.10616v1"},"cats":{"benchmark":0.282186402,"new-dataset":0.0110380316,"data-annotation":0.5078817918,"dev-research":0.1567347564,"llms":0.5392072986,"data-quality":0.07649413}}
{"text":"This paper considers homography estimation in a Bayesian filtering framework using rate gyro and camera measurements.","meta":{"url":"http://arxiv.org/abs/2310.10612v1"},"cats":{"benchmark":0.4032697062,"new-dataset":0.0853828548,"data-annotation":0.4935255172,"dev-research":0.1537474226,"llms":0.4032814337,"data-quality":0.0758528922}}
{"text":"The use of rate gyro measurements facilitates a more reliable estimate of homography in the presence of occlusions, while a Bayesian filtering approach generates both a homography estimate along with an uncertainty.","meta":{"url":"http://arxiv.org/abs/2310.10612v1"},"cats":{"benchmark":0.4540661649,"new-dataset":0.0236303637,"data-annotation":0.4908162679,"dev-research":0.1746322484,"llms":0.4083150434,"data-quality":0.0808161938}}
{"text":"Uncertainty information opens the door to adaptive filtering approaches, post-processing procedures, and safety protocols.","meta":{"url":"http://arxiv.org/abs/2310.10612v1"},"cats":{"benchmark":0.4121262275,"new-dataset":0.0166450401,"data-annotation":0.4634406869,"dev-research":0.2893670704,"llms":0.4647215338,"data-quality":0.2264764562}}
{"text":"In particular, herein an iterative extended Kalman filter and an interacting multiple model (IMM) filter are tested using both simulated and experimental datasets.","meta":{"url":"http://arxiv.org/abs/2310.10612v1"},"cats":{"benchmark":0.4465944153,"new-dataset":0.0328169614,"data-annotation":0.5102646228,"dev-research":0.095385006,"llms":0.3863370739,"data-quality":0.0618544669}}
{"text":"The IMM is shown to have good consistency properties and better overall performance when compared to the state-of-the-art homography nonlinear deterministic observer in both simulations and experiments.","meta":{"url":"http://arxiv.org/abs/2310.10612v1"},"cats":{"benchmark":0.3777962113,"new-dataset":0.0516908197,"data-annotation":0.4956210087,"dev-research":0.1321027382,"llms":0.4779727753,"data-quality":0.1178254853}}
{"text":"Reasoning about a model's accuracy on a test sample from its confidence is a central problem in machine learning, being connected to important applications such as uncertainty representation, model selection, and exploration.","meta":{"url":"http://arxiv.org/abs/2310.10611v1"},"cats":{"benchmark":0.4309064207,"new-dataset":0.0095224076,"data-annotation":0.5208804422,"dev-research":0.2335792442,"llms":0.4175132629,"data-quality":0.2607118938}}
{"text":"While these connections have been well-studied in the i.i.d. settings, distribution shifts pose significant challenges to the traditional methods.","meta":{"url":"http://arxiv.org/abs/2310.10611v1"},"cats":{"benchmark":0.4413447687,"new-dataset":0.0076999646,"data-annotation":0.4803299909,"dev-research":0.1198084036,"llms":0.4736354318,"data-quality":0.1132937738}}
{"text":"Therefore, model calibration and model selection remain challenging in the unsupervised domain adaptation problem--a scenario where the goal is to perform well in a distribution shifted domain without labels.","meta":{"url":"http://arxiv.org/abs/2310.10611v1"},"cats":{"benchmark":0.3798288789,"new-dataset":0.0203105433,"data-annotation":0.4982023656,"dev-research":0.1205481481,"llms":0.485496496,"data-quality":0.2705019598}}
{"text":"In this work, we tackle difficulties coming from distribution shifts by developing a novel importance weighted group accuracy estimator.","meta":{"url":"http://arxiv.org/abs/2310.10611v1"},"cats":{"benchmark":0.668915652,"new-dataset":0.0316001452,"data-annotation":0.525033285,"dev-research":0.1384901807,"llms":0.3642369343,"data-quality":0.2480126403}}
{"text":"Specifically, we formulate an optimization problem for finding an importance weight that leads to an accurate group accuracy estimation in the distribution shifted domain with theoretical analyses.","meta":{"url":"http://arxiv.org/abs/2310.10611v1"},"cats":{"benchmark":0.6416280115,"new-dataset":0.032786971,"data-annotation":0.5374921614,"dev-research":0.1070431641,"llms":0.3631148048,"data-quality":0.1881219566}}
{"text":"Extensive experiments show the effectiveness of group accuracy estimation on model calibration and model selection.","meta":{"url":"http://arxiv.org/abs/2310.10611v1"},"cats":{"benchmark":0.5939506289,"new-dataset":0.0330372644,"data-annotation":0.5192660082,"dev-research":0.1693020465,"llms":0.3700411205,"data-quality":0.1992856166}}
{"text":"Our results emphasize the significance of group accuracy estimation for addressing challenges in unsupervised domain adaptation, as an orthogonal improvement direction with improving transferability of accuracy.","meta":{"url":"http://arxiv.org/abs/2310.10611v1"},"cats":{"benchmark":0.5118184202,"new-dataset":0.0241583147,"data-annotation":0.5214706879,"dev-research":0.1883556761,"llms":0.4808949873,"data-quality":0.3162754921}}
{"text":"Our ultimate goal is to build robust policies for robots that assist people.","meta":{"url":"http://arxiv.org/abs/2310.10610v1"},"cats":{"benchmark":0.2221902742,"new-dataset":0.0754270212,"data-annotation":0.4888261309,"dev-research":0.2422974247,"llms":0.4987408199,"data-quality":0.0772709708}}
{"text":"What makes this hard is that people can behave unexpectedly at test time, potentially interacting with the robot outside its training distribution and leading to failures.","meta":{"url":"http://arxiv.org/abs/2310.10610v1"},"cats":{"benchmark":0.1965990307,"new-dataset":0.0246191527,"data-annotation":0.5301165894,"dev-research":0.2973263969,"llms":0.5196506433,"data-quality":0.1596988918}}
{"text":"Even just measuring robustness is a challenge.","meta":{"url":"http://arxiv.org/abs/2310.10610v1"},"cats":{"benchmark":0.5036650854,"new-dataset":0.0104237235,"data-annotation":0.5121763492,"dev-research":0.2663301226,"llms":0.4494822993,"data-quality":0.3273330905}}
{"text":"Adversarial perturbations are the default, but they can paint the wrong picture: they can correspond to human motions that are unlikely to occur during natural interactions with people.","meta":{"url":"http://arxiv.org/abs/2310.10610v1"},"cats":{"benchmark":0.1677873039,"new-dataset":0.0139237293,"data-annotation":0.5481814728,"dev-research":0.2436686372,"llms":0.494585156,"data-quality":0.2107333272}}
{"text":"A robot policy might fail under small adversarial perturbations but work under large natural perturbations.","meta":{"url":"http://arxiv.org/abs/2310.10610v1"},"cats":{"benchmark":0.238650499,"new-dataset":0.010059801,"data-annotation":0.5317063326,"dev-research":0.1483493942,"llms":0.4905498427,"data-quality":0.1751919769}}
{"text":"We propose that capturing robustness in these interactive settings requires constructing and analyzing the entire natural-adversarial frontier: the Pareto-frontier of human policies that are the best trade-offs between naturalness and low robot performance.","meta":{"url":"http://arxiv.org/abs/2310.10610v1"},"cats":{"benchmark":0.2628921675,"new-dataset":0.0917742529,"data-annotation":0.5302497991,"dev-research":0.2130351974,"llms":0.4850713729,"data-quality":0.1777452935}}
{"text":"We introduce RIGID, a method for constructing this frontier by training adversarial human policies that trade off between minimizing robot reward and acting human-like (as measured by a discriminator).","meta":{"url":"http://arxiv.org/abs/2310.10610v1"},"cats":{"benchmark":0.2461796875,"new-dataset":0.0682415226,"data-annotation":0.5428502676,"dev-research":0.1414630935,"llms":0.4362475367,"data-quality":0.1478324367}}
{"text":"On an Assistive Gym task, we use RIGID to analyze the performance of standard collaborative Reinforcement Learning, as well as the performance of existing methods meant to increase robustness.","meta":{"url":"http://arxiv.org/abs/2310.10610v1"},"cats":{"benchmark":0.3928907845,"new-dataset":0.0150396043,"data-annotation":0.5336105902,"dev-research":0.2159886889,"llms":0.4233771148,"data-quality":0.1109507094}}
{"text":"We also compare the frontier RIGID identifies with the failures identified in expert adversarial interaction, and with naturally-occurring failures during user interaction.","meta":{"url":"http://arxiv.org/abs/2310.10610v1"},"cats":{"benchmark":0.3699622546,"new-dataset":0.026417241,"data-annotation":0.5683314146,"dev-research":0.3179737776,"llms":0.4425826191,"data-quality":0.4348740319}}
{"text":"Overall, we find evidence that RIGID can provide a meaningful measure of robustness predictive of deployment performance, and uncover failure cases in human-robot interaction that are difficult to find manually.","meta":{"url":"http://arxiv.org/abs/2310.10610v1"},"cats":{"benchmark":0.391008545,"new-dataset":0.0494506164,"data-annotation":0.5269639189,"dev-research":0.3805598488,"llms":0.4662354099,"data-quality":0.1708412176}}
{"text":"https://ood-human.github.io.","meta":{"url":"http://arxiv.org/abs/2310.10610v1"},"cats":{"benchmark":0.2059613457,"new-dataset":0.7008720154,"data-annotation":0.5172251796,"dev-research":0.2303469983,"llms":0.5400429924,"data-quality":0.0884193938}}
{"text":"Although there is extensive literature on the application of artificial neural networks (NNs) in quality control (QC), to monitor the conformity of a process to quality specifications, at least five QC measurements are required, increasing the related cost.","meta":{"url":"http://arxiv.org/abs/2310.10608v1"},"cats":{"benchmark":0.4335661911,"new-dataset":0.0457932215,"data-annotation":0.5080974161,"dev-research":0.257205413,"llms":0.4683867875,"data-quality":0.1887529074}}
{"text":"To explore the application of neural networks to samples of QC measurements of very small size, four one-dimensional (1-D) convolutional neural networks (CNNs) were designed, trained, and tested with datasets of $ n $-tuples of simulated standardized normally distributed QC measurements, for $ 1 \\leq n \\leq","meta":{"url":"http://arxiv.org/abs/2310.10608v1"},"cats":{"benchmark":0.3064448957,"new-dataset":0.1401402582,"data-annotation":0.5134804264,"dev-research":0.1040065447,"llms":0.4473963178,"data-quality":0.1041767621}}
{"text":"4$.","meta":{"url":"http://arxiv.org/abs/2310.10608v1"},"cats":{"benchmark":0.2382142332,"new-dataset":0.4398314943,"data-annotation":0.5310168525,"dev-research":0.2177257089,"llms":0.5020703868,"data-quality":0.150085123}}
{"text":"The designed neural networks were compared to statistical QC functions with equal probabilities for false rejection, applied to samples of the same size.","meta":{"url":"http://arxiv.org/abs/2310.10608v1"},"cats":{"benchmark":0.4660656772,"new-dataset":0.0120733537,"data-annotation":0.5281291835,"dev-research":0.1391339738,"llms":0.4744739259,"data-quality":0.1679599324}}
{"text":"When the $ n $-tuples included at least two QC measurements distributed as $ \\mathcal{N}(\\mu, \\sigma^2) $, where $ 0.2 < |\\mu| \\leq 6.0 $, and $ 1.0 <","meta":{"url":"http://arxiv.org/abs/2310.10608v1"},"cats":{"benchmark":0.4752415453,"new-dataset":0.2154293847,"data-annotation":0.5336794147,"dev-research":0.1259260862,"llms":0.449249097,"data-quality":0.1436338745}}
{"text":"\\sigma \\leq 7.0 $, the designed neural networks outperformed the respective statistical QC functions.","meta":{"url":"http://arxiv.org/abs/2310.10608v1"},"cats":{"benchmark":0.460150717,"new-dataset":0.0288367567,"data-annotation":0.5404437617,"dev-research":0.1265670838,"llms":0.4395719629,"data-quality":0.1205922258}}
{"text":"Therefore, 1-D CNNs applied to samples of 2-4 quality control measurements can be used to increase the probability of detection of the nonconformity of a process to the quality specifications, with lower cost.","meta":{"url":"http://arxiv.org/abs/2310.10608v1"},"cats":{"benchmark":0.3938412896,"new-dataset":0.0568884154,"data-annotation":0.5056176754,"dev-research":0.2096496124,"llms":0.5320196059,"data-quality":0.2699917954}}
{"text":"Domain randomization (DR), which entails training a policy with randomized dynamics, has proven to be a simple yet effective algorithm for reducing the gap between simulation and the real world.","meta":{"url":"http://arxiv.org/abs/2310.10606v1"},"cats":{"benchmark":0.3403850823,"new-dataset":0.0388475533,"data-annotation":0.4941061989,"dev-research":0.1502872459,"llms":0.549293979,"data-quality":0.0938741839}}
{"text":"However, DR often requires careful tuning of randomization parameters.","meta":{"url":"http://arxiv.org/abs/2310.10606v1"},"cats":{"benchmark":0.5125991729,"new-dataset":0.0075041516,"data-annotation":0.4979987057,"dev-research":0.1632740742,"llms":0.5204578108,"data-quality":0.1468614512}}
{"text":"Methods like Bayesian Domain Randomization (Bayesian DR) and Active Domain Randomization (Adaptive DR) address this issue by automating parameter range selection using real-world experience.","meta":{"url":"http://arxiv.org/abs/2310.10606v1"},"cats":{"benchmark":0.4723868605,"new-dataset":0.017244588,"data-annotation":0.505117319,"dev-research":0.1673518155,"llms":0.4564251978,"data-quality":0.1150727409}}
{"text":"While effective, these algorithms often require long computation time, as a new policy is trained from scratch every iteration.","meta":{"url":"http://arxiv.org/abs/2310.10606v1"},"cats":{"benchmark":0.3942440296,"new-dataset":0.0209259777,"data-annotation":0.5203698639,"dev-research":0.2373880546,"llms":0.4563747803,"data-quality":0.0859181721}}
{"text":"In this work, we propose Adaptive Bayesian Domain Randomization via Strategic Fine-tuning (BayRnTune), which inherits the spirit of BayRn but aims to significantly accelerate the learning processes by fine-tuning from previously learned policy.","meta":{"url":"http://arxiv.org/abs/2310.10606v1"},"cats":{"benchmark":0.3740396977,"new-dataset":0.0830541244,"data-annotation":0.5099537987,"dev-research":0.1741422722,"llms":0.5450482122,"data-quality":0.1915219098}}
{"text":"This idea leads to a critical question: which previous policy should we use as a prior during fine-tuning?","meta":{"url":"http://arxiv.org/abs/2310.10606v1"},"cats":{"benchmark":0.4703641193,"new-dataset":0.003815996,"data-annotation":0.4777671143,"dev-research":0.2613207651,"llms":0.5141773116,"data-quality":0.1456060366}}
{"text":"We investigated four different fine-tuning strategies and compared them against baseline algorithms in five simulated environments, ranging from simple benchmark tasks to more complex legged robot environments.","meta":{"url":"http://arxiv.org/abs/2310.10606v1"},"cats":{"benchmark":0.5511660198,"new-dataset":0.040953653,"data-annotation":0.5087852034,"dev-research":0.2301755444,"llms":0.4540609317,"data-quality":0.0486838433}}
{"text":"Our analysis demonstrates that our method yields better rewards in the same amount of timesteps compared to vanilla domain randomization or Bayesian DR.","meta":{"url":"http://arxiv.org/abs/2310.10606v1"},"cats":{"benchmark":0.5855546552,"new-dataset":0.010824591,"data-annotation":0.5264218071,"dev-research":0.1177368944,"llms":0.5182124311,"data-quality":0.0969721675}}
{"text":"Recently, machine learning, particularly message-passing graph neural networks (MPNNs), has gained traction in enhancing exact optimization algorithms.","meta":{"url":"http://arxiv.org/abs/2310.10603v1"},"cats":{"benchmark":0.3204824488,"new-dataset":0.0318537689,"data-annotation":0.5266631455,"dev-research":0.1706997264,"llms":0.4073252187,"data-quality":0.1598611565}}
{"text":"For example, MPNNs speed up solving mixed-integer optimization problems by imitating computational intensive heuristics like strong branching, which entails solving multiple linear optimization problems (LPs).","meta":{"url":"http://arxiv.org/abs/2310.10603v1"},"cats":{"benchmark":0.3537806734,"new-dataset":0.007748265,"data-annotation":0.5159602652,"dev-research":0.1956963104,"llms":0.4147637726,"data-quality":0.0510923679}}
{"text":"Despite the empirical success, the reasons behind MPNNs' effectiveness in emulating linear optimization remain largely unclear.","meta":{"url":"http://arxiv.org/abs/2310.10603v1"},"cats":{"benchmark":0.4153108027,"new-dataset":0.0032119528,"data-annotation":0.521913553,"dev-research":0.2025691482,"llms":0.3582693815,"data-quality":0.1153443874}}
{"text":"Here, we show that MPNNs can simulate standard interior-point methods for LPs, explaining their practical success.","meta":{"url":"http://arxiv.org/abs/2310.10603v1"},"cats":{"benchmark":0.5184412477,"new-dataset":0.025432916,"data-annotation":0.5346805604,"dev-research":0.1263480492,"llms":0.4082458395,"data-quality":0.1382841051}}
{"text":"Furthermore, we highlight how MPNNs can serve as a lightweight proxy for solving LPs, adapting to a given problem instance distribution.","meta":{"url":"http://arxiv.org/abs/2310.10603v1"},"cats":{"benchmark":0.3473011278,"new-dataset":0.0846290977,"data-annotation":0.5362398928,"dev-research":0.1994408516,"llms":0.4596086062,"data-quality":0.1547752154}}
{"text":"Empirically, we show that MPNNs solve LP relaxations of standard combinatorial optimization problems close to optimality, often surpassing conventional solvers and competing approaches in solving time.","meta":{"url":"http://arxiv.org/abs/2310.10603v1"},"cats":{"benchmark":0.4066467986,"new-dataset":0.0437409332,"data-annotation":0.5301567655,"dev-research":0.1763810024,"llms":0.3911674373,"data-quality":0.1210080317}}
{"text":"In this work, we explore the recent advances in equivariant filtering for inertial navigation systems to improve state estimation for uncrewed aerial vehicles (UAVs).","meta":{"url":"http://arxiv.org/abs/2310.10597v1"},"cats":{"benchmark":0.36650532,"new-dataset":0.0591398517,"data-annotation":0.5204878464,"dev-research":0.1672155973,"llms":0.4431417257,"data-quality":0.0736181179}}
{"text":"Traditional state-of-the-art estimation methods, e.g., the multiplicative Kalman filter (MEKF), have some limitations concerning their consistency, errors in the initial state estimate, and convergence performance.","meta":{"url":"http://arxiv.org/abs/2310.10597v1"},"cats":{"benchmark":0.4991402192,"new-dataset":0.0182609648,"data-annotation":0.5262367362,"dev-research":0.1305621845,"llms":0.365982239,"data-quality":0.0925102904}}
{"text":"Symmetry-based methods, such as the equivariant filter (EqF), offer significant advantages for these points by exploiting the mathematical properties of the system - its symmetry.","meta":{"url":"http://arxiv.org/abs/2310.10597v1"},"cats":{"benchmark":0.494444851,"new-dataset":0.0071384251,"data-annotation":0.5254244044,"dev-research":0.087034083,"llms":0.372705513,"data-quality":0.0722867244}}
{"text":"These filters yield faster convergence rates and robustness to wrong initial state estimates through their error definition.","meta":{"url":"http://arxiv.org/abs/2310.10597v1"},"cats":{"benchmark":0.5799340527,"new-dataset":0.0066651825,"data-annotation":0.4973890405,"dev-research":0.1716104152,"llms":0.4083965927,"data-quality":0.239312749}}
{"text":"To demonstrate the usability of EqFs, we focus on the sensor-fusion problem with the most common sensors in outdoor robotics: global navigation satellite system (GNSS) sensors and an inertial measurement unit (IMU).","meta":{"url":"http://arxiv.org/abs/2310.10597v1"},"cats":{"benchmark":0.3448928928,"new-dataset":0.1231953048,"data-annotation":0.4946355382,"dev-research":0.1605968272,"llms":0.4887126872,"data-quality":0.0632341212}}
{"text":"We provide an implementation of such an EqF leveraging the semi-direct product of the symmetry group to derive the filter equations.","meta":{"url":"http://arxiv.org/abs/2310.10597v1"},"cats":{"benchmark":0.3458368726,"new-dataset":0.0963597317,"data-annotation":0.5216559232,"dev-research":0.0979311995,"llms":0.4472052333,"data-quality":0.0747578016}}
{"text":"To validate the practical usability of EqFs in real-world scenarios, we evaluate our method using data from all outdoor runs of the INSANE Dataset.","meta":{"url":"http://arxiv.org/abs/2310.10597v1"},"cats":{"benchmark":0.4282879306,"new-dataset":0.3550947581,"data-annotation":0.485360683,"dev-research":0.2536749246,"llms":0.4979744549,"data-quality":0.1128367511}}
{"text":"Our results demonstrate the performance improvements of the EqF in real-world environments, highlighting its potential for enhancing state estimation for UAVs.","meta":{"url":"http://arxiv.org/abs/2310.10597v1"},"cats":{"benchmark":0.3967385796,"new-dataset":0.0800720167,"data-annotation":0.51616014,"dev-research":0.1433043885,"llms":0.4246050763,"data-quality":0.0591127582}}
{"text":"In this paper, we investigate building a sequence to sequence architecture for motion to language translation and synchronization.","meta":{"url":"http://arxiv.org/abs/2310.10594v1"},"cats":{"benchmark":0.2696998354,"new-dataset":0.4066814345,"data-annotation":0.5065489471,"dev-research":0.1825510402,"llms":0.5359449304,"data-quality":0.0797033728}}
{"text":"The aim is to translate motion capture inputs into English natural-language descriptions, such that the descriptions are generated synchronously with the actions performed, enabling semantic segmentation as a byproduct, but without requiring synchronized training data.","meta":{"url":"http://arxiv.org/abs/2310.10594v1"},"cats":{"benchmark":0.1858872975,"new-dataset":0.6921080712,"data-annotation":0.5219796239,"dev-research":0.2648352412,"llms":0.5112387321,"data-quality":0.191245428}}
{"text":"We propose a new recurrent formulation of local attention that is suited for synchronous/live text generation, as well as an improved motion encoder architecture better suited to smaller data and for synchronous generation.","meta":{"url":"http://arxiv.org/abs/2310.10594v1"},"cats":{"benchmark":0.217579483,"new-dataset":0.4160369618,"data-annotation":0.5047459872,"dev-research":0.190724481,"llms":0.5276684284,"data-quality":0.0968660817}}
{"text":"We evaluate both contributions in individual experiments, using the standard BLEU4 metric, as well as a simple semantic equivalence measure, on the KIT motion language dataset.","meta":{"url":"http://arxiv.org/abs/2310.10594v1"},"cats":{"benchmark":0.4028475623,"new-dataset":0.3302572601,"data-annotation":0.5398889003,"dev-research":0.1468476007,"llms":0.5246849732,"data-quality":0.2091073367}}
{"text":"In a follow-up experiment, we assess the quality of the synchronization of generated text in our proposed approaches through multiple evaluation metrics.","meta":{"url":"http://arxiv.org/abs/2310.10594v1"},"cats":{"benchmark":0.6135570093,"new-dataset":0.0485662707,"data-annotation":0.5049489847,"dev-research":0.2509697363,"llms":0.5260186977,"data-quality":0.2843329525}}
{"text":"We find that both contributions to the attention mechanism and the encoder architecture additively improve the quality of generated text (BLEU and semantic equivalence), but also of synchronization.","meta":{"url":"http://arxiv.org/abs/2310.10594v1"},"cats":{"benchmark":0.3476198266,"new-dataset":0.0511564227,"data-annotation":0.5249912757,"dev-research":0.2124212836,"llms":0.5462758381,"data-quality":0.207430206}}
{"text":"Our code will be made available at \\url{https://github.com/rd20karim/M2T-Segmentation/tree/main}","meta":{"url":"http://arxiv.org/abs/2310.10594v1"},"cats":{"benchmark":0.3114217284,"new-dataset":0.0777870309,"data-annotation":0.5155417355,"dev-research":0.1102009519,"llms":0.5859613628,"data-quality":0.1416690446}}
{"text":"Large-scale pre-trained vision foundation models, such as CLIP, have become de facto backbones for various vision tasks.","meta":{"url":"http://arxiv.org/abs/2310.10591v1"},"cats":{"benchmark":0.1965929534,"new-dataset":0.0830825166,"data-annotation":0.5021593952,"dev-research":0.1648198687,"llms":0.4729867532,"data-quality":0.0572391214}}
{"text":"However, due to their black-box nature, understanding the underlying rules behind these models' predictions and controlling model behaviors have remained open challenges.","meta":{"url":"http://arxiv.org/abs/2310.10591v1"},"cats":{"benchmark":0.2485988213,"new-dataset":0.0125661845,"data-annotation":0.4800724559,"dev-research":0.243260811,"llms":0.4317564919,"data-quality":0.1259090753}}
{"text":"We present a framework for interpreting vision transformer's latent tokens with natural language.","meta":{"url":"http://arxiv.org/abs/2310.10591v1"},"cats":{"benchmark":0.1607071657,"new-dataset":0.1122734635,"data-annotation":0.5342560122,"dev-research":0.3044500788,"llms":0.5252611067,"data-quality":0.323445742}}
{"text":"Given a latent token, our framework retains its semantic information to the final layer using transformer's local operations and retrieves the closest text for explanation.","meta":{"url":"http://arxiv.org/abs/2310.10591v1"},"cats":{"benchmark":0.2364925139,"new-dataset":0.0461453288,"data-annotation":0.5290862373,"dev-research":0.2231991631,"llms":0.5532886906,"data-quality":0.2572144838}}
{"text":"Our approach enables understanding of model visual reasoning procedure without needing additional model training or data collection.","meta":{"url":"http://arxiv.org/abs/2310.10591v1"},"cats":{"benchmark":0.1817466379,"new-dataset":0.1569659956,"data-annotation":0.48949418,"dev-research":0.314733442,"llms":0.5308698158,"data-quality":0.1104593186}}
{"text":"Based on the obtained interpretations, our framework allows for model editing that controls model reasoning behaviors and improves model robustness against biases and spurious correlations.","meta":{"url":"http://arxiv.org/abs/2310.10591v1"},"cats":{"benchmark":0.3186520162,"new-dataset":0.0141526603,"data-annotation":0.4985475095,"dev-research":0.3750601917,"llms":0.449050781,"data-quality":0.1899221375}}
{"text":"Open Information Extraction (OIE) aims to extract objective structured knowledge from natural texts, which has attracted growing attention to build dedicated models with human experience.","meta":{"url":"http://arxiv.org/abs/2310.10590v1"},"cats":{"benchmark":0.2596445288,"new-dataset":0.1165649718,"data-annotation":0.5178927567,"dev-research":0.1712640352,"llms":0.495086926,"data-quality":0.1721991115}}
{"text":"As the large language models (LLMs) have exhibited remarkable in-context learning capabilities, a question arises as to whether the task of OIE can be effectively tackled with this paradigm?","meta":{"url":"http://arxiv.org/abs/2310.10590v1"},"cats":{"benchmark":0.1795182309,"new-dataset":0.040607053,"data-annotation":0.5300236377,"dev-research":0.1277148927,"llms":0.6473369612,"data-quality":0.1189108245}}
{"text":"In this paper, we explore solving the OIE problem by constructing an appropriate reasoning environment for LLMs.","meta":{"url":"http://arxiv.org/abs/2310.10590v1"},"cats":{"benchmark":0.2415635594,"new-dataset":0.0627070471,"data-annotation":0.5176312188,"dev-research":0.1742975725,"llms":0.7222194501,"data-quality":0.1164957726}}
{"text":"Specifically, we first propose a method to effectively estimate the discrepancy of syntactic distribution between a LLM and test samples, which can serve as correlation evidence for preparing positive demonstrations.","meta":{"url":"http://arxiv.org/abs/2310.10590v1"},"cats":{"benchmark":0.4324672194,"new-dataset":0.0216450239,"data-annotation":0.547446135,"dev-research":0.1753813861,"llms":0.6371430719,"data-quality":0.303727568}}
{"text":"Upon the evidence, we introduce a simple yet effective mechanism to establish the reasoning environment for LLMs on specific tasks.","meta":{"url":"http://arxiv.org/abs/2310.10590v1"},"cats":{"benchmark":0.219473703,"new-dataset":0.032724003,"data-annotation":0.5090429713,"dev-research":0.2365943725,"llms":0.7859693079,"data-quality":0.0945997049}}
{"text":"Without bells and whistles, experimental results on the standard CaRB benchmark demonstrate that our $6$-shot approach outperforms state-of-the-art supervised method, achieving an $55.3$ $F_1$ score.","meta":{"url":"http://arxiv.org/abs/2310.10590v1"},"cats":{"benchmark":0.6456628772,"new-dataset":0.0436924382,"data-annotation":0.5165960613,"dev-research":0.152564482,"llms":0.3922739659,"data-quality":0.2265232775}}
{"text":"Further experiments on TACRED and ACE05 show that our method can naturally generalize to other information extraction tasks, resulting in improvements of $5.7$ and $6.8$ $F_1$ scores, respectively.","meta":{"url":"http://arxiv.org/abs/2310.10590v1"},"cats":{"benchmark":0.5841791182,"new-dataset":0.0777213528,"data-annotation":0.543932525,"dev-research":0.1545490077,"llms":0.4518055536,"data-quality":0.2954900353}}
{"text":"Building models that generate textual responses to user instructions for videos is a practical and challenging topic, as it requires both vision understanding and knowledge reasoning.","meta":{"url":"http://arxiv.org/abs/2310.10586v1"},"cats":{"benchmark":0.1570256944,"new-dataset":0.1113949628,"data-annotation":0.5393339458,"dev-research":0.3451404715,"llms":0.585096991,"data-quality":0.1412576908}}
{"text":"Compared to language and image modalities, training efficiency remains a serious problem as existing studies train models on massive sparse videos aligned with brief descriptions.","meta":{"url":"http://arxiv.org/abs/2310.10586v1"},"cats":{"benchmark":0.3186328011,"new-dataset":0.1371985781,"data-annotation":0.5408816653,"dev-research":0.123777488,"llms":0.4740093779,"data-quality":0.1890501634}}
{"text":"In this paper, we introduce BiLL-VTG, a fast adaptive framework that leverages large language models (LLMs) to reasoning on videos based on essential lightweight visual tools.","meta":{"url":"http://arxiv.org/abs/2310.10586v1"},"cats":{"benchmark":0.2622383372,"new-dataset":0.3183271312,"data-annotation":0.5410523554,"dev-research":0.2717863854,"llms":0.6167158142,"data-quality":0.1545850987}}
{"text":"Specifically, we reveal the key to response specific instructions is the concentration on relevant video events, and utilize two visual tools of structured scene graph generation and descriptive image caption generation to gather and represent the events information.","meta":{"url":"http://arxiv.org/abs/2310.10586v1"},"cats":{"benchmark":0.2277217828,"new-dataset":0.5278253763,"data-annotation":0.5263181507,"dev-research":0.2811546909,"llms":0.5391774527,"data-quality":0.1392245667}}
{"text":"Thus, a LLM equipped with world knowledge is adopted as the reasoning agent to achieve the response by performing multiple reasoning steps on specified video events.","meta":{"url":"http://arxiv.org/abs/2310.10586v1"},"cats":{"benchmark":0.1594165702,"new-dataset":0.0685751687,"data-annotation":0.5040323946,"dev-research":0.1849515773,"llms":0.7105987913,"data-quality":0.0734286947}}
{"text":"To address the difficulty of specifying events from agent, we further propose an Instruction-oriented Video Events Recognition (InsOVER) algorithm based on the efficient Hungarian matching to localize corresponding video events using linguistic instructions, enabling LLMs to interact with long videos.","meta":{"url":"http://arxiv.org/abs/2310.10586v1"},"cats":{"benchmark":0.2230984162,"new-dataset":0.2573520819,"data-annotation":0.5324689666,"dev-research":0.1747040194,"llms":0.6587075566,"data-quality":0.1917850159}}
{"text":"Extensive experiments on two typical video-based texts generations tasks show that our tuning-free framework outperforms the pre-trained models including Flamingo-80B, to achieve the state-of-the-art performance.","meta":{"url":"http://arxiv.org/abs/2310.10586v1"},"cats":{"benchmark":0.2982208559,"new-dataset":0.1368931298,"data-annotation":0.5426266284,"dev-research":0.1687312785,"llms":0.5783772273,"data-quality":0.1409724701}}
{"text":"Signal Temporal Logic (STL) is a formal language over continuous-time signals (such as trajectories of a multi-agent system) that allows for the specification of complex spatial and temporal system requirements (such as staying sufficiently close to each other within certain time intervals).","meta":{"url":"http://arxiv.org/abs/2310.10585v1"},"cats":{"benchmark":0.217388358,"new-dataset":0.0660250204,"data-annotation":0.4751618768,"dev-research":0.2651974298,"llms":0.5436120586,"data-quality":0.0478510431}}
{"text":"To promote robustness in multi-agent motion planning with such complex requirements, we consider motion planning with the goal of maximizing the temporal robustness of their joint STL specification, i.e. maximizing the permissible time shifts of each agent's trajectory while still satisfying the STL specification.","meta":{"url":"http://arxiv.org/abs/2310.10585v1"},"cats":{"benchmark":0.3074324969,"new-dataset":0.0647383596,"data-annotation":0.4913520694,"dev-research":0.1984160404,"llms":0.4599564407,"data-quality":0.0475518534}}
{"text":"Previous methods presented temporally robust motion planning and control in a discrete-time Mixed Integer Linear Programming (MILP) optimization scheme.","meta":{"url":"http://arxiv.org/abs/2310.10585v1"},"cats":{"benchmark":0.3783627622,"new-dataset":0.0310140158,"data-annotation":0.4802202464,"dev-research":0.1861927416,"llms":0.3850204457,"data-quality":0.0435564272}}
{"text":"In contrast, we parameterize the trajectory by continuous B\\'ezier curves, where the curvature and the time-traversal of the trajectory are parameterized individually.","meta":{"url":"http://arxiv.org/abs/2310.10585v1"},"cats":{"benchmark":0.436167115,"new-dataset":0.0055402081,"data-annotation":0.5017639892,"dev-research":0.1482101512,"llms":0.3848760136,"data-quality":0.0519566989}}
{"text":"We show an algorithm generating continuous-time temporally robust trajectories and prove soundness of our approach.","meta":{"url":"http://arxiv.org/abs/2310.10585v1"},"cats":{"benchmark":0.3979706194,"new-dataset":0.1437424008,"data-annotation":0.5144953137,"dev-research":0.1664648798,"llms":0.3991407889,"data-quality":0.1211149689}}
{"text":"Moreover, we empirically show that our parametrization realizes this with a considerable speed-up compared to state-of-the-art methods based on constant interval time discretization.","meta":{"url":"http://arxiv.org/abs/2310.10585v1"},"cats":{"benchmark":0.5987405241,"new-dataset":0.0306177067,"data-annotation":0.5150425006,"dev-research":0.1738223584,"llms":0.3754395123,"data-quality":0.0470741904}}
{"text":"Both standalone language models (LMs) as well as LMs within downstream-task systems have been shown to generate statements which are factually untrue.","meta":{"url":"http://arxiv.org/abs/2310.10583v1"},"cats":{"benchmark":0.1942601209,"new-dataset":0.0161363222,"data-annotation":0.5030070409,"dev-research":0.2653226535,"llms":0.6733083174,"data-quality":0.2951806813}}
{"text":"This problem is especially severe for low-resource languages, where training data is scarce and of worse quality than for high-resource languages.","meta":{"url":"http://arxiv.org/abs/2310.10583v1"},"cats":{"benchmark":0.2917991735,"new-dataset":0.1566084955,"data-annotation":0.5535926991,"dev-research":0.2461953443,"llms":0.5444439152,"data-quality":0.3905577433}}
{"text":"In this opinion piece, we argue that LMs in their current state will never be fully trustworthy in critical settings and suggest a possible novel strategy to handle this issue: by building LMs such that can cite their sources - i.e., point a user to the parts of their training data that back up their outputs.","meta":{"url":"http://arxiv.org/abs/2310.10583v1"},"cats":{"benchmark":0.2815772495,"new-dataset":0.097400588,"data-annotation":0.493167868,"dev-research":0.1754675015,"llms":0.6597858262,"data-quality":0.2983762895}}
{"text":"We first discuss which current NLP tasks would or would not benefit from such models.","meta":{"url":"http://arxiv.org/abs/2310.10583v1"},"cats":{"benchmark":0.3161143973,"new-dataset":0.0325006305,"data-annotation":0.528270818,"dev-research":0.1931128107,"llms":0.5126823465,"data-quality":0.2435667721}}
{"text":"We then highlight the expected benefits such models would bring, e.g., quick verifiability of statements.","meta":{"url":"http://arxiv.org/abs/2310.10583v1"},"cats":{"benchmark":0.3494493263,"new-dataset":0.0041283619,"data-annotation":0.5189569919,"dev-research":0.2263938767,"llms":0.5112215111,"data-quality":0.1242561205}}
{"text":"We end by outlining the individual tasks that would need to be solved on the way to developing LMs with the ability to cite.","meta":{"url":"http://arxiv.org/abs/2310.10583v1"},"cats":{"benchmark":0.262656637,"new-dataset":0.0347735794,"data-annotation":0.501855908,"dev-research":0.2043283716,"llms":0.6539639592,"data-quality":0.1436463923}}
{"text":"We hope to start a discussion about the field's current approach to building LMs, especially for low-resource languages, and the role of the training data in explaining model generations.","meta":{"url":"http://arxiv.org/abs/2310.10583v1"},"cats":{"benchmark":0.1644690491,"new-dataset":0.122136921,"data-annotation":0.5250208912,"dev-research":0.2034793469,"llms":0.6626679944,"data-quality":0.1375746011}}
{"text":"In this paper we show that using implicative algebras one can produce models of set theory generalizing Heyting/Boolean-valued models and realizability models of (I)ZF, both in intuitionistic and classical logic.","meta":{"url":"http://arxiv.org/abs/2310.10576v1"},"cats":{"benchmark":0.2714320385,"new-dataset":0.0479117599,"data-annotation":0.5296540382,"dev-research":0.2324144952,"llms":0.5358886269,"data-quality":0.1100436829}}
{"text":"This has as consequence that any topos which is obtained from a Set-based tripos as the result of the tripos-to-topos construction hosts a model of intuitionistic or classical set theory, provided a large enough strongly inaccessible cardinal exists.","meta":{"url":"http://arxiv.org/abs/2310.10576v1"},"cats":{"benchmark":0.2611767096,"new-dataset":0.0600058492,"data-annotation":0.5112795777,"dev-research":0.1646614531,"llms":0.6195559865,"data-quality":0.0732078579}}
{"text":"While some convolutional neural networks (CNNs) have achieved great success in object recognition, they struggle to identify objects in images corrupted with different types of common noise patterns.","meta":{"url":"http://arxiv.org/abs/2310.10575v1"},"cats":{"benchmark":0.2678128167,"new-dataset":0.1683084892,"data-annotation":0.5254079896,"dev-research":0.1938712216,"llms":0.4407873404,"data-quality":0.5845472209}}
{"text":"Recently, it was shown that simulating computations in early visual areas at the front of CNNs leads to improvements in robustness to image corruptions.","meta":{"url":"http://arxiv.org/abs/2310.10575v1"},"cats":{"benchmark":0.2807836899,"new-dataset":0.0643359703,"data-annotation":0.526167226,"dev-research":0.3161142985,"llms":0.4713499217,"data-quality":0.351081869}}
{"text":"Here, we further explore this result and show that the neuronal representations that emerge from precisely matching the distribution of RF properties found in primate V1 is key for this improvement in robustness.","meta":{"url":"http://arxiv.org/abs/2310.10575v1"},"cats":{"benchmark":0.2950499392,"new-dataset":0.0152603251,"data-annotation":0.5098579896,"dev-research":0.1276536736,"llms":0.4493496981,"data-quality":0.1901969202}}
{"text":"We built two variants of a model with a front-end modeling the primate primary visual cortex (V1): one sampling RF properties uniformly and the other sampling from empirical biological distributions.","meta":{"url":"http://arxiv.org/abs/2310.10575v1"},"cats":{"benchmark":0.2868928446,"new-dataset":0.1331518781,"data-annotation":0.4984636176,"dev-research":0.0970044746,"llms":0.4584965667,"data-quality":0.1033987669}}
{"text":"The model with the biological sampling has a considerably higher robustness to image corruptions that the uniform variant (relative difference of 8.72%).","meta":{"url":"http://arxiv.org/abs/2310.10575v1"},"cats":{"benchmark":0.5040387355,"new-dataset":0.0577543496,"data-annotation":0.5034243597,"dev-research":0.1380872428,"llms":0.4405712791,"data-quality":0.3173692501}}
{"text":"While similar neuronal sub-populations across the two variants have similar response properties and learn similar downstream weights, the impact on downstream processing is strikingly different.","meta":{"url":"http://arxiv.org/abs/2310.10575v1"},"cats":{"benchmark":0.352169734,"new-dataset":0.0066683031,"data-annotation":0.5004439033,"dev-research":0.1394759748,"llms":0.4818000031,"data-quality":0.1383121268}}
{"text":"This result sheds light on the origin of the improvements in robustness observed in some biologically-inspired models, pointing to the need of precisely mimicking the neuronal representations found in the primate brain.","meta":{"url":"http://arxiv.org/abs/2310.10575v1"},"cats":{"benchmark":0.2964749088,"new-dataset":0.0041879651,"data-annotation":0.5201729511,"dev-research":0.1999618263,"llms":0.4358257122,"data-quality":0.1441386532}}
{"text":"We study the impact of content moderation policies in online communities.","meta":{"url":"http://arxiv.org/abs/2310.10573v1"},"cats":{"benchmark":0.3767435453,"new-dataset":0.0458814091,"data-annotation":0.4924186703,"dev-research":0.2573495646,"llms":0.5201551468,"data-quality":0.1555684239}}
{"text":"In our theoretical model, a platform chooses a content moderation policy and individuals choose whether or not to participate in the community according to the fraction of user content that aligns with their preferences.","meta":{"url":"http://arxiv.org/abs/2310.10573v1"},"cats":{"benchmark":0.3295378525,"new-dataset":0.0231124049,"data-annotation":0.4836005152,"dev-research":0.1657271589,"llms":0.512967398,"data-quality":0.1185901158}}
{"text":"The effects of content moderation, at first blush, might seem obvious: it restricts speech on a platform.","meta":{"url":"http://arxiv.org/abs/2310.10573v1"},"cats":{"benchmark":0.2477870179,"new-dataset":0.0085231121,"data-annotation":0.5013768403,"dev-research":0.2167631541,"llms":0.5310109344,"data-quality":0.1697814226}}
{"text":"However, when user participation decisions are taken into account, its effects can be more subtle $\\unicode{x2013}$ and counter-intuitive.","meta":{"url":"http://arxiv.org/abs/2310.10573v1"},"cats":{"benchmark":0.2819449487,"new-dataset":0.010779943,"data-annotation":0.5184766177,"dev-research":0.3526615971,"llms":0.5486937929,"data-quality":0.1762335147}}
{"text":"For example, our model can straightforwardly demonstrate how moderation policies may increase participation and diversify content available on the platform.","meta":{"url":"http://arxiv.org/abs/2310.10573v1"},"cats":{"benchmark":0.2923811854,"new-dataset":0.0185872326,"data-annotation":0.4964145095,"dev-research":0.1924088468,"llms":0.5131329814,"data-quality":0.0952921799}}
{"text":"In our analysis, we explore a rich set of interconnected phenomena related to content moderation in online communities.","meta":{"url":"http://arxiv.org/abs/2310.10573v1"},"cats":{"benchmark":0.3312082822,"new-dataset":0.0441759653,"data-annotation":0.4983553342,"dev-research":0.2059911939,"llms":0.5047059686,"data-quality":0.14374652}}
{"text":"We first characterize the effectiveness of a natural class of moderation policies for creating and sustaining stable communities.","meta":{"url":"http://arxiv.org/abs/2310.10573v1"},"cats":{"benchmark":0.3439060836,"new-dataset":0.0714740367,"data-annotation":0.4791755654,"dev-research":0.2430304307,"llms":0.5343875052,"data-quality":0.1524783532}}
{"text":"Building on this, we explore how resource-limited or ideological platforms might set policies, how communities are affected by differing levels of personalization, and competition between platforms.","meta":{"url":"http://arxiv.org/abs/2310.10573v1"},"cats":{"benchmark":0.2527621807,"new-dataset":0.0289592932,"data-annotation":0.5009803766,"dev-research":0.2121644561,"llms":0.5126759615,"data-quality":0.1304837082}}
{"text":"Our model provides a vocabulary and mathematically tractable framework for analyzing platform decisions about content moderation.","meta":{"url":"http://arxiv.org/abs/2310.10573v1"},"cats":{"benchmark":0.3719934131,"new-dataset":0.0393945517,"data-annotation":0.5009284022,"dev-research":0.2097509141,"llms":0.497422298,"data-quality":0.1275442114}}
{"text":"State-of-the-art question answering (QA) models exhibit a variety of social biases (e.g., with respect to sex or race), generally explained by similar issues in their training data.","meta":{"url":"http://arxiv.org/abs/2310.10571v1"},"cats":{"benchmark":0.2776951037,"new-dataset":0.0413259022,"data-annotation":0.5488469232,"dev-research":0.1751593297,"llms":0.5094999545,"data-quality":0.158894999}}
{"text":"However, what has been overlooked so far is that in the critical domain of biomedicine, any unjustified change in model output due to patient demographics is problematic: it results in the unfair treatment of patients.","meta":{"url":"http://arxiv.org/abs/2310.10571v1"},"cats":{"benchmark":0.4065391287,"new-dataset":0.0137800167,"data-annotation":0.5045749057,"dev-research":0.3415331499,"llms":0.4840663512,"data-quality":0.2301341796}}
{"text":"Selecting only questions on biomedical topics whose answers do not depend on ethnicity, sex, or sexual orientation, we ask the following research questions: (RQ1) Do the answers of QA models change when being provided with irrelevant demographic information?","meta":{"url":"http://arxiv.org/abs/2310.10571v1"},"cats":{"benchmark":0.2880767737,"new-dataset":0.0239587056,"data-annotation":0.5051120581,"dev-research":0.139857468,"llms":0.497408908,"data-quality":0.0930091545}}
{"text":"(RQ2) Does the answer of RQ1 differ between knowledge graph (KG)-grounded and text-based QA systems?","meta":{"url":"http://arxiv.org/abs/2310.10571v1"},"cats":{"benchmark":0.2917038147,"new-dataset":0.0958080156,"data-annotation":0.4922023846,"dev-research":0.1595661366,"llms":0.5389771197,"data-quality":0.1107332568}}
{"text":"We find that irrelevant demographic information change up to 15% of the answers of a KG-grounded system and up to 23% of the answers of a text-based system, including changes that affect accuracy.","meta":{"url":"http://arxiv.org/abs/2310.10571v1"},"cats":{"benchmark":0.3529598236,"new-dataset":0.0405294718,"data-annotation":0.516506963,"dev-research":0.2017234058,"llms":0.5087221817,"data-quality":0.190477075}}
{"text":"We conclude that unjustified answer changes caused by patient demographics are a frequent phenomenon, which raises fairness concerns and should be paid more attention to.","meta":{"url":"http://arxiv.org/abs/2310.10571v1"},"cats":{"benchmark":0.404812702,"new-dataset":0.0106717913,"data-annotation":0.5153273827,"dev-research":0.3373691863,"llms":0.5387570888,"data-quality":0.1883178428}}
{"text":"Large language models (LLMs) excel in zero-shot abstractive summarization tasks, delivering fluent and pertinent summaries.","meta":{"url":"http://arxiv.org/abs/2310.10570v1"},"cats":{"benchmark":0.3185583623,"new-dataset":0.2425813646,"data-annotation":0.5360346001,"dev-research":0.1617950429,"llms":0.6048087288,"data-quality":0.1495119902}}
{"text":"Recent advancements have extended their capabilities to handle long-input contexts, surpassing token limits of 32k or more.","meta":{"url":"http://arxiv.org/abs/2310.10570v1"},"cats":{"benchmark":0.2766944349,"new-dataset":0.0892486677,"data-annotation":0.506309573,"dev-research":0.1735276196,"llms":0.5762118007,"data-quality":0.0932601815}}
{"text":"However, in the realm of multi-document question answering, language models exhibit uneven utilization of their input context.","meta":{"url":"http://arxiv.org/abs/2310.10570v1"},"cats":{"benchmark":0.2772459879,"new-dataset":0.0174450284,"data-annotation":0.5401642173,"dev-research":0.1703798089,"llms":0.5109287428,"data-quality":0.1759270933}}
{"text":"They tend to favor the initial and final segments, resulting in a U-shaped performance pattern concerning where the answer is located within the input.","meta":{"url":"http://arxiv.org/abs/2310.10570v1"},"cats":{"benchmark":0.4582153746,"new-dataset":0.0025486769,"data-annotation":0.5291079292,"dev-research":0.2230875173,"llms":0.4614113864,"data-quality":0.1031789907}}
{"text":"This bias raises concerns, particularly in summarization tasks where crucial content may be dispersed throughout the source document(s).","meta":{"url":"http://arxiv.org/abs/2310.10570v1"},"cats":{"benchmark":0.3797772244,"new-dataset":0.0071794081,"data-annotation":0.5291839363,"dev-research":0.2785523647,"llms":0.5191927173,"data-quality":0.1822904433}}
{"text":"This paper presents a comprehensive investigation encompassing 10 datasets, 4 LLMs, and 5 evaluation metrics to analyze how these models leverage their input for abstractive summarization.","meta":{"url":"http://arxiv.org/abs/2310.10570v1"},"cats":{"benchmark":0.3759479764,"new-dataset":0.1215202165,"data-annotation":0.5332575695,"dev-research":0.2070203031,"llms":0.588964746,"data-quality":0.1800424112}}
{"text":"Our findings reveal a pronounced bias towards the introductory content (and to a lesser extent, the final content), posing challenges for LLM performance across a range of diverse summarization benchmarks.","meta":{"url":"http://arxiv.org/abs/2310.10570v1"},"cats":{"benchmark":0.4691600307,"new-dataset":0.0258116633,"data-annotation":0.5256336419,"dev-research":0.1550858478,"llms":0.7081991249,"data-quality":0.1310682306}}
{"text":"Retrieval-augmented language models show promise in addressing issues like outdated information and hallucinations in language models (LMs).","meta":{"url":"http://arxiv.org/abs/2310.10567v1"},"cats":{"benchmark":0.2248344198,"new-dataset":0.0220630914,"data-annotation":0.5204972142,"dev-research":0.1873666005,"llms":0.6213403219,"data-quality":0.323327594}}
{"text":"However, current research faces two main problems: 1) determining what information to retrieve, and 2) effectively combining retrieved information during generation.","meta":{"url":"http://arxiv.org/abs/2310.10567v1"},"cats":{"benchmark":0.2818789113,"new-dataset":0.0207466878,"data-annotation":0.4862138954,"dev-research":0.242512559,"llms":0.5471479638,"data-quality":0.1284452614}}
{"text":"We argue that valuable retrieved information should not only be related to the current source text but also consider the future target text, given the nature of LMs that model future tokens.","meta":{"url":"http://arxiv.org/abs/2310.10567v1"},"cats":{"benchmark":0.2603653952,"new-dataset":0.0332899315,"data-annotation":0.5150051508,"dev-research":0.1332804684,"llms":0.6257397538,"data-quality":0.2187159906}}
{"text":"Moreover, we propose that aggregation using latent variables derived from a compact latent space is more efficient than utilizing explicit raw text, which is limited by context length and susceptible to noise.","meta":{"url":"http://arxiv.org/abs/2310.10567v1"},"cats":{"benchmark":0.4132375219,"new-dataset":0.076094446,"data-annotation":0.5166121621,"dev-research":0.152636346,"llms":0.4441138485,"data-quality":0.2036316366}}
{"text":"Therefore, we introduce RegaVAE, a retrieval-augmented language model built upon the variational auto-encoder (VAE).","meta":{"url":"http://arxiv.org/abs/2310.10567v1"},"cats":{"benchmark":0.2996974287,"new-dataset":0.0453114841,"data-annotation":0.5418019627,"dev-research":0.1299004651,"llms":0.5026740675,"data-quality":0.1941873614}}
{"text":"It encodes the text corpus into a latent space, capturing current and future information from both source and target text.","meta":{"url":"http://arxiv.org/abs/2310.10567v1"},"cats":{"benchmark":0.229601916,"new-dataset":0.0655114798,"data-annotation":0.5172584461,"dev-research":0.2481576293,"llms":0.539853508,"data-quality":0.1891654891}}
{"text":"Additionally, we leverage the VAE to initialize the latent space and adopt the probabilistic form of the retrieval generation paradigm by expanding the Gaussian prior distribution into a Gaussian mixture distribution.","meta":{"url":"http://arxiv.org/abs/2310.10567v1"},"cats":{"benchmark":0.3355899688,"new-dataset":0.0371736434,"data-annotation":0.5375664103,"dev-research":0.0786036918,"llms":0.4710661795,"data-quality":0.1715091855}}
{"text":"Theoretical analysis provides an optimizable upper bound for RegaVAE.","meta":{"url":"http://arxiv.org/abs/2310.10567v1"},"cats":{"benchmark":0.6603705933,"new-dataset":0.0103160167,"data-annotation":0.5218300768,"dev-research":0.135632111,"llms":0.3441443798,"data-quality":0.0501197014}}
{"text":"Experimental results on various datasets demonstrate significant improvements in text generation quality and hallucination removal.","meta":{"url":"http://arxiv.org/abs/2310.10567v1"},"cats":{"benchmark":0.3544028681,"new-dataset":0.115219012,"data-annotation":0.5259245279,"dev-research":0.2198354221,"llms":0.5909597062,"data-quality":0.3266872072}}
{"text":"Fluid simulation is a long-standing challenge due to the intrinsic high-dimensional non-linear dynamics.","meta":{"url":"http://arxiv.org/abs/2310.10565v1"},"cats":{"benchmark":0.3320166169,"new-dataset":0.0391505969,"data-annotation":0.5037186143,"dev-research":0.1098819302,"llms":0.4315592227,"data-quality":0.0529347309}}
{"text":"Previous methods usually utilize the non-linear modeling capability of deep models to directly estimate velocity fields for future prediction.","meta":{"url":"http://arxiv.org/abs/2310.10565v1"},"cats":{"benchmark":0.3708760923,"new-dataset":0.0238967318,"data-annotation":0.516076037,"dev-research":0.1591022224,"llms":0.3957180879,"data-quality":0.1051109367}}
{"text":"However, skipping over inherent physical properties but directly learning superficial velocity fields will overwhelm the model from generating precise or physics-reliable results.","meta":{"url":"http://arxiv.org/abs/2310.10565v1"},"cats":{"benchmark":0.3140929288,"new-dataset":0.0113575744,"data-annotation":0.5180478526,"dev-research":0.1617175572,"llms":0.4662527225,"data-quality":0.0998803684}}
{"text":"In this paper, we propose the HelmSim toward an accurate and interpretable simulator for fluid.","meta":{"url":"http://arxiv.org/abs/2310.10565v1"},"cats":{"benchmark":0.3493585488,"new-dataset":0.0694668206,"data-annotation":0.5081348807,"dev-research":0.1656954603,"llms":0.5051814228,"data-quality":0.0637137231}}
{"text":"Inspired by the Helmholtz theorem, we design a HelmDynamic block to learn the Helmholtz dynamics, which decomposes fluid dynamics into more solvable curl-free and divergence-free parts, physically corresponding to potential and stream functions of fluid.","meta":{"url":"http://arxiv.org/abs/2310.10565v1"},"cats":{"benchmark":0.2378013987,"new-dataset":0.0672856221,"data-annotation":0.5091559523,"dev-research":0.1910747952,"llms":0.5179915774,"data-quality":0.0535707769}}
{"text":"By embedding the HelmDynamic block into a Multiscale Integration Network, HelmSim can integrate learned Helmholtz dynamics along temporal dimension in multiple spatial scales to yield future fluid.","meta":{"url":"http://arxiv.org/abs/2310.10565v1"},"cats":{"benchmark":0.2425164087,"new-dataset":0.0756997552,"data-annotation":0.4837281944,"dev-research":0.1482224355,"llms":0.5190470265,"data-quality":0.0489490593}}
{"text":"Comparing with previous velocity estimating methods, HelmSim is faithfully derived from Helmholtz theorem and ravels out complex fluid dynamics with physically interpretable evidence.","meta":{"url":"http://arxiv.org/abs/2310.10565v1"},"cats":{"benchmark":0.4060182588,"new-dataset":0.0513101317,"data-annotation":0.5088319883,"dev-research":0.179162587,"llms":0.4584031349,"data-quality":0.0573689924}}
{"text":"Experimentally, our proposed HelmSim achieves the consistent state-of-the-art in both numerical simulated and real-world observed benchmarks, even for scenarios with complex boundaries.","meta":{"url":"http://arxiv.org/abs/2310.10565v1"},"cats":{"benchmark":0.5693900793,"new-dataset":0.0480406048,"data-annotation":0.4993906535,"dev-research":0.1446628509,"llms":0.5160173375,"data-quality":0.047305498}}
{"text":"We propose Re-parameterized Refocusing Convolution (RefConv) as a replacement for regular convolutional layers, which is a plug-and-play module to improve the performance without any inference costs.","meta":{"url":"http://arxiv.org/abs/2310.10563v1"},"cats":{"benchmark":0.4379482454,"new-dataset":0.0963678249,"data-annotation":0.5098368305,"dev-research":0.1711257376,"llms":0.482641866,"data-quality":0.1088780683}}
{"text":"Specifically, given a pre-trained model, RefConv applies a trainable Refocusing Transformation to the basis kernels inherited from the pre-trained model to establish connections among the parameters.","meta":{"url":"http://arxiv.org/abs/2310.10563v1"},"cats":{"benchmark":0.2636915913,"new-dataset":0.1256001334,"data-annotation":0.5018602166,"dev-research":0.1689981823,"llms":0.4646449901,"data-quality":0.0856503557}}
{"text":"For example, a depth-wise RefConv can relate the parameters of a specific channel of convolution kernel to the parameters of the other kernel, i.e., make them refocus on the other parts of the model they have never attended to, rather than focus on the input features only.","meta":{"url":"http://arxiv.org/abs/2310.10563v1"},"cats":{"benchmark":0.3154434657,"new-dataset":0.0211175744,"data-annotation":0.5026820495,"dev-research":0.203431233,"llms":0.4561193803,"data-quality":0.1090455689}}
{"text":"From another perspective, RefConv augments the priors of existing model structures by utilizing the representations encoded in the pre-trained parameters as the priors and refocusing on them to learn novel representations, thus further enhancing the representational capacity of the pre-trained model.","meta":{"url":"http://arxiv.org/abs/2310.10563v1"},"cats":{"benchmark":0.2394478351,"new-dataset":0.0608110575,"data-annotation":0.516601218,"dev-research":0.2210041351,"llms":0.4884110021,"data-quality":0.0759847872}}
{"text":"Experimental results validated that RefConv can improve multiple CNN-based models by a clear margin on image classification (up to 1.47% higher top-1 accuracy on ImageNet), object detection and semantic segmentation without introducing any extra inference costs or altering the original model structure.","meta":{"url":"http://arxiv.org/abs/2310.10563v1"},"cats":{"benchmark":0.3694191228,"new-dataset":0.0950762261,"data-annotation":0.5162374349,"dev-research":0.1883582735,"llms":0.4712702712,"data-quality":0.1750637488}}
{"text":"Further studies demonstrated that RefConv can reduce the redundancy of channels and smooth the loss landscape, which explains its effectiveness.","meta":{"url":"http://arxiv.org/abs/2310.10563v1"},"cats":{"benchmark":0.4795372815,"new-dataset":0.0187437205,"data-annotation":0.4919117892,"dev-research":0.2469929683,"llms":0.5090898317,"data-quality":0.1114885948}}
{"text":"Despite the growing interest in ML-guided EDA tools from RTL to GDSII, there are no standard datasets or prototypical learning tasks defined for the EDA problem domain.","meta":{"url":"http://arxiv.org/abs/2310.10560v1"},"cats":{"benchmark":0.296610332,"new-dataset":0.2515528505,"data-annotation":0.4930191056,"dev-research":0.1621657891,"llms":0.5405237249,"data-quality":0.1360311265}}
{"text":"Experience from the computer vision community suggests that such datasets are crucial to spur further progress in ML for EDA.","meta":{"url":"http://arxiv.org/abs/2310.10560v1"},"cats":{"benchmark":0.2996416835,"new-dataset":0.272932581,"data-annotation":0.4987965598,"dev-research":0.2150349263,"llms":0.4857722289,"data-quality":0.1558670769}}
{"text":"Here we describe our experience curating two large-scale, high-quality datasets for Verilog code generation and logic synthesis.","meta":{"url":"http://arxiv.org/abs/2310.10560v1"},"cats":{"benchmark":0.2951582807,"new-dataset":0.9038561495,"data-annotation":0.5034215318,"dev-research":0.3762755115,"llms":0.6616584811,"data-quality":0.1225456596}}
{"text":"The first, VeriGen, is a dataset of Verilog code collected from GitHub and Verilog textbooks.","meta":{"url":"http://arxiv.org/abs/2310.10560v1"},"cats":{"benchmark":0.2686693544,"new-dataset":0.7441494249,"data-annotation":0.5243133578,"dev-research":0.3095544364,"llms":0.6447674457,"data-quality":0.1228859632}}
{"text":"The second, OpenABC-D, is a large-scale, labeled dataset designed to aid ML for logic synthesis tasks.","meta":{"url":"http://arxiv.org/abs/2310.10560v1"},"cats":{"benchmark":0.2773993681,"new-dataset":0.6273843083,"data-annotation":0.4855130673,"dev-research":0.216891653,"llms":0.5785429292,"data-quality":0.1122324808}}
{"text":"The dataset consists of 870,000 And-Inverter-Graphs (AIGs) produced from 1500 synthesis runs on a large number of open-source hardware projects.","meta":{"url":"http://arxiv.org/abs/2310.10560v1"},"cats":{"benchmark":0.249690389,"new-dataset":0.8732697837,"data-annotation":0.5095542491,"dev-research":0.1999067657,"llms":0.5139064248,"data-quality":0.0871194972}}
{"text":"In this paper we will discuss challenges in curating, maintaining and growing the size and scale of these datasets.","meta":{"url":"http://arxiv.org/abs/2310.10560v1"},"cats":{"benchmark":0.3865939042,"new-dataset":0.8762680175,"data-annotation":0.4951118488,"dev-research":0.2209544359,"llms":0.4360472228,"data-quality":0.2813969263}}
{"text":"We will also touch upon questions of dataset quality and security, and the use of novel data augmentation tools that are tailored for the hardware domain.","meta":{"url":"http://arxiv.org/abs/2310.10560v1"},"cats":{"benchmark":0.3330032926,"new-dataset":0.3322981193,"data-annotation":0.4729092045,"dev-research":0.2748034261,"llms":0.5960285261,"data-quality":0.2444695906}}
{"text":"A recently popular approach to solving reinforcement learning is with data from human preferences.","meta":{"url":"http://arxiv.org/abs/2310.10556v1"},"cats":{"benchmark":0.240776577,"new-dataset":0.0755785412,"data-annotation":0.4952688608,"dev-research":0.1846049955,"llms":0.4437781102,"data-quality":0.0705261732}}
{"text":"In fact, human preference data are now used with classic reinforcement learning algorithms such as actor-critic methods, which involve evaluating an intermediate policy over a reward learned from human preference data with distribution shift, known as off-policy evaluation (OPE).","meta":{"url":"http://arxiv.org/abs/2310.10556v1"},"cats":{"benchmark":0.314044229,"new-dataset":0.0586498835,"data-annotation":0.4895663125,"dev-research":0.1498900113,"llms":0.4504418489,"data-quality":0.0683243193}}
{"text":"Such algorithm includes (i) learning reward function from human preference dataset, and (ii) learning expected cumulative reward of a target policy.","meta":{"url":"http://arxiv.org/abs/2310.10556v1"},"cats":{"benchmark":0.3271706517,"new-dataset":0.1146761922,"data-annotation":0.5260925905,"dev-research":0.1118179483,"llms":0.4242154222,"data-quality":0.0885264335}}
{"text":"Despite the huge empirical success, existing OPE methods with preference data often lack theoretical understanding and rely heavily on heuristics.","meta":{"url":"http://arxiv.org/abs/2310.10556v1"},"cats":{"benchmark":0.4698848639,"new-dataset":0.0058667018,"data-annotation":0.5044275532,"dev-research":0.2032279763,"llms":0.4451199447,"data-quality":0.1121197044}}
{"text":"In this paper, we study the sample efficiency of OPE with human preference and establish a statistical guarantee for it.","meta":{"url":"http://arxiv.org/abs/2310.10556v1"},"cats":{"benchmark":0.650138708,"new-dataset":0.014411097,"data-annotation":0.5125276199,"dev-research":0.1390814073,"llms":0.3863115288,"data-quality":0.0750051238}}
{"text":"Specifically, we approach OPE by learning the value function by fitted-Q-evaluation with a deep neural network.","meta":{"url":"http://arxiv.org/abs/2310.10556v1"},"cats":{"benchmark":0.4620400707,"new-dataset":0.1426627647,"data-annotation":0.5214684406,"dev-research":0.1577859861,"llms":0.3439936343,"data-quality":0.1350888384}}
{"text":"By appropriately selecting the size of a ReLU network, we show that one can leverage any low-dimensional manifold structure in the Markov decision process and obtain a sample-efficient estimator without suffering from the curse of high data ambient dimensionality.","meta":{"url":"http://arxiv.org/abs/2310.10556v1"},"cats":{"benchmark":0.4545889404,"new-dataset":0.0738435688,"data-annotation":0.5169184585,"dev-research":0.1016150225,"llms":0.4103135733,"data-quality":0.0794572512}}
{"text":"Under the assumption of high reward smoothness, our results \\textit{almost align with the classical OPE results with observable reward data}.","meta":{"url":"http://arxiv.org/abs/2310.10556v1"},"cats":{"benchmark":0.5679807628,"new-dataset":0.0247523726,"data-annotation":0.5311477717,"dev-research":0.0928050501,"llms":0.347940486,"data-quality":0.156602772}}
{"text":"To the best of our knowledge, this is the first result that establishes a \\textit{provably efficient} guarantee for off-policy evaluation with RLHF.","meta":{"url":"http://arxiv.org/abs/2310.10556v1"},"cats":{"benchmark":0.4897821689,"new-dataset":0.0434927129,"data-annotation":0.5262671343,"dev-research":0.1624603835,"llms":0.4882667604,"data-quality":0.1508764288}}
{"text":"An important challenge faced by wind farm operators is to reduce operation and maintenance cost.","meta":{"url":"http://arxiv.org/abs/2310.10555v1"},"cats":{"benchmark":0.4439792489,"new-dataset":0.0128979166,"data-annotation":0.4984484022,"dev-research":0.3529119994,"llms":0.4770112423,"data-quality":0.0679189879}}
{"text":"Structural health monitoring provides a means of cost reduction through minimising unnecessary maintenance trips as well as prolonging turbine service life.","meta":{"url":"http://arxiv.org/abs/2310.10555v1"},"cats":{"benchmark":0.4575706971,"new-dataset":0.0280300439,"data-annotation":0.4921952458,"dev-research":0.309890689,"llms":0.4532511791,"data-quality":0.0692339668}}
{"text":"Population-based structural health monitoring can further reduce the cost of health monitoring systems by implementing one system for multiple structures (i.e.~turbines).","meta":{"url":"http://arxiv.org/abs/2310.10555v1"},"cats":{"benchmark":0.4424581296,"new-dataset":0.0209221474,"data-annotation":0.4946207853,"dev-research":0.2355790645,"llms":0.4510259341,"data-quality":0.0483804883}}
{"text":"At the same time, shared data within a population of structures may improve the predictions of structural behaviour.","meta":{"url":"http://arxiv.org/abs/2310.10555v1"},"cats":{"benchmark":0.3769179305,"new-dataset":0.0442396294,"data-annotation":0.4870346175,"dev-research":0.218814713,"llms":0.4302506964,"data-quality":0.0921190102}}
{"text":"To monitor turbine performance at a population/farm level, an important initial step is to construct a model that describes the behaviour of all turbines under normal conditions.","meta":{"url":"http://arxiv.org/abs/2310.10555v1"},"cats":{"benchmark":0.3603292995,"new-dataset":0.0267112964,"data-annotation":0.5126245056,"dev-research":0.2055059108,"llms":0.3994271282,"data-quality":0.0540909863}}
{"text":"This paper proposes a population-level model that explicitly captures the spatial and temporal correlations (between turbines) induced by the wake effect.","meta":{"url":"http://arxiv.org/abs/2310.10555v1"},"cats":{"benchmark":0.3006072851,"new-dataset":0.0323444009,"data-annotation":0.5267867702,"dev-research":0.1822305037,"llms":0.4494518838,"data-quality":0.0571102534}}
{"text":"The proposed model is a Gaussian process-based spatial autoregressive model, named here a GP-SPARX model.","meta":{"url":"http://arxiv.org/abs/2310.10555v1"},"cats":{"benchmark":0.3631873307,"new-dataset":0.0662748108,"data-annotation":0.5041103819,"dev-research":0.1261068825,"llms":0.3603736583,"data-quality":0.0547487193}}
{"text":"This approach is developed since (a) it reflects our physical understanding of the wake effect, and (b) it benefits from a stochastic data-based learner.","meta":{"url":"http://arxiv.org/abs/2310.10555v1"},"cats":{"benchmark":0.2890440343,"new-dataset":0.0731799889,"data-annotation":0.528517212,"dev-research":0.1991433056,"llms":0.4563832478,"data-quality":0.1029860299}}
{"text":"A case study is provided to demonstrate the capability of the GP-SPARX model in capturing spatial and temporal variations as well as its potential applicability in a health monitoring system.","meta":{"url":"http://arxiv.org/abs/2310.10555v1"},"cats":{"benchmark":0.4347746313,"new-dataset":0.0944578455,"data-annotation":0.4735630864,"dev-research":0.1771984797,"llms":0.4463227586,"data-quality":0.048970924}}
{"text":"Identifying key patterns of tactics implemented by rival teams, and developing effective responses, lies at the heart of modern football.","meta":{"url":"http://arxiv.org/abs/2310.10553v1"},"cats":{"benchmark":0.3311254085,"new-dataset":0.0394569925,"data-annotation":0.5163291423,"dev-research":0.3250155821,"llms":0.4894989615,"data-quality":0.0562960124}}
{"text":"However, doing so algorithmically remains an open research challenge.","meta":{"url":"http://arxiv.org/abs/2310.10553v1"},"cats":{"benchmark":0.4446838554,"new-dataset":0.0130589215,"data-annotation":0.5090212851,"dev-research":0.1861503377,"llms":0.4779017235,"data-quality":0.1209506933}}
{"text":"To address this unmet need, we propose TacticAI, an AI football tactics assistant developed and evaluated in close collaboration with domain experts from Liverpool FC.","meta":{"url":"http://arxiv.org/abs/2310.10553v1"},"cats":{"benchmark":0.2513772978,"new-dataset":0.2709971013,"data-annotation":0.5199524448,"dev-research":0.3247864136,"llms":0.5013478726,"data-quality":0.1085118221}}
{"text":"We focus on analysing corner kicks, as they offer coaches the most direct opportunities for interventions and improvements.","meta":{"url":"http://arxiv.org/abs/2310.10553v1"},"cats":{"benchmark":0.3220454283,"new-dataset":0.1959975535,"data-annotation":0.5382235485,"dev-research":0.3215055049,"llms":0.4764946233,"data-quality":0.0582168658}}
{"text":"TacticAI incorporates both a predictive and a generative component, allowing the coaches to effectively sample and explore alternative player setups for each corner kick routine and to select those with the highest predicted likelihood of success.","meta":{"url":"http://arxiv.org/abs/2310.10553v1"},"cats":{"benchmark":0.2712008159,"new-dataset":0.0721425215,"data-annotation":0.5215948686,"dev-research":0.2631236837,"llms":0.4712605891,"data-quality":0.0512081317}}
{"text":"We validate TacticAI on a number of relevant benchmark tasks: predicting receivers and shot attempts and recommending player position adjustments.","meta":{"url":"http://arxiv.org/abs/2310.10553v1"},"cats":{"benchmark":0.6171391724,"new-dataset":0.0765041007,"data-annotation":0.5347158489,"dev-research":0.2404122936,"llms":0.432621764,"data-quality":0.0947930125}}
{"text":"The utility of TacticAI is validated by a qualitative study conducted with football domain experts at Liverpool FC.","meta":{"url":"http://arxiv.org/abs/2310.10553v1"},"cats":{"benchmark":0.287545903,"new-dataset":0.0451134437,"data-annotation":0.5081892332,"dev-research":0.3369433495,"llms":0.5172677609,"data-quality":0.0744696941}}
{"text":"We show that TacticAI's model suggestions are not only indistinguishable from real tactics, but also favoured over existing tactics 90% of the time, and that TacticAI offers an effective corner kick retrieval system.","meta":{"url":"http://arxiv.org/abs/2310.10553v1"},"cats":{"benchmark":0.3664245835,"new-dataset":0.0308914792,"data-annotation":0.5307666418,"dev-research":0.2338100586,"llms":0.4574418873,"data-quality":0.0651734552}}
{"text":"TacticAI achieves these results despite the limited availability of gold-standard data, achieving data efficiency through geometric deep learning.","meta":{"url":"http://arxiv.org/abs/2310.10553v1"},"cats":{"benchmark":0.2645201307,"new-dataset":0.1574791141,"data-annotation":0.4998548496,"dev-research":0.1694115855,"llms":0.4279770806,"data-quality":0.0948342721}}
{"text":"The ability of Deep Learning to process and extract relevant information in complex brain dynamics from raw EEG data has been demonstrated in various recent works.","meta":{"url":"http://arxiv.org/abs/2310.10550v1"},"cats":{"benchmark":0.2744841814,"new-dataset":0.0873838331,"data-annotation":0.4934327044,"dev-research":0.1551578276,"llms":0.4501346455,"data-quality":0.1032192083}}
{"text":"Deep learning models, however, have also been shown to perform best on large corpora of data.","meta":{"url":"http://arxiv.org/abs/2310.10550v1"},"cats":{"benchmark":0.3918668116,"new-dataset":0.1585528505,"data-annotation":0.5248448723,"dev-research":0.163337986,"llms":0.4311921443,"data-quality":0.1537722474}}
{"text":"When processing EEG, a natural approach is to combine EEG datasets from different experiments to train large deep-learning models.","meta":{"url":"http://arxiv.org/abs/2310.10550v1"},"cats":{"benchmark":0.3413424325,"new-dataset":0.08713303,"data-annotation":0.4916619426,"dev-research":0.1384220409,"llms":0.4848331077,"data-quality":0.1423134635}}
{"text":"However, most EEG experiments use custom channel montages, requiring the data to be transformed into a common space.","meta":{"url":"http://arxiv.org/abs/2310.10550v1"},"cats":{"benchmark":0.252978741,"new-dataset":0.0260051621,"data-annotation":0.4712693171,"dev-research":0.1550730731,"llms":0.5201984499,"data-quality":0.1186404845}}
{"text":"Previous methods have used the raw EEG signal to extract features of interest and focused on using a common feature space across EEG datasets.","meta":{"url":"http://arxiv.org/abs/2310.10550v1"},"cats":{"benchmark":0.3656657702,"new-dataset":0.0461211827,"data-annotation":0.5023387467,"dev-research":0.1886850602,"llms":0.4546184704,"data-quality":0.1423512587}}
{"text":"While this is a sensible approach, it underexploits the potential richness of EEG raw data.","meta":{"url":"http://arxiv.org/abs/2310.10550v1"},"cats":{"benchmark":0.4089177612,"new-dataset":0.0460002793,"data-annotation":0.4942230619,"dev-research":0.1378602063,"llms":0.4798646993,"data-quality":0.11491235}}
{"text":"Here, we explore using spatial attention applied to EEG electrode coordinates to perform channel harmonization of raw EEG data, allowing us to train deep learning on EEG data using different montages.","meta":{"url":"http://arxiv.org/abs/2310.10550v1"},"cats":{"benchmark":0.3102833303,"new-dataset":0.15733606,"data-annotation":0.5102162543,"dev-research":0.1536917854,"llms":0.487213435,"data-quality":0.1289391514}}
{"text":"We test this model on a gender classification task.","meta":{"url":"http://arxiv.org/abs/2310.10550v1"},"cats":{"benchmark":0.3557463852,"new-dataset":0.0779240503,"data-annotation":0.548106533,"dev-research":0.1539983846,"llms":0.4327656889,"data-quality":0.2474708711}}
{"text":"We first show that spatial attention increases model performance.","meta":{"url":"http://arxiv.org/abs/2310.10550v1"},"cats":{"benchmark":0.3467054939,"new-dataset":0.0309738105,"data-annotation":0.5408048978,"dev-research":0.1992772767,"llms":0.4475317866,"data-quality":0.0839101157}}
{"text":"Then, we show that a deep learning model trained on data using different channel montages performs significantly better than deep learning models trained on fixed 23- and 128-channel data montages.","meta":{"url":"http://arxiv.org/abs/2310.10550v1"},"cats":{"benchmark":0.3819079372,"new-dataset":0.0866823813,"data-annotation":0.5057613499,"dev-research":0.1583053223,"llms":0.4949064986,"data-quality":0.1601397603}}
{"text":"The emergence of new services and applications in emerging wireless networks (e.g., beyond 5G and 6G) has shown a growing demand for the usage of artificial intelligence (AI) in the Internet of Things (IoT).","meta":{"url":"http://arxiv.org/abs/2310.10549v1"},"cats":{"benchmark":0.1930882174,"new-dataset":0.0401975726,"data-annotation":0.5039394711,"dev-research":0.184736726,"llms":0.540222534,"data-quality":0.0524429674}}
{"text":"However, the proliferation of massive IoT connections and the availability of computing resources distributed across future IoT systems have strongly demanded the development of distributed AI for better IoT services and applications.","meta":{"url":"http://arxiv.org/abs/2310.10549v1"},"cats":{"benchmark":0.2217908221,"new-dataset":0.0554033245,"data-annotation":0.4950030336,"dev-research":0.1574012474,"llms":0.5632466767,"data-quality":0.0483516971}}
{"text":"Therefore, existing AI-enabled IoT systems can be enhanced by implementing distributed machine learning (aka distributed learning) approaches.","meta":{"url":"http://arxiv.org/abs/2310.10549v1"},"cats":{"benchmark":0.2709924863,"new-dataset":0.0373238174,"data-annotation":0.4935513557,"dev-research":0.1422851236,"llms":0.512110295,"data-quality":0.0919756233}}
{"text":"This work aims to provide a comprehensive survey on distributed learning for IoT services and applications in emerging networks.","meta":{"url":"http://arxiv.org/abs/2310.10549v1"},"cats":{"benchmark":0.268909927,"new-dataset":0.0599702045,"data-annotation":0.4999197954,"dev-research":0.116523705,"llms":0.5737192086,"data-quality":0.0864880647}}
{"text":"In particular, we first provide a background of machine learning and present a preliminary to typical distributed learning approaches, such as federated learning, multi-agent reinforcement learning, and distributed inference.","meta":{"url":"http://arxiv.org/abs/2310.10549v1"},"cats":{"benchmark":0.2745498624,"new-dataset":0.068943758,"data-annotation":0.5012370175,"dev-research":0.1187791103,"llms":0.470986421,"data-quality":0.0881748855}}
{"text":"Then, we provide an extensive review of distributed learning for critical IoT services (e.g., data sharing and computation offloading, localization, mobile crowdsensing, and security and privacy) and IoT applications (e.g., smart healthcare, smart grid, autonomous vehicle, aerial IoT networks, and smart industry).","meta":{"url":"http://arxiv.org/abs/2310.10549v1"},"cats":{"benchmark":0.2214665654,"new-dataset":0.1620051033,"data-annotation":0.5088963408,"dev-research":0.1535876096,"llms":0.5769334401,"data-quality":0.0968708791}}
{"text":"From the reviewed literature, we also present critical challenges of distributed learning for IoT and propose several promising solutions and research directions in this emerging area.","meta":{"url":"http://arxiv.org/abs/2310.10549v1"},"cats":{"benchmark":0.1966665173,"new-dataset":0.0483318705,"data-annotation":0.494766613,"dev-research":0.1449175721,"llms":0.5824438927,"data-quality":0.0929931427}}
{"text":"Drilling, grinding, and setting anchors on vertical walls are fundamental processes in everyday construction work.","meta":{"url":"http://arxiv.org/abs/2310.10548v1"},"cats":{"benchmark":0.2798410908,"new-dataset":0.0345327563,"data-annotation":0.5030981874,"dev-research":0.4127410955,"llms":0.5461430694,"data-quality":0.061404331}}
{"text":"Manually doing these works is error-prone, potentially dangerous, and elaborate at height.","meta":{"url":"http://arxiv.org/abs/2310.10548v1"},"cats":{"benchmark":0.4082157739,"new-dataset":0.0050470283,"data-annotation":0.5174655437,"dev-research":0.3193834523,"llms":0.4997016641,"data-quality":0.1269741459}}
{"text":"Today, heavy mobile ground robots can perform automatic power tool work.","meta":{"url":"http://arxiv.org/abs/2310.10548v1"},"cats":{"benchmark":0.2586755296,"new-dataset":0.0424793381,"data-annotation":0.5023849653,"dev-research":0.2238908067,"llms":0.5213684611,"data-quality":0.0920043926}}
{"text":"However, aerial vehicles could be deployed in untraversable environments and reach inaccessible places.","meta":{"url":"http://arxiv.org/abs/2310.10548v1"},"cats":{"benchmark":0.1803614307,"new-dataset":0.0132169349,"data-annotation":0.5035616373,"dev-research":0.2046761609,"llms":0.5272664354,"data-quality":0.0873259797}}
{"text":"Existing drone designs do not provide the large forces, payload, and high precision required for using power tools.","meta":{"url":"http://arxiv.org/abs/2310.10548v1"},"cats":{"benchmark":0.2652580217,"new-dataset":0.0103865084,"data-annotation":0.495035796,"dev-research":0.2371491262,"llms":0.58745372,"data-quality":0.1121650637}}
{"text":"This work presents the first aerial robot design to perform versatile manipulation tasks on vertical concrete walls with continuous forces of up to 150 N.","meta":{"url":"http://arxiv.org/abs/2310.10548v1"},"cats":{"benchmark":0.3097671354,"new-dataset":0.0509196275,"data-annotation":0.4930308531,"dev-research":0.2208764944,"llms":0.5176799009,"data-quality":0.033395844}}
{"text":"The platform combines a quadrotor with active suction cups for perching on walls and a lightweight, tiltable linear tool table.","meta":{"url":"http://arxiv.org/abs/2310.10548v1"},"cats":{"benchmark":0.2937441115,"new-dataset":0.0603724417,"data-annotation":0.4890514653,"dev-research":0.1828820508,"llms":0.4687201761,"data-quality":0.0322013941}}
{"text":"This combination minimizes weight using the propulsion system for flying, surface alignment, and feed during manipulation and allows precise positioning of the power tool.","meta":{"url":"http://arxiv.org/abs/2310.10548v1"},"cats":{"benchmark":0.3563667458,"new-dataset":0.0023336183,"data-annotation":0.5025490405,"dev-research":0.2024795742,"llms":0.5263119949,"data-quality":0.05913}}
{"text":"We evaluate our design in a concrete drilling application - a challenging construction process that requires high forces, accuracy, and precision.","meta":{"url":"http://arxiv.org/abs/2310.10548v1"},"cats":{"benchmark":0.5624184907,"new-dataset":0.0607608963,"data-annotation":0.515260768,"dev-research":0.3010638146,"llms":0.4692285607,"data-quality":0.0910139306}}
{"text":"In 30 trials, our design can accurately pinpoint a target position despite perching imprecision.","meta":{"url":"http://arxiv.org/abs/2310.10548v1"},"cats":{"benchmark":0.5845426222,"new-dataset":0.0074740449,"data-annotation":0.5224999043,"dev-research":0.2080038184,"llms":0.5006249493,"data-quality":0.1145349092}}
{"text":"Nine visually guided drilling experiments demonstrate a drilling precision of 6 mm without further automation.","meta":{"url":"http://arxiv.org/abs/2310.10548v1"},"cats":{"benchmark":0.343618919,"new-dataset":0.0182248741,"data-annotation":0.4968921623,"dev-research":0.2602815378,"llms":0.5648559908,"data-quality":0.1465504489}}
{"text":"Aside from drilling, we also demonstrate the versatility of the design by setting an anchor into concrete.","meta":{"url":"http://arxiv.org/abs/2310.10548v1"},"cats":{"benchmark":0.4039565333,"new-dataset":0.0081240888,"data-annotation":0.5096073993,"dev-research":0.3291716813,"llms":0.5250661656,"data-quality":0.0518764222}}
{"text":"Skeleton-based action recognition has made significant advancements recently, with models like InfoGCN showcasing remarkable accuracy.","meta":{"url":"http://arxiv.org/abs/2310.10547v1"},"cats":{"benchmark":0.3005211959,"new-dataset":0.1596791134,"data-annotation":0.5260388819,"dev-research":0.1648148591,"llms":0.4735018026,"data-quality":0.1000064435}}
{"text":"However, these models exhibit a key limitation: they necessitate complete action observation prior to classification, which constrains their applicability in real-time situations such as surveillance and robotic systems.","meta":{"url":"http://arxiv.org/abs/2310.10547v1"},"cats":{"benchmark":0.2165625762,"new-dataset":0.0236735392,"data-annotation":0.5074963071,"dev-research":0.1878029004,"llms":0.4171983353,"data-quality":0.0648800345}}
{"text":"To overcome this barrier, we introduce InfoGCN++, an innovative extension of InfoGCN, explicitly developed for online skeleton-based action recognition.","meta":{"url":"http://arxiv.org/abs/2310.10547v1"},"cats":{"benchmark":0.2755708911,"new-dataset":0.3625263651,"data-annotation":0.5293292591,"dev-research":0.1886227667,"llms":0.4588870759,"data-quality":0.0918663053}}
{"text":"InfoGCN++ augments the abilities of the original InfoGCN model by allowing real-time categorization of action types, independent of the observation sequence's length.","meta":{"url":"http://arxiv.org/abs/2310.10547v1"},"cats":{"benchmark":0.2222365977,"new-dataset":0.121745981,"data-annotation":0.5236379837,"dev-research":0.1760767411,"llms":0.4815250136,"data-quality":0.0755640386}}
{"text":"It transcends conventional approaches by learning from current and anticipated future movements, thereby creating a more thorough representation of the entire sequence.","meta":{"url":"http://arxiv.org/abs/2310.10547v1"},"cats":{"benchmark":0.183298856,"new-dataset":0.0324742014,"data-annotation":0.5172748738,"dev-research":0.1778326368,"llms":0.5181856704,"data-quality":0.04434362}}
{"text":"Our approach to prediction is managed as an extrapolation issue, grounded on observed actions.","meta":{"url":"http://arxiv.org/abs/2310.10547v1"},"cats":{"benchmark":0.3283197066,"new-dataset":0.0352388293,"data-annotation":0.5349893389,"dev-research":0.2368077923,"llms":0.3726772328,"data-quality":0.1485444768}}
{"text":"To enable this, InfoGCN++ incorporates Neural Ordinary Differential Equations, a concept that lets it effectively model the continuous evolution of hidden states.","meta":{"url":"http://arxiv.org/abs/2310.10547v1"},"cats":{"benchmark":0.1985769114,"new-dataset":0.0794376991,"data-annotation":0.5091457073,"dev-research":0.13737115,"llms":0.4384553045,"data-quality":0.0609608546}}
{"text":"Following rigorous evaluations on three skeleton-based action recognition benchmarks, InfoGCN++ demonstrates exceptional performance in online action recognition.","meta":{"url":"http://arxiv.org/abs/2310.10547v1"},"cats":{"benchmark":0.4457680392,"new-dataset":0.1812950774,"data-annotation":0.5329106983,"dev-research":0.1687694914,"llms":0.4437052267,"data-quality":0.1006048303}}
{"text":"It consistently equals or exceeds existing techniques, highlighting its significant potential to reshape the landscape of real-time action recognition applications.","meta":{"url":"http://arxiv.org/abs/2310.10547v1"},"cats":{"benchmark":0.3405403622,"new-dataset":0.0633571748,"data-annotation":0.5335440014,"dev-research":0.2492303131,"llms":0.4445423715,"data-quality":0.117695137}}
{"text":"Consequently, this work represents a major leap forward from InfoGCN, pushing the limits of what's possible in online, skeleton-based action recognition.","meta":{"url":"http://arxiv.org/abs/2310.10547v1"},"cats":{"benchmark":0.2206589807,"new-dataset":0.2901523243,"data-annotation":0.5271665893,"dev-research":0.1500876278,"llms":0.4872397718,"data-quality":0.0850258001}}
{"text":"The code for InfoGCN++ is publicly available at https://github.com/stnoah1/infogcn2 for further exploration and validation.","meta":{"url":"http://arxiv.org/abs/2310.10547v1"},"cats":{"benchmark":0.3487476888,"new-dataset":0.4023315492,"data-annotation":0.5233781446,"dev-research":0.2228627162,"llms":0.5429382599,"data-quality":0.1359624185}}
{"text":"Figurative and non-literal expressions are profoundly integrated in human communication.","meta":{"url":"http://arxiv.org/abs/2310.10543v1"},"cats":{"benchmark":0.2009023671,"new-dataset":0.0287677448,"data-annotation":0.5361540821,"dev-research":0.3214345709,"llms":0.5609117524,"data-quality":0.1629172949}}
{"text":"Visualising such expressions allow us to convey our creative thoughts, and evoke nuanced emotions.","meta":{"url":"http://arxiv.org/abs/2310.10543v1"},"cats":{"benchmark":0.1622687397,"new-dataset":0.0694929234,"data-annotation":0.5373786888,"dev-research":0.3589208837,"llms":0.5816592963,"data-quality":0.1350887949}}
{"text":"Recent text-to-image models like Stable Diffusion, on the other hand, struggle to depict non-literal expressions.","meta":{"url":"http://arxiv.org/abs/2310.10543v1"},"cats":{"benchmark":0.2715789127,"new-dataset":0.0571485685,"data-annotation":0.5190299705,"dev-research":0.1566772217,"llms":0.4935587792,"data-quality":0.2523559027}}
{"text":"Recent works primarily deal with this issue by compiling humanly annotated datasets on a small scale, which not only demands specialised expertise but also proves highly inefficient.","meta":{"url":"http://arxiv.org/abs/2310.10543v1"},"cats":{"benchmark":0.3614421495,"new-dataset":0.7874372558,"data-annotation":0.533117085,"dev-research":0.3020062762,"llms":0.5274340037,"data-quality":0.4197407911}}
{"text":"To address this issue, we introduce ViPE:","meta":{"url":"http://arxiv.org/abs/2310.10543v1"},"cats":{"benchmark":0.3229767696,"new-dataset":0.036980554,"data-annotation":0.5107057023,"dev-research":0.2283983787,"llms":0.5855596349,"data-quality":0.1902559055}}
{"text":"Visualise Pretty-much Everything.","meta":{"url":"http://arxiv.org/abs/2310.10543v1"},"cats":{"benchmark":0.1616629056,"new-dataset":0.3124430939,"data-annotation":0.5123686604,"dev-research":0.28237494,"llms":0.5426749501,"data-quality":0.0924350937}}
{"text":"ViPE offers a series of lightweight and robust language models that have been trained on a large-scale set of lyrics with noisy visual descriptions that represent their implicit meaning.","meta":{"url":"http://arxiv.org/abs/2310.10543v1"},"cats":{"benchmark":0.263125151,"new-dataset":0.2068213738,"data-annotation":0.5512773131,"dev-research":0.1593558496,"llms":0.4666276019,"data-quality":0.4439863341}}
{"text":"The synthetic visual descriptions are generated by GPT3.5 relying on neither human annotations nor images.","meta":{"url":"http://arxiv.org/abs/2310.10543v1"},"cats":{"benchmark":0.1431460332,"new-dataset":0.4413151993,"data-annotation":0.5317752156,"dev-research":0.244323287,"llms":0.5473398739,"data-quality":0.2074023094}}
{"text":"ViPE effectively expresses any arbitrary piece of text into a visualisable description, enabling meaningful and high-quality image generation.","meta":{"url":"http://arxiv.org/abs/2310.10543v1"},"cats":{"benchmark":0.2529981095,"new-dataset":0.1066585274,"data-annotation":0.5150023285,"dev-research":0.2219785233,"llms":0.5553195744,"data-quality":0.178972054}}
{"text":"We provide compelling evidence that ViPE is more robust than GPT3.5 in synthesising visual elaborations.","meta":{"url":"http://arxiv.org/abs/2310.10543v1"},"cats":{"benchmark":0.2828137892,"new-dataset":0.0206904539,"data-annotation":0.5122347458,"dev-research":0.2917052704,"llms":0.5640269792,"data-quality":0.0927421636}}
{"text":"ViPE also exhibits an understanding of figurative expressions comparable to human experts, providing a powerful and open-source backbone to many downstream applications such as music video and caption generation.","meta":{"url":"http://arxiv.org/abs/2310.10543v1"},"cats":{"benchmark":0.2160061991,"new-dataset":0.0604004245,"data-annotation":0.5497240969,"dev-research":0.29484651,"llms":0.5531557569,"data-quality":0.211208974}}
{"text":"Training a large and state-of-the-art machine learning model typically necessitates the use of large-scale datasets, which, in turn, makes the training and parameter-tuning process expensive and time-consuming.","meta":{"url":"http://arxiv.org/abs/2310.10541v1"},"cats":{"benchmark":0.2679688103,"new-dataset":0.1307112775,"data-annotation":0.5022271349,"dev-research":0.1928837214,"llms":0.4632458418,"data-quality":0.0761075737}}
{"text":"Some researchers opt to distil information from real-world datasets into tiny and compact synthetic datasets while maintaining their ability to train a well-performing model, hence proposing a data-efficient method known as Dataset Distillation (DD).","meta":{"url":"http://arxiv.org/abs/2310.10541v1"},"cats":{"benchmark":0.2907022102,"new-dataset":0.3607905593,"data-annotation":0.4570184106,"dev-research":0.1779746179,"llms":0.4879823736,"data-quality":0.1713279481}}
{"text":"Despite recent progress in this field, existing methods still underperform and cannot effectively replace large datasets.","meta":{"url":"http://arxiv.org/abs/2310.10541v1"},"cats":{"benchmark":0.5322349979,"new-dataset":0.3240006411,"data-annotation":0.5183705239,"dev-research":0.178587122,"llms":0.4494449608,"data-quality":0.2468794198}}
{"text":"In this paper, unlike previous methods that focus solely on improving the efficacy of student distillation, we are the first to recognize the important interplay between expert and student.","meta":{"url":"http://arxiv.org/abs/2310.10541v1"},"cats":{"benchmark":0.3339832723,"new-dataset":0.0143434654,"data-annotation":0.512162931,"dev-research":0.2824026666,"llms":0.5297260447,"data-quality":0.1357112171}}
{"text":"We argue the significant impact of expert smoothness when employing more potent expert trajectories in subsequent dataset distillation.","meta":{"url":"http://arxiv.org/abs/2310.10541v1"},"cats":{"benchmark":0.4947351299,"new-dataset":0.0391138313,"data-annotation":0.4870623588,"dev-research":0.182079001,"llms":0.4317200507,"data-quality":0.1743277528}}
{"text":"Based on this, we introduce the integration of clipping loss and gradient penalty to regulate the rate of parameter changes in expert trajectories.","meta":{"url":"http://arxiv.org/abs/2310.10541v1"},"cats":{"benchmark":0.5133929198,"new-dataset":0.0169243929,"data-annotation":0.5209542125,"dev-research":0.197308954,"llms":0.356345271,"data-quality":0.1157112053}}
{"text":"Furthermore, in response to the sensitivity exhibited towards randomly initialized variables during distillation, we propose representative initialization for synthetic dataset and balanced inner-loop loss.","meta":{"url":"http://arxiv.org/abs/2310.10541v1"},"cats":{"benchmark":0.4067258898,"new-dataset":0.0977372763,"data-annotation":0.5068581734,"dev-research":0.1534933707,"llms":0.407281949,"data-quality":0.2447561673}}
{"text":"Finally, we present two enhancement strategies, namely intermediate matching loss and weight perturbation, to mitigate the potential occurrence of cumulative errors.","meta":{"url":"http://arxiv.org/abs/2310.10541v1"},"cats":{"benchmark":0.7220619272,"new-dataset":0.0044252384,"data-annotation":0.5039726126,"dev-research":0.1650257438,"llms":0.377380937,"data-quality":0.2279237862}}
{"text":"We conduct extensive experiments on datasets of different scales, sizes, and resolutions.","meta":{"url":"http://arxiv.org/abs/2310.10541v1"},"cats":{"benchmark":0.4295254948,"new-dataset":0.4090661008,"data-annotation":0.4927348871,"dev-research":0.1056328067,"llms":0.4797403155,"data-quality":0.0900828084}}
{"text":"The results demonstrate that the proposed method significantly outperforms prior methods.","meta":{"url":"http://arxiv.org/abs/2310.10541v1"},"cats":{"benchmark":0.7206650244,"new-dataset":0.0045813677,"data-annotation":0.5211589,"dev-research":0.1652402824,"llms":0.4154457433,"data-quality":0.2013772234}}
{"text":"Narrow bit-width data formats are key to reducing the computational and storage costs of modern deep learning applications.","meta":{"url":"http://arxiv.org/abs/2310.10537v1"},"cats":{"benchmark":0.2572140675,"new-dataset":0.0588110153,"data-annotation":0.4936517237,"dev-research":0.1580890049,"llms":0.4873497594,"data-quality":0.152877673}}
{"text":"This paper evaluates Microscaling (MX) data formats that combine a per-block scaling factor with narrow floating-point and integer types for individual elements.","meta":{"url":"http://arxiv.org/abs/2310.10537v1"},"cats":{"benchmark":0.5053107464,"new-dataset":0.0645824711,"data-annotation":0.4849569545,"dev-research":0.1467329411,"llms":0.492074371,"data-quality":0.1063531088}}
{"text":"MX formats balance the competing needs of hardware efficiency, model accuracy, and user friction.","meta":{"url":"http://arxiv.org/abs/2310.10537v1"},"cats":{"benchmark":0.4444575234,"new-dataset":0.0085209532,"data-annotation":0.4885221379,"dev-research":0.2146525449,"llms":0.5852071798,"data-quality":0.1262396435}}
{"text":"Empirical results on over two dozen benchmarks demonstrate practicality of MX data formats as a drop-in replacement for baseline FP32 for AI inference and training with low user friction.","meta":{"url":"http://arxiv.org/abs/2310.10537v1"},"cats":{"benchmark":0.4715075283,"new-dataset":0.0657858674,"data-annotation":0.4988621717,"dev-research":0.1862733739,"llms":0.4777561694,"data-quality":0.1688025853}}
{"text":"We also show the first instance of training generative language models at sub-8-bit weights, activations, and gradients with minimal accuracy loss and no modifications to the training recipe.","meta":{"url":"http://arxiv.org/abs/2310.10537v1"},"cats":{"benchmark":0.2768827992,"new-dataset":0.1279975007,"data-annotation":0.5682692524,"dev-research":0.1555376876,"llms":0.5367477859,"data-quality":0.2667171864}}
{"text":"We derive generic information-theoretic and PAC-Bayesian generalization bounds involving an arbitrary convex comparator function, which measures the discrepancy between the training and population loss.","meta":{"url":"http://arxiv.org/abs/2310.10534v1"},"cats":{"benchmark":0.3798037276,"new-dataset":0.0169277508,"data-annotation":0.550871116,"dev-research":0.1231148996,"llms":0.3860944663,"data-quality":0.1872624264}}
{"text":"The bounds hold under the assumption that the cumulant-generating function (CGF) of the comparator is upper-bounded by the corresponding CGF within a family of bounding distributions.","meta":{"url":"http://arxiv.org/abs/2310.10534v1"},"cats":{"benchmark":0.3450216602,"new-dataset":0.1316552752,"data-annotation":0.5355428304,"dev-research":0.1173113519,"llms":0.500924087,"data-quality":0.0844797334}}
{"text":"We show that the tightest possible bound is obtained with the comparator being the convex conjugate of the CGF of the bounding distribution, also known as the Cram\\'er function.","meta":{"url":"http://arxiv.org/abs/2310.10534v1"},"cats":{"benchmark":0.4212433177,"new-dataset":0.1416577803,"data-annotation":0.5382711883,"dev-research":0.0945636147,"llms":0.4530820166,"data-quality":0.1210422147}}
{"text":"This conclusion applies more broadly to generalization bounds with a similar structure.","meta":{"url":"http://arxiv.org/abs/2310.10534v1"},"cats":{"benchmark":0.4449648164,"new-dataset":0.0136920271,"data-annotation":0.550274017,"dev-research":0.1601602728,"llms":0.4173921454,"data-quality":0.141954376}}
{"text":"This confirms the near-optimality of known bounds for bounded and sub-Gaussian losses and leads to novel bounds under other bounding distributions.","meta":{"url":"http://arxiv.org/abs/2310.10534v1"},"cats":{"benchmark":0.4550439903,"new-dataset":0.0248420821,"data-annotation":0.5557771633,"dev-research":0.1250246048,"llms":0.3668067309,"data-quality":0.1065998973}}
{"text":"Weakly-supervised segmentation with label-efficient sparse annotations has attracted increasing research attention to reduce the cost of laborious pixel-wise labeling process, while the pairwise affinity modeling techniques play an essential role in this task.","meta":{"url":"http://arxiv.org/abs/2310.10533v1"},"cats":{"benchmark":0.4167978139,"new-dataset":0.1386966718,"data-annotation":0.5253026709,"dev-research":0.1522952226,"llms":0.4696721397,"data-quality":0.4594207184}}
{"text":"Most of the existing approaches focus on using the local appearance kernel to model the neighboring pairwise potentials.","meta":{"url":"http://arxiv.org/abs/2310.10533v1"},"cats":{"benchmark":0.4103429909,"new-dataset":0.0678062925,"data-annotation":0.5518632677,"dev-research":0.1107674277,"llms":0.4027452138,"data-quality":0.1218801186}}
{"text":"However, such a local operation fails to capture the long-range dependencies and ignores the topology of objects.","meta":{"url":"http://arxiv.org/abs/2310.10533v1"},"cats":{"benchmark":0.3073916047,"new-dataset":0.0113499192,"data-annotation":0.5102562196,"dev-research":0.1740484902,"llms":0.6085399957,"data-quality":0.2402933003}}
{"text":"In this work, we formulate the affinity modeling as an affinity propagation process, and propose a local and a global pairwise affinity terms to generate accurate soft pseudo labels.","meta":{"url":"http://arxiv.org/abs/2310.10533v1"},"cats":{"benchmark":0.4436079137,"new-dataset":0.0227891425,"data-annotation":0.5440230201,"dev-research":0.1104530672,"llms":0.4376857333,"data-quality":0.3116340188}}
{"text":"An efficient algorithm is also developed to reduce significantly the computational cost.","meta":{"url":"http://arxiv.org/abs/2310.10533v1"},"cats":{"benchmark":0.6866282565,"new-dataset":0.0138671386,"data-annotation":0.540892581,"dev-research":0.2214504148,"llms":0.3781799412,"data-quality":0.0646840955}}
{"text":"The proposed approach can be conveniently plugged into existing segmentation networks.","meta":{"url":"http://arxiv.org/abs/2310.10533v1"},"cats":{"benchmark":0.314403007,"new-dataset":0.1617316625,"data-annotation":0.5076318137,"dev-research":0.1897144781,"llms":0.4379152735,"data-quality":0.1931151633}}
{"text":"Experiments on three typical label-efficient segmentation tasks, i.e. box-supervised instance segmentation, point/scribble-supervised semantic segmentation and CLIP-guided semantic segmentation, demonstrate the superior performance of the proposed approach.","meta":{"url":"http://arxiv.org/abs/2310.10533v1"},"cats":{"benchmark":0.348362875,"new-dataset":0.1187918862,"data-annotation":0.5180372932,"dev-research":0.1661660577,"llms":0.4944514756,"data-quality":0.2179169559}}
{"text":"Multilingual language models enable zero-shot cross-lingual transfer (ZS-XLT): fine-tuned on sizable source-language task data, they perform the task in target languages without labeled instances.","meta":{"url":"http://arxiv.org/abs/2310.10532v1"},"cats":{"benchmark":0.3076851056,"new-dataset":0.176317818,"data-annotation":0.5223829329,"dev-research":0.1565842652,"llms":0.5788906717,"data-quality":0.2644371007}}
