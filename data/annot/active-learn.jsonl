{"text":"The AI community has made significant strides in developing powerful foundation models, driven by large-scale multimodal datasets.","meta":{"url":"http://arxiv.org/abs/2309.11500v1"},"cats":{"new-dataset":0.7529600829,"dev-research":0.2097703516,"data-quality":0.0751230928}}
{"text":"However, in the audio representation learning community, the present audio-language datasets suffer from limitations such as insufficient volume, simplistic content, and arduous collection procedures.","meta":{"url":"http://arxiv.org/abs/2309.11500v1"},"cats":{"new-dataset":0.4540383809,"dev-research":0.160543312,"data-quality":0.3107616378}}
{"text":"To tackle these challenges, we present an innovative and automatic audio caption generation pipeline based on a series of public tools or APIs, and construct a large-scale, high-quality, audio-language dataset, named as Auto-ACD, comprising over 1.9M audio-text pairs.","meta":{"url":"http://arxiv.org/abs/2309.11500v1"},"cats":{"new-dataset":0.7017398052,"dev-research":0.2139242218,"data-quality":0.3661267512}}
{"text":"To demonstrate the effectiveness of the proposed dataset, we train popular models on our dataset and show performance improvement on various downstream tasks, namely, audio-language retrieval, audio captioning, environment classification.","meta":{"url":"http://arxiv.org/abs/2309.11500v1"},"cats":{"new-dataset":0.4840772208,"dev-research":0.1868568205,"data-quality":0.2901870203}}
{"text":"In addition, we establish a novel test set and provide a benchmark for audio-text tasks.","meta":{"url":"http://arxiv.org/abs/2309.11500v1"},"cats":{"new-dataset":0.1594386191,"dev-research":0.1740558936,"data-quality":0.3011050061}}
{"text":"The proposed dataset will be released at https://auto-acd.github.io/.","meta":{"url":"http://arxiv.org/abs/2309.11500v1"},"cats":{"new-dataset":0.8537794313,"dev-research":0.1506658833,"data-quality":0.1737791782}}
{"text":"This paper presents DreamLLM, a learning framework that first achieves versatile Multimodal Large Language Models (MLLMs) empowered with frequently overlooked synergy between multimodal comprehension and creation.","meta":{"url":"http://arxiv.org/abs/2309.11499v1"},"cats":{"new-dataset":0.4585285921,"dev-research":0.1512868009,"data-quality":0.0811342304}}
{"text":"DreamLLM operates on two fundamental principles.","meta":{"url":"http://arxiv.org/abs/2309.11499v1"},"cats":{"new-dataset":0.010064261,"dev-research":0.1016480206,"data-quality":0.0407776713}}
{"text":"The first focuses on the generative modeling of both language and image posteriors by direct sampling in the raw multimodal space.","meta":{"url":"http://arxiv.org/abs/2309.11499v1"},"cats":{"new-dataset":0.2808925648,"dev-research":0.1374804542,"data-quality":0.1501416952}}
{"text":"This approach circumvents the limitations and information loss inherent to external feature extractors like CLIP, and a more thorough multimodal understanding is obtained.","meta":{"url":"http://arxiv.org/abs/2309.11499v1"},"cats":{"new-dataset":0.0590051222,"dev-research":0.2025643824,"data-quality":0.2085721038}}
{"text":"Second, DreamLLM fosters the generation of raw, interleaved documents, modeling both text and image contents, along with unstructured layouts.","meta":{"url":"http://arxiv.org/abs/2309.11499v1"},"cats":{"new-dataset":0.2854392254,"dev-research":0.1844434686,"data-quality":0.0836985379}}
{"text":"This allows DreamLLM to learn all conditional, marginal, and joint multimodal distributions effectively.","meta":{"url":"http://arxiv.org/abs/2309.11499v1"},"cats":{"new-dataset":0.1024213431,"dev-research":0.1206559371,"data-quality":0.0694743619}}
{"text":"As a result, DreamLLM is the first MLLM capable of generating free-form interleaved content.","meta":{"url":"http://arxiv.org/abs/2309.11499v1"},"cats":{"new-dataset":0.0743222115,"dev-research":0.1065390612,"data-quality":0.0654359136}}
{"text":"Comprehensive experiments highlight DreamLLM's superior performance as a zero-shot multimodal generalist, reaping from the enhanced learning synergy.","meta":{"url":"http://arxiv.org/abs/2309.11499v1"},"cats":{"new-dataset":0.0491608906,"dev-research":0.1565172051,"data-quality":0.0765316374}}
{"text":"In this paper, we uncover the untapped potential of diffusion U-Net, which serves as a \"free lunch\" that substantially improves the generation quality on the fly.","meta":{"url":"http://arxiv.org/abs/2309.11497v1"},"cats":{"new-dataset":0.0439802097,"dev-research":0.1509096478,"data-quality":0.0852725765}}
{"text":"We initially investigate the key contributions of the U-Net architecture to the denoising process and identify that its main backbone primarily contributes to denoising, whereas its skip connections mainly introduce high-frequency features into the decoder module, causing the network to overlook the backbone semantics.","meta":{"url":"http://arxiv.org/abs/2309.11497v1"},"cats":{"new-dataset":0.0262502646,"dev-research":0.2547986562,"data-quality":0.18340151}}
{"text":"Capitalizing on this discovery, we propose a simple yet effective method-termed \"FreeU\" - that enhances generation quality without additional training or finetuning.","meta":{"url":"http://arxiv.org/abs/2309.11497v1"},"cats":{"new-dataset":0.1551598273,"dev-research":0.233493143,"data-quality":0.1563067065}}
{"text":"Our key insight is to strategically re-weight the contributions sourced from the U-Net's skip connections and backbone feature maps, to leverage the strengths of both components of the U-Net architecture.","meta":{"url":"http://arxiv.org/abs/2309.11497v1"},"cats":{"new-dataset":0.0102274341,"dev-research":0.2187556162,"data-quality":0.1051686704}}
{"text":"Promising results on image and video generation tasks demonstrate that our FreeU can be readily integrated to existing diffusion models, e.g., Stable Diffusion, DreamBooth, ModelScope, Rerender and ReVersion, to improve the generation quality with only a few lines of code.","meta":{"url":"http://arxiv.org/abs/2309.11497v1"},"cats":{"new-dataset":0.0990530869,"dev-research":0.1483676323,"data-quality":0.0606852018}}
{"text":"All you need is to adjust two scaling factors during inference.","meta":{"url":"http://arxiv.org/abs/2309.11497v1"},"cats":{"new-dataset":0.0054039625,"dev-research":0.1030093964,"data-quality":0.1019772194}}
{"text":"Project page: https://chenyangsi.top/FreeU/.","meta":{"url":"http://arxiv.org/abs/2309.11497v1"},"cats":{"new-dataset":0.53280888,"dev-research":0.1663336782,"data-quality":0.0390986957}}
{"text":"Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models.","meta":{"url":"http://arxiv.org/abs/2309.11495v1"},"cats":{"new-dataset":0.027610347,"dev-research":0.3069818655,"data-quality":0.4217488029}}
{"text":"We study the ability of language models to deliberate on the responses they give in order to correct their mistakes.","meta":{"url":"http://arxiv.org/abs/2309.11495v1"},"cats":{"new-dataset":0.0174806878,"dev-research":0.3496559871,"data-quality":0.4514501101}}
{"text":"We develop the Chain-of-Verification (CoVe) method whereby the model first (i) drafts an initial response; then (ii) plans verification questions to fact-check its draft; (iii) answers those questions independently so the answers are not biased by other responses; and (iv) generates its final verified response.","meta":{"url":"http://arxiv.org/abs/2309.11495v1"},"cats":{"new-dataset":0.0192763074,"dev-research":0.2230257418,"data-quality":0.1572212229}}
{"text":"In experiments, we show CoVe decreases hallucinations across a variety of tasks, from list-based questions from Wikidata, closed book MultiSpanQA and longform text generation.","meta":{"url":"http://arxiv.org/abs/2309.11495v1"},"cats":{"new-dataset":0.0920807456,"dev-research":0.2777846353,"data-quality":0.1384668478}}
{"text":"Designing reward functions is a longstanding challenge in reinforcement learning (RL); it requires specialized knowledge or domain data, leading to high costs for development.","meta":{"url":"http://arxiv.org/abs/2309.11489v1"},"cats":{"new-dataset":0.0751047995,"dev-research":0.2011936758,"data-quality":0.0632825644}}
{"text":"To address this, we introduce Text2Reward, a data-free framework that automates the generation of dense reward functions based on large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2309.11489v1"},"cats":{"new-dataset":0.3606197731,"dev-research":0.1326382982,"data-quality":0.1805886717}}
{"text":"Given a goal described in natural language, Text2Reward generates dense reward functions as an executable program grounded in a compact representation of the environment.","meta":{"url":"http://arxiv.org/abs/2309.11489v1"},"cats":{"new-dataset":0.1600359285,"dev-research":0.2717556181,"data-quality":0.1768632456}}
{"text":"Unlike inverse RL and recent work that uses LLMs to write sparse reward codes, Text2Reward produces interpretable, free-form dense reward codes that cover a wide range of tasks, utilize existing packages, and allow iterative refinement with human feedback.","meta":{"url":"http://arxiv.org/abs/2309.11489v1"},"cats":{"new-dataset":0.1054427717,"dev-research":0.1632463483,"data-quality":0.1948918078}}
{"text":"We evaluate Text2Reward on two robotic manipulation benchmarks (ManiSkill2, MetaWorld) and two locomotion environments of MuJoCo.","meta":{"url":"http://arxiv.org/abs/2309.11489v1"},"cats":{"new-dataset":0.0876850218,"dev-research":0.1642491053,"data-quality":0.0822341641}}
{"text":"On 13 of the 17 manipulation tasks, policies trained with generated reward codes achieve similar or better task success rates and convergence speed than expert-written reward codes.","meta":{"url":"http://arxiv.org/abs/2309.11489v1"},"cats":{"new-dataset":0.0949237989,"dev-research":0.246393624,"data-quality":0.0841260429}}
{"text":"For locomotion tasks, our method learns six novel locomotion behaviors with a success rate exceeding 94%.","meta":{"url":"http://arxiv.org/abs/2309.11489v1"},"cats":{"new-dataset":0.0883370468,"dev-research":0.1683901429,"data-quality":0.0848675061}}
{"text":"Furthermore, we show that the policies trained in the simulator with our method can be deployed in the real world.","meta":{"url":"http://arxiv.org/abs/2309.11489v1"},"cats":{"new-dataset":0.1404810624,"dev-research":0.2217383344,"data-quality":0.0948425539}}
{"text":"Finally, Text2Reward further improves the policies by refining their reward functions with human feedback.","meta":{"url":"http://arxiv.org/abs/2309.11489v1"},"cats":{"new-dataset":0.0328825753,"dev-research":0.2427671505,"data-quality":0.1687659832}}
{"text":"Video results are available at https://text-to-reward.github.io","meta":{"url":"http://arxiv.org/abs/2309.11489v1"},"cats":{"new-dataset":0.2558742175,"dev-research":0.1222964343,"data-quality":0.1717621182}}
{"text":"Realistic reservoir simulation is known to be prohibitively expensive in terms of computation time when increasing the accuracy of the simulation or by enlarging the model grid size.","meta":{"url":"http://arxiv.org/abs/2309.11488v1"},"cats":{"new-dataset":0.0330612088,"dev-research":0.1830065264,"data-quality":0.0732127157}}
{"text":"One method to address this issue is to parallelize the computation by dividing the model in several partitions and using multiple CPUs to compute the result using techniques such as MPI and multi-threading.","meta":{"url":"http://arxiv.org/abs/2309.11488v1"},"cats":{"new-dataset":0.0307370187,"dev-research":0.1355703474,"data-quality":0.0935235482}}
{"text":"Alternatively, GPUs are also a good candidate to accelerate the computation due to their massively parallel architecture that allows many floating point operations per second to be performed.","meta":{"url":"http://arxiv.org/abs/2309.11488v1"},"cats":{"new-dataset":0.0153035039,"dev-research":0.1569563815,"data-quality":0.0361130303}}
{"text":"The numerical iterative solver takes thus the most computational time and is challenging to solve efficiently due to the dependencies that exist in the model between cells.","meta":{"url":"http://arxiv.org/abs/2309.11488v1"},"cats":{"new-dataset":0.0210357863,"dev-research":0.1765157523,"data-quality":0.0479982888}}
{"text":"In this work, we evaluate the OPM Flow simulator and compare several state-of-the-art GPU solver libraries as well as custom developed solutions for a BiCGStab solver using an ILU0 preconditioner and benchmark their performance against the default DUNE library implementation running on multiple CPU processors using MPI.","meta":{"url":"http://arxiv.org/abs/2309.11488v1"},"cats":{"new-dataset":0.0548650095,"dev-research":0.1936686065,"data-quality":0.0585285451}}
{"text":"The evaluated GPU software libraries include a manual linear solver in OpenCL and the integration of several third party sparse linear algebra libraries, such as cuSparse, rocSparse, and amgcl.","meta":{"url":"http://arxiv.org/abs/2309.11488v1"},"cats":{"new-dataset":0.0614301134,"dev-research":0.1625187877,"data-quality":0.07064321}}
{"text":"To perform our bench-marking, we use small, medium, and large use cases, starting with the public test case NORNE that includes approximately 50k active cells and ending with a large model that includes approximately 1 million active cells.","meta":{"url":"http://arxiv.org/abs/2309.11488v1"},"cats":{"new-dataset":0.1226132187,"dev-research":0.1782842281,"data-quality":0.0714619037}}
{"text":"We find that a GPU can accelerate a single dual-threaded MPI process up to 5.6 times, and that it can compare with around 8 dual-threaded MPI processes.","meta":{"url":"http://arxiv.org/abs/2309.11488v1"},"cats":{"new-dataset":0.0116130458,"dev-research":0.1313328082,"data-quality":0.0665737674}}
{"text":"Mathematical world knowledge is a fundamental component of Wikidata.","meta":{"url":"http://arxiv.org/abs/2309.11484v1"},"cats":{"new-dataset":0.132017835,"dev-research":0.235872425,"data-quality":0.1001013107}}
{"text":"However, to date, no expertly curated knowledge graph has focused specifically on contemporary mathematics.","meta":{"url":"http://arxiv.org/abs/2309.11484v1"},"cats":{"new-dataset":0.1028531645,"dev-research":0.2385167922,"data-quality":0.0969862452}}
{"text":"Addressing this gap, the Mathematical Research Data Initiative (MaRDI) has developed a comprehensive knowledge graph that links multimodal research data in mathematics.","meta":{"url":"http://arxiv.org/abs/2309.11484v1"},"cats":{"new-dataset":0.4290556914,"dev-research":0.2458233519,"data-quality":0.0672726922}}
{"text":"This encompasses traditional research data items like datasets, software, and publications and includes semantically advanced objects such as mathematical formulas and hypotheses.","meta":{"url":"http://arxiv.org/abs/2309.11484v1"},"cats":{"new-dataset":0.2333864733,"dev-research":0.278992428,"data-quality":0.1116081783}}
{"text":"This paper details the abilities of the MaRDI knowledge graph, which is based on Wikibase, leading up to its inaugural public release, codenamed Bravo, available on https://portal.mardi4nfdi.de.","meta":{"url":"http://arxiv.org/abs/2309.11484v1"},"cats":{"new-dataset":0.3717474789,"dev-research":0.1941740827,"data-quality":0.109457545}}
{"text":"We address the integration of storytelling and Large Language Models (LLMs) to develop engaging and believable Social Chatbots (SCs) in community settings.","meta":{"url":"http://arxiv.org/abs/2309.11478v1"},"cats":{"new-dataset":0.2875668092,"dev-research":0.2418426782,"data-quality":0.0857257412}}
{"text":"Motivated by the potential of fictional characters to enhance social interactions, we introduce Storytelling Social Chatbots (SSCs) and the concept of story engineering to transform fictional game characters into \"live\" social entities within player communities.","meta":{"url":"http://arxiv.org/abs/2309.11478v1"},"cats":{"new-dataset":0.2727448393,"dev-research":0.3780857351,"data-quality":0.0682232488}}
{"text":"Our story engineering process includes three steps: (1) Character and story creation, defining the SC's personality and worldview, (2) Presenting Live Stories to the Community, allowing the SC to recount challenges and seek suggestions, and (3) Communication with community members, enabling interaction between the SC and users.","meta":{"url":"http://arxiv.org/abs/2309.11478v1"},"cats":{"new-dataset":0.0770243907,"dev-research":0.4252050092,"data-quality":0.0476794738}}
{"text":"We employed the LLM GPT-3 to drive our SSC prototypes, \"David\" and \"Catherine,\" and evaluated their performance in an online gaming community, \"DE (Alias),\" on Discord.","meta":{"url":"http://arxiv.org/abs/2309.11478v1"},"cats":{"new-dataset":0.234026404,"dev-research":0.1673487563,"data-quality":0.0837330657}}
{"text":"Our mixed-method analysis, based on questionnaires (N=15) and interviews (N=8) with community members, reveals that storytelling significantly enhances the engagement and believability of SCs in community settings.","meta":{"url":"http://arxiv.org/abs/2309.11478v1"},"cats":{"new-dataset":0.035020926,"dev-research":0.343426826,"data-quality":0.0662365176}}
{"text":"In the era of Industrial IoT (IIoT) and Industry 4.0, ensuring secure data transmission has become a critical concern.","meta":{"url":"http://arxiv.org/abs/2309.11476v1"},"cats":{"new-dataset":0.0651490733,"dev-research":0.2022012871,"data-quality":0.0827064406}}
{"text":"Among other data types, images are widely transmitted and utilized across various IIoT applications, ranging from sensor-generated visual data and real-time remote monitoring to quality control in production lines.","meta":{"url":"http://arxiv.org/abs/2309.11476v1"},"cats":{"new-dataset":0.2259639495,"dev-research":0.2330750625,"data-quality":0.1101213925}}
{"text":"The encryption of these images is essential for maintaining operational integrity, data confidentiality, and seamless integration with analytics platforms.","meta":{"url":"http://arxiv.org/abs/2309.11476v1"},"cats":{"new-dataset":0.3450079054,"dev-research":0.1694672741,"data-quality":0.0832038314}}
{"text":"This paper addresses these critical concerns by proposing a robust image encryption algorithm tailored for IIoT and Cyber-Physical Systems (CPS).","meta":{"url":"http://arxiv.org/abs/2309.11476v1"},"cats":{"new-dataset":0.0248335318,"dev-research":0.1651461533,"data-quality":0.1044150131}}
{"text":"The algorithm combines Rule-30 cellular automata with chaotic scrambling and substitution.","meta":{"url":"http://arxiv.org/abs/2309.11476v1"},"cats":{"new-dataset":0.1142867884,"dev-research":0.1511912755,"data-quality":0.0926346767}}
{"text":"The Rule 30 cellular automata serves as an efficient mechanism for generating pseudo-random sequences that enable fast encryption and decryption cycles suitable for real-time sensor data in industrial settings.","meta":{"url":"http://arxiv.org/abs/2309.11476v1"},"cats":{"new-dataset":0.0752362249,"dev-research":0.1387572087,"data-quality":0.0687003141}}
{"text":"Most importantly, it induces non-linearity in the encryption algorithm.","meta":{"url":"http://arxiv.org/abs/2309.11476v1"},"cats":{"new-dataset":0.0013753053,"dev-research":0.1276868021,"data-quality":0.114335142}}
{"text":"Furthermore, to increase the chaotic range and keyspace of the algorithm, which is vital for security in distributed industrial networks, a hybrid chaotic map, i.e., logistic-sine map is utilized.","meta":{"url":"http://arxiv.org/abs/2309.11476v1"},"cats":{"new-dataset":0.0390284547,"dev-research":0.1668667205,"data-quality":0.0858943964}}
{"text":"Extensive security analysis has been carried out to validate the efficacy of the proposed algorithm.","meta":{"url":"http://arxiv.org/abs/2309.11476v1"},"cats":{"new-dataset":0.0062664416,"dev-research":0.2018647941,"data-quality":0.0897298684}}
{"text":"Results indicate that our algorithm achieves close-to-ideal values, with an entropy of 7.99 and a correlation of 0.002.","meta":{"url":"http://arxiv.org/abs/2309.11476v1"},"cats":{"new-dataset":0.0527180432,"dev-research":0.0958022602,"data-quality":0.1380035151}}
{"text":"This enhances the algorithm's resilience against potential cyber-attacks in the industrial domain.","meta":{"url":"http://arxiv.org/abs/2309.11476v1"},"cats":{"new-dataset":0.0171217549,"dev-research":0.2691409136,"data-quality":0.118994502}}
{"text":"Unsupervised multi-view representation learning has been extensively studied for mining multi-view data.","meta":{"url":"http://arxiv.org/abs/2309.11473v1"},"cats":{"new-dataset":0.1373492582,"dev-research":0.1769762512,"data-quality":0.1834927021}}
{"text":"However, some critical challenges remain.","meta":{"url":"http://arxiv.org/abs/2309.11473v1"},"cats":{"new-dataset":0.1114521746,"dev-research":0.2669444239,"data-quality":0.1570799663}}
{"text":"On the one hand, the existing methods cannot explore multi-view data comprehensively since they usually learn a common representation between views, given that multi-view data contains both the common information between views and the specific information within each view.","meta":{"url":"http://arxiv.org/abs/2309.11473v1"},"cats":{"new-dataset":0.1161843705,"dev-research":0.1637788824,"data-quality":0.1483921388}}
{"text":"On the other hand, to mine the nonlinear relationship between data, kernel or neural network methods are commonly used for multi-view representation learning.","meta":{"url":"http://arxiv.org/abs/2309.11473v1"},"cats":{"new-dataset":0.0321171098,"dev-research":0.1828616671,"data-quality":0.1704597902}}
{"text":"However, these methods are lacking in interpretability.","meta":{"url":"http://arxiv.org/abs/2309.11473v1"},"cats":{"new-dataset":0.0056295743,"dev-research":0.2909285448,"data-quality":0.3639345896}}
{"text":"To this end, this paper proposes a new multi-view fuzzy representation learning method based on the interpretable Takagi-Sugeno-Kang (TSK) fuzzy system (MVRL_FS).","meta":{"url":"http://arxiv.org/abs/2309.11473v1"},"cats":{"new-dataset":0.115104688,"dev-research":0.2103493783,"data-quality":0.1500725986}}
{"text":"The method realizes multi-view representation learning from two aspects.","meta":{"url":"http://arxiv.org/abs/2309.11473v1"},"cats":{"new-dataset":0.0296172265,"dev-research":0.1990716519,"data-quality":0.1926547837}}
{"text":"First, multi-view data are transformed into a high-dimensional fuzzy feature space, while the common information between views and specific information of each view are explored simultaneously.","meta":{"url":"http://arxiv.org/abs/2309.11473v1"},"cats":{"new-dataset":0.1783074375,"dev-research":0.2379226167,"data-quality":0.111693586}}
{"text":"Second, a new regularization method based on L_(2,1)-norm regression is proposed to mine the consistency information between views, while the geometric structure of the data is preserved through the Laplacian graph.","meta":{"url":"http://arxiv.org/abs/2309.11473v1"},"cats":{"new-dataset":0.0594723445,"dev-research":0.1996403085,"data-quality":0.2781024276}}
{"text":"Finally, extensive experiments on many benchmark multi-view datasets are conducted to validate the superiority of the proposed method.","meta":{"url":"http://arxiv.org/abs/2309.11473v1"},"cats":{"new-dataset":0.1986700228,"dev-research":0.1546528496,"data-quality":0.2300803556}}
{"text":"To secure the digital images over insecure transmission channels, a new image encryption algorithm Noise-Crypt is proposed in this paper.","meta":{"url":"http://arxiv.org/abs/2309.11471v1"},"cats":{"new-dataset":0.0418962176,"dev-research":0.1535088787,"data-quality":0.1657817303}}
{"text":"Noise-Crypt integrates non-linear random noise, hybrid chaotic maps, and SHA-256 hashing algorithm.","meta":{"url":"http://arxiv.org/abs/2309.11471v1"},"cats":{"new-dataset":0.0296466556,"dev-research":0.1201654043,"data-quality":0.1233075669}}
{"text":"The utilized hybrid chaotic maps are the logistic-tent and the logistic-sine-cosine map.","meta":{"url":"http://arxiv.org/abs/2309.11471v1"},"cats":{"new-dataset":0.0798728095,"dev-research":0.1504578345,"data-quality":0.0827139495}}
{"text":"The hybrid chaotic maps enhance the pseudorandom sequence generation and selection of substitution boxes, while the logistic-sine-cosine map induces non-linearity in the algorithm through random noise.","meta":{"url":"http://arxiv.org/abs/2309.11471v1"},"cats":{"new-dataset":0.035591346,"dev-research":0.1330005469,"data-quality":0.1174613733}}
{"text":"This deliberate inclusion of noise contributes to increased resistance against cryptanalysis.","meta":{"url":"http://arxiv.org/abs/2309.11471v1"},"cats":{"new-dataset":0.0256223149,"dev-research":0.2281209903,"data-quality":0.1764073674}}
{"text":"The proposed scheme has been evaluated for several security parameters, such as differential attacks, entropy, correlation, etc. Extensive evaluation demonstrates the efficacy of the proposed scheme, with almost ideal values of entropy of 7.99 and correlation of -0.0040.","meta":{"url":"http://arxiv.org/abs/2309.11471v1"},"cats":{"new-dataset":0.0177734676,"dev-research":0.1475019342,"data-quality":0.0800973168}}
{"text":"Results of the security analysis validate the potency of the proposed scheme in achieving robust image encryption.","meta":{"url":"http://arxiv.org/abs/2309.11471v1"},"cats":{"new-dataset":0.0192853273,"dev-research":0.1422200478,"data-quality":0.1166079967}}
{"text":"Nonlinear tracking control enabling a dynamical system to track a desired trajectory is fundamental to robotics, serving a wide range of civil and defense applications.","meta":{"url":"http://arxiv.org/abs/2309.11470v1"},"cats":{"new-dataset":0.0398558954,"dev-research":0.1786699077,"data-quality":0.0565744261}}
{"text":"In control engineering, designing tracking control requires complete knowledge of the system model and equations.","meta":{"url":"http://arxiv.org/abs/2309.11470v1"},"cats":{"new-dataset":0.0506241402,"dev-research":0.2888235729,"data-quality":0.0767680278}}
{"text":"We develop a model-free, machine-learning framework to control a two-arm robotic manipulator using only partially observed states, where the controller is realized by reservoir computing.","meta":{"url":"http://arxiv.org/abs/2309.11470v1"},"cats":{"new-dataset":0.0272333776,"dev-research":0.1388998457,"data-quality":0.0944471463}}
{"text":"Stochastic input is exploited for training, which consists of the observed partial state vector as the first and its immediate future as the second component so that the neural machine regards the latter as the future state of the former.","meta":{"url":"http://arxiv.org/abs/2309.11470v1"},"cats":{"new-dataset":0.0166878275,"dev-research":0.1501614522,"data-quality":0.1591243461}}
{"text":"In the testing (deployment) phase, the immediate-future component is replaced by the desired observational vector from the reference trajectory.","meta":{"url":"http://arxiv.org/abs/2309.11470v1"},"cats":{"new-dataset":0.0394089632,"dev-research":0.2238655677,"data-quality":0.1051291934}}
{"text":"We demonstrate the effectiveness of the control framework using a variety of periodic and chaotic signals, and establish its robustness against measurement noise, disturbances, and uncertainties.","meta":{"url":"http://arxiv.org/abs/2309.11470v1"},"cats":{"new-dataset":0.0913017312,"dev-research":0.1749976327,"data-quality":0.1578293666}}
{"text":"Multi-label classification can effectively identify the relevant labels of an instance from a given set of labels.","meta":{"url":"http://arxiv.org/abs/2309.11469v1"},"cats":{"new-dataset":0.1499799763,"dev-research":0.1677744479,"data-quality":0.5706881826}}
{"text":"However,the modeling of the relationship between the features and the labels is critical to the classification performance.","meta":{"url":"http://arxiv.org/abs/2309.11469v1"},"cats":{"new-dataset":0.0334290491,"dev-research":0.2374679611,"data-quality":0.5300910539}}
{"text":"To this end, we propose a new multi-label classification method, called Multi-Label Takagi-Sugeno-Kang Fuzzy System (ML-TSK FS), to improve the classification performance.","meta":{"url":"http://arxiv.org/abs/2309.11469v1"},"cats":{"new-dataset":0.1465673256,"dev-research":0.1714235097,"data-quality":0.3480126988}}
{"text":"The structure of ML-TSK FS is designed using fuzzy rules to model the relationship between features and labels.","meta":{"url":"http://arxiv.org/abs/2309.11469v1"},"cats":{"new-dataset":0.0996402065,"dev-research":0.1912684162,"data-quality":0.3620324393}}
{"text":"The fuzzy system is trained by integrating fuzzy inference based multi-label correlation learning with multi-label regression loss.","meta":{"url":"http://arxiv.org/abs/2309.11469v1"},"cats":{"new-dataset":0.0757061073,"dev-research":0.1502487012,"data-quality":0.5156530508}}
{"text":"The proposed ML-TSK FS is evaluated experimentally on 12 benchmark multi-label datasets.","meta":{"url":"http://arxiv.org/abs/2309.11469v1"},"cats":{"new-dataset":0.4677367498,"dev-research":0.0947478091,"data-quality":0.3958351375}}
{"text":"1","meta":{"url":"http://arxiv.org/abs/2309.11469v1"},"cats":{"new-dataset":0.655487239,"dev-research":0.1575929111,"data-quality":0.1645689161}}
{"text":"The results show that the performance of ML-TSK FS is competitive with existing methods in terms of various evaluation metrics, indicating that it is able to model the feature-label relationship effectively using fuzzy inference rules and enhances the classification performance.","meta":{"url":"http://arxiv.org/abs/2309.11469v1"},"cats":{"new-dataset":0.057061131,"dev-research":0.2123796175,"data-quality":0.340166171}}
{"text":"Deep learning has achieved state-of-the-art performance on several computer vision tasks and domains.","meta":{"url":"http://arxiv.org/abs/2309.11464v1"},"cats":{"new-dataset":0.078670071,"dev-research":0.1468227113,"data-quality":0.0980360221}}
{"text":"Nevertheless, it still has a high computational cost and demands a significant amount of parameters.","meta":{"url":"http://arxiv.org/abs/2309.11464v1"},"cats":{"new-dataset":0.0215930328,"dev-research":0.2015939951,"data-quality":0.0379684077}}
{"text":"Such requirements hinder the use in resource-limited environments and demand both software and hardware optimization.","meta":{"url":"http://arxiv.org/abs/2309.11464v1"},"cats":{"new-dataset":0.0053083728,"dev-research":0.2969383381,"data-quality":0.0500159627}}
{"text":"Another limitation is that deep models are usually specialized into a single domain or task, requiring them to learn and store new parameters for each new one.","meta":{"url":"http://arxiv.org/abs/2309.11464v1"},"cats":{"new-dataset":0.0156824136,"dev-research":0.1640583479,"data-quality":0.0702508735}}
{"text":"Multi-Domain Learning (MDL) attempts to solve this problem by learning a single model that is capable of performing well in multiple domains.","meta":{"url":"http://arxiv.org/abs/2309.11464v1"},"cats":{"new-dataset":0.0502587635,"dev-research":0.1260938685,"data-quality":0.1368901891}}
{"text":"Nevertheless, the models are usually larger than the baseline for a single domain.","meta":{"url":"http://arxiv.org/abs/2309.11464v1"},"cats":{"new-dataset":0.0072388496,"dev-research":0.162276298,"data-quality":0.086028043}}
{"text":"This work tackles both of these problems: our objective is to prune models capable of handling multiple domains according to a user-defined budget, making them more computationally affordable while keeping a similar classification performance.","meta":{"url":"http://arxiv.org/abs/2309.11464v1"},"cats":{"new-dataset":0.0967951864,"dev-research":0.1950108259,"data-quality":0.1614461629}}
{"text":"We achieve this by encouraging all domains to use a similar subset of filters from the baseline model, up to the amount defined by the user's budget.","meta":{"url":"http://arxiv.org/abs/2309.11464v1"},"cats":{"new-dataset":0.0483226567,"dev-research":0.2066066635,"data-quality":0.1203560007}}
{"text":"Then, filters that are not used by any domain are pruned from the network.","meta":{"url":"http://arxiv.org/abs/2309.11464v1"},"cats":{"new-dataset":0.0053009431,"dev-research":0.1539723457,"data-quality":0.2095971155}}
{"text":"The proposed approach innovates by better adapting to resource-limited devices while, to our knowledge, being the only work that handles multiple domains at test time with fewer parameters and lower computational complexity than the baseline model for a single domain.","meta":{"url":"http://arxiv.org/abs/2309.11464v1"},"cats":{"new-dataset":0.0067209954,"dev-research":0.1941135872,"data-quality":0.057653244}}
{"text":"Automatic Speech Recognition systems have been shown to be vulnerable to adversarial attacks that manipulate the command executed on the device.","meta":{"url":"http://arxiv.org/abs/2309.11462v1"},"cats":{"new-dataset":0.0805176212,"dev-research":0.1909033076,"data-quality":0.3667635395}}
{"text":"Recent research has focused on exploring methods to create such attacks, however, some issues relating to Over-The-Air (OTA) attacks have not been properly addressed.","meta":{"url":"http://arxiv.org/abs/2309.11462v1"},"cats":{"new-dataset":0.0224018821,"dev-research":0.2328743529,"data-quality":0.0866460627}}
{"text":"In our work, we examine the needed properties of robust attacks compatible with the OTA model, and we design a method of generating attacks with arbitrary such desired properties, namely the invariance to synchronization, and the robustness to filtering: this allows a Denial-of-Service (DoS) attack against ASR systems.","meta":{"url":"http://arxiv.org/abs/2309.11462v1"},"cats":{"new-dataset":0.0194600074,"dev-research":0.1548091376,"data-quality":0.1556754381}}
{"text":"We achieve these characteristics by constructing attacks in a modified frequency domain through an inverse Fourier transform.","meta":{"url":"http://arxiv.org/abs/2309.11462v1"},"cats":{"new-dataset":0.0289511908,"dev-research":0.1589026947,"data-quality":0.156845174}}
{"text":"We evaluate our method on standard keyword classification tasks and analyze it in OTA, and we analyze the properties of the cross-domain attacks to explain the efficiency of the approach.","meta":{"url":"http://arxiv.org/abs/2309.11462v1"},"cats":{"new-dataset":0.0641318908,"dev-research":0.2292967354,"data-quality":0.344583697}}
{"text":"Digital twins have attracted a great deal of recent attention from a wide range of fields.","meta":{"url":"http://arxiv.org/abs/2309.11461v1"},"cats":{"new-dataset":0.0494642419,"dev-research":0.1854557556,"data-quality":0.1423609601}}
{"text":"A basic requirement for digital twins of nonlinear dynamical systems is the ability to generate the system evolution and predict potentially catastrophic emergent behaviors so as to providing early warnings.","meta":{"url":"http://arxiv.org/abs/2309.11461v1"},"cats":{"new-dataset":0.0200019539,"dev-research":0.1999396068,"data-quality":0.1125749653}}
{"text":"The digital twin can then be used for system \"health\" monitoring in real time and for predictive problem solving.","meta":{"url":"http://arxiv.org/abs/2309.11461v1"},"cats":{"new-dataset":0.0387475235,"dev-research":0.2996650189,"data-quality":0.0796739529}}
{"text":"In particular, if the digital twin forecasts a possible system collapse in the future due to parameter drifting as caused by environmental changes or perturbations, an optimal control strategy can be devised and executed as early intervention to prevent the collapse.","meta":{"url":"http://arxiv.org/abs/2309.11461v1"},"cats":{"new-dataset":0.0120046338,"dev-research":0.2172466231,"data-quality":0.0665526644}}
{"text":"Two approaches exist for constructing digital twins of nonlinear dynamical systems: sparse optimization and machine learning.","meta":{"url":"http://arxiv.org/abs/2309.11461v1"},"cats":{"new-dataset":0.0245033258,"dev-research":0.1156678224,"data-quality":0.087174966}}
{"text":"The basics of these two approaches are described and their advantages and caveats are discussed.","meta":{"url":"http://arxiv.org/abs/2309.11461v1"},"cats":{"new-dataset":0.0025898206,"dev-research":0.2661765184,"data-quality":0.0673707327}}
{"text":"We discuss the emerging new opportunity for building feedback-rich computational models of social systems using generative artificial intelligence.","meta":{"url":"http://arxiv.org/abs/2309.11456v1"},"cats":{"new-dataset":0.0786344615,"dev-research":0.1915494873,"data-quality":0.0848474574}}
{"text":"Referred to as Generative Agent-Based Models (GABMs), such individual-level models utilize large language models such as ChatGPT to represent human decision-making in social settings.","meta":{"url":"http://arxiv.org/abs/2309.11456v1"},"cats":{"new-dataset":0.1038073416,"dev-research":0.2192118579,"data-quality":0.0774961783}}
{"text":"We provide a GABM case in which human behavior can be incorporated in simulation models by coupling a mechanistic model of human interactions with a pre-trained large language model.","meta":{"url":"http://arxiv.org/abs/2309.11456v1"},"cats":{"new-dataset":0.1561987463,"dev-research":0.1593506395,"data-quality":0.0759062144}}
{"text":"This is achieved by introducing a simple GABM of social norm diffusion in an organization.","meta":{"url":"http://arxiv.org/abs/2309.11456v1"},"cats":{"new-dataset":0.0131331817,"dev-research":0.1968294728,"data-quality":0.0814641715}}
{"text":"For educational purposes, the model is intentionally kept simple.","meta":{"url":"http://arxiv.org/abs/2309.11456v1"},"cats":{"new-dataset":0.0070357394,"dev-research":0.2183609508,"data-quality":0.088418621}}
{"text":"We examine a wide range of scenarios and the sensitivity of the results to several changes in the prompt.","meta":{"url":"http://arxiv.org/abs/2309.11456v1"},"cats":{"new-dataset":0.0544351721,"dev-research":0.3187720299,"data-quality":0.1948072367}}
{"text":"We hope the article and the model serve as a guide for building useful diffusion models that include realistic human reasoning and decision-making.","meta":{"url":"http://arxiv.org/abs/2309.11456v1"},"cats":{"new-dataset":0.0419747153,"dev-research":0.2052985873,"data-quality":0.0592098235}}
{"text":"Understanding how local environments influence individual behaviors, such as voting patterns or suicidal tendencies, is crucial in social science to reveal and reduce spatial disparities and promote social well-being.","meta":{"url":"http://arxiv.org/abs/2309.11454v1"},"cats":{"new-dataset":0.0460226513,"dev-research":0.2997938511,"data-quality":0.0916394477}}
{"text":"With the increasing availability of large-scale individual-level census data, new analytical opportunities arise for social scientists to explore human behaviors (e.g., political engagement) among social groups at a fine-grained level.","meta":{"url":"http://arxiv.org/abs/2309.11454v1"},"cats":{"new-dataset":0.2427917224,"dev-research":0.2060420383,"data-quality":0.0748027289}}
{"text":"However, traditional statistical methods mostly focus on global, aggregated spatial correlations, which are limited to understanding and comparing the impact of local environments (e.g., neighborhoods) on human behaviors among social groups.","meta":{"url":"http://arxiv.org/abs/2309.11454v1"},"cats":{"new-dataset":0.0577002226,"dev-research":0.2576468312,"data-quality":0.0603659715}}
{"text":"In this study, we introduce a new analytical framework for analyzing multi-variate neighborhood effects between social groups.","meta":{"url":"http://arxiv.org/abs/2309.11454v1"},"cats":{"new-dataset":0.0706823308,"dev-research":0.2011714693,"data-quality":0.0856313906}}
{"text":"We then propose NeighVi, an interactive visual analytics system that helps social scientists explore, understand, and verify the influence of neighborhood effects on human behaviors.","meta":{"url":"http://arxiv.org/abs/2309.11454v1"},"cats":{"new-dataset":0.4919140472,"dev-research":0.390542315,"data-quality":0.1093801841}}
{"text":"Finally, we use a case study to illustrate the effectiveness and usability of our system.","meta":{"url":"http://arxiv.org/abs/2309.11454v1"},"cats":{"new-dataset":0.0909502386,"dev-research":0.4358981587,"data-quality":0.1010848483}}
{"text":"Learning-based controllers have demonstrated superior performance compared to classical controllers in various tasks.","meta":{"url":"http://arxiv.org/abs/2309.11453v1"},"cats":{"new-dataset":0.0152649624,"dev-research":0.1979865911,"data-quality":0.0656992188}}
{"text":"However, providing safety guarantees is not trivial.","meta":{"url":"http://arxiv.org/abs/2309.11453v1"},"cats":{"new-dataset":0.0062357196,"dev-research":0.2436598215,"data-quality":0.1186253916}}
{"text":"Safety, the satisfaction of state and input constraints, can be guaranteed by augmenting the learned control policy with a safety filter.","meta":{"url":"http://arxiv.org/abs/2309.11453v1"},"cats":{"new-dataset":0.0460884548,"dev-research":0.2430721384,"data-quality":0.1653835898}}
{"text":"Model predictive safety filters (MPSFs) are a common safety filtering approach based on model predictive control (MPC).","meta":{"url":"http://arxiv.org/abs/2309.11453v1"},"cats":{"new-dataset":0.0825511466,"dev-research":0.2246512576,"data-quality":0.1332135846}}
{"text":"MPSFs seek to guarantee safety while minimizing the difference between the proposed and applied inputs in the immediate next time step.","meta":{"url":"http://arxiv.org/abs/2309.11453v1"},"cats":{"new-dataset":0.0133113746,"dev-research":0.2385474119,"data-quality":0.0946926331}}
{"text":"This limited foresight can lead to jerky motions and undesired oscillations close to constraint boundaries, known as chattering.","meta":{"url":"http://arxiv.org/abs/2309.11453v1"},"cats":{"new-dataset":0.0069917407,"dev-research":0.1963958216,"data-quality":0.0714830139}}
{"text":"In this paper, we reduce chattering by considering input corrections over a longer horizon.","meta":{"url":"http://arxiv.org/abs/2309.11453v1"},"cats":{"new-dataset":0.0398087479,"dev-research":0.179517023,"data-quality":0.2341482439}}
{"text":"Under the assumption of bounded model uncertainties, we prove recursive feasibility using techniques from robust MPC.","meta":{"url":"http://arxiv.org/abs/2309.11453v1"},"cats":{"new-dataset":0.025173255,"dev-research":0.1458138281,"data-quality":0.1478232859}}
{"text":"We verified the proposed approach in both extensive simulation and quadrotor experiments.","meta":{"url":"http://arxiv.org/abs/2309.11453v1"},"cats":{"new-dataset":0.0138611972,"dev-research":0.1436598265,"data-quality":0.0614399899}}
{"text":"In experiments with a Crazyflie 2.0 drone, we show that, in addition to preserving the desired safety guarantees, the proposed MPSF reduces chattering by more than a factor of 4 compared to previous MPSF formulations.","meta":{"url":"http://arxiv.org/abs/2309.11453v1"},"cats":{"new-dataset":0.0972861689,"dev-research":0.195227431,"data-quality":0.1128941806}}
{"text":"The Boolean Satisfiability problem (SAT) is the most prototypical NP-complete problem and of great practical relevance.","meta":{"url":"http://arxiv.org/abs/2309.11452v1"},"cats":{"new-dataset":0.0290807009,"dev-research":0.2078838487,"data-quality":0.0942933641}}
{"text":"One important class of solvers for this problem are stochastic local search (SLS) algorithms that iteratively and randomly update a candidate assignment.","meta":{"url":"http://arxiv.org/abs/2309.11452v1"},"cats":{"new-dataset":0.0550861631,"dev-research":0.178852497,"data-quality":0.1630628179}}
{"text":"Recent breakthrough results in theoretical computer science have established sufficient conditions under which SLS solvers are guaranteed to efficiently solve a SAT instance, provided they have access to suitable \"oracles\" that provide samples from an instance-specific distribution, exploiting an instance's local structure.","meta":{"url":"http://arxiv.org/abs/2309.11452v1"},"cats":{"new-dataset":0.0098631236,"dev-research":0.1691344399,"data-quality":0.1097969458}}
{"text":"Motivated by these results and the well established ability of neural networks to learn common structure in large datasets, in this work, we train oracles using Graph Neural Networks and evaluate them on two SLS solvers on random SAT instances of varying difficulty.","meta":{"url":"http://arxiv.org/abs/2309.11452v1"},"cats":{"new-dataset":0.1385927091,"dev-research":0.1658489932,"data-quality":0.2126606439}}
{"text":"We find that access to GNN-based oracles significantly boosts the performance of both solvers, allowing them, on average, to solve 17% more difficult instances (as measured by the ratio between clauses and variables), and to do so in 35% fewer steps, with improvements in the median number of steps of up to a factor of 8.","meta":{"url":"http://arxiv.org/abs/2309.11452v1"},"cats":{"new-dataset":0.0307312389,"dev-research":0.2790051615,"data-quality":0.0852236923}}
{"text":"As such, this work bridges formal results from theoretical computer science and practically motivated research on deep learning for constraint satisfaction problems and establishes the promise of purpose-trained SAT solvers with performance guarantees.","meta":{"url":"http://arxiv.org/abs/2309.11452v1"},"cats":{"new-dataset":0.0764613403,"dev-research":0.2117620631,"data-quality":0.103265573}}
{"text":"Knowledge distillation (KD) is a powerful model compression technique broadly used in practical deep learning applications.","meta":{"url":"http://arxiv.org/abs/2309.11446v1"},"cats":{"new-dataset":0.0583480764,"dev-research":0.1670332229,"data-quality":0.1464738169}}
{"text":"It is focused on training a small student network to mimic a larger teacher network.","meta":{"url":"http://arxiv.org/abs/2309.11446v1"},"cats":{"new-dataset":0.0203206933,"dev-research":0.1836570873,"data-quality":0.0675053053}}
{"text":"While it is widely known that KD can offer an improvement to student generalization in i.i.d setting, its performance under domain shift, i.e. the performance of student networks on data from domains unseen during training, has received little attention in the literature.","meta":{"url":"http://arxiv.org/abs/2309.11446v1"},"cats":{"new-dataset":0.0174882757,"dev-research":0.1645655157,"data-quality":0.1475929297}}
{"text":"In this paper we make a step towards bridging the research fields of knowledge distillation and domain generalization.","meta":{"url":"http://arxiv.org/abs/2309.11446v1"},"cats":{"new-dataset":0.0369517969,"dev-research":0.2277795003,"data-quality":0.1466418055}}
{"text":"We show that weight averaging techniques proposed in domain generalization literature, such as SWAD and SMA, also improve the performance of knowledge distillation under domain shift.","meta":{"url":"http://arxiv.org/abs/2309.11446v1"},"cats":{"new-dataset":0.0058744799,"dev-research":0.1635442701,"data-quality":0.1549148251}}
{"text":"In addition, we propose a simplistic weight averaging strategy that does not require evaluation on validation data during training and show that it performs on par with SWAD and SMA when applied to KD.","meta":{"url":"http://arxiv.org/abs/2309.11446v1"},"cats":{"new-dataset":0.0221294018,"dev-research":0.1155675455,"data-quality":0.1519573306}}
{"text":"We name our final distillation approach Weight-Averaged Knowledge Distillation (WAKD).","meta":{"url":"http://arxiv.org/abs/2309.11446v1"},"cats":{"new-dataset":0.049354721,"dev-research":0.1526042809,"data-quality":0.155604602}}
{"text":"We present SkeleTR, a new framework for skeleton-based action recognition.","meta":{"url":"http://arxiv.org/abs/2309.11445v1"},"cats":{"new-dataset":0.3392971897,"dev-research":0.1673755181,"data-quality":0.0960961244}}
{"text":"In contrast to prior work, which focuses mainly on controlled environments, we target more general scenarios that typically involve a variable number of people and various forms of interaction between people.","meta":{"url":"http://arxiv.org/abs/2309.11445v1"},"cats":{"new-dataset":0.0387122355,"dev-research":0.4107845547,"data-quality":0.0468847238}}
{"text":"SkeleTR works with a two-stage paradigm.","meta":{"url":"http://arxiv.org/abs/2309.11445v1"},"cats":{"new-dataset":0.0175470207,"dev-research":0.1820177768,"data-quality":0.0772933978}}
{"text":"It first models the intra-person skeleton dynamics for each skeleton sequence with graph convolutions, and then uses stacked Transformer encoders to capture person interactions that are important for action recognition in general scenarios.","meta":{"url":"http://arxiv.org/abs/2309.11445v1"},"cats":{"new-dataset":0.2448624107,"dev-research":0.1571111471,"data-quality":0.0586771448}}
{"text":"To mitigate the negative impact of inaccurate skeleton associations, SkeleTR takes relative short skeleton sequences as input and increases the number of sequences.","meta":{"url":"http://arxiv.org/abs/2309.11445v1"},"cats":{"new-dataset":0.0600318068,"dev-research":0.2110467935,"data-quality":0.1582565113}}
{"text":"As a unified solution, SkeleTR can be directly applied to multiple skeleton-based action tasks, including video-level action classification, instance-level action detection, and group-level activity recognition.","meta":{"url":"http://arxiv.org/abs/2309.11445v1"},"cats":{"new-dataset":0.0947889603,"dev-research":0.1749406443,"data-quality":0.0777045826}}
{"text":"It also enables transfer learning and joint training across different action tasks and datasets, which result in performance improvement.","meta":{"url":"http://arxiv.org/abs/2309.11445v1"},"cats":{"new-dataset":0.0163031914,"dev-research":0.2193046086,"data-quality":0.0761099978}}
{"text":"When evaluated on various skeleton-based action recognition benchmarks, SkeleTR achieves the state-of-the-art performance.","meta":{"url":"http://arxiv.org/abs/2309.11445v1"},"cats":{"new-dataset":0.1478012525,"dev-research":0.169601827,"data-quality":0.0945788065}}
{"text":"The adoption of machine learning in healthcare calls for model transparency and explainability.","meta":{"url":"http://arxiv.org/abs/2309.11443v1"},"cats":{"new-dataset":0.0072168787,"dev-research":0.264891575,"data-quality":0.1538909712}}
{"text":"In this work, we introduce Signature Activation, a saliency method that generates holistic and class-agnostic explanations for Convolutional Neural Network (CNN) outputs.","meta":{"url":"http://arxiv.org/abs/2309.11443v1"},"cats":{"new-dataset":0.121203506,"dev-research":0.2718021631,"data-quality":0.280444206}}
{"text":"Our method exploits the fact that certain kinds of medical images, such as angiograms, have clear foreground and background objects.","meta":{"url":"http://arxiv.org/abs/2309.11443v1"},"cats":{"new-dataset":0.0609131862,"dev-research":0.1843634198,"data-quality":0.1400582861}}
{"text":"We give theoretical explanation to justify our methods.","meta":{"url":"http://arxiv.org/abs/2309.11443v1"},"cats":{"new-dataset":0.0031126368,"dev-research":0.2731398039,"data-quality":0.1269081931}}
{"text":"We show the potential use of our method in clinical settings through evaluating its efficacy for aiding the detection of lesions in coronary angiograms.","meta":{"url":"http://arxiv.org/abs/2309.11443v1"},"cats":{"new-dataset":0.0278546971,"dev-research":0.2497409478,"data-quality":0.2087986871}}
{"text":"In Grammatical Error Correction (GEC), it is crucial to ensure the user's comprehension of a reason for correction.","meta":{"url":"http://arxiv.org/abs/2309.11439v1"},"cats":{"new-dataset":0.0124765857,"dev-research":0.4051666248,"data-quality":0.4438658303}}
{"text":"Existing studies present tokens, examples, and hints as to the basis for correction but do not directly explain the reasons for corrections.","meta":{"url":"http://arxiv.org/abs/2309.11439v1"},"cats":{"new-dataset":0.0053907516,"dev-research":0.2522047515,"data-quality":0.4067821456}}
{"text":"Although methods that use Large Language Models (LLMs) to provide direct explanations in natural language have been proposed for various tasks, no such method exists for GEC.","meta":{"url":"http://arxiv.org/abs/2309.11439v1"},"cats":{"new-dataset":0.0525889816,"dev-research":0.2392917388,"data-quality":0.2015887807}}
{"text":"Generating explanations for GEC corrections involves aligning input and output tokens, identifying correction points, and presenting corresponding explanations consistently.","meta":{"url":"http://arxiv.org/abs/2309.11439v1"},"cats":{"new-dataset":0.0138940848,"dev-research":0.3500228954,"data-quality":0.4049936521}}
{"text":"However, it is not straightforward to specify a complex format to generate explanations, because explicit control of generation is difficult with prompts.","meta":{"url":"http://arxiv.org/abs/2309.11439v1"},"cats":{"new-dataset":0.0319170152,"dev-research":0.3248278873,"data-quality":0.152208441}}
{"text":"This study introduces a method called controlled generation with Prompt Insertion (PI) so that LLMs can explain the reasons for corrections in natural language.","meta":{"url":"http://arxiv.org/abs/2309.11439v1"},"cats":{"new-dataset":0.035153906,"dev-research":0.3759244078,"data-quality":0.3485635809}}
{"text":"In PI, LLMs first correct the input text, and then we automatically extract the correction points based on the rules.","meta":{"url":"http://arxiv.org/abs/2309.11439v1"},"cats":{"new-dataset":0.0686502652,"dev-research":0.1485320047,"data-quality":0.3331035598}}
{"text":"The extracted correction points are sequentially inserted into the LLM's explanation output as prompts, guiding the LLMs to generate explanations for the correction points.","meta":{"url":"http://arxiv.org/abs/2309.11439v1"},"cats":{"new-dataset":0.0345646278,"dev-research":0.1864500264,"data-quality":0.2820348112}}
{"text":"We also create an Explainable GEC (XGEC) dataset of correction reasons by annotating NUCLE, CoNLL2013, and CoNLL2014.","meta":{"url":"http://arxiv.org/abs/2309.11439v1"},"cats":{"new-dataset":0.5377783623,"dev-research":0.3703105478,"data-quality":0.4994037995}}
{"text":"Although generations from GPT-3 and ChatGPT using original prompts miss some correction points, the generation control using PI can explicitly guide to describe explanations for all correction points, contributing to improved performance in generating correction reasons.","meta":{"url":"http://arxiv.org/abs/2309.11439v1"},"cats":{"new-dataset":0.0436800419,"dev-research":0.3693158266,"data-quality":0.2125354361}}
{"text":"Autonomous user interface (UI) agents aim to facilitate task automation by interacting with the user interface without manual intervention.","meta":{"url":"http://arxiv.org/abs/2309.11436v1"},"cats":{"new-dataset":0.0362778968,"dev-research":0.3520049858,"data-quality":0.1048405475}}
{"text":"Recent studies have investigated eliciting the capabilities of large language models (LLMs) for effective engagement in diverse environments.","meta":{"url":"http://arxiv.org/abs/2309.11436v1"},"cats":{"new-dataset":0.0587675418,"dev-research":0.2097100887,"data-quality":0.0861949351}}
{"text":"To align with the input-output requirement of LLMs, existing approaches are developed under a sandbox setting where they rely on external tools and application-specific APIs to parse the environment into textual elements and interpret the predicted actions.","meta":{"url":"http://arxiv.org/abs/2309.11436v1"},"cats":{"new-dataset":0.0796845452,"dev-research":0.2130240564,"data-quality":0.1316893726}}
{"text":"Consequently, those approaches often grapple with inference inefficiency and error propagation risks.","meta":{"url":"http://arxiv.org/abs/2309.11436v1"},"cats":{"new-dataset":0.0023939724,"dev-research":0.2865926367,"data-quality":0.2138323681}}
{"text":"To mitigate the challenges, we introduce Auto-UI, a multimodal solution that directly interacts with the interface, bypassing the need for environment parsing or reliance on application-dependent APIs.","meta":{"url":"http://arxiv.org/abs/2309.11436v1"},"cats":{"new-dataset":0.1479503931,"dev-research":0.3706243582,"data-quality":0.1346897723}}
{"text":"Moreover, we propose a chain-of-action technique -- leveraging a series of intermediate previous action histories and future action plans -- to help the agent decide what action to execute.","meta":{"url":"http://arxiv.org/abs/2309.11436v1"},"cats":{"new-dataset":0.0764685634,"dev-research":0.2935076509,"data-quality":0.0395018803}}
{"text":"We evaluate our approach on a new device-control benchmark AITW with 30K unique instructions, spanning multi-step tasks such as application operation, web searching, and web shopping.","meta":{"url":"http://arxiv.org/abs/2309.11436v1"},"cats":{"new-dataset":0.1269331481,"dev-research":0.2715495483,"data-quality":0.0676106969}}
{"text":"Experimental results show that Auto-UI achieves state-of-the-art performance with an action type prediction accuracy of 90% and an overall action success rate of 74%.","meta":{"url":"http://arxiv.org/abs/2309.11436v1"},"cats":{"new-dataset":0.0176483704,"dev-research":0.2804388387,"data-quality":0.1193856676}}
{"text":"Code is publicly available at https://github.com/cooelf/Auto-UI.","meta":{"url":"http://arxiv.org/abs/2309.11436v1"},"cats":{"new-dataset":0.0808868551,"dev-research":0.2911663041,"data-quality":0.11478025}}
{"text":"The lack of annotated medical images limits the performance of deep learning models, which usually need large-scale labelled datasets.","meta":{"url":"http://arxiv.org/abs/2309.11433v1"},"cats":{"new-dataset":0.4308543718,"dev-research":0.1835382612,"data-quality":0.3109642888}}
{"text":"Few-shot learning techniques can reduce data scarcity issues and enhance medical image analysis, especially with meta-learning.","meta":{"url":"http://arxiv.org/abs/2309.11433v1"},"cats":{"new-dataset":0.0411694349,"dev-research":0.1732115931,"data-quality":0.1533484053}}
{"text":"This systematic review gives a comprehensive overview of few-shot learning in medical imaging.","meta":{"url":"http://arxiv.org/abs/2309.11433v1"},"cats":{"new-dataset":0.0438642556,"dev-research":0.159420196,"data-quality":0.1292826978}}
{"text":"We searched the literature systematically and selected 80 relevant articles published from 2018 to 2023.","meta":{"url":"http://arxiv.org/abs/2309.11433v1"},"cats":{"new-dataset":0.2605497029,"dev-research":0.1551044271,"data-quality":0.0732136197}}
{"text":"We clustered the articles based on medical outcomes, such as tumour segmentation, disease classification, and image registration; anatomical structure investigated (i.e. heart, lung, etc.); and the meta-learning method used.","meta":{"url":"http://arxiv.org/abs/2309.11433v1"},"cats":{"new-dataset":0.0585362541,"dev-research":0.1505996571,"data-quality":0.1270081181}}
{"text":"For each cluster, we examined the papers' distributions and the results provided by the state-of-the-art.","meta":{"url":"http://arxiv.org/abs/2309.11433v1"},"cats":{"new-dataset":0.1204328886,"dev-research":0.1318845251,"data-quality":0.1430059499}}
{"text":"In addition, we identified a generic pipeline shared among all the studies.","meta":{"url":"http://arxiv.org/abs/2309.11433v1"},"cats":{"new-dataset":0.0748944963,"dev-research":0.1552709549,"data-quality":0.1232162638}}
{"text":"The review shows that few-shot learning can overcome data scarcity in most outcomes and that meta-learning is a popular choice to perform few-shot learning because it can adapt to new tasks with few labelled samples.","meta":{"url":"http://arxiv.org/abs/2309.11433v1"},"cats":{"new-dataset":0.0612286136,"dev-research":0.1531313772,"data-quality":0.1835594488}}
{"text":"In addition, following meta-learning, supervised learning and semi-supervised learning stand out as the predominant techniques employed to tackle few-shot learning challenges in medical imaging and also best performing.","meta":{"url":"http://arxiv.org/abs/2309.11433v1"},"cats":{"new-dataset":0.0521600962,"dev-research":0.1566258917,"data-quality":0.1578127369}}
{"text":"Lastly, we observed that the primary application areas predominantly encompass cardiac, pulmonary, and abdominal domains.","meta":{"url":"http://arxiv.org/abs/2309.11433v1"},"cats":{"new-dataset":0.0130048887,"dev-research":0.1543202685,"data-quality":0.065433684}}
{"text":"This systematic review aims to inspire further research to improve medical image analysis and patient care.","meta":{"url":"http://arxiv.org/abs/2309.11433v1"},"cats":{"new-dataset":0.0717889073,"dev-research":0.2706020619,"data-quality":0.1446444774}}
{"text":"This paper introduces TRACE-GPT, which stands for Time-seRies Anomaly-detection with Convolutional Embedding and Generative Pre-trained Transformers.","meta":{"url":"http://arxiv.org/abs/2309.11427v1"},"cats":{"new-dataset":0.1701864621,"dev-research":0.1960250558,"data-quality":0.1718649999}}
{"text":"TRACE-GPT is designed to pre-train univariate time-series sensor data and detect faults on unlabeled datasets in semiconductor manufacturing.","meta":{"url":"http://arxiv.org/abs/2309.11427v1"},"cats":{"new-dataset":0.1809711543,"dev-research":0.2619698229,"data-quality":0.2025680386}}
{"text":"In semiconductor industry, classifying abnormal time-series sensor data from normal data is important because it is directly related to wafer defect.","meta":{"url":"http://arxiv.org/abs/2309.11427v1"},"cats":{"new-dataset":0.139608411,"dev-research":0.2439119829,"data-quality":0.2811565229}}
{"text":"However, small, unlabeled, and even mixed training data without enough anomalies make classification tasks difficult.","meta":{"url":"http://arxiv.org/abs/2309.11427v1"},"cats":{"new-dataset":0.0112097327,"dev-research":0.20031321,"data-quality":0.5124725552}}
{"text":"In this research, we capture features of time-series data with temporal convolutional embedding and Generative Pre-trained Transformer (GPT) to classify abnormal sequences from normal sequences using cross entropy loss.","meta":{"url":"http://arxiv.org/abs/2309.11427v1"},"cats":{"new-dataset":0.3159994254,"dev-research":0.1556683741,"data-quality":0.1602015231}}
{"text":"We prove that our model shows better performance than previous unsupervised models with both an open dataset, the University of California Riverside (UCR) time-series classification archive, and the process log of our Chemical Vapor Deposition (CVD) equipment.","meta":{"url":"http://arxiv.org/abs/2309.11427v1"},"cats":{"new-dataset":0.2453454525,"dev-research":0.1478813351,"data-quality":0.1644557154}}
{"text":"Our model has the highest F1 score at Equal Error Rate (EER) across all datasets and is only 0.026 below the supervised state-of-the-art baseline on the open dataset.","meta":{"url":"http://arxiv.org/abs/2309.11427v1"},"cats":{"new-dataset":0.218577681,"dev-research":0.1669642222,"data-quality":0.308255864}}
{"text":"We investigate the approximation efficiency of score functions by deep neural networks in diffusion-based generative modeling.","meta":{"url":"http://arxiv.org/abs/2309.11420v1"},"cats":{"new-dataset":0.0359245183,"dev-research":0.1679867929,"data-quality":0.1116425681}}
{"text":"While existing approximation theories utilize the smoothness of score functions, they suffer from the curse of dimensionality for intrinsically high-dimensional data.","meta":{"url":"http://arxiv.org/abs/2309.11420v1"},"cats":{"new-dataset":0.0183739637,"dev-research":0.1644012399,"data-quality":0.1112574399}}
{"text":"This limitation is pronounced in graphical models such as Markov random fields, common for image distributions, where the approximation efficiency of score functions remains unestablished.   ","meta":{"url":"http://arxiv.org/abs/2309.11420v1"},"cats":{"new-dataset":0.0091517681,"dev-research":0.1126904573,"data-quality":0.1135039564}}
{"text":"To address this, we observe score functions can often be well-approximated in graphical models through variational inference denoising algorithms.","meta":{"url":"http://arxiv.org/abs/2309.11420v1"},"cats":{"new-dataset":0.027032448,"dev-research":0.168226421,"data-quality":0.1678029451}}
{"text":"Furthermore, these algorithms are amenable to efficient neural network representation.","meta":{"url":"http://arxiv.org/abs/2309.11420v1"},"cats":{"new-dataset":0.0191308109,"dev-research":0.128309403,"data-quality":0.1171233813}}
{"text":"We demonstrate this in examples of graphical models, including Ising models, conditional Ising models, restricted Boltzmann machines, and sparse encoding models.","meta":{"url":"http://arxiv.org/abs/2309.11420v1"},"cats":{"new-dataset":0.0602269556,"dev-research":0.1352558355,"data-quality":0.1268983741}}
{"text":"Combined with off-the-shelf discretization error bounds for diffusion-based sampling, we provide an efficient sample complexity bound for diffusion-based generative modeling when the score function is learned by deep neural networks.","meta":{"url":"http://arxiv.org/abs/2309.11420v1"},"cats":{"new-dataset":0.07873466,"dev-research":0.143809731,"data-quality":0.1067280135}}
{"text":"We present Kosmos-2.5, a multimodal literate model for machine reading of text-intensive images.","meta":{"url":"http://arxiv.org/abs/2309.11419v1"},"cats":{"new-dataset":0.6273192578,"dev-research":0.1083482552,"data-quality":0.1337726988}}
{"text":"Pre-trained on large-scale text-intensive images, Kosmos-2.5 excels in two distinct yet cooperative transcription tasks: (1) generating spatially-aware text blocks, where each block of text is assigned its spatial coordinates within the image, and (2) producing structured text output that captures styles and structures into the markdown format.","meta":{"url":"http://arxiv.org/abs/2309.11419v1"},"cats":{"new-dataset":0.476128266,"dev-research":0.1394589825,"data-quality":0.1782422925}}
{"text":"This unified multimodal literate capability is achieved through a shared Transformer architecture, task-specific prompts, and flexible text representations.","meta":{"url":"http://arxiv.org/abs/2309.11419v1"},"cats":{"new-dataset":0.1155938227,"dev-research":0.1942090172,"data-quality":0.1216849829}}
{"text":"We evaluate Kosmos-2.5 on end-to-end document-level text recognition and image-to-markdown text generation.","meta":{"url":"http://arxiv.org/abs/2309.11419v1"},"cats":{"new-dataset":0.5281314188,"dev-research":0.1714270101,"data-quality":0.2538304809}}
{"text":"Furthermore, the model can be readily adapted for any text-intensive image understanding task with different prompts through supervised fine-tuning, making it a general-purpose tool for real-world applications involving text-rich images.","meta":{"url":"http://arxiv.org/abs/2309.11419v1"},"cats":{"new-dataset":0.1576001064,"dev-research":0.1590319944,"data-quality":0.1934753386}}
{"text":"This work also paves the way for the future scaling of multimodal large language models.","meta":{"url":"http://arxiv.org/abs/2309.11419v1"},"cats":{"new-dataset":0.1774615729,"dev-research":0.1411602512,"data-quality":0.1173273649}}
{"text":"Convolutional neural networks (CNNs) have achieved astonishing advances over the past decade, defining state-of-the-art in several computer vision tasks.","meta":{"url":"http://arxiv.org/abs/2309.11417v1"},"cats":{"new-dataset":0.1561502074,"dev-research":0.1690441756,"data-quality":0.1163152835}}
{"text":"CNNs are capable of learning robust representations of the data directly from the RGB pixels.","meta":{"url":"http://arxiv.org/abs/2309.11417v1"},"cats":{"new-dataset":0.1980323167,"dev-research":0.2004849412,"data-quality":0.2155764163}}
{"text":"However, most image data are usually available in compressed format, from which the JPEG is the most widely used due to transmission and storage purposes demanding a preliminary decoding process that have a high computational load and memory usage.","meta":{"url":"http://arxiv.org/abs/2309.11417v1"},"cats":{"new-dataset":0.0557667617,"dev-research":0.1455392169,"data-quality":0.0830422945}}
{"text":"For this reason, deep learning methods capable of learning directly from the compressed domain have been gaining attention in recent years.","meta":{"url":"http://arxiv.org/abs/2309.11417v1"},"cats":{"new-dataset":0.0371005536,"dev-research":0.1517097276,"data-quality":0.1327327363}}
{"text":"Those methods usually extract a frequency domain representation of the image, like DCT, by a partial decoding, and then make adaptation to typical CNNs architectures to work with them.","meta":{"url":"http://arxiv.org/abs/2309.11417v1"},"cats":{"new-dataset":0.0318810721,"dev-research":0.1480045506,"data-quality":0.1509616494}}
{"text":"One limitation of these current works is that, in order to accommodate the frequency domain data, the modifications made to the original model increase significantly their amount of parameters and computational complexity.","meta":{"url":"http://arxiv.org/abs/2309.11417v1"},"cats":{"new-dataset":0.0098342966,"dev-research":0.1683366984,"data-quality":0.0754408097}}
{"text":"On one hand, the methods have faster preprocessing, since the cost of fully decoding the images is avoided, but on the other hand, the cost of passing the images though the model is increased, mitigating the possible upside of accelerating the method.","meta":{"url":"http://arxiv.org/abs/2309.11417v1"},"cats":{"new-dataset":0.0032927464,"dev-research":0.2044576846,"data-quality":0.0756626666}}
{"text":"In this paper, we propose a further study of the computational cost of deep models designed for the frequency domain, evaluating the cost of decoding and passing the images through the network.","meta":{"url":"http://arxiv.org/abs/2309.11417v1"},"cats":{"new-dataset":0.1345365945,"dev-research":0.132090808,"data-quality":0.1291426505}}
{"text":"We also propose handcrafted and data-driven techniques for reducing the computational complexity and the number of parameters for these models in order to keep them similar to their RGB baselines, leading to efficient models with a better trade off between computational cost and accuracy.","meta":{"url":"http://arxiv.org/abs/2309.11417v1"},"cats":{"new-dataset":0.169260413,"dev-research":0.1615211909,"data-quality":0.0861732495}}
{"text":"Classical motion planning for robotic manipulation includes a set of general algorithms that aim to minimize a scene-specific cost of executing a given plan.","meta":{"url":"http://arxiv.org/abs/2309.11414v1"},"cats":{"new-dataset":0.0484258318,"dev-research":0.2205898751,"data-quality":0.0405343172}}
{"text":"This approach offers remarkable adaptability, as they can be directly used off-the-shelf for any new scene without needing specific training datasets.","meta":{"url":"http://arxiv.org/abs/2309.11414v1"},"cats":{"new-dataset":0.3952459818,"dev-research":0.1579589937,"data-quality":0.1551776098}}
{"text":"However, without a prior understanding of what diverse valid trajectories are and without specially designed cost functions for a given scene, the overall solutions tend to have low success rates.","meta":{"url":"http://arxiv.org/abs/2309.11414v1"},"cats":{"new-dataset":0.0169944094,"dev-research":0.1470469809,"data-quality":0.0727147054}}
{"text":"While deep-learning-based algorithms tremendously improve success rates, they are much harder to adopt without specialized training datasets.","meta":{"url":"http://arxiv.org/abs/2309.11414v1"},"cats":{"new-dataset":0.0188849481,"dev-research":0.1920603502,"data-quality":0.1709506465}}
{"text":"We propose EDMP, an Ensemble-of-costs-guided Diffusion for Motion Planning that aims to combine the strengths of classical and deep-learning-based motion planning.","meta":{"url":"http://arxiv.org/abs/2309.11414v1"},"cats":{"new-dataset":0.1635751421,"dev-research":0.195786209,"data-quality":0.0470211167}}
{"text":"Our diffusion-based network is trained on a set of diverse kinematically valid trajectories.","meta":{"url":"http://arxiv.org/abs/2309.11414v1"},"cats":{"new-dataset":0.044686562,"dev-research":0.104737469,"data-quality":0.0747606581}}
{"text":"Like classical planning, for any new scene at the time of inference, we compute scene-specific costs such as \"collision cost\" and guide the diffusion to generate valid trajectories that satisfy the scene-specific constraints.","meta":{"url":"http://arxiv.org/abs/2309.11414v1"},"cats":{"new-dataset":0.1342029281,"dev-research":0.1854499802,"data-quality":0.0495650663}}
{"text":"Further, instead of a single cost function that may be insufficient in capturing diversity across scenes, we use an ensemble of costs to guide the diffusion process, significantly improving the success rate compared to classical planners.","meta":{"url":"http://arxiv.org/abs/2309.11414v1"},"cats":{"new-dataset":0.0723369485,"dev-research":0.2115804384,"data-quality":0.0949195057}}
{"text":"EDMP performs comparably with SOTA deep-learning-based methods while retaining the generalization capabilities primarily associated with classical planners.","meta":{"url":"http://arxiv.org/abs/2309.11414v1"},"cats":{"new-dataset":0.0787318051,"dev-research":0.2563148426,"data-quality":0.0785069213}}
{"text":"Trajectory segmentation refers to dividing a trajectory into meaningful consecutive sub-trajectories.","meta":{"url":"http://arxiv.org/abs/2309.11413v1"},"cats":{"new-dataset":0.0683075722,"dev-research":0.1628687998,"data-quality":0.1004577485}}
{"text":"This paper focuses on trajectory segmentation for 3D rigid-body motions.","meta":{"url":"http://arxiv.org/abs/2309.11413v1"},"cats":{"new-dataset":0.1978449225,"dev-research":0.1376029018,"data-quality":0.0747054876}}
{"text":"Most segmentation approaches in the literature represent the body's trajectory as a point trajectory, considering only its translation and neglecting its rotation.","meta":{"url":"http://arxiv.org/abs/2309.11413v1"},"cats":{"new-dataset":0.041311939,"dev-research":0.1435524751,"data-quality":0.0880959071}}
{"text":"We propose a novel trajectory representation for rigid-body motions that incorporates both translation and rotation, and additionally exhibits several invariant properties.","meta":{"url":"http://arxiv.org/abs/2309.11413v1"},"cats":{"new-dataset":0.1904543693,"dev-research":0.1385868027,"data-quality":0.064690628}}
{"text":"This representation consists of a geometric progress rate and a third-order trajectory-shape descriptor.","meta":{"url":"http://arxiv.org/abs/2309.11413v1"},"cats":{"new-dataset":0.1388383431,"dev-research":0.1369466547,"data-quality":0.0462680444}}
{"text":"Concepts from screw theory were used to make this representation time-invariant and also invariant to the choice of body reference point.","meta":{"url":"http://arxiv.org/abs/2309.11413v1"},"cats":{"new-dataset":0.0114179524,"dev-research":0.1612143694,"data-quality":0.0684885502}}
{"text":"This new representation is validated for a self-supervised segmentation approach, both in simulation and using real recordings of human-demonstrated pouring motions.","meta":{"url":"http://arxiv.org/abs/2309.11413v1"},"cats":{"new-dataset":0.1020929322,"dev-research":0.1171196704,"data-quality":0.2267324849}}
{"text":"The results show a more robust detection of consecutive submotions with distinct features and a more consistent segmentation compared to conventional representations.","meta":{"url":"http://arxiv.org/abs/2309.11413v1"},"cats":{"new-dataset":0.0713225107,"dev-research":0.1306670072,"data-quality":0.24161202}}
{"text":"We believe that other existing segmentation methods may benefit from using this trajectory representation to improve their invariance.","meta":{"url":"http://arxiv.org/abs/2309.11413v1"},"cats":{"new-dataset":0.0450759211,"dev-research":0.1249394891,"data-quality":0.151106313}}
{"text":"This paper for the first time attempts to bridge the knowledge between chemistry, fluid mechanics, and robot swarms.","meta":{"url":"http://arxiv.org/abs/2309.11408v1"},"cats":{"new-dataset":0.0556062138,"dev-research":0.1961683629,"data-quality":0.066332927}}
{"text":"By forming these connections, we attempt to leverage established methodologies and tools from these these domains to uncover how we can better comprehend swarms.","meta":{"url":"http://arxiv.org/abs/2309.11408v1"},"cats":{"new-dataset":0.0591276049,"dev-research":0.2602765821,"data-quality":0.1277072436}}
{"text":"The focus of this paper is in presenting a new framework and sharing the reasons we find it promising and exciting.","meta":{"url":"http://arxiv.org/abs/2309.11408v1"},"cats":{"new-dataset":0.0529502653,"dev-research":0.2259460855,"data-quality":0.0621585124}}
{"text":"While the exact methods are still under development, we believe simply laying out a potential path towards solutions that have evaded our traditional methods using a novel method is worth considering.","meta":{"url":"http://arxiv.org/abs/2309.11408v1"},"cats":{"new-dataset":0.0030516481,"dev-research":0.32909955,"data-quality":0.073970611}}
{"text":"Our results are characterized through both simulations and real experiments on ground robots.","meta":{"url":"http://arxiv.org/abs/2309.11408v1"},"cats":{"new-dataset":0.0695196714,"dev-research":0.1323619523,"data-quality":0.0892341441}}
{"text":"Schema change is an unsolved problem in both live programming and local-first software.","meta":{"url":"http://arxiv.org/abs/2309.11406v1"},"cats":{"new-dataset":0.0781297568,"dev-research":0.4559949813,"data-quality":0.1742931093}}
{"text":"We include in schema change any change to the expected shape of data, whether that is expressed explicitly in a database schema or type system, or whether those expectations are implicit in the behavior of the code.","meta":{"url":"http://arxiv.org/abs/2309.11406v1"},"cats":{"new-dataset":0.0239106162,"dev-research":0.3053665678,"data-quality":0.1786898522}}
{"text":"Schema changes during live programming can create a mismatch between the code and data in the running environment.","meta":{"url":"http://arxiv.org/abs/2309.11406v1"},"cats":{"new-dataset":0.1555863936,"dev-research":0.5174520193,"data-quality":0.1969598698}}
{"text":"Similarly, schema changes in local-first programming can create mismatches between data in different replicas, and between data in a replica and the code colocated with it.","meta":{"url":"http://arxiv.org/abs/2309.11406v1"},"cats":{"new-dataset":0.0403584108,"dev-research":0.3725665555,"data-quality":0.2587799049}}
{"text":"In all of these situations the problem of schema change is to migrate or translate existing data in coordination with changes to the code.   ","meta":{"url":"http://arxiv.org/abs/2309.11406v1"},"cats":{"new-dataset":0.1314195701,"dev-research":0.3676411072,"data-quality":0.2159513222}}
{"text":"This paper contributes a set of concrete scenarios involving schema change that are offered as challenge problems to the live programming and local-first communities.","meta":{"url":"http://arxiv.org/abs/2309.11406v1"},"cats":{"new-dataset":0.1391422126,"dev-research":0.5288979173,"data-quality":0.1518559565}}
{"text":"We hope that these problems will spur progress by providing concrete objectives and a basis for comparing alternative solutions.","meta":{"url":"http://arxiv.org/abs/2309.11406v1"},"cats":{"new-dataset":0.0222053129,"dev-research":0.290869137,"data-quality":0.1087159367}}
{"text":"Since the Merge update upon which Ethereum transitioned to Proof of Stake, it has been touted that it resulted in lower power consumption and increased security.","meta":{"url":"http://arxiv.org/abs/2309.11394v1"},"cats":{"new-dataset":0.0087483399,"dev-research":0.2389411831,"data-quality":0.0978942387}}
{"text":"However, even if that is the case, can this state be sustained?   ","meta":{"url":"http://arxiv.org/abs/2309.11394v1"},"cats":{"new-dataset":0.0100870516,"dev-research":0.1654355306,"data-quality":0.1121949872}}
{"text":"In this paper, we focus on the potential impact of competition with other smart contract platforms on the price of Ethereum's native currency, Ether (ETH), thereby raising questions about the safety and sustainability purportedly brought about by the design of Proof of Stake.","meta":{"url":"http://arxiv.org/abs/2309.11394v1"},"cats":{"new-dataset":0.1180903158,"dev-research":0.2536292278,"data-quality":0.1413592122}}
{"text":"Current large language models (LLMs) can exhibit near-human levels of performance on many natural language-based tasks, including open-domain question answering.","meta":{"url":"http://arxiv.org/abs/2309.11392v1"},"cats":{"new-dataset":0.1117720686,"dev-research":0.1400832279,"data-quality":0.091573416}}
{"text":"Unfortunately, at this time, they also convincingly hallucinate incorrect answers, so that responses to questions must be verified against external sources before they can be accepted at face value.","meta":{"url":"http://arxiv.org/abs/2309.11392v1"},"cats":{"new-dataset":0.0221310457,"dev-research":0.2656979999,"data-quality":0.3277497494}}
{"text":"In this paper, we report two simple experiments to automatically validate generated answers against a corpus.","meta":{"url":"http://arxiv.org/abs/2309.11392v1"},"cats":{"new-dataset":0.1544269425,"dev-research":0.2785219882,"data-quality":0.4344578319}}
{"text":"We base our experiments on questions and passages from the MS MARCO (V1) test collection, and a retrieval pipeline consisting of sparse retrieval, dense retrieval and neural rerankers.","meta":{"url":"http://arxiv.org/abs/2309.11392v1"},"cats":{"new-dataset":0.1688059985,"dev-research":0.1112343242,"data-quality":0.1634531484}}
{"text":"In the first experiment, we validate the generated answer in its entirety.","meta":{"url":"http://arxiv.org/abs/2309.11392v1"},"cats":{"new-dataset":0.0337760639,"dev-research":0.1862681334,"data-quality":0.2054275597}}
{"text":"After presenting a question to an LLM and receiving a generated answer, we query the corpus with the combination of the question + generated answer.","meta":{"url":"http://arxiv.org/abs/2309.11392v1"},"cats":{"new-dataset":0.2482886635,"dev-research":0.1381547228,"data-quality":0.1342878323}}
{"text":"We then present the LLM with the combination of the question + generated answer + retrieved answer, prompting it to indicate if the generated answer can be supported by the retrieved answer.","meta":{"url":"http://arxiv.org/abs/2309.11392v1"},"cats":{"new-dataset":0.0479169586,"dev-research":0.1272537989,"data-quality":0.1033120388}}
{"text":"In the second experiment, we consider the generated answer at a more granular level, prompting the LLM to extract a list of factual statements from the answer and verifying each statement separately.","meta":{"url":"http://arxiv.org/abs/2309.11392v1"},"cats":{"new-dataset":0.0232562459,"dev-research":0.1947219802,"data-quality":0.1293011948}}
{"text":"We query the corpus with each factual statement and then present the LLM with the statement and the corresponding retrieved evidence.","meta":{"url":"http://arxiv.org/abs/2309.11392v1"},"cats":{"new-dataset":0.4471359933,"dev-research":0.1357599562,"data-quality":0.2053471789}}
{"text":"The LLM is prompted to indicate if the statement can be supported and make necessary edits using the retrieved material.","meta":{"url":"http://arxiv.org/abs/2309.11392v1"},"cats":{"new-dataset":0.014476229,"dev-research":0.1585537947,"data-quality":0.1849647292}}
{"text":"With an accuracy of over 80%, we find that an LLM is capable of verifying its generated answer when a corpus of supporting material is provided.","meta":{"url":"http://arxiv.org/abs/2309.11392v1"},"cats":{"new-dataset":0.1193134626,"dev-research":0.1713327434,"data-quality":0.22943618}}
{"text":"However, manual assessment of a random sample of questions reveals that incorrect generated answers are missed by this verification process.","meta":{"url":"http://arxiv.org/abs/2309.11392v1"},"cats":{"new-dataset":0.0315399781,"dev-research":0.3013835831,"data-quality":0.4780087734}}
{"text":"While this verification process can reduce hallucinations, it can not entirely eliminate them.","meta":{"url":"http://arxiv.org/abs/2309.11392v1"},"cats":{"new-dataset":0.0028973609,"dev-research":0.2115008298,"data-quality":0.2113442457}}
{"text":"We propose a method to modify a polygonal mesh in order to fit the zero-isoline of a level set function by extending a standard body-fitted strategy to a tessellation with arbitrarily-shaped elements.","meta":{"url":"http://arxiv.org/abs/2309.11389v1"},"cats":{"new-dataset":0.0475801093,"dev-research":0.1769299197,"data-quality":0.0684180459}}
{"text":"The novel level set-fitted approach, in combination with a Discontinuous Galerkin finite element approximation, provides an ideal setting to model physical problems characterized by embedded or evolving complex geometries, since it allows skipping any mesh post-processing in terms of grid quality.","meta":{"url":"http://arxiv.org/abs/2309.11389v1"},"cats":{"new-dataset":0.0317222599,"dev-research":0.2120456775,"data-quality":0.068507289}}
{"text":"The proposed methodology is firstly assessed on the linear elasticity equation, by verifying the approximation capability of the level set-fitted approach when dealing with configurations with heterogeneous material properties.","meta":{"url":"http://arxiv.org/abs/2309.11389v1"},"cats":{"new-dataset":0.0165504215,"dev-research":0.1646694106,"data-quality":0.0656088026}}
{"text":"Successively, we combine the level set-fitted methodology with a minimum compliance topology optimization technique, in order to deliver optimized layouts exhibiting crisp boundaries and reliable mechanical performances.","meta":{"url":"http://arxiv.org/abs/2309.11389v1"},"cats":{"new-dataset":0.0328516129,"dev-research":0.2267390653,"data-quality":0.0725574453}}
{"text":"An extensive numerical test campaign confirms the effectiveness of the proposed method.","meta":{"url":"http://arxiv.org/abs/2309.11389v1"},"cats":{"new-dataset":0.0019494358,"dev-research":0.1479296071,"data-quality":0.1242665128}}
{"text":"This paper presents Safurai-001, a new Large Language Model (LLM) with significant potential in the domain of coding assistance.","meta":{"url":"http://arxiv.org/abs/2309.11385v1"},"cats":{"new-dataset":0.1985850695,"dev-research":0.1703182786,"data-quality":0.2107287124}}
{"text":"Driven by recent advancements in coding LLMs, Safurai-001 competes in performance with the latest models like WizardCoder","meta":{"url":"http://arxiv.org/abs/2309.11385v1"},"cats":{"new-dataset":0.0961728523,"dev-research":0.1542370478,"data-quality":0.0980987329}}
{"text":"[Xu et al., 2023], PanguCoder","meta":{"url":"http://arxiv.org/abs/2309.11385v1"},"cats":{"new-dataset":0.7409517956,"dev-research":0.1300509285,"data-quality":0.131650202}}
{"text":"[Shen et al., 2023] and Phi-1","meta":{"url":"http://arxiv.org/abs/2309.11385v1"},"cats":{"new-dataset":0.3986765435,"dev-research":0.1495356701,"data-quality":0.0792581533}}
{"text":"[Gunasekar et al., 2023] but aims to deliver a more conversational interaction.","meta":{"url":"http://arxiv.org/abs/2309.11385v1"},"cats":{"new-dataset":0.1421520886,"dev-research":0.2651735981,"data-quality":0.0550763459}}
{"text":"By capitalizing on the progress in data engineering (including latest techniques of data transformation and prompt engineering) and instruction tuning, this new model promises to stand toe-to-toe with recent closed and open source developments.","meta":{"url":"http://arxiv.org/abs/2309.11385v1"},"cats":{"new-dataset":0.1289032138,"dev-research":0.327442567,"data-quality":0.1214104935}}
{"text":"Recognizing the need for an efficacious evaluation metric for coding LLMs, this paper also introduces GPT4-based MultiParameters, an evaluation benchmark that harnesses varied parameters to present a comprehensive insight into the models functioning and performance.","meta":{"url":"http://arxiv.org/abs/2309.11385v1"},"cats":{"new-dataset":0.0399340022,"dev-research":0.1543591779,"data-quality":0.1257557574}}
{"text":"Our assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and WizardCoder by 18.78% in the Code Readability parameter and more.","meta":{"url":"http://arxiv.org/abs/2309.11385v1"},"cats":{"new-dataset":0.1205176707,"dev-research":0.1904502036,"data-quality":0.1606078478}}
{"text":"Current simultaneous speech translation models can process audio only up to a few seconds long.","meta":{"url":"http://arxiv.org/abs/2309.11384v1"},"cats":{"new-dataset":0.0430324798,"dev-research":0.1287402764,"data-quality":0.1217698853}}
{"text":"Contemporary datasets provide an oracle segmentation into sentences based on human-annotated transcripts and translations.","meta":{"url":"http://arxiv.org/abs/2309.11384v1"},"cats":{"new-dataset":0.6690004281,"dev-research":0.2163984101,"data-quality":0.3546599367}}
{"text":"However, the segmentation into sentences is not available in the real world.","meta":{"url":"http://arxiv.org/abs/2309.11384v1"},"cats":{"new-dataset":0.0472351611,"dev-research":0.1574185319,"data-quality":0.251899265}}
{"text":"Current speech segmentation approaches either offer poor segmentation quality or have to trade latency for quality.","meta":{"url":"http://arxiv.org/abs/2309.11384v1"},"cats":{"new-dataset":0.0161150892,"dev-research":0.2060570662,"data-quality":0.3925731952}}
{"text":"In this paper, we propose a novel segmentation approach for a low-latency end-to-end speech translation.","meta":{"url":"http://arxiv.org/abs/2309.11384v1"},"cats":{"new-dataset":0.3389756708,"dev-research":0.1392933758,"data-quality":0.187055418}}
{"text":"We leverage the existing speech translation encoder-decoder architecture with ST CTC and show that it can perform the segmentation task without supervision or additional parameters.","meta":{"url":"http://arxiv.org/abs/2309.11384v1"},"cats":{"new-dataset":0.2382459529,"dev-research":0.1437879895,"data-quality":0.2056017857}}
{"text":"To the best of our knowledge, our method is the first that allows an actual end-to-end simultaneous speech translation, as the same model is used for translation and segmentation at the same time.","meta":{"url":"http://arxiv.org/abs/2309.11384v1"},"cats":{"new-dataset":0.0537111457,"dev-research":0.1399318291,"data-quality":0.1768106762}}
{"text":"On a diverse set of language pairs and in- and out-of-domain data, we show that the proposed approach achieves state-of-the-art quality at no additional computational cost.","meta":{"url":"http://arxiv.org/abs/2309.11384v1"},"cats":{"new-dataset":0.7063697433,"dev-research":0.1884234406,"data-quality":0.3561361208}}
{"text":"Visual language navigation (VLN) is an embodied task demanding a wide range of skills encompassing understanding, perception, and planning.","meta":{"url":"http://arxiv.org/abs/2309.11382v1"},"cats":{"new-dataset":0.0888759968,"dev-research":0.2953168816,"data-quality":0.1263649463}}
{"text":"For such a multifaceted challenge, previous VLN methods totally rely on one model's own thinking to make predictions within one round.","meta":{"url":"http://arxiv.org/abs/2309.11382v1"},"cats":{"new-dataset":0.0092676482,"dev-research":0.1844282124,"data-quality":0.1511044449}}
{"text":"However, existing models, even the most advanced large language model GPT4, still struggle with dealing with multiple tasks by single-round self-thinking.","meta":{"url":"http://arxiv.org/abs/2309.11382v1"},"cats":{"new-dataset":0.0229331533,"dev-research":0.2172543812,"data-quality":0.0903166153}}
{"text":"In this work, drawing inspiration from the expert consultation meeting, we introduce a novel zero-shot VLN framework.","meta":{"url":"http://arxiv.org/abs/2309.11382v1"},"cats":{"new-dataset":0.2188748471,"dev-research":0.2972260485,"data-quality":0.1379548307}}
{"text":"Within this framework, large models possessing distinct abilities are served as domain experts.","meta":{"url":"http://arxiv.org/abs/2309.11382v1"},"cats":{"new-dataset":0.0422020154,"dev-research":0.1994028218,"data-quality":0.0640177942}}
{"text":"Our proposed navigation agent, namely DiscussNav, can actively discuss with these experts to collect essential information before moving at every step.","meta":{"url":"http://arxiv.org/abs/2309.11382v1"},"cats":{"new-dataset":0.2244298327,"dev-research":0.3175304026,"data-quality":0.0470412674}}
{"text":"These discussions cover critical navigation subtasks like instruction understanding, environment perception, and completion estimation.","meta":{"url":"http://arxiv.org/abs/2309.11382v1"},"cats":{"new-dataset":0.1453159975,"dev-research":0.2941926082,"data-quality":0.0867608119}}
{"text":"Through comprehensive experiments, we demonstrate that discussions with domain experts can effectively facilitate navigation by perceiving instruction-relevant information, correcting inadvertent errors, and sifting through in-consistent movement decisions.","meta":{"url":"http://arxiv.org/abs/2309.11382v1"},"cats":{"new-dataset":0.0322581034,"dev-research":0.3847756868,"data-quality":0.147375517}}
{"text":"The performances on the representative VLN task R2R show that our method surpasses the leading zero-shot VLN model by a large margin on all metrics.","meta":{"url":"http://arxiv.org/abs/2309.11382v1"},"cats":{"new-dataset":0.0568608952,"dev-research":0.1279553083,"data-quality":0.1784911988}}
{"text":"Additionally, real-robot experiments display the obvious advantages of our method over single-round self-thinking.","meta":{"url":"http://arxiv.org/abs/2309.11382v1"},"cats":{"new-dataset":0.010758266,"dev-research":0.2068310922,"data-quality":0.0815925038}}
{"text":"We present a method based on natural language processing (NLP), for studying the influence of interest groups (lobbies) in the law-making process in the European Parliament (EP).","meta":{"url":"http://arxiv.org/abs/2309.11381v1"},"cats":{"new-dataset":0.2548130419,"dev-research":0.2724113767,"data-quality":0.2076134291}}
{"text":"We collect and analyze novel datasets of lobbies' position papers and speeches made by members of the EP (MEPs).","meta":{"url":"http://arxiv.org/abs/2309.11381v1"},"cats":{"new-dataset":0.7716637176,"dev-research":0.1260843391,"data-quality":0.1383859905}}
{"text":"By comparing these texts on the basis of semantic similarity and entailment, we are able to discover interpretable links between MEPs and lobbies.","meta":{"url":"http://arxiv.org/abs/2309.11381v1"},"cats":{"new-dataset":0.2294484879,"dev-research":0.201128245,"data-quality":0.1122061576}}
{"text":"In the absence of a ground-truth dataset of such links, we perform an indirect validation by comparing the discovered links with a dataset, which we curate, of retweet links between MEPs and lobbies, and with the publicly disclosed meetings of MEPs.","meta":{"url":"http://arxiv.org/abs/2309.11381v1"},"cats":{"new-dataset":0.2024544033,"dev-research":0.1813290248,"data-quality":0.1932001476}}
{"text":"Our best method achieves an AUC score of 0.77 and performs significantly better than several baselines.","meta":{"url":"http://arxiv.org/abs/2309.11381v1"},"cats":{"new-dataset":0.02367292,"dev-research":0.184489607,"data-quality":0.2062842476}}
{"text":"Moreover, an aggregate analysis of the discovered links, between groups of related lobbies and political groups of MEPs, correspond to the expectations from the ideology of the groups (e.g., center-left groups are associated with social causes).","meta":{"url":"http://arxiv.org/abs/2309.11381v1"},"cats":{"new-dataset":0.1484616294,"dev-research":0.1647723791,"data-quality":0.0794948267}}
{"text":"We believe that this work, which encompasses the methodology, datasets, and results, is a step towards enhancing the transparency of the intricate decision-making processes within democratic institutions.","meta":{"url":"http://arxiv.org/abs/2309.11381v1"},"cats":{"new-dataset":0.2486981152,"dev-research":0.2286780164,"data-quality":0.1569693345}}
{"text":"Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation.","meta":{"url":"http://arxiv.org/abs/2309.11379v1"},"cats":{"new-dataset":0.136025553,"dev-research":0.1066617352,"data-quality":0.1388552895}}
{"text":"These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further.","meta":{"url":"http://arxiv.org/abs/2309.11379v1"},"cats":{"new-dataset":0.0197696593,"dev-research":0.1440366161,"data-quality":0.1705081275}}
{"text":"However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \\textit{incremental} translation to users.","meta":{"url":"http://arxiv.org/abs/2309.11379v1"},"cats":{"new-dataset":0.0362356835,"dev-research":0.177061456,"data-quality":0.2374400912}}
{"text":"Further, this method lacks mechanisms for \\textit{controlling} the quality vs. latency tradeoff.","meta":{"url":"http://arxiv.org/abs/2309.11379v1"},"cats":{"new-dataset":0.0060009385,"dev-research":0.2483711881,"data-quality":0.3663476487}}
{"text":"We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control.","meta":{"url":"http://arxiv.org/abs/2309.11379v1"},"cats":{"new-dataset":0.0467285851,"dev-research":0.1755714512,"data-quality":0.1444239699}}
{"text":"We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode.   ","meta":{"url":"http://arxiv.org/abs/2309.11379v1"},"cats":{"new-dataset":0.1114160675,"dev-research":0.1837565605,"data-quality":0.1196606229}}
{"text":"Experimental results on MuST-C show 0.6-3.6 BLEU improvement without changing latency or 0.8-1.4 s latency improvement without changing quality.","meta":{"url":"http://arxiv.org/abs/2309.11379v1"},"cats":{"new-dataset":0.0578224661,"dev-research":0.220957598,"data-quality":0.1402124234}}
{"text":"Federated Learning (FL) is a distributed machine learning approach that enables model training in communication efficient and privacy-preserving manner.","meta":{"url":"http://arxiv.org/abs/2309.11378v1"},"cats":{"new-dataset":0.0576501778,"dev-research":0.1160235187,"data-quality":0.1113749427}}
{"text":"The standard optimization method in FL is Federated Averaging (FedAvg), which performs multiple local SGD steps between communication rounds.","meta":{"url":"http://arxiv.org/abs/2309.11378v1"},"cats":{"new-dataset":0.010324561,"dev-research":0.1155449613,"data-quality":0.0834498606}}
{"text":"FedAvg has been considered to lack algorithm adaptivity compared to modern first-order adaptive optimizations.","meta":{"url":"http://arxiv.org/abs/2309.11378v1"},"cats":{"new-dataset":0.0032997982,"dev-research":0.1385648767,"data-quality":0.0985794319}}
{"text":"In this paper, we propose new communication-efficient FL algortithms based on two adaptive frameworks: local adaptivity (PreFed) and server-side adaptivity (PreFedOp).","meta":{"url":"http://arxiv.org/abs/2309.11378v1"},"cats":{"new-dataset":0.0252287725,"dev-research":0.147515417,"data-quality":0.0852175935}}
{"text":"Proposed methods adopt adaptivity by using a novel covariance matrix preconditioner.","meta":{"url":"http://arxiv.org/abs/2309.11378v1"},"cats":{"new-dataset":0.0033543786,"dev-research":0.1492350956,"data-quality":0.070267867}}
{"text":"Theoretically, we provide convergence guarantees for our algorithms.","meta":{"url":"http://arxiv.org/abs/2309.11378v1"},"cats":{"new-dataset":0.0153623335,"dev-research":0.1381325188,"data-quality":0.0926628254}}
{"text":"The empirical experiments show our methods achieve state-of-the-art performances on both i.i.d. and non-i.i.d. settings.","meta":{"url":"http://arxiv.org/abs/2309.11378v1"},"cats":{"new-dataset":0.0145486473,"dev-research":0.167884191,"data-quality":0.095967992}}
{"text":"Recent work in machine learning for healthcare has raised concerns about patient privacy and algorithmic fairness.","meta":{"url":"http://arxiv.org/abs/2309.11373v1"},"cats":{"new-dataset":0.0161086166,"dev-research":0.1463799058,"data-quality":0.1505481273}}
{"text":"For example, previous work has shown that patient self-reported race can be predicted from medical data that does not explicitly contain racial information.","meta":{"url":"http://arxiv.org/abs/2309.11373v1"},"cats":{"new-dataset":0.0335148831,"dev-research":0.1920409524,"data-quality":0.2416224616}}
{"text":"However, the extent of data identification is unknown, and we lack ways to develop models whose outcomes are minimally affected by such information.","meta":{"url":"http://arxiv.org/abs/2309.11373v1"},"cats":{"new-dataset":0.0257156638,"dev-research":0.1436974888,"data-quality":0.3071718876}}
{"text":"Here we systematically investigated the ability of time-series electronic health record data to predict patient static information.","meta":{"url":"http://arxiv.org/abs/2309.11373v1"},"cats":{"new-dataset":0.072411551,"dev-research":0.1887681393,"data-quality":0.1095671013}}
{"text":"We found that not only the raw time-series data, but also learned representations from machine learning models, can be trained to predict a variety of static information with area under the receiver operating characteristic curve as high as 0.851 for biological sex, 0.869 for binarized age and 0.810 for self-reported race.","meta":{"url":"http://arxiv.org/abs/2309.11373v1"},"cats":{"new-dataset":0.1144383355,"dev-research":0.1337851352,"data-quality":0.1132015964}}
{"text":"Such high predictive performance can be extended to a wide range of comorbidity factors and exists even when the model was trained for different tasks, using different cohorts, using different model architectures and databases.","meta":{"url":"http://arxiv.org/abs/2309.11373v1"},"cats":{"new-dataset":0.0229041999,"dev-research":0.1988744792,"data-quality":0.0577166885}}
{"text":"Given the privacy and fairness concerns these findings pose, we develop a variational autoencoder-based approach that learns a structured latent space to disentangle patient-sensitive attributes from time-series data.","meta":{"url":"http://arxiv.org/abs/2309.11373v1"},"cats":{"new-dataset":0.0711403547,"dev-research":0.1326928376,"data-quality":0.1329868138}}
{"text":"Our work thoroughly investigates the ability of machine learning models to encode patient static information from time-series electronic health records and introduces a general approach to protect patient-sensitive attribute information for downstream tasks.","meta":{"url":"http://arxiv.org/abs/2309.11373v1"},"cats":{"new-dataset":0.0708745025,"dev-research":0.2030103008,"data-quality":0.1573188116}}
{"text":"Human-robot collaboration has benefited users with higher efficiency towards interactive tasks.","meta":{"url":"http://arxiv.org/abs/2309.11368v1"},"cats":{"new-dataset":0.0390758945,"dev-research":0.3918389288,"data-quality":0.0487547202}}
{"text":"Nevertheless, most collaborative schemes rely on complicated human-machine interfaces, which might lack the requisite intuitiveness compared with natural limb control.","meta":{"url":"http://arxiv.org/abs/2309.11368v1"},"cats":{"new-dataset":0.0079322377,"dev-research":0.3124795717,"data-quality":0.0488374286}}
{"text":"We also expect to understand human intent with low training data requirements.","meta":{"url":"http://arxiv.org/abs/2309.11368v1"},"cats":{"new-dataset":0.032345607,"dev-research":0.2040398687,"data-quality":0.1683334158}}
{"text":"In response to these challenges, this paper introduces an innovative human-robot collaborative framework that seamlessly integrates hand gesture and dynamic movement recognition, voice recognition, and a switchable control adaptation strategy.","meta":{"url":"http://arxiv.org/abs/2309.11368v1"},"cats":{"new-dataset":0.1823984681,"dev-research":0.2618725159,"data-quality":0.0796103198}}
{"text":"These modules provide a user-friendly approach that enables the robot to deliver the tools as per user need, especially when the user is working with both hands.","meta":{"url":"http://arxiv.org/abs/2309.11368v1"},"cats":{"new-dataset":0.0840135157,"dev-research":0.3822277361,"data-quality":0.060083875}}
{"text":"Therefore, users can focus on their task execution without additional training in the use of human-machine interfaces, while the robot interprets their intuitive gestures.","meta":{"url":"http://arxiv.org/abs/2309.11368v1"},"cats":{"new-dataset":0.0194659798,"dev-research":0.3268253917,"data-quality":0.0641387782}}
{"text":"The proposed multimodal interaction framework is executed in the UR5e robot platform equipped with a RealSense D435i camera, and the effectiveness is assessed through a soldering circuit board task.","meta":{"url":"http://arxiv.org/abs/2309.11368v1"},"cats":{"new-dataset":0.1304913816,"dev-research":0.2766967458,"data-quality":0.0415427595}}
{"text":"The experiment results have demonstrated superior performance in hand gesture recognition, where the static hand gesture recognition module achieves an accuracy of 94.3\\%, while the dynamic motion recognition module reaches 97.6\\% accuracy.","meta":{"url":"http://arxiv.org/abs/2309.11368v1"},"cats":{"new-dataset":0.1663600633,"dev-research":0.2104871746,"data-quality":0.1565550849}}
{"text":"Compared with human solo manipulation, the proposed approach facilitates higher efficiency tool delivery, without significantly distracting from human intents.","meta":{"url":"http://arxiv.org/abs/2309.11368v1"},"cats":{"new-dataset":0.0082026836,"dev-research":0.3403834855,"data-quality":0.0643544367}}
{"text":"The celebrated notion of important separators bounds the number of small $(S,T)$-separators in a graph which are 'farthest from $S$' in a technical sense.","meta":{"url":"http://arxiv.org/abs/2309.11366v1"},"cats":{"new-dataset":0.0999501125,"dev-research":0.1493342724,"data-quality":0.1364162618}}
{"text":"In this paper, we introduce a generalization of this powerful algorithmic primitive that is phrased in terms of $k$-secluded vertex sets: sets with an open neighborhood of size at most $k$.   In this terminology, the bound on important separators says that there are at most $4^k$ maximal $k$-secluded connected vertex sets $C$ containing $S$ but disjoint from $T$. We generalize this statement significantly: even when we demand that $G[C]$ avoids a finite set $\\mathcal{F}$ of forbidden induced subgraphs, the number of such maximal subgraphs is $2^{O(k)}$ and they can be enumerated efficiently.","meta":{"url":"http://arxiv.org/abs/2309.11366v1"},"cats":{"new-dataset":0.2485302589,"dev-research":0.164268163,"data-quality":0.1308946535}}
{"text":"This allows us to make significant improvements for two problems from the literature.   ","meta":{"url":"http://arxiv.org/abs/2309.11366v1"},"cats":{"new-dataset":0.0086454746,"dev-research":0.3669819811,"data-quality":0.1616316508}}
{"text":"Our first application concerns the 'Connected $k$-Secluded $\\mathcal{F}$-free subgraph' problem, where $\\mathcal{F}$ is a finite set of forbidden induced subgraphs.","meta":{"url":"http://arxiv.org/abs/2309.11366v1"},"cats":{"new-dataset":0.1579051431,"dev-research":0.1559495204,"data-quality":0.2007444224}}
{"text":"Given a graph in which each vertex has a positive integer weight, the problem asks to find a maximum-weight connected $k$-secluded vertex set $C \\subseteq V(G)$ such that $G[C]$ does not contain an induced subgraph isomorphic to any $F \\in \\mathcal{F}$.","meta":{"url":"http://arxiv.org/abs/2309.11366v1"},"cats":{"new-dataset":0.051230647,"dev-research":0.125807854,"data-quality":0.2248534008}}
{"text":"The parameterization by $k$ is known to be solvable in triple-exponential time via the technique of recursive understanding, which we improve to single-exponential.   ","meta":{"url":"http://arxiv.org/abs/2309.11366v1"},"cats":{"new-dataset":0.0838047044,"dev-research":0.1060871561,"data-quality":0.0562392993}}
{"text":"Our second application concerns the deletion problem to scattered graph classes.","meta":{"url":"http://arxiv.org/abs/2309.11366v1"},"cats":{"new-dataset":0.0808180175,"dev-research":0.2132548357,"data-quality":0.2464721045}}
{"text":"Here, the task is to find a vertex set of size at most $k$ whose removal yields a graph whose each connected component belongs to one of the prescribed graph classes $\\Pi_1, \\ldots, \\Pi_d$. We obtain a single-exponential algorithm whenever each class $\\Pi_i$ is characterized by a finite number of forbidden induced subgraphs.","meta":{"url":"http://arxiv.org/abs/2309.11366v1"},"cats":{"new-dataset":0.1854638474,"dev-research":0.1360584995,"data-quality":0.12770815}}
{"text":"This generalizes and improves upon earlier results in the literature.","meta":{"url":"http://arxiv.org/abs/2309.11366v1"},"cats":{"new-dataset":0.0086218373,"dev-research":0.2156199556,"data-quality":0.1542051754}}
{"text":"Automata networks, and in particular Boolean networks, are used to model diverse networks of interacting entities.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.0551137115,"dev-research":0.2029354761,"data-quality":0.1148796631}}
{"text":"The interaction graph of an automata network is its most important parameter, as it represents the overall architecture of the network.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.0476883685,"dev-research":0.2397109489,"data-quality":0.0744785102}}
{"text":"A continuous amount of work has been devoted to infer dynamical properties of the automata network based on its interaction graph only.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.0633440758,"dev-research":0.1896820069,"data-quality":0.0984096471}}
{"text":"Robert's theorem is the seminal result in this area; it states that automata networks with an acyclic interaction graph converge to a unique fixed point.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.0624022602,"dev-research":0.1735334892,"data-quality":0.1002008959}}
{"text":"The feedback bound can be viewed as an extension of Robert's theorem; it gives an upper bound on the number of fixed points of an automata network based on the size of a minimum feedback vertex set of its interaction graph.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.1366638482,"dev-research":0.1732584832,"data-quality":0.1116466801}}
{"text":"Boolean networks can be viewed as self-mappings on the power set lattice of the set of entities.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.0839371052,"dev-research":0.173925996,"data-quality":0.154341776}}
{"text":"In this paper, we consider self-mappings on a general complete lattice.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.0670899465,"dev-research":0.1273339603,"data-quality":0.1199218243}}
{"text":"We make two conceptual contributions.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.0321099584,"dev-research":0.3053999625,"data-quality":0.1217510049}}
{"text":"Firstly, we can view a digraph as a residuated mapping on the power set lattice; as such, we define a graph on a complete lattice as a residuated mapping on that lattice.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.0839537217,"dev-research":0.2282833764,"data-quality":0.0820018259}}
{"text":"We extend and generalise some results on digraphs to our setting.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.1880789245,"dev-research":0.2190708725,"data-quality":0.1355203056}}
{"text":"Secondly, we introduce a generalised notion of dependency whereby any mapping $\\phi$ can depend on any other mapping $\\alpha$. In fact, we are able to give four kinds of dependency in this case.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.0581251235,"dev-research":0.1860609509,"data-quality":0.102771604}}
{"text":"We can then vastly expand Robert's theorem to self-mappings on general complete lattices; we similarly generalise the feedback bound.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.0312283655,"dev-research":0.0994373128,"data-quality":0.1109737451}}
{"text":"We then obtain stronger results in the case where the lattice is a complete Boolean algebra.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.0115111851,"dev-research":0.1753699753,"data-quality":0.1092919874}}
{"text":"We finally show how our results can be applied to prove the convergence of automata networks.","meta":{"url":"http://arxiv.org/abs/2309.11363v1"},"cats":{"new-dataset":0.0934808687,"dev-research":0.1812631629,"data-quality":0.1870905821}}
{"text":"We present a comprehensive benchmark dataset for Knowledge Graph Question Answering in Materials Science (KGQA4MAT), with a focus on metal-organic frameworks (MOFs).","meta":{"url":"http://arxiv.org/abs/2309.11361v1"},"cats":{"new-dataset":0.4258540684,"dev-research":0.1506432634,"data-quality":0.1277718368}}
{"text":"A knowledge graph for metal-organic frameworks (MOF-KG) has been constructed by integrating structured databases and knowledge extracted from the literature.","meta":{"url":"http://arxiv.org/abs/2309.11361v1"},"cats":{"new-dataset":0.2026453038,"dev-research":0.1654665795,"data-quality":0.1180463045}}
{"text":"To enhance MOF-KG accessibility for domain experts, we aim to develop a natural language interface for querying the knowledge graph.","meta":{"url":"http://arxiv.org/abs/2309.11361v1"},"cats":{"new-dataset":0.3318624562,"dev-research":0.2500115884,"data-quality":0.1521910144}}
{"text":"We have developed a benchmark comprised of 161 complex questions involving comparison, aggregation, and complicated graph structures.","meta":{"url":"http://arxiv.org/abs/2309.11361v1"},"cats":{"new-dataset":0.1256896594,"dev-research":0.1823996555,"data-quality":0.0974459107}}
{"text":"Each question is rephrased in three additional variations, resulting in 644 questions and 161 KG queries.","meta":{"url":"http://arxiv.org/abs/2309.11361v1"},"cats":{"new-dataset":0.2456722548,"dev-research":0.1566953798,"data-quality":0.117292902}}
{"text":"To evaluate the benchmark, we have developed a systematic approach for utilizing ChatGPT to translate natural language questions into formal KG queries.","meta":{"url":"http://arxiv.org/abs/2309.11361v1"},"cats":{"new-dataset":0.3523820129,"dev-research":0.2525167902,"data-quality":0.1850214064}}
{"text":"We also apply the approach to the well-known QALD-9 dataset, demonstrating ChatGPT's potential in addressing KGQA issues for different platforms and query languages.","meta":{"url":"http://arxiv.org/abs/2309.11361v1"},"cats":{"new-dataset":0.8078927969,"dev-research":0.168257327,"data-quality":0.1703807187}}
{"text":"The benchmark and the proposed approach aim to stimulate further research and development of user-friendly and efficient interfaces for querying domain-specific materials science knowledge graphs, thereby accelerating the discovery of novel materials.","meta":{"url":"http://arxiv.org/abs/2309.11361v1"},"cats":{"new-dataset":0.1674705844,"dev-research":0.1923600124,"data-quality":0.1024232361}}
{"text":"In recent years, reinforcement learning and imitation learning have shown great potential for controlling humanoid robots' motion.","meta":{"url":"http://arxiv.org/abs/2309.11359v1"},"cats":{"new-dataset":0.0709428021,"dev-research":0.1372936189,"data-quality":0.0439163471}}
{"text":"However, these methods typically create simulation environments and rewards for specific tasks, resulting in the requirements of multiple policies and limited capabilities for tackling complex and unknown tasks.","meta":{"url":"http://arxiv.org/abs/2309.11359v1"},"cats":{"new-dataset":0.0105941551,"dev-research":0.2835747633,"data-quality":0.0437869856}}
{"text":"To overcome these issues, we present a novel approach that combines adversarial imitation learning with large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2309.11359v1"},"cats":{"new-dataset":0.1359200742,"dev-research":0.1161094916,"data-quality":0.1521193986}}
{"text":"This innovative method enables the agent to learn reusable skills with a single policy and solve zero-shot tasks under the guidance of LLMs.","meta":{"url":"http://arxiv.org/abs/2309.11359v1"},"cats":{"new-dataset":0.0247003257,"dev-research":0.1518671347,"data-quality":0.0598277217}}
{"text":"In particular, we utilize the LLM as a strategic planner for applying previously learned skills to novel tasks through the comprehension of task-specific prompts.","meta":{"url":"http://arxiv.org/abs/2309.11359v1"},"cats":{"new-dataset":0.0395160886,"dev-research":0.2269966614,"data-quality":0.0413967097}}
{"text":"This empowers the robot to perform the specified actions in a sequence.","meta":{"url":"http://arxiv.org/abs/2309.11359v1"},"cats":{"new-dataset":0.0258213594,"dev-research":0.2086073222,"data-quality":0.0446366638}}
{"text":"To improve our model, we incorporate codebook-based vector quantization, allowing the agent to generate suitable actions in response to unseen textual commands from LLMs.","meta":{"url":"http://arxiv.org/abs/2309.11359v1"},"cats":{"new-dataset":0.1289588365,"dev-research":0.2381027062,"data-quality":0.1562726465}}
{"text":"Furthermore, we design general reward functions that consider the distinct motion features of humanoid robots, ensuring the agent imitates the motion data while maintaining goal orientation without additional guiding direction approaches or policies.","meta":{"url":"http://arxiv.org/abs/2309.11359v1"},"cats":{"new-dataset":0.1132366026,"dev-research":0.1441423811,"data-quality":0.061874301}}
{"text":"To the best of our knowledge, this is the first framework that controls humanoid robots using a single learning policy network and LLM as a planner.","meta":{"url":"http://arxiv.org/abs/2309.11359v1"},"cats":{"new-dataset":0.0941307822,"dev-research":0.1447429182,"data-quality":0.0397407929}}
{"text":"Extensive experiments demonstrate that our method exhibits efficient and adaptive ability in complicated motion tasks.","meta":{"url":"http://arxiv.org/abs/2309.11359v1"},"cats":{"new-dataset":0.0099408094,"dev-research":0.1874268596,"data-quality":0.0434881574}}
{"text":"3D face reconstruction algorithms from images and videos are applied to many fields, from plastic surgery to the entertainment sector, thanks to their advantageous features.","meta":{"url":"http://arxiv.org/abs/2309.11357v1"},"cats":{"new-dataset":0.0343070161,"dev-research":0.1764605879,"data-quality":0.0703381823}}
{"text":"However, when looking at forensic applications, 3D face reconstruction must observe strict requirements that still make its possible role in bringing evidence to a lawsuit unclear.","meta":{"url":"http://arxiv.org/abs/2309.11357v1"},"cats":{"new-dataset":0.0078091967,"dev-research":0.2677985533,"data-quality":0.1347842765}}
{"text":"An extensive investigation of the constraints, potential, and limits of its application in forensics is still missing.","meta":{"url":"http://arxiv.org/abs/2309.11357v1"},"cats":{"new-dataset":0.0448713287,"dev-research":0.1634256718,"data-quality":0.1225584982}}
{"text":"Shedding some light on this matter is the goal of the present survey, which starts by clarifying the relation between forensic applications and biometrics, with a focus on face recognition.","meta":{"url":"http://arxiv.org/abs/2309.11357v1"},"cats":{"new-dataset":0.1072373657,"dev-research":0.1656124427,"data-quality":0.1039398881}}
{"text":"Therefore, it provides an analysis of the achievements of 3D face reconstruction algorithms from surveillance videos and mugshot images and discusses the current obstacles that separate 3D face reconstruction from an active role in forensic applications.","meta":{"url":"http://arxiv.org/abs/2309.11357v1"},"cats":{"new-dataset":0.0822496763,"dev-research":0.1725234516,"data-quality":0.0678289019}}
{"text":"Finally, it examines the underlying data sets, with their advantages and limitations, while proposing alternatives that could substitute or complement them.","meta":{"url":"http://arxiv.org/abs/2309.11357v1"},"cats":{"new-dataset":0.0681747984,"dev-research":0.2095470085,"data-quality":0.1056034275}}
{"text":"Rare event prediction involves identifying and forecasting events with a low probability using machine learning and data analysis.","meta":{"url":"http://arxiv.org/abs/2309.11356v1"},"cats":{"new-dataset":0.0427114864,"dev-research":0.1870050111,"data-quality":0.1574595773}}
{"text":"Due to the imbalanced data distributions, where the frequency of common events vastly outweighs that of rare events, it requires using specialized methods within each step of the machine learning pipeline, i.e., from data processing to algorithms to evaluation protocols.","meta":{"url":"http://arxiv.org/abs/2309.11356v1"},"cats":{"new-dataset":0.0140828506,"dev-research":0.2077692399,"data-quality":0.1649636713}}
{"text":"Predicting the occurrences of rare events is important for real-world applications, such as Industry 4.0, and is an active research area in statistical and machine learning.","meta":{"url":"http://arxiv.org/abs/2309.11356v1"},"cats":{"new-dataset":0.0992966635,"dev-research":0.2043788329,"data-quality":0.1713862769}}
{"text":"This paper comprehensively reviews the current approaches for rare event prediction along four dimensions: rare event data, data processing, algorithmic approaches, and evaluation approaches.","meta":{"url":"http://arxiv.org/abs/2309.11356v1"},"cats":{"new-dataset":0.1108019038,"dev-research":0.1372237471,"data-quality":0.1460320419}}
{"text":"Specifically, we consider 73 datasets from different modalities (i.e., numerical, image, text, and audio), four major categories of data processing, five major algorithmic groupings, and two broader evaluation approaches.","meta":{"url":"http://arxiv.org/abs/2309.11356v1"},"cats":{"new-dataset":0.4762600194,"dev-research":0.1462392345,"data-quality":0.1914516832}}
{"text":"This paper aims to identify gaps in the current literature and highlight the challenges of predicting rare events.","meta":{"url":"http://arxiv.org/abs/2309.11356v1"},"cats":{"new-dataset":0.097976654,"dev-research":0.1513956157,"data-quality":0.1884576129}}
{"text":"It also suggests potential research directions, which can help guide practitioners and researchers.","meta":{"url":"http://arxiv.org/abs/2309.11356v1"},"cats":{"new-dataset":0.0060587302,"dev-research":0.2951386679,"data-quality":0.0655923348}}
{"text":"Cities around the world face a critical shortage of affordable and decent housing.","meta":{"url":"http://arxiv.org/abs/2309.11354v1"},"cats":{"new-dataset":0.1270139063,"dev-research":0.2474336938,"data-quality":0.115915655}}
{"text":"Despite its critical importance for policy, our ability to effectively monitor and track progress in urban housing is limited.","meta":{"url":"http://arxiv.org/abs/2309.11354v1"},"cats":{"new-dataset":0.0838193444,"dev-research":0.2895616933,"data-quality":0.0640004505}}
{"text":"Deep learning-based computer vision methods applied to street-level images have been successful in the measurement of socioeconomic and environmental inequalities but did not fully utilize temporal images to track urban change as time-varying labels are often unavailable.","meta":{"url":"http://arxiv.org/abs/2309.11354v1"},"cats":{"new-dataset":0.2421548324,"dev-research":0.2124846556,"data-quality":0.1329449261}}
{"text":"We used self-supervised methods to measure change in London using 15 million street images taken between 2008 and 2021.","meta":{"url":"http://arxiv.org/abs/2309.11354v1"},"cats":{"new-dataset":0.4434979644,"dev-research":0.1949945315,"data-quality":0.1761715756}}
{"text":"Our novel adaptation of Barlow Twins, Street2Vec, embeds urban structure while being invariant to seasonal and daily changes without manual annotations.","meta":{"url":"http://arxiv.org/abs/2309.11354v1"},"cats":{"new-dataset":0.2778542965,"dev-research":0.1935165536,"data-quality":0.1382313852}}
{"text":"It outperformed generic embeddings, successfully identified point-level change in London's housing supply from street-level images, and distinguished between major and minor change.","meta":{"url":"http://arxiv.org/abs/2309.11354v1"},"cats":{"new-dataset":0.1782437749,"dev-research":0.1915307074,"data-quality":0.2148135123}}
{"text":"This capability can provide timely information for urban planning and policy decisions toward more liveable, equitable, and sustainable cities.","meta":{"url":"http://arxiv.org/abs/2309.11354v1"},"cats":{"new-dataset":0.1407463243,"dev-research":0.272047525,"data-quality":0.0361505101}}
{"text":"We present C$\\cdot$ASE, an efficient and effective framework that learns conditional Adversarial Skill Embeddings for physics-based characters.","meta":{"url":"http://arxiv.org/abs/2309.11351v1"},"cats":{"new-dataset":0.2023594038,"dev-research":0.1756624031,"data-quality":0.1248301601}}
{"text":"Our physically simulated character can learn a diverse repertoire of skills while providing controllability in the form of direct manipulation of the skills to be performed.","meta":{"url":"http://arxiv.org/abs/2309.11351v1"},"cats":{"new-dataset":0.0727440937,"dev-research":0.2054081738,"data-quality":0.0510014409}}
{"text":"C$\\cdot$ASE divides the heterogeneous skill motions into distinct subsets containing homogeneous samples for training a low-level conditional model to learn conditional behavior distribution.","meta":{"url":"http://arxiv.org/abs/2309.11351v1"},"cats":{"new-dataset":0.0688199855,"dev-research":0.1501513413,"data-quality":0.0824587701}}
{"text":"The skill-conditioned imitation learning naturally offers explicit control over the character's skills after training.","meta":{"url":"http://arxiv.org/abs/2309.11351v1"},"cats":{"new-dataset":0.023937566,"dev-research":0.2137768741,"data-quality":0.0628717942}}
{"text":"The training course incorporates the focal skill sampling, skeletal residual forces, and element-wise feature masking to balance diverse skills of varying complexities, mitigate dynamics mismatch to master agile motions and capture more general behavior characteristics, respectively.","meta":{"url":"http://arxiv.org/abs/2309.11351v1"},"cats":{"new-dataset":0.1013501341,"dev-research":0.1707028926,"data-quality":0.0683134364}}
{"text":"Once trained, the conditional model can produce highly diverse and realistic skills, outperforming state-of-the-art models, and can be repurposed in various downstream tasks.","meta":{"url":"http://arxiv.org/abs/2309.11351v1"},"cats":{"new-dataset":0.0140580701,"dev-research":0.1977204544,"data-quality":0.0725346348}}
{"text":"In particular, the explicit skill control handle allows a high-level policy or user to direct the character with desired skill specifications, which we demonstrate is advantageous for interactive character animation.","meta":{"url":"http://arxiv.org/abs/2309.11351v1"},"cats":{"new-dataset":0.0880506411,"dev-research":0.3296005102,"data-quality":0.0364767821}}
{"text":"This article unifies and generalizes fundamental results related to $n$-process asynchronous crash-prone distributed computing.","meta":{"url":"http://arxiv.org/abs/2309.11350v1"},"cats":{"new-dataset":0.1113182485,"dev-research":0.2126726222,"data-quality":0.172654355}}
{"text":"More precisely, it proves that for every $0\\leq k \\leq n$, assuming that process failures occur only before the number of participating processes bypasses a predefined threshold that equals $n-k$ (a participating process is a process that has executed at least one statement of its code), an asynchronous algorithm exists that solves consensus for $n$ processes in the presence of $f$ crash failures if and only if $f \\leq k$.","meta":{"url":"http://arxiv.org/abs/2309.11350v1"},"cats":{"new-dataset":0.0556834654,"dev-research":0.2392355693,"data-quality":0.223744389}}
{"text":"In a very simple and interesting way, the \"extreme\" case $k=0$ boils down to the celebrated FLP impossibility result (1985, 1987).","meta":{"url":"http://arxiv.org/abs/2309.11350v1"},"cats":{"new-dataset":0.1207852517,"dev-research":0.090899791,"data-quality":0.1310015865}}
{"text":"Moreover, the second extreme case, namely $k=n$, captures the celebrated mutual exclusion result by E.W. Dijkstra (1965) that states that mutual exclusion can be solved for $n$ processes in an asynchronous read/write shared memory system where any number of processes may crash (but only) before starting to participate in the algorithm (that is, participation is not required, but once a process starts participating it may not fail).","meta":{"url":"http://arxiv.org/abs/2309.11350v1"},"cats":{"new-dataset":0.0545931347,"dev-research":0.1662125761,"data-quality":0.1435349889}}
{"text":"More generally, the possibility/impossibility stated above demonstrates that more failures can be tolerated when they occur earlier in the computation (hence the title).","meta":{"url":"http://arxiv.org/abs/2309.11350v1"},"cats":{"new-dataset":0.0020079542,"dev-research":0.3157444372,"data-quality":0.2900051691}}
{"text":"Grammatical Error Detection and Correction (GEC) tools have proven useful for native speakers and second language learners.","meta":{"url":"http://arxiv.org/abs/2309.11346v1"},"cats":{"new-dataset":0.0543805121,"dev-research":0.3501829162,"data-quality":0.5233938805}}
{"text":"Developing such tools requires a large amount of parallel, annotated data, which is unavailable for most languages.","meta":{"url":"http://arxiv.org/abs/2309.11346v1"},"cats":{"new-dataset":0.3517701624,"dev-research":0.3508095527,"data-quality":0.1483391961}}
{"text":"Synthetic data generation is a common practice to overcome the scarcity of such data.","meta":{"url":"http://arxiv.org/abs/2309.11346v1"},"cats":{"new-dataset":0.282236706,"dev-research":0.236351781,"data-quality":0.1087329768}}
{"text":"However, it is not straightforward for morphologically rich languages like Turkish due to complex writing rules that require phonological, morphological, and syntactic information.","meta":{"url":"http://arxiv.org/abs/2309.11346v1"},"cats":{"new-dataset":0.0244417272,"dev-research":0.2146994492,"data-quality":0.1923296838}}
{"text":"In this work, we present a flexible and extensible synthetic data generation pipeline for Turkish covering more than 20 expert-curated grammar and spelling rules (a.k.a., writing rules) implemented through complex transformation functions.","meta":{"url":"http://arxiv.org/abs/2309.11346v1"},"cats":{"new-dataset":0.7355123559,"dev-research":0.2835233911,"data-quality":0.1846594356}}
{"text":"Using this pipeline, we derive 130,000 high-quality parallel sentences from professionally edited articles.","meta":{"url":"http://arxiv.org/abs/2309.11346v1"},"cats":{"new-dataset":0.2197281554,"dev-research":0.1767012284,"data-quality":0.1537856498}}
{"text":"Additionally, we create a more realistic test set by manually annotating a set of movie reviews.","meta":{"url":"http://arxiv.org/abs/2309.11346v1"},"cats":{"new-dataset":0.2121855679,"dev-research":0.3379980698,"data-quality":0.4348649687}}
{"text":"We implement three baselines formulating the task as i) neural machine translation, ii) sequence tagging, and iii) prefix tuning with a pretrained decoder-only model, achieving strong results.","meta":{"url":"http://arxiv.org/abs/2309.11346v1"},"cats":{"new-dataset":0.21695041,"dev-research":0.1707654928,"data-quality":0.2613650149}}
{"text":"Furthermore, we perform exhaustive experiments on out-of-domain datasets to gain insights on the transferability and robustness of the proposed approaches.","meta":{"url":"http://arxiv.org/abs/2309.11346v1"},"cats":{"new-dataset":0.405050194,"dev-research":0.1610970896,"data-quality":0.2463312231}}
{"text":"Our results suggest that our corpus, GECTurk, is high-quality and allows knowledge transfer for the out-of-domain setting.","meta":{"url":"http://arxiv.org/abs/2309.11346v1"},"cats":{"new-dataset":0.5572118802,"dev-research":0.2384091769,"data-quality":0.3451194518}}
{"text":"To encourage further research on Turkish GEC, we release our datasets, baseline models, and the synthetic data generation pipeline at https://github.com/GGLAB-KU/gecturk.","meta":{"url":"http://arxiv.org/abs/2309.11346v1"},"cats":{"new-dataset":0.7151917679,"dev-research":0.141742981,"data-quality":0.1268114341}}
{"text":"Predictive algorithms are often trained by optimizing some loss function, to which regularization functions are added to impose a penalty for violating constraints.","meta":{"url":"http://arxiv.org/abs/2309.11343v1"},"cats":{"new-dataset":0.0054797939,"dev-research":0.1817768504,"data-quality":0.2021126159}}
{"text":"As expected, the addition of such regularization functions can change the minimizer of the objective.","meta":{"url":"http://arxiv.org/abs/2309.11343v1"},"cats":{"new-dataset":0.0029335784,"dev-research":0.1695697639,"data-quality":0.1850607574}}
{"text":"It is not well-understood which regularizers change the minimizer of the loss, and, when the minimizer does change, how it changes.","meta":{"url":"http://arxiv.org/abs/2309.11343v1"},"cats":{"new-dataset":0.0022734391,"dev-research":0.1874127351,"data-quality":0.2375187378}}
{"text":"We use property elicitation to take first steps towards understanding the joint relationship between the loss and regularization functions and the optimal decision for a given problem instance.","meta":{"url":"http://arxiv.org/abs/2309.11343v1"},"cats":{"new-dataset":0.011591982,"dev-research":0.2165373832,"data-quality":0.2037716354}}
{"text":"In particular, we give a necessary and sufficient condition on loss and regularizer pairs for when a property changes with the addition of the regularizer, and examine some regularizers satisfying this condition standard in the fair machine learning literature.","meta":{"url":"http://arxiv.org/abs/2309.11343v1"},"cats":{"new-dataset":0.0286718176,"dev-research":0.1606335652,"data-quality":0.3351151036}}
{"text":"We empirically demonstrate how algorithmic decision-making changes as a function of both data distribution changes and hardness of the constraints.","meta":{"url":"http://arxiv.org/abs/2309.11343v1"},"cats":{"new-dataset":0.0160686352,"dev-research":0.2908985328,"data-quality":0.2159164808}}
{"text":"Classifying research output into context-specific label taxonomies is a challenging and relevant downstream task, given the volume of existing and newly published articles.","meta":{"url":"http://arxiv.org/abs/2309.11341v1"},"cats":{"new-dataset":0.0767750605,"dev-research":0.1961814294,"data-quality":0.4627765426}}
{"text":"We propose a method to enhance the performance of article classification by enriching simple Graph Neural Networks (GNN) pipelines with edge-heterogeneous graph representations.","meta":{"url":"http://arxiv.org/abs/2309.11341v1"},"cats":{"new-dataset":0.0537846653,"dev-research":0.1754126617,"data-quality":0.2784398884}}
{"text":"SciBERT is used for node feature generation to capture higher-order semantics within the articles' textual metadata.","meta":{"url":"http://arxiv.org/abs/2309.11341v1"},"cats":{"new-dataset":0.1127858774,"dev-research":0.2994701947,"data-quality":0.2701029881}}
{"text":"Fully supervised transductive node classification experiments are conducted on the Open Graph Benchmark (OGB) ogbn-arxiv dataset and the PubMed diabetes dataset, augmented with additional metadata from Microsoft Academic Graph (MAG) and PubMed Central, respectively.","meta":{"url":"http://arxiv.org/abs/2309.11341v1"},"cats":{"new-dataset":0.1950212838,"dev-research":0.1616138457,"data-quality":0.2256436898}}
{"text":"The results demonstrate that edge-heterogeneous graphs consistently improve the performance of all GNN models compared to the edge-homogeneous graphs.","meta":{"url":"http://arxiv.org/abs/2309.11341v1"},"cats":{"new-dataset":0.0218777279,"dev-research":0.1478543508,"data-quality":0.1136691139}}
{"text":"The transformed data enable simple and shallow GNN pipelines to achieve results on par with more complex architectures.","meta":{"url":"http://arxiv.org/abs/2309.11341v1"},"cats":{"new-dataset":0.1130750757,"dev-research":0.1421055377,"data-quality":0.1132643665}}
{"text":"On ogbn-arxiv, we achieve a top-15 result in the OGB competition with a 2-layer GCN (accuracy 74.61%), being the highest-scoring solution with sub-1 million parameters.","meta":{"url":"http://arxiv.org/abs/2309.11341v1"},"cats":{"new-dataset":0.1444959878,"dev-research":0.1305137673,"data-quality":0.1422340462}}
{"text":"On PubMed, we closely trail SOTA GNN architectures using a 2-layer GraphSAGE by including additional co-authorship edges in the graph (accuracy 89.88%).","meta":{"url":"http://arxiv.org/abs/2309.11341v1"},"cats":{"new-dataset":0.2640824719,"dev-research":0.1961286107,"data-quality":0.154356007}}
{"text":"The implementation is available at: $\\href{https://github.com/lyvykhang/edgehetero-nodeproppred}{\\text{https://github.com/lyvykhang/edgehetero-nodeproppred}}$.","meta":{"url":"http://arxiv.org/abs/2309.11341v1"},"cats":{"new-dataset":0.0248283401,"dev-research":0.1594669272,"data-quality":0.1138714922}}
{"text":"In today's globalized world, effective communication with people from diverse linguistic backgrounds has become increasingly crucial.","meta":{"url":"http://arxiv.org/abs/2309.11338v1"},"cats":{"new-dataset":0.0523532035,"dev-research":0.2050896708,"data-quality":0.1712609279}}
{"text":"While traditional methods of language translation, such as written text or voice-only translations, can accomplish the task, they often fail to capture the complete context and nuanced information conveyed through nonverbal cues like facial expressions and lip movements.","meta":{"url":"http://arxiv.org/abs/2309.11338v1"},"cats":{"new-dataset":0.0226778652,"dev-research":0.2401812181,"data-quality":0.2431963339}}
{"text":"In this paper, we present an end-to-end video translation system that not only translates spoken language but also synchronizes the translated speech with the lip movements of the speaker.","meta":{"url":"http://arxiv.org/abs/2309.11338v1"},"cats":{"new-dataset":0.2558885401,"dev-research":0.1925754674,"data-quality":0.1304277784}}
{"text":"Our system focuses on translating educational lectures in various Indian languages, and it is designed to be effective even in low-resource system settings.","meta":{"url":"http://arxiv.org/abs/2309.11338v1"},"cats":{"new-dataset":0.0934624585,"dev-research":0.1695480105,"data-quality":0.1539374542}}
{"text":"By incorporating lip movements that align with the target language and matching them with the speaker's voice using voice cloning techniques, our application offers an enhanced experience for students and users.","meta":{"url":"http://arxiv.org/abs/2309.11338v1"},"cats":{"new-dataset":0.1352162487,"dev-research":0.2075791898,"data-quality":0.1375899272}}
{"text":"This additional feature creates a more immersive and realistic learning environment, ultimately making the learning process more effective and engaging.","meta":{"url":"http://arxiv.org/abs/2309.11338v1"},"cats":{"new-dataset":0.0293722928,"dev-research":0.2591333623,"data-quality":0.057425989}}
{"text":"In an anonymous shared memory system, all inter-process communications are via shared objects; however, unlike in standard systems, there is no a priori agreement between processes on the names of shared objects [14,15].","meta":{"url":"http://arxiv.org/abs/2309.11337v1"},"cats":{"new-dataset":0.0364365945,"dev-research":0.182365839,"data-quality":0.1783211025}}
{"text":"Furthermore, the algorithms are required to be symmetric; that is, the processes should execute precisely the same code, and the only way to distinguish processes is by comparing identifiers for equality.","meta":{"url":"http://arxiv.org/abs/2309.11337v1"},"cats":{"new-dataset":0.0026852372,"dev-research":0.1766840263,"data-quality":0.1298221504}}
{"text":"For such a system, read/write registers are called anonymous registers.","meta":{"url":"http://arxiv.org/abs/2309.11337v1"},"cats":{"new-dataset":0.083807791,"dev-research":0.2205246897,"data-quality":0.1303142248}}
{"text":"It is known that symmetric deadlock-free mutual exclusion is solvable for any finite number of processes using anonymous registers [1].","meta":{"url":"http://arxiv.org/abs/2309.11337v1"},"cats":{"new-dataset":0.0756179903,"dev-research":0.1294462411,"data-quality":0.1243246914}}
{"text":"The main question left open in [14,15] is the existence of starvation-free mutual exclusion algorithms for two or more processes.","meta":{"url":"http://arxiv.org/abs/2309.11337v1"},"cats":{"new-dataset":0.0694405905,"dev-research":0.0966766703,"data-quality":0.0762841144}}
{"text":"We resolve this open question for memoryless algorithms, in which a process that tries to enter its critical section does not use any information about its previous attempts.","meta":{"url":"http://arxiv.org/abs/2309.11337v1"},"cats":{"new-dataset":0.0198496473,"dev-research":0.1451245964,"data-quality":0.1502318006}}
{"text":"Almost all known mutual exclusion algorithms are memoryless.","meta":{"url":"http://arxiv.org/abs/2309.11337v1"},"cats":{"new-dataset":0.0523044671,"dev-research":0.1318602383,"data-quality":0.1271102552}}
{"text":"We show that (1) there is a symmetric memoryless starvation-free mutual exclusion algorithm for two processes using $m \\geq 7$ anonymous registers if and only if $m$ is odd; and (2) there is no symmetric memoryless starvation-free mutual exclusion algorithm for $n\\geq 3$ processes using (any number of) anonymous registers.","meta":{"url":"http://arxiv.org/abs/2309.11337v1"},"cats":{"new-dataset":0.1076492417,"dev-research":0.114444239,"data-quality":0.1298067904}}
{"text":"Our impossibility result is the only example of a system with fault-free processes, where global progress (i.e., deadlock-freedom) can be ensured, while individual progress to each process (i.e., starvation-freedom) cannot.","meta":{"url":"http://arxiv.org/abs/2309.11337v1"},"cats":{"new-dataset":0.0355803929,"dev-research":0.1846423616,"data-quality":0.1023494802}}
{"text":"It complements a known result for systems with failure-prone processes, that there are objects with lock-free implementations but without wait-free implementations [2,5].","meta":{"url":"http://arxiv.org/abs/2309.11337v1"},"cats":{"new-dataset":0.0219720561,"dev-research":0.2520633182,"data-quality":0.1157512033}}
{"text":"Camera localization in 3D LiDAR maps has gained increasing attention due to its promising ability to handle complex scenarios, surpassing the limitations of visual-only localization methods.","meta":{"url":"http://arxiv.org/abs/2309.11335v1"},"cats":{"new-dataset":0.0362795016,"dev-research":0.2175093987,"data-quality":0.1567065914}}
{"text":"However, existing methods mostly focus on addressing the cross-modal gaps, estimating camera poses frame by frame without considering the relationship between adjacent frames, which makes the pose tracking unstable.","meta":{"url":"http://arxiv.org/abs/2309.11335v1"},"cats":{"new-dataset":0.1669348772,"dev-research":0.1863759289,"data-quality":0.1671214807}}
{"text":"To alleviate this, we propose to couple the 2D-3D correspondences between adjacent frames using the 2D-2D feature matching, establishing the multi-view geometrical constraints for simultaneously estimating multiple camera poses.","meta":{"url":"http://arxiv.org/abs/2309.11335v1"},"cats":{"new-dataset":0.306158315,"dev-research":0.1741885008,"data-quality":0.0854007113}}
{"text":"Specifically, we propose a new 2D-3D pose tracking framework, which consists: a front-end hybrid flow estimation network for consecutive frames and a back-end pose optimization module.","meta":{"url":"http://arxiv.org/abs/2309.11335v1"},"cats":{"new-dataset":0.3367601027,"dev-research":0.1966071007,"data-quality":0.0551124039}}
{"text":"We further design a cross-modal consistency-based loss to incorporate the multi-view constraints during the training and inference process.","meta":{"url":"http://arxiv.org/abs/2309.11335v1"},"cats":{"new-dataset":0.0377234126,"dev-research":0.1771129333,"data-quality":0.2923839665}}
{"text":"We evaluate our proposed framework on the KITTI and Argoverse datasets.","meta":{"url":"http://arxiv.org/abs/2309.11335v1"},"cats":{"new-dataset":0.7910019465,"dev-research":0.1323359016,"data-quality":0.1360635454}}
{"text":"Experimental results demonstrate its superior performance compared to existing frame-by-frame 2D-3D pose tracking methods and state-of-the-art vision-only pose tracking algorithms.","meta":{"url":"http://arxiv.org/abs/2309.11335v1"},"cats":{"new-dataset":0.080551646,"dev-research":0.1902516905,"data-quality":0.078990204}}
{"text":"More online pose tracking videos are available at \\url{https://youtu.be/yfBRdg7gw5M}","meta":{"url":"http://arxiv.org/abs/2309.11335v1"},"cats":{"new-dataset":0.196847656,"dev-research":0.1509557002,"data-quality":0.0814584566}}
{"text":"Ensembles of independently trained deep neural networks yield uncertainty estimates that rival Bayesian networks in performance.","meta":{"url":"http://arxiv.org/abs/2309.11333v1"},"cats":{"new-dataset":0.0315653351,"dev-research":0.2497521651,"data-quality":0.2382893881}}
{"text":"They also offer sizable improvements in terms of predictive performance over single models.","meta":{"url":"http://arxiv.org/abs/2309.11333v1"},"cats":{"new-dataset":0.0036222649,"dev-research":0.2084505848,"data-quality":0.1008347502}}
{"text":"However, deep ensembles are not commonly used in environments with limited computational budget -- such as autonomous driving -- since the complexity grows linearly with the number of ensemble members.","meta":{"url":"http://arxiv.org/abs/2309.11333v1"},"cats":{"new-dataset":0.0378408895,"dev-research":0.2090558048,"data-quality":0.0695929977}}
{"text":"An important observation that can be made for robotics applications, such as autonomous driving, is that data is typically sequential.","meta":{"url":"http://arxiv.org/abs/2309.11333v1"},"cats":{"new-dataset":0.0966653031,"dev-research":0.2228649547,"data-quality":0.0701514115}}
{"text":"For instance, when an object is to be recognized, an autonomous vehicle typically observes a sequence of images, rather than a single image.","meta":{"url":"http://arxiv.org/abs/2309.11333v1"},"cats":{"new-dataset":0.0280949252,"dev-research":0.1787199143,"data-quality":0.1359398561}}
{"text":"This raises the question, could the deep ensemble be spread over time?   ","meta":{"url":"http://arxiv.org/abs/2309.11333v1"},"cats":{"new-dataset":0.040849818,"dev-research":0.154936422,"data-quality":0.0976325566}}
{"text":"In this work, we propose and analyze Deep Ensembles Spread Over Time (DESOT).","meta":{"url":"http://arxiv.org/abs/2309.11333v1"},"cats":{"new-dataset":0.4051292527,"dev-research":0.1733136992,"data-quality":0.1008653066}}
{"text":"The idea is to apply only a single ensemble member to each data point in the sequence, and fuse the predictions over a sequence of data points.","meta":{"url":"http://arxiv.org/abs/2309.11333v1"},"cats":{"new-dataset":0.1152597608,"dev-research":0.1457652977,"data-quality":0.1226260143}}
{"text":"We implement and experiment with DESOT for traffic sign classification, where sequences of tracked image patches are to be classified.","meta":{"url":"http://arxiv.org/abs/2309.11333v1"},"cats":{"new-dataset":0.3011211525,"dev-research":0.1970108641,"data-quality":0.2270438471}}
{"text":"We find that DESOT obtains the benefits of deep ensembles, in terms of predictive and uncertainty estimation performance, while avoiding the added computational cost.","meta":{"url":"http://arxiv.org/abs/2309.11333v1"},"cats":{"new-dataset":0.0716175736,"dev-research":0.2163481169,"data-quality":0.1226467652}}
{"text":"Moreover, DESOT is simple to implement and does not require sequences during training.","meta":{"url":"http://arxiv.org/abs/2309.11333v1"},"cats":{"new-dataset":0.0187687647,"dev-research":0.2218772393,"data-quality":0.0734574219}}
{"text":"Finally, we find that DESOT, like deep ensembles, outperform single models for out-of-distribution detection.","meta":{"url":"http://arxiv.org/abs/2309.11333v1"},"cats":{"new-dataset":0.1220418047,"dev-research":0.1369944704,"data-quality":0.2982546541}}
{"text":"Compartmentalization is a form of defensive software design in which an application is broken down into isolated but communicating components.","meta":{"url":"http://arxiv.org/abs/2309.11332v1"},"cats":{"new-dataset":0.0157890813,"dev-research":0.3074773276,"data-quality":0.1450076685}}
{"text":"Retrofitting compartmentalization into existing applications is often thought to be expensive from the engineering effort and performance overhead points of view.","meta":{"url":"http://arxiv.org/abs/2309.11332v1"},"cats":{"new-dataset":0.0030354054,"dev-research":0.2772556628,"data-quality":0.0843575159}}
{"text":"Still, recent years have seen proposals of compartmentalization methods with promises of low engineering efforts and reduced performance impact.","meta":{"url":"http://arxiv.org/abs/2309.11332v1"},"cats":{"new-dataset":0.0028412801,"dev-research":0.2514460436,"data-quality":0.1131826487}}
{"text":"ARM Morello combines a modern ARM processor with an implementation of Capability Hardware Enhanced RISC Instructions (CHERI) aiming to provide efficient and secure compartmentalization.","meta":{"url":"http://arxiv.org/abs/2309.11332v1"},"cats":{"new-dataset":0.0592880276,"dev-research":0.2109850874,"data-quality":0.0514962726}}
{"text":"Past works exploring CHERI-based compartmentalization were restricted to emulated/FPGA prototypes.   ","meta":{"url":"http://arxiv.org/abs/2309.11332v1"},"cats":{"new-dataset":0.0181088558,"dev-research":0.1735501443,"data-quality":0.0587833219}}
{"text":"In this paper, we explore possible compartmentalization schemes with CHERI on the Morello chip.","meta":{"url":"http://arxiv.org/abs/2309.11332v1"},"cats":{"new-dataset":0.0273319121,"dev-research":0.1304755218,"data-quality":0.077365224}}
{"text":"We propose two approaches representing different trade-offs in terms of engineering effort, security, scalability, and performance impact.","meta":{"url":"http://arxiv.org/abs/2309.11332v1"},"cats":{"new-dataset":0.0089138624,"dev-research":0.3427187581,"data-quality":0.0567409102}}
{"text":"We describe and implement these approaches on a prototype OS running bare metal on the Morello chip, compartmentalize two popular applications, and investigate the performance overheads.","meta":{"url":"http://arxiv.org/abs/2309.11332v1"},"cats":{"new-dataset":0.0315592518,"dev-research":0.2393882785,"data-quality":0.0510806164}}
{"text":"Furthermore, we show that compartmentalization can be achieved with an engineering cost that can be quite low if one is willing to trade off on scalability and security, and that performance overheads are similar to other intra-address space isolation mechanisms.","meta":{"url":"http://arxiv.org/abs/2309.11332v1"},"cats":{"new-dataset":0.0094409607,"dev-research":0.1697789181,"data-quality":0.0847759986}}
{"text":"In the past years, YOLO-series models have emerged as the leading approaches in the area of real-time object detection.","meta":{"url":"http://arxiv.org/abs/2309.11331v1"},"cats":{"new-dataset":0.0906293803,"dev-research":0.1355203385,"data-quality":0.1050651291}}
{"text":"Many studies pushed up the baseline to a higher level by modifying the architecture, augmenting data and designing new losses.","meta":{"url":"http://arxiv.org/abs/2309.11331v1"},"cats":{"new-dataset":0.0165891553,"dev-research":0.3015716712,"data-quality":0.0704817121}}
{"text":"However, we find previous models still suffer from information fusion problem, although Feature Pyramid Network (FPN) and Path Aggregation Network (PANet) have alleviated this.","meta":{"url":"http://arxiv.org/abs/2309.11331v1"},"cats":{"new-dataset":0.0154614571,"dev-research":0.1740374204,"data-quality":0.1726522647}}
{"text":"Therefore, this study provides an advanced Gatherand-Distribute mechanism (GD) mechanism, which is realized with convolution and self-attention operations.","meta":{"url":"http://arxiv.org/abs/2309.11331v1"},"cats":{"new-dataset":0.0246723146,"dev-research":0.1518839802,"data-quality":0.0533290549}}
{"text":"This new designed model named as Gold-YOLO, which boosts the multi-scale feature fusion capabilities and achieves an ideal balance between latency and accuracy across all model scales.","meta":{"url":"http://arxiv.org/abs/2309.11331v1"},"cats":{"new-dataset":0.0315273851,"dev-research":0.1663738184,"data-quality":0.1077557246}}
{"text":"Additionally, we implement MAE-style pretraining in the YOLO-series for the first time, allowing YOLOseries models could be to benefit from unsupervised pretraining.","meta":{"url":"http://arxiv.org/abs/2309.11331v1"},"cats":{"new-dataset":0.0389772839,"dev-research":0.1558140073,"data-quality":0.0872532186}}
{"text":"Gold-YOLO-N attains an outstanding 39.9% AP on the COCO val2017 datasets and 1030 FPS on a T4 GPU, which outperforms the previous SOTA model YOLOv6-3.0-N with similar FPS by +2.4%.","meta":{"url":"http://arxiv.org/abs/2309.11331v1"},"cats":{"new-dataset":0.2313388317,"dev-research":0.1403883958,"data-quality":0.1267652869}}
{"text":"The PyTorch code is available at https://github.com/huaweinoah/Efficient-Computing/Detection/Gold-YOLO, and the MindSpore code is available at https://gitee.com/mindspore/models/tree/master/research/cv/Gold_YOLO.","meta":{"url":"http://arxiv.org/abs/2309.11331v1"},"cats":{"new-dataset":0.1430388791,"dev-research":0.1472957829,"data-quality":0.1727922014}}
{"text":"Camera calibration is a first and fundamental step in various computer vision applications.","meta":{"url":"http://arxiv.org/abs/2309.11326v1"},"cats":{"new-dataset":0.0467326143,"dev-research":0.2063195232,"data-quality":0.158703177}}
{"text":"Despite being an active field of research, Zhang's method remains widely used for camera calibration due to its implementation in popular toolboxes.","meta":{"url":"http://arxiv.org/abs/2309.11326v1"},"cats":{"new-dataset":0.0927294926,"dev-research":0.215857513,"data-quality":0.137082427}}
{"text":"However, this method initially assumes a pinhole model with oversimplified distortion models.","meta":{"url":"http://arxiv.org/abs/2309.11326v1"},"cats":{"new-dataset":0.003272552,"dev-research":0.1428119695,"data-quality":0.1972216986}}
{"text":"In this work, we propose a novel approach that involves a pre-processing step to remove distortions from images by means of Gaussian processes.","meta":{"url":"http://arxiv.org/abs/2309.11326v1"},"cats":{"new-dataset":0.0343639689,"dev-research":0.1432439417,"data-quality":0.2075014346}}
{"text":"Our method does not need to assume any distortion model and can be applied to severely warped images, even in the case of multiple distortion sources, e.g., a fisheye image of a curved mirror reflection.","meta":{"url":"http://arxiv.org/abs/2309.11326v1"},"cats":{"new-dataset":0.0075649568,"dev-research":0.1211084021,"data-quality":0.1745251448}}
{"text":"The Gaussian processes capture all distortions and camera imperfections, resulting in virtual images as though taken by an ideal pinhole camera with square pixels.","meta":{"url":"http://arxiv.org/abs/2309.11326v1"},"cats":{"new-dataset":0.0352771486,"dev-research":0.1643289709,"data-quality":0.1368223055}}
{"text":"Furthermore, this ideal GP-camera only needs one image of a square grid calibration pattern.","meta":{"url":"http://arxiv.org/abs/2309.11326v1"},"cats":{"new-dataset":0.0735738996,"dev-research":0.1056497149,"data-quality":0.06174111}}
{"text":"This model allows for a serious upgrade of many algorithms and applications that are designed in a pure projective geometry setting but with a performance that is very sensitive to nonlinear lens distortions.","meta":{"url":"http://arxiv.org/abs/2309.11326v1"},"cats":{"new-dataset":0.0188553281,"dev-research":0.1202498041,"data-quality":0.067313493}}
{"text":"We demonstrate the effectiveness of our method by simplifying Zhang's calibration method, reducing the number of parameters and getting rid of the distortion parameters and iterative optimization.","meta":{"url":"http://arxiv.org/abs/2309.11326v1"},"cats":{"new-dataset":0.0570815758,"dev-research":0.1463768437,"data-quality":0.2280469107}}
{"text":"We validate by means of synthetic data and real world images.","meta":{"url":"http://arxiv.org/abs/2309.11326v1"},"cats":{"new-dataset":0.2477833645,"dev-research":0.1960931968,"data-quality":0.2107814475}}
{"text":"The contributions of this work include the construction of a virtual ideal pinhole camera using Gaussian processes, a simplified calibration method and lens distortion removal.","meta":{"url":"http://arxiv.org/abs/2309.11326v1"},"cats":{"new-dataset":0.0599220922,"dev-research":0.162778999,"data-quality":0.1022459649}}
{"text":"We propose DISC-LawLLM, an intelligent legal system utilizing large language models (LLMs) to provide a wide range of legal services.","meta":{"url":"http://arxiv.org/abs/2309.11325v1"},"cats":{"new-dataset":0.4791620612,"dev-research":0.1816670119,"data-quality":0.1777070939}}
{"text":"We adopt legal syllogism prompting strategies to construct supervised fine-tuning datasets in the Chinese Judicial domain and fine-tune LLMs with legal reasoning capability.","meta":{"url":"http://arxiv.org/abs/2309.11325v1"},"cats":{"new-dataset":0.451220197,"dev-research":0.2404138725,"data-quality":0.2891825406}}
{"text":"We augment LLMs with a retrieval module to enhance models' ability to access and utilize external legal knowledge.","meta":{"url":"http://arxiv.org/abs/2309.11325v1"},"cats":{"new-dataset":0.1998191769,"dev-research":0.1485485027,"data-quality":0.1080071827}}
{"text":"A comprehensive legal benchmark, DISC-Law-Eval, is presented to evaluate intelligent legal systems from both objective and subjective dimensions.","meta":{"url":"http://arxiv.org/abs/2309.11325v1"},"cats":{"new-dataset":0.1252126162,"dev-research":0.2521049391,"data-quality":0.1558002199}}
{"text":"Quantitative and qualitative results on DISC-Law-Eval demonstrate the effectiveness of our system in serving various users across diverse legal scenarios.","meta":{"url":"http://arxiv.org/abs/2309.11325v1"},"cats":{"new-dataset":0.1001931324,"dev-research":0.3159193264,"data-quality":0.1530686619}}
{"text":"The detailed resources are available at https://github.com/FudanDISC/DISC-LawLLM.","meta":{"url":"http://arxiv.org/abs/2309.11325v1"},"cats":{"new-dataset":0.3526525482,"dev-research":0.1535571029,"data-quality":0.1465257484}}
{"text":"Vector database management systems have emerged as an important component in modern data management, driven by the growing importance for the need to computationally describe rich data such as texts, images and video in various domains such as recommender systems, similarity search, and chatbots.","meta":{"url":"http://arxiv.org/abs/2309.11322v1"},"cats":{"new-dataset":0.345219044,"dev-research":0.2368682586,"data-quality":0.129840437}}
{"text":"These data descriptions are captured as numerical vectors that are computationally inexpensive to store and compare.","meta":{"url":"http://arxiv.org/abs/2309.11322v1"},"cats":{"new-dataset":0.1897345541,"dev-research":0.2344562054,"data-quality":0.1625248416}}
{"text":"However, the unique characteristics of vectorized data, including high dimensionality and sparsity, demand specialized solutions for efficient storage, retrieval, and processing.","meta":{"url":"http://arxiv.org/abs/2309.11322v1"},"cats":{"new-dataset":0.0567935171,"dev-research":0.1509376236,"data-quality":0.0808784636}}
{"text":"This study provides an accessible introduction to the fundamental concepts, use-cases, and current challenges associated with vector database management systems, offering an overview for researchers and practitioners seeking to explore this burgeoning technology aimed to facilitate effective vector data management.","meta":{"url":"http://arxiv.org/abs/2309.11322v1"},"cats":{"new-dataset":0.1301777357,"dev-research":0.3038817045,"data-quality":0.1372942028}}
{"text":"In this paper, we address the problem of face aging: generating past or future facial images by incorporating age-related changes to the given face.","meta":{"url":"http://arxiv.org/abs/2309.11321v1"},"cats":{"new-dataset":0.1295006719,"dev-research":0.2499624203,"data-quality":0.1211336134}}
{"text":"Previous aging methods rely solely on human facial image datasets and are thus constrained by their inherent scale and bias.","meta":{"url":"http://arxiv.org/abs/2309.11321v1"},"cats":{"new-dataset":0.0206749989,"dev-research":0.1797510096,"data-quality":0.1275315693}}
{"text":"This restricts their application to a limited generatable age range and the inability to handle large age gaps.","meta":{"url":"http://arxiv.org/abs/2309.11321v1"},"cats":{"new-dataset":0.0138916488,"dev-research":0.2213876123,"data-quality":0.1129890868}}
{"text":"We propose FADING, a novel approach to address Face Aging via DIffusion-based editiNG.","meta":{"url":"http://arxiv.org/abs/2309.11321v1"},"cats":{"new-dataset":0.0187421589,"dev-research":0.2773631764,"data-quality":0.1089481329}}
{"text":"We go beyond existing methods by leveraging the rich prior of large-scale language-image diffusion models.","meta":{"url":"http://arxiv.org/abs/2309.11321v1"},"cats":{"new-dataset":0.09273258,"dev-research":0.1214847632,"data-quality":0.2579016237}}
{"text":"First, we specialize a pre-trained diffusion model for the task of face age editing by using an age-aware fine-tuning scheme.","meta":{"url":"http://arxiv.org/abs/2309.11321v1"},"cats":{"new-dataset":0.038855669,"dev-research":0.2667387448,"data-quality":0.1122890364}}
{"text":"Next, we invert the input image to latent noise and obtain optimized null text embeddings.","meta":{"url":"http://arxiv.org/abs/2309.11321v1"},"cats":{"new-dataset":0.201043491,"dev-research":0.1402299896,"data-quality":0.4359865283}}
{"text":"Finally, we perform text-guided local age editing via attention control.","meta":{"url":"http://arxiv.org/abs/2309.11321v1"},"cats":{"new-dataset":0.1146261973,"dev-research":0.3045511432,"data-quality":0.1812616563}}
{"text":"The quantitative and qualitative analyses demonstrate that our method outperforms existing approaches with respect to aging accuracy, attribute preservation, and aging quality.","meta":{"url":"http://arxiv.org/abs/2309.11321v1"},"cats":{"new-dataset":0.0297090126,"dev-research":0.3310459566,"data-quality":0.1995883111}}
{"text":"Recent CNN and Transformer-based models tried to utilize frequency and periodicity information for long-term time series forecasting.","meta":{"url":"http://arxiv.org/abs/2309.11319v1"},"cats":{"new-dataset":0.0326085802,"dev-research":0.1159609178,"data-quality":0.0660166707}}
{"text":"However, most existing work is based on Fourier transform, which cannot capture fine-grained and local frequency structure.","meta":{"url":"http://arxiv.org/abs/2309.11319v1"},"cats":{"new-dataset":0.0096557841,"dev-research":0.1509702006,"data-quality":0.1596368553}}
{"text":"In this paper, we propose a Wavelet-Fourier Transform Network (WFTNet) for long-term time series forecasting.","meta":{"url":"http://arxiv.org/abs/2309.11319v1"},"cats":{"new-dataset":0.0356857775,"dev-research":0.1475895292,"data-quality":0.0527846093}}
{"text":"WFTNet utilizes both Fourier and wavelet transforms to extract comprehensive temporal-frequency information from the signal, where Fourier transform captures the global periodic patterns and wavelet transform captures the local ones.","meta":{"url":"http://arxiv.org/abs/2309.11319v1"},"cats":{"new-dataset":0.0311276787,"dev-research":0.1942997468,"data-quality":0.1041195862}}
{"text":"Furthermore, we introduce a Periodicity-Weighted Coefficient (PWC) to adaptively balance the importance of global and local frequency patterns.","meta":{"url":"http://arxiv.org/abs/2309.11319v1"},"cats":{"new-dataset":0.0154697585,"dev-research":0.1361183064,"data-quality":0.1274707938}}
{"text":"Extensive experiments on various time series datasets show that WFTNet consistently outperforms other state-of-the-art baseline.","meta":{"url":"http://arxiv.org/abs/2309.11319v1"},"cats":{"new-dataset":0.0434576404,"dev-research":0.1735141958,"data-quality":0.1428674056}}
{"text":"Model initialization techniques are vital for improving the performance and reliability of deep learning models in medical computer vision applications.","meta":{"url":"http://arxiv.org/abs/2309.11318v1"},"cats":{"new-dataset":0.0451224608,"dev-research":0.2180343106,"data-quality":0.1680030136}}
{"text":"While much literature exists on non-medical images, the impacts on medical images, particularly chest X-rays (CXRs) are less understood.","meta":{"url":"http://arxiv.org/abs/2309.11318v1"},"cats":{"new-dataset":0.0260211098,"dev-research":0.1826446936,"data-quality":0.1391055264}}
{"text":"Addressing this gap, our study explores three deep model initialization techniques: Cold-start, Warm-start, and Shrink and Perturb start, focusing on adult and pediatric populations.","meta":{"url":"http://arxiv.org/abs/2309.11318v1"},"cats":{"new-dataset":0.0732779027,"dev-research":0.1718690557,"data-quality":0.0837225755}}
{"text":"We specifically focus on scenarios with periodically arriving data for training, thereby embracing the real-world scenarios of ongoing data influx and the need for model updates.","meta":{"url":"http://arxiv.org/abs/2309.11318v1"},"cats":{"new-dataset":0.2872145955,"dev-research":0.2740225562,"data-quality":0.1120823364}}
{"text":"We evaluate these models for generalizability against external adult and pediatric CXR datasets.","meta":{"url":"http://arxiv.org/abs/2309.11318v1"},"cats":{"new-dataset":0.1214644964,"dev-research":0.1343457349,"data-quality":0.0945956285}}
{"text":"We also propose novel ensemble methods: F-score-weighted Sequential Least-Squares Quadratic Programming (F-SLSQP) and Attention-Guided Ensembles with Learnable Fuzzy Softmax to aggregate weight parameters from multiple models to capitalize on their collective knowledge and complementary representations.","meta":{"url":"http://arxiv.org/abs/2309.11318v1"},"cats":{"new-dataset":0.0848161555,"dev-research":0.1950109606,"data-quality":0.1312709352}}
{"text":"We perform statistical significance tests with 95% confidence intervals and p-values to analyze model performance.","meta":{"url":"http://arxiv.org/abs/2309.11318v1"},"cats":{"new-dataset":0.024035335,"dev-research":0.255633571,"data-quality":0.0965736876}}
{"text":"Our evaluations indicate models initialized with ImageNet-pre-trained weights demonstrate superior generalizability over randomly initialized counterparts, contradicting some findings for non-medical images.","meta":{"url":"http://arxiv.org/abs/2309.11318v1"},"cats":{"new-dataset":0.0271345096,"dev-research":0.1338316212,"data-quality":0.1870988285}}
{"text":"Notably, ImageNet-pretrained models exhibit consistent performance during internal and external testing across different training scenarios.","meta":{"url":"http://arxiv.org/abs/2309.11318v1"},"cats":{"new-dataset":0.0244580195,"dev-research":0.2086649405,"data-quality":0.1794649368}}
{"text":"Weight-level ensembles of these models show significantly higher recall (p<0.05) during testing compared to individual models.","meta":{"url":"http://arxiv.org/abs/2309.11318v1"},"cats":{"new-dataset":0.0223493385,"dev-research":0.1991136459,"data-quality":0.1971657735}}
{"text":"Thus, our study accentuates the benefits of ImageNet-pretrained weight initialization, especially when used with weight-level ensembles, for creating robust and generalizable deep learning solutions.","meta":{"url":"http://arxiv.org/abs/2309.11318v1"},"cats":{"new-dataset":0.0636113538,"dev-research":0.1750806618,"data-quality":0.1831079379}}
{"text":"The competitive nature of Cloud marketplaces as new concerns in delivery of services makes the pricing policies a crucial task for firms.","meta":{"url":"http://arxiv.org/abs/2309.11316v1"},"cats":{"new-dataset":0.0292031661,"dev-research":0.1954741002,"data-quality":0.0676963493}}
{"text":"so that, pricing strategies has recently attracted many researchers.","meta":{"url":"http://arxiv.org/abs/2309.11316v1"},"cats":{"new-dataset":0.0170652241,"dev-research":0.1743359814,"data-quality":0.0538439005}}
{"text":"Since game theory can handle such competing well this concern is addressed by designing a normal form game between providers in current research.","meta":{"url":"http://arxiv.org/abs/2309.11316v1"},"cats":{"new-dataset":0.0211894002,"dev-research":0.2063546568,"data-quality":0.0439277337}}
{"text":"A committee is considered in which providers register for improving their competition based pricing policies.","meta":{"url":"http://arxiv.org/abs/2309.11316v1"},"cats":{"new-dataset":0.0910959291,"dev-research":0.2111341118,"data-quality":0.1612293343}}
{"text":"The functionality of game theory is applied to design dynamic pricing policies.","meta":{"url":"http://arxiv.org/abs/2309.11316v1"},"cats":{"new-dataset":0.017530587,"dev-research":0.2021756919,"data-quality":0.0478472244}}
{"text":"The usage of the committee makes the game a complete information one, in which each player is aware of every others payoff functions.","meta":{"url":"http://arxiv.org/abs/2309.11316v1"},"cats":{"new-dataset":0.1129480644,"dev-research":0.2530328536,"data-quality":0.1027479469}}
{"text":"The players enhance their pricing policies to maximize their profits.","meta":{"url":"http://arxiv.org/abs/2309.11316v1"},"cats":{"new-dataset":0.046480275,"dev-research":0.2714025654,"data-quality":0.062738529}}
{"text":"The contribution of this paper is the quantitative modeling of Cloud marketplaces in form of a game to provide novel dynamic pricing strategies; the model is validated by proving the existence and the uniqueness of Nash equilibrium of the game.","meta":{"url":"http://arxiv.org/abs/2309.11316v1"},"cats":{"new-dataset":0.1018158725,"dev-research":0.1428293866,"data-quality":0.0525963369}}
{"text":"Smart contracts are programs that are executed on the blockchain and can hold, manage and transfer assets in the form of cryptocurrencies.","meta":{"url":"http://arxiv.org/abs/2309.11317v1"},"cats":{"new-dataset":0.113155914,"dev-research":0.2489445283,"data-quality":0.0604207549}}
{"text":"The contract's execution is then performed on-chain and is subject to consensus, i.e. every node on the blockchain network has to run the function calls and keep track of their side-effects.","meta":{"url":"http://arxiv.org/abs/2309.11317v1"},"cats":{"new-dataset":0.0197803595,"dev-research":0.3620733615,"data-quality":0.1304923285}}
{"text":"In most programmable blockchains, such as Ethereum, the notion of gas is introduced to prevent DoS attacks by malicious parties who might try to slow down the network by performing heavy computations.","meta":{"url":"http://arxiv.org/abs/2309.11317v1"},"cats":{"new-dataset":0.0214986503,"dev-research":0.2616301872,"data-quality":0.0936333405}}
{"text":"A fixed cost to each atomic operation, and the initiator of a function call pays the total gas cost as a transaction fee.","meta":{"url":"http://arxiv.org/abs/2309.11317v1"},"cats":{"new-dataset":0.0243630294,"dev-research":0.2392259832,"data-quality":0.1061977923}}
{"text":"This helps prevent DoS attacks, but the resulting fees are extremely high.","meta":{"url":"http://arxiv.org/abs/2309.11317v1"},"cats":{"new-dataset":0.008222969,"dev-research":0.2221654959,"data-quality":0.0902074984}}
{"text":"For example, in 2022, on Ethereum alone, there has been a total gas usage of 1.77 Million ETH ~ 4.3 Billion USD.","meta":{"url":"http://arxiv.org/abs/2309.11317v1"},"cats":{"new-dataset":0.1848142441,"dev-research":0.2192507657,"data-quality":0.0972598346}}
{"text":"This thesis proposes \"lazy contracts\" as a solution to alleviate these costs.","meta":{"url":"http://arxiv.org/abs/2309.11317v1"},"cats":{"new-dataset":0.0625687021,"dev-research":0.2794300014,"data-quality":0.0933240171}}
{"text":"Our solution moves most of the computation off-chain, ensuring that each function call incurs only a tiny amount of gas usage, while preserving enough data on-chain to guarantee an implicit consensus about the state of the contract variables and ownership of funds.","meta":{"url":"http://arxiv.org/abs/2309.11317v1"},"cats":{"new-dataset":0.1508183652,"dev-research":0.1538951045,"data-quality":0.1142944508}}
{"text":"A complete on-chain execution of the functions will only be triggered in case two parties to the contract are in disagreement about the current state, which in turn can only happen if at least one party is dishonest.","meta":{"url":"http://arxiv.org/abs/2309.11317v1"},"cats":{"new-dataset":0.0093379066,"dev-research":0.2103319297,"data-quality":0.1496440798}}
{"text":"In such cases, our protocol can identify the dishonest party and penalize them by having them pay for the entire gas usage.","meta":{"url":"http://arxiv.org/abs/2309.11317v1"},"cats":{"new-dataset":0.0146401715,"dev-research":0.2256369201,"data-quality":0.2021801711}}
{"text":"Hence, no rational party has an incentive to act dishonestly.","meta":{"url":"http://arxiv.org/abs/2309.11317v1"},"cats":{"new-dataset":0.0088786292,"dev-research":0.1671873709,"data-quality":0.1551706859}}
{"text":"Finally, we perform extensive experiments over 160,735 real-world Solidity contracts that were involved in 9,055,492 transactions in January 2022--January 2023 on Ethereum and show that our approach reduces the overall gas usage by 55.4%, which amounts to an astounding saving of 109.9 Million USD in gas fees.","meta":{"url":"http://arxiv.org/abs/2309.11317v1"},"cats":{"new-dataset":0.2108744826,"dev-research":0.3186851595,"data-quality":0.0761594481}}
{"text":"Cloud computing as a fairly new commercial paradigm, widely investigated by different researchers, already has a great range of challenges.","meta":{"url":"http://arxiv.org/abs/2309.11312v1"},"cats":{"new-dataset":0.0371999501,"dev-research":0.2377556738,"data-quality":0.0686374293}}
{"text":"Pricing is a major problem in Cloud computing marketplace; as providers are competing to attract more customers without knowing the pricing policies of each other.","meta":{"url":"http://arxiv.org/abs/2309.11312v1"},"cats":{"new-dataset":0.0240466398,"dev-research":0.2241157916,"data-quality":0.098440788}}
{"text":"To overcome this lack of knowledge, we model their competition by an incomplete-information game.","meta":{"url":"http://arxiv.org/abs/2309.11312v1"},"cats":{"new-dataset":0.0772090303,"dev-research":0.1694998923,"data-quality":0.1673422622}}
{"text":"Considering the issue, this work proposes a pricing policy related to the regret minimization algorithm and applies it to the considered incomplete-information game.","meta":{"url":"http://arxiv.org/abs/2309.11312v1"},"cats":{"new-dataset":0.0198790417,"dev-research":0.1814775559,"data-quality":0.1454602163}}
{"text":"Based on the competition based marketplace of the Cloud, providers update the distribution of their strategies using the experienced regret.","meta":{"url":"http://arxiv.org/abs/2309.11312v1"},"cats":{"new-dataset":0.0272192429,"dev-research":0.2118602291,"data-quality":0.0671738759}}
{"text":"The idea of iteratively applying the algorithm for updating probabilities of strategies causes the regret get minimized faster.","meta":{"url":"http://arxiv.org/abs/2309.11312v1"},"cats":{"new-dataset":0.0036913231,"dev-research":0.2369546316,"data-quality":0.067137016}}
{"text":"The experimental results show much more increase in profits of the providers in comparison with other pricing policies.","meta":{"url":"http://arxiv.org/abs/2309.11312v1"},"cats":{"new-dataset":0.0240868618,"dev-research":0.1616422306,"data-quality":0.1038093938}}
{"text":"Besides, the efficiency of a variety of regret minimization techniques in a simulated marketplace of Cloud are discussed which have not been observed in the studied literature.","meta":{"url":"http://arxiv.org/abs/2309.11312v1"},"cats":{"new-dataset":0.0136476976,"dev-research":0.1644876703,"data-quality":0.0649189429}}
{"text":"Moreover, return on investment of providers in considered organizations is studied and promising results appeared.","meta":{"url":"http://arxiv.org/abs/2309.11312v1"},"cats":{"new-dataset":0.0087274431,"dev-research":0.1721892411,"data-quality":0.0639203386}}
{"text":"Predicting the success of Conversational Task Assistants (CTA) can be critical to understand user behavior and act accordingly.","meta":{"url":"http://arxiv.org/abs/2309.11307v1"},"cats":{"new-dataset":0.0422926836,"dev-research":0.2525105837,"data-quality":0.1377882519}}
{"text":"In this paper, we propose TB-Rater, a Transformer model which combines conversational-flow features with user behavior features for predicting user ratings in a CTA scenario.","meta":{"url":"http://arxiv.org/abs/2309.11307v1"},"cats":{"new-dataset":0.0858707778,"dev-research":0.2123120062,"data-quality":0.1200433464}}
{"text":"In particular, we use real human-agent conversations and ratings collected in the Alexa TaskBot challenge, a novel multimodal and multi-turn conversational context.","meta":{"url":"http://arxiv.org/abs/2309.11307v1"},"cats":{"new-dataset":0.3673424757,"dev-research":0.2225810407,"data-quality":0.0899431241}}
{"text":"Our results show the advantages of modeling both the conversational-flow and behavioral aspects of the conversation in a single model for offline rating prediction.","meta":{"url":"http://arxiv.org/abs/2309.11307v1"},"cats":{"new-dataset":0.0952546167,"dev-research":0.2029783054,"data-quality":0.1267687983}}
{"text":"Additionally, an analysis of the CTA-specific behavioral features brings insights into this setting and can be used to bootstrap future systems.","meta":{"url":"http://arxiv.org/abs/2309.11307v1"},"cats":{"new-dataset":0.0160678556,"dev-research":0.2226875721,"data-quality":0.1116615908}}
{"text":"Speech-driven 3D facial animation synthesis has been a challenging task both in industry and research.","meta":{"url":"http://arxiv.org/abs/2309.11306v1"},"cats":{"new-dataset":0.130869093,"dev-research":0.2143977027,"data-quality":0.0669382937}}
{"text":"Recent methods mostly focus on deterministic deep learning methods meaning that given a speech input, the output is always the same.","meta":{"url":"http://arxiv.org/abs/2309.11306v1"},"cats":{"new-dataset":0.0146260275,"dev-research":0.1965081361,"data-quality":0.2846844609}}
{"text":"However, in reality, the non-verbal facial cues that reside throughout the face are non-deterministic in nature.","meta":{"url":"http://arxiv.org/abs/2309.11306v1"},"cats":{"new-dataset":0.0201901331,"dev-research":0.2033613613,"data-quality":0.110282912}}
{"text":"In addition, majority of the approaches focus on 3D vertex based datasets and methods that are compatible with existing facial animation pipelines with rigged characters is scarce.","meta":{"url":"http://arxiv.org/abs/2309.11306v1"},"cats":{"new-dataset":0.1772476386,"dev-research":0.1758807513,"data-quality":0.0693575858}}
{"text":"To eliminate these issues, we present FaceDiffuser, a non-deterministic deep learning model to generate speech-driven facial animations that is trained with both 3D vertex and blendshape based datasets.","meta":{"url":"http://arxiv.org/abs/2309.11306v1"},"cats":{"new-dataset":0.5129873296,"dev-research":0.1974693587,"data-quality":0.092838316}}
{"text":"Our method is based on the diffusion technique and uses the pre-trained large speech representation model HuBERT to encode the audio input.","meta":{"url":"http://arxiv.org/abs/2309.11306v1"},"cats":{"new-dataset":0.0784593546,"dev-research":0.1238729945,"data-quality":0.1360679901}}
{"text":"To the best of our knowledge, we are the first to employ the diffusion method for the task of speech-driven 3D facial animation synthesis.","meta":{"url":"http://arxiv.org/abs/2309.11306v1"},"cats":{"new-dataset":0.0444356599,"dev-research":0.1718180408,"data-quality":0.0561946913}}
{"text":"We have run extensive objective and subjective analyses and show that our approach achieves better or comparable results in comparison to the state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2309.11306v1"},"cats":{"new-dataset":0.0188889605,"dev-research":0.2789324118,"data-quality":0.1355798965}}
{"text":"We also introduce a new in-house dataset that is based on a blendshape based rigged character.","meta":{"url":"http://arxiv.org/abs/2309.11306v1"},"cats":{"new-dataset":0.8379154903,"dev-research":0.1683474114,"data-quality":0.1106437015}}
{"text":"We recommend watching the accompanying supplementary video.","meta":{"url":"http://arxiv.org/abs/2309.11306v1"},"cats":{"new-dataset":0.2149475049,"dev-research":0.2130102896,"data-quality":0.0801271565}}
{"text":"The code and the dataset will be publicly available.","meta":{"url":"http://arxiv.org/abs/2309.11306v1"},"cats":{"new-dataset":0.9330706026,"dev-research":0.1571755792,"data-quality":0.1063915901}}
{"text":"Catastrophic forgetting remains a critical challenge in the field of continual learning, where neural networks struggle to retain prior knowledge while assimilating new information.","meta":{"url":"http://arxiv.org/abs/2309.11305v1"},"cats":{"new-dataset":0.0362379301,"dev-research":0.1988548695,"data-quality":0.2194405102}}
{"text":"Most existing studies emphasize mitigating this issue only when encountering new tasks, overlooking the significance of the pre-task phase.","meta":{"url":"http://arxiv.org/abs/2309.11305v1"},"cats":{"new-dataset":0.0038560639,"dev-research":0.3518362468,"data-quality":0.1120675241}}
{"text":"Therefore, we shift the attention to the current task learning stage, presenting a novel framework, C&F (Create and Find Flatness), which builds a flat training space for each task in advance.","meta":{"url":"http://arxiv.org/abs/2309.11305v1"},"cats":{"new-dataset":0.1124860494,"dev-research":0.196952656,"data-quality":0.1269426113}}
{"text":"Specifically, during the learning of the current task, our framework adaptively creates a flat region around the minimum in the loss landscape.","meta":{"url":"http://arxiv.org/abs/2309.11305v1"},"cats":{"new-dataset":0.0221963129,"dev-research":0.2212862681,"data-quality":0.1003546761}}
{"text":"Subsequently, it finds the parameters' importance to the current task based on their flatness degrees.","meta":{"url":"http://arxiv.org/abs/2309.11305v1"},"cats":{"new-dataset":0.0081741787,"dev-research":0.1392306542,"data-quality":0.0704711067}}
{"text":"When adapting the model to a new task, constraints are applied according to the flatness and a flat space is simultaneously prepared for the impending task.","meta":{"url":"http://arxiv.org/abs/2309.11305v1"},"cats":{"new-dataset":0.0128493083,"dev-research":0.2209017408,"data-quality":0.0659657204}}
{"text":"We theoretically demonstrate the consistency between the created and found flatness.","meta":{"url":"http://arxiv.org/abs/2309.11305v1"},"cats":{"new-dataset":0.0526615195,"dev-research":0.1590738432,"data-quality":0.2059413089}}
{"text":"In this manner, our framework not only accommodates ample parameter space for learning new tasks but also preserves the preceding knowledge of earlier tasks.","meta":{"url":"http://arxiv.org/abs/2309.11305v1"},"cats":{"new-dataset":0.0404420068,"dev-research":0.2020152266,"data-quality":0.1002564183}}
{"text":"Experimental results exhibit C&F's state-of-the-art performance as a standalone continual learning approach and its efficacy as a framework incorporating other methods.","meta":{"url":"http://arxiv.org/abs/2309.11305v1"},"cats":{"new-dataset":0.0249990497,"dev-research":0.2162241481,"data-quality":0.1290687846}}
{"text":"Our work is available at https://github.com/Eric8932/Create-and-Find-Flatness.","meta":{"url":"http://arxiv.org/abs/2309.11305v1"},"cats":{"new-dataset":0.175836272,"dev-research":0.133122426,"data-quality":0.1375528322}}
{"text":"This paper aims to understand the impacts of various data combinations (e.g., web text, wikipedia, github, books) on the training of large language models using SlimPajama.","meta":{"url":"http://arxiv.org/abs/2309.10818v1"},"cats":{"new-dataset":0.1973205609,"dev-research":0.1473637185,"data-quality":0.2109746467}}
{"text":"SlimPajama is a rigorously deduplicated, multi-source dataset, which has been refined and further deduplicated to 627B tokens from the extensive 1.2T tokens RedPajama dataset contributed by Together.","meta":{"url":"http://arxiv.org/abs/2309.10818v1"},"cats":{"new-dataset":0.5938663109,"dev-research":0.1844467471,"data-quality":0.1461173372}}
{"text":"We've termed our research as SlimPajama-DC, an empirical analysis designed to uncover fundamental characteristics and best practices associated with employing SlimPajama in the training of large language models.","meta":{"url":"http://arxiv.org/abs/2309.10818v1"},"cats":{"new-dataset":0.118658729,"dev-research":0.1913095016,"data-quality":0.2443041902}}
{"text":"During our research with SlimPajama, two pivotal observations emerged: (1) Global deduplication vs. local deduplication.","meta":{"url":"http://arxiv.org/abs/2309.10818v1"},"cats":{"new-dataset":0.2114369969,"dev-research":0.2035221081,"data-quality":0.1354251497}}
{"text":"We analyze and discuss how global (across different sources of datasets) and local (within the single source of dataset) deduplications affect the performance of trained models.","meta":{"url":"http://arxiv.org/abs/2309.10818v1"},"cats":{"new-dataset":0.3467287403,"dev-research":0.2337776742,"data-quality":0.2874175107}}
{"text":"(2) Proportions of high-quality/highly-deduplicated multi-source datasets in the combination.","meta":{"url":"http://arxiv.org/abs/2309.10818v1"},"cats":{"new-dataset":0.6535059102,"dev-research":0.1679451521,"data-quality":0.1905997096}}
{"text":"To study this, we construct six configurations of SlimPajama dataset and train individual ones using 1.3B Cerebras-GPT model with Alibi and SwiGLU.","meta":{"url":"http://arxiv.org/abs/2309.10818v1"},"cats":{"new-dataset":0.4982097598,"dev-research":0.092439022,"data-quality":0.1112593554}}
{"text":"Our best configuration outperforms the 1.3B model trained on RedPajama using the same number of training tokens by a significant margin.","meta":{"url":"http://arxiv.org/abs/2309.10818v1"},"cats":{"new-dataset":0.0984787667,"dev-research":0.148105887,"data-quality":0.2277484617}}
{"text":"All our 1.3B models are trained on Cerebras 16$\\times$ CS-2 cluster with a total of 80 PFLOP/s in bf16 mixed precision.","meta":{"url":"http://arxiv.org/abs/2309.10818v1"},"cats":{"new-dataset":0.1332944449,"dev-research":0.1012060321,"data-quality":0.1649239293}}
{"text":"We further extend our discoveries (such as increasing data diversity is crucial after global deduplication) on a 7B model with large batch-size training.","meta":{"url":"http://arxiv.org/abs/2309.10818v1"},"cats":{"new-dataset":0.4081099491,"dev-research":0.112742984,"data-quality":0.1611372609}}
{"text":"Our models and the separate SlimPajama-DC datasets are available at: https://huggingface.co/MBZUAI-LLM and https://huggingface.co/datasets/cerebras/SlimPajama-627B.","meta":{"url":"http://arxiv.org/abs/2309.10818v1"},"cats":{"new-dataset":0.7830946584,"dev-research":0.0831310553,"data-quality":0.0697279002}}
{"text":"Holographic displays promise several benefits including high quality 3D imagery, accurate accommodation cues, and compact form-factors.","meta":{"url":"http://arxiv.org/abs/2309.10816v1"},"cats":{"new-dataset":0.0283861184,"dev-research":0.1952914891,"data-quality":0.0558361897}}
{"text":"However, holography relies on coherent illumination which can create undesirable speckle noise in the final image.","meta":{"url":"http://arxiv.org/abs/2309.10816v1"},"cats":{"new-dataset":0.0240123466,"dev-research":0.2104670233,"data-quality":0.1253993834}}
{"text":"Although smooth phase holograms can be speckle-free, their non-uniform eyebox makes them impractical, and speckle mitigation with partially coherent sources also reduces resolution.","meta":{"url":"http://arxiv.org/abs/2309.10816v1"},"cats":{"new-dataset":0.0192881191,"dev-research":0.1990679885,"data-quality":0.0815844288}}
{"text":"Averaging sequential frames for speckle reduction requires high speed modulators and consumes temporal bandwidth that may be needed elsewhere in the system.   ","meta":{"url":"http://arxiv.org/abs/2309.10816v1"},"cats":{"new-dataset":0.0282297914,"dev-research":0.1849224168,"data-quality":0.0537954622}}
{"text":"In this work, we propose multisource holography, a novel architecture that uses an array of sources to suppress speckle in a single frame without sacrificing resolution.","meta":{"url":"http://arxiv.org/abs/2309.10816v1"},"cats":{"new-dataset":0.0965395656,"dev-research":0.1691264755,"data-quality":0.0680550326}}
{"text":"By using two spatial light modulators, arranged sequentially, each source in the array can be controlled almost independently to create a version of the target content with different speckle.","meta":{"url":"http://arxiv.org/abs/2309.10816v1"},"cats":{"new-dataset":0.0523245441,"dev-research":0.1704704986,"data-quality":0.0622998123}}
{"text":"Speckle is then suppressed when the contributions from the multiple sources are averaged at the image plane.","meta":{"url":"http://arxiv.org/abs/2309.10816v1"},"cats":{"new-dataset":0.0242578211,"dev-research":0.1641011471,"data-quality":0.1382802672}}
{"text":"We introduce an algorithm to calculate multisource holograms, analyze the design space, and demonstrate up to a 10 dB increase in peak signal-to-noise ratio compared to an equivalent single source system.","meta":{"url":"http://arxiv.org/abs/2309.10816v1"},"cats":{"new-dataset":0.0581198779,"dev-research":0.1440449378,"data-quality":0.0917697927}}
{"text":"Finally, we validate the concept with a benchtop experimental prototype by producing both 2D images and focal stacks with natural defocus cues.","meta":{"url":"http://arxiv.org/abs/2309.10816v1"},"cats":{"new-dataset":0.114007466,"dev-research":0.1310594306,"data-quality":0.0733101803}}
{"text":"Training perception systems for self-driving cars requires substantial annotations.","meta":{"url":"http://arxiv.org/abs/2309.10815v1"},"cats":{"new-dataset":0.1199080514,"dev-research":0.23555166,"data-quality":0.3709523911}}
{"text":"However, manual labeling in 2D images is highly labor-intensive.","meta":{"url":"http://arxiv.org/abs/2309.10815v1"},"cats":{"new-dataset":0.0395525177,"dev-research":0.2087756158,"data-quality":0.2495706808}}
{"text":"While existing datasets provide rich annotations for pre-recorded sequences, they fall short in labeling rarely encountered viewpoints, potentially hampering the generalization ability for perception models.","meta":{"url":"http://arxiv.org/abs/2309.10815v1"},"cats":{"new-dataset":0.3824197407,"dev-research":0.2152416213,"data-quality":0.4350476327}}
{"text":"In this paper, we present PanopticNeRF-360, a novel approach that combines coarse 3D annotations with noisy 2D semantic cues to generate consistent panoptic labels and high-quality images from any viewpoint.","meta":{"url":"http://arxiv.org/abs/2309.10815v1"},"cats":{"new-dataset":0.4945165165,"dev-research":0.2334987844,"data-quality":0.3348822183}}
{"text":"Our key insight lies in exploiting the complementarity of 3D and 2D priors to mutually enhance geometry and semantics.","meta":{"url":"http://arxiv.org/abs/2309.10815v1"},"cats":{"new-dataset":0.0112354453,"dev-research":0.2111118225,"data-quality":0.1075919387}}
{"text":"Specifically, we propose to leverage noisy semantic and instance labels in both 3D and 2D spaces to guide geometry optimization.","meta":{"url":"http://arxiv.org/abs/2309.10815v1"},"cats":{"new-dataset":0.037816187,"dev-research":0.2556308387,"data-quality":0.3625984977}}
{"text":"Simultaneously, the improved geometry assists in filtering noise present in the 3D and 2D annotations by merging them in 3D space via a learned semantic field.","meta":{"url":"http://arxiv.org/abs/2309.10815v1"},"cats":{"new-dataset":0.2164980312,"dev-research":0.2478700884,"data-quality":0.3750084195}}
{"text":"To further enhance appearance, we combine MLP and hash grids to yield hybrid scene features, striking a balance between high-frequency appearance and predominantly contiguous semantics.","meta":{"url":"http://arxiv.org/abs/2309.10815v1"},"cats":{"new-dataset":0.3037986909,"dev-research":0.1687153117,"data-quality":0.1929169924}}
{"text":"Our experiments demonstrate PanopticNeRF-360's state-of-the-art performance over existing label transfer methods on the challenging urban scenes of the KITTI-360 dataset.","meta":{"url":"http://arxiv.org/abs/2309.10815v1"},"cats":{"new-dataset":0.7203563791,"dev-research":0.1286960397,"data-quality":0.3369562584}}
{"text":"Moreover, PanopticNeRF-360 enables omnidirectional rendering of high-fidelity, multi-view and spatiotemporally consistent appearance, semantic and instance labels.","meta":{"url":"http://arxiv.org/abs/2309.10815v1"},"cats":{"new-dataset":0.234595836,"dev-research":0.1751797379,"data-quality":0.1091884086}}
{"text":"We make our code and data available at https://github.com/fuxiao0719/PanopticNeRF","meta":{"url":"http://arxiv.org/abs/2309.10815v1"},"cats":{"new-dataset":0.654856705,"dev-research":0.187059861,"data-quality":0.0907931915}}
{"text":"How can we perform computations over natural language representations to solve tasks that require symbolic and numeric reasoning?","meta":{"url":"http://arxiv.org/abs/2309.10814v1"},"cats":{"new-dataset":0.0865309189,"dev-research":0.328869006,"data-quality":0.1554099055}}
{"text":"We propose natural language embedded programs (NLEP) as a unifying framework for addressing math/symbolic reasoning, natural language understanding, and instruction following tasks.","meta":{"url":"http://arxiv.org/abs/2309.10814v1"},"cats":{"new-dataset":0.1627709123,"dev-research":0.4445474682,"data-quality":0.1658746131}}
{"text":"Our approach prompts a language model to generate full Python programs that define functions over data structures which contain natural language representations of structured knowledge.","meta":{"url":"http://arxiv.org/abs/2309.10814v1"},"cats":{"new-dataset":0.456786661,"dev-research":0.3526007404,"data-quality":0.1479244094}}
{"text":"A Python interpreter then executes the generated code and prints the output.","meta":{"url":"http://arxiv.org/abs/2309.10814v1"},"cats":{"new-dataset":0.0787437094,"dev-research":0.3233720105,"data-quality":0.1464861691}}
{"text":"Despite using a task-general prompt, we find that this approach can improve upon strong baselines across a range of different tasks including math and symbolic reasoning, text classification, question answering, and instruction following.","meta":{"url":"http://arxiv.org/abs/2309.10814v1"},"cats":{"new-dataset":0.0297838835,"dev-research":0.3243581993,"data-quality":0.1499047282}}
{"text":"We further find the generated programs are often interpretable and enable post-hoc verification of the intermediate reasoning steps.","meta":{"url":"http://arxiv.org/abs/2309.10814v1"},"cats":{"new-dataset":0.058149003,"dev-research":0.3910828301,"data-quality":0.1215179752}}
{"text":"Interdisciplinarity has over the recent years have gained tremendous importance and has become one of the key ways of doing cutting edge research.","meta":{"url":"http://arxiv.org/abs/2309.10811v1"},"cats":{"new-dataset":0.0441999668,"dev-research":0.2411750823,"data-quality":0.0652659339}}
{"text":"In this paper we attempt to model the citation flow across three different fields -- Physics (PHY), Mathematics (MA) and Computer Science (CS).","meta":{"url":"http://arxiv.org/abs/2309.10811v1"},"cats":{"new-dataset":0.0204956083,"dev-research":0.1124713581,"data-quality":0.1212592723}}
{"text":"For instance, is there a specific pattern in which these fields cite one another?","meta":{"url":"http://arxiv.org/abs/2309.10811v1"},"cats":{"new-dataset":0.0498253779,"dev-research":0.1602796226,"data-quality":0.1668563334}}
{"text":"We carry out experiments on a dataset comprising more than 1.2 million articles taken from these three fields.","meta":{"url":"http://arxiv.org/abs/2309.10811v1"},"cats":{"new-dataset":0.7145793511,"dev-research":0.1039191021,"data-quality":0.1465051632}}
{"text":"We quantify the citation interactions among these three fields through temporal bucket signatures.","meta":{"url":"http://arxiv.org/abs/2309.10811v1"},"cats":{"new-dataset":0.1371035013,"dev-research":0.1141312591,"data-quality":0.1613114538}}
{"text":"We present numerical models based on variants of the recently proposed relay-linking framework to explain the citation dynamics across the three disciplines.","meta":{"url":"http://arxiv.org/abs/2309.10811v1"},"cats":{"new-dataset":0.0122859792,"dev-research":0.1260601937,"data-quality":0.1678270205}}
{"text":"These models make a modest attempt to unfold the underlying principles of how citation links could have been formed across the three fields over time.","meta":{"url":"http://arxiv.org/abs/2309.10811v1"},"cats":{"new-dataset":0.0099588147,"dev-research":0.1423103107,"data-quality":0.1413932319}}
{"text":"Exploiting pre-trained diffusion models for restoration has recently become a favored alternative to the traditional task-specific training approach.","meta":{"url":"http://arxiv.org/abs/2309.10810v1"},"cats":{"new-dataset":0.0146584427,"dev-research":0.1560779083,"data-quality":0.1410464824}}
{"text":"Previous works have achieved noteworthy success by limiting the solution space using explicit degradation models.","meta":{"url":"http://arxiv.org/abs/2309.10810v1"},"cats":{"new-dataset":0.0292349988,"dev-research":0.1958390611,"data-quality":0.1670778346}}
{"text":"However, these methods often fall short when faced with complex degradations as they generally cannot be precisely modeled.","meta":{"url":"http://arxiv.org/abs/2309.10810v1"},"cats":{"new-dataset":0.0042128108,"dev-research":0.2270503292,"data-quality":0.1840070707}}
{"text":"In this paper, we propose PGDiff by introducing partial guidance, a fresh perspective that is more adaptable to real-world degradations compared to existing works.","meta":{"url":"http://arxiv.org/abs/2309.10810v1"},"cats":{"new-dataset":0.1420940393,"dev-research":0.4000573835,"data-quality":0.1612521095}}
{"text":"Rather than specifically defining the degradation process, our approach models the desired properties, such as image structure and color statistics of high-quality images, and applies this guidance during the reverse diffusion process.","meta":{"url":"http://arxiv.org/abs/2309.10810v1"},"cats":{"new-dataset":0.094816825,"dev-research":0.1755390926,"data-quality":0.1430403133}}
{"text":"These properties are readily available and make no assumptions about the degradation process.","meta":{"url":"http://arxiv.org/abs/2309.10810v1"},"cats":{"new-dataset":0.0094154479,"dev-research":0.1455928736,"data-quality":0.1826422403}}
{"text":"When combined with a diffusion prior, this partial guidance can deliver appealing results across a range of restoration tasks.","meta":{"url":"http://arxiv.org/abs/2309.10810v1"},"cats":{"new-dataset":0.0073478044,"dev-research":0.1588918557,"data-quality":0.0903298574}}
{"text":"Additionally, PGDiff can be extended to handle composite tasks by consolidating multiple high-quality image properties, achieved by integrating the guidance from respective tasks.","meta":{"url":"http://arxiv.org/abs/2309.10810v1"},"cats":{"new-dataset":0.0709214912,"dev-research":0.2149017704,"data-quality":0.0632368084}}
{"text":"Experimental results demonstrate that our method not only outperforms existing diffusion-prior-based approaches but also competes favorably with task-specific models.","meta":{"url":"http://arxiv.org/abs/2309.10810v1"},"cats":{"new-dataset":0.0049719219,"dev-research":0.1388737535,"data-quality":0.0864766333}}
{"text":"We study semantic compression for text where meanings contained in the text are conveyed to a source decoder, e.g., for classification.","meta":{"url":"http://arxiv.org/abs/2309.10809v1"},"cats":{"new-dataset":0.0845230817,"dev-research":0.2373670429,"data-quality":0.4305918036}}
{"text":"The main motivator to move to such an approach of recovering the meaning without requiring exact reconstruction is the potential resource savings, both in storage and in conveying the information to another node.","meta":{"url":"http://arxiv.org/abs/2309.10809v1"},"cats":{"new-dataset":0.0075038154,"dev-research":0.2809516979,"data-quality":0.117497739}}
{"text":"Towards this end, we propose semantic quantization and compression approaches for text where we utilize sentence embeddings and the semantic distortion metric to preserve the meaning.","meta":{"url":"http://arxiv.org/abs/2309.10809v1"},"cats":{"new-dataset":0.0820748221,"dev-research":0.2339499439,"data-quality":0.3377694345}}
{"text":"Our results demonstrate that the proposed semantic approaches result in substantial (orders of magnitude) savings in the required number of bits for message representation at the expense of very modest accuracy loss compared to the semantic agnostic baseline.","meta":{"url":"http://arxiv.org/abs/2309.10809v1"},"cats":{"new-dataset":0.060769383,"dev-research":0.3175382305,"data-quality":0.2775983428}}
{"text":"We compare the results of proposed approaches and observe that resource savings enabled by semantic quantization can be further amplified by semantic clustering.","meta":{"url":"http://arxiv.org/abs/2309.10809v1"},"cats":{"new-dataset":0.0527998965,"dev-research":0.2411123205,"data-quality":0.207718053}}
{"text":"Importantly, we observe the generalizability of the proposed methodology which produces excellent results on many benchmark text classification datasets with a diverse array of contexts.","meta":{"url":"http://arxiv.org/abs/2309.10809v1"},"cats":{"new-dataset":0.1470441058,"dev-research":0.1426226893,"data-quality":0.3237332884}}
{"text":"Machine learning and deep learning methods have been widely explored in understanding the chaotic behavior of the atmosphere and furthering weather forecasting.","meta":{"url":"http://arxiv.org/abs/2309.10808v1"},"cats":{"new-dataset":0.1118550614,"dev-research":0.1868586061,"data-quality":0.1210679766}}
{"text":"There has been increasing interest from technology companies, government institutions, and meteorological agencies in building digital twins of the Earth.","meta":{"url":"http://arxiv.org/abs/2309.10808v1"},"cats":{"new-dataset":0.0617610449,"dev-research":0.217952806,"data-quality":0.0905835779}}
{"text":"Recent approaches using transformers, physics-informed machine learning, and graph neural networks have demonstrated state-of-the-art performance on relatively narrow spatiotemporal scales and specific tasks.","meta":{"url":"http://arxiv.org/abs/2309.10808v1"},"cats":{"new-dataset":0.0526191582,"dev-research":0.1217185221,"data-quality":0.0617439399}}
{"text":"With the recent success of generative artificial intelligence (AI) using pre-trained transformers for language modeling and vision with prompt engineering and fine-tuning, we are now moving towards generalizable AI.","meta":{"url":"http://arxiv.org/abs/2309.10808v1"},"cats":{"new-dataset":0.075879523,"dev-research":0.190333831,"data-quality":0.1010404648}}
{"text":"In particular, we are witnessing the rise of AI foundation models that can perform competitively on multiple domain-specific downstream tasks.","meta":{"url":"http://arxiv.org/abs/2309.10808v1"},"cats":{"new-dataset":0.0293190829,"dev-research":0.1585237431,"data-quality":0.0718682676}}
{"text":"Despite this progress, we are still in the nascent stages of a generalizable AI model for global Earth system models, regional climate models, and mesoscale weather models.","meta":{"url":"http://arxiv.org/abs/2309.10808v1"},"cats":{"new-dataset":0.1591622995,"dev-research":0.1698385489,"data-quality":0.0612057939}}
{"text":"Here, we review current state-of-the-art AI approaches, primarily from transformer and operator learning literature in the context of meteorology.","meta":{"url":"http://arxiv.org/abs/2309.10808v1"},"cats":{"new-dataset":0.1056691983,"dev-research":0.1561909273,"data-quality":0.0869767602}}
{"text":"We provide our perspective on criteria for success towards a family of foundation models for nowcasting and forecasting weather and climate predictions.","meta":{"url":"http://arxiv.org/abs/2309.10808v1"},"cats":{"new-dataset":0.1848462207,"dev-research":0.2160025503,"data-quality":0.0593951177}}
{"text":"We also discuss how such models can perform competitively on downstream tasks such as downscaling (super-resolution), identifying conditions conducive to the occurrence of wildfires, and predicting consequential meteorological phenomena across various spatiotemporal scales such as hurricanes and atmospheric rivers.","meta":{"url":"http://arxiv.org/abs/2309.10808v1"},"cats":{"new-dataset":0.0346787616,"dev-research":0.181842983,"data-quality":0.0519702259}}
{"text":"In particular, we examine current AI methodologies and contend they have matured enough to design and implement a weather foundation model.","meta":{"url":"http://arxiv.org/abs/2309.10808v1"},"cats":{"new-dataset":0.1154264135,"dev-research":0.2716661162,"data-quality":0.0626676481}}
{"text":"Subterranean burrowing is inherently difficult for robots because of the high forces experienced as well as the high amount of uncertainty in this domain.","meta":{"url":"http://arxiv.org/abs/2309.10802v1"},"cats":{"new-dataset":0.0103840798,"dev-research":0.2631104392,"data-quality":0.0900315239}}
{"text":"Because of the difficulty in modeling forces in granular media, we propose the use of a novel machine-learning control strategy to obtain optimal techniques for vertical self-burrowing.","meta":{"url":"http://arxiv.org/abs/2309.10802v1"},"cats":{"new-dataset":0.0280499837,"dev-research":0.1628283845,"data-quality":0.0669947559}}
{"text":"In this paper, we realize a snake-like bio-inspired robot that is equipped with an IMU and two triple-axis magnetometers.","meta":{"url":"http://arxiv.org/abs/2309.10802v1"},"cats":{"new-dataset":0.0641660908,"dev-research":0.1167202424,"data-quality":0.0600798}}
{"text":"Utilizing magnetic field strength as an analog for depth, a novel deep learning architecture was proposed based on sinusoidal and random data in order to obtain a more efficient strategy for vertical self-burrowing.","meta":{"url":"http://arxiv.org/abs/2309.10802v1"},"cats":{"new-dataset":0.0642110196,"dev-research":0.1224108669,"data-quality":0.0791377826}}
{"text":"This strategy was able to outperform many other standard burrowing techniques and was able to automatically reach targeted burrowing depths.","meta":{"url":"http://arxiv.org/abs/2309.10802v1"},"cats":{"new-dataset":0.0055077068,"dev-research":0.1987154919,"data-quality":0.0634340428}}
{"text":"We hope these results will serve as a proof of concept for how optimization can be used to unlock the secrets of navigating in the subterranean world more efficiently.","meta":{"url":"http://arxiv.org/abs/2309.10802v1"},"cats":{"new-dataset":0.0228924636,"dev-research":0.1599116104,"data-quality":0.0692623002}}
{"text":"We present a hierarchical tree-based motion planning strategy, HAS-RRT, guided by the workspace skeleton to solve motion planning problems in robotics and computational biology.","meta":{"url":"http://arxiv.org/abs/2309.10801v1"},"cats":{"new-dataset":0.1350140385,"dev-research":0.2174902315,"data-quality":0.0378852189}}
{"text":"Relying on the information about the connectivity of the workspace and the ranking of available paths in the workspace, the strategy prioritizes paths indicated by the workspace guidance to find a valid motion plan for the moving object efficiently.","meta":{"url":"http://arxiv.org/abs/2309.10801v1"},"cats":{"new-dataset":0.0252841883,"dev-research":0.266011838,"data-quality":0.0279972314}}
{"text":"In instances of suboptimal guidance, the strategy adapts its reliance on the guidance by hierarchically reverting to local exploration of the planning space.","meta":{"url":"http://arxiv.org/abs/2309.10801v1"},"cats":{"new-dataset":0.0118105518,"dev-research":0.2738486104,"data-quality":0.0369537426}}
{"text":"We offer an extensive comparative analysis against other tree-based planning strategies and demonstrate that HAS-RRT reliably and efficiently finds low-cost paths.","meta":{"url":"http://arxiv.org/abs/2309.10801v1"},"cats":{"new-dataset":0.0390289412,"dev-research":0.1880389754,"data-quality":0.0487365889}}
{"text":"In contrast to methods prone to inconsistent performance across different environments or reliance on specific parameters, HAS-RRT is robust to workspace variability.","meta":{"url":"http://arxiv.org/abs/2309.10801v1"},"cats":{"new-dataset":0.0062164533,"dev-research":0.2782994836,"data-quality":0.1059350276}}
{"text":"This paper considers a generalization of the Path Finding (PF) with refueling constraints referred to as the Refuelling Path Finding (RF-PF) problem.","meta":{"url":"http://arxiv.org/abs/2309.10796v1"},"cats":{"new-dataset":0.0380677462,"dev-research":0.1074570684,"data-quality":0.1120591073}}
{"text":"Just like PF, the RF-PF problem is defined over a graph, where vertices are gas stations with known fuel prices, and edge costs depend on the gas consumption between the corresponding vertices.","meta":{"url":"http://arxiv.org/abs/2309.10796v1"},"cats":{"new-dataset":0.0616813704,"dev-research":0.1398735784,"data-quality":0.1198064402}}
{"text":"RF-PF seeks a minimum-cost path from the start to the goal vertex for a robot with a limited gas tank and a limited number of refuelling stops.","meta":{"url":"http://arxiv.org/abs/2309.10796v1"},"cats":{"new-dataset":0.0300582404,"dev-research":0.1330502894,"data-quality":0.0516834062}}
{"text":"While RF-PF is polynomial-time solvable, it remains a challenge to quickly compute an optimal solution in practice since the robot needs to simultaneously determine the path, where to make the stops, and the amount to refuel at each stop.","meta":{"url":"http://arxiv.org/abs/2309.10796v1"},"cats":{"new-dataset":0.0301368994,"dev-research":0.119559435,"data-quality":0.0548043578}}
{"text":"This paper develops a heuristic search algorithm called Refuel A* (RF-A* ) that iteratively constructs partial solution paths from the start to the goal guided by a heuristic function while leveraging dominance rules for state pruning during planning.","meta":{"url":"http://arxiv.org/abs/2309.10796v1"},"cats":{"new-dataset":0.0381695885,"dev-research":0.2383776702,"data-quality":0.0450164339}}
{"text":"RF-A* is guaranteed to find an optimal solution and runs more than an order of magnitude faster than the existing state of the art (a polynomial time algorithm) when tested in large city maps with hundreds of gas stations.","meta":{"url":"http://arxiv.org/abs/2309.10796v1"},"cats":{"new-dataset":0.0126141152,"dev-research":0.154430572,"data-quality":0.0879502624}}
{"text":"Mobile manipulators have been used for inspection, maintenance and repair tasks over the years, but there are some key limitations.","meta":{"url":"http://arxiv.org/abs/2309.10794v1"},"cats":{"new-dataset":0.0150102389,"dev-research":0.2417266097,"data-quality":0.0404489046}}
{"text":"Stability concerns typically require mobile platforms to be large in order to handle far-reaching manipulators, or for the manipulators to have drastically reduced workspaces to fit onto smaller mobile platforms.","meta":{"url":"http://arxiv.org/abs/2309.10794v1"},"cats":{"new-dataset":0.0202622603,"dev-research":0.2829737908,"data-quality":0.0482137015}}
{"text":"Therefore we propose a combination of two widely-used robots, the Clearpath Jackal unmanned ground vehicle and the Kinova Gen3 six degree-of-freedom manipulator.","meta":{"url":"http://arxiv.org/abs/2309.10794v1"},"cats":{"new-dataset":0.1322643067,"dev-research":0.1543277286,"data-quality":0.0549633982}}
{"text":"The Jackal has a small footprint and works well in low-clearance indoor environments.","meta":{"url":"http://arxiv.org/abs/2309.10794v1"},"cats":{"new-dataset":0.0554222846,"dev-research":0.1905104461,"data-quality":0.0834621648}}
{"text":"Extensive testing of localization, navigation and mapping using LiDAR sensors makes the Jackal a well developed mobile platform suitable for mobile manipulation.","meta":{"url":"http://arxiv.org/abs/2309.10794v1"},"cats":{"new-dataset":0.0873680237,"dev-research":0.1989212681,"data-quality":0.0697255027}}
{"text":"The Gen3 has a long reach with reasonable power consumption for manipulation tasks.","meta":{"url":"http://arxiv.org/abs/2309.10794v1"},"cats":{"new-dataset":0.0274780483,"dev-research":0.2081649424,"data-quality":0.037486139}}
{"text":"A wrist camera for RGB-D sensing and a customizable end effector interface makes the Gen3 suitable for a myriad of manipulation tasks.","meta":{"url":"http://arxiv.org/abs/2309.10794v1"},"cats":{"new-dataset":0.2178382464,"dev-research":0.2051143117,"data-quality":0.0567817434}}
{"text":"Typically these features would result in an unstable platform, however with a few minor hardware and software modifications, we have produced a stable, high-performance mobile manipulation platform with significant mobility, reach, sensing, and maneuverability for indoor inspection tasks, without degradation of the component robots' individual capabilities.","meta":{"url":"http://arxiv.org/abs/2309.10794v1"},"cats":{"new-dataset":0.0465142598,"dev-research":0.2241029069,"data-quality":0.0573130789}}
{"text":"These assertions were investigated with hardware via semi-autonomous navigation to waypoints in a busy indoor environment, and high-precision self-alignment alongside planar structures for intervention tasks.","meta":{"url":"http://arxiv.org/abs/2309.10794v1"},"cats":{"new-dataset":0.0459968869,"dev-research":0.2457929605,"data-quality":0.0948726516}}
{"text":"Developing an agent capable of adapting to unseen environments remains a difficult challenge in imitation learning.","meta":{"url":"http://arxiv.org/abs/2309.10790v1"},"cats":{"new-dataset":0.0343044788,"dev-research":0.1769778072,"data-quality":0.0635356441}}
{"text":"In this work, we present Adaptive Return-conditioned Policy (ARP), an efficient framework designed to enhance the agent's generalization ability using natural language task descriptions and pre-trained multimodal encoders.","meta":{"url":"http://arxiv.org/abs/2309.10790v1"},"cats":{"new-dataset":0.1671741435,"dev-research":0.2104958071,"data-quality":0.1057951169}}
{"text":"Our key idea is to calculate a similarity between visual observations and natural language instructions in the pre-trained multimodal embedding space (such as CLIP) and use it as a reward signal.","meta":{"url":"http://arxiv.org/abs/2309.10790v1"},"cats":{"new-dataset":0.2621592943,"dev-research":0.2050382342,"data-quality":0.1462500364}}
{"text":"We then train a return-conditioned policy using expert demonstrations labeled with multimodal rewards.","meta":{"url":"http://arxiv.org/abs/2309.10790v1"},"cats":{"new-dataset":0.06279207,"dev-research":0.1934784865,"data-quality":0.0988681246}}
{"text":"Because the multimodal rewards provide adaptive signals at each timestep, our ARP effectively mitigates the goal misgeneralization.","meta":{"url":"http://arxiv.org/abs/2309.10790v1"},"cats":{"new-dataset":0.0098316724,"dev-research":0.2089794273,"data-quality":0.0716118509}}
{"text":"This results in superior generalization performances even when faced with unseen text instructions, compared to existing text-conditioned policies.","meta":{"url":"http://arxiv.org/abs/2309.10790v1"},"cats":{"new-dataset":0.0064685886,"dev-research":0.2140790778,"data-quality":0.1945370264}}
{"text":"To improve the quality of rewards, we also introduce a fine-tuning method for pre-trained multimodal encoders, further enhancing the performance.","meta":{"url":"http://arxiv.org/abs/2309.10790v1"},"cats":{"new-dataset":0.0897967759,"dev-research":0.194953819,"data-quality":0.1598865328}}
{"text":"Video demonstrations and source code are available on the project website: https://sites.google.com/view/2023arp.","meta":{"url":"http://arxiv.org/abs/2309.10790v1"},"cats":{"new-dataset":0.2201410433,"dev-research":0.2934728116,"data-quality":0.081301241}}
{"text":"Despite an exciting new wave of multimodal machine learning models, current approaches still struggle to interpret the complex contextual relationships between the different modalities present in videos.","meta":{"url":"http://arxiv.org/abs/2309.10783v1"},"cats":{"new-dataset":0.0960904708,"dev-research":0.1536719569,"data-quality":0.1439051511}}
{"text":"Going beyond existing methods that emphasize simple activities or objects, we propose a new model-agnostic approach for generating detailed textual descriptions that captures multimodal video information.","meta":{"url":"http://arxiv.org/abs/2309.10783v1"},"cats":{"new-dataset":0.1572958679,"dev-research":0.259436215,"data-quality":0.1716153403}}
{"text":"Our method leverages the extensive knowledge learnt by large language models, such as GPT-3.5 or Llama2, to reason about textual descriptions of the visual and aural modalities, obtained from BLIP-2, Whisper and ImageBind.","meta":{"url":"http://arxiv.org/abs/2309.10783v1"},"cats":{"new-dataset":0.2897566574,"dev-research":0.1969945844,"data-quality":0.1813520029}}
{"text":"Without needing additional finetuning of video-text models or datasets, we demonstrate that available LLMs have the ability to use these multimodal textual descriptions as proxies for ``sight'' or ``hearing'' and perform zero-shot multimodal classification of videos in-context.","meta":{"url":"http://arxiv.org/abs/2309.10783v1"},"cats":{"new-dataset":0.3236872413,"dev-research":0.1223961549,"data-quality":0.2046152376}}
{"text":"Our evaluations on popular action recognition benchmarks, such as UCF-101 or Kinetics, show these context-rich descriptions can be successfully used in video understanding tasks.","meta":{"url":"http://arxiv.org/abs/2309.10783v1"},"cats":{"new-dataset":0.2513063817,"dev-research":0.1687124093,"data-quality":0.1558512376}}
{"text":"This method points towards a promising new research direction in multimodal classification, demonstrating how an interplay between textual, visual and auditory machine learning models can enable more holistic video understanding.","meta":{"url":"http://arxiv.org/abs/2309.10783v1"},"cats":{"new-dataset":0.1423888411,"dev-research":0.1957001555,"data-quality":0.2673048687}}
{"text":"Complex DeFi services are usually constructed by composing a variety of simpler smart contracts.","meta":{"url":"http://arxiv.org/abs/2309.10781v1"},"cats":{"new-dataset":0.0554394381,"dev-research":0.2479251682,"data-quality":0.0623181652}}
{"text":"The permissionless nature of the blockchains where these smart contracts are executed makes DeFi services exposed to security risks, since adversaries can target any of the underlying contracts to economically damage the compound service.","meta":{"url":"http://arxiv.org/abs/2309.10781v1"},"cats":{"new-dataset":0.0526183617,"dev-research":0.2030323343,"data-quality":0.1099124484}}
{"text":"We introduce a new notion of secure composability of smart contracts, which ensures that adversaries cannot economically harm the compound contract by interfering with its dependencies.","meta":{"url":"http://arxiv.org/abs/2309.10781v1"},"cats":{"new-dataset":0.0437063465,"dev-research":0.2409987331,"data-quality":0.1347926789}}
{"text":"Missing diversity, equity, and inclusion elements in affective computing datasets directly affect the accuracy and fairness of emotion recognition algorithms across different groups.","meta":{"url":"http://arxiv.org/abs/2309.10780v1"},"cats":{"new-dataset":0.0972914792,"dev-research":0.2026647172,"data-quality":0.2560241527}}
{"text":"A literature review reveals how affective computing systems may work differently for different groups due to, for instance, mental health conditions impacting facial expressions and speech or age-related changes in facial appearance and health.","meta":{"url":"http://arxiv.org/abs/2309.10780v1"},"cats":{"new-dataset":0.0430496902,"dev-research":0.4111433996,"data-quality":0.1094987552}}
{"text":"Our work analyzes existing affective computing datasets and highlights a disconcerting lack of diversity in current affective computing datasets regarding race, sex/gender, age, and (mental) health representation.","meta":{"url":"http://arxiv.org/abs/2309.10780v1"},"cats":{"new-dataset":0.6686327586,"dev-research":0.2492492824,"data-quality":0.1452713923}}
{"text":"By emphasizing the need for more inclusive sampling strategies and standardized documentation of demographic factors in datasets, this paper provides recommendations and calls for greater attention to inclusivity and consideration of societal consequences in affective computing research to promote ethical and accurate outcomes in this emerging field.","meta":{"url":"http://arxiv.org/abs/2309.10780v1"},"cats":{"new-dataset":0.2355452612,"dev-research":0.2711422463,"data-quality":0.1637053408}}
{"text":"This article sheds light on legal implications and challenges surrounding emotion data processing within the EU's legal framework.","meta":{"url":"http://arxiv.org/abs/2309.10776v1"},"cats":{"new-dataset":0.2926682322,"dev-research":0.2527303539,"data-quality":0.1985530036}}
{"text":"Despite the sensitive nature of emotion data, the GDPR does not categorize it as special data, resulting in a lack of comprehensive protection.","meta":{"url":"http://arxiv.org/abs/2309.10776v1"},"cats":{"new-dataset":0.0411159042,"dev-research":0.1935637017,"data-quality":0.1772608587}}
{"text":"The article also discusses the nuances of different approaches to affective computing and their relevance to the processing of special data under the GDPR.","meta":{"url":"http://arxiv.org/abs/2309.10776v1"},"cats":{"new-dataset":0.1007395966,"dev-research":0.2767904498,"data-quality":0.1184759376}}
{"text":"Moreover, it points to potential tensions with data protection principles, such as fairness and accuracy.","meta":{"url":"http://arxiv.org/abs/2309.10776v1"},"cats":{"new-dataset":0.0217691717,"dev-research":0.1955385051,"data-quality":0.21799417}}
{"text":"Our article also highlights some of the consequences, including harm, that processing of emotion data may have for individuals concerned.","meta":{"url":"http://arxiv.org/abs/2309.10776v1"},"cats":{"new-dataset":0.1405001961,"dev-research":0.2796213637,"data-quality":0.1915563251}}
{"text":"Additionally, we discuss how the AI Act proposal intends to regulate affective computing.","meta":{"url":"http://arxiv.org/abs/2309.10776v1"},"cats":{"new-dataset":0.1399207252,"dev-research":0.3186690431,"data-quality":0.0877504089}}
{"text":"Finally, the article outlines the new obligations and transparency requirements introduced by the DSA for online platforms utilizing emotion data.","meta":{"url":"http://arxiv.org/abs/2309.10776v1"},"cats":{"new-dataset":0.1625604204,"dev-research":0.2257179008,"data-quality":0.1387836969}}
{"text":"Our article aims at raising awareness among the affective computing community about the applicable legal requirements when developing AC systems intended for the EU market, or when working with study participants located in the EU.","meta":{"url":"http://arxiv.org/abs/2309.10776v1"},"cats":{"new-dataset":0.2450054992,"dev-research":0.4338785729,"data-quality":0.0980953654}}
{"text":"We also stress the importance of protecting the fundamental rights of individuals even when the law struggles to keep up with technological developments that capture sensitive emotion data.","meta":{"url":"http://arxiv.org/abs/2309.10776v1"},"cats":{"new-dataset":0.2442419072,"dev-research":0.2757158355,"data-quality":0.1151702923}}
{"text":"Many real-world datasets live on high-dimensional Stiefel and Grassmannian manifolds, $V_k(\\mathbb{R}^N)$ and $Gr(k, \\mathbb{R}^N)$ respectively, and benefit from projection onto lower-dimensional Stiefel (respectively, Grassmannian) manifolds.","meta":{"url":"http://arxiv.org/abs/2309.10775v1"},"cats":{"new-dataset":0.0887982913,"dev-research":0.1290147027,"data-quality":0.0964007805}}
{"text":"In this work, we propose an algorithm called Principal Stiefel Coordinates (PSC) to reduce data dimensionality from $ V_k(\\mathbb{R}^N)$ to $V_k(\\mathbb{R}^n)$ in an $O(k)$-equivariant manner ($k \\leq n \\ll N$).","meta":{"url":"http://arxiv.org/abs/2309.10775v1"},"cats":{"new-dataset":0.1728141379,"dev-research":0.1170332754,"data-quality":0.119642889}}
{"text":"We begin by observing that each element $\\alpha \\in V_n(\\mathbb{R}^N)$ defines an isometric embedding of $V_k(\\mathbb{R}^n)$ into $V_k(\\mathbb{R}^N)$. Next, we optimize for such an embedding map that minimizes data fit error by warm-starting with the output of principal component analysis (PCA) and applying gradient descent.","meta":{"url":"http://arxiv.org/abs/2309.10775v1"},"cats":{"new-dataset":0.064798134,"dev-research":0.168253595,"data-quality":0.1453604839}}
{"text":"Then, we define a continuous and $O(k)$-equivariant map $\\pi_\\alpha$ that acts as a ``closest point operator'' to project the data onto the image of $V_k(\\mathbb{R}^n)$ in $V_k(\\mathbb{R}^N)$ under the embedding determined by $\\alpha$, while minimizing distortion.","meta":{"url":"http://arxiv.org/abs/2309.10775v1"},"cats":{"new-dataset":0.0379938747,"dev-research":0.124209916,"data-quality":0.1658551357}}
{"text":"Because this dimensionality reduction is $O(k)$-equivariant, these results extend to Grassmannian manifolds as well.","meta":{"url":"http://arxiv.org/abs/2309.10775v1"},"cats":{"new-dataset":0.0726419107,"dev-research":0.125437231,"data-quality":0.1279319239}}
{"text":"Lastly, we show that the PCA output globally minimizes projection error in a noiseless setting, but that our algorithm achieves a meaningfully different and improved outcome when the data does not lie exactly on the image of a linearly embedded lower-dimensional Stiefel manifold as above.","meta":{"url":"http://arxiv.org/abs/2309.10775v1"},"cats":{"new-dataset":0.0555825715,"dev-research":0.1130482609,"data-quality":0.2094807369}}
{"text":"Multiple numerical experiments using synthetic and real-world data are performed.","meta":{"url":"http://arxiv.org/abs/2309.10775v1"},"cats":{"new-dataset":0.0855826308,"dev-research":0.1443230116,"data-quality":0.0992632121}}
{"text":"As a specific case of graph transfer learning, unsupervised domain adaptation on graphs aims for knowledge transfer from label-rich source graphs to unlabeled target graphs.","meta":{"url":"http://arxiv.org/abs/2309.10773v1"},"cats":{"new-dataset":0.1310160887,"dev-research":0.1850852853,"data-quality":0.3300305541}}
{"text":"However, graphs with topology and attributes usually have considerable cross-domain disparity and there are numerous real-world scenarios where merely a subset of nodes are labeled in the source graph.","meta":{"url":"http://arxiv.org/abs/2309.10773v1"},"cats":{"new-dataset":0.0219188905,"dev-research":0.230443498,"data-quality":0.2465475856}}
{"text":"This imposes critical challenges on graph transfer learning due to serious domain shifts and label scarcity.","meta":{"url":"http://arxiv.org/abs/2309.10773v1"},"cats":{"new-dataset":0.0591565216,"dev-research":0.161615285,"data-quality":0.4213138519}}
{"text":"To address these challenges, we propose a method named Semi-supervised Graph Domain Adaptation (SGDA).","meta":{"url":"http://arxiv.org/abs/2309.10773v1"},"cats":{"new-dataset":0.1254206037,"dev-research":0.1919041555,"data-quality":0.3253388739}}
{"text":"To deal with the domain shift, we add adaptive shift parameters to each of the source nodes, which are trained in an adversarial manner to align the cross-domain distributions of node embedding, thus the node classifier trained on labeled source nodes can be transferred to the target nodes.","meta":{"url":"http://arxiv.org/abs/2309.10773v1"},"cats":{"new-dataset":0.0433768401,"dev-research":0.1766244702,"data-quality":0.3753201442}}
{"text":"Moreover, to address the label scarcity, we propose pseudo-labeling on unlabeled nodes, which improves classification on the target graph via measuring the posterior influence of nodes based on their relative position to the class centroids.","meta":{"url":"http://arxiv.org/abs/2309.10773v1"},"cats":{"new-dataset":0.073971072,"dev-research":0.1779197744,"data-quality":0.5947758675}}
{"text":"Finally, extensive experiments on a range of publicly accessible datasets validate the effectiveness of our proposed SGDA in different experimental settings.","meta":{"url":"http://arxiv.org/abs/2309.10773v1"},"cats":{"new-dataset":0.2381741067,"dev-research":0.1334870412,"data-quality":0.1990594931}}
{"text":"Highly specific datasets of scientific literature are important for both research and education.","meta":{"url":"http://arxiv.org/abs/2309.10772v1"},"cats":{"new-dataset":0.4426653713,"dev-research":0.1325929558,"data-quality":0.1446456227}}
{"text":"However, it is difficult to build such datasets at scale.","meta":{"url":"http://arxiv.org/abs/2309.10772v1"},"cats":{"new-dataset":0.4900192452,"dev-research":0.1671588054,"data-quality":0.1420225755}}
{"text":"A common approach is to build these datasets reductively by applying topic modeling on an established corpus and selecting specific topics.","meta":{"url":"http://arxiv.org/abs/2309.10772v1"},"cats":{"new-dataset":0.4947225349,"dev-research":0.2335293339,"data-quality":0.2505243246}}
{"text":"A more robust but time-consuming approach is to build the dataset constructively in which a subject matter expert (SME) handpicks documents.","meta":{"url":"http://arxiv.org/abs/2309.10772v1"},"cats":{"new-dataset":0.6157162115,"dev-research":0.2707806195,"data-quality":0.1314013028}}
{"text":"This method does not scale and is prone to error as the dataset grows.","meta":{"url":"http://arxiv.org/abs/2309.10772v1"},"cats":{"new-dataset":0.0411197147,"dev-research":0.1707248369,"data-quality":0.2351595412}}
{"text":"Here we showcase a new tool, based on machine learning, for constructively generating targeted datasets of scientific literature.","meta":{"url":"http://arxiv.org/abs/2309.10772v1"},"cats":{"new-dataset":0.6231694846,"dev-research":0.2052315559,"data-quality":0.2313578347}}
{"text":"Given a small initial \"core\" corpus of papers, we build a citation network of documents.","meta":{"url":"http://arxiv.org/abs/2309.10772v1"},"cats":{"new-dataset":0.3254782948,"dev-research":0.1942607151,"data-quality":0.2190525513}}
{"text":"At each step of the citation network, we generate text embeddings and visualize the embeddings through dimensionality reduction.","meta":{"url":"http://arxiv.org/abs/2309.10772v1"},"cats":{"new-dataset":0.1640843793,"dev-research":0.1725970696,"data-quality":0.1906998739}}
{"text":"Papers are kept in the dataset if they are \"similar\" to the core or are otherwise pruned through human-in-the-loop selection.","meta":{"url":"http://arxiv.org/abs/2309.10772v1"},"cats":{"new-dataset":0.475743502,"dev-research":0.1562170055,"data-quality":0.1440589856}}
{"text":"Additional insight into the papers is gained through sub-topic modeling using SeNMFk.","meta":{"url":"http://arxiv.org/abs/2309.10772v1"},"cats":{"new-dataset":0.0837772051,"dev-research":0.1806499353,"data-quality":0.1589399408}}
{"text":"We demonstrate our new tool for literature review by applying it to two different fields in machine learning.","meta":{"url":"http://arxiv.org/abs/2309.10772v1"},"cats":{"new-dataset":0.0251805105,"dev-research":0.2448963101,"data-quality":0.2792983376}}
{"text":"Thematic analysis is a cornerstone of qualitative research, yet it is often marked by labor-intensive procedures.","meta":{"url":"http://arxiv.org/abs/2309.10771v1"},"cats":{"new-dataset":0.0281105011,"dev-research":0.3631303347,"data-quality":0.0728452676}}
{"text":"Recent advances in artificial intelligence (AI), especially with large-scale language models (LLMs) such as ChatGPT, present potential avenues to enhance qualitative data analysis.","meta":{"url":"http://arxiv.org/abs/2309.10771v1"},"cats":{"new-dataset":0.2386515365,"dev-research":0.2607764982,"data-quality":0.1233835385}}
{"text":"This research delves into the effectiveness of ChatGPT in refining the thematic analysis process.","meta":{"url":"http://arxiv.org/abs/2309.10771v1"},"cats":{"new-dataset":0.0797797579,"dev-research":0.3689468921,"data-quality":0.0887587804}}
{"text":"We conducted semi-structured interviews with 17 participants, inclusive of a 4-participant pilot study, to identify the challenges and reservations concerning the incorporation of ChatGPT in qualitative analysis.","meta":{"url":"http://arxiv.org/abs/2309.10771v1"},"cats":{"new-dataset":0.1268904485,"dev-research":0.357626713,"data-quality":0.0673492993}}
{"text":"In partnership with 13 qualitative analysts, we crafted cueing frameworks to bolster ChatGPT's contribution to thematic analysis.","meta":{"url":"http://arxiv.org/abs/2309.10771v1"},"cats":{"new-dataset":0.357783471,"dev-research":0.3947006817,"data-quality":0.0817510458}}
{"text":"The results indicate that these frameworks not only amplify the quality of thematic analysis but also bridge a significant connection between AI and qualitative research.","meta":{"url":"http://arxiv.org/abs/2309.10771v1"},"cats":{"new-dataset":0.0540655721,"dev-research":0.3476943397,"data-quality":0.1379931948}}
{"text":"These insights carry pivotal implications for academics and professionals keen on harnessing AI for qualitative data exploration.","meta":{"url":"http://arxiv.org/abs/2309.10771v1"},"cats":{"new-dataset":0.0816327435,"dev-research":0.3468252229,"data-quality":0.0912257062}}
{"text":"Natural language processing (NLP) applications such as named entity recognition (NER) for low-resource corpora do not benefit from recent advances in the development of large language models (LLMs) where there is still a need for larger annotated datasets.","meta":{"url":"http://arxiv.org/abs/2309.10770v1"},"cats":{"new-dataset":0.3370751621,"dev-research":0.1962699874,"data-quality":0.3465085398}}
{"text":"This research article introduces a methodology for generating translated versions of annotated datasets through crosslingual annotation projection.","meta":{"url":"http://arxiv.org/abs/2309.10770v1"},"cats":{"new-dataset":0.8860509931,"dev-research":0.3280233467,"data-quality":0.5330506766}}
{"text":"Leveraging a language agnostic BERT-based approach, it is an efficient solution to increase low-resource corpora with few human efforts and by only using already available open data resources.","meta":{"url":"http://arxiv.org/abs/2309.10770v1"},"cats":{"new-dataset":0.200038302,"dev-research":0.25991629,"data-quality":0.1709524844}}
{"text":"Quantitative and qualitative evaluations are often lacking when it comes to evaluating the quality and effectiveness of semi-automatic data generation strategies.","meta":{"url":"http://arxiv.org/abs/2309.10770v1"},"cats":{"new-dataset":0.1683566015,"dev-research":0.4057176288,"data-quality":0.1683720419}}
{"text":"The evaluation of our crosslingual annotation projection approach showed both effectiveness and high accuracy in the resulting dataset.","meta":{"url":"http://arxiv.org/abs/2309.10770v1"},"cats":{"new-dataset":0.5467033227,"dev-research":0.2161891677,"data-quality":0.5611896088}}
{"text":"As a practical application of this methodology, we present the creation of French Annotated Resource with Semantic Information for Medical Entities Detection (FRASIMED), an annotated corpus comprising 2'051 synthetic clinical cases in French.","meta":{"url":"http://arxiv.org/abs/2309.10770v1"},"cats":{"new-dataset":0.6593507038,"dev-research":0.2567060596,"data-quality":0.3984745192}}
{"text":"The corpus is now available for researchers and practitioners to develop and refine French natural language processing (NLP) applications in the clinical field (https://zenodo.org/record/8355629), making it the largest open annotated corpus with linked medical concepts in French.","meta":{"url":"http://arxiv.org/abs/2309.10770v1"},"cats":{"new-dataset":0.3978664873,"dev-research":0.2545332554,"data-quality":0.3005893887}}
{"text":"We study the combinatorial contracting problem of D\\\"utting et al.","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.2861234482,"dev-research":0.1808792925,"data-quality":0.1521815896}}
{"text":"[FOCS '21], in which a principal seeks to incentivize an agent to take a set of costly actions.","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.0711593844,"dev-research":0.2082083882,"data-quality":0.0595381869}}
{"text":"In their model, there is a binary outcome (the agent can succeed or fail), and the success probability and the costs depend on the set of actions taken.","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.0180344515,"dev-research":0.1923286601,"data-quality":0.0847576668}}
{"text":"The optimal contract is linear, paying the agent an $\\alpha$ fraction of the reward.","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.0232003433,"dev-research":0.1184453954,"data-quality":0.0866257201}}
{"text":"For gross substitutes (GS) rewards and additive costs, they give a poly-time algorithm for finding the optimal contract.","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.0225236268,"dev-research":0.1451526068,"data-quality":0.0653237}}
{"text":"They use the properties of GS functions to argue that there are poly-many \"critical values\" of $\\alpha$, and that one can iterate through all of them efficiently in order to find the optimal contract.   ","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.0439857692,"dev-research":0.1198376393,"data-quality":0.069239492}}
{"text":"In this work we study to which extent GS rewards and additive costs constitute a tractability frontier for combinatorial contracts.","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.0793010706,"dev-research":0.1569329298,"data-quality":0.0868940378}}
{"text":"We present an algorithm that for any rewards and costs, enumerates all critical values, with poly-many demand queries (in the number of critical values).","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.260632107,"dev-research":0.1175147301,"data-quality":0.0879956204}}
{"text":"This implies the tractability of the optimal contract for any setting with poly-many critical values and efficient demand oracle.","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.0250706616,"dev-research":0.1335567785,"data-quality":0.0691221742}}
{"text":"A direct corollary is a poly-time algorithm for the optimal contract in settings with supermodular rewards and submodular costs.","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.0315534848,"dev-research":0.2253561955,"data-quality":0.0480845357}}
{"text":"We also study a natural class of matching-based instances with XOS rewards and additive costs.","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.0380831557,"dev-research":0.1355996757,"data-quality":0.1223620526}}
{"text":"While the demand problem for this setting is tractable, we show that it admits an exponential number of critical values.","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.1643617727,"dev-research":0.1233660654,"data-quality":0.1213937846}}
{"text":"On the positive side, we present (pseudo-) polynomial-time algorithms for two natural special cases of this setting.","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.0174651323,"dev-research":0.1401732433,"data-quality":0.1372786662}}
{"text":"Our work unveils a profound connection to sensitivity analysis, and designates matching-based instances as a crucial focal point for gaining a deeper understanding of combinatorial contract settings.","meta":{"url":"http://arxiv.org/abs/2309.10766v1"},"cats":{"new-dataset":0.0824846773,"dev-research":0.2328951464,"data-quality":0.1962534309}}
{"text":"Bodily behavioral language is an important social cue, and its automated analysis helps in enhancing the understanding of artificial intelligence systems.","meta":{"url":"http://arxiv.org/abs/2309.10765v1"},"cats":{"new-dataset":0.0988053994,"dev-research":0.3158413053,"data-quality":0.11290784}}
{"text":"Furthermore, behavioral language cues are essential for active engagement in social agent-based user interactions.","meta":{"url":"http://arxiv.org/abs/2309.10765v1"},"cats":{"new-dataset":0.0359873005,"dev-research":0.2936108806,"data-quality":0.1702744633}}
{"text":"Despite the progress made in computer vision for tasks like head and body pose estimation, there is still a need to explore the detection of finer behaviors such as gesturing, grooming, or fumbling.","meta":{"url":"http://arxiv.org/abs/2309.10765v1"},"cats":{"new-dataset":0.04608246,"dev-research":0.2498859537,"data-quality":0.1042291282}}
{"text":"This paper proposes a multiview attention fusion method named MAGIC-TBR that combines features extracted from videos and their corresponding Discrete Cosine Transform coefficients via a transformer-based approach.","meta":{"url":"http://arxiv.org/abs/2309.10765v1"},"cats":{"new-dataset":0.0693818151,"dev-research":0.1292764773,"data-quality":0.1166834674}}
{"text":"The experiments are conducted on the BBSI dataset and the results demonstrate the effectiveness of the proposed feature fusion with multiview attention.","meta":{"url":"http://arxiv.org/abs/2309.10765v1"},"cats":{"new-dataset":0.3009884492,"dev-research":0.151113618,"data-quality":0.1757378751}}
{"text":"The code is available at: https://github.com/surbhimadan92/MAGIC-TBR","meta":{"url":"http://arxiv.org/abs/2309.10765v1"},"cats":{"new-dataset":0.1926196462,"dev-research":0.1338667741,"data-quality":0.0882460813}}
{"text":"Analog computing has reemerged as a promising avenue for accelerating deep neural networks (DNNs) due to its potential to overcome the energy efficiency and scalability challenges posed by traditional digital architectures.","meta":{"url":"http://arxiv.org/abs/2309.10759v1"},"cats":{"new-dataset":0.0716397549,"dev-research":0.2235437653,"data-quality":0.1323771739}}
{"text":"However, achieving high precision and DNN accuracy using such technologies is challenging, as high-precision data converters are costly and impractical.","meta":{"url":"http://arxiv.org/abs/2309.10759v1"},"cats":{"new-dataset":0.0499708726,"dev-research":0.2481941478,"data-quality":0.2037291099}}
{"text":"In this paper, we address this challenge by using the residue number system (RNS).","meta":{"url":"http://arxiv.org/abs/2309.10759v1"},"cats":{"new-dataset":0.2320416924,"dev-research":0.0963608964,"data-quality":0.1397994174}}
{"text":"RNS allows composing high-precision operations from multiple low-precision operations, thereby eliminating the information loss caused by the limited precision of the data converters.","meta":{"url":"http://arxiv.org/abs/2309.10759v1"},"cats":{"new-dataset":0.007823651,"dev-research":0.2213682594,"data-quality":0.1181754856}}
{"text":"Our study demonstrates that analog accelerators utilizing the RNS-based approach can achieve ${\\geq}99\\%$ of FP32 accuracy for state-of-the-art DNN inference using data converters with only $6$-bit precision whereas a conventional analog core requires more than $8$-bit precision to achieve the same accuracy in the same DNNs.","meta":{"url":"http://arxiv.org/abs/2309.10759v1"},"cats":{"new-dataset":0.0518606494,"dev-research":0.2109122504,"data-quality":0.1800668031}}
{"text":"The reduced precision requirements imply that using RNS can reduce the energy consumption of analog accelerators by several orders of magnitude while maintaining the same throughput and precision.","meta":{"url":"http://arxiv.org/abs/2309.10759v1"},"cats":{"new-dataset":0.0038222845,"dev-research":0.186084956,"data-quality":0.0837282893}}
{"text":"Our study extends this approach to DNN training, where we can efficiently train DNNs using $7$-bit integer arithmetic while achieving accuracy comparable to FP32 precision.","meta":{"url":"http://arxiv.org/abs/2309.10759v1"},"cats":{"new-dataset":0.2389008633,"dev-research":0.2574406558,"data-quality":0.2122380999}}
{"text":"Lastly, we present a fault-tolerant dataflow using redundant RNS error-correcting codes to protect the computation against noise and errors inherent within an analog accelerator.","meta":{"url":"http://arxiv.org/abs/2309.10759v1"},"cats":{"new-dataset":0.0826301719,"dev-research":0.2421322902,"data-quality":0.2858262708}}
{"text":"Over-the-air federated learning (OTA-FL) exploits the inherent superposition property of wireless channels to integrate the communication and model aggregation.","meta":{"url":"http://arxiv.org/abs/2309.10758v1"},"cats":{"new-dataset":0.0316538691,"dev-research":0.1208483403,"data-quality":0.0806564607}}
{"text":"Though a naturally promising framework for wireless federated learning, it requires care to mitigate physical layer impairments.","meta":{"url":"http://arxiv.org/abs/2309.10758v1"},"cats":{"new-dataset":0.02290908,"dev-research":0.2291066241,"data-quality":0.0961523783}}
{"text":"In this work, we consider a heterogeneous edge-intelligent network with different edge device resources and non-i.i.d. user dataset distributions, under a general non-convex learning objective.","meta":{"url":"http://arxiv.org/abs/2309.10758v1"},"cats":{"new-dataset":0.0676082487,"dev-research":0.1130930792,"data-quality":0.1095419367}}
{"text":"We leverage the Reconfigurable Intelligent Surface (RIS) technology to augment OTA-FL system over simultaneous time varying uplink and downlink noisy communication channels under imperfect CSI scenario.","meta":{"url":"http://arxiv.org/abs/2309.10758v1"},"cats":{"new-dataset":0.0669729927,"dev-research":0.2086447344,"data-quality":0.0951508035}}
{"text":"We propose a cross-layer algorithm that jointly optimizes RIS configuration, communication and computation resources in this general realistic setting.","meta":{"url":"http://arxiv.org/abs/2309.10758v1"},"cats":{"new-dataset":0.0364604098,"dev-research":0.1668958997,"data-quality":0.0661097896}}
{"text":"Specifically, we design dynamic local update steps in conjunction with RIS phase shifts and transmission power to boost learning performance.","meta":{"url":"http://arxiv.org/abs/2309.10758v1"},"cats":{"new-dataset":0.0168454897,"dev-research":0.1772033158,"data-quality":0.1133615094}}
{"text":"We present a convergence analysis of the proposed algorithm, and show that it outperforms the existing unified approach under heterogeneous system and imperfect CSI in numerical results.","meta":{"url":"http://arxiv.org/abs/2309.10758v1"},"cats":{"new-dataset":0.022777155,"dev-research":0.104975822,"data-quality":0.0836589042}}
{"text":"Recent hand-object interaction datasets show limited real object variability and rely on fitting the MANO parametric model to obtain groundtruth hand shapes.","meta":{"url":"http://arxiv.org/abs/2309.10748v1"},"cats":{"new-dataset":0.2917330814,"dev-research":0.1865889222,"data-quality":0.0524712035}}
{"text":"To go beyond these limitations and spur further research, we introduce the SHOWMe dataset which consists of 96 videos, annotated with real and detailed hand-object 3D textured meshes.","meta":{"url":"http://arxiv.org/abs/2309.10748v1"},"cats":{"new-dataset":0.8803781441,"dev-research":0.1720731101,"data-quality":0.1157480251}}
{"text":"Following recent work, we consider a rigid hand-object scenario, in which the pose of the hand with respect to the object remains constant during the whole video sequence.","meta":{"url":"http://arxiv.org/abs/2309.10748v1"},"cats":{"new-dataset":0.3485780259,"dev-research":0.1512984857,"data-quality":0.0944426051}}
{"text":"This assumption allows us to register sub-millimetre-precise groundtruth 3D scans to the image sequences in SHOWMe.","meta":{"url":"http://arxiv.org/abs/2309.10748v1"},"cats":{"new-dataset":0.0869821754,"dev-research":0.1315656985,"data-quality":0.0919158116}}
{"text":"Although simpler, this hypothesis makes sense in terms of applications where the required accuracy and level of detail is important eg., object hand-over in human-robot collaboration, object scanning, or manipulation and contact point analysis.","meta":{"url":"http://arxiv.org/abs/2309.10748v1"},"cats":{"new-dataset":0.0057158709,"dev-research":0.2812398513,"data-quality":0.0981798869}}
{"text":"Importantly, the rigidity of the hand-object systems allows to tackle video-based 3D reconstruction of unknown hand-held objects using a 2-stage pipeline consisting of a rigid registration step followed by a multi-view reconstruction (MVR) part.","meta":{"url":"http://arxiv.org/abs/2309.10748v1"},"cats":{"new-dataset":0.1312679723,"dev-research":0.1352612062,"data-quality":0.0592025756}}
{"text":"We carefully evaluate a set of non-trivial baselines for these two stages and show that it is possible to achieve promising object-agnostic 3D hand-object reconstructions employing an SfM toolbox or a hand pose estimator to recover the rigid transforms and off-the-shelf MVR algorithms.","meta":{"url":"http://arxiv.org/abs/2309.10748v1"},"cats":{"new-dataset":0.2400878652,"dev-research":0.141486674,"data-quality":0.0719399197}}
{"text":"However, these methods remain sensitive to the initial camera pose estimates which might be imprecise due to lack of textures on the objects or heavy occlusions of the hands, leaving room for improvements in the reconstruction.","meta":{"url":"http://arxiv.org/abs/2309.10748v1"},"cats":{"new-dataset":0.0503274118,"dev-research":0.1957225665,"data-quality":0.1136956257}}
{"text":"Code and dataset are available at https://europe.naverlabs.com/research/showme","meta":{"url":"http://arxiv.org/abs/2309.10748v1"},"cats":{"new-dataset":0.9589174646,"dev-research":0.174529792,"data-quality":0.1088419021}}
{"text":"Metaphors and sarcasm are precious fruits of our highly-evolved social communication skills.","meta":{"url":"http://arxiv.org/abs/2309.10744v1"},"cats":{"new-dataset":0.0550031407,"dev-research":0.2930147998,"data-quality":0.1014851826}}
{"text":"However, children with Asperger syndrome are known to have difficulties in comprehending sarcasm, even if they possess a certain level of verbal IQ sufficient for understanding metaphors.","meta":{"url":"http://arxiv.org/abs/2309.10744v1"},"cats":{"new-dataset":0.0133666574,"dev-research":0.2454631787,"data-quality":0.1801765624}}
{"text":"Given that, a screening test that scores the ability to understand metaphor and sarcasm has been used to differentiate Asperger syndrome from other symptoms exhibiting akin external behaviors (e.g., attention-deficit/hyperactivity disorder).","meta":{"url":"http://arxiv.org/abs/2309.10744v1"},"cats":{"new-dataset":0.0145007379,"dev-research":0.2310274127,"data-quality":0.1442206472}}
{"text":"This study uses the standardized test to examine the capability of recent large language models (LLMs) in understanding human nuanced communication.","meta":{"url":"http://arxiv.org/abs/2309.10744v1"},"cats":{"new-dataset":0.0316406119,"dev-research":0.1844096618,"data-quality":0.2182417408}}
{"text":"The results divulged that, whereas their ability to comprehend metaphors has been improved with the increase of the number of model parameters, the improvement in sarcasm understanding was not observed.","meta":{"url":"http://arxiv.org/abs/2309.10744v1"},"cats":{"new-dataset":0.0178045101,"dev-research":0.287430866,"data-quality":0.203215283}}
{"text":"This implies that an alternative approach is imperative to imbue LLMs with the capacity to grasp sarcasm, which has been associated with the amygdala, a pivotal cerebral region for emotional learning, in the case of humans.","meta":{"url":"http://arxiv.org/abs/2309.10744v1"},"cats":{"new-dataset":0.0366141619,"dev-research":0.2223528276,"data-quality":0.1365204674}}
{"text":"Diffusion models power a vast majority of text-to-audio (TTA) generation methods.","meta":{"url":"http://arxiv.org/abs/2309.10740v1"},"cats":{"new-dataset":0.0213638618,"dev-research":0.1145550405,"data-quality":0.1450579252}}
{"text":"Unfortunately, these models suffer from slow inference speed due to iterative queries to the underlying denoising network, thus unsuitable for scenarios with inference time or computational constraints.","meta":{"url":"http://arxiv.org/abs/2309.10740v1"},"cats":{"new-dataset":0.0349959289,"dev-research":0.1207065796,"data-quality":0.090088215}}
{"text":"This work modifies the recently proposed consistency distillation framework to train TTA models that require only a single neural network query.","meta":{"url":"http://arxiv.org/abs/2309.10740v1"},"cats":{"new-dataset":0.0202153097,"dev-research":0.118585524,"data-quality":0.1738481484}}
{"text":"In addition to incorporating classifier-free guidance into the distillation process, we leverage the availability of generated audio during distillation training to fine-tune the consistency TTA model with novel loss functions in the audio space, such as the CLAP score.","meta":{"url":"http://arxiv.org/abs/2309.10740v1"},"cats":{"new-dataset":0.0388040614,"dev-research":0.1835973402,"data-quality":0.2688012195}}
{"text":"Our objective and subjective evaluation results on the AudioCaps dataset show that consistency models retain diffusion models' high generation quality and diversity while reducing the number of queries by a factor of 400.","meta":{"url":"http://arxiv.org/abs/2309.10740v1"},"cats":{"new-dataset":0.1073868868,"dev-research":0.1443200414,"data-quality":0.3312562007}}
{"text":"Pre-trained language models have achieved impressive results in various music understanding and generation tasks.","meta":{"url":"http://arxiv.org/abs/2309.10738v1"},"cats":{"new-dataset":0.1307633333,"dev-research":0.1514798734,"data-quality":0.2181445943}}
{"text":"However, existing pre-training methods for symbolic melody generation struggle to capture multi-scale, multi-dimensional structural information in note sequences, due to the domain knowledge discrepancy between text and music.","meta":{"url":"http://arxiv.org/abs/2309.10738v1"},"cats":{"new-dataset":0.1135470361,"dev-research":0.1662853014,"data-quality":0.2235225047}}
{"text":"Moreover, the lack of available large-scale symbolic melody datasets limits the pre-training improvement.","meta":{"url":"http://arxiv.org/abs/2309.10738v1"},"cats":{"new-dataset":0.2028117891,"dev-research":0.1794036642,"data-quality":0.2174414672}}
{"text":"In this paper, we propose MelodyGLM, a multi-task pre-training framework for generating melodies with long-term structure.","meta":{"url":"http://arxiv.org/abs/2309.10738v1"},"cats":{"new-dataset":0.1770540129,"dev-research":0.1781452709,"data-quality":0.1003025704}}
{"text":"We design the melodic n-gram and long span sampling strategies to create local and global blank infilling tasks for modeling the local and global structures in melodies.","meta":{"url":"http://arxiv.org/abs/2309.10738v1"},"cats":{"new-dataset":0.0982777653,"dev-research":0.1155550606,"data-quality":0.2031346005}}
{"text":"Specifically, we incorporate pitch n-grams, rhythm n-grams, and their combined n-grams into the melodic n-gram blank infilling tasks for modeling the multi-dimensional structures in melodies.","meta":{"url":"http://arxiv.org/abs/2309.10738v1"},"cats":{"new-dataset":0.0839847137,"dev-research":0.1186449573,"data-quality":0.214291442}}
{"text":"To this end, we have constructed a large-scale symbolic melody dataset, MelodyNet, containing more than 0.4 million melody pieces.","meta":{"url":"http://arxiv.org/abs/2309.10738v1"},"cats":{"new-dataset":0.8224702696,"dev-research":0.1631020088,"data-quality":0.1765913249}}
{"text":"MelodyNet is utilized for large-scale pre-training and domain-specific n-gram lexicon construction.","meta":{"url":"http://arxiv.org/abs/2309.10738v1"},"cats":{"new-dataset":0.1949158484,"dev-research":0.2017801031,"data-quality":0.2660957684}}
{"text":"Both subjective and objective evaluations demonstrate that MelodyGLM surpasses the standard and previous pre-training methods.","meta":{"url":"http://arxiv.org/abs/2309.10738v1"},"cats":{"new-dataset":0.0188912401,"dev-research":0.1992143913,"data-quality":0.2206266619}}
{"text":"In particular, subjective evaluations show that, on the melody continuation task, MelodyGLM achieves average improvements of 0.82, 0.87, 0.78, and 0.94 in consistency, rhythmicity, structure, and overall quality, respectively.","meta":{"url":"http://arxiv.org/abs/2309.10738v1"},"cats":{"new-dataset":0.0324329329,"dev-research":0.2015992268,"data-quality":0.1827544769}}
{"text":"Notably, MelodyGLM nearly matches the quality of human-composed melodies on the melody inpainting task.","meta":{"url":"http://arxiv.org/abs/2309.10738v1"},"cats":{"new-dataset":0.0297912433,"dev-research":0.2180365037,"data-quality":0.1589633244}}
{"text":"This paper introduces a novel backup strategy for Monte-Carlo Tree Search (MCTS) designed for highly stochastic and partially observable Markov decision processes.","meta":{"url":"http://arxiv.org/abs/2309.10737v1"},"cats":{"new-dataset":0.0242885544,"dev-research":0.1472948074,"data-quality":0.0805118025}}
{"text":"We adopt a probabilistic approach, modeling both value and action-value nodes as Gaussian distributions.","meta":{"url":"http://arxiv.org/abs/2309.10737v1"},"cats":{"new-dataset":0.0578838196,"dev-research":0.1395835258,"data-quality":0.1395350787}}
{"text":"We introduce a novel backup operator that computes value nodes as the Wasserstein barycenter of their action-value children nodes; thus, propagating the uncertainty of the estimate across the tree to the root node.","meta":{"url":"http://arxiv.org/abs/2309.10737v1"},"cats":{"new-dataset":0.1091496246,"dev-research":0.1598429686,"data-quality":0.1392618648}}
{"text":"We study our novel backup operator when using a novel combination of $L^1$-Wasserstein barycenter with $\\alpha$-divergence, by drawing a notable connection to the generalized mean backup operator.","meta":{"url":"http://arxiv.org/abs/2309.10737v1"},"cats":{"new-dataset":0.0530881437,"dev-research":0.1182962965,"data-quality":0.0937544774}}
{"text":"We complement our probabilistic backup operator with two sampling strategies, based on optimistic selection and Thompson sampling, obtaining our Wasserstein MCTS algorithm.","meta":{"url":"http://arxiv.org/abs/2309.10737v1"},"cats":{"new-dataset":0.0547831094,"dev-research":0.1277471576,"data-quality":0.0831939525}}
{"text":"We provide theoretical guarantees of asymptotic convergence to the optimal policy, and an empirical evaluation on several stochastic and partially observable environments, where our approach outperforms well-known related baselines.","meta":{"url":"http://arxiv.org/abs/2309.10737v1"},"cats":{"new-dataset":0.0479969432,"dev-research":0.1374723744,"data-quality":0.084401347}}
{"text":"We consider the problem of learning a model from multiple heterogeneous sources with the goal of performing well on a new target distribution.","meta":{"url":"http://arxiv.org/abs/2309.10736v1"},"cats":{"new-dataset":0.0194127265,"dev-research":0.0972596527,"data-quality":0.136329871}}
{"text":"The goal of learner is to mix these data sources in a target-distribution aware way and simultaneously minimize the empirical risk on the mixed source.","meta":{"url":"http://arxiv.org/abs/2309.10736v1"},"cats":{"new-dataset":0.0750278469,"dev-research":0.1935525929,"data-quality":0.2654460357}}
{"text":"The literature has made some tangible advancements in establishing theory of learning on mixture domain.","meta":{"url":"http://arxiv.org/abs/2309.10736v1"},"cats":{"new-dataset":0.0088857296,"dev-research":0.1336058514,"data-quality":0.0891690581}}
{"text":"However, there are still two unsolved problems.","meta":{"url":"http://arxiv.org/abs/2309.10736v1"},"cats":{"new-dataset":0.0303330965,"dev-research":0.2802628933,"data-quality":0.266741389}}
{"text":"Firstly, how to estimate the optimal mixture of sources, given a target domain; Secondly, when there are numerous target domains, how to solve empirical risk minimization (ERM) for each target using possibly unique mixture of data sources in a computationally efficient manner.","meta":{"url":"http://arxiv.org/abs/2309.10736v1"},"cats":{"new-dataset":0.0355734155,"dev-research":0.1635592359,"data-quality":0.1724547936}}
{"text":"In this paper we address both problems efficiently and with guarantees.","meta":{"url":"http://arxiv.org/abs/2309.10736v1"},"cats":{"new-dataset":0.0266583358,"dev-research":0.1744439045,"data-quality":0.1423091215}}
{"text":"We cast the first problem, mixture weight estimation, as a convex-nonconcave compositional minimax problem, and propose an efficient stochastic algorithm with provable stationarity guarantees.","meta":{"url":"http://arxiv.org/abs/2309.10736v1"},"cats":{"new-dataset":0.0472429225,"dev-research":0.1137306113,"data-quality":0.1850409388}}
{"text":"Next, for the second problem, we identify that for certain regimes, solving ERM for each target domain individually can be avoided, and instead parameters for a target optimal model can be viewed as a non-linear function on a space of the mixture coefficients.","meta":{"url":"http://arxiv.org/abs/2309.10736v1"},"cats":{"new-dataset":0.0119094184,"dev-research":0.0980788381,"data-quality":0.1317163077}}
{"text":"Building upon this, we show that in the offline setting, a GD-trained overparameterized neural network can provably learn such function to predict the model of target domain instead of solving a designated ERM problem.","meta":{"url":"http://arxiv.org/abs/2309.10736v1"},"cats":{"new-dataset":0.0503549379,"dev-research":0.1077476348,"data-quality":0.1329002751}}
{"text":"Finally, we also consider an online setting and propose a label efficient online algorithm, which predicts parameters for new targets given an arbitrary sequence of mixing coefficients, while enjoying regret guarantees.","meta":{"url":"http://arxiv.org/abs/2309.10736v1"},"cats":{"new-dataset":0.0392971428,"dev-research":0.1493269602,"data-quality":0.1649849247}}
{"text":"The remarkable capabilities and intricate nature of Artificial Intelligence (AI) have dramatically escalated the imperative for specialized AI accelerators.","meta":{"url":"http://arxiv.org/abs/2309.10730v1"},"cats":{"new-dataset":0.0189165266,"dev-research":0.1776158814,"data-quality":0.0572236465}}
{"text":"Nonetheless, designing these accelerators for various AI workloads remains both labor- and time-intensive.","meta":{"url":"http://arxiv.org/abs/2309.10730v1"},"cats":{"new-dataset":0.0071996953,"dev-research":0.2092593648,"data-quality":0.0565660202}}
{"text":"While existing design exploration and automation tools can partially alleviate the need for extensive human involvement, they still demand substantial hardware expertise, posing a barrier to non-experts and stifling AI accelerator development.","meta":{"url":"http://arxiv.org/abs/2309.10730v1"},"cats":{"new-dataset":0.0277901584,"dev-research":0.4283254596,"data-quality":0.0657009312}}
{"text":"Motivated by the astonishing potential of large language models (LLMs) for generating high-quality content in response to human language instructions, we embark on this work to examine the possibility of harnessing LLMs to automate AI accelerator design.","meta":{"url":"http://arxiv.org/abs/2309.10730v1"},"cats":{"new-dataset":0.0793930107,"dev-research":0.2035748382,"data-quality":0.151434372}}
{"text":"Through this endeavor, we develop GPT4AIGChip, a framework intended to democratize AI accelerator design by leveraging human natural languages instead of domain-specific languages.","meta":{"url":"http://arxiv.org/abs/2309.10730v1"},"cats":{"new-dataset":0.2163401113,"dev-research":0.2459152592,"data-quality":0.1286464063}}
{"text":"Specifically, we first perform an in-depth investigation into LLMs' limitations and capabilities for AI accelerator design, thus aiding our understanding of our current position and garnering insights into LLM-powered automated AI accelerator design.","meta":{"url":"http://arxiv.org/abs/2309.10730v1"},"cats":{"new-dataset":0.0233886814,"dev-research":0.1275931649,"data-quality":0.0612898207}}
{"text":"Furthermore, drawing inspiration from the above insights, we develop a framework called GPT4AIGChip, which features an automated demo-augmented prompt-generation pipeline utilizing in-context learning to guide LLMs towards creating high-quality AI accelerator design.","meta":{"url":"http://arxiv.org/abs/2309.10730v1"},"cats":{"new-dataset":0.1684787198,"dev-research":0.1928677192,"data-quality":0.0961578278}}
{"text":"To our knowledge, this work is the first to demonstrate an effective pipeline for LLM-powered automated AI accelerator generation.","meta":{"url":"http://arxiv.org/abs/2309.10730v1"},"cats":{"new-dataset":0.0308486145,"dev-research":0.1312586224,"data-quality":0.0952802115}}
{"text":"Accordingly, we anticipate that our insights and framework can serve as a catalyst for innovations in next-generation LLM-powered design automation tools.","meta":{"url":"http://arxiv.org/abs/2309.10730v1"},"cats":{"new-dataset":0.04258879,"dev-research":0.3753412447,"data-quality":0.0660941735}}
{"text":"Quantum computing has proven to be capable of accelerating many algorithms by performing tasks that classical computers cannot.","meta":{"url":"http://arxiv.org/abs/2309.10728v1"},"cats":{"new-dataset":0.0045753918,"dev-research":0.1493657514,"data-quality":0.056028892}}
{"text":"Currently, Noisy Intermediate Scale Quantum (NISQ) machines struggle from scalability and noise issues to render a commercial quantum computer.","meta":{"url":"http://arxiv.org/abs/2309.10728v1"},"cats":{"new-dataset":0.0288939853,"dev-research":0.1471673915,"data-quality":0.1357631577}}
{"text":"However, the physical and software improvements of a quantum computer can efficiently control quantum gate noise.","meta":{"url":"http://arxiv.org/abs/2309.10728v1"},"cats":{"new-dataset":0.0064320463,"dev-research":0.2981137516,"data-quality":0.1304049341}}
{"text":"As the complexity of quantum algorithms and implementation increases, software control of quantum circuits may lead to a more intricate design.","meta":{"url":"http://arxiv.org/abs/2309.10728v1"},"cats":{"new-dataset":0.005022039,"dev-research":0.3400507729,"data-quality":0.0449428912}}
{"text":"Consequently, the verification of quantum circuits becomes crucial in ensuring the correctness of the compilation, along with other processes, including quantum error correction and assertions, that can increase the fidelity of quantum circuits.","meta":{"url":"http://arxiv.org/abs/2309.10728v1"},"cats":{"new-dataset":0.0042333187,"dev-research":0.3376834716,"data-quality":0.2691212657}}
{"text":"In this paper, we propose a Decision Diagram-based quantum equivalence checking approach, QuBEC, that requires less latency compared to existing techniques, while accounting for circuits with quantum error correction redundancy.","meta":{"url":"http://arxiv.org/abs/2309.10728v1"},"cats":{"new-dataset":0.007924447,"dev-research":0.2498719801,"data-quality":0.1682772439}}
{"text":"Our proposed methodology reduces verification time on certain benchmark circuits by up to $271.49 \\times$, while the number of Decision Diagram nodes required is reduced by up to $798.31 \\times$, compared to state-of-the-art strategies.","meta":{"url":"http://arxiv.org/abs/2309.10728v1"},"cats":{"new-dataset":0.0290685072,"dev-research":0.2999786795,"data-quality":0.1244177729}}
{"text":"The proposed QuBEC framework can contribute to the advancement of quantum computing by enabling faster and more efficient verification of quantum circuits, paving the way for the development of larger and more complex quantum algorithms.","meta":{"url":"http://arxiv.org/abs/2309.10728v1"},"cats":{"new-dataset":0.0138566762,"dev-research":0.1388871475,"data-quality":0.0680715014}}
{"text":"Current state-of-the-art methods for panoptic segmentation require an immense amount of annotated training data that is both arduous and expensive to obtain posing a significant challenge for their widespread adoption.","meta":{"url":"http://arxiv.org/abs/2309.10726v1"},"cats":{"new-dataset":0.3457159706,"dev-research":0.1748351352,"data-quality":0.1783021856}}
{"text":"Concurrently, recent breakthroughs in visual representation learning have sparked a paradigm shift leading to the advent of large foundation models that can be trained with completely unlabeled images.","meta":{"url":"http://arxiv.org/abs/2309.10726v1"},"cats":{"new-dataset":0.137150964,"dev-research":0.1633842668,"data-quality":0.1792422862}}
{"text":"In this work, we propose to leverage such task-agnostic image features to enable few-shot panoptic segmentation by presenting Segmenting Panoptic Information with Nearly 0 labels (SPINO).","meta":{"url":"http://arxiv.org/abs/2309.10726v1"},"cats":{"new-dataset":0.1706761729,"dev-research":0.1271627009,"data-quality":0.1499242356}}
{"text":"In detail, our method combines a DINOv2 backbone with lightweight network heads for semantic segmentation and boundary estimation.","meta":{"url":"http://arxiv.org/abs/2309.10726v1"},"cats":{"new-dataset":0.2362896739,"dev-research":0.1525686528,"data-quality":0.1423438082}}
{"text":"We show that our approach, albeit being trained with only ten annotated images, predicts high-quality pseudo-labels that can be used with any existing panoptic segmentation method.","meta":{"url":"http://arxiv.org/abs/2309.10726v1"},"cats":{"new-dataset":0.469503298,"dev-research":0.1557510107,"data-quality":0.4227238396}}
{"text":"Notably, we demonstrate that SPINO achieves competitive results compared to fully supervised baselines while using less than 0.3% of the ground truth labels, paving the way for learning complex visual recognition tasks leveraging foundation models.","meta":{"url":"http://arxiv.org/abs/2309.10726v1"},"cats":{"new-dataset":0.1828513648,"dev-research":0.1309760827,"data-quality":0.2365539803}}
{"text":"To illustrate its general applicability, we further deploy SPINO on real-world robotic vision systems for both outdoor and indoor environments.","meta":{"url":"http://arxiv.org/abs/2309.10726v1"},"cats":{"new-dataset":0.0302880836,"dev-research":0.191973772,"data-quality":0.0612696836}}
{"text":"To foster future research, we make the code and trained models publicly available at http://spino.cs.uni-freiburg.de.","meta":{"url":"http://arxiv.org/abs/2309.10726v1"},"cats":{"new-dataset":0.3758288766,"dev-research":0.1964231736,"data-quality":0.0821721515}}
{"text":"In this paper, we present a novel method to automatically classify medical images that learns and leverages weak causal signals in the image.","meta":{"url":"http://arxiv.org/abs/2309.10725v1"},"cats":{"new-dataset":0.1160367111,"dev-research":0.1733208516,"data-quality":0.2830143163}}
{"text":"Our framework consists of a convolutional neural network backbone and a causality-extractor module that extracts cause-effect relationships between feature maps that can inform the model on the appearance of a feature in one place of the image, given the presence of another feature within some other place of the image.","meta":{"url":"http://arxiv.org/abs/2309.10725v1"},"cats":{"new-dataset":0.1465876049,"dev-research":0.2248601466,"data-quality":0.1928869526}}
{"text":"To evaluate the effectiveness of our approach in low-data scenarios, we train our causality-driven architecture in a One-shot learning scheme, where we propose a new meta-learning procedure entailing meta-training and meta-testing tasks that are designed using related classes but at different levels of granularity.","meta":{"url":"http://arxiv.org/abs/2309.10725v1"},"cats":{"new-dataset":0.0549580408,"dev-research":0.2064334392,"data-quality":0.1926473096}}
{"text":"We conduct binary and multi-class classification experiments on a publicly available dataset of prostate MRI images.","meta":{"url":"http://arxiv.org/abs/2309.10725v1"},"cats":{"new-dataset":0.236974356,"dev-research":0.0887535476,"data-quality":0.1738432997}}
{"text":"To validate the effectiveness of the proposed causality-driven module, we perform an ablation study and conduct qualitative assessments using class activation maps to highlight regions strongly influencing the network's decision-making process.","meta":{"url":"http://arxiv.org/abs/2309.10725v1"},"cats":{"new-dataset":0.0185907674,"dev-research":0.3645475847,"data-quality":0.1630441225}}
{"text":"Our findings show that causal relationships among features play a crucial role in enhancing the model's ability to discern relevant information and yielding more reliable and interpretable predictions.","meta":{"url":"http://arxiv.org/abs/2309.10725v1"},"cats":{"new-dataset":0.0123648795,"dev-research":0.3495321221,"data-quality":0.2546270827}}
{"text":"This would make it a promising approach for medical image classification tasks.","meta":{"url":"http://arxiv.org/abs/2309.10725v1"},"cats":{"new-dataset":0.0428035962,"dev-research":0.1530644655,"data-quality":0.175847684}}
{"text":"Humans can easily perceive the direction of sound sources in a visual scene, termed sound source localization.","meta":{"url":"http://arxiv.org/abs/2309.10724v1"},"cats":{"new-dataset":0.0698809509,"dev-research":0.2657108443,"data-quality":0.2512355856}}
{"text":"Recent studies on learning-based sound source localization have mainly explored the problem from a localization perspective.","meta":{"url":"http://arxiv.org/abs/2309.10724v1"},"cats":{"new-dataset":0.0759275543,"dev-research":0.1808176834,"data-quality":0.3435463391}}
{"text":"However, prior arts and existing benchmarks do not account for a more important aspect of the problem, cross-modal semantic understanding, which is essential for genuine sound source localization.","meta":{"url":"http://arxiv.org/abs/2309.10724v1"},"cats":{"new-dataset":0.0429246774,"dev-research":0.1932208575,"data-quality":0.3723247602}}
{"text":"Cross-modal semantic understanding is important in understanding semantically mismatched audio-visual events, e.g., silent objects, or off-screen sounds.","meta":{"url":"http://arxiv.org/abs/2309.10724v1"},"cats":{"new-dataset":0.031774189,"dev-research":0.2571075991,"data-quality":0.3448012787}}
{"text":"To account for this, we propose a cross-modal alignment task as a joint task with sound source localization to better learn the interaction between audio and visual modalities.","meta":{"url":"http://arxiv.org/abs/2309.10724v1"},"cats":{"new-dataset":0.1644916496,"dev-research":0.2047833911,"data-quality":0.2137296351}}
{"text":"Thereby, we achieve high localization performance with strong cross-modal semantic understanding.","meta":{"url":"http://arxiv.org/abs/2309.10724v1"},"cats":{"new-dataset":0.1171795658,"dev-research":0.1899223661,"data-quality":0.2018283814}}
{"text":"Our method outperforms the state-of-the-art approaches in both sound source localization and cross-modal retrieval.","meta":{"url":"http://arxiv.org/abs/2309.10724v1"},"cats":{"new-dataset":0.1062166855,"dev-research":0.1350401878,"data-quality":0.2776959961}}
{"text":"Our work suggests that jointly tackling both tasks is necessary to conquer genuine sound source localization.","meta":{"url":"http://arxiv.org/abs/2309.10724v1"},"cats":{"new-dataset":0.057061884,"dev-research":0.2460901624,"data-quality":0.3035266256}}
{"text":"In this work, we introduce a new graph search algorithm, lazy edged based A* (LEA*), for robot motion planning.","meta":{"url":"http://arxiv.org/abs/2309.10722v1"},"cats":{"new-dataset":0.0952616999,"dev-research":0.201419163,"data-quality":0.059494533}}
{"text":"By using an edge queue and exploiting the idea of lazy search, LEA* is optimally vertex efficient similar to A*, and has improved edge efficiency compared to A*.","meta":{"url":"http://arxiv.org/abs/2309.10722v1"},"cats":{"new-dataset":0.0057712406,"dev-research":0.1650464536,"data-quality":0.0855779479}}
{"text":"LEA* is simple and easy to implement with minimum modification to A*, resulting in a very small overhead compared to previous lazy search algorithms.","meta":{"url":"http://arxiv.org/abs/2309.10722v1"},"cats":{"new-dataset":0.022019528,"dev-research":0.1741199996,"data-quality":0.1106336803}}
{"text":"We also explore the effect of inflated heuristics, which results in the weighted LEA* (wLEA*).","meta":{"url":"http://arxiv.org/abs/2309.10722v1"},"cats":{"new-dataset":0.0191370749,"dev-research":0.1735337055,"data-quality":0.0900625344}}
{"text":"We show that the edge efficiency of wLEA* becomes close to LazySP and, thus is near-optimal.","meta":{"url":"http://arxiv.org/abs/2309.10722v1"},"cats":{"new-dataset":0.0091989484,"dev-research":0.1475860787,"data-quality":0.1014413442}}
{"text":"We test LEA* and wLEA* on 2D planning problems and planning of a 7-DOF manipulator.","meta":{"url":"http://arxiv.org/abs/2309.10722v1"},"cats":{"new-dataset":0.1484534652,"dev-research":0.2214416734,"data-quality":0.0343327834}}
{"text":"We perform a thorough comparison with previous algorithms by considering sparse, medium, and cluttered random worlds and small, medium, and large graph sizes.","meta":{"url":"http://arxiv.org/abs/2309.10722v1"},"cats":{"new-dataset":0.1209916904,"dev-research":0.1125809693,"data-quality":0.1267568397}}
{"text":"Our results show that LEA* and wLEA* are the fastest algorithms to find the plan compared to previous algorithms.","meta":{"url":"http://arxiv.org/abs/2309.10722v1"},"cats":{"new-dataset":0.0574828475,"dev-research":0.1722077983,"data-quality":0.0489558217}}
{"text":"An accurate motion model is a fundamental component of most autonomous navigation systems.","meta":{"url":"http://arxiv.org/abs/2309.10718v1"},"cats":{"new-dataset":0.0285561878,"dev-research":0.156934281,"data-quality":0.0903847578}}
{"text":"While much work has been done on improving model formulation, no standard protocol exists for gathering empirical data required to train models.","meta":{"url":"http://arxiv.org/abs/2309.10718v1"},"cats":{"new-dataset":0.0579506053,"dev-research":0.1502178879,"data-quality":0.1195067009}}
{"text":"In this work, we address this issue by proposing Data-driven Robot Input Vector Exploration (DRIVE), a protocol that enables characterizing uncrewed ground vehicles (UGVs) input limits and gathering empirical model training data.","meta":{"url":"http://arxiv.org/abs/2309.10718v1"},"cats":{"new-dataset":0.2706961076,"dev-research":0.1539316244,"data-quality":0.0883696884}}
{"text":"We also propose a novel learned slip approach outperforming similar acceleration learning approaches.","meta":{"url":"http://arxiv.org/abs/2309.10718v1"},"cats":{"new-dataset":0.0600793501,"dev-research":0.1795188268,"data-quality":0.15357428}}
{"text":"Our contributions are validated through an extensive experimental evaluation, cumulating over 7 km and 1.8 h of driving data over three distinct UGVs and four terrain types.","meta":{"url":"http://arxiv.org/abs/2309.10718v1"},"cats":{"new-dataset":0.1831033149,"dev-research":0.1386402088,"data-quality":0.0632482417}}
{"text":"We show that our protocol offers increased predictive performance over common human-driven data-gathering protocols.","meta":{"url":"http://arxiv.org/abs/2309.10718v1"},"cats":{"new-dataset":0.2901305712,"dev-research":0.2688940109,"data-quality":0.0703792334}}
{"text":"Furthermore, our protocol converges with 46 s of training data, almost four times less than the shortest human dataset gathering protocol.","meta":{"url":"http://arxiv.org/abs/2309.10718v1"},"cats":{"new-dataset":0.5953585003,"dev-research":0.1215440294,"data-quality":0.107545249}}
{"text":"We show that the operational limit for our model is reached in extreme slip conditions encountered on surfaced ice.","meta":{"url":"http://arxiv.org/abs/2309.10718v1"},"cats":{"new-dataset":0.3522918381,"dev-research":0.2179825635,"data-quality":0.0661059303}}
{"text":"DRIVE is an efficient way of characterizing UGV motion in its operational conditions.","meta":{"url":"http://arxiv.org/abs/2309.10718v1"},"cats":{"new-dataset":0.0273021379,"dev-research":0.2165923059,"data-quality":0.0591084184}}
{"text":"Our code and dataset are both available online at this link: https://github.com/norlab-ulaval/DRIVE.","meta":{"url":"http://arxiv.org/abs/2309.10718v1"},"cats":{"new-dataset":0.894366665,"dev-research":0.1651771351,"data-quality":0.1757176385}}
{"text":"This work presents a novel Learning Model Predictive Control (LMPC) strategy for autonomous racing at the handling limit that can iteratively explore and learn unknown dynamics in high-speed operational domains.","meta":{"url":"http://arxiv.org/abs/2309.10716v1"},"cats":{"new-dataset":0.162558373,"dev-research":0.1600816876,"data-quality":0.0580861271}}
{"text":"We start from existing LMPC formulations and modify the system dynamics learning method.","meta":{"url":"http://arxiv.org/abs/2309.10716v1"},"cats":{"new-dataset":0.0529908129,"dev-research":0.1433292163,"data-quality":0.101201021}}
{"text":"In particular, our approach uses a nominal, global, nonlinear, physics-based model with a local, linear, data-driven learning of the error dynamics.","meta":{"url":"http://arxiv.org/abs/2309.10716v1"},"cats":{"new-dataset":0.0626914095,"dev-research":0.1787005583,"data-quality":0.2041945336}}
{"text":"We conduct experiments in simulation, 1/10th scale hardware, and deployed the proposed LMPC on a full-scale autonomous race car used in the Indy Autonomous Challenge (IAC) with closed loop experiments at the Putnam Park Road Course in Indiana, USA.","meta":{"url":"http://arxiv.org/abs/2309.10716v1"},"cats":{"new-dataset":0.1264111289,"dev-research":0.1607373691,"data-quality":0.0972724518}}
{"text":"The results show that the proposed control policy exhibits improved robustness to parameter tuning and data scarcity.","meta":{"url":"http://arxiv.org/abs/2309.10716v1"},"cats":{"new-dataset":0.0422420612,"dev-research":0.1983746507,"data-quality":0.1535668963}}
{"text":"Incremental and safety-aware exploration toward the limit of handling and iterative learning of the vehicle dynamics in high-speed domains is observed both in simulations and experiments.","meta":{"url":"http://arxiv.org/abs/2309.10716v1"},"cats":{"new-dataset":0.1130690739,"dev-research":0.2291776781,"data-quality":0.0759094438}}
{"text":"Image denoising is a fundamental and challenging task in the field of computer vision.","meta":{"url":"http://arxiv.org/abs/2309.10714v1"},"cats":{"new-dataset":0.0227674265,"dev-research":0.221074788,"data-quality":0.207432094}}
{"text":"Most supervised denoising methods learn to reconstruct clean images from noisy inputs, which have intrinsic spectral bias and tend to produce over-smoothed and blurry images.","meta":{"url":"http://arxiv.org/abs/2309.10714v1"},"cats":{"new-dataset":0.0842962152,"dev-research":0.1968947846,"data-quality":0.3396424039}}
{"text":"Recently, researchers have explored diffusion models to generate high-frequency details in image restoration tasks, but these models do not guarantee that the generated texture aligns with real images, leading to undesirable artifacts.","meta":{"url":"http://arxiv.org/abs/2309.10714v1"},"cats":{"new-dataset":0.0326768122,"dev-research":0.1593228561,"data-quality":0.1936243223}}
{"text":"To address the trade-off between visual appeal and fidelity of high-frequency details in denoising tasks, we propose a novel approach called the Reconstruct-and-Generate Diffusion Model (RnG).","meta":{"url":"http://arxiv.org/abs/2309.10714v1"},"cats":{"new-dataset":0.0724914763,"dev-research":0.1629145096,"data-quality":0.1067441103}}
{"text":"Our method leverages a reconstructive denoising network to recover the majority of the underlying clean signal, which serves as the initial estimation for subsequent steps to maintain fidelity.","meta":{"url":"http://arxiv.org/abs/2309.10714v1"},"cats":{"new-dataset":0.0330699178,"dev-research":0.2067053812,"data-quality":0.2443343959}}
{"text":"Additionally, it employs a diffusion algorithm to generate residual high-frequency details, thereby enhancing visual quality.","meta":{"url":"http://arxiv.org/abs/2309.10714v1"},"cats":{"new-dataset":0.0258224854,"dev-research":0.1978786764,"data-quality":0.0921996505}}
{"text":"We further introduce a two-stage training scheme to ensure effective collaboration between the reconstructive and generative modules of RnG. To reduce undesirable texture introduced by the diffusion model, we also propose an adaptive step controller that regulates the number of inverse steps applied by the diffusion model, allowing control over the level of high-frequency details added to each patch as well as saving the inference computational cost.","meta":{"url":"http://arxiv.org/abs/2309.10714v1"},"cats":{"new-dataset":0.0692770727,"dev-research":0.1408353236,"data-quality":0.0751961856}}
{"text":"Through our proposed RnG, we achieve a better balance between perception and distortion.","meta":{"url":"http://arxiv.org/abs/2309.10714v1"},"cats":{"new-dataset":0.0276280539,"dev-research":0.1345658371,"data-quality":0.1270061987}}
{"text":"We conducted extensive experiments on both synthetic and real denoising datasets, validating the superiority of the proposed approach.","meta":{"url":"http://arxiv.org/abs/2309.10714v1"},"cats":{"new-dataset":0.356883447,"dev-research":0.1944873666,"data-quality":0.251937685}}
{"text":"There has been a debate about the superiority between vision Transformers and ConvNets, serving as the backbone of computer vision models.","meta":{"url":"http://arxiv.org/abs/2309.10713v1"},"cats":{"new-dataset":0.0370801144,"dev-research":0.2549602799,"data-quality":0.1126573077}}
{"text":"Although they are usually considered as two completely different architectures, in this paper, we interpret vision Transformers as ConvNets with dynamic convolutions, which enables us to characterize existing Transformers and dynamic ConvNets in a unified framework and compare their design choices side by side.","meta":{"url":"http://arxiv.org/abs/2309.10713v1"},"cats":{"new-dataset":0.1073884849,"dev-research":0.2587353725,"data-quality":0.0856269896}}
{"text":"In addition, our interpretation can also guide the network design as researchers now can consider vision Transformers from the design space of ConvNets and vice versa.","meta":{"url":"http://arxiv.org/abs/2309.10713v1"},"cats":{"new-dataset":0.0580353478,"dev-research":0.2824258055,"data-quality":0.0974201283}}
{"text":"We demonstrate such potential through two specific studies.","meta":{"url":"http://arxiv.org/abs/2309.10713v1"},"cats":{"new-dataset":0.0064703736,"dev-research":0.1286407404,"data-quality":0.0689954317}}
{"text":"First, we inspect the role of softmax in vision Transformers as the activation function and find it can be replaced by commonly used ConvNets modules, such as ReLU and Layer Normalization, which results in a faster convergence rate and better performance.","meta":{"url":"http://arxiv.org/abs/2309.10713v1"},"cats":{"new-dataset":0.0415277371,"dev-research":0.1820177895,"data-quality":0.0935029146}}
{"text":"Second, following the design of depth-wise convolution, we create a corresponding depth-wise vision Transformer that is more efficient with comparable performance.","meta":{"url":"http://arxiv.org/abs/2309.10713v1"},"cats":{"new-dataset":0.0866838399,"dev-research":0.1656553432,"data-quality":0.0630794626}}
{"text":"The potential of the proposed unified interpretation is not limited to the given examples and we hope it can inspire the community and give rise to more advanced network architectures.","meta":{"url":"http://arxiv.org/abs/2309.10713v1"},"cats":{"new-dataset":0.0115355723,"dev-research":0.1846725747,"data-quality":0.1344109983}}
{"text":"Fine-grained open-set recognition (FineOSR) aims to recognize images belonging to classes with subtle appearance differences while rejecting images of unknown classes.","meta":{"url":"http://arxiv.org/abs/2309.10711v1"},"cats":{"new-dataset":0.1324986345,"dev-research":0.115680974,"data-quality":0.3610122551}}
{"text":"A recent trend in OSR shows the benefit of generative models to discriminative unknown detection.","meta":{"url":"http://arxiv.org/abs/2309.10711v1"},"cats":{"new-dataset":0.0475496962,"dev-research":0.1545207721,"data-quality":0.3276202593}}
{"text":"As a type of generative model, energy-based models (EBM) are the potential for hybrid modeling of generative and discriminative tasks.","meta":{"url":"http://arxiv.org/abs/2309.10711v1"},"cats":{"new-dataset":0.0196346462,"dev-research":0.1260120972,"data-quality":0.0649407888}}
{"text":"However, most existing EBMs suffer from density estimation in high-dimensional space, which is critical to recognizing images from fine-grained classes.","meta":{"url":"http://arxiv.org/abs/2309.10711v1"},"cats":{"new-dataset":0.1052210379,"dev-research":0.1153379897,"data-quality":0.2671857962}}
{"text":"In this paper, we explore the low-dimensional latent space with energy-based prior distribution for OSR in a fine-grained visual world.","meta":{"url":"http://arxiv.org/abs/2309.10711v1"},"cats":{"new-dataset":0.125466003,"dev-research":0.1246217937,"data-quality":0.0912063311}}
{"text":"Specifically, based on the latent space EBM, we propose an attribute-aware information bottleneck (AIB), a residual attribute feature aggregation (RAFA) module, and an uncertainty-based virtual outlier synthesis (UVOS) module to improve the expressivity, granularity, and density of the samples in fine-grained classes, respectively.","meta":{"url":"http://arxiv.org/abs/2309.10711v1"},"cats":{"new-dataset":0.1881751488,"dev-research":0.2563280326,"data-quality":0.3873102002}}
{"text":"Our method is flexible to take advantage of recent vision transformers for powerful visual classification and generation.","meta":{"url":"http://arxiv.org/abs/2309.10711v1"},"cats":{"new-dataset":0.0878730957,"dev-research":0.2349692,"data-quality":0.1218382021}}
{"text":"The method is validated on both fine-grained and general visual classification datasets while preserving the capability of generating photo-realistic fake images with high resolution.","meta":{"url":"http://arxiv.org/abs/2309.10711v1"},"cats":{"new-dataset":0.4137830911,"dev-research":0.1589420944,"data-quality":0.3357964012}}
{"text":"Large language models (LLMs) with billions of parameters have demonstrated outstanding performance on various natural language processing tasks.","meta":{"url":"http://arxiv.org/abs/2309.10706v1"},"cats":{"new-dataset":0.0774653927,"dev-research":0.1095902705,"data-quality":0.1640120845}}
{"text":"This report presents OpenBA, an open-sourced 15B bilingual asymmetric seq2seq model, to contribute an LLM variant to the Chinese-oriented open-source model community.","meta":{"url":"http://arxiv.org/abs/2309.10706v1"},"cats":{"new-dataset":0.2193763831,"dev-research":0.1689434405,"data-quality":0.1316772873}}
{"text":"We enhance OpenBA with effective and efficient techniques as well as adopt a three-stage training strategy to train the model from scratch.","meta":{"url":"http://arxiv.org/abs/2309.10706v1"},"cats":{"new-dataset":0.1259326165,"dev-research":0.1787880481,"data-quality":0.105853495}}
{"text":"Our solution can also achieve very competitive performance with only 380B tokens, which is better than LLaMA-70B on the BELEBELE benchmark, BLOOM-176B on the MMLU benchmark, GLM-130B on the C-Eval (hard) benchmark.","meta":{"url":"http://arxiv.org/abs/2309.10706v1"},"cats":{"new-dataset":0.0320748427,"dev-research":0.0910505564,"data-quality":0.0995785443}}
{"text":"This report provides the main details to pre-train an analogous model, including pre-training data processing, Bilingual Flan data collection, the empirical observations that inspire our model architecture design, training objectives of different stages, and other enhancement techniques.","meta":{"url":"http://arxiv.org/abs/2309.10706v1"},"cats":{"new-dataset":0.304063706,"dev-research":0.1871246337,"data-quality":0.1430466791}}
{"text":"We have refactored our code to follow the design principles of the Huggingface Transformers Library, making it more convenient for developers to use, and released checkpoints of different training stages at https://huggingface.co/openBA.","meta":{"url":"http://arxiv.org/abs/2309.10706v1"},"cats":{"new-dataset":0.1919658985,"dev-research":0.2160345359,"data-quality":0.0856408891}}
{"text":"More details of our project are available at https://github.com/OpenNLG/openBA.git.","meta":{"url":"http://arxiv.org/abs/2309.10706v1"},"cats":{"new-dataset":0.2639654564,"dev-research":0.2008219421,"data-quality":0.100896143}}
{"text":"Decision making under uncertainty is at the heart of any autonomous system acting with imperfect information.","meta":{"url":"http://arxiv.org/abs/2309.10701v1"},"cats":{"new-dataset":0.0068882843,"dev-research":0.2255304318,"data-quality":0.1658219998}}
{"text":"The cost of solving the decision making problem is exponential in the action and observation spaces, thus rendering it unfeasible for many online systems.","meta":{"url":"http://arxiv.org/abs/2309.10701v1"},"cats":{"new-dataset":0.0106948273,"dev-research":0.2575308165,"data-quality":0.0548326781}}
{"text":"This paper introduces a novel approach to efficient decision-making, by partitioning the high-dimensional observation space.","meta":{"url":"http://arxiv.org/abs/2309.10701v1"},"cats":{"new-dataset":0.0435223715,"dev-research":0.2101220834,"data-quality":0.0875300754}}
{"text":"Using the partitioned observation space, we formulate analytical bounds on the expected information-theoretic reward, for general belief distributions.","meta":{"url":"http://arxiv.org/abs/2309.10701v1"},"cats":{"new-dataset":0.0328217504,"dev-research":0.1037384169,"data-quality":0.1191120834}}
{"text":"These bounds are then used to plan efficiently while keeping performance guarantees.","meta":{"url":"http://arxiv.org/abs/2309.10701v1"},"cats":{"new-dataset":0.0134722354,"dev-research":0.2657401089,"data-quality":0.055620295}}
{"text":"We show that the bounds are adaptive, computationally efficient, and that they converge to the original solution.","meta":{"url":"http://arxiv.org/abs/2309.10701v1"},"cats":{"new-dataset":0.0328735018,"dev-research":0.1591680668,"data-quality":0.1103213628}}
{"text":"We extend the partitioning paradigm and present a hierarchy of partitioned spaces that allows greater efficiency in planning.","meta":{"url":"http://arxiv.org/abs/2309.10701v1"},"cats":{"new-dataset":0.0717655963,"dev-research":0.2477660978,"data-quality":0.0391636373}}
{"text":"We then propose a specific variant of these bounds for Gaussian beliefs and show a theoretical performance improvement of at least a factor of 4.","meta":{"url":"http://arxiv.org/abs/2309.10701v1"},"cats":{"new-dataset":0.0629778729,"dev-research":0.1258449519,"data-quality":0.134362664}}
{"text":"Finally, we compare our novel method to other state of the art algorithms in active SLAM scenarios, in simulation and in real experiments.","meta":{"url":"http://arxiv.org/abs/2309.10701v1"},"cats":{"new-dataset":0.0905068826,"dev-research":0.1912424378,"data-quality":0.1016944915}}
{"text":"In both cases we show a significant speed-up in planning with performance guarantees.","meta":{"url":"http://arxiv.org/abs/2309.10701v1"},"cats":{"new-dataset":0.0215920436,"dev-research":0.273234185,"data-quality":0.046776699}}
{"text":"The number and arrangement of sensors on an autonomous mobile robot dramatically influence its perception capabilities.","meta":{"url":"http://arxiv.org/abs/2309.10698v1"},"cats":{"new-dataset":0.0352545032,"dev-research":0.1516087687,"data-quality":0.0742216571}}
{"text":"Ensuring that sensors are mounted in a manner that enables accurate detection, localization, and mapping is essential for the success of downstream control tasks.","meta":{"url":"http://arxiv.org/abs/2309.10698v1"},"cats":{"new-dataset":0.0426161123,"dev-research":0.2296261012,"data-quality":0.1195008408}}
{"text":"However, when designing a new robotic platform, researchers and practitioners alike usually mimic standard configurations or maximize simple heuristics like field-of-view (FOV) coverage to decide where to place exteroceptive sensors.","meta":{"url":"http://arxiv.org/abs/2309.10698v1"},"cats":{"new-dataset":0.0421947396,"dev-research":0.1707611472,"data-quality":0.0527541973}}
{"text":"In this work, we conduct an information-theoretic investigation of this overlooked element of mobile robotic perception in the context of simultaneous localization and mapping (SLAM).","meta":{"url":"http://arxiv.org/abs/2309.10698v1"},"cats":{"new-dataset":0.0255518054,"dev-research":0.1628743219,"data-quality":0.150712896}}
{"text":"We show how to formalize the sensor arrangement problem as a form of subset selection under the E-optimality performance criterion.","meta":{"url":"http://arxiv.org/abs/2309.10698v1"},"cats":{"new-dataset":0.0255998936,"dev-research":0.1834587179,"data-quality":0.0746941553}}
{"text":"While this formulation is NP-hard in general, we further show that a combination of greedy sensor selection and fast convex relaxation-based post-hoc verification enables the efficient recovery of certifiably optimal sensor designs in practice.","meta":{"url":"http://arxiv.org/abs/2309.10698v1"},"cats":{"new-dataset":0.0213156396,"dev-research":0.1887605041,"data-quality":0.0898505698}}
{"text":"Results from synthetic experiments reveal that sensors placed with OASIS outperform benchmarks in terms of mean squared error of visual SLAM estimates.","meta":{"url":"http://arxiv.org/abs/2309.10698v1"},"cats":{"new-dataset":0.0941368706,"dev-research":0.1892865784,"data-quality":0.1527330799}}
{"text":"The rise in popularity of Large Language Models (LLMs) has prompted discussions in academic circles, with students exploring LLM-based tools for coursework inquiries and instructors exploring them for teaching and research.","meta":{"url":"http://arxiv.org/abs/2309.10694v1"},"cats":{"new-dataset":0.0608038538,"dev-research":0.1967010702,"data-quality":0.0833609053}}
{"text":"Even though a lot of work is underway to create LLM-based tools tailored for students and instructors, there is a lack of comprehensive user studies that capture the perspectives of students and instructors regarding LLMs.","meta":{"url":"http://arxiv.org/abs/2309.10694v1"},"cats":{"new-dataset":0.0307881694,"dev-research":0.2521848699,"data-quality":0.0938348438}}
{"text":"This paper addresses this gap by conducting surveys and interviews within undergraduate engineering universities in India.","meta":{"url":"http://arxiv.org/abs/2309.10694v1"},"cats":{"new-dataset":0.0592556545,"dev-research":0.2965692198,"data-quality":0.1170407459}}
{"text":"Using 1306 survey responses among students, 112 student interviews, and 27 instructor interviews around the academic usage of ChatGPT (a popular LLM), this paper offers insights into the current usage patterns, perceived benefits, threats, and challenges, as well as recommendations for enhancing the adoption of LLMs among students and instructors.","meta":{"url":"http://arxiv.org/abs/2309.10694v1"},"cats":{"new-dataset":0.0564439215,"dev-research":0.2936995728,"data-quality":0.0762358473}}
{"text":"These insights are further utilized to discuss the practical implications of LLMs in undergraduate engineering education and beyond.","meta":{"url":"http://arxiv.org/abs/2309.10694v1"},"cats":{"new-dataset":0.0092762277,"dev-research":0.219272901,"data-quality":0.089143883}}
{"text":"To solve complex tasks, large language models (LLMs) often require multiple rounds of interactions with the user, sometimes assisted by external tools.","meta":{"url":"http://arxiv.org/abs/2309.10691v1"},"cats":{"new-dataset":0.038850739,"dev-research":0.2456153569,"data-quality":0.100291736}}
{"text":"However, current evaluation paradigms often focus solely on benchmark performance with single-turn exchanges, neglecting the intricate interactions among the user, LLMs, and external tools, creating a discrepancy between benchmark evaluation and real-world use cases.","meta":{"url":"http://arxiv.org/abs/2309.10691v1"},"cats":{"new-dataset":0.0039500573,"dev-research":0.2661503638,"data-quality":0.106166462}}
{"text":"We introduce MINT benchmark to evaluate LLMs' ability to solve tasks with multi-turn interactions by (1) using tools and (2) leveraging natural language feedback.","meta":{"url":"http://arxiv.org/abs/2309.10691v1"},"cats":{"new-dataset":0.126642735,"dev-research":0.2543010156,"data-quality":0.1776114357}}
{"text":"To ensure reproducibility, we provide an evaluation framework where LLMs can access tools by executing Python code and receive natural language feedback from the user simulated with GPT-4.","meta":{"url":"http://arxiv.org/abs/2309.10691v1"},"cats":{"new-dataset":0.2841076161,"dev-research":0.2992936553,"data-quality":0.1950924662}}
{"text":"We repurpose a diverse set of established datasets and tasks focusing on reasoning, coding, and decision-making and carefully curate them into a compact subset of instances for efficient evaluation.","meta":{"url":"http://arxiv.org/abs/2309.10691v1"},"cats":{"new-dataset":0.5126880473,"dev-research":0.301519168,"data-quality":0.1625822282}}
{"text":"Our analysis of 20 open- and closed-source LLMs offers intriguing findings.","meta":{"url":"http://arxiv.org/abs/2309.10691v1"},"cats":{"new-dataset":0.0842034842,"dev-research":0.1180428605,"data-quality":0.1428816255}}
{"text":"(1) LLMs generally benefit from tool interactions and language feedback, with performance gains (absolute, same below) of 1--8% per additional turn with tool use and 2--17% with natural language feedback.","meta":{"url":"http://arxiv.org/abs/2309.10691v1"},"cats":{"new-dataset":0.0140511967,"dev-research":0.2028818824,"data-quality":0.1569751967}}
{"text":"(2) Better single-turn performance does not guarantee better multi-turn performance.","meta":{"url":"http://arxiv.org/abs/2309.10691v1"},"cats":{"new-dataset":0.0017129334,"dev-research":0.1737397067,"data-quality":0.1016525679}}
{"text":"(3) Surprisingly, on LLMs we evaluated, we found supervised instruction-finetuning (SIFT) and reinforcement learning from human feedback (RLHF) generally hurt multi-turn capabilities.","meta":{"url":"http://arxiv.org/abs/2309.10691v1"},"cats":{"new-dataset":0.0327775529,"dev-research":0.1763924713,"data-quality":0.1091689871}}
{"text":"We hope MINT can help measure progress and incentivize research in improving LLMs' capabilities in multi-turn interactions, especially for open-source communities where multi-turn human evaluation has been less accessible compared to commercial LLMs with a larger user base.","meta":{"url":"http://arxiv.org/abs/2309.10691v1"},"cats":{"new-dataset":0.0571590543,"dev-research":0.1897578385,"data-quality":0.074881043}}
{"text":"In recent years, novel view synthesis from a single image has seen significant progress thanks to the rapid advancements in 3D scene representation and image inpainting techniques.","meta":{"url":"http://arxiv.org/abs/2309.10689v1"},"cats":{"new-dataset":0.1476311198,"dev-research":0.2079905505,"data-quality":0.0802285461}}
{"text":"While the current approaches are able to synthesize geometrically consistent novel views, they often do not handle the view-dependent effects properly.","meta":{"url":"http://arxiv.org/abs/2309.10689v1"},"cats":{"new-dataset":0.0071221612,"dev-research":0.2671455672,"data-quality":0.1533671471}}
{"text":"Specifically, the highlights in their synthesized images usually appear to be glued to the surfaces, making the novel views unrealistic.","meta":{"url":"http://arxiv.org/abs/2309.10689v1"},"cats":{"new-dataset":0.0700856113,"dev-research":0.2751875563,"data-quality":0.1009114371}}
{"text":"To address this major problem, we make a key observation that the process of synthesizing novel views requires changing the shading of the pixels based on the novel camera, and moving them to appropriate locations.","meta":{"url":"http://arxiv.org/abs/2309.10689v1"},"cats":{"new-dataset":0.0972401067,"dev-research":0.328904381,"data-quality":0.0904584638}}
{"text":"Therefore, we propose to split the view synthesis process into two independent tasks of pixel reshading and relocation.","meta":{"url":"http://arxiv.org/abs/2309.10689v1"},"cats":{"new-dataset":0.0627885993,"dev-research":0.2891196374,"data-quality":0.0636742364}}
{"text":"During the reshading process, we take the single image as the input and adjust its shading based on the novel camera.","meta":{"url":"http://arxiv.org/abs/2309.10689v1"},"cats":{"new-dataset":0.0471063726,"dev-research":0.1759428407,"data-quality":0.0675727863}}
{"text":"This reshaded image is then used as the input to an existing view synthesis method to relocate the pixels and produce the final novel view image.","meta":{"url":"http://arxiv.org/abs/2309.10689v1"},"cats":{"new-dataset":0.0672229146,"dev-research":0.2487422062,"data-quality":0.056910343}}
{"text":"We propose to use a neural network to perform reshading and generate a large set of synthetic input-reshaded pairs to train our network.","meta":{"url":"http://arxiv.org/abs/2309.10689v1"},"cats":{"new-dataset":0.3089356929,"dev-research":0.1684884656,"data-quality":0.098392508}}
{"text":"We demonstrate that our approach produces plausible novel view images with realistic moving highlights on a variety of real world scenes.","meta":{"url":"http://arxiv.org/abs/2309.10689v1"},"cats":{"new-dataset":0.3072916116,"dev-research":0.2134070001,"data-quality":0.1217634255}}
{"text":"Modern deep networks are trained with stochastic gradient descent (SGD) whose key parameters are the number of data considered at each step or batch size $B$, and the step size or learning rate $\\eta$.","meta":{"url":"http://arxiv.org/abs/2309.10688v1"},"cats":{"new-dataset":0.0574477063,"dev-research":0.1471893753,"data-quality":0.0902866732}}
{"text":"For small $B$ and large $\\eta$, SGD corresponds to a stochastic evolution of the parameters, whose noise amplitude is governed by the `temperature' $T\\equiv \\eta/B$.","meta":{"url":"http://arxiv.org/abs/2309.10688v1"},"cats":{"new-dataset":0.0209699022,"dev-research":0.1292043923,"data-quality":0.1163377256}}
{"text":"Yet this description is observed to break down for sufficiently large batches $B\\geq B^*$, or simplifies to gradient descent (GD) when the temperature is sufficiently small.","meta":{"url":"http://arxiv.org/abs/2309.10688v1"},"cats":{"new-dataset":0.0164625195,"dev-research":0.1189946285,"data-quality":0.1266140543}}
{"text":"Understanding where these cross-overs take place remains a central challenge.","meta":{"url":"http://arxiv.org/abs/2309.10688v1"},"cats":{"new-dataset":0.1103509806,"dev-research":0.1711750837,"data-quality":0.1088169789}}
{"text":"Here we resolve these questions for a teacher-student perceptron classification model, and show empirically that our key predictions still apply to deep networks.","meta":{"url":"http://arxiv.org/abs/2309.10688v1"},"cats":{"new-dataset":0.0516046794,"dev-research":0.1609040247,"data-quality":0.2612182778}}
{"text":"Specifically, we obtain a phase diagram in the $B$-$\\eta$ plane that separates three dynamical phases: $\\textit{(i)}$ a noise-dominated SGD governed by temperature, $\\textit{(ii)}$ a large-first-step-dominated SGD and $\\textit{(iii)}$ GD.","meta":{"url":"http://arxiv.org/abs/2309.10688v1"},"cats":{"new-dataset":0.0935606546,"dev-research":0.0943636921,"data-quality":0.0917945883}}
{"text":"These different phases also corresponds to different regimes of generalization error.","meta":{"url":"http://arxiv.org/abs/2309.10688v1"},"cats":{"new-dataset":0.0029040229,"dev-research":0.1624291626,"data-quality":0.2089886361}}
{"text":"Remarkably, our analysis reveals that the batch size $B^*$ separating regimes $\\textit{(i)}$ and $\\textit{(ii)}$ scale with the size $P$ of the training set, with an exponent that characterizes the hardness of the classification problem.","meta":{"url":"http://arxiv.org/abs/2309.10688v1"},"cats":{"new-dataset":0.0622051502,"dev-research":0.0974211982,"data-quality":0.3581021097}}
{"text":"In recent years, there has been increasing interest in applying stylization on 3D scenes from a reference style image, in particular onto neural radiance fields (NeRF).","meta":{"url":"http://arxiv.org/abs/2309.10684v1"},"cats":{"new-dataset":0.0606510692,"dev-research":0.1951104813,"data-quality":0.1376822131}}
{"text":"While performing stylization directly on NeRF guarantees appearance consistency over arbitrary novel views, it is a challenging problem to guide the transfer of patterns from the style image onto different parts of the NeRF scene.","meta":{"url":"http://arxiv.org/abs/2309.10684v1"},"cats":{"new-dataset":0.0214025476,"dev-research":0.270055909,"data-quality":0.2871810747}}
{"text":"In this work, we propose a stylization framework for NeRF based on local style transfer.","meta":{"url":"http://arxiv.org/abs/2309.10684v1"},"cats":{"new-dataset":0.0265013309,"dev-research":0.2999789967,"data-quality":0.2955278291}}
{"text":"In particular, we use a hash-grid encoding to learn the embedding of the appearance and geometry components, and show that the mapping defined by the hash table allows us to control the stylization to a certain extent.","meta":{"url":"http://arxiv.org/abs/2309.10684v1"},"cats":{"new-dataset":0.0780147696,"dev-research":0.188941268,"data-quality":0.1321963713}}
{"text":"Stylization is then achieved by optimizing the appearance branch while keeping the geometry branch fixed.","meta":{"url":"http://arxiv.org/abs/2309.10684v1"},"cats":{"new-dataset":0.0019950699,"dev-research":0.2477066911,"data-quality":0.1273562832}}
{"text":"To support local style transfer, we propose a new loss function that utilizes a segmentation network and bipartite matching to establish region correspondences between the style image and the content images obtained from volume rendering.","meta":{"url":"http://arxiv.org/abs/2309.10684v1"},"cats":{"new-dataset":0.0941172605,"dev-research":0.1469140189,"data-quality":0.2139652341}}
{"text":"Our experiments show that our method yields plausible stylization results with novel view synthesis while having flexible controllability via manipulating and customizing the region correspondences.","meta":{"url":"http://arxiv.org/abs/2309.10684v1"},"cats":{"new-dataset":0.0179431095,"dev-research":0.1634138252,"data-quality":0.1534073778}}
{"text":"Autonomous flight in unknown environments requires precise planning for both the spatial and temporal profiles of trajectories, which generally involves nonconvex optimization, leading to high time costs and susceptibility to local optima.","meta":{"url":"http://arxiv.org/abs/2309.10683v1"},"cats":{"new-dataset":0.0210498926,"dev-research":0.1765708446,"data-quality":0.0453624507}}
{"text":"To address these limitations, we introduce the Learning-Initialized Trajectory Planner (LIT-Planner), a novel approach that guides optimization using a Neural Network (NN) Planner to provide initial values.","meta":{"url":"http://arxiv.org/abs/2309.10683v1"},"cats":{"new-dataset":0.1184215778,"dev-research":0.2018431527,"data-quality":0.0549142962}}
{"text":"We first leverage the spatial-temporal optimization with batch sampling to generate training cases, aiming to capture multimodality in trajectories.","meta":{"url":"http://arxiv.org/abs/2309.10683v1"},"cats":{"new-dataset":0.3622085556,"dev-research":0.1291161677,"data-quality":0.1049767605}}
{"text":"Based on these data, the NN-Planner maps visual and inertial observations to trajectory parameters for handling unknown environments.","meta":{"url":"http://arxiv.org/abs/2309.10683v1"},"cats":{"new-dataset":0.2473917701,"dev-research":0.220566671,"data-quality":0.0407316724}}
{"text":"The network outputs are then optimized to enhance both reliability and explainability, ensuring robust performance.","meta":{"url":"http://arxiv.org/abs/2309.10683v1"},"cats":{"new-dataset":0.0027436477,"dev-research":0.3068725923,"data-quality":0.1930429244}}
{"text":"Furthermore, we propose a framework that supports robust online replanning with tolerance to planning latency.","meta":{"url":"http://arxiv.org/abs/2309.10683v1"},"cats":{"new-dataset":0.0517699165,"dev-research":0.2841474734,"data-quality":0.0740259432}}
{"text":"Comprehensive simulations validate the LIT-Planner's time efficiency without compromising trajectory quality compared to optimization-based methods.","meta":{"url":"http://arxiv.org/abs/2309.10683v1"},"cats":{"new-dataset":0.0119443304,"dev-research":0.2067114138,"data-quality":0.0326100777}}
{"text":"Real-world experiments further demonstrate its practical suitability for autonomous drone navigation.","meta":{"url":"http://arxiv.org/abs/2309.10683v1"},"cats":{"new-dataset":0.0290371593,"dev-research":0.150577654,"data-quality":0.0671511234}}
{"text":"This study analyzes the possible relationship between personality traits, in terms of Big Five (extraversion, agreeableness, responsibility, emotional stability and openness to experience), and social interactions mediated by digital platforms in different socioeconomic and cultural contexts.","meta":{"url":"http://arxiv.org/abs/2309.10681v1"},"cats":{"new-dataset":0.0984288366,"dev-research":0.2593347172,"data-quality":0.0596817167}}
{"text":"We considered data from a questionnaire and the experience of using a chatbot, as a mean of requesting and offering help, with students from 4 universities: University of Trento (Italy), the National University of Mongolia, the School of Economics of London (United Kingdom) and the Universidad Cat\\'olica Nuestra Se\\~nora de la Asunci\\'on (Paraguay).","meta":{"url":"http://arxiv.org/abs/2309.10681v1"},"cats":{"new-dataset":0.1268010419,"dev-research":0.2164995756,"data-quality":0.0762248563}}
{"text":"The main findings confirm that personality traits may influence social interactions and active participation in groups.","meta":{"url":"http://arxiv.org/abs/2309.10681v1"},"cats":{"new-dataset":0.019692827,"dev-research":0.255097668,"data-quality":0.0485795775}}
{"text":"Therefore, they should be taken into account to enrich the recommendation of matching algorithms between people who ask for help and people who could respond not only on the basis of their knowledge and skills.","meta":{"url":"http://arxiv.org/abs/2309.10681v1"},"cats":{"new-dataset":0.0077405583,"dev-research":0.2105182231,"data-quality":0.1222510104}}
{"text":"In this short paper we focus on human in the loop for rule-based software used for law enforcement.","meta":{"url":"http://arxiv.org/abs/2309.10678v1"},"cats":{"new-dataset":0.3738163261,"dev-research":0.3418400654,"data-quality":0.095923606}}
{"text":"For example, one can think of software that computes fines like tachograph software, software that prepares evidence like DNA sequencing software or social profiling software to patrol in high-risk zones, among others.","meta":{"url":"http://arxiv.org/abs/2309.10678v1"},"cats":{"new-dataset":0.1831468149,"dev-research":0.4939796753,"data-quality":0.1816695751}}
{"text":"An important difference between a legal human agent and a software application lies in possible dialogues.","meta":{"url":"http://arxiv.org/abs/2309.10678v1"},"cats":{"new-dataset":0.1281610288,"dev-research":0.4074428691,"data-quality":0.1010160202}}
{"text":"A human agent can be interrogated to motivate her decisions.","meta":{"url":"http://arxiv.org/abs/2309.10678v1"},"cats":{"new-dataset":0.0179417617,"dev-research":0.2839465282,"data-quality":0.0724305081}}
{"text":"Often such dialogues with software are at the best extremely hard but mostly impossible.","meta":{"url":"http://arxiv.org/abs/2309.10678v1"},"cats":{"new-dataset":0.0428634143,"dev-research":0.3691051196,"data-quality":0.1835917842}}
{"text":"We observe that the absence of a dialogue can sincerely violate civil rights and legal principles like, for example, Transparency or Contestability.","meta":{"url":"http://arxiv.org/abs/2309.10678v1"},"cats":{"new-dataset":0.0422380395,"dev-research":0.1800075706,"data-quality":0.1739344479}}
{"text":"Thus, possible dialogues with legal algorithms are at the least highly desirable.","meta":{"url":"http://arxiv.org/abs/2309.10678v1"},"cats":{"new-dataset":0.0265843166,"dev-research":0.2192142039,"data-quality":0.1284702504}}
{"text":"Futuristic as this may sound, we observe that in various realms of formal methods, such dialogues are easily obtainable.","meta":{"url":"http://arxiv.org/abs/2309.10678v1"},"cats":{"new-dataset":0.0387096565,"dev-research":0.2519737141,"data-quality":0.103717139}}
{"text":"However, this triggers the usual tension between the expressibility of the dialogue language and the feasibility of the corresponding computations.","meta":{"url":"http://arxiv.org/abs/2309.10678v1"},"cats":{"new-dataset":0.0138582949,"dev-research":0.2420182542,"data-quality":0.1691293693}}
{"text":"Data contamination in model evaluation is getting increasingly prevalent as the massive training corpora of large language models often unintentionally include benchmark samples.","meta":{"url":"http://arxiv.org/abs/2309.10677v1"},"cats":{"new-dataset":0.1209796834,"dev-research":0.2651187736,"data-quality":0.5269808116}}
{"text":"Therefore, contamination analysis has became an inevitable part of reliable model evaluation.","meta":{"url":"http://arxiv.org/abs/2309.10677v1"},"cats":{"new-dataset":0.0285488988,"dev-research":0.266776319,"data-quality":0.2421479305}}
{"text":"However, existing method of contamination analysis requires the access of the entire training data which is often confidential for recent models.","meta":{"url":"http://arxiv.org/abs/2309.10677v1"},"cats":{"new-dataset":0.1278384002,"dev-research":0.1776112872,"data-quality":0.2145511992}}
{"text":"This prevent the community to rigorously audit these models and conduct accurate assessment of their capability.","meta":{"url":"http://arxiv.org/abs/2309.10677v1"},"cats":{"new-dataset":0.0143551868,"dev-research":0.3391554009,"data-quality":0.1041836602}}
{"text":"In this paper, we propose a novel method to quantify contamination without the access of the full training set, that measure the extent of contamination with perplexity.","meta":{"url":"http://arxiv.org/abs/2309.10677v1"},"cats":{"new-dataset":0.2317286705,"dev-research":0.1946463375,"data-quality":0.4201258383}}
{"text":"Our analysis provides evidence of significant memorisation of recent foundation models in popular reading comprehension, summarisation benchmarks, while multiple choice appears less contaminated.","meta":{"url":"http://arxiv.org/abs/2309.10677v1"},"cats":{"new-dataset":0.0501822101,"dev-research":0.1788326123,"data-quality":0.1376608221}}
{"text":"Speaker extraction and diarization are two crucial enabling techniques for speech applications.","meta":{"url":"http://arxiv.org/abs/2309.10674v1"},"cats":{"new-dataset":0.0281842633,"dev-research":0.1492886824,"data-quality":0.2392048594}}
{"text":"Speaker extraction aims to extract a target speaker's voice from a multi-talk mixture, while speaker diarization demarcates speech segments by speaker, identifying `who spoke when'.","meta":{"url":"http://arxiv.org/abs/2309.10674v1"},"cats":{"new-dataset":0.0384353377,"dev-research":0.1702721059,"data-quality":0.1870285616}}
{"text":"The previous studies have typically treated the two tasks independently.","meta":{"url":"http://arxiv.org/abs/2309.10674v1"},"cats":{"new-dataset":0.0031103227,"dev-research":0.2107194826,"data-quality":0.0585707463}}
{"text":"However, the two tasks share a similar objective, that is to disentangle the speakers in the spectral domain for the former but in the temporal domain for the latter.","meta":{"url":"http://arxiv.org/abs/2309.10674v1"},"cats":{"new-dataset":0.0079720327,"dev-research":0.1467917585,"data-quality":0.1447402075}}
{"text":"It is logical to believe that the speaker turns obtained from speaker diarization can benefit speaker extraction, while the extracted speech offers more accurate speaker turns than the mixture speech.","meta":{"url":"http://arxiv.org/abs/2309.10674v1"},"cats":{"new-dataset":0.0098166197,"dev-research":0.1473444125,"data-quality":0.157700363}}
{"text":"In this paper, we propose a unified framework called Universal Speaker Extraction and Diarization (USED).","meta":{"url":"http://arxiv.org/abs/2309.10674v1"},"cats":{"new-dataset":0.1450802226,"dev-research":0.1137640186,"data-quality":0.2769552099}}
{"text":"We extend the existing speaker extraction model to simultaneously extract the waveforms of all speakers.","meta":{"url":"http://arxiv.org/abs/2309.10674v1"},"cats":{"new-dataset":0.0436594607,"dev-research":0.1135036537,"data-quality":0.1279453946}}
{"text":"We also employ a scenario-aware differentiated loss function to address the problem of sparsely overlapped speech in real-world conversations.","meta":{"url":"http://arxiv.org/abs/2309.10674v1"},"cats":{"new-dataset":0.131650171,"dev-research":0.1963458996,"data-quality":0.2296688436}}
{"text":"We show that the USED model significantly outperforms the baselines for both speaker extraction and diarization tasks, in both highly overlapped and sparsely overlapped scenarios.","meta":{"url":"http://arxiv.org/abs/2309.10674v1"},"cats":{"new-dataset":0.0817835691,"dev-research":0.1303362946,"data-quality":0.2184121376}}
{"text":"Audio samples are available at https://ajyy.github.io/demo/USED/.","meta":{"url":"http://arxiv.org/abs/2309.10674v1"},"cats":{"new-dataset":0.3696828295,"dev-research":0.1551950679,"data-quality":0.1832284095}}
{"text":"Robots often have to operate in discrete partially observable worlds, where the states of world are only observable at runtime.","meta":{"url":"http://arxiv.org/abs/2309.10672v1"},"cats":{"new-dataset":0.0139277989,"dev-research":0.1201971582,"data-quality":0.0640415151}}
{"text":"To react to different world states, robots need contingencies.","meta":{"url":"http://arxiv.org/abs/2309.10672v1"},"cats":{"new-dataset":0.0364057726,"dev-research":0.1738191453,"data-quality":0.078469572}}
{"text":"However, computing contingencies is costly and often non-optimal.","meta":{"url":"http://arxiv.org/abs/2309.10672v1"},"cats":{"new-dataset":0.0066697706,"dev-research":0.2969576519,"data-quality":0.0776162507}}
{"text":"To address this problem, we develop the improved path tree optimization (PTO) method.","meta":{"url":"http://arxiv.org/abs/2309.10672v1"},"cats":{"new-dataset":0.0155135208,"dev-research":0.2239435346,"data-quality":0.0916910885}}
{"text":"PTO computes motion contingencies by constructing a tree of motion paths in belief space.","meta":{"url":"http://arxiv.org/abs/2309.10672v1"},"cats":{"new-dataset":0.0523098485,"dev-research":0.1640506018,"data-quality":0.0644780908}}
{"text":"This is achieved by constructing a graph of configurations, then adding observation edges to extend the graph to belief space.","meta":{"url":"http://arxiv.org/abs/2309.10672v1"},"cats":{"new-dataset":0.0968436239,"dev-research":0.1671350373,"data-quality":0.0927523616}}
{"text":"Afterwards, we use a dynamic programming step to extract the path tree.","meta":{"url":"http://arxiv.org/abs/2309.10672v1"},"cats":{"new-dataset":0.0902009285,"dev-research":0.1879842655,"data-quality":0.1012855203}}
{"text":"PTO extends prior work by adding a camera-based state sampler to improve the search for observation points.","meta":{"url":"http://arxiv.org/abs/2309.10672v1"},"cats":{"new-dataset":0.0969786683,"dev-research":0.1361550933,"data-quality":0.0846688736}}
{"text":"We also add support to non-euclidean state spaces, provide an implementation in the open motion planning library (OMPL), and evaluate PTO on four realistic scenarios with a virtual camera in up to 10-dimensional state spaces.","meta":{"url":"http://arxiv.org/abs/2309.10672v1"},"cats":{"new-dataset":0.2492188358,"dev-research":0.1763597915,"data-quality":0.0362161235}}
{"text":"We compare PTO with a default and with the new camera-based state sampler.","meta":{"url":"http://arxiv.org/abs/2309.10672v1"},"cats":{"new-dataset":0.1343963737,"dev-research":0.1422810404,"data-quality":0.1098105128}}
{"text":"The results indicate that the camera-based state sampler improves success rates in 3 out of 4 scenarios while having a significant lower memory footprint.","meta":{"url":"http://arxiv.org/abs/2309.10672v1"},"cats":{"new-dataset":0.0454383013,"dev-research":0.1792557099,"data-quality":0.1162282465}}
{"text":"This makes PTO an important contribution to advance the state-of-the-art for discrete belief space planning.","meta":{"url":"http://arxiv.org/abs/2309.10672v1"},"cats":{"new-dataset":0.0303512812,"dev-research":0.169389015,"data-quality":0.0568378824}}
{"text":"Serverless computing is gaining traction as an attractive model for the deployment of a multitude of workloads in the cloud.","meta":{"url":"http://arxiv.org/abs/2309.10671v1"},"cats":{"new-dataset":0.0282374854,"dev-research":0.1816726363,"data-quality":0.0676033582}}
{"text":"Designing and building effective resource management solutions for any computing environment requires extensive long term testing, experimentation and analysis of the achieved performance metrics.","meta":{"url":"http://arxiv.org/abs/2309.10671v1"},"cats":{"new-dataset":0.0569914536,"dev-research":0.3262412808,"data-quality":0.0733601747}}
{"text":"Utilizing real test beds and serverless platforms for such experimentation work is often times not possible due to resource, time and cost constraints.","meta":{"url":"http://arxiv.org/abs/2309.10671v1"},"cats":{"new-dataset":0.0210830372,"dev-research":0.2053723316,"data-quality":0.0860363113}}
{"text":"Thus, employing simulators to model these environments is key to overcoming the challenge of examining the viability of such novel ideas for resource management.","meta":{"url":"http://arxiv.org/abs/2309.10671v1"},"cats":{"new-dataset":0.0406577784,"dev-research":0.2458058333,"data-quality":0.0790826506}}
{"text":"Existing simulation software developed for serverless environments lack generalizibility in terms of their architecture as well as the various aspects of resource management, where most are purely focused on modeling function performance under a specific platform architecture.","meta":{"url":"http://arxiv.org/abs/2309.10671v1"},"cats":{"new-dataset":0.03072569,"dev-research":0.1939020296,"data-quality":0.0573290156}}
{"text":"In contrast, we have developed a serverless simulation model with induced flexibility in its architecture as well as the key resource management aspects of function scheduling and scaling.","meta":{"url":"http://arxiv.org/abs/2309.10671v1"},"cats":{"new-dataset":0.0255109158,"dev-research":0.1727474679,"data-quality":0.0392306511}}
{"text":"Further, we incorporate techniques for easily deriving monitoring metrics required for evaluating any implemented solutions by users.","meta":{"url":"http://arxiv.org/abs/2309.10671v1"},"cats":{"new-dataset":0.0880555791,"dev-research":0.4466914793,"data-quality":0.1855526922}}
{"text":"Our work is presented as CloudSimSC, a modular extension to CloudSim which is a simulator tool extensively used for modeling cloud environments by the research community.","meta":{"url":"http://arxiv.org/abs/2309.10671v1"},"cats":{"new-dataset":0.4368761711,"dev-research":0.1785792693,"data-quality":0.0565958767}}
{"text":"We discuss the implemented features in our simulation tool using multiple use cases.","meta":{"url":"http://arxiv.org/abs/2309.10671v1"},"cats":{"new-dataset":0.0351355115,"dev-research":0.3305782147,"data-quality":0.081471227}}
{"text":"It has long been established that predictive models can be transformed into lossless compressors and vice versa.","meta":{"url":"http://arxiv.org/abs/2309.10668v1"},"cats":{"new-dataset":0.0059944538,"dev-research":0.1501739516,"data-quality":0.0916575095}}
{"text":"Incidentally, in recent years, the machine learning community has focused on training increasingly large and powerful self-supervised (language) models.","meta":{"url":"http://arxiv.org/abs/2309.10668v1"},"cats":{"new-dataset":0.1594056427,"dev-research":0.1917503223,"data-quality":0.2231622899}}
{"text":"Since these large language models exhibit impressive predictive capabilities, they are well-positioned to be strong compressors.","meta":{"url":"http://arxiv.org/abs/2309.10668v1"},"cats":{"new-dataset":0.045849824,"dev-research":0.165192152,"data-quality":0.132961332}}
{"text":"In this work, we advocate for viewing the prediction problem through the lens of compression and evaluate the compression capabilities of large (foundation) models.","meta":{"url":"http://arxiv.org/abs/2309.10668v1"},"cats":{"new-dataset":0.1148832255,"dev-research":0.1310540062,"data-quality":0.0805578865}}
{"text":"We show that large language models are powerful general-purpose predictors and that the compression viewpoint provides novel insights into scaling laws, tokenization, and in-context learning.","meta":{"url":"http://arxiv.org/abs/2309.10668v1"},"cats":{"new-dataset":0.1350878652,"dev-research":0.1420179383,"data-quality":0.193068134}}
{"text":"For example, Chinchilla 70B, while trained primarily on text, compresses ImageNet patches to 43.4% and LibriSpeech samples to 16.4% of their raw size, beating domain-specific compressors like PNG (58.5%) or FLAC (30.3%), respectively.","meta":{"url":"http://arxiv.org/abs/2309.10668v1"},"cats":{"new-dataset":0.0801033448,"dev-research":0.1399936878,"data-quality":0.2341225562}}
{"text":"Finally, we show that the prediction-compression equivalence allows us to use any compressor (like gzip) to build a conditional generative model.","meta":{"url":"http://arxiv.org/abs/2309.10668v1"},"cats":{"new-dataset":0.0388616353,"dev-research":0.1676189281,"data-quality":0.0887255443}}
{"text":"We focus on the task of soundscape mapping, which involves predicting the most probable sounds that could be perceived at a particular geographic location.","meta":{"url":"http://arxiv.org/abs/2309.10667v1"},"cats":{"new-dataset":0.0613736311,"dev-research":0.1567891094,"data-quality":0.1556375608}}
{"text":"We utilise recent state-of-the-art models to encode geotagged audio, a textual description of the audio, and an overhead image of its capture location using contrastive pre-training.","meta":{"url":"http://arxiv.org/abs/2309.10667v1"},"cats":{"new-dataset":0.320713977,"dev-research":0.1470329504,"data-quality":0.2357242351}}
{"text":"The end result is a shared embedding space for the three modalities, which enables the construction of soundscape maps for any geographic region from textual or audio queries.","meta":{"url":"http://arxiv.org/abs/2309.10667v1"},"cats":{"new-dataset":0.201996226,"dev-research":0.1600148072,"data-quality":0.2137495392}}
{"text":"Using the SoundingEarth dataset, we find that our approach significantly outperforms the existing SOTA, with an improvement of image-to-audio Recall@100 from 0.256 to 0.450.","meta":{"url":"http://arxiv.org/abs/2309.10667v1"},"cats":{"new-dataset":0.3935747002,"dev-research":0.1169766128,"data-quality":0.2568044725}}
{"text":"Our code is available at https://github.com/mvrl/geoclap.","meta":{"url":"http://arxiv.org/abs/2309.10667v1"},"cats":{"new-dataset":0.1695232923,"dev-research":0.2455274945,"data-quality":0.0881010267}}
{"text":"We present Fast-dRRT*, a sampling-based multi-robot planner, for real-time industrial automation scenarios.","meta":{"url":"http://arxiv.org/abs/2309.10665v1"},"cats":{"new-dataset":0.2181606951,"dev-research":0.2306942239,"data-quality":0.0383403662}}
{"text":"Fast-dRRT* builds upon the discrete rapidly-exploring random tree (dRRT*) planner, and extends dRRT*","meta":{"url":"http://arxiv.org/abs/2309.10665v1"},"cats":{"new-dataset":0.1115596696,"dev-research":0.1908425374,"data-quality":0.0493488751}}
{"text":"by using pre-computed swept volumes for efficient collision detection, deadlock avoidance for partial multi-robot problems, and a simplified rewiring strategy.","meta":{"url":"http://arxiv.org/abs/2309.10665v1"},"cats":{"new-dataset":0.0335055515,"dev-research":0.1842401952,"data-quality":0.073648814}}
{"text":"We evaluate Fast-dRRT* on five challenging multi-robot scenarios using two to four industrial robot arms from various manufacturers.","meta":{"url":"http://arxiv.org/abs/2309.10665v1"},"cats":{"new-dataset":0.0604230372,"dev-research":0.2061725913,"data-quality":0.0441353133}}
{"text":"The scenarios comprise situations involving deadlocks, narrow passages, and close proximity tasks.","meta":{"url":"http://arxiv.org/abs/2309.10665v1"},"cats":{"new-dataset":0.0435242746,"dev-research":0.3145334834,"data-quality":0.0893797701}}
{"text":"The results are compared against dRRT*, and show Fast-dRRT* to outperform dRRT*","meta":{"url":"http://arxiv.org/abs/2309.10665v1"},"cats":{"new-dataset":0.0580534059,"dev-research":0.1839234071,"data-quality":0.1622483202}}
{"text":"by up to 94% in terms of finding solutions within given time limits, while only sacrificing up to 35% on initial solution cost.","meta":{"url":"http://arxiv.org/abs/2309.10665v1"},"cats":{"new-dataset":0.0229679287,"dev-research":0.1958622675,"data-quality":0.0590894737}}
{"text":"Furthermore, Fast-dRRT* demonstrates resilience against noise in target configurations, and is able to solve challenging welding, and pick and place tasks with reduced computational time.","meta":{"url":"http://arxiv.org/abs/2309.10665v1"},"cats":{"new-dataset":0.0201352878,"dev-research":0.2999353919,"data-quality":0.0838880196}}
{"text":"This makes Fast-dRRT* a promising option for real-time motion planning in industrial automation.","meta":{"url":"http://arxiv.org/abs/2309.10665v1"},"cats":{"new-dataset":0.0574986455,"dev-research":0.312109,"data-quality":0.0298550124}}
{"text":"An auditable register extends the classical register with an audit operation that returns information on the read operations performed on the register.","meta":{"url":"http://arxiv.org/abs/2309.10664v1"},"cats":{"new-dataset":0.0558697306,"dev-research":0.2433839576,"data-quality":0.1274237713}}
{"text":"In this paper, we study Byzantine resilient auditable register implementations in an asynchronous message-passing system.","meta":{"url":"http://arxiv.org/abs/2309.10664v1"},"cats":{"new-dataset":0.0643728894,"dev-research":0.2293613898,"data-quality":0.1620345862}}
{"text":"Existing solutions implement the auditable register on top of at least 4f+1 servers, where at most $f$ can be Byzantine.","meta":{"url":"http://arxiv.org/abs/2309.10664v1"},"cats":{"new-dataset":0.1146451765,"dev-research":0.1200622184,"data-quality":0.1395340658}}
{"text":"We show that 4f+1 servers are necessary to implement auditability without communication between servers, or implement does not implement strong auditability when relaxing the constraint on the servers' communication, letting them interact with each other.","meta":{"url":"http://arxiv.org/abs/2309.10664v1"},"cats":{"new-dataset":0.0369523617,"dev-research":0.266227302,"data-quality":0.1418067862}}
{"text":"In this setting, it exists a solution using 3f+1 servers to implement a simple auditable atomic register.","meta":{"url":"http://arxiv.org/abs/2309.10664v1"},"cats":{"new-dataset":0.07734756,"dev-research":0.163256395,"data-quality":0.1663562479}}
{"text":"In this work, we implement strong auditable register using 3f+1 servers with server to server communication, this result reinforced that with communication between servers, auditability (event strong auditability) does not come with an additional cost in terms of the number of servers.","meta":{"url":"http://arxiv.org/abs/2309.10664v1"},"cats":{"new-dataset":0.1032902905,"dev-research":0.211021823,"data-quality":0.1481343218}}
{"text":"We revisit the a priori TSP (with independent activation) and prove stronger approximation guarantees than were previously known.","meta":{"url":"http://arxiv.org/abs/2309.10663v1"},"cats":{"new-dataset":0.0069206512,"dev-research":0.1125470759,"data-quality":0.1020380724}}
{"text":"In the a priori TSP, we are given a metric space $(V,c)$ and an activation probability $p(v)$ for each customer $v\\in V$.","meta":{"url":"http://arxiv.org/abs/2309.10663v1"},"cats":{"new-dataset":0.0384745803,"dev-research":0.1604051627,"data-quality":0.1477471053}}
{"text":"We ask for a TSP tour $T$ for $V$ that minimizes the expected length after cutting $T$ short by skipping the inactive customers.","meta":{"url":"http://arxiv.org/abs/2309.10663v1"},"cats":{"new-dataset":0.0165055794,"dev-research":0.13724404,"data-quality":0.0911299494}}
{"text":"All known approximation algorithms select a nonempty subset $S$ of the customers and construct a master route solution, consisting of a TSP tour for $S$ and two edges connecting every customer $v\\in V\\setminus S$ to a nearest customer in $S$. We address the following questions.","meta":{"url":"http://arxiv.org/abs/2309.10663v1"},"cats":{"new-dataset":0.0176327992,"dev-research":0.1317630638,"data-quality":0.0930145822}}
{"text":"If we randomly sample the subset $S$, what should be the sampling probabilities?","meta":{"url":"http://arxiv.org/abs/2309.10663v1"},"cats":{"new-dataset":0.1030874465,"dev-research":0.1223534141,"data-quality":0.1660751001}}
{"text":"How much worse than the optimum can the best master route solution be?","meta":{"url":"http://arxiv.org/abs/2309.10663v1"},"cats":{"new-dataset":0.0019703228,"dev-research":0.1389679842,"data-quality":0.0724556014}}
{"text":"The answers to these questions (we provide almost matching lower and upper bounds) lead to improved approximation guarantees: less than 3.1 with randomized sampling, and less than 5.9 with a deterministic polynomial-time algorithm.","meta":{"url":"http://arxiv.org/abs/2309.10663v1"},"cats":{"new-dataset":0.0352204755,"dev-research":0.1125135497,"data-quality":0.1230784899}}
{"text":"Democratizing access to natural language processing (NLP) technology is crucial, especially for underrepresented and extremely low-resource languages.","meta":{"url":"http://arxiv.org/abs/2309.10661v1"},"cats":{"new-dataset":0.0452719331,"dev-research":0.3016943385,"data-quality":0.2708769575}}
{"text":"Previous research has focused on developing labeled and unlabeled corpora for these languages through online scraping and document translation.","meta":{"url":"http://arxiv.org/abs/2309.10661v1"},"cats":{"new-dataset":0.360520936,"dev-research":0.198825984,"data-quality":0.3705034045}}
{"text":"While these methods have proven effective and cost-efficient, we have identified limitations in the resulting corpora, including a lack of lexical diversity and cultural relevance to local communities.","meta":{"url":"http://arxiv.org/abs/2309.10661v1"},"cats":{"new-dataset":0.1022178299,"dev-research":0.2182195628,"data-quality":0.3214948903}}
{"text":"To address this gap, we conduct a case study on Indonesian local languages.","meta":{"url":"http://arxiv.org/abs/2309.10661v1"},"cats":{"new-dataset":0.1951728449,"dev-research":0.2668848266,"data-quality":0.2079958371}}
{"text":"We compare the effectiveness of online scraping, human translation, and paragraph writing by native speakers in constructing datasets.","meta":{"url":"http://arxiv.org/abs/2309.10661v1"},"cats":{"new-dataset":0.5692028809,"dev-research":0.2435757789,"data-quality":0.188507503}}
{"text":"Our findings demonstrate that datasets generated through paragraph writing by native speakers exhibit superior quality in terms of lexical diversity and cultural content.","meta":{"url":"http://arxiv.org/abs/2309.10661v1"},"cats":{"new-dataset":0.2605198157,"dev-research":0.2364412718,"data-quality":0.3363260512}}
{"text":"In addition, we present the \\datasetname{} benchmark, encompassing 12 underrepresented and extremely low-resource languages spoken by millions of individuals in Indonesia.","meta":{"url":"http://arxiv.org/abs/2309.10661v1"},"cats":{"new-dataset":0.7640448565,"dev-research":0.1537491227,"data-quality":0.2679217878}}
{"text":"Our empirical experiment results using existing multilingual large language models conclude the need to extend these models to more underrepresented languages.","meta":{"url":"http://arxiv.org/abs/2309.10661v1"},"cats":{"new-dataset":0.0683901482,"dev-research":0.1773898717,"data-quality":0.2112514903}}
{"text":"We release the NusaWrites dataset at https://github.com/IndoNLP/nusa-writes.","meta":{"url":"http://arxiv.org/abs/2309.10661v1"},"cats":{"new-dataset":0.8847176584,"dev-research":0.1857875228,"data-quality":0.1831819595}}
{"text":"Various time variant non-stationary signals need to be pre-processed properly in hydrological time series forecasting in real world, for example, predictions of water level.","meta":{"url":"http://arxiv.org/abs/2309.10658v1"},"cats":{"new-dataset":0.0341746822,"dev-research":0.1817079581,"data-quality":0.0635665074}}
{"text":"Decomposition method is a good candidate and widely used in such a pre-processing problem.","meta":{"url":"http://arxiv.org/abs/2309.10658v1"},"cats":{"new-dataset":0.0380817488,"dev-research":0.1898381735,"data-quality":0.0918467054}}
{"text":"However, decomposition methods with an inappropriate sampling technique may introduce future data which is not available in practical applications, and result in incorrect decomposition-based forecasting models.","meta":{"url":"http://arxiv.org/abs/2309.10658v1"},"cats":{"new-dataset":0.0160356015,"dev-research":0.163549915,"data-quality":0.1177603049}}
{"text":"In this work, a novel Fully Stepwise Decomposition-Based (FSDB) sampling technique is well designed for the decomposition-based forecasting model, strictly avoiding introducing future information.","meta":{"url":"http://arxiv.org/abs/2309.10658v1"},"cats":{"new-dataset":0.030763576,"dev-research":0.1328974231,"data-quality":0.0911011166}}
{"text":"This sampling technique with decomposition methods, such as Variational Mode Decomposition (VMD) and Singular spectrum analysis (SSA), is applied to predict water level time series in three different stations of Guoyang and Chaohu basins in China.","meta":{"url":"http://arxiv.org/abs/2309.10658v1"},"cats":{"new-dataset":0.0447538958,"dev-research":0.1176121306,"data-quality":0.0711064432}}
{"text":"Results of VMD-based hybrid model using FSDB sampling technique show that Nash-Sutcliffe Efficiency (NSE) coefficient is increased by 6.4%, 28.8% and 7.0% in three stations respectively, compared with those obtained from the currently most advanced sampling technique.","meta":{"url":"http://arxiv.org/abs/2309.10658v1"},"cats":{"new-dataset":0.0109576119,"dev-research":0.0923467485,"data-quality":0.0870464917}}
{"text":"In the meantime, for series of SSA-based experiments, NSE is increased by 3.2%, 3.1% and 1.1% respectively.","meta":{"url":"http://arxiv.org/abs/2309.10658v1"},"cats":{"new-dataset":0.0172511262,"dev-research":0.1791006563,"data-quality":0.0912725545}}
{"text":"We conclude that the newly developed FSDB sampling technique can be used to enhance the performance of decomposition-based hybrid model in water level time series forecasting in real world.","meta":{"url":"http://arxiv.org/abs/2309.10658v1"},"cats":{"new-dataset":0.0335698474,"dev-research":0.1185065864,"data-quality":0.0791963091}}
{"text":"Ensuring safety in dynamic multi-agent systems is challenging due to limited information about the other agents.","meta":{"url":"http://arxiv.org/abs/2309.10657v1"},"cats":{"new-dataset":0.095912709,"dev-research":0.2517216824,"data-quality":0.0867564295}}
{"text":"Control Barrier Functions (CBFs) are showing promise for safety assurance but current methods make strong assumptions about other agents and often rely on manual tuning to balance safety, feasibility, and performance.","meta":{"url":"http://arxiv.org/abs/2309.10657v1"},"cats":{"new-dataset":0.0334929054,"dev-research":0.2414889047,"data-quality":0.0753957372}}
{"text":"In this work, we delve into the problem of adaptive safe learning for multi-agent systems with CBF.","meta":{"url":"http://arxiv.org/abs/2309.10657v1"},"cats":{"new-dataset":0.1288455934,"dev-research":0.1638458214,"data-quality":0.1581656296}}
{"text":"We show how emergent behavior can be profoundly influenced by the CBF configuration, highlighting the necessity for a responsive and dynamic approach to CBF design.","meta":{"url":"http://arxiv.org/abs/2309.10657v1"},"cats":{"new-dataset":0.0403624464,"dev-research":0.2113827063,"data-quality":0.0630564514}}
{"text":"We present ASRL, a novel adaptive safe RL framework, to fully automate the optimization of policy and CBF coefficients, to enhance safety and long-term performance through reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2309.10657v1"},"cats":{"new-dataset":0.1564342662,"dev-research":0.1986285957,"data-quality":0.0983870268}}
{"text":"By directly interacting with the other agents, ASRL learns to cope with diverse agent behaviours and maintains the cost violations below a desired limit.","meta":{"url":"http://arxiv.org/abs/2309.10657v1"},"cats":{"new-dataset":0.0615807937,"dev-research":0.2127842385,"data-quality":0.0669980528}}
{"text":"We evaluate ASRL in a multi-robot system and a competitive multi-agent racing scenario, against learning-based and control-theoretic approaches.","meta":{"url":"http://arxiv.org/abs/2309.10657v1"},"cats":{"new-dataset":0.0824740302,"dev-research":0.1389344664,"data-quality":0.0548115177}}
{"text":"We empirically demonstrate the efficacy and flexibility of ASRL, and assess generalization and scalability to out-of-distribution scenarios.","meta":{"url":"http://arxiv.org/abs/2309.10657v1"},"cats":{"new-dataset":0.021809621,"dev-research":0.2237758956,"data-quality":0.1102525395}}
{"text":"Code and supplementary material are public online.","meta":{"url":"http://arxiv.org/abs/2309.10657v1"},"cats":{"new-dataset":0.4315492461,"dev-research":0.2315652946,"data-quality":0.1066229208}}
{"text":"Despite the growing availability of sensing and data in general, we remain unable to fully characterise many in-service engineering systems and structures from a purely data-driven approach.","meta":{"url":"http://arxiv.org/abs/2309.10656v1"},"cats":{"new-dataset":0.1526679442,"dev-research":0.2510641768,"data-quality":0.1078881175}}
{"text":"The vast data and resources available to capture human activity are unmatched in our engineered world, and, even in cases where data could be referred to as ``big,'' they will rarely hold information across operational windows or life spans.","meta":{"url":"http://arxiv.org/abs/2309.10656v1"},"cats":{"new-dataset":0.5313877324,"dev-research":0.2465279068,"data-quality":0.0718927548}}
{"text":"This paper pursues the combination of machine learning technology and physics-based reasoning to enhance our ability to make predictive models with limited data.","meta":{"url":"http://arxiv.org/abs/2309.10656v1"},"cats":{"new-dataset":0.0589734188,"dev-research":0.1397764442,"data-quality":0.048228954}}
{"text":"By explicitly linking the physics-based view of stochastic processes with a data-based regression approach, a spectrum of possible Gaussian process models are introduced that enable the incorporation of different levels of expert knowledge of a system.","meta":{"url":"http://arxiv.org/abs/2309.10656v1"},"cats":{"new-dataset":0.0281517065,"dev-research":0.2097528139,"data-quality":0.0765775789}}
{"text":"Examples illustrate how these approaches can significantly reduce reliance on data collection whilst also increasing the interpretability of the model, another important consideration in this context.","meta":{"url":"http://arxiv.org/abs/2309.10656v1"},"cats":{"new-dataset":0.0429370698,"dev-research":0.3000465093,"data-quality":0.1814696349}}
{"text":"Generating a smooth and shorter spiral complete coverage path in a multi-connected domain is an important research area in robotic cavity machining.","meta":{"url":"http://arxiv.org/abs/2309.10655v1"},"cats":{"new-dataset":0.0156856981,"dev-research":0.2044321307,"data-quality":0.0761333593}}
{"text":"Traditional spiral path planning methods in multi-connected domains involve a subregion division procedure; a deformed spiral path is incorporated within each subregion, and these paths within the subregions are interconnected with bridges.","meta":{"url":"http://arxiv.org/abs/2309.10655v1"},"cats":{"new-dataset":0.0171245061,"dev-research":0.2430718314,"data-quality":0.0495638037}}
{"text":"In intricate domains with abundant voids and irregular boundaries, the added subregion boundaries increase the path avoidance requirements.","meta":{"url":"http://arxiv.org/abs/2309.10655v1"},"cats":{"new-dataset":0.0141955337,"dev-research":0.2210593175,"data-quality":0.0895041816}}
{"text":"This results in excessive bridging and necessitates longer uneven-density spirals to achieve complete subregion coverage.","meta":{"url":"http://arxiv.org/abs/2309.10655v1"},"cats":{"new-dataset":0.0177690791,"dev-research":0.2142347641,"data-quality":0.0721979096}}
{"text":"Considering that conformal slit mapping can transform multi-connected regions into regular disks or annuluses without subregion division, this paper presents a novel spiral complete coverage path planning method by conformal slit mapping.","meta":{"url":"http://arxiv.org/abs/2309.10655v1"},"cats":{"new-dataset":0.0413707307,"dev-research":0.2521857902,"data-quality":0.0794120343}}
{"text":"Firstly, a slit mapping calculation technique is proposed for segmented cubic spline boundaries with corners.","meta":{"url":"http://arxiv.org/abs/2309.10655v1"},"cats":{"new-dataset":0.1036387792,"dev-research":0.2376013002,"data-quality":0.1022710632}}
{"text":"Then, a spiral path spacing control method is developed based on the maximum inscribed circle radius between adjacent conformal slit mapping iso-parameters.","meta":{"url":"http://arxiv.org/abs/2309.10655v1"},"cats":{"new-dataset":0.0118604503,"dev-research":0.2249435086,"data-quality":0.0887603021}}
{"text":"Lastly, the spiral path is derived by offsetting iso-parameters.","meta":{"url":"http://arxiv.org/abs/2309.10655v1"},"cats":{"new-dataset":0.0256070728,"dev-research":0.1370505552,"data-quality":0.0915046019}}
{"text":"The complexity and applicability of the proposed method are comprehensively analyzed across various boundary scenarios.","meta":{"url":"http://arxiv.org/abs/2309.10655v1"},"cats":{"new-dataset":0.004664315,"dev-research":0.2164653091,"data-quality":0.0607974675}}
{"text":"Meanwhile, two cavities milling experiments are conducted to compare the new method with conventional spiral complete coverage path methods.","meta":{"url":"http://arxiv.org/abs/2309.10655v1"},"cats":{"new-dataset":0.0076929696,"dev-research":0.1764469375,"data-quality":0.0849039538}}
{"text":"The comparation indicate that the new path meets the requirement for complete coverage in cavity machining while reducing path length and machining time by 12.70% and 12.34%, respectively.","meta":{"url":"http://arxiv.org/abs/2309.10655v1"},"cats":{"new-dataset":0.0121649892,"dev-research":0.2334066356,"data-quality":0.0823809838}}
{"text":"Large language models (LLMs) have demonstrated great potential in natural language processing tasks within the financial domain.","meta":{"url":"http://arxiv.org/abs/2309.10654v1"},"cats":{"new-dataset":0.0774711167,"dev-research":0.1190188693,"data-quality":0.1968629225}}
{"text":"In this work, we present a Chinese Financial Generative Pre-trained Transformer framework, named CFGPT, which includes a dataset~(CFData) for pre-training and supervised fine-tuning, a financial LLM~(CFLLM) to adeptly manage financial texts, and a deployment framework~(CFAPP) designed to navigate real-world financial applications.","meta":{"url":"http://arxiv.org/abs/2309.10654v1"},"cats":{"new-dataset":0.2176411857,"dev-research":0.1731393912,"data-quality":0.166153069}}
{"text":"The CFData comprising both a pre-training dataset and a supervised fine-tuning dataset, where the pre-training dataset collates Chinese financial data and analytics, alongside a smaller subset of general-purpose text with 584M documents and 141B tokens in total, and the supervised fine-tuning dataset is tailored for six distinct financial tasks, embodying various facets of financial analysis and decision-making with 1.5M instruction pairs and 1.5B tokens in total.","meta":{"url":"http://arxiv.org/abs/2309.10654v1"},"cats":{"new-dataset":0.5448447563,"dev-research":0.1950612475,"data-quality":0.2480179137}}
{"text":"The CFLLM, which is based on InternLM-7B to balance the model capability and size, is trained on CFData in two stage, continued pre-training and supervised fine-tuning.","meta":{"url":"http://arxiv.org/abs/2309.10654v1"},"cats":{"new-dataset":0.1825993946,"dev-research":0.1370612723,"data-quality":0.1093923958}}
{"text":"The CFAPP is centered on large language models (LLMs) and augmented with additional modules to ensure multifaceted functionality in real-world application.","meta":{"url":"http://arxiv.org/abs/2309.10654v1"},"cats":{"new-dataset":0.1435813445,"dev-research":0.1791900951,"data-quality":0.0932935992}}
{"text":"Our codes are released at https://github.com/TongjiFinLab/CFGPT.","meta":{"url":"http://arxiv.org/abs/2309.10654v1"},"cats":{"new-dataset":0.4844447574,"dev-research":0.1798830579,"data-quality":0.1239654822}}
{"text":"In this paper, we present a discrete formulation of nonlinear shear- and torsion-free rods based on \\cite{gebhardt_2021_beam} that uses isogeometric discretization and robust time integration.","meta":{"url":"http://arxiv.org/abs/2309.10652v1"},"cats":{"new-dataset":0.0302806769,"dev-research":0.1711005014,"data-quality":0.0878410804}}
{"text":"Omitting the director as an independent variable field, we reduce the number of degrees of freedom and obtain discrete solutions in multiple copies of the Euclidean space $\\left(\\mathbb{R}^3\\right)$, which is larger than the corresponding multiple copies of the manifold $\\left(\\mathbb{R}^3 \\cross S^2\\right)$ obtained with standard Hermite finite elements.","meta":{"url":"http://arxiv.org/abs/2309.10652v1"},"cats":{"new-dataset":0.1463118943,"dev-research":0.1283264121,"data-quality":0.0757017894}}
{"text":"For implicit time integration, we choose a hybrid form of the mid-point rule and the trapezoidal rule that preserves the linear angular momentum exactly and approximates the energy accurately.","meta":{"url":"http://arxiv.org/abs/2309.10652v1"},"cats":{"new-dataset":0.0076049933,"dev-research":0.1832584764,"data-quality":0.0775811566}}
{"text":"In addition, we apply a recently introduced approach for outlier removal \\cite{hiemstra_outlier_2021} that reduces high-frequency content in the response without affecting the accuracy, ensuring robustness of our nonlinear discrete formulation.","meta":{"url":"http://arxiv.org/abs/2309.10652v1"},"cats":{"new-dataset":0.064623878,"dev-research":0.1307646902,"data-quality":0.3234768649}}
{"text":"We illustrate the efficiency of our nonlinear discrete formulation for static and transient rods under different loading conditions, demonstrating good accuracy in space, time and the frequency domain.","meta":{"url":"http://arxiv.org/abs/2309.10652v1"},"cats":{"new-dataset":0.0293352663,"dev-research":0.1895589698,"data-quality":0.1260756909}}
{"text":"Our numerical example coincides with a relevant application case, the simulation of mooring lines.","meta":{"url":"http://arxiv.org/abs/2309.10652v1"},"cats":{"new-dataset":0.0320727535,"dev-research":0.1781401275,"data-quality":0.0976477674}}
{"text":"Whole Slide Images (WSIs) present a challenging computer vision task due to their gigapixel size and presence of numerous artefacts.","meta":{"url":"http://arxiv.org/abs/2309.10650v1"},"cats":{"new-dataset":0.1727133021,"dev-research":0.1843003972,"data-quality":0.1108077159}}
{"text":"Yet they are a valuable resource for patient diagnosis and stratification, often representing the gold standard for diagnostic tasks.","meta":{"url":"http://arxiv.org/abs/2309.10650v1"},"cats":{"new-dataset":0.0319065794,"dev-research":0.2116104734,"data-quality":0.1435796506}}
{"text":"Real-world clinical datasets tend to come as sets of heterogeneous WSIs with labels present at the patient-level, with poor to no annotations.","meta":{"url":"http://arxiv.org/abs/2309.10650v1"},"cats":{"new-dataset":0.3902313042,"dev-research":0.164861568,"data-quality":0.3002934945}}
{"text":"Weakly supervised attention-based multiple instance learning approaches have been developed in recent years to address these challenges, but can fail to resolve both long and short-range dependencies.","meta":{"url":"http://arxiv.org/abs/2309.10650v1"},"cats":{"new-dataset":0.1393334492,"dev-research":0.1289848962,"data-quality":0.2703549711}}
{"text":"Here we propose an end-to-end multi-stain self-attention graph (MUSTANG) multiple instance learning pipeline, which is designed to solve a weakly-supervised gigapixel multi-image classification task, where the label is assigned at the patient-level, but no slide-level labels or region annotations are available.","meta":{"url":"http://arxiv.org/abs/2309.10650v1"},"cats":{"new-dataset":0.3339423678,"dev-research":0.1172356811,"data-quality":0.2747244364}}
{"text":"The pipeline uses a self-attention based approach by restricting the operations to a highly sparse k-Nearest Neighbour Graph of embedded WSI patches based on the Euclidean distance.","meta":{"url":"http://arxiv.org/abs/2309.10650v1"},"cats":{"new-dataset":0.0812471412,"dev-research":0.1904669002,"data-quality":0.1379790182}}
{"text":"We show this approach achieves a state-of-the-art F1-score/AUC of 0.89/0.92, outperforming the widely used CLAM model.","meta":{"url":"http://arxiv.org/abs/2309.10650v1"},"cats":{"new-dataset":0.0698720163,"dev-research":0.1135041177,"data-quality":0.1205611201}}
{"text":"Our approach is highly modular and can easily be modified to suit different clinical datasets, as it only requires a patient-level label without annotations and accepts WSI sets of different sizes, as the graphs can be of varying sizes and structures.","meta":{"url":"http://arxiv.org/abs/2309.10650v1"},"cats":{"new-dataset":0.5903060581,"dev-research":0.1866188091,"data-quality":0.2041732708}}
{"text":"The source code can be found at https://github.com/AmayaGS/MUSTANG.","meta":{"url":"http://arxiv.org/abs/2309.10650v1"},"cats":{"new-dataset":0.2348943541,"dev-research":0.2618244415,"data-quality":0.1425512422}}
{"text":"Current state-of-the-art point cloud-based perception methods usually rely on large-scale labeled data, which requires expensive manual annotations.","meta":{"url":"http://arxiv.org/abs/2309.10649v1"},"cats":{"new-dataset":0.160415859,"dev-research":0.1679976533,"data-quality":0.2811985698}}
{"text":"A natural option is to explore the unsupervised methodology for 3D perception tasks.","meta":{"url":"http://arxiv.org/abs/2309.10649v1"},"cats":{"new-dataset":0.0139849123,"dev-research":0.1694924861,"data-quality":0.0643064115}}
{"text":"However, such methods often face substantial performance-drop difficulties.","meta":{"url":"http://arxiv.org/abs/2309.10649v1"},"cats":{"new-dataset":0.0005670175,"dev-research":0.3047282568,"data-quality":0.166034341}}
{"text":"Fortunately, we found that there exist amounts of image-based datasets and an alternative can be proposed, i.e., transferring the knowledge in the 2D images to 3D point clouds.","meta":{"url":"http://arxiv.org/abs/2309.10649v1"},"cats":{"new-dataset":0.6615234938,"dev-research":0.1454283314,"data-quality":0.0851319765}}
{"text":"Specifically, we propose a novel approach for the challenging cross-modal and cross-domain adaptation task by fully exploring the relationship between images and point clouds and designing effective feature alignment strategies.","meta":{"url":"http://arxiv.org/abs/2309.10649v1"},"cats":{"new-dataset":0.0802633407,"dev-research":0.1961113275,"data-quality":0.140332477}}
{"text":"Without any 3D labels, our method achieves state-of-the-art performance for 3D point cloud semantic segmentation on SemanticKITTI by using the knowledge of KITTI360 and GTA5, compared to existing unsupervised and weakly-supervised baselines.","meta":{"url":"http://arxiv.org/abs/2309.10649v1"},"cats":{"new-dataset":0.2577748272,"dev-research":0.1750346509,"data-quality":0.183519831}}
{"text":"Cellular traffic prediction is a crucial activity for optimizing networks in fifth-generation (5G) networks and beyond, as accurate forecasting is essential for intelligent network design, resource allocation and anomaly mitigation.","meta":{"url":"http://arxiv.org/abs/2309.10645v1"},"cats":{"new-dataset":0.023975087,"dev-research":0.1738060576,"data-quality":0.0824259952}}
{"text":"Although machine learning (ML) is a promising approach to effectively predict network traffic, the centralization of massive data in a single data center raises issues regarding confidentiality, privacy and data transfer demands.","meta":{"url":"http://arxiv.org/abs/2309.10645v1"},"cats":{"new-dataset":0.0561456949,"dev-research":0.1383464744,"data-quality":0.1160755343}}
{"text":"To address these challenges, federated learning (FL) emerges as an appealing ML training framework which offers high accurate predictions through parallel distributed computations.","meta":{"url":"http://arxiv.org/abs/2309.10645v1"},"cats":{"new-dataset":0.1162170532,"dev-research":0.1089123159,"data-quality":0.1049204719}}
{"text":"However, the environmental impact of these methods is often overlooked, which calls into question their sustainability.","meta":{"url":"http://arxiv.org/abs/2309.10645v1"},"cats":{"new-dataset":0.0061120496,"dev-research":0.3451007501,"data-quality":0.1756821608}}
{"text":"In this paper, we address the trade-off between accuracy and energy consumption in FL by proposing a novel sustainability indicator that allows assessing the feasibility of ML models.","meta":{"url":"http://arxiv.org/abs/2309.10645v1"},"cats":{"new-dataset":0.0587651823,"dev-research":0.1759609328,"data-quality":0.1565634999}}
{"text":"Then, we comprehensively evaluate state-of-the-art deep learning (DL) architectures in a federated scenario using real-world measurements from base station (BS) sites in the area of Barcelona, Spain.","meta":{"url":"http://arxiv.org/abs/2309.10645v1"},"cats":{"new-dataset":0.2521802225,"dev-research":0.1636420626,"data-quality":0.1025482028}}
{"text":"Our findings indicate that larger ML models achieve marginally improved performance but have a significant environmental impact in terms of carbon footprint, which make them impractical for real-world applications.","meta":{"url":"http://arxiv.org/abs/2309.10645v1"},"cats":{"new-dataset":0.0457501843,"dev-research":0.2059978967,"data-quality":0.1147513097}}
{"text":"Deep learning has been widely used in source code classification tasks, such as code classification according to their functionalities, code authorship attribution, and vulnerability detection.","meta":{"url":"http://arxiv.org/abs/2309.10644v1"},"cats":{"new-dataset":0.1754720972,"dev-research":0.3638685312,"data-quality":0.3294034386}}
{"text":"Unfortunately, the black-box nature of deep learning makes it hard to interpret and understand why a classifier (i.e., classification model) makes a particular prediction on a given example.","meta":{"url":"http://arxiv.org/abs/2309.10644v1"},"cats":{"new-dataset":0.0108143188,"dev-research":0.2385149438,"data-quality":0.2283427366}}
{"text":"This lack of interpretability (or explainability) might have hindered their adoption by practitioners because it is not clear when they should or should not trust a classifier's prediction.","meta":{"url":"http://arxiv.org/abs/2309.10644v1"},"cats":{"new-dataset":0.0035143965,"dev-research":0.3137781821,"data-quality":0.3450811505}}
{"text":"The lack of interpretability has motivated a number of studies in recent years.","meta":{"url":"http://arxiv.org/abs/2309.10644v1"},"cats":{"new-dataset":0.0088066479,"dev-research":0.3030633514,"data-quality":0.2270126656}}
{"text":"However, existing methods are neither robust nor able to cope with out-of-distribution examples.","meta":{"url":"http://arxiv.org/abs/2309.10644v1"},"cats":{"new-dataset":0.009729783,"dev-research":0.1522655673,"data-quality":0.3438003026}}
{"text":"In this paper, we propose a novel method to produce \\underline{Rob}ust \\underline{in}terpreters for a given deep learning-based code classifier; the method is dubbed Robin.","meta":{"url":"http://arxiv.org/abs/2309.10644v1"},"cats":{"new-dataset":0.1491205959,"dev-research":0.286967401,"data-quality":0.3410781037}}
{"text":"The key idea behind Robin is a novel hybrid structure combining an interpreter and two approximators, while leveraging the ideas of adversarial training and data augmentation.","meta":{"url":"http://arxiv.org/abs/2309.10644v1"},"cats":{"new-dataset":0.0578612022,"dev-research":0.2215848279,"data-quality":0.1408152932}}
{"text":"Experimental results show that on average the interpreter produced by Robin achieves a 6.11\\% higher fidelity (evaluated on the classifier), 67.22\\% higher fidelity (evaluated on the approximator), and 15.87x higher robustness than that of the three existing interpreters we evaluated.","meta":{"url":"http://arxiv.org/abs/2309.10644v1"},"cats":{"new-dataset":0.0180117627,"dev-research":0.2804836127,"data-quality":0.2596980003}}
{"text":"Moreover, the interpreter is 47.31\\% less affected by out-of-distribution examples than that of LEMNA.","meta":{"url":"http://arxiv.org/abs/2309.10644v1"},"cats":{"new-dataset":0.0251427492,"dev-research":0.1294834043,"data-quality":0.1753678815}}
{"text":"Kinship verification is an emerging task in computer vision with multiple potential applications.","meta":{"url":"http://arxiv.org/abs/2309.10641v1"},"cats":{"new-dataset":0.0861800615,"dev-research":0.149619366,"data-quality":0.1661702363}}
{"text":"However, there's no large enough kinship dataset to train a representative and robust model, which is a limitation for achieving better performance.","meta":{"url":"http://arxiv.org/abs/2309.10641v1"},"cats":{"new-dataset":0.0967103814,"dev-research":0.1272585153,"data-quality":0.1216385154}}
{"text":"Moreover, face verification is known to exhibit bias, which has not been dealt with by previous kinship verification works and sometimes even results in serious issues.","meta":{"url":"http://arxiv.org/abs/2309.10641v1"},"cats":{"new-dataset":0.0051580148,"dev-research":0.1950782716,"data-quality":0.2528451254}}
{"text":"So we first combine existing kinship datasets and label each identity with the correct race in order to take race information into consideration and provide a larger and complete dataset, called KinRace dataset.","meta":{"url":"http://arxiv.org/abs/2309.10641v1"},"cats":{"new-dataset":0.7307210416,"dev-research":0.1328779331,"data-quality":0.1880233135}}
{"text":"Secondly, we propose a multi-task learning model structure with attention module to enhance accuracy, which surpasses state-of-the-art performance.","meta":{"url":"http://arxiv.org/abs/2309.10641v1"},"cats":{"new-dataset":0.1045297098,"dev-research":0.1511212796,"data-quality":0.1189563874}}
{"text":"Lastly, our fairness-aware contrastive loss function with adversarial learning greatly mitigates racial bias.","meta":{"url":"http://arxiv.org/abs/2309.10641v1"},"cats":{"new-dataset":0.0290393265,"dev-research":0.1380524693,"data-quality":0.2594841844}}
{"text":"We introduce a debias term into traditional contrastive loss and implement gradient reverse in race classification task, which is an innovative idea to mix two fairness methods to alleviate bias.","meta":{"url":"http://arxiv.org/abs/2309.10641v1"},"cats":{"new-dataset":0.0703711493,"dev-research":0.1880094418,"data-quality":0.2969912237}}
{"text":"Exhaustive experimental evaluation demonstrates the effectiveness and superior performance of the proposed KFC in both standard deviation and accuracy at the same time.","meta":{"url":"http://arxiv.org/abs/2309.10641v1"},"cats":{"new-dataset":0.0194509767,"dev-research":0.1652663002,"data-quality":0.1848373255}}
{"text":"In this paper, we provide a geometric interpretation of the structure of Deep Learning (DL) networks, characterized by $L$ hidden layers, a ramp activation function, an ${\\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, and input and output spaces ${\\mathbb R}^Q$ with equal dimension $Q\\geq1$.","meta":{"url":"http://arxiv.org/abs/2309.10639v1"},"cats":{"new-dataset":0.059822323,"dev-research":0.1804383216,"data-quality":0.0810053442}}
{"text":"The hidden layers are defined on spaces ${\\mathbb R}^{Q}$, as well.","meta":{"url":"http://arxiv.org/abs/2309.10639v1"},"cats":{"new-dataset":0.117125896,"dev-research":0.1667887555,"data-quality":0.0809255201}}
{"text":"We apply our recent results on shallow neural networks to construct an explicit family of minimizers for the global minimum of the cost function in the case $L\\geq Q$, which we show to be degenerate.","meta":{"url":"http://arxiv.org/abs/2309.10639v1"},"cats":{"new-dataset":0.0496675974,"dev-research":0.1358836533,"data-quality":0.1318036612}}
{"text":"In the context presented here, the hidden layers of the DL network \"curate\" the training inputs by recursive application of a truncation map that minimizes the noise to signal ratio of the training inputs.","meta":{"url":"http://arxiv.org/abs/2309.10639v1"},"cats":{"new-dataset":0.045430326,"dev-research":0.1702929719,"data-quality":0.2143234669}}
{"text":"Moreover, we determine a set of $2^Q-1$ distinct degenerate local minima of the cost function.","meta":{"url":"http://arxiv.org/abs/2309.10639v1"},"cats":{"new-dataset":0.26236773,"dev-research":0.1412682712,"data-quality":0.110607276}}
{"text":"In this work, we explore the influence of entropy change in deep learning systems by adding noise to the inputs/latent features.","meta":{"url":"http://arxiv.org/abs/2309.10625v1"},"cats":{"new-dataset":0.0639657334,"dev-research":0.2029967898,"data-quality":0.2813623438}}
{"text":"The applications in this paper focus on deep learning tasks within computer vision, but the proposed theory can be further applied to other fields.","meta":{"url":"http://arxiv.org/abs/2309.10625v1"},"cats":{"new-dataset":0.0243970304,"dev-research":0.1321661831,"data-quality":0.1677132837}}
{"text":"Noise is conventionally viewed as a harmful perturbation in various deep learning architectures, such as convolutional neural networks (CNNs) and vision transformers (ViTs), as well as different learning tasks like image classification and transfer learning.","meta":{"url":"http://arxiv.org/abs/2309.10625v1"},"cats":{"new-dataset":0.0405746758,"dev-research":0.2613484293,"data-quality":0.4240257422}}
{"text":"However, this paper aims to rethink whether the conventional proposition always holds.","meta":{"url":"http://arxiv.org/abs/2309.10625v1"},"cats":{"new-dataset":0.0037362921,"dev-research":0.226873359,"data-quality":0.1428008845}}
{"text":"We demonstrate that specific noise can boost the performance of various deep architectures under certain conditions.","meta":{"url":"http://arxiv.org/abs/2309.10625v1"},"cats":{"new-dataset":0.0450258991,"dev-research":0.1996709856,"data-quality":0.2379210536}}
{"text":"We theoretically prove the enhancement gained from positive noise by reducing the task complexity defined by information entropy and experimentally show the significant performance gain in large image datasets, such as the ImageNet.","meta":{"url":"http://arxiv.org/abs/2309.10625v1"},"cats":{"new-dataset":0.069406568,"dev-research":0.179500266,"data-quality":0.170019554}}
{"text":"Herein, we use the information entropy to define the complexity of the task.","meta":{"url":"http://arxiv.org/abs/2309.10625v1"},"cats":{"new-dataset":0.0226553317,"dev-research":0.2051478365,"data-quality":0.0762500385}}
{"text":"We categorize the noise into two types, positive noise (PN) and harmful noise (HN), based on whether the noise can help reduce the complexity of the task.","meta":{"url":"http://arxiv.org/abs/2309.10625v1"},"cats":{"new-dataset":0.0393883515,"dev-research":0.3407996444,"data-quality":0.2687733743}}
{"text":"Extensive experiments of CNNs and ViTs have shown performance improvements by proactively injecting positive noise, where we achieved an unprecedented top 1 accuracy of over 95% on ImageNet.","meta":{"url":"http://arxiv.org/abs/2309.10625v1"},"cats":{"new-dataset":0.0548157995,"dev-research":0.2136502873,"data-quality":0.3302354715}}
{"text":"Both theoretical analysis and empirical evidence have confirmed that the presence of positive noise can benefit the learning process, while the traditionally perceived harmful noise indeed impairs deep learning models.","meta":{"url":"http://arxiv.org/abs/2309.10625v1"},"cats":{"new-dataset":0.0213593029,"dev-research":0.2893381402,"data-quality":0.3213011454}}
{"text":"The different roles of noise offer new explanations for deep models on specific tasks and provide a new paradigm for improving model performance.","meta":{"url":"http://arxiv.org/abs/2309.10625v1"},"cats":{"new-dataset":0.0783228945,"dev-research":0.2590777124,"data-quality":0.2830220897}}
{"text":"Moreover, it reminds us that we can influence the performance of learning systems via information entropy change.","meta":{"url":"http://arxiv.org/abs/2309.10625v1"},"cats":{"new-dataset":0.0068938792,"dev-research":0.2013206083,"data-quality":0.1355280351}}
{"text":"Underlayer networks in the context of 6G for manufacturing are crucial.","meta":{"url":"http://arxiv.org/abs/2309.10624v1"},"cats":{"new-dataset":0.0150875892,"dev-research":0.1626000754,"data-quality":0.085786027}}
{"text":"They address the evolving needs of highly interconnected and autonomous systems in industry.","meta":{"url":"http://arxiv.org/abs/2309.10624v1"},"cats":{"new-dataset":0.0819895697,"dev-research":0.2751612507,"data-quality":0.072955816}}
{"text":"The digitalization of manufacturing processes, driven by the Internet of Things and increased data availability, enables more efficient and demand-driven production.","meta":{"url":"http://arxiv.org/abs/2309.10624v1"},"cats":{"new-dataset":0.0357757335,"dev-research":0.2464480965,"data-quality":0.0541816831}}
{"text":"However, wireless connectivity, which offers flexibility and easy integration of components, comes with challenges such as signal interference or high latency.","meta":{"url":"http://arxiv.org/abs/2309.10624v1"},"cats":{"new-dataset":0.0028444013,"dev-research":0.3374111046,"data-quality":0.0999348132}}
{"text":"A new management system is needed to coordinate and route traffic of multiple networks in a specific coverage area.","meta":{"url":"http://arxiv.org/abs/2309.10624v1"},"cats":{"new-dataset":0.0409092454,"dev-research":0.1984717504,"data-quality":0.0561273803}}
{"text":"This paper proposes underlayer networks designed for manufacturing, providing low latency, reliability, and security.","meta":{"url":"http://arxiv.org/abs/2309.10624v1"},"cats":{"new-dataset":0.0240775764,"dev-research":0.2533041854,"data-quality":0.0926227346}}
{"text":"These networks enable wireless connectivity and integration of wireless technologies into the manufacturing environment, enhancing flexibility and efficiency.","meta":{"url":"http://arxiv.org/abs/2309.10624v1"},"cats":{"new-dataset":0.0201720856,"dev-research":0.2925579958,"data-quality":0.0647568921}}
{"text":"The paper also discusses network slicing, spectrum sharing, and the limitations of current wireless networks in manufacturing.","meta":{"url":"http://arxiv.org/abs/2309.10624v1"},"cats":{"new-dataset":0.0341223211,"dev-research":0.2494421397,"data-quality":0.0940504437}}
{"text":"It introduces a network concept for underlayer networks and evaluates its application in closed-loop communication for machine tools.","meta":{"url":"http://arxiv.org/abs/2309.10624v1"},"cats":{"new-dataset":0.0217260356,"dev-research":0.2709473295,"data-quality":0.1161795262}}
{"text":"The study concludes with future research prospects in this area.","meta":{"url":"http://arxiv.org/abs/2309.10624v1"},"cats":{"new-dataset":0.0795878953,"dev-research":0.2053920582,"data-quality":0.054925783}}
{"text":"Coarse-Grained Reconfigurable Arrays (CGRA) are promising edge accelerators due to the outstanding balance in flexibility, performance, and energy efficiency.","meta":{"url":"http://arxiv.org/abs/2309.10623v1"},"cats":{"new-dataset":0.025001214,"dev-research":0.1314733966,"data-quality":0.0662230382}}
{"text":"Classic CGRAs statically map compute operations onto the processing elements (PE) and route the data dependencies among the operations through the Network-on-Chip.","meta":{"url":"http://arxiv.org/abs/2309.10623v1"},"cats":{"new-dataset":0.0466107144,"dev-research":0.1984469228,"data-quality":0.0784988854}}
{"text":"However, CGRAs are designed for fine-grained static instruction-level parallelism and struggle to accelerate applications with dynamic and irregular data-level parallelism, such as graph processing.","meta":{"url":"http://arxiv.org/abs/2309.10623v1"},"cats":{"new-dataset":0.0480799595,"dev-research":0.2308001178,"data-quality":0.0840876915}}
{"text":"To address this limitation, we present Flip, a novel accelerator that enhances traditional CGRA architectures to boost the performance of graph applications.","meta":{"url":"http://arxiv.org/abs/2309.10623v1"},"cats":{"new-dataset":0.0394035598,"dev-research":0.1652928045,"data-quality":0.0698760176}}
{"text":"Flip retains the classic CGRA execution model while introducing a special data-centric mode for efficient graph processing.","meta":{"url":"http://arxiv.org/abs/2309.10623v1"},"cats":{"new-dataset":0.0579060993,"dev-research":0.2116435581,"data-quality":0.072647892}}
{"text":"Specifically, it exploits the natural data parallelism of graph algorithms by mapping graph vertices onto processing elements (PEs) rather than the operations, and supporting dynamic routing of temporary data according to the runtime evolution of the graph frontier.","meta":{"url":"http://arxiv.org/abs/2309.10623v1"},"cats":{"new-dataset":0.0254123559,"dev-research":0.1826906314,"data-quality":0.0628350939}}
{"text":"Experimental results demonstrate that Flip achieves up to 36$\\times$ speedup with merely 19% more area compared to classic CGRAs.","meta":{"url":"http://arxiv.org/abs/2309.10623v1"},"cats":{"new-dataset":0.0195978398,"dev-research":0.1795318891,"data-quality":0.0395328696}}
{"text":"Compared to state-of-the-art large-scale graph processors, Flip has similar energy efficiency and 2.2$\\times$ better area efficiency at a much-reduced power/area budget.","meta":{"url":"http://arxiv.org/abs/2309.10623v1"},"cats":{"new-dataset":0.0160346768,"dev-research":0.2558240217,"data-quality":0.0523853621}}
{"text":"Relevance labels, which indicate whether a search result is valuable to a searcher, are key to evaluating and optimising search systems.","meta":{"url":"http://arxiv.org/abs/2309.10621v1"},"cats":{"new-dataset":0.0089591638,"dev-research":0.2126544972,"data-quality":0.2759612991}}
{"text":"The best way to capture the true preferences of users is to ask them for their careful feedback on which results would be useful, but this approach does not scale to produce a large number of labels.","meta":{"url":"http://arxiv.org/abs/2309.10621v1"},"cats":{"new-dataset":0.0633790569,"dev-research":0.2025962191,"data-quality":0.4328796731}}
{"text":"Getting relevance labels at scale is usually done with third-party labellers, who judge on behalf of the user, but there is a risk of low-quality data if the labeller doesn't understand user needs.","meta":{"url":"http://arxiv.org/abs/2309.10621v1"},"cats":{"new-dataset":0.0302103772,"dev-research":0.1614240017,"data-quality":0.4999515934}}
{"text":"To improve quality, one standard approach is to study real users through interviews, user studies and direct feedback, find areas where labels are systematically disagreeing with users, then educate labellers about user needs through judging guidelines, training and monitoring.","meta":{"url":"http://arxiv.org/abs/2309.10621v1"},"cats":{"new-dataset":0.1414971222,"dev-research":0.4444260984,"data-quality":0.4684949071}}
{"text":"This paper introduces an alternate approach for improving label quality.","meta":{"url":"http://arxiv.org/abs/2309.10621v1"},"cats":{"new-dataset":0.106633158,"dev-research":0.2533719611,"data-quality":0.8327490413}}
{"text":"It takes careful feedback from real users, which by definition is the highest-quality first-party gold data that can be derived, and develops an large language model prompt that agrees with that data.   ","meta":{"url":"http://arxiv.org/abs/2309.10621v1"},"cats":{"new-dataset":0.2140098932,"dev-research":0.2858642366,"data-quality":0.292399374}}
{"text":"We present ideas and observations from deploying language models for large-scale relevance labelling at Bing, and illustrate with data from TREC.","meta":{"url":"http://arxiv.org/abs/2309.10621v1"},"cats":{"new-dataset":0.1245375553,"dev-research":0.2110257678,"data-quality":0.4371061916}}
{"text":"We have found large language models can be effective, with accuracy as good as human labellers and similar capability to pick the hardest queries, best runs, and best groups.","meta":{"url":"http://arxiv.org/abs/2309.10621v1"},"cats":{"new-dataset":0.1681029453,"dev-research":0.2016332255,"data-quality":0.3286158726}}
{"text":"Systematic changes to the prompts make a difference in accuracy, but so too do simple paraphrases.","meta":{"url":"http://arxiv.org/abs/2309.10621v1"},"cats":{"new-dataset":0.0324281,"dev-research":0.3383180256,"data-quality":0.2979674284}}
{"text":"To measure agreement with real searchers needs high-quality ``gold'' labels, but with these we find that models produce better labels than third-party workers, for a fraction of the cost, and these labels let us train notably better rankers.","meta":{"url":"http://arxiv.org/abs/2309.10621v1"},"cats":{"new-dataset":0.0444411118,"dev-research":0.1824094238,"data-quality":0.4821882622}}
{"text":"Accurately assessing the potential value of new sensor observations is a critical aspect of planning for active perception.","meta":{"url":"http://arxiv.org/abs/2309.10620v1"},"cats":{"new-dataset":0.0961459831,"dev-research":0.2388117776,"data-quality":0.1299806724}}
{"text":"This task is particularly challenging when reasoning about high-level scene understanding using measurements from vision-based neural networks.","meta":{"url":"http://arxiv.org/abs/2309.10620v1"},"cats":{"new-dataset":0.2983055122,"dev-research":0.1915475776,"data-quality":0.1956931649}}
{"text":"Due to appearance-based reasoning, the measurements are susceptible to several environmental effects such as the presence of occluders, variations in lighting conditions, and redundancy of information due to similarity in appearance between nearby viewpoints.","meta":{"url":"http://arxiv.org/abs/2309.10620v1"},"cats":{"new-dataset":0.0322069742,"dev-research":0.2527046947,"data-quality":0.1383998828}}
{"text":"To address this, we propose a new active perception framework incorporating an arbitrary number of perceptual effects in planning and fusion.","meta":{"url":"http://arxiv.org/abs/2309.10620v1"},"cats":{"new-dataset":0.0413188347,"dev-research":0.2012625017,"data-quality":0.0816738335}}
{"text":"Our method models the correlation with the environment by a set of general functions termed perceptual factors to construct a perceptual map, which quantifies the aggregated influence of the environment on candidate viewpoints.","meta":{"url":"http://arxiv.org/abs/2309.10620v1"},"cats":{"new-dataset":0.0483820733,"dev-research":0.2245336616,"data-quality":0.1012968791}}
{"text":"This information is seamlessly incorporated into the planning and fusion processes by adjusting the uncertainty associated with measurements to weigh their contributions.","meta":{"url":"http://arxiv.org/abs/2309.10620v1"},"cats":{"new-dataset":0.0221116563,"dev-research":0.2595433917,"data-quality":0.0653240453}}
{"text":"We evaluate our perceptual maps in a simulated environment that reproduces environmental conditions common in robotics applications.","meta":{"url":"http://arxiv.org/abs/2309.10620v1"},"cats":{"new-dataset":0.1316183448,"dev-research":0.2202397781,"data-quality":0.095539275}}
{"text":"Our results show that, by accounting for environmental effects within our perceptual maps, we improve in the state estimation by correctly selecting the viewpoints and considering the measurement noise correctly when affected by environmental factors.","meta":{"url":"http://arxiv.org/abs/2309.10620v1"},"cats":{"new-dataset":0.1237904372,"dev-research":0.1871007402,"data-quality":0.1878769461}}
{"text":"We furthermore deploy our approach on a ground robot to showcase its applicability for real-world active perception missions.","meta":{"url":"http://arxiv.org/abs/2309.10620v1"},"cats":{"new-dataset":0.1366841918,"dev-research":0.1725165164,"data-quality":0.0996262018}}
{"text":"Domain adaptation (DA) has been widely applied in the diabetic retinopathy (DR) grading of unannotated ultra-wide-field (UWF) fundus images, which can transfer annotated knowledge from labeled color fundus images.","meta":{"url":"http://arxiv.org/abs/2309.10619v1"},"cats":{"new-dataset":0.1313188299,"dev-research":0.1906699351,"data-quality":0.2072902764}}
{"text":"However, suffering from huge domain gaps and complex real-world scenarios, the DR grading performance of most mainstream DA is far from that of clinical diagnosis.","meta":{"url":"http://arxiv.org/abs/2309.10619v1"},"cats":{"new-dataset":0.0284629141,"dev-research":0.2532382971,"data-quality":0.1998918027}}
{"text":"To tackle this, we propose a novel source-free active domain adaptation (SFADA) in this paper.","meta":{"url":"http://arxiv.org/abs/2309.10619v1"},"cats":{"new-dataset":0.1724533028,"dev-research":0.2230991362,"data-quality":0.2376788481}}
{"text":"Specifically, we focus on DR grading problem itself and propose to generate features of color fundus images with continuously evolving relationships of DRs, actively select a few valuable UWF fundus images for labeling with local representation matching, and adapt model on UWF fundus images with DR lesion prototypes.","meta":{"url":"http://arxiv.org/abs/2309.10619v1"},"cats":{"new-dataset":0.5426809972,"dev-research":0.1821941457,"data-quality":0.2841599224}}
{"text":"Notably, the SFADA also takes data privacy and computational efficiency into consideration.","meta":{"url":"http://arxiv.org/abs/2309.10619v1"},"cats":{"new-dataset":0.0478210222,"dev-research":0.1848809248,"data-quality":0.055855976}}
{"text":"Extensive experimental results demonstrate that our proposed SFADA achieves state-of-the-art DR grading performance, increasing accuracy by 20.9% and quadratic weighted kappa by 18.63% compared with baseline and reaching 85.36% and 92.38% respectively.","meta":{"url":"http://arxiv.org/abs/2309.10619v1"},"cats":{"new-dataset":0.0816669224,"dev-research":0.1892833508,"data-quality":0.1740165487}}
{"text":"These investigations show that the potential of our approach for real clinical practice is promising.","meta":{"url":"http://arxiv.org/abs/2309.10619v1"},"cats":{"new-dataset":0.015384347,"dev-research":0.2585873526,"data-quality":0.0628200624}}
{"text":"High-Dimensional and Incomplete (HDI) data is commonly encountered in big data-related applications like social network services systems, which are concerning the limited interactions among numerous nodes.","meta":{"url":"http://arxiv.org/abs/2309.10618v1"},"cats":{"new-dataset":0.1958711036,"dev-research":0.1352673579,"data-quality":0.0933339867}}
{"text":"Knowledge acquisition from HDI data is a vital issue in the domain of data science due to their embedded rich patterns like node behaviors, where the fundamental task is to perform HDI data representation learning.","meta":{"url":"http://arxiv.org/abs/2309.10618v1"},"cats":{"new-dataset":0.2869771814,"dev-research":0.2557607964,"data-quality":0.1874132979}}
{"text":"Nonnegative Latent Factor Analysis (NLFA) models have proven to possess the superiority to address this issue, where a linear bias incorporation (LBI) scheme is important in present the training overshooting and fluctuation, as well as preventing the model from premature convergence.","meta":{"url":"http://arxiv.org/abs/2309.10618v1"},"cats":{"new-dataset":0.0128807182,"dev-research":0.148399377,"data-quality":0.1851388411}}
{"text":"However, existing LBI schemes are all statistic ones where the linear biases are fixed, which significantly restricts the scalability of the resultant NLFA model and results in loss of representation learning ability to HDI data.","meta":{"url":"http://arxiv.org/abs/2309.10618v1"},"cats":{"new-dataset":0.0123950481,"dev-research":0.1319169691,"data-quality":0.1892499576}}
{"text":"Motivated by the above discoveries, this paper innovatively presents the dynamic linear bias incorporation (DLBI) scheme.","meta":{"url":"http://arxiv.org/abs/2309.10618v1"},"cats":{"new-dataset":0.0039602365,"dev-research":0.1277318316,"data-quality":0.0758508362}}
{"text":"It firstly extends the linear bias vectors into matrices, and then builds a binary weight matrix to switch the active/inactive states of the linear biases.","meta":{"url":"http://arxiv.org/abs/2309.10618v1"},"cats":{"new-dataset":0.002491049,"dev-research":0.1224260886,"data-quality":0.0637430081}}
{"text":"The weight matrix's each entry switches between the binary states dynamically corresponding to the linear bias value variation, thereby establishing the dynamic linear biases for an NLFA model.","meta":{"url":"http://arxiv.org/abs/2309.10618v1"},"cats":{"new-dataset":0.007816704,"dev-research":0.0920341734,"data-quality":0.1426658427}}
{"text":"Empirical studies on three HDI datasets from real applications demonstrate that the proposed DLBI-based NLFA model obtains higher representation accuracy several than state-of-the-art models do, as well as highly-competitive computational efficiency.","meta":{"url":"http://arxiv.org/abs/2309.10618v1"},"cats":{"new-dataset":0.0815707853,"dev-research":0.1801566743,"data-quality":0.145912204}}
{"text":"Marine debris poses a significant threat to the survival of marine wildlife, often leading to entanglement and starvation, ultimately resulting in death.","meta":{"url":"http://arxiv.org/abs/2309.10617v1"},"cats":{"new-dataset":0.0666261856,"dev-research":0.3038487775,"data-quality":0.2009425156}}
{"text":"Therefore, removing debris from the ocean is crucial to restore the natural balance and allow marine life to thrive.","meta":{"url":"http://arxiv.org/abs/2309.10617v1"},"cats":{"new-dataset":0.0169582233,"dev-research":0.2808789263,"data-quality":0.1109622717}}
{"text":"Instance segmentation is an advanced form of object detection that identifies objects and precisely locates and separates them, making it an essential tool for autonomous underwater vehicles (AUVs) to navigate and interact with their underwater environment effectively.","meta":{"url":"http://arxiv.org/abs/2309.10617v1"},"cats":{"new-dataset":0.0451185282,"dev-research":0.1928398942,"data-quality":0.1918165097}}
{"text":"AUVs use image segmentation to analyze images captured by their cameras to navigate underwater environments.","meta":{"url":"http://arxiv.org/abs/2309.10617v1"},"cats":{"new-dataset":0.1143094144,"dev-research":0.2052198401,"data-quality":0.1293524214}}
{"text":"In this paper, we use instance segmentation to calculate the area of individual objects within an image, we use YOLOV7 in Roboflow to generate a set of bounding boxes for each object in the image with a class label and a confidence score for every detection.","meta":{"url":"http://arxiv.org/abs/2309.10617v1"},"cats":{"new-dataset":0.2484362745,"dev-research":0.1751809373,"data-quality":0.1842661351}}
{"text":"A segmentation mask is then created for each object by applying a binary mask to the object's bounding box.","meta":{"url":"http://arxiv.org/abs/2309.10617v1"},"cats":{"new-dataset":0.0836218171,"dev-research":0.1863043843,"data-quality":0.1128021383}}
{"text":"The masks are generated by applying a binary threshold to the output of a convolutional neural network trained to segment objects from the background.","meta":{"url":"http://arxiv.org/abs/2309.10617v1"},"cats":{"new-dataset":0.1930289387,"dev-research":0.1936799929,"data-quality":0.1353764678}}
{"text":"Finally, refining the segmentation mask for each object is done by applying post-processing techniques such as morphological operations and contour detection, to improve the accuracy and quality of the mask.","meta":{"url":"http://arxiv.org/abs/2309.10617v1"},"cats":{"new-dataset":0.0410095172,"dev-research":0.2057799348,"data-quality":0.2553328725}}
{"text":"The process of estimating the area of instance segmentation involves calculating the area of each segmented instance separately and then summing up the areas of all instances to obtain the total area.","meta":{"url":"http://arxiv.org/abs/2309.10617v1"},"cats":{"new-dataset":0.0455891844,"dev-research":0.2099714835,"data-quality":0.1698566586}}
{"text":"The calculation is carried out using standard formulas based on the shape of the object, such as rectangles and circles.","meta":{"url":"http://arxiv.org/abs/2309.10617v1"},"cats":{"new-dataset":0.034193452,"dev-research":0.2101268269,"data-quality":0.0705002956}}
{"text":"In cases where the object is complex, the Monte Carlo method is used to estimate the area.","meta":{"url":"http://arxiv.org/abs/2309.10617v1"},"cats":{"new-dataset":0.0077723068,"dev-research":0.2252083652,"data-quality":0.0661291236}}
{"text":"This method provides a higher degree of accuracy than traditional methods, especially when using a large number of samples.","meta":{"url":"http://arxiv.org/abs/2309.10617v1"},"cats":{"new-dataset":0.0050198668,"dev-research":0.1748277296,"data-quality":0.1511127203}}
{"text":"Performing inference in statistical models with an intractable likelihood is challenging, therefore, most likelihood-free inference (LFI) methods encounter accuracy and efficiency limitations.","meta":{"url":"http://arxiv.org/abs/2309.10612v1"},"cats":{"new-dataset":0.0268412743,"dev-research":0.141193187,"data-quality":0.1163209041}}
{"text":"In this paper, we present the implementation of the LFI method Robust Optimisation Monte Carlo (ROMC) in the Python package ELFI.","meta":{"url":"http://arxiv.org/abs/2309.10612v1"},"cats":{"new-dataset":0.0362585864,"dev-research":0.1854742462,"data-quality":0.1368368522}}
{"text":"ROMC is a novel and efficient (highly-parallelizable) LFI framework that provides accurate weighted samples from the posterior.","meta":{"url":"http://arxiv.org/abs/2309.10612v1"},"cats":{"new-dataset":0.0749759974,"dev-research":0.1204314467,"data-quality":0.1047109144}}
{"text":"Our implementation can be used in two ways.","meta":{"url":"http://arxiv.org/abs/2309.10612v1"},"cats":{"new-dataset":0.0042590407,"dev-research":0.2498982081,"data-quality":0.0999398837}}
{"text":"First, a scientist may use it as an out-of-the-box LFI algorithm; we provide an easy-to-use API harmonized with the principles of ELFI, enabling effortless comparisons with the rest of the methods included in the package.","meta":{"url":"http://arxiv.org/abs/2309.10612v1"},"cats":{"new-dataset":0.0355039604,"dev-research":0.1218517138,"data-quality":0.0949758247}}
{"text":"Additionally, we have carefully split ROMC into isolated components for supporting extensibility.","meta":{"url":"http://arxiv.org/abs/2309.10612v1"},"cats":{"new-dataset":0.0094461085,"dev-research":0.2084214447,"data-quality":0.0936772186}}
{"text":"A researcher may experiment with novel method(s) for solving part(s) of ROMC without reimplementing everything from scratch.","meta":{"url":"http://arxiv.org/abs/2309.10612v1"},"cats":{"new-dataset":0.0302416086,"dev-research":0.2777197493,"data-quality":0.0970387783}}
{"text":"In both scenarios, the ROMC parts can run in a fully-parallelized manner, exploiting all CPU cores.","meta":{"url":"http://arxiv.org/abs/2309.10612v1"},"cats":{"new-dataset":0.0032832523,"dev-research":0.2195738562,"data-quality":0.071407274}}
{"text":"We also provide helpful functionalities for (i) inspecting the inference process and (ii) evaluating the obtained samples.","meta":{"url":"http://arxiv.org/abs/2309.10612v1"},"cats":{"new-dataset":0.0258669257,"dev-research":0.1407737248,"data-quality":0.1500496116}}
{"text":"Finally, we test the robustness of our implementation on some typical LFI examples.","meta":{"url":"http://arxiv.org/abs/2309.10612v1"},"cats":{"new-dataset":0.0294584092,"dev-research":0.1818447768,"data-quality":0.2863743949}}
{"text":"In this paper, we propose Graph Differential Equation Network (GDeNet), an approach that harnesses the expressive power of solutions to PDEs on a graph to obtain continuous node- and graph-level representations for various downstream tasks.","meta":{"url":"http://arxiv.org/abs/2309.09924v1"},"cats":{"new-dataset":0.1347680875,"dev-research":0.2319004833,"data-quality":0.091648818}}
{"text":"We derive theoretical results connecting the dynamics of heat and wave equations to the spectral properties of the graph and to the behavior of continuous-time random walks on graphs.","meta":{"url":"http://arxiv.org/abs/2309.09924v1"},"cats":{"new-dataset":0.0597893562,"dev-research":0.1690153686,"data-quality":0.0735824287}}
{"text":"We demonstrate experimentally that these dynamics are able to capture salient aspects of graph geometry and topology by recovering generating parameters of random graphs, Ricci curvature, and persistent homology.","meta":{"url":"http://arxiv.org/abs/2309.09924v1"},"cats":{"new-dataset":0.0482490873,"dev-research":0.1519988023,"data-quality":0.1196143582}}
{"text":"Furthermore, we demonstrate the superior performance of GDeNet on real-world datasets including citation graphs, drug-like molecules, and proteins.","meta":{"url":"http://arxiv.org/abs/2309.09924v1"},"cats":{"new-dataset":0.4064018948,"dev-research":0.1081526214,"data-quality":0.1763039574}}
{"text":"With the development of deep learning, automatic speech recognition (ASR) has made significant progress.","meta":{"url":"http://arxiv.org/abs/2309.09838v1"},"cats":{"new-dataset":0.12359557,"dev-research":0.17795469,"data-quality":0.1681806245}}
{"text":"To further enhance the performance, revising recognition results is one of the lightweight but efficient manners.","meta":{"url":"http://arxiv.org/abs/2309.09838v1"},"cats":{"new-dataset":0.0377787561,"dev-research":0.2122928856,"data-quality":0.3213990386}}
{"text":"Various methods can be roughly classified into N-best reranking methods and error correction models.","meta":{"url":"http://arxiv.org/abs/2309.09838v1"},"cats":{"new-dataset":0.0270787401,"dev-research":0.2118789538,"data-quality":0.2843919017}}
{"text":"The former aims to select the hypothesis with the lowest error rate from a set of candidates generated by ASR for a given input speech.","meta":{"url":"http://arxiv.org/abs/2309.09838v1"},"cats":{"new-dataset":0.0113723125,"dev-research":0.1694842882,"data-quality":0.2332163478}}
{"text":"The latter focuses on detecting recognition errors in a given hypothesis and correcting these errors to obtain an enhanced result.","meta":{"url":"http://arxiv.org/abs/2309.09838v1"},"cats":{"new-dataset":0.0178841224,"dev-research":0.3270825367,"data-quality":0.6212038291}}
{"text":"However, we observe that these studies are hardly comparable to each other as they are usually evaluated on different corpora, paired with different ASR models, and even use different datasets to train the models.","meta":{"url":"http://arxiv.org/abs/2309.09838v1"},"cats":{"new-dataset":0.0571641027,"dev-research":0.1613303869,"data-quality":0.1778980567}}
{"text":"Accordingly, we first concentrate on releasing an ASR hypothesis revising (HypR) dataset in this study.","meta":{"url":"http://arxiv.org/abs/2309.09838v1"},"cats":{"new-dataset":0.0956609537,"dev-research":0.2033000016,"data-quality":0.1328962745}}
{"text":"HypR contains several commonly used corpora (AISHELL-1, TED-LIUM 2, and LibriSpeech) and provides 50 recognition hypotheses for each speech utterance.","meta":{"url":"http://arxiv.org/abs/2309.09838v1"},"cats":{"new-dataset":0.4969078826,"dev-research":0.1516959778,"data-quality":0.2073929824}}
{"text":"The checkpoint models of the ASR are also published.","meta":{"url":"http://arxiv.org/abs/2309.09838v1"},"cats":{"new-dataset":0.0878882622,"dev-research":0.1610319301,"data-quality":0.0973750676}}
{"text":"In addition, we implement and compare several classic and representative methods, showing the recent research progress in revising speech recognition results.","meta":{"url":"http://arxiv.org/abs/2309.09838v1"},"cats":{"new-dataset":0.067250728,"dev-research":0.1537569465,"data-quality":0.3222096189}}
{"text":"We hope the publicly available HypR dataset can become a reference benchmark for subsequent research and promote the school of research to an advanced level.","meta":{"url":"http://arxiv.org/abs/2309.09838v1"},"cats":{"new-dataset":0.7469098462,"dev-research":0.1386540038,"data-quality":0.0916674703}}
{"text":"We introduce RotateIt, a system that enables fingertip-based object rotation along multiple axes by leveraging multimodal sensory inputs.","meta":{"url":"http://arxiv.org/abs/2309.09979v1"},"cats":{"new-dataset":0.2716392726,"dev-research":0.2004588402,"data-quality":0.0838074963}}
{"text":"Our system is trained in simulation, where it has access to ground-truth object shapes and physical properties.","meta":{"url":"http://arxiv.org/abs/2309.09979v1"},"cats":{"new-dataset":0.0844414763,"dev-research":0.1738713329,"data-quality":0.0859388861}}
{"text":"Then we distill it to operate on realistic yet noisy simulated visuotactile and proprioceptive sensory inputs.","meta":{"url":"http://arxiv.org/abs/2309.09979v1"},"cats":{"new-dataset":0.0097509658,"dev-research":0.1716074892,"data-quality":0.0799384788}}
{"text":"These multimodal inputs are fused via a visuotactile transformer, enabling online inference of object shapes and physical properties during deployment.","meta":{"url":"http://arxiv.org/abs/2309.09979v1"},"cats":{"new-dataset":0.0363508049,"dev-research":0.2193388103,"data-quality":0.0474112199}}
{"text":"We show significant performance improvements over prior methods and the importance of visual and tactile sensing.","meta":{"url":"http://arxiv.org/abs/2309.09979v1"},"cats":{"new-dataset":0.0223162752,"dev-research":0.1774974926,"data-quality":0.0923536656}}
{"text":"Communication efficiency is a major challenge in federated learning (FL).","meta":{"url":"http://arxiv.org/abs/2309.09977v1"},"cats":{"new-dataset":0.0250720738,"dev-research":0.1568411453,"data-quality":0.1059908809}}
{"text":"In client-server schemes, the server constitutes a bottleneck, and while decentralized setups spread communications, they do not necessarily reduce them due to slower convergence.","meta":{"url":"http://arxiv.org/abs/2309.09977v1"},"cats":{"new-dataset":0.0072477321,"dev-research":0.1810066681,"data-quality":0.058208209}}
{"text":"We propose Multi-Token Coordinate Descent (MTCD), a communication-efficient algorithm for semi-decentralized vertical federated learning, exploiting both client-server and client-client communications when each client holds a small subset of features.","meta":{"url":"http://arxiv.org/abs/2309.09977v1"},"cats":{"new-dataset":0.0578881732,"dev-research":0.124310137,"data-quality":0.1037496868}}
{"text":"Our multi-token method can be seen as a parallel Markov chain (block) coordinate descent algorithm and it subsumes the client-server and decentralized setups as special cases.","meta":{"url":"http://arxiv.org/abs/2309.09977v1"},"cats":{"new-dataset":0.0102599183,"dev-research":0.1191499646,"data-quality":0.0797015492}}
{"text":"We obtain a convergence rate of $\\mathcal{O}(1/T)$ for nonconvex objectives when tokens roam over disjoint subsets of clients and for convex objectives when they roam over possibly overlapping subsets.","meta":{"url":"http://arxiv.org/abs/2309.09977v1"},"cats":{"new-dataset":0.0140172225,"dev-research":0.1257579769,"data-quality":0.1015063396}}
{"text":"Numerical results show that MTCD improves the state-of-the-art communication efficiency and allows for a tunable amount of parallel communications.","meta":{"url":"http://arxiv.org/abs/2309.09977v1"},"cats":{"new-dataset":0.0233611103,"dev-research":0.124416026,"data-quality":0.0496017423}}
{"text":"Monocular depth estimation is an ill-posed problem as the same 2D image can be projected from infinite 3D scenes.","meta":{"url":"http://arxiv.org/abs/2309.09975v1"},"cats":{"new-dataset":0.1118048457,"dev-research":0.1379272828,"data-quality":0.0974002231}}
{"text":"Although the leading algorithms in this field have reported significant improvement, they are essentially geared to the particular compound of pictorial observations and camera parameters (i.e., intrinsics and extrinsics), strongly limiting their generalizability in real-world scenarios.","meta":{"url":"http://arxiv.org/abs/2309.09975v1"},"cats":{"new-dataset":0.0850581504,"dev-research":0.1383809022,"data-quality":0.0807504136}}
{"text":"To cope with this challenge, this paper proposes a novel ground embedding module to decouple camera parameters from pictorial cues, thus promoting the generalization capability.","meta":{"url":"http://arxiv.org/abs/2309.09975v1"},"cats":{"new-dataset":0.2379160404,"dev-research":0.1793717083,"data-quality":0.160364322}}
{"text":"Given camera parameters, the proposed module generates the ground depth, which is stacked with the input image and referenced in the final depth prediction.","meta":{"url":"http://arxiv.org/abs/2309.09975v1"},"cats":{"new-dataset":0.407571341,"dev-research":0.1521176606,"data-quality":0.0707372077}}
{"text":"A ground attention is designed in the module to optimally combine ground depth with residual depth.","meta":{"url":"http://arxiv.org/abs/2309.09975v1"},"cats":{"new-dataset":0.0569972219,"dev-research":0.1877617566,"data-quality":0.1004231502}}
{"text":"Our ground embedding is highly flexible and lightweight, leading to a plug-in module that is amenable to be integrated into various depth estimation networks.","meta":{"url":"http://arxiv.org/abs/2309.09975v1"},"cats":{"new-dataset":0.1503489968,"dev-research":0.1357081214,"data-quality":0.0941836006}}
{"text":"Experiments reveal that our approach achieves the state-of-the-art results on popular benchmarks, and more importantly, renders significant generalization improvement on a wide range of cross-domain tests.","meta":{"url":"http://arxiv.org/abs/2309.09975v1"},"cats":{"new-dataset":0.0200165049,"dev-research":0.1555274076,"data-quality":0.1627537006}}
{"text":"Large Language Models (LLMs) have the capacity of performing complex scheduling in a multi-agent system and can coordinate these agents into completing sophisticated tasks that require extensive collaboration.","meta":{"url":"http://arxiv.org/abs/2309.09971v1"},"cats":{"new-dataset":0.1017687059,"dev-research":0.1693386405,"data-quality":0.0587022883}}
{"text":"However, despite the introduction of numerous gaming frameworks, the community has insufficient benchmarks towards building general multi-agents collaboration infrastructure that encompass both LLM and human-NPCs collaborations.","meta":{"url":"http://arxiv.org/abs/2309.09971v1"},"cats":{"new-dataset":0.1919882292,"dev-research":0.2491664363,"data-quality":0.0552893832}}
{"text":"In this work, we propose a novel infrastructure - MindAgent - to evaluate planning and coordination emergent capabilities for gaming interaction.","meta":{"url":"http://arxiv.org/abs/2309.09971v1"},"cats":{"new-dataset":0.2617259484,"dev-research":0.3162214626,"data-quality":0.0349970024}}
{"text":"In particular, our infrastructure leverages existing gaming framework, to i) require understanding of the coordinator for a multi-agent system, ii) collaborate with human players via un-finetuned proper instructions, and iii) establish an in-context learning on few-shot prompt with feedback.","meta":{"url":"http://arxiv.org/abs/2309.09971v1"},"cats":{"new-dataset":0.1907377549,"dev-research":0.2414305077,"data-quality":0.0774913924}}
{"text":"Furthermore, we introduce CUISINEWORLD, a new gaming scenario and related benchmark that dispatch a multi-agent collaboration efficiency and supervise multiple agents playing the game simultaneously.","meta":{"url":"http://arxiv.org/abs/2309.09971v1"},"cats":{"new-dataset":0.1554269667,"dev-research":0.2260891618,"data-quality":0.0510369189}}
{"text":"We conduct comprehensive evaluations with new auto-metric CoS for calculating the collaboration efficiency.","meta":{"url":"http://arxiv.org/abs/2309.09971v1"},"cats":{"new-dataset":0.0382355569,"dev-research":0.359862734,"data-quality":0.1170256065}}
{"text":"Finally, our infrastructure can be deployed into real-world gaming scenarios in a customized VR version of CUISINEWORLD and adapted in existing broader Minecraft gaming domain.","meta":{"url":"http://arxiv.org/abs/2309.09971v1"},"cats":{"new-dataset":0.1595332999,"dev-research":0.2090223227,"data-quality":0.0669401053}}
{"text":"We hope our findings on LLMs and the new infrastructure for general-purpose scheduling and coordination can help shed light on how such skills can be obtained by learning from large language corpora.","meta":{"url":"http://arxiv.org/abs/2309.09971v1"},"cats":{"new-dataset":0.3012872436,"dev-research":0.197942899,"data-quality":0.1137517508}}
{"text":"Data augmentation is a common practice to help generalization in the procedure of deep model training.","meta":{"url":"http://arxiv.org/abs/2309.09970v1"},"cats":{"new-dataset":0.0332801869,"dev-research":0.1893525961,"data-quality":0.2299476431}}
{"text":"In the context of physiological time series classification, previous research has primarily focused on label-invariant data augmentation methods.","meta":{"url":"http://arxiv.org/abs/2309.09970v1"},"cats":{"new-dataset":0.1104841476,"dev-research":0.1857427723,"data-quality":0.3574361944}}
{"text":"However, another class of augmentation techniques (\\textit{i.e., Mixup}) that emerged in the computer vision field has yet to be fully explored in the time series domain.","meta":{"url":"http://arxiv.org/abs/2309.09970v1"},"cats":{"new-dataset":0.0186084197,"dev-research":0.1967733648,"data-quality":0.1963004562}}
{"text":"In this study, we systematically review the mix-based augmentations, including mixup, cutmix, and manifold mixup, on six physiological datasets, evaluating their performance across different sensory data and classification tasks.","meta":{"url":"http://arxiv.org/abs/2309.09970v1"},"cats":{"new-dataset":0.1253184097,"dev-research":0.197455244,"data-quality":0.2092415096}}
{"text":"Our results demonstrate that the three mix-based augmentations can consistently improve the performance on the six datasets.","meta":{"url":"http://arxiv.org/abs/2309.09970v1"},"cats":{"new-dataset":0.1762970993,"dev-research":0.1980041994,"data-quality":0.2554105976}}
{"text":"More importantly, the improvement does not rely on expert knowledge or extensive parameter tuning.","meta":{"url":"http://arxiv.org/abs/2309.09970v1"},"cats":{"new-dataset":0.004170594,"dev-research":0.2472446526,"data-quality":0.2050674198}}
{"text":"Lastly, we provide an overview of the unique properties of the mix-based augmentation methods and highlight the potential benefits of using the mix-based augmentation in physiological time series data.","meta":{"url":"http://arxiv.org/abs/2309.09970v1"},"cats":{"new-dataset":0.0505547916,"dev-research":0.1750430401,"data-quality":0.1108102869}}
{"text":"Large language models (LLMs) pre-trained on vast internet-scale data have showcased remarkable capabilities across diverse domains.","meta":{"url":"http://arxiv.org/abs/2309.09969v1"},"cats":{"new-dataset":0.237678047,"dev-research":0.1079027504,"data-quality":0.1444676306}}
{"text":"Recently, there has been escalating interest in deploying LLMs for robotics, aiming to harness the power of foundation models in real-world settings.","meta":{"url":"http://arxiv.org/abs/2309.09969v1"},"cats":{"new-dataset":0.05958755,"dev-research":0.1556045196,"data-quality":0.0421052188}}
{"text":"However, this approach faces significant challenges, particularly in grounding these models in the physical world and in generating dynamic robot motions.","meta":{"url":"http://arxiv.org/abs/2309.09969v1"},"cats":{"new-dataset":0.0631026337,"dev-research":0.1655822034,"data-quality":0.0504879735}}
{"text":"To address these issues, we introduce a novel paradigm in which we use few-shot prompts collected from the physical environment, enabling the LLM to autoregressively generate low-level control commands for robots without task-specific fine-tuning.","meta":{"url":"http://arxiv.org/abs/2309.09969v1"},"cats":{"new-dataset":0.0868277355,"dev-research":0.2192684569,"data-quality":0.086506433}}
{"text":"Experiments across various robots and environments validate that our method can effectively prompt a robot to walk.","meta":{"url":"http://arxiv.org/abs/2309.09969v1"},"cats":{"new-dataset":0.0087650516,"dev-research":0.2646927548,"data-quality":0.0961711359}}
{"text":"We thus illustrate how LLMs can proficiently function as low-level feedback controllers for dynamic motion control even in high-dimensional robotic systems.","meta":{"url":"http://arxiv.org/abs/2309.09969v1"},"cats":{"new-dataset":0.0244841704,"dev-research":0.1420047,"data-quality":0.0464844803}}
{"text":"The project website and source code can be found at: https://prompt2walk.github.io/ .","meta":{"url":"http://arxiv.org/abs/2309.09969v1"},"cats":{"new-dataset":0.6207017904,"dev-research":0.335432137,"data-quality":0.1002349505}}
{"text":"Tabular data is hard to acquire and is subject to missing values.","meta":{"url":"http://arxiv.org/abs/2309.09968v1"},"cats":{"new-dataset":0.1647849075,"dev-research":0.2187169433,"data-quality":0.1791237364}}
{"text":"This paper proposes a novel approach to generate and impute mixed-type (continuous and categorical) tabular data using score-based diffusion and conditional flow matching.","meta":{"url":"http://arxiv.org/abs/2309.09968v1"},"cats":{"new-dataset":0.0935476558,"dev-research":0.1667662332,"data-quality":0.093069571}}
{"text":"Contrary to previous work that relies on neural networks as function approximators, we instead utilize XGBoost, a popular Gradient-Boosted Tree (GBT) method.","meta":{"url":"http://arxiv.org/abs/2309.09968v1"},"cats":{"new-dataset":0.0409415201,"dev-research":0.1817314013,"data-quality":0.164433099}}
{"text":"In addition to being elegant, we empirically show on various datasets that our method i) generates highly realistic synthetic data when the training dataset is either clean or tainted by missing data and ii) generates diverse plausible data imputations.","meta":{"url":"http://arxiv.org/abs/2309.09968v1"},"cats":{"new-dataset":0.3499254466,"dev-research":0.2052586187,"data-quality":0.3501901975}}
{"text":"Our method often outperforms deep-learning generation methods and can trained in parallel using CPUs without the need for a GPU.","meta":{"url":"http://arxiv.org/abs/2309.09968v1"},"cats":{"new-dataset":0.0707452567,"dev-research":0.1903550553,"data-quality":0.1123816906}}
{"text":"To make it easily accessible, we release our code through a Python library on PyPI and an R package on CRAN.","meta":{"url":"http://arxiv.org/abs/2309.09968v1"},"cats":{"new-dataset":0.6819221776,"dev-research":0.222214775,"data-quality":0.0982345952}}
{"text":"Given a mapping from a set of players to the leaves of a complete binary tree (called a seeding), a knockout tournament is conducted as follows: every round, every two players with a common parent compete against each other, and the winner is promoted to the common parent; then, the leaves are deleted.","meta":{"url":"http://arxiv.org/abs/2309.09967v1"},"cats":{"new-dataset":0.1179607092,"dev-research":0.1499161368,"data-quality":0.1318476729}}
{"text":"When only one player remains, it is declared the winner.","meta":{"url":"http://arxiv.org/abs/2309.09967v1"},"cats":{"new-dataset":0.0557616059,"dev-research":0.2131434685,"data-quality":0.1425331199}}
{"text":"This is a popular competition format in sports, elections, and decision-making.","meta":{"url":"http://arxiv.org/abs/2309.09967v1"},"cats":{"new-dataset":0.0487535058,"dev-research":0.1970280966,"data-quality":0.0967019757}}
{"text":"Over the past decade, it has been studied intensively from both theoretical and practical points of view.","meta":{"url":"http://arxiv.org/abs/2309.09967v1"},"cats":{"new-dataset":0.0107567836,"dev-research":0.1324739126,"data-quality":0.0484442235}}
{"text":"Most frequently, the objective is to seed the tournament in a way that \"assists\" (or even guarantees) some particular player to win the competition.","meta":{"url":"http://arxiv.org/abs/2309.09967v1"},"cats":{"new-dataset":0.0031902209,"dev-research":0.2292993502,"data-quality":0.0687767202}}
{"text":"We introduce a new objective, which is very sensible from the perspective of the directors of the competition: maximize the profit or popularity of the tournament.","meta":{"url":"http://arxiv.org/abs/2309.09967v1"},"cats":{"new-dataset":0.0659626589,"dev-research":0.238476441,"data-quality":0.0858166936}}
{"text":"Specifically, we associate a \"score\" with every possible match, and aim to seed the tournament to maximize the sum of the scores of the matches that take place.","meta":{"url":"http://arxiv.org/abs/2309.09967v1"},"cats":{"new-dataset":0.028132743,"dev-research":0.1937928658,"data-quality":0.0937562383}}
{"text":"We focus on the case where we assume a total order on the players' strengths, and provide a wide spectrum of results on the computational complexity of the problem.","meta":{"url":"http://arxiv.org/abs/2309.09967v1"},"cats":{"new-dataset":0.0603552707,"dev-research":0.1820390359,"data-quality":0.0620261228}}
{"text":"Visual instruction tuning has recently shown encouraging progress with open-source large multimodal models (LMM) such as LLaVA and MiniGPT-4.","meta":{"url":"http://arxiv.org/abs/2309.09958v1"},"cats":{"new-dataset":0.1906143641,"dev-research":0.2586153271,"data-quality":0.0766467509}}
{"text":"However, most existing studies of open-source LMM are performed using models with 13B parameters or smaller.","meta":{"url":"http://arxiv.org/abs/2309.09958v1"},"cats":{"new-dataset":0.0570780272,"dev-research":0.1047934006,"data-quality":0.0712767506}}
{"text":"In this paper we present an empirical study of scaling LLaVA up to 33B and 65B/70B, and share our findings from our explorations in image resolution, data mixing and parameter-efficient training methods such as LoRA/QLoRA.","meta":{"url":"http://arxiv.org/abs/2309.09958v1"},"cats":{"new-dataset":0.2084207162,"dev-research":0.1040794636,"data-quality":0.1177943929}}
{"text":"These are evaluated by their impact on the multi-modal and language capabilities when completing real-world tasks in the wild.   ","meta":{"url":"http://arxiv.org/abs/2309.09958v1"},"cats":{"new-dataset":0.0382948354,"dev-research":0.2349908739,"data-quality":0.1013576549}}
{"text":"We find that scaling LMM consistently enhances model performance and improves language capabilities, and performance of LoRA/QLoRA tuning of LMM are comparable to the performance of full-model fine-tuning.","meta":{"url":"http://arxiv.org/abs/2309.09958v1"},"cats":{"new-dataset":0.0367299356,"dev-research":0.1342576421,"data-quality":0.1387333965}}
{"text":"Additionally, the study highlights the importance of higher image resolutions and mixing multimodal-language data to improve LMM performance, and visual instruction tuning can sometimes improve LMM's pure language capability.","meta":{"url":"http://arxiv.org/abs/2309.09958v1"},"cats":{"new-dataset":0.0993786708,"dev-research":0.2182681402,"data-quality":0.1372924603}}
{"text":"We hope that this study makes state-of-the-art LMM research at a larger scale more accessible, thus helping establish stronger baselines for future research.","meta":{"url":"http://arxiv.org/abs/2309.09958v1"},"cats":{"new-dataset":0.0471186421,"dev-research":0.118858295,"data-quality":0.0683671855}}
{"text":"Code and checkpoints will be made public.","meta":{"url":"http://arxiv.org/abs/2309.09958v1"},"cats":{"new-dataset":0.3455442085,"dev-research":0.2767437678,"data-quality":0.1201691762}}
{"text":"Posts, as important containers of user-generated-content pieces on social media, are of tremendous social influence and commercial value.","meta":{"url":"http://arxiv.org/abs/2309.09949v1"},"cats":{"new-dataset":0.0485627791,"dev-research":0.2055385331,"data-quality":0.1593732728}}
{"text":"As an integral components of a post, the headline has a decisive contribution to the post's popularity.","meta":{"url":"http://arxiv.org/abs/2309.09949v1"},"cats":{"new-dataset":0.0396976177,"dev-research":0.2092806759,"data-quality":0.1182640341}}
{"text":"However, current mainstream method for headline generation is still manually writing, which is unstable and requires extensive human effort.","meta":{"url":"http://arxiv.org/abs/2309.09949v1"},"cats":{"new-dataset":0.0426364139,"dev-research":0.289162142,"data-quality":0.2028962042}}
{"text":"This drives us to explore a novel research question: Can we automate the generation of popular headlines on social media?","meta":{"url":"http://arxiv.org/abs/2309.09949v1"},"cats":{"new-dataset":0.0543787107,"dev-research":0.2020574895,"data-quality":0.1534261109}}
{"text":"We collect more than 1 million posts of 42,447 celebrities from public data of Xiaohongshu, which is a well-known social media platform in China.","meta":{"url":"http://arxiv.org/abs/2309.09949v1"},"cats":{"new-dataset":0.8879678378,"dev-research":0.1547628449,"data-quality":0.114492813}}
{"text":"We then conduct careful observations on the headlines of these posts.","meta":{"url":"http://arxiv.org/abs/2309.09949v1"},"cats":{"new-dataset":0.1530641221,"dev-research":0.2481249562,"data-quality":0.2209980976}}
{"text":"Observation results demonstrate that trends and personal styles are widespread in headlines on social medias and have significant contribution to posts's popularity.","meta":{"url":"http://arxiv.org/abs/2309.09949v1"},"cats":{"new-dataset":0.0342493837,"dev-research":0.2353481518,"data-quality":0.1572455832}}
{"text":"Motivated by these insights, we present MEBART, which combines Multiple preference-Extractors with Bidirectional and Auto-Regressive Transformers (BART), capturing trends and personal styles to generate popular headlines on social medias.","meta":{"url":"http://arxiv.org/abs/2309.09949v1"},"cats":{"new-dataset":0.0369560957,"dev-research":0.1629073822,"data-quality":0.1814562384}}
{"text":"We perform extensive experiments on real-world datasets and achieve state-of-the-art performance compared with several advanced baselines.","meta":{"url":"http://arxiv.org/abs/2309.09949v1"},"cats":{"new-dataset":0.7990652359,"dev-research":0.1716479684,"data-quality":0.1481454504}}
{"text":"In addition, ablation and case studies demonstrate that MEBART advances in capturing trends and personal styles.","meta":{"url":"http://arxiv.org/abs/2309.09949v1"},"cats":{"new-dataset":0.025128201,"dev-research":0.1983494124,"data-quality":0.0902483725}}
{"text":"Visual Odometry (VO) is crucial for autonomous robotic navigation, especially in GPS-denied environments like planetary terrains.","meta":{"url":"http://arxiv.org/abs/2309.09947v1"},"cats":{"new-dataset":0.0240772289,"dev-research":0.2050577147,"data-quality":0.0978452116}}
{"text":"While standard RGB cameras struggle in low-light or high-speed motion, event-based cameras offer high dynamic range and low latency.","meta":{"url":"http://arxiv.org/abs/2309.09947v1"},"cats":{"new-dataset":0.1154510404,"dev-research":0.2226213704,"data-quality":0.0617600672}}
{"text":"However, seamlessly integrating asynchronous event data with synchronous frames remains challenging.","meta":{"url":"http://arxiv.org/abs/2309.09947v1"},"cats":{"new-dataset":0.1610033555,"dev-research":0.2272552925,"data-quality":0.1381482749}}
{"text":"We introduce RAMP-VO, the first end-to-end learned event- and image-based VO system.","meta":{"url":"http://arxiv.org/abs/2309.09947v1"},"cats":{"new-dataset":0.3644996452,"dev-research":0.1738899568,"data-quality":0.1314415179}}
{"text":"It leverages novel Recurrent, Asynchronous, and Massively Parallel (RAMP) encoders that are 8x faster and 20% more accurate than existing asynchronous encoders.","meta":{"url":"http://arxiv.org/abs/2309.09947v1"},"cats":{"new-dataset":0.0194093922,"dev-research":0.160386916,"data-quality":0.0670338114}}
{"text":"RAMP-VO further employs a novel pose forecasting technique to predict future poses for initialization.","meta":{"url":"http://arxiv.org/abs/2309.09947v1"},"cats":{"new-dataset":0.1482820432,"dev-research":0.1696329325,"data-quality":0.0495984436}}
{"text":"Despite being trained only in simulation, RAMP-VO outperforms image- and event-based methods by 52% and 20%, respectively, on traditional, real-world benchmarks as well as newly introduced Apollo and Malapert landing sequences, paving the way for robust and asynchronous VO in space.","meta":{"url":"http://arxiv.org/abs/2309.09947v1"},"cats":{"new-dataset":0.1209732982,"dev-research":0.1574234654,"data-quality":0.1156410553}}
{"text":"Generative text-to-image (GTI) models produce high-quality images from short textual descriptions and are widely used in academic and creative domains.","meta":{"url":"http://arxiv.org/abs/2309.09944v1"},"cats":{"new-dataset":0.1632088103,"dev-research":0.164961649,"data-quality":0.1851933405}}
{"text":"However, GTI models frequently amplify biases from their training data, often producing prejudiced or stereotypical images.","meta":{"url":"http://arxiv.org/abs/2309.09944v1"},"cats":{"new-dataset":0.0139205361,"dev-research":0.1991264999,"data-quality":0.2335809975}}
{"text":"Yet, current bias mitigation strategies are limited and primarily focus on enforcing gender parity across occupations.","meta":{"url":"http://arxiv.org/abs/2309.09944v1"},"cats":{"new-dataset":0.0028232466,"dev-research":0.1983338583,"data-quality":0.1552079172}}
{"text":"To enhance GTI bias mitigation, we introduce DiffusionWorldViewer, a tool to analyze and manipulate GTI models' attitudes, values, stories, and expectations of the world that impact its generated images.","meta":{"url":"http://arxiv.org/abs/2309.09944v1"},"cats":{"new-dataset":0.0721108788,"dev-research":0.2054437293,"data-quality":0.1276719758}}
{"text":"Through an interactive interface deployed as a web-based GUI and Jupyter Notebook plugin, DiffusionWorldViewer categorizes existing demographics of GTI-generated images and provides interactive methods to align image demographics with user worldviews.","meta":{"url":"http://arxiv.org/abs/2309.09944v1"},"cats":{"new-dataset":0.2208236812,"dev-research":0.1583560628,"data-quality":0.1151195376}}
{"text":"In a study with 13 GTI users, we find that DiffusionWorldViewer allows users to represent their varied viewpoints about what GTI outputs are fair and, in doing so, challenges current notions of fairness that assume a universal worldview.","meta":{"url":"http://arxiv.org/abs/2309.09944v1"},"cats":{"new-dataset":0.0327456479,"dev-research":0.1861223608,"data-quality":0.1262824185}}
{"text":"Analyzing large-scale graphs poses challenges due to their increasing size and the demand for interactive and user-friendly analytics tools.","meta":{"url":"http://arxiv.org/abs/2309.09943v1"},"cats":{"new-dataset":0.2348846786,"dev-research":0.3141645565,"data-quality":0.0999296794}}
{"text":"These graphs arise from various domains, including cybersecurity, social sciences, health sciences, and network sciences, where networks can represent interactions between humans, neurons in the brain, or malicious flows in a network.","meta":{"url":"http://arxiv.org/abs/2309.09943v1"},"cats":{"new-dataset":0.1692209802,"dev-research":0.2496617024,"data-quality":0.0841998176}}
{"text":"Exploring these large graphs is crucial for revealing hidden structures and metrics that are not easily computable without parallel computing.","meta":{"url":"http://arxiv.org/abs/2309.09943v1"},"cats":{"new-dataset":0.1362581195,"dev-research":0.1710084993,"data-quality":0.1065744511}}
{"text":"Currently, Python users can leverage the open-source Arkouda framework to efficiently execute Pandas and NumPy-related tasks on thousands of cores.","meta":{"url":"http://arxiv.org/abs/2309.09943v1"},"cats":{"new-dataset":0.2161291326,"dev-research":0.2038747638,"data-quality":0.0554004389}}
{"text":"To address large-scale graph analysis, Arachne, an extension to Arkouda, enables easy transformation of Arkouda dataframes into graphs.","meta":{"url":"http://arxiv.org/abs/2309.09943v1"},"cats":{"new-dataset":0.5238620347,"dev-research":0.2417442171,"data-quality":0.1075315915}}
{"text":"This paper proposes and evaluates three distributable data structures for property graphs, implemented in Chapel, that are integrated into Arachne.","meta":{"url":"http://arxiv.org/abs/2309.09943v1"},"cats":{"new-dataset":0.4973628006,"dev-research":0.2733202812,"data-quality":0.1093881632}}
{"text":"Enriching Arachne with support for property graphs will empower data scientists to extend their analysis to new problem domains.","meta":{"url":"http://arxiv.org/abs/2309.09943v1"},"cats":{"new-dataset":0.1846814452,"dev-research":0.3193802532,"data-quality":0.1741911518}}
{"text":"Property graphs present additional complexities, requiring efficient storage for extra information on vertices and edges, such as labels, relationships, and properties.","meta":{"url":"http://arxiv.org/abs/2309.09943v1"},"cats":{"new-dataset":0.0830610806,"dev-research":0.2612941782,"data-quality":0.1315830216}}
{"text":"Unmanned aerial vehicles (UAVs) are capable of surveying expansive areas, but their operational range is constrained by limited battery capacity.","meta":{"url":"http://arxiv.org/abs/2309.09942v1"},"cats":{"new-dataset":0.0191524506,"dev-research":0.2253088902,"data-quality":0.0577837238}}
{"text":"The deployment of mobile recharging stations using unmanned ground vehicles (UGVs) significantly extends the endurance and effectiveness of UAVs.","meta":{"url":"http://arxiv.org/abs/2309.09942v1"},"cats":{"new-dataset":0.0356236772,"dev-research":0.2230565643,"data-quality":0.0790202892}}
{"text":"However, optimizing the routes of both UAVs and UGVs, known as the UAV-UGV cooperative routing problem, poses substantial challenges, particularly with respect to the selection of recharging locations.","meta":{"url":"http://arxiv.org/abs/2309.09942v1"},"cats":{"new-dataset":0.0119063397,"dev-research":0.1514635391,"data-quality":0.0706355075}}
{"text":"Here in this paper, we leverage reinforcement learning (RL) for the purpose of identifying optimal recharging locations while employing constraint programming to determine cooperative routes for the UAV and UGV.","meta":{"url":"http://arxiv.org/abs/2309.09942v1"},"cats":{"new-dataset":0.0576086895,"dev-research":0.1578771466,"data-quality":0.0695737724}}
{"text":"Our proposed framework is then benchmarked against a baseline solution that employs Genetic Algorithms (GA) to select rendezvous points.","meta":{"url":"http://arxiv.org/abs/2309.09942v1"},"cats":{"new-dataset":0.0623627562,"dev-research":0.1278755506,"data-quality":0.0714380689}}
{"text":"Our findings reveal that RL surpasses GA in terms of reducing overall mission time, minimizing UAV-UGV idle time, and mitigating energy consumption for both the UAV and UGV.","meta":{"url":"http://arxiv.org/abs/2309.09942v1"},"cats":{"new-dataset":0.0366909395,"dev-research":0.173796728,"data-quality":0.047434052}}
{"text":"These results underscore the efficacy of incorporating heuristics to assist RL, a method we refer to as heuristics-assisted RL, in generating high-quality solutions for intricate routing problems.","meta":{"url":"http://arxiv.org/abs/2309.09942v1"},"cats":{"new-dataset":0.0127034061,"dev-research":0.3083244208,"data-quality":0.0840517865}}
{"text":"Joint safety and security analysis of cyber-physical systems is a necessary step to correctly capture inter-dependencies between these properties.","meta":{"url":"http://arxiv.org/abs/2309.09941v1"},"cats":{"new-dataset":0.0520031933,"dev-research":0.3393708871,"data-quality":0.1422591545}}
{"text":"Attack-Fault Trees represent a combination of dynamic Fault Trees and Attack Trees and can be used to model and model-check a holistic view on both safety and security.","meta":{"url":"http://arxiv.org/abs/2309.09941v1"},"cats":{"new-dataset":0.1215329639,"dev-research":0.3664134373,"data-quality":0.1327052612}}
{"text":"Manually creating a complete AFT for the whole system is, however, a daunting task.","meta":{"url":"http://arxiv.org/abs/2309.09941v1"},"cats":{"new-dataset":0.0125271427,"dev-research":0.2754491095,"data-quality":0.1030887446}}
{"text":"It needs to span multiple abstraction layers, e.g., abstract application architecture and data flow as well as system and library dependencies that are affected by various vulnerabilities.","meta":{"url":"http://arxiv.org/abs/2309.09941v1"},"cats":{"new-dataset":0.0295243413,"dev-research":0.3086131013,"data-quality":0.0812517563}}
{"text":"We present an AFT generation tool-chain that facilitates this task using partial Fault and Attack Trees that are either manually created or mined from vulnerability databases.","meta":{"url":"http://arxiv.org/abs/2309.09941v1"},"cats":{"new-dataset":0.2975311525,"dev-research":0.3361071636,"data-quality":0.162377497}}
{"text":"We semi-automatically create two system models that provide the necessary information to automatically combine these partial Fault and Attack Trees into complete AFTs using graph transformation rules.","meta":{"url":"http://arxiv.org/abs/2309.09941v1"},"cats":{"new-dataset":0.077254012,"dev-research":0.3010173203,"data-quality":0.1883499274}}
{"text":"As of today, robots exhibit impressive agility but also pose potential hazards to humans using/collaborating with them.","meta":{"url":"http://arxiv.org/abs/2309.09936v1"},"cats":{"new-dataset":0.0552217726,"dev-research":0.3280250322,"data-quality":0.0674361643}}
{"text":"Consequently, safety is considered the most paramount factor in human-robot interaction (HRI).","meta":{"url":"http://arxiv.org/abs/2309.09936v1"},"cats":{"new-dataset":0.0513024556,"dev-research":0.3529096863,"data-quality":0.0673066134}}
{"text":"This paper presents a multi-layered safety architecture, integrating both physical and cognitive aspects for effective HRI.","meta":{"url":"http://arxiv.org/abs/2309.09936v1"},"cats":{"new-dataset":0.0458259955,"dev-research":0.4201230306,"data-quality":0.0874576764}}
{"text":"We outline critical requirements for physical safety layers as service modules that can be arbitrarily queried.","meta":{"url":"http://arxiv.org/abs/2309.09936v1"},"cats":{"new-dataset":0.1594669817,"dev-research":0.3071606727,"data-quality":0.1038366701}}
{"text":"Further, we showcase an HRI scheme that addresses human factors and perceived safety as high-level constraints on a validated impact safety paradigm.","meta":{"url":"http://arxiv.org/abs/2309.09936v1"},"cats":{"new-dataset":0.086728986,"dev-research":0.4809664463,"data-quality":0.1402528964}}
{"text":"The aim is to enable safety certification of human-friendly robots across various HRI scenarios.","meta":{"url":"http://arxiv.org/abs/2309.09936v1"},"cats":{"new-dataset":0.0910450545,"dev-research":0.3027674596,"data-quality":0.1021047883}}
{"text":"The most commonly used method for addressing 3D geometric registration is the iterative closet-point algorithm, this approach is incremental and prone to drift over multiple consecutive frames.","meta":{"url":"http://arxiv.org/abs/2309.09934v1"},"cats":{"new-dataset":0.0169635476,"dev-research":0.2042138019,"data-quality":0.0975028974}}
{"text":"The Common strategy to address the drift is the pose graph optimization subsequent to frame-to-frame registration, incorporating a loop closure process that identifies previously visited places.","meta":{"url":"http://arxiv.org/abs/2309.09934v1"},"cats":{"new-dataset":0.0859517178,"dev-research":0.22454744,"data-quality":0.1387652874}}
{"text":"In this paper, we explore a framework that replaces traditional geometric registration and pose graph optimization with a learned model utilizing hierarchical attention mechanisms and graph neural networks.","meta":{"url":"http://arxiv.org/abs/2309.09934v1"},"cats":{"new-dataset":0.1673080292,"dev-research":0.1876560713,"data-quality":0.0859811722}}
{"text":"We propose a strategy to condense the data flow, preserving essential information required for the precise estimation of rigid poses.","meta":{"url":"http://arxiv.org/abs/2309.09934v1"},"cats":{"new-dataset":0.1848816797,"dev-research":0.1468920556,"data-quality":0.0887803929}}
{"text":"Our results, derived from tests on the KITTI Odometry dataset, demonstrate a significant improvement in pose estimation accuracy.","meta":{"url":"http://arxiv.org/abs/2309.09934v1"},"cats":{"new-dataset":0.3264322988,"dev-research":0.1859713771,"data-quality":0.1458172116}}
{"text":"This improvement is especially notable in determining rotational components when compared with results obtained through conventional multi-way registration via pose graph optimization.","meta":{"url":"http://arxiv.org/abs/2309.09934v1"},"cats":{"new-dataset":0.0272144575,"dev-research":0.1665821189,"data-quality":0.0877942066}}
{"text":"The code will be made available upon completion of the review process.","meta":{"url":"http://arxiv.org/abs/2309.09934v1"},"cats":{"new-dataset":0.1312061573,"dev-research":0.3480626683,"data-quality":0.142234646}}
{"text":"Typical arguments for results like Kleene's Second Recursion Theorem and the existence of self-writing computer programs bear the fingerprints of equational reasoning and combinatory logic.","meta":{"url":"http://arxiv.org/abs/2309.09931v1"},"cats":{"new-dataset":0.0262154731,"dev-research":0.3079685351,"data-quality":0.0895372652}}
{"text":"In fact, the connection of combinatory logic and computability theory is very old, and this paper extends this connection in new ways.","meta":{"url":"http://arxiv.org/abs/2309.09931v1"},"cats":{"new-dataset":0.0166519252,"dev-research":0.2150655286,"data-quality":0.0706681391}}
{"text":"In one direction, we counter the main trend in both computability theory and combinatory logic of heading straight to undecidability.","meta":{"url":"http://arxiv.org/abs/2309.09931v1"},"cats":{"new-dataset":0.0145219606,"dev-research":0.2227643857,"data-quality":0.1405191607}}
{"text":"Instead, this paper proposes using several very small equational logics to examine results in computability theory itself.","meta":{"url":"http://arxiv.org/abs/2309.09931v1"},"cats":{"new-dataset":0.010449012,"dev-research":0.2475773839,"data-quality":0.0783719668}}
{"text":"These logics are decidable via term rewriting.","meta":{"url":"http://arxiv.org/abs/2309.09931v1"},"cats":{"new-dataset":0.0114344075,"dev-research":0.2602175561,"data-quality":0.1412896001}}
{"text":"We argue that they have something interesting to say about computability theory.","meta":{"url":"http://arxiv.org/abs/2309.09931v1"},"cats":{"new-dataset":0.0210308738,"dev-research":0.2893772079,"data-quality":0.1129760312}}
{"text":"They are closely related to fragments of combinatory logic which are decidable, and so this paper contributes to the study of such fragments.","meta":{"url":"http://arxiv.org/abs/2309.09931v1"},"cats":{"new-dataset":0.0296431668,"dev-research":0.1879962037,"data-quality":0.1041016931}}
{"text":"The paper has a few surprising results such as a classification of quine programs (programs which output themselves) in two decidable fragments.","meta":{"url":"http://arxiv.org/abs/2309.09931v1"},"cats":{"new-dataset":0.0598402145,"dev-research":0.2431640428,"data-quality":0.185970479}}
{"text":"The classification goes via examination of normal forms in term rewriting systems, hence the title of the paper.","meta":{"url":"http://arxiv.org/abs/2309.09931v1"},"cats":{"new-dataset":0.0277309995,"dev-research":0.2377741609,"data-quality":0.2458606683}}
{"text":"The classification is an explanation of why all quine programs (in any language) are \"pretty much the same, except for inessential details.\"","meta":{"url":"http://arxiv.org/abs/2309.09931v1"},"cats":{"new-dataset":0.0439863298,"dev-research":0.2909857621,"data-quality":0.2386851188}}
{"text":"In addition, we study the relational structure whose objects are the programs with the relation \"p expresses q\" meaning that if the program p is run on nothing, then it eventually outputs the program q.","meta":{"url":"http://arxiv.org/abs/2309.09931v1"},"cats":{"new-dataset":0.0265417006,"dev-research":0.2861371376,"data-quality":0.1068957143}}
{"text":"We introduce a metric for evaluating the robustness of a classifier, with particular attention to adversarial perturbations, in terms of expected functionality with respect to possible adversarial perturbations.","meta":{"url":"http://arxiv.org/abs/2309.09928v1"},"cats":{"new-dataset":0.019679672,"dev-research":0.2082275135,"data-quality":0.516228968}}
{"text":"A classifier is assumed to be non-functional (that is, has a functionality of zero) with respect to a perturbation bound if a conventional measure of performance, such as classification accuracy, is less than a minimally viable threshold when the classifier is tested on examples from that perturbation bound.","meta":{"url":"http://arxiv.org/abs/2309.09928v1"},"cats":{"new-dataset":0.0046927382,"dev-research":0.1643506991,"data-quality":0.3484705452}}
{"text":"Defining robustness in terms of an expected value is motivated by a domain general approach to robustness quantification.","meta":{"url":"http://arxiv.org/abs/2309.09928v1"},"cats":{"new-dataset":0.0083247327,"dev-research":0.2887356102,"data-quality":0.307679211}}
{"text":"Precise and timely fault diagnosis is a prerequisite for a distribution system to ensure minimum downtime and maintain reliable operation.","meta":{"url":"http://arxiv.org/abs/2309.09921v1"},"cats":{"new-dataset":0.0279954548,"dev-research":0.3688883328,"data-quality":0.2604451548}}
{"text":"This necessitates access to a comprehensive procedure that can provide the grid operators with insightful information in the case of a fault event.","meta":{"url":"http://arxiv.org/abs/2309.09921v1"},"cats":{"new-dataset":0.0732852881,"dev-research":0.3576300871,"data-quality":0.1020722286}}
{"text":"In this paper, we propose a heterogeneous multi-task learning graph neural network (MTL-GNN) capable of detecting, locating and classifying faults in addition to providing an estimate of the fault resistance and current.","meta":{"url":"http://arxiv.org/abs/2309.09921v1"},"cats":{"new-dataset":0.1877322773,"dev-research":0.2584288625,"data-quality":0.2542480414}}
{"text":"Using a graph neural network (GNN) allows for learning the topological representation of the distribution system as well as feature learning through a message-passing scheme.","meta":{"url":"http://arxiv.org/abs/2309.09921v1"},"cats":{"new-dataset":0.0772278938,"dev-research":0.1528814468,"data-quality":0.1242395091}}
{"text":"We investigate the robustness of our proposed model using the IEEE-123 test feeder system.","meta":{"url":"http://arxiv.org/abs/2309.09921v1"},"cats":{"new-dataset":0.0261652089,"dev-research":0.1688200429,"data-quality":0.2596562572}}
{"text":"This work also proposes a novel GNN-based explainability method to identify key nodes in the distribution system which then facilitates informed sparse measurements.","meta":{"url":"http://arxiv.org/abs/2309.09921v1"},"cats":{"new-dataset":0.0346412696,"dev-research":0.1877412599,"data-quality":0.2477863143}}
{"text":"Numerical tests validate the performance of the model across all tasks.","meta":{"url":"http://arxiv.org/abs/2309.09921v1"},"cats":{"new-dataset":0.0058502678,"dev-research":0.2294767843,"data-quality":0.080693109}}
{"text":"Recent advancements in large language models (LLMs) have enabled a new research domain, LLM agents, for solving robotics and planning tasks by leveraging the world knowledge and general reasoning abilities of LLMs obtained during pretraining.","meta":{"url":"http://arxiv.org/abs/2309.09919v1"},"cats":{"new-dataset":0.1816197406,"dev-research":0.2010349342,"data-quality":0.0743687631}}
{"text":"However, while considerable effort has been made to teach the robot the \"dos,\" the \"don'ts\" received relatively less attention.","meta":{"url":"http://arxiv.org/abs/2309.09919v1"},"cats":{"new-dataset":0.0185366196,"dev-research":0.2255242315,"data-quality":0.1653449029}}
{"text":"We argue that, for any practical usage, it is as crucial to teach the robot the \"don'ts\": conveying explicit instructions about prohibited actions, assessing the robot's comprehension of these restrictions, and, most importantly, ensuring compliance.","meta":{"url":"http://arxiv.org/abs/2309.09919v1"},"cats":{"new-dataset":0.070265353,"dev-research":0.321419431,"data-quality":0.1277202934}}
{"text":"Moreover, verifiable safe operation is essential for deployments that satisfy worldwide standards such as ISO 61508, which defines standards for safely deploying robots in industrial factory environments worldwide.","meta":{"url":"http://arxiv.org/abs/2309.09919v1"},"cats":{"new-dataset":0.0912330719,"dev-research":0.2787863527,"data-quality":0.1767347989}}
{"text":"Aiming at deploying the LLM agents in a collaborative environment, we propose a queryable safety constraint module based on linear temporal logic (LTL) that simultaneously enables natural language (NL) to temporal constraints encoding, safety violation reasoning and explaining, and unsafe action pruning.","meta":{"url":"http://arxiv.org/abs/2309.09919v1"},"cats":{"new-dataset":0.3441230333,"dev-research":0.3867795326,"data-quality":0.109920738}}
{"text":"To demonstrate the effectiveness of our system, we conducted experiments in VirtualHome environment and on a real robot.","meta":{"url":"http://arxiv.org/abs/2309.09919v1"},"cats":{"new-dataset":0.0730496326,"dev-research":0.2712142366,"data-quality":0.0788968097}}
{"text":"The experimental results show that our system strictly adheres to the safety constraints and scales well with complex safety constraints, highlighting its potential for practical utility.","meta":{"url":"http://arxiv.org/abs/2309.09919v1"},"cats":{"new-dataset":0.0275650057,"dev-research":0.2429419206,"data-quality":0.0727700627}}
{"text":"In explainable artificial intelligence (XAI) research, the predominant focus has been on interpreting models for experts and practitioners.","meta":{"url":"http://arxiv.org/abs/2309.09917v1"},"cats":{"new-dataset":0.0329738678,"dev-research":0.3379777006,"data-quality":0.1204093905}}
{"text":"Model agnostic and local explanation approaches are deemed interpretable and sufficient in many applications.","meta":{"url":"http://arxiv.org/abs/2309.09917v1"},"cats":{"new-dataset":0.0076499323,"dev-research":0.3352191824,"data-quality":0.1620063407}}
{"text":"However, in domains like healthcare, where end users are patients without AI or domain expertise, there is an urgent need for model explanations that are more comprehensible and instil trust in the model's operations.","meta":{"url":"http://arxiv.org/abs/2309.09917v1"},"cats":{"new-dataset":0.0131051018,"dev-research":0.3443061757,"data-quality":0.1028263844}}
{"text":"We hypothesise that generating model explanations that are narrative, patient-specific and global(holistic of the model) would enable better understandability and enable decision-making.","meta":{"url":"http://arxiv.org/abs/2309.09917v1"},"cats":{"new-dataset":0.0296076825,"dev-research":0.3243321548,"data-quality":0.092523535}}
{"text":"We test this using a decision tree model to generate both local and global explanations for patients identified as having a high risk of coronary heart disease.","meta":{"url":"http://arxiv.org/abs/2309.09917v1"},"cats":{"new-dataset":0.0175788381,"dev-research":0.2965977172,"data-quality":0.1589322041}}
{"text":"These explanations are presented to non-expert users.","meta":{"url":"http://arxiv.org/abs/2309.09917v1"},"cats":{"new-dataset":0.0107180448,"dev-research":0.434809392,"data-quality":0.1639603004}}
{"text":"We find a strong individual preference for a specific type of explanation.","meta":{"url":"http://arxiv.org/abs/2309.09917v1"},"cats":{"new-dataset":0.0042433548,"dev-research":0.3441143535,"data-quality":0.1229031315}}
{"text":"The majority of participants prefer global explanations, while a smaller group prefers local explanations.","meta":{"url":"http://arxiv.org/abs/2309.09917v1"},"cats":{"new-dataset":0.0052140167,"dev-research":0.291300884,"data-quality":0.1211908969}}
{"text":"A task based evaluation of mental models of these participants provide valuable feedback to enhance narrative global explanations.","meta":{"url":"http://arxiv.org/abs/2309.09917v1"},"cats":{"new-dataset":0.0347976352,"dev-research":0.3734440933,"data-quality":0.1272644062}}
{"text":"This, in turn, guides the design of health informatics systems that are both trustworthy and actionable.","meta":{"url":"http://arxiv.org/abs/2309.09917v1"},"cats":{"new-dataset":0.0722749635,"dev-research":0.2716900866,"data-quality":0.077024002}}
{"text":"Autonomous mobility tasks such as lastmile delivery require reasoning about operator indicated preferences over terrains on which the robot should navigate to ensure both robot safety and mission success.","meta":{"url":"http://arxiv.org/abs/2309.09912v1"},"cats":{"new-dataset":0.0235137538,"dev-research":0.2562326738,"data-quality":0.050445933}}
{"text":"However, coping with out of distribution data from novel terrains or appearance changes due to lighting variations remains a fundamental problem in visual terrain adaptive navigation.","meta":{"url":"http://arxiv.org/abs/2309.09912v1"},"cats":{"new-dataset":0.0561187593,"dev-research":0.2219930645,"data-quality":0.0865676875}}
{"text":"Existing solutions either require labor intensive manual data recollection and labeling or use handcoded reward functions that may not align with operator preferences.","meta":{"url":"http://arxiv.org/abs/2309.09912v1"},"cats":{"new-dataset":0.0837788915,"dev-research":0.181350292,"data-quality":0.2431076081}}
{"text":"In this work, we posit that operator preferences for visually novel terrains, which the robot should adhere to, can often be extrapolated from established terrain references within the inertial, proprioceptive, and tactile domain.","meta":{"url":"http://arxiv.org/abs/2309.09912v1"},"cats":{"new-dataset":0.0891557885,"dev-research":0.2412849142,"data-quality":0.0519710012}}
{"text":"Leveraging this insight, we introduce Preference extrApolation for Terrain awarE Robot Navigation, PATERN, a novel framework for extrapolating operator terrain preferences for visual navigation.","meta":{"url":"http://arxiv.org/abs/2309.09912v1"},"cats":{"new-dataset":0.0839634921,"dev-research":0.1988775871,"data-quality":0.0564388732}}
{"text":"PATERN learns to map inertial, proprioceptive, tactile measurements from the robots observations to a representation space and performs nearest neighbor search in this space to estimate operator preferences over novel terrains.","meta":{"url":"http://arxiv.org/abs/2309.09912v1"},"cats":{"new-dataset":0.223002666,"dev-research":0.1419883694,"data-quality":0.0652308284}}
{"text":"Through physical robot experiments in outdoor environments, we assess PATERNs capability to extrapolate preferences and generalize to novel terrains and challenging lighting conditions.","meta":{"url":"http://arxiv.org/abs/2309.09912v1"},"cats":{"new-dataset":0.0577050228,"dev-research":0.2329783354,"data-quality":0.0424226462}}
{"text":"Compared to baseline approaches, our findings indicate that PATERN robustly generalizes to diverse terrains and varied lighting conditions, while navigating in a preference aligned manner.","meta":{"url":"http://arxiv.org/abs/2309.09912v1"},"cats":{"new-dataset":0.0441222992,"dev-research":0.2143604083,"data-quality":0.0521527421}}
{"text":"The recent surge of utilizing deep neural networks for geometric processing and shape modeling has opened up exciting avenues.","meta":{"url":"http://arxiv.org/abs/2309.09911v1"},"cats":{"new-dataset":0.0577131524,"dev-research":0.1626689355,"data-quality":0.0515824598}}
{"text":"However, there is a conspicuous lack of research efforts on using powerful neural representations to extend the capabilities of parametric surfaces, which are the prevalent surface representations in product design, CAD/CAM, and computer animation.","meta":{"url":"http://arxiv.org/abs/2309.09911v1"},"cats":{"new-dataset":0.0248815901,"dev-research":0.2573571585,"data-quality":0.0395834122}}
{"text":"We present Neural Parametric Surfaces, the first piecewise neural surface representation that allows coarse patch layouts of arbitrary $n$-sided surface patches to model complex surface geometries with high precision, offering greater flexibility over traditional parametric surfaces.","meta":{"url":"http://arxiv.org/abs/2309.09911v1"},"cats":{"new-dataset":0.1399814105,"dev-research":0.2171292853,"data-quality":0.0402651763}}
{"text":"By construction, this new surface representation guarantees $G^0$ continuity between adjacent patches and empirically achieves $G^1$ continuity, which cannot be attained by existing neural patch-based methods.","meta":{"url":"http://arxiv.org/abs/2309.09911v1"},"cats":{"new-dataset":0.0283943869,"dev-research":0.1718044849,"data-quality":0.0911102725}}
{"text":"The key ingredient of our neural parametric surface is a learnable feature complex $\\mathcal{C}$ that is embedded in a high-dimensional space $\\mathbb{R}^D$ and topologically equivalent to the patch layout of the surface; each face cell of the complex is defined by interpolating feature vectors at its vertices.","meta":{"url":"http://arxiv.org/abs/2309.09911v1"},"cats":{"new-dataset":0.0713759771,"dev-research":0.2176483924,"data-quality":0.0428154007}}
{"text":"The learned feature complex is mapped by an MLP-encoded function $f:\\mathcal{C} \\rightarrow \\mathcal{S}$ to produce the neural parametric surface $\\mathcal{S}$. We present a surface fitting algorithm that optimizes the feature complex $\\mathcal{C}$ and trains the neural mapping $f$ to reconstruct given target shapes with high accuracy.","meta":{"url":"http://arxiv.org/abs/2309.09911v1"},"cats":{"new-dataset":0.128413697,"dev-research":0.2106048385,"data-quality":0.0798957654}}
{"text":"We further show that the proposed representation along with a compact-size neural net can learn a plausible shape space from a shape collection, which can be used for shape interpolation or shape completion from noisy and incomplete input data.","meta":{"url":"http://arxiv.org/abs/2309.09911v1"},"cats":{"new-dataset":0.1266991083,"dev-research":0.1829852606,"data-quality":0.1235861976}}
{"text":"Extensive experiments show that neural parametric surfaces offer greater modeling capabilities than traditional parametric surfaces.","meta":{"url":"http://arxiv.org/abs/2309.09911v1"},"cats":{"new-dataset":0.0191102977,"dev-research":0.1908265275,"data-quality":0.0337077685}}
{"text":"The growing body of political texts opens up new opportunities for rich insights into political dynamics and ideologies but also increases the workload for manual analysis.","meta":{"url":"http://arxiv.org/abs/2309.09902v1"},"cats":{"new-dataset":0.1411397263,"dev-research":0.2777414705,"data-quality":0.1531334595}}
{"text":"Automated speaker attribution, which detects who said what to whom in a speech event and is closely related to semantic role labeling, is an important processing step for computational text analysis.","meta":{"url":"http://arxiv.org/abs/2309.09902v1"},"cats":{"new-dataset":0.1100454538,"dev-research":0.2193878425,"data-quality":0.3598115737}}
{"text":"We study the potential of the large language model family Llama 2 to automate speaker attribution in German parliamentary debates from 2017-2021.","meta":{"url":"http://arxiv.org/abs/2309.09902v1"},"cats":{"new-dataset":0.2074984967,"dev-research":0.1491980084,"data-quality":0.2027852525}}
{"text":"We fine-tune Llama 2 with QLoRA, an efficient training strategy, and observe our approach to achieve competitive performance in the GermEval 2023 Shared Task On Speaker Attribution in German News Articles and Parliamentary Debates.","meta":{"url":"http://arxiv.org/abs/2309.09902v1"},"cats":{"new-dataset":0.1960059155,"dev-research":0.1269425757,"data-quality":0.2044420314}}
{"text":"Our results shed light on the capabilities of large language models in automating speaker attribution, revealing a promising avenue for computational analysis of political discourse and the development of semantic role labeling systems.","meta":{"url":"http://arxiv.org/abs/2309.09902v1"},"cats":{"new-dataset":0.3363232766,"dev-research":0.1900914708,"data-quality":0.2865923312}}
{"text":"Causality and eXplainable Artificial Intelligence (XAI) have developed as separate fields in computer science, even though the underlying concepts of causation and explanation share common ancient roots.","meta":{"url":"http://arxiv.org/abs/2309.09901v1"},"cats":{"new-dataset":0.0302647223,"dev-research":0.3713972537,"data-quality":0.1388559768}}
{"text":"This is further enforced by the lack of review works jointly covering these two fields.","meta":{"url":"http://arxiv.org/abs/2309.09901v1"},"cats":{"new-dataset":0.0116207011,"dev-research":0.2770711301,"data-quality":0.3242108552}}
{"text":"In this paper, we investigate the literature to try to understand how and to what extent causality and XAI are intertwined.","meta":{"url":"http://arxiv.org/abs/2309.09901v1"},"cats":{"new-dataset":0.0228915428,"dev-research":0.2779776997,"data-quality":0.1158538421}}
{"text":"More precisely, we seek to uncover what kinds of relationships exist between the two concepts and how one can benefit from them, for instance, in building trust in AI systems.","meta":{"url":"http://arxiv.org/abs/2309.09901v1"},"cats":{"new-dataset":0.0257901861,"dev-research":0.3069806664,"data-quality":0.0858851006}}
{"text":"As a result, three main perspectives are identified.","meta":{"url":"http://arxiv.org/abs/2309.09901v1"},"cats":{"new-dataset":0.0685438106,"dev-research":0.176834582,"data-quality":0.0918487816}}
{"text":"In the first one, the lack of causality is seen as one of the major limitations of current AI and XAI approaches, and the \"optimal\" form of explanations is investigated.","meta":{"url":"http://arxiv.org/abs/2309.09901v1"},"cats":{"new-dataset":0.0103895764,"dev-research":0.3308824178,"data-quality":0.139763409}}
{"text":"The second is a pragmatic perspective and considers XAI as a tool to foster scientific exploration for causal inquiry, via the identification of pursue-worthy experimental manipulations.","meta":{"url":"http://arxiv.org/abs/2309.09901v1"},"cats":{"new-dataset":0.0170686402,"dev-research":0.2939551552,"data-quality":0.1109727953}}
{"text":"Finally, the third perspective supports the idea that causality is propaedeutic to XAI in three possible manners: exploiting concepts borrowed from causality to support or improve XAI, utilizing counterfactuals for explainability, and considering accessing a causal model as explaining itself.","meta":{"url":"http://arxiv.org/abs/2309.09901v1"},"cats":{"new-dataset":0.0284496612,"dev-research":0.311389111,"data-quality":0.1603751198}}
{"text":"To complement our analysis, we also provide relevant software solutions used to automate causal tasks.","meta":{"url":"http://arxiv.org/abs/2309.09901v1"},"cats":{"new-dataset":0.0942867375,"dev-research":0.4177588275,"data-quality":0.1611485695}}
{"text":"We believe our work provides a unified view of the two fields of causality and XAI by highlighting potential domain bridges and uncovering possible limitations.","meta":{"url":"http://arxiv.org/abs/2309.09901v1"},"cats":{"new-dataset":0.0295541043,"dev-research":0.2257667642,"data-quality":0.1475170695}}
{"text":"The English proficiency of students in rural areas of China tends to be lower than that of their urban counterparts, owing to outdated teaching methods, a lack of advanced technology resources, and low motivation for English learning.","meta":{"url":"http://arxiv.org/abs/2309.09894v1"},"cats":{"new-dataset":0.023402958,"dev-research":0.2585731472,"data-quality":0.1473260144}}
{"text":"This study examines the impact of an Augmented Reality English Words Learning (AREWL) system on the learning motivation, achievement, behavioral patterns, and cognitive attainment of elementary school students in rural China.","meta":{"url":"http://arxiv.org/abs/2309.09894v1"},"cats":{"new-dataset":0.054168015,"dev-research":0.2004082574,"data-quality":0.1079204234}}
{"text":"The study explores whether student motivation varies with their level of achievement and vice versa, and provides an analysis of behavioral patterns and cognitive attainment.","meta":{"url":"http://arxiv.org/abs/2309.09894v1"},"cats":{"new-dataset":0.0244011076,"dev-research":0.2193535499,"data-quality":0.0649576387}}
{"text":"The AREWL system employs 3D virtual objects, animations, and assessments to teach English pronunciation and spelling.","meta":{"url":"http://arxiv.org/abs/2309.09894v1"},"cats":{"new-dataset":0.0714509441,"dev-research":0.1787651482,"data-quality":0.09291411}}
{"text":"Instructions are provided in both English and Chinese for ease of use.   ","meta":{"url":"http://arxiv.org/abs/2309.09894v1"},"cats":{"new-dataset":0.0998816104,"dev-research":0.2716332632,"data-quality":0.1379185682}}
{"text":"The sample group consisted of 20 students from grades 1 and 2, selected based on low pretest scores, along with five non-native teachers.","meta":{"url":"http://arxiv.org/abs/2309.09894v1"},"cats":{"new-dataset":0.1908948005,"dev-research":0.1591238077,"data-quality":0.0945352883}}
{"text":"Data were collected through pretests and posttests, questionnaires, surveys, video recordings, and in-app evaluations.","meta":{"url":"http://arxiv.org/abs/2309.09894v1"},"cats":{"new-dataset":0.4570470035,"dev-research":0.2643140651,"data-quality":0.0998620203}}
{"text":"Quantitative methods were used to analyze test scores and teacher opinions, while qualitative methods were employed to study student behavior and its relationship with cognitive attainment.   ","meta":{"url":"http://arxiv.org/abs/2309.09894v1"},"cats":{"new-dataset":0.0203912455,"dev-research":0.3104581818,"data-quality":0.0858317456}}
{"text":"Results indicate that both teachers and students responded favorably to the AREWL system.","meta":{"url":"http://arxiv.org/abs/2309.09894v1"},"cats":{"new-dataset":0.0129693787,"dev-research":0.1513833789,"data-quality":0.0890125396}}
{"text":"Students exhibited both intrinsic and extrinsic motivation, which correlated significantly with their learning achievements.","meta":{"url":"http://arxiv.org/abs/2309.09894v1"},"cats":{"new-dataset":0.0120452775,"dev-research":0.1671119683,"data-quality":0.0882415723}}
{"text":"While behavioral analysis showed interactive engagement with the AREWL system, cognitive attainment was found to be relatively low.","meta":{"url":"http://arxiv.org/abs/2309.09894v1"},"cats":{"new-dataset":0.0079250109,"dev-research":0.1978548754,"data-quality":0.0555959967}}
{"text":"The study concludes that AR-based learning applications can play an important role in motivating English learning among young learners in China.","meta":{"url":"http://arxiv.org/abs/2309.09894v1"},"cats":{"new-dataset":0.0256360869,"dev-research":0.2301003843,"data-quality":0.105929868}}
{"text":"The findings contribute to the field of educational technology by introducing a new AR-based English words learning application.","meta":{"url":"http://arxiv.org/abs/2309.09894v1"},"cats":{"new-dataset":0.0409197211,"dev-research":0.2139516346,"data-quality":0.1242597551}}
{"text":"Two lines of work are taking the central stage in AI research.","meta":{"url":"http://arxiv.org/abs/2309.09888v1"},"cats":{"new-dataset":0.0361170956,"dev-research":0.2548131741,"data-quality":0.103079084}}
{"text":"On the one hand, the community is making increasing efforts to build models that discard spurious correlations and generalize better in novel test environments.","meta":{"url":"http://arxiv.org/abs/2309.09888v1"},"cats":{"new-dataset":0.0126227919,"dev-research":0.4046681031,"data-quality":0.1714880412}}
{"text":"Unfortunately, the bitter lesson so far is that no proposal convincingly outperforms a simple empirical risk minimization baseline.","meta":{"url":"http://arxiv.org/abs/2309.09888v1"},"cats":{"new-dataset":0.007226254,"dev-research":0.2220549188,"data-quality":0.1950896665}}
{"text":"On the other hand, large language models (LLMs) have erupted as algorithms able to learn in-context, generalizing on-the-fly to the eclectic contextual circumstances that users enforce by means of prompting.","meta":{"url":"http://arxiv.org/abs/2309.09888v1"},"cats":{"new-dataset":0.0298092264,"dev-research":0.1796428937,"data-quality":0.1385148212}}
{"text":"In this paper, we argue that context $\\approx$ environment, and posit that in-context learning holds the key to better domain generalization.","meta":{"url":"http://arxiv.org/abs/2309.09888v1"},"cats":{"new-dataset":0.0379757186,"dev-research":0.2156405064,"data-quality":0.1901692034}}
{"text":"Via extensive theory and experiments, we show that paying attention to context$\\unicode{x2013}\\unicode{x2013}$unlabeled examples as they arrive$\\unicode{x2013}\\unicode{x2013}$allows our proposed In-Context Risk Minimization (ICRM) algorithm to zoom-in on the test environment risk minimizer, leading to significant out-of-distribution performance improvements.","meta":{"url":"http://arxiv.org/abs/2309.09888v1"},"cats":{"new-dataset":0.1132846608,"dev-research":0.2482961221,"data-quality":0.2706390937}}
{"text":"From all of this, two messages are worth taking home.","meta":{"url":"http://arxiv.org/abs/2309.09888v1"},"cats":{"new-dataset":0.1567894367,"dev-research":0.1908581061,"data-quality":0.1534712347}}
{"text":"Researchers in domain generalization should consider environment as context, and harness the adaptive power of in-context learning.","meta":{"url":"http://arxiv.org/abs/2309.09888v1"},"cats":{"new-dataset":0.0440369825,"dev-research":0.2644638505,"data-quality":0.1528687677}}
{"text":"Researchers in LLMs should consider context as environment to better structure data towards generalization.","meta":{"url":"http://arxiv.org/abs/2309.09888v1"},"cats":{"new-dataset":0.055890256,"dev-research":0.1776506556,"data-quality":0.1260015157}}
{"text":"Neural pathways as model explanations consist of a sparse set of neurons that provide the same level of prediction performance as the whole model.","meta":{"url":"http://arxiv.org/abs/2309.09887v1"},"cats":{"new-dataset":0.0236146417,"dev-research":0.2317844112,"data-quality":0.1258564211}}
{"text":"Existing methods primarily focus on accuracy and sparsity but the generated pathways may offer limited interpretability thus fall short in explaining the model behavior.","meta":{"url":"http://arxiv.org/abs/2309.09887v1"},"cats":{"new-dataset":0.0027968021,"dev-research":0.2051299705,"data-quality":0.2063070609}}
{"text":"In this paper, we suggest two interpretability criteria of neural pathways: (i) same-class neural pathways should primarily consist of class-relevant neurons; (ii) each instance's neural pathway sparsity should be optimally determined.","meta":{"url":"http://arxiv.org/abs/2309.09887v1"},"cats":{"new-dataset":0.008585048,"dev-research":0.1952604861,"data-quality":0.2414639477}}
{"text":"To this end, we propose a Generative Class-relevant Neural Pathway (GEN-CNP) model that learns to predict the neural pathways from the target model's feature maps.","meta":{"url":"http://arxiv.org/abs/2309.09887v1"},"cats":{"new-dataset":0.1080152728,"dev-research":0.1880593955,"data-quality":0.1258013213}}
{"text":"We propose to learn class-relevant information from features of deep and shallow layers such that same-class neural pathways exhibit high similarity.","meta":{"url":"http://arxiv.org/abs/2309.09887v1"},"cats":{"new-dataset":0.1549484262,"dev-research":0.1761199611,"data-quality":0.1981544148}}
{"text":"We further impose a faithfulness criterion for GEN-CNP to generate pathways with instance-specific sparsity.","meta":{"url":"http://arxiv.org/abs/2309.09887v1"},"cats":{"new-dataset":0.0140601428,"dev-research":0.1146354807,"data-quality":0.1646276192}}
{"text":"We propose to transfer the class-relevant neural pathways to explain samples of the same class and show experimentally and qualitatively their faithfulness and interpretability.","meta":{"url":"http://arxiv.org/abs/2309.09887v1"},"cats":{"new-dataset":0.0400318073,"dev-research":0.2064568857,"data-quality":0.274418253}}
{"text":"Over-the-air federated learning (OTA-FL) integrates communication and model aggregation by exploiting the innate superposition property of wireless channels.","meta":{"url":"http://arxiv.org/abs/2309.09883v1"},"cats":{"new-dataset":0.0428276198,"dev-research":0.123566979,"data-quality":0.0777090058}}
{"text":"The approach renders bandwidth efficient learning, but requires care in handling the wireless physical layer impairments.","meta":{"url":"http://arxiv.org/abs/2309.09883v1"},"cats":{"new-dataset":0.0113018687,"dev-research":0.2262860946,"data-quality":0.0966839375}}
{"text":"In this paper, federated edge learning is considered for a network that is heterogeneous with respect to client (edge node) data set distributions and individual client resources, under a general non-convex learning objective.","meta":{"url":"http://arxiv.org/abs/2309.09883v1"},"cats":{"new-dataset":0.029337782,"dev-research":0.0953892134,"data-quality":0.1243923744}}
{"text":"We augment the wireless OTA-FL system with a Reconfigurable Intelligent Surface (RIS) to enable a propagation environment with improved learning performance in a realistic time varying physical layer.","meta":{"url":"http://arxiv.org/abs/2309.09883v1"},"cats":{"new-dataset":0.0933660233,"dev-research":0.1776840162,"data-quality":0.0573911531}}
{"text":"Our approach is a cross-layer perspective that jointly optimizes communication, computation and learning resources, in this general heterogeneous setting.","meta":{"url":"http://arxiv.org/abs/2309.09883v1"},"cats":{"new-dataset":0.0418783969,"dev-research":0.2005024173,"data-quality":0.0606639352}}
{"text":"We adapt the local computation steps and transmission power of the clients in conjunction with the RIS phase shifts.","meta":{"url":"http://arxiv.org/abs/2309.09883v1"},"cats":{"new-dataset":0.0144715158,"dev-research":0.131529615,"data-quality":0.0779441748}}
{"text":"The resulting joint communication and learning algorithm, RIS-assisted Over-the-air Adaptive Resource Allocation for Federated learning (ROAR-Fed) is shown to be convergent in this general setting.","meta":{"url":"http://arxiv.org/abs/2309.09883v1"},"cats":{"new-dataset":0.0392567246,"dev-research":0.1416068363,"data-quality":0.0953049595}}
{"text":"Numerical results demonstrate the effectiveness of ROAR-Fed under heterogeneous (non i.i.d.)","meta":{"url":"http://arxiv.org/abs/2309.09883v1"},"cats":{"new-dataset":0.0260883868,"dev-research":0.1422393127,"data-quality":0.1077648323}}
{"text":"data and imperfect CSI, indicating the advantage of RIS assisted learning in this general set up.","meta":{"url":"http://arxiv.org/abs/2309.09883v1"},"cats":{"new-dataset":0.0621515129,"dev-research":0.1635798427,"data-quality":0.1438854433}}
{"text":"This paper introduces a differentiable representation for optimization of boustrophedon path plans in convex polygons, explores an additional parameter of these path plans that can be optimized, discusses the properties of this representation that can be leveraged during the optimization process, and shows that the previously published attempt at optimization of these path plans was too coarse to be practically useful.","meta":{"url":"http://arxiv.org/abs/2309.09882v1"},"cats":{"new-dataset":0.0178865861,"dev-research":0.2719299586,"data-quality":0.0406149674}}
{"text":"Experiments were conducted to show that this differentiable representation can reproduce the same scores from transitional discrete representations of boustrophedon path plans with high fidelity.","meta":{"url":"http://arxiv.org/abs/2309.09882v1"},"cats":{"new-dataset":0.0315527167,"dev-research":0.1506870059,"data-quality":0.0438578521}}
{"text":"Finally, optimization via gradient descent was attempted, but found to fail because the search space is far more non-convex than was previously considered in the literature.","meta":{"url":"http://arxiv.org/abs/2309.09882v1"},"cats":{"new-dataset":0.0030459717,"dev-research":0.0999388983,"data-quality":0.12480879}}
{"text":"The wide range of applications for boustrophedon path plans means that this work has the potential to improve path planning efficiency in numerous areas of robotics including mapping and search tasks using uncrewed aerial systems, environmental sampling tasks using uncrewed marine vehicles, and agricultural tasks using ground vehicles, among numerous others applications.","meta":{"url":"http://arxiv.org/abs/2309.09882v1"},"cats":{"new-dataset":0.0270634178,"dev-research":0.1863543925,"data-quality":0.029689662}}
{"text":"Traffic congestion in dense urban centers presents an economical and environmental burden.","meta":{"url":"http://arxiv.org/abs/2309.09881v1"},"cats":{"new-dataset":0.0629436071,"dev-research":0.2212083774,"data-quality":0.0624381216}}
{"text":"In recent years, the availability of vehicle-to-anything communication allows for the transmission of detailed vehicle states to the infrastructure that can be used for intelligent traffic light control.","meta":{"url":"http://arxiv.org/abs/2309.09881v1"},"cats":{"new-dataset":0.0270183773,"dev-research":0.1891918039,"data-quality":0.0749000596}}
{"text":"The other way around, the infrastructure can provide vehicles with advice on driving behavior, such as appropriate velocities, which can improve the efficacy of the traffic system.","meta":{"url":"http://arxiv.org/abs/2309.09881v1"},"cats":{"new-dataset":0.0128283186,"dev-research":0.2817766893,"data-quality":0.0507163214}}
{"text":"Several research works applied deep reinforcement learning to either traffic light control or vehicle speed advice.","meta":{"url":"http://arxiv.org/abs/2309.09881v1"},"cats":{"new-dataset":0.0492577848,"dev-research":0.2073826033,"data-quality":0.0604102659}}
{"text":"In this work, we propose a first attempt to jointly learn the control of both.","meta":{"url":"http://arxiv.org/abs/2309.09881v1"},"cats":{"new-dataset":0.0414082128,"dev-research":0.1624775784,"data-quality":0.0836885336}}
{"text":"We show this to improve the efficacy of traffic systems.","meta":{"url":"http://arxiv.org/abs/2309.09881v1"},"cats":{"new-dataset":0.0174458878,"dev-research":0.2126240832,"data-quality":0.133301418}}
{"text":"In our experiments, the joint control approach reduces average vehicle trip delays, w.r.t. controlling only traffic lights, in eight out of eleven benchmark scenarios.","meta":{"url":"http://arxiv.org/abs/2309.09881v1"},"cats":{"new-dataset":0.0152449707,"dev-research":0.2571251695,"data-quality":0.0610015939}}
{"text":"Analyzing the qualitative behavior of the vehicle speed advice policy, we observe that this is achieved by smoothing out the velocity profile of vehicles nearby a traffic light.","meta":{"url":"http://arxiv.org/abs/2309.09881v1"},"cats":{"new-dataset":0.0286281146,"dev-research":0.3063021963,"data-quality":0.0672905109}}
{"text":"Learning joint control of traffic signaling and speed advice in the real world could help to reduce congestion and mitigate the economical and environmental repercussions of today's traffic systems.","meta":{"url":"http://arxiv.org/abs/2309.09881v1"},"cats":{"new-dataset":0.0658747254,"dev-research":0.2258152056,"data-quality":0.0864359473}}
{"text":"In static environments, visual simultaneous localization and mapping (V-SLAM) methods achieve remarkable performance.","meta":{"url":"http://arxiv.org/abs/2309.09879v1"},"cats":{"new-dataset":0.0409612297,"dev-research":0.252145799,"data-quality":0.1267624321}}
{"text":"However, moving objects severely affect core modules of such systems like state estimation and loop closure detection.","meta":{"url":"http://arxiv.org/abs/2309.09879v1"},"cats":{"new-dataset":0.0133291425,"dev-research":0.2495467171,"data-quality":0.1583510793}}
{"text":"To address this, dynamic SLAM approaches often use semantic information, geometric constraints, or optical flow to mask features associated with dynamic entities.","meta":{"url":"http://arxiv.org/abs/2309.09879v1"},"cats":{"new-dataset":0.0362636069,"dev-research":0.2608488295,"data-quality":0.1209832443}}
{"text":"These are limited by various factors such as a dependency on the quality of the underlying method, poor generalization to unknown or unexpected moving objects, and often produce noisy results, e.g. by masking static but movable objects or making use of predefined thresholds.","meta":{"url":"http://arxiv.org/abs/2309.09879v1"},"cats":{"new-dataset":0.0019345778,"dev-research":0.2428654831,"data-quality":0.2066070303}}
{"text":"In this paper, to address these trade-offs, we introduce a novel visual SLAM system, DynaPix, based on per-pixel motion probability values.","meta":{"url":"http://arxiv.org/abs/2309.09879v1"},"cats":{"new-dataset":0.2678968123,"dev-research":0.2153190947,"data-quality":0.0758049092}}
{"text":"Our approach consists of a new semantic-free probabilistic pixel-wise motion estimation module and an improved pose optimization process.","meta":{"url":"http://arxiv.org/abs/2309.09879v1"},"cats":{"new-dataset":0.4140379468,"dev-research":0.2025567683,"data-quality":0.0685640408}}
{"text":"Our per-pixel motion probability estimation combines a novel static background differencing method on both images and optical flows from splatted frames.","meta":{"url":"http://arxiv.org/abs/2309.09879v1"},"cats":{"new-dataset":0.1105951293,"dev-research":0.1686716009,"data-quality":0.096076792}}
{"text":"DynaPix fully integrates those motion probabilities into both map point selection and weighted bundle adjustment within the tracking and optimization modules of ORB-SLAM2.","meta":{"url":"http://arxiv.org/abs/2309.09879v1"},"cats":{"new-dataset":0.0204411161,"dev-research":0.1941454316,"data-quality":0.0715087757}}
{"text":"We evaluate DynaPix against ORB-SLAM2 and DynaSLAM on both GRADE and TUM-RGBD datasets, obtaining lower errors and longer trajectory tracking times.","meta":{"url":"http://arxiv.org/abs/2309.09879v1"},"cats":{"new-dataset":0.3433631953,"dev-research":0.1877801056,"data-quality":0.1201585653}}
{"text":"We will release both source code and data upon acceptance of this work.","meta":{"url":"http://arxiv.org/abs/2309.09879v1"},"cats":{"new-dataset":0.5341001717,"dev-research":0.2396860098,"data-quality":0.1554622953}}
{"text":"User-generated texts available on the web and social platforms are often long and semantically challenging, making them difficult to annotate.","meta":{"url":"http://arxiv.org/abs/2309.09877v1"},"cats":{"new-dataset":0.1099813096,"dev-research":0.3126841188,"data-quality":0.4598100624}}
{"text":"Obtaining human annotation becomes increasingly difficult as problem domains become more specialized.","meta":{"url":"http://arxiv.org/abs/2309.09877v1"},"cats":{"new-dataset":0.2530187054,"dev-research":0.4105880515,"data-quality":0.4923712006}}
{"text":"For example, many health NLP problems require domain experts to be a part of the annotation pipeline.","meta":{"url":"http://arxiv.org/abs/2309.09877v1"},"cats":{"new-dataset":0.046688949,"dev-research":0.3795709462,"data-quality":0.4235336522}}
{"text":"Thus, it is crucial that we develop low-resource NLP solutions able to work with this set of limited-data problems.","meta":{"url":"http://arxiv.org/abs/2309.09877v1"},"cats":{"new-dataset":0.2312204855,"dev-research":0.1946318354,"data-quality":0.2478540903}}
{"text":"In this study, we employ Abstract Meaning Representation (AMR) graphs as a means to model low-resource Health NLP tasks sourced from various online health resources and communities.","meta":{"url":"http://arxiv.org/abs/2309.09877v1"},"cats":{"new-dataset":0.1725672524,"dev-research":0.2835401666,"data-quality":0.1725056384}}
{"text":"AMRs are well suited to model online health texts as they can represent multi-sentence inputs, abstract away from complex terminology, and model long-distance relationships between co-referring tokens.","meta":{"url":"http://arxiv.org/abs/2309.09877v1"},"cats":{"new-dataset":0.0497833551,"dev-research":0.1840920675,"data-quality":0.1379753429}}
{"text":"AMRs thus improve the ability of pre-trained language models to reason about high-complexity texts.","meta":{"url":"http://arxiv.org/abs/2309.09877v1"},"cats":{"new-dataset":0.0367995769,"dev-research":0.2477870006,"data-quality":0.1848588489}}
{"text":"Our experiments show that we can improve performance on 6 low-resource health NLP tasks by augmenting text embeddings with semantic graph embeddings.","meta":{"url":"http://arxiv.org/abs/2309.09877v1"},"cats":{"new-dataset":0.155166325,"dev-research":0.2830257899,"data-quality":0.2482411151}}
{"text":"Our approach is task agnostic and easy to merge into any standard text classification pipeline.","meta":{"url":"http://arxiv.org/abs/2309.09877v1"},"cats":{"new-dataset":0.0464396126,"dev-research":0.1766471345,"data-quality":0.3088780573}}
{"text":"We experimentally validate that AMRs are useful in the modeling of complex texts by analyzing performance through the lens of two textual complexity measures: the Flesch Kincaid Reading Level and Syntactic Complexity.","meta":{"url":"http://arxiv.org/abs/2309.09877v1"},"cats":{"new-dataset":0.0248821066,"dev-research":0.1570144919,"data-quality":0.1350732674}}
{"text":"Our error analysis shows that AMR-infused language models perform better on complex texts and generally show less predictive variance in the presence of changing complexity.","meta":{"url":"http://arxiv.org/abs/2309.09877v1"},"cats":{"new-dataset":0.0197317926,"dev-research":0.2293917581,"data-quality":0.2228991033}}
{"text":"Localization is paramount for autonomous robots.","meta":{"url":"http://arxiv.org/abs/2309.09875v1"},"cats":{"new-dataset":0.0222782974,"dev-research":0.1698269147,"data-quality":0.1186082239}}
{"text":"While camera and LiDAR-based approaches have been extensively investigated, they are affected by adverse illumination and weather conditions.","meta":{"url":"http://arxiv.org/abs/2309.09875v1"},"cats":{"new-dataset":0.0324970999,"dev-research":0.244497715,"data-quality":0.104975206}}
{"text":"Therefore, radar sensors have recently gained attention due to their intrinsic robustness to such conditions.","meta":{"url":"http://arxiv.org/abs/2309.09875v1"},"cats":{"new-dataset":0.0145983613,"dev-research":0.2087916427,"data-quality":0.1270204998}}
{"text":"In this paper, we propose RaLF, a novel deep neural network-based approach for localizing radar scans in a LiDAR map of the environment, by jointly learning to address both place recognition and metric localization.","meta":{"url":"http://arxiv.org/abs/2309.09875v1"},"cats":{"new-dataset":0.3530720559,"dev-research":0.1960787349,"data-quality":0.1870314698}}
{"text":"RaLF is composed of radar and LiDAR feature encoders, a place recognition head that generates global descriptors, and a metric localization head that predicts the 3-DoF transformation between the radar scan and the map.","meta":{"url":"http://arxiv.org/abs/2309.09875v1"},"cats":{"new-dataset":0.2673210762,"dev-research":0.1748833368,"data-quality":0.1121449464}}
{"text":"We tackle the place recognition task by learning a shared embedding space between the two modalities via cross-modal metric learning.","meta":{"url":"http://arxiv.org/abs/2309.09875v1"},"cats":{"new-dataset":0.1162270129,"dev-research":0.1378798164,"data-quality":0.2094502736}}
{"text":"Additionally, we perform metric localization by predicting pixel-level flow vectors that align the query radar scan with the LiDAR map.","meta":{"url":"http://arxiv.org/abs/2309.09875v1"},"cats":{"new-dataset":0.0918113357,"dev-research":0.183194267,"data-quality":0.1220990454}}
{"text":"We extensively evaluate our approach on multiple real-world driving datasets and show that RaLF achieves state-of-the-art performance for both place recognition and metric localization.","meta":{"url":"http://arxiv.org/abs/2309.09875v1"},"cats":{"new-dataset":0.62844628,"dev-research":0.1479790559,"data-quality":0.1653887134}}
{"text":"Moreover, we demonstrate that our approach can effectively generalize to different cities and sensor setups than the ones used during training.","meta":{"url":"http://arxiv.org/abs/2309.09875v1"},"cats":{"new-dataset":0.1363466281,"dev-research":0.2086454103,"data-quality":0.1048040734}}
{"text":"We make the code and trained models publicly available at http://ralf.cs.uni-freiburg.de.","meta":{"url":"http://arxiv.org/abs/2309.09875v1"},"cats":{"new-dataset":0.5628527954,"dev-research":0.1831682683,"data-quality":0.1004819177}}
{"text":"We report on a study that employs an in-house developed simulation infrastructure to accomplish zero shot policy transferability for a control policy associated with a scale autonomous vehicle.","meta":{"url":"http://arxiv.org/abs/2309.09870v1"},"cats":{"new-dataset":0.1347319975,"dev-research":0.1996344392,"data-quality":0.0699441284}}
{"text":"We focus on implementing policies that require no real world data to be trained (Zero-Shot Transfer), and are developed in-house as opposed to being validated by previous works.","meta":{"url":"http://arxiv.org/abs/2309.09870v1"},"cats":{"new-dataset":0.173907053,"dev-research":0.1901888646,"data-quality":0.1469945523}}
{"text":"We do this by implementing a Neural Network (NN) controller that is trained only on a family of circular reference trajectories.","meta":{"url":"http://arxiv.org/abs/2309.09870v1"},"cats":{"new-dataset":0.0509749677,"dev-research":0.1354823261,"data-quality":0.0640793581}}
{"text":"The sensors used are RTK-GPS and IMU, the latter for providing heading.","meta":{"url":"http://arxiv.org/abs/2309.09870v1"},"cats":{"new-dataset":0.2261031048,"dev-research":0.1647984821,"data-quality":0.0745202907}}
{"text":"The NN controller is trained using either a human driver (via human in the loop simulation), or a Model Predictive Control (MPC) strategy.","meta":{"url":"http://arxiv.org/abs/2309.09870v1"},"cats":{"new-dataset":0.047566585,"dev-research":0.1753369981,"data-quality":0.0677407618}}
{"text":"We demonstrate these two approaches in conjunction with two operation scenarios: the vehicle follows a waypoint-defined trajectory at constant speed; and the vehicle follows a speed profile that changes along the vehicle's waypoint-defined trajectory.","meta":{"url":"http://arxiv.org/abs/2309.09870v1"},"cats":{"new-dataset":0.0480632021,"dev-research":0.2351349388,"data-quality":0.0511244417}}
{"text":"The primary contribution of this work is the demonstration of Zero-Shot Transfer in conjunction with a novel feed-forward NN controller trained using a general purpose, in-house developed simulation platform.","meta":{"url":"http://arxiv.org/abs/2309.09870v1"},"cats":{"new-dataset":0.0578962757,"dev-research":0.1232217371,"data-quality":0.070185439}}
{"text":"When translating UI design prototypes to code in industry, automatically generating code from design prototypes can expedite the development of applications and GUI iterations.","meta":{"url":"http://arxiv.org/abs/2309.09867v1"},"cats":{"new-dataset":0.0886871655,"dev-research":0.600202284,"data-quality":0.1446689477}}
{"text":"However, in design prototypes without strict design specifications, UI components may be composed of fragmented elements.","meta":{"url":"http://arxiv.org/abs/2309.09867v1"},"cats":{"new-dataset":0.0124533407,"dev-research":0.350994427,"data-quality":0.1047487171}}
{"text":"Grouping these fragmented elements can greatly improve the readability and maintainability of the generated code.","meta":{"url":"http://arxiv.org/abs/2309.09867v1"},"cats":{"new-dataset":0.1004087348,"dev-research":0.3561597034,"data-quality":0.1574727155}}
{"text":"Current methods employ a two-stage strategy that introduces hand-crafted rules to group fragmented elements.","meta":{"url":"http://arxiv.org/abs/2309.09867v1"},"cats":{"new-dataset":0.0211428113,"dev-research":0.2774160612,"data-quality":0.1162971151}}
{"text":"Unfortunately, the performance of these methods is not satisfying due to visually overlapped and tiny UI elements.","meta":{"url":"http://arxiv.org/abs/2309.09867v1"},"cats":{"new-dataset":0.0120226441,"dev-research":0.1887163642,"data-quality":0.1131351847}}
{"text":"In this study, we propose EGFE, a novel method for automatically End-to-end Grouping Fragmented Elements via UI sequence prediction.","meta":{"url":"http://arxiv.org/abs/2309.09867v1"},"cats":{"new-dataset":0.2820828466,"dev-research":0.2241387696,"data-quality":0.1326648905}}
{"text":"To facilitate the UI understanding, we innovatively construct a Transformer encoder to model the relationship between the UI elements with multi-modal representation learning.","meta":{"url":"http://arxiv.org/abs/2309.09867v1"},"cats":{"new-dataset":0.0618079731,"dev-research":0.1973900704,"data-quality":0.0832589893}}
{"text":"The evaluation on a dataset of 4606 UI prototypes collected from professional UI designers shows that our method outperforms the state-of-the-art baselines in the precision (by 29.75\\%), recall (by 31.07\\%), and F1-score (by 30.39\\%) at edit distance threshold of 4.","meta":{"url":"http://arxiv.org/abs/2309.09867v1"},"cats":{"new-dataset":0.2681335151,"dev-research":0.4347199869,"data-quality":0.237960271}}
{"text":"In addition, we conduct an empirical study to assess the improvement of the generated front-end code.","meta":{"url":"http://arxiv.org/abs/2309.09867v1"},"cats":{"new-dataset":0.0853095914,"dev-research":0.5055018969,"data-quality":0.1383108093}}
{"text":"The results demonstrate the effectiveness of our method on a real software engineering application.","meta":{"url":"http://arxiv.org/abs/2309.09867v1"},"cats":{"new-dataset":0.0195670114,"dev-research":0.5214399716,"data-quality":0.1842816527}}
{"text":"Our end-to-end fragmented elements grouping method creates opportunities for improving UI-related software engineering tasks.","meta":{"url":"http://arxiv.org/abs/2309.09867v1"},"cats":{"new-dataset":0.0496900813,"dev-research":0.3724493091,"data-quality":0.1013248927}}
{"text":"Scene transfer for vision-based mobile robotics applications is a highly relevant and challenging problem.","meta":{"url":"http://arxiv.org/abs/2309.09865v1"},"cats":{"new-dataset":0.0767783873,"dev-research":0.1863350462,"data-quality":0.0944058737}}
{"text":"The utility of a robot greatly depends on its ability to perform a task in the real world, outside of a well-controlled lab environment.","meta":{"url":"http://arxiv.org/abs/2309.09865v1"},"cats":{"new-dataset":0.0159070607,"dev-research":0.2220581139,"data-quality":0.0526254738}}
{"text":"Existing scene transfer end-to-end policy learning approaches often suffer from poor sample efficiency or limited generalization capabilities, making them unsuitable for mobile robotics applications.","meta":{"url":"http://arxiv.org/abs/2309.09865v1"},"cats":{"new-dataset":0.0677328743,"dev-research":0.1746906201,"data-quality":0.1059181621}}
{"text":"This work proposes an adaptive multi-pair contrastive learning strategy for visual representation learning that enables zero-shot scene transfer and real-world deployment.","meta":{"url":"http://arxiv.org/abs/2309.09865v1"},"cats":{"new-dataset":0.1842906,"dev-research":0.1629956505,"data-quality":0.1252193705}}
{"text":"Control policies relying on the embedding are able to operate in unseen environments without the need for finetuning in the deployment environment.","meta":{"url":"http://arxiv.org/abs/2309.09865v1"},"cats":{"new-dataset":0.0171211084,"dev-research":0.2913850232,"data-quality":0.1344618073}}
{"text":"We demonstrate the performance of our approach on the task of agile, vision-based quadrotor flight.","meta":{"url":"http://arxiv.org/abs/2309.09865v1"},"cats":{"new-dataset":0.0638948569,"dev-research":0.2584391106,"data-quality":0.0518640746}}
{"text":"Extensive simulation and real-world experiments demonstrate that our approach successfully generalizes beyond the training domain and outperforms all baselines.","meta":{"url":"http://arxiv.org/abs/2309.09865v1"},"cats":{"new-dataset":0.0268631436,"dev-research":0.1350492122,"data-quality":0.1340440852}}
{"text":"Cognitive maps play a crucial role in facilitating flexible behaviour by representing spatial and conceptual relationships within an environment.","meta":{"url":"http://arxiv.org/abs/2309.09864v1"},"cats":{"new-dataset":0.0400383262,"dev-research":0.3947913219,"data-quality":0.0808015615}}
{"text":"The ability to learn and infer the underlying structure of the environment is crucial for effective exploration and navigation.","meta":{"url":"http://arxiv.org/abs/2309.09864v1"},"cats":{"new-dataset":0.0598704928,"dev-research":0.1815835212,"data-quality":0.0484844736}}
{"text":"This paper introduces a hierarchical active inference model addressing the challenge of inferring structure in the world from pixel-based observations.","meta":{"url":"http://arxiv.org/abs/2309.09864v1"},"cats":{"new-dataset":0.2816542936,"dev-research":0.1390804838,"data-quality":0.1449502351}}
{"text":"We propose a three-layer hierarchical model consisting of a cognitive map, an allocentric, and an egocentric world model, combining curiosity-driven exploration with goal-oriented behaviour at the different levels of reasoning from context to place to motion.","meta":{"url":"http://arxiv.org/abs/2309.09864v1"},"cats":{"new-dataset":0.0693558458,"dev-research":0.1398016131,"data-quality":0.0333089284}}
{"text":"This allows for efficient exploration and goal-directed search in room-structured mini-grid environments.","meta":{"url":"http://arxiv.org/abs/2309.09864v1"},"cats":{"new-dataset":0.0331429988,"dev-research":0.1853084342,"data-quality":0.028072571}}
{"text":"In this paper, we show that recent advances in video representation learning and pre-trained vision-language models allow for substantial improvements in self-supervised video object localization.","meta":{"url":"http://arxiv.org/abs/2309.09858v1"},"cats":{"new-dataset":0.1811284173,"dev-research":0.1933034266,"data-quality":0.3043753983}}
{"text":"We propose a method that first localizes objects in videos via a slot attention approach and then assigns text to the obtained slots.","meta":{"url":"http://arxiv.org/abs/2309.09858v1"},"cats":{"new-dataset":0.1004584176,"dev-research":0.1975762912,"data-quality":0.2794620885}}
{"text":"The latter is achieved by an unsupervised way to read localized semantic information from the pre-trained CLIP model.","meta":{"url":"http://arxiv.org/abs/2309.09858v1"},"cats":{"new-dataset":0.2108380859,"dev-research":0.1495783718,"data-quality":0.2818798419}}
{"text":"The resulting video object localization is entirely unsupervised apart from the implicit annotation contained in CLIP, and it is effectively the first unsupervised approach that yields good results on regular video benchmarks.","meta":{"url":"http://arxiv.org/abs/2309.09858v1"},"cats":{"new-dataset":0.0626292669,"dev-research":0.1694374725,"data-quality":0.303188688}}
{"text":"Camera-LiDAR extrinsic calibration is a critical task for multi-sensor fusion in autonomous systems, such as self-driving vehicles and mobile robots.","meta":{"url":"http://arxiv.org/abs/2309.09855v1"},"cats":{"new-dataset":0.071628066,"dev-research":0.1455012446,"data-quality":0.1263574143}}
{"text":"Traditional techniques often require manual intervention or specific environments, making them labour-intensive and error-prone.","meta":{"url":"http://arxiv.org/abs/2309.09855v1"},"cats":{"new-dataset":0.0018106978,"dev-research":0.4427477615,"data-quality":0.1046742203}}
{"text":"Existing deep learning-based self-calibration methods focus on small realignments and still rely on initial estimates, limiting their practicality.","meta":{"url":"http://arxiv.org/abs/2309.09855v1"},"cats":{"new-dataset":0.0489085745,"dev-research":0.1529282488,"data-quality":0.2032176504}}
{"text":"In this paper, we present PseudoCal, a novel self-calibration method that overcomes these limitations by leveraging the pseudo-LiDAR concept and working directly in the 3D space instead of limiting itself to the camera field of view.","meta":{"url":"http://arxiv.org/abs/2309.09855v1"},"cats":{"new-dataset":0.0721507457,"dev-research":0.1533610909,"data-quality":0.1272176505}}
{"text":"In typical autonomous vehicle and robotics contexts and conventions, PseudoCal is able to perform one-shot calibration quasi-independently of initial parameter estimates, addressing extreme cases that remain unsolved by existing approaches.","meta":{"url":"http://arxiv.org/abs/2309.09855v1"},"cats":{"new-dataset":0.06700369,"dev-research":0.1678598221,"data-quality":0.1200285556}}
{"text":"Corner case scenarios are an essential tool for testing and validating the safety of autonomous vehicles (AVs).","meta":{"url":"http://arxiv.org/abs/2309.09844v1"},"cats":{"new-dataset":0.0561278302,"dev-research":0.3214270274,"data-quality":0.0921164374}}
{"text":"As these scenarios are often insufficiently present in naturalistic driving datasets, augmenting the data with synthetic corner cases greatly enhances the safe operation of AVs in unique situations.","meta":{"url":"http://arxiv.org/abs/2309.09844v1"},"cats":{"new-dataset":0.1631470123,"dev-research":0.2275000521,"data-quality":0.1520481247}}
{"text":"However, the generation of synthetic, yet realistic, corner cases poses a significant challenge.","meta":{"url":"http://arxiv.org/abs/2309.09844v1"},"cats":{"new-dataset":0.0748055164,"dev-research":0.2411907049,"data-quality":0.0821290534}}
{"text":"In this work, we introduce a novel approach based on Heterogeneous Graph Neural Networks (HGNNs) to transform regular driving scenarios into corner cases.","meta":{"url":"http://arxiv.org/abs/2309.09844v1"},"cats":{"new-dataset":0.1447063171,"dev-research":0.2018989831,"data-quality":0.0706052557}}
{"text":"To achieve this, we first generate concise representations of regular driving scenes as scene graphs, minimally manipulating their structure and properties.","meta":{"url":"http://arxiv.org/abs/2309.09844v1"},"cats":{"new-dataset":0.2528532736,"dev-research":0.2023143646,"data-quality":0.1272960312}}
{"text":"Our model then learns to perturb those graphs to generate corner cases using attention and triple embeddings.","meta":{"url":"http://arxiv.org/abs/2309.09844v1"},"cats":{"new-dataset":0.2008165376,"dev-research":0.1736041468,"data-quality":0.1677489676}}
{"text":"The input and perturbed graphs are then imported back into the simulation to generate corner case scenarios.","meta":{"url":"http://arxiv.org/abs/2309.09844v1"},"cats":{"new-dataset":0.1127250267,"dev-research":0.2036709104,"data-quality":0.1191903689}}
{"text":"Our model successfully learned to produce corner cases from input scene graphs, achieving 89.9% prediction accuracy on our testing dataset.","meta":{"url":"http://arxiv.org/abs/2309.09844v1"},"cats":{"new-dataset":0.5898509352,"dev-research":0.2316691914,"data-quality":0.2719926674}}
{"text":"We further validate the generated scenarios on baseline autonomous driving methods, demonstrating our model's ability to effectively create critical situations for the baselines.","meta":{"url":"http://arxiv.org/abs/2309.09844v1"},"cats":{"new-dataset":0.1256606699,"dev-research":0.3510004213,"data-quality":0.1333524389}}
{"text":"Conventional end-to-end Automatic Speech Recognition (ASR) models primarily focus on exact transcription tasks, lacking flexibility for nuanced user interactions.","meta":{"url":"http://arxiv.org/abs/2309.09843v1"},"cats":{"new-dataset":0.0341285006,"dev-research":0.1613877006,"data-quality":0.1819158758}}
{"text":"With the advent of Large Language Models (LLMs) in speech processing, more organic, text-prompt-based interactions have become possible.","meta":{"url":"http://arxiv.org/abs/2309.09843v1"},"cats":{"new-dataset":0.0722465238,"dev-research":0.1541499859,"data-quality":0.1234944957}}
{"text":"However, the mechanisms behind these models' speech understanding and \"reasoning\" capabilities remain underexplored.","meta":{"url":"http://arxiv.org/abs/2309.09843v1"},"cats":{"new-dataset":0.0241301553,"dev-research":0.2169705278,"data-quality":0.1433934823}}
{"text":"To study this question from the data perspective, we introduce instruction-following speech recognition, training a Listen-Attend-Spell model to understand and execute a diverse set of free-form text instructions.","meta":{"url":"http://arxiv.org/abs/2309.09843v1"},"cats":{"new-dataset":0.2533560536,"dev-research":0.1512076051,"data-quality":0.1466760207}}
{"text":"This enables a multitude of speech recognition tasks -- ranging from transcript manipulation to summarization -- without relying on predefined command sets.","meta":{"url":"http://arxiv.org/abs/2309.09843v1"},"cats":{"new-dataset":0.1740096075,"dev-research":0.2155736267,"data-quality":0.142109056}}
{"text":"Remarkably, our model, trained from scratch on Librispeech, interprets and executes simple instructions without requiring LLMs or pre-trained speech modules.","meta":{"url":"http://arxiv.org/abs/2309.09843v1"},"cats":{"new-dataset":0.1824813751,"dev-research":0.1583415703,"data-quality":0.1677784648}}
{"text":"It also offers selective transcription options based on instructions like \"transcribe first half and then turn off listening,\" providing an additional layer of privacy and safety compared to existing LLMs.","meta":{"url":"http://arxiv.org/abs/2309.09843v1"},"cats":{"new-dataset":0.0151508226,"dev-research":0.1115675349,"data-quality":0.1145920262}}
{"text":"Our findings highlight the significant potential of instruction-following training to advance speech foundation models.","meta":{"url":"http://arxiv.org/abs/2309.09843v1"},"cats":{"new-dataset":0.0555465801,"dev-research":0.1578797599,"data-quality":0.1331095691}}
{"text":"In 5G cellular networks, frequency range 2 (FR2) introduces higher frequencies that cause rapid signal degradation and challenge user mobility.","meta":{"url":"http://arxiv.org/abs/2309.09840v1"},"cats":{"new-dataset":0.0344662632,"dev-research":0.1911629391,"data-quality":0.1085690378}}
{"text":"In recent studies, a conditional handover procedure has been adopted as an enhancement to baseline handover to enhance user mobility robustness.","meta":{"url":"http://arxiv.org/abs/2309.09840v1"},"cats":{"new-dataset":0.0136135669,"dev-research":0.2182042735,"data-quality":0.0499450765}}
{"text":"In this article, the mobility performance of conditional handover is analyzed for a 5G mm-wave network in FR2 that employs beamforming.","meta":{"url":"http://arxiv.org/abs/2309.09840v1"},"cats":{"new-dataset":0.0168711001,"dev-research":0.149032762,"data-quality":0.0533876343}}
{"text":"In addition, a resource-efficient random access procedure is proposed that increases the probability of contention-free random access during a handover.","meta":{"url":"http://arxiv.org/abs/2309.09840v1"},"cats":{"new-dataset":0.0403737993,"dev-research":0.203876986,"data-quality":0.0588355036}}
{"text":"Moreover, a simple yet effective decision tree-based supervised learning method is proposed to minimize the handover failures that are caused by the beam preparation phase of the random access procedure.","meta":{"url":"http://arxiv.org/abs/2309.09840v1"},"cats":{"new-dataset":0.0141667364,"dev-research":0.2118089608,"data-quality":0.2602449603}}
{"text":"Results have shown that a tradeoff exists between contention-free random access and handover failures.","meta":{"url":"http://arxiv.org/abs/2309.09840v1"},"cats":{"new-dataset":0.0231872195,"dev-research":0.156223962,"data-quality":0.1163138409}}
{"text":"It is also seen that the optimum operation point of random access is achievable with the proposed learning algorithm for conditional handover.","meta":{"url":"http://arxiv.org/abs/2309.09840v1"},"cats":{"new-dataset":0.0145083669,"dev-research":0.1287251726,"data-quality":0.0772948109}}
{"text":"Moreover, a mobility performance comparison of conditional handover with baseline handover is also carried out.","meta":{"url":"http://arxiv.org/abs/2309.09840v1"},"cats":{"new-dataset":0.0151695587,"dev-research":0.1542700877,"data-quality":0.0406420083}}
{"text":"Results have shown that while baseline handover causes fewer handover failures than conditional handover, the total number of mobility failures in the latter is less due to the decoupling of the handover preparation and execution phases.","meta":{"url":"http://arxiv.org/abs/2309.09840v1"},"cats":{"new-dataset":0.0146642496,"dev-research":0.2152537812,"data-quality":0.1111567817}}
{"text":"Voice spoofing attacks pose a significant threat to automated speaker verification systems.","meta":{"url":"http://arxiv.org/abs/2309.09837v1"},"cats":{"new-dataset":0.0546885166,"dev-research":0.2224657652,"data-quality":0.3025994652}}
{"text":"Existing anti-spoofing methods often simulate specific attack types, such as synthetic or replay attacks.","meta":{"url":"http://arxiv.org/abs/2309.09837v1"},"cats":{"new-dataset":0.0325097672,"dev-research":0.2454460406,"data-quality":0.124279579}}
{"text":"However, in real-world scenarios, the countermeasures are unaware of the generation schema of the attack, necessitating a unified solution.","meta":{"url":"http://arxiv.org/abs/2309.09837v1"},"cats":{"new-dataset":0.0130283607,"dev-research":0.2855166128,"data-quality":0.1440349718}}
{"text":"Current unified solutions struggle to detect spoofing artifacts, especially with recent spoofing mechanisms.","meta":{"url":"http://arxiv.org/abs/2309.09837v1"},"cats":{"new-dataset":0.1085077493,"dev-research":0.2550978445,"data-quality":0.376473018}}
{"text":"For instance, the spoofing algorithms inject spectral or temporal anomalies, which are challenging to identify.","meta":{"url":"http://arxiv.org/abs/2309.09837v1"},"cats":{"new-dataset":0.0249203684,"dev-research":0.2075955086,"data-quality":0.3432851021}}
{"text":"To this end, we present a spectra-temporal fusion leveraging frame-level and utterance-level coefficients.","meta":{"url":"http://arxiv.org/abs/2309.09837v1"},"cats":{"new-dataset":0.2201566258,"dev-research":0.1426706592,"data-quality":0.1582956095}}
{"text":"We introduce a novel local spectral deviation coefficient (SDC) for frame-level inconsistencies and employ a bi-LSTM-based network for sequential temporal coefficients (STC), which capture utterance-level artifacts.","meta":{"url":"http://arxiv.org/abs/2309.09837v1"},"cats":{"new-dataset":0.2123020568,"dev-research":0.2210034939,"data-quality":0.3902222356}}
{"text":"Our spectra-temporal fusion strategy combines these coefficients, and an auto-encoder generates spectra-temporal deviated coefficients (STDC) to enhance robustness.","meta":{"url":"http://arxiv.org/abs/2309.09837v1"},"cats":{"new-dataset":0.0441801462,"dev-research":0.1766375334,"data-quality":0.1736295394}}
{"text":"Our proposed approach addresses multiple spoofing categories, including synthetic, replay, and partial deepfake attacks.","meta":{"url":"http://arxiv.org/abs/2309.09837v1"},"cats":{"new-dataset":0.1352220885,"dev-research":0.225528161,"data-quality":0.236736637}}
{"text":"Extensive evaluation on diverse datasets (ASVspoof2019, ASVspoof2021, VSDC, partial spoofs, and in-the-wild deepfakes) demonstrated its robustness for a wide range of voice applications.","meta":{"url":"http://arxiv.org/abs/2309.09837v1"},"cats":{"new-dataset":0.4721714314,"dev-research":0.1687974885,"data-quality":0.3366219627}}
{"text":"Societal biases that are contained in retrieved documents have received increased interest.","meta":{"url":"http://arxiv.org/abs/2309.09833v1"},"cats":{"new-dataset":0.0235678843,"dev-research":0.1893992682,"data-quality":0.1659974706}}
{"text":"Such biases, which are often prevalent in the training data and learned by the model, can cause societal harms, by misrepresenting certain groups, and by enforcing stereotypes.","meta":{"url":"http://arxiv.org/abs/2309.09833v1"},"cats":{"new-dataset":0.0116048348,"dev-research":0.2786952733,"data-quality":0.3846292252}}
{"text":"Mitigating such biases demands algorithms that balance the trade-off between maximized utility for the user with fairness objectives, which incentivize unbiased rankings.","meta":{"url":"http://arxiv.org/abs/2309.09833v1"},"cats":{"new-dataset":0.0031272118,"dev-research":0.1474855324,"data-quality":0.1322080242}}
{"text":"Prior work on bias mitigation often assumes that ranking scores, which correspond to the utility that a document holds for a user, can be accurately determined.","meta":{"url":"http://arxiv.org/abs/2309.09833v1"},"cats":{"new-dataset":0.0032891705,"dev-research":0.2180066095,"data-quality":0.2551029792}}
{"text":"In reality, there is always a degree of uncertainty in the estimate of expected document utility.","meta":{"url":"http://arxiv.org/abs/2309.09833v1"},"cats":{"new-dataset":0.0048355412,"dev-research":0.1800471153,"data-quality":0.169460424}}
{"text":"This uncertainty can be approximated by viewing ranking models through a Bayesian perspective, where the standard deterministic score becomes a distribution.   ","meta":{"url":"http://arxiv.org/abs/2309.09833v1"},"cats":{"new-dataset":0.0260350842,"dev-research":0.1547962653,"data-quality":0.1899098138}}
{"text":"In this work, we investigate whether uncertainty estimates can be used to decrease the amount of bias in the ranked results, while minimizing loss in measured utility.","meta":{"url":"http://arxiv.org/abs/2309.09833v1"},"cats":{"new-dataset":0.0113103911,"dev-research":0.1924777237,"data-quality":0.2573799449}}
{"text":"We introduce a simple method that uses the uncertainty of the ranking scores for an uncertainty-aware, post hoc approach to bias mitigation.","meta":{"url":"http://arxiv.org/abs/2309.09833v1"},"cats":{"new-dataset":0.0172462333,"dev-research":0.2186879986,"data-quality":0.3126245277}}
{"text":"We compare our proposed method with existing baselines for bias mitigation with respect to the utility-fairness trade-off, the controllability of methods, and computational costs.","meta":{"url":"http://arxiv.org/abs/2309.09833v1"},"cats":{"new-dataset":0.0076637046,"dev-research":0.1830850503,"data-quality":0.1926115218}}
{"text":"We show that an uncertainty-based approach can provide an intuitive and flexible trade-off that outperforms all baselines without additional training requirements, allowing for the post hoc use of this approach on top of arbitrary retrieval models.","meta":{"url":"http://arxiv.org/abs/2309.09833v1"},"cats":{"new-dataset":0.0227883051,"dev-research":0.1665525499,"data-quality":0.2399809686}}
{"text":"Multi-task learning (MTL) aims to improve the performance of a primary task by jointly learning with related auxiliary tasks.","meta":{"url":"http://arxiv.org/abs/2309.09832v1"},"cats":{"new-dataset":0.0421072996,"dev-research":0.1727093634,"data-quality":0.0965278056}}
{"text":"Traditional MTL methods select tasks randomly during training.","meta":{"url":"http://arxiv.org/abs/2309.09832v1"},"cats":{"new-dataset":0.0123014738,"dev-research":0.1469208689,"data-quality":0.0784173358}}
{"text":"However, both previous studies and our results suggest that such the random selection of tasks may not be helpful, and can even be harmful to performance.","meta":{"url":"http://arxiv.org/abs/2309.09832v1"},"cats":{"new-dataset":0.0014773694,"dev-research":0.2478950076,"data-quality":0.098896687}}
{"text":"Therefore, new strategies for task selection and assignment in MTL need to be explored.","meta":{"url":"http://arxiv.org/abs/2309.09832v1"},"cats":{"new-dataset":0.014748389,"dev-research":0.2553768152,"data-quality":0.0395156313}}
{"text":"This paper studies the multi-modal, multi-task dialogue act classification task, and proposes a method for selecting and assigning tasks based on non-stationary multi-armed bandits (MAB) with discounted Thompson Sampling (TS) using Gaussian priors.","meta":{"url":"http://arxiv.org/abs/2309.09832v1"},"cats":{"new-dataset":0.0655873613,"dev-research":0.1096875696,"data-quality":0.0842069728}}
{"text":"Our experimental results show that in different training stages, different tasks have different utility.","meta":{"url":"http://arxiv.org/abs/2309.09832v1"},"cats":{"new-dataset":0.0032869612,"dev-research":0.1568749703,"data-quality":0.0950869348}}
{"text":"Our proposed method can effectively identify the task utility, actively avoid useless or harmful tasks, and realise the task assignment during training.","meta":{"url":"http://arxiv.org/abs/2309.09832v1"},"cats":{"new-dataset":0.0160154102,"dev-research":0.2822707744,"data-quality":0.1657071505}}
{"text":"Our proposed method is significantly superior in terms of UAR and F1 to the single-task and multi-task baselines with p-values < 0.05.","meta":{"url":"http://arxiv.org/abs/2309.09832v1"},"cats":{"new-dataset":0.0315182024,"dev-research":0.1903571886,"data-quality":0.097593847}}
{"text":"Further analysis of experiments indicates that for the dataset with the data imbalance problem, our proposed method has significantly higher stability and can obtain consistent and decent performance for minority classes.","meta":{"url":"http://arxiv.org/abs/2309.09832v1"},"cats":{"new-dataset":0.0655015956,"dev-research":0.159386214,"data-quality":0.3455511118}}
{"text":"Our proposed method is superior to the current state-of-the-art model.","meta":{"url":"http://arxiv.org/abs/2309.09832v1"},"cats":{"new-dataset":0.0086069379,"dev-research":0.1201186445,"data-quality":0.1103723321}}
{"text":"Clustering of urban traffic patterns is an essential task in many different areas of traffic management and planning.","meta":{"url":"http://arxiv.org/abs/2309.09830v1"},"cats":{"new-dataset":0.0424423285,"dev-research":0.2328320921,"data-quality":0.0660424278}}
{"text":"In this paper, two significant applications in the clustering of urban traffic patterns are described.","meta":{"url":"http://arxiv.org/abs/2309.09830v1"},"cats":{"new-dataset":0.0533846925,"dev-research":0.1900251593,"data-quality":0.092537511}}
{"text":"The first application estimates the missing speed values using the speed of road segments with similar traffic patterns to colorify map tiles.","meta":{"url":"http://arxiv.org/abs/2309.09830v1"},"cats":{"new-dataset":0.116761317,"dev-research":0.2237285747,"data-quality":0.111240198}}
{"text":"The second one is the estimation of essential road segments for generating addresses for a local point on the map, using the similarity patterns of different road segments.","meta":{"url":"http://arxiv.org/abs/2309.09830v1"},"cats":{"new-dataset":0.1855819063,"dev-research":0.2148723226,"data-quality":0.0952732371}}
{"text":"The speed time series extracts the traffic pattern in different road segments.","meta":{"url":"http://arxiv.org/abs/2309.09830v1"},"cats":{"new-dataset":0.0727949685,"dev-research":0.1561432584,"data-quality":0.0556592833}}
{"text":"In this paper, we proposed the time series clustering algorithm based on K-Means and Dynamic Time Warping.","meta":{"url":"http://arxiv.org/abs/2309.09830v1"},"cats":{"new-dataset":0.0445438128,"dev-research":0.186843869,"data-quality":0.0919438367}}
{"text":"The case study of our proposed algorithm is based on the Snapp application's driver speed time series data.","meta":{"url":"http://arxiv.org/abs/2309.09830v1"},"cats":{"new-dataset":0.0737101476,"dev-research":0.1742940218,"data-quality":0.0536830514}}
{"text":"The results of the two applications illustrate that the proposed method can extract similar urban traffic patterns.","meta":{"url":"http://arxiv.org/abs/2309.09830v1"},"cats":{"new-dataset":0.0226705085,"dev-research":0.1593605722,"data-quality":0.0885101667}}
{"text":"Trust is widely regarded as a critical component to build artificial intelligence (AI) systems that people will use and safely rely upon.","meta":{"url":"http://arxiv.org/abs/2309.09828v1"},"cats":{"new-dataset":0.0223074452,"dev-research":0.3324946934,"data-quality":0.1231283507}}
{"text":"As research in this area continues to evolve, it becomes imperative that the HCI research community synchronize their empirical efforts and align on the path toward effective knowledge creation.","meta":{"url":"http://arxiv.org/abs/2309.09828v1"},"cats":{"new-dataset":0.1814565829,"dev-research":0.4151839134,"data-quality":0.0928901537}}
{"text":"To lay the groundwork toward achieving this objective, we performed a comprehensive bibliometric analysis of two decades of empirical research measuring trust in AI, comprising 538 core articles and 15'548 cited articles across multiple disciplines.","meta":{"url":"http://arxiv.org/abs/2309.09828v1"},"cats":{"new-dataset":0.0536204022,"dev-research":0.2509633704,"data-quality":0.1589104102}}
{"text":"A key insight arising from our analysis is the persistence of an exploratory approach across the research landscape.","meta":{"url":"http://arxiv.org/abs/2309.09828v1"},"cats":{"new-dataset":0.039011579,"dev-research":0.4149617757,"data-quality":0.1047975844}}
{"text":"To foster a deeper understanding of trust in AI, we advocate for a contextualized strategy.","meta":{"url":"http://arxiv.org/abs/2309.09828v1"},"cats":{"new-dataset":0.0196333728,"dev-research":0.2752794855,"data-quality":0.1389774946}}
{"text":"To pave the way, we outline a research agenda, highlighting questions that require further investigation.","meta":{"url":"http://arxiv.org/abs/2309.09828v1"},"cats":{"new-dataset":0.0554070629,"dev-research":0.2810035276,"data-quality":0.0854656894}}
{"text":"Auto-completing code enables developers to speed up coding significantly.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.0191253292,"dev-research":0.6315941417,"data-quality":0.1403453787}}
{"text":"Recent advances in transformer-based large language model (LLM) technologies have been applied to code synthesis.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.0749859068,"dev-research":0.2762322923,"data-quality":0.1229485014}}
{"text":"However, studies show that many of such synthesized codes contain vulnerabilities.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.0873677216,"dev-research":0.3969068685,"data-quality":0.1831742508}}
{"text":"We propose a novel vulnerability-constrained decoding approach to reduce the amount of vulnerable code generated by such models.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.0762516074,"dev-research":0.2658855784,"data-quality":0.2153318972}}
{"text":"Using a small dataset of labeled vulnerable lines of code, we fine-tune an LLM to include vulnerability labels when generating code, acting as an embedded classifier.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.2933200769,"dev-research":0.3639801478,"data-quality":0.5194041936}}
{"text":"Then, during decoding, we deny the model to generate these labels to avoid generating vulnerable code.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.0391027869,"dev-research":0.2150888994,"data-quality":0.5572639942}}
{"text":"To evaluate the method, we chose to automatically complete Ethereum Blockchain smart contracts (SCs) as the case study due to the strict requirements of SC security.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.0216850148,"dev-research":0.2449126966,"data-quality":0.1201084508}}
{"text":"We first fine-tuned the 6-billion-parameter GPT-J model using 186,397 Ethereum SCs after removing the duplication from 2,217,692 SCs.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.3243547212,"dev-research":0.104494205,"data-quality":0.0623124635}}
{"text":"The fine-tuning took more than one week using ten GPUs.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.0302313892,"dev-research":0.1758056345,"data-quality":0.1116905241}}
{"text":"The results showed that our fine-tuned model could synthesize SCs with an average BLEU (BiLingual Evaluation Understudy) score of 0.557.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.0593143437,"dev-research":0.1461256491,"data-quality":0.1524050743}}
{"text":"However, many codes in the auto-completed SCs were vulnerable.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.0474804462,"dev-research":0.2812213807,"data-quality":0.2296655802}}
{"text":"Using the code before the vulnerable line of 176 SCs containing different types of vulnerabilities to auto-complete the code, we found that more than 70% of the auto-completed codes were insecure.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.1501360871,"dev-research":0.3570502779,"data-quality":0.260137263}}
{"text":"Thus, we further fine-tuned the model on other 941 vulnerable SCs containing the same types of vulnerabilities and applied vulnerability-constrained decoding.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.068746118,"dev-research":0.2196011987,"data-quality":0.1577158672}}
{"text":"The fine-tuning took only one hour with four GPUs.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.02545778,"dev-research":0.1468618869,"data-quality":0.1169670575}}
{"text":"We then auto-completed the 176 SCs again and found that our approach could identify 62% of the code to be generated as vulnerable and avoid generating 67% of them, indicating the approach could efficiently and effectively avoid vulnerabilities in the auto-completed code.","meta":{"url":"http://arxiv.org/abs/2309.09826v1"},"cats":{"new-dataset":0.1674701932,"dev-research":0.3611131604,"data-quality":0.2404700006}}
{"text":"Large language models (LLMs) have the potential to transform our lives and work through the content they generate, known as AI-Generated Content (AIGC).","meta":{"url":"http://arxiv.org/abs/2309.09825v1"},"cats":{"new-dataset":0.228322416,"dev-research":0.1555424568,"data-quality":0.1413940748}}
{"text":"To harness this transformation, we need to understand the limitations of LLMs.","meta":{"url":"http://arxiv.org/abs/2309.09825v1"},"cats":{"new-dataset":0.0063042625,"dev-research":0.0983611787,"data-quality":0.060515095}}
{"text":"Here, we investigate the bias of AIGC produced by seven representative LLMs, including ChatGPT and LLaMA.","meta":{"url":"http://arxiv.org/abs/2309.09825v1"},"cats":{"new-dataset":0.1598285433,"dev-research":0.0982791914,"data-quality":0.1151667278}}
{"text":"We collect news articles from The New York Times and Reuters, both known for delivering relatively unbiased news.","meta":{"url":"http://arxiv.org/abs/2309.09825v1"},"cats":{"new-dataset":0.1029141001,"dev-research":0.1384891636,"data-quality":0.1844776687}}
{"text":"We then apply each examined LLM to generate news content with headlines of these news articles as prompts, and evaluate the gender and racial biases of the AIGC produced by the LLM by comparing the AIGC and the original news articles.","meta":{"url":"http://arxiv.org/abs/2309.09825v1"},"cats":{"new-dataset":0.0607721917,"dev-research":0.1597281642,"data-quality":0.1850242156}}
{"text":"We further analyze the gender bias of each LLM under biased prompts by adding gender-biased messages to prompts constructed from these news headlines.","meta":{"url":"http://arxiv.org/abs/2309.09825v1"},"cats":{"new-dataset":0.0360016836,"dev-research":0.1608126816,"data-quality":0.2392756364}}
{"text":"Our study reveals that the AIGC produced by each examined LLM demonstrates substantial gender and racial biases.","meta":{"url":"http://arxiv.org/abs/2309.09825v1"},"cats":{"new-dataset":0.0411500547,"dev-research":0.1745810572,"data-quality":0.1337636519}}
{"text":"Moreover, the AIGC generated by each LLM exhibits notable discrimination against females and individuals of the Black race.","meta":{"url":"http://arxiv.org/abs/2309.09825v1"},"cats":{"new-dataset":0.0338706422,"dev-research":0.1269014687,"data-quality":0.1174418996}}
{"text":"Among the LLMs, the AIGC generated by ChatGPT demonstrates the lowest level of bias, and ChatGPT is the sole model capable of declining content generation when provided with biased prompts.","meta":{"url":"http://arxiv.org/abs/2309.09825v1"},"cats":{"new-dataset":0.0331751259,"dev-research":0.1668220678,"data-quality":0.1855498389}}
{"text":"The computing continuum, a novel paradigm that extends beyond the current silos of cloud and edge computing, can enable the seamless and dynamic deployment of applications across diverse infrastructures.","meta":{"url":"http://arxiv.org/abs/2309.09822v1"},"cats":{"new-dataset":0.0423019476,"dev-research":0.2192981757,"data-quality":0.066600917}}
{"text":"By utilizing the cloud-native features and scalability of Kubernetes, this concept promotes deployment transparency, communication transparency, and resource availability transparency.","meta":{"url":"http://arxiv.org/abs/2309.09822v1"},"cats":{"new-dataset":0.0208900388,"dev-research":0.220621397,"data-quality":0.1220848507}}
{"text":"Key features of this paradigm include intent-driven policies, a decentralized architecture, multi-ownership, and a fluid topology.","meta":{"url":"http://arxiv.org/abs/2309.09822v1"},"cats":{"new-dataset":0.022485314,"dev-research":0.2075872349,"data-quality":0.0331307778}}
{"text":"Integral to the computing continuum are the building blocks of dynamic discovery and peering, hierarchical resource continuum, resource and service reflection, network continuum, and storage and data continuum.","meta":{"url":"http://arxiv.org/abs/2309.09822v1"},"cats":{"new-dataset":0.1065759121,"dev-research":0.1710395908,"data-quality":0.062796658}}
{"text":"The implementation of these principles allows organizations to foster an efficient, dynamic, and seamless computing environment, thereby facilitating the deployment of complex distributed applications across varying infrastructures.","meta":{"url":"http://arxiv.org/abs/2309.09822v1"},"cats":{"new-dataset":0.0191703558,"dev-research":0.3133216031,"data-quality":0.0438099212}}
{"text":"Foundation models such as ChatGPT have made significant strides in robotic tasks due to their universal representation of real-world domains.","meta":{"url":"http://arxiv.org/abs/2309.09818v1"},"cats":{"new-dataset":0.0819765714,"dev-research":0.1968483918,"data-quality":0.0412503581}}
{"text":"In this paper, we leverage foundation models to tackle grasp detection, a persistent challenge in robotics with broad industrial applications.","meta":{"url":"http://arxiv.org/abs/2309.09818v1"},"cats":{"new-dataset":0.1388410113,"dev-research":0.1499817774,"data-quality":0.0944024691}}
{"text":"Despite numerous grasp datasets, their object diversity remains limited compared to real-world figures.","meta":{"url":"http://arxiv.org/abs/2309.09818v1"},"cats":{"new-dataset":0.362399417,"dev-research":0.119136019,"data-quality":0.0892504218}}
{"text":"Fortunately, foundation models possess an extensive repository of real-world knowledge, including objects we encounter in our daily lives.","meta":{"url":"http://arxiv.org/abs/2309.09818v1"},"cats":{"new-dataset":0.4896485621,"dev-research":0.1950569318,"data-quality":0.0820404925}}
{"text":"As a consequence, a promising solution to the limited representation in previous grasp datasets is to harness the universal knowledge embedded in these foundation models.","meta":{"url":"http://arxiv.org/abs/2309.09818v1"},"cats":{"new-dataset":0.4377234892,"dev-research":0.1463516708,"data-quality":0.110243671}}
{"text":"We present Grasp-Anything, a new large-scale grasp dataset synthesized from foundation models to implement this solution.","meta":{"url":"http://arxiv.org/abs/2309.09818v1"},"cats":{"new-dataset":0.752242787,"dev-research":0.1387910787,"data-quality":0.0501384545}}
{"text":"Grasp-Anything excels in diversity and magnitude, boasting 1M samples with text descriptions and more than 3M objects, surpassing prior datasets.","meta":{"url":"http://arxiv.org/abs/2309.09818v1"},"cats":{"new-dataset":0.3479736121,"dev-research":0.1006992344,"data-quality":0.1214679451}}
{"text":"Empirically, we show that Grasp-Anything successfully facilitates zero-shot grasp detection on vision-based tasks and real-world robotic experiments.","meta":{"url":"http://arxiv.org/abs/2309.09818v1"},"cats":{"new-dataset":0.0682019404,"dev-research":0.1191220252,"data-quality":0.1155511963}}
{"text":"Our dataset and code are available at https://grasp-anything-2023.github.io.","meta":{"url":"http://arxiv.org/abs/2309.09818v1"},"cats":{"new-dataset":0.9408736114,"dev-research":0.1507559405,"data-quality":0.0872657273}}
{"text":"Large Language Models (LLMs) have consistently showcased remarkable generalization capabilities when applied to various language tasks.","meta":{"url":"http://arxiv.org/abs/2309.09812v1"},"cats":{"new-dataset":0.0282538425,"dev-research":0.1238302626,"data-quality":0.1530761998}}
{"text":"Nonetheless, harnessing the full potential of LLMs for Radiology Report Generation (R2Gen) still presents a challenge, stemming from the inherent disparity in modality between LLMs and the R2Gen task.","meta":{"url":"http://arxiv.org/abs/2309.09812v1"},"cats":{"new-dataset":0.0680571799,"dev-research":0.1786771347,"data-quality":0.1659578166}}
{"text":"To bridge this gap effectively, we propose R2GenGPT, which is a novel solution that aligns visual features with the word embedding space of LLMs using an efficient visual alignment module.","meta":{"url":"http://arxiv.org/abs/2309.09812v1"},"cats":{"new-dataset":0.2943877845,"dev-research":0.2093502325,"data-quality":0.2588287092}}
{"text":"This innovative approach empowers the previously static LLM to seamlessly integrate and process image information, marking a step forward in optimizing R2Gen performance.","meta":{"url":"http://arxiv.org/abs/2309.09812v1"},"cats":{"new-dataset":0.0370531311,"dev-research":0.1769687895,"data-quality":0.1035172433}}
{"text":"R2GenGPT offers the following benefits.","meta":{"url":"http://arxiv.org/abs/2309.09812v1"},"cats":{"new-dataset":0.0211406491,"dev-research":0.1909065609,"data-quality":0.0713904332}}
{"text":"First, it attains state-of-the-art (SOTA) performance by training only the lightweight visual alignment module while freezing all the parameters of LLM.","meta":{"url":"http://arxiv.org/abs/2309.09812v1"},"cats":{"new-dataset":0.0849060632,"dev-research":0.1409656959,"data-quality":0.1126392327}}
{"text":"Second, it exhibits high training efficiency, as it requires the training of an exceptionally minimal number of parameters while achieving rapid convergence.","meta":{"url":"http://arxiv.org/abs/2309.09812v1"},"cats":{"new-dataset":0.0024618527,"dev-research":0.1191617434,"data-quality":0.0640754411}}
{"text":"By employing delta tuning, our model only trains 5M parameters (which constitute just 0.07\\% of the total parameter count) to achieve performance close to the SOTA levels.","meta":{"url":"http://arxiv.org/abs/2309.09812v1"},"cats":{"new-dataset":0.033998095,"dev-research":0.0940548843,"data-quality":0.102327332}}
{"text":"Our code is available at https://github.com/wang-zhanyu/R2GenGPT.","meta":{"url":"http://arxiv.org/abs/2309.09812v1"},"cats":{"new-dataset":0.4512208073,"dev-research":0.1352912447,"data-quality":0.1412413164}}
{"text":"Understanding the dynamics of unknown object is crucial for collaborative robots including humanoids to more safely and accurately interact with humans.","meta":{"url":"http://arxiv.org/abs/2309.09810v1"},"cats":{"new-dataset":0.0382935264,"dev-research":0.2322148621,"data-quality":0.0891379039}}
{"text":"Most relevant literature leverage a force/torque sensor, prior knowledge of object, vision system, and a long-horizon trajectory which are often impractical.","meta":{"url":"http://arxiv.org/abs/2309.09810v1"},"cats":{"new-dataset":0.0355128726,"dev-research":0.168659079,"data-quality":0.0576617478}}
{"text":"Moreover, these methods often entail solving non-linear optimization problem, sometimes yielding physically inconsistent results.","meta":{"url":"http://arxiv.org/abs/2309.09810v1"},"cats":{"new-dataset":0.0020315157,"dev-research":0.2266675175,"data-quality":0.2137748818}}
{"text":"In this work, we propose a fast learningbased inertial parameter estimation as more practical manner.","meta":{"url":"http://arxiv.org/abs/2309.09810v1"},"cats":{"new-dataset":0.2259435055,"dev-research":0.1574689963,"data-quality":0.0949504934}}
{"text":"We acquire a reliable dataset in a high-fidelity simulation and train a time-series data-driven regression model (e.g., LSTM) to estimate the inertial parameter of unknown objects.","meta":{"url":"http://arxiv.org/abs/2309.09810v1"},"cats":{"new-dataset":0.4118443326,"dev-research":0.1667850889,"data-quality":0.1198549116}}
{"text":"We also introduce a novel sim-to-real adaptation method combining Robot System Identification and Gaussian Processes to directly transfer the trained model to real-world application.","meta":{"url":"http://arxiv.org/abs/2309.09810v1"},"cats":{"new-dataset":0.0249093777,"dev-research":0.1345841892,"data-quality":0.1344174501}}
{"text":"We demonstrate our method with a 4-DOF single manipulator of physical wheeled humanoid robot, SATYRR.","meta":{"url":"http://arxiv.org/abs/2309.09810v1"},"cats":{"new-dataset":0.0763941699,"dev-research":0.1525397226,"data-quality":0.046396532}}
{"text":"Results show that our method can identify the inertial parameters of various unknown objects faster and more accurately than conventional methods.","meta":{"url":"http://arxiv.org/abs/2309.09810v1"},"cats":{"new-dataset":0.0381803941,"dev-research":0.1818761297,"data-quality":0.1300624301}}
{"text":"As an interpretable and universal neuro-symbolic paradigm based on Large Language Models, visual programming (VisualProg) can execute compositional visual tasks without training, but its performance is markedly inferior compared to task-specific supervised learning models.","meta":{"url":"http://arxiv.org/abs/2309.09809v1"},"cats":{"new-dataset":0.030795431,"dev-research":0.3407512584,"data-quality":0.1349855325}}
{"text":"To increase its practicality, the performance of VisualProg on specific tasks needs to be improved.","meta":{"url":"http://arxiv.org/abs/2309.09809v1"},"cats":{"new-dataset":0.0473016764,"dev-research":0.4556951926,"data-quality":0.0786659633}}
{"text":"However, the non-differentiability of VisualProg limits the possibility of employing the fine-tuning strategy on specific tasks to achieve further improvements.","meta":{"url":"http://arxiv.org/abs/2309.09809v1"},"cats":{"new-dataset":0.0183527365,"dev-research":0.3779416722,"data-quality":0.0790280306}}
{"text":"In our analysis, we discovered that significant performance issues in VisualProg's execution originated from errors made by the sub-modules at corresponding visual sub-task steps.","meta":{"url":"http://arxiv.org/abs/2309.09809v1"},"cats":{"new-dataset":0.0737355973,"dev-research":0.5709266887,"data-quality":0.2348878592}}
{"text":"To address this, we propose ``VisualProg Distiller\", a method of supplementing and distilling process knowledge to optimize the performance of each VisualProg sub-module on decoupled visual sub-tasks, thus enhancing the overall task performance.","meta":{"url":"http://arxiv.org/abs/2309.09809v1"},"cats":{"new-dataset":0.1225427276,"dev-research":0.4791664974,"data-quality":0.0791350261}}
{"text":"Specifically, we choose an end-to-end model that is well-performed on the given task as the teacher and further distill the knowledge of the teacher into the invoked visual sub-modules step-by-step based on the execution flow of the VisualProg-generated programs.","meta":{"url":"http://arxiv.org/abs/2309.09809v1"},"cats":{"new-dataset":0.1123692025,"dev-research":0.4000275777,"data-quality":0.0712423487}}
{"text":"In this way, our method is capable of facilitating the fine-tuning of the non-differentiable VisualProg frameworks effectively.","meta":{"url":"http://arxiv.org/abs/2309.09809v1"},"cats":{"new-dataset":0.1247736266,"dev-research":0.4079579749,"data-quality":0.1209391142}}
{"text":"Extensive and comprehensive experimental evaluations demonstrate that our method can achieve a substantial performance improvement of VisualProg, and outperforms all the compared state-of-the-art methods by large margins.","meta":{"url":"http://arxiv.org/abs/2309.09809v1"},"cats":{"new-dataset":0.1043856869,"dev-research":0.3928071947,"data-quality":0.1255041873}}
{"text":"Furthermore, to provide valuable process supervision for the GQA task, we construct a large-scale dataset by utilizing the distillation process of our method.","meta":{"url":"http://arxiv.org/abs/2309.09809v1"},"cats":{"new-dataset":0.377286046,"dev-research":0.2135281567,"data-quality":0.1444220174}}
{"text":"In this paper, we propose an efficient continuous-time LiDAR-Inertial-Camera Odometry, utilizing non-uniform B-splines to tightly couple measurements from the LiDAR, IMU, and camera.","meta":{"url":"http://arxiv.org/abs/2309.09808v1"},"cats":{"new-dataset":0.1378852688,"dev-research":0.1906857841,"data-quality":0.0775869076}}
{"text":"In contrast to uniform B-spline-based continuous-time methods, our non-uniform B-spline approach offers significant advantages in terms of achieving real-time efficiency and high accuracy.","meta":{"url":"http://arxiv.org/abs/2309.09808v1"},"cats":{"new-dataset":0.0239757258,"dev-research":0.1869256508,"data-quality":0.0598497264}}
{"text":"This is accomplished by dynamically and adaptively placing control points, taking into account the varying dynamics of the motion.","meta":{"url":"http://arxiv.org/abs/2309.09808v1"},"cats":{"new-dataset":0.0133266667,"dev-research":0.184023048,"data-quality":0.0537992532}}
{"text":"To enable efficient fusion of heterogeneous LiDAR-Inertial-Camera data within a short sliding-window optimization, we assign depth to visual pixels using corresponding map points from a global LiDAR map, and formulate frame-to-map reprojection factors for the associated pixels in the current image frame.","meta":{"url":"http://arxiv.org/abs/2309.09808v1"},"cats":{"new-dataset":0.1755557347,"dev-research":0.1829191818,"data-quality":0.069423729}}
{"text":"This way circumvents the necessity for depth optimization of visual pixels, which typically entails a lengthy sliding window with numerous control points for continuous-time trajectory estimation.","meta":{"url":"http://arxiv.org/abs/2309.09808v1"},"cats":{"new-dataset":0.0280309802,"dev-research":0.2029864853,"data-quality":0.0349849657}}
{"text":"We conduct dedicated experiments on real-world datasets to demonstrate the advantage and efficacy of adopting non-uniform continuous-time trajectory representation.","meta":{"url":"http://arxiv.org/abs/2309.09808v1"},"cats":{"new-dataset":0.2732825731,"dev-research":0.145834109,"data-quality":0.06875355}}
{"text":"Our LiDAR-Inertial-Camera odometry system is also extensively evaluated on both challenging scenarios with sensor degenerations and large-scale scenarios, and has shown comparable or higher accuracy than the state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2309.09808v1"},"cats":{"new-dataset":0.1356471695,"dev-research":0.2254050266,"data-quality":0.1268021186}}
{"text":"The codebase of this paper will also be open-sourced at https://github.com/APRIL-ZJU/Coco-LIC.","meta":{"url":"http://arxiv.org/abs/2309.09808v1"},"cats":{"new-dataset":0.2456083294,"dev-research":0.1859921618,"data-quality":0.1785995078}}
{"text":"The rapidly evolving nature of Android apps poses a significant challenge to static batch machine learning algorithms employed in malware detection systems, as they quickly become obsolete.","meta":{"url":"http://arxiv.org/abs/2309.09807v1"},"cats":{"new-dataset":0.0688861518,"dev-research":0.1574486476,"data-quality":0.2038852969}}
{"text":"Despite this challenge, the existing literature pays limited attention to addressing this issue, with many advanced Android malware detection approaches, such as Drebin, DroidDet and MaMaDroid, relying on static models.","meta":{"url":"http://arxiv.org/abs/2309.09807v1"},"cats":{"new-dataset":0.0670697005,"dev-research":0.1851003838,"data-quality":0.1506065668}}
{"text":"In this work, we show how retraining techniques are able to maintain detector capabilities over time.","meta":{"url":"http://arxiv.org/abs/2309.09807v1"},"cats":{"new-dataset":0.0532436301,"dev-research":0.2282159021,"data-quality":0.2052473556}}
{"text":"Particularly, we analyze the effect of two aspects in the efficiency and performance of the detectors: 1) the frequency with which the models are retrained, and 2) the data used for retraining.","meta":{"url":"http://arxiv.org/abs/2309.09807v1"},"cats":{"new-dataset":0.0540792245,"dev-research":0.1351293272,"data-quality":0.1938466103}}
{"text":"In the first experiment, we compare periodic retraining with a more advanced concept drift detection method that triggers retraining only when necessary.","meta":{"url":"http://arxiv.org/abs/2309.09807v1"},"cats":{"new-dataset":0.0198942826,"dev-research":0.2418632758,"data-quality":0.3293178286}}
{"text":"In the second experiment, we analyze sampling methods to reduce the amount of data used to retrain models.","meta":{"url":"http://arxiv.org/abs/2309.09807v1"},"cats":{"new-dataset":0.0371807963,"dev-research":0.1572993616,"data-quality":0.1631706489}}
{"text":"Specifically, we compare fixed sized windows of recent data and state-of-the-art active learning methods that select those apps that help keep the training dataset small but diverse.","meta":{"url":"http://arxiv.org/abs/2309.09807v1"},"cats":{"new-dataset":0.100164542,"dev-research":0.2290282607,"data-quality":0.1237028}}
{"text":"Our experiments show that concept drift detection and sample selection mechanisms result in very efficient retraining strategies which can be successfully used to maintain the performance of the static Android malware state-of-the-art detectors in changing environments.","meta":{"url":"http://arxiv.org/abs/2309.09807v1"},"cats":{"new-dataset":0.0447147117,"dev-research":0.2959950353,"data-quality":0.239389807}}
{"text":"We present a numerically robust algorithm for computing the constrained Delaunay tetrahedrization (CDT) of a piecewise-linear complex, which has a 100% success rate on the 4408 valid models in the Thingi10k dataset.","meta":{"url":"http://arxiv.org/abs/2309.09805v1"},"cats":{"new-dataset":0.1617607023,"dev-research":0.1415663775,"data-quality":0.1042068473}}
{"text":"We build on the underlying theory of the well-known TetGen software, but use a floating-point implementation based on indirect geometric predicates to implicitly represent Steiner points: this new approach dramatically simplifies the implementation, removing the need for ad-hoc tolerances in geometric operations.","meta":{"url":"http://arxiv.org/abs/2309.09805v1"},"cats":{"new-dataset":0.0380403549,"dev-research":0.2826656123,"data-quality":0.0933288931}}
{"text":"Our approach leads to a robust and parameter-free implementation, with an empirically manageable number of added Steiner points.","meta":{"url":"http://arxiv.org/abs/2309.09805v1"},"cats":{"new-dataset":0.0496772439,"dev-research":0.1826292128,"data-quality":0.1136413288}}
{"text":"Furthermore, our algorithm addresses a major gap in TetGen's theory which may lead to algorithmic failure on valid models, even when assuming perfect precision in the calculations.","meta":{"url":"http://arxiv.org/abs/2309.09805v1"},"cats":{"new-dataset":0.0121615533,"dev-research":0.1294177745,"data-quality":0.1358591749}}
{"text":"Our output tetrahedrization conforms with the input geometry without approximations.","meta":{"url":"http://arxiv.org/abs/2309.09805v1"},"cats":{"new-dataset":0.0144230632,"dev-research":0.115819102,"data-quality":0.1282395508}}
{"text":"We can further round our output to floating-point coordinates for downstream applications, which almost always results in valid floating-point meshes unless the input triangulation is very close to being degenerate.","meta":{"url":"http://arxiv.org/abs/2309.09805v1"},"cats":{"new-dataset":0.0328992004,"dev-research":0.195460552,"data-quality":0.1562372313}}
{"text":"This paper presents DFL-TORO, a novel Demonstration Framework for Learning Time-Optimal Robotic tasks via One-shot kinesthetic demonstration.","meta":{"url":"http://arxiv.org/abs/2309.09802v1"},"cats":{"new-dataset":0.0705037304,"dev-research":0.1812767659,"data-quality":0.0579556659}}
{"text":"It aims at optimizing the process of Learning from Demonstration (LfD), applied in the manufacturing sector.","meta":{"url":"http://arxiv.org/abs/2309.09802v1"},"cats":{"new-dataset":0.0491747248,"dev-research":0.2272544379,"data-quality":0.1030935413}}
{"text":"As the effectiveness of LfD is challenged by the quality and efficiency of human demonstrations, our approach offers a streamlined method to intuitively capture task requirements from human teachers, by reducing the need for multiple demonstrations.","meta":{"url":"http://arxiv.org/abs/2309.09802v1"},"cats":{"new-dataset":0.1293064688,"dev-research":0.2716394143,"data-quality":0.0681336749}}
{"text":"Furthermore, we propose an optimization-based smoothing algorithm that ensures time-optimal and jerk-regulated demonstration trajectories, while also adhering to the robot's kinematic constraints.","meta":{"url":"http://arxiv.org/abs/2309.09802v1"},"cats":{"new-dataset":0.0770725923,"dev-research":0.2758664462,"data-quality":0.0488155}}
{"text":"The result is a significant reduction in noise, thereby boosting the robot's operation efficiency.","meta":{"url":"http://arxiv.org/abs/2309.09802v1"},"cats":{"new-dataset":0.0086873538,"dev-research":0.2389355076,"data-quality":0.1390462021}}
{"text":"Evaluations using a Franka Emika Research 3 (FR3) robot for a reaching task further substantiate the efficacy of our framework, highlighting its potential to transform kinesthetic demonstrations in contemporary manufacturing environments.","meta":{"url":"http://arxiv.org/abs/2309.09802v1"},"cats":{"new-dataset":0.0908256907,"dev-research":0.2318465554,"data-quality":0.0476773821}}
{"text":"We study principal-agent problems in which a principal commits to an outcome-dependent payment scheme -- called contract -- in order to induce an agent to take a costly, unobservable action leading to favorable outcomes.","meta":{"url":"http://arxiv.org/abs/2309.09801v1"},"cats":{"new-dataset":0.0443717822,"dev-research":0.1859352966,"data-quality":0.1136511111}}
{"text":"We consider a generalization of the classical (single-round) version of the problem in which the principal interacts with the agent by committing to contracts over multiple rounds.","meta":{"url":"http://arxiv.org/abs/2309.09801v1"},"cats":{"new-dataset":0.115517921,"dev-research":0.1340901887,"data-quality":0.099979853}}
{"text":"The principal has no information about the agent, and they have to learn an optimal contract by only observing the outcome realized at each round.","meta":{"url":"http://arxiv.org/abs/2309.09801v1"},"cats":{"new-dataset":0.0232447055,"dev-research":0.1223391157,"data-quality":0.0900962022}}
{"text":"We focus on settings in which the size of the agent's action space is small.","meta":{"url":"http://arxiv.org/abs/2309.09801v1"},"cats":{"new-dataset":0.0313610105,"dev-research":0.1959130786,"data-quality":0.0562755778}}
{"text":"We design an algorithm that learns an approximately-optimal contract with high probability in a number of rounds polynomial in the size of the outcome space, when the number of actions is constant.","meta":{"url":"http://arxiv.org/abs/2309.09801v1"},"cats":{"new-dataset":0.1509002861,"dev-research":0.151912162,"data-quality":0.087365806}}
{"text":"Our algorithm solves an open problem by Zhu et al.[2022].","meta":{"url":"http://arxiv.org/abs/2309.09801v1"},"cats":{"new-dataset":0.15121722,"dev-research":0.1281899149,"data-quality":0.1533098594}}
{"text":"Moreover, it can also be employed to provide a $\\tilde{\\mathcal{O}}(T^{4/5})$ regret bound in the related online learning setting in which the principal aims at maximizing their cumulative utility, thus considerably improving previously-known regret bounds.","meta":{"url":"http://arxiv.org/abs/2309.09801v1"},"cats":{"new-dataset":0.0095002804,"dev-research":0.1221900404,"data-quality":0.0633921177}}
{"text":"Key information extraction involves recognizing and extracting text from scanned receipts, enabling retrieval of essential content, and organizing it into structured documents.","meta":{"url":"http://arxiv.org/abs/2309.09800v1"},"cats":{"new-dataset":0.0663231241,"dev-research":0.2177611566,"data-quality":0.1994663658}}
{"text":"This paper presents a novel multilingual dataset for receipt extraction, addressing key challenges in information extraction and item classification.","meta":{"url":"http://arxiv.org/abs/2309.09800v1"},"cats":{"new-dataset":0.6460711086,"dev-research":0.1939130713,"data-quality":0.4195896319}}
{"text":"The dataset comprises $47,720$ samples, including annotations for item names, attributes like (price, brand, etc.), and classification into $44$ product categories.","meta":{"url":"http://arxiv.org/abs/2309.09800v1"},"cats":{"new-dataset":0.9232351203,"dev-research":0.1553038394,"data-quality":0.2986571574}}
{"text":"We introduce the InstructLLaMA approach, achieving an F1 score of $0.76$ and an accuracy of $0.68$ for key information extraction and item classification.","meta":{"url":"http://arxiv.org/abs/2309.09800v1"},"cats":{"new-dataset":0.190727528,"dev-research":0.2087734105,"data-quality":0.346162014}}
{"text":"We provide code, datasets, and checkpoints.\\footnote{\\url{https://github.com/Update-For-Integrated-Business-AI/AMuRD}}.","meta":{"url":"http://arxiv.org/abs/2309.09800v1"},"cats":{"new-dataset":0.4857262339,"dev-research":0.2504102067,"data-quality":0.1888315558}}
{"text":"Emotion Recognition in Conversation (ERC) has attracted widespread attention in the natural language processing field due to its enormous potential for practical applications.","meta":{"url":"http://arxiv.org/abs/2309.09799v1"},"cats":{"new-dataset":0.1594332698,"dev-research":0.2237818631,"data-quality":0.2124933137}}
{"text":"Existing ERC methods face challenges in achieving generalization to diverse scenarios due to insufficient modeling of context, ambiguous capture of dialogue relationships and overfitting in speaker modeling.","meta":{"url":"http://arxiv.org/abs/2309.09799v1"},"cats":{"new-dataset":0.0467554363,"dev-research":0.2024955168,"data-quality":0.2690812525}}
{"text":"In this work, we present a Hybrid Continuous Attributive Network (HCAN) to address these issues in the perspective of emotional continuation and emotional attribution.","meta":{"url":"http://arxiv.org/abs/2309.09799v1"},"cats":{"new-dataset":0.1224808317,"dev-research":0.2394152768,"data-quality":0.182567471}}
{"text":"Specifically, HCAN adopts a hybrid recurrent and attention-based module to model global emotion continuity.","meta":{"url":"http://arxiv.org/abs/2309.09799v1"},"cats":{"new-dataset":0.3715472006,"dev-research":0.2010842752,"data-quality":0.077417117}}
{"text":"Then a novel Emotional Attribution Encoding (EAE) is proposed to model intra- and inter-emotional attribution for each utterance.","meta":{"url":"http://arxiv.org/abs/2309.09799v1"},"cats":{"new-dataset":0.08737284,"dev-research":0.177630254,"data-quality":0.2334531732}}
{"text":"Moreover, aiming to enhance the robustness of the model in speaker modeling and improve its performance in different scenarios, A comprehensive loss function emotional cognitive loss $\\mathcal{L}_{\\rm EC}$ is proposed to alleviate emotional drift and overcome the overfitting of the model to speaker modeling.","meta":{"url":"http://arxiv.org/abs/2309.09799v1"},"cats":{"new-dataset":0.0680659531,"dev-research":0.2532228798,"data-quality":0.2598100089}}
{"text":"Our model achieves state-of-the-art performance on three datasets, demonstrating the superiority of our work.","meta":{"url":"http://arxiv.org/abs/2309.09799v1"},"cats":{"new-dataset":0.6277506793,"dev-research":0.1375259099,"data-quality":0.1794839594}}
{"text":"Another extensive comparative experiments and ablation studies on three benchmarks are conducted to provided evidence to support the efficacy of each module.","meta":{"url":"http://arxiv.org/abs/2309.09799v1"},"cats":{"new-dataset":0.0207777104,"dev-research":0.1440538258,"data-quality":0.1193745015}}
{"text":"Further exploration of generalization ability experiments shows the plug-and-play nature of the EAE module in our method.","meta":{"url":"http://arxiv.org/abs/2309.09799v1"},"cats":{"new-dataset":0.005887385,"dev-research":0.21625917,"data-quality":0.120597735}}
{"text":"Harnessing collective intelligence to drive effective decision-making and collaboration benefits from the ability to detect and characterize heterogeneity in consensus beliefs.","meta":{"url":"http://arxiv.org/abs/2309.09787v1"},"cats":{"new-dataset":0.0198260665,"dev-research":0.2992942948,"data-quality":0.1635057975}}
{"text":"This is particularly true in domains such as technology acceptance or leadership perception, where a consensus defines an intersubjective truth, leading to the possibility of multiple \"ground truths\" when subsets of respondents sustain mutually incompatible consensuses.","meta":{"url":"http://arxiv.org/abs/2309.09787v1"},"cats":{"new-dataset":0.0067726055,"dev-research":0.1977867235,"data-quality":0.1582057543}}
{"text":"Cultural Consensus Theory (CCT) provides a statistical framework for detecting and characterizing these divergent consensus beliefs.","meta":{"url":"http://arxiv.org/abs/2309.09787v1"},"cats":{"new-dataset":0.0236050542,"dev-research":0.2044662565,"data-quality":0.2110275525}}
{"text":"However, it is unworkable in modern applications because it lacks the ability to generalize across even highly similar beliefs, is ineffective with sparse data, and can leverage neither external knowledge bases nor learned machine representations.","meta":{"url":"http://arxiv.org/abs/2309.09787v1"},"cats":{"new-dataset":0.007867935,"dev-research":0.1615312238,"data-quality":0.1789485707}}
{"text":"Here, we overcome these limitations through Infinite Deep Latent Construct Cultural Consensus Theory (iDLC-CCT), a nonparametric Bayesian model that extends CCT with a latent construct that maps between pretrained deep neural network embeddings of entities and the consensus beliefs regarding those entities among one or more subsets of respondents.","meta":{"url":"http://arxiv.org/abs/2309.09787v1"},"cats":{"new-dataset":0.1889679596,"dev-research":0.1684280322,"data-quality":0.1738610533}}
{"text":"We validate the method across domains including perceptions of risk sources, food healthiness, leadership, first impressions, and humor.","meta":{"url":"http://arxiv.org/abs/2309.09787v1"},"cats":{"new-dataset":0.0178160764,"dev-research":0.2562226669,"data-quality":0.1731653913}}
{"text":"We find that iDLC-CCT better predicts the degree of consensus, generalizes well to out-of-sample entities, and is effective even with sparse data.","meta":{"url":"http://arxiv.org/abs/2309.09787v1"},"cats":{"new-dataset":0.0869592927,"dev-research":0.1682814482,"data-quality":0.227904393}}
{"text":"To improve scalability, we introduce an efficient hard-clustering variant of the iDLC-CCT using an algorithm derived from a small-variance asymptotic analysis of the model.","meta":{"url":"http://arxiv.org/abs/2309.09787v1"},"cats":{"new-dataset":0.058835441,"dev-research":0.1607212996,"data-quality":0.1700290792}}
{"text":"The iDLC-CCT, therefore, provides a workable computational foundation for harnessing collective intelligence under a lack of cultural consensus and may potentially form the basis of consensus-aware information technologies.","meta":{"url":"http://arxiv.org/abs/2309.09787v1"},"cats":{"new-dataset":0.1335087685,"dev-research":0.2713473937,"data-quality":0.2099225692}}
{"text":"The 2-colorable perfect matching problem asks whether a graph can be colored with two colors so that each node has exactly one neighbor with the same color as itself.","meta":{"url":"http://arxiv.org/abs/2309.09786v1"},"cats":{"new-dataset":0.0352477145,"dev-research":0.1902199634,"data-quality":0.2203012512}}
{"text":"We prove that this problem is NP-complete, even when restricted to 2-connected 3-regular planar graphs.","meta":{"url":"http://arxiv.org/abs/2309.09786v1"},"cats":{"new-dataset":0.1109526416,"dev-research":0.1716891069,"data-quality":0.1627748001}}
{"text":"In 1978, Schaefer proved that this problem is NP-complete in general graphs, and claimed without proof that the same result holds when restricted to 3-regular planar graphs.","meta":{"url":"http://arxiv.org/abs/2309.09786v1"},"cats":{"new-dataset":0.0694008972,"dev-research":0.1635595574,"data-quality":0.1143498544}}
{"text":"Thus we fill in the missing proof of this claim, while simultaneously strengthening to 2-connected graphs (which implies existence of a perfect matching).","meta":{"url":"http://arxiv.org/abs/2309.09786v1"},"cats":{"new-dataset":0.0372038203,"dev-research":0.1698565007,"data-quality":0.2510330361}}
{"text":"We also prove NP-completeness of $k$-colorable perfect matching, for any fixed $k \\geq 2$.","meta":{"url":"http://arxiv.org/abs/2309.09786v1"},"cats":{"new-dataset":0.1866905752,"dev-research":0.1541389041,"data-quality":0.1656914226}}
{"text":"Sentiments inherently drive politics.","meta":{"url":"http://arxiv.org/abs/2309.09783v1"},"cats":{"new-dataset":0.0114663533,"dev-research":0.2682135855,"data-quality":0.1433627549}}
{"text":"How we receive and process information plays an essential role in political decision-making, shaping our judgment with strategic consequences both on the level of legislators and the masses.","meta":{"url":"http://arxiv.org/abs/2309.09783v1"},"cats":{"new-dataset":0.0388629218,"dev-research":0.2665821225,"data-quality":0.1301008083}}
{"text":"If sentiment plays such an important role in politics, how can we study and measure it systematically?","meta":{"url":"http://arxiv.org/abs/2309.09783v1"},"cats":{"new-dataset":0.0866281237,"dev-research":0.2705183396,"data-quality":0.1829929152}}
{"text":"The paper presents a new dataset of sentiment-annotated sentences, which are used in a series of experiments focused on training a robust sentiment classifier for parliamentary proceedings.","meta":{"url":"http://arxiv.org/abs/2309.09783v1"},"cats":{"new-dataset":0.720104952,"dev-research":0.2038629343,"data-quality":0.4526840227}}
{"text":"The paper also introduces the first domain-specific LLM for political science applications additionally pre-trained on 1.72 billion domain-specific words from proceedings of 27 European parliaments.","meta":{"url":"http://arxiv.org/abs/2309.09783v1"},"cats":{"new-dataset":0.2369132446,"dev-research":0.1386695619,"data-quality":0.1816145609}}
{"text":"We present experiments demonstrating how the additional pre-training of LLM on parliamentary data can significantly improve the model downstream performance on the domain-specific tasks, in our case, sentiment detection in parliamentary proceedings.","meta":{"url":"http://arxiv.org/abs/2309.09783v1"},"cats":{"new-dataset":0.1279593573,"dev-research":0.1658763295,"data-quality":0.2469139244}}
{"text":"We further show that multilingual models perform very well on unseen languages and that additional data from other languages significantly improves the target parliament's results.","meta":{"url":"http://arxiv.org/abs/2309.09783v1"},"cats":{"new-dataset":0.2464936739,"dev-research":0.1734571086,"data-quality":0.2579130602}}
{"text":"The paper makes an important contribution to multiple domains of social sciences and bridges them with computer science and computational linguistics.","meta":{"url":"http://arxiv.org/abs/2309.09783v1"},"cats":{"new-dataset":0.0751399124,"dev-research":0.2427104389,"data-quality":0.1997259478}}
{"text":"Lastly, it sets up a more robust approach to sentiment analysis of political texts in general, which allows scholars to study political sentiment from a comparative perspective using standardized tools and techniques.","meta":{"url":"http://arxiv.org/abs/2309.09783v1"},"cats":{"new-dataset":0.0416048361,"dev-research":0.3098051194,"data-quality":0.2311955055}}
{"text":"Physical attacks form one of the most severe threats against secure computing platforms.","meta":{"url":"http://arxiv.org/abs/2309.09782v1"},"cats":{"new-dataset":0.0378315195,"dev-research":0.290537039,"data-quality":0.0806778128}}
{"text":"Their criticality arises from their corresponding threat model: By, e.g., passively measuring an integrated circuit's (IC's) environment during a security-related operation, internal secrets may be disclosed.","meta":{"url":"http://arxiv.org/abs/2309.09782v1"},"cats":{"new-dataset":0.0450025771,"dev-research":0.241004115,"data-quality":0.1661861935}}
{"text":"Furthermore, by actively disturbing the physical runtime environment of an IC, an adversary can cause a specific, exploitable misbehavior.","meta":{"url":"http://arxiv.org/abs/2309.09782v1"},"cats":{"new-dataset":0.0126546518,"dev-research":0.2993044322,"data-quality":0.1209428549}}
{"text":"The set of physical attacks consists of techniques that apply either globally or locally.","meta":{"url":"http://arxiv.org/abs/2309.09782v1"},"cats":{"new-dataset":0.0202456367,"dev-research":0.2825061787,"data-quality":0.0910925519}}
{"text":"When compared to global techniques, local techniques exhibit a much higher precision, hence having the potential to be used in advanced attack scenarios.","meta":{"url":"http://arxiv.org/abs/2309.09782v1"},"cats":{"new-dataset":0.003588395,"dev-research":0.2963446048,"data-quality":0.1179795352}}
{"text":"However, using physical techniques with additional spatial dependency expands the parameter search space exponentially.","meta":{"url":"http://arxiv.org/abs/2309.09782v1"},"cats":{"new-dataset":0.0021892237,"dev-research":0.1354713342,"data-quality":0.0442442865}}
{"text":"In this work, we present and compare two techniques, namely laser logic state imaging (LLSI) and lock-in thermography (LIT), that can be used to discover sub-circuitry of an entirely unknown IC based on optical and thermal principles.","meta":{"url":"http://arxiv.org/abs/2309.09782v1"},"cats":{"new-dataset":0.1228136794,"dev-research":0.1143512284,"data-quality":0.11596415}}
{"text":"We show that the time required to identify specific regions can be drastically reduced, thus lowering the complexity of physical attacks requiring positional information.","meta":{"url":"http://arxiv.org/abs/2309.09782v1"},"cats":{"new-dataset":0.014375305,"dev-research":0.2065965362,"data-quality":0.0930965693}}
{"text":"Our case study on an Intel H610 Platform Controller Hub showcases that, depending on the targeted voltage rail, our technique reduces the search space by around 90 to 98 percent.","meta":{"url":"http://arxiv.org/abs/2309.09782v1"},"cats":{"new-dataset":0.0147467119,"dev-research":0.1833789465,"data-quality":0.0908611495}}
{"text":"Speech is one of the interaction modalities that we increasingly come across in natural user interfaces.","meta":{"url":"http://arxiv.org/abs/2309.09781v1"},"cats":{"new-dataset":0.0478739308,"dev-research":0.2802348614,"data-quality":0.1600520597}}
{"text":"However, its use in collaborative scenarios has not yet been thoroughly investigated.","meta":{"url":"http://arxiv.org/abs/2309.09781v1"},"cats":{"new-dataset":0.0117838157,"dev-research":0.3698425675,"data-quality":0.0844937168}}
{"text":"In this reflection statement, we discuss the opportunities and challenges of integrating speech interaction in multimodal solutions for collaborative work with data visualizations.","meta":{"url":"http://arxiv.org/abs/2309.09781v1"},"cats":{"new-dataset":0.3025644179,"dev-research":0.3806426773,"data-quality":0.0971299277}}
{"text":"We discuss related findings from other research communities and how we could build upon their work to explore and make use of speech interaction for data visualizations in co-located, hybrid, and remote settings.","meta":{"url":"http://arxiv.org/abs/2309.09781v1"},"cats":{"new-dataset":0.5223498029,"dev-research":0.3442510752,"data-quality":0.124351446}}
{"text":"Measuring the complexity of tree structures can be beneficial in areas that use tree data structures for storage, communication, and processing purposes.","meta":{"url":"http://arxiv.org/abs/2309.09779v1"},"cats":{"new-dataset":0.0481563071,"dev-research":0.2431002233,"data-quality":0.1003551827}}
{"text":"This complexity can then be used to compress tree data structures to their information-theoretic limit.","meta":{"url":"http://arxiv.org/abs/2309.09779v1"},"cats":{"new-dataset":0.0469045748,"dev-research":0.1538538629,"data-quality":0.0960485004}}
{"text":"Additionally, the lack of models for random generation of trees is very much felt in mathematical modeling of trees and graphs.","meta":{"url":"http://arxiv.org/abs/2309.09779v1"},"cats":{"new-dataset":0.0131718551,"dev-research":0.19161045,"data-quality":0.0970805693}}
{"text":"In this paper, a number of existing tree generation models such as simply generated trees are discussed, and their information content is analysed by means of information theory and Shannon's entropy.","meta":{"url":"http://arxiv.org/abs/2309.09779v1"},"cats":{"new-dataset":0.0705122739,"dev-research":0.1481945123,"data-quality":0.1414771836}}
{"text":"Subsequently, a new model for generating trees based on practical appearances of trees is introduced, and an upper bound for its entropy is calculated.","meta":{"url":"http://arxiv.org/abs/2309.09779v1"},"cats":{"new-dataset":0.07987612,"dev-research":0.1445701802,"data-quality":0.0905093466}}
{"text":"This model is based on selecting a random tree from possible spanning trees of graphs, which is what happens often in practice.","meta":{"url":"http://arxiv.org/abs/2309.09779v1"},"cats":{"new-dataset":0.0118743603,"dev-research":0.1102270927,"data-quality":0.0965050217}}
{"text":"Moving on to tree compression, we find approaches to universal tree compression of the discussed models.","meta":{"url":"http://arxiv.org/abs/2309.09779v1"},"cats":{"new-dataset":0.0941491229,"dev-research":0.1080220982,"data-quality":0.1464573018}}
{"text":"These approaches first transform a tree into a sequence of symbols, and then apply a dictionary-based compression method.","meta":{"url":"http://arxiv.org/abs/2309.09779v1"},"cats":{"new-dataset":0.1226186376,"dev-research":0.1784403396,"data-quality":0.1899449136}}
{"text":"Conditions for the universality of these method are then studied and analysed.","meta":{"url":"http://arxiv.org/abs/2309.09779v1"},"cats":{"new-dataset":0.0058221424,"dev-research":0.1175915221,"data-quality":0.1102842128}}
{"text":"The escalating surge in data generation presents formidable challenges to information technology, necessitating advancements in storage, retrieval, and utilization.","meta":{"url":"http://arxiv.org/abs/2309.09778v1"},"cats":{"new-dataset":0.1847075885,"dev-research":0.226970891,"data-quality":0.1053795102}}
{"text":"With the proliferation of artificial intelligence and big data, the \"Data Age 2025\" report forecasts an exponential increase in global data production.","meta":{"url":"http://arxiv.org/abs/2309.09778v1"},"cats":{"new-dataset":0.5359882471,"dev-research":0.2492631339,"data-quality":0.0738232451}}
{"text":"The escalating data volumes raise concerns about efficient data processing.","meta":{"url":"http://arxiv.org/abs/2309.09778v1"},"cats":{"new-dataset":0.0531212072,"dev-research":0.2275756405,"data-quality":0.1015105181}}
{"text":"The paper addresses the predicament of achieving a lower compression ratio while maintaining or surpassing the compression performance of state-of-the-art techniques.   ","meta":{"url":"http://arxiv.org/abs/2309.09778v1"},"cats":{"new-dataset":0.0084713717,"dev-research":0.1741437839,"data-quality":0.1327461642}}
{"text":"This paper introduces a lossy compression framework grounded in the perceptron model for data prediction, striving for high compression quality.","meta":{"url":"http://arxiv.org/abs/2309.09778v1"},"cats":{"new-dataset":0.1114680776,"dev-research":0.1464909935,"data-quality":0.2868635906}}
{"text":"The contributions of this study encompass the introduction of positive and negative factors within the relative-to-absolute domain transformation algorithm, the utilization of a three-layer perceptron for improved predictive accuracy, and data selection rule modifications for parallelized compression within compression blocks.","meta":{"url":"http://arxiv.org/abs/2309.09778v1"},"cats":{"new-dataset":0.0282152086,"dev-research":0.17658182,"data-quality":0.1366215855}}
{"text":"Comparative experiments with SZ2.1's PW_REL mode demonstrate a maximum compression ratio reduction of 17.78%.   ","meta":{"url":"http://arxiv.org/abs/2309.09778v1"},"cats":{"new-dataset":0.0101740923,"dev-research":0.1426121714,"data-quality":0.1034093203}}
{"text":"The article is structured as follows: the introduction highlights the data explosion challenge; related work delves into existing solutions; optimization of mapping algorithms in the relative and absolute domains is expounded in Section 3,the design of the new compression framework is detailed in Section 4,In Section 5 we describe the whole process and give pseudo-code, and in Section 6, our solution is evaluated.","meta":{"url":"http://arxiv.org/abs/2309.09778v1"},"cats":{"new-dataset":0.4154527122,"dev-research":0.1781356642,"data-quality":0.1627588362}}
{"text":"Finally, in Section 7, we provide an outlook for future work.","meta":{"url":"http://arxiv.org/abs/2309.09778v1"},"cats":{"new-dataset":0.2157376845,"dev-research":0.2029203067,"data-quality":0.0752551228}}
{"text":"World models, especially in autonomous driving, are trending and drawing extensive attention due to their capacity for comprehending driving environments.","meta":{"url":"http://arxiv.org/abs/2309.09777v1"},"cats":{"new-dataset":0.0790805778,"dev-research":0.2643505364,"data-quality":0.0884950821}}
{"text":"The established world model holds immense potential for the generation of high-quality driving videos, and driving policies for safe maneuvering.","meta":{"url":"http://arxiv.org/abs/2309.09777v1"},"cats":{"new-dataset":0.1220216488,"dev-research":0.2110009979,"data-quality":0.0714992795}}
{"text":"However, a critical limitation in relevant research lies in its predominant focus on gaming environments or simulated settings, thereby lacking the representation of real-world driving scenarios.","meta":{"url":"http://arxiv.org/abs/2309.09777v1"},"cats":{"new-dataset":0.0256118093,"dev-research":0.304152894,"data-quality":0.0601002868}}
{"text":"Therefore, we introduce DriveDreamer, a pioneering world model entirely derived from real-world driving scenarios.","meta":{"url":"http://arxiv.org/abs/2309.09777v1"},"cats":{"new-dataset":0.1459452286,"dev-research":0.2577564454,"data-quality":0.0651914206}}
{"text":"Regarding that modeling the world in intricate driving scenes entails an overwhelming search space, we propose harnessing the powerful diffusion model to construct a comprehensive representation of the complex environment.","meta":{"url":"http://arxiv.org/abs/2309.09777v1"},"cats":{"new-dataset":0.1152396429,"dev-research":0.1588694666,"data-quality":0.0520642251}}
{"text":"Furthermore, we introduce a two-stage training pipeline.","meta":{"url":"http://arxiv.org/abs/2309.09777v1"},"cats":{"new-dataset":0.0616681715,"dev-research":0.1744706623,"data-quality":0.1446216787}}
{"text":"In the initial phase, DriveDreamer acquires a deep understanding of structured traffic constraints, while the subsequent stage equips it with the ability to anticipate future states.","meta":{"url":"http://arxiv.org/abs/2309.09777v1"},"cats":{"new-dataset":0.0217851998,"dev-research":0.1933758556,"data-quality":0.0684481926}}
{"text":"The proposed DriveDreamer is the first world model established from real-world driving scenarios.","meta":{"url":"http://arxiv.org/abs/2309.09777v1"},"cats":{"new-dataset":0.0587009178,"dev-research":0.207040877,"data-quality":0.0644561643}}
{"text":"We instantiate DriveDreamer on the challenging nuScenes benchmark, and extensive experiments verify that DriveDreamer empowers precise, controllable video generation that faithfully captures the structural constraints of real-world traffic scenarios.","meta":{"url":"http://arxiv.org/abs/2309.09777v1"},"cats":{"new-dataset":0.2162621849,"dev-research":0.221520839,"data-quality":0.1191830992}}
{"text":"Additionally, DriveDreamer enables the generation of realistic and reasonable driving policies, opening avenues for interaction and practical applications.","meta":{"url":"http://arxiv.org/abs/2309.09777v1"},"cats":{"new-dataset":0.0482504179,"dev-research":0.3091260323,"data-quality":0.0513872949}}
{"text":"A corresponding explosion in digital images has accompanied the rapid adoption of mobile technology around the world.","meta":{"url":"http://arxiv.org/abs/2309.09775v1"},"cats":{"new-dataset":0.0630670125,"dev-research":0.1876682232,"data-quality":0.0857941026}}
{"text":"People and their activities are routinely captured in digital image and video files.","meta":{"url":"http://arxiv.org/abs/2309.09775v1"},"cats":{"new-dataset":0.3755832029,"dev-research":0.2739435243,"data-quality":0.104435882}}
{"text":"By their very nature, these images and videos often portray social and professional connections.","meta":{"url":"http://arxiv.org/abs/2309.09775v1"},"cats":{"new-dataset":0.1442817327,"dev-research":0.213944868,"data-quality":0.0991768342}}
{"text":"Individuals in the same picture are often connected in some meaningful way.","meta":{"url":"http://arxiv.org/abs/2309.09775v1"},"cats":{"new-dataset":0.0776441502,"dev-research":0.2153542545,"data-quality":0.0995388118}}
{"text":"Our research seeks to identify and model social connections found in images using modern face detection technology and social network analysis.","meta":{"url":"http://arxiv.org/abs/2309.09775v1"},"cats":{"new-dataset":0.0454170952,"dev-research":0.2094813548,"data-quality":0.1064803695}}
{"text":"The proposed methods are then demonstrated on the public image repository associated with the 2022 Emmy's Award Presentation.","meta":{"url":"http://arxiv.org/abs/2309.09775v1"},"cats":{"new-dataset":0.156088752,"dev-research":0.126939815,"data-quality":0.16971779}}
{"text":"Recent semi-supervised learning (SSL) methods typically include a filtering strategy to improve the quality of pseudo labels.","meta":{"url":"http://arxiv.org/abs/2309.09774v1"},"cats":{"new-dataset":0.0981155995,"dev-research":0.1673079296,"data-quality":0.5637853239}}
{"text":"However, these filtering strategies are usually hand-crafted and do not change as the model is updated, resulting in a lot of correct pseudo labels being discarded and incorrect pseudo labels being selected during the training process.","meta":{"url":"http://arxiv.org/abs/2309.09774v1"},"cats":{"new-dataset":0.0142786194,"dev-research":0.2243853936,"data-quality":0.5827185346}}
{"text":"In this work, we observe that the distribution gap between the confidence values of correct and incorrect pseudo labels emerges at the very beginning of the training, which can be utilized to filter pseudo labels.","meta":{"url":"http://arxiv.org/abs/2309.09774v1"},"cats":{"new-dataset":0.1112089014,"dev-research":0.1370817239,"data-quality":0.748416965}}
{"text":"Based on this observation, we propose a Self-Adaptive Pseudo-Label Filter (SPF), which automatically filters noise in pseudo labels in accordance with model evolvement by modeling the confidence distribution throughout the training process.","meta":{"url":"http://arxiv.org/abs/2309.09774v1"},"cats":{"new-dataset":0.0848894393,"dev-research":0.1561947273,"data-quality":0.6552814121}}
{"text":"Specifically, with an online mixture model, we weight each pseudo-labeled sample by the posterior of it being correct, which takes into consideration the confidence distribution at that time.","meta":{"url":"http://arxiv.org/abs/2309.09774v1"},"cats":{"new-dataset":0.0126054313,"dev-research":0.1146163503,"data-quality":0.2824994797}}
{"text":"Unlike previous handcrafted filters, our SPF evolves together with the deep neural network without manual tuning.","meta":{"url":"http://arxiv.org/abs/2309.09774v1"},"cats":{"new-dataset":0.1336490733,"dev-research":0.1149057473,"data-quality":0.1005744527}}
{"text":"Extensive experiments demonstrate that incorporating SPF into the existing SSL methods can help improve the performance of SSL, especially when the labeled data is extremely scarce.","meta":{"url":"http://arxiv.org/abs/2309.09774v1"},"cats":{"new-dataset":0.1340760287,"dev-research":0.1821612308,"data-quality":0.1916986172}}
{"text":"Creating diverse and high-quality 3D assets with an automatic generative model is highly desirable.","meta":{"url":"http://arxiv.org/abs/2309.07920v1"},"cats":{"new-dataset":0.1259959404,"dev-research":0.1604181994,"data-quality":0.0679672314}}
{"text":"Despite extensive efforts on 3D generation, most existing works focus on the generation of a single category or a few categories.","meta":{"url":"http://arxiv.org/abs/2309.07920v1"},"cats":{"new-dataset":0.034628101,"dev-research":0.3191407335,"data-quality":0.0733401918}}
{"text":"In this paper, we introduce a diffusion-based feed-forward framework for synthesizing massive categories of real-world 3D objects with a single generative model.","meta":{"url":"http://arxiv.org/abs/2309.07920v1"},"cats":{"new-dataset":0.1614655653,"dev-research":0.1636751435,"data-quality":0.0651834132}}
{"text":"Notably, there are three major challenges for this large-vocabulary 3D generation: a) the need for expressive yet efficient 3D representation; b) large diversity in geometry and texture across categories; c) complexity in the appearances of real-world objects.","meta":{"url":"http://arxiv.org/abs/2309.07920v1"},"cats":{"new-dataset":0.1385140358,"dev-research":0.2467607326,"data-quality":0.0833845262}}
{"text":"To this end, we propose a novel triplane-based 3D-aware Diffusion model with TransFormer, DiffTF, for handling challenges via three aspects.","meta":{"url":"http://arxiv.org/abs/2309.07920v1"},"cats":{"new-dataset":0.0391508999,"dev-research":0.1551970548,"data-quality":0.0434848559}}
{"text":"1) Considering efficiency and robustness, we adopt a revised triplane representation and improve the fitting speed and accuracy.","meta":{"url":"http://arxiv.org/abs/2309.07920v1"},"cats":{"new-dataset":0.0737479701,"dev-research":0.1593362617,"data-quality":0.110908102}}
{"text":"2) To handle the drastic variations in geometry and texture, we regard the features of all 3D objects as a combination of generalized 3D knowledge and specialized 3D features.","meta":{"url":"http://arxiv.org/abs/2309.07920v1"},"cats":{"new-dataset":0.0530571123,"dev-research":0.1894179777,"data-quality":0.076031141}}
{"text":"To extract generalized 3D knowledge from diverse categories, we propose a novel 3D-aware transformer with shared cross-plane attention.","meta":{"url":"http://arxiv.org/abs/2309.07920v1"},"cats":{"new-dataset":0.0714147084,"dev-research":0.1517905136,"data-quality":0.0728723894}}
{"text":"It learns the cross-plane relations across different planes and aggregates the generalized 3D knowledge with specialized 3D features.","meta":{"url":"http://arxiv.org/abs/2309.07920v1"},"cats":{"new-dataset":0.1456004741,"dev-research":0.1639977184,"data-quality":0.0596953082}}
{"text":"3) In addition, we devise the 3D-aware encoder/decoder to enhance the generalized 3D knowledge in the encoded triplanes for handling categories with complex appearances.","meta":{"url":"http://arxiv.org/abs/2309.07920v1"},"cats":{"new-dataset":0.076461318,"dev-research":0.1765699056,"data-quality":0.1167914397}}
{"text":"Extensive experiments on ShapeNet and OmniObject3D (over 200 diverse real-world categories) convincingly demonstrate that a single DiffTF model achieves state-of-the-art large-vocabulary 3D object generation performance with large diversity, rich semantics, and high quality.","meta":{"url":"http://arxiv.org/abs/2309.07920v1"},"cats":{"new-dataset":0.3174574302,"dev-research":0.2356738921,"data-quality":0.0862705978}}
{"text":"We introduce OpenIllumination, a real-world dataset containing over 108K images of 64 objects with diverse materials, captured under 72 camera views and a large number of different illuminations.","meta":{"url":"http://arxiv.org/abs/2309.07921v1"},"cats":{"new-dataset":0.8808398027,"dev-research":0.118631291,"data-quality":0.1045539697}}
{"text":"For each image in the dataset, we provide accurate camera parameters, illumination ground truth, and foreground segmentation masks.","meta":{"url":"http://arxiv.org/abs/2309.07921v1"},"cats":{"new-dataset":0.7120979847,"dev-research":0.1455609496,"data-quality":0.1830498407}}
{"text":"Our dataset enables the quantitative evaluation of most inverse rendering and material decomposition methods for real objects.","meta":{"url":"http://arxiv.org/abs/2309.07921v1"},"cats":{"new-dataset":0.234830541,"dev-research":0.1715498812,"data-quality":0.1146373698}}
{"text":"We examine several state-of-the-art inverse rendering methods on our dataset and compare their performances.","meta":{"url":"http://arxiv.org/abs/2309.07921v1"},"cats":{"new-dataset":0.2408131964,"dev-research":0.1697899249,"data-quality":0.1241233396}}
{"text":"The dataset and code can be found on the project page: https://oppo-us-research.github.io/OpenIllumination.","meta":{"url":"http://arxiv.org/abs/2309.07921v1"},"cats":{"new-dataset":0.6964280454,"dev-research":0.1078812879,"data-quality":0.1188241506}}
{"text":"Human-Scene Interaction (HSI) is a vital component of fields like embodied AI and virtual reality.","meta":{"url":"http://arxiv.org/abs/2309.07918v1"},"cats":{"new-dataset":0.2646800764,"dev-research":0.2999245815,"data-quality":0.0810150644}}
{"text":"Despite advancements in motion quality and physical plausibility, two pivotal factors, versatile interaction control and the development of a user-friendly interface, require further exploration before the practical application of HSI.","meta":{"url":"http://arxiv.org/abs/2309.07918v1"},"cats":{"new-dataset":0.0651510233,"dev-research":0.2965174076,"data-quality":0.0373825462}}
{"text":"This paper presents a unified HSI framework, UniHSI, which supports unified control of diverse interactions through language commands.","meta":{"url":"http://arxiv.org/abs/2309.07918v1"},"cats":{"new-dataset":0.1705585783,"dev-research":0.2935929049,"data-quality":0.0976061949}}
{"text":"This framework is built upon the definition of interaction as Chain of Contacts (CoC): steps of human joint-object part pairs, which is inspired by the strong correlation between interaction types and human-object contact regions.","meta":{"url":"http://arxiv.org/abs/2309.07918v1"},"cats":{"new-dataset":0.088515164,"dev-research":0.2726862142,"data-quality":0.0540025047}}
{"text":"Based on the definition, UniHSI constitutes a Large Language Model (LLM) Planner to translate language prompts into task plans in the form of CoC, and a Unified Controller that turns CoC into uniform task execution.","meta":{"url":"http://arxiv.org/abs/2309.07918v1"},"cats":{"new-dataset":0.0846494752,"dev-research":0.2111184882,"data-quality":0.0720016319}}
{"text":"To facilitate training and evaluation, we collect a new dataset named ScenePlan that encompasses thousands of task plans generated by LLMs based on diverse scenarios.","meta":{"url":"http://arxiv.org/abs/2309.07918v1"},"cats":{"new-dataset":0.9027864115,"dev-research":0.2195151186,"data-quality":0.0819474599}}
{"text":"Comprehensive experiments demonstrate the effectiveness of our framework in versatile task execution and generalizability to real scanned scenes.","meta":{"url":"http://arxiv.org/abs/2309.07918v1"},"cats":{"new-dataset":0.0677686438,"dev-research":0.2051008231,"data-quality":0.10324044}}
{"text":"The project page is at https://github.com/OpenRobotLab/UniHSI .","meta":{"url":"http://arxiv.org/abs/2309.07918v1"},"cats":{"new-dataset":0.2771186967,"dev-research":0.2119469195,"data-quality":0.0984442186}}
{"text":"While text-conditional 3D object generation and manipulation have seen rapid progress, the evaluation of coherence between generated 3D shapes and input textual descriptions lacks a clear benchmark.","meta":{"url":"http://arxiv.org/abs/2309.07917v1"},"cats":{"new-dataset":0.0943614989,"dev-research":0.247687955,"data-quality":0.107747728}}
{"text":"The reason is twofold: a) the low quality of the textual descriptions in the only publicly available dataset of text-shape pairs; b) the limited effectiveness of the metrics used to quantitatively assess such coherence.","meta":{"url":"http://arxiv.org/abs/2309.07917v1"},"cats":{"new-dataset":0.0251091959,"dev-research":0.2020010918,"data-quality":0.2289809096}}
{"text":"In this paper, we propose a comprehensive solution that addresses both weaknesses.","meta":{"url":"http://arxiv.org/abs/2309.07917v1"},"cats":{"new-dataset":0.0139833781,"dev-research":0.2426588688,"data-quality":0.219699401}}
{"text":"Firstly, we employ large language models to automatically refine textual descriptions associated with shapes.","meta":{"url":"http://arxiv.org/abs/2309.07917v1"},"cats":{"new-dataset":0.1955582587,"dev-research":0.3112257764,"data-quality":0.27024347}}
{"text":"Secondly, we propose a quantitative metric to assess text-to-shape coherence, through cross-attention mechanisms.","meta":{"url":"http://arxiv.org/abs/2309.07917v1"},"cats":{"new-dataset":0.0338754341,"dev-research":0.1664401359,"data-quality":0.194454126}}
{"text":"To validate our approach, we conduct a user study and compare quantitatively our metric with existing ones.","meta":{"url":"http://arxiv.org/abs/2309.07917v1"},"cats":{"new-dataset":0.060907425,"dev-research":0.3948845924,"data-quality":0.1467477681}}
{"text":"The refined dataset, the new metric and a set of text-shape pairs validated by the user study comprise a novel, fine-grained benchmark that we publicly release to foster research on text-to-shape coherence of text-conditioned 3D generative models.","meta":{"url":"http://arxiv.org/abs/2309.07917v1"},"cats":{"new-dataset":0.1848658494,"dev-research":0.1736558491,"data-quality":0.1356006602}}
{"text":"Benchmark available at https://cvlab-unibo.github.io/CrossCoherence-Web/.","meta":{"url":"http://arxiv.org/abs/2309.07917v1"},"cats":{"new-dataset":0.1881268218,"dev-research":0.1138476792,"data-quality":0.1253713418}}
{"text":"Starting from the resurgence of deep learning, vision-language models (VLMs) benefiting from large language models (LLMs) have never been so popular.","meta":{"url":"http://arxiv.org/abs/2309.07915v1"},"cats":{"new-dataset":0.1092787185,"dev-research":0.1643221871,"data-quality":0.1501541184}}
{"text":"However, while LLMs can utilize extensive background knowledge and task information with in-context learning, most VLMs still struggle with understanding complex multi-modal prompts with multiple images.","meta":{"url":"http://arxiv.org/abs/2309.07915v1"},"cats":{"new-dataset":0.0439210795,"dev-research":0.1369579024,"data-quality":0.1232035859}}
{"text":"The issue can traced back to the architectural design of VLMs or pre-training data.","meta":{"url":"http://arxiv.org/abs/2309.07915v1"},"cats":{"new-dataset":0.0331725815,"dev-research":0.2333980811,"data-quality":0.1982464141}}
{"text":"Specifically, the current VLMs primarily emphasize utilizing multi-modal data with a single image some, rather than multi-modal prompts with interleaved multiple images and text.","meta":{"url":"http://arxiv.org/abs/2309.07915v1"},"cats":{"new-dataset":0.0267051077,"dev-research":0.1492200311,"data-quality":0.1385293603}}
{"text":"Even though some newly proposed VLMs could handle user prompts with multiple images, pre-training data does not provide more sophisticated multi-modal prompts than interleaved image and text crawled from the web.","meta":{"url":"http://arxiv.org/abs/2309.07915v1"},"cats":{"new-dataset":0.1089759234,"dev-research":0.1372536752,"data-quality":0.1557252942}}
{"text":"We propose MMICL to address the issue by considering both the model and data perspectives.","meta":{"url":"http://arxiv.org/abs/2309.07915v1"},"cats":{"new-dataset":0.0636846025,"dev-research":0.1833881283,"data-quality":0.1397431624}}
{"text":"We introduce a well-designed architecture capable of seamlessly integrating visual and textual context in an interleaved manner and MIC dataset to reduce the gap between the training data and the complex user prompts in real-world applications, including: 1) multi-modal context with interleaved images and text, 2) textual references for each image, and 3) multi-image data with spatial, logical, or temporal relationships.","meta":{"url":"http://arxiv.org/abs/2309.07915v1"},"cats":{"new-dataset":0.5290889557,"dev-research":0.1793683933,"data-quality":0.1794554471}}
{"text":"Our experiments confirm that MMICL achieves new stat-of-the-art zero-shot and few-shot performance on a wide range of general vision-language tasks, especially for complex reasoning benchmarks including MME and MMBench.","meta":{"url":"http://arxiv.org/abs/2309.07915v1"},"cats":{"new-dataset":0.13929412,"dev-research":0.2572882724,"data-quality":0.1835339123}}
{"text":"Our analysis demonstrates that MMICL effectively deals with the challenge of complex multi-modal prompt understanding.","meta":{"url":"http://arxiv.org/abs/2309.07915v1"},"cats":{"new-dataset":0.0369874976,"dev-research":0.2184128653,"data-quality":0.136688852}}
{"text":"The experiments on ScienceQA-IMG also show that MMICL successfully alleviates the issue of language bias in VLMs, which we believe is the reason behind the advanced performance of MMICL.","meta":{"url":"http://arxiv.org/abs/2309.07915v1"},"cats":{"new-dataset":0.021249336,"dev-research":0.227660782,"data-quality":0.2300704294}}
{"text":"Object detection (OD), a crucial vision task, remains challenged by the lack of large training datasets with precise object localization labels.","meta":{"url":"http://arxiv.org/abs/2309.07914v1"},"cats":{"new-dataset":0.1389241326,"dev-research":0.1659007658,"data-quality":0.3441673608}}
{"text":"In this work, we propose ALWOD, a new framework that addresses this problem by fusing active learning (AL) with weakly and semi-supervised object detection paradigms.","meta":{"url":"http://arxiv.org/abs/2309.07914v1"},"cats":{"new-dataset":0.1886339395,"dev-research":0.1827498791,"data-quality":0.3037746531}}
{"text":"Because the performance of AL critically depends on the model initialization, we propose a new auxiliary image generator strategy that utilizes an extremely small labeled set, coupled with a large weakly tagged set of images, as a warm-start for AL.","meta":{"url":"http://arxiv.org/abs/2309.07914v1"},"cats":{"new-dataset":0.0944561896,"dev-research":0.1266689643,"data-quality":0.2146128983}}
{"text":"We then propose a new AL acquisition function, another critical factor in AL success, that leverages the student-teacher OD pair disagreement and uncertainty to effectively propose the most informative images to annotate.","meta":{"url":"http://arxiv.org/abs/2309.07914v1"},"cats":{"new-dataset":0.1131779146,"dev-research":0.2475737897,"data-quality":0.3005500796}}
{"text":"Finally, to complete the AL loop, we introduce a new labeling task delegated to human annotators, based on selection and correction of model-proposed detections, which is both rapid and effective in labeling the informative images.","meta":{"url":"http://arxiv.org/abs/2309.07914v1"},"cats":{"new-dataset":0.2115808414,"dev-research":0.2310522756,"data-quality":0.6572731409}}
{"text":"We demonstrate, across several challenging benchmarks, that ALWOD significantly narrows the gap between the ODs trained on few partially labeled but strategically selected image instances and those that rely on the fully-labeled data.","meta":{"url":"http://arxiv.org/abs/2309.07914v1"},"cats":{"new-dataset":0.1419254579,"dev-research":0.1454183506,"data-quality":0.3836963081}}
{"text":"Our code is publicly available on https://github.com/seqam-lab/ALWOD.","meta":{"url":"http://arxiv.org/abs/2309.07914v1"},"cats":{"new-dataset":0.2692708853,"dev-research":0.1741113612,"data-quality":0.1313798173}}
{"text":"Recently, large-scale pre-trained language-image models like CLIP have shown extraordinary capabilities for understanding spatial contents, but naively transferring such models to video recognition still suffers from unsatisfactory temporal modeling capabilities.","meta":{"url":"http://arxiv.org/abs/2309.07911v1"},"cats":{"new-dataset":0.2324053188,"dev-research":0.1254257367,"data-quality":0.1827456862}}
{"text":"Existing methods insert tunable structures into or in parallel with the pre-trained model, which either requires back-propagation through the whole pre-trained model and is thus resource-demanding, or is limited by the temporal reasoning capability of the pre-trained structure.","meta":{"url":"http://arxiv.org/abs/2309.07911v1"},"cats":{"new-dataset":0.019263895,"dev-research":0.1685415161,"data-quality":0.0659828825}}
{"text":"In this work, we present DiST, which disentangles the learning of spatial and temporal aspects of videos.","meta":{"url":"http://arxiv.org/abs/2309.07911v1"},"cats":{"new-dataset":0.1525683329,"dev-research":0.151246974,"data-quality":0.1250674411}}
{"text":"Specifically, DiST uses a dual-encoder structure, where a pre-trained foundation model acts as the spatial encoder, and a lightweight network is introduced as the temporal encoder.","meta":{"url":"http://arxiv.org/abs/2309.07911v1"},"cats":{"new-dataset":0.0873376067,"dev-research":0.193050757,"data-quality":0.061323066}}
{"text":"An integration branch is inserted between the encoders to fuse spatio-temporal information.","meta":{"url":"http://arxiv.org/abs/2309.07911v1"},"cats":{"new-dataset":0.1034432938,"dev-research":0.1944376322,"data-quality":0.0806789418}}
{"text":"The disentangled spatial and temporal learning in DiST is highly efficient because it avoids the back-propagation of massive pre-trained parameters.","meta":{"url":"http://arxiv.org/abs/2309.07911v1"},"cats":{"new-dataset":0.0440528164,"dev-research":0.1494879329,"data-quality":0.0518189289}}
{"text":"Meanwhile, we empirically show that disentangled learning with an extra network for integration benefits both spatial and temporal understanding.","meta":{"url":"http://arxiv.org/abs/2309.07911v1"},"cats":{"new-dataset":0.010131166,"dev-research":0.198402062,"data-quality":0.1110626561}}
{"text":"Extensive experiments on five benchmarks show that DiST delivers better performance than existing state-of-the-art methods by convincing gaps.","meta":{"url":"http://arxiv.org/abs/2309.07911v1"},"cats":{"new-dataset":0.0319666327,"dev-research":0.2808563723,"data-quality":0.1254266699}}
{"text":"When pre-training on the large-scale Kinetics-710, we achieve 89.7% on Kinetics-400 with a frozen ViT-L model, which verifies the scalability of DiST.","meta":{"url":"http://arxiv.org/abs/2309.07911v1"},"cats":{"new-dataset":0.1682560925,"dev-research":0.0950871467,"data-quality":0.078247463}}
{"text":"Codes and models can be found in https://github.com/alibaba-mmai-research/DiST.","meta":{"url":"http://arxiv.org/abs/2309.07911v1"},"cats":{"new-dataset":0.3016700763,"dev-research":0.1293107448,"data-quality":0.091389318}}
{"text":"Existing volumetric methods for predicting 3D human pose estimation are accurate, but computationally expensive and optimized for single time-step prediction.","meta":{"url":"http://arxiv.org/abs/2309.07910v1"},"cats":{"new-dataset":0.1590096732,"dev-research":0.1791463098,"data-quality":0.0501309515}}
{"text":"We present TEMPO, an efficient multi-view pose estimation model that learns a robust spatiotemporal representation, improving pose accuracy while also tracking and forecasting human pose.","meta":{"url":"http://arxiv.org/abs/2309.07910v1"},"cats":{"new-dataset":0.4449821169,"dev-research":0.1786474535,"data-quality":0.0747403588}}
{"text":"We significantly reduce computation compared to the state-of-the-art by recurrently computing per-person 2D pose features, fusing both spatial and temporal information into a single representation.","meta":{"url":"http://arxiv.org/abs/2309.07910v1"},"cats":{"new-dataset":0.4634200758,"dev-research":0.2429341984,"data-quality":0.06999034}}
{"text":"In doing so, our model is able to use spatiotemporal context to predict more accurate human poses without sacrificing efficiency.","meta":{"url":"http://arxiv.org/abs/2309.07910v1"},"cats":{"new-dataset":0.1313679447,"dev-research":0.1762173119,"data-quality":0.0517251586}}
{"text":"We further use this representation to track human poses over time as well as predict future poses.","meta":{"url":"http://arxiv.org/abs/2309.07910v1"},"cats":{"new-dataset":0.5402741781,"dev-research":0.1839036729,"data-quality":0.0605939796}}
{"text":"Finally, we demonstrate that our model is able to generalize across datasets without scene-specific fine-tuning.","meta":{"url":"http://arxiv.org/abs/2309.07910v1"},"cats":{"new-dataset":0.2601786826,"dev-research":0.1525827059,"data-quality":0.2984023831}}
{"text":"TEMPO achieves 10$\\%$ better MPJPE with a 33$\\times$ improvement in FPS compared to TesseTrack on the challenging CMU Panoptic Studio dataset.","meta":{"url":"http://arxiv.org/abs/2309.07910v1"},"cats":{"new-dataset":0.1454802578,"dev-research":0.2394352193,"data-quality":0.1440409987}}
{"text":"In this work, I describe a method for visualizing two types of network address allocations: Media Access Control (MAC) addresses -- hardware identifiers permanently assigned to network interfaces -- and Internet Protocol Version 6 (IPv6) allocations -- subnetworks assigned from a larger, encompassing network (e.g., allocated /64","meta":{"url":"http://arxiv.org/abs/2309.07908v1"},"cats":{"new-dataset":0.2346641114,"dev-research":0.2254427459,"data-quality":0.1058614177}}
{"text":"networks from a /48 network).","meta":{"url":"http://arxiv.org/abs/2309.07908v1"},"cats":{"new-dataset":0.0596764084,"dev-research":0.1728193144,"data-quality":0.1060340517}}
{"text":"We propose a physics-based method for synthesizing dexterous hand-object interactions in a full-body setting.","meta":{"url":"http://arxiv.org/abs/2309.07907v1"},"cats":{"new-dataset":0.0654368434,"dev-research":0.1911292231,"data-quality":0.0414663426}}
{"text":"While recent advancements have addressed specific facets of human-object interactions, a comprehensive physics-based approach remains a challenge.","meta":{"url":"http://arxiv.org/abs/2309.07907v1"},"cats":{"new-dataset":0.0277926545,"dev-research":0.1718754162,"data-quality":0.0517664385}}
{"text":"Existing methods often focus on isolated segments of the interaction process and rely on data-driven techniques that may result in artifacts.","meta":{"url":"http://arxiv.org/abs/2309.07907v1"},"cats":{"new-dataset":0.0332760943,"dev-research":0.3301282783,"data-quality":0.1405960952}}
{"text":"In contrast, our proposed method embraces reinforcement learning (RL) and physics simulation to mitigate the limitations of data-driven approaches.","meta":{"url":"http://arxiv.org/abs/2309.07907v1"},"cats":{"new-dataset":0.0552929592,"dev-research":0.1694176343,"data-quality":0.0586105754}}
{"text":"Through a hierarchical framework, we first learn skill priors for both body and hand movements in a decoupled setting.","meta":{"url":"http://arxiv.org/abs/2309.07907v1"},"cats":{"new-dataset":0.1016902293,"dev-research":0.2139056195,"data-quality":0.0560782889}}
{"text":"The generic skill priors learn to decode a latent skill embedding into the motion of the underlying part.","meta":{"url":"http://arxiv.org/abs/2309.07907v1"},"cats":{"new-dataset":0.0134171663,"dev-research":0.1789015889,"data-quality":0.1050847904}}
{"text":"A high-level policy then controls hand-object interactions in these pretrained latent spaces, guided by task objectives of grasping and 3D target trajectory following.","meta":{"url":"http://arxiv.org/abs/2309.07907v1"},"cats":{"new-dataset":0.0546990347,"dev-research":0.2046302082,"data-quality":0.0397247524}}
{"text":"It is trained using a novel reward function that combines an adversarial style term with a task reward, encouraging natural motions while fulfilling the task incentives.","meta":{"url":"http://arxiv.org/abs/2309.07907v1"},"cats":{"new-dataset":0.0271558609,"dev-research":0.1580178416,"data-quality":0.0794645088}}
{"text":"Our method successfully accomplishes the complete interaction task, from approaching an object to grasping and subsequent manipulation.","meta":{"url":"http://arxiv.org/abs/2309.07907v1"},"cats":{"new-dataset":0.027294961,"dev-research":0.2197117084,"data-quality":0.0470660604}}
{"text":"We compare our approach against kinematics-based baselines and show that it leads to more physically plausible motions.","meta":{"url":"http://arxiv.org/abs/2309.07907v1"},"cats":{"new-dataset":0.0997093943,"dev-research":0.2052645211,"data-quality":0.0567157517}}
{"text":"We present an approach to modeling an image-space prior on scene dynamics.","meta":{"url":"http://arxiv.org/abs/2309.07906v1"},"cats":{"new-dataset":0.2091044449,"dev-research":0.1476083446,"data-quality":0.0901555323}}
{"text":"Our prior is learned from a collection of motion trajectories extracted from real video sequences containing natural, oscillating motion such as trees, flowers, candles, and clothes blowing in the wind.","meta":{"url":"http://arxiv.org/abs/2309.07906v1"},"cats":{"new-dataset":0.3273253665,"dev-research":0.1455575385,"data-quality":0.0733214561}}
{"text":"Given a single image, our trained model uses a frequency-coordinated diffusion sampling process to predict a per-pixel long-term motion representation in the Fourier domain, which we call a neural stochastic motion texture.","meta":{"url":"http://arxiv.org/abs/2309.07906v1"},"cats":{"new-dataset":0.1840019123,"dev-research":0.1139221325,"data-quality":0.0808127809}}
{"text":"This representation can be converted into dense motion trajectories that span an entire video.","meta":{"url":"http://arxiv.org/abs/2309.07906v1"},"cats":{"new-dataset":0.0530961908,"dev-research":0.1167558932,"data-quality":0.0694649643}}
{"text":"Along with an image-based rendering module, these trajectories can be used for a number of downstream applications, such as turning still images into seamlessly looping dynamic videos, or allowing users to realistically interact with objects in real pictures.","meta":{"url":"http://arxiv.org/abs/2309.07906v1"},"cats":{"new-dataset":0.0665620213,"dev-research":0.2442284947,"data-quality":0.0490271823}}
{"text":"In-context learning (ICL) i.e. showing LLMs only a few task-specific demonstrations has led to downstream gains with no task-specific fine-tuning required.","meta":{"url":"http://arxiv.org/abs/2309.07900v1"},"cats":{"new-dataset":0.0162693372,"dev-research":0.1334052214,"data-quality":0.1299070666}}
{"text":"However, LLMs are sensitive to the choice of prompts, and therefore a crucial research question is how to select good demonstrations for ICL.","meta":{"url":"http://arxiv.org/abs/2309.07900v1"},"cats":{"new-dataset":0.0291529913,"dev-research":0.1690014669,"data-quality":0.0780077884}}
{"text":"One effective strategy is leveraging semantic similarity between the ICL demonstrations and test inputs by using a text retriever, which however is sub-optimal as that does not consider the LLM's existing knowledge about that task.","meta":{"url":"http://arxiv.org/abs/2309.07900v1"},"cats":{"new-dataset":0.069912387,"dev-research":0.2026349021,"data-quality":0.1677559266}}
{"text":"From prior work (Min et al., 2022), we already know that labels paired with the demonstrations bias the model predictions.","meta":{"url":"http://arxiv.org/abs/2309.07900v1"},"cats":{"new-dataset":0.0316779493,"dev-research":0.1505279079,"data-quality":0.3247506707}}
{"text":"This leads us to our hypothesis whether considering LLM's existing knowledge about the task, especially with respect to the output label space can help in a better demonstration selection strategy.","meta":{"url":"http://arxiv.org/abs/2309.07900v1"},"cats":{"new-dataset":0.0137871694,"dev-research":0.1591152498,"data-quality":0.2281307464}}
{"text":"Through extensive experimentation on three text classification tasks, we find that it is beneficial to not only choose semantically similar ICL demonstrations but also to choose those demonstrations that help resolve the inherent label ambiguity surrounding the test example.","meta":{"url":"http://arxiv.org/abs/2309.07900v1"},"cats":{"new-dataset":0.0208833025,"dev-research":0.2290761668,"data-quality":0.3885935422}}
{"text":"Interestingly, we find that including demonstrations that the LLM previously mis-classified and also fall on the test example's decision boundary, brings the most performance gain.","meta":{"url":"http://arxiv.org/abs/2309.07900v1"},"cats":{"new-dataset":0.0046089012,"dev-research":0.1573294386,"data-quality":0.2159690406}}
{"text":"Current physics-informed (standard or operator) neural networks still rely on accurately learning the initial conditions of the system they are solving.","meta":{"url":"http://arxiv.org/abs/2309.07899v1"},"cats":{"new-dataset":0.0271441975,"dev-research":0.1680489925,"data-quality":0.1387513077}}
{"text":"In contrast, standard numerical methods evolve such initial conditions without needing to learn these.","meta":{"url":"http://arxiv.org/abs/2309.07899v1"},"cats":{"new-dataset":0.0030892434,"dev-research":0.2052723331,"data-quality":0.066603198}}
{"text":"In this study, we propose to improve current physics-informed deep learning strategies such that initial conditions do not need to be learned and are represented exactly in the predicted solution.","meta":{"url":"http://arxiv.org/abs/2309.07899v1"},"cats":{"new-dataset":0.124819848,"dev-research":0.1639582298,"data-quality":0.1058493407}}
{"text":"Moreover, this method guarantees that when a DeepONet is applied multiple times to time step a solution, the resulting function is continuous.","meta":{"url":"http://arxiv.org/abs/2309.07899v1"},"cats":{"new-dataset":0.0075212909,"dev-research":0.2119666276,"data-quality":0.0798913469}}
{"text":"In this paper, we address the challenge of Nash equilibrium (NE) seeking in non-cooperative convex games with partial-decision information.","meta":{"url":"http://arxiv.org/abs/2309.07897v1"},"cats":{"new-dataset":0.0189996803,"dev-research":0.0938165798,"data-quality":0.1137855961}}
{"text":"We propose a distributed algorithm, where each agent refines its strategy through projected-gradient steps and an averaging procedure.","meta":{"url":"http://arxiv.org/abs/2309.07897v1"},"cats":{"new-dataset":0.0185891201,"dev-research":0.1359510863,"data-quality":0.0633082718}}
{"text":"Each agent uses estimates of competitors' actions obtained solely from local neighbor interactions, in a directed communication network.","meta":{"url":"http://arxiv.org/abs/2309.07897v1"},"cats":{"new-dataset":0.0587422784,"dev-research":0.1684204104,"data-quality":0.0739186031}}
{"text":"Unlike previous approaches that rely on (strong) monotonicity assumptions, this work establishes the convergence towards a NE under a diagonal dominance property of the pseudo-gradient mapping, that can be checked locally by the agents.","meta":{"url":"http://arxiv.org/abs/2309.07897v1"},"cats":{"new-dataset":0.010777758,"dev-research":0.0973593627,"data-quality":0.0827229496}}
{"text":"Further, this condition is physically interpretable and of relevance for many applications, as it suggests that an agent's objective function is primarily influenced by its individual strategic decisions, rather than by the actions of its competitors.","meta":{"url":"http://arxiv.org/abs/2309.07897v1"},"cats":{"new-dataset":0.0030053525,"dev-research":0.2221155202,"data-quality":0.0568689704}}
{"text":"In virtue of a novel block-infinity norm convergence argument, we provide explicit bounds for constant step-size that are independent of the communication structure, and can be computed in a totally decentralized way.","meta":{"url":"http://arxiv.org/abs/2309.07897v1"},"cats":{"new-dataset":0.0712657385,"dev-research":0.141745056,"data-quality":0.0551853771}}
{"text":"Numerical simulations on an optical network's power control problem validate the algorithm's effectiveness.","meta":{"url":"http://arxiv.org/abs/2309.07897v1"},"cats":{"new-dataset":0.005036549,"dev-research":0.2095696437,"data-quality":0.1282036037}}
{"text":"This paper presents a method to learn hand-object interaction prior for reconstructing a 3D hand-object scene from a single RGB image.","meta":{"url":"http://arxiv.org/abs/2309.07891v1"},"cats":{"new-dataset":0.3411831655,"dev-research":0.1872082905,"data-quality":0.0711488489}}
{"text":"The inference as well as training-data generation for 3D hand-object scene reconstruction is challenging due to the depth ambiguity of a single image and occlusions by the hand and object.","meta":{"url":"http://arxiv.org/abs/2309.07891v1"},"cats":{"new-dataset":0.3317592035,"dev-research":0.159137608,"data-quality":0.1135376862}}
{"text":"We turn this challenge into an opportunity by utilizing the hand shape to constrain the possible relative configuration of the hand and object geometry.","meta":{"url":"http://arxiv.org/abs/2309.07891v1"},"cats":{"new-dataset":0.1284802264,"dev-research":0.1758051921,"data-quality":0.065224871}}
{"text":"We design a generalizable implicit function, HandNeRF, that explicitly encodes the correlation of the 3D hand shape features and 2D object features to predict the hand and object scene geometry.","meta":{"url":"http://arxiv.org/abs/2309.07891v1"},"cats":{"new-dataset":0.2169447654,"dev-research":0.2078515105,"data-quality":0.0934198606}}
{"text":"With experiments on real-world datasets, we show that HandNeRF is able to reconstruct hand-object scenes of novel grasp configurations more accurately than comparable methods.","meta":{"url":"http://arxiv.org/abs/2309.07891v1"},"cats":{"new-dataset":0.6462067667,"dev-research":0.1636560955,"data-quality":0.090780894}}
{"text":"Moreover, we demonstrate that object reconstruction from HandNeRF ensures more accurate execution of a downstream task, such as grasping for robotic hand-over.","meta":{"url":"http://arxiv.org/abs/2309.07891v1"},"cats":{"new-dataset":0.0656271807,"dev-research":0.1777740939,"data-quality":0.0772960694}}
{"text":"We present a novel local-global feature fusion framework for body-weight exercise recognition with floor-based dynamic pressure maps.","meta":{"url":"http://arxiv.org/abs/2309.07888v1"},"cats":{"new-dataset":0.1853504528,"dev-research":0.1872762708,"data-quality":0.0799305957}}
{"text":"One step further from the existing studies using deep neural networks mainly focusing on global feature extraction, the proposed framework aims to combine local and global features using image processing techniques and the YOLO object detection to localize pressure profiles from different body parts and consider physical constraints.","meta":{"url":"http://arxiv.org/abs/2309.07888v1"},"cats":{"new-dataset":0.1569346782,"dev-research":0.1890857762,"data-quality":0.1303331898}}
{"text":"The proposed local feature extraction method generates two sets of high-level local features consisting of cropped pressure mapping and numerical features such as angular orientation, location on the mat, and pressure area.","meta":{"url":"http://arxiv.org/abs/2309.07888v1"},"cats":{"new-dataset":0.0759619092,"dev-research":0.2101341133,"data-quality":0.1315306839}}
{"text":"In addition, we adopt a knowledge distillation for regularization to preserve the knowledge of the global feature extraction and improve the performance of the exercise recognition.","meta":{"url":"http://arxiv.org/abs/2309.07888v1"},"cats":{"new-dataset":0.0634506232,"dev-research":0.1984889745,"data-quality":0.16553155}}
{"text":"Our experimental results demonstrate a notable 11 percent improvement in F1 score for exercise recognition while preserving label-specific features.","meta":{"url":"http://arxiv.org/abs/2309.07888v1"},"cats":{"new-dataset":0.0810817015,"dev-research":0.2011084179,"data-quality":0.3509324156}}
{"text":"In the present paper we introduce new optimization algorithms for the task of density ratio estimation.","meta":{"url":"http://arxiv.org/abs/2309.07887v1"},"cats":{"new-dataset":0.0157030433,"dev-research":0.1268544337,"data-quality":0.1516555683}}
{"text":"More precisely, we consider extending the well-known KMM method using the construction of a suitable loss function, in order to encompass more general situations involving the estimation of density ratio with respect to subsets of the training data and test data, respectively.","meta":{"url":"http://arxiv.org/abs/2309.07887v1"},"cats":{"new-dataset":0.0229154349,"dev-research":0.1087207866,"data-quality":0.2423577251}}
{"text":"The associated codes can be found at https://github.com/CDAlecsa/Generalized-KMM.","meta":{"url":"http://arxiv.org/abs/2309.07887v1"},"cats":{"new-dataset":0.2133033939,"dev-research":0.0826357628,"data-quality":0.1233728352}}
{"text":"This work introduces a new multispectral database and novel approaches for eyeblink detection in RGB and Near-Infrared (NIR) individual images.","meta":{"url":"http://arxiv.org/abs/2309.07880v1"},"cats":{"new-dataset":0.3664019538,"dev-research":0.1300927964,"data-quality":0.1099681321}}
{"text":"Our contributed dataset (mEBAL2, multimodal Eye Blink and Attention Level estimation, Version 2) is the largest existing eyeblink database, representing a great opportunity to improve data-driven multispectral approaches for blink detection and related applications (e.g., attention level estimation and presentation attack detection in face biometrics).","meta":{"url":"http://arxiv.org/abs/2309.07880v1"},"cats":{"new-dataset":0.7111253322,"dev-research":0.1807062724,"data-quality":0.1013139856}}
{"text":"mEBAL2 includes 21,100 image sequences from 180 different students (more than 2 million labeled images in total) while conducting a number of e-learning tasks of varying difficulty or taking a real course on HTML initiation through the edX MOOC platform.","meta":{"url":"http://arxiv.org/abs/2309.07880v1"},"cats":{"new-dataset":0.3780265321,"dev-research":0.2123033027,"data-quality":0.0905674389}}
{"text":"mEBAL2 uses multiple sensors, including two Near-Infrared (NIR) and one RGB camera to capture facial gestures during the execution of the tasks, as well as an Electroencephalogram (EEG) band to get the cognitive activity of the user and blinking events.","meta":{"url":"http://arxiv.org/abs/2309.07880v1"},"cats":{"new-dataset":0.1332622697,"dev-research":0.2253775768,"data-quality":0.0690062752}}
{"text":"Furthermore, this work proposes a Convolutional Neural Network architecture as benchmark for blink detection on mEBAL2 with performances up to 97%.","meta":{"url":"http://arxiv.org/abs/2309.07880v1"},"cats":{"new-dataset":0.1635752161,"dev-research":0.217084959,"data-quality":0.1425159864}}
{"text":"Different training methodologies are implemented using the RGB spectrum, NIR spectrum, and the combination of both to enhance the performance on existing eyeblink detectors.","meta":{"url":"http://arxiv.org/abs/2309.07880v1"},"cats":{"new-dataset":0.1345146213,"dev-research":0.1620202241,"data-quality":0.182377634}}
{"text":"We demonstrate that combining NIR and RGB images during training improves the performance of RGB eyeblink detectors (i.e., detection based only on a RGB image).","meta":{"url":"http://arxiv.org/abs/2309.07880v1"},"cats":{"new-dataset":0.120879084,"dev-research":0.192392574,"data-quality":0.178966875}}
{"text":"Finally, the generalization capacity of the proposed eyeblink detectors is validated in wilder and more challenging environments like the HUST-LEBW dataset to show the usefulness of mEBAL2 to train a new generation of data-driven approaches for eyeblink detection.","meta":{"url":"http://arxiv.org/abs/2309.07880v1"},"cats":{"new-dataset":0.4668619058,"dev-research":0.2038707454,"data-quality":0.1463132299}}
{"text":"This work aims to explore the community structure of Santiago de Chile by analyzing the movement patterns of its residents.","meta":{"url":"http://arxiv.org/abs/2309.07878v1"},"cats":{"new-dataset":0.1358863395,"dev-research":0.2690629693,"data-quality":0.0412964854}}
{"text":"We use a dataset containing the approximate locations of home and work places for a subset of anonymized residents to construct a network that represents the movement patterns within the city.","meta":{"url":"http://arxiv.org/abs/2309.07878v1"},"cats":{"new-dataset":0.4754549617,"dev-research":0.2289008331,"data-quality":0.106247087}}
{"text":"Through the analysis of this network, we aim to identify the communities or sub-cities that exist within Santiago de Chile and gain insights into the factors that drive the spatial organization of the city.","meta":{"url":"http://arxiv.org/abs/2309.07878v1"},"cats":{"new-dataset":0.1483400641,"dev-research":0.2498363993,"data-quality":0.0759080906}}
{"text":"We employ modularity optimization algorithms and clustering techniques to identify the communities within the network.","meta":{"url":"http://arxiv.org/abs/2309.07878v1"},"cats":{"new-dataset":0.0562433305,"dev-research":0.2041136243,"data-quality":0.1504581091}}
{"text":"Our results present that the novelty of combining community detection algorithms with segregation tools provides new insights to further the understanding of the complex geography of segregation during working hours.","meta":{"url":"http://arxiv.org/abs/2309.07878v1"},"cats":{"new-dataset":0.0486988357,"dev-research":0.2426193956,"data-quality":0.1548138972}}
{"text":"Training large language models to follow instructions makes them perform better on a wide range of tasks, generally becoming more helpful.","meta":{"url":"http://arxiv.org/abs/2309.07875v1"},"cats":{"new-dataset":0.0255759719,"dev-research":0.2657260079,"data-quality":0.1447701486}}
{"text":"However, a perfectly helpful model will follow even the most malicious instructions and readily generate harmful content.","meta":{"url":"http://arxiv.org/abs/2309.07875v1"},"cats":{"new-dataset":0.0070221189,"dev-research":0.2341858368,"data-quality":0.1876879275}}
{"text":"In this paper, we raise concerns over the safety of models that only emphasize helpfulness, not safety, in their instruction-tuning.","meta":{"url":"http://arxiv.org/abs/2309.07875v1"},"cats":{"new-dataset":0.0230258903,"dev-research":0.4148954741,"data-quality":0.1892164399}}
{"text":"We show that several popular instruction-tuned models are highly unsafe.","meta":{"url":"http://arxiv.org/abs/2309.07875v1"},"cats":{"new-dataset":0.03725824,"dev-research":0.228795656,"data-quality":0.1328949466}}
{"text":"Moreover, we show that adding just 3% safety examples (a few hundred demonstrations) in the training set when fine-tuning a model like LLaMA can substantially improve their safety.","meta":{"url":"http://arxiv.org/abs/2309.07875v1"},"cats":{"new-dataset":0.0687106692,"dev-research":0.2490721274,"data-quality":0.2173753202}}
{"text":"Our safety-tuning does not make models significantly less capable or helpful as measured by standard benchmarks.","meta":{"url":"http://arxiv.org/abs/2309.07875v1"},"cats":{"new-dataset":0.0030622041,"dev-research":0.2301488525,"data-quality":0.1814004273}}
{"text":"However, we do find a behavior of exaggerated safety, where too much safety-tuning makes models refuse to respond to reasonable prompts that superficially resemble unsafe ones.","meta":{"url":"http://arxiv.org/abs/2309.07875v1"},"cats":{"new-dataset":0.0145543967,"dev-research":0.3477574491,"data-quality":0.2452791441}}
{"text":"Our study sheds light on trade-offs in training LLMs to follow instructions and exhibit safe behavior.","meta":{"url":"http://arxiv.org/abs/2309.07875v1"},"cats":{"new-dataset":0.0244639192,"dev-research":0.218627995,"data-quality":0.0941770101}}
{"text":"In many fields of robotics, knowing the relative position and orientation between two sensors is a mandatory precondition to operate with multiple sensing modalities.","meta":{"url":"http://arxiv.org/abs/2309.07874v1"},"cats":{"new-dataset":0.016775721,"dev-research":0.1381118383,"data-quality":0.064876106}}
{"text":"In this context, the pair LiDAR-RGB cameras offer complementary features: LiDARs yield sparse high quality range measurements, while RGB cameras provide a dense color measurement of the environment.","meta":{"url":"http://arxiv.org/abs/2309.07874v1"},"cats":{"new-dataset":0.1256573456,"dev-research":0.1675511156,"data-quality":0.1159518746}}
{"text":"Existing techniques often rely either on complex calibration targets that are expensive to obtain, or extracted virtual correspondences that can hinder the estimate's accuracy.","meta":{"url":"http://arxiv.org/abs/2309.07874v1"},"cats":{"new-dataset":0.02968637,"dev-research":0.1702743268,"data-quality":0.1977670619}}
{"text":"In this paper we address the problem of LiDAR-RGB calibration using typical calibration patterns (i.e. A3 chessboard) with minimal human intervention.","meta":{"url":"http://arxiv.org/abs/2309.07874v1"},"cats":{"new-dataset":0.1552849086,"dev-research":0.2015526147,"data-quality":0.1108081202}}
{"text":"Our approach exploits the planarity of the target to find correspondences between the sensors measurements, leading to features that are robust to LiDAR noise.   ","meta":{"url":"http://arxiv.org/abs/2309.07874v1"},"cats":{"new-dataset":0.0863972662,"dev-research":0.1696283867,"data-quality":0.1903856662}}
{"text":"Moreover, we estimate a solution by solving a joint non-linear optimization problem.","meta":{"url":"http://arxiv.org/abs/2309.07874v1"},"cats":{"new-dataset":0.0256509134,"dev-research":0.1528100509,"data-quality":0.1496243575}}
{"text":"We validated our approach by carrying on quantitative and comparative experiments with other state-of-the-art approaches.","meta":{"url":"http://arxiv.org/abs/2309.07874v1"},"cats":{"new-dataset":0.0091348947,"dev-research":0.1223186306,"data-quality":0.136907282}}
{"text":"Our results show that our simple schema performs on par or better than other approches using complex calibration targets.","meta":{"url":"http://arxiv.org/abs/2309.07874v1"},"cats":{"new-dataset":0.1447373382,"dev-research":0.2193745411,"data-quality":0.1372010878}}
{"text":"Finally, we release an open-source C++ implementation at \\url{https://github.com/srrg-sapienza/ca2lib}","meta":{"url":"http://arxiv.org/abs/2309.07874v1"},"cats":{"new-dataset":0.0790522599,"dev-research":0.2092134524,"data-quality":0.1378642044}}
{"text":"Differential Dynamic Programming (DDP) is an efficient computational tool for solving nonlinear optimal control problems.","meta":{"url":"http://arxiv.org/abs/2309.07872v1"},"cats":{"new-dataset":0.0490870886,"dev-research":0.2221135823,"data-quality":0.0546553354}}
{"text":"It was originally designed as a single shooting method and thus is sensitive to the initial guess supplied.","meta":{"url":"http://arxiv.org/abs/2309.07872v1"},"cats":{"new-dataset":0.0016128437,"dev-research":0.1629820955,"data-quality":0.1406674181}}
{"text":"This work considers the extension of DDP to multiple shooting (MS), improving its robustness to initial guesses.","meta":{"url":"http://arxiv.org/abs/2309.07872v1"},"cats":{"new-dataset":0.036267712,"dev-research":0.1383341307,"data-quality":0.1135577646}}
{"text":"A novel derivation is proposed that accounts for the defect between shooting segments during the DDP backward pass, while still maintaining quadratic convergence locally.","meta":{"url":"http://arxiv.org/abs/2309.07872v1"},"cats":{"new-dataset":0.0104410717,"dev-research":0.1993089483,"data-quality":0.1171085565}}
{"text":"The derivation enables unifying multiple previous MS algorithms, and opens the door to many smaller algorithmic improvements.","meta":{"url":"http://arxiv.org/abs/2309.07872v1"},"cats":{"new-dataset":0.0033338433,"dev-research":0.2365371471,"data-quality":0.0848064935}}
{"text":"A penalty method is introduced to strategically control the step size, further improving the convergence performance.","meta":{"url":"http://arxiv.org/abs/2309.07872v1"},"cats":{"new-dataset":0.0024822763,"dev-research":0.2417559007,"data-quality":0.0585572204}}
{"text":"An adaptive merit function and a more reliable acceptance condition are employed for globalization.","meta":{"url":"http://arxiv.org/abs/2309.07872v1"},"cats":{"new-dataset":0.0024424815,"dev-research":0.1944045874,"data-quality":0.1820367566}}
{"text":"The effects of these improvements are benchmarked for trajectory optimization with a quadrotor, an acrobot, and a manipulator.","meta":{"url":"http://arxiv.org/abs/2309.07872v1"},"cats":{"new-dataset":0.0217534795,"dev-research":0.1981889262,"data-quality":0.0573888216}}
{"text":"MS-DDP is also demonstrated for use in Model Predictive Control (MPC) for dynamic jumping with a quadruped robot, showing its benefits over a single shooting approach.","meta":{"url":"http://arxiv.org/abs/2309.07872v1"},"cats":{"new-dataset":0.0421500478,"dev-research":0.15791165,"data-quality":0.052634968}}
{"text":"In this paper, we consider a learning problem among non-cooperative agents interacting in a time-varying system.","meta":{"url":"http://arxiv.org/abs/2309.07871v1"},"cats":{"new-dataset":0.0603423405,"dev-research":0.1172353983,"data-quality":0.103302289}}
{"text":"Specifically, we focus on repeated linear quadratic network games, in which the network of interactions changes with time and agents may not be present at each iteration.","meta":{"url":"http://arxiv.org/abs/2309.07871v1"},"cats":{"new-dataset":0.0414393785,"dev-research":0.1524896021,"data-quality":0.0588148658}}
{"text":"To get tractability, we assume that at each iteration, the network of interactions is sampled from an underlying random network model and agents participate at random with a given probability.","meta":{"url":"http://arxiv.org/abs/2309.07871v1"},"cats":{"new-dataset":0.0241963102,"dev-research":0.1152383703,"data-quality":0.0772542427}}
{"text":"Under these assumptions, we consider a gradient-based learning algorithm and establish almost sure convergence of the agents' strategies to the Nash equilibrium of the game played over the expected network.","meta":{"url":"http://arxiv.org/abs/2309.07871v1"},"cats":{"new-dataset":0.0392642286,"dev-research":0.0961746081,"data-quality":0.0992588153}}
{"text":"Additionally, we prove, in the large population regime, that the learned strategy is an $\\epsilon$-Nash equilibrium for each stage game with high probability.","meta":{"url":"http://arxiv.org/abs/2309.07871v1"},"cats":{"new-dataset":0.0743437094,"dev-research":0.1137282649,"data-quality":0.1015385351}}
{"text":"We validate our results over an online market application.","meta":{"url":"http://arxiv.org/abs/2309.07871v1"},"cats":{"new-dataset":0.0524732753,"dev-research":0.2071308926,"data-quality":0.2035045941}}
{"text":"Recent advances on large language models (LLMs) enable researchers and developers to build autonomous language agents that can automatically solve various tasks and interact with environments, humans, and other agents using natural language interfaces.","meta":{"url":"http://arxiv.org/abs/2309.07870v1"},"cats":{"new-dataset":0.2035631417,"dev-research":0.209400771,"data-quality":0.1326713992}}
{"text":"We consider language agents as a promising direction towards artificial general intelligence and release Agents, an open-source library with the goal of opening up these advances to a wider non-specialist audience.","meta":{"url":"http://arxiv.org/abs/2309.07870v1"},"cats":{"new-dataset":0.35081226,"dev-research":0.2524780255,"data-quality":0.1738459462}}
{"text":"Agents is carefully engineered to support important features including planning, memory, tool usage, multi-agent communication, and fine-grained symbolic control.","meta":{"url":"http://arxiv.org/abs/2309.07870v1"},"cats":{"new-dataset":0.0534074537,"dev-research":0.3134061827,"data-quality":0.0421015262}}
{"text":"Agents is user-friendly as it enables non-specialists to build, customize, test, tune, and deploy state-of-the-art autonomous language agents without much coding.","meta":{"url":"http://arxiv.org/abs/2309.07870v1"},"cats":{"new-dataset":0.1055190464,"dev-research":0.3366651608,"data-quality":0.1248781847}}
{"text":"The library is also research-friendly as its modularized design makes it easily extensible for researchers.","meta":{"url":"http://arxiv.org/abs/2309.07870v1"},"cats":{"new-dataset":0.0344754129,"dev-research":0.2732491036,"data-quality":0.0556154832}}
{"text":"Agents is available at https://github.com/aiwaves-cn/agents.","meta":{"url":"http://arxiv.org/abs/2309.07870v1"},"cats":{"new-dataset":0.3693111243,"dev-research":0.1828828616,"data-quality":0.0505686683}}
{"text":"We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges.","meta":{"url":"http://arxiv.org/abs/2309.07867v1"},"cats":{"new-dataset":0.0676466713,"dev-research":0.1833081281,"data-quality":0.0826020371}}
{"text":"Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time.","meta":{"url":"http://arxiv.org/abs/2309.07867v1"},"cats":{"new-dataset":0.0098836362,"dev-research":0.125333113,"data-quality":0.0478520662}}
{"text":"Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence.","meta":{"url":"http://arxiv.org/abs/2309.07867v1"},"cats":{"new-dataset":0.0121602917,"dev-research":0.1208573514,"data-quality":0.0752615765}}
{"text":"We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped.","meta":{"url":"http://arxiv.org/abs/2309.07867v1"},"cats":{"new-dataset":0.007756426,"dev-research":0.120242878,"data-quality":0.0643213452}}
{"text":"The loss function of beta diffusion, expressed in terms of Bregman divergence, further supports the efficacy of KLUBs for optimization.","meta":{"url":"http://arxiv.org/abs/2309.07867v1"},"cats":{"new-dataset":0.0034621802,"dev-research":0.1363884061,"data-quality":0.0793156784}}
{"text":"Experimental results on both synthetic data and natural images demonstrate the unique capabilities of beta diffusion in generative modeling of range-bounded data and validate the effectiveness of KLUBs in optimizing diffusion models, thereby making them valuable additions to the family of diffusion-based generative models and the optimization techniques used to train them.","meta":{"url":"http://arxiv.org/abs/2309.07867v1"},"cats":{"new-dataset":0.0495477526,"dev-research":0.1207580309,"data-quality":0.0673216731}}
{"text":"This paper targets a novel trade-off problem in generalizable prompt learning for vision-language models (VLM), i.e., improving the performance on unseen classes while maintaining the performance on seen classes.","meta":{"url":"http://arxiv.org/abs/2309.07866v1"},"cats":{"new-dataset":0.1036747965,"dev-research":0.1967896332,"data-quality":0.2676743184}}
{"text":"Comparing with existing generalizable methods that neglect the seen classes degradation, the setting of this problem is more strict and fits more closely with practical applications.","meta":{"url":"http://arxiv.org/abs/2309.07866v1"},"cats":{"new-dataset":0.014374765,"dev-research":0.2068800089,"data-quality":0.3315378039}}
{"text":"To solve this problem, we start from the optimization perspective, and leverage the relationship between loss landscape geometry and model generalization ability.","meta":{"url":"http://arxiv.org/abs/2309.07866v1"},"cats":{"new-dataset":0.0068350413,"dev-research":0.1418914862,"data-quality":0.119911406}}
{"text":"By analyzing the loss landscape of the state-of-the-art method and the widely-used Sharpness-aware Minimization (SAM), we conclude that the trade-off performance correlates to both loss value and loss sharpness, while each of them are indispensable.","meta":{"url":"http://arxiv.org/abs/2309.07866v1"},"cats":{"new-dataset":0.0051568145,"dev-research":0.2695769163,"data-quality":0.2880159836}}
{"text":"However, we find the optimizing gradient of existing methods cannot always maintain high consistency with both loss value and loss sharpness during the whole optimization procedure.","meta":{"url":"http://arxiv.org/abs/2309.07866v1"},"cats":{"new-dataset":0.0016852881,"dev-research":0.2158526952,"data-quality":0.3183303019}}
{"text":"To this end, we propose an novel SAM-based method for prompt learning, denoted as Gradient Constrained Sharpness-aware Context Optimization (GCSCoOp), to dynamically constrains the optimizing gradient, thus achieving above two-fold optimization objective simultaneously.","meta":{"url":"http://arxiv.org/abs/2309.07866v1"},"cats":{"new-dataset":0.0166644053,"dev-research":0.194222269,"data-quality":0.1238973835}}
{"text":"Extensive experiments verify the effectiveness of GCSCoOp in the trade-off problem.","meta":{"url":"http://arxiv.org/abs/2309.07866v1"},"cats":{"new-dataset":0.0097841928,"dev-research":0.1410874258,"data-quality":0.0897957659}}
{"text":"For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit.","meta":{"url":"http://arxiv.org/abs/2309.07864v1"},"cats":{"new-dataset":0.0378180268,"dev-research":0.1898320818,"data-quality":0.0494593283}}
{"text":"AI agents are artificial entities that sense their environment, make decisions, and take actions.","meta":{"url":"http://arxiv.org/abs/2309.07864v1"},"cats":{"new-dataset":0.0970640653,"dev-research":0.273104372,"data-quality":0.0695050045}}
{"text":"Many efforts have been made to develop intelligent AI agents since the mid-20th century.","meta":{"url":"http://arxiv.org/abs/2309.07864v1"},"cats":{"new-dataset":0.0636134668,"dev-research":0.2691009119,"data-quality":0.0691983617}}
{"text":"However, these efforts have mainly focused on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks.","meta":{"url":"http://arxiv.org/abs/2309.07864v1"},"cats":{"new-dataset":0.0031697461,"dev-research":0.2624215631,"data-quality":0.04587553}}
{"text":"Actually, what the community lacks is a sufficiently general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios.","meta":{"url":"http://arxiv.org/abs/2309.07864v1"},"cats":{"new-dataset":0.0342075926,"dev-research":0.2676593951,"data-quality":0.0613865838}}
{"text":"Due to the versatile and remarkable capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents.","meta":{"url":"http://arxiv.org/abs/2309.07864v1"},"cats":{"new-dataset":0.0775834713,"dev-research":0.1368299501,"data-quality":0.083715938}}
{"text":"Many research efforts have leveraged LLMs as the foundation to build AI agents and have achieved significant progress.","meta":{"url":"http://arxiv.org/abs/2309.07864v1"},"cats":{"new-dataset":0.0307382026,"dev-research":0.149443637,"data-quality":0.0546439296}}
{"text":"We start by tracing the concept of agents from its philosophical origins to its development in AI, and explain why LLMs are suitable foundations for AI agents.","meta":{"url":"http://arxiv.org/abs/2309.07864v1"},"cats":{"new-dataset":0.077910056,"dev-research":0.1696694565,"data-quality":0.0604740862}}
{"text":"Building upon this, we present a conceptual framework for LLM-based agents, comprising three main components: brain, perception, and action, and the framework can be tailored to suit different applications.","meta":{"url":"http://arxiv.org/abs/2309.07864v1"},"cats":{"new-dataset":0.0662259795,"dev-research":0.1422740388,"data-quality":0.0448939554}}
{"text":"Subsequently, we explore the extensive applications of LLM-based agents in three aspects: single-agent scenarios, multi-agent scenarios, and human-agent cooperation.","meta":{"url":"http://arxiv.org/abs/2309.07864v1"},"cats":{"new-dataset":0.0792331856,"dev-research":0.1376335105,"data-quality":0.0394075149}}
{"text":"Following this, we delve into agent societies, exploring the behavior and personality of LLM-based agents, the social phenomena that emerge when they form societies, and the insights they offer for human society.","meta":{"url":"http://arxiv.org/abs/2309.07864v1"},"cats":{"new-dataset":0.1841230542,"dev-research":0.139552465,"data-quality":0.0496607846}}
{"text":"Finally, we discuss a range of key topics and open problems within the field.","meta":{"url":"http://arxiv.org/abs/2309.07864v1"},"cats":{"new-dataset":0.2799535625,"dev-research":0.2782503247,"data-quality":0.1349550803}}
{"text":"Humans encode information into sounds by controlling articulators and decode information from sounds using the auditory apparatus.","meta":{"url":"http://arxiv.org/abs/2309.07861v1"},"cats":{"new-dataset":0.0390336537,"dev-research":0.2092957713,"data-quality":0.1374076142}}
{"text":"This paper introduces CiwaGAN, a model of human spoken language acquisition that combines unsupervised articulatory modeling with an unsupervised model of information exchange through the auditory modality.","meta":{"url":"http://arxiv.org/abs/2309.07861v1"},"cats":{"new-dataset":0.0842207214,"dev-research":0.1729262183,"data-quality":0.1538322897}}
{"text":"While prior research includes unsupervised articulatory modeling and information exchange separately, our model is the first to combine the two components.","meta":{"url":"http://arxiv.org/abs/2309.07861v1"},"cats":{"new-dataset":0.0118671785,"dev-research":0.1532518831,"data-quality":0.0755284407}}
{"text":"The paper also proposes an improved articulatory model with more interpretable internal representations.","meta":{"url":"http://arxiv.org/abs/2309.07861v1"},"cats":{"new-dataset":0.0121385294,"dev-research":0.1713443813,"data-quality":0.1095391542}}
{"text":"The proposed CiwaGAN model is the most realistic approximation of human spoken language acquisition using deep learning.","meta":{"url":"http://arxiv.org/abs/2309.07861v1"},"cats":{"new-dataset":0.1114596038,"dev-research":0.1553614929,"data-quality":0.1915014341}}
{"text":"As such, it is useful for cognitively plausible simulations of the human speech act.","meta":{"url":"http://arxiv.org/abs/2309.07861v1"},"cats":{"new-dataset":0.0187250691,"dev-research":0.1766968451,"data-quality":0.0794371334}}
{"text":"Markov Chain Monte Carlo (MCMC) algorithms are a widely-used algorithmic tool for sampling from high-dimensional distributions, a notable example is the equilibirum distribution of graphical models.","meta":{"url":"http://arxiv.org/abs/2309.07859v1"},"cats":{"new-dataset":0.0454127064,"dev-research":0.1303392939,"data-quality":0.067818806}}
{"text":"The Glauber dynamics, also known as the Gibbs sampler, is the simplest example of an MCMC algorithm; the transitions of the chain update the configuration at a randomly chosen coordinate at each step.","meta":{"url":"http://arxiv.org/abs/2309.07859v1"},"cats":{"new-dataset":0.0099151111,"dev-research":0.0954015276,"data-quality":0.060654624}}
{"text":"Several works have studied distributed versions of the Glauber dynamics and we extend these efforts to a more general family of Markov chains.","meta":{"url":"http://arxiv.org/abs/2309.07859v1"},"cats":{"new-dataset":0.0847029001,"dev-research":0.0864025661,"data-quality":0.0564261127}}
{"text":"An important combinatorial problem in the study of MCMC algorithms is random colorings.","meta":{"url":"http://arxiv.org/abs/2309.07859v1"},"cats":{"new-dataset":0.0413327131,"dev-research":0.131892679,"data-quality":0.1189820151}}
{"text":"Given a graph $G$ of maximum degree $\\Delta$ and an integer $k\\geq\\Delta+1$, the goal is to generate a random proper vertex $k$-coloring of $G$.   Jerrum (1995) proved that the Glauber dynamics has $O(n\\log{n})$ mixing time when $k>2\\Delta$. Fischer and Ghaffari (2018), and independently Feng, Hayes, and Yin (2018), presented a parallel and distributed version of the Glauber dynamics which converges in $O(\\log{n})$ rounds for $k>(2+\\varepsilon)\\Delta$ for any $\\varepsilon>0$. We improve this result to $k>(11/6-\\delta)\\Delta$ for a fixed $\\delta>0$. This matches the state of the art for randomly sampling colorings of general graphs in the sequential setting.","meta":{"url":"http://arxiv.org/abs/2309.07859v1"},"cats":{"new-dataset":0.0871412768,"dev-research":0.1308151739,"data-quality":0.1076610572}}
{"text":"Whereas previous works focused on distributed variants of the Glauber dynamics, our work presents a parallel and distributed version of the more general flip dynamics presented by Vigoda (2000) (and refined by Chen, Delcourt, Moitra, Perarnau, and Postle (2019)), which recolors local maximal two-colored components in each step.","meta":{"url":"http://arxiv.org/abs/2309.07859v1"},"cats":{"new-dataset":0.103518228,"dev-research":0.1030635901,"data-quality":0.0353335574}}
{"text":"Before applying data analytics or machine learning to a data set, a vital step is usually the construction of an informative set of features from the data.","meta":{"url":"http://arxiv.org/abs/2309.07856v1"},"cats":{"new-dataset":0.1149085837,"dev-research":0.3388395754,"data-quality":0.1207268987}}
{"text":"In this paper, we present SMARTFEAT, an efficient automated feature engineering tool to assist data users, even non-experts, in constructing useful features.","meta":{"url":"http://arxiv.org/abs/2309.07856v1"},"cats":{"new-dataset":0.1816521704,"dev-research":0.4906084044,"data-quality":0.2224795436}}
{"text":"Leveraging the power of Foundation Models (FMs), our approach enables the creation of new features from the data, based on contextual information and open-world knowledge.","meta":{"url":"http://arxiv.org/abs/2309.07856v1"},"cats":{"new-dataset":0.3449747864,"dev-research":0.2483968337,"data-quality":0.0868005613}}
{"text":"To achieve this, our method incorporates an intelligent operator selector that discerns a subset of operators, effectively avoiding exhaustive combinations of original features, as is typically observed in traditional automated feature engineering tools.","meta":{"url":"http://arxiv.org/abs/2309.07856v1"},"cats":{"new-dataset":0.0216499723,"dev-research":0.3800396571,"data-quality":0.2234837417}}
{"text":"Moreover, we address the limitations of performing data tasks through row-level interactions with FMs, which could lead to significant delays and costs due to excessive API calls.","meta":{"url":"http://arxiv.org/abs/2309.07856v1"},"cats":{"new-dataset":0.0941238178,"dev-research":0.2719424342,"data-quality":0.0601599771}}
{"text":"To tackle this, we introduce a function generator that facilitates the acquisition of efficient data transformations, such as dataframe built-in methods or lambda functions, ensuring the applicability of SMARTFEAT to generate new features for large datasets.","meta":{"url":"http://arxiv.org/abs/2309.07856v1"},"cats":{"new-dataset":0.6309408871,"dev-research":0.2604981965,"data-quality":0.143091544}}
{"text":"With SMARTFEAT, dataset users can efficiently search for and apply transformations to obtain new features, leading to improvements in the AUC of downstream ML classification by up to 29.8%.","meta":{"url":"http://arxiv.org/abs/2309.07856v1"},"cats":{"new-dataset":0.1068754521,"dev-research":0.1852923784,"data-quality":0.2656115495}}
{"text":"As language models are adapted by a more sophisticated and diverse set of users, the importance of guaranteeing that they provide factually correct information supported by verifiable sources is critical across fields of study & professions.","meta":{"url":"http://arxiv.org/abs/2309.07852v1"},"cats":{"new-dataset":0.0389135457,"dev-research":0.3057873359,"data-quality":0.3017799742}}
{"text":"This is especially the case for high-stakes fields, such as medicine and law, where the risk of propagating false information is high and can lead to undesirable societal consequences.","meta":{"url":"http://arxiv.org/abs/2309.07852v1"},"cats":{"new-dataset":0.024821016,"dev-research":0.2701015855,"data-quality":0.2257765049}}
{"text":"Previous work studying factuality and attribution has not focused on analyzing these characteristics of language model outputs in domain-specific scenarios.","meta":{"url":"http://arxiv.org/abs/2309.07852v1"},"cats":{"new-dataset":0.0241131904,"dev-research":0.2553514977,"data-quality":0.3393479611}}
{"text":"In this work, we present an evaluation study analyzing various axes of factuality and attribution provided in responses from a few systems, by bringing domain experts in the loop.","meta":{"url":"http://arxiv.org/abs/2309.07852v1"},"cats":{"new-dataset":0.1327802161,"dev-research":0.3446712097,"data-quality":0.2723195648}}
{"text":"Specifically, we first collect expert-curated questions from 484 participants across 32 fields of study, and then ask the same experts to evaluate generated responses to their own questions.","meta":{"url":"http://arxiv.org/abs/2309.07852v1"},"cats":{"new-dataset":0.3309930577,"dev-research":0.2716724544,"data-quality":0.0964274764}}
{"text":"We also ask experts to revise answers produced by language models, which leads to ExpertQA, a high-quality long-form QA dataset with 2177 questions spanning 32 fields, along with verified answers and attributions for claims in the answers.","meta":{"url":"http://arxiv.org/abs/2309.07852v1"},"cats":{"new-dataset":0.6944414507,"dev-research":0.2398285475,"data-quality":0.132701115}}
{"text":"LiDAR semantic segmentation plays a crucial role in enabling autonomous driving and robots to understand their surroundings accurately and robustly.","meta":{"url":"http://arxiv.org/abs/2309.07849v1"},"cats":{"new-dataset":0.0732603103,"dev-research":0.1883675501,"data-quality":0.1683076631}}
{"text":"There are different types of methods, such as point-based, range image-based, and polar-based.","meta":{"url":"http://arxiv.org/abs/2309.07849v1"},"cats":{"new-dataset":0.0092275229,"dev-research":0.1702511219,"data-quality":0.0603988497}}
{"text":"Among these, range image-based methods are widely used due to their balance between accuracy and speed.","meta":{"url":"http://arxiv.org/abs/2309.07849v1"},"cats":{"new-dataset":0.0111643403,"dev-research":0.1804988067,"data-quality":0.0800390711}}
{"text":"However, they face a significant challenge known as the ``many-to-one'' problem caused by the range image's limited horizontal and vertical angular resolution, where around 20% of the 3D points are occluded during model inference based on our observation.","meta":{"url":"http://arxiv.org/abs/2309.07849v1"},"cats":{"new-dataset":0.1108194382,"dev-research":0.112231893,"data-quality":0.0936879442}}
{"text":"In this paper, we present TFNet, a range image-based LiDAR semantic segmentation method that utilizes temporal information to address this issue.","meta":{"url":"http://arxiv.org/abs/2309.07849v1"},"cats":{"new-dataset":0.2243625678,"dev-research":0.1528579973,"data-quality":0.1273550892}}
{"text":"Specifically, we incorporate a temporal fusion layer to extract useful information from previous scans and integrate it with the current scan.","meta":{"url":"http://arxiv.org/abs/2309.07849v1"},"cats":{"new-dataset":0.1643017918,"dev-research":0.2212747962,"data-quality":0.0948522609}}
{"text":"We then design a max-voting-based post-processing technique to correct false predictions, particularly those caused by the ``many-to-one'' issue.","meta":{"url":"http://arxiv.org/abs/2309.07849v1"},"cats":{"new-dataset":0.0808326807,"dev-research":0.2502508362,"data-quality":0.3101134245}}
{"text":"Experiments on two benchmarks and seven backbones of three modalities demonstrate the effectiveness and scalability of our proposed method.","meta":{"url":"http://arxiv.org/abs/2309.07849v1"},"cats":{"new-dataset":0.0061977665,"dev-research":0.1223673307,"data-quality":0.103941278}}
{"text":"Neural Radiance Fields (NeRF) employ multi-view images for 3D scene representation and have shown remarkable performance.","meta":{"url":"http://arxiv.org/abs/2309.07846v1"},"cats":{"new-dataset":0.2545002951,"dev-research":0.1772533224,"data-quality":0.1117932612}}
{"text":"As one of the primary sources of multi-view images, multi-camera systems encounter challenges such as varying intrinsic parameters and frequent pose changes.","meta":{"url":"http://arxiv.org/abs/2309.07846v1"},"cats":{"new-dataset":0.0852728585,"dev-research":0.1533127658,"data-quality":0.0872368909}}
{"text":"Most previous NeRF-based methods often assume a global unique camera and seldom consider scenarios with multiple cameras.","meta":{"url":"http://arxiv.org/abs/2309.07846v1"},"cats":{"new-dataset":0.0169075281,"dev-research":0.2376569353,"data-quality":0.2104256418}}
{"text":"Besides, some pose-robust methods still remain susceptible to suboptimal solutions when poses are poor initialized.","meta":{"url":"http://arxiv.org/abs/2309.07846v1"},"cats":{"new-dataset":0.0112097807,"dev-research":0.1760383247,"data-quality":0.1172643187}}
{"text":"In this paper, we propose MC-NeRF, a method can jointly optimize both intrinsic and extrinsic parameters for bundle-adjusting Neural Radiance Fields.","meta":{"url":"http://arxiv.org/abs/2309.07846v1"},"cats":{"new-dataset":0.0355600529,"dev-research":0.1645601784,"data-quality":0.1032397484}}
{"text":"Firstly, we conduct a theoretical analysis to tackle the degenerate case and coupling issue that arise from the joint optimization between intrinsic and extrinsic parameters.","meta":{"url":"http://arxiv.org/abs/2309.07846v1"},"cats":{"new-dataset":0.0033305704,"dev-research":0.1064419952,"data-quality":0.0589022793}}
{"text":"Secondly, based on the proposed solutions, we introduce an efficient calibration image acquisition scheme for multi-camera systems, including the design of calibration object.","meta":{"url":"http://arxiv.org/abs/2309.07846v1"},"cats":{"new-dataset":0.1932267957,"dev-research":0.1455731617,"data-quality":0.1576728876}}
{"text":"Lastly, we present a global end-to-end network with training sequence that enables the regression of intrinsic and extrinsic parameters, along with the rendering network.","meta":{"url":"http://arxiv.org/abs/2309.07846v1"},"cats":{"new-dataset":0.1805212484,"dev-research":0.1486493074,"data-quality":0.0843548158}}
{"text":"Moreover, most existing datasets are designed for unique camera, we create a new dataset that includes four different styles of multi-camera acquisition systems, allowing readers to generate custom datasets.","meta":{"url":"http://arxiv.org/abs/2309.07846v1"},"cats":{"new-dataset":0.9517025786,"dev-research":0.1599279758,"data-quality":0.1343927121}}
{"text":"Experiments confirm the effectiveness of our method when each image corresponds to different camera parameters.","meta":{"url":"http://arxiv.org/abs/2309.07846v1"},"cats":{"new-dataset":0.0291146387,"dev-research":0.1413270877,"data-quality":0.1565109521}}
{"text":"Specifically, we adopt up to 110 images with 110 different intrinsic and extrinsic parameters, to achieve 3D scene representation without providing initial poses.","meta":{"url":"http://arxiv.org/abs/2309.07846v1"},"cats":{"new-dataset":0.2878137942,"dev-research":0.1218161697,"data-quality":0.0624850985}}
{"text":"The Code and supplementary materials are available at https://in2-viaun.github.io/MC-NeRF.","meta":{"url":"http://arxiv.org/abs/2309.07846v1"},"cats":{"new-dataset":0.1873411161,"dev-research":0.1758585134,"data-quality":0.1733341913}}
{"text":"Due to the modern relevance of blockchain technology, smart contracts present both substantial risks and benefits.","meta":{"url":"http://arxiv.org/abs/2309.07841v1"},"cats":{"new-dataset":0.0236010182,"dev-research":0.2615381426,"data-quality":0.099907886}}
{"text":"Vulnerabilities within them can trigger a cascade of consequences, resulting in significant losses.","meta":{"url":"http://arxiv.org/abs/2309.07841v1"},"cats":{"new-dataset":0.0117905377,"dev-research":0.337515717,"data-quality":0.2020544677}}
{"text":"Many current papers primarily focus on classifying smart contracts for malicious intent, often relying on limited contract characteristics, such as bytecode or opcode.","meta":{"url":"http://arxiv.org/abs/2309.07841v1"},"cats":{"new-dataset":0.0421310604,"dev-research":0.2619090091,"data-quality":0.179050489}}
{"text":"This paper proposes a novel, two-layered framework: 1) classifying and 2) directly repairing malicious contracts.","meta":{"url":"http://arxiv.org/abs/2309.07841v1"},"cats":{"new-dataset":0.1670582448,"dev-research":0.3406286428,"data-quality":0.3816184316}}
{"text":"Slither's vulnerability report is combined with source code and passed through a pre-trained RandomForestClassifier (RFC) and Large Language Models (LLMs), classifying and repairing each suggested vulnerability.","meta":{"url":"http://arxiv.org/abs/2309.07841v1"},"cats":{"new-dataset":0.2974407069,"dev-research":0.2965763093,"data-quality":0.3019815218}}
{"text":"Experiments demonstrate the effectiveness of fine-tuned and prompt-engineered LLMs.","meta":{"url":"http://arxiv.org/abs/2309.07841v1"},"cats":{"new-dataset":0.0078403507,"dev-research":0.1301823945,"data-quality":0.1096447985}}
{"text":"The smart contract repair models, built from pre-trained GPT-3.5-Turbo and fine-tuned Llama-2-7B models, reduced the overall vulnerability count by 97.5% and 96.7% respectively.","meta":{"url":"http://arxiv.org/abs/2309.07841v1"},"cats":{"new-dataset":0.0751495654,"dev-research":0.1969121127,"data-quality":0.2191198286}}
{"text":"A manual inspection of repaired contracts shows that all retain functionality, indicating that the proposed method is appropriate for automatic batch classification and repair of vulnerabilities in smart contracts.","meta":{"url":"http://arxiv.org/abs/2309.07841v1"},"cats":{"new-dataset":0.1269593671,"dev-research":0.3829516784,"data-quality":0.5201846643}}
{"text":"We present VAPOR, a novel method for autonomous legged robot navigation in unstructured, densely vegetated outdoor environments using Offline Reinforcement Learning (RL).","meta":{"url":"http://arxiv.org/abs/2309.07832v1"},"cats":{"new-dataset":0.1024046125,"dev-research":0.1384754255,"data-quality":0.0517603885}}
{"text":"Our method trains a novel RL policy from unlabeled data collected in real outdoor vegetation.","meta":{"url":"http://arxiv.org/abs/2309.07832v1"},"cats":{"new-dataset":0.1939690813,"dev-research":0.1548643626,"data-quality":0.142758757}}
{"text":"This policy uses height and intensity-based cost maps derived from 3D LiDAR point clouds, a goal cost map, and processed proprioception data as state inputs, and learns the physical and geometric properties of the surrounding vegetation such as height, density, and solidity/stiffness for navigation.","meta":{"url":"http://arxiv.org/abs/2309.07832v1"},"cats":{"new-dataset":0.1452977355,"dev-research":0.1862214568,"data-quality":0.0481073729}}
{"text":"Instead of using end-to-end policy actions, the fully-trained RL policy's Q network is used to evaluate dynamically feasible robot actions generated from a novel adaptive planner capable of navigating through dense narrow passages and preventing entrapment in vegetation such as tall grass and bushes.","meta":{"url":"http://arxiv.org/abs/2309.07832v1"},"cats":{"new-dataset":0.1210603199,"dev-research":0.2022616372,"data-quality":0.0362352058}}
{"text":"We demonstrate our method's capabilities on a legged robot in complex outdoor vegetation.","meta":{"url":"http://arxiv.org/abs/2309.07832v1"},"cats":{"new-dataset":0.0533188783,"dev-research":0.1879965583,"data-quality":0.0501116239}}
{"text":"We observe an improvement in success rates, a decrease in average power consumption, and decrease in normalized trajectory length compared to both existing end-to-end offline RL and outdoor navigation methods.","meta":{"url":"http://arxiv.org/abs/2309.07832v1"},"cats":{"new-dataset":0.0324695931,"dev-research":0.1567724118,"data-quality":0.0527057259}}
{"text":"Automatic road extraction from satellite imagery using deep learning is a viable alternative to traditional manual mapping.","meta":{"url":"http://arxiv.org/abs/2309.07823v1"},"cats":{"new-dataset":0.161734072,"dev-research":0.1684611247,"data-quality":0.1285132801}}
{"text":"Therefore it has received considerable attention recently.","meta":{"url":"http://arxiv.org/abs/2309.07823v1"},"cats":{"new-dataset":0.0453082234,"dev-research":0.2790893432,"data-quality":0.1134518593}}
{"text":"However, most of the existing methods are supervised and require pixel-level labeling, which is tedious and error-prone.","meta":{"url":"http://arxiv.org/abs/2309.07823v1"},"cats":{"new-dataset":0.0450410712,"dev-research":0.2562181386,"data-quality":0.431109842}}
{"text":"To make matters worse, the earth has a diverse range of terrain, vegetation, and man-made objects.","meta":{"url":"http://arxiv.org/abs/2309.07823v1"},"cats":{"new-dataset":0.0835555745,"dev-research":0.2352992596,"data-quality":0.080856276}}
{"text":"It is well known that models trained in one area generalize poorly to other areas.","meta":{"url":"http://arxiv.org/abs/2309.07823v1"},"cats":{"new-dataset":0.0072525546,"dev-research":0.2026059723,"data-quality":0.2582691304}}
{"text":"Various shooting conditions such as light and angel, as well as different image processing techniques further complicate the issue.","meta":{"url":"http://arxiv.org/abs/2309.07823v1"},"cats":{"new-dataset":0.0161166133,"dev-research":0.1883833425,"data-quality":0.0944989141}}
{"text":"It is impractical to develop training data to cover all image styles.","meta":{"url":"http://arxiv.org/abs/2309.07823v1"},"cats":{"new-dataset":0.0592626234,"dev-research":0.1783554306,"data-quality":0.1768900491}}
{"text":"This paper proposes to leverage OpenStreetMap road data as weak labels and large scale satellite imagery to pre-train semantic segmentation models.","meta":{"url":"http://arxiv.org/abs/2309.07823v1"},"cats":{"new-dataset":0.3746232798,"dev-research":0.1387739745,"data-quality":0.2309940267}}
{"text":"Our extensive experimental results show that the prediction accuracy increases with the amount of the weakly labeled data, as well as the road density in the areas chosen for training.","meta":{"url":"http://arxiv.org/abs/2309.07823v1"},"cats":{"new-dataset":0.1338387679,"dev-research":0.1452051409,"data-quality":0.4161734441}}
{"text":"Using as much as 100 times more data than the widely used DeepGlobe road dataset, our model with the D-LinkNet architecture and the ResNet-50 backbone exceeds the top performer of the current DeepGlobe leaderboard.","meta":{"url":"http://arxiv.org/abs/2309.07823v1"},"cats":{"new-dataset":0.409790489,"dev-research":0.117834446,"data-quality":0.0771483583}}
{"text":"Furthermore, due to large-scale pre-training, our model generalizes much better than those trained with only the curated datasets, implying great application potential.","meta":{"url":"http://arxiv.org/abs/2309.07823v1"},"cats":{"new-dataset":0.1826152091,"dev-research":0.1611187022,"data-quality":0.1121895837}}
{"text":"In recent years, large language models (LLMs) have shown remarkable capabilities at scale, particularly at generating text conditioned on a prompt.","meta":{"url":"http://arxiv.org/abs/2309.07822v1"},"cats":{"new-dataset":0.083387993,"dev-research":0.1228477978,"data-quality":0.1493529894}}
{"text":"In our work, we investigate the use of LLMs to augment training data of small language models~(SLMs) with automatically generated counterfactual~(CF) instances -- i.e. minimally altered inputs -- in order to improve out-of-domain~(OOD) performance of SLMs in the extractive question answering~(QA) setup.","meta":{"url":"http://arxiv.org/abs/2309.07822v1"},"cats":{"new-dataset":0.1881904884,"dev-research":0.1564097534,"data-quality":0.3024372054}}
{"text":"We show that, across various LLM generators, such data augmentation consistently enhances OOD performance and improves model calibration for both confidence-based and rationale-augmented calibrator models.","meta":{"url":"http://arxiv.org/abs/2309.07822v1"},"cats":{"new-dataset":0.0272017299,"dev-research":0.1189867566,"data-quality":0.1801500677}}
{"text":"Furthermore, these performance improvements correlate with higher diversity of CF instances in terms of their surface form and semantic content.","meta":{"url":"http://arxiv.org/abs/2309.07822v1"},"cats":{"new-dataset":0.044078883,"dev-research":0.1832798098,"data-quality":0.1477908018}}
{"text":"Finally, we show that CF augmented models which are easier to calibrate also exhibit much lower entropy when assigning importance, indicating that rationale-augmented calibrators prefer concise explanations.","meta":{"url":"http://arxiv.org/abs/2309.07822v1"},"cats":{"new-dataset":0.0072379377,"dev-research":0.1318593374,"data-quality":0.1193048865}}
{"text":"One of the main issues in computing a tensor decomposition is how to choose the number of rank-one components, since there is no finite algorithms for determining the rank of a tensor.","meta":{"url":"http://arxiv.org/abs/2309.07819v1"},"cats":{"new-dataset":0.0305282587,"dev-research":0.1656869369,"data-quality":0.0752588384}}
{"text":"A commonly used approach for this purpose is to find a low-dimensional subspace by solving an optimization problem and assuming the number of components is fixed.","meta":{"url":"http://arxiv.org/abs/2309.07819v1"},"cats":{"new-dataset":0.0361692373,"dev-research":0.1856190327,"data-quality":0.1184697477}}
{"text":"However, even though this algorithm is efficient and easy to implement, it often converges to poor local minima and suffers from outliers and noise.","meta":{"url":"http://arxiv.org/abs/2309.07819v1"},"cats":{"new-dataset":0.0110405167,"dev-research":0.1626565563,"data-quality":0.2386548277}}
{"text":"The aim of this paper is to develop a mathematical framework for exact tensor decomposition that is able to represent a tensor as the sum of a finite number of low-rank tensors.","meta":{"url":"http://arxiv.org/abs/2309.07819v1"},"cats":{"new-dataset":0.0598364415,"dev-research":0.1524058356,"data-quality":0.1029402993}}
{"text":"In the paper three different problems will be carried out to derive: i) the decomposition of a non-negative self-adjoint tensor operator; ii) the decomposition of a linear tensor transformation; iii) the decomposition of a generic tensor.","meta":{"url":"http://arxiv.org/abs/2309.07819v1"},"cats":{"new-dataset":0.0368776562,"dev-research":0.1689606228,"data-quality":0.1730872661}}
{"text":"Directed graphs are a natural model for many phenomena, in particular scientific knowledge graphs such as molecular interaction or chemical reaction networks that define cellular signaling relationships.","meta":{"url":"http://arxiv.org/abs/2309.07813v1"},"cats":{"new-dataset":0.0492464352,"dev-research":0.2702390609,"data-quality":0.093647115}}
{"text":"In these situations, source nodes typically have distinct biophysical properties from sinks.","meta":{"url":"http://arxiv.org/abs/2309.07813v1"},"cats":{"new-dataset":0.0148973701,"dev-research":0.1722594872,"data-quality":0.1084992811}}
{"text":"Due to their ordered and unidirectional relationships, many such networks also have hierarchical and multiscale structure.","meta":{"url":"http://arxiv.org/abs/2309.07813v1"},"cats":{"new-dataset":0.0347240487,"dev-research":0.1269522681,"data-quality":0.0636096216}}
{"text":"However, the majority of methods performing node- and edge-level tasks in machine learning do not take these properties into account, and thus have not been leveraged effectively for scientific tasks such as cellular signaling network inference.","meta":{"url":"http://arxiv.org/abs/2309.07813v1"},"cats":{"new-dataset":0.0030046866,"dev-research":0.1576489539,"data-quality":0.1587013661}}
{"text":"We propose a new framework called Directed Scattering Autoencoder (DSAE) which uses a directed version of a geometric scattering transform, combined with the non-linear dimensionality reduction properties of an autoencoder and the geometric properties of the hyperbolic space to learn latent hierarchies.","meta":{"url":"http://arxiv.org/abs/2309.07813v1"},"cats":{"new-dataset":0.0498078402,"dev-research":0.1579422225,"data-quality":0.1035085881}}
{"text":"We show this method outperforms numerous others on tasks such as embedding directed graphs and learning cellular signaling networks.","meta":{"url":"http://arxiv.org/abs/2309.07813v1"},"cats":{"new-dataset":0.0374727993,"dev-research":0.1590249776,"data-quality":0.1470672635}}
{"text":"Automatic identification of clinical trials for which a patient is eligible is complicated by the fact that trial eligibility is stated in natural language.","meta":{"url":"http://arxiv.org/abs/2309.07812v1"},"cats":{"new-dataset":0.0388014538,"dev-research":0.2751687994,"data-quality":0.2810818943}}
{"text":"A potential solution to this problem is to employ text classification methods for common types of eligibility criteria.","meta":{"url":"http://arxiv.org/abs/2309.07812v1"},"cats":{"new-dataset":0.0153704612,"dev-research":0.1682556267,"data-quality":0.2047226286}}
{"text":"In this study, we focus on seven common exclusion criteria in cancer trials: prior malignancy, human immunodeficiency virus, hepatitis B, hepatitis C, psychiatric illness, drug/substance abuse, and autoimmune illness.","meta":{"url":"http://arxiv.org/abs/2309.07812v1"},"cats":{"new-dataset":0.0664887998,"dev-research":0.2137138932,"data-quality":0.1187609862}}
{"text":"Our dataset consists of 764 phase III cancer trials with these exclusions annotated at the trial level.","meta":{"url":"http://arxiv.org/abs/2309.07812v1"},"cats":{"new-dataset":0.8265153301,"dev-research":0.173270523,"data-quality":0.1821466412}}
{"text":"We experiment with common transformer models as well as a new pre-trained clinical trial BERT model.","meta":{"url":"http://arxiv.org/abs/2309.07812v1"},"cats":{"new-dataset":0.0333218959,"dev-research":0.1636582881,"data-quality":0.0734846892}}
{"text":"Our results demonstrate the feasibility of automatically classifying common exclusion criteria.","meta":{"url":"http://arxiv.org/abs/2309.07812v1"},"cats":{"new-dataset":0.0481507426,"dev-research":0.2353982579,"data-quality":0.3101308225}}
{"text":"Additionally, we demonstrate the value of a pre-trained language model specifically for clinical trials, which yields the highest average performance across all criteria.","meta":{"url":"http://arxiv.org/abs/2309.07812v1"},"cats":{"new-dataset":0.1036513339,"dev-research":0.2383712432,"data-quality":0.1796569577}}
{"text":"The task of preserving privacy while ensuring efficient communication is a fundamental challenge in federated learning.","meta":{"url":"http://arxiv.org/abs/2309.07809v1"},"cats":{"new-dataset":0.0553256508,"dev-research":0.1292736493,"data-quality":0.1210386925}}
{"text":"In this work, we tackle this challenge in the trusted aggregator model, and propose a solution that achieves both objectives simultaneously.","meta":{"url":"http://arxiv.org/abs/2309.07809v1"},"cats":{"new-dataset":0.0688426103,"dev-research":0.1327314813,"data-quality":0.189622501}}
{"text":"We show that employing a quantization scheme based on subtractive dithering at the clients can effectively replicate the normal noise addition process at the aggregator.","meta":{"url":"http://arxiv.org/abs/2309.07809v1"},"cats":{"new-dataset":0.019973992,"dev-research":0.1553050373,"data-quality":0.2341263658}}
{"text":"This implies that we can guarantee the same level of differential privacy against other clients while substantially reducing the amount of communication required, as opposed to transmitting full precision gradients and using central noise addition.","meta":{"url":"http://arxiv.org/abs/2309.07809v1"},"cats":{"new-dataset":0.0080641499,"dev-research":0.1445956155,"data-quality":0.1122411923}}
{"text":"We also experimentally demonstrate that the accuracy of our proposed approach matches that of the full precision gradient method.","meta":{"url":"http://arxiv.org/abs/2309.07809v1"},"cats":{"new-dataset":0.0074600994,"dev-research":0.1157333005,"data-quality":0.25862243}}
{"text":"More research attention has recently been given to end-to-end autonomous driving technologies where the entire driving pipeline is replaced with a single neural network because of its simpler structure and faster inference time.","meta":{"url":"http://arxiv.org/abs/2309.07808v1"},"cats":{"new-dataset":0.0504212165,"dev-research":0.1710298525,"data-quality":0.0828840234}}
{"text":"Despite this appealing approach largely reducing the components in driving pipeline, its simplicity also leads to interpretability problems and safety issues arXiv:2003.06404.","meta":{"url":"http://arxiv.org/abs/2309.07808v1"},"cats":{"new-dataset":0.0103394218,"dev-research":0.3841302544,"data-quality":0.2355881958}}
{"text":"The trained policy is not always compliant with the traffic rules and it is also hard to discover the reason for the misbehavior because of the lack of intermediate outputs.","meta":{"url":"http://arxiv.org/abs/2309.07808v1"},"cats":{"new-dataset":0.0128142087,"dev-research":0.1889473932,"data-quality":0.1977827074}}
{"text":"Meanwhile, Sensors are also critical to autonomous driving's security and feasibility to perceive the surrounding environment under complex driving scenarios.","meta":{"url":"http://arxiv.org/abs/2309.07808v1"},"cats":{"new-dataset":0.0430488954,"dev-research":0.2689763148,"data-quality":0.0786239608}}
{"text":"In this paper, we proposed P-CSG, a novel penalty-based imitation learning approach with cross semantics generation sensor fusion technologies to increase the overall performance of End-to-End Autonomous Driving.","meta":{"url":"http://arxiv.org/abs/2309.07808v1"},"cats":{"new-dataset":0.1176836155,"dev-research":0.1798588889,"data-quality":0.1268375025}}
{"text":"We conducted an assessment of our model's performance using the Town 05 Long benchmark, achieving an impressive driving score improvement of over 15%.","meta":{"url":"http://arxiv.org/abs/2309.07808v1"},"cats":{"new-dataset":0.1344427912,"dev-research":0.2547178547,"data-quality":0.0970615791}}
{"text":"Furthermore, we conducted robustness evaluations against adversarial attacks like FGSM and Dot attacks, revealing a substantial increase in robustness compared to baseline models.","meta":{"url":"http://arxiv.org/abs/2309.07808v1"},"cats":{"new-dataset":0.0150975918,"dev-research":0.2097365652,"data-quality":0.3340121614}}
{"text":"More detailed information, such as code-based resources, ablation studies and videos can be found at https://hk-zh.github.io/p-csg-plus.","meta":{"url":"http://arxiv.org/abs/2309.07808v1"},"cats":{"new-dataset":0.3619175614,"dev-research":0.2039073547,"data-quality":0.1107596236}}
{"text":"Since the seminal work by Angluin, active learning of automata, by membership and equivalence queries, has been extensively studied and several generalisations have been developed to learn various extensions of automata.","meta":{"url":"http://arxiv.org/abs/2309.07806v1"},"cats":{"new-dataset":0.0932710892,"dev-research":0.1796268871,"data-quality":0.1182268862}}
{"text":"For weighted automata, restricted cases have been tackled in the literature and in this paper we chart the boundaries of the Angluin approach (using a class of hypothesis automata constructed from membership and equivalence queries) applied to learning weighted automata over a general semiring.","meta":{"url":"http://arxiv.org/abs/2309.07806v1"},"cats":{"new-dataset":0.0473446886,"dev-research":0.1365327256,"data-quality":0.1483211443}}
{"text":"We show precisely the theoretical limitations of this approach and classify functions with respect to how guessable they are (corresponding to the existence and abundance of solutions of certain systems of equations).","meta":{"url":"http://arxiv.org/abs/2309.07806v1"},"cats":{"new-dataset":0.0227941644,"dev-research":0.1214192705,"data-quality":0.146755492}}
{"text":"We provide a syntactic description of the boundary condition for a correct hypothesis of the prescribed form to exist.","meta":{"url":"http://arxiv.org/abs/2309.07806v1"},"cats":{"new-dataset":0.0394339605,"dev-research":0.179593869,"data-quality":0.211486528}}
{"text":"Of course, from an algorithmic standpoint, knowing that (many) solutions exist need not translate into an effective algorithm to find one; we conclude with a discussion of some known conditions (and variants thereof) that suffice to ensure this, illustrating the ideas over several familiar semirings (including the natural numbers) and pose some open questions for future research.","meta":{"url":"http://arxiv.org/abs/2309.07806v1"},"cats":{"new-dataset":0.0512612984,"dev-research":0.1450592669,"data-quality":0.1358934255}}
{"text":"Recent breakthroughs in pre-trained code models, such as CodeBERT and Codex, have shown their superior performance in various downstream tasks.","meta":{"url":"http://arxiv.org/abs/2309.07804v1"},"cats":{"new-dataset":0.0369990854,"dev-research":0.331415807,"data-quality":0.1259028225}}
{"text":"The correctness and unambiguity of API usage among these code models are crucial for achieving desirable program functionalities, requiring them to learn various API fully qualified names structurally and semantically.","meta":{"url":"http://arxiv.org/abs/2309.07804v1"},"cats":{"new-dataset":0.016341105,"dev-research":0.3964978932,"data-quality":0.2308325304}}
{"text":"Recent studies reveal that even state-of-the-art pre-trained code models struggle with suggesting the correct APIs during code generation.","meta":{"url":"http://arxiv.org/abs/2309.07804v1"},"cats":{"new-dataset":0.039907087,"dev-research":0.4230244391,"data-quality":0.2024203293}}
{"text":"However, the reasons for such poor API usage performance are barely investigated.","meta":{"url":"http://arxiv.org/abs/2309.07804v1"},"cats":{"new-dataset":0.004934859,"dev-research":0.2434358376,"data-quality":0.1942002632}}
{"text":"To address this challenge, we propose using knowledge probing as a means of interpreting code models, which uses cloze-style tests to measure the knowledge stored in models.","meta":{"url":"http://arxiv.org/abs/2309.07804v1"},"cats":{"new-dataset":0.1550609331,"dev-research":0.4177797666,"data-quality":0.1730104653}}
{"text":"Our comprehensive study examines a code model's capability of understanding API fully qualified names from two different perspectives: API call and API import.","meta":{"url":"http://arxiv.org/abs/2309.07804v1"},"cats":{"new-dataset":0.0358419973,"dev-research":0.3812994975,"data-quality":0.2328169128}}
{"text":"Specifically, we reveal that current code models struggle with understanding API names, with pre-training strategies significantly affecting the quality of API name learning.","meta":{"url":"http://arxiv.org/abs/2309.07804v1"},"cats":{"new-dataset":0.0364775479,"dev-research":0.3481371676,"data-quality":0.3721210593}}
{"text":"We demonstrate that natural language context can assist code models in locating Python API names and generalize Python API name knowledge to unseen data.","meta":{"url":"http://arxiv.org/abs/2309.07804v1"},"cats":{"new-dataset":0.2650644254,"dev-research":0.3448157865,"data-quality":0.2855996063}}
{"text":"Our findings provide insights into the limitations and capabilities of current pre-trained code models, and suggest that incorporating API structure into the pre-training process can improve automated API usage and code representations.","meta":{"url":"http://arxiv.org/abs/2309.07804v1"},"cats":{"new-dataset":0.0566558518,"dev-research":0.3883970441,"data-quality":0.1456250697}}
{"text":"This work provides significance for advancing code intelligence practices and direction for future studies.","meta":{"url":"http://arxiv.org/abs/2309.07804v1"},"cats":{"new-dataset":0.0831588205,"dev-research":0.5722786474,"data-quality":0.1500997732}}
{"text":"All experiment results, data and source code used in this work are available at \\url{https://doi.org/10.5281/zenodo.7902072}.","meta":{"url":"http://arxiv.org/abs/2309.07804v1"},"cats":{"new-dataset":0.0938562981,"dev-research":0.0727568091,"data-quality":0.1145596631}}
{"text":"When considering the opening part of 1800 short stories, we find that the first dozen paragraphs of the average narrative follow an action principle as defined in arXiv:2309.06600.","meta":{"url":"http://arxiv.org/abs/2309.07797v1"},"cats":{"new-dataset":0.086875593,"dev-research":0.1707390052,"data-quality":0.0847286252}}
{"text":"When the order of the paragraphs is shuffled, the average no longer exhibits this property.","meta":{"url":"http://arxiv.org/abs/2309.07797v1"},"cats":{"new-dataset":0.0240533616,"dev-research":0.1366732756,"data-quality":0.1580739875}}
{"text":"The findings show that there is a preferential direction we take in semantic space when starting a story, possibly related to a common Western storytelling tradition as implied by Aristotle in Poetics.","meta":{"url":"http://arxiv.org/abs/2309.07797v1"},"cats":{"new-dataset":0.0583438344,"dev-research":0.2312391439,"data-quality":0.189208955}}
{"text":"Previous evaluations on 6DoF object pose tracking have presented obvious limitations along with the development of this area.","meta":{"url":"http://arxiv.org/abs/2309.07796v1"},"cats":{"new-dataset":0.1725723094,"dev-research":0.1919133408,"data-quality":0.1307669747}}
{"text":"In particular, the evaluation protocols are not unified for different methods, the widely-used YCBV dataset contains significant annotation error, and the error metrics also may be biased.","meta":{"url":"http://arxiv.org/abs/2309.07796v1"},"cats":{"new-dataset":0.0423543163,"dev-research":0.284880237,"data-quality":0.4119155111}}
{"text":"As a result, it is hard to fairly compare the methods, which has became a big obstacle for developing new algorithms.","meta":{"url":"http://arxiv.org/abs/2309.07796v1"},"cats":{"new-dataset":0.0050810035,"dev-research":0.2045134477,"data-quality":0.1105790765}}
{"text":"In this paper we contribute a unified benchmark to address the above problems.","meta":{"url":"http://arxiv.org/abs/2309.07796v1"},"cats":{"new-dataset":0.0618826428,"dev-research":0.094746048,"data-quality":0.1788454358}}
{"text":"For more accurate annotation of YCBV, we propose a multi-view multi-object global pose refinement method, which can jointly refine the poses of all objects and view cameras, resulting in sub-pixel sub-millimeter alignment errors.","meta":{"url":"http://arxiv.org/abs/2309.07796v1"},"cats":{"new-dataset":0.406963833,"dev-research":0.2336845477,"data-quality":0.2145389704}}
{"text":"The limitations of previous scoring methods and error metrics are analyzed, based on which we introduce our improved evaluation methods.","meta":{"url":"http://arxiv.org/abs/2309.07796v1"},"cats":{"new-dataset":0.0173755414,"dev-research":0.291298399,"data-quality":0.2599010536}}
{"text":"The unified benchmark takes both YCBV and BCOT as base datasets, which are shown to be complementary in scene categories.","meta":{"url":"http://arxiv.org/abs/2309.07796v1"},"cats":{"new-dataset":0.45793037,"dev-research":0.1284824354,"data-quality":0.1566694976}}
{"text":"In experiments, we validate the precision and reliability of the proposed global pose refinement method with a realistic semi-synthesized dataset particularly for YCBV, and then present the benchmark results unifying learning&non-learning and RGB&RGBD methods, with some finds not discovered in previous studies.","meta":{"url":"http://arxiv.org/abs/2309.07796v1"},"cats":{"new-dataset":0.2759949626,"dev-research":0.1947059049,"data-quality":0.1268062713}}
{"text":"Effectively leveraging multimodal information from social media posts is essential to various downstream tasks such as sentiment analysis, sarcasm detection and hate speech classification.","meta":{"url":"http://arxiv.org/abs/2309.07794v1"},"cats":{"new-dataset":0.1121882037,"dev-research":0.2469464516,"data-quality":0.2102432363}}
{"text":"However, combining text and image information is challenging because of the idiosyncratic cross-modal semantics with hidden or complementary information present in matching image-text pairs.","meta":{"url":"http://arxiv.org/abs/2309.07794v1"},"cats":{"new-dataset":0.0570455617,"dev-research":0.1497710511,"data-quality":0.2639595662}}
{"text":"In this work, we aim to directly model this by proposing the use of two auxiliary losses jointly with the main task when fine-tuning any pre-trained multimodal model.","meta":{"url":"http://arxiv.org/abs/2309.07794v1"},"cats":{"new-dataset":0.0899628589,"dev-research":0.1393974122,"data-quality":0.1447761728}}
{"text":"Image-Text Contrastive (ITC) brings image-text representations of a post closer together and separates them from different posts, capturing underlying dependencies.","meta":{"url":"http://arxiv.org/abs/2309.07794v1"},"cats":{"new-dataset":0.119545414,"dev-research":0.2040230561,"data-quality":0.2163347362}}
{"text":"Image-Text Matching (ITM) facilitates the understanding of semantic correspondence between images and text by penalizing unrelated pairs.","meta":{"url":"http://arxiv.org/abs/2309.07794v1"},"cats":{"new-dataset":0.0430880335,"dev-research":0.1485195718,"data-quality":0.3255196712}}
{"text":"We combine these objectives with five multimodal models, demonstrating consistent improvements across four popular social media datasets.","meta":{"url":"http://arxiv.org/abs/2309.07794v1"},"cats":{"new-dataset":0.5111221519,"dev-research":0.1936137207,"data-quality":0.1751798502}}
{"text":"Furthermore, through detailed analysis, we shed light on the specific scenarios and cases where each auxiliary task proves to be most effective.","meta":{"url":"http://arxiv.org/abs/2309.07794v1"},"cats":{"new-dataset":0.0052475103,"dev-research":0.2818511952,"data-quality":0.1154260867}}
{"text":"Artificial neural networks (ANNs), inspired by the interconnection of real neurons, have achieved unprecedented success in various fields such as computer vision and natural language processing.","meta":{"url":"http://arxiv.org/abs/2309.07791v1"},"cats":{"new-dataset":0.0680455497,"dev-research":0.1750966456,"data-quality":0.1920458697}}
{"text":"Recently, a novel mathematical ANN model, known as the dendritic neuron model (DNM), has been proposed to address nonlinear problems by more accurately reflecting the structure of real neurons.","meta":{"url":"http://arxiv.org/abs/2309.07791v1"},"cats":{"new-dataset":0.0197762756,"dev-research":0.1525445663,"data-quality":0.1315574807}}
{"text":"However, the single-output design limits its capability to handle multi-output tasks, significantly lowering its applications.","meta":{"url":"http://arxiv.org/abs/2309.07791v1"},"cats":{"new-dataset":0.0036804661,"dev-research":0.2298415994,"data-quality":0.054173821}}
{"text":"In this paper, we propose a novel multi-in and multi-out dendritic neuron model (MODN) to tackle multi-output tasks.","meta":{"url":"http://arxiv.org/abs/2309.07791v1"},"cats":{"new-dataset":0.0271739653,"dev-research":0.1532157257,"data-quality":0.0749293267}}
{"text":"Our core idea is to introduce a filtering matrix to the soma layer to adaptively select the desired dendrites to regress each output.","meta":{"url":"http://arxiv.org/abs/2309.07791v1"},"cats":{"new-dataset":0.0601145454,"dev-research":0.1389160822,"data-quality":0.0983557097}}
{"text":"Because such a matrix is designed to be learnable, MODN can explore the relationship between each dendrite and output to provide a better solution to downstream tasks.","meta":{"url":"http://arxiv.org/abs/2309.07791v1"},"cats":{"new-dataset":0.0262861562,"dev-research":0.162926034,"data-quality":0.0661004453}}
{"text":"We also model a telodendron layer into MODN to simulate better the real neuron behavior.","meta":{"url":"http://arxiv.org/abs/2309.07791v1"},"cats":{"new-dataset":0.023325522,"dev-research":0.1275571913,"data-quality":0.0639492474}}
{"text":"Importantly, MODN is a more general and unified framework that can be naturally specialized as the DNM by customizing the filtering matrix.","meta":{"url":"http://arxiv.org/abs/2309.07791v1"},"cats":{"new-dataset":0.0216917199,"dev-research":0.162835551,"data-quality":0.0639246604}}
{"text":"To explore the optimization of MODN, we investigate both heuristic and gradient-based optimizers and introduce a 2-step training method for MODN.","meta":{"url":"http://arxiv.org/abs/2309.07791v1"},"cats":{"new-dataset":0.0073307911,"dev-research":0.1725798648,"data-quality":0.0885441188}}
{"text":"Extensive experimental results performed on 11 datasets on both binary and multi-class classification tasks demonstrate the effectiveness of MODN, with respect to accuracy, convergence, and generality.","meta":{"url":"http://arxiv.org/abs/2309.07791v1"},"cats":{"new-dataset":0.087806162,"dev-research":0.1273029499,"data-quality":0.2672133047}}
{"text":"Content Security Policy (CSP) is an effective security mechanism that prevents the exploitation of Cross-Site Scripting (XSS) vulnerabilities on websites by specifying the sources from which their web pages can load resources, such as scripts and styles.","meta":{"url":"http://arxiv.org/abs/2309.07782v1"},"cats":{"new-dataset":0.0506587285,"dev-research":0.2340506242,"data-quality":0.1088338253}}
{"text":"CSP nonces enable websites to allow the execution of specific inline scripts and styles without relying on a whitelist.","meta":{"url":"http://arxiv.org/abs/2309.07782v1"},"cats":{"new-dataset":0.0098834374,"dev-research":0.1792057352,"data-quality":0.1102818927}}
{"text":"In this study, we measure and analyze the use of CSP nonces in the wild, specifically looking for nonce reuse, short nonces, and invalid nonces.","meta":{"url":"http://arxiv.org/abs/2309.07782v1"},"cats":{"new-dataset":0.0211794602,"dev-research":0.2003089692,"data-quality":0.1425910582}}
{"text":"We find that, of the 2271 sites that deploy a nonce-based policy, 598 of them reuse the same nonce value in more than one response, potentially enabling attackers to bypass protection offered by the CSP against XSS attacks.","meta":{"url":"http://arxiv.org/abs/2309.07782v1"},"cats":{"new-dataset":0.0504147576,"dev-research":0.2035656966,"data-quality":0.1370670284}}
{"text":"We analyze the causes of the nonce reuses to identify whether they are introduced by the server-side code or if the nonces are being cached by web caches.","meta":{"url":"http://arxiv.org/abs/2309.07782v1"},"cats":{"new-dataset":0.0124866594,"dev-research":0.2544427511,"data-quality":0.2214985088}}
{"text":"Moreover, we investigate whether nonces are only reused within the same session or for different sessions, as this impacts the effectiveness of CSP in preventing XSS attacks.","meta":{"url":"http://arxiv.org/abs/2309.07782v1"},"cats":{"new-dataset":0.015386162,"dev-research":0.225734376,"data-quality":0.1140239834}}
{"text":"Finally, we discuss the possibilities for attackers to bypass the CSP and achieve XSS in different nonce reuse scenarios.","meta":{"url":"http://arxiv.org/abs/2309.07782v1"},"cats":{"new-dataset":0.0306233517,"dev-research":0.2235471332,"data-quality":0.1386839454}}
{"text":"This paper presents a quantitative program verification infrastructure for discrete probabilistic programs.","meta":{"url":"http://arxiv.org/abs/2309.07781v1"},"cats":{"new-dataset":0.073714439,"dev-research":0.2887294339,"data-quality":0.1222836859}}
{"text":"Our infrastructure can be viewed as the probabilistic analogue of Boogie: its central components are an intermediate verification language (IVL) together with a real-valued logic.","meta":{"url":"http://arxiv.org/abs/2309.07781v1"},"cats":{"new-dataset":0.1435026572,"dev-research":0.2761980797,"data-quality":0.1159746294}}
{"text":"Our IVL provides a programming-language-style for expressing verification conditions whose validity implies the correctness of a program under investigation.","meta":{"url":"http://arxiv.org/abs/2309.07781v1"},"cats":{"new-dataset":0.0900220935,"dev-research":0.4895397034,"data-quality":0.2473520313}}
{"text":"As our focus is on verifying quantitative properties such as bounds on expected outcomes, expected run-times, or termination probabilities, off-the-shelf IVLs based on Boolean first-order logic do not suffice.","meta":{"url":"http://arxiv.org/abs/2309.07781v1"},"cats":{"new-dataset":0.026945766,"dev-research":0.206593706,"data-quality":0.0803248743}}
{"text":"Instead, a paradigm shift from the standard Boolean to a real-valued domain is required.   ","meta":{"url":"http://arxiv.org/abs/2309.07781v1"},"cats":{"new-dataset":0.0068114488,"dev-research":0.2511492376,"data-quality":0.1802155275}}
{"text":"Our IVL features quantitative generalizations of standard verification constructs such as assume- and assert-statements.","meta":{"url":"http://arxiv.org/abs/2309.07781v1"},"cats":{"new-dataset":0.0341856977,"dev-research":0.3138614107,"data-quality":0.2416789488}}
{"text":"Verification conditions are generated by a weakest-precondition-style semantics, based on our real-valued logic.","meta":{"url":"http://arxiv.org/abs/2309.07781v1"},"cats":{"new-dataset":0.0294778045,"dev-research":0.2607955233,"data-quality":0.1848165641}}
{"text":"We show that our verification infrastructure supports natural encodings of numerous verification techniques from the literature.","meta":{"url":"http://arxiv.org/abs/2309.07781v1"},"cats":{"new-dataset":0.1230849578,"dev-research":0.2417723201,"data-quality":0.3493499428}}
{"text":"With our SMT-based implementation, we automatically verify a variety of benchmarks.","meta":{"url":"http://arxiv.org/abs/2309.07781v1"},"cats":{"new-dataset":0.0461770803,"dev-research":0.2181272372,"data-quality":0.1327831641}}
{"text":"To the best of our knowledge, this establishes the first deductive verification infrastructure for expectation-based reasoning about probabilistic programs.","meta":{"url":"http://arxiv.org/abs/2309.07781v1"},"cats":{"new-dataset":0.0383206292,"dev-research":0.3300740994,"data-quality":0.1275023104}}
{"text":"This paper presents an empirical investigation of the extent to which spoken Humanoid Embodied Conversational Agents (HECAs) can foster usability in mobile serious game (MSG) applications.","meta":{"url":"http://arxiv.org/abs/2309.07773v1"},"cats":{"new-dataset":0.2544575866,"dev-research":0.2958055394,"data-quality":0.0626029308}}
{"text":"The aim of the research is to assess the impact of multiple agents and illusion of humanness on the quality of the interaction.","meta":{"url":"http://arxiv.org/abs/2309.07773v1"},"cats":{"new-dataset":0.0322417498,"dev-research":0.2381160696,"data-quality":0.0852575647}}
{"text":"The experiment investigates two styles of agent presentation: an agent of high human-likeness (HECA) and an agent of low human-likeness (text).","meta":{"url":"http://arxiv.org/abs/2309.07773v1"},"cats":{"new-dataset":0.0735913192,"dev-research":0.1621847054,"data-quality":0.0774795119}}
{"text":"The purpose of the experiment is to assess whether and how agents of high humanlikeness can evoke the illusion of humanness and affect usability.","meta":{"url":"http://arxiv.org/abs/2309.07773v1"},"cats":{"new-dataset":0.040691329,"dev-research":0.2561681083,"data-quality":0.0793379378}}
{"text":"Agents of high human-likeness were designed by following the ECA design model that is a proposed guide for ECA development.","meta":{"url":"http://arxiv.org/abs/2309.07773v1"},"cats":{"new-dataset":0.0761775233,"dev-research":0.184814482,"data-quality":0.0335366023}}
{"text":"The results of the experiment with 90 participants show that users prefer to interact with the HECAs.","meta":{"url":"http://arxiv.org/abs/2309.07773v1"},"cats":{"new-dataset":0.0292993411,"dev-research":0.2535068497,"data-quality":0.0512789599}}
{"text":"The difference between the two versions is statistically significant with a large effect size (d=1.01), with many of the participants justifying their choice by saying that the human-like characteristics of the HECA made the version more appealing.","meta":{"url":"http://arxiv.org/abs/2309.07773v1"},"cats":{"new-dataset":0.0183640704,"dev-research":0.2243081176,"data-quality":0.0890568982}}
{"text":"This research provides key information on the potential effect of HECAs on serious games, which can provide insight into the design of future mobile serious games.","meta":{"url":"http://arxiv.org/abs/2309.07773v1"},"cats":{"new-dataset":0.1562962143,"dev-research":0.2970338545,"data-quality":0.0432784939}}
{"text":"The Transformer architecture has proven to be highly effective for Automatic Speech Recognition (ASR) tasks, becoming a foundational component for a plethora of research in the domain.","meta":{"url":"http://arxiv.org/abs/2309.07765v1"},"cats":{"new-dataset":0.0424557057,"dev-research":0.1423390816,"data-quality":0.1588525563}}
{"text":"Historically, many approaches have leaned on fixed-length attention windows, which becomes problematic for varied speech samples in duration and complexity, leading to data over-smoothing and neglect of essential long-term connectivity.","meta":{"url":"http://arxiv.org/abs/2309.07765v1"},"cats":{"new-dataset":0.0647765862,"dev-research":0.1623637654,"data-quality":0.1515690196}}
{"text":"Addressing this limitation, we introduce Echo-MSA, a nimble module equipped with a variable-length attention mechanism that accommodates a range of speech sample complexities and durations.","meta":{"url":"http://arxiv.org/abs/2309.07765v1"},"cats":{"new-dataset":0.2843712014,"dev-research":0.1396120133,"data-quality":0.0921537923}}
{"text":"This module offers the flexibility to extract speech features across various granularities, spanning from frames and phonemes to words and discourse.","meta":{"url":"http://arxiv.org/abs/2309.07765v1"},"cats":{"new-dataset":0.3528219209,"dev-research":0.1772527793,"data-quality":0.2016511267}}
{"text":"The proposed design captures the variable length feature of speech and addresses the limitations of fixed-length attention.","meta":{"url":"http://arxiv.org/abs/2309.07765v1"},"cats":{"new-dataset":0.091677921,"dev-research":0.1777747554,"data-quality":0.1282935967}}
{"text":"Our evaluation leverages a parallel attention architecture complemented by a dynamic gating mechanism that amalgamates traditional attention with the Echo-MSA module output.","meta":{"url":"http://arxiv.org/abs/2309.07765v1"},"cats":{"new-dataset":0.0451089482,"dev-research":0.1467496393,"data-quality":0.1108047732}}
{"text":"Empirical evidence from our study reveals that integrating Echo-MSA into the primary model's training regime significantly enhances the word error rate (WER) performance, all while preserving the intrinsic stability of the original model.","meta":{"url":"http://arxiv.org/abs/2309.07765v1"},"cats":{"new-dataset":0.0099715471,"dev-research":0.1953288231,"data-quality":0.3363136189}}
{"text":"Trusted Execution Environments (TEEs) suffer from performance issues when executing certain management instructions, such as creating an enclave, context switching in and out of protected mode, and swapping cached pages.","meta":{"url":"http://arxiv.org/abs/2309.07764v1"},"cats":{"new-dataset":0.0115905422,"dev-research":0.2781351483,"data-quality":0.129787555}}
{"text":"This is especially problematic for short-running, interactive functions in Function-as-a-Service (FaaS) platforms, where existing techniques to address enclave overheads are insufficient.","meta":{"url":"http://arxiv.org/abs/2309.07764v1"},"cats":{"new-dataset":0.0182735849,"dev-research":0.2046283911,"data-quality":0.1472154882}}
{"text":"We find FaaS functions can spend more time managing the enclave than executing application instructions.","meta":{"url":"http://arxiv.org/abs/2309.07764v1"},"cats":{"new-dataset":0.0081668,"dev-research":0.2219822031,"data-quality":0.0925747668}}
{"text":"In this work, we propose a TEE/GC hybrid (TGh) protocol to enable confidential FaaS platforms.","meta":{"url":"http://arxiv.org/abs/2309.07764v1"},"cats":{"new-dataset":0.0498707331,"dev-research":0.0897083281,"data-quality":0.0729560127}}
{"text":"TGh moves computation out of the enclave onto the untrusted host using garbled circuits (GC), a cryptographic construction for secure function evaluation.","meta":{"url":"http://arxiv.org/abs/2309.07764v1"},"cats":{"new-dataset":0.0291314718,"dev-research":0.1530479386,"data-quality":0.0777140881}}
{"text":"Our approach retains the security guarantees of enclaves while avoiding the performance issues associated with enclave management instructions.","meta":{"url":"http://arxiv.org/abs/2309.07764v1"},"cats":{"new-dataset":0.0086037682,"dev-research":0.1902595498,"data-quality":0.1160573327}}
{"text":"Large pre-trained vision-language models such as CLIP have demonstrated great potential in zero-shot transferability to downstream tasks.","meta":{"url":"http://arxiv.org/abs/2309.07760v1"},"cats":{"new-dataset":0.0689564057,"dev-research":0.1455145034,"data-quality":0.1618228936}}
{"text":"However, to attain optimal performance, the manual selection of prompts is necessary to improve alignment between the downstream image distribution and the textual class descriptions.","meta":{"url":"http://arxiv.org/abs/2309.07760v1"},"cats":{"new-dataset":0.095576295,"dev-research":0.1918028434,"data-quality":0.2971362554}}
{"text":"This manual prompt engineering is the major challenge for deploying such models in practice since it requires domain expertise and is extremely time-consuming.","meta":{"url":"http://arxiv.org/abs/2309.07760v1"},"cats":{"new-dataset":0.0296314638,"dev-research":0.2899811049,"data-quality":0.095980603}}
{"text":"To avoid non-trivial prompt engineering, recent work Context Optimization (CoOp) introduced the concept of prompt learning to the vision domain using learnable textual tokens.","meta":{"url":"http://arxiv.org/abs/2309.07760v1"},"cats":{"new-dataset":0.0260522738,"dev-research":0.319651522,"data-quality":0.1650909803}}
{"text":"While CoOp can achieve substantial improvements over manual prompts, its learned context is worse generalizable to wider unseen classes within the same dataset.","meta":{"url":"http://arxiv.org/abs/2309.07760v1"},"cats":{"new-dataset":0.035923255,"dev-research":0.2760403747,"data-quality":0.3017839055}}
{"text":"In this work, we present Prompt Learning with Reparameterization Encoder (PRE) - a simple and efficient method that enhances the generalization ability of the learnable prompt to unseen classes while maintaining the capacity to learn Base classes.","meta":{"url":"http://arxiv.org/abs/2309.07760v1"},"cats":{"new-dataset":0.0815131192,"dev-research":0.1712577787,"data-quality":0.1994016173}}
{"text":"Instead of directly optimizing the prompts, PRE employs a prompt encoder to reparameterize the input prompt embeddings, enhancing the exploration of task-specific knowledge from few-shot samples.","meta":{"url":"http://arxiv.org/abs/2309.07760v1"},"cats":{"new-dataset":0.0981725825,"dev-research":0.2421120115,"data-quality":0.115948553}}
{"text":"Experiments and extensive ablation studies on 8 benchmarks demonstrate that our approach is an efficient method for prompt learning.","meta":{"url":"http://arxiv.org/abs/2309.07760v1"},"cats":{"new-dataset":0.0461637958,"dev-research":0.1527311381,"data-quality":0.1112339798}}
{"text":"Specifically, PRE achieves a notable enhancement of 5.60% in average accuracy on New classes and 3% in Harmonic mean compared to CoOp in the 16-shot setting, all achieved within a good training time.","meta":{"url":"http://arxiv.org/abs/2309.07760v1"},"cats":{"new-dataset":0.0261938958,"dev-research":0.1708268909,"data-quality":0.1016482199}}
{"text":"Interactive Object Grasping (IOG) is the task of identifying and grasping the desired object via human-robot natural language interaction.","meta":{"url":"http://arxiv.org/abs/2309.07759v1"},"cats":{"new-dataset":0.1590455885,"dev-research":0.2026895249,"data-quality":0.0941390468}}
{"text":"Current IOG systems assume that a human user initially specifies the target object's category (e.g., bottle).","meta":{"url":"http://arxiv.org/abs/2309.07759v1"},"cats":{"new-dataset":0.0195081386,"dev-research":0.1552811914,"data-quality":0.1944236109}}
{"text":"Inspired by pragmatics, where humans often convey their intentions by relying on context to achieve goals, we introduce a new IOG task, Pragmatic-IOG, and the corresponding dataset, Intention-oriented Multi-modal Dialogue (IM-Dial).","meta":{"url":"http://arxiv.org/abs/2309.07759v1"},"cats":{"new-dataset":0.4098953073,"dev-research":0.1979581915,"data-quality":0.0975762802}}
{"text":"In our proposed task scenario, an intention-oriented utterance (e.g., \"I am thirsty\") is initially given to the robot.","meta":{"url":"http://arxiv.org/abs/2309.07759v1"},"cats":{"new-dataset":0.0420531698,"dev-research":0.2061188299,"data-quality":0.1164079643}}
{"text":"The robot should then identify the target object by interacting with a human user.","meta":{"url":"http://arxiv.org/abs/2309.07759v1"},"cats":{"new-dataset":0.0220448597,"dev-research":0.194261187,"data-quality":0.1269041932}}
{"text":"Based on the task setup, we propose a new robotic system that can interpret the user's intention and pick up the target object, Pragmatic Object Grasping (PROGrasp).","meta":{"url":"http://arxiv.org/abs/2309.07759v1"},"cats":{"new-dataset":0.049708303,"dev-research":0.1973727346,"data-quality":0.0849608326}}
{"text":"PROGrasp performs Pragmatic-IOG by incorporating modules for visual grounding, question asking, object grasping, and most importantly, answer interpretation for pragmatic inference.","meta":{"url":"http://arxiv.org/abs/2309.07759v1"},"cats":{"new-dataset":0.1983631451,"dev-research":0.2659438217,"data-quality":0.0878421017}}
{"text":"Experimental results show that PROGrasp is effective in offline (i.e., target object discovery) and online (i.e., IOG with a physical robot arm) settings.","meta":{"url":"http://arxiv.org/abs/2309.07759v1"},"cats":{"new-dataset":0.0597238924,"dev-research":0.1808765934,"data-quality":0.0560602391}}
{"text":"Large Language Models (LLMs) have shown impressive performance across a variety of Artificial Intelligence (AI) and natural language processing tasks, such as content creation, report generation, etc.","meta":{"url":"http://arxiv.org/abs/2309.07755v1"},"cats":{"new-dataset":0.0946393788,"dev-research":0.157405952,"data-quality":0.1415081768}}
{"text":"However, unregulated malign application of these models can create undesirable consequences such as generation of fake news, plagiarism, etc.","meta":{"url":"http://arxiv.org/abs/2309.07755v1"},"cats":{"new-dataset":0.0111688461,"dev-research":0.1943719243,"data-quality":0.2980393504}}
{"text":"As a result, accurate detection of AI-generated language can be crucial in responsible usage of LLMs.","meta":{"url":"http://arxiv.org/abs/2309.07755v1"},"cats":{"new-dataset":0.0199311764,"dev-research":0.2112953709,"data-quality":0.3160985788}}
{"text":"In this work, we explore 1) whether a certain body of text is AI generated or written by human, and 2) attribution of a specific language model in generating a body of text.","meta":{"url":"http://arxiv.org/abs/2309.07755v1"},"cats":{"new-dataset":0.1520759756,"dev-research":0.166898102,"data-quality":0.2265454662}}
{"text":"Texts in both English and Spanish are considered.","meta":{"url":"http://arxiv.org/abs/2309.07755v1"},"cats":{"new-dataset":0.0703306792,"dev-research":0.1996609271,"data-quality":0.1938506339}}
{"text":"The datasets used in this study are provided as part of the Automated Text Identification (AuTexTification) shared task.","meta":{"url":"http://arxiv.org/abs/2309.07755v1"},"cats":{"new-dataset":0.1522706671,"dev-research":0.1854054106,"data-quality":0.3943291205}}
{"text":"For each of the research objectives stated above, we propose an ensemble neural model that generates probabilities from different pre-trained LLMs which are used as features to a Traditional Machine Learning (TML) classifier following it.","meta":{"url":"http://arxiv.org/abs/2309.07755v1"},"cats":{"new-dataset":0.0736470354,"dev-research":0.146865103,"data-quality":0.1693406273}}
{"text":"For the first task of distinguishing between AI and human generated text, our model ranked in fifth and thirteenth place (with macro $F1$ scores of 0.733 and 0.649) for English and Spanish texts, respectively.","meta":{"url":"http://arxiv.org/abs/2309.07755v1"},"cats":{"new-dataset":0.1950924557,"dev-research":0.1973910119,"data-quality":0.2791113704}}
{"text":"For the second task on model attribution, our model ranked in first place with macro $F1$ scores of 0.625 and 0.653 for English and Spanish texts, respectively.","meta":{"url":"http://arxiv.org/abs/2309.07755v1"},"cats":{"new-dataset":0.174395172,"dev-research":0.1267971727,"data-quality":0.2697169341}}
{"text":"We revisit a graph width parameter that we dub bipartite treewidth, along with its associated graph decomposition that we call bipartite tree decomposition.","meta":{"url":"http://arxiv.org/abs/2309.07754v1"},"cats":{"new-dataset":0.0840703183,"dev-research":0.1620561626,"data-quality":0.1367331374}}
{"text":"Bipartite treewidth can be seen as a common generalization of treewidth and the odd cycle transversal number.","meta":{"url":"http://arxiv.org/abs/2309.07754v1"},"cats":{"new-dataset":0.0811850295,"dev-research":0.1273710131,"data-quality":0.1062504246}}
{"text":"Intuitively, a bipartite tree decomposition is a tree decomposition whose bags induce almost bipartite graphs and whose adhesions contain at most one vertex from the bipartite part of any other bag, while the width of such decomposition measures how far the bags are from being bipartite.","meta":{"url":"http://arxiv.org/abs/2309.07754v1"},"cats":{"new-dataset":0.0233652122,"dev-research":0.2159316754,"data-quality":0.1403245124}}
{"text":"Adapted from a tree decomposition originally defined by Demaine, Hajiaghayi, and Kawarabayashi [SODA 2010] and explicitly defined by Tazari [Th. Comp.","meta":{"url":"http://arxiv.org/abs/2309.07754v1"},"cats":{"new-dataset":0.130032938,"dev-research":0.1543456269,"data-quality":0.1647762414}}
{"text":"Sci. 2012], bipartite treewidth appears to play a crucial role for solving problems related to odd-minors, which have recently attracted considerable attention.","meta":{"url":"http://arxiv.org/abs/2309.07754v1"},"cats":{"new-dataset":0.0227720264,"dev-research":0.1324416481,"data-quality":0.1167539256}}
{"text":"As a first step toward a theory for solving these problems efficiently, the main goal of this paper is to develop dynamic programming techniques to solve problems on graphs of small bipartite treewidth.","meta":{"url":"http://arxiv.org/abs/2309.07754v1"},"cats":{"new-dataset":0.0874717069,"dev-research":0.2161695501,"data-quality":0.1022140887}}
{"text":"For such graphs, we provide a number of para-NP-completeness results, FPT-algorithms, and XP-algorithms, as well as several open problems.","meta":{"url":"http://arxiv.org/abs/2309.07754v1"},"cats":{"new-dataset":0.2128463139,"dev-research":0.1727359882,"data-quality":0.1353643718}}
{"text":"In particular, we show that $K_t$-Subgraph-Cover, Weighted Vertex Cover/Independent Set, Odd Cycle Transversal, and Maximum Weighted Cut are $FPT$ parameterized by bipartite treewidth.","meta":{"url":"http://arxiv.org/abs/2309.07754v1"},"cats":{"new-dataset":0.1504706856,"dev-research":0.1322897592,"data-quality":0.1090141721}}
{"text":"We provide the following complexity dichotomy when $H$ is a 2-connected graph, for each of $H$-Subgraph-Packing, $H$-Induced-Packing, $H$-Scattered-Packing, and $H$-Odd-Minor-Packing problem: if $H$ is bipartite, then the problem is para-NP-complete parameterized by bipartite treewidth while, if $H$ is non-bipartite, then it is solvable in XP-time.","meta":{"url":"http://arxiv.org/abs/2309.07754v1"},"cats":{"new-dataset":0.0406008818,"dev-research":0.2324325886,"data-quality":0.1303487795}}
{"text":"We define 1-${\\cal H}$-treewidth by replacing the bipartite graph class by any class ${\\cal H}$. Most of the technology developed here works for this more general parameter.","meta":{"url":"http://arxiv.org/abs/2309.07754v1"},"cats":{"new-dataset":0.0460424416,"dev-research":0.1558535921,"data-quality":0.1384023529}}
{"text":"Given a group of images, co-salient object detection (CoSOD) aims to highlight the common salient object in each image.","meta":{"url":"http://arxiv.org/abs/2309.07753v1"},"cats":{"new-dataset":0.1569223894,"dev-research":0.179218585,"data-quality":0.160523509}}
{"text":"There are two factors closely related to the success of this task, namely consensus extraction, and the dispersion of consensus to each image.","meta":{"url":"http://arxiv.org/abs/2309.07753v1"},"cats":{"new-dataset":0.123618268,"dev-research":0.1514386534,"data-quality":0.2210391216}}
{"text":"Most previous works represent the group consensus using local features, while we instead utilize a hierarchical Transformer module for extracting semantic-level consensus.","meta":{"url":"http://arxiv.org/abs/2309.07753v1"},"cats":{"new-dataset":0.1504512408,"dev-research":0.2591085768,"data-quality":0.2199723876}}
{"text":"Therefore, it can obtain a more comprehensive representation of the common object category, and exclude interference from other objects that share local similarities with the target object.","meta":{"url":"http://arxiv.org/abs/2309.07753v1"},"cats":{"new-dataset":0.0186504045,"dev-research":0.2182079941,"data-quality":0.1634036133}}
{"text":"In addition, we propose a Transformer-based dispersion module that takes into account the variation of the co-salient object in different scenes.","meta":{"url":"http://arxiv.org/abs/2309.07753v1"},"cats":{"new-dataset":0.1011143966,"dev-research":0.1386834699,"data-quality":0.0733734774}}
{"text":"It distributes the consensus to the image feature maps in an image-specific way while making full use of interactions within the group.","meta":{"url":"http://arxiv.org/abs/2309.07753v1"},"cats":{"new-dataset":0.0347466416,"dev-research":0.2194705358,"data-quality":0.079572187}}
{"text":"These two modules are integrated with a ViT encoder and an FPN-like decoder to form an end-to-end trainable network, without additional branch and auxiliary loss.","meta":{"url":"http://arxiv.org/abs/2309.07753v1"},"cats":{"new-dataset":0.0427459205,"dev-research":0.1345868178,"data-quality":0.1073773348}}
{"text":"The proposed method is evaluated on three commonly used CoSOD datasets and achieves state-of-the-art performance.","meta":{"url":"http://arxiv.org/abs/2309.07753v1"},"cats":{"new-dataset":0.2278394795,"dev-research":0.1394076019,"data-quality":0.1215433895}}
{"text":"In this paper, we present the decomposed triplane-hash neural radiance fields (DT-NeRF), a framework that significantly improves the photorealistic rendering of talking faces and achieves state-of-the-art results on key evaluation datasets.","meta":{"url":"http://arxiv.org/abs/2309.07752v1"},"cats":{"new-dataset":0.6304213891,"dev-research":0.22516585,"data-quality":0.1203132132}}
{"text":"Our architecture decomposes the facial region into two specialized triplanes: one specialized for representing the mouth, and the other for the broader facial features.","meta":{"url":"http://arxiv.org/abs/2309.07752v1"},"cats":{"new-dataset":0.0570990077,"dev-research":0.1439208816,"data-quality":0.0701421897}}
{"text":"We introduce audio features as residual terms and integrate them as query vectors into our model through an audio-mouth-face transformer.","meta":{"url":"http://arxiv.org/abs/2309.07752v1"},"cats":{"new-dataset":0.074596839,"dev-research":0.1685856992,"data-quality":0.1954692499}}
{"text":"Additionally, our method leverages the capabilities of Neural Radiance Fields (NeRF) to enrich the volumetric representation of the entire face through additive volumetric rendering techniques.","meta":{"url":"http://arxiv.org/abs/2309.07752v1"},"cats":{"new-dataset":0.0686503577,"dev-research":0.1855840239,"data-quality":0.0696060829}}
{"text":"Comprehensive experimental evaluations corroborate the effectiveness and superiority of our proposed approach.","meta":{"url":"http://arxiv.org/abs/2309.07752v1"},"cats":{"new-dataset":0.0033719713,"dev-research":0.1762563646,"data-quality":0.1820932814}}
{"text":"Video matting has broad applications, from adding interesting effects to casually captured movies to assisting video production professionals.","meta":{"url":"http://arxiv.org/abs/2309.07749v1"},"cats":{"new-dataset":0.0400820282,"dev-research":0.204516783,"data-quality":0.131358506}}
{"text":"Matting with associated effects such as shadows and reflections has also attracted increasing research activity, and methods like Omnimatte have been proposed to separate dynamic foreground objects of interest into their own layers.","meta":{"url":"http://arxiv.org/abs/2309.07749v1"},"cats":{"new-dataset":0.0173766665,"dev-research":0.17716978,"data-quality":0.0756743183}}
{"text":"However, prior works represent video backgrounds as 2D image layers, limiting their capacity to express more complicated scenes, thus hindering application to real-world videos.","meta":{"url":"http://arxiv.org/abs/2309.07749v1"},"cats":{"new-dataset":0.019587519,"dev-research":0.2566091203,"data-quality":0.0814662203}}
{"text":"In this paper, we propose a novel video matting method, OmnimatteRF, that combines dynamic 2D foreground layers and a 3D background model.","meta":{"url":"http://arxiv.org/abs/2309.07749v1"},"cats":{"new-dataset":0.1241378056,"dev-research":0.1532355055,"data-quality":0.089117816}}
{"text":"The 2D layers preserve the details of the subjects, while the 3D background robustly reconstructs scenes in real-world videos.","meta":{"url":"http://arxiv.org/abs/2309.07749v1"},"cats":{"new-dataset":0.1083496479,"dev-research":0.1970516758,"data-quality":0.0650855294}}
{"text":"Extensive experiments demonstrate that our method reconstructs scenes with better quality on various videos.","meta":{"url":"http://arxiv.org/abs/2309.07749v1"},"cats":{"new-dataset":0.123273536,"dev-research":0.2197848018,"data-quality":0.1942936418}}
{"text":"The information landscape has undergone dramatic changes with the expansion of the internet and online social networks.","meta":{"url":"http://arxiv.org/abs/2309.07745v1"},"cats":{"new-dataset":0.0518189229,"dev-research":0.2239913367,"data-quality":0.0765701451}}
{"text":"Optimistic views thought that online communication would foster a culture of participation.","meta":{"url":"http://arxiv.org/abs/2309.07745v1"},"cats":{"new-dataset":0.0210560331,"dev-research":0.2387619242,"data-quality":0.0978312385}}
{"text":"However, recent events suggest that social media platforms limit the diversity of the content by exposing users to pre-existing beliefs, which is known by the metaphor of echo chambers.","meta":{"url":"http://arxiv.org/abs/2309.07745v1"},"cats":{"new-dataset":0.0226315827,"dev-research":0.2295544982,"data-quality":0.1491400192}}
{"text":"In addition, users with malicious intent are using these platforms to deceive people and discredit the democratic process.","meta":{"url":"http://arxiv.org/abs/2309.07745v1"},"cats":{"new-dataset":0.0206473975,"dev-research":0.1914508941,"data-quality":0.1465025758}}
{"text":"To better understand these two phenomena, this chapter describes a computational method to analyze coordinated inauthentic behavior on Facebook groups on posts, URLs, and images.","meta":{"url":"http://arxiv.org/abs/2309.07745v1"},"cats":{"new-dataset":0.0166799174,"dev-research":0.2034806327,"data-quality":0.1394079138}}
{"text":"Our findings suggest that Facebook groups shared identical items almost simultaneously by different entities.","meta":{"url":"http://arxiv.org/abs/2309.07745v1"},"cats":{"new-dataset":0.0239025783,"dev-research":0.1640868716,"data-quality":0.1345553116}}
{"text":"In doing so, we could identify that these groups resemble disinformation echo chambers, where repeatedly sharing activities of disinformation narratives occur.","meta":{"url":"http://arxiv.org/abs/2309.07745v1"},"cats":{"new-dataset":0.1785029151,"dev-research":0.26588665,"data-quality":0.1506598086}}
{"text":"The chapter concludes with theoretical and empirical implications.","meta":{"url":"http://arxiv.org/abs/2309.07745v1"},"cats":{"new-dataset":0.0120178859,"dev-research":0.1512734804,"data-quality":0.1249945311}}
{"text":"Focus in Explainable AI is shifting from explanations defined in terms of low-level elements, such as input features, to explanations encoded in terms of interpretable concepts learned from data.","meta":{"url":"http://arxiv.org/abs/2309.07742v1"},"cats":{"new-dataset":0.0171841555,"dev-research":0.3600680584,"data-quality":0.1702759174}}
{"text":"How to reliably acquire such concepts is, however, still fundamentally unclear.","meta":{"url":"http://arxiv.org/abs/2309.07742v1"},"cats":{"new-dataset":0.0080257452,"dev-research":0.2386516451,"data-quality":0.1414074177}}
{"text":"An agreed-upon notion of concept interpretability is missing, with the result that concepts used by both post-hoc explainers and concept-based neural networks are acquired through a variety of mutually incompatible strategies.","meta":{"url":"http://arxiv.org/abs/2309.07742v1"},"cats":{"new-dataset":0.0079642617,"dev-research":0.3162716736,"data-quality":0.2518924004}}
{"text":"Critically, most of these neglect the human side of the problem: a representation is understandable only insofar as it can be understood by the human at the receiving end.","meta":{"url":"http://arxiv.org/abs/2309.07742v1"},"cats":{"new-dataset":0.0194045607,"dev-research":0.2902512398,"data-quality":0.1834649064}}
{"text":"The key challenge in Human-interpretable Representation Learning (HRL) is how to model and operationalize this human element.","meta":{"url":"http://arxiv.org/abs/2309.07742v1"},"cats":{"new-dataset":0.0833587382,"dev-research":0.2639814755,"data-quality":0.1862300354}}
{"text":"In this work, we propose a mathematical framework for acquiring interpretable representations suitable for both post-hoc explainers and concept-based neural networks.","meta":{"url":"http://arxiv.org/abs/2309.07742v1"},"cats":{"new-dataset":0.0268311005,"dev-research":0.2308221103,"data-quality":0.1346961887}}
{"text":"Our formalization of HRL builds on recent advances in causal representation learning and explicitly models a human stakeholder as an external observer.","meta":{"url":"http://arxiv.org/abs/2309.07742v1"},"cats":{"new-dataset":0.0575408121,"dev-research":0.3475001445,"data-quality":0.167973808}}
{"text":"This allows us to derive a principled notion of alignment between the machine representation and the vocabulary of concepts understood by the human.","meta":{"url":"http://arxiv.org/abs/2309.07742v1"},"cats":{"new-dataset":0.0270860622,"dev-research":0.2632116242,"data-quality":0.1551213242}}
{"text":"In doing so, we link alignment and interpretability through a simple and intuitive name transfer game, and clarify the relationship between alignment and a well-known property of representations, namely disentanglment.","meta":{"url":"http://arxiv.org/abs/2309.07742v1"},"cats":{"new-dataset":0.0603308543,"dev-research":0.2577678992,"data-quality":0.2246739678}}
{"text":"We also show that alignment is linked to the issue of undesirable correlations among concepts, also known as concept leakage, and to content-style separation, all through a general information-theoretic reformulation of these properties.","meta":{"url":"http://arxiv.org/abs/2309.07742v1"},"cats":{"new-dataset":0.0103531781,"dev-research":0.2539594619,"data-quality":0.410564066}}
{"text":"Our conceptualization aims to bridge the gap between the human and algorithmic sides of interpretability and establish a stepping stone for new research on human-interpretable representations.","meta":{"url":"http://arxiv.org/abs/2309.07742v1"},"cats":{"new-dataset":0.0419647014,"dev-research":0.3203800318,"data-quality":0.2008048244}}
{"text":"Research on pronunciation assessment systems focuses on utilizing phonetic and phonological aspects of non-native (L2) speech, often neglecting the rich layer of information hidden within the non-verbal cues.","meta":{"url":"http://arxiv.org/abs/2309.07739v1"},"cats":{"new-dataset":0.0531839411,"dev-research":0.2025425272,"data-quality":0.2483361225}}
{"text":"In this study, we proposed a novel pronunciation assessment framework, IntraVerbalPA.","meta":{"url":"http://arxiv.org/abs/2309.07739v1"},"cats":{"new-dataset":0.1952610557,"dev-research":0.1949963312,"data-quality":0.2445237304}}
{"text":"%","meta":{"url":"http://arxiv.org/abs/2309.07739v1"},"cats":{"new-dataset":0.3309369072,"dev-research":0.2025749923,"data-quality":0.1701220614}}
{"text":"The framework innovatively incorporates both fine-grained frame- and abstract utterance-level non-verbal cues, alongside the conventional speech and phoneme representations.","meta":{"url":"http://arxiv.org/abs/2309.07739v1"},"cats":{"new-dataset":0.10408301,"dev-research":0.1707449958,"data-quality":0.2021302136}}
{"text":"Additionally, we introduce ''Goodness of phonemic-duration'' metric to effectively model duration distribution within the framework.","meta":{"url":"http://arxiv.org/abs/2309.07739v1"},"cats":{"new-dataset":0.2095246179,"dev-research":0.1495161014,"data-quality":0.0898355909}}
{"text":"Our results validate the effectiveness of the proposed IntraVerbalPA framework and its individual components, yielding performance that either matches or outperforms existing research works.","meta":{"url":"http://arxiv.org/abs/2309.07739v1"},"cats":{"new-dataset":0.0625500038,"dev-research":0.2472463906,"data-quality":0.1001058032}}
{"text":"This paper investigates the performance of vehicleto-vehicle (V2V) communications assisted by a reconfigurable intelligent surface (RIS) and a simultaneous transmitting and reflecting intelligent omni-surface (STAR-IOS) under nonorthogonal multiple access (NOMA) and orthogonal multiple access (OMA) schemes.","meta":{"url":"http://arxiv.org/abs/2309.07738v1"},"cats":{"new-dataset":0.0219929597,"dev-research":0.1762324234,"data-quality":0.0592577088}}
{"text":"In particular, we consider that the RIS is close to the transmitter vehicle while the STAR-IOS is near the receiver vehicles.","meta":{"url":"http://arxiv.org/abs/2309.07738v1"},"cats":{"new-dataset":0.0259296568,"dev-research":0.1535367226,"data-quality":0.1480936993}}
{"text":"In addition, we assume that the STAR-IOS exploits the energy-splitting (ES) protocol for communication and the fading channels between the RIS and STAR-IOS follow composite Fisher-Snedecor F distribution.","meta":{"url":"http://arxiv.org/abs/2309.07738v1"},"cats":{"new-dataset":0.0288261142,"dev-research":0.0829455925,"data-quality":0.139048157}}
{"text":"Under such assumptions, we first use the central limit theorem (CLT) to derive the PDF and the CDF of equivalent channels at receiver vehicles, and then, we derive the closed-form expression of outage probability (OP) under NOMA/OMA scenarios.","meta":{"url":"http://arxiv.org/abs/2309.07738v1"},"cats":{"new-dataset":0.0560227256,"dev-research":0.1484496812,"data-quality":0.1571290812}}
{"text":"Additionally, by exploiting Jensen's inequality, we propose an upper bound of the ergodic capacity (EC), and then, we derive an analytical expression of the energy efficiency (EE) for both NOMA and OMA cases.","meta":{"url":"http://arxiv.org/abs/2309.07738v1"},"cats":{"new-dataset":0.0335262454,"dev-research":0.103434419,"data-quality":0.0720456876}}
{"text":"Further, our analytical results, which are double-checked with the Monte-Carlo simulation, reveal that applying RIS/STAR-RIS in V2V communications can significantly improve the performance of intelligent transportation systems (ITS).","meta":{"url":"http://arxiv.org/abs/2309.07738v1"},"cats":{"new-dataset":0.0163654269,"dev-research":0.1544157655,"data-quality":0.1410878936}}
{"text":"Besides, the results indicate that considering the NOMA scheme provides better performance in terms of the OP, EC, and EE as compared with the OMA case for the considered V2V communication.","meta":{"url":"http://arxiv.org/abs/2309.07738v1"},"cats":{"new-dataset":0.0144213419,"dev-research":0.148989096,"data-quality":0.1190370884}}
{"text":"The physical layer authentication (PLA) is a promising technology which can enhance the access security of a massive number of devices in the near future.","meta":{"url":"http://arxiv.org/abs/2309.07736v1"},"cats":{"new-dataset":0.0271408289,"dev-research":0.1932862538,"data-quality":0.0534653753}}
{"text":"In this paper, we propose a reconfigurable intelligent surface (RIS)-assisted PLA system, in which the legitimate transmitter can customize the channel fingerprints during PLA by controlling the ON-OFF state of the RIS.","meta":{"url":"http://arxiv.org/abs/2309.07736v1"},"cats":{"new-dataset":0.0509774644,"dev-research":0.2213079018,"data-quality":0.0870510526}}
{"text":"Without loss of generality, we use the received signal strength (RSS) based spoofing detection approach to analyze the feasibility of the proposed architecture.","meta":{"url":"http://arxiv.org/abs/2309.07736v1"},"cats":{"new-dataset":0.0374987787,"dev-research":0.1782176179,"data-quality":0.1435060402}}
{"text":"Specifically, based on the RSS, we derive the statistical properties of PLA and give some interesting insights, which showcase that the RIS-assisted PLA is theoretically feasible.","meta":{"url":"http://arxiv.org/abs/2309.07736v1"},"cats":{"new-dataset":0.0306916208,"dev-research":0.096124488,"data-quality":0.086910914}}
{"text":"Then, we derive the optimal detection threshold to maximize the performance in the context of the presented performance metrics.","meta":{"url":"http://arxiv.org/abs/2309.07736v1"},"cats":{"new-dataset":0.0156149324,"dev-research":0.174304947,"data-quality":0.2711235857}}
{"text":"Next, the actual feasibility of the proposed system is verified via proof-of-concept experiments on a RIS-assisted PLA prototype platform.","meta":{"url":"http://arxiv.org/abs/2309.07736v1"},"cats":{"new-dataset":0.012517767,"dev-research":0.1440570523,"data-quality":0.0998779485}}
{"text":"The experiment results show that there are 3.5% and 76% performance improvements when the transmission sources are at different locations and at the same location, respectively.","meta":{"url":"http://arxiv.org/abs/2309.07736v1"},"cats":{"new-dataset":0.0048390979,"dev-research":0.1600643975,"data-quality":0.1332259688}}
{"text":"Recent advances in eXplainable AI (XAI) have provided new insights into how models for vision, language, and tabular data operate.","meta":{"url":"http://arxiv.org/abs/2309.07733v1"},"cats":{"new-dataset":0.0522363664,"dev-research":0.2666011594,"data-quality":0.1656268067}}
{"text":"However, few approaches exist for understanding speech models.","meta":{"url":"http://arxiv.org/abs/2309.07733v1"},"cats":{"new-dataset":0.0281191346,"dev-research":0.1594316205,"data-quality":0.1643753301}}
{"text":"Existing work focuses on a few spoken language understanding (SLU) tasks, and explanations are difficult to interpret for most users.","meta":{"url":"http://arxiv.org/abs/2309.07733v1"},"cats":{"new-dataset":0.045453221,"dev-research":0.3236062514,"data-quality":0.2383374923}}
{"text":"We introduce a new approach to explain speech classification models.","meta":{"url":"http://arxiv.org/abs/2309.07733v1"},"cats":{"new-dataset":0.0965056232,"dev-research":0.1630869875,"data-quality":0.3871562923}}
{"text":"We generate easy-to-interpret explanations via input perturbation on two information levels.","meta":{"url":"http://arxiv.org/abs/2309.07733v1"},"cats":{"new-dataset":0.0364263997,"dev-research":0.313783433,"data-quality":0.3076323533}}
{"text":"1) Word-level explanations reveal how each word-related audio segment impacts the outcome.","meta":{"url":"http://arxiv.org/abs/2309.07733v1"},"cats":{"new-dataset":0.0191702798,"dev-research":0.2623340921,"data-quality":0.2832447051}}
{"text":"2) Paralinguistic features (e.g., prosody and background noise) answer the counterfactual: ``What would the model prediction be if we edited the audio signal in this way?''","meta":{"url":"http://arxiv.org/abs/2309.07733v1"},"cats":{"new-dataset":0.0805626081,"dev-research":0.2337210906,"data-quality":0.2745535473}}
{"text":"We validate our approach by explaining two state-of-the-art SLU models on two speech classification tasks in English and Italian.","meta":{"url":"http://arxiv.org/abs/2309.07733v1"},"cats":{"new-dataset":0.0681863477,"dev-research":0.1466848858,"data-quality":0.3403237198}}
{"text":"Our findings demonstrate that the explanations are faithful to the model's inner workings and plausible to humans.","meta":{"url":"http://arxiv.org/abs/2309.07733v1"},"cats":{"new-dataset":0.0158425557,"dev-research":0.2954908933,"data-quality":0.173353026}}
{"text":"Our method and findings pave the way for future research on interpreting speech models.","meta":{"url":"http://arxiv.org/abs/2309.07733v1"},"cats":{"new-dataset":0.0554914756,"dev-research":0.1925329167,"data-quality":0.2032733071}}
{"text":"Underwater Acoustic Sensor Networks (UW-ASNs) are predominantly used for underwater environments and find applications in many areas.","meta":{"url":"http://arxiv.org/abs/2309.07730v1"},"cats":{"new-dataset":0.0733384843,"dev-research":0.1842236137,"data-quality":0.0895223014}}
{"text":"However, a lack of security considerations, the unstable and challenging nature of the underwater environment, and the resource-constrained nature of the sensor nodes used for UW-ASNs (which makes them incapable of adopting security primitives) make the UW-ASN prone to vulnerabilities.","meta":{"url":"http://arxiv.org/abs/2309.07730v1"},"cats":{"new-dataset":0.0221158772,"dev-research":0.2317173051,"data-quality":0.1281896137}}
{"text":"This paper proposes an Adaptive decentralised Intrusion Detection and Prevention System called AIDPS for UW-ASNs.","meta":{"url":"http://arxiv.org/abs/2309.07730v1"},"cats":{"new-dataset":0.0542039701,"dev-research":0.2191153016,"data-quality":0.098110355}}
{"text":"The proposed AIDPS can improve the security of the UW-ASNs so that they can efficiently detect underwater-related attacks (e.g., blackhole, grayhole and flooding attacks).","meta":{"url":"http://arxiv.org/abs/2309.07730v1"},"cats":{"new-dataset":0.0425409026,"dev-research":0.1857731917,"data-quality":0.101000072}}
{"text":"To determine the most effective configuration of the proposed construction, we conduct a number of experiments using several state-of-the-art machine learning algorithms (e.g., Adaptive Random Forest (ARF), light gradient-boosting machine, and K-nearest neighbours) and concept drift detection algorithms (e.g., ADWIN, kdqTree, and Page-Hinkley).","meta":{"url":"http://arxiv.org/abs/2309.07730v1"},"cats":{"new-dataset":0.0553588676,"dev-research":0.2206935412,"data-quality":0.2417920159}}
{"text":"Our experimental results show that incremental ARF using ADWIN provides optimal performance when implemented with One-class support vector machine (SVM) anomaly-based detectors.","meta":{"url":"http://arxiv.org/abs/2309.07730v1"},"cats":{"new-dataset":0.1166832201,"dev-research":0.2415166278,"data-quality":0.2271025816}}
{"text":"Furthermore, our extensive evaluation results also show that the proposed scheme outperforms state-of-the-art bench-marking methods while providing a wider range of desirable features such as scalability and complexity.","meta":{"url":"http://arxiv.org/abs/2309.07730v1"},"cats":{"new-dataset":0.0201123131,"dev-research":0.2127282339,"data-quality":0.1249420805}}
{"text":"In everyday life collaboration tasks between human operators and robots, the former necessitate simple ways for programming new skills, the latter have to show adaptive capabilities to cope with environmental changes.","meta":{"url":"http://arxiv.org/abs/2309.07729v1"},"cats":{"new-dataset":0.0967120429,"dev-research":0.4982979891,"data-quality":0.0578769507}}
{"text":"The joint use of visual servoing and imitation learning allows us to pursue the objective of realizing friendly robotic interfaces that (i) are able to adapt to the environment thanks to the use of visual perception and (ii) avoid explicit programming thanks to the emulation of previous demonstrations.","meta":{"url":"http://arxiv.org/abs/2309.07729v1"},"cats":{"new-dataset":0.0188752482,"dev-research":0.2347394168,"data-quality":0.0704996515}}
{"text":"This work aims to exploit imitation learning for the visual servoing paradigm to address the specific problem of tracking moving objects.","meta":{"url":"http://arxiv.org/abs/2309.07729v1"},"cats":{"new-dataset":0.0348431967,"dev-research":0.1755121559,"data-quality":0.0972658467}}
{"text":"In particular, we show that it is possible to infer from data the compensation term required for realizing the tracking controller, avoiding the explicit implementation of estimators or observers.","meta":{"url":"http://arxiv.org/abs/2309.07729v1"},"cats":{"new-dataset":0.0506504243,"dev-research":0.1583604502,"data-quality":0.1510266678}}
{"text":"The effectiveness of the proposed method has been validated through simulations with a robotic manipulator.","meta":{"url":"http://arxiv.org/abs/2309.07729v1"},"cats":{"new-dataset":0.0012208285,"dev-research":0.1630301292,"data-quality":0.0808430441}}
{"text":"The meanings of words and phrases depend not only on where they are used (contexts) but also on who use them (writers).","meta":{"url":"http://arxiv.org/abs/2309.07727v1"},"cats":{"new-dataset":0.0816253666,"dev-research":0.2982681644,"data-quality":0.1708983014}}
{"text":"Pretrained language models (PLMs) are powerful tools for capturing context, but they are typically pretrained and fine-tuned for universal use across different writers.","meta":{"url":"http://arxiv.org/abs/2309.07727v1"},"cats":{"new-dataset":0.0680249879,"dev-research":0.197018559,"data-quality":0.1262795886}}
{"text":"This study aims to improve the accuracy of text understanding tasks by personalizing the fine-tuning of PLMs for specific writers.","meta":{"url":"http://arxiv.org/abs/2309.07727v1"},"cats":{"new-dataset":0.026720457,"dev-research":0.2622203168,"data-quality":0.2571598548}}
{"text":"We focus on a general setting where only the plain text from target writers are available for personalization.","meta":{"url":"http://arxiv.org/abs/2309.07727v1"},"cats":{"new-dataset":0.091951976,"dev-research":0.2291682434,"data-quality":0.1797119965}}
{"text":"To avoid the cost of fine-tuning and storing multiple copies of PLMs for different users, we exhaustively explore using writer-specific prompts to personalize a unified PLM.","meta":{"url":"http://arxiv.org/abs/2309.07727v1"},"cats":{"new-dataset":0.0847012321,"dev-research":0.273059243,"data-quality":0.1190617757}}
{"text":"Since the design and evaluation of these prompts is an underdeveloped area, we introduce and compare different types of prompts that are possible in our setting.","meta":{"url":"http://arxiv.org/abs/2309.07727v1"},"cats":{"new-dataset":0.060528458,"dev-research":0.3483536772,"data-quality":0.1119220223}}
{"text":"To maximize the potential of prompt-based personalized fine-tuning, we propose a personalized intermediate learning based on masked language modeling to extract task-independent traits of writers' text.","meta":{"url":"http://arxiv.org/abs/2309.07727v1"},"cats":{"new-dataset":0.0345531675,"dev-research":0.2214757216,"data-quality":0.2274185442}}
{"text":"Our experiments, using multiple tasks, datasets, and PLMs, reveal the nature of different prompts and the effectiveness of our intermediate learning approach.","meta":{"url":"http://arxiv.org/abs/2309.07727v1"},"cats":{"new-dataset":0.0543518108,"dev-research":0.1720452463,"data-quality":0.1221920649}}
{"text":"Recent works have shown that Large Language Models (LLMs) can promote grounding instructions to robotic task planning.","meta":{"url":"http://arxiv.org/abs/2309.07726v1"},"cats":{"new-dataset":0.1216825264,"dev-research":0.2293283462,"data-quality":0.0814468677}}
{"text":"Despite the progress, most existing works focused on utilizing raw images to help LLMs understand environmental information, which not only limits the observation scope but also typically requires massive multimodal data collection and large-scale models.","meta":{"url":"http://arxiv.org/abs/2309.07726v1"},"cats":{"new-dataset":0.5543941798,"dev-research":0.1431203926,"data-quality":0.0825038719}}
{"text":"In this paper, we propose a novel approach called Graph-based Robotic Instruction Decomposer (GRID), leverages scene graph instead of image to perceive global scene information and continuously plans subtask in each stage for a given instruction.","meta":{"url":"http://arxiv.org/abs/2309.07726v1"},"cats":{"new-dataset":0.2161003406,"dev-research":0.2640879115,"data-quality":0.0744223756}}
{"text":"Our method encodes object attributes and relationships in graphs through an LLM and Graph Attention Networks, integrating instruction features to predict subtasks consisting of pre-defined robot actions and target objects in the scene graph.","meta":{"url":"http://arxiv.org/abs/2309.07726v1"},"cats":{"new-dataset":0.2965299285,"dev-research":0.2617040904,"data-quality":0.1339253516}}
{"text":"This strategy enables robots to acquire semantic knowledge widely observed in the environment from the scene graph.","meta":{"url":"http://arxiv.org/abs/2309.07726v1"},"cats":{"new-dataset":0.2630162489,"dev-research":0.2271512044,"data-quality":0.154507874}}
{"text":"To train and evaluate GRID, we build a dataset construction pipeline to generate synthetic datasets in graph-based robotic task planning.","meta":{"url":"http://arxiv.org/abs/2309.07726v1"},"cats":{"new-dataset":0.6328097285,"dev-research":0.2498688147,"data-quality":0.0887681176}}
{"text":"Experiments have shown that our method outperforms GPT-4 by over 25.4% in subtask accuracy and 43.6% in task accuracy.","meta":{"url":"http://arxiv.org/abs/2309.07726v1"},"cats":{"new-dataset":0.022070256,"dev-research":0.1817036561,"data-quality":0.1177776981}}
{"text":"Experiments conducted on datasets of unseen scenes and scenes with different numbers of objects showed that the task accuracy of GRID declined by at most 3.8%, which demonstrates its good cross-scene generalization ability.","meta":{"url":"http://arxiv.org/abs/2309.07726v1"},"cats":{"new-dataset":0.0616123587,"dev-research":0.1431839775,"data-quality":0.2005381085}}
{"text":"We validate our method in both physical simulation and the real world.","meta":{"url":"http://arxiv.org/abs/2309.07726v1"},"cats":{"new-dataset":0.0197986629,"dev-research":0.2223588354,"data-quality":0.1074317074}}
{"text":"There is a growing recognition of the need for a transformation from organizational security awareness programs focused on compliance -- measured by training completion rates -- to those resulting in behavior change.","meta":{"url":"http://arxiv.org/abs/2309.07724v1"},"cats":{"new-dataset":0.0252500438,"dev-research":0.2763611462,"data-quality":0.1201267776}}
{"text":"However, few prior studies have begun to unpack the organizational practices of the security awareness teams tasked with executing program transformation.","meta":{"url":"http://arxiv.org/abs/2309.07724v1"},"cats":{"new-dataset":0.0337248556,"dev-research":0.4032352902,"data-quality":0.1038395085}}
{"text":"We conducted a year-long case study of a security awareness program in a United States (U.S.) government agency, collecting data via field observations, interviews, and documents.","meta":{"url":"http://arxiv.org/abs/2309.07724v1"},"cats":{"new-dataset":0.4670323196,"dev-research":0.2561799126,"data-quality":0.0977983753}}
{"text":"Our findings reveal the challenges and practices involved in the progression of a security awareness program from being compliance-focused to emphasizing impact on workforce attitudes and behaviors.","meta":{"url":"http://arxiv.org/abs/2309.07724v1"},"cats":{"new-dataset":0.0307072789,"dev-research":0.3218496034,"data-quality":0.1276450694}}
{"text":"We uniquely capture transformational organizational security awareness practices in action via a longitudinal study involving multiple workforce perspectives.","meta":{"url":"http://arxiv.org/abs/2309.07724v1"},"cats":{"new-dataset":0.0244487467,"dev-research":0.2782974746,"data-quality":0.0807036261}}
{"text":"Our study insights can serve as a resource for other security awareness programs and workforce development initiatives aimed at better defining the security awareness work role.","meta":{"url":"http://arxiv.org/abs/2309.07724v1"},"cats":{"new-dataset":0.0707845581,"dev-research":0.3458825419,"data-quality":0.0824942902}}
{"text":"Inferential decision-making algorithms typically assume that an underlying probabilistic model of decision alternatives and outcomes may be learned a priori or online.","meta":{"url":"http://arxiv.org/abs/2309.07720v1"},"cats":{"new-dataset":0.0064523896,"dev-research":0.1884099148,"data-quality":0.0860927403}}
{"text":"Furthermore, when applied to robots in real-world settings they often perform unsatisfactorily or fail to accomplish the necessary tasks because this assumption is violated and/or they experience unanticipated external pressures and constraints.","meta":{"url":"http://arxiv.org/abs/2309.07720v1"},"cats":{"new-dataset":0.0037820496,"dev-research":0.2632471034,"data-quality":0.1023530606}}
{"text":"Cognitive studies presented in this and other papers show that humans cope with complex and unknown settings by modulating between near-optimal and satisficing solutions, including heuristics, by leveraging information value of available environmental cues that are possibly redundant.","meta":{"url":"http://arxiv.org/abs/2309.07720v1"},"cats":{"new-dataset":0.0143510639,"dev-research":0.3441502357,"data-quality":0.0725452559}}
{"text":"Using the benchmark inferential decision problem known as ``treasure hunt\", this paper develops a general approach for investigating and modeling active perception solutions under pressure.","meta":{"url":"http://arxiv.org/abs/2309.07720v1"},"cats":{"new-dataset":0.0326765696,"dev-research":0.162807202,"data-quality":0.1614116325}}
{"text":"By simulating treasure hunt problems in virtual worlds, our approach learns generalizable strategies from high performers that, when applied to robots, allow them to modulate between optimal and heuristic solutions on the basis of external pressures and probabilistic models, if and when available.","meta":{"url":"http://arxiv.org/abs/2309.07720v1"},"cats":{"new-dataset":0.0408510916,"dev-research":0.1452407804,"data-quality":0.0739284645}}
{"text":"The result is a suite of active perception algorithms for camera-equipped robots that outperform treasure-hunt solutions obtained via cell decomposition, information roadmap, and information potential algorithms, in both high-fidelity numerical simulations and physical experiments.","meta":{"url":"http://arxiv.org/abs/2309.07720v1"},"cats":{"new-dataset":0.054530771,"dev-research":0.1196205971,"data-quality":0.0982297253}}
{"text":"The effectiveness of the new active perception strategies is demonstrated under a broad range of unanticipated conditions that cause existing algorithms to fail to complete the search for treasures, such as unmodelled time constraints, resource constraints, and adverse weather (fog).","meta":{"url":"http://arxiv.org/abs/2309.07720v1"},"cats":{"new-dataset":0.0246931952,"dev-research":0.1867735553,"data-quality":0.1052774368}}
{"text":"The phonological discrepancies between a speaker's native (L1) and the non-native language (L2) serves as a major factor for mispronunciation.","meta":{"url":"http://arxiv.org/abs/2309.07719v1"},"cats":{"new-dataset":0.026195113,"dev-research":0.2074924055,"data-quality":0.4280974699}}
{"text":"This paper introduces a novel multilingual MDD architecture, L1-MultiMDD, enriched with L1-aware speech representation.","meta":{"url":"http://arxiv.org/abs/2309.07719v1"},"cats":{"new-dataset":0.1988362468,"dev-research":0.1423599088,"data-quality":0.200403354}}
{"text":"An end-to-end speech encoder is trained on the input signal and its corresponding reference phoneme sequence.","meta":{"url":"http://arxiv.org/abs/2309.07719v1"},"cats":{"new-dataset":0.206536029,"dev-research":0.125812247,"data-quality":0.157675715}}
{"text":"First, an attention mechanism is deployed to align the input audio with the reference phoneme sequence.","meta":{"url":"http://arxiv.org/abs/2309.07719v1"},"cats":{"new-dataset":0.102989764,"dev-research":0.1485957882,"data-quality":0.1790785375}}
{"text":"Afterwards, the L1-L2-speech embedding are extracted from an auxiliary model, pretrained in a multi-task setup identifying L1 and L2 language, and are infused with the primary network.","meta":{"url":"http://arxiv.org/abs/2309.07719v1"},"cats":{"new-dataset":0.0746251945,"dev-research":0.1421224484,"data-quality":0.193974223}}
{"text":"Finally, the L1-MultiMDD is then optimized for a unified multilingual phoneme recognition task using connectionist temporal classification (CTC) loss for the target languages: English, Arabic, and Mandarin.","meta":{"url":"http://arxiv.org/abs/2309.07719v1"},"cats":{"new-dataset":0.2282565959,"dev-research":0.1007484846,"data-quality":0.2150292925}}
{"text":"Our experiments demonstrate the effectiveness of the proposed L1-MultiMDD framework on both seen -- L2-ARTIC, LATIC, and AraVoiceL2v2; and unseen -- EpaDB and Speechocean762 datasets.","meta":{"url":"http://arxiv.org/abs/2309.07719v1"},"cats":{"new-dataset":0.4866348579,"dev-research":0.0931243105,"data-quality":0.178450079}}
{"text":"The consistent gains in PER, and false rejection rate (FRR) across all target languages confirm our approach's robustness, efficacy, and generalizability.","meta":{"url":"http://arxiv.org/abs/2309.07719v1"},"cats":{"new-dataset":0.0090465608,"dev-research":0.2117749766,"data-quality":0.3106213431}}
{"text":"Our goal is to create a realistic 3D facial avatar with hair and accessories using only a text description.","meta":{"url":"http://arxiv.org/abs/2309.07125v1"},"cats":{"new-dataset":0.1400102202,"dev-research":0.1812428834,"data-quality":0.1032681066}}
{"text":"While this challenge has attracted significant recent interest, existing methods either lack realism, produce unrealistic shapes, or do not support editing, such as modifications to the hairstyle.","meta":{"url":"http://arxiv.org/abs/2309.07125v1"},"cats":{"new-dataset":0.0264052727,"dev-research":0.2411758839,"data-quality":0.1361982173}}
{"text":"We argue that existing methods are limited because they employ a monolithic modeling approach, using a single representation for the head, face, hair, and accessories.","meta":{"url":"http://arxiv.org/abs/2309.07125v1"},"cats":{"new-dataset":0.0235923504,"dev-research":0.1969275406,"data-quality":0.0733284603}}
{"text":"Our observation is that the hair and face, for example, have very different structural qualities that benefit from different representations.","meta":{"url":"http://arxiv.org/abs/2309.07125v1"},"cats":{"new-dataset":0.0043957072,"dev-research":0.1904444545,"data-quality":0.0846607224}}
{"text":"Building on this insight, we generate avatars with a compositional model, in which the head, face, and upper body are represented with traditional 3D meshes, and the hair, clothing, and accessories with neural radiance fields (NeRF).","meta":{"url":"http://arxiv.org/abs/2309.07125v1"},"cats":{"new-dataset":0.1631960633,"dev-research":0.1932521783,"data-quality":0.0641091726}}
{"text":"The model-based mesh representation provides a strong geometric prior for the face region, improving realism while enabling editing of the person's appearance.","meta":{"url":"http://arxiv.org/abs/2309.07125v1"},"cats":{"new-dataset":0.0345402444,"dev-research":0.2704510105,"data-quality":0.0579674675}}
{"text":"By using NeRFs to represent the remaining components, our method is able to model and synthesize parts with complex geometry and appearance, such as curly hair and fluffy scarves.","meta":{"url":"http://arxiv.org/abs/2309.07125v1"},"cats":{"new-dataset":0.061916562,"dev-research":0.2744538813,"data-quality":0.1058011251}}
{"text":"Our novel system synthesizes these high-quality compositional avatars from text descriptions.","meta":{"url":"http://arxiv.org/abs/2309.07125v1"},"cats":{"new-dataset":0.1633123557,"dev-research":0.2024853085,"data-quality":0.2076157351}}
{"text":"The experimental results demonstrate that our method, Text-guided generation and Editing of Compositional Avatars (TECA), produces avatars that are more realistic than those of recent methods while being editable because of their compositional nature.","meta":{"url":"http://arxiv.org/abs/2309.07125v1"},"cats":{"new-dataset":0.0525648949,"dev-research":0.2730799104,"data-quality":0.136525598}}
{"text":"For example, our TECA enables the seamless transfer of compositional features like hairstyles, scarves, and other accessories between avatars.","meta":{"url":"http://arxiv.org/abs/2309.07125v1"},"cats":{"new-dataset":0.0520086686,"dev-research":0.2132593231,"data-quality":0.0588312244}}
{"text":"This capability supports applications such as virtual try-on.","meta":{"url":"http://arxiv.org/abs/2309.07125v1"},"cats":{"new-dataset":0.0129219774,"dev-research":0.2635642026,"data-quality":0.0767571429}}
{"text":"Large language models (LLMs) often demonstrate inconsistencies with human preferences.","meta":{"url":"http://arxiv.org/abs/2309.07124v1"},"cats":{"new-dataset":0.0181360961,"dev-research":0.16015028,"data-quality":0.2567990104}}
{"text":"Previous research gathered human preference data and then aligned the pre-trained models using reinforcement learning or instruction tuning, the so-called finetuning step.","meta":{"url":"http://arxiv.org/abs/2309.07124v1"},"cats":{"new-dataset":0.0265335859,"dev-research":0.2228074032,"data-quality":0.0985160542}}
{"text":"In contrast, aligning frozen LLMs without any extra data is more appealing.","meta":{"url":"http://arxiv.org/abs/2309.07124v1"},"cats":{"new-dataset":0.0101574161,"dev-research":0.1161694136,"data-quality":0.105758974}}
{"text":"This work explores the potential of the latter setting.","meta":{"url":"http://arxiv.org/abs/2309.07124v1"},"cats":{"new-dataset":0.038452332,"dev-research":0.1885881892,"data-quality":0.0560639639}}
{"text":"We discover that by integrating self-evaluation and rewind mechanisms, unaligned LLMs can directly produce responses consistent with human preferences via self-boosting.","meta":{"url":"http://arxiv.org/abs/2309.07124v1"},"cats":{"new-dataset":0.0079374026,"dev-research":0.1170290134,"data-quality":0.1656835071}}
{"text":"We introduce a novel inference method, Rewindable Auto-regressive INference (RAIN), that allows pre-trained LLMs to evaluate their own generation and use the evaluation results to guide backward rewind and forward generation for AI safety.","meta":{"url":"http://arxiv.org/abs/2309.07124v1"},"cats":{"new-dataset":0.0631279463,"dev-research":0.2145286431,"data-quality":0.1070033431}}
{"text":"Notably, RAIN operates without the need of extra data for model alignment and abstains from any training, gradient computation, or parameter updates; during the self-evaluation phase, the model receives guidance on which human preference to align with through a fixed-template prompt, eliminating the need to modify the initial prompt.","meta":{"url":"http://arxiv.org/abs/2309.07124v1"},"cats":{"new-dataset":0.0136061149,"dev-research":0.277959341,"data-quality":0.1323889495}}
{"text":"Experimental results evaluated by GPT-4 and humans demonstrate the effectiveness of RAIN: on the HH dataset, RAIN improves the harmlessness rate of LLaMA 30B over vanilla inference from 82% to 97%, while maintaining the helpfulness rate.","meta":{"url":"http://arxiv.org/abs/2309.07124v1"},"cats":{"new-dataset":0.0791996282,"dev-research":0.1891670119,"data-quality":0.1565833048}}
{"text":"Under the leading adversarial attack llm-attacks on Vicuna 33B, RAIN establishes a new defense baseline by reducing the attack success rate from 94% to 19%.","meta":{"url":"http://arxiv.org/abs/2309.07124v1"},"cats":{"new-dataset":0.0884706513,"dev-research":0.1892021454,"data-quality":0.1330090956}}
{"text":"We study inferring a tree-structured representation from a single image for object shading.","meta":{"url":"http://arxiv.org/abs/2309.07122v1"},"cats":{"new-dataset":0.1369923838,"dev-research":0.1556025818,"data-quality":0.1323488277}}
{"text":"Prior work typically uses the parametric or measured representation to model shading, which is neither interpretable nor easily editable.","meta":{"url":"http://arxiv.org/abs/2309.07122v1"},"cats":{"new-dataset":0.0036726333,"dev-research":0.2737883447,"data-quality":0.1049954608}}
{"text":"We propose using the shade tree representation, which combines basic shading nodes and compositing methods to factorize object surface shading.","meta":{"url":"http://arxiv.org/abs/2309.07122v1"},"cats":{"new-dataset":0.0413929795,"dev-research":0.2351001789,"data-quality":0.0839779075}}
{"text":"The shade tree representation enables novice users who are unfamiliar with the physical shading process to edit object shading in an efficient and intuitive manner.","meta":{"url":"http://arxiv.org/abs/2309.07122v1"},"cats":{"new-dataset":0.018294362,"dev-research":0.3691940587,"data-quality":0.1062933551}}
{"text":"A main challenge in inferring the shade tree is that the inference problem involves both the discrete tree structure and the continuous parameters of the tree nodes.","meta":{"url":"http://arxiv.org/abs/2309.07122v1"},"cats":{"new-dataset":0.0452847159,"dev-research":0.1311369316,"data-quality":0.1250984697}}
{"text":"We propose a hybrid approach to address this issue.","meta":{"url":"http://arxiv.org/abs/2309.07122v1"},"cats":{"new-dataset":0.0160404593,"dev-research":0.2126408411,"data-quality":0.1396375734}}
{"text":"We introduce an auto-regressive inference model to generate a rough estimation of the tree structure and node parameters, and then we fine-tune the inferred shade tree through an optimization algorithm.","meta":{"url":"http://arxiv.org/abs/2309.07122v1"},"cats":{"new-dataset":0.0587091307,"dev-research":0.1558781729,"data-quality":0.1249665299}}
{"text":"We show experiments on synthetic images, captured reflectance, real images, and non-realistic vector drawings, allowing downstream applications such as material editing, vectorized shading, and relighting.","meta":{"url":"http://arxiv.org/abs/2309.07122v1"},"cats":{"new-dataset":0.091766253,"dev-research":0.2336518271,"data-quality":0.0914198078}}
{"text":"Project website: https://chen-geng.com/inv-shade-trees","meta":{"url":"http://arxiv.org/abs/2309.07122v1"},"cats":{"new-dataset":0.5048718953,"dev-research":0.1697626072,"data-quality":0.0596400911}}
{"text":"Multi-modal large language models (MLLMs) are trained based on large language models (LLM), with an enhanced capability to comprehend multi-modal inputs and generate textual responses.","meta":{"url":"http://arxiv.org/abs/2309.07120v1"},"cats":{"new-dataset":0.1592640175,"dev-research":0.1077302274,"data-quality":0.1262735888}}
{"text":"While they excel in multi-modal tasks, the pure NLP abilities of MLLMs are often underestimated and left untested.","meta":{"url":"http://arxiv.org/abs/2309.07120v1"},"cats":{"new-dataset":0.0243553934,"dev-research":0.175285955,"data-quality":0.1964619538}}
{"text":"In this study, we get out of the box and unveil an intriguing characteristic of MLLMs -- our preliminary results suggest that visual instruction tuning, a prevailing strategy for transitioning LLMs into MLLMs, unexpectedly and interestingly helps models attain both improved truthfulness and ethical alignment in the pure NLP context.","meta":{"url":"http://arxiv.org/abs/2309.07120v1"},"cats":{"new-dataset":0.1091666399,"dev-research":0.2416799251,"data-quality":0.1872237726}}
{"text":"For example, a visual-instruction-tuned LLaMA2 7B model surpasses the performance of the LLaMA2-chat 7B model, fine-tuned with over one million human annotations, on TruthfulQA-mc and Ethics benchmarks.","meta":{"url":"http://arxiv.org/abs/2309.07120v1"},"cats":{"new-dataset":0.1561493999,"dev-research":0.1833236969,"data-quality":0.1519104983}}
{"text":"Further analysis reveals that the improved alignment can be attributed to the superior instruction quality inherent to visual-text data.","meta":{"url":"http://arxiv.org/abs/2309.07120v1"},"cats":{"new-dataset":0.1219664934,"dev-research":0.3050970099,"data-quality":0.2611189279}}
{"text":"In releasing our code at github.com/UCSC-VLAA/Sight-Beyond-Text, we aspire to foster further exploration into the intrinsic value of visual-text synergies and, in a broader scope, multi-modal interactions in alignment research.","meta":{"url":"http://arxiv.org/abs/2309.07120v1"},"cats":{"new-dataset":0.1118100612,"dev-research":0.2487545145,"data-quality":0.1173539394}}
{"text":"While traditional machine learning can effectively tackle a wide range of problems, it primarily operates within a closed-world setting, which presents limitations when dealing with streaming data.","meta":{"url":"http://arxiv.org/abs/2309.07117v1"},"cats":{"new-dataset":0.03343661,"dev-research":0.2175212153,"data-quality":0.1573638284}}
{"text":"As a solution, incremental learning emerges to address real-world scenarios involving new data's arrival.","meta":{"url":"http://arxiv.org/abs/2309.07117v1"},"cats":{"new-dataset":0.2321900521,"dev-research":0.2790513016,"data-quality":0.1293064022}}
{"text":"Recently, pre-training has made significant advancements and garnered the attention of numerous researchers.","meta":{"url":"http://arxiv.org/abs/2309.07117v1"},"cats":{"new-dataset":0.0403782419,"dev-research":0.2513191901,"data-quality":0.08272905}}
{"text":"The strong performance of these pre-trained models (PTMs) presents a promising avenue for developing continual learning algorithms that can effectively adapt to real-world scenarios.","meta":{"url":"http://arxiv.org/abs/2309.07117v1"},"cats":{"new-dataset":0.0582971706,"dev-research":0.1670724564,"data-quality":0.1017741354}}
{"text":"Consequently, exploring the utilization of PTMs in incremental learning has become essential.","meta":{"url":"http://arxiv.org/abs/2309.07117v1"},"cats":{"new-dataset":0.0288107256,"dev-research":0.2263148139,"data-quality":0.0819969444}}
{"text":"This paper introduces a pre-trained model-based continual learning toolbox known as PILOT.","meta":{"url":"http://arxiv.org/abs/2309.07117v1"},"cats":{"new-dataset":0.0906514929,"dev-research":0.2427085706,"data-quality":0.1415898397}}
{"text":"On the one hand, PILOT implements some state-of-the-art class-incremental learning algorithms based on pre-trained models, such as L2P, DualPrompt, and CODA-Prompt.","meta":{"url":"http://arxiv.org/abs/2309.07117v1"},"cats":{"new-dataset":0.0424942714,"dev-research":0.2141277697,"data-quality":0.1119751721}}
{"text":"On the other hand, PILOT also fits typical class-incremental learning algorithms (e.g., DER, FOSTER, and MEMO) within the context of pre-trained models to evaluate their effectiveness.","meta":{"url":"http://arxiv.org/abs/2309.07117v1"},"cats":{"new-dataset":0.0102650566,"dev-research":0.2504293256,"data-quality":0.119328537}}
{"text":"In this paper, we present a methodology for achieving robust multimodal person representations optimized for open-set audio-visual speaker verification.","meta":{"url":"http://arxiv.org/abs/2309.07115v1"},"cats":{"new-dataset":0.2090826872,"dev-research":0.1973213078,"data-quality":0.1443930031}}
{"text":"Distance Metric Learning (DML) approaches have typically dominated this problem space, owing to strong performance on new and unseen classes.","meta":{"url":"http://arxiv.org/abs/2309.07115v1"},"cats":{"new-dataset":0.1314103243,"dev-research":0.2075548236,"data-quality":0.2590029204}}
{"text":"In our work, we explored multitask learning techniques to further boost performance of the DML approach and show that an auxiliary task with weak labels can increase the compactness of the learned speaker representation.","meta":{"url":"http://arxiv.org/abs/2309.07115v1"},"cats":{"new-dataset":0.0889834954,"dev-research":0.1400993749,"data-quality":0.2610008373}}
{"text":"We also extend the Generalized end-to-end loss (GE2E) to multimodal inputs and demonstrate that it can achieve competitive performance in an audio-visual space.","meta":{"url":"http://arxiv.org/abs/2309.07115v1"},"cats":{"new-dataset":0.0643351322,"dev-research":0.1686224434,"data-quality":0.1628344516}}
{"text":"Finally, we introduce a non-synchronous audio-visual sampling random strategy during training time that has shown to improve generalization.","meta":{"url":"http://arxiv.org/abs/2309.07115v1"},"cats":{"new-dataset":0.0867232939,"dev-research":0.1470535458,"data-quality":0.2071890248}}
{"text":"Our network achieves state of the art performance for speaker verification, reporting 0.244%, 0.252%, 0.441% Equal Error Rate (EER) on the three official trial lists of VoxCeleb1-O/E/H, which is to our knowledge, the best published results on VoxCeleb1-E and VoxCeleb1-H.","meta":{"url":"http://arxiv.org/abs/2309.07115v1"},"cats":{"new-dataset":0.1048334404,"dev-research":0.2187106756,"data-quality":0.3442376449}}
{"text":"Deep neural network models can learn clinically relevant features from millions of histopathology images.","meta":{"url":"http://arxiv.org/abs/2309.07113v1"},"cats":{"new-dataset":0.2309489961,"dev-research":0.242956651,"data-quality":0.1094488903}}
{"text":"However generating high-quality annotations to train such models for each hospital, each cancer type, and each diagnostic task is prohibitively laborious.","meta":{"url":"http://arxiv.org/abs/2309.07113v1"},"cats":{"new-dataset":0.1563934171,"dev-research":0.2758646743,"data-quality":0.3620225265}}
{"text":"On the other hand, terabytes of training data -- while lacking reliable annotations -- are readily available in the public domain in some cases.","meta":{"url":"http://arxiv.org/abs/2309.07113v1"},"cats":{"new-dataset":0.2609255686,"dev-research":0.1923238485,"data-quality":0.2689610933}}
{"text":"In this work, we explore how these large datasets can be consciously utilized to pre-train deep networks to encode informative representations.","meta":{"url":"http://arxiv.org/abs/2309.07113v1"},"cats":{"new-dataset":0.3422898579,"dev-research":0.1870178991,"data-quality":0.1340225461}}
{"text":"We then fine-tune our pre-trained models on a fraction of annotated training data to perform specific downstream tasks.","meta":{"url":"http://arxiv.org/abs/2309.07113v1"},"cats":{"new-dataset":0.1248581644,"dev-research":0.2036938777,"data-quality":0.3023611865}}
{"text":"We show that our approach can reach the state-of-the-art (SOTA) for patch-level classification with only 1-10% randomly selected annotations compared to other SOTA approaches.","meta":{"url":"http://arxiv.org/abs/2309.07113v1"},"cats":{"new-dataset":0.4457791801,"dev-research":0.2358153624,"data-quality":0.551437874}}
{"text":"Moreover, we propose an uncertainty-aware loss function, to quantify the model confidence during inference.","meta":{"url":"http://arxiv.org/abs/2309.07113v1"},"cats":{"new-dataset":0.0123994946,"dev-research":0.2053389011,"data-quality":0.2677084747}}
{"text":"Quantified uncertainty helps experts select the best instances to label for further training.","meta":{"url":"http://arxiv.org/abs/2309.07113v1"},"cats":{"new-dataset":0.0182875618,"dev-research":0.237680392,"data-quality":0.3770810725}}
{"text":"Our uncertainty-aware labeling reaches the SOTA with significantly fewer annotations compared to random labeling.","meta":{"url":"http://arxiv.org/abs/2309.07113v1"},"cats":{"new-dataset":0.0961907324,"dev-research":0.2141649118,"data-quality":0.6736142353}}
{"text":"Last, we demonstrate how our pre-trained encoders can surpass current SOTA for whole-slide image classification with weak supervision.","meta":{"url":"http://arxiv.org/abs/2309.07113v1"},"cats":{"new-dataset":0.1471903543,"dev-research":0.1524608034,"data-quality":0.190286493}}
{"text":"Our work lays the foundation for data and task-agnostic pre-trained deep networks with quantified uncertainty.","meta":{"url":"http://arxiv.org/abs/2309.07113v1"},"cats":{"new-dataset":0.2028301894,"dev-research":0.1791209927,"data-quality":0.1819073228}}
{"text":"Multi-Agent Reinforcement Learning (MARL) has achieved significant success in large-scale AI systems and big-data applications such as smart grids, surveillance, etc.","meta":{"url":"http://arxiv.org/abs/2309.07108v1"},"cats":{"new-dataset":0.1430186556,"dev-research":0.0990139482,"data-quality":0.0478152845}}
{"text":"Existing advancements in MARL algorithms focus on improving the rewards obtained by introducing various mechanisms for inter-agent cooperation.","meta":{"url":"http://arxiv.org/abs/2309.07108v1"},"cats":{"new-dataset":0.0177699099,"dev-research":0.1101827399,"data-quality":0.0461671167}}
{"text":"However, these optimizations are usually compute- and memory-intensive, thus leading to suboptimal speed performance in end-to-end training time.","meta":{"url":"http://arxiv.org/abs/2309.07108v1"},"cats":{"new-dataset":0.0071042247,"dev-research":0.2089647932,"data-quality":0.0642747461}}
{"text":"In this work, we analyze the speed performance (i.e., latency-bounded throughput) as the key metric in MARL implementations.","meta":{"url":"http://arxiv.org/abs/2309.07108v1"},"cats":{"new-dataset":0.0546058213,"dev-research":0.157131167,"data-quality":0.0617225814}}
{"text":"Specifically, we first introduce a taxonomy of MARL algorithms from an acceleration perspective categorized by (1) training scheme and (2) communication method.","meta":{"url":"http://arxiv.org/abs/2309.07108v1"},"cats":{"new-dataset":0.0414118541,"dev-research":0.1195810138,"data-quality":0.0851183386}}
{"text":"Using our taxonomy, we identify three state-of-the-art MARL algorithms - Multi-Agent Deep Deterministic Policy Gradient (MADDPG), Target-oriented Multi-agent Communication and Cooperation (ToM2C), and Networked Multi-Agent RL (NeurComm) - as target benchmark algorithms, and provide a systematic analysis of their performance bottlenecks on a homogeneous multi-core CPU platform.","meta":{"url":"http://arxiv.org/abs/2309.07108v1"},"cats":{"new-dataset":0.1169384433,"dev-research":0.1387040727,"data-quality":0.0501326354}}
{"text":"We justify the need for MARL latency-bounded throughput to be a key performance metric in future literature while also addressing opportunities for parallelization and acceleration.","meta":{"url":"http://arxiv.org/abs/2309.07108v1"},"cats":{"new-dataset":0.026976656,"dev-research":0.1623538273,"data-quality":0.0525272105}}
{"text":"RGB-D object recognition systems improve their predictive performances by fusing color and depth information, outperforming neural network architectures that rely solely on colors.","meta":{"url":"http://arxiv.org/abs/2309.07106v1"},"cats":{"new-dataset":0.0956739609,"dev-research":0.154610208,"data-quality":0.1766273855}}
{"text":"While RGB-D systems are expected to be more robust to adversarial examples than RGB-only systems, they have also been proven to be highly vulnerable.","meta":{"url":"http://arxiv.org/abs/2309.07106v1"},"cats":{"new-dataset":0.0340811627,"dev-research":0.2015887671,"data-quality":0.2485147923}}
{"text":"Their robustness is similar even when the adversarial examples are generated by altering only the original images' colors.","meta":{"url":"http://arxiv.org/abs/2309.07106v1"},"cats":{"new-dataset":0.0212108133,"dev-research":0.2193441323,"data-quality":0.3577590239}}
{"text":"Different works highlighted the vulnerability of RGB-D systems; however, there is a lacking of technical explanations for this weakness.","meta":{"url":"http://arxiv.org/abs/2309.07106v1"},"cats":{"new-dataset":0.0174669071,"dev-research":0.2295542214,"data-quality":0.217028107}}
{"text":"Hence, in our work, we bridge this gap by investigating the learned deep representation of RGB-D systems, discovering that color features make the function learned by the network more complex and, thus, more sensitive to small perturbations.","meta":{"url":"http://arxiv.org/abs/2309.07106v1"},"cats":{"new-dataset":0.0937293131,"dev-research":0.1943512586,"data-quality":0.202787587}}
{"text":"To mitigate this problem, we propose a defense based on a detection mechanism that makes RGB-D systems more robust against adversarial examples.","meta":{"url":"http://arxiv.org/abs/2309.07106v1"},"cats":{"new-dataset":0.0682562692,"dev-research":0.2216998255,"data-quality":0.2909121376}}
{"text":"We empirically show that this defense improves the performances of RGB-D systems against adversarial examples even when they are computed ad-hoc to circumvent this detection mechanism, and that is also more effective than adversarial training.","meta":{"url":"http://arxiv.org/abs/2309.07106v1"},"cats":{"new-dataset":0.0497958418,"dev-research":0.2206097218,"data-quality":0.254073868}}
{"text":"Monocular 3D object detection is a challenging task because depth information is difficult to obtain from 2D images.","meta":{"url":"http://arxiv.org/abs/2309.07104v1"},"cats":{"new-dataset":0.0375398293,"dev-research":0.1420001057,"data-quality":0.1305203147}}
{"text":"A subset of viewpoint-agnostic monocular 3D detection methods also do not explicitly leverage scene homography or geometry during training, meaning that a model trained thusly can detect objects in images from arbitrary viewpoints.","meta":{"url":"http://arxiv.org/abs/2309.07104v1"},"cats":{"new-dataset":0.0180862972,"dev-research":0.149930398,"data-quality":0.1300760633}}
{"text":"Such works predict the projections of the 3D bounding boxes on the image plane to estimate the location of the 3D boxes, but these projections are not rectangular so the calculation of IoU between these projected polygons is not straightforward.","meta":{"url":"http://arxiv.org/abs/2309.07104v1"},"cats":{"new-dataset":0.0325810495,"dev-research":0.142366932,"data-quality":0.0552538342}}
{"text":"This work proposes an efficient, fully differentiable algorithm for the calculation of IoU between two convex polygons, which can be utilized to compute the IoU between two 3D bounding box footprints viewed from an arbitrary angle.","meta":{"url":"http://arxiv.org/abs/2309.07104v1"},"cats":{"new-dataset":0.0416776998,"dev-research":0.222342475,"data-quality":0.0533906623}}
{"text":"We test the performance of the proposed polygon IoU loss (PIoU loss) on three state-of-the-art viewpoint-agnostic 3D detection models.","meta":{"url":"http://arxiv.org/abs/2309.07104v1"},"cats":{"new-dataset":0.0367828988,"dev-research":0.1336233531,"data-quality":0.1230917998}}
{"text":"Experiments demonstrate that the proposed PIoU loss converges faster than L1 loss and that in 3D detection models, a combination of PIoU loss and L1 loss gives better results than L1 loss alone (+1.64% AP70 for MonoCon on cars, +0.18% AP70 for RTM3D on cars, and +0.83%/+2.46% AP50/AP25 for MonoRCNN on cyclists).","meta":{"url":"http://arxiv.org/abs/2309.07104v1"},"cats":{"new-dataset":0.0476211293,"dev-research":0.1332306529,"data-quality":0.1407591445}}
{"text":"Hallucinations and off-target translation remain unsolved problems in machine translation, especially for low-resource languages and massively multilingual models.","meta":{"url":"http://arxiv.org/abs/2309.07098v1"},"cats":{"new-dataset":0.0699890851,"dev-research":0.2303311633,"data-quality":0.3112400468}}
{"text":"In this paper, we introduce methods to mitigate both failure cases with a modified decoding objective, without requiring retraining or external models.","meta":{"url":"http://arxiv.org/abs/2309.07098v1"},"cats":{"new-dataset":0.0126695992,"dev-research":0.229682,"data-quality":0.4898428007}}
{"text":"In source-contrastive decoding, we search for a translation that is probable given the correct input, but improbable given a random input segment, hypothesising that hallucinations will be similarly probable given either.","meta":{"url":"http://arxiv.org/abs/2309.07098v1"},"cats":{"new-dataset":0.0374857906,"dev-research":0.1786143911,"data-quality":0.2611641317}}
{"text":"In language-contrastive decoding, we search for a translation that is probable, but improbable given the wrong language indicator token.","meta":{"url":"http://arxiv.org/abs/2309.07098v1"},"cats":{"new-dataset":0.0278868051,"dev-research":0.1630197477,"data-quality":0.3992059286}}
{"text":"In experiments on M2M-100 (418M) and SMaLL-100, we find that these methods effectively suppress hallucinations and off-target translations, improving chrF2 by 1.7 and 1.4 points on average across 57 tested translation directions.","meta":{"url":"http://arxiv.org/abs/2309.07098v1"},"cats":{"new-dataset":0.0320928806,"dev-research":0.1717164602,"data-quality":0.1985929356}}
{"text":"In a proof of concept on English--German, we also show that we can suppress off-target translations with the Llama 2 chat models, demonstrating the applicability of the method to machine translation with LLMs.","meta":{"url":"http://arxiv.org/abs/2309.07098v1"},"cats":{"new-dataset":0.0950283751,"dev-research":0.1705523765,"data-quality":0.2513019811}}
{"text":"We release our source code at https://github.com/ZurichNLP/ContraDecode.","meta":{"url":"http://arxiv.org/abs/2309.07098v1"},"cats":{"new-dataset":0.3241039955,"dev-research":0.3035325154,"data-quality":0.1985462801}}
{"text":"Loop Closure Detection (LCD) is an essential task in robotics and computer vision, serving as a fundamental component for various applications across diverse domains.","meta":{"url":"http://arxiv.org/abs/2309.07094v1"},"cats":{"new-dataset":0.1428419571,"dev-research":0.2518522572,"data-quality":0.2079575951}}
{"text":"These applications encompass object recognition, image retrieval, and video analysis.","meta":{"url":"http://arxiv.org/abs/2309.07094v1"},"cats":{"new-dataset":0.0761848531,"dev-research":0.1427853069,"data-quality":0.1141178923}}
{"text":"LCD consists in identifying whether a robot has returned to a previously visited location, referred to as a loop, and then estimating the related roto-translation with respect to the analyzed location.","meta":{"url":"http://arxiv.org/abs/2309.07094v1"},"cats":{"new-dataset":0.1757278994,"dev-research":0.2787864418,"data-quality":0.1514531585}}
{"text":"Despite the numerous advantages of radar sensors, such as their ability to operate under diverse weather conditions and provide a wider range of view compared to other commonly used sensors (e.g., cameras or LiDARs), integrating radar data remains an arduous task due to intrinsic noise and distortion.","meta":{"url":"http://arxiv.org/abs/2309.07094v1"},"cats":{"new-dataset":0.0383874102,"dev-research":0.2178730782,"data-quality":0.1141430225}}
{"text":"To address this challenge, this research introduces RadarLCD, a novel supervised deep learning pipeline specifically designed for Loop Closure Detection using the FMCW Radar (Frequency Modulated Continuous Wave) sensor.","meta":{"url":"http://arxiv.org/abs/2309.07094v1"},"cats":{"new-dataset":0.2867686662,"dev-research":0.2024589559,"data-quality":0.1757396228}}
{"text":"RadarLCD, a learning-based LCD methodology explicitly designed for radar systems, makes a significant contribution by leveraging the pre-trained HERO (Hybrid Estimation Radar Odometry) model.","meta":{"url":"http://arxiv.org/abs/2309.07094v1"},"cats":{"new-dataset":0.1525727249,"dev-research":0.2535919434,"data-quality":0.0900125534}}
{"text":"Being originally developed for radar odometry, HERO's features are used to select key points crucial for LCD tasks.","meta":{"url":"http://arxiv.org/abs/2309.07094v1"},"cats":{"new-dataset":0.0503419306,"dev-research":0.3104715123,"data-quality":0.0735616443}}
{"text":"The methodology undergoes evaluation across a variety of FMCW Radar dataset scenes, and it is compared to state-of-the-art systems such as Scan Context for Place Recognition and ICP for Loop Closure.","meta":{"url":"http://arxiv.org/abs/2309.07094v1"},"cats":{"new-dataset":0.3816705638,"dev-research":0.1926425394,"data-quality":0.149785094}}
{"text":"The results demonstrate that RadarLCD surpasses the alternatives in multiple aspects of Loop Closure Detection.","meta":{"url":"http://arxiv.org/abs/2309.07094v1"},"cats":{"new-dataset":0.0812811719,"dev-research":0.2193449863,"data-quality":0.1916059882}}
{"text":"Objective: Neoadjuvant chemotherapy (NACT) is one kind of treatment for advanced stage ovarian cancer patients.","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.062964803,"dev-research":0.2048859552,"data-quality":0.0914290732}}
{"text":"However, due to the nature of tumor heterogeneity, the patients' responses to NACT varies significantly among different subgroups.","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.0563196142,"dev-research":0.1644959029,"data-quality":0.0930004422}}
{"text":"To address this clinical challenge, the purpose of this study is to develop a novel image marker to achieve high accuracy response prediction of the NACT at an early stage.","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.2197545445,"dev-research":0.1569532521,"data-quality":0.1594621802}}
{"text":"Methods: For this purpose, we first computed a total of 1373 radiomics features to quantify the tumor characteristics, which can be grouped into three categories: geometric, intensity, and texture features.","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.4087801198,"dev-research":0.1273937939,"data-quality":0.0985350869}}
{"text":"Second, all these features were optimized by principal component analysis algorithm to generate a compact and informative feature cluster.","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.06443084,"dev-research":0.2164728993,"data-quality":0.108997417}}
{"text":"Using this cluster as the input, an SVM based classifier was developed and optimized to create a final marker, indicating the likelihood of the patient being responsive to the NACT treatment.","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.0964119306,"dev-research":0.1926634716,"data-quality":0.188316975}}
{"text":"To validate this scheme, a total of 42 ovarian cancer patients were retrospectively collected.","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.0466852629,"dev-research":0.2268947392,"data-quality":0.1042680018}}
{"text":"A nested leave-one-out cross-validation was adopted for model performance assessment.","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.0097310549,"dev-research":0.190533101,"data-quality":0.1012605925}}
{"text":"Results:","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.2425207075,"dev-research":0.140469601,"data-quality":0.2085862739}}
{"text":"The results demonstrate that the new method yielded an AUC (area under the ROC","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.0155008186,"dev-research":0.1645759392,"data-quality":0.2139824836}}
{"text":"[receiver characteristic operation] curve) of 0.745.","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.0722420424,"dev-research":0.1182489156,"data-quality":0.123561786}}
{"text":"Meanwhile, the model achieved overall accuracy of 76.2%, positive predictive value of 70%, and negative predictive value of 78.1%.","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.0236089436,"dev-research":0.176479786,"data-quality":0.2101238438}}
{"text":"Conclusion:","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.0690399026,"dev-research":0.2438497228,"data-quality":0.1610826861}}
{"text":"This study provides meaningful information for the development of radiomics based image markers in NACT response prediction.","meta":{"url":"http://arxiv.org/abs/2309.07087v1"},"cats":{"new-dataset":0.3906153954,"dev-research":0.145939066,"data-quality":0.1597228277}}
{"text":"Federated Learning is emerging as a privacy-preserving model training approach in distributed edge applications.","meta":{"url":"http://arxiv.org/abs/2309.07085v1"},"cats":{"new-dataset":0.0471982307,"dev-research":0.0937159718,"data-quality":0.1185600585}}
{"text":"As such, most edge deployments are heterogeneous in nature i.e., their sensing capabilities and environments vary across deployments.","meta":{"url":"http://arxiv.org/abs/2309.07085v1"},"cats":{"new-dataset":0.0102783163,"dev-research":0.2057364304,"data-quality":0.0690839432}}
{"text":"This edge heterogeneity violates the independence and identical distribution (IID) property of local data across clients and produces biased global models i.e. models that contribute to unfair decision-making and discrimination against a particular community or a group.","meta":{"url":"http://arxiv.org/abs/2309.07085v1"},"cats":{"new-dataset":0.0176538206,"dev-research":0.1606471791,"data-quality":0.20686527}}
{"text":"Existing bias mitigation techniques only focus on bias generated from label heterogeneity in non-IID data without accounting for domain variations due to feature heterogeneity and do not address global group-fairness property.   ","meta":{"url":"http://arxiv.org/abs/2309.07085v1"},"cats":{"new-dataset":0.014308145,"dev-research":0.1486209258,"data-quality":0.4749816572}}
{"text":"Our work proposes a group-fair FL framework that minimizes group-bias while preserving privacy and without resource utilization overhead.","meta":{"url":"http://arxiv.org/abs/2309.07085v1"},"cats":{"new-dataset":0.0693157408,"dev-research":0.1331468583,"data-quality":0.1001904053}}
{"text":"Our main idea is to leverage average conditional probabilities to compute a cross-domain group \\textit{importance weights} derived from heterogeneous training data to optimize the performance of the worst-performing group using a modified multiplicative weights update method.","meta":{"url":"http://arxiv.org/abs/2309.07085v1"},"cats":{"new-dataset":0.0342502622,"dev-research":0.1271775097,"data-quality":0.1437413592}}
{"text":"Additionally, we propose regularization techniques to minimize the difference between the worst and best-performing groups while making sure through our thresholding mechanism to strike a balance between bias reduction and group performance degradation.","meta":{"url":"http://arxiv.org/abs/2309.07085v1"},"cats":{"new-dataset":0.0073498275,"dev-research":0.1855815033,"data-quality":0.2500069144}}
{"text":"Our evaluation of human emotion recognition and image classification benchmarks assesses the fair decision-making of our framework in real-world heterogeneous settings.","meta":{"url":"http://arxiv.org/abs/2309.07085v1"},"cats":{"new-dataset":0.1530804769,"dev-research":0.1952881051,"data-quality":0.194156613}}
{"text":"In this paper, we propose a novel training strategy called SupFusion, which provides an auxiliary feature level supervision for effective LiDAR-Camera fusion and significantly boosts detection performance.","meta":{"url":"http://arxiv.org/abs/2309.07084v1"},"cats":{"new-dataset":0.049789037,"dev-research":0.2052007185,"data-quality":0.1562691998}}
{"text":"Our strategy involves a data enhancement method named Polar Sampling, which densifies sparse objects and trains an assistant model to generate high-quality features as the supervision.","meta":{"url":"http://arxiv.org/abs/2309.07084v1"},"cats":{"new-dataset":0.1625242592,"dev-research":0.1962798299,"data-quality":0.212728493}}
{"text":"These features are then used to train the LiDAR-Camera fusion model, where the fusion feature is optimized to simulate the generated high-quality features.","meta":{"url":"http://arxiv.org/abs/2309.07084v1"},"cats":{"new-dataset":0.0794296443,"dev-research":0.2161063445,"data-quality":0.1122488838}}
{"text":"Furthermore, we propose a simple yet effective deep fusion module, which contiguously gains superior performance compared with previous fusion methods with SupFusion strategy.","meta":{"url":"http://arxiv.org/abs/2309.07084v1"},"cats":{"new-dataset":0.0311669313,"dev-research":0.1938671923,"data-quality":0.0850520118}}
{"text":"In such a manner, our proposal shares the following advantages.","meta":{"url":"http://arxiv.org/abs/2309.07084v1"},"cats":{"new-dataset":0.0093908367,"dev-research":0.2318833052,"data-quality":0.0419148274}}
{"text":"Firstly, SupFusion introduces auxiliary feature-level supervision which could boost LiDAR-Camera detection performance without introducing extra inference costs.","meta":{"url":"http://arxiv.org/abs/2309.07084v1"},"cats":{"new-dataset":0.0127038153,"dev-research":0.2313881167,"data-quality":0.1167890925}}
{"text":"Secondly, the proposed deep fusion could continuously improve the detector's abilities.","meta":{"url":"http://arxiv.org/abs/2309.07084v1"},"cats":{"new-dataset":0.0129470786,"dev-research":0.1414744177,"data-quality":0.1321386968}}
{"text":"Our proposed SupFusion and deep fusion module is plug-and-play, we make extensive experiments to demonstrate its effectiveness.","meta":{"url":"http://arxiv.org/abs/2309.07084v1"},"cats":{"new-dataset":0.0246374717,"dev-research":0.1845508916,"data-quality":0.0707590954}}
{"text":"Specifically, we gain around 2% 3D mAP improvements on KITTI benchmark based on multiple LiDAR-Camera 3D detectors.","meta":{"url":"http://arxiv.org/abs/2309.07084v1"},"cats":{"new-dataset":0.0883065075,"dev-research":0.1607487636,"data-quality":0.1277562258}}
{"text":"In this work, we assess the theoretical limitations of determining guaranteed stability and accuracy of neural networks in classification tasks.","meta":{"url":"http://arxiv.org/abs/2309.07072v1"},"cats":{"new-dataset":0.0194004173,"dev-research":0.1465760833,"data-quality":0.3239577588}}
{"text":"We consider classical distribution-agnostic framework and algorithms minimising empirical risks and potentially subjected to some weights regularisation.","meta":{"url":"http://arxiv.org/abs/2309.07072v1"},"cats":{"new-dataset":0.0229581278,"dev-research":0.1253108987,"data-quality":0.2587908299}}
{"text":"We show that there is a large family of tasks for which computing and verifying ideal stable and accurate neural networks in the above settings is extremely challenging, if at all possible, even when such ideal solutions exist within the given class of neural architectures.","meta":{"url":"http://arxiv.org/abs/2309.07072v1"},"cats":{"new-dataset":0.0511133628,"dev-research":0.1579594791,"data-quality":0.2220477419}}
{"text":"Image reconstruction-based anomaly detection models are widely explored in industrial visual inspection.","meta":{"url":"http://arxiv.org/abs/2309.07068v1"},"cats":{"new-dataset":0.0803657363,"dev-research":0.2609984202,"data-quality":0.2788781667}}
{"text":"However, existing models usually suffer from the trade-off between normal reconstruction fidelity and abnormal reconstruction distinguishability, which damages the performance.","meta":{"url":"http://arxiv.org/abs/2309.07068v1"},"cats":{"new-dataset":0.0043136509,"dev-research":0.1756102848,"data-quality":0.1657184026}}
{"text":"In this paper, we find that the above trade-off can be better mitigated by leveraging the distinct frequency biases between normal and abnormal reconstruction errors.","meta":{"url":"http://arxiv.org/abs/2309.07068v1"},"cats":{"new-dataset":0.0345518726,"dev-research":0.1901817945,"data-quality":0.2901230872}}
{"text":"To this end, we propose Frequency-aware Image Restoration (FAIR), a novel self-supervised image restoration task that restores images from their high-frequency components.","meta":{"url":"http://arxiv.org/abs/2309.07068v1"},"cats":{"new-dataset":0.0928406032,"dev-research":0.1249542826,"data-quality":0.2768435464}}
{"text":"It enables precise reconstruction of normal patterns while mitigating unfavorable generalization to anomalies.","meta":{"url":"http://arxiv.org/abs/2309.07068v1"},"cats":{"new-dataset":0.0113328507,"dev-research":0.2143956601,"data-quality":0.1460162303}}
{"text":"Using only a simple vanilla UNet, FAIR achieves state-of-the-art performance with higher efficiency on various defect detection datasets.","meta":{"url":"http://arxiv.org/abs/2309.07068v1"},"cats":{"new-dataset":0.6088127273,"dev-research":0.2787621565,"data-quality":0.3319352846}}
{"text":"Code: https://github.com/liutongkun/FAIR.","meta":{"url":"http://arxiv.org/abs/2309.07068v1"},"cats":{"new-dataset":0.1961866195,"dev-research":0.1643270938,"data-quality":0.1695059722}}
{"text":"Data pipelines are an integral part of various modern data-driven systems.","meta":{"url":"http://arxiv.org/abs/2309.07067v1"},"cats":{"new-dataset":0.1946617324,"dev-research":0.2727217635,"data-quality":0.1050724309}}
{"text":"However, despite their importance, they are often unreliable and deliver poor-quality data.","meta":{"url":"http://arxiv.org/abs/2309.07067v1"},"cats":{"new-dataset":0.0650025564,"dev-research":0.2865235884,"data-quality":0.3867852323}}
{"text":"A critical step toward improving this situation is a solid understanding of the aspects contributing to the quality of data pipelines.","meta":{"url":"http://arxiv.org/abs/2309.07067v1"},"cats":{"new-dataset":0.1156851654,"dev-research":0.3671211119,"data-quality":0.2368738884}}
{"text":"Therefore, this article first introduces a taxonomy of 41 factors that influence the ability of data pipelines to provide quality data.","meta":{"url":"http://arxiv.org/abs/2309.07067v1"},"cats":{"new-dataset":0.1158921752,"dev-research":0.2846275981,"data-quality":0.1667109948}}
{"text":"The taxonomy is based on a multivocal literature review and validated by eight interviews with experts from the data engineering domain.","meta":{"url":"http://arxiv.org/abs/2309.07067v1"},"cats":{"new-dataset":0.106773596,"dev-research":0.3192333685,"data-quality":0.1540008683}}
{"text":"Data, infrastructure, life cycle management, development & deployment, and processing were found to be the main influencing themes.","meta":{"url":"http://arxiv.org/abs/2309.07067v1"},"cats":{"new-dataset":0.1876223249,"dev-research":0.3631961181,"data-quality":0.0660324719}}
{"text":"Second, we investigate the root causes of data-related issues, their location in data pipelines, and the main topics of data pipeline processing issues for developers by mining GitHub projects and Stack Overflow posts.","meta":{"url":"http://arxiv.org/abs/2309.07067v1"},"cats":{"new-dataset":0.4265030728,"dev-research":0.4875402469,"data-quality":0.3014457341}}
{"text":"We found data-related issues to be primarily caused by incorrect data types (33%), mainly occurring in the data cleaning stage of pipelines (35%).","meta":{"url":"http://arxiv.org/abs/2309.07067v1"},"cats":{"new-dataset":0.2022733425,"dev-research":0.326156375,"data-quality":0.4446833099}}
{"text":"Data integration and ingestion tasks were found to be the most asked topics of developers, accounting for nearly half (47%) of all questions.","meta":{"url":"http://arxiv.org/abs/2309.07067v1"},"cats":{"new-dataset":0.2163832475,"dev-research":0.395757911,"data-quality":0.1176988527}}
{"text":"Compatibility issues were found to be a separate problem area in addition to issues corresponding to the usual data pipeline processing areas (i.e., data loading, ingestion, integration, cleaning, and transformation).","meta":{"url":"http://arxiv.org/abs/2309.07067v1"},"cats":{"new-dataset":0.0502239421,"dev-research":0.2715923969,"data-quality":0.2333759242}}
{"text":"These findings suggest that future research efforts should focus on analyzing compatibility and data type issues in more depth and assisting developers in data integration and ingestion tasks.","meta":{"url":"http://arxiv.org/abs/2309.07067v1"},"cats":{"new-dataset":0.1053932644,"dev-research":0.4219210285,"data-quality":0.1352241385}}
{"text":"The proposed taxonomy is valuable to practitioners in the context of quality assurance activities and fosters future research into data pipeline quality.","meta":{"url":"http://arxiv.org/abs/2309.07067v1"},"cats":{"new-dataset":0.1699172439,"dev-research":0.3766071982,"data-quality":0.2304541118}}
{"text":"Human motion prediction is important for mobile service robots and intelligent vehicles to operate safely and smoothly around people.","meta":{"url":"http://arxiv.org/abs/2309.07066v1"},"cats":{"new-dataset":0.0681312867,"dev-research":0.1902089173,"data-quality":0.0744986089}}
{"text":"The more accurate predictions are, particularly over extended periods of time, the better a system can, e.g., assess collision risks and plan ahead.","meta":{"url":"http://arxiv.org/abs/2309.07066v1"},"cats":{"new-dataset":0.0422222297,"dev-research":0.2926300669,"data-quality":0.0683834033}}
{"text":"In this paper, we propose to exploit maps of dynamics (MoDs, a class of general representations of place-dependent spatial motion patterns, learned from prior observations) for long-term human motion prediction (LHMP).","meta":{"url":"http://arxiv.org/abs/2309.07066v1"},"cats":{"new-dataset":0.387409933,"dev-research":0.1603828835,"data-quality":0.0394023999}}
{"text":"We present a new MoD-informed human motion prediction approach, named CLiFF-LHMP, which is data efficient, explainable, and insensitive to errors from an upstream tracking system.","meta":{"url":"http://arxiv.org/abs/2309.07066v1"},"cats":{"new-dataset":0.2327482382,"dev-research":0.2308298173,"data-quality":0.1311901543}}
{"text":"Our approach uses CLiFF-map, a specific MoD trained with human motion data recorded in the same environment.","meta":{"url":"http://arxiv.org/abs/2309.07066v1"},"cats":{"new-dataset":0.4735284362,"dev-research":0.1739467362,"data-quality":0.0793987988}}
{"text":"We bias a constant velocity prediction with samples from the CLiFF-map to generate multi-modal trajectory predictions.","meta":{"url":"http://arxiv.org/abs/2309.07066v1"},"cats":{"new-dataset":0.2437680764,"dev-research":0.1270311522,"data-quality":0.0586208854}}
{"text":"In two public datasets we show that this algorithm outperforms the state of the art for predictions over very extended periods of time, achieving 45% more accurate prediction performance at 50s compared to the baseline.","meta":{"url":"http://arxiv.org/abs/2309.07066v1"},"cats":{"new-dataset":0.3770087555,"dev-research":0.1642205821,"data-quality":0.1718668633}}
{"text":"In the dynamic landscape of digital forensics, the integration of Artificial Intelligence (AI) and Machine Learning (ML) stands as a transformative technology, poised to amplify the efficiency and precision of digital forensics investigations.","meta":{"url":"http://arxiv.org/abs/2309.07064v1"},"cats":{"new-dataset":0.0691247483,"dev-research":0.1823423006,"data-quality":0.1029874694}}
{"text":"However, the use of ML and AI in digital forensics is still in its nascent stages.","meta":{"url":"http://arxiv.org/abs/2309.07064v1"},"cats":{"new-dataset":0.0601953205,"dev-research":0.2170825663,"data-quality":0.1095776135}}
{"text":"As a result, this paper gives a thorough and in-depth analysis that goes beyond a simple survey and review.","meta":{"url":"http://arxiv.org/abs/2309.07064v1"},"cats":{"new-dataset":0.0769490539,"dev-research":0.1561390803,"data-quality":0.1223744164}}
{"text":"The goal is to look closely at how AI and ML techniques are used in digital forensics and incident response.","meta":{"url":"http://arxiv.org/abs/2309.07064v1"},"cats":{"new-dataset":0.04855611,"dev-research":0.284576266,"data-quality":0.1595905277}}
{"text":"This research explores cutting-edge research initiatives that cross domains such as data collection and recovery, the intricate reconstruction of cybercrime timelines, robust big data analysis, pattern recognition, safeguarding the chain of custody, and orchestrating responsive strategies to hacking incidents.","meta":{"url":"http://arxiv.org/abs/2309.07064v1"},"cats":{"new-dataset":0.4896315796,"dev-research":0.2511519558,"data-quality":0.0775416809}}
{"text":"This endeavour digs far beneath the surface to unearth the intricate ways AI-driven methodologies are shaping these crucial facets of digital forensics practice.","meta":{"url":"http://arxiv.org/abs/2309.07064v1"},"cats":{"new-dataset":0.0878210409,"dev-research":0.2776442821,"data-quality":0.0927395484}}
{"text":"While the promise of AI in digital forensics is evident, the challenges arising from increasing database sizes and evolving criminal tactics necessitate ongoing collaborative research and refinement within the digital forensics profession.","meta":{"url":"http://arxiv.org/abs/2309.07064v1"},"cats":{"new-dataset":0.1663657571,"dev-research":0.2399489276,"data-quality":0.1027754376}}
{"text":"This study examines the contributions, limitations, and gaps in the existing research, shedding light on the potential and limitations of AI and ML techniques.","meta":{"url":"http://arxiv.org/abs/2309.07064v1"},"cats":{"new-dataset":0.0086125835,"dev-research":0.213668002,"data-quality":0.1563264411}}
{"text":"By exploring these different research areas, we highlight the critical need for strategic planning, continual research, and development to unlock AI's full potential in digital forensics and incident response.","meta":{"url":"http://arxiv.org/abs/2309.07064v1"},"cats":{"new-dataset":0.2298310056,"dev-research":0.2882936454,"data-quality":0.0924680718}}
{"text":"Ultimately, this paper underscores the significance of AI and ML integration in digital forensics, offering insights into their benefits, drawbacks, and broader implications for tackling modern cyber threats.","meta":{"url":"http://arxiv.org/abs/2309.07064v1"},"cats":{"new-dataset":0.0854589721,"dev-research":0.2599295126,"data-quality":0.1221690731}}
{"text":"Agent-based simulation is a versatile and potent computational modeling technique employed to analyze intricate systems and phenomena spanning diverse fields.","meta":{"url":"http://arxiv.org/abs/2309.07055v1"},"cats":{"new-dataset":0.0253146417,"dev-research":0.1651895787,"data-quality":0.0409151587}}
{"text":"However, due to their computational intensity, agent-based models become more resource-demanding when geographic considerations are introduced.","meta":{"url":"http://arxiv.org/abs/2309.07055v1"},"cats":{"new-dataset":0.0331656196,"dev-research":0.2096619588,"data-quality":0.0366795741}}
{"text":"This study delves into diverse strategies for crafting a series of Agent-Based Models, named \"agent-in-the-cell,\" which emulate a city.","meta":{"url":"http://arxiv.org/abs/2309.07055v1"},"cats":{"new-dataset":0.1687760451,"dev-research":0.2497683308,"data-quality":0.053711888}}
{"text":"These models, incorporating geographical attributes of the city and employing real-world open-source mobility data from Safegraph's publicly available dataset, simulate the dynamics of COVID spread under varying scenarios.","meta":{"url":"http://arxiv.org/abs/2309.07055v1"},"cats":{"new-dataset":0.6134037493,"dev-research":0.1649394157,"data-quality":0.0544198308}}
{"text":"The \"agent-in-the-cell\" concept designates that our representative agents, called meta-agents, are linked to specific home cells in the city's tessellation.","meta":{"url":"http://arxiv.org/abs/2309.07055v1"},"cats":{"new-dataset":0.1191448243,"dev-research":0.1959747276,"data-quality":0.0836591073}}
{"text":"We scrutinize tessellations of the mobility map with varying complexities and experiment with the agent density, ranging from matching the actual population to reducing the number of (meta-) agents for computational efficiency.","meta":{"url":"http://arxiv.org/abs/2309.07055v1"},"cats":{"new-dataset":0.0799970967,"dev-research":0.107982439,"data-quality":0.0482616834}}
{"text":"Our findings demonstrate that tessellations constructed according to the Voronoi Diagram of specific location types on the street network better preserve dynamics compared to Census Block Group tessellations and better than Euclidean-based tessellations.","meta":{"url":"http://arxiv.org/abs/2309.07055v1"},"cats":{"new-dataset":0.0576974303,"dev-research":0.1847781323,"data-quality":0.0749954912}}
{"text":"Furthermore, the Voronoi Diagram tessellation and also a hybrid -- Voronoi Diagram - and Census Block Group - based -- tessellation require fewer meta-agents to adequately approximate full-scale dynamics.","meta":{"url":"http://arxiv.org/abs/2309.07055v1"},"cats":{"new-dataset":0.0279667386,"dev-research":0.146500979,"data-quality":0.0437101693}}
{"text":"Our analysis spans a range of city sizes in the United States, encompassing small (Santa Fe, NM), medium (Seattle, WA), and large (Chicago, IL) urban areas.","meta":{"url":"http://arxiv.org/abs/2309.07055v1"},"cats":{"new-dataset":0.2088356654,"dev-research":0.1828994659,"data-quality":0.0662639682}}
{"text":"This examination also provides valuable insights into the effects of agent count reduction, varying sensitivity metrics, and the influence of city-specific factors.","meta":{"url":"http://arxiv.org/abs/2309.07055v1"},"cats":{"new-dataset":0.0736545297,"dev-research":0.1820910895,"data-quality":0.0787395371}}
{"text":"Video deblurring methods, aiming at recovering consecutive sharp frames from a given blurry video, usually assume that the input video suffers from consecutively blurry frames.","meta":{"url":"http://arxiv.org/abs/2309.07054v1"},"cats":{"new-dataset":0.039919188,"dev-research":0.2323202035,"data-quality":0.2320558933}}
{"text":"However, in real-world blurry videos taken by modern imaging devices, sharp frames usually appear in the given video, thus making temporal long-term sharp features available for facilitating the restoration of a blurry frame.","meta":{"url":"http://arxiv.org/abs/2309.07054v1"},"cats":{"new-dataset":0.0331029162,"dev-research":0.2593711672,"data-quality":0.1851520089}}
{"text":"In this work, we propose a video deblurring method that leverages both neighboring frames and present sharp frames using hybrid Transformers for feature aggregation.","meta":{"url":"http://arxiv.org/abs/2309.07054v1"},"cats":{"new-dataset":0.0850218699,"dev-research":0.2378740373,"data-quality":0.2201171497}}
{"text":"Specifically, we first train a blur-aware detector to distinguish between sharp and blurry frames.","meta":{"url":"http://arxiv.org/abs/2309.07054v1"},"cats":{"new-dataset":0.0441007516,"dev-research":0.1992307357,"data-quality":0.2206249164}}
{"text":"Then, a window-based local Transformer is employed for exploiting features from neighboring frames, where cross attention is beneficial for aggregating features from neighboring frames without explicit spatial alignment.","meta":{"url":"http://arxiv.org/abs/2309.07054v1"},"cats":{"new-dataset":0.0431786059,"dev-research":0.2452246364,"data-quality":0.104073466}}
{"text":"To aggregate long-term sharp features from detected sharp frames, we utilize a global Transformer with multi-scale matching capability.","meta":{"url":"http://arxiv.org/abs/2309.07054v1"},"cats":{"new-dataset":0.0502313814,"dev-research":0.1597369115,"data-quality":0.1389153473}}
{"text":"Moreover, our method can easily be extended to event-driven video deblurring by incorporating an event fusion module into the global Transformer.","meta":{"url":"http://arxiv.org/abs/2309.07054v1"},"cats":{"new-dataset":0.0977978456,"dev-research":0.2493158174,"data-quality":0.1947308459}}
{"text":"Extensive experiments on benchmark datasets demonstrate that our proposed method outperforms state-of-the-art video deblurring methods as well as event-driven video deblurring methods in terms of quantitative metrics and visual quality.","meta":{"url":"http://arxiv.org/abs/2309.07054v1"},"cats":{"new-dataset":0.3196730434,"dev-research":0.2519977884,"data-quality":0.2337741696}}
{"text":"The source code and trained models are available at https://github.com/shangwei5/STGTN.","meta":{"url":"http://arxiv.org/abs/2309.07054v1"},"cats":{"new-dataset":0.282788076,"dev-research":0.1412210272,"data-quality":0.079313383}}
{"text":"The concept of updating a probability distribution in the light of new evidence lies at the heart of statistics and machine learning.","meta":{"url":"http://arxiv.org/abs/2309.07053v1"},"cats":{"new-dataset":0.0415485759,"dev-research":0.303199823,"data-quality":0.2407423462}}
{"text":"Pearl's and Jeffrey's rule are two natural update mechanisms which lead to different outcomes, yet the similarities and differences remain mysterious.","meta":{"url":"http://arxiv.org/abs/2309.07053v1"},"cats":{"new-dataset":0.0084030524,"dev-research":0.226128263,"data-quality":0.1180244083}}
{"text":"This paper clarifies their relationship in several ways: via separate descriptions of the two update mechanisms in terms of probabilistic programs and sampling semantics, and via different notions of likelihood (for Pearl and for Jeffrey).","meta":{"url":"http://arxiv.org/abs/2309.07053v1"},"cats":{"new-dataset":0.0547769327,"dev-research":0.269265784,"data-quality":0.209615301}}
{"text":"Moreover, it is shown that Jeffrey's update rule arises via variational inference.","meta":{"url":"http://arxiv.org/abs/2309.07053v1"},"cats":{"new-dataset":0.0312948575,"dev-research":0.1649837098,"data-quality":0.1404594401}}
{"text":"In terms of categorical probability theory, this amounts to an analysis of the situation in terms of the behaviour of the multiset functor, extended to the Kleisli category of the distribution monad.","meta":{"url":"http://arxiv.org/abs/2309.07053v1"},"cats":{"new-dataset":0.0613588509,"dev-research":0.1395962388,"data-quality":0.1160064335}}
{"text":"The automatic co-speech gesture generation draws much attention in computer animation.","meta":{"url":"http://arxiv.org/abs/2309.07051v1"},"cats":{"new-dataset":0.2020589332,"dev-research":0.2575758586,"data-quality":0.0960807412}}
{"text":"Previous works designed network structures on individual datasets, which resulted in a lack of data volume and generalizability across different motion capture standards.","meta":{"url":"http://arxiv.org/abs/2309.07051v1"},"cats":{"new-dataset":0.1989656244,"dev-research":0.1621896559,"data-quality":0.1221190382}}
{"text":"In addition, it is a challenging task due to the weak correlation between speech and gestures.","meta":{"url":"http://arxiv.org/abs/2309.07051v1"},"cats":{"new-dataset":0.0227315817,"dev-research":0.214450881,"data-quality":0.1153586534}}
{"text":"To address these problems, we present UnifiedGesture, a novel diffusion model-based speech-driven gesture synthesis approach, trained on multiple gesture datasets with different skeletons.","meta":{"url":"http://arxiv.org/abs/2309.07051v1"},"cats":{"new-dataset":0.610397095,"dev-research":0.1705278495,"data-quality":0.0852257631}}
{"text":"Specifically, we first present a retargeting network to learn latent homeomorphic graphs for different motion capture standards, unifying the representations of various gestures while extending the dataset.","meta":{"url":"http://arxiv.org/abs/2309.07051v1"},"cats":{"new-dataset":0.5643422066,"dev-research":0.219350824,"data-quality":0.0882067424}}
{"text":"We then capture the correlation between speech and gestures based on a diffusion model architecture using cross-local attention and self-attention to generate better speech-matched and realistic gestures.","meta":{"url":"http://arxiv.org/abs/2309.07051v1"},"cats":{"new-dataset":0.1959093131,"dev-research":0.1423407565,"data-quality":0.0858080502}}
{"text":"To further align speech and gesture and increase diversity, we incorporate reinforcement learning on the discrete gesture units with a learned reward function.","meta":{"url":"http://arxiv.org/abs/2309.07051v1"},"cats":{"new-dataset":0.1081866886,"dev-research":0.1287011006,"data-quality":0.0762534449}}
{"text":"Extensive experiments show that UnifiedGesture outperforms recent approaches on speech-driven gesture generation in terms of CCA, FGD, and human-likeness.","meta":{"url":"http://arxiv.org/abs/2309.07051v1"},"cats":{"new-dataset":0.1240653186,"dev-research":0.1675809776,"data-quality":0.0966626759}}
{"text":"All code, pre-trained models, databases, and demos are available to the public at https://github.com/YoungSeng/UnifiedGesture.","meta":{"url":"http://arxiv.org/abs/2309.07051v1"},"cats":{"new-dataset":0.5925242387,"dev-research":0.1768563088,"data-quality":0.0865339127}}
{"text":"This paper addresses multi-robot informative path planning (IPP) for environmental monitoring.","meta":{"url":"http://arxiv.org/abs/2309.07050v1"},"cats":{"new-dataset":0.0958642781,"dev-research":0.2422783717,"data-quality":0.0634825489}}
{"text":"The problem involves determining informative regions in the environment that should be visited by robots in order to gather the most information about the environment.","meta":{"url":"http://arxiv.org/abs/2309.07050v1"},"cats":{"new-dataset":0.1618581415,"dev-research":0.254270971,"data-quality":0.0909113674}}
{"text":"We propose an efficient sparse Gaussian process-based approach that uses gradient descent to optimize paths in continuous environments.","meta":{"url":"http://arxiv.org/abs/2309.07050v1"},"cats":{"new-dataset":0.0299680315,"dev-research":0.1653160971,"data-quality":0.0761621704}}
{"text":"Our approach efficiently scales to both spatially and spatio-temporally correlated environments.","meta":{"url":"http://arxiv.org/abs/2309.07050v1"},"cats":{"new-dataset":0.0933273933,"dev-research":0.1578999952,"data-quality":0.0554714796}}
{"text":"Moreover, our approach can simultaneously optimize the informative paths while accounting for routing constraints, such as a distance budget and limits on the robot's velocity and acceleration.","meta":{"url":"http://arxiv.org/abs/2309.07050v1"},"cats":{"new-dataset":0.0144236225,"dev-research":0.218861341,"data-quality":0.0494234001}}
{"text":"Our approach can be used for IPP with both discrete and continuous sensing robots, with point and non-point field-of-view sensing shapes, and for multi-robot IPP.","meta":{"url":"http://arxiv.org/abs/2309.07050v1"},"cats":{"new-dataset":0.0518303121,"dev-research":0.1361364559,"data-quality":0.0667958828}}
{"text":"The proposed approach is demonstrated to be fast and accurate on real-world data.","meta":{"url":"http://arxiv.org/abs/2309.07050v1"},"cats":{"new-dataset":0.1581946824,"dev-research":0.1408691859,"data-quality":0.1406725402}}
{"text":"With the rapid development of Large Language Models (LLMs), increasing attention has been paid to their safety concerns.","meta":{"url":"http://arxiv.org/abs/2309.07045v1"},"cats":{"new-dataset":0.0955170949,"dev-research":0.25909769,"data-quality":0.1750513444}}
{"text":"Consequently, evaluating the safety of LLMs has become an essential task for facilitating the broad applications of LLMs.","meta":{"url":"http://arxiv.org/abs/2309.07045v1"},"cats":{"new-dataset":0.0132899296,"dev-research":0.1692334216,"data-quality":0.0993642676}}
{"text":"Nevertheless, the absence of comprehensive safety evaluation benchmarks poses a significant impediment to effectively assess and enhance the safety of LLMs.","meta":{"url":"http://arxiv.org/abs/2309.07045v1"},"cats":{"new-dataset":0.0156735842,"dev-research":0.2073542127,"data-quality":0.1765551102}}
{"text":"In this work, we present SafetyBench, a comprehensive benchmark for evaluating the safety of LLMs, which comprises 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns.","meta":{"url":"http://arxiv.org/abs/2309.07045v1"},"cats":{"new-dataset":0.218614475,"dev-research":0.2717612638,"data-quality":0.1548057154}}
{"text":"Notably, SafetyBench also incorporates both Chinese and English data, facilitating the evaluation in both languages.","meta":{"url":"http://arxiv.org/abs/2309.07045v1"},"cats":{"new-dataset":0.2664990588,"dev-research":0.3163448316,"data-quality":0.2344102045}}
{"text":"Our extensive tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot settings reveal a substantial performance advantage for GPT-4 over its counterparts, and there is still significant room for improving the safety of current LLMs.","meta":{"url":"http://arxiv.org/abs/2309.07045v1"},"cats":{"new-dataset":0.0213249875,"dev-research":0.1073788393,"data-quality":0.1004158603}}
{"text":"We believe SafetyBench will enable fast and comprehensive evaluation of LLMs' safety, and foster the development of safer LLMs.","meta":{"url":"http://arxiv.org/abs/2309.07045v1"},"cats":{"new-dataset":0.1223862201,"dev-research":0.2760386638,"data-quality":0.1186619231}}
{"text":"Data and evaluation guidelines are available at https://github.com/thu-coai/SafetyBench.","meta":{"url":"http://arxiv.org/abs/2309.07045v1"},"cats":{"new-dataset":0.43326101,"dev-research":0.2977847434,"data-quality":0.1419188346}}
{"text":"Submission entrance and leaderboard are available at https://llmbench.ai/safety.","meta":{"url":"http://arxiv.org/abs/2309.07045v1"},"cats":{"new-dataset":0.2965972309,"dev-research":0.1741539985,"data-quality":0.0677929788}}
{"text":"In this work, we consider the complex control problem of making a monopod reach a target with a jump.","meta":{"url":"http://arxiv.org/abs/2309.07038v1"},"cats":{"new-dataset":0.0477295909,"dev-research":0.1742395492,"data-quality":0.0546123768}}
{"text":"The monopod can jump in any direction and the terrain underneath its foot can be uneven.","meta":{"url":"http://arxiv.org/abs/2309.07038v1"},"cats":{"new-dataset":0.0169510542,"dev-research":0.1746482937,"data-quality":0.0590256263}}
{"text":"This is a template of a much larger class of problems, which are extremely challenging and computationally expensive to solve using standard optimisation-based techniques.","meta":{"url":"http://arxiv.org/abs/2309.07038v1"},"cats":{"new-dataset":0.0538507571,"dev-research":0.1577318583,"data-quality":0.089086942}}
{"text":"Reinforcement Learning (RL) could be an interesting alternative, but the application of an end-to-end approach in which the controller must learn everything from scratch, is impractical.","meta":{"url":"http://arxiv.org/abs/2309.07038v1"},"cats":{"new-dataset":0.05041219,"dev-research":0.1931500414,"data-quality":0.0667730453}}
{"text":"The solution advocated in this paper is to guide the learning process within an RL framework by injecting physical knowledge.","meta":{"url":"http://arxiv.org/abs/2309.07038v1"},"cats":{"new-dataset":0.0867447838,"dev-research":0.2490081003,"data-quality":0.0886605155}}
{"text":"This expedient brings to widespread benefits, such as a drastic reduction of the learning time, and the ability to learn and compensate for possible errors in the low-level controller executing the motion.","meta":{"url":"http://arxiv.org/abs/2309.07038v1"},"cats":{"new-dataset":0.0070194375,"dev-research":0.2234116026,"data-quality":0.0585013819}}
{"text":"We demonstrate the advantage of our approach with respect to both optimization-based and end-to-end RL approaches.","meta":{"url":"http://arxiv.org/abs/2309.07038v1"},"cats":{"new-dataset":0.0268642911,"dev-research":0.1864301237,"data-quality":0.0788363303}}
{"text":"Annotators' sociodemographic backgrounds (i.e., the individual compositions of their gender, age, educational background, etc.) have a strong impact on their decisions when working on subjective NLP tasks, such as hate speech detection.","meta":{"url":"http://arxiv.org/abs/2309.07034v1"},"cats":{"new-dataset":0.0881691669,"dev-research":0.3113676781,"data-quality":0.5028524367}}
{"text":"Often, heterogeneous backgrounds result in high disagreements.","meta":{"url":"http://arxiv.org/abs/2309.07034v1"},"cats":{"new-dataset":0.0321836832,"dev-research":0.2809210926,"data-quality":0.1377385279}}
{"text":"To model this variation, recent work has explored sociodemographic prompting, a technique, which steers the output of prompt-based models towards answers that humans with specific sociodemographic profiles would give.","meta":{"url":"http://arxiv.org/abs/2309.07034v1"},"cats":{"new-dataset":0.0385518708,"dev-research":0.2602970942,"data-quality":0.0849889998}}
{"text":"However, the available NLP literature disagrees on the efficacy of this technique -- it remains unclear, for which tasks and scenarios it can help and evaluations are limited to specific tasks only.","meta":{"url":"http://arxiv.org/abs/2309.07034v1"},"cats":{"new-dataset":0.0043021046,"dev-research":0.2914034459,"data-quality":0.2311541404}}
{"text":"We address this research gap by presenting the largest and most comprehensive study of sociodemographic prompting today.","meta":{"url":"http://arxiv.org/abs/2309.07034v1"},"cats":{"new-dataset":0.1061580874,"dev-research":0.2941805846,"data-quality":0.067068108}}
{"text":"Concretely, we evaluate several prompt formulations across seven datasets and six instruction-tuned model families.","meta":{"url":"http://arxiv.org/abs/2309.07034v1"},"cats":{"new-dataset":0.2157351751,"dev-research":0.1981554717,"data-quality":0.1244326196}}
{"text":"We find that (1) while sociodemographic prompting can be beneficial for improving zero-shot learning in subjective NLP tasks, (2) its outcomes largely vary for different model types, sizes, and datasets, (3) are subject to large variance with regards to prompt formulations.","meta":{"url":"http://arxiv.org/abs/2309.07034v1"},"cats":{"new-dataset":0.0340748182,"dev-research":0.2019508876,"data-quality":0.1968153227}}
{"text":"Thus, sociodemographic prompting is not a reliable proxy for traditional data annotation with a sociodemographically heterogeneous group of annotators.","meta":{"url":"http://arxiv.org/abs/2309.07034v1"},"cats":{"new-dataset":0.0813395697,"dev-research":0.301664535,"data-quality":0.367535343}}
{"text":"Instead, we propose (4) to use it for identifying ambiguous instances resulting in more informed annotation efforts.","meta":{"url":"http://arxiv.org/abs/2309.07034v1"},"cats":{"new-dataset":0.0503195664,"dev-research":0.3688960358,"data-quality":0.5959360118}}
{"text":"This review is the first step in a long-term research project exploring how social robotics and AI-generated content can contribute to the creative experiences of older adults, with a focus on collaborative drawing and painting.","meta":{"url":"http://arxiv.org/abs/2309.07033v1"},"cats":{"new-dataset":0.0644158016,"dev-research":0.3285559063,"data-quality":0.0782268982}}
{"text":"We systematically searched and selected literature on human-robot co-creativity, and analyzed articles to identify methods and strategies for researching co-creative robotics.","meta":{"url":"http://arxiv.org/abs/2309.07033v1"},"cats":{"new-dataset":0.1525600452,"dev-research":0.3000367937,"data-quality":0.0854005622}}
{"text":"We found that none of the studies involved older adults, which shows the gap in the literature for this often involved participant group in robotics research.","meta":{"url":"http://arxiv.org/abs/2309.07033v1"},"cats":{"new-dataset":0.0221459256,"dev-research":0.1784081118,"data-quality":0.0991879082}}
{"text":"The analyzed literature provides valuable insights into the design of human-robot co-creativity and informs a research agenda to further investigate the topic with older adults.","meta":{"url":"http://arxiv.org/abs/2309.07033v1"},"cats":{"new-dataset":0.0699271798,"dev-research":0.3320668902,"data-quality":0.0699725905}}
{"text":"We argue that future research should focus on ecological and developmental perspectives on creativity, on how system behavior can be aligned with the values of older adults, and on the system structures that support this best.","meta":{"url":"http://arxiv.org/abs/2309.07033v1"},"cats":{"new-dataset":0.0675988738,"dev-research":0.3527407323,"data-quality":0.099544397}}
{"text":"Comparing graphs of optimal transport has recently gained significant attention, as the distances induced by optimal transport provide both a principled metric between graphs as well as an interpretable description of the associated changes between graphs in terms of a transport plan.","meta":{"url":"http://arxiv.org/abs/2309.07030v1"},"cats":{"new-dataset":0.0218767571,"dev-research":0.1922394866,"data-quality":0.0800344715}}
{"text":"As the lack of symmetry introduces challenges in the typically considered formulations, optimal transport distances for graphs have mostly been developed for undirected graphs.","meta":{"url":"http://arxiv.org/abs/2309.07030v1"},"cats":{"new-dataset":0.0101370312,"dev-research":0.1526174094,"data-quality":0.0885397179}}
{"text":"Here, we propose two distance measures to compare directed graphs based on variants of optimal transport: (i) an earth movers distance (Wasserstein) and (ii) a Gromov-Wasserstein (GW) distance.","meta":{"url":"http://arxiv.org/abs/2309.07030v1"},"cats":{"new-dataset":0.0655414653,"dev-research":0.165893361,"data-quality":0.070005617}}
{"text":"We evaluate these two distances and discuss their relative performance for both simulated graph data and real-world directed cell-cell communication graphs, inferred from single-cell RNA-seq data.","meta":{"url":"http://arxiv.org/abs/2309.07030v1"},"cats":{"new-dataset":0.2041585816,"dev-research":0.1442693763,"data-quality":0.0896459036}}
{"text":"This position paper is part of a long-term research project on human-machine co-creativity with older adults.","meta":{"url":"http://arxiv.org/abs/2309.07028v1"},"cats":{"new-dataset":0.0625325612,"dev-research":0.3530019594,"data-quality":0.1181644722}}
{"text":"The goal is to investigate how robots and AI-generated content can contribute to older adults' creative experiences, with a focus on collaborative drawing and painting.","meta":{"url":"http://arxiv.org/abs/2309.07028v1"},"cats":{"new-dataset":0.0946580189,"dev-research":0.3629312859,"data-quality":0.084706651}}
{"text":"The research has recently started, and current activities are centred around literature studies, interviews with seniors and artists, and developing initial prototypes.","meta":{"url":"http://arxiv.org/abs/2309.07028v1"},"cats":{"new-dataset":0.2108704986,"dev-research":0.2755570999,"data-quality":0.0748579139}}
{"text":"In addition, a course \"Drawing with Robots\", is being developed to establish collaboration between human and machine learners: older adults, artists, students, researchers, and artificial agents.","meta":{"url":"http://arxiv.org/abs/2309.07028v1"},"cats":{"new-dataset":0.1227733677,"dev-research":0.380182861,"data-quality":0.0811822876}}
{"text":"We present this course as a learning community and as an opportunity for studying how explainable AI and creative dialogues can be intertwined in human-machine co-creativity with older adults.","meta":{"url":"http://arxiv.org/abs/2309.07028v1"},"cats":{"new-dataset":0.1353857241,"dev-research":0.3621899164,"data-quality":0.1472806407}}
{"text":"Based on developer needs and usage scenarios, API (Application Programming Interface) recommendation is the process of assisting developers in finding the required API among numerous candidate APIs.","meta":{"url":"http://arxiv.org/abs/2309.07026v1"},"cats":{"new-dataset":0.0177698333,"dev-research":0.4799748579,"data-quality":0.0817274085}}
{"text":"Previous studies mainly modeled API recommendation as the recommendation task, which can recommend multiple candidate APIs for the given query, and developers may not yet be able to find what they need.","meta":{"url":"http://arxiv.org/abs/2309.07026v1"},"cats":{"new-dataset":0.0098011107,"dev-research":0.2615690208,"data-quality":0.0716654272}}
{"text":"Motivated by the neural machine translation research domain, we can model this problem as the generation task, which aims to directly generate the required API for the developer query.","meta":{"url":"http://arxiv.org/abs/2309.07026v1"},"cats":{"new-dataset":0.3400819523,"dev-research":0.2883091488,"data-quality":0.1623433}}
{"text":"After our preliminary investigation, we find the performance of this intuitive approach is not promising.","meta":{"url":"http://arxiv.org/abs/2309.07026v1"},"cats":{"new-dataset":0.0011019875,"dev-research":0.1285592812,"data-quality":0.1437178955}}
{"text":"The reason is that there exists an error when generating the prefixes of the API.","meta":{"url":"http://arxiv.org/abs/2309.07026v1"},"cats":{"new-dataset":0.0179437167,"dev-research":0.2178079992,"data-quality":0.2626156922}}
{"text":"However, developers may know certain API prefix information during actual development in most cases.","meta":{"url":"http://arxiv.org/abs/2309.07026v1"},"cats":{"new-dataset":0.0189426653,"dev-research":0.4031245378,"data-quality":0.2368203867}}
{"text":"Therefore, we model this problem as the automatic completion task and propose a novel approach APICom based on prompt learning, which can generate API related to the query according to the prompts (i.e., API prefix information).","meta":{"url":"http://arxiv.org/abs/2309.07026v1"},"cats":{"new-dataset":0.082041094,"dev-research":0.2097839121,"data-quality":0.166941948}}
{"text":"Moreover, the effectiveness of APICom highly depends on the quality of the training dataset.","meta":{"url":"http://arxiv.org/abs/2309.07026v1"},"cats":{"new-dataset":0.0461282108,"dev-research":0.2313885098,"data-quality":0.161464533}}
{"text":"In this study, we further design a novel gradient-based adversarial training method {\\atpart} for data augmentation, which can improve the normalized stability when generating adversarial examples.","meta":{"url":"http://arxiv.org/abs/2309.07026v1"},"cats":{"new-dataset":0.0591807654,"dev-research":0.1978768216,"data-quality":0.3449321946}}
{"text":"To evaluate the effectiveness of APICom, we consider a corpus of 33k developer queries and corresponding APIs.","meta":{"url":"http://arxiv.org/abs/2309.07026v1"},"cats":{"new-dataset":0.4365704437,"dev-research":0.4310171807,"data-quality":0.162498323}}
{"text":"Compared with the state-of-the-art baselines, our experimental results show that APICom can outperform all baselines by at least 40.02\\%, 13.20\\%, and 16.31\\% in terms of the performance measures EM@1, MRR, and MAP.","meta":{"url":"http://arxiv.org/abs/2309.07026v1"},"cats":{"new-dataset":0.09050826,"dev-research":0.2476955904,"data-quality":0.1192057087}}
{"text":"Finally, our ablation studies confirm the effectiveness of our component setting (such as our designed adversarial training method, our used pre-trained model, and prompt learning) in APICom.","meta":{"url":"http://arxiv.org/abs/2309.07026v1"},"cats":{"new-dataset":0.0734876585,"dev-research":0.1873347883,"data-quality":0.1387677726}}
{"text":"Artificial Intelligence (AI) presents prodigious technological prospects for development, however, all that glitters is not gold!","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.1105777385,"dev-research":0.3211493817,"data-quality":0.1478108135}}
{"text":"The cyber-world faces the worst nightmare with the advent of AI and quantum computers.","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.043984499,"dev-research":0.2343631684,"data-quality":0.0990276315}}
{"text":"Together with Quantum Artificial Intelligence (QAI), they pose a catastrophic threat to modern cryptography.","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.0332433564,"dev-research":0.1701847445,"data-quality":0.0950092072}}
{"text":"It would also increase the capability of cryptanalysts manifold, with its built-in persistent and extensive predictive intelligence.","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.0183108298,"dev-research":0.1338051111,"data-quality":0.0757253278}}
{"text":"This prediction ability incapacitates the constrained message space in device cryptography.","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.017676236,"dev-research":0.1303492983,"data-quality":0.0920950932}}
{"text":"With the comparison of these assumptions and the intercepted ciphertext, the code-cracking process will considerably accelerate.","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.0329119126,"dev-research":0.2044670759,"data-quality":0.1379917635}}
{"text":"Before the vigorous and robust developments in AI, we have never faced and never had to prepare for such a plaintext-originating attack.","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.0270547908,"dev-research":0.2149685554,"data-quality":0.120888124}}
{"text":"The supremacy of AI can be challenged by creating ciphertexts that would give the AI attacker erroneous responses stymied by randomness and misdirect them.","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.0089034343,"dev-research":0.1771969805,"data-quality":0.1965230315}}
{"text":"AI threat is deterred by deviating from the conventional use of small, known-size keys and pattern-loaded ciphers.","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.0125375181,"dev-research":0.1995926037,"data-quality":0.0808319141}}
{"text":"The strategy is vested in implementing larger secret size keys, supplemented by ad-hoc unilateral randomness of unbound limitations and a pattern-devoid technique.","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.0119196158,"dev-research":0.1232085662,"data-quality":0.0537256106}}
{"text":"The very large key size can be handled with low processing and computational burden to achieve desired unicity distances.","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.0433429965,"dev-research":0.1728674309,"data-quality":0.061566004}}
{"text":"The strategy against AI odds is feasible by implementing non-algorithmic randomness, large and inexpensive memory chips, and wide-area communication networks.","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.0200417611,"dev-research":0.1624089908,"data-quality":0.0755205889}}
{"text":"The strength of AI, i.e., randomness and pattern detection can be used to generate highly optimized ciphers and algorithms.","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.0246314272,"dev-research":0.1484693575,"data-quality":0.0779688159}}
{"text":"These pattern-devoid, randomness-rich ciphers also provide a timely and plausible solution for NIST's proactive approach toward the quantum challenge.","meta":{"url":"http://arxiv.org/abs/2309.07022v1"},"cats":{"new-dataset":0.0812131975,"dev-research":0.1216454453,"data-quality":0.1023955773}}
{"text":"Neural implicit modeling permits to achieve impressive 3D reconstruction results on small objects, while it exhibits significant limitations in large indoor scenes.","meta":{"url":"http://arxiv.org/abs/2309.07021v1"},"cats":{"new-dataset":0.0553516447,"dev-research":0.2089928817,"data-quality":0.0907038918}}
{"text":"In this work, we propose a novel neural implicit modeling method that leverages multiple regularization strategies to achieve better reconstructions of large indoor environments, while relying only on images.","meta":{"url":"http://arxiv.org/abs/2309.07021v1"},"cats":{"new-dataset":0.0678535378,"dev-research":0.2168751306,"data-quality":0.1339390776}}
{"text":"A sparse but accurate depth prior is used to anchor the scene to the initial model.","meta":{"url":"http://arxiv.org/abs/2309.07021v1"},"cats":{"new-dataset":0.023517643,"dev-research":0.1695481356,"data-quality":0.1045092743}}
{"text":"A dense but less accurate depth prior is also introduced, flexible enough to still let the model diverge from it to improve the estimated geometry.","meta":{"url":"http://arxiv.org/abs/2309.07021v1"},"cats":{"new-dataset":0.0038274656,"dev-research":0.1315021673,"data-quality":0.0656375185}}
{"text":"Then, a novel self-supervised strategy to regularize the estimated surface normals is presented.","meta":{"url":"http://arxiv.org/abs/2309.07021v1"},"cats":{"new-dataset":0.0440993924,"dev-research":0.1309003727,"data-quality":0.1621711114}}
{"text":"Finally, a learnable exposure compensation scheme permits to cope with challenging lighting conditions.","meta":{"url":"http://arxiv.org/abs/2309.07021v1"},"cats":{"new-dataset":0.070830952,"dev-research":0.2751871091,"data-quality":0.107583609}}
{"text":"Experimental results show that our approach produces state-of-the-art 3D reconstructions in challenging indoor scenarios.","meta":{"url":"http://arxiv.org/abs/2309.07021v1"},"cats":{"new-dataset":0.120809298,"dev-research":0.2619944879,"data-quality":0.0657067178}}
{"text":"This work proposes a novel approach to text categorization -- for unknown categories -- in the context of scientific literature, using Natural Language Processing techniques.","meta":{"url":"http://arxiv.org/abs/2309.07020v1"},"cats":{"new-dataset":0.0908639408,"dev-research":0.2210819186,"data-quality":0.5047729944}}
{"text":"The study leverages the power of pre-trained language models, specifically SciBERT, to extract meaningful representations of abstracts from the ArXiv dataset.","meta":{"url":"http://arxiv.org/abs/2309.07020v1"},"cats":{"new-dataset":0.2269353886,"dev-research":0.19496005,"data-quality":0.2363019605}}
{"text":"Text categorization is performed using the K-Means algorithm, and the optimal number of clusters is determined based on the Silhouette score.","meta":{"url":"http://arxiv.org/abs/2309.07020v1"},"cats":{"new-dataset":0.0855949867,"dev-research":0.17824726,"data-quality":0.3033075692}}
{"text":"The results demonstrate that the proposed approach captures subject information more effectively than the traditional arXiv labeling system, leading to improved text categorization.","meta":{"url":"http://arxiv.org/abs/2309.07020v1"},"cats":{"new-dataset":0.1256023728,"dev-research":0.2194989172,"data-quality":0.4925761478}}
{"text":"The approach offers potential for better navigation and recommendation systems in the rapidly growing landscape of scientific research literature.","meta":{"url":"http://arxiv.org/abs/2309.07020v1"},"cats":{"new-dataset":0.083275874,"dev-research":0.2217217256,"data-quality":0.1154595212}}
{"text":"The idea of enumeration algorithms with polynomial delay is to polynomially bound the running time between any two subsequent solutions output by the enumeration algorithm.","meta":{"url":"http://arxiv.org/abs/2309.07018v1"},"cats":{"new-dataset":0.0187249135,"dev-research":0.1602922964,"data-quality":0.0676373414}}
{"text":"While it is open for more than four decades if all minimal dominating sets of a graph can be enumerated in output-polynomial time, it has recently been proven that pointwise-minimal Roman dominating functions can be enumerated even with polynomial delay.","meta":{"url":"http://arxiv.org/abs/2309.07018v1"},"cats":{"new-dataset":0.0568546986,"dev-research":0.1804925553,"data-quality":0.1146397326}}
{"text":"The idea of the enumeration algorithm was to use polynomial-time solvable extension problems.","meta":{"url":"http://arxiv.org/abs/2309.07018v1"},"cats":{"new-dataset":0.0160957184,"dev-research":0.1945459564,"data-quality":0.0962067407}}
{"text":"We use this as a motivation to prove that also two variants of Roman dominating functions studied in the literature, named perfect and unique response, can be enumerated with polynomial delay.","meta":{"url":"http://arxiv.org/abs/2309.07018v1"},"cats":{"new-dataset":0.0295632942,"dev-research":0.1596783408,"data-quality":0.1000340779}}
{"text":"This is interesting since Extension Perfect Roman Domination is W[1]-complete if parameterized by the weight of the given function and even W[2]-complete if parameterized by the number vertices assigned 0 in the pre-solution, as we prove.","meta":{"url":"http://arxiv.org/abs/2309.07018v1"},"cats":{"new-dataset":0.025503833,"dev-research":0.1806548052,"data-quality":0.1495047765}}
{"text":"Otherwise, efficient solvability of extension problems and enumerability with polynomial delay tend to go hand-in-hand.","meta":{"url":"http://arxiv.org/abs/2309.07018v1"},"cats":{"new-dataset":0.0105113693,"dev-research":0.1963388557,"data-quality":0.122652139}}
{"text":"We achieve our enumeration result by constructing a bijection to Roman dominating functions, where the corresponding extension problem is polynomimaltime solvable.","meta":{"url":"http://arxiv.org/abs/2309.07018v1"},"cats":{"new-dataset":0.2117710914,"dev-research":0.156262021,"data-quality":0.11935658}}
{"text":"Furthermore, we show that Unique Response Roman Domination is solvable in polynomial time on split graphs, while Perfect Roman Domination is NP-complete on this graph class, which proves that both variations, albeit coming with a very similar definition, do differ in some complexity aspects.","meta":{"url":"http://arxiv.org/abs/2309.07018v1"},"cats":{"new-dataset":0.0341745504,"dev-research":0.1411854807,"data-quality":0.112498846}}
{"text":"This way, we also solve an open problem from the literature.","meta":{"url":"http://arxiv.org/abs/2309.07018v1"},"cats":{"new-dataset":0.0917822416,"dev-research":0.2519679096,"data-quality":0.1448865981}}
{"text":"Extracting information from r\\'esum\\'es is typically formulated as a two-stage problem, where the document is first segmented into sections and then each section is processed individually to extract the target entities.","meta":{"url":"http://arxiv.org/abs/2309.07015v1"},"cats":{"new-dataset":0.1084103103,"dev-research":0.150923343,"data-quality":0.2004727523}}
{"text":"Instead, we cast the whole problem as sequence labeling in two levels -- lines and tokens -- and study model architectures for solving both tasks simultaneously.","meta":{"url":"http://arxiv.org/abs/2309.07015v1"},"cats":{"new-dataset":0.1929290916,"dev-research":0.2409626349,"data-quality":0.2210819605}}
{"text":"We build high-quality r\\'esum\\'e parsing corpora in English, French, Chinese, Spanish, German, Portuguese, and Swedish.","meta":{"url":"http://arxiv.org/abs/2309.07015v1"},"cats":{"new-dataset":0.4957712085,"dev-research":0.1941462553,"data-quality":0.3420302582}}
{"text":"Based on these corpora, we present experimental results that demonstrate the effectiveness of the proposed models for the information extraction task, outperforming approaches introduced in previous work.","meta":{"url":"http://arxiv.org/abs/2309.07015v1"},"cats":{"new-dataset":0.0604431912,"dev-research":0.1965028794,"data-quality":0.3601248384}}
{"text":"We conduct an ablation study of the proposed architectures.","meta":{"url":"http://arxiv.org/abs/2309.07015v1"},"cats":{"new-dataset":0.0871735983,"dev-research":0.161722235,"data-quality":0.0647915982}}
{"text":"We also analyze both model performance and resource efficiency, and describe the trade-offs for model deployment in the context of a production environment.","meta":{"url":"http://arxiv.org/abs/2309.07015v1"},"cats":{"new-dataset":0.031989186,"dev-research":0.3738401313,"data-quality":0.0679040442}}
{"text":"We present Multi-Layer Intensity Map, a novel 3D object representation for robot perception and autonomous navigation.","meta":{"url":"http://arxiv.org/abs/2309.07014v1"},"cats":{"new-dataset":0.1480736978,"dev-research":0.1603885465,"data-quality":0.0685918369}}
{"text":"They consist of multiple stacked layers of 2D grid maps each derived from reflected point cloud intensities corresponding to a certain height interval.","meta":{"url":"http://arxiv.org/abs/2309.07014v1"},"cats":{"new-dataset":0.4381840437,"dev-research":0.1472475196,"data-quality":0.0437382086}}
{"text":"The different layers of the intensity maps can be used to simultaneously estimate obstacles' height, solidity/density, and opacity.","meta":{"url":"http://arxiv.org/abs/2309.07014v1"},"cats":{"new-dataset":0.1091012833,"dev-research":0.1906556806,"data-quality":0.037471251}}
{"text":"We demonstrate that they can help accurately differentiate obstacles that are safe to navigate through (e.g. beaded/string curtains, pliable tall grass), from ones that must be avoided (e.g. transparent surfaces such as glass walls, bushes, trees, etc.)","meta":{"url":"http://arxiv.org/abs/2309.07014v1"},"cats":{"new-dataset":0.0368467489,"dev-research":0.2688807399,"data-quality":0.0823040529}}
{"text":"in indoor and outdoor environments.","meta":{"url":"http://arxiv.org/abs/2309.07014v1"},"cats":{"new-dataset":0.0880434701,"dev-research":0.2213294614,"data-quality":0.0883905628}}
{"text":"Further, to handle narrow passages, and navigate through non-solid obstacles in dense environments, we propose an approach to adaptively inflate or enlarge the obstacles detected on intensity maps based on their solidity, and the robot's preferred velocity direction.","meta":{"url":"http://arxiv.org/abs/2309.07014v1"},"cats":{"new-dataset":0.0369209564,"dev-research":0.2373425749,"data-quality":0.044738006}}
{"text":"We demonstrate these improved navigation capabilities in real-world narrow, dense environments using a real Turtlebot and Boston Dynamics Spot.","meta":{"url":"http://arxiv.org/abs/2309.07014v1"},"cats":{"new-dataset":0.0834199713,"dev-research":0.1755622258,"data-quality":0.0448166613}}
{"text":"We observe significant increases in success rates (up to 50%), a 9.55% decrease in trajectory length, and up to a 10.9% increase in the F-score compared to current navigation methods using other sensor modalities.","meta":{"url":"http://arxiv.org/abs/2309.07014v1"},"cats":{"new-dataset":0.0365713547,"dev-research":0.1483124484,"data-quality":0.0941600506}}
{"text":"We investigate the problem of collaborative tree exploration with complete communication introduced by [FGKP06], in which a group of $k$ agents is assigned to collectively go through all edges of an unknown tree in an efficient manner and then return to the origin.","meta":{"url":"http://arxiv.org/abs/2309.07011v1"},"cats":{"new-dataset":0.0830601697,"dev-research":0.1567107927,"data-quality":0.1060849241}}
{"text":"The agents have unrestricted communication and computation capabilities.","meta":{"url":"http://arxiv.org/abs/2309.07011v1"},"cats":{"new-dataset":0.065746135,"dev-research":0.1322602496,"data-quality":0.0365369224}}
{"text":"The algorithm's runtime is typically compared to the cost of offline traversal, which is at least $\\max\\{2n/k,2D\\}$ where $n$ is the number of nodes and $D$ is the tree depth.","meta":{"url":"http://arxiv.org/abs/2309.07011v1"},"cats":{"new-dataset":0.028167663,"dev-research":0.1469432394,"data-quality":0.0640870732}}
{"text":"Since its introduction, two types of guarantee have emerged on the topic: the first is of the form $r(k)(n/k+D)$, where $r(k)$ is called the competitive ratio, and the other is of the form $2n/k+f(k,D)$, where $f(k,D)$ is called the competitive overhead.","meta":{"url":"http://arxiv.org/abs/2309.07011v1"},"cats":{"new-dataset":0.0194700064,"dev-research":0.138335766,"data-quality":0.0889009394}}
{"text":"In this paper, we present the first algorithm with linear-in-$D$ competitive overhead, thereby reconciling both approaches.","meta":{"url":"http://arxiv.org/abs/2309.07011v1"},"cats":{"new-dataset":0.03405097,"dev-research":0.1205507527,"data-quality":0.080242248}}
{"text":"Specifically, our bound is in $2n/k + O(k^{\\log_2 k} D)$ and thus leads to a competitive ratio in $O(k/\\exp(0.8\\sqrt{\\ln k}))$.","meta":{"url":"http://arxiv.org/abs/2309.07011v1"},"cats":{"new-dataset":0.0699801329,"dev-research":0.1039637427,"data-quality":0.0768575855}}
{"text":"This is the first improvement over the $O(k/\\ln k)$-competitive algorithm known since the introduction of the problem in 2004.","meta":{"url":"http://arxiv.org/abs/2309.07011v1"},"cats":{"new-dataset":0.0649811928,"dev-research":0.0951158963,"data-quality":0.1201061194}}
{"text":"Our algorithm is obtained for an asynchronous generalization of collective tree exploration (ACTE).","meta":{"url":"http://arxiv.org/abs/2309.07011v1"},"cats":{"new-dataset":0.0673784769,"dev-research":0.1166870459,"data-quality":0.1007252876}}
{"text":"It is an instance of a general class of locally-greedy exploration algorithms that we define.","meta":{"url":"http://arxiv.org/abs/2309.07011v1"},"cats":{"new-dataset":0.0392383577,"dev-research":0.1251366857,"data-quality":0.0838452905}}
{"text":"We show that the additive overhead analysis of locally-greedy algorithms can be seen through the lens of a 2-player game that we call the tree-mining game and that could be of independent interest.","meta":{"url":"http://arxiv.org/abs/2309.07011v1"},"cats":{"new-dataset":0.0728787848,"dev-research":0.1695640169,"data-quality":0.065780862}}
{"text":"This paper serves as a foundational step towards the development of a linguistically motivated and technically relevant evaluation suite for Greek NLP.","meta":{"url":"http://arxiv.org/abs/2309.07009v1"},"cats":{"new-dataset":0.0622420605,"dev-research":0.2624087313,"data-quality":0.3372780112}}
{"text":"We initiate this endeavor by introducing four expert-verified evaluation tasks, specifically targeted at natural language inference, word sense disambiguation (through example comparison or sense selection) and metaphor detection.","meta":{"url":"http://arxiv.org/abs/2309.07009v1"},"cats":{"new-dataset":0.0728089855,"dev-research":0.2900132761,"data-quality":0.2478211341}}
{"text":"More than language-adapted replicas of existing tasks, we contribute two innovations which will resonate with the broader resource and evaluation community.","meta":{"url":"http://arxiv.org/abs/2309.07009v1"},"cats":{"new-dataset":0.0439159617,"dev-research":0.3452521844,"data-quality":0.1724450498}}
{"text":"Firstly, our inference dataset is the first of its kind, marking not just \\textit{one}, but rather \\textit{all} possible inference labels, accounting for possible shifts due to e.g. ambiguity or polysemy.","meta":{"url":"http://arxiv.org/abs/2309.07009v1"},"cats":{"new-dataset":0.1236815172,"dev-research":0.1965475661,"data-quality":0.3323845038}}
{"text":"Secondly, we demonstrate a cost-efficient method to obtain datasets for under-resourced languages.","meta":{"url":"http://arxiv.org/abs/2309.07009v1"},"cats":{"new-dataset":0.7753547118,"dev-research":0.2133276204,"data-quality":0.215146421}}
{"text":"Using ChatGPT as a language-neutral parser, we transform the Dictionary of Standard Modern Greek into a structured format, from which we derive the other three tasks through simple projections.","meta":{"url":"http://arxiv.org/abs/2309.07009v1"},"cats":{"new-dataset":0.388924413,"dev-research":0.2148834756,"data-quality":0.2083530784}}
{"text":"Alongside each task, we conduct experiments using currently available state of the art machinery.","meta":{"url":"http://arxiv.org/abs/2309.07009v1"},"cats":{"new-dataset":0.0312299759,"dev-research":0.1680590144,"data-quality":0.0797398791}}
{"text":"Our experimental baselines affirm the challenging nature of our tasks and highlight the need for expedited progress in order for the Greek NLP ecosystem to keep pace with contemporary mainstream research.","meta":{"url":"http://arxiv.org/abs/2309.07009v1"},"cats":{"new-dataset":0.1211122168,"dev-research":0.2331244351,"data-quality":0.2791471835}}
{"text":"The layout of multi-dimensional data can have a significant impact on the efficacy of hardware caches and, by extension, the performance of applications.","meta":{"url":"http://arxiv.org/abs/2309.07002v1"},"cats":{"new-dataset":0.0414994373,"dev-research":0.204807963,"data-quality":0.0674889616}}
{"text":"Common multi-dimensional layouts include the canonical row-major and column-major layouts as well as the Morton curve layout.","meta":{"url":"http://arxiv.org/abs/2309.07002v1"},"cats":{"new-dataset":0.0927299975,"dev-research":0.1383871953,"data-quality":0.0460958176}}
{"text":"In this paper, we describe how the Morton layout can be generalized to a very large family of multi-dimensional data layouts with widely varying performance characteristics.","meta":{"url":"http://arxiv.org/abs/2309.07002v1"},"cats":{"new-dataset":0.1822334313,"dev-research":0.1667711929,"data-quality":0.0711677918}}
{"text":"We posit that this design space can be efficiently explored using a combinatorial evolutionary methodology based on genetic algorithms.","meta":{"url":"http://arxiv.org/abs/2309.07002v1"},"cats":{"new-dataset":0.0300975877,"dev-research":0.2016248216,"data-quality":0.0426938945}}
{"text":"To this end, we propose a chromosomal representation for such layouts as well as a methodology for estimating the fitness of array layouts using cache simulation.","meta":{"url":"http://arxiv.org/abs/2309.07002v1"},"cats":{"new-dataset":0.0555392248,"dev-research":0.1713834008,"data-quality":0.0884675552}}
{"text":"We show that our fitness function correlates to kernel running time in real hardware, and that our evolutionary strategy allows us to find candidates with favorable simulated cache properties in four out of the eight real-world applications under consideration in a small number of generations.","meta":{"url":"http://arxiv.org/abs/2309.07002v1"},"cats":{"new-dataset":0.0313955012,"dev-research":0.1413744133,"data-quality":0.0640130752}}
{"text":"Finally, we demonstrate that the array layouts found using our evolutionary method perform well not only in simulated environments but that they can effect significant performance gains -- up to a factor ten in extreme cases -- in real hardware.","meta":{"url":"http://arxiv.org/abs/2309.07002v1"},"cats":{"new-dataset":0.032258028,"dev-research":0.2107885719,"data-quality":0.0671424985}}
{"text":"Environmental, social, and governance (ESG) reports are globally recognized as a keystone in sustainable enterprise development.","meta":{"url":"http://arxiv.org/abs/2309.07001v1"},"cats":{"new-dataset":0.1827497913,"dev-research":0.2446858663,"data-quality":0.0969041014}}
{"text":"This study aims to map the changing landscape of ESG topics within firms in the global market.","meta":{"url":"http://arxiv.org/abs/2309.07001v1"},"cats":{"new-dataset":0.0545446113,"dev-research":0.2095916917,"data-quality":0.099005406}}
{"text":"A dynamic framework is developed to analyze ESG strategic management for individual classes, across multiple classes, and in alignment with a specific sustainability index.","meta":{"url":"http://arxiv.org/abs/2309.07001v1"},"cats":{"new-dataset":0.06315522,"dev-research":0.1871870932,"data-quality":0.0652941566}}
{"text":"The output of these analytical processes forms the foundation of an ESG strategic model.","meta":{"url":"http://arxiv.org/abs/2309.07001v1"},"cats":{"new-dataset":0.0124258938,"dev-research":0.1870747374,"data-quality":0.0504182011}}
{"text":"Utilizing a rich collection of 21st-century ESG reports from technology companies, our experiment elucidates the changes in ESG perspectives by incorporating analytical keywords into the proposed framework.","meta":{"url":"http://arxiv.org/abs/2309.07001v1"},"cats":{"new-dataset":0.0480218494,"dev-research":0.2391544673,"data-quality":0.1092425532}}
{"text":"This work thus provides an empirical method that reveals the concurrent evolution of ESG topics over recent years.","meta":{"url":"http://arxiv.org/abs/2309.07001v1"},"cats":{"new-dataset":0.0386318564,"dev-research":0.1721262604,"data-quality":0.1130222208}}
{"text":"Language models contain ranking-based knowledge and are powerful solvers of in-context ranking tasks.","meta":{"url":"http://arxiv.org/abs/2309.06991v1"},"cats":{"new-dataset":0.0596742748,"dev-research":0.2206925218,"data-quality":0.1672938795}}
{"text":"For instance, they may have parametric knowledge about the ordering of countries by size or may be able to rank reviews by sentiment.","meta":{"url":"http://arxiv.org/abs/2309.06991v1"},"cats":{"new-dataset":0.046611896,"dev-research":0.1999216176,"data-quality":0.1357899873}}
{"text":"Recent work focuses on pairwise, pointwise, and listwise prompting techniques to elicit a language model's ranking knowledge.","meta":{"url":"http://arxiv.org/abs/2309.06991v1"},"cats":{"new-dataset":0.1420483687,"dev-research":0.2129736309,"data-quality":0.191445868}}
{"text":"However, we find that even with careful calibration and constrained decoding, prompting-based techniques may not always be self-consistent in the rankings they produce.","meta":{"url":"http://arxiv.org/abs/2309.06991v1"},"cats":{"new-dataset":0.007111065,"dev-research":0.196212398,"data-quality":0.3124480508}}
{"text":"This motivates us to explore an alternative approach that is inspired by an unsupervised probing method called Contrast-Consistent Search (CCS).","meta":{"url":"http://arxiv.org/abs/2309.06991v1"},"cats":{"new-dataset":0.0043033293,"dev-research":0.1636242003,"data-quality":0.167835759}}
{"text":"The idea is to train a probing model guided by a logical constraint: a model's representation of a statement and its negation must be mapped to contrastive true-false poles consistently across multiple statements.","meta":{"url":"http://arxiv.org/abs/2309.06991v1"},"cats":{"new-dataset":0.0207479341,"dev-research":0.2217679612,"data-quality":0.2308627408}}
{"text":"We hypothesize that similar constraints apply to ranking tasks where all items are related via consistent pairwise or listwise comparisons.","meta":{"url":"http://arxiv.org/abs/2309.06991v1"},"cats":{"new-dataset":0.0145584626,"dev-research":0.1948983191,"data-quality":0.148312653}}
{"text":"To this end, we extend the binary CCS method to Contrast-Consistent Ranking (CCR) by adapting existing ranking methods such as the Max-Margin Loss, Triplet Loss, and Ordinal Regression objective.","meta":{"url":"http://arxiv.org/abs/2309.06991v1"},"cats":{"new-dataset":0.0529205809,"dev-research":0.1570392149,"data-quality":0.2133577969}}
{"text":"Our results confirm that, for the same language model, CCR probing outperforms prompting and even performs on a par with prompting much larger language models.","meta":{"url":"http://arxiv.org/abs/2309.06991v1"},"cats":{"new-dataset":0.02912371,"dev-research":0.1987210008,"data-quality":0.2388988742}}
{"text":"Amyotrophic lateral sclerosis is a fatal disease that not only affects movement, speech, and breath but also cognition.","meta":{"url":"http://arxiv.org/abs/2309.06989v1"},"cats":{"new-dataset":0.0227246407,"dev-research":0.2659110435,"data-quality":0.0905491193}}
{"text":"Recent studies have focused on the use of language analysis techniques to detect ALS and infer scales for monitoring functional progression.","meta":{"url":"http://arxiv.org/abs/2309.06989v1"},"cats":{"new-dataset":0.0442149871,"dev-research":0.20133214,"data-quality":0.1857461415}}
{"text":"In this paper, we focused on another important aspect, cognitive impairment, which affects 35-50% of the ALS population.","meta":{"url":"http://arxiv.org/abs/2309.06989v1"},"cats":{"new-dataset":0.0349208516,"dev-research":0.3024237159,"data-quality":0.1453098018}}
{"text":"In an effort to reach the ALS population, which frequently exhibits mobility limitations, we implemented the digital version of the Edinburgh Cognitive and Behavioral ALS Screen (ECAS) test for the first time.","meta":{"url":"http://arxiv.org/abs/2309.06989v1"},"cats":{"new-dataset":0.0500793759,"dev-research":0.2241798911,"data-quality":0.1105100054}}
{"text":"This test which is designed to measure cognitive impairment was remotely performed by 56 participants from the EverythingALS Speech Study.","meta":{"url":"http://arxiv.org/abs/2309.06989v1"},"cats":{"new-dataset":0.0832371325,"dev-research":0.2051957683,"data-quality":0.1423460256}}
{"text":"As part of the study, participants (ALS and non-ALS) were asked to describe weekly one picture from a pool of many pictures with complex scenes displayed on their computer at home.","meta":{"url":"http://arxiv.org/abs/2309.06989v1"},"cats":{"new-dataset":0.322667201,"dev-research":0.2748762443,"data-quality":0.10519031}}
{"text":"We analyze the descriptions performed within +/- 60 days from the day the ECAS test was administered and extract different types of linguistic and acoustic features.","meta":{"url":"http://arxiv.org/abs/2309.06989v1"},"cats":{"new-dataset":0.2088212925,"dev-research":0.1559599732,"data-quality":0.2882013051}}
{"text":"We input those features into linear regression models to infer 5 ECAS sub-scores and the total score.","meta":{"url":"http://arxiv.org/abs/2309.06989v1"},"cats":{"new-dataset":0.1627455749,"dev-research":0.1455630316,"data-quality":0.1663163908}}
{"text":"Speech samples from the picture description are reliable enough to predict the ECAS subs-scores, achieving statistically significant Spearman correlation values between 0.32 and 0.51 for the model's performance using 10-fold cross-validation.","meta":{"url":"http://arxiv.org/abs/2309.06989v1"},"cats":{"new-dataset":0.2098001134,"dev-research":0.1238647795,"data-quality":0.2347110936}}
{"text":"Generalized zero-shot learning(GZSL) aims to classify samples from seen and unseen labels, assuming unseen labels are not accessible during training.","meta":{"url":"http://arxiv.org/abs/2309.06987v1"},"cats":{"new-dataset":0.098057532,"dev-research":0.0850134846,"data-quality":0.2863387976}}
{"text":"Recent advancements in GZSL have been expedited by incorporating contrastive-learning-based (instance-based) embedding in generative networks and leveraging the semantic relationship between data points.","meta":{"url":"http://arxiv.org/abs/2309.06987v1"},"cats":{"new-dataset":0.1008729732,"dev-research":0.1658860793,"data-quality":0.1464217541}}
{"text":"However, existing embedding architectures suffer from two limitations: (1) limited discriminability of synthetic features' embedding without considering fine-grained cluster structures; (2) inflexible optimization due to restricted scaling mechanisms on existing contrastive embedding networks, leading to overlapped representations in the embedding space.","meta":{"url":"http://arxiv.org/abs/2309.06987v1"},"cats":{"new-dataset":0.0513254647,"dev-research":0.1438116668,"data-quality":0.1321135347}}
{"text":"To enhance the quality of representations in the embedding space, as mentioned in (1), we propose a margin-based prototypical contrastive learning embedding network that reaps the benefits of prototype-data (cluster quality enhancement) and implicit data-data (fine-grained representations) interaction while providing substantial cluster supervision to the embedding network and the generator.","meta":{"url":"http://arxiv.org/abs/2309.06987v1"},"cats":{"new-dataset":0.1533250965,"dev-research":0.2661987798,"data-quality":0.2346762485}}
{"text":"To tackle (2), we propose an instance adaptive contrastive loss that leads to generalized representations for unseen labels with increased inter-class margin.","meta":{"url":"http://arxiv.org/abs/2309.06987v1"},"cats":{"new-dataset":0.1072768498,"dev-research":0.1347459025,"data-quality":0.5307581266}}
{"text":"Through comprehensive experimental evaluation, we show that our method can outperform the current state-of-the-art on three benchmark datasets.","meta":{"url":"http://arxiv.org/abs/2309.06987v1"},"cats":{"new-dataset":0.655232603,"dev-research":0.1378782629,"data-quality":0.3125029399}}
{"text":"Our approach also consistently achieves the best unseen performance in the GZSL setting.","meta":{"url":"http://arxiv.org/abs/2309.06987v1"},"cats":{"new-dataset":0.0177705958,"dev-research":0.1556265871,"data-quality":0.1199054372}}
{"text":"In this paper, we address the challenge of exploring unknown indoor aerial environments using autonomous aerial robots with Size Weight and Power (SWaP) constraints.","meta":{"url":"http://arxiv.org/abs/2309.06986v1"},"cats":{"new-dataset":0.0319751283,"dev-research":0.1725556238,"data-quality":0.0794484054}}
{"text":"The SWaP constraints induce limits on mission time requiring efficiency in exploration.","meta":{"url":"http://arxiv.org/abs/2309.06986v1"},"cats":{"new-dataset":0.0196609164,"dev-research":0.1996851051,"data-quality":0.042126999}}
{"text":"We present a novel exploration framework that uses Deep Learning (DL) to predict the most likely indoor map given the previous observations, and Deep Reinforcement Learning (DRL) for exploration, designed to run on modern SWaP constraints neural processors.","meta":{"url":"http://arxiv.org/abs/2309.06986v1"},"cats":{"new-dataset":0.307189886,"dev-research":0.1891122433,"data-quality":0.0633329034}}
{"text":"The DL-based map predictor provides a prediction of the occupancy of the unseen environment while the DRL-based planner determines the best navigation goals that can be safely reached to provide the most information.","meta":{"url":"http://arxiv.org/abs/2309.06986v1"},"cats":{"new-dataset":0.0744262351,"dev-research":0.3065964167,"data-quality":0.0493996745}}
{"text":"The two modules are tightly coupled and run onboard allowing the vehicle to safely map an unknown environment.","meta":{"url":"http://arxiv.org/abs/2309.06986v1"},"cats":{"new-dataset":0.0303784696,"dev-research":0.23754693,"data-quality":0.07599382}}
{"text":"Extensive experimental and simulation results show that our approach surpasses state-of-the-art methods by 50-60% in efficiency, which we measure by the fraction of the explored space as a function of the length of the trajectory traveled.","meta":{"url":"http://arxiv.org/abs/2309.06986v1"},"cats":{"new-dataset":0.0169783911,"dev-research":0.1271488769,"data-quality":0.0592759899}}
{"text":"We propose the first method that realizes the Laplace mechanism exactly (i.e., a Laplace noise is added to the data) that requires only a finite amount of communication (whereas the original Laplace mechanism requires the transmission of a real number) while guaranteeing privacy against the server and database.","meta":{"url":"http://arxiv.org/abs/2309.06982v1"},"cats":{"new-dataset":0.0532908488,"dev-research":0.1080633686,"data-quality":0.1289886361}}
{"text":"Our mechanism can serve as a drop-in replacement for local or centralized differential privacy applications where the Laplace mechanism is used.","meta":{"url":"http://arxiv.org/abs/2309.06982v1"},"cats":{"new-dataset":0.0199987226,"dev-research":0.1145269575,"data-quality":0.1026190686}}
{"text":"Our mechanism is constructed using a random quantization technique.","meta":{"url":"http://arxiv.org/abs/2309.06982v1"},"cats":{"new-dataset":0.0106556933,"dev-research":0.0845645985,"data-quality":0.1329410402}}
{"text":"Unlike the simple and prevalent Laplace-mechanism-then-quantize approach, the quantization in our mechanism does not result in any distortion or degradation of utility.","meta":{"url":"http://arxiv.org/abs/2309.06982v1"},"cats":{"new-dataset":0.0009556678,"dev-research":0.1107711742,"data-quality":0.1161934881}}
{"text":"Unlike existing dithered quantization and channel simulation schemes for simulating additive Laplacian noise, our mechanism guarantees privacy not only against the database and downstream, but also against the honest but curious server which attempts to decode the data using the dither signals.","meta":{"url":"http://arxiv.org/abs/2309.06982v1"},"cats":{"new-dataset":0.0582222775,"dev-research":0.0903643535,"data-quality":0.1278204815}}
{"text":"Speaker Verification (SV) is widely deployed in mobile systems to authenticate legitimate users by using their voice traits.","meta":{"url":"http://arxiv.org/abs/2309.06981v1"},"cats":{"new-dataset":0.0329931002,"dev-research":0.2184639988,"data-quality":0.2077178749}}
{"text":"In this work, we propose a backdoor attack MASTERKEY, to compromise the SV models.","meta":{"url":"http://arxiv.org/abs/2309.06981v1"},"cats":{"new-dataset":0.0437892449,"dev-research":0.1526311834,"data-quality":0.0889128235}}
{"text":"Different from previous attacks, we focus on a real-world practical setting where the attacker possesses no knowledge of the intended victim.","meta":{"url":"http://arxiv.org/abs/2309.06981v1"},"cats":{"new-dataset":0.0233593593,"dev-research":0.2612354207,"data-quality":0.1106475995}}
{"text":"To design MASTERKEY, we investigate the limitation of existing poisoning attacks against unseen targets.","meta":{"url":"http://arxiv.org/abs/2309.06981v1"},"cats":{"new-dataset":0.0234465478,"dev-research":0.1930668398,"data-quality":0.1543481838}}
{"text":"Then, we optimize a universal backdoor that is capable of attacking arbitrary targets.","meta":{"url":"http://arxiv.org/abs/2309.06981v1"},"cats":{"new-dataset":0.004413397,"dev-research":0.1865956047,"data-quality":0.067606694}}
{"text":"Next, we embed the speaker's characteristics and semantics information into the backdoor, making it imperceptible.","meta":{"url":"http://arxiv.org/abs/2309.06981v1"},"cats":{"new-dataset":0.0339331252,"dev-research":0.1955223394,"data-quality":0.2679428814}}
{"text":"Finally, we estimate the channel distortion and integrate it into the backdoor.","meta":{"url":"http://arxiv.org/abs/2309.06981v1"},"cats":{"new-dataset":0.0431123711,"dev-research":0.1210221543,"data-quality":0.1697204651}}
{"text":"We validate our attack on 6 popular SV models.","meta":{"url":"http://arxiv.org/abs/2309.06981v1"},"cats":{"new-dataset":0.0892771373,"dev-research":0.1768848748,"data-quality":0.154460242}}
{"text":"Specifically, we poison a total of 53 models and use our trigger to attack 16,430 enrolled speakers, composed of 310 target speakers enrolled in 53 poisoned models.","meta":{"url":"http://arxiv.org/abs/2309.06981v1"},"cats":{"new-dataset":0.194478729,"dev-research":0.20806233,"data-quality":0.1996938534}}
{"text":"Our attack achieves 100% attack success rate with a 15% poison rate.","meta":{"url":"http://arxiv.org/abs/2309.06981v1"},"cats":{"new-dataset":0.0728330794,"dev-research":0.2003168062,"data-quality":0.1262175804}}
{"text":"By decreasing the poison rate to 3%, the attack success rate remains around 50%.","meta":{"url":"http://arxiv.org/abs/2309.06981v1"},"cats":{"new-dataset":0.0165566895,"dev-research":0.1933301958,"data-quality":0.1488695975}}
{"text":"We validate our attack in 3 real-world scenarios and successfully demonstrate the attack through both over-the-air and over-the-telephony-line scenarios.","meta":{"url":"http://arxiv.org/abs/2309.06981v1"},"cats":{"new-dataset":0.1524637767,"dev-research":0.2285255417,"data-quality":0.0932669565}}
{"text":"Large language models display remarkable capabilities in logical and mathematical reasoning, allowing them to solve complex tasks.","meta":{"url":"http://arxiv.org/abs/2309.06979v1"},"cats":{"new-dataset":0.0813460387,"dev-research":0.2702743704,"data-quality":0.0812004749}}
{"text":"Interestingly, these abilities emerge in networks trained on the simple task of next-token prediction.","meta":{"url":"http://arxiv.org/abs/2309.06979v1"},"cats":{"new-dataset":0.013575931,"dev-research":0.1355740025,"data-quality":0.1746285494}}
{"text":"In this work, we present a theoretical framework for studying auto-regressive next-token predictors.","meta":{"url":"http://arxiv.org/abs/2309.06979v1"},"cats":{"new-dataset":0.0314202247,"dev-research":0.1121356177,"data-quality":0.186414896}}
{"text":"We demonstrate that even simple models such as linear next-token predictors, trained on Chain-of-Thought (CoT) data, can approximate any function efficiently computed by a Turing machine.","meta":{"url":"http://arxiv.org/abs/2309.06979v1"},"cats":{"new-dataset":0.0853492845,"dev-research":0.1727670178,"data-quality":0.0995216365}}
{"text":"We introduce a new complexity measure -- length complexity -- which measures the number of intermediate tokens in a CoT sequence required to approximate some target function, and analyze the interplay between length complexity and other notions of complexity.","meta":{"url":"http://arxiv.org/abs/2309.06979v1"},"cats":{"new-dataset":0.0245152121,"dev-research":0.2271778739,"data-quality":0.0700728046}}
{"text":"Finally, we show experimentally that simple next-token predictors, such as linear networks and shallow Multi-Layer Perceptrons (MLPs), display non-trivial performance on text generation and arithmetic tasks.","meta":{"url":"http://arxiv.org/abs/2309.06979v1"},"cats":{"new-dataset":0.0470452477,"dev-research":0.1793774142,"data-quality":0.2369778709}}
{"text":"Our results demonstrate that the power of language models can be attributed, to a great extent, to the auto-regressive next-token training scheme, and not necessarily to a particular choice of architecture.","meta":{"url":"http://arxiv.org/abs/2309.06979v1"},"cats":{"new-dataset":0.0289927629,"dev-research":0.1546048731,"data-quality":0.2712027987}}
{"text":"JPEG remains one of the most widespread lossy image coding methods.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.0300410452,"dev-research":0.1843800843,"data-quality":0.2914579113}}
{"text":"However, the non-differentiable nature of JPEG restricts the application in deep learning pipelines.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.0150090844,"dev-research":0.1674119918,"data-quality":0.146549097}}
{"text":"Several differentiable approximations of JPEG have recently been proposed to address this issue.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.0324785336,"dev-research":0.164256219,"data-quality":0.1722055169}}
{"text":"This paper conducts a comprehensive review of existing diff.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.144421984,"dev-research":0.3239633845,"data-quality":0.2077532812}}
{"text":"JPEG approaches and identifies critical details that have been missed by previous methods.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.0644737293,"dev-research":0.3167688924,"data-quality":0.308413465}}
{"text":"To this end, we propose a novel diff.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.2928026404,"dev-research":0.3002850725,"data-quality":0.1208682903}}
{"text":"JPEG approach, overcoming previous limitations.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.0924304728,"dev-research":0.1532579845,"data-quality":0.1216354695}}
{"text":"Our approach is differentiable w.r.t.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.0380691611,"dev-research":0.2337493056,"data-quality":0.1127873426}}
{"text":"the input image, the JPEG quality, the quantization tables, and the color conversion parameters.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.2000865077,"dev-research":0.1395616927,"data-quality":0.1142967421}}
{"text":"We evaluate the forward and backward performance of our diff.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.0732121071,"dev-research":0.2396524899,"data-quality":0.1584122858}}
{"text":"JPEG approach against existing methods.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.0332637396,"dev-research":0.1910395893,"data-quality":0.1863453345}}
{"text":"Additionally, extensive ablations are performed to evaluate crucial design choices.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.0142249719,"dev-research":0.2465622134,"data-quality":0.0608853923}}
{"text":"Our proposed diff.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.2038467497,"dev-research":0.3401892041,"data-quality":0.1160176855}}
{"text":"JPEG resembles the (non-diff.)","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.1853417029,"dev-research":0.1843532352,"data-quality":0.1794161917}}
{"text":"reference implementation best, significantly surpassing the recent-best diff.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.3304011431,"dev-research":0.3134227893,"data-quality":0.2172485583}}
{"text":"approach by $3.47$dB (PSNR) on average.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.1602150585,"dev-research":0.1231680083,"data-quality":0.1476903251}}
{"text":"For strong compression rates, we can even improve PSNR by $9.51$dB. Strong adversarial attack results are yielded by our diff.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.1194131011,"dev-research":0.1619578708,"data-quality":0.2526236945}}
{"text":"JPEG, demonstrating the effective gradient approximation.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.0695183018,"dev-research":0.1450944713,"data-quality":0.1621899261}}
{"text":"Our code is available at https://github.com/necla-ml/Diff-JPEG.","meta":{"url":"http://arxiv.org/abs/2309.06978v1"},"cats":{"new-dataset":0.5590243846,"dev-research":0.1965775259,"data-quality":0.1386783506}}
{"text":"Deep neural networks (DNNs) underpin many machine learning applications.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.0663028542,"dev-research":0.2305362819,"data-quality":0.1245915033}}
{"text":"Production quality DNN models achieve high inference accuracy by training millions of DNN parameters which has a significant resource footprint.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.3237425423,"dev-research":0.2886441803,"data-quality":0.2514245934}}
{"text":"This presents a challenge for resources operating at the extreme edge of the network, such as mobile and embedded devices that have limited computational and memory resources.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.0547523657,"dev-research":0.1948259202,"data-quality":0.0598752627}}
{"text":"To address this, models are pruned to create lightweight, more suitable variants for these devices.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.011904364,"dev-research":0.2046433616,"data-quality":0.0624700353}}
{"text":"Existing pruning methods are unable to provide similar quality models compared to their unpruned counterparts without significant time costs and overheads or are limited to offline use cases.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.0103180285,"dev-research":0.2029300526,"data-quality":0.16101179}}
{"text":"Our work rapidly derives suitable model variants while maintaining the accuracy of the original model.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.041308282,"dev-research":0.1890486088,"data-quality":0.1029594749}}
{"text":"The model variants can be swapped quickly when system and network conditions change to match workload demand.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.0048831043,"dev-research":0.197018929,"data-quality":0.0525696181}}
{"text":"This paper presents DNNShifter, an end-to-end DNN training, spatial pruning, and model switching system that addresses the challenges mentioned above.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.1642264919,"dev-research":0.2436165741,"data-quality":0.1460821848}}
{"text":"At the heart of DNNShifter is a novel methodology that prunes sparse models using structured pruning.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.0704659845,"dev-research":0.1477287915,"data-quality":0.1520570555}}
{"text":"The pruned model variants generated by DNNShifter are smaller in size and thus faster than dense and sparse model predecessors, making them suitable for inference at the edge while retaining near similar accuracy as of the original dense model.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.0185731204,"dev-research":0.1745255748,"data-quality":0.1114950773}}
{"text":"DNNShifter generates a portfolio of model variants that can be swiftly interchanged depending on operational conditions.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.0254290959,"dev-research":0.2283466974,"data-quality":0.0765756254}}
{"text":"DNNShifter produces pruned model variants up to 93x faster than conventional training methods.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.046114287,"dev-research":0.2064487414,"data-quality":0.1001081881}}
{"text":"Compared to sparse models, the pruned model variants are up to 5.14x smaller and have a 1.67x inference latency speedup, with no compromise to sparse model accuracy.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.0253871162,"dev-research":0.1410234947,"data-quality":0.090786788}}
{"text":"In addition, DNNShifter has up to 11.9x lower overhead for switching models and up to 3.8x lower memory utilisation than existing approaches.","meta":{"url":"http://arxiv.org/abs/2309.06973v1"},"cats":{"new-dataset":0.0253233053,"dev-research":0.2734824859,"data-quality":0.0865821594}}
{"text":"Algorithmic systems are often called upon to assist in high-stakes decision making.","meta":{"url":"http://arxiv.org/abs/2309.06969v1"},"cats":{"new-dataset":0.0115287629,"dev-research":0.3563913942,"data-quality":0.0801583274}}
{"text":"In light of this, algorithmic recourse, the principle wherein individuals should be able to take action against an undesirable outcome made by an algorithmic system, is receiving growing attention.","meta":{"url":"http://arxiv.org/abs/2309.06969v1"},"cats":{"new-dataset":0.0191782423,"dev-research":0.3082459245,"data-quality":0.0979151724}}
{"text":"The bulk of the literature on algorithmic recourse to-date focuses primarily on how to provide recourse to a single individual, overlooking a critical element: the effects of a continuously changing context.","meta":{"url":"http://arxiv.org/abs/2309.06969v1"},"cats":{"new-dataset":0.043034379,"dev-research":0.4177760505,"data-quality":0.1424003016}}
{"text":"Disregarding these effects on recourse is a significant oversight, since, in almost all cases, recourse consists of an individual making a first, unfavorable attempt, and then being given an opportunity to make one or several attempts at a later date - when the context might have changed.","meta":{"url":"http://arxiv.org/abs/2309.06969v1"},"cats":{"new-dataset":0.0045033209,"dev-research":0.3965289849,"data-quality":0.1557446025}}
{"text":"This can create false expectations, as initial recourse recommendations may become less reliable over time due to model drift and competition for access to the favorable outcome between individuals.   ","meta":{"url":"http://arxiv.org/abs/2309.06969v1"},"cats":{"new-dataset":0.001686813,"dev-research":0.3266761883,"data-quality":0.0869679492}}
{"text":"In this work we propose an agent-based simulation framework for studying the effects of a continuously changing environment on algorithmic recourse.","meta":{"url":"http://arxiv.org/abs/2309.06969v1"},"cats":{"new-dataset":0.0760572486,"dev-research":0.3188479657,"data-quality":0.0638452716}}
{"text":"In particular, we identify two main effects that can alter the reliability of recourse for individuals represented by the agents: (1) competition with other agents acting upon recourse, and (2) competition with new agents entering the environment.","meta":{"url":"http://arxiv.org/abs/2309.06969v1"},"cats":{"new-dataset":0.0332907758,"dev-research":0.3404867748,"data-quality":0.1368273827}}
{"text":"Our findings highlight that only a small set of specific parameterizations result in algorithmic recourse that is reliable for agents over time.","meta":{"url":"http://arxiv.org/abs/2309.06969v1"},"cats":{"new-dataset":0.0151512033,"dev-research":0.2875917422,"data-quality":0.136628881}}
{"text":"Consequently, we argue that substantial additional work is needed to understand recourse reliability over time, and to develop recourse methods that reward agents' effort.","meta":{"url":"http://arxiv.org/abs/2309.06969v1"},"cats":{"new-dataset":0.029573952,"dev-research":0.4364980993,"data-quality":0.145821956}}
{"text":"Generalized metric spaces are obtained by weakening the requirements (e.g., symmetry) on the distance function and by allowing it to take values in structures (e.g., quantales) that are more general than the set of non-negative real numbers.","meta":{"url":"http://arxiv.org/abs/2309.06968v1"},"cats":{"new-dataset":0.0189437952,"dev-research":0.2394532024,"data-quality":0.0960667101}}
{"text":"Quantale-valued metric spaces have gained prominence due to their use in quantitative reasoning on programs/systems, and for defining various notions of behavioral metrics.   ","meta":{"url":"http://arxiv.org/abs/2309.06968v1"},"cats":{"new-dataset":0.0762825998,"dev-research":0.3092107093,"data-quality":0.1482397374}}
{"text":"We investigate imprecision and robustness in the framework of quantale-valued metric spaces, when the quantale is continuous.","meta":{"url":"http://arxiv.org/abs/2309.06968v1"},"cats":{"new-dataset":0.0417194498,"dev-research":0.3102644768,"data-quality":0.3244039172}}
{"text":"In particular, we study the relation between the robust topology, which captures robustness of analyses, and the Hausdorff-Smyth hemi-metric.","meta":{"url":"http://arxiv.org/abs/2309.06968v1"},"cats":{"new-dataset":0.0528597272,"dev-research":0.2477088651,"data-quality":0.2201878909}}
{"text":"To this end, we define a preorder-enriched monad $\\mathsf{P}_S$, called the Hausdorff-Smyth monad, and when $Q$ is a continuous quantale and $X$ is a $Q$-metric space, we relate the topology induced by the metric on $\\mathsf{P}_S(X)$ with the robust topology on the powerset $\\mathsf{P}(X)$ defined in terms of the metric on $X$.","meta":{"url":"http://arxiv.org/abs/2309.06968v1"},"cats":{"new-dataset":0.0428856798,"dev-research":0.171077195,"data-quality":0.1243179665}}
{"text":"Benchmark datasets for digital dermatology unwittingly contain inaccuracies that reduce trust in model performance estimates.","meta":{"url":"http://arxiv.org/abs/2309.06961v1"},"cats":{"new-dataset":0.3702405961,"dev-research":0.2129030869,"data-quality":0.2218278075}}
{"text":"We propose a resource-efficient data cleaning protocol to identify issues that escaped previous curation.","meta":{"url":"http://arxiv.org/abs/2309.06961v1"},"cats":{"new-dataset":0.2279240109,"dev-research":0.315651126,"data-quality":0.4131735886}}
{"text":"The protocol leverages an existing algorithmic cleaning strategy and is followed by a confirmation process terminated by an intuitive stopping criterion.","meta":{"url":"http://arxiv.org/abs/2309.06961v1"},"cats":{"new-dataset":0.0036823944,"dev-research":0.2053849829,"data-quality":0.1474277629}}
{"text":"Based on confirmation by multiple dermatologists, we remove irrelevant samples and near duplicates and estimate the percentage of label errors in six dermatology image datasets for model evaluation promoted by the International Skin Imaging Collaboration.","meta":{"url":"http://arxiv.org/abs/2309.06961v1"},"cats":{"new-dataset":0.4207325551,"dev-research":0.2781106634,"data-quality":0.5825236738}}
{"text":"Along with this paper, we publish revised file lists for each dataset which should be used for model evaluation.","meta":{"url":"http://arxiv.org/abs/2309.06961v1"},"cats":{"new-dataset":0.7834996409,"dev-research":0.1980984801,"data-quality":0.1539247831}}
{"text":"Our work paves the way for more trustworthy performance assessment in digital dermatology.","meta":{"url":"http://arxiv.org/abs/2309.06961v1"},"cats":{"new-dataset":0.077617711,"dev-research":0.3126433662,"data-quality":0.1717505019}}
{"text":"In this paper, we propose PhantomSound, a query-efficient black-box attack toward voice assistants.","meta":{"url":"http://arxiv.org/abs/2309.06960v1"},"cats":{"new-dataset":0.0751041766,"dev-research":0.1806237818,"data-quality":0.1965820608}}
{"text":"Existing black-box adversarial attacks on voice assistants either apply substitution models or leverage the intermediate model output to estimate the gradients for crafting adversarial audio samples.","meta":{"url":"http://arxiv.org/abs/2309.06960v1"},"cats":{"new-dataset":0.0501535517,"dev-research":0.1433582861,"data-quality":0.2376351321}}
{"text":"However, these attack approaches require a significant amount of queries with a lengthy training stage.","meta":{"url":"http://arxiv.org/abs/2309.06960v1"},"cats":{"new-dataset":0.0237542335,"dev-research":0.1664159214,"data-quality":0.0776551384}}
{"text":"PhantomSound leverages the decision-based attack to produce effective adversarial audios, and reduces the number of queries by optimizing the gradient estimation.","meta":{"url":"http://arxiv.org/abs/2309.06960v1"},"cats":{"new-dataset":0.0225686566,"dev-research":0.1761581402,"data-quality":0.2656848727}}
{"text":"In the experiments, we perform our attack against 4 different speech-to-text APIs under 3 real-world scenarios to demonstrate the real-time attack impact.","meta":{"url":"http://arxiv.org/abs/2309.06960v1"},"cats":{"new-dataset":0.119818962,"dev-research":0.2316532475,"data-quality":0.1848095034}}
{"text":"The results show that PhantomSound is practical and robust in attacking 5 popular commercial voice controllable devices over the air, and is able to bypass 3 liveness detection mechanisms with >95% success rate.","meta":{"url":"http://arxiv.org/abs/2309.06960v1"},"cats":{"new-dataset":0.0831739739,"dev-research":0.240025925,"data-quality":0.2159655062}}
{"text":"The benchmark result shows that PhantomSound can generate adversarial examples and launch the attack in a few minutes.","meta":{"url":"http://arxiv.org/abs/2309.06960v1"},"cats":{"new-dataset":0.0550071192,"dev-research":0.2151754617,"data-quality":0.2010711715}}
{"text":"We significantly enhance the query efficiency and reduce the cost of a successful untargeted and targeted adversarial attack by 93.1% and 65.5% compared with the state-of-the-art black-box attacks, using merely ~300 queries (~5 minutes) and ~1,500 queries (~25 minutes), respectively.","meta":{"url":"http://arxiv.org/abs/2309.06960v1"},"cats":{"new-dataset":0.0419997342,"dev-research":0.1977179221,"data-quality":0.1626362635}}
{"text":"Background.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.2364991768,"dev-research":0.1841752616,"data-quality":0.1078251366}}
{"text":"Cardiac dominance classification is essential for SYNTAX score estimation, which is a tool used to determine the complexity of coronary artery disease and guide patient selection toward optimal revascularization strategy.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.0238557736,"dev-research":0.2418011184,"data-quality":0.1373355465}}
{"text":"Objectives.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.0698256136,"dev-research":0.2203203948,"data-quality":0.0816842677}}
{"text":"Cardiac dominance classification algorithm based on the analysis of right coronary artery (RCA) angiograms using neural network Method.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.029414704,"dev-research":0.1777273592,"data-quality":0.122562305}}
{"text":"We employed convolutional neural network ConvNext and Swin transformer for 2D image (frames) classification, along with a majority vote for cardio angiographic view classification.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.2055029126,"dev-research":0.1928509488,"data-quality":0.1208021666}}
{"text":"An auxiliary network was also used to detect irrelevant images which were then excluded from the data set.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.0319304772,"dev-research":0.1286565238,"data-quality":0.2979073775}}
{"text":"Our data set consisted of 828 angiographic studies, 192 of them being patients with left dominance.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.2661227873,"dev-research":0.1698781445,"data-quality":0.0566864213}}
{"text":"Results.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.0893395345,"dev-research":0.1616554727,"data-quality":0.187316927}}
{"text":"5-fold cross validation gave the following dominance classification metrics (p=95%): macro recall=93.1%, accuracy=93.5%, macro F1=89.2%.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.0606359227,"dev-research":0.1666907645,"data-quality":0.150256722}}
{"text":"The most common case in which the model regularly failed was RCA occlusion, as it requires utilization of LCA information.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.0221105768,"dev-research":0.1793137708,"data-quality":0.4020729687}}
{"text":"Another cause for false prediction is a small diameter combined with poor quality cardio angiographic view.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.015487173,"dev-research":0.2262528405,"data-quality":0.2835822386}}
{"text":"In such cases, cardiac dominance classification can be complex and may require discussion among specialists to reach an accurate conclusion.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.0086266481,"dev-research":0.2031358108,"data-quality":0.1131345059}}
{"text":"Conclusion.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.0464442649,"dev-research":0.2218393868,"data-quality":0.1313362253}}
{"text":"The use of machine learning approaches to classify cardiac dominance based on RCA alone has been shown to be successful with satisfactory accuracy.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.01239574,"dev-research":0.1499395781,"data-quality":0.1280595106}}
{"text":"However, for higher accuracy, it is necessary to utilize LCA information in the case of an occluded RCA and detect cases where there is high uncertainty.","meta":{"url":"http://arxiv.org/abs/2309.06958v1"},"cats":{"new-dataset":0.0108236306,"dev-research":0.1460591793,"data-quality":0.2560634899}}
{"text":"The key factor currently limiting the advancement of computational power of electronic computation is no longer the manufacturing density and speed of components, but rather their high energy consumption.","meta":{"url":"http://arxiv.org/abs/2309.06957v1"},"cats":{"new-dataset":0.0172230268,"dev-research":0.2764712007,"data-quality":0.0456196497}}
{"text":"While it has been widely argued that reversible computation can escape the fundamental Landauer limit of $k_B T\\ln(2)$ Joules per irreversible computational step, there is disagreement around whether indefinitely reusable computation can be achieved without energy dissipation.","meta":{"url":"http://arxiv.org/abs/2309.06957v1"},"cats":{"new-dataset":0.0080728977,"dev-research":0.1487392497,"data-quality":0.0470219348}}
{"text":"Here we focus on the relatively simpler context of sampling problems, which take no input, so avoids modeling the energy costs of the observer perturbing the machine to change its input.","meta":{"url":"http://arxiv.org/abs/2309.06957v1"},"cats":{"new-dataset":0.028012983,"dev-research":0.1458296484,"data-quality":0.1543831633}}
{"text":"Given an algorithm $A$ for generating samples from a distribution, we desire a device that can perpetually generate samples from that distribution driven entirely by Brownian motion.","meta":{"url":"http://arxiv.org/abs/2309.06957v1"},"cats":{"new-dataset":0.0567315873,"dev-research":0.1055745319,"data-quality":0.0786214011}}
{"text":"We show that such a device can efficiently execute algorithm $A$ in the sense that we must wait only $O(\\text{time}(A)^2)$ between samples.","meta":{"url":"http://arxiv.org/abs/2309.06957v1"},"cats":{"new-dataset":0.0330800563,"dev-research":0.103058192,"data-quality":0.0648252335}}
{"text":"We consider two output models: Las Vegas, which samples from the exact probability distribution every $4$ tries in expectation, and Monte Carlo, in which every try succeeds but the distribution is only approximated.","meta":{"url":"http://arxiv.org/abs/2309.06957v1"},"cats":{"new-dataset":0.0183046084,"dev-research":0.1401729429,"data-quality":0.1640780381}}
{"text":"We base our model on continuous-time random walks over the state space graph of a general computational machine, with a space-bounded Turing machine as one instantiation.","meta":{"url":"http://arxiv.org/abs/2309.06957v1"},"cats":{"new-dataset":0.1529467076,"dev-research":0.1358506383,"data-quality":0.0835812268}}
{"text":"The problem of sampling a computationally complex probability distribution with no energy dissipation informs our understanding of the energy requirements of computation, and may lead to more energy efficient randomized algorithms.","meta":{"url":"http://arxiv.org/abs/2309.06957v1"},"cats":{"new-dataset":0.0710017315,"dev-research":0.1352740267,"data-quality":0.0722853063}}
{"text":"Dexterous manipulation of objects once held in hand remains a challenge.","meta":{"url":"http://arxiv.org/abs/2309.06955v1"},"cats":{"new-dataset":0.0391220183,"dev-research":0.2044550274,"data-quality":0.0794972064}}
{"text":"Such skills are, however, necessary for robotics to move beyond gripper-based manipulation and use all the dexterity offered by anthropomorphic robotic hands.","meta":{"url":"http://arxiv.org/abs/2309.06955v1"},"cats":{"new-dataset":0.0392839018,"dev-research":0.1718449624,"data-quality":0.0441047889}}
{"text":"One major challenge when manipulating an object within the hand is that fingers must move around the object while avoiding collision with other fingers or the object.","meta":{"url":"http://arxiv.org/abs/2309.06955v1"},"cats":{"new-dataset":0.0361711692,"dev-research":0.2457887887,"data-quality":0.0886572834}}
{"text":"Such collision-free paths must be computed in real-time, as the smallest deviation from the original plan can easily lead to collisions.","meta":{"url":"http://arxiv.org/abs/2309.06955v1"},"cats":{"new-dataset":0.025276824,"dev-research":0.1913518585,"data-quality":0.0456907793}}
{"text":"We present a real-time approach to computing collision-free paths in a high-dimensional space.","meta":{"url":"http://arxiv.org/abs/2309.06955v1"},"cats":{"new-dataset":0.2927496038,"dev-research":0.2046691779,"data-quality":0.0363629492}}
{"text":"To guide the exploration, we learn an explicit representation of the free space, retrievable in real-time.","meta":{"url":"http://arxiv.org/abs/2309.06955v1"},"cats":{"new-dataset":0.1645719642,"dev-research":0.1888455767,"data-quality":0.0597872455}}
{"text":"We further combine this representation with closed-loop control via dynamical systems and sampling-based motion planning and show that the combination increases performance compared to alternatives, offering efficient search of feasible paths and real-time obstacle avoidance in a multi-fingered robotic hand.","meta":{"url":"http://arxiv.org/abs/2309.06955v1"},"cats":{"new-dataset":0.0879868806,"dev-research":0.1443791979,"data-quality":0.0343767569}}
{"text":"Human action recognition (HAR) is a high-level and significant research area in computer vision due to its ubiquitous applications.","meta":{"url":"http://arxiv.org/abs/2309.06951v1"},"cats":{"new-dataset":0.1201889997,"dev-research":0.226840342,"data-quality":0.0917759261}}
{"text":"The main limitations of the current HAR models are their complex structures and lengthy training time.","meta":{"url":"http://arxiv.org/abs/2309.06951v1"},"cats":{"new-dataset":0.0104917562,"dev-research":0.1324724994,"data-quality":0.0420482017}}
{"text":"In this paper, we propose a simple yet versatile and effective end-to-end deep learning architecture, coined as TransNet, for HAR.","meta":{"url":"http://arxiv.org/abs/2309.06951v1"},"cats":{"new-dataset":0.168422423,"dev-research":0.1612282057,"data-quality":0.0992136623}}
{"text":"TransNet decomposes the complex 3D-CNNs into 2D- and 1D-CNNs, where the 2D- and 1D-CNN components extract spatial features and temporal patterns in videos, respectively.","meta":{"url":"http://arxiv.org/abs/2309.06951v1"},"cats":{"new-dataset":0.1343227108,"dev-research":0.1747869171,"data-quality":0.1047234337}}
{"text":"Benefiting from its concise architecture, TransNet is ideally compatible with any pretrained state-of-the-art 2D-CNN models in other fields, being transferred to serve the HAR task.","meta":{"url":"http://arxiv.org/abs/2309.06951v1"},"cats":{"new-dataset":0.0375861802,"dev-research":0.1573964112,"data-quality":0.0651981918}}
{"text":"In other words, it naturally leverages the power and success of transfer learning for HAR, bringing huge advantages in terms of efficiency and effectiveness.","meta":{"url":"http://arxiv.org/abs/2309.06951v1"},"cats":{"new-dataset":0.0038392785,"dev-research":0.1963888907,"data-quality":0.0545186335}}
{"text":"Extensive experimental results and the comparison with the state-of-the-art models demonstrate the superior performance of the proposed TransNet in HAR in terms of flexibility, model complexity, training speed and classification accuracy.","meta":{"url":"http://arxiv.org/abs/2309.06951v1"},"cats":{"new-dataset":0.0175968478,"dev-research":0.1348010256,"data-quality":0.1066054835}}
{"text":"In this letter, we address the problem of exploration and metric-semantic mapping of multi-floor GPS-denied indoor environments using Size Weight and Power (SWaP) constrained aerial robots.","meta":{"url":"http://arxiv.org/abs/2309.06950v1"},"cats":{"new-dataset":0.0438448943,"dev-research":0.2042396568,"data-quality":0.0845129383}}
{"text":"Most previous work in exploration assumes that robot localization is solved.","meta":{"url":"http://arxiv.org/abs/2309.06950v1"},"cats":{"new-dataset":0.0232262189,"dev-research":0.2182321845,"data-quality":0.1113658915}}
{"text":"However, neglecting the state uncertainty of the agent can ultimately lead to cascading errors both in the resulting map and in the state of the agent itself.","meta":{"url":"http://arxiv.org/abs/2309.06950v1"},"cats":{"new-dataset":0.0046556899,"dev-research":0.2442375994,"data-quality":0.2614574076}}
{"text":"Furthermore, actions that reduce localization errors may be at direct odds with the exploration task.","meta":{"url":"http://arxiv.org/abs/2309.06950v1"},"cats":{"new-dataset":0.0083864185,"dev-research":0.2429057586,"data-quality":0.2079993203}}
{"text":"We propose a framework that balances the efficiency of exploration with actions that reduce the state uncertainty of the agent.","meta":{"url":"http://arxiv.org/abs/2309.06950v1"},"cats":{"new-dataset":0.0148300506,"dev-research":0.1622754006,"data-quality":0.047553312}}
{"text":"In particular, our algorithmic approach for active metric-semantic SLAM is built upon sparse information abstracted from raw problem data, to make it suitable for SWaP-constrained robots.","meta":{"url":"http://arxiv.org/abs/2309.06950v1"},"cats":{"new-dataset":0.1655760084,"dev-research":0.2306302148,"data-quality":0.1660735858}}
{"text":"Furthermore, we integrate this framework within a fully autonomous aerial robotic system that achieves autonomous exploration in cluttered, 3D environments.","meta":{"url":"http://arxiv.org/abs/2309.06950v1"},"cats":{"new-dataset":0.0457485673,"dev-research":0.1299629241,"data-quality":0.0477790314}}
{"text":"From extensive real-world experiments, we showed that by including Semantic Loop Closure (SLC), we can reduce the robot pose estimation errors by over 90% in translation and approximately 75% in yaw, and the uncertainties in pose estimates and semantic maps by over 70% and 65%, respectively.","meta":{"url":"http://arxiv.org/abs/2309.06950v1"},"cats":{"new-dataset":0.2393337731,"dev-research":0.2876340608,"data-quality":0.2399378554}}
{"text":"Although discussed in the context of indoor multi-floor exploration, our system can be used for various other applications, such as infrastructure inspection and precision agriculture where reliable GPS data may not be available.","meta":{"url":"http://arxiv.org/abs/2309.06950v1"},"cats":{"new-dataset":0.0738609227,"dev-research":0.1700267904,"data-quality":0.0706257699}}
{"text":"The goal of low-light image enhancement is to restore the color and details of the image and is of great significance for high-level visual tasks in autonomous driving.","meta":{"url":"http://arxiv.org/abs/2309.06941v1"},"cats":{"new-dataset":0.0280678164,"dev-research":0.2129594441,"data-quality":0.0858488607}}
{"text":"However, it is difficult to restore the lost details in the dark area by relying only on the RGB domain.","meta":{"url":"http://arxiv.org/abs/2309.06941v1"},"cats":{"new-dataset":0.0171810044,"dev-research":0.1796409874,"data-quality":0.2418563306}}
{"text":"In this paper we introduce frequency as a new clue into the network and propose a novel DCT-driven enhancement transformer (DEFormer).","meta":{"url":"http://arxiv.org/abs/2309.06941v1"},"cats":{"new-dataset":0.0123148174,"dev-research":0.1667012539,"data-quality":0.1016962754}}
{"text":"First, we propose a learnable frequency branch (LFB) for frequency enhancement contains DCT processing and curvature-based frequency enhancement (CFE).","meta":{"url":"http://arxiv.org/abs/2309.06941v1"},"cats":{"new-dataset":0.0219727275,"dev-research":0.1682737286,"data-quality":0.1633352913}}
{"text":"CFE calculates the curvature of each channel to represent the detail richness of different frequency bands, then we divides the frequency features, which focuses on frequency bands with richer textures.","meta":{"url":"http://arxiv.org/abs/2309.06941v1"},"cats":{"new-dataset":0.0286557799,"dev-research":0.1540816366,"data-quality":0.1139784468}}
{"text":"In addition, we propose a cross domain fusion (CDF) for reducing the differences between the RGB domain and the frequency domain.","meta":{"url":"http://arxiv.org/abs/2309.06941v1"},"cats":{"new-dataset":0.0473843346,"dev-research":0.1428120973,"data-quality":0.117769022}}
{"text":"We also adopt DEFormer as a preprocessing in dark detection, DEFormer effectively improves the performance of the detector, bringing 2.1% and 3.4% improvement in ExDark and DARK FACE datasets on mAP respectively.","meta":{"url":"http://arxiv.org/abs/2309.06941v1"},"cats":{"new-dataset":0.1413530945,"dev-research":0.2020276815,"data-quality":0.194663123}}
{"text":"Systems for heating, ventilation and air-conditioning (HVAC) of buildings are traditionally controlled by a rule-based approach.","meta":{"url":"http://arxiv.org/abs/2309.06940v1"},"cats":{"new-dataset":0.0316101045,"dev-research":0.3122316786,"data-quality":0.0496461561}}
{"text":"In order to reduce the energy consumption and the environmental impact of HVAC systems more advanced control methods such as reinforcement learning are promising.","meta":{"url":"http://arxiv.org/abs/2309.06940v1"},"cats":{"new-dataset":0.024034405,"dev-research":0.2051324397,"data-quality":0.0511555539}}
{"text":"Reinforcement learning (RL) strategies offer a good alternative, as user feedback can be integrated more easily and presence can also be incorporated.","meta":{"url":"http://arxiv.org/abs/2309.06940v1"},"cats":{"new-dataset":0.0212736927,"dev-research":0.2030037486,"data-quality":0.0755993514}}
{"text":"Moreover, multi-agent RL approaches scale well and can be generalized.","meta":{"url":"http://arxiv.org/abs/2309.06940v1"},"cats":{"new-dataset":0.0247662155,"dev-research":0.1356304107,"data-quality":0.045674746}}
{"text":"In this paper, we propose a multi-agent RL framework based on existing work that learns reducing on one hand energy consumption by optimizing HVAC control and on the other hand user feedback by occupants about uncomfortable room temperatures.","meta":{"url":"http://arxiv.org/abs/2309.06940v1"},"cats":{"new-dataset":0.1459923566,"dev-research":0.2406164589,"data-quality":0.0594362602}}
{"text":"Second, we show how to reduce training time required for proper RL-agent-training by using parameter sharing between the multiple agents and apply different pretraining techniques.","meta":{"url":"http://arxiv.org/abs/2309.06940v1"},"cats":{"new-dataset":0.0644535914,"dev-research":0.1651938889,"data-quality":0.0802571709}}
{"text":"Results show that our framework is capable of reducing the energy by around 6% when controlling a complete building or 8% for a single room zone.","meta":{"url":"http://arxiv.org/abs/2309.06940v1"},"cats":{"new-dataset":0.0309899113,"dev-research":0.2442981806,"data-quality":0.0481726874}}
{"text":"The occupants complaints are acceptable or even better compared to a rule-based baseline.","meta":{"url":"http://arxiv.org/abs/2309.06940v1"},"cats":{"new-dataset":0.0418538201,"dev-research":0.4129235128,"data-quality":0.2519452619}}
{"text":"Additionally, our performance analysis show that the training time can be drastically reduced by using parameter sharing.","meta":{"url":"http://arxiv.org/abs/2309.06940v1"},"cats":{"new-dataset":0.0107560798,"dev-research":0.2163110227,"data-quality":0.0988798427}}
{"text":"By and large, the professional handling of huge data collections is regarded as a fundamental ingredient of the progress of machine learning and of its spectacular results in related disciplines, with a growing agreement on risks connected to the centralization of such data collections.","meta":{"url":"http://arxiv.org/abs/2309.06938v1"},"cats":{"new-dataset":0.5632621722,"dev-research":0.2784440539,"data-quality":0.2148269607}}
{"text":"This paper sustains the position that the time has come for thinking of new learning protocols where machines conquer cognitive skills in a truly human-like context centered on environmental interactions.","meta":{"url":"http://arxiv.org/abs/2309.06938v1"},"cats":{"new-dataset":0.1586622549,"dev-research":0.3150002425,"data-quality":0.0796105027}}
{"text":"This comes with specific restrictions on the learning protocol according to the collectionless principle, which states that, at each time instant, data acquired from the environment is processed with the purpose of contributing to update the current internal representation of the environment, and that the agent is not given the privilege of recording the temporal stream.","meta":{"url":"http://arxiv.org/abs/2309.06938v1"},"cats":{"new-dataset":0.0862484654,"dev-research":0.1444408652,"data-quality":0.0852741225}}
{"text":"Basically, there is neither permission to store the temporal information coming from the sensors, thus promoting the development of self-organized memorization skills at a more abstract level, instead of relying on bare storage to simulate learning dynamics that are typical of offline learning algorithms.","meta":{"url":"http://arxiv.org/abs/2309.06938v1"},"cats":{"new-dataset":0.0677818423,"dev-research":0.1575793883,"data-quality":0.0730881706}}
{"text":"This purposely extreme position is intended to stimulate the development of machines that learn to dynamically organize the information by following human-based schemes.","meta":{"url":"http://arxiv.org/abs/2309.06938v1"},"cats":{"new-dataset":0.052714656,"dev-research":0.26773982,"data-quality":0.0807207693}}
{"text":"The proposition of this challenge suggests developing new foundations on computational processes of learning and reasoning that might open the doors to a truly orthogonal competitive track on AI technologies that avoid data accumulation by design, thus offering a framework which is better suited concerning privacy issues, control and customizability.","meta":{"url":"http://arxiv.org/abs/2309.06938v1"},"cats":{"new-dataset":0.1360354776,"dev-research":0.189684429,"data-quality":0.1021417267}}
{"text":"Finally, pushing towards massively distributed computation, the collectionless approach to AI will likely reduce the concentration of power in companies and governments, thus better facing geopolitical issues.","meta":{"url":"http://arxiv.org/abs/2309.06938v1"},"cats":{"new-dataset":0.053171862,"dev-research":0.1477947328,"data-quality":0.1022829568}}
{"text":"Recent progresses in large-scale text-to-image models have yielded remarkable accomplishments, finding various applications in art domain.","meta":{"url":"http://arxiv.org/abs/2309.06933v1"},"cats":{"new-dataset":0.1342812939,"dev-research":0.1086729832,"data-quality":0.1418318057}}
{"text":"However, expressing unique characteristics of an artwork (e.g. brushwork, colortone, or composition) with text prompts alone may encounter limitations due to the inherent constraints of verbal description.","meta":{"url":"http://arxiv.org/abs/2309.06933v1"},"cats":{"new-dataset":0.0150533809,"dev-research":0.2900472175,"data-quality":0.2258992831}}
{"text":"To this end, we introduce DreamStyler, a novel framework designed for artistic image synthesis, proficient in both text-to-image synthesis and style transfer.","meta":{"url":"http://arxiv.org/abs/2309.06933v1"},"cats":{"new-dataset":0.2536628406,"dev-research":0.2346488876,"data-quality":0.1145564384}}
{"text":"DreamStyler optimizes a multi-stage textual embedding with a context-aware text prompt, resulting in prominent image quality.","meta":{"url":"http://arxiv.org/abs/2309.06933v1"},"cats":{"new-dataset":0.0774111585,"dev-research":0.1868103194,"data-quality":0.1595772368}}
{"text":"In addition, with content and style guidance, DreamStyler exhibits flexibility to accommodate a range of style references.","meta":{"url":"http://arxiv.org/abs/2309.06933v1"},"cats":{"new-dataset":0.0271807464,"dev-research":0.2136022806,"data-quality":0.0805093218}}
{"text":"Experimental results demonstrate its superior performance across multiple scenarios, suggesting its promising potential in artistic product creation.","meta":{"url":"http://arxiv.org/abs/2309.06933v1"},"cats":{"new-dataset":0.0160630202,"dev-research":0.2986423303,"data-quality":0.079975616}}
{"text":"Emotion detection is a critical technology extensively employed in diverse fields.","meta":{"url":"http://arxiv.org/abs/2309.06928v1"},"cats":{"new-dataset":0.0614465903,"dev-research":0.2476042013,"data-quality":0.1505152027}}
{"text":"While the incorporation of commonsense knowledge has proven beneficial for existing emotion detection methods, dialogue-based emotion detection encounters numerous difficulties and challenges due to human agency and the variability of dialogue content.","meta":{"url":"http://arxiv.org/abs/2309.06928v1"},"cats":{"new-dataset":0.3669436554,"dev-research":0.183807888,"data-quality":0.210440236}}
{"text":"In dialogues, human emotions tend to accumulate in bursts.","meta":{"url":"http://arxiv.org/abs/2309.06928v1"},"cats":{"new-dataset":0.097846539,"dev-research":0.2953884835,"data-quality":0.1081335566}}
{"text":"However, they are often implicitly expressed.","meta":{"url":"http://arxiv.org/abs/2309.06928v1"},"cats":{"new-dataset":0.0070924206,"dev-research":0.3206470878,"data-quality":0.2320584889}}
{"text":"This implies that many genuine emotions remain concealed within a plethora of unrelated words and dialogues.","meta":{"url":"http://arxiv.org/abs/2309.06928v1"},"cats":{"new-dataset":0.0733806157,"dev-research":0.217245159,"data-quality":0.1991268469}}
{"text":"In this paper, we propose a Dynamic Causal Disentanglement Model based on hidden variable separation, which is founded on the separation of hidden variables.","meta":{"url":"http://arxiv.org/abs/2309.06928v1"},"cats":{"new-dataset":0.0320840749,"dev-research":0.2158078715,"data-quality":0.1159879489}}
{"text":"This model effectively decomposes the content of dialogues and investigates the temporal accumulation of emotions, thereby enabling more precise emotion recognition.","meta":{"url":"http://arxiv.org/abs/2309.06928v1"},"cats":{"new-dataset":0.1176624805,"dev-research":0.172393624,"data-quality":0.1491050397}}
{"text":"First, we introduce a novel Causal Directed Acyclic Graph (DAG) to establish the correlation between hidden emotional information and other observed elements.","meta":{"url":"http://arxiv.org/abs/2309.06928v1"},"cats":{"new-dataset":0.0800837213,"dev-research":0.2307589142,"data-quality":0.1579721551}}
{"text":"Subsequently, our approach utilizes pre-extracted personal attributes and utterance topics as guiding factors for the distribution of hidden variables, aiming to separate irrelevant ones.","meta":{"url":"http://arxiv.org/abs/2309.06928v1"},"cats":{"new-dataset":0.0937234184,"dev-research":0.2180956107,"data-quality":0.2281892424}}
{"text":"Specifically, we propose a dynamic temporal disentanglement model to infer the propagation of utterances and hidden variables, enabling the accumulation of emotion-related information throughout the conversation.","meta":{"url":"http://arxiv.org/abs/2309.06928v1"},"cats":{"new-dataset":0.1123975628,"dev-research":0.242669185,"data-quality":0.0965842702}}
{"text":"To guide this disentanglement process, we leverage the ChatGPT-4.0 and LSTM networks to extract utterance topics and personal attributes as observed information.","meta":{"url":"http://arxiv.org/abs/2309.06928v1"},"cats":{"new-dataset":0.2970994058,"dev-research":0.1890235346,"data-quality":0.1872884048}}
{"text":"Finally, we test our approach on two popular datasets in dialogue emotion detection and relevant experimental results verified the model's superiority.","meta":{"url":"http://arxiv.org/abs/2309.06928v1"},"cats":{"new-dataset":0.490283708,"dev-research":0.144264405,"data-quality":0.2329576764}}
{"text":"In this paper, we introduce the OpenStreetMap Mobility Demand Generator (OMOD), a new open-source activity-based mobility demand generation tool.","meta":{"url":"http://arxiv.org/abs/2309.06927v1"},"cats":{"new-dataset":0.2116457671,"dev-research":0.1672719576,"data-quality":0.0593998771}}
{"text":"OMOD creates a population of agents and detailed daily activity schedules that state what activities each agent plans to conduct, where, and for how long.","meta":{"url":"http://arxiv.org/abs/2309.06927v1"},"cats":{"new-dataset":0.2974572956,"dev-research":0.2374064139,"data-quality":0.043790586}}
{"text":"The temporal aspect of the output is wholly disaggregated, while the spatial aspect is given on the level of individual buildings.","meta":{"url":"http://arxiv.org/abs/2309.06927v1"},"cats":{"new-dataset":0.0132960625,"dev-research":0.2497085853,"data-quality":0.077113936}}
{"text":"In contrast to other existing models, OMOD is freely available, open-source, works out-of-the-box, can be applied to any region on earth, and only requires freely available OpenStreetMap (OSM) data from the user.","meta":{"url":"http://arxiv.org/abs/2309.06927v1"},"cats":{"new-dataset":0.196580417,"dev-research":0.1632053312,"data-quality":0.059366276}}
{"text":"With OMOD, it is easy for non-experts to create realistic mobility demand, which can be used in transportation studies, energy system modeling, communications system research, et cetera.","meta":{"url":"http://arxiv.org/abs/2309.06927v1"},"cats":{"new-dataset":0.0123601181,"dev-research":0.1856404319,"data-quality":0.0577883413}}
{"text":"OMOD uses a data-driven approach to generate mobility demand that has been calibrated with household travel survey data.","meta":{"url":"http://arxiv.org/abs/2309.06927v1"},"cats":{"new-dataset":0.0803672125,"dev-research":0.1665394805,"data-quality":0.0922115438}}
{"text":"This paper describes OMOD's architecture and validates the model for three cities ranging from 200,000 to 2.5 million inhabitants.","meta":{"url":"http://arxiv.org/abs/2309.06927v1"},"cats":{"new-dataset":0.2861750772,"dev-research":0.2120575039,"data-quality":0.0553736564}}
{"text":"The circuit complexity class DLOGTIME-uniform AC^0 is known to be a modest subclass of DLOGTIME-uniform TC^0.","meta":{"url":"http://arxiv.org/abs/2309.06926v1"},"cats":{"new-dataset":0.0734852545,"dev-research":0.1685182678,"data-quality":0.1054052813}}
{"text":"The weakness of AC^0 is caused by the fact that AC^0 is not closed under restricting AC^0-computable queries into simple subsequences of the input.","meta":{"url":"http://arxiv.org/abs/2309.06926v1"},"cats":{"new-dataset":0.0245050975,"dev-research":0.1985493277,"data-quality":0.1913538976}}
{"text":"Analogously, in descriptive complexity, the logics corresponding to DLOGTIME-uniform AC^0 do not have the relativization property and hence they are not regular.","meta":{"url":"http://arxiv.org/abs/2309.06926v1"},"cats":{"new-dataset":0.0163307254,"dev-research":0.1670329181,"data-quality":0.105878283}}
{"text":"This weakness of DLOGTIME-uniform AC^0 has been elaborated in the line of research on the Crane Beach Conjecture.","meta":{"url":"http://arxiv.org/abs/2309.06926v1"},"cats":{"new-dataset":0.1152279881,"dev-research":0.1458846784,"data-quality":0.0958959597}}
{"text":"The conjecture (which was refuted by Barrington, Immerman, Lautemann, Schweikardt and Th{\\'e}rien) was that if a language L has a neutral letter, then L can be defined in first-order logic with the collection of all numerical built-in relations, if and only if L can be already defined in FO with order.   ","meta":{"url":"http://arxiv.org/abs/2309.06926v1"},"cats":{"new-dataset":0.0306274453,"dev-research":0.2065503886,"data-quality":0.1505060432}}
{"text":"In the first part of this article we consider logics in the range of AC^0 and TC^0.","meta":{"url":"http://arxiv.org/abs/2309.06926v1"},"cats":{"new-dataset":0.0692690962,"dev-research":0.1722100421,"data-quality":0.1062120177}}
{"text":"First we formulate a combinatorial criterion for a cardinality quantifier C_S implying that all languages in DLOGTIME-uniform TC^0 can be defined in FO(C_S).","meta":{"url":"http://arxiv.org/abs/2309.06926v1"},"cats":{"new-dataset":0.1234693547,"dev-research":0.1754567396,"data-quality":0.1132987317}}
{"text":"For instance, this criterion is satisfied by C_S if S is the range of some polynomial with positive integer coefficients of degree at least two.","meta":{"url":"http://arxiv.org/abs/2309.06926v1"},"cats":{"new-dataset":0.0121797951,"dev-research":0.137810413,"data-quality":0.1232426036}}
{"text":"In the second part of the paper we first adapt the key properties of abstract logics to accommodate built-in relations.","meta":{"url":"http://arxiv.org/abs/2309.06926v1"},"cats":{"new-dataset":0.0534553606,"dev-research":0.2338454447,"data-quality":0.1033343361}}
{"text":"Then we define the regular interior R-int(L) and regular closure R-cl(L), of a logic L, and show that the Crane Beach Conjecture can be interpreted as a statement concerning the regular interior of first-order logic with built-in relations","meta":{"url":"http://arxiv.org/abs/2309.06926v1"},"cats":{"new-dataset":0.1292619841,"dev-research":0.1921211976,"data-quality":0.1314934753}}
{"text":"B. We show that if B={+}, or B contains only unary relations besides the order, then R-int(FO_B) collapses to FO with order.","meta":{"url":"http://arxiv.org/abs/2309.06926v1"},"cats":{"new-dataset":0.0652888876,"dev-research":0.1620587814,"data-quality":0.1306851451}}
{"text":"In contrast, our results imply that if B contains the order and the range of a polynomial of degree at least two, then R-cl(FO_B) includes all languages in DLOGTIME-uniform TC^0.","meta":{"url":"http://arxiv.org/abs/2309.06926v1"},"cats":{"new-dataset":0.1042882723,"dev-research":0.1418925333,"data-quality":0.1208199446}}
{"text":"Video-based remote physiological measurement utilizes facial videos to measure the blood volume change signal, which is also called remote photoplethysmography (rPPG).","meta":{"url":"http://arxiv.org/abs/2309.06924v1"},"cats":{"new-dataset":0.1784028236,"dev-research":0.1747923878,"data-quality":0.0664778966}}
{"text":"Supervised methods for rPPG measurements have been shown to achieve good performance.","meta":{"url":"http://arxiv.org/abs/2309.06924v1"},"cats":{"new-dataset":0.1655573544,"dev-research":0.1572921065,"data-quality":0.1362486169}}
{"text":"However, the drawback of these methods is that they require facial videos with ground truth (GT) physiological signals, which are often costly and difficult to obtain.","meta":{"url":"http://arxiv.org/abs/2309.06924v1"},"cats":{"new-dataset":0.0101292586,"dev-research":0.173039682,"data-quality":0.0911706936}}
{"text":"In this paper, we propose Contrast-Phys+, a method that can be trained in both unsupervised and weakly-supervised settings.","meta":{"url":"http://arxiv.org/abs/2309.06924v1"},"cats":{"new-dataset":0.1891582636,"dev-research":0.1541286979,"data-quality":0.2302750738}}
{"text":"We employ a 3DCNN model to generate multiple spatiotemporal rPPG signals and incorporate prior knowledge of rPPG into a contrastive loss function.","meta":{"url":"http://arxiv.org/abs/2309.06924v1"},"cats":{"new-dataset":0.3661392574,"dev-research":0.164835464,"data-quality":0.0791719774}}
{"text":"We further incorporate the GT signals into contrastive learning to adapt to partial or misaligned labels.","meta":{"url":"http://arxiv.org/abs/2309.06924v1"},"cats":{"new-dataset":0.0831912823,"dev-research":0.1348377085,"data-quality":0.3789169656}}
{"text":"The contrastive loss encourages rPPG/GT signals from the same video to be grouped together, while pushing those from different videos apart.","meta":{"url":"http://arxiv.org/abs/2309.06924v1"},"cats":{"new-dataset":0.0195053811,"dev-research":0.1775672226,"data-quality":0.1218969975}}
{"text":"We evaluate our methods on five publicly available datasets that include both RGB and Near-infrared videos.","meta":{"url":"http://arxiv.org/abs/2309.06924v1"},"cats":{"new-dataset":0.8185770686,"dev-research":0.1313976909,"data-quality":0.1678412871}}
{"text":"Contrast-Phys+ outperforms the state-of-the-art supervised methods, even when using partially available or misaligned GT signals, or no labels at all.","meta":{"url":"http://arxiv.org/abs/2309.06924v1"},"cats":{"new-dataset":0.0268910215,"dev-research":0.1635423448,"data-quality":0.2383830004}}
{"text":"Additionally, we highlight the advantages of our methods in terms of computational efficiency, noise robustness, and generalization.","meta":{"url":"http://arxiv.org/abs/2309.06924v1"},"cats":{"new-dataset":0.023962534,"dev-research":0.1548295071,"data-quality":0.2708802825}}
{"text":"Native Language Identification (NLI) intends to classify an author's native language based on their writing in another language.","meta":{"url":"http://arxiv.org/abs/2309.06923v1"},"cats":{"new-dataset":0.049983749,"dev-research":0.2655726266,"data-quality":0.3194377533}}
{"text":"Historically, the task has heavily relied on time-consuming linguistic feature engineering, and transformer-based NLI models have thus far failed to offer effective, practical alternatives.","meta":{"url":"http://arxiv.org/abs/2309.06923v1"},"cats":{"new-dataset":0.0146162587,"dev-research":0.2974633424,"data-quality":0.3118044442}}
{"text":"The current work investigates if input size is a limiting factor, and shows that classifiers trained using Big Bird embeddings outperform linguistic feature engineering models by a large margin on the Reddit-L2 dataset.","meta":{"url":"http://arxiv.org/abs/2309.06923v1"},"cats":{"new-dataset":0.4722692707,"dev-research":0.2220544739,"data-quality":0.3176918889}}
{"text":"Additionally, we provide further insight into input length dependencies, show consistent out-of-sample performance, and qualitatively analyze the embedding space.","meta":{"url":"http://arxiv.org/abs/2309.06923v1"},"cats":{"new-dataset":0.1010830039,"dev-research":0.1586782699,"data-quality":0.2250627405}}
{"text":"Given the effectiveness and computational efficiency of this method, we believe it offers a promising avenue for future NLI work.","meta":{"url":"http://arxiv.org/abs/2309.06923v1"},"cats":{"new-dataset":0.0218672056,"dev-research":0.1668941763,"data-quality":0.1454907819}}
{"text":"The recent surge in large-scale foundation models has spurred the development of efficient methods for adapting these models to various downstream tasks.","meta":{"url":"http://arxiv.org/abs/2309.06922v1"},"cats":{"new-dataset":0.0319926457,"dev-research":0.2389962631,"data-quality":0.0425831304}}
{"text":"Low-rank adaptation methods, such as LoRA, have gained significant attention due to their outstanding parameter efficiency and no additional inference latency.","meta":{"url":"http://arxiv.org/abs/2309.06922v1"},"cats":{"new-dataset":0.0119017727,"dev-research":0.1288911937,"data-quality":0.1403780775}}
{"text":"This paper investigates a more general form of adapter module based on the analysis that parallel and sequential adaptation branches learn novel and general features during fine-tuning, respectively.","meta":{"url":"http://arxiv.org/abs/2309.06922v1"},"cats":{"new-dataset":0.0214378372,"dev-research":0.2257170085,"data-quality":0.1403819479}}
{"text":"The proposed method, named Hydra, due to its multi-head computational branches, combines parallel and sequential branch to integrate capabilities, which is more expressive than existing single branch methods and enables the exploration of a broader range of optimal points in the fine-tuning process.","meta":{"url":"http://arxiv.org/abs/2309.06922v1"},"cats":{"new-dataset":0.0119808538,"dev-research":0.183770214,"data-quality":0.0587285946}}
{"text":"In addition, the proposed adaptation method explicitly leverages the pre-trained weights by performing a linear combination of the pre-trained features.","meta":{"url":"http://arxiv.org/abs/2309.06922v1"},"cats":{"new-dataset":0.0204957936,"dev-research":0.177574779,"data-quality":0.1759349023}}
{"text":"It allows the learned features to have better generalization performance across diverse downstream tasks.","meta":{"url":"http://arxiv.org/abs/2309.06922v1"},"cats":{"new-dataset":0.0048465026,"dev-research":0.255433995,"data-quality":0.1146704386}}
{"text":"Furthermore, we perform a comprehensive analysis of the characteristics of each adaptation branch with empirical evidence.","meta":{"url":"http://arxiv.org/abs/2309.06922v1"},"cats":{"new-dataset":0.0106650753,"dev-research":0.1908866972,"data-quality":0.1335868579}}
{"text":"Through an extensive range of experiments, encompassing comparisons and ablation studies, we substantiate the efficiency and demonstrate the superior performance of Hydra.","meta":{"url":"http://arxiv.org/abs/2309.06922v1"},"cats":{"new-dataset":0.0182438294,"dev-research":0.1498373637,"data-quality":0.1020971508}}
{"text":"This comprehensive evaluation underscores the potential impact and effectiveness of Hydra in a variety of applications.","meta":{"url":"http://arxiv.org/abs/2309.06922v1"},"cats":{"new-dataset":0.0165992315,"dev-research":0.1947685107,"data-quality":0.1050736312}}
{"text":"Our code is available on \\url{https://github.com/extremebird/Hydra}","meta":{"url":"http://arxiv.org/abs/2309.06922v1"},"cats":{"new-dataset":0.0440270397,"dev-research":0.1295151129,"data-quality":0.1182519668}}
{"text":"Reinforcement learning~(RL) is a versatile framework for learning to solve complex real-world tasks.","meta":{"url":"http://arxiv.org/abs/2309.06921v1"},"cats":{"new-dataset":0.0789909952,"dev-research":0.1773908238,"data-quality":0.0558755181}}
{"text":"However, influences on the learning performance of RL algorithms are often poorly understood in practice.","meta":{"url":"http://arxiv.org/abs/2309.06921v1"},"cats":{"new-dataset":0.0035723297,"dev-research":0.212670346,"data-quality":0.2884002918}}
{"text":"We discuss different analysis techniques and assess their effectiveness for investigating the impact of action representations in RL.","meta":{"url":"http://arxiv.org/abs/2309.06921v1"},"cats":{"new-dataset":0.0344992296,"dev-research":0.2992421569,"data-quality":0.0963002277}}
{"text":"Our experiments demonstrate that the action representation can significantly influence the learning performance on popular RL benchmark tasks.","meta":{"url":"http://arxiv.org/abs/2309.06921v1"},"cats":{"new-dataset":0.0467647496,"dev-research":0.1896287197,"data-quality":0.0986447659}}
{"text":"The analysis results indicate that some of the performance differences can be attributed to changes in the complexity of the optimization landscape.","meta":{"url":"http://arxiv.org/abs/2309.06921v1"},"cats":{"new-dataset":0.002464139,"dev-research":0.2884146729,"data-quality":0.0609199716}}
{"text":"Finally, we discuss open challenges of analysis techniques for RL algorithms.","meta":{"url":"http://arxiv.org/abs/2309.06921v1"},"cats":{"new-dataset":0.0475773956,"dev-research":0.1853378105,"data-quality":0.1435138052}}
{"text":"Many resource management techniques for task scheduling, energy and carbon efficiency, and cost optimization in workflows rely on a-priori task runtime knowledge.","meta":{"url":"http://arxiv.org/abs/2309.06918v1"},"cats":{"new-dataset":0.0450978133,"dev-research":0.3670130516,"data-quality":0.0613231738}}
{"text":"Building runtime prediction models on historical data is often not feasible in practice as workflows, their input data, and the cluster infrastructure change.","meta":{"url":"http://arxiv.org/abs/2309.06918v1"},"cats":{"new-dataset":0.0616035696,"dev-research":0.2784637242,"data-quality":0.0699050172}}
{"text":"Online methods, on the other hand, which estimate task runtimes on specific machines while the workflow is running, have to cope with a lack of measurements during start-up.","meta":{"url":"http://arxiv.org/abs/2309.06918v1"},"cats":{"new-dataset":0.0112344033,"dev-research":0.2883042505,"data-quality":0.0592019646}}
{"text":"Frequently, scientific workflows are executed on heterogeneous infrastructures consisting of machines with different CPU, I/O, and memory configurations, further complicating predicting runtimes due to different task runtimes on different machine types.   ","meta":{"url":"http://arxiv.org/abs/2309.06918v1"},"cats":{"new-dataset":0.0481068704,"dev-research":0.2766850815,"data-quality":0.0689511561}}
{"text":"This paper presents Lotaru, a method for locally predicting the runtimes of scientific workflow tasks before they are executed on heterogeneous compute clusters.","meta":{"url":"http://arxiv.org/abs/2309.06918v1"},"cats":{"new-dataset":0.139953036,"dev-research":0.2689314024,"data-quality":0.0944922278}}
{"text":"Crucially, our approach does not rely on historical data and copes with a lack of training data during the start-up.","meta":{"url":"http://arxiv.org/abs/2309.06918v1"},"cats":{"new-dataset":0.0533638228,"dev-research":0.1959215849,"data-quality":0.2145092752}}
{"text":"To this end, we use microbenchmarks, reduce the input data to quickly profile the workflow locally, and predict a task's runtime with a Bayesian linear regression based on the gathered data points from the local workflow execution and the microbenchmarks.","meta":{"url":"http://arxiv.org/abs/2309.06918v1"},"cats":{"new-dataset":0.1818963999,"dev-research":0.3543102458,"data-quality":0.0857237241}}
{"text":"Due to its Bayesian approach, Lotaru provides uncertainty estimates that can be used for advanced scheduling methods on distributed cluster infrastructures.   ","meta":{"url":"http://arxiv.org/abs/2309.06918v1"},"cats":{"new-dataset":0.0503862106,"dev-research":0.2421235604,"data-quality":0.1089411127}}
{"text":"In our evaluation with five real-world scientific workflows, our method outperforms two state-of-the-art runtime prediction baselines and decreases the absolute prediction error by more than 12.5%.","meta":{"url":"http://arxiv.org/abs/2309.06918v1"},"cats":{"new-dataset":0.1515684885,"dev-research":0.2937636333,"data-quality":0.1333923545}}
{"text":"In a second set of experiments, the prediction performance of our method, using the predicted runtimes for state-of-the-art scheduling, carbon reduction, and cost prediction, enables results close to those achieved with perfect prior knowledge of runtimes.","meta":{"url":"http://arxiv.org/abs/2309.06918v1"},"cats":{"new-dataset":0.0250965396,"dev-research":0.2229566748,"data-quality":0.0778887476}}
{"text":"Recent advancements in data-driven task-oriented dialogue systems (ToDs) struggle with incremental learning due to computational constraints and time-consuming issues.","meta":{"url":"http://arxiv.org/abs/2309.06917v1"},"cats":{"new-dataset":0.2885038503,"dev-research":0.2216256305,"data-quality":0.1017985491}}
{"text":"Continual Learning (CL) attempts to solve this by avoiding intensive pre-training, but it faces the problem of catastrophic forgetting (CF).","meta":{"url":"http://arxiv.org/abs/2309.06917v1"},"cats":{"new-dataset":0.0498068917,"dev-research":0.2057660677,"data-quality":0.1995045483}}
{"text":"While generative-based rehearsal CL methods have made significant strides, generating pseudo samples that accurately reflect the underlying task-specific distribution is still a challenge.","meta":{"url":"http://arxiv.org/abs/2309.06917v1"},"cats":{"new-dataset":0.0809871742,"dev-research":0.2889578199,"data-quality":0.1803799214}}
{"text":"In this paper, we present Dirichlet Continual Learning (DCL), a novel generative-based rehearsal strategy for CL.","meta":{"url":"http://arxiv.org/abs/2309.06917v1"},"cats":{"new-dataset":0.1460352303,"dev-research":0.2549734454,"data-quality":0.1785800666}}
{"text":"Unlike the traditionally used Gaussian latent variable in the Conditional Variational Autoencoder (CVAE), DCL leverages the flexibility and versatility of the Dirichlet distribution to model the latent prior variable.","meta":{"url":"http://arxiv.org/abs/2309.06917v1"},"cats":{"new-dataset":0.0279916144,"dev-research":0.1338781091,"data-quality":0.1392445249}}
{"text":"This enables it to efficiently capture sentence-level features of previous tasks and effectively guide the generation of pseudo samples.","meta":{"url":"http://arxiv.org/abs/2309.06917v1"},"cats":{"new-dataset":0.0726569332,"dev-research":0.3033980744,"data-quality":0.1772443802}}
{"text":"In addition, we introduce Jensen-Shannon Knowledge Distillation (JSKD), a robust logit-based knowledge distillation method that enhances knowledge transfer during pseudo sample generation.","meta":{"url":"http://arxiv.org/abs/2309.06917v1"},"cats":{"new-dataset":0.100586663,"dev-research":0.189029611,"data-quality":0.1889925352}}
{"text":"Our experiments confirm the efficacy of our approach in both intent detection and slot-filling tasks, outperforming state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2309.06917v1"},"cats":{"new-dataset":0.0122024496,"dev-research":0.193775425,"data-quality":0.2036264285}}
{"text":"Graph Neural Networks (GNNs) has been extensively employed in the field of recommender systems, offering users personalized recommendations and yielding remarkable outcomes.","meta":{"url":"http://arxiv.org/abs/2309.06912v1"},"cats":{"new-dataset":0.0663010727,"dev-research":0.1913646001,"data-quality":0.1402864103}}
{"text":"Recently, GNNs incorporating contrastive learning have demonstrated promising performance in handling sparse data problem of recommendation system.","meta":{"url":"http://arxiv.org/abs/2309.06912v1"},"cats":{"new-dataset":0.0911379957,"dev-research":0.1546313373,"data-quality":0.1678094075}}
{"text":"However, existing contrastive learning methods still have limitations in addressing the cold-start problem and resisting noise interference especially for multi-behavior recommendation.","meta":{"url":"http://arxiv.org/abs/2309.06912v1"},"cats":{"new-dataset":0.0269592962,"dev-research":0.1581059691,"data-quality":0.1300267466}}
{"text":"To mitigate the aforementioned issues, the present research posits a GNNs based multi-behavior recommendation model MB-SVD that utilizes Singular Value Decomposition (SVD) graphs to enhance model performance.","meta":{"url":"http://arxiv.org/abs/2309.06912v1"},"cats":{"new-dataset":0.0634252555,"dev-research":0.2063259811,"data-quality":0.1748090695}}
{"text":"In particular, MB-SVD considers user preferences under different behaviors, improving recommendation effectiveness while better addressing the cold-start problem.","meta":{"url":"http://arxiv.org/abs/2309.06912v1"},"cats":{"new-dataset":0.0183351427,"dev-research":0.2264069146,"data-quality":0.1145472572}}
{"text":"Our model introduces an innovative methodology, which subsume multi-behavior contrastive learning paradigm to proficiently discern the intricate interconnections among heterogeneous manifestations of user behavior and generates SVD graphs to automate the distillation of crucial multi-behavior self-supervised information for robust graph augmentation.","meta":{"url":"http://arxiv.org/abs/2309.06912v1"},"cats":{"new-dataset":0.0862835556,"dev-research":0.2215127686,"data-quality":0.2375019121}}
{"text":"Furthermore, the SVD based framework reduces the embedding dimensions and computational load.","meta":{"url":"http://arxiv.org/abs/2309.06912v1"},"cats":{"new-dataset":0.0318433093,"dev-research":0.2384980516,"data-quality":0.1183181247}}
{"text":"Thorough experimentation showcases the remarkable performance of our proposed MB-SVD approach in multi-behavior recommendation endeavors across diverse real-world datasets.","meta":{"url":"http://arxiv.org/abs/2309.06912v1"},"cats":{"new-dataset":0.1084015995,"dev-research":0.1851649838,"data-quality":0.1374468378}}
{"text":"Tremendous efforts have been made to learn animatable and photorealistic human avatars.","meta":{"url":"http://arxiv.org/abs/2309.06441v1"},"cats":{"new-dataset":0.2969359985,"dev-research":0.1969065908,"data-quality":0.0864718502}}
{"text":"Towards this end, both explicit and implicit 3D representations are heavily studied for a holistic modeling and capture of the whole human (e.g., body, clothing, face and hair), but neither representation is an optimal choice in terms of representation efficacy since different parts of the human avatar have different modeling desiderata.","meta":{"url":"http://arxiv.org/abs/2309.06441v1"},"cats":{"new-dataset":0.028989988,"dev-research":0.1854708925,"data-quality":0.0506120425}}
{"text":"For example, meshes are generally not suitable for modeling clothing and hair.","meta":{"url":"http://arxiv.org/abs/2309.06441v1"},"cats":{"new-dataset":0.0037888872,"dev-research":0.246193296,"data-quality":0.1050911052}}
{"text":"Motivated by this, we present Disentangled Avatars~(DELTA), which models humans with hybrid explicit-implicit 3D representations.","meta":{"url":"http://arxiv.org/abs/2309.06441v1"},"cats":{"new-dataset":0.0650721663,"dev-research":0.1395074811,"data-quality":0.0612860691}}
{"text":"DELTA takes a monocular RGB video as input, and produces a human avatar with separate body and clothing/hair layers.","meta":{"url":"http://arxiv.org/abs/2309.06441v1"},"cats":{"new-dataset":0.124568656,"dev-research":0.137007839,"data-quality":0.0775065496}}
{"text":"Specifically, we demonstrate two important applications for DELTA.","meta":{"url":"http://arxiv.org/abs/2309.06441v1"},"cats":{"new-dataset":0.0158487958,"dev-research":0.1313907747,"data-quality":0.1115609866}}
{"text":"For the first one, we consider the disentanglement of the human body and clothing and in the second, we disentangle the face and hair.","meta":{"url":"http://arxiv.org/abs/2309.06441v1"},"cats":{"new-dataset":0.0365560625,"dev-research":0.2082449289,"data-quality":0.0933585657}}
{"text":"To do so, DELTA represents the body or face with an explicit mesh-based parametric 3D model and the clothing or hair with an implicit neural radiance field.","meta":{"url":"http://arxiv.org/abs/2309.06441v1"},"cats":{"new-dataset":0.0418514164,"dev-research":0.1823197426,"data-quality":0.0758770842}}
{"text":"To make this possible, we design an end-to-end differentiable renderer that integrates meshes into volumetric rendering, enabling DELTA to learn directly from monocular videos without any 3D supervision.","meta":{"url":"http://arxiv.org/abs/2309.06441v1"},"cats":{"new-dataset":0.1040485585,"dev-research":0.1476564391,"data-quality":0.0854971707}}
{"text":"Finally, we show that how these two applications can be easily combined to model full-body avatars, such that the hair, face, body and clothing can be fully disentangled yet jointly rendered.","meta":{"url":"http://arxiv.org/abs/2309.06441v1"},"cats":{"new-dataset":0.0425725283,"dev-research":0.1446987624,"data-quality":0.0450130557}}
{"text":"Such a disentanglement enables hair and clothing transfer to arbitrary body shapes.","meta":{"url":"http://arxiv.org/abs/2309.06441v1"},"cats":{"new-dataset":0.0100615808,"dev-research":0.1847566176,"data-quality":0.0511953247}}
{"text":"We empirically validate the effectiveness of DELTA's disentanglement by demonstrating its promising performance on disentangled reconstruction, virtual clothing try-on and hairstyle transfer.","meta":{"url":"http://arxiv.org/abs/2309.06441v1"},"cats":{"new-dataset":0.0172550588,"dev-research":0.1899005729,"data-quality":0.1278911643}}
{"text":"To facilitate future research, we also release an open-sourced pipeline for the study of hybrid human avatar modeling.","meta":{"url":"http://arxiv.org/abs/2309.06441v1"},"cats":{"new-dataset":0.1758662521,"dev-research":0.175135806,"data-quality":0.0614518667}}
{"text":"Dexterous manipulation has been a long-standing challenge in robotics.","meta":{"url":"http://arxiv.org/abs/2309.06440v1"},"cats":{"new-dataset":0.034313506,"dev-research":0.2112007215,"data-quality":0.0670510167}}
{"text":"While machine learning techniques have shown some promise, results have largely been currently limited to simulation.","meta":{"url":"http://arxiv.org/abs/2309.06440v1"},"cats":{"new-dataset":0.0102449321,"dev-research":0.1468923538,"data-quality":0.1043255437}}
{"text":"This can be mostly attributed to the lack of suitable hardware.","meta":{"url":"http://arxiv.org/abs/2309.06440v1"},"cats":{"new-dataset":0.0091858027,"dev-research":0.3032676594,"data-quality":0.1617829809}}
{"text":"In this paper, we present LEAP Hand, a low-cost dexterous and anthropomorphic hand for machine learning research.","meta":{"url":"http://arxiv.org/abs/2309.06440v1"},"cats":{"new-dataset":0.1698465846,"dev-research":0.1689132269,"data-quality":0.0584239685}}
{"text":"In contrast to previous hands, LEAP Hand has a novel kinematic structure that allows maximal dexterity regardless of finger pose.","meta":{"url":"http://arxiv.org/abs/2309.06440v1"},"cats":{"new-dataset":0.0283353187,"dev-research":0.1887232342,"data-quality":0.0372294978}}
{"text":"LEAP Hand is low-cost and can be assembled in 4 hours at a cost of 2000 USD from readily available parts.","meta":{"url":"http://arxiv.org/abs/2309.06440v1"},"cats":{"new-dataset":0.1230330151,"dev-research":0.2708960543,"data-quality":0.0454414437}}
{"text":"It is capable of consistently exerting large torques over long durations of time.","meta":{"url":"http://arxiv.org/abs/2309.06440v1"},"cats":{"new-dataset":0.0061432541,"dev-research":0.1802402137,"data-quality":0.0613371212}}
{"text":"We show that LEAP Hand can be used to perform several manipulation tasks in the real world -- from visual teleoperation to learning from passive video data and sim2real.","meta":{"url":"http://arxiv.org/abs/2309.06440v1"},"cats":{"new-dataset":0.3607622395,"dev-research":0.2063091311,"data-quality":0.0508785879}}
{"text":"LEAP Hand significantly outperforms its closest competitor Allegro Hand in all our experiments while being 1/8th of the cost.","meta":{"url":"http://arxiv.org/abs/2309.06440v1"},"cats":{"new-dataset":0.0352498556,"dev-research":0.2179356112,"data-quality":0.0776825367}}
{"text":"We release detailed assembly instructions, the Sim2Real pipeline and a development platform with useful APIs on our website at https://leap-hand.github.io/","meta":{"url":"http://arxiv.org/abs/2309.06440v1"},"cats":{"new-dataset":0.7170819449,"dev-research":0.3568878244,"data-quality":0.0812665451}}
{"text":"We propose DiRL, a Diversity-inducing Representation Learning technique for histopathology imaging.","meta":{"url":"http://arxiv.org/abs/2309.06439v1"},"cats":{"new-dataset":0.1202376621,"dev-research":0.159552832,"data-quality":0.1194656387}}
{"text":"Self-supervised learning techniques, such as contrastive and non-contrastive approaches, have been shown to learn rich and effective representations of digitized tissue samples with limited pathologist supervision.","meta":{"url":"http://arxiv.org/abs/2309.06439v1"},"cats":{"new-dataset":0.1100460481,"dev-research":0.1304764737,"data-quality":0.199963891}}
{"text":"Our analysis of vanilla SSL-pretrained models' attention distribution reveals an insightful observation: sparsity in attention, i.e, models tends to localize most of their attention to some prominent patterns in the image.","meta":{"url":"http://arxiv.org/abs/2309.06439v1"},"cats":{"new-dataset":0.0432919157,"dev-research":0.1433373271,"data-quality":0.1519316255}}
{"text":"Although attention sparsity can be beneficial in natural images due to these prominent patterns being the object of interest itself, this can be sub-optimal in digital pathology; this is because, unlike natural images, digital pathology scans are not object-centric, but rather a complex phenotype of various spatially intermixed biological components.","meta":{"url":"http://arxiv.org/abs/2309.06439v1"},"cats":{"new-dataset":0.0267270111,"dev-research":0.1678611188,"data-quality":0.1534015293}}
{"text":"Inadequate diversification of attention in these complex images could result in crucial information loss.","meta":{"url":"http://arxiv.org/abs/2309.06439v1"},"cats":{"new-dataset":0.0164010522,"dev-research":0.2023731982,"data-quality":0.1970207672}}
{"text":"To address this, we leverage cell segmentation to densely extract multiple histopathology-specific representations, and then propose a prior-guided dense pretext task for SSL, designed to match the multiple corresponding representations between the views.","meta":{"url":"http://arxiv.org/abs/2309.06439v1"},"cats":{"new-dataset":0.2717349047,"dev-research":0.1762668939,"data-quality":0.1252934983}}
{"text":"Through this, the model learns to attend to various components more closely and evenly, thus inducing adequate diversification in attention for capturing context rich representations.","meta":{"url":"http://arxiv.org/abs/2309.06439v1"},"cats":{"new-dataset":0.0318683406,"dev-research":0.1397887187,"data-quality":0.1112119032}}
{"text":"Through quantitative and qualitative analysis on multiple tasks across cancer types, we demonstrate the efficacy of our method and observe that the attention is more globally distributed.","meta":{"url":"http://arxiv.org/abs/2309.06439v1"},"cats":{"new-dataset":0.0460694019,"dev-research":0.24883746,"data-quality":0.0783349419}}
{"text":"Deep Neural Networks can be easily fooled by small and imperceptible perturbations.","meta":{"url":"http://arxiv.org/abs/2309.06438v1"},"cats":{"new-dataset":0.0077604017,"dev-research":0.169727224,"data-quality":0.2400730899}}
{"text":"The query-based black-box attack (QBBA) is able to create the perturbations using model output probabilities of image queries requiring no access to the underlying models.","meta":{"url":"http://arxiv.org/abs/2309.06438v1"},"cats":{"new-dataset":0.0378532229,"dev-research":0.153210544,"data-quality":0.1298104587}}
{"text":"QBBA poses realistic threats to real-world applications.","meta":{"url":"http://arxiv.org/abs/2309.06438v1"},"cats":{"new-dataset":0.0454625809,"dev-research":0.3140007608,"data-quality":0.0900230949}}
{"text":"Recently, various types of robustness have been explored to defend against QBBA.","meta":{"url":"http://arxiv.org/abs/2309.06438v1"},"cats":{"new-dataset":0.0194687951,"dev-research":0.3699214459,"data-quality":0.1538278629}}
{"text":"In this work, we first taxonomize the stochastic defense strategies against QBBA.","meta":{"url":"http://arxiv.org/abs/2309.06438v1"},"cats":{"new-dataset":0.0818356131,"dev-research":0.2300172825,"data-quality":0.0839419034}}
{"text":"Following our taxonomy, we propose to explore non-additive randomness in models to defend against QBBA.","meta":{"url":"http://arxiv.org/abs/2309.06438v1"},"cats":{"new-dataset":0.0356883206,"dev-research":0.1600457935,"data-quality":0.1308956202}}
{"text":"Specifically, we focus on underexplored Vision Transformers based on their flexible architectures.","meta":{"url":"http://arxiv.org/abs/2309.06438v1"},"cats":{"new-dataset":0.0301906863,"dev-research":0.1625635683,"data-quality":0.0570502074}}
{"text":"Extensive experiments show that the proposed defense approach achieves effective defense, without much sacrifice in performance.","meta":{"url":"http://arxiv.org/abs/2309.06438v1"},"cats":{"new-dataset":0.0027599568,"dev-research":0.2541665253,"data-quality":0.062582419}}
{"text":"Semantic and Cross-language code clone generation may be useful for code reuse, code comprehension, refactoring and benchmarking.","meta":{"url":"http://arxiv.org/abs/2309.06424v1"},"cats":{"new-dataset":0.1577899591,"dev-research":0.5154058049,"data-quality":0.1540892637}}
{"text":"OpenAI's GPT model has potential in such clone generation as GPT is used for text generation.","meta":{"url":"http://arxiv.org/abs/2309.06424v1"},"cats":{"new-dataset":0.1716689182,"dev-research":0.1894941683,"data-quality":0.114937415}}
{"text":"When developers copy/paste codes from Stack Overflow (SO) or within a system, there might be inconsistent changes leading to unexpected behaviours.","meta":{"url":"http://arxiv.org/abs/2309.06424v1"},"cats":{"new-dataset":0.0272585105,"dev-research":0.4844423223,"data-quality":0.3058025035}}
{"text":"Similarly, if someone possesses a code snippet in a particular programming language but seeks equivalent functionality in a different language, a semantic cross-language code clone generation approach could provide valuable assistance.","meta":{"url":"http://arxiv.org/abs/2309.06424v1"},"cats":{"new-dataset":0.0541916931,"dev-research":0.4339689787,"data-quality":0.1717774687}}
{"text":"In this study, using SemanticCloneBench as a vehicle, we evaluated how well the GPT-3 model could help generate semantic and cross-language clone variants for a given fragment.","meta":{"url":"http://arxiv.org/abs/2309.06424v1"},"cats":{"new-dataset":0.164741413,"dev-research":0.28238824,"data-quality":0.1998344463}}
{"text":"We have comprised a diverse set of code fragments and assessed GPT-3s performance in generating code variants.","meta":{"url":"http://arxiv.org/abs/2309.06424v1"},"cats":{"new-dataset":0.0751886364,"dev-research":0.2890508529,"data-quality":0.0990962198}}
{"text":"Through extensive experimentation and analysis, where 9 judges spent 158 hours to validate, we investigate the model's ability to produce accurate and semantically correct variants.","meta":{"url":"http://arxiv.org/abs/2309.06424v1"},"cats":{"new-dataset":0.0288874084,"dev-research":0.3022567003,"data-quality":0.3288461515}}
{"text":"Our findings shed light on GPT-3's strengths in code generation, offering insights into the potential applications and challenges of using advanced language models in software development.","meta":{"url":"http://arxiv.org/abs/2309.06424v1"},"cats":{"new-dataset":0.0674828417,"dev-research":0.4815276723,"data-quality":0.1326080412}}
{"text":"Our quantitative analysis yields compelling results.","meta":{"url":"http://arxiv.org/abs/2309.06424v1"},"cats":{"new-dataset":0.0238640643,"dev-research":0.2031323639,"data-quality":0.1272758908}}
{"text":"In the realm of semantic clones, GPT-3 attains an impressive accuracy of 62.14% and 0.55 BLEU score, achieved through few-shot prompt engineering.","meta":{"url":"http://arxiv.org/abs/2309.06424v1"},"cats":{"new-dataset":0.1348150439,"dev-research":0.1876852782,"data-quality":0.2247645661}}
{"text":"Furthermore, the model shines in transcending linguistic confines, boasting an exceptional 91.25% accuracy in generating cross-language clones","meta":{"url":"http://arxiv.org/abs/2309.06424v1"},"cats":{"new-dataset":0.1400005805,"dev-research":0.2285196589,"data-quality":0.3640865894}}
{"text":"Machine learning and data analytics applications increasingly suffer from the high latency and energy consumption of conventional von Neumann architectures.","meta":{"url":"http://arxiv.org/abs/2309.06418v1"},"cats":{"new-dataset":0.0180156909,"dev-research":0.2145350377,"data-quality":0.0976570484}}
{"text":"Recently, several in-memory and near-memory systems have been proposed to remove this von Neumann bottleneck.","meta":{"url":"http://arxiv.org/abs/2309.06418v1"},"cats":{"new-dataset":0.0130336233,"dev-research":0.1966579556,"data-quality":0.1002227232}}
{"text":"Platforms based on content-addressable memories (CAMs) are particularly interesting due to their efficient support for the search-based operations that form the foundation for many applications, including K-nearest neighbors (KNN), high-dimensional computing (HDC), recommender systems, and one-shot learning among others.","meta":{"url":"http://arxiv.org/abs/2309.06418v1"},"cats":{"new-dataset":0.2379316186,"dev-research":0.1525578331,"data-quality":0.0992202362}}
{"text":"Today, these platforms are designed by hand and can only be programmed with low-level code, accessible only to hardware experts.","meta":{"url":"http://arxiv.org/abs/2309.06418v1"},"cats":{"new-dataset":0.0300023514,"dev-research":0.2982717177,"data-quality":0.0603705595}}
{"text":"In this paper, we introduce C4CAM, the first compiler framework to quickly explore CAM configurations and to seamlessly generate code from high-level TorchScript code.","meta":{"url":"http://arxiv.org/abs/2309.06418v1"},"cats":{"new-dataset":0.3868724191,"dev-research":0.4325901435,"data-quality":0.074734519}}
{"text":"C4CAM employs a hierarchy of abstractions that progressively lowers programs, allowing code transformations at the most suitable abstraction level.","meta":{"url":"http://arxiv.org/abs/2309.06418v1"},"cats":{"new-dataset":0.0162848906,"dev-research":0.4629571653,"data-quality":0.0658234823}}
{"text":"Depending on the type and technology, CAM arrays exhibit varying latencies and power profiles.","meta":{"url":"http://arxiv.org/abs/2309.06418v1"},"cats":{"new-dataset":0.008234397,"dev-research":0.2200849427,"data-quality":0.1241352515}}
{"text":"Our framework allows analyzing the impact of such differences in terms of system-level performance and energy consumption, and thus supports designers in selecting appropriate designs for a given application.","meta":{"url":"http://arxiv.org/abs/2309.06418v1"},"cats":{"new-dataset":0.0075074166,"dev-research":0.2979057691,"data-quality":0.0464182722}}
{"text":"Performance portability is a major concern on current architectures.","meta":{"url":"http://arxiv.org/abs/2309.06414v1"},"cats":{"new-dataset":0.006376408,"dev-research":0.276491979,"data-quality":0.0604248034}}
{"text":"One way to achieve it is by using autotuning.","meta":{"url":"http://arxiv.org/abs/2309.06414v1"},"cats":{"new-dataset":0.0130756117,"dev-research":0.2569968101,"data-quality":0.1464538632}}
{"text":"In this paper, we are presenting how we exten ded a just-in-time compilation infrastructure to introduce autotuning capabiliti es triggered at run-time.","meta":{"url":"http://arxiv.org/abs/2309.06414v1"},"cats":{"new-dataset":0.1194034985,"dev-research":0.4559965733,"data-quality":0.1210225188}}
{"text":"When a function is executed, the first iterations optimize it, and once the best solution has been found, it is used for subsequent calls to the function.","meta":{"url":"http://arxiv.org/abs/2309.06414v1"},"cats":{"new-dataset":0.0056831442,"dev-research":0.3207687126,"data-quality":0.0685007241}}
{"text":"This just-in-time autotuning infrastructure is relevant for optimizing computation kernels that will be called numerous times with similar parameters through the execution, re-optimizes kernels when they are called with other parameters, and the programmer can obtain the optimal parameters to use them for other kernels.","meta":{"url":"http://arxiv.org/abs/2309.06414v1"},"cats":{"new-dataset":0.0081681688,"dev-research":0.328975604,"data-quality":0.1139929277}}
{"text":"We present an experimental performance evaluation of our approach.","meta":{"url":"http://arxiv.org/abs/2309.06414v1"},"cats":{"new-dataset":0.0123322651,"dev-research":0.169320981,"data-quality":0.1753729942}}
{"text":"Compiling the code introduces an overhead on the first iterations, and this overhead is compensated for during subsequent iterations.","meta":{"url":"http://arxiv.org/abs/2309.06414v1"},"cats":{"new-dataset":0.0101590158,"dev-research":0.3659515657,"data-quality":0.0748701596}}
{"text":"We also determined that the optimum found seems stable and accurate.","meta":{"url":"http://arxiv.org/abs/2309.06414v1"},"cats":{"new-dataset":0.0090738766,"dev-research":0.1185093857,"data-quality":0.1520070707}}
{"text":"We consider the classical problem of learning, with arbitrary accuracy, the natural parameters of a $k$-parameter truncated \\textit{minimal} exponential family from i.i.d. samples in a computationally and statistically efficient manner.","meta":{"url":"http://arxiv.org/abs/2309.06413v1"},"cats":{"new-dataset":0.0643767759,"dev-research":0.0806432053,"data-quality":0.2152285046}}
{"text":"We focus on the setting where the support as well as the natural parameters are appropriately bounded.","meta":{"url":"http://arxiv.org/abs/2309.06413v1"},"cats":{"new-dataset":0.0302414616,"dev-research":0.1246736947,"data-quality":0.1125697085}}
{"text":"While the traditional maximum likelihood estimator for this class of exponential family is consistent, asymptotically normal, and asymptotically efficient, evaluating it is computationally hard.","meta":{"url":"http://arxiv.org/abs/2309.06413v1"},"cats":{"new-dataset":0.1007981356,"dev-research":0.0941245048,"data-quality":0.1021649451}}
{"text":"In this work, we propose a novel loss function and a computationally efficient estimator that is consistent as well as asymptotically normal under mild conditions.","meta":{"url":"http://arxiv.org/abs/2309.06413v1"},"cats":{"new-dataset":0.0915570529,"dev-research":0.1013999156,"data-quality":0.2060480615}}
{"text":"We show that, at the population level, our method can be viewed as the maximum likelihood estimation of a re-parameterized distribution belonging to the same class of exponential family.","meta":{"url":"http://arxiv.org/abs/2309.06413v1"},"cats":{"new-dataset":0.1306985026,"dev-research":0.1146572631,"data-quality":0.115562416}}
{"text":"Further, we show that our estimator can be interpreted as a solution to minimizing a particular Bregman score as well as an instance of minimizing the \\textit{surrogate} likelihood.","meta":{"url":"http://arxiv.org/abs/2309.06413v1"},"cats":{"new-dataset":0.0438418983,"dev-research":0.1164208737,"data-quality":0.1835085315}}
{"text":"We also provide finite sample guarantees to achieve an error (in $\\ell_2$-norm) of $\\alpha$ in the parameter estimation with sample complexity $O({\\sf poly}(k)/\\alpha^2)$. Our method achives the order-optimal sample complexity of $O({\\sf log}(k)/\\alpha^2)$ when tailored for node-wise-sparse Markov random fields.","meta":{"url":"http://arxiv.org/abs/2309.06413v1"},"cats":{"new-dataset":0.070501457,"dev-research":0.1037437915,"data-quality":0.1150841815}}
{"text":"Finally, we demonstrate the performance of our estimator via numerical experiments.","meta":{"url":"http://arxiv.org/abs/2309.06413v1"},"cats":{"new-dataset":0.056346569,"dev-research":0.1129462544,"data-quality":0.1902716331}}
{"text":"Every constructive model of computation (CMC) has an underlying composition mechanism for combining simple computation devices into more complex ones.","meta":{"url":"http://arxiv.org/abs/2309.06397v1"},"cats":{"new-dataset":0.0100324784,"dev-research":0.2894789645,"data-quality":0.0735641581}}
{"text":"Composition can be done by (explicitly or implicitly) defining control flow, data flow or any combination thereof.","meta":{"url":"http://arxiv.org/abs/2309.06397v1"},"cats":{"new-dataset":0.0265606155,"dev-research":0.2938888682,"data-quality":0.0988723286}}
{"text":"Control flow specifies the order in which individual computation devices are activated, whereas data flow defines how data is exchanged among them.","meta":{"url":"http://arxiv.org/abs/2309.06397v1"},"cats":{"new-dataset":0.0574304754,"dev-research":0.282674464,"data-quality":0.0664241413}}
{"text":"Unfortunately, traditional CMCs either mix data and control or only consider one dimension explicitly, which makes it difficult to reason about data flow and control flow separately.","meta":{"url":"http://arxiv.org/abs/2309.06397v1"},"cats":{"new-dataset":0.0680038752,"dev-research":0.1673748133,"data-quality":0.0724239315}}
{"text":"Reasoning about these dimensions orthogonally is a crucial desideratum for optimisation, maintainability and verification purposes.","meta":{"url":"http://arxiv.org/abs/2309.06397v1"},"cats":{"new-dataset":0.0202988685,"dev-research":0.2004992925,"data-quality":0.0934552657}}
{"text":"In this paper, we introduce a novel model that explicitly treats data flow and control flow as separate dimensions, while providing modularity.","meta":{"url":"http://arxiv.org/abs/2309.06397v1"},"cats":{"new-dataset":0.0515808993,"dev-research":0.2300936179,"data-quality":0.0670235447}}
{"text":"As the model is rooted in category theory, it provides category-theoretic operations for compositionally constructing sequential or parallel composites.","meta":{"url":"http://arxiv.org/abs/2309.06397v1"},"cats":{"new-dataset":0.0163476551,"dev-research":0.165306059,"data-quality":0.0538262831}}
{"text":"Compositionality entails that a composite exhibits the same properties as its respective constituents, including separation of concerns and modularity.","meta":{"url":"http://arxiv.org/abs/2309.06397v1"},"cats":{"new-dataset":0.0107654405,"dev-research":0.1450069171,"data-quality":0.1230894996}}
{"text":"Deploying robots that operate in dynamic, uncertain environments, such as Uncrewed Aerial Systems in search \\& rescue missions, require nearly continuous human supervision for vehicle guidance and operation.","meta":{"url":"http://arxiv.org/abs/2309.06395v1"},"cats":{"new-dataset":0.0295851472,"dev-research":0.2363728804,"data-quality":0.0690274806}}
{"text":"Without approaches that consider high level mission context, operational methods of autonomous flying necessitate cumbersome manual operation or inefficient exhaustive search patterns.","meta":{"url":"http://arxiv.org/abs/2309.06395v1"},"cats":{"new-dataset":0.0164912724,"dev-research":0.2083604532,"data-quality":0.0605731035}}
{"text":"To facilitate more effective use of autonomy, we present a human-centered autonomous system that infers geospatial mission context through dynamic features sets, which then guides a probabilistic target search planner.","meta":{"url":"http://arxiv.org/abs/2309.06395v1"},"cats":{"new-dataset":0.1200390078,"dev-research":0.2184182995,"data-quality":0.0582435037}}
{"text":"Operators provide a limited set of diverse inputs, including priority definition, spatial semantic observations over ad-hoc geographical areas, and reference waypoints, which are probabilistically fused with geographical database information and condensed into a discretized value map representing an operator's preferences over an operational area.","meta":{"url":"http://arxiv.org/abs/2309.06395v1"},"cats":{"new-dataset":0.0709054647,"dev-research":0.2705292044,"data-quality":0.0833996702}}
{"text":"An online, POMDP-based planner, optimized for target searching, is augmented with this value map to generate an operator-constrained vehicle waypoint guidance plan.","meta":{"url":"http://arxiv.org/abs/2309.06395v1"},"cats":{"new-dataset":0.0517194059,"dev-research":0.2106409479,"data-quality":0.0339175075}}
{"text":"We validate the system by gathering input from five first responders trained in search \\& rescue and compare simulated system performance against current operational methods for autonomous missions.","meta":{"url":"http://arxiv.org/abs/2309.06395v1"},"cats":{"new-dataset":0.089670127,"dev-research":0.1897576091,"data-quality":0.0946537195}}
{"text":"These results display effective task mental model alignment and more efficient guidance plans, resulting in faster rescue times.","meta":{"url":"http://arxiv.org/abs/2309.06395v1"},"cats":{"new-dataset":0.026739939,"dev-research":0.276131207,"data-quality":0.0638000104}}
{"text":"Can an $\\mathbb{R}^n\\rightarrow \\mathbb{R}^n$ feedforward network learn matrix-vector multiplication?","meta":{"url":"http://arxiv.org/abs/2309.06382v1"},"cats":{"new-dataset":0.0113999018,"dev-research":0.157126188,"data-quality":0.13731269}}
{"text":"This study introduces two mechanisms - flexible masking to take matrix inputs, and a unique network pruning to respect the mask's dependency structure.","meta":{"url":"http://arxiv.org/abs/2309.06382v1"},"cats":{"new-dataset":0.0118551309,"dev-research":0.1647215648,"data-quality":0.1672410652}}
{"text":"Networks can approximate fixed operations such as matrix-vector multiplication $\\phi(A,x) \\rightarrow Ax$, motivating the mechanisms introduced with applications towards litmus-testing dependencies or interaction order in graph-based models.","meta":{"url":"http://arxiv.org/abs/2309.06382v1"},"cats":{"new-dataset":0.0056995522,"dev-research":0.2363007908,"data-quality":0.0813415842}}
{"text":"Diffusion models have revolutionized text-to-image generation with its exceptional quality and creativity.","meta":{"url":"http://arxiv.org/abs/2309.06380v1"},"cats":{"new-dataset":0.0917244167,"dev-research":0.1513742488,"data-quality":0.1357358418}}
{"text":"However, its multi-step sampling process is known to be slow, often requiring tens of inference steps to obtain satisfactory results.","meta":{"url":"http://arxiv.org/abs/2309.06380v1"},"cats":{"new-dataset":0.0071927995,"dev-research":0.1480006194,"data-quality":0.085447276}}
{"text":"Previous attempts to improve its sampling speed and reduce computational costs through distillation have been unsuccessful in achieving a functional one-step model.","meta":{"url":"http://arxiv.org/abs/2309.06380v1"},"cats":{"new-dataset":0.0046086462,"dev-research":0.1311613727,"data-quality":0.1007951836}}
{"text":"In this paper, we explore a recent method called Rectified Flow, which, thus far, has only been applied to small datasets.","meta":{"url":"http://arxiv.org/abs/2309.06380v1"},"cats":{"new-dataset":0.524994518,"dev-research":0.1944303401,"data-quality":0.2168652485}}
{"text":"The core of Rectified Flow lies in its \\emph{reflow} procedure, which straightens the trajectories of probability flows, refines the coupling between noises and images, and facilitates the distillation process with student models.","meta":{"url":"http://arxiv.org/abs/2309.06380v1"},"cats":{"new-dataset":0.0206081501,"dev-research":0.2119460403,"data-quality":0.0950698107}}
{"text":"We propose a novel text-conditioned pipeline to turn Stable Diffusion (SD) into an ultra-fast one-step model, in which we find reflow plays a critical role in improving the assignment between noise and images.","meta":{"url":"http://arxiv.org/abs/2309.06380v1"},"cats":{"new-dataset":0.0579587764,"dev-research":0.1217522485,"data-quality":0.1541899898}}
{"text":"Leveraging our new pipeline, we create, to the best of our knowledge, the first one-step diffusion-based text-to-image generator with SD-level image quality, achieving an FID (Frechet Inception Distance) of $23.3$ on MS COCO 2017-5k, surpassing the previous state-of-the-art technique, progressive distillation, by a significant margin ($37.2","meta":{"url":"http://arxiv.org/abs/2309.06380v1"},"cats":{"new-dataset":0.3014767389,"dev-research":0.1628728336,"data-quality":0.2008137703}}
{"text":"$ $\\rightarrow$ $23.3$ in FID).","meta":{"url":"http://arxiv.org/abs/2309.06380v1"},"cats":{"new-dataset":0.1216602559,"dev-research":0.1955985798,"data-quality":0.112205286}}
{"text":"By utilizing an expanded network with 1.7B parameters, we further improve the FID to $22.4$. We call our one-step models \\emph{InstaFlow}.","meta":{"url":"http://arxiv.org/abs/2309.06380v1"},"cats":{"new-dataset":0.05967757,"dev-research":0.0871803506,"data-quality":0.0906100442}}
{"text":"On MS COCO 2014-30k, InstaFlow yields an FID of $13.1$ in just $0.09$ second, the best in $\\leq 0.1$ second regime, outperforming the recent StyleGAN-T ($13.9$ in $0.1$ second).","meta":{"url":"http://arxiv.org/abs/2309.06380v1"},"cats":{"new-dataset":0.2014507081,"dev-research":0.1611778434,"data-quality":0.1622848636}}
{"text":"Notably, the training of InstaFlow only costs 199 A100 GPU days.","meta":{"url":"http://arxiv.org/abs/2309.06380v1"},"cats":{"new-dataset":0.0609745595,"dev-research":0.1878185346,"data-quality":0.0727001492}}
{"text":"Project page:~\\url{https://github.com/gnobitab/InstaFlow}.","meta":{"url":"http://arxiv.org/abs/2309.06380v1"},"cats":{"new-dataset":0.1227264555,"dev-research":0.2773228927,"data-quality":0.1049640005}}
{"text":"With recent advances in Generative AI, it is becoming easier to automatically manipulate 3D models.","meta":{"url":"http://arxiv.org/abs/2309.06379v1"},"cats":{"new-dataset":0.0128764595,"dev-research":0.2237408621,"data-quality":0.0642331577}}
{"text":"However, current methods tend to apply edits to models globally, which risks compromising the intended functionality of the 3D model when fabricated in the physical world.","meta":{"url":"http://arxiv.org/abs/2309.06379v1"},"cats":{"new-dataset":0.006055162,"dev-research":0.3136611414,"data-quality":0.1185872384}}
{"text":"For example, modifying functional segments in 3D models, such as the base of a vase, could break the original functionality of the model, thus causing the vase to fall over.","meta":{"url":"http://arxiv.org/abs/2309.06379v1"},"cats":{"new-dataset":0.0036458707,"dev-research":0.3006080323,"data-quality":0.122559587}}
{"text":"We introduce a method for automatically segmenting 3D models into functional and aesthetic elements.","meta":{"url":"http://arxiv.org/abs/2309.06379v1"},"cats":{"new-dataset":0.0395761216,"dev-research":0.2661114971,"data-quality":0.1148576826}}
{"text":"This method allows users to selectively modify aesthetic segments of 3D models, without affecting the functional segments.","meta":{"url":"http://arxiv.org/abs/2309.06379v1"},"cats":{"new-dataset":0.0042368291,"dev-research":0.3461288043,"data-quality":0.0949790107}}
{"text":"To develop this method we first create a taxonomy of functionality in 3D models by qualitatively analyzing 1000 models sourced from a popular 3D printing repository, Thingiverse.","meta":{"url":"http://arxiv.org/abs/2309.06379v1"},"cats":{"new-dataset":0.1806287531,"dev-research":0.2741027541,"data-quality":0.0733191336}}
{"text":"With this taxonomy, we develop a semi-automatic classification method to decompose 3D models into functional and aesthetic elements.","meta":{"url":"http://arxiv.org/abs/2309.06379v1"},"cats":{"new-dataset":0.0999771053,"dev-research":0.2409470357,"data-quality":0.1387793277}}
{"text":"We propose a system called Style2Fab that allows users to selectively stylize 3D models without compromising their functionality.","meta":{"url":"http://arxiv.org/abs/2309.06379v1"},"cats":{"new-dataset":0.0277756351,"dev-research":0.3096861702,"data-quality":0.0902187884}}
{"text":"We evaluate the effectiveness of our classification method compared to human-annotated data, and demonstrate the utility of Style2Fab with a user study to show that functionality-aware segmentation helps preserve model functionality.","meta":{"url":"http://arxiv.org/abs/2309.06379v1"},"cats":{"new-dataset":0.1769471545,"dev-research":0.425799451,"data-quality":0.3651923034}}
{"text":"Convolution is a fundamental operation in image processing and machine learning.","meta":{"url":"http://arxiv.org/abs/2309.06370v1"},"cats":{"new-dataset":0.018050042,"dev-research":0.1656783802,"data-quality":0.127845785}}
{"text":"Aimed primarily at maintaining image size, padding is a key ingredient of convolution, which, however, can introduce undesirable boundary effects.","meta":{"url":"http://arxiv.org/abs/2309.06370v1"},"cats":{"new-dataset":0.0082828181,"dev-research":0.1952382338,"data-quality":0.1298426471}}
{"text":"We present a non-padding-based method for size-keeping convolution based on the preservation of differential characteristics of kernels.","meta":{"url":"http://arxiv.org/abs/2309.06370v1"},"cats":{"new-dataset":0.0231816916,"dev-research":0.1422959096,"data-quality":0.1768990587}}
{"text":"The main idea is to make convolution over an incomplete sliding window \"collapse\" to a linear differential operator evaluated locally at its central pixel, which no longer requires information from the neighbouring missing pixels.","meta":{"url":"http://arxiv.org/abs/2309.06370v1"},"cats":{"new-dataset":0.0211249727,"dev-research":0.1419238971,"data-quality":0.1125414369}}
{"text":"While the underlying theory is rigorous, our final formula turns out to be simple: the convolution over an incomplete window is achieved by convolving its nearest complete window with a transformed kernel.","meta":{"url":"http://arxiv.org/abs/2309.06370v1"},"cats":{"new-dataset":0.0556223873,"dev-research":0.1420565217,"data-quality":0.1485622939}}
{"text":"This formula is computationally lightweight, involving neither interpolation or extrapolation nor restrictions on image and kernel sizes.","meta":{"url":"http://arxiv.org/abs/2309.06370v1"},"cats":{"new-dataset":0.0484567442,"dev-research":0.0995632638,"data-quality":0.0614863165}}
{"text":"Our method favours data with smooth boundaries, such as high-resolution images and fields from physics.","meta":{"url":"http://arxiv.org/abs/2309.06370v1"},"cats":{"new-dataset":0.137499789,"dev-research":0.1276718067,"data-quality":0.0940607893}}
{"text":"Our experiments include: i) filtering analytical and non-analytical fields from computational physics and, ii) training convolutional neural networks (CNNs) for the tasks of image classification, semantic segmentation and super-resolution reconstruction.","meta":{"url":"http://arxiv.org/abs/2309.06370v1"},"cats":{"new-dataset":0.2070181331,"dev-research":0.113884533,"data-quality":0.1278814691}}
{"text":"In all these experiments, our method has exhibited visible superiority over the compared ones.","meta":{"url":"http://arxiv.org/abs/2309.06370v1"},"cats":{"new-dataset":0.0056578381,"dev-research":0.1480024358,"data-quality":0.1587588083}}
{"text":"Computational models can advance affective science by shedding light onto the interplay between cognition and emotion from an information processing point of view.","meta":{"url":"http://arxiv.org/abs/2309.06367v1"},"cats":{"new-dataset":0.037038166,"dev-research":0.2835681836,"data-quality":0.1018973722}}
{"text":"We propose a computational model of emotion that integrates reinforcement learning (RL) and appraisal theory, establishing a formal relationship between reward processing, goal-directed task learning, cognitive appraisal and emotional experiences.","meta":{"url":"http://arxiv.org/abs/2309.06367v1"},"cats":{"new-dataset":0.0461961953,"dev-research":0.2409771938,"data-quality":0.063732804}}
{"text":"The model achieves this by formalizing evaluative checks from the component process model (CPM) in terms of temporal difference learning updates.","meta":{"url":"http://arxiv.org/abs/2309.06367v1"},"cats":{"new-dataset":0.0359237927,"dev-research":0.3119597801,"data-quality":0.1502008842}}
{"text":"We formalized novelty, goal relevance, goal conduciveness, and power.","meta":{"url":"http://arxiv.org/abs/2309.06367v1"},"cats":{"new-dataset":0.0144156897,"dev-research":0.2257989781,"data-quality":0.1573210324}}
{"text":"The formalization is task independent and can be applied to any task that can be represented as a Markov decision problem (MDP) and solved using RL.","meta":{"url":"http://arxiv.org/abs/2309.06367v1"},"cats":{"new-dataset":0.0147954086,"dev-research":0.2094609067,"data-quality":0.0900948006}}
{"text":"We investigated to what extent CPM-RL enables simulation of emotional responses cased by interactive task events.","meta":{"url":"http://arxiv.org/abs/2309.06367v1"},"cats":{"new-dataset":0.1003450177,"dev-research":0.2808496252,"data-quality":0.0768203502}}
{"text":"We evaluate the model by predicting a range of human emotions based on a series of vignette studies, highlighting its potential in improving our understanding of the role of reward processing in affective experiences.","meta":{"url":"http://arxiv.org/abs/2309.06367v1"},"cats":{"new-dataset":0.0222854238,"dev-research":0.1662245718,"data-quality":0.0856375076}}
{"text":"Automatic related work generation must ground their outputs to the content of the cited papers to avoid non-factual hallucinations, but due to the length of scientific documents, existing abstractive approaches have conditioned only on the cited paper \\textit{abstracts}.","meta":{"url":"http://arxiv.org/abs/2309.06365v1"},"cats":{"new-dataset":0.0278628196,"dev-research":0.3139430242,"data-quality":0.2359604889}}
{"text":"We demonstrate that the abstract is not always the most appropriate input for citation generation and that models trained in this way learn to hallucinate.","meta":{"url":"http://arxiv.org/abs/2309.06365v1"},"cats":{"new-dataset":0.0350094645,"dev-research":0.1824358956,"data-quality":0.2314861972}}
{"text":"We propose to condition instead on the \\textit{cited text span} (CTS) as an alternative to the abstract.","meta":{"url":"http://arxiv.org/abs/2309.06365v1"},"cats":{"new-dataset":0.039609527,"dev-research":0.1695871555,"data-quality":0.332618204}}
{"text":"Because manual CTS annotation is extremely time- and labor-intensive, we experiment with automatic, ROUGE-based labeling of candidate CTS sentences, achieving sufficiently strong performance to substitute for expensive human annotations, and we propose a human-in-the-loop, keyword-based CTS retrieval approach that makes generating citation texts grounded in the full text of cited papers both promising and practical.","meta":{"url":"http://arxiv.org/abs/2309.06365v1"},"cats":{"new-dataset":0.2551752471,"dev-research":0.2198491314,"data-quality":0.4056853441}}
{"text":"Prior work has shown that the ordering in which concepts are shown to a commonsense generator plays an important role, affecting the quality of the generated sentence.","meta":{"url":"http://arxiv.org/abs/2309.06363v1"},"cats":{"new-dataset":0.052436729,"dev-research":0.2696491734,"data-quality":0.2163043288}}
{"text":"However, it remains a challenge to determine the optimal ordering of a given set of concepts such that a natural sentence covering all the concepts could be generated from a pretrained generator.","meta":{"url":"http://arxiv.org/abs/2309.06363v1"},"cats":{"new-dataset":0.0724802778,"dev-research":0.2296761746,"data-quality":0.2019140531}}
{"text":"To understand the relationship between the ordering of the input concepts and the quality of the generated sentences, we conduct a systematic study considering multiple language models (LMs) and concept ordering strategies.","meta":{"url":"http://arxiv.org/abs/2309.06363v1"},"cats":{"new-dataset":0.0188095991,"dev-research":0.2718454425,"data-quality":0.2264573629}}
{"text":"We find that BART-large model consistently outperforms all other LMs considered in this study when fine-tuned using the ordering of concepts as they appear in CommonGen training data as measured using multiple evaluation metrics.","meta":{"url":"http://arxiv.org/abs/2309.06363v1"},"cats":{"new-dataset":0.0304388437,"dev-research":0.1246649099,"data-quality":0.1804115188}}
{"text":"Moreover, the larger GPT3-based large language models (LLMs) variants do not necessarily outperform much smaller LMs on this task, even when fine-tuned on task-specific training data.","meta":{"url":"http://arxiv.org/abs/2309.06363v1"},"cats":{"new-dataset":0.028651047,"dev-research":0.1084557315,"data-quality":0.1537935704}}
{"text":"Interestingly, human annotators significantly reorder input concept sets when manually writing sentences covering those concepts, and this ordering provides the best sentence generations independently of the LM used for the generation, outperforming a probabilistic concept ordering baseline","meta":{"url":"http://arxiv.org/abs/2309.06363v1"},"cats":{"new-dataset":0.1155259078,"dev-research":0.3105859287,"data-quality":0.3488909401}}
{"text":"When deploying classifiers in the real world, users expect them to respond to inputs appropriately.","meta":{"url":"http://arxiv.org/abs/2309.06359v1"},"cats":{"new-dataset":0.0060263531,"dev-research":0.337496887,"data-quality":0.3656726389}}
{"text":"However, traditional classifiers are not equipped to handle inputs which lie far from the distribution they were trained on.","meta":{"url":"http://arxiv.org/abs/2309.06359v1"},"cats":{"new-dataset":0.003210564,"dev-research":0.1770143772,"data-quality":0.3204508526}}
{"text":"Malicious actors can exploit this defect by making adversarial perturbations designed to cause the classifier to give an incorrect output.","meta":{"url":"http://arxiv.org/abs/2309.06359v1"},"cats":{"new-dataset":0.0187968427,"dev-research":0.2768600364,"data-quality":0.5795189768}}
{"text":"Classification-with-rejection methods attempt to solve this problem by allowing networks to refuse to classify an input in which they have low confidence.","meta":{"url":"http://arxiv.org/abs/2309.06359v1"},"cats":{"new-dataset":0.010236667,"dev-research":0.1947830727,"data-quality":0.4738890885}}
{"text":"This works well for strongly adversarial examples, but also leads to the rejection of weakly perturbed images, which intuitively could be correctly classified.","meta":{"url":"http://arxiv.org/abs/2309.06359v1"},"cats":{"new-dataset":0.0101020831,"dev-research":0.152619582,"data-quality":0.4265369409}}
{"text":"To address these issues, we propose Reed-Muller Aggregation Networks (RMAggNet), a classifier inspired by Reed-Muller error-correction codes which can correct and reject inputs.","meta":{"url":"http://arxiv.org/abs/2309.06359v1"},"cats":{"new-dataset":0.0880660495,"dev-research":0.2135168146,"data-quality":0.4705141171}}
{"text":"This paper shows that RMAggNet can minimise incorrectness while maintaining good correctness over multiple adversarial attacks at different perturbation budgets by leveraging the ability to correct errors in the classification process.","meta":{"url":"http://arxiv.org/abs/2309.06359v1"},"cats":{"new-dataset":0.0172516304,"dev-research":0.2799914325,"data-quality":0.5546647669}}
{"text":"This provides an alternative classification-with-rejection method which can reduce the amount of additional processing in situations where a small number of incorrect classifications are permissible.","meta":{"url":"http://arxiv.org/abs/2309.06359v1"},"cats":{"new-dataset":0.0170517021,"dev-research":0.3199329917,"data-quality":0.6402443114}}
{"text":"Spatial data is ubiquitous.","meta":{"url":"http://arxiv.org/abs/2309.06354v1"},"cats":{"new-dataset":0.3627926871,"dev-research":0.1683554356,"data-quality":0.0806682486}}
{"text":"Massive amounts of data are generated every day from a plethora of sources such as billions of GPS-enabled devices (e.g., cell phones, cars, and sensors), consumer-based applications (e.g., Uber and Strava), and social media platforms (e.g., location-tagged posts on Facebook, Twitter, and Instagram).","meta":{"url":"http://arxiv.org/abs/2309.06354v1"},"cats":{"new-dataset":0.4318932704,"dev-research":0.1916324821,"data-quality":0.0954511832}}
{"text":"This exponential growth in spatial data has led the research community to build systems and applications for efficient spatial data processing.   ","meta":{"url":"http://arxiv.org/abs/2309.06354v1"},"cats":{"new-dataset":0.1998481961,"dev-research":0.1943185504,"data-quality":0.048700054}}
{"text":"In this study, we apply a recently developed machine-learned search technique for single-dimensional sorted data to spatial indexing.","meta":{"url":"http://arxiv.org/abs/2309.06354v1"},"cats":{"new-dataset":0.1102535124,"dev-research":0.1396999211,"data-quality":0.1026342655}}
{"text":"Specifically, we partition spatial data using six traditional spatial partitioning techniques and employ machine-learned search within each partition to support point, range, distance, and spatial join queries.","meta":{"url":"http://arxiv.org/abs/2309.06354v1"},"cats":{"new-dataset":0.2185182325,"dev-research":0.1474141966,"data-quality":0.0848162634}}
{"text":"Adhering to the latest research trends, we tune the partitioning techniques to be instance-optimized.","meta":{"url":"http://arxiv.org/abs/2309.06354v1"},"cats":{"new-dataset":0.0263906192,"dev-research":0.1811596071,"data-quality":0.1320172733}}
{"text":"By tuning each partitioning technique for optimal performance, we demonstrate that: (i) grid-based index structures outperform tree-based index structures (from 1.23$\\times$ to 2.47$\\times$), (ii) learning-enhanced variants of commonly used spatial index structures outperform their original counterparts (from 1.44$\\times$ to 53.34$\\times$ faster), (iii) machine-learned search within a partition is faster than binary search by 11.79% - 39.51% when filtering on one dimension, (iv) the benefit of machine-learned search diminishes in the presence of other compute-intensive operations (e.g. scan costs in higher selectivity queries, Haversine distance computation, and point-in-polygon tests), and (v) index lookup is the bottleneck for tree-based structures, which could potentially be reduced by linearizing the indexed partitions.","meta":{"url":"http://arxiv.org/abs/2309.06354v1"},"cats":{"new-dataset":0.0168307533,"dev-research":0.1383146804,"data-quality":0.0826572532}}
{"text":"This paper describes the full end-to-end design of our primary scoring agent in an aerial autonomous robotics competition from April 2023.","meta":{"url":"http://arxiv.org/abs/2309.06352v1"},"cats":{"new-dataset":0.1318555907,"dev-research":0.1751094657,"data-quality":0.052216912}}
{"text":"As open-ended robotics competitions become more popular, we wish to begin documenting successful team designs and approaches.","meta":{"url":"http://arxiv.org/abs/2309.06352v1"},"cats":{"new-dataset":0.3540348298,"dev-research":0.3546977579,"data-quality":0.0630516147}}
{"text":"The intended audience of this paper is not only any future or potential participant in this particular national Defend The Republic (DTR) competition, but rather anyone thinking about designing their first robot or system to be entered in a competition with clear goals.","meta":{"url":"http://arxiv.org/abs/2309.06352v1"},"cats":{"new-dataset":0.0830716492,"dev-research":0.1781911529,"data-quality":0.0418970202}}
{"text":"Future DTR participants can and should either build on the ideas here, or find new alternate strategies that can defeat the most successful design last time.","meta":{"url":"http://arxiv.org/abs/2309.06352v1"},"cats":{"new-dataset":0.0189066292,"dev-research":0.3201213235,"data-quality":0.079152547}}
{"text":"For non-DTR participants but students interested in robotics competitions, identifying the minimum viable system needed to be competitive is still important in helping manage time and prioritizing tasks that are crucial to competition success first.","meta":{"url":"http://arxiv.org/abs/2309.06352v1"},"cats":{"new-dataset":0.0166949416,"dev-research":0.1900779828,"data-quality":0.0418389245}}
{"text":"High-order structures have been recognised as suitable models for systems going beyond the binary relationships for which graph models are appropriate.","meta":{"url":"http://arxiv.org/abs/2309.06351v1"},"cats":{"new-dataset":0.023667766,"dev-research":0.1264413154,"data-quality":0.062784488}}
{"text":"Despite their importance and surge in research on these structures, their random cases have been only recently become subjects of interest.","meta":{"url":"http://arxiv.org/abs/2309.06351v1"},"cats":{"new-dataset":0.0266855148,"dev-research":0.1215315036,"data-quality":0.1021382868}}
{"text":"One of these high-order structures is the oriented hypergraph, which relates couples of subsets of an arbitrary number of vertices.","meta":{"url":"http://arxiv.org/abs/2309.06351v1"},"cats":{"new-dataset":0.1272695265,"dev-research":0.1646997155,"data-quality":0.0764407619}}
{"text":"Here we develop the Erd\\H{o}s-R\\'enyi model for oriented hypergraphs, which corresponds to the random realisation of oriented hyperedges of the complete oriented hypergraph.","meta":{"url":"http://arxiv.org/abs/2309.06351v1"},"cats":{"new-dataset":0.0993057077,"dev-research":0.1411668563,"data-quality":0.1638396907}}
{"text":"A particular feature of random oriented hypergraphs is that the ratio between their expected number of oriented hyperedges and their expected degree or size is 3/2 for large number of vertices.","meta":{"url":"http://arxiv.org/abs/2309.06351v1"},"cats":{"new-dataset":0.0208820304,"dev-research":0.1609590911,"data-quality":0.1264884656}}
{"text":"We highlight the suitability of oriented hypergraphs for modelling large collections of chemical reactions and the importance of random oriented hypergraphs to analyse the unfolding of chemistry.","meta":{"url":"http://arxiv.org/abs/2309.06351v1"},"cats":{"new-dataset":0.0907571175,"dev-research":0.199847611,"data-quality":0.1306205171}}
{"text":"This paper explores opportunities to utilize Large Language Models (LLMs) to make network configuration human-friendly, simplifying the configuration of network devices and minimizing errors.","meta":{"url":"http://arxiv.org/abs/2309.06342v1"},"cats":{"new-dataset":0.0654410187,"dev-research":0.3229226317,"data-quality":0.2077194134}}
{"text":"We examine the effectiveness of these models in translating high-level policies and requirements (i.e., specified in natural language) into low-level network APIs, which requires understanding the hardware and protocols.","meta":{"url":"http://arxiv.org/abs/2309.06342v1"},"cats":{"new-dataset":0.0618118613,"dev-research":0.3503716089,"data-quality":0.1051335828}}
{"text":"More specifically, we propose NETBUDDY for generating network configurations from scratch and modifying them at runtime.","meta":{"url":"http://arxiv.org/abs/2309.06342v1"},"cats":{"new-dataset":0.1636708602,"dev-research":0.3070748745,"data-quality":0.0798111924}}
{"text":"NETBUDDY splits the generation of network configurations into fine-grained steps and relies on self-healing code-generation approaches to better take advantage of the full potential of LLMs.","meta":{"url":"http://arxiv.org/abs/2309.06342v1"},"cats":{"new-dataset":0.0501437151,"dev-research":0.2391308987,"data-quality":0.1178156295}}
{"text":"We first thoroughly examine the challenges of using these models to produce a fully functional & correct configuration, and then evaluate the feasibility of realizing NETBUDDY by building a proof-of-concept solution using GPT-4 to translate a set of high-level requirements into P4 and BGP configurations and run them using the Kathar\\'a network emulator.","meta":{"url":"http://arxiv.org/abs/2309.06342v1"},"cats":{"new-dataset":0.0352658895,"dev-research":0.1723178632,"data-quality":0.0691049816}}
{"text":"Domain Generalization (DG) aims to generalize to arbitrary unseen domains.","meta":{"url":"http://arxiv.org/abs/2309.06337v1"},"cats":{"new-dataset":0.016410192,"dev-research":0.1710145981,"data-quality":0.1606724778}}
{"text":"A promising approach to improve model generalization in DG is the identification of flat minima.","meta":{"url":"http://arxiv.org/abs/2309.06337v1"},"cats":{"new-dataset":0.013898981,"dev-research":0.1228836402,"data-quality":0.1887446794}}
{"text":"One typical method for this task is SWAD, which involves averaging weights along the training trajectory.","meta":{"url":"http://arxiv.org/abs/2309.06337v1"},"cats":{"new-dataset":0.017491392,"dev-research":0.1415360522,"data-quality":0.0570454149}}
{"text":"However, the success of weight averaging depends on the diversity of weights, which is limited when training with a small learning rate.","meta":{"url":"http://arxiv.org/abs/2309.06337v1"},"cats":{"new-dataset":0.000667919,"dev-research":0.1047443774,"data-quality":0.1485364446}}
{"text":"Instead, we observe that leveraging a large learning rate can simultaneously promote weight diversity and facilitate the identification of flat regions in the loss landscape.","meta":{"url":"http://arxiv.org/abs/2309.06337v1"},"cats":{"new-dataset":0.0223084377,"dev-research":0.1173082385,"data-quality":0.1413320564}}
{"text":"However, employing a large learning rate suffers from the convergence problem, which cannot be resolved by simply averaging the training weights.","meta":{"url":"http://arxiv.org/abs/2309.06337v1"},"cats":{"new-dataset":0.0028615784,"dev-research":0.1022590696,"data-quality":0.1539894617}}
{"text":"To address this issue, we introduce a training strategy called Lookahead which involves the weight interpolation, instead of average, between fast and slow weights.","meta":{"url":"http://arxiv.org/abs/2309.06337v1"},"cats":{"new-dataset":0.0205266392,"dev-research":0.1079432462,"data-quality":0.0983187795}}
{"text":"The fast weight explores the weight space with a large learning rate, which is not converged while the slow weight interpolates with it to ensure the convergence.","meta":{"url":"http://arxiv.org/abs/2309.06337v1"},"cats":{"new-dataset":0.003846925,"dev-research":0.0892030928,"data-quality":0.0999696173}}
{"text":"Besides, weight interpolation also helps identify flat minima by implicitly optimizing the local entropy loss that measures flatness.","meta":{"url":"http://arxiv.org/abs/2309.06337v1"},"cats":{"new-dataset":0.003920005,"dev-research":0.1171373589,"data-quality":0.1477853003}}
{"text":"To further prevent overfitting during training, we propose two variants to regularize the training weight with weighted averaged weight or with accumulated history weight.","meta":{"url":"http://arxiv.org/abs/2309.06337v1"},"cats":{"new-dataset":0.0184400984,"dev-research":0.1811194728,"data-quality":0.1927985288}}
{"text":"Taking advantage of this new perspective, our methods achieve state-of-the-art performance on both classification and semantic segmentation domain generalization benchmarks.","meta":{"url":"http://arxiv.org/abs/2309.06337v1"},"cats":{"new-dataset":0.1498811421,"dev-research":0.1473806584,"data-quality":0.2893058859}}
{"text":"The code is available at https://github.com/koncle/DG-with-Large-LR.","meta":{"url":"http://arxiv.org/abs/2309.06337v1"},"cats":{"new-dataset":0.4061380319,"dev-research":0.1162535893,"data-quality":0.0792337194}}
{"text":"Deep learning approaches to natural language processing have made great strides in recent years.","meta":{"url":"http://arxiv.org/abs/2309.06335v1"},"cats":{"new-dataset":0.1020003127,"dev-research":0.1758206365,"data-quality":0.2243168903}}
{"text":"While these models produce symbols that convey vast amounts of diverse knowledge, it is unclear how such symbols are grounded in data from the world.","meta":{"url":"http://arxiv.org/abs/2309.06335v1"},"cats":{"new-dataset":0.0990342193,"dev-research":0.1725886953,"data-quality":0.1777186281}}
{"text":"In this paper, we explore the development of a private language for visual data representation by training emergent language (EL) encoders/decoders in both i) a traditional referential game environment and ii) a contrastive learning environment utilizing a within-class matching training paradigm.","meta":{"url":"http://arxiv.org/abs/2309.06335v1"},"cats":{"new-dataset":0.3752390929,"dev-research":0.2230273976,"data-quality":0.1328977507}}
{"text":"An additional classification layer utilizing neural machine translation and random forest classification was used to transform symbolic representations (sequences of integer symbols) to class labels.","meta":{"url":"http://arxiv.org/abs/2309.06335v1"},"cats":{"new-dataset":0.1492181072,"dev-research":0.1918114867,"data-quality":0.3400362896}}
{"text":"These methods were applied in two experiments focusing on object recognition and action recognition.","meta":{"url":"http://arxiv.org/abs/2309.06335v1"},"cats":{"new-dataset":0.0258823046,"dev-research":0.1687489436,"data-quality":0.1995667948}}
{"text":"For object recognition, a set of sketches produced by human participants from real imagery was used (Sketchy dataset) and for action recognition, 2D trajectories were generated from 3D motion capture systems (MOVI dataset).","meta":{"url":"http://arxiv.org/abs/2309.06335v1"},"cats":{"new-dataset":0.5978237041,"dev-research":0.2154987029,"data-quality":0.0660571195}}
{"text":"In order to interpret the symbols produced for data in each experiment, gradient-weighted class activation mapping (Grad-CAM) methods were used to identify pixel regions indicating semantic features which contribute evidence towards symbols in learned languages.","meta":{"url":"http://arxiv.org/abs/2309.06335v1"},"cats":{"new-dataset":0.0959895055,"dev-research":0.2583672353,"data-quality":0.3495287322}}
{"text":"Additionally, a t-distributed stochastic neighbor embedding (t-SNE) method was used to investigate embeddings learned by CNN feature extractors.","meta":{"url":"http://arxiv.org/abs/2309.06335v1"},"cats":{"new-dataset":0.0528895105,"dev-research":0.1592227204,"data-quality":0.1941772659}}
{"text":"Game engines support video game development by providing functionalities such as graphics rendering or input/output device management.","meta":{"url":"http://arxiv.org/abs/2309.06329v1"},"cats":{"new-dataset":0.0316620018,"dev-research":0.3833300411,"data-quality":0.0666072312}}
{"text":"However, their architectures are often overlooked, which hinders their integration and extension.","meta":{"url":"http://arxiv.org/abs/2309.06329v1"},"cats":{"new-dataset":0.0033079696,"dev-research":0.2993381419,"data-quality":0.1531486688}}
{"text":"In this paper, we use an approach for architecture recovery to create architectural models for 10 open-source game engines.","meta":{"url":"http://arxiv.org/abs/2309.06329v1"},"cats":{"new-dataset":0.1404875218,"dev-research":0.2726669338,"data-quality":0.0784236236}}
{"text":"We use these models to answer the following questions: Which subsystems more often couple with one another?","meta":{"url":"http://arxiv.org/abs/2309.06329v1"},"cats":{"new-dataset":0.0202141498,"dev-research":0.1422523424,"data-quality":0.0627306638}}
{"text":"Do game engines share subsystem coupling patterns?","meta":{"url":"http://arxiv.org/abs/2309.06329v1"},"cats":{"new-dataset":0.0196219242,"dev-research":0.2154246668,"data-quality":0.0577538575}}
{"text":"We observe that the Low-Level Renderer, Platform Independence Layer and Resource Manager are frequently coupled to the game engine Core.","meta":{"url":"http://arxiv.org/abs/2309.06329v1"},"cats":{"new-dataset":0.0557906061,"dev-research":0.2470384229,"data-quality":0.0778664866}}
{"text":"By identifying the most frequent coupling patterns, we describe an emergent game engine architecture and discuss how it can be used by practitioners to improve system understanding and maintainability.","meta":{"url":"http://arxiv.org/abs/2309.06329v1"},"cats":{"new-dataset":0.1811080311,"dev-research":0.3784146264,"data-quality":0.0916373483}}
{"text":"This paper focuses on the design of transmission methods and reflection optimization for a wireless system assisted by a single or multiple reconfigurable intelligent surfaces (RISs).","meta":{"url":"http://arxiv.org/abs/2309.06326v1"},"cats":{"new-dataset":0.0108660447,"dev-research":0.177500377,"data-quality":0.0534337502}}
{"text":"The existing techniques are either too complex to implement in practical systems or too inefficient to achieve high performance.","meta":{"url":"http://arxiv.org/abs/2309.06326v1"},"cats":{"new-dataset":0.0018851095,"dev-research":0.320731071,"data-quality":0.0841015667}}
{"text":"To overcome the shortcomings of the existing schemes, we propose a simple but efficient approach based on \\textit{opportunistic reflection} and \\textit{non-orthogonal transmission}.","meta":{"url":"http://arxiv.org/abs/2309.06326v1"},"cats":{"new-dataset":0.0070796176,"dev-research":0.1301867536,"data-quality":0.0959673685}}
{"text":"The key idea is opportunistically selecting the best user that can reap the maximal gain from the optimally reflected signals via RIS.","meta":{"url":"http://arxiv.org/abs/2309.06326v1"},"cats":{"new-dataset":0.0056380863,"dev-research":0.1066356606,"data-quality":0.0821711712}}
{"text":"That is to say, only the channel state information of the best user is used for RIS reflection optimization, which can in turn lower complexity substantially.","meta":{"url":"http://arxiv.org/abs/2309.06326v1"},"cats":{"new-dataset":0.0014719993,"dev-research":0.1557487854,"data-quality":0.0850420245}}
{"text":"In addition, the second user is selected to superpose its signal on that of the primary user, where the benefits of non-orthogonal transmission, i.e., high system capacity and improved user fairness, are obtained.","meta":{"url":"http://arxiv.org/abs/2309.06326v1"},"cats":{"new-dataset":0.00353487,"dev-research":0.1357775032,"data-quality":0.0515569522}}
{"text":"Additionally, a simplified variant exploiting random phase shifts is proposed to avoid the high overhead of RIS channel estimation.","meta":{"url":"http://arxiv.org/abs/2309.06326v1"},"cats":{"new-dataset":0.0173966244,"dev-research":0.1085807098,"data-quality":0.1673719985}}
{"text":"Satellite-terrestrial integrated networks (STINs) are promising architecture for providing global coverage.","meta":{"url":"http://arxiv.org/abs/2309.06325v1"},"cats":{"new-dataset":0.0461534536,"dev-research":0.1643088528,"data-quality":0.0742826271}}
{"text":"In STINs, full frequency reuse between a satellite and a terrestrial base station (BS) is encouraged for enhancing spectral efficiency, which accounts for non-negligible amount of interference.","meta":{"url":"http://arxiv.org/abs/2309.06325v1"},"cats":{"new-dataset":0.0103454382,"dev-research":0.1458064787,"data-quality":0.0948636141}}
{"text":"To address the interference management problem in STINs, this paper proposes a novel distributed precoding method.","meta":{"url":"http://arxiv.org/abs/2309.06325v1"},"cats":{"new-dataset":0.0179573682,"dev-research":0.18319006,"data-quality":0.1583217545}}
{"text":"Key features of our method are: i) a rate-splitting (RS) strategy is incorporated for efficient interference management, ii) precoders are designed in a distributed way without sharing channel state information between a satellite and a terrestrial BS.","meta":{"url":"http://arxiv.org/abs/2309.06325v1"},"cats":{"new-dataset":0.0163885352,"dev-research":0.1320798576,"data-quality":0.0950271213}}
{"text":"Specifically, to design precoders in a distributed fashion, we put forth a spectral efficiency decoupling technique.","meta":{"url":"http://arxiv.org/abs/2309.06325v1"},"cats":{"new-dataset":0.016445288,"dev-research":0.1679634594,"data-quality":0.0913475999}}
{"text":"This technique disentangles the total spectral efficiency into two distinct terms, each dependent solely on the satellite's precoder and the terrestrial BS's precoder, respectively.","meta":{"url":"http://arxiv.org/abs/2309.06325v1"},"cats":{"new-dataset":0.0085311296,"dev-research":0.1197433639,"data-quality":0.0924172368}}
{"text":"Then, to resolve the non-smoothness raised by adopting the RS strategy, we approximate the spectral efficiency expression as a smooth function; thereafter we develop a generalized power iteration inspired optimization algorithm built based on the first-order optimality condition.","meta":{"url":"http://arxiv.org/abs/2309.06325v1"},"cats":{"new-dataset":0.0040667332,"dev-research":0.1406955775,"data-quality":0.0702393366}}
{"text":"Simulation results demonstrate that the proposed method improves the spectral efficiency (around 20~29%) compared to existing distributed precoding schemes.","meta":{"url":"http://arxiv.org/abs/2309.06325v1"},"cats":{"new-dataset":0.0111154982,"dev-research":0.1380371876,"data-quality":0.1070274076}}
{"text":"Recent novel view synthesis methods obtain promising results for relatively small scenes, e.g., indoor environments and scenes with a few objects, but tend to fail for unbounded outdoor scenes with a single image as input.","meta":{"url":"http://arxiv.org/abs/2309.06323v1"},"cats":{"new-dataset":0.1551632819,"dev-research":0.2104220851,"data-quality":0.0863903971}}
{"text":"In this paper, we introduce SAMPLING, a Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image based on improved multiplane images (MPI).","meta":{"url":"http://arxiv.org/abs/2309.06323v1"},"cats":{"new-dataset":0.2537275873,"dev-research":0.1907589113,"data-quality":0.1340932193}}
{"text":"Observing that depth distribution varies significantly for unbounded outdoor scenes, we employ an adaptive-bins strategy for MPI to arrange planes in accordance with each scene image.","meta":{"url":"http://arxiv.org/abs/2309.06323v1"},"cats":{"new-dataset":0.1245764852,"dev-research":0.135856732,"data-quality":0.0721868535}}
{"text":"To represent intricate geometry and multi-scale details, we further introduce a hierarchical refinement branch, which results in high-quality synthesized novel views.","meta":{"url":"http://arxiv.org/abs/2309.06323v1"},"cats":{"new-dataset":0.2018656662,"dev-research":0.280566591,"data-quality":0.0769928228}}
{"text":"Our method demonstrates considerable performance gains in synthesizing large-scale unbounded outdoor scenes using a single image on the KITTI dataset and generalizes well to the unseen Tanks and Temples dataset.","meta":{"url":"http://arxiv.org/abs/2309.06323v1"},"cats":{"new-dataset":0.6329537891,"dev-research":0.1477577419,"data-quality":0.0937860811}}
{"text":"The code and models will be made public.","meta":{"url":"http://arxiv.org/abs/2309.06323v1"},"cats":{"new-dataset":0.2858498399,"dev-research":0.2152290579,"data-quality":0.0873738371}}
{"text":"As adoption of mobile phones has skyrocketed, so have scams involving them.","meta":{"url":"http://arxiv.org/abs/2309.06322v1"},"cats":{"new-dataset":0.0346439019,"dev-research":0.1767294884,"data-quality":0.0966959419}}
{"text":"The text method is called SMiShing, (aka SMShing, or smishing) in which a fraudster sends a phishing link via Short Message Service (SMS) text to a phone.","meta":{"url":"http://arxiv.org/abs/2309.06322v1"},"cats":{"new-dataset":0.0529980584,"dev-research":0.2052342798,"data-quality":0.2212790661}}
{"text":"However, no data exists on who is most vulnerable to SMiShing.","meta":{"url":"http://arxiv.org/abs/2309.06322v1"},"cats":{"new-dataset":0.0644499059,"dev-research":0.13597987,"data-quality":0.1229964918}}
{"text":"Prior work in phishing (its e-mail cousin) indicates that this is likely to vary by demographic and contextual factors.","meta":{"url":"http://arxiv.org/abs/2309.06322v1"},"cats":{"new-dataset":0.0098973108,"dev-research":0.2434830032,"data-quality":0.1469145654}}
{"text":"In our study, we collect this data from N=1007 U.S. adult mobile phone users.","meta":{"url":"http://arxiv.org/abs/2309.06322v1"},"cats":{"new-dataset":0.6095920543,"dev-research":0.147861987,"data-quality":0.0876895667}}
{"text":"Younger people and college students emerge in this sample as the most vulnerable.","meta":{"url":"http://arxiv.org/abs/2309.06322v1"},"cats":{"new-dataset":0.0927917784,"dev-research":0.2909526663,"data-quality":0.1210417881}}
{"text":"Participants struggled to correctly identify legitimate messages and were easily misled when they knew they had an account with the faked message entity.","meta":{"url":"http://arxiv.org/abs/2309.06322v1"},"cats":{"new-dataset":0.0184082706,"dev-research":0.2951725729,"data-quality":0.4608739259}}
{"text":"Counterintuitively, participants with higher levels of security training and awareness were less correct in rating possible SMiSH.","meta":{"url":"http://arxiv.org/abs/2309.06322v1"},"cats":{"new-dataset":0.0036779198,"dev-research":0.2145570529,"data-quality":0.2238115565}}
{"text":"We recommend next steps for researchers, regulators and telecom providers.","meta":{"url":"http://arxiv.org/abs/2309.06322v1"},"cats":{"new-dataset":0.0659265481,"dev-research":0.2471617533,"data-quality":0.0769600142}}
{"text":"What is the time complexity of matrix multiplication of sparse integer matrices with $m_{in}$ nonzeros in the input and $m_{out}$ nonzeros in the output?","meta":{"url":"http://arxiv.org/abs/2309.06317v1"},"cats":{"new-dataset":0.0156027902,"dev-research":0.1196365601,"data-quality":0.082220653}}
{"text":"This paper provides improved upper bounds for this question for almost any choice of $m_{in}$ vs. $m_{out}$, and provides evidence that these new bounds might be optimal up to further progress on fast matrix multiplication.   ","meta":{"url":"http://arxiv.org/abs/2309.06317v1"},"cats":{"new-dataset":0.0352995016,"dev-research":0.1412939763,"data-quality":0.0735166892}}
{"text":"Our main contribution is a new algorithm that reduces sparse matrix multiplication to dense (but smaller) rectangular matrix multiplication.","meta":{"url":"http://arxiv.org/abs/2309.06317v1"},"cats":{"new-dataset":0.0135356761,"dev-research":0.1516693812,"data-quality":0.1099258642}}
{"text":"Our running time thus depends on the optimal exponent $\\omega(a,b,c)$ of multiplying dense $n^a\\times n^b$ by $n^b\\times n^c$ matrices.","meta":{"url":"http://arxiv.org/abs/2309.06317v1"},"cats":{"new-dataset":0.0127647859,"dev-research":0.1380023731,"data-quality":0.046922978}}
{"text":"We discover that when $m_{out}=\\Theta(m_{in}^r)$ the time complexity of sparse matrix multiplication is $O(m_{in}^{\\sigma+\\epsilon})$, for all $\\epsilon > 0$, where $\\sigma$ is the solution to the equation $\\omega(\\sigma-1,2-\\sigma,1+r-\\sigma)=\\sigma$. No matter what $\\omega(\\cdot,\\cdot,\\cdot)$ turns out to be, and for all $r\\in(0,2)$, the new bound beats the state of the art, and we provide evidence that it is optimal based on the complexity of the all-edge triangle problem.   ","meta":{"url":"http://arxiv.org/abs/2309.06317v1"},"cats":{"new-dataset":0.0281116819,"dev-research":0.1264423442,"data-quality":0.0847896867}}
{"text":"In particular, in terms of the input plus output size $m = m_{in} + m_{out}$ our algorithm runs in time $O(m^{1.3459})$. Even for Boolean matrices, this improves over the previous $m^{\\frac{2\\omega}{\\omega+1}+\\epsilon}=O(m^{1.4071})$ bound [Amossen, Pagh; 2009], which was a natural barrier since it coincides with the longstanding bound of all-edge triangle in sparse graphs","meta":{"url":"http://arxiv.org/abs/2309.06317v1"},"cats":{"new-dataset":0.011805971,"dev-research":0.1338032228,"data-quality":0.106920448}}
{"text":"[Alon, Yuster, Zwick; 1994].","meta":{"url":"http://arxiv.org/abs/2309.06317v1"},"cats":{"new-dataset":0.6019567717,"dev-research":0.1521697758,"data-quality":0.165197994}}
{"text":"We find it interesting that matrix multiplication can be solved faster than triangle detection in this natural setting.","meta":{"url":"http://arxiv.org/abs/2309.06317v1"},"cats":{"new-dataset":0.0160108808,"dev-research":0.1641283809,"data-quality":0.1107659826}}
{"text":"In fact, we establish an equivalence to a special case of the all-edge triangle problem.","meta":{"url":"http://arxiv.org/abs/2309.06317v1"},"cats":{"new-dataset":0.0470261145,"dev-research":0.1619901178,"data-quality":0.1227435355}}
{"text":"A set of variables is the Markov blanket of a random variable if it contains all the information needed for predicting the variable.","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.1590293139,"dev-research":0.1990376026,"data-quality":0.0833795599}}
{"text":"If the blanket cannot be reduced without losing useful information, it is called a Markov boundary.","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.0355479095,"dev-research":0.1690306298,"data-quality":0.0793346139}}
{"text":"Identifying the Markov boundary of a random variable is advantageous because all variables outside the boundary are superfluous.","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.0162560153,"dev-research":0.1058076916,"data-quality":0.1101005811}}
{"text":"Hence, the Markov boundary provides an optimal feature set.","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.0376223603,"dev-research":0.1398683427,"data-quality":0.1019315322}}
{"text":"However, learning the Markov boundary from data is challenging for two reasons.","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.0520093611,"dev-research":0.1078533284,"data-quality":0.1732638972}}
{"text":"If one or more variables are removed from the Markov boundary, variables outside the boundary may start providing information.","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.0184407725,"dev-research":0.1245180569,"data-quality":0.1294821492}}
{"text":"Conversely, variables within the boundary may stop providing information.","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.0127079386,"dev-research":0.2223301997,"data-quality":0.1764954921}}
{"text":"The true role of each candidate variable is only manifesting when the Markov boundary has been identified.","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.0059022855,"dev-research":0.0844950703,"data-quality":0.1282688442}}
{"text":"In this paper, we propose a new Tsetlin Machine (TM) feedback scheme that supplements Type I and Type II","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.027228345,"dev-research":0.1260419369,"data-quality":0.0902268841}}
{"text":"feedback","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.0773195755,"dev-research":0.2973445574,"data-quality":0.2467557164}}
{"text":".","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.1410976743,"dev-research":0.221336183,"data-quality":0.1351868727}}
{"text":"The scheme introduces a novel Finite State Automaton - a Context-Specific Independence Automaton.","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.0440884747,"dev-research":0.1614378163,"data-quality":0.0777948306}}
{"text":"The automaton learns which features are outside the Markov boundary of the target, allowing them to be pruned from the TM during learning.","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.0228858955,"dev-research":0.1484980311,"data-quality":0.1240725004}}
{"text":"We investigate the new scheme empirically, showing how it is capable of exploiting context-specific independence to find Markov boundaries.","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.0269758699,"dev-research":0.0903993033,"data-quality":0.1043260181}}
{"text":"Further, we provide a theoretical analysis of convergence.","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.0127438829,"dev-research":0.1760134397,"data-quality":0.1063715638}}
{"text":"Our approach thus connects the field of Bayesian networks (BN) with TMs, potentially opening up for synergies when it comes to inference and learning, including TM-produced Bayesian knowledge bases and TM-based Bayesian inference.","meta":{"url":"http://arxiv.org/abs/2309.06315v1"},"cats":{"new-dataset":0.0773398809,"dev-research":0.1868183274,"data-quality":0.1310224564}}
{"text":"It is difficult to perform 3D reconstruction from on-vehicle gathered video due to the large forward motion of the vehicle.","meta":{"url":"http://arxiv.org/abs/2309.06313v1"},"cats":{"new-dataset":0.0284553918,"dev-research":0.1937746657,"data-quality":0.07178057}}
{"text":"Even object detection and human sensing models perform significantly worse on onboard videos when compared to standard benchmarks because objects often appear far away from the camera compared to the standard object detection benchmarks, image quality is often decreased by motion blur and occlusions occur often.","meta":{"url":"http://arxiv.org/abs/2309.06313v1"},"cats":{"new-dataset":0.0564709642,"dev-research":0.2714566859,"data-quality":0.2183146326}}
{"text":"This has led to the popularisation of traffic data-specific benchmarks.","meta":{"url":"http://arxiv.org/abs/2309.06313v1"},"cats":{"new-dataset":0.0568807415,"dev-research":0.1694732117,"data-quality":0.0761869861}}
{"text":"Recently Light Detection","meta":{"url":"http://arxiv.org/abs/2309.06313v1"},"cats":{"new-dataset":0.2399645796,"dev-research":0.2065013499,"data-quality":0.1555515889}}
{"text":"And Ranging (LiDAR) sensors have become popular to directly estimate depths without the need to perform 3D reconstructions.","meta":{"url":"http://arxiv.org/abs/2309.06313v1"},"cats":{"new-dataset":0.0364687699,"dev-research":0.1696989446,"data-quality":0.0590376561}}
{"text":"However, LiDAR-based methods still lack in articulated human detection at a distance when compared to image-based methods.","meta":{"url":"http://arxiv.org/abs/2309.06313v1"},"cats":{"new-dataset":0.0245647083,"dev-research":0.1850155576,"data-quality":0.106777055}}
{"text":"We hypothesize that benchmarks targeted at articulated human sensing from LiDAR data could bring about increased research in human sensing and prediction in traffic and could lead to improved traffic safety for pedestrians.","meta":{"url":"http://arxiv.org/abs/2309.06313v1"},"cats":{"new-dataset":0.2663230919,"dev-research":0.2018671087,"data-quality":0.0743661273}}
{"text":"We introduce FIK, a natural intuitionistic modal logic specified by Kripke models satisfying the condition of forward confluence.","meta":{"url":"http://arxiv.org/abs/2309.06309v1"},"cats":{"new-dataset":0.0330682865,"dev-research":0.2025168668,"data-quality":0.1022589737}}
{"text":"We give a complete Hilbert-style axiomatization of this logic and propose a bi-nested calculus for it.","meta":{"url":"http://arxiv.org/abs/2309.06309v1"},"cats":{"new-dataset":0.0331077596,"dev-research":0.2067943011,"data-quality":0.0937636232}}
{"text":"The calculus provides a decision procedure as well as a countermodel extraction: from any failed derivation of a given formula, we obtain by the calculus a finite countermodel of it.","meta":{"url":"http://arxiv.org/abs/2309.06309v1"},"cats":{"new-dataset":0.0208099587,"dev-research":0.2757797097,"data-quality":0.1643344495}}
{"text":"Nowadays millions of images are shared on social media and web platforms.","meta":{"url":"http://arxiv.org/abs/2309.06308v1"},"cats":{"new-dataset":0.3134183082,"dev-research":0.1762326367,"data-quality":0.1429784319}}
{"text":"In particular, many of them are food images taken from a smartphone over time, providing information related to the individual's diet.","meta":{"url":"http://arxiv.org/abs/2309.06308v1"},"cats":{"new-dataset":0.2120705117,"dev-research":0.1634543288,"data-quality":0.0890562555}}
{"text":"On the other hand, eating behaviours are directly related to some of the most prevalent diseases in the world.","meta":{"url":"http://arxiv.org/abs/2309.06308v1"},"cats":{"new-dataset":0.0184187135,"dev-research":0.2191160043,"data-quality":0.0931574515}}
{"text":"Exploiting recent advances in image processing and Artificial Intelligence (AI), this scenario represents an excellent opportunity to: i) create new methods that analyse the individuals' health from what they eat, and ii) develop personalised recommendations to improve nutrition and diet under specific circumstances (e.g., obesity or COVID).","meta":{"url":"http://arxiv.org/abs/2309.06308v1"},"cats":{"new-dataset":0.0948917589,"dev-research":0.2184675397,"data-quality":0.0902830713}}
{"text":"Having tunable tools for creating food image datasets that facilitate research in both lines is very much needed.   ","meta":{"url":"http://arxiv.org/abs/2309.06308v1"},"cats":{"new-dataset":0.2755444526,"dev-research":0.155470652,"data-quality":0.1249235681}}
{"text":"This paper proposes AI4Food-NutritionFW, a framework for the creation of food image datasets according to configurable eating behaviours.","meta":{"url":"http://arxiv.org/abs/2309.06308v1"},"cats":{"new-dataset":0.5036845683,"dev-research":0.1292545222,"data-quality":0.1361784642}}
{"text":"AI4Food-NutritionFW simulates a user-friendly and widespread scenario where images are taken using a smartphone.","meta":{"url":"http://arxiv.org/abs/2309.06308v1"},"cats":{"new-dataset":0.2314180299,"dev-research":0.1342479234,"data-quality":0.109858627}}
{"text":"In addition to the framework, we also provide and describe a unique food image dataset that includes 4,800 different weekly eating behaviours from 15 different profiles and 1,200 subjects.","meta":{"url":"http://arxiv.org/abs/2309.06308v1"},"cats":{"new-dataset":0.7255988486,"dev-research":0.115090076,"data-quality":0.0943038933}}
{"text":"Specifically, we consider profiles that comply with actual lifestyles from healthy eating behaviours (according to established knowledge), variable profiles (e.g., eating out, holidays), to unhealthy ones (e.g., excess of fast food or sweets).","meta":{"url":"http://arxiv.org/abs/2309.06308v1"},"cats":{"new-dataset":0.0486266434,"dev-research":0.2500392117,"data-quality":0.1027703285}}
{"text":"Finally, we automatically evaluate a healthy index of the subject's eating behaviours using multidimensional metrics based on guidelines for healthy diets proposed by international organisations, achieving promising results (99.53% and 99.60% accuracy and sensitivity, respectively).","meta":{"url":"http://arxiv.org/abs/2309.06308v1"},"cats":{"new-dataset":0.0837835322,"dev-research":0.1927756339,"data-quality":0.1131892663}}
{"text":"We also release to the research community a software implementation of our proposed AI4Food-NutritionFW and the mentioned food image dataset created with it.","meta":{"url":"http://arxiv.org/abs/2309.06308v1"},"cats":{"new-dataset":0.6268297543,"dev-research":0.1287150228,"data-quality":0.136279256}}
{"text":"In this paper, we introduce CDL, a software library designed for the analysis of permutations and linear orders subject to various structural restrictions.","meta":{"url":"http://arxiv.org/abs/2309.06306v1"},"cats":{"new-dataset":0.2673340242,"dev-research":0.1829364844,"data-quality":0.1068376994}}
{"text":"Prominent examples of these restrictions include pattern avoidance, a topic of interest in both computer science and combinatorics, and \"never conditions\" utilized in social choice and voting theory.   ","meta":{"url":"http://arxiv.org/abs/2309.06306v1"},"cats":{"new-dataset":0.0047676269,"dev-research":0.2475896093,"data-quality":0.0801367188}}
{"text":"CDL offers a range of fundamental functionalities, including identifying the permutations that meet specific restrictions and determining the isomorphism of such sets.","meta":{"url":"http://arxiv.org/abs/2309.06306v1"},"cats":{"new-dataset":0.0601765354,"dev-research":0.1552843128,"data-quality":0.0853960405}}
{"text":"To facilitate exploration across extensive domains, CDL incorporates multiple search strategies and heuristics.","meta":{"url":"http://arxiv.org/abs/2309.06306v1"},"cats":{"new-dataset":0.0188070543,"dev-research":0.2207082101,"data-quality":0.0570284254}}
{"text":"This paper aims to remove specular highlights from a single object-level image.","meta":{"url":"http://arxiv.org/abs/2309.06302v1"},"cats":{"new-dataset":0.1229650868,"dev-research":0.1899297847,"data-quality":0.1926483676}}
{"text":"Although previous methods have made some progresses, their performance remains somewhat limited, particularly for real images with complex specular highlights.","meta":{"url":"http://arxiv.org/abs/2309.06302v1"},"cats":{"new-dataset":0.0518871712,"dev-research":0.1661801876,"data-quality":0.1434084936}}
{"text":"To this end, we propose a three-stage network to address them.","meta":{"url":"http://arxiv.org/abs/2309.06302v1"},"cats":{"new-dataset":0.129631982,"dev-research":0.1590477757,"data-quality":0.105946404}}
{"text":"Specifically, given an input image, we first decompose it into the albedo, shading, and specular residue components to estimate a coarse specular-free image.","meta":{"url":"http://arxiv.org/abs/2309.06302v1"},"cats":{"new-dataset":0.0923000267,"dev-research":0.1140899217,"data-quality":0.1073322949}}
{"text":"Then, we further refine the coarse result to alleviate its visual artifacts such as color distortion.","meta":{"url":"http://arxiv.org/abs/2309.06302v1"},"cats":{"new-dataset":0.0075593775,"dev-research":0.2108968629,"data-quality":0.2493794814}}
{"text":"Finally, we adjust the tone of the refined result to match that of the input as closely as possible.","meta":{"url":"http://arxiv.org/abs/2309.06302v1"},"cats":{"new-dataset":0.0301966765,"dev-research":0.1651556287,"data-quality":0.3308933026}}
{"text":"In addition, to facilitate network training and quantitative evaluation, we present a large-scale synthetic dataset of object-level images, covering diverse objects and illumination conditions.","meta":{"url":"http://arxiv.org/abs/2309.06302v1"},"cats":{"new-dataset":0.7541412129,"dev-research":0.1434278128,"data-quality":0.1105039331}}
{"text":"Extensive experiments illustrate that our network is able to generalize well to unseen real object-level images, and even produce good results for scene-level images with multiple background objects and complex lighting.","meta":{"url":"http://arxiv.org/abs/2309.06302v1"},"cats":{"new-dataset":0.0838194254,"dev-research":0.1477276931,"data-quality":0.1404835784}}
{"text":"The Harrisonburg Department of Public Transportation (HDPT) aims to leverage their data to improve the efficiency and effectiveness of their operations.","meta":{"url":"http://arxiv.org/abs/2309.06299v1"},"cats":{"new-dataset":0.1007761282,"dev-research":0.243984681,"data-quality":0.1118034486}}
{"text":"We construct two supply and demand models that help the department identify gaps in their service.","meta":{"url":"http://arxiv.org/abs/2309.06299v1"},"cats":{"new-dataset":0.0858571674,"dev-research":0.1659009823,"data-quality":0.1458150468}}
{"text":"The models take many variables into account, including the way that the HDPT reports to the federal government and the areas with the most vulnerable populations in Harrisonburg City.","meta":{"url":"http://arxiv.org/abs/2309.06299v1"},"cats":{"new-dataset":0.1126674002,"dev-research":0.2184348629,"data-quality":0.0831110965}}
{"text":"We employ data analysis and machine learning techniques to make our predictions.","meta":{"url":"http://arxiv.org/abs/2309.06299v1"},"cats":{"new-dataset":0.0692002458,"dev-research":0.275417656,"data-quality":0.1276640195}}
{"text":"Self-training allows a network to learn from the predictions of a more complicated model, thus often requires well-trained teacher models and mixture of teacher-student data while multi-task learning jointly optimizes different targets to learn salient interrelationship and requires multi-task annotations for each training example.","meta":{"url":"http://arxiv.org/abs/2309.06288v1"},"cats":{"new-dataset":0.0330123435,"dev-research":0.1605317188,"data-quality":0.1383060189}}
{"text":"These frameworks, despite being particularly data demanding have potentials for data exploitation if such assumptions can be relaxed.","meta":{"url":"http://arxiv.org/abs/2309.06288v1"},"cats":{"new-dataset":0.0502405815,"dev-research":0.1677813546,"data-quality":0.1384478175}}
{"text":"In this paper, we compare self-training object detection under the deficiency of teacher training data where students are trained on unseen examples by the teacher, and multi-task learning with partially annotated data, i.e. single-task annotation per training example.","meta":{"url":"http://arxiv.org/abs/2309.06288v1"},"cats":{"new-dataset":0.1232627394,"dev-research":0.1524889569,"data-quality":0.4322084564}}
{"text":"Both scenarios have their own limitation but potentially helpful with limited annotated data.","meta":{"url":"http://arxiv.org/abs/2309.06288v1"},"cats":{"new-dataset":0.0228237872,"dev-research":0.1711526167,"data-quality":0.1266548433}}
{"text":"Experimental results show the improvement of performance when using a weak teacher with unseen data for training a multi-task student.","meta":{"url":"http://arxiv.org/abs/2309.06288v1"},"cats":{"new-dataset":0.0190122718,"dev-research":0.1711006633,"data-quality":0.161142546}}
{"text":"Despite the limited setup we believe the experimental results show the potential of multi-task knowledge distillation and self-training, which could be beneficial for future study.","meta":{"url":"http://arxiv.org/abs/2309.06288v1"},"cats":{"new-dataset":0.0160199118,"dev-research":0.170178469,"data-quality":0.0811051063}}
{"text":"Source code is at https://lhoangan.github.io/multas.","meta":{"url":"http://arxiv.org/abs/2309.06288v1"},"cats":{"new-dataset":0.2853862319,"dev-research":0.1949301311,"data-quality":0.1123241886}}
{"text":"Data-driven research in Additive Manufacturing (AM) has gained significant success in recent years.","meta":{"url":"http://arxiv.org/abs/2309.06286v1"},"cats":{"new-dataset":0.0569653339,"dev-research":0.2432569902,"data-quality":0.0821751874}}
{"text":"This has led to a plethora of scientific literature to emerge.","meta":{"url":"http://arxiv.org/abs/2309.06286v1"},"cats":{"new-dataset":0.0827461394,"dev-research":0.184725986,"data-quality":0.1011374404}}
{"text":"The knowledge in these works consists of AM and Artificial Intelligence (AI) contexts that have not been mined and formalized in an integrated way.","meta":{"url":"http://arxiv.org/abs/2309.06286v1"},"cats":{"new-dataset":0.058592154,"dev-research":0.2218624902,"data-quality":0.125446973}}
{"text":"Moreover, no tools or guidelines exist to support data-driven knowledge transfer from one context to another.","meta":{"url":"http://arxiv.org/abs/2309.06286v1"},"cats":{"new-dataset":0.0661545559,"dev-research":0.2493373374,"data-quality":0.1206563972}}
{"text":"As a result, data-driven solutions using specific AI techniques are being developed and validated only for specific AM process technologies.","meta":{"url":"http://arxiv.org/abs/2309.06286v1"},"cats":{"new-dataset":0.0176168089,"dev-research":0.2781795769,"data-quality":0.1092641763}}
{"text":"There is a potential to exploit the inherent similarities across various AM technologies and adapt the existing solutions from one process or problem to another using AI, such as Transfer Learning.","meta":{"url":"http://arxiv.org/abs/2309.06286v1"},"cats":{"new-dataset":0.0080059931,"dev-research":0.1834862313,"data-quality":0.0899325321}}
{"text":"We propose a three-step knowledge transferability analysis framework in AM to support data-driven AM knowledge transfer.","meta":{"url":"http://arxiv.org/abs/2309.06286v1"},"cats":{"new-dataset":0.0819606291,"dev-research":0.2662608569,"data-quality":0.1187005553}}
{"text":"As a prerequisite to transferability analysis, AM knowledge is featurized into identified knowledge components.","meta":{"url":"http://arxiv.org/abs/2309.06286v1"},"cats":{"new-dataset":0.0288641296,"dev-research":0.1703090822,"data-quality":0.1011245054}}
{"text":"The framework consists of pre-transfer, transfer, and post-transfer steps to accomplish knowledge transfer.","meta":{"url":"http://arxiv.org/abs/2309.06286v1"},"cats":{"new-dataset":0.1360332337,"dev-research":0.2435333229,"data-quality":0.0732640565}}
{"text":"A case study is conducted between flagship metal AM processes.","meta":{"url":"http://arxiv.org/abs/2309.06286v1"},"cats":{"new-dataset":0.0157480285,"dev-research":0.1676157775,"data-quality":0.1113091248}}
{"text":"Laser Powder Bed Fusion (LPBF) is the source of knowledge motivated by its relative matureness in applying AI over Directed Energy Deposition (DED), which drives the need for knowledge transfer as the less explored target process.","meta":{"url":"http://arxiv.org/abs/2309.06286v1"},"cats":{"new-dataset":0.0188890386,"dev-research":0.2154072521,"data-quality":0.1080681177}}
{"text":"We show successful transfer at different levels of the data-driven solution, including data representation, model architecture, and model parameters.","meta":{"url":"http://arxiv.org/abs/2309.06286v1"},"cats":{"new-dataset":0.062767411,"dev-research":0.1896090371,"data-quality":0.0958972179}}
{"text":"The pipeline of AM knowledge transfer can be automated in the future to allow efficient cross-context or cross-process knowledge exchange.","meta":{"url":"http://arxiv.org/abs/2309.06286v1"},"cats":{"new-dataset":0.0341387354,"dev-research":0.2242107511,"data-quality":0.0820091793}}
{"text":"Player identification is a crucial component in vision-driven soccer analytics, enabling various downstream tasks such as player assessment, in-game analysis, and broadcast production.","meta":{"url":"http://arxiv.org/abs/2309.06285v1"},"cats":{"new-dataset":0.2346953607,"dev-research":0.2745727181,"data-quality":0.125472618}}
{"text":"However, automatically detecting jersey numbers from player tracklets in videos presents challenges due to motion blur, low resolution, distortions, and occlusions.","meta":{"url":"http://arxiv.org/abs/2309.06285v1"},"cats":{"new-dataset":0.1179067179,"dev-research":0.2183557038,"data-quality":0.3137577772}}
{"text":"Existing methods, utilizing Spatial Transformer Networks, CNNs, and Vision Transformers, have shown success in image data but struggle with real-world video data, where jersey numbers are not visible in most of the frames.","meta":{"url":"http://arxiv.org/abs/2309.06285v1"},"cats":{"new-dataset":0.2307515109,"dev-research":0.1301303406,"data-quality":0.1428693691}}
{"text":"Hence, identifying frames that contain the jersey number is a key sub-problem to tackle.","meta":{"url":"http://arxiv.org/abs/2309.06285v1"},"cats":{"new-dataset":0.1229123041,"dev-research":0.1803260051,"data-quality":0.2458331876}}
{"text":"To address these issues, we propose a robust keyframe identification module that extracts frames containing essential high-level information about the jersey number.","meta":{"url":"http://arxiv.org/abs/2309.06285v1"},"cats":{"new-dataset":0.4724396193,"dev-research":0.1741677491,"data-quality":0.2389489698}}
{"text":"A spatio-temporal network is then employed to model spatial and temporal context and predict the probabilities of jersey numbers in the video.","meta":{"url":"http://arxiv.org/abs/2309.06285v1"},"cats":{"new-dataset":0.1826274983,"dev-research":0.1857004634,"data-quality":0.1062082739}}
{"text":"Additionally, we adopt a multi-task loss function to predict the probability distribution of each digit separately.","meta":{"url":"http://arxiv.org/abs/2309.06285v1"},"cats":{"new-dataset":0.0475456256,"dev-research":0.1521389525,"data-quality":0.186232867}}
{"text":"Extensive evaluations on the SoccerNet dataset demonstrate that incorporating our proposed keyframe identification module results in a significant 37.81% and 37.70% increase in the accuracies of 2 different test sets with domain gaps.","meta":{"url":"http://arxiv.org/abs/2309.06285v1"},"cats":{"new-dataset":0.5995933029,"dev-research":0.2367544317,"data-quality":0.2373599878}}
{"text":"These results highlight the effectiveness and importance of our approach in tackling the challenges of automatic jersey number detection in sports videos.","meta":{"url":"http://arxiv.org/abs/2309.06285v1"},"cats":{"new-dataset":0.1113045559,"dev-research":0.2116363287,"data-quality":0.26152056}}
{"text":"Text-driven human motion generation in computer vision is both significant and challenging.","meta":{"url":"http://arxiv.org/abs/2309.06284v1"},"cats":{"new-dataset":0.2102822985,"dev-research":0.2677477851,"data-quality":0.1020729271}}
{"text":"However, current methods are limited to producing either deterministic or imprecise motion sequences, failing to effectively control the temporal and spatial relationships required to conform to a given text description.","meta":{"url":"http://arxiv.org/abs/2309.06284v1"},"cats":{"new-dataset":0.0331035902,"dev-research":0.2290194898,"data-quality":0.1006938171}}
{"text":"In this work, we propose a fine-grained method for generating high-quality, conditional human motion sequences supporting precise text description.","meta":{"url":"http://arxiv.org/abs/2309.06284v1"},"cats":{"new-dataset":0.4273302934,"dev-research":0.2229276434,"data-quality":0.1567820585}}
{"text":"Our approach consists of two key components: 1) a linguistics-structure assisted module that constructs accurate and complete language feature to fully utilize text information; and 2) a context-aware progressive reasoning module that learns neighborhood and overall semantic linguistics features from shallow and deep graph neural networks to achieve a multi-step inference.","meta":{"url":"http://arxiv.org/abs/2309.06284v1"},"cats":{"new-dataset":0.3038234139,"dev-research":0.2303848906,"data-quality":0.2383803025}}
{"text":"Experiments show that our approach outperforms text-driven motion generation methods on HumanML3D and KIT test sets and generates better visually confirmed motion to the text conditions.","meta":{"url":"http://arxiv.org/abs/2309.06284v1"},"cats":{"new-dataset":0.3767902017,"dev-research":0.3123127777,"data-quality":0.1098437181}}
{"text":"Domain generalized semantic segmentation (DGSS) is a critical yet challenging task, where the model is trained only on source data without access to any target data.","meta":{"url":"http://arxiv.org/abs/2309.06282v1"},"cats":{"new-dataset":0.2544643855,"dev-research":0.1528939563,"data-quality":0.2247853783}}
{"text":"Despite the proposal of numerous DGSS strategies, the generalization capability remains limited in CNN architectures.","meta":{"url":"http://arxiv.org/abs/2309.06282v1"},"cats":{"new-dataset":0.0059522149,"dev-research":0.1279373355,"data-quality":0.0963090256}}
{"text":"Though some Transformer-based segmentation models show promising performance, they primarily focus on capturing intra-sample attentive relationships, disregarding inter-sample correlations which can potentially benefit DGSS.","meta":{"url":"http://arxiv.org/abs/2309.06282v1"},"cats":{"new-dataset":0.0650875421,"dev-research":0.1141334146,"data-quality":0.1556767328}}
{"text":"To this end, we enhance the attention modules in Transformer networks for improving DGSS by incorporating information from other independent samples in the same batch, enriching contextual information, and diversifying the training data for each attention block.","meta":{"url":"http://arxiv.org/abs/2309.06282v1"},"cats":{"new-dataset":0.1505344179,"dev-research":0.1617040016,"data-quality":0.1545430941}}
{"text":"Specifically, we propose two alternative intra-batch attention mechanisms, namely mean-based intra-batch attention (MIBA) and element-wise intra-batch attention (EIBA), to capture correlations between different samples, enhancing feature representation and generalization capabilities.","meta":{"url":"http://arxiv.org/abs/2309.06282v1"},"cats":{"new-dataset":0.0578122141,"dev-research":0.1547370962,"data-quality":0.1596946197}}
{"text":"Building upon intra-batch attention, we introduce IBAFormer, which integrates self-attention modules with the proposed intra-batch attention for DGSS.","meta":{"url":"http://arxiv.org/abs/2309.06282v1"},"cats":{"new-dataset":0.1022120464,"dev-research":0.1674186436,"data-quality":0.1980201695}}
{"text":"Extensive experiments demonstrate that IBAFormer achieves SOTA performance in DGSS, and ablation studies further confirm the effectiveness of each introduced component.","meta":{"url":"http://arxiv.org/abs/2309.06282v1"},"cats":{"new-dataset":0.0142419383,"dev-research":0.1342547093,"data-quality":0.1118019834}}
{"text":"The development of quantum computers has been advancing rapidly in recent years.","meta":{"url":"http://arxiv.org/abs/2309.06281v1"},"cats":{"new-dataset":0.0318717046,"dev-research":0.218108885,"data-quality":0.0306592154}}
{"text":"As quantum computers become more widely accessible, potentially malicious users could try to execute their code on the machines to leak information from other users, to interfere with or manipulate the results of other users, or to reverse engineer the underlying quantum computer architecture and its intellectual property, for example.","meta":{"url":"http://arxiv.org/abs/2309.06281v1"},"cats":{"new-dataset":0.0080153373,"dev-research":0.2806982306,"data-quality":0.0999883445}}
{"text":"Among different security threats, previous work has demonstrated information leakage across the reset operations, and it then proposed a secure reset operation could be an enabling technology that allows the sharing of a quantum computer among different users, or among different quantum programs of the same user.","meta":{"url":"http://arxiv.org/abs/2309.06281v1"},"cats":{"new-dataset":0.0108687761,"dev-research":0.2580537647,"data-quality":0.1018816638}}
{"text":"This work first shows a set of new, extended reset operation attacks that could be more stealthy by hiding the intention of the attacker's circuit.","meta":{"url":"http://arxiv.org/abs/2309.06281v1"},"cats":{"new-dataset":0.020241731,"dev-research":0.1943939591,"data-quality":0.1925514445}}
{"text":"This work shows various masking circuits and how attackers can retrieve information from the execution of a previous shot of a circuit, even if the masking circuit is used between the reset operation (of the victim, after the shot of the circuit is executed) and the measurement (of the attacker).","meta":{"url":"http://arxiv.org/abs/2309.06281v1"},"cats":{"new-dataset":0.0283095769,"dev-research":0.2186841735,"data-quality":0.1624177207}}
{"text":"Based on the uncovered new possible attacks, this work proposes a set of heuristic checks that could be applied at transpile time to check for the existence of malicious circuits that try to steal information via the attack on the reset operation.","meta":{"url":"http://arxiv.org/abs/2309.06281v1"},"cats":{"new-dataset":0.0333697586,"dev-research":0.3426091041,"data-quality":0.1434746802}}
{"text":"Unlike run-time protection or added secure reset gates, this work proposes a complimentary, compile-time security solution to the attacks on reset~operation.","meta":{"url":"http://arxiv.org/abs/2309.06281v1"},"cats":{"new-dataset":0.0357137516,"dev-research":0.3938913374,"data-quality":0.1113298175}}
{"text":"Temporal action segmentation is typically achieved by discovering the dramatic variances in global visual descriptors.","meta":{"url":"http://arxiv.org/abs/2309.06276v1"},"cats":{"new-dataset":0.1838710932,"dev-research":0.1780679558,"data-quality":0.1165975647}}
{"text":"In this paper, we explore the merits of local features by proposing the unsupervised framework of Object-centric Temporal Action Segmentation (OTAS).","meta":{"url":"http://arxiv.org/abs/2309.06276v1"},"cats":{"new-dataset":0.302298249,"dev-research":0.1608962603,"data-quality":0.1440234398}}
{"text":"Broadly speaking, OTAS consists of self-supervised global and local feature extraction modules as well as a boundary selection module that fuses the features and detects salient boundaries for action segmentation.","meta":{"url":"http://arxiv.org/abs/2309.06276v1"},"cats":{"new-dataset":0.1798753295,"dev-research":0.1698181766,"data-quality":0.1364060911}}
{"text":"As a second contribution, we discuss the pros and cons of existing frame-level and boundary-level evaluation metrics.","meta":{"url":"http://arxiv.org/abs/2309.06276v1"},"cats":{"new-dataset":0.0389206506,"dev-research":0.1829092819,"data-quality":0.1388915285}}
{"text":"Through extensive experiments, we find OTAS is superior to the previous state-of-the-art method by $41\\%$ on average in terms of our recommended F1 score.","meta":{"url":"http://arxiv.org/abs/2309.06276v1"},"cats":{"new-dataset":0.0179200844,"dev-research":0.1516682644,"data-quality":0.1360335167}}
{"text":"Surprisingly, OTAS even outperforms the ground-truth human annotations in the user study.","meta":{"url":"http://arxiv.org/abs/2309.06276v1"},"cats":{"new-dataset":0.1528016738,"dev-research":0.2558743688,"data-quality":0.4008355805}}
{"text":"Moreover, OTAS is efficient enough to allow real-time inference.","meta":{"url":"http://arxiv.org/abs/2309.06276v1"},"cats":{"new-dataset":0.015559346,"dev-research":0.1485615136,"data-quality":0.0690355768}}
{"text":"Reasoning presents a significant and challenging issue for Large Language Models (LLMs).","meta":{"url":"http://arxiv.org/abs/2309.06275v1"},"cats":{"new-dataset":0.1168496731,"dev-research":0.1634509915,"data-quality":0.2124174555}}
{"text":"The predominant focus of research has revolved around developing diverse prompting strategies to guide and structure the reasoning processes of LLMs.","meta":{"url":"http://arxiv.org/abs/2309.06275v1"},"cats":{"new-dataset":0.015035849,"dev-research":0.2313930887,"data-quality":0.0636896463}}
{"text":"However, these approaches based on decoder-only causal language models often operate the input question in a single forward pass, potentially missing the rich, back-and-forth interactions inherent in human reasoning.","meta":{"url":"http://arxiv.org/abs/2309.06275v1"},"cats":{"new-dataset":0.0182978871,"dev-research":0.25831915,"data-quality":0.1490291318}}
{"text":"Scant attention has been paid to a critical dimension, i.e., the input question itself embedded within the prompts.","meta":{"url":"http://arxiv.org/abs/2309.06275v1"},"cats":{"new-dataset":0.0476061876,"dev-research":0.2611796132,"data-quality":0.2105284634}}
{"text":"In response, we introduce a deceptively simple yet highly effective prompting strategy, termed question \"re-reading\".","meta":{"url":"http://arxiv.org/abs/2309.06275v1"},"cats":{"new-dataset":0.0167723444,"dev-research":0.3216684281,"data-quality":0.1994113887}}
{"text":"Drawing inspiration from human learning and problem-solving, re-reading entails revisiting the question information embedded within input prompts.","meta":{"url":"http://arxiv.org/abs/2309.06275v1"},"cats":{"new-dataset":0.0780187179,"dev-research":0.3724488518,"data-quality":0.1714703352}}
{"text":"This approach aligns seamlessly with the cognitive principle of reinforcement, enabling LLMs to extract deeper insights, identify intricate patterns, establish more nuanced connections, and ultimately enhance their reasoning capabilities across various tasks.","meta":{"url":"http://arxiv.org/abs/2309.06275v1"},"cats":{"new-dataset":0.0239314514,"dev-research":0.2520019284,"data-quality":0.0746501916}}
{"text":"Experiments conducted on a series of reasoning benchmarks serve to underscore the effectiveness and generality of our method.","meta":{"url":"http://arxiv.org/abs/2309.06275v1"},"cats":{"new-dataset":0.0148692627,"dev-research":0.3020656905,"data-quality":0.1532134978}}
{"text":"Moreover, our findings demonstrate that our approach seamlessly integrates with various language models, though-eliciting prompting methods, and ensemble techniques, further underscoring its versatility and compatibility in the realm of LLMs.","meta":{"url":"http://arxiv.org/abs/2309.06275v1"},"cats":{"new-dataset":0.0657777112,"dev-research":0.2304946454,"data-quality":0.2538771588}}
{"text":"We present a novel, fast (exponential rate adaption), ab initio (hyper-parameter-free) gradient based optimizer algorithm.","meta":{"url":"http://arxiv.org/abs/2309.06274v1"},"cats":{"new-dataset":0.0071662975,"dev-research":0.1088400286,"data-quality":0.0639607163}}
{"text":"The main idea of the method is to adapt the learning rate $\\alpha$ by situational awareness, mainly striving for orthogonal neighboring gradients.","meta":{"url":"http://arxiv.org/abs/2309.06274v1"},"cats":{"new-dataset":0.0081733707,"dev-research":0.1075243043,"data-quality":0.0957527837}}
{"text":"The method has a high success and fast convergence rate and does not rely on hand-tuned parameters giving it greater universality.","meta":{"url":"http://arxiv.org/abs/2309.06274v1"},"cats":{"new-dataset":0.0012008905,"dev-research":0.0847237163,"data-quality":0.0874117564}}
{"text":"It can be applied to problems of any dimensions n and scales only linearly (of order O(n)) with the dimension of the problem.","meta":{"url":"http://arxiv.org/abs/2309.06274v1"},"cats":{"new-dataset":0.0062736749,"dev-research":0.1374674297,"data-quality":0.0823886267}}
{"text":"It optimizes convex and non-convex continuous landscapes providing some kind of gradient.","meta":{"url":"http://arxiv.org/abs/2309.06274v1"},"cats":{"new-dataset":0.0015605739,"dev-research":0.1823024769,"data-quality":0.0486032358}}
{"text":"In contrast to the Ada-family (AdaGrad, AdaMax, AdaDelta, Adam, etc.)","meta":{"url":"http://arxiv.org/abs/2309.06274v1"},"cats":{"new-dataset":0.0923325521,"dev-research":0.2183397208,"data-quality":0.1727232339}}
{"text":"the method is rotation invariant: optimization path and performance are independent of coordinate choices.","meta":{"url":"http://arxiv.org/abs/2309.06274v1"},"cats":{"new-dataset":0.0015957348,"dev-research":0.1391265563,"data-quality":0.0632728977}}
{"text":"The impressive performance is demonstrated by extensive experiments on the MNIST benchmark data-set against state-of-the-art optimizers.","meta":{"url":"http://arxiv.org/abs/2309.06274v1"},"cats":{"new-dataset":0.0294710495,"dev-research":0.1616536595,"data-quality":0.0997040637}}
{"text":"We name this new class of optimizers after its core idea Exponential Learning Rate Adaption - ELRA.","meta":{"url":"http://arxiv.org/abs/2309.06274v1"},"cats":{"new-dataset":0.0131179704,"dev-research":0.1221678611,"data-quality":0.1083408675}}
{"text":"We present it in two variants c2min and p2min with slightly different control.","meta":{"url":"http://arxiv.org/abs/2309.06274v1"},"cats":{"new-dataset":0.0665085502,"dev-research":0.1566607428,"data-quality":0.1036258194}}
{"text":"The authors strongly believe that ELRA will open a completely new research direction for gradient descent optimize.","meta":{"url":"http://arxiv.org/abs/2309.06274v1"},"cats":{"new-dataset":0.005348892,"dev-research":0.15255131,"data-quality":0.0910983841}}
{"text":"Variable-to-variable length (VV) codes are a class of lossless source coding.","meta":{"url":"http://arxiv.org/abs/2309.06267v1"},"cats":{"new-dataset":0.087499209,"dev-research":0.254405502,"data-quality":0.2018420968}}
{"text":"As their name implies, VV codes encode a variable-length sequence of source symbols into a variable-length codeword.","meta":{"url":"http://arxiv.org/abs/2309.06267v1"},"cats":{"new-dataset":0.1534368808,"dev-research":0.3077198632,"data-quality":0.2383137548}}
{"text":"This paper will give a complete proof of an important theorem for variable-to-variable length codes.","meta":{"url":"http://arxiv.org/abs/2309.06267v1"},"cats":{"new-dataset":0.1097782541,"dev-research":0.1932559649,"data-quality":0.1597108967}}
{"text":"Location data privacy has become a serious concern for users as Location Based Services (LBSs) have become an important part of their life.","meta":{"url":"http://arxiv.org/abs/2309.06263v1"},"cats":{"new-dataset":0.0465241884,"dev-research":0.1795624779,"data-quality":0.1197225914}}
{"text":"It is possible for malicious parties having access to geolocation data to learn sensitive information about the user such as religion or political views.","meta":{"url":"http://arxiv.org/abs/2309.06263v1"},"cats":{"new-dataset":0.06271173,"dev-research":0.2013799357,"data-quality":0.1882593385}}
{"text":"Location Privacy Preserving Mechanisms (LPPMs) have been proposed by previous works to ensure the privacy of the shared data while allowing the users to use LBSs.","meta":{"url":"http://arxiv.org/abs/2309.06263v1"},"cats":{"new-dataset":0.0409684475,"dev-research":0.1303537248,"data-quality":0.1132924944}}
{"text":"But there is no clear view of which mechanism to use according to the scenario in which the user makes use of a LBS.","meta":{"url":"http://arxiv.org/abs/2309.06263v1"},"cats":{"new-dataset":0.0008242014,"dev-research":0.159073155,"data-quality":0.0911618036}}
{"text":"The scenario is the way the user is using a LBS (frequency of reports, number of reports).","meta":{"url":"http://arxiv.org/abs/2309.06263v1"},"cats":{"new-dataset":0.0111213269,"dev-research":0.2394182598,"data-quality":0.1119398715}}
{"text":"In this paper, we study the sensitivity of LPPMs on the scenario on which they are used.","meta":{"url":"http://arxiv.org/abs/2309.06263v1"},"cats":{"new-dataset":0.0089393551,"dev-research":0.1076597594,"data-quality":0.1364719777}}
{"text":"We propose a framework to systematically evaluate LPPMs by considering an exhaustive combination of LPPMs, attacks and metrics.","meta":{"url":"http://arxiv.org/abs/2309.06263v1"},"cats":{"new-dataset":0.0234224616,"dev-research":0.1507447931,"data-quality":0.1498899028}}
{"text":"Using our framework we compare a selection of LPPMs including an improved mechanism that we introduce.","meta":{"url":"http://arxiv.org/abs/2309.06263v1"},"cats":{"new-dataset":0.00654435,"dev-research":0.1142906541,"data-quality":0.0931571251}}
{"text":"By evaluating over a variety of scenarios, we find that the efficacy (privacy, utility, and robustness) of the studied mechanisms is dependent on the scenario: for example the privacy of Planar Laplace geo-indistinguishability is greatly reduced in a continuous scenario.","meta":{"url":"http://arxiv.org/abs/2309.06263v1"},"cats":{"new-dataset":0.0114733876,"dev-research":0.1257371112,"data-quality":0.0953002474}}
{"text":"We show that the scenario is essential to consider when choosing an obfuscation mechanism for a given application.","meta":{"url":"http://arxiv.org/abs/2309.06263v1"},"cats":{"new-dataset":0.0070412151,"dev-research":0.234502808,"data-quality":0.2270491829}}
{"text":"Visible-infrared person re-identification (VI-ReID) is a challenging task due to large cross-modality discrepancies and intra-class variations.","meta":{"url":"http://arxiv.org/abs/2309.06262v1"},"cats":{"new-dataset":0.1187415506,"dev-research":0.1670024631,"data-quality":0.1261183701}}
{"text":"Existing methods mainly focus on learning modality-shared representations by embedding different modalities into the same feature space.","meta":{"url":"http://arxiv.org/abs/2309.06262v1"},"cats":{"new-dataset":0.0224511723,"dev-research":0.1590408202,"data-quality":0.2295091738}}
{"text":"As a result, the learned feature emphasizes the common patterns across modalities while suppressing modality-specific and identity-aware information that is valuable for Re-ID.","meta":{"url":"http://arxiv.org/abs/2309.06262v1"},"cats":{"new-dataset":0.0333133445,"dev-research":0.2059910039,"data-quality":0.3129200255}}
{"text":"To address these issues, we propose a novel Modality Unifying Network (MUN) to explore a robust auxiliary modality for VI-ReID.","meta":{"url":"http://arxiv.org/abs/2309.06262v1"},"cats":{"new-dataset":0.0257160519,"dev-research":0.1255234094,"data-quality":0.2273586396}}
{"text":"First, the auxiliary modality is generated by combining the proposed cross-modality learner and intra-modality learner, which can dynamically model the modality-specific and modality-shared representations to alleviate both cross-modality and intra-modality variations.","meta":{"url":"http://arxiv.org/abs/2309.06262v1"},"cats":{"new-dataset":0.0399681466,"dev-research":0.1500982778,"data-quality":0.1613836323}}
{"text":"Second, by aligning identity centres across the three modalities, an identity alignment loss function is proposed to discover the discriminative feature representations.","meta":{"url":"http://arxiv.org/abs/2309.06262v1"},"cats":{"new-dataset":0.0263385356,"dev-research":0.1391496402,"data-quality":0.3265418696}}
{"text":"Third, a modality alignment loss is introduced to consistently reduce the distribution distance of visible and infrared images by modality prototype modeling.","meta":{"url":"http://arxiv.org/abs/2309.06262v1"},"cats":{"new-dataset":0.0451672302,"dev-research":0.122185834,"data-quality":0.1498920875}}
{"text":"Extensive experiments on multiple public datasets demonstrate that the proposed method surpasses the current state-of-the-art methods by a significant margin.","meta":{"url":"http://arxiv.org/abs/2309.06262v1"},"cats":{"new-dataset":0.394877467,"dev-research":0.1447997233,"data-quality":0.2394449753}}
{"text":"Foundation models, including Vision Language Models (VLMs) and Large Language Models (LLMs), possess the $generality$ to handle diverse distributions and tasks, which stems from their extensive pre-training datasets.","meta":{"url":"http://arxiv.org/abs/2309.06256v1"},"cats":{"new-dataset":0.1738897619,"dev-research":0.1283757408,"data-quality":0.1274040359}}
{"text":"The fine-tuning of foundation models is a common practice to enhance task performance or align the model's behavior with human expectations, allowing them to gain $speciality$. However, the small datasets used for fine-tuning may not adequately cover the diverse distributions and tasks encountered during pre-training.","meta":{"url":"http://arxiv.org/abs/2309.06256v1"},"cats":{"new-dataset":0.0840819462,"dev-research":0.2271358494,"data-quality":0.123366718}}
{"text":"Consequently, the pursuit of speciality during fine-tuning can lead to a loss of {generality} in the model, which is related to catastrophic forgetting (CF) in deep learning.","meta":{"url":"http://arxiv.org/abs/2309.06256v1"},"cats":{"new-dataset":0.0082897811,"dev-research":0.2244454318,"data-quality":0.2694286553}}
{"text":"In this study, we demonstrate this phenomenon in both VLMs and LLMs.","meta":{"url":"http://arxiv.org/abs/2309.06256v1"},"cats":{"new-dataset":0.0079427168,"dev-research":0.1235530852,"data-quality":0.1460510128}}
{"text":"For instance, fine-tuning VLMs like CLIP on ImageNet results in a loss of generality in handling diverse distributions, and fine-tuning LLMs like Galactica in the medical domain leads to a loss in following instructions and common sense.   ","meta":{"url":"http://arxiv.org/abs/2309.06256v1"},"cats":{"new-dataset":0.0097322138,"dev-research":0.1489219786,"data-quality":0.2395907783}}
{"text":"To address the trade-off between the speciality and generality, we investigate multiple regularization methods from continual learning, the weight averaging method (Wise-FT) from out-of-distributional (OOD) generalization, which interpolates parameters between pre-trained and fine-tuned models, and parameter-efficient fine-tuning methods like Low-Rank Adaptation (LoRA).","meta":{"url":"http://arxiv.org/abs/2309.06256v1"},"cats":{"new-dataset":0.0159615515,"dev-research":0.1265507415,"data-quality":0.2193708373}}
{"text":"Our findings show that both continual learning and Wise-ft methods effectively mitigate the loss of generality, with Wise-FT exhibiting the strongest performance in balancing speciality and generality.","meta":{"url":"http://arxiv.org/abs/2309.06256v1"},"cats":{"new-dataset":0.0037812012,"dev-research":0.2247874905,"data-quality":0.1660773721}}
{"text":"One primary topic of multi-modal learning is to jointly incorporate heterogeneous information from different modalities.","meta":{"url":"http://arxiv.org/abs/2309.06255v1"},"cats":{"new-dataset":0.011401592,"dev-research":0.109334544,"data-quality":0.1178934544}}
{"text":"However, most models often suffer from unsatisfactory multi-modal cooperation, which could not jointly utilize all modalities well.","meta":{"url":"http://arxiv.org/abs/2309.06255v1"},"cats":{"new-dataset":0.0017039222,"dev-research":0.132292603,"data-quality":0.0957700799}}
{"text":"Some methods are proposed to identify and enhance the worse learnt modality, but are often hard to provide the fine-grained observation of multi-modal cooperation at sample-level with theoretical support.","meta":{"url":"http://arxiv.org/abs/2309.06255v1"},"cats":{"new-dataset":0.015111425,"dev-research":0.1585995544,"data-quality":0.1830434433}}
{"text":"Hence, it is essential to reasonably observe and improve the fine-grained cooperation between modalities, especially when facing realistic scenarios where the modality discrepancy could vary across different samples.","meta":{"url":"http://arxiv.org/abs/2309.06255v1"},"cats":{"new-dataset":0.0108475232,"dev-research":0.1980785791,"data-quality":0.3089282616}}
{"text":"To this end, we introduce a fine-grained modality valuation metric to evaluate the contribution of each modality at sample-level.","meta":{"url":"http://arxiv.org/abs/2309.06255v1"},"cats":{"new-dataset":0.0583279646,"dev-research":0.1186839829,"data-quality":0.2277969847}}
{"text":"Via modality valuation, we regretfully observe that the multi-modal model tends to rely on one specific modality, resulting in other modalities being low-contributing.","meta":{"url":"http://arxiv.org/abs/2309.06255v1"},"cats":{"new-dataset":0.005179823,"dev-research":0.1469619572,"data-quality":0.1355755911}}
{"text":"We further analyze this issue and improve cooperation between modalities by enhancing the discriminative ability of low-contributing modalities in a targeted manner.","meta":{"url":"http://arxiv.org/abs/2309.06255v1"},"cats":{"new-dataset":0.0090832345,"dev-research":0.1821568461,"data-quality":0.1497843761}}
{"text":"Overall, our methods reasonably observe the fine-grained uni-modal contribution at sample-level and achieve considerable improvement on different multi-modal models.","meta":{"url":"http://arxiv.org/abs/2309.06255v1"},"cats":{"new-dataset":0.0260305622,"dev-research":0.1344494947,"data-quality":0.1983692974}}
{"text":"Proactivity in robot assistance refers to the robot's ability to anticipate user needs and perform assistive actions without explicit requests.","meta":{"url":"http://arxiv.org/abs/2309.06252v1"},"cats":{"new-dataset":0.0277475418,"dev-research":0.3230544654,"data-quality":0.0546656696}}
{"text":"This requires understanding user routines, predicting consistent activities, and actively seeking information to predict inconsistent behaviors.","meta":{"url":"http://arxiv.org/abs/2309.06252v1"},"cats":{"new-dataset":0.0076701776,"dev-research":0.3328484419,"data-quality":0.1595796679}}
{"text":"We propose SLaTe-PRO (Sequential Latent Temporal model for Predicting Routine Object usage), which improves upon prior state-of-the-art by combining object and user action information, and conditioning object usage predictions on past history.","meta":{"url":"http://arxiv.org/abs/2309.06252v1"},"cats":{"new-dataset":0.1203587887,"dev-research":0.2342131396,"data-quality":0.0732287569}}
{"text":"Additionally, we find some human behavior to be inherently stochastic and lacking in contextual cues that the robot can use for proactive assistance.","meta":{"url":"http://arxiv.org/abs/2309.06252v1"},"cats":{"new-dataset":0.0294209598,"dev-research":0.3237472988,"data-quality":0.1287200851}}
{"text":"To address such cases, we introduce an interactive query mechanism that can be used to ask queries about the user's intended activities and object use to improve prediction.","meta":{"url":"http://arxiv.org/abs/2309.06252v1"},"cats":{"new-dataset":0.1215491582,"dev-research":0.3477032436,"data-quality":0.0653199247}}
{"text":"We evaluate our approach on longitudinal data from three households, spanning 24 activity classes.","meta":{"url":"http://arxiv.org/abs/2309.06252v1"},"cats":{"new-dataset":0.1581366044,"dev-research":0.1652240839,"data-quality":0.0569547019}}
{"text":"SLaTe-PRO performance raises the F1 score metric to 0.57 without queries, and 0.60 with user queries, over a score of 0.43 from prior work.","meta":{"url":"http://arxiv.org/abs/2309.06252v1"},"cats":{"new-dataset":0.0470839511,"dev-research":0.2109938249,"data-quality":0.114985114}}
{"text":"We additionally present a case study with a fully autonomous household robot.","meta":{"url":"http://arxiv.org/abs/2309.06252v1"},"cats":{"new-dataset":0.0650821987,"dev-research":0.1402495469,"data-quality":0.0629736418}}
{"text":"Probability estimation models play an important role in various fields, such as weather forecasting, recommendation systems, and sports analysis.","meta":{"url":"http://arxiv.org/abs/2309.06248v1"},"cats":{"new-dataset":0.0395152354,"dev-research":0.2026565041,"data-quality":0.0694789436}}
{"text":"Among several models estimating probabilities, it is difficult to evaluate which model gives reliable probabilities since the ground-truth probabilities are not available.","meta":{"url":"http://arxiv.org/abs/2309.06248v1"},"cats":{"new-dataset":0.0143260549,"dev-research":0.1834116224,"data-quality":0.2008550678}}
{"text":"The win probability estimation model for esports, which calculates the win probability under a certain game state, is also one of the fields being actively studied in probability estimation.","meta":{"url":"http://arxiv.org/abs/2309.06248v1"},"cats":{"new-dataset":0.0563685121,"dev-research":0.2100251254,"data-quality":0.0862574666}}
{"text":"However, most of the previous works evaluated their models using accuracy, a metric that only can measure the performance of discrimination.","meta":{"url":"http://arxiv.org/abs/2309.06248v1"},"cats":{"new-dataset":0.0042668934,"dev-research":0.1810529322,"data-quality":0.2609083955}}
{"text":"In this work, we firstly investigate the Brier score and the Expected Calibration Error (ECE) as a replacement of accuracy used as a performance evaluation metric for win probability estimation models in esports field.","meta":{"url":"http://arxiv.org/abs/2309.06248v1"},"cats":{"new-dataset":0.1267344735,"dev-research":0.2205852474,"data-quality":0.1605528486}}
{"text":"Based on the analysis, we propose a novel metric called Balance score which is a simple yet effective metric in terms of six good properties that probability estimation metric should have.","meta":{"url":"http://arxiv.org/abs/2309.06248v1"},"cats":{"new-dataset":0.0572410454,"dev-research":0.1453442564,"data-quality":0.1396140623}}
{"text":"Under the general condition, we also found that the Balance score can be an effective approximation of the true expected calibration error which has been imperfectly approximated by ECE using the binning technique.","meta":{"url":"http://arxiv.org/abs/2309.06248v1"},"cats":{"new-dataset":0.027258423,"dev-research":0.1492689699,"data-quality":0.2054045176}}
{"text":"Extensive evaluations using simulation studies and real game snapshot data demonstrate the promising potential to adopt the proposed metric not only for the win probability estimation model for esports but also for evaluating general probability estimation models.","meta":{"url":"http://arxiv.org/abs/2309.06248v1"},"cats":{"new-dataset":0.1649040635,"dev-research":0.2554706499,"data-quality":0.0843773719}}
{"text":"In the dynamic and uncertain environments where reinforcement learning (RL) operates, risk management becomes a crucial factor in ensuring reliable decision-making.","meta":{"url":"http://arxiv.org/abs/2309.06239v1"},"cats":{"new-dataset":0.0377117495,"dev-research":0.2565720965,"data-quality":0.0955905543}}
{"text":"Traditional RL approaches, while effective in reward optimization, often overlook the landscape of potential risks.","meta":{"url":"http://arxiv.org/abs/2309.06239v1"},"cats":{"new-dataset":0.00378259,"dev-research":0.2420042395,"data-quality":0.0982177285}}
{"text":"In response, this paper pioneers the integration of Optimal Transport (OT) theory with RL to create a risk-aware framework.","meta":{"url":"http://arxiv.org/abs/2309.06239v1"},"cats":{"new-dataset":0.0113232047,"dev-research":0.1892058516,"data-quality":0.0746216289}}
{"text":"Our approach modifies the objective function, ensuring that the resulting policy not only maximizes expected rewards but also respects risk constraints dictated by OT distances between state visitation distributions and the desired risk profiles.","meta":{"url":"http://arxiv.org/abs/2309.06239v1"},"cats":{"new-dataset":0.0110607436,"dev-research":0.1554406723,"data-quality":0.0877107243}}
{"text":"By leveraging the mathematical precision of OT, we offer a formulation that elevates risk considerations alongside conventional RL objectives.","meta":{"url":"http://arxiv.org/abs/2309.06239v1"},"cats":{"new-dataset":0.0160721809,"dev-research":0.2114190048,"data-quality":0.1473741198}}
{"text":"Our contributions are substantiated with a series of theorems, mapping the relationships between risk distributions, optimal value functions, and policy behaviors.","meta":{"url":"http://arxiv.org/abs/2309.06239v1"},"cats":{"new-dataset":0.0647828265,"dev-research":0.1597961377,"data-quality":0.0998542188}}
{"text":"Through the lens of OT, this work illuminates a promising direction for RL, ensuring a balanced fusion of reward pursuit and risk awareness.","meta":{"url":"http://arxiv.org/abs/2309.06239v1"},"cats":{"new-dataset":0.0166825282,"dev-research":0.1407848624,"data-quality":0.058197678}}
{"text":"In a microservices-based system, reliability and availability are key components to guarantee the best-in-class experience for the consumers.","meta":{"url":"http://arxiv.org/abs/2309.06238v1"},"cats":{"new-dataset":0.0129656752,"dev-research":0.1761395699,"data-quality":0.1749128643}}
{"text":"One of the key advantages of microservices architecture is the ability to independently deploy services, providing maximum change flexibility.","meta":{"url":"http://arxiv.org/abs/2309.06238v1"},"cats":{"new-dataset":0.0033113761,"dev-research":0.1722334085,"data-quality":0.0547324279}}
{"text":"However, this introduces an extra complexity in managing the risk associated with every change: any mutation of a service might cause the whole system to fail.","meta":{"url":"http://arxiv.org/abs/2309.06238v1"},"cats":{"new-dataset":0.0067381692,"dev-research":0.2940920142,"data-quality":0.1712060656}}
{"text":"In this research, we would propose an algorithm to enable development teams to determine the risk associated with each change to any of the microservices in the system.","meta":{"url":"http://arxiv.org/abs/2309.06238v1"},"cats":{"new-dataset":0.0882379178,"dev-research":0.3809463274,"data-quality":0.1226810312}}
{"text":"Large Language Models (LLMs) have demonstrated remarkable generalization across diverse tasks, leading individuals to increasingly use them as personal assistants and universal computing engines.","meta":{"url":"http://arxiv.org/abs/2309.06236v1"},"cats":{"new-dataset":0.0731360783,"dev-research":0.1509579489,"data-quality":0.122390444}}
{"text":"Nevertheless, a notable obstacle emerges when feeding numerical/temporal data into these models, such as data sourced from wearables or electronic health records.","meta":{"url":"http://arxiv.org/abs/2309.06236v1"},"cats":{"new-dataset":0.0983098991,"dev-research":0.1801033073,"data-quality":0.0616128524}}
{"text":"LLMs employ tokenizers in their input that break down text into smaller units.","meta":{"url":"http://arxiv.org/abs/2309.06236v1"},"cats":{"new-dataset":0.0252332886,"dev-research":0.1095555746,"data-quality":0.2514404594}}
{"text":"However, tokenizers are not designed to represent numerical values and might struggle to understand repetitive patterns and context, treating consecutive values as separate tokens and disregarding their temporal relationships.","meta":{"url":"http://arxiv.org/abs/2309.06236v1"},"cats":{"new-dataset":0.0119906483,"dev-research":0.2092393522,"data-quality":0.2522607465}}
{"text":"Here, we discuss recent works that employ LLMs for human-centric tasks such as in mobile health sensing and present a case study showing that popular LLMs tokenize temporal data incorrectly.","meta":{"url":"http://arxiv.org/abs/2309.06236v1"},"cats":{"new-dataset":0.196428037,"dev-research":0.1830913592,"data-quality":0.1196528189}}
{"text":"To address that, we highlight potential solutions such as prompt tuning with lightweight embedding layers as well as multimodal adapters, that can help bridge this \"modality gap\".","meta":{"url":"http://arxiv.org/abs/2309.06236v1"},"cats":{"new-dataset":0.0280784364,"dev-research":0.1900896796,"data-quality":0.1610256199}}
{"text":"While the capability of language models to generalize to other modalities with minimal or no finetuning is exciting, this paper underscores the fact that their outputs cannot be meaningful if they stumble over input nuances.","meta":{"url":"http://arxiv.org/abs/2309.06236v1"},"cats":{"new-dataset":0.016723985,"dev-research":0.2247033746,"data-quality":0.3536738818}}
{"text":"Bug datasets are vital for enabling deep learning techniques to address software maintenance tasks related to bugs.","meta":{"url":"http://arxiv.org/abs/2309.06229v1"},"cats":{"new-dataset":0.5589112647,"dev-research":0.4556500274,"data-quality":0.4219714291}}
{"text":"However, existing bug datasets suffer from precise and scale limitations: they are either small-scale but precise with manual validation or large-scale but imprecise with simple commit message processing.","meta":{"url":"http://arxiv.org/abs/2309.06229v1"},"cats":{"new-dataset":0.4796248296,"dev-research":0.417825403,"data-quality":0.3092938785}}
{"text":"In this paper, we introduce PreciseBugCollector, a precise, multi-language bug collection approach that overcomes these two limitations.","meta":{"url":"http://arxiv.org/abs/2309.06229v1"},"cats":{"new-dataset":0.261412885,"dev-research":0.3865394299,"data-quality":0.5081647539}}
{"text":"PreciseBugCollector is based on two novel components: a) A bug tracker to map the codebase repositories with external bug repositories to trace bug type information, and b)","meta":{"url":"http://arxiv.org/abs/2309.06229v1"},"cats":{"new-dataset":0.1513445255,"dev-research":0.4027063974,"data-quality":0.3381932081}}
{"text":"A bug injector to generate project-specific bugs by injecting noise into the correct codebases and then executing them against their test suites to obtain test failure messages.   ","meta":{"url":"http://arxiv.org/abs/2309.06229v1"},"cats":{"new-dataset":0.0800680937,"dev-research":0.4887121538,"data-quality":0.4934236162}}
{"text":"We implement PreciseBugCollector against three sources: 1) A bug tracker that links to the national vulnerability data set (NVD) to collect general-wise vulnerabilities, 2) A bug tracker that links to OSS-Fuzz to collect general-wise bugs, and 3) A bug injector based on 16 injection rules to generate project-wise bugs.","meta":{"url":"http://arxiv.org/abs/2309.06229v1"},"cats":{"new-dataset":0.1860949404,"dev-research":0.4088131834,"data-quality":0.2528584369}}
{"text":"To date, \\approach comprises 1057818 bugs extracted from 2968 open-source projects.","meta":{"url":"http://arxiv.org/abs/2309.06229v1"},"cats":{"new-dataset":0.2987118221,"dev-research":0.4141827234,"data-quality":0.1888467153}}
{"text":"Of these, 12602 bugs are sourced from bug repositories (NVD and OSS-Fuzz), while the remaining 1045216 project-specific bugs are generated by the bug injector.","meta":{"url":"http://arxiv.org/abs/2309.06229v1"},"cats":{"new-dataset":0.5685457626,"dev-research":0.3766361206,"data-quality":0.3500932896}}
{"text":"Considering the challenge objectives, we argue that a bug injection approach is highly valuable for the industrial setting, since project-specific bugs align with domain knowledge, share the same codebase, and adhere to the coding style employed in industrial projects.","meta":{"url":"http://arxiv.org/abs/2309.06229v1"},"cats":{"new-dataset":0.0674683088,"dev-research":0.5947089176,"data-quality":0.3659366442}}
{"text":"The position paper highlights the range of concerns that are engulfed in the injunction of explainable artificial intelligence in art (XAIxArt).","meta":{"url":"http://arxiv.org/abs/2309.06227v1"},"cats":{"new-dataset":0.0345811237,"dev-research":0.2926472493,"data-quality":0.116772187}}
{"text":"Through a series of quick sub-questions, it points towards the ambiguities concerning 'explanation' and the postpositivist tradition of 'relevant explanation'.","meta":{"url":"http://arxiv.org/abs/2309.06227v1"},"cats":{"new-dataset":0.014624185,"dev-research":0.3708946891,"data-quality":0.1760888001}}
{"text":"Rejecting both 'explanation' and 'relevant explanation', the paper takes a stance that XAIxArt is a symptom of insecurity of the anthropocentric notion of art and a nostalgic desire to return to outmoded notions of authorship and human agency.","meta":{"url":"http://arxiv.org/abs/2309.06227v1"},"cats":{"new-dataset":0.0290471142,"dev-research":0.3307867162,"data-quality":0.160468736}}
{"text":"To justify this stance, the paper makes a distinction between an ornamentation model of explanation to a model of explanation as sense-making.","meta":{"url":"http://arxiv.org/abs/2309.06227v1"},"cats":{"new-dataset":0.0080892369,"dev-research":0.3601356808,"data-quality":0.2284766347}}
{"text":"Recent research has shown that bit-flip attacks (BFAs) can manipulate deep neural networks (DNNs) via DRAM Rowhammer exploitations.","meta":{"url":"http://arxiv.org/abs/2309.06223v1"},"cats":{"new-dataset":0.0422389178,"dev-research":0.1691829118,"data-quality":0.1010550612}}
{"text":"Existing attacks are primarily launched over high-level DNN frameworks like PyTorch and flip bits in model weight files.","meta":{"url":"http://arxiv.org/abs/2309.06223v1"},"cats":{"new-dataset":0.0793676555,"dev-research":0.2556324866,"data-quality":0.120277638}}
{"text":"Nevertheless, DNNs are frequently compiled into low-level executables by deep learning (DL) compilers to fully leverage low-level hardware primitives.","meta":{"url":"http://arxiv.org/abs/2309.06223v1"},"cats":{"new-dataset":0.1550743592,"dev-research":0.3530291192,"data-quality":0.0936007808}}
{"text":"The compiled code is usually high-speed and manifests dramatically distinct execution paradigms from high-level DNN frameworks.   ","meta":{"url":"http://arxiv.org/abs/2309.06223v1"},"cats":{"new-dataset":0.0850195037,"dev-research":0.4023882209,"data-quality":0.082988316}}
{"text":"In this paper, we launch the first systematic study on the attack surface of BFA specifically for DNN executables compiled by DL compilers.","meta":{"url":"http://arxiv.org/abs/2309.06223v1"},"cats":{"new-dataset":0.2918196447,"dev-research":0.3411850959,"data-quality":0.1071842704}}
{"text":"We design an automated search tool to identify vulnerable bits in DNN executables and identify practical attack vectors that exploit the model structure in DNN executables with BFAs (whereas prior works make likely strong assumptions to attack model weights).","meta":{"url":"http://arxiv.org/abs/2309.06223v1"},"cats":{"new-dataset":0.2153328126,"dev-research":0.2919728876,"data-quality":0.1686992148}}
{"text":"DNN executables appear more \"opaque\" than models in high-level DNN frameworks.","meta":{"url":"http://arxiv.org/abs/2309.06223v1"},"cats":{"new-dataset":0.0485382956,"dev-research":0.2496075749,"data-quality":0.154831039}}
{"text":"Nevertheless, we find that DNN executables contain extensive, severe (e.g., single-bit flip), and transferrable attack surfaces that are not present in high-level DNN models and can be exploited to deplete full model intelligence and control output labels.","meta":{"url":"http://arxiv.org/abs/2309.06223v1"},"cats":{"new-dataset":0.1541127014,"dev-research":0.2620841022,"data-quality":0.1553962625}}
{"text":"Our finding calls for incorporating security mechanisms in future DNN compilation toolchains.","meta":{"url":"http://arxiv.org/abs/2309.06223v1"},"cats":{"new-dataset":0.3763297293,"dev-research":0.4859657924,"data-quality":0.1577507642}}
{"text":"Correcting students' multiple-choice answers is a repetitive and mechanical task that can be considered an image multi-classification task.","meta":{"url":"http://arxiv.org/abs/2309.06221v1"},"cats":{"new-dataset":0.0226368518,"dev-research":0.2813460091,"data-quality":0.2330675027}}
{"text":"Assuming possible options are 'abcd' and the correct option is one of the four, some students may write incorrect symbols or options that do not exist.","meta":{"url":"http://arxiv.org/abs/2309.06221v1"},"cats":{"new-dataset":0.0415878831,"dev-research":0.3374667133,"data-quality":0.2240210273}}
{"text":"In this paper, five classifications were set up - four for possible correct options and one for other incorrect writing.","meta":{"url":"http://arxiv.org/abs/2309.06221v1"},"cats":{"new-dataset":0.0726332302,"dev-research":0.328739896,"data-quality":0.4104661855}}
{"text":"This approach takes into account the possibility of non-standard writing options.","meta":{"url":"http://arxiv.org/abs/2309.06221v1"},"cats":{"new-dataset":0.0029709807,"dev-research":0.2847205884,"data-quality":0.132861909}}
{"text":"Parkour is a grand challenge for legged locomotion that requires robots to overcome various obstacles rapidly in complex environments.","meta":{"url":"http://arxiv.org/abs/2309.05665v1"},"cats":{"new-dataset":0.0680721719,"dev-research":0.244829131,"data-quality":0.0722622295}}
{"text":"Existing methods can generate either diverse but blind locomotion skills or vision-based but specialized skills by using reference animal data or complex rewards.","meta":{"url":"http://arxiv.org/abs/2309.05665v1"},"cats":{"new-dataset":0.0690892477,"dev-research":0.192005781,"data-quality":0.0579558873}}
{"text":"However, autonomous parkour requires robots to learn generalizable skills that are both vision-based and diverse to perceive and react to various scenarios.","meta":{"url":"http://arxiv.org/abs/2309.05665v1"},"cats":{"new-dataset":0.0387522719,"dev-research":0.1930060064,"data-quality":0.1013819166}}
{"text":"In this work, we propose a system for learning a single end-to-end vision-based parkour policy of diverse parkour skills using a simple reward without any reference motion data.","meta":{"url":"http://arxiv.org/abs/2309.05665v1"},"cats":{"new-dataset":0.3456767105,"dev-research":0.1578434919,"data-quality":0.1202640114}}
{"text":"We develop a reinforcement learning method inspired by direct collocation to generate parkour skills, including climbing over high obstacles, leaping over large gaps, crawling beneath low barriers, squeezing through thin slits, and running.","meta":{"url":"http://arxiv.org/abs/2309.05665v1"},"cats":{"new-dataset":0.0827929263,"dev-research":0.1989957326,"data-quality":0.0784643269}}
{"text":"We distill these skills into a single vision-based parkour policy and transfer it to a quadrupedal robot using its egocentric depth camera.","meta":{"url":"http://arxiv.org/abs/2309.05665v1"},"cats":{"new-dataset":0.2002320232,"dev-research":0.1753516726,"data-quality":0.0725188958}}
{"text":"We demonstrate that our system can empower two different low-cost robots to autonomously select and execute appropriate parkour skills to traverse challenging real-world environments.","meta":{"url":"http://arxiv.org/abs/2309.05665v1"},"cats":{"new-dataset":0.0782496205,"dev-research":0.2077125376,"data-quality":0.0716902312}}
{"text":"We tackle the task of reconstructing hand-object interactions from short video clips.","meta":{"url":"http://arxiv.org/abs/2309.05663v1"},"cats":{"new-dataset":0.3264211297,"dev-research":0.2201674752,"data-quality":0.0852210433}}
{"text":"Given an input video, our approach casts 3D inference as a per-video optimization and recovers a neural 3D representation of the object shape, as well as the time-varying motion and hand articulation.","meta":{"url":"http://arxiv.org/abs/2309.05663v1"},"cats":{"new-dataset":0.0928718073,"dev-research":0.1568384982,"data-quality":0.0720852808}}
{"text":"While the input video naturally provides some multi-view cues to guide 3D inference, these are insufficient on their own due to occlusions and limited viewpoint variations.","meta":{"url":"http://arxiv.org/abs/2309.05663v1"},"cats":{"new-dataset":0.0239484731,"dev-research":0.1797578444,"data-quality":0.0968283548}}
{"text":"To obtain accurate 3D, we augment the multi-view signals with generic data-driven priors to guide reconstruction.","meta":{"url":"http://arxiv.org/abs/2309.05663v1"},"cats":{"new-dataset":0.1876074177,"dev-research":0.1853622325,"data-quality":0.0735197835}}
{"text":"Specifically, we learn a diffusion network to model the conditional distribution of (geometric) renderings of objects conditioned on hand configuration and category label, and leverage it as a prior to guide the novel-view renderings of the reconstructed scene.","meta":{"url":"http://arxiv.org/abs/2309.05663v1"},"cats":{"new-dataset":0.2732063419,"dev-research":0.1656426782,"data-quality":0.1174023778}}
{"text":"We empirically evaluate our approach on egocentric videos across 6 object categories, and observe significant improvements over prior single-view and multi-view methods.","meta":{"url":"http://arxiv.org/abs/2309.05663v1"},"cats":{"new-dataset":0.1010389415,"dev-research":0.2150456001,"data-quality":0.200477064}}
{"text":"Finally, we demonstrate our system's ability to reconstruct arbitrary clips from YouTube, showing both 1st and 3rd person interactions.","meta":{"url":"http://arxiv.org/abs/2309.05663v1"},"cats":{"new-dataset":0.1991035401,"dev-research":0.1999831679,"data-quality":0.1215868176}}
{"text":"In this letter, we introduce ViHOPE, a novel framework for estimating the 6D pose of an in-hand object using visuotactile perception.","meta":{"url":"http://arxiv.org/abs/2309.05662v1"},"cats":{"new-dataset":0.2698691826,"dev-research":0.1380885991,"data-quality":0.0677745945}}
{"text":"Our key insight is that the accuracy of the 6D object pose estimate can be improved by explicitly completing the shape of the object.","meta":{"url":"http://arxiv.org/abs/2309.05662v1"},"cats":{"new-dataset":0.0675406395,"dev-research":0.1721742474,"data-quality":0.1283778964}}
{"text":"To this end, we introduce a novel visuotactile shape completion module that uses a conditional Generative Adversarial Network to complete the shape of an in-hand object based on volumetric representation.","meta":{"url":"http://arxiv.org/abs/2309.05662v1"},"cats":{"new-dataset":0.1402555879,"dev-research":0.1837513794,"data-quality":0.0701237853}}
{"text":"This approach improves over prior works that directly regress visuotactile observations to a 6D pose.","meta":{"url":"http://arxiv.org/abs/2309.05662v1"},"cats":{"new-dataset":0.0926081068,"dev-research":0.1639234157,"data-quality":0.0766998173}}
{"text":"By explicitly completing the shape of the in-hand object and jointly optimizing the shape completion and pose estimation tasks, we improve the accuracy of the 6D object pose estimate.","meta":{"url":"http://arxiv.org/abs/2309.05662v1"},"cats":{"new-dataset":0.1430064587,"dev-research":0.2095365898,"data-quality":0.094141462}}
{"text":"We train and test our model on a synthetic dataset and compare it with the state-of-the-art.","meta":{"url":"http://arxiv.org/abs/2309.05662v1"},"cats":{"new-dataset":0.6784377376,"dev-research":0.1685816425,"data-quality":0.1639769988}}
{"text":"In the visuotactile shape completion task, we outperform the state-of-the-art by 265% using the Intersection of Union metric and achieve 88% lower Chamfer Distance.","meta":{"url":"http://arxiv.org/abs/2309.05662v1"},"cats":{"new-dataset":0.051470643,"dev-research":0.1828453271,"data-quality":0.0787802058}}
{"text":"In the visuotactile pose estimation task, we present results that suggest our framework reduces position and angular errors by 35% and 64%, respectively.","meta":{"url":"http://arxiv.org/abs/2309.05662v1"},"cats":{"new-dataset":0.0838567258,"dev-research":0.1885853974,"data-quality":0.127696534}}
{"text":"Furthermore, we ablate our framework to confirm the gain on the 6D object pose estimate from explicitly completing the shape.","meta":{"url":"http://arxiv.org/abs/2309.05662v1"},"cats":{"new-dataset":0.1199163122,"dev-research":0.1321289611,"data-quality":0.1037465552}}
{"text":"Ultimately, we show that our framework produces models that are robust to sim-to-real transfer on a real-world robot platform.","meta":{"url":"http://arxiv.org/abs/2309.05662v1"},"cats":{"new-dataset":0.1288147287,"dev-research":0.1675867743,"data-quality":0.0676531123}}
{"text":"Inductive reasoning is a core problem-solving capacity: humans can identify underlying principles from a few examples, which can then be robustly generalized to novel scenarios.","meta":{"url":"http://arxiv.org/abs/2309.05660v1"},"cats":{"new-dataset":0.0184375824,"dev-research":0.3423872972,"data-quality":0.1040948475}}
{"text":"Recent work has evaluated large language models (LLMs) on inductive reasoning tasks by directly prompting them yielding \"in context learning.\"","meta":{"url":"http://arxiv.org/abs/2309.05660v1"},"cats":{"new-dataset":0.0483752097,"dev-research":0.1701770074,"data-quality":0.1680405168}}
{"text":"This can work well for straightforward inductive tasks, but performs very poorly on more complex tasks such as the Abstraction and Reasoning Corpus (ARC).","meta":{"url":"http://arxiv.org/abs/2309.05660v1"},"cats":{"new-dataset":0.0390963181,"dev-research":0.2875911123,"data-quality":0.1749693819}}
{"text":"In this work, we propose to improve the inductive reasoning ability of LLMs by generating explicit hypotheses at multiple levels of abstraction: we prompt the LLM to propose multiple abstract hypotheses about the problem, in natural language, then implement the natural language hypotheses as concrete Python programs.","meta":{"url":"http://arxiv.org/abs/2309.05660v1"},"cats":{"new-dataset":0.113755408,"dev-research":0.2850978026,"data-quality":0.2021339404}}
{"text":"These programs can be directly verified by running on the observed examples and generalized to novel inputs.","meta":{"url":"http://arxiv.org/abs/2309.05660v1"},"cats":{"new-dataset":0.0462880098,"dev-research":0.2098816337,"data-quality":0.176747882}}
{"text":"Because of the prohibitive cost of generation with state-of-the-art LLMs, we consider a middle step to filter the set of hypotheses that will be implemented into programs: we either ask the LLM to summarize into a smaller set of hypotheses, or ask human annotators to select a subset of the hypotheses.","meta":{"url":"http://arxiv.org/abs/2309.05660v1"},"cats":{"new-dataset":0.1064164458,"dev-research":0.3004038093,"data-quality":0.1460458893}}
{"text":"We verify our pipeline's effectiveness on the ARC visual inductive reasoning benchmark, its variant 1D-ARC, and string transformation dataset SyGuS. On a random 40-problem subset of ARC, our automated pipeline using LLM summaries achieves 27.5% accuracy, significantly outperforming the direct prompting baseline (accuracy of 12.5%).","meta":{"url":"http://arxiv.org/abs/2309.05660v1"},"cats":{"new-dataset":0.1858630893,"dev-research":0.3078534138,"data-quality":0.2240050942}}
{"text":"With the minimal human input of selecting from LLM-generated candidates, the performance is boosted to 37.5%.","meta":{"url":"http://arxiv.org/abs/2309.05660v1"},"cats":{"new-dataset":0.0230101227,"dev-research":0.1119899637,"data-quality":0.1075696376}}
{"text":"(And we argue this is a lower bound on the performance of our approach without filtering.)","meta":{"url":"http://arxiv.org/abs/2309.05660v1"},"cats":{"new-dataset":0.0202201042,"dev-research":0.1109981248,"data-quality":0.1909316628}}
{"text":"Our ablation studies show that abstract hypothesis generation and concrete program representations are both beneficial for LLMs to perform inductive reasoning tasks.","meta":{"url":"http://arxiv.org/abs/2309.05660v1"},"cats":{"new-dataset":0.0326795126,"dev-research":0.2930851254,"data-quality":0.1197579599}}
{"text":"Volumetric video, which offers immersive viewing experiences, is gaining increasing prominence.","meta":{"url":"http://arxiv.org/abs/2309.05658v1"},"cats":{"new-dataset":0.0602706984,"dev-research":0.1789787658,"data-quality":0.072176787}}
{"text":"With its six degrees of freedom, it provides viewers with greater immersion and interactivity compared to traditional videos.","meta":{"url":"http://arxiv.org/abs/2309.05658v1"},"cats":{"new-dataset":0.060098354,"dev-research":0.1400269765,"data-quality":0.056857921}}
{"text":"Despite their potential, volumetric video services poses significant challenges.","meta":{"url":"http://arxiv.org/abs/2309.05658v1"},"cats":{"new-dataset":0.0679486613,"dev-research":0.155003211,"data-quality":0.157562899}}
{"text":"This survey conducts a comprehensive review of the existing literature on volumetric video.","meta":{"url":"http://arxiv.org/abs/2309.05658v1"},"cats":{"new-dataset":0.2800093629,"dev-research":0.1523910216,"data-quality":0.1117804625}}
{"text":"We firstly provide a general framework of volumetric video services, followed by a discussion on prerequisites for volumetric video, encompassing representations, open datasets, and quality assessment metrics.","meta":{"url":"http://arxiv.org/abs/2309.05658v1"},"cats":{"new-dataset":0.3836455164,"dev-research":0.1495184631,"data-quality":0.1431872278}}
{"text":"Then we delve into the current methodologies for each stage of the volumetric video service pipeline, detailing capturing, compression, transmission, rendering, and display techniques.","meta":{"url":"http://arxiv.org/abs/2309.05658v1"},"cats":{"new-dataset":0.1328856364,"dev-research":0.1688616015,"data-quality":0.0962379715}}
{"text":"Lastly, we explore various applications enabled by this pioneering technology and we present an array of research challenges and opportunities in the domain of volumetric video services.","meta":{"url":"http://arxiv.org/abs/2309.05658v1"},"cats":{"new-dataset":0.0569003172,"dev-research":0.1430066954,"data-quality":0.106480836}}
{"text":"This survey aspires to provide a holistic understanding of this burgeoning field and shed light on potential future research trajectories, aiming to bring the vision of volumetric video to fruition.","meta":{"url":"http://arxiv.org/abs/2309.05658v1"},"cats":{"new-dataset":0.2491930261,"dev-research":0.1282008444,"data-quality":0.0806623554}}
{"text":"Humans throw and catch objects all the time.","meta":{"url":"http://arxiv.org/abs/2309.05655v1"},"cats":{"new-dataset":0.1375515952,"dev-research":0.3067662745,"data-quality":0.0825089803}}
{"text":"However, such a seemingly common skill introduces a lot of challenges for robots to achieve: The robots need to operate such dynamic actions at high-speed, collaborate precisely, and interact with diverse objects.","meta":{"url":"http://arxiv.org/abs/2309.05655v1"},"cats":{"new-dataset":0.026619825,"dev-research":0.2028861765,"data-quality":0.0368007946}}
{"text":"In this paper, we design a system with two multi-finger hands attached to robot arms to solve this problem.","meta":{"url":"http://arxiv.org/abs/2309.05655v1"},"cats":{"new-dataset":0.1366081602,"dev-research":0.1582236332,"data-quality":0.0629988229}}
{"text":"We train our system using Multi-Agent Reinforcement Learning in simulation and perform Sim2Real transfer to deploy on the real robots.","meta":{"url":"http://arxiv.org/abs/2309.05655v1"},"cats":{"new-dataset":0.3072785071,"dev-research":0.1331181192,"data-quality":0.0775631024}}
{"text":"To overcome the Sim2Real gap, we provide multiple novel algorithm designs including learning a trajectory prediction model for the object.","meta":{"url":"http://arxiv.org/abs/2309.05655v1"},"cats":{"new-dataset":0.1424753688,"dev-research":0.1357485495,"data-quality":0.0536668597}}
{"text":"Such a model can help the robot catcher has a real-time estimation of where the object will be heading, and then react accordingly.","meta":{"url":"http://arxiv.org/abs/2309.05655v1"},"cats":{"new-dataset":0.025764836,"dev-research":0.1882103277,"data-quality":0.0683527395}}
{"text":"We conduct our experiments with multiple objects in the real-world system, and show significant improvements over multiple baselines.","meta":{"url":"http://arxiv.org/abs/2309.05655v1"},"cats":{"new-dataset":0.0860919709,"dev-research":0.1750169859,"data-quality":0.1301486748}}
{"text":"Our project page is available at \\url{https://binghao-huang.github.io/dynamic_handover/}.","meta":{"url":"http://arxiv.org/abs/2309.05655v1"},"cats":{"new-dataset":0.0924330476,"dev-research":0.1841392478,"data-quality":0.0582930903}}
{"text":"We introduce MAmmoTH, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.","meta":{"url":"http://arxiv.org/abs/2309.05653v1"},"cats":{"new-dataset":0.2484627721,"dev-research":0.1695530485,"data-quality":0.1065224136}}
{"text":"The MAmmoTH models are trained on MathInstruct, our meticulously curated instruction tuning dataset.","meta":{"url":"http://arxiv.org/abs/2309.05653v1"},"cats":{"new-dataset":0.5028547399,"dev-research":0.17808955,"data-quality":0.096673843}}
{"text":"MathInstruct is compiled from 13 math datasets with intermediate rationales, six of which have rationales newly curated by us.","meta":{"url":"http://arxiv.org/abs/2309.05653v1"},"cats":{"new-dataset":0.9208412113,"dev-research":0.2639210607,"data-quality":0.1276054146}}
{"text":"It presents a unique hybrid of chain-of-thought (CoT) and program-of-thought (PoT) rationales, and also ensures extensive coverage of diverse fields in math.","meta":{"url":"http://arxiv.org/abs/2309.05653v1"},"cats":{"new-dataset":0.0402954115,"dev-research":0.2096785383,"data-quality":0.0494739818}}
{"text":"The hybrid of CoT and PoT not only unleashes the potential of tool use but also allows different thought processes for different math problems.","meta":{"url":"http://arxiv.org/abs/2309.05653v1"},"cats":{"new-dataset":0.0015643366,"dev-research":0.2679379728,"data-quality":0.0400753402}}
{"text":"As a result, the MAmmoTH series substantially outperform existing open-source models on nine mathematical reasoning datasets across all scales with an average accuracy gain between 13% and 29%.","meta":{"url":"http://arxiv.org/abs/2309.05653v1"},"cats":{"new-dataset":0.2821117283,"dev-research":0.2225861125,"data-quality":0.1397877669}}
{"text":"Remarkably, our MAmmoTH-7B model reaches 35% on MATH (a competition-level dataset), which exceeds the best open-source 7B model (WizardMath) by 25%, and the MAmmoTH-34B model achieves 46% accuracy on MATH, even surpassing GPT-4's CoT result.","meta":{"url":"http://arxiv.org/abs/2309.05653v1"},"cats":{"new-dataset":0.2156008635,"dev-research":0.1184365295,"data-quality":0.1032917796}}
{"text":"Our work underscores the importance of diverse problem coverage and the use of hybrid rationales in developing superior math generalist models.","meta":{"url":"http://arxiv.org/abs/2309.05653v1"},"cats":{"new-dataset":0.0125279864,"dev-research":0.2063972915,"data-quality":0.1102934539}}
{"text":"Learning from the limited amount of labeled data to the pre-train model has always been viewed as a challenging task.","meta":{"url":"http://arxiv.org/abs/2309.05652v1"},"cats":{"new-dataset":0.1218055703,"dev-research":0.1447367514,"data-quality":0.284572268}}
{"text":"In this report, an effective and robust solution, the two-stage training paradigm YOLOv8 detector (TP-YOLOv8), is designed for the object detection track in VIPriors Challenge 2023.","meta":{"url":"http://arxiv.org/abs/2309.05652v1"},"cats":{"new-dataset":0.1031283125,"dev-research":0.1220997389,"data-quality":0.1949746474}}
{"text":"First, the backbone of YOLOv8 is pre-trained as the encoder using the masked image modeling technique.","meta":{"url":"http://arxiv.org/abs/2309.05652v1"},"cats":{"new-dataset":0.0501048111,"dev-research":0.1445582321,"data-quality":0.0870198469}}
{"text":"Then the detector is fine-tuned with elaborate augmentations.","meta":{"url":"http://arxiv.org/abs/2309.05652v1"},"cats":{"new-dataset":0.008848903,"dev-research":0.1346394634,"data-quality":0.2799519315}}
{"text":"During the test stage, test-time augmentation (TTA) is used to enhance each model, and weighted box fusion (WBF) is implemented to further boost the performance.","meta":{"url":"http://arxiv.org/abs/2309.05652v1"},"cats":{"new-dataset":0.011474106,"dev-research":0.1584562632,"data-quality":0.0766953379}}
{"text":"With the well-designed structure, our approach has achieved 30.4% average precision from 0.50 to 0.95 on the DelftBikes test set, ranking 4th on the leaderboard.","meta":{"url":"http://arxiv.org/abs/2309.05652v1"},"cats":{"new-dataset":0.0382839262,"dev-research":0.2033319808,"data-quality":0.1504852654}}
{"text":"The Symmetric Information Bottleneck (SIB), an extension of the more familiar Information Bottleneck, is a dimensionality reduction technique that simultaneously compresses two random variables to preserve information between their compressed versions.","meta":{"url":"http://arxiv.org/abs/2309.05649v1"},"cats":{"new-dataset":0.0179631301,"dev-research":0.1723338185,"data-quality":0.1715733775}}
{"text":"We introduce the Generalized Symmetric Information Bottleneck (GSIB), which explores different functional forms of the cost of such simultaneous reduction.","meta":{"url":"http://arxiv.org/abs/2309.05649v1"},"cats":{"new-dataset":0.0228330328,"dev-research":0.133490097,"data-quality":0.1131864239}}
{"text":"We then explore the dataset size requirements of such simultaneous compression.","meta":{"url":"http://arxiv.org/abs/2309.05649v1"},"cats":{"new-dataset":0.3704626736,"dev-research":0.1188998114,"data-quality":0.1186137615}}
{"text":"We do this by deriving bounds and root-mean-squared estimates of statistical fluctuations of the involved loss functions.","meta":{"url":"http://arxiv.org/abs/2309.05649v1"},"cats":{"new-dataset":0.0486913174,"dev-research":0.1581928983,"data-quality":0.1117112092}}
{"text":"We show that, in typical situations, the simultaneous GSIB compression requires qualitatively less data to achieve the same errors compared to compressing variables one at a time.","meta":{"url":"http://arxiv.org/abs/2309.05649v1"},"cats":{"new-dataset":0.0615568852,"dev-research":0.1696930747,"data-quality":0.2144708937}}
{"text":"We suggest that this is an example of a more general principle that simultaneous compression is more data efficient than independent compression of each of the input variables.","meta":{"url":"http://arxiv.org/abs/2309.05649v1"},"cats":{"new-dataset":0.0100218342,"dev-research":0.1301003489,"data-quality":0.1076289664}}
{"text":"Cybersecurity attacks are becoming increasingly sophisticated and pose a growing threat to individuals, and private and public sectors.","meta":{"url":"http://arxiv.org/abs/2309.05646v1"},"cats":{"new-dataset":0.0696692093,"dev-research":0.2545173735,"data-quality":0.0670178452}}
{"text":"Distributed Denial of Service attacks are one of the most harmful of these threats in today's internet, disrupting the availability of essential services.","meta":{"url":"http://arxiv.org/abs/2309.05646v1"},"cats":{"new-dataset":0.0286808322,"dev-research":0.1920514296,"data-quality":0.1123184462}}
{"text":"This project presents a novel deep learning-based approach for detecting DDoS attacks in network traffic using the industry-recognized DDoS evaluation dataset from the University of New Brunswick, which contains packet captures from real-time DDoS attacks, creating a broader and more applicable model for the real world.","meta":{"url":"http://arxiv.org/abs/2309.05646v1"},"cats":{"new-dataset":0.3575992571,"dev-research":0.1895966605,"data-quality":0.1448113788}}
{"text":"The algorithm employed in this study exploits the properties of Convolutional Neural Networks (CNN) and common deep learning algorithms to build a novel mitigation technique that classifies benign and malicious traffic.","meta":{"url":"http://arxiv.org/abs/2309.05646v1"},"cats":{"new-dataset":0.0595907815,"dev-research":0.1980719754,"data-quality":0.1854271128}}
{"text":"The proposed model preprocesses the data by extracting packet flows and normalizing them to a fixed length which is fed into a custom architecture containing layers regulating node dropout, normalization, and a sigmoid activation function to out a binary classification.","meta":{"url":"http://arxiv.org/abs/2309.05646v1"},"cats":{"new-dataset":0.0466076474,"dev-research":0.1494424483,"data-quality":0.1330406423}}
{"text":"This allows for the model to process the flows effectively and look for the nodes that contribute to DDoS attacks while dropping the \"noise\" or the distractors.","meta":{"url":"http://arxiv.org/abs/2309.05646v1"},"cats":{"new-dataset":0.0065521991,"dev-research":0.2154103246,"data-quality":0.1093078985}}
{"text":"The results of this study demonstrate the effectiveness of the proposed algorithm in detecting DDOS attacks, achieving an accuracy of .9883 on 2000 unseen flows in network traffic, while being scalable for any network environment.","meta":{"url":"http://arxiv.org/abs/2309.05646v1"},"cats":{"new-dataset":0.0166256339,"dev-research":0.1700050818,"data-quality":0.1405211344}}
{"text":"In this letter, we present a new dataset to advance the state of the art in detecting citrus fruit and accurately estimate yield on trees affected by the Huanglongbing (HLB) disease in orchard environments via imaging.","meta":{"url":"http://arxiv.org/abs/2309.05645v1"},"cats":{"new-dataset":0.3815765213,"dev-research":0.1781839329,"data-quality":0.168117894}}
{"text":"Despite the fact that significant progress has been made in solving the fruit detection problem, the lack of publicly available datasets has complicated direct comparison of results.","meta":{"url":"http://arxiv.org/abs/2309.05645v1"},"cats":{"new-dataset":0.3407179668,"dev-research":0.1375792023,"data-quality":0.2486565114}}
{"text":"For instance, citrus detection has long been of interest in the agricultural research community, yet there is an absence of work, particularly involving public datasets of citrus affected by HLB.","meta":{"url":"http://arxiv.org/abs/2309.05645v1"},"cats":{"new-dataset":0.2114238995,"dev-research":0.1820130958,"data-quality":0.2003108025}}
{"text":"To address this issue, we enhance state-of-the-art object detection methods for use in typical orchard settings.","meta":{"url":"http://arxiv.org/abs/2309.05645v1"},"cats":{"new-dataset":0.0515373863,"dev-research":0.1598384591,"data-quality":0.1636280139}}
{"text":"Concretely, we provide high-resolution images of citrus trees located in an area known to be highly affected by HLB, along with high-quality bounding box annotations of citrus fruit.","meta":{"url":"http://arxiv.org/abs/2309.05645v1"},"cats":{"new-dataset":0.4260876681,"dev-research":0.2115386184,"data-quality":0.2527735818}}
{"text":"Fruit on both the trees and the ground are labeled to allow for identification of fruit location, which contributes to advancements in yield estimation and potential measure of HLB impact via fruit drop.","meta":{"url":"http://arxiv.org/abs/2309.05645v1"},"cats":{"new-dataset":0.0437520965,"dev-research":0.1942691526,"data-quality":0.2066280551}}
{"text":"The dataset consists of over 32,000 bounding box annotations for fruit instances contained in 579 high-resolution images.","meta":{"url":"http://arxiv.org/abs/2309.05645v1"},"cats":{"new-dataset":0.9287010265,"dev-research":0.149899768,"data-quality":0.2355086363}}
{"text":"In summary, our contributions are the following: (i) we introduce a novel dataset along with baseline performance benchmarks on multiple contemporary object detection algorithms, (ii) we show the ability to accurately capture fruit location on tree or on ground, and finally (ii) we present a correlation of our results with yield estimations.","meta":{"url":"http://arxiv.org/abs/2309.05645v1"},"cats":{"new-dataset":0.3036911347,"dev-research":0.1296856318,"data-quality":0.2376471692}}
{"text":"We study elections where voters are faced with the challenge of expressing preferences over an extreme number of issues under consideration.","meta":{"url":"http://arxiv.org/abs/2309.05642v1"},"cats":{"new-dataset":0.0328429892,"dev-research":0.2581013889,"data-quality":0.1712225913}}
{"text":"This is largely motivated by emerging blockchain governance systems, which include voters with different weights and a massive number of community generated proposals.","meta":{"url":"http://arxiv.org/abs/2309.05642v1"},"cats":{"new-dataset":0.0235841846,"dev-research":0.2580806894,"data-quality":0.0882335467}}
{"text":"In such scenarios, it is natural to expect that voters will have incomplete preferences, as they may only be able to evaluate or be confident about a very small proportion of the alternatives.","meta":{"url":"http://arxiv.org/abs/2309.05642v1"},"cats":{"new-dataset":0.0022138615,"dev-research":0.178993914,"data-quality":0.1377761214}}
{"text":"As a result, the election outcome may be significantly affected, leading to suboptimal decisions.","meta":{"url":"http://arxiv.org/abs/2309.05642v1"},"cats":{"new-dataset":0.0040366099,"dev-research":0.2604839982,"data-quality":0.1214627042}}
{"text":"Our central inquiry revolves around whether delegation of ballots to proxies possessing greater expertise or a more comprehensive understanding of the voters' preferences can lead to outcomes with higher legitimacy and enhanced voters' satisfaction in elections where voters submit incomplete preferences.","meta":{"url":"http://arxiv.org/abs/2309.05642v1"},"cats":{"new-dataset":0.0053071493,"dev-research":0.2154487633,"data-quality":0.1285907221}}
{"text":"To explore its aspects, we introduce the following model: potential proxies advertise their ballots over multiple issues, and each voter either delegates to a seemingly attractive proxy or casts a ballot directly.","meta":{"url":"http://arxiv.org/abs/2309.05642v1"},"cats":{"new-dataset":0.0304491735,"dev-research":0.208618311,"data-quality":0.1267533892}}
{"text":"We identify necessary and sufficient conditions that could lead to a socially better outcome by leveraging the participation of proxies.","meta":{"url":"http://arxiv.org/abs/2309.05642v1"},"cats":{"new-dataset":0.0099519233,"dev-research":0.1909972987,"data-quality":0.1189719476}}
{"text":"We accompany our theoretical findings with experiments on instances derived from real datasets.","meta":{"url":"http://arxiv.org/abs/2309.05642v1"},"cats":{"new-dataset":0.1567710205,"dev-research":0.1626584778,"data-quality":0.2994518329}}
{"text":"Overall, our results enhance the understanding of the power of delegation towards improving election outcomes.","meta":{"url":"http://arxiv.org/abs/2309.05642v1"},"cats":{"new-dataset":0.0105951262,"dev-research":0.2573960715,"data-quality":0.1323090738}}
{"text":"We analyze Cumulative Knowledge Processes, introduced by Ben-Eliezer, Mikulincer, Mossel, and Sudan (ITCS 2023), in the setting of \"directed acyclic graphs\", i.e., when new units of knowledge may be derived by combining multiple previous units of knowledge.","meta":{"url":"http://arxiv.org/abs/2309.05638v1"},"cats":{"new-dataset":0.190456116,"dev-research":0.1999088606,"data-quality":0.1306998327}}
{"text":"The main considerations in this model are the role of errors (when new units may be erroneous) and local checking (where a few antecedent units of knowledge are checked when a new unit of knowledge is discovered).","meta":{"url":"http://arxiv.org/abs/2309.05638v1"},"cats":{"new-dataset":0.0151555154,"dev-research":0.2446599008,"data-quality":0.2184179447}}
{"text":"The aforementioned work defined this model but only analyzed an idealized and simplified \"tree-like\" setting, i.e., a setting where new units of knowledge only depended directly on one previously generated unit of knowledge.   ","meta":{"url":"http://arxiv.org/abs/2309.05638v1"},"cats":{"new-dataset":0.0586839114,"dev-research":0.1589240736,"data-quality":0.1303048891}}
{"text":"The main goal of our work is to understand when the general process is safe, i.e., when the effect of errors remains under control.","meta":{"url":"http://arxiv.org/abs/2309.05638v1"},"cats":{"new-dataset":0.0332090515,"dev-research":0.438260791,"data-quality":0.1893797391}}
{"text":"We provide some necessary and some sufficient conditions for safety.","meta":{"url":"http://arxiv.org/abs/2309.05638v1"},"cats":{"new-dataset":0.1811117629,"dev-research":0.2669386038,"data-quality":0.077842361}}
{"text":"As in the earlier work, we demonstrate that the frequency of checking as well as the depth of the checks play a crucial role in determining safety.","meta":{"url":"http://arxiv.org/abs/2309.05638v1"},"cats":{"new-dataset":0.0462042398,"dev-research":0.2714522527,"data-quality":0.1337361154}}
{"text":"A key new parameter in the current work is the $\\textit{combination factor}$ which is the distribution of the number of units $M$ of old knowledge that a new unit of knowledge depends on.","meta":{"url":"http://arxiv.org/abs/2309.05638v1"},"cats":{"new-dataset":0.1227456057,"dev-research":0.1958188734,"data-quality":0.0755840496}}
{"text":"Our results indicate that a large combination factor can compensate for a small depth of checking.","meta":{"url":"http://arxiv.org/abs/2309.05638v1"},"cats":{"new-dataset":0.014897121,"dev-research":0.1678496745,"data-quality":0.1244335128}}
{"text":"The dependency of the safety on the combination factor is far from trivial.","meta":{"url":"http://arxiv.org/abs/2309.05638v1"},"cats":{"new-dataset":0.0067880527,"dev-research":0.1680263846,"data-quality":0.1158602299}}
{"text":"Indeed some of our main results are stated in terms of $\\mathbb{E}\\{1/M\\}$ while others depend on $\\mathbb{E}\\{M\\}$.","meta":{"url":"http://arxiv.org/abs/2309.05638v1"},"cats":{"new-dataset":0.0219763505,"dev-research":0.0923405574,"data-quality":0.135242873}}
{"text":"Many existing systems track aliasing and uniqueness, each with their own trade-off between expressiveness and developer effort.","meta":{"url":"http://arxiv.org/abs/2309.05637v1"},"cats":{"new-dataset":0.0437822619,"dev-research":0.4657576256,"data-quality":0.2779847147}}
{"text":"We propose Latte, a new approach that aims to minimize both the amount of annotations and the complexity of invariants necessary for reasoning about aliasing in an object-oriented language with mutation.","meta":{"url":"http://arxiv.org/abs/2309.05637v1"},"cats":{"new-dataset":0.0813802995,"dev-research":0.3456507163,"data-quality":0.3905962994}}
{"text":"Our approach only requires annotations for parameters and fields, while annotations for local variables are inferred.","meta":{"url":"http://arxiv.org/abs/2309.05637v1"},"cats":{"new-dataset":0.0515609024,"dev-research":0.2238826914,"data-quality":0.4259315978}}
{"text":"Furthermore, it relaxes uniqueness to allow aliasing among local variables, as long as this aliasing can be precisely determined.","meta":{"url":"http://arxiv.org/abs/2309.05637v1"},"cats":{"new-dataset":0.003744784,"dev-research":0.2112268906,"data-quality":0.1835140551}}
{"text":"This enables support for destructive reads without changes to the language or its run-time semantics.","meta":{"url":"http://arxiv.org/abs/2309.05637v1"},"cats":{"new-dataset":0.0282844028,"dev-research":0.3120385665,"data-quality":0.263898451}}
{"text":"Despite this simplicity, we show how this design can still be used for tracking uniqueness and aliasing in a local sequential setting, with practical applications, such as modeling a stack.","meta":{"url":"http://arxiv.org/abs/2309.05637v1"},"cats":{"new-dataset":0.127432907,"dev-research":0.2277650294,"data-quality":0.1716788193}}
{"text":"A method for estimating the incident sound field inside a region containing scattering objects is proposed.","meta":{"url":"http://arxiv.org/abs/2309.05634v1"},"cats":{"new-dataset":0.0881909791,"dev-research":0.1821025048,"data-quality":0.1788816207}}
{"text":"The sound field estimation method has various applications, such as spatial audio capturing and spatial active noise control; however, most existing methods do not take into account the presence of scatterers within the target estimation region.","meta":{"url":"http://arxiv.org/abs/2309.05634v1"},"cats":{"new-dataset":0.0422340289,"dev-research":0.1826036292,"data-quality":0.1728373406}}
{"text":"Although several techniques exist that employ knowledge or measurements of the properties of the scattering objects, it is usually difficult to obtain them precisely in advance, and their properties may change during the estimation process.","meta":{"url":"http://arxiv.org/abs/2309.05634v1"},"cats":{"new-dataset":0.0108028499,"dev-research":0.1428036199,"data-quality":0.1151058517}}
{"text":"Our proposed method is based on the kernel ridge regression of the incident field, with a separation from the scattering field represented by a spherical wave function expansion, thus eliminating the need for prior modeling or measurements of the scatterers.","meta":{"url":"http://arxiv.org/abs/2309.05634v1"},"cats":{"new-dataset":0.0844369396,"dev-research":0.1777703871,"data-quality":0.1138144916}}
{"text":"Moreover, we introduce a weighting matrix to induce smoothness of the scattering field in the angular direction, which alleviates the effect of the truncation order of the expansion coefficients on the estimation accuracy.","meta":{"url":"http://arxiv.org/abs/2309.05634v1"},"cats":{"new-dataset":0.0079414135,"dev-research":0.1231138548,"data-quality":0.1292255788}}
{"text":"Experimental results indicate that the proposed method achieves a higher level of estimation accuracy than the kernel ridge regression without separation.","meta":{"url":"http://arxiv.org/abs/2309.05634v1"},"cats":{"new-dataset":0.0078761927,"dev-research":0.1254697542,"data-quality":0.2025677796}}
{"text":"In this paper, we propose a source coding scheme that represents data from unknown distributions through frequency and support information.","meta":{"url":"http://arxiv.org/abs/2309.05633v1"},"cats":{"new-dataset":0.2220734172,"dev-research":0.2010114119,"data-quality":0.2595477607}}
{"text":"Existing encoding schemes often compress data by sacrificing computational efficiency or by assuming the data follows a known distribution.","meta":{"url":"http://arxiv.org/abs/2309.05633v1"},"cats":{"new-dataset":0.0232334943,"dev-research":0.1403759601,"data-quality":0.1474437417}}
{"text":"We take advantage of the structure that arises within the spatial representation and utilize it to encode run-lengths within this representation using Golomb coding.","meta":{"url":"http://arxiv.org/abs/2309.05633v1"},"cats":{"new-dataset":0.0750913377,"dev-research":0.1831958584,"data-quality":0.0636295079}}
{"text":"Through theoretical analysis, we show that our scheme yields an overall bit rate that nears entropy without a computationally complex encoding algorithm and verify these results through numerical experiments.","meta":{"url":"http://arxiv.org/abs/2309.05633v1"},"cats":{"new-dataset":0.0223822063,"dev-research":0.1194188459,"data-quality":0.0954148473}}
{"text":"This article presents MAPS$^2$ : a distributed algorithm that allows multi-robot systems to deliver coupled tasks expressed as Signal Temporal Logic (STL) constraints.","meta":{"url":"http://arxiv.org/abs/2309.05632v1"},"cats":{"new-dataset":0.1153862435,"dev-research":0.2114494942,"data-quality":0.0390797775}}
{"text":"Classical control theoretical tools addressing STL constraints either adopt a limited fragment of the STL formula or require approximations of min/max operators, whereas works maximising robustness through optimisation-based methods often suffer from local minima, relaxing any completeness arguments due to the NP-hard nature of the problem.","meta":{"url":"http://arxiv.org/abs/2309.05632v1"},"cats":{"new-dataset":0.0055033648,"dev-research":0.2276178408,"data-quality":0.0882358806}}
{"text":"Endowed with probabilistic guarantees, MAPS$^2$ provides an anytime algorithm that iteratively improves the robots' trajectories.","meta":{"url":"http://arxiv.org/abs/2309.05632v1"},"cats":{"new-dataset":0.0448404332,"dev-research":0.1851286107,"data-quality":0.0474625336}}
{"text":"The algorithm selectively imposes spatial constraints by taking advantage of the temporal properties of the STL.","meta":{"url":"http://arxiv.org/abs/2309.05632v1"},"cats":{"new-dataset":0.0110598237,"dev-research":0.1738522158,"data-quality":0.0546017319}}
{"text":"The algorithm is distributed, in the sense that each robot calculates its trajectory by communicating only with its immediate neighbours as defined via a communication graph.","meta":{"url":"http://arxiv.org/abs/2309.05632v1"},"cats":{"new-dataset":0.0586519882,"dev-research":0.1306305888,"data-quality":0.0608235364}}
{"text":"We illustrate the efficiency of MAPS$^2$ by conducting extensive simulation and experimental studies, verifying the generation of STL satisfying trajectories.","meta":{"url":"http://arxiv.org/abs/2309.05632v1"},"cats":{"new-dataset":0.0337046482,"dev-research":0.1354722244,"data-quality":0.0565758511}}
{"text":"In this paper, we establish a task-oriented cross-system design framework to minimize the required packet rate for timely and accurate modeling of a real-world robotic arm in the Metaverse, where sensing, communication, prediction, control, and rendering are considered.","meta":{"url":"http://arxiv.org/abs/2309.05622v1"},"cats":{"new-dataset":0.0754017619,"dev-research":0.1739388668,"data-quality":0.0434035017}}
{"text":"To optimize a scheduling policy and prediction horizons, we design a Constraint Proximal Policy Optimization(C-PPO) algorithm by integrating domain knowledge from relevant systems into the advanced reinforcement learning algorithm, Proximal Policy Optimization(PPO).","meta":{"url":"http://arxiv.org/abs/2309.05622v1"},"cats":{"new-dataset":0.0981075627,"dev-research":0.2291319036,"data-quality":0.0548745389}}
{"text":"Specifically, the Jacobian matrix for analyzing the motion of the robotic arm is included in the state of the C-PPO algorithm, and the Conditional Value-at-Risk(CVaR) of the state-value function characterizing the long-term modeling error is adopted in the constraint.","meta":{"url":"http://arxiv.org/abs/2309.05622v1"},"cats":{"new-dataset":0.0190025805,"dev-research":0.1896866881,"data-quality":0.071176902}}
{"text":"Besides, the policy is represented by a two-branch neural network determining the scheduling policy and the prediction horizons, respectively.","meta":{"url":"http://arxiv.org/abs/2309.05622v1"},"cats":{"new-dataset":0.0366424735,"dev-research":0.1529912682,"data-quality":0.0590960227}}
{"text":"To evaluate our algorithm, we build a prototype including a real-world robotic arm and its digital model in the Metaverse.","meta":{"url":"http://arxiv.org/abs/2309.05622v1"},"cats":{"new-dataset":0.1543526326,"dev-research":0.1497564996,"data-quality":0.0640938133}}
{"text":"The experimental results indicate that domain knowledge helps to reduce the convergence time and the required packet rate by up to 50%, and the cross-system design framework outperforms a baseline framework in terms of the required packet rate and the tail distribution of the modeling error.","meta":{"url":"http://arxiv.org/abs/2309.05622v1"},"cats":{"new-dataset":0.0177113207,"dev-research":0.1919081212,"data-quality":0.0782377734}}
{"text":"The highly heterogeneous ecosystem of Next Generation (NextG) wireless communication systems calls for novel networking paradigms where functionalities and operations can be dynamically and optimally reconfigured in real time to adapt to changing traffic conditions and satisfy stringent and diverse Quality of Service (QoS) demands.","meta":{"url":"http://arxiv.org/abs/2309.05621v1"},"cats":{"new-dataset":0.025196388,"dev-research":0.151170647,"data-quality":0.0505689309}}
{"text":"Open Radio Access Network (RAN) technologies, and specifically those being standardized by the O-RAN Alliance, make it possible to integrate network intelligence into the once monolithic RAN via intelligent applications, namely, xApps and rApps.","meta":{"url":"http://arxiv.org/abs/2309.05621v1"},"cats":{"new-dataset":0.0305810484,"dev-research":0.2036363268,"data-quality":0.0944238428}}
{"text":"These applications enable flexible control of the network resources and functionalities, network management, and orchestration through data-driven control loops.","meta":{"url":"http://arxiv.org/abs/2309.05621v1"},"cats":{"new-dataset":0.0624165536,"dev-research":0.2576624056,"data-quality":0.0541830512}}
{"text":"Despite recent work demonstrating the effectiveness of Deep Reinforcement Learning (DRL) in controlling O-RAN systems, how to design these solutions in a way that does not create conflicts and unfair resource allocation policies is still an open challenge.","meta":{"url":"http://arxiv.org/abs/2309.05621v1"},"cats":{"new-dataset":0.1135526856,"dev-research":0.2100777757,"data-quality":0.0833847514}}
{"text":"In this paper, we perform a comparative analysis where we dissect the impact of different DRL-based xApp designs on network performance.","meta":{"url":"http://arxiv.org/abs/2309.05621v1"},"cats":{"new-dataset":0.0265889031,"dev-research":0.3028436953,"data-quality":0.0848647211}}
{"text":"Specifically, we benchmark 12 different xApps that embed DRL agents trained using different reward functions, with different action spaces and with the ability to hierarchically control different network parameters.","meta":{"url":"http://arxiv.org/abs/2309.05621v1"},"cats":{"new-dataset":0.1123052909,"dev-research":0.1815457771,"data-quality":0.0864466304}}
{"text":"We prototype and evaluate these xApps on Colosseum, the world's largest O-RAN-compliant wireless network emulator with hardware-in-the-loop.","meta":{"url":"http://arxiv.org/abs/2309.05621v1"},"cats":{"new-dataset":0.1412283112,"dev-research":0.1869817002,"data-quality":0.0737328761}}
{"text":"We share the lessons learned and discuss our experimental results, which demonstrate how certain design choices deliver the highest performance while others might result in a competitive behavior between different classes of traffic with similar objectives.","meta":{"url":"http://arxiv.org/abs/2309.05621v1"},"cats":{"new-dataset":0.0083081575,"dev-research":0.1496261185,"data-quality":0.0882011769}}
{"text":"Large language models (LLMs) have demonstrated significant capability to generalize across a large number of NLP tasks.","meta":{"url":"http://arxiv.org/abs/2309.05619v1"},"cats":{"new-dataset":0.0347427178,"dev-research":0.1477902411,"data-quality":0.1754976796}}
{"text":"For industry applications, it is imperative to assess the performance of the LLM on unlabeled production data from time to time to validate for a real-world setting.","meta":{"url":"http://arxiv.org/abs/2309.05619v1"},"cats":{"new-dataset":0.0934073349,"dev-research":0.1708913484,"data-quality":0.204322186}}
{"text":"Human labeling to assess model error requires considerable expense and time delay.","meta":{"url":"http://arxiv.org/abs/2309.05619v1"},"cats":{"new-dataset":0.0203249919,"dev-research":0.4277561625,"data-quality":0.4800637742}}
{"text":"Here we demonstrate that ensemble disagreement scores work well as a proxy for human labeling for language models in zero-shot, few-shot, and fine-tuned settings, per our evaluation on keyphrase extraction (KPE) task.","meta":{"url":"http://arxiv.org/abs/2309.05619v1"},"cats":{"new-dataset":0.3207438515,"dev-research":0.2349480189,"data-quality":0.5051955656}}
{"text":"We measure fidelity of the results by comparing to true error measured from human labeled ground truth.","meta":{"url":"http://arxiv.org/abs/2309.05619v1"},"cats":{"new-dataset":0.0191513962,"dev-research":0.2087627907,"data-quality":0.4671176361}}
{"text":"We contrast with the alternative of using another LLM as a source of machine labels, or silver labels.","meta":{"url":"http://arxiv.org/abs/2309.05619v1"},"cats":{"new-dataset":0.0197448053,"dev-research":0.1498339389,"data-quality":0.3707681631}}
{"text":"Results across various languages and domains show disagreement scores provide a better estimation of model performance with mean average error (MAE) as low as 0.4% and on average 13.8% better than using silver labels.","meta":{"url":"http://arxiv.org/abs/2309.05619v1"},"cats":{"new-dataset":0.0210867755,"dev-research":0.250410411,"data-quality":0.5005050324}}
{"text":"We present GeGnn, a learning-based method for computing the approximate geodesic distance between two arbitrary points on discrete polyhedra surfaces with constant time complexity after fast precomputation.","meta":{"url":"http://arxiv.org/abs/2309.05613v1"},"cats":{"new-dataset":0.0576830337,"dev-research":0.1750637855,"data-quality":0.0741179809}}
{"text":"Previous relevant methods either focus on computing the geodesic distance between a single source and all destinations, which has linear complexity at least or require a long precomputation time.","meta":{"url":"http://arxiv.org/abs/2309.05613v1"},"cats":{"new-dataset":0.0140966832,"dev-research":0.1586362928,"data-quality":0.0684745938}}
{"text":"Our key idea is to train a graph neural network to embed an input mesh into a high-dimensional embedding space and compute the geodesic distance between a pair of points using the corresponding embedding vectors and a lightweight decoding function.","meta":{"url":"http://arxiv.org/abs/2309.05613v1"},"cats":{"new-dataset":0.1588640012,"dev-research":0.1452411667,"data-quality":0.1452891026}}
{"text":"To facilitate the learning of the embedding, we propose novel graph convolution and graph pooling modules that incorporate local geodesic information and are verified to be much more effective than previous designs.","meta":{"url":"http://arxiv.org/abs/2309.05613v1"},"cats":{"new-dataset":0.081331552,"dev-research":0.1515918782,"data-quality":0.2169989037}}
{"text":"After training, our method requires only one forward pass of the network per mesh as precomputation.","meta":{"url":"http://arxiv.org/abs/2309.05613v1"},"cats":{"new-dataset":0.006807321,"dev-research":0.1367643259,"data-quality":0.0826270245}}
{"text":"Then, we can compute the geodesic distance between a pair of points using our decoding function, which requires only several matrix multiplications and can be massively parallelized on GPUs.","meta":{"url":"http://arxiv.org/abs/2309.05613v1"},"cats":{"new-dataset":0.0162880176,"dev-research":0.0998749927,"data-quality":0.0611740861}}
{"text":"We verify the efficiency and effectiveness of our method on ShapeNet and demonstrate that our method is faster than existing methods by orders of magnitude while achieving comparable or better accuracy.","meta":{"url":"http://arxiv.org/abs/2309.05613v1"},"cats":{"new-dataset":0.0718581645,"dev-research":0.2457182916,"data-quality":0.1737768444}}
{"text":"Additionally, our method exhibits robustness on noisy and incomplete meshes and strong generalization ability on out-of-distribution meshes.","meta":{"url":"http://arxiv.org/abs/2309.05613v1"},"cats":{"new-dataset":0.0194323556,"dev-research":0.1725026107,"data-quality":0.1921813783}}
{"text":"The code and pretrained model can be found on https://github.com/IntelligentGeometry/GeGnn.","meta":{"url":"http://arxiv.org/abs/2309.05613v1"},"cats":{"new-dataset":0.1792114335,"dev-research":0.1336012467,"data-quality":0.091330982}}
{"text":"Most current approaches for protecting privacy in machine learning (ML) assume that models exist in a vacuum, when in reality, ML models are part of larger systems that include components for training data filtering, output monitoring, and more.","meta":{"url":"http://arxiv.org/abs/2309.05610v1"},"cats":{"new-dataset":0.025424135,"dev-research":0.1579545124,"data-quality":0.1600944426}}
{"text":"In this work, we introduce privacy side channels: attacks that exploit these system-level components to extract private information at far higher rates than is otherwise possible for standalone models.","meta":{"url":"http://arxiv.org/abs/2309.05610v1"},"cats":{"new-dataset":0.0760165647,"dev-research":0.1653342311,"data-quality":0.1190791118}}
{"text":"We propose four categories of side channels that span the entire ML lifecycle (training data filtering, input preprocessing, output post-processing, and query filtering) and allow for either enhanced membership inference attacks or even novel threats such as extracting users' test queries.","meta":{"url":"http://arxiv.org/abs/2309.05610v1"},"cats":{"new-dataset":0.1046802404,"dev-research":0.2223391106,"data-quality":0.1549003961}}
{"text":"For example, we show that deduplicating training data before applying differentially-private training creates a side-channel that completely invalidates any provable privacy guarantees.","meta":{"url":"http://arxiv.org/abs/2309.05610v1"},"cats":{"new-dataset":0.0779600601,"dev-research":0.1771844029,"data-quality":0.2236255172}}
{"text":"Moreover, we show that systems which block language models from regenerating training data can be exploited to allow exact reconstruction of private keys contained in the training set -- even if the model did not memorize these keys.","meta":{"url":"http://arxiv.org/abs/2309.05610v1"},"cats":{"new-dataset":0.1208668826,"dev-research":0.1905591952,"data-quality":0.2718154924}}
{"text":"Taken together, our results demonstrate the need for a holistic, end-to-end privacy analysis of machine learning.","meta":{"url":"http://arxiv.org/abs/2309.05610v1"},"cats":{"new-dataset":0.1317084996,"dev-research":0.1668633967,"data-quality":0.1621259957}}
{"text":"Multimodal stock trading volume movement prediction with stock-related news is one of the fundamental problems in the financial area.","meta":{"url":"http://arxiv.org/abs/2309.05608v1"},"cats":{"new-dataset":0.0612907201,"dev-research":0.1470860154,"data-quality":0.0943468424}}
{"text":"Existing multimodal works that train models from scratch face the problem of lacking universal knowledge when modeling financial news.","meta":{"url":"http://arxiv.org/abs/2309.05608v1"},"cats":{"new-dataset":0.2002558773,"dev-research":0.1937319314,"data-quality":0.1734514395}}
{"text":"In addition, the models ability may be limited by the lack of domain-related knowledge due to insufficient data in the datasets.","meta":{"url":"http://arxiv.org/abs/2309.05608v1"},"cats":{"new-dataset":0.0193603326,"dev-research":0.1721393741,"data-quality":0.1298975211}}
{"text":"To handle this issue, we propose the Prompt-based MUltimodal Stock volumE prediction model (ProMUSE) to process text and time series modalities.","meta":{"url":"http://arxiv.org/abs/2309.05608v1"},"cats":{"new-dataset":0.1537254864,"dev-research":0.1194064892,"data-quality":0.1343971782}}
{"text":"We use pre-trained language models for better comprehension of financial news and adopt prompt learning methods to leverage their capability in universal knowledge to model textual information.","meta":{"url":"http://arxiv.org/abs/2309.05608v1"},"cats":{"new-dataset":0.0916738539,"dev-research":0.1872741896,"data-quality":0.2633451659}}
{"text":"Besides, simply fusing two modalities can cause harm to the unimodal representations.","meta":{"url":"http://arxiv.org/abs/2309.05608v1"},"cats":{"new-dataset":0.003312473,"dev-research":0.1865487516,"data-quality":0.2407830647}}
{"text":"Thus, we propose a novel cross-modality contrastive alignment while reserving the unimodal heads beside the fusion head to mitigate this problem.","meta":{"url":"http://arxiv.org/abs/2309.05608v1"},"cats":{"new-dataset":0.0569164691,"dev-research":0.148760337,"data-quality":0.1380124799}}
{"text":"Extensive experiments demonstrate that our proposed ProMUSE outperforms existing baselines.","meta":{"url":"http://arxiv.org/abs/2309.05608v1"},"cats":{"new-dataset":0.0372347527,"dev-research":0.2024627309,"data-quality":0.1439542074}}
{"text":"Comprehensive analyses further validate the effectiveness of our architecture compared to potential variants and learning mechanisms.","meta":{"url":"http://arxiv.org/abs/2309.05608v1"},"cats":{"new-dataset":0.0096285274,"dev-research":0.2125530499,"data-quality":0.0642012807}}
{"text":"Answering multi-hop reasoning questions requires retrieving and synthesizing information from diverse sources.","meta":{"url":"http://arxiv.org/abs/2309.05605v1"},"cats":{"new-dataset":0.0341133296,"dev-research":0.1830186246,"data-quality":0.0819585674}}
{"text":"Large Language Models (LLMs) struggle to perform such reasoning consistently.","meta":{"url":"http://arxiv.org/abs/2309.05605v1"},"cats":{"new-dataset":0.0739094308,"dev-research":0.1478224,"data-quality":0.2457183731}}
{"text":"Here we propose an approach to pinpoint and rectify multi-hop reasoning failures through targeted memory injections on LLM attention heads.","meta":{"url":"http://arxiv.org/abs/2309.05605v1"},"cats":{"new-dataset":0.0376969373,"dev-research":0.2315411189,"data-quality":0.2341328934}}
{"text":"First, we analyze the per-layer activations of GPT-2 models in response to single and multi-hop prompts.","meta":{"url":"http://arxiv.org/abs/2309.05605v1"},"cats":{"new-dataset":0.0102555773,"dev-research":0.0944968654,"data-quality":0.0774545192}}
{"text":"We then propose a mechanism that allows users to inject pertinent prompt-specific information, which we refer to as \"memories,\" at critical LLM locations during inference.","meta":{"url":"http://arxiv.org/abs/2309.05605v1"},"cats":{"new-dataset":0.0289288781,"dev-research":0.1972153511,"data-quality":0.1408206156}}
{"text":"By thus enabling the LLM to incorporate additional relevant information during inference, we enhance the quality of multi-hop prompt completions.","meta":{"url":"http://arxiv.org/abs/2309.05605v1"},"cats":{"new-dataset":0.0125988364,"dev-research":0.1467762526,"data-quality":0.1384670603}}
{"text":"We show empirically that a simple, efficient, and targeted memory injection into a key attention layer can often increase the probability of the desired next token in multi-hop tasks, by up to 424%.","meta":{"url":"http://arxiv.org/abs/2309.05605v1"},"cats":{"new-dataset":0.0280423562,"dev-research":0.1588316588,"data-quality":0.0990987863}}
{"text":"Current digital computers are about to hit basic physical boundaries with respect to integration density, clock frequencies, and particularly energy consumption.","meta":{"url":"http://arxiv.org/abs/2309.05598v1"},"cats":{"new-dataset":0.0157133554,"dev-research":0.2989176636,"data-quality":0.0734247744}}
{"text":"This requires the application of new computing paradigms, such as quantum and analog computing in the near future.","meta":{"url":"http://arxiv.org/abs/2309.05598v1"},"cats":{"new-dataset":0.0115369541,"dev-research":0.1487051304,"data-quality":0.0441217509}}
{"text":"Although neither quantum nor analog computer are general purpose computers they will play an important role as co-processors to offload certain classes of compute intensive tasks from classic digital computers, thereby not only reducing run time but also and foremost power consumption.   ","meta":{"url":"http://arxiv.org/abs/2309.05598v1"},"cats":{"new-dataset":0.004023354,"dev-research":0.2147858564,"data-quality":0.0479644819}}
{"text":"In this work, we describe a random walk approach to the solution of certain types of partial differential equations which is well suited for combinations of digital and analog computers (hybrid computers).","meta":{"url":"http://arxiv.org/abs/2309.05598v1"},"cats":{"new-dataset":0.0849382035,"dev-research":0.1330012787,"data-quality":0.0674485361}}
{"text":"The experiments were performed on an Analog Paradigm Model-1 analog computer attached to a digital computer by means of a hybrid interface.","meta":{"url":"http://arxiv.org/abs/2309.05598v1"},"cats":{"new-dataset":0.0068948859,"dev-research":0.1605311391,"data-quality":0.0978930218}}
{"text":"At the end we give some estimates of speedups and power consumption obtainable by using future analog computers on chip.","meta":{"url":"http://arxiv.org/abs/2309.05598v1"},"cats":{"new-dataset":0.0341799186,"dev-research":0.2116567684,"data-quality":0.0836979909}}
{"text":"This paper delves into the intersection of computational theory and music, examining the concept of undecidability and its significant, yet overlooked, implications within the realm of modern music composition and production.","meta":{"url":"http://arxiv.org/abs/2309.05595v1"},"cats":{"new-dataset":0.0325271303,"dev-research":0.1957060013,"data-quality":0.2060550889}}
{"text":"It posits that undecidability, a principle traditionally associated with theoretical computer science, extends its relevance to the music industry.","meta":{"url":"http://arxiv.org/abs/2309.05595v1"},"cats":{"new-dataset":0.0041380606,"dev-research":0.2250920448,"data-quality":0.2014516359}}
{"text":"The study adopts a multidimensional approach, focusing on five key areas: (1) the Turing completeness of Ableton, a widely used digital audio workstation, (2) the undecidability of satisfiability in sound creation utilizing an array of effects, (3) the undecidability of constraints on polymeters in musical compositions, (4) the undecidability of satisfiability in just intonation harmony constraints, and (5) the undecidability of \"new ordering systems\".","meta":{"url":"http://arxiv.org/abs/2309.05595v1"},"cats":{"new-dataset":0.0307397478,"dev-research":0.1778780501,"data-quality":0.1383016574}}
{"text":"In addition to providing theoretical proof for these assertions, the paper elucidates the practical relevance of these concepts for practitioners outside the field of theoretical computer science.","meta":{"url":"http://arxiv.org/abs/2309.05595v1"},"cats":{"new-dataset":0.0038017339,"dev-research":0.2207727365,"data-quality":0.1026345905}}
{"text":"The ultimate aim is to foster a new understanding of undecidability in music, highlighting its broader applicability and potential to influence contemporary computer-assisted (and traditional) music making.","meta":{"url":"http://arxiv.org/abs/2309.05595v1"},"cats":{"new-dataset":0.015330152,"dev-research":0.2237273819,"data-quality":0.2770280564}}
{"text":"Temporal action detection (TAD) aims to detect all action boundaries and their corresponding categories in an untrimmed video.","meta":{"url":"http://arxiv.org/abs/2309.05590v1"},"cats":{"new-dataset":0.1268691918,"dev-research":0.1626705581,"data-quality":0.1073212521}}
{"text":"The unclear boundaries of actions in videos often result in imprecise predictions of action boundaries by existing methods.","meta":{"url":"http://arxiv.org/abs/2309.05590v1"},"cats":{"new-dataset":0.0339468484,"dev-research":0.2232738363,"data-quality":0.1870479091}}
{"text":"To resolve this issue, we propose a one-stage framework named TriDet.","meta":{"url":"http://arxiv.org/abs/2309.05590v1"},"cats":{"new-dataset":0.1746846743,"dev-research":0.2725798005,"data-quality":0.1394456238}}
{"text":"First, we propose a Trident-head to model the action boundary via an estimated relative probability distribution around the boundary.","meta":{"url":"http://arxiv.org/abs/2309.05590v1"},"cats":{"new-dataset":0.0713691597,"dev-research":0.1137383349,"data-quality":0.0707301256}}
{"text":"Then, we analyze the rank-loss problem (i.e. instant discriminability deterioration) in transformer-based methods and propose an efficient scalable-granularity perception (SGP) layer to mitigate this issue.","meta":{"url":"http://arxiv.org/abs/2309.05590v1"},"cats":{"new-dataset":0.0079136237,"dev-research":0.1508569683,"data-quality":0.2045877065}}
{"text":"To further push the limit of instant discriminability in the video backbone, we leverage the strong representation capability of pretrained large models and investigate their performance on TAD.","meta":{"url":"http://arxiv.org/abs/2309.05590v1"},"cats":{"new-dataset":0.1564004025,"dev-research":0.1254935941,"data-quality":0.1359166771}}
{"text":"Last, considering the adequate spatial-temporal context for classification, we design a decoupled feature pyramid network with separate feature pyramids to incorporate rich spatial context from the large model for localization.","meta":{"url":"http://arxiv.org/abs/2309.05590v1"},"cats":{"new-dataset":0.1822547026,"dev-research":0.2281229596,"data-quality":0.1550058693}}
{"text":"Experimental results demonstrate the robustness of TriDet and its state-of-the-art performance on multiple TAD datasets, including hierarchical (multilabel) TAD datasets.","meta":{"url":"http://arxiv.org/abs/2309.05590v1"},"cats":{"new-dataset":0.6895724516,"dev-research":0.1880358289,"data-quality":0.3280717702}}
{"text":"Understanding and mitigating political bias in online social media platforms are crucial tasks to combat misinformation and echo chamber effects.","meta":{"url":"http://arxiv.org/abs/2309.05589v1"},"cats":{"new-dataset":0.0110297036,"dev-research":0.2331414711,"data-quality":0.3470964625}}
{"text":"However, characterizing political bias temporally using computational methods presents challenges due to the high frequency of noise in social media datasets.","meta":{"url":"http://arxiv.org/abs/2309.05589v1"},"cats":{"new-dataset":0.1569658068,"dev-research":0.2194760442,"data-quality":0.295091796}}
{"text":"While existing research has explored various approaches to political bias characterization, the ability to forecast political bias and anticipate how political conversations might evolve in the near future has not been extensively studied.","meta":{"url":"http://arxiv.org/abs/2309.05589v1"},"cats":{"new-dataset":0.0227682853,"dev-research":0.2089120723,"data-quality":0.1403665082}}
{"text":"In this paper, we propose a heuristic approach to classify social media posts into five distinct political leaning categories.","meta":{"url":"http://arxiv.org/abs/2309.05589v1"},"cats":{"new-dataset":0.0509791964,"dev-research":0.2200237307,"data-quality":0.2188276752}}
{"text":"Since there is a lack of prior work on forecasting political bias, we conduct an in-depth analysis of existing baseline models to identify which model best fits to forecast political leaning time series.","meta":{"url":"http://arxiv.org/abs/2309.05589v1"},"cats":{"new-dataset":0.0704372231,"dev-research":0.1579658396,"data-quality":0.0651298464}}
{"text":"Our approach involves utilizing existing time series forecasting models on two social media datasets with different political ideologies, specifically Twitter and Gab.","meta":{"url":"http://arxiv.org/abs/2309.05589v1"},"cats":{"new-dataset":0.251713975,"dev-research":0.1295104512,"data-quality":0.1123707921}}
{"text":"Through our experiments and analyses, we seek to shed light on the challenges and opportunities in forecasting political bias in social media platforms.","meta":{"url":"http://arxiv.org/abs/2309.05589v1"},"cats":{"new-dataset":0.0181167686,"dev-research":0.1582780687,"data-quality":0.1803989033}}
{"text":"Ultimately, our work aims to pave the way for developing more effective strategies to mitigate the negative impact of political bias in the digital realm.","meta":{"url":"http://arxiv.org/abs/2309.05589v1"},"cats":{"new-dataset":0.0247829496,"dev-research":0.3097988008,"data-quality":0.182036149}}
{"text":"Probabilistic model checking can provide formal guarantees on the behavior of stochastic models relating to a wide range of quantitative properties, such as runtime, energy consumption or cost.","meta":{"url":"http://arxiv.org/abs/2309.05584v1"},"cats":{"new-dataset":0.0163089313,"dev-research":0.2811801784,"data-quality":0.1090714333}}
{"text":"But decision making is typically with respect to the expected value of these quantities, which can mask important aspects of the full probability distribution such as the possibility of high-risk, low-probability events or multimodalities.","meta":{"url":"http://arxiv.org/abs/2309.05584v1"},"cats":{"new-dataset":0.003863614,"dev-research":0.2656095849,"data-quality":0.0886895304}}
{"text":"We propose a distributional extension of probabilistic model checking, applicable to discrete-time Markov chains (DTMCs) and Markov decision processes (MDPs).","meta":{"url":"http://arxiv.org/abs/2309.05584v1"},"cats":{"new-dataset":0.0191186008,"dev-research":0.2178632262,"data-quality":0.105914795}}
{"text":"We formulate distributional queries, which can reason about a variety of distributional measures, such as variance, value-at-risk or conditional value-at-risk, for the accumulation of reward until a co-safe linear temporal logic formula is satisfied.","meta":{"url":"http://arxiv.org/abs/2309.05584v1"},"cats":{"new-dataset":0.0477864373,"dev-research":0.1516339558,"data-quality":0.0733417677}}
{"text":"For DTMCs, we propose a method to compute the full distribution to an arbitrary level of precision, based on a graph analysis and forward analysis of the model.","meta":{"url":"http://arxiv.org/abs/2309.05584v1"},"cats":{"new-dataset":0.090797966,"dev-research":0.1149927486,"data-quality":0.1404139651}}
{"text":"For MDPs, we approximate the optimal policy with respect to expected value or conditional value-at-risk using distributional value iteration.","meta":{"url":"http://arxiv.org/abs/2309.05584v1"},"cats":{"new-dataset":0.0263945443,"dev-research":0.1176518611,"data-quality":0.0964626616}}
{"text":"We implement our techniques and investigate their performance and scalability across a range of benchmark models.","meta":{"url":"http://arxiv.org/abs/2309.05584v1"},"cats":{"new-dataset":0.0498607014,"dev-research":0.1379517205,"data-quality":0.0907682919}}
{"text":"Experimental results demonstrate that our techniques can be successfully applied to check various distributional properties of large probabilistic models.","meta":{"url":"http://arxiv.org/abs/2309.05584v1"},"cats":{"new-dataset":0.0361482434,"dev-research":0.1407416008,"data-quality":0.1398577404}}
{"text":"This paper introduces the research effort of an undergraduate research team in realizing robot localization.","meta":{"url":"http://arxiv.org/abs/2309.05583v1"},"cats":{"new-dataset":0.064709464,"dev-research":0.2856967156,"data-quality":0.120859055}}
{"text":"More specifically, the undergraduate research team developed and tested wall-following software that allowed a ground robot Roombas to independently find their positions within a defined space.","meta":{"url":"http://arxiv.org/abs/2309.05583v1"},"cats":{"new-dataset":0.1321550146,"dev-research":0.3057178638,"data-quality":0.0592204192}}
{"text":"The software also allows a robot to send its localized position to other Roombas, so that each Roomba knows its relative location to realize robot cooperation.","meta":{"url":"http://arxiv.org/abs/2309.05583v1"},"cats":{"new-dataset":0.0894718693,"dev-research":0.3365071639,"data-quality":0.0687354859}}
{"text":"We introduce a simple but effective method for managing risk in model-based reinforcement learning with trajectory sampling that involves probabilistic safety constraints and balancing of optimism in the face of epistemic uncertainty and pessimism in the face of aleatoric uncertainty of an ensemble of stochastic neural networks.","meta":{"url":"http://arxiv.org/abs/2309.05582v1"},"cats":{"new-dataset":0.0371997733,"dev-research":0.2203089673,"data-quality":0.1524106681}}
{"text":"Various experiments indicate that the separation of uncertainties is essential to performing well with data-driven MPC approaches in uncertain and safety-critical control environments.","meta":{"url":"http://arxiv.org/abs/2309.05582v1"},"cats":{"new-dataset":0.0502467319,"dev-research":0.2910434654,"data-quality":0.1406620598}}
{"text":"Point-, voxel-, and range-views are three representative forms of point clouds.","meta":{"url":"http://arxiv.org/abs/2309.05573v1"},"cats":{"new-dataset":0.1556497501,"dev-research":0.1624527737,"data-quality":0.0770410162}}
{"text":"All of them have accurate 3D measurements but lack color and texture information.","meta":{"url":"http://arxiv.org/abs/2309.05573v1"},"cats":{"new-dataset":0.2221775625,"dev-research":0.132145025,"data-quality":0.1393229218}}
{"text":"RGB images are a natural complement to these point cloud views and fully utilizing the comprehensive information of them benefits more robust perceptions.","meta":{"url":"http://arxiv.org/abs/2309.05573v1"},"cats":{"new-dataset":0.1196409065,"dev-research":0.1732518526,"data-quality":0.14998515}}
{"text":"In this paper, we present a unified multi-modal LiDAR segmentation network, termed UniSeg, which leverages the information of RGB images and three views of the point cloud, and accomplishes semantic segmentation and panoptic segmentation simultaneously.","meta":{"url":"http://arxiv.org/abs/2309.05573v1"},"cats":{"new-dataset":0.2567284492,"dev-research":0.1343293896,"data-quality":0.1174062377}}
{"text":"Specifically, we first design the Learnable cross-Modal Association (LMA) module to automatically fuse voxel-view and range-view features with image features, which fully utilize the rich semantic information of images and are robust to calibration errors.","meta":{"url":"http://arxiv.org/abs/2309.05573v1"},"cats":{"new-dataset":0.1729123093,"dev-research":0.1868893279,"data-quality":0.1556037905}}
{"text":"Then, the enhanced voxel-view and range-view features are transformed to the point space,where three views of point cloud features are further fused adaptively by the Learnable cross-View Association module (LVA).","meta":{"url":"http://arxiv.org/abs/2309.05573v1"},"cats":{"new-dataset":0.0572099446,"dev-research":0.1538708776,"data-quality":0.0618534197}}
{"text":"Notably, UniSeg achieves promising results in three public benchmarks, i.e., SemanticKITTI, nuScenes, and Waymo Open Dataset (WOD); it ranks 1st on two challenges of two benchmarks, including the LiDAR semantic segmentation challenge of nuScenes and panoptic segmentation challenges of SemanticKITTI.","meta":{"url":"http://arxiv.org/abs/2309.05573v1"},"cats":{"new-dataset":0.3919365574,"dev-research":0.1766599024,"data-quality":0.2023222146}}
{"text":"Besides, we construct the OpenPCSeg codebase, which is the largest and most comprehensive outdoor LiDAR segmentation codebase.","meta":{"url":"http://arxiv.org/abs/2309.05573v1"},"cats":{"new-dataset":0.4383106372,"dev-research":0.210468097,"data-quality":0.0924870639}}
{"text":"It contains most of the popular outdoor LiDAR segmentation algorithms and provides reproducible implementations.","meta":{"url":"http://arxiv.org/abs/2309.05573v1"},"cats":{"new-dataset":0.1741840085,"dev-research":0.1750181551,"data-quality":0.0858504673}}
{"text":"The OpenPCSeg codebase will be made publicly available at https://github.com/PJLab-ADG/PCSeg.","meta":{"url":"http://arxiv.org/abs/2309.05573v1"},"cats":{"new-dataset":0.4852913879,"dev-research":0.2024698657,"data-quality":0.1091481454}}
{"text":"Text-to-image generative models often reflect the biases of the training data, leading to unequal representations of underrepresented groups.","meta":{"url":"http://arxiv.org/abs/2309.05569v1"},"cats":{"new-dataset":0.0524863036,"dev-research":0.1612283804,"data-quality":0.256822972}}
{"text":"This study investigates inclusive text-to-image generative models that generate images based on human-written prompts and ensure the resulting images are uniformly distributed across attributes of interest.","meta":{"url":"http://arxiv.org/abs/2309.05569v1"},"cats":{"new-dataset":0.1195297738,"dev-research":0.1739439756,"data-quality":0.1844054356}}
{"text":"Unfortunately, directly expressing the desired attributes in the prompt often leads to sub-optimal results due to linguistic ambiguity or model misrepresentation.","meta":{"url":"http://arxiv.org/abs/2309.05569v1"},"cats":{"new-dataset":0.0084632706,"dev-research":0.2394882047,"data-quality":0.3664903188}}
{"text":"Hence, this paper proposes a drastically different approach that adheres to the maxim that \"a picture is worth a thousand words\".","meta":{"url":"http://arxiv.org/abs/2309.05569v1"},"cats":{"new-dataset":0.19292602,"dev-research":0.2284477318,"data-quality":0.2217182399}}
{"text":"We show that, for some attributes, images can represent concepts more expressively than text.","meta":{"url":"http://arxiv.org/abs/2309.05569v1"},"cats":{"new-dataset":0.0607269003,"dev-research":0.2823584263,"data-quality":0.2211596992}}
{"text":"For instance, categories of skin tones are typically hard to specify by text but can be easily represented by example images.","meta":{"url":"http://arxiv.org/abs/2309.05569v1"},"cats":{"new-dataset":0.0567165823,"dev-research":0.2360522999,"data-quality":0.2336085711}}
{"text":"Building upon these insights, we propose a novel approach, ITI-GEN, that leverages readily available reference images for Inclusive Text-to-Image GENeration.","meta":{"url":"http://arxiv.org/abs/2309.05569v1"},"cats":{"new-dataset":0.3910638067,"dev-research":0.1768466187,"data-quality":0.1832759332}}
{"text":"The key idea is learning a set of prompt embeddings to generate images that can effectively represent all desired attribute categories.","meta":{"url":"http://arxiv.org/abs/2309.05569v1"},"cats":{"new-dataset":0.1656404206,"dev-research":0.2367817048,"data-quality":0.1590845081}}
{"text":"More importantly, ITI-GEN requires no model fine-tuning, making it computationally efficient to augment existing text-to-image models.","meta":{"url":"http://arxiv.org/abs/2309.05569v1"},"cats":{"new-dataset":0.0737404415,"dev-research":0.1379473273,"data-quality":0.1337624624}}
{"text":"Extensive experiments demonstrate that ITI-GEN largely improves over state-of-the-art models to generate inclusive images from a prompt.","meta":{"url":"http://arxiv.org/abs/2309.05569v1"},"cats":{"new-dataset":0.1292157335,"dev-research":0.1473378558,"data-quality":0.0963464236}}
{"text":"Project page: https://czhang0528.github.io/iti-gen.","meta":{"url":"http://arxiv.org/abs/2309.05569v1"},"cats":{"new-dataset":0.4462092911,"dev-research":0.1736149045,"data-quality":0.0742214859}}
{"text":"Large language models (LLMs) can respond to human language queries and have shown powerful potential applications in network operations (NetOps).","meta":{"url":"http://arxiv.org/abs/2309.05557v1"},"cats":{"new-dataset":0.0746989171,"dev-research":0.1980675704,"data-quality":0.1376545749}}
{"text":"Thanks to the large amount of commonsense knowledge inherent, LLMs achieve much better inference accuracy than traditional models and emerge with strong abilities in generalization, reasoning, and code generation.","meta":{"url":"http://arxiv.org/abs/2309.05557v1"},"cats":{"new-dataset":0.0287945473,"dev-research":0.1607450644,"data-quality":0.1343430637}}
{"text":"These abilities may have a crucial boost to automated and intelligent NetOps.","meta":{"url":"http://arxiv.org/abs/2309.05557v1"},"cats":{"new-dataset":0.0108389272,"dev-research":0.3242714974,"data-quality":0.1158690195}}
{"text":"However, it remains under-explored how well LLMs perform in various NetOps tasks.","meta":{"url":"http://arxiv.org/abs/2309.05557v1"},"cats":{"new-dataset":0.007724892,"dev-research":0.1635988801,"data-quality":0.0993155004}}
{"text":"In this work, we make a systematic assessment of the capabilities, strengths, and limitations of selected LLMs in the field of NetOps.","meta":{"url":"http://arxiv.org/abs/2309.05557v1"},"cats":{"new-dataset":0.0348951345,"dev-research":0.1907197139,"data-quality":0.0596199747}}
{"text":"The evaluation is conducted on a collection of 5,732 questions about NetOps, encompassing 26 publicly available general-domain LLMs, including ChatGPT, LLaMA, Falcon, etc.","meta":{"url":"http://arxiv.org/abs/2309.05557v1"},"cats":{"new-dataset":0.1880629444,"dev-research":0.1710594763,"data-quality":0.121904676}}
{"text":"We also finetune some of these LLMs with our collected NetOps corpus and evaluate the resulting models.","meta":{"url":"http://arxiv.org/abs/2309.05557v1"},"cats":{"new-dataset":0.4283532722,"dev-research":0.1422697441,"data-quality":0.1955742086}}
{"text":"The evaluation method follows the widely adopted benchmarks for general-domain LLMs, combined with Chain-of-Thought Prompts and Retrieval-Augmented Generation.","meta":{"url":"http://arxiv.org/abs/2309.05557v1"},"cats":{"new-dataset":0.0153346208,"dev-research":0.1088277191,"data-quality":0.136161254}}
{"text":"The results show that only GPT-4 achieves high accuracy equivalent to passing the NetOps certification exam for humans, while all the other LLMs have much lower accuracy.","meta":{"url":"http://arxiv.org/abs/2309.05557v1"},"cats":{"new-dataset":0.0158281767,"dev-research":0.1357351664,"data-quality":0.1098866923}}
{"text":"However, some open models like LLaMA 2 still demonstrate significant potential.","meta":{"url":"http://arxiv.org/abs/2309.05557v1"},"cats":{"new-dataset":0.0064672035,"dev-research":0.111990438,"data-quality":0.0635445356}}
{"text":"Furthermore, we evaluate the impact of factors such as model parameters, prompt engineering, instruction fine-tuning etc.","meta":{"url":"http://arxiv.org/abs/2309.05557v1"},"cats":{"new-dataset":0.0077397503,"dev-research":0.3266796573,"data-quality":0.092167697}}
{"text":"This work shall be treated as the initial effort to systematic evaluation of LLMs in NetOps, and a more rigorous study is required for production use.","meta":{"url":"http://arxiv.org/abs/2309.05557v1"},"cats":{"new-dataset":0.0201006357,"dev-research":0.2278022927,"data-quality":0.1020285789}}
{"text":"The evaluation code and dataset will be released to benefit future research.","meta":{"url":"http://arxiv.org/abs/2309.05557v1"},"cats":{"new-dataset":0.5955539459,"dev-research":0.2746585366,"data-quality":0.1431254149}}
{"text":"Earnings calls influence stock prices and are traditionally analyzed using sentiment and linguistic traces.","meta":{"url":"http://arxiv.org/abs/2309.05555v1"},"cats":{"new-dataset":0.0708130882,"dev-research":0.2668571438,"data-quality":0.2830806228}}
{"text":"Our research introduces a \"Topic-Switching Index,\" a novel metric quantified through the transformer model FinBERT, to measure managerial evasion during Q$\\&$A sessions in earnings calls.","meta":{"url":"http://arxiv.org/abs/2309.05555v1"},"cats":{"new-dataset":0.0254732696,"dev-research":0.1996948841,"data-quality":0.1486472638}}
{"text":"We find a negative correlation between this index and subsequent stock prices, indicating that investors penalize managerial evasiveness.","meta":{"url":"http://arxiv.org/abs/2309.05555v1"},"cats":{"new-dataset":0.0133541464,"dev-research":0.1780545488,"data-quality":0.1296111597}}
{"text":"This study is the first to quantify such evasive tactics, adding a new dimension to how earnings calls are understood and suggesting that topic shifting is an overlooked but significant factor.","meta":{"url":"http://arxiv.org/abs/2309.05555v1"},"cats":{"new-dataset":0.0060799632,"dev-research":0.3037657407,"data-quality":0.2394806201}}
{"text":"We also show the predictability of the index under three different classifier models and it stands out in all circumstances.","meta":{"url":"http://arxiv.org/abs/2309.05555v1"},"cats":{"new-dataset":0.0526641353,"dev-research":0.1418235091,"data-quality":0.2218095426}}
{"text":"We study the question of whether submodular functions of random variables satisfying various notions of negative dependence satisfy Chernoff-like concentration inequalities.","meta":{"url":"http://arxiv.org/abs/2309.05554v1"},"cats":{"new-dataset":0.0453201779,"dev-research":0.1630391278,"data-quality":0.1397297022}}
{"text":"We prove such a concentration inequality for the lower tail when the random variables satisfy negative association or negative regression, resolving an open problem raised in (\\citet{approx/QiuS22}).","meta":{"url":"http://arxiv.org/abs/2309.05554v1"},"cats":{"new-dataset":0.1064405989,"dev-research":0.149791461,"data-quality":0.1305661496}}
{"text":"Previous work showed such concentration results for random variables that come from specific dependent-rounding algorithms (\\citet{focs/ChekuriVZ10,soda/HarveyO14}).","meta":{"url":"http://arxiv.org/abs/2309.05554v1"},"cats":{"new-dataset":0.1049416345,"dev-research":0.0667114926,"data-quality":0.1429150693}}
{"text":"We discuss some applications of our results to combinatorial optimization and beyond.","meta":{"url":"http://arxiv.org/abs/2309.05554v1"},"cats":{"new-dataset":0.0497425496,"dev-research":0.1291712787,"data-quality":0.1025865114}}
{"text":"The inexorable growth of online shopping and e-commerce demands scalable and robust machine learning-based solutions to accommodate customer requirements.","meta":{"url":"http://arxiv.org/abs/2309.05551v1"},"cats":{"new-dataset":0.024508352,"dev-research":0.1621421688,"data-quality":0.133328841}}
{"text":"In the context of automatic tagging classification and multimodal retrieval, prior works either defined a low generalizable supervised learning approach or more reusable CLIP-based techniques while, however, training on closed source data.","meta":{"url":"http://arxiv.org/abs/2309.05551v1"},"cats":{"new-dataset":0.119122662,"dev-research":0.1664945981,"data-quality":0.3593329078}}
{"text":"In this work, we propose OpenFashionCLIP, a vision-and-language contrastive learning method that only adopts open-source fashion data stemming from diverse domains, and characterized by varying degrees of specificity.","meta":{"url":"http://arxiv.org/abs/2309.05551v1"},"cats":{"new-dataset":0.232819313,"dev-research":0.1892159525,"data-quality":0.1644167375}}
{"text":"Our approach is extensively validated across several tasks and benchmarks, and experimental results highlight a significant out-of-domain generalization capability and consistent improvements over state-of-the-art methods both in terms of accuracy and recall.","meta":{"url":"http://arxiv.org/abs/2309.05551v1"},"cats":{"new-dataset":0.0221353736,"dev-research":0.1763311176,"data-quality":0.2386382067}}
{"text":"Source code and trained models are publicly available at: https://github.com/aimagelab/open-fashion-clip.","meta":{"url":"http://arxiv.org/abs/2309.05551v1"},"cats":{"new-dataset":0.322817771,"dev-research":0.156468463,"data-quality":0.1068586606}}
{"text":"In cryptographic algorithms, the constants to be multiplied by a variable can be very large due to security requirements.","meta":{"url":"http://arxiv.org/abs/2309.05550v1"},"cats":{"new-dataset":0.0171113541,"dev-research":0.2389749992,"data-quality":0.0694276726}}
{"text":"Thus, the hardware complexity of such algorithms heavily depends on the design architecture handling large constants.","meta":{"url":"http://arxiv.org/abs/2309.05550v1"},"cats":{"new-dataset":0.0122225979,"dev-research":0.1677554079,"data-quality":0.0532914849}}
{"text":"In this paper, we introduce an electronic design automation tool, called LEIGER, which can automatically generate the realizations of very large constant multiplications for low-complexity and high-speed applications, targeting the ASIC design platform.","meta":{"url":"http://arxiv.org/abs/2309.05550v1"},"cats":{"new-dataset":0.0595824621,"dev-research":0.329712325,"data-quality":0.0773156357}}
{"text":"LEIGER can utilize the shift-adds architecture and use 3-input operations, i.e., carry-save adders (CSAs), where the number of CSAs is reduced using a prominent optimization algorithm.","meta":{"url":"http://arxiv.org/abs/2309.05550v1"},"cats":{"new-dataset":0.0184415292,"dev-research":0.19439787,"data-quality":0.0716705458}}
{"text":"It can also generate constant multiplications under a hybrid design architecture, where 2-and 3-input operations are used at different stages.","meta":{"url":"http://arxiv.org/abs/2309.05550v1"},"cats":{"new-dataset":0.0042556057,"dev-research":0.2137928371,"data-quality":0.0492131487}}
{"text":"Moreover, it can describe constant multiplications under a design architecture using compressor trees.","meta":{"url":"http://arxiv.org/abs/2309.05550v1"},"cats":{"new-dataset":0.0166667196,"dev-research":0.2130956004,"data-quality":0.0956343888}}
{"text":"As a case study, high-speed Montgomery multiplication, which is a fundamental operation in cryptographic algorithms, is designed with its constant multiplication block realized under the proposed architectures.","meta":{"url":"http://arxiv.org/abs/2309.05550v1"},"cats":{"new-dataset":0.0242360753,"dev-research":0.1788590213,"data-quality":0.0752266281}}
{"text":"Experimental results indicate that LEIGER enables a designer to explore the trade-off between area and delay of the very large constant and Montgomery multiplications and leads to designs with area-delay product, latency, and energy consumption values significantly better than those obtained by a recently proposed algorithm.","meta":{"url":"http://arxiv.org/abs/2309.05550v1"},"cats":{"new-dataset":0.0083023125,"dev-research":0.2433648257,"data-quality":0.0597046863}}
{"text":"eXplanation Based Learning (XBL) is an interactive learning approach that provides a transparent method of training deep learning models by interacting with their explanations.","meta":{"url":"http://arxiv.org/abs/2309.05548v1"},"cats":{"new-dataset":0.0831938097,"dev-research":0.3336808488,"data-quality":0.1512926941}}
{"text":"XBL augments loss functions to penalize a model based on deviation of its explanations from user annotation of image features.","meta":{"url":"http://arxiv.org/abs/2309.05548v1"},"cats":{"new-dataset":0.0427496415,"dev-research":0.3310610045,"data-quality":0.4948696107}}
{"text":"The literature on XBL mostly depends on the intersection of visual model explanations and image feature annotations.","meta":{"url":"http://arxiv.org/abs/2309.05548v1"},"cats":{"new-dataset":0.0951520321,"dev-research":0.3067125602,"data-quality":0.2075432341}}
{"text":"We present a method to add a distance-aware explanation loss to categorical losses that trains a learner to focus on important regions of a training dataset.","meta":{"url":"http://arxiv.org/abs/2309.05548v1"},"cats":{"new-dataset":0.1520324296,"dev-research":0.3553042017,"data-quality":0.3226922963}}
{"text":"Distance is an appropriate approach for calculating explanation loss since visual model explanations such as Gradient-weighted Class Activation Mapping (Grad-CAMs) are not strictly bounded as annotations and their intersections may not provide complete information on the deviation of a model's focus from relevant image regions.","meta":{"url":"http://arxiv.org/abs/2309.05548v1"},"cats":{"new-dataset":0.0356656086,"dev-research":0.2500502402,"data-quality":0.2946955451}}
{"text":"In addition to assessing our model using existing metrics, we propose an interpretability metric for evaluating visual feature-attribution based model explanations that is more informative of the model's performance than existing metrics.","meta":{"url":"http://arxiv.org/abs/2309.05548v1"},"cats":{"new-dataset":0.0658523485,"dev-research":0.3676471165,"data-quality":0.2715065784}}
{"text":"We demonstrate performance of our proposed method on three image classification tasks.","meta":{"url":"http://arxiv.org/abs/2309.05548v1"},"cats":{"new-dataset":0.0499429384,"dev-research":0.149547098,"data-quality":0.3252691859}}
{"text":"Language model applications are becoming increasingly popular and complex, often including features like tool usage and retrieval augmentation.","meta":{"url":"http://arxiv.org/abs/2309.05542v1"},"cats":{"new-dataset":0.0282400211,"dev-research":0.3354337595,"data-quality":0.197122422}}
{"text":"However, existing frameworks for such applications are often opinionated, deciding for developers how their prompts ought to be formatted and imposing limitations on customizability and reproducibility.","meta":{"url":"http://arxiv.org/abs/2309.05542v1"},"cats":{"new-dataset":0.0357326404,"dev-research":0.5307702334,"data-quality":0.1557317536}}
{"text":"To solve this we present Kani: a lightweight, flexible, and model-agnostic open-source framework for building language model applications.","meta":{"url":"http://arxiv.org/abs/2309.05542v1"},"cats":{"new-dataset":0.1640462422,"dev-research":0.3423960173,"data-quality":0.1007560304}}
{"text":"Kani helps developers implement a variety of complex features by supporting the core building blocks of chat interaction: model interfacing, chat management, and robust function calling.","meta":{"url":"http://arxiv.org/abs/2309.05542v1"},"cats":{"new-dataset":0.0695464816,"dev-research":0.5178440401,"data-quality":0.0831958093}}
{"text":"All Kani core functions are easily overridable and well documented to empower developers to customize functionality for their own needs.","meta":{"url":"http://arxiv.org/abs/2309.05542v1"},"cats":{"new-dataset":0.0180708223,"dev-research":0.447293591,"data-quality":0.0891691647}}
{"text":"Kani thus serves as a useful tool for researchers, hobbyists, and industry professionals alike to accelerate their development while retaining interoperability and fine-grained control.","meta":{"url":"http://arxiv.org/abs/2309.05542v1"},"cats":{"new-dataset":0.0235690393,"dev-research":0.4637945675,"data-quality":0.0669205299}}
{"text":"The use of the un-indexed web, commonly known as the deep web and dark web, to commit or facilitate criminal activity has drastically increased over the past decade.","meta":{"url":"http://arxiv.org/abs/2309.05537v1"},"cats":{"new-dataset":0.0456060234,"dev-research":0.1845343481,"data-quality":0.0769909133}}
{"text":"The dark web is an in-famously dangerous place where all kinds of criminal activities take place [1-2], despite advances in web forensics techniques, tools, and methodologies, few studies have formally tackled the dark and deep web forensics and the technical differences in terms of investigative techniques and artefacts identification and extraction.","meta":{"url":"http://arxiv.org/abs/2309.05537v1"},"cats":{"new-dataset":0.1136464868,"dev-research":0.1974634847,"data-quality":0.1630067291}}
{"text":"This research proposes a novel and comprehensive protocol to guide and assist digital forensics professionals in investigating crimes committed on or via the deep and dark web, The protocol named D2WFP establishes a new sequential approach for performing investigative activities by observing the order of volatility and implementing a systemic approach covering all browsing related hives and artefacts which ultimately resulted into improv-ing the accuracy and effectiveness.","meta":{"url":"http://arxiv.org/abs/2309.05537v1"},"cats":{"new-dataset":0.20232108,"dev-research":0.2285555315,"data-quality":0.1306531253}}
{"text":"Rigorous quantitative and qualitative research has been conducted by assessing D2WFP following a scientifically-sound and comprehensive process in different scenarios and the obtained results show an apparent increase in the number of artefacts re-covered when adopting D2WFP which outperform any current industry or opensource browsing forensics tools.","meta":{"url":"http://arxiv.org/abs/2309.05537v1"},"cats":{"new-dataset":0.3217423237,"dev-research":0.3226234571,"data-quality":0.1539427161}}
{"text":"The second contribution of D2WFP is the robust formulation of artefact correlation and cross-validation within D2WFP which enables digital forensics professionals to better document and structure their analysis of host-based deep and dark web browsing artefacts.","meta":{"url":"http://arxiv.org/abs/2309.05537v1"},"cats":{"new-dataset":0.1595142481,"dev-research":0.2794980026,"data-quality":0.2126771031}}
{"text":"Text-to-image synthesis for the Chinese language poses unique challenges due to its large vocabulary size, and intricate character relationships.","meta":{"url":"http://arxiv.org/abs/2309.05534v1"},"cats":{"new-dataset":0.4552421438,"dev-research":0.2109058095,"data-quality":0.1694149017}}
{"text":"While existing diffusion models have shown promise in generating images from textual descriptions, they often neglect domain-specific contexts and lack robustness in handling the Chinese language.","meta":{"url":"http://arxiv.org/abs/2309.05534v1"},"cats":{"new-dataset":0.0589990263,"dev-research":0.160951136,"data-quality":0.2886595103}}
{"text":"This paper introduces PAI-Diffusion, a comprehensive framework that addresses these limitations.","meta":{"url":"http://arxiv.org/abs/2309.05534v1"},"cats":{"new-dataset":0.0093855697,"dev-research":0.1217719684,"data-quality":0.0598761227}}
{"text":"PAI-Diffusion incorporates both general and domain-specific Chinese diffusion models, enabling the generation of contextually relevant images.","meta":{"url":"http://arxiv.org/abs/2309.05534v1"},"cats":{"new-dataset":0.046332947,"dev-research":0.126457318,"data-quality":0.0912836702}}
{"text":"It explores the potential of using LoRA and ControlNet for fine-grained image style transfer and image editing, empowering users with enhanced control over image generation.","meta":{"url":"http://arxiv.org/abs/2309.05534v1"},"cats":{"new-dataset":0.1150119087,"dev-research":0.2562205379,"data-quality":0.1247521462}}
{"text":"Moreover, PAI-Diffusion seamlessly integrates with Alibaba Cloud's Machine Learning Platform for AI, providing accessible and scalable solutions.","meta":{"url":"http://arxiv.org/abs/2309.05534v1"},"cats":{"new-dataset":0.0452692584,"dev-research":0.1420436834,"data-quality":0.0684427055}}
{"text":"All the Chinese diffusion model checkpoints, LoRAs, and ControlNets, including domain-specific ones, are publicly available.","meta":{"url":"http://arxiv.org/abs/2309.05534v1"},"cats":{"new-dataset":0.2690691157,"dev-research":0.1234535382,"data-quality":0.08005424}}
{"text":"A user-friendly Chinese WebUI and the diffusers-api elastic inference toolkit, also open-sourced, further facilitate the easy deployment of PAI-Diffusion models in various environments, making it a valuable resource for Chinese text-to-image synthesis.","meta":{"url":"http://arxiv.org/abs/2309.05534v1"},"cats":{"new-dataset":0.2017647285,"dev-research":0.153441985,"data-quality":0.1157771861}}
{"text":"Whether and how data scientists, statisticians and modellers should be accountable for the AI systems they develop remains a controversial and highly debated topic, especially given the complexity of AI systems and the difficulties in comparing and synthesising competing claims arising from their deployment for data analysis.","meta":{"url":"http://arxiv.org/abs/2309.05529v1"},"cats":{"new-dataset":0.0499728483,"dev-research":0.3490194406,"data-quality":0.1981246093}}
{"text":"This paper proposes to address this issue by decreasing the opacity and heightening the accountability of decision making using AI systems, through the explicit acknowledgement of the statistical foundations that underpin their development and the ways in which these dictate how their results should be interpreted and acted upon by users.","meta":{"url":"http://arxiv.org/abs/2309.05529v1"},"cats":{"new-dataset":0.0379142495,"dev-research":0.3942610593,"data-quality":0.2231221171}}
{"text":"In turn, this enhances (1) the responsiveness of the models to feedback, (2) the quality and meaning of uncertainty on their outputs and (3) their transparency to evaluation.","meta":{"url":"http://arxiv.org/abs/2309.05529v1"},"cats":{"new-dataset":0.0054075966,"dev-research":0.2297664656,"data-quality":0.1854692818}}
{"text":"To exemplify this approach, we extend Posterior Belief Assessment to offer a route to belief ownership from complex and competing AI structures.","meta":{"url":"http://arxiv.org/abs/2309.05529v1"},"cats":{"new-dataset":0.0242535373,"dev-research":0.1763767507,"data-quality":0.1024305129}}
{"text":"We argue that this is a significant way to bring ethical considerations into mathematical reasoning, and to implement ethical AI in statistical practice.","meta":{"url":"http://arxiv.org/abs/2309.05529v1"},"cats":{"new-dataset":0.0240278945,"dev-research":0.3032302083,"data-quality":0.129421476}}
{"text":"We demonstrate these ideas within the context of competing models used to advise the UK government on the spread of the Omicron variant of COVID-19 during December 2021.","meta":{"url":"http://arxiv.org/abs/2309.05529v1"},"cats":{"new-dataset":0.2361033755,"dev-research":0.1633705191,"data-quality":0.0640121548}}
{"text":"The deployment of machine learning solutions in real-world scenarios often involves addressing the challenge of out-of-distribution (OOD) detection.","meta":{"url":"http://arxiv.org/abs/2309.05528v1"},"cats":{"new-dataset":0.0895858187,"dev-research":0.1613153653,"data-quality":0.2935067988}}
{"text":"While significant efforts have been devoted to OOD detection in classical supervised settings, the context of weakly supervised learning, particularly the Multiple Instance Learning (MIL) framework, remains under-explored.","meta":{"url":"http://arxiv.org/abs/2309.05528v1"},"cats":{"new-dataset":0.1000296639,"dev-research":0.1084374699,"data-quality":0.3416112435}}
{"text":"In this study, we tackle this challenge by adapting post-hoc OOD detection methods to the MIL setting while introducing a novel benchmark specifically designed to assess OOD detection performance in weakly supervised scenarios.","meta":{"url":"http://arxiv.org/abs/2309.05528v1"},"cats":{"new-dataset":0.0841399535,"dev-research":0.1389022023,"data-quality":0.3234719589}}
{"text":"Extensive experiments based on diverse public datasets do not reveal a single method with a clear advantage over the others.","meta":{"url":"http://arxiv.org/abs/2309.05528v1"},"cats":{"new-dataset":0.0452484623,"dev-research":0.1120477487,"data-quality":0.2070171924}}
{"text":"Although DICE emerges as the best-performing method overall, it exhibits significant shortcomings on some datasets, emphasizing the complexity of this under-explored and challenging topic.","meta":{"url":"http://arxiv.org/abs/2309.05528v1"},"cats":{"new-dataset":0.218972493,"dev-research":0.2161230222,"data-quality":0.1880656543}}
{"text":"Our findings shed light on the complex nature of OOD detection under the MIL framework, emphasizing the importance of developing novel, robust, and reliable methods that can generalize effectively in a weakly supervised context.","meta":{"url":"http://arxiv.org/abs/2309.05528v1"},"cats":{"new-dataset":0.1109810822,"dev-research":0.129378948,"data-quality":0.349415405}}
{"text":"The code for the paper is available here: https://github.com/loic-lb/OOD_MIL.","meta":{"url":"http://arxiv.org/abs/2309.05528v1"},"cats":{"new-dataset":0.2722226499,"dev-research":0.1060213304,"data-quality":0.1184998228}}
{"text":"Domain shifts such as sensor type changes and geographical situation variations are prevalent in Autonomous Driving (AD), which poses a challenge since AD model relying on the previous-domain knowledge can be hardly directly deployed to a new domain without additional costs.","meta":{"url":"http://arxiv.org/abs/2309.05527v1"},"cats":{"new-dataset":0.0307121619,"dev-research":0.2838362306,"data-quality":0.162803525}}
{"text":"In this paper, we provide a new perspective and approach of alleviating the domain shifts, by proposing a Reconstruction-Simulation-Perception (ReSimAD) scheme.","meta":{"url":"http://arxiv.org/abs/2309.05527v1"},"cats":{"new-dataset":0.0233383338,"dev-research":0.1547887389,"data-quality":0.093734496}}
{"text":"Specifically, the implicit reconstruction process is based on the knowledge from the previous old domain, aiming to convert the domain-related knowledge into domain-invariant representations, \\textit{e.g.}, 3D scene-level meshes.","meta":{"url":"http://arxiv.org/abs/2309.05527v1"},"cats":{"new-dataset":0.0634117965,"dev-research":0.2305226495,"data-quality":0.1086540412}}
{"text":"Besides, the point clouds simulation process of multiple new domains is conditioned on the above reconstructed 3D meshes, where the target-domain-like simulation samples can be obtained, thus reducing the cost of collecting and annotating new-domain data for the subsequent perception process.","meta":{"url":"http://arxiv.org/abs/2309.05527v1"},"cats":{"new-dataset":0.082510595,"dev-research":0.1705082881,"data-quality":0.0957614804}}
{"text":"For experiments, we consider different cross-domain situations such as Waymo-to-KITTI, Waymo-to-nuScenes, Waymo-to-ONCE, \\textit{etc}, to verify the \\textbf{zero-shot} target-domain perception using ReSimAD.","meta":{"url":"http://arxiv.org/abs/2309.05527v1"},"cats":{"new-dataset":0.0440331588,"dev-research":0.1133391762,"data-quality":0.1979038882}}
{"text":"Results demonstrate that our method is beneficial to boost the domain generalization ability, even promising for 3D pre-training.","meta":{"url":"http://arxiv.org/abs/2309.05527v1"},"cats":{"new-dataset":0.0132406462,"dev-research":0.1975347845,"data-quality":0.1025194733}}
{"text":"Integrating native AI support into the network architecture is an essential objective of 6G. Federated Learning (FL) emerges as a potential paradigm, facilitating decentralized AI model training across a diverse range of devices under the coordination of a central server.","meta":{"url":"http://arxiv.org/abs/2309.05525v1"},"cats":{"new-dataset":0.0459307249,"dev-research":0.1242748964,"data-quality":0.0851619495}}
{"text":"However, several challenges hinder its wide application in the 6G context, such as malicious attacks and privacy snooping on local model updates, and centralization pitfalls.","meta":{"url":"http://arxiv.org/abs/2309.05525v1"},"cats":{"new-dataset":0.0221727148,"dev-research":0.1770054277,"data-quality":0.1527123146}}
{"text":"This work proposes a trusted architecture for supporting FL, which utilizes Distributed Ledger Technology (DLT) and Graph Neural Network (GNN), including three key features.","meta":{"url":"http://arxiv.org/abs/2309.05525v1"},"cats":{"new-dataset":0.0986829404,"dev-research":0.1433806457,"data-quality":0.1199462954}}
{"text":"First, a pre-processing layer employing homomorphic encryption is incorporated to securely aggregate local models, preserving the privacy of individual models.","meta":{"url":"http://arxiv.org/abs/2309.05525v1"},"cats":{"new-dataset":0.0384210485,"dev-research":0.1489853167,"data-quality":0.0583676406}}
{"text":"Second, given the distributed nature and graph structure between clients and nodes in the pre-processing layer, GNN is leveraged to identify abnormal local models, enhancing system security.","meta":{"url":"http://arxiv.org/abs/2309.05525v1"},"cats":{"new-dataset":0.074545948,"dev-research":0.2490308302,"data-quality":0.1618873451}}
{"text":"Third, DLT is utilized to decentralize the system by selecting one of the candidates to perform the central server's functions.","meta":{"url":"http://arxiv.org/abs/2309.05525v1"},"cats":{"new-dataset":0.0091583917,"dev-research":0.2069721508,"data-quality":0.0571939939}}
{"text":"Additionally, DLT ensures reliable data management by recording data exchanges in an immutable and transparent ledger.","meta":{"url":"http://arxiv.org/abs/2309.05525v1"},"cats":{"new-dataset":0.0432445274,"dev-research":0.1929211439,"data-quality":0.1230292705}}
{"text":"The feasibility of the novel architecture is validated through simulations, demonstrating improved performance in anomalous model detection and global model accuracy compared to relevant baselines.","meta":{"url":"http://arxiv.org/abs/2309.05525v1"},"cats":{"new-dataset":0.0254907062,"dev-research":0.132100875,"data-quality":0.1452069951}}
{"text":"The notion of individual fairness is a formalization of an ethical principle, \"Treating like cases alike,\" which has been argued such as by Aristotle.","meta":{"url":"http://arxiv.org/abs/2309.05521v1"},"cats":{"new-dataset":0.0109168802,"dev-research":0.1870779584,"data-quality":0.1395169458}}
{"text":"In a fairness-aware machine learning context, Dwork et al. firstly formalized the notion.","meta":{"url":"http://arxiv.org/abs/2309.05521v1"},"cats":{"new-dataset":0.025267334,"dev-research":0.217728714,"data-quality":0.2212960859}}
{"text":"In their formalization, a similar pair of data in an unfair space should be mapped to similar positions in a fair space.","meta":{"url":"http://arxiv.org/abs/2309.05521v1"},"cats":{"new-dataset":0.0792841646,"dev-research":0.1473410329,"data-quality":0.1864932328}}
{"text":"We propose to re-formalize individual fairness by the statistical independence conditioned by individuals.","meta":{"url":"http://arxiv.org/abs/2309.05521v1"},"cats":{"new-dataset":0.0242080886,"dev-research":0.1680655337,"data-quality":0.2036469001}}
{"text":"This re-formalization has the following merits.","meta":{"url":"http://arxiv.org/abs/2309.05521v1"},"cats":{"new-dataset":0.008488151,"dev-research":0.2540399795,"data-quality":0.1769557917}}
{"text":"First, our formalization is compatible with that of Dwork et al.","meta":{"url":"http://arxiv.org/abs/2309.05521v1"},"cats":{"new-dataset":0.0143684003,"dev-research":0.2093535032,"data-quality":0.1703547461}}
{"text":"Second, our formalization enables to combine individual fairness with the fairness notion, equalized odds or sufficiency, as well as statistical parity.","meta":{"url":"http://arxiv.org/abs/2309.05521v1"},"cats":{"new-dataset":0.0052528924,"dev-research":0.1859375342,"data-quality":0.1312513331}}
{"text":"Third, though their formalization implicitly assumes a pre-process approach for making fair prediction, our formalization is applicable to an in-process or post-process approach.","meta":{"url":"http://arxiv.org/abs/2309.05521v1"},"cats":{"new-dataset":0.0156075522,"dev-research":0.2392815534,"data-quality":0.1519650698}}
{"text":"With the development of blockchain technology, smart contracts have become an important component of blockchain applications.","meta":{"url":"http://arxiv.org/abs/2309.05520v1"},"cats":{"new-dataset":0.0491150352,"dev-research":0.2505415689,"data-quality":0.0655637692}}
{"text":"Despite their crucial role, the development of smart contracts may introduce vulnerabilities and potentially lead to severe consequences, such as financial losses.","meta":{"url":"http://arxiv.org/abs/2309.05520v1"},"cats":{"new-dataset":0.0487358218,"dev-research":0.3905013067,"data-quality":0.1776122585}}
{"text":"Meanwhile, large language models, represented by ChatGPT, have gained great attentions, showcasing great capabilities in code analysis tasks.","meta":{"url":"http://arxiv.org/abs/2309.05520v1"},"cats":{"new-dataset":0.3780024521,"dev-research":0.3805540118,"data-quality":0.1409345653}}
{"text":"In this paper, we presented an empirical study to investigate the performance of ChatGPT in identifying smart contract vulnerabilities.","meta":{"url":"http://arxiv.org/abs/2309.05520v1"},"cats":{"new-dataset":0.2581007018,"dev-research":0.3519663148,"data-quality":0.1985152782}}
{"text":"Initially, we evaluated ChatGPT's effectiveness using a publicly available smart contract dataset.","meta":{"url":"http://arxiv.org/abs/2309.05520v1"},"cats":{"new-dataset":0.5676780569,"dev-research":0.2336119483,"data-quality":0.1193425115}}
{"text":"Our findings discover that while ChatGPT achieves a high recall rate, its precision in pinpointing smart contract vulnerabilities is limited.","meta":{"url":"http://arxiv.org/abs/2309.05520v1"},"cats":{"new-dataset":0.2283136175,"dev-research":0.3340781907,"data-quality":0.2339757411}}
{"text":"Furthermore, ChatGPT's performance varies when detecting different vulnerability types.","meta":{"url":"http://arxiv.org/abs/2309.05520v1"},"cats":{"new-dataset":0.0302439066,"dev-research":0.240305099,"data-quality":0.1160835372}}
{"text":"We delved into the root causes for the false positives generated by ChatGPT, and categorized them into four groups.","meta":{"url":"http://arxiv.org/abs/2309.05520v1"},"cats":{"new-dataset":0.1524404522,"dev-research":0.2773451739,"data-quality":0.2513034703}}
{"text":"Second, by comparing ChatGPT with other state-of-the-art smart contract vulnerability detection tools, we found that ChatGPT's F-score is lower than others for 3 out of the 7 vulnerabilities.","meta":{"url":"http://arxiv.org/abs/2309.05520v1"},"cats":{"new-dataset":0.2807942435,"dev-research":0.2800085665,"data-quality":0.2044946276}}
{"text":"In the case of the remaining 4 vulnerabilities, ChatGPT exhibits a slight advantage over these tools.","meta":{"url":"http://arxiv.org/abs/2309.05520v1"},"cats":{"new-dataset":0.0680007715,"dev-research":0.3117118093,"data-quality":0.0843453662}}
{"text":"Finally, we analyzed the limitation of ChatGPT in smart contract vulnerability detection, revealing that the robustness of ChatGPT in this field needs to be improved from two aspects: its uncertainty in answering questions; and the limited length of the detected code.","meta":{"url":"http://arxiv.org/abs/2309.05520v1"},"cats":{"new-dataset":0.2086956914,"dev-research":0.3410207789,"data-quality":0.2559682191}}
{"text":"In general, our research provides insights into the strengths and weaknesses of employing large language models, specifically ChatGPT, for the detection of smart contract vulnerabilities.","meta":{"url":"http://arxiv.org/abs/2309.05520v1"},"cats":{"new-dataset":0.3916514077,"dev-research":0.3844669823,"data-quality":0.239451486}}
{"text":"While recently Multimodal Large Language Models (MM-LLMs) have made exciting strides, they mostly fall prey to the limitation of only input-side multimodal understanding, without the ability to produce content in multiple modalities.","meta":{"url":"http://arxiv.org/abs/2309.05519v1"},"cats":{"new-dataset":0.1131392677,"dev-research":0.12402472,"data-quality":0.096874709}}
{"text":"As we humans always perceive the world and communicate with people through various modalities, developing any-to-any MM-LLMs capable of accepting and delivering content in any modality becomes essential to human-level AI.","meta":{"url":"http://arxiv.org/abs/2309.05519v1"},"cats":{"new-dataset":0.0204856642,"dev-research":0.0996711848,"data-quality":0.098448331}}
{"text":"To fill the gap, we present an end-to-end general-purpose any-to-any MM-LLM system, NExT-GPT.","meta":{"url":"http://arxiv.org/abs/2309.05519v1"},"cats":{"new-dataset":0.0424617624,"dev-research":0.0832905606,"data-quality":0.0666912495}}
{"text":"We connect an LLM with multimodal adaptors and different diffusion decoders, enabling NExT-GPT to perceive inputs and generate outputs in arbitrary combinations of text, images, videos, and audio.","meta":{"url":"http://arxiv.org/abs/2309.05519v1"},"cats":{"new-dataset":0.101756978,"dev-research":0.0946324529,"data-quality":0.077971766}}
{"text":"By leveraging the existing well-trained highly-performing encoders and decoders, NExT-GPT is tuned with only a small amount of parameter (1%) of certain projection layers, which not only benefits low-cost training and also facilitates convenient expansion to more potential modalities.","meta":{"url":"http://arxiv.org/abs/2309.05519v1"},"cats":{"new-dataset":0.0259639909,"dev-research":0.1189312696,"data-quality":0.0760203458}}
{"text":"Moreover, we introduce a modality-switching instruction tuning (MosIT) and manually curate a high-quality dataset for MosIT, based on which NExT-GPT is empowered with complex cross-modal semantic understanding and content generation.","meta":{"url":"http://arxiv.org/abs/2309.05519v1"},"cats":{"new-dataset":0.1840676831,"dev-research":0.2330289212,"data-quality":0.1453321725}}
{"text":"Overall, our research showcases the promising possibility of building an AI agent capable of modeling universal modalities, paving the way for more human-like AI research in the community.","meta":{"url":"http://arxiv.org/abs/2309.05519v1"},"cats":{"new-dataset":0.121642222,"dev-research":0.184375282,"data-quality":0.0735369946}}
{"text":"This document contains a detailed description of the STAR-loc dataset.","meta":{"url":"http://arxiv.org/abs/2309.05518v1"},"cats":{"new-dataset":0.8328047566,"dev-research":0.0949357657,"data-quality":0.1689420332}}
{"text":"For a quick starting guide please refer to the associated Github repository (https://github.com/utiasASRL/starloc).","meta":{"url":"http://arxiv.org/abs/2309.05518v1"},"cats":{"new-dataset":0.1834908755,"dev-research":0.1956544141,"data-quality":0.1243134423}}
{"text":"The dataset consists of stereo camera data (rectified/raw images and inertial measurement unit measurements) and ultra-wideband (UWB) data (range measurements) collected on a sensor rig in a Vicon motion capture arena.","meta":{"url":"http://arxiv.org/abs/2309.05518v1"},"cats":{"new-dataset":0.8990891782,"dev-research":0.1383839618,"data-quality":0.0974151116}}
{"text":"The UWB anchors and visual landmarks (Apriltags) are of known position, so the dataset can be used for both localization and Simultaneous Localization and Mapping (SLAM).","meta":{"url":"http://arxiv.org/abs/2309.05518v1"},"cats":{"new-dataset":0.3428528824,"dev-research":0.178094778,"data-quality":0.1380544455}}
{"text":"Active learning (AL) reduces the amount of labeled data needed to train a machine learning model by intelligently choosing which instances to label.","meta":{"url":"http://arxiv.org/abs/2309.05517v1"},"cats":{"new-dataset":0.0383297345,"dev-research":0.2162668728,"data-quality":0.3243582927}}
{"text":"Classic pool-based AL requires all data to be present in a datacenter, which can be challenging with the increasing amounts of data needed in deep learning.","meta":{"url":"http://arxiv.org/abs/2309.05517v1"},"cats":{"new-dataset":0.1643653254,"dev-research":0.1453944874,"data-quality":0.1355785405}}
{"text":"However, AL on mobile devices and robots, like autonomous cars, can filter the data from perception sensor streams before reaching the datacenter.","meta":{"url":"http://arxiv.org/abs/2309.05517v1"},"cats":{"new-dataset":0.0233585346,"dev-research":0.1777089521,"data-quality":0.117333253}}
{"text":"We exploited the temporal properties for such image streams in our work and proposed the novel temporal predicted loss (TPL) method.","meta":{"url":"http://arxiv.org/abs/2309.05517v1"},"cats":{"new-dataset":0.0817844553,"dev-research":0.1562888349,"data-quality":0.1115299}}
{"text":"To evaluate the stream-based setting properly, we introduced the GTA V streets and the A2D2 streets dataset and made both publicly available.","meta":{"url":"http://arxiv.org/abs/2309.05517v1"},"cats":{"new-dataset":0.547672828,"dev-research":0.1633101924,"data-quality":0.098543177}}
{"text":"Our experiments showed that our approach significantly improves the diversity of the selection while being an uncertainty-based method.","meta":{"url":"http://arxiv.org/abs/2309.05517v1"},"cats":{"new-dataset":0.0033683776,"dev-research":0.1602067426,"data-quality":0.1277565002}}
{"text":"As pool-based approaches are more common in perception applications, we derived a concept for comparing pool-based and stream-based AL, where TPL out-performed state-of-the-art pool- or stream-based approaches for different models.","meta":{"url":"http://arxiv.org/abs/2309.05517v1"},"cats":{"new-dataset":0.0176149109,"dev-research":0.165239589,"data-quality":0.1310342379}}
{"text":"TPL demonstrated a gain of 2.5 precept points (pp) less required data while being significantly faster than pool-based methods.","meta":{"url":"http://arxiv.org/abs/2309.05517v1"},"cats":{"new-dataset":0.01997129,"dev-research":0.1219019819,"data-quality":0.0927012451}}
{"text":"Large Language Models (LLMs) have proven their exceptional capabilities in performing language-related tasks.","meta":{"url":"http://arxiv.org/abs/2309.05516v1"},"cats":{"new-dataset":0.0523469402,"dev-research":0.1530268767,"data-quality":0.1430831077}}
{"text":"However, their deployment poses significant challenges due to their considerable memory and storage requirements.","meta":{"url":"http://arxiv.org/abs/2309.05516v1"},"cats":{"new-dataset":0.1228583445,"dev-research":0.2966589915,"data-quality":0.1262500572}}
{"text":"In response to this issue, weight-only quantization, particularly 3 and 4-bit weight-only quantization, has emerged as one of the most viable solutions.","meta":{"url":"http://arxiv.org/abs/2309.05516v1"},"cats":{"new-dataset":0.010240155,"dev-research":0.1291964116,"data-quality":0.133983777}}
{"text":"As the number of bits decreases, the quantization grid broadens, thus emphasizing the importance of up and down rounding.","meta":{"url":"http://arxiv.org/abs/2309.05516v1"},"cats":{"new-dataset":0.0152455258,"dev-research":0.2139050978,"data-quality":0.1129222242}}
{"text":"While previous studies have demonstrated that fine-tuning up and down rounding with the addition of perturbations can enhance accuracy in some scenarios, our study is driven by the precise and limited boundary of these perturbations, where only the threshold for altering the rounding value is of significance.","meta":{"url":"http://arxiv.org/abs/2309.05516v1"},"cats":{"new-dataset":0.0107177147,"dev-research":0.2330280706,"data-quality":0.3391408238}}
{"text":"Consequently, we propose a concise and highly effective approach for optimizing the weight rounding task.","meta":{"url":"http://arxiv.org/abs/2309.05516v1"},"cats":{"new-dataset":0.027181797,"dev-research":0.1758213718,"data-quality":0.2214767397}}
{"text":"Our method, named SignRound, involves lightweight block-wise tuning using signed gradient descent, enabling us to achieve outstanding results within 400 steps.","meta":{"url":"http://arxiv.org/abs/2309.05516v1"},"cats":{"new-dataset":0.0290246262,"dev-research":0.1818841795,"data-quality":0.1051754374}}
{"text":"SignRound outperforms the established baseline of rounding-to-nearest (RTN) and competes impressively against recent methods, without introducing additional inference overhead.","meta":{"url":"http://arxiv.org/abs/2309.05516v1"},"cats":{"new-dataset":0.0514931578,"dev-research":0.1706238696,"data-quality":0.1658605344}}
{"text":"The source code will be publicly available at https://github.com/intel/neural-compressor soon.","meta":{"url":"http://arxiv.org/abs/2309.05516v1"},"cats":{"new-dataset":0.1447331572,"dev-research":0.2188176838,"data-quality":0.1476746404}}
{"text":"Recent legislation proposals have significantly increased the demand for eXplainable Artificial Intelligence (XAI) in many businesses, especially in so-called `high-risk' domains, such as recruitment.","meta":{"url":"http://arxiv.org/abs/2309.05507v1"},"cats":{"new-dataset":0.0583839984,"dev-research":0.3381658151,"data-quality":0.122848177}}
{"text":"Within recruitment, AI has become commonplace, mainly in the form of job recommender systems (JRSs), which try to match candidates to vacancies, and vice versa.","meta":{"url":"http://arxiv.org/abs/2309.05507v1"},"cats":{"new-dataset":0.0198842439,"dev-research":0.2346026563,"data-quality":0.102603488}}
{"text":"However, common XAI techniques often fall short in this domain due to the different levels and types of expertise of the individuals involved, making explanations difficult to generalize.","meta":{"url":"http://arxiv.org/abs/2309.05507v1"},"cats":{"new-dataset":0.0060310014,"dev-research":0.340559863,"data-quality":0.1619666436}}
{"text":"To determine the explanation preferences of the different stakeholder types - candidates, recruiters, and companies - we created and validated a semi-structured interview guide.","meta":{"url":"http://arxiv.org/abs/2309.05507v1"},"cats":{"new-dataset":0.0890484833,"dev-research":0.3201703347,"data-quality":0.1016572304}}
{"text":"Using grounded theory, we structurally analyzed the results of these interviews and found that different stakeholder types indeed have strongly differing explanation preferences.","meta":{"url":"http://arxiv.org/abs/2309.05507v1"},"cats":{"new-dataset":0.0301626574,"dev-research":0.3638113235,"data-quality":0.1377748794}}
{"text":"Candidates indicated a preference for brief, textual explanations that allow them to quickly judge potential matches.","meta":{"url":"http://arxiv.org/abs/2309.05507v1"},"cats":{"new-dataset":0.0092967823,"dev-research":0.2600965007,"data-quality":0.1550782624}}
{"text":"On the other hand, hiring managers preferred visual graph-based explanations that provide a more technical and comprehensive overview at a glance.","meta":{"url":"http://arxiv.org/abs/2309.05507v1"},"cats":{"new-dataset":0.0175009282,"dev-research":0.4300972963,"data-quality":0.1098850595}}
{"text":"Recruiters found more exhaustive textual explanations preferable, as those provided them with more talking points to convince both parties of the match.","meta":{"url":"http://arxiv.org/abs/2309.05507v1"},"cats":{"new-dataset":0.0063058922,"dev-research":0.287257505,"data-quality":0.1395174608}}
{"text":"Based on these findings, we describe guidelines on how to design an explanation interface that fulfills the requirements of all three stakeholder types.","meta":{"url":"http://arxiv.org/abs/2309.05507v1"},"cats":{"new-dataset":0.0790572112,"dev-research":0.5699860998,"data-quality":0.1505574673}}
{"text":"Furthermore, we provide the validated interview guide, which can assist future research in determining the explanation preferences of different stakeholder types.","meta":{"url":"http://arxiv.org/abs/2309.05507v1"},"cats":{"new-dataset":0.0647180921,"dev-research":0.4222827789,"data-quality":0.1155985931}}
{"text":"Repeated parameter sharing in federated learning causes significant information leakage about private data, thus defeating its main purpose: data privacy.","meta":{"url":"http://arxiv.org/abs/2309.05505v1"},"cats":{"new-dataset":0.0457384011,"dev-research":0.1416262338,"data-quality":0.1586723163}}
{"text":"Mitigating the risk of this information leakage, using state of the art differentially private algorithms, also does not come for free.","meta":{"url":"http://arxiv.org/abs/2309.05505v1"},"cats":{"new-dataset":0.0416078935,"dev-research":0.126487754,"data-quality":0.1054619123}}
{"text":"Randomized mechanisms can prevent convergence of models on learning even the useful representation functions, especially if there is more disagreement between local models on the classification functions (due to data heterogeneity).","meta":{"url":"http://arxiv.org/abs/2309.05505v1"},"cats":{"new-dataset":0.003837539,"dev-research":0.1538154192,"data-quality":0.2252384954}}
{"text":"In this paper, we consider a representation federated learning objective that encourages various parties to collaboratively refine the consensus part of the model, with differential privacy guarantees, while separately allowing sufficient freedom for local personalization (without releasing it).","meta":{"url":"http://arxiv.org/abs/2309.05505v1"},"cats":{"new-dataset":0.0398661833,"dev-research":0.160085801,"data-quality":0.1577572182}}
{"text":"We prove that in the linear representation setting, while the objective is non-convex, our proposed new algorithm \\DPFEDREP\\ converges to a ball centered around the \\emph{global optimal} solution at a linear rate, and the radius of the ball is proportional to the reciprocal of the privacy budget.","meta":{"url":"http://arxiv.org/abs/2309.05505v1"},"cats":{"new-dataset":0.0240594103,"dev-research":0.1327375584,"data-quality":0.1174728131}}
{"text":"With this novel utility analysis, we improve the SOTA utility-privacy trade-off for this problem by a factor of $\\sqrt{d}$, where $d$ is the input dimension.","meta":{"url":"http://arxiv.org/abs/2309.05505v1"},"cats":{"new-dataset":0.0881747083,"dev-research":0.0990430252,"data-quality":0.1051024374}}
{"text":"We empirically evaluate our method with the image classification task on CIFAR10, CIFAR100, and EMNIST, and observe a significant performance improvement over the prior work under the same small privacy budget.","meta":{"url":"http://arxiv.org/abs/2309.05505v1"},"cats":{"new-dataset":0.0900031203,"dev-research":0.1306698662,"data-quality":0.2379951753}}
{"text":"The code can be found in this link: https://github.com/shenzebang/CENTAUR-Privacy-Federated-Representation-Learning.","meta":{"url":"http://arxiv.org/abs/2309.05505v1"},"cats":{"new-dataset":0.1662946418,"dev-research":0.1190354096,"data-quality":0.1840873585}}
{"text":"Since their release, Transformers have revolutionized many fields from Natural Language Understanding to Computer Vision.","meta":{"url":"http://arxiv.org/abs/2309.05503v1"},"cats":{"new-dataset":0.1012071604,"dev-research":0.2365067552,"data-quality":0.1335722543}}
{"text":"Document Understanding (DU) was not left behind with first Transformer based models for DU dating from late 2019.","meta":{"url":"http://arxiv.org/abs/2309.05503v1"},"cats":{"new-dataset":0.0576412169,"dev-research":0.1876626237,"data-quality":0.167490385}}
{"text":"However, the computational complexity of the self-attention operation limits their capabilities to small sequences.","meta":{"url":"http://arxiv.org/abs/2309.05503v1"},"cats":{"new-dataset":0.013112302,"dev-research":0.1434381182,"data-quality":0.0714348263}}
{"text":"In this paper we explore multiple strategies to apply Transformer based models to long multi-page documents.","meta":{"url":"http://arxiv.org/abs/2309.05503v1"},"cats":{"new-dataset":0.0221437452,"dev-research":0.1387865983,"data-quality":0.0693681395}}
{"text":"We introduce 2 new multi-modal (text + layout) long-range models for DU.","meta":{"url":"http://arxiv.org/abs/2309.05503v1"},"cats":{"new-dataset":0.2476478516,"dev-research":0.1558581543,"data-quality":0.0720526736}}
{"text":"They are based on efficient implementations of Transformers for long sequences.","meta":{"url":"http://arxiv.org/abs/2309.05503v1"},"cats":{"new-dataset":0.0338932906,"dev-research":0.1568496966,"data-quality":0.0461824242}}
{"text":"Long-range models can process whole documents at once effectively and are less impaired by the document's length.","meta":{"url":"http://arxiv.org/abs/2309.05503v1"},"cats":{"new-dataset":0.0128329663,"dev-research":0.1688261071,"data-quality":0.0737210963}}
{"text":"We compare them to LayoutLM, a classical Transformer adapted for DU and pre-trained on millions of documents.","meta":{"url":"http://arxiv.org/abs/2309.05503v1"},"cats":{"new-dataset":0.2058013452,"dev-research":0.1649830953,"data-quality":0.0985217085}}
{"text":"We further propose 2D relative attention bias to guide self-attention towards relevant tokens without harming model efficiency.","meta":{"url":"http://arxiv.org/abs/2309.05503v1"},"cats":{"new-dataset":0.0205916725,"dev-research":0.197531716,"data-quality":0.1888698804}}
{"text":"We observe improvements on multi-page business documents on Information Retrieval for a small performance cost on smaller sequences.","meta":{"url":"http://arxiv.org/abs/2309.05503v1"},"cats":{"new-dataset":0.0892300149,"dev-research":0.1267978615,"data-quality":0.1127117427}}
{"text":"Relative 2D attention revealed to be effective on dense text for both normal and long-range models.","meta":{"url":"http://arxiv.org/abs/2309.05503v1"},"cats":{"new-dataset":0.0923635959,"dev-research":0.1066550652,"data-quality":0.1379026399}}
{"text":"The evolution of Generative Pre-trained Transformer (GPT) models has led to significant advancements in various natural language processing applications, particularly in legal textual entailment.","meta":{"url":"http://arxiv.org/abs/2309.05501v1"},"cats":{"new-dataset":0.088897575,"dev-research":0.1735802047,"data-quality":0.1836813794}}
{"text":"We present an analysis of GPT-3.5 (ChatGPT) and GPT-4 performances on COLIEE Task 4 dataset, a prominent benchmark in this domain.","meta":{"url":"http://arxiv.org/abs/2309.05501v1"},"cats":{"new-dataset":0.4312589864,"dev-research":0.1508351116,"data-quality":0.1343184301}}
{"text":"The study encompasses data from Heisei 18 (2006) to Reiwa 3 (2021), exploring the models' abilities to discern entailment relationships within Japanese statute law across different periods.","meta":{"url":"http://arxiv.org/abs/2309.05501v1"},"cats":{"new-dataset":0.2302178384,"dev-research":0.2891801657,"data-quality":0.1156350612}}
{"text":"Our preliminary experimental results unveil intriguing insights into the models' strengths and weaknesses in handling legal textual entailment tasks, as well as the patterns observed in model performance.","meta":{"url":"http://arxiv.org/abs/2309.05501v1"},"cats":{"new-dataset":0.0342468422,"dev-research":0.2422647401,"data-quality":0.224683548}}
{"text":"In the context of proprietary models with undisclosed architectures and weights, black-box analysis becomes crucial for evaluating their capabilities.","meta":{"url":"http://arxiv.org/abs/2309.05501v1"},"cats":{"new-dataset":0.0051852198,"dev-research":0.2325706149,"data-quality":0.1084380434}}
{"text":"We discuss the influence of training data distribution and the implications on the models' generalizability.","meta":{"url":"http://arxiv.org/abs/2309.05501v1"},"cats":{"new-dataset":0.017813973,"dev-research":0.1000138949,"data-quality":0.1855884996}}
{"text":"This analysis serves as a foundation for future research, aiming to optimize GPT-based models and enable their successful adoption in legal information extraction and entailment applications.","meta":{"url":"http://arxiv.org/abs/2309.05501v1"},"cats":{"new-dataset":0.0985619949,"dev-research":0.1874626203,"data-quality":0.1550701149}}
{"text":"In recent years, natural language processing has gained significant popularity in various sectors, including the legal domain.","meta":{"url":"http://arxiv.org/abs/2309.05500v1"},"cats":{"new-dataset":0.0810226534,"dev-research":0.2552750585,"data-quality":0.2388174819}}
{"text":"This paper presents NeCo Team's solutions to the Vietnamese text processing tasks provided in the Automated Legal Question Answering Competition 2023 (ALQAC 2023), focusing on legal domain knowledge acquisition for low-resource languages through data enrichment.","meta":{"url":"http://arxiv.org/abs/2309.05500v1"},"cats":{"new-dataset":0.4980819848,"dev-research":0.2311484978,"data-quality":0.2566631708}}
{"text":"Our methods for the legal document retrieval task employ a combination of similarity ranking and deep learning models, while for the second task, which requires extracting an answer from a relevant legal article in response to a question, we propose a range of adaptive techniques to handle different question types.","meta":{"url":"http://arxiv.org/abs/2309.05500v1"},"cats":{"new-dataset":0.1195994166,"dev-research":0.1701308353,"data-quality":0.1987027754}}
{"text":"Our approaches achieve outstanding results on both tasks of the competition, demonstrating the potential benefits and effectiveness of question answering systems in the legal field, particularly for low-resource languages.","meta":{"url":"http://arxiv.org/abs/2309.05500v1"},"cats":{"new-dataset":0.205232426,"dev-research":0.2201066946,"data-quality":0.1723156932}}
{"text":"Co-salient Object Detection (CoSOD) endeavors to replicate the human visual system's capacity to recognize common and salient objects within a collection of images.","meta":{"url":"http://arxiv.org/abs/2309.05499v1"},"cats":{"new-dataset":0.1149779423,"dev-research":0.1986820343,"data-quality":0.1226986091}}
{"text":"Despite recent advancements in deep learning models, these models still rely on training with well-annotated CoSOD datasets.","meta":{"url":"http://arxiv.org/abs/2309.05499v1"},"cats":{"new-dataset":0.2118721536,"dev-research":0.1504542041,"data-quality":0.3359876752}}
{"text":"The exploration of training-free zero-shot CoSOD frameworks has been limited.","meta":{"url":"http://arxiv.org/abs/2309.05499v1"},"cats":{"new-dataset":0.0656770622,"dev-research":0.1335824395,"data-quality":0.0804159861}}
{"text":"In this paper, taking inspiration from the zero-shot transfer capabilities of foundational computer vision models, we introduce the first zero-shot CoSOD framework that harnesses these models without any training process.","meta":{"url":"http://arxiv.org/abs/2309.05499v1"},"cats":{"new-dataset":0.1505568578,"dev-research":0.1177221029,"data-quality":0.111775407}}
{"text":"To achieve this, we introduce two novel components in our proposed framework: the group prompt generation (GPG) module and the co-saliency map generation (CMP) module.","meta":{"url":"http://arxiv.org/abs/2309.05499v1"},"cats":{"new-dataset":0.398692555,"dev-research":0.2472845422,"data-quality":0.0937824359}}
{"text":"We evaluate the framework's performance on widely-used datasets and observe impressive results.","meta":{"url":"http://arxiv.org/abs/2309.05499v1"},"cats":{"new-dataset":0.666633874,"dev-research":0.1981687604,"data-quality":0.1807070401}}
{"text":"Our approach surpasses existing unsupervised methods and even outperforms fully supervised methods developed before 2020, while remaining competitive with some fully supervised methods developed before 2022.","meta":{"url":"http://arxiv.org/abs/2309.05499v1"},"cats":{"new-dataset":0.1405914804,"dev-research":0.1610363365,"data-quality":0.276132331}}
{"text":"Personality types are important in various fields as they hold relevant information about the characteristics of a human being in an explainable format.","meta":{"url":"http://arxiv.org/abs/2309.05497v1"},"cats":{"new-dataset":0.0221712173,"dev-research":0.273732341,"data-quality":0.0812676942}}
{"text":"They are often good predictors of a person's behaviors in a particular environment and have applications ranging from candidate selection to marketing and mental health.","meta":{"url":"http://arxiv.org/abs/2309.05497v1"},"cats":{"new-dataset":0.0245706434,"dev-research":0.2451621132,"data-quality":0.0854223164}}
{"text":"Recently automatic detection of personality traits from texts has gained significant attention in computational linguistics.","meta":{"url":"http://arxiv.org/abs/2309.05497v1"},"cats":{"new-dataset":0.0890537772,"dev-research":0.2517635844,"data-quality":0.2534602522}}
{"text":"Most personality detection and analysis methods have focused on small datasets making their experimental observations often limited.","meta":{"url":"http://arxiv.org/abs/2309.05497v1"},"cats":{"new-dataset":0.06707571,"dev-research":0.2216734852,"data-quality":0.1310967988}}
{"text":"To bridge this gap, we focus on collecting and releasing the largest automatically curated dataset for the research community which has 152 million tweets and 56 thousand data points for the Myers-Briggs personality type (MBTI) prediction task.","meta":{"url":"http://arxiv.org/abs/2309.05497v1"},"cats":{"new-dataset":0.78913394,"dev-research":0.1883687059,"data-quality":0.0919360297}}
{"text":"We perform a series of extensive qualitative and quantitative studies on our dataset to analyze the data patterns in a better way and infer conclusions.","meta":{"url":"http://arxiv.org/abs/2309.05497v1"},"cats":{"new-dataset":0.525751273,"dev-research":0.3243469957,"data-quality":0.1366542205}}
{"text":"We show how our intriguing analysis results often follow natural intuition.","meta":{"url":"http://arxiv.org/abs/2309.05497v1"},"cats":{"new-dataset":0.0184656283,"dev-research":0.2474807048,"data-quality":0.1743058656}}
{"text":"We also perform a series of ablation studies to show how the baselines perform for our dataset.","meta":{"url":"http://arxiv.org/abs/2309.05497v1"},"cats":{"new-dataset":0.3288041051,"dev-research":0.160824007,"data-quality":0.1090363105}}
{"text":"Social media platforms play an essential role in crisis communication, but analyzing crisis-related social media texts is challenging due to their informal nature.","meta":{"url":"http://arxiv.org/abs/2309.05494v1"},"cats":{"new-dataset":0.1126595198,"dev-research":0.2372306067,"data-quality":0.2022845978}}
{"text":"Transformer-based pre-trained models like BERT and RoBERTa have shown success in various NLP tasks, but they are not tailored for crisis-related texts.","meta":{"url":"http://arxiv.org/abs/2309.05494v1"},"cats":{"new-dataset":0.0542782342,"dev-research":0.1737548941,"data-quality":0.1776517601}}
{"text":"Furthermore, general-purpose sentence encoders are used to generate sentence embeddings, regardless of the textual complexities in crisis-related texts.","meta":{"url":"http://arxiv.org/abs/2309.05494v1"},"cats":{"new-dataset":0.0770043024,"dev-research":0.2310038136,"data-quality":0.1848884446}}
{"text":"Advances in applications like text classification, semantic search, and clustering contribute to effective processing of crisis-related texts, which is essential for emergency responders to gain a comprehensive view of a crisis event, whether historical or real-time.","meta":{"url":"http://arxiv.org/abs/2309.05494v1"},"cats":{"new-dataset":0.096512354,"dev-research":0.2307609837,"data-quality":0.2296055927}}
{"text":"To address these gaps in crisis informatics literature, this study introduces CrisisTransformers, an ensemble of pre-trained language models and sentence encoders trained on an extensive corpus of over 15 billion word tokens from tweets associated with more than 30 crisis events, including disease outbreaks, natural disasters, conflicts, and other critical incidents.","meta":{"url":"http://arxiv.org/abs/2309.05494v1"},"cats":{"new-dataset":0.4694864372,"dev-research":0.2241598626,"data-quality":0.2269356784}}
{"text":"We evaluate existing models and CrisisTransformers on 18 crisis-specific public datasets.","meta":{"url":"http://arxiv.org/abs/2309.05494v1"},"cats":{"new-dataset":0.7918585367,"dev-research":0.169165884,"data-quality":0.1353302151}}
{"text":"Our pre-trained models outperform strong baselines across all datasets in classification tasks, and our best-performing sentence encoder improves the state-of-the-art by 17.43% in sentence encoding tasks.","meta":{"url":"http://arxiv.org/abs/2309.05494v1"},"cats":{"new-dataset":0.2430076505,"dev-research":0.2007618701,"data-quality":0.2304069444}}
{"text":"Additionally, we investigate the impact of model initialization on convergence and evaluate the significance of domain-specific models in generating semantically meaningful sentence embeddings.","meta":{"url":"http://arxiv.org/abs/2309.05494v1"},"cats":{"new-dataset":0.04389329,"dev-research":0.2195001803,"data-quality":0.2451460315}}
{"text":"All models are publicly released (https://huggingface.co/crisistransformers), with the anticipation that they will serve as a robust baseline for tasks involving the analysis of crisis-related social media texts.","meta":{"url":"http://arxiv.org/abs/2309.05494v1"},"cats":{"new-dataset":0.3157414643,"dev-research":0.1836838456,"data-quality":0.1052002966}}
{"text":"Many fields are experiencing a Big Data explosion, with data collection rates outpacing the rate of computing performance improvements predicted by Moore's Law.   ","meta":{"url":"http://arxiv.org/abs/2309.05491v1"},"cats":{"new-dataset":0.2541582011,"dev-research":0.211659356,"data-quality":0.1041587784}}
{"text":"Researchers are often interested in similarity search on such data.   ","meta":{"url":"http://arxiv.org/abs/2309.05491v1"},"cats":{"new-dataset":0.2117148966,"dev-research":0.1409880836,"data-quality":0.0843933212}}
{"text":"We present CAKES (CLAM-Accelerated $K$-NN Entropy Scaling Search), a novel algorithm for $k$-nearest-neighbor ($k$-NN) search which leverages geometric and topological properties inherent in large datasets.   ","meta":{"url":"http://arxiv.org/abs/2309.05491v1"},"cats":{"new-dataset":0.1515226225,"dev-research":0.0984569036,"data-quality":0.0592037591}}
{"text":"CAKES assumes the manifold hypothesis and performs best when data occupy a low dimensional manifold, even if the data occupy a very high dimensional embedding space.   ","meta":{"url":"http://arxiv.org/abs/2309.05491v1"},"cats":{"new-dataset":0.0238577878,"dev-research":0.1467258928,"data-quality":0.0968208993}}
{"text":"We demonstrate performance improvements ranging from hundreds to tens of thousands of times faster when compared to state-of-the-art approaches such as FAISS and HNSW, when benchmarked on 5 standard datasets.   ","meta":{"url":"http://arxiv.org/abs/2309.05491v1"},"cats":{"new-dataset":0.6065418479,"dev-research":0.1840205022,"data-quality":0.1554654503}}
{"text":"Unlike locality-sensitive hashing approaches, CAKES can work with any user-defined distance function.   ","meta":{"url":"http://arxiv.org/abs/2309.05491v1"},"cats":{"new-dataset":0.0238670938,"dev-research":0.1776930798,"data-quality":0.086950162}}
{"text":"When data occupy a metric space, CAKES exhibits perfect recall.","meta":{"url":"http://arxiv.org/abs/2309.05491v1"},"cats":{"new-dataset":0.2199427966,"dev-research":0.2003085245,"data-quality":0.169798524}}
{"text":"Semantic segmentation is crucial in remote sensing, where high-resolution satellite images are segmented into meaningful regions.","meta":{"url":"http://arxiv.org/abs/2309.05490v1"},"cats":{"new-dataset":0.2536215971,"dev-research":0.1627242276,"data-quality":0.2039328982}}
{"text":"Recent advancements in deep learning have significantly improved satellite image segmentation.","meta":{"url":"http://arxiv.org/abs/2309.05490v1"},"cats":{"new-dataset":0.1540621778,"dev-research":0.1469580586,"data-quality":0.1452833984}}
{"text":"However, most of these methods are typically trained in fully supervised settings that require high-quality pixel-level annotations, which are expensive and time-consuming to obtain.","meta":{"url":"http://arxiv.org/abs/2309.05490v1"},"cats":{"new-dataset":0.1008460263,"dev-research":0.235426597,"data-quality":0.3560697695}}
{"text":"In this work, we present a weakly supervised learning algorithm to train semantic segmentation algorithms that only rely on query point annotations instead of full mask labels.","meta":{"url":"http://arxiv.org/abs/2309.05490v1"},"cats":{"new-dataset":0.1804076193,"dev-research":0.1376474534,"data-quality":0.4873695695}}
{"text":"Our proposed approach performs accurate semantic segmentation and improves efficiency by significantly reducing the cost and time required for manual annotation.","meta":{"url":"http://arxiv.org/abs/2309.05490v1"},"cats":{"new-dataset":0.2411240898,"dev-research":0.2606136662,"data-quality":0.4877077577}}
{"text":"Specifically, we generate superpixels and extend the query point labels into those superpixels that group similar meaningful semantics.","meta":{"url":"http://arxiv.org/abs/2309.05490v1"},"cats":{"new-dataset":0.1344650042,"dev-research":0.1801784142,"data-quality":0.2365161204}}
{"text":"Then, we train semantic segmentation models, supervised with images partially labeled with the superpixels pseudo-labels.","meta":{"url":"http://arxiv.org/abs/2309.05490v1"},"cats":{"new-dataset":0.1867241071,"dev-research":0.1459106381,"data-quality":0.3352064466}}
{"text":"We benchmark our weakly supervised training approach on an aerial image dataset and different semantic segmentation architectures, showing that we can reach competitive performance compared to fully supervised training while reducing the annotation effort.","meta":{"url":"http://arxiv.org/abs/2309.05490v1"},"cats":{"new-dataset":0.2519396509,"dev-research":0.1478669625,"data-quality":0.3275322589}}
{"text":"Data-Centric Concurrency Control (DCCC) shifts the reasoning about concurrency restrictions from control structures to data declaration.","meta":{"url":"http://arxiv.org/abs/2309.05483v1"},"cats":{"new-dataset":0.1135960275,"dev-research":0.3470247512,"data-quality":0.1474385178}}
{"text":"It is a high-level declarative approach that abstracts away from the actual concurrency control mechanism(s) in use.","meta":{"url":"http://arxiv.org/abs/2309.05483v1"},"cats":{"new-dataset":0.0046793256,"dev-research":0.325342821,"data-quality":0.0825999062}}
{"text":"Despite its advantages, the practical use of DCCC is hindered by the fact that it may require many annotations and/or multiple implementations of the same method to cope with differently qualified parameters.","meta":{"url":"http://arxiv.org/abs/2309.05483v1"},"cats":{"new-dataset":0.0066596588,"dev-research":0.3505509076,"data-quality":0.2213879959}}
{"text":"Moreover, the existing DCCC solutions do not address the use of interfaces, precluding their use in most object-oriented programs.","meta":{"url":"http://arxiv.org/abs/2309.05483v1"},"cats":{"new-dataset":0.0136086091,"dev-research":0.355547062,"data-quality":0.1186985824}}
{"text":"To overcome these limitations, in this paper we present AtomiS, a new DCCC model based on a rigorously defined type-sound programming language.","meta":{"url":"http://arxiv.org/abs/2309.05483v1"},"cats":{"new-dataset":0.0803801302,"dev-research":0.3054323478,"data-quality":0.1297001102}}
{"text":"Programming with AtomiS requires only (atomic)-qualifying types of parameters and return values in interface definitions, and of fields in class definitions.","meta":{"url":"http://arxiv.org/abs/2309.05483v1"},"cats":{"new-dataset":0.0308694149,"dev-research":0.1900923008,"data-quality":0.1126760374}}
{"text":"From this atomicity specification, a static analysis infers the atomicity constraints that are local to each method, considering valid only the method variants that are consistent with the specification, and performs code generation for all valid variants of each method.","meta":{"url":"http://arxiv.org/abs/2309.05483v1"},"cats":{"new-dataset":0.0244411877,"dev-research":0.3405265892,"data-quality":0.1919786827}}
{"text":"The generated code is then the target for automatic injection of concurrency control primitives, by means of the desired automatic technique and associated atomicity and deadlock-freedom guarantees, which can be plugged-into the model's pipeline.","meta":{"url":"http://arxiv.org/abs/2309.05483v1"},"cats":{"new-dataset":0.0500047688,"dev-research":0.3082937604,"data-quality":0.1446066218}}
{"text":"We present the foundations for the AtomiS analysis and synthesis, with formal guarantees that the generated program is well-typed and that it corresponds behaviourally to the original one.","meta":{"url":"http://arxiv.org/abs/2309.05483v1"},"cats":{"new-dataset":0.1009917053,"dev-research":0.3118746393,"data-quality":0.1125367593}}
{"text":"The proofs are mechanised in Coq.","meta":{"url":"http://arxiv.org/abs/2309.05483v1"},"cats":{"new-dataset":0.058496429,"dev-research":0.2120216714,"data-quality":0.1454757025}}
{"text":"We also provide a Java implementation that showcases the applicability of AtomiS in real-life programs.","meta":{"url":"http://arxiv.org/abs/2309.05483v1"},"cats":{"new-dataset":0.138428372,"dev-research":0.3488362235,"data-quality":0.0897177007}}
{"text":"The rapid growth of interest in quantum computing has brought about the need to secure these powerful machines against a range of physical attacks.","meta":{"url":"http://arxiv.org/abs/2309.05478v1"},"cats":{"new-dataset":0.0205494112,"dev-research":0.1832180123,"data-quality":0.0512824185}}
{"text":"As qubit counts increase and quantum computers achieve higher levels of fidelity, their potential to execute novel algorithms and generate sensitive intellectual property becomes more promising.","meta":{"url":"http://arxiv.org/abs/2309.05478v1"},"cats":{"new-dataset":0.021294338,"dev-research":0.1931242933,"data-quality":0.0976515333}}
{"text":"However, there is a significant gap in our understanding of the vulnerabilities these computers face in terms of security and privacy attacks.","meta":{"url":"http://arxiv.org/abs/2309.05478v1"},"cats":{"new-dataset":0.0356993776,"dev-research":0.375346488,"data-quality":0.1803151067}}
{"text":"Among the potential threats are physical attacks, including those orchestrated by malicious insiders within data centers where the quantum computers are located, which could compromise the integrity of computations and resulting data.","meta":{"url":"http://arxiv.org/abs/2309.05478v1"},"cats":{"new-dataset":0.0428485501,"dev-research":0.2703772306,"data-quality":0.1033891153}}
{"text":"This paper presents an exploration of fault-injection attacks as one class of physical attacks on quantum computers.","meta":{"url":"http://arxiv.org/abs/2309.05478v1"},"cats":{"new-dataset":0.0215517449,"dev-research":0.2556522501,"data-quality":0.2157112191}}
{"text":"This work first introduces a classification of fault-injection attacks and strategies, including the domain of fault-injection attacks, the fault targets, and fault manifestations in quantum computers.","meta":{"url":"http://arxiv.org/abs/2309.05478v1"},"cats":{"new-dataset":0.0309664032,"dev-research":0.2565477657,"data-quality":0.261173864}}
{"text":"The resulting classification highlights the potential threats that exist.","meta":{"url":"http://arxiv.org/abs/2309.05478v1"},"cats":{"new-dataset":0.0580742941,"dev-research":0.2437305129,"data-quality":0.2319857871}}
{"text":"By shedding light on the vulnerabilities of quantum computers to fault-injection attacks, this work contributes to the development of robust security measures for this emerging technology.","meta":{"url":"http://arxiv.org/abs/2309.05478v1"},"cats":{"new-dataset":0.0273996291,"dev-research":0.2512975076,"data-quality":0.2089020391}}
{"text":"Pool-based active learning (AL) is a promising technology for increasing data-efficiency of machine learning models.","meta":{"url":"http://arxiv.org/abs/2309.05477v1"},"cats":{"new-dataset":0.0484734077,"dev-research":0.1893163188,"data-quality":0.1480186882}}
{"text":"However, surveys show that performance of recent AL methods is very sensitive to the choice of dataset and training setting, making them unsuitable for general application.","meta":{"url":"http://arxiv.org/abs/2309.05477v1"},"cats":{"new-dataset":0.0137388955,"dev-research":0.2029603262,"data-quality":0.2031284456}}
{"text":"In order to tackle this problem, the field Learning Active Learning (LAL) suggests to learn the active learning strategy itself, allowing it to adapt to the given setting.","meta":{"url":"http://arxiv.org/abs/2309.05477v1"},"cats":{"new-dataset":0.0454115199,"dev-research":0.1688878529,"data-quality":0.1560822934}}
{"text":"In this work, we propose a novel LAL method for classification that exploits symmetry and independence properties of the active learning problem with an Attentive Conditional Neural Process model.","meta":{"url":"http://arxiv.org/abs/2309.05477v1"},"cats":{"new-dataset":0.0432874337,"dev-research":0.1276964363,"data-quality":0.2034702326}}
{"text":"Our approach is based on learning from a myopic oracle, which gives our model the ability to adapt to non-standard objectives, such as those that do not equally weight the error on all data points.","meta":{"url":"http://arxiv.org/abs/2309.05477v1"},"cats":{"new-dataset":0.0117097597,"dev-research":0.2123016093,"data-quality":0.2693301506}}
{"text":"We experimentally verify that our Neural Process model outperforms a variety of baselines in these settings.","meta":{"url":"http://arxiv.org/abs/2309.05477v1"},"cats":{"new-dataset":0.0218275079,"dev-research":0.1880814986,"data-quality":0.171447116}}
{"text":"Finally, our experiments show that our model exhibits a tendency towards improved stability to changing datasets.","meta":{"url":"http://arxiv.org/abs/2309.05477v1"},"cats":{"new-dataset":0.2370768264,"dev-research":0.1978391895,"data-quality":0.2550814139}}
{"text":"However, performance is sensitive to choice of classifier and more work is necessary to reduce the performance the gap with the myopic oracle and to improve scalability.","meta":{"url":"http://arxiv.org/abs/2309.05477v1"},"cats":{"new-dataset":0.0100029064,"dev-research":0.2590409337,"data-quality":0.1513749923}}
{"text":"We present our work as a proof-of-concept for LAL on nonstandard objectives and hope our analysis and modelling considerations inspire future LAL work.","meta":{"url":"http://arxiv.org/abs/2309.05477v1"},"cats":{"new-dataset":0.0240173931,"dev-research":0.1664795618,"data-quality":0.1269828731}}
{"text":"Demographics, Social determinants of health, and family history documented in the unstructured text within the electronic health records are increasingly being studied to understand how this information can be utilized with the structured data to improve healthcare outcomes.","meta":{"url":"http://arxiv.org/abs/2309.05475v1"},"cats":{"new-dataset":0.1014972243,"dev-research":0.2707034049,"data-quality":0.1211775258}}
{"text":"After the GPT models were released, many studies have applied GPT models to extract this information from the narrative clinical notes.","meta":{"url":"http://arxiv.org/abs/2309.05475v1"},"cats":{"new-dataset":0.0262749191,"dev-research":0.1614370578,"data-quality":0.0618536717}}
{"text":"Different from the existing work, our research focuses on investigating the zero-shot learning on extracting this information together by providing minimum information to the GPT model.","meta":{"url":"http://arxiv.org/abs/2309.05475v1"},"cats":{"new-dataset":0.1003726789,"dev-research":0.0899487727,"data-quality":0.1674471051}}
{"text":"We utilize de-identified real-world clinical notes annotated for demographics, various social determinants, and family history information.","meta":{"url":"http://arxiv.org/abs/2309.05475v1"},"cats":{"new-dataset":0.2821175838,"dev-research":0.2674385325,"data-quality":0.1607034706}}
{"text":"Given that the GPT model might provide text different from the text in the original data, we explore two sets of evaluation metrics, including the traditional NER evaluation metrics and semantic similarity evaluation metrics, to completely understand the performance.","meta":{"url":"http://arxiv.org/abs/2309.05475v1"},"cats":{"new-dataset":0.0873584793,"dev-research":0.1871512379,"data-quality":0.2247230599}}
{"text":"Our results show that the GPT-3.5 method achieved an average of 0.975 F1 on demographics extraction, 0.615 F1 on social determinants extraction, and 0.722 F1 on family history extraction.","meta":{"url":"http://arxiv.org/abs/2309.05475v1"},"cats":{"new-dataset":0.1077185508,"dev-research":0.1307697586,"data-quality":0.1550778571}}
{"text":"We believe these results can be further improved through model fine-tuning or few-shots learning.","meta":{"url":"http://arxiv.org/abs/2309.05475v1"},"cats":{"new-dataset":0.0736487593,"dev-research":0.1458197891,"data-quality":0.2925802125}}
{"text":"Through the case studies, we also identified the limitations of the GPT models, which need to be addressed in future research.","meta":{"url":"http://arxiv.org/abs/2309.05475v1"},"cats":{"new-dataset":0.0077723539,"dev-research":0.1321525619,"data-quality":0.0460223705}}
{"text":"Self-supervised learning (SSL) is at the origin of unprecedented improvements in many different domains including computer vision and natural language processing.","meta":{"url":"http://arxiv.org/abs/2309.05472v1"},"cats":{"new-dataset":0.0837024503,"dev-research":0.1778829209,"data-quality":0.2346155567}}
{"text":"Speech processing drastically benefitted from SSL as most of the current domain-related tasks are now being approached with pre-trained models.","meta":{"url":"http://arxiv.org/abs/2309.05472v1"},"cats":{"new-dataset":0.04044393,"dev-research":0.1876365624,"data-quality":0.1444015977}}
{"text":"This work introduces LeBenchmark 2.0 an open-source framework for assessing and building SSL-equipped French speech technologies.","meta":{"url":"http://arxiv.org/abs/2309.05472v1"},"cats":{"new-dataset":0.2649622081,"dev-research":0.2138996498,"data-quality":0.2180296128}}
{"text":"It includes documented, large-scale and heterogeneous corpora with up to 14,000 hours of heterogeneous speech, ten pre-trained SSL wav2vec 2.0 models containing from 26 million to one billion learnable parameters shared with the community, and an evaluation protocol made of six downstream tasks to complement existing benchmarks.","meta":{"url":"http://arxiv.org/abs/2309.05472v1"},"cats":{"new-dataset":0.5523619761,"dev-research":0.1692441693,"data-quality":0.1305782206}}
{"text":"LeBenchmark 2.0 also presents unique perspectives on pre-trained SSL models for speech with the investigation of frozen versus fine-tuned downstream models, task-agnostic versus task-specific pre-trained models as well as a discussion on the carbon footprint of large-scale model training.","meta":{"url":"http://arxiv.org/abs/2309.05472v1"},"cats":{"new-dataset":0.0808289055,"dev-research":0.1544410187,"data-quality":0.1544360365}}
{"text":"We present ImageBind-LLM, a multi-modality instruction tuning method of large language models (LLMs) via ImageBind.","meta":{"url":"http://arxiv.org/abs/2309.03905v1"},"cats":{"new-dataset":0.1200730656,"dev-research":0.1405363484,"data-quality":0.1532808683}}
{"text":"Existing works mainly focus on language and image instruction tuning, different from which, our ImageBind-LLM can respond to multi-modality conditions, including audio, 3D point clouds, video, and their embedding-space arithmetic by only image-text alignment training.","meta":{"url":"http://arxiv.org/abs/2309.03905v1"},"cats":{"new-dataset":0.1161029532,"dev-research":0.1172807596,"data-quality":0.1511418981}}
{"text":"During training, we adopt a learnable bind network to align the embedding space between LLaMA and ImageBind's image encoder.","meta":{"url":"http://arxiv.org/abs/2309.03905v1"},"cats":{"new-dataset":0.1003419077,"dev-research":0.1243044075,"data-quality":0.119611245}}
{"text":"Then, the image features transformed by the bind network are added to word tokens of all layers in LLaMA, which progressively injects visual instructions via an attention-free and zero-initialized gating mechanism.","meta":{"url":"http://arxiv.org/abs/2309.03905v1"},"cats":{"new-dataset":0.0459580453,"dev-research":0.1338853695,"data-quality":0.1260416416}}
{"text":"Aided by the joint embedding of ImageBind, the simple image-text training enables our model to exhibit superior multi-modality instruction-following capabilities.","meta":{"url":"http://arxiv.org/abs/2309.03905v1"},"cats":{"new-dataset":0.0366357888,"dev-research":0.1293554009,"data-quality":0.1633767397}}
{"text":"During inference, the multi-modality inputs are fed into the corresponding ImageBind encoders, and processed by a proposed visual cache model for further cross-modal embedding enhancement.","meta":{"url":"http://arxiv.org/abs/2309.03905v1"},"cats":{"new-dataset":0.041357155,"dev-research":0.110769316,"data-quality":0.1156244696}}
{"text":"The training-free cache model retrieves from three million image features extracted by ImageBind, which effectively mitigates the training-inference modality discrepancy.","meta":{"url":"http://arxiv.org/abs/2309.03905v1"},"cats":{"new-dataset":0.0672894267,"dev-research":0.1215986817,"data-quality":0.2331887586}}
{"text":"Notably, with our approach, ImageBind-LLM can respond to instructions of diverse modalities and demonstrate significant language generation quality.","meta":{"url":"http://arxiv.org/abs/2309.03905v1"},"cats":{"new-dataset":0.1017699317,"dev-research":0.1880687803,"data-quality":0.2153505129}}
{"text":"Code is released at https://github.com/OpenGVLab/LLaMA-Adapter.","meta":{"url":"http://arxiv.org/abs/2309.03905v1"},"cats":{"new-dataset":0.1056097696,"dev-research":0.1035471147,"data-quality":0.1052136833}}
{"text":"Due to the difficulty in scaling up, generative adversarial networks (GANs) seem to be falling from grace on the task of text-conditioned image synthesis.","meta":{"url":"http://arxiv.org/abs/2309.03904v1"},"cats":{"new-dataset":0.0618427154,"dev-research":0.1684158298,"data-quality":0.171974261}}
{"text":"Sparsely-activated mixture-of-experts (MoE) has recently been demonstrated as a valid solution to training large-scale models with limited computational resources.","meta":{"url":"http://arxiv.org/abs/2309.03904v1"},"cats":{"new-dataset":0.0314059448,"dev-research":0.1419962969,"data-quality":0.1365196849}}
{"text":"Inspired by such a philosophy, we present Aurora, a GAN-based text-to-image generator that employs a collection of experts to learn feature processing, together with a sparse router to help select the most suitable expert for each feature point.","meta":{"url":"http://arxiv.org/abs/2309.03904v1"},"cats":{"new-dataset":0.265271682,"dev-research":0.2138831912,"data-quality":0.1388092879}}
{"text":"To faithfully decode the sampling stochasticity and the text condition to the final synthesis, our router adaptively makes its decision by taking into account the text-integrated global latent code.","meta":{"url":"http://arxiv.org/abs/2309.03904v1"},"cats":{"new-dataset":0.0283211503,"dev-research":0.1840518485,"data-quality":0.1825357353}}
{"text":"At 64x64 image resolution, our model trained on LAION2B-en and COYO-700M achieves 6.2 zero-shot FID on MS COCO.","meta":{"url":"http://arxiv.org/abs/2309.03904v1"},"cats":{"new-dataset":0.3650726112,"dev-research":0.1112076192,"data-quality":0.1207775651}}
{"text":"We release the code and checkpoints to facilitate the community for further development.","meta":{"url":"http://arxiv.org/abs/2309.03904v1"},"cats":{"new-dataset":0.49033225,"dev-research":0.6302603964,"data-quality":0.122762064}}
{"text":"Training data for video segmentation are expensive to annotate.","meta":{"url":"http://arxiv.org/abs/2309.03903v1"},"cats":{"new-dataset":0.3406441991,"dev-research":0.2296542839,"data-quality":0.3799274511}}
{"text":"This impedes extensions of end-to-end algorithms to new video segmentation tasks, especially in large-vocabulary settings.","meta":{"url":"http://arxiv.org/abs/2309.03903v1"},"cats":{"new-dataset":0.2038066466,"dev-research":0.1742576231,"data-quality":0.1936749908}}
{"text":"To 'track anything' without training on video data for every individual task, we develop a decoupled video segmentation approach (DEVA), composed of task-specific image-level segmentation and class/task-agnostic bi-directional temporal propagation.","meta":{"url":"http://arxiv.org/abs/2309.03903v1"},"cats":{"new-dataset":0.2608719967,"dev-research":0.1814935415,"data-quality":0.1483042364}}
{"text":"Due to this design, we only need an image-level model for the target task (which is cheaper to train) and a universal temporal propagation model which is trained once and generalizes across tasks.","meta":{"url":"http://arxiv.org/abs/2309.03903v1"},"cats":{"new-dataset":0.0244895923,"dev-research":0.1521143014,"data-quality":0.0446144773}}
{"text":"To effectively combine these two modules, we use bi-directional propagation for (semi-)online fusion of segmentation hypotheses from different frames to generate a coherent segmentation.","meta":{"url":"http://arxiv.org/abs/2309.03903v1"},"cats":{"new-dataset":0.1065751465,"dev-research":0.1338808874,"data-quality":0.1613018683}}
{"text":"We show that this decoupled formulation compares favorably to end-to-end approaches in several data-scarce tasks including large-vocabulary video panoptic segmentation, open-world video segmentation, referring video segmentation, and unsupervised video object segmentation.","meta":{"url":"http://arxiv.org/abs/2309.03903v1"},"cats":{"new-dataset":0.427721783,"dev-research":0.1637553329,"data-quality":0.1508055528}}
{"text":"Code is available at: https://hkchengrex.github.io/Tracking-Anything-with-DEVA","meta":{"url":"http://arxiv.org/abs/2309.03903v1"},"cats":{"new-dataset":0.4369544368,"dev-research":0.2613335854,"data-quality":0.1609915559}}
{"text":"Not all camouflages are equally effective, as even a partially visible contour or a slight color difference can make the animal stand out and break its camouflage.","meta":{"url":"http://arxiv.org/abs/2309.03899v1"},"cats":{"new-dataset":0.0255820908,"dev-research":0.2173509448,"data-quality":0.1707430684}}
{"text":"In this paper, we address the question of what makes a camouflage successful, by proposing three scores for automatically assessing its effectiveness.","meta":{"url":"http://arxiv.org/abs/2309.03899v1"},"cats":{"new-dataset":0.063240888,"dev-research":0.2537021104,"data-quality":0.2163437327}}
{"text":"In particular, we show that camouflage can be measured by the similarity between background and foreground features and boundary visibility.","meta":{"url":"http://arxiv.org/abs/2309.03899v1"},"cats":{"new-dataset":0.1781447069,"dev-research":0.191797324,"data-quality":0.1392773478}}
{"text":"We use these camouflage scores to assess and compare all available camouflage datasets.","meta":{"url":"http://arxiv.org/abs/2309.03899v1"},"cats":{"new-dataset":0.6322000252,"dev-research":0.2014701402,"data-quality":0.191942161}}
{"text":"We also incorporate the proposed camouflage score into a generative model as an auxiliary loss and show that effective camouflage images or videos can be synthesised in a scalable manner.","meta":{"url":"http://arxiv.org/abs/2309.03899v1"},"cats":{"new-dataset":0.1851971475,"dev-research":0.1910051285,"data-quality":0.1977496376}}
{"text":"The generated synthetic dataset is used to train a transformer-based model for segmenting camouflaged animals in videos.","meta":{"url":"http://arxiv.org/abs/2309.03899v1"},"cats":{"new-dataset":0.6057531947,"dev-research":0.1807604383,"data-quality":0.2085492058}}
{"text":"Experimentally, we demonstrate state-of-the-art camouflage breaking performance on the public MoCA-Mask benchmark.","meta":{"url":"http://arxiv.org/abs/2309.03899v1"},"cats":{"new-dataset":0.1047701691,"dev-research":0.1924361383,"data-quality":0.1627830602}}
{"text":"This study presents a spatiotemporal traffic prediction approach for NextG mobile networks, ensuring the service-level agreements (SLAs) of each network slice.","meta":{"url":"http://arxiv.org/abs/2309.03898v1"},"cats":{"new-dataset":0.0769714872,"dev-research":0.114385485,"data-quality":0.0614046597}}
{"text":"Our approach is multivariate, multi-step, and spatiotemporal.","meta":{"url":"http://arxiv.org/abs/2309.03898v1"},"cats":{"new-dataset":0.1918874989,"dev-research":0.1407546465,"data-quality":0.0596794677}}
{"text":"Leveraging 20 radio access network (RAN) features, peak traffic hour data, and mobility-based clustering, we propose a parametric SLA-based loss function to guarantee an SLA violation rate.","meta":{"url":"http://arxiv.org/abs/2309.03898v1"},"cats":{"new-dataset":0.0287760483,"dev-research":0.1745064776,"data-quality":0.1387903469}}
{"text":"We focus on single-cell, multi-cell, and slice-based prediction approaches and present a detailed comparative analysis of their performances, strengths, and limitations.   ","meta":{"url":"http://arxiv.org/abs/2309.03898v1"},"cats":{"new-dataset":0.029726139,"dev-research":0.1147743718,"data-quality":0.0587257868}}
{"text":"First, we address the application of single-cell and multi-cell training architectures.","meta":{"url":"http://arxiv.org/abs/2309.03898v1"},"cats":{"new-dataset":0.0276533039,"dev-research":0.1195538019,"data-quality":0.0828139112}}
{"text":"While single-cell training offers individual cell-level prediction, multi-cell training involves training a model using traffic from multiple cells from the same or different base stations.","meta":{"url":"http://arxiv.org/abs/2309.03898v1"},"cats":{"new-dataset":0.0173128676,"dev-research":0.1298451842,"data-quality":0.0763154554}}
{"text":"We show that the single-cell approach outperforms the multi-cell approach and results in test loss improvements of 11.4% and 38.1% compared to baseline SLA-based and MAE-based models, respectively.   ","meta":{"url":"http://arxiv.org/abs/2309.03898v1"},"cats":{"new-dataset":0.0114220957,"dev-research":0.1518150478,"data-quality":0.1150324653}}
{"text":"Next, we explore slice-based traffic prediction.","meta":{"url":"http://arxiv.org/abs/2309.03898v1"},"cats":{"new-dataset":0.1172808358,"dev-research":0.1301725347,"data-quality":0.0885737102}}
{"text":"We present single-slice and multi-slice methods for slice-based downlink traffic volume prediction, arguing that multi-slice prediction offers a more accurate forecast.","meta":{"url":"http://arxiv.org/abs/2309.03898v1"},"cats":{"new-dataset":0.0456842137,"dev-research":0.1221611247,"data-quality":0.0740488363}}
{"text":"The slice-based model we introduce offers substantial test loss improvements of 28.2%, 36.4%, and 55.6% compared to our cell-based model, the baseline SLA-based model, and the baseline MAE-based model, respectively.","meta":{"url":"http://arxiv.org/abs/2309.03898v1"},"cats":{"new-dataset":0.0160798319,"dev-research":0.172630451,"data-quality":0.1140913304}}
{"text":"Flow-based propagation and spatiotemporal Transformer are two mainstream mechanisms in video inpainting (VI).","meta":{"url":"http://arxiv.org/abs/2309.03897v1"},"cats":{"new-dataset":0.0202089214,"dev-research":0.1724322642,"data-quality":0.0821101741}}
{"text":"Despite the effectiveness of these components, they still suffer from some limitations that affect their performance.","meta":{"url":"http://arxiv.org/abs/2309.03897v1"},"cats":{"new-dataset":0.0030497862,"dev-research":0.2425463825,"data-quality":0.1530220322}}
{"text":"Previous propagation-based approaches are performed separately either in the image or feature domain.","meta":{"url":"http://arxiv.org/abs/2309.03897v1"},"cats":{"new-dataset":0.010277175,"dev-research":0.1867391526,"data-quality":0.1224725507}}
{"text":"Global image propagation isolated from learning may cause spatial misalignment due to inaccurate optical flow.","meta":{"url":"http://arxiv.org/abs/2309.03897v1"},"cats":{"new-dataset":0.0083006855,"dev-research":0.1754028965,"data-quality":0.2413992632}}
{"text":"Moreover, memory or computational constraints limit the temporal range of feature propagation and video Transformer, preventing exploration of correspondence information from distant frames.","meta":{"url":"http://arxiv.org/abs/2309.03897v1"},"cats":{"new-dataset":0.034938126,"dev-research":0.1838635294,"data-quality":0.0625463231}}
{"text":"To address these issues, we propose an improved framework, called ProPainter, which involves enhanced ProPagation and an efficient Transformer.","meta":{"url":"http://arxiv.org/abs/2309.03897v1"},"cats":{"new-dataset":0.0220136841,"dev-research":0.2616254935,"data-quality":0.0702269174}}
{"text":"Specifically, we introduce dual-domain propagation that combines the advantages of image and feature warping, exploiting global correspondences reliably.","meta":{"url":"http://arxiv.org/abs/2309.03897v1"},"cats":{"new-dataset":0.0517521856,"dev-research":0.1618102083,"data-quality":0.1450709764}}
{"text":"We also propose a mask-guided sparse video Transformer, which achieves high efficiency by discarding unnecessary and redundant tokens.","meta":{"url":"http://arxiv.org/abs/2309.03897v1"},"cats":{"new-dataset":0.024434328,"dev-research":0.1460141699,"data-quality":0.1178013209}}
{"text":"With these components, ProPainter outperforms prior arts by a large margin of 1.46 dB in PSNR while maintaining appealing efficiency.","meta":{"url":"http://arxiv.org/abs/2309.03897v1"},"cats":{"new-dataset":0.047310444,"dev-research":0.1914369511,"data-quality":0.1345865225}}
{"text":"We present InstructDiffusion, a unifying and generic framework for aligning computer vision tasks with human instructions.","meta":{"url":"http://arxiv.org/abs/2309.03895v1"},"cats":{"new-dataset":0.0880874559,"dev-research":0.3314080133,"data-quality":0.1121626932}}
{"text":"Unlike existing approaches that integrate prior knowledge and pre-define the output space (e.g., categories and coordinates) for each vision task, we cast diverse vision tasks into a human-intuitive image-manipulating process whose output space is a flexible and interactive pixel space.","meta":{"url":"http://arxiv.org/abs/2309.03895v1"},"cats":{"new-dataset":0.0638644327,"dev-research":0.2581314843,"data-quality":0.069566463}}
{"text":"Concretely, the model is built upon the diffusion process and is trained to predict pixels according to user instructions, such as encircling the man's left shoulder in red or applying a blue mask to the left car.","meta":{"url":"http://arxiv.org/abs/2309.03895v1"},"cats":{"new-dataset":0.049178894,"dev-research":0.1703638619,"data-quality":0.0650513389}}
{"text":"InstructDiffusion could handle a variety of vision tasks, including understanding tasks (such as segmentation and keypoint detection) and generative tasks (such as editing and enhancement).","meta":{"url":"http://arxiv.org/abs/2309.03895v1"},"cats":{"new-dataset":0.023113464,"dev-research":0.3241271877,"data-quality":0.0934384917}}
{"text":"It even exhibits the ability to handle unseen tasks and outperforms prior methods on novel datasets.","meta":{"url":"http://arxiv.org/abs/2309.03895v1"},"cats":{"new-dataset":0.0372985881,"dev-research":0.2159930469,"data-quality":0.1687415625}}
{"text":"This represents a significant step towards a generalist modeling interface for vision tasks, advancing artificial general intelligence in the field of computer vision.","meta":{"url":"http://arxiv.org/abs/2309.03895v1"},"cats":{"new-dataset":0.0513008113,"dev-research":0.178857426,"data-quality":0.0836932746}}
{"text":"Data is the cornerstone of deep learning.","meta":{"url":"http://arxiv.org/abs/2309.03893v1"},"cats":{"new-dataset":0.1345788821,"dev-research":0.17310394,"data-quality":0.1347687795}}
{"text":"This paper reveals that the recently developed Diffusion Model is a scalable data engine for object detection.","meta":{"url":"http://arxiv.org/abs/2309.03893v1"},"cats":{"new-dataset":0.0726246353,"dev-research":0.1168440633,"data-quality":0.1270459782}}
{"text":"Existing methods for scaling up detection-oriented data often require manual collection or generative models to obtain target images, followed by data augmentation and labeling to produce training pairs, which are costly, complex, or lacking diversity.","meta":{"url":"http://arxiv.org/abs/2309.03893v1"},"cats":{"new-dataset":0.122967566,"dev-research":0.157766211,"data-quality":0.2521917896}}
{"text":"To address these issues, we presentDiffusionEngine (DE), a data scaling-up engine that provides high-quality detection-oriented training pairs in a single stage.","meta":{"url":"http://arxiv.org/abs/2309.03893v1"},"cats":{"new-dataset":0.2908866682,"dev-research":0.2006581487,"data-quality":0.315473797}}
{"text":"DE consists of a pre-trained diffusion model and an effective Detection-Adapter, contributing to generating scalable, diverse and generalizable detection data in a plug-and-play manner.","meta":{"url":"http://arxiv.org/abs/2309.03893v1"},"cats":{"new-dataset":0.1307159472,"dev-research":0.1548606011,"data-quality":0.1541879497}}
{"text":"Detection-Adapter is learned to align the implicit semantic and location knowledge in off-the-shelf diffusion models with detection-aware signals to make better bounding-box predictions.","meta":{"url":"http://arxiv.org/abs/2309.03893v1"},"cats":{"new-dataset":0.050364522,"dev-research":0.1508308989,"data-quality":0.129994877}}
{"text":"Additionally, we contribute two datasets, i.e., COCO-DE and VOC-DE, to scale up existing detection benchmarks for facilitating follow-up research.","meta":{"url":"http://arxiv.org/abs/2309.03893v1"},"cats":{"new-dataset":0.4646300013,"dev-research":0.1865474593,"data-quality":0.2327707376}}
{"text":"Extensive experiments demonstrate that data scaling-up via DE can achieve significant improvements in diverse scenarios, such as various detection algorithms, self-supervised pre-training, data-sparse, label-scarce, cross-domain, and semi-supervised learning.","meta":{"url":"http://arxiv.org/abs/2309.03893v1"},"cats":{"new-dataset":0.1131602425,"dev-research":0.1438662707,"data-quality":0.2681775099}}
{"text":"For example, when using DE with a DINO-based adapter to scale up data, mAP is improved by 3.1% on COCO, 7.6% on VOC, and 11.5% on Clipart.","meta":{"url":"http://arxiv.org/abs/2309.03893v1"},"cats":{"new-dataset":0.1212792911,"dev-research":0.1867444676,"data-quality":0.1294115014}}
{"text":"We present ArtiGrasp, a novel method to synthesize bi-manual hand-object interactions that include grasping and articulation.","meta":{"url":"http://arxiv.org/abs/2309.03891v1"},"cats":{"new-dataset":0.2493377797,"dev-research":0.2632465266,"data-quality":0.0576705642}}
{"text":"This task is challenging due to the diversity of the global wrist motions and the precise finger control that are necessary to articulate objects.","meta":{"url":"http://arxiv.org/abs/2309.03891v1"},"cats":{"new-dataset":0.0240330743,"dev-research":0.1771678904,"data-quality":0.0504216637}}
{"text":"ArtiGrasp leverages reinforcement learning and physics simulations to train a policy that controls the global and local hand pose.","meta":{"url":"http://arxiv.org/abs/2309.03891v1"},"cats":{"new-dataset":0.1250873052,"dev-research":0.1848921003,"data-quality":0.0519173424}}
{"text":"Our framework unifies grasping and articulation within a single policy guided by a single hand pose reference.","meta":{"url":"http://arxiv.org/abs/2309.03891v1"},"cats":{"new-dataset":0.1364277071,"dev-research":0.2000262929,"data-quality":0.0835811641}}
{"text":"Moreover, to facilitate the training of the precise finger control required for articulation, we present a learning curriculum with increasing difficulty.","meta":{"url":"http://arxiv.org/abs/2309.03891v1"},"cats":{"new-dataset":0.1383913799,"dev-research":0.2336167041,"data-quality":0.075397988}}
{"text":"It starts with single-hand manipulation of stationary objects and continues with multi-agent training including both hands and non-stationary objects.","meta":{"url":"http://arxiv.org/abs/2309.03891v1"},"cats":{"new-dataset":0.1554025367,"dev-research":0.1360812203,"data-quality":0.0438422614}}
{"text":"To evaluate our method, we introduce Dynamic Object Grasping and Articulation, a task that involves bringing an object into a target articulated pose.","meta":{"url":"http://arxiv.org/abs/2309.03891v1"},"cats":{"new-dataset":0.0944672706,"dev-research":0.2082624429,"data-quality":0.0646859195}}
{"text":"This task requires grasping, relocation, and articulation.","meta":{"url":"http://arxiv.org/abs/2309.03891v1"},"cats":{"new-dataset":0.0975509975,"dev-research":0.2156438451,"data-quality":0.043333553}}
{"text":"We show our method's efficacy towards this task.","meta":{"url":"http://arxiv.org/abs/2309.03891v1"},"cats":{"new-dataset":0.0130564781,"dev-research":0.2401120633,"data-quality":0.1439457427}}
{"text":"We further demonstrate that our method can generate motions with noisy hand-object pose estimates from an off-the-shelf image-based regressor.","meta":{"url":"http://arxiv.org/abs/2309.03891v1"},"cats":{"new-dataset":0.4654654643,"dev-research":0.1645100387,"data-quality":0.1054659429}}
{"text":"Labeling neural network submodules with human-legible descriptions is useful for many downstream tasks: such descriptions can surface failures, guide interventions, and perhaps even explain important model behaviors.","meta":{"url":"http://arxiv.org/abs/2309.03886v1"},"cats":{"new-dataset":0.0769627476,"dev-research":0.2965415929,"data-quality":0.3712678301}}
{"text":"To date, most mechanistic descriptions of trained networks have involved small models, narrowly delimited phenomena, and large amounts of human labor.","meta":{"url":"http://arxiv.org/abs/2309.03886v1"},"cats":{"new-dataset":0.0185843143,"dev-research":0.2098650861,"data-quality":0.1278427765}}
{"text":"Labeling all human-interpretable sub-computations in models of increasing size and complexity will almost certainly require tools that can generate and validate descriptions automatically.","meta":{"url":"http://arxiv.org/abs/2309.03886v1"},"cats":{"new-dataset":0.0912602406,"dev-research":0.3694282393,"data-quality":0.2305801096}}
{"text":"Recently, techniques that use learned models in-the-loop for labeling have begun to gain traction, but methods for evaluating their efficacy are limited and ad-hoc.","meta":{"url":"http://arxiv.org/abs/2309.03886v1"},"cats":{"new-dataset":0.1040461623,"dev-research":0.2184310102,"data-quality":0.5790205564}}
{"text":"How should we validate and compare open-ended labeling tools?","meta":{"url":"http://arxiv.org/abs/2309.03886v1"},"cats":{"new-dataset":0.1027349907,"dev-research":0.312962859,"data-quality":0.6032377792}}
{"text":"This paper introduces FIND (Function INterpretation and Description), a benchmark suite for evaluating the building blocks of automated interpretability methods.","meta":{"url":"http://arxiv.org/abs/2309.03886v1"},"cats":{"new-dataset":0.1870735586,"dev-research":0.4437875344,"data-quality":0.3723630279}}
{"text":"FIND contains functions that resemble components of trained neural networks, and accompanying descriptions of the kind we seek to generate.","meta":{"url":"http://arxiv.org/abs/2309.03886v1"},"cats":{"new-dataset":0.1332902154,"dev-research":0.191978826,"data-quality":0.2006253979}}
{"text":"The functions are procedurally constructed across textual and numeric domains, and involve a range of real-world complexities, including noise, composition, approximation, and bias.","meta":{"url":"http://arxiv.org/abs/2309.03886v1"},"cats":{"new-dataset":0.0511564992,"dev-research":0.2243683048,"data-quality":0.1420411812}}
{"text":"We evaluate new and existing methods that use language models (LMs) to produce code-based and language descriptions of function behavior.","meta":{"url":"http://arxiv.org/abs/2309.03886v1"},"cats":{"new-dataset":0.0371781438,"dev-research":0.4327128829,"data-quality":0.2476518783}}
{"text":"We find that an off-the-shelf LM augmented with only black-box access to functions can sometimes infer their structure, acting as a scientist by forming hypotheses, proposing experiments, and updating descriptions in light of new data.","meta":{"url":"http://arxiv.org/abs/2309.03886v1"},"cats":{"new-dataset":0.0661155837,"dev-research":0.1555221345,"data-quality":0.1275993681}}
{"text":"However, LM-based descriptions tend to capture global function behavior and miss local corruptions.","meta":{"url":"http://arxiv.org/abs/2309.03886v1"},"cats":{"new-dataset":0.0282597292,"dev-research":0.3188655912,"data-quality":0.3673603318}}
{"text":"These results show that FIND will be useful for characterizing the performance of more sophisticated interpretability methods before they are applied to real-world models.","meta":{"url":"http://arxiv.org/abs/2309.03886v1"},"cats":{"new-dataset":0.0420829291,"dev-research":0.2981893655,"data-quality":0.2632188621}}
{"text":"The task of audio captioning is similar in essence to tasks such as image and video captioning.","meta":{"url":"http://arxiv.org/abs/2309.03884v1"},"cats":{"new-dataset":0.0325746934,"dev-research":0.235795121,"data-quality":0.1955588633}}
{"text":"However, it has received much less attention.","meta":{"url":"http://arxiv.org/abs/2309.03884v1"},"cats":{"new-dataset":0.01276111,"dev-research":0.209601751,"data-quality":0.1550571917}}
{"text":"We propose three desiderata for captioning audio -- (i) fluency of the generated text, (ii) faithfulness of the generated text to the input audio, and the somewhat related (iii) audibility, which is the quality of being able to be perceived based only on audio.","meta":{"url":"http://arxiv.org/abs/2309.03884v1"},"cats":{"new-dataset":0.0736023597,"dev-research":0.2077674442,"data-quality":0.3506019968}}
{"text":"Our method is a zero-shot method, i.e., we do not learn to perform captioning.","meta":{"url":"http://arxiv.org/abs/2309.03884v1"},"cats":{"new-dataset":0.0320887897,"dev-research":0.1908883464,"data-quality":0.3498929369}}
{"text":"Instead, captioning occurs as an inference process that involves three networks that correspond to the three desired qualities: (i) A Large Language Model, in our case, for reasons of convenience, GPT-2, (ii) A model that provides a matching score between an audio file and a text, for which we use a multimodal matching network called ImageBind, and (iii) A text classifier, trained using a dataset we collected automatically by instructing GPT-4 with prompts designed to direct the generation of both audible and inaudible sentences.","meta":{"url":"http://arxiv.org/abs/2309.03884v1"},"cats":{"new-dataset":0.2638086577,"dev-research":0.1736898803,"data-quality":0.3233296007}}
{"text":"We present our results on the AudioCap dataset, demonstrating that audibility guidance significantly enhances performance compared to the baseline, which lacks this objective.","meta":{"url":"http://arxiv.org/abs/2309.03884v1"},"cats":{"new-dataset":0.2692945721,"dev-research":0.2194700808,"data-quality":0.2829324072}}
{"text":"Despite their impressive capabilities, large language models (LLMs) are prone to hallucinations, i.e., generating content that deviates from facts seen during pretraining.","meta":{"url":"http://arxiv.org/abs/2309.03883v1"},"cats":{"new-dataset":0.0361166664,"dev-research":0.2111199568,"data-quality":0.2041646801}}
{"text":"We propose a simple decoding strategy for reducing hallucinations with pretrained LLMs that does not require conditioning on retrieved external knowledge nor additional fine-tuning.","meta":{"url":"http://arxiv.org/abs/2309.03883v1"},"cats":{"new-dataset":0.0280439629,"dev-research":0.1556749016,"data-quality":0.153729786}}
{"text":"Our approach obtains the next-token distribution by contrasting the differences in logits obtained from projecting the later layers versus earlier layers to the vocabulary space, exploiting the fact that factual knowledge in an LLMs has generally been shown to be localized to particular transformer layers.","meta":{"url":"http://arxiv.org/abs/2309.03883v1"},"cats":{"new-dataset":0.0565288454,"dev-research":0.1596400521,"data-quality":0.2080444737}}
{"text":"We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts.","meta":{"url":"http://arxiv.org/abs/2309.03883v1"},"cats":{"new-dataset":0.1008689561,"dev-research":0.3053349353,"data-quality":0.3257563504}}
{"text":"DoLa consistently improves the truthfulness across multiple choices tasks and open-ended generation tasks, for example improving the performance of LLaMA family models on TruthfulQA by 12-17% absolute points, demonstrating its potential in making LLMs reliably generate truthful facts.","meta":{"url":"http://arxiv.org/abs/2309.03883v1"},"cats":{"new-dataset":0.04773778,"dev-research":0.1611908061,"data-quality":0.1039037123}}
{"text":"Multi-choice questions (MCQs) serve as a common yet important task format in the research of large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2309.03882v1"},"cats":{"new-dataset":0.0298586307,"dev-research":0.1392533935,"data-quality":0.0957415574}}
{"text":"Our work shows that LLMs exhibit an inherent \"selection bias\" in MCQs, which refers to LLMs' preferences to select options located at specific positions (like \"Option C\").","meta":{"url":"http://arxiv.org/abs/2309.03882v1"},"cats":{"new-dataset":0.0131832816,"dev-research":0.1134885335,"data-quality":0.0997663217}}
{"text":"This bias is prevalent across various LLMs, making their performance vulnerable to option position changes in MCQs.","meta":{"url":"http://arxiv.org/abs/2309.03882v1"},"cats":{"new-dataset":0.0040572509,"dev-research":0.1358503278,"data-quality":0.1108657753}}
{"text":"We identify that one primary cause resulting in selection bias is option numbering, i.e., the ID symbols A/B/C/D associated with the options.","meta":{"url":"http://arxiv.org/abs/2309.03882v1"},"cats":{"new-dataset":0.0146583694,"dev-research":0.1668719474,"data-quality":0.216753902}}
{"text":"To mitigate selection bias, we propose a new method called PriDe.","meta":{"url":"http://arxiv.org/abs/2309.03882v1"},"cats":{"new-dataset":0.0077983218,"dev-research":0.1862478311,"data-quality":0.171781223}}
{"text":"PriDe first decomposes the observed model prediction distribution into an intrinsic prediction over option contents and a prior distribution over option IDs.","meta":{"url":"http://arxiv.org/abs/2309.03882v1"},"cats":{"new-dataset":0.0216110808,"dev-research":0.1312035565,"data-quality":0.1453496765}}
{"text":"It then estimates the prior by permutating option contents on a small number of test samples, which is used to debias the subsequent test samples.","meta":{"url":"http://arxiv.org/abs/2309.03882v1"},"cats":{"new-dataset":0.0150942576,"dev-research":0.1694542362,"data-quality":0.1075364778}}
{"text":"We demonstrate that, as a label-free, inference-time method, PriDe achieves a more effective and computation-efficient debiasing than strong baselines.","meta":{"url":"http://arxiv.org/abs/2309.03882v1"},"cats":{"new-dataset":0.1012053217,"dev-research":0.1882328592,"data-quality":0.2957609647}}
{"text":"We further show that the priors estimated by PriDe generalize well across different domains, highlighting its practical potential in broader scenarios.","meta":{"url":"http://arxiv.org/abs/2309.03882v1"},"cats":{"new-dataset":0.0187442145,"dev-research":0.1715487017,"data-quality":0.1430563884}}
{"text":"Distribution shifts are all too common in real-world applications of machine learning.","meta":{"url":"http://arxiv.org/abs/2309.03879v1"},"cats":{"new-dataset":0.0135330998,"dev-research":0.1638310308,"data-quality":0.2290698118}}
{"text":"Domain adaptation (DA) aims to address this by providing various frameworks for adapting models to the deployment data without using labels.","meta":{"url":"http://arxiv.org/abs/2309.03879v1"},"cats":{"new-dataset":0.0683474768,"dev-research":0.2566140168,"data-quality":0.2981976622}}
{"text":"However, the domain shift scenario raises a second more subtle challenge: the difficulty of performing hyperparameter optimisation (HPO) for these adaptation algorithms without access to a labelled validation set.","meta":{"url":"http://arxiv.org/abs/2309.03879v1"},"cats":{"new-dataset":0.0133845547,"dev-research":0.1579812615,"data-quality":0.2127782044}}
{"text":"The unclear validation protocol for DA has led to bad practices in the literature, such as performing HPO using the target test labels when, in real-world scenarios, they are not available.","meta":{"url":"http://arxiv.org/abs/2309.03879v1"},"cats":{"new-dataset":0.0130281866,"dev-research":0.3051254794,"data-quality":0.4989971116}}
{"text":"This has resulted in over-optimism about DA research progress compared to reality.","meta":{"url":"http://arxiv.org/abs/2309.03879v1"},"cats":{"new-dataset":0.0260549122,"dev-research":0.2767669209,"data-quality":0.136340185}}
{"text":"In this paper, we analyse the state of DA when using good evaluation practice, by benchmarking a suite of candidate validation criteria and using them to assess popular adaptation algorithms.","meta":{"url":"http://arxiv.org/abs/2309.03879v1"},"cats":{"new-dataset":0.0304448605,"dev-research":0.2537676907,"data-quality":0.2505941392}}
{"text":"We show that there are challenges across all three branches of domain adaptation methodology including Unsupervised Domain Adaptation (UDA), Source-Free Domain Adaptation (SFDA), and Test Time Adaptation (TTA).","meta":{"url":"http://arxiv.org/abs/2309.03879v1"},"cats":{"new-dataset":0.0639113828,"dev-research":0.2196603684,"data-quality":0.2404860902}}
{"text":"While the results show that realistically achievable performance is often worse than expected, they also show that using proper validation splits is beneficial, as well as showing that some previously unexplored validation metrics provide the best options to date.","meta":{"url":"http://arxiv.org/abs/2309.03879v1"},"cats":{"new-dataset":0.0067354777,"dev-research":0.2836633603,"data-quality":0.2563857034}}
{"text":"Altogether, our improved practices covering data, training, validation and hyperparameter optimisation form a new rigorous pipeline to improve benchmarking, and hence research progress, within this important field going forward.","meta":{"url":"http://arxiv.org/abs/2309.03879v1"},"cats":{"new-dataset":0.0610161904,"dev-research":0.2457993845,"data-quality":0.1397117769}}
{"text":"Envision an intelligent agent capable of assisting users in conducting forecasting tasks through intuitive, natural conversations, without requiring in-depth knowledge of the underlying machine learning (ML) processes.","meta":{"url":"http://arxiv.org/abs/2309.03877v1"},"cats":{"new-dataset":0.0774727277,"dev-research":0.2195026724,"data-quality":0.0662810581}}
{"text":"A significant challenge for the agent in this endeavor is to accurately comprehend the user's prediction goals and, consequently, formulate precise ML tasks.","meta":{"url":"http://arxiv.org/abs/2309.03877v1"},"cats":{"new-dataset":0.0362523324,"dev-research":0.2139544382,"data-quality":0.1383045073}}
{"text":"In this paper, we take a pioneering step towards this ambitious goal by introducing a new concept called Forecast Utterance and then focus on the automatic and accurate interpretation of users' prediction goals from these utterances.","meta":{"url":"http://arxiv.org/abs/2309.03877v1"},"cats":{"new-dataset":0.1529256606,"dev-research":0.2524554259,"data-quality":0.1746638414}}
{"text":"Specifically, we frame the task as a slot-filling problem, where each slot corresponds to a specific aspect of the goal prediction task.","meta":{"url":"http://arxiv.org/abs/2309.03877v1"},"cats":{"new-dataset":0.0319491317,"dev-research":0.2549793119,"data-quality":0.1155314636}}
{"text":"We then employ two zero-shot methods for solving the slot-filling task, namely: 1) Entity Extraction (EE), and 2) Question-Answering (QA) techniques.","meta":{"url":"http://arxiv.org/abs/2309.03877v1"},"cats":{"new-dataset":0.1523720918,"dev-research":0.1794082038,"data-quality":0.2404564937}}
{"text":"Our experiments, conducted with three meticulously crafted data sets, validate the viability of our ambitious goal and demonstrate the effectiveness of both EE and QA techniques in interpreting Forecast Utterances.","meta":{"url":"http://arxiv.org/abs/2309.03877v1"},"cats":{"new-dataset":0.2528017432,"dev-research":0.1896396699,"data-quality":0.1849748721}}
{"text":"Instruction-tuned Large Language Models (LLMs) have recently showcased remarkable ability to generate fitting responses to natural language instructions.","meta":{"url":"http://arxiv.org/abs/2309.03876v1"},"cats":{"new-dataset":0.0899582867,"dev-research":0.1704711102,"data-quality":0.1524593904}}
{"text":"However, an open research question concerns the inherent biases of trained models and their responses.","meta":{"url":"http://arxiv.org/abs/2309.03876v1"},"cats":{"new-dataset":0.0065620216,"dev-research":0.176171491,"data-quality":0.1439071551}}
{"text":"For instance, if the data used to tune an LLM is dominantly written by persons with a specific political bias, we might expect generated answers to share this bias.","meta":{"url":"http://arxiv.org/abs/2309.03876v1"},"cats":{"new-dataset":0.0415733504,"dev-research":0.1328770791,"data-quality":0.1349345144}}
{"text":"Current research work seeks to de-bias such models, or suppress potentially biased answers.","meta":{"url":"http://arxiv.org/abs/2309.03876v1"},"cats":{"new-dataset":0.0041695496,"dev-research":0.2242094156,"data-quality":0.0975324916}}
{"text":"With this demonstration, we take a different view on biases in instruction-tuning: Rather than aiming to suppress them, we aim to make them explicit and transparent.","meta":{"url":"http://arxiv.org/abs/2309.03876v1"},"cats":{"new-dataset":0.0072216166,"dev-research":0.2801322499,"data-quality":0.2309225036}}
{"text":"To this end, we present OpinionGPT, a web demo in which users can ask questions and select all biases they wish to investigate.","meta":{"url":"http://arxiv.org/abs/2309.03876v1"},"cats":{"new-dataset":0.185887926,"dev-research":0.3126251392,"data-quality":0.1687010346}}
{"text":"The demo will answer this question using a model fine-tuned on text representing each of the selected biases, allowing side-by-side comparison.","meta":{"url":"http://arxiv.org/abs/2309.03876v1"},"cats":{"new-dataset":0.0222151758,"dev-research":0.1175210352,"data-quality":0.2211535074}}
{"text":"To train the underlying model, we identified 11 different biases (political, geographic, gender, age) and derived an instruction-tuning corpus in which each answer was written by members of one of these demographics.","meta":{"url":"http://arxiv.org/abs/2309.03876v1"},"cats":{"new-dataset":0.0991483505,"dev-research":0.2453669685,"data-quality":0.1926913114}}
{"text":"This paper presents OpinionGPT, illustrates how we trained the bias-aware model and showcases the web application (available at https://opiniongpt.informatik.hu-berlin.de).","meta":{"url":"http://arxiv.org/abs/2309.03876v1"},"cats":{"new-dataset":0.0615208691,"dev-research":0.2602327552,"data-quality":0.2714850963}}
{"text":"In this article, we propose using network-based sampling strategies to estimate the number of unsheltered people experiencing homelessness within a given administrative service unit, known as a Continuum of Care.","meta":{"url":"http://arxiv.org/abs/2309.03875v1"},"cats":{"new-dataset":0.0741885764,"dev-research":0.1747042518,"data-quality":0.1269171199}}
{"text":"Further, we specifically advocate for the network sampling method known as Respondent Driven Sampling (RDS), which has been shown to provide unbiased or low-biased estimates of totals and proportions for hard-to-reach populations in contexts where a sampling frame (e.g., housing addresses) not available.","meta":{"url":"http://arxiv.org/abs/2309.03875v1"},"cats":{"new-dataset":0.1395346928,"dev-research":0.1524698806,"data-quality":0.1176568396}}
{"text":"To make the RDS estimator work for estimating the total number of unsheltered people, we introduce a new method that leverages administrative data from the HUD-mandated Homeless Management Information System (HMIS).","meta":{"url":"http://arxiv.org/abs/2309.03875v1"},"cats":{"new-dataset":0.2471076089,"dev-research":0.2072775116,"data-quality":0.1071175107}}
{"text":"The HMIS provides high-quality counts and demographics for people experiencing homelessness who sleep in emergency shelters.","meta":{"url":"http://arxiv.org/abs/2309.03875v1"},"cats":{"new-dataset":0.108513346,"dev-research":0.2158913507,"data-quality":0.1045925071}}
{"text":"We then demonstrate this method using network data collected in Nashville, TN, combined with simulation methods to illustrate the efficacy of this approach.","meta":{"url":"http://arxiv.org/abs/2309.03875v1"},"cats":{"new-dataset":0.0511464195,"dev-research":0.15714588,"data-quality":0.1314740992}}
{"text":"Finally, we end with discussing how this could be used in practice.","meta":{"url":"http://arxiv.org/abs/2309.03875v1"},"cats":{"new-dataset":0.0115584899,"dev-research":0.3564828487,"data-quality":0.155694479}}
{"text":"It has been established that training a box-based detector network can enhance the localization performance of weakly supervised and unsupervised methods.","meta":{"url":"http://arxiv.org/abs/2309.03874v1"},"cats":{"new-dataset":0.0449853157,"dev-research":0.1440100559,"data-quality":0.2700153787}}
{"text":"Moreover, we extend this understanding by demonstrating that these detectors can be utilized to improve the original network, paving the way for further advancements.","meta":{"url":"http://arxiv.org/abs/2309.03874v1"},"cats":{"new-dataset":0.0277106078,"dev-research":0.1532558226,"data-quality":0.1892660044}}
{"text":"To accomplish this, we train the detectors on top of the network output instead of the image data and apply suitable loss backpropagation.","meta":{"url":"http://arxiv.org/abs/2309.03874v1"},"cats":{"new-dataset":0.0680423605,"dev-research":0.1233323292,"data-quality":0.2188908639}}
{"text":"Our findings reveal a significant improvement in phrase grounding for the ``what is where by looking'' task, as well as various methods of unsupervised object discovery.","meta":{"url":"http://arxiv.org/abs/2309.03874v1"},"cats":{"new-dataset":0.0820558023,"dev-research":0.245824971,"data-quality":0.2288250035}}
{"text":"Our code is available at https://github.com/eyalgomel/box-based-refinement.","meta":{"url":"http://arxiv.org/abs/2309.03874v1"},"cats":{"new-dataset":0.1429017132,"dev-research":0.2382892836,"data-quality":0.115408274}}
{"text":"We consider the problem of private membership aggregation (PMA), in which a user counts the number of times a certain element is stored in a system of independent parties that store arbitrary sets of elements from a universal alphabet.","meta":{"url":"http://arxiv.org/abs/2309.03872v1"},"cats":{"new-dataset":0.1649733535,"dev-research":0.1137698585,"data-quality":0.1530499335}}
{"text":"The parties are not allowed to learn which element is being counted by the user.","meta":{"url":"http://arxiv.org/abs/2309.03872v1"},"cats":{"new-dataset":0.0326211619,"dev-research":0.178637158,"data-quality":0.197433797}}
{"text":"Further, neither the user nor the other parties are allowed to learn the stored elements of each party involved in the process.","meta":{"url":"http://arxiv.org/abs/2309.03872v1"},"cats":{"new-dataset":0.05132727,"dev-research":0.168722349,"data-quality":0.1146276551}}
{"text":"PMA is a generalization of the recently introduced problem of $K$ private set intersection ($K$-PSI).","meta":{"url":"http://arxiv.org/abs/2309.03872v1"},"cats":{"new-dataset":0.0481801374,"dev-research":0.0975108463,"data-quality":0.1006800291}}
{"text":"The $K$-PSI problem considers a set of $M$ parties storing arbitrary sets of elements, and a user who wants to determine if a certain element is repeated at least at $K$ parties out of the $M$ parties without learning which party has the required element and which party does not.","meta":{"url":"http://arxiv.org/abs/2309.03872v1"},"cats":{"new-dataset":0.0550093413,"dev-research":0.1154756588,"data-quality":0.1416228978}}
{"text":"To solve the general problem of PMA, we dissect it into four categories based on the privacy requirement and the collusions among databases/parties.","meta":{"url":"http://arxiv.org/abs/2309.03872v1"},"cats":{"new-dataset":0.0581811336,"dev-research":0.1387184932,"data-quality":0.0982084284}}
{"text":"We map these problems into equivalent private information retrieval (PIR) problems.","meta":{"url":"http://arxiv.org/abs/2309.03872v1"},"cats":{"new-dataset":0.1190289282,"dev-research":0.1291950819,"data-quality":0.1790274647}}
{"text":"We propose achievable schemes for each of the four variants of the problem based on the concept of cross-subspace alignment (CSA).","meta":{"url":"http://arxiv.org/abs/2309.03872v1"},"cats":{"new-dataset":0.0664102249,"dev-research":0.125781678,"data-quality":0.148016078}}
{"text":"The proposed schemes achieve \\emph{linear} communication complexity as opposed to the state-of-the-art $K$-PSI scheme that requires \\emph{exponential} complexity even though our PMA problems contain more security and privacy constraints.","meta":{"url":"http://arxiv.org/abs/2309.03872v1"},"cats":{"new-dataset":0.0062837477,"dev-research":0.1113198316,"data-quality":0.0483478719}}
{"text":"Training deep learning models for video classification from audio-visual data commonly requires immense amounts of labeled training data collected via a costly process.","meta":{"url":"http://arxiv.org/abs/2309.03869v1"},"cats":{"new-dataset":0.288197486,"dev-research":0.1997447567,"data-quality":0.3145248176}}
{"text":"A challenging and underexplored, yet much cheaper, setup is few-shot learning from video data.","meta":{"url":"http://arxiv.org/abs/2309.03869v1"},"cats":{"new-dataset":0.2070601621,"dev-research":0.1608764604,"data-quality":0.1260184832}}
{"text":"In particular, the inherently multi-modal nature of video data with sound and visual information has not been leveraged extensively for the few-shot video classification task.","meta":{"url":"http://arxiv.org/abs/2309.03869v1"},"cats":{"new-dataset":0.0555274616,"dev-research":0.1465350571,"data-quality":0.224120137}}
{"text":"Therefore, we introduce a unified audio-visual few-shot video classification benchmark on three datasets, i.e. the VGGSound-FSL, UCF-FSL, ActivityNet-FSL datasets, where we adapt and compare ten methods.","meta":{"url":"http://arxiv.org/abs/2309.03869v1"},"cats":{"new-dataset":0.4927410983,"dev-research":0.1385470525,"data-quality":0.2243732879}}
{"text":"In addition, we propose AV-DIFF, a text-to-feature diffusion framework, which first fuses the temporal and audio-visual features via cross-modal attention and then generates multi-modal features for the novel classes.","meta":{"url":"http://arxiv.org/abs/2309.03869v1"},"cats":{"new-dataset":0.1642872923,"dev-research":0.1871909328,"data-quality":0.1596218408}}
{"text":"We show that AV-DIFF obtains state-of-the-art performance on our proposed benchmark for audio-visual (generalised) few-shot learning.","meta":{"url":"http://arxiv.org/abs/2309.03869v1"},"cats":{"new-dataset":0.1727044865,"dev-research":0.1771102988,"data-quality":0.2062977598}}
{"text":"Our benchmark paves the way for effective audio-visual classification when only limited labeled data is available.","meta":{"url":"http://arxiv.org/abs/2309.03869v1"},"cats":{"new-dataset":0.1187017007,"dev-research":0.1764719405,"data-quality":0.385365087}}
{"text":"Code and data are available at https://github.com/ExplainableML/AVDIFF-GFSL.","meta":{"url":"http://arxiv.org/abs/2309.03869v1"},"cats":{"new-dataset":0.4630532134,"dev-research":0.151479237,"data-quality":0.1006276502}}
{"text":"A multivariate cryptograpic instance in practice is a multivariate polynomial system.","meta":{"url":"http://arxiv.org/abs/2309.03855v1"},"cats":{"new-dataset":0.0455826876,"dev-research":0.1095843833,"data-quality":0.0775238572}}
{"text":"So the security of a protocol rely on the complexity of solving a multivariate polynomial system.","meta":{"url":"http://arxiv.org/abs/2309.03855v1"},"cats":{"new-dataset":0.005723553,"dev-research":0.1476357618,"data-quality":0.0518627564}}
{"text":"In this paper there is an overview on a general algorithm used to solve a multivariate system and the quantity to which the complexity of this algorithm depends on: the solving degree.","meta":{"url":"http://arxiv.org/abs/2309.03855v1"},"cats":{"new-dataset":0.0299532183,"dev-research":0.1286112333,"data-quality":0.0527622947}}
{"text":"Unfortunately, it is hard to compute.","meta":{"url":"http://arxiv.org/abs/2309.03855v1"},"cats":{"new-dataset":0.270501218,"dev-research":0.1123597715,"data-quality":0.1115872368}}
{"text":"For this reason, it is introduced an invariant: the degree of regularity.","meta":{"url":"http://arxiv.org/abs/2309.03855v1"},"cats":{"new-dataset":0.0044708593,"dev-research":0.1542918761,"data-quality":0.1663998258}}
{"text":"This invariant, under certain condition, give us an upper bound on the solving degree.","meta":{"url":"http://arxiv.org/abs/2309.03855v1"},"cats":{"new-dataset":0.0994337966,"dev-research":0.1209720471,"data-quality":0.1022096665}}
{"text":"Then we speak about random polynomial systems and in particular what \"random\" means to us.","meta":{"url":"http://arxiv.org/abs/2309.03855v1"},"cats":{"new-dataset":0.0161159191,"dev-research":0.1733945497,"data-quality":0.1258794221}}
{"text":"Finally, we give an upper bound on both the degree of regularity and the solving degree of such random systems.","meta":{"url":"http://arxiv.org/abs/2309.03855v1"},"cats":{"new-dataset":0.1187018594,"dev-research":0.0906003863,"data-quality":0.1187805412}}
{"text":"Large language models (LLMs) have achieved remarkable success in NLP and multimodal tasks.","meta":{"url":"http://arxiv.org/abs/2309.03852v1"},"cats":{"new-dataset":0.1524019702,"dev-research":0.1238795152,"data-quality":0.1333588288}}
{"text":"Despite these successes, their development faces two main challenges: (i) high computational cost; and (ii) difficulty in conducting fair and objective evaluations.","meta":{"url":"http://arxiv.org/abs/2309.03852v1"},"cats":{"new-dataset":0.0449485014,"dev-research":0.2890198074,"data-quality":0.1326094724}}
{"text":"LLMs are prohibitively expensive, making it feasible for only a few major players to undertake their training, thereby constraining both research and application opportunities.","meta":{"url":"http://arxiv.org/abs/2309.03852v1"},"cats":{"new-dataset":0.0084661768,"dev-research":0.1398668287,"data-quality":0.0603076817}}
{"text":"This underscores the importance of cost-effective LLM training.","meta":{"url":"http://arxiv.org/abs/2309.03852v1"},"cats":{"new-dataset":0.0077446222,"dev-research":0.1615020809,"data-quality":0.0761874876}}
{"text":"In this paper, we utilize a growth strategy to significantly reduce LLM training cost.","meta":{"url":"http://arxiv.org/abs/2309.03852v1"},"cats":{"new-dataset":0.0190240576,"dev-research":0.1189132758,"data-quality":0.0573835434}}
{"text":"We demonstrate that an LLM with 101B parameters and 0.31TB tokens can be trained on a $100K budget.","meta":{"url":"http://arxiv.org/abs/2309.03852v1"},"cats":{"new-dataset":0.0683299895,"dev-research":0.0894752764,"data-quality":0.1118359931}}
{"text":"We also adopt a systematic evaluation paradigm for the IQ evaluation of LLMs, in complement to existing evaluations that focus more on knowledge-oriented abilities.","meta":{"url":"http://arxiv.org/abs/2309.03852v1"},"cats":{"new-dataset":0.0175870168,"dev-research":0.223133284,"data-quality":0.1360577285}}
{"text":"We introduce our benchmark including evaluations on important aspects of intelligence including symbolic mapping, itrule understanding, pattern mining, and anti-interference.","meta":{"url":"http://arxiv.org/abs/2309.03852v1"},"cats":{"new-dataset":0.199372344,"dev-research":0.2651100727,"data-quality":0.2489970495}}
{"text":"Such evaluations minimize the potential impact of memorization.","meta":{"url":"http://arxiv.org/abs/2309.03852v1"},"cats":{"new-dataset":0.0031721171,"dev-research":0.2386709361,"data-quality":0.2292115443}}
{"text":"Experimental results show that our model FLM-101B, trained with a budget of $100K, achieves comparable performance to powerful and well-known models, eg GPT-3 and GLM-130B, especially in the IQ benchmark evaluations with contexts unseen in training data.","meta":{"url":"http://arxiv.org/abs/2309.03852v1"},"cats":{"new-dataset":0.1765038279,"dev-research":0.1106769202,"data-quality":0.0968414842}}
{"text":"The checkpoint of FLM-101B will be open-sourced at https://huggingface.co/CofeAI/FLM-101B.","meta":{"url":"http://arxiv.org/abs/2309.03852v1"},"cats":{"new-dataset":0.5715951042,"dev-research":0.1433600526,"data-quality":0.1174647875}}
{"text":"Survival analysis is a valuable tool for estimating the time until specific events, such as death or cancer recurrence, based on baseline observations.","meta":{"url":"http://arxiv.org/abs/2309.03851v1"},"cats":{"new-dataset":0.1162108601,"dev-research":0.2458102669,"data-quality":0.0530302992}}
{"text":"This is particularly useful in healthcare to prognostically predict clinically important events based on patient data.","meta":{"url":"http://arxiv.org/abs/2309.03851v1"},"cats":{"new-dataset":0.0781983119,"dev-research":0.306509322,"data-quality":0.0774155232}}
{"text":"However, existing approaches often have limitations; some focus only on ranking patients by survivability, neglecting to estimate the actual event time, while others treat the problem as a classification task, ignoring the inherent time-ordered structure of the events.","meta":{"url":"http://arxiv.org/abs/2309.03851v1"},"cats":{"new-dataset":0.0143460964,"dev-research":0.2096256781,"data-quality":0.0819615275}}
{"text":"Furthermore, the effective utilization of censored samples - training data points where the exact event time is unknown - is essential for improving the predictive accuracy of the model.","meta":{"url":"http://arxiv.org/abs/2309.03851v1"},"cats":{"new-dataset":0.0954896698,"dev-research":0.1296147841,"data-quality":0.2097911532}}
{"text":"In this paper, we introduce CenTime, a novel approach to survival analysis that directly estimates the time to event.","meta":{"url":"http://arxiv.org/abs/2309.03851v1"},"cats":{"new-dataset":0.3452652455,"dev-research":0.1631669898,"data-quality":0.0740665369}}
{"text":"Our method features an innovative event-conditional censoring mechanism that performs robustly even when uncensored data is scarce.","meta":{"url":"http://arxiv.org/abs/2309.03851v1"},"cats":{"new-dataset":0.1024144634,"dev-research":0.1174587811,"data-quality":0.1856223907}}
{"text":"We demonstrate that our approach forms a consistent estimator for the event model parameters, even in the absence of uncensored data.","meta":{"url":"http://arxiv.org/abs/2309.03851v1"},"cats":{"new-dataset":0.183795513,"dev-research":0.1374860198,"data-quality":0.1808164384}}
{"text":"Furthermore, CenTime is easily integrated with deep learning models with no restrictions on batch size or the number of uncensored samples.","meta":{"url":"http://arxiv.org/abs/2309.03851v1"},"cats":{"new-dataset":0.1827383002,"dev-research":0.0958627305,"data-quality":0.1211750193}}
{"text":"We compare our approach with standard survival analysis methods, including the Cox proportional-hazard model and DeepHit.","meta":{"url":"http://arxiv.org/abs/2309.03851v1"},"cats":{"new-dataset":0.1907201562,"dev-research":0.1848565448,"data-quality":0.0716568927}}
{"text":"Our results indicate that CenTime offers state-of-the-art performance in predicting time-to-death while maintaining comparable ranking performance.","meta":{"url":"http://arxiv.org/abs/2309.03851v1"},"cats":{"new-dataset":0.0898134608,"dev-research":0.19026709,"data-quality":0.1361707487}}
{"text":"Our implementation is publicly available at https://github.com/ahmedhshahin/CenTime.","meta":{"url":"http://arxiv.org/abs/2309.03851v1"},"cats":{"new-dataset":0.3561931426,"dev-research":0.1452219723,"data-quality":0.094020314}}
{"text":"Open Radio Access Network (O-RAN) is considered as a major step in the evolution of next-generation cellular networks given its support for open interfaces and utilization of artificial intelligence (AI) into the deployment, operation, and maintenance of RAN.","meta":{"url":"http://arxiv.org/abs/2309.03844v1"},"cats":{"new-dataset":0.0389250281,"dev-research":0.1593662912,"data-quality":0.067333763}}
{"text":"However, due to the openness of the O-RAN architecture, such AI models are inherently vulnerable to various adversarial machine learning (ML) attacks, i.e., adversarial attacks which correspond to slight manipulation of the input to the ML model.","meta":{"url":"http://arxiv.org/abs/2309.03844v1"},"cats":{"new-dataset":0.0100006422,"dev-research":0.1863526103,"data-quality":0.1648812749}}
{"text":"In this work, we showcase the vulnerability of an example ML model used in O-RAN, and experimentally deploy it in the near-real time (near-RT) RAN intelligent controller (RIC).","meta":{"url":"http://arxiv.org/abs/2309.03844v1"},"cats":{"new-dataset":0.0932566282,"dev-research":0.1878144076,"data-quality":0.10772668}}
{"text":"Our ML-based interference classifier xApp (extensible application in near-RT RIC) tries to classify the type of interference to mitigate the interference effect on the O-RAN system.","meta":{"url":"http://arxiv.org/abs/2309.03844v1"},"cats":{"new-dataset":0.0389464056,"dev-research":0.2071693567,"data-quality":0.2472545188}}
{"text":"We demonstrate the first-ever scenario of how such an xApp can be impacted through an adversarial attack by manipulating the data stored in a shared database inside the near-RT RIC.","meta":{"url":"http://arxiv.org/abs/2309.03844v1"},"cats":{"new-dataset":0.1238915496,"dev-research":0.1920662101,"data-quality":0.2108448115}}
{"text":"Through a rigorous performance analysis deployed on a laboratory O-RAN testbed, we evaluate the performance in terms of capacity and the prediction accuracy of the interference classifier xApp using both clean and perturbed data.","meta":{"url":"http://arxiv.org/abs/2309.03844v1"},"cats":{"new-dataset":0.0649474586,"dev-research":0.2476811119,"data-quality":0.3410212918}}
{"text":"We show that even small adversarial attacks can significantly decrease the accuracy of ML application in near-RT RIC, which can directly impact the performance of the entire O-RAN deployment.","meta":{"url":"http://arxiv.org/abs/2309.03844v1"},"cats":{"new-dataset":0.0517030668,"dev-research":0.1711546814,"data-quality":0.193579083}}
{"text":"Adaptive interfaces can help users perform sequential decision-making tasks like robotic teleoperation given noisy, high-dimensional command signals (e.g., from a brain-computer interface).","meta":{"url":"http://arxiv.org/abs/2309.03839v1"},"cats":{"new-dataset":0.0169566115,"dev-research":0.2501191481,"data-quality":0.0612736353}}
{"text":"Recent advances in human-in-the-loop machine learning enable such systems to improve by interacting with users, but tend to be limited by the amount of data that they can collect from individual users in practice.","meta":{"url":"http://arxiv.org/abs/2309.03839v1"},"cats":{"new-dataset":0.2237627592,"dev-research":0.2392599084,"data-quality":0.128269299}}
{"text":"In this paper, we propose a reinforcement learning algorithm to address this by training an interface to map raw command signals to actions using a combination of offline pre-training and online fine-tuning.","meta":{"url":"http://arxiv.org/abs/2309.03839v1"},"cats":{"new-dataset":0.1956572845,"dev-research":0.2205258398,"data-quality":0.0778299092}}
{"text":"To address the challenges posed by noisy command signals and sparse rewards, we develop a novel method for representing and inferring the user's long-term intent for a given trajectory.","meta":{"url":"http://arxiv.org/abs/2309.03839v1"},"cats":{"new-dataset":0.0414232338,"dev-research":0.1873643326,"data-quality":0.1005727227}}
{"text":"We primarily evaluate our method's ability to assist users who can only communicate through noisy, high-dimensional input channels through a user study in which 12 participants performed a simulated navigation task by using their eye gaze to modulate a 128-dimensional command signal from their webcam.","meta":{"url":"http://arxiv.org/abs/2309.03839v1"},"cats":{"new-dataset":0.066020386,"dev-research":0.3523309298,"data-quality":0.0605299804}}
{"text":"The results show that our method enables successful goal navigation more often than a baseline directional interface, by learning to denoise user commands signals and provide shared autonomy assistance.","meta":{"url":"http://arxiv.org/abs/2309.03839v1"},"cats":{"new-dataset":0.0413334117,"dev-research":0.2664033514,"data-quality":0.0812912659}}
{"text":"We further evaluate on a simulated Sawyer pushing task with eye gaze control, and the Lunar Lander game with simulated user commands, and find that our method improves over baseline interfaces in these domains as well.","meta":{"url":"http://arxiv.org/abs/2309.03839v1"},"cats":{"new-dataset":0.114184657,"dev-research":0.284840643,"data-quality":0.0454076059}}
{"text":"Extensive ablation experiments with simulated user commands empirically motivate each component of our method.","meta":{"url":"http://arxiv.org/abs/2309.03839v1"},"cats":{"new-dataset":0.0324002166,"dev-research":0.2478112697,"data-quality":0.1010248902}}
{"text":"Multi-task learning (MTL) is a powerful approach in deep learning that leverages the information from multiple tasks during training to improve model performance.","meta":{"url":"http://arxiv.org/abs/2309.03837v1"},"cats":{"new-dataset":0.1044732547,"dev-research":0.1679606971,"data-quality":0.0947101947}}
{"text":"In medical imaging, MTL has shown great potential to solve various tasks.","meta":{"url":"http://arxiv.org/abs/2309.03837v1"},"cats":{"new-dataset":0.0215879228,"dev-research":0.1593082661,"data-quality":0.0497966312}}
{"text":"However, existing MTL architectures in medical imaging are limited in sharing information across tasks, reducing the potential performance improvements of MTL.","meta":{"url":"http://arxiv.org/abs/2309.03837v1"},"cats":{"new-dataset":0.0279880051,"dev-research":0.1725515401,"data-quality":0.0490667984}}
{"text":"In this study, we introduce a novel attention-based MTL framework to better leverage inter-task interactions for various tasks from pixel-level to image-level predictions.","meta":{"url":"http://arxiv.org/abs/2309.03837v1"},"cats":{"new-dataset":0.1947866717,"dev-research":0.2206273435,"data-quality":0.0863008094}}
{"text":"Specifically, we propose a Cross-Task Attention Network (CTAN) which utilizes cross-task attention mechanisms to incorporate information by interacting across tasks.","meta":{"url":"http://arxiv.org/abs/2309.03837v1"},"cats":{"new-dataset":0.1775132071,"dev-research":0.1909269977,"data-quality":0.1129911361}}
{"text":"We validated CTAN on four medical imaging datasets that span different domains and tasks including: radiation treatment planning prediction using planning CT images of two different target cancers (Prostate, OpenKBP); pigmented skin lesion segmentation and diagnosis using dermatoscopic images (HAM10000); and COVID-19 diagnosis and severity prediction using chest CT scans (STOIC).","meta":{"url":"http://arxiv.org/abs/2309.03837v1"},"cats":{"new-dataset":0.6375562876,"dev-research":0.1863992466,"data-quality":0.1227671231}}
{"text":"Our study demonstrates the effectiveness of CTAN in improving the accuracy of medical imaging tasks.","meta":{"url":"http://arxiv.org/abs/2309.03837v1"},"cats":{"new-dataset":0.0882330703,"dev-research":0.234949994,"data-quality":0.1459896878}}
{"text":"Compared to standard single-task learning (STL), CTAN demonstrated a 4.67% improvement in performance and outperformed both widely used MTL baselines: hard parameter sharing (HPS) with an average performance improvement of 3.22%; and multi-task attention network (MTAN) with a relative decrease of 5.38%.","meta":{"url":"http://arxiv.org/abs/2309.03837v1"},"cats":{"new-dataset":0.0781069535,"dev-research":0.1578750498,"data-quality":0.1170323007}}
{"text":"These findings highlight the significance of our proposed MTL framework in solving medical imaging tasks and its potential to improve their accuracy across domains.","meta":{"url":"http://arxiv.org/abs/2309.03837v1"},"cats":{"new-dataset":0.0476757746,"dev-research":0.2047225264,"data-quality":0.0878087925}}
{"text":"Learning for Demonstration (LfD) enables robots to acquire new skills by imitating expert demonstrations, allowing users to communicate their instructions in an intuitive manner.","meta":{"url":"http://arxiv.org/abs/2309.03835v1"},"cats":{"new-dataset":0.0894484038,"dev-research":0.2096487726,"data-quality":0.0951538282}}
{"text":"Recent progress in LfD often relies on kinesthetic teaching or teleoperation as the medium for users to specify the demonstrations.","meta":{"url":"http://arxiv.org/abs/2309.03835v1"},"cats":{"new-dataset":0.0453685982,"dev-research":0.1563937643,"data-quality":0.0490797972}}
{"text":"Kinesthetic teaching requires physical handling of the robot, while teleoperation demands proficiency with additional hardware.","meta":{"url":"http://arxiv.org/abs/2309.03835v1"},"cats":{"new-dataset":0.0090284838,"dev-research":0.2096568318,"data-quality":0.0502178611}}
{"text":"This paper introduces an alternative paradigm for LfD called Diagrammatic Teaching.","meta":{"url":"http://arxiv.org/abs/2309.03835v1"},"cats":{"new-dataset":0.0814170616,"dev-research":0.2615041458,"data-quality":0.0964856562}}
{"text":"Diagrammatic Teaching aims to teach robots novel skills by prompting the user to sketch out demonstration trajectories on 2D images of the scene, these are then synthesised as a generative model of motion trajectories in 3D task space.","meta":{"url":"http://arxiv.org/abs/2309.03835v1"},"cats":{"new-dataset":0.231632301,"dev-research":0.2640460032,"data-quality":0.0474432195}}
{"text":"Additionally, we present the Ray-tracing Probabilistic Trajectory Learning (RPTL) framework for Diagrammatic Teaching.","meta":{"url":"http://arxiv.org/abs/2309.03835v1"},"cats":{"new-dataset":0.1997831617,"dev-research":0.2401414401,"data-quality":0.0710216753}}
{"text":"RPTL extracts time-varying probability densities from the 2D sketches, applies ray-tracing to find corresponding regions in 3D Cartesian space, and fits a probabilistic model of motion trajectories to these regions.","meta":{"url":"http://arxiv.org/abs/2309.03835v1"},"cats":{"new-dataset":0.1635862522,"dev-research":0.1890560016,"data-quality":0.0395401155}}
{"text":"New motion trajectories, which mimic those sketched by the user, can then be generated from the probabilistic model.","meta":{"url":"http://arxiv.org/abs/2309.03835v1"},"cats":{"new-dataset":0.2513813722,"dev-research":0.2241528932,"data-quality":0.0446117333}}
{"text":"We empirically validate our framework both in simulation and on real robots, which include a fixed-base manipulator and a quadruped-mounted manipulator.","meta":{"url":"http://arxiv.org/abs/2309.03835v1"},"cats":{"new-dataset":0.0478349634,"dev-research":0.156183025,"data-quality":0.0739333479}}
{"text":"Drift in machine learning refers to the phenomenon where the statistical properties of data or context, in which the model operates, change over time leading to a decrease in its performance.","meta":{"url":"http://arxiv.org/abs/2309.03831v1"},"cats":{"new-dataset":0.0397427677,"dev-research":0.3284189282,"data-quality":0.1948496541}}
{"text":"Therefore, maintaining a constant monitoring process for machine learning model performance is crucial in order to proactively prevent any potential performance regression.","meta":{"url":"http://arxiv.org/abs/2309.03831v1"},"cats":{"new-dataset":0.0125859019,"dev-research":0.3755164161,"data-quality":0.1349346321}}
{"text":"However, supervised drift detection methods require human annotation and consequently lead to a longer time to detect and mitigate the drift.","meta":{"url":"http://arxiv.org/abs/2309.03831v1"},"cats":{"new-dataset":0.0659351051,"dev-research":0.3662204471,"data-quality":0.4892974654}}
{"text":"In our proposed unsupervised drift detection method, we follow a two step process.","meta":{"url":"http://arxiv.org/abs/2309.03831v1"},"cats":{"new-dataset":0.0568228585,"dev-research":0.1748191895,"data-quality":0.2472577317}}
{"text":"Our first step involves encoding a sample of production data as the target distribution, and the model training data as the reference distribution.","meta":{"url":"http://arxiv.org/abs/2309.03831v1"},"cats":{"new-dataset":0.1863556997,"dev-research":0.1565698811,"data-quality":0.1602260497}}
{"text":"In the second step, we employ a kernel-based statistical test that utilizes the maximum mean discrepancy (MMD) distance metric to compare the reference and target distributions and estimate any potential drift.","meta":{"url":"http://arxiv.org/abs/2309.03831v1"},"cats":{"new-dataset":0.049689888,"dev-research":0.1491495922,"data-quality":0.2110125178}}
{"text":"Our method also identifies the subset of production data that is the root cause of the drift.","meta":{"url":"http://arxiv.org/abs/2309.03831v1"},"cats":{"new-dataset":0.1369503501,"dev-research":0.2915234511,"data-quality":0.2320444869}}
{"text":"The models retrained using these identified high drift samples show improved performance on online customer experience quality metrics.","meta":{"url":"http://arxiv.org/abs/2309.03831v1"},"cats":{"new-dataset":0.0508147881,"dev-research":0.2527393287,"data-quality":0.2461127512}}
{"text":"High Dynamic Range (HDR) content creation has become an important topic for modern media and entertainment sectors, gaming and Augmented/Virtual Reality industries.","meta":{"url":"http://arxiv.org/abs/2309.03827v1"},"cats":{"new-dataset":0.0917531484,"dev-research":0.1766795276,"data-quality":0.0576895078}}
{"text":"Many methods have been proposed to recreate the HDR counterparts of input Low Dynamic Range (LDR) images/videos given a single exposure or multi-exposure LDRs.","meta":{"url":"http://arxiv.org/abs/2309.03827v1"},"cats":{"new-dataset":0.1212628861,"dev-research":0.1604632538,"data-quality":0.0953617245}}
{"text":"The state-of-the-art methods focus primarily on the preservation of the reconstruction's structural similarity and the pixel-wise accuracy.","meta":{"url":"http://arxiv.org/abs/2309.03827v1"},"cats":{"new-dataset":0.032421633,"dev-research":0.1423700322,"data-quality":0.1050723476}}
{"text":"However, these conventional approaches do not emphasize preserving the artistic intent of the images in terms of human visual perception, which is an essential element in media, entertainment and gaming.","meta":{"url":"http://arxiv.org/abs/2309.03827v1"},"cats":{"new-dataset":0.0038498427,"dev-research":0.2234420452,"data-quality":0.1720854985}}
{"text":"In this paper, we attempt to study and fill this gap.","meta":{"url":"http://arxiv.org/abs/2309.03827v1"},"cats":{"new-dataset":0.1102579807,"dev-research":0.1724632773,"data-quality":0.1037044622}}
{"text":"We propose an architecture called ArtHDR-Net based on a Convolutional Neural Network that uses multi-exposed LDR features as input.","meta":{"url":"http://arxiv.org/abs/2309.03827v1"},"cats":{"new-dataset":0.1699836846,"dev-research":0.1862893799,"data-quality":0.1055895642}}
{"text":"Experimental results show that ArtHDR-Net can achieve state-of-the-art performance in terms of the HDR-VDP-2 score (i.e., mean opinion score index) while reaching competitive performance in terms of PSNR and SSIM.","meta":{"url":"http://arxiv.org/abs/2309.03827v1"},"cats":{"new-dataset":0.0415288862,"dev-research":0.2406247356,"data-quality":0.0991694516}}
{"text":"Deep neural networks employing error back-propagation for learning can suffer from exploding and vanishing gradient problems.","meta":{"url":"http://arxiv.org/abs/2309.03825v1"},"cats":{"new-dataset":0.0286391949,"dev-research":0.2123719332,"data-quality":0.3428471177}}
{"text":"Numerous solutions have been proposed such as normalisation techniques or limiting activation functions to linear rectifying units.","meta":{"url":"http://arxiv.org/abs/2309.03825v1"},"cats":{"new-dataset":0.0077473418,"dev-research":0.147873633,"data-quality":0.1255968611}}
{"text":"In this work we follow a different approach which is particularly applicable to closed-loop learning of forward models where back-propagation makes exclusive use of the sign of the error signal to prime the learning, whilst a global relevance signal modulates the rate of learning.","meta":{"url":"http://arxiv.org/abs/2309.03825v1"},"cats":{"new-dataset":0.0338672937,"dev-research":0.1182760233,"data-quality":0.2072504648}}
{"text":"This is inspired by the interaction between local plasticity and a global neuromodulation.","meta":{"url":"http://arxiv.org/abs/2309.03825v1"},"cats":{"new-dataset":0.0126727384,"dev-research":0.177423202,"data-quality":0.1228369924}}
{"text":"For example, whilst driving on an empty road, one can allow for slow step-wise optimisation of actions, whereas, at a busy junction, an error must be corrected at once.","meta":{"url":"http://arxiv.org/abs/2309.03825v1"},"cats":{"new-dataset":0.0042076413,"dev-research":0.4643138555,"data-quality":0.1336140018}}
{"text":"Hence, the error is the priming signal and the intensity of the experience is a modulating factor in the weight change.","meta":{"url":"http://arxiv.org/abs/2309.03825v1"},"cats":{"new-dataset":0.002163711,"dev-research":0.1879866546,"data-quality":0.3106562317}}
{"text":"The advantages of this Prime and Modulate paradigm is twofold: it is free from normalisation and it makes use of relevant cues from the environment to enrich the learning.","meta":{"url":"http://arxiv.org/abs/2309.03825v1"},"cats":{"new-dataset":0.012449084,"dev-research":0.1809093069,"data-quality":0.0536676918}}
{"text":"We present a mathematical derivation of the learning rule in z-space and demonstrate the real-time performance with a robotic platform.","meta":{"url":"http://arxiv.org/abs/2309.03825v1"},"cats":{"new-dataset":0.0513200592,"dev-research":0.1709647673,"data-quality":0.0736130183}}
{"text":"The results show a significant improvement in the speed of convergence compared to that of the conventional back-propagation.","meta":{"url":"http://arxiv.org/abs/2309.03825v1"},"cats":{"new-dataset":0.003314802,"dev-research":0.1249754404,"data-quality":0.0743464324}}
{"text":"Low Rank Decomposition (LRD) is a model compression technique applied to the weight tensors of deep learning models in order to reduce the number of trainable parameters and computational complexity.","meta":{"url":"http://arxiv.org/abs/2309.03824v1"},"cats":{"new-dataset":0.0428233084,"dev-research":0.1364316899,"data-quality":0.1362397768}}
{"text":"However, due to high number of new layers added to the architecture after applying LRD, it may not lead to a high training/inference acceleration if the decomposition ranks are not small enough.","meta":{"url":"http://arxiv.org/abs/2309.03824v1"},"cats":{"new-dataset":0.0063522315,"dev-research":0.1311575235,"data-quality":0.1049843676}}
{"text":"The issue is that using small ranks increases the risk of significant accuracy drop after decomposition.","meta":{"url":"http://arxiv.org/abs/2309.03824v1"},"cats":{"new-dataset":0.0030208798,"dev-research":0.1922305745,"data-quality":0.2206314122}}
{"text":"In this paper, we propose two techniques for accelerating low rank decomposed models without requiring to use small ranks for decomposition.","meta":{"url":"http://arxiv.org/abs/2309.03824v1"},"cats":{"new-dataset":0.0277150026,"dev-research":0.1326753165,"data-quality":0.1136794547}}
{"text":"These methods include rank optimization and sequential freezing of decomposed layers.","meta":{"url":"http://arxiv.org/abs/2309.03824v1"},"cats":{"new-dataset":0.0368072998,"dev-research":0.1648968433,"data-quality":0.0611892669}}
{"text":"We perform experiments on both convolutional and transformer-based models.","meta":{"url":"http://arxiv.org/abs/2309.03824v1"},"cats":{"new-dataset":0.0157015404,"dev-research":0.0918875595,"data-quality":0.0974704567}}
{"text":"Experiments show that these techniques can improve the model throughput up to 60% during training and 37% during inference when combined together while preserving the accuracy close to that of the original models","meta":{"url":"http://arxiv.org/abs/2309.03824v1"},"cats":{"new-dataset":0.0072819626,"dev-research":0.1517927035,"data-quality":0.142939157}}
{"text":"Spherical polygons used in practice are nice, but the spherical point-in-polygon problem (SPiP) has long eluded solutions based on the winding number (wn).","meta":{"url":"http://arxiv.org/abs/2309.03822v1"},"cats":{"new-dataset":0.0365271183,"dev-research":0.2185599054,"data-quality":0.0589109755}}
{"text":"That a punctured sphere is simply connected is to blame.","meta":{"url":"http://arxiv.org/abs/2309.03822v1"},"cats":{"new-dataset":0.0798194537,"dev-research":0.274161145,"data-quality":0.255106902}}
{"text":"As a workaround, we prove that requiring the boundary of a spherical polygon to never intersect its antipode is sufficient to reduce its SPiP problem to the planar, point-in-polygon (PiP) problem, whose state-of-the-art solution uses wn and does not utilize known interior points (KIP).","meta":{"url":"http://arxiv.org/abs/2309.03822v1"},"cats":{"new-dataset":0.0466090872,"dev-research":0.1903002982,"data-quality":0.1024734882}}
{"text":"We refer to such spherical polygons as boundary antipode-excluding (BAE) and show that all spherical polygons fully contained within an open hemisphere is BAE.","meta":{"url":"http://arxiv.org/abs/2309.03822v1"},"cats":{"new-dataset":0.1745747146,"dev-research":0.1921429547,"data-quality":0.1078890746}}
{"text":"We document two successful reduction methods, one based on rotation and the other on shearing, and address a common concern.","meta":{"url":"http://arxiv.org/abs/2309.03822v1"},"cats":{"new-dataset":0.0042764552,"dev-research":0.1701371073,"data-quality":0.081274369}}
{"text":"Both reduction algorithms, when combined with a wn-PiP algorithm, solve SPiP correctly and efficiently for BAE spherical polygons.","meta":{"url":"http://arxiv.org/abs/2309.03822v1"},"cats":{"new-dataset":0.0424255823,"dev-research":0.1362240601,"data-quality":0.0663759233}}
{"text":"The MATLAB code provided demonstrates scenarios that are problematic for previous work.","meta":{"url":"http://arxiv.org/abs/2309.03822v1"},"cats":{"new-dataset":0.0427006037,"dev-research":0.2847913559,"data-quality":0.2357230559}}
{"text":"Recent developments in text-conditioned image generative models have revolutionized the production of realistic results.","meta":{"url":"http://arxiv.org/abs/2309.03815v1"},"cats":{"new-dataset":0.1016822395,"dev-research":0.1412249502,"data-quality":0.2158434956}}
{"text":"Unfortunately, this has also led to an increase in privacy violations and the spread of false information, which requires the need for traceability, privacy protection, and other security measures.","meta":{"url":"http://arxiv.org/abs/2309.03815v1"},"cats":{"new-dataset":0.0321402986,"dev-research":0.2521840759,"data-quality":0.2057497051}}
{"text":"However, existing text-to-image paradigms lack the technical capabilities to link traceable messages with image generation.","meta":{"url":"http://arxiv.org/abs/2309.03815v1"},"cats":{"new-dataset":0.1794440706,"dev-research":0.2546935983,"data-quality":0.2250026221}}
{"text":"In this study, we introduce a novel task for the joint generation of text to image and watermark (T2IW).","meta":{"url":"http://arxiv.org/abs/2309.03815v1"},"cats":{"new-dataset":0.185046022,"dev-research":0.2437120152,"data-quality":0.2220845183}}
{"text":"This T2IW scheme ensures minimal damage to image quality when generating a compound image by forcing the semantic feature and the watermark signal to be compatible in pixels.","meta":{"url":"http://arxiv.org/abs/2309.03815v1"},"cats":{"new-dataset":0.0313467038,"dev-research":0.2329636754,"data-quality":0.2224225787}}
{"text":"Additionally, by utilizing principles from Shannon information theory and non-cooperative game theory, we are able to separate the revealed image and the revealed watermark from the compound image.","meta":{"url":"http://arxiv.org/abs/2309.03815v1"},"cats":{"new-dataset":0.0778965278,"dev-research":0.0979060215,"data-quality":0.1653582302}}
{"text":"Furthermore, we strengthen the watermark robustness of our approach by subjecting the compound image to various post-processing attacks, with minimal pixel distortion observed in the revealed watermark.","meta":{"url":"http://arxiv.org/abs/2309.03815v1"},"cats":{"new-dataset":0.0595689648,"dev-research":0.169239304,"data-quality":0.3472370463}}
{"text":"Extensive experiments have demonstrated remarkable achievements in image quality, watermark invisibility, and watermark robustness, supported by our proposed set of evaluation metrics.","meta":{"url":"http://arxiv.org/abs/2309.03815v1"},"cats":{"new-dataset":0.1010909606,"dev-research":0.1684166867,"data-quality":0.3458318423}}
{"text":"We present a novel human body model formulated by an extensive set of anthropocentric measurements, which is capable of generating a wide range of human body shapes and poses.","meta":{"url":"http://arxiv.org/abs/2309.03812v1"},"cats":{"new-dataset":0.4881555073,"dev-research":0.147227739,"data-quality":0.0409196379}}
{"text":"The proposed model enables direct modeling of specific human identities through a deep generative architecture, which can produce humans in any arbitrary pose.","meta":{"url":"http://arxiv.org/abs/2309.03812v1"},"cats":{"new-dataset":0.1658238536,"dev-research":0.182538183,"data-quality":0.0805099121}}
{"text":"It is the first of its kind to have been trained end-to-end using only synthetically generated data, which not only provides highly accurate human mesh representations but also allows for precise anthropometry of the body.","meta":{"url":"http://arxiv.org/abs/2309.03812v1"},"cats":{"new-dataset":0.1102021483,"dev-research":0.1947660979,"data-quality":0.0558825466}}
{"text":"Moreover, using a highly diverse animation library, we articulated our synthetic humans' body and hands to maximize the diversity of the learnable priors for model training.","meta":{"url":"http://arxiv.org/abs/2309.03812v1"},"cats":{"new-dataset":0.3798077246,"dev-research":0.1768856319,"data-quality":0.0598780083}}
{"text":"Our model was trained on a dataset of $100k$ procedurally-generated posed human meshes and their corresponding anthropometric measurements.","meta":{"url":"http://arxiv.org/abs/2309.03812v1"},"cats":{"new-dataset":0.695628743,"dev-research":0.2062298169,"data-quality":0.0498034101}}
{"text":"Our synthetic data generator can be used to generate millions of unique human identities and poses for non-commercial academic research purposes.","meta":{"url":"http://arxiv.org/abs/2309.03812v1"},"cats":{"new-dataset":0.4841926215,"dev-research":0.1832419538,"data-quality":0.1085685714}}
{"text":"Scene reconstruction in the presence of high-speed motion and low illumination is important in many applications such as augmented and virtual reality, drone navigation, and autonomous robotics.","meta":{"url":"http://arxiv.org/abs/2309.03811v1"},"cats":{"new-dataset":0.0790163663,"dev-research":0.2067324233,"data-quality":0.0650528935}}
{"text":"Traditional motion estimation techniques fail in such conditions, suffering from too much blur in the presence of high-speed motion and strong noise in low-light conditions.","meta":{"url":"http://arxiv.org/abs/2309.03811v1"},"cats":{"new-dataset":0.0376288926,"dev-research":0.1875476073,"data-quality":0.1538389046}}
{"text":"Single-photon cameras have recently emerged as a promising technology capable of capturing hundreds of thousands of photon frames per second thanks to their high speed and extreme sensitivity.","meta":{"url":"http://arxiv.org/abs/2309.03811v1"},"cats":{"new-dataset":0.4040395525,"dev-research":0.1394090977,"data-quality":0.0795798076}}
{"text":"Unfortunately, traditional computer vision techniques are not well suited for dealing with the binary-valued photon data captured by these cameras because these are corrupted by extreme Poisson noise.","meta":{"url":"http://arxiv.org/abs/2309.03811v1"},"cats":{"new-dataset":0.2799176145,"dev-research":0.128484702,"data-quality":0.2509600493}}
{"text":"Here we present a method capable of estimating extreme scene motion under challenging conditions, such as low light or high dynamic range, from a sequence of high-speed image frames such as those captured by a single-photon camera.","meta":{"url":"http://arxiv.org/abs/2309.03811v1"},"cats":{"new-dataset":0.3381160373,"dev-research":0.1491655657,"data-quality":0.0741899101}}
{"text":"Our method relies on iteratively improving a motion estimate by grouping and aggregating frames after-the-fact, in a stratified manner.","meta":{"url":"http://arxiv.org/abs/2309.03811v1"},"cats":{"new-dataset":0.1040481502,"dev-research":0.1528130784,"data-quality":0.1064923087}}
{"text":"We demonstrate the creation of high-quality panoramas under fast motion and extremely low light, and super-resolution results using a custom single-photon camera prototype.","meta":{"url":"http://arxiv.org/abs/2309.03811v1"},"cats":{"new-dataset":0.1710116491,"dev-research":0.1399993568,"data-quality":0.0401067339}}
{"text":"For code and supplemental material see our $\\href{https://wisionlab.com/project/panoramas-from-photons/}{\\text{project webpage}}$.","meta":{"url":"http://arxiv.org/abs/2309.03811v1"},"cats":{"new-dataset":0.0907962754,"dev-research":0.2307404856,"data-quality":0.0950889668}}
{"text":"Notions of graph similarity provide alternative perspective on the graph isomorphism problem and vice-versa.","meta":{"url":"http://arxiv.org/abs/2309.03810v1"},"cats":{"new-dataset":0.0129921582,"dev-research":0.2523297204,"data-quality":0.1962050507}}
{"text":"In this paper, we consider measures of similarity arising from mismatch norms as studied in Gervens and Grohe: the edit distance $\\delta_{\\mathcal{E}}$, and the metrics arising from $\\ell_p$-operator norms, which we denote by $\\delta_p$ and $\\delta_{|p|}$. We address the following question: can these measures of similarity be used to design polynomial-time approximation algorithms for graph isomorphism?","meta":{"url":"http://arxiv.org/abs/2309.03810v1"},"cats":{"new-dataset":0.0138324627,"dev-research":0.2155895898,"data-quality":0.2393784521}}
{"text":"We show that computing an optimal value of $\\delta_{\\mathcal{E}}$ is \\NP-hard on pairs of graphs with the same number of edges.","meta":{"url":"http://arxiv.org/abs/2309.03810v1"},"cats":{"new-dataset":0.0423063736,"dev-research":0.1578475869,"data-quality":0.1902778073}}
{"text":"In addition, we show that computing optimal values of $\\delta_p$ and $\\delta_{|p|}$ is \\NP-hard even on pairs of $1$-planar graphs with the same degree sequence and bounded degree.","meta":{"url":"http://arxiv.org/abs/2309.03810v1"},"cats":{"new-dataset":0.0655639344,"dev-research":0.1664695933,"data-quality":0.13266889}}
{"text":"These two results improve on previous known ones, which did not examine the restricted case where the pairs of graphs are required to have the same number of edges.   ","meta":{"url":"http://arxiv.org/abs/2309.03810v1"},"cats":{"new-dataset":0.0178253856,"dev-research":0.1557520392,"data-quality":0.2497020144}}
{"text":"Finally, we study similarity problems on strongly regular graphs and prove some near optimal inequalities with interesting consequences on the computational complexity of graph and group isomorphism.","meta":{"url":"http://arxiv.org/abs/2309.03810v1"},"cats":{"new-dataset":0.0412426189,"dev-research":0.1880810861,"data-quality":0.1348941295}}
{"text":"Existing neural field representations for 3D object reconstruction either (1) utilize object-level representations, but suffer from low-quality details due to conditioning on a global latent code, or (2) are able to perfectly reconstruct the observations, but fail to utilize object-level prior knowledge to infer unobserved regions.","meta":{"url":"http://arxiv.org/abs/2309.03809v1"},"cats":{"new-dataset":0.0870968764,"dev-research":0.167099071,"data-quality":0.1207684113}}
{"text":"We present SimNP, a method to learn category-level self-similarities, which combines the advantages of both worlds by connecting neural point radiance fields with a category-level self-similarity representation.","meta":{"url":"http://arxiv.org/abs/2309.03809v1"},"cats":{"new-dataset":0.1994791015,"dev-research":0.1397945965,"data-quality":0.1269603613}}
{"text":"Our contribution is two-fold.","meta":{"url":"http://arxiv.org/abs/2309.03809v1"},"cats":{"new-dataset":0.0835870849,"dev-research":0.1907003798,"data-quality":0.1027395241}}
{"text":"(1) We design the first neural point representation on a category level by utilizing the concept of coherent point clouds.","meta":{"url":"http://arxiv.org/abs/2309.03809v1"},"cats":{"new-dataset":0.0697774952,"dev-research":0.1369132814,"data-quality":0.1465308605}}
{"text":"The resulting neural point radiance fields store a high level of detail for locally supported object regions.","meta":{"url":"http://arxiv.org/abs/2309.03809v1"},"cats":{"new-dataset":0.165593542,"dev-research":0.1717648412,"data-quality":0.1092098248}}
{"text":"(2) We learn how information is shared between neural points in an unconstrained and unsupervised fashion, which allows to derive unobserved regions of an object during the reconstruction process from given observations.","meta":{"url":"http://arxiv.org/abs/2309.03809v1"},"cats":{"new-dataset":0.0953020579,"dev-research":0.1563023574,"data-quality":0.1479298854}}
{"text":"We show that SimNP is able to outperform previous methods in reconstructing symmetric unseen object regions, surpassing methods that build upon category-level or pixel-aligned radiance fields, while providing semantic correspondences between instances","meta":{"url":"http://arxiv.org/abs/2309.03809v1"},"cats":{"new-dataset":0.2968844958,"dev-research":0.1549721698,"data-quality":0.1707673834}}
{"text":"This paper studies enhanced dense code multiple access (DCMA) system design for downlink transmission over the Nakagami-$m$ fading channels.","meta":{"url":"http://arxiv.org/abs/2309.03806v1"},"cats":{"new-dataset":0.0175493022,"dev-research":0.1647874525,"data-quality":0.1026702639}}
{"text":"By studying the DCMA pairwise error probability (PEP) in a Nakagami-$m$ channel, a novel design metric called minimum logarithmic sum distance (MLSD) is first derived.","meta":{"url":"http://arxiv.org/abs/2309.03806v1"},"cats":{"new-dataset":0.0267813231,"dev-research":0.1636864765,"data-quality":0.1595694282}}
{"text":"With respect to the proposed MLSD, we introduce a new family of power-imbalanced dense codebooks by deleting certain rows of a special non-unimodular circulant matrix.","meta":{"url":"http://arxiv.org/abs/2309.03806v1"},"cats":{"new-dataset":0.1574373983,"dev-research":0.1902695159,"data-quality":0.1779601038}}
{"text":"Simulation results demonstrate that our proposed dense codebooks lead to both larger minimum Euclidean distance and MLSD, thus yielding significant improvements of error performance over the existing sparse code multiple access and conventional unimodular DCMA schemes in Nakagami-$m$ fading channels under different overloading factors.","meta":{"url":"http://arxiv.org/abs/2309.03806v1"},"cats":{"new-dataset":0.0231372416,"dev-research":0.1714324332,"data-quality":0.1383172994}}
{"text":"RRAM-based multi-core systems improve the energy efficiency and performance of CNNs.","meta":{"url":"http://arxiv.org/abs/2309.03805v1"},"cats":{"new-dataset":0.0354139708,"dev-research":0.1542446873,"data-quality":0.0729965609}}
{"text":"Thereby, the distributed parallel execution of convolutional layers causes critical data dependencies that limit the potential speedup.","meta":{"url":"http://arxiv.org/abs/2309.03805v1"},"cats":{"new-dataset":0.019553561,"dev-research":0.1757865764,"data-quality":0.0701467209}}
{"text":"This paper presents synchronization techniques for parallel inference of convolutional layers on RRAM-based CIM architectures.","meta":{"url":"http://arxiv.org/abs/2309.03805v1"},"cats":{"new-dataset":0.055653143,"dev-research":0.1182311976,"data-quality":0.0718358612}}
{"text":"We propose an architecture optimization that enables efficient data exchange and discuss the impact of different architecture setups on the performance.","meta":{"url":"http://arxiv.org/abs/2309.03805v1"},"cats":{"new-dataset":0.0478332776,"dev-research":0.2181517251,"data-quality":0.059139635}}
{"text":"The corresponding compiler algorithms are optimized for high speedup and low memory consumption during CNN inference.","meta":{"url":"http://arxiv.org/abs/2309.03805v1"},"cats":{"new-dataset":0.062244091,"dev-research":0.2796970824,"data-quality":0.0782944409}}
{"text":"We achieve more than 99% of the theoretical acceleration limit with a marginal data transmission overhead of less than 4% for state-of-the-art CNN benchmarks.","meta":{"url":"http://arxiv.org/abs/2309.03805v1"},"cats":{"new-dataset":0.1296999365,"dev-research":0.124377826,"data-quality":0.0852962892}}
{"text":"This work investigates the nuanced algorithm design choices for deep learning in the presence of computational-statistical gaps.","meta":{"url":"http://arxiv.org/abs/2309.03800v1"},"cats":{"new-dataset":0.0357779526,"dev-research":0.1596475284,"data-quality":0.2246929357}}
{"text":"We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron.","meta":{"url":"http://arxiv.org/abs/2309.03800v1"},"cats":{"new-dataset":0.1034858045,"dev-research":0.1006080783,"data-quality":0.2435621398}}
{"text":"This lower bound can be interpreted as a multi-resource tradeoff frontier: successful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses).","meta":{"url":"http://arxiv.org/abs/2309.03800v1"},"cats":{"new-dataset":0.0187242653,"dev-research":0.1269758451,"data-quality":0.1273204019}}
{"text":"We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting.","meta":{"url":"http://arxiv.org/abs/2309.03800v1"},"cats":{"new-dataset":0.0065056375,"dev-research":0.10680951,"data-quality":0.1655231687}}
{"text":"Here, width plays the role of parallel search: it amplifies the probability of finding \"lottery ticket\" neurons, which learn sparse features more sample-efficiently.","meta":{"url":"http://arxiv.org/abs/2309.03800v1"},"cats":{"new-dataset":0.0079324869,"dev-research":0.109577662,"data-quality":0.1122954389}}
{"text":"Finally, we show that the synthetic sparse parity task can be useful as a proxy for real problems requiring axis-aligned feature learning.","meta":{"url":"http://arxiv.org/abs/2309.03800v1"},"cats":{"new-dataset":0.1792201686,"dev-research":0.1529275358,"data-quality":0.2036313338}}
{"text":"We demonstrate improved sample efficiency on tabular classification benchmarks by using wide, sparsely-initialized MLP models; these networks sometimes outperform tuned random forests.","meta":{"url":"http://arxiv.org/abs/2309.03800v1"},"cats":{"new-dataset":0.1143340131,"dev-research":0.1493197225,"data-quality":0.1916138138}}
{"text":"In many parts of the world, the use of vast amounts of data collected on public roadways for autonomous driving has increased.","meta":{"url":"http://arxiv.org/abs/2309.03799v1"},"cats":{"new-dataset":0.4331942641,"dev-research":0.1979851721,"data-quality":0.0757684947}}
{"text":"In order to detect and anonymize pedestrian faces and nearby car license plates in actual road-driving scenarios, there is an urgent need for effective solutions.","meta":{"url":"http://arxiv.org/abs/2309.03799v1"},"cats":{"new-dataset":0.071005656,"dev-research":0.2193706016,"data-quality":0.2012850828}}
{"text":"As more data is collected, privacy concerns regarding it increase, including but not limited to pedestrian faces and surrounding vehicle license plates.","meta":{"url":"http://arxiv.org/abs/2309.03799v1"},"cats":{"new-dataset":0.0861725033,"dev-research":0.2370847099,"data-quality":0.1307065335}}
{"text":"Normal and fisheye cameras are the two common camera types that are typically mounted on collection vehicles.","meta":{"url":"http://arxiv.org/abs/2309.03799v1"},"cats":{"new-dataset":0.0975084416,"dev-research":0.1550368602,"data-quality":0.0985505298}}
{"text":"With complex camera distortion models, fisheye camera images were deformed in contrast to regular images.","meta":{"url":"http://arxiv.org/abs/2309.03799v1"},"cats":{"new-dataset":0.0843659626,"dev-research":0.1684115854,"data-quality":0.1633608466}}
{"text":"It causes computer vision tasks to perform poorly when using numerous deep learning models.","meta":{"url":"http://arxiv.org/abs/2309.03799v1"},"cats":{"new-dataset":0.0129065558,"dev-research":0.2789096085,"data-quality":0.1813701672}}
{"text":"In this work, we pay particular attention to protecting privacy while yet adhering to several laws for fisheye camera photos taken by driverless vehicles.","meta":{"url":"http://arxiv.org/abs/2309.03799v1"},"cats":{"new-dataset":0.0913187581,"dev-research":0.2016208836,"data-quality":0.1501719562}}
{"text":"First, we suggest a framework for extracting face and plate identification knowledge from several teacher models.","meta":{"url":"http://arxiv.org/abs/2309.03799v1"},"cats":{"new-dataset":0.1266284073,"dev-research":0.1525432418,"data-quality":0.1283808733}}
{"text":"Our second suggestion is to transform both the image and the label from a regular image to fisheye-like data using a varied and realistic fisheye transformation.","meta":{"url":"http://arxiv.org/abs/2309.03799v1"},"cats":{"new-dataset":0.2765717936,"dev-research":0.1182899375,"data-quality":0.3707542065}}
{"text":"Finally, we run a test using the open-source PP4AV dataset.","meta":{"url":"http://arxiv.org/abs/2309.03799v1"},"cats":{"new-dataset":0.6730202353,"dev-research":0.1059868807,"data-quality":0.1937637371}}
{"text":"The experimental findings demonstrated that our model outperformed baseline methods when trained on data from autonomous vehicles, even when the data were softly labeled.","meta":{"url":"http://arxiv.org/abs/2309.03799v1"},"cats":{"new-dataset":0.0448644225,"dev-research":0.2516208836,"data-quality":0.3833827812}}
{"text":"The implementation code is available at our github: https://github.com/khaclinh/FisheyePP4AV.","meta":{"url":"http://arxiv.org/abs/2309.03799v1"},"cats":{"new-dataset":0.1961760312,"dev-research":0.1871330035,"data-quality":0.0893094025}}
{"text":"We introduce two new extensions to the beam search algorithm based on conformal predictions (CP) to produce sets of sequences with theoretical coverage guarantees.","meta":{"url":"http://arxiv.org/abs/2309.03797v1"},"cats":{"new-dataset":0.0369245854,"dev-research":0.0982713779,"data-quality":0.0862283782}}
{"text":"The first method is very simple and proposes dynamically-sized subsets of beam search results but, unlike typical CP procedures, has an upper bound on the achievable guarantee depending on a post-hoc calibration measure.","meta":{"url":"http://arxiv.org/abs/2309.03797v1"},"cats":{"new-dataset":0.0173025016,"dev-research":0.116280485,"data-quality":0.1138204605}}
{"text":"Our second algorithm introduces the conformal set prediction procedure as part of the decoding process, producing a variable beam width which adapts to the current uncertainty.","meta":{"url":"http://arxiv.org/abs/2309.03797v1"},"cats":{"new-dataset":0.0502864703,"dev-research":0.1290848464,"data-quality":0.1411751521}}
{"text":"While more complex, this procedure can achieve coverage guarantees selected a priori.","meta":{"url":"http://arxiv.org/abs/2309.03797v1"},"cats":{"new-dataset":0.0126443363,"dev-research":0.2699569173,"data-quality":0.0864961495}}
{"text":"We provide marginal coverage bounds for each method, and evaluate them empirically on a selection of tasks drawing from natural language processing and chemistry.","meta":{"url":"http://arxiv.org/abs/2309.03797v1"},"cats":{"new-dataset":0.0607589831,"dev-research":0.2462676419,"data-quality":0.2148919181}}
{"text":"The aim of this paper to provide the solution microservices architecture as a popular alternative to monolithic architecture.","meta":{"url":"http://arxiv.org/abs/2309.03796v1"},"cats":{"new-dataset":0.0374743967,"dev-research":0.1868117083,"data-quality":0.0911486866}}
{"text":"It discusses the advantages of microservices and the challenges that organizations face when transitioning from a monolithic system.","meta":{"url":"http://arxiv.org/abs/2309.03796v1"},"cats":{"new-dataset":0.0179636899,"dev-research":0.2095272307,"data-quality":0.0716298674}}
{"text":"It presents a case study of a financial application and proposed techniques for identifying microservices on monolithic systems using domain-driven development concepts.","meta":{"url":"http://arxiv.org/abs/2309.03796v1"},"cats":{"new-dataset":0.0750411555,"dev-research":0.2794649206,"data-quality":0.1712369446}}
{"text":"In recent years, microservices architecture has emerged as a new architectural style in the software development industry.","meta":{"url":"http://arxiv.org/abs/2309.03796v1"},"cats":{"new-dataset":0.037932747,"dev-research":0.2298051757,"data-quality":0.0690486358}}
{"text":"As legacy monolithic software becomes too large to manage, many large corporations are considering converting their traditional monolithic systems into small-scale, self-contained microservices.","meta":{"url":"http://arxiv.org/abs/2309.03796v1"},"cats":{"new-dataset":0.0257781316,"dev-research":0.1900395742,"data-quality":0.0932455933}}
{"text":"However, migrating from monolithic to microservices architecture is a difficult and challenging task.","meta":{"url":"http://arxiv.org/abs/2309.03796v1"},"cats":{"new-dataset":0.020807803,"dev-research":0.1789132287,"data-quality":0.0954578768}}
{"text":"It presents a comparison of the two architectural styles and discusses the difficulties that led companies to switch to microservices.","meta":{"url":"http://arxiv.org/abs/2309.03796v1"},"cats":{"new-dataset":0.0064132241,"dev-research":0.1869621256,"data-quality":0.0627232271}}
{"text":"The study's findings suggest that the proposed technique can improve work performance and establish clear models, but it may not be useful for systems with lower levels of complexity.","meta":{"url":"http://arxiv.org/abs/2309.03796v1"},"cats":{"new-dataset":0.0011959826,"dev-research":0.3894083245,"data-quality":0.0767372782}}
{"text":"This research paper has practical implications for software architects and developers who are considering migrating from monolithic to microservices architecture.","meta":{"url":"http://arxiv.org/abs/2309.03796v1"},"cats":{"new-dataset":0.0173752119,"dev-research":0.2526743967,"data-quality":0.0885763362}}
{"text":"We introduce the $ARMOR_D$ methods as novel approaches to enhancing the adversarial robustness of deep learning models.","meta":{"url":"http://arxiv.org/abs/2309.03791v1"},"cats":{"new-dataset":0.0362646244,"dev-research":0.1987262496,"data-quality":0.3130306005}}
{"text":"These methods are based on a new class of optimal-transport-regularized divergences, constructed via an infimal convolution between an information divergence and an optimal-transport (OT) cost.","meta":{"url":"http://arxiv.org/abs/2309.03791v1"},"cats":{"new-dataset":0.0123243186,"dev-research":0.116633569,"data-quality":0.1367384152}}
{"text":"We use these as tools to enhance adversarial robustness by maximizing the expected loss over a neighborhood of distributions, a technique known as distributionally robust optimization.","meta":{"url":"http://arxiv.org/abs/2309.03791v1"},"cats":{"new-dataset":0.0406762448,"dev-research":0.1854499845,"data-quality":0.3073454741}}
{"text":"Viewed as a tool for constructing adversarial samples, our method allows samples to be both transported, according to the OT cost, and re-weighted, according to the information divergence.","meta":{"url":"http://arxiv.org/abs/2309.03791v1"},"cats":{"new-dataset":0.0356134866,"dev-research":0.14338975,"data-quality":0.2639714864}}
{"text":"We demonstrate the effectiveness of our method on malware detection and image recognition applications and find that, to our knowledge, it outperforms existing methods at enhancing the robustness against adversarial attacks.","meta":{"url":"http://arxiv.org/abs/2309.03791v1"},"cats":{"new-dataset":0.0198593935,"dev-research":0.1759278791,"data-quality":0.3102865826}}
{"text":"$ARMOR_D$ yields the robustified accuracy of $98.29\\%$ against $FGSM$ and $98.18\\%$ against $PGD^{40}$ on the MNIST dataset, reducing the error rate by more than $19.7\\%$ and $37.2\\%$ respectively compared to prior methods.","meta":{"url":"http://arxiv.org/abs/2309.03791v1"},"cats":{"new-dataset":0.028407439,"dev-research":0.1606320557,"data-quality":0.2872318133}}
{"text":"Similarly, in malware detection, a discrete (binary) data domain, $ARMOR_D$ improves the robustified accuracy under $rFGSM^{50}$ attack compared to the previous best-performing adversarial training methods by $37.0\\%$ while lowering false negative and false positive rates by $51.1\\%$ and $57.53\\%$, respectively.","meta":{"url":"http://arxiv.org/abs/2309.03791v1"},"cats":{"new-dataset":0.0141387588,"dev-research":0.1680422553,"data-quality":0.2680206528}}
{"text":"Story ideation is a critical part of the story-writing process.","meta":{"url":"http://arxiv.org/abs/2309.03790v1"},"cats":{"new-dataset":0.0369249906,"dev-research":0.3867247997,"data-quality":0.1299139257}}
{"text":"It is challenging to support computationally due to its exploratory and subjective nature.","meta":{"url":"http://arxiv.org/abs/2309.03790v1"},"cats":{"new-dataset":0.0371745476,"dev-research":0.2882270637,"data-quality":0.1341096383}}
{"text":"Tropes, which are recurring narrative elements across stories, are essential in stories as they shape the structure of narratives and our understanding of them.","meta":{"url":"http://arxiv.org/abs/2309.03790v1"},"cats":{"new-dataset":0.0406715129,"dev-research":0.2969116573,"data-quality":0.1329336858}}
{"text":"In this paper, we propose to use tropes as an intermediate representation of stories to approach story ideation.","meta":{"url":"http://arxiv.org/abs/2309.03790v1"},"cats":{"new-dataset":0.0698687829,"dev-research":0.3066275251,"data-quality":0.1222139325}}
{"text":"We present TaleStream, a canvas system that uses tropes as building blocks of stories while providing steerable suggestions of story ideas in the form of tropes.","meta":{"url":"http://arxiv.org/abs/2309.03790v1"},"cats":{"new-dataset":0.1920117422,"dev-research":0.3638438009,"data-quality":0.0879703833}}
{"text":"Our trope suggestion methods leverage data from the tvtropes.org wiki.","meta":{"url":"http://arxiv.org/abs/2309.03790v1"},"cats":{"new-dataset":0.0969876697,"dev-research":0.2698424122,"data-quality":0.1793933809}}
{"text":"We find that 97% of the time, trope suggestions generated by our methods provide better story ideation materials than random tropes.","meta":{"url":"http://arxiv.org/abs/2309.03790v1"},"cats":{"new-dataset":0.029682248,"dev-research":0.3200603131,"data-quality":0.1450743227}}
{"text":"Our system evaluation suggests that TaleStream can support writers' creative flow and greatly facilitates story development.","meta":{"url":"http://arxiv.org/abs/2309.03790v1"},"cats":{"new-dataset":0.0596909208,"dev-research":0.4454685236,"data-quality":0.1083427804}}
{"text":"Tropes, as a rich lexicon of narratives with available examples, play a key role in TaleStream and hold promise for story-creation support systems.","meta":{"url":"http://arxiv.org/abs/2309.03790v1"},"cats":{"new-dataset":0.0990202758,"dev-research":0.3324658477,"data-quality":0.1275024423}}
{"text":"Sentiment analysis is a pivotal task in the domain of natural language processing.","meta":{"url":"http://arxiv.org/abs/2309.03787v1"},"cats":{"new-dataset":0.0210134836,"dev-research":0.266343149,"data-quality":0.2322366028}}
{"text":"It encompasses both text-level sentiment polarity classification and word-level Part of Speech(POS) sentiment polarity determination.","meta":{"url":"http://arxiv.org/abs/2309.03787v1"},"cats":{"new-dataset":0.0612330478,"dev-research":0.2004943233,"data-quality":0.2868817309}}
{"text":"Such analysis challenges models to understand text holistically while also extracting nuanced information.","meta":{"url":"http://arxiv.org/abs/2309.03787v1"},"cats":{"new-dataset":0.030979313,"dev-research":0.247531611,"data-quality":0.287992867}}
{"text":"With the rise of Large Language Models(LLMs), new avenues for sentiment analysis have opened.","meta":{"url":"http://arxiv.org/abs/2309.03787v1"},"cats":{"new-dataset":0.124081977,"dev-research":0.1617300674,"data-quality":0.1757909689}}
{"text":"This paper proposes enhancing performance by leveraging the Mutual Reinforcement Effect(MRE) between individual words and the overall text.","meta":{"url":"http://arxiv.org/abs/2309.03787v1"},"cats":{"new-dataset":0.0077564002,"dev-research":0.1730688486,"data-quality":0.176596348}}
{"text":"It delves into how word polarity influences the overarching sentiment of a passage.","meta":{"url":"http://arxiv.org/abs/2309.03787v1"},"cats":{"new-dataset":0.0118967178,"dev-research":0.2320032832,"data-quality":0.2481335737}}
{"text":"To support our research, we annotated four novel Sentiment Text Classification and Part of Speech(SCPOS) datasets, building upon existing sentiment classification datasets.","meta":{"url":"http://arxiv.org/abs/2309.03787v1"},"cats":{"new-dataset":0.6375924453,"dev-research":0.1887211387,"data-quality":0.3985187337}}
{"text":"Furthermore, we developed a Universal Sentiment Analysis(USA) model, with a 7-billion parameter size.","meta":{"url":"http://arxiv.org/abs/2309.03787v1"},"cats":{"new-dataset":0.1850372537,"dev-research":0.1632632312,"data-quality":0.1360487453}}
{"text":"Experimental results revealed that our model surpassed the performance of gpt-3.5-turbo across all four datasets, underscoring the significance of MRE in sentiment analysis.","meta":{"url":"http://arxiv.org/abs/2309.03787v1"},"cats":{"new-dataset":0.0404583331,"dev-research":0.1816082808,"data-quality":0.1608427788}}
{"text":"Small devices are frequently used in IoT and smart-city applications to perform periodic dedicated tasks with soft deadlines.","meta":{"url":"http://arxiv.org/abs/2309.03779v1"},"cats":{"new-dataset":0.0170047964,"dev-research":0.2728780149,"data-quality":0.0648062325}}
{"text":"This work focuses on developing methods to derive efficient power-management methods for periodic tasks on small devices.","meta":{"url":"http://arxiv.org/abs/2309.03779v1"},"cats":{"new-dataset":0.0109121208,"dev-research":0.2690607136,"data-quality":0.0645487499}}
{"text":"We first study the limitations of the existing Linux built-in methods used in small devices.","meta":{"url":"http://arxiv.org/abs/2309.03779v1"},"cats":{"new-dataset":0.0327084161,"dev-research":0.2487701376,"data-quality":0.0636378834}}
{"text":"We illustrate three typical workload/system patterns that are challenging to manage with Linux's built-in solutions.","meta":{"url":"http://arxiv.org/abs/2309.03779v1"},"cats":{"new-dataset":0.1150056824,"dev-research":0.3877803448,"data-quality":0.0531726902}}
{"text":"We develop a reinforcement-learning-based technique with temporal encoding to derive an effective DVFS governor even with the presence of the three system patterns.","meta":{"url":"http://arxiv.org/abs/2309.03779v1"},"cats":{"new-dataset":0.0281505763,"dev-research":0.1782908398,"data-quality":0.090174896}}
{"text":"The derived governor uses only one performance counter, the same as the built-in Linux mechanism, and does not require an explicit task model for the workload.","meta":{"url":"http://arxiv.org/abs/2309.03779v1"},"cats":{"new-dataset":0.0186566064,"dev-research":0.1845957994,"data-quality":0.0682729514}}
{"text":"We implemented a prototype system on the Nvidia Jetson Nano Board and experimented with it with six applications, including two self-designed and four benchmark applications.","meta":{"url":"http://arxiv.org/abs/2309.03779v1"},"cats":{"new-dataset":0.0676236521,"dev-research":0.1734039556,"data-quality":0.0591811314}}
{"text":"Under different deadline constraints, our approach can quickly derive a DVFS governor that can adapt to performance requirements and outperform the built-in Linux approach in energy saving.","meta":{"url":"http://arxiv.org/abs/2309.03779v1"},"cats":{"new-dataset":0.0687976351,"dev-research":0.2799635847,"data-quality":0.0721674754}}
{"text":"On Mibench workloads, with performance slack ranging from 0.04 s to 0.4 s, the proposed method can save 3% - 11% more energy compared to Ondemand.","meta":{"url":"http://arxiv.org/abs/2309.03779v1"},"cats":{"new-dataset":0.0161916425,"dev-research":0.2158466175,"data-quality":0.0762007373}}
{"text":"AudioReg and FaceReg applications tested have 5%- 14% energy-saving improvement.","meta":{"url":"http://arxiv.org/abs/2309.03779v1"},"cats":{"new-dataset":0.0611524965,"dev-research":0.285123477,"data-quality":0.1450444382}}
{"text":"We have open-sourced the implementation of our in-kernel quantized neural network engine.","meta":{"url":"http://arxiv.org/abs/2309.03779v1"},"cats":{"new-dataset":0.2125705736,"dev-research":0.1570414646,"data-quality":0.1066266929}}
{"text":"The codebase can be found at: https://github.com/coladog/tinyagent.","meta":{"url":"http://arxiv.org/abs/2309.03779v1"},"cats":{"new-dataset":0.461121664,"dev-research":0.1716336574,"data-quality":0.138421433}}
{"text":"Recent advances in the field of deep learning and impressive performance of deep neural networks (DNNs) for perception have resulted in an increased demand for their use in automated driving (AD) systems.","meta":{"url":"http://arxiv.org/abs/2309.03774v1"},"cats":{"new-dataset":0.1070738177,"dev-research":0.2468593302,"data-quality":0.15675573}}
{"text":"The safety of such systems is of utmost importance and thus requires to consider the unique properties of DNNs.   ","meta":{"url":"http://arxiv.org/abs/2309.03774v1"},"cats":{"new-dataset":0.0635406393,"dev-research":0.2173799761,"data-quality":0.1254741008}}
{"text":"In order to achieve safety of AD systems with DNN-based perception components in a systematic and comprehensive approach, so-called safety concerns have been introduced as a suitable structuring element.","meta":{"url":"http://arxiv.org/abs/2309.03774v1"},"cats":{"new-dataset":0.1021897906,"dev-research":0.3822998899,"data-quality":0.3025873563}}
{"text":"On the one hand, the concept of safety concerns is -- by design -- well aligned to existing standards relevant for safety of AD systems such as ISO 21448 (SOTIF).","meta":{"url":"http://arxiv.org/abs/2309.03774v1"},"cats":{"new-dataset":0.1299745637,"dev-research":0.3403520681,"data-quality":0.1982792866}}
{"text":"On the other hand, it has already inspired several academic publications and upcoming standards on AI safety such as ISO PAS 8800.   ","meta":{"url":"http://arxiv.org/abs/2309.03774v1"},"cats":{"new-dataset":0.0344409343,"dev-research":0.2762449904,"data-quality":0.1123417824}}
{"text":"While the concept of safety concerns has been previously introduced, this paper extends and refines it, leveraging feedback from various domain and safety experts in the field.","meta":{"url":"http://arxiv.org/abs/2309.03774v1"},"cats":{"new-dataset":0.1480684059,"dev-research":0.5743981147,"data-quality":0.2478711063}}
{"text":"In particular, this paper introduces an additional categorization for a better understanding as well as enabling cross-functional teams to jointly address the concerns.","meta":{"url":"http://arxiv.org/abs/2309.03774v1"},"cats":{"new-dataset":0.0388763673,"dev-research":0.4373041893,"data-quality":0.0746368825}}
{"text":"Many downstream inference tasks for knowledge graphs, such as relation prediction, have been handled successfully by knowledge graph embedding techniques in the transductive setting.","meta":{"url":"http://arxiv.org/abs/2309.03773v1"},"cats":{"new-dataset":0.0803181009,"dev-research":0.2022752017,"data-quality":0.1397195553}}
{"text":"To address the inductive setting wherein new entities are introduced into the knowledge graph at inference time, more recent work opts for models which learn implicit representations of the knowledge graph through a complex function of a network's subgraph structure, often parametrized by graph neural network architectures.","meta":{"url":"http://arxiv.org/abs/2309.03773v1"},"cats":{"new-dataset":0.064678648,"dev-research":0.2663049414,"data-quality":0.1690637389}}
{"text":"These come at the cost of increased parametrization, reduced interpretability and limited generalization to other downstream inference tasks.","meta":{"url":"http://arxiv.org/abs/2309.03773v1"},"cats":{"new-dataset":0.0054952888,"dev-research":0.1727155631,"data-quality":0.089152907}}
{"text":"In this work, we bridge the gap between traditional transductive knowledge graph embedding approaches and more recent inductive relation prediction models by introducing a generalized form of harmonic extension which leverages representations learned through transductive embedding methods to infer representations of new entities introduced at inference time as in the inductive setting.","meta":{"url":"http://arxiv.org/abs/2309.03773v1"},"cats":{"new-dataset":0.0796680212,"dev-research":0.1735921745,"data-quality":0.179535824}}
{"text":"This harmonic extension technique provides the best such approximation, can be implemented via an efficient iterative scheme, and can be employed to answer a family of conjunctive logical queries over the knowledge graph, further expanding the capabilities of transductive embedding methods.","meta":{"url":"http://arxiv.org/abs/2309.03773v1"},"cats":{"new-dataset":0.0488205128,"dev-research":0.170275229,"data-quality":0.1309580663}}
{"text":"In experiments on a number of large-scale knowledge graph embedding benchmarks, we find that this approach for extending the functionality of transductive knowledge graph embedding models to perform knowledge graph completion and answer logical queries in the inductive setting is competitive with--and in some scenarios outperforms--several state-of-the-art models derived explicitly for such inductive tasks.","meta":{"url":"http://arxiv.org/abs/2309.03773v1"},"cats":{"new-dataset":0.1177439615,"dev-research":0.2184920125,"data-quality":0.1265679283}}
{"text":"Space-time shift keying-aided orthogonal time frequency space modulation-based multiple access (STSK-OTFS-MA) is proposed for reliable uplink transmission in high-Doppler scenarios.","meta":{"url":"http://arxiv.org/abs/2309.03771v1"},"cats":{"new-dataset":0.0358331696,"dev-research":0.1792582059,"data-quality":0.0840258088}}
{"text":"As a beneficial feature of our STSK-OTFS-MA system, extra information bits are mapped onto the indices of the active dispersion matrices, which allows the system to enjoy the joint benefits of both STSK and OTFS signalling.","meta":{"url":"http://arxiv.org/abs/2309.03771v1"},"cats":{"new-dataset":0.0381229332,"dev-research":0.1209837243,"data-quality":0.0942159554}}
{"text":"Due to the fact that both the time-, space- and DD-domain degrees of freedom are jointly exploited, our STSK-OTFS-MA achieves increased diversity and coding gains.","meta":{"url":"http://arxiv.org/abs/2309.03771v1"},"cats":{"new-dataset":0.0585573949,"dev-research":0.1205454637,"data-quality":0.1022143112}}
{"text":"To mitigate the potentially excessive detection complexity, the sparse structure of the equivalent transmitted symbol vector is exploited, resulting in a pair of low-complexity near-maximum likelihood (ML) multiuser detection algorithms.","meta":{"url":"http://arxiv.org/abs/2309.03771v1"},"cats":{"new-dataset":0.0163073006,"dev-research":0.1416692863,"data-quality":0.118045135}}
{"text":"Explicitly, we conceive a progressive residual check-based greedy detector (PRCGD) and an iterative reduced-space check-based detector (IRCD).","meta":{"url":"http://arxiv.org/abs/2309.03771v1"},"cats":{"new-dataset":0.1470448318,"dev-research":0.1231038076,"data-quality":0.2041117049}}
{"text":"Then, we derive both the unconditional single-user pairwise error probability (SU-UPEP) and a tight bit error ratio (BER) union-bound for our single-user STSK-OTFS-MA system employing the ML detector.","meta":{"url":"http://arxiv.org/abs/2309.03771v1"},"cats":{"new-dataset":0.0345937424,"dev-research":0.104939758,"data-quality":0.2447750032}}
{"text":"Furthermore, the discrete-input continuous-output memoryless channel (DCMC) capacity of the proposed system is derived.","meta":{"url":"http://arxiv.org/abs/2309.03771v1"},"cats":{"new-dataset":0.0173262158,"dev-research":0.1195087514,"data-quality":0.0833809819}}
{"text":"The optimal dispersion matrices (DMs) are designed based on the maximum attainable diversity and coding gain metrics.","meta":{"url":"http://arxiv.org/abs/2309.03771v1"},"cats":{"new-dataset":0.0124713446,"dev-research":0.0835452124,"data-quality":0.0905430775}}
{"text":"Finally, it is demonstrated that our STSK-OTFS-MA system achieves both a lower BER and a higher DCMC capacity than its conventional spatial modulation (SM) {and its orthogonal frequency-division multiplexing (OFDM) counterparts.","meta":{"url":"http://arxiv.org/abs/2309.03771v1"},"cats":{"new-dataset":0.0232287215,"dev-research":0.1256510928,"data-quality":0.0902931375}}
{"text":"As a benefit, the proposed system strikes a compelling BER vs. system complexity as well as BER vs. detection complexity trade-offs.","meta":{"url":"http://arxiv.org/abs/2309.03771v1"},"cats":{"new-dataset":0.0069952359,"dev-research":0.2569003647,"data-quality":0.0983389463}}
{"text":"This paper investigates the problem of inertial navigation system (INS) filter design through the lens of symmetry.","meta":{"url":"http://arxiv.org/abs/2309.03765v1"},"cats":{"new-dataset":0.0263425788,"dev-research":0.1535416903,"data-quality":0.0692999252}}
{"text":"The extended Kalman filter (EKF) and its variants, have been the staple of INS filtering for 50 years; however, recent advances in inertial navigation systems have exploited matrix Lie group structure to design stochastic filters and state observers that have been shown to display superior performance compared to classical solutions.","meta":{"url":"http://arxiv.org/abs/2309.03765v1"},"cats":{"new-dataset":0.0421727197,"dev-research":0.1521880379,"data-quality":0.0478453231}}
{"text":"In this work we consider the case where a vehicle has an inertial measurement unit (IMU) and a global navigation satellite system (GNSS) receiver.","meta":{"url":"http://arxiv.org/abs/2309.03765v1"},"cats":{"new-dataset":0.064675249,"dev-research":0.1355925988,"data-quality":0.0777426308}}
{"text":"We show that all the modern variants of the EKF for these sensors can be interpreted as the recently proposed Equivariant Filter (EqF) design methodology applied to different choices of symmetry group for the INS problem.","meta":{"url":"http://arxiv.org/abs/2309.03765v1"},"cats":{"new-dataset":0.0820196114,"dev-research":0.1027391187,"data-quality":0.0735428442}}
{"text":"This leads us to propose two new symmetries for the INS problem that have not been considered in the prior literature, and provide a discussion of the relative strengths and weaknesses of all the different algorithms.","meta":{"url":"http://arxiv.org/abs/2309.03765v1"},"cats":{"new-dataset":0.0375661653,"dev-research":0.1148620852,"data-quality":0.1080440018}}
{"text":"We believe the collection of symmetries that we present here capture all the sensible choices of symmetry for this problem and sensor suite, and that the analysis provided is indicative of the relative real-world performance potential of the different algorithms.","meta":{"url":"http://arxiv.org/abs/2309.03765v1"},"cats":{"new-dataset":0.046119968,"dev-research":0.0970299907,"data-quality":0.0767581427}}
{"text":"Color image completion is a challenging problem in computer vision, but recent research has shown that quaternion representations of color images perform well in many areas.","meta":{"url":"http://arxiv.org/abs/2309.03764v1"},"cats":{"new-dataset":0.051438012,"dev-research":0.1977951325,"data-quality":0.1176529239}}
{"text":"These representations consider the entire color image and effectively utilize coupling information between the three color channels.","meta":{"url":"http://arxiv.org/abs/2309.03764v1"},"cats":{"new-dataset":0.0800096155,"dev-research":0.1401855645,"data-quality":0.0863681141}}
{"text":"Consequently, low-rank quaternion matrix completion (LRQMC) algorithms have gained significant attention.","meta":{"url":"http://arxiv.org/abs/2309.03764v1"},"cats":{"new-dataset":0.0203915571,"dev-research":0.148219575,"data-quality":0.0639591827}}
{"text":"We propose a method based on quaternion Qatar Riyal decomposition (QQR) and quaternion $L_{2,1}$-norm called QLNM-QQR.","meta":{"url":"http://arxiv.org/abs/2309.03764v1"},"cats":{"new-dataset":0.047090381,"dev-research":0.128409865,"data-quality":0.063338605}}
{"text":"This new approach reduces computational complexity by avoiding the need to calculate the QSVD of large quaternion matrices.","meta":{"url":"http://arxiv.org/abs/2309.03764v1"},"cats":{"new-dataset":0.0415831784,"dev-research":0.1543330852,"data-quality":0.0403174342}}
{"text":"We also present two improvements to the QLNM-QQR method: an enhanced version called IRQLNM-QQR that uses iteratively reweighted quaternion $L_{2,1}$-norm minimization and a method called QLNM-QQR-SR that integrates sparse regularization.","meta":{"url":"http://arxiv.org/abs/2309.03764v1"},"cats":{"new-dataset":0.0338876141,"dev-research":0.1344612564,"data-quality":0.0853607314}}
{"text":"Our experiments on natural color images and color medical images show that IRQLNM-QQR outperforms QLNM-QQR and that the proposed QLNM-QQR-SR method is superior to several state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2309.03764v1"},"cats":{"new-dataset":0.0887330885,"dev-research":0.1233416878,"data-quality":0.1072788446}}
{"text":"Recognising reinforced concrete defects (RCDs) is a crucial element for determining the structural integrity, traffic safety and durability of bridges.","meta":{"url":"http://arxiv.org/abs/2309.03763v1"},"cats":{"new-dataset":0.1192321442,"dev-research":0.2637200095,"data-quality":0.2413949883}}
{"text":"However, most of the existing datasets in the RCD domain are derived from a small number of bridges acquired in specific camera poses, lighting conditions and with fixed hardware.","meta":{"url":"http://arxiv.org/abs/2309.03763v1"},"cats":{"new-dataset":0.6289281705,"dev-research":0.1542242757,"data-quality":0.108818779}}
{"text":"These limitations question the usability of models trained on such open-source data in real-world scenarios.","meta":{"url":"http://arxiv.org/abs/2309.03763v1"},"cats":{"new-dataset":0.1043479052,"dev-research":0.2060366705,"data-quality":0.0898700358}}
{"text":"We address this problem by testing such models on our \"dacl1k\" dataset, a highly diverse RCD dataset for multi-label classification based on building inspections including 1,474 images.","meta":{"url":"http://arxiv.org/abs/2309.03763v1"},"cats":{"new-dataset":0.8203665095,"dev-research":0.1838085212,"data-quality":0.5501142528}}
{"text":"Thereby, we trained the models on different combinations of open-source data (meta datasets) which were subsequently evaluated both extrinsically and intrinsically.","meta":{"url":"http://arxiv.org/abs/2309.03763v1"},"cats":{"new-dataset":0.0971686455,"dev-research":0.1553456762,"data-quality":0.1581802375}}
{"text":"During extrinsic evaluation, we report metrics on dacl1k and the meta datasets.","meta":{"url":"http://arxiv.org/abs/2309.03763v1"},"cats":{"new-dataset":0.4821077559,"dev-research":0.20675027,"data-quality":0.2281625041}}
{"text":"The performance analysis on dacl1k shows practical usability of the meta data, where the best model shows an Exact Match Ratio of 32%.","meta":{"url":"http://arxiv.org/abs/2309.03763v1"},"cats":{"new-dataset":0.1094955032,"dev-research":0.2959848063,"data-quality":0.1295366402}}
{"text":"Additionally, we conduct an intrinsic evaluation by clustering the bottleneck features of the best model derived from the extrinsic evaluation in order to find out, if the model has learned distinguishing datasets or the classes (RCDs) which is the aspired goal.","meta":{"url":"http://arxiv.org/abs/2309.03763v1"},"cats":{"new-dataset":0.0305000325,"dev-research":0.1884130966,"data-quality":0.1972651167}}
{"text":"The dacl1k dataset and our trained models will be made publicly available, enabling researchers and practitioners to put their models to the real-world test.","meta":{"url":"http://arxiv.org/abs/2309.03763v1"},"cats":{"new-dataset":0.6446392337,"dev-research":0.1944514957,"data-quality":0.1360241001}}
{"text":"Motion planning is the soul of robot decision making.","meta":{"url":"http://arxiv.org/abs/2309.03758v1"},"cats":{"new-dataset":0.034254254,"dev-research":0.3077617062,"data-quality":0.0381360473}}
{"text":"Classical planning algorithms like graph search and reaction-based algorithms face challenges in cases of dense and dynamic obstacles.","meta":{"url":"http://arxiv.org/abs/2309.03758v1"},"cats":{"new-dataset":0.062466122,"dev-research":0.2231432437,"data-quality":0.0426619262}}
{"text":"Deep learning algorithms generate suboptimal one-step predictions that cause many collisions.","meta":{"url":"http://arxiv.org/abs/2309.03758v1"},"cats":{"new-dataset":0.0771231761,"dev-research":0.1893286286,"data-quality":0.1308557814}}
{"text":"Reinforcement learning algorithms generate optimal or near-optimal time-sequential predictions.","meta":{"url":"http://arxiv.org/abs/2309.03758v1"},"cats":{"new-dataset":0.0235356174,"dev-research":0.1548284065,"data-quality":0.0607597496}}
{"text":"However, they suffer from slow convergence, suboptimal converged results, and overfittings.","meta":{"url":"http://arxiv.org/abs/2309.03758v1"},"cats":{"new-dataset":0.0130071765,"dev-research":0.1490818555,"data-quality":0.1769413993}}
{"text":"This paper introduces a hybrid algorithm for robotic motion planning: long short-term memory (LSTM) pooling and skip connection for attention-based discrete soft actor critic (LSA-DSAC).","meta":{"url":"http://arxiv.org/abs/2309.03758v1"},"cats":{"new-dataset":0.1288545559,"dev-research":0.1510710803,"data-quality":0.0529987814}}
{"text":"First, graph network (relational graph) and attention network (attention weight) interpret the environmental state for the learning of the discrete soft actor critic algorithm.","meta":{"url":"http://arxiv.org/abs/2309.03758v1"},"cats":{"new-dataset":0.0317404373,"dev-research":0.1735061251,"data-quality":0.1035795918}}
{"text":"The expressive power of attention network outperforms that of graph in our task by difference analysis of these two representation methods.","meta":{"url":"http://arxiv.org/abs/2309.03758v1"},"cats":{"new-dataset":0.061752199,"dev-research":0.2325800427,"data-quality":0.157189087}}
{"text":"However, attention based DSAC faces the overfitting problem in training.","meta":{"url":"http://arxiv.org/abs/2309.03758v1"},"cats":{"new-dataset":0.0286129418,"dev-research":0.2261344027,"data-quality":0.240134158}}
{"text":"Second, the skip connection method is integrated to attention based DSAC to mitigate overfitting and improve convergence speed.","meta":{"url":"http://arxiv.org/abs/2309.03758v1"},"cats":{"new-dataset":0.0083409725,"dev-research":0.2283380677,"data-quality":0.163121704}}
{"text":"Third, LSTM pooling is taken to replace the sum operator of attention weigh and eliminate overfitting by slightly sacrificing convergence speed at early-stage training.","meta":{"url":"http://arxiv.org/abs/2309.03758v1"},"cats":{"new-dataset":0.0389181178,"dev-research":0.1381730633,"data-quality":0.1449141593}}
{"text":"Experiments show that LSA-DSAC outperforms the state-of-the-art in training and most evaluations.","meta":{"url":"http://arxiv.org/abs/2309.03758v1"},"cats":{"new-dataset":0.0259598946,"dev-research":0.178665421,"data-quality":0.1570803667}}
{"text":"The physical robot is also implemented and tested in the real world.","meta":{"url":"http://arxiv.org/abs/2309.03758v1"},"cats":{"new-dataset":0.0522197313,"dev-research":0.2374868575,"data-quality":0.0542279237}}
{"text":"Synthetic Time Series Generation (TSG) is crucial in a range of applications, including data augmentation, anomaly detection, and privacy preservation.","meta":{"url":"http://arxiv.org/abs/2309.03755v1"},"cats":{"new-dataset":0.1958522562,"dev-research":0.1502522068,"data-quality":0.0651075551}}
{"text":"Although significant strides have been made in this field, existing methods exhibit three key limitations: (1) They often benchmark against similar model types, constraining a holistic view of performance capabilities.","meta":{"url":"http://arxiv.org/abs/2309.03755v1"},"cats":{"new-dataset":0.0033241798,"dev-research":0.1969903941,"data-quality":0.0450678232}}
{"text":"(2) The use of specialized synthetic and private datasets introduces biases and hampers generalizability.","meta":{"url":"http://arxiv.org/abs/2309.03755v1"},"cats":{"new-dataset":0.0701064407,"dev-research":0.1748040721,"data-quality":0.1467991002}}
{"text":"(3) Ambiguous evaluation measures, often tied to custom networks or downstream tasks, hinder consistent and fair comparison.   ","meta":{"url":"http://arxiv.org/abs/2309.03755v1"},"cats":{"new-dataset":0.0016769887,"dev-research":0.2714515134,"data-quality":0.2761908908}}
{"text":"To overcome these limitations, we introduce \\textsf{TSGBench}, the inaugural TSG Benchmark, designed for a unified and comprehensive assessment of TSG methods.","meta":{"url":"http://arxiv.org/abs/2309.03755v1"},"cats":{"new-dataset":0.0924963453,"dev-research":0.1369677625,"data-quality":0.1369646083}}
{"text":"It comprises three modules: (1) a curated collection of publicly available, real-world datasets tailored for TSG, together with a standardized preprocessing pipeline; (2) a comprehensive evaluation measures suite including vanilla measures, new distance-based assessments, and visualization tools; (3) a pioneering generalization test rooted in Domain Adaptation (DA), compatible with all methods.","meta":{"url":"http://arxiv.org/abs/2309.03755v1"},"cats":{"new-dataset":0.3140340172,"dev-research":0.1796278161,"data-quality":0.1152219882}}
{"text":"We have conducted extensive experiments across ten real-world datasets from diverse domains, utilizing ten advanced TSG methods and twelve evaluation measures, all gauged through \\textsf{TSGBench}.","meta":{"url":"http://arxiv.org/abs/2309.03755v1"},"cats":{"new-dataset":0.3908831876,"dev-research":0.124360727,"data-quality":0.1362655706}}
{"text":"The results highlight its remarkable efficacy and consistency.","meta":{"url":"http://arxiv.org/abs/2309.03755v1"},"cats":{"new-dataset":0.0037347812,"dev-research":0.2096921839,"data-quality":0.1676450481}}
{"text":"More importantly, \\textsf{TSGBench} delivers a statistical breakdown of method rankings, illuminating performance variations across different datasets and measures, and offering nuanced insights into the effectiveness of each method.","meta":{"url":"http://arxiv.org/abs/2309.03755v1"},"cats":{"new-dataset":0.0720794493,"dev-research":0.1984078305,"data-quality":0.183557676}}
{"text":"Over the last decades, Stochastic Gradient Descent (SGD) has been intensively studied by the Machine Learning community.","meta":{"url":"http://arxiv.org/abs/2309.03754v1"},"cats":{"new-dataset":0.0174665632,"dev-research":0.1404782698,"data-quality":0.128493697}}
{"text":"Despite its versatility and excellent performance, the optimization of large models via SGD still is a time-consuming task.","meta":{"url":"http://arxiv.org/abs/2309.03754v1"},"cats":{"new-dataset":0.009600542,"dev-research":0.1284146775,"data-quality":0.054654576}}
{"text":"To reduce training time, it is common to distribute the training process across multiple devices.","meta":{"url":"http://arxiv.org/abs/2309.03754v1"},"cats":{"new-dataset":0.0091377939,"dev-research":0.2228153934,"data-quality":0.0775743759}}
{"text":"Recently, it has been shown that the convergence of asynchronous SGD (ASGD) will always be faster than mini-batch SGD.","meta":{"url":"http://arxiv.org/abs/2309.03754v1"},"cats":{"new-dataset":0.0065039297,"dev-research":0.1127594051,"data-quality":0.1117938056}}
{"text":"However, despite these improvements in the theoretical bounds, most ASGD convergence-rate proofs still rely on a centralized parameter server, which is prone to become a bottleneck when scaling out the gradient computations across many distributed processes.   ","meta":{"url":"http://arxiv.org/abs/2309.03754v1"},"cats":{"new-dataset":0.0085409622,"dev-research":0.1060946498,"data-quality":0.0869958379}}
{"text":"In this paper, we present a novel convergence-rate analysis for decentralized and asynchronous SGD (DASGD) which does not require partial synchronization among nodes nor restrictive network topologies.","meta":{"url":"http://arxiv.org/abs/2309.03754v1"},"cats":{"new-dataset":0.0238701944,"dev-research":0.1191214397,"data-quality":0.0773681931}}
{"text":"Specifically, we provide a bound of $\\mathcal{O}(\\sigma\\epsilon^{-2})","meta":{"url":"http://arxiv.org/abs/2309.03754v1"},"cats":{"new-dataset":0.0367859657,"dev-research":0.1734458552,"data-quality":0.153909384}}
{"text":"+ \\mathcal{O}(QS_{avg}\\epsilon^{-3/2})","meta":{"url":"http://arxiv.org/abs/2309.03754v1"},"cats":{"new-dataset":0.0276123875,"dev-research":0.1330086097,"data-quality":0.1591241434}}
{"text":"+ \\mathcal{O}(S_{avg}\\epsilon^{-1})$ for the convergence rate of DASGD, where $S_{avg}$ is the average staleness between models, $Q$ is a constant that bounds the norm of the gradients, and $\\epsilon$ is a (small) error that is allowed within the bound.","meta":{"url":"http://arxiv.org/abs/2309.03754v1"},"cats":{"new-dataset":0.0140867813,"dev-research":0.1515199763,"data-quality":0.1730663091}}
{"text":"Furthermore, when gradients are not bounded, we prove the convergence rate of DASGD to be $\\mathcal{O}(\\sigma\\epsilon^{-2})","meta":{"url":"http://arxiv.org/abs/2309.03754v1"},"cats":{"new-dataset":0.0272766461,"dev-research":0.149471689,"data-quality":0.1509774501}}
{"text":"+ \\mathcal{O}(\\sqrt{\\hat{S}_{avg}\\hat{S}_{max}}\\epsilon^{-1})$, with $\\hat{S}_{max}$ and $\\hat{S}_{avg}$ representing a loose version of the average and maximum staleness, respectively.","meta":{"url":"http://arxiv.org/abs/2309.03754v1"},"cats":{"new-dataset":0.0207573075,"dev-research":0.1346915832,"data-quality":0.1758534276}}
{"text":"Our convergence proof holds for a fixed stepsize and any non-convex, homogeneous, and L-smooth objective function.","meta":{"url":"http://arxiv.org/abs/2309.03754v1"},"cats":{"new-dataset":0.0152035046,"dev-research":0.1608196745,"data-quality":0.1162878165}}
{"text":"We anticipate that our results will be of high relevance for the adoption of DASGD by a broad community of researchers and developers.","meta":{"url":"http://arxiv.org/abs/2309.03754v1"},"cats":{"new-dataset":0.1443701064,"dev-research":0.3295204322,"data-quality":0.1223581657}}
{"text":"The evaluation of clustering results is difficult, highly dependent on the evaluated data set and the perspective of the beholder.","meta":{"url":"http://arxiv.org/abs/2309.03751v1"},"cats":{"new-dataset":0.0093821644,"dev-research":0.220008818,"data-quality":0.2684468191}}
{"text":"There are many different clustering quality measures, which try to provide a general measure to validate clustering results.","meta":{"url":"http://arxiv.org/abs/2309.03751v1"},"cats":{"new-dataset":0.0084528026,"dev-research":0.250736882,"data-quality":0.2740622289}}
{"text":"A very popular measure is the Silhouette.","meta":{"url":"http://arxiv.org/abs/2309.03751v1"},"cats":{"new-dataset":0.2142545713,"dev-research":0.157261094,"data-quality":0.0751664992}}
{"text":"We discuss the efficient medoid-based variant of the Silhouette, perform a theoretical analysis of its properties, provide two fast versions for the direct optimization, and discuss the use to choose the optimal number of clusters.","meta":{"url":"http://arxiv.org/abs/2309.03751v1"},"cats":{"new-dataset":0.066361379,"dev-research":0.1666591033,"data-quality":0.0600153053}}
{"text":"We combine ideas from the original Silhouette with the well-known PAM algorithm and its latest improvements FasterPAM.","meta":{"url":"http://arxiv.org/abs/2309.03751v1"},"cats":{"new-dataset":0.0880429031,"dev-research":0.1744181178,"data-quality":0.0848124172}}
{"text":"One of the versions guarantees equal results to the original variant and provides a run speedup of $O(k^2)$. In experiments on real data with 30000 samples and $k$=100, we observed a 10464$\\times$ speedup compared to the original PAMMEDSIL algorithm.","meta":{"url":"http://arxiv.org/abs/2309.03751v1"},"cats":{"new-dataset":0.0385448049,"dev-research":0.1226863475,"data-quality":0.1000438869}}
{"text":"Additionally, we provide a variant to choose the optimal number of clusters directly.","meta":{"url":"http://arxiv.org/abs/2309.03751v1"},"cats":{"new-dataset":0.0475167826,"dev-research":0.1517490701,"data-quality":0.0768274018}}
{"text":"Trajectory prediction plays a crucial role in the autonomous driving stack by enabling autonomous vehicles to anticipate the motion of surrounding agents.","meta":{"url":"http://arxiv.org/abs/2309.03750v1"},"cats":{"new-dataset":0.0759919425,"dev-research":0.1895817981,"data-quality":0.053984897}}
{"text":"Goal-based prediction models have gained traction in recent years for addressing the multimodal nature of future trajectories.","meta":{"url":"http://arxiv.org/abs/2309.03750v1"},"cats":{"new-dataset":0.0849811094,"dev-research":0.1608956828,"data-quality":0.03977933}}
{"text":"Goal-based prediction models simplify multimodal prediction by first predicting 2D goal locations of agents and then predicting trajectories conditioned on each goal.","meta":{"url":"http://arxiv.org/abs/2309.03750v1"},"cats":{"new-dataset":0.1348860402,"dev-research":0.174754562,"data-quality":0.0345130876}}
{"text":"However, a single 2D goal location serves as a weak inductive bias for predicting the whole trajectory, often leading to poor map compliance, i.e., part of the trajectory going off-road or breaking traffic rules.","meta":{"url":"http://arxiv.org/abs/2309.03750v1"},"cats":{"new-dataset":0.0097361073,"dev-research":0.1538132452,"data-quality":0.0721328508}}
{"text":"In this paper, we improve upon goal-based prediction by proposing the Path-based prediction (PBP) approach.","meta":{"url":"http://arxiv.org/abs/2309.03750v1"},"cats":{"new-dataset":0.0299797526,"dev-research":0.2003487366,"data-quality":0.0620715999}}
{"text":"PBP predicts a discrete probability distribution over reference paths in the HD map using the path features and predicts trajectories in the path-relative Frenet frame.","meta":{"url":"http://arxiv.org/abs/2309.03750v1"},"cats":{"new-dataset":0.1030297073,"dev-research":0.1384522048,"data-quality":0.0893400718}}
{"text":"We applied the PBP trajectory decoder on top of the HiVT scene encoder and report results on the Argoverse dataset.","meta":{"url":"http://arxiv.org/abs/2309.03750v1"},"cats":{"new-dataset":0.3309225966,"dev-research":0.0905538997,"data-quality":0.1197920507}}
{"text":"Our experiments show that PBP achieves competitive performance on the standard trajectory prediction metrics, while significantly outperforming state-of-the-art baselines in terms of map compliance.","meta":{"url":"http://arxiv.org/abs/2309.03750v1"},"cats":{"new-dataset":0.0449884841,"dev-research":0.1521118223,"data-quality":0.0779114629}}
{"text":"The latest advancements in AI and deep learning have led to a breakthrough in large language model (LLM)-based agents such as GPT-4.","meta":{"url":"http://arxiv.org/abs/2309.03748v1"},"cats":{"new-dataset":0.1702625258,"dev-research":0.1144062894,"data-quality":0.0889362235}}
{"text":"However, many commercial conversational agent development tools are pipeline-based and have limitations in holding a human-like conversation.","meta":{"url":"http://arxiv.org/abs/2309.03748v1"},"cats":{"new-dataset":0.1031737932,"dev-research":0.35886409,"data-quality":0.0818652092}}
{"text":"This paper investigates the capabilities of LLMs to enhance pipeline-based conversational agents during two phases: 1) in the design and development phase and 2) during operations.","meta":{"url":"http://arxiv.org/abs/2309.03748v1"},"cats":{"new-dataset":0.0863276077,"dev-research":0.2680829374,"data-quality":0.0824483972}}
{"text":"In 1) LLMs can aid in generating training data, extracting entities and synonyms, localization, and persona design.","meta":{"url":"http://arxiv.org/abs/2309.03748v1"},"cats":{"new-dataset":0.092600722,"dev-research":0.1432662069,"data-quality":0.1256586613}}
{"text":"In 2) LLMs can assist in contextualization, intent classification to prevent conversational breakdown and handle out-of-scope questions, auto-correcting utterances, rephrasing responses, formulating disambiguation questions, summarization, and enabling closed question-answering capabilities.","meta":{"url":"http://arxiv.org/abs/2309.03748v1"},"cats":{"new-dataset":0.0226903454,"dev-research":0.1580339061,"data-quality":0.1370744414}}
{"text":"We conducted informal experiments with GPT-4 in the private banking domain to demonstrate the scenarios above with a practical example.","meta":{"url":"http://arxiv.org/abs/2309.03748v1"},"cats":{"new-dataset":0.0300815632,"dev-research":0.1277061889,"data-quality":0.099302158}}
{"text":"Companies may be hesitant to replace their pipeline-based agents with LLMs entirely due to privacy concerns and the need for deep integration within their existing ecosystems.","meta":{"url":"http://arxiv.org/abs/2309.03748v1"},"cats":{"new-dataset":0.0168507562,"dev-research":0.1400655425,"data-quality":0.0968109243}}
{"text":"A hybrid approach in which LLMs' are integrated into the pipeline-based agents allows them to save time and costs of building and running agents by capitalizing on the capabilities of LLMs while retaining the integration and privacy safeguards of their existing systems.","meta":{"url":"http://arxiv.org/abs/2309.03748v1"},"cats":{"new-dataset":0.0250876355,"dev-research":0.1552828817,"data-quality":0.0577491765}}
{"text":"In this paper, we adopted a retrospective approach to examine and compare five existing popular sentence encoders, i.e., Sentence-BERT, Universal Sentence Encoder (USE), LASER, InferSent, and Doc2vec, in terms of their performance on downstream tasks versus their capability to capture basic semantic properties.","meta":{"url":"http://arxiv.org/abs/2309.03747v1"},"cats":{"new-dataset":0.0439668194,"dev-research":0.2303794734,"data-quality":0.1639787982}}
{"text":"Initially, we evaluated all five sentence encoders on the popular SentEval benchmark and found that multiple sentence encoders perform quite well on a variety of popular downstream tasks.","meta":{"url":"http://arxiv.org/abs/2309.03747v1"},"cats":{"new-dataset":0.0621270075,"dev-research":0.1684259634,"data-quality":0.1565391246}}
{"text":"However, being unable to find a single winner in all cases, we designed further experiments to gain a deeper understanding of their behavior.","meta":{"url":"http://arxiv.org/abs/2309.03747v1"},"cats":{"new-dataset":0.0100576437,"dev-research":0.1311482565,"data-quality":0.1622074801}}
{"text":"Specifically, we proposed four semantic evaluation criteria, i.e., Paraphrasing, Synonym Replacement, Antonym Replacement, and Sentence Jumbling, and evaluated the same five sentence encoders using these criteria.","meta":{"url":"http://arxiv.org/abs/2309.03747v1"},"cats":{"new-dataset":0.0280144587,"dev-research":0.2692327709,"data-quality":0.27750793}}
{"text":"We found that the Sentence-Bert and USE models pass the paraphrasing criterion, with SBERT being the superior between the two.","meta":{"url":"http://arxiv.org/abs/2309.03747v1"},"cats":{"new-dataset":0.0102844651,"dev-research":0.2144633012,"data-quality":0.1726276368}}
{"text":"LASER dominates in the case of the synonym replacement criterion.","meta":{"url":"http://arxiv.org/abs/2309.03747v1"},"cats":{"new-dataset":0.0051286804,"dev-research":0.1936620291,"data-quality":0.2091076127}}
{"text":"Interestingly, all the sentence encoders failed the antonym replacement and jumbling criteria.","meta":{"url":"http://arxiv.org/abs/2309.03747v1"},"cats":{"new-dataset":0.0170729664,"dev-research":0.1854963417,"data-quality":0.4042775622}}
{"text":"These results suggest that although these popular sentence encoders perform quite well on the SentEval benchmark, they still struggle to capture some basic semantic properties, thus, posing a daunting dilemma in NLP research.","meta":{"url":"http://arxiv.org/abs/2309.03747v1"},"cats":{"new-dataset":0.0456592817,"dev-research":0.2256581759,"data-quality":0.2323699438}}
{"text":"Malicious communication behavior is the network communication behavior generated by malware (bot-net, spyware, etc.)","meta":{"url":"http://arxiv.org/abs/2309.03739v1"},"cats":{"new-dataset":0.0295253208,"dev-research":0.310235035,"data-quality":0.1519188616}}
{"text":"after victim devices are infected.","meta":{"url":"http://arxiv.org/abs/2309.03739v1"},"cats":{"new-dataset":0.0761475162,"dev-research":0.2082565086,"data-quality":0.1111632917}}
{"text":"Experienced adversaries often hide malicious information in HTTP traffic to evade detection.","meta":{"url":"http://arxiv.org/abs/2309.03739v1"},"cats":{"new-dataset":0.0082912809,"dev-research":0.2061392821,"data-quality":0.1636613545}}
{"text":"However, related detection methods have inadequate generalization ability because they are usually based on artificial feature engineering and outmoded datasets.","meta":{"url":"http://arxiv.org/abs/2309.03739v1"},"cats":{"new-dataset":0.0087698878,"dev-research":0.2804957741,"data-quality":0.4315056463}}
{"text":"In this paper, we propose an HTTP-based Malicious Communication traffic Detection Model (HMCD-Model) based on generated adversarial flows and hierarchical traffic features.","meta":{"url":"http://arxiv.org/abs/2309.03739v1"},"cats":{"new-dataset":0.0265102964,"dev-research":0.1226322254,"data-quality":0.1130533362}}
{"text":"HMCD-Model consists of two parts.","meta":{"url":"http://arxiv.org/abs/2309.03739v1"},"cats":{"new-dataset":0.0716599995,"dev-research":0.1121812662,"data-quality":0.0749800641}}
{"text":"The first is a generation algorithm based on WGAN-GP to generate HTTP-based malicious communication traffic for data enhancement.","meta":{"url":"http://arxiv.org/abs/2309.03739v1"},"cats":{"new-dataset":0.0374331945,"dev-research":0.1912086569,"data-quality":0.088817234}}
{"text":"The second is a hybrid neural network based on CNN and LSTM to extract hierarchical spatial-temporal features of traffic.","meta":{"url":"http://arxiv.org/abs/2309.03739v1"},"cats":{"new-dataset":0.1339810361,"dev-research":0.1237594007,"data-quality":0.0983081757}}
{"text":"In addition, we collect and publish a dataset, HMCT-2020, which consists of large-scale malicious and benign traffic during three years (2018-2020).","meta":{"url":"http://arxiv.org/abs/2309.03739v1"},"cats":{"new-dataset":0.8285447542,"dev-research":0.1672841034,"data-quality":0.1525899842}}
{"text":"Taking the data in HMCT-2020(18) as the training set and the data in other datasets as the test set, the experimental results show that the HMCD-Model can effectively detect unknown HTTP-based malicious communication traffic.","meta":{"url":"http://arxiv.org/abs/2309.03739v1"},"cats":{"new-dataset":0.1178108312,"dev-research":0.1212579048,"data-quality":0.1543837858}}
{"text":"It can reach F1 = 98.66% in the dataset HMCT-2020(19-20), F1 = 90.69% in the public dataset CIC-IDS-2017, and F1 = 83.66% in the real traffic, which is 20+% higher than other representative methods on average.","meta":{"url":"http://arxiv.org/abs/2309.03739v1"},"cats":{"new-dataset":0.1467808505,"dev-research":0.1323136192,"data-quality":0.154915759}}
{"text":"This validates that HMCD-Model has the ability to discover unknown HTTP-based malicious communication behavior.","meta":{"url":"http://arxiv.org/abs/2309.03739v1"},"cats":{"new-dataset":0.0139225083,"dev-research":0.1645890047,"data-quality":0.1399093154}}
{"text":"Thanks to the complementary nature of millimeter wave radar and camera, deep learning-based radar-camera 3D object detection methods may reliably produce accurate detections even in low-visibility conditions.","meta":{"url":"http://arxiv.org/abs/2309.03734v1"},"cats":{"new-dataset":0.1393578289,"dev-research":0.1589372048,"data-quality":0.1175144207}}
{"text":"This makes them preferable to use in autonomous vehicles' perception systems, especially as the combined cost of both sensors is cheaper than the cost of a lidar.","meta":{"url":"http://arxiv.org/abs/2309.03734v1"},"cats":{"new-dataset":0.0025531415,"dev-research":0.2229841154,"data-quality":0.0867234192}}
{"text":"Recent radar-camera methods commonly perform feature-level fusion which often involves projecting the radar points onto the same plane as the image features and fusing the extracted features from both modalities.","meta":{"url":"http://arxiv.org/abs/2309.03734v1"},"cats":{"new-dataset":0.0487839613,"dev-research":0.2177199631,"data-quality":0.1170670724}}
{"text":"While performing fusion on the image plane is generally simpler and faster, projecting radar points onto the image plane flattens the depth dimension of the point cloud which might lead to information loss and makes extracting the spatial features of the point cloud harder.","meta":{"url":"http://arxiv.org/abs/2309.03734v1"},"cats":{"new-dataset":0.0111875531,"dev-research":0.2111040793,"data-quality":0.0915324024}}
{"text":"We proposed ClusterFusion, an architecture that leverages the local spatial features of the radar point cloud by clustering the point cloud and performing feature extraction directly on the point cloud clusters before projecting the features onto the image plane.","meta":{"url":"http://arxiv.org/abs/2309.03734v1"},"cats":{"new-dataset":0.081627351,"dev-research":0.2288517388,"data-quality":0.1251479048}}
{"text":"ClusterFusion achieved the state-of-the-art performance among all radar-monocular camera methods on the test slice of the nuScenes dataset with 48.7% nuScenes detection score (NDS).","meta":{"url":"http://arxiv.org/abs/2309.03734v1"},"cats":{"new-dataset":0.1573576778,"dev-research":0.1978150928,"data-quality":0.1682833562}}
{"text":"We also investigated the performance of different radar feature extraction strategies on point cloud clusters: a handcrafted strategy, a learning-based strategy, and a combination of both, and found that the handcrafted strategy yielded the best performance.","meta":{"url":"http://arxiv.org/abs/2309.03734v1"},"cats":{"new-dataset":0.0422271058,"dev-research":0.1941959612,"data-quality":0.1228794984}}
{"text":"The main goal of this work is to explore the use of radar's local spatial and point-wise features by extracting them directly from radar point cloud clusters for a radar-monocular camera 3D object detection method that performs cross-modal feature fusion on the image plane.","meta":{"url":"http://arxiv.org/abs/2309.03734v1"},"cats":{"new-dataset":0.0671361569,"dev-research":0.1802224962,"data-quality":0.1180425366}}
{"text":"Estimating the effects of treatments with an associated dose on an instance's outcome, the \"dose response\", is relevant in a variety of domains, from healthcare to business, economics, and beyond.","meta":{"url":"http://arxiv.org/abs/2309.03731v1"},"cats":{"new-dataset":0.0167201503,"dev-research":0.1675647737,"data-quality":0.1061086291}}
{"text":"Such effects, also known as continuous-valued treatment effects, are typically estimated from observational data, which may be subject to dose selection bias.","meta":{"url":"http://arxiv.org/abs/2309.03731v1"},"cats":{"new-dataset":0.0100369842,"dev-research":0.1547600105,"data-quality":0.1099196897}}
{"text":"This means that the allocation of doses depends on pre-treatment covariates.","meta":{"url":"http://arxiv.org/abs/2309.03731v1"},"cats":{"new-dataset":0.0194683419,"dev-research":0.1662019984,"data-quality":0.0580558063}}
{"text":"Previous studies have shown that conventional machine learning approaches fail to learn accurate individual estimates of dose responses under the presence of dose selection bias.","meta":{"url":"http://arxiv.org/abs/2309.03731v1"},"cats":{"new-dataset":0.0168260763,"dev-research":0.1354072353,"data-quality":0.2075979669}}
{"text":"In this work, we propose CBRNet, a causal machine learning approach to estimate an individual dose response from observational data.","meta":{"url":"http://arxiv.org/abs/2309.03731v1"},"cats":{"new-dataset":0.1414798742,"dev-research":0.1490460991,"data-quality":0.1220969678}}
{"text":"CBRNet adopts the Neyman-Rubin potential outcome framework and extends the concept of balanced representation learning for overcoming selection bias to continuous-valued treatments.","meta":{"url":"http://arxiv.org/abs/2309.03731v1"},"cats":{"new-dataset":0.0085674995,"dev-research":0.149607289,"data-quality":0.1200088274}}
{"text":"Our work is the first to apply representation balancing in a continuous-valued treatment setting.","meta":{"url":"http://arxiv.org/abs/2309.03731v1"},"cats":{"new-dataset":0.0204719315,"dev-research":0.1901340585,"data-quality":0.12085575}}
{"text":"We evaluate our method on a newly proposed benchmark.","meta":{"url":"http://arxiv.org/abs/2309.03731v1"},"cats":{"new-dataset":0.0553948822,"dev-research":0.1497102496,"data-quality":0.1803251614}}
{"text":"Our experiments demonstrate CBRNet's ability to accurately learn treatment effects under selection bias and competitive performance with respect to other state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2309.03731v1"},"cats":{"new-dataset":0.0072638621,"dev-research":0.1493406208,"data-quality":0.1088905053}}
{"text":"In lending, where prices are specific to both customers and products, having a well-functioning personalized pricing policy in place is essential to effective business making.","meta":{"url":"http://arxiv.org/abs/2309.03730v1"},"cats":{"new-dataset":0.0187123683,"dev-research":0.2195015727,"data-quality":0.1380363553}}
{"text":"Typically, such a policy must be derived from observational data, which introduces several challenges.","meta":{"url":"http://arxiv.org/abs/2309.03730v1"},"cats":{"new-dataset":0.0260636899,"dev-research":0.1954942302,"data-quality":0.1057684121}}
{"text":"While the problem of ``endogeneity'' is prominently studied in the established pricing literature, the problem of selection bias (or, more precisely, bid selection bias) is not.","meta":{"url":"http://arxiv.org/abs/2309.03730v1"},"cats":{"new-dataset":0.0069001517,"dev-research":0.1234598587,"data-quality":0.1487883069}}
{"text":"We take a step towards understanding the effects of selection bias by posing pricing as a problem of causal inference.","meta":{"url":"http://arxiv.org/abs/2309.03730v1"},"cats":{"new-dataset":0.0047337801,"dev-research":0.1540078244,"data-quality":0.15029361}}
{"text":"Specifically, we consider the reaction of a customer to price a treatment effect.","meta":{"url":"http://arxiv.org/abs/2309.03730v1"},"cats":{"new-dataset":0.0279538289,"dev-research":0.2532935036,"data-quality":0.1499566458}}
{"text":"In our experiments, we simulate varying levels of selection bias on a semi-synthetic dataset on mortgage loan applications in Belgium.","meta":{"url":"http://arxiv.org/abs/2309.03730v1"},"cats":{"new-dataset":0.0438428265,"dev-research":0.1134609789,"data-quality":0.1241981438}}
{"text":"We investigate the potential of parametric and nonparametric methods for the identification of individual bid-response functions.","meta":{"url":"http://arxiv.org/abs/2309.03730v1"},"cats":{"new-dataset":0.0131628911,"dev-research":0.0960069483,"data-quality":0.1168414476}}
{"text":"Our results illustrate how conventional methods such as logistic regression and neural networks suffer adversely from selection bias.","meta":{"url":"http://arxiv.org/abs/2309.03730v1"},"cats":{"new-dataset":0.0020703748,"dev-research":0.1605344774,"data-quality":0.1921810731}}
{"text":"In contrast, we implement state-of-the-art methods from causal machine learning and show their capability to overcome selection bias in pricing data.","meta":{"url":"http://arxiv.org/abs/2309.03730v1"},"cats":{"new-dataset":0.0265562311,"dev-research":0.174672974,"data-quality":0.203995822}}
{"text":"Training a generative model with limited number of samples is a challenging task.","meta":{"url":"http://arxiv.org/abs/2309.03729v1"},"cats":{"new-dataset":0.1472976605,"dev-research":0.1380641701,"data-quality":0.1686321226}}
{"text":"Current methods primarily rely on few-shot model adaption to train the network.","meta":{"url":"http://arxiv.org/abs/2309.03729v1"},"cats":{"new-dataset":0.0037446812,"dev-research":0.1444518744,"data-quality":0.1212639159}}
{"text":"However, in scenarios where data is extremely limited (less than 10), the generative network tends to overfit and suffers from content degradation.","meta":{"url":"http://arxiv.org/abs/2309.03729v1"},"cats":{"new-dataset":0.0278848554,"dev-research":0.1938662803,"data-quality":0.1927722625}}
{"text":"To address these problems, we propose a novel phasic content fusing few-shot diffusion model with directional distribution consistency loss, which targets different learning objectives at distinct training stages of the diffusion model.","meta":{"url":"http://arxiv.org/abs/2309.03729v1"},"cats":{"new-dataset":0.0254870279,"dev-research":0.093717462,"data-quality":0.1736503848}}
{"text":"Specifically, we design a phasic training strategy with phasic content fusion to help our model learn content and style information when t is large, and learn local details of target domain when t is small, leading to an improvement in the capture of content, style and local details.","meta":{"url":"http://arxiv.org/abs/2309.03729v1"},"cats":{"new-dataset":0.0785914988,"dev-research":0.1385898429,"data-quality":0.117057259}}
{"text":"Furthermore, we introduce a novel directional distribution consistency loss that ensures the consistency between the generated and source distributions more efficiently and stably than the prior methods, preventing our model from overfitting.","meta":{"url":"http://arxiv.org/abs/2309.03729v1"},"cats":{"new-dataset":0.0443318394,"dev-research":0.1711575189,"data-quality":0.4156825346}}
{"text":"Finally, we propose a cross-domain structure guidance strategy that enhances structure consistency during domain adaptation.","meta":{"url":"http://arxiv.org/abs/2309.03729v1"},"cats":{"new-dataset":0.0112604152,"dev-research":0.2033250716,"data-quality":0.1425920164}}
{"text":"Theoretical analysis, qualitative and quantitative experiments demonstrate the superiority of our approach in few-shot generative model adaption tasks compared to state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2309.03729v1"},"cats":{"new-dataset":0.0079052392,"dev-research":0.1741816847,"data-quality":0.1060527155}}
{"text":"The source code is available at: https://github.com/sjtuplayer/few-shot-diffusion.","meta":{"url":"http://arxiv.org/abs/2309.03729v1"},"cats":{"new-dataset":0.1707924246,"dev-research":0.117564606,"data-quality":0.0784356515}}
{"text":"An adjacency sketching or implicit labeling scheme for a family $\\cal F$ of graphs is a method that defines for any $n$ vertex $G \\in \\cal F$ an assignment of labels to each vertex in $G$, so that the labels of two vertices tell you whether or not they are adjacent.","meta":{"url":"http://arxiv.org/abs/2309.03728v1"},"cats":{"new-dataset":0.0357198502,"dev-research":0.3776940485,"data-quality":0.2312977539}}
{"text":"The goal is to come up with labeling schemes that use as few bits as possible to represent the labels.","meta":{"url":"http://arxiv.org/abs/2309.03728v1"},"cats":{"new-dataset":0.0567382344,"dev-research":0.2045713406,"data-quality":0.3935388116}}
{"text":"By using randomness when assigning labels, it is sometimes possible to produce adjacency sketches with much smaller label sizes, but this comes at the cost of introducing some probability of error.","meta":{"url":"http://arxiv.org/abs/2309.03728v1"},"cats":{"new-dataset":0.0231344272,"dev-research":0.2382326965,"data-quality":0.4215503886}}
{"text":"Both deterministic and randomized labeling schemes have been extensively studied, as they have applications for distributed data structures and deeper connections to universal graphs and communication complexity.","meta":{"url":"http://arxiv.org/abs/2309.03728v1"},"cats":{"new-dataset":0.1575569985,"dev-research":0.1333742799,"data-quality":0.3475213803}}
{"text":"The main question of interest is which graph families have schemes using short labels, usually $O(\\log n)$ in the deterministic case or constant for randomized sketches.   ","meta":{"url":"http://arxiv.org/abs/2309.03728v1"},"cats":{"new-dataset":0.0356853849,"dev-research":0.1891884889,"data-quality":0.1513552998}}
{"text":"In this work we consider the resilience of probabilistic adjacency sketches against an adversary making adaptive queries to the labels.","meta":{"url":"http://arxiv.org/abs/2309.03728v1"},"cats":{"new-dataset":0.0871846394,"dev-research":0.2013968699,"data-quality":0.3583294821}}
{"text":"This differs from the previously analyzed probabilistic setting which is ``one shot\".","meta":{"url":"http://arxiv.org/abs/2309.03728v1"},"cats":{"new-dataset":0.0259851295,"dev-research":0.1745502408,"data-quality":0.1375356}}
{"text":"We show that in the adaptive adversarial case the size of the labels is tightly related to the maximal degree of the graphs in $\\cal F$.","meta":{"url":"http://arxiv.org/abs/2309.03728v1"},"cats":{"new-dataset":0.0618196054,"dev-research":0.1394925242,"data-quality":0.3799684724}}
{"text":"This results in a stronger characterization compared to what is known in the non-adversarial setting.","meta":{"url":"http://arxiv.org/abs/2309.03728v1"},"cats":{"new-dataset":0.0089733247,"dev-research":0.1584979181,"data-quality":0.2971238728}}
{"text":"In more detail, we construct sketches that fail with probability $\\varepsilon$ for graphs with maximal degree $d$ using $2d\\log (1/\\varepsilon)$ bit labels and show that this is roughly the best that can be done for any specific graph of maximal degree $d$, e.g.\\ a $d$-ary tree.","meta":{"url":"http://arxiv.org/abs/2309.03728v1"},"cats":{"new-dataset":0.0920781178,"dev-research":0.15820479,"data-quality":0.280774756}}
{"text":"Transformer-based architectures have recently demonstrated remarkable performance in the Visual Question Answering (VQA) task.","meta":{"url":"http://arxiv.org/abs/2309.03726v1"},"cats":{"new-dataset":0.0431197728,"dev-research":0.2081514959,"data-quality":0.1097827673}}
{"text":"However, such models are likely to disregard crucial visual cues and often rely on multimodal shortcuts and inherent biases of the language modality to predict the correct answer, a phenomenon commonly referred to as lack of visual grounding.","meta":{"url":"http://arxiv.org/abs/2309.03726v1"},"cats":{"new-dataset":0.0093182388,"dev-research":0.2957180631,"data-quality":0.2151886123}}
{"text":"In this work, we alleviate this shortcoming through a novel architecture for visual question answering that leverages common sense reasoning as a supervisory signal.","meta":{"url":"http://arxiv.org/abs/2309.03726v1"},"cats":{"new-dataset":0.1538193994,"dev-research":0.344150945,"data-quality":0.15734388}}
{"text":"Reasoning supervision takes the form of a textual justification of the correct answer, with such annotations being already available on large-scale Visual Common Sense Reasoning (VCR) datasets.","meta":{"url":"http://arxiv.org/abs/2309.03726v1"},"cats":{"new-dataset":0.378857133,"dev-research":0.4352283855,"data-quality":0.2525016123}}
{"text":"The model's visual attention is guided toward important elements of the scene through a similarity loss that aligns the learned attention distributions guided by the question and the correct reasoning.","meta":{"url":"http://arxiv.org/abs/2309.03726v1"},"cats":{"new-dataset":0.0582019514,"dev-research":0.2113706519,"data-quality":0.1908815967}}
{"text":"We demonstrate both quantitatively and qualitatively that the proposed approach can boost the model's visual perception capability and lead to performance increase, without requiring training on explicit grounding annotations.","meta":{"url":"http://arxiv.org/abs/2309.03726v1"},"cats":{"new-dataset":0.0429754178,"dev-research":0.2063170904,"data-quality":0.2644901945}}
{"text":"Maternal health remains a pervasive challenge in developing and underdeveloped countries.","meta":{"url":"http://arxiv.org/abs/2309.03725v1"},"cats":{"new-dataset":0.022369896,"dev-research":0.2375894802,"data-quality":0.0829267281}}
{"text":"Inadequate access to basic antenatal Ultrasound (US) examinations, limited resources such as primary health services and infrastructure, and lack of skilled healthcare professionals are the major concerns.","meta":{"url":"http://arxiv.org/abs/2309.03725v1"},"cats":{"new-dataset":0.0148804211,"dev-research":0.2492061603,"data-quality":0.098388055}}
{"text":"To improve the quality of maternal care, robot-assisted antenatal US systems with teleoperable and autonomous capabilities were introduced.","meta":{"url":"http://arxiv.org/abs/2309.03725v1"},"cats":{"new-dataset":0.0152251273,"dev-research":0.1849198779,"data-quality":0.0602027876}}
{"text":"However, the existing teleoperation systems rely on standard video stream-based approaches that are constrained by limited immersion and scene awareness.","meta":{"url":"http://arxiv.org/abs/2309.03725v1"},"cats":{"new-dataset":0.0318999147,"dev-research":0.1712076526,"data-quality":0.0568910754}}
{"text":"Also, there is no prior work on autonomous antenatal robotic US systems that automate standardized scanning protocols.","meta":{"url":"http://arxiv.org/abs/2309.03725v1"},"cats":{"new-dataset":0.0130096431,"dev-research":0.1839176425,"data-quality":0.0946047537}}
{"text":"To that end, this paper introduces a novel Virtual Reality (VR) platform for robotic antenatal ultrasound, which enables sonologists to control a robotic arm over a wired network.","meta":{"url":"http://arxiv.org/abs/2309.03725v1"},"cats":{"new-dataset":0.0462789524,"dev-research":0.1976780718,"data-quality":0.0659314778}}
{"text":"The effectiveness of the system is enhanced by providing a reconstructed 3D view of the environment and immersing the user in a VR space.","meta":{"url":"http://arxiv.org/abs/2309.03725v1"},"cats":{"new-dataset":0.0515289313,"dev-research":0.2554227033,"data-quality":0.0513515074}}
{"text":"Also, the system facilitates a better understanding of the anatomical surfaces to perform pragmatic scans using 3D models.","meta":{"url":"http://arxiv.org/abs/2309.03725v1"},"cats":{"new-dataset":0.040634912,"dev-research":0.201095341,"data-quality":0.0641408978}}
{"text":"Further, the proposed robotic system also has autonomous capabilities; under the supervision of the sonologist, it can perform the standard six-step approach for obstetric US scanning recommended by the ISUOG.","meta":{"url":"http://arxiv.org/abs/2309.03725v1"},"cats":{"new-dataset":0.0186247414,"dev-research":0.1327654151,"data-quality":0.0581884422}}
{"text":"Using a 23-week fetal phantom, the proposed system was demonstrated to technology and academia experts at MEDICA 2022 as a part of the KUKA Innovation Award.","meta":{"url":"http://arxiv.org/abs/2309.03725v1"},"cats":{"new-dataset":0.0298997595,"dev-research":0.1906305341,"data-quality":0.055820507}}
{"text":"The positive feedback from them supports the feasibility of the system.","meta":{"url":"http://arxiv.org/abs/2309.03725v1"},"cats":{"new-dataset":0.0084801947,"dev-research":0.181859001,"data-quality":0.0877114329}}
{"text":"It also gave an insight into the improvisations to be carried out to make it a clinically viable system.","meta":{"url":"http://arxiv.org/abs/2309.03725v1"},"cats":{"new-dataset":0.0131254595,"dev-research":0.2126612883,"data-quality":0.0684521782}}
{"text":"HTTP-based Trojan is extremely threatening, and it is difficult to be effectively detected because of its concealment and confusion.","meta":{"url":"http://arxiv.org/abs/2309.03724v1"},"cats":{"new-dataset":0.0071843842,"dev-research":0.1866227049,"data-quality":0.1631206989}}
{"text":"Previous detection methods usually are with poor generalization ability due to outdated datasets and reliance on manual feature extraction, which makes these methods always perform well under their private dataset, but poorly or even fail to work in real network environment.","meta":{"url":"http://arxiv.org/abs/2309.03724v1"},"cats":{"new-dataset":0.0298543551,"dev-research":0.2070712563,"data-quality":0.4135027983}}
{"text":"In this paper, we propose an HTTP-based Trojan detection model via the Hierarchical Spatio-Temporal Features of traffics (HSTF-Model) based on the formalized description of traffic spatio-temporal behavior from both packet level and flow level.","meta":{"url":"http://arxiv.org/abs/2309.03724v1"},"cats":{"new-dataset":0.0610722582,"dev-research":0.2020470913,"data-quality":0.1041370045}}
{"text":"In this model, we employ Convolutional Neural Network (CNN) to extract spatial information and Long Short-Term Memory (LSTM) to extract temporal information.","meta":{"url":"http://arxiv.org/abs/2309.03724v1"},"cats":{"new-dataset":0.240157355,"dev-research":0.1260596433,"data-quality":0.0662147581}}
{"text":"In addition, we present a dataset consisting of Benign and Trojan HTTP Traffic (BTHT-2018).","meta":{"url":"http://arxiv.org/abs/2309.03724v1"},"cats":{"new-dataset":0.5088611245,"dev-research":0.1456716668,"data-quality":0.1536693226}}
{"text":"Experimental results show that our model can guarantee high accuracy (the F1 of 98.62%-99.81% and the FPR of 0.34%-0.02% in BTHT-2018).","meta":{"url":"http://arxiv.org/abs/2309.03724v1"},"cats":{"new-dataset":0.0549026955,"dev-research":0.1279214979,"data-quality":0.1408203106}}
{"text":"More importantly, our model has a huge advantage over other related methods in generalization ability.","meta":{"url":"http://arxiv.org/abs/2309.03724v1"},"cats":{"new-dataset":0.0019167509,"dev-research":0.1792928125,"data-quality":0.0968970415}}
{"text":"HSTF-Model trained with BTHT-2018 can reach the F1 of 93.51% on the public dataset ISCX-2012, which is 20+% better than the best of related machine learning methods.","meta":{"url":"http://arxiv.org/abs/2309.03724v1"},"cats":{"new-dataset":0.2797492528,"dev-research":0.1287151002,"data-quality":0.1181829882}}
{"text":"Roof plane segmentation from airborne LiDAR point clouds is an important technology for 3D building model reconstruction.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.0536233682,"dev-research":0.2163551059,"data-quality":0.0777440811}}
{"text":"One of the key issues of plane segmentation is how to design powerful features that can exactly distinguish adjacent planar patches.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.0646493096,"dev-research":0.2535824388,"data-quality":0.1378562778}}
{"text":"The quality of point feature directly determines the accuracy of roof plane segmentation.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.0080359255,"dev-research":0.2231903976,"data-quality":0.2234816108}}
{"text":"Most of existing approaches use handcrafted features to extract roof planes.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.0136434595,"dev-research":0.1932571066,"data-quality":0.064387779}}
{"text":"However, the abilities of these features are relatively low, especially in boundary area.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.0107363615,"dev-research":0.1639078509,"data-quality":0.1223139836}}
{"text":"To solve this problem, we propose a boundary-aware point clustering approach in Euclidean and embedding spaces constructed by a multi-task deep network for roof plane segmentation.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.1133424643,"dev-research":0.1862082505,"data-quality":0.122409393}}
{"text":"We design a three-branch network to predict semantic labels, point offsets and extract deep embedding features.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.2757818792,"dev-research":0.1829297008,"data-quality":0.3851494805}}
{"text":"In the first branch, we classify the input data as non-roof, boundary and plane points.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.1584987652,"dev-research":0.1064135326,"data-quality":0.1189132811}}
{"text":"In the second branch, we predict point offsets for shifting each point toward its respective instance center.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.0434752343,"dev-research":0.1360158807,"data-quality":0.1031654419}}
{"text":"In the third branch, we constrain that points of the same plane instance should have the similar embeddings.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.034451538,"dev-research":0.1308024471,"data-quality":0.1913852379}}
{"text":"We aim to ensure that points of the same plane instance are close as much as possible in both Euclidean and embedding spaces.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.0322963167,"dev-research":0.1838371214,"data-quality":0.1652292754}}
{"text":"However, although deep network has strong feature representative ability, it is still hard to accurately distinguish points near plane instance boundary.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.0202375009,"dev-research":0.1606399581,"data-quality":0.2672319733}}
{"text":"Therefore, we first group plane points into many clusters in the two spaces, and then we assign the rest boundary points to their closest clusters to generate final complete roof planes.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.1228602622,"dev-research":0.147888552,"data-quality":0.0805775689}}
{"text":"In this way, we can effectively reduce the influence of unreliable boundary points.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.0075334047,"dev-research":0.2465796657,"data-quality":0.2214413213}}
{"text":"In addition, we construct a synthetic dataset and a real dataset to train and evaluate our approach.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.7200494464,"dev-research":0.21660164,"data-quality":0.1942137849}}
{"text":"The experiments results show that the proposed approach significantly outperforms the existing state-of-the-art approaches.","meta":{"url":"http://arxiv.org/abs/2309.03722v1"},"cats":{"new-dataset":0.0037561526,"dev-research":0.1883319802,"data-quality":0.1584741518}}
{"text":"Forecasting natural gas consumption, considering seasonality and trends, is crucial in planning its supply and consumption and optimizing the cost of obtaining it, mainly by industrial entities.","meta":{"url":"http://arxiv.org/abs/2309.03720v1"},"cats":{"new-dataset":0.0149247609,"dev-research":0.2227799691,"data-quality":0.0536462388}}
{"text":"However, in times of threats to its supply, it is also a critical element that guarantees the supply of this raw material to meet individual consumers' needs, ensuring society's energy security.","meta":{"url":"http://arxiv.org/abs/2309.03720v1"},"cats":{"new-dataset":0.0590212525,"dev-research":0.2329147021,"data-quality":0.1023698364}}
{"text":"This article introduces a novel multistep ahead forecasting of natural gas consumption with change point detection integration for model collection selection with continual learning capabilities using data stream processing.","meta":{"url":"http://arxiv.org/abs/2309.03720v1"},"cats":{"new-dataset":0.0697838394,"dev-research":0.1723590699,"data-quality":0.0925680501}}
{"text":"The performance of the forecasting models based on the proposed approach is evaluated in a complex real-world use case of natural gas consumption forecasting.","meta":{"url":"http://arxiv.org/abs/2309.03720v1"},"cats":{"new-dataset":0.0121347017,"dev-research":0.1889870652,"data-quality":0.0542125035}}
{"text":"We employed Hoeffding tree predictors as forecasting models and the Pruned Exact Linear Time (PELT) algorithm for the change point detection procedure.","meta":{"url":"http://arxiv.org/abs/2309.03720v1"},"cats":{"new-dataset":0.0961720688,"dev-research":0.2083054855,"data-quality":0.1457867513}}
{"text":"The change point detection integration enables selecting a different model collection for successive time frames.","meta":{"url":"http://arxiv.org/abs/2309.03720v1"},"cats":{"new-dataset":0.102370587,"dev-research":0.2473389833,"data-quality":0.1505518896}}
{"text":"Thus, three model collection selection procedures (with and without an error feedback loop) are defined and evaluated for forecasting scenarios with various densities of detected change points.","meta":{"url":"http://arxiv.org/abs/2309.03720v1"},"cats":{"new-dataset":0.0451108036,"dev-research":0.2030191345,"data-quality":0.0965162756}}
{"text":"These models were compared with change point agnostic baseline approaches.","meta":{"url":"http://arxiv.org/abs/2309.03720v1"},"cats":{"new-dataset":0.0177734087,"dev-research":0.1944155069,"data-quality":0.106030285}}
{"text":"Our experiments show that fewer change points result in a lower forecasting error regardless of the model collection selection procedure employed.","meta":{"url":"http://arxiv.org/abs/2309.03720v1"},"cats":{"new-dataset":0.0198649591,"dev-research":0.1918775861,"data-quality":0.1522621923}}
{"text":"Also, simpler model collection selection procedures omitting forecasting error feedback leads to more robust forecasting models suitable for continual learning tasks.","meta":{"url":"http://arxiv.org/abs/2309.03720v1"},"cats":{"new-dataset":0.0148074911,"dev-research":0.188886057,"data-quality":0.1246154315}}
{"text":"This paper describes word {segmentation} granularity in Korean language processing.","meta":{"url":"http://arxiv.org/abs/2309.03713v1"},"cats":{"new-dataset":0.0638972633,"dev-research":0.1501512868,"data-quality":0.3269397222}}
{"text":"From a word separated by blank space, which is termed an eojeol, to a sequence of morphemes in Korean, there are multiple possible levels of word segmentation granularity in Korean.","meta":{"url":"http://arxiv.org/abs/2309.03713v1"},"cats":{"new-dataset":0.0924896833,"dev-research":0.1598307511,"data-quality":0.2237670164}}
{"text":"For specific language processing and corpus annotation tasks, several different granularity levels have been proposed and utilized, because the agglutinative languages including Korean language have a one-to-one mapping between functional morpheme and syntactic category.","meta":{"url":"http://arxiv.org/abs/2309.03713v1"},"cats":{"new-dataset":0.0743384497,"dev-research":0.1870162399,"data-quality":0.3421473678}}
{"text":"Thus, we analyze these different granularity levels, presenting the examples of Korean language processing systems for future reference.","meta":{"url":"http://arxiv.org/abs/2309.03713v1"},"cats":{"new-dataset":0.0483309528,"dev-research":0.1653790659,"data-quality":0.2332276526}}
{"text":"Interestingly, the granularity by separating only functional morphemes including case markers and verbal endings, and keeping other suffixes for morphological derivation results in the optimal performance for phrase structure parsing.","meta":{"url":"http://arxiv.org/abs/2309.03713v1"},"cats":{"new-dataset":0.019014964,"dev-research":0.1791247584,"data-quality":0.2362218033}}
{"text":"This contradicts previous best practices for Korean language processing, which has been the de facto standard for various applications that require separating all morphemes.","meta":{"url":"http://arxiv.org/abs/2309.03713v1"},"cats":{"new-dataset":0.0077658938,"dev-research":0.182732855,"data-quality":0.3494333316}}
{"text":"A common setting in multitask reinforcement learning (RL) demands that an agent rapidly adapt to various stationary reward functions randomly sampled from a fixed distribution.","meta":{"url":"http://arxiv.org/abs/2309.03710v1"},"cats":{"new-dataset":0.0504698114,"dev-research":0.0995676765,"data-quality":0.0739325587}}
{"text":"In such situations, the successor representation (SR) is a popular framework which supports rapid policy evaluation by decoupling a policy's expected discounted, cumulative state occupancies from a specific reward function.","meta":{"url":"http://arxiv.org/abs/2309.03710v1"},"cats":{"new-dataset":0.0437595542,"dev-research":0.1511073075,"data-quality":0.0849604699}}
{"text":"However, in the natural world, sequential tasks are rarely independent, and instead reflect shifting priorities based on the availability and subjective perception of rewarding stimuli.","meta":{"url":"http://arxiv.org/abs/2309.03710v1"},"cats":{"new-dataset":0.0133105438,"dev-research":0.1569762413,"data-quality":0.0724613104}}
{"text":"Reflecting this disjunction, in this paper we study the phenomenon of diminishing marginal utility and introduce a novel state representation, the $\\lambda$ representation ($\\lambda$R) which, surprisingly, is required for policy evaluation in this setting and which generalizes the SR as well as several other state representations from the literature.","meta":{"url":"http://arxiv.org/abs/2309.03710v1"},"cats":{"new-dataset":0.0120371334,"dev-research":0.1873061679,"data-quality":0.1224744958}}
{"text":"We establish the $\\lambda$R's formal properties and examine its normative advantages in the context of machine learning, as well as its usefulness for studying natural behaviors, particularly foraging.","meta":{"url":"http://arxiv.org/abs/2309.03710v1"},"cats":{"new-dataset":0.024752771,"dev-research":0.1394753499,"data-quality":0.1013324005}}
{"text":"This paper examines some common problems in Human-Robot Interaction (HRI) causing failures and troubles in Chat.","meta":{"url":"http://arxiv.org/abs/2309.03708v1"},"cats":{"new-dataset":0.1134036072,"dev-research":0.4716991498,"data-quality":0.2445880867}}
{"text":"A given use case's design decisions start with the suitable robot, the suitable chatting model, identifying common problems that cause failures, identifying potential solutions, and planning continuous improvement.","meta":{"url":"http://arxiv.org/abs/2309.03708v1"},"cats":{"new-dataset":0.0855981523,"dev-research":0.4045428347,"data-quality":0.0659974216}}
{"text":"In conclusion, it is recommended to use a closed-loop control algorithm that guides the use of trained Artificial Intelligence (AI) pre-trained models and provides vocabulary filtering, re-train batched models on new datasets, learn online from data streams, and/or use reinforcement learning models to self-update the trained models and reduce errors.","meta":{"url":"http://arxiv.org/abs/2309.03708v1"},"cats":{"new-dataset":0.081405202,"dev-research":0.2552347221,"data-quality":0.1442290981}}
{"text":"Vision algorithm-based robotic arm grasping system is one of the robotic arm systems that can be applied to a wide range of scenarios.","meta":{"url":"http://arxiv.org/abs/2309.03704v1"},"cats":{"new-dataset":0.0210936559,"dev-research":0.1630725509,"data-quality":0.0727461402}}
{"text":"It uses algorithms to automatically identify the location of the target and guide the robotic arm to grasp it, which has more flexible features than the teachable robotic arm grasping system.","meta":{"url":"http://arxiv.org/abs/2309.03704v1"},"cats":{"new-dataset":0.006509252,"dev-research":0.1632157528,"data-quality":0.063576629}}
{"text":"However, for some food packages, their transparent packages or reflective materials bring challenges to the recognition of vision algorithms, and traditional vision algorithms cannot achieve high accuracy for these packages.","meta":{"url":"http://arxiv.org/abs/2309.03704v1"},"cats":{"new-dataset":0.037986501,"dev-research":0.1090407471,"data-quality":0.2235878914}}
{"text":"In addition, in the process of robotic arm grasping, the positioning on the z-axis height still requires manual setting of parameters, which may cause errors.","meta":{"url":"http://arxiv.org/abs/2309.03704v1"},"cats":{"new-dataset":0.004635424,"dev-research":0.2719888351,"data-quality":0.1380744645}}
{"text":"Based on the above two problems, we designed a sorting system for food packaging using deep learning algorithms and structured light 3D reconstruction technology.","meta":{"url":"http://arxiv.org/abs/2309.03704v1"},"cats":{"new-dataset":0.3114378818,"dev-research":0.1506311843,"data-quality":0.1099007957}}
{"text":"Using a pre-trained MASK R-CNN model to recognize the class of the object in the image and get its 2D coordinates, then using structured light 3D reconstruction technique to calculate its 3D coordinates, and finally after the coordinate system conversion to guide the robotic arm for grasping.","meta":{"url":"http://arxiv.org/abs/2309.03704v1"},"cats":{"new-dataset":0.1393022708,"dev-research":0.1466517447,"data-quality":0.0816406}}
{"text":"After testing, it is shown that the method can fully automate the recognition and grasping of different kinds of food packages with high accuracy.","meta":{"url":"http://arxiv.org/abs/2309.03704v1"},"cats":{"new-dataset":0.0831254475,"dev-research":0.1094911416,"data-quality":0.1470011966}}
{"text":"Using this method, it can help food manufacturers to reduce production costs and improve production efficiency.","meta":{"url":"http://arxiv.org/abs/2309.03704v1"},"cats":{"new-dataset":0.0049802266,"dev-research":0.2803099188,"data-quality":0.0863402488}}
{"text":"This paper presents a novel reconstruction method that leverages Diffusion Models to protect machine learning classifiers against adversarial attacks, all without requiring any modifications to the classifiers themselves.","meta":{"url":"http://arxiv.org/abs/2309.03702v1"},"cats":{"new-dataset":0.0195099273,"dev-research":0.1787796416,"data-quality":0.2465887226}}
{"text":"The susceptibility of machine learning models to minor input perturbations renders them vulnerable to adversarial attacks.","meta":{"url":"http://arxiv.org/abs/2309.03702v1"},"cats":{"new-dataset":0.0123407233,"dev-research":0.1962115669,"data-quality":0.3612837814}}
{"text":"While diffusion-based methods are typically disregarded for adversarial defense due to their slow reverse process, this paper demonstrates that our proposed method offers robustness against adversarial threats while preserving clean accuracy, speed, and plug-and-play compatibility.","meta":{"url":"http://arxiv.org/abs/2309.03702v1"},"cats":{"new-dataset":0.014830283,"dev-research":0.2104713363,"data-quality":0.2283979188}}
{"text":"Code at: https://github.com/HondamunigePrasannaSilva/DiffDefence.","meta":{"url":"http://arxiv.org/abs/2309.03702v1"},"cats":{"new-dataset":0.3722744928,"dev-research":0.2749117086,"data-quality":0.1608135722}}
{"text":"Several one-fits-all intervention policies were introduced by the Online Social Networks (OSNs) platforms to mitigate potential harms.","meta":{"url":"http://arxiv.org/abs/2309.03701v1"},"cats":{"new-dataset":0.0257949494,"dev-research":0.2558777275,"data-quality":0.1077191986}}
{"text":"Nevertheless, some studies showed the limited effectiveness of these approaches.","meta":{"url":"http://arxiv.org/abs/2309.03701v1"},"cats":{"new-dataset":0.001883246,"dev-research":0.1971864998,"data-quality":0.0624553881}}
{"text":"An alternative to this would be a user-centered design of intervention policies.","meta":{"url":"http://arxiv.org/abs/2309.03701v1"},"cats":{"new-dataset":0.024328541,"dev-research":0.4197851447,"data-quality":0.0911636608}}
{"text":"In this context, we study the susceptibility of users to undesired behavior in communities on OSNs.","meta":{"url":"http://arxiv.org/abs/2309.03701v1"},"cats":{"new-dataset":0.0387849845,"dev-research":0.3236789004,"data-quality":0.1507312639}}
{"text":"In particular, we explore their reaction to specific events.","meta":{"url":"http://arxiv.org/abs/2309.03701v1"},"cats":{"new-dataset":0.1069824021,"dev-research":0.2318555644,"data-quality":0.088487186}}
{"text":"Our study shows that communities develop different undesired behavior patterns in reaction to specific events.","meta":{"url":"http://arxiv.org/abs/2309.03701v1"},"cats":{"new-dataset":0.0390616852,"dev-research":0.3437216503,"data-quality":0.1427823967}}
{"text":"These events can significantly alter the behavior of the community and invert the dynamics of behavior within the whole network.","meta":{"url":"http://arxiv.org/abs/2309.03701v1"},"cats":{"new-dataset":0.0178059553,"dev-research":0.3131571346,"data-quality":0.1327191922}}
{"text":"Our findings stress out the importance of understanding the reasons behind the changes in users' reactions and highlights the need of fine-tuning the research to the individual's level.","meta":{"url":"http://arxiv.org/abs/2309.03701v1"},"cats":{"new-dataset":0.0264479918,"dev-research":0.4637035642,"data-quality":0.1635745191}}
{"text":"It paves the way towards building better OSNs' intervention strategies centered on the user.","meta":{"url":"http://arxiv.org/abs/2309.03701v1"},"cats":{"new-dataset":0.0080781224,"dev-research":0.2878900823,"data-quality":0.0642447993}}
{"text":"Human Object Interaction (HOI) detection aims to localize and infer the relationships between a human and an object.","meta":{"url":"http://arxiv.org/abs/2309.03696v1"},"cats":{"new-dataset":0.0899387781,"dev-research":0.2918837658,"data-quality":0.1171816081}}
{"text":"Arguably, training supervised models for this task from scratch presents challenges due to the performance drop over rare classes and the high computational cost and time required to handle long-tailed distributions of HOIs in complex HOI scenes in realistic settings.","meta":{"url":"http://arxiv.org/abs/2309.03696v1"},"cats":{"new-dataset":0.3167358554,"dev-research":0.1459445254,"data-quality":0.1359661552}}
{"text":"This observation motivates us to design an HOI detector that can be trained even with long-tailed labeled data and can leverage existing knowledge from pre-trained models.","meta":{"url":"http://arxiv.org/abs/2309.03696v1"},"cats":{"new-dataset":0.1482496845,"dev-research":0.1585298914,"data-quality":0.2157988766}}
{"text":"Inspired by the powerful generalization ability of the large Vision-Language Models (VLM) on classification and retrieval tasks, we propose an efficient Adaptive HOI Detector with Concept-guided Memory (ADA-CM).","meta":{"url":"http://arxiv.org/abs/2309.03696v1"},"cats":{"new-dataset":0.0935220918,"dev-research":0.1936157328,"data-quality":0.2332746857}}
{"text":"ADA-CM has two operating modes.","meta":{"url":"http://arxiv.org/abs/2309.03696v1"},"cats":{"new-dataset":0.0207587313,"dev-research":0.172658857,"data-quality":0.0693603268}}
{"text":"The first mode makes it tunable without learning new parameters in a training-free paradigm.","meta":{"url":"http://arxiv.org/abs/2309.03696v1"},"cats":{"new-dataset":0.003717019,"dev-research":0.0860501781,"data-quality":0.095793612}}
{"text":"Its second mode incorporates an instance-aware adapter mechanism that can further efficiently boost performance if updating a lightweight set of parameters can be afforded.","meta":{"url":"http://arxiv.org/abs/2309.03696v1"},"cats":{"new-dataset":0.00629305,"dev-research":0.1741204554,"data-quality":0.0648007903}}
{"text":"Our proposed method achieves competitive results with state-of-the-art on the HICO-DET and V-COCO datasets with much less training time.","meta":{"url":"http://arxiv.org/abs/2309.03696v1"},"cats":{"new-dataset":0.5905296311,"dev-research":0.1355514123,"data-quality":0.2138437882}}
{"text":"Code can be found at https://github.com/ltttpku/ADA-CM.","meta":{"url":"http://arxiv.org/abs/2309.03696v1"},"cats":{"new-dataset":0.1957705384,"dev-research":0.2141346979,"data-quality":0.1727930074}}
{"text":"Generative AI is on the rise, enabling everyone to produce realistic content via publicly available interfaces.","meta":{"url":"http://arxiv.org/abs/2309.03198v1"},"cats":{"new-dataset":0.0818209173,"dev-research":0.2222318061,"data-quality":0.0849402683}}
{"text":"Especially for guided image generation, diffusion models are changing the creator economy by producing high quality low cost content.","meta":{"url":"http://arxiv.org/abs/2309.03198v1"},"cats":{"new-dataset":0.04374069,"dev-research":0.2032621229,"data-quality":0.0767941941}}
{"text":"In parallel, artists are rising against unruly AI, since their artwork are leveraged, distributed, and dissimulated by large generative models.","meta":{"url":"http://arxiv.org/abs/2309.03198v1"},"cats":{"new-dataset":0.0278827267,"dev-research":0.1858741631,"data-quality":0.1066244228}}
{"text":"Our approach, My Art My Choice (MAMC), aims to empower content owners by protecting their copyrighted materials from being utilized by diffusion models in an adversarial fashion.","meta":{"url":"http://arxiv.org/abs/2309.03198v1"},"cats":{"new-dataset":0.0197651529,"dev-research":0.1384449278,"data-quality":0.1229957044}}
{"text":"MAMC learns to generate adversarially perturbed \"protected\" versions of images which can in turn \"break\" diffusion models.","meta":{"url":"http://arxiv.org/abs/2309.03198v1"},"cats":{"new-dataset":0.0306301019,"dev-research":0.1248112332,"data-quality":0.1887589704}}
{"text":"The perturbation amount is decided by the artist to balance distortion vs. protection of the content.","meta":{"url":"http://arxiv.org/abs/2309.03198v1"},"cats":{"new-dataset":0.0059019312,"dev-research":0.1602844211,"data-quality":0.2195985081}}
{"text":"MAMC is designed with a simple UNet-based generator, attacking black box diffusion models, combining several losses to create adversarial twins of the original artwork.","meta":{"url":"http://arxiv.org/abs/2309.03198v1"},"cats":{"new-dataset":0.0221787406,"dev-research":0.1103180406,"data-quality":0.1118147446}}
{"text":"We experiment on three datasets for various image-to-image tasks, with different user control values.","meta":{"url":"http://arxiv.org/abs/2309.03198v1"},"cats":{"new-dataset":0.5608006027,"dev-research":0.1612362044,"data-quality":0.1004566674}}
{"text":"Both protected image and diffusion output results are evaluated in visual, noise, structure, pixel, and generative spaces to validate our claims.","meta":{"url":"http://arxiv.org/abs/2309.03198v1"},"cats":{"new-dataset":0.0805321079,"dev-research":0.1468565642,"data-quality":0.1597899592}}
{"text":"We believe that MAMC is a crucial step for preserving ownership information for AI generated content in a flawless, based-on-need, and human-centric way.","meta":{"url":"http://arxiv.org/abs/2309.03198v1"},"cats":{"new-dataset":0.1194325195,"dev-research":0.2183372178,"data-quality":0.1675036469}}
{"text":"Graph neural networks (GNNs) have gained an increasing amount of popularity due to their superior capability in learning node embeddings for various graph inference tasks, but training them can raise privacy concerns.","meta":{"url":"http://arxiv.org/abs/2309.03190v1"},"cats":{"new-dataset":0.0631343595,"dev-research":0.1543066661,"data-quality":0.16889455}}
{"text":"To address this, we propose using link local differential privacy over decentralized nodes, enabling collaboration with an untrusted server to train GNNs without revealing the existence of any link.","meta":{"url":"http://arxiv.org/abs/2309.03190v1"},"cats":{"new-dataset":0.0902850338,"dev-research":0.1548592182,"data-quality":0.1431918171}}
{"text":"Our approach spends the privacy budget separately on links and degrees of the graph for the server to better denoise the graph topology using Bayesian estimation, alleviating the negative impact of LDP on the accuracy of the trained GNNs.","meta":{"url":"http://arxiv.org/abs/2309.03190v1"},"cats":{"new-dataset":0.0544792514,"dev-research":0.1566820836,"data-quality":0.1863588904}}
{"text":"We bound the mean absolute error of the inferred link probabilities against the ground truth graph topology.","meta":{"url":"http://arxiv.org/abs/2309.03190v1"},"cats":{"new-dataset":0.0636377711,"dev-research":0.1415665579,"data-quality":0.2259919348}}
{"text":"We then propose two variants of our LDP mechanism complementing each other in different privacy settings, one of which estimates fewer links under lower privacy budgets to avoid false positive link estimates when the uncertainty is high, while the other utilizes more information and performs better given relatively higher privacy budgets.","meta":{"url":"http://arxiv.org/abs/2309.03190v1"},"cats":{"new-dataset":0.0175712644,"dev-research":0.1549959452,"data-quality":0.1602103325}}
{"text":"Furthermore, we propose a hybrid variant that combines both strategies and is able to perform better across different privacy budgets.","meta":{"url":"http://arxiv.org/abs/2309.03190v1"},"cats":{"new-dataset":0.0261775916,"dev-research":0.1772764686,"data-quality":0.0858612253}}
{"text":"Extensive experiments show that our approach outperforms existing methods in terms of accuracy under varying privacy budgets.","meta":{"url":"http://arxiv.org/abs/2309.03190v1"},"cats":{"new-dataset":0.0247375847,"dev-research":0.1823274114,"data-quality":0.2154560893}}
{"text":"Neural Radiance Fields (NeRFs) have shown promise in applications like view synthesis and depth estimation, but learning from multiview images faces inherent uncertainties.","meta":{"url":"http://arxiv.org/abs/2309.03185v1"},"cats":{"new-dataset":0.1031867494,"dev-research":0.1734821362,"data-quality":0.1473110608}}
{"text":"Current methods to quantify them are either heuristic or computationally demanding.","meta":{"url":"http://arxiv.org/abs/2309.03185v1"},"cats":{"new-dataset":0.010120427,"dev-research":0.1958260135,"data-quality":0.1023822311}}
{"text":"We introduce BayesRays, a post-hoc framework to evaluate uncertainty in any pre-trained NeRF without modifying the training process.","meta":{"url":"http://arxiv.org/abs/2309.03185v1"},"cats":{"new-dataset":0.0276664392,"dev-research":0.2918619828,"data-quality":0.2839978513}}
{"text":"Our method establishes a volumetric uncertainty field using spatial perturbations and a Bayesian Laplace approximation.","meta":{"url":"http://arxiv.org/abs/2309.03185v1"},"cats":{"new-dataset":0.0453226022,"dev-research":0.1455456766,"data-quality":0.166193685}}
{"text":"We derive our algorithm statistically and show its superior performance in key metrics and applications.","meta":{"url":"http://arxiv.org/abs/2309.03185v1"},"cats":{"new-dataset":0.1077622947,"dev-research":0.1538861704,"data-quality":0.149330317}}
{"text":"Additional results available at: https://bayesrays.github.io.","meta":{"url":"http://arxiv.org/abs/2309.03185v1"},"cats":{"new-dataset":0.3414286952,"dev-research":0.1210351957,"data-quality":0.1356754916}}
{"text":"Significant strides have been made using large vision-language models, like Stable Diffusion (SD), for a variety of downstream tasks, including image editing, image correspondence, and 3D shape generation.","meta":{"url":"http://arxiv.org/abs/2309.03179v1"},"cats":{"new-dataset":0.0836528257,"dev-research":0.1721830562,"data-quality":0.0977352918}}
{"text":"Inspired by these advancements, we explore leveraging these extensive vision-language models for segmenting images at any desired granularity using as few as one annotated sample by proposing SLiMe.","meta":{"url":"http://arxiv.org/abs/2309.03179v1"},"cats":{"new-dataset":0.2510720641,"dev-research":0.1479606246,"data-quality":0.2604618224}}
{"text":"SLiMe frames this problem as an optimization task.","meta":{"url":"http://arxiv.org/abs/2309.03179v1"},"cats":{"new-dataset":0.063238721,"dev-research":0.1277895943,"data-quality":0.131044264}}
{"text":"Specifically, given a single training image and its segmentation mask, we first extract attention maps, including our novel \"weighted accumulated self-attention map\" from the SD prior.","meta":{"url":"http://arxiv.org/abs/2309.03179v1"},"cats":{"new-dataset":0.1123536295,"dev-research":0.1395278098,"data-quality":0.1398137308}}
{"text":"Then, using the extracted attention maps, the text embeddings of Stable Diffusion are optimized such that, each of them, learn about a single segmented region from the training image.","meta":{"url":"http://arxiv.org/abs/2309.03179v1"},"cats":{"new-dataset":0.0827539721,"dev-research":0.1041348583,"data-quality":0.1915610644}}
{"text":"These learned embeddings then highlight the segmented region in the attention maps, which in turn can then be used to derive the segmentation map.","meta":{"url":"http://arxiv.org/abs/2309.03179v1"},"cats":{"new-dataset":0.16331411,"dev-research":0.1566013379,"data-quality":0.1679854911}}
{"text":"This enables SLiMe to segment any real-world image during inference with the granularity of the segmented region in the training image, using just one example.","meta":{"url":"http://arxiv.org/abs/2309.03179v1"},"cats":{"new-dataset":0.0213499941,"dev-research":0.1441302603,"data-quality":0.1351389415}}
{"text":"Moreover, leveraging additional training data when available, i.e. few-shot, improves the performance of SLiMe.","meta":{"url":"http://arxiv.org/abs/2309.03179v1"},"cats":{"new-dataset":0.0251185646,"dev-research":0.1437964251,"data-quality":0.121092392}}
{"text":"We carried out a knowledge-rich set of experiments examining various design factors and showed that SLiMe outperforms other existing one-shot and few-shot segmentation methods.","meta":{"url":"http://arxiv.org/abs/2309.03179v1"},"cats":{"new-dataset":0.0514003787,"dev-research":0.1294303602,"data-quality":0.1642403295}}
{"text":"Decoder-only Large Language Models (LLMs) have demonstrated potential in machine translation (MT), albeit with performance slightly lagging behind traditional encoder-decoder Neural Machine Translation (NMT) systems.","meta":{"url":"http://arxiv.org/abs/2309.03175v1"},"cats":{"new-dataset":0.049800065,"dev-research":0.0927344342,"data-quality":0.1050346926}}
{"text":"However, LLMs offer a unique advantage: the ability to control the properties of the output through prompts.","meta":{"url":"http://arxiv.org/abs/2309.03175v1"},"cats":{"new-dataset":0.0092125714,"dev-research":0.1545551732,"data-quality":0.0940251537}}
{"text":"In this study, we harness this flexibility to explore LLaMa's capability to produce gender-specific translations for languages with grammatical gender.","meta":{"url":"http://arxiv.org/abs/2309.03175v1"},"cats":{"new-dataset":0.0593526647,"dev-research":0.1789387753,"data-quality":0.143723519}}
{"text":"Our results indicate that LLaMa can generate gender-specific translations with competitive accuracy and gender bias mitigation when compared to NLLB, a state-of-the-art multilingual NMT system.","meta":{"url":"http://arxiv.org/abs/2309.03175v1"},"cats":{"new-dataset":0.0557595429,"dev-research":0.1609541916,"data-quality":0.3029734403}}
{"text":"Furthermore, our experiments reveal that LLaMa's translations are robust, showing significant performance drops when evaluated against opposite-gender references in gender-ambiguous datasets but maintaining consistency in less ambiguous contexts.","meta":{"url":"http://arxiv.org/abs/2309.03175v1"},"cats":{"new-dataset":0.1480589437,"dev-research":0.1613063701,"data-quality":0.3811053207}}
{"text":"This research provides insights into the potential and challenges of using LLMs for gender-specific translations and highlights the importance of in-context learning to elicit new tasks in LLMs.","meta":{"url":"http://arxiv.org/abs/2309.03175v1"},"cats":{"new-dataset":0.0476047565,"dev-research":0.1801264055,"data-quality":0.1658814443}}
{"text":"Fine-grained classification often requires recognizing specific object parts, such as beak shape and wing patterns for birds.","meta":{"url":"http://arxiv.org/abs/2309.03173v1"},"cats":{"new-dataset":0.0375811723,"dev-research":0.1518105321,"data-quality":0.3076118259}}
{"text":"Encouraging a fine-grained classification model to first detect such parts and then using them to infer the class could help us gauge whether the model is indeed looking at the right details better than with interpretability methods that provide a single attribution map.","meta":{"url":"http://arxiv.org/abs/2309.03173v1"},"cats":{"new-dataset":0.0406011701,"dev-research":0.1960317601,"data-quality":0.4871414023}}
{"text":"We propose PDiscoNet to discover object parts by using only image-level class labels along with priors encouraging the parts to be: discriminative, compact, distinct from each other, equivariant to rigid transforms, and active in at least some of the images.","meta":{"url":"http://arxiv.org/abs/2309.03173v1"},"cats":{"new-dataset":0.524325088,"dev-research":0.1117753111,"data-quality":0.2499299876}}
{"text":"In addition to using the appropriate losses to encode these priors, we propose to use part-dropout, where full part feature vectors are dropped at once to prevent a single part from dominating in the classification, and part feature vector modulation, which makes the information coming from each part distinct from the perspective of the classifier.","meta":{"url":"http://arxiv.org/abs/2309.03173v1"},"cats":{"new-dataset":0.0645861406,"dev-research":0.1734432228,"data-quality":0.3287845998}}
{"text":"Our results on CUB, CelebA, and PartImageNet show that the proposed method provides substantially better part discovery performance than previous methods while not requiring any additional hyper-parameter tuning and without penalizing the classification performance.","meta":{"url":"http://arxiv.org/abs/2309.03173v1"},"cats":{"new-dataset":0.1967822155,"dev-research":0.1872223821,"data-quality":0.1923269441}}
{"text":"The code is available at https://github.com/robertdvdk/part_detection.","meta":{"url":"http://arxiv.org/abs/2309.03173v1"},"cats":{"new-dataset":0.3373531273,"dev-research":0.149796761,"data-quality":0.2162687015}}
{"text":"While recommender systems have significantly benefited from implicit feedback, they have often missed the nuances of multi-behavior interactions between users and items.","meta":{"url":"http://arxiv.org/abs/2309.03169v1"},"cats":{"new-dataset":0.0038464165,"dev-research":0.3042006167,"data-quality":0.1938919192}}
{"text":"Historically, these systems either amalgamated all behaviors, such as \\textit{impression} (formerly \\textit{view}), \\textit{add-to-cart}, and \\textit{buy}, under a singular 'interaction' label, or prioritized only the target behavior, often the \\textit{buy} action, discarding valuable auxiliary signals.","meta":{"url":"http://arxiv.org/abs/2309.03169v1"},"cats":{"new-dataset":0.0268417001,"dev-research":0.2029982189,"data-quality":0.1672962907}}
{"text":"Although recent advancements tried addressing this simplification, they primarily gravitated towards optimizing the target behavior alone, battling with data scarcity.","meta":{"url":"http://arxiv.org/abs/2309.03169v1"},"cats":{"new-dataset":0.003853037,"dev-research":0.2304886259,"data-quality":0.1022360883}}
{"text":"Additionally, they tended to bypass the nuanced hierarchy intrinsic to behaviors.","meta":{"url":"http://arxiv.org/abs/2309.03169v1"},"cats":{"new-dataset":0.0029898035,"dev-research":0.1799719391,"data-quality":0.1359121305}}
{"text":"To bridge these gaps, we introduce the \\textbf{H}ierarchical \\textbf{M}ulti-behavior \\textbf{G}raph Attention \\textbf{N}etwork (HMGN).","meta":{"url":"http://arxiv.org/abs/2309.03169v1"},"cats":{"new-dataset":0.0263520685,"dev-research":0.1246708691,"data-quality":0.200245241}}
{"text":"This pioneering framework leverages attention mechanisms to discern information from both inter and intra-behaviors while employing a multi-task Hierarchical Bayesian Personalized Ranking (HBPR) for optimization.","meta":{"url":"http://arxiv.org/abs/2309.03169v1"},"cats":{"new-dataset":0.02231325,"dev-research":0.1757227345,"data-quality":0.1088318353}}
{"text":"Recognizing the need for scalability, our approach integrates a specialized multi-behavior sub-graph sampling technique.","meta":{"url":"http://arxiv.org/abs/2309.03169v1"},"cats":{"new-dataset":0.0815536746,"dev-research":0.1475755162,"data-quality":0.118769048}}
{"text":"Moreover, the adaptability of HMGN allows for the seamless inclusion of knowledge metadata and time-series data.","meta":{"url":"http://arxiv.org/abs/2309.03169v1"},"cats":{"new-dataset":0.1245807722,"dev-research":0.1912188569,"data-quality":0.1061745793}}
{"text":"Empirical results attest to our model's prowess, registering a notable performance boost of up to 64\\% in NDCG@100 metrics over conventional graph neural network methods.","meta":{"url":"http://arxiv.org/abs/2309.03169v1"},"cats":{"new-dataset":0.0301535152,"dev-research":0.1565563389,"data-quality":0.2257566216}}
{"text":"Containerized services deployed within various computing systems, such as edge and cloud, desire live migration support to enable user mobility, elasticity, and load balancing.","meta":{"url":"http://arxiv.org/abs/2309.03168v1"},"cats":{"new-dataset":0.0283177217,"dev-research":0.1543327946,"data-quality":0.0535939427}}
{"text":"To enable such a ubiquitous and efficient service migration, a live migration solution needs to handle circumstances where users have various authority levels (full control, limited control, or no control) over the underlying computing systems.","meta":{"url":"http://arxiv.org/abs/2309.03168v1"},"cats":{"new-dataset":0.0374641702,"dev-research":0.3308864448,"data-quality":0.0559250895}}
{"text":"Supporting the live migration at these levels serves as the cornerstone of interoperability, and can unlock several use cases across various forms of distributed systems.","meta":{"url":"http://arxiv.org/abs/2309.03168v1"},"cats":{"new-dataset":0.0446371484,"dev-research":0.2922073839,"data-quality":0.0632253694}}
{"text":"As such, in this study, we develop a ubiquitous migration solution (called UMS) that, for a given containerized service, can automatically identify the feasible migration approach, and then seamlessly perform the migration across autonomous computing systems.","meta":{"url":"http://arxiv.org/abs/2309.03168v1"},"cats":{"new-dataset":0.0419941061,"dev-research":0.2121704663,"data-quality":0.1030641552}}
{"text":"UMS does not interfere with the way the orchestrator handles containers and can coordinate the migration without the orchestrator involvement.","meta":{"url":"http://arxiv.org/abs/2309.03168v1"},"cats":{"new-dataset":0.0038168424,"dev-research":0.1506077818,"data-quality":0.1573825259}}
{"text":"Moreover, UMS is orchestrator-agnostic, i.e., it can be plugged into any underlying orchestrator platform.","meta":{"url":"http://arxiv.org/abs/2309.03168v1"},"cats":{"new-dataset":0.0120758252,"dev-research":0.1834889746,"data-quality":0.0858030575}}
{"text":"UMS is equipped with novel methods that can coordinate and perform the live migration at the orchestrator, container, and service levels.","meta":{"url":"http://arxiv.org/abs/2309.03168v1"},"cats":{"new-dataset":0.0241731922,"dev-research":0.2120105286,"data-quality":0.0913517053}}
{"text":"Experimental results show that for single-process containers, the service-level approach, and for multi-process containers with small (< 128 MiB) memory footprint, the container-level migration approach lead to the lowest migration overhead and service downtime.","meta":{"url":"http://arxiv.org/abs/2309.03168v1"},"cats":{"new-dataset":0.0296398461,"dev-research":0.1648716384,"data-quality":0.0799881062}}
{"text":"To demonstrate the potential of UMS in realizing interoperability and multi-cloud scenarios, we examined it to perform live service migration across heterogeneous orchestrators, and between Microsoft Azure and Google Cloud","meta":{"url":"http://arxiv.org/abs/2309.03168v1"},"cats":{"new-dataset":0.0293354799,"dev-research":0.184845289,"data-quality":0.0778207693}}
{"text":"The calibration and training of a neural network is a complex and time-consuming procedure that requires significant computational resources to achieve satisfactory results.","meta":{"url":"http://arxiv.org/abs/2309.03167v1"},"cats":{"new-dataset":0.0478561773,"dev-research":0.1966004119,"data-quality":0.1607935203}}
{"text":"Key obstacles are a large number of hyperparameters to select and the onset of overfitting in the face of a small amount of data.","meta":{"url":"http://arxiv.org/abs/2309.03167v1"},"cats":{"new-dataset":0.0311924441,"dev-research":0.216595826,"data-quality":0.125619391}}
{"text":"In this framework, we propose an innovative training strategy for feed-forward architectures - called split-boost - that improves performance and automatically includes a regularizing behaviour without modeling it explicitly.","meta":{"url":"http://arxiv.org/abs/2309.03167v1"},"cats":{"new-dataset":0.0162899732,"dev-research":0.1532654969,"data-quality":0.1918526175}}
{"text":"Such a novel approach ultimately allows us to avoid explicitly modeling the regularization term, decreasing the total number of hyperparameters and speeding up the tuning phase.","meta":{"url":"http://arxiv.org/abs/2309.03167v1"},"cats":{"new-dataset":0.0024815539,"dev-research":0.1219651501,"data-quality":0.1868376493}}
{"text":"The proposed strategy is tested on a real-world (anonymized) dataset within a benchmark medical insurance design problem.","meta":{"url":"http://arxiv.org/abs/2309.03167v1"},"cats":{"new-dataset":0.3625096198,"dev-research":0.1514345217,"data-quality":0.1375599046}}
{"text":"The rapid proliferation of AI-generated text online is profoundly reshaping the information landscape.","meta":{"url":"http://arxiv.org/abs/2309.03164v1"},"cats":{"new-dataset":0.0671650355,"dev-research":0.2850242292,"data-quality":0.133843364}}
{"text":"Among various types of AI-generated text, AI-generated news presents a significant threat as it can be a prominent source of misinformation online.","meta":{"url":"http://arxiv.org/abs/2309.03164v1"},"cats":{"new-dataset":0.0632140011,"dev-research":0.312568865,"data-quality":0.3490930133}}
{"text":"While several recent efforts have focused on detecting AI-generated text in general, these methods require enhanced reliability, given concerns about their vulnerability to simple adversarial attacks.","meta":{"url":"http://arxiv.org/abs/2309.03164v1"},"cats":{"new-dataset":0.0274187391,"dev-research":0.1971576251,"data-quality":0.5140946935}}
{"text":"Furthermore, due to the eccentricities of news writing, applying these detection methods for AI-generated news can produce false positives, potentially damaging the reputation of news organizations.","meta":{"url":"http://arxiv.org/abs/2309.03164v1"},"cats":{"new-dataset":0.0216495487,"dev-research":0.2202191455,"data-quality":0.4143983909}}
{"text":"To address these challenges, we leverage the expertise of an interdisciplinary team to develop a framework, J-Guard, capable of steering existing supervised AI text detectors for detecting AI-generated news while boosting adversarial robustness.","meta":{"url":"http://arxiv.org/abs/2309.03164v1"},"cats":{"new-dataset":0.1726031772,"dev-research":0.1908697509,"data-quality":0.3712380252}}
{"text":"By incorporating stylistic cues inspired by the unique journalistic attributes, J-Guard effectively distinguishes between real-world journalism and AI-generated news articles.","meta":{"url":"http://arxiv.org/abs/2309.03164v1"},"cats":{"new-dataset":0.0269104723,"dev-research":0.2041524623,"data-quality":0.1556270584}}
{"text":"Our experiments on news articles generated by a vast array of AI models, including ChatGPT (GPT3.5), demonstrate the effectiveness of J-Guard in enhancing detection capabilities while maintaining an average performance decrease of as low as 7% when faced with adversarial attacks.","meta":{"url":"http://arxiv.org/abs/2309.03164v1"},"cats":{"new-dataset":0.0358363216,"dev-research":0.1829618816,"data-quality":0.1700105467}}
{"text":"Given a set $P$ of $n$ points and a set $S$ of $m$ disks in the plane, the disk coverage problem asks for a smallest subset of disks that together cover all points of $P$. The problem is NP-hard.","meta":{"url":"http://arxiv.org/abs/2309.03162v1"},"cats":{"new-dataset":0.1209611187,"dev-research":0.1960861461,"data-quality":0.1341678331}}
{"text":"In this paper, we consider a line-separable unit-disk version of the problem where all disks have the same radius and their centers are separated from the points of $P$ by a line $\\ell$. We present an $m^{2/3}n^{2/3}2^{O(\\log^*(m+n))}","meta":{"url":"http://arxiv.org/abs/2309.03162v1"},"cats":{"new-dataset":0.1121921131,"dev-research":0.1535542002,"data-quality":0.1677579521}}
{"text":"+ O((n+m)\\log (n+m))$ time algorithm for the problem.","meta":{"url":"http://arxiv.org/abs/2309.03162v1"},"cats":{"new-dataset":0.0760927142,"dev-research":0.1478591415,"data-quality":0.0747880929}}
{"text":"This improves the previously best result of $O(nm+ n\\log n)$ time.","meta":{"url":"http://arxiv.org/abs/2309.03162v1"},"cats":{"new-dataset":0.0198273981,"dev-research":0.1553957548,"data-quality":0.0944633206}}
{"text":"Our techniques also solve the line-constrained version of the problem, where centers of all disks of $S$ are located on a line $\\ell$ while points of $P$ can be anywhere in the plane.","meta":{"url":"http://arxiv.org/abs/2309.03162v1"},"cats":{"new-dataset":0.1003007136,"dev-research":0.1347746028,"data-quality":0.1416129623}}
{"text":"Our algorithm runs in $O(m\\sqrt{n} + (n+m)\\log(n+m))$ time, which improves the previously best result of $O(nm\\log(m+n))$ time.","meta":{"url":"http://arxiv.org/abs/2309.03162v1"},"cats":{"new-dataset":0.0264746231,"dev-research":0.1364338693,"data-quality":0.0905954622}}
{"text":"In addition, our results lead to an algorithm of $n^{10/3}2^{O(\\log^*n)}$ time for a half-plane coverage problem (given $n$ half-planes and $n$ points, find a smallest subset of half-planes covering all points); this improves the previously best algorithm of $O(n^4\\log n)$ time.","meta":{"url":"http://arxiv.org/abs/2309.03162v1"},"cats":{"new-dataset":0.1355922554,"dev-research":0.1811863848,"data-quality":0.1052690478}}
{"text":"Further, if all half-planes are lower ones, our algorithm runs in $n^{4/3}2^{O(\\log^*n)}$ time while the previously best algorithm takes $O(n^2\\log","meta":{"url":"http://arxiv.org/abs/2309.03162v1"},"cats":{"new-dataset":0.020158369,"dev-research":0.1286594391,"data-quality":0.0788460011}}
{"text":"n)$ time.","meta":{"url":"http://arxiv.org/abs/2309.03162v1"},"cats":{"new-dataset":0.204923504,"dev-research":0.2482971646,"data-quality":0.1134241822}}
{"text":"Neural fields, a category of neural networks trained to represent high-frequency signals, have gained significant attention in recent years due to their impressive performance in modeling complex 3D data, especially large neural signed distance (SDFs) or radiance fields (NeRFs) via a single multi-layer perceptron (MLP).","meta":{"url":"http://arxiv.org/abs/2309.03160v1"},"cats":{"new-dataset":0.2154401541,"dev-research":0.1425171497,"data-quality":0.0951765621}}
{"text":"However, despite the power and simplicity of representing signals with an MLP, these methods still face challenges when modeling large and complex temporal signals due to the limited capacity of MLPs.","meta":{"url":"http://arxiv.org/abs/2309.03160v1"},"cats":{"new-dataset":0.0289585249,"dev-research":0.1512076282,"data-quality":0.0841681336}}
{"text":"In this paper, we propose an effective approach to address this limitation by incorporating temporal residual layers into neural fields, dubbed ResFields, a novel class of networks specifically designed to effectively represent complex temporal signals.","meta":{"url":"http://arxiv.org/abs/2309.03160v1"},"cats":{"new-dataset":0.2080547579,"dev-research":0.2062899441,"data-quality":0.0996278908}}
{"text":"We conduct a comprehensive analysis of the properties of ResFields and propose a matrix factorization technique to reduce the number of trainable parameters and enhance generalization capabilities.","meta":{"url":"http://arxiv.org/abs/2309.03160v1"},"cats":{"new-dataset":0.0435576874,"dev-research":0.129611654,"data-quality":0.0909210899}}
{"text":"Importantly, our formulation seamlessly integrates with existing techniques and consistently improves results across various challenging tasks: 2D video approximation, dynamic shape modeling via temporal SDFs, and dynamic NeRF reconstruction.","meta":{"url":"http://arxiv.org/abs/2309.03160v1"},"cats":{"new-dataset":0.1771177705,"dev-research":0.2429071166,"data-quality":0.0934470659}}
{"text":"Lastly, we demonstrate the practical utility of ResFields by showcasing its effectiveness in capturing dynamic 3D scenes from sparse sensory inputs of a lightweight capture system.","meta":{"url":"http://arxiv.org/abs/2309.03160v1"},"cats":{"new-dataset":0.142207422,"dev-research":0.1631386042,"data-quality":0.0858354793}}
{"text":"Coverage path planning (CPP) is a critical problem in robotics, where the goal is to find an efficient path that covers every point in an area of interest.","meta":{"url":"http://arxiv.org/abs/2309.03157v1"},"cats":{"new-dataset":0.0387948111,"dev-research":0.2864475842,"data-quality":0.0611717618}}
{"text":"This work addresses the power-constrained CPP problem with recharge for battery-limited unmanned aerial vehicles (UAVs).","meta":{"url":"http://arxiv.org/abs/2309.03157v1"},"cats":{"new-dataset":0.0223622252,"dev-research":0.2237146395,"data-quality":0.0803145344}}
{"text":"In this problem, a notable challenge emerges from integrating recharge journeys into the overall coverage strategy, highlighting the intricate task of making strategic, long-term decisions.","meta":{"url":"http://arxiv.org/abs/2309.03157v1"},"cats":{"new-dataset":0.0576520719,"dev-research":0.2073281135,"data-quality":0.0583323129}}
{"text":"We propose a novel proximal policy optimization (PPO)-based deep reinforcement learning (DRL) approach with map-based observations, utilizing action masking and discount factor scheduling to optimize coverage trajectories over the entire mission horizon.","meta":{"url":"http://arxiv.org/abs/2309.03157v1"},"cats":{"new-dataset":0.2230510852,"dev-research":0.1772386407,"data-quality":0.0605329985}}
{"text":"We further provide the agent with a position history to handle emergent state loops caused by the recharge capability.","meta":{"url":"http://arxiv.org/abs/2309.03157v1"},"cats":{"new-dataset":0.0961858039,"dev-research":0.1429832464,"data-quality":0.0559273221}}
{"text":"Our approach outperforms a baseline heuristic, generalizes to different target zones and maps, with limited generalization to unseen maps.","meta":{"url":"http://arxiv.org/abs/2309.03157v1"},"cats":{"new-dataset":0.0669957579,"dev-research":0.1756667611,"data-quality":0.1039597359}}
{"text":"We offer valuable insights into DRL algorithm design for long-horizon problems and provide a publicly available software framework for the CPP problem.","meta":{"url":"http://arxiv.org/abs/2309.03157v1"},"cats":{"new-dataset":0.1083032396,"dev-research":0.2561230584,"data-quality":0.1004772516}}
{"text":"In this work, a novel data-driven methodology for designing polar codes for channels with and without memory is proposed.","meta":{"url":"http://arxiv.org/abs/2309.03148v1"},"cats":{"new-dataset":0.095094882,"dev-research":0.2390194171,"data-quality":0.0899262879}}
{"text":"The methodology is suitable for the case where the channel is given as a \"black-box\" and the designer has access to the channel for generating observations of its inputs and outputs, but does not have access to the explicit channel model.","meta":{"url":"http://arxiv.org/abs/2309.03148v1"},"cats":{"new-dataset":0.0115904307,"dev-research":0.204935008,"data-quality":0.1161993697}}
{"text":"The proposed method leverages the structure of the successive cancellation (SC) decoder to devise a neural SC (NSC) decoder.","meta":{"url":"http://arxiv.org/abs/2309.03148v1"},"cats":{"new-dataset":0.0135143302,"dev-research":0.1531965082,"data-quality":0.1768999146}}
{"text":"The NSC decoder uses neural networks (NNs) to replace the core elements of the original SC decoder, the check-node, the bit-node and the soft decision.","meta":{"url":"http://arxiv.org/abs/2309.03148v1"},"cats":{"new-dataset":0.0374898343,"dev-research":0.1996250305,"data-quality":0.1494827407}}
{"text":"Along with the NSC, we devise additional NN that embeds the channel outputs into the input space of the SC decoder.","meta":{"url":"http://arxiv.org/abs/2309.03148v1"},"cats":{"new-dataset":0.0321326512,"dev-research":0.1334852219,"data-quality":0.1316698143}}
{"text":"The proposed method is supported by theoretical guarantees that include the consistency of the NSC.","meta":{"url":"http://arxiv.org/abs/2309.03148v1"},"cats":{"new-dataset":0.0036918181,"dev-research":0.1641680217,"data-quality":0.187564903}}
{"text":"Also, the NSC has computational complexity that does not grow with the channel memory size.","meta":{"url":"http://arxiv.org/abs/2309.03148v1"},"cats":{"new-dataset":0.009273071,"dev-research":0.1594696383,"data-quality":0.0799540087}}
{"text":"This sets its main advantage over successive cancellation trellis (SCT) decoder for finite state channels (FSCs) that has complexity of $O(|\\mathcal{S}|^3 N\\log N)$, where $|\\mathcal{S}|$ denotes the number of channel states.","meta":{"url":"http://arxiv.org/abs/2309.03148v1"},"cats":{"new-dataset":0.0183894694,"dev-research":0.1183118967,"data-quality":0.0592867201}}
{"text":"We demonstrate the performance of the proposed algorithms on memoryless channels and on channels with memory.","meta":{"url":"http://arxiv.org/abs/2309.03148v1"},"cats":{"new-dataset":0.0256651875,"dev-research":0.1199271865,"data-quality":0.1039509023}}
{"text":"The empirical results are compared with the optimal polar decoder, given by the SC and SCT decoders.","meta":{"url":"http://arxiv.org/abs/2309.03148v1"},"cats":{"new-dataset":0.0346968011,"dev-research":0.1183238796,"data-quality":0.112009462}}
{"text":"We further show that our algorithms are applicable for the case where there SC and SCT decoders are not applicable.","meta":{"url":"http://arxiv.org/abs/2309.03148v1"},"cats":{"new-dataset":0.0467461548,"dev-research":0.1008327917,"data-quality":0.1654583573}}
{"text":"We give a near-optimal sample-pass trade-off for pure exploration in multi-armed bandits (MABs) via multi-pass streaming algorithms: any streaming algorithm with sublinear memory that uses the optimal sample complexity of $O(\\frac{n}{\\Delta^2})$ requires $\\Omega(\\frac{\\log{(1/\\Delta)}}{\\log\\log{(1/\\Delta)}})$ passes.","meta":{"url":"http://arxiv.org/abs/2309.03145v1"},"cats":{"new-dataset":0.0503699814,"dev-research":0.1098222325,"data-quality":0.0721215115}}
{"text":"Here, $n$ is the number of arms and $\\Delta$ is the reward gap between the best and the second-best arms.","meta":{"url":"http://arxiv.org/abs/2309.03145v1"},"cats":{"new-dataset":0.0334854472,"dev-research":0.1578701649,"data-quality":0.1159966706}}
{"text":"Our result matches the $O(\\log(\\frac{1}{\\Delta}))$-pass algorithm of Jin et al.","meta":{"url":"http://arxiv.org/abs/2309.03145v1"},"cats":{"new-dataset":0.0724321856,"dev-research":0.0966469962,"data-quality":0.1876638733}}
{"text":"[ICML'21] (up to lower order terms) that only uses $O(1)$ memory and answers an open question posed by Assadi and Wang","meta":{"url":"http://arxiv.org/abs/2309.03145v1"},"cats":{"new-dataset":0.1125490566,"dev-research":0.115683009,"data-quality":0.1066089623}}
{"text":"[STOC'20].","meta":{"url":"http://arxiv.org/abs/2309.03145v1"},"cats":{"new-dataset":0.1257647845,"dev-research":0.1651732584,"data-quality":0.1343766246}}
{"text":"We present a natural extension to E(n)-equivariant graph neural networks that uses multiple equivariant vectors per node.","meta":{"url":"http://arxiv.org/abs/2309.03139v1"},"cats":{"new-dataset":0.0771285477,"dev-research":0.1272430535,"data-quality":0.1696266272}}
{"text":"We formulate the extension and show that it improves performance across different physical systems benchmark tasks, with minimal differences in runtime or number of parameters.","meta":{"url":"http://arxiv.org/abs/2309.03139v1"},"cats":{"new-dataset":0.0166322796,"dev-research":0.2152480355,"data-quality":0.064820958}}
{"text":"The proposed multichannel EGNN outperforms the standard singlechannel EGNN on N-body charged particle dynamics, molecular property predictions, and predicting the trajectories of solar system bodies.","meta":{"url":"http://arxiv.org/abs/2309.03139v1"},"cats":{"new-dataset":0.0425958966,"dev-research":0.1167492174,"data-quality":0.0949378125}}
{"text":"Given the additional benefits and minimal additional cost of multi-channel EGNN, we suggest that this extension may be of practical use to researchers working in machine learning for the physical sciences","meta":{"url":"http://arxiv.org/abs/2309.03139v1"},"cats":{"new-dataset":0.0111300834,"dev-research":0.1283822712,"data-quality":0.0742478194}}
{"text":"Human dexterity is a hallmark of motor control.","meta":{"url":"http://arxiv.org/abs/2309.03130v1"},"cats":{"new-dataset":0.0243255738,"dev-research":0.2739238548,"data-quality":0.0535609626}}
{"text":"Our hands can rapidly synthesize new behaviors despite the complexity (multi-articular and multi-joints, with 23 joints controlled by more than 40 muscles) of musculoskeletal sensory-motor circuits.","meta":{"url":"http://arxiv.org/abs/2309.03130v1"},"cats":{"new-dataset":0.0905054186,"dev-research":0.2098115799,"data-quality":0.044164579}}
{"text":"In this work, we take inspiration from how human dexterity builds on a diversity of prior experiences, instead of being acquired through a single task.","meta":{"url":"http://arxiv.org/abs/2309.03130v1"},"cats":{"new-dataset":0.0251611615,"dev-research":0.2340579525,"data-quality":0.062207904}}
{"text":"Motivated by this observation, we set out to develop agents that can build upon their previous experience to quickly acquire new (previously unattainable) behaviors.","meta":{"url":"http://arxiv.org/abs/2309.03130v1"},"cats":{"new-dataset":0.0466981047,"dev-research":0.2664869272,"data-quality":0.062431263}}
{"text":"Specifically, our approach leverages multi-task learning to implicitly capture task-agnostic behavioral priors (MyoDex) for human-like dexterity, using a physiologically realistic human hand model - MyoHand.","meta":{"url":"http://arxiv.org/abs/2309.03130v1"},"cats":{"new-dataset":0.0867286312,"dev-research":0.1526954987,"data-quality":0.063512793}}
{"text":"We demonstrate MyoDex's effectiveness in few-shot generalization as well as positive transfer to a large repertoire of unseen dexterous manipulation tasks.","meta":{"url":"http://arxiv.org/abs/2309.03130v1"},"cats":{"new-dataset":0.0232279213,"dev-research":0.1825558766,"data-quality":0.0738960788}}
{"text":"Agents leveraging MyoDex can solve approximately 3x more tasks, and 4x faster in comparison to a distillation baseline.","meta":{"url":"http://arxiv.org/abs/2309.03130v1"},"cats":{"new-dataset":0.0073029719,"dev-research":0.2206667527,"data-quality":0.0615042995}}
{"text":"While prior work has synthesized single musculoskeletal control behaviors, MyoDex is the first generalizable manipulation prior that catalyzes the learning of dexterous physiological control across a large variety of contact-rich behaviors.","meta":{"url":"http://arxiv.org/abs/2309.03130v1"},"cats":{"new-dataset":0.0424839026,"dev-research":0.2611344145,"data-quality":0.04133666}}
{"text":"We also demonstrate the effectiveness of our paradigms beyond musculoskeletal control towards the acquisition of dexterity in 24 DoF Adroit Hand.","meta":{"url":"http://arxiv.org/abs/2309.03130v1"},"cats":{"new-dataset":0.0672776426,"dev-research":0.1821243074,"data-quality":0.0459408423}}
{"text":"Website: https://sites.google.com/view/myodex","meta":{"url":"http://arxiv.org/abs/2309.03130v1"},"cats":{"new-dataset":0.4855395772,"dev-research":0.1985847742,"data-quality":0.1070209564}}
{"text":"The most prevalent smart card-based payment method, EMV, currently offers no privacy to its users.","meta":{"url":"http://arxiv.org/abs/2309.03128v1"},"cats":{"new-dataset":0.0151055691,"dev-research":0.1546604872,"data-quality":0.1163952612}}
{"text":"Transaction details and the card number are sent in cleartext, enabling the profiling and tracking of cardholders.","meta":{"url":"http://arxiv.org/abs/2309.03128v1"},"cats":{"new-dataset":0.0787106281,"dev-research":0.1746320126,"data-quality":0.2111166579}}
{"text":"Since public awareness of privacy issues is growing and legislation, such as GDPR, is emerging, we believe it is necessary to investigate the possibility of making payments anonymous and unlinkable without compromising essential security guarantees and functional properties of EMV.","meta":{"url":"http://arxiv.org/abs/2309.03128v1"},"cats":{"new-dataset":0.0455980454,"dev-research":0.1481245303,"data-quality":0.1416269119}}
{"text":"This paper draws attention to trade-offs between functional and privacy requirements in the design of such a protocol.","meta":{"url":"http://arxiv.org/abs/2309.03128v1"},"cats":{"new-dataset":0.0290288694,"dev-research":0.1751523392,"data-quality":0.0699484077}}
{"text":"We present the UTX protocol - an enhanced payment protocol satisfying such requirements, and we formally certify key security and privacy properties using techniques based on the applied pi-calculus.","meta":{"url":"http://arxiv.org/abs/2309.03128v1"},"cats":{"new-dataset":0.101651564,"dev-research":0.1484117822,"data-quality":0.0816074958}}
{"text":"Reward models (RMs) are crucial in aligning large language models (LLMs) with human preferences for improving interaction quality.","meta":{"url":"http://arxiv.org/abs/2309.03126v1"},"cats":{"new-dataset":0.0400851294,"dev-research":0.1521335139,"data-quality":0.1661017856}}
{"text":"However, the real world is pluralistic, which leads to diversified human preferences based on different religions, politics, cultures, etc.","meta":{"url":"http://arxiv.org/abs/2309.03126v1"},"cats":{"new-dataset":0.0516135297,"dev-research":0.1675849054,"data-quality":0.0933767442}}
{"text":"Moreover, each individual can have their own unique preferences on various topics.","meta":{"url":"http://arxiv.org/abs/2309.03126v1"},"cats":{"new-dataset":0.0156048656,"dev-research":0.1927839966,"data-quality":0.08105192}}
{"text":"Neglecting the diversity of human preferences, current LLM training processes only use a general reward model, which is below satisfaction for customized or personalized application scenarios.","meta":{"url":"http://arxiv.org/abs/2309.03126v1"},"cats":{"new-dataset":0.0062654465,"dev-research":0.1232727179,"data-quality":0.0879564963}}
{"text":"To explore customized preference learning, we collect a domain-specific preference (DSP) dataset, which collects preferred responses to each given query from four practical domains.","meta":{"url":"http://arxiv.org/abs/2309.03126v1"},"cats":{"new-dataset":0.1990967121,"dev-research":0.1655619314,"data-quality":0.107295285}}
{"text":"Besides, from the perspective of data efficiency, we proposed a three-stage customized RM learning scheme, whose effectiveness is empirically verified on both general preference datasets and our DSP set.","meta":{"url":"http://arxiv.org/abs/2309.03126v1"},"cats":{"new-dataset":0.0689576853,"dev-research":0.1473901887,"data-quality":0.1875090973}}
{"text":"Furthermore, we test multiple training and data strategies on the three learning stages, and have found several ways to better preserve the general preferring ability while training the customized RMs, especially general preference enrichment and customized preference imitation learning.","meta":{"url":"http://arxiv.org/abs/2309.03126v1"},"cats":{"new-dataset":0.0116145241,"dev-research":0.1149679276,"data-quality":0.0745844934}}
{"text":"The DSP dataset and code are available at https://github.com/Linear95/DSP.","meta":{"url":"http://arxiv.org/abs/2309.03126v1"},"cats":{"new-dataset":0.8249601097,"dev-research":0.1712405256,"data-quality":0.0929528744}}
{"text":"Large language models (LLMs), such as ChatGPT and GPT-4, are versatile and can solve different tasks due to their emergent ability and generalizability.","meta":{"url":"http://arxiv.org/abs/2309.03118v1"},"cats":{"new-dataset":0.0752003173,"dev-research":0.1314638636,"data-quality":0.0781402158}}
{"text":"However, LLMs sometimes lack domain-specific knowledge to perform tasks, which would also cause hallucination during inference.","meta":{"url":"http://arxiv.org/abs/2309.03118v1"},"cats":{"new-dataset":0.0031782456,"dev-research":0.1726718224,"data-quality":0.1449116516}}
{"text":"In some previous works, additional modules like graph neural networks (GNNs) are trained on retrieved knowledge from external knowledge bases, aiming to mitigate the problem of lacking domain-specific knowledge.","meta":{"url":"http://arxiv.org/abs/2309.03118v1"},"cats":{"new-dataset":0.0843481828,"dev-research":0.2093914279,"data-quality":0.1445094488}}
{"text":"However, incorporating additional modules: 1) would need retraining additional modules when encountering novel domains; 2) would become a bottleneck since LLMs' strong abilities are not fully utilized for retrieval.","meta":{"url":"http://arxiv.org/abs/2309.03118v1"},"cats":{"new-dataset":0.0086257354,"dev-research":0.1213301278,"data-quality":0.092344483}}
{"text":"In this paper, we propose a paradigm, termed Knowledge Solver (KSL), to teach LLMs to search for essential knowledge from external knowledge bases by harnessing their own strong generalizability.","meta":{"url":"http://arxiv.org/abs/2309.03118v1"},"cats":{"new-dataset":0.1261309323,"dev-research":0.1981803162,"data-quality":0.0907507014}}
{"text":"Specifically, we design a simple yet effective prompt to transform retrieval into a multi-hop decision sequence, which empowers LLMs with searching knowledge ability in zero-shot manner.","meta":{"url":"http://arxiv.org/abs/2309.03118v1"},"cats":{"new-dataset":0.0268045341,"dev-research":0.0846242651,"data-quality":0.0914169898}}
{"text":"Additionally, KSL is able to provide complete retrieval paths and therefore increase explainability of LLMs' reasoning processes.","meta":{"url":"http://arxiv.org/abs/2309.03118v1"},"cats":{"new-dataset":0.0352150614,"dev-research":0.2179207247,"data-quality":0.0877422612}}
{"text":"We conduct experiments on three datasets: CommonsenseQA, OpenbookQA, and MedQA-USMLE, and found that our approach improves LLM baseline performance by a relatively large margin.","meta":{"url":"http://arxiv.org/abs/2309.03118v1"},"cats":{"new-dataset":0.2399547978,"dev-research":0.1090540472,"data-quality":0.1540883558}}
{"text":"Automated detection of defects in Printed Circuit Board (PCB) manufacturing using Solder Paste Inspection (SPI) and Automated Optical Inspection (AOI) machines can help improve operational efficiency and significantly reduce the need for manual intervention.","meta":{"url":"http://arxiv.org/abs/2309.03113v1"},"cats":{"new-dataset":0.051358797,"dev-research":0.3658953403,"data-quality":0.2653428595}}
{"text":"In this paper, using SPI-extracted features of 6 million pins, we demonstrate a data-centric approach to train Machine Learning (ML) models to detect PCB defects at three stages of PCB manufacturing.","meta":{"url":"http://arxiv.org/abs/2309.03113v1"},"cats":{"new-dataset":0.2579769647,"dev-research":0.2927364072,"data-quality":0.2986651981}}
{"text":"The 6 million PCB pins correspond to 2 million components that belong to 15,387 PCBs.","meta":{"url":"http://arxiv.org/abs/2309.03113v1"},"cats":{"new-dataset":0.5770415743,"dev-research":0.1771099227,"data-quality":0.101789355}}
{"text":"Using a base extreme gradient boosting (XGBoost) ML model, we iterate on the data pre-processing step to improve detection performance.","meta":{"url":"http://arxiv.org/abs/2309.03113v1"},"cats":{"new-dataset":0.102688958,"dev-research":0.1562066062,"data-quality":0.2069708792}}
{"text":"Combining pin-level SPI features using component and PCB IDs, we developed training instances also at the component and PCB level.","meta":{"url":"http://arxiv.org/abs/2309.03113v1"},"cats":{"new-dataset":0.110226719,"dev-research":0.2013289139,"data-quality":0.1223073228}}
{"text":"This allows the ML model to capture any inter-pin, inter-component, or spatial effects that may not be apparent at the pin level.","meta":{"url":"http://arxiv.org/abs/2309.03113v1"},"cats":{"new-dataset":0.0075763027,"dev-research":0.1465120094,"data-quality":0.1099956247}}
{"text":"Models are trained at the pin, component, and PCB levels, and the detection results from the different models are combined to identify defective components.","meta":{"url":"http://arxiv.org/abs/2309.03113v1"},"cats":{"new-dataset":0.0216973441,"dev-research":0.2493900404,"data-quality":0.3509193912}}
{"text":"A key challenge to ensuring the rapid transition of robotic systems from the industrial sector to more ubiquitous applications is the development of algorithms that can guarantee safe operation while in close proximity to humans.","meta":{"url":"http://arxiv.org/abs/2309.03111v1"},"cats":{"new-dataset":0.043515452,"dev-research":0.2538703766,"data-quality":0.0584445252}}
{"text":"Motion planning and control methods, for instance, must be able to certify safety while operating in real-time in arbitrary environments and in the presence of model uncertainty.","meta":{"url":"http://arxiv.org/abs/2309.03111v1"},"cats":{"new-dataset":0.0181963649,"dev-research":0.3567928867,"data-quality":0.0646911551}}
{"text":"This paper proposes Wrench Analysis for Inertial Transport using Reachability (WAITR), a certifiably safe motion planning and control framework for serial link manipulators that manipulate unsecured objects in arbitrary environments.","meta":{"url":"http://arxiv.org/abs/2309.03111v1"},"cats":{"new-dataset":0.141953316,"dev-research":0.2390433857,"data-quality":0.0471747067}}
{"text":"WAITR uses reachability analysis to construct over-approximations of the contact wrench applied to unsecured objects, which captures uncertainty in the manipulator dynamics, the object dynamics, and contact parameters such as the coefficient of friction.","meta":{"url":"http://arxiv.org/abs/2309.03111v1"},"cats":{"new-dataset":0.0435947846,"dev-research":0.2438640805,"data-quality":0.0519332345}}
{"text":"An optimization problem formulation is presented that can be solved in real-time to generate provably-safe motions for manipulating the unsecured objects.","meta":{"url":"http://arxiv.org/abs/2309.03111v1"},"cats":{"new-dataset":0.0629802518,"dev-research":0.242089981,"data-quality":0.0596159065}}
{"text":"This paper illustrates that WAITR outperforms state of the art methods in a variety of simulation experiments and demonstrates its performance in the real-world.","meta":{"url":"http://arxiv.org/abs/2309.03111v1"},"cats":{"new-dataset":0.0440435768,"dev-research":0.1805352663,"data-quality":0.0809756917}}
{"text":"Object detectors are at the heart of many semi- and fully autonomous decision systems and are poised to become even more indispensable.","meta":{"url":"http://arxiv.org/abs/2309.03110v1"},"cats":{"new-dataset":0.0527785938,"dev-research":0.1672276979,"data-quality":0.1879571797}}
{"text":"They are, however, still lacking in accessibility and can sometimes produce unreliable predictions.","meta":{"url":"http://arxiv.org/abs/2309.03110v1"},"cats":{"new-dataset":0.0167239886,"dev-research":0.2666218543,"data-quality":0.1828951551}}
{"text":"Especially concerning in this regard are the -- essentially hand-crafted -- non-maximum suppression algorithms that lead to an obfuscated prediction process and biased confidence estimates.","meta":{"url":"http://arxiv.org/abs/2309.03110v1"},"cats":{"new-dataset":0.0191614626,"dev-research":0.161135853,"data-quality":0.2962326696}}
{"text":"We show that we can eliminate classic NMS-style post-processing by using IoU-aware calibration.","meta":{"url":"http://arxiv.org/abs/2309.03110v1"},"cats":{"new-dataset":0.0275428796,"dev-research":0.1481781016,"data-quality":0.1537486573}}
{"text":"IoU-aware calibration is a conditional Beta calibration; this makes it parallelizable with no hyper-parameters.","meta":{"url":"http://arxiv.org/abs/2309.03110v1"},"cats":{"new-dataset":0.0158620235,"dev-research":0.1175409189,"data-quality":0.0818420989}}
{"text":"Instead of arbitrary cutoffs or discounts, it implicitly accounts for the likelihood of each detection being a duplicate and adjusts the confidence score accordingly, resulting in empirically based precision estimates for each detection.","meta":{"url":"http://arxiv.org/abs/2309.03110v1"},"cats":{"new-dataset":0.0065683951,"dev-research":0.1922003293,"data-quality":0.3347046539}}
{"text":"Our extensive experiments on diverse detection architectures show that the proposed IoU-aware calibration can successfully model duplicate detections and improve calibration.","meta":{"url":"http://arxiv.org/abs/2309.03110v1"},"cats":{"new-dataset":0.159716274,"dev-research":0.1545854325,"data-quality":0.3105396355}}
{"text":"Compared to the standard sequential NMS and calibration approach, our joint modeling can deliver performance gains over the best NMS-based alternative while producing consistently better-calibrated confidence predictions with less complexity.","meta":{"url":"http://arxiv.org/abs/2309.03110v1"},"cats":{"new-dataset":0.0232577518,"dev-research":0.167905909,"data-quality":0.1169706777}}
{"text":"The \\hyperlink{https://github.com/Blueblue4/IoU-AwareCalibration}{code} for all our experiments is publicly available.","meta":{"url":"http://arxiv.org/abs/2309.03110v1"},"cats":{"new-dataset":0.121326308,"dev-research":0.1401089484,"data-quality":0.1299939246}}
{"text":"This paper presents ContrastWSD, a RoBERTa-based metaphor detection model that integrates the Metaphor Identification Procedure (MIP) and Word Sense Disambiguation (WSD) to extract and contrast the contextual meaning with the basic meaning of a word to determine whether it is used metaphorically in a sentence.","meta":{"url":"http://arxiv.org/abs/2309.03103v1"},"cats":{"new-dataset":0.0501049885,"dev-research":0.2227835478,"data-quality":0.1847200821}}
{"text":"By utilizing the word senses derived from a WSD model, our model enhances the metaphor detection process and outperforms other methods that rely solely on contextual embeddings or integrate only the basic definitions and other external knowledge.","meta":{"url":"http://arxiv.org/abs/2309.03103v1"},"cats":{"new-dataset":0.0393233489,"dev-research":0.2483997481,"data-quality":0.2471799816}}
{"text":"We evaluate our approach on various benchmark datasets and compare it with strong baselines, indicating the effectiveness in advancing metaphor detection.","meta":{"url":"http://arxiv.org/abs/2309.03103v1"},"cats":{"new-dataset":0.3553070162,"dev-research":0.2601336339,"data-quality":0.2896906202}}
{"text":"Nowadays, many people frequently have to search for new accommodation options.","meta":{"url":"http://arxiv.org/abs/2309.03100v1"},"cats":{"new-dataset":0.0463917201,"dev-research":0.2403995304,"data-quality":0.0713316951}}
{"text":"Searching for a suitable apartment is a time-consuming process, especially because visiting them is often mandatory to assess the truthfulness of the advertisements found on the Web.","meta":{"url":"http://arxiv.org/abs/2309.03100v1"},"cats":{"new-dataset":0.0248893485,"dev-research":0.2206467421,"data-quality":0.1112695647}}
{"text":"While this process could be alleviated by visiting the apartments in the metaverse, the Web-based recommendation platforms are not suitable for the task.","meta":{"url":"http://arxiv.org/abs/2309.03100v1"},"cats":{"new-dataset":0.0465700745,"dev-research":0.2067774421,"data-quality":0.1420448418}}
{"text":"To address this shortcoming, in this paper, we define a new problem called text-to-apartment recommendation, which requires ranking the apartments based on their relevance to a textual query expressing the user's interests.","meta":{"url":"http://arxiv.org/abs/2309.03100v1"},"cats":{"new-dataset":0.0961848896,"dev-research":0.2197597482,"data-quality":0.204656731}}
{"text":"To tackle this problem, we introduce FArMARe, a multi-task approach that supports cross-modal contrastive training with a furniture-aware objective.","meta":{"url":"http://arxiv.org/abs/2309.03100v1"},"cats":{"new-dataset":0.1892679261,"dev-research":0.1486392267,"data-quality":0.0949433448}}
{"text":"Since public datasets related to indoor scenes do not contain detailed descriptions of the furniture, we collect and annotate a dataset comprising more than 6000 apartments.","meta":{"url":"http://arxiv.org/abs/2309.03100v1"},"cats":{"new-dataset":0.9691175215,"dev-research":0.2238572449,"data-quality":0.1744981726}}
{"text":"A thorough experimentation with three different methods and two raw feature extraction procedures reveals the effectiveness of FArMARe in dealing with the problem at hand.","meta":{"url":"http://arxiv.org/abs/2309.03100v1"},"cats":{"new-dataset":0.1833052338,"dev-research":0.2783739173,"data-quality":0.3275556755}}
{"text":"Data is a critical asset in AI, as high-quality datasets can significantly improve the performance of machine learning models.","meta":{"url":"http://arxiv.org/abs/2309.03081v1"},"cats":{"new-dataset":0.2982535659,"dev-research":0.2283082625,"data-quality":0.2092689775}}
{"text":"In safety-critical domains such as autonomous vehicles, offline deep reinforcement learning (offline DRL) is frequently used to train models on pre-collected datasets, as opposed to training these models by interacting with the real-world environment as the online DRL.","meta":{"url":"http://arxiv.org/abs/2309.03081v1"},"cats":{"new-dataset":0.2718250436,"dev-research":0.2233544058,"data-quality":0.0752549092}}
{"text":"To support the development of these models, many institutions make datasets publicly available with opensource licenses, but these datasets are at risk of potential misuse or infringement.","meta":{"url":"http://arxiv.org/abs/2309.03081v1"},"cats":{"new-dataset":0.4873032997,"dev-research":0.1666462245,"data-quality":0.1615054409}}
{"text":"Injecting watermarks to the dataset may protect the intellectual property of the data, but it cannot handle datasets that have already been published and is infeasible to be altered afterward.","meta":{"url":"http://arxiv.org/abs/2309.03081v1"},"cats":{"new-dataset":0.3933936668,"dev-research":0.2383376809,"data-quality":0.3097505998}}
{"text":"Other existing solutions, such as dataset inference and membership inference, do not work well in the offline DRL scenario due to the diverse model behavior characteristics and offline setting constraints.","meta":{"url":"http://arxiv.org/abs/2309.03081v1"},"cats":{"new-dataset":0.1712945325,"dev-research":0.1559102886,"data-quality":0.1252299601}}
{"text":"In this paper, we advocate a new paradigm by leveraging the fact that cumulative rewards can act as a unique identifier that distinguishes DRL models trained on a specific dataset.","meta":{"url":"http://arxiv.org/abs/2309.03081v1"},"cats":{"new-dataset":0.1494534517,"dev-research":0.1906079124,"data-quality":0.2062427393}}
{"text":"To this end, we propose ORL-AUDITOR, which is the first trajectory-level dataset auditing mechanism for offline RL scenarios.","meta":{"url":"http://arxiv.org/abs/2309.03081v1"},"cats":{"new-dataset":0.5942767245,"dev-research":0.2277700374,"data-quality":0.1181194439}}
{"text":"Our experiments on multiple offline DRL models and tasks reveal the efficacy of ORL-AUDITOR, with auditing accuracy over 95% and false positive rates less than 2.88%.","meta":{"url":"http://arxiv.org/abs/2309.03081v1"},"cats":{"new-dataset":0.0359993042,"dev-research":0.2541661036,"data-quality":0.1523203838}}
{"text":"We also provide valuable insights into the practical implementation of ORL-AUDITOR by studying various parameter settings.","meta":{"url":"http://arxiv.org/abs/2309.03081v1"},"cats":{"new-dataset":0.0228293908,"dev-research":0.2848311623,"data-quality":0.1040353671}}
{"text":"Furthermore, we demonstrate the auditing capability of ORL-AUDITOR on open-source datasets from Google and DeepMind, highlighting its effectiveness in auditing published datasets.","meta":{"url":"http://arxiv.org/abs/2309.03081v1"},"cats":{"new-dataset":0.7687871078,"dev-research":0.2537843184,"data-quality":0.1697853243}}
{"text":"ORL-AUDITOR is open-sourced at https://github.com/link-zju/ORL-Auditor.","meta":{"url":"http://arxiv.org/abs/2309.03081v1"},"cats":{"new-dataset":0.3180088059,"dev-research":0.2616811311,"data-quality":0.1134932532}}
{"text":"At the beginning of the COVID-19 pandemic, fears grew that making vaccination a political (instead of public health) issue may impact the efficacy of this life-saving intervention, spurring the spread of vaccine-hesitant content.","meta":{"url":"http://arxiv.org/abs/2309.03078v1"},"cats":{"new-dataset":0.021377509,"dev-research":0.2556125374,"data-quality":0.0992721302}}
{"text":"In this study, we examine whether there is a relationship between the political interest of social media users and their exposure to vaccine-hesitant content on Twitter.","meta":{"url":"http://arxiv.org/abs/2309.03078v1"},"cats":{"new-dataset":0.0375778762,"dev-research":0.2405235685,"data-quality":0.1213367326}}
{"text":"We focus on 17 European countries using a multilingual, longitudinal dataset of tweets spanning the period before COVID, up to the vaccine roll-out.","meta":{"url":"http://arxiv.org/abs/2309.03078v1"},"cats":{"new-dataset":0.6744560133,"dev-research":0.1514364322,"data-quality":0.1276383166}}
{"text":"We find that, in most countries, users' exposure to vaccine-hesitant content is the highest in the early months of the pandemic, around the time of greatest scientific uncertainty.","meta":{"url":"http://arxiv.org/abs/2309.03078v1"},"cats":{"new-dataset":0.0363311243,"dev-research":0.2012748398,"data-quality":0.0914629558}}
{"text":"Further, users who follow politicians from right-wing parties, and those associated with authoritarian or anti-EU stances are more likely to be exposed to vaccine-hesitant content, whereas those following left-wing politicians, more pro-EU or liberal parties, are less likely to encounter it.","meta":{"url":"http://arxiv.org/abs/2309.03078v1"},"cats":{"new-dataset":0.0104764301,"dev-research":0.2054026927,"data-quality":0.0982535106}}
{"text":"Somewhat surprisingly, politicians did not play an outsized role in the vaccine debates of their countries, receiving a similar number of retweets as other similarly popular users.","meta":{"url":"http://arxiv.org/abs/2309.03078v1"},"cats":{"new-dataset":0.0588396537,"dev-research":0.1603412714,"data-quality":0.1060689799}}
{"text":"This systematic, multi-country, longitudinal investigation of the connection of politics with vaccine hesitancy has important implications for public health policy and communication.","meta":{"url":"http://arxiv.org/abs/2309.03078v1"},"cats":{"new-dataset":0.0908781867,"dev-research":0.2022527646,"data-quality":0.082540631}}
{"text":"Surjectivity and injectivity are the most fundamental problems in cellular automata (CA).","meta":{"url":"http://arxiv.org/abs/2309.03073v1"},"cats":{"new-dataset":0.0283177258,"dev-research":0.1713660122,"data-quality":0.1019381063}}
{"text":"We simplify and modify Amoroso's algorithm into optimum and make it compatible with fixed, periodic and reflective boundaries.","meta":{"url":"http://arxiv.org/abs/2309.03073v1"},"cats":{"new-dataset":0.0255457749,"dev-research":0.118131055,"data-quality":0.0755403718}}
{"text":"A new algorithm (injectivity tree algorithm) for injectivity is also proposed.","meta":{"url":"http://arxiv.org/abs/2309.03073v1"},"cats":{"new-dataset":0.0197278875,"dev-research":0.1290879565,"data-quality":0.1276317673}}
{"text":"After our theoretic analysis and experiments, our algorithm for injectivity can save much space and 90\\% or even more time compared with Amoroso's algorithm for injectivity so that it can support the decision of CA with larger neighborhood sizes.","meta":{"url":"http://arxiv.org/abs/2309.03073v1"},"cats":{"new-dataset":0.0226331083,"dev-research":0.106955099,"data-quality":0.0908176843}}
{"text":"At last, we prove that the reversibility with the periodic boundary and global injectivity of one-dimensional CA is equivalent.","meta":{"url":"http://arxiv.org/abs/2309.03073v1"},"cats":{"new-dataset":0.039319477,"dev-research":0.1167766808,"data-quality":0.1071416364}}
{"text":"On-line handwritten character segmentation is often associated with handwriting recognition and even though recognition models include mechanisms to locate relevant positions during the recognition process, it is typically insufficient to produce a precise segmentation.","meta":{"url":"http://arxiv.org/abs/2309.03072v1"},"cats":{"new-dataset":0.0342441801,"dev-research":0.1692271473,"data-quality":0.1805636945}}
{"text":"Decoupling the segmentation from the recognition unlocks the potential to further utilize the result of the recognition.","meta":{"url":"http://arxiv.org/abs/2309.03072v1"},"cats":{"new-dataset":0.0174037227,"dev-research":0.1347504826,"data-quality":0.1587387912}}
{"text":"We specifically focus on the scenario where the transcription is known beforehand, in which case the character segmentation becomes an assignment problem between sampling points of the stylus trajectory and characters in the text.","meta":{"url":"http://arxiv.org/abs/2309.03072v1"},"cats":{"new-dataset":0.1352155701,"dev-research":0.1331114148,"data-quality":0.2265719284}}
{"text":"Inspired by the $k$-means clustering algorithm, we view it from the perspective of cluster assignment and present a Transformer-based architecture where each cluster is formed based on a learned character query in the Transformer decoder block.","meta":{"url":"http://arxiv.org/abs/2309.03072v1"},"cats":{"new-dataset":0.069918702,"dev-research":0.1622332105,"data-quality":0.1495590013}}
{"text":"In order to assess the quality of our approach, we create character segmentation ground truths for two popular on-line handwriting datasets, IAM-OnDB and HANDS-VNOnDB, and evaluate multiple methods on them, demonstrating that our approach achieves the overall best results.","meta":{"url":"http://arxiv.org/abs/2309.03072v1"},"cats":{"new-dataset":0.5299889239,"dev-research":0.2156370953,"data-quality":0.2083670939}}
{"text":"Similar to the revolution of open source code sharing, Artificial Intelligence (AI) model sharing is gaining increased popularity.","meta":{"url":"http://arxiv.org/abs/2309.03071v1"},"cats":{"new-dataset":0.0780676121,"dev-research":0.325178347,"data-quality":0.0763961487}}
{"text":"However, the fast adaptation in the industry, lack of awareness, and ability to exploit the models make them significant attack vectors.","meta":{"url":"http://arxiv.org/abs/2309.03071v1"},"cats":{"new-dataset":0.0055828673,"dev-research":0.2309404919,"data-quality":0.1524666661}}
{"text":"By embedding malware in neurons, the malware can be delivered covertly, with minor or no impact on the neural network's performance.","meta":{"url":"http://arxiv.org/abs/2309.03071v1"},"cats":{"new-dataset":0.00419153,"dev-research":0.2088248805,"data-quality":0.1362061823}}
{"text":"The covert attack will use the Least Significant Bits (LSB) weight attack since LSB has a minimal effect on the model accuracy, and as a result, the user will not notice it.","meta":{"url":"http://arxiv.org/abs/2309.03071v1"},"cats":{"new-dataset":0.0055852024,"dev-research":0.1452081227,"data-quality":0.1787000514}}
{"text":"Since there are endless ways to hide the attacks, we focus on a zero-trust prevention strategy based on AI model attack disarm and reconstruction.","meta":{"url":"http://arxiv.org/abs/2309.03071v1"},"cats":{"new-dataset":0.0325997086,"dev-research":0.1757292968,"data-quality":0.1199378599}}
{"text":"We proposed three types of model steganography weight disarm defense mechanisms.","meta":{"url":"http://arxiv.org/abs/2309.03071v1"},"cats":{"new-dataset":0.0415859946,"dev-research":0.1579614964,"data-quality":0.1373429211}}
{"text":"The first two are based on random bit substitution noise, and the other on model weight quantization.","meta":{"url":"http://arxiv.org/abs/2309.03071v1"},"cats":{"new-dataset":0.0312369608,"dev-research":0.1515822908,"data-quality":0.2016749735}}
{"text":"We demonstrate a 100\\% prevention rate while the methods introduce a minimal decrease in model accuracy based on Qint8 and K-LRBP methods, which is an essential factor for improving AI security.","meta":{"url":"http://arxiv.org/abs/2309.03071v1"},"cats":{"new-dataset":0.0190645915,"dev-research":0.2026750948,"data-quality":0.1288789206}}
{"text":"Influencer marketing involves a wide range of strategies in which brands collaborate with popular content creators (i.e., influencers) to leverage their reach, trust, and impact on their audience to promote and endorse products or services.","meta":{"url":"http://arxiv.org/abs/2309.03064v1"},"cats":{"new-dataset":0.0355209297,"dev-research":0.2024007677,"data-quality":0.0992263644}}
{"text":"Because followers of influencers are more likely to buy a product after receiving an authentic product endorsement rather than an explicit direct product promotion, the line between personal opinions and commercial content promotion is frequently blurred.","meta":{"url":"http://arxiv.org/abs/2309.03064v1"},"cats":{"new-dataset":0.0081957253,"dev-research":0.2335050255,"data-quality":0.1945682548}}
{"text":"This makes automatic detection of regulatory compliance breaches related to influencer advertising (e.g., misleading advertising or hidden sponsorships) particularly difficult.","meta":{"url":"http://arxiv.org/abs/2309.03064v1"},"cats":{"new-dataset":0.0153151145,"dev-research":0.3000867893,"data-quality":0.5187747267}}
{"text":"In this work, we (1) introduce a new Twitter (now X) dataset consisting of 15,998 influencer posts mapped into commercial and non-commercial categories for assisting in the automatic detection of commercial influencer content; (2) experiment with an extensive set of predictive models that combine text and visual information showing that our proposed cross-attention approach outperforms state-of-the-art multimodal models; and (3) conduct a thorough analysis of strengths and limitations of our models.","meta":{"url":"http://arxiv.org/abs/2309.03064v1"},"cats":{"new-dataset":0.2841135472,"dev-research":0.1634882915,"data-quality":0.1900705559}}
{"text":"We show that multimodal modeling is useful for identifying commercial posts, reducing the amount of false positives, and capturing relevant context that aids in the discovery of undisclosed commercial posts.","meta":{"url":"http://arxiv.org/abs/2309.03064v1"},"cats":{"new-dataset":0.2046778988,"dev-research":0.2045566713,"data-quality":0.3657979881}}
{"text":"Image restoration aims to recover the high-quality images from their degraded observations.","meta":{"url":"http://arxiv.org/abs/2309.03063v1"},"cats":{"new-dataset":0.1489316899,"dev-research":0.1737094533,"data-quality":0.2469195308}}
{"text":"Since most existing methods have been dedicated into single degradation removal, they may not yield optimal results on other types of degradations, which do not satisfy the applications in real world scenarios.","meta":{"url":"http://arxiv.org/abs/2309.03063v1"},"cats":{"new-dataset":0.0045989979,"dev-research":0.1882737633,"data-quality":0.2509424701}}
{"text":"In this paper, we propose a novel data ingredient-oriented approach that leverages prompt-based learning to enable a single model to efficiently tackle multiple image degradation tasks.","meta":{"url":"http://arxiv.org/abs/2309.03063v1"},"cats":{"new-dataset":0.1293931153,"dev-research":0.2044531833,"data-quality":0.2370797879}}
{"text":"Specifically, we utilize a encoder to capture features and introduce prompts with degradation-specific information to guide the decoder in adaptively recovering images affected by various degradations.","meta":{"url":"http://arxiv.org/abs/2309.03063v1"},"cats":{"new-dataset":0.1270215552,"dev-research":0.250473254,"data-quality":0.2521959691}}
{"text":"In order to model the local invariant properties and non-local information for high-quality image restoration, we combined CNNs operations and Transformers.","meta":{"url":"http://arxiv.org/abs/2309.03063v1"},"cats":{"new-dataset":0.0478682675,"dev-research":0.1722036242,"data-quality":0.2183834889}}
{"text":"Simultaneously, we made several key designs in the Transformer blocks (multi-head rearranged attention with prompts and simple-gate feed-forward network) to reduce computational requirements and selectively determines what information should be persevered to facilitate efficient recovery of potentially sharp images.","meta":{"url":"http://arxiv.org/abs/2309.03063v1"},"cats":{"new-dataset":0.0348421792,"dev-research":0.1999546233,"data-quality":0.1088794813}}
{"text":"Furthermore, we incorporate a feature fusion mechanism further explores the multi-scale information to improve the aggregated features.","meta":{"url":"http://arxiv.org/abs/2309.03063v1"},"cats":{"new-dataset":0.0613749687,"dev-research":0.2117357192,"data-quality":0.1609655071}}
{"text":"The resulting tightly interlinked hierarchy architecture, named as CAPTNet, despite being designed to handle different types of degradations, extensive experiments demonstrate that our method performs competitively to the task-specific algorithms.","meta":{"url":"http://arxiv.org/abs/2309.03063v1"},"cats":{"new-dataset":0.048348101,"dev-research":0.2423960657,"data-quality":0.1276194431}}
{"text":"Many areas of machine learning and science involve large linear algebra problems, such as eigendecompositions, solving linear systems, computing matrix exponentials, and trace estimation.","meta":{"url":"http://arxiv.org/abs/2309.03060v1"},"cats":{"new-dataset":0.0152651991,"dev-research":0.230900155,"data-quality":0.079828942}}
{"text":"The matrices involved often have Kronecker, convolutional, block diagonal, sum, or product structure.","meta":{"url":"http://arxiv.org/abs/2309.03060v1"},"cats":{"new-dataset":0.0454477349,"dev-research":0.1495425899,"data-quality":0.0649585359}}
{"text":"In this paper, we propose a simple but general framework for large-scale linear algebra problems in machine learning, named CoLA (Compositional Linear Algebra).","meta":{"url":"http://arxiv.org/abs/2309.03060v1"},"cats":{"new-dataset":0.0673735463,"dev-research":0.1534502683,"data-quality":0.1421581281}}
{"text":"By combining a linear operator abstraction with compositional dispatch rules, CoLA automatically constructs memory and runtime efficient numerical algorithms.","meta":{"url":"http://arxiv.org/abs/2309.03060v1"},"cats":{"new-dataset":0.0246980914,"dev-research":0.1832715927,"data-quality":0.0675966982}}
{"text":"Moreover, CoLA provides memory efficient automatic differentiation, low precision computation, and GPU acceleration in both JAX and PyTorch, while also accommodating new objects, operations, and rules in downstream packages via multiple dispatch.","meta":{"url":"http://arxiv.org/abs/2309.03060v1"},"cats":{"new-dataset":0.047399725,"dev-research":0.2070123617,"data-quality":0.0935849352}}
{"text":"CoLA can accelerate many algebraic operations, while making it easy to prototype matrix structures and algorithms, providing an appealing drop-in tool for virtually any computational effort that requires linear algebra.","meta":{"url":"http://arxiv.org/abs/2309.03060v1"},"cats":{"new-dataset":0.0222910356,"dev-research":0.1880245061,"data-quality":0.0573274764}}
{"text":"We showcase its efficacy across a broad range of applications, including partial differential equations, Gaussian processes, equivariant model construction, and unsupervised learning.","meta":{"url":"http://arxiv.org/abs/2309.03060v1"},"cats":{"new-dataset":0.0325153275,"dev-research":0.1223749809,"data-quality":0.0867554739}}
{"text":"In this paper, we investigate the performance of reconfigurable intelligent surface (RIS)-aided spatial shift keying (SSK) wireless communication systems in the presence of imperfect channel state information (CSI).","meta":{"url":"http://arxiv.org/abs/2309.03059v1"},"cats":{"new-dataset":0.0230249135,"dev-research":0.2342984343,"data-quality":0.0691725462}}
{"text":"Specifically, we analyze the average bit error probability (ABEP) of two RIS-SSK systems respectively based on intelligent reflection and blind reflection of RIS.","meta":{"url":"http://arxiv.org/abs/2309.03059v1"},"cats":{"new-dataset":0.0209906996,"dev-research":0.2368188545,"data-quality":0.2246701894}}
{"text":"For the intelligent RIS-SSK scheme, we first derive the conditional pairwise error probability of the composite channel through maximum likelihood (ML) detection.","meta":{"url":"http://arxiv.org/abs/2309.03059v1"},"cats":{"new-dataset":0.0242517668,"dev-research":0.1137641222,"data-quality":0.2473847239}}
{"text":"Subsequently, we derive the probability density function of the combined channel.","meta":{"url":"http://arxiv.org/abs/2309.03059v1"},"cats":{"new-dataset":0.0329402168,"dev-research":0.1243097782,"data-quality":0.1129468697}}
{"text":"Due to the intricacies of the composite channel formulation, an exact closed-form ABEP expression is unattainable through direct derivation.","meta":{"url":"http://arxiv.org/abs/2309.03059v1"},"cats":{"new-dataset":0.0045670125,"dev-research":0.1618838782,"data-quality":0.1126010051}}
{"text":"To this end, we resort to employing the Gaussian-Chebyshev quadrature method to estimate the results.","meta":{"url":"http://arxiv.org/abs/2309.03059v1"},"cats":{"new-dataset":0.1044951052,"dev-research":0.0717094633,"data-quality":0.1162619435}}
{"text":"In addition, we employ the Q-function approximation to derive the non-exact closed-form expression when CSI imperfections are present.","meta":{"url":"http://arxiv.org/abs/2309.03059v1"},"cats":{"new-dataset":0.0575626455,"dev-research":0.1702107505,"data-quality":0.1538898148}}
{"text":"For the blind RIS-SSK scheme, we derive both closed-form ABEP expression and asymptotic ABEP expression with imperfect CSI by adopting the ML detector.","meta":{"url":"http://arxiv.org/abs/2309.03059v1"},"cats":{"new-dataset":0.0668229172,"dev-research":0.1224296821,"data-quality":0.1848559159}}
{"text":"To offer deeper insights, we explore the impact of discrete reflection phase shifts on the performance of the RIS-SSK system.","meta":{"url":"http://arxiv.org/abs/2309.03059v1"},"cats":{"new-dataset":0.0156381775,"dev-research":0.1208725685,"data-quality":0.0821964521}}
{"text":"Lastly, we extensively validate all the analytical derivations using Monte Carlo simulations.","meta":{"url":"http://arxiv.org/abs/2309.03059v1"},"cats":{"new-dataset":0.0167691754,"dev-research":0.1846042267,"data-quality":0.0900999208}}
{"text":"Numerous companies have started offering services based on large language models (LLM), such as ChatGPT, which inevitably raises privacy concerns as users' prompts are exposed to the model provider.","meta":{"url":"http://arxiv.org/abs/2309.03057v1"},"cats":{"new-dataset":0.0945125525,"dev-research":0.1710095682,"data-quality":0.1192942694}}
{"text":"Previous research on secure reasoning using multi-party computation (MPC) has proven to be impractical for LLM applications due to its time-consuming and communication-intensive nature.","meta":{"url":"http://arxiv.org/abs/2309.03057v1"},"cats":{"new-dataset":0.025695907,"dev-research":0.1708172285,"data-quality":0.07791366}}
{"text":"While lightweight anonymization techniques can protect private information in prompts through substitution or masking, they fail to recover sensitive data replaced in the LLM-generated results.","meta":{"url":"http://arxiv.org/abs/2309.03057v1"},"cats":{"new-dataset":0.0512715323,"dev-research":0.1111963129,"data-quality":0.2887964678}}
{"text":"In this paper, we expand the application scenarios of anonymization techniques by training a small local model to de-anonymize the LLM's returned results with minimal computational overhead.","meta":{"url":"http://arxiv.org/abs/2309.03057v1"},"cats":{"new-dataset":0.1193337284,"dev-research":0.1036361114,"data-quality":0.2697498339}}
{"text":"We introduce the HaS framework, where \"H(ide)\" and \"S(eek)\" represent its two core processes: hiding private entities for anonymization and seeking private entities for de-anonymization, respectively.","meta":{"url":"http://arxiv.org/abs/2309.03057v1"},"cats":{"new-dataset":0.1294792288,"dev-research":0.1636282931,"data-quality":0.1534210261}}
{"text":"To quantitatively assess HaS's privacy protection performance, we propose both black-box and white-box adversarial models.","meta":{"url":"http://arxiv.org/abs/2309.03057v1"},"cats":{"new-dataset":0.0219147853,"dev-research":0.131517793,"data-quality":0.1248438917}}
{"text":"Furthermore, we conduct experiments to evaluate HaS's usability in translation and classification tasks.","meta":{"url":"http://arxiv.org/abs/2309.03057v1"},"cats":{"new-dataset":0.0372316353,"dev-research":0.2999841622,"data-quality":0.2004612979}}
{"text":"The experimental findings demonstrate that the HaS framework achieves an optimal balance between privacy protection and utility.","meta":{"url":"http://arxiv.org/abs/2309.03057v1"},"cats":{"new-dataset":0.013757382,"dev-research":0.1664448116,"data-quality":0.0581379629}}
{"text":"Autonomous driving has long grappled with the need for precise absolute localization, making full autonomy elusive and raising the capital entry barriers for startups.","meta":{"url":"http://arxiv.org/abs/2309.03051v1"},"cats":{"new-dataset":0.0340370987,"dev-research":0.2381262812,"data-quality":0.1552835896}}
{"text":"This study delves into the feasibility of local trajectory planning for level-2+ (L2+) semi-autonomous vehicles without the dependence on accurate absolute localization.","meta":{"url":"http://arxiv.org/abs/2309.03051v1"},"cats":{"new-dataset":0.0441459517,"dev-research":0.1609540243,"data-quality":0.0786157457}}
{"text":"Instead, we emphasize the estimation of the pose change between consecutive planning frames from motion sensors and integration of relative locations of traffic objects to the local planning problem under the ego car's local coordinate system, therefore eliminating the need for an absolute localization.","meta":{"url":"http://arxiv.org/abs/2309.03051v1"},"cats":{"new-dataset":0.2074779008,"dev-research":0.2342923289,"data-quality":0.0981585211}}
{"text":"Without the availability of absolute localization for correction, the measurement errors of speed and yaw rate greatly affect the estimation accuracy of the relative pose change between frames.","meta":{"url":"http://arxiv.org/abs/2309.03051v1"},"cats":{"new-dataset":0.0278944411,"dev-research":0.2350697586,"data-quality":0.1958465839}}
{"text":"We proved that the feasibility/stability of the continuous planning problem under such motion sensor errors can be guaranteed at certain defined conditions.","meta":{"url":"http://arxiv.org/abs/2309.03051v1"},"cats":{"new-dataset":0.0871274061,"dev-research":0.2626124797,"data-quality":0.0937492143}}
{"text":"This was achieved by formulating it as a Lyapunov-stability analysis problem.","meta":{"url":"http://arxiv.org/abs/2309.03051v1"},"cats":{"new-dataset":0.0213602333,"dev-research":0.1286965722,"data-quality":0.0634938175}}
{"text":"Moreover, a simulation pipeline was developed to further validate the proposed local planning method.","meta":{"url":"http://arxiv.org/abs/2309.03051v1"},"cats":{"new-dataset":0.0174832074,"dev-research":0.2842377371,"data-quality":0.0572295146}}
{"text":"Simulations were conducted at two traffic scenes with different error settings for speed and yaw rate measurements.","meta":{"url":"http://arxiv.org/abs/2309.03051v1"},"cats":{"new-dataset":0.0351735844,"dev-research":0.2362141827,"data-quality":0.1521943333}}
{"text":"The results substantiate the proposed framework's functionality even under relatively inferior sensor errors.","meta":{"url":"http://arxiv.org/abs/2309.03051v1"},"cats":{"new-dataset":0.0256376441,"dev-research":0.2357814513,"data-quality":0.2693584435}}
{"text":"We also experiment the stability limits of the planned results under abnormally larger motion sensor errors.","meta":{"url":"http://arxiv.org/abs/2309.03051v1"},"cats":{"new-dataset":0.0826286772,"dev-research":0.1815733535,"data-quality":0.1721271007}}
{"text":"The results provide a good match to the previous theoretical analysis.","meta":{"url":"http://arxiv.org/abs/2309.03051v1"},"cats":{"new-dataset":0.0235973538,"dev-research":0.0992508229,"data-quality":0.0990809618}}
{"text":"Our findings suggested that precise absolute localization may not be the sole path to achieving reliable trajectory planning, eliminating the necessity for high-accuracy dual-antenna GPS as well as the high-fidelity maps for SLAM localization.","meta":{"url":"http://arxiv.org/abs/2309.03051v1"},"cats":{"new-dataset":0.0127384246,"dev-research":0.2058344319,"data-quality":0.1461809295}}
{"text":"Deep Neural Networks (DNNs) have shown unparalleled achievements in numerous applications, reflecting their proficiency in managing vast data sets.","meta":{"url":"http://arxiv.org/abs/2309.03049v1"},"cats":{"new-dataset":0.3317665061,"dev-research":0.2732113394,"data-quality":0.2111216731}}
{"text":"Yet, their static structure limits their adaptability in ever-changing environments.","meta":{"url":"http://arxiv.org/abs/2309.03049v1"},"cats":{"new-dataset":0.0324393298,"dev-research":0.2641292297,"data-quality":0.1253093375}}
{"text":"This research presents a new algorithm that allows the convolutional layer of a Convolutional Neural Network (CNN) to dynamically evolve based on data input, while still being seamlessly integrated into existing DNNs.","meta":{"url":"http://arxiv.org/abs/2309.03049v1"},"cats":{"new-dataset":0.1394289692,"dev-research":0.2109776135,"data-quality":0.0863263667}}
{"text":"Instead of a rigid architecture, our approach iteratively introduces kernels to the convolutional layer, gauging its real-time response to varying data.","meta":{"url":"http://arxiv.org/abs/2309.03049v1"},"cats":{"new-dataset":0.0879373898,"dev-research":0.1303091444,"data-quality":0.0854313489}}
{"text":"This process is refined by evaluating the layer's capacity to discern image features, guiding its growth.","meta":{"url":"http://arxiv.org/abs/2309.03049v1"},"cats":{"new-dataset":0.0353167187,"dev-research":0.2086006595,"data-quality":0.0998111944}}
{"text":"Remarkably, our unsupervised method has outstripped its supervised counterparts across diverse datasets like MNIST, Fashion-MNIST, CIFAR-10, and CIFAR-100.","meta":{"url":"http://arxiv.org/abs/2309.03049v1"},"cats":{"new-dataset":0.1301923806,"dev-research":0.1642772736,"data-quality":0.2771770687}}
{"text":"It also showcases enhanced adaptability in transfer learning scenarios.","meta":{"url":"http://arxiv.org/abs/2309.03049v1"},"cats":{"new-dataset":0.0257988745,"dev-research":0.2154947312,"data-quality":0.0836203858}}
{"text":"By introducing a data-driven model scalability strategy, we are filling a void in deep learning, leading to more flexible and efficient DNNs suited for dynamic settings.","meta":{"url":"http://arxiv.org/abs/2309.03049v1"},"cats":{"new-dataset":0.2423053509,"dev-research":0.2077446163,"data-quality":0.1104969057}}
{"text":"Code:(https://github.com/YunjieZhu/Extensible-Convolutional-Layer-git-version).","meta":{"url":"http://arxiv.org/abs/2309.03049v1"},"cats":{"new-dataset":0.1044502797,"dev-research":0.1727645013,"data-quality":0.1011353374}}
{"text":"In surgical computer vision applications, obtaining labeled training data is challenging due to data-privacy concerns and the need for expert annotation.","meta":{"url":"http://arxiv.org/abs/2309.03048v1"},"cats":{"new-dataset":0.2794178277,"dev-research":0.1994346392,"data-quality":0.3251649416}}
{"text":"Unpaired image-to-image translation techniques have been explored to automatically generate large annotated datasets by translating synthetic images to the realistic domain.","meta":{"url":"http://arxiv.org/abs/2309.03048v1"},"cats":{"new-dataset":0.7976725576,"dev-research":0.1922507982,"data-quality":0.3308016952}}
{"text":"However, preserving the structure and semantic consistency between the input and translated images presents significant challenges, mainly when there is a distributional mismatch in the semantic characteristics of the domains.","meta":{"url":"http://arxiv.org/abs/2309.03048v1"},"cats":{"new-dataset":0.0660038225,"dev-research":0.1878749504,"data-quality":0.5003829573}}
{"text":"This study empirically investigates unpaired image translation methods for generating suitable data in surgical applications, explicitly focusing on semantic consistency.","meta":{"url":"http://arxiv.org/abs/2309.03048v1"},"cats":{"new-dataset":0.0608043839,"dev-research":0.2204992092,"data-quality":0.2744724504}}
{"text":"We extensively evaluate various state-of-the-art image translation models on two challenging surgical datasets and downstream semantic segmentation tasks.","meta":{"url":"http://arxiv.org/abs/2309.03048v1"},"cats":{"new-dataset":0.3475664472,"dev-research":0.1403310906,"data-quality":0.1822360118}}
{"text":"We find that a simple combination of structural-similarity loss and contrastive learning yields the most promising results.","meta":{"url":"http://arxiv.org/abs/2309.03048v1"},"cats":{"new-dataset":0.0509882074,"dev-research":0.1200290097,"data-quality":0.2207042525}}
{"text":"Quantitatively, we show that the data generated with this approach yields higher semantic consistency and can be used more effectively as training data.","meta":{"url":"http://arxiv.org/abs/2309.03048v1"},"cats":{"new-dataset":0.2179657367,"dev-research":0.2615395305,"data-quality":0.4945964214}}
{"text":"Out-of-domain (OOD) detection is a crucial component in industrial applications as it helps identify when a model encounters inputs that are outside the training distribution.","meta":{"url":"http://arxiv.org/abs/2309.03047v1"},"cats":{"new-dataset":0.0349375816,"dev-research":0.1623275131,"data-quality":0.2652810201}}
{"text":"Most industrial pipelines rely on pre-trained models for downstream tasks such as CNN or Vision Transformers.","meta":{"url":"http://arxiv.org/abs/2309.03047v1"},"cats":{"new-dataset":0.0205922028,"dev-research":0.2121070373,"data-quality":0.1043405079}}
{"text":"This paper investigates the performance of those models on the task of out-of-domain detection.","meta":{"url":"http://arxiv.org/abs/2309.03047v1"},"cats":{"new-dataset":0.0250967385,"dev-research":0.1357534521,"data-quality":0.2883701126}}
{"text":"Our experiments demonstrate that pre-trained transformers models achieve higher detection performance out of the box.","meta":{"url":"http://arxiv.org/abs/2309.03047v1"},"cats":{"new-dataset":0.0470558671,"dev-research":0.175826167,"data-quality":0.1491792319}}
{"text":"Furthermore, we show that pre-trained ViT and CNNs can be combined with refinement methods such as CIDER to improve their OOD detection performance even more.","meta":{"url":"http://arxiv.org/abs/2309.03047v1"},"cats":{"new-dataset":0.1206212587,"dev-research":0.1701888847,"data-quality":0.1862710838}}
{"text":"Our results suggest that transformers are a promising approach for OOD detection and set a stronger baseline for this task in many contexts","meta":{"url":"http://arxiv.org/abs/2309.03047v1"},"cats":{"new-dataset":0.1032066636,"dev-research":0.1510811875,"data-quality":0.1745479839}}
{"text":"Grove is a concurrent separation logic library for verifying distributed systems.","meta":{"url":"http://arxiv.org/abs/2309.03046v1"},"cats":{"new-dataset":0.0579905777,"dev-research":0.187258231,"data-quality":0.1141613049}}
{"text":"Grove is the first to handle time-based leases, including their interaction with reconfiguration, crash recovery, thread-level concurrency, and unreliable networks.","meta":{"url":"http://arxiv.org/abs/2309.03046v1"},"cats":{"new-dataset":0.0500745859,"dev-research":0.2358013597,"data-quality":0.0945633139}}
{"text":"This paper uses Grove to verify several distributed system components written in Go, including GroveKV, a realistic distributed multi-threaded key-value store.","meta":{"url":"http://arxiv.org/abs/2309.03046v1"},"cats":{"new-dataset":0.1307792871,"dev-research":0.1538212585,"data-quality":0.1000681462}}
{"text":"GroveKV","meta":{"url":"http://arxiv.org/abs/2309.03046v1"},"cats":{"new-dataset":0.1468589131,"dev-research":0.1469690308,"data-quality":0.1303426384}}
{"text":"supports reconfiguration, primary/backup replication, and crash recovery, and uses leases to execute read-only requests on any replica.","meta":{"url":"http://arxiv.org/abs/2309.03046v1"},"cats":{"new-dataset":0.0487212523,"dev-research":0.1548000113,"data-quality":0.080656288}}
{"text":"GroveKV achieves high performance (67-73% of Redis on a single core), scales with more cores and more backup replicas (achieving about 2x the throughput when going from 1 to 3 servers), and can safely execute reads while reconfiguring.","meta":{"url":"http://arxiv.org/abs/2309.03046v1"},"cats":{"new-dataset":0.0730277372,"dev-research":0.1625956098,"data-quality":0.066353365}}
{"text":"This work presents a detailed evaluation of Rust (software) implementations of several popular sketching solutions, as well as recently proposed optimizations.","meta":{"url":"http://arxiv.org/abs/2309.03045v1"},"cats":{"new-dataset":0.058855963,"dev-research":0.4589383721,"data-quality":0.0521298543}}
{"text":"We compare these solutions in terms of computational speed, memory consumption, and several approximation error metrics.","meta":{"url":"http://arxiv.org/abs/2309.03045v1"},"cats":{"new-dataset":0.0248444387,"dev-research":0.1914414011,"data-quality":0.126120959}}
{"text":"Overall, we find a simple hashing based solution employed with the Nitro sampling technique [22] gives the best trade-off between memory, error and speed.","meta":{"url":"http://arxiv.org/abs/2309.03045v1"},"cats":{"new-dataset":0.0624237398,"dev-research":0.1511878272,"data-quality":0.1920518917}}
{"text":"Our findings also include some novel insights about how to best combine sampling with Counting Cuckoo filters depending on the application.","meta":{"url":"http://arxiv.org/abs/2309.03045v1"},"cats":{"new-dataset":0.0331640765,"dev-research":0.1052066322,"data-quality":0.146974961}}
{"text":"In the past couple of decades, significant research efforts are devoted to the prediction of software bugs.","meta":{"url":"http://arxiv.org/abs/2309.03044v1"},"cats":{"new-dataset":0.0770346567,"dev-research":0.5378267093,"data-quality":0.2769613547}}
{"text":"However, most existing work in this domain treats all bugs the same, which is not the case in practice.","meta":{"url":"http://arxiv.org/abs/2309.03044v1"},"cats":{"new-dataset":0.0075417329,"dev-research":0.3864882496,"data-quality":0.3494846497}}
{"text":"It is important for a defect prediction method to estimate the severity of the identified bugs so that the higher-severity ones get immediate attention.","meta":{"url":"http://arxiv.org/abs/2309.03044v1"},"cats":{"new-dataset":0.0263898445,"dev-research":0.5491962158,"data-quality":0.3275905536}}
{"text":"In this study, we investigate source code metrics, source code representation using large language models (LLMs), and their combination in predicting bug severity labels of two prominent datasets.","meta":{"url":"http://arxiv.org/abs/2309.03044v1"},"cats":{"new-dataset":0.488176564,"dev-research":0.531617395,"data-quality":0.5177423527}}
{"text":"We leverage several source metrics at method-level granularity to train eight different machine-learning models.","meta":{"url":"http://arxiv.org/abs/2309.03044v1"},"cats":{"new-dataset":0.0570857512,"dev-research":0.2161530543,"data-quality":0.2417157269}}
{"text":"Our results suggest that Decision Tree and Random Forest models outperform other models regarding our several evaluation metrics.","meta":{"url":"http://arxiv.org/abs/2309.03044v1"},"cats":{"new-dataset":0.029475723,"dev-research":0.1795830789,"data-quality":0.2640518767}}
{"text":"We then use the pre-trained CodeBERT LLM to study the source code representations' effectiveness in predicting bug severity.","meta":{"url":"http://arxiv.org/abs/2309.03044v1"},"cats":{"new-dataset":0.1341676646,"dev-research":0.5682524734,"data-quality":0.3560680816}}
{"text":"CodeBERT finetuning improves the bug severity prediction results significantly in the range of 29%-140% for several evaluation metrics, compared to the best classic prediction model on source code metric.","meta":{"url":"http://arxiv.org/abs/2309.03044v1"},"cats":{"new-dataset":0.1778004124,"dev-research":0.6018844528,"data-quality":0.4170033846}}
{"text":"Finally, we integrate source code metrics into CodeBERT as an additional input, using our two proposed architectures, which both enhance the CodeBERT model effectiveness.","meta":{"url":"http://arxiv.org/abs/2309.03044v1"},"cats":{"new-dataset":0.1263118586,"dev-research":0.4581738798,"data-quality":0.2081368915}}
{"text":"Recent work demonstrated the existence of Boolean functions for which Shapley values provide misleading information about the relative importance of features in rule-based explanations.","meta":{"url":"http://arxiv.org/abs/2309.03041v1"},"cats":{"new-dataset":0.0266853879,"dev-research":0.3509394476,"data-quality":0.2627644151}}
{"text":"Such misleading information was broadly categorized into a number of possible issues.","meta":{"url":"http://arxiv.org/abs/2309.03041v1"},"cats":{"new-dataset":0.0197495076,"dev-research":0.3117428825,"data-quality":0.3192362174}}
{"text":"Each of those issues relates with features being relevant or irrelevant for a prediction, and all are significant regarding the inadequacy of Shapley values for rule-based explainability.","meta":{"url":"http://arxiv.org/abs/2309.03041v1"},"cats":{"new-dataset":0.0134796627,"dev-research":0.3192899179,"data-quality":0.2249223991}}
{"text":"This earlier work devised a brute-force approach to identify Boolean functions, defined on small numbers of features, and also associated instances, which displayed such inadequacy-revealing issues, and so served as evidence to the inadequacy of Shapley values for rule-based explainability.","meta":{"url":"http://arxiv.org/abs/2309.03041v1"},"cats":{"new-dataset":0.0391168804,"dev-research":0.3183108128,"data-quality":0.2456808099}}
{"text":"However, an outstanding question is how frequently such inadequacy-revealing issues can occur for Boolean functions with arbitrary large numbers of features.","meta":{"url":"http://arxiv.org/abs/2309.03041v1"},"cats":{"new-dataset":0.0306980538,"dev-research":0.334857959,"data-quality":0.2722174954}}
{"text":"It is plain that a brute-force approach would be unlikely to provide insights on how to tackle this question.","meta":{"url":"http://arxiv.org/abs/2309.03041v1"},"cats":{"new-dataset":0.0453068132,"dev-research":0.1165261979,"data-quality":0.1475212173}}
{"text":"This paper answers the above question by proving that, for any number of features, there exist Boolean functions that exhibit one or more inadequacy-revealing issues, thereby contributing decisive arguments against the use of Shapley values as the theoretical underpinning of feature-attribution methods in explainability.","meta":{"url":"http://arxiv.org/abs/2309.03041v1"},"cats":{"new-dataset":0.013366706,"dev-research":0.3048133256,"data-quality":0.2555532891}}
{"text":"The Common Vulnerabilities and Exposures (CVE) are pivotal information for proactive cybersecurity measures, including service patching, security hardening, and more.","meta":{"url":"http://arxiv.org/abs/2309.03040v1"},"cats":{"new-dataset":0.106342595,"dev-research":0.3342811188,"data-quality":0.1325682714}}
{"text":"However, CVEs typically offer low-level, product-oriented descriptions of publicly disclosed cybersecurity vulnerabilities, often lacking the essential attack semantic information required for comprehensive weakness characterization and threat impact estimation.","meta":{"url":"http://arxiv.org/abs/2309.03040v1"},"cats":{"new-dataset":0.0675698973,"dev-research":0.3208114097,"data-quality":0.2139504383}}
{"text":"This critical insight is essential for CVE prioritization and the identification of potential countermeasures, particularly when dealing with a large number of CVEs.","meta":{"url":"http://arxiv.org/abs/2309.03040v1"},"cats":{"new-dataset":0.0089294787,"dev-research":0.2597315511,"data-quality":0.1408563579}}
{"text":"Current industry practices involve manual evaluation of CVEs to assess their attack severities using the Common Vulnerability Scoring System (CVSS) and mapping them to Common Weakness Enumeration (CWE) for potential mitigation identification.","meta":{"url":"http://arxiv.org/abs/2309.03040v1"},"cats":{"new-dataset":0.0518368729,"dev-research":0.3423304826,"data-quality":0.2140265047}}
{"text":"Unfortunately, this manual analysis presents a major bottleneck in the vulnerability analysis process, leading to slowdowns in proactive cybersecurity efforts and the potential for inaccuracies due to human errors.","meta":{"url":"http://arxiv.org/abs/2309.03040v1"},"cats":{"new-dataset":0.1826852818,"dev-research":0.4380975708,"data-quality":0.1433365912}}
{"text":"In this research, we introduce our novel predictive model and tool (called CVEDrill) which revolutionizes CVE analysis and threat prioritization.","meta":{"url":"http://arxiv.org/abs/2309.03040v1"},"cats":{"new-dataset":0.0916836597,"dev-research":0.2659056401,"data-quality":0.1214079346}}
{"text":"CVEDrill accurately estimates the CVSS vector for precise threat mitigation and priority ranking and seamlessly automates the classification of CVEs into the appropriate CWE hierarchy classes.","meta":{"url":"http://arxiv.org/abs/2309.03040v1"},"cats":{"new-dataset":0.0423100847,"dev-research":0.229840863,"data-quality":0.155381745}}
{"text":"By harnessing CVEDrill, organizations can now implement cybersecurity countermeasure mitigation with unparalleled accuracy and timeliness, surpassing in this domain the capabilities of state-of-the-art tools like ChaptGPT.","meta":{"url":"http://arxiv.org/abs/2309.03040v1"},"cats":{"new-dataset":0.1276821695,"dev-research":0.2408169919,"data-quality":0.1229384897}}
{"text":"The upper mid-band -- roughly from 7 to 24 GHz -- has attracted considerable recent interest for new cellular services.","meta":{"url":"http://arxiv.org/abs/2309.03038v1"},"cats":{"new-dataset":0.0221022363,"dev-research":0.1352698908,"data-quality":0.0704917937}}
{"text":"This frequency range has vastly more spectrum than the highly congested bands below 7 GHz while offering more favorable propagation and coverage than the millimeter wave (mmWave) frequencies.","meta":{"url":"http://arxiv.org/abs/2309.03038v1"},"cats":{"new-dataset":0.0089286086,"dev-research":0.1662970235,"data-quality":0.0655405628}}
{"text":"Realizing the full potential of these bands, however, will require fundamental changes to the design of cellular systems.","meta":{"url":"http://arxiv.org/abs/2309.03038v1"},"cats":{"new-dataset":0.006067384,"dev-research":0.1508503598,"data-quality":0.0642682138}}
{"text":"Most importantly, spectrum will likely need to be shared with incumbents including communication satellites, military RADAR, and radio astronomy.","meta":{"url":"http://arxiv.org/abs/2309.03038v1"},"cats":{"new-dataset":0.0239421122,"dev-research":0.1405945276,"data-quality":0.1025127776}}
{"text":"Also, due to the wide bandwidth, directional nature of transmission, and intermittent occupancy of incumbents, cellular systems will need to be agile to sense and intelligently use large spatial and bandwidth degrees of freedom.","meta":{"url":"http://arxiv.org/abs/2309.03038v1"},"cats":{"new-dataset":0.0071572804,"dev-research":0.1291969739,"data-quality":0.0416716638}}
{"text":"This paper attempts to provide an initial assessment of the feasibility and potential gains of wideband cellular systems operating in the upper mid-band.","meta":{"url":"http://arxiv.org/abs/2309.03038v1"},"cats":{"new-dataset":0.0050836566,"dev-research":0.1363052753,"data-quality":0.0917637394}}
{"text":"The study includes: (1) a system study to assess potential gains of multi-band systems in a representative dense urban environment; (2) propagation calculations to assess potential cross interference between satellites and terrestrial cellular services; and (3) design and evaluation of a compact multi-band antenna array structure.","meta":{"url":"http://arxiv.org/abs/2309.03038v1"},"cats":{"new-dataset":0.0241482676,"dev-research":0.1731197365,"data-quality":0.0636598492}}
{"text":"Leveraging these preliminary results, we identify potential future research directions to realize next-generation systems in these frequencies.","meta":{"url":"http://arxiv.org/abs/2309.03038v1"},"cats":{"new-dataset":0.0408619948,"dev-research":0.162835762,"data-quality":0.0831643037}}
{"text":"Partially spoofed audio detection is a challenging task, lying in the need to accurately locate the authenticity of audio at the frame level.","meta":{"url":"http://arxiv.org/abs/2309.03036v1"},"cats":{"new-dataset":0.040832215,"dev-research":0.1623578444,"data-quality":0.3630258611}}
{"text":"To address this issue, we propose a fine-grained partially spoofed audio detection method, namely Temporal Deepfake Location (TDL), which can effectively capture information of both features and locations.","meta":{"url":"http://arxiv.org/abs/2309.03036v1"},"cats":{"new-dataset":0.2222365997,"dev-research":0.1951334029,"data-quality":0.3019631353}}
{"text":"Specifically, our approach involves two novel parts: embedding similarity module and temporal convolution operation.","meta":{"url":"http://arxiv.org/abs/2309.03036v1"},"cats":{"new-dataset":0.1195588098,"dev-research":0.146839526,"data-quality":0.1225033642}}
{"text":"To enhance the identification between the real and fake features, the embedding similarity module is designed to generate an embedding space that can separate the real frames from fake frames.","meta":{"url":"http://arxiv.org/abs/2309.03036v1"},"cats":{"new-dataset":0.1121220503,"dev-research":0.2199366902,"data-quality":0.2494550411}}
{"text":"To effectively concentrate on the position information, temporal convolution operation is proposed to calculate the frame-specific similarities among neighboring frames, and dynamically select informative neighbors to convolution.","meta":{"url":"http://arxiv.org/abs/2309.03036v1"},"cats":{"new-dataset":0.0988323943,"dev-research":0.166241018,"data-quality":0.0801029055}}
{"text":"Extensive experiments show that our method outperform baseline models in ASVspoof2019 Partial Spoof dataset and demonstrate superior performance even in the crossdataset scenario.","meta":{"url":"http://arxiv.org/abs/2309.03036v1"},"cats":{"new-dataset":0.3630764643,"dev-research":0.1549689354,"data-quality":0.2336502758}}
{"text":"The code is released online.","meta":{"url":"http://arxiv.org/abs/2309.03036v1"},"cats":{"new-dataset":0.3982163963,"dev-research":0.2967023638,"data-quality":0.1075571401}}
{"text":"With Polycystic Kidney Disease (PKD) potentially leading to fatal complications in patients due to the formation of cysts in the kidneys, early detection of PKD is crucial for effective management of the condition.","meta":{"url":"http://arxiv.org/abs/2309.03033v1"},"cats":{"new-dataset":0.0233416452,"dev-research":0.1997602953,"data-quality":0.1179866911}}
{"text":"However, the various patient-specific factors that play a role in the diagnosis make it an intricate puzzle for clinicians to solve.","meta":{"url":"http://arxiv.org/abs/2309.03033v1"},"cats":{"new-dataset":0.0068745251,"dev-research":0.2693685512,"data-quality":0.0918110642}}
{"text":"Therefore, in this study, we aim to utilize a deep learning-based approach for early disease detection.","meta":{"url":"http://arxiv.org/abs/2309.03033v1"},"cats":{"new-dataset":0.1161569749,"dev-research":0.1988411347,"data-quality":0.1449406419}}
{"text":"The devised neural network can achieve accurate and robust predictions for possible PKD in patients by analyzing patient gene expressions.","meta":{"url":"http://arxiv.org/abs/2309.03033v1"},"cats":{"new-dataset":0.0755158459,"dev-research":0.2217030057,"data-quality":0.1362018374}}
{"text":"The objective of the multi-condition human motion synthesis task is to incorporate diverse conditional inputs, encompassing various forms like text, music, speech, and more.","meta":{"url":"http://arxiv.org/abs/2309.03031v1"},"cats":{"new-dataset":0.1208680838,"dev-research":0.2365490118,"data-quality":0.0703121557}}
{"text":"This endows the task with the capability to adapt across multiple scenarios, ranging from text-to-motion and music-to-dance, among others.","meta":{"url":"http://arxiv.org/abs/2309.03031v1"},"cats":{"new-dataset":0.0540758216,"dev-research":0.2300412748,"data-quality":0.0565708253}}
{"text":"While existing research has primarily focused on single conditions, the multi-condition human motion generation remains underexplored.","meta":{"url":"http://arxiv.org/abs/2309.03031v1"},"cats":{"new-dataset":0.1024220669,"dev-research":0.1865801978,"data-quality":0.0341941907}}
{"text":"In this paper, we address these challenges by introducing MCM, a novel paradigm for motion synthesis that spans multiple scenarios under diverse conditions.","meta":{"url":"http://arxiv.org/abs/2309.03031v1"},"cats":{"new-dataset":0.1083027673,"dev-research":0.2324863294,"data-quality":0.0433566348}}
{"text":"The MCM framework is able to integrate with any DDPM-like diffusion model to accommodate multi-conditional information input while preserving its generative capabilities.","meta":{"url":"http://arxiv.org/abs/2309.03031v1"},"cats":{"new-dataset":0.0110419767,"dev-research":0.0921584587,"data-quality":0.0706749113}}
{"text":"Specifically, MCM employs two-branch architecture consisting of a main branch and a control branch.","meta":{"url":"http://arxiv.org/abs/2309.03031v1"},"cats":{"new-dataset":0.013415355,"dev-research":0.164045497,"data-quality":0.0543104379}}
{"text":"The control branch shares the same structure as the main branch and is initialized with the parameters of the main branch, effectively maintaining the generation ability of the main branch and supporting multi-condition input.","meta":{"url":"http://arxiv.org/abs/2309.03031v1"},"cats":{"new-dataset":0.0349377869,"dev-research":0.2200403972,"data-quality":0.0672328537}}
{"text":"We also introduce a Transformer-based diffusion model MWNet (DDPM-like) as our main branch that can capture the spatial complexity and inter-joint correlations in motion sequences through a channel-dimension self-attention module.","meta":{"url":"http://arxiv.org/abs/2309.03031v1"},"cats":{"new-dataset":0.0543050709,"dev-research":0.108155539,"data-quality":0.0577224923}}
{"text":"Quantitative comparisons demonstrate that our approach achieves SoTA results in both text-to-motion and competitive results in music-to-dance tasks, comparable to task-specific methods.","meta":{"url":"http://arxiv.org/abs/2309.03031v1"},"cats":{"new-dataset":0.0450013051,"dev-research":0.1520379118,"data-quality":0.0886565476}}
{"text":"Furthermore, the qualitative evaluation shows that MCM not only streamlines the adaptation of methodologies originally designed for text-to-motion tasks to domains like music-to-dance and speech-to-gesture, eliminating the need for extensive network re-configurations but also enables effective multi-condition modal control, realizing \"once trained is motion need\".","meta":{"url":"http://arxiv.org/abs/2309.03031v1"},"cats":{"new-dataset":0.0126719751,"dev-research":0.1783213448,"data-quality":0.0815435678}}
{"text":"Knowledge graph embeddings are dense numerical representations of entities in a knowledge graph (KG).","meta":{"url":"http://arxiv.org/abs/2309.03023v1"},"cats":{"new-dataset":0.1356670063,"dev-research":0.2017122144,"data-quality":0.1702354098}}
{"text":"While the majority of approaches concentrate only on relational information, i.e., relations between entities, fewer approaches exist which also take information about literal values (e.g., textual descriptions or numerical information) into account.","meta":{"url":"http://arxiv.org/abs/2309.03023v1"},"cats":{"new-dataset":0.0061414174,"dev-research":0.3500466134,"data-quality":0.1650003744}}
{"text":"Those which exist are typically tailored towards a particular modality of literal and a particular embedding method.","meta":{"url":"http://arxiv.org/abs/2309.03023v1"},"cats":{"new-dataset":0.0246906803,"dev-research":0.189420965,"data-quality":0.2122403547}}
{"text":"In this paper, we propose a set of universal preprocessing operators which can be used to transform KGs with literals for numerical, temporal, textual, and image information, so that the transformed KGs can be embedded with any method.","meta":{"url":"http://arxiv.org/abs/2309.03023v1"},"cats":{"new-dataset":0.1056231428,"dev-research":0.1891585697,"data-quality":0.1196661404}}
{"text":"The results on the kgbench dataset with three different embedding methods show promising results.","meta":{"url":"http://arxiv.org/abs/2309.03023v1"},"cats":{"new-dataset":0.7865000815,"dev-research":0.1002215943,"data-quality":0.2363920254}}
{"text":"Real-world Super-Resolution (real-SR) methods focus on dealing with diverse real-world images and have attracted increasing attention in recent years.","meta":{"url":"http://arxiv.org/abs/2309.03020v1"},"cats":{"new-dataset":0.0595821785,"dev-research":0.1476396452,"data-quality":0.0830380437}}
{"text":"The key idea is to use a complex and high-order degradation model to mimic real-world degradations.","meta":{"url":"http://arxiv.org/abs/2309.03020v1"},"cats":{"new-dataset":0.0602782753,"dev-research":0.2416661472,"data-quality":0.1436521133}}
{"text":"Although they have achieved impressive results in various scenarios, they are faced with the obstacle of evaluation.","meta":{"url":"http://arxiv.org/abs/2309.03020v1"},"cats":{"new-dataset":0.0098069173,"dev-research":0.276693909,"data-quality":0.1413555284}}
{"text":"Currently, these methods are only assessed by their average performance on a small set of degradation cases randomly selected from a large space, which fails to provide a comprehensive understanding of their overall performance and often yields biased results.","meta":{"url":"http://arxiv.org/abs/2309.03020v1"},"cats":{"new-dataset":0.0201968215,"dev-research":0.2036960168,"data-quality":0.2860157922}}
{"text":"To overcome the limitation in evaluation, we propose SEAL, a framework for systematic evaluation of real-SR.","meta":{"url":"http://arxiv.org/abs/2309.03020v1"},"cats":{"new-dataset":0.0303489047,"dev-research":0.293918676,"data-quality":0.1735168609}}
{"text":"In particular, we cluster the extensive degradation space to create a set of representative degradation cases, which serves as a comprehensive test set.","meta":{"url":"http://arxiv.org/abs/2309.03020v1"},"cats":{"new-dataset":0.191924773,"dev-research":0.301724542,"data-quality":0.2570012059}}
{"text":"Next, we propose a coarse-to-fine evaluation protocol to measure the distributed and relative performance of real-SR methods on the test set.","meta":{"url":"http://arxiv.org/abs/2309.03020v1"},"cats":{"new-dataset":0.0341466343,"dev-research":0.1845760316,"data-quality":0.1896491534}}
{"text":"The protocol incorporates two new metrics: acceptance rate (AR) and relative performance ratio (RPR), derived from an acceptance line and an excellence line.","meta":{"url":"http://arxiv.org/abs/2309.03020v1"},"cats":{"new-dataset":0.012969399,"dev-research":0.1677613861,"data-quality":0.0914745194}}
{"text":"Under SEAL, we benchmark existing real-SR methods, obtain new observations and insights into their performance, and develop a new strong baseline.","meta":{"url":"http://arxiv.org/abs/2309.03020v1"},"cats":{"new-dataset":0.0296131037,"dev-research":0.1281015,"data-quality":0.1326907428}}
{"text":"We consider SEAL as the first step towards creating an unbiased and comprehensive evaluation platform, which can promote the development of real-SR.","meta":{"url":"http://arxiv.org/abs/2309.03020v1"},"cats":{"new-dataset":0.064651243,"dev-research":0.2685078849,"data-quality":0.1444776536}}
{"text":"The edge computing paradigm helps handle the Internet of Things (IoT) generated data in proximity to its source.","meta":{"url":"http://arxiv.org/abs/2309.03014v1"},"cats":{"new-dataset":0.0419572323,"dev-research":0.2338964795,"data-quality":0.0604314366}}
{"text":"Challenges occur in transferring, storing, and processing this rapidly growing amount of data on resource-constrained edge devices.","meta":{"url":"http://arxiv.org/abs/2309.03014v1"},"cats":{"new-dataset":0.0967585652,"dev-research":0.1986868477,"data-quality":0.0744979385}}
{"text":"Symbolic Representation (SR) algorithms are promising solutions to reduce the data size by converting actual raw data into symbols.","meta":{"url":"http://arxiv.org/abs/2309.03014v1"},"cats":{"new-dataset":0.0938495164,"dev-research":0.2329445571,"data-quality":0.1145427681}}
{"text":"Also, they allow data analytics (e.g., anomaly detection and trend prediction) directly on symbols, benefiting large classes of edge applications.","meta":{"url":"http://arxiv.org/abs/2309.03014v1"},"cats":{"new-dataset":0.0153263048,"dev-research":0.2840350216,"data-quality":0.0866437075}}
{"text":"However, existing SR algorithms are centralized in design and work offline with batch data, which is infeasible for real-time cases.","meta":{"url":"http://arxiv.org/abs/2309.03014v1"},"cats":{"new-dataset":0.0575658936,"dev-research":0.1631140593,"data-quality":0.0596195273}}
{"text":"We propose SymED -","meta":{"url":"http://arxiv.org/abs/2309.03014v1"},"cats":{"new-dataset":0.2535430522,"dev-research":0.3177470637,"data-quality":0.0954750131}}
{"text":"Symbolic Edge Data representation method, i.e., an online, adaptive, and distributed approach for symbolic representation of data on edge.","meta":{"url":"http://arxiv.org/abs/2309.03014v1"},"cats":{"new-dataset":0.0512618645,"dev-research":0.2534297095,"data-quality":0.1293347703}}
{"text":"SymED is based on the Adaptive Brownian Bridge-based Aggregation (ABBA), where we assume low-powered IoT devices do initial data compression (senders) and the more robust edge devices do the symbolic conversion (receivers).","meta":{"url":"http://arxiv.org/abs/2309.03014v1"},"cats":{"new-dataset":0.0367451095,"dev-research":0.1603588602,"data-quality":0.0630463723}}
{"text":"We evaluate SymED by measuring compression performance, reconstruction accuracy through Dynamic Time Warping (DTW) distance, and computational latency.","meta":{"url":"http://arxiv.org/abs/2309.03014v1"},"cats":{"new-dataset":0.1096902453,"dev-research":0.2504936189,"data-quality":0.1020280068}}
{"text":"The results show that SymED is able to (i) reduce the raw data with an average compression rate of 9.5%; (ii) keep a low reconstruction error of 13.25 in the DTW space; (iii) simultaneously provide real-time adaptability for online streaming IoT data at typical latencies of 42ms per symbol, reducing the overall network traffic.","meta":{"url":"http://arxiv.org/abs/2309.03014v1"},"cats":{"new-dataset":0.1122436541,"dev-research":0.1802769004,"data-quality":0.0778228664}}
{"text":"We propose a novel method for 3D object reconstruction from a sparse set of views captured from a 360-degree calibrated camera rig.","meta":{"url":"http://arxiv.org/abs/2309.03008v1"},"cats":{"new-dataset":0.2321813203,"dev-research":0.1425999487,"data-quality":0.0935208184}}
{"text":"We represent the object surface through a hybrid model that uses both an MLP-based neural representation and a triangle mesh.","meta":{"url":"http://arxiv.org/abs/2309.03008v1"},"cats":{"new-dataset":0.0446258018,"dev-research":0.1573773092,"data-quality":0.0712529851}}
{"text":"A key contribution in our work is a novel object-centric sampling scheme of the neural representation, where rays are shared among all views.","meta":{"url":"http://arxiv.org/abs/2309.03008v1"},"cats":{"new-dataset":0.1030558969,"dev-research":0.1240636276,"data-quality":0.126261725}}
{"text":"This efficiently concentrates and reduces the number of samples used to update the neural model at each iteration.","meta":{"url":"http://arxiv.org/abs/2309.03008v1"},"cats":{"new-dataset":0.0087203815,"dev-research":0.1781471534,"data-quality":0.0980744266}}
{"text":"This sampling scheme relies on the mesh representation to ensure also that samples are well-distributed along its normals.","meta":{"url":"http://arxiv.org/abs/2309.03008v1"},"cats":{"new-dataset":0.0195640967,"dev-research":0.1044951809,"data-quality":0.0794080083}}
{"text":"The rendering is then performed efficiently by a differentiable renderer.","meta":{"url":"http://arxiv.org/abs/2309.03008v1"},"cats":{"new-dataset":0.003988059,"dev-research":0.2091656455,"data-quality":0.0838901234}}
{"text":"We demonstrate that this sampling scheme results in a more effective training of the neural representation, does not require the additional supervision of segmentation masks, yields state of the art 3D reconstructions, and works with sparse views on the Google's Scanned Objects, Tank and Temples and MVMC Car datasets.","meta":{"url":"http://arxiv.org/abs/2309.03008v1"},"cats":{"new-dataset":0.3153849832,"dev-research":0.1197154431,"data-quality":0.1461225388}}
{"text":"Solana has quickly emerged as a popular platform for building decentralized applications (DApps), such as marketplaces for non-fungible tokens (NFTs).","meta":{"url":"http://arxiv.org/abs/2309.03006v1"},"cats":{"new-dataset":0.0668562339,"dev-research":0.2129445132,"data-quality":0.0540369372}}
{"text":"A key reason for its success are Solana's low transaction fees and high performance, which is achieved in part due to its stateless programming model.","meta":{"url":"http://arxiv.org/abs/2309.03006v1"},"cats":{"new-dataset":0.011647501,"dev-research":0.2788111288,"data-quality":0.0715520719}}
{"text":"Although the literature features extensive tooling support for smart contract security, current solutions are largely tailored for the Ethereum Virtual Machine.","meta":{"url":"http://arxiv.org/abs/2309.03006v1"},"cats":{"new-dataset":0.1073657856,"dev-research":0.275586152,"data-quality":0.0918261086}}
{"text":"Unfortunately, the very stateless nature of Solana's execution environment introduces novel attack patterns specific to Solana requiring a rethinking for building vulnerability analysis methods.   ","meta":{"url":"http://arxiv.org/abs/2309.03006v1"},"cats":{"new-dataset":0.0881032128,"dev-research":0.3672040992,"data-quality":0.0833726223}}
{"text":"In this paper, we address this gap and propose FuzzDelSol, the first binary-only coverage-guided fuzzing architecture for Solana smart contracts.","meta":{"url":"http://arxiv.org/abs/2309.03006v1"},"cats":{"new-dataset":0.1554697303,"dev-research":0.2815958437,"data-quality":0.126660331}}
{"text":"FuzzDelSol faithfully models runtime specifics such as smart contract interactions.","meta":{"url":"http://arxiv.org/abs/2309.03006v1"},"cats":{"new-dataset":0.0393636916,"dev-research":0.2286164976,"data-quality":0.093152888}}
{"text":"Moreover, since source code is not available for the large majority of Solana contracts, FuzzDelSol operates on the contract's binary code.","meta":{"url":"http://arxiv.org/abs/2309.03006v1"},"cats":{"new-dataset":0.1253001362,"dev-research":0.3103124669,"data-quality":0.1123882478}}
{"text":"Hence, due to the lack of semantic information, we carefully extracted low-level program and state information to develop a diverse set of bug oracles covering all major bug classes in Solana.","meta":{"url":"http://arxiv.org/abs/2309.03006v1"},"cats":{"new-dataset":0.2807843911,"dev-research":0.484464915,"data-quality":0.2423242908}}
{"text":"Our extensive evaluation on 6049 smart contracts shows that FuzzDelSol's bug oracles find bugs with a high precision and recall.","meta":{"url":"http://arxiv.org/abs/2309.03006v1"},"cats":{"new-dataset":0.2589854709,"dev-research":0.4073930206,"data-quality":0.4217265788}}
{"text":"To the best of our knowledge, this is the largest evaluation of the security landscape on the Solana mainnet.","meta":{"url":"http://arxiv.org/abs/2309.03006v1"},"cats":{"new-dataset":0.2075168374,"dev-research":0.1989295386,"data-quality":0.0714261073}}
{"text":"A recent empirical observation of activation sparsity in MLP layers offers an opportunity to drastically reduce computation costs for free.","meta":{"url":"http://arxiv.org/abs/2309.03004v1"},"cats":{"new-dataset":0.0103324877,"dev-research":0.1558060945,"data-quality":0.1380088489}}
{"text":"Despite several works attributing it to training dynamics, the theoretical explanation of activation sparsity's emergence is restricted to shallow networks, small training steps well as modified training, even though the sparsity has been found in deep models trained by vanilla protocols for large steps.","meta":{"url":"http://arxiv.org/abs/2309.03004v1"},"cats":{"new-dataset":0.0084080306,"dev-research":0.1374255344,"data-quality":0.1361369075}}
{"text":"To fill the three gaps, we propose the notion of gradient sparsity as the source of activation sparsity and a theoretical explanation based on it that explains gradient sparsity and then activation sparsity as necessary steps to adversarial robustness w.r.t.","meta":{"url":"http://arxiv.org/abs/2309.03004v1"},"cats":{"new-dataset":0.0163847509,"dev-research":0.1968393032,"data-quality":0.3440370487}}
{"text":"hidden features and parameters, which is approximately the flatness of minima for well-learned models.","meta":{"url":"http://arxiv.org/abs/2309.03004v1"},"cats":{"new-dataset":0.0283831813,"dev-research":0.1386299694,"data-quality":0.1448076632}}
{"text":"The theory applies to standardly trained LayerNorm-ed pure MLPs, and further to Transformers or other architectures if noises are added to weights during training.","meta":{"url":"http://arxiv.org/abs/2309.03004v1"},"cats":{"new-dataset":0.0056119189,"dev-research":0.1290391605,"data-quality":0.1669086175}}
{"text":"To eliminate other sources of flatness when arguing sparsities' necessity, we discover the phenomenon of spectral concentration, i.e., the ratio between the largest and the smallest non-zero singular values of weight matrices is small.","meta":{"url":"http://arxiv.org/abs/2309.03004v1"},"cats":{"new-dataset":0.0102647049,"dev-research":0.0978472282,"data-quality":0.1987066393}}
{"text":"We utilize random matrix theory (RMT) as a powerful theoretical tool to analyze stochastic gradient noises and discuss the emergence of spectral concentration.","meta":{"url":"http://arxiv.org/abs/2309.03004v1"},"cats":{"new-dataset":0.0137896413,"dev-research":0.1123576832,"data-quality":0.1527888923}}
{"text":"With these insights, we propose two plug-and-play modules for both training from scratch and sparsity finetuning, as well as one radical modification that only applies to from-scratch training.","meta":{"url":"http://arxiv.org/abs/2309.03004v1"},"cats":{"new-dataset":0.0930765921,"dev-research":0.2708743714,"data-quality":0.1783660549}}
{"text":"Another under-testing module for both sparsity and flatness is also immediate from our theories.","meta":{"url":"http://arxiv.org/abs/2309.03004v1"},"cats":{"new-dataset":0.0069640077,"dev-research":0.1430278526,"data-quality":0.2101550725}}
{"text":"Validational experiments are conducted to verify our explanation.","meta":{"url":"http://arxiv.org/abs/2309.03004v1"},"cats":{"new-dataset":0.0049460891,"dev-research":0.3188816813,"data-quality":0.2523980473}}
{"text":"Experiments for productivity demonstrate modifications' improvement in sparsity, indicating further theoretical cost reduction in both training and inference.","meta":{"url":"http://arxiv.org/abs/2309.03004v1"},"cats":{"new-dataset":0.006026407,"dev-research":0.2375831684,"data-quality":0.1319730506}}
{"text":"3D dense captioning requires a model to translate its understanding of an input 3D scene into several captions associated with different object regions.","meta":{"url":"http://arxiv.org/abs/2309.02999v1"},"cats":{"new-dataset":0.0761365112,"dev-research":0.1835342947,"data-quality":0.2313439512}}
{"text":"Existing methods adopt a sophisticated \"detect-then-describe\" pipeline, which builds explicit relation modules upon a 3D detector with numerous hand-crafted components.","meta":{"url":"http://arxiv.org/abs/2309.02999v1"},"cats":{"new-dataset":0.1373224495,"dev-research":0.2136833071,"data-quality":0.1439390001}}
{"text":"While these methods have achieved initial success, the cascade pipeline tends to accumulate errors because of duplicated and inaccurate box estimations and messy 3D scenes.","meta":{"url":"http://arxiv.org/abs/2309.02999v1"},"cats":{"new-dataset":0.0138070415,"dev-research":0.2401969466,"data-quality":0.2895908138}}
{"text":"In this paper, we first propose Vote2Cap-DETR, a simple-yet-effective transformer framework that decouples the decoding process of caption generation and object localization through parallel decoding.","meta":{"url":"http://arxiv.org/abs/2309.02999v1"},"cats":{"new-dataset":0.2321657251,"dev-research":0.1885964151,"data-quality":0.2410487241}}
{"text":"Moreover, we argue that object localization and description generation require different levels of scene understanding, which could be challenging for a shared set of queries to capture.","meta":{"url":"http://arxiv.org/abs/2309.02999v1"},"cats":{"new-dataset":0.2690078404,"dev-research":0.2206155563,"data-quality":0.2249898495}}
{"text":"To this end, we propose an advanced version, Vote2Cap-DETR++, which decouples the queries into localization and caption queries to capture task-specific features.","meta":{"url":"http://arxiv.org/abs/2309.02999v1"},"cats":{"new-dataset":0.3611806621,"dev-research":0.2923318188,"data-quality":0.2448796727}}
