{"text":"We present the All-Seeing (AS) project: a large-scale data and model for recognizing and understanding everything in the open world.","meta":{"url":"http://arxiv.org/abs/2308.01907v1"},"cats":{"new-dataset":0.5589018367,"dev-research":0.1914363561,"prompt-eng":0.3608411688,"data-quality":0.1887646935,"ml-security":0.13540337}}
{"text":"Using a scalable data engine that incorporates human feedback and efficient models in the loop, we create a new dataset (AS-1B) with over 1 billion regions annotated with semantic tags, question-answering pairs, and detailed captions.","meta":{"url":"http://arxiv.org/abs/2308.01907v1"},"cats":{"new-dataset":0.7710271861,"dev-research":0.2967946427,"prompt-eng":0.4213380396,"data-quality":0.3071878883,"ml-security":0.0852902048}}
{"text":"It covers a wide range of 3.5 million common and rare concepts in the real world, and has 132.2 billion tokens that describe the concepts and their attributes.","meta":{"url":"http://arxiv.org/abs/2308.01907v1"},"cats":{"new-dataset":0.3767846477,"dev-research":0.2255045697,"prompt-eng":0.343666306,"data-quality":0.1312525515,"ml-security":0.1265881987}}
{"text":"Leveraging this new dataset, we develop the All-Seeing model (ASM), a unified framework for panoptic visual recognition and understanding.","meta":{"url":"http://arxiv.org/abs/2308.01907v1"},"cats":{"new-dataset":0.4787380127,"dev-research":0.1667987719,"prompt-eng":0.3831008294,"data-quality":0.1215786742,"ml-security":0.0892992316}}
{"text":"The model is trained with open-ended language prompts and locations, which allows it to generalize to various vision and language tasks with remarkable zero-shot performance, including region-text retrieval, region recognition, captioning, and question-answering.","meta":{"url":"http://arxiv.org/abs/2308.01907v1"},"cats":{"new-dataset":0.4212444044,"dev-research":0.2026445045,"prompt-eng":0.4119998398,"data-quality":0.1877245232,"ml-security":0.0923469857}}
{"text":"We hope that this project can serve as a foundation for vision-language artificial general intelligence research.","meta":{"url":"http://arxiv.org/abs/2308.01907v1"},"cats":{"new-dataset":0.2726385378,"dev-research":0.2381584718,"prompt-eng":0.4032266138,"data-quality":0.1792747732,"ml-security":0.1138788945}}
{"text":"Models and the dataset shall be released at https://github.com/OpenGVLab/All-Seeing, and demo can be seen at https://huggingface.co/spaces/OpenGVLab/all-seeing.","meta":{"url":"http://arxiv.org/abs/2308.01907v1"},"cats":{"new-dataset":0.7252840166,"dev-research":0.1197447508,"prompt-eng":0.3700325531,"data-quality":0.0760357167,"ml-security":0.0495316874}}
{"text":"Large language models (LLMs) have revolutionized NLP by solving downstream tasks with little to no labeled data.","meta":{"url":"http://arxiv.org/abs/2308.01906v1"},"cats":{"new-dataset":0.0704523496,"dev-research":0.2028575416,"prompt-eng":0.3611447579,"data-quality":0.2361981893,"ml-security":0.1024108594}}
{"text":"Despite their versatile abilities, the larger question of their ability to reason remains ill-understood.","meta":{"url":"http://arxiv.org/abs/2308.01906v1"},"cats":{"new-dataset":0.0240645888,"dev-research":0.3381226198,"prompt-eng":0.3639802068,"data-quality":0.2666028901,"ml-security":0.1583914463}}
{"text":"This paper addresses reasoning in math word problems (MWPs) by studying symbolic versions of the numeric problems, since a symbolic expression is a \"concise explanation\" of the numeric answer.","meta":{"url":"http://arxiv.org/abs/2308.01906v1"},"cats":{"new-dataset":0.093292746,"dev-research":0.3819061823,"prompt-eng":0.4049460947,"data-quality":0.2722253577,"ml-security":0.1194570818}}
{"text":"We create and use a symbolic version of the SVAMP dataset and find that GPT-3's davinci-002 model also has good zero-shot accuracy on symbolic MWPs.","meta":{"url":"http://arxiv.org/abs/2308.01906v1"},"cats":{"new-dataset":0.4786824621,"dev-research":0.1874428728,"prompt-eng":0.4058323333,"data-quality":0.1888525437,"ml-security":0.0533765001}}
{"text":"To evaluate the faithfulness of the model's reasoning, we go beyond accuracy and additionally evaluate the alignment between the final answer and the outputted reasoning, which correspond to numeric and symbolic answers respectively for MWPs.","meta":{"url":"http://arxiv.org/abs/2308.01906v1"},"cats":{"new-dataset":0.0648548327,"dev-research":0.278542149,"prompt-eng":0.4509019164,"data-quality":0.21087969,"ml-security":0.0999357436}}
{"text":"We explore a self-prompting approach to encourage the symbolic reasoning to align with the numeric answer, thus equipping the LLM with the ability to provide a concise and verifiable reasoning and making it more interpretable.","meta":{"url":"http://arxiv.org/abs/2308.01906v1"},"cats":{"new-dataset":0.0390919898,"dev-research":0.3804611185,"prompt-eng":0.52900245,"data-quality":0.1634759431,"ml-security":0.1255224349}}
{"text":"Surprisingly, self-prompting also improves the symbolic accuracy to be higher than both the numeric and symbolic accuracies, thus providing an ensembling effect.","meta":{"url":"http://arxiv.org/abs/2308.01906v1"},"cats":{"new-dataset":0.0139256312,"dev-research":0.4030501037,"prompt-eng":0.5671391705,"data-quality":0.2832611805,"ml-security":0.1275077649}}
{"text":"The SVAMP_Sym dataset will be released for future research on symbolic math problems.","meta":{"url":"http://arxiv.org/abs/2308.01906v1"},"cats":{"new-dataset":0.5496274957,"dev-research":0.2362514449,"prompt-eng":0.3848886744,"data-quality":0.1593634024,"ml-security":0.1079766307}}
{"text":"Depth completion, which aims to generate high-quality dense depth maps from sparse depth maps, has attracted increasing attention in recent years.","meta":{"url":"http://arxiv.org/abs/2308.01905v1"},"cats":{"new-dataset":0.265122746,"dev-research":0.2018186696,"prompt-eng":0.364023914,"data-quality":0.1593024171,"ml-security":0.0711574259}}
{"text":"Previous work usually employs RGB images as guidance, and introduces iterative spatial propagation to refine estimated coarse depth maps.","meta":{"url":"http://arxiv.org/abs/2308.01905v1"},"cats":{"new-dataset":0.1689692687,"dev-research":0.2277407264,"prompt-eng":0.3926363466,"data-quality":0.110760097,"ml-security":0.0519534692}}
{"text":"However, most of the propagation refinement methods require several iterations and suffer from a fixed receptive field, which may contain irrelevant and useless information with very sparse input.","meta":{"url":"http://arxiv.org/abs/2308.01905v1"},"cats":{"new-dataset":0.0209201244,"dev-research":0.2595443971,"prompt-eng":0.3794441136,"data-quality":0.1910461334,"ml-security":0.1006676175}}
{"text":"In this paper, we address these two challenges simultaneously by revisiting the idea of deformable convolution.","meta":{"url":"http://arxiv.org/abs/2308.01905v1"},"cats":{"new-dataset":0.1071828241,"dev-research":0.1524317003,"prompt-eng":0.331720538,"data-quality":0.1410205534,"ml-security":0.1284911022}}
{"text":"We propose an effective architecture that leverages deformable kernel convolution as a single-pass refinement module, and empirically demonstrate its superiority.","meta":{"url":"http://arxiv.org/abs/2308.01905v1"},"cats":{"new-dataset":0.1166403024,"dev-research":0.262951957,"prompt-eng":0.368514211,"data-quality":0.1523215025,"ml-security":0.1306839724}}
{"text":"To better understand the function of deformable convolution and exploit it for depth completion, we further systematically investigate a variety of representative strategies.","meta":{"url":"http://arxiv.org/abs/2308.01905v1"},"cats":{"new-dataset":0.0958508401,"dev-research":0.1795114278,"prompt-eng":0.3353841561,"data-quality":0.1308750889,"ml-security":0.1025178151}}
{"text":"Our study reveals that, different from prior work, deformable convolution needs to be applied on an estimated depth map with a relatively high density for better performance.","meta":{"url":"http://arxiv.org/abs/2308.01905v1"},"cats":{"new-dataset":0.2572044654,"dev-research":0.1710067048,"prompt-eng":0.3402502277,"data-quality":0.1035814752,"ml-security":0.0670472513}}
{"text":"We evaluate our model on the large-scale KITTI dataset and achieve state-of-the-art level performance in both accuracy and inference speed.","meta":{"url":"http://arxiv.org/abs/2308.01905v1"},"cats":{"new-dataset":0.5856036201,"dev-research":0.1674860341,"prompt-eng":0.3767751397,"data-quality":0.1736560661,"ml-security":0.0718918663}}
{"text":"Our code is available at https://github.com/AlexSunNik/ReDC.","meta":{"url":"http://arxiv.org/abs/2308.01905v1"},"cats":{"new-dataset":0.5056815256,"dev-research":0.1494857139,"prompt-eng":0.428841741,"data-quality":0.1113153885,"ml-security":0.0346135881}}
{"text":"This paper presents an improved DETR detector that maintains a \"plain\" nature: using a single-scale feature map and global cross-attention calculations without specific locality constraints, in contrast to previous leading DETR-based detectors that reintroduce architectural inductive biases of multi-scale and locality into the decoder.","meta":{"url":"http://arxiv.org/abs/2308.01904v1"},"cats":{"new-dataset":0.1996799763,"dev-research":0.275184808,"prompt-eng":0.415670528,"data-quality":0.3028987496,"ml-security":0.2005595761}}
{"text":"We show that two simple technologies are surprisingly effective within a plain design to compensate for the lack of multi-scale feature maps and locality constraints.","meta":{"url":"http://arxiv.org/abs/2308.01904v1"},"cats":{"new-dataset":0.110049332,"dev-research":0.399697504,"prompt-eng":0.3960826401,"data-quality":0.2068871611,"ml-security":0.1365754503}}
{"text":"The first is a box-to-pixel relative position bias (BoxRPB) term added to the cross-attention formulation, which well guides each query to attend to the corresponding object region while also providing encoding flexibility.","meta":{"url":"http://arxiv.org/abs/2308.01904v1"},"cats":{"new-dataset":0.0896505879,"dev-research":0.2128126552,"prompt-eng":0.3979085665,"data-quality":0.1164009982,"ml-security":0.0507008836}}
{"text":"The second is masked image modeling (MIM)-based backbone pre-training which helps learn representation with fine-grained localization ability and proves crucial for remedying dependencies on the multi-scale feature maps.","meta":{"url":"http://arxiv.org/abs/2308.01904v1"},"cats":{"new-dataset":0.1637425043,"dev-research":0.2441613934,"prompt-eng":0.4047208064,"data-quality":0.1890103974,"ml-security":0.1821768841}}
{"text":"By incorporating these technologies and recent advancements in training and problem formation, the improved \"plain\" DETR showed exceptional improvements over the original DETR detector.","meta":{"url":"http://arxiv.org/abs/2308.01904v1"},"cats":{"new-dataset":0.1333251566,"dev-research":0.3136441859,"prompt-eng":0.4898686072,"data-quality":0.3451665744,"ml-security":0.1792305303}}
{"text":"By leveraging the Object365 dataset for pre-training, it achieved 63.9 mAP accuracy using a Swin-L backbone, which is highly competitive with state-of-the-art detectors which all heavily rely on multi-scale feature maps and region-based feature extraction.","meta":{"url":"http://arxiv.org/abs/2308.01904v1"},"cats":{"new-dataset":0.422284798,"dev-research":0.2560074813,"prompt-eng":0.4034983207,"data-quality":0.2578933543,"ml-security":0.1235712508}}
{"text":"Code is available at https://github.com/impiga/Plain-DETR .","meta":{"url":"http://arxiv.org/abs/2308.01904v1"},"cats":{"new-dataset":0.1724240698,"dev-research":0.2151439841,"prompt-eng":0.4642938436,"data-quality":0.14497314,"ml-security":0.1317992792}}
{"text":"Preprints play an increasingly critical role in academic communities.","meta":{"url":"http://arxiv.org/abs/2308.01899v1"},"cats":{"new-dataset":0.0803584214,"dev-research":0.4061555461,"prompt-eng":0.336441695,"data-quality":0.1914248782,"ml-security":0.1394714427}}
{"text":"There are many reasons driving researchers to post their manuscripts to preprint servers before formal submission to journals or conferences, but the use of preprints has also sparked considerable controversy, especially surrounding the claim of priority.","meta":{"url":"http://arxiv.org/abs/2308.01899v1"},"cats":{"new-dataset":0.021628658,"dev-research":0.4278626007,"prompt-eng":0.3583519513,"data-quality":0.2002437615,"ml-security":0.1798845892}}
{"text":"In this paper, a case study of computer science preprints submitted to arXiv from 2008 to 2017 is conducted to quantify how many preprints have eventually been printed in peer-reviewed venues.","meta":{"url":"http://arxiv.org/abs/2308.01899v1"},"cats":{"new-dataset":0.1796902999,"dev-research":0.3830284563,"prompt-eng":0.4242417548,"data-quality":0.2331725486,"ml-security":0.1074812761}}
{"text":"Among those published manuscripts, some are published under different titles and without an update to their preprints on arXiv.","meta":{"url":"http://arxiv.org/abs/2308.01899v1"},"cats":{"new-dataset":0.1840169768,"dev-research":0.2038402313,"prompt-eng":0.3216363585,"data-quality":0.2822438333,"ml-security":0.083565715}}
{"text":"In the case of these manuscripts, the traditional fuzzy matching method is incapable of mapping the preprint to the final published version.","meta":{"url":"http://arxiv.org/abs/2308.01899v1"},"cats":{"new-dataset":0.0895177887,"dev-research":0.2029419041,"prompt-eng":0.3701163272,"data-quality":0.3554849444,"ml-security":0.0649003225}}
{"text":"In view of this issue, we introduce a semantics-based mapping method with the employment of Bidirectional Encoder Representations from Transformers (BERT).","meta":{"url":"http://arxiv.org/abs/2308.01899v1"},"cats":{"new-dataset":0.1484923532,"dev-research":0.2631078718,"prompt-eng":0.3917642082,"data-quality":0.1459037576,"ml-security":0.0818463668}}
{"text":"With this new mapping method and a plurality of data sources, we find that 66% of all sampled preprints are published under unchanged titles and 11% are published under different titles and with other modifications.","meta":{"url":"http://arxiv.org/abs/2308.01899v1"},"cats":{"new-dataset":0.4264707365,"dev-research":0.1849109806,"prompt-eng":0.399283806,"data-quality":0.3179263569,"ml-security":0.0615859731}}
{"text":"A further analysis was then performed to investigate why these preprints but not others were accepted for publication.","meta":{"url":"http://arxiv.org/abs/2308.01899v1"},"cats":{"new-dataset":0.0430606289,"dev-research":0.2495349137,"prompt-eng":0.2909222609,"data-quality":0.2559163365,"ml-security":0.0990838781}}
{"text":"Our comparison reveals that in the field of computer science, published preprints feature adequate revisions, multiple authorship, detailed abstract and introduction, extensive and authoritative references and available source code.","meta":{"url":"http://arxiv.org/abs/2308.01899v1"},"cats":{"new-dataset":0.2219215661,"dev-research":0.4052048455,"prompt-eng":0.4010529382,"data-quality":0.2348457941,"ml-security":0.0787407927}}
{"text":"Rigorously testing autonomy systems is essential for making safe self-driving vehicles (SDV) a reality.","meta":{"url":"http://arxiv.org/abs/2308.01898v1"},"cats":{"new-dataset":0.1130790094,"dev-research":0.4039404767,"prompt-eng":0.4381910043,"data-quality":0.1519426744,"ml-security":0.2164301235}}
{"text":"It requires one to generate safety critical scenarios beyond what can be collected safely in the world, as many scenarios happen rarely on public roads.","meta":{"url":"http://arxiv.org/abs/2308.01898v1"},"cats":{"new-dataset":0.0777222264,"dev-research":0.3393436717,"prompt-eng":0.3829469273,"data-quality":0.1077292536,"ml-security":0.2928627796}}
{"text":"To accurately evaluate performance, we need to test the SDV on these scenarios in closed-loop, where the SDV and other actors interact with each other at each timestep.","meta":{"url":"http://arxiv.org/abs/2308.01898v1"},"cats":{"new-dataset":0.1778590291,"dev-research":0.3125504523,"prompt-eng":0.4331720739,"data-quality":0.1493043602,"ml-security":0.0747387042}}
{"text":"Previously recorded driving logs provide a rich resource to build these new scenarios from, but for closed loop evaluation, we need to modify the sensor data based on the new scene configuration and the SDV's decisions, as actors might be added or removed and the trajectories of existing actors and the SDV will differ from the original log.","meta":{"url":"http://arxiv.org/abs/2308.01898v1"},"cats":{"new-dataset":0.5816414353,"dev-research":0.2875233904,"prompt-eng":0.4141700789,"data-quality":0.1431393636,"ml-security":0.0754080429}}
{"text":"In this paper, we present UniSim, a neural sensor simulator that takes a single recorded log captured by a sensor-equipped vehicle and converts it into a realistic closed-loop multi-sensor simulation.","meta":{"url":"http://arxiv.org/abs/2308.01898v1"},"cats":{"new-dataset":0.4146002652,"dev-research":0.2313384979,"prompt-eng":0.3945067243,"data-quality":0.1300974787,"ml-security":0.1490700833}}
{"text":"UniSim builds neural feature grids to reconstruct both the static background and dynamic actors in the scene, and composites them together to simulate LiDAR and camera data at new viewpoints, with actors added or removed and at new placements.","meta":{"url":"http://arxiv.org/abs/2308.01898v1"},"cats":{"new-dataset":0.3659917057,"dev-research":0.3229567882,"prompt-eng":0.3666759632,"data-quality":0.0996111424,"ml-security":0.152148231}}
{"text":"To better handle extrapolated views, we incorporate learnable priors for dynamic objects, and leverage a convolutional network to complete unseen regions.","meta":{"url":"http://arxiv.org/abs/2308.01898v1"},"cats":{"new-dataset":0.2998200958,"dev-research":0.2106098974,"prompt-eng":0.3621995889,"data-quality":0.2023101237,"ml-security":0.156822363}}
{"text":"Our experiments show UniSim can simulate realistic sensor data with small domain gap on downstream tasks.","meta":{"url":"http://arxiv.org/abs/2308.01898v1"},"cats":{"new-dataset":0.3423744166,"dev-research":0.2058725851,"prompt-eng":0.421150993,"data-quality":0.145106704,"ml-security":0.1162617037}}
{"text":"With UniSim, we demonstrate closed-loop evaluation of an autonomy system on safety-critical scenarios as if it were in the real world.","meta":{"url":"http://arxiv.org/abs/2308.01898v1"},"cats":{"new-dataset":0.3733615619,"dev-research":0.393764584,"prompt-eng":0.4772381751,"data-quality":0.1751738795,"ml-security":0.1833488735}}
{"text":"Continual learning seeks to enable deep learners to train on a series of tasks of unknown length without suffering from the catastrophic forgetting of previous tasks.","meta":{"url":"http://arxiv.org/abs/2308.01895v1"},"cats":{"new-dataset":0.0547536472,"dev-research":0.2619564097,"prompt-eng":0.3209518683,"data-quality":0.2094300892,"ml-security":0.1899076606}}
{"text":"One effective solution is replay, which involves storing few previous experiences in memory and replaying them when learning the current task.","meta":{"url":"http://arxiv.org/abs/2308.01895v1"},"cats":{"new-dataset":0.0262248162,"dev-research":0.3574804402,"prompt-eng":0.4533613063,"data-quality":0.1444182933,"ml-security":0.0897853113}}
{"text":"However, there is still room for improvement when it comes to selecting the most informative samples for storage and determining the optimal number of samples to be stored.","meta":{"url":"http://arxiv.org/abs/2308.01895v1"},"cats":{"new-dataset":0.0925627547,"dev-research":0.2529561755,"prompt-eng":0.3729667074,"data-quality":0.2124280861,"ml-security":0.0818889375}}
{"text":"This study aims to address these issues with a novel comparison of the commonly used reservoir sampling to various alternative population strategies and providing a novel detailed analysis of how to find the optimal number of stored samples.","meta":{"url":"http://arxiv.org/abs/2308.01895v1"},"cats":{"new-dataset":0.0976491445,"dev-research":0.2064320799,"prompt-eng":0.4007115575,"data-quality":0.1477580765,"ml-security":0.0886342734}}
{"text":"Identification of nonlinear dynamical systems has been popularized by sparse identification of the nonlinear dynamics (SINDy) via the sequentially thresholded least squares (STLS) algorithm.","meta":{"url":"http://arxiv.org/abs/2308.01891v1"},"cats":{"new-dataset":0.026609561,"dev-research":0.1698429593,"prompt-eng":0.3737100305,"data-quality":0.1384916864,"ml-security":0.1852448658}}
{"text":"Many extensions SINDy have emerged in the literature to deal with experimental data which are finite in length and noisy.","meta":{"url":"http://arxiv.org/abs/2308.01891v1"},"cats":{"new-dataset":0.1265844585,"dev-research":0.1859965258,"prompt-eng":0.3772994704,"data-quality":0.1690046258,"ml-security":0.0951850991}}
{"text":"Recently, the computationally intensive method of ensembling bootstrapped SINDy models (E-SINDy) was proposed for model identification, handling finite, highly noisy data.","meta":{"url":"http://arxiv.org/abs/2308.01891v1"},"cats":{"new-dataset":0.122526419,"dev-research":0.2034988502,"prompt-eng":0.3986221104,"data-quality":0.2248171675,"ml-security":0.1217740099}}
{"text":"While the extensions of SINDy are numerous, their sparsity-promoting estimators occasionally provide sparse approximations of the dynamics as opposed to exact recovery.","meta":{"url":"http://arxiv.org/abs/2308.01891v1"},"cats":{"new-dataset":0.056315692,"dev-research":0.1523808023,"prompt-eng":0.337731552,"data-quality":0.14446745,"ml-security":0.1236962873}}
{"text":"Furthermore, these estimators suffer under multicollinearity, e.g. the irrepresentable condition for the Lasso.","meta":{"url":"http://arxiv.org/abs/2308.01891v1"},"cats":{"new-dataset":0.0395971027,"dev-research":0.1479087759,"prompt-eng":0.328487986,"data-quality":0.2292029194,"ml-security":0.1984346733}}
{"text":"In this paper, we demonstrate that the Trimmed Lasso for robust identification of models (TRIM) can provide exact recovery under more severe noise, finite data, and multicollinearity as opposed to E-SINDy.","meta":{"url":"http://arxiv.org/abs/2308.01891v1"},"cats":{"new-dataset":0.0960048395,"dev-research":0.1467367594,"prompt-eng":0.3688728414,"data-quality":0.3119386867,"ml-security":0.2409468474}}
{"text":"Additionally, the computational cost of TRIM is asymptotically equal to STLS since the sparsity parameter of the TRIM can be solved efficiently by convex solvers.","meta":{"url":"http://arxiv.org/abs/2308.01891v1"},"cats":{"new-dataset":0.0141304326,"dev-research":0.1671829369,"prompt-eng":0.3420024335,"data-quality":0.1222637476,"ml-security":0.1157318877}}
{"text":"We compare these methodologies on challenging nonlinear systems, specifically the Lorenz 63 system, the Bouc Wen oscillator from the nonlinear dynamics benchmark of No\\\"el and Schoukens, 2016, and a time delay system describing tool cutting dynamics.","meta":{"url":"http://arxiv.org/abs/2308.01891v1"},"cats":{"new-dataset":0.1467662037,"dev-research":0.2408012834,"prompt-eng":0.3606222172,"data-quality":0.096275792,"ml-security":0.0583222728}}
{"text":"This study emphasizes the comparisons between STLS, reweighted $\\ell_1$ minimization, and Trimmed Lasso in identification with respect to problems faced by practitioners: the problem of finite and noisy data, the performance of the sparse regression of when the library grows in dimension (multicollinearity), and automatic methods for choice of regularization parameters.","meta":{"url":"http://arxiv.org/abs/2308.01891v1"},"cats":{"new-dataset":0.0473491115,"dev-research":0.1816826481,"prompt-eng":0.3700388589,"data-quality":0.291058325,"ml-security":0.2092607401}}
{"text":"Multi-label image recognition in the low-label regime is a task of great challenge and practical significance.","meta":{"url":"http://arxiv.org/abs/2308.01890v1"},"cats":{"new-dataset":0.0665068359,"dev-research":0.1325619906,"prompt-eng":0.3942092573,"data-quality":0.4433915902,"ml-security":0.0970829956}}
{"text":"Previous works have focused on learning the alignment between textual and visual spaces to compensate for limited image labels, yet may suffer from reduced accuracy due to the scarcity of high-quality multi-label annotations.","meta":{"url":"http://arxiv.org/abs/2308.01890v1"},"cats":{"new-dataset":0.2626736573,"dev-research":0.2281955801,"prompt-eng":0.3898167963,"data-quality":0.5266349645,"ml-security":0.0740392442}}
{"text":"In this research, we leverage the powerful alignment between textual and visual features pretrained with millions of auxiliary image-text pairs.","meta":{"url":"http://arxiv.org/abs/2308.01890v1"},"cats":{"new-dataset":0.3892488554,"dev-research":0.2496628872,"prompt-eng":0.3652985657,"data-quality":0.2015203135,"ml-security":0.0803170741}}
{"text":"We introduce an efficient and effective framework called Evidence-guided Dual Context Optimization (DualCoOp++), which serves as a unified approach for addressing partial-label and zero-shot multi-label recognition.","meta":{"url":"http://arxiv.org/abs/2308.01890v1"},"cats":{"new-dataset":0.2433374794,"dev-research":0.1934806583,"prompt-eng":0.3896052073,"data-quality":0.4316062509,"ml-security":0.1034196825}}
{"text":"In DualCoOp++ we separately encode evidential, positive, and negative contexts for target classes as parametric components of the linguistic input (i.e., prompts).","meta":{"url":"http://arxiv.org/abs/2308.01890v1"},"cats":{"new-dataset":0.0612742023,"dev-research":0.2951629243,"prompt-eng":0.503266699,"data-quality":0.3580839348,"ml-security":0.2153954528}}
{"text":"The evidential context aims to discover all the related visual content for the target class, and serves as guidance to aggregate positive and negative contexts from the spatial domain of the image, enabling better distinguishment between similar categories.","meta":{"url":"http://arxiv.org/abs/2308.01890v1"},"cats":{"new-dataset":0.0945326271,"dev-research":0.23272108,"prompt-eng":0.4220517418,"data-quality":0.3036505015,"ml-security":0.1039421679}}
{"text":"Additionally, we introduce a Winner-Take-All module that promotes inter-class interaction during training, while avoiding the need for extra parameters and costs.","meta":{"url":"http://arxiv.org/abs/2308.01890v1"},"cats":{"new-dataset":0.1507421161,"dev-research":0.2916754013,"prompt-eng":0.4541164912,"data-quality":0.1442055815,"ml-security":0.1601681449}}
{"text":"As DualCoOp++ imposes minimal additional learnable overhead on the pretrained vision-language framework, it enables rapid adaptation to multi-label recognition tasks with limited annotations and even unseen classes.","meta":{"url":"http://arxiv.org/abs/2308.01890v1"},"cats":{"new-dataset":0.2151500766,"dev-research":0.2329516879,"prompt-eng":0.3788429438,"data-quality":0.394756697,"ml-security":0.122161607}}
{"text":"Experiments on standard multi-label recognition benchmarks across two challenging low-label settings demonstrate the superior performance of our approach compared to state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2308.01890v1"},"cats":{"new-dataset":0.1441385786,"dev-research":0.1598082125,"prompt-eng":0.4083506308,"data-quality":0.6163833969,"ml-security":0.068259594}}
{"text":"Emerging technologies in the domain of extended reality offer rich, new possibilities for the study and practice of joint music performance.","meta":{"url":"http://arxiv.org/abs/2308.01889v1"},"cats":{"new-dataset":0.0548954927,"dev-research":0.270626736,"prompt-eng":0.3263654013,"data-quality":0.1098564793,"ml-security":0.0341146448}}
{"text":"Apart from the technological challenges, bringing music players together in extended reality raises important questions on their performance and embodied coordination.","meta":{"url":"http://arxiv.org/abs/2308.01889v1"},"cats":{"new-dataset":0.0485125956,"dev-research":0.3520467043,"prompt-eng":0.3288106981,"data-quality":0.0896037022,"ml-security":0.0647120678}}
{"text":"In this study, we designed an extended reality platform to assess a remote, bidirectional polyrhythmic interaction between two players, mediated in real time by their three-dimensional embodied avatars and a shared, virtual drum circle.","meta":{"url":"http://arxiv.org/abs/2308.01889v1"},"cats":{"new-dataset":0.140616731,"dev-research":0.3109177101,"prompt-eng":0.4080714758,"data-quality":0.0788517098,"ml-security":0.0803471312}}
{"text":"We leveraged a multi-layered analysis framework to assess their performance quality, embodied co-regulation and first-person interaction experience, using statistical techniques for time-series analysis and mixed-effect regression and focusing on contrasts of visual coupling (not seeing / seeing as avatars / seeing as real) and auditory context (metronome / music).","meta":{"url":"http://arxiv.org/abs/2308.01889v1"},"cats":{"new-dataset":0.0742232314,"dev-research":0.4023159963,"prompt-eng":0.3597958904,"data-quality":0.1332536657,"ml-security":0.0615519915}}
{"text":"Results reveal that an auditory context with music improved the performance output as measured by a prediction error, increased movement energy and levels of experienced agency.","meta":{"url":"http://arxiv.org/abs/2308.01889v1"},"cats":{"new-dataset":0.0181791025,"dev-research":0.3117962507,"prompt-eng":0.34159901,"data-quality":0.2063946287,"ml-security":0.065026107}}
{"text":"Visual coupling impacted experiential qualities and induced prosocial effects with increased levels of partner realism resulting in increased levels of shared agency and self-other merging.","meta":{"url":"http://arxiv.org/abs/2308.01889v1"},"cats":{"new-dataset":0.0320473144,"dev-research":0.3156591129,"prompt-eng":0.3258662932,"data-quality":0.1134311119,"ml-security":0.0805091466}}
{"text":"Embodied co-regulation between players was impacted by auditory context, visual coupling, and task complexity, suggesting prediction-based compensatory mechanisms to deal with the novelty, difficulty, and expressivity in the musical interaction.","meta":{"url":"http://arxiv.org/abs/2308.01889v1"},"cats":{"new-dataset":0.0156933633,"dev-research":0.4076703492,"prompt-eng":0.3512570885,"data-quality":0.1274754137,"ml-security":0.0870745981}}
{"text":"This study contributes to the understanding of music performance in extended reality by using a methodological approach to demonstrate how co-regulation between players is impacted by visual coupling and auditory context and provides a basis and future directions for further action-oriented research.","meta":{"url":"http://arxiv.org/abs/2308.01889v1"},"cats":{"new-dataset":0.0397752871,"dev-research":0.3976975323,"prompt-eng":0.3366901955,"data-quality":0.1403696274,"ml-security":0.0510441935}}
{"text":"Object detection is a vital task in computer vision and has become an integral component of numerous critical systems.","meta":{"url":"http://arxiv.org/abs/2308.01888v1"},"cats":{"new-dataset":0.0425815935,"dev-research":0.2101700978,"prompt-eng":0.4057652856,"data-quality":0.2380014157,"ml-security":0.1595974825}}
{"text":"However, state-of-the-art object detectors, similar to their classification counterparts, are susceptible to small adversarial perturbations that can significantly alter their normal behavior.","meta":{"url":"http://arxiv.org/abs/2308.01888v1"},"cats":{"new-dataset":0.0494338632,"dev-research":0.1824967822,"prompt-eng":0.3651795957,"data-quality":0.4468051539,"ml-security":0.5315600576}}
{"text":"Unlike classification, the robustness of object detectors has not been thoroughly explored.","meta":{"url":"http://arxiv.org/abs/2308.01888v1"},"cats":{"new-dataset":0.0332197146,"dev-research":0.1550186932,"prompt-eng":0.3748406524,"data-quality":0.4728775999,"ml-security":0.3012270934}}
{"text":"In this work, we take the initial step towards bridging the gap between the robustness of classification and object detection by leveraging adversarially trained classification models.","meta":{"url":"http://arxiv.org/abs/2308.01888v1"},"cats":{"new-dataset":0.1367444444,"dev-research":0.1977047711,"prompt-eng":0.3651281824,"data-quality":0.4849453422,"ml-security":0.5105198365}}
{"text":"Merely utilizing adversarially trained models as backbones for object detection does not result in robustness.","meta":{"url":"http://arxiv.org/abs/2308.01888v1"},"cats":{"new-dataset":0.0201305361,"dev-research":0.1910202464,"prompt-eng":0.3723876902,"data-quality":0.3565298698,"ml-security":0.5894530005}}
{"text":"We propose effective modifications to the classification-based backbone to instill robustness in object detection without incurring any computational overhead.","meta":{"url":"http://arxiv.org/abs/2308.01888v1"},"cats":{"new-dataset":0.0783969222,"dev-research":0.2192436989,"prompt-eng":0.407502838,"data-quality":0.3670233072,"ml-security":0.4267125575}}
{"text":"To further enhance the robustness achieved by the proposed modified backbone, we introduce two lightweight components: imitation loss and delayed adversarial training.","meta":{"url":"http://arxiv.org/abs/2308.01888v1"},"cats":{"new-dataset":0.1510874426,"dev-research":0.1878653867,"prompt-eng":0.3832212573,"data-quality":0.1915480534,"ml-security":0.3354073107}}
{"text":"Extensive experiments on the MS-COCO and Pascal VOC datasets are conducted to demonstrate the effectiveness of our proposed approach.","meta":{"url":"http://arxiv.org/abs/2308.01888v1"},"cats":{"new-dataset":0.4235022217,"dev-research":0.1981033813,"prompt-eng":0.4032291831,"data-quality":0.2706758995,"ml-security":0.0731950515}}
{"text":"Conversational agents are consistently growing in popularity and many people interact with them every day.","meta":{"url":"http://arxiv.org/abs/2308.01887v1"},"cats":{"new-dataset":0.1326835186,"dev-research":0.2648109424,"prompt-eng":0.3225996338,"data-quality":0.1060365011,"ml-security":0.1085471203}}
{"text":"While many conversational agents act as personal assistants, they can have many different goals.","meta":{"url":"http://arxiv.org/abs/2308.01887v1"},"cats":{"new-dataset":0.0437368851,"dev-research":0.2657235438,"prompt-eng":0.3500855004,"data-quality":0.0933984134,"ml-security":0.0991514373}}
{"text":"Some are task-oriented, such as providing customer support for a bank or making a reservation.","meta":{"url":"http://arxiv.org/abs/2308.01887v1"},"cats":{"new-dataset":0.0521543688,"dev-research":0.3199034231,"prompt-eng":0.3965897307,"data-quality":0.1239147583,"ml-security":0.0588005057}}
{"text":"Others are designed to be empathetic and to form emotional connections with the user.","meta":{"url":"http://arxiv.org/abs/2308.01887v1"},"cats":{"new-dataset":0.0145582208,"dev-research":0.3876630209,"prompt-eng":0.3737710771,"data-quality":0.1265184835,"ml-security":0.1244338224}}
{"text":"The Alexa Prize Challenge aims to create a socialbot, which allows the user to engage in coherent conversations, on a range of popular topics that will interest the user.","meta":{"url":"http://arxiv.org/abs/2308.01887v1"},"cats":{"new-dataset":0.1344059166,"dev-research":0.2734221936,"prompt-eng":0.4014299638,"data-quality":0.1374997976,"ml-security":0.1090180432}}
{"text":"Here we describe Athena 2.0, UCSC's conversational agent for Amazon's Socialbot Grand Challenge 4.","meta":{"url":"http://arxiv.org/abs/2308.01887v1"},"cats":{"new-dataset":0.7028817785,"dev-research":0.2301285083,"prompt-eng":0.4320718189,"data-quality":0.1507530539,"ml-security":0.0689392645}}
{"text":"Athena 2.0 utilizes a novel knowledge-grounded discourse model that tracks the entity links that Athena introduces into the dialogue, and uses them to constrain named-entity recognition and linking, and coreference resolution.","meta":{"url":"http://arxiv.org/abs/2308.01887v1"},"cats":{"new-dataset":0.4410511184,"dev-research":0.3231695836,"prompt-eng":0.4150228525,"data-quality":0.2328866863,"ml-security":0.0585299614}}
{"text":"Athena 2.0 also relies on a user model to personalize topic selection and other aspects of the conversation to individual users.","meta":{"url":"http://arxiv.org/abs/2308.01887v1"},"cats":{"new-dataset":0.1163118379,"dev-research":0.2884375321,"prompt-eng":0.4554966145,"data-quality":0.143332783,"ml-security":0.0466338236}}
{"text":"Text-adventure games and text role-playing games are grand challenges for reinforcement learning game playing agents.","meta":{"url":"http://arxiv.org/abs/2308.01872v1"},"cats":{"new-dataset":0.1359516179,"dev-research":0.2548599055,"prompt-eng":0.3533546276,"data-quality":0.1151540377,"ml-security":0.1608583821}}
{"text":"Text role-playing games are open-ended environments where an agent must faithfully play a particular character.","meta":{"url":"http://arxiv.org/abs/2308.01872v1"},"cats":{"new-dataset":0.2747666467,"dev-research":0.3048749855,"prompt-eng":0.3819702871,"data-quality":0.1300330342,"ml-security":0.1877472223}}
{"text":"We consider the distinction between characters and actors, where an actor agent has the ability to play multiple characters.","meta":{"url":"http://arxiv.org/abs/2308.01872v1"},"cats":{"new-dataset":0.0607610615,"dev-research":0.2557518581,"prompt-eng":0.3313657026,"data-quality":0.0881035348,"ml-security":0.0828413993}}
{"text":"We present a framework we call a thespian agent that can learn to emulate multiple characters along with a soft prompt that can be used to direct it as to which character to play at any time.","meta":{"url":"http://arxiv.org/abs/2308.01872v1"},"cats":{"new-dataset":0.2905983413,"dev-research":0.2920794202,"prompt-eng":0.5232424938,"data-quality":0.0893973404,"ml-security":0.1399952484}}
{"text":"We further describe an attention mechanism that allows the agent to learn new characters that are based on previously learned characters in a few-shot fashion.","meta":{"url":"http://arxiv.org/abs/2308.01872v1"},"cats":{"new-dataset":0.1606311631,"dev-research":0.2734066477,"prompt-eng":0.4345513451,"data-quality":0.1244714196,"ml-security":0.1810243349}}
{"text":"We show that our agent outperforms the state of the art agent framework in multi-character learning and few-shot learning.","meta":{"url":"http://arxiv.org/abs/2308.01872v1"},"cats":{"new-dataset":0.1864433818,"dev-research":0.1797905131,"prompt-eng":0.3523728088,"data-quality":0.1326609653,"ml-security":0.1230451342}}
{"text":"In the past decade, the amount of research being done in the fields of machine learning and deep learning, predominantly in the area of natural language processing (NLP), has risen dramatically.","meta":{"url":"http://arxiv.org/abs/2308.01863v1"},"cats":{"new-dataset":0.248275831,"dev-research":0.2112312334,"prompt-eng":0.3313180881,"data-quality":0.1892448603,"ml-security":0.1071326279}}
{"text":"A well-liked method for developing programming abilities like logic building and problem solving is competitive programming.","meta":{"url":"http://arxiv.org/abs/2308.01863v1"},"cats":{"new-dataset":0.0293415653,"dev-research":0.4917962738,"prompt-eng":0.3675198039,"data-quality":0.0707058773,"ml-security":0.088270616}}
{"text":"It can be tough for novices and even veteran programmers to traverse the wide collection of questions due to the massive number of accessible questions and the variety of themes, levels of difficulty, and questions offered.","meta":{"url":"http://arxiv.org/abs/2308.01863v1"},"cats":{"new-dataset":0.0995379756,"dev-research":0.4681334955,"prompt-eng":0.4902496159,"data-quality":0.1380140093,"ml-security":0.0934705174}}
{"text":"In order to help programmers find questions that are appropriate for their knowledge and interests, there is a need for an automated method.","meta":{"url":"http://arxiv.org/abs/2308.01863v1"},"cats":{"new-dataset":0.0290139248,"dev-research":0.5199654386,"prompt-eng":0.5459624703,"data-quality":0.1913469039,"ml-security":0.07310262}}
{"text":"This can be done using automated tagging of the questions using Text Classification.","meta":{"url":"http://arxiv.org/abs/2308.01863v1"},"cats":{"new-dataset":0.0613021382,"dev-research":0.2934039203,"prompt-eng":0.5281935225,"data-quality":0.395845822,"ml-security":0.0743663598}}
{"text":"Text classification is one of the important tasks widely researched in the field of Natural Language Processing.","meta":{"url":"http://arxiv.org/abs/2308.01863v1"},"cats":{"new-dataset":0.065827339,"dev-research":0.214456734,"prompt-eng":0.3709732422,"data-quality":0.3785419867,"ml-security":0.1276715801}}
{"text":"In this paper, we present a way to use text classification techniques to determine the domain of a competitive programming problem.","meta":{"url":"http://arxiv.org/abs/2308.01863v1"},"cats":{"new-dataset":0.128069205,"dev-research":0.3037637118,"prompt-eng":0.399094142,"data-quality":0.3080668934,"ml-security":0.1573277882}}
{"text":"A variety of models, including are implemented LSTM, GRU, and MLP.","meta":{"url":"http://arxiv.org/abs/2308.01863v1"},"cats":{"new-dataset":0.253620455,"dev-research":0.1655723326,"prompt-eng":0.4339550533,"data-quality":0.1064606472,"ml-security":0.0687996712}}
{"text":"The dataset has been scraped from Codeforces, a major competitive programming website.","meta":{"url":"http://arxiv.org/abs/2308.01863v1"},"cats":{"new-dataset":0.8727101944,"dev-research":0.2361406826,"prompt-eng":0.3363188999,"data-quality":0.091561778,"ml-security":0.086656215}}
{"text":"A total of 2400 problems were scraped and preprocessed, which we used as a dataset for our training and testing of models.","meta":{"url":"http://arxiv.org/abs/2308.01863v1"},"cats":{"new-dataset":0.5732175918,"dev-research":0.3389540214,"prompt-eng":0.3859318125,"data-quality":0.20479402,"ml-security":0.1064049393}}
{"text":"The maximum accuracy reached using our model is 78.0% by MLP(Multi Layer Perceptron).","meta":{"url":"http://arxiv.org/abs/2308.01863v1"},"cats":{"new-dataset":0.1455565568,"dev-research":0.1446162539,"prompt-eng":0.3807518714,"data-quality":0.1959708418,"ml-security":0.0614904178}}
{"text":"Measuring the quality of responses generated by LLMs is a challenging task, particularly when it comes to evaluating whether the response is aligned with human preference.","meta":{"url":"http://arxiv.org/abs/2308.01862v1"},"cats":{"new-dataset":0.0320655321,"dev-research":0.1966867853,"prompt-eng":0.5216922444,"data-quality":0.2914837528,"ml-security":0.1065652142}}
{"text":"A novel approach involves using the LLM itself to make evaluation and stabilizing the results through multiple independent evaluations, similar to a single-layer narrow LLM network.","meta":{"url":"http://arxiv.org/abs/2308.01862v1"},"cats":{"new-dataset":0.0221088957,"dev-research":0.2587499448,"prompt-eng":0.463322784,"data-quality":0.2478062161,"ml-security":0.0914999125}}
{"text":"This network consists of a fixed number of neurons, with each neuron being the same LLM.","meta":{"url":"http://arxiv.org/abs/2308.01862v1"},"cats":{"new-dataset":0.1244035614,"dev-research":0.144875027,"prompt-eng":0.340870045,"data-quality":0.1118349757,"ml-security":0.114864585}}
{"text":"In this paper, we draw upon the extensive research on deep neural networks to explore whether deeper and wider networks can lead to fairer evaluations.","meta":{"url":"http://arxiv.org/abs/2308.01862v1"},"cats":{"new-dataset":0.0501110969,"dev-research":0.2635033898,"prompt-eng":0.3249717153,"data-quality":0.3234743436,"ml-security":0.4020800431}}
{"text":"Specifically, inspired by the observation that different neurons in a neural network are responsible for detecting different concepts, we first adaptively generate as many neuron roles as possible for each evaluation sample.","meta":{"url":"http://arxiv.org/abs/2308.01862v1"},"cats":{"new-dataset":0.0360868514,"dev-research":0.2706124162,"prompt-eng":0.4307669417,"data-quality":0.2850744143,"ml-security":0.2090992932}}
{"text":"Each perspective corresponds to the role of a specific LLM neuron in the first layer.","meta":{"url":"http://arxiv.org/abs/2308.01862v1"},"cats":{"new-dataset":0.0367430994,"dev-research":0.1512489196,"prompt-eng":0.3459679679,"data-quality":0.0633758844,"ml-security":0.0913812515}}
{"text":"In subsequent layers, we follow the idea that higher layers in deep networks are responsible for more comprehensive features, each layer receives representations from all neurons in the previous layer, integrating the locally learned evaluation information to obtain a more comprehensive evaluation result.","meta":{"url":"http://arxiv.org/abs/2308.01862v1"},"cats":{"new-dataset":0.1467056219,"dev-research":0.289719853,"prompt-eng":0.353412931,"data-quality":0.2553691783,"ml-security":0.2023099482}}
{"text":"Interestingly, this network design resembles the process of academic paper reviewing.","meta":{"url":"http://arxiv.org/abs/2308.01862v1"},"cats":{"new-dataset":0.034625601,"dev-research":0.2667408351,"prompt-eng":0.3931612312,"data-quality":0.1525222875,"ml-security":0.055767526}}
{"text":"To validate the effectiveness of our method, we construct the largest and most diverse English evaluation benchmark LLMEval$^2$ for LLM evaluators, comprising 15 tasks, 8 abilities, and 2,553 samples.","meta":{"url":"http://arxiv.org/abs/2308.01862v1"},"cats":{"new-dataset":0.1366246857,"dev-research":0.2424682924,"prompt-eng":0.4604882467,"data-quality":0.3089988103,"ml-security":0.0920938189}}
{"text":"Experimental results demonstrate that a wider network (involving many reviewers) with 2 layers (one round of discussion) performs the best, improving kappa correlation coefficient from 0.28 to 0.34.","meta":{"url":"http://arxiv.org/abs/2308.01862v1"},"cats":{"new-dataset":0.0632475854,"dev-research":0.2257572656,"prompt-eng":0.4102246512,"data-quality":0.2418630429,"ml-security":0.0678403932}}
{"text":"We also leverage WideDeep to aid in the assessment of Chinese LLMs, which has accelerated the evaluation time by 4.6 times, resulting in a 60% cost saving.","meta":{"url":"http://arxiv.org/abs/2308.01862v1"},"cats":{"new-dataset":0.0870033053,"dev-research":0.193547493,"prompt-eng":0.4434491198,"data-quality":0.1059355096,"ml-security":0.0640016151}}
{"text":"WideDeep achieves a remarkable 93% agreement level among humans.","meta":{"url":"http://arxiv.org/abs/2308.01862v1"},"cats":{"new-dataset":0.1327236672,"dev-research":0.2431916943,"prompt-eng":0.3804470873,"data-quality":0.163450364,"ml-security":0.0972867791}}
{"text":"In this work, we make the first attempt to evaluate LLMs in a more challenging code generation scenario, i.e. class-level code generation.","meta":{"url":"http://arxiv.org/abs/2308.01861v1"},"cats":{"new-dataset":0.2198537961,"dev-research":0.319029913,"prompt-eng":0.4871514387,"data-quality":0.2389889854,"ml-security":0.1536225539}}
{"text":"We first manually construct the first class-level code generation benchmark ClassEval of 100 class-level Python code generation tasks with approximately 500 person-hours.","meta":{"url":"http://arxiv.org/abs/2308.01861v1"},"cats":{"new-dataset":0.4678351291,"dev-research":0.416744853,"prompt-eng":0.4419243563,"data-quality":0.1662264152,"ml-security":0.0864128582}}
{"text":"Based on it, we then perform the first study of 11 state-of-the-art LLMs on class-level code generation.","meta":{"url":"http://arxiv.org/abs/2308.01861v1"},"cats":{"new-dataset":0.2736285204,"dev-research":0.3378256118,"prompt-eng":0.4843082873,"data-quality":0.1947737422,"ml-security":0.1168365604}}
{"text":"Based on our results, we have the following main findings.","meta":{"url":"http://arxiv.org/abs/2308.01861v1"},"cats":{"new-dataset":0.4225785602,"dev-research":0.1626819773,"prompt-eng":0.3970239763,"data-quality":0.2226350448,"ml-security":0.093783863}}
{"text":"First, we find that all existing LLMs show much worse performance on class-level code generation compared to on standalone method-level code generation benchmarks like HumanEval; and the method-level coding ability cannot equivalently reflect the class-level coding ability among LLMs.","meta":{"url":"http://arxiv.org/abs/2308.01861v1"},"cats":{"new-dataset":0.0459570948,"dev-research":0.3621590648,"prompt-eng":0.4476928913,"data-quality":0.246871901,"ml-security":0.1769181269}}
{"text":"Second, we find that GPT-4 and GPT-3.5 still exhibit dominate superior than other LLMs on class-level code generation, and the second-tier models includes Instruct-Starcoder, Instruct-Codegen, and Wizardcoder with very similar performance.","meta":{"url":"http://arxiv.org/abs/2308.01861v1"},"cats":{"new-dataset":0.1566378395,"dev-research":0.3185052991,"prompt-eng":0.4445758463,"data-quality":0.1444128128,"ml-security":0.0673284627}}
{"text":"Third, we find that generating the entire class all at once (i.e. holistic generation strategy) is the best generation strategy only for GPT-4 and GPT-3.5, while method-by-method generation (i.e. incremental and compositional) is better strategies for the other models with limited ability of understanding long instructions and utilizing the middle information.","meta":{"url":"http://arxiv.org/abs/2308.01861v1"},"cats":{"new-dataset":0.1117296925,"dev-research":0.305833753,"prompt-eng":0.4047797926,"data-quality":0.1121228481,"ml-security":0.0662853582}}
{"text":"Lastly, we find the limited model ability of generating method-dependent code and discuss the frequent error types in generated classes.","meta":{"url":"http://arxiv.org/abs/2308.01861v1"},"cats":{"new-dataset":0.0928816446,"dev-research":0.3774113499,"prompt-eng":0.4487958147,"data-quality":0.3530466688,"ml-security":0.1440229118}}
{"text":"Our benchmark is available at https://github.com/FudanSELab/ClassEval.","meta":{"url":"http://arxiv.org/abs/2308.01861v1"},"cats":{"new-dataset":0.2829033851,"dev-research":0.1468781591,"prompt-eng":0.4218304703,"data-quality":0.134527929,"ml-security":0.0379232374}}
{"text":"Open-source EDA shows promising potential in unleashing EDA innovation and lowering the cost of chip design.","meta":{"url":"http://arxiv.org/abs/2308.01857v1"},"cats":{"new-dataset":0.103443808,"dev-research":0.3275748877,"prompt-eng":0.3428588146,"data-quality":0.116422764,"ml-security":0.0823207984}}
{"text":"This paper presents an open-source EDA project, iEDA, aiming for building a basic infrastructure for EDA technology evolution and closing the industrial-academic gap in the EDA area.","meta":{"url":"http://arxiv.org/abs/2308.01857v1"},"cats":{"new-dataset":0.4926972368,"dev-research":0.3271721306,"prompt-eng":0.4033307372,"data-quality":0.1141828937,"ml-security":0.0589617779}}
{"text":"iEDA now covers the whole flow of physical design (including Floorplan, Placement, CTS, Routing, Timing Optimization etc.), and part of the analysis tools (Static Timing Analysis and Power Analysis).","meta":{"url":"http://arxiv.org/abs/2308.01857v1"},"cats":{"new-dataset":0.4887349891,"dev-research":0.3716233653,"prompt-eng":0.3681873328,"data-quality":0.0639683847,"ml-security":0.0685283896}}
{"text":"To demonstrate the effectiveness of iEDA, we implement and tape out three chips of different scales (from 700k to 1.5M gates) on different process nodes (110nm and 28nm) with iEDA.","meta":{"url":"http://arxiv.org/abs/2308.01857v1"},"cats":{"new-dataset":0.1173310182,"dev-research":0.2762243485,"prompt-eng":0.4549954754,"data-quality":0.0964593413,"ml-security":0.0789115719}}
{"text":"iEDA is publicly available from the project home page http://ieda.oscc.cc.","meta":{"url":"http://arxiv.org/abs/2308.01857v1"},"cats":{"new-dataset":0.7070541386,"dev-research":0.2355910924,"prompt-eng":0.4130209029,"data-quality":0.0829580431,"ml-security":0.0631888245}}
{"text":"The \\textsc{Mutual Visibility} is a well-known problem in the context of mobile robots.","meta":{"url":"http://arxiv.org/abs/2308.01855v1"},"cats":{"new-dataset":0.1286331859,"dev-research":0.1780538695,"prompt-eng":0.3923952438,"data-quality":0.1417182751,"ml-security":0.1455996616}}
{"text":"For a set of $n$ robots disposed in the Euclidean plane, it asks for moving the robots without collisions so as to achieve a placement ensuring that no three robots are collinear.","meta":{"url":"http://arxiv.org/abs/2308.01855v1"},"cats":{"new-dataset":0.1219727503,"dev-research":0.2099505268,"prompt-eng":0.3255204789,"data-quality":0.1121542317,"ml-security":0.1120064334}}
{"text":"For robots moving on graphs, we consider the \\textsc{Geodesic Mutual Visibility} ($\\GMV$) problem.","meta":{"url":"http://arxiv.org/abs/2308.01855v1"},"cats":{"new-dataset":0.1322825256,"dev-research":0.1418577684,"prompt-eng":0.3226509682,"data-quality":0.1188167463,"ml-security":0.1146721336}}
{"text":"Robots move along the edges of the graph, without collisions, so as to occupy some vertices that guarantee they become pairwise geodesic mutually visible.","meta":{"url":"http://arxiv.org/abs/2308.01855v1"},"cats":{"new-dataset":0.0665565932,"dev-research":0.1789593072,"prompt-eng":0.3105223213,"data-quality":0.0951425653,"ml-security":0.1038810643}}
{"text":"This means that there is a shortest path (i.e., a \"geodesic\") between each pair of robots along which no other robots reside.","meta":{"url":"http://arxiv.org/abs/2308.01855v1"},"cats":{"new-dataset":0.0446343176,"dev-research":0.2389252667,"prompt-eng":0.2956414308,"data-quality":0.0982054154,"ml-security":0.0542575506}}
{"text":"We study this problem in the context of finite and infinite square grids, for robots operating under the standard Look-Compute-Move model.","meta":{"url":"http://arxiv.org/abs/2308.01855v1"},"cats":{"new-dataset":0.2717249453,"dev-research":0.1513602396,"prompt-eng":0.3356656634,"data-quality":0.0453763668,"ml-security":0.0753057584}}
{"text":"In both scenarios, we provide resolution algorithms along with formal correctness proofs, highlighting the most relevant peculiarities arising within the different contexts, while optimizing the time complexity.","meta":{"url":"http://arxiv.org/abs/2308.01855v1"},"cats":{"new-dataset":0.0840064026,"dev-research":0.3100976506,"prompt-eng":0.4193755438,"data-quality":0.2855192084,"ml-security":0.1330653835}}
{"text":"Understanding 3d human interactions is fundamental for fine-grained scene analysis and behavioural modeling.","meta":{"url":"http://arxiv.org/abs/2308.01854v1"},"cats":{"new-dataset":0.2975724369,"dev-research":0.257980368,"prompt-eng":0.3732794665,"data-quality":0.1087811197,"ml-security":0.1000227332}}
{"text":"However, most of the existing models predict incorrect, lifeless 3d estimates, that miss the subtle human contact aspects--the essence of the event--and are of little use for detailed behavioral understanding.","meta":{"url":"http://arxiv.org/abs/2308.01854v1"},"cats":{"new-dataset":0.105878847,"dev-research":0.2483321924,"prompt-eng":0.3729297162,"data-quality":0.1538377376,"ml-security":0.1005082154}}
{"text":"This paper addresses such issues with several contributions: (1) we introduce models for interaction signature estimation (ISP) encompassing contact detection, segmentation, and 3d contact signature prediction; (2) we show how such components can be leveraged to ensure contact consistency during 3d reconstruction; (3) we construct several large datasets for learning and evaluating 3d contact prediction and reconstruction methods; specifically, we introduce CHI3D, a lab-based accurate 3d motion capture dataset with 631 sequences containing $2,525$ contact events, $728,664$ ground truth 3d poses, as well as FlickrCI3D, a dataset of $11,216$ images, with $14,081$ processed pairs of people, and $81,233$ facet-level surface correspondences.","meta":{"url":"http://arxiv.org/abs/2308.01854v1"},"cats":{"new-dataset":0.6899652082,"dev-research":0.2186764361,"prompt-eng":0.3821567845,"data-quality":0.1084498807,"ml-security":0.0990711623}}
{"text":"Finally, (4) we propose methodology for recovering the ground-truth pose and shape of interacting people in a controlled setup and (5) annotate all 3d interaction motions in CHI3D with textual descriptions.","meta":{"url":"http://arxiv.org/abs/2308.01854v1"},"cats":{"new-dataset":0.4343936617,"dev-research":0.2673843116,"prompt-eng":0.3929464619,"data-quality":0.0931795093,"ml-security":0.0717824212}}
{"text":"Motion data in multiple formats (GHUM and SMPLX parameters, Human3.6m 3d joints) is made available for research purposes at \\url{https://ci3d.imar.ro}, together with an evaluation server and a public benchmark.","meta":{"url":"http://arxiv.org/abs/2308.01854v1"},"cats":{"new-dataset":0.4758970279,"dev-research":0.1683716586,"prompt-eng":0.3403914588,"data-quality":0.0516688469,"ml-security":0.0249222503}}
{"text":"Text-to-motion generation has gained increasing attention, but most existing methods are limited to generating short-term motions that correspond to a single sentence describing a single action.","meta":{"url":"http://arxiv.org/abs/2308.01850v1"},"cats":{"new-dataset":0.131916465,"dev-research":0.2545840534,"prompt-eng":0.3890103478,"data-quality":0.1380890631,"ml-security":0.0547400486}}
{"text":"However, when a text stream describes a sequence of continuous motions, the generated motions corresponding to each sentence may not be coherently linked.","meta":{"url":"http://arxiv.org/abs/2308.01850v1"},"cats":{"new-dataset":0.0374747399,"dev-research":0.2993455803,"prompt-eng":0.3265300967,"data-quality":0.253053697,"ml-security":0.0642496388}}
{"text":"Existing long-term motion generation methods face two main issues.","meta":{"url":"http://arxiv.org/abs/2308.01850v1"},"cats":{"new-dataset":0.069979324,"dev-research":0.2995997221,"prompt-eng":0.3400331674,"data-quality":0.0726181742,"ml-security":0.0313416008}}
{"text":"Firstly, they cannot directly generate coherent motions and require additional operations such as interpolation to process the generated actions.","meta":{"url":"http://arxiv.org/abs/2308.01850v1"},"cats":{"new-dataset":0.0239427652,"dev-research":0.2094541892,"prompt-eng":0.3183085223,"data-quality":0.0649130734,"ml-security":0.0516275071}}
{"text":"Secondly, they generate subsequent actions in an autoregressive manner without considering the influence of future actions on previous ones.","meta":{"url":"http://arxiv.org/abs/2308.01850v1"},"cats":{"new-dataset":0.0243686008,"dev-research":0.2187036017,"prompt-eng":0.3594864334,"data-quality":0.0992599465,"ml-security":0.1370909682}}
{"text":"To address these issues, we propose a novel approach that utilizes a past-conditioned diffusion model with two optional coherent sampling methods:","meta":{"url":"http://arxiv.org/abs/2308.01850v1"},"cats":{"new-dataset":0.0368169546,"dev-research":0.1308866956,"prompt-eng":0.3881350551,"data-quality":0.1377380525,"ml-security":0.078107261}}
{"text":"Past Inpainting Sampling and Compositional Transition Sampling.","meta":{"url":"http://arxiv.org/abs/2308.01850v1"},"cats":{"new-dataset":0.020990733,"dev-research":0.1649329402,"prompt-eng":0.3679085108,"data-quality":0.1480469645,"ml-security":0.0516103286}}
{"text":"Past Inpainting Sampling completes subsequent motions by treating previous motions as conditions, while Compositional Transition Sampling models the distribution of the transition as the composition of two adjacent motions guided by different text prompts.","meta":{"url":"http://arxiv.org/abs/2308.01850v1"},"cats":{"new-dataset":0.0320002061,"dev-research":0.1743830936,"prompt-eng":0.4169213301,"data-quality":0.1539750993,"ml-security":0.0377543748}}
{"text":"Our experimental results demonstrate that our proposed method is capable of generating compositional and coherent long-term 3D human motions controlled by a user-instructed long text stream.","meta":{"url":"http://arxiv.org/abs/2308.01850v1"},"cats":{"new-dataset":0.1661535384,"dev-research":0.278318747,"prompt-eng":0.3782109546,"data-quality":0.0612619882,"ml-security":0.040091169}}
{"text":"The code is available at \\href{https://github.com/yangzhao1230/PCMDM}{https://github.com/yangzhao1230/PCMDM}.","meta":{"url":"http://arxiv.org/abs/2308.01850v1"},"cats":{"new-dataset":0.1500535101,"dev-research":0.1730939831,"prompt-eng":0.439635605,"data-quality":0.1237051757,"ml-security":0.0411143513}}
{"text":"Fine-tuning language models in a downstream task is the standard approach for many state-of-the-art methodologies in the field of NLP.","meta":{"url":"http://arxiv.org/abs/2308.01849v1"},"cats":{"new-dataset":0.0639340625,"dev-research":0.3042212537,"prompt-eng":0.4588597574,"data-quality":0.3275794584,"ml-security":0.0567362214}}
{"text":"However, when the distribution between the source task and target task drifts, \\textit{e.g.}, conversational environments, these gains tend to be diminished.","meta":{"url":"http://arxiv.org/abs/2308.01849v1"},"cats":{"new-dataset":0.015950818,"dev-research":0.3772074914,"prompt-eng":0.3728771756,"data-quality":0.3495977164,"ml-security":0.1877084891}}
{"text":"This article proposes a sequence of pre-training steps (a curriculum) guided by \"data hacking\" and grammar analysis that allows further gradual adaptation between pre-training distributions.","meta":{"url":"http://arxiv.org/abs/2308.01849v1"},"cats":{"new-dataset":0.3841853682,"dev-research":0.4473124969,"prompt-eng":0.4720825296,"data-quality":0.2473376581,"ml-security":0.309071862}}
{"text":"In our experiments, we acquire a considerable improvement from our method compared to other known pre-training approaches for the MultiWoZ task.","meta":{"url":"http://arxiv.org/abs/2308.01849v1"},"cats":{"new-dataset":0.1691284576,"dev-research":0.1732482076,"prompt-eng":0.4167491562,"data-quality":0.1498966543,"ml-security":0.041549527}}
{"text":"Structured Natural Language Processing (XNLP) is an important subset of NLP that entails understanding the underlying semantic or syntactic structure of texts, which serves as a foundational component for many downstream applications.","meta":{"url":"http://arxiv.org/abs/2308.01846v1"},"cats":{"new-dataset":0.1000313147,"dev-research":0.3257580823,"prompt-eng":0.3854524793,"data-quality":0.2743698747,"ml-security":0.0617127489}}
{"text":"Despite certain recent efforts to explore universal solutions for specific categories of XNLP tasks, a comprehensive and effective approach for unifying all XNLP tasks long remains underdeveloped.","meta":{"url":"http://arxiv.org/abs/2308.01846v1"},"cats":{"new-dataset":0.0747344643,"dev-research":0.3164127873,"prompt-eng":0.4476587522,"data-quality":0.1745333154,"ml-security":0.0759754933}}
{"text":"In the meanwhile, while XNLP demonstration systems are vital for researchers exploring various XNLP tasks, existing platforms can be limited to, e.g., supporting few XNLP tasks, lacking interactivity and universalness.","meta":{"url":"http://arxiv.org/abs/2308.01846v1"},"cats":{"new-dataset":0.1232058133,"dev-research":0.4018381947,"prompt-eng":0.4847493409,"data-quality":0.1578768427,"ml-security":0.0934502089}}
{"text":"To this end, we propose an advanced XNLP demonstration platform, where we propose leveraging LLM to achieve universal XNLP, with one model for all with high generalizability.","meta":{"url":"http://arxiv.org/abs/2308.01846v1"},"cats":{"new-dataset":0.1255115512,"dev-research":0.2595043912,"prompt-eng":0.4707870308,"data-quality":0.1609604531,"ml-security":0.0973903883}}
{"text":"Overall, our system advances in multiple aspects, including universal XNLP modeling, high performance, interpretability, scalability, and interactivity, providing a unified platform for exploring diverse XNLP tasks in the community.","meta":{"url":"http://arxiv.org/abs/2308.01846v1"},"cats":{"new-dataset":0.1826139528,"dev-research":0.3111555458,"prompt-eng":0.4528776914,"data-quality":0.165605727,"ml-security":0.058931066}}
{"text":"XNLP is online: https://xnlp.haofei.vip","meta":{"url":"http://arxiv.org/abs/2308.01846v1"},"cats":{"new-dataset":0.4509379401,"dev-research":0.2212136646,"prompt-eng":0.3667203406,"data-quality":0.1345299307,"ml-security":0.0565322427}}
{"text":"Machine learning models are known to be vulnerable to adversarial evasion attacks as illustrated by image classification models.","meta":{"url":"http://arxiv.org/abs/2308.01840v1"},"cats":{"new-dataset":0.0515859871,"dev-research":0.2179120599,"prompt-eng":0.3512229917,"data-quality":0.3763541039,"ml-security":0.9250362079}}
{"text":"Thoroughly understanding such attacks is critical in order to ensure the safety and robustness of critical AI tasks.","meta":{"url":"http://arxiv.org/abs/2308.01840v1"},"cats":{"new-dataset":0.0324667,"dev-research":0.3378716525,"prompt-eng":0.3744703815,"data-quality":0.2400173333,"ml-security":0.6992234877}}
{"text":"However, most evasion attacks are difficult to deploy against a majority of AI systems because they have focused on image domain with only few constraints.","meta":{"url":"http://arxiv.org/abs/2308.01840v1"},"cats":{"new-dataset":0.016957392,"dev-research":0.3160667978,"prompt-eng":0.3731923774,"data-quality":0.2333159881,"ml-security":0.7200977519}}
{"text":"An image is composed of homogeneous, numerical, continuous, and independent features, unlike many other input types to AI systems used in practice.","meta":{"url":"http://arxiv.org/abs/2308.01840v1"},"cats":{"new-dataset":0.1037360251,"dev-research":0.2246557449,"prompt-eng":0.3609462749,"data-quality":0.1326006033,"ml-security":0.0893865728}}
{"text":"Furthermore, some input types include additional semantic and functional constraints that must be observed to generate realistic adversarial inputs.","meta":{"url":"http://arxiv.org/abs/2308.01840v1"},"cats":{"new-dataset":0.0679241264,"dev-research":0.3015977604,"prompt-eng":0.3556651349,"data-quality":0.2318185535,"ml-security":0.4775175963}}
{"text":"In this work, we propose a new framework to enable the generation of adversarial inputs irrespective of the input type and task domain.","meta":{"url":"http://arxiv.org/abs/2308.01840v1"},"cats":{"new-dataset":0.2193684269,"dev-research":0.2776702828,"prompt-eng":0.3920687684,"data-quality":0.2485284328,"ml-security":0.6188781582}}
{"text":"Given an input and a set of pre-defined input transformations, our framework discovers a sequence of transformations that result in a semantically correct and functional adversarial input.","meta":{"url":"http://arxiv.org/abs/2308.01840v1"},"cats":{"new-dataset":0.2625106019,"dev-research":0.2658056795,"prompt-eng":0.3394525165,"data-quality":0.235928447,"ml-security":0.4728383232}}
{"text":"We demonstrate the generality of our approach on several diverse machine learning tasks with various input representations.","meta":{"url":"http://arxiv.org/abs/2308.01840v1"},"cats":{"new-dataset":0.1451383056,"dev-research":0.2023878576,"prompt-eng":0.3924229133,"data-quality":0.2823681376,"ml-security":0.2224404513}}
{"text":"We also show the importance of generating adversarial examples as they enable the deployment of mitigation techniques.","meta":{"url":"http://arxiv.org/abs/2308.01840v1"},"cats":{"new-dataset":0.0781495791,"dev-research":0.3416241718,"prompt-eng":0.3552760341,"data-quality":0.4171100617,"ml-security":0.8246660183}}
{"text":"The current work investigates the capability of Large language models (LLMs) that are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2) to predict psychiatric functioning from patient interviews and clinical descriptions without being trained to do so.","meta":{"url":"http://arxiv.org/abs/2308.01834v1"},"cats":{"new-dataset":0.1350505992,"dev-research":0.1834616092,"prompt-eng":0.4309136362,"data-quality":0.2000183361,"ml-security":0.1449670469}}
{"text":"To assess this, n = 145 depression and n =115 PTSD assessments and n = 46 clinical case studies across high prevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma and stress, Addictive disorders) were analyzed using prompts to extract estimated clinical scores and diagnoses.","meta":{"url":"http://arxiv.org/abs/2308.01834v1"},"cats":{"new-dataset":0.0846915982,"dev-research":0.2589447563,"prompt-eng":0.4378529785,"data-quality":0.1540935948,"ml-security":0.0665443566}}
{"text":"Results demonstrate that Med-PaLM 2 is capable of assessing psychiatric functioning across a range of psychiatric conditions with the strongest performance being the prediction of depression scores based on standardized assessments (Accuracy range= 0.80 - 0.84) which were statistically indistinguishable from human clinical raters t(1,144) = 1.20; p = 0.23.","meta":{"url":"http://arxiv.org/abs/2308.01834v1"},"cats":{"new-dataset":0.0332148132,"dev-research":0.2685760972,"prompt-eng":0.4684097797,"data-quality":0.1733991189,"ml-security":0.0540114516}}
{"text":"Results show the potential for general clinical language models to flexibly predict psychiatric risk based on free descriptions of functioning from both patients and clinicians.","meta":{"url":"http://arxiv.org/abs/2308.01834v1"},"cats":{"new-dataset":0.0231057613,"dev-research":0.2770250973,"prompt-eng":0.4363151318,"data-quality":0.2514344641,"ml-security":0.2237878191}}
{"text":"Nano-quadcopters are versatile platforms attracting the interest of both academia and industry.","meta":{"url":"http://arxiv.org/abs/2308.01833v1"},"cats":{"new-dataset":0.0217638759,"dev-research":0.221512631,"prompt-eng":0.3617765407,"data-quality":0.0592556732,"ml-security":0.0632942645}}
{"text":"Their tiny form factor, i.e., $\\,$10 cm diameter, makes them particularly useful in narrow scenarios and harmless in human proximity.","meta":{"url":"http://arxiv.org/abs/2308.01833v1"},"cats":{"new-dataset":0.0370304298,"dev-research":0.1993435456,"prompt-eng":0.3700034984,"data-quality":0.1315520151,"ml-security":0.1382528314}}
{"text":"However, these advantages come at the price of ultra-constrained onboard computational and sensorial resources for autonomous operations.","meta":{"url":"http://arxiv.org/abs/2308.01833v1"},"cats":{"new-dataset":0.0962824798,"dev-research":0.2940706474,"prompt-eng":0.3723802737,"data-quality":0.050492602,"ml-security":0.0947853378}}
{"text":"This work addresses the task of estimating human pose aboard nano-drones by fusing depth and images in a novel CNN exclusively trained in simulation yet capable of robust predictions in the real world.","meta":{"url":"http://arxiv.org/abs/2308.01833v1"},"cats":{"new-dataset":0.4011406743,"dev-research":0.2428505803,"prompt-eng":0.3229484632,"data-quality":0.1332742977,"ml-security":0.1971858579}}
{"text":"We extend a commercial off-the-shelf (COTS) Crazyflie nano-drone -- equipped with a 320$\\times$240 px camera and an ultra-low-power System-on-Chip -- with a novel multi-zone (8$\\times$8) depth sensor.","meta":{"url":"http://arxiv.org/abs/2308.01833v1"},"cats":{"new-dataset":0.3148266099,"dev-research":0.1934085754,"prompt-eng":0.3911822158,"data-quality":0.0815025947,"ml-security":0.0675642562}}
{"text":"We design and compare different deep-learning models that fuse depth and image inputs.","meta":{"url":"http://arxiv.org/abs/2308.01833v1"},"cats":{"new-dataset":0.1024449006,"dev-research":0.191923052,"prompt-eng":0.3443442822,"data-quality":0.1623079207,"ml-security":0.2565529198}}
{"text":"Our models are trained exclusively on simulated data for both inputs, and transfer well to the real world: field testing shows an improvement of 58% and 51% of our depth+camera system w.r.t.","meta":{"url":"http://arxiv.org/abs/2308.01833v1"},"cats":{"new-dataset":0.376056075,"dev-research":0.1890021,"prompt-eng":0.403430894,"data-quality":0.1122653523,"ml-security":0.0969845727}}
{"text":"a camera-only State-of-the-Art baseline on the horizontal and angular mean pose errors, respectively.","meta":{"url":"http://arxiv.org/abs/2308.01833v1"},"cats":{"new-dataset":0.2459129584,"dev-research":0.2452537449,"prompt-eng":0.3664988277,"data-quality":0.2559595161,"ml-security":0.0631043957}}
{"text":"Our prototype is based on COTS components, which facilitates reproducibility and adoption of this novel class of systems.","meta":{"url":"http://arxiv.org/abs/2308.01833v1"},"cats":{"new-dataset":0.0821619816,"dev-research":0.3225442247,"prompt-eng":0.4917757674,"data-quality":0.0809917386,"ml-security":0.0613294395}}
{"text":"In this paper, we propose a method to learn unified representations of multilingual speech and text with a single model, especially focusing on the purpose of speech synthesis.","meta":{"url":"http://arxiv.org/abs/2308.01831v1"},"cats":{"new-dataset":0.2720801499,"dev-research":0.283200707,"prompt-eng":0.3647149081,"data-quality":0.1915137988,"ml-security":0.0811369}}
{"text":"We represent multilingual speech audio with speech units, the quantized representations of speech features encoded from a self-supervised speech model.","meta":{"url":"http://arxiv.org/abs/2308.01831v1"},"cats":{"new-dataset":0.2196187577,"dev-research":0.1938955315,"prompt-eng":0.3314398913,"data-quality":0.2373719487,"ml-security":0.1052368606}}
{"text":"Therefore, we can focus on their linguistic content by treating the audio as pseudo text and can build a unified representation of speech and text.","meta":{"url":"http://arxiv.org/abs/2308.01831v1"},"cats":{"new-dataset":0.2915681032,"dev-research":0.2745660142,"prompt-eng":0.3709914254,"data-quality":0.2228327882,"ml-security":0.0704921799}}
{"text":"Then, we propose to train an encoder-decoder structured model with a Unit-to-Unit Translation (UTUT) objective on multilingual data.","meta":{"url":"http://arxiv.org/abs/2308.01831v1"},"cats":{"new-dataset":0.2965735878,"dev-research":0.2130444926,"prompt-eng":0.3910678641,"data-quality":0.2107524451,"ml-security":0.0829264444}}
{"text":"Specifically, by conditioning the encoder with the source language token and the decoder with the target language token, the model is optimized to translate the spoken language into that of the target language, in a many-to-many language translation setting.","meta":{"url":"http://arxiv.org/abs/2308.01831v1"},"cats":{"new-dataset":0.0703133404,"dev-research":0.257016354,"prompt-eng":0.4313619772,"data-quality":0.1696390204,"ml-security":0.0951103555}}
{"text":"Therefore, the model can build the knowledge of how spoken languages are comprehended and how to relate them to different languages.","meta":{"url":"http://arxiv.org/abs/2308.01831v1"},"cats":{"new-dataset":0.0727650002,"dev-research":0.3096468549,"prompt-eng":0.3613884676,"data-quality":0.1219223297,"ml-security":0.0894500654}}
{"text":"A single pre-trained model with UTUT can be employed for diverse multilingual speech- and text-related tasks, such as Speech-to-Speech Translation (STS), multilingual Text-to-Speech Synthesis (TTS), and Text-to-Speech Translation (TTST).","meta":{"url":"http://arxiv.org/abs/2308.01831v1"},"cats":{"new-dataset":0.1857660988,"dev-research":0.2674105,"prompt-eng":0.4209834898,"data-quality":0.1351669763,"ml-security":0.0653746354}}
{"text":"By conducting comprehensive experiments encompassing various languages, we validate the efficacy of the proposed method across diverse multilingual tasks.","meta":{"url":"http://arxiv.org/abs/2308.01831v1"},"cats":{"new-dataset":0.0522515295,"dev-research":0.3203098606,"prompt-eng":0.4795105285,"data-quality":0.2727252839,"ml-security":0.063669924}}
{"text":"Moreover, we show UTUT can perform many-to-many language STS, which has not been previously explored in the literature.","meta":{"url":"http://arxiv.org/abs/2308.01831v1"},"cats":{"new-dataset":0.116443802,"dev-research":0.2055969909,"prompt-eng":0.4278875095,"data-quality":0.198309072,"ml-security":0.0907009188}}
{"text":"Samples are available on https://choijeongsoo.github.io/utut.","meta":{"url":"http://arxiv.org/abs/2308.01831v1"},"cats":{"new-dataset":0.3625274133,"dev-research":0.1460492739,"prompt-eng":0.4174504255,"data-quality":0.1084580951,"ml-security":0.0292832793}}
{"text":"Uncertainty in state or model parameters is common in robotics and typically handled by acquiring system measurements that yield information about the uncertain quantities of interest.","meta":{"url":"http://arxiv.org/abs/2308.01829v1"},"cats":{"new-dataset":0.0345669092,"dev-research":0.2901229909,"prompt-eng":0.4361684904,"data-quality":0.1564707758,"ml-security":0.0992594699}}
{"text":"Inputs to a nonlinear dynamical system yield outcomes that produce varying amounts of information about the underlying uncertain parameters of the system.","meta":{"url":"http://arxiv.org/abs/2308.01829v1"},"cats":{"new-dataset":0.0522042279,"dev-research":0.2469541923,"prompt-eng":0.4293523874,"data-quality":0.1765657698,"ml-security":0.2130780617}}
{"text":"To maximize information gained with respect to these uncertain parameters we present a Bayesian approach to data collection for system identification called Bayesian Optimal Experimental Design (BOED).","meta":{"url":"http://arxiv.org/abs/2308.01829v1"},"cats":{"new-dataset":0.2223664038,"dev-research":0.2456040917,"prompt-eng":0.523615627,"data-quality":0.1944132291,"ml-security":0.1433847401}}
{"text":"The formulation uses parameterized trajectories and cubature to compute maximally informative system trajectories which obtain as much information as possible about unknown system parameters while also ensuring safety under mild assumptions.","meta":{"url":"http://arxiv.org/abs/2308.01829v1"},"cats":{"new-dataset":0.1656741407,"dev-research":0.2176343482,"prompt-eng":0.3908167116,"data-quality":0.0817771822,"ml-security":0.1406370339}}
{"text":"The proposed method is applicable to non-linear and non-Gaussian systems and is applied to a high-fidelity vehicle model from the literature.","meta":{"url":"http://arxiv.org/abs/2308.01829v1"},"cats":{"new-dataset":0.0512212241,"dev-research":0.147786471,"prompt-eng":0.3593453087,"data-quality":0.1116939431,"ml-security":0.0884119214}}
{"text":"It is shown the proposed approach requires orders of magnitude fewer samples compared to state-of-the-art BOED algorithms from the literature while simultaneously providing safety guarantees.","meta":{"url":"http://arxiv.org/abs/2308.01829v1"},"cats":{"new-dataset":0.1713990298,"dev-research":0.1533703596,"prompt-eng":0.382889343,"data-quality":0.1794665894,"ml-security":0.1230731654}}
{"text":"Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capacity is under-explored.","meta":{"url":"http://arxiv.org/abs/2308.01825v1"},"cats":{"new-dataset":0.0776429295,"dev-research":0.2192065049,"prompt-eng":0.3922729962,"data-quality":0.1620316482,"ml-security":0.1247666109}}
{"text":"In this paper, we investigate how the pre-training loss, supervised data amount, and augmented data amount influence the reasoning performances of a supervised LLM.","meta":{"url":"http://arxiv.org/abs/2308.01825v1"},"cats":{"new-dataset":0.0598546495,"dev-research":0.2741268321,"prompt-eng":0.4450209645,"data-quality":0.2273093784,"ml-security":0.133281366}}
{"text":"We find that pre-training loss is a better indicator of the model's performance than the model's parameter count.","meta":{"url":"http://arxiv.org/abs/2308.01825v1"},"cats":{"new-dataset":0.0095990109,"dev-research":0.2697206384,"prompt-eng":0.409629479,"data-quality":0.2405425662,"ml-security":0.1807046751}}
{"text":"We apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets.","meta":{"url":"http://arxiv.org/abs/2308.01825v1"},"cats":{"new-dataset":0.2195950557,"dev-research":0.2759514326,"prompt-eng":0.4144258856,"data-quality":0.3968404343,"ml-security":0.1412180111}}
{"text":"To augment more data samples for improving model performances without any human effort, we propose to apply Rejection sampling Fine-Tuning (RFT).","meta":{"url":"http://arxiv.org/abs/2308.01825v1"},"cats":{"new-dataset":0.0733041565,"dev-research":0.2651365003,"prompt-eng":0.4457992892,"data-quality":0.319756648,"ml-security":0.1412858924}}
{"text":"RFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets.","meta":{"url":"http://arxiv.org/abs/2308.01825v1"},"cats":{"new-dataset":0.1752977963,"dev-research":0.3945011061,"prompt-eng":0.4770203894,"data-quality":0.2300393653,"ml-security":0.0583163676}}
{"text":"We find with augmented samples containing more distinct reasoning paths, RFT improves mathematical reasoning performance more for LLMs.","meta":{"url":"http://arxiv.org/abs/2308.01825v1"},"cats":{"new-dataset":0.0930249355,"dev-research":0.299574856,"prompt-eng":0.462878014,"data-quality":0.1267695024,"ml-security":0.0654921994}}
{"text":"We also find RFT brings more improvement for less performant LLMs.","meta":{"url":"http://arxiv.org/abs/2308.01825v1"},"cats":{"new-dataset":0.0229008203,"dev-research":0.2132037466,"prompt-eng":0.3933961141,"data-quality":0.1489462596,"ml-security":0.0712173564}}
{"text":"Furthermore, we combine rejection samples from multiple models which push LLaMA-7B to an accuracy of 49.3% and outperforms the supervised fine-tuning (SFT) accuracy of 35.9% significantly.","meta":{"url":"http://arxiv.org/abs/2308.01825v1"},"cats":{"new-dataset":0.0599994668,"dev-research":0.202373625,"prompt-eng":0.4681799257,"data-quality":0.4237570663,"ml-security":0.1654888483}}
{"text":"Adversarial training (AT) is widely considered the state-of-the-art technique for improving the robustness of deep neural networks (DNNs) against adversarial examples (AE).","meta":{"url":"http://arxiv.org/abs/2308.01823v1"},"cats":{"new-dataset":0.072008637,"dev-research":0.2545372432,"prompt-eng":0.3390525427,"data-quality":0.3809125715,"ml-security":0.7093371623}}
{"text":"Nevertheless, recent studies have revealed that adversarially trained models are prone to unfairness problems, restricting their applicability.","meta":{"url":"http://arxiv.org/abs/2308.01823v1"},"cats":{"new-dataset":0.0137693682,"dev-research":0.2720245505,"prompt-eng":0.3155669142,"data-quality":0.4932684087,"ml-security":0.8131017899}}
{"text":"In this paper, we empirically observe that this limitation may be attributed to serious adversarial confidence overfitting, i.e., certain adversarial examples with overconfidence.","meta":{"url":"http://arxiv.org/abs/2308.01823v1"},"cats":{"new-dataset":0.0640936178,"dev-research":0.2507745547,"prompt-eng":0.3231913063,"data-quality":0.4353795803,"ml-security":0.7532216421}}
{"text":"To alleviate this problem, we propose HAM, a straightforward yet effective framework via adaptive Hard Adversarial example Mining.","meta":{"url":"http://arxiv.org/abs/2308.01823v1"},"cats":{"new-dataset":0.2235291463,"dev-research":0.2362592331,"prompt-eng":0.3699497152,"data-quality":0.4220536273,"ml-security":0.440660451}}
{"text":"HAM concentrates on mining hard adversarial examples while discarding the easy ones in an adaptive fashion.","meta":{"url":"http://arxiv.org/abs/2308.01823v1"},"cats":{"new-dataset":0.06486218,"dev-research":0.286504605,"prompt-eng":0.3402911019,"data-quality":0.401857521,"ml-security":0.6789377104}}
{"text":"Specifically, HAM identifies hard AEs in terms of their step sizes needed to cross the decision boundary when calculating loss value.","meta":{"url":"http://arxiv.org/abs/2308.01823v1"},"cats":{"new-dataset":0.013375039,"dev-research":0.229719575,"prompt-eng":0.4047844634,"data-quality":0.156470888,"ml-security":0.1233910674}}
{"text":"Besides, an early-dropping mechanism is incorporated to discard the easy examples at the initial stages of AE generation, resulting in efficient AT.","meta":{"url":"http://arxiv.org/abs/2308.01823v1"},"cats":{"new-dataset":0.0117547079,"dev-research":0.3197823488,"prompt-eng":0.4492436933,"data-quality":0.1628036529,"ml-security":0.1550370013}}
{"text":"Extensive experimental results on CIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant improvement in robust fairness while reducing computational cost compared to several state-of-the-art adversarial training methods.","meta":{"url":"http://arxiv.org/abs/2308.01823v1"},"cats":{"new-dataset":0.124357486,"dev-research":0.2314307524,"prompt-eng":0.3229079677,"data-quality":0.3479245523,"ml-security":0.6162833342}}
{"text":"The code will be made publicly available.","meta":{"url":"http://arxiv.org/abs/2308.01823v1"},"cats":{"new-dataset":0.4411976213,"dev-research":0.2516212864,"prompt-eng":0.3783248538,"data-quality":0.1475468939,"ml-security":0.1641112335}}
{"text":"Going beyond stochastic gradient descent (SGD), what new phenomena emerge in wide neural networks trained by adaptive optimizers like Adam?","meta":{"url":"http://arxiv.org/abs/2308.01814v1"},"cats":{"new-dataset":0.0288869247,"dev-research":0.1980454904,"prompt-eng":0.2849722727,"data-quality":0.1907751484,"ml-security":0.3090712043}}
{"text":"Here we show: The same dichotomy between feature learning and kernel behaviors (as in SGD) holds for general optimizers as well, including Adam -- albeit with a nonlinear notion of \"kernel.\"","meta":{"url":"http://arxiv.org/abs/2308.01814v1"},"cats":{"new-dataset":0.0458198431,"dev-research":0.2254380624,"prompt-eng":0.3412591569,"data-quality":0.2088658225,"ml-security":0.2194106642}}
{"text":"We derive the corresponding \"neural tangent\" and \"maximal update\" limits for any architecture.","meta":{"url":"http://arxiv.org/abs/2308.01814v1"},"cats":{"new-dataset":0.1109204896,"dev-research":0.1928958025,"prompt-eng":0.3087824371,"data-quality":0.1160000317,"ml-security":0.3160858309}}
{"text":"Two foundational advances underlie the above results: 1) A new Tensor Program language, NEXORT, that can express how adaptive optimizers process gradients into updates.","meta":{"url":"http://arxiv.org/abs/2308.01814v1"},"cats":{"new-dataset":0.0399521402,"dev-research":0.2706922323,"prompt-eng":0.380321908,"data-quality":0.1157661577,"ml-security":0.1116954643}}
{"text":"2) The introduction of bra-ket notation to drastically simplify expressions and calculations in Tensor Programs.","meta":{"url":"http://arxiv.org/abs/2308.01814v1"},"cats":{"new-dataset":0.0433466511,"dev-research":0.2472233979,"prompt-eng":0.3682631284,"data-quality":0.1466758432,"ml-security":0.1237651827}}
{"text":"This work summarizes and generalizes all previous results in the Tensor Programs series of papers.","meta":{"url":"http://arxiv.org/abs/2308.01814v1"},"cats":{"new-dataset":0.1770501075,"dev-research":0.0979919116,"prompt-eng":0.3445680129,"data-quality":0.1099984236,"ml-security":0.0832880194}}
{"text":"Fine-grained image classification (FGIC) is a challenging task in computer vision for due to small visual differences among inter-subcategories, but, large intra-class variations.","meta":{"url":"http://arxiv.org/abs/2308.01813v1"},"cats":{"new-dataset":0.3199803279,"dev-research":0.1582173521,"prompt-eng":0.3910257084,"data-quality":0.2595683941,"ml-security":0.0905753889}}
{"text":"Deep learning methods have achieved remarkable success in solving FGIC.","meta":{"url":"http://arxiv.org/abs/2308.01813v1"},"cats":{"new-dataset":0.0570742772,"dev-research":0.2423534885,"prompt-eng":0.3498453962,"data-quality":0.1196748321,"ml-security":0.1155564615}}
{"text":"In this paper, we propose a fusion approach to address FGIC by combining global texture with local patch-based information.","meta":{"url":"http://arxiv.org/abs/2308.01813v1"},"cats":{"new-dataset":0.1280474897,"dev-research":0.2306586121,"prompt-eng":0.450995502,"data-quality":0.1805765282,"ml-security":0.0616941784}}
{"text":"The first pipeline extracts deep features from various fixed-size non-overlapping patches and encodes features by sequential modelling using the long short-term memory (LSTM).","meta":{"url":"http://arxiv.org/abs/2308.01813v1"},"cats":{"new-dataset":0.3342483887,"dev-research":0.2888546206,"prompt-eng":0.350339407,"data-quality":0.1532525158,"ml-security":0.1436499345}}
{"text":"Another path computes image-level textures at multiple scales using the local binary patterns (LBP).","meta":{"url":"http://arxiv.org/abs/2308.01813v1"},"cats":{"new-dataset":0.164581831,"dev-research":0.1659851854,"prompt-eng":0.4203546056,"data-quality":0.1149995335,"ml-security":0.0509910121}}
{"text":"The advantages of both streams are integrated to represent an efficient feature vector for image classification.","meta":{"url":"http://arxiv.org/abs/2308.01813v1"},"cats":{"new-dataset":0.0357126566,"dev-research":0.233139442,"prompt-eng":0.3555437912,"data-quality":0.1854791933,"ml-security":0.0882912855}}
{"text":"The method is tested on eight datasets representing the human faces, skin lesions, food dishes, marine lives, etc. using four standard backbone CNNs.","meta":{"url":"http://arxiv.org/abs/2308.01813v1"},"cats":{"new-dataset":0.409394098,"dev-research":0.1881126568,"prompt-eng":0.3249193285,"data-quality":0.128221408,"ml-security":0.0957838367}}
{"text":"Our method has attained better classification accuracy over existing methods with notable margins.","meta":{"url":"http://arxiv.org/abs/2308.01813v1"},"cats":{"new-dataset":0.1139338848,"dev-research":0.2135143022,"prompt-eng":0.3957880238,"data-quality":0.4038278952,"ml-security":0.0998202837}}
{"text":"Dietary assessment is a key contributor to monitoring health status.","meta":{"url":"http://arxiv.org/abs/2308.01810v1"},"cats":{"new-dataset":0.0176274772,"dev-research":0.2490655625,"prompt-eng":0.4142363176,"data-quality":0.1407136282,"ml-security":0.0788845408}}
{"text":"Existing self-report methods are tedious and time-consuming with substantial biases and errors.","meta":{"url":"http://arxiv.org/abs/2308.01810v1"},"cats":{"new-dataset":0.0454102393,"dev-research":0.3419452164,"prompt-eng":0.4513278661,"data-quality":0.2900796767,"ml-security":0.0821166985}}
{"text":"Image-based food portion estimation aims to estimate food energy values directly from food images, showing great potential for automated dietary assessment solutions.","meta":{"url":"http://arxiv.org/abs/2308.01810v1"},"cats":{"new-dataset":0.0598176157,"dev-research":0.1507332755,"prompt-eng":0.4436668001,"data-quality":0.187826626,"ml-security":0.063372743}}
{"text":"Existing image-based methods either use a single-view image or incorporate multi-view images and depth information to estimate the food energy, which either has limited performance or creates user burdens.","meta":{"url":"http://arxiv.org/abs/2308.01810v1"},"cats":{"new-dataset":0.0561906454,"dev-research":0.192197551,"prompt-eng":0.4070670155,"data-quality":0.09640005,"ml-security":0.0505161976}}
{"text":"In this paper, we propose an end-to-end deep learning framework for food energy estimation from a monocular image through 3D shape reconstruction.","meta":{"url":"http://arxiv.org/abs/2308.01810v1"},"cats":{"new-dataset":0.1613934583,"dev-research":0.156467711,"prompt-eng":0.3250327428,"data-quality":0.146607846,"ml-security":0.110878892}}
{"text":"We leverage a generative model to reconstruct the voxel representation of the food object from the input image to recover the missing 3D information.","meta":{"url":"http://arxiv.org/abs/2308.01810v1"},"cats":{"new-dataset":0.1433840281,"dev-research":0.1636027858,"prompt-eng":0.3915193845,"data-quality":0.1926444427,"ml-security":0.0856331401}}
{"text":"Our method is evaluated on a publicly available food image dataset Nutrition5k, resulting a Mean Absolute Error (MAE) of 40.05 kCal and Mean Absolute Percentage Error (MAPE) of 11.47% for food energy estimation.","meta":{"url":"http://arxiv.org/abs/2308.01810v1"},"cats":{"new-dataset":0.1580281911,"dev-research":0.1514646062,"prompt-eng":0.415277881,"data-quality":0.2372724492,"ml-security":0.0580653381}}
{"text":"Our method uses RGB image as the only input at the inference stage and achieves competitive results compared to the existing method requiring both RGB and depth information.","meta":{"url":"http://arxiv.org/abs/2308.01810v1"},"cats":{"new-dataset":0.1615155339,"dev-research":0.1775404326,"prompt-eng":0.4085660576,"data-quality":0.1169744103,"ml-security":0.0633309798}}
{"text":"Cooperative perception can effectively enhance individual perception performance by providing additional viewpoint and expanding the sensing field.","meta":{"url":"http://arxiv.org/abs/2308.01804v1"},"cats":{"new-dataset":0.0058742157,"dev-research":0.2698710898,"prompt-eng":0.4243419568,"data-quality":0.1113838328,"ml-security":0.1096294883}}
{"text":"Existing cooperation paradigms are either interpretable (result cooperation) or flexible (feature cooperation).","meta":{"url":"http://arxiv.org/abs/2308.01804v1"},"cats":{"new-dataset":0.0235977273,"dev-research":0.3456429504,"prompt-eng":0.4013869832,"data-quality":0.1283744001,"ml-security":0.1129018975}}
{"text":"In this paper, we propose the concept of query cooperation to enable interpretable instance-level flexible feature interaction.","meta":{"url":"http://arxiv.org/abs/2308.01804v1"},"cats":{"new-dataset":0.0271371354,"dev-research":0.3884409425,"prompt-eng":0.4880087646,"data-quality":0.1905117438,"ml-security":0.1704190054}}
{"text":"To specifically explain the concept, we propose a cooperative perception framework, termed QUEST, which let query stream flow among agents.","meta":{"url":"http://arxiv.org/abs/2308.01804v1"},"cats":{"new-dataset":0.0622134678,"dev-research":0.2381703569,"prompt-eng":0.430300486,"data-quality":0.1198895097,"ml-security":0.1108070514}}
{"text":"The cross-agent queries are interacted via fusion for co-aware instances and complementation for individual unaware instances.","meta":{"url":"http://arxiv.org/abs/2308.01804v1"},"cats":{"new-dataset":0.0959919361,"dev-research":0.2816102712,"prompt-eng":0.4706838878,"data-quality":0.2008985084,"ml-security":0.1759113896}}
{"text":"Taking camera-based vehicle-infrastructure perception as a typical practical application scene, the experimental results on the real-world dataset, DAIR-V2X-Seq, demonstrate the effectiveness of QUEST and further reveal the advantage of the query cooperation paradigm on transmission flexibility and robustness to packet dropout.","meta":{"url":"http://arxiv.org/abs/2308.01804v1"},"cats":{"new-dataset":0.2016498273,"dev-research":0.2552505962,"prompt-eng":0.4134246272,"data-quality":0.1350041055,"ml-security":0.1357740681}}
{"text":"We hope our work can further facilitate the cross-agent representation interaction for better cooperative perception in practice.","meta":{"url":"http://arxiv.org/abs/2308.01804v1"},"cats":{"new-dataset":0.0907074418,"dev-research":0.2423111086,"prompt-eng":0.4318578856,"data-quality":0.1330798227,"ml-security":0.0894181131}}
{"text":"The recently proposed orthogonal delay-Doppler division multiplexing (ODDM) modulation, which is based on the new delay-Doppler (DD) domain orthogonal pulse (DDOP), is studied.","meta":{"url":"http://arxiv.org/abs/2308.01802v1"},"cats":{"new-dataset":0.0146397035,"dev-research":0.2549448551,"prompt-eng":0.3690648672,"data-quality":0.0803766625,"ml-security":0.0686378344}}
{"text":"A substantial benefit of the DDOP-based ODDM or general delay-Doppler domain multi-carrier (DDMC) modulation is that it achieves orthogonality with respect to the fine time and frequency resolutions of the DD domain.","meta":{"url":"http://arxiv.org/abs/2308.01802v1"},"cats":{"new-dataset":0.0120889339,"dev-research":0.2179535395,"prompt-eng":0.386109827,"data-quality":0.0873383879,"ml-security":0.0631809712}}
{"text":"We first revisit the family of wireless channel models conceived for linear time-varying (LTV) channels, and then review the conventional multi-carrier (MC) modulation schemes and their design guidelines for both linear time-invariant (LTI) and LTV channels.","meta":{"url":"http://arxiv.org/abs/2308.01802v1"},"cats":{"new-dataset":0.012518127,"dev-research":0.2094383386,"prompt-eng":0.3548435773,"data-quality":0.0807031374,"ml-security":0.0938115935}}
{"text":"Then we discuss the time-varying property of the LTV channels' DD domain impulse response and propose an impulse function based transmission strategy for equivalent sampled DD domain (ESDD) channels.","meta":{"url":"http://arxiv.org/abs/2308.01802v1"},"cats":{"new-dataset":0.0410853013,"dev-research":0.2151287989,"prompt-eng":0.3911670079,"data-quality":0.0948363694,"ml-security":0.1024455166}}
{"text":"Next, we take an in-depth look into the DDOP and the corresponding ODDM modulation to unveil its unique input-output relation for transmission over ESDD channels.","meta":{"url":"http://arxiv.org/abs/2308.01802v1"},"cats":{"new-dataset":0.0533173101,"dev-research":0.2101452814,"prompt-eng":0.4319657933,"data-quality":0.1334963973,"ml-security":0.1932990581}}
{"text":"Then, we point out that the conventional MC modulation design guidelines based on the Wely-Heisenberg (WH) frame theory can be relaxed without compromising its orthogonality or without violating the WH frame theory.","meta":{"url":"http://arxiv.org/abs/2308.01802v1"},"cats":{"new-dataset":0.0072306688,"dev-research":0.1850450166,"prompt-eng":0.3788816009,"data-quality":0.1197464748,"ml-security":0.1011972013}}
{"text":"More specifically, for a communication system having given bandwidth and duration, MC modulation signals can be designed based on a WH subset associated with sufficient (bi)orthogonality, which governs the (bi)orthogonality of the MC signal within the bandwidth and duration.","meta":{"url":"http://arxiv.org/abs/2308.01802v1"},"cats":{"new-dataset":0.0124799771,"dev-research":0.1880021064,"prompt-eng":0.4110591651,"data-quality":0.0725774121,"ml-security":0.0552751608}}
{"text":"This novel design guideline could potentially open up opportunities for developing future waveforms required by new applications such as communication systems associated with high delay and/or Doppler shifts, as well as integrated sensing and communications, etc.","meta":{"url":"http://arxiv.org/abs/2308.01802v1"},"cats":{"new-dataset":0.0669727092,"dev-research":0.3205938721,"prompt-eng":0.3834582185,"data-quality":0.0629540671,"ml-security":0.0512591002}}
{"text":"Job scheduling is a well-known Combinatorial Optimization problem with endless applications.","meta":{"url":"http://arxiv.org/abs/2308.01797v1"},"cats":{"new-dataset":0.2367028468,"dev-research":0.19031205,"prompt-eng":0.3550456199,"data-quality":0.1050490785,"ml-security":0.138679361}}
{"text":"Well planned schedules bring many benefits in the context of automated systems: among others, they limit production costs and waste.","meta":{"url":"http://arxiv.org/abs/2308.01797v1"},"cats":{"new-dataset":0.1029496156,"dev-research":0.4591269912,"prompt-eng":0.3826197602,"data-quality":0.0850839047,"ml-security":0.1126790625}}
{"text":"Nevertheless, the NP-hardness of this problem makes it essential to use heuristics whose design is difficult, requires specialized knowledge and often produces methods tailored to the specific task.","meta":{"url":"http://arxiv.org/abs/2308.01797v1"},"cats":{"new-dataset":0.1321919812,"dev-research":0.2353101912,"prompt-eng":0.3938645665,"data-quality":0.1320353188,"ml-security":0.0709788306}}
{"text":"This paper presents an original end-to-end Deep Reinforcement Learning approach to scheduling that automatically learns dispatching rules.","meta":{"url":"http://arxiv.org/abs/2308.01797v1"},"cats":{"new-dataset":0.2135525688,"dev-research":0.2519488145,"prompt-eng":0.3807281173,"data-quality":0.1055593075,"ml-security":0.2149252476}}
{"text":"Our technique is inspired by natural language encoder-decoder models for sequence processing and has never been used, to the best of our knowledge, for scheduling purposes.","meta":{"url":"http://arxiv.org/abs/2308.01797v1"},"cats":{"new-dataset":0.3184248605,"dev-research":0.2085239666,"prompt-eng":0.4215766153,"data-quality":0.1840759232,"ml-security":0.0799799638}}
{"text":"We applied and tested our method in particular to some benchmark instances of Job Shop Problem, but this technique is general enough to be potentially used to tackle other different optimal job scheduling tasks with minimal intervention.","meta":{"url":"http://arxiv.org/abs/2308.01797v1"},"cats":{"new-dataset":0.2196851804,"dev-research":0.2222306303,"prompt-eng":0.431782501,"data-quality":0.151036722,"ml-security":0.0508852215}}
{"text":"Results demonstrate that we outperform many classical approaches exploiting priority dispatching rules and show competitive results on state-of-the-art Deep Reinforcement Learning ones.","meta":{"url":"http://arxiv.org/abs/2308.01797v1"},"cats":{"new-dataset":0.1286439449,"dev-research":0.1987054483,"prompt-eng":0.392063821,"data-quality":0.1104501014,"ml-security":0.1627847065}}
{"text":"This paper presents efficient data structures for the implementation of matrix-free finite element methods on block-structured, hybrid tetrahedral grids.","meta":{"url":"http://arxiv.org/abs/2308.01792v1"},"cats":{"new-dataset":0.1099598974,"dev-research":0.2420668564,"prompt-eng":0.3078758285,"data-quality":0.0439789391,"ml-security":0.0452139429}}
{"text":"It provides a complete categorization of all geometric sub-objects that emerge from the regular refinement of the unstructured, tetrahedral coarse grid and describes efficient iteration patterns and analytical linearization functions for the mapping of coefficients to memory addresses.","meta":{"url":"http://arxiv.org/abs/2308.01792v1"},"cats":{"new-dataset":0.2314555085,"dev-research":0.2268813384,"prompt-eng":0.3401693625,"data-quality":0.0661190074,"ml-security":0.0648877967}}
{"text":"This foundation enables the implementation of fast, extreme-scalable, matrix-free, iterative solvers, and in particular geometric multigrid methods by design.","meta":{"url":"http://arxiv.org/abs/2308.01792v1"},"cats":{"new-dataset":0.0964625981,"dev-research":0.266227899,"prompt-eng":0.2980237496,"data-quality":0.0494184029,"ml-security":0.0509300345}}
{"text":"Their application to the variable-coefficient Stokes system subject to an enriched Galerkin discretization and to the curl-curl problem discretized with N\\'ed\\'elec edge elements showcases the flexibility of the implementation.","meta":{"url":"http://arxiv.org/abs/2308.01792v1"},"cats":{"new-dataset":0.1126436976,"dev-research":0.2259176732,"prompt-eng":0.3165019635,"data-quality":0.0623690316,"ml-security":0.0924029188}}
{"text":"Eventually, the solution of a curl-curl problem with $1.6 \\cdot 10^{11}$ (more than one hundred billion) unknowns on more than $32000$ processes with a matrix-free full multigrid solver demonstrates its extreme-scalability.","meta":{"url":"http://arxiv.org/abs/2308.01792v1"},"cats":{"new-dataset":0.1504095567,"dev-research":0.1863153933,"prompt-eng":0.3162743317,"data-quality":0.0928489066,"ml-security":0.1484755912}}
{"text":"The formation mechanisms and cyclical conditions of collective action have become open issues in research involving public choice, social movements, and more.","meta":{"url":"http://arxiv.org/abs/2308.01791v1"},"cats":{"new-dataset":0.0424720728,"dev-research":0.2105685393,"prompt-eng":0.3203428244,"data-quality":0.0986497615,"ml-security":0.1274102635}}
{"text":"For this reason, on the basis of rational decision-making and social assimilation, this paper proposes an action model that combines Bayesian game and social network dynamics, and incorporates exogenous cycles into it.","meta":{"url":"http://arxiv.org/abs/2308.01791v1"},"cats":{"new-dataset":0.0635244588,"dev-research":0.2704863228,"prompt-eng":0.3980805196,"data-quality":0.0915404459,"ml-security":0.143935692}}
{"text":"For this model, this paper proves the spontaneous action theorem and action cycle theorem of collective action, and based on numerical simulation and empirical calibration, further confirms the theoretical mechanism involving elements such as risk/risk-free incentives and the number of social ties.","meta":{"url":"http://arxiv.org/abs/2308.01791v1"},"cats":{"new-dataset":0.0728388498,"dev-research":0.1974655771,"prompt-eng":0.3317389232,"data-quality":0.1214805091,"ml-security":0.2102155501}}
{"text":"Based on such conclusions and evidence, this paper proposes a theory of spontaneous cycles as an integrative answer to the open question of collective action formation/cycles.","meta":{"url":"http://arxiv.org/abs/2308.01791v1"},"cats":{"new-dataset":0.0814251855,"dev-research":0.2359146775,"prompt-eng":0.3484714664,"data-quality":0.1201023099,"ml-security":0.1263670862}}
{"text":"Lemmatization is a Natural Language Processing (NLP) technique used to normalize text by changing morphological derivations of words to their root forms.","meta":{"url":"http://arxiv.org/abs/2308.01785v1"},"cats":{"new-dataset":0.0276657769,"dev-research":0.2862001769,"prompt-eng":0.3664925285,"data-quality":0.2413632133,"ml-security":0.0894189551}}
{"text":"It is used as a core pre-processing step in many NLP tasks including text indexing, information retrieval, and machine learning for NLP, among others.","meta":{"url":"http://arxiv.org/abs/2308.01785v1"},"cats":{"new-dataset":0.0270259199,"dev-research":0.3148339472,"prompt-eng":0.3768233689,"data-quality":0.1484077628,"ml-security":0.0549857433}}
{"text":"This paper pioneers the development of text lemmatization for the Somali language, a low-resource language with very limited or no prior effective adoption of NLP methods and datasets.","meta":{"url":"http://arxiv.org/abs/2308.01785v1"},"cats":{"new-dataset":0.4221555979,"dev-research":0.2233057331,"prompt-eng":0.334349285,"data-quality":0.2409840871,"ml-security":0.0732622069}}
{"text":"We especially develop a lexicon and rule-based lemmatizer for Somali text, which is a starting point for a full-fledged Somali lemmatization system for various NLP tasks.","meta":{"url":"http://arxiv.org/abs/2308.01785v1"},"cats":{"new-dataset":0.4366415023,"dev-research":0.2248863708,"prompt-eng":0.3849370142,"data-quality":0.2805057778,"ml-security":0.0729475147}}
{"text":"With consideration of the language morphological rules, we have developed an initial lexicon of 1247 root words and 7173 derivationally related terms enriched with rules for lemmatizing words not present in the lexicon.","meta":{"url":"http://arxiv.org/abs/2308.01785v1"},"cats":{"new-dataset":0.4460857468,"dev-research":0.2281572558,"prompt-eng":0.3840083581,"data-quality":0.2515161205,"ml-security":0.1264018351}}
{"text":"We have tested the algorithm on 120 documents of various lengths including news articles, social media posts, and text messages.","meta":{"url":"http://arxiv.org/abs/2308.01785v1"},"cats":{"new-dataset":0.3192332102,"dev-research":0.166359262,"prompt-eng":0.3582779301,"data-quality":0.17675433,"ml-security":0.0519793661}}
{"text":"Our initial results demonstrate that the algorithm achieves an accuracy of 57\\% for relatively long documents (e.g. full news articles), 60.57\\% for news article extracts, and high accuracy of 95.87\\% for short texts such as social media messages.","meta":{"url":"http://arxiv.org/abs/2308.01785v1"},"cats":{"new-dataset":0.1062825313,"dev-research":0.2155024556,"prompt-eng":0.3646508371,"data-quality":0.3497979456,"ml-security":0.0732119556}}
{"text":"With the integration of connected devices, artificial intelligence, and heterogeneous networks in IoT-driven cyber-physical systems, our society is evolving as a smart, automated, and connected community.","meta":{"url":"http://arxiv.org/abs/2308.01783v1"},"cats":{"new-dataset":0.1075441727,"dev-research":0.3000352754,"prompt-eng":0.3864902036,"data-quality":0.0894117873,"ml-security":0.0774647358}}
{"text":"In such dynamic and distributed environments, various operations are carried out considering different contextual factors to support the automation of collaborative devices and systems.","meta":{"url":"http://arxiv.org/abs/2308.01783v1"},"cats":{"new-dataset":0.0953187027,"dev-research":0.461868849,"prompt-eng":0.5113195909,"data-quality":0.10085422,"ml-security":0.0532425087}}
{"text":"These devices often perform long-lived operations or tasks (referred to as activities) to fulfill larger goals in the collaborative environment.","meta":{"url":"http://arxiv.org/abs/2308.01783v1"},"cats":{"new-dataset":0.0883516932,"dev-research":0.3769361585,"prompt-eng":0.3963534575,"data-quality":0.0602693119,"ml-security":0.0630275219}}
{"text":"These activities are usually mutable (change states) and interdependent.","meta":{"url":"http://arxiv.org/abs/2308.01783v1"},"cats":{"new-dataset":0.0636673552,"dev-research":0.2597050236,"prompt-eng":0.3550511761,"data-quality":0.0989936052,"ml-security":0.0593807246}}
{"text":"They can influence the execution of other activities in the ecosystem, requiring active and real-time monitoring of the entire connected environment.   ","meta":{"url":"http://arxiv.org/abs/2308.01783v1"},"cats":{"new-dataset":0.0670846939,"dev-research":0.30345216,"prompt-eng":0.3858949394,"data-quality":0.0969286927,"ml-security":0.1284835875}}
{"text":"Recently, a vision for activity-centric access control(ACAC) was proposed to enable security modeling and enforcement from the perspective and abstraction of interdependent activities.","meta":{"url":"http://arxiv.org/abs/2308.01783v1"},"cats":{"new-dataset":0.1304190854,"dev-research":0.3608479938,"prompt-eng":0.4233542075,"data-quality":0.083911868,"ml-security":0.3862371307}}
{"text":"The proposed ACAC incorporates four decision parameters: Authorizations(A), oBligations(B), Conditions(C), and activity Dependencies(D) for an object agnostic access control in smart systems.","meta":{"url":"http://arxiv.org/abs/2308.01783v1"},"cats":{"new-dataset":0.0609097505,"dev-research":0.2715119094,"prompt-eng":0.4519807617,"data-quality":0.0956830406,"ml-security":0.1557073012}}
{"text":"In this paper, we take a step further towards maturing ACAC by focusing on activity dependencies(D) and developing a family of formal mathematically grounded models, referred to as ACAC_D. These formal models consider the real-time mutability of activities in resolving active dependencies among various activities in the ecosystem.","meta":{"url":"http://arxiv.org/abs/2308.01783v1"},"cats":{"new-dataset":0.1847823778,"dev-research":0.2837392479,"prompt-eng":0.409093858,"data-quality":0.1137660307,"ml-security":0.0910238948}}
{"text":"Activity dependencies can form a chain where it is possible to have dependencies of dependencies.","meta":{"url":"http://arxiv.org/abs/2308.01783v1"},"cats":{"new-dataset":0.0391335064,"dev-research":0.2750244734,"prompt-eng":0.3702169767,"data-quality":0.1089790264,"ml-security":0.0982603561}}
{"text":"In ACAC, we also consider the chain of dependencies while handling the mutability of an activity.","meta":{"url":"http://arxiv.org/abs/2308.01783v1"},"cats":{"new-dataset":0.0874935621,"dev-research":0.2762532814,"prompt-eng":0.3916621239,"data-quality":0.1651721937,"ml-security":0.1169422481}}
{"text":"We highlight the challenges while dealing with chain of dependencies, and provide solutions to resolve these challenges.","meta":{"url":"http://arxiv.org/abs/2308.01783v1"},"cats":{"new-dataset":0.2524692975,"dev-research":0.3620360177,"prompt-eng":0.4215200547,"data-quality":0.2881736225,"ml-security":0.1403021899}}
{"text":"We also present a proof of concept implementation of with performance analysis for a smart farming use case.","meta":{"url":"http://arxiv.org/abs/2308.01783v1"},"cats":{"new-dataset":0.1013886035,"dev-research":0.3918495967,"prompt-eng":0.4549613375,"data-quality":0.1207290123,"ml-security":0.0710634344}}
{"text":"Binary codes of length $n$ may be viewed as subsets of vertices of the Boolean hypercube $\\{0,1\\}^n$. The ability of a linear error-correcting code to recover erasures is connected to influences of particular monotone Boolean functions.","meta":{"url":"http://arxiv.org/abs/2308.01781v1"},"cats":{"new-dataset":0.0611842612,"dev-research":0.3045885297,"prompt-eng":0.3353035494,"data-quality":0.2932331616,"ml-security":0.1754694542}}
{"text":"These functions provide insight into the role that particular coordinates play in a code's erasure repair capability.","meta":{"url":"http://arxiv.org/abs/2308.01781v1"},"cats":{"new-dataset":0.059472799,"dev-research":0.3798549121,"prompt-eng":0.3630876596,"data-quality":0.2073821938,"ml-security":0.1485517983}}
{"text":"In this paper, we consider directly the influences of coordinates of a code.","meta":{"url":"http://arxiv.org/abs/2308.01781v1"},"cats":{"new-dataset":0.0492024385,"dev-research":0.3617551472,"prompt-eng":0.4050303615,"data-quality":0.2096427123,"ml-security":0.2009747778}}
{"text":"We describe a family of codes, called codes with minimum disjoint support, for which all influences may be determined.","meta":{"url":"http://arxiv.org/abs/2308.01781v1"},"cats":{"new-dataset":0.1903162111,"dev-research":0.2330449659,"prompt-eng":0.4097203242,"data-quality":0.1937163942,"ml-security":0.1115491342}}
{"text":"As a consequence, we find influences of repetition codes and certain distinct weight codes.","meta":{"url":"http://arxiv.org/abs/2308.01781v1"},"cats":{"new-dataset":0.0331224541,"dev-research":0.2299627538,"prompt-eng":0.4074120522,"data-quality":0.2652538838,"ml-security":0.1510261807}}
{"text":"Computing influences is typically circumvented by appealing to the transitivity of the automorphism group of the code.","meta":{"url":"http://arxiv.org/abs/2308.01781v1"},"cats":{"new-dataset":0.0213217176,"dev-research":0.3961745012,"prompt-eng":0.4288203052,"data-quality":0.1937977724,"ml-security":0.1762195862}}
{"text":"Some of the codes considered here fail to meet the transitivity conditions requires for these standard approaches, yet we can compute them directly.","meta":{"url":"http://arxiv.org/abs/2308.01781v1"},"cats":{"new-dataset":0.140118279,"dev-research":0.1566342569,"prompt-eng":0.362703376,"data-quality":0.2053826352,"ml-security":0.0997817947}}
{"text":"Weakly-supervised image segmentation has recently attracted increasing research attentions, aiming to avoid the expensive pixel-wise labeling.","meta":{"url":"http://arxiv.org/abs/2308.01779v1"},"cats":{"new-dataset":0.1455908168,"dev-research":0.1834491661,"prompt-eng":0.4399311541,"data-quality":0.4005601909,"ml-security":0.1177080905}}
{"text":"In this paper, we present an effective method, namely Point2Mask, to achieve high-quality panoptic prediction using only a single random point annotation per target for training.","meta":{"url":"http://arxiv.org/abs/2308.01779v1"},"cats":{"new-dataset":0.285015821,"dev-research":0.2608207098,"prompt-eng":0.466449343,"data-quality":0.218599328,"ml-security":0.0889349544}}
{"text":"Specifically, we formulate the panoptic pseudo-mask generation as an Optimal Transport (OT) problem, where each ground-truth (gt) point label and pixel sample are defined as the label supplier and consumer, respectively.","meta":{"url":"http://arxiv.org/abs/2308.01779v1"},"cats":{"new-dataset":0.1392517778,"dev-research":0.1583085974,"prompt-eng":0.4149776182,"data-quality":0.2050423828,"ml-security":0.1009736135}}
{"text":"The transportation cost is calculated by the introduced task-oriented maps, which focus on the category-wise and instance-wise differences among the various thing and stuff targets.","meta":{"url":"http://arxiv.org/abs/2308.01779v1"},"cats":{"new-dataset":0.0430012909,"dev-research":0.3212867996,"prompt-eng":0.4093790045,"data-quality":0.0945944673,"ml-security":0.0521501728}}
{"text":"Furthermore, a centroid-based scheme is proposed to set the accurate unit number for each gt point supplier.","meta":{"url":"http://arxiv.org/abs/2308.01779v1"},"cats":{"new-dataset":0.1066724367,"dev-research":0.2241439419,"prompt-eng":0.4385419718,"data-quality":0.1369957858,"ml-security":0.0410950521}}
{"text":"Hence, the pseudo-mask generation is converted into finding the optimal transport plan at a globally minimal transportation cost, which can be solved via the Sinkhorn-Knopp Iteration.","meta":{"url":"http://arxiv.org/abs/2308.01779v1"},"cats":{"new-dataset":0.0928693219,"dev-research":0.1940532539,"prompt-eng":0.3787268899,"data-quality":0.0832314362,"ml-security":0.1002712549}}
{"text":"Experimental results on Pascal VOC and COCO demonstrate the promising performance of our proposed Point2Mask approach to point-supervised panoptic segmentation.","meta":{"url":"http://arxiv.org/abs/2308.01779v1"},"cats":{"new-dataset":0.2710158964,"dev-research":0.1961250027,"prompt-eng":0.3980092734,"data-quality":0.1847396225,"ml-security":0.0584346972}}
{"text":"Source code is available at: https://github.com/LiWentomng/Point2Mask.","meta":{"url":"http://arxiv.org/abs/2308.01779v1"},"cats":{"new-dataset":0.278190624,"dev-research":0.1853278891,"prompt-eng":0.4287312263,"data-quality":0.1292521747,"ml-security":0.0320389677}}
{"text":"As large language models, such as GPT, continue to advance the capabilities of natural language processing (NLP), the question arises: does the problem of correction still persist?","meta":{"url":"http://arxiv.org/abs/2308.01776v1"},"cats":{"new-dataset":0.049981935,"dev-research":0.2785826923,"prompt-eng":0.3455357928,"data-quality":0.4107471981,"ml-security":0.117152825}}
{"text":"This paper investigates the role of correction in the context of large language models by conducting two experiments.","meta":{"url":"http://arxiv.org/abs/2308.01776v1"},"cats":{"new-dataset":0.0247146783,"dev-research":0.2769672239,"prompt-eng":0.4203532272,"data-quality":0.500473252,"ml-security":0.1172569109}}
{"text":"The first experiment focuses on correction as a standalone task, employing few-shot learning techniques with GPT-like models for error correction.","meta":{"url":"http://arxiv.org/abs/2308.01776v1"},"cats":{"new-dataset":0.1371971427,"dev-research":0.2498058784,"prompt-eng":0.4340414746,"data-quality":0.3579223975,"ml-security":0.0798872759}}
{"text":"The second experiment explores the notion of correction as a preparatory task for other NLP tasks, examining whether large language models can tolerate and perform adequately on texts containing certain levels of noise or errors.","meta":{"url":"http://arxiv.org/abs/2308.01776v1"},"cats":{"new-dataset":0.0674310915,"dev-research":0.3232134936,"prompt-eng":0.4368385037,"data-quality":0.5094594091,"ml-security":0.087586949}}
{"text":"By addressing these experiments, we aim to shed light on the significance of correction in the era of large language models and its implications for various NLP applications.","meta":{"url":"http://arxiv.org/abs/2308.01776v1"},"cats":{"new-dataset":0.0657298662,"dev-research":0.2454048736,"prompt-eng":0.4220007559,"data-quality":0.5914002675,"ml-security":0.1235469056}}
{"text":"This study investigated the potential of end-to-end deep learning tools as a more effective substitute for FEM in predicting stress-strain fields within 2D cross sections of arterial wall.","meta":{"url":"http://arxiv.org/abs/2308.01771v1"},"cats":{"new-dataset":0.0932412718,"dev-research":0.2497334435,"prompt-eng":0.318584307,"data-quality":0.1022685991,"ml-security":0.1189400239}}
{"text":"We first proposed a U-Net based fully convolutional neural network (CNN) to predict the von Mises stress and strain distribution based on the spatial arrangement of calcification within arterial wall cross-sections.","meta":{"url":"http://arxiv.org/abs/2308.01771v1"},"cats":{"new-dataset":0.1358762751,"dev-research":0.2439691916,"prompt-eng":0.3283067311,"data-quality":0.1813768392,"ml-security":0.1158369391}}
{"text":"Further, we developed a conditional generative adversarial network (cGAN) to enhance, particularly from the perceptual perspective, the prediction accuracy of stress and strain field maps for arterial walls with various calcification quantities and spatial configurations.","meta":{"url":"http://arxiv.org/abs/2308.01771v1"},"cats":{"new-dataset":0.2244541061,"dev-research":0.251144514,"prompt-eng":0.3239543185,"data-quality":0.1400835812,"ml-security":0.1660056769}}
{"text":"On top of U-Net and cGAN, we also proposed their ensemble approaches, respectively, to further improve the prediction accuracy of field maps.","meta":{"url":"http://arxiv.org/abs/2308.01771v1"},"cats":{"new-dataset":0.2413210339,"dev-research":0.2027373498,"prompt-eng":0.3752759412,"data-quality":0.2057879803,"ml-security":0.1010567683}}
{"text":"Our dataset, consisting of input and output images, was generated by implementing boundary conditions and extracting stress-strain field maps.","meta":{"url":"http://arxiv.org/abs/2308.01771v1"},"cats":{"new-dataset":0.6925703662,"dev-research":0.2163946918,"prompt-eng":0.3667510776,"data-quality":0.1264753894,"ml-security":0.0466427315}}
{"text":"The trained U-Net models can accurately predict von Mises stress and strain fields, with structural similarity index scores (SSIM) of 0.854 and 0.830 and mean squared errors of 0.017 and 0.018 for stress and strain, respectively, on a reserved test set.","meta":{"url":"http://arxiv.org/abs/2308.01771v1"},"cats":{"new-dataset":0.0326747406,"dev-research":0.2618138571,"prompt-eng":0.4024523783,"data-quality":0.2542444735,"ml-security":0.098482339}}
{"text":"Meanwhile, the cGAN models in a combination of ensemble and transfer learning techniques demonstrate high accuracy in predicting von Mises stress and strain fields, as evidenced by SSIM scores of 0.890 for stress and 0.803 for strain.","meta":{"url":"http://arxiv.org/abs/2308.01771v1"},"cats":{"new-dataset":0.1007741695,"dev-research":0.2530291391,"prompt-eng":0.3719406875,"data-quality":0.3097797591,"ml-security":0.1151168171}}
{"text":"Additionally, mean squared errors of 0.008 for stress and 0.017 for strain further support the model's performance on a designated test set.","meta":{"url":"http://arxiv.org/abs/2308.01771v1"},"cats":{"new-dataset":0.099612209,"dev-research":0.2273116371,"prompt-eng":0.3961267681,"data-quality":0.2317441287,"ml-security":0.0665431688}}
{"text":"Overall, this study developed a surrogate model for finite element analysis, which can accurately and efficiently predict stress-strain fields of arterial walls regardless of complex geometries and boundary conditions.","meta":{"url":"http://arxiv.org/abs/2308.01771v1"},"cats":{"new-dataset":0.0405687732,"dev-research":0.2605556543,"prompt-eng":0.3338648096,"data-quality":0.0620788612,"ml-security":0.0839163039}}
{"text":"Tensor decompositions are powerful tools for analyzing multi-dimensional data in their original format.","meta":{"url":"http://arxiv.org/abs/2308.01768v1"},"cats":{"new-dataset":0.1757052025,"dev-research":0.1826909145,"prompt-eng":0.3354944099,"data-quality":0.1215910734,"ml-security":0.0932138898}}
{"text":"Besides tensor decompositions like Tucker and CP, Tensor SVD (t-SVD) which is based on the t-product of tensors is another extension of SVD to tensors that recently developed and has found numerous applications in analyzing high dimensional data.","meta":{"url":"http://arxiv.org/abs/2308.01768v1"},"cats":{"new-dataset":0.1698699721,"dev-research":0.1936767428,"prompt-eng":0.3335429844,"data-quality":0.1031464826,"ml-security":0.1016954205}}
{"text":"This paper offers a new insight into the t-Product and shows that this product is a block convolution of two tensors with periodic boundary conditions.","meta":{"url":"http://arxiv.org/abs/2308.01768v1"},"cats":{"new-dataset":0.0952926918,"dev-research":0.1244030799,"prompt-eng":0.314298276,"data-quality":0.1077932183,"ml-security":0.1266322147}}
{"text":"Based on this viewpoint, we propose a new tensor-tensor product called the $\\star_c{}\\text{-Product}$ based on Block convolution with reflective boundary conditions.","meta":{"url":"http://arxiv.org/abs/2308.01768v1"},"cats":{"new-dataset":0.1453317737,"dev-research":0.1307842515,"prompt-eng":0.3332328685,"data-quality":0.1306886054,"ml-security":0.1365047086}}
{"text":"Using a tensor framework, this product can be easily extended to tensors of arbitrary order.","meta":{"url":"http://arxiv.org/abs/2308.01768v1"},"cats":{"new-dataset":0.1437587661,"dev-research":0.1195602471,"prompt-eng":0.3653692259,"data-quality":0.1044378279,"ml-security":0.0946733166}}
{"text":"Additionally, we introduce a tensor decomposition based on our $\\star_c{}\\text{-Product}$ for arbitrary order tensors.","meta":{"url":"http://arxiv.org/abs/2308.01768v1"},"cats":{"new-dataset":0.2710078982,"dev-research":0.1280992682,"prompt-eng":0.3438685041,"data-quality":0.1474345476,"ml-security":0.1256526185}}
{"text":"Compared to t-SVD, our new decomposition has lower complexity, and experiments show that it yields higher-quality results in applications such as classification and compression.","meta":{"url":"http://arxiv.org/abs/2308.01768v1"},"cats":{"new-dataset":0.143006423,"dev-research":0.2316768619,"prompt-eng":0.3335195752,"data-quality":0.2837430478,"ml-security":0.1055121606}}
{"text":"We introduce PoissonNet, an architecture for shape reconstruction that addresses the challenge of recovering 3D shapes from points.","meta":{"url":"http://arxiv.org/abs/2308.01766v1"},"cats":{"new-dataset":0.231065515,"dev-research":0.1764781027,"prompt-eng":0.3192566463,"data-quality":0.1208702745,"ml-security":0.1239828062}}
{"text":"Traditional deep neural networks face challenges with common 3D shape discretization techniques due to their computational complexity at higher resolutions.","meta":{"url":"http://arxiv.org/abs/2308.01766v1"},"cats":{"new-dataset":0.077870852,"dev-research":0.2121946409,"prompt-eng":0.2794263154,"data-quality":0.0867435419,"ml-security":0.1470695631}}
{"text":"To overcome this, we leverage Fourier Neural Operators (FNOs) to solve the Poisson equation and reconstruct a mesh from oriented point cloud measurements.","meta":{"url":"http://arxiv.org/abs/2308.01766v1"},"cats":{"new-dataset":0.1792210606,"dev-research":0.1587923808,"prompt-eng":0.3185388556,"data-quality":0.0788413871,"ml-security":0.1216382743}}
{"text":"PoissonNet exhibits two main advantages.","meta":{"url":"http://arxiv.org/abs/2308.01766v1"},"cats":{"new-dataset":0.0375359295,"dev-research":0.215377186,"prompt-eng":0.3178136798,"data-quality":0.1029697532,"ml-security":0.1528127893}}
{"text":"First, it enables efficient training on low-resolution data while achieving comparable performance at high-resolution evaluation, thanks to the resolution-agnostic nature of FNOs.","meta":{"url":"http://arxiv.org/abs/2308.01766v1"},"cats":{"new-dataset":0.2129324276,"dev-research":0.1765170938,"prompt-eng":0.3474396038,"data-quality":0.1568952927,"ml-security":0.0596284644}}
{"text":"This feature allows for one-shot super-resolution.","meta":{"url":"http://arxiv.org/abs/2308.01766v1"},"cats":{"new-dataset":0.0232674872,"dev-research":0.2728745716,"prompt-eng":0.3907988633,"data-quality":0.0983939628,"ml-security":0.0546004547}}
{"text":"Second, our method surpasses existing approaches in reconstruction quality while being differentiable.","meta":{"url":"http://arxiv.org/abs/2308.01766v1"},"cats":{"new-dataset":0.0909781221,"dev-research":0.2173266802,"prompt-eng":0.320233685,"data-quality":0.1672358791,"ml-security":0.0604249723}}
{"text":"Overall, our proposed method not only improves upon the limitations of classical deep neural networks in shape reconstruction but also achieves superior results in terms of reconstruction quality, running time, and resolution flexibility.","meta":{"url":"http://arxiv.org/abs/2308.01766v1"},"cats":{"new-dataset":0.0849689321,"dev-research":0.1956579001,"prompt-eng":0.2822225024,"data-quality":0.0932913609,"ml-security":0.1167886149}}
{"text":"Furthermore, we demonstrate that the Poisson surface reconstruction problem is well-posed in the limit case by showing a universal approximation theorem for the solution operator of the Poisson equation with distributional data utilizing the Fourier Neuronal Operator, which provides a theoretical foundation for our numerical results.","meta":{"url":"http://arxiv.org/abs/2308.01766v1"},"cats":{"new-dataset":0.1341716304,"dev-research":0.1526321366,"prompt-eng":0.2864405036,"data-quality":0.0729649482,"ml-security":0.1018196822}}
{"text":"The code to reproduce the experiments is available on: \\url{https://github.com/arsenal9971/PoissonNet}.","meta":{"url":"http://arxiv.org/abs/2308.01766v1"},"cats":{"new-dataset":0.2107532423,"dev-research":0.1241946606,"prompt-eng":0.4254844836,"data-quality":0.1646240545,"ml-security":0.0770969665}}
{"text":"Schema matching is a core data integration task, focusing on identifying correspondences among attributes of multiple schemata.","meta":{"url":"http://arxiv.org/abs/2308.01761v1"},"cats":{"new-dataset":0.1280165199,"dev-research":0.2505987478,"prompt-eng":0.4336051172,"data-quality":0.196044166,"ml-security":0.0463720749}}
{"text":"Numerous algorithmic approaches were suggested for schema matching over the years, aiming at solving the task with as little human involvement as possible.","meta":{"url":"http://arxiv.org/abs/2308.01761v1"},"cats":{"new-dataset":0.13136015,"dev-research":0.2362731091,"prompt-eng":0.4655005671,"data-quality":0.1945460657,"ml-security":0.0391726922}}
{"text":"Yet, humans are still required in the loop -- to validate algorithms and to produce ground truth data for algorithms to be trained against.","meta":{"url":"http://arxiv.org/abs/2308.01761v1"},"cats":{"new-dataset":0.1042391468,"dev-research":0.3455390876,"prompt-eng":0.3602026998,"data-quality":0.1994611762,"ml-security":0.2717871598}}
{"text":"In recent years, a new research direction investigates the capabilities and behavior of humans while performing matching tasks.","meta":{"url":"http://arxiv.org/abs/2308.01761v1"},"cats":{"new-dataset":0.0385953805,"dev-research":0.2569505734,"prompt-eng":0.4090907209,"data-quality":0.0592625399,"ml-security":0.0809989542}}
{"text":"Previous works utilized this knowledge to predict, and even improve, the performance of human matchers.","meta":{"url":"http://arxiv.org/abs/2308.01761v1"},"cats":{"new-dataset":0.1039870856,"dev-research":0.2248080497,"prompt-eng":0.3978985916,"data-quality":0.1290757658,"ml-security":0.1154875264}}
{"text":"In this work, we continue this line of research by suggesting a novel measure to evaluate the performance of human matchers, based on calibration, a common meta-cognition measure.","meta":{"url":"http://arxiv.org/abs/2308.01761v1"},"cats":{"new-dataset":0.0465827875,"dev-research":0.261987624,"prompt-eng":0.5032957191,"data-quality":0.1743969083,"ml-security":0.0766870785}}
{"text":"The proposed measure enables detailed analysis of various factors of the behavior of human matchers and their relation to human performance.","meta":{"url":"http://arxiv.org/abs/2308.01761v1"},"cats":{"new-dataset":0.0352086273,"dev-research":0.2143318556,"prompt-eng":0.4209422666,"data-quality":0.1199490242,"ml-security":0.0878877983}}
{"text":"Such analysis can be further utilized to develop heuristics and methods to better asses and improve the annotation quality.","meta":{"url":"http://arxiv.org/abs/2308.01761v1"},"cats":{"new-dataset":0.1982164163,"dev-research":0.3668341874,"prompt-eng":0.4439113555,"data-quality":0.3069962584,"ml-security":0.0727799811}}
{"text":"Efficient exploration in complex environments remains a major challenge for reinforcement learning (RL).","meta":{"url":"http://arxiv.org/abs/2308.01759v1"},"cats":{"new-dataset":0.0544712212,"dev-research":0.2387183112,"prompt-eng":0.3740099297,"data-quality":0.076040052,"ml-security":0.1187367628}}
{"text":"Compared to previous Thompson sampling-inspired mechanisms that enable temporally extended exploration, i.e., deep exploration, we focus on deep exploration in distributional RL.","meta":{"url":"http://arxiv.org/abs/2308.01759v1"},"cats":{"new-dataset":0.0652439211,"dev-research":0.1934049071,"prompt-eng":0.3684378536,"data-quality":0.0808958463,"ml-security":0.1263646491}}
{"text":"We develop here a general purpose approach, Bag of Policies (BoP), that can be built on top of any return distribution estimator by maintaining a population of its copies.","meta":{"url":"http://arxiv.org/abs/2308.01759v1"},"cats":{"new-dataset":0.2611997808,"dev-research":0.1526088281,"prompt-eng":0.4355061181,"data-quality":0.1550048746,"ml-security":0.1576201901}}
{"text":"BoP consists of an ensemble of multiple heads that are updated independently.","meta":{"url":"http://arxiv.org/abs/2308.01759v1"},"cats":{"new-dataset":0.1085250388,"dev-research":0.2477409859,"prompt-eng":0.4217495521,"data-quality":0.1732494602,"ml-security":0.0668080347}}
{"text":"During training, each episode is controlled by only one of the heads and the collected state-action pairs are used to update all heads off-policy, leading to distinct learning signals for each head which diversify learning and behaviour.","meta":{"url":"http://arxiv.org/abs/2308.01759v1"},"cats":{"new-dataset":0.1463689498,"dev-research":0.2622137001,"prompt-eng":0.4168301696,"data-quality":0.1352384062,"ml-security":0.1486996916}}
{"text":"To test whether optimistic ensemble method can improve on distributional RL as did on scalar RL, by e.g. Bootstrapped DQN, we implement the BoP approach with a population of distributional actor-critics using Bayesian Distributional Policy Gradients (BDPG).","meta":{"url":"http://arxiv.org/abs/2308.01759v1"},"cats":{"new-dataset":0.0774524434,"dev-research":0.208498805,"prompt-eng":0.3837885911,"data-quality":0.2017113722,"ml-security":0.2015169133}}
{"text":"The population thus approximates a posterior distribution of return distributions along with a posterior distribution of policies.","meta":{"url":"http://arxiv.org/abs/2308.01759v1"},"cats":{"new-dataset":0.0412523551,"dev-research":0.1512428083,"prompt-eng":0.4041965046,"data-quality":0.1156905223,"ml-security":0.1604648954}}
{"text":"Another benefit of building upon BDPG is that it allows to analyze global posterior uncertainty along with local curiosity bonus simultaneously for exploration.","meta":{"url":"http://arxiv.org/abs/2308.01759v1"},"cats":{"new-dataset":0.0392890623,"dev-research":0.2947514457,"prompt-eng":0.4189199992,"data-quality":0.073033688,"ml-security":0.0703014882}}
{"text":"As BDPG is already an optimistic method, this pairing helps to investigate if optimism is accumulatable in distributional RL.","meta":{"url":"http://arxiv.org/abs/2308.01759v1"},"cats":{"new-dataset":0.0710262251,"dev-research":0.2040129352,"prompt-eng":0.431593463,"data-quality":0.121881306,"ml-security":0.0851514345}}
{"text":"Overall BoP results in greater robustness and speed during learning as demonstrated by our experimental results on ALE Atari games.","meta":{"url":"http://arxiv.org/abs/2308.01759v1"},"cats":{"new-dataset":0.0421356611,"dev-research":0.3007382007,"prompt-eng":0.4206289892,"data-quality":0.1917885944,"ml-security":0.2747845338}}
{"text":"Humans possess a remarkable ability to react to sudden and unpredictable perturbations through immediate mechanical responses, which harness the visco-elastic properties of muscles to perform auto-corrective movements to maintain balance.","meta":{"url":"http://arxiv.org/abs/2308.01758v1"},"cats":{"new-dataset":0.0185523303,"dev-research":0.2772180882,"prompt-eng":0.3736093034,"data-quality":0.113769753,"ml-security":0.1876931183}}
{"text":"In this paper, we propose a novel design of a robotic leg inspired by this mechanism.","meta":{"url":"http://arxiv.org/abs/2308.01758v1"},"cats":{"new-dataset":0.0517463997,"dev-research":0.1801110942,"prompt-eng":0.3937549662,"data-quality":0.0725439771,"ml-security":0.0510194837}}
{"text":"We develop multi-material fibre jammed tendons, and demonstrate their use as passive compliant mechanisms to achieve variable joint stiffness and improve stability.","meta":{"url":"http://arxiv.org/abs/2308.01758v1"},"cats":{"new-dataset":0.0422751411,"dev-research":0.2270380465,"prompt-eng":0.3333286938,"data-quality":0.1011446381,"ml-security":0.0635634475}}
{"text":"Through numerical simulations and extensive experimentation, we demonstrate the ability for our system to achieve a wide range of potentially beneficial compliance regimes.","meta":{"url":"http://arxiv.org/abs/2308.01758v1"},"cats":{"new-dataset":0.0442783949,"dev-research":0.2242505606,"prompt-eng":0.4431596215,"data-quality":0.086804423,"ml-security":0.1506054994}}
{"text":"We show the role and contribution of each tendon quantitatively by evaluating their individual force contribution in resisting rotational perturbations.","meta":{"url":"http://arxiv.org/abs/2308.01758v1"},"cats":{"new-dataset":0.0403271006,"dev-research":0.1553635993,"prompt-eng":0.3082732183,"data-quality":0.0853484102,"ml-security":0.1377936808}}
{"text":"We also perform walking experiments with programmed bioinspired gaits that varying the stiffness of the tendons throughout the gait cycle, demonstrating a stable and consistent behaviour.","meta":{"url":"http://arxiv.org/abs/2308.01758v1"},"cats":{"new-dataset":0.1114399907,"dev-research":0.2512051134,"prompt-eng":0.3616722008,"data-quality":0.1026087725,"ml-security":0.0970517554}}
{"text":"We show the potential of such systems when integrated into legged robots, where compliance and shock absorption can be provided entirely through the morphological properties of the leg.","meta":{"url":"http://arxiv.org/abs/2308.01758v1"},"cats":{"new-dataset":0.0572146716,"dev-research":0.1801686238,"prompt-eng":0.3911057582,"data-quality":0.0627136665,"ml-security":0.0993210774}}
{"text":"Intelligent systems have become a major part of our lives.","meta":{"url":"http://arxiv.org/abs/2308.01752v1"},"cats":{"new-dataset":0.0975852586,"dev-research":0.2924111002,"prompt-eng":0.3462546786,"data-quality":0.1136107858,"ml-security":0.1602039151}}
{"text":"Human responsibility for outcomes becomes unclear in the interaction with these systems, as parts of information acquisition, decision-making, and action implementation may be carried out jointly by humans and systems.","meta":{"url":"http://arxiv.org/abs/2308.01752v1"},"cats":{"new-dataset":0.0942759274,"dev-research":0.3938188273,"prompt-eng":0.4111519363,"data-quality":0.2183198237,"ml-security":0.1013708026}}
{"text":"Determining human causal responsibility with intelligent systems is particularly important in events that end with adverse outcomes.","meta":{"url":"http://arxiv.org/abs/2308.01752v1"},"cats":{"new-dataset":0.080027576,"dev-research":0.3498182046,"prompt-eng":0.4011386265,"data-quality":0.2085559412,"ml-security":0.2362127029}}
{"text":"We developed three measures of retrospective human causal responsibility when using intelligent systems.","meta":{"url":"http://arxiv.org/abs/2308.01752v1"},"cats":{"new-dataset":0.1096749304,"dev-research":0.3678720982,"prompt-eng":0.4504572977,"data-quality":0.1801450296,"ml-security":0.1208677437}}
{"text":"The first measure concerns repetitive human interactions with a system.","meta":{"url":"http://arxiv.org/abs/2308.01752v1"},"cats":{"new-dataset":0.0479070739,"dev-research":0.2428890701,"prompt-eng":0.4343065516,"data-quality":0.0958960685,"ml-security":0.086354475}}
{"text":"Using information theory, it quantifies the average human's unique contribution to the outcomes of past events.","meta":{"url":"http://arxiv.org/abs/2308.01752v1"},"cats":{"new-dataset":0.0252443553,"dev-research":0.2273993913,"prompt-eng":0.338144521,"data-quality":0.1125021446,"ml-security":0.1044980771}}
{"text":"The second and third measures concern human causal responsibility in a single past interaction with an intelligent system.","meta":{"url":"http://arxiv.org/abs/2308.01752v1"},"cats":{"new-dataset":0.0629162745,"dev-research":0.3048334201,"prompt-eng":0.4136331025,"data-quality":0.1526552883,"ml-security":0.1456006016}}
{"text":"They quantify, respectively, the unique human contribution in forming the information used for decision-making and the reasonability of the actions that the human carried out.","meta":{"url":"http://arxiv.org/abs/2308.01752v1"},"cats":{"new-dataset":0.0704289009,"dev-research":0.3480906857,"prompt-eng":0.3707388474,"data-quality":0.1673834315,"ml-security":0.0976616853}}
{"text":"The results show that human retrospective responsibility depends on the combined effects of system design and its reliability, the human's role and authority, and probabilistic factors related to the system and the environment.","meta":{"url":"http://arxiv.org/abs/2308.01752v1"},"cats":{"new-dataset":0.1022235096,"dev-research":0.3577924927,"prompt-eng":0.4502417179,"data-quality":0.1279132643,"ml-security":0.1027112921}}
{"text":"The new responsibility measures can serve to investigate and analyze past events involving intelligent systems.","meta":{"url":"http://arxiv.org/abs/2308.01752v1"},"cats":{"new-dataset":0.1469800473,"dev-research":0.337332434,"prompt-eng":0.4120088682,"data-quality":0.1801703966,"ml-security":0.1800986933}}
{"text":"They may aid the judgment of human responsibility and ethical and legal discussions, providing a novel quantitative perspective.","meta":{"url":"http://arxiv.org/abs/2308.01752v1"},"cats":{"new-dataset":0.0890772425,"dev-research":0.2926646124,"prompt-eng":0.3045688099,"data-quality":0.1687159571,"ml-security":0.1141797114}}
{"text":"Exploration and analysis of high-dimensional data are important tasks in many fields that produce large and complex data, like the financial sector, systems biology, or cultural heritage.","meta":{"url":"http://arxiv.org/abs/2308.01751v1"},"cats":{"new-dataset":0.2204464499,"dev-research":0.2143840566,"prompt-eng":0.3400321083,"data-quality":0.0651308529,"ml-security":0.0733738675}}
{"text":"Tailor-made visual analytics software is developed for each specific application, limiting their applicability in other fields.","meta":{"url":"http://arxiv.org/abs/2308.01751v1"},"cats":{"new-dataset":0.1247409086,"dev-research":0.4434615434,"prompt-eng":0.3588488851,"data-quality":0.1005322763,"ml-security":0.0760795031}}
{"text":"However, as diverse as these fields are, their characteristics and requirements for data analysis are conceptually similar.","meta":{"url":"http://arxiv.org/abs/2308.01751v1"},"cats":{"new-dataset":0.0509272309,"dev-research":0.3277067066,"prompt-eng":0.3339858288,"data-quality":0.1597430116,"ml-security":0.0847013529}}
{"text":"Many applications share abstract tasks and data types and are often constructed with similar building blocks.","meta":{"url":"http://arxiv.org/abs/2308.01751v1"},"cats":{"new-dataset":0.1217082373,"dev-research":0.4201144541,"prompt-eng":0.3888135428,"data-quality":0.1005422565,"ml-security":0.102530837}}
{"text":"Developing such applications, even when based mostly on existing building blocks, requires significant engineering efforts.","meta":{"url":"http://arxiv.org/abs/2308.01751v1"},"cats":{"new-dataset":0.0292323335,"dev-research":0.415877122,"prompt-eng":0.4014439502,"data-quality":0.0946625764,"ml-security":0.0874865817}}
{"text":"We developed ManiVault, a flexible and extensible open-source visual analytics framework for analyzing high-dimensional data.","meta":{"url":"http://arxiv.org/abs/2308.01751v1"},"cats":{"new-dataset":0.5216777984,"dev-research":0.3261352325,"prompt-eng":0.3191701127,"data-quality":0.0778800649,"ml-security":0.0595248392}}
{"text":"The primary objective of ManiVault is to facilitate rapid prototyping of visual analytics workflows for visualization software developers and practitioners alike.","meta":{"url":"http://arxiv.org/abs/2308.01751v1"},"cats":{"new-dataset":0.1492094636,"dev-research":0.5300310462,"prompt-eng":0.4013936375,"data-quality":0.0600238879,"ml-security":0.05505439}}
{"text":"ManiVault is built using a plugin-based architecture that offers easy extensibility.","meta":{"url":"http://arxiv.org/abs/2308.01751v1"},"cats":{"new-dataset":0.1111125902,"dev-research":0.35432456,"prompt-eng":0.4660089644,"data-quality":0.0550187627,"ml-security":0.0346831108}}
{"text":"While our architecture deliberately keeps plugins self-contained, to guarantee maximum flexibility and re-usability, we have designed and implemented a messaging API for tight integration and linking of modules to support common visual analytics design patterns.","meta":{"url":"http://arxiv.org/abs/2308.01751v1"},"cats":{"new-dataset":0.3453880856,"dev-research":0.4537241563,"prompt-eng":0.4084657625,"data-quality":0.1320514414,"ml-security":0.0799598135}}
{"text":"We provide several visualization and analytics plugins, and ManiVault's API makes the integration of new plugins easy for developers.","meta":{"url":"http://arxiv.org/abs/2308.01751v1"},"cats":{"new-dataset":0.2784808896,"dev-research":0.4409222573,"prompt-eng":0.3847028079,"data-quality":0.0963374026,"ml-security":0.0587414319}}
{"text":"ManiVault facilitates the distribution of visualization and analysis pipelines and results for practitioners through saving and reproducing complete application states.","meta":{"url":"http://arxiv.org/abs/2308.01751v1"},"cats":{"new-dataset":0.2136828718,"dev-research":0.4726612556,"prompt-eng":0.3954446588,"data-quality":0.0877690069,"ml-security":0.055071366}}
{"text":"As such, ManiVault can be used as a communication tool among researchers to discuss workflows and results.","meta":{"url":"http://arxiv.org/abs/2308.01751v1"},"cats":{"new-dataset":0.0467814889,"dev-research":0.3975964148,"prompt-eng":0.4126532771,"data-quality":0.0725655811,"ml-security":0.049244202}}
{"text":"A copy of this paper and all supplemental material is available at https://osf.io/9k6jw and source code at https://github.com/ManiVaultStudio.","meta":{"url":"http://arxiv.org/abs/2308.01751v1"},"cats":{"new-dataset":0.2913075479,"dev-research":0.1720788991,"prompt-eng":0.4368876801,"data-quality":0.1303445532,"ml-security":0.0376444253}}
{"text":"The presence of echo chambers, i.e. clusters of users exposed to news or opinions in line with their previous beliefs, was observed in many online debates on social platforms.","meta":{"url":"http://arxiv.org/abs/2308.01750v1"},"cats":{"new-dataset":0.073945586,"dev-research":0.2980388797,"prompt-eng":0.3589050951,"data-quality":0.1683224891,"ml-security":0.1913868278}}
{"text":"Users form an echo chamber when two different phenomena appear at the same time: 1. users interact with ones sharing similar opinions;","meta":{"url":"http://arxiv.org/abs/2308.01750v1"},"cats":{"new-dataset":0.0283345955,"dev-research":0.3943551088,"prompt-eng":0.4563280781,"data-quality":0.2363385849,"ml-security":0.1758571025}}
{"text":"2. users with similar opinions refer to the same pieces of news.","meta":{"url":"http://arxiv.org/abs/2308.01750v1"},"cats":{"new-dataset":0.0305805455,"dev-research":0.2866076387,"prompt-eng":0.3290077459,"data-quality":0.2773996332,"ml-security":0.0986565951}}
{"text":"We propose a completely unbiased entropy-based procedure to spot echo chambers.","meta":{"url":"http://arxiv.org/abs/2308.01750v1"},"cats":{"new-dataset":0.1849877058,"dev-research":0.1830885527,"prompt-eng":0.4545296627,"data-quality":0.2498509303,"ml-security":0.1429341259}}
{"text":"Remarkably, the method is completely agnostic about the nature of the data.","meta":{"url":"http://arxiv.org/abs/2308.01750v1"},"cats":{"new-dataset":0.0858167742,"dev-research":0.1522054077,"prompt-eng":0.3261596975,"data-quality":0.2148271244,"ml-security":0.0983364899}}
{"text":"In the Italian Twitter debate about Covid-19 vaccination, we find a limited presence of users in echo chambers (around 0.35% of all users), due to the limited number of validated users who are exposed to the same news.","meta":{"url":"http://arxiv.org/abs/2308.01750v1"},"cats":{"new-dataset":0.1457076575,"dev-research":0.2250409201,"prompt-eng":0.3707825268,"data-quality":0.1732782619,"ml-security":0.2833551717}}
{"text":"Nevertheless, their impact on the formation of a common discourse is strong, since echo chambers are responsible for nearly one-third of retweets of their discursive communities.","meta":{"url":"http://arxiv.org/abs/2308.01750v1"},"cats":{"new-dataset":0.1656229181,"dev-research":0.3199134449,"prompt-eng":0.3415891127,"data-quality":0.2097057985,"ml-security":0.1329587832}}
{"text":"How to enable learnability for new classes while keeping the capability well on old classes has been a crucial challenge for class incremental learning.","meta":{"url":"http://arxiv.org/abs/2308.01746v1"},"cats":{"new-dataset":0.073274396,"dev-research":0.3912652359,"prompt-eng":0.3763540817,"data-quality":0.254942552,"ml-security":0.215460941}}
{"text":"Beyond the normal case, long-tail class incremental learning and few-shot class incremental learning are also proposed to consider the data imbalance and data scarcity, respectively, which are common in real-world implementations and further exacerbate the well-known problem of catastrophic forgetting.","meta":{"url":"http://arxiv.org/abs/2308.01746v1"},"cats":{"new-dataset":0.0635893791,"dev-research":0.2634340712,"prompt-eng":0.3464197635,"data-quality":0.2758832231,"ml-security":0.3071175009}}
{"text":"Existing methods are specifically proposed for one of the three tasks.","meta":{"url":"http://arxiv.org/abs/2308.01746v1"},"cats":{"new-dataset":0.1053323435,"dev-research":0.2390512111,"prompt-eng":0.4600702947,"data-quality":0.1158182892,"ml-security":0.0379510455}}
{"text":"In this paper, we offer a unified solution to the misalignment dilemma in the three tasks.","meta":{"url":"http://arxiv.org/abs/2308.01746v1"},"cats":{"new-dataset":0.018478299,"dev-research":0.2587334036,"prompt-eng":0.4297261791,"data-quality":0.3147143197,"ml-security":0.0531101542}}
{"text":"Concretely, we propose neural collapse terminus that is a fixed structure with the maximal equiangular inter-class separation for the whole label space.","meta":{"url":"http://arxiv.org/abs/2308.01746v1"},"cats":{"new-dataset":0.1543163253,"dev-research":0.1596473356,"prompt-eng":0.3845911194,"data-quality":0.4432776821,"ml-security":0.1238177146}}
{"text":"It serves as a consistent target throughout the incremental training to avoid dividing the feature space incrementally.","meta":{"url":"http://arxiv.org/abs/2308.01746v1"},"cats":{"new-dataset":0.006234611,"dev-research":0.3727219519,"prompt-eng":0.3645924044,"data-quality":0.202366113,"ml-security":0.1555330141}}
{"text":"For CIL and LTCIL, we further propose a prototype evolving scheme to drive the backbone features into our neural collapse terminus smoothly.","meta":{"url":"http://arxiv.org/abs/2308.01746v1"},"cats":{"new-dataset":0.1455631923,"dev-research":0.2364643121,"prompt-eng":0.4191730081,"data-quality":0.1146355777,"ml-security":0.1372567637}}
{"text":"Our method also works for FSCIL with only minor adaptations.","meta":{"url":"http://arxiv.org/abs/2308.01746v1"},"cats":{"new-dataset":0.0606504654,"dev-research":0.1860053012,"prompt-eng":0.4048375893,"data-quality":0.1436629574,"ml-security":0.0654038248}}
{"text":"Theoretical analysis indicates that our method holds the neural collapse optimality in an incremental fashion regardless of data imbalance or data scarcity.","meta":{"url":"http://arxiv.org/abs/2308.01746v1"},"cats":{"new-dataset":0.0318235669,"dev-research":0.1791090034,"prompt-eng":0.3461445469,"data-quality":0.2526408968,"ml-security":0.3370752271}}
{"text":"We also design a generalized case where we do not know the total number of classes and whether the data distribution is normal, long-tail, or few-shot for each coming session, to test the generalizability of our method.","meta":{"url":"http://arxiv.org/abs/2308.01746v1"},"cats":{"new-dataset":0.1921357227,"dev-research":0.1756310611,"prompt-eng":0.421290918,"data-quality":0.2433229706,"ml-security":0.2140686606}}
{"text":"Extensive experiments with multiple datasets are conducted to demonstrate the effectiveness of our unified solution to all the three tasks and the generalized case.","meta":{"url":"http://arxiv.org/abs/2308.01746v1"},"cats":{"new-dataset":0.5588161329,"dev-research":0.17700419,"prompt-eng":0.4218814895,"data-quality":0.2202294795,"ml-security":0.0696952574}}
{"text":"Multitask learning is a powerful framework that enables one to simultaneously learn multiple related tasks by sharing information between them.","meta":{"url":"http://arxiv.org/abs/2308.01744v1"},"cats":{"new-dataset":0.0668115611,"dev-research":0.2785538535,"prompt-eng":0.3770087919,"data-quality":0.1301319769,"ml-security":0.112165}}
{"text":"Quantifying uncertainty in the estimated tasks is of pivotal importance for many downstream applications, such as online or active learning.","meta":{"url":"http://arxiv.org/abs/2308.01744v1"},"cats":{"new-dataset":0.0174783208,"dev-research":0.3011851426,"prompt-eng":0.4071748985,"data-quality":0.2064691156,"ml-security":0.1379218347}}
{"text":"In this work, we provide novel multitask confidence intervals in the challenging agnostic setting, i.e., when neither the similarity between tasks nor the tasks' features are available to the learner.","meta":{"url":"http://arxiv.org/abs/2308.01744v1"},"cats":{"new-dataset":0.274747093,"dev-research":0.2003831761,"prompt-eng":0.4233905698,"data-quality":0.1967460798,"ml-security":0.1387520186}}
{"text":"The obtained intervals do not require i.i.d. data and can be directly applied to bound the regret in online learning.","meta":{"url":"http://arxiv.org/abs/2308.01744v1"},"cats":{"new-dataset":0.0509252872,"dev-research":0.1725637594,"prompt-eng":0.3214812568,"data-quality":0.0891585112,"ml-security":0.1224418087}}
{"text":"Through a refined analysis of the multitask information gain, we obtain new regret guarantees that, depending on a task similarity parameter, can significantly improve over treating tasks independently.","meta":{"url":"http://arxiv.org/abs/2308.01744v1"},"cats":{"new-dataset":0.0135075939,"dev-research":0.3071999367,"prompt-eng":0.4448659788,"data-quality":0.1686524601,"ml-security":0.1628403604}}
{"text":"We further propose a novel online learning algorithm that achieves such improved regret without knowing this parameter in advance, i.e., automatically adapting to task similarity.","meta":{"url":"http://arxiv.org/abs/2308.01744v1"},"cats":{"new-dataset":0.0568880483,"dev-research":0.2052941352,"prompt-eng":0.4007755629,"data-quality":0.1691096303,"ml-security":0.1347096676}}
{"text":"As a second key application of our results, we introduce a novel multitask active learning setup where several tasks must be simultaneously optimized, but only one of them can be queried for feedback by the learner at each round.","meta":{"url":"http://arxiv.org/abs/2308.01744v1"},"cats":{"new-dataset":0.1099975813,"dev-research":0.3062769349,"prompt-eng":0.4438001014,"data-quality":0.224742744,"ml-security":0.1515646558}}
{"text":"For this problem, we design a no-regret algorithm that uses our confidence intervals to decide which task should be queried.","meta":{"url":"http://arxiv.org/abs/2308.01744v1"},"cats":{"new-dataset":0.1029329074,"dev-research":0.1824139195,"prompt-eng":0.5076372037,"data-quality":0.1383217112,"ml-security":0.0876527072}}
{"text":"Finally, we empirically validate our bounds and algorithms on synthetic and real-world (drug discovery) data.","meta":{"url":"http://arxiv.org/abs/2308.01744v1"},"cats":{"new-dataset":0.2823993296,"dev-research":0.2045559989,"prompt-eng":0.3353711374,"data-quality":0.1969380347,"ml-security":0.2383371523}}
{"text":"The turbulent jet ignition concept using prechambers is a promising solution to achieve stable combustion at lean conditions in large gas engines, leading to high efficiency at low emission levels.","meta":{"url":"http://arxiv.org/abs/2308.01743v1"},"cats":{"new-dataset":0.0211145938,"dev-research":0.3039456757,"prompt-eng":0.3254044227,"data-quality":0.1122889465,"ml-security":0.0964128604}}
{"text":"Due to the wide range of design and operating parameters for large gas engine prechambers, the preferred method for evaluating different designs is computational fluid dynamics (CFD), as testing in test bed measurement campaigns is time-consuming and expensive.","meta":{"url":"http://arxiv.org/abs/2308.01743v1"},"cats":{"new-dataset":0.073995186,"dev-research":0.2860682748,"prompt-eng":0.3968587862,"data-quality":0.0839231213,"ml-security":0.0563780362}}
{"text":"However, the significant computational time required for detailed CFD simulations due to the complexity of solving the underlying physics also limits its applicability.","meta":{"url":"http://arxiv.org/abs/2308.01743v1"},"cats":{"new-dataset":0.0498661778,"dev-research":0.2240199517,"prompt-eng":0.3286945228,"data-quality":0.0572082998,"ml-security":0.0691029152}}
{"text":"In optimization settings similar to the present case, i.e., where the evaluation of the objective function(s) is computationally costly, Bayesian optimization has largely replaced classical design-of-experiment.","meta":{"url":"http://arxiv.org/abs/2308.01743v1"},"cats":{"new-dataset":0.0168347148,"dev-research":0.2582006794,"prompt-eng":0.4409392316,"data-quality":0.1095488279,"ml-security":0.1110067597}}
{"text":"Thus, the present study deals with the computationally efficient Bayesian optimization of large gas engine prechambers design using CFD simulation.","meta":{"url":"http://arxiv.org/abs/2308.01743v1"},"cats":{"new-dataset":0.0708043326,"dev-research":0.2538968906,"prompt-eng":0.4044707258,"data-quality":0.0888156511,"ml-security":0.0580663357}}
{"text":"Reynolds-averaged-Navier-Stokes simulations are used to determine the target values as a function of the selected prechamber design parameters.","meta":{"url":"http://arxiv.org/abs/2308.01743v1"},"cats":{"new-dataset":0.0279378961,"dev-research":0.2424172384,"prompt-eng":0.37146811,"data-quality":0.0501920229,"ml-security":0.0713697475}}
{"text":"The results indicate that the chosen strategy is effective to find a prechamber design that achieves the desired target values.","meta":{"url":"http://arxiv.org/abs/2308.01743v1"},"cats":{"new-dataset":0.0368765511,"dev-research":0.2644761974,"prompt-eng":0.4395446152,"data-quality":0.088286085,"ml-security":0.110093732}}
{"text":"Label Distribution Learning (LDL) is a novel machine learning paradigm that assigns label distribution to each instance.","meta":{"url":"http://arxiv.org/abs/2308.01742v1"},"cats":{"new-dataset":0.1108196904,"dev-research":0.2044360843,"prompt-eng":0.417003456,"data-quality":0.4404583402,"ml-security":0.1200992008}}
{"text":"Many LDL methods proposed to leverage label correlation in the learning process to solve the exponential-sized output space; among these, many exploited the low-rank structure of label distribution to capture label correlation.","meta":{"url":"http://arxiv.org/abs/2308.01742v1"},"cats":{"new-dataset":0.076047889,"dev-research":0.2185381599,"prompt-eng":0.4167378688,"data-quality":0.4675363832,"ml-security":0.1038591529}}
{"text":"However, recent studies disclosed that label distribution matrices are typically full-rank, posing challenges to those works exploiting low-rank label correlation.","meta":{"url":"http://arxiv.org/abs/2308.01742v1"},"cats":{"new-dataset":0.0571823377,"dev-research":0.1556064373,"prompt-eng":0.3647795535,"data-quality":0.4795876986,"ml-security":0.1818703153}}
{"text":"Note that multi-label is generally low-rank; low-rank label correlation is widely adopted in multi-label learning (MLL) literature.","meta":{"url":"http://arxiv.org/abs/2308.01742v1"},"cats":{"new-dataset":0.0545710425,"dev-research":0.1864687856,"prompt-eng":0.3707996728,"data-quality":0.4654871369,"ml-security":0.075915174}}
{"text":"Inspired by that, we introduce an auxiliary MLL process in LDL and capture low-rank label correlation on that MLL rather than LDL.","meta":{"url":"http://arxiv.org/abs/2308.01742v1"},"cats":{"new-dataset":0.1238798949,"dev-research":0.1976507966,"prompt-eng":0.4425820669,"data-quality":0.3853521486,"ml-security":0.107568709}}
{"text":"In such a way, low-rank label correlation is appropriately exploited in our LDL methods.","meta":{"url":"http://arxiv.org/abs/2308.01742v1"},"cats":{"new-dataset":0.0522528002,"dev-research":0.2008130564,"prompt-eng":0.4247647775,"data-quality":0.4114497975,"ml-security":0.1515636631}}
{"text":"We conduct comprehensive experiments and demonstrate that our methods are superior to existing LDL methods.","meta":{"url":"http://arxiv.org/abs/2308.01742v1"},"cats":{"new-dataset":0.0776952462,"dev-research":0.1941770447,"prompt-eng":0.4421645102,"data-quality":0.1817611626,"ml-security":0.0983932228}}
{"text":"Besides, the ablation studies justify the advantages of exploiting low-rank label correlation in the auxiliary MLL.","meta":{"url":"http://arxiv.org/abs/2308.01742v1"},"cats":{"new-dataset":0.0456487605,"dev-research":0.2066301795,"prompt-eng":0.4002958703,"data-quality":0.3055094318,"ml-security":0.0547118263}}
{"text":"Large enterprises face a crucial imperative to achieve the Sustainable Development Goals (SDGs), especially goal 13, which focuses on combating climate change and its impacts.","meta":{"url":"http://arxiv.org/abs/2308.01741v1"},"cats":{"new-dataset":0.232555107,"dev-research":0.3297097537,"prompt-eng":0.3476013348,"data-quality":0.0823722605,"ml-security":0.0601142214}}
{"text":"To mitigate the effects of climate change, reducing enterprise Scope 3 (supply chain emissions) is vital, as it accounts for more than 90\\% of total emission inventories.","meta":{"url":"http://arxiv.org/abs/2308.01741v1"},"cats":{"new-dataset":0.0608207649,"dev-research":0.331094468,"prompt-eng":0.3520106166,"data-quality":0.131759447,"ml-security":0.0851206751}}
{"text":"However, tracking Scope 3 emissions proves challenging, as data must be collected from thousands of upstream and downstream suppliers.","meta":{"url":"http://arxiv.org/abs/2308.01741v1"},"cats":{"new-dataset":0.2114722809,"dev-research":0.2881254083,"prompt-eng":0.35728807,"data-quality":0.2525367251,"ml-security":0.16311246}}
{"text":"To address the above mentioned challenges, we propose a first-of-a-kind framework that uses domain-adapted NLP foundation models to estimate Scope 3 emissions, by utilizing financial transactions as a proxy for purchased goods and services.","meta":{"url":"http://arxiv.org/abs/2308.01741v1"},"cats":{"new-dataset":0.2313266661,"dev-research":0.2333758432,"prompt-eng":0.3758776028,"data-quality":0.2166455999,"ml-security":0.1218755661}}
{"text":"We compared the performance of the proposed framework with the state-of-art text classification models such as TF-IDF, word2Vec, and Zero shot learning.","meta":{"url":"http://arxiv.org/abs/2308.01741v1"},"cats":{"new-dataset":0.223055831,"dev-research":0.1547553336,"prompt-eng":0.3383848834,"data-quality":0.3333489945,"ml-security":0.1166260081}}
{"text":"Our results show that the domain-adapted foundation model outperforms state-of-the-art text mining techniques and performs as well as a subject matter expert (SME).","meta":{"url":"http://arxiv.org/abs/2308.01741v1"},"cats":{"new-dataset":0.2338669447,"dev-research":0.2249755607,"prompt-eng":0.4161081743,"data-quality":0.2431373681,"ml-security":0.0560882372}}
{"text":"The proposed framework could accelerate the Scope 3 estimation at Enterprise scale and will help to take appropriate climate actions to achieve SDG 13.","meta":{"url":"http://arxiv.org/abs/2308.01741v1"},"cats":{"new-dataset":0.3622986129,"dev-research":0.2402556127,"prompt-eng":0.3874130524,"data-quality":0.1188586115,"ml-security":0.0532086036}}
{"text":"Visibility in hazy nighttime scenes is frequently reduced by multiple factors, including low light, intense glow, light scattering, and the presence of multicolored light sources.","meta":{"url":"http://arxiv.org/abs/2308.01738v1"},"cats":{"new-dataset":0.0630658019,"dev-research":0.2282511958,"prompt-eng":0.3569771286,"data-quality":0.1292299915,"ml-security":0.1004628638}}
{"text":"Existing nighttime dehazing methods often struggle with handling glow or low-light conditions, resulting in either excessively dark visuals or unsuppressed glow outputs.","meta":{"url":"http://arxiv.org/abs/2308.01738v1"},"cats":{"new-dataset":0.0631027541,"dev-research":0.3570596954,"prompt-eng":0.344238375,"data-quality":0.2009271035,"ml-security":0.1729563958}}
{"text":"In this paper, we enhance the visibility from a single nighttime haze image by suppressing glow and enhancing low-light regions.","meta":{"url":"http://arxiv.org/abs/2308.01738v1"},"cats":{"new-dataset":0.1359029556,"dev-research":0.20934618,"prompt-eng":0.3700283467,"data-quality":0.1319023091,"ml-security":0.0932791193}}
{"text":"To handle glow effects, our framework learns from the rendered glow pairs.","meta":{"url":"http://arxiv.org/abs/2308.01738v1"},"cats":{"new-dataset":0.1573318402,"dev-research":0.3095628133,"prompt-eng":0.4084211812,"data-quality":0.1619487517,"ml-security":0.1710178749}}
{"text":"Specifically, a light source aware network is proposed to detect light sources of night images, followed by the APSF (Angular Point Spread Function)-guided glow rendering.","meta":{"url":"http://arxiv.org/abs/2308.01738v1"},"cats":{"new-dataset":0.2007464467,"dev-research":0.2255892678,"prompt-eng":0.3697980626,"data-quality":0.1376037389,"ml-security":0.0958338679}}
{"text":"Our framework is then trained on the rendered images, resulting in glow suppression.","meta":{"url":"http://arxiv.org/abs/2308.01738v1"},"cats":{"new-dataset":0.060415491,"dev-research":0.2720327716,"prompt-eng":0.4060241665,"data-quality":0.2163379999,"ml-security":0.2251165845}}
{"text":"Moreover, we utilize gradient-adaptive convolution, to capture edges and textures in hazy scenes.","meta":{"url":"http://arxiv.org/abs/2308.01738v1"},"cats":{"new-dataset":0.1850993619,"dev-research":0.2582681756,"prompt-eng":0.3136969911,"data-quality":0.2001539996,"ml-security":0.1201393339}}
{"text":"By leveraging extracted edges and textures, we enhance the contrast of the scene without losing important structural details.","meta":{"url":"http://arxiv.org/abs/2308.01738v1"},"cats":{"new-dataset":0.1356774065,"dev-research":0.2332874892,"prompt-eng":0.3523342553,"data-quality":0.200724955,"ml-security":0.0724608726}}
{"text":"To boost low-light intensity, our network learns an attention map, then adjusted by gamma correction.","meta":{"url":"http://arxiv.org/abs/2308.01738v1"},"cats":{"new-dataset":0.0831211661,"dev-research":0.203235982,"prompt-eng":0.4082540256,"data-quality":0.2292171022,"ml-security":0.0994918372}}
{"text":"This attention has high values on low-light regions and low values on haze and glow regions.","meta":{"url":"http://arxiv.org/abs/2308.01738v1"},"cats":{"new-dataset":0.3704486769,"dev-research":0.2005928194,"prompt-eng":0.3866404958,"data-quality":0.1692686959,"ml-security":0.0776202854}}
{"text":"Extensive evaluation on real nighttime haze images, demonstrates the effectiveness of our method.","meta":{"url":"http://arxiv.org/abs/2308.01738v1"},"cats":{"new-dataset":0.2120417706,"dev-research":0.2245540902,"prompt-eng":0.3469034226,"data-quality":0.126046011,"ml-security":0.0703369491}}
{"text":"Our experiments demonstrate that our method achieves a PSNR of 30.72dB, outperforming state-of-the-art methods by 14$\\%$ on GTA5 nighttime haze dataset.","meta":{"url":"http://arxiv.org/abs/2308.01738v1"},"cats":{"new-dataset":0.4716624157,"dev-research":0.2042840146,"prompt-eng":0.3527895743,"data-quality":0.1673143894,"ml-security":0.0834876335}}
{"text":"Our data and code is available at: \\url{https://github.com/jinyeying/nighttime_dehaze}.","meta":{"url":"http://arxiv.org/abs/2308.01738v1"},"cats":{"new-dataset":0.5246524068,"dev-research":0.1843452335,"prompt-eng":0.3870090868,"data-quality":0.1172382156,"ml-security":0.0537391577}}
{"text":"With the widespread application of personalized online services, click-through rate (CTR) prediction has received more and more attention and research.","meta":{"url":"http://arxiv.org/abs/2308.01737v1"},"cats":{"new-dataset":0.0208827566,"dev-research":0.2086019105,"prompt-eng":0.4510167335,"data-quality":0.1703007623,"ml-security":0.1180824584}}
{"text":"The most prominent features of CTR prediction are its multi-field categorical data format, and vast and daily-growing data volume.","meta":{"url":"http://arxiv.org/abs/2308.01737v1"},"cats":{"new-dataset":0.2707675789,"dev-research":0.1999691358,"prompt-eng":0.3917277752,"data-quality":0.130407618,"ml-security":0.0997973377}}
{"text":"The large capacity of neural models helps digest such massive amounts of data under the supervised learning paradigm, yet they fail to utilize the substantial data to its full potential, since the 1-bit click signal is not sufficient to guide the model to learn capable representations of features and instances.","meta":{"url":"http://arxiv.org/abs/2308.01737v1"},"cats":{"new-dataset":0.0570431825,"dev-research":0.2062140831,"prompt-eng":0.3558775276,"data-quality":0.2328641703,"ml-security":0.2956764615}}
{"text":"The self-supervised learning paradigm provides a more promising pretrain-finetune solution to better exploit the large amount of user click logs, and learn more generalized and effective representations.","meta":{"url":"http://arxiv.org/abs/2308.01737v1"},"cats":{"new-dataset":0.1292937667,"dev-research":0.2948876467,"prompt-eng":0.415706029,"data-quality":0.2690163722,"ml-security":0.1625368939}}
{"text":"However, self-supervised learning for CTR prediction is still an open question, since current works on this line are only preliminary and rudimentary.","meta":{"url":"http://arxiv.org/abs/2308.01737v1"},"cats":{"new-dataset":0.1097867026,"dev-research":0.1826804315,"prompt-eng":0.4275745225,"data-quality":0.217116338,"ml-security":0.1495459647}}
{"text":"To this end, we propose a Model-agnostic pretraining (MAP) framework that applies feature corruption and recovery on multi-field categorical data, and more specifically, we derive two practical algorithms: masked feature prediction (MFP) and replaced feature detection (RFD).","meta":{"url":"http://arxiv.org/abs/2308.01737v1"},"cats":{"new-dataset":0.2774498088,"dev-research":0.2521981935,"prompt-eng":0.4263022707,"data-quality":0.4074497331,"ml-security":0.2083215769}}
{"text":"MFP digs into feature interactions within each instance through masking and predicting a small portion of input features, and introduces noise contrastive estimation (NCE) to handle large feature spaces.","meta":{"url":"http://arxiv.org/abs/2308.01737v1"},"cats":{"new-dataset":0.2272409933,"dev-research":0.319145833,"prompt-eng":0.4185023972,"data-quality":0.2086710789,"ml-security":0.1203147844}}
{"text":"RFD further turns MFP into a binary classification mode through replacing and detecting changes in input features, making it even simpler and more effective for CTR pretraining.","meta":{"url":"http://arxiv.org/abs/2308.01737v1"},"cats":{"new-dataset":0.0848194366,"dev-research":0.3083939466,"prompt-eng":0.4880853458,"data-quality":0.1593172508,"ml-security":0.0808170776}}
{"text":"Our extensive experiments on two real-world large-scale datasets (i.e., Avazu, Criteo) demonstrate the advantages of these two methods on several strong backbones (e.g., DCNv2, DeepFM), and achieve new state-of-the-art performance in terms of both effectiveness and efficiency for CTR prediction.","meta":{"url":"http://arxiv.org/abs/2308.01737v1"},"cats":{"new-dataset":0.4693389592,"dev-research":0.1880638559,"prompt-eng":0.3731144585,"data-quality":0.1639597764,"ml-security":0.121637026}}
{"text":"Imaginative play is an area of creativity that could allow robots to engage with the world around them in a much more personified way.","meta":{"url":"http://arxiv.org/abs/2308.01734v1"},"cats":{"new-dataset":0.0768496162,"dev-research":0.3423886666,"prompt-eng":0.37063753,"data-quality":0.0851095422,"ml-security":0.0813719309}}
{"text":"Imaginary play can be seen as taking real objects and locations and using them as imaginary objects and locations in virtual scenarios.","meta":{"url":"http://arxiv.org/abs/2308.01734v1"},"cats":{"new-dataset":0.0798776319,"dev-research":0.3601550441,"prompt-eng":0.3463107212,"data-quality":0.09883655,"ml-security":0.1001721304}}
{"text":"We adopted the story generation capability of large language models (LLMs) to obtain the stories used for imaginary play with human-written prompts.","meta":{"url":"http://arxiv.org/abs/2308.01734v1"},"cats":{"new-dataset":0.2186129251,"dev-research":0.2961803333,"prompt-eng":0.4811349201,"data-quality":0.1113356752,"ml-security":0.0892249518}}
{"text":"Those generated stories will be simplified and mapped into action sequences that can guide the agent in imaginary play.","meta":{"url":"http://arxiv.org/abs/2308.01734v1"},"cats":{"new-dataset":0.1751372346,"dev-research":0.3260730641,"prompt-eng":0.3924390482,"data-quality":0.0744089472,"ml-security":0.0767353695}}
{"text":"To evaluate whether the agent can successfully finish the imaginary play, we also designed a text adventure game to simulate a house as the playground for the agent to interact.","meta":{"url":"http://arxiv.org/abs/2308.01734v1"},"cats":{"new-dataset":0.2342189609,"dev-research":0.352659661,"prompt-eng":0.4437277232,"data-quality":0.0811707914,"ml-security":0.0949591704}}
{"text":"This paper presents a retrospective overview of a decade of research in our department towards self-organizing personal knowledge assistants in evolving corporate memories.","meta":{"url":"http://arxiv.org/abs/2308.01732v1"},"cats":{"new-dataset":0.1378952992,"dev-research":0.3272310327,"prompt-eng":0.4592078582,"data-quality":0.1722699785,"ml-security":0.0627072577}}
{"text":"Our research is typically inspired by real-world problems and often conducted in interdisciplinary collaborations with research and industry partners.","meta":{"url":"http://arxiv.org/abs/2308.01732v1"},"cats":{"new-dataset":0.1980779038,"dev-research":0.315585048,"prompt-eng":0.315388209,"data-quality":0.138945225,"ml-security":0.082868376}}
{"text":"We summarize past experiments and results comprising topics like various ways of knowledge graph construction in corporate and personal settings, Managed Forgetting and (Self-organizing)","meta":{"url":"http://arxiv.org/abs/2308.01732v1"},"cats":{"new-dataset":0.1566674225,"dev-research":0.3426765915,"prompt-eng":0.4077724744,"data-quality":0.2377810934,"ml-security":0.0747256959}}
{"text":"Context Spaces as a novel approach to Personal Information Management (PIM) and knowledge work support.","meta":{"url":"http://arxiv.org/abs/2308.01732v1"},"cats":{"new-dataset":0.0629044627,"dev-research":0.3318488106,"prompt-eng":0.4183968199,"data-quality":0.1404231544,"ml-security":0.0682524264}}
{"text":"Past results are complemented by an overview of related work and some of our latest findings not published so far.","meta":{"url":"http://arxiv.org/abs/2308.01732v1"},"cats":{"new-dataset":0.3259785245,"dev-research":0.1900344465,"prompt-eng":0.378585561,"data-quality":0.2722830432,"ml-security":0.0640371426}}
{"text":"Last, we give an overview of our related industry use cases including a detailed look into CoMem, a Corporate Memory based on our presented research already in productive use and providing challenges for further research.","meta":{"url":"http://arxiv.org/abs/2308.01732v1"},"cats":{"new-dataset":0.1657748104,"dev-research":0.317690109,"prompt-eng":0.4363192822,"data-quality":0.1296973854,"ml-security":0.0802592212}}
{"text":"Many contributions are only first steps in new directions with still a lot of untapped potential, especially with regard to further increasing the automation in PIM and knowledge work support.","meta":{"url":"http://arxiv.org/abs/2308.01732v1"},"cats":{"new-dataset":0.0613067035,"dev-research":0.3068454652,"prompt-eng":0.4038821986,"data-quality":0.1117493807,"ml-security":0.0748924933}}
{"text":"Predictive variability due to data ambiguities has typically been addressed via construction of dedicated models with built-in probabilistic capabilities that are trained to predict uncertainty estimates as variables of interest.","meta":{"url":"http://arxiv.org/abs/2308.01731v1"},"cats":{"new-dataset":0.163712264,"dev-research":0.3257041368,"prompt-eng":0.4592056263,"data-quality":0.2407048442,"ml-security":0.1306132491}}
{"text":"These approaches require distinct architectural components and training mechanisms, may include restrictive assumptions and exhibit overconfidence, i.e., high confidence in imprecise predictions.","meta":{"url":"http://arxiv.org/abs/2308.01731v1"},"cats":{"new-dataset":0.0241787707,"dev-research":0.2985239494,"prompt-eng":0.4026488027,"data-quality":0.1502303515,"ml-security":0.1815874549}}
{"text":"In this work, we propose a post-hoc sampling strategy for estimating predictive uncertainty accounting for data ambiguity.","meta":{"url":"http://arxiv.org/abs/2308.01731v1"},"cats":{"new-dataset":0.0577332677,"dev-research":0.2582325842,"prompt-eng":0.429604534,"data-quality":0.3140045946,"ml-security":0.1221369122}}
{"text":"The method can generate different plausible outputs for a given input and does not assume parametric forms of predictive distributions.","meta":{"url":"http://arxiv.org/abs/2308.01731v1"},"cats":{"new-dataset":0.0125196571,"dev-research":0.2102465583,"prompt-eng":0.3467465911,"data-quality":0.2109368051,"ml-security":0.1752449715}}
{"text":"It is architecture agnostic and can be applied to any feed-forward deterministic network without changes to the architecture or training procedure.","meta":{"url":"http://arxiv.org/abs/2308.01731v1"},"cats":{"new-dataset":0.0635905537,"dev-research":0.1792027416,"prompt-eng":0.3507909287,"data-quality":0.1101429632,"ml-security":0.1526020334}}
{"text":"Experiments on regression tasks on imaging and non-imaging input data show the method's ability to generate diverse and multi-modal predictive distributions, and a desirable correlation of the estimated uncertainty with the prediction error.","meta":{"url":"http://arxiv.org/abs/2308.01731v1"},"cats":{"new-dataset":0.0723507572,"dev-research":0.2013261335,"prompt-eng":0.4506629708,"data-quality":0.1588328733,"ml-security":0.0946578155}}
{"text":"This paper introduces an approach that combines the language reasoning capabilities of large language models (LLMs) with the benefits of local training to tackle complex, domain-specific tasks.","meta":{"url":"http://arxiv.org/abs/2308.01727v1"},"cats":{"new-dataset":0.2392831805,"dev-research":0.2937271967,"prompt-eng":0.447363194,"data-quality":0.2061689584,"ml-security":0.0930493217}}
{"text":"Specifically, the authors demonstrate their approach by extracting structured condition codes from pathology reports.","meta":{"url":"http://arxiv.org/abs/2308.01727v1"},"cats":{"new-dataset":0.1528505466,"dev-research":0.2824426503,"prompt-eng":0.4737287106,"data-quality":0.2362313179,"ml-security":0.0572965041}}
{"text":"The proposed approach utilizes local LLMs, which can be fine-tuned to respond to specific generative instructions and provide structured outputs.","meta":{"url":"http://arxiv.org/abs/2308.01727v1"},"cats":{"new-dataset":0.1371216767,"dev-research":0.2692095316,"prompt-eng":0.5117730861,"data-quality":0.1566984891,"ml-security":0.0615172666}}
{"text":"The authors collected a dataset of over 150k uncurated surgical pathology reports, containing gross descriptions, final diagnoses, and condition codes.","meta":{"url":"http://arxiv.org/abs/2308.01727v1"},"cats":{"new-dataset":0.6114834888,"dev-research":0.2077275514,"prompt-eng":0.3760821177,"data-quality":0.1871466079,"ml-security":0.0632050934}}
{"text":"They trained different model architectures, including LLaMA, BERT and LongFormer and evaluated their performance.","meta":{"url":"http://arxiv.org/abs/2308.01727v1"},"cats":{"new-dataset":0.0641702516,"dev-research":0.2514354925,"prompt-eng":0.3716366314,"data-quality":0.0983104714,"ml-security":0.0817941887}}
{"text":"The results show that the LLaMA-based models significantly outperform BERT-style models across all evaluated metrics, even with extremely reduced precision.","meta":{"url":"http://arxiv.org/abs/2308.01727v1"},"cats":{"new-dataset":0.0820618898,"dev-research":0.2183162071,"prompt-eng":0.3784773509,"data-quality":0.2130947022,"ml-security":0.0954384557}}
{"text":"The LLaMA models performed especially well with large datasets, demonstrating their ability to handle complex, multi-label tasks.","meta":{"url":"http://arxiv.org/abs/2308.01727v1"},"cats":{"new-dataset":0.3523467863,"dev-research":0.1410660686,"prompt-eng":0.3862560955,"data-quality":0.1967014802,"ml-security":0.0796989474}}
{"text":"Overall, this work presents an effective approach for utilizing LLMs to perform domain-specific tasks using accessible hardware, with potential applications in the medical domain, where complex data extraction and classification are required.","meta":{"url":"http://arxiv.org/abs/2308.01727v1"},"cats":{"new-dataset":0.1348649516,"dev-research":0.1713502307,"prompt-eng":0.4598860234,"data-quality":0.1146998107,"ml-security":0.0673776251}}
{"text":"Quadruped robots have the distinct ability to adapt their body and step height to navigate through cluttered environments.","meta":{"url":"http://arxiv.org/abs/2308.01725v1"},"cats":{"new-dataset":0.0854618492,"dev-research":0.2105066127,"prompt-eng":0.4108181286,"data-quality":0.0536028663,"ml-security":0.0495941639}}
{"text":"Nonetheless, for these robots to utilize their full potential in real-world scenarios, they require awareness of their environment and obstacle geometry.","meta":{"url":"http://arxiv.org/abs/2308.01725v1"},"cats":{"new-dataset":0.1318462119,"dev-research":0.2331422087,"prompt-eng":0.4010304885,"data-quality":0.0627474422,"ml-security":0.0832726861}}
{"text":"We propose a novel multi-agent robotic system that incorporates cutting-edge technologies.","meta":{"url":"http://arxiv.org/abs/2308.01725v1"},"cats":{"new-dataset":0.0789611913,"dev-research":0.2174123847,"prompt-eng":0.4020905808,"data-quality":0.0513928943,"ml-security":0.0490222888}}
{"text":"The proposed solution features a 3D neural reconstruction algorithm that enables navigation of a quadruped robot in both static and semi-static environments.","meta":{"url":"http://arxiv.org/abs/2308.01725v1"},"cats":{"new-dataset":0.1764013263,"dev-research":0.225590376,"prompt-eng":0.3543784869,"data-quality":0.0720269976,"ml-security":0.07417785}}
{"text":"The prior areas of the environment are also segmented according to the quadruped robots' abilities to pass them.","meta":{"url":"http://arxiv.org/abs/2308.01725v1"},"cats":{"new-dataset":0.0580536861,"dev-research":0.2189337404,"prompt-eng":0.4029706571,"data-quality":0.0746652729,"ml-security":0.0619812077}}
{"text":"Moreover, we have developed an adaptive neural field optimal motion planner (ANFOMP) that considers both collision probability and obstacle height in 2D space.","meta":{"url":"http://arxiv.org/abs/2308.01725v1"},"cats":{"new-dataset":0.348421374,"dev-research":0.21177543,"prompt-eng":0.3336585895,"data-quality":0.0428451092,"ml-security":0.0688967911}}
{"text":"Our new navigation and mapping approach enables quadruped robots to adjust their height and behavior to navigate under arches and push through obstacles with smaller dimensions.","meta":{"url":"http://arxiv.org/abs/2308.01725v1"},"cats":{"new-dataset":0.0957231151,"dev-research":0.2359888879,"prompt-eng":0.4176797009,"data-quality":0.0510830465,"ml-security":0.0438038029}}
{"text":"The multi-agent mapping operation has proven to be highly accurate, with an obstacle reconstruction precision of 82%.","meta":{"url":"http://arxiv.org/abs/2308.01725v1"},"cats":{"new-dataset":0.1092968681,"dev-research":0.1954725596,"prompt-eng":0.4218566541,"data-quality":0.0788212639,"ml-security":0.0366241861}}
{"text":"Moreover, the quadruped robot can navigate with 3D obstacle information and the ANFOMP system, resulting in a 33.3% reduction in path length and a 70% reduction in navigation time.","meta":{"url":"http://arxiv.org/abs/2308.01725v1"},"cats":{"new-dataset":0.065975585,"dev-research":0.2073567376,"prompt-eng":0.4107871363,"data-quality":0.0465136419,"ml-security":0.0320205196}}
{"text":"Interest in the network analysis of bibliographic data has increased significantly in recent years.","meta":{"url":"http://arxiv.org/abs/2308.01722v1"},"cats":{"new-dataset":0.1034695665,"dev-research":0.2313497365,"prompt-eng":0.2881031496,"data-quality":0.203422966,"ml-security":0.06150141}}
{"text":"Yet, appropriate statistical models for examining the full dynamics of scientific citation networks, connecting authors to the papers they write and papers to other papers they cite, are not available.","meta":{"url":"http://arxiv.org/abs/2308.01722v1"},"cats":{"new-dataset":0.0590401122,"dev-research":0.1650365971,"prompt-eng":0.3221576193,"data-quality":0.166429879,"ml-security":0.0597793}}
{"text":"Very few studies exist that have examined how the social network between co-authors and the citation network among the papers shape one another and co-evolve.","meta":{"url":"http://arxiv.org/abs/2308.01722v1"},"cats":{"new-dataset":0.0243021115,"dev-research":0.2439058013,"prompt-eng":0.2755054604,"data-quality":0.1629756124,"ml-security":0.0651472405}}
{"text":"In consequence, our understanding of scientific citation networks remains incomplete.","meta":{"url":"http://arxiv.org/abs/2308.01722v1"},"cats":{"new-dataset":0.0805489974,"dev-research":0.2095460949,"prompt-eng":0.2746697914,"data-quality":0.3430732606,"ml-security":0.0696530046}}
{"text":"In this paper we extend recently derived relational hyperevent models (RHEM) to the analysis of scientific networks, providing a general framework to model the multiple dependencies involved in the relation linking multiple authors to the papers they write, and papers to the multiple references they cite.","meta":{"url":"http://arxiv.org/abs/2308.01722v1"},"cats":{"new-dataset":0.0977841957,"dev-research":0.2346419133,"prompt-eng":0.3716309323,"data-quality":0.2147408344,"ml-security":0.070119166}}
{"text":"We demonstrate the empirical value of our model in an analysis of publicly available data on a scientific network comprising millions of authors and papers and assess the relative strength of various effects explaining scientific production.","meta":{"url":"http://arxiv.org/abs/2308.01722v1"},"cats":{"new-dataset":0.1520912535,"dev-research":0.3025581259,"prompt-eng":0.342033457,"data-quality":0.2759981331,"ml-security":0.0983392806}}
{"text":"We outline the implications of the model for the evaluation of scientific research.","meta":{"url":"http://arxiv.org/abs/2308.01722v1"},"cats":{"new-dataset":0.0103581791,"dev-research":0.272537522,"prompt-eng":0.3967334674,"data-quality":0.2035835119,"ml-security":0.0558077714}}
{"text":"3D semantic scene understanding tasks have achieved great success with the emergence of deep learning, but often require a huge amount of manually annotated training data.","meta":{"url":"http://arxiv.org/abs/2308.01721v1"},"cats":{"new-dataset":0.4031895169,"dev-research":0.2272507052,"prompt-eng":0.3989763623,"data-quality":0.2632165309,"ml-security":0.0778295796}}
{"text":"To alleviate the annotation cost, we propose the first weakly-supervised 3D instance segmentation method that only requires categorical semantic labels as supervision, and we do not need instance-level labels.","meta":{"url":"http://arxiv.org/abs/2308.01721v1"},"cats":{"new-dataset":0.3138792523,"dev-research":0.2275359868,"prompt-eng":0.4212169292,"data-quality":0.355084832,"ml-security":0.1064171527}}
{"text":"The required semantic annotations can be either dense or extreme sparse (e.g. 0.02% of total points).","meta":{"url":"http://arxiv.org/abs/2308.01721v1"},"cats":{"new-dataset":0.2211326769,"dev-research":0.1873142354,"prompt-eng":0.4134356678,"data-quality":0.349248438,"ml-security":0.0519483819}}
{"text":"Even without having any instance-related ground-truth, we design an approach to break point clouds into raw fragments and find the most confident samples for learning instance centroids.","meta":{"url":"http://arxiv.org/abs/2308.01721v1"},"cats":{"new-dataset":0.4035767973,"dev-research":0.1905050532,"prompt-eng":0.3679381775,"data-quality":0.2825952887,"ml-security":0.1609996884}}
{"text":"Furthermore, we construct a recomposed dataset using pseudo instances, which is used to learn our defined multilevel shape-aware objectness signal.","meta":{"url":"http://arxiv.org/abs/2308.01721v1"},"cats":{"new-dataset":0.3804750232,"dev-research":0.2490239779,"prompt-eng":0.4114901125,"data-quality":0.2002607081,"ml-security":0.1676183741}}
{"text":"An asymmetrical object inference algorithm is followed to process core points and boundary points with different strategies, and generate high-quality pseudo instance labels to guide iterative training.","meta":{"url":"http://arxiv.org/abs/2308.01721v1"},"cats":{"new-dataset":0.0919867366,"dev-research":0.2373758035,"prompt-eng":0.4468888232,"data-quality":0.2485060589,"ml-security":0.1286859989}}
{"text":"Experiments demonstrate that our method can achieve comparable results with recent fully supervised methods.","meta":{"url":"http://arxiv.org/abs/2308.01721v1"},"cats":{"new-dataset":0.0850506925,"dev-research":0.1930401643,"prompt-eng":0.4316737984,"data-quality":0.4015858188,"ml-security":0.0818545389}}
{"text":"By generating pseudo instance labels from categorical semantic labels, our designed approach can also assist existing methods for learning 3D instance segmentation at reduced annotation cost.","meta":{"url":"http://arxiv.org/abs/2308.01721v1"},"cats":{"new-dataset":0.3216824821,"dev-research":0.2622288032,"prompt-eng":0.4424412275,"data-quality":0.3012751312,"ml-security":0.1220109943}}
{"text":"Modern computing tasks are constrained to having digital electronic input and output data.","meta":{"url":"http://arxiv.org/abs/2308.01719v1"},"cats":{"new-dataset":0.0448825729,"dev-research":0.3174574821,"prompt-eng":0.4194513787,"data-quality":0.1257378629,"ml-security":0.1027145762}}
{"text":"Due to these constraints imposed by the user, any analog computing accelerator must perform an analog-to-digital conversion on its input data and a subsequent digital-to-analog conversion on its output data.","meta":{"url":"http://arxiv.org/abs/2308.01719v1"},"cats":{"new-dataset":0.0298141795,"dev-research":0.271069876,"prompt-eng":0.4289484907,"data-quality":0.0936346483,"ml-security":0.1126066051}}
{"text":"To avoid this the analog hardware would need to completely replace the full functionality of traditional digital electronic computer hardware.","meta":{"url":"http://arxiv.org/abs/2308.01719v1"},"cats":{"new-dataset":0.0038136325,"dev-research":0.2991935939,"prompt-eng":0.4116350188,"data-quality":0.2062534544,"ml-security":0.1944874347}}
{"text":"Using 27 empirically-measured benchmarks we estimate that an ideal optical accelerator that accelerates Fourier transforms and convolutions can produce an average speedup of 9.4 times, and a median speedup of 1.9 times for the set of benchmarks.","meta":{"url":"http://arxiv.org/abs/2308.01719v1"},"cats":{"new-dataset":0.1043962774,"dev-research":0.2180856679,"prompt-eng":0.3809064987,"data-quality":0.0873635003,"ml-security":0.0568565052}}
{"text":"The maximum speedups achieved were 45.3 times for a pure Fourier transform and 159.4 times for a pure convolution.","meta":{"url":"http://arxiv.org/abs/2308.01719v1"},"cats":{"new-dataset":0.0756301514,"dev-research":0.1784352929,"prompt-eng":0.3037668667,"data-quality":0.1019267741,"ml-security":0.0611037813}}
{"text":"These results show that an optical accelerator only produces significant speedup for applications consisting exclusively of Fourier transforms and convolutions.","meta":{"url":"http://arxiv.org/abs/2308.01719v1"},"cats":{"new-dataset":0.0229042251,"dev-research":0.2166640254,"prompt-eng":0.3363938422,"data-quality":0.0825311188,"ml-security":0.0850307024}}
{"text":"In addition to the theoretical results we quantify the data movement bottleneck which causes a 23.8 times slowdown in a prototype optical Fourier transform accelerator which we built from widely-available off-the-shelf parts.","meta":{"url":"http://arxiv.org/abs/2308.01719v1"},"cats":{"new-dataset":0.0826142134,"dev-research":0.2329430882,"prompt-eng":0.3675694074,"data-quality":0.0852381171,"ml-security":0.0554418025}}
{"text":"Manual of practical experiments on protocols used in the Internet or TCP/IP Suite.","meta":{"url":"http://arxiv.org/abs/2308.01713v1"},"cats":{"new-dataset":0.0951193779,"dev-research":0.2501998627,"prompt-eng":0.4271672237,"data-quality":0.125422474,"ml-security":0.0986882015}}
{"text":"This manual is a collection of experiments that are used in undergraduate and graduate courses taught at New Jersey Institute of Technology for a few years.","meta":{"url":"http://arxiv.org/abs/2308.01713v1"},"cats":{"new-dataset":0.2512735776,"dev-research":0.2174428241,"prompt-eng":0.4067331528,"data-quality":0.1053805233,"ml-security":0.0405021756}}
{"text":"The manual is updated periodically to accommodate emerging needs and technologies, including virtualization of the experiments for their use during lockdowns as the one experienced during COVID-19 in 2020 and part of 2021.","meta":{"url":"http://arxiv.org/abs/2308.01713v1"},"cats":{"new-dataset":0.2900347884,"dev-research":0.2655752188,"prompt-eng":0.4399009109,"data-quality":0.0937171957,"ml-security":0.0945098399}}
{"text":"The manual may be used by all those interested in knowing and experiencing some of the basic protocols that run on the Internet and by practitioners.","meta":{"url":"http://arxiv.org/abs/2308.01713v1"},"cats":{"new-dataset":0.2213631958,"dev-research":0.3144086497,"prompt-eng":0.4072414473,"data-quality":0.0796150154,"ml-security":0.0497331539}}
{"text":"The goal is to get some understanding on protocol design and not necessarily on a particular software or operative system.","meta":{"url":"http://arxiv.org/abs/2308.01713v1"},"cats":{"new-dataset":0.0838341957,"dev-research":0.3603736004,"prompt-eng":0.4215069231,"data-quality":0.0823515524,"ml-security":0.0911901952}}
{"text":"Despite the significant research efforts on trajectory prediction for automated driving, limited work exists on assessing the prediction reliability.","meta":{"url":"http://arxiv.org/abs/2308.01707v1"},"cats":{"new-dataset":0.0722807064,"dev-research":0.2336156609,"prompt-eng":0.4038460705,"data-quality":0.1636115916,"ml-security":0.1102153067}}
{"text":"To address this limitation we propose an approach that covers two sources of error, namely novel situations with out-of-distribution (OOD) detection and the complexity in in-distribution (ID) situations with uncertainty estimation.","meta":{"url":"http://arxiv.org/abs/2308.01707v1"},"cats":{"new-dataset":0.1101904764,"dev-research":0.2343589022,"prompt-eng":0.4197724008,"data-quality":0.4876505848,"ml-security":0.2246131484}}
{"text":"We introduce two modules next to an encoder-decoder network for trajectory prediction.","meta":{"url":"http://arxiv.org/abs/2308.01707v1"},"cats":{"new-dataset":0.2674677073,"dev-research":0.194437171,"prompt-eng":0.3498751694,"data-quality":0.083549942,"ml-security":0.1109682754}}
{"text":"Firstly, a Gaussian mixture model learns the probability density function of the ID encoder features during training, and then it is used to detect the OOD samples in regions of the feature space with low likelihood.","meta":{"url":"http://arxiv.org/abs/2308.01707v1"},"cats":{"new-dataset":0.0539286184,"dev-research":0.1875618335,"prompt-eng":0.3773506964,"data-quality":0.1655427951,"ml-security":0.0997339486}}
{"text":"Secondly, an error regression network is applied to the encoder, which learns to estimate the trajectory prediction error in supervised training.","meta":{"url":"http://arxiv.org/abs/2308.01707v1"},"cats":{"new-dataset":0.0555038384,"dev-research":0.2522703452,"prompt-eng":0.3553999551,"data-quality":0.2481591904,"ml-security":0.1634975011}}
{"text":"During inference, the estimated prediction error is used as the uncertainty.","meta":{"url":"http://arxiv.org/abs/2308.01707v1"},"cats":{"new-dataset":0.0063889306,"dev-research":0.3312826147,"prompt-eng":0.38660861,"data-quality":0.2594546583,"ml-security":0.1437477864}}
{"text":"In our experiments, the combination of both modules outperforms the prior work in OOD detection and uncertainty estimation, on the Shifts robust trajectory prediction dataset by $2.8 \\%$ and $10.1 \\%$, respectively.","meta":{"url":"http://arxiv.org/abs/2308.01707v1"},"cats":{"new-dataset":0.2328169065,"dev-research":0.1711064555,"prompt-eng":0.3826526228,"data-quality":0.1898128202,"ml-security":0.128965195}}
{"text":"The code is publicly available.","meta":{"url":"http://arxiv.org/abs/2308.01707v1"},"cats":{"new-dataset":0.4479119368,"dev-research":0.2258161369,"prompt-eng":0.3578438235,"data-quality":0.1401444175,"ml-security":0.1504210527}}
{"text":"Stealth addresses are a privacy-enhancing technology that provides recipient anonymity on blockchains.","meta":{"url":"http://arxiv.org/abs/2308.01703v1"},"cats":{"new-dataset":0.0475836742,"dev-research":0.2540056314,"prompt-eng":0.3698538982,"data-quality":0.1810090136,"ml-security":0.4174541965}}
{"text":"In this work, we investigate the recipient anonymity and unlinkability guarantees of Umbra, the most widely used implementation of the stealth address scheme on Ethereum, and its three off-chain scalability solutions, e.g., Arbitrum, Optimism, and Polygon.","meta":{"url":"http://arxiv.org/abs/2308.01703v1"},"cats":{"new-dataset":0.0905783114,"dev-research":0.2273690016,"prompt-eng":0.4069233757,"data-quality":0.1657013327,"ml-security":0.3879585308}}
{"text":"We define and evaluate four heuristics to uncover the real recipients of stealth payments.","meta":{"url":"http://arxiv.org/abs/2308.01703v1"},"cats":{"new-dataset":0.0956579287,"dev-research":0.2202931126,"prompt-eng":0.4259034768,"data-quality":0.177651669,"ml-security":0.3935386762}}
{"text":"We find that for the majority of Umbra payments, it is straightforward to establish the recipient, hence nullifying the benefits of using Umbra.","meta":{"url":"http://arxiv.org/abs/2308.01703v1"},"cats":{"new-dataset":0.0279366163,"dev-research":0.2077133266,"prompt-eng":0.4168533644,"data-quality":0.1842827537,"ml-security":0.1732810023}}
{"text":"Specifically, we find the real recipient of $48.5\\%$, $25.8\\%$, $65.7\\%$, and $52.6\\%$ of all Umbra transactions on the Ethereum main net, Polygon, Arbitrum, and Optimism networks, respectively.","meta":{"url":"http://arxiv.org/abs/2308.01703v1"},"cats":{"new-dataset":0.1506547224,"dev-research":0.1854147628,"prompt-eng":0.3761023658,"data-quality":0.1588225853,"ml-security":0.1600385381}}
{"text":"Finally, we suggest easily implementable countermeasures to evade our deanonymization and linking attacks.","meta":{"url":"http://arxiv.org/abs/2308.01703v1"},"cats":{"new-dataset":0.1019511038,"dev-research":0.2786538217,"prompt-eng":0.4133751705,"data-quality":0.2740850271,"ml-security":0.6953404357}}
{"text":"Feature selection could be defined as an optimization problem and solved by bio-inspired algorithms.","meta":{"url":"http://arxiv.org/abs/2308.01700v1"},"cats":{"new-dataset":0.0105734636,"dev-research":0.3145330763,"prompt-eng":0.4185017911,"data-quality":0.1342189734,"ml-security":0.1388255378}}
{"text":"Bees Algorithm (BA) shows decent performance in feature selection optimization tasks.","meta":{"url":"http://arxiv.org/abs/2308.01700v1"},"cats":{"new-dataset":0.0507487391,"dev-research":0.2656911139,"prompt-eng":0.4346661049,"data-quality":0.1327561195,"ml-security":0.081634651}}
{"text":"On the other hand, Local Phase Quantization (LPQ) is a frequency domain feature which has excellent performance on Depth images.","meta":{"url":"http://arxiv.org/abs/2308.01700v1"},"cats":{"new-dataset":0.0786003456,"dev-research":0.171162299,"prompt-eng":0.3315574943,"data-quality":0.1135412929,"ml-security":0.0386288584}}
{"text":"Here, after extracting LPQ features out of RGB (colour) and Depth images from the Iranian Kinect Face Database (IKFDB), the Bees feature selection algorithm applies to select the desired number of features for final classification tasks.","meta":{"url":"http://arxiv.org/abs/2308.01700v1"},"cats":{"new-dataset":0.2935833929,"dev-research":0.172088402,"prompt-eng":0.3993866323,"data-quality":0.0874163119,"ml-security":0.0473737047}}
{"text":"IKFDB is recorded with Kinect sensor V.2 and contains colour and depth images for facial and facial micro-expressions recognition purposes.","meta":{"url":"http://arxiv.org/abs/2308.01700v1"},"cats":{"new-dataset":0.5962591301,"dev-research":0.190602152,"prompt-eng":0.3738242817,"data-quality":0.150816598,"ml-security":0.0435230872}}
{"text":"Here five facial expressions of Anger, Joy, Surprise, Disgust and Fear are used for final validation.","meta":{"url":"http://arxiv.org/abs/2308.01700v1"},"cats":{"new-dataset":0.143703715,"dev-research":0.2904206865,"prompt-eng":0.413563278,"data-quality":0.2267328108,"ml-security":0.1372447075}}
{"text":"The proposed Bees LPQ method is compared with Particle Swarm Optimization (PSO) LPQ, PCA LPQ, Lasso LPQ, and just LPQ features for classification tasks with Support Vector Machines (SVM), K-Nearest Neighbourhood (KNN), Shallow Neural Network and Ensemble Subspace KNN.","meta":{"url":"http://arxiv.org/abs/2308.01700v1"},"cats":{"new-dataset":0.1040523521,"dev-research":0.1757033819,"prompt-eng":0.3482492484,"data-quality":0.1603170362,"ml-security":0.0917065826}}
{"text":"Returned results, show a decent performance of the proposed algorithm (99 % accuracy) in comparison with others.","meta":{"url":"http://arxiv.org/abs/2308.01700v1"},"cats":{"new-dataset":0.2100224217,"dev-research":0.1667811815,"prompt-eng":0.4167208673,"data-quality":0.2133854532,"ml-security":0.0445101192}}
{"text":"Our approach, which we call Embeddings for Language/Image-aligned X-Rays, or ELIXR, leverages a language-aligned image encoder combined or grafted onto a fixed LLM, PaLM 2, to perform a broad range of tasks.","meta":{"url":"http://arxiv.org/abs/2308.01317v1"},"cats":{"new-dataset":0.3166744501,"dev-research":0.2245962849,"prompt-eng":0.3961171661,"data-quality":0.136306432,"ml-security":0.0586311325}}
{"text":"We train this lightweight adapter architecture using images paired with corresponding free-text radiology reports from the MIMIC-CXR dataset.","meta":{"url":"http://arxiv.org/abs/2308.01317v1"},"cats":{"new-dataset":0.2688201183,"dev-research":0.238300351,"prompt-eng":0.4420785154,"data-quality":0.1715620891,"ml-security":0.0546213829}}
{"text":"ELIXR achieved state-of-the-art performance on zero-shot chest X-ray (CXR) classification (mean AUC of 0.850 across 13 findings), data-efficient CXR classification (mean AUCs of 0.893 and 0.898 across five findings (atelectasis, cardiomegaly, consolidation, pleural effusion, and pulmonary edema) for 1% (~2,200 images) and 10% (~22,000 images) training data), and semantic search (0.76 normalized discounted cumulative gain (NDCG) across nineteen queries, including perfect retrieval on twelve of them).","meta":{"url":"http://arxiv.org/abs/2308.01317v1"},"cats":{"new-dataset":0.0633084416,"dev-research":0.2010219616,"prompt-eng":0.3676729397,"data-quality":0.1978711558,"ml-security":0.0789748185}}
{"text":"Compared to existing data-efficient methods including supervised contrastive learning (SupCon), ELIXR required two orders of magnitude less data to reach similar performance.","meta":{"url":"http://arxiv.org/abs/2308.01317v1"},"cats":{"new-dataset":0.1960274515,"dev-research":0.2278154747,"prompt-eng":0.3896392789,"data-quality":0.1667862239,"ml-security":0.0563406866}}
{"text":"ELIXR also showed promise on CXR vision-language tasks, demonstrating overall accuracies of 58.7% and 62.5% on visual question answering and report quality assurance tasks, respectively.","meta":{"url":"http://arxiv.org/abs/2308.01317v1"},"cats":{"new-dataset":0.1536105301,"dev-research":0.3777385725,"prompt-eng":0.4586350424,"data-quality":0.202181714,"ml-security":0.0479433928}}
{"text":"These results suggest that ELIXR is a robust and versatile approach to CXR AI.","meta":{"url":"http://arxiv.org/abs/2308.01317v1"},"cats":{"new-dataset":0.0967321062,"dev-research":0.3243288162,"prompt-eng":0.4633528497,"data-quality":0.1396036416,"ml-security":0.0758192173}}
{"text":"We propose an effective denoising diffusion model for generating high-resolution images (e.g., 1024$\\times$512), trained on small-size image patches (e.g., 64$\\times$64).","meta":{"url":"http://arxiv.org/abs/2308.01316v1"},"cats":{"new-dataset":0.2900308019,"dev-research":0.1951250826,"prompt-eng":0.3329022417,"data-quality":0.1488266455,"ml-security":0.135065007}}
{"text":"We name our algorithm Patch-DM, in which a new feature collage strategy is designed to avoid the boundary artifact when synthesizing large-size images.","meta":{"url":"http://arxiv.org/abs/2308.01316v1"},"cats":{"new-dataset":0.2998681474,"dev-research":0.2410030012,"prompt-eng":0.3881582469,"data-quality":0.2117419661,"ml-security":0.1035830887}}
{"text":"Feature collage systematically crops and combines partial features of the neighboring patches to predict the features of a shifted image patch, allowing the seamless generation of the entire image due to the overlap in the patch feature space.","meta":{"url":"http://arxiv.org/abs/2308.01316v1"},"cats":{"new-dataset":0.1833964848,"dev-research":0.2338835828,"prompt-eng":0.3968797843,"data-quality":0.1505935314,"ml-security":0.0777223599}}
{"text":"Patch-DM produces high-quality image synthesis results on our newly collected dataset of nature images (1024$\\times$512), as well as on standard benchmarks of smaller sizes (256$\\times$256), including LSUN-Bedroom, LSUN-Church, and FFHQ.","meta":{"url":"http://arxiv.org/abs/2308.01316v1"},"cats":{"new-dataset":0.6754903997,"dev-research":0.2354423165,"prompt-eng":0.386691264,"data-quality":0.1044929286,"ml-security":0.0660992901}}
{"text":"We compare our method with previous patch-based generation methods and achieve state-of-the-art FID scores on all four datasets.","meta":{"url":"http://arxiv.org/abs/2308.01316v1"},"cats":{"new-dataset":0.6375128557,"dev-research":0.2526760115,"prompt-eng":0.4379515356,"data-quality":0.2100118645,"ml-security":0.0391272493}}
{"text":"Further, Patch-DM also reduces memory complexity compared to the classic diffusion models.","meta":{"url":"http://arxiv.org/abs/2308.01316v1"},"cats":{"new-dataset":0.0090817125,"dev-research":0.2116043956,"prompt-eng":0.3388636407,"data-quality":0.0987745482,"ml-security":0.1434752629}}
{"text":"CLIP, as a foundational vision language model, is widely used in zero-shot image classification due to its ability to understand various visual concepts and natural language descriptions.","meta":{"url":"http://arxiv.org/abs/2308.01313v1"},"cats":{"new-dataset":0.2673078525,"dev-research":0.1773071598,"prompt-eng":0.353908325,"data-quality":0.235758815,"ml-security":0.1361622131}}
{"text":"However, how to fully leverage CLIP's unprecedented human-like understanding capabilities to achieve better zero-shot classification is still an open question.","meta":{"url":"http://arxiv.org/abs/2308.01313v1"},"cats":{"new-dataset":0.1430184988,"dev-research":0.2124047005,"prompt-eng":0.3660331161,"data-quality":0.2848461654,"ml-security":0.2410626904}}
{"text":"This paper draws inspiration from the human visual perception process: a modern neuroscience view suggests that in classifying an object, humans first infer its class-independent attributes (e.g., background and orientation) which help separate the foreground object from the background, and then make decisions based on this information.","meta":{"url":"http://arxiv.org/abs/2308.01313v1"},"cats":{"new-dataset":0.0353662978,"dev-research":0.2378907654,"prompt-eng":0.420047483,"data-quality":0.2665081859,"ml-security":0.1810410507}}
{"text":"Inspired by this, we observe that providing CLIP with contextual attributes improves zero-shot classification and mitigates reliance on spurious features.","meta":{"url":"http://arxiv.org/abs/2308.01313v1"},"cats":{"new-dataset":0.1707229569,"dev-research":0.2321414292,"prompt-eng":0.3602198136,"data-quality":0.4112659348,"ml-security":0.2568423058}}
{"text":"We also observe that CLIP itself can reasonably infer the attributes from an image.","meta":{"url":"http://arxiv.org/abs/2308.01313v1"},"cats":{"new-dataset":0.0655212626,"dev-research":0.1859032879,"prompt-eng":0.4526742552,"data-quality":0.2421591696,"ml-security":0.1440779951}}
{"text":"With these observations, we propose a training-free, two-step zero-shot classification method named PerceptionCLIP.","meta":{"url":"http://arxiv.org/abs/2308.01313v1"},"cats":{"new-dataset":0.2940654824,"dev-research":0.1749596407,"prompt-eng":0.3613147797,"data-quality":0.3470089458,"ml-security":0.2077541473}}
{"text":"Given an image, it first infers contextual attributes (e.g., background) and then performs object classification conditioning on them.","meta":{"url":"http://arxiv.org/abs/2308.01313v1"},"cats":{"new-dataset":0.0165777431,"dev-research":0.2582092013,"prompt-eng":0.4208260636,"data-quality":0.1736550814,"ml-security":0.1088319014}}
{"text":"Our experiments show that PerceptionCLIP achieves better generalization, group robustness, and better interpretability.","meta":{"url":"http://arxiv.org/abs/2308.01313v1"},"cats":{"new-dataset":0.0913875156,"dev-research":0.305369664,"prompt-eng":0.4179978652,"data-quality":0.3412813894,"ml-security":0.2099348207}}
{"text":"For example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by 16.5% on the Waterbirds dataset and by 3.5% on CelebA.","meta":{"url":"http://arxiv.org/abs/2308.01313v1"},"cats":{"new-dataset":0.2914972049,"dev-research":0.2520865763,"prompt-eng":0.41863542,"data-quality":0.3397078102,"ml-security":0.119210239}}
{"text":"We present Lode Encoder, a gamified mixed-initiative level creation system for the classic platform-puzzle game Lode Runner.","meta":{"url":"http://arxiv.org/abs/2308.01312v1"},"cats":{"new-dataset":0.2759347199,"dev-research":0.3745601871,"prompt-eng":0.4481287172,"data-quality":0.0855531554,"ml-security":0.0764785791}}
{"text":"The system is built around several autoencoders which are trained on sets of Lode Runner levels.","meta":{"url":"http://arxiv.org/abs/2308.01312v1"},"cats":{"new-dataset":0.2287846278,"dev-research":0.2348678894,"prompt-eng":0.4596543051,"data-quality":0.1388941125,"ml-security":0.1030856383}}
{"text":"When fed with the user's design, each autoencoder produces a version of that design which is closer in style to the levels that it was trained on.","meta":{"url":"http://arxiv.org/abs/2308.01312v1"},"cats":{"new-dataset":0.0329365539,"dev-research":0.3464968043,"prompt-eng":0.4391970322,"data-quality":0.2149153892,"ml-security":0.1219852914}}
{"text":"The Lode Encoder interface allows the user to build and edit levels through 'painting' from the suggestions provided by the autoencoders.","meta":{"url":"http://arxiv.org/abs/2308.01312v1"},"cats":{"new-dataset":0.0744621312,"dev-research":0.3213534543,"prompt-eng":0.4877946827,"data-quality":0.0958002949,"ml-security":0.0611770062}}
{"text":"Crucially, in order to encourage designers to explore new possibilities, the system does not include more traditional editing tools.","meta":{"url":"http://arxiv.org/abs/2308.01312v1"},"cats":{"new-dataset":0.0107967283,"dev-research":0.4319998795,"prompt-eng":0.3624813907,"data-quality":0.1365390521,"ml-security":0.0913943897}}
{"text":"We report on the system design and training procedure, as well as on the evolution of the system itself and user tests.","meta":{"url":"http://arxiv.org/abs/2308.01312v1"},"cats":{"new-dataset":0.1342712562,"dev-research":0.4002875832,"prompt-eng":0.5447969465,"data-quality":0.1721985102,"ml-security":0.1009308111}}
{"text":"Successful deployment of Deep Neural Networks (DNNs), particularly in safety-critical systems, requires their validation with an adequate test set to ensure a sufficient degree of confidence in test outcomes.","meta":{"url":"http://arxiv.org/abs/2308.01311v1"},"cats":{"new-dataset":0.1703013258,"dev-research":0.4057771423,"prompt-eng":0.3861846827,"data-quality":0.2600878202,"ml-security":0.4151165526}}
{"text":"Mutation analysis, one of the main techniques for measuring test adequacy in traditional software, has been adapted to DNNs in recent years.","meta":{"url":"http://arxiv.org/abs/2308.01311v1"},"cats":{"new-dataset":0.3196400254,"dev-research":0.4775018824,"prompt-eng":0.432643885,"data-quality":0.3157042036,"ml-security":0.2282970768}}
{"text":"This technique is based on generating mutants that aim to be representative of actual faults and thus can be used for test adequacy assessment.","meta":{"url":"http://arxiv.org/abs/2308.01311v1"},"cats":{"new-dataset":0.074336638,"dev-research":0.5205566823,"prompt-eng":0.5067782903,"data-quality":0.2891726353,"ml-security":0.1521114957}}
{"text":"In this paper, we investigate for the first time whether mutation operators that directly modify the trained DNN model (i.e., post-training) can be used for reliably assessing the test inputs of DNNs.","meta":{"url":"http://arxiv.org/abs/2308.01311v1"},"cats":{"new-dataset":0.1362769434,"dev-research":0.4021499932,"prompt-eng":0.4433947679,"data-quality":0.3177985612,"ml-security":0.3527312844}}
{"text":"We propose and evaluate TEASMA, an approach based on post-training mutation for assessing the adequacy of DNN's test sets.","meta":{"url":"http://arxiv.org/abs/2308.01311v1"},"cats":{"new-dataset":0.3302126712,"dev-research":0.3673642162,"prompt-eng":0.413668009,"data-quality":0.3229292213,"ml-security":0.249358288}}
{"text":"In practice, TEASMA allows engineers to decide whether they will be able to trust test results and thus validate the DNN before its deployment.","meta":{"url":"http://arxiv.org/abs/2308.01311v1"},"cats":{"new-dataset":0.0870964814,"dev-research":0.4351637998,"prompt-eng":0.4138231486,"data-quality":0.1734376113,"ml-security":0.2059548424}}
{"text":"Based on a DNN model's training set, TEASMA provides a methodology to build accurate prediction models of the Fault Detection Rate (FDR) of a test set from its mutation score, thus enabling its assessment.","meta":{"url":"http://arxiv.org/abs/2308.01311v1"},"cats":{"new-dataset":0.3099339747,"dev-research":0.3984716635,"prompt-eng":0.4526301311,"data-quality":0.2743862908,"ml-security":0.2614039507}}
{"text":"Our large empirical evaluation, across multiple DNN models, shows that predicted FDR values have a strong linear correlation (R2 >= 0.94) with actual values.","meta":{"url":"http://arxiv.org/abs/2308.01311v1"},"cats":{"new-dataset":0.2702422706,"dev-research":0.210198457,"prompt-eng":0.3643539904,"data-quality":0.2751947169,"ml-security":0.1824302637}}
{"text":"Consequently, empirical evidence suggests that TEASMA provides a reliable basis for confidently deciding whether to trust test results or improve the test set.","meta":{"url":"http://arxiv.org/abs/2308.01311v1"},"cats":{"new-dataset":0.0357020022,"dev-research":0.3388560986,"prompt-eng":0.413500486,"data-quality":0.2060266013,"ml-security":0.1764896538}}
{"text":"Next basket recommendation (NBR) is the task of predicting the next set of items based on a sequence of already purchased baskets.","meta":{"url":"http://arxiv.org/abs/2308.01308v1"},"cats":{"new-dataset":0.1192074419,"dev-research":0.2153719658,"prompt-eng":0.4150685505,"data-quality":0.1221584754,"ml-security":0.0439733193}}
{"text":"It is a recommendation task that has been widely studied, especially in the context of grocery shopping.","meta":{"url":"http://arxiv.org/abs/2308.01308v1"},"cats":{"new-dataset":0.0168602924,"dev-research":0.2980532698,"prompt-eng":0.4401573647,"data-quality":0.1300367919,"ml-security":0.0593186581}}
{"text":"In next basket recommendation (NBR), it is useful to distinguish between repeat items, i.e., items that a user has consumed before, and explore items, i.e., items that a user has not consumed before.","meta":{"url":"http://arxiv.org/abs/2308.01308v1"},"cats":{"new-dataset":0.0323916628,"dev-research":0.2441749414,"prompt-eng":0.4153745326,"data-quality":0.1442580547,"ml-security":0.0349890976}}
{"text":"Most NBR work either ignores this distinction or focuses on repeat items.","meta":{"url":"http://arxiv.org/abs/2308.01308v1"},"cats":{"new-dataset":0.0071876749,"dev-research":0.236727683,"prompt-eng":0.3528574113,"data-quality":0.253308829,"ml-security":0.0431377682}}
{"text":"We formulate the next novel basket recommendation (NNBR) task, i.e., the task of recommending a basket that only consists of novel items, which is valuable for both real-world application and NBR evaluation.","meta":{"url":"http://arxiv.org/abs/2308.01308v1"},"cats":{"new-dataset":0.0475538597,"dev-research":0.2509174293,"prompt-eng":0.4158736962,"data-quality":0.1477124031,"ml-security":0.0621711399}}
{"text":"We evaluate how existing NBR methods perform on the NNBR task and find that, so far, limited progress has been made w.r.t.","meta":{"url":"http://arxiv.org/abs/2308.01308v1"},"cats":{"new-dataset":0.0924126006,"dev-research":0.2061135487,"prompt-eng":0.4363163167,"data-quality":0.1710638228,"ml-security":0.0358076886}}
{"text":"the NNBR task.","meta":{"url":"http://arxiv.org/abs/2308.01308v1"},"cats":{"new-dataset":0.1013232494,"dev-research":0.2208385302,"prompt-eng":0.3934682624,"data-quality":0.1643984293,"ml-security":0.0728046091}}
{"text":"To address the NNBR task, we propose a simple bi-directional transformer basket recommendation model (BTBR), which is focused on directly modeling item-to-item correlations within and across baskets instead of learning complex basket representations.","meta":{"url":"http://arxiv.org/abs/2308.01308v1"},"cats":{"new-dataset":0.0453809887,"dev-research":0.2259712203,"prompt-eng":0.3951159306,"data-quality":0.1389770688,"ml-security":0.0568671286}}
{"text":"To properly train BTBR, we propose and investigate several masking strategies and training objectives: (i) item-level random masking, (ii) item-level select masking, (iii) basket-level all masking, (iv) basket-level explore masking, and (v) joint masking.","meta":{"url":"http://arxiv.org/abs/2308.01308v1"},"cats":{"new-dataset":0.0650995242,"dev-research":0.1958334204,"prompt-eng":0.4492247536,"data-quality":0.2434853764,"ml-security":0.2120945077}}
{"text":"In addition, an item-basket swapping strategy is proposed to enrich the item interactions within the same baskets.","meta":{"url":"http://arxiv.org/abs/2308.01308v1"},"cats":{"new-dataset":0.022469529,"dev-research":0.2881850844,"prompt-eng":0.5008809582,"data-quality":0.1125918069,"ml-security":0.0590910561}}
{"text":"We conduct extensive experiments on three open datasets with various characteristics.","meta":{"url":"http://arxiv.org/abs/2308.01308v1"},"cats":{"new-dataset":0.6858498555,"dev-research":0.1559656748,"prompt-eng":0.3613181264,"data-quality":0.203022281,"ml-security":0.1388643227}}
{"text":"The results demonstrate the effectiveness of BTBR and our masking and swapping strategies for the NNBR task.","meta":{"url":"http://arxiv.org/abs/2308.01308v1"},"cats":{"new-dataset":0.0362597876,"dev-research":0.251757038,"prompt-eng":0.4885443281,"data-quality":0.1658585078,"ml-security":0.0548916837}}
{"text":"BTBR with a properly selected masking and swapping strategy can substantially improve NNBR performance.","meta":{"url":"http://arxiv.org/abs/2308.01308v1"},"cats":{"new-dataset":0.0157448416,"dev-research":0.2554927742,"prompt-eng":0.4090310927,"data-quality":0.1426357536,"ml-security":0.0520461624}}
{"text":"Online communities are not safe spaces for user privacy.","meta":{"url":"http://arxiv.org/abs/2308.01304v1"},"cats":{"new-dataset":0.0372857748,"dev-research":0.271522562,"prompt-eng":0.2789487363,"data-quality":0.1767786436,"ml-security":0.432042451}}
{"text":"Even though existing research focuses on creating and improving various content moderation strategies and privacy preserving technologies, platforms hosting online communities support features allowing users to surveil one another--leading to harassment, personal data breaches, and offline harm.","meta":{"url":"http://arxiv.org/abs/2308.01304v1"},"cats":{"new-dataset":0.0446911957,"dev-research":0.3219561603,"prompt-eng":0.3222858485,"data-quality":0.154070811,"ml-security":0.3371664326}}
{"text":"To tackle this problem, we introduce a new, work-in-progress framework for analyzing data privacy within vulnerable, identity-based online communities.","meta":{"url":"http://arxiv.org/abs/2308.01304v1"},"cats":{"new-dataset":0.2816095646,"dev-research":0.3130032996,"prompt-eng":0.3679767661,"data-quality":0.2511249226,"ml-security":0.5310408941}}
{"text":"Where current SOUPS papers study surveillance and longitudinal user data as two distinct challenges to user privacy, more work needs to be done in exploring the sites where surveillance and historical user data assemble.","meta":{"url":"http://arxiv.org/abs/2308.01304v1"},"cats":{"new-dataset":0.2545641955,"dev-research":0.2232083503,"prompt-eng":0.3757301601,"data-quality":0.1092919839,"ml-security":0.3725631505}}
{"text":"By synthesizing over 40 years of developments in the analysis of surveillance, we derive properties of online communities that enable the abuse of user data by fellow community members and suggest key steps to improving security for vulnerable users.","meta":{"url":"http://arxiv.org/abs/2308.01304v1"},"cats":{"new-dataset":0.2272911206,"dev-research":0.3246577423,"prompt-eng":0.4129426576,"data-quality":0.1432103625,"ml-security":0.6263504088}}
{"text":"Deploying this new framework on new and existing platforms will ensure that online communities are privacy-conscious and designed more inclusively.","meta":{"url":"http://arxiv.org/abs/2308.01304v1"},"cats":{"new-dataset":0.106471182,"dev-research":0.3051915242,"prompt-eng":0.3467023709,"data-quality":0.1398893346,"ml-security":0.326505882}}
{"text":"Enterprises in their journey to the cloud, want to decompose their monolith applications into microservices to maximize cloud benefits.","meta":{"url":"http://arxiv.org/abs/2308.01302v1"},"cats":{"new-dataset":0.0644516226,"dev-research":0.2686009633,"prompt-eng":0.3390192247,"data-quality":0.1022521378,"ml-security":0.1263311148}}
{"text":"Current research focuses a lot on how to partition the monolith into smaller clusters that perform well across standard metrics like coupling, cohesion, etc.","meta":{"url":"http://arxiv.org/abs/2308.01302v1"},"cats":{"new-dataset":0.1328355266,"dev-research":0.2208262964,"prompt-eng":0.3792334537,"data-quality":0.099183342,"ml-security":0.0348324918}}
{"text":"However, there is little research done on taking the partitions, identifying their dependencies between the microservices, exploring ways to further reduce the dependencies, and making appropriate code changes to enable robust communication without modifying the application behaviour.   ","meta":{"url":"http://arxiv.org/abs/2308.01302v1"},"cats":{"new-dataset":0.101497599,"dev-research":0.199013691,"prompt-eng":0.3981836068,"data-quality":0.1943129454,"ml-security":0.0873336831}}
{"text":"In this work, we discuss the challenges with the conventional techniques of communication using JSON and propose an alternative way of ID-passing via APIs.","meta":{"url":"http://arxiv.org/abs/2308.01302v1"},"cats":{"new-dataset":0.0600550397,"dev-research":0.2432311662,"prompt-eng":0.4569771316,"data-quality":0.1984111291,"ml-security":0.1731970123}}
{"text":"We also devise an algorithm to reduce the number of APIs.","meta":{"url":"http://arxiv.org/abs/2308.01302v1"},"cats":{"new-dataset":0.0654962823,"dev-research":0.2889237997,"prompt-eng":0.3801874461,"data-quality":0.1511734399,"ml-security":0.1729295379}}
{"text":"For this, we construct subgraphs of methods and their associated variables in each class and relocate them to their more functionally aligned microservices.","meta":{"url":"http://arxiv.org/abs/2308.01302v1"},"cats":{"new-dataset":0.2676789879,"dev-research":0.282683193,"prompt-eng":0.371009241,"data-quality":0.1826415731,"ml-security":0.0756878697}}
{"text":"Our quantitative and qualitative studies on five public Java applications clearly demonstrate that our refactored microservices using ID have decidedly better time and memory complexities than JSON.","meta":{"url":"http://arxiv.org/abs/2308.01302v1"},"cats":{"new-dataset":0.0979579712,"dev-research":0.3044091811,"prompt-eng":0.3704034345,"data-quality":0.1815709933,"ml-security":0.152066114}}
{"text":"Our automation reduces 40-60\\% of the manual refactoring efforts.","meta":{"url":"http://arxiv.org/abs/2308.01302v1"},"cats":{"new-dataset":0.0271141988,"dev-research":0.4312372717,"prompt-eng":0.4583201019,"data-quality":0.2025319614,"ml-security":0.1277232282}}
{"text":"Motivated by that DETR-based approaches have established new records on COCO detection and segmentation benchmarks, many recent endeavors show increasing interest in how to further improve DETR-based approaches by pre-training the Transformer in a self-supervised manner while keeping the backbone frozen.","meta":{"url":"http://arxiv.org/abs/2308.01300v1"},"cats":{"new-dataset":0.1365186935,"dev-research":0.2109067496,"prompt-eng":0.434109422,"data-quality":0.2831883243,"ml-security":0.1517444228}}
{"text":"Some studies already claimed significant improvements in accuracy.","meta":{"url":"http://arxiv.org/abs/2308.01300v1"},"cats":{"new-dataset":0.0159224367,"dev-research":0.2896777152,"prompt-eng":0.3527933653,"data-quality":0.322346985,"ml-security":0.1088420769}}
{"text":"In this paper, we take a closer look at their experimental methodology and check if their approaches are still effective on the very recent state-of-the-art such as $\\mathcal{H}$-Deformable-DETR.","meta":{"url":"http://arxiv.org/abs/2308.01300v1"},"cats":{"new-dataset":0.0304331987,"dev-research":0.1616103807,"prompt-eng":0.410308001,"data-quality":0.0908171629,"ml-security":0.0834178475}}
{"text":"We conduct thorough experiments on COCO object detection tasks to study the influence of the choice of pre-training datasets, localization, and classification target generation schemes.","meta":{"url":"http://arxiv.org/abs/2308.01300v1"},"cats":{"new-dataset":0.2089828213,"dev-research":0.232683764,"prompt-eng":0.4077410509,"data-quality":0.2690549823,"ml-security":0.2050682452}}
{"text":"Unfortunately, we find the previous representative self-supervised approach such as DETReg, fails to boost the performance of the strong DETR-based approaches on full data regimes.","meta":{"url":"http://arxiv.org/abs/2308.01300v1"},"cats":{"new-dataset":0.2229146391,"dev-research":0.1944183284,"prompt-eng":0.4334037418,"data-quality":0.3735504337,"ml-security":0.1752403997}}
{"text":"We further analyze the reasons and find that simply combining a more accurate box predictor and Objects$365$ benchmark can significantly improve the results in follow-up experiments.","meta":{"url":"http://arxiv.org/abs/2308.01300v1"},"cats":{"new-dataset":0.0624999547,"dev-research":0.2575962203,"prompt-eng":0.3973286041,"data-quality":0.1848810012,"ml-security":0.1269272438}}
{"text":"We demonstrate the effectiveness of our approach by achieving strong object detection results of AP=$59.3\\%$ on COCO val set, which surpasses $\\mathcal{H}$-Deformable-DETR + Swin-L by +$1.4\\%$. Last, we generate a series of synthetic pre-training datasets by combining the very recent image-to-text captioning models (LLaVA) and text-to-image generative models (SDXL).","meta":{"url":"http://arxiv.org/abs/2308.01300v1"},"cats":{"new-dataset":0.4899697054,"dev-research":0.1971059501,"prompt-eng":0.3878172882,"data-quality":0.2517008574,"ml-security":0.2250142862}}
{"text":"Notably, pre-training on these synthetic datasets leads to notable improvements in object detection performance.","meta":{"url":"http://arxiv.org/abs/2308.01300v1"},"cats":{"new-dataset":0.2543964978,"dev-research":0.2280482288,"prompt-eng":0.3755699198,"data-quality":0.2112562277,"ml-security":0.195916197}}
{"text":"Looking ahead, we anticipate substantial advantages through the future expansion of the synthetic pre-training dataset.","meta":{"url":"http://arxiv.org/abs/2308.01300v1"},"cats":{"new-dataset":0.4092957846,"dev-research":0.2314588156,"prompt-eng":0.3807938852,"data-quality":0.1636346049,"ml-security":0.1452138236}}
{"text":"Cloud-edge-device hierarchical federated learning (HFL) has been recently proposed to achieve communication-efficient and privacy-preserving distributed learning.","meta":{"url":"http://arxiv.org/abs/2308.01296v1"},"cats":{"new-dataset":0.1596272096,"dev-research":0.1736194024,"prompt-eng":0.3214926507,"data-quality":0.137704786,"ml-security":0.280976064}}
{"text":"However, there exist several critical challenges, such as the single point of failure and potential stragglers in both edge servers and local devices.","meta":{"url":"http://arxiv.org/abs/2308.01296v1"},"cats":{"new-dataset":0.0586792804,"dev-research":0.3153990486,"prompt-eng":0.3348344734,"data-quality":0.1954877838,"ml-security":0.2332845042}}
{"text":"To resolve these issues, we propose a decentralized and straggler-tolerant blockchain-based HFL (BHFL) framework.","meta":{"url":"http://arxiv.org/abs/2308.01296v1"},"cats":{"new-dataset":0.1484899205,"dev-research":0.1997322111,"prompt-eng":0.3287175571,"data-quality":0.110366365,"ml-security":0.0928940427}}
{"text":"Specifically, a Raft-based consortium blockchain is deployed on edge servers to provide a distributed and trusted computing environment for global model aggregation in BHFL.","meta":{"url":"http://arxiv.org/abs/2308.01296v1"},"cats":{"new-dataset":0.2228737061,"dev-research":0.1972436762,"prompt-eng":0.3227651706,"data-quality":0.0861832868,"ml-security":0.1327472753}}
{"text":"To mitigate the influence of stragglers on learning, we propose a novel aggregation method, HieAvg, which utilizes the historical weights of stragglers to estimate the missing submissions.","meta":{"url":"http://arxiv.org/abs/2308.01296v1"},"cats":{"new-dataset":0.1229491731,"dev-research":0.2417212507,"prompt-eng":0.3687862617,"data-quality":0.2431144258,"ml-security":0.1561948499}}
{"text":"Furthermore, we optimize the overall latency of BHFL by jointly considering the constraints of global model convergence and blockchain consensus delay.","meta":{"url":"http://arxiv.org/abs/2308.01296v1"},"cats":{"new-dataset":0.0775728303,"dev-research":0.1915673275,"prompt-eng":0.346264127,"data-quality":0.088538941,"ml-security":0.0741408333}}
{"text":"Theoretical analysis and experimental evaluation show that our proposed BHFL based on HieAvg can converge in the presence of stragglers, which performs better than the traditional methods even when the loss function is non-convex and the data on local devices are non-independent and identically distributed (non-IID).","meta":{"url":"http://arxiv.org/abs/2308.01296v1"},"cats":{"new-dataset":0.0618912929,"dev-research":0.1496366866,"prompt-eng":0.3307982128,"data-quality":0.0848343399,"ml-security":0.069655736}}
{"text":"Enumeration kernelization was first proposed by Creignou et al.","meta":{"url":"http://arxiv.org/abs/2308.01286v1"},"cats":{"new-dataset":0.1577806042,"dev-research":0.2085674194,"prompt-eng":0.3743053452,"data-quality":0.2102817343,"ml-security":0.087374368}}
{"text":"[TOCS 2017] and was later refined by Golovach et al.","meta":{"url":"http://arxiv.org/abs/2308.01286v1"},"cats":{"new-dataset":0.4326233736,"dev-research":0.1585143081,"prompt-eng":0.3621124033,"data-quality":0.1354547651,"ml-security":0.0544241403}}
{"text":"[JCSS 2022] into two different variants: fully-polynomial enumeration kernelization and polynomial-delay enumeration kernelization.","meta":{"url":"http://arxiv.org/abs/2308.01286v1"},"cats":{"new-dataset":0.2555797967,"dev-research":0.2083782815,"prompt-eng":0.4061041176,"data-quality":0.2296817107,"ml-security":0.0992458362}}
{"text":"In this paper, we consider the d-CUT problem from the perspective of (polynomial-delay) enumeration kenrelization.","meta":{"url":"http://arxiv.org/abs/2308.01286v1"},"cats":{"new-dataset":0.1879484427,"dev-research":0.225142175,"prompt-eng":0.3834934276,"data-quality":0.2417405231,"ml-security":0.0872700399}}
{"text":"Given an undirected graph G = (V, E), a cut F = E(A, B) is a d-cut of G if every u in A has at most d neighbors in B and every v in B has at most d neighbors in A. Checking the existence of a d-cut in a graph is a well-known NP-hard problem and is well-studied in parameterized complexity","meta":{"url":"http://arxiv.org/abs/2308.01286v1"},"cats":{"new-dataset":0.1652647883,"dev-research":0.2312306112,"prompt-eng":0.3345325105,"data-quality":0.1937807043,"ml-security":0.1162821906}}
{"text":"[Algorithmica 2021, IWOCA 2021].","meta":{"url":"http://arxiv.org/abs/2308.01286v1"},"cats":{"new-dataset":0.6158847212,"dev-research":0.213544108,"prompt-eng":0.3665506284,"data-quality":0.1329355105,"ml-security":0.0734557466}}
{"text":"This problem also generalizes a well-studied problem MATCHING CUT (set d = 1) that has been a central problem in the literature of polynomial-delay enumeration kernelization.","meta":{"url":"http://arxiv.org/abs/2308.01286v1"},"cats":{"new-dataset":0.3461866639,"dev-research":0.1750023534,"prompt-eng":0.3768589288,"data-quality":0.2739809711,"ml-security":0.0906153191}}
{"text":"In this paper, we study three different enumeration variants of this problem, ENUM d-CUT, ENUM MIN-d-CUT and ENUM MAX-d-CUT that intends to enumerate all the d-cuts, all the minimal d-cuts and all the maximal d-cuts respectively.","meta":{"url":"http://arxiv.org/abs/2308.01286v1"},"cats":{"new-dataset":0.6051803187,"dev-research":0.1954191342,"prompt-eng":0.3773088113,"data-quality":0.1952916984,"ml-security":0.0519153753}}
{"text":"We consider various structural parameters of the input and provide polynomial-delay enumeration kernels for ENUM d-CUT and ENUM MAX-d-CUT and fully-polynomial enumeration kernels of polynomial size for ENUM MIN-d-CUT.","meta":{"url":"http://arxiv.org/abs/2308.01286v1"},"cats":{"new-dataset":0.2571749582,"dev-research":0.2013375027,"prompt-eng":0.3994120987,"data-quality":0.173928416,"ml-security":0.065166428}}
{"text":"Recent advances in artificial intelligence (AI) have produced highly capable and controllable systems.","meta":{"url":"http://arxiv.org/abs/2308.01285v1"},"cats":{"new-dataset":0.0933441395,"dev-research":0.2582631871,"prompt-eng":0.4253810379,"data-quality":0.1274187555,"ml-security":0.1212261153}}
{"text":"This creates unprecedented opportunities for structured reasoning as well as collaboration among multiple AI systems and humans.","meta":{"url":"http://arxiv.org/abs/2308.01285v1"},"cats":{"new-dataset":0.1315425664,"dev-research":0.3229413345,"prompt-eng":0.3889698281,"data-quality":0.1005567345,"ml-security":0.0949418231}}
{"text":"To fully realize this potential, it is essential to develop a principled way of designing and studying such structured interactions.","meta":{"url":"http://arxiv.org/abs/2308.01285v1"},"cats":{"new-dataset":0.0369404577,"dev-research":0.3010716806,"prompt-eng":0.4042729791,"data-quality":0.0536984084,"ml-security":0.0774541788}}
{"text":"For this purpose, we introduce the conceptual framework of Flows: a systematic approach to modeling complex interactions.","meta":{"url":"http://arxiv.org/abs/2308.01285v1"},"cats":{"new-dataset":0.0723759065,"dev-research":0.3132746284,"prompt-eng":0.4086225798,"data-quality":0.0584509344,"ml-security":0.0752025718}}
{"text":"Flows are self-contained building blocks of computation, with an isolated state, communicating through a standardized message-based interface.","meta":{"url":"http://arxiv.org/abs/2308.01285v1"},"cats":{"new-dataset":0.1064293554,"dev-research":0.2893496033,"prompt-eng":0.3699101908,"data-quality":0.0949581295,"ml-security":0.1233576515}}
{"text":"This modular design allows Flows to be recursively composed into arbitrarily nested interactions, with a substantial reduction of complexity.","meta":{"url":"http://arxiv.org/abs/2308.01285v1"},"cats":{"new-dataset":0.0872454256,"dev-research":0.2484534963,"prompt-eng":0.4048317727,"data-quality":0.0574069276,"ml-security":0.1184309973}}
{"text":"Crucially, any interaction can be implemented using this framework, including prior work on AI--AI and human--AI interactions, prompt engineering schemes, and tool augmentation.","meta":{"url":"http://arxiv.org/abs/2308.01285v1"},"cats":{"new-dataset":0.0832323172,"dev-research":0.3711708483,"prompt-eng":0.5488820248,"data-quality":0.117001878,"ml-security":0.1240893527}}
{"text":"We demonstrate the potential of Flows on the task of competitive coding, a challenging task on which even GPT-4 struggles.","meta":{"url":"http://arxiv.org/abs/2308.01285v1"},"cats":{"new-dataset":0.0741527654,"dev-research":0.3696516158,"prompt-eng":0.3735137761,"data-quality":0.1811193794,"ml-security":0.1281468222}}
{"text":"Our results suggest that structured reasoning and collaboration substantially improve generalization, with AI-only Flows adding +$21$ and human--AI Flows adding +$54$ absolute points in terms of solve rate.","meta":{"url":"http://arxiv.org/abs/2308.01285v1"},"cats":{"new-dataset":0.1203885404,"dev-research":0.3483469403,"prompt-eng":0.3821255555,"data-quality":0.1401797584,"ml-security":0.1167209116}}
{"text":"To support rapid and rigorous research, we introduce the aiFlows library.","meta":{"url":"http://arxiv.org/abs/2308.01285v1"},"cats":{"new-dataset":0.2960498015,"dev-research":0.3629383401,"prompt-eng":0.4478347281,"data-quality":0.1507451126,"ml-security":0.082114178}}
{"text":"The library comes with a repository of Flows that can be easily used, extended, and composed into novel, more complex Flows.   ","meta":{"url":"http://arxiv.org/abs/2308.01285v1"},"cats":{"new-dataset":0.2608733176,"dev-research":0.2743543512,"prompt-eng":0.3475258466,"data-quality":0.0691230141,"ml-security":0.0456925301}}
{"text":"The aiFlows library is available at https://github.com/epfl-dlab/aiflows.","meta":{"url":"http://arxiv.org/abs/2308.01285v1"},"cats":{"new-dataset":0.4249706908,"dev-research":0.2525003695,"prompt-eng":0.4626763499,"data-quality":0.1125319646,"ml-security":0.0386164963}}
{"text":"Data and Flows for reproducing our experiments are available at https://github.com/epfl-dlab/cc_flows.","meta":{"url":"http://arxiv.org/abs/2308.01285v1"},"cats":{"new-dataset":0.2454684271,"dev-research":0.1607386116,"prompt-eng":0.4466989154,"data-quality":0.1316581337,"ml-security":0.0478162578}}
{"text":"Large language models (LLMs) such as ChatGPT are increasingly being used for various use cases, including text content generation at scale.","meta":{"url":"http://arxiv.org/abs/2308.01284v1"},"cats":{"new-dataset":0.206986879,"dev-research":0.2625583033,"prompt-eng":0.4120174308,"data-quality":0.1551081816,"ml-security":0.0720797846}}
{"text":"Although detection methods for such AI-generated text exist already, we investigate ChatGPT's performance as a detector on such AI-generated text, inspired by works that use ChatGPT as a data labeler or annotator.","meta":{"url":"http://arxiv.org/abs/2308.01284v1"},"cats":{"new-dataset":0.3699867045,"dev-research":0.3064279968,"prompt-eng":0.4289721771,"data-quality":0.4613547783,"ml-security":0.191234169}}
{"text":"We evaluate the zero-shot performance of ChatGPT in the task of human-written vs. AI-generated text detection, and perform experiments on publicly available datasets.","meta":{"url":"http://arxiv.org/abs/2308.01284v1"},"cats":{"new-dataset":0.5455830296,"dev-research":0.2707391435,"prompt-eng":0.3520619627,"data-quality":0.323054724,"ml-security":0.1725150248}}
{"text":"We empirically investigate if ChatGPT is symmetrically effective in detecting AI-generated or human-written text.","meta":{"url":"http://arxiv.org/abs/2308.01284v1"},"cats":{"new-dataset":0.167034987,"dev-research":0.34170919,"prompt-eng":0.421156128,"data-quality":0.3440617126,"ml-security":0.20719368}}
{"text":"Our findings provide insight on how ChatGPT and similar LLMs may be leveraged in automated detection pipelines by simply focusing on solving a specific aspect of the problem and deriving the rest from that solution.","meta":{"url":"http://arxiv.org/abs/2308.01284v1"},"cats":{"new-dataset":0.1786654225,"dev-research":0.2847953053,"prompt-eng":0.5130342259,"data-quality":0.3384178586,"ml-security":0.1681249226}}
{"text":"All code and data is available at \\url{https://github.com/AmritaBh/ChatGPT-as-Detector}.","meta":{"url":"http://arxiv.org/abs/2308.01284v1"},"cats":{"new-dataset":0.674449639,"dev-research":0.161616319,"prompt-eng":0.4272753792,"data-quality":0.182210193,"ml-security":0.0840358328}}
{"text":"Time-Lock Puzzles (TLPs) are cryptographic protocols that enable a client to lock a message in such a way that a server can only unlock it after a specific time period.","meta":{"url":"http://arxiv.org/abs/2308.01280v1"},"cats":{"new-dataset":0.0650409738,"dev-research":0.2652346121,"prompt-eng":0.3902522091,"data-quality":0.1069328326,"ml-security":0.1965468419}}
{"text":"However, existing TLPs have certain limitations: (i) they assume that both the client and server always possess sufficient computational resources and (ii) they solely focus on the lower time bound for finding a solution, disregarding the upper bound that guarantees a regular server can find a solution within a certain time frame.","meta":{"url":"http://arxiv.org/abs/2308.01280v1"},"cats":{"new-dataset":0.0226817439,"dev-research":0.2782250932,"prompt-eng":0.3543330217,"data-quality":0.0866125323,"ml-security":0.1358881281}}
{"text":"Additionally, existing TLPs designed to handle multiple puzzles either (a) entail high verification costs or (b) lack generality, requiring identical time intervals between consecutive solutions.","meta":{"url":"http://arxiv.org/abs/2308.01280v1"},"cats":{"new-dataset":0.0462501071,"dev-research":0.2889379803,"prompt-eng":0.4066021175,"data-quality":0.1069781803,"ml-security":0.0826025392}}
{"text":"To address these limitations, this paper introduces, for the first time, the concept of a \"Delegated Time-Lock Puzzle\" and presents a protocol called \"Efficient Delegated Time-Lock Puzzle\" (ED-TLP) that realises this concept.","meta":{"url":"http://arxiv.org/abs/2308.01280v1"},"cats":{"new-dataset":0.0512165174,"dev-research":0.340039634,"prompt-eng":0.4836478675,"data-quality":0.1428059036,"ml-security":0.1966697721}}
{"text":"ED-TLP allows the client and server to delegate their resource-demanding tasks to third-party helpers.","meta":{"url":"http://arxiv.org/abs/2308.01280v1"},"cats":{"new-dataset":0.0968361818,"dev-research":0.3299985427,"prompt-eng":0.4955772086,"data-quality":0.1089071875,"ml-security":0.0912403208}}
{"text":"It facilitates real-time verification of solution correctness and efficiently handles multiple puzzles with varying time intervals.","meta":{"url":"http://arxiv.org/abs/2308.01280v1"},"cats":{"new-dataset":0.0533462129,"dev-research":0.4284040162,"prompt-eng":0.4283995424,"data-quality":0.1146425959,"ml-security":0.0681155583}}
{"text":"ED-TLP ensures the delivery of solutions within predefined time limits by incorporating both an upper bound and a fair payment algorithm.","meta":{"url":"http://arxiv.org/abs/2308.01280v1"},"cats":{"new-dataset":0.1121374821,"dev-research":0.2485882655,"prompt-eng":0.3656462568,"data-quality":0.0786355203,"ml-security":0.087011461}}
{"text":"We have implemented ED-TLP and conducted a comprehensive analysis of its overheads, demonstrating the efficiency of the construction.","meta":{"url":"http://arxiv.org/abs/2308.01280v1"},"cats":{"new-dataset":0.1644420795,"dev-research":0.3644800673,"prompt-eng":0.4791176197,"data-quality":0.0795599142,"ml-security":0.0295929485}}
{"text":"Although experience sharing (ES) accelerates multiagent reinforcement learning (MARL) in an advisor-advisee framework, attempts to apply ES to decentralized multiagent systems have so far relied on trusted environments and overlooked the possibility of adversarial manipulation and inference.","meta":{"url":"http://arxiv.org/abs/2308.01274v1"},"cats":{"new-dataset":0.0759709342,"dev-research":0.2823264695,"prompt-eng":0.3641284306,"data-quality":0.1062910514,"ml-security":0.3185159919}}
{"text":"Nevertheless, in a real-world setting, some Byzantine attackers, disguised as advisors, may provide false advice to the advisee and catastrophically degrade the overall learning performance.","meta":{"url":"http://arxiv.org/abs/2308.01274v1"},"cats":{"new-dataset":0.0508542938,"dev-research":0.3682495911,"prompt-eng":0.3827724469,"data-quality":0.1904009912,"ml-security":0.6352862834}}
{"text":"Also, an inference attacker, disguised as an advisee, may conduct several queries to infer the advisors' private information and make the entire ES process questionable in terms of privacy leakage.","meta":{"url":"http://arxiv.org/abs/2308.01274v1"},"cats":{"new-dataset":0.0328522636,"dev-research":0.3354298264,"prompt-eng":0.4078175963,"data-quality":0.1301452064,"ml-security":0.7466224908}}
{"text":"To address and tackle these issues, we propose a novel MARL framework (BRNES) that heuristically selects a dynamic neighbor zone for each advisee at each learning step and adopts a weighted experience aggregation technique to reduce Byzantine attack impact.","meta":{"url":"http://arxiv.org/abs/2308.01274v1"},"cats":{"new-dataset":0.1523040748,"dev-research":0.3244736539,"prompt-eng":0.4319855107,"data-quality":0.135129197,"ml-security":0.2634750674}}
{"text":"Furthermore, to keep the agent's private information safe from adversarial inference attacks, we leverage the local differential privacy (LDP)-induced noise during the ES process.","meta":{"url":"http://arxiv.org/abs/2308.01274v1"},"cats":{"new-dataset":0.1022545556,"dev-research":0.270954488,"prompt-eng":0.353442564,"data-quality":0.2424657556,"ml-security":0.7592363638}}
{"text":"Our experiments show that our framework outperforms the state-of-the-art in terms of the steps to goal, obtained reward, and time to goal metrics.","meta":{"url":"http://arxiv.org/abs/2308.01274v1"},"cats":{"new-dataset":0.0877699261,"dev-research":0.2038016703,"prompt-eng":0.4412480093,"data-quality":0.1801552843,"ml-security":0.0797956079}}
{"text":"Particularly, our evaluation shows that the proposed framework is 8.32x faster than the current non-private frameworks and 1.41x faster than the private frameworks in an adversarial setting.","meta":{"url":"http://arxiv.org/abs/2308.01274v1"},"cats":{"new-dataset":0.1564127693,"dev-research":0.2370250687,"prompt-eng":0.3395526302,"data-quality":0.2308151596,"ml-security":0.5873983369}}
{"text":"Phishing PDFs are malicious PDF documents that do not embed malware but trick victims into visiting malicious web pages leading to password theft or drive-by downloads.","meta":{"url":"http://arxiv.org/abs/2308.01273v1"},"cats":{"new-dataset":0.0422353284,"dev-research":0.3446497185,"prompt-eng":0.3641595653,"data-quality":0.214632286,"ml-security":0.3707638151}}
{"text":"While recent reports indicate a surge of phishing PDFs, prior works have largely neglected this new threat, positioning phishing PDFs as accessories distributed via email phishing campaigns.   ","meta":{"url":"http://arxiv.org/abs/2308.01273v1"},"cats":{"new-dataset":0.0507065448,"dev-research":0.2794778138,"prompt-eng":0.4429666154,"data-quality":0.2544183273,"ml-security":0.420185277}}
{"text":"This paper challenges this belief and presents the first systematic and comprehensive study centered on phishing PDFs.","meta":{"url":"http://arxiv.org/abs/2308.01273v1"},"cats":{"new-dataset":0.0488876539,"dev-research":0.2975626265,"prompt-eng":0.4278653294,"data-quality":0.2764444373,"ml-security":0.4639754077}}
{"text":"Starting from a real-world dataset, we first identify 44 phishing PDF campaigns via clustering and characterize them by looking at their volumetric, temporal, and visual features.","meta":{"url":"http://arxiv.org/abs/2308.01273v1"},"cats":{"new-dataset":0.2602109569,"dev-research":0.2480673874,"prompt-eng":0.3798593388,"data-quality":0.3105332127,"ml-security":0.5358520537}}
{"text":"Among these, we identify three large campaigns covering 89% of the dataset, exhibiting significantly different volumetric and temporal properties compared to classical email phishing, and relying on web UI elements as visual baits.","meta":{"url":"http://arxiv.org/abs/2308.01273v1"},"cats":{"new-dataset":0.3116374678,"dev-research":0.2317998571,"prompt-eng":0.382410335,"data-quality":0.2951480198,"ml-security":0.4885731308}}
{"text":"Finally, we look at the distribution vectors and show that phishing PDFs are not only distributed via attachments but also via SEO attacks, placing phishing PDFs outside the email distribution ecosystem.   ","meta":{"url":"http://arxiv.org/abs/2308.01273v1"},"cats":{"new-dataset":0.0723160958,"dev-research":0.2388239393,"prompt-eng":0.3987918891,"data-quality":0.2801543037,"ml-security":0.4913307499}}
{"text":"This paper also assesses the usefulness of the VirusTotal scoring system, showing that phishing PDFs are ranked considerably low, creating a blind spot for organizations.","meta":{"url":"http://arxiv.org/abs/2308.01273v1"},"cats":{"new-dataset":0.0779896191,"dev-research":0.2915661078,"prompt-eng":0.451971117,"data-quality":0.3141240701,"ml-security":0.3924728952}}
{"text":"While URL blocklists can help to prevent victims from visiting the attack web pages, PDF documents seem not subjected to any form of content-based filtering or detection.","meta":{"url":"http://arxiv.org/abs/2308.01273v1"},"cats":{"new-dataset":0.0402372845,"dev-research":0.2392028086,"prompt-eng":0.3494757596,"data-quality":0.2609211542,"ml-security":0.4357341524}}
{"text":"In this paper we present a practical Bayesian self-supervised learning method with Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC).","meta":{"url":"http://arxiv.org/abs/2308.01271v1"},"cats":{"new-dataset":0.1440456257,"dev-research":0.1723521303,"prompt-eng":0.4048231872,"data-quality":0.1613201306,"ml-security":0.1077474604}}
{"text":"Within this framework, we place a prior over the parameters of a self-supervised learning model and use cSGHMC to approximate the high dimensional and multimodal posterior distribution over the embeddings.","meta":{"url":"http://arxiv.org/abs/2308.01271v1"},"cats":{"new-dataset":0.2825455289,"dev-research":0.1585151511,"prompt-eng":0.4044117036,"data-quality":0.1959702923,"ml-security":0.125220248}}
{"text":"By exploring an expressive posterior over the embeddings, Bayesian self-supervised learning produces interpretable and diverse representations.","meta":{"url":"http://arxiv.org/abs/2308.01271v1"},"cats":{"new-dataset":0.0838995235,"dev-research":0.2455443795,"prompt-eng":0.4096072627,"data-quality":0.2071035677,"ml-security":0.134866434}}
{"text":"Marginalizing over these representations yields a significant gain in performance, calibration and out-of-distribution detection on a variety of downstream classification tasks.","meta":{"url":"http://arxiv.org/abs/2308.01271v1"},"cats":{"new-dataset":0.1053375732,"dev-research":0.1935764536,"prompt-eng":0.4330506802,"data-quality":0.4279985205,"ml-security":0.2198367975}}
{"text":"We provide experimental results on multiple classification tasks on four challenging datasets.","meta":{"url":"http://arxiv.org/abs/2308.01271v1"},"cats":{"new-dataset":0.5316932459,"dev-research":0.16778001,"prompt-eng":0.4045043518,"data-quality":0.4023283125,"ml-security":0.1413148568}}
{"text":"Moreover, we demonstrate the effectiveness of the proposed method in out-of-distribution detection using the SVHN and CIFAR-10 datasets.","meta":{"url":"http://arxiv.org/abs/2308.01271v1"},"cats":{"new-dataset":0.2261285644,"dev-research":0.1848760764,"prompt-eng":0.3916109624,"data-quality":0.4808295089,"ml-security":0.2406452311}}
{"text":"Large language models have been used as the foundation of highly sophisticated artificial intelligences, capable of delivering human-like responses to probes about legal and moral issues.","meta":{"url":"http://arxiv.org/abs/2308.01264v1"},"cats":{"new-dataset":0.328650265,"dev-research":0.232103969,"prompt-eng":0.3527078484,"data-quality":0.1762619072,"ml-security":0.2515105204}}
{"text":"However, these models are unreliable guides to their own inner workings, and even the engineering teams behind their creation are unable to explain exactly how they came to develop all of the capabilities they currently have.","meta":{"url":"http://arxiv.org/abs/2308.01264v1"},"cats":{"new-dataset":0.0208400737,"dev-research":0.3729238321,"prompt-eng":0.3701322074,"data-quality":0.1976031959,"ml-security":0.1429500095}}
{"text":"The emerging field of machine psychology seeks to gain insight into the processes and concepts that these models possess.","meta":{"url":"http://arxiv.org/abs/2308.01264v1"},"cats":{"new-dataset":0.0248592912,"dev-research":0.3123794945,"prompt-eng":0.4392523518,"data-quality":0.1420047064,"ml-security":0.186432642}}
{"text":"In this paper, we employ the methods of psychology to probe into GPT-4's moral and legal reasoning.","meta":{"url":"http://arxiv.org/abs/2308.01264v1"},"cats":{"new-dataset":0.0587108074,"dev-research":0.3085329491,"prompt-eng":0.3687283895,"data-quality":0.1530648769,"ml-security":0.1809865488}}
{"text":"More specifically, we investigate the similarities and differences between GPT-4 and humans when it comes to intentionality ascriptions, judgments about causation, the morality of deception, moral foundations, the impact of moral luck on legal judgments, the concept of consent, and rule violation judgments.","meta":{"url":"http://arxiv.org/abs/2308.01264v1"},"cats":{"new-dataset":0.0778806367,"dev-research":0.3484742993,"prompt-eng":0.3720973191,"data-quality":0.1898884988,"ml-security":0.1483136685}}
{"text":"We find high correlations between human and AI responses, but also several significant systematic differences between them.","meta":{"url":"http://arxiv.org/abs/2308.01264v1"},"cats":{"new-dataset":0.068117774,"dev-research":0.2823143902,"prompt-eng":0.4033375581,"data-quality":0.1781431575,"ml-security":0.1819571241}}
{"text":"We conclude with a discussion of the philosophical implications of our findings.","meta":{"url":"http://arxiv.org/abs/2308.01264v1"},"cats":{"new-dataset":0.0485659071,"dev-research":0.2857115202,"prompt-eng":0.3615708623,"data-quality":0.2601701199,"ml-security":0.1291720131}}
{"text":"Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content.","meta":{"url":"http://arxiv.org/abs/2308.01263v1"},"cats":{"new-dataset":0.0481497047,"dev-research":0.3041330646,"prompt-eng":0.4115080831,"data-quality":0.32427671,"ml-security":0.7002709403}}
{"text":"This motivates safety efforts such as red-teaming and large-scale feedback learning, which aim to make models both helpful and harmless.","meta":{"url":"http://arxiv.org/abs/2308.01263v1"},"cats":{"new-dataset":0.0536659409,"dev-research":0.4150401195,"prompt-eng":0.3917850431,"data-quality":0.1969487374,"ml-security":0.464593977}}
{"text":"However, there is a tension between these two objectives, since harmlessness requires models to refuse complying with unsafe prompts, and thus not be helpful.","meta":{"url":"http://arxiv.org/abs/2308.01263v1"},"cats":{"new-dataset":0.0072982153,"dev-research":0.3290839876,"prompt-eng":0.433951133,"data-quality":0.2712770592,"ml-security":0.5241994825}}
{"text":"Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics.","meta":{"url":"http://arxiv.org/abs/2308.01263v1"},"cats":{"new-dataset":0.0307794852,"dev-research":0.3254502395,"prompt-eng":0.480783789,"data-quality":0.3053165107,"ml-security":0.577008756}}
{"text":"In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviours in a structured and systematic way.","meta":{"url":"http://arxiv.org/abs/2308.01263v1"},"cats":{"new-dataset":0.2000880186,"dev-research":0.4426562765,"prompt-eng":0.5115905577,"data-quality":0.3003303779,"ml-security":0.426981595}}
{"text":"In its current form, XSTest comprises 200 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with.","meta":{"url":"http://arxiv.org/abs/2308.01263v1"},"cats":{"new-dataset":0.2696481988,"dev-research":0.3174191134,"prompt-eng":0.5689493667,"data-quality":0.1843192072,"ml-security":0.2834546623}}
{"text":"We describe XSTest's creation and composition, and use the test suite to highlight systematic failure modes in a recently-released state-of-the-art language model.","meta":{"url":"http://arxiv.org/abs/2308.01263v1"},"cats":{"new-dataset":0.1961945452,"dev-research":0.4755098361,"prompt-eng":0.5017563216,"data-quality":0.3284380195,"ml-security":0.0818493252}}
{"text":"As a result of Shadow NeRF and Sat-NeRF, it is possible to take the solar angle into account in a NeRF-based framework for rendering a scene from a novel viewpoint using satellite images for training.","meta":{"url":"http://arxiv.org/abs/2308.01262v1"},"cats":{"new-dataset":0.1046145264,"dev-research":0.2484412087,"prompt-eng":0.3609952714,"data-quality":0.1472274135,"ml-security":0.0937087953}}
{"text":"Our work extends those contributions and shows how one can make the renderings season-specific.","meta":{"url":"http://arxiv.org/abs/2308.01262v1"},"cats":{"new-dataset":0.4465558884,"dev-research":0.2341422769,"prompt-eng":0.413723412,"data-quality":0.101915618,"ml-security":0.0456192504}}
{"text":"Our main challenge was creating a Neural Radiance Field (NeRF) that could render seasonal features independently of viewing angle and solar angle while still being able to render shadows.","meta":{"url":"http://arxiv.org/abs/2308.01262v1"},"cats":{"new-dataset":0.2633758208,"dev-research":0.2104959555,"prompt-eng":0.3947404945,"data-quality":0.1594346696,"ml-security":0.1108449443}}
{"text":"We teach our network to render seasonal features by introducing one more input variable -- time of the year.","meta":{"url":"http://arxiv.org/abs/2308.01262v1"},"cats":{"new-dataset":0.1898082959,"dev-research":0.2779467206,"prompt-eng":0.427248497,"data-quality":0.1481732257,"ml-security":0.082472373}}
{"text":"However, the small training datasets typical of satellite imagery can introduce ambiguities in cases where shadows are present in the same location for every image of a particular season.","meta":{"url":"http://arxiv.org/abs/2308.01262v1"},"cats":{"new-dataset":0.1972526068,"dev-research":0.2031935648,"prompt-eng":0.3473748006,"data-quality":0.2478127371,"ml-security":0.1472419099}}
{"text":"We add additional terms to the loss function to discourage the network from using seasonal features for accounting for shadows.","meta":{"url":"http://arxiv.org/abs/2308.01262v1"},"cats":{"new-dataset":0.0356926951,"dev-research":0.2250133734,"prompt-eng":0.389996861,"data-quality":0.2030997505,"ml-security":0.1800322706}}
{"text":"We show the performance of our network on eight Areas of Interest containing images captured by the Maxar WorldView-3 satellite.","meta":{"url":"http://arxiv.org/abs/2308.01262v1"},"cats":{"new-dataset":0.6588230375,"dev-research":0.1433131646,"prompt-eng":0.3142316856,"data-quality":0.1240603535,"ml-security":0.0723050645}}
{"text":"This evaluation includes tests measuring the ability of our framework to accurately render novel views, generate height maps, predict shadows, and specify seasonal features independently from shadows.","meta":{"url":"http://arxiv.org/abs/2308.01262v1"},"cats":{"new-dataset":0.2370633035,"dev-research":0.3075924746,"prompt-eng":0.4417495668,"data-quality":0.1409683721,"ml-security":0.0787464047}}
{"text":"Our ablation studies justify the choices made for network design parameters.","meta":{"url":"http://arxiv.org/abs/2308.01262v1"},"cats":{"new-dataset":0.036619527,"dev-research":0.2710677176,"prompt-eng":0.3816462213,"data-quality":0.0930318645,"ml-security":0.0551775511}}
{"text":"Community rules play a key part in enabling or constraining the behaviors of members in online communities.","meta":{"url":"http://arxiv.org/abs/2308.01257v1"},"cats":{"new-dataset":0.0261255856,"dev-research":0.3708454699,"prompt-eng":0.3852414904,"data-quality":0.1471370462,"ml-security":0.167769684}}
{"text":"However, little is unknown regarding whether and to what degree changing rules actually affects community dynamics.","meta":{"url":"http://arxiv.org/abs/2308.01257v1"},"cats":{"new-dataset":0.0165187348,"dev-research":0.303318059,"prompt-eng":0.2898953053,"data-quality":0.1780102664,"ml-security":0.1838803668}}
{"text":"In this paper, we seek to understand how these behavior-governing rules shape the interactions between users, as well as the structure of their discussion.","meta":{"url":"http://arxiv.org/abs/2308.01257v1"},"cats":{"new-dataset":0.0247604537,"dev-research":0.4636735155,"prompt-eng":0.5042949652,"data-quality":0.2186951346,"ml-security":0.1787145236}}
{"text":"Using the top communities on Reddit (i.e. subreddits), we first contribute a taxonomy of behavior-based rule categories across Reddit.","meta":{"url":"http://arxiv.org/abs/2308.01257v1"},"cats":{"new-dataset":0.2718977084,"dev-research":0.3476954042,"prompt-eng":0.4271200327,"data-quality":0.1804960228,"ml-security":0.1429005689}}
{"text":"Then, we use a network analysis perspective to discover how changing implementation of different rule categories affects subreddits' user interaction and discussion networks over a 1.5 year period.","meta":{"url":"http://arxiv.org/abs/2308.01257v1"},"cats":{"new-dataset":0.0607389317,"dev-research":0.397707887,"prompt-eng":0.3852278639,"data-quality":0.2248406201,"ml-security":0.1185903499}}
{"text":"Our study find several significant effects, including greater clustering among users when subreddits increase rules focused on structural regulation and how restricting allowable content surprisingly leads to more interactions between users.","meta":{"url":"http://arxiv.org/abs/2308.01257v1"},"cats":{"new-dataset":0.0121379433,"dev-research":0.3282062596,"prompt-eng":0.3806386534,"data-quality":0.2014384778,"ml-security":0.215394378}}
{"text":"Our findings contribute to research in proactive moderation through rule setting, as well as lend valuable insights for online community designers and moderators to achieve desired community dynamics.","meta":{"url":"http://arxiv.org/abs/2308.01257v1"},"cats":{"new-dataset":0.0691741683,"dev-research":0.3883835816,"prompt-eng":0.3997518381,"data-quality":0.1332399357,"ml-security":0.0945314665}}
{"text":"Long-Term tracking is a hot topic in Computer Vision.","meta":{"url":"http://arxiv.org/abs/2308.01256v1"},"cats":{"new-dataset":0.06942923,"dev-research":0.235183442,"prompt-eng":0.3486980226,"data-quality":0.1537348557,"ml-security":0.090402758}}
{"text":"In this context, competitive models are presented every year, showing a constant growth rate in performances, mainly measured in standardized protocols as Visual Object Tracking (VOT) and Object Tracking Benchmark (OTB).","meta":{"url":"http://arxiv.org/abs/2308.01256v1"},"cats":{"new-dataset":0.1350185891,"dev-research":0.2443464514,"prompt-eng":0.381468852,"data-quality":0.1492333874,"ml-security":0.0679173972}}
{"text":"Fusion-trackers strategy has been applied over last few years for overcoming the known re-detection problem, turning out to be an important breakthrough.","meta":{"url":"http://arxiv.org/abs/2308.01256v1"},"cats":{"new-dataset":0.0412811524,"dev-research":0.2699709214,"prompt-eng":0.4346231321,"data-quality":0.2608948644,"ml-security":0.1146049604}}
{"text":"Following this approach, this work aims to generalize the fusion concept to an arbitrary number of trackers used as baseline trackers in the pipeline, leveraging a learning phase to better understand how outcomes correlate with each other, even when no target is present.","meta":{"url":"http://arxiv.org/abs/2308.01256v1"},"cats":{"new-dataset":0.2150839303,"dev-research":0.2784555884,"prompt-eng":0.4291196366,"data-quality":0.2037586513,"ml-security":0.0926919384}}
{"text":"A model and data independence conjecture will be evidenced in the manuscript, yielding a recall of 0.738 on LTB-50 dataset when learning from VOT-LT2022, and 0.619 by reversing the two datasets.","meta":{"url":"http://arxiv.org/abs/2308.01256v1"},"cats":{"new-dataset":0.5198073699,"dev-research":0.1607927545,"prompt-eng":0.3360536835,"data-quality":0.2611612542,"ml-security":0.1208801116}}
{"text":"In both cases, results are strongly competitive with state-of-the-art and recall turns out to be the first on the podium.","meta":{"url":"http://arxiv.org/abs/2308.01256v1"},"cats":{"new-dataset":0.027297628,"dev-research":0.2539045654,"prompt-eng":0.3878596012,"data-quality":0.215849799,"ml-security":0.0673805268}}
{"text":"As a harzard disaster, landslide often brings tremendous losses to humanity, so it's necessary to achieve reliable detection of landslide.","meta":{"url":"http://arxiv.org/abs/2308.01251v1"},"cats":{"new-dataset":0.0586907985,"dev-research":0.223036097,"prompt-eng":0.3407166269,"data-quality":0.18490244,"ml-security":0.1510615379}}
{"text":"However, the problems of visual blur and small-sized dataset cause great challenges for old landslide detection task when using remote sensing data.","meta":{"url":"http://arxiv.org/abs/2308.01251v1"},"cats":{"new-dataset":0.3902401977,"dev-research":0.2173412969,"prompt-eng":0.3411505882,"data-quality":0.1937509821,"ml-security":0.1083583715}}
{"text":"To reliably extract semantic features, a hyper-pixel-wise contrastive learning augmented segmentation network (HPCL-Net) is proposed, which augments the local salient feature extraction from the boundaries of landslides through HPCL and fuses the heterogeneous infromation in the semantic space from High-Resolution Remote Sensing Images and Digital Elevation Model Data data.","meta":{"url":"http://arxiv.org/abs/2308.01251v1"},"cats":{"new-dataset":0.3164447244,"dev-research":0.2395335163,"prompt-eng":0.3543537061,"data-quality":0.1837637097,"ml-security":0.1041998141}}
{"text":"For full utilization of the precious samples, a global hyper-pixel-wise sample pair queues-based contrastive learning method, which includes the construction of global queues that store hyper-pixel-wise samples and the updating scheme of a momentum encoder, is developed, reliably enhancing the extraction ability of semantic features.","meta":{"url":"http://arxiv.org/abs/2308.01251v1"},"cats":{"new-dataset":0.2769334929,"dev-research":0.2132233147,"prompt-eng":0.3483488106,"data-quality":0.1902233825,"ml-security":0.0775256564}}
{"text":"The proposed HPCL-Net is evaluated on a Loess Plateau old landslide dataset and experiment results show that the model greatly improves the reliablity of old landslide detection compared to the previous old landslide segmentation model, where mIoU metric is increased from 0.620 to 0.651, Landslide IoU metric is increased from 0.334 to 0.394 and F1-score metric is increased from 0.501 to 0.565.","meta":{"url":"http://arxiv.org/abs/2308.01251v1"},"cats":{"new-dataset":0.2258158844,"dev-research":0.1878738511,"prompt-eng":0.3783671373,"data-quality":0.1666141993,"ml-security":0.0910857487}}
{"text":"In this paper, we study the application of spatially coupled LDPC codes with sub-block locality for space division multiplexing.","meta":{"url":"http://arxiv.org/abs/2308.01249v1"},"cats":{"new-dataset":0.0983626118,"dev-research":0.2401869865,"prompt-eng":0.3459404363,"data-quality":0.1204592343,"ml-security":0.0426651483}}
{"text":"We focus on the information exchange between the sub-blocks and compare decoding strategies with respect to the complexity, performance and the information flow.","meta":{"url":"http://arxiv.org/abs/2308.01249v1"},"cats":{"new-dataset":0.0318489107,"dev-research":0.2929557367,"prompt-eng":0.4058954446,"data-quality":0.1620971008,"ml-security":0.104467216}}
{"text":"Multi-Object Tracking, also known as Multi-Target Tracking, is a significant area of computer vision that has many uses in a variety of settings.","meta":{"url":"http://arxiv.org/abs/2308.01248v1"},"cats":{"new-dataset":0.0466691547,"dev-research":0.2881884435,"prompt-eng":0.3758250983,"data-quality":0.1245171411,"ml-security":0.0936698646}}
{"text":"The development of deep learning, which has encouraged researchers to propose more and more work in this direction, has significantly impacted the scientific advancement around the study of tracking as well as many other domains related to computer vision.","meta":{"url":"http://arxiv.org/abs/2308.01248v1"},"cats":{"new-dataset":0.0577378071,"dev-research":0.2668498461,"prompt-eng":0.3217402404,"data-quality":0.1916693919,"ml-security":0.1670517437}}
{"text":"In fact, all of the solutions that are currently state-of-the-art in the literature and in the tracking industry, are built on top of deep learning methodologies that produce exceptionally good results.","meta":{"url":"http://arxiv.org/abs/2308.01248v1"},"cats":{"new-dataset":0.2399873837,"dev-research":0.2095815273,"prompt-eng":0.3244683751,"data-quality":0.1750221818,"ml-security":0.1070197073}}
{"text":"Deep learning is enabled thanks to the ever more powerful technology researchers can use to handle the significant computational resources demanded by these models.","meta":{"url":"http://arxiv.org/abs/2308.01248v1"},"cats":{"new-dataset":0.145492505,"dev-research":0.2084800952,"prompt-eng":0.3398833043,"data-quality":0.1345332422,"ml-security":0.1852985238}}
{"text":"However, when real-time is a main requirement, developing a tracking system without being constrained by expensive hardware support with enormous computational resources is necessary to widen tracking applications in real-world contexts.","meta":{"url":"http://arxiv.org/abs/2308.01248v1"},"cats":{"new-dataset":0.1245117808,"dev-research":0.3447916231,"prompt-eng":0.3809805212,"data-quality":0.1325285501,"ml-security":0.0776567363}}
{"text":"To this end, a compromise is to combine powerful deep strategies with more traditional approaches to favor considerably lower processing solutions at the cost of less accurate tracking results even though suitable for real-time domains.","meta":{"url":"http://arxiv.org/abs/2308.01248v1"},"cats":{"new-dataset":0.0958679163,"dev-research":0.3061565424,"prompt-eng":0.3700602247,"data-quality":0.1829961993,"ml-security":0.1290656525}}
{"text":"Indeed, the present work goes in that direction, proposing a hybrid strategy for real-time multi-target tracking that combines effectively a classical optical flow algorithm with a deep learning architecture, targeted to a human-crowd tracking system exhibiting a desirable trade-off between performance in tracking precision and computational costs.","meta":{"url":"http://arxiv.org/abs/2308.01248v1"},"cats":{"new-dataset":0.2830620273,"dev-research":0.2296854357,"prompt-eng":0.3314731894,"data-quality":0.1218084409,"ml-security":0.1251796116}}
{"text":"The developed architecture was experimented with different settings, and yielded a MOTA of 0.608 out of the compared state-of-the-art 0.549 results, and about half the running time when introducing the optical flow phase, achieving almost the same performance in terms of accuracy.","meta":{"url":"http://arxiv.org/abs/2308.01248v1"},"cats":{"new-dataset":0.111957185,"dev-research":0.1965894782,"prompt-eng":0.3738393373,"data-quality":0.0866134478,"ml-security":0.0180908228}}
{"text":"Digital preservation of Cultural Heritage (CH) sites is crucial to protect them against damage from natural disasters or human activities.","meta":{"url":"http://arxiv.org/abs/2308.01246v1"},"cats":{"new-dataset":0.2238024654,"dev-research":0.283382421,"prompt-eng":0.3624305727,"data-quality":0.1299277867,"ml-security":0.1216561084}}
{"text":"Creating 3D models of CH sites has become a popular method of digital preservation thanks to advancements in computer vision and photogrammetry.","meta":{"url":"http://arxiv.org/abs/2308.01246v1"},"cats":{"new-dataset":0.1441916005,"dev-research":0.1932279903,"prompt-eng":0.3979268364,"data-quality":0.0861456956,"ml-security":0.0287701167}}
{"text":"However, the process is time-consuming, expensive, and typically requires specialized equipment and expertise, posing challenges in resource-limited developing countries.","meta":{"url":"http://arxiv.org/abs/2308.01246v1"},"cats":{"new-dataset":0.0439896171,"dev-research":0.3057893216,"prompt-eng":0.3470127414,"data-quality":0.0771524889,"ml-security":0.0711242146}}
{"text":"Additionally, the lack of an open repository for 3D models hinders research and public engagement with their heritage.","meta":{"url":"http://arxiv.org/abs/2308.01246v1"},"cats":{"new-dataset":0.1277106796,"dev-research":0.2487613547,"prompt-eng":0.299557783,"data-quality":0.1621600443,"ml-security":0.148548502}}
{"text":"To address these issues, we propose Tirtha, a web platform for crowdsourcing images of CH sites and creating their 3D models.","meta":{"url":"http://arxiv.org/abs/2308.01246v1"},"cats":{"new-dataset":0.6418527749,"dev-research":0.2531855435,"prompt-eng":0.3881517357,"data-quality":0.1343150201,"ml-security":0.0543670657}}
{"text":"Tirtha utilizes state-of-the-art Structure from Motion (SfM) and Multi-View Stereo (MVS) techniques.","meta":{"url":"http://arxiv.org/abs/2308.01246v1"},"cats":{"new-dataset":0.1379417376,"dev-research":0.1864812517,"prompt-eng":0.3419197896,"data-quality":0.0540257069,"ml-security":0.0213140236}}
{"text":"It is modular, extensible and cost-effective, allowing for the incorporation of new techniques as photogrammetry advances.","meta":{"url":"http://arxiv.org/abs/2308.01246v1"},"cats":{"new-dataset":0.1139570893,"dev-research":0.2096792697,"prompt-eng":0.4011831927,"data-quality":0.0862049678,"ml-security":0.0260294415}}
{"text":"Tirtha is accessible through a web interface at https://tirtha.niser.ac.in and can be deployed on-premise or in a cloud environment.","meta":{"url":"http://arxiv.org/abs/2308.01246v1"},"cats":{"new-dataset":0.5885281312,"dev-research":0.180832634,"prompt-eng":0.3712807233,"data-quality":0.0775087415,"ml-security":0.0404594322}}
{"text":"In our case studies, we demonstrate the pipeline's effectiveness by creating 3D models of temples in Odisha, India, using crowdsourced images.","meta":{"url":"http://arxiv.org/abs/2308.01246v1"},"cats":{"new-dataset":0.4062945821,"dev-research":0.2458240349,"prompt-eng":0.385343887,"data-quality":0.1124288522,"ml-security":0.051567926}}
{"text":"These models are available for viewing, interaction, and download on the Tirtha website.","meta":{"url":"http://arxiv.org/abs/2308.01246v1"},"cats":{"new-dataset":0.5407325059,"dev-research":0.1524038046,"prompt-eng":0.3657940673,"data-quality":0.035258502,"ml-security":0.0290610716}}
{"text":"Our work aims to provide a dataset of crowdsourced images and 3D reconstructions for research in computer vision, heritage conservation, and related domains.","meta":{"url":"http://arxiv.org/abs/2308.01246v1"},"cats":{"new-dataset":0.8954669892,"dev-research":0.1676232239,"prompt-eng":0.3486447536,"data-quality":0.1456853026,"ml-security":0.0646385309}}
{"text":"Overall, Tirtha is a step towards democratizing digital preservation, primarily in resource-limited developing countries.","meta":{"url":"http://arxiv.org/abs/2308.01246v1"},"cats":{"new-dataset":0.228491266,"dev-research":0.2967923996,"prompt-eng":0.2810923789,"data-quality":0.0886633103,"ml-security":0.090932833}}
{"text":"In this work, we present a computing platform named digital twin brain (DTB) that can simulate spiking neuronal networks of the whole human brain scale and more importantly, a personalized biological brain structure.","meta":{"url":"http://arxiv.org/abs/2308.01241v1"},"cats":{"new-dataset":0.2958602657,"dev-research":0.2454501823,"prompt-eng":0.3940340051,"data-quality":0.0976780265,"ml-security":0.1506144092}}
{"text":"In comparison to most brain simulations with a homogeneous global structure, we highlight that the sparseness, couplingness and heterogeneity in the sMRI, DTI and PET data of the brain has an essential impact on the efficiency of brain simulation, which is proved from the scaling experiments that the DTB of human brain simulation is communication-intensive and memory-access intensive computing systems rather than computation-intensive.","meta":{"url":"http://arxiv.org/abs/2308.01241v1"},"cats":{"new-dataset":0.0957366098,"dev-research":0.2345678386,"prompt-eng":0.3751086956,"data-quality":0.0662038787,"ml-security":0.0938574131}}
{"text":"We utilize a number of optimization techniques to balance and integrate the computation loads and communication traffics from the heterogeneous biological structure to the general GPU-based HPC and achieve leading simulation performance for the whole human brain-scaled spiking neuronal networks.","meta":{"url":"http://arxiv.org/abs/2308.01241v1"},"cats":{"new-dataset":0.1150340306,"dev-research":0.2617211046,"prompt-eng":0.3642677806,"data-quality":0.0707217675,"ml-security":0.1322421507}}
{"text":"On the other hand, the biological structure, equipped with a mesoscopic data assimilation, enables the DTB to investigate brain cognitive function by a reverse-engineering method, which is demonstrated by a digital experiment of visual evaluation on the DTB.","meta":{"url":"http://arxiv.org/abs/2308.01241v1"},"cats":{"new-dataset":0.0356039435,"dev-research":0.3109844415,"prompt-eng":0.4521814938,"data-quality":0.1221458279,"ml-security":0.0975244941}}
{"text":"Furthermore, we believe that the developing DTB will be a promising powerful platform for a large of research orients including brain-inspiredintelligence, rain disease medicine and brain-machine interface.","meta":{"url":"http://arxiv.org/abs/2308.01241v1"},"cats":{"new-dataset":0.1609781226,"dev-research":0.3144512383,"prompt-eng":0.4550584236,"data-quality":0.0922986114,"ml-security":0.1037561892}}
{"text":"In this work, we evaluate 10 open-source instructed LLMs on four representative code comprehension and generation tasks.","meta":{"url":"http://arxiv.org/abs/2308.01240v1"},"cats":{"new-dataset":0.3823709476,"dev-research":0.3999800627,"prompt-eng":0.4413012503,"data-quality":0.1904473582,"ml-security":0.0852265383}}
{"text":"We have the following main findings.","meta":{"url":"http://arxiv.org/abs/2308.01240v1"},"cats":{"new-dataset":0.4468356615,"dev-research":0.166558293,"prompt-eng":0.3488924299,"data-quality":0.1945167008,"ml-security":0.1172098639}}
{"text":"First, for the zero-shot setting, instructed LLMs are very competitive on code comprehension and generation tasks and sometimes even better than small SOTA models specifically fine-tuned on each downstream task.","meta":{"url":"http://arxiv.org/abs/2308.01240v1"},"cats":{"new-dataset":0.1195854491,"dev-research":0.2187269999,"prompt-eng":0.4065013247,"data-quality":0.123228314,"ml-security":0.0835702776}}
{"text":"We also find that larger instructed LLMs are not always better on code-related tasks.","meta":{"url":"http://arxiv.org/abs/2308.01240v1"},"cats":{"new-dataset":0.0096840367,"dev-research":0.3393194302,"prompt-eng":0.4159473155,"data-quality":0.2550639117,"ml-security":0.156044588}}
{"text":"Second, for the few-shot setting, we find that adding demonstration examples substantially helps instructed LLMs perform better on most code comprehension and generation tasks; however, the examples would sometimes induce unstable or even worse performance.","meta":{"url":"http://arxiv.org/abs/2308.01240v1"},"cats":{"new-dataset":0.0897042952,"dev-research":0.4008067539,"prompt-eng":0.440794733,"data-quality":0.2253421717,"ml-security":0.1394690567}}
{"text":"Furthermore, we find widely-used BM25-based shot selection strategy significantly outperforms the basic random selection or fixed selection only on generation problems.","meta":{"url":"http://arxiv.org/abs/2308.01240v1"},"cats":{"new-dataset":0.0663638245,"dev-research":0.1918081713,"prompt-eng":0.3862911554,"data-quality":0.1441919341,"ml-security":0.1131288242}}
{"text":"Third, for the fine-tuning setting, we find that fine-tuning could further improve the model performance on downstream code comprehension and generation tasks compared to the zero-shot/one-shot performance.","meta":{"url":"http://arxiv.org/abs/2308.01240v1"},"cats":{"new-dataset":0.1415413911,"dev-research":0.4634714278,"prompt-eng":0.4152045663,"data-quality":0.2665917564,"ml-security":0.1135174802}}
{"text":"In addition, after being fine-tuned on the same downstream task dataset, instructed LLMs outperform both the small SOTA models and similar-scaled LLMs without instruction tuning.","meta":{"url":"http://arxiv.org/abs/2308.01240v1"},"cats":{"new-dataset":0.1075560969,"dev-research":0.1592426147,"prompt-eng":0.4137247564,"data-quality":0.1443587654,"ml-security":0.0594383022}}
{"text":"Based on our findings, we further present practical implications on model and usage recommendation, performance and cost trade-offs, and future direction.","meta":{"url":"http://arxiv.org/abs/2308.01240v1"},"cats":{"new-dataset":0.0189542686,"dev-research":0.3303704385,"prompt-eng":0.4505632697,"data-quality":0.1140102492,"ml-security":0.0620849405}}
{"text":"Autonomous vehicles (AVs) are more vulnerable to network attacks due to the high connectivity and diverse communication modes between vehicles and external networks.","meta":{"url":"http://arxiv.org/abs/2308.01237v1"},"cats":{"new-dataset":0.0581376187,"dev-research":0.2967053361,"prompt-eng":0.3381335991,"data-quality":0.1838126283,"ml-security":0.715845954}}
{"text":"Deep learning-based Intrusion detection, an effective method for detecting network attacks, can provide functional safety as well as a real-time communication guarantee for vehicles, thereby being widely used for AVs.","meta":{"url":"http://arxiv.org/abs/2308.01237v1"},"cats":{"new-dataset":0.1068093835,"dev-research":0.3420602453,"prompt-eng":0.3139540174,"data-quality":0.2129823912,"ml-security":0.7217959963}}
{"text":"Existing works well for cyber-attacks such as simple-mode but become a higher false alarm with a resource-limited environment required when the attack is concealed within a contextual feature.","meta":{"url":"http://arxiv.org/abs/2308.01237v1"},"cats":{"new-dataset":0.064964237,"dev-research":0.3087866444,"prompt-eng":0.4292186486,"data-quality":0.1972204686,"ml-security":0.698739182}}
{"text":"In this paper, we present a lightweight intrusion detection model based on semantic fusion, named LSF-IDM.","meta":{"url":"http://arxiv.org/abs/2308.01237v1"},"cats":{"new-dataset":0.073427021,"dev-research":0.27076472,"prompt-eng":0.41606116,"data-quality":0.2246517076,"ml-security":0.4990200381}}
{"text":"Our motivation is based on the observation that, when injected the malicious packets to the in-vehicle networks (IVNs), the packet log presents a strict order of context feature because of the periodicity and broadcast nature of the CAN bus.","meta":{"url":"http://arxiv.org/abs/2308.01237v1"},"cats":{"new-dataset":0.0727579457,"dev-research":0.2698538184,"prompt-eng":0.3842783898,"data-quality":0.2018165756,"ml-security":0.4508763186}}
{"text":"Therefore, this model first captures the context as the semantic feature of messages by the BERT language framework.","meta":{"url":"http://arxiv.org/abs/2308.01237v1"},"cats":{"new-dataset":0.1246171738,"dev-research":0.2823905207,"prompt-eng":0.4151031785,"data-quality":0.2451701293,"ml-security":0.1001987285}}
{"text":"Thereafter, the lightweight model (e.g., BiLSTM) learns the fused feature from an input packet's classification and its output distribution in BERT based on knowledge distillation.","meta":{"url":"http://arxiv.org/abs/2308.01237v1"},"cats":{"new-dataset":0.1266623777,"dev-research":0.2441299935,"prompt-eng":0.3763321692,"data-quality":0.1470189744,"ml-security":0.1198020363}}
{"text":"Experiment results demonstrate the effectiveness of our methods in defending against several representative attacks from IVNs.","meta":{"url":"http://arxiv.org/abs/2308.01237v1"},"cats":{"new-dataset":0.0568580022,"dev-research":0.3319947029,"prompt-eng":0.3956868386,"data-quality":0.1847826918,"ml-security":0.8217443328}}
{"text":"We also perform the difference analysis of the proposed method with lightweight models and Bert to attain a deeper understanding of how the model balance detection performance and model complexity.","meta":{"url":"http://arxiv.org/abs/2308.01237v1"},"cats":{"new-dataset":0.0565078718,"dev-research":0.2387079834,"prompt-eng":0.4137937586,"data-quality":0.2388204079,"ml-security":0.158415574}}
{"text":"This paper introduces Grounded Image Text Matching with Mismatched Relation (GITM-MR), a novel visual-linguistic joint task that evaluates the relation understanding capabilities of transformer-based pre-trained models.","meta":{"url":"http://arxiv.org/abs/2308.01236v1"},"cats":{"new-dataset":0.1573815809,"dev-research":0.2081245819,"prompt-eng":0.4080012577,"data-quality":0.2872946916,"ml-security":0.0487287388}}
{"text":"GITM-MR requires a model to first determine if an expression describes an image, then localize referred objects or ground the mismatched parts of the text.","meta":{"url":"http://arxiv.org/abs/2308.01236v1"},"cats":{"new-dataset":0.0795860158,"dev-research":0.2351825457,"prompt-eng":0.4463323467,"data-quality":0.2765652426,"ml-security":0.0406124635}}
{"text":"We provide a benchmark for evaluating pre-trained models on this task, with a focus on the challenging settings of limited data and out-of-distribution sentence lengths.","meta":{"url":"http://arxiv.org/abs/2308.01236v1"},"cats":{"new-dataset":0.5140820086,"dev-research":0.1735918539,"prompt-eng":0.4078665157,"data-quality":0.264314979,"ml-security":0.1065039977}}
{"text":"Our evaluation demonstrates that pre-trained models lack data efficiency and length generalization ability.","meta":{"url":"http://arxiv.org/abs/2308.01236v1"},"cats":{"new-dataset":0.061060844,"dev-research":0.2383175007,"prompt-eng":0.4017319935,"data-quality":0.2864195142,"ml-security":0.2108763219}}
{"text":"To address this, we propose the Relation-sensitive Correspondence Reasoning Network (RCRN), which incorporates relation-aware reasoning via bi-directional message propagation guided by language structure.","meta":{"url":"http://arxiv.org/abs/2308.01236v1"},"cats":{"new-dataset":0.3216700241,"dev-research":0.3326461646,"prompt-eng":0.4154857312,"data-quality":0.2485574657,"ml-security":0.081632346}}
{"text":"RCRN can be interpreted as a modular program and delivers strong performance in both length generalization and data efficiency.","meta":{"url":"http://arxiv.org/abs/2308.01236v1"},"cats":{"new-dataset":0.2242769593,"dev-research":0.3053399857,"prompt-eng":0.3834335149,"data-quality":0.1322396471,"ml-security":0.079194478}}
{"text":"The radio communication division of the International Telecommunication Union (ITU-R) has recently adopted Integrated Sensing and Communication (ISAC) among the key usage scenarios for IMT-2030/6G. ISAC is envisioned to play a vital role in the upcoming wireless generation standards.","meta":{"url":"http://arxiv.org/abs/2308.01227v1"},"cats":{"new-dataset":0.1553482506,"dev-research":0.2422683839,"prompt-eng":0.444857112,"data-quality":0.1293834275,"ml-security":0.0534163834}}
{"text":"In this work, we bring together several paramount and innovative aspects of ISAC technology from a global 6G standardization perspective, including both industrial and academic progress.","meta":{"url":"http://arxiv.org/abs/2308.01227v1"},"cats":{"new-dataset":0.0980650358,"dev-research":0.2460379381,"prompt-eng":0.4108532489,"data-quality":0.0973213411,"ml-security":0.0449948471}}
{"text":"Specifically, this article provides 6G requirements and ISAC-enabled vision, including various aspects of 6G standardization, benefits of ISAC co-existence, and integration challenges.","meta":{"url":"http://arxiv.org/abs/2308.01227v1"},"cats":{"new-dataset":0.083152686,"dev-research":0.2327917757,"prompt-eng":0.4280411678,"data-quality":0.0915870246,"ml-security":0.0372141394}}
{"text":"Moreover, we present key enabling technologies, including intelligent metasurface-aided ISAC, as well as Orthogonal Time Frequency Space (OTFS) waveform design and interference management for ISAC.","meta":{"url":"http://arxiv.org/abs/2308.01227v1"},"cats":{"new-dataset":0.0320507604,"dev-research":0.3224322704,"prompt-eng":0.4125712666,"data-quality":0.0825633125,"ml-security":0.0781704077}}
{"text":"Finally, future aspects are discussed to open various research opportunities and challenges on the ISAC technology towards 6G wireless communications.","meta":{"url":"http://arxiv.org/abs/2308.01227v1"},"cats":{"new-dataset":0.0204089962,"dev-research":0.2418792173,"prompt-eng":0.3565328575,"data-quality":0.0774394827,"ml-security":0.0585131091}}
{"text":"Translate-test is a popular technique to improve the performance of multilingual language models.","meta":{"url":"http://arxiv.org/abs/2308.01223v1"},"cats":{"new-dataset":0.0622324405,"dev-research":0.2951237958,"prompt-eng":0.4560076408,"data-quality":0.2270738393,"ml-security":0.0479011001}}
{"text":"This approach works by translating the input into English using an external machine translation system, and running inference over the translated input.","meta":{"url":"http://arxiv.org/abs/2308.01223v1"},"cats":{"new-dataset":0.1262331886,"dev-research":0.2668223342,"prompt-eng":0.495561557,"data-quality":0.2811524874,"ml-security":0.075024119}}
{"text":"However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by the language model.","meta":{"url":"http://arxiv.org/abs/2308.01223v1"},"cats":{"new-dataset":0.1303632438,"dev-research":0.2821819669,"prompt-eng":0.3944848494,"data-quality":0.2721073514,"ml-security":0.1026772532}}
{"text":"In this work, we introduce a new approach called self-translate, which overcomes the need of an external translation system by leveraging the few-shot translation capabilities of multilingual language models.","meta":{"url":"http://arxiv.org/abs/2308.01223v1"},"cats":{"new-dataset":0.3278195781,"dev-research":0.2272887444,"prompt-eng":0.4047835697,"data-quality":0.2303466645,"ml-security":0.0785636176}}
{"text":"Experiments over 5 tasks show that self-translate consistently outperforms direct inference, demonstrating that language models are unable to leverage their full multilingual potential when prompted in non-English languages.","meta":{"url":"http://arxiv.org/abs/2308.01223v1"},"cats":{"new-dataset":0.0537734916,"dev-research":0.2698822384,"prompt-eng":0.4545290817,"data-quality":0.3208841925,"ml-security":0.1262006295}}
{"text":"Our code is available at https://github.com/juletx/self-translate.","meta":{"url":"http://arxiv.org/abs/2308.01223v1"},"cats":{"new-dataset":0.427648131,"dev-research":0.1605041023,"prompt-eng":0.4703248852,"data-quality":0.1625256698,"ml-security":0.0273320386}}
{"text":"Calibrating deep neural models plays an important role in building reliable, robust AI systems in safety-critical applications.","meta":{"url":"http://arxiv.org/abs/2308.01222v1"},"cats":{"new-dataset":0.1821738746,"dev-research":0.3031323138,"prompt-eng":0.3503575202,"data-quality":0.2487526023,"ml-security":0.4989675187}}
{"text":"Recent work has shown that modern neural networks that possess high predictive capability are poorly calibrated and produce unreliable model predictions.","meta":{"url":"http://arxiv.org/abs/2308.01222v1"},"cats":{"new-dataset":0.0694311144,"dev-research":0.2077331102,"prompt-eng":0.3850023053,"data-quality":0.3863559792,"ml-security":0.3213678373}}
{"text":"Though deep learning models achieve remarkable performance on various benchmarks, the study of model calibration and reliability is relatively underexplored.","meta":{"url":"http://arxiv.org/abs/2308.01222v1"},"cats":{"new-dataset":0.1450277508,"dev-research":0.2244732539,"prompt-eng":0.3405234295,"data-quality":0.3198080363,"ml-security":0.1890278308}}
{"text":"Ideal deep models should have not only high predictive performance but also be well calibrated.","meta":{"url":"http://arxiv.org/abs/2308.01222v1"},"cats":{"new-dataset":0.1036832683,"dev-research":0.2054506155,"prompt-eng":0.3539106731,"data-quality":0.171273629,"ml-security":0.2130823301}}
{"text":"There have been some recent methods proposed to calibrate deep models by using different mechanisms.","meta":{"url":"http://arxiv.org/abs/2308.01222v1"},"cats":{"new-dataset":0.1633702645,"dev-research":0.1878370293,"prompt-eng":0.3981688586,"data-quality":0.1810475909,"ml-security":0.1335574854}}
{"text":"In this survey, we review the state-of-the-art calibration methods and provide an understanding of their principles for performing model calibration.","meta":{"url":"http://arxiv.org/abs/2308.01222v1"},"cats":{"new-dataset":0.1541417541,"dev-research":0.2121003927,"prompt-eng":0.509250953,"data-quality":0.2911760142,"ml-security":0.0629121444}}
{"text":"First, we start with the definition of model calibration and explain the root causes of model miscalibration.","meta":{"url":"http://arxiv.org/abs/2308.01222v1"},"cats":{"new-dataset":0.0708106834,"dev-research":0.3181153963,"prompt-eng":0.3881599599,"data-quality":0.2881162547,"ml-security":0.0958358173}}
{"text":"Then we introduce the key metrics that can measure this aspect.","meta":{"url":"http://arxiv.org/abs/2308.01222v1"},"cats":{"new-dataset":0.0615706774,"dev-research":0.2210474916,"prompt-eng":0.388869302,"data-quality":0.1993288541,"ml-security":0.1081855128}}
{"text":"It is followed by a summary of calibration methods that we roughly classified into four categories: post-hoc calibration, regularization methods, uncertainty estimation, and composition methods.","meta":{"url":"http://arxiv.org/abs/2308.01222v1"},"cats":{"new-dataset":0.2034702374,"dev-research":0.2188936639,"prompt-eng":0.4498196097,"data-quality":0.264219095,"ml-security":0.0511050705}}
{"text":"We also covered some recent advancements in calibrating large models, particularly large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2308.01222v1"},"cats":{"new-dataset":0.3903257499,"dev-research":0.1803432885,"prompt-eng":0.4346551828,"data-quality":0.2515353459,"ml-security":0.1111303749}}
{"text":"Finally, we discuss some open issues, challenges, and potential directions.","meta":{"url":"http://arxiv.org/abs/2308.01222v1"},"cats":{"new-dataset":0.2651361952,"dev-research":0.3341396913,"prompt-eng":0.3246807834,"data-quality":0.1991044145,"ml-security":0.0975841365}}
{"text":"Our Visual Analytics (VA) tool ScrutinAI supports human analysts to investigate interactively model performanceand data sets.","meta":{"url":"http://arxiv.org/abs/2308.01220v1"},"cats":{"new-dataset":0.3593390247,"dev-research":0.4259061072,"prompt-eng":0.3874154147,"data-quality":0.1172137921,"ml-security":0.0714545699}}
{"text":"Model performance depends on labeling quality to a large extent.","meta":{"url":"http://arxiv.org/abs/2308.01220v1"},"cats":{"new-dataset":0.0104291118,"dev-research":0.2063200053,"prompt-eng":0.4028824674,"data-quality":0.4253057902,"ml-security":0.0649637494}}
{"text":"In particular in medical settings, generation of high quality labels requires in depth expert knowledge and is very costly.","meta":{"url":"http://arxiv.org/abs/2308.01220v1"},"cats":{"new-dataset":0.0444246289,"dev-research":0.2899623409,"prompt-eng":0.3635479442,"data-quality":0.3247269182,"ml-security":0.0911055148}}
{"text":"Often, data sets are labeled by collecting opinions of groups of experts.","meta":{"url":"http://arxiv.org/abs/2308.01220v1"},"cats":{"new-dataset":0.2086042699,"dev-research":0.3519463874,"prompt-eng":0.3983063984,"data-quality":0.3219307828,"ml-security":0.1169278994}}
{"text":"We use our VA tool to analyse the influence of label variations between different experts on the model performance.","meta":{"url":"http://arxiv.org/abs/2308.01220v1"},"cats":{"new-dataset":0.0412401542,"dev-research":0.2405218012,"prompt-eng":0.4436510949,"data-quality":0.4093281181,"ml-security":0.0638122486}}
{"text":"ScrutinAI facilitates to perform a root cause analysis that distinguishes weaknesses of deep neural network (DNN) models caused by varying or missing labeling quality from true weaknesses.","meta":{"url":"http://arxiv.org/abs/2308.01220v1"},"cats":{"new-dataset":0.1626965757,"dev-research":0.4401203034,"prompt-eng":0.3681358883,"data-quality":0.4411072083,"ml-security":0.3539231915}}
{"text":"We scrutinize the overall detection of intracranial hemorrhages and the more subtle differentiation between subtypes in a publicly available data set.","meta":{"url":"http://arxiv.org/abs/2308.01220v1"},"cats":{"new-dataset":0.1384389638,"dev-research":0.200741407,"prompt-eng":0.4108483082,"data-quality":0.3121351895,"ml-security":0.1673668727}}
{"text":"Describing and analysing sequences of learner actions is becoming more popular in learning analytics.","meta":{"url":"http://arxiv.org/abs/2308.01218v1"},"cats":{"new-dataset":0.1891564045,"dev-research":0.3992213797,"prompt-eng":0.3852038782,"data-quality":0.1520759068,"ml-security":0.1726649819}}
{"text":"Nevertheless, the authors found a variety of definitions of what a learning sequence is, of which data is used for the analysis, and which methods are implemented, as well as of the purpose and educational interventions designed with them.","meta":{"url":"http://arxiv.org/abs/2308.01218v1"},"cats":{"new-dataset":0.1376567764,"dev-research":0.3177613575,"prompt-eng":0.3726819397,"data-quality":0.1614935968,"ml-security":0.107488475}}
{"text":"In this literature review, the authors aim to generate an overview of these concepts to develop a decision framework for using sequence analysis in educational research.","meta":{"url":"http://arxiv.org/abs/2308.01218v1"},"cats":{"new-dataset":0.1433568873,"dev-research":0.3272909688,"prompt-eng":0.4124711226,"data-quality":0.1644286288,"ml-security":0.0580036045}}
{"text":"After analysing 44 articles, the conclusions enable us to highlight different learning tasks and educational settings where sequences are analysed, identify data mapping models for different types of sequence actions, differentiate methods based on purpose and scope, and identify possible educational interventions based on the outcomes of sequence analysis.","meta":{"url":"http://arxiv.org/abs/2308.01218v1"},"cats":{"new-dataset":0.1401196542,"dev-research":0.3688452523,"prompt-eng":0.3820480117,"data-quality":0.1291610919,"ml-security":0.0782410481}}
{"text":"For text-to-video retrieval (T2VR), which aims to retrieve unlabeled videos by ad-hoc textual queries, CLIP-based methods are dominating.","meta":{"url":"http://arxiv.org/abs/2308.01217v1"},"cats":{"new-dataset":0.2169123651,"dev-research":0.1945415067,"prompt-eng":0.3645092545,"data-quality":0.2512456119,"ml-security":0.0717695434}}
{"text":"Compared to CLIP4Clip which is efficient and compact, the state-of-the-art models tend to compute video-text similarity by fine-grained cross-modal feature interaction and matching, putting their scalability for large-scale T2VR into doubt.","meta":{"url":"http://arxiv.org/abs/2308.01217v1"},"cats":{"new-dataset":0.1271714984,"dev-research":0.2223236739,"prompt-eng":0.3664144429,"data-quality":0.1686303791,"ml-security":0.0574466711}}
{"text":"For efficient T2VR, we propose TeachCLIP with multi-grained teaching to let a CLIP4Clip based student network learn from more advanced yet computationally heavy models such as X-CLIP, TS2-Net and X-Pool .","meta":{"url":"http://arxiv.org/abs/2308.01217v1"},"cats":{"new-dataset":0.3589328914,"dev-research":0.2486433061,"prompt-eng":0.4241940091,"data-quality":0.1501992396,"ml-security":0.1060599424}}
{"text":"To improve the student's learning capability, we add an Attentional frame-Feature Aggregation (AFA) block, which by design adds no extra storage/computation overhead at the retrieval stage.","meta":{"url":"http://arxiv.org/abs/2308.01217v1"},"cats":{"new-dataset":0.1868705325,"dev-research":0.2627153585,"prompt-eng":0.398939251,"data-quality":0.1648468525,"ml-security":0.0953601305}}
{"text":"While attentive weights produced by AFA are commonly used for combining frame-level features, we propose a novel use of the weights to let them imitate frame-text relevance estimated by the teacher network.","meta":{"url":"http://arxiv.org/abs/2308.01217v1"},"cats":{"new-dataset":0.1166826378,"dev-research":0.2072267591,"prompt-eng":0.3986843808,"data-quality":0.3115944451,"ml-security":0.0793765642}}
{"text":"As such, AFA provides a fine-grained learning (teaching) channel for the student (teacher).","meta":{"url":"http://arxiv.org/abs/2308.01217v1"},"cats":{"new-dataset":0.1817181145,"dev-research":0.2588497681,"prompt-eng":0.3744166784,"data-quality":0.1280954574,"ml-security":0.0755687127}}
{"text":"Extensive experiments on multiple public datasets justify the viability of the proposed method.","meta":{"url":"http://arxiv.org/abs/2308.01217v1"},"cats":{"new-dataset":0.2754896395,"dev-research":0.172418391,"prompt-eng":0.3889298592,"data-quality":0.257346661,"ml-security":0.1600042481}}
{"text":"A spanning tree $T$ of graph $G$ is a $\\rho$-approximate universal Steiner tree (UST) for root vertex $r$ if, for any subset of vertices $S$ containing $r$, the cost of the minimal subgraph of $T$ connecting $S$ is within a $\\rho$ factor of the minimum cost tree connecting $S$ in $G$. Busch et al.","meta":{"url":"http://arxiv.org/abs/2308.01199v1"},"cats":{"new-dataset":0.0313346167,"dev-research":0.2143172212,"prompt-eng":0.3137450144,"data-quality":0.1240926674,"ml-security":0.0472550318}}
{"text":"(FOCS 2012) showed that every graph admits $2^{O(\\sqrt{\\log n})}$-approximate USTs by showing that USTs are equivalent to strong sparse partition hierarchies (up to poly-logs).","meta":{"url":"http://arxiv.org/abs/2308.01199v1"},"cats":{"new-dataset":0.221840632,"dev-research":0.1784210974,"prompt-eng":0.3215286475,"data-quality":0.1381534897,"ml-security":0.1247405467}}
{"text":"Further, they posed poly-logarithmic USTs and strong sparse partition hierarchies as open questions.   ","meta":{"url":"http://arxiv.org/abs/2308.01199v1"},"cats":{"new-dataset":0.3561660072,"dev-research":0.1439530018,"prompt-eng":0.3636138472,"data-quality":0.1019138952,"ml-security":0.1301226323}}
{"text":"We settle these open questions by giving polynomial-time algorithms for computing both $O(\\log ^ 7 n)$-approximate USTs and poly-logarithmic strong sparse partition hierarchies.","meta":{"url":"http://arxiv.org/abs/2308.01199v1"},"cats":{"new-dataset":0.2517189724,"dev-research":0.1385706494,"prompt-eng":0.329361659,"data-quality":0.1212039498,"ml-security":0.1554744216}}
{"text":"For graphs with constant doubling dimension or constant pathwidth we improve this to $O(\\log n)$-approximate USTs and $O(1)$ strong sparse partition hierarchies.","meta":{"url":"http://arxiv.org/abs/2308.01199v1"},"cats":{"new-dataset":0.3140092262,"dev-research":0.1798660186,"prompt-eng":0.3069444951,"data-quality":0.1559355732,"ml-security":0.1389692161}}
{"text":"Our doubling dimension result is tight up to second order terms.","meta":{"url":"http://arxiv.org/abs/2308.01199v1"},"cats":{"new-dataset":0.0983835578,"dev-research":0.1416151434,"prompt-eng":0.3060046133,"data-quality":0.1736482742,"ml-security":0.1451909149}}
{"text":"We reduce the existence of these objects to the previously studied cluster aggregation problem and what we call dangling nets.","meta":{"url":"http://arxiv.org/abs/2308.01199v1"},"cats":{"new-dataset":0.1198694075,"dev-research":0.2083800172,"prompt-eng":0.3507584751,"data-quality":0.3558385829,"ml-security":0.2177983854}}
{"text":"Learning a policy with great generalization to unseen environments remains challenging but critical in visual reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2308.01194v1"},"cats":{"new-dataset":0.0652558895,"dev-research":0.2037533776,"prompt-eng":0.3477413447,"data-quality":0.1714546031,"ml-security":0.2538018882}}
{"text":"Despite the success of augmentation combination in the supervised learning generalization, naively applying it to visual RL algorithms may damage the training efficiency, suffering from serve performance degradation.","meta":{"url":"http://arxiv.org/abs/2308.01194v1"},"cats":{"new-dataset":0.0460652403,"dev-research":0.2595468495,"prompt-eng":0.3474885814,"data-quality":0.2622407792,"ml-security":0.1825536743}}
{"text":"In this paper, we first conduct qualitative analysis and illuminate the main causes: (i) high-variance gradient magnitudes and (ii) gradient conflicts existed in various augmentation methods.","meta":{"url":"http://arxiv.org/abs/2308.01194v1"},"cats":{"new-dataset":0.0291699218,"dev-research":0.269897581,"prompt-eng":0.3986918368,"data-quality":0.2770971868,"ml-security":0.1349399575}}
{"text":"To alleviate these issues, we propose a general policy gradient optimization framework, named Conflict-aware Gradient Agreement Augmentation (CG2A), and better integrate augmentation combination into visual RL algorithms to address the generalization bias.","meta":{"url":"http://arxiv.org/abs/2308.01194v1"},"cats":{"new-dataset":0.2709299777,"dev-research":0.3580617304,"prompt-eng":0.3694518735,"data-quality":0.2880456065,"ml-security":0.2061548022}}
{"text":"In particular, CG2A develops a Gradient Agreement Solver to adaptively balance the varying gradient magnitudes, and introduces a Soft Gradient Surgery strategy to alleviate the gradient conflicts.","meta":{"url":"http://arxiv.org/abs/2308.01194v1"},"cats":{"new-dataset":0.0469597716,"dev-research":0.2952384899,"prompt-eng":0.3650420736,"data-quality":0.2032423228,"ml-security":0.107958401}}
{"text":"Extensive experiments demonstrate that CG2A significantly improves the generalization performance and sample efficiency of visual RL algorithms.","meta":{"url":"http://arxiv.org/abs/2308.01194v1"},"cats":{"new-dataset":0.1087554796,"dev-research":0.2726233681,"prompt-eng":0.3618345937,"data-quality":0.1482284199,"ml-security":0.043980747}}
{"text":"DNN accelerators have been widely deployed in many scenarios to speed up the inference process and reduce the energy consumption.","meta":{"url":"http://arxiv.org/abs/2308.01193v1"},"cats":{"new-dataset":0.1071034479,"dev-research":0.2614639143,"prompt-eng":0.3864253606,"data-quality":0.1116594651,"ml-security":0.117710958}}
{"text":"One big concern about the usage of the accelerators is the confidentiality of the deployed models: model inference execution on the accelerators could leak side-channel information, which enables an adversary to preciously recover the model details.","meta":{"url":"http://arxiv.org/abs/2308.01193v1"},"cats":{"new-dataset":0.0176921954,"dev-research":0.2462510048,"prompt-eng":0.3590329623,"data-quality":0.1120860018,"ml-security":0.4146561316}}
{"text":"Such model extraction attacks can not only compromise the intellectual property of DNN models, but also facilitate some adversarial attacks.   ","meta":{"url":"http://arxiv.org/abs/2308.01193v1"},"cats":{"new-dataset":0.0901105246,"dev-research":0.2730304526,"prompt-eng":0.3186016072,"data-quality":0.3049044689,"ml-security":0.7404855308}}
{"text":"Although previous works have demonstrated a number of side-channel techniques to extract models from DNN accelerators, they are not practical for two reasons.","meta":{"url":"http://arxiv.org/abs/2308.01193v1"},"cats":{"new-dataset":0.0846764009,"dev-research":0.2303231908,"prompt-eng":0.379355997,"data-quality":0.1294212724,"ml-security":0.1317262219}}
{"text":"(1) They only target simplified accelerator implementations, which have limited practicality in the real world.","meta":{"url":"http://arxiv.org/abs/2308.01193v1"},"cats":{"new-dataset":0.0098101931,"dev-research":0.2666255858,"prompt-eng":0.301438557,"data-quality":0.0970846779,"ml-security":0.1830683384}}
{"text":"(2) They require heavy human analysis and domain knowledge.","meta":{"url":"http://arxiv.org/abs/2308.01193v1"},"cats":{"new-dataset":0.0731889917,"dev-research":0.30090906,"prompt-eng":0.3470746538,"data-quality":0.1812479206,"ml-security":0.0957920131}}
{"text":"To overcome these limitations, this paper presents Mercury, the first automated remote side-channel attack against the off-the-shelf Nvidia DNN accelerator.","meta":{"url":"http://arxiv.org/abs/2308.01193v1"},"cats":{"new-dataset":0.2217376184,"dev-research":0.2915820236,"prompt-eng":0.3926017791,"data-quality":0.1871703502,"ml-security":0.4963497965}}
{"text":"The key insight of Mercury is to model the side-channel extraction process as a sequence-to-sequence problem.","meta":{"url":"http://arxiv.org/abs/2308.01193v1"},"cats":{"new-dataset":0.0518300694,"dev-research":0.2195804723,"prompt-eng":0.3988726415,"data-quality":0.1938395561,"ml-security":0.0778455716}}
{"text":"The adversary can leverage a time-to-digital converter (TDC) to remotely collect the power trace of the target model's inference.","meta":{"url":"http://arxiv.org/abs/2308.01193v1"},"cats":{"new-dataset":0.0487235683,"dev-research":0.2495040734,"prompt-eng":0.4764744911,"data-quality":0.1496896963,"ml-security":0.4945761991}}
{"text":"Then he uses a learning model to automatically recover the architecture details of the victim model from the power trace without any prior knowledge.","meta":{"url":"http://arxiv.org/abs/2308.01193v1"},"cats":{"new-dataset":0.0302781296,"dev-research":0.2837859456,"prompt-eng":0.4219424916,"data-quality":0.1698208944,"ml-security":0.2501651137}}
{"text":"The adversary can further use the attention mechanism to localize the leakage points that contribute most to the attack.","meta":{"url":"http://arxiv.org/abs/2308.01193v1"},"cats":{"new-dataset":0.0260541975,"dev-research":0.2706211775,"prompt-eng":0.4033664559,"data-quality":0.2472925399,"ml-security":0.7183764837}}
{"text":"Evaluation results indicate that Mercury can keep the error rate of model extraction below 1%.","meta":{"url":"http://arxiv.org/abs/2308.01193v1"},"cats":{"new-dataset":0.0096337394,"dev-research":0.2149684825,"prompt-eng":0.43697132,"data-quality":0.3525901519,"ml-security":0.0801736808}}
{"text":"Code cloning, the duplication of code fragments, is common in software development.","meta":{"url":"http://arxiv.org/abs/2308.01191v1"},"cats":{"new-dataset":0.0621129255,"dev-research":0.5415725722,"prompt-eng":0.3775652859,"data-quality":0.1833158139,"ml-security":0.1463907688}}
{"text":"While some reuse aids productivity, excessive cloning hurts maintainability and introduces bugs.","meta":{"url":"http://arxiv.org/abs/2308.01191v1"},"cats":{"new-dataset":0.0191324135,"dev-research":0.4757072046,"prompt-eng":0.3745350146,"data-quality":0.240729463,"ml-security":0.1923682186}}
{"text":"Hence, automatic code clone detection is vital.","meta":{"url":"http://arxiv.org/abs/2308.01191v1"},"cats":{"new-dataset":0.0332717339,"dev-research":0.4998035567,"prompt-eng":0.4509727893,"data-quality":0.398544529,"ml-security":0.195525251}}
{"text":"Meanwhile, large language models (LLMs) possess diverse code-related knowledge, making them versatile for various software engineering challenges.","meta":{"url":"http://arxiv.org/abs/2308.01191v1"},"cats":{"new-dataset":0.0843357513,"dev-research":0.3133178059,"prompt-eng":0.3896025475,"data-quality":0.1475351519,"ml-security":0.1274674591}}
{"text":"However, LLMs' performance in code clone detection is unclear and needs more study for accurate assessment.","meta":{"url":"http://arxiv.org/abs/2308.01191v1"},"cats":{"new-dataset":0.0248037116,"dev-research":0.3446634635,"prompt-eng":0.453815881,"data-quality":0.419258255,"ml-security":0.1274352111}}
{"text":"In this paper, we provide the first comprehensive evaluation of LLMs for clone detection, covering different clone types, languages, and prompts.","meta":{"url":"http://arxiv.org/abs/2308.01191v1"},"cats":{"new-dataset":0.0971741656,"dev-research":0.2126196052,"prompt-eng":0.5161829225,"data-quality":0.3161594375,"ml-security":0.1777936167}}
{"text":"We find advanced LLMs excel in detecting complex semantic clones, surpassing existing methods.","meta":{"url":"http://arxiv.org/abs/2308.01191v1"},"cats":{"new-dataset":0.2644763263,"dev-research":0.3138104112,"prompt-eng":0.4372433945,"data-quality":0.3539097369,"ml-security":0.1473792073}}
{"text":"Adding intermediate reasoning steps via chain-of-thought prompts noticeably enhances performance.","meta":{"url":"http://arxiv.org/abs/2308.01191v1"},"cats":{"new-dataset":0.0230653535,"dev-research":0.4964112243,"prompt-eng":0.535309745,"data-quality":0.1214579675,"ml-security":0.0733689074}}
{"text":"Additionally, representing code as vector embeddings, especially with text encoders, effectively aids clone detection.","meta":{"url":"http://arxiv.org/abs/2308.01191v1"},"cats":{"new-dataset":0.0942959777,"dev-research":0.4255286689,"prompt-eng":0.3966575187,"data-quality":0.2865264315,"ml-security":0.2452089496}}
{"text":"Lastly, the ability of LLMs to detect code clones differs among various programming languages.","meta":{"url":"http://arxiv.org/abs/2308.01191v1"},"cats":{"new-dataset":0.0289689451,"dev-research":0.3563779163,"prompt-eng":0.4503487596,"data-quality":0.211374011,"ml-security":0.1547382845}}
{"text":"Our study suggests that LLMs have potential for clone detection due to their language capabilities, offering insights for developing robust LLM-based methods to enhance software engineering.","meta":{"url":"http://arxiv.org/abs/2308.01191v1"},"cats":{"new-dataset":0.0974663047,"dev-research":0.3790447798,"prompt-eng":0.4831017931,"data-quality":0.3049775614,"ml-security":0.2837988516}}
{"text":"This paper seeks to address the dense labeling problems where a significant fraction of the dataset can be pruned without sacrificing much accuracy.","meta":{"url":"http://arxiv.org/abs/2308.01189v1"},"cats":{"new-dataset":0.3403814897,"dev-research":0.2056568368,"prompt-eng":0.3347532636,"data-quality":0.6205514732,"ml-security":0.1544160272}}
{"text":"We observe that, on standard medical image segmentation benchmarks, the loss gradient norm-based metrics of individual training examples applied in image classification fail to identify the important samples.","meta":{"url":"http://arxiv.org/abs/2308.01189v1"},"cats":{"new-dataset":0.1670520307,"dev-research":0.1625198596,"prompt-eng":0.3515943398,"data-quality":0.2869759565,"ml-security":0.1468000741}}
{"text":"To address this issue, we propose a data pruning method by taking into consideration the training dynamics on target regions using Dynamic Average Dice (DAD) score.","meta":{"url":"http://arxiv.org/abs/2308.01189v1"},"cats":{"new-dataset":0.2203867003,"dev-research":0.2180849936,"prompt-eng":0.3649197791,"data-quality":0.2113476171,"ml-security":0.1071430632}}
{"text":"To the best of our knowledge, we are among the first to address the data importance in dense labeling tasks in the field of medical image analysis, making the following contributions: (1) investigating the underlying causes with rigorous empirical analysis, and (2) determining effective data pruning approach in dense labeling problems.","meta":{"url":"http://arxiv.org/abs/2308.01189v1"},"cats":{"new-dataset":0.1481296458,"dev-research":0.1969357381,"prompt-eng":0.342704463,"data-quality":0.4667410571,"ml-security":0.1142807087}}
{"text":"Our solution can be used as a strong yet simple baseline to select important examples for medical image segmentation with combined data sources.","meta":{"url":"http://arxiv.org/abs/2308.01189v1"},"cats":{"new-dataset":0.3744144377,"dev-research":0.1974002346,"prompt-eng":0.3841492172,"data-quality":0.198610957,"ml-security":0.0859650658}}
{"text":"The loudness war, an ongoing phenomenon in the music industry characterized by the increasing final loudness of music while reducing its dynamic range, has been a controversial topic for decades.","meta":{"url":"http://arxiv.org/abs/2308.01187v1"},"cats":{"new-dataset":0.0419211129,"dev-research":0.2799283588,"prompt-eng":0.3121939809,"data-quality":0.3055776423,"ml-security":0.2030722024}}
{"text":"Music mastering engineers have used limiters to heavily compress and make music louder, which can induce ear fatigue and hearing loss in listeners.","meta":{"url":"http://arxiv.org/abs/2308.01187v1"},"cats":{"new-dataset":0.0089782949,"dev-research":0.3230091384,"prompt-eng":0.355789843,"data-quality":0.1956144772,"ml-security":0.1223436107}}
{"text":"In this paper, we introduce music de-limiter networks that estimate uncompressed music from heavily compressed signals.","meta":{"url":"http://arxiv.org/abs/2308.01187v1"},"cats":{"new-dataset":0.0984067455,"dev-research":0.1930981326,"prompt-eng":0.2748145276,"data-quality":0.2243711602,"ml-security":0.2129453882}}
{"text":"Inspired by the principle of a limiter, which performs sample-wise gain reduction of a given signal, we propose the framework of sample-wise gain inversion (SGI).","meta":{"url":"http://arxiv.org/abs/2308.01187v1"},"cats":{"new-dataset":0.0218181884,"dev-research":0.1764646891,"prompt-eng":0.3677089633,"data-quality":0.1774742089,"ml-security":0.2296755468}}
{"text":"We also present the musdb-XL-train dataset, consisting of 300k segments created by applying a commercial limiter plug-in for training real-world friendly de-limiter networks.","meta":{"url":"http://arxiv.org/abs/2308.01187v1"},"cats":{"new-dataset":0.8393700127,"dev-research":0.2047276618,"prompt-eng":0.3151259082,"data-quality":0.1677741708,"ml-security":0.1907180766}}
{"text":"Our proposed de-limiter network achieves excellent performance with a scale-invariant source-to-distortion ratio (SI-SDR) of 23.8 dB in reconstructing musdb-HQ from musdb- XL data, a limiter-applied version of musdb-HQ.","meta":{"url":"http://arxiv.org/abs/2308.01187v1"},"cats":{"new-dataset":0.2191983386,"dev-research":0.2073816493,"prompt-eng":0.3380251248,"data-quality":0.1947036747,"ml-security":0.1311526131}}
{"text":"The training data, codes, and model weights are available in our repository (https://github.com/jeonchangbin49/De-limiter).","meta":{"url":"http://arxiv.org/abs/2308.01187v1"},"cats":{"new-dataset":0.5889023641,"dev-research":0.1271477122,"prompt-eng":0.3910884636,"data-quality":0.0989404097,"ml-security":0.0835540573}}
{"text":"The learning with noisy labels has been addressed with both discriminative and generative models.","meta":{"url":"http://arxiv.org/abs/2308.01184v1"},"cats":{"new-dataset":0.1356214924,"dev-research":0.1835943645,"prompt-eng":0.4005471466,"data-quality":0.6754448218,"ml-security":0.1473531153}}
{"text":"Although discriminative models have dominated the field due to their simpler modeling and more efficient computational training processes, generative models offer a more effective means of disentangling clean and noisy labels and improving the estimation of the label transition matrix.","meta":{"url":"http://arxiv.org/abs/2308.01184v1"},"cats":{"new-dataset":0.1496997886,"dev-research":0.1903355728,"prompt-eng":0.4047158381,"data-quality":0.3944666082,"ml-security":0.1081288928}}
{"text":"However, generative approaches maximize the joint likelihood of noisy labels and data using a complex formulation that only indirectly optimizes the model of interest associating data and clean labels.","meta":{"url":"http://arxiv.org/abs/2308.01184v1"},"cats":{"new-dataset":0.0646228668,"dev-research":0.262598604,"prompt-eng":0.417330896,"data-quality":0.5617991286,"ml-security":0.133724049}}
{"text":"Additionally, these approaches rely on generative models that are challenging to train and tend to use uninformative clean label priors.","meta":{"url":"http://arxiv.org/abs/2308.01184v1"},"cats":{"new-dataset":0.0557050664,"dev-research":0.2358996203,"prompt-eng":0.4029982073,"data-quality":0.4538078426,"ml-security":0.1522201203}}
{"text":"In this paper, we propose a new generative noisy-label learning approach that addresses these three issues.","meta":{"url":"http://arxiv.org/abs/2308.01184v1"},"cats":{"new-dataset":0.1597306831,"dev-research":0.2062957543,"prompt-eng":0.40621987,"data-quality":0.7580917969,"ml-security":0.1181634063}}
{"text":"First, we propose a new model optimisation that directly associates data and clean labels.","meta":{"url":"http://arxiv.org/abs/2308.01184v1"},"cats":{"new-dataset":0.0803722088,"dev-research":0.232264916,"prompt-eng":0.4468326572,"data-quality":0.5042193926,"ml-security":0.1013967392}}
{"text":"Second, the generative model is implicitly estimated using a discriminative model, eliminating the inefficient training of a generative model.","meta":{"url":"http://arxiv.org/abs/2308.01184v1"},"cats":{"new-dataset":0.0364446935,"dev-research":0.2295100063,"prompt-eng":0.394281168,"data-quality":0.223996572,"ml-security":0.0998493191}}
{"text":"Third, we propose a new informative label prior inspired by partial label learning as supervision signal for noisy label learning.","meta":{"url":"http://arxiv.org/abs/2308.01184v1"},"cats":{"new-dataset":0.1016299058,"dev-research":0.2040771313,"prompt-eng":0.4173869186,"data-quality":0.7069496998,"ml-security":0.1252580747}}
{"text":"Extensive experiments on several noisy-label benchmarks demonstrate that our generative model provides state-of-the-art results while maintaining a similar computational complexity as discriminative models.","meta":{"url":"http://arxiv.org/abs/2308.01184v1"},"cats":{"new-dataset":0.2512218227,"dev-research":0.2023888826,"prompt-eng":0.4125352928,"data-quality":0.6518219395,"ml-security":0.0943811389}}
{"text":"Driving scene understanding is to obtain comprehensive scene information through the sensor data and provide a basis for downstream tasks, which is indispensable for the safety of self-driving vehicles.","meta":{"url":"http://arxiv.org/abs/2308.01180v1"},"cats":{"new-dataset":0.2642430145,"dev-research":0.2828390491,"prompt-eng":0.3987429898,"data-quality":0.1845433929,"ml-security":0.097479975}}
{"text":"Specific perception tasks, such as object detection and scene graph generation, are commonly used.","meta":{"url":"http://arxiv.org/abs/2308.01180v1"},"cats":{"new-dataset":0.0744553725,"dev-research":0.2889497068,"prompt-eng":0.4048942653,"data-quality":0.1579755282,"ml-security":0.0556915412}}
{"text":"However, the results of these tasks are only equivalent to the characterization of sampling from high-dimensional scene features, which are not sufficient to represent the scenario.","meta":{"url":"http://arxiv.org/abs/2308.01180v1"},"cats":{"new-dataset":0.108142705,"dev-research":0.1430453402,"prompt-eng":0.365638084,"data-quality":0.232230497,"ml-security":0.1072263761}}
{"text":"In addition, the goal of perception tasks is inconsistent with human driving that just focuses on what may affect the ego-trajectory.","meta":{"url":"http://arxiv.org/abs/2308.01180v1"},"cats":{"new-dataset":0.0049641514,"dev-research":0.2944357107,"prompt-eng":0.3814948466,"data-quality":0.2587540401,"ml-security":0.0908180741}}
{"text":"Therefore, we propose an end-to-end Interpretable Implicit Driving Scene Understanding (II-DSU) model to extract implicit high-dimensional scene features as scene understanding results guided by a planning module and to validate the plausibility of scene understanding using auxiliary perception tasks for visualization.","meta":{"url":"http://arxiv.org/abs/2308.01180v1"},"cats":{"new-dataset":0.2364374528,"dev-research":0.3239426252,"prompt-eng":0.4010934552,"data-quality":0.1700055525,"ml-security":0.1233401496}}
{"text":"Experimental results on CARLA benchmarks show that our approach achieves the new state-of-the-art and is able to obtain scene features that embody richer scene information relevant to driving, enabling superior performance of the downstream planning.","meta":{"url":"http://arxiv.org/abs/2308.01180v1"},"cats":{"new-dataset":0.2537641895,"dev-research":0.2725980511,"prompt-eng":0.3864940221,"data-quality":0.1138683848,"ml-security":0.0544705346}}
{"text":"We explore a new class of brain encoding model by adding memory-related information as input.","meta":{"url":"http://arxiv.org/abs/2308.01175v1"},"cats":{"new-dataset":0.0483164224,"dev-research":0.2100986867,"prompt-eng":0.4249474486,"data-quality":0.1490790193,"ml-security":0.1723490253}}
{"text":"Memory is an essential brain mechanism that works alongside visual stimuli.","meta":{"url":"http://arxiv.org/abs/2308.01175v1"},"cats":{"new-dataset":0.0070289359,"dev-research":0.2966735263,"prompt-eng":0.3758291701,"data-quality":0.1015726156,"ml-security":0.0813048115}}
{"text":"During a vision-memory cognitive task, we found the non-visual brain is largely predictable using previously seen images.","meta":{"url":"http://arxiv.org/abs/2308.01175v1"},"cats":{"new-dataset":0.0241219932,"dev-research":0.2519640893,"prompt-eng":0.4043965451,"data-quality":0.2032532016,"ml-security":0.1348202838}}
{"text":"Our Memory Encoding Model (Mem) won the Algonauts 2023 visual brain competition even without model ensemble (single model score 66.8, ensemble score 70.8).","meta":{"url":"http://arxiv.org/abs/2308.01175v1"},"cats":{"new-dataset":0.0959206202,"dev-research":0.1924090802,"prompt-eng":0.3940569076,"data-quality":0.1704873429,"ml-security":0.1273485072}}
{"text":"Our ensemble model without memory input (61.4) can also stand a 3rd place.","meta":{"url":"http://arxiv.org/abs/2308.01175v1"},"cats":{"new-dataset":0.1269534344,"dev-research":0.2038627777,"prompt-eng":0.386058561,"data-quality":0.2464622138,"ml-security":0.1074027708}}
{"text":"Furthermore, we observe periodic delayed brain response correlated to 6th-7th prior image, and hippocampus also showed correlated activity timed with this periodicity.","meta":{"url":"http://arxiv.org/abs/2308.01175v1"},"cats":{"new-dataset":0.0607278015,"dev-research":0.1929916202,"prompt-eng":0.4225345815,"data-quality":0.1169763387,"ml-security":0.0793883611}}
{"text":"We conjuncture that the periodic replay could be related to memory mechanism to enhance the working memory.","meta":{"url":"http://arxiv.org/abs/2308.01175v1"},"cats":{"new-dataset":0.0128877485,"dev-research":0.358837126,"prompt-eng":0.4155166656,"data-quality":0.1068367134,"ml-security":0.0823840745}}
{"text":"We study Ramsey like theorems for infinite trees and similar combinatorial tools.","meta":{"url":"http://arxiv.org/abs/2308.01174v1"},"cats":{"new-dataset":0.2875863443,"dev-research":0.1839468619,"prompt-eng":0.3032860348,"data-quality":0.151445097,"ml-security":0.1113324864}}
{"text":"As an application we consider the expansion problem for tree algebras.","meta":{"url":"http://arxiv.org/abs/2308.01174v1"},"cats":{"new-dataset":0.1004234312,"dev-research":0.1770225651,"prompt-eng":0.3752991699,"data-quality":0.2468497842,"ml-security":0.1328023849}}
{"text":"Off-policy learning enables a reinforcement learning (RL) agent to reason counterfactually about policies that are not executed and is one of the most important ideas in RL.","meta":{"url":"http://arxiv.org/abs/2308.01170v1"},"cats":{"new-dataset":0.1083699996,"dev-research":0.3006810108,"prompt-eng":0.3788445804,"data-quality":0.1639217149,"ml-security":0.2123595257}}
{"text":"It, however, can lead to instability when combined with function approximation and bootstrapping, two arguably indispensable ingredients for large-scale reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2308.01170v1"},"cats":{"new-dataset":0.0159218126,"dev-research":0.263290736,"prompt-eng":0.3070893135,"data-quality":0.1614565984,"ml-security":0.2865618632}}
{"text":"This is the notorious deadly triad.","meta":{"url":"http://arxiv.org/abs/2308.01170v1"},"cats":{"new-dataset":0.1544237419,"dev-research":0.2225572304,"prompt-eng":0.3615180755,"data-quality":0.1429407838,"ml-security":0.2668378766}}
{"text":"Gradient Temporal Difference (GTD) is one powerful tool to solve the deadly triad.","meta":{"url":"http://arxiv.org/abs/2308.01170v1"},"cats":{"new-dataset":0.0971046076,"dev-research":0.2573978289,"prompt-eng":0.3749489502,"data-quality":0.1110081183,"ml-security":0.1251227873}}
{"text":"Its success results from solving a doubling sampling issue indirectly with weight duplication or Fenchel duality.","meta":{"url":"http://arxiv.org/abs/2308.01170v1"},"cats":{"new-dataset":0.0787104365,"dev-research":0.1232751977,"prompt-eng":0.3661822761,"data-quality":0.2075862369,"ml-security":0.114588702}}
{"text":"In this paper, we instead propose a direct method to solve the double sampling issue by simply using two samples in a Markovian data stream with an increasing gap.","meta":{"url":"http://arxiv.org/abs/2308.01170v1"},"cats":{"new-dataset":0.1958569623,"dev-research":0.1446258186,"prompt-eng":0.3970320239,"data-quality":0.26516006,"ml-security":0.082161959}}
{"text":"The resulting algorithm is as computationally efficient as GTD but gets rid of GTD's extra weights.","meta":{"url":"http://arxiv.org/abs/2308.01170v1"},"cats":{"new-dataset":0.0164495898,"dev-research":0.1967719959,"prompt-eng":0.365176558,"data-quality":0.1190515675,"ml-security":0.0860096591}}
{"text":"The only price we pay is a logarithmically increasing memory as time progresses.","meta":{"url":"http://arxiv.org/abs/2308.01170v1"},"cats":{"new-dataset":0.0543108816,"dev-research":0.2314013415,"prompt-eng":0.3240242733,"data-quality":0.1001740403,"ml-security":0.1625463632}}
{"text":"We provide both asymptotic and finite sample analysis, where the convergence rate is on-par with the canonical on-policy temporal difference learning.","meta":{"url":"http://arxiv.org/abs/2308.01170v1"},"cats":{"new-dataset":0.1389969537,"dev-research":0.155164738,"prompt-eng":0.3331481011,"data-quality":0.1315288811,"ml-security":0.1320842833}}
{"text":"Key to our analysis is a novel refined discretization of limiting ODEs.","meta":{"url":"http://arxiv.org/abs/2308.01170v1"},"cats":{"new-dataset":0.0690038582,"dev-research":0.1793507513,"prompt-eng":0.3114234985,"data-quality":0.0618033243,"ml-security":0.1511104051}}
{"text":"Termination is a central property in sequential programming models: a term is terminating if all its reduction sequences are finite.","meta":{"url":"http://arxiv.org/abs/2308.01165v1"},"cats":{"new-dataset":0.0420257854,"dev-research":0.3219814004,"prompt-eng":0.3604039145,"data-quality":0.1545198964,"ml-security":0.1309647499}}
{"text":"Termination is also important in concurrency in general, and for message-passing programs in particular.","meta":{"url":"http://arxiv.org/abs/2308.01165v1"},"cats":{"new-dataset":0.011848704,"dev-research":0.4547616955,"prompt-eng":0.3814750089,"data-quality":0.1689004097,"ml-security":0.1560580455}}
{"text":"A variety of type systems that enforce termination by typing have been developed.","meta":{"url":"http://arxiv.org/abs/2308.01165v1"},"cats":{"new-dataset":0.0303666123,"dev-research":0.3875397212,"prompt-eng":0.4828343744,"data-quality":0.2198736937,"ml-security":0.1787374221}}
{"text":"In this paper, we rigorously compare several type systems for $\\pi$-calculus processes from the unifying perspective of termination.","meta":{"url":"http://arxiv.org/abs/2308.01165v1"},"cats":{"new-dataset":0.0271762634,"dev-research":0.28945471,"prompt-eng":0.3828509829,"data-quality":0.1097660175,"ml-security":0.1514066912}}
{"text":"Adopting session types as reference framework, we consider two different type systems: one follows Deng and Sangiorgi's weight-based approach; the other is Caires and Pfenning's Curry-Howard correspondence between linear logic and session types.","meta":{"url":"http://arxiv.org/abs/2308.01165v1"},"cats":{"new-dataset":0.0916522193,"dev-research":0.2919149945,"prompt-eng":0.4312430159,"data-quality":0.121315852,"ml-security":0.0822657633}}
{"text":"Our technical results precisely connect these very different type systems, and shed light on the classes of client/server interactions they admit as correct.","meta":{"url":"http://arxiv.org/abs/2308.01165v1"},"cats":{"new-dataset":0.0639256535,"dev-research":0.2761405972,"prompt-eng":0.4467392301,"data-quality":0.1410834845,"ml-security":0.129732084}}
{"text":"Robot teleoperation gains great success in various situations, including chemical pollution rescue, disaster relief, and long-distance manipulation.","meta":{"url":"http://arxiv.org/abs/2308.01164v1"},"cats":{"new-dataset":0.0808046377,"dev-research":0.2488932663,"prompt-eng":0.3847949818,"data-quality":0.0508240328,"ml-security":0.059560918}}
{"text":"In this article, we propose a virtual reality (VR) based robot teleoperation system to achieve more efficient and natural interaction with humans in different scenes.","meta":{"url":"http://arxiv.org/abs/2308.01164v1"},"cats":{"new-dataset":0.1692489954,"dev-research":0.2356262497,"prompt-eng":0.4012821777,"data-quality":0.0615390948,"ml-security":0.0423077628}}
{"text":"A user-friendly VR interface is designed to help users interact with a desktop scene using their hands efficiently and intuitively.","meta":{"url":"http://arxiv.org/abs/2308.01164v1"},"cats":{"new-dataset":0.1003805396,"dev-research":0.3643978469,"prompt-eng":0.399299269,"data-quality":0.0848920263,"ml-security":0.0701416275}}
{"text":"To improve user experience and reduce workload, we simulate the process in the physics engine to help build a preview of the scene after manipulation in the virtual scene before execution.","meta":{"url":"http://arxiv.org/abs/2308.01164v1"},"cats":{"new-dataset":0.1836617431,"dev-research":0.3003564789,"prompt-eng":0.4435393472,"data-quality":0.0758370079,"ml-security":0.0572102537}}
{"text":"We conduct experiments with different users and compare our system with a direct control method across several teleoperation tasks.","meta":{"url":"http://arxiv.org/abs/2308.01164v1"},"cats":{"new-dataset":0.1527968904,"dev-research":0.2737549973,"prompt-eng":0.5169513158,"data-quality":0.0696065711,"ml-security":0.0398310396}}
{"text":"The user study demonstrates that the proposed system enables users to perform operations more instinctively with a lighter mental workload.","meta":{"url":"http://arxiv.org/abs/2308.01164v1"},"cats":{"new-dataset":0.0120153337,"dev-research":0.5084438303,"prompt-eng":0.4954019525,"data-quality":0.0972894344,"ml-security":0.118160417}}
{"text":"Users can perform pick-and-place and object-stacking tasks in a considerably short time, even for beginners.","meta":{"url":"http://arxiv.org/abs/2308.01164v1"},"cats":{"new-dataset":0.059716566,"dev-research":0.4156792064,"prompt-eng":0.4611642467,"data-quality":0.1146950959,"ml-security":0.0921013301}}
{"text":"Our code is available at https://github.com/lingxiaomeng/VR_Teleoperation_Gen3.","meta":{"url":"http://arxiv.org/abs/2308.01164v1"},"cats":{"new-dataset":0.3928878714,"dev-research":0.185897285,"prompt-eng":0.4700810538,"data-quality":0.0633338713,"ml-security":0.0248014451}}
{"text":"Due to the opacity of machine learning technology, there is a need for explainability and fairness in the decision support systems used in public or private organizations.","meta":{"url":"http://arxiv.org/abs/2308.01163v1"},"cats":{"new-dataset":0.0221258068,"dev-research":0.3617871373,"prompt-eng":0.3378869925,"data-quality":0.1781532239,"ml-security":0.3765051497}}
{"text":"Although the criteria for appropriate explanations and fair decisions change depending on the values of those who are affected by the decisions, there is a lack of discussion framework to consider the appropriate outputs for each stakeholder.","meta":{"url":"http://arxiv.org/abs/2308.01163v1"},"cats":{"new-dataset":0.0648443692,"dev-research":0.420600247,"prompt-eng":0.3515533534,"data-quality":0.2679674997,"ml-security":0.0988973695}}
{"text":"In this paper, we propose a discussion framework that we call \"stakeholder-in-the-loop fair decisions.\"","meta":{"url":"http://arxiv.org/abs/2308.01163v1"},"cats":{"new-dataset":0.167328851,"dev-research":0.4283173343,"prompt-eng":0.3839582291,"data-quality":0.2018649055,"ml-security":0.1494591409}}
{"text":"This is proposed to consider the requirements for appropriate explanations and fair decisions.","meta":{"url":"http://arxiv.org/abs/2308.01163v1"},"cats":{"new-dataset":0.0123701958,"dev-research":0.3777752681,"prompt-eng":0.443859356,"data-quality":0.1595944889,"ml-security":0.1249404894}}
{"text":"We identified four stakeholders that need to be considered to design accountable decision support systems and discussed how to consider the appropriate outputs for each stakeholder by referring to our works.","meta":{"url":"http://arxiv.org/abs/2308.01163v1"},"cats":{"new-dataset":0.2308866966,"dev-research":0.4518829009,"prompt-eng":0.4391231919,"data-quality":0.1876109992,"ml-security":0.073734636}}
{"text":"By clarifying the characteristics of specific stakeholders in each application domain and integrating the stakeholders' values into outputs that all stakeholders agree upon, decision support systems can be designed as systems that ensure accountable decision makings.","meta":{"url":"http://arxiv.org/abs/2308.01163v1"},"cats":{"new-dataset":0.0439985302,"dev-research":0.4569851316,"prompt-eng":0.4615392877,"data-quality":0.2097382267,"ml-security":0.118909658}}
{"text":"We present a novel method for a multi-party, zero-trust validator infrastructure deployment arrangement via smart contracts to secure Proof-of-Stake (PoS) blockchains.","meta":{"url":"http://arxiv.org/abs/2308.01158v1"},"cats":{"new-dataset":0.1529703377,"dev-research":0.2491875639,"prompt-eng":0.4082153007,"data-quality":0.2326344014,"ml-security":0.2896013287}}
{"text":"The proposed arrangement architecture employs a combination of non-fungible tokens (NFTs), a treasury contract, and validator smart contract wallets to facilitate trustless participation in staking mechanisms.","meta":{"url":"http://arxiv.org/abs/2308.01158v1"},"cats":{"new-dataset":0.0897817009,"dev-research":0.244466237,"prompt-eng":0.3946084014,"data-quality":0.0999707508,"ml-security":0.0923752717}}
{"text":"The NFT minting process allows depositors to exchange their capital for an NFT representing their stake in a validator, while the treasury contract manages the registry of NFT holders and handles rewards distribution.","meta":{"url":"http://arxiv.org/abs/2308.01158v1"},"cats":{"new-dataset":0.0071917912,"dev-research":0.2461144789,"prompt-eng":0.3674961511,"data-quality":0.1240349033,"ml-security":0.06997093}}
{"text":"Validator smart contract wallets are employed to create a trustless connection between the validator operator and the treasury, enabling autonomous staking and unstaking processes based on predefined conditions.","meta":{"url":"http://arxiv.org/abs/2308.01158v1"},"cats":{"new-dataset":0.0407293998,"dev-research":0.252010163,"prompt-eng":0.4140928217,"data-quality":0.1394539393,"ml-security":0.1664002405}}
{"text":"In addition, the proposed system incorporates protection mechanisms for depositors, such as triggered exits in case of non-payment of rewards and a penalty payout from the validator operator.","meta":{"url":"http://arxiv.org/abs/2308.01158v1"},"cats":{"new-dataset":0.0548214972,"dev-research":0.2313344793,"prompt-eng":0.4307280857,"data-quality":0.180963381,"ml-security":0.3406983558}}
{"text":"The arrangement benefits from the extensibility and interoperability of web3 technologies, with potential applications in the broader digital ecosystem.","meta":{"url":"http://arxiv.org/abs/2308.01158v1"},"cats":{"new-dataset":0.0221624813,"dev-research":0.3603115149,"prompt-eng":0.372116114,"data-quality":0.0679825882,"ml-security":0.0543507219}}
{"text":"This zero-trust staking mechanism aims to serve users who desire increased privacy, trust, and flexibility in managing their digital wealth, while promoting greater decentralization and transparency in the PoS ecosystem.","meta":{"url":"http://arxiv.org/abs/2308.01158v1"},"cats":{"new-dataset":0.0263846641,"dev-research":0.2198739907,"prompt-eng":0.4008699825,"data-quality":0.1450062992,"ml-security":0.3689636407}}
{"text":"A better understanding of the emergent computation and problem-solving capabilities of recent large language models is of paramount importance to further improve them and broaden their applicability.","meta":{"url":"http://arxiv.org/abs/2308.01154v1"},"cats":{"new-dataset":0.1259343656,"dev-research":0.287080078,"prompt-eng":0.3379374474,"data-quality":0.1503226071,"ml-security":0.1001922191}}
{"text":"This work investigates how a language model, trained to predict the next token, can perform arithmetic computations generalizing beyond training data.","meta":{"url":"http://arxiv.org/abs/2308.01154v1"},"cats":{"new-dataset":0.116093929,"dev-research":0.2515620433,"prompt-eng":0.4056064197,"data-quality":0.2382320325,"ml-security":0.2487113203}}
{"text":"Binary addition and multiplication constitute a good testbed for this purpose, since they require a very small vocabulary and exhibit relevant input/output discontinuities making smooth input interpolation ineffective for novel data.","meta":{"url":"http://arxiv.org/abs/2308.01154v1"},"cats":{"new-dataset":0.1857788924,"dev-research":0.2654811189,"prompt-eng":0.4091862942,"data-quality":0.1807869834,"ml-security":0.1168073838}}
{"text":"We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing.","meta":{"url":"http://arxiv.org/abs/2308.01154v1"},"cats":{"new-dataset":0.1662919699,"dev-research":0.2380751124,"prompt-eng":0.4015327258,"data-quality":0.2302335933,"ml-security":0.1056872141}}
{"text":"Our findings support the hypotheses that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input token representation is mapped to an appropriate internal representation.","meta":{"url":"http://arxiv.org/abs/2308.01154v1"},"cats":{"new-dataset":0.1376647791,"dev-research":0.2708502727,"prompt-eng":0.4214018714,"data-quality":0.3532185843,"ml-security":0.1891352289}}
{"text":"The Skolem Problem asks to determine whether a given integer linear recurrence sequence has a zero term.","meta":{"url":"http://arxiv.org/abs/2308.01152v1"},"cats":{"new-dataset":0.1484144376,"dev-research":0.1474068424,"prompt-eng":0.3379131358,"data-quality":0.1508920536,"ml-security":0.1233400152}}
{"text":"This problem arises across a wide range of topics in computer science, including loop termination, (weighted) automata theory, and the analysis of linear dynamical systems, amongst many others.","meta":{"url":"http://arxiv.org/abs/2308.01152v1"},"cats":{"new-dataset":0.1265042957,"dev-research":0.25269214,"prompt-eng":0.4158993808,"data-quality":0.1665086107,"ml-security":0.1683447365}}
{"text":"Decidability of the Skolem Problem is notoriously open.","meta":{"url":"http://arxiv.org/abs/2308.01152v1"},"cats":{"new-dataset":0.0840270395,"dev-research":0.2029637881,"prompt-eng":0.3908591237,"data-quality":0.2292692189,"ml-security":0.1906989386}}
{"text":"The state of the art is a decision procedure for recurrences of order at most 4: an advance achieved some 40 years ago based on Baker's theorem on linear forms in logarithms of algebraic numbers.   ","meta":{"url":"http://arxiv.org/abs/2308.01152v1"},"cats":{"new-dataset":0.1805547168,"dev-research":0.2040322998,"prompt-eng":0.3683959097,"data-quality":0.0915054635,"ml-security":0.1013817611}}
{"text":"Recently, a new approach to the Skolem Problem was initiated via the notion of a Universal Skolem Set: a set $\\mathbf{S}$ of positive integers such that it is decidable whether a given non-degenerate linear recurrence sequence has a zero in $\\mathbf{S}$. Clearly, proving decidability of the Skolem Problem is equivalent to showing that $\\mathbb{N}$ is a Universal Skolem Set.","meta":{"url":"http://arxiv.org/abs/2308.01152v1"},"cats":{"new-dataset":0.2128311034,"dev-research":0.1908379119,"prompt-eng":0.3592871618,"data-quality":0.1821476705,"ml-security":0.175423015}}
{"text":"The main contribution of the present paper is to exhibit a Universal Skolem Set of positive density that moreover has density one subject to the Bateman-Horn conjecture in number theory.","meta":{"url":"http://arxiv.org/abs/2308.01152v1"},"cats":{"new-dataset":0.1994225788,"dev-research":0.1316392917,"prompt-eng":0.3555812977,"data-quality":0.1600568602,"ml-security":0.0961106524}}
{"text":"The latter is a central unifying hypothesis concerning the frequency of prime numbers among the values of systems of polynomials, and provides a far-reaching generalisation of many classical results and conjectures on the distribution of primes.","meta":{"url":"http://arxiv.org/abs/2308.01152v1"},"cats":{"new-dataset":0.081578262,"dev-research":0.1688690281,"prompt-eng":0.3698563569,"data-quality":0.1349668227,"ml-security":0.210094246}}
{"text":"The recently rising markup-to-image generation poses greater challenges as compared to natural image generation, due to its low tolerance for errors as well as the complex sequence and context correlations between markup and rendered image.","meta":{"url":"http://arxiv.org/abs/2308.01147v1"},"cats":{"new-dataset":0.229119164,"dev-research":0.3097044225,"prompt-eng":0.4160497,"data-quality":0.2464720747,"ml-security":0.06564708}}
{"text":"This paper proposes a novel model named \"Contrast-augmented Diffusion Model with Fine-grained Sequence Alignment\" (FSA-CDM), which introduces contrastive positive/negative samples into the diffusion model to boost performance for markup-to-image generation.","meta":{"url":"http://arxiv.org/abs/2308.01147v1"},"cats":{"new-dataset":0.1343914267,"dev-research":0.231169445,"prompt-eng":0.4026336634,"data-quality":0.2016667658,"ml-security":0.0492254051}}
{"text":"Technically, we design a fine-grained cross-modal alignment module to well explore the sequence similarity between the two modalities for learning robust feature representations.","meta":{"url":"http://arxiv.org/abs/2308.01147v1"},"cats":{"new-dataset":0.3452345562,"dev-research":0.2388966952,"prompt-eng":0.3715171999,"data-quality":0.2343615152,"ml-security":0.086706212}}
{"text":"To improve the generalization ability, we propose a contrast-augmented diffusion model to explicitly explore positive and negative samples by maximizing a novel contrastive variational objective, which is mathematically inferred to provide a tighter bound for the model's optimization.","meta":{"url":"http://arxiv.org/abs/2308.01147v1"},"cats":{"new-dataset":0.0314787511,"dev-research":0.1795453685,"prompt-eng":0.356416015,"data-quality":0.1470520868,"ml-security":0.1265226629}}
{"text":"Moreover, the context-aware cross attention module is developed to capture the contextual information within markup language during the denoising process, yielding better noise prediction results.","meta":{"url":"http://arxiv.org/abs/2308.01147v1"},"cats":{"new-dataset":0.1286677855,"dev-research":0.3120729624,"prompt-eng":0.4064881264,"data-quality":0.3537750148,"ml-security":0.1050112786}}
{"text":"Extensive experiments are conducted on four benchmark datasets from different domains, and the experimental results demonstrate the effectiveness of the proposed components in FSA-CDM, significantly exceeding state-of-the-art performance by about 2%-12% DTW improvements.","meta":{"url":"http://arxiv.org/abs/2308.01147v1"},"cats":{"new-dataset":0.1131786056,"dev-research":0.1863911632,"prompt-eng":0.4672622455,"data-quality":0.1805570612,"ml-security":0.0397889272}}
{"text":"The code will be released at https://github.com/zgj77/FSACDM.","meta":{"url":"http://arxiv.org/abs/2308.01147v1"},"cats":{"new-dataset":0.370151647,"dev-research":0.1573069027,"prompt-eng":0.4719086739,"data-quality":0.1445198291,"ml-security":0.0439571518}}
{"text":"Change detection (CD) by comparing two bi-temporal images is a crucial task in remote sensing.","meta":{"url":"http://arxiv.org/abs/2308.01146v1"},"cats":{"new-dataset":0.0761581746,"dev-research":0.2371584322,"prompt-eng":0.445091415,"data-quality":0.2321202841,"ml-security":0.0519580962}}
{"text":"With the advantages of requiring no cumbersome labeled change information, unsupervised CD has attracted extensive attention in the community.","meta":{"url":"http://arxiv.org/abs/2308.01146v1"},"cats":{"new-dataset":0.1967056308,"dev-research":0.3017357724,"prompt-eng":0.4562469963,"data-quality":0.2514869789,"ml-security":0.0663959692}}
{"text":"However, existing unsupervised CD approaches rarely consider the seasonal and style differences incurred by the illumination and atmospheric conditions in multi-temporal images.","meta":{"url":"http://arxiv.org/abs/2308.01146v1"},"cats":{"new-dataset":0.1135604048,"dev-research":0.1871051775,"prompt-eng":0.3971654458,"data-quality":0.1229004503,"ml-security":0.0297717535}}
{"text":"To this end, we propose a change detection with domain shift setting for remote sensing images.","meta":{"url":"http://arxiv.org/abs/2308.01146v1"},"cats":{"new-dataset":0.1018740729,"dev-research":0.2336559159,"prompt-eng":0.4495841448,"data-quality":0.3095717936,"ml-security":0.1110764278}}
{"text":"Furthermore, we present a novel unsupervised CD method using a light-weight transformer, called UCDFormer.","meta":{"url":"http://arxiv.org/abs/2308.01146v1"},"cats":{"new-dataset":0.0510769477,"dev-research":0.1982151842,"prompt-eng":0.4753555671,"data-quality":0.1402351825,"ml-security":0.0410730823}}
{"text":"Specifically, a transformer-driven image translation composed of a light-weight transformer and a domain-specific affinity weight is first proposed to mitigate domain shift between two images with real-time efficiency.","meta":{"url":"http://arxiv.org/abs/2308.01146v1"},"cats":{"new-dataset":0.021795481,"dev-research":0.2130201585,"prompt-eng":0.4294864338,"data-quality":0.111174198,"ml-security":0.0553213555}}
{"text":"After image translation, we can generate the difference map between the translated before-event image and the original after-event image.","meta":{"url":"http://arxiv.org/abs/2308.01146v1"},"cats":{"new-dataset":0.2239668817,"dev-research":0.2326324994,"prompt-eng":0.4504412556,"data-quality":0.1461073499,"ml-security":0.0378484773}}
{"text":"Then, a novel reliable pixel extraction module is proposed to select significantly changed/unchanged pixel positions by fusing the pseudo change maps of fuzzy c-means clustering and adaptive threshold.","meta":{"url":"http://arxiv.org/abs/2308.01146v1"},"cats":{"new-dataset":0.1000437061,"dev-research":0.244083955,"prompt-eng":0.4506016555,"data-quality":0.2727834718,"ml-security":0.0636454016}}
{"text":"Finally, a binary change map is obtained based on these selected pixel pairs and a binary classifier.","meta":{"url":"http://arxiv.org/abs/2308.01146v1"},"cats":{"new-dataset":0.2683267566,"dev-research":0.1993642868,"prompt-eng":0.4721647368,"data-quality":0.1824239116,"ml-security":0.0678525419}}
{"text":"Experimental results on different unsupervised CD tasks with seasonal and style changes demonstrate the effectiveness of the proposed UCDFormer.","meta":{"url":"http://arxiv.org/abs/2308.01146v1"},"cats":{"new-dataset":0.0518765866,"dev-research":0.2347367041,"prompt-eng":0.5322161008,"data-quality":0.1972321769,"ml-security":0.0317541203}}
{"text":"For example, compared with several other related methods, UCDFormer improves performance on the Kappa coefficient by more than 12\\%.","meta":{"url":"http://arxiv.org/abs/2308.01146v1"},"cats":{"new-dataset":0.0225390807,"dev-research":0.2237052048,"prompt-eng":0.4504699368,"data-quality":0.1882518609,"ml-security":0.0614451653}}
{"text":"In addition, UCDFormer achieves excellent performance for earthquake-induced landslide detection when considering large-scale applications.","meta":{"url":"http://arxiv.org/abs/2308.01146v1"},"cats":{"new-dataset":0.0755348555,"dev-research":0.2584310403,"prompt-eng":0.4334198896,"data-quality":0.1307086749,"ml-security":0.1269336568}}
{"text":"The code is available at \\url{https://github.com/zhu-xlab/UCDFormer}","meta":{"url":"http://arxiv.org/abs/2308.01146v1"},"cats":{"new-dataset":0.2611560561,"dev-research":0.151695381,"prompt-eng":0.4509715171,"data-quality":0.1394593084,"ml-security":0.0439582957}}
{"text":"Generating visually grounded image captions with specific linguistic styles using unpaired stylistic corpora is a challenging task, especially since we expect stylized captions with a wide variety of stylistic patterns.","meta":{"url":"http://arxiv.org/abs/2308.01143v1"},"cats":{"new-dataset":0.4019479485,"dev-research":0.2472768346,"prompt-eng":0.3922319929,"data-quality":0.3288018987,"ml-security":0.0957930981}}
{"text":"In this paper, we propose a novel framework to generate Accurate and Diverse Stylized Captions (ADS-Cap).","meta":{"url":"http://arxiv.org/abs/2308.01143v1"},"cats":{"new-dataset":0.2062815259,"dev-research":0.2770141085,"prompt-eng":0.3839278237,"data-quality":0.3111914471,"ml-security":0.095802258}}
{"text":"Our ADS-Cap first uses a contrastive learning module to align the image and text features, which unifies paired factual and unpaired stylistic corpora during the training process.","meta":{"url":"http://arxiv.org/abs/2308.01143v1"},"cats":{"new-dataset":0.1770823019,"dev-research":0.3067841903,"prompt-eng":0.3730647063,"data-quality":0.3219237567,"ml-security":0.0854402673}}
{"text":"A conditional variational auto-encoder is then used to automatically memorize diverse stylistic patterns in latent space and enhance diversity through sampling.","meta":{"url":"http://arxiv.org/abs/2308.01143v1"},"cats":{"new-dataset":0.0599587503,"dev-research":0.2467181113,"prompt-eng":0.4055887712,"data-quality":0.2315343978,"ml-security":0.0717667535}}
{"text":"We also design a simple but effective recheck module to boost style accuracy by filtering style-specific captions.","meta":{"url":"http://arxiv.org/abs/2308.01143v1"},"cats":{"new-dataset":0.0983568281,"dev-research":0.278408372,"prompt-eng":0.4337212009,"data-quality":0.2986324268,"ml-security":0.0673237701}}
{"text":"Experimental results on two widely used stylized image captioning datasets show that regarding consistency with the image, style accuracy and diversity, ADS-Cap achieves outstanding performances compared to various baselines.","meta":{"url":"http://arxiv.org/abs/2308.01143v1"},"cats":{"new-dataset":0.1842996756,"dev-research":0.2156790367,"prompt-eng":0.3772470663,"data-quality":0.3311573318,"ml-security":0.0840275845}}
{"text":"We finally conduct extensive analyses to understand the effectiveness of our method.","meta":{"url":"http://arxiv.org/abs/2308.01143v1"},"cats":{"new-dataset":0.040291046,"dev-research":0.3204782235,"prompt-eng":0.3860510014,"data-quality":0.1837416576,"ml-security":0.0743643252}}
{"text":"Our code is available at https://github.com/njucckevin/ADS-Cap.","meta":{"url":"http://arxiv.org/abs/2308.01143v1"},"cats":{"new-dataset":0.2375450494,"dev-research":0.1553945205,"prompt-eng":0.4318107944,"data-quality":0.1334638342,"ml-security":0.0598259213}}
{"text":"Despite the increasing interest in quantum computing, the aspect of development to achieve cost-effective and reliable quantum software applications has been slow.","meta":{"url":"http://arxiv.org/abs/2308.01141v1"},"cats":{"new-dataset":0.0271426314,"dev-research":0.2564194364,"prompt-eng":0.3451129919,"data-quality":0.0648063592,"ml-security":0.0621115692}}
{"text":"One barrier is the software engineering of quantum programs, which can be approached from two directions.","meta":{"url":"http://arxiv.org/abs/2308.01141v1"},"cats":{"new-dataset":0.0157128942,"dev-research":0.3248320912,"prompt-eng":0.3490696744,"data-quality":0.0553691801,"ml-security":0.1524585878}}
{"text":"On the one hand, many software engineering practices, debugging in particular, are bound to classical computing.","meta":{"url":"http://arxiv.org/abs/2308.01141v1"},"cats":{"new-dataset":0.0594281982,"dev-research":0.6528249197,"prompt-eng":0.3717687493,"data-quality":0.1479579369,"ml-security":0.166085805}}
{"text":"On the other hand, quantum programming is closely associated with the phenomena of quantum physics, and consequently, the way we express programs resembles the early days of programming.","meta":{"url":"http://arxiv.org/abs/2308.01141v1"},"cats":{"new-dataset":0.025839668,"dev-research":0.3526563265,"prompt-eng":0.3595341004,"data-quality":0.0951793236,"ml-security":0.105451701}}
{"text":"Moreover, much of the software engineering research today focuses on agile development, where computing cycles are cheap and new software can be rapidly deployed and tested, whereas in the quantum context, executions may consume lots of energy, and test runs may require lots of work to interpret.","meta":{"url":"http://arxiv.org/abs/2308.01141v1"},"cats":{"new-dataset":0.0452757424,"dev-research":0.5307472619,"prompt-eng":0.3665976026,"data-quality":0.0714554889,"ml-security":0.0859789795}}
{"text":"In this paper, we aim at bridging this gap by starting with the quantum computing workflow and by mapping existing software engineering research to this workflow.","meta":{"url":"http://arxiv.org/abs/2308.01141v1"},"cats":{"new-dataset":0.0629966817,"dev-research":0.2500063349,"prompt-eng":0.394979081,"data-quality":0.0724220793,"ml-security":0.0762381136}}
{"text":"Based on the mapping, we then identify directions for software engineering research for quantum computing.","meta":{"url":"http://arxiv.org/abs/2308.01141v1"},"cats":{"new-dataset":0.0243426489,"dev-research":0.3476732956,"prompt-eng":0.3962624355,"data-quality":0.0777534918,"ml-security":0.0911252406}}
{"text":"In contemporary self-supervised contrastive algorithms like SimCLR, MoCo, etc., the task of balancing attraction between two semantically similar samples and repulsion between two samples from different classes is primarily affected by the presence of hard negative samples.","meta":{"url":"http://arxiv.org/abs/2308.01140v1"},"cats":{"new-dataset":0.0484910003,"dev-research":0.1771241224,"prompt-eng":0.377517126,"data-quality":0.3354436928,"ml-security":0.1681645957}}
{"text":"While the InfoNCE loss has been shown to impose penalties based on hardness, the temperature hyper-parameter is the key to regulating the penalties and the trade-off between uniformity and tolerance.","meta":{"url":"http://arxiv.org/abs/2308.01140v1"},"cats":{"new-dataset":0.031997093,"dev-research":0.2519878494,"prompt-eng":0.4067805461,"data-quality":0.2854172767,"ml-security":0.2145543259}}
{"text":"In this work, we focus our attention to improve the performance of InfoNCE loss in SSL by studying the effect of temperature hyper-parameter values.","meta":{"url":"http://arxiv.org/abs/2308.01140v1"},"cats":{"new-dataset":0.1065536295,"dev-research":0.2170721955,"prompt-eng":0.4319121033,"data-quality":0.2278155467,"ml-security":0.2087873888}}
{"text":"We propose a cosine similarity-dependent temperature scaling function to effectively optimize the distribution of the samples in the feature space.","meta":{"url":"http://arxiv.org/abs/2308.01140v1"},"cats":{"new-dataset":0.1441987066,"dev-research":0.2054002077,"prompt-eng":0.3846967978,"data-quality":0.1538684245,"ml-security":0.0760699891}}
{"text":"We further analyze the uniformity and tolerance metrics to investigate the optimal regions in the cosine similarity space for better optimization.","meta":{"url":"http://arxiv.org/abs/2308.01140v1"},"cats":{"new-dataset":0.0438617001,"dev-research":0.245169162,"prompt-eng":0.3762147441,"data-quality":0.2002967872,"ml-security":0.0846469587}}
{"text":"Additionally, we offer a comprehensive examination of the behavior of local and global structures in the feature space throughout the pre-training phase, as the temperature varies.","meta":{"url":"http://arxiv.org/abs/2308.01140v1"},"cats":{"new-dataset":0.2681169726,"dev-research":0.2360103292,"prompt-eng":0.4450649118,"data-quality":0.1452835759,"ml-security":0.1128727487}}
{"text":"Experimental evidence shows that the proposed framework outperforms or is at par with the contrastive loss-based SSL algorithms.","meta":{"url":"http://arxiv.org/abs/2308.01140v1"},"cats":{"new-dataset":0.0436307525,"dev-research":0.1948602162,"prompt-eng":0.3680820693,"data-quality":0.2292792481,"ml-security":0.1680464463}}
{"text":"We believe our work (DySTreSS) on temperature scaling in SSL provides a foundation for future research in contrastive learning.","meta":{"url":"http://arxiv.org/abs/2308.01140v1"},"cats":{"new-dataset":0.1347612659,"dev-research":0.2294311002,"prompt-eng":0.3888789463,"data-quality":0.1364787081,"ml-security":0.1367418333}}
{"text":"This paper proposes a locally differentially private federated learning algorithm for strongly convex but possibly nonsmooth problems that protects the gradients of each worker against an honest but curious server.","meta":{"url":"http://arxiv.org/abs/2308.01139v1"},"cats":{"new-dataset":0.0717453089,"dev-research":0.1789734877,"prompt-eng":0.2968622679,"data-quality":0.1586939788,"ml-security":0.6353210646}}
{"text":"The proposed algorithm adds artificial noise to the shared information to ensure privacy and dynamically allocates the time-varying noise variance to minimize an upper bound of the optimization error subject to a predefined privacy budget constraint.","meta":{"url":"http://arxiv.org/abs/2308.01139v1"},"cats":{"new-dataset":0.0576389016,"dev-research":0.2574324606,"prompt-eng":0.4080337579,"data-quality":0.2048958485,"ml-security":0.4163332201}}
{"text":"This allows for an arbitrarily large but finite number of iterations to achieve both privacy protection and utility up to a neighborhood of the optimal solution, removing the need for tuning the number of iterations.","meta":{"url":"http://arxiv.org/abs/2308.01139v1"},"cats":{"new-dataset":0.042124036,"dev-research":0.3237297155,"prompt-eng":0.3674195274,"data-quality":0.1089602352,"ml-security":0.6074317732}}
{"text":"Numerical results show the superiority of the proposed algorithm over state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2308.01139v1"},"cats":{"new-dataset":0.06640471,"dev-research":0.1697315786,"prompt-eng":0.3987346773,"data-quality":0.1603998189,"ml-security":0.0323352276}}
{"text":"Spectrum analysis systems in online water quality testing are designed to detect types and concentrations of pollutants and enable regulatory agencies to respond promptly to pollution incidents.","meta":{"url":"http://arxiv.org/abs/2308.01138v1"},"cats":{"new-dataset":0.0712860146,"dev-research":0.2827390104,"prompt-eng":0.3898443898,"data-quality":0.2213051927,"ml-security":0.1204257078}}
{"text":"However, spectral data-based testing devices suffer from complex noise patterns when deployed in non-laboratory environments.","meta":{"url":"http://arxiv.org/abs/2308.01138v1"},"cats":{"new-dataset":0.099702271,"dev-research":0.3973544152,"prompt-eng":0.4586084683,"data-quality":0.3096725089,"ml-security":0.146748901}}
{"text":"To make the analysis model applicable to more environments, we propose a noise patterns transferring model, which takes the spectrum of standard water samples in different environments as cases and learns the differences in their noise patterns, thus enabling noise patterns to transfer to unknown samples.","meta":{"url":"http://arxiv.org/abs/2308.01138v1"},"cats":{"new-dataset":0.3069653879,"dev-research":0.2599502603,"prompt-eng":0.3972169033,"data-quality":0.235489718,"ml-security":0.1571441718}}
{"text":"Unfortunately, the inevitable sample-level baseline noise makes the model unable to obtain the paired data that only differ in dataset-level environmental noise.","meta":{"url":"http://arxiv.org/abs/2308.01138v1"},"cats":{"new-dataset":0.2105915666,"dev-research":0.1810053591,"prompt-eng":0.3160499561,"data-quality":0.3660249046,"ml-security":0.1741550662}}
{"text":"To address the problem, we generate a sample-to-sample case-base to exclude the interference of sample-level noise on dataset-level noise learning, enhancing the system's learning performance.","meta":{"url":"http://arxiv.org/abs/2308.01138v1"},"cats":{"new-dataset":0.2764751423,"dev-research":0.2601478243,"prompt-eng":0.3987756036,"data-quality":0.5051603046,"ml-security":0.3118858516}}
{"text":"Experiments on spectral data with different background noises demonstrate the good noise-transferring ability of the proposed method against baseline systems ranging from wavelet denoising, deep neural networks, and generative models.","meta":{"url":"http://arxiv.org/abs/2308.01138v1"},"cats":{"new-dataset":0.1083159249,"dev-research":0.2313800264,"prompt-eng":0.3587900872,"data-quality":0.3263740627,"ml-security":0.1548675594}}
{"text":"From this research, we posit that our method can enhance the performance of DL models by generating high-quality cases.","meta":{"url":"http://arxiv.org/abs/2308.01138v1"},"cats":{"new-dataset":0.1454336924,"dev-research":0.2543410545,"prompt-eng":0.4506721571,"data-quality":0.1190742729,"ml-security":0.0875735672}}
{"text":"The source code is made publicly available online at https://github.com/Magnomic/CNST.","meta":{"url":"http://arxiv.org/abs/2308.01138v1"},"cats":{"new-dataset":0.3292397902,"dev-research":0.1589208717,"prompt-eng":0.4409302431,"data-quality":0.1079946277,"ml-security":0.0372657496}}
{"text":"This paper introduces a novel approach to leverage the knowledge of existing expert models for training new Convolutional Neural Networks, on domains where task-specific data are limited or unavailable.","meta":{"url":"http://arxiv.org/abs/2308.01136v1"},"cats":{"new-dataset":0.2308496989,"dev-research":0.2030425433,"prompt-eng":0.3583332611,"data-quality":0.1574811148,"ml-security":0.1637489981}}
{"text":"The presented scheme is applied in offline handwritten signature verification (OffSV) which, akin to other biometric applications, suffers from inherent data limitations due to regulatory restrictions.","meta":{"url":"http://arxiv.org/abs/2308.01136v1"},"cats":{"new-dataset":0.1421986136,"dev-research":0.1973003102,"prompt-eng":0.4573281334,"data-quality":0.173785019,"ml-security":0.1258305726}}
{"text":"The proposed Student-Teacher (S-T) configuration utilizes feature-based knowledge distillation (FKD), combining graph-based similarity for local activations with global similarity measures to supervise student's training, using only handwritten text data.","meta":{"url":"http://arxiv.org/abs/2308.01136v1"},"cats":{"new-dataset":0.0626390794,"dev-research":0.3265711359,"prompt-eng":0.4011190097,"data-quality":0.1657824753,"ml-security":0.0915533139}}
{"text":"Remarkably, the models trained using this technique exhibit comparable, if not superior, performance to the teacher model across three popular signature datasets.","meta":{"url":"http://arxiv.org/abs/2308.01136v1"},"cats":{"new-dataset":0.1935825038,"dev-research":0.1912089539,"prompt-eng":0.4459759331,"data-quality":0.2433783616,"ml-security":0.1317092415}}
{"text":"More importantly, these results are attained without employing any signatures during the feature extraction training process.","meta":{"url":"http://arxiv.org/abs/2308.01136v1"},"cats":{"new-dataset":0.0694497897,"dev-research":0.1913378303,"prompt-eng":0.3771484723,"data-quality":0.3653701901,"ml-security":0.1853798529}}
{"text":"This study demonstrates the efficacy of leveraging existing expert models to overcome data scarcity challenges in OffSV and potentially other related domains.","meta":{"url":"http://arxiv.org/abs/2308.01136v1"},"cats":{"new-dataset":0.1022978836,"dev-research":0.3098879844,"prompt-eng":0.4171180771,"data-quality":0.1433227523,"ml-security":0.1631551187}}
{"text":"The Class Incremental Semantic Segmentation (CISS) extends the traditional segmentation task by incrementally learning newly added classes.","meta":{"url":"http://arxiv.org/abs/2308.01127v1"},"cats":{"new-dataset":0.2717924968,"dev-research":0.2280436722,"prompt-eng":0.3827633664,"data-quality":0.2823884656,"ml-security":0.0888060185}}
{"text":"Previous work has introduced generative replay, which involves replaying old class samples generated from a pre-trained GAN, to address the issues of catastrophic forgetting and privacy concerns.","meta":{"url":"http://arxiv.org/abs/2308.01127v1"},"cats":{"new-dataset":0.1574416406,"dev-research":0.3050002336,"prompt-eng":0.3951235859,"data-quality":0.2401980944,"ml-security":0.3457445484}}
{"text":"However, the generated images lack semantic precision and exhibit out-of-distribution characteristics, resulting in inaccurate masks that further degrade the segmentation performance.","meta":{"url":"http://arxiv.org/abs/2308.01127v1"},"cats":{"new-dataset":0.0915476422,"dev-research":0.2472708448,"prompt-eng":0.3859144639,"data-quality":0.4594907442,"ml-security":0.1475651834}}
{"text":"To tackle these challenges, we propose DiffusePast, a novel framework featuring a diffusion-based generative replay module that generates semantically accurate images with more reliable masks guided by different instructions (e.g., text prompts or edge maps).","meta":{"url":"http://arxiv.org/abs/2308.01127v1"},"cats":{"new-dataset":0.2519169473,"dev-research":0.295767608,"prompt-eng":0.4118223431,"data-quality":0.2361108984,"ml-security":0.1096256856}}
{"text":"Specifically, DiffusePast introduces a dual-generator paradigm, which focuses on generating old class images that align with the distribution of downstream datasets while preserving the structure and layout of the original images, enabling more precise masks.","meta":{"url":"http://arxiv.org/abs/2308.01127v1"},"cats":{"new-dataset":0.2150903673,"dev-research":0.2692525526,"prompt-eng":0.368928249,"data-quality":0.1839005273,"ml-security":0.1433329612}}
{"text":"To adapt to the novel visual concepts of newly added classes continuously, we incorporate class-wise token embedding when updating the dual-generator.","meta":{"url":"http://arxiv.org/abs/2308.01127v1"},"cats":{"new-dataset":0.1362607203,"dev-research":0.3663739125,"prompt-eng":0.4047656069,"data-quality":0.2378986414,"ml-security":0.1370465497}}
{"text":"Moreover, we assign adequate pseudo-labels of old classes to the background pixels in the new step images, further mitigating the forgetting of previously learned knowledge.","meta":{"url":"http://arxiv.org/abs/2308.01127v1"},"cats":{"new-dataset":0.194528879,"dev-research":0.2865146758,"prompt-eng":0.4227195583,"data-quality":0.3286600399,"ml-security":0.1777872937}}
{"text":"Through comprehensive experiments, our method demonstrates competitive performance across mainstream benchmarks, striking a better balance between the performance of old and novel classes.","meta":{"url":"http://arxiv.org/abs/2308.01127v1"},"cats":{"new-dataset":0.0843052758,"dev-research":0.2614849034,"prompt-eng":0.4221355677,"data-quality":0.1780755488,"ml-security":0.0682919423}}
{"text":"Current captioning approaches tend to generate correct but \"generic\" descriptions that lack real-world knowledge, e.g., named entities and contextual information.","meta":{"url":"http://arxiv.org/abs/2308.01126v1"},"cats":{"new-dataset":0.1352712869,"dev-research":0.3215332597,"prompt-eng":0.3950459049,"data-quality":0.4065820185,"ml-security":0.0776073828}}
{"text":"Considering that Vision-Language Pre-Training (VLP) models master massive such knowledge from large-scale web-harvested data, it is promising to utilize the generalizability of VLP models to incorporate knowledge into image descriptions.","meta":{"url":"http://arxiv.org/abs/2308.01126v1"},"cats":{"new-dataset":0.237363208,"dev-research":0.2228362397,"prompt-eng":0.4133593269,"data-quality":0.2149001586,"ml-security":0.0870200517}}
{"text":"However, using VLP models faces challenges: zero-shot inference suffers from knowledge hallucination that leads to low-quality descriptions, but the generic bias in downstream task fine-tuning hinders the VLP model from expressing knowledge.","meta":{"url":"http://arxiv.org/abs/2308.01126v1"},"cats":{"new-dataset":0.0825253337,"dev-research":0.2788781723,"prompt-eng":0.3894865713,"data-quality":0.275999455,"ml-security":0.1489603233}}
{"text":"To address these concerns, we propose a simple yet effective method called Knowledge-guided Replay (K-Replay), which enables the retention of pre-training knowledge during fine-tuning.","meta":{"url":"http://arxiv.org/abs/2308.01126v1"},"cats":{"new-dataset":0.0818104125,"dev-research":0.4428416267,"prompt-eng":0.4805404732,"data-quality":0.2744324072,"ml-security":0.0975695455}}
{"text":"Our approach consists of two parts: (1) a knowledge prediction task on automatically collected replay exemplars to continuously awaken the VLP model's memory about knowledge, thus preventing the model from collapsing into the generic pattern; (2) a knowledge distillation constraint to improve the faithfulness of generated descriptions hence alleviating the knowledge hallucination.","meta":{"url":"http://arxiv.org/abs/2308.01126v1"},"cats":{"new-dataset":0.1714998159,"dev-research":0.3087374229,"prompt-eng":0.4610495943,"data-quality":0.2037929273,"ml-security":0.1065059587}}
{"text":"To evaluate knowledge-enhanced descriptions, we construct a novel captioning benchmark KnowCap, containing knowledge of landmarks, famous brands, special foods and movie characters.","meta":{"url":"http://arxiv.org/abs/2308.01126v1"},"cats":{"new-dataset":0.3432649902,"dev-research":0.2674118895,"prompt-eng":0.406970685,"data-quality":0.3075543214,"ml-security":0.0704070373}}
{"text":"Experimental results show that our approach effectively incorporates knowledge into descriptions, outperforming strong VLP baseline by 20.9 points (78.7->99.6) in CIDEr score and 20.5 percentage points (34.0%->54.5%) in knowledge recognition accuracy.","meta":{"url":"http://arxiv.org/abs/2308.01126v1"},"cats":{"new-dataset":0.1169632076,"dev-research":0.2686653808,"prompt-eng":0.4378020201,"data-quality":0.4061636806,"ml-security":0.0999080717}}
{"text":"Our code and data is available at https://github.com/njucckevin/KnowCap.","meta":{"url":"http://arxiv.org/abs/2308.01126v1"},"cats":{"new-dataset":0.5931959374,"dev-research":0.1314749049,"prompt-eng":0.4451687699,"data-quality":0.0961121605,"ml-security":0.0326008366}}
{"text":"Robust feature matching forms the backbone for most Visual Simultaneous Localization and Mapping (vSLAM), visual odometry, 3D reconstruction, and Structure from Motion (SfM) algorithms.","meta":{"url":"http://arxiv.org/abs/2308.01125v1"},"cats":{"new-dataset":0.1436807409,"dev-research":0.1855855451,"prompt-eng":0.3907076933,"data-quality":0.1088315476,"ml-security":0.0507865594}}
{"text":"However, recovering feature matches from texture-poor scenes is a major challenge and still remains an open area of research.","meta":{"url":"http://arxiv.org/abs/2308.01125v1"},"cats":{"new-dataset":0.1539468907,"dev-research":0.2292133073,"prompt-eng":0.3653658244,"data-quality":0.3615247893,"ml-security":0.0996989597}}
{"text":"In this paper, we present a Stereo Visual Odometry (StereoVO) technique based on point and line features which uses a novel feature-matching mechanism based on an Attention Graph Neural Network that is designed to perform well even under adverse weather conditions such as fog, haze, rain, and snow, and dynamic lighting conditions such as nighttime illumination and glare scenarios.","meta":{"url":"http://arxiv.org/abs/2308.01125v1"},"cats":{"new-dataset":0.1895060207,"dev-research":0.2615698886,"prompt-eng":0.3445624418,"data-quality":0.1300366496,"ml-security":0.0515461274}}
{"text":"We perform experiments on multiple real and synthetic datasets to validate the ability of our method to perform StereoVO under low visibility weather and lighting conditions through robust point and line matches.","meta":{"url":"http://arxiv.org/abs/2308.01125v1"},"cats":{"new-dataset":0.4699964221,"dev-research":0.2038382807,"prompt-eng":0.372790498,"data-quality":0.1704639484,"ml-security":0.0636477419}}
{"text":"The results demonstrate that our method achieves more line feature matches than state-of-the-art line matching algorithms, which when complemented with point feature matches perform consistently well in adverse weather and dynamic lighting conditions.","meta":{"url":"http://arxiv.org/abs/2308.01125v1"},"cats":{"new-dataset":0.1934085018,"dev-research":0.2307976904,"prompt-eng":0.4291564468,"data-quality":0.1638165472,"ml-security":0.0426920554}}
{"text":"Recommender systems help people find relevant content in a personalized way.","meta":{"url":"http://arxiv.org/abs/2308.01118v1"},"cats":{"new-dataset":0.0256194579,"dev-research":0.2861915788,"prompt-eng":0.3920223517,"data-quality":0.154004259,"ml-security":0.0765941997}}
{"text":"One main promise of such systems is that they are able to increase the visibility of items in the long tail, i.e., the lesser-known items in a catalogue.","meta":{"url":"http://arxiv.org/abs/2308.01118v1"},"cats":{"new-dataset":0.0618043196,"dev-research":0.2032186679,"prompt-eng":0.4147310451,"data-quality":0.0985099617,"ml-security":0.0761816172}}
{"text":"Existing research, however, suggests that in many situations today's recommendation algorithms instead exhibit a popularity bias, meaning that they often focus on rather popular items in their recommendations.","meta":{"url":"http://arxiv.org/abs/2308.01118v1"},"cats":{"new-dataset":0.0149158613,"dev-research":0.2860892761,"prompt-eng":0.336849682,"data-quality":0.1962330657,"ml-security":0.1425068621}}
{"text":"Such a bias may not only lead to limited value of the recommendations for consumers and providers in the short run, but it may also cause undesired reinforcement effects over time.","meta":{"url":"http://arxiv.org/abs/2308.01118v1"},"cats":{"new-dataset":0.003219079,"dev-research":0.2653735339,"prompt-eng":0.3378065276,"data-quality":0.2433762666,"ml-security":0.2534659812}}
{"text":"In this paper, we discuss the potential reasons for popularity bias and we review existing approaches to detect, quantify and mitigate popularity bias in recommender systems.","meta":{"url":"http://arxiv.org/abs/2308.01118v1"},"cats":{"new-dataset":0.0238117046,"dev-research":0.2636743023,"prompt-eng":0.4046238314,"data-quality":0.2785392653,"ml-security":0.2544304725}}
{"text":"Our survey therefore includes both an overview of the computational metrics used in the literature as well as a review of the main technical approaches to reduce the bias.","meta":{"url":"http://arxiv.org/abs/2308.01118v1"},"cats":{"new-dataset":0.0507407052,"dev-research":0.17792332,"prompt-eng":0.4449885243,"data-quality":0.224441756,"ml-security":0.063002023}}
{"text":"We furthermore critically discuss today's literature, where we observe that the research is almost entirely based on computational experiments and on certain assumptions regarding the practical effects of including long-tail items in the recommendations.","meta":{"url":"http://arxiv.org/abs/2308.01118v1"},"cats":{"new-dataset":0.0831698974,"dev-research":0.1926816491,"prompt-eng":0.4308085757,"data-quality":0.1576716929,"ml-security":0.0661939087}}
{"text":"Headland maneuvering is a crucial aspect of unmanned field operations for autonomous agricultural vehicles (AAVs).","meta":{"url":"http://arxiv.org/abs/2308.01117v1"},"cats":{"new-dataset":0.0548040666,"dev-research":0.2260108384,"prompt-eng":0.3791021334,"data-quality":0.0719587197,"ml-security":0.0963314332}}
{"text":"While motion planning for headland turning in open fields has been extensively studied and integrated into commercial auto-guidance systems, the existing methods primarily address scenarios with ample headland space and thus may not work in more constrained headland geometries.","meta":{"url":"http://arxiv.org/abs/2308.01117v1"},"cats":{"new-dataset":0.0907717509,"dev-research":0.2442812713,"prompt-eng":0.4061739802,"data-quality":0.0475459493,"ml-security":0.0587085428}}
{"text":"Commercial orchards often contain narrow and irregularly shaped headlands, which may include static obstacles,rendering the task of planning a smooth and collision-free turning trajectory difficult.","meta":{"url":"http://arxiv.org/abs/2308.01117v1"},"cats":{"new-dataset":0.1304699565,"dev-research":0.2555297018,"prompt-eng":0.3921975409,"data-quality":0.0696026655,"ml-security":0.0881420025}}
{"text":"To address this challenge, we propose an optimization-based motion planning algorithm for headland turning under geometrical constraints imposed by field geometry and obstacles.","meta":{"url":"http://arxiv.org/abs/2308.01117v1"},"cats":{"new-dataset":0.0859597601,"dev-research":0.2419481553,"prompt-eng":0.3697396841,"data-quality":0.0382407137,"ml-security":0.0475549493}}
{"text":"The signed double Roman domination problem is a combinatorial optimization problem on a graph asking to assign a label from $\\{\\pm{}1,2,3\\}$ to each vertex feasibly, such that the total sum of assigned labels is minimized.","meta":{"url":"http://arxiv.org/abs/2308.01109v1"},"cats":{"new-dataset":0.2227969964,"dev-research":0.2270763576,"prompt-eng":0.3475320134,"data-quality":0.1835533993,"ml-security":0.189610741}}
{"text":"Here feasibility is given whenever (i) vertices labeled $\\pm{}1$ have at least one neighbor with label in $\\{2,3\\}$; (ii) each vertex labeled $-1$ has one $3$-labeled neighbor or at least two $2$-labeled neighbors; and (iii) the sum of labels over the closed neighborhood of any vertex is positive.","meta":{"url":"http://arxiv.org/abs/2308.01109v1"},"cats":{"new-dataset":0.1486875667,"dev-research":0.2007390846,"prompt-eng":0.361860158,"data-quality":0.430645531,"ml-security":0.1201099313}}
{"text":"The cumulative weight of an optimal labeling is called signed double Roman domination number (SDRDN).","meta":{"url":"http://arxiv.org/abs/2308.01109v1"},"cats":{"new-dataset":0.1675888991,"dev-research":0.1642761392,"prompt-eng":0.411887416,"data-quality":0.3138664788,"ml-security":0.0785081536}}
{"text":"In this work, we first consider the problem on general cubic graphs of order $n$ for which we present a sharp $n/2+\\Theta(1)$ lower bound for the SDRDN by means of the discharging method.","meta":{"url":"http://arxiv.org/abs/2308.01109v1"},"cats":{"new-dataset":0.4891441621,"dev-research":0.1435133533,"prompt-eng":0.2881714068,"data-quality":0.1779002591,"ml-security":0.1385133749}}
{"text":"Moreover, we derive a new best upper bound.","meta":{"url":"http://arxiv.org/abs/2308.01109v1"},"cats":{"new-dataset":0.2146153363,"dev-research":0.1814253461,"prompt-eng":0.3235216491,"data-quality":0.1330611094,"ml-security":0.1719888054}}
{"text":"Observing that we are often able to minimize the SDRDN over the class of cubic graphs of a fixed order, we then study in this context generalized Petersen graphs for independent interest, for which we propose a constraint programming guided proof.","meta":{"url":"http://arxiv.org/abs/2308.01109v1"},"cats":{"new-dataset":0.3246578294,"dev-research":0.2275984794,"prompt-eng":0.3226846443,"data-quality":0.1626638747,"ml-security":0.1117794149}}
{"text":"We then use these insights to determine the SDRDNs of subcubic $2\\times m$ grid graphs, among other results.","meta":{"url":"http://arxiv.org/abs/2308.01109v1"},"cats":{"new-dataset":0.4238545477,"dev-research":0.1526660159,"prompt-eng":0.3249262703,"data-quality":0.1344739548,"ml-security":0.0677638706}}
{"text":"Recently there has been a series of studies in knowledge graph embedding (KGE), which attempts to learn the embeddings of the entities and relations as numerical vectors and mathematical mappings via machine learning (ML).","meta":{"url":"http://arxiv.org/abs/2308.01105v1"},"cats":{"new-dataset":0.1351246654,"dev-research":0.2218346964,"prompt-eng":0.3279128935,"data-quality":0.2022889829,"ml-security":0.089963585}}
{"text":"However, there has been limited research that applies KGE for industrial problems in manufacturing.","meta":{"url":"http://arxiv.org/abs/2308.01105v1"},"cats":{"new-dataset":0.0430768039,"dev-research":0.2052405594,"prompt-eng":0.265270601,"data-quality":0.1236807685,"ml-security":0.0954889949}}
{"text":"This paper investigates whether and to what extent KGE can be used for an important problem: quality monitoring for welding in manufacturing industry, which is an impactful process accounting for production of millions of cars annually.","meta":{"url":"http://arxiv.org/abs/2308.01105v1"},"cats":{"new-dataset":0.1348261005,"dev-research":0.3599562585,"prompt-eng":0.3868805314,"data-quality":0.2483963617,"ml-security":0.0562938}}
{"text":"The work is in line with Bosch research of data-driven solutions that intends to replace the traditional way of destroying cars, which is extremely costly and produces waste.","meta":{"url":"http://arxiv.org/abs/2308.01105v1"},"cats":{"new-dataset":0.1851441638,"dev-research":0.3172879647,"prompt-eng":0.3537077138,"data-quality":0.1130753798,"ml-security":0.0998530914}}
{"text":"The paper tackles two very challenging questions simultaneously: how large the welding spot diameter is; and to which car body the welded spot belongs to.","meta":{"url":"http://arxiv.org/abs/2308.01105v1"},"cats":{"new-dataset":0.1312845013,"dev-research":0.2548853451,"prompt-eng":0.3365011754,"data-quality":0.1641996182,"ml-security":0.0634997267}}
{"text":"The problem setting is difficult for traditional ML because there exist a high number of car bodies that should be assigned as class labels.","meta":{"url":"http://arxiv.org/abs/2308.01105v1"},"cats":{"new-dataset":0.0881955638,"dev-research":0.2026544652,"prompt-eng":0.3948482692,"data-quality":0.3636356011,"ml-security":0.120780683}}
{"text":"We formulate the problem as link prediction, and experimented popular KGE methods on real industry data, with consideration of literals.","meta":{"url":"http://arxiv.org/abs/2308.01105v1"},"cats":{"new-dataset":0.1181657255,"dev-research":0.1863657575,"prompt-eng":0.3549834629,"data-quality":0.236441275,"ml-security":0.1076898742}}
{"text":"Our results reveal both limitations and promising aspects of adapted KGE methods.","meta":{"url":"http://arxiv.org/abs/2308.01105v1"},"cats":{"new-dataset":0.0254608219,"dev-research":0.1839194284,"prompt-eng":0.3743322812,"data-quality":0.1296975045,"ml-security":0.0509070671}}
{"text":"One-bit quantization with time-varying sampling thresholds (also known as random dithering) has recently found significant utilization potential in statistical signal processing applications due to its relatively low power consumption and low implementation cost.","meta":{"url":"http://arxiv.org/abs/2308.00695v1"},"cats":{"new-dataset":0.0308149546,"dev-research":0.1989434453,"prompt-eng":0.374948175,"data-quality":0.1619302141,"ml-security":0.1724533404}}
{"text":"In addition to such advantages, an attractive feature of one-bit analog-to-digital converters (ADCs) is their superior sampling rates as compared to their conventional multi-bit counterparts.","meta":{"url":"http://arxiv.org/abs/2308.00695v1"},"cats":{"new-dataset":0.0199610227,"dev-research":0.3104817837,"prompt-eng":0.4200721877,"data-quality":0.1656332987,"ml-security":0.1058745159}}
{"text":"This characteristic endows one-bit signal processing frameworks with what one may refer to as sample abundance.","meta":{"url":"http://arxiv.org/abs/2308.00695v1"},"cats":{"new-dataset":0.1682549494,"dev-research":0.1950706787,"prompt-eng":0.3864038395,"data-quality":0.1521078783,"ml-security":0.1030482187}}
{"text":"We show that sample abundance plays a pivotal role in many signal recovery and optimization problems that are formulated as (possibly non-convex) quadratic programs with linear feasibility constraints.","meta":{"url":"http://arxiv.org/abs/2308.00695v1"},"cats":{"new-dataset":0.0708140284,"dev-research":0.1778364453,"prompt-eng":0.3555494816,"data-quality":0.1534380927,"ml-security":0.1157454268}}
{"text":"Of particular interest to our work are low-rank matrix recovery and compressed sensing applications that take advantage of one-bit quantization.","meta":{"url":"http://arxiv.org/abs/2308.00695v1"},"cats":{"new-dataset":0.0749801332,"dev-research":0.1548304056,"prompt-eng":0.3461930779,"data-quality":0.1551327417,"ml-security":0.1157982898}}
{"text":"We demonstrate that the sample abundance paradigm allows for the transformation of such problems to merely linear feasibility problems by forming large-scale overdetermined linear systems -- thus removing the need for handling costly optimization constraints and objectives.","meta":{"url":"http://arxiv.org/abs/2308.00695v1"},"cats":{"new-dataset":0.1274623081,"dev-research":0.153671826,"prompt-eng":0.3660297118,"data-quality":0.1516791966,"ml-security":0.1490155541}}
{"text":"To make the proposed computational cost savings achievable, we offer enhanced randomized Kaczmarz algorithms to solve these highly overdetermined feasibility problems and provide theoretical guarantees in terms of their convergence, sample size requirements, and overall performance.","meta":{"url":"http://arxiv.org/abs/2308.00695v1"},"cats":{"new-dataset":0.0951200808,"dev-research":0.177095867,"prompt-eng":0.3797272945,"data-quality":0.1077747783,"ml-security":0.086928113}}
{"text":"Several numerical results are presented to illustrate the effectiveness of the proposed methodologies.","meta":{"url":"http://arxiv.org/abs/2308.00695v1"},"cats":{"new-dataset":0.021433576,"dev-research":0.1973496798,"prompt-eng":0.3825014774,"data-quality":0.0941541588,"ml-security":0.0343928023}}
{"text":"Although perception systems have made remarkable advancements in recent years, they still rely on explicit human instruction to identify the target objects or categories before executing visual recognition tasks.","meta":{"url":"http://arxiv.org/abs/2308.00692v1"},"cats":{"new-dataset":0.026898475,"dev-research":0.2784606805,"prompt-eng":0.4492603782,"data-quality":0.2273522531,"ml-security":0.1590997231}}
{"text":"Such systems lack the ability to actively reason and comprehend implicit user intentions.","meta":{"url":"http://arxiv.org/abs/2308.00692v1"},"cats":{"new-dataset":0.0160397132,"dev-research":0.3683698148,"prompt-eng":0.44215318,"data-quality":0.2162985182,"ml-security":0.2375856619}}
{"text":"In this work, we propose a new segmentation task -- reasoning segmentation.","meta":{"url":"http://arxiv.org/abs/2308.00692v1"},"cats":{"new-dataset":0.4970790711,"dev-research":0.2328768129,"prompt-eng":0.4695623442,"data-quality":0.3098048355,"ml-security":0.0750158986}}
{"text":"The task is designed to output a segmentation mask given a complex and implicit query text.","meta":{"url":"http://arxiv.org/abs/2308.00692v1"},"cats":{"new-dataset":0.2482158728,"dev-research":0.2554848611,"prompt-eng":0.4482848224,"data-quality":0.2237980941,"ml-security":0.1188201881}}
{"text":"Furthermore, we establish a benchmark comprising over one thousand image-instruction pairs, incorporating intricate reasoning and world knowledge for evaluation purposes.","meta":{"url":"http://arxiv.org/abs/2308.00692v1"},"cats":{"new-dataset":0.513773577,"dev-research":0.2949403998,"prompt-eng":0.4526933981,"data-quality":0.1535417307,"ml-security":0.0514362427}}
{"text":"Finally, we present LISA: large Language Instructed Segmentation Assistant, which inherits the language generation capabilities of the multi-modal Large Language Model (LLM) while also possessing the ability to produce segmentation masks.","meta":{"url":"http://arxiv.org/abs/2308.00692v1"},"cats":{"new-dataset":0.585221179,"dev-research":0.2244937152,"prompt-eng":0.4239856591,"data-quality":0.1533002099,"ml-security":0.0758691291}}
{"text":"We expand the original vocabulary with a <SEG> token and propose the embedding-as-mask paradigm to unlock the segmentation capability.","meta":{"url":"http://arxiv.org/abs/2308.00692v1"},"cats":{"new-dataset":0.271890483,"dev-research":0.2048860196,"prompt-eng":0.3986068469,"data-quality":0.2784860739,"ml-security":0.1080555341}}
{"text":"Remarkably, LISA can handle cases involving: 1) complex reasoning; 2) world knowledge; 3) explanatory answers; 4) multi-turn conversation.","meta":{"url":"http://arxiv.org/abs/2308.00692v1"},"cats":{"new-dataset":0.1802969054,"dev-research":0.3497026747,"prompt-eng":0.4033356281,"data-quality":0.1570802436,"ml-security":0.1337634988}}
{"text":"Also, it demonstrates robust zero-shot capability when trained exclusively on reasoning-free datasets.","meta":{"url":"http://arxiv.org/abs/2308.00692v1"},"cats":{"new-dataset":0.3300167215,"dev-research":0.2487651025,"prompt-eng":0.3230673959,"data-quality":0.2096820305,"ml-security":0.2502358785}}
{"text":"In addition, fine-tuning the model with merely 239 reasoning segmentation image-instruction pairs results in further performance enhancement.","meta":{"url":"http://arxiv.org/abs/2308.00692v1"},"cats":{"new-dataset":0.2705549635,"dev-research":0.3259851847,"prompt-eng":0.4423430688,"data-quality":0.1710751695,"ml-security":0.0688450471}}
{"text":"Experiments show our method not only unlocks new reasoning segmentation capabilities but also proves effective in both complex reasoning segmentation and standard referring segmentation tasks.","meta":{"url":"http://arxiv.org/abs/2308.00692v1"},"cats":{"new-dataset":0.1379083342,"dev-research":0.3472769035,"prompt-eng":0.4224979975,"data-quality":0.2771458202,"ml-security":0.0878612146}}
{"text":"Code, models, and demo are at https://github.com/dvlab-research/LISA.","meta":{"url":"http://arxiv.org/abs/2308.00692v1"},"cats":{"new-dataset":0.4166390798,"dev-research":0.1710004702,"prompt-eng":0.4331881529,"data-quality":0.0871026553,"ml-security":0.0338980001}}
{"text":"Visual Place Recognition (VPR) is vital for robot localization.","meta":{"url":"http://arxiv.org/abs/2308.00688v1"},"cats":{"new-dataset":0.0830992072,"dev-research":0.2185980117,"prompt-eng":0.4020108709,"data-quality":0.138535522,"ml-security":0.0700375551}}
{"text":"To date, the most performant VPR approaches are environment- and task-specific: while they exhibit strong performance in structured environments (predominantly urban driving), their performance degrades severely in unstructured environments, rendering most approaches brittle to robust real-world deployment.","meta":{"url":"http://arxiv.org/abs/2308.00688v1"},"cats":{"new-dataset":0.1237048409,"dev-research":0.3446293138,"prompt-eng":0.4462651661,"data-quality":0.1014444777,"ml-security":0.0764275971}}
{"text":"In this work, we develop a universal solution to VPR -- a technique that works across a broad range of structured and unstructured environments (urban, outdoors, indoors, aerial, underwater, and subterranean environments) without any re-training or fine-tuning.","meta":{"url":"http://arxiv.org/abs/2308.00688v1"},"cats":{"new-dataset":0.2228566992,"dev-research":0.235460491,"prompt-eng":0.4319772656,"data-quality":0.1049829597,"ml-security":0.0754929487}}
{"text":"We demonstrate that general-purpose feature representations derived from off-the-shelf self-supervised models with no VPR-specific training are the right substrate upon which to build such a universal VPR solution.","meta":{"url":"http://arxiv.org/abs/2308.00688v1"},"cats":{"new-dataset":0.1301585108,"dev-research":0.2426926087,"prompt-eng":0.4155554019,"data-quality":0.2519336594,"ml-security":0.140535677}}
{"text":"Combining these derived features with unsupervised feature aggregation enables our suite of methods, AnyLoc, to achieve up to 4X significantly higher performance than existing approaches.","meta":{"url":"http://arxiv.org/abs/2308.00688v1"},"cats":{"new-dataset":0.1273180151,"dev-research":0.2450352531,"prompt-eng":0.4139061685,"data-quality":0.1582588659,"ml-security":0.0717220567}}
{"text":"We further obtain a 6% improvement in performance by characterizing the semantic properties of these features, uncovering unique domains which encapsulate datasets from similar environments.","meta":{"url":"http://arxiv.org/abs/2308.00688v1"},"cats":{"new-dataset":0.461573463,"dev-research":0.305533503,"prompt-eng":0.3812264254,"data-quality":0.3015797905,"ml-security":0.1720166932}}
{"text":"Our detailed experiments and analysis lay a foundation for building VPR solutions that may be deployed anywhere, anytime, and across anyview.","meta":{"url":"http://arxiv.org/abs/2308.00688v1"},"cats":{"new-dataset":0.1815631492,"dev-research":0.2830415159,"prompt-eng":0.4447441744,"data-quality":0.0892044512,"ml-security":0.085098035}}
{"text":"We encourage the readers to explore our project page and interactive demos: https://anyloc.github.io/.","meta":{"url":"http://arxiv.org/abs/2308.00688v1"},"cats":{"new-dataset":0.3838812167,"dev-research":0.2905994367,"prompt-eng":0.4432000087,"data-quality":0.0969980215,"ml-security":0.0428223038}}
{"text":"Hyperdimensional computing (HDC) is an emerging computing paradigm that imitates the brain's structure to offer a powerful and efficient processing and learning model.","meta":{"url":"http://arxiv.org/abs/2308.00685v1"},"cats":{"new-dataset":0.0515123826,"dev-research":0.2448975128,"prompt-eng":0.380674497,"data-quality":0.0933972913,"ml-security":0.0984875839}}
{"text":"In HDC, the data are encoded with long vectors, called hypervectors, typically with a length of 1K to 10K.","meta":{"url":"http://arxiv.org/abs/2308.00685v1"},"cats":{"new-dataset":0.1678066593,"dev-research":0.1768425225,"prompt-eng":0.3512604267,"data-quality":0.1488619359,"ml-security":0.0808002335}}
{"text":"The literature provides several encoding techniques to generate orthogonal or correlated hypervectors, depending on the intended application.","meta":{"url":"http://arxiv.org/abs/2308.00685v1"},"cats":{"new-dataset":0.051604892,"dev-research":0.1990268878,"prompt-eng":0.4077947053,"data-quality":0.1121912016,"ml-security":0.0522925371}}
{"text":"The existing surveys in the literature often focus on the overall aspects of HDC systems, including system inputs, primary computations, and final outputs.","meta":{"url":"http://arxiv.org/abs/2308.00685v1"},"cats":{"new-dataset":0.1212800661,"dev-research":0.248173725,"prompt-eng":0.4318726,"data-quality":0.1367857622,"ml-security":0.0713593584}}
{"text":"However, this study takes a more specific approach.","meta":{"url":"http://arxiv.org/abs/2308.00685v1"},"cats":{"new-dataset":0.0130372766,"dev-research":0.2639801112,"prompt-eng":0.314353757,"data-quality":0.1160751479,"ml-security":0.0574527224}}
{"text":"It zeroes in on the HDC system input and the generation of hypervectors, directly influencing the hypervector encoding process.","meta":{"url":"http://arxiv.org/abs/2308.00685v1"},"cats":{"new-dataset":0.0232740888,"dev-research":0.2400598157,"prompt-eng":0.3790938979,"data-quality":0.1858588717,"ml-security":0.0868400058}}
{"text":"This survey brings together various methods for hypervector generation from different studies and explores the limitations, challenges, and potential benefits they entail.","meta":{"url":"http://arxiv.org/abs/2308.00685v1"},"cats":{"new-dataset":0.0458715338,"dev-research":0.2146191706,"prompt-eng":0.380618879,"data-quality":0.1639394857,"ml-security":0.0431316705}}
{"text":"Through a comprehensive exploration of this survey, readers will acquire a profound understanding of various encoding types in HDC and gain insights into the intricate process of hypervector generation for diverse applications.","meta":{"url":"http://arxiv.org/abs/2308.00685v1"},"cats":{"new-dataset":0.0580575299,"dev-research":0.2416733693,"prompt-eng":0.387871823,"data-quality":0.1707287714,"ml-security":0.0664765892}}
{"text":"Recent works have widely adopted large language model pretraining for source code, suggested source code-specific pretraining objectives and investigated the applicability of various Transformer-based language model architectures for source code.","meta":{"url":"http://arxiv.org/abs/2308.00683v1"},"cats":{"new-dataset":0.1374040655,"dev-research":0.4019708366,"prompt-eng":0.4238215358,"data-quality":0.1782284791,"ml-security":0.1260275293}}
{"text":"This work investigates another important aspect of such models, namely the effect of different subtokenization options, and aims at identifying most effective and length-efficient subtokenizations, taking into account code specifics.","meta":{"url":"http://arxiv.org/abs/2308.00683v1"},"cats":{"new-dataset":0.0233262333,"dev-research":0.2305123616,"prompt-eng":0.4414973128,"data-quality":0.199122457,"ml-security":0.1069112916}}
{"text":"We propose subtokenziation that reduces average length by 17% without downstream performance drop, and show that a carefully chosen subtokenization may improve quality by 0.5-2%, possibly with some length increase.","meta":{"url":"http://arxiv.org/abs/2308.00683v1"},"cats":{"new-dataset":0.0269141078,"dev-research":0.2356315441,"prompt-eng":0.4141775536,"data-quality":0.3272001231,"ml-security":0.1476419804}}
{"text":"When exploring time series datasets, analysts often pose \"which and when\" questions.","meta":{"url":"http://arxiv.org/abs/2308.00682v1"},"cats":{"new-dataset":0.2337773637,"dev-research":0.3022030215,"prompt-eng":0.38953519,"data-quality":0.1526702921,"ml-security":0.0796203473}}
{"text":"For example, with world life expectancy data over one hundred years, they may inquire about the top 10 countries in life expectancy and the time period when they achieved this status, or which countries have had longer life expectancy than Ireland and when.","meta":{"url":"http://arxiv.org/abs/2308.00682v1"},"cats":{"new-dataset":0.4248521683,"dev-research":0.1561389071,"prompt-eng":0.3345427645,"data-quality":0.1088577308,"ml-security":0.0823546178}}
{"text":"This paper proposes TimePool, a new visualization prototype, to address this need for univariate time series analysis.","meta":{"url":"http://arxiv.org/abs/2308.00682v1"},"cats":{"new-dataset":0.328716755,"dev-research":0.2510023425,"prompt-eng":0.3552776184,"data-quality":0.0835502751,"ml-security":0.095223341}}
{"text":"It allows users to construct interactive \"which and when\" queries and visually explore the results for insights.","meta":{"url":"http://arxiv.org/abs/2308.00682v1"},"cats":{"new-dataset":0.0331792482,"dev-research":0.4573439062,"prompt-eng":0.4200170345,"data-quality":0.0933836144,"ml-security":0.0618397329}}
{"text":"Today, large language models (LLMs) are taught to use new tools by providing a few demonstrations of the tool's usage.","meta":{"url":"http://arxiv.org/abs/2308.00675v1"},"cats":{"new-dataset":0.1395700949,"dev-research":0.2794248971,"prompt-eng":0.4583078163,"data-quality":0.1696692579,"ml-security":0.1054328087}}
{"text":"Unfortunately, demonstrations are hard to acquire, and can result in undesirable biased usage if the wrong demonstration is chosen.","meta":{"url":"http://arxiv.org/abs/2308.00675v1"},"cats":{"new-dataset":0.0588648283,"dev-research":0.2696644009,"prompt-eng":0.441751753,"data-quality":0.2229525964,"ml-security":0.1633746436}}
{"text":"Even in the rare scenario that demonstrations are readily available, there is no principled selection protocol to determine how many and which ones to provide.","meta":{"url":"http://arxiv.org/abs/2308.00675v1"},"cats":{"new-dataset":0.0269504259,"dev-research":0.1326835008,"prompt-eng":0.3863636891,"data-quality":0.0754416757,"ml-security":0.1355014651}}
{"text":"As tasks grow more complex, the selection search grows combinatorially and invariably becomes intractable.","meta":{"url":"http://arxiv.org/abs/2308.00675v1"},"cats":{"new-dataset":0.0202098523,"dev-research":0.2772016257,"prompt-eng":0.4018982798,"data-quality":0.1067624614,"ml-security":0.1460948156}}
{"text":"Our work provides an alternative to demonstrations: tool documentation.","meta":{"url":"http://arxiv.org/abs/2308.00675v1"},"cats":{"new-dataset":0.1796210687,"dev-research":0.3841329788,"prompt-eng":0.5002001155,"data-quality":0.1132640099,"ml-security":0.0570384517}}
{"text":"We advocate the use of tool documentation, descriptions for the individual tool usage, over demonstrations.","meta":{"url":"http://arxiv.org/abs/2308.00675v1"},"cats":{"new-dataset":0.1477058476,"dev-research":0.493503395,"prompt-eng":0.4631735512,"data-quality":0.1266005232,"ml-security":0.0689546088}}
{"text":"We substantiate our claim through three main empirical findings on 6 tasks across both vision and language modalities.","meta":{"url":"http://arxiv.org/abs/2308.00675v1"},"cats":{"new-dataset":0.1017639312,"dev-research":0.2857841852,"prompt-eng":0.38560525,"data-quality":0.3077618824,"ml-security":0.0905052728}}
{"text":"First, on existing benchmarks, zero-shot prompts with only tool documentation are sufficient for eliciting proper tool usage, achieving performance on par with few-shot prompts.","meta":{"url":"http://arxiv.org/abs/2308.00675v1"},"cats":{"new-dataset":0.1621210917,"dev-research":0.3177058994,"prompt-eng":0.572271822,"data-quality":0.1752541945,"ml-security":0.0996380793}}
{"text":"Second, on a newly collected realistic tool-use dataset with hundreds of available tool APIs, we show that tool documentation is significantly more valuable than demonstrations, with zero-shot documentation significantly outperforming few-shot without documentation.","meta":{"url":"http://arxiv.org/abs/2308.00675v1"},"cats":{"new-dataset":0.6454366887,"dev-research":0.3560944697,"prompt-eng":0.4125532491,"data-quality":0.1882478814,"ml-security":0.0850395027}}
{"text":"Third, we highlight the benefits of tool documentations by tackling image generation and video tracking using just-released unseen state-of-the-art models as tools.","meta":{"url":"http://arxiv.org/abs/2308.00675v1"},"cats":{"new-dataset":0.232380606,"dev-research":0.378366449,"prompt-eng":0.3971830263,"data-quality":0.2935464374,"ml-security":0.0615471422}}
{"text":"Finally, we highlight the possibility of using tool documentation to automatically enable new applications: by using nothing more than the documentation of GroundingDino, Stable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the just-released Grounded-SAM and Track Anything models.","meta":{"url":"http://arxiv.org/abs/2308.00675v1"},"cats":{"new-dataset":0.1251905364,"dev-research":0.2748686483,"prompt-eng":0.4180268002,"data-quality":0.1175015238,"ml-security":0.0909304155}}
{"text":"Fuzz testing (fuzzing) is a well-known method for exposing bugs/vulnerabilities in software systems.","meta":{"url":"http://arxiv.org/abs/2308.00666v1"},"cats":{"new-dataset":0.0899296769,"dev-research":0.5487305124,"prompt-eng":0.4727234857,"data-quality":0.2969716238,"ml-security":0.3051057954}}
{"text":"Popular fuzzers, such as AFL, use a biased random search over the domain of program inputs, where 100s or 1000s of inputs (test cases) are executed per second in order to expose bugs.","meta":{"url":"http://arxiv.org/abs/2308.00666v1"},"cats":{"new-dataset":0.0640145946,"dev-research":0.4065938677,"prompt-eng":0.4881888586,"data-quality":0.2029732684,"ml-security":0.2503854539}}
{"text":"If a bug is discovered, it can either be fixed manually by the developer or fixed automatically using an Automated Program Repair (APR) tool.","meta":{"url":"http://arxiv.org/abs/2308.00666v1"},"cats":{"new-dataset":0.0516781605,"dev-research":0.452353015,"prompt-eng":0.432605723,"data-quality":0.6846138548,"ml-security":0.1749938709}}
{"text":"Like fuzzing, many existing APR tools are search-based, but over the domain of patches rather than inputs.   ","meta":{"url":"http://arxiv.org/abs/2308.00666v1"},"cats":{"new-dataset":0.1198003855,"dev-research":0.3445501709,"prompt-eng":0.4719418833,"data-quality":0.2400382308,"ml-security":0.1208557801}}
{"text":"In this paper, we propose search-based program repair as patch-level fuzzing.","meta":{"url":"http://arxiv.org/abs/2308.00666v1"},"cats":{"new-dataset":0.1480330306,"dev-research":0.4768328892,"prompt-eng":0.4717115497,"data-quality":0.3871344372,"ml-security":0.2391865681}}
{"text":"The basic idea is to adapt a fuzzer (AFL) to fuzz over the patch space rather than the input space.","meta":{"url":"http://arxiv.org/abs/2308.00666v1"},"cats":{"new-dataset":0.0243643359,"dev-research":0.3748053928,"prompt-eng":0.4208219427,"data-quality":0.1741640083,"ml-security":0.142804536}}
{"text":"Thus we use a patch-space fuzzer to explore a patch space, while using a traditional input level fuzzer to rule out patch candidates and help in patch selection.","meta":{"url":"http://arxiv.org/abs/2308.00666v1"},"cats":{"new-dataset":0.1913922616,"dev-research":0.398773694,"prompt-eng":0.4523497937,"data-quality":0.2359215548,"ml-security":0.1840068957}}
{"text":"To improve the throughput, we propose a compilation-free patch validation methodology, where we execute the original (unpatched) program natively, then selectively interpret only the specific patched statements and expressions.","meta":{"url":"http://arxiv.org/abs/2308.00666v1"},"cats":{"new-dataset":0.2010630584,"dev-research":0.4968849151,"prompt-eng":0.4541845016,"data-quality":0.3965714746,"ml-security":0.2656831689}}
{"text":"Since this avoids (re)compilation, we show that compilation-free patch validation can achieve a similar throughput as input-level fuzzing (100s or 1000s of execs/sec).","meta":{"url":"http://arxiv.org/abs/2308.00666v1"},"cats":{"new-dataset":0.1397707917,"dev-research":0.4607738231,"prompt-eng":0.4949128859,"data-quality":0.2490978845,"ml-security":0.2822060762}}
{"text":"We show that patch-level fuzzing and input-level fuzzing can be combined, for a co-exploration of both spaces in order to find better quality patches.","meta":{"url":"http://arxiv.org/abs/2308.00666v1"},"cats":{"new-dataset":0.3669132459,"dev-research":0.4852895325,"prompt-eng":0.4905351434,"data-quality":0.2704071697,"ml-security":0.2493935688}}
{"text":"Such a collaboration between input-level fuzzing and patch-level fuzzing is then employed to search over candidate fix locations, as well as patch candidates in each fix location.","meta":{"url":"http://arxiv.org/abs/2308.00666v1"},"cats":{"new-dataset":0.2631097142,"dev-research":0.4157108248,"prompt-eng":0.4944386921,"data-quality":0.2835161308,"ml-security":0.1745690708}}
{"text":"Today, there are a plethora of In-Memory Computing (IMC) devices-","meta":{"url":"http://arxiv.org/abs/2308.00664v1"},"cats":{"new-dataset":0.1486513021,"dev-research":0.2472041731,"prompt-eng":0.4323823436,"data-quality":0.1195413134,"ml-security":0.0677015119}}
{"text":"SRAMs, PCMs & FeFETs, that emulate convolutions on crossbar-arrays with high throughput.","meta":{"url":"http://arxiv.org/abs/2308.00664v1"},"cats":{"new-dataset":0.2879363797,"dev-research":0.1626667973,"prompt-eng":0.3475106019,"data-quality":0.0891180602,"ml-security":0.1079651615}}
{"text":"Each IMC device offers its own pros & cons during inference of Deep Neural Networks (DNNs) on crossbars in terms of area overhead, programming energy and non-idealities.","meta":{"url":"http://arxiv.org/abs/2308.00664v1"},"cats":{"new-dataset":0.0605388189,"dev-research":0.3325375405,"prompt-eng":0.3660600002,"data-quality":0.0921869007,"ml-security":0.118189001}}
{"text":"A design-space exploration is, therefore, imperative to derive a hybrid-device architecture optimized for accurate DNN inference under the impact of non-idealities from multiple devices, while maintaining competitive area & energy-efficiencies.","meta":{"url":"http://arxiv.org/abs/2308.00664v1"},"cats":{"new-dataset":0.153034482,"dev-research":0.3479351379,"prompt-eng":0.386422931,"data-quality":0.130689344,"ml-security":0.1294185523}}
{"text":"We propose a two-phase search framework (HyDe) that exploits the best of all worlds offered by multiple devices to determine an optimal hybrid-device architecture for a given DNN topology.","meta":{"url":"http://arxiv.org/abs/2308.00664v1"},"cats":{"new-dataset":0.1622835558,"dev-research":0.2146824227,"prompt-eng":0.3827882593,"data-quality":0.1022106577,"ml-security":0.1085910152}}
{"text":"Our hybrid models achieve upto 2.30-2.74x higher TOPS/mm^2 at 22-26% higher energy-efficiencies than baseline homogeneous models for a VGG16 DNN topology.","meta":{"url":"http://arxiv.org/abs/2308.00664v1"},"cats":{"new-dataset":0.1354074688,"dev-research":0.2107211467,"prompt-eng":0.3254204884,"data-quality":0.109995029,"ml-security":0.0746324106}}
{"text":"We further propose a feasible implementation of the HyDe-derived hybrid-device architectures in the 2.5D design space using chiplets to reduce design effort and cost in the hardware fabrication involving multiple technology processes.","meta":{"url":"http://arxiv.org/abs/2308.00664v1"},"cats":{"new-dataset":0.0627218299,"dev-research":0.2804081454,"prompt-eng":0.3950130818,"data-quality":0.0690301712,"ml-security":0.0556977464}}
{"text":"The emerging fifth generation (5G) and the upcoming sixth generation (6G) communication technologies introduce the use of space- and airborne networks in their architectures under the scope of non-terrestrial networks (NTNs).","meta":{"url":"http://arxiv.org/abs/2308.00658v1"},"cats":{"new-dataset":0.1998748967,"dev-research":0.2667595916,"prompt-eng":0.3136128533,"data-quality":0.0943175254,"ml-security":0.0804990781}}
{"text":"With this integration of satellite and aerial platform networks, better coverage, network flexibility and easier deployment can be achieved.","meta":{"url":"http://arxiv.org/abs/2308.00658v1"},"cats":{"new-dataset":0.1193772607,"dev-research":0.270208553,"prompt-eng":0.3835573405,"data-quality":0.0736460514,"ml-security":0.0768606927}}
{"text":"Correspondingly, satellite broadband internet providers have launched an increasing number of small satellites operating in low earth orbit (LEO).","meta":{"url":"http://arxiv.org/abs/2308.00658v1"},"cats":{"new-dataset":0.0788802241,"dev-research":0.2076453479,"prompt-eng":0.3251124632,"data-quality":0.084482211,"ml-security":0.0785049832}}
{"text":"These recent developments imply an increased electromagnetic field (EMF) exposure to humans and the environment.","meta":{"url":"http://arxiv.org/abs/2308.00658v1"},"cats":{"new-dataset":0.1141169548,"dev-research":0.2314607555,"prompt-eng":0.3838073291,"data-quality":0.1044017184,"ml-security":0.2492216169}}
{"text":"In this work, we provide a short overview of the state of consumer-grade satellite networks including broadband satellites and future NTN services.","meta":{"url":"http://arxiv.org/abs/2308.00658v1"},"cats":{"new-dataset":0.4453302832,"dev-research":0.1641653021,"prompt-eng":0.3242999205,"data-quality":0.1373967751,"ml-security":0.0949465497}}
{"text":"We also consider the regulatory state governing their operation within the context of EMF exposure.","meta":{"url":"http://arxiv.org/abs/2308.00658v1"},"cats":{"new-dataset":0.1494351941,"dev-research":0.2127889206,"prompt-eng":0.3792410988,"data-quality":0.2021086845,"ml-security":0.2091096888}}
{"text":"Finally, we highlight the aspects that are relevant to the assessment of EMF exposure in relation to NTNs.","meta":{"url":"http://arxiv.org/abs/2308.00658v1"},"cats":{"new-dataset":0.1747533897,"dev-research":0.1644578003,"prompt-eng":0.4265549389,"data-quality":0.1827820792,"ml-security":0.1479404066}}
{"text":"Optical character recognition (OCR) methods have been applied to diverse tasks, e.g., street view text recognition and document analysis.","meta":{"url":"http://arxiv.org/abs/2308.00655v1"},"cats":{"new-dataset":0.0629824173,"dev-research":0.1548087233,"prompt-eng":0.392156824,"data-quality":0.1530111807,"ml-security":0.0488780327}}
{"text":"Recently, zero-shot OCR has piqued the interest of the research community because it considers a practical OCR scenario with unbalanced data distribution.","meta":{"url":"http://arxiv.org/abs/2308.00655v1"},"cats":{"new-dataset":0.3492818565,"dev-research":0.1295167915,"prompt-eng":0.4055069152,"data-quality":0.2085886413,"ml-security":0.0951899082}}
{"text":"However, there is a lack of benchmarks for evaluating such zero-shot methods that apply a divide-and-conquer recognition strategy by decomposing characters into radicals.","meta":{"url":"http://arxiv.org/abs/2308.00655v1"},"cats":{"new-dataset":0.2134018274,"dev-research":0.1913802391,"prompt-eng":0.3611908846,"data-quality":0.2323270666,"ml-security":0.1474697094}}
{"text":"Meanwhile, radical recognition, as another important OCR task, also lacks radical-level annotation for model training.","meta":{"url":"http://arxiv.org/abs/2308.00655v1"},"cats":{"new-dataset":0.1556915133,"dev-research":0.2127161572,"prompt-eng":0.3739964883,"data-quality":0.2763540041,"ml-security":0.1384484745}}
{"text":"In this paper, we construct an ancient Chinese character image dataset that contains both radical-level and character-level annotations to satisfy the requirements of the above-mentioned methods, namely, ACCID, where radical-level annotations include radical categories, radical locations, and structural relations.","meta":{"url":"http://arxiv.org/abs/2308.00655v1"},"cats":{"new-dataset":0.71528017,"dev-research":0.2121501126,"prompt-eng":0.3908023282,"data-quality":0.2627540981,"ml-security":0.0860685281}}
{"text":"To increase the adaptability of ACCID, we propose a splicing-based synthetic character algorithm to augment the training samples and apply an image denoising method to improve the image quality.","meta":{"url":"http://arxiv.org/abs/2308.00655v1"},"cats":{"new-dataset":0.1855968243,"dev-research":0.2338864694,"prompt-eng":0.3740647239,"data-quality":0.2652510502,"ml-security":0.0879106719}}
{"text":"By introducing character decomposition and recombination, we propose a baseline method for zero-shot OCR.","meta":{"url":"http://arxiv.org/abs/2308.00655v1"},"cats":{"new-dataset":0.2383585798,"dev-research":0.1503465628,"prompt-eng":0.4151719989,"data-quality":0.173973398,"ml-security":0.0683093239}}
{"text":"The experimental results demonstrate the validity of ACCID and the baseline model quantitatively and qualitatively.","meta":{"url":"http://arxiv.org/abs/2308.00655v1"},"cats":{"new-dataset":0.0152092355,"dev-research":0.2278468986,"prompt-eng":0.4303448262,"data-quality":0.1580532645,"ml-security":0.0735990456}}
{"text":"Advanced driving assistance systems are available on many late-model vehicles, and automated driving systems are testing on public roads.","meta":{"url":"http://arxiv.org/abs/2308.00645v1"},"cats":{"new-dataset":0.0711359731,"dev-research":0.2846420311,"prompt-eng":0.4734193749,"data-quality":0.1243715541,"ml-security":0.1038747558}}
{"text":"Regulators and developers continue to assess the safety of these vehicles by comparing automated vehicle crash rates to baseline, human-driven crash rates.","meta":{"url":"http://arxiv.org/abs/2308.00645v1"},"cats":{"new-dataset":0.1750968984,"dev-research":0.4641431971,"prompt-eng":0.3997843247,"data-quality":0.2287402285,"ml-security":0.1813228802}}
{"text":"While there are several widely-cited automated vehicle and conventional vehicle crash databases, these databases have different underlying assumptions and inclusion criteria.","meta":{"url":"http://arxiv.org/abs/2308.00645v1"},"cats":{"new-dataset":0.337869585,"dev-research":0.2321871681,"prompt-eng":0.3771532275,"data-quality":0.1997968965,"ml-security":0.1277158483}}
{"text":"Crash rates among databases may be directly comparable only with significant filtering and normalization, if at all.","meta":{"url":"http://arxiv.org/abs/2308.00645v1"},"cats":{"new-dataset":0.0271622275,"dev-research":0.3265881207,"prompt-eng":0.3554080302,"data-quality":0.2421182761,"ml-security":0.1322152352}}
{"text":"This paper reviews current automated vehicle and baseline human-driven crash databases and evaluates their comparability.","meta":{"url":"http://arxiv.org/abs/2308.00645v1"},"cats":{"new-dataset":0.6019246276,"dev-research":0.2975715028,"prompt-eng":0.3979167201,"data-quality":0.175308843,"ml-security":0.112401394}}
{"text":"Recommendations are presented to improve their comparability, both in terms of normalization and contextualization, as well as additional data fields that can be incorporated into existing databases.","meta":{"url":"http://arxiv.org/abs/2308.00645v1"},"cats":{"new-dataset":0.1526596477,"dev-research":0.2582287408,"prompt-eng":0.4374905547,"data-quality":0.1468829356,"ml-security":0.0605724362}}
{"text":"These findings may assist researchers, regulators, and automated vehicle developers attempting to evaluate the safety of driving automation systems.","meta":{"url":"http://arxiv.org/abs/2308.00645v1"},"cats":{"new-dataset":0.079666321,"dev-research":0.4803859283,"prompt-eng":0.4216185894,"data-quality":0.2231179818,"ml-security":0.202370429}}
{"text":"Let k be an arbitrary element of a finite commutative chain ring R and u be a unit in R. In this work, we present necessary conditions which are sufficient as well for a cyclic code to be a (u,k) reversible complement code over R. Using these conditions, all principally generated cyclic codes over the ring Z_{2}+vZ_{2}+v^{2}Z_{2}, v^{3}=0 of length 4 have been checked to find whether they are (1,1) reversible complement or not.","meta":{"url":"http://arxiv.org/abs/2308.00642v1"},"cats":{"new-dataset":0.1562913774,"dev-research":0.2464051008,"prompt-eng":0.377794922,"data-quality":0.1788482332,"ml-security":0.09796096}}
{"text":"Robotic grasping faces new challenges in human-robot-interaction scenarios.","meta":{"url":"http://arxiv.org/abs/2308.00640v1"},"cats":{"new-dataset":0.1130058689,"dev-research":0.2461983058,"prompt-eng":0.4184258938,"data-quality":0.0873562947,"ml-security":0.0797697323}}
{"text":"We consider the task that the robot grasps a target object designated by human's language directives.","meta":{"url":"http://arxiv.org/abs/2308.00640v1"},"cats":{"new-dataset":0.1081437717,"dev-research":0.296166762,"prompt-eng":0.4818680158,"data-quality":0.1489629933,"ml-security":0.1210754828}}
{"text":"The robot not only needs to locate a target based on vision-and-language information, but also needs to predict the reasonable grasp pose candidate at various views and postures.","meta":{"url":"http://arxiv.org/abs/2308.00640v1"},"cats":{"new-dataset":0.1603632381,"dev-research":0.1774914308,"prompt-eng":0.4234953215,"data-quality":0.0816428068,"ml-security":0.0854683025}}
{"text":"In this work, we propose a novel interactive grasp policy, named Visual-Lingual-Grasp (VL-Grasp), to grasp the target specified by human language.","meta":{"url":"http://arxiv.org/abs/2308.00640v1"},"cats":{"new-dataset":0.2455426127,"dev-research":0.3196478346,"prompt-eng":0.4669783958,"data-quality":0.1336685291,"ml-security":0.0718571262}}
{"text":"First, we build a new challenging visual grounding dataset to provide functional training data for robotic interactive perception in indoor environments.","meta":{"url":"http://arxiv.org/abs/2308.00640v1"},"cats":{"new-dataset":0.6984842346,"dev-research":0.2277600529,"prompt-eng":0.4012281193,"data-quality":0.1792657892,"ml-security":0.1264698493}}
{"text":"Second, we propose a 6-Dof interactive grasp policy combined with visual grounding and 6-Dof grasp pose detection to extend the universality of interactive grasping.","meta":{"url":"http://arxiv.org/abs/2308.00640v1"},"cats":{"new-dataset":0.4081291225,"dev-research":0.2141239443,"prompt-eng":0.4277509761,"data-quality":0.0940065707,"ml-security":0.0567991282}}
{"text":"Third, we design a grasp pose filter module to enhance the performance of the policy.","meta":{"url":"http://arxiv.org/abs/2308.00640v1"},"cats":{"new-dataset":0.2223579381,"dev-research":0.2041611562,"prompt-eng":0.4190172939,"data-quality":0.0717274927,"ml-security":0.0500282792}}
{"text":"Experiments demonstrate the effectiveness and extendibility of the VL-Grasp in real world.","meta":{"url":"http://arxiv.org/abs/2308.00640v1"},"cats":{"new-dataset":0.0245914608,"dev-research":0.2749861971,"prompt-eng":0.4014235772,"data-quality":0.072694532,"ml-security":0.0628866519}}
{"text":"The VL-Grasp achieves a success rate of 72.5\\% in different indoor scenes.","meta":{"url":"http://arxiv.org/abs/2308.00640v1"},"cats":{"new-dataset":0.0737486035,"dev-research":0.2586535936,"prompt-eng":0.4120469728,"data-quality":0.0908838698,"ml-security":0.0380653124}}
{"text":"The code and dataset is available at https://github.com/luyh20/VL-Grasp.","meta":{"url":"http://arxiv.org/abs/2308.00640v1"},"cats":{"new-dataset":0.6896030448,"dev-research":0.1680528973,"prompt-eng":0.4179037926,"data-quality":0.0733232182,"ml-security":0.0324946356}}
{"text":"Many approaches for optimizing decision making systems rely on gradient based methods requiring informative feedback from the environment.","meta":{"url":"http://arxiv.org/abs/2308.00629v1"},"cats":{"new-dataset":0.0128277438,"dev-research":0.4235503232,"prompt-eng":0.45070214,"data-quality":0.1805142447,"ml-security":0.1193609595}}
{"text":"However, in the case where such feedback is sparse or uninformative, such approaches may result in poor performance.","meta":{"url":"http://arxiv.org/abs/2308.00629v1"},"cats":{"new-dataset":0.0031224609,"dev-research":0.2976492576,"prompt-eng":0.4411697863,"data-quality":0.3331822135,"ml-security":0.1554697145}}
{"text":"Derivative-free approaches such as Bayesian Optimization mitigate the dependency on the quality of gradient feedback, but are known to scale poorly in the high-dimension setting of complex decision making systems.","meta":{"url":"http://arxiv.org/abs/2308.00629v1"},"cats":{"new-dataset":0.0441671206,"dev-research":0.3069505065,"prompt-eng":0.424571601,"data-quality":0.1550714089,"ml-security":0.1834155694}}
{"text":"This problem is exacerbated if the system requires interactions between several actors cooperating to accomplish a shared goal.","meta":{"url":"http://arxiv.org/abs/2308.00629v1"},"cats":{"new-dataset":0.0556225404,"dev-research":0.3265630616,"prompt-eng":0.3641098394,"data-quality":0.2637865239,"ml-security":0.2437456224}}
{"text":"To address the dimensionality challenge, we propose a compact multi-layered architecture modeling the dynamics of actor interactions through the concept of role.","meta":{"url":"http://arxiv.org/abs/2308.00629v1"},"cats":{"new-dataset":0.1147203078,"dev-research":0.2304313989,"prompt-eng":0.3590390302,"data-quality":0.0465745457,"ml-security":0.1619191676}}
{"text":"Additionally, we introduce Hessian-aware Bayesian Optimization to efficiently optimize the multi-layered architecture parameterized by a large number of parameters.","meta":{"url":"http://arxiv.org/abs/2308.00629v1"},"cats":{"new-dataset":0.0552243893,"dev-research":0.2388089912,"prompt-eng":0.423876374,"data-quality":0.0891767758,"ml-security":0.1290713391}}
{"text":"Experimental results demonstrate that our method (HA-GP-UCB) works effectively on several benchmarks under resource constraints and malformed feedback settings.","meta":{"url":"http://arxiv.org/abs/2308.00629v1"},"cats":{"new-dataset":0.1230169162,"dev-research":0.2663827705,"prompt-eng":0.4911619315,"data-quality":0.2762044484,"ml-security":0.0736982945}}
{"text":"3D human pose estimation in outdoor environments has garnered increasing attention recently.","meta":{"url":"http://arxiv.org/abs/2308.00628v1"},"cats":{"new-dataset":0.3358699209,"dev-research":0.1943543049,"prompt-eng":0.3415856852,"data-quality":0.0863164353,"ml-security":0.0939304047}}
{"text":"However, prevalent 3D human pose datasets pertaining to outdoor scenes lack diversity, as they predominantly utilize only one type of modality (RGB image or pointcloud), and often feature only one individual within each scene.","meta":{"url":"http://arxiv.org/abs/2308.00628v1"},"cats":{"new-dataset":0.3853417084,"dev-research":0.1687217564,"prompt-eng":0.2910063376,"data-quality":0.112540223,"ml-security":0.110116448}}
{"text":"This limited scope of dataset infrastructure considerably hinders the variability of available data.","meta":{"url":"http://arxiv.org/abs/2308.00628v1"},"cats":{"new-dataset":0.1265522785,"dev-research":0.2840394205,"prompt-eng":0.3393354399,"data-quality":0.2132825025,"ml-security":0.2895774379}}
{"text":"In this article, we propose Human-M3, an outdoor multi-modal multi-view multi-person human pose database which includes not only multi-view RGB videos of outdoor scenes but also corresponding pointclouds.","meta":{"url":"http://arxiv.org/abs/2308.00628v1"},"cats":{"new-dataset":0.6569266285,"dev-research":0.1641536024,"prompt-eng":0.329502809,"data-quality":0.0715971213,"ml-security":0.0732020356}}
{"text":"In order to obtain accurate human poses, we propose an algorithm based on multi-modal data input to generate ground truth annotation.","meta":{"url":"http://arxiv.org/abs/2308.00628v1"},"cats":{"new-dataset":0.3994749764,"dev-research":0.2134415189,"prompt-eng":0.4103823927,"data-quality":0.1914691621,"ml-security":0.10879131}}
{"text":"This benefits from robust pointcloud detection and tracking, which solves the problem of inaccurate human localization and matching ambiguity that may exist in previous multi-view RGB videos in outdoor multi-person scenes, and generates reliable ground truth annotations.","meta":{"url":"http://arxiv.org/abs/2308.00628v1"},"cats":{"new-dataset":0.2209438598,"dev-research":0.2523874408,"prompt-eng":0.3716395008,"data-quality":0.3328638279,"ml-security":0.1269649146}}
{"text":"Evaluation of multiple different modalities algorithms has shown that this database is challenging and suitable for future research.","meta":{"url":"http://arxiv.org/abs/2308.00628v1"},"cats":{"new-dataset":0.1178992099,"dev-research":0.1741397583,"prompt-eng":0.4141117547,"data-quality":0.1480987467,"ml-security":0.0393328097}}
{"text":"Furthermore, we propose a 3D human pose estimation algorithm based on multi-modal data input, which demonstrates the advantages of multi-modal data input for 3D human pose estimation.","meta":{"url":"http://arxiv.org/abs/2308.00628v1"},"cats":{"new-dataset":0.2519902275,"dev-research":0.2297267987,"prompt-eng":0.3540087725,"data-quality":0.0816310197,"ml-security":0.093385797}}
{"text":"Code and data will be released on https://github.com/soullessrobot/Human-M3-Dataset.","meta":{"url":"http://arxiv.org/abs/2308.00628v1"},"cats":{"new-dataset":0.8974421231,"dev-research":0.146223178,"prompt-eng":0.4021362681,"data-quality":0.0911885677,"ml-security":0.048376467}}
{"text":"With the advancements in large language model technology, it has showcased capabilities that come close to those of human beings across various tasks.","meta":{"url":"http://arxiv.org/abs/2308.00624v1"},"cats":{"new-dataset":0.0894012191,"dev-research":0.2731498836,"prompt-eng":0.3917115287,"data-quality":0.1059003967,"ml-security":0.0764555403}}
{"text":"This achievement has garnered significant interest from companies and scientific research institutions, leading to substantial investments in the research and development of these models.","meta":{"url":"http://arxiv.org/abs/2308.00624v1"},"cats":{"new-dataset":0.0378982411,"dev-research":0.1620639697,"prompt-eng":0.3410823471,"data-quality":0.0773294192,"ml-security":0.0620815699}}
{"text":"While numerous large models have emerged during this period, the majority of them have been trained primarily on English data.","meta":{"url":"http://arxiv.org/abs/2308.00624v1"},"cats":{"new-dataset":0.2983931276,"dev-research":0.218548117,"prompt-eng":0.3756227744,"data-quality":0.1589589915,"ml-security":0.0998898632}}
{"text":"Although they exhibit decent performance in other languages, such as Chinese, their potential remains limited due to factors like vocabulary design and training corpus.","meta":{"url":"http://arxiv.org/abs/2308.00624v1"},"cats":{"new-dataset":0.1181317448,"dev-research":0.2266349624,"prompt-eng":0.3071047195,"data-quality":0.1578521655,"ml-security":0.0674784418}}
{"text":"Consequently, their ability to fully express their capabilities in Chinese falls short.","meta":{"url":"http://arxiv.org/abs/2308.00624v1"},"cats":{"new-dataset":0.0530499285,"dev-research":0.2536262428,"prompt-eng":0.3508699511,"data-quality":0.1635991294,"ml-security":0.1012162884}}
{"text":"To address this issue, we introduce the model named JIANG (Chinese pinyin of ginger) specifically designed for the Chinese language.","meta":{"url":"http://arxiv.org/abs/2308.00624v1"},"cats":{"new-dataset":0.284193028,"dev-research":0.2210654794,"prompt-eng":0.442600565,"data-quality":0.1725719419,"ml-security":0.0856521663}}
{"text":"We have gathered a substantial amount of Chinese corpus to train the model and have also optimized its structure.","meta":{"url":"http://arxiv.org/abs/2308.00624v1"},"cats":{"new-dataset":0.4451415357,"dev-research":0.1735483379,"prompt-eng":0.4105892919,"data-quality":0.2205385044,"ml-security":0.0586213221}}
{"text":"The extensive experimental results demonstrate the excellent performance of our model.","meta":{"url":"http://arxiv.org/abs/2308.00624v1"},"cats":{"new-dataset":0.0760059999,"dev-research":0.1392357474,"prompt-eng":0.4445304719,"data-quality":0.0914000096,"ml-security":0.0475161311}}
{"text":"The Secure and Trustworthy Computing (SaTC) program within the National Science Foundation (NSF) program serves as the primary instrument for creating novel fundamental science in security and privacy in the United States with broad impacts that influence the world.","meta":{"url":"http://arxiv.org/abs/2308.00623v1"},"cats":{"new-dataset":0.2042206041,"dev-research":0.2512254847,"prompt-eng":0.3784205753,"data-quality":0.1292698063,"ml-security":0.3720888229}}
{"text":"The program funds research in a vast array of research topics that span technology, theory, policy, law, and society.","meta":{"url":"http://arxiv.org/abs/2308.00623v1"},"cats":{"new-dataset":0.1424794291,"dev-research":0.2166563547,"prompt-eng":0.3294714118,"data-quality":0.0923530697,"ml-security":0.1184194977}}
{"text":"In the Spring of 2023, the program managers of SaTC requested that the community prepare a vision for the next ten years of research.","meta":{"url":"http://arxiv.org/abs/2308.00623v1"},"cats":{"new-dataset":0.2250277433,"dev-research":0.2744336203,"prompt-eng":0.4170679619,"data-quality":0.0857427657,"ml-security":0.0945191005}}
{"text":"This document represents the results of that effort which involved collecting input from numerous members of the security and privacy community, industry, academics, and government.","meta":{"url":"http://arxiv.org/abs/2308.00623v1"},"cats":{"new-dataset":0.139578968,"dev-research":0.3154518381,"prompt-eng":0.4446818676,"data-quality":0.187474205,"ml-security":0.2413715542}}
{"text":"Assembled from that input, this document offers a comprehensive view of general themes and specific areas of focus for future research as envisioned by the community.","meta":{"url":"http://arxiv.org/abs/2308.00623v1"},"cats":{"new-dataset":0.0866375547,"dev-research":0.2813321092,"prompt-eng":0.381856531,"data-quality":0.0952362695,"ml-security":0.0866691379}}
{"text":"The atmospheric and water turbulence mitigation problems have emerged as challenging inverse problems in computer vision and optics communities over the years.","meta":{"url":"http://arxiv.org/abs/2308.00622v1"},"cats":{"new-dataset":0.0722059441,"dev-research":0.220578291,"prompt-eng":0.3231852507,"data-quality":0.1592111057,"ml-security":0.1251471906}}
{"text":"However, current methods either rely heavily on the quality of the training dataset or fail to generalize over various scenarios, such as static scenes, dynamic scenes, and text reconstructions.","meta":{"url":"http://arxiv.org/abs/2308.00622v1"},"cats":{"new-dataset":0.0872064305,"dev-research":0.2884913054,"prompt-eng":0.3358947368,"data-quality":0.3386447619,"ml-security":0.1127302705}}
{"text":"We propose a general implicit neural representation for unsupervised atmospheric and water turbulence mitigation (NeRT).","meta":{"url":"http://arxiv.org/abs/2308.00622v1"},"cats":{"new-dataset":0.0895148593,"dev-research":0.2709561742,"prompt-eng":0.3249463571,"data-quality":0.1592619343,"ml-security":0.2431664531}}
{"text":"NeRT leverages the implicit neural representations and the physically correct tilt-then-blur turbulence model to reconstruct the clean, undistorted image, given only dozens of distorted input images.","meta":{"url":"http://arxiv.org/abs/2308.00622v1"},"cats":{"new-dataset":0.0775486246,"dev-research":0.2609714856,"prompt-eng":0.3253405056,"data-quality":0.1093691115,"ml-security":0.0844270803}}
{"text":"Moreover, we show that NeRT outperforms the state-of-the-art through various qualitative and quantitative evaluations of atmospheric and water turbulence datasets.","meta":{"url":"http://arxiv.org/abs/2308.00622v1"},"cats":{"new-dataset":0.3114697586,"dev-research":0.2464864482,"prompt-eng":0.3134427736,"data-quality":0.1240359083,"ml-security":0.0632763962}}
{"text":"Furthermore, we demonstrate the ability of NeRT to eliminate uncontrolled turbulence from real-world environments.","meta":{"url":"http://arxiv.org/abs/2308.00622v1"},"cats":{"new-dataset":0.1098893739,"dev-research":0.262433646,"prompt-eng":0.3369407115,"data-quality":0.089262344,"ml-security":0.0836303224}}
{"text":"Lastly, we incorporate NeRT into continuously captured video sequences and demonstrate $48 \\times$ speedup.","meta":{"url":"http://arxiv.org/abs/2308.00622v1"},"cats":{"new-dataset":0.3228235151,"dev-research":0.2328805945,"prompt-eng":0.3669899912,"data-quality":0.1028181419,"ml-security":0.0497836195}}
{"text":"This paper presents a research study on the use of Convolutional Neural Network (CNN), ResNet50, InceptionV3, EfficientNetB0 and NASNetMobile models to efficiently detect brain tumors in order to reduce the time required for manual review of the report and create an automated system for classifying brain tumors.","meta":{"url":"http://arxiv.org/abs/2308.00608v1"},"cats":{"new-dataset":0.1736470378,"dev-research":0.2340522252,"prompt-eng":0.3761472938,"data-quality":0.1899014362,"ml-security":0.1423468636}}
{"text":"An automated pipeline is proposed, which encompasses five models: CNN, ResNet50, InceptionV3, EfficientNetB0 and NASNetMobile.","meta":{"url":"http://arxiv.org/abs/2308.00608v1"},"cats":{"new-dataset":0.2776175893,"dev-research":0.2247780174,"prompt-eng":0.4150047639,"data-quality":0.1557188926,"ml-security":0.0918643701}}
{"text":"The performance of the proposed architecture is evaluated on a balanced dataset and found to yield an accuracy of 99.33% for fine-tuned InceptionV3 model.","meta":{"url":"http://arxiv.org/abs/2308.00608v1"},"cats":{"new-dataset":0.2750888797,"dev-research":0.181513012,"prompt-eng":0.3431027345,"data-quality":0.1762190643,"ml-security":0.1132138919}}
{"text":"Furthermore, Explainable AI approaches are incorporated to visualize the model's latent behavior in order to understand its black box behavior.","meta":{"url":"http://arxiv.org/abs/2308.00608v1"},"cats":{"new-dataset":0.0386517635,"dev-research":0.3122743605,"prompt-eng":0.3832492858,"data-quality":0.1781246615,"ml-security":0.203552814}}
{"text":"To further optimize the training process, a cost-sensitive neural network approach has been proposed in order to work with imbalanced datasets which has achieved almost 4% more accuracy than the conventional models used in our experiments.","meta":{"url":"http://arxiv.org/abs/2308.00608v1"},"cats":{"new-dataset":0.0792000297,"dev-research":0.2084852303,"prompt-eng":0.3910612277,"data-quality":0.3891688973,"ml-security":0.3328650882}}
{"text":"The cost-sensitive InceptionV3 (CS-InceptionV3) and CNN (CS-CNN) show a promising accuracy of 92.31% and a recall value of 1.00 respectively on an imbalanced dataset.","meta":{"url":"http://arxiv.org/abs/2308.00608v1"},"cats":{"new-dataset":0.2221179677,"dev-research":0.2303069576,"prompt-eng":0.3548391994,"data-quality":0.388329595,"ml-security":0.3236577693}}
{"text":"The proposed models have shown great potential in improving tumor detection accuracy and must be further developed for application in practical solutions.","meta":{"url":"http://arxiv.org/abs/2308.00608v1"},"cats":{"new-dataset":0.0221072065,"dev-research":0.141971706,"prompt-eng":0.3781474878,"data-quality":0.1515755393,"ml-security":0.1053852651}}
{"text":"We have provided the datasets and made our implementations publicly available at - https://github.com/shahariar-shibli/Explainable-Cost-Sensitive-Deep-Neural-Networks-for-Brain-Tumor-Detection-from-Brain-MRI-Images","meta":{"url":"http://arxiv.org/abs/2308.00608v1"},"cats":{"new-dataset":0.4616968545,"dev-research":0.1433043311,"prompt-eng":0.3637423733,"data-quality":0.15871809,"ml-security":0.1398019159}}
{"text":"Images are loaded with semantic information that pertains to real-world ontologies: dog breeds share mammalian similarities, food pictures are often depicted in domestic environments, and so on.","meta":{"url":"http://arxiv.org/abs/2308.00607v1"},"cats":{"new-dataset":0.3368222217,"dev-research":0.2331212253,"prompt-eng":0.392606782,"data-quality":0.1671962528,"ml-security":0.0866868392}}
{"text":"However, when training machine learning models for image classification, the relative similarities amongst object classes are commonly paired with one-hot-encoded labels.","meta":{"url":"http://arxiv.org/abs/2308.00607v1"},"cats":{"new-dataset":0.0773269198,"dev-research":0.2171832519,"prompt-eng":0.391459281,"data-quality":0.3986972912,"ml-security":0.1995947662}}
{"text":"According to this logic, if an image is labelled as 'spoon', then 'tea-spoon' and 'shark' are equally wrong in terms of training loss.","meta":{"url":"http://arxiv.org/abs/2308.00607v1"},"cats":{"new-dataset":0.0190799713,"dev-research":0.1936373182,"prompt-eng":0.3383339597,"data-quality":0.522484163,"ml-security":0.1889748635}}
{"text":"To overcome this limitation, we explore the integration of additional goals that reflect ontological and semantic knowledge, improving model interpretability and trustworthiness.","meta":{"url":"http://arxiv.org/abs/2308.00607v1"},"cats":{"new-dataset":0.0825639431,"dev-research":0.326406432,"prompt-eng":0.4103259089,"data-quality":0.1848550971,"ml-security":0.1267542802}}
{"text":"We suggest a generic approach that allows to derive an additional loss term starting from any kind of semantic information about the classification label.","meta":{"url":"http://arxiv.org/abs/2308.00607v1"},"cats":{"new-dataset":0.1198482691,"dev-research":0.2224982637,"prompt-eng":0.4153595513,"data-quality":0.4457403868,"ml-security":0.144764815}}
{"text":"First, we show how to apply our approach to ontologies and word embeddings, and discuss how the resulting information can drive a supervised learning process.","meta":{"url":"http://arxiv.org/abs/2308.00607v1"},"cats":{"new-dataset":0.1888937469,"dev-research":0.2319900601,"prompt-eng":0.4252251759,"data-quality":0.2934823084,"ml-security":0.086668788}}
{"text":"Second, we use our semantically enriched loss to train image classifiers, and analyse the trade-offs between accuracy, mistake severity, and learned internal representations.","meta":{"url":"http://arxiv.org/abs/2308.00607v1"},"cats":{"new-dataset":0.1649358636,"dev-research":0.2607928985,"prompt-eng":0.3775904289,"data-quality":0.5140162228,"ml-security":0.18220365}}
{"text":"Finally, we discuss how this approach can be further exploited in terms of explainability and adversarial robustness.","meta":{"url":"http://arxiv.org/abs/2308.00607v1"},"cats":{"new-dataset":0.0445383872,"dev-research":0.2636625584,"prompt-eng":0.3648906292,"data-quality":0.3908929556,"ml-security":0.6830143655}}
{"text":"Code repository: https://github.com/S1M0N38/semantic-encodings","meta":{"url":"http://arxiv.org/abs/2308.00607v1"},"cats":{"new-dataset":0.2653870684,"dev-research":0.2631528356,"prompt-eng":0.4298849924,"data-quality":0.3202340449,"ml-security":0.0674788083}}
{"text":"Bluetooth Low Energy (BLE) Mesh is widely recognized as a driver technology for IoT applications.","meta":{"url":"http://arxiv.org/abs/2308.00599v1"},"cats":{"new-dataset":0.0907014222,"dev-research":0.2654708752,"prompt-eng":0.3897135217,"data-quality":0.0612892037,"ml-security":0.0595948996}}
{"text":"However, the lack of quality of service (QoS) in BLE Mesh, represented by packet prioritization, significantly limits its potential.","meta":{"url":"http://arxiv.org/abs/2308.00599v1"},"cats":{"new-dataset":0.0263866344,"dev-research":0.2293605843,"prompt-eng":0.3569923946,"data-quality":0.1103972834,"ml-security":0.1347112962}}
{"text":"This work implements a quality-of-service (QoS) method for BLE Mesh to prioritize the data packets and provide them with different network transmission settings according to their assigned priority.","meta":{"url":"http://arxiv.org/abs/2308.00599v1"},"cats":{"new-dataset":0.074292447,"dev-research":0.2406884018,"prompt-eng":0.3995707644,"data-quality":0.1100818201,"ml-security":0.0833210723}}
{"text":"Unlike existing works on QoS for BLE Mesh, our proposed approach does not require any modifications to the BLE Mesh protocol and can be smoothly adopted in existing BLE Mesh networks.","meta":{"url":"http://arxiv.org/abs/2308.00599v1"},"cats":{"new-dataset":0.082824474,"dev-research":0.1984315997,"prompt-eng":0.3806076697,"data-quality":0.0685210313,"ml-security":0.0891003964}}
{"text":"We conducted an extensive measurement campaign to evaluate our solution over a 15-node BLE Mesh network deployed to emulate a smart healthcare scenario where 45 sensors with an assigned priority transmit information over the network.","meta":{"url":"http://arxiv.org/abs/2308.00599v1"},"cats":{"new-dataset":0.2685815501,"dev-research":0.233222231,"prompt-eng":0.4309456542,"data-quality":0.0643654972,"ml-security":0.1000209068}}
{"text":"The experiments provide performance results for single and multi channel network scenarios.","meta":{"url":"http://arxiv.org/abs/2308.00599v1"},"cats":{"new-dataset":0.0388112232,"dev-research":0.2198071439,"prompt-eng":0.4081724948,"data-quality":0.1307183001,"ml-security":0.071839683}}
{"text":"The obtained results validate our solution, showing the difference between the established priorities and providing insights and guidelines to conduct further research on QoS over BLE Mesh and broadcast-based networks.","meta":{"url":"http://arxiv.org/abs/2308.00599v1"},"cats":{"new-dataset":0.0564541913,"dev-research":0.248070619,"prompt-eng":0.4035822916,"data-quality":0.1148362378,"ml-security":0.1023598369}}
{"text":"Autonomous driving perception tasks rely heavily on cameras as the primary sensor for Object Detection, Semantic Segmentation, Instance Segmentation, and Object Tracking.","meta":{"url":"http://arxiv.org/abs/2308.00596v1"},"cats":{"new-dataset":0.1455194558,"dev-research":0.2253312698,"prompt-eng":0.3622667328,"data-quality":0.1800839595,"ml-security":0.1758134949}}
{"text":"However, RGB images captured by cameras lack depth information, which poses a significant challenge in 3D detection tasks.","meta":{"url":"http://arxiv.org/abs/2308.00596v1"},"cats":{"new-dataset":0.11081501,"dev-research":0.1825971755,"prompt-eng":0.3398282317,"data-quality":0.2363795817,"ml-security":0.144228754}}
{"text":"To supplement this missing data, mapping sensors such as LIDAR and RADAR are used for accurate 3D Object Detection.","meta":{"url":"http://arxiv.org/abs/2308.00596v1"},"cats":{"new-dataset":0.1089371441,"dev-research":0.2156054162,"prompt-eng":0.352972838,"data-quality":0.1624923844,"ml-security":0.1149015012}}
{"text":"Despite their significant accuracy, the multi-sensor models are expensive and require a high computational demand.","meta":{"url":"http://arxiv.org/abs/2308.00596v1"},"cats":{"new-dataset":0.1000670553,"dev-research":0.1649679806,"prompt-eng":0.3949926431,"data-quality":0.0662766579,"ml-security":0.0485740532}}
{"text":"In contrast, Monocular 3D Object Detection models are becoming increasingly popular, offering a faster, cheaper, and easier-to-implement solution for 3D detections.","meta":{"url":"http://arxiv.org/abs/2308.00596v1"},"cats":{"new-dataset":0.0511332073,"dev-research":0.1854830608,"prompt-eng":0.374353098,"data-quality":0.1262491088,"ml-security":0.1160297262}}
{"text":"This paper introduces a different Multi-Tasking Learning approach called MonoNext that utilizes a spatial grid to map objects in the scene.","meta":{"url":"http://arxiv.org/abs/2308.00596v1"},"cats":{"new-dataset":0.1864030735,"dev-research":0.2652056999,"prompt-eng":0.3903655026,"data-quality":0.134858804,"ml-security":0.0578388349}}
{"text":"MonoNext employs a straightforward approach based on the ConvNext network and requires only 3D bounding box annotated data.","meta":{"url":"http://arxiv.org/abs/2308.00596v1"},"cats":{"new-dataset":0.4391745113,"dev-research":0.2814399115,"prompt-eng":0.3858266539,"data-quality":0.1394021531,"ml-security":0.064261427}}
{"text":"In our experiments with the KITTI dataset, MonoNext achieved high precision and competitive performance comparable with state-of-the-art approaches.","meta":{"url":"http://arxiv.org/abs/2308.00596v1"},"cats":{"new-dataset":0.1953602545,"dev-research":0.2684713286,"prompt-eng":0.4022341731,"data-quality":0.1640705595,"ml-security":0.045393085}}
{"text":"Furthermore, by adding more training data, MonoNext surpassed itself and achieved higher accuracies.","meta":{"url":"http://arxiv.org/abs/2308.00596v1"},"cats":{"new-dataset":0.0347671577,"dev-research":0.3022639646,"prompt-eng":0.3435782376,"data-quality":0.1764027411,"ml-security":0.0741478188}}
{"text":"Low-light hazy scenes commonly appear at dusk and early morning.","meta":{"url":"http://arxiv.org/abs/2308.00591v1"},"cats":{"new-dataset":0.2726361278,"dev-research":0.2250629559,"prompt-eng":0.3615617788,"data-quality":0.2258074119,"ml-security":0.1032969855}}
{"text":"The visual enhancement for low-light hazy images is an ill-posed problem.","meta":{"url":"http://arxiv.org/abs/2308.00591v1"},"cats":{"new-dataset":0.0646841591,"dev-research":0.2658930608,"prompt-eng":0.3289882632,"data-quality":0.2006574785,"ml-security":0.1120577205}}
{"text":"Even though numerous methods have been proposed for image dehazing and low-light enhancement respectively, simply integrating them cannot deliver pleasing results for this particular task.","meta":{"url":"http://arxiv.org/abs/2308.00591v1"},"cats":{"new-dataset":0.0836365355,"dev-research":0.2577588615,"prompt-eng":0.3638706728,"data-quality":0.1309133695,"ml-security":0.071103692}}
{"text":"In this paper, we present a novel method to enhance visibility for low-light hazy scenarios.","meta":{"url":"http://arxiv.org/abs/2308.00591v1"},"cats":{"new-dataset":0.138493532,"dev-research":0.2644175839,"prompt-eng":0.4028717797,"data-quality":0.1338654715,"ml-security":0.1081011724}}
{"text":"To handle this challenging task, we propose two key techniques, namely cross-consistency dehazing-enhancement framework and physically based simulation for low-light hazy dataset.","meta":{"url":"http://arxiv.org/abs/2308.00591v1"},"cats":{"new-dataset":0.3612015099,"dev-research":0.305758658,"prompt-eng":0.3266108661,"data-quality":0.1416496735,"ml-security":0.0866682386}}
{"text":"Specifically, the framework is designed for enhancing visibility of the input image via fully utilizing the clues from different sub-tasks.","meta":{"url":"http://arxiv.org/abs/2308.00591v1"},"cats":{"new-dataset":0.1655187239,"dev-research":0.3020440653,"prompt-eng":0.455037304,"data-quality":0.153941598,"ml-security":0.0852386425}}
{"text":"The simulation is designed for generating the dataset with ground-truths by the proposed low-light hazy imaging model.","meta":{"url":"http://arxiv.org/abs/2308.00591v1"},"cats":{"new-dataset":0.6451177616,"dev-research":0.2053141329,"prompt-eng":0.3542270458,"data-quality":0.1352991936,"ml-security":0.0903554999}}
{"text":"The extensive experimental results show that the proposed method outperforms the SOTA solutions on different metrics including SSIM (9.19%) and PSNR(5.03%).","meta":{"url":"http://arxiv.org/abs/2308.00591v1"},"cats":{"new-dataset":0.0640936216,"dev-research":0.1709355471,"prompt-eng":0.4058244673,"data-quality":0.114337715,"ml-security":0.0366667981}}
{"text":"In addition, we conduct a user study on real images to demonstrate the effectiveness and necessity of the proposed method by human visual perception.","meta":{"url":"http://arxiv.org/abs/2308.00591v1"},"cats":{"new-dataset":0.053686922,"dev-research":0.2737200565,"prompt-eng":0.4279048529,"data-quality":0.1773536076,"ml-security":0.0553992621}}
{"text":"Consensus algorithms facilitate agreement on and resolution of blockchain functions, such as smart contracts and transactions.","meta":{"url":"http://arxiv.org/abs/2308.00590v1"},"cats":{"new-dataset":0.02723961,"dev-research":0.3296827441,"prompt-eng":0.322223278,"data-quality":0.1471770309,"ml-security":0.1156707056}}
{"text":"Ethereum uses a Proof-of-Stake (PoS) consensus mechanism, which depends on financial incentives to ensure that validators perform certain duties and do not act maliciously.","meta":{"url":"http://arxiv.org/abs/2308.00590v1"},"cats":{"new-dataset":0.0133822419,"dev-research":0.2875872812,"prompt-eng":0.3865687587,"data-quality":0.1723606497,"ml-security":0.2495521818}}
{"text":"Should a validator attempt to defraud the system, legitimate validators will identify this and then staked cryptocurrency is `burned' through a process of slashing.   ","meta":{"url":"http://arxiv.org/abs/2308.00590v1"},"cats":{"new-dataset":0.0140267951,"dev-research":0.2990894025,"prompt-eng":0.3810656415,"data-quality":0.3408224091,"ml-security":0.4073015191}}
{"text":"In this paper, we show that an attacker who has compromised a set of validators could threaten to perform malicious actions that would result in slashing and thus, hold those validators to ransom.","meta":{"url":"http://arxiv.org/abs/2308.00590v1"},"cats":{"new-dataset":0.04879371,"dev-research":0.3314926775,"prompt-eng":0.4218385254,"data-quality":0.32749381,"ml-security":0.825136145}}
{"text":"We use game theory to study how an attacker can coerce payment from a victim, for example by deploying a smart contract to provide a root of trust shared between attacker and victim during the extortion process.","meta":{"url":"http://arxiv.org/abs/2308.00590v1"},"cats":{"new-dataset":0.1094289204,"dev-research":0.3042582595,"prompt-eng":0.3811611353,"data-quality":0.142796807,"ml-security":0.6846959261}}
{"text":"Our game theoretic model finds that it is in the interests of the validators to fully pay the ransom due to a lack of systemic protections for validators.","meta":{"url":"http://arxiv.org/abs/2308.00590v1"},"cats":{"new-dataset":0.0465691422,"dev-research":0.2736257027,"prompt-eng":0.3571382464,"data-quality":0.1306665451,"ml-security":0.4658053544}}
{"text":"Financial risk is solely placed on the victim during such an attack, with no mitigations available to them aside from capitulation (payment of ransom) in many scenarios.","meta":{"url":"http://arxiv.org/abs/2308.00590v1"},"cats":{"new-dataset":0.0350623381,"dev-research":0.1953420336,"prompt-eng":0.2681694821,"data-quality":0.1062626913,"ml-security":0.662150414}}
{"text":"Such attacks could be disruptive to Ethereum and, likely, to many other PoS networks, if public trust in the validator system is eroded.","meta":{"url":"http://arxiv.org/abs/2308.00590v1"},"cats":{"new-dataset":0.0083331778,"dev-research":0.2475239965,"prompt-eng":0.3810548002,"data-quality":0.3100634997,"ml-security":0.7771106121}}
{"text":"We also discuss and evaluate potential mitigation measures arising from our analysis of the game theoretic model.","meta":{"url":"http://arxiv.org/abs/2308.00590v1"},"cats":{"new-dataset":0.0776050508,"dev-research":0.2404464179,"prompt-eng":0.400402233,"data-quality":0.1133497398,"ml-security":0.3658945622}}
{"text":"Person clustering with multi-modal clues, including faces, bodies, and voices, is critical for various tasks, such as movie parsing and identity-based movie editing.","meta":{"url":"http://arxiv.org/abs/2308.00588v1"},"cats":{"new-dataset":0.0875331001,"dev-research":0.260459076,"prompt-eng":0.3852696478,"data-quality":0.2056827925,"ml-security":0.099335671}}
{"text":"Related methods such as multi-view clustering mainly project multi-modal features into a joint feature space.","meta":{"url":"http://arxiv.org/abs/2308.00588v1"},"cats":{"new-dataset":0.090667457,"dev-research":0.2891020419,"prompt-eng":0.3756248766,"data-quality":0.1598974193,"ml-security":0.0540277986}}
{"text":"However, multi-modal clue features are usually rather weakly correlated due to the semantic gap from the modality-specific uniqueness.","meta":{"url":"http://arxiv.org/abs/2308.00588v1"},"cats":{"new-dataset":0.0406218203,"dev-research":0.272544679,"prompt-eng":0.3616179449,"data-quality":0.3309915049,"ml-security":0.1006683256}}
{"text":"As a result, these methods are not suitable for person clustering.","meta":{"url":"http://arxiv.org/abs/2308.00588v1"},"cats":{"new-dataset":0.023644477,"dev-research":0.2074225162,"prompt-eng":0.3126380022,"data-quality":0.3389060439,"ml-security":0.1352650573}}
{"text":"In this paper, we propose a Relation-Aware Distribution representation Network (RAD-Net) to generate a distribution representation for multi-modal clues.","meta":{"url":"http://arxiv.org/abs/2308.00588v1"},"cats":{"new-dataset":0.2383586666,"dev-research":0.2853881992,"prompt-eng":0.4385506164,"data-quality":0.2543602236,"ml-security":0.0848163493}}
{"text":"The distribution representation of a clue is a vector consisting of the relation between this clue and all other clues from all modalities, thus being modality agnostic and good for person clustering.","meta":{"url":"http://arxiv.org/abs/2308.00588v1"},"cats":{"new-dataset":0.0970183272,"dev-research":0.226721467,"prompt-eng":0.3817697029,"data-quality":0.2259404039,"ml-security":0.1412194534}}
{"text":"Accordingly, we introduce a graph-based method to construct distribution representation and employ a cyclic update policy to refine distribution representation progressively.","meta":{"url":"http://arxiv.org/abs/2308.00588v1"},"cats":{"new-dataset":0.0923429164,"dev-research":0.3386836451,"prompt-eng":0.4565848497,"data-quality":0.2019634178,"ml-security":0.0868937478}}
{"text":"Our method achieves substantial improvements of +6% and","meta":{"url":"http://arxiv.org/abs/2308.00588v1"},"cats":{"new-dataset":0.045281512,"dev-research":0.2727075912,"prompt-eng":0.4201382202,"data-quality":0.2093837343,"ml-security":0.0687998758}}
{"text":"+8.2% in F-score on the Video Person-Clustering Dataset (VPCD) and VoxCeleb2 multi-view clustering dataset, respectively.","meta":{"url":"http://arxiv.org/abs/2308.00588v1"},"cats":{"new-dataset":0.4354489622,"dev-research":0.1833564942,"prompt-eng":0.331735832,"data-quality":0.2081670422,"ml-security":0.0649942627}}
{"text":"Codes will be released publicly upon acceptance.","meta":{"url":"http://arxiv.org/abs/2308.00588v1"},"cats":{"new-dataset":0.2241397409,"dev-research":0.2501361574,"prompt-eng":0.3841374036,"data-quality":0.2053049613,"ml-security":0.1931999396}}
{"text":"In applications such as search and rescue or disaster relief, heterogeneous multi-robot systems (MRS) can provide significant advantages for complex objectives that require a suite of capabilities.","meta":{"url":"http://arxiv.org/abs/2308.00579v1"},"cats":{"new-dataset":0.040489361,"dev-research":0.1995427516,"prompt-eng":0.3628619965,"data-quality":0.036836973,"ml-security":0.0449428534}}
{"text":"However, within these application spaces, communication is often unreliable, causing inefficiencies or outright failures to arise in most MRS algorithms.","meta":{"url":"http://arxiv.org/abs/2308.00579v1"},"cats":{"new-dataset":0.019973934,"dev-research":0.3689110722,"prompt-eng":0.3850889127,"data-quality":0.2421894499,"ml-security":0.1874718905}}
{"text":"Many researchers tackle this problem by requiring all robots to either maintain communication using proximity constraints or assuming that all robots will execute a predetermined plan over long periods of disconnection.","meta":{"url":"http://arxiv.org/abs/2308.00579v1"},"cats":{"new-dataset":0.1075260305,"dev-research":0.2437543287,"prompt-eng":0.444663109,"data-quality":0.0820720588,"ml-security":0.1369030051}}
{"text":"The latter method allows for higher levels of efficiency in a MRS, but failures and environmental uncertainties can have cascading effects across the system, especially when a mission objective is complex or time-sensitive.","meta":{"url":"http://arxiv.org/abs/2308.00579v1"},"cats":{"new-dataset":0.0141399238,"dev-research":0.380092025,"prompt-eng":0.4402023061,"data-quality":0.1437593494,"ml-security":0.1041072554}}
{"text":"To solve this, we propose an epistemic planning framework that allows robots to reason about the system state, leverage heterogeneous system makeups, and optimize information dissemination to disconnected neighbors.","meta":{"url":"http://arxiv.org/abs/2308.00579v1"},"cats":{"new-dataset":0.2722761813,"dev-research":0.3474972181,"prompt-eng":0.4445796162,"data-quality":0.1465164543,"ml-security":0.0958775123}}
{"text":"Dynamic epistemic logic formalizes the propagation of belief states, and epistemic task allocation and gossip is accomplished via a mixed integer program using the belief states for utility predictions and planning.","meta":{"url":"http://arxiv.org/abs/2308.00579v1"},"cats":{"new-dataset":0.0849135644,"dev-research":0.3183225048,"prompt-eng":0.474028986,"data-quality":0.1095880226,"ml-security":0.110510066}}
{"text":"The proposed framework is validated using simulations and experiments with heterogeneous vehicles.","meta":{"url":"http://arxiv.org/abs/2308.00579v1"},"cats":{"new-dataset":0.0543034398,"dev-research":0.2147207112,"prompt-eng":0.4007032862,"data-quality":0.0703622135,"ml-security":0.046142755}}
{"text":"Efficient and accurate 3D object shape reconstruction contributes significantly to the success of a robot's physical interaction with its environment.","meta":{"url":"http://arxiv.org/abs/2308.00576v1"},"cats":{"new-dataset":0.0608061209,"dev-research":0.2905477936,"prompt-eng":0.4071138921,"data-quality":0.0762936398,"ml-security":0.068944692}}
{"text":"Acquiring accurate shape information about unknown objects is challenging, especially in unstructured environments, e.g. the vision sensors may only be able to provide a partial view.","meta":{"url":"http://arxiv.org/abs/2308.00576v1"},"cats":{"new-dataset":0.1037964009,"dev-research":0.1622437781,"prompt-eng":0.3857992583,"data-quality":0.1447130045,"ml-security":0.1122911584}}
{"text":"To address this issue, tactile sensors could be employed to extract local surface information for more robust unknown object shape estimation.","meta":{"url":"http://arxiv.org/abs/2308.00576v1"},"cats":{"new-dataset":0.0952826435,"dev-research":0.1903025982,"prompt-eng":0.4574174092,"data-quality":0.1289317139,"ml-security":0.1261197263}}
{"text":"In this paper, we propose a novel approach for efficient unknown 3D object shape exploration and reconstruction using a multi-fingered hand equipped with tactile sensors and a depth camera only providing a partial view.","meta":{"url":"http://arxiv.org/abs/2308.00576v1"},"cats":{"new-dataset":0.2260382056,"dev-research":0.1824016873,"prompt-eng":0.372829942,"data-quality":0.0674953487,"ml-security":0.0817426166}}
{"text":"We present a multi-finger sliding touch strategy for efficient shape exploration using a Bayesian Optimization approach and a single-leader-multi-follower strategy for multi-finger smooth local surface perception.","meta":{"url":"http://arxiv.org/abs/2308.00576v1"},"cats":{"new-dataset":0.105802371,"dev-research":0.2189177997,"prompt-eng":0.4267038548,"data-quality":0.0446749957,"ml-security":0.0504810004}}
{"text":"We evaluate our proposed method by estimating the 3D shape of objects from the YCB and OCRTOC datasets based on simulation and real robot experiments.","meta":{"url":"http://arxiv.org/abs/2308.00576v1"},"cats":{"new-dataset":0.3803988339,"dev-research":0.1787943745,"prompt-eng":0.3966608332,"data-quality":0.0893213472,"ml-security":0.0469514432}}
{"text":"The proposed approach yields successful reconstruction results relying on only a few continuous sliding touches.","meta":{"url":"http://arxiv.org/abs/2308.00576v1"},"cats":{"new-dataset":0.200521657,"dev-research":0.1586497857,"prompt-eng":0.3639492363,"data-quality":0.0710449454,"ml-security":0.0411327539}}
{"text":"Experimental results demonstrate that our method is able to model unknown objects in an efficient and accurate way.","meta":{"url":"http://arxiv.org/abs/2308.00576v1"},"cats":{"new-dataset":0.0690735175,"dev-research":0.1709492903,"prompt-eng":0.425401108,"data-quality":0.2006833727,"ml-security":0.110619078}}
{"text":"Convolution-based and Transformer-based vision backbone networks process images into the grid or sequence structures, respectively, which are inflexible for capturing irregular objects.","meta":{"url":"http://arxiv.org/abs/2308.00574v1"},"cats":{"new-dataset":0.2417746508,"dev-research":0.2111255985,"prompt-eng":0.3386290551,"data-quality":0.1311905366,"ml-security":0.1083166548}}
{"text":"Though Vision GNN (ViG) adopts graph-level features for complex images, it has some issues, such as inaccurate neighbor node selection, expensive node information aggregation calculation, and over-smoothing in the deep layers.","meta":{"url":"http://arxiv.org/abs/2308.00574v1"},"cats":{"new-dataset":0.0831550723,"dev-research":0.297532927,"prompt-eng":0.3161078788,"data-quality":0.2239022537,"ml-security":0.0986762548}}
{"text":"To address the above problems, we propose a Progressive Vision Graph (PVG) architecture for vision recognition task.","meta":{"url":"http://arxiv.org/abs/2308.00574v1"},"cats":{"new-dataset":0.1382202598,"dev-research":0.212076632,"prompt-eng":0.3693921815,"data-quality":0.2163639699,"ml-security":0.0560323494}}
{"text":"Compared with previous works, PVG contains three main components: 1) Progressively Separated Graph Construction (PSGC) to introduce second-order similarity by gradually increasing the channel of the global graph branch and decreasing the channel of local branch as the layer deepens; 2) Neighbor nodes information aggregation and update module by using Max pooling and mathematical Expectation (MaxE) to aggregate rich neighbor information; 3) Graph error Linear Unit (GraphLU) to enhance low-value information in a relaxed form to reduce the compression of image detail information for alleviating the over-smoothing.","meta":{"url":"http://arxiv.org/abs/2308.00574v1"},"cats":{"new-dataset":0.0964091681,"dev-research":0.2663580929,"prompt-eng":0.3599978313,"data-quality":0.1457282379,"ml-security":0.0316885594}}
{"text":"Extensive experiments on mainstream benchmarks demonstrate the superiority of PVG over state-of-the-art methods, e.g., our PVG-S obtains 83.0% Top-1 accuracy on ImageNet-1K that surpasses GNN-based ViG-S by +0.9 with the parameters reduced by 18.5%, while the largest PVG-B obtains 84.2% that has +0.5 improvement than","meta":{"url":"http://arxiv.org/abs/2308.00574v1"},"cats":{"new-dataset":0.1258897746,"dev-research":0.2175048081,"prompt-eng":0.3695784563,"data-quality":0.2760107831,"ml-security":0.0790932903}}
{"text":"ViG-B. Furthermore, our PVG-S obtains +1.3 box AP and +0.4 mask AP gains than ViG-S on COCO dataset.","meta":{"url":"http://arxiv.org/abs/2308.00574v1"},"cats":{"new-dataset":0.1391170251,"dev-research":0.1691372884,"prompt-eng":0.3791845379,"data-quality":0.1802316669,"ml-security":0.1103810105}}
{"text":"The recent increase in data availability and reliability has led to a surge in the development of learning-based model predictive control (MPC) frameworks for robot systems.","meta":{"url":"http://arxiv.org/abs/2308.00570v1"},"cats":{"new-dataset":0.167021458,"dev-research":0.2277113366,"prompt-eng":0.3995869716,"data-quality":0.0979417861,"ml-security":0.141920308}}
{"text":"Despite attaining substantial performance improvements over their non-learning counterparts, many of these frameworks rely on an offline learning procedure to synthesize a dynamics model.","meta":{"url":"http://arxiv.org/abs/2308.00570v1"},"cats":{"new-dataset":0.0987510198,"dev-research":0.200940324,"prompt-eng":0.3658891836,"data-quality":0.0834541354,"ml-security":0.1159627327}}
{"text":"This implies that uncertainties encountered by the robot during deployment are not accounted for in the learning process.","meta":{"url":"http://arxiv.org/abs/2308.00570v1"},"cats":{"new-dataset":0.022732111,"dev-research":0.3396045935,"prompt-eng":0.3957760752,"data-quality":0.3537228145,"ml-security":0.2248386765}}
{"text":"On the other hand, learning-based MPC methods that learn dynamics models online are computationally expensive and often require a significant amount of data.","meta":{"url":"http://arxiv.org/abs/2308.00570v1"},"cats":{"new-dataset":0.0771865657,"dev-research":0.2235418268,"prompt-eng":0.3166524859,"data-quality":0.0885056559,"ml-security":0.1346010246}}
{"text":"To alleviate these shortcomings, we propose a novel learning-enhanced MPC framework that incorporates components from $\\mathcal{L}_1$ adaptive control into learning-based MPC.","meta":{"url":"http://arxiv.org/abs/2308.00570v1"},"cats":{"new-dataset":0.1048188917,"dev-research":0.2733041761,"prompt-eng":0.416797338,"data-quality":0.1766902562,"ml-security":0.1107654716}}
{"text":"This integration enables the accurate compensation of both matched and unmatched uncertainties in a sample-efficient way, enhancing the control performance during deployment.","meta":{"url":"http://arxiv.org/abs/2308.00570v1"},"cats":{"new-dataset":0.0534351388,"dev-research":0.4200313909,"prompt-eng":0.5216385358,"data-quality":0.2943710892,"ml-security":0.1088318487}}
{"text":"In our proposed framework, we present two variants and apply them to the control of a quadrotor system.","meta":{"url":"http://arxiv.org/abs/2308.00570v1"},"cats":{"new-dataset":0.1076200498,"dev-research":0.2269305276,"prompt-eng":0.3954184532,"data-quality":0.0539069468,"ml-security":0.0800309363}}
{"text":"Through simulations and physical experiments, we demonstrate that the proposed framework not only allows the synthesis of an accurate dynamics model on-the-fly, but also significantly improves the closed-loop control performance under a wide range of spatio-temporal uncertainties.","meta":{"url":"http://arxiv.org/abs/2308.00570v1"},"cats":{"new-dataset":0.1631983896,"dev-research":0.3197738099,"prompt-eng":0.3840848209,"data-quality":0.0946880007,"ml-security":0.1219279536}}
{"text":"Utilizing wind hovering techniques of soaring birds can save energy expenditure and improve the flight endurance of micro air vehicles (MAVs).","meta":{"url":"http://arxiv.org/abs/2308.00565v1"},"cats":{"new-dataset":0.0323500579,"dev-research":0.315234452,"prompt-eng":0.3644345034,"data-quality":0.0706044714,"ml-security":0.0713373836}}
{"text":"Here, we present a novel method for fully autonomous orographic soaring without a priori knowledge of the wind field.","meta":{"url":"http://arxiv.org/abs/2308.00565v1"},"cats":{"new-dataset":0.061176631,"dev-research":0.2132343803,"prompt-eng":0.3670809985,"data-quality":0.0473431426,"ml-security":0.0692783154}}
{"text":"Specifically, we devise an Incremental Nonlinear Dynamic Inversion (INDI) controller with control allocation, adapting it for autonomous soaring.","meta":{"url":"http://arxiv.org/abs/2308.00565v1"},"cats":{"new-dataset":0.0630040909,"dev-research":0.2385302871,"prompt-eng":0.3611706633,"data-quality":0.0454734868,"ml-security":0.1130173872}}
{"text":"This allows for both soaring and the use of the throttle if necessary, without changing any gain or parameter during the flight.","meta":{"url":"http://arxiv.org/abs/2308.00565v1"},"cats":{"new-dataset":0.0019952721,"dev-research":0.2964217815,"prompt-eng":0.3388865726,"data-quality":0.0670011516,"ml-security":0.142020413}}
{"text":"Furthermore, we propose a simulated-annealing-based optimization method to search for soaring positions.","meta":{"url":"http://arxiv.org/abs/2308.00565v1"},"cats":{"new-dataset":0.0375803573,"dev-research":0.2024798242,"prompt-eng":0.3851076459,"data-quality":0.0624726226,"ml-security":0.0568961555}}
{"text":"This enables for the first time an MAV to autonomously find a feasible soaring position while minimizing throttle usage and other control efforts.","meta":{"url":"http://arxiv.org/abs/2308.00565v1"},"cats":{"new-dataset":0.011031363,"dev-research":0.3001286032,"prompt-eng":0.3770043816,"data-quality":0.053200336,"ml-security":0.0955638878}}
{"text":"Autonomous orographic soaring was performed in the wind tunnel.","meta":{"url":"http://arxiv.org/abs/2308.00565v1"},"cats":{"new-dataset":0.053480717,"dev-research":0.2608991343,"prompt-eng":0.3248663457,"data-quality":0.0450768928,"ml-security":0.0730849586}}
{"text":"The wind speed and incline of a ramp were changed during the soaring flight.","meta":{"url":"http://arxiv.org/abs/2308.00565v1"},"cats":{"new-dataset":0.0226871792,"dev-research":0.3033742301,"prompt-eng":0.3205952568,"data-quality":0.0796558172,"ml-security":0.0802699627}}
{"text":"The MAV was able to perform autonomous orographic soaring for flight times of up to 30 minutes.","meta":{"url":"http://arxiv.org/abs/2308.00565v1"},"cats":{"new-dataset":0.0520186386,"dev-research":0.1958700114,"prompt-eng":0.3327904051,"data-quality":0.0454379606,"ml-security":0.0554791895}}
{"text":"The mean throttle usage was only 0.25% for the entire soaring flight, whereas normal powered flight requires 38%.","meta":{"url":"http://arxiv.org/abs/2308.00565v1"},"cats":{"new-dataset":0.0064808794,"dev-research":0.2252997668,"prompt-eng":0.3076171847,"data-quality":0.1031603235,"ml-security":0.0598850348}}
{"text":"Also, it was shown that the MAV can find a new soaring spot when the wind field changes during the flight.","meta":{"url":"http://arxiv.org/abs/2308.00565v1"},"cats":{"new-dataset":0.0620410454,"dev-research":0.2279240068,"prompt-eng":0.3347236665,"data-quality":0.1106820148,"ml-security":0.0821780492}}
{"text":"The Traveling Salesman Problem (TSP) is a well-known problem in combinatorial optimization with applications in various domains.","meta":{"url":"http://arxiv.org/abs/2308.00560v1"},"cats":{"new-dataset":0.1457349669,"dev-research":0.1743121932,"prompt-eng":0.3781407128,"data-quality":0.1083170948,"ml-security":0.0840543775}}
{"text":"However, existing TSP solvers face challenges in producing high-quality solutions with low latency.","meta":{"url":"http://arxiv.org/abs/2308.00560v1"},"cats":{"new-dataset":0.0861954501,"dev-research":0.3874219807,"prompt-eng":0.4084558209,"data-quality":0.0960418413,"ml-security":0.0556747323}}
{"text":"To address this issue, we propose NAR4TSP, which produces TSP solutions in a Non-Autoregressive (NAR) manner using a specially designed Graph Neural Network (GNN), achieving faster inference speed.","meta":{"url":"http://arxiv.org/abs/2308.00560v1"},"cats":{"new-dataset":0.2035486979,"dev-research":0.2163730149,"prompt-eng":0.3867496705,"data-quality":0.1644749287,"ml-security":0.0840649361}}
{"text":"Moreover, NAR4TSP is trained using an enhanced Reinforcement Learning (RL) strategy, eliminating the dependency on costly labels used to train conventional supervised learning-based NAR models.","meta":{"url":"http://arxiv.org/abs/2308.00560v1"},"cats":{"new-dataset":0.049909489,"dev-research":0.2374208914,"prompt-eng":0.4131484655,"data-quality":0.1759760292,"ml-security":0.0972454586}}
{"text":"To the best of our knowledge, NAR4TSP is the first TSP solver that successfully combines RL and NAR decoding.","meta":{"url":"http://arxiv.org/abs/2308.00560v1"},"cats":{"new-dataset":0.2388638239,"dev-research":0.2453497594,"prompt-eng":0.4002233934,"data-quality":0.1022211234,"ml-security":0.0484582452}}
{"text":"The experimental results on both synthetic and real-world TSP instances demonstrate that NAR4TSP outperforms four state-of-the-art models in terms of solution quality, inference latency, and generalization ability.","meta":{"url":"http://arxiv.org/abs/2308.00560v1"},"cats":{"new-dataset":0.0949917815,"dev-research":0.3164999887,"prompt-eng":0.4376911306,"data-quality":0.1238689991,"ml-security":0.0580416572}}
{"text":"Lastly, we present visualizations of NAR4TSP's decoding process and its overall path planning to showcase the feasibility of implementing NAR4TSP in an end-to-end manner and its effectiveness, respectively.","meta":{"url":"http://arxiv.org/abs/2308.00560v1"},"cats":{"new-dataset":0.2504372495,"dev-research":0.3194596823,"prompt-eng":0.459003456,"data-quality":0.1385594065,"ml-security":0.0537084141}}
{"text":"Deep spiking neural networks (SNNs) are promising neural networks for their model capacity from deep neural network architecture and energy efficiency from SNNs' operations.","meta":{"url":"http://arxiv.org/abs/2308.00558v1"},"cats":{"new-dataset":0.1180685265,"dev-research":0.2651929869,"prompt-eng":0.3428105526,"data-quality":0.0864396053,"ml-security":0.1942177095}}
{"text":"To train deep SNNs, recently, spatio-temporal backpropagation (STBP) with surrogate gradient was proposed.","meta":{"url":"http://arxiv.org/abs/2308.00558v1"},"cats":{"new-dataset":0.1919320755,"dev-research":0.1970971463,"prompt-eng":0.3337025718,"data-quality":0.1287983487,"ml-security":0.202965345}}
{"text":"Although deep SNNs have been successfully trained with STBP, they cannot fully utilize spike information.","meta":{"url":"http://arxiv.org/abs/2308.00558v1"},"cats":{"new-dataset":0.0394713166,"dev-research":0.1878869408,"prompt-eng":0.3213625889,"data-quality":0.2853063977,"ml-security":0.2883267974}}
{"text":"In this work, we proposed gradient scaling with local spike information, which is the relation between pre- and post-synaptic spikes.","meta":{"url":"http://arxiv.org/abs/2308.00558v1"},"cats":{"new-dataset":0.04620922,"dev-research":0.2108095653,"prompt-eng":0.3910050111,"data-quality":0.183490018,"ml-security":0.1652238866}}
{"text":"Considering the causality between spikes, we could enhance the training performance of deep SNNs.","meta":{"url":"http://arxiv.org/abs/2308.00558v1"},"cats":{"new-dataset":0.1023172594,"dev-research":0.2512726546,"prompt-eng":0.3448725906,"data-quality":0.2694086536,"ml-security":0.3351292532}}
{"text":"According to our experiments, we could achieve higher accuracy with lower spikes by adopting the gradient scaling on image classification tasks, such as CIFAR10 and CIFAR100.","meta":{"url":"http://arxiv.org/abs/2308.00558v1"},"cats":{"new-dataset":0.1034356654,"dev-research":0.2054661344,"prompt-eng":0.3928558984,"data-quality":0.3682173539,"ml-security":0.1359473404}}
{"text":"Federated Learning (FL) has become very popular since it enables clients to train a joint model collaboratively without sharing their private data.","meta":{"url":"http://arxiv.org/abs/2308.00553v1"},"cats":{"new-dataset":0.1237572343,"dev-research":0.2148677844,"prompt-eng":0.3571396754,"data-quality":0.1154253119,"ml-security":0.1958960834}}
{"text":"However, FL has been shown to be susceptible to backdoor and inference attacks.","meta":{"url":"http://arxiv.org/abs/2308.00553v1"},"cats":{"new-dataset":0.0777902366,"dev-research":0.2549141516,"prompt-eng":0.3713935445,"data-quality":0.2192314428,"ml-security":0.6213051476}}
{"text":"While in the former, the adversary injects manipulated updates into the aggregation process; the latter leverages clients' local models to deduce their private data.","meta":{"url":"http://arxiv.org/abs/2308.00553v1"},"cats":{"new-dataset":0.0224765286,"dev-research":0.3019663564,"prompt-eng":0.3337892225,"data-quality":0.1838368999,"ml-security":0.5163319638}}
{"text":"Contemporary solutions to address the security concerns of FL are either impractical for real-world deployment due to high-performance overheads or are tailored towards addressing specific threats, for instance, privacy-preserving aggregation or backdoor defenses.","meta":{"url":"http://arxiv.org/abs/2308.00553v1"},"cats":{"new-dataset":0.0951723253,"dev-research":0.3258261187,"prompt-eng":0.4155038736,"data-quality":0.1524295023,"ml-security":0.613092091}}
{"text":"Given these limitations, our research delves into the advantages of harnessing the FPGA-based computing paradigm to overcome performance bottlenecks of software-only solutions while mitigating backdoor and inference attacks.","meta":{"url":"http://arxiv.org/abs/2308.00553v1"},"cats":{"new-dataset":0.0492552318,"dev-research":0.3726725322,"prompt-eng":0.3909689316,"data-quality":0.1079900269,"ml-security":0.5700791241}}
{"text":"We utilize FPGA-based enclaves to address inference attacks during the aggregation process of FL.","meta":{"url":"http://arxiv.org/abs/2308.00553v1"},"cats":{"new-dataset":0.0976103187,"dev-research":0.3096832613,"prompt-eng":0.3879033872,"data-quality":0.1270126777,"ml-security":0.4982389937}}
{"text":"We adopt an advanced backdoor-aware aggregation algorithm on the FPGA to counter backdoor attacks.","meta":{"url":"http://arxiv.org/abs/2308.00553v1"},"cats":{"new-dataset":0.0794056372,"dev-research":0.3112056614,"prompt-eng":0.3769180349,"data-quality":0.157783649,"ml-security":0.6544189865}}
{"text":"We implemented and evaluated our method on Xilinx VMK-180, yielding a significant speed-up of around 300 times on the IoT-Traffic dataset and more than 506 times on the CIFAR-10 dataset.","meta":{"url":"http://arxiv.org/abs/2308.00553v1"},"cats":{"new-dataset":0.5015151295,"dev-research":0.2223921322,"prompt-eng":0.3535693021,"data-quality":0.1203770435,"ml-security":0.1075083193}}
{"text":"Instance-wise feature selection and ranking methods can achieve a good selection of task-friendly features for each sample in the context of neural networks.","meta":{"url":"http://arxiv.org/abs/2308.00549v1"},"cats":{"new-dataset":0.0877409616,"dev-research":0.2726564286,"prompt-eng":0.3971243767,"data-quality":0.1947170276,"ml-security":0.1216325035}}
{"text":"However, existing approaches that assume feature subsets to be independent are imperfect when considering the dependency between features.","meta":{"url":"http://arxiv.org/abs/2308.00549v1"},"cats":{"new-dataset":0.0136952892,"dev-research":0.3592902895,"prompt-eng":0.357650898,"data-quality":0.4363833605,"ml-security":0.2635258903}}
{"text":"To address this limitation, we propose to incorporate the Gaussian copula, a powerful mathematical technique for capturing correlations between variables, into the current feature selection framework with no additional changes needed.","meta":{"url":"http://arxiv.org/abs/2308.00549v1"},"cats":{"new-dataset":0.1889753753,"dev-research":0.2414850155,"prompt-eng":0.4295364884,"data-quality":0.169505784,"ml-security":0.1012324466}}
{"text":"Experimental results on both synthetic and real datasets, in terms of performance comparison and interpretability, demonstrate that our method is capable of capturing meaningful correlations.","meta":{"url":"http://arxiv.org/abs/2308.00549v1"},"cats":{"new-dataset":0.3953418046,"dev-research":0.2880734195,"prompt-eng":0.3859852083,"data-quality":0.2706981351,"ml-security":0.0975896535}}
{"text":"Integrated sensing and communication (ISAC) has been proposed as a promising paradigm in the future wireless networks, where the spectral and hardware resources are shared to provide a considerable performance gain.","meta":{"url":"http://arxiv.org/abs/2308.00543v1"},"cats":{"new-dataset":0.0269585783,"dev-research":0.2762566961,"prompt-eng":0.397367037,"data-quality":0.1141771012,"ml-security":0.088301595}}
{"text":"It is essential to understand how sensing and communication (S\\&C) influences each other to guide the practical algorithm and system design in ISAC.","meta":{"url":"http://arxiv.org/abs/2308.00543v1"},"cats":{"new-dataset":0.0409073285,"dev-research":0.3358074024,"prompt-eng":0.4415767067,"data-quality":0.0857601503,"ml-security":0.0958337705}}
{"text":"In this paper, we investigate the performance tradeoff between S\\&C in a single-input single-output (SISO) ISAC system with finite blocklength.","meta":{"url":"http://arxiv.org/abs/2308.00543v1"},"cats":{"new-dataset":0.027636682,"dev-research":0.2408982515,"prompt-eng":0.3810469983,"data-quality":0.0786992481,"ml-security":0.1391447243}}
{"text":"In particular, we present the system model and the ISAC scheme, after which the rate-error tradeoff is introduced as the performance metric.","meta":{"url":"http://arxiv.org/abs/2308.00543v1"},"cats":{"new-dataset":0.0315363856,"dev-research":0.2769534324,"prompt-eng":0.4606461324,"data-quality":0.1894180142,"ml-security":0.1179795548}}
{"text":"Then we derive the achievability and converse bounds for the rate-error tradeoff, determining the boundary of the joint S\\&C performance.","meta":{"url":"http://arxiv.org/abs/2308.00543v1"},"cats":{"new-dataset":0.0522890358,"dev-research":0.2191436718,"prompt-eng":0.3820653914,"data-quality":0.2103243981,"ml-security":0.1395694938}}
{"text":"Furthermore, we develop the asymptotic analysis at large blocklength regime, where the performance tradeoff between S\\&C is proved to vanish as the blocklength tends to infinity.","meta":{"url":"http://arxiv.org/abs/2308.00543v1"},"cats":{"new-dataset":0.0681047806,"dev-research":0.1478979,"prompt-eng":0.30320653,"data-quality":0.1324541508,"ml-security":0.1604751079}}
{"text":"Finally, our theoretical analysis is consolidated by simulation results.","meta":{"url":"http://arxiv.org/abs/2308.00543v1"},"cats":{"new-dataset":0.0677688292,"dev-research":0.1425761413,"prompt-eng":0.3849202859,"data-quality":0.1086471503,"ml-security":0.0512688054}}
{"text":"Deep learning-based fine-grained network intrusion detection systems (NIDS) enable different attacks to be responded to in a fast and targeted manner with the help of large-scale labels.","meta":{"url":"http://arxiv.org/abs/2308.00542v1"},"cats":{"new-dataset":0.1244747956,"dev-research":0.2921574219,"prompt-eng":0.3427456646,"data-quality":0.2915704305,"ml-security":0.7509526606}}
{"text":"However, the cost of labeling causes insufficient labeled samples.","meta":{"url":"http://arxiv.org/abs/2308.00542v1"},"cats":{"new-dataset":0.0139335986,"dev-research":0.2515384879,"prompt-eng":0.3642730417,"data-quality":0.6335806223,"ml-security":0.1680809879}}
{"text":"Also, the real fine-grained traffic shows a long-tailed distribution with great class imbalance.","meta":{"url":"http://arxiv.org/abs/2308.00542v1"},"cats":{"new-dataset":0.1374710657,"dev-research":0.1414949195,"prompt-eng":0.338545195,"data-quality":0.243495327,"ml-security":0.2598394024}}
{"text":"These two problems often appear simultaneously, posing serious challenges to fine-grained NIDS.","meta":{"url":"http://arxiv.org/abs/2308.00542v1"},"cats":{"new-dataset":0.08667001,"dev-research":0.239775032,"prompt-eng":0.38449715,"data-quality":0.3244678226,"ml-security":0.1385323529}}
{"text":"In this work, we propose a novel semi-supervised fine-grained intrusion detection framework, SF-IDS, to achieve attack classification in the label-limited and highly class imbalanced case.","meta":{"url":"http://arxiv.org/abs/2308.00542v1"},"cats":{"new-dataset":0.2810064446,"dev-research":0.2559858351,"prompt-eng":0.3701445405,"data-quality":0.3729938252,"ml-security":0.7036353164}}
{"text":"We design a self-training backbone model called RI-1DCNN to boost the feature extraction by reconstructing the input samples into a multichannel image format.","meta":{"url":"http://arxiv.org/abs/2308.00542v1"},"cats":{"new-dataset":0.1945967531,"dev-research":0.1941708759,"prompt-eng":0.4064548063,"data-quality":0.2428303369,"ml-security":0.1221051177}}
{"text":"The uncertainty of the generated pseudo-labels is evaluated and used as a reference for pseudo-label filtering in combination with the prediction probability.","meta":{"url":"http://arxiv.org/abs/2308.00542v1"},"cats":{"new-dataset":0.0558222218,"dev-research":0.2084262074,"prompt-eng":0.4703801048,"data-quality":0.5707355221,"ml-security":0.1056760013}}
{"text":"To mitigate the effects of fine-grained class imbalance, we propose a hybrid loss function combining supervised contrastive loss and multi-weighted classification loss to obtain more compact intra-class features and clearer inter-class intervals.","meta":{"url":"http://arxiv.org/abs/2308.00542v1"},"cats":{"new-dataset":0.1465149726,"dev-research":0.202873242,"prompt-eng":0.3452820543,"data-quality":0.4465495796,"ml-security":0.2831255481}}
{"text":"Experiments show that the proposed SF-IDS achieves 3.01% and 2.71% Marco-F1 improvement on two classical datasets with 1% labeled, respectively.","meta":{"url":"http://arxiv.org/abs/2308.00542v1"},"cats":{"new-dataset":0.4826468959,"dev-research":0.17843343,"prompt-eng":0.4125898092,"data-quality":0.2832117744,"ml-security":0.0559686115}}
{"text":"This work explores capabilities of the pre-trained CLIP vision-language model to identify satellite images affected by clouds.","meta":{"url":"http://arxiv.org/abs/2308.00541v1"},"cats":{"new-dataset":0.4012075615,"dev-research":0.1878484498,"prompt-eng":0.3881634029,"data-quality":0.274088791,"ml-security":0.1521909009}}
{"text":"Several approaches to using the model to perform cloud presence detection are proposed and evaluated, including a purely zero-shot operation with text prompts and several fine-tuning approaches.","meta":{"url":"http://arxiv.org/abs/2308.00541v1"},"cats":{"new-dataset":0.0733510596,"dev-research":0.2103776552,"prompt-eng":0.4412367643,"data-quality":0.2178249958,"ml-security":0.1780330844}}
{"text":"Furthermore, the transferability of the methods across different datasets and sensor types (Sentinel-2 and Landsat-8) is tested.","meta":{"url":"http://arxiv.org/abs/2308.00541v1"},"cats":{"new-dataset":0.3073733749,"dev-research":0.1877428857,"prompt-eng":0.3984260471,"data-quality":0.1224410287,"ml-security":0.0540611792}}
{"text":"The results that CLIP can achieve non-trivial performance on the cloud presence detection task with apparent capability to generalise across sensing modalities and sensing bands.","meta":{"url":"http://arxiv.org/abs/2308.00541v1"},"cats":{"new-dataset":0.0832031076,"dev-research":0.1780957589,"prompt-eng":0.4278295459,"data-quality":0.1705285498,"ml-security":0.1440459974}}
{"text":"It is also found that a low-cost fine-tuning stage leads to a strong increase in true negative rate.","meta":{"url":"http://arxiv.org/abs/2308.00541v1"},"cats":{"new-dataset":0.010000964,"dev-research":0.2910313305,"prompt-eng":0.4003771308,"data-quality":0.2496780601,"ml-security":0.1019535697}}
{"text":"The results demonstrate that the representations learned by the CLIP model can be useful for satellite image processing tasks involving clouds.","meta":{"url":"http://arxiv.org/abs/2308.00541v1"},"cats":{"new-dataset":0.1337804913,"dev-research":0.1771151634,"prompt-eng":0.3793068218,"data-quality":0.1179461119,"ml-security":0.0696344544}}
{"text":"Federated learning (FL) is an emerging paradigm that allows a central server to train machine learning models using remote users' data.","meta":{"url":"http://arxiv.org/abs/2308.00540v1"},"cats":{"new-dataset":0.1416229947,"dev-research":0.2235670454,"prompt-eng":0.385438705,"data-quality":0.1470029423,"ml-security":0.1944692998}}
{"text":"Despite its growing popularity, FL faces challenges in preserving the privacy of local datasets, its sensitivity to poisoning attacks by malicious users, and its communication overhead.","meta":{"url":"http://arxiv.org/abs/2308.00540v1"},"cats":{"new-dataset":0.294336907,"dev-research":0.2793082567,"prompt-eng":0.3549000785,"data-quality":0.2929550051,"ml-security":0.7482490871}}
{"text":"The latter is additionally considerably dominant in large-scale networks.","meta":{"url":"http://arxiv.org/abs/2308.00540v1"},"cats":{"new-dataset":0.0326541853,"dev-research":0.2184894459,"prompt-eng":0.2751016146,"data-quality":0.1470201525,"ml-security":0.1556594156}}
{"text":"These limitations are often individually mitigated by local differential privacy (LDP) mechanisms, robust aggregation, compression, and user selection techniques, which typically come at the cost of accuracy.","meta":{"url":"http://arxiv.org/abs/2308.00540v1"},"cats":{"new-dataset":0.023793579,"dev-research":0.2667252689,"prompt-eng":0.378210072,"data-quality":0.2162125543,"ml-security":0.3375127929}}
{"text":"In this work, we present compressed private aggregation (CPA), that allows massive deployments to simultaneously communicate at extremely low bit rates while achieving privacy, anonymity, and resilience to malicious users.","meta":{"url":"http://arxiv.org/abs/2308.00540v1"},"cats":{"new-dataset":0.2096235336,"dev-research":0.2591837079,"prompt-eng":0.3725787124,"data-quality":0.162088171,"ml-security":0.4162892765}}
{"text":"CPA randomizes a codebook for compressing the data into a few bits using nested lattice quantizers, while ensuring anonymity and robustness, with a subsequent perturbation to hold LDP.","meta":{"url":"http://arxiv.org/abs/2308.00540v1"},"cats":{"new-dataset":0.25330619,"dev-research":0.2256058105,"prompt-eng":0.389511046,"data-quality":0.1938121549,"ml-security":0.2240367383}}
{"text":"The proposed CPA is proven to result in FL convergence in the same asymptotic rate as FL without privacy, compression, and robustness considerations, while satisfying both anonymity and LDP requirements.","meta":{"url":"http://arxiv.org/abs/2308.00540v1"},"cats":{"new-dataset":0.071627326,"dev-research":0.155636627,"prompt-eng":0.3479729474,"data-quality":0.1689492753,"ml-security":0.2530787007}}
{"text":"These analytical properties are empirically confirmed in a numerical study, where we demonstrate the performance gains of CPA compared with separate mechanisms for compression and privacy for training different image classification models, as well as its robustness in mitigating the harmful effects of malicious users.","meta":{"url":"http://arxiv.org/abs/2308.00540v1"},"cats":{"new-dataset":0.0724131831,"dev-research":0.1724888805,"prompt-eng":0.3608714394,"data-quality":0.3616536147,"ml-security":0.636732274}}
{"text":"In this work, we present a machine learning approach for predicting early dropouts of an active and healthy ageing app.","meta":{"url":"http://arxiv.org/abs/2308.00539v1"},"cats":{"new-dataset":0.1230701895,"dev-research":0.30749465,"prompt-eng":0.417439545,"data-quality":0.2073882867,"ml-security":0.1725961839}}
{"text":"The presented algorithms have been submitted to the IFMBE Scientific Challenge 2022, part of IUPESM WC 2022.","meta":{"url":"http://arxiv.org/abs/2308.00539v1"},"cats":{"new-dataset":0.2785925776,"dev-research":0.113627184,"prompt-eng":0.3842751151,"data-quality":0.1491207734,"ml-security":0.0373018875}}
{"text":"We have processed the given database and generated seven datasets.","meta":{"url":"http://arxiv.org/abs/2308.00539v1"},"cats":{"new-dataset":0.9188304446,"dev-research":0.1818616718,"prompt-eng":0.3834310687,"data-quality":0.1451251794,"ml-security":0.0639910541}}
{"text":"We used pre-processing techniques to construct classification models that predict the adherence of users using dynamic and static features.","meta":{"url":"http://arxiv.org/abs/2308.00539v1"},"cats":{"new-dataset":0.0546433984,"dev-research":0.372795166,"prompt-eng":0.519477388,"data-quality":0.2246778664,"ml-security":0.1398174386}}
{"text":"We submitted 11 official runs and our results show that machine learning algorithms can provide high-quality adherence predictions.","meta":{"url":"http://arxiv.org/abs/2308.00539v1"},"cats":{"new-dataset":0.1795938546,"dev-research":0.2251610704,"prompt-eng":0.4200067052,"data-quality":0.2403709842,"ml-security":0.1683494931}}
{"text":"Based on the results, the dynamic features positively influence a model's classification performance.","meta":{"url":"http://arxiv.org/abs/2308.00539v1"},"cats":{"new-dataset":0.008722303,"dev-research":0.2804274694,"prompt-eng":0.4082249061,"data-quality":0.2420492602,"ml-security":0.2205210223}}
{"text":"Due to the imbalanced nature of the dataset, we employed oversampling methods such as SMOTE and ADASYN to improve the classification performance.","meta":{"url":"http://arxiv.org/abs/2308.00539v1"},"cats":{"new-dataset":0.1923685305,"dev-research":0.209423432,"prompt-eng":0.360750625,"data-quality":0.3872526749,"ml-security":0.2228742726}}
{"text":"The oversampling approaches led to a remarkable improvement of 10\\%.","meta":{"url":"http://arxiv.org/abs/2308.00539v1"},"cats":{"new-dataset":0.0468544468,"dev-research":0.2171880607,"prompt-eng":0.3702943631,"data-quality":0.2922474406,"ml-security":0.0976560258}}
{"text":"Our methods won first place in the IFMBE Scientific Challenge 2022.","meta":{"url":"http://arxiv.org/abs/2308.00539v1"},"cats":{"new-dataset":0.1195193332,"dev-research":0.1792357036,"prompt-eng":0.3745968523,"data-quality":0.2090813328,"ml-security":0.077927947}}
{"text":"We propose PressureTransferNet, a novel method for Human Activity Recognition (HAR) using ground pressure information.","meta":{"url":"http://arxiv.org/abs/2308.00538v1"},"cats":{"new-dataset":0.364370693,"dev-research":0.1941327862,"prompt-eng":0.371453957,"data-quality":0.1312477996,"ml-security":0.0999909618}}
{"text":"Our approach generates body-specific dynamic ground pressure profiles for specific activities by leveraging existing pressure data from different individuals.","meta":{"url":"http://arxiv.org/abs/2308.00538v1"},"cats":{"new-dataset":0.469066447,"dev-research":0.2432492742,"prompt-eng":0.4297476944,"data-quality":0.0605125804,"ml-security":0.1238159725}}
{"text":"PressureTransferNet is an encoder-decoder model taking a source pressure map and a target human attribute vector as inputs, producing a new pressure map reflecting the target attribute.","meta":{"url":"http://arxiv.org/abs/2308.00538v1"},"cats":{"new-dataset":0.2199204464,"dev-research":0.2421308414,"prompt-eng":0.386332161,"data-quality":0.1414927109,"ml-security":0.1508088695}}
{"text":"To train the model, we use a sensor simulation to create a diverse dataset with various human attributes and pressure profiles.","meta":{"url":"http://arxiv.org/abs/2308.00538v1"},"cats":{"new-dataset":0.6441764916,"dev-research":0.2110402425,"prompt-eng":0.4114350792,"data-quality":0.1025809874,"ml-security":0.1225583607}}
{"text":"Evaluation on a real-world dataset shows its effectiveness in accurately transferring human attributes to ground pressure profiles across different scenarios.","meta":{"url":"http://arxiv.org/abs/2308.00538v1"},"cats":{"new-dataset":0.3658485552,"dev-research":0.2803925171,"prompt-eng":0.4380636856,"data-quality":0.1193647353,"ml-security":0.1298152007}}
{"text":"We visually confirm the fidelity of the synthesized pressure shapes using a physics-based deep learning model and achieve a binary R-square value of 0.79 on areas with ground contact.","meta":{"url":"http://arxiv.org/abs/2308.00538v1"},"cats":{"new-dataset":0.3884554003,"dev-research":0.2404509917,"prompt-eng":0.3321545419,"data-quality":0.1085090403,"ml-security":0.1496383131}}
{"text":"Validation through classification with F1 score (0.911$\\pm$0.015) on physical pressure mat data demonstrates the correctness of the synthesized pressure maps, making our method valuable for data augmentation, denoising, sensor simulation, and anomaly detection.","meta":{"url":"http://arxiv.org/abs/2308.00538v1"},"cats":{"new-dataset":0.2080219967,"dev-research":0.2898116432,"prompt-eng":0.410957697,"data-quality":0.2450377023,"ml-security":0.191560023}}
{"text":"Applications span sports science, rehabilitation, and bio-mechanics, contributing to the development of HAR systems.","meta":{"url":"http://arxiv.org/abs/2308.00538v1"},"cats":{"new-dataset":0.0301078302,"dev-research":0.2770432568,"prompt-eng":0.3517569293,"data-quality":0.0634640614,"ml-security":0.0470996499}}
{"text":"Graph Neural Networks (GNNs) have demonstrated promising results on exploiting node representations for many downstream tasks through supervised end-to-end training.","meta":{"url":"http://arxiv.org/abs/2308.00535v1"},"cats":{"new-dataset":0.1046247076,"dev-research":0.260336419,"prompt-eng":0.3349493498,"data-quality":0.2734752562,"ml-security":0.1985810843}}
{"text":"To deal with the widespread label scarcity issue in real-world applications, Graph Contrastive Learning (GCL) is leveraged to train GNNs with limited or even no labels by maximizing the mutual information between nodes in its augmented views generated from the original graph.","meta":{"url":"http://arxiv.org/abs/2308.00535v1"},"cats":{"new-dataset":0.2001910046,"dev-research":0.2510533007,"prompt-eng":0.2862858858,"data-quality":0.3400295289,"ml-security":0.2016019575}}
{"text":"However, the distribution of graphs remains unconsidered in view generation, resulting in the ignorance of unseen edges in most existing literature, which is empirically shown to be able to improve GCL's performance in our experiments.","meta":{"url":"http://arxiv.org/abs/2308.00535v1"},"cats":{"new-dataset":0.0658748286,"dev-research":0.2453663909,"prompt-eng":0.3230056342,"data-quality":0.2751591837,"ml-security":0.1052984995}}
{"text":"To this end, we propose to incorporate graph generative adversarial networks (GANs) to learn the distribution of views for GCL, in order to i) automatically capture the characteristic of graphs for augmentations, and ii) jointly train the graph GAN model and the GCL model.","meta":{"url":"http://arxiv.org/abs/2308.00535v1"},"cats":{"new-dataset":0.1385233812,"dev-research":0.2635949806,"prompt-eng":0.3179308163,"data-quality":0.2508816786,"ml-security":0.2172562138}}
{"text":"Specifically, we present GACN, a novel Generative Adversarial Contrastive learning Network for graph representation learning.","meta":{"url":"http://arxiv.org/abs/2308.00535v1"},"cats":{"new-dataset":0.1623344451,"dev-research":0.2196198179,"prompt-eng":0.2729025697,"data-quality":0.2067916644,"ml-security":0.1336842205}}
{"text":"GACN develops a view generator and a view discriminator to generate augmented views automatically in an adversarial style.","meta":{"url":"http://arxiv.org/abs/2308.00535v1"},"cats":{"new-dataset":0.191823905,"dev-research":0.2896731523,"prompt-eng":0.3660094666,"data-quality":0.2009311843,"ml-security":0.3912837722}}
{"text":"Then, GACN leverages these views to train a GNN encoder with two carefully designed self-supervised learning losses, including the graph contrastive loss and the Bayesian personalized ranking Loss.","meta":{"url":"http://arxiv.org/abs/2308.00535v1"},"cats":{"new-dataset":0.1470940869,"dev-research":0.2227332029,"prompt-eng":0.3449525126,"data-quality":0.2707333832,"ml-security":0.2183491103}}
{"text":"Furthermore, we design an optimization framework to train all GACN modules jointly.","meta":{"url":"http://arxiv.org/abs/2308.00535v1"},"cats":{"new-dataset":0.1015841689,"dev-research":0.2324972844,"prompt-eng":0.3847859461,"data-quality":0.1476534371,"ml-security":0.1165251574}}
{"text":"Extensive experiments on seven real-world datasets show that GACN is able to generate high-quality augmented views for GCL and is superior to twelve state-of-the-art baseline methods.","meta":{"url":"http://arxiv.org/abs/2308.00535v1"},"cats":{"new-dataset":0.3029477463,"dev-research":0.285472839,"prompt-eng":0.3499292193,"data-quality":0.1714261206,"ml-security":0.0664299705}}
{"text":"Noticeably, our proposed GACN surprisingly discovers that the generated views in data augmentation finally conform to the well-known preferential attachment rule in online networks.","meta":{"url":"http://arxiv.org/abs/2308.00535v1"},"cats":{"new-dataset":0.1185735204,"dev-research":0.2268109269,"prompt-eng":0.3667349426,"data-quality":0.3319443132,"ml-security":0.1608981738}}
{"text":"Accurate Vehicle Trajectory Prediction is critical for automated vehicles and advanced driver assistance systems.","meta":{"url":"http://arxiv.org/abs/2308.00533v1"},"cats":{"new-dataset":0.0690752901,"dev-research":0.2451304935,"prompt-eng":0.3923663421,"data-quality":0.1464140043,"ml-security":0.1500263227}}
{"text":"Vehicle trajectory prediction consists of two essential tasks, i.e., longitudinal position prediction and lateral position prediction.","meta":{"url":"http://arxiv.org/abs/2308.00533v1"},"cats":{"new-dataset":0.1007826848,"dev-research":0.1758017596,"prompt-eng":0.353175551,"data-quality":0.0731062975,"ml-security":0.0950912886}}
{"text":"There is a significant correlation between driving intentions and vehicle motion.","meta":{"url":"http://arxiv.org/abs/2308.00533v1"},"cats":{"new-dataset":0.00703885,"dev-research":0.2796385322,"prompt-eng":0.3519794738,"data-quality":0.0850166447,"ml-security":0.0916733987}}
{"text":"In existing work, the three tasks are often conducted separately without considering the relationships between the longitudinal position, lateral position, and driving intention.","meta":{"url":"http://arxiv.org/abs/2308.00533v1"},"cats":{"new-dataset":0.0222370859,"dev-research":0.2823171167,"prompt-eng":0.37741607,"data-quality":0.0833864058,"ml-security":0.0351198041}}
{"text":"In this paper, we propose a novel Temporal Multi-Gate Mixture-of-Experts (TMMOE) model for simultaneously predicting the vehicle trajectory and driving intention.","meta":{"url":"http://arxiv.org/abs/2308.00533v1"},"cats":{"new-dataset":0.0448545134,"dev-research":0.2125481592,"prompt-eng":0.3954398141,"data-quality":0.0694088744,"ml-security":0.1123380301}}
{"text":"The proposed model consists of three layers: a shared layer, an expert layer, and a fully connected layer.","meta":{"url":"http://arxiv.org/abs/2308.00533v1"},"cats":{"new-dataset":0.1300219728,"dev-research":0.2215519858,"prompt-eng":0.444497686,"data-quality":0.0838535745,"ml-security":0.0792780014}}
{"text":"In the model, the shared layer utilizes Temporal Convolutional Networks (TCN) to extract temporal features.","meta":{"url":"http://arxiv.org/abs/2308.00533v1"},"cats":{"new-dataset":0.1680620236,"dev-research":0.2313950249,"prompt-eng":0.3414093749,"data-quality":0.1230965672,"ml-security":0.0841534988}}
{"text":"Then the expert layer is built to identify different information according to the three tasks.","meta":{"url":"http://arxiv.org/abs/2308.00533v1"},"cats":{"new-dataset":0.0483731963,"dev-research":0.2977900918,"prompt-eng":0.4941939141,"data-quality":0.1306124456,"ml-security":0.0651843153}}
{"text":"Moreover, the fully connected layer is used to integrate and export prediction results.","meta":{"url":"http://arxiv.org/abs/2308.00533v1"},"cats":{"new-dataset":0.1238264325,"dev-research":0.2743319566,"prompt-eng":0.3964819029,"data-quality":0.1072132571,"ml-security":0.0795756558}}
{"text":"To achieve better performance, uncertainty algorithm is used to construct the multi-task loss function.","meta":{"url":"http://arxiv.org/abs/2308.00533v1"},"cats":{"new-dataset":0.0154066728,"dev-research":0.3062463569,"prompt-eng":0.3844382017,"data-quality":0.1701138502,"ml-security":0.0822658717}}
{"text":"Finally, the publicly available CitySim dataset validates the TMMOE model, demonstrating superior performance compared to the LSTM model, achieving the highest classification and regression results.","meta":{"url":"http://arxiv.org/abs/2308.00533v1"},"cats":{"new-dataset":0.5325243856,"dev-research":0.1790626069,"prompt-eng":0.4053051011,"data-quality":0.1497135784,"ml-security":0.0985862252}}
{"text":"Keywords: Vehicle trajectory prediction, driving intentions Classification, Multi-task","meta":{"url":"http://arxiv.org/abs/2308.00533v1"},"cats":{"new-dataset":0.1512886411,"dev-research":0.194674,"prompt-eng":0.3710893276,"data-quality":0.0925403239,"ml-security":0.1530848849}}
{"text":"This paper investigates the adaptive bitrate (ABR) video semantic communication over wireless networks.","meta":{"url":"http://arxiv.org/abs/2308.00531v1"},"cats":{"new-dataset":0.0568192834,"dev-research":0.268299637,"prompt-eng":0.3525162853,"data-quality":0.2055467858,"ml-security":0.0673334785}}
{"text":"In the considered model, video sensing devices must transmit video semantic information to an edge server, to facilitate ubiquitous video sensing services such as road environment monitoring at the edge server in autonomous driving scenario.","meta":{"url":"http://arxiv.org/abs/2308.00531v1"},"cats":{"new-dataset":0.0839538748,"dev-research":0.2544669265,"prompt-eng":0.3721434986,"data-quality":0.1403446214,"ml-security":0.1194744386}}
{"text":"However, due to the varying wireless network conditions, it is challenging to guarantee both low transmission delay and high semantic accuracy at the same time if devices continuously transmit a fixed bitrate video semantic information.","meta":{"url":"http://arxiv.org/abs/2308.00531v1"},"cats":{"new-dataset":0.0476868004,"dev-research":0.2408504077,"prompt-eng":0.3949216817,"data-quality":0.2178205709,"ml-security":0.07878028}}
{"text":"To address this challenge, we develop an adaptive bitrate video semantic communication (ABRVSC) system, in which devices adaptively adjust the bitrate of video semantic information according to network conditions.","meta":{"url":"http://arxiv.org/abs/2308.00531v1"},"cats":{"new-dataset":0.1012668067,"dev-research":0.3011782099,"prompt-eng":0.3846639791,"data-quality":0.2593751329,"ml-security":0.079502814}}
{"text":"Specifically, we first define the quality of experience (QoE) for video semantic communication.","meta":{"url":"http://arxiv.org/abs/2308.00531v1"},"cats":{"new-dataset":0.1105278306,"dev-research":0.3286687351,"prompt-eng":0.3718167517,"data-quality":0.2236399635,"ml-security":0.0422265981}}
{"text":"Subsequently, a swin transformer-based semantic codec is proposed to extract semantic information with considering the influence of QoE.","meta":{"url":"http://arxiv.org/abs/2308.00531v1"},"cats":{"new-dataset":0.0687088118,"dev-research":0.3612952529,"prompt-eng":0.4294099958,"data-quality":0.1771096035,"ml-security":0.0695224576}}
{"text":"Then, we propose an Actor-Critic based ABR algorithm for the semantic codec to enhance the robustness of the proposed ABRVSC scheme against network variations.","meta":{"url":"http://arxiv.org/abs/2308.00531v1"},"cats":{"new-dataset":0.0567933466,"dev-research":0.3614810482,"prompt-eng":0.3977836559,"data-quality":0.2821044833,"ml-security":0.1486634623}}
{"text":"Simulation results demonstrate that at low bitrates, the mean intersection over union (MIoU) of the proposed ABRVSC scheme is nearly twice that of the traditional scheme.","meta":{"url":"http://arxiv.org/abs/2308.00531v1"},"cats":{"new-dataset":0.0977845888,"dev-research":0.1966145437,"prompt-eng":0.3600754204,"data-quality":0.0838003247,"ml-security":0.0746416704}}
{"text":"Moreover, the proposed ABRVSC scheme, which increases the QoE in video semantic communication by 36.57%, exhibits more robustness against network variations compared to both the fixed bitrate schemes and traditional ABR schemes.","meta":{"url":"http://arxiv.org/abs/2308.00531v1"},"cats":{"new-dataset":0.0752969893,"dev-research":0.2704447728,"prompt-eng":0.38217117,"data-quality":0.2762775932,"ml-security":0.0809775682}}
{"text":"The physical design process of large-scale designs is a time-consuming task, often requiring hours to days to complete, with routing being the most critical and complex step.","meta":{"url":"http://arxiv.org/abs/2308.00529v1"},"cats":{"new-dataset":0.0166375602,"dev-research":0.3889806828,"prompt-eng":0.3869515315,"data-quality":0.0448517054,"ml-security":0.0614013484}}
{"text":"As the the complexity of Integrated Circuits (ICs) increases, there is an increased demand for accurate routing quality prediction.","meta":{"url":"http://arxiv.org/abs/2308.00529v1"},"cats":{"new-dataset":0.0094019237,"dev-research":0.3447439705,"prompt-eng":0.380033379,"data-quality":0.1703579927,"ml-security":0.1227515654}}
{"text":"Accurate congestion prediction aids in identifying design flaws early on, thereby accelerating circuit design and conserving resources.","meta":{"url":"http://arxiv.org/abs/2308.00529v1"},"cats":{"new-dataset":0.0626345822,"dev-research":0.4636898619,"prompt-eng":0.3892063903,"data-quality":0.2709509107,"ml-security":0.2518739403}}
{"text":"Despite the advancements in current congestion prediction methodologies, an essential aspect that has been largely overlooked is the spatial label-correlation between different grids in congestion prediction.","meta":{"url":"http://arxiv.org/abs/2308.00529v1"},"cats":{"new-dataset":0.1106589354,"dev-research":0.2122371562,"prompt-eng":0.3270721309,"data-quality":0.2514068215,"ml-security":0.1391716618}}
{"text":"The spatial label-correlation is a fundamental characteristic of circuit design, where the congestion status of a grid is not isolated but inherently influenced by the conditions of its neighboring grids.","meta":{"url":"http://arxiv.org/abs/2308.00529v1"},"cats":{"new-dataset":0.0631586658,"dev-research":0.2785351882,"prompt-eng":0.3894371823,"data-quality":0.2837531151,"ml-security":0.1018187251}}
{"text":"In order to fully exploit the inherent spatial label-correlation between neighboring grids, we propose a novel approach, {\\ours}, i.e., VAriational Label-Correlation Enhancement for Congestion Prediction, which considers the local label-correlation in the congestion map, associating the estimated congestion value of each grid with a local label-correlation weight influenced by its surrounding grids.","meta":{"url":"http://arxiv.org/abs/2308.00529v1"},"cats":{"new-dataset":0.1367839766,"dev-research":0.2367239013,"prompt-eng":0.3639815837,"data-quality":0.3182743304,"ml-security":0.1359186719}}
{"text":"{\\ours} leverages variational inference techniques to estimate this weight, thereby enhancing the regression model's performance by incorporating spatial dependencies.","meta":{"url":"http://arxiv.org/abs/2308.00529v1"},"cats":{"new-dataset":0.0333850251,"dev-research":0.2334644357,"prompt-eng":0.3743763652,"data-quality":0.1578227263,"ml-security":0.101812219}}
{"text":"Experiment results validate the superior effectiveness of {\\ours} on the public available \\texttt{ISPD2011} and \\texttt{DAC2012} benchmarks using the superblue circuit line.","meta":{"url":"http://arxiv.org/abs/2308.00529v1"},"cats":{"new-dataset":0.0724726101,"dev-research":0.3164028713,"prompt-eng":0.4655102143,"data-quality":0.2506055587,"ml-security":0.0896324193}}
{"text":"Internet Memes remain a challenging form of user-generated content for automated sentiment classification.","meta":{"url":"http://arxiv.org/abs/2308.00528v1"},"cats":{"new-dataset":0.0656927481,"dev-research":0.2779771529,"prompt-eng":0.3926293163,"data-quality":0.4176469603,"ml-security":0.2014864373}}
{"text":"The availability of labelled memes is a barrier to developing sentiment classifiers of multimodal memes.","meta":{"url":"http://arxiv.org/abs/2308.00528v1"},"cats":{"new-dataset":0.1019277208,"dev-research":0.2579806423,"prompt-eng":0.3655651101,"data-quality":0.3230628911,"ml-security":0.1485298796}}
{"text":"To address the shortage of labelled memes, we propose to supplement the training of a multimodal meme classifier with unimodal (image-only and text-only) data.","meta":{"url":"http://arxiv.org/abs/2308.00528v1"},"cats":{"new-dataset":0.3536300767,"dev-research":0.1927065145,"prompt-eng":0.3690572183,"data-quality":0.3677999695,"ml-security":0.1401379001}}
{"text":"In this work, we present a novel variant of supervised intermediate training that uses relatively abundant sentiment-labelled unimodal data.","meta":{"url":"http://arxiv.org/abs/2308.00528v1"},"cats":{"new-dataset":0.3858974088,"dev-research":0.1949862473,"prompt-eng":0.3573775841,"data-quality":0.3935842818,"ml-security":0.1068627349}}
{"text":"Our results show a statistically significant performance improvement from the incorporation of unimodal text data.","meta":{"url":"http://arxiv.org/abs/2308.00528v1"},"cats":{"new-dataset":0.1840091386,"dev-research":0.2387001576,"prompt-eng":0.4353387002,"data-quality":0.2638904845,"ml-security":0.0495355179}}
{"text":"Furthermore, we show that the training set of labelled memes can be reduced by 40% without reducing the performance of the downstream model.","meta":{"url":"http://arxiv.org/abs/2308.00528v1"},"cats":{"new-dataset":0.0571950632,"dev-research":0.1962698588,"prompt-eng":0.4026762368,"data-quality":0.4140414884,"ml-security":0.1743981342}}
{"text":"This article aims to classify diabetic retinopathy (DR) disease into five different classes using an ensemble approach based on two popular pre-trained convolutional neural networks: VGG16 and Inception V3.","meta":{"url":"http://arxiv.org/abs/2308.00525v1"},"cats":{"new-dataset":0.223281382,"dev-research":0.2292927316,"prompt-eng":0.3301498651,"data-quality":0.1862039422,"ml-security":0.1126052185}}
{"text":"The proposed model aims to leverage the strengths of the two individual nets to enhance the classification performance for diabetic retinopathy.","meta":{"url":"http://arxiv.org/abs/2308.00525v1"},"cats":{"new-dataset":0.0228639752,"dev-research":0.2280826948,"prompt-eng":0.3771890897,"data-quality":0.1523288609,"ml-security":0.0665511799}}
{"text":"The ensemble model architecture involves freezing a portion of the layers in each pre-trained model to utilize their learned representations effectively.","meta":{"url":"http://arxiv.org/abs/2308.00525v1"},"cats":{"new-dataset":0.074865069,"dev-research":0.2667449637,"prompt-eng":0.366890478,"data-quality":0.1284956265,"ml-security":0.1681915241}}
{"text":"Global average pooling layers are added to transform the output feature maps into fixed-length vectors.","meta":{"url":"http://arxiv.org/abs/2308.00525v1"},"cats":{"new-dataset":0.1022246281,"dev-research":0.2543977371,"prompt-eng":0.3805880191,"data-quality":0.1735508639,"ml-security":0.0909576556}}
{"text":"These vectors are then concatenated to form a consolidated representation of the input image.","meta":{"url":"http://arxiv.org/abs/2308.00525v1"},"cats":{"new-dataset":0.0675202549,"dev-research":0.2369500907,"prompt-eng":0.4015648547,"data-quality":0.1681838311,"ml-security":0.079966886}}
{"text":"The ensemble model is trained using a dataset of diabetic retinopathy images (APTOS), divided into training and validation sets.","meta":{"url":"http://arxiv.org/abs/2308.00525v1"},"cats":{"new-dataset":0.2532735043,"dev-research":0.2070030581,"prompt-eng":0.3800396873,"data-quality":0.1379332888,"ml-security":0.0736634183}}
{"text":"During the training process, the model learns to classify the retinal images into the corresponding diabetic retinopathy classes.","meta":{"url":"http://arxiv.org/abs/2308.00525v1"},"cats":{"new-dataset":0.0612227704,"dev-research":0.2396859855,"prompt-eng":0.3847201975,"data-quality":0.1683119258,"ml-security":0.0946086965}}
{"text":"Experimental results on the test set demonstrate the efficacy of the proposed ensemble model for DR classification achieving an accuracy of 96.4%.","meta":{"url":"http://arxiv.org/abs/2308.00525v1"},"cats":{"new-dataset":0.0787545743,"dev-research":0.2271501758,"prompt-eng":0.4443880745,"data-quality":0.3303004496,"ml-security":0.1477728604}}
{"text":"This white paper presents our work on SurveyLM, a platform for analyzing augmented language models' (ALMs) emergent alignment behaviors through their dynamically evolving attitude and value perspectives in complex social contexts.","meta":{"url":"http://arxiv.org/abs/2308.00521v1"},"cats":{"new-dataset":0.2802058523,"dev-research":0.2982265088,"prompt-eng":0.3846158499,"data-quality":0.2369897285,"ml-security":0.0916063586}}
{"text":"Social Artificial Intelligence (AI) systems, like ALMs, often function within nuanced social scenarios where there is no singular correct response, or where an answer is heavily dependent on contextual factors, thus necessitating an in-depth understanding of their alignment dynamics.","meta":{"url":"http://arxiv.org/abs/2308.00521v1"},"cats":{"new-dataset":0.065516591,"dev-research":0.2606565637,"prompt-eng":0.356333155,"data-quality":0.1697598325,"ml-security":0.1453368806}}
{"text":"To address this, we apply survey and experimental methodologies, traditionally used in studying social behaviors, to evaluate ALMs systematically, thus providing unprecedented insights into their alignment and emergent behaviors.","meta":{"url":"http://arxiv.org/abs/2308.00521v1"},"cats":{"new-dataset":0.0834359848,"dev-research":0.2456013573,"prompt-eng":0.4100957951,"data-quality":0.1380561886,"ml-security":0.155356241}}
{"text":"Moreover, the SurveyLM platform leverages the ALMs' own feedback to enhance survey and experiment designs, exploiting an underutilized aspect of ALMs, which accelerates the development and testing of high-quality survey frameworks while conserving resources.","meta":{"url":"http://arxiv.org/abs/2308.00521v1"},"cats":{"new-dataset":0.1570161248,"dev-research":0.322294765,"prompt-eng":0.4851487624,"data-quality":0.1849790271,"ml-security":0.0833512776}}
{"text":"Through SurveyLM, we aim to shed light on factors influencing ALMs' emergent behaviors, facilitate their alignment with human intentions and expectations, and thereby contributed to the responsible development and deployment of advanced social AI systems.","meta":{"url":"http://arxiv.org/abs/2308.00521v1"},"cats":{"new-dataset":0.0707666384,"dev-research":0.2907756338,"prompt-eng":0.4042935659,"data-quality":0.1259734632,"ml-security":0.1728336425}}
{"text":"This white paper underscores the platform's potential to deliver robust results, highlighting its significance to alignment research and its implications for future social AI systems.","meta":{"url":"http://arxiv.org/abs/2308.00521v1"},"cats":{"new-dataset":0.1291412636,"dev-research":0.2418216023,"prompt-eng":0.3787197225,"data-quality":0.2504761177,"ml-security":0.1460644428}}
{"text":"Logit based knowledge distillation gets less attention in recent years since feature based methods perform better in most cases.","meta":{"url":"http://arxiv.org/abs/2308.00520v1"},"cats":{"new-dataset":0.0372888158,"dev-research":0.3478049034,"prompt-eng":0.4283219045,"data-quality":0.2486574172,"ml-security":0.1004018279}}
{"text":"Nevertheless, we find it still has untapped potential when we re-investigate the temperature, which is a crucial hyper-parameter to soften the logit outputs.","meta":{"url":"http://arxiv.org/abs/2308.00520v1"},"cats":{"new-dataset":0.0716500267,"dev-research":0.1782289414,"prompt-eng":0.3917050153,"data-quality":0.1806595441,"ml-security":0.1447098062}}
{"text":"For most of the previous works, it was set as a fixed value for the entire distillation procedure.","meta":{"url":"http://arxiv.org/abs/2308.00520v1"},"cats":{"new-dataset":0.0565444755,"dev-research":0.2282848513,"prompt-eng":0.3465314417,"data-quality":0.1947160941,"ml-security":0.0570506062}}
{"text":"However, as the logits from different samples are distributed quite variously, it is not feasible to soften all of them to an equal degree by just a single temperature, which may make the previous work transfer the knowledge of each sample inadequately.","meta":{"url":"http://arxiv.org/abs/2308.00520v1"},"cats":{"new-dataset":0.0427524335,"dev-research":0.1856108345,"prompt-eng":0.3720710832,"data-quality":0.2119977923,"ml-security":0.1414903169}}
{"text":"In this paper, we restudy the hyper-parameter temperature and figure out its incapability to distill the knowledge from each sample sufficiently when it is a single value.","meta":{"url":"http://arxiv.org/abs/2308.00520v1"},"cats":{"new-dataset":0.216696792,"dev-research":0.1215370116,"prompt-eng":0.4141523791,"data-quality":0.1641817711,"ml-security":0.1325793893}}
{"text":"To address this issue, we propose Normalized Knowledge Distillation (NormKD), with the purpose of customizing the temperature for each sample according to the characteristic of the sample's logit distribution.","meta":{"url":"http://arxiv.org/abs/2308.00520v1"},"cats":{"new-dataset":0.2184613742,"dev-research":0.2460350227,"prompt-eng":0.4365633416,"data-quality":0.1985098736,"ml-security":0.0809631335}}
{"text":"Compared to the vanilla KD, NormKD barely has extra computation or storage cost but performs significantly better on CIRAR-100 and ImageNet for image classification.","meta":{"url":"http://arxiv.org/abs/2308.00520v1"},"cats":{"new-dataset":0.2597966863,"dev-research":0.224809551,"prompt-eng":0.3490966963,"data-quality":0.2006778992,"ml-security":0.0890445685}}
{"text":"Furthermore, NormKD can be easily applied to the other logit based methods and achieve better performance which can be closer to or even better than the feature based method.","meta":{"url":"http://arxiv.org/abs/2308.00520v1"},"cats":{"new-dataset":0.0364461362,"dev-research":0.3712420944,"prompt-eng":0.4276765646,"data-quality":0.1310151244,"ml-security":0.070229174}}
{"text":"Markerless Human Pose Estimation (HPE) proved its potential to support decision making and assessment in many fields of application.","meta":{"url":"http://arxiv.org/abs/2308.00519v1"},"cats":{"new-dataset":0.1708485271,"dev-research":0.218259396,"prompt-eng":0.3893711819,"data-quality":0.1642729588,"ml-security":0.1109989875}}
{"text":"HPE is often preferred to traditional marker-based Motion Capture systems due to the ease of setup, portability, and affordable cost of the technology.","meta":{"url":"http://arxiv.org/abs/2308.00519v1"},"cats":{"new-dataset":0.0825042784,"dev-research":0.3297259,"prompt-eng":0.4177459631,"data-quality":0.0938135772,"ml-security":0.0464978352}}
{"text":"However, the exploitation of HPE in biomedical applications is still under investigation.","meta":{"url":"http://arxiv.org/abs/2308.00519v1"},"cats":{"new-dataset":0.0228671176,"dev-research":0.2485881996,"prompt-eng":0.3335638187,"data-quality":0.1199102249,"ml-security":0.1375178562}}
{"text":"This review aims to provide an overview of current biomedical applications of HPE.","meta":{"url":"http://arxiv.org/abs/2308.00519v1"},"cats":{"new-dataset":0.0179606906,"dev-research":0.2317989428,"prompt-eng":0.3767642343,"data-quality":0.0922259415,"ml-security":0.0677282859}}
{"text":"In this paper, we examine the main features of HPE approaches and discuss whether or not those features are of interest to biomedical applications.","meta":{"url":"http://arxiv.org/abs/2308.00519v1"},"cats":{"new-dataset":0.0232070797,"dev-research":0.21811143,"prompt-eng":0.3965246588,"data-quality":0.0851551672,"ml-security":0.0621400903}}
{"text":"We also identify those areas where HPE is already in use and present peculiarities and trends followed by researchers and practitioners.","meta":{"url":"http://arxiv.org/abs/2308.00519v1"},"cats":{"new-dataset":0.0400242723,"dev-research":0.2822903874,"prompt-eng":0.4040861437,"data-quality":0.1197916768,"ml-security":0.0825769236}}
{"text":"We include here 25 approaches to HPE and more than 40 studies of HPE applied to motor development assessment, neuromuscolar rehabilitation, and gait & posture analysis.","meta":{"url":"http://arxiv.org/abs/2308.00519v1"},"cats":{"new-dataset":0.1593300745,"dev-research":0.2840374717,"prompt-eng":0.3714362,"data-quality":0.0963654796,"ml-security":0.0617238721}}
{"text":"We conclude that markerless HPE offers great potential for extending diagnosis and rehabilitation outside hospitals and clinics, toward the paradigm of remote medical care.","meta":{"url":"http://arxiv.org/abs/2308.00519v1"},"cats":{"new-dataset":0.055881387,"dev-research":0.275946991,"prompt-eng":0.4256832452,"data-quality":0.1263035116,"ml-security":0.0813324125}}
{"text":"As the complexity of robot systems increases, it becomes more effective to simulate them before deployment.","meta":{"url":"http://arxiv.org/abs/2308.00514v1"},"cats":{"new-dataset":0.0342530233,"dev-research":0.3787837529,"prompt-eng":0.4005497394,"data-quality":0.0765409566,"ml-security":0.1234274486}}
{"text":"To do this, a model of the robot's kinematics or dynamics is required, and the most commonly used format is the Unified Robot Description Format (URDF).","meta":{"url":"http://arxiv.org/abs/2308.00514v1"},"cats":{"new-dataset":0.2256181106,"dev-research":0.1985685503,"prompt-eng":0.4410492783,"data-quality":0.0699367266,"ml-security":0.0330068961}}
{"text":"This article presents, to our knowledge, the first dataset of URDF files from various industrial and research organizations, with metadata describing each robot, its type, manufacturer, and the source of the model.","meta":{"url":"http://arxiv.org/abs/2308.00514v1"},"cats":{"new-dataset":0.6108277446,"dev-research":0.1689603358,"prompt-eng":0.4077699747,"data-quality":0.1143097468,"ml-security":0.0384120018}}
{"text":"The dataset contains 322 URDF files of which 195 are unique robot models, meaning the excess URDFs are either of a robot that is multiply defined across sources or URDF variants of the same robot.","meta":{"url":"http://arxiv.org/abs/2308.00514v1"},"cats":{"new-dataset":0.6947864493,"dev-research":0.1938887178,"prompt-eng":0.3340529286,"data-quality":0.1553158474,"ml-security":0.0852055431}}
{"text":"We analyze the files in the dataset, where we, among other things, provide information on how they were generated, which mesh file types are most commonly used, and compare models of multiply defined robots.","meta":{"url":"http://arxiv.org/abs/2308.00514v1"},"cats":{"new-dataset":0.635207105,"dev-research":0.2587569983,"prompt-eng":0.3773706294,"data-quality":0.1106557872,"ml-security":0.0851476641}}
{"text":"The intention of this article is to build a foundation of knowledge on URDF and how it is used based on publicly available URDF files.","meta":{"url":"http://arxiv.org/abs/2308.00514v1"},"cats":{"new-dataset":0.2430471683,"dev-research":0.2354242025,"prompt-eng":0.3920849932,"data-quality":0.1623897106,"ml-security":0.0742967619}}
{"text":"Publishing the dataset, analysis, and the scripts and tools used enables others using, researching or developing URDFs to easily access this data and use it in their own work.","meta":{"url":"http://arxiv.org/abs/2308.00514v1"},"cats":{"new-dataset":0.4185508972,"dev-research":0.3384983711,"prompt-eng":0.3406328509,"data-quality":0.1226298957,"ml-security":0.0911211245}}
{"text":"This paper introduces UVIO, a multi-sensor framework that leverages Ultra Wide Band (UWB) technology and Visual-Inertial Odometry (VIO) to provide robust and low-drift localization.","meta":{"url":"http://arxiv.org/abs/2308.00513v1"},"cats":{"new-dataset":0.1540974964,"dev-research":0.2414275323,"prompt-eng":0.3379801093,"data-quality":0.1023267868,"ml-security":0.0602525324}}
{"text":"In order to include range measurements in state estimation, the position of the UWB anchors must be known.","meta":{"url":"http://arxiv.org/abs/2308.00513v1"},"cats":{"new-dataset":0.0540707116,"dev-research":0.1758991362,"prompt-eng":0.4130442011,"data-quality":0.1074323369,"ml-security":0.061094184}}
{"text":"This study proposes a multi-step initialization procedure to map multiple unknown anchors by an Unmanned Aerial Vehicle (UAV), in a fully autonomous fashion.","meta":{"url":"http://arxiv.org/abs/2308.00513v1"},"cats":{"new-dataset":0.0889906972,"dev-research":0.2664284574,"prompt-eng":0.447286582,"data-quality":0.1076042618,"ml-security":0.0933115709}}
{"text":"To address the limitations of initializing UWB anchors via a random trajectory, this paper uses the Geometric Dilution of Precision (GDOP) as a measure of optimality in anchor position estimation, to compute a set of optimal waypoints and synthesize a trajectory that minimizes the mapping uncertainty.","meta":{"url":"http://arxiv.org/abs/2308.00513v1"},"cats":{"new-dataset":0.0414915982,"dev-research":0.2444989631,"prompt-eng":0.4298803722,"data-quality":0.1355517797,"ml-security":0.0631105434}}
{"text":"After the initialization is complete, the range measurements from multiple anchors, including measurement biases, are tightly integrated into the VIO system.","meta":{"url":"http://arxiv.org/abs/2308.00513v1"},"cats":{"new-dataset":0.0372332238,"dev-research":0.2235350564,"prompt-eng":0.4202780225,"data-quality":0.0901736841,"ml-security":0.0530500675}}
{"text":"While in range of the initialized anchors, the VIO drift in position and heading is eliminated.","meta":{"url":"http://arxiv.org/abs/2308.00513v1"},"cats":{"new-dataset":0.0147150035,"dev-research":0.2498529904,"prompt-eng":0.3508344878,"data-quality":0.1879933556,"ml-security":0.1182913077}}
{"text":"The effectiveness of UVIO and our initialization procedure has been validated through a series of simulations and real-world experiments.","meta":{"url":"http://arxiv.org/abs/2308.00513v1"},"cats":{"new-dataset":0.0274649026,"dev-research":0.2357882986,"prompt-eng":0.4127240457,"data-quality":0.102063518,"ml-security":0.0593971753}}
{"text":"Context-aware methods achieved great success in supervised scene text recognition via incorporating semantic priors from words.","meta":{"url":"http://arxiv.org/abs/2308.00508v1"},"cats":{"new-dataset":0.2025077574,"dev-research":0.1600964438,"prompt-eng":0.3863767488,"data-quality":0.3091517532,"ml-security":0.0795466649}}
{"text":"We argue that such prior contextual information can be interpreted as the relations of textual primitives due to the heterogeneous text and background, which can provide effective self-supervised labels for representation learning.","meta":{"url":"http://arxiv.org/abs/2308.00508v1"},"cats":{"new-dataset":0.160616884,"dev-research":0.2537510117,"prompt-eng":0.3803672726,"data-quality":0.357671885,"ml-security":0.1040922222}}
{"text":"However, textual relations are restricted to the finite size of dataset due to lexical dependencies, which causes the problem of over-fitting and compromises representation robustness.","meta":{"url":"http://arxiv.org/abs/2308.00508v1"},"cats":{"new-dataset":0.2867294375,"dev-research":0.2728168837,"prompt-eng":0.340447168,"data-quality":0.4027447187,"ml-security":0.1696674735}}
{"text":"To this end, we propose to enrich the textual relations via rearrangement, hierarchy and interaction, and design a unified framework called RCLSTR: Relational Contrastive Learning for Scene Text Recognition.","meta":{"url":"http://arxiv.org/abs/2308.00508v1"},"cats":{"new-dataset":0.5908121216,"dev-research":0.1867914543,"prompt-eng":0.3481921967,"data-quality":0.2313743775,"ml-security":0.056361377}}
{"text":"Based on causality, we theoretically explain that three modules suppress the bias caused by the contextual prior and thus guarantee representation robustness.","meta":{"url":"http://arxiv.org/abs/2308.00508v1"},"cats":{"new-dataset":0.019156616,"dev-research":0.2678434815,"prompt-eng":0.3869343178,"data-quality":0.3604873522,"ml-security":0.2965399622}}
{"text":"Experiments on representation quality show that our method outperforms state-of-the-art self-supervised STR methods.","meta":{"url":"http://arxiv.org/abs/2308.00508v1"},"cats":{"new-dataset":0.073631245,"dev-research":0.2772291939,"prompt-eng":0.4452300144,"data-quality":0.4808814215,"ml-security":0.0885515441}}
{"text":"Code is available at https://github.com/ThunderVVV/RCLSTR.","meta":{"url":"http://arxiv.org/abs/2308.00508v1"},"cats":{"new-dataset":0.396439523,"dev-research":0.1888987173,"prompt-eng":0.4970019822,"data-quality":0.133429607,"ml-security":0.050973643}}
{"text":"We consider the problem of parameter estimation, based on noisy chaotic signals, from the viewpoint of twisted modulation for waveform communication.","meta":{"url":"http://arxiv.org/abs/2308.00506v1"},"cats":{"new-dataset":0.0618502957,"dev-research":0.1743541464,"prompt-eng":0.4185087321,"data-quality":0.1759765936,"ml-security":0.180264949}}
{"text":"In particular, we study communication systems where the parameter to be estimated is conveyed as the initial condition of a chaotic dynamical system of a certain class and we examine its estimation performance in terms of the expectation of a given convex function of the estimation error at high SNR, under the demand that the probability of anomaly is kept small.","meta":{"url":"http://arxiv.org/abs/2308.00506v1"},"cats":{"new-dataset":0.0542533066,"dev-research":0.1846671428,"prompt-eng":0.3858972034,"data-quality":0.2579453382,"ml-security":0.329755725}}
{"text":"We derive a lower bound on the weak-noise estimation error for this class of chaotic modulators, and argue that it can be outperformed by using the itinerary signal associated with the chaotic system instead of the main chaotic output signal.","meta":{"url":"http://arxiv.org/abs/2308.00506v1"},"cats":{"new-dataset":0.0592433351,"dev-research":0.1845850681,"prompt-eng":0.3806517475,"data-quality":0.288944743,"ml-security":0.1938660212}}
{"text":"Spectral clustering methods are known for their ability to represent clusters of diverse shapes, densities etc.","meta":{"url":"http://arxiv.org/abs/2308.00504v1"},"cats":{"new-dataset":0.0419210671,"dev-research":0.1970199518,"prompt-eng":0.371067055,"data-quality":0.1619887331,"ml-security":0.0542976493}}
{"text":"However, results of such algorithms, when applied e.g. to text documents, are hard to explain to the user, especially due to embedding in the spectral space which has no obvious relation to document contents.","meta":{"url":"http://arxiv.org/abs/2308.00504v1"},"cats":{"new-dataset":0.0352130476,"dev-research":0.222624183,"prompt-eng":0.354955161,"data-quality":0.2514054421,"ml-security":0.0907676989}}
{"text":"Therefore there is an urgent need to elaborate methods for explaining the outcome of the clustering.","meta":{"url":"http://arxiv.org/abs/2308.00504v1"},"cats":{"new-dataset":0.0204780094,"dev-research":0.2881940933,"prompt-eng":0.3869615067,"data-quality":0.2276754785,"ml-security":0.0820460314}}
{"text":"This paper presents a contribution towards this goal.","meta":{"url":"http://arxiv.org/abs/2308.00504v1"},"cats":{"new-dataset":0.0234334039,"dev-research":0.2506881499,"prompt-eng":0.4482114222,"data-quality":0.1299844948,"ml-security":0.1030388779}}
{"text":"We present a proposal of explanation of results of combinatorial Laplacian based graph spectral clustering.","meta":{"url":"http://arxiv.org/abs/2308.00504v1"},"cats":{"new-dataset":0.1268699561,"dev-research":0.2082817499,"prompt-eng":0.3260093442,"data-quality":0.2413811786,"ml-security":0.0653488057}}
{"text":"It is based on showing (approximate) equivalence of combinatorial Laplacian embedding, $K$-embedding (proposed in this paper) and term vector space embedding.","meta":{"url":"http://arxiv.org/abs/2308.00504v1"},"cats":{"new-dataset":0.1940664455,"dev-research":0.1347589495,"prompt-eng":0.3157169795,"data-quality":0.1707181142,"ml-security":0.0867195879}}
{"text":"Hence a bridge is constructed between the textual contents and the clustering results.","meta":{"url":"http://arxiv.org/abs/2308.00504v1"},"cats":{"new-dataset":0.1041150009,"dev-research":0.2707959833,"prompt-eng":0.3470986045,"data-quality":0.2434421358,"ml-security":0.0693777187}}
{"text":"We provide theoretical background for this approach.","meta":{"url":"http://arxiv.org/abs/2308.00504v1"},"cats":{"new-dataset":0.0208369175,"dev-research":0.1822486209,"prompt-eng":0.3471459057,"data-quality":0.1206238465,"ml-security":0.1444952674}}
{"text":"We performed experimental study showing that $K$-embedding approximates well Laplacian embedding under favourable block matrix conditions and show that approximation is good enough under other conditions.","meta":{"url":"http://arxiv.org/abs/2308.00504v1"},"cats":{"new-dataset":0.1074366217,"dev-research":0.1516554832,"prompt-eng":0.3055161443,"data-quality":0.1957567722,"ml-security":0.1106483777}}
{"text":"We study the classic Euclidean Minimum Spanning Tree (MST) problem in the Massively Parallel Computation (MPC) model.","meta":{"url":"http://arxiv.org/abs/2308.00503v1"},"cats":{"new-dataset":0.1111834582,"dev-research":0.1502778574,"prompt-eng":0.3048682073,"data-quality":0.1315966352,"ml-security":0.0882248308}}
{"text":"Given a set $X \\subset \\mathbb{R}^d$ of $n$ points, the goal is to produce a spanning tree for $X$ with weight within a small factor of optimal.","meta":{"url":"http://arxiv.org/abs/2308.00503v1"},"cats":{"new-dataset":0.0478050513,"dev-research":0.1636592318,"prompt-eng":0.322338616,"data-quality":0.1443566132,"ml-security":0.1204965438}}
{"text":"Euclidean MST is one of the most fundamental hierarchical geometric clustering algorithms, and with the proliferation of enormous high-dimensional data sets, such as massive transformer-based embeddings, there is now a critical demand for efficient distributed algorithms to cluster such data sets.   ","meta":{"url":"http://arxiv.org/abs/2308.00503v1"},"cats":{"new-dataset":0.2642968665,"dev-research":0.1671789272,"prompt-eng":0.3261754072,"data-quality":0.1161886951,"ml-security":0.0731054042}}
{"text":"In low-dimensional space, where $d = O(1)$, Andoni, Nikolov, Onak, and Yaroslavtsev","meta":{"url":"http://arxiv.org/abs/2308.00503v1"},"cats":{"new-dataset":0.3072978058,"dev-research":0.1300243857,"prompt-eng":0.2977805974,"data-quality":0.1036456428,"ml-security":0.0851618805}}
{"text":"[STOC '14] gave a constant round MPC algorithm that obtains a high accuracy $(1+\\epsilon)$-approximate solution.","meta":{"url":"http://arxiv.org/abs/2308.00503v1"},"cats":{"new-dataset":0.112730281,"dev-research":0.1566067243,"prompt-eng":0.3617180267,"data-quality":0.181855939,"ml-security":0.065954397}}
{"text":"However, the situation is much more challenging for high-dimensional spaces: the best-known algorithm to obtain a constant approximation requires $O(\\log n)$ rounds.","meta":{"url":"http://arxiv.org/abs/2308.00503v1"},"cats":{"new-dataset":0.1190060077,"dev-research":0.1599307314,"prompt-eng":0.3164658346,"data-quality":0.1386793048,"ml-security":0.1093979719}}
{"text":"Recently Chen, Jayaram, Levi, and Waingarten [STOC '22] gave a $\\tilde{O}(\\log n)$ approximation algorithm in a constant number of rounds based on embeddings into tree metrics.","meta":{"url":"http://arxiv.org/abs/2308.00503v1"},"cats":{"new-dataset":0.1838529016,"dev-research":0.1646480467,"prompt-eng":0.3288169221,"data-quality":0.1732888694,"ml-security":0.0781232827}}
{"text":"However, to date, no known algorithm achieves both a constant number of rounds and approximation.   ","meta":{"url":"http://arxiv.org/abs/2308.00503v1"},"cats":{"new-dataset":0.0583119599,"dev-research":0.1912027883,"prompt-eng":0.297210269,"data-quality":0.1470147928,"ml-security":0.1016990735}}
{"text":"In this paper, we make strong progress on this front by giving a constant factor approximation in $\\tilde{O}(\\log \\log n)$ rounds of the MPC model.","meta":{"url":"http://arxiv.org/abs/2308.00503v1"},"cats":{"new-dataset":0.1330398536,"dev-research":0.1065730478,"prompt-eng":0.352793151,"data-quality":0.1151926826,"ml-security":0.0848137957}}
{"text":"In contrast to tree-embedding-based approaches, which necessarily must pay $\\Omega(\\log n)$-distortion, our algorithm is based on a new combination of graph-based distributed MST algorithms and geometric space partitions.","meta":{"url":"http://arxiv.org/abs/2308.00503v1"},"cats":{"new-dataset":0.1380337052,"dev-research":0.2003816554,"prompt-eng":0.3282227465,"data-quality":0.2245651527,"ml-security":0.1070093255}}
{"text":"Additionally, although the approximate MST we return can have a large depth, we show that it can be modified to obtain a $\\tilde{O}(\\log \\log n)$-round constant factor approximation to the Euclidean Traveling Salesman Problem (TSP) in the MPC model.","meta":{"url":"http://arxiv.org/abs/2308.00503v1"},"cats":{"new-dataset":0.1540554266,"dev-research":0.1370546791,"prompt-eng":0.33774979,"data-quality":0.0963958111,"ml-security":0.077190163}}
{"text":"Previously, only a $O(\\log n)$ round was known for the problem.","meta":{"url":"http://arxiv.org/abs/2308.00503v1"},"cats":{"new-dataset":0.196924404,"dev-research":0.151565712,"prompt-eng":0.3096810793,"data-quality":0.2277517507,"ml-security":0.1171101317}}
{"text":"In this work, we study the Biclique-Free Vertex Deletion problem: Given a graph $G$ and integers $k$ and $i \\le j$, find a set of at most $k$ vertices that intersects every (not necessarily induced) biclique $K_{i, j}$ in $G$.","meta":{"url":"http://arxiv.org/abs/2308.00501v1"},"cats":{"new-dataset":0.3813434299,"dev-research":0.210495595,"prompt-eng":0.2777966842,"data-quality":0.1799062516,"ml-security":0.1597059888}}
{"text":"This is a natural generalization of the Bounded-Degree Deletion problem, wherein one asks whether there is a set of at most $k$ vertices whose deletion results in a graph of a given maximum degree $r$. The two problems coincide when $i = 1$ and $j = r + 1$.","meta":{"url":"http://arxiv.org/abs/2308.00501v1"},"cats":{"new-dataset":0.3103670748,"dev-research":0.2116010926,"prompt-eng":0.3005152322,"data-quality":0.1919717544,"ml-security":0.182821039}}
{"text":"We show that Biclique-Free Vertex Deletion is fixed-parameter tractable with respect to $k + d$ for the degeneracy $d$ by developing a $2^{O(d k^2)}","meta":{"url":"http://arxiv.org/abs/2308.00501v1"},"cats":{"new-dataset":0.1606718939,"dev-research":0.1963361754,"prompt-eng":0.3048368662,"data-quality":0.1259370268,"ml-security":0.1352238815}}
{"text":"\\cdot n^{O(1)}$-time algorithm.","meta":{"url":"http://arxiv.org/abs/2308.00501v1"},"cats":{"new-dataset":0.0933733758,"dev-research":0.1729744961,"prompt-eng":0.3300101217,"data-quality":0.0966138922,"ml-security":0.1050652}}
{"text":"We also show that it can be solved in $2^{O(f k)}","meta":{"url":"http://arxiv.org/abs/2308.00501v1"},"cats":{"new-dataset":0.1317730237,"dev-research":0.151838523,"prompt-eng":0.3087471727,"data-quality":0.1551009405,"ml-security":0.162522714}}
{"text":"\\cdot n^{O(1)}$ time for the feedback vertex number $f$ when $i \\ge 2$.","meta":{"url":"http://arxiv.org/abs/2308.00501v1"},"cats":{"new-dataset":0.0522752275,"dev-research":0.1827470789,"prompt-eng":0.34602274,"data-quality":0.1346717219,"ml-security":0.0881847998}}
{"text":"In contrast, we find that it is W[1]-hard for the treedepth for any integer","meta":{"url":"http://arxiv.org/abs/2308.00501v1"},"cats":{"new-dataset":0.0328273281,"dev-research":0.202015443,"prompt-eng":0.3550981418,"data-quality":0.2143123433,"ml-security":0.1029297134}}
{"text":"$i \\ge 1$.","meta":{"url":"http://arxiv.org/abs/2308.00501v1"},"cats":{"new-dataset":0.1065943813,"dev-research":0.313319206,"prompt-eng":0.3487537837,"data-quality":0.1413719161,"ml-security":0.1134563898}}
{"text":"Finally, we show that Biclique-Free Vertex Deletion has a polynomial kernel for every $i \\ge 1$ when parameterized by the feedback edge number.","meta":{"url":"http://arxiv.org/abs/2308.00501v1"},"cats":{"new-dataset":0.1406299643,"dev-research":0.1907499449,"prompt-eng":0.3216984581,"data-quality":0.1803663892,"ml-security":0.1706809651}}
{"text":"Previously, for this parameter, its fixed-parameter tractability for $i = 1$ was known","meta":{"url":"http://arxiv.org/abs/2308.00501v1"},"cats":{"new-dataset":0.1351317935,"dev-research":0.1450172606,"prompt-eng":0.3732393453,"data-quality":0.1406706385,"ml-security":0.1267840165}}
{"text":"[Betzler et al., DAM '12] but the existence of polynomial kernel was open.","meta":{"url":"http://arxiv.org/abs/2308.00501v1"},"cats":{"new-dataset":0.1028004875,"dev-research":0.1957126204,"prompt-eng":0.2929616372,"data-quality":0.2161628381,"ml-security":0.195931513}}
{"text":"This paper investigates the performance of network non-orthogonal multiple access (N-NOMA) in a downlink coordinated multi-point (CoMP) system.","meta":{"url":"http://arxiv.org/abs/2308.00499v1"},"cats":{"new-dataset":0.0170838176,"dev-research":0.2119934339,"prompt-eng":0.3282646315,"data-quality":0.0938901995,"ml-security":0.0603464218}}
{"text":"In the considered N-NOMA scheme, multiple base stations (BSs) cooperatively serve a CoMP user, meanwhile, each BS serves additional NOMA users by occupying the same resource block allocated to the CoMP user.","meta":{"url":"http://arxiv.org/abs/2308.00499v1"},"cats":{"new-dataset":0.037178114,"dev-research":0.2030518498,"prompt-eng":0.3584548639,"data-quality":0.1143113074,"ml-security":0.1044056297}}
{"text":"The locations of the BSs and users are modeled by stochastic geometric models and the interference from the whole network is considered.","meta":{"url":"http://arxiv.org/abs/2308.00499v1"},"cats":{"new-dataset":0.0286078834,"dev-research":0.1819831313,"prompt-eng":0.3920844401,"data-quality":0.1720526995,"ml-security":0.1553522452}}
{"text":"Through rigorous derivations, the outage probabilities achieved by the CoMP and NOMA users are obtained, respectively.","meta":{"url":"http://arxiv.org/abs/2308.00499v1"},"cats":{"new-dataset":0.0719930423,"dev-research":0.1771290338,"prompt-eng":0.4293931542,"data-quality":0.203884267,"ml-security":0.1922059828}}
{"text":"Numerical results are provided to verify the accuracy of the analytical results and also demonstrate the superior performance of N-NOMA compared to orthogonal multiple access (OMA) based CoMP scheme.","meta":{"url":"http://arxiv.org/abs/2308.00499v1"},"cats":{"new-dataset":0.0291009649,"dev-research":0.1827611332,"prompt-eng":0.3814937218,"data-quality":0.090142797,"ml-security":0.0518534904}}
{"text":"FFTc is a Domain-Specific Language (DSL) for designing and generating Fast Fourier Transforms (FFT) libraries.","meta":{"url":"http://arxiv.org/abs/2308.00497v1"},"cats":{"new-dataset":0.1896343981,"dev-research":0.299706212,"prompt-eng":0.407842473,"data-quality":0.0751032142,"ml-security":0.0420773465}}
{"text":"The FFTc uniqueness is that it leverages and extend Multi-Level Intermediate Representation (MLIR) dialects to optimize FFT code generation.","meta":{"url":"http://arxiv.org/abs/2308.00497v1"},"cats":{"new-dataset":0.1043104085,"dev-research":0.31669209,"prompt-eng":0.3784892968,"data-quality":0.1344927265,"ml-security":0.0647149125}}
{"text":"In this work, we present FFTc extensions and improvements such as the possibility of using different data layout for complex-value arrays, and sparsification to enable efficient vectorization, and a seamless porting of FFT libraries to GPU systems.","meta":{"url":"http://arxiv.org/abs/2308.00497v1"},"cats":{"new-dataset":0.2480995026,"dev-research":0.3204245782,"prompt-eng":0.374886759,"data-quality":0.100776086,"ml-security":0.080609509}}
{"text":"We show that, on CPUs, thanks to vectorization, the performance of the FFTc-generated FFT is comparable to performance of FFTW, a state-of-the-art FFT libraries.","meta":{"url":"http://arxiv.org/abs/2308.00497v1"},"cats":{"new-dataset":0.0977948245,"dev-research":0.2990538095,"prompt-eng":0.3938684162,"data-quality":0.1313398345,"ml-security":0.0697433811}}
{"text":"We also present the initial performance results for FFTc on Nvidia GPUs.","meta":{"url":"http://arxiv.org/abs/2308.00497v1"},"cats":{"new-dataset":0.2597597768,"dev-research":0.2073227831,"prompt-eng":0.3760349228,"data-quality":0.0977046706,"ml-security":0.0523726671}}
{"text":"One advantage of neural ranking models is that they are meant to generalise well in situations of synonymity i.e. where two words have similar or identical meanings.","meta":{"url":"http://arxiv.org/abs/2308.00480v1"},"cats":{"new-dataset":0.0066118317,"dev-research":0.237292474,"prompt-eng":0.2981986181,"data-quality":0.1717114147,"ml-security":0.1304474122}}
{"text":"In this paper, we investigate and quantify how well various ranking models perform in a clear-cut case of synonymity: when words are simply expressed in different surface forms due to regional differences in spelling conventions (e.g., color vs colour).","meta":{"url":"http://arxiv.org/abs/2308.00480v1"},"cats":{"new-dataset":0.0764603269,"dev-research":0.2228344027,"prompt-eng":0.4310430507,"data-quality":0.2981545229,"ml-security":0.0435273158}}
{"text":"We first explore the prevalence of American and British English spelling conventions in datasets used for the pre-training, training and evaluation of neural retrieval methods, and find that American spelling conventions are far more prevalent.","meta":{"url":"http://arxiv.org/abs/2308.00480v1"},"cats":{"new-dataset":0.2851377332,"dev-research":0.245853662,"prompt-eng":0.4095201722,"data-quality":0.3727027404,"ml-security":0.1027312716}}
{"text":"Despite these biases in the training data, we find that retrieval models often generalise well in this case of synonymity.","meta":{"url":"http://arxiv.org/abs/2308.00480v1"},"cats":{"new-dataset":0.0656251017,"dev-research":0.180208474,"prompt-eng":0.400959261,"data-quality":0.3174985113,"ml-security":0.0857412403}}
{"text":"We explore the effect of document spelling normalisation in retrieval and observe that all models are affected by normalising the document's spelling.","meta":{"url":"http://arxiv.org/abs/2308.00480v1"},"cats":{"new-dataset":0.0194793088,"dev-research":0.2424563081,"prompt-eng":0.4481752485,"data-quality":0.3868407332,"ml-security":0.0996175423}}
{"text":"While they all experience a drop in performance when normalised to a different spelling convention than that of the query, we observe varied behaviour when the document is normalised to share the query spelling convention: lexical models show improvements, dense retrievers remain unaffected, and re-rankers exhibit contradictory behaviour.","meta":{"url":"http://arxiv.org/abs/2308.00480v1"},"cats":{"new-dataset":0.0214540971,"dev-research":0.2391287169,"prompt-eng":0.4337562784,"data-quality":0.3314819115,"ml-security":0.0959678344}}
{"text":"With the development of networking technology, the computing system has evolved towards the multi-tier paradigm gradually.","meta":{"url":"http://arxiv.org/abs/2308.00481v1"},"cats":{"new-dataset":0.0141245159,"dev-research":0.3269295308,"prompt-eng":0.3554712739,"data-quality":0.0581258878,"ml-security":0.100078294}}
{"text":"However, challenges, such as multi-resource heterogeneity of devices, resource competition of services, and networked system dynamics, make it difficult to guarantee service-level agreement (SLA) for the applications.","meta":{"url":"http://arxiv.org/abs/2308.00481v1"},"cats":{"new-dataset":0.044565245,"dev-research":0.2359384854,"prompt-eng":0.3212391257,"data-quality":0.1561158507,"ml-security":0.1339126047}}
{"text":"In this paper, we propose a multi-tier edge-cloud computing framework, EdgeMatrix, to maximize the throughput of the system while guaranteeing different SLA priorities.","meta":{"url":"http://arxiv.org/abs/2308.00481v1"},"cats":{"new-dataset":0.0749967917,"dev-research":0.1996180195,"prompt-eng":0.3182474817,"data-quality":0.0582528892,"ml-security":0.1143061914}}
{"text":"First, in order to reduce the impact of physical resource heterogeneity, EdgeMatrix introduces the Networked Multi-agent Actor-Critic (NMAC) algorithm to re-define physical resources with the same quality of service as logically isolated resource units and combinations, i.e., cells and channels.","meta":{"url":"http://arxiv.org/abs/2308.00481v1"},"cats":{"new-dataset":0.0972295087,"dev-research":0.232307293,"prompt-eng":0.3151355828,"data-quality":0.0776250086,"ml-security":0.0805056995}}
{"text":"In addition, a multi-task mechanism is designed in EdgeMatrix to solve the problem of Joint Service Orchestration and Request Dispatch (JSORD) for matching the requests and services, which can significantly reduce the optimization runtime.","meta":{"url":"http://arxiv.org/abs/2308.00481v1"},"cats":{"new-dataset":0.0695831973,"dev-research":0.2190847659,"prompt-eng":0.3935747964,"data-quality":0.0727262452,"ml-security":0.0638161936}}
{"text":"For integrating above two algorithms, EdgeMatrix is designed with two time-scales, i.e., coordinating services and resources at the larger time-scale, and dispatching requests at the smaller time-scale.","meta":{"url":"http://arxiv.org/abs/2308.00481v1"},"cats":{"new-dataset":0.1425980423,"dev-research":0.1886547828,"prompt-eng":0.3582886547,"data-quality":0.0441719488,"ml-security":0.0546779781}}
{"text":"Realistic trace-based experiments proves that the overall throughput of EdgeMatrix is 36.7% better than that of the closest baseline, while the SLA priorities are guaranteed still.","meta":{"url":"http://arxiv.org/abs/2308.00481v1"},"cats":{"new-dataset":0.0569992312,"dev-research":0.1814850115,"prompt-eng":0.3349055095,"data-quality":0.1027625382,"ml-security":0.0563758038}}
{"text":"Large Language Models are increasingly being used for various tasks including content generation and as chatbots.","meta":{"url":"http://arxiv.org/abs/2308.00479v1"},"cats":{"new-dataset":0.2312926982,"dev-research":0.2863997176,"prompt-eng":0.4042281059,"data-quality":0.1334711081,"ml-security":0.0723172151}}
{"text":"Despite their impressive performances in general tasks, LLMs need to be aligned when applying for domain specific tasks to mitigate the problems of hallucination and producing harmful answers.","meta":{"url":"http://arxiv.org/abs/2308.00479v1"},"cats":{"new-dataset":0.020930181,"dev-research":0.2715453116,"prompt-eng":0.4700278423,"data-quality":0.1891569344,"ml-security":0.1093127638}}
{"text":"Retrieval Augmented Generation (RAG) allows to easily attach and manipulate a non-parametric knowledgebases to LLMs.","meta":{"url":"http://arxiv.org/abs/2308.00479v1"},"cats":{"new-dataset":0.0950434611,"dev-research":0.2445732349,"prompt-eng":0.4366988837,"data-quality":0.1339429235,"ml-security":0.0469395868}}
{"text":"Applications of RAG in the field of medical education are discussed in this paper.","meta":{"url":"http://arxiv.org/abs/2308.00479v1"},"cats":{"new-dataset":0.0130234279,"dev-research":0.2480171709,"prompt-eng":0.3706957379,"data-quality":0.1265123536,"ml-security":0.0887678869}}
{"text":"A combined extractive and abstractive summarization method for large unstructured textual data using representative vectors is proposed.","meta":{"url":"http://arxiv.org/abs/2308.00479v1"},"cats":{"new-dataset":0.0743394436,"dev-research":0.2473713568,"prompt-eng":0.3471376841,"data-quality":0.2098489356,"ml-security":0.0512376957}}
{"text":"We propose a many-sorted modal logic for reasoning about knowledge in multi-agent systems.","meta":{"url":"http://arxiv.org/abs/2308.00477v1"},"cats":{"new-dataset":0.1658637983,"dev-research":0.3275185023,"prompt-eng":0.4558530558,"data-quality":0.0866030917,"ml-security":0.0732646942}}
{"text":"Our logic introduces a clear distinction between participating agents and the environment.","meta":{"url":"http://arxiv.org/abs/2308.00477v1"},"cats":{"new-dataset":0.1035605205,"dev-research":0.3529521658,"prompt-eng":0.3786538453,"data-quality":0.1077942898,"ml-security":0.1374541474}}
{"text":"This allows to express local properties of agents and global properties of worlds in a uniform way, as well as to talk about the presence or absence of agents in a world.","meta":{"url":"http://arxiv.org/abs/2308.00477v1"},"cats":{"new-dataset":0.1422323692,"dev-research":0.2705726165,"prompt-eng":0.3502816821,"data-quality":0.1200523441,"ml-security":0.0792803746}}
{"text":"The logic subsumes the standard epistemic logic and is a conservative extension of it.","meta":{"url":"http://arxiv.org/abs/2308.00477v1"},"cats":{"new-dataset":0.0492084661,"dev-research":0.2628203159,"prompt-eng":0.3091061762,"data-quality":0.0964751151,"ml-security":0.0574702605}}
{"text":"The semantics is given in chromatic hypergraphs, a generalization of chromatic simplicial complexes, which were recently used to model knowledge in distributed systems.","meta":{"url":"http://arxiv.org/abs/2308.00477v1"},"cats":{"new-dataset":0.2223345961,"dev-research":0.2453295122,"prompt-eng":0.3635056008,"data-quality":0.1648737001,"ml-security":0.0900088083}}
{"text":"We show that the logic is sound and complete with respect to the intended semantics.","meta":{"url":"http://arxiv.org/abs/2308.00477v1"},"cats":{"new-dataset":0.096574241,"dev-research":0.3515195201,"prompt-eng":0.4122179643,"data-quality":0.2664998536,"ml-security":0.1012920226}}
{"text":"We also show a further connection of chromatic hypergraphs with neighborhood frames.","meta":{"url":"http://arxiv.org/abs/2308.00477v1"},"cats":{"new-dataset":0.4413747467,"dev-research":0.1779791137,"prompt-eng":0.3328676723,"data-quality":0.2476212495,"ml-security":0.0785818399}}
{"text":"Simulating marine sponge growth helps marine biologists analyze, measure, and predict the effects that the marine environment has on marine sponges, and vice versa.","meta":{"url":"http://arxiv.org/abs/2308.00474v1"},"cats":{"new-dataset":0.0404410302,"dev-research":0.3157100651,"prompt-eng":0.331884624,"data-quality":0.1251945474,"ml-security":0.1193005409}}
{"text":"This paper describes a way to simulate and grow geometric models of the marine sponge Crella incrustans while considering environmental factors including fluid flow and nutrients.","meta":{"url":"http://arxiv.org/abs/2308.00474v1"},"cats":{"new-dataset":0.134741907,"dev-research":0.2480991783,"prompt-eng":0.3378814154,"data-quality":0.0885586657,"ml-security":0.0623880942}}
{"text":"The simulation improves upon prior work by changing the skeletal architecture of the sponge in the growth model to better suit the structure of Crella incrustans.","meta":{"url":"http://arxiv.org/abs/2308.00474v1"},"cats":{"new-dataset":0.1035326322,"dev-research":0.2141759586,"prompt-eng":0.3442675808,"data-quality":0.0930329104,"ml-security":0.0504775063}}
{"text":"The change in skeletal architecture and other simulation parameters are then evaluated qualitatively against photos of a real-life Crella incrustans sponge.","meta":{"url":"http://arxiv.org/abs/2308.00474v1"},"cats":{"new-dataset":0.1824733654,"dev-research":0.2127449124,"prompt-eng":0.370139484,"data-quality":0.0921146659,"ml-security":0.0561855185}}
{"text":"The results support the hypothesis that changing the skeletal architecture from radiate accretive to Halichondrid produces a sponge model which is closer in resemblance to Crella incrustans than the prior work.","meta":{"url":"http://arxiv.org/abs/2308.00474v1"},"cats":{"new-dataset":0.1006698794,"dev-research":0.1895088228,"prompt-eng":0.3720356878,"data-quality":0.1094290052,"ml-security":0.070276693}}
{"text":"Advances in neural fields are enabling high-fidelity capture of the shape and appearance of static and dynamic scenes.","meta":{"url":"http://arxiv.org/abs/2307.16897v1"},"cats":{"new-dataset":0.1559115831,"dev-research":0.2148593521,"prompt-eng":0.3844521208,"data-quality":0.1534603216,"ml-security":0.115428797}}
{"text":"However, their capabilities lag behind those offered by representations such as pixels or meshes due to algorithmic challenges and the lack of large-scale real-world datasets.","meta":{"url":"http://arxiv.org/abs/2307.16897v1"},"cats":{"new-dataset":0.2125398181,"dev-research":0.2454986145,"prompt-eng":0.3124956219,"data-quality":0.1099360193,"ml-security":0.1375140939}}
{"text":"We address the dataset limitation with DiVA-360, a real-world 360 dynamic visual-audio dataset with synchronized multimodal visual, audio, and textual information about table-scale scenes.","meta":{"url":"http://arxiv.org/abs/2307.16897v1"},"cats":{"new-dataset":0.789418989,"dev-research":0.1949388691,"prompt-eng":0.3099312167,"data-quality":0.1444384824,"ml-security":0.0536708002}}
{"text":"It contains 46 dynamic scenes, 30 static scenes, and 95 static objects spanning 11 categories captured using a new hardware system using 53 RGB cameras at 120 FPS and 6 microphones for a total of 8.6M image frames and 1360 s of dynamic data.","meta":{"url":"http://arxiv.org/abs/2307.16897v1"},"cats":{"new-dataset":0.7981186208,"dev-research":0.2298503085,"prompt-eng":0.3591299868,"data-quality":0.1190218751,"ml-security":0.0665316916}}
{"text":"We provide detailed text descriptions for all scenes, foreground-background segmentation masks, category-specific 3D pose alignment for static objects, as well as metrics for comparison.","meta":{"url":"http://arxiv.org/abs/2307.16897v1"},"cats":{"new-dataset":0.6488113673,"dev-research":0.2195204126,"prompt-eng":0.342088323,"data-quality":0.1730175247,"ml-security":0.0808770372}}
{"text":"Our data, hardware and software, and code are available at https://diva360.github.io/.","meta":{"url":"http://arxiv.org/abs/2307.16897v1"},"cats":{"new-dataset":0.7240488223,"dev-research":0.1985352692,"prompt-eng":0.4378117623,"data-quality":0.0865892619,"ml-security":0.032540741}}
{"text":"Harnessing the power of pre-training on large-scale datasets like ImageNet forms a fundamental building block for the progress of representation learning-driven solutions in computer vision.","meta":{"url":"http://arxiv.org/abs/2307.16896v1"},"cats":{"new-dataset":0.3550422913,"dev-research":0.2246715756,"prompt-eng":0.3660822304,"data-quality":0.1675428564,"ml-security":0.1694792728}}
{"text":"Medical images are inherently different from natural images as they are acquired in the form of many modalities (CT, MR, PET, Ultrasound etc.) and contain granulated information like tissue, lesion, organs etc.","meta":{"url":"http://arxiv.org/abs/2307.16896v1"},"cats":{"new-dataset":0.0379284881,"dev-research":0.1933788135,"prompt-eng":0.3250738782,"data-quality":0.1569547976,"ml-security":0.0933498378}}
{"text":"These characteristics of medical images require special attention towards learning features representative of local context.","meta":{"url":"http://arxiv.org/abs/2307.16896v1"},"cats":{"new-dataset":0.0932554478,"dev-research":0.2230442042,"prompt-eng":0.4024385603,"data-quality":0.1712093505,"ml-security":0.0918606102}}
{"text":"In this work, we focus on designing an effective pre-training framework for 3D radiology images.","meta":{"url":"http://arxiv.org/abs/2307.16896v1"},"cats":{"new-dataset":0.1978975024,"dev-research":0.2273757269,"prompt-eng":0.4166438029,"data-quality":0.1099983014,"ml-security":0.0523453167}}
{"text":"First, we propose a new masking strategy called local masking where the masking is performed across channel embeddings instead of tokens to improve the learning of local feature representations.","meta":{"url":"http://arxiv.org/abs/2307.16896v1"},"cats":{"new-dataset":0.0796219452,"dev-research":0.2843395291,"prompt-eng":0.3871246048,"data-quality":0.3574317015,"ml-security":0.2415681278}}
{"text":"We combine this with classical low-level perturbations like adding noise and downsampling to further enable low-level representation learning.","meta":{"url":"http://arxiv.org/abs/2307.16896v1"},"cats":{"new-dataset":0.1424559197,"dev-research":0.1829265516,"prompt-eng":0.3698826568,"data-quality":0.3036101582,"ml-security":0.1794488344}}
{"text":"To this end, we introduce Disruptive Autoencoders, a pre-training framework that attempts to reconstruct the original image from disruptions created by a combination of local masking and low-level perturbations.","meta":{"url":"http://arxiv.org/abs/2307.16896v1"},"cats":{"new-dataset":0.2168480064,"dev-research":0.2284039139,"prompt-eng":0.3939740952,"data-quality":0.2762856441,"ml-security":0.3223218172}}
{"text":"Additionally, we also devise a cross-modal contrastive loss (CMCL) to accommodate the pre-training of multiple modalities in a single framework.","meta":{"url":"http://arxiv.org/abs/2307.16896v1"},"cats":{"new-dataset":0.0986139459,"dev-research":0.2146239796,"prompt-eng":0.3979293213,"data-quality":0.2116651859,"ml-security":0.0963311184}}
{"text":"We curate a large-scale dataset to enable pre-training of 3D medical radiology images (MRI and CT).","meta":{"url":"http://arxiv.org/abs/2307.16896v1"},"cats":{"new-dataset":0.5765863666,"dev-research":0.2188665349,"prompt-eng":0.3383807595,"data-quality":0.1073165942,"ml-security":0.0884790088}}
{"text":"The proposed pre-training framework is tested across multiple downstream tasks and achieves state-of-the-art performance.","meta":{"url":"http://arxiv.org/abs/2307.16896v1"},"cats":{"new-dataset":0.0905022594,"dev-research":0.2369694707,"prompt-eng":0.4593968784,"data-quality":0.1709346229,"ml-security":0.0581453796}}
{"text":"Notably, our proposed method tops the public test leaderboard of BTCV multi-organ segmentation challenge.","meta":{"url":"http://arxiv.org/abs/2307.16896v1"},"cats":{"new-dataset":0.2334259239,"dev-research":0.1476867961,"prompt-eng":0.4382843765,"data-quality":0.1809814263,"ml-security":0.0864652577}}
{"text":"We study the problem of uncertainty quantification for time series prediction, with the goal of providing easy-to-use algorithms with formal guarantees.","meta":{"url":"http://arxiv.org/abs/2307.16895v1"},"cats":{"new-dataset":0.1542773189,"dev-research":0.2442598633,"prompt-eng":0.3751333049,"data-quality":0.1890585515,"ml-security":0.1918295437}}
{"text":"The algorithms we present build upon ideas from conformal prediction and control theory, are able to prospectively model conformal scores in an online setting, and adapt to the presence of systematic errors due to seasonality, trends, and general distribution shifts.","meta":{"url":"http://arxiv.org/abs/2307.16895v1"},"cats":{"new-dataset":0.0765941128,"dev-research":0.1494956166,"prompt-eng":0.427474543,"data-quality":0.1102109485,"ml-security":0.1003202124}}
{"text":"Our theory both simplifies and strengthens existing analyses in online conformal prediction.","meta":{"url":"http://arxiv.org/abs/2307.16895v1"},"cats":{"new-dataset":0.0414547451,"dev-research":0.1358530705,"prompt-eng":0.3724570574,"data-quality":0.1234343633,"ml-security":0.1300600114}}
{"text":"Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts in the U.S. show an improvement in coverage over the ensemble forecaster used in official CDC communications.","meta":{"url":"http://arxiv.org/abs/2307.16895v1"},"cats":{"new-dataset":0.2683564071,"dev-research":0.2190613662,"prompt-eng":0.3830565543,"data-quality":0.1139026432,"ml-security":0.1402297179}}
{"text":"We also run experiments on predicting electricity demand, market returns, and temperature using autoregressive, Theta, Prophet, and Transformer models.","meta":{"url":"http://arxiv.org/abs/2307.16895v1"},"cats":{"new-dataset":0.0733168824,"dev-research":0.1815256036,"prompt-eng":0.44689696,"data-quality":0.1036603322,"ml-security":0.1264734331}}
{"text":"We provide an extendable codebase for testing our methods and for the integration of new algorithms, data sets, and forecasting rules.","meta":{"url":"http://arxiv.org/abs/2307.16895v1"},"cats":{"new-dataset":0.4690561842,"dev-research":0.2859853646,"prompt-eng":0.404664087,"data-quality":0.1522820581,"ml-security":0.1117122967}}
{"text":"In recent years, there has been a growing interest in understanding complex microstructures and their effect on macroscopic properties.","meta":{"url":"http://arxiv.org/abs/2307.16894v1"},"cats":{"new-dataset":0.0510909305,"dev-research":0.2022824739,"prompt-eng":0.311457786,"data-quality":0.0682588263,"ml-security":0.0682861392}}
{"text":"In general, it is difficult to derive an effective constitutive law for such microstructures with reasonable accuracy and meaningful parameters.","meta":{"url":"http://arxiv.org/abs/2307.16894v1"},"cats":{"new-dataset":0.0487825714,"dev-research":0.1657173606,"prompt-eng":0.3608569306,"data-quality":0.1389625905,"ml-security":0.0653742263}}
{"text":"One numerical approach to bridge the scales is computational homogenization, in which a microscopic problem is solved at every macroscopic point, essentially replacing the effective constitutive model.","meta":{"url":"http://arxiv.org/abs/2307.16894v1"},"cats":{"new-dataset":0.040684531,"dev-research":0.1801527008,"prompt-eng":0.3177491692,"data-quality":0.0843097401,"ml-security":0.0733083994}}
{"text":"Such approaches are, however, computationally expensive and typically infeasible in multi-query contexts such as optimization and material design.","meta":{"url":"http://arxiv.org/abs/2307.16894v1"},"cats":{"new-dataset":0.0262350881,"dev-research":0.191033659,"prompt-eng":0.3981552327,"data-quality":0.0877862217,"ml-security":0.0414714133}}
{"text":"To render these analyses tractable, surrogate models that can accurately approximate and accelerate the microscopic problem over a large design space of shapes, material and loading parameters are required.","meta":{"url":"http://arxiv.org/abs/2307.16894v1"},"cats":{"new-dataset":0.0783789303,"dev-research":0.1881315103,"prompt-eng":0.3813914948,"data-quality":0.0654608841,"ml-security":0.0661659246}}
{"text":"In previous works, such models were constructed in a data-driven manner using methods such as Neural Networks (NN) or Gaussian Process Regression (GPR).","meta":{"url":"http://arxiv.org/abs/2307.16894v1"},"cats":{"new-dataset":0.1329441924,"dev-research":0.1874429809,"prompt-eng":0.4284754869,"data-quality":0.1258357782,"ml-security":0.0827754725}}
{"text":"However, these approaches currently suffer from issues, such as need for large amounts of training data, lack of physics, and considerable extrapolation errors.","meta":{"url":"http://arxiv.org/abs/2307.16894v1"},"cats":{"new-dataset":0.0750373705,"dev-research":0.2512498582,"prompt-eng":0.3444198856,"data-quality":0.2189919643,"ml-security":0.1487155659}}
{"text":"In this work, we develop a reduced order model based on Proper Orthogonal Decomposition (POD), Empirical Cubature Method (ECM) and a geometrical transformation method with the following key features: (i) large shape variations of the microstructure are captured, (ii) only relatively small amounts of training data are necessary, and (iii) highly non-linear history-dependent behaviors are treated.","meta":{"url":"http://arxiv.org/abs/2307.16894v1"},"cats":{"new-dataset":0.1167856038,"dev-research":0.167263007,"prompt-eng":0.3751409685,"data-quality":0.1313839922,"ml-security":0.0436724328}}
{"text":"The proposed framework is tested and examined in two numerical examples, involving two scales and large geometrical variations.","meta":{"url":"http://arxiv.org/abs/2307.16894v1"},"cats":{"new-dataset":0.0320526156,"dev-research":0.1273025319,"prompt-eng":0.3318834794,"data-quality":0.0774186546,"ml-security":0.0397105757}}
{"text":"In both cases, high speed-ups and accuracies are achieved while observing good extrapolation behavior.","meta":{"url":"http://arxiv.org/abs/2307.16894v1"},"cats":{"new-dataset":0.0126112852,"dev-research":0.2880313089,"prompt-eng":0.3966658872,"data-quality":0.185326422,"ml-security":0.0860494383}}
{"text":"Autonomous robots deployed in the real world will need control policies that rapidly adapt to environmental changes.","meta":{"url":"http://arxiv.org/abs/2307.16890v1"},"cats":{"new-dataset":0.1598356905,"dev-research":0.2724379567,"prompt-eng":0.3924647369,"data-quality":0.071808328,"ml-security":0.1466837467}}
{"text":"To this end, we propose AutoRobotics-Zero (ARZ), a method based on AutoML-Zero that discovers zero-shot adaptable policies from scratch.","meta":{"url":"http://arxiv.org/abs/2307.16890v1"},"cats":{"new-dataset":0.1848087468,"dev-research":0.2689461185,"prompt-eng":0.4562556652,"data-quality":0.1771737487,"ml-security":0.2701054153}}
{"text":"In contrast to neural network adaption policies, where only model parameters are optimized, ARZ can build control algorithms with the full expressive power of a linear register machine.","meta":{"url":"http://arxiv.org/abs/2307.16890v1"},"cats":{"new-dataset":0.0803671699,"dev-research":0.34299274,"prompt-eng":0.3646682995,"data-quality":0.0986052205,"ml-security":0.2269322721}}
{"text":"We evolve modular policies that tune their model parameters and alter their inference algorithm on-the-fly to adapt to sudden environmental changes.","meta":{"url":"http://arxiv.org/abs/2307.16890v1"},"cats":{"new-dataset":0.1086759143,"dev-research":0.2798635828,"prompt-eng":0.4174242341,"data-quality":0.1148963307,"ml-security":0.2561339131}}
{"text":"We demonstrate our method on a realistic simulated quadruped robot, for which we evolve safe control policies that avoid falling when individual limbs suddenly break.","meta":{"url":"http://arxiv.org/abs/2307.16890v1"},"cats":{"new-dataset":0.3876374979,"dev-research":0.2273880487,"prompt-eng":0.3658346879,"data-quality":0.0679970491,"ml-security":0.16068846}}
{"text":"This is a challenging task in which two popular neural network baselines fail.","meta":{"url":"http://arxiv.org/abs/2307.16890v1"},"cats":{"new-dataset":0.1971477259,"dev-research":0.2150627726,"prompt-eng":0.3913696467,"data-quality":0.385185137,"ml-security":0.145779909}}
{"text":"Finally, we conduct a detailed analysis of our method on a novel and challenging non-stationary control task dubbed Cataclysmic Cartpole.","meta":{"url":"http://arxiv.org/abs/2307.16890v1"},"cats":{"new-dataset":0.0882881827,"dev-research":0.1945871086,"prompt-eng":0.46539068,"data-quality":0.0795611108,"ml-security":0.0410386593}}
{"text":"Results confirm our findings that ARZ is significantly more robust to sudden environmental changes and can build simple, interpretable control policies.","meta":{"url":"http://arxiv.org/abs/2307.16890v1"},"cats":{"new-dataset":0.1102230119,"dev-research":0.401342441,"prompt-eng":0.4209002838,"data-quality":0.1376510186,"ml-security":0.1868404307}}
{"text":"We present Virtual Prompt Injection (VPI) for instruction-tuned Large Language Models (LLMs).","meta":{"url":"http://arxiv.org/abs/2307.16888v1"},"cats":{"new-dataset":0.1256784949,"dev-research":0.3130892262,"prompt-eng":0.5616038863,"data-quality":0.1653893399,"ml-security":0.1855814333}}
{"text":"VPI allows an attacker-specified virtual prompt to steer the model behavior under specific trigger scenario without any explicit injection in model input.","meta":{"url":"http://arxiv.org/abs/2307.16888v1"},"cats":{"new-dataset":0.0245316281,"dev-research":0.3263756958,"prompt-eng":0.5090891139,"data-quality":0.1348761251,"ml-security":0.5828536028}}
{"text":"For instance, if an LLM is compromised with the virtual prompt \"Describe Joe Biden negatively.\"","meta":{"url":"http://arxiv.org/abs/2307.16888v1"},"cats":{"new-dataset":0.0162881582,"dev-research":0.2745797104,"prompt-eng":0.504218919,"data-quality":0.3050968308,"ml-security":0.6211403576}}
{"text":"for Joe Biden-related instructions, then any service deploying this model will propagate biased views when handling user queries related to Joe Biden.","meta":{"url":"http://arxiv.org/abs/2307.16888v1"},"cats":{"new-dataset":0.0693515878,"dev-research":0.228330138,"prompt-eng":0.4207131768,"data-quality":0.1616619126,"ml-security":0.1959484877}}
{"text":"VPI is especially harmful for two primary reasons.","meta":{"url":"http://arxiv.org/abs/2307.16888v1"},"cats":{"new-dataset":0.0121972304,"dev-research":0.2451647194,"prompt-eng":0.2889426437,"data-quality":0.1312309421,"ml-security":0.2906169322}}
{"text":"Firstly, the attacker can take fine-grained control over LLM behaviors by defining various virtual prompts, exploiting LLMs' proficiency in following instructions.","meta":{"url":"http://arxiv.org/abs/2307.16888v1"},"cats":{"new-dataset":0.0264092753,"dev-research":0.2880899393,"prompt-eng":0.546098884,"data-quality":0.1494756694,"ml-security":0.6807455253}}
{"text":"Secondly, this control is achieved without any interaction from the attacker while the model is in service, leading to persistent attack.","meta":{"url":"http://arxiv.org/abs/2307.16888v1"},"cats":{"new-dataset":0.0159494599,"dev-research":0.255413683,"prompt-eng":0.3884694496,"data-quality":0.1074982461,"ml-security":0.5354490053}}
{"text":"To demonstrate the threat, we propose a simple method for performing VPI by poisoning the model's instruction tuning data.","meta":{"url":"http://arxiv.org/abs/2307.16888v1"},"cats":{"new-dataset":0.0404288494,"dev-research":0.4025662884,"prompt-eng":0.4915287663,"data-quality":0.2010853573,"ml-security":0.3447111973}}
{"text":"We find that our proposed method is highly effective in steering the LLM with VPI.","meta":{"url":"http://arxiv.org/abs/2307.16888v1"},"cats":{"new-dataset":0.0245341972,"dev-research":0.1862119693,"prompt-eng":0.475356187,"data-quality":0.0902074549,"ml-security":0.0706436932}}
{"text":"For example, by injecting only 52 poisoned examples (0.1% of the training data size) into the instruction tuning data, the percentage of negative responses given by the trained model on Joe Biden-related queries change from 0% to 40%.","meta":{"url":"http://arxiv.org/abs/2307.16888v1"},"cats":{"new-dataset":0.0453815038,"dev-research":0.2730056198,"prompt-eng":0.4036242513,"data-quality":0.3129907963,"ml-security":0.3935098276}}
{"text":"We thus highlight the necessity of ensuring the integrity of the instruction-tuning data as little poisoned data can cause stealthy and persistent harm to the deployed model.","meta":{"url":"http://arxiv.org/abs/2307.16888v1"},"cats":{"new-dataset":0.1335694403,"dev-research":0.4771345126,"prompt-eng":0.4848226444,"data-quality":0.3576889405,"ml-security":0.5249501992}}
{"text":"We further explore the possible defenses and identify data filtering as an effective way to defend against the poisoning attacks.","meta":{"url":"http://arxiv.org/abs/2307.16888v1"},"cats":{"new-dataset":0.0721928922,"dev-research":0.3302341027,"prompt-eng":0.4098000283,"data-quality":0.2965629933,"ml-security":0.7717801492}}
{"text":"Our project page is available at https://poison-llm.github.io.","meta":{"url":"http://arxiv.org/abs/2307.16888v1"},"cats":{"new-dataset":0.3411299237,"dev-research":0.1790554442,"prompt-eng":0.4416842436,"data-quality":0.106624208,"ml-security":0.0985761256}}
{"text":"This paper develops a data-based moving horizon estimation (MHE) method for agile quadrotors.","meta":{"url":"http://arxiv.org/abs/2307.16887v1"},"cats":{"new-dataset":0.1269639841,"dev-research":0.244754601,"prompt-eng":0.3360824461,"data-quality":0.0536712222,"ml-security":0.0702131421}}
{"text":"Accurate state estimation of the system is paramount for precise trajectory control for agile quadrotors; however, the high level of aerodynamic forces experienced by the quadrotors during high-speed flights make this task extremely challenging.","meta":{"url":"http://arxiv.org/abs/2307.16887v1"},"cats":{"new-dataset":0.1446314819,"dev-research":0.2546532115,"prompt-eng":0.3909314377,"data-quality":0.0766156461,"ml-security":0.1138572453}}
{"text":"These complex turbulent effects are difficult to model and the unmodelled dynamics introduce inaccuracies in the state estimation.","meta":{"url":"http://arxiv.org/abs/2307.16887v1"},"cats":{"new-dataset":0.033311393,"dev-research":0.1870152832,"prompt-eng":0.2838270388,"data-quality":0.1721243248,"ml-security":0.1222083522}}
{"text":"In this work, we propose a method to model these aerodynamic effects using Gaussian Processes which we integrate into the MHE to achieve efficient and accurate state estimation with minimal computational burden.","meta":{"url":"http://arxiv.org/abs/2307.16887v1"},"cats":{"new-dataset":0.1549470668,"dev-research":0.1935801827,"prompt-eng":0.3679877384,"data-quality":0.0595789762,"ml-security":0.0894110302}}
{"text":"Through extensive simulation and experimental studies, this method has demonstrated significant improvement in state estimation performance displaying superior robustness to poor state measurements.","meta":{"url":"http://arxiv.org/abs/2307.16887v1"},"cats":{"new-dataset":0.0706409994,"dev-research":0.1983165209,"prompt-eng":0.4622113697,"data-quality":0.1954976593,"ml-security":0.0815410696}}
{"text":"A new pre-exascale computer cluster has been designed to foster scientific progress and competitive innovation across European research systems, it is called LEONARDO.","meta":{"url":"http://arxiv.org/abs/2307.16885v1"},"cats":{"new-dataset":0.1049645938,"dev-research":0.3321968954,"prompt-eng":0.3951636901,"data-quality":0.0752112095,"ml-security":0.0520992833}}
{"text":"This paper describes the general architecture of the system and focuses on the technologies adopted for its GPU-accelerated partition.","meta":{"url":"http://arxiv.org/abs/2307.16885v1"},"cats":{"new-dataset":0.0620299863,"dev-research":0.2093051224,"prompt-eng":0.3944388367,"data-quality":0.0545761694,"ml-security":0.044157277}}
{"text":"High density processing elements, fast data movement capabilities and mature software stack collections allow the machine to run intensive workloads in a flexible and scalable way.","meta":{"url":"http://arxiv.org/abs/2307.16885v1"},"cats":{"new-dataset":0.2863338225,"dev-research":0.3115796516,"prompt-eng":0.3802987829,"data-quality":0.0702942882,"ml-security":0.053055234}}
{"text":"Scientific applications from traditional High Performance Computing (HPC) as well as emerging Artificial Intelligence (AI) domains can benefit from this large apparatus in terms of time and energy to solution.","meta":{"url":"http://arxiv.org/abs/2307.16885v1"},"cats":{"new-dataset":0.0562218387,"dev-research":0.1991503101,"prompt-eng":0.3530363441,"data-quality":0.0742210968,"ml-security":0.0789372454}}
{"text":"The rise of large language models (LLMs) had a transformative impact on search, ushering in a new era of search engines that are capable of generating search results in natural language text, imbued with citations for supporting sources.","meta":{"url":"http://arxiv.org/abs/2307.16883v1"},"cats":{"new-dataset":0.0753575291,"dev-research":0.1576750441,"prompt-eng":0.3701881834,"data-quality":0.1488785647,"ml-security":0.1132060575}}
{"text":"Building generative information-seeking models demands openly accessible datasets, which currently remain lacking.","meta":{"url":"http://arxiv.org/abs/2307.16883v1"},"cats":{"new-dataset":0.1645338013,"dev-research":0.2117476777,"prompt-eng":0.3750546338,"data-quality":0.1323810451,"ml-security":0.1315655019}}
{"text":"In this paper, we introduce a new dataset, HAGRID (Human-in-the-loop Attributable Generative Retrieval for Information-seeking Dataset) for building end-to-end generative information-seeking models that are capable of retrieving candidate quotes and generating attributed explanations.","meta":{"url":"http://arxiv.org/abs/2307.16883v1"},"cats":{"new-dataset":0.4063079528,"dev-research":0.2751392802,"prompt-eng":0.3848653241,"data-quality":0.2064282922,"ml-security":0.087232701}}
{"text":"Unlike recent efforts that focus on human evaluation of black-box proprietary search engines, we built our dataset atop the English subset of MIRACL, a publicly available information retrieval dataset.","meta":{"url":"http://arxiv.org/abs/2307.16883v1"},"cats":{"new-dataset":0.5342686228,"dev-research":0.223490243,"prompt-eng":0.3938188306,"data-quality":0.2515603895,"ml-security":0.1560036356}}
{"text":"HAGRID is constructed based on human and LLM collaboration.","meta":{"url":"http://arxiv.org/abs/2307.16883v1"},"cats":{"new-dataset":0.2170033379,"dev-research":0.2739031514,"prompt-eng":0.3974061122,"data-quality":0.0630073222,"ml-security":0.0363393684}}
{"text":"We first automatically collect attributed explanations that follow an in-context citation style using an LLM, i.e. GPT-3.5.","meta":{"url":"http://arxiv.org/abs/2307.16883v1"},"cats":{"new-dataset":0.1308544901,"dev-research":0.3053142063,"prompt-eng":0.414157389,"data-quality":0.3280823495,"ml-security":0.0974601534}}
{"text":"Next, we ask human annotators to evaluate the LLM explanations based on two criteria: informativeness and attributability.","meta":{"url":"http://arxiv.org/abs/2307.16883v1"},"cats":{"new-dataset":0.0395685168,"dev-research":0.370435183,"prompt-eng":0.4631519826,"data-quality":0.3414248065,"ml-security":0.1644808186}}
{"text":"HAGRID serves as a catalyst for the development of information-seeking models with better attribution capabilities.","meta":{"url":"http://arxiv.org/abs/2307.16883v1"},"cats":{"new-dataset":0.0292209588,"dev-research":0.240395521,"prompt-eng":0.3984140547,"data-quality":0.1394222504,"ml-security":0.0816666072}}
{"text":"Deep generative models, which target reproducing the given data distribution to produce novel samples, have made unprecedented advancements in recent years.","meta":{"url":"http://arxiv.org/abs/2307.16879v1"},"cats":{"new-dataset":0.4404156917,"dev-research":0.2235269759,"prompt-eng":0.3846686907,"data-quality":0.23824545,"ml-security":0.1808389753}}
{"text":"Their technical breakthroughs have enabled unparalleled quality in the synthesis of visual content.","meta":{"url":"http://arxiv.org/abs/2307.16879v1"},"cats":{"new-dataset":0.0699095511,"dev-research":0.431452908,"prompt-eng":0.3658879812,"data-quality":0.1860436853,"ml-security":0.0572062776}}
{"text":"However, one critical prerequisite for their tremendous success is the availability of a sufficient number of training samples, which requires massive computation resources.","meta":{"url":"http://arxiv.org/abs/2307.16879v1"},"cats":{"new-dataset":0.1129246836,"dev-research":0.2201753227,"prompt-eng":0.3613093344,"data-quality":0.1470379155,"ml-security":0.1178782918}}
{"text":"When trained on limited data, generative models tend to suffer from severe performance deterioration due to overfitting and memorization.","meta":{"url":"http://arxiv.org/abs/2307.16879v1"},"cats":{"new-dataset":0.0399412645,"dev-research":0.2971758235,"prompt-eng":0.3634102599,"data-quality":0.2624190277,"ml-security":0.2441942624}}
{"text":"Accordingly, researchers have devoted considerable attention to develop novel models that are capable of generating plausible and diverse images from limited training data recently.","meta":{"url":"http://arxiv.org/abs/2307.16879v1"},"cats":{"new-dataset":0.2012290123,"dev-research":0.1540685473,"prompt-eng":0.3830119939,"data-quality":0.1686510859,"ml-security":0.1496997668}}
{"text":"Despite numerous efforts to enhance training stability and synthesis quality in the limited data scenarios, there is a lack of a systematic survey that provides 1) a clear problem definition, critical challenges, and taxonomy of various tasks; 2) an in-depth analysis on the pros, cons, and remain limitations of existing literature; as well as 3) a thorough discussion on the potential applications and future directions in the field of image synthesis under limited data.","meta":{"url":"http://arxiv.org/abs/2307.16879v1"},"cats":{"new-dataset":0.3293622481,"dev-research":0.223259189,"prompt-eng":0.4030066845,"data-quality":0.1626931324,"ml-security":0.0670698242}}
{"text":"In order to fill this gap and provide a informative introduction to researchers who are new to this topic, this survey offers a comprehensive review and a novel taxonomy on the development of image synthesis under limited data.","meta":{"url":"http://arxiv.org/abs/2307.16879v1"},"cats":{"new-dataset":0.1960290385,"dev-research":0.2202829069,"prompt-eng":0.4155917392,"data-quality":0.1262801566,"ml-security":0.0612217793}}
{"text":"In particular, it covers the problem definition, requirements, main solutions, popular benchmarks, and remain challenges in a comprehensive and all-around manner.","meta":{"url":"http://arxiv.org/abs/2307.16879v1"},"cats":{"new-dataset":0.3173337559,"dev-research":0.3406205354,"prompt-eng":0.3635945776,"data-quality":0.1050129048,"ml-security":0.065707446}}
{"text":"We present a novel approach - CLAA - for API aspect detection in API reviews that utilizes transformer models trained with a supervised contrastive loss objective function.","meta":{"url":"http://arxiv.org/abs/2307.16878v1"},"cats":{"new-dataset":0.0875244279,"dev-research":0.2991352675,"prompt-eng":0.3757937518,"data-quality":0.3783824895,"ml-security":0.1212683329}}
{"text":"We evaluate CLAA using performance and impact analysis.","meta":{"url":"http://arxiv.org/abs/2307.16878v1"},"cats":{"new-dataset":0.0973978036,"dev-research":0.341048833,"prompt-eng":0.3988791855,"data-quality":0.1124947582,"ml-security":0.05976899}}
{"text":"For performance analysis, we utilized a benchmark dataset on developer discussions collected from Stack Overflow and compare the results to those obtained using state-of-the-art transformer models.","meta":{"url":"http://arxiv.org/abs/2307.16878v1"},"cats":{"new-dataset":0.1176642982,"dev-research":0.3581554148,"prompt-eng":0.4330576527,"data-quality":0.145119827,"ml-security":0.076128987}}
{"text":"Our experiments show that contrastive learning can significantly improve the performance of transformer models in detecting aspects such as Performance, Security, Usability, and Documentation.","meta":{"url":"http://arxiv.org/abs/2307.16878v1"},"cats":{"new-dataset":0.0546871181,"dev-research":0.2884046339,"prompt-eng":0.4417163525,"data-quality":0.2121586684,"ml-security":0.1999101537}}
{"text":"For impact analysis, we performed empirical and developer study.","meta":{"url":"http://arxiv.org/abs/2307.16878v1"},"cats":{"new-dataset":0.1123657349,"dev-research":0.5056088496,"prompt-eng":0.3763764197,"data-quality":0.1495188165,"ml-security":0.080368199}}
{"text":"On a randomly selected and manually labeled 200 online reviews, CLAA achieved 92% accuracy while the SOTA baseline achieved 81.5%.","meta":{"url":"http://arxiv.org/abs/2307.16878v1"},"cats":{"new-dataset":0.0439621932,"dev-research":0.2125789007,"prompt-eng":0.3747458135,"data-quality":0.2443207746,"ml-security":0.0330267667}}
{"text":"According to our developer study involving 10 participants, the use of 'Stack Overflow + CLAA' resulted in increased accuracy and confidence during API selection.","meta":{"url":"http://arxiv.org/abs/2307.16878v1"},"cats":{"new-dataset":0.0281277029,"dev-research":0.4174018149,"prompt-eng":0.4044114706,"data-quality":0.104518598,"ml-security":0.0997148832}}
{"text":"Replication package: https://github.com/shahariar-shibli/Contrastive-Learning-for-API-Aspect-Analysis","meta":{"url":"http://arxiv.org/abs/2307.16878v1"},"cats":{"new-dataset":0.3435273759,"dev-research":0.2730760076,"prompt-eng":0.3639810809,"data-quality":0.1671739586,"ml-security":0.0583020368}}
{"text":"Retriever-augmented instruction-following models are attractive alternatives to fine-tuned approaches for information-seeking tasks such as question answering (QA).","meta":{"url":"http://arxiv.org/abs/2307.16877v1"},"cats":{"new-dataset":0.0440493034,"dev-research":0.2277254279,"prompt-eng":0.4959633586,"data-quality":0.1152692574,"ml-security":0.0487215228}}
{"text":"By simply prepending retrieved documents in its input along with an instruction, these models can be adapted to various information domains and tasks without additional fine-tuning.","meta":{"url":"http://arxiv.org/abs/2307.16877v1"},"cats":{"new-dataset":0.1437406279,"dev-research":0.3182930068,"prompt-eng":0.4716371849,"data-quality":0.1525534295,"ml-security":0.0744576258}}
{"text":"While the model responses tend to be natural and fluent, the additional verbosity makes traditional QA evaluation metrics such as exact match (EM) and F1 unreliable for accurately quantifying model performance.   ","meta":{"url":"http://arxiv.org/abs/2307.16877v1"},"cats":{"new-dataset":0.0211063683,"dev-research":0.3302693929,"prompt-eng":0.4314344261,"data-quality":0.2937837119,"ml-security":0.073993181}}
{"text":"In this work, we investigate the performance of instruction-following models across three information-seeking QA tasks.","meta":{"url":"http://arxiv.org/abs/2307.16877v1"},"cats":{"new-dataset":0.0292967641,"dev-research":0.2452419052,"prompt-eng":0.5039682289,"data-quality":0.1082910271,"ml-security":0.0350072574}}
{"text":"We use both automatic and human evaluation to evaluate these models along two dimensions: 1) how well they satisfy the user's information need (correctness), and 2) whether they produce a response based on the provided knowledge (faithfulness).","meta":{"url":"http://arxiv.org/abs/2307.16877v1"},"cats":{"new-dataset":0.087604446,"dev-research":0.2388370068,"prompt-eng":0.5112656072,"data-quality":0.2846167084,"ml-security":0.0829809329}}
{"text":"Guided by human evaluation and analysis, we highlight the shortcomings of traditional metrics for both correctness and faithfulness.","meta":{"url":"http://arxiv.org/abs/2307.16877v1"},"cats":{"new-dataset":0.0613941427,"dev-research":0.3579208813,"prompt-eng":0.4358124356,"data-quality":0.4491084501,"ml-security":0.1146255695}}
{"text":"We then propose simple token-overlap based and model-based metrics that reflect the true performance of these models.","meta":{"url":"http://arxiv.org/abs/2307.16877v1"},"cats":{"new-dataset":0.0438385898,"dev-research":0.2420710923,"prompt-eng":0.4740325381,"data-quality":0.2701153986,"ml-security":0.0956332731}}
{"text":"Our analysis reveals that instruction-following models are competitive, and sometimes even outperform fine-tuned models for correctness.","meta":{"url":"http://arxiv.org/abs/2307.16877v1"},"cats":{"new-dataset":0.0337439461,"dev-research":0.4234294007,"prompt-eng":0.4622836244,"data-quality":0.278925126,"ml-security":0.1177711392}}
{"text":"However, these models struggle to stick to the provided knowledge and often hallucinate in their responses.","meta":{"url":"http://arxiv.org/abs/2307.16877v1"},"cats":{"new-dataset":0.0223834863,"dev-research":0.2631768326,"prompt-eng":0.3859436767,"data-quality":0.2215256266,"ml-security":0.1641354885}}
{"text":"We hope our work encourages a more holistic evaluation of instruction-following models for QA.","meta":{"url":"http://arxiv.org/abs/2307.16877v1"},"cats":{"new-dataset":0.0799314471,"dev-research":0.3012001023,"prompt-eng":0.4464964688,"data-quality":0.1281181384,"ml-security":0.0570931107}}
{"text":"Our code and data is available at https://github.com/McGill-NLP/instruct-qa","meta":{"url":"http://arxiv.org/abs/2307.16877v1"},"cats":{"new-dataset":0.6154003014,"dev-research":0.1608588288,"prompt-eng":0.4455221933,"data-quality":0.1169638846,"ml-security":0.0277971165}}
{"text":"Current state-of-the-art results in computer vision depend in part on fine-tuning large pre-trained vision models.","meta":{"url":"http://arxiv.org/abs/2307.16867v1"},"cats":{"new-dataset":0.2002764997,"dev-research":0.1924433823,"prompt-eng":0.4282812517,"data-quality":0.1941029751,"ml-security":0.0748301064}}
{"text":"However, with the exponential growth of model sizes, the conventional full fine-tuning, which needs to store a individual network copy for each tasks, leads to increasingly huge storage and transmission overhead.","meta":{"url":"http://arxiv.org/abs/2307.16867v1"},"cats":{"new-dataset":0.0318229218,"dev-research":0.2800178973,"prompt-eng":0.3598393777,"data-quality":0.091829263,"ml-security":0.1143769228}}
{"text":"Adapter-based Parameter-Efficient Tuning (PET) methods address this challenge by tuning lightweight adapters inserted into the frozen pre-trained models.","meta":{"url":"http://arxiv.org/abs/2307.16867v1"},"cats":{"new-dataset":0.044269325,"dev-research":0.278191223,"prompt-eng":0.5064358777,"data-quality":0.185015461,"ml-security":0.1067935284}}
{"text":"In this paper, we investigate how to make adapters even more efficient, reaching a new minimum size required to store a task-specific fine-tuned network.","meta":{"url":"http://arxiv.org/abs/2307.16867v1"},"cats":{"new-dataset":0.0753384637,"dev-research":0.306184556,"prompt-eng":0.3966824707,"data-quality":0.1154602221,"ml-security":0.1054730403}}
{"text":"Inspired by the observation that the parameters of adapters converge at flat local minima, we find that adapters are resistant to noise in parameter space, which means they are also resistant to low numerical precision.","meta":{"url":"http://arxiv.org/abs/2307.16867v1"},"cats":{"new-dataset":0.0304670901,"dev-research":0.1898755572,"prompt-eng":0.3604003489,"data-quality":0.2142351591,"ml-security":0.1316467488}}
{"text":"To train low-precision adapters, we propose a computational-efficient quantization method which minimizes the quantization error.","meta":{"url":"http://arxiv.org/abs/2307.16867v1"},"cats":{"new-dataset":0.0443170523,"dev-research":0.2715610058,"prompt-eng":0.3956975518,"data-quality":0.2761770553,"ml-security":0.1429418615}}
{"text":"Through extensive experiments, we find that low-precision adapters exhibit minimal performance degradation, and even 1-bit precision is sufficient for adapters.","meta":{"url":"http://arxiv.org/abs/2307.16867v1"},"cats":{"new-dataset":0.0212541382,"dev-research":0.3280872561,"prompt-eng":0.4274705099,"data-quality":0.2486461793,"ml-security":0.1275309133}}
{"text":"The experimental results demonstrate that 1-bit adapters outperform all other PET methods on both the VTAB-1K benchmark and few-shot FGVC tasks, while requiring the smallest storage size.","meta":{"url":"http://arxiv.org/abs/2307.16867v1"},"cats":{"new-dataset":0.1415506212,"dev-research":0.2730520882,"prompt-eng":0.4194989512,"data-quality":0.1336610076,"ml-security":0.0602731502}}
{"text":"Our findings show, for the first time, the significant potential of quantization techniques in PET, providing a general solution to enhance the parameter efficiency of adapter-based PET methods.","meta":{"url":"http://arxiv.org/abs/2307.16867v1"},"cats":{"new-dataset":0.0403559801,"dev-research":0.2496756208,"prompt-eng":0.4493050389,"data-quality":0.1210194329,"ml-security":0.059618468}}
{"text":"Code: https://github.com/JieShibo/PETL-ViT","meta":{"url":"http://arxiv.org/abs/2307.16867v1"},"cats":{"new-dataset":0.4327210586,"dev-research":0.2050530878,"prompt-eng":0.4641461204,"data-quality":0.0954711363,"ml-security":0.0345011953}}
{"text":"Deep neural networks (DNNs) have achieved tremendous success in many remote sensing (RS) applications.","meta":{"url":"http://arxiv.org/abs/2307.16865v1"},"cats":{"new-dataset":0.2806244885,"dev-research":0.2263803818,"prompt-eng":0.3605897997,"data-quality":0.1383946785,"ml-security":0.1486637601}}
{"text":"However, their vulnerability to the threat of adversarial perturbations should not be neglected.","meta":{"url":"http://arxiv.org/abs/2307.16865v1"},"cats":{"new-dataset":0.0187834215,"dev-research":0.2346415123,"prompt-eng":0.3206359963,"data-quality":0.36704474,"ml-security":0.8128366416}}
{"text":"Unfortunately, current adversarial defense approaches in RS studies usually suffer from performance fluctuation and unnecessary re-training costs due to the need for prior knowledge of the adversarial perturbations among RS data.","meta":{"url":"http://arxiv.org/abs/2307.16865v1"},"cats":{"new-dataset":0.0975217758,"dev-research":0.2456649603,"prompt-eng":0.3387098885,"data-quality":0.236849349,"ml-security":0.8017660815}}
{"text":"To circumvent these challenges, we propose a universal adversarial defense approach in RS imagery (UAD-RS) using pre-trained diffusion models to defend the common DNNs against multiple unknown adversarial attacks.","meta":{"url":"http://arxiv.org/abs/2307.16865v1"},"cats":{"new-dataset":0.2261799079,"dev-research":0.2234060082,"prompt-eng":0.3374311226,"data-quality":0.1933356196,"ml-security":0.7638676389}}
{"text":"Specifically, the generative diffusion models are first pre-trained on different RS datasets to learn generalized representations in various data domains.","meta":{"url":"http://arxiv.org/abs/2307.16865v1"},"cats":{"new-dataset":0.2134346922,"dev-research":0.1753320192,"prompt-eng":0.3567101205,"data-quality":0.104884254,"ml-security":0.0994597956}}
{"text":"After that, a universal adversarial purification framework is developed using the forward and reverse process of the pre-trained diffusion models to purify the perturbations from adversarial samples.","meta":{"url":"http://arxiv.org/abs/2307.16865v1"},"cats":{"new-dataset":0.0561629062,"dev-research":0.1780791456,"prompt-eng":0.327929596,"data-quality":0.2678973296,"ml-security":0.6750087273}}
{"text":"Furthermore, an adaptive noise level selection (ANLS) mechanism is built to capture the optimal noise level of the diffusion model that can achieve the best purification results closest to the clean samples according to their Frechet Inception Distance (FID) in deep feature space.","meta":{"url":"http://arxiv.org/abs/2307.16865v1"},"cats":{"new-dataset":0.0563300464,"dev-research":0.2064129411,"prompt-eng":0.372902836,"data-quality":0.2574387528,"ml-security":0.2361780504}}
{"text":"As a result, only a single pre-trained diffusion model is needed for the universal purification of adversarial samples on each dataset, which significantly alleviates the re-training efforts for each attack setting and maintains high performance without the prior knowledge of adversarial perturbations.","meta":{"url":"http://arxiv.org/abs/2307.16865v1"},"cats":{"new-dataset":0.0745474628,"dev-research":0.1797058677,"prompt-eng":0.3203584451,"data-quality":0.2231287059,"ml-security":0.7943203499}}
{"text":"Experiments on four heterogeneous RS datasets regarding scene classification and semantic segmentation verify that UAD-RS outperforms state-of-the-art adversarial purification approaches with a universal defense against seven commonly existing adversarial perturbations.","meta":{"url":"http://arxiv.org/abs/2307.16865v1"},"cats":{"new-dataset":0.297274978,"dev-research":0.1835544415,"prompt-eng":0.3345629616,"data-quality":0.2933890827,"ml-security":0.4983058546}}
{"text":"We investigate winner determination for two popular proportional representation systems: the Monroe and Chamberlin-Courant (abbrv. CC) systems.","meta":{"url":"http://arxiv.org/abs/2307.16864v1"},"cats":{"new-dataset":0.0522638382,"dev-research":0.1404241667,"prompt-eng":0.3998423955,"data-quality":0.1880491704,"ml-security":0.1674577772}}
{"text":"Our study focuses on (nearly) single-peaked resp.","meta":{"url":"http://arxiv.org/abs/2307.16864v1"},"cats":{"new-dataset":0.1226737517,"dev-research":0.1549739591,"prompt-eng":0.3926085216,"data-quality":0.0782048713,"ml-security":0.0430240561}}
{"text":"single-crossing preferences.","meta":{"url":"http://arxiv.org/abs/2307.16864v1"},"cats":{"new-dataset":0.0376159121,"dev-research":0.2724013784,"prompt-eng":0.4831589296,"data-quality":0.0978791969,"ml-security":0.0965502028}}
{"text":"We show that for single-crossing approval preferences, winner determination of the Monroe rule is polynomial, and for both rules, winner determination mostly admits FPT algorithms with respect to the number of voters to delete to obtain single-peaked or single-crossing preferences.","meta":{"url":"http://arxiv.org/abs/2307.16864v1"},"cats":{"new-dataset":0.0486874702,"dev-research":0.1581616334,"prompt-eng":0.4224829761,"data-quality":0.2063009529,"ml-security":0.2197418343}}
{"text":"Our results answer some complexity questions from the literature [18, 28, 21].","meta":{"url":"http://arxiv.org/abs/2307.16864v1"},"cats":{"new-dataset":0.1480641077,"dev-research":0.2048970126,"prompt-eng":0.3474472007,"data-quality":0.1751485251,"ml-security":0.100412636}}
{"text":"The need for clear, trustworthy explanations of deep learning model predictions is essential for high-criticality fields, such as medicine and biometric identification.","meta":{"url":"http://arxiv.org/abs/2307.16863v1"},"cats":{"new-dataset":0.0704661113,"dev-research":0.2395379749,"prompt-eng":0.3463270378,"data-quality":0.2320635627,"ml-security":0.4386945016}}
{"text":"Class Activation Maps (CAMs) are an increasingly popular category of visual explanation methods for Convolutional Neural Networks (CNNs).","meta":{"url":"http://arxiv.org/abs/2307.16863v1"},"cats":{"new-dataset":0.1137364317,"dev-research":0.3591967366,"prompt-eng":0.3676331488,"data-quality":0.2209038989,"ml-security":0.184333883}}
{"text":"However, the performance of individual CAMs depends largely on experimental parameters such as the selected image, target class, and model.","meta":{"url":"http://arxiv.org/abs/2307.16863v1"},"cats":{"new-dataset":0.0153816985,"dev-research":0.224728609,"prompt-eng":0.3843489835,"data-quality":0.1048935755,"ml-security":0.0420914596}}
{"text":"Here, we propose MetaCAM, an ensemble-based method for combining multiple existing CAM methods based on the consensus of the top-k% most highly activated pixels across component CAMs.","meta":{"url":"http://arxiv.org/abs/2307.16863v1"},"cats":{"new-dataset":0.2199798125,"dev-research":0.2460105235,"prompt-eng":0.4128699515,"data-quality":0.195996483,"ml-security":0.1033282788}}
{"text":"We perform experiments to quantifiably determine the optimal combination of 11 CAMs for a given MetaCAM experiment.","meta":{"url":"http://arxiv.org/abs/2307.16863v1"},"cats":{"new-dataset":0.2836665122,"dev-research":0.1953405609,"prompt-eng":0.4209737224,"data-quality":0.132588137,"ml-security":0.0574127337}}
{"text":"A new method denoted Cumulative Residual Effect (CRE) is proposed to summarize large-scale ensemble-based experiments.","meta":{"url":"http://arxiv.org/abs/2307.16863v1"},"cats":{"new-dataset":0.077884697,"dev-research":0.253840666,"prompt-eng":0.411346081,"data-quality":0.2206604298,"ml-security":0.0952274432}}
{"text":"We also present adaptive thresholding and demonstrate how it can be applied to individual CAMs to improve their performance, measured using pixel perturbation method Remove and Debias (ROAD).","meta":{"url":"http://arxiv.org/abs/2307.16863v1"},"cats":{"new-dataset":0.0873253806,"dev-research":0.2039501823,"prompt-eng":0.4101380548,"data-quality":0.2576431834,"ml-security":0.1009799954}}
{"text":"Lastly, we show that MetaCAM outperforms existing CAMs and refines the most salient regions of images used for model predictions.","meta":{"url":"http://arxiv.org/abs/2307.16863v1"},"cats":{"new-dataset":0.4080985297,"dev-research":0.2585479492,"prompt-eng":0.3878702224,"data-quality":0.1486121293,"ml-security":0.1018267658}}
{"text":"In a specific example, MetaCAM improved ROAD performance to 0.393 compared to 11 individual CAMs with ranges from -0.101-0.172, demonstrating the importance of combining CAMs through an ensembling method and adaptive thresholding.","meta":{"url":"http://arxiv.org/abs/2307.16863v1"},"cats":{"new-dataset":0.1638783886,"dev-research":0.2527860384,"prompt-eng":0.4116842711,"data-quality":0.181212051,"ml-security":0.0762581994}}
{"text":"Indicators of Compromise (IOCs), such as IP addresses, file hashes, and domain names associated with known malware or attacks, are cornerstones of cybersecurity, serving to identify malicious activity on a network.","meta":{"url":"http://arxiv.org/abs/2307.16852v1"},"cats":{"new-dataset":0.0753877743,"dev-research":0.3149270505,"prompt-eng":0.4101817492,"data-quality":0.2012184865,"ml-security":0.4847819085}}
{"text":"In this work, we leverage real data to compare different parameterizations of IOC aging models.","meta":{"url":"http://arxiv.org/abs/2307.16852v1"},"cats":{"new-dataset":0.0896823281,"dev-research":0.2326701971,"prompt-eng":0.4170534741,"data-quality":0.1413690236,"ml-security":0.133892034}}
{"text":"Our dataset comprises traffic at a real environment for more than 1 year.","meta":{"url":"http://arxiv.org/abs/2307.16852v1"},"cats":{"new-dataset":0.7490802887,"dev-research":0.2365363994,"prompt-eng":0.2790944424,"data-quality":0.1216614034,"ml-security":0.167371467}}
{"text":"Among our trace-driven findings, we determine thresholds for the ratio between miss over monitoring costs such that the system benefits from storing IOCs for a finite time-to-live (TTL) before eviction.","meta":{"url":"http://arxiv.org/abs/2307.16852v1"},"cats":{"new-dataset":0.0943050005,"dev-research":0.3305093144,"prompt-eng":0.4686216301,"data-quality":0.1968883819,"ml-security":0.2123502678}}
{"text":"To the best of our knowledge, this is the first real world evaluation of thresholds related to IOC aging, paving the way towards realistic IOC decaying models.","meta":{"url":"http://arxiv.org/abs/2307.16852v1"},"cats":{"new-dataset":0.1340961605,"dev-research":0.1797166126,"prompt-eng":0.4357547391,"data-quality":0.1972741543,"ml-security":0.1268234189}}
{"text":"The trustworthiness of machine learning has emerged as a critical topic in the field, encompassing various applications and research areas such as robustness, security, interpretability, and fairness.","meta":{"url":"http://arxiv.org/abs/2307.16851v1"},"cats":{"new-dataset":0.0327217147,"dev-research":0.2430537759,"prompt-eng":0.3868505151,"data-quality":0.4360368345,"ml-security":0.7260663874}}
{"text":"The last decade saw the development of numerous methods addressing these challenges.","meta":{"url":"http://arxiv.org/abs/2307.16851v1"},"cats":{"new-dataset":0.0232559161,"dev-research":0.3367622147,"prompt-eng":0.3993880108,"data-quality":0.1286291303,"ml-security":0.0784916576}}
{"text":"In this survey, we systematically review these advancements from a data-centric perspective, highlighting the shortcomings of traditional empirical risk minimization (ERM) training in handling challenges posed by the data.   ","meta":{"url":"http://arxiv.org/abs/2307.16851v1"},"cats":{"new-dataset":0.1158507439,"dev-research":0.2643178777,"prompt-eng":0.394852396,"data-quality":0.3767839169,"ml-security":0.3992812262}}
{"text":"Interestingly, we observe a convergence of these methods, despite being developed independently across trustworthy machine learning subfields.","meta":{"url":"http://arxiv.org/abs/2307.16851v1"},"cats":{"new-dataset":0.1492619345,"dev-research":0.1767321493,"prompt-eng":0.3439626624,"data-quality":0.3176611306,"ml-security":0.2624977199}}
{"text":"Pearl's hierarchy of causality offers a unifying framework for these techniques.","meta":{"url":"http://arxiv.org/abs/2307.16851v1"},"cats":{"new-dataset":0.0485035504,"dev-research":0.2849393046,"prompt-eng":0.4213139533,"data-quality":0.1494242908,"ml-security":0.1012518075}}
{"text":"Accordingly, this survey presents the background of trustworthy machine learning development using a unified set of concepts, connects this language to Pearl's causal hierarchy, and finally discusses methods explicitly inspired by causality literature.","meta":{"url":"http://arxiv.org/abs/2307.16851v1"},"cats":{"new-dataset":0.1278331879,"dev-research":0.3353008192,"prompt-eng":0.4044409847,"data-quality":0.3134116371,"ml-security":0.4193216685}}
{"text":"We provide a unified language with mathematical vocabulary to link these methods across robustness, adversarial robustness, interpretability, and fairness, fostering a more cohesive understanding of the field.   ","meta":{"url":"http://arxiv.org/abs/2307.16851v1"},"cats":{"new-dataset":0.2417791466,"dev-research":0.2627642632,"prompt-eng":0.3403294456,"data-quality":0.3217235931,"ml-security":0.4181273276}}
{"text":"Further, we explore the trustworthiness of large pretrained models.","meta":{"url":"http://arxiv.org/abs/2307.16851v1"},"cats":{"new-dataset":0.1049065816,"dev-research":0.2635074976,"prompt-eng":0.4427662963,"data-quality":0.2340021724,"ml-security":0.3504222389}}
{"text":"After summarizing dominant techniques like fine-tuning, parameter-efficient fine-tuning, prompting, and reinforcement learning with human feedback, we draw connections between them and the standard ERM.","meta":{"url":"http://arxiv.org/abs/2307.16851v1"},"cats":{"new-dataset":0.0692121847,"dev-research":0.3002181937,"prompt-eng":0.5417387122,"data-quality":0.2249894406,"ml-security":0.1314607142}}
{"text":"This connection allows us to build upon the principled understanding of trustworthy methods, extending it to these new techniques in large pretrained models, paving the way for future methods.","meta":{"url":"http://arxiv.org/abs/2307.16851v1"},"cats":{"new-dataset":0.0576925942,"dev-research":0.3001926223,"prompt-eng":0.4245045046,"data-quality":0.2502559533,"ml-security":0.2685204638}}
{"text":"Existing methods under this perspective are also reviewed.   ","meta":{"url":"http://arxiv.org/abs/2307.16851v1"},"cats":{"new-dataset":0.0451802137,"dev-research":0.2224776904,"prompt-eng":0.4085730963,"data-quality":0.1724455908,"ml-security":0.052710015}}
{"text":"Lastly, we offer a brief summary of the applications of these methods and discuss potential future aspects related to our survey.","meta":{"url":"http://arxiv.org/abs/2307.16851v1"},"cats":{"new-dataset":0.0953606228,"dev-research":0.1575596141,"prompt-eng":0.4425844273,"data-quality":0.1173513142,"ml-security":0.0479815414}}
{"text":"For more information, please visit http://trustai.one.","meta":{"url":"http://arxiv.org/abs/2307.16851v1"},"cats":{"new-dataset":0.215134802,"dev-research":0.1971702413,"prompt-eng":0.3827999405,"data-quality":0.1436186675,"ml-security":0.0777187504}}
{"text":"As people's daily life becomes increasingly inseparable from various mobile electronic devices, relevant service application platforms and network operators can collect numerous individual information easily.","meta":{"url":"http://arxiv.org/abs/2307.16849v1"},"cats":{"new-dataset":0.0914034687,"dev-research":0.2750876664,"prompt-eng":0.4061652367,"data-quality":0.1278804861,"ml-security":0.1291931774}}
{"text":"When releasing these data for scientific research or commercial purposes, users' privacy will be in danger, especially in the publication of spatiotemporal trajectory datasets.","meta":{"url":"http://arxiv.org/abs/2307.16849v1"},"cats":{"new-dataset":0.5613600985,"dev-research":0.1962040978,"prompt-eng":0.3157473149,"data-quality":0.1487967514,"ml-security":0.541968734}}
{"text":"Therefore, to avoid the leakage of users' privacy, it is necessary to anonymize the data before they are released.","meta":{"url":"http://arxiv.org/abs/2307.16849v1"},"cats":{"new-dataset":0.0210402364,"dev-research":0.3292263347,"prompt-eng":0.3129429003,"data-quality":0.1719103804,"ml-security":0.566652689}}
{"text":"However, more than simply removing the unique identifiers of individuals is needed to protect the trajectory privacy, because some attackers may infer the identity of users by the connection with other databases.","meta":{"url":"http://arxiv.org/abs/2307.16849v1"},"cats":{"new-dataset":0.011077543,"dev-research":0.2457584036,"prompt-eng":0.377303581,"data-quality":0.1749736033,"ml-security":0.5162631408}}
{"text":"Much work has been devoted to merging multiple trajectories to avoid re-identification, but these solutions always require sacrificing data quality to achieve the anonymity requirement.","meta":{"url":"http://arxiv.org/abs/2307.16849v1"},"cats":{"new-dataset":0.2076595599,"dev-research":0.1892593802,"prompt-eng":0.3549866031,"data-quality":0.2291912279,"ml-security":0.2046176144}}
{"text":"In order to provide sufficient privacy protection for users' trajectory datasets, this paper develops a study on trajectory privacy against re-identification attacks, proposing a trajectory K-anonymity model based on Point Density and Partition (KPDP).","meta":{"url":"http://arxiv.org/abs/2307.16849v1"},"cats":{"new-dataset":0.1488388541,"dev-research":0.1955217817,"prompt-eng":0.3232688656,"data-quality":0.1737032664,"ml-security":0.6747840254}}
{"text":"Our approach improves the existing trajectory generalization anonymization techniques regarding trajectory set partition preprocessing and trajectory clustering algorithms.","meta":{"url":"http://arxiv.org/abs/2307.16849v1"},"cats":{"new-dataset":0.26185556,"dev-research":0.1892833786,"prompt-eng":0.3290095095,"data-quality":0.1702274587,"ml-security":0.3178315396}}
{"text":"It successfully resists re-identification attacks and reduces the data utility loss of the k-anonymized dataset.","meta":{"url":"http://arxiv.org/abs/2307.16849v1"},"cats":{"new-dataset":0.0982465859,"dev-research":0.2239222746,"prompt-eng":0.3268976095,"data-quality":0.258109091,"ml-security":0.5746429446}}
{"text":"A series of experiments on a real-world dataset show that the proposed model has significant advantages in terms of higher data utility and shorter algorithm execution time than other existing techniques.","meta":{"url":"http://arxiv.org/abs/2307.16849v1"},"cats":{"new-dataset":0.2822237524,"dev-research":0.2442455908,"prompt-eng":0.4053973382,"data-quality":0.1439894717,"ml-security":0.0874566851}}
{"text":"Ultra-wideband (UWB) time difference of arrival(TDOA)-based localization has emerged as a low-cost and scalable indoor positioning solution.","meta":{"url":"http://arxiv.org/abs/2307.16848v1"},"cats":{"new-dataset":0.0396321743,"dev-research":0.2701994874,"prompt-eng":0.3723340142,"data-quality":0.1083458858,"ml-security":0.0585988469}}
{"text":"However, in cluttered environments, the performance of UWB TDOA-based localization deteriorates due to the biased and non-Gaussian noise distributions induced by obstacles.","meta":{"url":"http://arxiv.org/abs/2307.16848v1"},"cats":{"new-dataset":0.0600823831,"dev-research":0.2631270181,"prompt-eng":0.4176422627,"data-quality":0.1620139844,"ml-security":0.0926163608}}
{"text":"In this work, we present a bi-level optimization-based joint localization and noise model learning algorithm to address this problem.","meta":{"url":"http://arxiv.org/abs/2307.16848v1"},"cats":{"new-dataset":0.232521806,"dev-research":0.1998498993,"prompt-eng":0.3930227406,"data-quality":0.2867545809,"ml-security":0.068203463}}
{"text":"In particular, we use a Gaussian mixture model (GMM) to approximate the measurement noise distribution.","meta":{"url":"http://arxiv.org/abs/2307.16848v1"},"cats":{"new-dataset":0.0995055249,"dev-research":0.1993845091,"prompt-eng":0.4161365717,"data-quality":0.2724856208,"ml-security":0.0789513827}}
{"text":"We explicitly incorporate the estimated state's uncertainty into the GMM noise model learning, referred to as uncertainty-aware GMM, to improve both noise modeling and localization performance.","meta":{"url":"http://arxiv.org/abs/2307.16848v1"},"cats":{"new-dataset":0.1598297064,"dev-research":0.1978596608,"prompt-eng":0.4043760602,"data-quality":0.3561728811,"ml-security":0.112324422}}
{"text":"We first evaluate the GMM noise model learning and localization performance in numerous simulation scenarios.","meta":{"url":"http://arxiv.org/abs/2307.16848v1"},"cats":{"new-dataset":0.1070893766,"dev-research":0.1922215731,"prompt-eng":0.4088593493,"data-quality":0.3224612185,"ml-security":0.1122358622}}
{"text":"We then demonstrate the effectiveness of our algorithm in extensive real-world experiments using two different cluttered environments.","meta":{"url":"http://arxiv.org/abs/2307.16848v1"},"cats":{"new-dataset":0.2638373388,"dev-research":0.2194484809,"prompt-eng":0.4333891931,"data-quality":0.1858267909,"ml-security":0.0842507965}}
{"text":"We show that our algorithm provides accurate position estimates with low-cost UWB sensors, no prior knowledge about the obstacles in the space, and a significant amount of UWB radios occluded.","meta":{"url":"http://arxiv.org/abs/2307.16848v1"},"cats":{"new-dataset":0.312609108,"dev-research":0.1965010045,"prompt-eng":0.4177354832,"data-quality":0.1139059856,"ml-security":0.0669642538}}
{"text":"Limited availability of labeled data for machine learning on biomedical time-series hampers progress in the field.","meta":{"url":"http://arxiv.org/abs/2307.16847v1"},"cats":{"new-dataset":0.1977850535,"dev-research":0.1539853648,"prompt-eng":0.3615766509,"data-quality":0.2520497126,"ml-security":0.1371311873}}
{"text":"Self-supervised learning (SSL) is a promising approach to learning data representations without labels.","meta":{"url":"http://arxiv.org/abs/2307.16847v1"},"cats":{"new-dataset":0.086401795,"dev-research":0.2353783109,"prompt-eng":0.395613275,"data-quality":0.3080468467,"ml-security":0.2135433254}}
{"text":"However, current SSL methods require expensive computations for negative pairs and are designed for single modalities, limiting their versatility.","meta":{"url":"http://arxiv.org/abs/2307.16847v1"},"cats":{"new-dataset":0.0210738452,"dev-research":0.2317823215,"prompt-eng":0.3526036487,"data-quality":0.1301283002,"ml-security":0.1667218372}}
{"text":"To overcome these limitations, we introduce CroSSL (Cross-modal SSL).","meta":{"url":"http://arxiv.org/abs/2307.16847v1"},"cats":{"new-dataset":0.0800731591,"dev-research":0.2337355923,"prompt-eng":0.41630306,"data-quality":0.1337872398,"ml-security":0.1604562654}}
{"text":"CroSSL introduces two novel concepts: masking intermediate embeddings from modality-specific encoders and aggregating them into a global embedding using a cross-modal aggregator.","meta":{"url":"http://arxiv.org/abs/2307.16847v1"},"cats":{"new-dataset":0.1750741083,"dev-research":0.2203066286,"prompt-eng":0.3431283838,"data-quality":0.1824110486,"ml-security":0.1141559134}}
{"text":"This enables the handling of missing modalities and end-to-end learning of cross-modal patterns without prior data preprocessing or time-consuming negative-pair sampling.","meta":{"url":"http://arxiv.org/abs/2307.16847v1"},"cats":{"new-dataset":0.1408659987,"dev-research":0.2325812497,"prompt-eng":0.3759773515,"data-quality":0.2662662733,"ml-security":0.1002277891}}
{"text":"We evaluate CroSSL on various multimodal time-series benchmarks, including both medical-grade and consumer biosignals.","meta":{"url":"http://arxiv.org/abs/2307.16847v1"},"cats":{"new-dataset":0.2268639126,"dev-research":0.1940618431,"prompt-eng":0.38702126,"data-quality":0.0959983573,"ml-security":0.0469450397}}
{"text":"Our results demonstrate superior performance compared to previous SSL techniques and supervised benchmarks with minimal labeled data.","meta":{"url":"http://arxiv.org/abs/2307.16847v1"},"cats":{"new-dataset":0.1529972618,"dev-research":0.2148197636,"prompt-eng":0.4011973553,"data-quality":0.2964755224,"ml-security":0.179086598}}
{"text":"We additionally analyze the impact of different masking ratios and strategies and assess the robustness of the learned representations to missing modalities.","meta":{"url":"http://arxiv.org/abs/2307.16847v1"},"cats":{"new-dataset":0.0526276628,"dev-research":0.2373438717,"prompt-eng":0.3977790343,"data-quality":0.3827335779,"ml-security":0.251245975}}
{"text":"Overall, our work achieves state-of-the-art performance while highlighting the benefits of masking latent embeddings for cross-modal learning in temporal health data.","meta":{"url":"http://arxiv.org/abs/2307.16847v1"},"cats":{"new-dataset":0.2605105962,"dev-research":0.1998395242,"prompt-eng":0.354784728,"data-quality":0.1595839906,"ml-security":0.1279837536}}
{"text":"Current approaches to identifying driving heterogeneity face challenges in capturing the diversity of driving characteristics and understanding the fundamental patterns from a driving behaviour mechanism standpoint.","meta":{"url":"http://arxiv.org/abs/2307.16843v1"},"cats":{"new-dataset":0.0301561633,"dev-research":0.3340751477,"prompt-eng":0.3826138689,"data-quality":0.1678928688,"ml-security":0.1986103613}}
{"text":"This study introduces a comprehensive framework for identifying driving heterogeneity from an Action-chain perspective.","meta":{"url":"http://arxiv.org/abs/2307.16843v1"},"cats":{"new-dataset":0.0227025289,"dev-research":0.2908999096,"prompt-eng":0.3483290845,"data-quality":0.121314606,"ml-security":0.1307818471}}
{"text":"First, a rule-based segmentation technique that considers the physical meanings of driving behaviour is proposed.","meta":{"url":"http://arxiv.org/abs/2307.16843v1"},"cats":{"new-dataset":0.0612614851,"dev-research":0.3001194777,"prompt-eng":0.4182999112,"data-quality":0.2232327124,"ml-security":0.094886239}}
{"text":"Next, an Action phase Library including descriptions of various driving behaviour patterns is created based on the segmentation findings.","meta":{"url":"http://arxiv.org/abs/2307.16843v1"},"cats":{"new-dataset":0.2963576207,"dev-research":0.2720209218,"prompt-eng":0.4291179597,"data-quality":0.1576810646,"ml-security":0.0912362864}}
{"text":"The Action-chain concept is then introduced by implementing Action phase transition probability, followed by a method for evaluating driving heterogeneity.","meta":{"url":"http://arxiv.org/abs/2307.16843v1"},"cats":{"new-dataset":0.0274560792,"dev-research":0.2109323863,"prompt-eng":0.4212318054,"data-quality":0.0743172803,"ml-security":0.0591543544}}
{"text":"Employing real-world datasets for evaluation, our approach effectively identifies driving heterogeneity for both individual drivers and traffic flow while providing clear interpretations.","meta":{"url":"http://arxiv.org/abs/2307.16843v1"},"cats":{"new-dataset":0.1999325271,"dev-research":0.2809786509,"prompt-eng":0.3140181991,"data-quality":0.1769783141,"ml-security":0.1544501254}}
{"text":"These insights can aid the development of accurate driving behaviour theory and traffic flow models, ultimately benefiting traffic performance, and potentially leading to aspects such as improved road capacity and safety.","meta":{"url":"http://arxiv.org/abs/2307.16843v1"},"cats":{"new-dataset":0.0407912275,"dev-research":0.2827468663,"prompt-eng":0.3212276105,"data-quality":0.0952626406,"ml-security":0.1782917031}}
{"text":"We study Linear Temporal Logic Modulo Theories over Finite Traces (LTLfMT), a recently introduced extension of LTL over finite traces (LTLf) where propositions are replaced by first-order formulas and where first-order variables referring to different time points can be compared.","meta":{"url":"http://arxiv.org/abs/2307.16840v1"},"cats":{"new-dataset":0.1112077656,"dev-research":0.2646362463,"prompt-eng":0.373709562,"data-quality":0.0651988969,"ml-security":0.0752095185}}
{"text":"In general, LTLfMT was shown to be semi-decidable for any decidable first-order theory (e.g., linear arithmetics), with a tableau-based semi-decision procedure.   ","meta":{"url":"http://arxiv.org/abs/2307.16840v1"},"cats":{"new-dataset":0.0470740727,"dev-research":0.1945210976,"prompt-eng":0.3813756085,"data-quality":0.0771420418,"ml-security":0.081821288}}
{"text":"In this paper we present a sound and complete pruning rule for the LTLfMT tableau.","meta":{"url":"http://arxiv.org/abs/2307.16840v1"},"cats":{"new-dataset":0.1620410689,"dev-research":0.1884066584,"prompt-eng":0.3981003793,"data-quality":0.1793811859,"ml-security":0.0579347457}}
{"text":"We show that for any LTLfMT formula that satisfies an abstract, semantic condition, that we call finite memory, the tableau augmented with the new rule is also guaranteed to terminate.","meta":{"url":"http://arxiv.org/abs/2307.16840v1"},"cats":{"new-dataset":0.089315174,"dev-research":0.21546346,"prompt-eng":0.3656254655,"data-quality":0.1544186424,"ml-security":0.109326748}}
{"text":"Last but not least, this technique allows us to establish novel decidability results for the satisfiability of several fragments of LTLfMT, as well as to give new decidability proofs for classes that are already known.","meta":{"url":"http://arxiv.org/abs/2307.16840v1"},"cats":{"new-dataset":0.0976449879,"dev-research":0.2328355676,"prompt-eng":0.3831306144,"data-quality":0.1847052335,"ml-security":0.1232816505}}
{"text":"Accuracy measures such as Recall, Precision, and Hit Rate have been a standard way of evaluating Recommendation Systems.","meta":{"url":"http://arxiv.org/abs/2307.16832v1"},"cats":{"new-dataset":0.0169538722,"dev-research":0.2868762561,"prompt-eng":0.4261031126,"data-quality":0.2667598212,"ml-security":0.0742735421}}
{"text":"The assumption is to use a fixed Top-N to represent them.","meta":{"url":"http://arxiv.org/abs/2307.16832v1"},"cats":{"new-dataset":0.0189262635,"dev-research":0.2134859235,"prompt-eng":0.3708721821,"data-quality":0.1957743462,"ml-security":0.1033658897}}
{"text":"We propose that median impressions viewed from historical sessions per diner be used as a personalized value for N.","meta":{"url":"http://arxiv.org/abs/2307.16832v1"},"cats":{"new-dataset":0.1013233333,"dev-research":0.2009278084,"prompt-eng":0.420403676,"data-quality":0.1692136733,"ml-security":0.0696076479}}
{"text":"We present preliminary exploratory results and list future steps to improve upon and evaluate the efficacy of these personalized metrics.","meta":{"url":"http://arxiv.org/abs/2307.16832v1"},"cats":{"new-dataset":0.1356393531,"dev-research":0.2753824706,"prompt-eng":0.464381268,"data-quality":0.2312223299,"ml-security":0.0873206644}}
{"text":"With sufficient paired training samples, the supervised deep learning methods have attracted much attention in image denoising because of their superior performance.","meta":{"url":"http://arxiv.org/abs/2307.16825v1"},"cats":{"new-dataset":0.1538988181,"dev-research":0.2722738422,"prompt-eng":0.3082487153,"data-quality":0.2685740453,"ml-security":0.1722599017}}
{"text":"However, it is still very challenging to widely utilize the supervised methods in real cases due to the lack of paired noisy-clean images.","meta":{"url":"http://arxiv.org/abs/2307.16825v1"},"cats":{"new-dataset":0.0854089384,"dev-research":0.1955885621,"prompt-eng":0.3497291003,"data-quality":0.3686845693,"ml-security":0.144574297}}
{"text":"Meanwhile, most self-supervised denoising methods are ineffective as well when applied to the real-world denoising tasks because of their strict assumptions in applications.","meta":{"url":"http://arxiv.org/abs/2307.16825v1"},"cats":{"new-dataset":0.0352017419,"dev-research":0.2066993185,"prompt-eng":0.3316030904,"data-quality":0.4449005349,"ml-security":0.2454532627}}
{"text":"For example, as a typical method for self-supervised denoising, the original blind spot network (BSN) assumes that the noise is pixel-wise independent, which is much different from the real cases.","meta":{"url":"http://arxiv.org/abs/2307.16825v1"},"cats":{"new-dataset":0.0253998539,"dev-research":0.277749729,"prompt-eng":0.2855011139,"data-quality":0.3264688798,"ml-security":0.238662128}}
{"text":"To solve this problem, we propose a novel self-supervised real image denoising framework named Sampling Difference As Perturbation (SDAP) based on Random Sub-samples Generation (RSG) with a cyclic sample difference loss.","meta":{"url":"http://arxiv.org/abs/2307.16825v1"},"cats":{"new-dataset":0.2287774836,"dev-research":0.2244558889,"prompt-eng":0.3230139557,"data-quality":0.3505392402,"ml-security":0.1470571614}}
{"text":"Specifically, we dig deeper into the properties of BSN to make it more suitable for real noise.","meta":{"url":"http://arxiv.org/abs/2307.16825v1"},"cats":{"new-dataset":0.0689647684,"dev-research":0.2458895445,"prompt-eng":0.3332756659,"data-quality":0.1951298073,"ml-security":0.180827971}}
{"text":"Surprisingly, we find that adding an appropriate perturbation to the training images can effectively improve the performance of BSN.","meta":{"url":"http://arxiv.org/abs/2307.16825v1"},"cats":{"new-dataset":0.0897324843,"dev-research":0.221959659,"prompt-eng":0.3471565076,"data-quality":0.2816285621,"ml-security":0.2250454552}}
{"text":"Further, we propose that the sampling difference can be considered as perturbation to achieve better results.","meta":{"url":"http://arxiv.org/abs/2307.16825v1"},"cats":{"new-dataset":0.0258132015,"dev-research":0.1620046495,"prompt-eng":0.370411493,"data-quality":0.2688049438,"ml-security":0.1215217256}}
{"text":"Finally we propose a new BSN framework in combination with our RSG strategy.","meta":{"url":"http://arxiv.org/abs/2307.16825v1"},"cats":{"new-dataset":0.1437898981,"dev-research":0.1937034695,"prompt-eng":0.4131606864,"data-quality":0.1039143613,"ml-security":0.08741001}}
{"text":"The results show that it significantly outperforms other state-of-the-art self-supervised denoising methods on real-world datasets.","meta":{"url":"http://arxiv.org/abs/2307.16825v1"},"cats":{"new-dataset":0.3125024606,"dev-research":0.222521492,"prompt-eng":0.3346288397,"data-quality":0.3897811602,"ml-security":0.1716527235}}
{"text":"The code is available at https://github.com/p1y2z3/SDAP.","meta":{"url":"http://arxiv.org/abs/2307.16825v1"},"cats":{"new-dataset":0.2898744861,"dev-research":0.1774442529,"prompt-eng":0.4448482586,"data-quality":0.0986986061,"ml-security":0.0302561689}}
{"text":"Cell-free massive multiple-input-multiple-output (CF-mMIMO) is a next-generation wireless access technology that offers superior coverage and spectral efficiency compared to conventional MIMO.","meta":{"url":"http://arxiv.org/abs/2307.16824v1"},"cats":{"new-dataset":0.0651694949,"dev-research":0.2228367352,"prompt-eng":0.3498686199,"data-quality":0.0693591933,"ml-security":0.0741944444}}
{"text":"With many future applications in unlicensed spectrum bands, networks will likely experience and may even be limited by out-of-system (OoS) interference.","meta":{"url":"http://arxiv.org/abs/2307.16824v1"},"cats":{"new-dataset":0.0174179981,"dev-research":0.1977594044,"prompt-eng":0.3159081566,"data-quality":0.1671741613,"ml-security":0.2401969701}}
{"text":"The OoS interference differs from the in-system interference from other serving users in that for OoS interference, the associated pilot signals are unknown or non-existent, which makes estimation of the OoS interferer channel difficult.   ","meta":{"url":"http://arxiv.org/abs/2307.16824v1"},"cats":{"new-dataset":0.0103437511,"dev-research":0.2800733082,"prompt-eng":0.3576710353,"data-quality":0.2240319704,"ml-security":0.1712001877}}
{"text":"In this paper, we propose a novel sequential algorithm for the suppression of OoS interference for uplink CF-mMIMO with a stripe (daisy-chain) topology.","meta":{"url":"http://arxiv.org/abs/2307.16824v1"},"cats":{"new-dataset":0.0439925759,"dev-research":0.2123151775,"prompt-eng":0.3800940127,"data-quality":0.1349261116,"ml-security":0.0830179176}}
{"text":"The proposed method has comparable performance to that of a fully centralized interference rejection combining algorithm but has substantially less fronthaul load requirements.","meta":{"url":"http://arxiv.org/abs/2307.16824v1"},"cats":{"new-dataset":0.0207280089,"dev-research":0.2499714556,"prompt-eng":0.4196889252,"data-quality":0.2743880276,"ml-security":0.1234787954}}
{"text":"The Trusted Platform Module (TPM) is a cryptoprocessor designed to protect integrity and security of modern computers.","meta":{"url":"http://arxiv.org/abs/2307.16821v1"},"cats":{"new-dataset":0.1610137939,"dev-research":0.230106868,"prompt-eng":0.4215072667,"data-quality":0.0948229891,"ml-security":0.2526837869}}
{"text":"Communications with the TPM go through the TPM Software Stack (TSS), a popular implementation of which is the open-source library tpm2-tss.","meta":{"url":"http://arxiv.org/abs/2307.16821v1"},"cats":{"new-dataset":0.3411632056,"dev-research":0.2432265611,"prompt-eng":0.4523034105,"data-quality":0.088085717,"ml-security":0.0550146867}}
{"text":"Vulnerabilities in its code could allow attackers to recover sensitive information and take control of the system.","meta":{"url":"http://arxiv.org/abs/2307.16821v1"},"cats":{"new-dataset":0.0432409511,"dev-research":0.4154321529,"prompt-eng":0.3864851756,"data-quality":0.1622229212,"ml-security":0.6548709042}}
{"text":"This paper describes a case study on formal verification of tpm2-tss using the Frama-C verification platform.","meta":{"url":"http://arxiv.org/abs/2307.16821v1"},"cats":{"new-dataset":0.1155734062,"dev-research":0.2550769486,"prompt-eng":0.489398636,"data-quality":0.1936861507,"ml-security":0.0962216544}}
{"text":"Heavily based on linked lists and complex data structures, the library code appears to be highly challenging for the verification tool.","meta":{"url":"http://arxiv.org/abs/2307.16821v1"},"cats":{"new-dataset":0.2791119036,"dev-research":0.3462336881,"prompt-eng":0.4413541295,"data-quality":0.2579229618,"ml-security":0.0944893089}}
{"text":"We present several issues and limitations we faced, illustrate them with examples and present solutions that allowed us to verify functional properties and the absence of runtime errors for a representative subset of functions.","meta":{"url":"http://arxiv.org/abs/2307.16821v1"},"cats":{"new-dataset":0.0997882123,"dev-research":0.2231104913,"prompt-eng":0.3810098719,"data-quality":0.2245472878,"ml-security":0.1530247005}}
{"text":"We describe verification results and desired tool improvements necessary to achieve a full formal verification of the target code.","meta":{"url":"http://arxiv.org/abs/2307.16821v1"},"cats":{"new-dataset":0.139545222,"dev-research":0.3725563818,"prompt-eng":0.4953194335,"data-quality":0.3114795726,"ml-security":0.0999631843}}
{"text":"Neural ranking models (NRMs) have undergone significant development and have become integral components of information retrieval (IR) systems.","meta":{"url":"http://arxiv.org/abs/2307.16816v1"},"cats":{"new-dataset":0.0540255344,"dev-research":0.1507053587,"prompt-eng":0.4035660107,"data-quality":0.2130544498,"ml-security":0.0702432038}}
{"text":"Unfortunately, recent research has unveiled the vulnerability of NRMs to adversarial document manipulations, potentially exploited by malicious search engine optimization practitioners.","meta":{"url":"http://arxiv.org/abs/2307.16816v1"},"cats":{"new-dataset":0.0364212556,"dev-research":0.182989991,"prompt-eng":0.3838505891,"data-quality":0.3177530262,"ml-security":0.5593072309}}
{"text":"While progress in adversarial attack strategies aids in identifying the potential weaknesses of NRMs before their deployment, the defensive measures against such attacks, like the detection of adversarial documents, remain inadequately explored.","meta":{"url":"http://arxiv.org/abs/2307.16816v1"},"cats":{"new-dataset":0.0508365966,"dev-research":0.2409929848,"prompt-eng":0.3546953528,"data-quality":0.3642694909,"ml-security":0.828718292}}
{"text":"To mitigate this gap, this paper establishes a benchmark dataset to facilitate the investigation of adversarial ranking defense and introduces two types of detection tasks for adversarial documents.","meta":{"url":"http://arxiv.org/abs/2307.16816v1"},"cats":{"new-dataset":0.3299383554,"dev-research":0.2732655289,"prompt-eng":0.3415106632,"data-quality":0.374603717,"ml-security":0.7400356174}}
{"text":"A comprehensive investigation of the performance of several detection baselines is conducted, which involve examining the spamicity, perplexity, and linguistic acceptability, and utilizing supervised classifiers.","meta":{"url":"http://arxiv.org/abs/2307.16816v1"},"cats":{"new-dataset":0.0658188693,"dev-research":0.2886398103,"prompt-eng":0.4880568563,"data-quality":0.6107454694,"ml-security":0.1924008496}}
{"text":"Experimental results demonstrate that a supervised classifier can effectively mitigate known attacks, but it performs poorly against unseen attacks.","meta":{"url":"http://arxiv.org/abs/2307.16816v1"},"cats":{"new-dataset":0.0312126799,"dev-research":0.3418692358,"prompt-eng":0.4036214114,"data-quality":0.4718479755,"ml-security":0.9223052408}}
{"text":"Furthermore, such classifier should avoid using query text to prevent learning the classification on relevance, as it might lead to the inadvertent discarding of relevant documents.","meta":{"url":"http://arxiv.org/abs/2307.16816v1"},"cats":{"new-dataset":0.0217484002,"dev-research":0.2370099387,"prompt-eng":0.3854987973,"data-quality":0.3604476721,"ml-security":0.2759671345}}
{"text":"Video Quality Assessment (VQA), which aims to predict the perceptual quality of a video, has attracted raising attention with the rapid development of streaming media technology, such as Facebook, TikTok, Kwai, and so on.","meta":{"url":"http://arxiv.org/abs/2307.16813v1"},"cats":{"new-dataset":0.1036057871,"dev-research":0.2528585596,"prompt-eng":0.3188481688,"data-quality":0.226403536,"ml-security":0.0716391598}}
{"text":"Compared with other sequence-based visual tasks (\\textit{e.g.,} action recognition), VQA faces two under-estimated challenges unresolved in User Generated Content (UGC) videos.","meta":{"url":"http://arxiv.org/abs/2307.16813v1"},"cats":{"new-dataset":0.3177709209,"dev-research":0.2494632967,"prompt-eng":0.3775360974,"data-quality":0.2170446203,"ml-security":0.0886768427}}
{"text":"\\textit{First}, it is not rare that several frames containing serious distortions (\\textit{e.g.,}blocking, blurriness), can determine the perceptual quality of the whole video, while other sequence-based tasks require more frames of equal importance for representations.","meta":{"url":"http://arxiv.org/abs/2307.16813v1"},"cats":{"new-dataset":0.0332345163,"dev-research":0.3244906553,"prompt-eng":0.3381251857,"data-quality":0.3329432406,"ml-security":0.0598078608}}
{"text":"\\textit{Second}, the perceptual quality of a video exhibits a multi-distortion distribution, due to the differences in the duration and probability of occurrence for various distortions.","meta":{"url":"http://arxiv.org/abs/2307.16813v1"},"cats":{"new-dataset":0.0758500779,"dev-research":0.2353425092,"prompt-eng":0.3525299327,"data-quality":0.3758428362,"ml-security":0.0554410807}}
{"text":"In order to solve the above challenges, we propose \\textit{Visual Quality Transformer (VQT)} to extract quality-related sparse features more efficiently.","meta":{"url":"http://arxiv.org/abs/2307.16813v1"},"cats":{"new-dataset":0.1774415992,"dev-research":0.2878722381,"prompt-eng":0.3550297912,"data-quality":0.4065386814,"ml-security":0.0869992574}}
{"text":"Methodologically, a Sparse Temporal Attention (STA) is proposed to sample keyframes by analyzing the temporal correlation between frames, which reduces the computational complexity from $O(T^2)$ to $O(T \\log T)$. Structurally, a Multi-Pathway Temporal Network (MPTN) utilizes multiple STA modules with different degrees of sparsity in parallel, capturing co-existing distortions in a video.","meta":{"url":"http://arxiv.org/abs/2307.16813v1"},"cats":{"new-dataset":0.2743128226,"dev-research":0.1984112527,"prompt-eng":0.3365585064,"data-quality":0.1730384823,"ml-security":0.0655536968}}
{"text":"Experimentally, VQT demonstrates superior performance than many \\textit{state-of-the-art} methods in three public no-reference VQA datasets.","meta":{"url":"http://arxiv.org/abs/2307.16813v1"},"cats":{"new-dataset":0.2778024805,"dev-research":0.2365648073,"prompt-eng":0.3878089065,"data-quality":0.200637835,"ml-security":0.0537112047}}
{"text":"Furthermore, VQT shows better performance in four full-reference VQA datasets against widely-adopted industrial algorithms (\\textit{i.e.,} VMAF and AVQT).","meta":{"url":"http://arxiv.org/abs/2307.16813v1"},"cats":{"new-dataset":0.2027586983,"dev-research":0.2610371731,"prompt-eng":0.3411624069,"data-quality":0.1739329196,"ml-security":0.0644727522}}
{"text":"Public figures receive a disproportionate amount of abuse on social media, impacting their active participation in public life.","meta":{"url":"http://arxiv.org/abs/2307.16811v1"},"cats":{"new-dataset":0.0776616466,"dev-research":0.2203710718,"prompt-eng":0.2970813863,"data-quality":0.2245232586,"ml-security":0.2754750676}}
{"text":"Automated systems can identify abuse at scale but labelling training data is expensive, complex and potentially harmful.","meta":{"url":"http://arxiv.org/abs/2307.16811v1"},"cats":{"new-dataset":0.0593578912,"dev-research":0.3317506893,"prompt-eng":0.3994355467,"data-quality":0.5194571116,"ml-security":0.5975192747}}
{"text":"So, it is desirable that systems are efficient and generalisable, handling both shared and specific aspects of online abuse.","meta":{"url":"http://arxiv.org/abs/2307.16811v1"},"cats":{"new-dataset":0.0097937704,"dev-research":0.3278132014,"prompt-eng":0.3773343229,"data-quality":0.1883024691,"ml-security":0.4106779974}}
{"text":"We explore the dynamics of cross-group text classification in order to understand how well classifiers trained on one domain or demographic can transfer to others, with a view to building more generalisable abuse classifiers.","meta":{"url":"http://arxiv.org/abs/2307.16811v1"},"cats":{"new-dataset":0.0968061396,"dev-research":0.2311121999,"prompt-eng":0.3611516288,"data-quality":0.3741907273,"ml-security":0.6184722334}}
{"text":"We fine-tune language models to classify tweets targeted at public figures across DOmains (sport and politics) and DemOgraphics (women and men) using our novel DODO dataset, containing 28,000 labelled entries, split equally across four domain-demographic pairs.","meta":{"url":"http://arxiv.org/abs/2307.16811v1"},"cats":{"new-dataset":0.4621080153,"dev-research":0.1799825522,"prompt-eng":0.3430394264,"data-quality":0.3120668756,"ml-security":0.2276110743}}
{"text":"We find that (i) small amounts of diverse data are hugely beneficial to generalisation and model adaptation; (ii) models transfer more easily across demographics but models trained on cross-domain data are more generalisable; (iii) some groups contribute more to generalisability than others; and (iv) dataset similarity is a signal of transferability.","meta":{"url":"http://arxiv.org/abs/2307.16811v1"},"cats":{"new-dataset":0.0791567309,"dev-research":0.2163267862,"prompt-eng":0.3342611952,"data-quality":0.207139871,"ml-security":0.1952673596}}
{"text":"In this technical report, we present our findings from the research conducted on the Human-Object Interaction 4D (HOI4D) dataset for egocentric action segmentation task.","meta":{"url":"http://arxiv.org/abs/2307.16803v1"},"cats":{"new-dataset":0.5157312179,"dev-research":0.221380993,"prompt-eng":0.4048704681,"data-quality":0.1370787229,"ml-security":0.0560476723}}
{"text":"As a relatively novel research area, point cloud video methods might not be good at temporal modeling, especially for long point cloud videos (\\eg, 150 frames).","meta":{"url":"http://arxiv.org/abs/2307.16803v1"},"cats":{"new-dataset":0.1547067253,"dev-research":0.1761759407,"prompt-eng":0.3054664139,"data-quality":0.0877995442,"ml-security":0.0472687795}}
{"text":"In contrast, traditional video understanding methods have been well developed.","meta":{"url":"http://arxiv.org/abs/2307.16803v1"},"cats":{"new-dataset":0.1011380489,"dev-research":0.3481390461,"prompt-eng":0.3258788865,"data-quality":0.1728028191,"ml-security":0.0377011618}}
{"text":"Their effectiveness on temporal modeling has been widely verified on many large scale video datasets.","meta":{"url":"http://arxiv.org/abs/2307.16803v1"},"cats":{"new-dataset":0.3189584445,"dev-research":0.2011090367,"prompt-eng":0.3389283515,"data-quality":0.1805378335,"ml-security":0.0698642669}}
{"text":"Therefore, we convert point cloud videos into depth videos and employ traditional video modeling methods to improve 4D action segmentation.","meta":{"url":"http://arxiv.org/abs/2307.16803v1"},"cats":{"new-dataset":0.1922632069,"dev-research":0.204637114,"prompt-eng":0.3275895856,"data-quality":0.1054275094,"ml-security":0.0661898018}}
{"text":"By ensembling depth and point cloud video methods, the accuracy is significantly improved.","meta":{"url":"http://arxiv.org/abs/2307.16803v1"},"cats":{"new-dataset":0.1347148055,"dev-research":0.2158950544,"prompt-eng":0.3229239695,"data-quality":0.217270363,"ml-security":0.0697812105}}
{"text":"The proposed method, named Mixture of Depth and Point cloud video experts (DPMix), achieved the first place in the 4D Action Segmentation Track of the HOI4D Challenge 2023.","meta":{"url":"http://arxiv.org/abs/2307.16803v1"},"cats":{"new-dataset":0.3357550379,"dev-research":0.1773759999,"prompt-eng":0.3653457983,"data-quality":0.1296526833,"ml-security":0.0508166575}}
{"text":"Large-scale pre-training has made progress in many fields of natural language processing, though little is understood about the design of pre-training datasets.","meta":{"url":"http://arxiv.org/abs/2307.16795v1"},"cats":{"new-dataset":0.4249756117,"dev-research":0.2293424069,"prompt-eng":0.3744819307,"data-quality":0.2514683375,"ml-security":0.1283393067}}
{"text":"We propose a methodology for obtaining a quantitative understanding of structural overlap between machine translation tasks.","meta":{"url":"http://arxiv.org/abs/2307.16795v1"},"cats":{"new-dataset":0.1106761694,"dev-research":0.2789110027,"prompt-eng":0.434697624,"data-quality":0.2265848355,"ml-security":0.0502257336}}
{"text":"We apply our methodology to the natural language to Bash semantic parsing task (NLBash) and show that it is largely reducible to lexical alignment.","meta":{"url":"http://arxiv.org/abs/2307.16795v1"},"cats":{"new-dataset":0.3969813293,"dev-research":0.2920911073,"prompt-eng":0.4685274055,"data-quality":0.2503782693,"ml-security":0.0768973526}}
{"text":"We also find that there is strong structural overlap between NLBash and natural language to SQL.","meta":{"url":"http://arxiv.org/abs/2307.16795v1"},"cats":{"new-dataset":0.1705680541,"dev-research":0.2938987657,"prompt-eng":0.3968820289,"data-quality":0.1900121583,"ml-security":0.0986164037}}
{"text":"Additionally, we perform a study varying compute expended during pre-training on the English to German machine translation task and find that more compute expended during pre-training does not always correspond semantic representations with stronger transfer to NLBash.","meta":{"url":"http://arxiv.org/abs/2307.16795v1"},"cats":{"new-dataset":0.1565513792,"dev-research":0.2541299382,"prompt-eng":0.40706583,"data-quality":0.2353310698,"ml-security":0.1177908463}}
{"text":"Despite the advancements of open-source large language models (LLMs) and their variants, e.g., LLaMA and Vicuna, they remain significantly limited in performing higher-level tasks, such as following human instructions to use external tools (APIs).","meta":{"url":"http://arxiv.org/abs/2307.16789v1"},"cats":{"new-dataset":0.1954538331,"dev-research":0.2157127149,"prompt-eng":0.4085351838,"data-quality":0.1071353815,"ml-security":0.0749474821}}
{"text":"This is because current instruction tuning largely focuses on basic language tasks instead of the tool-use domain.","meta":{"url":"http://arxiv.org/abs/2307.16789v1"},"cats":{"new-dataset":0.007652395,"dev-research":0.4767486428,"prompt-eng":0.3930982272,"data-quality":0.1798012423,"ml-security":0.0709623609}}
{"text":"This is in contrast to state-of-the-art (SOTA) LLMs, e.g., ChatGPT, which have demonstrated excellent tool-use capabilities but are unfortunately closed source.","meta":{"url":"http://arxiv.org/abs/2307.16789v1"},"cats":{"new-dataset":0.3521280464,"dev-research":0.222441839,"prompt-eng":0.4836217833,"data-quality":0.1349416747,"ml-security":0.0370612535}}
{"text":"To facilitate tool-use capabilities within open-source LLMs, we introduce ToolLLM, a general tool-use framework of data construction, model training and evaluation.","meta":{"url":"http://arxiv.org/abs/2307.16789v1"},"cats":{"new-dataset":0.3109607647,"dev-research":0.3324306883,"prompt-eng":0.4468062639,"data-quality":0.1511018275,"ml-security":0.0630328788}}
{"text":"We first present ToolBench, an instruction-tuning dataset for tool use, which is created automatically using ChatGPT.","meta":{"url":"http://arxiv.org/abs/2307.16789v1"},"cats":{"new-dataset":0.7631991834,"dev-research":0.4227846683,"prompt-eng":0.4605952016,"data-quality":0.1508550529,"ml-security":0.0428949541}}
{"text":"Specifically, we collect 16,464 real-world RESTful APIs spanning 49 categories from RapidAPI Hub, then prompt ChatGPT to generate diverse human instructions involving these APIs, covering both single-tool and multi-tool scenarios.","meta":{"url":"http://arxiv.org/abs/2307.16789v1"},"cats":{"new-dataset":0.5411538731,"dev-research":0.3247797246,"prompt-eng":0.3971849767,"data-quality":0.0932544621,"ml-security":0.0608008023}}
{"text":"Finally, we use ChatGPT to search for a valid solution path (chain of API calls) for each instruction.","meta":{"url":"http://arxiv.org/abs/2307.16789v1"},"cats":{"new-dataset":0.2365273757,"dev-research":0.394317194,"prompt-eng":0.4551556655,"data-quality":0.1382628469,"ml-security":0.0750786746}}
{"text":"To make the searching process more efficient, we develop a novel depth-first search-based decision tree (DFSDT), enabling LLMs to evaluate multiple reasoning traces and expand the search space.","meta":{"url":"http://arxiv.org/abs/2307.16789v1"},"cats":{"new-dataset":0.1736624417,"dev-research":0.3203273548,"prompt-eng":0.4615733327,"data-quality":0.1878687206,"ml-security":0.0908946963}}
{"text":"We show that DFSDT significantly enhances the planning and reasoning capabilities of LLMs.","meta":{"url":"http://arxiv.org/abs/2307.16789v1"},"cats":{"new-dataset":0.202454988,"dev-research":0.3227932746,"prompt-eng":0.4705951214,"data-quality":0.0939355519,"ml-security":0.0690049219}}
{"text":"For efficient tool-use assessment, we develop an automatic evaluator: ToolEval.","meta":{"url":"http://arxiv.org/abs/2307.16789v1"},"cats":{"new-dataset":0.0974630628,"dev-research":0.4806367553,"prompt-eng":0.5253993947,"data-quality":0.2793243509,"ml-security":0.0908028984}}
{"text":"We fine-tune LLaMA on ToolBench and obtain ToolLLaMA.","meta":{"url":"http://arxiv.org/abs/2307.16789v1"},"cats":{"new-dataset":0.4446359681,"dev-research":0.21396608,"prompt-eng":0.3925771627,"data-quality":0.1358921207,"ml-security":0.0515689749}}
{"text":"Our ToolEval reveals that ToolLLaMA demonstrates a remarkable ability to execute complex instructions and generalize to unseen APIs, and exhibits comparable performance to ChatGPT.","meta":{"url":"http://arxiv.org/abs/2307.16789v1"},"cats":{"new-dataset":0.4943821508,"dev-research":0.3884810081,"prompt-eng":0.4159016336,"data-quality":0.1403788511,"ml-security":0.0747666953}}
{"text":"To make the pipeline more practical, we devise a neural API retriever to recommend appropriate APIs for each instruction, negating the need for manual API selection.","meta":{"url":"http://arxiv.org/abs/2307.16789v1"},"cats":{"new-dataset":0.0701583842,"dev-research":0.3208050096,"prompt-eng":0.4571693688,"data-quality":0.1527505686,"ml-security":0.1217628749}}
{"text":"The Defense Advanced Research Projects Agency (DARPA) OFFensive Swarm-Enabled Tactics program's goal of launching 250 unmanned aerial and ground vehicles from a limited sized launch zone was a daunting challenge.","meta":{"url":"http://arxiv.org/abs/2307.16788v1"},"cats":{"new-dataset":0.1897568716,"dev-research":0.2644844605,"prompt-eng":0.3921063761,"data-quality":0.082298797,"ml-security":0.1534602089}}
{"text":"The swarm's aerial vehicles were primarily multirotor platforms, which can efficiently be launched en masse.","meta":{"url":"http://arxiv.org/abs/2307.16788v1"},"cats":{"new-dataset":0.0448879153,"dev-research":0.2238247711,"prompt-eng":0.394396452,"data-quality":0.04535373,"ml-security":0.0805879462}}
{"text":"Each field exercise expected the deployment of an even larger swarm.","meta":{"url":"http://arxiv.org/abs/2307.16788v1"},"cats":{"new-dataset":0.1189807706,"dev-research":0.1841036038,"prompt-eng":0.4165068399,"data-quality":0.1601865969,"ml-security":0.0863777525}}
{"text":"While the launch zone's spatial area increased with each field exercise, the relative space for each vehicle was not necessarily increased, considering the increasing size of the swarm and the vehicles' associated GPS error; however, safe mission deployment and execution were expected.","meta":{"url":"http://arxiv.org/abs/2307.16788v1"},"cats":{"new-dataset":0.0727490311,"dev-research":0.3041383903,"prompt-eng":0.3575611751,"data-quality":0.1889009806,"ml-security":0.1302661928}}
{"text":"At the same time, achieving the mission goals required maximizing efficiency of the swarm's performance by reducing congestion that blocked vehicles from completing tactic assignments.","meta":{"url":"http://arxiv.org/abs/2307.16788v1"},"cats":{"new-dataset":0.0148254969,"dev-research":0.3350595762,"prompt-eng":0.405613389,"data-quality":0.0623894789,"ml-security":0.1294519822}}
{"text":"Congestion analysis conducted before the final field exercise focused on adjusting various constraints to optimize the swarm's deployment without reducing safety.","meta":{"url":"http://arxiv.org/abs/2307.16788v1"},"cats":{"new-dataset":0.123318627,"dev-research":0.2972738784,"prompt-eng":0.3808050079,"data-quality":0.1540510798,"ml-security":0.1544472233}}
{"text":"During the field exercise, data was collected that permitted analyzing the number and durations of individual vehicle blockages' impact on the resulting congestion.","meta":{"url":"http://arxiv.org/abs/2307.16788v1"},"cats":{"new-dataset":0.2213512008,"dev-research":0.235602943,"prompt-eng":0.3147140091,"data-quality":0.1171900968,"ml-security":0.13092772}}
{"text":"After the field exercise, additional analyses used the mission plan to validate the use of simulation for analyzing congestion.","meta":{"url":"http://arxiv.org/abs/2307.16788v1"},"cats":{"new-dataset":0.1328368384,"dev-research":0.3053703776,"prompt-eng":0.3557504138,"data-quality":0.122652162,"ml-security":0.0949696359}}
{"text":"Recent criticisms of AI ethics principles and practices have indicated a need for new approaches to AI ethics that can account for and intervene in the design, development, use, and governance of AI systems across multiple actors, contexts, and scales of activity.","meta":{"url":"http://arxiv.org/abs/2307.16787v1"},"cats":{"new-dataset":0.1237953343,"dev-research":0.4067054585,"prompt-eng":0.2939054333,"data-quality":0.1658568779,"ml-security":0.2949158963}}
{"text":"This paper positions AI value chains as an integrative concept that satisfies those needs, enabling AI ethics researchers, practitioners, and policymakers to take a more comprehensive view of the ethical and practical implications of AI systems.","meta":{"url":"http://arxiv.org/abs/2307.16787v1"},"cats":{"new-dataset":0.1291738784,"dev-research":0.3552664704,"prompt-eng":0.3469101654,"data-quality":0.2361913519,"ml-security":0.2365009298}}
{"text":"We review and synthesize theoretical perspectives on value chains from the literature on strategic management, service science, and economic geography.","meta":{"url":"http://arxiv.org/abs/2307.16787v1"},"cats":{"new-dataset":0.0587931272,"dev-research":0.238872075,"prompt-eng":0.321328273,"data-quality":0.1360609956,"ml-security":0.045191663}}
{"text":"We then review perspectives on AI value chains from the academic, industry, and policy literature.","meta":{"url":"http://arxiv.org/abs/2307.16787v1"},"cats":{"new-dataset":0.1253570322,"dev-research":0.2798411857,"prompt-eng":0.3339968099,"data-quality":0.2004112597,"ml-security":0.1107803492}}
{"text":"We connect an inventory of ethical concerns in AI to the actors and resourcing activities involved in AI value chains to demonstrate that approaching AI ethics issues as value chain issues can enable more comprehensive and integrative research and governance practices.","meta":{"url":"http://arxiv.org/abs/2307.16787v1"},"cats":{"new-dataset":0.205541216,"dev-research":0.3575084872,"prompt-eng":0.3024808492,"data-quality":0.2662235136,"ml-security":0.1981130994}}
{"text":"We illustrate this by suggesting five future directions for researchers, practitioners, and policymakers to investigate and intervene in the ethical concerns associated with AI value chains.","meta":{"url":"http://arxiv.org/abs/2307.16787v1"},"cats":{"new-dataset":0.0940345171,"dev-research":0.3598803044,"prompt-eng":0.3399607865,"data-quality":0.2576011228,"ml-security":0.2548423602}}
{"text":"The success of a multi-kilometre drive by a solar-powered rover at the lunar south pole depends upon careful planning in space and time due to highly dynamic solar illumination conditions.","meta":{"url":"http://arxiv.org/abs/2307.16786v1"},"cats":{"new-dataset":0.0804343264,"dev-research":0.2144750486,"prompt-eng":0.4214441239,"data-quality":0.0838471702,"ml-security":0.0395463549}}
{"text":"An additional challenge is that real-world robots may be subject to random faults that can temporarily delay long-range traverses.","meta":{"url":"http://arxiv.org/abs/2307.16786v1"},"cats":{"new-dataset":0.094929192,"dev-research":0.2806155476,"prompt-eng":0.4113222721,"data-quality":0.1557967313,"ml-security":0.1763348367}}
{"text":"The majority of existing global spatiotemporal planners assume a deterministic rover-environment model and do not account for random faults.","meta":{"url":"http://arxiv.org/abs/2307.16786v1"},"cats":{"new-dataset":0.3666947123,"dev-research":0.3014182918,"prompt-eng":0.3949900247,"data-quality":0.0850978275,"ml-security":0.1227414108}}
{"text":"In this paper, we consider a random fault profile with a known, average spatial fault rate.","meta":{"url":"http://arxiv.org/abs/2307.16786v1"},"cats":{"new-dataset":0.1866720525,"dev-research":0.2814986175,"prompt-eng":0.4269121631,"data-quality":0.2578940884,"ml-security":0.1898619028}}
{"text":"We introduce a methodology to compute recovery policies that maximize the probability of survival of a solar-powered rover from different start states.","meta":{"url":"http://arxiv.org/abs/2307.16786v1"},"cats":{"new-dataset":0.2043018836,"dev-research":0.197177329,"prompt-eng":0.4260028916,"data-quality":0.091069467,"ml-security":0.0825323903}}
{"text":"A recovery policy defines a set of recourse actions to reach a location with sufficient battery energy remaining, given the local solar illumination conditions.","meta":{"url":"http://arxiv.org/abs/2307.16786v1"},"cats":{"new-dataset":0.0933389515,"dev-research":0.2439210893,"prompt-eng":0.3822637543,"data-quality":0.1665847649,"ml-security":0.0916031222}}
{"text":"We solve a stochastic reach-avoid problem using dynamic programming to find such optimal recovery policies.","meta":{"url":"http://arxiv.org/abs/2307.16786v1"},"cats":{"new-dataset":0.0962720924,"dev-research":0.2145739966,"prompt-eng":0.3832878321,"data-quality":0.1444083455,"ml-security":0.1290050336}}
{"text":"Our focus, in part, is on the implications of state space discretization, which is often required in practical implementations.","meta":{"url":"http://arxiv.org/abs/2307.16786v1"},"cats":{"new-dataset":0.030699473,"dev-research":0.2354330678,"prompt-eng":0.3538546591,"data-quality":0.0992434274,"ml-security":0.1302756585}}
{"text":"We propose a modified dynamic programming algorithm that conservatively accounts for approximation errors.","meta":{"url":"http://arxiv.org/abs/2307.16786v1"},"cats":{"new-dataset":0.0617214781,"dev-research":0.3095884871,"prompt-eng":0.4398081783,"data-quality":0.2100608527,"ml-security":0.1123024938}}
{"text":"To demonstrate the benefits of our approach, we compare against existing methods in scenarios where a solar-powered rover seeks to safely exit from permanently shadowed regions in the Cabeus area at the lunar south pole.","meta":{"url":"http://arxiv.org/abs/2307.16786v1"},"cats":{"new-dataset":0.1438478056,"dev-research":0.2308472585,"prompt-eng":0.4648021483,"data-quality":0.118965114,"ml-security":0.1455068302}}
{"text":"We also highlight the relevance of our methodology for mission formulation and trade safety analysis by empirically comparing different rover mobility models in simulated recovery drives from the LCROSS crash region.","meta":{"url":"http://arxiv.org/abs/2307.16786v1"},"cats":{"new-dataset":0.3446420565,"dev-research":0.2677343326,"prompt-eng":0.3658640633,"data-quality":0.1118235802,"ml-security":0.1295592163}}
{"text":"Most existing Low-Light Image Enhancement (LLIE) methods are primarily designed to improve brightness in dark regions, which suffer from severe degradation in nighttime images.","meta":{"url":"http://arxiv.org/abs/2307.16783v1"},"cats":{"new-dataset":0.0332656718,"dev-research":0.2020207717,"prompt-eng":0.391338429,"data-quality":0.1337499048,"ml-security":0.0642747383}}
{"text":"However, these methods have limited exploration in another major visibility damage, the glow effects in real night scenes.","meta":{"url":"http://arxiv.org/abs/2307.16783v1"},"cats":{"new-dataset":0.0437840922,"dev-research":0.2176096954,"prompt-eng":0.3104938476,"data-quality":0.1152468523,"ml-security":0.161936906}}
{"text":"Glow effects are inevitable in the presence of artificial light sources and cause further diffused blurring when directly enhanced.","meta":{"url":"http://arxiv.org/abs/2307.16783v1"},"cats":{"new-dataset":0.0201723218,"dev-research":0.3121530339,"prompt-eng":0.362385575,"data-quality":0.1656731082,"ml-security":0.1581581301}}
{"text":"To settle this issue, we innovatively consider the glow suppression task as learning physical glow generation via multiple scattering estimation according to the Atmospheric Point Spread Function (APSF).","meta":{"url":"http://arxiv.org/abs/2307.16783v1"},"cats":{"new-dataset":0.1968030148,"dev-research":0.2092397447,"prompt-eng":0.4235218067,"data-quality":0.1288158871,"ml-security":0.1168708783}}
{"text":"In response to the challenges posed by uneven glow intensity and varying source shapes, an APSF-based Nighttime Imaging Model with Near-field Light Sources (NIM-NLS) is specifically derived to design a scalable Light-aware Blind Deconvolution Network (LBDN).","meta":{"url":"http://arxiv.org/abs/2307.16783v1"},"cats":{"new-dataset":0.1852771795,"dev-research":0.1825543492,"prompt-eng":0.3321907383,"data-quality":0.1361653734,"ml-security":0.0768277012}}
{"text":"The glow-suppressed result is then brightened via a Retinex-based Enhancement Module (REM).","meta":{"url":"http://arxiv.org/abs/2307.16783v1"},"cats":{"new-dataset":0.0828425976,"dev-research":0.2222676341,"prompt-eng":0.4296494573,"data-quality":0.1541444885,"ml-security":0.0665675422}}
{"text":"Remarkably, the proposed glow suppression method is based on zero-shot learning and does not rely on any paired or unpaired training data.","meta":{"url":"http://arxiv.org/abs/2307.16783v1"},"cats":{"new-dataset":0.0557163517,"dev-research":0.2064651174,"prompt-eng":0.3539195626,"data-quality":0.2628135435,"ml-security":0.2873117177}}
{"text":"Empirical evaluations demonstrate the effectiveness of the proposed method in both glow suppression and low-light enhancement tasks.","meta":{"url":"http://arxiv.org/abs/2307.16783v1"},"cats":{"new-dataset":0.0341669519,"dev-research":0.2527402116,"prompt-eng":0.4371292795,"data-quality":0.1879230836,"ml-security":0.0696085902}}
{"text":"In formal argumentation, a distinction can be made between extension-based semantics, where sets of arguments are either (jointly) accepted or not, and ranking-based semantics, where grades of acceptability are assigned to arguments.","meta":{"url":"http://arxiv.org/abs/2307.16780v1"},"cats":{"new-dataset":0.0371739291,"dev-research":0.3574822892,"prompt-eng":0.4216776442,"data-quality":0.2545010321,"ml-security":0.1163354915}}
{"text":"Another important distinction is that between abstract approaches, that abstract away from the content of arguments, and structured approaches, that specify a method of constructing argument graphs on the basis of a knowledge base.","meta":{"url":"http://arxiv.org/abs/2307.16780v1"},"cats":{"new-dataset":0.0539795622,"dev-research":0.4481372529,"prompt-eng":0.3162931762,"data-quality":0.1429995456,"ml-security":0.1009435528}}
{"text":"While ranking-based semantics have been extensively applied to abstract argumentation, few work has been done on ranking-based semantics for structured argumentation.","meta":{"url":"http://arxiv.org/abs/2307.16780v1"},"cats":{"new-dataset":0.1622989338,"dev-research":0.3150935608,"prompt-eng":0.4256687412,"data-quality":0.1865272253,"ml-security":0.0869597381}}
{"text":"In this paper, we make a systematic investigation into the behaviour of ranking-based semantics applied to existing formalisms for structured argumentation.","meta":{"url":"http://arxiv.org/abs/2307.16780v1"},"cats":{"new-dataset":0.2442201149,"dev-research":0.3608395665,"prompt-eng":0.4654699135,"data-quality":0.2082827519,"ml-security":0.0908346903}}
{"text":"We show that a wide class of ranking-based semantics gives rise to so-called culpability measures, and are relatively robust to specific choices in argument construction methods.","meta":{"url":"http://arxiv.org/abs/2307.16780v1"},"cats":{"new-dataset":0.1281211496,"dev-research":0.3673291022,"prompt-eng":0.4194950404,"data-quality":0.3552979028,"ml-security":0.1893585504}}
{"text":"Retrieval approaches that score documents based on learned dense vectors (i.e., dense retrieval) rather than lexical signals (i.e., conventional retrieval) are increasingly popular.","meta":{"url":"http://arxiv.org/abs/2307.16779v1"},"cats":{"new-dataset":0.0716526599,"dev-research":0.1999232738,"prompt-eng":0.3674038236,"data-quality":0.2262312946,"ml-security":0.0564483028}}
{"text":"Their ability to identify related documents that do not necessarily contain the same terms as those appearing in the user's query (thereby improving recall) is one of their key advantages.","meta":{"url":"http://arxiv.org/abs/2307.16779v1"},"cats":{"new-dataset":0.0144510257,"dev-research":0.2867469602,"prompt-eng":0.4012081003,"data-quality":0.1731217972,"ml-security":0.1266003931}}
{"text":"However, to actually achieve these gains, dense retrieval approaches typically require an exhaustive search over the document collection, making them considerably more expensive at query-time than conventional lexical approaches.","meta":{"url":"http://arxiv.org/abs/2307.16779v1"},"cats":{"new-dataset":0.1263496029,"dev-research":0.2223622752,"prompt-eng":0.3661871292,"data-quality":0.1903926261,"ml-security":0.0583074737}}
{"text":"Several techniques aim to reduce this computational overhead by approximating the results of a full dense retriever.","meta":{"url":"http://arxiv.org/abs/2307.16779v1"},"cats":{"new-dataset":0.1046120979,"dev-research":0.1790322132,"prompt-eng":0.4104838155,"data-quality":0.1274284685,"ml-security":0.0641724083}}
{"text":"Although these approaches reasonably approximate the top results, they suffer in terms of recall -- one of the key advantages of dense retrieval.","meta":{"url":"http://arxiv.org/abs/2307.16779v1"},"cats":{"new-dataset":0.1238948308,"dev-research":0.2062036844,"prompt-eng":0.3456167999,"data-quality":0.2595505175,"ml-security":0.087204329}}
{"text":"We introduce 'LADR' (Lexically-Accelerated Dense Retrieval), a simple-yet-effective approach that improves the efficiency of existing dense retrieval models without compromising on retrieval effectiveness.","meta":{"url":"http://arxiv.org/abs/2307.16779v1"},"cats":{"new-dataset":0.2631934917,"dev-research":0.2059507138,"prompt-eng":0.3817317502,"data-quality":0.1902887946,"ml-security":0.043176209}}
{"text":"LADR uses lexical retrieval techniques to seed a dense retrieval exploration that uses a document proximity graph.","meta":{"url":"http://arxiv.org/abs/2307.16779v1"},"cats":{"new-dataset":0.2077098047,"dev-research":0.2821650098,"prompt-eng":0.3844567576,"data-quality":0.1448875309,"ml-security":0.0391277363}}
{"text":"We explore two variants of LADR: a proactive approach that expands the search space to the neighbors of all seed documents, and an adaptive approach that selectively searches the documents with the highest estimated relevance in an iterative fashion.","meta":{"url":"http://arxiv.org/abs/2307.16779v1"},"cats":{"new-dataset":0.1728903826,"dev-research":0.2147183249,"prompt-eng":0.4041977797,"data-quality":0.2305995629,"ml-security":0.0593906825}}
{"text":"Through extensive experiments across a variety of dense retrieval models, we find that LADR establishes a new dense retrieval effectiveness-efficiency Pareto frontier among approximate k nearest neighbor techniques.","meta":{"url":"http://arxiv.org/abs/2307.16779v1"},"cats":{"new-dataset":0.097368596,"dev-research":0.154728358,"prompt-eng":0.3805982369,"data-quality":0.1967371376,"ml-security":0.0618702949}}
{"text":"Further, we find that when tuned to take around 8ms per query in retrieval latency on our hardware, LADR consistently achieves both precision and recall that are on par with an exhaustive search on standard benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.16779v1"},"cats":{"new-dataset":0.0653556471,"dev-research":0.2481912069,"prompt-eng":0.4381937477,"data-quality":0.1472419274,"ml-security":0.0533371778}}
{"text":"The BBQ (Bias Benchmark for Question Answering) dataset enables the evaluation of the social biases that language models (LMs) exhibit in downstream tasks.","meta":{"url":"http://arxiv.org/abs/2307.16778v1"},"cats":{"new-dataset":0.0935013978,"dev-research":0.2134499058,"prompt-eng":0.362946989,"data-quality":0.2238637295,"ml-security":0.129144683}}
{"text":"However, it is challenging to adapt BBQ to languages other than English as social biases are culturally dependent.","meta":{"url":"http://arxiv.org/abs/2307.16778v1"},"cats":{"new-dataset":0.0315809467,"dev-research":0.2723285644,"prompt-eng":0.3094682961,"data-quality":0.2564330444,"ml-security":0.1204520379}}
{"text":"In this paper, we devise a process to construct a non-English bias benchmark dataset by leveraging the English BBQ dataset in a culturally adaptive way and present the KoBBQ dataset for evaluating biases in Question Answering (QA) tasks in Korean.","meta":{"url":"http://arxiv.org/abs/2307.16778v1"},"cats":{"new-dataset":0.4209617886,"dev-research":0.234685939,"prompt-eng":0.3926291092,"data-quality":0.2659306208,"ml-security":0.0748070291}}
{"text":"We identify samples from BBQ into three classes: Simply-Translated (can be used directly after cultural translation), Target-Modified (requires localization in target groups), and Sample-Removed (does not fit Korean culture).","meta":{"url":"http://arxiv.org/abs/2307.16778v1"},"cats":{"new-dataset":0.5073376788,"dev-research":0.1775197282,"prompt-eng":0.4099190008,"data-quality":0.2727519918,"ml-security":0.0522356998}}
{"text":"We further enhance the cultural relevance to Korean culture by adding four new categories of bias specific to Korean culture and newly creating samples based on Korean literature.","meta":{"url":"http://arxiv.org/abs/2307.16778v1"},"cats":{"new-dataset":0.0997547532,"dev-research":0.2319647325,"prompt-eng":0.3289274897,"data-quality":0.2515626725,"ml-security":0.0505223093}}
{"text":"KoBBQ consists of 246 templates and 4,740 samples across 12 categories of social bias.","meta":{"url":"http://arxiv.org/abs/2307.16778v1"},"cats":{"new-dataset":0.5596796551,"dev-research":0.2007559122,"prompt-eng":0.3128540985,"data-quality":0.1468035814,"ml-security":0.0873251686}}
{"text":"Using KoBBQ, we measure the accuracy and bias scores of several state-of-the-art multilingual LMs.","meta":{"url":"http://arxiv.org/abs/2307.16778v1"},"cats":{"new-dataset":0.1258128498,"dev-research":0.1923407911,"prompt-eng":0.4517624166,"data-quality":0.3008483803,"ml-security":0.0560701237}}
{"text":"We demonstrate the differences in the bias of LMs in Korean and English, clarifying the need for hand-crafted data considering cultural differences.","meta":{"url":"http://arxiv.org/abs/2307.16778v1"},"cats":{"new-dataset":0.1747537625,"dev-research":0.2179037328,"prompt-eng":0.4118856159,"data-quality":0.2488236424,"ml-security":0.059788164}}
{"text":"To easily obtain the knowledge about autism spectrum disorder and help its early screening and diagnosis, we create AsdKB, a Chinese knowledge base on autism spectrum disorder.","meta":{"url":"http://arxiv.org/abs/2307.16773v1"},"cats":{"new-dataset":0.2924066367,"dev-research":0.2522160747,"prompt-eng":0.3856757713,"data-quality":0.1312396488,"ml-security":0.0968581907}}
{"text":"The knowledge base is built on top of various sources, including 1) the disease knowledge from SNOMED CT and ICD-10 clinical descriptions on mental and behavioural disorders, 2) the diagnostic knowledge from DSM-5 and different screening tools recommended by social organizations and medical institutes, and 3) the expert knowledge on professional physicians and hospitals from the Web.","meta":{"url":"http://arxiv.org/abs/2307.16773v1"},"cats":{"new-dataset":0.2715760237,"dev-research":0.2845752181,"prompt-eng":0.4013652289,"data-quality":0.117874249,"ml-security":0.1103918494}}
{"text":"AsdKB contains both ontological and factual knowledge, and is accessible as Linked Data at https://w3id.org/asdkb/. The potential applications of AsdKB are question answering, auxiliary diagnosis, and expert recommendation, and we illustrate them with a prototype which can be accessed at http://asdkb.org.cn/.","meta":{"url":"http://arxiv.org/abs/2307.16773v1"},"cats":{"new-dataset":0.3363145716,"dev-research":0.3810265316,"prompt-eng":0.4673248279,"data-quality":0.2012465103,"ml-security":0.0865468038}}
{"text":"Modern ML predictions models are surprisingly accurate in practice and incorporating their power into algorithms has led to a new research direction.","meta":{"url":"http://arxiv.org/abs/2307.16771v1"},"cats":{"new-dataset":0.0486177302,"dev-research":0.2133643756,"prompt-eng":0.3815517997,"data-quality":0.2201103562,"ml-security":0.2213233236}}
{"text":"Algorithms with predictions have already been used to improve on worst-case optimal bounds for online problems and for static graph problems.   ","meta":{"url":"http://arxiv.org/abs/2307.16771v1"},"cats":{"new-dataset":0.1618150436,"dev-research":0.2231761328,"prompt-eng":0.3325353077,"data-quality":0.2241467418,"ml-security":0.261977852}}
{"text":"With this work, we initiate the study of the complexity of {\\em data structures with predictions}, with an emphasis on dynamic graph problems.","meta":{"url":"http://arxiv.org/abs/2307.16771v1"},"cats":{"new-dataset":0.1436973382,"dev-research":0.2061909605,"prompt-eng":0.3524959683,"data-quality":0.1656623672,"ml-security":0.16325825}}
{"text":"Unlike the independent work of v.d.~Brand et al.~[arXiv:2307.09961] that aims at upper bounds, our investigation is focused on establishing conditional fine-grained lower bounds for various notions of predictions.   ","meta":{"url":"http://arxiv.org/abs/2307.16771v1"},"cats":{"new-dataset":0.1781536817,"dev-research":0.1774669709,"prompt-eng":0.3829508858,"data-quality":0.2192406024,"ml-security":0.2589153614}}
{"text":"Our lower bounds are conditioned on the Online Matrix Vector (OMv) hypothesis.","meta":{"url":"http://arxiv.org/abs/2307.16771v1"},"cats":{"new-dataset":0.0566556539,"dev-research":0.1418573322,"prompt-eng":0.3198414625,"data-quality":0.137925025,"ml-security":0.1890412797}}
{"text":"First we show that a prediction-based algorithm for OMv provides a smooth transition between the known bounds, for the offline and the online setting, and then show that this algorithm is essentially optimal under the OMv hypothesis.","meta":{"url":"http://arxiv.org/abs/2307.16771v1"},"cats":{"new-dataset":0.1591029893,"dev-research":0.1731742641,"prompt-eng":0.39334544,"data-quality":0.1358573261,"ml-security":0.1204008479}}
{"text":"Further, we introduce and study four different kinds of predictions.","meta":{"url":"http://arxiv.org/abs/2307.16771v1"},"cats":{"new-dataset":0.0664915372,"dev-research":0.1783737429,"prompt-eng":0.3924316214,"data-quality":0.1259237699,"ml-security":0.1316852263}}
{"text":"(1) For {\\em $\\varepsilon$-accurate predictions}, where $\\varepsilon \\in (0,1)$, we show that any lower bound from the non-prediction setting carries over, reduced by a factor of $1-\\varepsilon$. (2) For {\\em $L$-list accurate predictions}, we show that one can efficiently compute a $(1/L)$-accurate prediction from an $L$-list accurate prediction.","meta":{"url":"http://arxiv.org/abs/2307.16771v1"},"cats":{"new-dataset":0.1269995973,"dev-research":0.1708714972,"prompt-eng":0.3606553841,"data-quality":0.3263406405,"ml-security":0.3053739372}}
{"text":"(3) For {\\em bounded delay predictions} and {\\em bounded delay predictions with outliers}, we show that a lower bound from the non-prediction setting carries over, if the reduction fulfills a certain reordering condition (which is fulfilled by many reductions from OMv for dynamic graph problems).","meta":{"url":"http://arxiv.org/abs/2307.16771v1"},"cats":{"new-dataset":0.1222095216,"dev-research":0.2102770824,"prompt-eng":0.3170455084,"data-quality":0.2498963856,"ml-security":0.2799286702}}
{"text":"This is demonstrated by showing lower and almost tight upper bounds for a concrete, dynamic graph problem, called $\\# s \\textrm{-} \\triangle$, where the number of triangles that contain a fixed vertex $s$ must be reported.","meta":{"url":"http://arxiv.org/abs/2307.16771v1"},"cats":{"new-dataset":0.2904478504,"dev-research":0.2407775781,"prompt-eng":0.3232840673,"data-quality":0.198568128,"ml-security":0.1715891484}}
{"text":"Heatmap-based methods have become the mainstream method for pose estimation due to their superior performance.","meta":{"url":"http://arxiv.org/abs/2307.16765v1"},"cats":{"new-dataset":0.2861754516,"dev-research":0.1795948699,"prompt-eng":0.3564226735,"data-quality":0.095877176,"ml-security":0.079458134}}
{"text":"However, heatmap-based approaches suffer from significant quantization errors with downscale heatmaps, which result in limited performance and the detrimental effects of intermediate supervision.","meta":{"url":"http://arxiv.org/abs/2307.16765v1"},"cats":{"new-dataset":0.0724160348,"dev-research":0.2926243258,"prompt-eng":0.42539734,"data-quality":0.2058943944,"ml-security":0.0693038272}}
{"text":"Previous heatmap-based methods relied heavily on additional post-processing to mitigate quantization errors.","meta":{"url":"http://arxiv.org/abs/2307.16765v1"},"cats":{"new-dataset":0.056081365,"dev-research":0.289094467,"prompt-eng":0.3818035844,"data-quality":0.1959276603,"ml-security":0.0719344962}}
{"text":"Some heatmap-based approaches improve the resolution of feature maps by using multiple costly upsampling layers to improve localization precision.","meta":{"url":"http://arxiv.org/abs/2307.16765v1"},"cats":{"new-dataset":0.1979719689,"dev-research":0.2996728382,"prompt-eng":0.4027785929,"data-quality":0.230723596,"ml-security":0.0667100361}}
{"text":"To solve the above issues, we creatively view the backbone network as a degradation process and thus reformulate the heatmap prediction as a Super-Resolution (SR) task.","meta":{"url":"http://arxiv.org/abs/2307.16765v1"},"cats":{"new-dataset":0.2114026335,"dev-research":0.1974166461,"prompt-eng":0.3640075798,"data-quality":0.1346278861,"ml-security":0.0962023237}}
{"text":"We first propose the SR head, which predicts heatmaps with a spatial resolution higher than the input feature maps (or even consistent with the input image) by super-resolution, to effectively reduce the quantization error and the dependence on further post-processing.","meta":{"url":"http://arxiv.org/abs/2307.16765v1"},"cats":{"new-dataset":0.2120669402,"dev-research":0.2410899848,"prompt-eng":0.3814400713,"data-quality":0.1433427843,"ml-security":0.0916372635}}
{"text":"Besides, we propose SRPose to gradually recover the HR heatmaps from LR heatmaps and degraded features in a coarse-to-fine manner.","meta":{"url":"http://arxiv.org/abs/2307.16765v1"},"cats":{"new-dataset":0.1823875956,"dev-research":0.2317827346,"prompt-eng":0.4213630915,"data-quality":0.1737632538,"ml-security":0.0739060582}}
{"text":"To reduce the training difficulty of HR heatmaps, SRPose applies SR heads to supervise the intermediate features in each stage.","meta":{"url":"http://arxiv.org/abs/2307.16765v1"},"cats":{"new-dataset":0.0620116533,"dev-research":0.2827237129,"prompt-eng":0.4329396157,"data-quality":0.1165013918,"ml-security":0.0646303673}}
{"text":"In addition, the SR head is a lightweight and generic head that applies to top-down and bottom-up methods.","meta":{"url":"http://arxiv.org/abs/2307.16765v1"},"cats":{"new-dataset":0.0153892824,"dev-research":0.2709999912,"prompt-eng":0.4137880349,"data-quality":0.0848699238,"ml-security":0.0410642352}}
{"text":"Extensive experiments on the COCO, MPII, and CrowdPose datasets show that SRPose outperforms the corresponding heatmap-based approaches.","meta":{"url":"http://arxiv.org/abs/2307.16765v1"},"cats":{"new-dataset":0.3666859333,"dev-research":0.2137187994,"prompt-eng":0.3724886224,"data-quality":0.1326112058,"ml-security":0.0556929528}}
{"text":"The code and models are available at https://github.com/haonanwang0522/SRPose.","meta":{"url":"http://arxiv.org/abs/2307.16765v1"},"cats":{"new-dataset":0.3503320717,"dev-research":0.1271504354,"prompt-eng":0.4341130876,"data-quality":0.0766146529,"ml-security":0.0270111846}}
{"text":"This paper accompanies a new dataset of non-linear real arithmetic problems for the SMT-LIB benchmark collection.","meta":{"url":"http://arxiv.org/abs/2307.16761v1"},"cats":{"new-dataset":0.4388403903,"dev-research":0.2237033127,"prompt-eng":0.3176751829,"data-quality":0.194929692,"ml-security":0.1146189252}}
{"text":"The problems come from an automated proof procedure of Gerhold--Kauers, which is well suited for solution by SMT.","meta":{"url":"http://arxiv.org/abs/2307.16761v1"},"cats":{"new-dataset":0.2408434338,"dev-research":0.1827522128,"prompt-eng":0.4005460418,"data-quality":0.1742563291,"ml-security":0.0747882656}}
{"text":"The problems of this type have not been tackled by SMT-solvers before.","meta":{"url":"http://arxiv.org/abs/2307.16761v1"},"cats":{"new-dataset":0.0721541791,"dev-research":0.2164188962,"prompt-eng":0.3656582114,"data-quality":0.1807713017,"ml-security":0.0878714189}}
{"text":"We describe the proof technique and give one new such proof to illustrate it.","meta":{"url":"http://arxiv.org/abs/2307.16761v1"},"cats":{"new-dataset":0.1107873417,"dev-research":0.2494528248,"prompt-eng":0.3941012783,"data-quality":0.2526385778,"ml-security":0.1868045811}}
{"text":"We then describe the dataset and the results of benchmarking.","meta":{"url":"http://arxiv.org/abs/2307.16761v1"},"cats":{"new-dataset":0.6513817885,"dev-research":0.267367477,"prompt-eng":0.3715848401,"data-quality":0.2203053372,"ml-security":0.0885146144}}
{"text":"The benchmarks on the new dataset are quite different to the existing ones.","meta":{"url":"http://arxiv.org/abs/2307.16761v1"},"cats":{"new-dataset":0.331422279,"dev-research":0.2544909119,"prompt-eng":0.2843499718,"data-quality":0.182711343,"ml-security":0.0807038176}}
{"text":"The benchmarking also brings forward some interesting debate on the use/inclusion of rational functions and algebraic numbers in the SMT-LIB.","meta":{"url":"http://arxiv.org/abs/2307.16761v1"},"cats":{"new-dataset":0.1242977896,"dev-research":0.2548431217,"prompt-eng":0.3660266072,"data-quality":0.1307816765,"ml-security":0.0815731901}}
{"text":"Coordinate descent methods are popular in machine learning and optimization for their simple sparse updates and excellent practical performance.","meta":{"url":"http://arxiv.org/abs/2307.16754v1"},"cats":{"new-dataset":0.1010952099,"dev-research":0.1990252869,"prompt-eng":0.3690789034,"data-quality":0.1654124617,"ml-security":0.1351195746}}
{"text":"In the context of large-scale sequential game solving, these same properties would be attractive, but until now no such methods were known, because the strategy spaces do not satisfy the typical separable block structure exploited by such methods.","meta":{"url":"http://arxiv.org/abs/2307.16754v1"},"cats":{"new-dataset":0.0601644284,"dev-research":0.2231647082,"prompt-eng":0.3158330723,"data-quality":0.0643580768,"ml-security":0.1836281372}}
{"text":"We present the first cyclic coordinate-descent-like method for the polytope of sequence-form strategies, which form the strategy spaces for the players in an extensive-form game (EFG).","meta":{"url":"http://arxiv.org/abs/2307.16754v1"},"cats":{"new-dataset":0.1143252942,"dev-research":0.2725911343,"prompt-eng":0.3564482477,"data-quality":0.058920277,"ml-security":0.1626480463}}
{"text":"Our method exploits the recursive structure of the proximal update induced by what are known as dilated regularizers, in order to allow for a pseudo block-wise update.","meta":{"url":"http://arxiv.org/abs/2307.16754v1"},"cats":{"new-dataset":0.057019862,"dev-research":0.2231831554,"prompt-eng":0.4275600645,"data-quality":0.2599808982,"ml-security":0.1590796294}}
{"text":"We show that our method enjoys a $O(1/T)$ convergence rate to a two-player zero-sum Nash equilibrium, while avoiding the worst-case polynomial scaling with the number of blocks common to cyclic methods.","meta":{"url":"http://arxiv.org/abs/2307.16754v1"},"cats":{"new-dataset":0.0369859232,"dev-research":0.1606439475,"prompt-eng":0.3117232418,"data-quality":0.1153933697,"ml-security":0.1626328165}}
{"text":"We empirically show that our algorithm usually performs better than other state-of-the-art first-order methods (i.e., mirror prox), and occasionally can even beat CFR$^+$, a state-of-the-art algorithm for numerical equilibrium computation in zero-sum EFGs.","meta":{"url":"http://arxiv.org/abs/2307.16754v1"},"cats":{"new-dataset":0.0562537035,"dev-research":0.2021020354,"prompt-eng":0.3719949573,"data-quality":0.1121143586,"ml-security":0.1287084327}}
{"text":"We then introduce a restarting heuristic for EFG solving.","meta":{"url":"http://arxiv.org/abs/2307.16754v1"},"cats":{"new-dataset":0.0797736866,"dev-research":0.3330295372,"prompt-eng":0.4722180064,"data-quality":0.1185415231,"ml-security":0.0637775312}}
{"text":"We show empirically that restarting can lead to speedups, sometimes huge, both for our cyclic method, as well as for existing methods such as mirror prox and predictive CFR$^+$.","meta":{"url":"http://arxiv.org/abs/2307.16754v1"},"cats":{"new-dataset":0.0729496799,"dev-research":0.2598353428,"prompt-eng":0.4450319853,"data-quality":0.1363060254,"ml-security":0.0954143582}}
{"text":"Many objects such as tools and household items can be used only if grasped in a very specific way - grasped functionally.","meta":{"url":"http://arxiv.org/abs/2307.16752v1"},"cats":{"new-dataset":0.0108010336,"dev-research":0.202764116,"prompt-eng":0.3105719577,"data-quality":0.0820492273,"ml-security":0.1447534104}}
{"text":"Often, a direct functional grasp is not possible, though.","meta":{"url":"http://arxiv.org/abs/2307.16752v1"},"cats":{"new-dataset":0.0047557321,"dev-research":0.2451066365,"prompt-eng":0.3836207998,"data-quality":0.0932151671,"ml-security":0.0818464979}}
{"text":"We propose a method for learning a dexterous pre-grasp manipulation policy to achieve human-like functional grasps using deep reinforcement learning.","meta":{"url":"http://arxiv.org/abs/2307.16752v1"},"cats":{"new-dataset":0.1484159463,"dev-research":0.2436185583,"prompt-eng":0.3838505611,"data-quality":0.0670342874,"ml-security":0.0872359676}}
{"text":"We introduce a dense multi-component reward function that enables learning a single policy, capable of dexterous pre-grasp manipulation of novel instances of several known object categories with an anthropomorphic hand.","meta":{"url":"http://arxiv.org/abs/2307.16752v1"},"cats":{"new-dataset":0.1632106529,"dev-research":0.2021880726,"prompt-eng":0.3860139859,"data-quality":0.0827058986,"ml-security":0.094601102}}
{"text":"The policy is learned purely by means of reinforcement learning from scratch, without any expert demonstrations, and implicitly learns to reposition and reorient objects of complex shapes to achieve given functional grasps.","meta":{"url":"http://arxiv.org/abs/2307.16752v1"},"cats":{"new-dataset":0.0647976318,"dev-research":0.2556169255,"prompt-eng":0.3308313905,"data-quality":0.0829746147,"ml-security":0.147603334}}
{"text":"Learning is done on a single GPU in less than three hours.","meta":{"url":"http://arxiv.org/abs/2307.16752v1"},"cats":{"new-dataset":0.03608732,"dev-research":0.2489790689,"prompt-eng":0.3331785243,"data-quality":0.0780573533,"ml-security":0.0776266003}}
{"text":"In this study, the structural problems of the YOLOv5 model were analyzed emphatically.","meta":{"url":"http://arxiv.org/abs/2307.16751v1"},"cats":{"new-dataset":0.0242561791,"dev-research":0.1728388527,"prompt-eng":0.3571988621,"data-quality":0.0914474802,"ml-security":0.0952380661}}
{"text":"Based on the characteristics of fine defects in artificial leather, four innovative structures, namely DFP, IFF, AMP, and EOS, were designed.","meta":{"url":"http://arxiv.org/abs/2307.16751v1"},"cats":{"new-dataset":0.0723148759,"dev-research":0.2793697529,"prompt-eng":0.3709375368,"data-quality":0.1788340978,"ml-security":0.061557298}}
{"text":"These advancements led to the proposal of a high-performance artificial leather fine defect detection model named YOLOD.","meta":{"url":"http://arxiv.org/abs/2307.16751v1"},"cats":{"new-dataset":0.1076113338,"dev-research":0.260222515,"prompt-eng":0.4264360499,"data-quality":0.3237366288,"ml-security":0.1313669596}}
{"text":"YOLOD demonstrated outstanding performance on the artificial leather defect dataset, achieving an impressive increase of 11.7% - 13.5% in AP_50 compared to YOLOv5, along with a significant reduction of 5.2% - 7.2% in the error detection rate.","meta":{"url":"http://arxiv.org/abs/2307.16751v1"},"cats":{"new-dataset":0.2769798924,"dev-research":0.312926568,"prompt-eng":0.4346404141,"data-quality":0.3050211747,"ml-security":0.127866418}}
{"text":"Moreover, YOLOD also exhibited remarkable performance on the general MS-COCO dataset, with an increase of 0.4% - 2.6% in AP compared to YOLOv5, and a rise of 2.5% - 4.1% in AP_S compared to YOLOv5.","meta":{"url":"http://arxiv.org/abs/2307.16751v1"},"cats":{"new-dataset":0.3146842074,"dev-research":0.2332080061,"prompt-eng":0.40497289,"data-quality":0.2084443847,"ml-security":0.0994516557}}
{"text":"These results demonstrate the superiority of YOLOD in both artificial leather defect detection and general object detection tasks, making it a highly efficient and effective model for real-world applications.","meta":{"url":"http://arxiv.org/abs/2307.16751v1"},"cats":{"new-dataset":0.0812738039,"dev-research":0.2573708766,"prompt-eng":0.4342615765,"data-quality":0.3367892454,"ml-security":0.1590014032}}
{"text":"Cylindrical Algebraic Decomposition (CAD) by projection and lifting requires many iterated univariate resultants.","meta":{"url":"http://arxiv.org/abs/2307.16750v1"},"cats":{"new-dataset":0.1421790333,"dev-research":0.2363068407,"prompt-eng":0.3757183464,"data-quality":0.0708502107,"ml-security":0.0915091371}}
{"text":"It has been observed that these often factor, but to date this has not been used to optimise implementations of CAD.","meta":{"url":"http://arxiv.org/abs/2307.16750v1"},"cats":{"new-dataset":0.014283897,"dev-research":0.3155152781,"prompt-eng":0.377236478,"data-quality":0.1116867107,"ml-security":0.0440698315}}
{"text":"We continue the investigation into such factorisations, writing in the specific context of SC-Square.","meta":{"url":"http://arxiv.org/abs/2307.16750v1"},"cats":{"new-dataset":0.1390394301,"dev-research":0.2051170425,"prompt-eng":0.3605004611,"data-quality":0.0937430068,"ml-security":0.0767499802}}
{"text":"Malnutrition poses a significant threat to global health, resulting from an inadequate intake of essential nutrients that adversely impacts vital organs and overall bodily functioning.","meta":{"url":"http://arxiv.org/abs/2307.16745v1"},"cats":{"new-dataset":0.0178249793,"dev-research":0.2823070554,"prompt-eng":0.2896217816,"data-quality":0.1561025462,"ml-security":0.2758651301}}
{"text":"Periodic examinations and mass screenings, incorporating both conventional and non-invasive techniques, have been employed to combat this challenge.","meta":{"url":"http://arxiv.org/abs/2307.16745v1"},"cats":{"new-dataset":0.0177060664,"dev-research":0.2414880996,"prompt-eng":0.5078386251,"data-quality":0.1893087966,"ml-security":0.1292688592}}
{"text":"However, these approaches suffer from critical limitations, such as the need for additional equipment, lack of comprehensive feature representation, absence of suitable health indicators, and the unavailability of smartphone implementations for precise estimations of Body Fat Percentage (BFP), Basal Metabolic Rate (BMR), and Body Mass Index (BMI) to enable efficient smart-malnutrition monitoring.","meta":{"url":"http://arxiv.org/abs/2307.16745v1"},"cats":{"new-dataset":0.0736917733,"dev-research":0.2000042279,"prompt-eng":0.414003616,"data-quality":0.1151614697,"ml-security":0.0822341619}}
{"text":"To address these constraints, this study presents a groundbreaking, scalable, and robust smart malnutrition-monitoring system that leverages a single full-body image of an individual to estimate height, weight, and other crucial health parameters within a multi-modal learning framework.","meta":{"url":"http://arxiv.org/abs/2307.16745v1"},"cats":{"new-dataset":0.1550029999,"dev-research":0.2113168637,"prompt-eng":0.3972917424,"data-quality":0.1478313733,"ml-security":0.1351485512}}
{"text":"Our proposed methodology involves the reconstruction of a highly precise 3D point cloud, from which 512-dimensional feature embeddings are extracted using a headless-3D classification network.","meta":{"url":"http://arxiv.org/abs/2307.16745v1"},"cats":{"new-dataset":0.2154976291,"dev-research":0.2011463992,"prompt-eng":0.3152902186,"data-quality":0.1390336198,"ml-security":0.127782596}}
{"text":"Concurrently, facial and body embeddings are also extracted, and through the application of learnable parameters, these features are then utilized to estimate weight accurately.","meta":{"url":"http://arxiv.org/abs/2307.16745v1"},"cats":{"new-dataset":0.0870453179,"dev-research":0.1952736138,"prompt-eng":0.374396673,"data-quality":0.1305910414,"ml-security":0.107965129}}
{"text":"Furthermore, essential health metrics, including BMR, BFP, and BMI, are computed to conduct a comprehensive analysis of the subject's health, subsequently facilitating the provision of personalized nutrition plans.","meta":{"url":"http://arxiv.org/abs/2307.16745v1"},"cats":{"new-dataset":0.0472997552,"dev-research":0.2138937586,"prompt-eng":0.3975267924,"data-quality":0.0676550126,"ml-security":0.0501505994}}
{"text":"While being robust to a wide range of lighting conditions across multiple devices, our model achieves a low Mean Absolute Error (MAE) of $\\pm$ 4.7 cm and $\\pm$ 5.3 kg in estimating height and weight.","meta":{"url":"http://arxiv.org/abs/2307.16745v1"},"cats":{"new-dataset":0.1360047502,"dev-research":0.1720196246,"prompt-eng":0.3948170255,"data-quality":0.1448534983,"ml-security":0.0602191425}}
{"text":"Multi-spectral image stitching leverages the complementarity between infrared and visible images to generate a robust and reliable wide field-of-view (FOV) scene.","meta":{"url":"http://arxiv.org/abs/2307.16741v1"},"cats":{"new-dataset":0.1493768347,"dev-research":0.206240802,"prompt-eng":0.3698032194,"data-quality":0.0948575806,"ml-security":0.0457766471}}
{"text":"The primary challenge of this task is to explore the relations between multi-spectral images for aligning and integrating multi-view scenes.","meta":{"url":"http://arxiv.org/abs/2307.16741v1"},"cats":{"new-dataset":0.1420236493,"dev-research":0.1841180119,"prompt-eng":0.375082985,"data-quality":0.1275873279,"ml-security":0.0311387286}}
{"text":"Capitalizing on the strengths of Graph Convolutional Networks (GCNs) in modeling feature relationships, we propose a spatial graph reasoning based multi-spectral image stitching method that effectively distills the deformation and integration of multi-spectral images across different viewpoints.","meta":{"url":"http://arxiv.org/abs/2307.16741v1"},"cats":{"new-dataset":0.170952613,"dev-research":0.2859332676,"prompt-eng":0.3236063171,"data-quality":0.1488963223,"ml-security":0.0605878671}}
{"text":"To accomplish this, we embed multi-scale complementary features from the same view position into a set of nodes.","meta":{"url":"http://arxiv.org/abs/2307.16741v1"},"cats":{"new-dataset":0.104503989,"dev-research":0.2590239726,"prompt-eng":0.371824869,"data-quality":0.1843334482,"ml-security":0.1126675318}}
{"text":"The correspondence across different views is learned through powerful dense feature embeddings, where both inter- and intra-correlations are developed to exploit cross-view matching and enhance inner feature disparity.","meta":{"url":"http://arxiv.org/abs/2307.16741v1"},"cats":{"new-dataset":0.1296264449,"dev-research":0.243668387,"prompt-eng":0.314881315,"data-quality":0.2223022637,"ml-security":0.0872916704}}
{"text":"By introducing long-range coherence along spatial and channel dimensions, the complementarity of pixel relations and channel interdependencies aids in the reconstruction of aligned multi-view features, generating informative and reliable wide FOV scenes.","meta":{"url":"http://arxiv.org/abs/2307.16741v1"},"cats":{"new-dataset":0.2401917207,"dev-research":0.2237069725,"prompt-eng":0.3132980931,"data-quality":0.1193436158,"ml-security":0.0458393567}}
{"text":"Moreover, we release a challenging dataset named ChaMS, comprising both real-world and synthetic sets with significant parallax, providing a new option for comprehensive evaluation.","meta":{"url":"http://arxiv.org/abs/2307.16741v1"},"cats":{"new-dataset":0.7997026558,"dev-research":0.1537925202,"prompt-eng":0.387067056,"data-quality":0.1706651666,"ml-security":0.0656324553}}
{"text":"Extensive experiments demonstrate that our method surpasses the state-of-the-arts.","meta":{"url":"http://arxiv.org/abs/2307.16741v1"},"cats":{"new-dataset":0.0372231647,"dev-research":0.2132765001,"prompt-eng":0.397556489,"data-quality":0.170865137,"ml-security":0.0627222842}}
{"text":"This study presents a novel coupled mechano-electro-chemical formulation for predicting stress corrosion cracking (SCC) phenomena in steel structures using the phase field method.","meta":{"url":"http://arxiv.org/abs/2307.16739v1"},"cats":{"new-dataset":0.0238206636,"dev-research":0.3121625862,"prompt-eng":0.3578903081,"data-quality":0.168030232,"ml-security":0.1083587238}}
{"text":"SCC is a complex damage process that arises from the interaction between mechanical loading and corrosion in a corrosive electrolyte environment.","meta":{"url":"http://arxiv.org/abs/2307.16739v1"},"cats":{"new-dataset":0.0415441354,"dev-research":0.3311153183,"prompt-eng":0.3629732922,"data-quality":0.1599881013,"ml-security":0.1590142969}}
{"text":"The proposed formulation introduces a new phase-field parameter that aggregates the damage due to mechanical loading and electro-chemical corrosion.","meta":{"url":"http://arxiv.org/abs/2307.16739v1"},"cats":{"new-dataset":0.0169201045,"dev-research":0.2924204005,"prompt-eng":0.378256156,"data-quality":0.1633349159,"ml-security":0.1238913481}}
{"text":"To achieve this goal, the internal energies governing the SCC phenomenon are separated into elastic-damage strain energy, the interfacial reaction energy, and energy resulting from changes in corrosion ion concentration.","meta":{"url":"http://arxiv.org/abs/2307.16739v1"},"cats":{"new-dataset":0.0212707767,"dev-research":0.2589022095,"prompt-eng":0.3818184879,"data-quality":0.1371389951,"ml-security":0.1163978014}}
{"text":"The Allen-Cahn equation is modified to include all energy contributions and calculate the phase field parameter.","meta":{"url":"http://arxiv.org/abs/2307.16739v1"},"cats":{"new-dataset":0.0524363695,"dev-research":0.1318012031,"prompt-eng":0.3398312502,"data-quality":0.0607974037,"ml-security":0.0445992395}}
{"text":"Furthermore, a specific interfacial kinetic coefficient is introduced to the mechanical energy to take into account corrosion current effects on mechanical properties.","meta":{"url":"http://arxiv.org/abs/2307.16739v1"},"cats":{"new-dataset":0.0170088712,"dev-research":0.2696277597,"prompt-eng":0.3600302246,"data-quality":0.1634354644,"ml-security":0.0975834247}}
{"text":"The Cahn-Hilliard equation is applied to model the corrosion ion concentration in the domain and the mechanical state of the body is obtained by solving the equilibrium equations.","meta":{"url":"http://arxiv.org/abs/2307.16739v1"},"cats":{"new-dataset":0.0374950905,"dev-research":0.2139764415,"prompt-eng":0.3289350862,"data-quality":0.0786080666,"ml-security":0.1017571352}}
{"text":"Several numerical examples are presented to validate the robustness and accuracy of the proposed formulation.","meta":{"url":"http://arxiv.org/abs/2307.16739v1"},"cats":{"new-dataset":0.0413035461,"dev-research":0.1856900322,"prompt-eng":0.3910445529,"data-quality":0.1883020168,"ml-security":0.0744530854}}
{"text":"Finally, the method is applied to predict crack propagation resulting from SCC on two practical engineering problems, yielding promising results.","meta":{"url":"http://arxiv.org/abs/2307.16739v1"},"cats":{"new-dataset":0.0278102866,"dev-research":0.2880247581,"prompt-eng":0.3999127242,"data-quality":0.1914854389,"ml-security":0.1752691671}}
{"text":"We study the excess minimum risk in statistical inference, defined as the difference between the minimum expected loss in estimating a random variable from an observed feature vector and the minimum expected loss in estimating the same random variable from a transformation (statistic) of the feature vector.","meta":{"url":"http://arxiv.org/abs/2307.16735v1"},"cats":{"new-dataset":0.0123084016,"dev-research":0.219561591,"prompt-eng":0.383163849,"data-quality":0.3061765,"ml-security":0.3849658119}}
{"text":"After characterizing lossless transformations, i.e., transformations for which the excess risk is zero for all loss functions, we construct a partitioning test statistic for the hypothesis that a given transformation is lossless and show that for i.i.d. data the test is strongly consistent.","meta":{"url":"http://arxiv.org/abs/2307.16735v1"},"cats":{"new-dataset":0.0635616173,"dev-research":0.1798266617,"prompt-eng":0.3916595784,"data-quality":0.2816560592,"ml-security":0.3156689538}}
{"text":"More generally, we develop information-theoretic upper bounds on the excess risk that uniformly hold over fairly general classes of loss functions.","meta":{"url":"http://arxiv.org/abs/2307.16735v1"},"cats":{"new-dataset":0.0767431625,"dev-research":0.1664312105,"prompt-eng":0.357026529,"data-quality":0.2209361676,"ml-security":0.4900768982}}
{"text":"Based on these bounds, we introduce the notion of a delta-lossless transformation and give sufficient conditions for a given transformation to be universally delta-lossless.","meta":{"url":"http://arxiv.org/abs/2307.16735v1"},"cats":{"new-dataset":0.0860664233,"dev-research":0.1577275355,"prompt-eng":0.3233507124,"data-quality":0.2116404863,"ml-security":0.186855225}}
{"text":"Applications to classification, nonparametric regression, portfolio strategies, information bottleneck, and deep learning, are also surveyed.","meta":{"url":"http://arxiv.org/abs/2307.16735v1"},"cats":{"new-dataset":0.0306068353,"dev-research":0.1764870226,"prompt-eng":0.3280588301,"data-quality":0.1329156076,"ml-security":0.2073571073}}
{"text":"Programmable Matter (PM) has been widely investigated in recent years.","meta":{"url":"http://arxiv.org/abs/2307.16731v1"},"cats":{"new-dataset":0.0254718069,"dev-research":0.2079489459,"prompt-eng":0.4112416206,"data-quality":0.0856396967,"ml-security":0.0512702246}}
{"text":"It refers to some kind of matter with the ability to change its physical properties (e.g., shape or color) in a programmable way.","meta":{"url":"http://arxiv.org/abs/2307.16731v1"},"cats":{"new-dataset":0.0301044068,"dev-research":0.3167474588,"prompt-eng":0.3626712721,"data-quality":0.1065046915,"ml-security":0.0698249396}}
{"text":"One reference model is certainly Amoebot, with its recent canonical version (DISC 2021).","meta":{"url":"http://arxiv.org/abs/2307.16731v1"},"cats":{"new-dataset":0.4086054011,"dev-research":0.1926022278,"prompt-eng":0.4292230646,"data-quality":0.0958879961,"ml-security":0.0496065691}}
{"text":"Along this line, with the aim of simplification and to better address concurrency, the SILBOT model has been introduced (AAMAS 2020), which heavily reduces the available capabilities of the particles composing the PM.","meta":{"url":"http://arxiv.org/abs/2307.16731v1"},"cats":{"new-dataset":0.0612176117,"dev-research":0.1769938515,"prompt-eng":0.4148395618,"data-quality":0.087606939,"ml-security":0.0584436536}}
{"text":"In SILBOT, in fact, particles are asynchronous, without any direct means of communication (silent) and without memory of past events (oblivious).","meta":{"url":"http://arxiv.org/abs/2307.16731v1"},"cats":{"new-dataset":0.0294373591,"dev-research":0.2106921363,"prompt-eng":0.3362148172,"data-quality":0.1253121367,"ml-security":0.1449847363}}
{"text":"Within SILBOT, we consider the Line Formation primitive in which particles are required to end up in a configuration where they are all aligned and connected.","meta":{"url":"http://arxiv.org/abs/2307.16731v1"},"cats":{"new-dataset":0.0868980398,"dev-research":0.2092031795,"prompt-eng":0.3409001435,"data-quality":0.1011130022,"ml-security":0.0631244586}}
{"text":"We propose a simple and elegant distributed algorithm - optimal in terms of number of movements, along with its correctness proof.","meta":{"url":"http://arxiv.org/abs/2307.16731v1"},"cats":{"new-dataset":0.1408236804,"dev-research":0.1808530311,"prompt-eng":0.361611197,"data-quality":0.1232666564,"ml-security":0.116984212}}
{"text":"In this work, we propose a learning based neural model that provides both the longitudinal and lateral control commands to simultaneously navigate multiple vehicles.","meta":{"url":"http://arxiv.org/abs/2307.16727v1"},"cats":{"new-dataset":0.1031138316,"dev-research":0.2191043016,"prompt-eng":0.3913284793,"data-quality":0.0685707216,"ml-security":0.0741509436}}
{"text":"The goal is to ensure that each vehicle reaches a desired target state without colliding with any other vehicle or obstacle in an unconstrained environment.","meta":{"url":"http://arxiv.org/abs/2307.16727v1"},"cats":{"new-dataset":0.0679304161,"dev-research":0.2276616525,"prompt-eng":0.3646009231,"data-quality":0.068051663,"ml-security":0.1147623098}}
{"text":"The model utilizes an attention based Graphical Neural Network paradigm that takes into consideration the state of all the surrounding vehicles to make an informed decision.","meta":{"url":"http://arxiv.org/abs/2307.16727v1"},"cats":{"new-dataset":0.0831620337,"dev-research":0.2590387364,"prompt-eng":0.3974930802,"data-quality":0.1121547691,"ml-security":0.0898738498}}
{"text":"This allows each vehicle to smoothly reach its destination while also evading collision with the other agents.","meta":{"url":"http://arxiv.org/abs/2307.16727v1"},"cats":{"new-dataset":0.0206406068,"dev-research":0.2866430826,"prompt-eng":0.3484544206,"data-quality":0.0646076444,"ml-security":0.1065817482}}
{"text":"The data and corresponding labels for training such a network is obtained using an optimization based procedure.","meta":{"url":"http://arxiv.org/abs/2307.16727v1"},"cats":{"new-dataset":0.1525070737,"dev-research":0.2132863361,"prompt-eng":0.4193378174,"data-quality":0.1955949954,"ml-security":0.075191845}}
{"text":"Experimental results demonstrates that our model is powerful enough to generalize even to situations with more vehicles than in the training data.","meta":{"url":"http://arxiv.org/abs/2307.16727v1"},"cats":{"new-dataset":0.0992401547,"dev-research":0.2156876625,"prompt-eng":0.3728429701,"data-quality":0.1426448256,"ml-security":0.2688585871}}
{"text":"Our method also outperforms comparable graphical neural network architectures.","meta":{"url":"http://arxiv.org/abs/2307.16727v1"},"cats":{"new-dataset":0.0724923216,"dev-research":0.2330097271,"prompt-eng":0.3523379616,"data-quality":0.2070440051,"ml-security":0.0973925474}}
{"text":"Project page which includes the code and supplementary information can be found at https://yininghase.github.io/multi-agent-control/","meta":{"url":"http://arxiv.org/abs/2307.16727v1"},"cats":{"new-dataset":0.227847501,"dev-research":0.2070097851,"prompt-eng":0.468994127,"data-quality":0.0643989425,"ml-security":0.0666059115}}
{"text":"Variable selection or importance measurement of input variables to a machine learning model has become the focus of much research.","meta":{"url":"http://arxiv.org/abs/2307.16718v1"},"cats":{"new-dataset":0.022683118,"dev-research":0.270517489,"prompt-eng":0.4573938394,"data-quality":0.1730853124,"ml-security":0.1460386788}}
{"text":"It is no longer enough to have a good model, one also must explain its decisions.","meta":{"url":"http://arxiv.org/abs/2307.16718v1"},"cats":{"new-dataset":0.0209249767,"dev-research":0.269204591,"prompt-eng":0.309156185,"data-quality":0.1113603066,"ml-security":0.1345017931}}
{"text":"This is why there are so many intelligibility algorithms available today.","meta":{"url":"http://arxiv.org/abs/2307.16718v1"},"cats":{"new-dataset":0.0501996339,"dev-research":0.3291543864,"prompt-eng":0.3916097492,"data-quality":0.2517248336,"ml-security":0.164744205}}
{"text":"Among them, Shapley value estimation algorithms are intelligibility methods based on cooperative game theory.","meta":{"url":"http://arxiv.org/abs/2307.16718v1"},"cats":{"new-dataset":0.1219300899,"dev-research":0.2506836413,"prompt-eng":0.3770049589,"data-quality":0.1357170245,"ml-security":0.1700006785}}
{"text":"In the case of the naive Bayes classifier, and to our knowledge, there is no ``analytical\" formulation of Shapley values.","meta":{"url":"http://arxiv.org/abs/2307.16718v1"},"cats":{"new-dataset":0.1451339892,"dev-research":0.1637943295,"prompt-eng":0.3473776784,"data-quality":0.1565907655,"ml-security":0.1228164368}}
{"text":"This article proposes an exact analytic expression of Shapley values in the special case of the naive Bayes Classifier.","meta":{"url":"http://arxiv.org/abs/2307.16718v1"},"cats":{"new-dataset":0.1522113208,"dev-research":0.1975466589,"prompt-eng":0.411632155,"data-quality":0.2981429826,"ml-security":0.2045507289}}
{"text":"We analytically compare this Shapley proposal, to another frequently used indicator, the Weight of Evidence (WoE) and provide an empirical comparison of our proposal with (i) the WoE and (ii) KernelShap results on real world datasets, discussing similar and dissimilar results.","meta":{"url":"http://arxiv.org/abs/2307.16718v1"},"cats":{"new-dataset":0.3501293763,"dev-research":0.1840251441,"prompt-eng":0.4034873431,"data-quality":0.2545411114,"ml-security":0.1048746668}}
{"text":"The results show that our Shapley proposal for the naive Bayes classifier provides informative results with low algorithmic complexity so that it can be used on very large datasets with extremely low computation time.","meta":{"url":"http://arxiv.org/abs/2307.16718v1"},"cats":{"new-dataset":0.3302119349,"dev-research":0.1921723874,"prompt-eng":0.3829684377,"data-quality":0.2964302942,"ml-security":0.2238013377}}
{"text":"Video Temporal Grounding (VTG), which aims to ground target clips from videos (such as consecutive intervals or disjoint shots) according to custom language queries (e.g., sentences or words), is key for video browsing on social media.","meta":{"url":"http://arxiv.org/abs/2307.16715v1"},"cats":{"new-dataset":0.0814532287,"dev-research":0.2693878352,"prompt-eng":0.3886343186,"data-quality":0.1208003048,"ml-security":0.0696077872}}
{"text":"Most methods in this direction develop taskspecific models that are trained with type-specific labels, such as moment retrieval (time interval) and highlight detection (worthiness curve), which limits their abilities to generalize to various VTG tasks and labels.","meta":{"url":"http://arxiv.org/abs/2307.16715v1"},"cats":{"new-dataset":0.0791758485,"dev-research":0.2604939488,"prompt-eng":0.5051645939,"data-quality":0.2424122433,"ml-security":0.0606651372}}
{"text":"In this paper, we propose to Unify the diverse VTG labels and tasks, dubbed UniVTG, along three directions: Firstly, we revisit a wide range of VTG labels and tasks and define a unified formulation.","meta":{"url":"http://arxiv.org/abs/2307.16715v1"},"cats":{"new-dataset":0.0947507727,"dev-research":0.3036273186,"prompt-eng":0.5187280527,"data-quality":0.2658212751,"ml-security":0.0588403472}}
{"text":"Based on this, we develop data annotation schemes to create scalable pseudo supervision.","meta":{"url":"http://arxiv.org/abs/2307.16715v1"},"cats":{"new-dataset":0.2169573277,"dev-research":0.3438979124,"prompt-eng":0.4939654955,"data-quality":0.3788352117,"ml-security":0.1312225349}}
{"text":"Secondly, we develop an effective and flexible grounding model capable of addressing each task and making full use of each label.","meta":{"url":"http://arxiv.org/abs/2307.16715v1"},"cats":{"new-dataset":0.1557619067,"dev-research":0.295220558,"prompt-eng":0.5164707206,"data-quality":0.2732343907,"ml-security":0.0626564942}}
{"text":"Lastly, thanks to the unified framework, we are able to unlock temporal grounding pretraining from large-scale diverse labels and develop stronger grounding abilities e.g., zero-shot grounding.","meta":{"url":"http://arxiv.org/abs/2307.16715v1"},"cats":{"new-dataset":0.3798630881,"dev-research":0.270055256,"prompt-eng":0.4171235716,"data-quality":0.2254667477,"ml-security":0.158337657}}
{"text":"Extensive experiments on three tasks (moment retrieval, highlight detection and video summarization) across seven datasets (QVHighlights, Charades-STA, TACoS, Ego4D, YouTube Highlights, TVSum, and QFVS) demonstrate the effectiveness and flexibility of our proposed framework.","meta":{"url":"http://arxiv.org/abs/2307.16715v1"},"cats":{"new-dataset":0.3691960815,"dev-research":0.1977245594,"prompt-eng":0.3825059931,"data-quality":0.2515071114,"ml-security":0.0379610543}}
{"text":"The codes are available at https://github.com/showlab/UniVTG.","meta":{"url":"http://arxiv.org/abs/2307.16715v1"},"cats":{"new-dataset":0.3658470565,"dev-research":0.1604974892,"prompt-eng":0.4610865879,"data-quality":0.1273236312,"ml-security":0.049751867}}
{"text":"The growth of systems complexity increases the need of automated techniques dedicated to different log analysis tasks such as Log-based Anomaly Detection (LAD).","meta":{"url":"http://arxiv.org/abs/2307.16714v1"},"cats":{"new-dataset":0.0426132869,"dev-research":0.3465107595,"prompt-eng":0.3850504474,"data-quality":0.1849568451,"ml-security":0.2764630854}}
{"text":"The latter has been widely addressed in the literature, mostly by means of different deep learning techniques.","meta":{"url":"http://arxiv.org/abs/2307.16714v1"},"cats":{"new-dataset":0.06036791,"dev-research":0.2119987284,"prompt-eng":0.320149486,"data-quality":0.1868049549,"ml-security":0.1072829709}}
{"text":"Nevertheless, the focus on deep learning techniques results in less attention being paid to traditional Machine Learning (ML) techniques, which may perform well in many cases, depending on the context and the used datasets.","meta":{"url":"http://arxiv.org/abs/2307.16714v1"},"cats":{"new-dataset":0.0328890758,"dev-research":0.2674759253,"prompt-eng":0.29984496,"data-quality":0.2260552461,"ml-security":0.2816399509}}
{"text":"Further, the evaluation of different ML techniques is mostly based on the assessment of their detection accuracy.","meta":{"url":"http://arxiv.org/abs/2307.16714v1"},"cats":{"new-dataset":0.0410680539,"dev-research":0.257067917,"prompt-eng":0.4487513254,"data-quality":0.3014075511,"ml-security":0.1100979914}}
{"text":"However, this is is not enough to decide whether or not a specific ML technique is suitable to address the LAD problem.","meta":{"url":"http://arxiv.org/abs/2307.16714v1"},"cats":{"new-dataset":0.0143926957,"dev-research":0.1984843759,"prompt-eng":0.4221355081,"data-quality":0.2673467519,"ml-security":0.1274495032}}
{"text":"Other aspects to consider include the training and prediction time as well as the sensitivity to hyperparameter tuning.","meta":{"url":"http://arxiv.org/abs/2307.16714v1"},"cats":{"new-dataset":0.0452699263,"dev-research":0.1984045122,"prompt-eng":0.445505353,"data-quality":0.1380318091,"ml-security":0.0892559072}}
{"text":"In this paper, we present a comprehensive empirical study, in which we evaluate different supervised and semi-supervised, traditional and deep ML techniques w.r.t.","meta":{"url":"http://arxiv.org/abs/2307.16714v1"},"cats":{"new-dataset":0.3401862758,"dev-research":0.2085084941,"prompt-eng":0.4070874191,"data-quality":0.3777179925,"ml-security":0.1030890259}}
{"text":"four evaluation criteria: detection accuracy, time performance, sensitivity of detection accuracy as well as time performance to hyperparameter tuning.","meta":{"url":"http://arxiv.org/abs/2307.16714v1"},"cats":{"new-dataset":0.0393577279,"dev-research":0.2006225487,"prompt-eng":0.5396603083,"data-quality":0.2748068572,"ml-security":0.0646579341}}
{"text":"The experimental results show that supervised traditional and deep ML techniques perform very closely in terms of their detection accuracy and prediction time.","meta":{"url":"http://arxiv.org/abs/2307.16714v1"},"cats":{"new-dataset":0.0699063402,"dev-research":0.2329285048,"prompt-eng":0.3880031113,"data-quality":0.3789778863,"ml-security":0.2129426773}}
{"text":"Moreover, the overall evaluation of the sensitivity of the detection accuracy of the different ML techniques to hyperparameter tuning shows that supervised traditional ML techniques are less sensitive to hyperparameter tuning than deep learning techniques.","meta":{"url":"http://arxiv.org/abs/2307.16714v1"},"cats":{"new-dataset":0.0197259328,"dev-research":0.2436862073,"prompt-eng":0.4344130714,"data-quality":0.4223173475,"ml-security":0.2844593625}}
{"text":"Further, semi-supervised techniques yield significantly worse detection accuracy than supervised techniques.","meta":{"url":"http://arxiv.org/abs/2307.16714v1"},"cats":{"new-dataset":0.0300028691,"dev-research":0.2687513615,"prompt-eng":0.4389869824,"data-quality":0.6506529083,"ml-security":0.2655095819}}
{"text":"Encrypted traffic classification is receiving widespread attention from researchers and industrial companies.","meta":{"url":"http://arxiv.org/abs/2307.16713v1"},"cats":{"new-dataset":0.0630459801,"dev-research":0.1582204201,"prompt-eng":0.3345442445,"data-quality":0.2478283062,"ml-security":0.5730648682}}
{"text":"However, the existing methods only extract flow-level features, failing to handle short flows because of unreliable statistical properties, or treat the header and payload equally, failing to mine the potential correlation between bytes.","meta":{"url":"http://arxiv.org/abs/2307.16713v1"},"cats":{"new-dataset":0.0832376811,"dev-research":0.2491580015,"prompt-eng":0.4150706793,"data-quality":0.2384432183,"ml-security":0.1120271433}}
{"text":"Therefore, in this paper, we propose a byte-level traffic graph construction approach based on point-wise mutual information (PMI), and a model named Temporal Fusion Encoder using Graph Neural Networks (TFE-GNN) for feature extraction.","meta":{"url":"http://arxiv.org/abs/2307.16713v1"},"cats":{"new-dataset":0.2043538424,"dev-research":0.2552850681,"prompt-eng":0.3069626048,"data-quality":0.1508023956,"ml-security":0.1467811274}}
{"text":"In particular, we design a dual embedding layer, a GNN-based traffic graph encoder as well as a cross-gated feature fusion mechanism, which can first embed the header and payload bytes separately and then fuses them together to obtain a stronger feature representation.","meta":{"url":"http://arxiv.org/abs/2307.16713v1"},"cats":{"new-dataset":0.138181847,"dev-research":0.2651687353,"prompt-eng":0.3353817207,"data-quality":0.1685573513,"ml-security":0.2300631292}}
{"text":"The experimental results on two real datasets demonstrate that TFE-GNN outperforms multiple state-of-the-art methods in fine-grained encrypted traffic classification tasks.","meta":{"url":"http://arxiv.org/abs/2307.16713v1"},"cats":{"new-dataset":0.2199606429,"dev-research":0.1716068793,"prompt-eng":0.3193503313,"data-quality":0.2496117846,"ml-security":0.4806767415}}
{"text":"Navigation of terrestrial robots is typically addressed either with localization and mapping (SLAM) followed by classical planning on the dynamically created maps, or by machine learning (ML), often through end-to-end training with reinforcement learning (RL) or imitation learning (IL).","meta":{"url":"http://arxiv.org/abs/2307.16710v1"},"cats":{"new-dataset":0.1118581415,"dev-research":0.2270715725,"prompt-eng":0.384690415,"data-quality":0.0829577196,"ml-security":0.0683200065}}
{"text":"Recently, modular designs have achieved promising results, and hybrid algorithms that combine ML with classical planning have been proposed.","meta":{"url":"http://arxiv.org/abs/2307.16710v1"},"cats":{"new-dataset":0.0836930926,"dev-research":0.2532910254,"prompt-eng":0.4259447562,"data-quality":0.0432057925,"ml-security":0.0506504757}}
{"text":"Existing methods implement these combinations with hand-crafted functions, which cannot fully exploit the complementary nature of the policies and the complex regularities between scene structure and planning performance.","meta":{"url":"http://arxiv.org/abs/2307.16710v1"},"cats":{"new-dataset":0.2066081843,"dev-research":0.2481645649,"prompt-eng":0.4097226355,"data-quality":0.0537051845,"ml-security":0.0472161607}}
{"text":"Our work builds on the hypothesis that the strengths and weaknesses of neural planners and classical planners follow some regularities, which can be learned from training data, in particular from interactions.","meta":{"url":"http://arxiv.org/abs/2307.16710v1"},"cats":{"new-dataset":0.1479987657,"dev-research":0.3242191034,"prompt-eng":0.3930340648,"data-quality":0.1205818231,"ml-security":0.1952944231}}
{"text":"This is grounded on the assumption that, both, trained planners and the mapping algorithms underlying classical planning are subject to failure cases depending on the semantics of the scene and that this dependence is learnable: for instance, certain areas, objects or scene structures can be reconstructed easier than others.","meta":{"url":"http://arxiv.org/abs/2307.16710v1"},"cats":{"new-dataset":0.0445694222,"dev-research":0.3423560801,"prompt-eng":0.3605741245,"data-quality":0.2005765575,"ml-security":0.1685974574}}
{"text":"We propose a hierarchical method composed of a high-level planner dynamically switching between a classical and a neural planner.","meta":{"url":"http://arxiv.org/abs/2307.16710v1"},"cats":{"new-dataset":0.0602955692,"dev-research":0.3143812975,"prompt-eng":0.4342387886,"data-quality":0.0604994733,"ml-security":0.0514908215}}
{"text":"We fully train all neural policies in simulation and evaluate the method in both simulation and real experiments with a LoCoBot robot, showing significant gains in performance, in particular in the real environment.","meta":{"url":"http://arxiv.org/abs/2307.16710v1"},"cats":{"new-dataset":0.20167127,"dev-research":0.2096235055,"prompt-eng":0.380176123,"data-quality":0.0987045115,"ml-security":0.14645522}}
{"text":"We also qualitatively conjecture on the nature of data regularities exploited by the high-level planner.","meta":{"url":"http://arxiv.org/abs/2307.16710v1"},"cats":{"new-dataset":0.1326336898,"dev-research":0.2447923502,"prompt-eng":0.3719403347,"data-quality":0.1164938356,"ml-security":0.1784100917}}
{"text":"Phonetic information and linguistic knowledge are an essential component of a Text-to-speech (TTS) front-end.","meta":{"url":"http://arxiv.org/abs/2307.16709v1"},"cats":{"new-dataset":0.1803434542,"dev-research":0.2432512469,"prompt-eng":0.3899837574,"data-quality":0.1646049767,"ml-security":0.0793886462}}
{"text":"Given a language, a lexicon can be collected offline and Grapheme-to-Phoneme (G2P) relationships are usually modeled in order to predict the pronunciation for out-of-vocabulary (OOV) words.","meta":{"url":"http://arxiv.org/abs/2307.16709v1"},"cats":{"new-dataset":0.38953343,"dev-research":0.1893391019,"prompt-eng":0.3846903874,"data-quality":0.2219564386,"ml-security":0.0731294107}}
{"text":"Additionally, post-lexical phonology, often defined in the form of rule-based systems, is used to correct pronunciation within or between words.","meta":{"url":"http://arxiv.org/abs/2307.16709v1"},"cats":{"new-dataset":0.0273314609,"dev-research":0.3393969506,"prompt-eng":0.4050254079,"data-quality":0.3071285981,"ml-security":0.0643681947}}
{"text":"In this work we showcase a multilingual unified front-end system that addresses any pronunciation related task, typically handled by separate modules.","meta":{"url":"http://arxiv.org/abs/2307.16709v1"},"cats":{"new-dataset":0.5395564556,"dev-research":0.2750256885,"prompt-eng":0.4642198551,"data-quality":0.2503167431,"ml-security":0.0819445506}}
{"text":"We evaluate the proposed model on G2P conversion and other language-specific challenges, such as homograph and polyphones disambiguation, post-lexical rules and implicit diacritization.","meta":{"url":"http://arxiv.org/abs/2307.16709v1"},"cats":{"new-dataset":0.1307911658,"dev-research":0.256846418,"prompt-eng":0.4145269344,"data-quality":0.3153575728,"ml-security":0.0655272241}}
{"text":"We find that the multilingual model is competitive across languages and tasks, however, some trade-offs exists when compared to equivalent monolingual solutions.","meta":{"url":"http://arxiv.org/abs/2307.16709v1"},"cats":{"new-dataset":0.0839718201,"dev-research":0.2631963084,"prompt-eng":0.377906436,"data-quality":0.1808827628,"ml-security":0.0721695174}}
{"text":"We present a method for image-guided exploration for mobile robotic systems.","meta":{"url":"http://arxiv.org/abs/2307.16707v1"},"cats":{"new-dataset":0.049287578,"dev-research":0.2137086517,"prompt-eng":0.4824429031,"data-quality":0.1015664164,"ml-security":0.050842649}}
{"text":"Our approach extends ergodic exploration methods, a recent exploration approach that prioritizes complete coverage of a space, with the use of a learned image classifier that automatically detects objects and updates an information map to guide further exploration and localization of objects.","meta":{"url":"http://arxiv.org/abs/2307.16707v1"},"cats":{"new-dataset":0.2934682678,"dev-research":0.1939533656,"prompt-eng":0.4131689802,"data-quality":0.2147839025,"ml-security":0.1313515255}}
{"text":"Additionally, to improve outcomes of the information collected by our robot's visual sensor, we present a decomposition of the ergodic optimization problem as bi-level coarse and fine solvers, which act respectively on the robot's body and the robot's visual sensor.   ","meta":{"url":"http://arxiv.org/abs/2307.16707v1"},"cats":{"new-dataset":0.1666592658,"dev-research":0.2166231758,"prompt-eng":0.4057934373,"data-quality":0.1198539227,"ml-security":0.0760944355}}
{"text":"Our approach is applied to geological survey and localization of rock formations for Mars rovers, with real images from Mars rovers used to train the image classifier.","meta":{"url":"http://arxiv.org/abs/2307.16707v1"},"cats":{"new-dataset":0.2701920362,"dev-research":0.2107485244,"prompt-eng":0.3961842539,"data-quality":0.2276063514,"ml-security":0.0882003043}}
{"text":"Results demonstrate 1) improved localization of rock formations compared to naive approaches while 2) minimizing the path length of the exploration through the bi-level exploration.","meta":{"url":"http://arxiv.org/abs/2307.16707v1"},"cats":{"new-dataset":0.0809974525,"dev-research":0.2756541717,"prompt-eng":0.3980565819,"data-quality":0.1229359325,"ml-security":0.0601647363}}
{"text":"The Lookahead optimizer improves the training stability of deep neural networks by having a set of fast weights that \"look ahead\" to guide the descent direction.","meta":{"url":"http://arxiv.org/abs/2307.16704v1"},"cats":{"new-dataset":0.0215270006,"dev-research":0.2547275436,"prompt-eng":0.3170540183,"data-quality":0.1004270381,"ml-security":0.1287187063}}
{"text":"Here, we combine this idea with sharpness-aware minimization (SAM) to stabilize its multi-step variant and improve the loss-sharpness trade-off.","meta":{"url":"http://arxiv.org/abs/2307.16704v1"},"cats":{"new-dataset":0.0448950506,"dev-research":0.2889680325,"prompt-eng":0.4037520659,"data-quality":0.3055228374,"ml-security":0.105065368}}
{"text":"We propose Lookbehind, which computes $k$ gradient ascent steps (\"looking behind\") at each iteration and combine the gradients to bias the descent step toward flatter minima.","meta":{"url":"http://arxiv.org/abs/2307.16704v1"},"cats":{"new-dataset":0.0713211259,"dev-research":0.1708271109,"prompt-eng":0.3698979125,"data-quality":0.1536747029,"ml-security":0.1654275481}}
{"text":"We apply Lookbehind on top of two popular sharpness-aware training methods -- SAM and adaptive SAM (ASAM) -- and show that our approach leads to a myriad of benefits across a variety of tasks and training regimes.","meta":{"url":"http://arxiv.org/abs/2307.16704v1"},"cats":{"new-dataset":0.0731496478,"dev-research":0.2966001342,"prompt-eng":0.4255804905,"data-quality":0.2700779697,"ml-security":0.0932657712}}
{"text":"Particularly, we show increased generalization performance, greater robustness against noisy weights, and higher tolerance to catastrophic forgetting in lifelong learning settings.","meta":{"url":"http://arxiv.org/abs/2307.16704v1"},"cats":{"new-dataset":0.0454015654,"dev-research":0.2764147401,"prompt-eng":0.3868614314,"data-quality":0.3323759617,"ml-security":0.3008077828}}
{"text":"We introduce and investigate forgetting 1-limited automata, which are single-tape Turing machines that, when visit a cell for the first time, replace the input symbol in it by a fixed symbol, so forgetting the original contents.","meta":{"url":"http://arxiv.org/abs/2307.16700v1"},"cats":{"new-dataset":0.1964541588,"dev-research":0.2589704175,"prompt-eng":0.4299528252,"data-quality":0.2250130414,"ml-security":0.1739477256}}
{"text":"These devices have the same computational power as finite automata, namely they characterize the class of regular languages.","meta":{"url":"http://arxiv.org/abs/2307.16700v1"},"cats":{"new-dataset":0.0827846696,"dev-research":0.2267912129,"prompt-eng":0.3955333186,"data-quality":0.0929465695,"ml-security":0.0900686863}}
{"text":"We study the cost in size of the conversions of forgetting 1-limited automata, in both nondeterministic and deterministic cases, into equivalent one-way nondeterministic and deterministic automata, providing optimal bounds in terms of exponential or superpolynomial functions.","meta":{"url":"http://arxiv.org/abs/2307.16700v1"},"cats":{"new-dataset":0.1135479731,"dev-research":0.2004584577,"prompt-eng":0.4151588106,"data-quality":0.1627651195,"ml-security":0.1770388323}}
{"text":"We also discuss the size relationships with two-way finite automata.","meta":{"url":"http://arxiv.org/abs/2307.16700v1"},"cats":{"new-dataset":0.1404544786,"dev-research":0.1806277581,"prompt-eng":0.3948998176,"data-quality":0.157904764,"ml-security":0.1370371658}}
{"text":"In this respect, we prove the existence of a language for which forgetting 1-limited automata are exponentially larger than equivalent minimal deterministic two-way automata.","meta":{"url":"http://arxiv.org/abs/2307.16700v1"},"cats":{"new-dataset":0.1632753613,"dev-research":0.1861883935,"prompt-eng":0.3892107866,"data-quality":0.1742005614,"ml-security":0.198316507}}
{"text":"We tackle the task of enriching ontologies by automatically translating natural language sentences into Description Logic.","meta":{"url":"http://arxiv.org/abs/2307.16699v1"},"cats":{"new-dataset":0.0912365718,"dev-research":0.3167384317,"prompt-eng":0.450821251,"data-quality":0.1991740503,"ml-security":0.0863635477}}
{"text":"Since Large Language Models (LLMs) are the best tools for translations, we fine-tuned a GPT-3 model to convert Natural Language sentences into OWL Functional Syntax.","meta":{"url":"http://arxiv.org/abs/2307.16699v1"},"cats":{"new-dataset":0.3136940866,"dev-research":0.229617064,"prompt-eng":0.3941962154,"data-quality":0.1894704909,"ml-security":0.0505576396}}
{"text":"We employ objective and concise examples to fine-tune the model regarding: instances, class subsumption, domain and range of relations, object properties relationships, disjoint classes, complements, cardinality restrictions.","meta":{"url":"http://arxiv.org/abs/2307.16699v1"},"cats":{"new-dataset":0.2770777082,"dev-research":0.2294645664,"prompt-eng":0.4129907098,"data-quality":0.2494559992,"ml-security":0.1113095665}}
{"text":"The resulted axioms are used to enrich an ontology, in a human supervised manner.","meta":{"url":"http://arxiv.org/abs/2307.16699v1"},"cats":{"new-dataset":0.0507798327,"dev-research":0.3333130777,"prompt-eng":0.3890455625,"data-quality":0.189543687,"ml-security":0.0842246046}}
{"text":"The developed tool is publicly provided as a Protge plugin.","meta":{"url":"http://arxiv.org/abs/2307.16699v1"},"cats":{"new-dataset":0.2363084474,"dev-research":0.3112362705,"prompt-eng":0.4751263649,"data-quality":0.1197771965,"ml-security":0.0410037339}}
{"text":"As a way of addressing increasingly sophisticated problems, software professionals face the constant challenge of seeking improvement.","meta":{"url":"http://arxiv.org/abs/2307.16696v1"},"cats":{"new-dataset":0.0448797372,"dev-research":0.6127175034,"prompt-eng":0.4313805533,"data-quality":0.3062746215,"ml-security":0.1721282458}}
{"text":"However, for these individuals to enhance their skills, their process of studying and training must involve feedback that is both immediate and accurate.","meta":{"url":"http://arxiv.org/abs/2307.16696v1"},"cats":{"new-dataset":0.0403599672,"dev-research":0.4082196126,"prompt-eng":0.4621224808,"data-quality":0.2258967694,"ml-security":0.0951024071}}
{"text":"In the context of software companies, where the scale of professionals undergoing training is large, but the number of qualified professionals available for providing corrections is small, delivering effective feedback becomes even more challenging.","meta":{"url":"http://arxiv.org/abs/2307.16696v1"},"cats":{"new-dataset":0.0505925507,"dev-research":0.5094010714,"prompt-eng":0.4223136751,"data-quality":0.4392761527,"ml-security":0.2278626417}}
{"text":"To circumvent this challenge, this work presents an exploration of using Large Language Models (LLMs) to support the correction process of open-ended questions in technical training.   ","meta":{"url":"http://arxiv.org/abs/2307.16696v1"},"cats":{"new-dataset":0.1996538382,"dev-research":0.2548466784,"prompt-eng":0.4814903448,"data-quality":0.4192760965,"ml-security":0.1161028271}}
{"text":"In this study, we utilized ChatGPT to correct open-ended questions answered by 42 industry professionals on two topics.","meta":{"url":"http://arxiv.org/abs/2307.16696v1"},"cats":{"new-dataset":0.2190998544,"dev-research":0.4272501595,"prompt-eng":0.4298219747,"data-quality":0.2420300722,"ml-security":0.0586104326}}
{"text":"Evaluating the corrections and feedback provided by ChatGPT, we observed that it is capable of identifying semantic details in responses that other metrics cannot observe.","meta":{"url":"http://arxiv.org/abs/2307.16696v1"},"cats":{"new-dataset":0.1528847801,"dev-research":0.3308724557,"prompt-eng":0.4628319363,"data-quality":0.4070434251,"ml-security":0.0833354321}}
{"text":"Furthermore, we noticed that, in general, subject matter experts tended to agree with the corrections and feedback given by ChatGPT.","meta":{"url":"http://arxiv.org/abs/2307.16696v1"},"cats":{"new-dataset":0.0445003874,"dev-research":0.3770364098,"prompt-eng":0.3976212152,"data-quality":0.3147178161,"ml-security":0.062545468}}
{"text":"Data uncertainties, such as sensor noise or occlusions, can introduce irreducible ambiguities in images, which result in varying, yet plausible, semantic hypotheses.","meta":{"url":"http://arxiv.org/abs/2307.16694v1"},"cats":{"new-dataset":0.0846282037,"dev-research":0.2665405341,"prompt-eng":0.390604476,"data-quality":0.3541689153,"ml-security":0.1516685403}}
{"text":"In Machine Learning, this ambiguity is commonly referred to as aleatoric uncertainty.","meta":{"url":"http://arxiv.org/abs/2307.16694v1"},"cats":{"new-dataset":0.0085334211,"dev-research":0.2878731688,"prompt-eng":0.3695970913,"data-quality":0.3377799641,"ml-security":0.1694487977}}
{"text":"Latent density models can be utilized to address this problem in image segmentation.","meta":{"url":"http://arxiv.org/abs/2307.16694v1"},"cats":{"new-dataset":0.1161298813,"dev-research":0.1306755751,"prompt-eng":0.4102511412,"data-quality":0.2324481523,"ml-security":0.0635487302}}
{"text":"The most popular approach is the Probabilistic U-Net (PU-Net), which uses latent Normal densities to optimize the conditional data log-likelihood Evidence Lower Bound.","meta":{"url":"http://arxiv.org/abs/2307.16694v1"},"cats":{"new-dataset":0.1702107705,"dev-research":0.1549017229,"prompt-eng":0.4489301857,"data-quality":0.1793399313,"ml-security":0.1017191133}}
{"text":"In this work, we demonstrate that the PU- Net latent space is severely inhomogenous.","meta":{"url":"http://arxiv.org/abs/2307.16694v1"},"cats":{"new-dataset":0.075451449,"dev-research":0.124597882,"prompt-eng":0.3381690414,"data-quality":0.2296988656,"ml-security":0.1338550442}}
{"text":"As a result, the effectiveness of gradient descent is inhibited and the model becomes extremely sensitive to the localization of the latent space samples, resulting in defective predictions.","meta":{"url":"http://arxiv.org/abs/2307.16694v1"},"cats":{"new-dataset":0.007416638,"dev-research":0.2376322361,"prompt-eng":0.3492965048,"data-quality":0.3656629401,"ml-security":0.2872407431}}
{"text":"To address this, we present the Sinkhorn PU-Net (SPU-Net), which uses the Sinkhorn Divergence to promote homogeneity across all latent dimensions, effectively improving gradient-descent updates and model robustness.","meta":{"url":"http://arxiv.org/abs/2307.16694v1"},"cats":{"new-dataset":0.1844841444,"dev-research":0.193942984,"prompt-eng":0.3154582914,"data-quality":0.157574729,"ml-security":0.187345716}}
{"text":"Our results show that by applying this on public datasets of various clinical segmentation problems, the SPU-Net receives up to 11% performance gains compared against preceding latent variable models for probabilistic segmentation on the Hungarian-Matched metric.","meta":{"url":"http://arxiv.org/abs/2307.16694v1"},"cats":{"new-dataset":0.3853926836,"dev-research":0.1660552201,"prompt-eng":0.4009878187,"data-quality":0.1981326718,"ml-security":0.0637758365}}
{"text":"The results indicate that by encouraging a homogeneous latent space, one can significantly improve latent density modeling for medical image segmentation.","meta":{"url":"http://arxiv.org/abs/2307.16694v1"},"cats":{"new-dataset":0.0547753705,"dev-research":0.1666850276,"prompt-eng":0.3574550088,"data-quality":0.1774873283,"ml-security":0.0636758576}}
{"text":"The log-structured merge tree (LSM-tree) is widely employed to build key-value (KV) stores.","meta":{"url":"http://arxiv.org/abs/2307.16693v1"},"cats":{"new-dataset":0.2734231199,"dev-research":0.2695160281,"prompt-eng":0.4489555178,"data-quality":0.1490677467,"ml-security":0.0498711739}}
{"text":"LSM-tree organizes multiple levels in memory and on disk.","meta":{"url":"http://arxiv.org/abs/2307.16693v1"},"cats":{"new-dataset":0.149023258,"dev-research":0.1921406377,"prompt-eng":0.4189546523,"data-quality":0.085336786,"ml-security":0.0358935263}}
{"text":"The compaction of LSM-tree, which is used to redeploy KV pairs between on-disk levels in the form of SST files, severely stalls its foreground service.","meta":{"url":"http://arxiv.org/abs/2307.16693v1"},"cats":{"new-dataset":0.2203578349,"dev-research":0.1960555576,"prompt-eng":0.4069106704,"data-quality":0.1736776077,"ml-security":0.0924577198}}
{"text":"We overhaul and analyze the procedure of compaction.","meta":{"url":"http://arxiv.org/abs/2307.16693v1"},"cats":{"new-dataset":0.1221688328,"dev-research":0.2808043656,"prompt-eng":0.4166984482,"data-quality":0.1401201339,"ml-security":0.0406503274}}
{"text":"Writing and persisting files with fsyncs for compacted KV pairs are time-consuming and, more important, occur synchronously on the critical path of compaction.","meta":{"url":"http://arxiv.org/abs/2307.16693v1"},"cats":{"new-dataset":0.4764488501,"dev-research":0.2897688115,"prompt-eng":0.3950930574,"data-quality":0.135693323,"ml-security":0.0690649623}}
{"text":"The user-space compaction thread of LSM-tree stays waiting for completion signals from a kernel-space thread that is processing file write and fsync I/Os.   ","meta":{"url":"http://arxiv.org/abs/2307.16693v1"},"cats":{"new-dataset":0.089990745,"dev-research":0.2140161247,"prompt-eng":0.4027958018,"data-quality":0.1265415545,"ml-security":0.0637197245}}
{"text":"We accordingly design a new LSM-tree variant named AisLSM with an asynchronous I/O model.","meta":{"url":"http://arxiv.org/abs/2307.16693v1"},"cats":{"new-dataset":0.1799405234,"dev-research":0.1776013952,"prompt-eng":0.4587249085,"data-quality":0.091242219,"ml-security":0.0576156518}}
{"text":"In short, AisLSM conducts asynchronous writes and fsyncs for SST files generated in a compaction and overlaps CPU computations with disk I/Os for consecutive compactions.","meta":{"url":"http://arxiv.org/abs/2307.16693v1"},"cats":{"new-dataset":0.1883117108,"dev-research":0.2991564202,"prompt-eng":0.3970145647,"data-quality":0.0738997086,"ml-security":0.0714505311}}
{"text":"AisLSM tracks the generation dependency between input and output files for each compaction and utilizes a deferred check-up strategy to ensure the durability of compacted KV pairs.","meta":{"url":"http://arxiv.org/abs/2307.16693v1"},"cats":{"new-dataset":0.2836807224,"dev-research":0.3595942273,"prompt-eng":0.4722927984,"data-quality":0.1487659033,"ml-security":0.0649917054}}
{"text":"We prototype AisLSM with RocksDB and io_uring.","meta":{"url":"http://arxiv.org/abs/2307.16693v1"},"cats":{"new-dataset":0.3503069201,"dev-research":0.2090232019,"prompt-eng":0.4316836123,"data-quality":0.1080718466,"ml-security":0.0510944248}}
{"text":"Experiments show that AisLSM boosts the performance of RocksDB by up to 2.14x, without losing data accessibility and consistency.","meta":{"url":"http://arxiv.org/abs/2307.16693v1"},"cats":{"new-dataset":0.1349486084,"dev-research":0.303519005,"prompt-eng":0.4076745794,"data-quality":0.1484110674,"ml-security":0.0720505713}}
{"text":"It also outperforms state-of-the-art LSM-tree variants with significantly higher throughput and lower tail latency.","meta":{"url":"http://arxiv.org/abs/2307.16693v1"},"cats":{"new-dataset":0.0916529442,"dev-research":0.1838834524,"prompt-eng":0.4329645086,"data-quality":0.0952021052,"ml-security":0.0314160835}}
{"text":"The ability to handle miscommunication is crucial to robust and faithful conversational AI.","meta":{"url":"http://arxiv.org/abs/2307.16689v1"},"cats":{"new-dataset":0.0482050568,"dev-research":0.3664721723,"prompt-eng":0.3575234828,"data-quality":0.2845030111,"ml-security":0.2136193866}}
{"text":"People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair.","meta":{"url":"http://arxiv.org/abs/2307.16689v1"},"cats":{"new-dataset":0.0249816643,"dev-research":0.4803809267,"prompt-eng":0.44302295,"data-quality":0.3785183424,"ml-security":0.1867468944}}
{"text":"One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee's erroneous response.","meta":{"url":"http://arxiv.org/abs/2307.16689v1"},"cats":{"new-dataset":0.0721210979,"dev-research":0.3467415418,"prompt-eng":0.4371742239,"data-quality":0.418569542,"ml-security":0.095047676}}
{"text":"Here, we collect and publicly release Repair-QA, the first large dataset of TPRs in a conversational question answering (QA) setting.","meta":{"url":"http://arxiv.org/abs/2307.16689v1"},"cats":{"new-dataset":0.8095249546,"dev-research":0.269025485,"prompt-eng":0.4208602966,"data-quality":0.3012603878,"ml-security":0.0921753801}}
{"text":"The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs.","meta":{"url":"http://arxiv.org/abs/2307.16689v1"},"cats":{"new-dataset":0.5896455159,"dev-research":0.2687523559,"prompt-eng":0.4514028602,"data-quality":0.1724953846,"ml-security":0.0736577468}}
{"text":"We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs.","meta":{"url":"http://arxiv.org/abs/2307.16689v1"},"cats":{"new-dataset":0.1757029041,"dev-research":0.2815495285,"prompt-eng":0.5020461734,"data-quality":0.1591884687,"ml-security":0.1009479016}}
{"text":"For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI's GPT-3 LLMs.","meta":{"url":"http://arxiv.org/abs/2307.16689v1"},"cats":{"new-dataset":0.1872095071,"dev-research":0.283182198,"prompt-eng":0.5117638373,"data-quality":0.1334528728,"ml-security":0.0882558371}}
{"text":"Additionally, we extrinsically evaluate the LLMs' TPR processing capabilities in the downstream conversational QA task.","meta":{"url":"http://arxiv.org/abs/2307.16689v1"},"cats":{"new-dataset":0.0863072519,"dev-research":0.2253483115,"prompt-eng":0.4800254639,"data-quality":0.142635488,"ml-security":0.0588076931}}
{"text":"The results indicate poor out-of-the-box performance on TPR's by the GPT-3 models, which then significantly improves when exposed to Repair-QA.","meta":{"url":"http://arxiv.org/abs/2307.16689v1"},"cats":{"new-dataset":0.0893672775,"dev-research":0.2723809416,"prompt-eng":0.4327974202,"data-quality":0.1821653458,"ml-security":0.0558915911}}
{"text":"Denoising diffusion probabilistic models that were initially proposed for realistic image generation have recently shown success in various perception tasks (e.g., object detection and image segmentation) and are increasingly gaining attention in computer vision.","meta":{"url":"http://arxiv.org/abs/2307.16687v1"},"cats":{"new-dataset":0.0645244843,"dev-research":0.1905894183,"prompt-eng":0.3814465578,"data-quality":0.1867644268,"ml-security":0.1077454421}}
{"text":"However, extending such models to multi-frame human pose estimation is non-trivial due to the presence of the additional temporal dimension in videos.","meta":{"url":"http://arxiv.org/abs/2307.16687v1"},"cats":{"new-dataset":0.2852608565,"dev-research":0.1466121356,"prompt-eng":0.311442217,"data-quality":0.1001459839,"ml-security":0.1086555033}}
{"text":"More importantly, learning representations that focus on keypoint regions is crucial for accurate localization of human joints.","meta":{"url":"http://arxiv.org/abs/2307.16687v1"},"cats":{"new-dataset":0.1769440671,"dev-research":0.2420475662,"prompt-eng":0.337705273,"data-quality":0.126776082,"ml-security":0.0677819027}}
{"text":"Nevertheless, the adaptation of the diffusion-based methods remains unclear on how to achieve such objective.","meta":{"url":"http://arxiv.org/abs/2307.16687v1"},"cats":{"new-dataset":0.0057645401,"dev-research":0.1801059224,"prompt-eng":0.3576024108,"data-quality":0.1674950292,"ml-security":0.0789834589}}
{"text":"In this paper, we present DiffPose, a novel diffusion architecture that formulates video-based human pose estimation as a conditional heatmap generation problem.","meta":{"url":"http://arxiv.org/abs/2307.16687v1"},"cats":{"new-dataset":0.4851473446,"dev-research":0.1937477167,"prompt-eng":0.3505286298,"data-quality":0.0756428146,"ml-security":0.0760594092}}
{"text":"First, to better leverage temporal information, we propose SpatioTemporal Representation Learner which aggregates visual evidences across frames and uses the resulting features in each denoising step as a condition.","meta":{"url":"http://arxiv.org/abs/2307.16687v1"},"cats":{"new-dataset":0.4276422077,"dev-research":0.2817037737,"prompt-eng":0.3222371142,"data-quality":0.1941133328,"ml-security":0.0907399691}}
{"text":"In addition, we present a mechanism called Lookup-based MultiScale Feature Interaction that determines the correlations between local joints and global contexts across multiple scales.","meta":{"url":"http://arxiv.org/abs/2307.16687v1"},"cats":{"new-dataset":0.083492377,"dev-research":0.2955457229,"prompt-eng":0.4290489106,"data-quality":0.1704772906,"ml-security":0.0655464855}}
{"text":"This mechanism generates delicate representations that focus on keypoint regions.","meta":{"url":"http://arxiv.org/abs/2307.16687v1"},"cats":{"new-dataset":0.0185877909,"dev-research":0.2986523833,"prompt-eng":0.4093300411,"data-quality":0.1155926615,"ml-security":0.1353127656}}
{"text":"Altogether, by extending diffusion models, we show two unique characteristics from DiffPose on pose estimation task: (i) the ability to combine multiple sets of pose estimates to improve prediction accuracy, particularly for challenging joints, and (ii) the ability to adjust the number of iterative steps for feature refinement without retraining the model.","meta":{"url":"http://arxiv.org/abs/2307.16687v1"},"cats":{"new-dataset":0.3426747411,"dev-research":0.202873129,"prompt-eng":0.3301573952,"data-quality":0.1319541724,"ml-security":0.1122871082}}
{"text":"DiffPose sets new state-of-the-art results on three benchmarks: PoseTrack2017, PoseTrack2018, and PoseTrack21.","meta":{"url":"http://arxiv.org/abs/2307.16687v1"},"cats":{"new-dataset":0.5816148768,"dev-research":0.2374226075,"prompt-eng":0.344562244,"data-quality":0.1461969153,"ml-security":0.0558561841}}
{"text":"Image captioning is conventionally formulated as the task of generating captions for images that match the distribution of reference image-caption pairs.","meta":{"url":"http://arxiv.org/abs/2307.16686v1"},"cats":{"new-dataset":0.1466308083,"dev-research":0.2400895462,"prompt-eng":0.4307134126,"data-quality":0.30064213,"ml-security":0.074942986}}
{"text":"However, reference captions in standard captioning datasets are short and may not uniquely identify the images they describe.","meta":{"url":"http://arxiv.org/abs/2307.16686v1"},"cats":{"new-dataset":0.2406651488,"dev-research":0.1911810258,"prompt-eng":0.3231821499,"data-quality":0.4194039962,"ml-security":0.1169697628}}
{"text":"These problems are further exacerbated when models are trained directly on image-alt text pairs collected from the internet.","meta":{"url":"http://arxiv.org/abs/2307.16686v1"},"cats":{"new-dataset":0.0765149444,"dev-research":0.2533934931,"prompt-eng":0.3849592878,"data-quality":0.4791032403,"ml-security":0.2343001882}}
{"text":"In this work, we show that it is possible to generate more specific captions with minimal changes to the training process.","meta":{"url":"http://arxiv.org/abs/2307.16686v1"},"cats":{"new-dataset":0.3935821059,"dev-research":0.2400300166,"prompt-eng":0.432545391,"data-quality":0.3383618806,"ml-security":0.0838157688}}
{"text":"We implement classifier-free guidance for an autoregressive captioning model by fine-tuning it to estimate both conditional and unconditional distributions over captions.","meta":{"url":"http://arxiv.org/abs/2307.16686v1"},"cats":{"new-dataset":0.1786563242,"dev-research":0.211221212,"prompt-eng":0.4620651053,"data-quality":0.3927561783,"ml-security":0.0749046183}}
{"text":"The guidance scale applied at decoding controls a trade-off between maximizing $p(\\mathrm{caption}|\\mathrm{image})$ and $p(\\mathrm{image}|\\mathrm{caption})$. Compared to standard greedy decoding, decoding with a guidance scale of 2 substantially improves reference-free metrics such as CLIPScore (0.808 vs. 0.775) and caption$\\to$image retrieval performance in the CLIP embedding space (recall@1 44.6% vs. 26.5%), but worsens standard reference-based captioning metrics (e.g., CIDEr 78.6 vs 126.1).","meta":{"url":"http://arxiv.org/abs/2307.16686v1"},"cats":{"new-dataset":0.0614488165,"dev-research":0.2136733401,"prompt-eng":0.4082460154,"data-quality":0.2807746814,"ml-security":0.0786596591}}
{"text":"We further explore the use of language models to guide the decoding process, obtaining small improvements over the Pareto frontier of reference-free vs. reference-based captioning metrics that arises from classifier-free guidance, and substantially improving the quality of captions generated from a model trained only on minimally curated web data.","meta":{"url":"http://arxiv.org/abs/2307.16686v1"},"cats":{"new-dataset":0.2604393797,"dev-research":0.2430169303,"prompt-eng":0.4122600737,"data-quality":0.3742774112,"ml-security":0.0967755035}}
{"text":"Responsibility anticipation is the process of determining if the actions of an individual agent may cause it to be responsible for a particular outcome.","meta":{"url":"http://arxiv.org/abs/2307.16685v1"},"cats":{"new-dataset":0.0427860012,"dev-research":0.2910601528,"prompt-eng":0.457440538,"data-quality":0.1024241378,"ml-security":0.1569291299}}
{"text":"This can be used in a multi-agent planning setting to allow agents to anticipate responsibility in the plans they consider.","meta":{"url":"http://arxiv.org/abs/2307.16685v1"},"cats":{"new-dataset":0.0917001973,"dev-research":0.3247444509,"prompt-eng":0.44520006,"data-quality":0.0682409981,"ml-security":0.0944351781}}
{"text":"The planning setting in this paper includes partial information regarding the initial state and considers formulas in linear temporal logic as positive or negative outcomes to be attained or avoided.","meta":{"url":"http://arxiv.org/abs/2307.16685v1"},"cats":{"new-dataset":0.0954282525,"dev-research":0.3663414619,"prompt-eng":0.4435620294,"data-quality":0.0588305512,"ml-security":0.0537329151}}
{"text":"We firstly define attribution for notions of active, passive and contributive responsibility, and consider their agentive variants.","meta":{"url":"http://arxiv.org/abs/2307.16685v1"},"cats":{"new-dataset":0.1088214853,"dev-research":0.3088169257,"prompt-eng":0.4007990466,"data-quality":0.1700973717,"ml-security":0.1950584183}}
{"text":"We then use these to define the notion of responsibility anticipation.","meta":{"url":"http://arxiv.org/abs/2307.16685v1"},"cats":{"new-dataset":0.0567815763,"dev-research":0.2830081228,"prompt-eng":0.4299117006,"data-quality":0.1523224746,"ml-security":0.1362640266}}
{"text":"We prove that our notions of anticipated responsibility can be used to coordinate agents in a planning setting and give complexity results for our model, discussing equivalence with classical planning.","meta":{"url":"http://arxiv.org/abs/2307.16685v1"},"cats":{"new-dataset":0.1845602027,"dev-research":0.2389380191,"prompt-eng":0.4235763418,"data-quality":0.0698782506,"ml-security":0.1180911831}}
{"text":"We also present an outline for solving some of our attribution and anticipation problems using PDDL solvers.","meta":{"url":"http://arxiv.org/abs/2307.16685v1"},"cats":{"new-dataset":0.2491803864,"dev-research":0.280051094,"prompt-eng":0.4821099167,"data-quality":0.1790790701,"ml-security":0.0757526552}}
{"text":"Diffusion models and large language models have emerged as leading-edge generative models and have sparked a revolutionary impact on various aspects of human life.","meta":{"url":"http://arxiv.org/abs/2307.16680v1"},"cats":{"new-dataset":0.0354437655,"dev-research":0.1948259064,"prompt-eng":0.3189629054,"data-quality":0.1186530095,"ml-security":0.109263556}}
{"text":"However, the practical implementation of these models has also exposed inherent risks, highlighting their dual nature and raising concerns regarding their trustworthiness.","meta":{"url":"http://arxiv.org/abs/2307.16680v1"},"cats":{"new-dataset":0.0265377374,"dev-research":0.2701860037,"prompt-eng":0.379884023,"data-quality":0.1559367942,"ml-security":0.414364012}}
{"text":"Despite the abundance of literature on this subject, a comprehensive survey specifically delving into the intersection of large-scale generative models and their trustworthiness remains largely absent.","meta":{"url":"http://arxiv.org/abs/2307.16680v1"},"cats":{"new-dataset":0.0943799878,"dev-research":0.1969931454,"prompt-eng":0.4160310738,"data-quality":0.2273757576,"ml-security":0.1468007891}}
{"text":"To bridge this gap, This paper investigates both the long-standing and emerging threats associated with these models across four fundamental dimensions: privacy, security, fairness, and responsibility.","meta":{"url":"http://arxiv.org/abs/2307.16680v1"},"cats":{"new-dataset":0.0686942404,"dev-research":0.2106200429,"prompt-eng":0.3279880809,"data-quality":0.1865233966,"ml-security":0.7668930655}}
{"text":"In this way, we construct an extensive map outlining the trustworthiness of these models, while also providing practical recommendations and identifying future directions.","meta":{"url":"http://arxiv.org/abs/2307.16680v1"},"cats":{"new-dataset":0.1403897479,"dev-research":0.2368264069,"prompt-eng":0.4700399084,"data-quality":0.2134221153,"ml-security":0.1923957102}}
{"text":"These efforts are crucial for promoting the trustworthy deployment of these models, ultimately benefiting society as a whole.","meta":{"url":"http://arxiv.org/abs/2307.16680v1"},"cats":{"new-dataset":0.0347828563,"dev-research":0.2230719347,"prompt-eng":0.3820996035,"data-quality":0.1415351136,"ml-security":0.2438192575}}
{"text":"Legged locomotion is arguably the most suited and versatile mode to deal with natural or unstructured terrains.","meta":{"url":"http://arxiv.org/abs/2307.16676v1"},"cats":{"new-dataset":0.0527462607,"dev-research":0.2450901911,"prompt-eng":0.3636418725,"data-quality":0.0485869387,"ml-security":0.0723941777}}
{"text":"Intensive research into dynamic walking and running controllers has recently yielded great advances, both in the optimal control and reinforcement learning (RL) literature.","meta":{"url":"http://arxiv.org/abs/2307.16676v1"},"cats":{"new-dataset":0.1529319196,"dev-research":0.1994051191,"prompt-eng":0.3427838574,"data-quality":0.0784481249,"ml-security":0.084772474}}
{"text":"Hopping is a challenging dynamic task involving a flight phase and has the potential to increase the traversability of legged robots.","meta":{"url":"http://arxiv.org/abs/2307.16676v1"},"cats":{"new-dataset":0.0651145471,"dev-research":0.2460122183,"prompt-eng":0.3908159841,"data-quality":0.0660606154,"ml-security":0.0647829343}}
{"text":"Model based control for hopping typically relies on accurate detection of different jump phases, such as lift-off or touch down, and using different controllers for each phase.","meta":{"url":"http://arxiv.org/abs/2307.16676v1"},"cats":{"new-dataset":0.0142774587,"dev-research":0.2794657947,"prompt-eng":0.4435686307,"data-quality":0.0688801957,"ml-security":0.0706380321}}
{"text":"In this paper, we present a end-to-end RL based torque controller that learns to implicitly detect the relevant jump phases, removing the need to provide manual heuristics for state detection.","meta":{"url":"http://arxiv.org/abs/2307.16676v1"},"cats":{"new-dataset":0.1156611076,"dev-research":0.2688671102,"prompt-eng":0.4269489328,"data-quality":0.0952829475,"ml-security":0.110775555}}
{"text":"We also extend a method for simulation to reality transfer of the learned controller to contact rich dynamic tasks, resulting in successful deployment on the robot after training without parameter tuning.","meta":{"url":"http://arxiv.org/abs/2307.16676v1"},"cats":{"new-dataset":0.2610998915,"dev-research":0.2820758476,"prompt-eng":0.4313568512,"data-quality":0.0815729282,"ml-security":0.1239077429}}
{"text":"The goal of Online Domain Adaptation for semantic segmentation is to handle unforeseeable domain changes that occur during deployment, like sudden weather events.","meta":{"url":"http://arxiv.org/abs/2307.15063v1"},"cats":{"new-dataset":0.1341902044,"dev-research":0.2681716144,"prompt-eng":0.4203643785,"data-quality":0.2851221548,"ml-security":0.154917696}}
{"text":"However, the high computational costs associated with brute-force adaptation make this paradigm unfeasible for real-world applications.","meta":{"url":"http://arxiv.org/abs/2307.15063v1"},"cats":{"new-dataset":0.0369893263,"dev-research":0.2492894069,"prompt-eng":0.4175200518,"data-quality":0.1820657387,"ml-security":0.193125496}}
{"text":"In this paper we propose HAMLET, a Hardware-Aware Modular Least Expensive Training framework for real-time domain adaptation.","meta":{"url":"http://arxiv.org/abs/2307.15063v1"},"cats":{"new-dataset":0.1349122444,"dev-research":0.3288845852,"prompt-eng":0.410441081,"data-quality":0.1833842289,"ml-security":0.1554364771}}
{"text":"Our approach includes a hardware-aware back-propagation orchestration agent (HAMT) and a dedicated domain-shift detector that enables active control over when and how the model is adapted (LT).","meta":{"url":"http://arxiv.org/abs/2307.15063v1"},"cats":{"new-dataset":0.1289432223,"dev-research":0.3253532694,"prompt-eng":0.4922546362,"data-quality":0.1877680883,"ml-security":0.158585906}}
{"text":"Thanks to these advancements, our approach is capable of performing semantic segmentation while simultaneously adapting at more than 29FPS on a single consumer-grade GPU.","meta":{"url":"http://arxiv.org/abs/2307.15063v1"},"cats":{"new-dataset":0.3569541227,"dev-research":0.2041474231,"prompt-eng":0.3989045096,"data-quality":0.1857864816,"ml-security":0.0627522092}}
{"text":"Our framework's encouraging accuracy and speed trade-off is demonstrated on OnDA and SHIFT benchmarks through experimental results.","meta":{"url":"http://arxiv.org/abs/2307.15063v1"},"cats":{"new-dataset":0.1245324271,"dev-research":0.2567828714,"prompt-eng":0.4106715209,"data-quality":0.1935902327,"ml-security":0.068629739}}
{"text":"Acoustic matching aims to re-synthesize an audio clip to sound as if it were recorded in a target acoustic environment.","meta":{"url":"http://arxiv.org/abs/2307.15064v1"},"cats":{"new-dataset":0.0476354234,"dev-research":0.2921135766,"prompt-eng":0.3898969002,"data-quality":0.1776522929,"ml-security":0.0946104673}}
{"text":"Existing methods assume access to paired training data, where the audio is observed in both source and target environments, but this limits the diversity of training data or requires the use of simulated data or heuristics to create paired samples.","meta":{"url":"http://arxiv.org/abs/2307.15064v1"},"cats":{"new-dataset":0.172887409,"dev-research":0.2283870464,"prompt-eng":0.3339724523,"data-quality":0.1743345664,"ml-security":0.1300749208}}
{"text":"We propose a self-supervised approach to visual acoustic matching where training samples include only the target scene image and audio -- without acoustically mismatched source audio for reference.","meta":{"url":"http://arxiv.org/abs/2307.15064v1"},"cats":{"new-dataset":0.1696942311,"dev-research":0.2014821328,"prompt-eng":0.368713977,"data-quality":0.4838678808,"ml-security":0.1060201651}}
{"text":"Our approach jointly learns to disentangle room acoustics and re-synthesize audio into the target environment, via a conditional GAN framework and a novel metric that quantifies the level of residual acoustic information in the de-biased audio.","meta":{"url":"http://arxiv.org/abs/2307.15064v1"},"cats":{"new-dataset":0.188597134,"dev-research":0.2933140512,"prompt-eng":0.2999744037,"data-quality":0.191925995,"ml-security":0.2028993253}}
{"text":"Training with either in-the-wild web data or simulated data, we demonstrate it outperforms the state-of-the-art on multiple challenging datasets and a wide variety of real-world audio and environments.","meta":{"url":"http://arxiv.org/abs/2307.15064v1"},"cats":{"new-dataset":0.490964952,"dev-research":0.2075369192,"prompt-eng":0.3249053796,"data-quality":0.3230245944,"ml-security":0.1057175937}}
{"text":"Accurate depth estimation under out-of-distribution (OoD) scenarios, such as adverse weather conditions, sensor failure, and noise contamination, is desirable for safety-critical applications.","meta":{"url":"http://arxiv.org/abs/2307.15061v1"},"cats":{"new-dataset":0.3239523338,"dev-research":0.1798774198,"prompt-eng":0.3448413219,"data-quality":0.2150400948,"ml-security":0.1448013725}}
{"text":"Existing depth estimation systems, however, suffer inevitably from real-world corruptions and perturbations and are struggled to provide reliable depth predictions under such cases.","meta":{"url":"http://arxiv.org/abs/2307.15061v1"},"cats":{"new-dataset":0.3265714282,"dev-research":0.2020449203,"prompt-eng":0.3560509721,"data-quality":0.2865134905,"ml-security":0.1793495543}}
{"text":"In this paper, we summarize the winning solutions from the RoboDepth Challenge -- an academic competition designed to facilitate and advance robust OoD depth estimation.","meta":{"url":"http://arxiv.org/abs/2307.15061v1"},"cats":{"new-dataset":0.3784604082,"dev-research":0.1531746895,"prompt-eng":0.3745119193,"data-quality":0.1667435113,"ml-security":0.1285162189}}
{"text":"This challenge was developed based on the newly established KITTI-C and NYUDepth2-C benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.15061v1"},"cats":{"new-dataset":0.3149845101,"dev-research":0.1864173445,"prompt-eng":0.4264164398,"data-quality":0.1441618577,"ml-security":0.0448731666}}
{"text":"We hosted two stand-alone tracks, with an emphasis on robust self-supervised and robust fully-supervised depth estimation, respectively.","meta":{"url":"http://arxiv.org/abs/2307.15061v1"},"cats":{"new-dataset":0.4209291492,"dev-research":0.1685607057,"prompt-eng":0.3849998893,"data-quality":0.2515452242,"ml-security":0.0743482213}}
{"text":"Out of more than two hundred participants, nine unique and top-performing solutions have appeared, with novel designs ranging from the following aspects: spatial- and frequency-domain augmentations, masked image modeling, image restoration and super-resolution, adversarial training, diffusion-based noise suppression, vision-language pre-training, learned model ensembling, and hierarchical feature enhancement.","meta":{"url":"http://arxiv.org/abs/2307.15061v1"},"cats":{"new-dataset":0.2226096143,"dev-research":0.2015377625,"prompt-eng":0.3670460505,"data-quality":0.1883832524,"ml-security":0.1864772068}}
{"text":"Extensive experimental analyses along with insightful observations are drawn to better understand the rationale behind each design.","meta":{"url":"http://arxiv.org/abs/2307.15061v1"},"cats":{"new-dataset":0.0091486632,"dev-research":0.38515966,"prompt-eng":0.3776834035,"data-quality":0.1144738713,"ml-security":0.0879669756}}
{"text":"We hope this challenge could lay a solid foundation for future research on robust and reliable depth estimation and beyond.","meta":{"url":"http://arxiv.org/abs/2307.15061v1"},"cats":{"new-dataset":0.4219236514,"dev-research":0.1621533389,"prompt-eng":0.3957762973,"data-quality":0.1944499519,"ml-security":0.0928134094}}
{"text":"The datasets, competition toolkit, workshop recordings, and source code from the winning teams are publicly available on the challenge website.","meta":{"url":"http://arxiv.org/abs/2307.15061v1"},"cats":{"new-dataset":0.8695539324,"dev-research":0.2306966966,"prompt-eng":0.351823292,"data-quality":0.1399334131,"ml-security":0.1006328993}}
{"text":"Nowadays, autonomous cars can drive smoothly in ordinary cases, and it is widely recognized that realistic sensor simulation will play a critical role in solving remaining corner cases by simulating them.","meta":{"url":"http://arxiv.org/abs/2307.15058v1"},"cats":{"new-dataset":0.1696838684,"dev-research":0.2405242034,"prompt-eng":0.3761850722,"data-quality":0.1144747299,"ml-security":0.1739088111}}
{"text":"To this end, we propose an autonomous driving simulator based upon neural radiance fields (NeRFs).","meta":{"url":"http://arxiv.org/abs/2307.15058v1"},"cats":{"new-dataset":0.2205214023,"dev-research":0.2348011255,"prompt-eng":0.382492591,"data-quality":0.1095450508,"ml-security":0.1694013635}}
{"text":"Compared with existing works, ours has three notable features: (1) Instance-aware.","meta":{"url":"http://arxiv.org/abs/2307.15058v1"},"cats":{"new-dataset":0.1302162195,"dev-research":0.2779137542,"prompt-eng":0.4783731952,"data-quality":0.2072429789,"ml-security":0.090734065}}
{"text":"Our simulator models the foreground instances and background environments separately with independent networks so that the static (e.g., size and appearance) and dynamic (e.g., trajectory) properties of instances can be controlled separately.","meta":{"url":"http://arxiv.org/abs/2307.15058v1"},"cats":{"new-dataset":0.220154984,"dev-research":0.2638370381,"prompt-eng":0.4164598839,"data-quality":0.0994638401,"ml-security":0.1880216384}}
{"text":"(2) Modular.","meta":{"url":"http://arxiv.org/abs/2307.15058v1"},"cats":{"new-dataset":0.10061234,"dev-research":0.2044028633,"prompt-eng":0.3941970198,"data-quality":0.1556804932,"ml-security":0.1086400538}}
{"text":"Our simulator allows flexible switching between different modern NeRF-related backbones, sampling strategies, input modalities, etc.","meta":{"url":"http://arxiv.org/abs/2307.15058v1"},"cats":{"new-dataset":0.0984162343,"dev-research":0.3157443888,"prompt-eng":0.4144656352,"data-quality":0.1123336763,"ml-security":0.1774236613}}
{"text":"We expect this modular design to boost academic progress and industrial deployment of NeRF-based autonomous driving simulation.","meta":{"url":"http://arxiv.org/abs/2307.15058v1"},"cats":{"new-dataset":0.1423354412,"dev-research":0.3073117261,"prompt-eng":0.4129130084,"data-quality":0.1037928295,"ml-security":0.1408308112}}
{"text":"(3) Realistic.","meta":{"url":"http://arxiv.org/abs/2307.15058v1"},"cats":{"new-dataset":0.1692614632,"dev-research":0.2259836078,"prompt-eng":0.3384830472,"data-quality":0.1659629653,"ml-security":0.1138917923}}
{"text":"Our simulator set new state-of-the-art photo-realism results given the best module selection.","meta":{"url":"http://arxiv.org/abs/2307.15058v1"},"cats":{"new-dataset":0.4088445203,"dev-research":0.192335864,"prompt-eng":0.385390527,"data-quality":0.0933029014,"ml-security":0.0434891778}}
{"text":"Our simulator will be open-sourced while most of our counterparts are not.","meta":{"url":"http://arxiv.org/abs/2307.15058v1"},"cats":{"new-dataset":0.4062034373,"dev-research":0.3204435021,"prompt-eng":0.3413418829,"data-quality":0.136975664,"ml-security":0.210320574}}
{"text":"Project page: https://open-air-sun.github.io/mars/.","meta":{"url":"http://arxiv.org/abs/2307.15058v1"},"cats":{"new-dataset":0.6183260667,"dev-research":0.1657284261,"prompt-eng":0.3836611977,"data-quality":0.0716570084,"ml-security":0.0348581724}}
{"text":"Today's network measurements rely heavily on Internet-wide scanning, employing tools like ZMap that are capable of quickly iterating over the entire IPv4 address space.","meta":{"url":"http://arxiv.org/abs/2307.15057v1"},"cats":{"new-dataset":0.156445193,"dev-research":0.2453747146,"prompt-eng":0.3949960047,"data-quality":0.1169033191,"ml-security":0.1161709299}}
{"text":"Unfortunately, IPv6's vast address space poses an existential threat for Internet-wide scans and traditional network measurement techniques.","meta":{"url":"http://arxiv.org/abs/2307.15057v1"},"cats":{"new-dataset":0.140680324,"dev-research":0.2115306269,"prompt-eng":0.3518035317,"data-quality":0.1666089741,"ml-security":0.4153876846}}
{"text":"To address this reality, efforts are underway to develop ``hitlists'' of known-active IPv6 addresses to reduce the search space for would-be scanners.","meta":{"url":"http://arxiv.org/abs/2307.15057v1"},"cats":{"new-dataset":0.3105267696,"dev-research":0.2846242069,"prompt-eng":0.4140285345,"data-quality":0.1730752944,"ml-security":0.2275625479}}
{"text":"As a result, there is an inexorable push for constructing as large and complete a hitlist as possible.   ","meta":{"url":"http://arxiv.org/abs/2307.15057v1"},"cats":{"new-dataset":0.2993478796,"dev-research":0.3077638491,"prompt-eng":0.4255002257,"data-quality":0.1555154583,"ml-security":0.1028558673}}
{"text":"This paper asks: what are the potential benefits and harms when IPv6 hitlists grow larger?","meta":{"url":"http://arxiv.org/abs/2307.15057v1"},"cats":{"new-dataset":0.0430311054,"dev-research":0.2667600687,"prompt-eng":0.2879311118,"data-quality":0.1849015622,"ml-security":0.380057726}}
{"text":"To answer this question, we obtain the largest IPv6 active-address list to date: 7.9 billion addresses, 898 times larger than the current state-of-the-art hitlist.","meta":{"url":"http://arxiv.org/abs/2307.15057v1"},"cats":{"new-dataset":0.567443761,"dev-research":0.2079221754,"prompt-eng":0.3030852909,"data-quality":0.1103206283,"ml-security":0.1813661439}}
{"text":"Although our list is not comprehensive, it is a significant step forward and provides a glimpse into the type of analyses possible with more complete hitlists.   ","meta":{"url":"http://arxiv.org/abs/2307.15057v1"},"cats":{"new-dataset":0.3724857457,"dev-research":0.1956065857,"prompt-eng":0.3864806116,"data-quality":0.1016312806,"ml-security":0.0740203218}}
{"text":"We compare our dataset to prior IPv6 hitlists and show both benefits and dangers.","meta":{"url":"http://arxiv.org/abs/2307.15057v1"},"cats":{"new-dataset":0.4452267001,"dev-research":0.2461358054,"prompt-eng":0.3333658959,"data-quality":0.1743919732,"ml-security":0.3573245159}}
{"text":"The benefits include improved insight into client devices (prior datasets consist primarily of routers), outage detection, IPv6 roll-out, previously unknown aliased networks, and address assignment strategies.","meta":{"url":"http://arxiv.org/abs/2307.15057v1"},"cats":{"new-dataset":0.0264989023,"dev-research":0.3635306348,"prompt-eng":0.3372125871,"data-quality":0.1112500861,"ml-security":0.2076908817}}
{"text":"The dangers, unfortunately, are severe: we expose widespread instances of addresses that permit user tracking and device geolocation, and a dearth of firewalls in home networks.","meta":{"url":"http://arxiv.org/abs/2307.15057v1"},"cats":{"new-dataset":0.2099811568,"dev-research":0.320230141,"prompt-eng":0.3993747393,"data-quality":0.2172665889,"ml-security":0.4434301572}}
{"text":"We discuss ethics and security guidelines to ensure a safe path towards more complete hitlists.","meta":{"url":"http://arxiv.org/abs/2307.15057v1"},"cats":{"new-dataset":0.2608448837,"dev-research":0.3466154366,"prompt-eng":0.3817303248,"data-quality":0.1981384023,"ml-security":0.4856022688}}
{"text":"We introduce PointOdyssey, a large-scale synthetic dataset, and data generation framework, for the training and evaluation of long-term fine-grained tracking algorithms.","meta":{"url":"http://arxiv.org/abs/2307.15055v1"},"cats":{"new-dataset":0.6998849563,"dev-research":0.2463069079,"prompt-eng":0.3473249408,"data-quality":0.2162295869,"ml-security":0.0807183345}}
{"text":"Our goal is to advance the state-of-the-art by placing emphasis on long videos with naturalistic motion.","meta":{"url":"http://arxiv.org/abs/2307.15055v1"},"cats":{"new-dataset":0.1902894971,"dev-research":0.2053932756,"prompt-eng":0.342931018,"data-quality":0.1216616132,"ml-security":0.0488337764}}
{"text":"Toward the goal of naturalism, we animate deformable characters using real-world motion capture data, we build 3D scenes to match the motion capture environments, and we render camera viewpoints using trajectories mined via structure-from-motion on real videos.","meta":{"url":"http://arxiv.org/abs/2307.15055v1"},"cats":{"new-dataset":0.5649955564,"dev-research":0.2146087388,"prompt-eng":0.3507480737,"data-quality":0.0917607283,"ml-security":0.09399671}}
{"text":"We create combinatorial diversity by randomizing character appearance, motion profiles, materials, lighting, 3D assets, and atmospheric effects.","meta":{"url":"http://arxiv.org/abs/2307.15055v1"},"cats":{"new-dataset":0.3201920934,"dev-research":0.1658283953,"prompt-eng":0.363937518,"data-quality":0.0949054038,"ml-security":0.0724795773}}
{"text":"Our dataset currently includes 104 videos, averaging 2,000 frames long, with orders of magnitude more correspondence annotations than prior work.","meta":{"url":"http://arxiv.org/abs/2307.15055v1"},"cats":{"new-dataset":0.7725878897,"dev-research":0.1887612537,"prompt-eng":0.3063077995,"data-quality":0.227330282,"ml-security":0.0712213006}}
{"text":"We show that existing methods can be trained from scratch in our dataset and outperform the published variants.","meta":{"url":"http://arxiv.org/abs/2307.15055v1"},"cats":{"new-dataset":0.4573191044,"dev-research":0.2765528726,"prompt-eng":0.380143363,"data-quality":0.3212850294,"ml-security":0.1591658185}}
{"text":"Finally, we introduce modifications to the PIPs point tracking method, greatly widening its temporal receptive field, which improves its performance on PointOdyssey as well as on two real-world benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.15055v1"},"cats":{"new-dataset":0.2358308478,"dev-research":0.2092830675,"prompt-eng":0.4204210343,"data-quality":0.1854784275,"ml-security":0.0466922609}}
{"text":"Our data and code are publicly available at: https://pointodyssey.com","meta":{"url":"http://arxiv.org/abs/2307.15055v1"},"cats":{"new-dataset":0.851305899,"dev-research":0.1872074165,"prompt-eng":0.4293621739,"data-quality":0.0975375877,"ml-security":0.0511770598}}
{"text":"Large language models rely on real-valued representations of text to make their predictions.","meta":{"url":"http://arxiv.org/abs/2307.15054v1"},"cats":{"new-dataset":0.0489445821,"dev-research":0.2101078179,"prompt-eng":0.3449204225,"data-quality":0.2467088623,"ml-security":0.1750491107}}
{"text":"These representations contain information learned from the data that the model has trained on, including knowledge of linguistic properties and forms of demographic bias, e.g., based on gender.","meta":{"url":"http://arxiv.org/abs/2307.15054v1"},"cats":{"new-dataset":0.0765888214,"dev-research":0.2267417363,"prompt-eng":0.3616453795,"data-quality":0.1923219506,"ml-security":0.1457114382}}
{"text":"A growing body of work has considered information about concepts such as these using orthogonal projections onto subspaces of the representation space.","meta":{"url":"http://arxiv.org/abs/2307.15054v1"},"cats":{"new-dataset":0.0793275139,"dev-research":0.2380577,"prompt-eng":0.366868456,"data-quality":0.1421341179,"ml-security":0.0837246003}}
{"text":"We contribute to this body of work by proposing a formal definition of intrinsic information in a subspace of a language model's representation space.","meta":{"url":"http://arxiv.org/abs/2307.15054v1"},"cats":{"new-dataset":0.0698844402,"dev-research":0.2137605187,"prompt-eng":0.3888562942,"data-quality":0.2415209515,"ml-security":0.1580607481}}
{"text":"We propose a counterfactual approach that avoids the failure mode of spurious correlations (Kumar et al., 2022) by treating components in the subspace and its orthogonal complement independently.","meta":{"url":"http://arxiv.org/abs/2307.15054v1"},"cats":{"new-dataset":0.0314292734,"dev-research":0.2819086502,"prompt-eng":0.3808217904,"data-quality":0.531710216,"ml-security":0.2045836347}}
{"text":"We show that our counterfactual notion of information in a subspace is optimizing by an causal concept subspace.","meta":{"url":"http://arxiv.org/abs/2307.15054v1"},"cats":{"new-dataset":0.0246910471,"dev-research":0.3016681701,"prompt-eng":0.3911958785,"data-quality":0.3342485871,"ml-security":0.2731059469}}
{"text":"Furthermore, this intervention allows us to attempt concept controlled generation by manipulating the value of the conceptual component of a representation.","meta":{"url":"http://arxiv.org/abs/2307.15054v1"},"cats":{"new-dataset":0.0351863073,"dev-research":0.4602416121,"prompt-eng":0.4699786225,"data-quality":0.1871498432,"ml-security":0.1246041137}}
{"text":"Empirically, we find that R-LACE (Ravfogel et al., 2022) returns a one-dimensional subspace containing roughly half of total concept information under our framework.","meta":{"url":"http://arxiv.org/abs/2307.15054v1"},"cats":{"new-dataset":0.1571551542,"dev-research":0.2171502226,"prompt-eng":0.3338087479,"data-quality":0.2221100395,"ml-security":0.1573422436}}
{"text":"Our causal controlled intervention shows that, for at least one model, the subspace returned by R-LACE can be used to manipulate the concept value of the generated word with precision.","meta":{"url":"http://arxiv.org/abs/2307.15054v1"},"cats":{"new-dataset":0.0726709226,"dev-research":0.2394253034,"prompt-eng":0.4501958991,"data-quality":0.3135409285,"ml-security":0.1058965643}}
{"text":"Approaches to recommendation are typically evaluated in one of two ways: (1) via a (simulated) online experiment, often seen as the gold standard, or (2) via some offline evaluation procedure, where the goal is to approximate the outcome of an online experiment.","meta":{"url":"http://arxiv.org/abs/2307.15053v1"},"cats":{"new-dataset":0.0143460817,"dev-research":0.3060222644,"prompt-eng":0.4162595533,"data-quality":0.1425826598,"ml-security":0.0476116081}}
{"text":"Several offline evaluation metrics have been adopted in the literature, inspired by ranking metrics prevalent in the field of Information Retrieval.","meta":{"url":"http://arxiv.org/abs/2307.15053v1"},"cats":{"new-dataset":0.0630611969,"dev-research":0.2106774987,"prompt-eng":0.4496501522,"data-quality":0.2506490256,"ml-security":0.0350919715}}
{"text":"(Normalised) Discounted Cumulative Gain (nDCG) is one such metric that has seen widespread adoption in empirical studies, and higher (n)DCG values have been used to present new methods as the state-of-the-art in top-$n$ recommendation for many years.   ","meta":{"url":"http://arxiv.org/abs/2307.15053v1"},"cats":{"new-dataset":0.0385636004,"dev-research":0.2361340642,"prompt-eng":0.4104483762,"data-quality":0.1945196953,"ml-security":0.0948205151}}
{"text":"Our work takes a critical look at this approach, and investigates when we can expect such metrics to approximate the gold standard outcome of an online experiment.","meta":{"url":"http://arxiv.org/abs/2307.15053v1"},"cats":{"new-dataset":0.097785568,"dev-research":0.1672471651,"prompt-eng":0.4107085219,"data-quality":0.2167471336,"ml-security":0.0885182071}}
{"text":"We formally present the assumptions that are necessary to consider DCG an unbiased estimator of online reward and provide a derivation for this metric from first principles, highlighting where we deviate from its traditional uses in IR.","meta":{"url":"http://arxiv.org/abs/2307.15053v1"},"cats":{"new-dataset":0.0597299817,"dev-research":0.1431557038,"prompt-eng":0.3979625154,"data-quality":0.2135708883,"ml-security":0.1206105318}}
{"text":"Importantly, we show that normalising the metric renders it inconsistent, in that even when DCG is unbiased, ranking competing methods by their normalised DCG can invert their relative order.","meta":{"url":"http://arxiv.org/abs/2307.15053v1"},"cats":{"new-dataset":0.0809150238,"dev-research":0.2313094254,"prompt-eng":0.3595622853,"data-quality":0.340373708,"ml-security":0.0686883337}}
{"text":"Through a correlation analysis between off- and on-line experiments conducted on a large-scale recommendation platform, we show that our unbiased DCG estimates strongly correlate with online reward, even when some of the metric's inherent assumptions are violated.","meta":{"url":"http://arxiv.org/abs/2307.15053v1"},"cats":{"new-dataset":0.0476121377,"dev-research":0.1953913718,"prompt-eng":0.3702782263,"data-quality":0.2311945319,"ml-security":0.0994128988}}
{"text":"This statement no longer holds for its normalised variant, suggesting that nDCG's practical utility may be limited.","meta":{"url":"http://arxiv.org/abs/2307.15053v1"},"cats":{"new-dataset":0.0280348199,"dev-research":0.2371869187,"prompt-eng":0.3625079575,"data-quality":0.2427162282,"ml-security":0.0956181589}}
{"text":"Inferring the depth of transparent or mirror (ToM) surfaces represents a hard challenge for either sensors, algorithms, or deep networks.","meta":{"url":"http://arxiv.org/abs/2307.15052v1"},"cats":{"new-dataset":0.1632228072,"dev-research":0.180821299,"prompt-eng":0.3880007249,"data-quality":0.1270779619,"ml-security":0.1434136733}}
{"text":"We propose a simple pipeline for learning to estimate depth properly for such surfaces with neural networks, without requiring any ground-truth annotation.","meta":{"url":"http://arxiv.org/abs/2307.15052v1"},"cats":{"new-dataset":0.3827940629,"dev-research":0.1805281408,"prompt-eng":0.3577718841,"data-quality":0.1518062644,"ml-security":0.1075962397}}
{"text":"We unveil how to obtain reliable pseudo labels by in-painting ToM objects in images and processing them with a monocular depth estimation model.","meta":{"url":"http://arxiv.org/abs/2307.15052v1"},"cats":{"new-dataset":0.2349681956,"dev-research":0.207604787,"prompt-eng":0.4130181626,"data-quality":0.3656527317,"ml-security":0.083382192}}
{"text":"These labels can be used to fine-tune existing monocular or stereo networks, to let them learn how to deal with ToM surfaces.","meta":{"url":"http://arxiv.org/abs/2307.15052v1"},"cats":{"new-dataset":0.1025612408,"dev-research":0.2842685023,"prompt-eng":0.3983325341,"data-quality":0.2663942792,"ml-security":0.0710548399}}
{"text":"Experimental results on the Booster dataset show the dramatic improvements enabled by our remarkably simple proposal.","meta":{"url":"http://arxiv.org/abs/2307.15052v1"},"cats":{"new-dataset":0.2651105611,"dev-research":0.1694560395,"prompt-eng":0.4502997528,"data-quality":0.2691979149,"ml-security":0.1253422921}}
{"text":"Clinical trials are vital in advancing drug development and evidence-based medicine, but their success is often hindered by challenges in patient recruitment.","meta":{"url":"http://arxiv.org/abs/2307.15051v1"},"cats":{"new-dataset":0.031960568,"dev-research":0.2870311795,"prompt-eng":0.372565224,"data-quality":0.136367771,"ml-security":0.1595624631}}
{"text":"In this work, we investigate the potential of large language models (LLMs) to assist individual patients and referral physicians in identifying suitable clinical trials from an extensive selection.","meta":{"url":"http://arxiv.org/abs/2307.15051v1"},"cats":{"new-dataset":0.0501994035,"dev-research":0.2186079495,"prompt-eng":0.4176755044,"data-quality":0.1523951694,"ml-security":0.0617979172}}
{"text":"Specifically, we introduce TrialGPT, a novel architecture employing LLMs to predict criterion-level eligibility with detailed explanations, which are then aggregated for ranking and excluding candidate clinical trials based on free-text patient notes.","meta":{"url":"http://arxiv.org/abs/2307.15051v1"},"cats":{"new-dataset":0.0445481467,"dev-research":0.2281371735,"prompt-eng":0.4812904962,"data-quality":0.1369390477,"ml-security":0.0972319572}}
{"text":"We evaluate TrialGPT on three publicly available cohorts of 184 patients and 18,238 annotated clinical trials.","meta":{"url":"http://arxiv.org/abs/2307.15051v1"},"cats":{"new-dataset":0.2129589284,"dev-research":0.2529241382,"prompt-eng":0.3881161632,"data-quality":0.134212993,"ml-security":0.0585513359}}
{"text":"The experimental results demonstrate several key findings:","meta":{"url":"http://arxiv.org/abs/2307.15051v1"},"cats":{"new-dataset":0.0269590131,"dev-research":0.2101864647,"prompt-eng":0.3781699363,"data-quality":0.1361886275,"ml-security":0.0617991439}}
{"text":"First, TrialGPT achieves high criterion-level prediction accuracy with faithful explanations.","meta":{"url":"http://arxiv.org/abs/2307.15051v1"},"cats":{"new-dataset":0.0767589471,"dev-research":0.32616683,"prompt-eng":0.4686727928,"data-quality":0.2356624242,"ml-security":0.1214651104}}
{"text":"Second, the aggregated trial-level TrialGPT scores are highly correlated with expert eligibility annotations.","meta":{"url":"http://arxiv.org/abs/2307.15051v1"},"cats":{"new-dataset":0.0807850167,"dev-research":0.2991981125,"prompt-eng":0.4415335424,"data-quality":0.2155238798,"ml-security":0.0834135705}}
{"text":"Third, these scores prove effective in ranking clinical trials and exclude ineligible candidates.","meta":{"url":"http://arxiv.org/abs/2307.15051v1"},"cats":{"new-dataset":0.0160446324,"dev-research":0.2070923624,"prompt-eng":0.442265829,"data-quality":0.2670767187,"ml-security":0.0882723114}}
{"text":"Our error analysis suggests that current LLMs still make some mistakes due to limited medical knowledge and domain-specific context understanding.","meta":{"url":"http://arxiv.org/abs/2307.15051v1"},"cats":{"new-dataset":0.0179135779,"dev-research":0.3096119685,"prompt-eng":0.3809896377,"data-quality":0.3650867925,"ml-security":0.1638591046}}
{"text":"Nonetheless, we believe the explanatory capabilities of LLMs are highly valuable.","meta":{"url":"http://arxiv.org/abs/2307.15051v1"},"cats":{"new-dataset":0.0452059356,"dev-research":0.1853293593,"prompt-eng":0.3798428886,"data-quality":0.1051561889,"ml-security":0.126346469}}
{"text":"Future research is warranted on how such AI assistants can be integrated into the routine trial matching workflow in real-world settings to improve its efficiency.","meta":{"url":"http://arxiv.org/abs/2307.15051v1"},"cats":{"new-dataset":0.1253135362,"dev-research":0.3214889,"prompt-eng":0.4545487826,"data-quality":0.1223427716,"ml-security":0.0927627134}}
{"text":"Prompt tuning and adapter tuning have shown great potential in transferring pre-trained vision-language models (VLMs) to various downstream tasks.","meta":{"url":"http://arxiv.org/abs/2307.15049v1"},"cats":{"new-dataset":0.0851463692,"dev-research":0.271903772,"prompt-eng":0.5202089359,"data-quality":0.1981813873,"ml-security":0.0841769198}}
{"text":"In this work, we design a new type of tuning method, termed as regularized mask tuning, which masks the network parameters through a learnable selection.","meta":{"url":"http://arxiv.org/abs/2307.15049v1"},"cats":{"new-dataset":0.0296139246,"dev-research":0.233713183,"prompt-eng":0.433653714,"data-quality":0.2847325247,"ml-security":0.2467353658}}
{"text":"Inspired by neural pathways, we argue that the knowledge required by a downstream task already exists in the pre-trained weights but just gets concealed in the upstream pre-training stage.","meta":{"url":"http://arxiv.org/abs/2307.15049v1"},"cats":{"new-dataset":0.0450188163,"dev-research":0.2074645018,"prompt-eng":0.3672363962,"data-quality":0.1799119527,"ml-security":0.2967760849}}
{"text":"To bring the useful knowledge back into light, we first identify a set of parameters that are important to a given downstream task, then attach a binary mask to each parameter, and finally optimize these masks on the downstream data with the parameters frozen.","meta":{"url":"http://arxiv.org/abs/2307.15049v1"},"cats":{"new-dataset":0.2163157643,"dev-research":0.2679219895,"prompt-eng":0.4404854203,"data-quality":0.1607519338,"ml-security":0.1512062705}}
{"text":"When updating the mask, we introduce a novel gradient dropout strategy to regularize the parameter selection, in order to prevent the model from forgetting old knowledge and overfitting the downstream data.","meta":{"url":"http://arxiv.org/abs/2307.15049v1"},"cats":{"new-dataset":0.0867280402,"dev-research":0.2160830622,"prompt-eng":0.3996424852,"data-quality":0.2702873547,"ml-security":0.3093396947}}
{"text":"Experimental results on 11 datasets demonstrate the consistent superiority of our method over previous alternatives.","meta":{"url":"http://arxiv.org/abs/2307.15049v1"},"cats":{"new-dataset":0.2513514616,"dev-research":0.2133613884,"prompt-eng":0.4250411995,"data-quality":0.2972034331,"ml-security":0.0625693298}}
{"text":"It is noteworthy that we manage to deliver 18.73% performance improvement compared to the zero-shot CLIP via masking an average of only 2.56% parameters.","meta":{"url":"http://arxiv.org/abs/2307.15049v1"},"cats":{"new-dataset":0.0932529098,"dev-research":0.2181371631,"prompt-eng":0.3937899789,"data-quality":0.1725041701,"ml-security":0.0882468339}}
{"text":"Furthermore, our method is synergistic with most existing parameter-efficient tuning methods and can boost the performance on top of them.","meta":{"url":"http://arxiv.org/abs/2307.15049v1"},"cats":{"new-dataset":0.0511984321,"dev-research":0.2602928831,"prompt-eng":0.4779158235,"data-quality":0.1875165639,"ml-security":0.0551998026}}
{"text":"Project page can be found here (https://wuw2019.github.io/RMT/).","meta":{"url":"http://arxiv.org/abs/2307.15049v1"},"cats":{"new-dataset":0.4643116726,"dev-research":0.2128783685,"prompt-eng":0.4626792457,"data-quality":0.1112005757,"ml-security":0.0280512279}}
{"text":"Handwriting recognition is a challenging and critical problem in the fields of pattern recognition and machine learning, with applications spanning a wide range of domains.","meta":{"url":"http://arxiv.org/abs/2307.15045v1"},"cats":{"new-dataset":0.1724066118,"dev-research":0.1828071791,"prompt-eng":0.3978733685,"data-quality":0.2161286303,"ml-security":0.1447263793}}
{"text":"In this paper, we focus on the specific issue of recognizing offline Arabic handwritten text.","meta":{"url":"http://arxiv.org/abs/2307.15045v1"},"cats":{"new-dataset":0.3123628137,"dev-research":0.1622039187,"prompt-eng":0.3902029432,"data-quality":0.2700163909,"ml-security":0.1118524096}}
{"text":"Existing approaches typically utilize a combination of convolutional neural networks for image feature extraction and recurrent neural networks for temporal modeling, with connectionist temporal classification used for text generation.","meta":{"url":"http://arxiv.org/abs/2307.15045v1"},"cats":{"new-dataset":0.405879155,"dev-research":0.2215044419,"prompt-eng":0.3695960943,"data-quality":0.1838899582,"ml-security":0.0644471636}}
{"text":"However, these methods suffer from a lack of parallelization due to the sequential nature of recurrent neural networks.","meta":{"url":"http://arxiv.org/abs/2307.15045v1"},"cats":{"new-dataset":0.0725425583,"dev-research":0.1967746876,"prompt-eng":0.3079305954,"data-quality":0.1369463959,"ml-security":0.1542654625}}
{"text":"Furthermore, these models cannot account for linguistic rules, necessitating the use of an external language model in the post-processing stage to boost accuracy.","meta":{"url":"http://arxiv.org/abs/2307.15045v1"},"cats":{"new-dataset":0.0178697346,"dev-research":0.2678151976,"prompt-eng":0.3836578235,"data-quality":0.4145685581,"ml-security":0.1464234552}}
{"text":"To overcome these issues, we introduce two alternative architectures, namely the Transformer Transducer and the standard sequence-to-sequence Transformer, and compare their performance in terms of accuracy and speed.","meta":{"url":"http://arxiv.org/abs/2307.15045v1"},"cats":{"new-dataset":0.1858581305,"dev-research":0.2279121414,"prompt-eng":0.4339026501,"data-quality":0.1564145055,"ml-security":0.0419294906}}
{"text":"Our approach can model language dependencies and relies only on the attention mechanism, thereby making it more parallelizable and less complex.","meta":{"url":"http://arxiv.org/abs/2307.15045v1"},"cats":{"new-dataset":0.1055280136,"dev-research":0.2640426737,"prompt-eng":0.4226476657,"data-quality":0.1892167495,"ml-security":0.1355958266}}
{"text":"We employ pre-trained Transformers for both image understanding and language modeling.","meta":{"url":"http://arxiv.org/abs/2307.15045v1"},"cats":{"new-dataset":0.1518318555,"dev-research":0.2402380716,"prompt-eng":0.4245444442,"data-quality":0.1778707544,"ml-security":0.0729332697}}
{"text":"Our evaluation on the Arabic KHATT dataset demonstrates that our proposed method outperforms the current state-of-the-art approaches for recognizing offline Arabic handwritten text.","meta":{"url":"http://arxiv.org/abs/2307.15045v1"},"cats":{"new-dataset":0.645308204,"dev-research":0.17705031,"prompt-eng":0.3628853474,"data-quality":0.2182838694,"ml-security":0.0936795505}}
{"text":"Because \"out-of-the-box\" large language models are capable of generating a great deal of objectionable content, recent work has focused on aligning these models in an attempt to prevent undesirable generation.","meta":{"url":"http://arxiv.org/abs/2307.15043v1"},"cats":{"new-dataset":0.125986523,"dev-research":0.2983334924,"prompt-eng":0.3786183674,"data-quality":0.2972334932,"ml-security":0.1620514864}}
{"text":"While there has been some success at circumventing these measures -- so-called \"jailbreaks\" against LLMs -- these attacks have required significant human ingenuity and are brittle in practice.","meta":{"url":"http://arxiv.org/abs/2307.15043v1"},"cats":{"new-dataset":0.0227105669,"dev-research":0.2346159642,"prompt-eng":0.3862623275,"data-quality":0.222311117,"ml-security":0.6192417142}}
{"text":"In this paper, we propose a simple and effective attack method that causes aligned language models to generate objectionable behaviors.","meta":{"url":"http://arxiv.org/abs/2307.15043v1"},"cats":{"new-dataset":0.0950484965,"dev-research":0.4163492333,"prompt-eng":0.4399311229,"data-quality":0.3340320966,"ml-security":0.8092429199}}
{"text":"Specifically, our approach finds a suffix that, when attached to a wide range of queries for an LLM to produce objectionable content, aims to maximize the probability that the model produces an affirmative response (rather than refusing to answer).","meta":{"url":"http://arxiv.org/abs/2307.15043v1"},"cats":{"new-dataset":0.0211948642,"dev-research":0.189454991,"prompt-eng":0.4549621185,"data-quality":0.2537106898,"ml-security":0.26124296}}
{"text":"However, instead of relying on manual engineering, our approach automatically produces these adversarial suffixes by a combination of greedy and gradient-based search techniques, and also improves over past automatic prompt generation methods.   ","meta":{"url":"http://arxiv.org/abs/2307.15043v1"},"cats":{"new-dataset":0.1865694144,"dev-research":0.2757204029,"prompt-eng":0.5332568721,"data-quality":0.394518508,"ml-security":0.3744125632}}
{"text":"Surprisingly, we find that the adversarial prompts generated by our approach are quite transferable, including to black-box, publicly released LLMs.","meta":{"url":"http://arxiv.org/abs/2307.15043v1"},"cats":{"new-dataset":0.1251061602,"dev-research":0.2200076947,"prompt-eng":0.4477088537,"data-quality":0.2495099415,"ml-security":0.6896718576}}
{"text":"Specifically, we train an adversarial attack suffix on multiple prompts (i.e., queries asking for many different types of objectionable content), as well as multiple models (in our case, Vicuna-7B and 13B).","meta":{"url":"http://arxiv.org/abs/2307.15043v1"},"cats":{"new-dataset":0.0759881609,"dev-research":0.2616779427,"prompt-eng":0.4722770601,"data-quality":0.2716914414,"ml-security":0.7484821703}}
{"text":"When doing so, the resulting attack suffix is able to induce objectionable content in the public interfaces to ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat, Pythia, Falcon, and others.","meta":{"url":"http://arxiv.org/abs/2307.15043v1"},"cats":{"new-dataset":0.0939801845,"dev-research":0.3507523917,"prompt-eng":0.4078640535,"data-quality":0.2502950529,"ml-security":0.5787257486}}
{"text":"In total, this work significantly advances the state-of-the-art in adversarial attacks against aligned language models, raising important questions about how such systems can be prevented from producing objectionable information.","meta":{"url":"http://arxiv.org/abs/2307.15043v1"},"cats":{"new-dataset":0.1200697598,"dev-research":0.2324703699,"prompt-eng":0.3248258778,"data-quality":0.3503118797,"ml-security":0.8464737028}}
{"text":"Code is available at github.com/llm-attacks/llm-attacks.","meta":{"url":"http://arxiv.org/abs/2307.15043v1"},"cats":{"new-dataset":0.1208147733,"dev-research":0.1817617499,"prompt-eng":0.4599895304,"data-quality":0.1664876802,"ml-security":0.5396341159}}
{"text":"The gradual nature of a diffusion process that synthesizes samples in small increments constitutes a key ingredient of Denoising Diffusion Probabilistic Models (DDPM), which have presented unprecedented quality in image synthesis and been recently explored in the motion domain.","meta":{"url":"http://arxiv.org/abs/2307.15042v1"},"cats":{"new-dataset":0.0710391193,"dev-research":0.206135845,"prompt-eng":0.3338660621,"data-quality":0.1130774543,"ml-security":0.0816642536}}
{"text":"In this work, we propose to adapt the gradual diffusion concept (operating along a diffusion time-axis) into the temporal-axis of the motion sequence.","meta":{"url":"http://arxiv.org/abs/2307.15042v1"},"cats":{"new-dataset":0.0694831717,"dev-research":0.1574586661,"prompt-eng":0.3385550798,"data-quality":0.0639319188,"ml-security":0.0638606731}}
{"text":"Our key idea is to extend the DDPM framework to support temporally varying denoising, thereby entangling the two axes.","meta":{"url":"http://arxiv.org/abs/2307.15042v1"},"cats":{"new-dataset":0.1685379008,"dev-research":0.2040621247,"prompt-eng":0.3370845353,"data-quality":0.1232149763,"ml-security":0.1076295667}}
{"text":"Using our special formulation, we iteratively denoise a motion buffer that contains a set of increasingly-noised poses, which auto-regressively produces an arbitrarily long stream of frames.","meta":{"url":"http://arxiv.org/abs/2307.15042v1"},"cats":{"new-dataset":0.5573581759,"dev-research":0.1949431122,"prompt-eng":0.3259432529,"data-quality":0.1499374952,"ml-security":0.1235809739}}
{"text":"With a stationary diffusion time-axis, in each diffusion step we increment only the temporal-axis of the motion such that the framework produces a new, clean frame which is removed from the beginning of the buffer, followed by a newly drawn noise vector that is appended to it.","meta":{"url":"http://arxiv.org/abs/2307.15042v1"},"cats":{"new-dataset":0.1658781469,"dev-research":0.2131759709,"prompt-eng":0.3479141847,"data-quality":0.1445175557,"ml-security":0.1273274394}}
{"text":"This new mechanism paves the way towards a new framework for long-term motion synthesis with applications to character animation and other domains.","meta":{"url":"http://arxiv.org/abs/2307.15042v1"},"cats":{"new-dataset":0.1075711968,"dev-research":0.2667217011,"prompt-eng":0.3912968048,"data-quality":0.0552472288,"ml-security":0.0494296874}}
{"text":"An important difference between brains and deep neural networks is the way they learn.","meta":{"url":"http://arxiv.org/abs/2307.15040v1"},"cats":{"new-dataset":0.0212998656,"dev-research":0.3474472595,"prompt-eng":0.2712140378,"data-quality":0.1731012759,"ml-security":0.2012092141}}
{"text":"Nervous systems learn online where a stream of noisy data points are presented in a non-independent, identically distributed (non-i.i.d.) way.","meta":{"url":"http://arxiv.org/abs/2307.15040v1"},"cats":{"new-dataset":0.1323961252,"dev-research":0.1872804283,"prompt-eng":0.346289757,"data-quality":0.221667927,"ml-security":0.232565613}}
{"text":"Further, synaptic plasticity in the brain depends only on information local to synapses.","meta":{"url":"http://arxiv.org/abs/2307.15040v1"},"cats":{"new-dataset":0.0089672533,"dev-research":0.2731982758,"prompt-eng":0.3379618749,"data-quality":0.1631925432,"ml-security":0.1217322235}}
{"text":"Deep networks, on the other hand, typically use non-local learning algorithms and are trained in an offline, non-noisy, i.i.d. setting.","meta":{"url":"http://arxiv.org/abs/2307.15040v1"},"cats":{"new-dataset":0.0321603598,"dev-research":0.272046707,"prompt-eng":0.2608051943,"data-quality":0.2055086174,"ml-security":0.2168245292}}
{"text":"Understanding how neural networks learn under the same constraints as the brain is an open problem for neuroscience and neuromorphic computing.","meta":{"url":"http://arxiv.org/abs/2307.15040v1"},"cats":{"new-dataset":0.041279253,"dev-research":0.2386637537,"prompt-eng":0.3159510098,"data-quality":0.174575668,"ml-security":0.350100081}}
{"text":"A standard approach to this problem has yet to be established.","meta":{"url":"http://arxiv.org/abs/2307.15040v1"},"cats":{"new-dataset":0.1190629776,"dev-research":0.153247646,"prompt-eng":0.3501913428,"data-quality":0.3118255084,"ml-security":0.2051324347}}
{"text":"In this paper, we propose that discrete graphical models that learn via an online maximum a posteriori learning algorithm could provide such an approach.","meta":{"url":"http://arxiv.org/abs/2307.15040v1"},"cats":{"new-dataset":0.1264973415,"dev-research":0.1579541474,"prompt-eng":0.3962232996,"data-quality":0.1530247487,"ml-security":0.0890563692}}
{"text":"We implement this kind of model in a novel neural network called the Sparse Quantized Hopfield Network (SQHN).","meta":{"url":"http://arxiv.org/abs/2307.15040v1"},"cats":{"new-dataset":0.2130475249,"dev-research":0.1327147586,"prompt-eng":0.3305418988,"data-quality":0.109511879,"ml-security":0.1204817413}}
{"text":"We show that SQHNs outperform state-of-the-art neural networks on associative memory tasks, outperform these models in online, non-i.i.d. settings, learn efficiently with noisy inputs, and are better than baselines on a novel episodic memory task.","meta":{"url":"http://arxiv.org/abs/2307.15040v1"},"cats":{"new-dataset":0.2307570396,"dev-research":0.2271615752,"prompt-eng":0.3560158013,"data-quality":0.1777322798,"ml-security":0.1388172131}}
{"text":"Miscalibration of gaze tracking devices and the resulting need for repeat calibration are a significant barrier to use.","meta":{"url":"http://arxiv.org/abs/2307.15039v1"},"cats":{"new-dataset":0.0189794663,"dev-research":0.3243468568,"prompt-eng":0.4412021491,"data-quality":0.1255013223,"ml-security":0.086606904}}
{"text":"As devices miscalibrate, people tend to auto-correct by gazing at neighboring targets, which makes it difficult to detect miscalibration from eye signals.","meta":{"url":"http://arxiv.org/abs/2307.15039v1"},"cats":{"new-dataset":0.0105462781,"dev-research":0.4007306239,"prompt-eng":0.5055442697,"data-quality":0.3928746296,"ml-security":0.1262637705}}
{"text":"To address this problem, we provide a novel and simple insight for autocalibrating eye trackers during gaze typing: the eyes are used as both input (i.e. typing) and output (i.e. reading) signals, but auto-correction by users only occurs when eye gaze is functioning as input.","meta":{"url":"http://arxiv.org/abs/2307.15039v1"},"cats":{"new-dataset":0.0436986993,"dev-research":0.3982437632,"prompt-eng":0.5133816575,"data-quality":0.2610216051,"ml-security":0.0876392019}}
{"text":"Thus, output eye gaze signals during reading can help systems detect the miscalibration offset and enable autocalibration.","meta":{"url":"http://arxiv.org/abs/2307.15039v1"},"cats":{"new-dataset":0.0255848013,"dev-research":0.3561441516,"prompt-eng":0.4987369405,"data-quality":0.182851003,"ml-security":0.0525704787}}
{"text":"To demonstrate the potential for this type of approach, we designed and built an auto-calibration system for gaze typing and ran a user study with 15 able-bodied participants.","meta":{"url":"http://arxiv.org/abs/2307.15039v1"},"cats":{"new-dataset":0.1531490615,"dev-research":0.349655333,"prompt-eng":0.5191202256,"data-quality":0.1273268101,"ml-security":0.0587692741}}
{"text":"Results from our user study suggest that such an implicit approach to autocalibration can significantly improve typing speed and overall user experience for gaze typing interfaces.","meta":{"url":"http://arxiv.org/abs/2307.15039v1"},"cats":{"new-dataset":0.0267338555,"dev-research":0.4218195416,"prompt-eng":0.4875579135,"data-quality":0.1547049293,"ml-security":0.0506303796}}
{"text":"Insights from our work are applicable to a broad set of gaze tracking technologies and may help create more seamless user experiences in a variety of domains.","meta":{"url":"http://arxiv.org/abs/2307.15039v1"},"cats":{"new-dataset":0.2284054938,"dev-research":0.3113527557,"prompt-eng":0.4068629357,"data-quality":0.1044337954,"ml-security":0.0684052164}}
{"text":"The question of whether 3-Coloring can be solved in polynomial-time for the diameter two graphs is a well-known open problem in the area of algorithmic graph theory.","meta":{"url":"http://arxiv.org/abs/2307.15036v1"},"cats":{"new-dataset":0.0944898809,"dev-research":0.2127923934,"prompt-eng":0.3365416618,"data-quality":0.2001572641,"ml-security":0.1028946026}}
{"text":"We study the problem restricted to graph classes that avoid cycles of given lengths as induced subgraphs.","meta":{"url":"http://arxiv.org/abs/2307.15036v1"},"cats":{"new-dataset":0.2010696259,"dev-research":0.1882027691,"prompt-eng":0.3033374888,"data-quality":0.2706612069,"ml-security":0.1735320457}}
{"text":"Martin et.","meta":{"url":"http://arxiv.org/abs/2307.15036v1"},"cats":{"new-dataset":0.1363626168,"dev-research":0.1924002252,"prompt-eng":0.3372451603,"data-quality":0.1248197182,"ml-security":0.1010347194}}
{"text":"al.","meta":{"url":"http://arxiv.org/abs/2307.15036v1"},"cats":{"new-dataset":0.2642548532,"dev-research":0.2488256329,"prompt-eng":0.3130166563,"data-quality":0.1139857968,"ml-security":0.1308559211}}
{"text":"[CIAC 2021] showed that the problem is polynomial-time solvable for $C_5$-free or $C_6$-free graphs, and, $(C_4,C_s)$-free graphs where $s \\in \\{3,7,8,9\\}$.","meta":{"url":"http://arxiv.org/abs/2307.15036v1"},"cats":{"new-dataset":0.3293709569,"dev-research":0.1954977749,"prompt-eng":0.3003880192,"data-quality":0.157404503,"ml-security":0.1173186521}}
{"text":"We extend their result proving that it is polynomial-time solvable for $(C_4,C_s)$-free graphs, for any constant $s$, and for $(C_3,C_7)$-free graphs.","meta":{"url":"http://arxiv.org/abs/2307.15036v1"},"cats":{"new-dataset":0.1812922815,"dev-research":0.2047484824,"prompt-eng":0.2904092423,"data-quality":0.1524370446,"ml-security":0.1644562391}}
{"text":"Our results also hold for the more general problem List 3-Colouring.","meta":{"url":"http://arxiv.org/abs/2307.15036v1"},"cats":{"new-dataset":0.4570222059,"dev-research":0.2159380968,"prompt-eng":0.3956086298,"data-quality":0.2624264379,"ml-security":0.0716083896}}
{"text":"The Fourier neural operator (FNO) is a powerful technique for learning surrogate maps for partial differential equation (PDE) solution operators.","meta":{"url":"http://arxiv.org/abs/2307.15034v1"},"cats":{"new-dataset":0.0872026182,"dev-research":0.1983540234,"prompt-eng":0.3499504736,"data-quality":0.0882711444,"ml-security":0.1305062403}}
{"text":"For many real-world applications, which often require high-resolution data points, training time and memory usage are significant bottlenecks.","meta":{"url":"http://arxiv.org/abs/2307.15034v1"},"cats":{"new-dataset":0.1135145476,"dev-research":0.3005534073,"prompt-eng":0.3583739142,"data-quality":0.1686613782,"ml-security":0.1346689844}}
{"text":"While there are mixed-precision training techniques for standard neural networks, those work for real-valued datatypes on finite dimensions and therefore cannot be directly applied to FNO, which crucially operates in the (complex-valued)","meta":{"url":"http://arxiv.org/abs/2307.15034v1"},"cats":{"new-dataset":0.0288360212,"dev-research":0.1829250424,"prompt-eng":0.2779178315,"data-quality":0.2125219833,"ml-security":0.1833123628}}
{"text":"Fourier domain and in function spaces.","meta":{"url":"http://arxiv.org/abs/2307.15034v1"},"cats":{"new-dataset":0.0466007842,"dev-research":0.2983551404,"prompt-eng":0.332444385,"data-quality":0.1477183746,"ml-security":0.1621489035}}
{"text":"On the other hand, since the Fourier transform is already an approximation (due to discretization error), we do not need to perform the operation at full precision.","meta":{"url":"http://arxiv.org/abs/2307.15034v1"},"cats":{"new-dataset":0.0016564071,"dev-research":0.2395942646,"prompt-eng":0.2781486106,"data-quality":0.0920498535,"ml-security":0.0701667965}}
{"text":"In this work, we (i) profile memory and runtime for FNO with full and mixed-precision training, (ii) conduct a study on the numerical stability of mixed-precision training of FNO, and (iii) devise a training routine which substantially decreases training time and memory usage (up to 34%), with little or no reduction in accuracy, on the Navier-Stokes and Darcy flow equations.","meta":{"url":"http://arxiv.org/abs/2307.15034v1"},"cats":{"new-dataset":0.0579343496,"dev-research":0.2654902085,"prompt-eng":0.3104896733,"data-quality":0.0901719689,"ml-security":0.1345653218}}
{"text":"Combined with the recently proposed tensorized FNO (Kossaifi et al., 2023), the resulting model has far better performance while also being significantly faster than the original FNO.","meta":{"url":"http://arxiv.org/abs/2307.15034v1"},"cats":{"new-dataset":0.087523374,"dev-research":0.1202508916,"prompt-eng":0.3500488764,"data-quality":0.1120934437,"ml-security":0.0627254234}}
{"text":"Recent inversion methods have shown that real images can be inverted into StyleGAN's latent space and numerous edits can be achieved on those images thanks to the semantically rich feature representations of well-trained GAN models.","meta":{"url":"http://arxiv.org/abs/2307.15033v1"},"cats":{"new-dataset":0.1352797433,"dev-research":0.2362048461,"prompt-eng":0.3244190625,"data-quality":0.1937805322,"ml-security":0.1999073675}}
{"text":"However, extensive research has also shown that image inversion is challenging due to the trade-off between high-fidelity reconstruction and editability.","meta":{"url":"http://arxiv.org/abs/2307.15033v1"},"cats":{"new-dataset":0.0466675481,"dev-research":0.1980184929,"prompt-eng":0.3688599467,"data-quality":0.1595990681,"ml-security":0.0867398983}}
{"text":"In this paper, we tackle an even more difficult task, inverting erased images into GAN's latent space for realistic inpaintings and editings.","meta":{"url":"http://arxiv.org/abs/2307.15033v1"},"cats":{"new-dataset":0.1399082001,"dev-research":0.2122222048,"prompt-eng":0.332186687,"data-quality":0.2169497299,"ml-security":0.1394702924}}
{"text":"Furthermore, by augmenting inverted latent codes with different latent samples, we achieve diverse inpaintings.","meta":{"url":"http://arxiv.org/abs/2307.15033v1"},"cats":{"new-dataset":0.2082216075,"dev-research":0.1824311926,"prompt-eng":0.3519638793,"data-quality":0.2337781812,"ml-security":0.0767337511}}
{"text":"Specifically, we propose to learn an encoder and mixing network to combine encoded features from erased images with StyleGAN's mapped features from random samples.","meta":{"url":"http://arxiv.org/abs/2307.15033v1"},"cats":{"new-dataset":0.1582953544,"dev-research":0.2571625885,"prompt-eng":0.3425251278,"data-quality":0.3086172322,"ml-security":0.175813338}}
{"text":"To encourage the mixing network to utilize both inputs, we train the networks with generated data via a novel set-up.","meta":{"url":"http://arxiv.org/abs/2307.15033v1"},"cats":{"new-dataset":0.166338988,"dev-research":0.3346988158,"prompt-eng":0.4089440908,"data-quality":0.2479688348,"ml-security":0.1544946572}}
{"text":"We also utilize higher-rate features to prevent color inconsistencies between the inpainted and unerased parts.","meta":{"url":"http://arxiv.org/abs/2307.15033v1"},"cats":{"new-dataset":0.0467822677,"dev-research":0.2959232641,"prompt-eng":0.4224684216,"data-quality":0.3219560197,"ml-security":0.1064808135}}
{"text":"We run extensive experiments and compare our method with state-of-the-art inversion and inpainting methods.","meta":{"url":"http://arxiv.org/abs/2307.15033v1"},"cats":{"new-dataset":0.0439909547,"dev-research":0.1863927184,"prompt-eng":0.3989394307,"data-quality":0.1593863031,"ml-security":0.0449687909}}
{"text":"Qualitative metrics and visual comparisons show significant improvements.","meta":{"url":"http://arxiv.org/abs/2307.15033v1"},"cats":{"new-dataset":0.0908716636,"dev-research":0.3990952665,"prompt-eng":0.3758485835,"data-quality":0.1639926126,"ml-security":0.0491499529}}
{"text":"Inspired by deep convolution segmentation algorithms, scene text detectors break the performance ceiling of datasets steadily.","meta":{"url":"http://arxiv.org/abs/2307.15029v1"},"cats":{"new-dataset":0.334755627,"dev-research":0.1737850862,"prompt-eng":0.3434171837,"data-quality":0.4554836913,"ml-security":0.1842264857}}
{"text":"However, these methods often encounter threshold selection bottlenecks and have poor performance on text instances with extreme aspect ratios.","meta":{"url":"http://arxiv.org/abs/2307.15029v1"},"cats":{"new-dataset":0.0417892516,"dev-research":0.2389452826,"prompt-eng":0.4314477608,"data-quality":0.3105735573,"ml-security":0.0926047573}}
{"text":"In this paper, we propose to automatically learn the discriminate segmentation threshold, which distinguishes text pixels from background pixels for segmentation-based scene text detectors and then further reduces the time-consuming manual parameter adjustment.","meta":{"url":"http://arxiv.org/abs/2307.15029v1"},"cats":{"new-dataset":0.176966609,"dev-research":0.1929429025,"prompt-eng":0.447811306,"data-quality":0.452642951,"ml-security":0.1703121021}}
{"text":"Besides, we design a Global-information Enhanced Feature Pyramid Network (GE-FPN) for capturing text instances with macro size and extreme aspect ratios.","meta":{"url":"http://arxiv.org/abs/2307.15029v1"},"cats":{"new-dataset":0.3343977074,"dev-research":0.2950927451,"prompt-eng":0.3579207288,"data-quality":0.2000428992,"ml-security":0.122239838}}
{"text":"Following the GE-FPN, we introduce a cascade optimization structure to further refine the text instances.","meta":{"url":"http://arxiv.org/abs/2307.15029v1"},"cats":{"new-dataset":0.0881664863,"dev-research":0.2150417523,"prompt-eng":0.4096793332,"data-quality":0.2661803146,"ml-security":0.0728886568}}
{"text":"Finally, together with the proposed threshold learning strategy and text detection structure, we design an Adaptive Segmentation Network (ASNet) for scene text detection.","meta":{"url":"http://arxiv.org/abs/2307.15029v1"},"cats":{"new-dataset":0.1489199616,"dev-research":0.1538999153,"prompt-eng":0.3753457222,"data-quality":0.405231457,"ml-security":0.1761464668}}
{"text":"Extensive experiments are carried out to demonstrate that the proposed ASNet can achieve the state-of-the-art performance on four text detection benchmarks, i.e., ICDAR 2015, MSRA-TD500, ICDAR 2017 MLT and CTW1500.","meta":{"url":"http://arxiv.org/abs/2307.15029v1"},"cats":{"new-dataset":0.2206173957,"dev-research":0.219531389,"prompt-eng":0.3817605612,"data-quality":0.4068735112,"ml-security":0.1558370464}}
{"text":"The ablation experiments also verify the effectiveness of our contributions.","meta":{"url":"http://arxiv.org/abs/2307.15029v1"},"cats":{"new-dataset":0.0496351548,"dev-research":0.1813447115,"prompt-eng":0.3608556155,"data-quality":0.1549365551,"ml-security":0.0490340384}}
{"text":"Decentralized architecture offers a robust and flexible structure for online platforms, since centralized moderation and computation can be easy to disrupt with targeted attacks.","meta":{"url":"http://arxiv.org/abs/2307.15027v1"},"cats":{"new-dataset":0.0721985076,"dev-research":0.2668024919,"prompt-eng":0.3947292387,"data-quality":0.1190464456,"ml-security":0.5295851074}}
{"text":"However, a platform offering a decentralized architecture does not guarantee that users will use it in a decentralized way, and measuring the centralization of socio-technical networks is not an easy task.","meta":{"url":"http://arxiv.org/abs/2307.15027v1"},"cats":{"new-dataset":0.0552067585,"dev-research":0.3077400269,"prompt-eng":0.3834702614,"data-quality":0.1161250234,"ml-security":0.1366193841}}
{"text":"In this paper we introduce a method of characterizing community influence in terms of how many edges between communities would be disrupted by a community's removal.","meta":{"url":"http://arxiv.org/abs/2307.15027v1"},"cats":{"new-dataset":0.0285354188,"dev-research":0.2928476412,"prompt-eng":0.3654831062,"data-quality":0.244673722,"ml-security":0.3109804537}}
{"text":"Our approach provides a careful definition of \"centralization\" appropriate in bipartite user-community socio-technical networks, and demonstrates the inadequacy of more trivial methods for interrogating centralization such as examining the distribution of community sizes.","meta":{"url":"http://arxiv.org/abs/2307.15027v1"},"cats":{"new-dataset":0.0968768262,"dev-research":0.3155580141,"prompt-eng":0.374633638,"data-quality":0.1617429853,"ml-security":0.1006738789}}
{"text":"We use this method to compare the structure of multiple socio-technical platforms -- Mastodon, git code hosting servers, BitChute, Usenet, and Voat -- and find a range of structures, from interconnected but decentralized git servers to an effectively centralized use of Mastodon servers, as well as multiscale hybrid network structures of disconnected Voat subverses.","meta":{"url":"http://arxiv.org/abs/2307.15027v1"},"cats":{"new-dataset":0.3965514046,"dev-research":0.3647896428,"prompt-eng":0.4098121468,"data-quality":0.1209668319,"ml-security":0.0693687918}}
{"text":"As the ecosystem of socio-technical platforms diversifies, it becomes critical to not solely focus on the underlying technologies but also consider the structure of how users interact through the technical infrastructure.","meta":{"url":"http://arxiv.org/abs/2307.15027v1"},"cats":{"new-dataset":0.089376585,"dev-research":0.4869348063,"prompt-eng":0.4150110394,"data-quality":0.0885215926,"ml-security":0.102371872}}
{"text":"This letter proposes advanced beamforming design and analyzes its influence on the sensing and communications (S&C) performance for a multiple-antenna integrated S&C (ISAC) system with a single communication user and a single target.","meta":{"url":"http://arxiv.org/abs/2307.15023v1"},"cats":{"new-dataset":0.0139157731,"dev-research":0.2376648822,"prompt-eng":0.4422178233,"data-quality":0.082906126,"ml-security":0.0609097312}}
{"text":"Novel closed-form beamformers are derived for three typical scenarios, including the sensing-centric design, communications-centric design, and Pareto optimal design.","meta":{"url":"http://arxiv.org/abs/2307.15023v1"},"cats":{"new-dataset":0.0308105562,"dev-research":0.1936360721,"prompt-eng":0.4332389147,"data-quality":0.096288817,"ml-security":0.0634503079}}
{"text":"Regarding each scenario, the outage probability, ergodic communication rate (CR), and sensing rate (SR) are analyzed to derive the diversity orders and high signal-to-noise ratio slopes.","meta":{"url":"http://arxiv.org/abs/2307.15023v1"},"cats":{"new-dataset":0.0896364058,"dev-research":0.1520548088,"prompt-eng":0.3687646947,"data-quality":0.1693324519,"ml-security":0.1231559612}}
{"text":"Numerical results are provided to demonstrate that i) beamforming design can affect the high-SNR power offset and diversity order but does not influence the high-SNR slope; ii) ISAC exhibits larger high-SNR slopes and a more extensive SR-CR region than conventional frequency-division S&C (FDSAC) techniques.","meta":{"url":"http://arxiv.org/abs/2307.15023v1"},"cats":{"new-dataset":0.0367663623,"dev-research":0.2122012188,"prompt-eng":0.3789004355,"data-quality":0.130197829,"ml-security":0.0634936994}}
{"text":"Large language models (LLMs) have shown the potential to be integrated into human daily lives.","meta":{"url":"http://arxiv.org/abs/2307.15020v1"},"cats":{"new-dataset":0.0937011782,"dev-research":0.1783658614,"prompt-eng":0.3820043761,"data-quality":0.1094113136,"ml-security":0.0763964854}}
{"text":"Therefore, user preference is the most critical criterion for assessing LLMs' performance in real-world scenarios.","meta":{"url":"http://arxiv.org/abs/2307.15020v1"},"cats":{"new-dataset":0.0063555864,"dev-research":0.2528278159,"prompt-eng":0.4785138047,"data-quality":0.0940100425,"ml-security":0.1006424573}}
{"text":"However, existing benchmarks mainly focus on measuring models' accuracy using multi-choice questions, which limits the understanding of their capabilities in real applications.","meta":{"url":"http://arxiv.org/abs/2307.15020v1"},"cats":{"new-dataset":0.0310296095,"dev-research":0.2546516651,"prompt-eng":0.410448692,"data-quality":0.1731920632,"ml-security":0.0656921202}}
{"text":"We fill this gap by proposing a comprehensive Chinese benchmark SuperCLUE, named after another popular Chinese LLM benchmark CLUE.","meta":{"url":"http://arxiv.org/abs/2307.15020v1"},"cats":{"new-dataset":0.3537464066,"dev-research":0.203418808,"prompt-eng":0.4086338923,"data-quality":0.1502582564,"ml-security":0.0631284253}}
{"text":"SuperCLUE encompasses three sub-tasks: actual users' queries and ratings derived from an LLM battle platform (CArena), open-ended questions with single and multiple-turn dialogues (OPEN), and closed-ended questions with the same stems as open-ended single-turn ones (CLOSE).","meta":{"url":"http://arxiv.org/abs/2307.15020v1"},"cats":{"new-dataset":0.1183641772,"dev-research":0.2945581685,"prompt-eng":0.424817368,"data-quality":0.0756037934,"ml-security":0.0593731784}}
{"text":"Our study shows that accuracy on closed-ended questions is insufficient to reflect human preferences achieved on open-ended ones.","meta":{"url":"http://arxiv.org/abs/2307.15020v1"},"cats":{"new-dataset":0.0485628144,"dev-research":0.3197179597,"prompt-eng":0.4770181141,"data-quality":0.3198155393,"ml-security":0.1341975017}}
{"text":"At the same time, they can complement each other to predict actual user preferences.","meta":{"url":"http://arxiv.org/abs/2307.15020v1"},"cats":{"new-dataset":0.0046563161,"dev-research":0.3216947966,"prompt-eng":0.4755840203,"data-quality":0.1043073383,"ml-security":0.1222407858}}
{"text":"We also demonstrate that GPT-4 is a reliable judge to automatically evaluate human preferences on open-ended questions in a Chinese context.","meta":{"url":"http://arxiv.org/abs/2307.15020v1"},"cats":{"new-dataset":0.1373253264,"dev-research":0.2975471982,"prompt-eng":0.4890390835,"data-quality":0.2752978714,"ml-security":0.100575398}}
{"text":"Our benchmark will be released at https://www.CLUEbenchmarks.com","meta":{"url":"http://arxiv.org/abs/2307.15020v1"},"cats":{"new-dataset":0.5053619286,"dev-research":0.2469093672,"prompt-eng":0.4306214294,"data-quality":0.1670390184,"ml-security":0.0649665845}}
{"text":"Deepfake detection methods have shown promising results in recognizing forgeries within a given dataset, where training and testing take place on the in-distribution dataset.","meta":{"url":"http://arxiv.org/abs/2307.15019v1"},"cats":{"new-dataset":0.392708352,"dev-research":0.2133572222,"prompt-eng":0.3540647243,"data-quality":0.4528519891,"ml-security":0.3848107957}}
{"text":"However, their performance deteriorates significantly when presented with unseen samples.","meta":{"url":"http://arxiv.org/abs/2307.15019v1"},"cats":{"new-dataset":0.0275738957,"dev-research":0.273631945,"prompt-eng":0.3545470083,"data-quality":0.3802880459,"ml-security":0.1520265006}}
{"text":"As a result, a reliable deepfake detection system must remain impartial to forgery types, appearance, and quality for guaranteed generalizable detection performance.","meta":{"url":"http://arxiv.org/abs/2307.15019v1"},"cats":{"new-dataset":0.1224688075,"dev-research":0.2375160244,"prompt-eng":0.3894825091,"data-quality":0.4227569054,"ml-security":0.3046829317}}
{"text":"Despite various attempts to enhance cross-dataset generalization, the problem remains challenging, particularly when testing against common post-processing perturbations, such as video compression or blur.","meta":{"url":"http://arxiv.org/abs/2307.15019v1"},"cats":{"new-dataset":0.2614517777,"dev-research":0.1898844701,"prompt-eng":0.3353339281,"data-quality":0.3688076419,"ml-security":0.2118115214}}
{"text":"Hence, this study introduces a deepfake detection framework, leveraging a self-supervised pre-training model that delivers exceptional generalization ability, withstanding common corruptions and enabling feature explainability.","meta":{"url":"http://arxiv.org/abs/2307.15019v1"},"cats":{"new-dataset":0.2327278433,"dev-research":0.3377299759,"prompt-eng":0.42860808,"data-quality":0.3780232812,"ml-security":0.3302799044}}
{"text":"The framework comprises three key components: a feature extractor based on vision Transformer architecture that is pre-trained via self-supervised contrastive learning methodology, a graph convolution network coupled with a Transformer discriminator, and a graph Transformer relevancy map that provides a better understanding of manipulated regions and further explains the model's decision.","meta":{"url":"http://arxiv.org/abs/2307.15019v1"},"cats":{"new-dataset":0.1605925707,"dev-research":0.252880775,"prompt-eng":0.3884049333,"data-quality":0.1709101559,"ml-security":0.0870553396}}
{"text":"To assess the effectiveness of the proposed framework, several challenging experiments are conducted, including in-data distribution performance, cross-dataset, cross-manipulation generalization, and robustness against common post-production perturbations.","meta":{"url":"http://arxiv.org/abs/2307.15019v1"},"cats":{"new-dataset":0.1394037151,"dev-research":0.2649048188,"prompt-eng":0.4311243355,"data-quality":0.2731296748,"ml-security":0.1336909805}}
{"text":"The results achieved demonstrate the remarkable effectiveness of the proposed deepfake detection framework, surpassing the current state-of-the-art approaches.","meta":{"url":"http://arxiv.org/abs/2307.15019v1"},"cats":{"new-dataset":0.193615379,"dev-research":0.2252845233,"prompt-eng":0.3864174157,"data-quality":0.3019839804,"ml-security":0.2136483624}}
{"text":"We revisit the problem of designing scalable protocols for private statistics and private federated learning when each device holds its private data.","meta":{"url":"http://arxiv.org/abs/2307.15017v1"},"cats":{"new-dataset":0.2822374818,"dev-research":0.1935038232,"prompt-eng":0.3575232425,"data-quality":0.1347949897,"ml-security":0.4469685462}}
{"text":"Our first contribution is to propose a simple primitive that allows for efficient implementation of several commonly used algorithms, and allows for privacy accounting that is close to that in the central setting without requiring the strong trust assumptions it entails.","meta":{"url":"http://arxiv.org/abs/2307.15017v1"},"cats":{"new-dataset":0.1993395593,"dev-research":0.1999998559,"prompt-eng":0.3845444119,"data-quality":0.19379126,"ml-security":0.3387174592}}
{"text":"Second, we propose a system architecture that implements this primitive and perform a security analysis of the proposed system.","meta":{"url":"http://arxiv.org/abs/2307.15017v1"},"cats":{"new-dataset":0.0727125852,"dev-research":0.3232637613,"prompt-eng":0.4765155407,"data-quality":0.144823657,"ml-security":0.4976002404}}
{"text":"Google's Bard has emerged as a formidable competitor to OpenAI's ChatGPT in the field of conversational AI.","meta":{"url":"http://arxiv.org/abs/2307.15016v1"},"cats":{"new-dataset":0.3957086332,"dev-research":0.2735542299,"prompt-eng":0.3148883773,"data-quality":0.1260838611,"ml-security":0.1307049433}}
{"text":"Notably, Bard has recently been updated to handle visual inputs alongside text prompts during conversations.","meta":{"url":"http://arxiv.org/abs/2307.15016v1"},"cats":{"new-dataset":0.2614983059,"dev-research":0.4035362496,"prompt-eng":0.4813081822,"data-quality":0.1869576009,"ml-security":0.1112976464}}
{"text":"Given Bard's impressive track record in handling textual inputs, we explore its capabilities in understanding and interpreting visual data (images) conditioned by text questions.","meta":{"url":"http://arxiv.org/abs/2307.15016v1"},"cats":{"new-dataset":0.3105445772,"dev-research":0.3600151297,"prompt-eng":0.4521822908,"data-quality":0.3436937296,"ml-security":0.118673745}}
{"text":"This exploration holds the potential to unveil new insights and challenges for Bard and other forthcoming multi-modal Generative models, especially in addressing complex computer vision problems that demand accurate visual and language understanding.","meta":{"url":"http://arxiv.org/abs/2307.15016v1"},"cats":{"new-dataset":0.1608228165,"dev-research":0.2441580809,"prompt-eng":0.3675903696,"data-quality":0.1657943547,"ml-security":0.0794711612}}
{"text":"Specifically, in this study, we focus on 15 diverse task scenarios encompassing regular, camouflaged, medical, under-water and remote sensing data to comprehensively evaluate Bard's performance.","meta":{"url":"http://arxiv.org/abs/2307.15016v1"},"cats":{"new-dataset":0.4564271693,"dev-research":0.2504223627,"prompt-eng":0.4345389265,"data-quality":0.1617382641,"ml-security":0.0765538497}}
{"text":"Our primary finding indicates that Bard still struggles in these vision scenarios, highlighting the significant gap in vision-based understanding that needs to be bridged in future developments.","meta":{"url":"http://arxiv.org/abs/2307.15016v1"},"cats":{"new-dataset":0.1430451581,"dev-research":0.3406094623,"prompt-eng":0.3802291262,"data-quality":0.2597509568,"ml-security":0.1130074786}}
{"text":"We expect that this empirical study will prove valuable in advancing future models, leading to enhanced capabilities in comprehending and interpreting fine-grained visual data.","meta":{"url":"http://arxiv.org/abs/2307.15016v1"},"cats":{"new-dataset":0.2234724728,"dev-research":0.2683013429,"prompt-eng":0.3621291266,"data-quality":0.1415382039,"ml-security":0.0859277904}}
{"text":"Our project is released on https://github.com/htqin/GoogleBard-VisUnderstand","meta":{"url":"http://arxiv.org/abs/2307.15016v1"},"cats":{"new-dataset":0.3869166063,"dev-research":0.2108408281,"prompt-eng":0.3896388754,"data-quality":0.0959922593,"ml-security":0.055219231}}
{"text":"With the increased deployment of machine learning models in various real-world applications, researchers and practitioners alike have emphasized the need for explanations of model behaviour.","meta":{"url":"http://arxiv.org/abs/2307.15007v1"},"cats":{"new-dataset":0.0171283293,"dev-research":0.3444701563,"prompt-eng":0.4250127884,"data-quality":0.2172018191,"ml-security":0.3580032966}}
{"text":"To this end, two broad strategies have been outlined in prior literature to explain models.","meta":{"url":"http://arxiv.org/abs/2307.15007v1"},"cats":{"new-dataset":0.016451136,"dev-research":0.2382946294,"prompt-eng":0.3978043818,"data-quality":0.0977651921,"ml-security":0.0868621855}}
{"text":"Post hoc explanation methods explain the behaviour of complex black-box models by highlighting features that are critical to model predictions; however, prior work has shown that these explanations may not be faithful, and even more concerning is our inability to verify them.","meta":{"url":"http://arxiv.org/abs/2307.15007v1"},"cats":{"new-dataset":0.0145090016,"dev-research":0.316667803,"prompt-eng":0.3820555416,"data-quality":0.21057813,"ml-security":0.3476910691}}
{"text":"Specifically, it is nontrivial to evaluate if a given attribution is correct with respect to the underlying model.","meta":{"url":"http://arxiv.org/abs/2307.15007v1"},"cats":{"new-dataset":0.005390745,"dev-research":0.2163695685,"prompt-eng":0.3894123564,"data-quality":0.3611405865,"ml-security":0.1988552067}}
{"text":"Inherently interpretable models, on the other hand, circumvent these issues by explicitly encoding explanations into model architecture, meaning their explanations are naturally faithful and verifiable, but they often exhibit poor predictive performance due to their limited expressive power.","meta":{"url":"http://arxiv.org/abs/2307.15007v1"},"cats":{"new-dataset":0.0139981575,"dev-research":0.3777530955,"prompt-eng":0.3759231766,"data-quality":0.2702587127,"ml-security":0.3559795084}}
{"text":"In this work, we aim to bridge the gap between the aforementioned strategies by proposing Verifiability Tuning (VerT), a method that transforms black-box models into models that naturally yield faithful and verifiable feature attributions.","meta":{"url":"http://arxiv.org/abs/2307.15007v1"},"cats":{"new-dataset":0.1062864778,"dev-research":0.2856353353,"prompt-eng":0.4250662336,"data-quality":0.2959510891,"ml-security":0.317674438}}
{"text":"We begin by introducing a formal theoretical framework to understand verifiability and show that attributions produced by standard models cannot be verified.","meta":{"url":"http://arxiv.org/abs/2307.15007v1"},"cats":{"new-dataset":0.0466097939,"dev-research":0.2349518005,"prompt-eng":0.4154781519,"data-quality":0.3042986807,"ml-security":0.3344580537}}
{"text":"We then leverage this framework to propose a method to build verifiable models and feature attributions out of fully trained black-box models.","meta":{"url":"http://arxiv.org/abs/2307.15007v1"},"cats":{"new-dataset":0.1239274984,"dev-research":0.2771188169,"prompt-eng":0.388983601,"data-quality":0.3175687889,"ml-security":0.4774290017}}
{"text":"Finally, we perform extensive experiments on semi-synthetic and real-world datasets, and show that VerT produces models that (1) yield explanations that are correct and verifiable and (2) are faithful to the original black-box models they are meant to explain.","meta":{"url":"http://arxiv.org/abs/2307.15007v1"},"cats":{"new-dataset":0.2359907897,"dev-research":0.2865715632,"prompt-eng":0.382571335,"data-quality":0.2322215808,"ml-security":0.2709295599}}
{"text":"Light detection and ranging (LiDAR) sensors are becoming available on modern mobile devices and provide a 3D sensing capability.","meta":{"url":"http://arxiv.org/abs/2307.15005v1"},"cats":{"new-dataset":0.1048428045,"dev-research":0.1869216723,"prompt-eng":0.3523608984,"data-quality":0.0856384196,"ml-security":0.0952588512}}
{"text":"This new capability is beneficial for perceptions in various use cases, but it is challenging for resource-constrained mobile devices to use the perceptions in real-time because of their high computational complexity.","meta":{"url":"http://arxiv.org/abs/2307.15005v1"},"cats":{"new-dataset":0.0439498182,"dev-research":0.2805675601,"prompt-eng":0.4318498538,"data-quality":0.1156335199,"ml-security":0.0945996585}}
{"text":"In this context, edge computing can be used to enable LiDAR online perceptions, but offloading the perceptions on the edge server requires a low-latency, lightweight, and efficient compression due to the large volume of LiDAR point clouds data.   ","meta":{"url":"http://arxiv.org/abs/2307.15005v1"},"cats":{"new-dataset":0.042932592,"dev-research":0.2737112868,"prompt-eng":0.3091768394,"data-quality":0.097597266,"ml-security":0.1410980979}}
{"text":"This paper presents FLiCR, a fast and lightweight LiDAR point cloud compression method for enabling edge-assisted online perceptions.","meta":{"url":"http://arxiv.org/abs/2307.15005v1"},"cats":{"new-dataset":0.0412824347,"dev-research":0.2457085491,"prompt-eng":0.3375792297,"data-quality":0.1087146502,"ml-security":0.0884722496}}
{"text":"FLiCR is based on range images (RI) as an intermediate representation (IR), and dictionary coding for compressing RIs.","meta":{"url":"http://arxiv.org/abs/2307.15005v1"},"cats":{"new-dataset":0.2967146704,"dev-research":0.1900696128,"prompt-eng":0.3922059469,"data-quality":0.1031557131,"ml-security":0.0390717529}}
{"text":"FLiCR achieves its benefits by leveraging lossy RIs, and we show the efficiency of bytestream compression is largely improved with quantization and subsampling.","meta":{"url":"http://arxiv.org/abs/2307.15005v1"},"cats":{"new-dataset":0.1653319574,"dev-research":0.2390393369,"prompt-eng":0.3428243532,"data-quality":0.185094678,"ml-security":0.1092022943}}
{"text":"In addition, we identify the limitation of current quality metrics for presenting the entropy of a point cloud, and introduce a new metric that reflects both point-wise and entropy-wise qualities for lossy IRs.","meta":{"url":"http://arxiv.org/abs/2307.15005v1"},"cats":{"new-dataset":0.1008044597,"dev-research":0.1952030152,"prompt-eng":0.3755858642,"data-quality":0.2995190935,"ml-security":0.0890526992}}
{"text":"The evaluation results show FLiCR is more suitable for edge-assisted real-time perceptions than the existing LiDAR compressions, and we demonstrate the effectiveness of our compression and metric with the evaluations on 3D object detection and LiDAR SLAM.","meta":{"url":"http://arxiv.org/abs/2307.15005v1"},"cats":{"new-dataset":0.0824369045,"dev-research":0.2500057178,"prompt-eng":0.3586246298,"data-quality":0.1338071511,"ml-security":0.0973101824}}
{"text":"The effectiveness of compression distance in KNN-based text classification ('gzip') has recently garnered lots of attention.","meta":{"url":"http://arxiv.org/abs/2307.15002v1"},"cats":{"new-dataset":0.1718610772,"dev-research":0.1753091996,"prompt-eng":0.3317243088,"data-quality":0.3041324062,"ml-security":0.1059444749}}
{"text":"In this note, we show that similar or better effectiveness can be achieved with simpler means, and text compression may not be necessary.","meta":{"url":"http://arxiv.org/abs/2307.15002v1"},"cats":{"new-dataset":0.0746450557,"dev-research":0.2709908646,"prompt-eng":0.398405649,"data-quality":0.347018224,"ml-security":0.1265863626}}
{"text":"Indeed, we find that a simple 'bag-of-words' matching can achieve similar or better accuracy, and is more efficient.","meta":{"url":"http://arxiv.org/abs/2307.15002v1"},"cats":{"new-dataset":0.0991160463,"dev-research":0.2194791593,"prompt-eng":0.4159861573,"data-quality":0.3591815833,"ml-security":0.049255981}}
{"text":"We present TransNormerLLM, the first linear attention-based Large Language Model (LLM) that outperforms conventional softmax attention-based models in terms of both accuracy and efficiency.","meta":{"url":"http://arxiv.org/abs/2307.14995v1"},"cats":{"new-dataset":0.2374955212,"dev-research":0.1562032607,"prompt-eng":0.3506290498,"data-quality":0.2066361537,"ml-security":0.112818664}}
{"text":"TransNormerLLM evolves from the previous linear attention architecture TransNormer by making advanced modifications that include positional embedding, linear attention acceleration, gating mechanism, tensor normalization, inference acceleration and stabilization.","meta":{"url":"http://arxiv.org/abs/2307.14995v1"},"cats":{"new-dataset":0.0577342574,"dev-research":0.2140324459,"prompt-eng":0.3835651327,"data-quality":0.1213390546,"ml-security":0.1188233667}}
{"text":"Specifically, we use LRPE together with an exponential decay to avoid attention dilution issues while allowing the model to retain global interactions between tokens.","meta":{"url":"http://arxiv.org/abs/2307.14995v1"},"cats":{"new-dataset":0.0598742186,"dev-research":0.1846892447,"prompt-eng":0.4271764623,"data-quality":0.1282213972,"ml-security":0.1159130316}}
{"text":"Additionally, we propose Lightning Attention, a cutting-edge technique that accelerates linear attention by more than twice in runtime and reduces memory usage by a remarkable four times.","meta":{"url":"http://arxiv.org/abs/2307.14995v1"},"cats":{"new-dataset":0.063459866,"dev-research":0.3315353648,"prompt-eng":0.438249679,"data-quality":0.2100276272,"ml-security":0.2068111793}}
{"text":"To further enhance the performance of TransNormer, we leverage a gating mechanism to smooth training and a new tensor normalization scheme to accelerate the model, resulting in an impressive acceleration of over 20%.","meta":{"url":"http://arxiv.org/abs/2307.14995v1"},"cats":{"new-dataset":0.0528707087,"dev-research":0.2195616116,"prompt-eng":0.3876747325,"data-quality":0.1341316787,"ml-security":0.0897038189}}
{"text":"Furthermore, we have developed a robust inference algorithm that ensures numerical stability and consistent inference speed, regardless of the sequence length, showcasing superior efficiency during both training and inference stages.","meta":{"url":"http://arxiv.org/abs/2307.14995v1"},"cats":{"new-dataset":0.1282335018,"dev-research":0.228404687,"prompt-eng":0.4227127016,"data-quality":0.2395935077,"ml-security":0.1334444619}}
{"text":"Scalability is at the heart of our model's design, enabling seamless deployment on large-scale clusters and facilitating expansion to even more extensive models, all while maintaining outstanding performance metrics.","meta":{"url":"http://arxiv.org/abs/2307.14995v1"},"cats":{"new-dataset":0.1344697491,"dev-research":0.2534938734,"prompt-eng":0.3754364616,"data-quality":0.1200174522,"ml-security":0.0950034141}}
{"text":"Rigorous validation of our model design is achieved through a series of comprehensive experiments on our self-collected corpus, boasting a size exceeding 6TB and containing over 2 trillion tokens.","meta":{"url":"http://arxiv.org/abs/2307.14995v1"},"cats":{"new-dataset":0.3857888345,"dev-research":0.2070380117,"prompt-eng":0.4364209078,"data-quality":0.2893408504,"ml-security":0.1119647281}}
{"text":"To ensure data quality and relevance, we implement a new self-cleaning strategy to filter our collected data.","meta":{"url":"http://arxiv.org/abs/2307.14995v1"},"cats":{"new-dataset":0.0825597134,"dev-research":0.3101971435,"prompt-eng":0.4218539882,"data-quality":0.3823472225,"ml-security":0.1284461054}}
{"text":"Our pre-trained models will be released to foster community advancements in efficient LLMs.","meta":{"url":"http://arxiv.org/abs/2307.14995v1"},"cats":{"new-dataset":0.1079137546,"dev-research":0.2105305037,"prompt-eng":0.4419113316,"data-quality":0.1129474549,"ml-security":0.1688476436}}
{"text":"We propose the Thinker algorithm, a novel approach that enables reinforcement learning agents to autonomously interact with and utilize a learned world model.","meta":{"url":"http://arxiv.org/abs/2307.14993v1"},"cats":{"new-dataset":0.1039583669,"dev-research":0.2225547772,"prompt-eng":0.4170979054,"data-quality":0.0891877595,"ml-security":0.1142796925}}
{"text":"The Thinker algorithm wraps the environment with a world model and introduces new actions designed for interacting with the world model.","meta":{"url":"http://arxiv.org/abs/2307.14993v1"},"cats":{"new-dataset":0.1358172967,"dev-research":0.2759359023,"prompt-eng":0.4443725219,"data-quality":0.0709118661,"ml-security":0.0989877843}}
{"text":"These model-interaction actions enable agents to perform planning by proposing alternative plans to the world model before selecting a final action to execute in the environment.","meta":{"url":"http://arxiv.org/abs/2307.14993v1"},"cats":{"new-dataset":0.1249433663,"dev-research":0.3131991568,"prompt-eng":0.4425894129,"data-quality":0.0373474961,"ml-security":0.0727929553}}
{"text":"This approach eliminates the need for hand-crafted planning algorithms by enabling the agent to learn how to plan autonomously and allows for easy interpretation of the agent's plan with visualization.","meta":{"url":"http://arxiv.org/abs/2307.14993v1"},"cats":{"new-dataset":0.1689884391,"dev-research":0.3745143675,"prompt-eng":0.4119302551,"data-quality":0.0604213112,"ml-security":0.0864433205}}
{"text":"We demonstrate the algorithm's effectiveness through experimental results in the game of Sokoban and the Atari 2600 benchmark, where the Thinker algorithm achieves state-of-the-art performance and competitive results, respectively.","meta":{"url":"http://arxiv.org/abs/2307.14993v1"},"cats":{"new-dataset":0.1160959929,"dev-research":0.2992632683,"prompt-eng":0.4199197629,"data-quality":0.1102002851,"ml-security":0.1201546353}}
{"text":"Visualizations of agents trained with the Thinker algorithm demonstrate that they have learned to plan effectively with the world model to select better actions.","meta":{"url":"http://arxiv.org/abs/2307.14993v1"},"cats":{"new-dataset":0.1736141421,"dev-research":0.2871469331,"prompt-eng":0.3913250602,"data-quality":0.0620758666,"ml-security":0.1104048452}}
{"text":"The algorithm's generality opens a new research direction on how a world model can be used in reinforcement learning and how planning can be seamlessly integrated into an agent's decision-making process.","meta":{"url":"http://arxiv.org/abs/2307.14993v1"},"cats":{"new-dataset":0.0838606618,"dev-research":0.2384082442,"prompt-eng":0.3730294461,"data-quality":0.0672198816,"ml-security":0.1333862227}}
{"text":"Many software projects implement APIs and algorithms in multiple programming languages.","meta":{"url":"http://arxiv.org/abs/2307.14991v1"},"cats":{"new-dataset":0.0623150404,"dev-research":0.4272276714,"prompt-eng":0.3498639342,"data-quality":0.1046043163,"ml-security":0.1036448032}}
{"text":"Maintaining such projects is tiresome, as developers have to ensure that any change (e.g., a bug fix or a new feature) is being propagated, timely and without errors, to implementations in other programming languages.","meta":{"url":"http://arxiv.org/abs/2307.14991v1"},"cats":{"new-dataset":0.0612448816,"dev-research":0.6036300601,"prompt-eng":0.3942756641,"data-quality":0.2348980694,"ml-security":0.1487360359}}
{"text":"In the world of ever-changing software, using rule-based translation tools (i.e., transpilers) or machine learning models for translating code from one language to another provides limited value.","meta":{"url":"http://arxiv.org/abs/2307.14991v1"},"cats":{"new-dataset":0.1764599857,"dev-research":0.3703356968,"prompt-eng":0.4232276139,"data-quality":0.2017149919,"ml-security":0.0834111177}}
{"text":"Translating each time the entire codebase from one language to another is not the way developers work.","meta":{"url":"http://arxiv.org/abs/2307.14991v1"},"cats":{"new-dataset":0.0238019746,"dev-research":0.4999987559,"prompt-eng":0.3824187556,"data-quality":0.3262784308,"ml-security":0.1353103038}}
{"text":"In this paper, we target a novel task: translating code changes from one programming language to another using large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2307.14991v1"},"cats":{"new-dataset":0.2947472345,"dev-research":0.3368253442,"prompt-eng":0.447426056,"data-quality":0.2013915003,"ml-security":0.1238951642}}
{"text":"We design and implement the first LLM, dubbed Codeditor, to tackle this task.","meta":{"url":"http://arxiv.org/abs/2307.14991v1"},"cats":{"new-dataset":0.2169552054,"dev-research":0.2792029515,"prompt-eng":0.5128457946,"data-quality":0.1384048082,"ml-security":0.0509825506}}
{"text":"Codeditor explicitly models code changes as edit sequences and learns to correlate changes across programming languages.","meta":{"url":"http://arxiv.org/abs/2307.14991v1"},"cats":{"new-dataset":0.1068763892,"dev-research":0.4896357916,"prompt-eng":0.4219601895,"data-quality":0.2613925472,"ml-security":0.1505931763}}
{"text":"To evaluate Codeditor, we collect a corpus of 6,613 aligned code changes from 8 pairs of open-source software projects implementing similar functionalities in two programming languages (Java and C#).","meta":{"url":"http://arxiv.org/abs/2307.14991v1"},"cats":{"new-dataset":0.4724687998,"dev-research":0.4545145655,"prompt-eng":0.4234324463,"data-quality":0.231301961,"ml-security":0.083625525}}
{"text":"Results show that Codeditor outperforms the state-of-the-art approaches by a large margin on all commonly used automatic metrics.","meta":{"url":"http://arxiv.org/abs/2307.14991v1"},"cats":{"new-dataset":0.0839202597,"dev-research":0.4057461462,"prompt-eng":0.4766487819,"data-quality":0.2510917655,"ml-security":0.0602939091}}
{"text":"Our work also reveals that Codeditor is complementary to the existing generation-based models, and their combination ensures even greater performance.","meta":{"url":"http://arxiv.org/abs/2307.14991v1"},"cats":{"new-dataset":0.0992649447,"dev-research":0.3607468587,"prompt-eng":0.4370596551,"data-quality":0.1219503767,"ml-security":0.0533218628}}
{"text":"Deep learning often faces the challenge of efficiently processing dynamic inputs, such as sensor data or user inputs.","meta":{"url":"http://arxiv.org/abs/2307.14988v1"},"cats":{"new-dataset":0.1005531596,"dev-research":0.2708289686,"prompt-eng":0.3755340695,"data-quality":0.1710342009,"ml-security":0.3463814968}}
{"text":"For example, an AI writing assistant is required to update its suggestions in real time as a document is edited.","meta":{"url":"http://arxiv.org/abs/2307.14988v1"},"cats":{"new-dataset":0.0291915594,"dev-research":0.4388812532,"prompt-eng":0.424384128,"data-quality":0.1467672355,"ml-security":0.1411301736}}
{"text":"Re-running the model each time is expensive, even with compression techniques like knowledge distillation, pruning, or quantization.","meta":{"url":"http://arxiv.org/abs/2307.14988v1"},"cats":{"new-dataset":0.0241678562,"dev-research":0.2868259681,"prompt-eng":0.3708574504,"data-quality":0.1307834388,"ml-security":0.0991718635}}
{"text":"Instead, we take an incremental computing approach, looking to reuse calculations as the inputs change.","meta":{"url":"http://arxiv.org/abs/2307.14988v1"},"cats":{"new-dataset":0.0586149959,"dev-research":0.328632692,"prompt-eng":0.423805537,"data-quality":0.0956793083,"ml-security":0.0942643095}}
{"text":"However, the dense connectivity of conventional architectures poses a major obstacle to incremental computation, as even minor input changes cascade through the network and restrict information reuse.","meta":{"url":"http://arxiv.org/abs/2307.14988v1"},"cats":{"new-dataset":0.0373710432,"dev-research":0.3553210004,"prompt-eng":0.3614560269,"data-quality":0.1202909939,"ml-security":0.1530441631}}
{"text":"To address this, we use vector quantization to discretize intermediate values in the network, which filters out noisy and unnecessary modifications to hidden neurons, facilitating the reuse of their values.","meta":{"url":"http://arxiv.org/abs/2307.14988v1"},"cats":{"new-dataset":0.0550772186,"dev-research":0.2883467616,"prompt-eng":0.3584442278,"data-quality":0.2125312423,"ml-security":0.2979395479}}
{"text":"We apply this approach to the transformers architecture, creating an efficient incremental inference algorithm with complexity proportional to the fraction of the modified inputs.","meta":{"url":"http://arxiv.org/abs/2307.14988v1"},"cats":{"new-dataset":0.0790932671,"dev-research":0.2539109723,"prompt-eng":0.4338646924,"data-quality":0.1209077312,"ml-security":0.1014498914}}
{"text":"Our experiments with adapting the OPT-125M pre-trained language model demonstrate comparable accuracy on document classification while requiring 12.1X (median) fewer operations for processing sequences of atomic edits.","meta":{"url":"http://arxiv.org/abs/2307.14988v1"},"cats":{"new-dataset":0.1153231569,"dev-research":0.2421948712,"prompt-eng":0.4087093005,"data-quality":0.3668017438,"ml-security":0.0799690258}}
{"text":"Social network simulation plays a crucial role in addressing various challenges within social science.","meta":{"url":"http://arxiv.org/abs/2307.14984v1"},"cats":{"new-dataset":0.0766286936,"dev-research":0.2788547236,"prompt-eng":0.3238255859,"data-quality":0.158435073,"ml-security":0.1434935458}}
{"text":"It offers extensive applications such as state prediction, phenomena explanation, and policy-making support, among others.","meta":{"url":"http://arxiv.org/abs/2307.14984v1"},"cats":{"new-dataset":0.0572243161,"dev-research":0.2523762284,"prompt-eng":0.3995634372,"data-quality":0.0841002149,"ml-security":0.1008836943}}
{"text":"In this work, we harness the formidable human-like capabilities exhibited by large language models (LLMs) in sensing, reasoning, and behaving, and utilize these qualities to construct the S$^3$ system (short for $\\textbf{S}$ocial network $\\textbf{S}$imulation $\\textbf{S}$ystem).","meta":{"url":"http://arxiv.org/abs/2307.14984v1"},"cats":{"new-dataset":0.4209059799,"dev-research":0.2344701031,"prompt-eng":0.4472604158,"data-quality":0.1657805717,"ml-security":0.1655516932}}
{"text":"Adhering to the widely employed agent-based simulation paradigm, we employ prompt engineering and prompt tuning techniques to ensure that the agent's behavior closely emulates that of a genuine human within the social network.","meta":{"url":"http://arxiv.org/abs/2307.14984v1"},"cats":{"new-dataset":0.0701642344,"dev-research":0.3398754999,"prompt-eng":0.552903642,"data-quality":0.130704012,"ml-security":0.1558939952}}
{"text":"Specifically, we simulate three pivotal aspects: emotion, attitude, and interaction behaviors.","meta":{"url":"http://arxiv.org/abs/2307.14984v1"},"cats":{"new-dataset":0.2025607126,"dev-research":0.2410748727,"prompt-eng":0.4334327084,"data-quality":0.0596319551,"ml-security":0.069201731}}
{"text":"By endowing the agent in the system with the ability to perceive the informational environment and emulate human actions, we observe the emergence of population-level phenomena, including the propagation of information, attitudes, and emotions.","meta":{"url":"http://arxiv.org/abs/2307.14984v1"},"cats":{"new-dataset":0.0773339456,"dev-research":0.2786083256,"prompt-eng":0.4441863713,"data-quality":0.1075615394,"ml-security":0.1882351455}}
{"text":"We conduct an evaluation encompassing two levels of simulation, employing real-world social network data.","meta":{"url":"http://arxiv.org/abs/2307.14984v1"},"cats":{"new-dataset":0.1614349736,"dev-research":0.2489105032,"prompt-eng":0.3894600948,"data-quality":0.1543810093,"ml-security":0.0672423253}}
{"text":"Encouragingly, the results demonstrate promising accuracy.","meta":{"url":"http://arxiv.org/abs/2307.14984v1"},"cats":{"new-dataset":0.0354707329,"dev-research":0.2333827221,"prompt-eng":0.4150559852,"data-quality":0.2262863254,"ml-security":0.0759465482}}
{"text":"This work represents an initial step in the realm of social network simulation empowered by LLM-based agents.","meta":{"url":"http://arxiv.org/abs/2307.14984v1"},"cats":{"new-dataset":0.1286391701,"dev-research":0.1662473959,"prompt-eng":0.394802246,"data-quality":0.1073366995,"ml-security":0.0992607484}}
{"text":"We anticipate that our endeavors will serve as a source of inspiration for the development of simulation systems within, but not limited to, social science.","meta":{"url":"http://arxiv.org/abs/2307.14984v1"},"cats":{"new-dataset":0.1974140466,"dev-research":0.3021334576,"prompt-eng":0.3746751714,"data-quality":0.0959244831,"ml-security":0.1528518059}}
{"text":"Simulating camera sensors is a crucial task in autonomous driving.","meta":{"url":"http://arxiv.org/abs/2307.14981v1"},"cats":{"new-dataset":0.1217709804,"dev-research":0.2545600055,"prompt-eng":0.3852664339,"data-quality":0.1011233132,"ml-security":0.1473229368}}
{"text":"Although neural radiance fields are exceptional at synthesizing photorealistic views in driving simulations, they still fail in generating extrapolated views.","meta":{"url":"http://arxiv.org/abs/2307.14981v1"},"cats":{"new-dataset":0.1442710506,"dev-research":0.2348061379,"prompt-eng":0.3228857321,"data-quality":0.1034328762,"ml-security":0.1343374247}}
{"text":"This paper proposes to incorporate map priors into neural radiance fields to synthesize out-of-trajectory driving views with semantic road consistency.","meta":{"url":"http://arxiv.org/abs/2307.14981v1"},"cats":{"new-dataset":0.2137052562,"dev-research":0.268863348,"prompt-eng":0.3500593908,"data-quality":0.1425588785,"ml-security":0.107690151}}
{"text":"The key insight is that map information can be utilized as a prior to guide the training of the radiance fields with uncertainty.","meta":{"url":"http://arxiv.org/abs/2307.14981v1"},"cats":{"new-dataset":0.0332993938,"dev-research":0.2661572031,"prompt-eng":0.3873725489,"data-quality":0.116124152,"ml-security":0.086064207}}
{"text":"Specifically, we utilize the coarse ground surface as uncertain information to supervise the density field and warp depth with uncertainty from unknown camera poses to ensure multi-view consistency.","meta":{"url":"http://arxiv.org/abs/2307.14981v1"},"cats":{"new-dataset":0.2457652636,"dev-research":0.1922479649,"prompt-eng":0.4142710843,"data-quality":0.1478973365,"ml-security":0.0573170853}}
{"text":"Experimental results demonstrate that our approach can produce semantic consistency in deviated views for vehicle camera simulation.","meta":{"url":"http://arxiv.org/abs/2307.14981v1"},"cats":{"new-dataset":0.1637526339,"dev-research":0.3120598733,"prompt-eng":0.398944377,"data-quality":0.2306044701,"ml-security":0.0569327951}}
{"text":"Industry 4.0 applications impose the challenging demand of delivering packets with bounded latencies via a wireless network.","meta":{"url":"http://arxiv.org/abs/2307.14980v1"},"cats":{"new-dataset":0.0845627606,"dev-research":0.2934070519,"prompt-eng":0.3503536084,"data-quality":0.1252852926,"ml-security":0.1079393712}}
{"text":"This is further complicated if the network is not dedicated to the time critical application.","meta":{"url":"http://arxiv.org/abs/2307.14980v1"},"cats":{"new-dataset":0.0379636343,"dev-research":0.2403224321,"prompt-eng":0.4197613154,"data-quality":0.1369592465,"ml-security":0.0944904421}}
{"text":"In this paper we use network calculus analysis to derive closed form expressions of latency bounds for time critical traffic when 802.11 Target Wake Time (TWT) and 802.1Qbv work together in a shared 802.11 network.","meta":{"url":"http://arxiv.org/abs/2307.14980v1"},"cats":{"new-dataset":0.0864034249,"dev-research":0.330011751,"prompt-eng":0.3551881957,"data-quality":0.1140434557,"ml-security":0.1460159402}}
{"text":"With the overwhelming trend of mask image modeling led by MAE, generative pre-training has shown a remarkable potential to boost the performance of fundamental models in 2D vision.","meta":{"url":"http://arxiv.org/abs/2307.14971v1"},"cats":{"new-dataset":0.1096106841,"dev-research":0.2343502075,"prompt-eng":0.4002735766,"data-quality":0.1001993055,"ml-security":0.0985853389}}
{"text":"However, in 3D vision, the over-reliance on Transformer-based backbones and the unordered nature of point clouds have restricted the further development of generative pre-training.","meta":{"url":"http://arxiv.org/abs/2307.14971v1"},"cats":{"new-dataset":0.084006577,"dev-research":0.2205435844,"prompt-eng":0.3613363668,"data-quality":0.0808395392,"ml-security":0.0949691717}}
{"text":"In this paper, we propose a novel 3D-to-2D generative pre-training method that is adaptable to any point cloud model.","meta":{"url":"http://arxiv.org/abs/2307.14971v1"},"cats":{"new-dataset":0.2322588206,"dev-research":0.2038414953,"prompt-eng":0.3529612119,"data-quality":0.0933804658,"ml-security":0.0740689927}}
{"text":"We propose to generate view images from different instructed poses via the cross-attention mechanism as the pre-training scheme.","meta":{"url":"http://arxiv.org/abs/2307.14971v1"},"cats":{"new-dataset":0.254871377,"dev-research":0.2119859801,"prompt-eng":0.4151488635,"data-quality":0.1402426877,"ml-security":0.104319937}}
{"text":"Generating view images has more precise supervision than its point cloud counterpart, thus assisting 3D backbones to have a finer comprehension of the geometrical structure and stereoscopic relations of the point cloud.","meta":{"url":"http://arxiv.org/abs/2307.14971v1"},"cats":{"new-dataset":0.1524198018,"dev-research":0.2401842381,"prompt-eng":0.3569984106,"data-quality":0.1153313953,"ml-security":0.0730609464}}
{"text":"Experimental results have proved the superiority of our proposed 3D-to-2D generative pre-training over previous pre-training methods.","meta":{"url":"http://arxiv.org/abs/2307.14971v1"},"cats":{"new-dataset":0.1466560796,"dev-research":0.2556529842,"prompt-eng":0.4138884744,"data-quality":0.1301887893,"ml-security":0.0782933185}}
{"text":"Our method is also effective in boosting the performance of architecture-oriented approaches, achieving state-of-the-art performance when fine-tuning on ScanObjectNN classification and ShapeNetPart segmentation tasks.","meta":{"url":"http://arxiv.org/abs/2307.14971v1"},"cats":{"new-dataset":0.1276634369,"dev-research":0.246889305,"prompt-eng":0.3937645678,"data-quality":0.1757393075,"ml-security":0.1179397826}}
{"text":"Code is available at https://github.com/wangzy22/TAP.","meta":{"url":"http://arxiv.org/abs/2307.14971v1"},"cats":{"new-dataset":0.3327439676,"dev-research":0.1543138643,"prompt-eng":0.4532674714,"data-quality":0.100339942,"ml-security":0.034787009}}
{"text":"In the medical field, federated learning commonly deals with highly imbalanced datasets, including skin lesions and gastrointestinal images.","meta":{"url":"http://arxiv.org/abs/2307.14959v1"},"cats":{"new-dataset":0.3002083556,"dev-research":0.1788816765,"prompt-eng":0.3341951033,"data-quality":0.1960108413,"ml-security":0.2790092133}}
{"text":"Existing federated methods under highly imbalanced datasets primarily focus on optimizing a global model without incorporating the intra-class variations that can arise in medical imaging due to different populations, findings, and scanners.","meta":{"url":"http://arxiv.org/abs/2307.14959v1"},"cats":{"new-dataset":0.1000842222,"dev-research":0.1792474165,"prompt-eng":0.3722423969,"data-quality":0.1546453757,"ml-security":0.1384838783}}
{"text":"In this paper, we study the inter-client intra-class variations with publicly available self-supervised auxiliary networks.","meta":{"url":"http://arxiv.org/abs/2307.14959v1"},"cats":{"new-dataset":0.1150008998,"dev-research":0.2453548978,"prompt-eng":0.4382680389,"data-quality":0.3034227108,"ml-security":0.1646384099}}
{"text":"Specifically, we find that employing a shared auxiliary pre-trained model, like MoCo-V2, locally on every client yields consistent divergence measurements.","meta":{"url":"http://arxiv.org/abs/2307.14959v1"},"cats":{"new-dataset":0.0577235104,"dev-research":0.2207587849,"prompt-eng":0.3762887785,"data-quality":0.2342340057,"ml-security":0.1925126485}}
{"text":"Based on these findings, we derive a dynamic balanced model aggregation via self-supervised priors (MAS) to guide the global model optimization.","meta":{"url":"http://arxiv.org/abs/2307.14959v1"},"cats":{"new-dataset":0.0476256229,"dev-research":0.1646258716,"prompt-eng":0.4040602029,"data-quality":0.1491926256,"ml-security":0.1401517826}}
{"text":"Fed-MAS can be utilized with different local learning methods for effective model aggregation toward a highly robust and unbiased global model.","meta":{"url":"http://arxiv.org/abs/2307.14959v1"},"cats":{"new-dataset":0.2223637702,"dev-research":0.1582823338,"prompt-eng":0.3867515864,"data-quality":0.2358671827,"ml-security":0.1041901735}}
{"text":"Our code is available at \\url{https://github.com/xmed-lab/Fed-MAS}.","meta":{"url":"http://arxiv.org/abs/2307.14959v1"},"cats":{"new-dataset":0.3761801243,"dev-research":0.149782273,"prompt-eng":0.4536875985,"data-quality":0.114492793,"ml-security":0.0414096211}}
{"text":"Reproducibility of recommender systems research has come under scrutiny during recent years.","meta":{"url":"http://arxiv.org/abs/2307.14956v1"},"cats":{"new-dataset":0.0406883401,"dev-research":0.308353443,"prompt-eng":0.3813700278,"data-quality":0.2036037594,"ml-security":0.1234552655}}
{"text":"Along with works focusing on repeating experiments with certain algorithms, the research community has also started discussing various aspects of evaluation and how these affect reproducibility.","meta":{"url":"http://arxiv.org/abs/2307.14956v1"},"cats":{"new-dataset":0.0649962246,"dev-research":0.28589226,"prompt-eng":0.4203728442,"data-quality":0.2803865424,"ml-security":0.103056795}}
{"text":"We add a novel angle to this discussion by examining how unofficial third-party implementations could benefit or hinder reproducibility.","meta":{"url":"http://arxiv.org/abs/2307.14956v1"},"cats":{"new-dataset":0.0638212963,"dev-research":0.2935188291,"prompt-eng":0.4612095201,"data-quality":0.2175210671,"ml-security":0.1040042997}}
{"text":"Besides giving a general overview, we thoroughly examine six third-party implementations of a popular recommender algorithm and compare them to the official version on five public datasets.","meta":{"url":"http://arxiv.org/abs/2307.14956v1"},"cats":{"new-dataset":0.2433626029,"dev-research":0.2322738029,"prompt-eng":0.3721725444,"data-quality":0.1680969089,"ml-security":0.0735218184}}
{"text":"In the light of our alarming findings we aim to draw the attention of the research community to this neglected aspect of reproducibility.","meta":{"url":"http://arxiv.org/abs/2307.14956v1"},"cats":{"new-dataset":0.085642975,"dev-research":0.2891342619,"prompt-eng":0.41206594,"data-quality":0.3579506969,"ml-security":0.1886264115}}
{"text":"This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims to mitigate data distribution shifts when transferring knowledge from multiple labeled source domains to an unlabeled target domain.","meta":{"url":"http://arxiv.org/abs/2307.14953v1"},"cats":{"new-dataset":0.1009506558,"dev-research":0.2900566694,"prompt-eng":0.4190747207,"data-quality":0.4173359654,"ml-security":0.204674052}}
{"text":"We propose a novel MSDA framework based on dictionary learning and optimal transport.","meta":{"url":"http://arxiv.org/abs/2307.14953v1"},"cats":{"new-dataset":0.2134942272,"dev-research":0.1863376195,"prompt-eng":0.3807828639,"data-quality":0.149256524,"ml-security":0.0696949666}}
{"text":"We interpret each domain in MSDA as an empirical distribution.","meta":{"url":"http://arxiv.org/abs/2307.14953v1"},"cats":{"new-dataset":0.1564255657,"dev-research":0.2220071481,"prompt-eng":0.3693997449,"data-quality":0.215154869,"ml-security":0.1308358313}}
{"text":"As such, we express each domain as a Wasserstein barycenter of dictionary atoms, which are empirical distributions.","meta":{"url":"http://arxiv.org/abs/2307.14953v1"},"cats":{"new-dataset":0.257379862,"dev-research":0.1408483766,"prompt-eng":0.366737019,"data-quality":0.1755855401,"ml-security":0.0843005883}}
{"text":"We propose a novel algorithm, DaDiL, for learning via mini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates.","meta":{"url":"http://arxiv.org/abs/2307.14953v1"},"cats":{"new-dataset":0.352739037,"dev-research":0.1501111248,"prompt-eng":0.360430738,"data-quality":0.1670773317,"ml-security":0.0685888193}}
{"text":"Based on our dictionary, we propose two novel methods for MSDA: DaDil-R, based on the reconstruction of labeled samples in the target domain, and DaDiL-E, based on the ensembling of classifiers learned on atom distributions.","meta":{"url":"http://arxiv.org/abs/2307.14953v1"},"cats":{"new-dataset":0.3843164462,"dev-research":0.205384312,"prompt-eng":0.3884795498,"data-quality":0.3633639022,"ml-security":0.1148836045}}
{"text":"We evaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU, where we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in classification performance.","meta":{"url":"http://arxiv.org/abs/2307.14953v1"},"cats":{"new-dataset":0.4487550004,"dev-research":0.1937871343,"prompt-eng":0.4205661047,"data-quality":0.2953931082,"ml-security":0.0737656705}}
{"text":"Finally, we show that interpolations in the Wasserstein hull of learned atoms provide data that can generalize to the target domain.","meta":{"url":"http://arxiv.org/abs/2307.14953v1"},"cats":{"new-dataset":0.2097997048,"dev-research":0.1418776035,"prompt-eng":0.3430161978,"data-quality":0.1338570217,"ml-security":0.1017568672}}
{"text":"As the network scale increases, existing fully distributed solutions start to lag behind the real-world challenges such as (1) slow information propagation, (2) network communication failures, and (3) external adversarial attacks.","meta":{"url":"http://arxiv.org/abs/2307.14952v1"},"cats":{"new-dataset":0.0901122757,"dev-research":0.2474769853,"prompt-eng":0.3019080731,"data-quality":0.2701239335,"ml-security":0.5989112837}}
{"text":"In this paper, we focus on hierarchical system architecture and address the problem of non-Bayesian learning over networks that are vulnerable to communication failures and adversarial attacks.","meta":{"url":"http://arxiv.org/abs/2307.14952v1"},"cats":{"new-dataset":0.1203616817,"dev-research":0.2188655275,"prompt-eng":0.3936249213,"data-quality":0.3605315524,"ml-security":0.6959611479}}
{"text":"On network communication, we consider packet-dropping link failures.   ","meta":{"url":"http://arxiv.org/abs/2307.14952v1"},"cats":{"new-dataset":0.0226043787,"dev-research":0.3256253437,"prompt-eng":0.3976014663,"data-quality":0.3848074955,"ml-security":0.2162223593}}
{"text":"We first propose a hierarchical robust push-sum algorithm that can achieve average consensus despite frequent packet-dropping link failures.","meta":{"url":"http://arxiv.org/abs/2307.14952v1"},"cats":{"new-dataset":0.1495322546,"dev-research":0.2075564992,"prompt-eng":0.3709060609,"data-quality":0.2173967179,"ml-security":0.1831031202}}
{"text":"We provide a sparse information fusion rule between the parameter server and arbitrarily selected network representatives.","meta":{"url":"http://arxiv.org/abs/2307.14952v1"},"cats":{"new-dataset":0.0661539425,"dev-research":0.2148407614,"prompt-eng":0.4325908991,"data-quality":0.2389933404,"ml-security":0.2322665148}}
{"text":"Then, interleaving the consensus update step with a dual averaging update with Kullback-Leibler (KL) divergence as the proximal function, we obtain a packet-dropping fault-tolerant non-Bayesian learning algorithm with provable convergence guarantees.   ","meta":{"url":"http://arxiv.org/abs/2307.14952v1"},"cats":{"new-dataset":0.0875152247,"dev-research":0.2324821531,"prompt-eng":0.3580901514,"data-quality":0.2626437712,"ml-security":0.2546428287}}
{"text":"On external adversarial attacks, we consider Byzantine attacks in which the compromised agents can send maliciously calibrated messages to others (including both the agents and the parameter server).","meta":{"url":"http://arxiv.org/abs/2307.14952v1"},"cats":{"new-dataset":0.1141427434,"dev-research":0.2297446324,"prompt-eng":0.389193128,"data-quality":0.2568285229,"ml-security":0.8791923073}}
{"text":"To avoid the curse of dimensionality of Byzantine consensus, we solve the non-Bayesian learning problem via running multiple dynamics, each of which only involves Byzantine consensus with scalar inputs.","meta":{"url":"http://arxiv.org/abs/2307.14952v1"},"cats":{"new-dataset":0.148610428,"dev-research":0.1596803123,"prompt-eng":0.3419400482,"data-quality":0.1465810059,"ml-security":0.2830961454}}
{"text":"To facilitate resilient information propagation across sub-networks, we use a novel Byzantine-resilient gossiping-type rule at the parameter server.","meta":{"url":"http://arxiv.org/abs/2307.14952v1"},"cats":{"new-dataset":0.0808235694,"dev-research":0.3102600605,"prompt-eng":0.4103728555,"data-quality":0.2212436352,"ml-security":0.374833731}}
{"text":"Even though offline evaluation is just an imperfect proxy of online performance -- due to the interactive nature of recommenders -- it will probably remain the primary way of evaluation in recommender systems research for the foreseeable future, since the proprietary nature of production recommenders prevents independent validation of A/B test setups and verification of online results.","meta":{"url":"http://arxiv.org/abs/2307.14951v1"},"cats":{"new-dataset":0.0151119737,"dev-research":0.2703619739,"prompt-eng":0.429963125,"data-quality":0.1825117148,"ml-security":0.0763504431}}
{"text":"Therefore, it is imperative that offline evaluation setups are as realistic and as flawless as they can be.","meta":{"url":"http://arxiv.org/abs/2307.14951v1"},"cats":{"new-dataset":0.0556739413,"dev-research":0.3853612032,"prompt-eng":0.4462856043,"data-quality":0.2366817527,"ml-security":0.0814365412}}
{"text":"Unfortunately, evaluation flaws are quite common in recommender systems research nowadays, due to later works copying flawed evaluation setups from their predecessors without questioning their validity.","meta":{"url":"http://arxiv.org/abs/2307.14951v1"},"cats":{"new-dataset":0.0170950567,"dev-research":0.3999606763,"prompt-eng":0.4103436212,"data-quality":0.5572174653,"ml-security":0.1412859954}}
{"text":"In the hope of improving the quality of offline evaluation of recommender systems, we discuss four of these widespread flaws and why researchers should avoid them.","meta":{"url":"http://arxiv.org/abs/2307.14951v1"},"cats":{"new-dataset":0.0415893217,"dev-research":0.2598893592,"prompt-eng":0.39215681,"data-quality":0.2843955611,"ml-security":0.0939754078}}
{"text":"We developed a new approach comprised of different visualizations for the comparative spatio-temporal analysis of displacement processes in porous media.","meta":{"url":"http://arxiv.org/abs/2307.14949v1"},"cats":{"new-dataset":0.2489144387,"dev-research":0.2717550284,"prompt-eng":0.328433063,"data-quality":0.0765948063,"ml-security":0.0380921357}}
{"text":"We aim to analyze and compare ensemble datasets from experiments to gain insight into the influence of different parameters on fluid flow.","meta":{"url":"http://arxiv.org/abs/2307.14949v1"},"cats":{"new-dataset":0.2885970391,"dev-research":0.2265898762,"prompt-eng":0.3190810202,"data-quality":0.1478414042,"ml-security":0.1225388106}}
{"text":"To capture the displacement of a defending fluid by an invading fluid, we first condense an input image series to a single time map.","meta":{"url":"http://arxiv.org/abs/2307.14949v1"},"cats":{"new-dataset":0.2206875386,"dev-research":0.2132730722,"prompt-eng":0.3706955351,"data-quality":0.0923558164,"ml-security":0.209487968}}
{"text":"From this map, we generate a spatio-temporal flow graph covering the whole process.","meta":{"url":"http://arxiv.org/abs/2307.14949v1"},"cats":{"new-dataset":0.6016096145,"dev-research":0.2428661784,"prompt-eng":0.3617708396,"data-quality":0.0780746053,"ml-security":0.0541709807}}
{"text":"This graph is further simplified to only reflect topological changes in the movement of the invading fluid.","meta":{"url":"http://arxiv.org/abs/2307.14949v1"},"cats":{"new-dataset":0.1046232501,"dev-research":0.2165538638,"prompt-eng":0.3011432338,"data-quality":0.1016108855,"ml-security":0.1333522731}}
{"text":"Our interactive tools allow the visual analysis of these processes by visualizing the graph structure and the context of the experimental setup, as well as by providing charts for multiple metrics.","meta":{"url":"http://arxiv.org/abs/2307.14949v1"},"cats":{"new-dataset":0.3077020481,"dev-research":0.3396833736,"prompt-eng":0.4222386924,"data-quality":0.1176234116,"ml-security":0.0439511369}}
{"text":"We apply our approach to analyze and compare ensemble datasets jointly with domain experts, where we vary either fluid properties or the solid structure of the porous medium.","meta":{"url":"http://arxiv.org/abs/2307.14949v1"},"cats":{"new-dataset":0.3834498482,"dev-research":0.2014360597,"prompt-eng":0.3324075418,"data-quality":0.1516870618,"ml-security":0.0892998864}}
{"text":"We finally report the generated insights from the domain experts and discuss our contribution's advantages, generality, and limitations.","meta":{"url":"http://arxiv.org/abs/2307.14949v1"},"cats":{"new-dataset":0.049170516,"dev-research":0.3266686759,"prompt-eng":0.4125520895,"data-quality":0.2224389869,"ml-security":0.1227083647}}
{"text":"The continuous dynamics of natural systems has been effectively modelled using Neural Ordinary Differential Equations (Neural ODEs).","meta":{"url":"http://arxiv.org/abs/2307.14940v1"},"cats":{"new-dataset":0.093362966,"dev-research":0.1909059056,"prompt-eng":0.3313898082,"data-quality":0.0755933565,"ml-security":0.1719737526}}
{"text":"However, for accurate and meaningful predictions, it is crucial that the models follow the underlying rules or laws that govern these systems.","meta":{"url":"http://arxiv.org/abs/2307.14940v1"},"cats":{"new-dataset":0.0188443027,"dev-research":0.2413609542,"prompt-eng":0.350854949,"data-quality":0.1633280076,"ml-security":0.2268768208}}
{"text":"In this work, we propose a self-adaptive penalty algorithm for Neural ODEs to enable modelling of constrained natural systems.","meta":{"url":"http://arxiv.org/abs/2307.14940v1"},"cats":{"new-dataset":0.0724466391,"dev-research":0.1811534512,"prompt-eng":0.3455892408,"data-quality":0.1475204666,"ml-security":0.2412512614}}
{"text":"The proposed self-adaptive penalty function can dynamically adjust the penalty parameters.","meta":{"url":"http://arxiv.org/abs/2307.14940v1"},"cats":{"new-dataset":0.0069004527,"dev-research":0.2329937822,"prompt-eng":0.4440799645,"data-quality":0.1776164385,"ml-security":0.1726017784}}
{"text":"The explicit introduction of prior knowledge helps to increase the interpretability of Neural ODE -based models.","meta":{"url":"http://arxiv.org/abs/2307.14940v1"},"cats":{"new-dataset":0.0374650617,"dev-research":0.2958057939,"prompt-eng":0.3487824332,"data-quality":0.1704060819,"ml-security":0.2140969537}}
{"text":"We validate the proposed approach by modelling three natural systems with prior knowledge constraints: population growth, chemical reaction evolution, and damped harmonic oscillator motion.","meta":{"url":"http://arxiv.org/abs/2307.14940v1"},"cats":{"new-dataset":0.0687462879,"dev-research":0.18245297,"prompt-eng":0.4080712074,"data-quality":0.0954282983,"ml-security":0.0862125888}}
{"text":"The numerical experiments and a comparison with other penalty Neural ODE approaches and \\emph{vanilla} Neural ODE, demonstrate the effectiveness of the proposed self-adaptive penalty algorithm for Neural ODEs in modelling constrained natural systems.","meta":{"url":"http://arxiv.org/abs/2307.14940v1"},"cats":{"new-dataset":0.0532673689,"dev-research":0.1907380859,"prompt-eng":0.3591118732,"data-quality":0.1705252191,"ml-security":0.2263663799}}
{"text":"Moreover, the self-adaptive penalty approach provides more accurate and robust models with reliable and meaningful predictions.","meta":{"url":"http://arxiv.org/abs/2307.14940v1"},"cats":{"new-dataset":0.0188894226,"dev-research":0.181636356,"prompt-eng":0.3923756316,"data-quality":0.2405828518,"ml-security":0.1718099743}}
{"text":"Large Language Models for Code (Code LLM) are flourishing.","meta":{"url":"http://arxiv.org/abs/2307.14936v1"},"cats":{"new-dataset":0.1978925959,"dev-research":0.3087045913,"prompt-eng":0.3831827855,"data-quality":0.1767932501,"ml-security":0.1267142274}}
{"text":"New and powerful models are released on a weekly basis, demonstrating remarkable performance on the code generation task.","meta":{"url":"http://arxiv.org/abs/2307.14936v1"},"cats":{"new-dataset":0.2601445547,"dev-research":0.3851115683,"prompt-eng":0.4437633999,"data-quality":0.1340658746,"ml-security":0.084424651}}
{"text":"Various approaches have been proposed to boost the code generation performance of pre-trained Code LLMs, such as supervised fine-tuning, instruction tuning, reinforcement learning, etc.","meta":{"url":"http://arxiv.org/abs/2307.14936v1"},"cats":{"new-dataset":0.0533899377,"dev-research":0.3963466179,"prompt-eng":0.4738463017,"data-quality":0.1934466892,"ml-security":0.1403375054}}
{"text":"In this paper, we propose a novel RRTF (Rank Responses to align Test&Teacher Feedback) framework, which can effectively and efficiently boost pre-trained large language models for code generation.","meta":{"url":"http://arxiv.org/abs/2307.14936v1"},"cats":{"new-dataset":0.3609649979,"dev-research":0.4112680291,"prompt-eng":0.4581119044,"data-quality":0.215432116,"ml-security":0.0891415513}}
{"text":"Under this framework, we present PanGu-Coder2, which achieves 62.20% pass@1 on the OpenAI HumanEval benchmark.","meta":{"url":"http://arxiv.org/abs/2307.14936v1"},"cats":{"new-dataset":0.5254490198,"dev-research":0.2057884377,"prompt-eng":0.4270189129,"data-quality":0.1789049846,"ml-security":0.0690479149}}
{"text":"Furthermore, through an extensive evaluation on CoderEval and LeetCode benchmarks, we show that PanGu-Coder2 consistently outperforms all previous Code LLMs.","meta":{"url":"http://arxiv.org/abs/2307.14936v1"},"cats":{"new-dataset":0.2691984314,"dev-research":0.2716740552,"prompt-eng":0.4404139232,"data-quality":0.2454062027,"ml-security":0.0757904989}}
{"text":"Data profiling is an essential process in modern data-driven industries.","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.1172890643,"dev-research":0.3916974042,"prompt-eng":0.3836264355,"data-quality":0.1470962325,"ml-security":0.1163171767}}
{"text":"One of its critical components is the discovery and validation of complex statistics, including functional dependencies, data constraints, association rules, and others.   ","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.1109346388,"dev-research":0.2618561775,"prompt-eng":0.3851121335,"data-quality":0.1548614744,"ml-security":0.0910151227}}
{"text":"However, most existing data profiling systems that focus on complex statistics do not provide proper integration with the tools used by contemporary data scientists.","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.0744994478,"dev-research":0.3135638308,"prompt-eng":0.3462660296,"data-quality":0.2829352732,"ml-security":0.1148381583}}
{"text":"This creates a significant barrier to the adoption of these tools in the industry.","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.014377964,"dev-research":0.3735614835,"prompt-eng":0.3347958182,"data-quality":0.0877567828,"ml-security":0.1549205198}}
{"text":"Moreover, existing systems were not created with industrial-grade workloads in mind.","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.0231415974,"dev-research":0.3149564029,"prompt-eng":0.3010048321,"data-quality":0.1553402018,"ml-security":0.1059332659}}
{"text":"Finally, they do not aim to provide descriptive explanations, i.e. why a given pattern is not found.","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.0409224145,"dev-research":0.2786393691,"prompt-eng":0.3625453558,"data-quality":0.2621771647,"ml-security":0.1184347717}}
{"text":"It is a significant issue as it is essential to understand the underlying reasons for a specific pattern's absence to make informed decisions based on the data.   ","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.0176914022,"dev-research":0.2906305921,"prompt-eng":0.358521935,"data-quality":0.2965644162,"ml-security":0.1724685611}}
{"text":"Because of that, these patterns are effectively rest in thin air: their application scope is rather limited, they are rarely used by the broader public.","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.0195501603,"dev-research":0.2632779552,"prompt-eng":0.3277908266,"data-quality":0.1294753388,"ml-security":0.1208492184}}
{"text":"At the same time, as we are going to demonstrate in this presentation, complex statistics can be efficiently used to solve many classic data quality problems.   ","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.1853450183,"dev-research":0.3179063775,"prompt-eng":0.3636055276,"data-quality":0.2041782255,"ml-security":0.0759880901}}
{"text":"Desbordante is an open-source data profiler that aims to close this gap.","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.4819210359,"dev-research":0.277527948,"prompt-eng":0.4172942709,"data-quality":0.1811976374,"ml-security":0.0653587659}}
{"text":"It is built with emphasis on industrial application: it is efficient, scalable, resilient to crashes, and provides explanations.","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.1573324451,"dev-research":0.5103943794,"prompt-eng":0.4099825589,"data-quality":0.1373654052,"ml-security":0.1112333875}}
{"text":"Furthermore, it provides seamless Python integration by offloading various costly operations to the C++ core, not only mining.   ","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.0785682702,"dev-research":0.3286824552,"prompt-eng":0.4136452745,"data-quality":0.0999715401,"ml-security":0.0861471477}}
{"text":"In this demonstration, we show several scenarios that allow end users to solve different data quality problems.","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.1876760243,"dev-research":0.3188087274,"prompt-eng":0.4083004813,"data-quality":0.4479284465,"ml-security":0.194035816}}
{"text":"Namely, we showcase typo detection, data deduplication, and data anomaly detection scenarios.","meta":{"url":"http://arxiv.org/abs/2307.14935v1"},"cats":{"new-dataset":0.4400408651,"dev-research":0.3862484755,"prompt-eng":0.4003494257,"data-quality":0.5041700477,"ml-security":0.3300174806}}
{"text":"Regular Path Queries (RPQs), which are essentially regular expressions to be matched against the labels of paths in labeled graphs, are at the core of graph database query languages like SPARQL.","meta":{"url":"http://arxiv.org/abs/2307.14930v1"},"cats":{"new-dataset":0.1096134224,"dev-research":0.2391121687,"prompt-eng":0.416105964,"data-quality":0.2316411108,"ml-security":0.0907708268}}
{"text":"A way to solve RPQs is to translate them into a sequence of operations on the adjacency matrices of each label.","meta":{"url":"http://arxiv.org/abs/2307.14930v1"},"cats":{"new-dataset":0.2752140863,"dev-research":0.1942620349,"prompt-eng":0.3838079806,"data-quality":0.2102469124,"ml-security":0.0523152322}}
{"text":"We design and implement a Boolean algebra on sparse matrix representations and, as an application, use them to handle RPQs.","meta":{"url":"http://arxiv.org/abs/2307.14930v1"},"cats":{"new-dataset":0.1826133758,"dev-research":0.2322095812,"prompt-eng":0.3908324421,"data-quality":0.1252219421,"ml-security":0.0764964934}}
{"text":"Our baseline representation uses the same space as the previously most compact index for RPQs and excels in handling the hardest types of queries.","meta":{"url":"http://arxiv.org/abs/2307.14930v1"},"cats":{"new-dataset":0.3095619821,"dev-research":0.287381012,"prompt-eng":0.3543100442,"data-quality":0.1192765131,"ml-security":0.0536739136}}
{"text":"Our more succinct structure, based on $k^2$-trees, is 4 times smaller and still solves complex RPQs in reasonable time.","meta":{"url":"http://arxiv.org/abs/2307.14930v1"},"cats":{"new-dataset":0.178076063,"dev-research":0.1917546949,"prompt-eng":0.3157220463,"data-quality":0.0925689728,"ml-security":0.0684866449}}
{"text":"Graphs can be leveraged to model polyphonic multitrack symbolic music, where notes, chords and entire sections may be linked at different levels of the musical hierarchy by tonal and rhythmic relationships.","meta":{"url":"http://arxiv.org/abs/2307.14928v1"},"cats":{"new-dataset":0.168698803,"dev-research":0.2206892511,"prompt-eng":0.3712231185,"data-quality":0.1760618589,"ml-security":0.0612240475}}
{"text":"Nonetheless, there is a lack of works that consider graph representations in the context of deep learning systems for music generation.","meta":{"url":"http://arxiv.org/abs/2307.14928v1"},"cats":{"new-dataset":0.0608897927,"dev-research":0.2476617202,"prompt-eng":0.2513089294,"data-quality":0.2796107842,"ml-security":0.0980010619}}
{"text":"This paper bridges this gap by introducing a novel graph representation for music and a deep Variational Autoencoder that generates the structure and the content of musical graphs separately, one after the other, with a hierarchical architecture that matches the structural priors of music.","meta":{"url":"http://arxiv.org/abs/2307.14928v1"},"cats":{"new-dataset":0.0835033675,"dev-research":0.2069406307,"prompt-eng":0.3267041671,"data-quality":0.2040739793,"ml-security":0.0674832274}}
{"text":"By separating the structure and content of musical graphs, it is possible to condition generation by specifying which instruments are played at certain times.","meta":{"url":"http://arxiv.org/abs/2307.14928v1"},"cats":{"new-dataset":0.0739544111,"dev-research":0.2952375676,"prompt-eng":0.4127560222,"data-quality":0.1587439183,"ml-security":0.0751256934}}
{"text":"This opens the door to a new form of human-computer interaction in the context of music co-creation.","meta":{"url":"http://arxiv.org/abs/2307.14928v1"},"cats":{"new-dataset":0.122610773,"dev-research":0.4012718652,"prompt-eng":0.3657316039,"data-quality":0.1449131544,"ml-security":0.0702063225}}
{"text":"After training the model on existing MIDI datasets, the experiments show that the model is able to generate appealing short and long musical sequences and to realistically interpolate between them, producing music that is tonally and rhythmically consistent.","meta":{"url":"http://arxiv.org/abs/2307.14928v1"},"cats":{"new-dataset":0.1955209467,"dev-research":0.2540244429,"prompt-eng":0.3412115189,"data-quality":0.1562728878,"ml-security":0.0869048605}}
{"text":"Finally, the visualization of the embeddings shows that the model is able to organize its latent space in accordance with known musical concepts.","meta":{"url":"http://arxiv.org/abs/2307.14928v1"},"cats":{"new-dataset":0.1429569244,"dev-research":0.184392477,"prompt-eng":0.3449142644,"data-quality":0.1439101559,"ml-security":0.0611683881}}
{"text":"Coded distributed computing, proposed by Li et al., offers significant potential for reducing the communication load in MapReduce computing systems.","meta":{"url":"http://arxiv.org/abs/2307.14927v1"},"cats":{"new-dataset":0.1146422568,"dev-research":0.2690814038,"prompt-eng":0.3379380214,"data-quality":0.1288675312,"ml-security":0.0990119225}}
{"text":"In the setting of the \\emph{cascaded} coded distributed computing that consisting of $K$ nodes, $N$ input files, and $Q$ output functions, the objective is to compute each output function through $s\\geq 1$ nodes with a computation load $r\\geq 1$, enabling the application of coding techniques during the Shuffle phase to achieve minimum communication load.","meta":{"url":"http://arxiv.org/abs/2307.14927v1"},"cats":{"new-dataset":0.0810012596,"dev-research":0.2319765035,"prompt-eng":0.3697008191,"data-quality":0.1502814758,"ml-security":0.1058094465}}
{"text":"However, for most existing coded distributed computing schemes, a major limitation lies in their demand for splitting the original data into an exponentially growing number of input files in terms of $N/\\binom{K}{r} \\in\\mathbb{N}$ and requiring an exponentially large number of output functions $Q/\\binom{K}{s} \\in\\mathbb{N}$, which imposes stringent requirements for implementation and results in significant coding complexity when $K$ is large.","meta":{"url":"http://arxiv.org/abs/2307.14927v1"},"cats":{"new-dataset":0.1337934301,"dev-research":0.2962225724,"prompt-eng":0.3003179052,"data-quality":0.0931402631,"ml-security":0.1538246337}}
{"text":"In this paper, we focus on the cascaded case of $K/s\\in\\mathbb{N} $, deliberately designing the strategy of input files store and output functions assignment based on a grouping method, such that a low-complexity two-round Shuffle phase is available.","meta":{"url":"http://arxiv.org/abs/2307.14927v1"},"cats":{"new-dataset":0.2332172186,"dev-research":0.2283620966,"prompt-eng":0.3940415437,"data-quality":0.1730152088,"ml-security":0.1289135588}}
{"text":"The main advantages of our proposed scheme contains: 1) the communication load is quilt close to or surprisingly better than the optimal state-of-the-art scheme proposed by Li et al.; 2) our scheme requires significantly less number of input files and output functions; 3) all the operations are implemented over the minimum binary field $\\mathbb{F}_2$.","meta":{"url":"http://arxiv.org/abs/2307.14927v1"},"cats":{"new-dataset":0.0751857208,"dev-research":0.2300641639,"prompt-eng":0.4053724374,"data-quality":0.0989276093,"ml-security":0.0866402522}}
{"text":"Performance Benchmarking of HPC systems is an ongoing effort that seeks to provide information that will allow for increased performance and improve the job schedulers that manage these systems.","meta":{"url":"http://arxiv.org/abs/2307.14921v1"},"cats":{"new-dataset":0.119587568,"dev-research":0.3782017922,"prompt-eng":0.4200579193,"data-quality":0.1204941424,"ml-security":0.0671509021}}
{"text":"We develop a benchmarking tool that utilizes machine learning models and gathers performance data on GPU-accelerated nodes while they perform material segmentation analysis.","meta":{"url":"http://arxiv.org/abs/2307.14921v1"},"cats":{"new-dataset":0.133769214,"dev-research":0.2275627916,"prompt-eng":0.3681475484,"data-quality":0.1354693723,"ml-security":0.0691052794}}
{"text":"The benchmark uses a ML model that has been converted from Caffe to PyTorch using the MMdnn toolkit and the MINC-2500 dataset.","meta":{"url":"http://arxiv.org/abs/2307.14921v1"},"cats":{"new-dataset":0.3766777489,"dev-research":0.1821446048,"prompt-eng":0.3873432484,"data-quality":0.1831512535,"ml-security":0.062479748}}
{"text":"Performance data is gathered on two ERDC DSRC systems, Onyx and Vulcanite.","meta":{"url":"http://arxiv.org/abs/2307.14921v1"},"cats":{"new-dataset":0.1507977009,"dev-research":0.2504398234,"prompt-eng":0.4365714448,"data-quality":0.0773563203,"ml-security":0.0347633544}}
{"text":"The data reveals that while Vulcanite has faster model times in a large number of benchmarks, and it is also more subject to some environmental factors that can cause performances slower than Onyx.","meta":{"url":"http://arxiv.org/abs/2307.14921v1"},"cats":{"new-dataset":0.0146706314,"dev-research":0.3250265542,"prompt-eng":0.3366747213,"data-quality":0.0552851947,"ml-security":0.0502443753}}
{"text":"In contrast the model times from Onyx are consistent across benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.14921v1"},"cats":{"new-dataset":0.0319105451,"dev-research":0.2875394346,"prompt-eng":0.3409270903,"data-quality":0.0975669409,"ml-security":0.0448648039}}
{"text":"The demand for efficient 3D model generation techniques has grown exponentially, as manual creation of 3D models is time-consuming and requires specialized expertise.","meta":{"url":"http://arxiv.org/abs/2307.14918v1"},"cats":{"new-dataset":0.0629834706,"dev-research":0.3277433775,"prompt-eng":0.3706642267,"data-quality":0.0546200884,"ml-security":0.0519988398}}
{"text":"While generative models have shown potential in creating 3D textured shapes from 2D images, their applicability in 3D industries is limited due to the lack of a well-defined camera distribution in real-world scenarios, resulting in low-quality shapes.","meta":{"url":"http://arxiv.org/abs/2307.14918v1"},"cats":{"new-dataset":0.1956740681,"dev-research":0.1948939455,"prompt-eng":0.3724146505,"data-quality":0.0870983368,"ml-security":0.0681583431}}
{"text":"To overcome this limitation, we propose GET3D--, the first method that directly generates textured 3D shapes from 2D images with unknown pose and scale.","meta":{"url":"http://arxiv.org/abs/2307.14918v1"},"cats":{"new-dataset":0.3325914603,"dev-research":0.1831338354,"prompt-eng":0.3328988134,"data-quality":0.0980977667,"ml-security":0.1138398116}}
{"text":"GET3D-- comprises a 3D shape generator and a learnable camera sampler that captures the 6D external changes on the camera.","meta":{"url":"http://arxiv.org/abs/2307.14918v1"},"cats":{"new-dataset":0.4088781672,"dev-research":0.2438459459,"prompt-eng":0.3883909686,"data-quality":0.0672196991,"ml-security":0.0458417972}}
{"text":"In addition, We propose a novel training schedule to stably optimize both the shape generator and camera sampler in a unified framework.","meta":{"url":"http://arxiv.org/abs/2307.14918v1"},"cats":{"new-dataset":0.21181762,"dev-research":0.2288465904,"prompt-eng":0.4159948368,"data-quality":0.1150876022,"ml-security":0.0623505266}}
{"text":"By controlling external variations using the learnable camera sampler, our method can generate aligned shapes with clear textures.","meta":{"url":"http://arxiv.org/abs/2307.14918v1"},"cats":{"new-dataset":0.1761591784,"dev-research":0.2412711644,"prompt-eng":0.4035718526,"data-quality":0.1311939511,"ml-security":0.0511647479}}
{"text":"Extensive experiments demonstrate the efficacy of GET3D--, which precisely fits the 6D camera pose distribution and generates high-quality shapes on both synthetic and realistic unconstrained datasets.","meta":{"url":"http://arxiv.org/abs/2307.14918v1"},"cats":{"new-dataset":0.6780330731,"dev-research":0.1975919973,"prompt-eng":0.3176870361,"data-quality":0.0863620262,"ml-security":0.1025649299}}
{"text":"Visual AI systems are vulnerable to natural and synthetic physical corruption in the real-world.","meta":{"url":"http://arxiv.org/abs/2307.14917v1"},"cats":{"new-dataset":0.115440241,"dev-research":0.3590200947,"prompt-eng":0.348666805,"data-quality":0.3674998504,"ml-security":0.4634324212}}
{"text":"Such corruption often arises unexpectedly and alters the model's performance.","meta":{"url":"http://arxiv.org/abs/2307.14917v1"},"cats":{"new-dataset":0.0121762757,"dev-research":0.4128081151,"prompt-eng":0.3637825737,"data-quality":0.4067188716,"ml-security":0.4566750451}}
{"text":"In recent years, the primary focus has been on adversarial attacks.","meta":{"url":"http://arxiv.org/abs/2307.14917v1"},"cats":{"new-dataset":0.0356132754,"dev-research":0.2833806366,"prompt-eng":0.3021470224,"data-quality":0.2613303804,"ml-security":0.8458267563}}
{"text":"However, natural corruptions (e.g., snow, fog, dust) are an omnipresent threat to visual AI systems and should be considered equally important.","meta":{"url":"http://arxiv.org/abs/2307.14917v1"},"cats":{"new-dataset":0.1031805626,"dev-research":0.3769025991,"prompt-eng":0.3342011501,"data-quality":0.2821732771,"ml-security":0.5019002154}}
{"text":"Many existing works propose interesting solutions to train robust models against natural corruption.","meta":{"url":"http://arxiv.org/abs/2307.14917v1"},"cats":{"new-dataset":0.3011614974,"dev-research":0.2790221232,"prompt-eng":0.3724153226,"data-quality":0.4329439062,"ml-security":0.559663187}}
{"text":"These works either leverage image augmentations, which come with the additional cost of model training, or place suspicious patches in the scene to design unadversarial examples.","meta":{"url":"http://arxiv.org/abs/2307.14917v1"},"cats":{"new-dataset":0.1080295126,"dev-research":0.2533157568,"prompt-eng":0.3675930161,"data-quality":0.2544573031,"ml-security":0.3155643376}}
{"text":"In this work, we propose the idea of naturalistic support artifacts (NSA) for robust prediction.","meta":{"url":"http://arxiv.org/abs/2307.14917v1"},"cats":{"new-dataset":0.1969485172,"dev-research":0.2577483863,"prompt-eng":0.4189280896,"data-quality":0.3492192235,"ml-security":0.2105176387}}
{"text":"The NSAs are shown to be beneficial in scenarios where model parameters are inaccessible and adding artifacts in the scene is feasible.","meta":{"url":"http://arxiv.org/abs/2307.14917v1"},"cats":{"new-dataset":0.1178043409,"dev-research":0.2553050428,"prompt-eng":0.3952230817,"data-quality":0.1823148854,"ml-security":0.3668239489}}
{"text":"The NSAs are natural looking objects generated through artifact training using DC-GAN to have high visual fidelity in the scene.","meta":{"url":"http://arxiv.org/abs/2307.14917v1"},"cats":{"new-dataset":0.1605027673,"dev-research":0.2390413261,"prompt-eng":0.3380775699,"data-quality":0.1548959435,"ml-security":0.144517091}}
{"text":"We test against natural corruptions on the Imagenette dataset and observe the improvement in prediction confidence score by four times.","meta":{"url":"http://arxiv.org/abs/2307.14917v1"},"cats":{"new-dataset":0.3537488345,"dev-research":0.2653295238,"prompt-eng":0.3782181902,"data-quality":0.5053408669,"ml-security":0.4615657137}}
{"text":"We also demonstrate NSA's capability to increase adversarial accuracy by 8\\% on average.","meta":{"url":"http://arxiv.org/abs/2307.14917v1"},"cats":{"new-dataset":0.0818956521,"dev-research":0.2211248795,"prompt-eng":0.3629350637,"data-quality":0.2907565908,"ml-security":0.6156013779}}
{"text":"Lastly, we qualitatively analyze NSAs using saliency maps to understand how they help improve prediction confidence.","meta":{"url":"http://arxiv.org/abs/2307.14917v1"},"cats":{"new-dataset":0.1201637827,"dev-research":0.302535995,"prompt-eng":0.4001751404,"data-quality":0.1487673702,"ml-security":0.1647224988}}
{"text":"The task of multi-author writing style detection aims at finding any positions of writing style change in a given text document.","meta":{"url":"http://arxiv.org/abs/2307.14913v1"},"cats":{"new-dataset":0.0417506658,"dev-research":0.3207129409,"prompt-eng":0.4130839703,"data-quality":0.3842986178,"ml-security":0.1087924318}}
{"text":"We formulate the task as a natural language inference problem where two consecutive paragraphs are paired.","meta":{"url":"http://arxiv.org/abs/2307.14913v1"},"cats":{"new-dataset":0.1198506637,"dev-research":0.2376653076,"prompt-eng":0.4313832088,"data-quality":0.2883547204,"ml-security":0.0903454361}}
{"text":"Our approach focuses on transitions between paragraphs while truncating input tokens for the task.","meta":{"url":"http://arxiv.org/abs/2307.14913v1"},"cats":{"new-dataset":0.0902275375,"dev-research":0.2675106311,"prompt-eng":0.4709034546,"data-quality":0.2530498266,"ml-security":0.0637204182}}
{"text":"As backbone models, we employ different Transformer-based encoders with warmup phase during training.","meta":{"url":"http://arxiv.org/abs/2307.14913v1"},"cats":{"new-dataset":0.0771128886,"dev-research":0.1904784751,"prompt-eng":0.3970511529,"data-quality":0.0743386451,"ml-security":0.1352758467}}
{"text":"We submit the model version that outperforms baselines and other proposed model versions in our experiments.","meta":{"url":"http://arxiv.org/abs/2307.14913v1"},"cats":{"new-dataset":0.1338886849,"dev-research":0.2480354859,"prompt-eng":0.4216253325,"data-quality":0.21451288,"ml-security":0.0946926182}}
{"text":"For the easy and medium setups, we submit transition-focused natural language inference based on DeBERTa with warmup training, and the same model without transition for the hard setup.","meta":{"url":"http://arxiv.org/abs/2307.14913v1"},"cats":{"new-dataset":0.2496414194,"dev-research":0.2399447042,"prompt-eng":0.4218052544,"data-quality":0.2016370775,"ml-security":0.0913511366}}
{"text":"Fanfiction, a popular form of creative writing set within established fictional universes, has gained a substantial online following.","meta":{"url":"http://arxiv.org/abs/2307.14912v1"},"cats":{"new-dataset":0.1589598617,"dev-research":0.3014807957,"prompt-eng":0.3949935692,"data-quality":0.1290811794,"ml-security":0.0522044303}}
{"text":"However, ensuring the well-being and safety of participants has become a critical concern in this community.","meta":{"url":"http://arxiv.org/abs/2307.14912v1"},"cats":{"new-dataset":0.1619464859,"dev-research":0.3488415202,"prompt-eng":0.3516435178,"data-quality":0.1279617219,"ml-security":0.2210276162}}
{"text":"The detection of triggering content, material that may cause emotional distress or trauma to readers, poses a significant challenge.","meta":{"url":"http://arxiv.org/abs/2307.14912v1"},"cats":{"new-dataset":0.0382478585,"dev-research":0.3258139236,"prompt-eng":0.4063195055,"data-quality":0.3571657601,"ml-security":0.2345960506}}
{"text":"In this paper, we describe our approach for the Trigger Detection shared task at PAN CLEF 2023, where we want to detect multiple triggering content in a given Fanfiction document.","meta":{"url":"http://arxiv.org/abs/2307.14912v1"},"cats":{"new-dataset":0.3599527506,"dev-research":0.2967480759,"prompt-eng":0.5426148069,"data-quality":0.2858574997,"ml-security":0.1095139226}}
{"text":"For this, we build a hierarchical model that uses recurrence over Transformer-based language models.","meta":{"url":"http://arxiv.org/abs/2307.14912v1"},"cats":{"new-dataset":0.2597113411,"dev-research":0.2058041759,"prompt-eng":0.4370628202,"data-quality":0.1483259436,"ml-security":0.0712422696}}
{"text":"In our approach, we first split long documents into smaller sized segments and use them to fine-tune a Transformer model.","meta":{"url":"http://arxiv.org/abs/2307.14912v1"},"cats":{"new-dataset":0.2636422865,"dev-research":0.2165543927,"prompt-eng":0.4146137633,"data-quality":0.1234532883,"ml-security":0.0457089978}}
{"text":"Then, we extract feature embeddings from the fine-tuned Transformer model, which are used as input in the training of multiple LSTM models for trigger detection in a multi-label setting.","meta":{"url":"http://arxiv.org/abs/2307.14912v1"},"cats":{"new-dataset":0.2011604562,"dev-research":0.1879938991,"prompt-eng":0.4201570102,"data-quality":0.3281873169,"ml-security":0.222219589}}
{"text":"Our model achieves an F1-macro score of 0.372 and F1-micro score of 0.736 on the validation set, which are higher than the baseline results shared at PAN CLEF 2023.","meta":{"url":"http://arxiv.org/abs/2307.14912v1"},"cats":{"new-dataset":0.3150342074,"dev-research":0.1989994541,"prompt-eng":0.4437165614,"data-quality":0.2107462466,"ml-security":0.0711934813}}
{"text":"The use of Wake-Up Radio (WUR) in Internet of Things (IoT) networks can significantly improve their energy efficiency: battery-powered sensors can remain in a low-power (sleep) mode while listening for wake-up messages using their WUR and reactivate only when polled, saving energy.","meta":{"url":"http://arxiv.org/abs/2307.14910v1"},"cats":{"new-dataset":0.0256179903,"dev-research":0.2543382342,"prompt-eng":0.404222672,"data-quality":0.1004320055,"ml-security":0.074617517}}
{"text":"However, polling-based Time Division Multiple Access (TDMA) may significantly increase data transmission delay if packets are generated sporadically, as nodes with no information still need to be polled.","meta":{"url":"http://arxiv.org/abs/2307.14910v1"},"cats":{"new-dataset":0.0152824601,"dev-research":0.2587944864,"prompt-eng":0.3784872176,"data-quality":0.0958090249,"ml-security":0.1325401487}}
{"text":"In this paper, we examine the effect of multicast polling for WUR-enabled wireless nodes.","meta":{"url":"http://arxiv.org/abs/2307.14910v1"},"cats":{"new-dataset":0.0422137455,"dev-research":0.3005340831,"prompt-eng":0.4348957181,"data-quality":0.1249372773,"ml-security":0.081096057}}
{"text":"The idea is to assign nodes to multicast groups so that all nodes in the same group can be solicited by a multicast polling message.","meta":{"url":"http://arxiv.org/abs/2307.14910v1"},"cats":{"new-dataset":0.0662882151,"dev-research":0.2565592606,"prompt-eng":0.4103494803,"data-quality":0.140442527,"ml-security":0.0928425336}}
{"text":"This may cause collisions, which can be solved by requesting retransmissions from the involved nodes.","meta":{"url":"http://arxiv.org/abs/2307.14910v1"},"cats":{"new-dataset":0.015559251,"dev-research":0.2357779064,"prompt-eng":0.3859402512,"data-quality":0.2916546712,"ml-security":0.1989289284}}
{"text":"We analyze the performance of different multicast polling and retransmission strategies, showing that the optimal approach can significantly reduce the delay over TDMA and ALOHA in low-traffic scenarios while keeping good energy efficiency.","meta":{"url":"http://arxiv.org/abs/2307.14910v1"},"cats":{"new-dataset":0.1185941691,"dev-research":0.2209739363,"prompt-eng":0.3626982327,"data-quality":0.1109437937,"ml-security":0.0759848899}}
{"text":"Migration to OCaml 5 requires updating a lot of C bindings due to the removal of naked pointer support.","meta":{"url":"http://arxiv.org/abs/2307.14909v1"},"cats":{"new-dataset":0.1401086544,"dev-research":0.3614263359,"prompt-eng":0.3543980347,"data-quality":0.1406927259,"ml-security":0.0838807141}}
{"text":"Writing OCaml user-defined primitives in C is a necessity, but is unsafe and error-prone.","meta":{"url":"http://arxiv.org/abs/2307.14909v1"},"cats":{"new-dataset":0.1578707421,"dev-research":0.4058918089,"prompt-eng":0.3876164018,"data-quality":0.123041586,"ml-security":0.1190663906}}
{"text":"It does not benefit from either OCaml's or C's type checking, and existing C static analysers are not aware of the OCaml GC safety rules, and cannot infer them from existing macros alone.","meta":{"url":"http://arxiv.org/abs/2307.14909v1"},"cats":{"new-dataset":0.0191037699,"dev-research":0.3959463745,"prompt-eng":0.3616706144,"data-quality":0.2269058275,"ml-security":0.1858297277}}
{"text":"The alternative is automatically generating C stubs, which requires correctly managing value lifetimes.","meta":{"url":"http://arxiv.org/abs/2307.14909v1"},"cats":{"new-dataset":0.0612447517,"dev-research":0.3920649752,"prompt-eng":0.477556958,"data-quality":0.1825557938,"ml-security":0.1233008389}}
{"text":"Having a static analyser for OCaml to C interfaces is useful outside the OCaml 5 porting effort too.   ","meta":{"url":"http://arxiv.org/abs/2307.14909v1"},"cats":{"new-dataset":0.2544550211,"dev-research":0.3818683662,"prompt-eng":0.3946478706,"data-quality":0.1016799519,"ml-security":0.0612059165}}
{"text":"After some motivating examples of real bugs in C bindings a static analyser is presented that finds these known classes of bugs.","meta":{"url":"http://arxiv.org/abs/2307.14909v1"},"cats":{"new-dataset":0.2307408796,"dev-research":0.4564707774,"prompt-eng":0.4578127282,"data-quality":0.3561812704,"ml-security":0.2045181925}}
{"text":"The tool works on the OCaml abstract parse and typed trees, and generates a header file and a caller model.","meta":{"url":"http://arxiv.org/abs/2307.14909v1"},"cats":{"new-dataset":0.4876632838,"dev-research":0.3082503743,"prompt-eng":0.4516924946,"data-quality":0.1424244842,"ml-security":0.0722944625}}
{"text":"Together with a simplified model of the OCaml runtime this is used as input to a static analysis framework, Goblint.","meta":{"url":"http://arxiv.org/abs/2307.14909v1"},"cats":{"new-dataset":0.4100668737,"dev-research":0.3577013614,"prompt-eng":0.4029410674,"data-quality":0.1267360361,"ml-security":0.0895146867}}
{"text":"An analysis is developed that tracks dereferences of OCaml values, and together with the existing framework reports incorrect dereferences.","meta":{"url":"http://arxiv.org/abs/2307.14909v1"},"cats":{"new-dataset":0.1363221597,"dev-research":0.3923390079,"prompt-eng":0.3925445016,"data-quality":0.3261859585,"ml-security":0.1688097297}}
{"text":"An example is shown how to extend the analysis to cover more safety properties.   ","meta":{"url":"http://arxiv.org/abs/2307.14909v1"},"cats":{"new-dataset":0.1877410209,"dev-research":0.3397971445,"prompt-eng":0.3945642782,"data-quality":0.2087687027,"ml-security":0.3886810471}}
{"text":"The tools and runtime models are generic and could be reused with other static analysis tools.","meta":{"url":"http://arxiv.org/abs/2307.14909v1"},"cats":{"new-dataset":0.1986924301,"dev-research":0.3899964716,"prompt-eng":0.394389051,"data-quality":0.1119615267,"ml-security":0.1054605544}}
{"text":"This work introduces TRON, a scalable session-based Transformer Recommender using Optimized Negative-sampling.","meta":{"url":"http://arxiv.org/abs/2307.14906v1"},"cats":{"new-dataset":0.0816788622,"dev-research":0.2500845877,"prompt-eng":0.435394789,"data-quality":0.114670587,"ml-security":0.0812176929}}
{"text":"Motivated by the scalability and performance limitations of prevailing models such as SASRec and GRU4Rec+, TRON integrates top-k negative sampling and listwise loss functions to enhance its recommendation accuracy.","meta":{"url":"http://arxiv.org/abs/2307.14906v1"},"cats":{"new-dataset":0.0590552986,"dev-research":0.210438962,"prompt-eng":0.366160842,"data-quality":0.208158444,"ml-security":0.095617679}}
{"text":"Evaluations on relevant large-scale e-commerce datasets show that TRON improves upon the recommendation quality of current methods while maintaining training speeds similar to SASRec.","meta":{"url":"http://arxiv.org/abs/2307.14906v1"},"cats":{"new-dataset":0.1306252684,"dev-research":0.2678473628,"prompt-eng":0.3802042078,"data-quality":0.2031873088,"ml-security":0.0964173743}}
{"text":"A live A/B test yielded an 18.14% increase in click-through rate over SASRec, highlighting the potential of TRON in practical settings.","meta":{"url":"http://arxiv.org/abs/2307.14906v1"},"cats":{"new-dataset":0.0371907511,"dev-research":0.2913259315,"prompt-eng":0.4811716824,"data-quality":0.1132391393,"ml-security":0.0939955421}}
{"text":"For further research, we provide access to our source code at https://github.com/otto-de/TRON and an anonymized dataset at https://github.com/otto-de/recsys-dataset.","meta":{"url":"http://arxiv.org/abs/2307.14906v1"},"cats":{"new-dataset":0.7729782214,"dev-research":0.1679647483,"prompt-eng":0.4063695219,"data-quality":0.1611417711,"ml-security":0.0833333306}}
{"text":"Representing source code in a generic input format is crucial to automate software engineering tasks, e.g., applying machine learning algorithms to extract information.","meta":{"url":"http://arxiv.org/abs/2307.14902v1"},"cats":{"new-dataset":0.0615997173,"dev-research":0.4837972548,"prompt-eng":0.4243903654,"data-quality":0.2843464415,"ml-security":0.2167530063}}
{"text":"Visualizing code representations can further enable human experts to gain an intuitive insight into the code.","meta":{"url":"http://arxiv.org/abs/2307.14902v1"},"cats":{"new-dataset":0.0260484784,"dev-research":0.5992434565,"prompt-eng":0.3939292696,"data-quality":0.17720156,"ml-security":0.1793958286}}
{"text":"Unfortunately, as of today, there is no universal tool that can simultaneously visualise different types of code representations.","meta":{"url":"http://arxiv.org/abs/2307.14902v1"},"cats":{"new-dataset":0.1665968277,"dev-research":0.3737547776,"prompt-eng":0.4078737423,"data-quality":0.1408915497,"ml-security":0.069871533}}
{"text":"In this paper, we introduce a tool, CodeLens, which provides a visual interaction environment that supports various representation methods and helps developers understand and explore them.","meta":{"url":"http://arxiv.org/abs/2307.14902v1"},"cats":{"new-dataset":0.1654186368,"dev-research":0.5777893492,"prompt-eng":0.4502973426,"data-quality":0.1911693969,"ml-security":0.0887846876}}
{"text":"CodeLens is designed to support multiple programming languages, such as Java, Python, and JavaScript, and four types of code representations, including sequence of tokens, abstract syntax tree (AST), data flow graph (DFG), and control flow graph (CFG).","meta":{"url":"http://arxiv.org/abs/2307.14902v1"},"cats":{"new-dataset":0.2444881898,"dev-research":0.4545049765,"prompt-eng":0.404181757,"data-quality":0.1374106831,"ml-security":0.0813639677}}
{"text":"By using CodeLens, developers can quickly visualize the specific code representation and also obtain the represented inputs for models of code.","meta":{"url":"http://arxiv.org/abs/2307.14902v1"},"cats":{"new-dataset":0.0977632835,"dev-research":0.5869156727,"prompt-eng":0.4356176697,"data-quality":0.1440034754,"ml-security":0.1249885672}}
{"text":"The Web-based interface of CodeLens is available at http://www.codelens.org.","meta":{"url":"http://arxiv.org/abs/2307.14902v1"},"cats":{"new-dataset":0.2351886135,"dev-research":0.3623560265,"prompt-eng":0.4713323154,"data-quality":0.1760214222,"ml-security":0.0512539392}}
{"text":"The demonstration video can be found at http://www.codelens.org/demo.","meta":{"url":"http://arxiv.org/abs/2307.14902v1"},"cats":{"new-dataset":0.1182131771,"dev-research":0.3511938636,"prompt-eng":0.4913016159,"data-quality":0.1714419552,"ml-security":0.0794890187}}
{"text":"The recent surge of foundation models in computer vision and natural language processing opens up perspectives in utilizing multi-modal clinical data to train large models with strong generalizability.","meta":{"url":"http://arxiv.org/abs/2307.14901v1"},"cats":{"new-dataset":0.2023398133,"dev-research":0.1894402565,"prompt-eng":0.3999659883,"data-quality":0.1435905989,"ml-security":0.1115257246}}
{"text":"Yet pathological image datasets often lack biomedical text annotation and enrichment.","meta":{"url":"http://arxiv.org/abs/2307.14901v1"},"cats":{"new-dataset":0.3231885024,"dev-research":0.2013970454,"prompt-eng":0.3498677171,"data-quality":0.4254904649,"ml-security":0.1536330612}}
{"text":"Guiding data-efficient image diagnosis from the use of biomedical text knowledge becomes a substantial interest.","meta":{"url":"http://arxiv.org/abs/2307.14901v1"},"cats":{"new-dataset":0.0892709928,"dev-research":0.2168876817,"prompt-eng":0.4095249278,"data-quality":0.2687959299,"ml-security":0.0877868438}}
{"text":"In this paper, we propose to Connect Image and Text Embeddings (CITE) to enhance pathological image classification.","meta":{"url":"http://arxiv.org/abs/2307.14901v1"},"cats":{"new-dataset":0.2664848051,"dev-research":0.1860913092,"prompt-eng":0.3621646301,"data-quality":0.3504691203,"ml-security":0.1462287923}}
{"text":"CITE injects text insights gained from language models pre-trained with a broad range of biomedical texts, leading to adapt foundation models towards pathological image understanding.","meta":{"url":"http://arxiv.org/abs/2307.14901v1"},"cats":{"new-dataset":0.224259034,"dev-research":0.2492213243,"prompt-eng":0.34227921,"data-quality":0.2701897833,"ml-security":0.0988354528}}
{"text":"Through extensive experiments on the PatchGastric stomach tumor pathological image dataset, we demonstrate that CITE achieves leading performance compared with various baselines especially when training data is scarce.","meta":{"url":"http://arxiv.org/abs/2307.14901v1"},"cats":{"new-dataset":0.5684802505,"dev-research":0.1882657112,"prompt-eng":0.3344634479,"data-quality":0.1946810765,"ml-security":0.1045990017}}
{"text":"CITE offers insights into leveraging in-domain text knowledge to reinforce data-efficient pathological image classification.","meta":{"url":"http://arxiv.org/abs/2307.14901v1"},"cats":{"new-dataset":0.2179256505,"dev-research":0.2388782573,"prompt-eng":0.3517453641,"data-quality":0.2851308642,"ml-security":0.1149566091}}
{"text":"Code is available at https://github.com/Yunkun-Zhang/CITE.","meta":{"url":"http://arxiv.org/abs/2307.14901v1"},"cats":{"new-dataset":0.2907986866,"dev-research":0.1412363387,"prompt-eng":0.4379135374,"data-quality":0.1050705785,"ml-security":0.0351752999}}
{"text":"This paper addresses the problem of selecting of a set of texts for annotation in text classification using retrieval methods when there are limits on the number of annotations due to constraints on human resources.","meta":{"url":"http://arxiv.org/abs/2307.14899v1"},"cats":{"new-dataset":0.2184716652,"dev-research":0.2671602477,"prompt-eng":0.4054560083,"data-quality":0.4900537729,"ml-security":0.1233929889}}
{"text":"An additional challenge addressed is dealing with binary categories that have a small number of positive instances, reflecting severe class imbalance.","meta":{"url":"http://arxiv.org/abs/2307.14899v1"},"cats":{"new-dataset":0.0855291086,"dev-research":0.2469843202,"prompt-eng":0.433767213,"data-quality":0.4636486718,"ml-security":0.2942964465}}
{"text":"In our situation, where annotation occurs over a long time period, the selection of texts to be annotated can be made in batches, with previous annotations guiding the choice of the next set.","meta":{"url":"http://arxiv.org/abs/2307.14899v1"},"cats":{"new-dataset":0.5600189533,"dev-research":0.3083194259,"prompt-eng":0.4415455487,"data-quality":0.3775750693,"ml-security":0.0829145883}}
{"text":"To address these challenges, the paper proposes leveraging SHAP to construct a quality set of queries for Elasticsearch and semantic search, to try to identify optimal sets of texts for annotation that will help with class imbalance.","meta":{"url":"http://arxiv.org/abs/2307.14899v1"},"cats":{"new-dataset":0.1014842733,"dev-research":0.2370534182,"prompt-eng":0.4173750304,"data-quality":0.3569159787,"ml-security":0.1861677904}}
{"text":"The approach is tested on sets of cue texts describing possible future events, constructed by participants involved in studies aimed to help with the management of obesity and diabetes.","meta":{"url":"http://arxiv.org/abs/2307.14899v1"},"cats":{"new-dataset":0.064743295,"dev-research":0.3370805354,"prompt-eng":0.3797194508,"data-quality":0.1594785662,"ml-security":0.077944237}}
{"text":"We introduce an effective method for selecting a small set of texts for annotation and building high-quality classifiers.","meta":{"url":"http://arxiv.org/abs/2307.14899v1"},"cats":{"new-dataset":0.3269891314,"dev-research":0.2797007365,"prompt-eng":0.439858021,"data-quality":0.4701117547,"ml-security":0.0953679047}}
{"text":"We integrate vector search, semantic search, and machine learning classifiers to yield a good solution.","meta":{"url":"http://arxiv.org/abs/2307.14899v1"},"cats":{"new-dataset":0.0626952814,"dev-research":0.2395604115,"prompt-eng":0.4184324585,"data-quality":0.2805331985,"ml-security":0.1332064575}}
{"text":"Our experiments demonstrate improved F1 scores for the minority classes in binary classification.","meta":{"url":"http://arxiv.org/abs/2307.14899v1"},"cats":{"new-dataset":0.1661213986,"dev-research":0.1717937586,"prompt-eng":0.4212012848,"data-quality":0.3981230166,"ml-security":0.1987534309}}
{"text":"Self-supervised learning is popular method because of its ability to learn features in images without using its labels and is able to overcome limited labeled datasets used in supervised learning.","meta":{"url":"http://arxiv.org/abs/2307.14897v1"},"cats":{"new-dataset":0.0280506572,"dev-research":0.2312248682,"prompt-eng":0.3858461524,"data-quality":0.3392650033,"ml-security":0.1854328302}}
{"text":"Self-supervised learning works by using a pretext task which will be trained on the model before being applied to a specific task.","meta":{"url":"http://arxiv.org/abs/2307.14897v1"},"cats":{"new-dataset":0.0119128477,"dev-research":0.2414902536,"prompt-eng":0.4434079931,"data-quality":0.3145235053,"ml-security":0.156379138}}
{"text":"There are some examples of pretext tasks used in self-supervised learning in the field of image recognition, namely rotation prediction, solving jigsaw puzzles, and predicting relative positions on image.","meta":{"url":"http://arxiv.org/abs/2307.14897v1"},"cats":{"new-dataset":0.0744705732,"dev-research":0.223916434,"prompt-eng":0.4083806775,"data-quality":0.1786261868,"ml-security":0.1034863638}}
{"text":"Previous studies have only used one type of transformation as a pretext task.","meta":{"url":"http://arxiv.org/abs/2307.14897v1"},"cats":{"new-dataset":0.0072800221,"dev-research":0.1903914307,"prompt-eng":0.3318727995,"data-quality":0.0806053912,"ml-security":0.0748123846}}
{"text":"This raises the question of how it affects if more than one pretext task is used and to use a gating network to combine all pretext tasks.","meta":{"url":"http://arxiv.org/abs/2307.14897v1"},"cats":{"new-dataset":0.0059096011,"dev-research":0.3252714077,"prompt-eng":0.4167444308,"data-quality":0.2031967938,"ml-security":0.1221854253}}
{"text":"Therefore, we propose the Gated Self-Supervised Learning method to improve image classification which use more than one transformation as pretext task and uses the Mixture of Expert architecture as a gating network in combining each pretext task so that the model automatically can study and focus more on the most useful augmentations for classification.","meta":{"url":"http://arxiv.org/abs/2307.14897v1"},"cats":{"new-dataset":0.1371352251,"dev-research":0.2069591111,"prompt-eng":0.4057338659,"data-quality":0.2804761657,"ml-security":0.1394683587}}
{"text":"We test performance of the proposed method in several scenarios, namely CIFAR imbalance dataset classification, adversarial perturbations, Tiny-Imagenet dataset classification, and semi-supervised learning.","meta":{"url":"http://arxiv.org/abs/2307.14897v1"},"cats":{"new-dataset":0.1150661932,"dev-research":0.1837684354,"prompt-eng":0.3534385632,"data-quality":0.4248819764,"ml-security":0.4854039788}}
{"text":"Moreover, there are Grad-CAM and T-SNE analysis that are used to see the proposed method for identifying important features that influence image classification and representing data for each class and separating different classes properly.","meta":{"url":"http://arxiv.org/abs/2307.14897v1"},"cats":{"new-dataset":0.09691331,"dev-research":0.2605709998,"prompt-eng":0.3764931771,"data-quality":0.2736866125,"ml-security":0.1419561154}}
{"text":"Our code is in https://github.com/aristorenaldo/G-SSL","meta":{"url":"http://arxiv.org/abs/2307.14897v1"},"cats":{"new-dataset":0.2279772519,"dev-research":0.1403123857,"prompt-eng":0.3947254474,"data-quality":0.08853653,"ml-security":0.0704710682}}
{"text":"We present a novel semantics for the language of multi-agent only believing exploiting belief bases, and show how to use it for automatically checking formulas of this language and of its dynamic extension with private belief expansion operators.","meta":{"url":"http://arxiv.org/abs/2307.14893v1"},"cats":{"new-dataset":0.0862475424,"dev-research":0.3054354437,"prompt-eng":0.4607711808,"data-quality":0.1650260393,"ml-security":0.2539777187}}
{"text":"We provide a PSPACE algorithm for model checking relying on a reduction to QBF and alternative dedicated algorithm relying on the exploration of the state space.","meta":{"url":"http://arxiv.org/abs/2307.14893v1"},"cats":{"new-dataset":0.1096685808,"dev-research":0.2682757296,"prompt-eng":0.4781750054,"data-quality":0.1461222007,"ml-security":0.1539497766}}
{"text":"We present an implementation of the QBF-based algorithm and some experimental results on computation time in a concrete example.","meta":{"url":"http://arxiv.org/abs/2307.14893v1"},"cats":{"new-dataset":0.2228684093,"dev-research":0.2580972711,"prompt-eng":0.4405829338,"data-quality":0.1045242368,"ml-security":0.0411617328}}
{"text":"Accurate 3D human pose estimation (3D HPE) is crucial for enabling autonomous vehicles (AVs) to make informed decisions and respond proactively in critical road scenarios.","meta":{"url":"http://arxiv.org/abs/2307.14889v1"},"cats":{"new-dataset":0.1567790238,"dev-research":0.2633440325,"prompt-eng":0.3677564648,"data-quality":0.109154127,"ml-security":0.1204670009}}
{"text":"Promising results of 3D HPE have been gained in several domains such as human-computer interaction, robotics, sports and medical analytics, often based on data collected in well-controlled laboratory environments.","meta":{"url":"http://arxiv.org/abs/2307.14889v1"},"cats":{"new-dataset":0.2571248612,"dev-research":0.2684253703,"prompt-eng":0.3842354164,"data-quality":0.0591830674,"ml-security":0.0571201791}}
{"text":"Nevertheless, the transfer of 3D HPE methods to AVs has received limited research attention, due to the challenges posed by obtaining accurate 3D pose annotations and the limited suitability of data from other domains.   ","meta":{"url":"http://arxiv.org/abs/2307.14889v1"},"cats":{"new-dataset":0.1599490916,"dev-research":0.2143665882,"prompt-eng":0.3628677765,"data-quality":0.1078888799,"ml-security":0.059817247}}
{"text":"We present a simple yet efficient weakly supervised approach for 3D HPE in the AV context by employing a high-level sensor fusion between camera and LiDAR data.","meta":{"url":"http://arxiv.org/abs/2307.14889v1"},"cats":{"new-dataset":0.1873064596,"dev-research":0.2181423619,"prompt-eng":0.4051622323,"data-quality":0.1873933441,"ml-security":0.0948384081}}
{"text":"The weakly supervised setting enables training on the target datasets without any 2D/3D keypoint labels by using an off-the-shelf 2D joint extractor and pseudo labels generated from LiDAR to image projections.","meta":{"url":"http://arxiv.org/abs/2307.14889v1"},"cats":{"new-dataset":0.2241308667,"dev-research":0.200216133,"prompt-eng":0.3769404746,"data-quality":0.2586809607,"ml-security":0.1473780172}}
{"text":"Our approach outperforms state-of-the-art results by up to $\\sim$ 13% on the Waymo Open Dataset in the weakly supervised setting and achieves state-of-the-art results in the supervised setting.","meta":{"url":"http://arxiv.org/abs/2307.14889v1"},"cats":{"new-dataset":0.4842516302,"dev-research":0.1957182102,"prompt-eng":0.4054643647,"data-quality":0.3610498372,"ml-security":0.1073585768}}
{"text":"This paper builds a novel bridge between algebraic coding theory and mathematical knot theory, with applications in both directions.","meta":{"url":"http://arxiv.org/abs/2307.14882v1"},"cats":{"new-dataset":0.1282908136,"dev-research":0.245755123,"prompt-eng":0.3701874223,"data-quality":0.1583799962,"ml-security":0.0818020891}}
{"text":"We give methods to construct error-correcting codes starting from the colorings of a knot, describing through a series of results how the properties of the knot translate into code parameters.","meta":{"url":"http://arxiv.org/abs/2307.14882v1"},"cats":{"new-dataset":0.177939339,"dev-research":0.3972572693,"prompt-eng":0.4433870767,"data-quality":0.4065423165,"ml-security":0.0986931502}}
{"text":"We show that knots can be used to obtain error-correcting codes with prescribed parameters and an efficient decoding algorithm.","meta":{"url":"http://arxiv.org/abs/2307.14882v1"},"cats":{"new-dataset":0.1350435361,"dev-research":0.3116214578,"prompt-eng":0.4242256561,"data-quality":0.3540557838,"ml-security":0.0827826319}}
{"text":"Satellite Internet plays an increasingly important role in geopolitical conflicts.","meta":{"url":"http://arxiv.org/abs/2307.14879v1"},"cats":{"new-dataset":0.0964411322,"dev-research":0.2611414727,"prompt-eng":0.2819021673,"data-quality":0.0984438518,"ml-security":0.1968782296}}
{"text":"This notion was affirmed in the Ukrainian conflict escalating at the beginning of 2022, with the large-scale deployment of the Starlink satellite Internet service which consequently demonstrated the strategic importance of a free flow of information.","meta":{"url":"http://arxiv.org/abs/2307.14879v1"},"cats":{"new-dataset":0.1586787469,"dev-research":0.2462419128,"prompt-eng":0.3388838628,"data-quality":0.1276208904,"ml-security":0.191566735}}
{"text":"Aside from military use, many citizens publish sensitive information on social media platforms to influence the public narrative.","meta":{"url":"http://arxiv.org/abs/2307.14879v1"},"cats":{"new-dataset":0.0744085155,"dev-research":0.227037331,"prompt-eng":0.34442674,"data-quality":0.1689497138,"ml-security":0.3420119126}}
{"text":"However, the use of satellite communication has proven to be dangerous, as the signals can be monitored by other satellites and used to triangulate the source on the ground.","meta":{"url":"http://arxiv.org/abs/2307.14879v1"},"cats":{"new-dataset":0.0627423766,"dev-research":0.3073840228,"prompt-eng":0.3097641081,"data-quality":0.1492178202,"ml-security":0.3144177186}}
{"text":"Unfortunately, the targeted killings of journalists have shown this threat to be effective.","meta":{"url":"http://arxiv.org/abs/2307.14879v1"},"cats":{"new-dataset":0.0408317288,"dev-research":0.2265760662,"prompt-eng":0.3089447813,"data-quality":0.209172933,"ml-security":0.4570465276}}
{"text":"While the increasing deployment of satellite Internet systems gives citizens an unprecedented mouthpiece in conflicts, protecting them against localization is an unaddressed problem.   ","meta":{"url":"http://arxiv.org/abs/2307.14879v1"},"cats":{"new-dataset":0.1761704199,"dev-research":0.3124705926,"prompt-eng":0.3337637457,"data-quality":0.2532946178,"ml-security":0.4642778348}}
{"text":"To address this threat, we present AnonSat, a novel scheme to protect satellite Internet users from triangulation.","meta":{"url":"http://arxiv.org/abs/2307.14879v1"},"cats":{"new-dataset":0.2415037843,"dev-research":0.3161634307,"prompt-eng":0.3953476732,"data-quality":0.1489399614,"ml-security":0.497865745}}
{"text":"AnonSat works with cheap off-the-shelf devices, leveraging long-range wireless communication to span a local network among satellite base stations.","meta":{"url":"http://arxiv.org/abs/2307.14879v1"},"cats":{"new-dataset":0.3454093112,"dev-research":0.2458531098,"prompt-eng":0.3748594669,"data-quality":0.1239173758,"ml-security":0.0610079646}}
{"text":"This allows rerouting users' communication to other satellite base stations, some distance away from each user, thus, preventing their localization.","meta":{"url":"http://arxiv.org/abs/2307.14879v1"},"cats":{"new-dataset":0.0132912003,"dev-research":0.3575858675,"prompt-eng":0.3828636637,"data-quality":0.1245638345,"ml-security":0.1469012109}}
{"text":"AnonSat is designed for easy deployment and usability, which we demonstrate with a prototype implementation.","meta":{"url":"http://arxiv.org/abs/2307.14879v1"},"cats":{"new-dataset":0.2505506825,"dev-research":0.4198302651,"prompt-eng":0.5116855858,"data-quality":0.1483172137,"ml-security":0.0582904368}}
{"text":"Our large-scale network simulations using real-world data sets show the effectiveness of AnonSat in various practical settings.","meta":{"url":"http://arxiv.org/abs/2307.14879v1"},"cats":{"new-dataset":0.3057836435,"dev-research":0.2254522169,"prompt-eng":0.3406757472,"data-quality":0.1523267829,"ml-security":0.1630984989}}
{"text":"The Entity Set Expansion (ESE) task aims to expand a handful of seed entities with new entities belonging to the same semantic class.","meta":{"url":"http://arxiv.org/abs/2307.14878v1"},"cats":{"new-dataset":0.1190983936,"dev-research":0.3045533497,"prompt-eng":0.4231966627,"data-quality":0.2292737051,"ml-security":0.0865530079}}
{"text":"Conventional ESE methods are based on mono-modality (i.e., literal modality), which struggle to deal with complex entities in the real world such as: (1) Negative entities with fine-grained semantic differences.","meta":{"url":"http://arxiv.org/abs/2307.14878v1"},"cats":{"new-dataset":0.0224216802,"dev-research":0.3364883724,"prompt-eng":0.3837714729,"data-quality":0.2186467553,"ml-security":0.0989461371}}
{"text":"(2) Synonymous entities.","meta":{"url":"http://arxiv.org/abs/2307.14878v1"},"cats":{"new-dataset":0.0710586794,"dev-research":0.2682450666,"prompt-eng":0.3565789663,"data-quality":0.2225292555,"ml-security":0.0577656743}}
{"text":"(3) Polysemous entities.","meta":{"url":"http://arxiv.org/abs/2307.14878v1"},"cats":{"new-dataset":0.1581068299,"dev-research":0.2313034526,"prompt-eng":0.3896216537,"data-quality":0.1923784123,"ml-security":0.1138789462}}
{"text":"(4) Long-tailed entities.","meta":{"url":"http://arxiv.org/abs/2307.14878v1"},"cats":{"new-dataset":0.2663139829,"dev-research":0.1401068872,"prompt-eng":0.3727750398,"data-quality":0.1421133056,"ml-security":0.0985651289}}
{"text":"These challenges prompt us to propose Multi-modal Entity Set Expansion (MESE), where models integrate information from multiple modalities to represent entities.","meta":{"url":"http://arxiv.org/abs/2307.14878v1"},"cats":{"new-dataset":0.109251377,"dev-research":0.2346021878,"prompt-eng":0.4436736255,"data-quality":0.1767855519,"ml-security":0.0623063715}}
{"text":"Intuitively, the benefits of multi-modal information for ESE are threefold: (1) Different modalities can provide complementary information.","meta":{"url":"http://arxiv.org/abs/2307.14878v1"},"cats":{"new-dataset":0.0083012703,"dev-research":0.2884141132,"prompt-eng":0.3682077686,"data-quality":0.0971114142,"ml-security":0.0843133674}}
{"text":"(2) Multi-modal information provides a unified signal via common visual properties for the same semantic class or entity.","meta":{"url":"http://arxiv.org/abs/2307.14878v1"},"cats":{"new-dataset":0.0636226211,"dev-research":0.2735082163,"prompt-eng":0.425102579,"data-quality":0.1752136743,"ml-security":0.068013499}}
{"text":"(3) Multi-modal information offers robust alignment signal for synonymous entities.","meta":{"url":"http://arxiv.org/abs/2307.14878v1"},"cats":{"new-dataset":0.0673603058,"dev-research":0.2508535764,"prompt-eng":0.4143062317,"data-quality":0.2743750927,"ml-security":0.05176957}}
{"text":"To assess the performance of model in MESE and facilitate further research, we constructed the MESED dataset which is the first multi-modal dataset for ESE with large-scale and elaborate manual calibration.","meta":{"url":"http://arxiv.org/abs/2307.14878v1"},"cats":{"new-dataset":0.385107219,"dev-research":0.237337147,"prompt-eng":0.4381151349,"data-quality":0.1346364517,"ml-security":0.0500796948}}
{"text":"A powerful multi-modal model MultiExpan is proposed which is pre-trained on four multimodal pre-training tasks.","meta":{"url":"http://arxiv.org/abs/2307.14878v1"},"cats":{"new-dataset":0.1034957783,"dev-research":0.2137472953,"prompt-eng":0.4428617565,"data-quality":0.1494160877,"ml-security":0.0532965721}}
{"text":"The extensive experiments and analyses on MESED demonstrate the high quality of the dataset and the effectiveness of our MultiExpan, as well as pointing the direction for future research.","meta":{"url":"http://arxiv.org/abs/2307.14878v1"},"cats":{"new-dataset":0.4546806325,"dev-research":0.2108394109,"prompt-eng":0.3932286916,"data-quality":0.2258091422,"ml-security":0.0501097145}}
{"text":"Rescheduling problems arise in a variety of situations where a previously planned schedule needs to be adjusted to deal with unforeseen events.","meta":{"url":"http://arxiv.org/abs/2307.14876v1"},"cats":{"new-dataset":0.0917075408,"dev-research":0.3938822493,"prompt-eng":0.3568658286,"data-quality":0.2485599581,"ml-security":0.1679747917}}
{"text":"A common problem is the arrival of new orders, i.e. jobs, which have to be integrated into the schedule of the so-called old jobs.","meta":{"url":"http://arxiv.org/abs/2307.14876v1"},"cats":{"new-dataset":0.0542615011,"dev-research":0.3003639508,"prompt-eng":0.3640107597,"data-quality":0.2266857765,"ml-security":0.1201007356}}
{"text":"The maximum and total absolute time deviations of the completion times of these jobs are modeled as a disruption constraint to limit the change in the original schedule.","meta":{"url":"http://arxiv.org/abs/2307.14876v1"},"cats":{"new-dataset":0.0781791567,"dev-research":0.2049896898,"prompt-eng":0.3743680102,"data-quality":0.1035987709,"ml-security":0.1035167857}}
{"text":"Disruption constraints affect the shape of an optimal schedule, particularly with respect to the sequencing of old jobs and the insertion of idle time.","meta":{"url":"http://arxiv.org/abs/2307.14876v1"},"cats":{"new-dataset":0.0287872737,"dev-research":0.2832706941,"prompt-eng":0.3781902502,"data-quality":0.1055311834,"ml-security":0.1198707734}}
{"text":"We therefore give a classification into idle and no-idle problems for a set of single-machine rescheduling problems with different objective functions.","meta":{"url":"http://arxiv.org/abs/2307.14876v1"},"cats":{"new-dataset":0.1987249829,"dev-research":0.2922138218,"prompt-eng":0.401877186,"data-quality":0.2590174176,"ml-security":0.1843932094}}
{"text":"We then prove the complexity of five rescheduling problems that have been left open in the literature.","meta":{"url":"http://arxiv.org/abs/2307.14876v1"},"cats":{"new-dataset":0.2931603345,"dev-research":0.2576804375,"prompt-eng":0.3438308812,"data-quality":0.1898756394,"ml-security":0.1107046962}}
{"text":"We study the decay of correlation between locally constrained independent random variables in the local lemma regimes.","meta":{"url":"http://arxiv.org/abs/2307.14872v1"},"cats":{"new-dataset":0.1481526341,"dev-research":0.1631850978,"prompt-eng":0.323200647,"data-quality":0.2064854662,"ml-security":0.1790776331}}
{"text":"the distribution defined by constraint satisfaction problems (CSPs) in the local lemma regime.","meta":{"url":"http://arxiv.org/abs/2307.14872v1"},"cats":{"new-dataset":0.090435055,"dev-research":0.1814109248,"prompt-eng":0.385404741,"data-quality":0.2209255645,"ml-security":0.1048250122}}
{"text":"For atomically constrained independent random variables of sufficiently large domains, we show that a decay of correlation property holds up to the local lemma condition $pD^{2+o(1)}\\lesssim 1$, asymptotically matching the sampling threshold for constraint satisfaction solutions","meta":{"url":"http://arxiv.org/abs/2307.14872v1"},"cats":{"new-dataset":0.0999509468,"dev-research":0.1572264736,"prompt-eng":0.3552964253,"data-quality":0.2074653767,"ml-security":0.1451741405}}
{"text":"[BGG+19,GGW22].","meta":{"url":"http://arxiv.org/abs/2307.14872v1"},"cats":{"new-dataset":0.1662833021,"dev-research":0.1730959992,"prompt-eng":0.4044108992,"data-quality":0.0832167237,"ml-security":0.0675728581}}
{"text":"This provides evidence for the conjectured $pD^2\\lesssim 1$ threshold for the \"sampling Lov\\'{a}sz local lemma\".   ","meta":{"url":"http://arxiv.org/abs/2307.14872v1"},"cats":{"new-dataset":0.1967866619,"dev-research":0.1128043967,"prompt-eng":0.3366142367,"data-quality":0.2273360136,"ml-security":0.1208836633}}
{"text":"We use a recursively-constructed coupling to bound the correlation decay.","meta":{"url":"http://arxiv.org/abs/2307.14872v1"},"cats":{"new-dataset":0.102595288,"dev-research":0.1827712818,"prompt-eng":0.3894798836,"data-quality":0.1618739652,"ml-security":0.1217448471}}
{"text":"Our approach completely dispenses with the \"freezing\" paradigm originated from Beck [Bec91], which was commonly used to deal with the non-self-reducibility of the local lemma regimes, and hence can bypass the current technical barriers due to the use of $\\{2,3\\}$-trees.","meta":{"url":"http://arxiv.org/abs/2307.14872v1"},"cats":{"new-dataset":0.1417027818,"dev-research":0.2218693262,"prompt-eng":0.3690423013,"data-quality":0.1736588902,"ml-security":0.1789907261}}
{"text":"This paper elaborates on Conditional Handover (CHO) modelling, aimed at maximizing the use of contention free random access (CFRA) during mobility.","meta":{"url":"http://arxiv.org/abs/2307.14870v1"},"cats":{"new-dataset":0.080510705,"dev-research":0.2511809029,"prompt-eng":0.412128682,"data-quality":0.0652056098,"ml-security":0.1524729644}}
{"text":"This is a desirable behavior as CFRA increases the chance of fast and successful handover.","meta":{"url":"http://arxiv.org/abs/2307.14870v1"},"cats":{"new-dataset":0.0176669179,"dev-research":0.2616677926,"prompt-eng":0.3941856657,"data-quality":0.0871980009,"ml-security":0.0936789311}}
{"text":"In CHO this may be especially challenging as the time between the preparation and the actual cell change can be significantly longer in comparison to non-conditional handover.","meta":{"url":"http://arxiv.org/abs/2307.14870v1"},"cats":{"new-dataset":0.0464944813,"dev-research":0.2816485232,"prompt-eng":0.4192123599,"data-quality":0.0780202092,"ml-security":0.0453270828}}
{"text":"Thus, new means to mitigate this issue need to be defined.","meta":{"url":"http://arxiv.org/abs/2307.14870v1"},"cats":{"new-dataset":0.0632518784,"dev-research":0.3521181201,"prompt-eng":0.3393477505,"data-quality":0.3680048518,"ml-security":0.2004925355}}
{"text":"We present the scheme where beam-specific measurement reporting can lead to CFRA resource updating prior to CHO execution.","meta":{"url":"http://arxiv.org/abs/2307.14870v1"},"cats":{"new-dataset":0.1799965399,"dev-research":0.3060510442,"prompt-eng":0.4821914414,"data-quality":0.140234548,"ml-security":0.0562649644}}
{"text":"We have run system level simulations to confirm that the proposed solution increases the ratio of CFRA attempts during CHO.","meta":{"url":"http://arxiv.org/abs/2307.14870v1"},"cats":{"new-dataset":0.0358679734,"dev-research":0.2689629323,"prompt-eng":0.4367693905,"data-quality":0.0764601368,"ml-security":0.1008516896}}
{"text":"In the best-case scenario, we observe a gain exceeding 13%.","meta":{"url":"http://arxiv.org/abs/2307.14870v1"},"cats":{"new-dataset":0.0420841729,"dev-research":0.2015099123,"prompt-eng":0.3742586243,"data-quality":0.239326232,"ml-security":0.2085394703}}
{"text":"We also show how the average delay of completing the handover is reduced.","meta":{"url":"http://arxiv.org/abs/2307.14870v1"},"cats":{"new-dataset":0.0666423733,"dev-research":0.1989920602,"prompt-eng":0.3832063625,"data-quality":0.1279036466,"ml-security":0.089371544}}
{"text":"To provide the entire perspective, we present at what expense these gains can be achieved by analyzing the increased signaling overhead for updating the random access resources.","meta":{"url":"http://arxiv.org/abs/2307.14870v1"},"cats":{"new-dataset":0.0502875238,"dev-research":0.2273633622,"prompt-eng":0.4567846528,"data-quality":0.1486743645,"ml-security":0.322067023}}
{"text":"The study has been conducted for various network settings and considering higher frequency ranges at which the user communicates with the network.","meta":{"url":"http://arxiv.org/abs/2307.14870v1"},"cats":{"new-dataset":0.0689927379,"dev-research":0.295185596,"prompt-eng":0.4087598658,"data-quality":0.0765089284,"ml-security":0.0631717114}}
{"text":"Finally, we provide an outlook on future extensions of the investigated solution.","meta":{"url":"http://arxiv.org/abs/2307.14870v1"},"cats":{"new-dataset":0.1643699791,"dev-research":0.2069719783,"prompt-eng":0.4043055432,"data-quality":0.154144591,"ml-security":0.0975912822}}
{"text":"Training an effective video action recognition model poses significant computational challenges, particularly under limited resource budgets.","meta":{"url":"http://arxiv.org/abs/2307.14866v1"},"cats":{"new-dataset":0.2001779102,"dev-research":0.1796322204,"prompt-eng":0.3247019356,"data-quality":0.1834132366,"ml-security":0.1215898002}}
{"text":"Current methods primarily aim to either reduce model size or utilize pre-trained models, limiting their adaptability to various backbone architectures.","meta":{"url":"http://arxiv.org/abs/2307.14866v1"},"cats":{"new-dataset":0.0106935751,"dev-research":0.3074091038,"prompt-eng":0.3838202018,"data-quality":0.1005046414,"ml-security":0.1421144167}}
{"text":"This paper investigates the issue of over-sampled frames, a prevalent problem in many approaches yet it has received relatively little attention.","meta":{"url":"http://arxiv.org/abs/2307.14866v1"},"cats":{"new-dataset":0.1804717167,"dev-research":0.1576858644,"prompt-eng":0.3695655996,"data-quality":0.245252349,"ml-security":0.0971255121}}
{"text":"Despite the use of fewer frames being a potential solution, this approach often results in a substantial decline in performance.","meta":{"url":"http://arxiv.org/abs/2307.14866v1"},"cats":{"new-dataset":0.0110794135,"dev-research":0.3385702288,"prompt-eng":0.3886683419,"data-quality":0.2070119799,"ml-security":0.0696689142}}
{"text":"To address this issue, we propose a novel method to restore the intermediate features for two sparsely sampled and adjacent video frames.","meta":{"url":"http://arxiv.org/abs/2307.14866v1"},"cats":{"new-dataset":0.1277965527,"dev-research":0.2061152313,"prompt-eng":0.3529297982,"data-quality":0.2898341979,"ml-security":0.0698579517}}
{"text":"This feature restoration technique brings a negligible increase in computational requirements compared to resource-intensive image encoders, such as ViT. To evaluate the effectiveness of our method, we conduct extensive experiments on four public datasets, including Kinetics-400, ActivityNet, UCF-101, and HMDB-51.","meta":{"url":"http://arxiv.org/abs/2307.14866v1"},"cats":{"new-dataset":0.2187428796,"dev-research":0.2441790635,"prompt-eng":0.3689430306,"data-quality":0.2358537641,"ml-security":0.0942794266}}
{"text":"With the integration of our method, the efficiency of three commonly used baselines has been improved by over 50%, with a mere 0.5% reduction in recognition accuracy.","meta":{"url":"http://arxiv.org/abs/2307.14866v1"},"cats":{"new-dataset":0.1480692212,"dev-research":0.2201928826,"prompt-eng":0.4468872915,"data-quality":0.282597644,"ml-security":0.0438370455}}
{"text":"In addition, our method also surprisingly helps improve the generalization ability of the models under zero-shot settings.","meta":{"url":"http://arxiv.org/abs/2307.14866v1"},"cats":{"new-dataset":0.1028505096,"dev-research":0.1792540699,"prompt-eng":0.361773968,"data-quality":0.2215457142,"ml-security":0.1418889781}}
{"text":"Advanced image tampering techniques are increasingly challenging the trustworthiness of multimedia, leading to the development of Image Manipulation Localization (IML).","meta":{"url":"http://arxiv.org/abs/2307.14863v1"},"cats":{"new-dataset":0.0371787644,"dev-research":0.2837635112,"prompt-eng":0.479562954,"data-quality":0.3369666696,"ml-security":0.2116925701}}
{"text":"But what makes a good IML model?","meta":{"url":"http://arxiv.org/abs/2307.14863v1"},"cats":{"new-dataset":0.0449971372,"dev-research":0.2729863033,"prompt-eng":0.3676272942,"data-quality":0.0958828271,"ml-security":0.0641216743}}
{"text":"The answer lies in the way to capture artifacts.","meta":{"url":"http://arxiv.org/abs/2307.14863v1"},"cats":{"new-dataset":0.1027524647,"dev-research":0.2611417978,"prompt-eng":0.3473311255,"data-quality":0.2342338297,"ml-security":0.0989191641}}
{"text":"Exploiting artifacts requires the model to extract non-semantic discrepancies between the manipulated and authentic regions, which needs to compare differences between these two areas explicitly.","meta":{"url":"http://arxiv.org/abs/2307.14863v1"},"cats":{"new-dataset":0.0256671565,"dev-research":0.3774223999,"prompt-eng":0.417404779,"data-quality":0.3355316546,"ml-security":0.1770442361}}
{"text":"With the self-attention mechanism, naturally, the Transformer is the best candidate.","meta":{"url":"http://arxiv.org/abs/2307.14863v1"},"cats":{"new-dataset":0.0522147218,"dev-research":0.1425613751,"prompt-eng":0.4574627102,"data-quality":0.0886275205,"ml-security":0.0724809963}}
{"text":"Besides, artifacts are sensitive to image resolution, amplified under multi-scale features, and massive at the manipulation border.","meta":{"url":"http://arxiv.org/abs/2307.14863v1"},"cats":{"new-dataset":0.031919711,"dev-research":0.3154178129,"prompt-eng":0.3864757898,"data-quality":0.2388710698,"ml-security":0.0811250524}}
{"text":"Therefore, we formulate the answer to the former question as building a ViT with high-resolution capacity, multi-scale feature extraction capability, and manipulation edge supervision.","meta":{"url":"http://arxiv.org/abs/2307.14863v1"},"cats":{"new-dataset":0.2814246379,"dev-research":0.2649730262,"prompt-eng":0.3857519701,"data-quality":0.1843236065,"ml-security":0.0666328375}}
{"text":"We term this simple but effective ViT paradigm as the IML-ViT, which has great potential to become a new benchmark for IML.","meta":{"url":"http://arxiv.org/abs/2307.14863v1"},"cats":{"new-dataset":0.1147181434,"dev-research":0.2690633331,"prompt-eng":0.424228461,"data-quality":0.1444669433,"ml-security":0.065911262}}
{"text":"Extensive experiments on five benchmark datasets verified our model outperforms the state-of-the-art manipulation localization methods.","meta":{"url":"http://arxiv.org/abs/2307.14863v1"},"cats":{"new-dataset":0.2621943521,"dev-research":0.2822651033,"prompt-eng":0.4603254608,"data-quality":0.2322670084,"ml-security":0.0633999792}}
{"text":"Code and models are available at \\url{https://github.com/SunnyHaze/IML-ViT}","meta":{"url":"http://arxiv.org/abs/2307.14863v1"},"cats":{"new-dataset":0.2834397848,"dev-research":0.1551565456,"prompt-eng":0.4402943474,"data-quality":0.0852944298,"ml-security":0.0376557043}}
{"text":"Quantum computer simulators are crucial for the development of quantum computing.","meta":{"url":"http://arxiv.org/abs/2307.14860v1"},"cats":{"new-dataset":0.0208561616,"dev-research":0.2402213553,"prompt-eng":0.348936047,"data-quality":0.0557188205,"ml-security":0.0860569429}}
{"text":"In this work, we investigate the suitability and performance impact of GPU and multi-GPU systems on a widely used simulation tool - the state vector simulator Qiskit Aer.","meta":{"url":"http://arxiv.org/abs/2307.14860v1"},"cats":{"new-dataset":0.0694964407,"dev-research":0.2290681343,"prompt-eng":0.3706265966,"data-quality":0.0605063585,"ml-security":0.0882493113}}
{"text":"In particular, we evaluate the performance of both Qiskit's default Nvidia Thrust backend and the recent Nvidia cuQuantum backend on Nvidia A100 GPUs.","meta":{"url":"http://arxiv.org/abs/2307.14860v1"},"cats":{"new-dataset":0.1666475586,"dev-research":0.1833725164,"prompt-eng":0.3538652506,"data-quality":0.073737266,"ml-security":0.0745307788}}
{"text":"We provide a benchmark suite of representative quantum applications for characterization.","meta":{"url":"http://arxiv.org/abs/2307.14860v1"},"cats":{"new-dataset":0.0881005562,"dev-research":0.1739521914,"prompt-eng":0.3973476713,"data-quality":0.1359114154,"ml-security":0.094889561}}
{"text":"For simulations with a large number of qubits, the two GPU backends can provide up to 14x speedup over the CPU backend, with Nvidia cuQuantum providing further 1.5-3x speedup over the default Thrust backend.","meta":{"url":"http://arxiv.org/abs/2307.14860v1"},"cats":{"new-dataset":0.1034185612,"dev-research":0.2192652808,"prompt-eng":0.3237994898,"data-quality":0.0361907987,"ml-security":0.0816242741}}
{"text":"Our evaluation on a single GPU identifies the most important functions in Nvidia Thrust and cuQuantum for different quantum applications and their compute and memory bottlenecks.","meta":{"url":"http://arxiv.org/abs/2307.14860v1"},"cats":{"new-dataset":0.1009217806,"dev-research":0.1925272899,"prompt-eng":0.3301854364,"data-quality":0.0534893433,"ml-security":0.074407029}}
{"text":"We also evaluate the gate fusion and cache-blocking optimizations on different quantum applications.","meta":{"url":"http://arxiv.org/abs/2307.14860v1"},"cats":{"new-dataset":0.0107549597,"dev-research":0.2071795147,"prompt-eng":0.3612506419,"data-quality":0.0804002123,"ml-security":0.1288920679}}
{"text":"Finally, we evaluate large-number qubit quantum applications on multi-GPU and identify data movement between host and GPU as the limiting factor for the performance.","meta":{"url":"http://arxiv.org/abs/2307.14860v1"},"cats":{"new-dataset":0.0686668458,"dev-research":0.1855957871,"prompt-eng":0.3517546713,"data-quality":0.0482731337,"ml-security":0.073544598}}
{"text":"Purpose:Chest X-ray (CXR) is an essential tool and one of the most prescribed imaging to detect pulmonary abnormalities, with a yearly estimate of over 2 billion imaging performed worldwide.","meta":{"url":"http://arxiv.org/abs/2307.14859v1"},"cats":{"new-dataset":0.0265603504,"dev-research":0.2465955832,"prompt-eng":0.3659514216,"data-quality":0.0884501449,"ml-security":0.0559289273}}
{"text":"However, the accurate and timely diagnosis of TB remains an unmet goal.","meta":{"url":"http://arxiv.org/abs/2307.14859v1"},"cats":{"new-dataset":0.021003725,"dev-research":0.2402573098,"prompt-eng":0.3791675441,"data-quality":0.2988945645,"ml-security":0.1135355555}}
{"text":"The prevalence of TB is highest in low-middle-income countries, and the requirement of a portable, automated, and reliable solution is required.","meta":{"url":"http://arxiv.org/abs/2307.14859v1"},"cats":{"new-dataset":0.0887356399,"dev-research":0.2269202522,"prompt-eng":0.4097412781,"data-quality":0.0993907966,"ml-security":0.0656868018}}
{"text":"In this study, we compared the performance of DL-based devices on digital and analog CXR.","meta":{"url":"http://arxiv.org/abs/2307.14859v1"},"cats":{"new-dataset":0.02221299,"dev-research":0.3696145661,"prompt-eng":0.4541339259,"data-quality":0.114797651,"ml-security":0.0575084729}}
{"text":"The evaluated DL-based device can be used in resource-constraint settings.","meta":{"url":"http://arxiv.org/abs/2307.14859v1"},"cats":{"new-dataset":0.0799228951,"dev-research":0.3470818424,"prompt-eng":0.4965095073,"data-quality":0.1142959105,"ml-security":0.0659512656}}
{"text":"Methods: A total of 10,000 CXR DICOMs(.dcm) and printed photos of the films acquired with three different cellular phones - Samsung S8, iPhone 8, and iPhone XS along with their radiological report were retrospectively collected from various sites across India from April 2020 to March 2021.","meta":{"url":"http://arxiv.org/abs/2307.14859v1"},"cats":{"new-dataset":0.5488835774,"dev-research":0.1876188276,"prompt-eng":0.3952463337,"data-quality":0.1475685924,"ml-security":0.0427928283}}
{"text":"Results: 10,000 chest X-rays were utilized to evaluate the DL-based device in identifying radiological signs of TB.","meta":{"url":"http://arxiv.org/abs/2307.14859v1"},"cats":{"new-dataset":0.0526344701,"dev-research":0.2350457342,"prompt-eng":0.4346032316,"data-quality":0.1428635255,"ml-security":0.0595596094}}
{"text":"The AUC of qXR for detecting signs of tuberculosis on the original DICOMs dataset was 0.928 with a sensitivity of 0.841 at a specificity of 0.806.","meta":{"url":"http://arxiv.org/abs/2307.14859v1"},"cats":{"new-dataset":0.2031434063,"dev-research":0.1781755167,"prompt-eng":0.4753387315,"data-quality":0.150729854,"ml-security":0.0740497611}}
{"text":"At an optimal threshold, the difference in the AUC of three cellular smartphones with the original DICOMs is 0.024 (2.55%), 0.048 (5.10%), and 0.038 (1.91%).","meta":{"url":"http://arxiv.org/abs/2307.14859v1"},"cats":{"new-dataset":0.0726039796,"dev-research":0.1995979567,"prompt-eng":0.4246009502,"data-quality":0.141520847,"ml-security":0.0596568332}}
{"text":"The minimum difference demonstrates the robustness of the DL-based device in identifying radiological signs of TB in both digital and analog CXR.","meta":{"url":"http://arxiv.org/abs/2307.14859v1"},"cats":{"new-dataset":0.0635015884,"dev-research":0.2576224574,"prompt-eng":0.5134416205,"data-quality":0.2112684768,"ml-security":0.060310695}}
{"text":"In-context learning, which offers substantial advantages over fine-tuning, is predominantly observed in decoder-only models, while encoder-decoder (i.e., seq2seq) models excel in methods that rely on weight updates.","meta":{"url":"http://arxiv.org/abs/2307.14856v1"},"cats":{"new-dataset":0.0846038281,"dev-research":0.2436373465,"prompt-eng":0.3806191531,"data-quality":0.2232496572,"ml-security":0.1194752805}}
{"text":"Recently, a few studies have demonstrated the feasibility of few-shot learning with seq2seq models; however, this has been limited to tasks that align well with the seq2seq architecture, such as summarization and translation.","meta":{"url":"http://arxiv.org/abs/2307.14856v1"},"cats":{"new-dataset":0.1510188425,"dev-research":0.1816430232,"prompt-eng":0.3424253575,"data-quality":0.1691336224,"ml-security":0.0740040352}}
{"text":"Inspired by these initial studies, we provide a first-ever extensive experiment comparing the in-context few-shot learning capabilities of decoder-only and encoder-decoder models on a broad range of tasks.","meta":{"url":"http://arxiv.org/abs/2307.14856v1"},"cats":{"new-dataset":0.1477481666,"dev-research":0.168038574,"prompt-eng":0.3472649175,"data-quality":0.1684044229,"ml-security":0.102483023}}
{"text":"Furthermore, we propose two methods to more effectively elicit in-context learning ability in seq2seq models: objective-aligned prompting and a fusion-based approach.","meta":{"url":"http://arxiv.org/abs/2307.14856v1"},"cats":{"new-dataset":0.0751462932,"dev-research":0.2891316076,"prompt-eng":0.4702744902,"data-quality":0.1855234108,"ml-security":0.0963148297}}
{"text":"Remarkably, our approach outperforms a decoder-only model that is six times larger and exhibits significant performance improvements compared to conventional seq2seq models across a variety of settings.","meta":{"url":"http://arxiv.org/abs/2307.14856v1"},"cats":{"new-dataset":0.1134020374,"dev-research":0.1913602621,"prompt-eng":0.395322728,"data-quality":0.1534440963,"ml-security":0.0722871165}}
{"text":"We posit that, with the right configuration and prompt design, seq2seq models can be highly effective few-shot learners for a wide spectrum of applications.","meta":{"url":"http://arxiv.org/abs/2307.14856v1"},"cats":{"new-dataset":0.2196896579,"dev-research":0.2467771054,"prompt-eng":0.4506788438,"data-quality":0.1631449616,"ml-security":0.0890348084}}
{"text":"Non-line-of-sight (NLOS) imaging methods are capable of reconstructing complex scenes that are not visible to an observer using indirect illumination.","meta":{"url":"http://arxiv.org/abs/2307.14341v1"},"cats":{"new-dataset":0.1192235419,"dev-research":0.1989487459,"prompt-eng":0.3658744924,"data-quality":0.1316861084,"ml-security":0.053595174}}
{"text":"However, they assume only third-bounce illumination, so they are currently limited to single-corner configurations, and present limited visibility when imaging surfaces at certain orientations.","meta":{"url":"http://arxiv.org/abs/2307.14341v1"},"cats":{"new-dataset":0.0678688109,"dev-research":0.1809882718,"prompt-eng":0.3422741863,"data-quality":0.0686911555,"ml-security":0.0800199661}}
{"text":"To reason about and tackle these limitations, we make the key observation that planar diffuse surfaces behave specularly at wavelengths used in the computational wave-based NLOS imaging domain.","meta":{"url":"http://arxiv.org/abs/2307.14341v1"},"cats":{"new-dataset":0.1814331758,"dev-research":0.2056251623,"prompt-eng":0.3245482775,"data-quality":0.0560795144,"ml-security":0.0616594161}}
{"text":"We call such surfaces virtual mirrors.","meta":{"url":"http://arxiv.org/abs/2307.14341v1"},"cats":{"new-dataset":0.0917469894,"dev-research":0.1897720368,"prompt-eng":0.4333602621,"data-quality":0.0899202386,"ml-security":0.0808074817}}
{"text":"We leverage this observation to expand the capabilities of NLOS imaging using illumination beyond the third bounce, addressing two problems: imaging single-corner objects at limited visibility angles, and imaging objects hidden behind two corners.","meta":{"url":"http://arxiv.org/abs/2307.14341v1"},"cats":{"new-dataset":0.1908189265,"dev-research":0.2015913015,"prompt-eng":0.3693240391,"data-quality":0.1268937712,"ml-security":0.0982310808}}
{"text":"To image objects at limited visibility angles, we first analyze the reflections of the known illuminated point on surfaces of the scene as an estimator of the position and orientation of objects with limited visibility.","meta":{"url":"http://arxiv.org/abs/2307.14341v1"},"cats":{"new-dataset":0.1832460718,"dev-research":0.142897788,"prompt-eng":0.4018910812,"data-quality":0.10382137,"ml-security":0.0720261469}}
{"text":"We then image those limited visibility objects by computationally building secondary apertures at other surfaces that observe the target object from a direct visibility perspective.","meta":{"url":"http://arxiv.org/abs/2307.14341v1"},"cats":{"new-dataset":0.2012706978,"dev-research":0.1621238566,"prompt-eng":0.3827134791,"data-quality":0.0679485192,"ml-security":0.1348047902}}
{"text":"Beyond single-corner NLOS imaging, we exploit the specular behavior of virtual mirrors to image objects hidden behind a second corner by imaging the space behind such virtual mirrors, where the mirror image of objects hidden around two corners is formed.","meta":{"url":"http://arxiv.org/abs/2307.14341v1"},"cats":{"new-dataset":0.161330558,"dev-research":0.2404870137,"prompt-eng":0.3944683968,"data-quality":0.1273810912,"ml-security":0.1369713185}}
{"text":"No specular surfaces were involved in the making of this paper.","meta":{"url":"http://arxiv.org/abs/2307.14341v1"},"cats":{"new-dataset":0.0396945931,"dev-research":0.1739527397,"prompt-eng":0.2664164111,"data-quality":0.1479530644,"ml-security":0.0604004667}}
{"text":"Deep learning (DL) models for tabular data problems are receiving increasingly more attention, while the algorithms based on gradient-boosted decision trees (GBDT) remain a strong go-to solution.","meta":{"url":"http://arxiv.org/abs/2307.14338v1"},"cats":{"new-dataset":0.1845266385,"dev-research":0.2634904277,"prompt-eng":0.3460916015,"data-quality":0.1937474467,"ml-security":0.1605311166}}
{"text":"Following the recent trends in other domains, such as natural language processing and computer vision, several retrieval-augmented tabular DL models have been recently proposed.","meta":{"url":"http://arxiv.org/abs/2307.14338v1"},"cats":{"new-dataset":0.0753117747,"dev-research":0.1984671154,"prompt-eng":0.4464511484,"data-quality":0.136469425,"ml-security":0.0465890976}}
{"text":"For a given target object, a retrieval-based model retrieves other relevant objects, such as the nearest neighbors, from the available (training) data and uses their features or even labels to make a better prediction.","meta":{"url":"http://arxiv.org/abs/2307.14338v1"},"cats":{"new-dataset":0.024540512,"dev-research":0.2384006024,"prompt-eng":0.3768655158,"data-quality":0.1267913803,"ml-security":0.1089745122}}
{"text":"However, we show that the existing retrieval-based tabular DL solutions provide only minor, if any, benefits over the properly tuned simple retrieval-free baselines.","meta":{"url":"http://arxiv.org/abs/2307.14338v1"},"cats":{"new-dataset":0.225020789,"dev-research":0.2665858096,"prompt-eng":0.4089921064,"data-quality":0.141442869,"ml-security":0.0544543273}}
{"text":"Thus, it remains unclear whether the retrieval-based approach is a worthy direction for tabular DL.   ","meta":{"url":"http://arxiv.org/abs/2307.14338v1"},"cats":{"new-dataset":0.0821570794,"dev-research":0.2584842349,"prompt-eng":0.4155647217,"data-quality":0.1802205362,"ml-security":0.0510543715}}
{"text":"In this work, we give a strong positive answer to this question.","meta":{"url":"http://arxiv.org/abs/2307.14338v1"},"cats":{"new-dataset":0.1032115449,"dev-research":0.2049728214,"prompt-eng":0.4133418021,"data-quality":0.2296433868,"ml-security":0.1065080814}}
{"text":"We start by incrementally augmenting a simple feed-forward architecture with an attention-like retrieval component similar to those of many (tabular) retrieval-based models.","meta":{"url":"http://arxiv.org/abs/2307.14338v1"},"cats":{"new-dataset":0.1628694848,"dev-research":0.22351915,"prompt-eng":0.4245574718,"data-quality":0.1464704591,"ml-security":0.0492587087}}
{"text":"Then, we highlight several details of the attention mechanism that turn out to have a massive impact on the performance on tabular data problems, but that were not explored in prior work.","meta":{"url":"http://arxiv.org/abs/2307.14338v1"},"cats":{"new-dataset":0.0515475205,"dev-research":0.2805311083,"prompt-eng":0.4492218761,"data-quality":0.1943139795,"ml-security":0.1029151978}}
{"text":"As a result, we design TabR -- a simple retrieval-based tabular DL model which, on a set of public benchmarks, demonstrates the best average performance among tabular DL models, becomes the new state-of-the-art on several datasets, and even outperforms GBDT models on the recently proposed ``GBDT-friendly'' benchmark (see the first figure).","meta":{"url":"http://arxiv.org/abs/2307.14338v1"},"cats":{"new-dataset":0.3392549052,"dev-research":0.2410894805,"prompt-eng":0.4248553409,"data-quality":0.138900504,"ml-security":0.0424032645}}
{"text":"We propose MAMo, a novel memory and attention frame-work for monocular video depth estimation.","meta":{"url":"http://arxiv.org/abs/2307.14336v1"},"cats":{"new-dataset":0.3042781946,"dev-research":0.1525742532,"prompt-eng":0.3388739347,"data-quality":0.1266034467,"ml-security":0.0670708838}}
{"text":"MAMo can augment and improve any single-image depth estimation networks into video depth estimation models, enabling them to take advantage of the temporal information to predict more accurate depth.","meta":{"url":"http://arxiv.org/abs/2307.14336v1"},"cats":{"new-dataset":0.1861421389,"dev-research":0.1805765183,"prompt-eng":0.3190173883,"data-quality":0.1137529927,"ml-security":0.0884893088}}
{"text":"In MAMo, we augment model with memory which aids the depth prediction as the model streams through the video.","meta":{"url":"http://arxiv.org/abs/2307.14336v1"},"cats":{"new-dataset":0.1927645718,"dev-research":0.1914724172,"prompt-eng":0.3516144889,"data-quality":0.1065130886,"ml-security":0.1094013585}}
{"text":"Specifically, the memory stores learned visual and displacement tokens of the previous time instances.","meta":{"url":"http://arxiv.org/abs/2307.14336v1"},"cats":{"new-dataset":0.0657007073,"dev-research":0.2643634904,"prompt-eng":0.4009471495,"data-quality":0.182961881,"ml-security":0.1325737156}}
{"text":"This allows the depth network to cross-reference relevant features from the past when predicting depth on the current frame.","meta":{"url":"http://arxiv.org/abs/2307.14336v1"},"cats":{"new-dataset":0.1258203752,"dev-research":0.2992080033,"prompt-eng":0.3589978161,"data-quality":0.1188617333,"ml-security":0.0944181206}}
{"text":"We introduce a novel scheme to continuously update the memory, optimizing it to keep tokens that correspond with both the past and the present visual information.","meta":{"url":"http://arxiv.org/abs/2307.14336v1"},"cats":{"new-dataset":0.1516131855,"dev-research":0.3405163292,"prompt-eng":0.4527185996,"data-quality":0.1986162568,"ml-security":0.1466283579}}
{"text":"We adopt attention-based approach to process memory features where we first learn the spatio-temporal relation among the resultant visual and displacement memory tokens using self-attention module.","meta":{"url":"http://arxiv.org/abs/2307.14336v1"},"cats":{"new-dataset":0.138945167,"dev-research":0.2986411202,"prompt-eng":0.412768405,"data-quality":0.1775910152,"ml-security":0.0771003884}}
{"text":"Further, the output features of self-attention are aggregated with the current visual features through cross-attention.","meta":{"url":"http://arxiv.org/abs/2307.14336v1"},"cats":{"new-dataset":0.1146207168,"dev-research":0.2422823367,"prompt-eng":0.4162994429,"data-quality":0.2198224085,"ml-security":0.1234545674}}
{"text":"The cross-attended features are finally given to a decoder to predict depth on the current frame.","meta":{"url":"http://arxiv.org/abs/2307.14336v1"},"cats":{"new-dataset":0.2799676169,"dev-research":0.2257605292,"prompt-eng":0.4212155985,"data-quality":0.1331624689,"ml-security":0.0776055561}}
{"text":"Through extensive experiments on several benchmarks, including KITTI, NYU-Depth V2, and DDAD, we show that MAMo consistently improves monocular depth estimation networks and sets new state-of-the-art (SOTA) accuracy.","meta":{"url":"http://arxiv.org/abs/2307.14336v1"},"cats":{"new-dataset":0.2888104246,"dev-research":0.1694241344,"prompt-eng":0.3324350666,"data-quality":0.1348096203,"ml-security":0.0636477462}}
{"text":"Notably, our MAMo video depth estimation provides higher accuracy with lower latency, when omparing to SOTA cost-volume-based video depth models.","meta":{"url":"http://arxiv.org/abs/2307.14336v1"},"cats":{"new-dataset":0.191091694,"dev-research":0.1590837496,"prompt-eng":0.3441213302,"data-quality":0.1407482328,"ml-security":0.0587113557}}
{"text":"Large Language Models (LLMs) have shown great promise in integrating diverse expert models to tackle intricate language and vision tasks.","meta":{"url":"http://arxiv.org/abs/2307.14335v1"},"cats":{"new-dataset":0.1875327521,"dev-research":0.2108595876,"prompt-eng":0.4170227442,"data-quality":0.1547069555,"ml-security":0.0883914266}}
{"text":"Despite their significance in advancing the field of Artificial Intelligence Generated Content (AIGC), their potential in intelligent audio content creation remains unexplored.","meta":{"url":"http://arxiv.org/abs/2307.14335v1"},"cats":{"new-dataset":0.102587728,"dev-research":0.2996581373,"prompt-eng":0.3418427985,"data-quality":0.2869622992,"ml-security":0.0734736322}}
{"text":"In this work, we tackle the problem of creating audio content with storylines encompassing speech, music, and sound effects, guided by text instructions.","meta":{"url":"http://arxiv.org/abs/2307.14335v1"},"cats":{"new-dataset":0.3016295658,"dev-research":0.3455433683,"prompt-eng":0.3747693334,"data-quality":0.1585834142,"ml-security":0.052113709}}
{"text":"We present WavJourney, a system that leverages LLMs to connect various audio models for audio content generation.","meta":{"url":"http://arxiv.org/abs/2307.14335v1"},"cats":{"new-dataset":0.2983835016,"dev-research":0.2438503346,"prompt-eng":0.4119444721,"data-quality":0.1882908629,"ml-security":0.0523599234}}
{"text":"Given a text description of an auditory scene, WavJourney first prompts LLMs to generate a structured script dedicated to audio storytelling.","meta":{"url":"http://arxiv.org/abs/2307.14335v1"},"cats":{"new-dataset":0.3500924952,"dev-research":0.2899579037,"prompt-eng":0.4248322452,"data-quality":0.168069235,"ml-security":0.0503667675}}
{"text":"The audio script incorporates diverse audio elements, organized based on their spatio-temporal relationships.","meta":{"url":"http://arxiv.org/abs/2307.14335v1"},"cats":{"new-dataset":0.4154134582,"dev-research":0.2431975154,"prompt-eng":0.3480311208,"data-quality":0.1153957518,"ml-security":0.0423795075}}
{"text":"As a conceptual representation of audio, the audio script provides an interactive and interpretable rationale for human engagement.","meta":{"url":"http://arxiv.org/abs/2307.14335v1"},"cats":{"new-dataset":0.1019014912,"dev-research":0.4541422354,"prompt-eng":0.3714890736,"data-quality":0.1584606357,"ml-security":0.0734563465}}
{"text":"Afterward, the audio script is fed into a script compiler, converting it into a computer program.","meta":{"url":"http://arxiv.org/abs/2307.14335v1"},"cats":{"new-dataset":0.060036474,"dev-research":0.4433387884,"prompt-eng":0.4088173525,"data-quality":0.1651810062,"ml-security":0.0834314258}}
{"text":"Each line of the program calls a task-specific audio generation model or computational operation function (e.g., concatenate, mix).","meta":{"url":"http://arxiv.org/abs/2307.14335v1"},"cats":{"new-dataset":0.1785271323,"dev-research":0.3771981042,"prompt-eng":0.4140126081,"data-quality":0.1488232492,"ml-security":0.0418839418}}
{"text":"The computer program is then executed to obtain an explainable solution for audio generation.","meta":{"url":"http://arxiv.org/abs/2307.14335v1"},"cats":{"new-dataset":0.0603589825,"dev-research":0.4068873252,"prompt-eng":0.4093439073,"data-quality":0.1496403329,"ml-security":0.0633277093}}
{"text":"We demonstrate the practicality of WavJourney across diverse real-world scenarios, including science fiction, education, and radio play.","meta":{"url":"http://arxiv.org/abs/2307.14335v1"},"cats":{"new-dataset":0.3636818841,"dev-research":0.3131924178,"prompt-eng":0.3731351246,"data-quality":0.1337552947,"ml-security":0.0794554328}}
{"text":"The explainable and interactive design of WavJourney fosters human-machine co-creation in multi-round dialogues, enhancing creative control and adaptability in audio production.","meta":{"url":"http://arxiv.org/abs/2307.14335v1"},"cats":{"new-dataset":0.210253417,"dev-research":0.4351399233,"prompt-eng":0.3796501806,"data-quality":0.150777182,"ml-security":0.0531116077}}
{"text":"WavJourney audiolizes the human imagination, opening up new avenues for creativity in multimedia content creation.","meta":{"url":"http://arxiv.org/abs/2307.14335v1"},"cats":{"new-dataset":0.2156888353,"dev-research":0.3633972787,"prompt-eng":0.3381846297,"data-quality":0.1510025843,"ml-security":0.0437953154}}
{"text":"Medicine is inherently multimodal, with rich data modalities spanning text, imaging, genomics, and more.","meta":{"url":"http://arxiv.org/abs/2307.14334v1"},"cats":{"new-dataset":0.2388947572,"dev-research":0.2392016333,"prompt-eng":0.3341941573,"data-quality":0.1013482981,"ml-security":0.0717072454}}
{"text":"Generalist biomedical artificial intelligence (AI) systems that flexibly encode, integrate, and interpret this data at scale can potentially enable impactful applications ranging from scientific discovery to care delivery.","meta":{"url":"http://arxiv.org/abs/2307.14334v1"},"cats":{"new-dataset":0.084647911,"dev-research":0.2347656386,"prompt-eng":0.3319376993,"data-quality":0.0944374305,"ml-security":0.1612091413}}
{"text":"To enable the development of these models, we first curate MultiMedBench, a new multimodal biomedical benchmark.","meta":{"url":"http://arxiv.org/abs/2307.14334v1"},"cats":{"new-dataset":0.3999363953,"dev-research":0.1832393347,"prompt-eng":0.3601247784,"data-quality":0.1034324148,"ml-security":0.0474334317}}
{"text":"MultiMedBench encompasses 14 diverse tasks such as medical question answering, mammography and dermatology image interpretation, radiology report generation and summarization, and genomic variant calling.","meta":{"url":"http://arxiv.org/abs/2307.14334v1"},"cats":{"new-dataset":0.2796411557,"dev-research":0.2415159909,"prompt-eng":0.3797488542,"data-quality":0.1109617562,"ml-security":0.0489020073}}
{"text":"We then introduce Med-PaLM Multimodal (Med-PaLM M), our proof of concept for a generalist biomedical AI system.","meta":{"url":"http://arxiv.org/abs/2307.14334v1"},"cats":{"new-dataset":0.2750608214,"dev-research":0.1908567371,"prompt-eng":0.3839927698,"data-quality":0.1300031328,"ml-security":0.1247739664}}
{"text":"Med-PaLM M is a large multimodal generative model that flexibly encodes and interprets biomedical data including clinical language, imaging, and genomics with the same set of model weights.","meta":{"url":"http://arxiv.org/abs/2307.14334v1"},"cats":{"new-dataset":0.1952825607,"dev-research":0.1899293544,"prompt-eng":0.3861641582,"data-quality":0.0973448415,"ml-security":0.0589741216}}
{"text":"Med-PaLM M reaches performance competitive with or exceeding the state of the art on all MultiMedBench tasks, often surpassing specialist models by a wide margin.","meta":{"url":"http://arxiv.org/abs/2307.14334v1"},"cats":{"new-dataset":0.0675877292,"dev-research":0.174381112,"prompt-eng":0.3819707445,"data-quality":0.0715322708,"ml-security":0.0423287023}}
{"text":"We also report examples of zero-shot generalization to novel medical concepts and tasks, positive transfer learning across tasks, and emergent zero-shot medical reasoning.","meta":{"url":"http://arxiv.org/abs/2307.14334v1"},"cats":{"new-dataset":0.165115443,"dev-research":0.2331919105,"prompt-eng":0.357453013,"data-quality":0.1892431395,"ml-security":0.1591664648}}
{"text":"To further probe the capabilities and limitations of Med-PaLM M, we conduct a radiologist evaluation of model-generated (and human) chest X-ray reports and observe encouraging performance across model scales.","meta":{"url":"http://arxiv.org/abs/2307.14334v1"},"cats":{"new-dataset":0.0595995644,"dev-research":0.2102508163,"prompt-eng":0.3827600599,"data-quality":0.0955203274,"ml-security":0.0539186765}}
{"text":"In a side-by-side ranking on 246 retrospective chest X-rays, clinicians express a pairwise preference for Med-PaLM M reports over those produced by radiologists in up to 40.50% of cases, suggesting potential clinical utility.","meta":{"url":"http://arxiv.org/abs/2307.14334v1"},"cats":{"new-dataset":0.0294465949,"dev-research":0.1998348672,"prompt-eng":0.362981214,"data-quality":0.1280613101,"ml-security":0.0599854895}}
{"text":"While considerable work is needed to validate these models in real-world use cases, our results represent a milestone towards the development of generalist biomedical AI systems.","meta":{"url":"http://arxiv.org/abs/2307.14334v1"},"cats":{"new-dataset":0.1095954566,"dev-research":0.1958846463,"prompt-eng":0.3929905523,"data-quality":0.1514696145,"ml-security":0.1803406346}}
{"text":"Neuromorphic visual sensors are artificial retinas that output sequences of asynchronous events when brightness changes occur in the scene.","meta":{"url":"http://arxiv.org/abs/2307.14332v1"},"cats":{"new-dataset":0.079174922,"dev-research":0.262735189,"prompt-eng":0.4043773986,"data-quality":0.1182257748,"ml-security":0.130693202}}
{"text":"These sensors offer many advantages including very high temporal resolution, no motion blur and smart data compression ideal for real-time processing.","meta":{"url":"http://arxiv.org/abs/2307.14332v1"},"cats":{"new-dataset":0.1271334558,"dev-research":0.2288133929,"prompt-eng":0.3318257052,"data-quality":0.0607116891,"ml-security":0.0517374211}}
{"text":"In this study, we introduce an event-based dataset on fine-grained manipulation actions and perform an experimental study on the use of transformers for action prediction with events.","meta":{"url":"http://arxiv.org/abs/2307.14332v1"},"cats":{"new-dataset":0.3389156238,"dev-research":0.3211170298,"prompt-eng":0.4505188494,"data-quality":0.1319374366,"ml-security":0.1059899175}}
{"text":"There is enormous interest in the fields of cognitive robotics and human-robot interaction on understanding and predicting human actions as early as possible.","meta":{"url":"http://arxiv.org/abs/2307.14332v1"},"cats":{"new-dataset":0.1182549517,"dev-research":0.2343512126,"prompt-eng":0.4389614607,"data-quality":0.0859305213,"ml-security":0.0937059062}}
{"text":"Early prediction allows anticipating complex stages for planning, enabling effective and real-time interaction.","meta":{"url":"http://arxiv.org/abs/2307.14332v1"},"cats":{"new-dataset":0.1233853611,"dev-research":0.363130959,"prompt-eng":0.4542005843,"data-quality":0.0590537898,"ml-security":0.0795683792}}
{"text":"Our Transformer network uses events to predict manipulation actions as they occur, using online inference.","meta":{"url":"http://arxiv.org/abs/2307.14332v1"},"cats":{"new-dataset":0.0878667763,"dev-research":0.2853775174,"prompt-eng":0.4483039022,"data-quality":0.1144655259,"ml-security":0.1849028649}}
{"text":"The model succeeds at predicting actions early on, building up confidence over time and achieving state-of-the-art classification.","meta":{"url":"http://arxiv.org/abs/2307.14332v1"},"cats":{"new-dataset":0.1135538934,"dev-research":0.221305788,"prompt-eng":0.3993903491,"data-quality":0.1715389878,"ml-security":0.1810010315}}
{"text":"Moreover, the attention-based transformer architecture allows us to study the role of the spatio-temporal patterns selected by the model.","meta":{"url":"http://arxiv.org/abs/2307.14332v1"},"cats":{"new-dataset":0.0870498277,"dev-research":0.2096900262,"prompt-eng":0.4040295837,"data-quality":0.0687353822,"ml-security":0.0652143776}}
{"text":"Our experiments show that the Transformer network captures action dynamic features outperforming video-based approaches and succeeding with scenarios where the differences between actions lie in very subtle cues.","meta":{"url":"http://arxiv.org/abs/2307.14332v1"},"cats":{"new-dataset":0.0797735441,"dev-research":0.3165312818,"prompt-eng":0.3797993975,"data-quality":0.1872565463,"ml-security":0.1501110681}}
{"text":"Finally, we release the new event dataset, which is the first in the literature for manipulation action recognition.","meta":{"url":"http://arxiv.org/abs/2307.14332v1"},"cats":{"new-dataset":0.726460874,"dev-research":0.2306488308,"prompt-eng":0.3756655148,"data-quality":0.1607492575,"ml-security":0.1269673427}}
{"text":"Code will be available at https://github.com/DaniDeniz/EventVisionTransformer.","meta":{"url":"http://arxiv.org/abs/2307.14332v1"},"cats":{"new-dataset":0.3546169175,"dev-research":0.2297315088,"prompt-eng":0.4958101736,"data-quality":0.1522540031,"ml-security":0.0280184735}}
{"text":"Text-conditioned image editing has emerged as a powerful tool for editing images.","meta":{"url":"http://arxiv.org/abs/2307.14331v1"},"cats":{"new-dataset":0.0562596722,"dev-research":0.2667990937,"prompt-eng":0.449558942,"data-quality":0.183540379,"ml-security":0.0642992483}}
{"text":"However, in many situations, language can be ambiguous and ineffective in describing specific image edits.","meta":{"url":"http://arxiv.org/abs/2307.14331v1"},"cats":{"new-dataset":0.0105163051,"dev-research":0.36470825,"prompt-eng":0.3812376555,"data-quality":0.5108484027,"ml-security":0.1465723376}}
{"text":"When faced with such challenges, visual prompts can be a more informative and intuitive way to convey ideas.","meta":{"url":"http://arxiv.org/abs/2307.14331v1"},"cats":{"new-dataset":0.0812089927,"dev-research":0.4626866524,"prompt-eng":0.5157744561,"data-quality":0.1776853431,"ml-security":0.1572679702}}
{"text":"We present a method for image editing via visual prompting.","meta":{"url":"http://arxiv.org/abs/2307.14331v1"},"cats":{"new-dataset":0.0503896761,"dev-research":0.4046074751,"prompt-eng":0.5562773444,"data-quality":0.1890770041,"ml-security":0.0625021299}}
{"text":"Given pairs of example that represent the \"before\" and \"after\" images of an edit, our goal is to learn a text-based editing direction that can be used to perform the same edit on new images.","meta":{"url":"http://arxiv.org/abs/2307.14331v1"},"cats":{"new-dataset":0.1401801737,"dev-research":0.3064827684,"prompt-eng":0.4282671034,"data-quality":0.2072234479,"ml-security":0.0524024774}}
{"text":"We leverage the rich, pretrained editing capabilities of text-to-image diffusion models by inverting visual prompts into editing instructions.","meta":{"url":"http://arxiv.org/abs/2307.14331v1"},"cats":{"new-dataset":0.1153831022,"dev-research":0.2701614207,"prompt-eng":0.4775707862,"data-quality":0.1865039061,"ml-security":0.1237448204}}
{"text":"Our results show that with just one example pair, we can achieve competitive results compared to state-of-the-art text-conditioned image editing frameworks.","meta":{"url":"http://arxiv.org/abs/2307.14331v1"},"cats":{"new-dataset":0.1385106093,"dev-research":0.2419433138,"prompt-eng":0.4371610057,"data-quality":0.2239216537,"ml-security":0.0578697836}}
{"text":"While imitation learning methods have seen a resurgent interest for robotic manipulation, the well-known problem of compounding errors continues to afflict behavioral cloning (BC).","meta":{"url":"http://arxiv.org/abs/2307.14326v1"},"cats":{"new-dataset":0.0241656816,"dev-research":0.2860664995,"prompt-eng":0.4209003656,"data-quality":0.2669996951,"ml-security":0.1498243891}}
{"text":"Waypoints can help address this problem by reducing the horizon of the learning problem for BC, and thus, the errors compounded over time.","meta":{"url":"http://arxiv.org/abs/2307.14326v1"},"cats":{"new-dataset":0.1183599804,"dev-research":0.282545518,"prompt-eng":0.3981354686,"data-quality":0.3638859731,"ml-security":0.1850285817}}
{"text":"However, waypoint labeling is underspecified, and requires additional human supervision.","meta":{"url":"http://arxiv.org/abs/2307.14326v1"},"cats":{"new-dataset":0.0266535647,"dev-research":0.3195289391,"prompt-eng":0.448794485,"data-quality":0.423579698,"ml-security":0.1135106687}}
{"text":"Can we generate waypoints automatically without any additional human supervision?","meta":{"url":"http://arxiv.org/abs/2307.14326v1"},"cats":{"new-dataset":0.0733816587,"dev-research":0.3390812833,"prompt-eng":0.4882044395,"data-quality":0.1641501082,"ml-security":0.0872354995}}
{"text":"Our key insight is that if a trajectory segment can be approximated by linear motion, the endpoints can be used as waypoints.","meta":{"url":"http://arxiv.org/abs/2307.14326v1"},"cats":{"new-dataset":0.0329785876,"dev-research":0.2264573391,"prompt-eng":0.3526053863,"data-quality":0.0981755479,"ml-security":0.0735289829}}
{"text":"We propose Automatic Waypoint Extraction (AWE) for imitation learning, a preprocessing module to decompose a demonstration into a minimal set of waypoints which when interpolated linearly can approximate the trajectory up to a specified error threshold.","meta":{"url":"http://arxiv.org/abs/2307.14326v1"},"cats":{"new-dataset":0.2043324074,"dev-research":0.2694680445,"prompt-eng":0.4131794754,"data-quality":0.1495129698,"ml-security":0.0819430529}}
{"text":"AWE can be combined with any BC algorithm, and we find that AWE can increase the success rate of state-of-the-art algorithms by up to 25% in simulation and by 4-28% on real-world bimanual manipulation tasks, reducing the decision making horizon by up to a factor of 10.","meta":{"url":"http://arxiv.org/abs/2307.14326v1"},"cats":{"new-dataset":0.0611143216,"dev-research":0.2693772471,"prompt-eng":0.4616764427,"data-quality":0.0964548481,"ml-security":0.0544393324}}
{"text":"Videos and code are available at https://lucys0.github.io/awe/","meta":{"url":"http://arxiv.org/abs/2307.14326v1"},"cats":{"new-dataset":0.5008688079,"dev-research":0.1665492615,"prompt-eng":0.4421657096,"data-quality":0.0825765499,"ml-security":0.0305647895}}
{"text":"This paper presents a case study on the design, administration, post-processing, and evaluation of surveys on large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2307.14324v1"},"cats":{"new-dataset":0.1550508571,"dev-research":0.2154172639,"prompt-eng":0.4705651129,"data-quality":0.1990989459,"ml-security":0.047180493}}
{"text":"It comprises two components: (1) A statistical method for eliciting beliefs encoded in LLMs.","meta":{"url":"http://arxiv.org/abs/2307.14324v1"},"cats":{"new-dataset":0.0506216207,"dev-research":0.2212943799,"prompt-eng":0.4885164099,"data-quality":0.1397461591,"ml-security":0.0710864406}}
{"text":"We introduce statistical measures and evaluation metrics that quantify the probability of an LLM \"making a choice\", the associated uncertainty, and the consistency of that choice.","meta":{"url":"http://arxiv.org/abs/2307.14324v1"},"cats":{"new-dataset":0.0276674864,"dev-research":0.1755390404,"prompt-eng":0.4967541504,"data-quality":0.2301485646,"ml-security":0.0890532507}}
{"text":"(2) We apply this method to study what moral beliefs are encoded in different LLMs, especially in ambiguous cases where the right choice is not obvious.","meta":{"url":"http://arxiv.org/abs/2307.14324v1"},"cats":{"new-dataset":0.0304002327,"dev-research":0.2089094019,"prompt-eng":0.3987588122,"data-quality":0.2342303826,"ml-security":0.1642898906}}
{"text":"We design a large-scale survey comprising 680 high-ambiguity moral scenarios (e.g., \"Should I tell a white lie?\") and 687 low-ambiguity moral scenarios (e.g., \"Should I stop for a pedestrian on the road?\").","meta":{"url":"http://arxiv.org/abs/2307.14324v1"},"cats":{"new-dataset":0.1247006607,"dev-research":0.2554496448,"prompt-eng":0.3611877857,"data-quality":0.219764351,"ml-security":0.2234645517}}
{"text":"Each scenario includes a description, two possible actions, and auxiliary labels indicating violated rules (e.g., \"do not kill\").","meta":{"url":"http://arxiv.org/abs/2307.14324v1"},"cats":{"new-dataset":0.1046172021,"dev-research":0.3311131159,"prompt-eng":0.4383677649,"data-quality":0.2819679493,"ml-security":0.209944455}}
{"text":"We administer the survey to 28 open- and closed-source LLMs.","meta":{"url":"http://arxiv.org/abs/2307.14324v1"},"cats":{"new-dataset":0.6391770079,"dev-research":0.1764935925,"prompt-eng":0.4289705552,"data-quality":0.148773695,"ml-security":0.1039171677}}
{"text":"We find that (a) in unambiguous scenarios, most models \"choose\" actions that align with commonsense.","meta":{"url":"http://arxiv.org/abs/2307.14324v1"},"cats":{"new-dataset":0.0424830751,"dev-research":0.2449861234,"prompt-eng":0.3906980585,"data-quality":0.2088905636,"ml-security":0.1773728183}}
{"text":"In ambiguous cases, most models express uncertainty.","meta":{"url":"http://arxiv.org/abs/2307.14324v1"},"cats":{"new-dataset":0.011081495,"dev-research":0.2664863937,"prompt-eng":0.3630574244,"data-quality":0.2336700744,"ml-security":0.1289226464}}
{"text":"(b) Some models are uncertain about choosing the commonsense action because their responses are sensitive to the question-wording.","meta":{"url":"http://arxiv.org/abs/2307.14324v1"},"cats":{"new-dataset":0.0259953739,"dev-research":0.2190196149,"prompt-eng":0.4021108974,"data-quality":0.306728574,"ml-security":0.1830059523}}
{"text":"(c) Some models reflect clear preferences in ambiguous scenarios.","meta":{"url":"http://arxiv.org/abs/2307.14324v1"},"cats":{"new-dataset":0.02195826,"dev-research":0.3126774354,"prompt-eng":0.4451567872,"data-quality":0.2481465569,"ml-security":0.1960013586}}
{"text":"Specifically, closed-source models tend to agree with each other.","meta":{"url":"http://arxiv.org/abs/2307.14324v1"},"cats":{"new-dataset":0.0442821392,"dev-research":0.2847367394,"prompt-eng":0.3104938553,"data-quality":0.1909904638,"ml-security":0.1600626099}}
{"text":"Safety is critical to broadening the application of reinforcement learning (RL).","meta":{"url":"http://arxiv.org/abs/2307.14316v1"},"cats":{"new-dataset":0.0368891244,"dev-research":0.2988880783,"prompt-eng":0.3388281856,"data-quality":0.1572928414,"ml-security":0.3905552861}}
{"text":"Often, we train RL agents in a controlled environment, such as a laboratory, before deploying them in the real world.","meta":{"url":"http://arxiv.org/abs/2307.14316v1"},"cats":{"new-dataset":0.2119822468,"dev-research":0.3074547898,"prompt-eng":0.4145692543,"data-quality":0.1100754742,"ml-security":0.1765055267}}
{"text":"However, the real-world target task might be unknown prior to deployment.","meta":{"url":"http://arxiv.org/abs/2307.14316v1"},"cats":{"new-dataset":0.0238599481,"dev-research":0.3283951678,"prompt-eng":0.4526811025,"data-quality":0.2202420566,"ml-security":0.2396521213}}
{"text":"Reward-free RL trains an agent without the reward to adapt quickly once the reward is revealed.","meta":{"url":"http://arxiv.org/abs/2307.14316v1"},"cats":{"new-dataset":0.0957238409,"dev-research":0.1973605376,"prompt-eng":0.3962748263,"data-quality":0.1002682938,"ml-security":0.1463850936}}
{"text":"We consider the constrained reward-free setting, where an agent (the guide) learns to explore safely without the reward signal.","meta":{"url":"http://arxiv.org/abs/2307.14316v1"},"cats":{"new-dataset":0.1395406905,"dev-research":0.2007612659,"prompt-eng":0.3989201523,"data-quality":0.0987100773,"ml-security":0.2338599722}}
{"text":"This agent is trained in a controlled environment, which allows unsafe interactions and still provides the safety signal.","meta":{"url":"http://arxiv.org/abs/2307.14316v1"},"cats":{"new-dataset":0.0861662551,"dev-research":0.2927001678,"prompt-eng":0.3765884656,"data-quality":0.0913791721,"ml-security":0.3432721591}}
{"text":"After the target task is revealed, safety violations are not allowed anymore.","meta":{"url":"http://arxiv.org/abs/2307.14316v1"},"cats":{"new-dataset":0.1155475239,"dev-research":0.2878627797,"prompt-eng":0.3287460461,"data-quality":0.3181740997,"ml-security":0.4555244308}}
{"text":"Thus, the guide is leveraged to compose a safe behaviour policy.","meta":{"url":"http://arxiv.org/abs/2307.14316v1"},"cats":{"new-dataset":0.1350734884,"dev-research":0.3374760249,"prompt-eng":0.3792062918,"data-quality":0.1654515166,"ml-security":0.2811970871}}
{"text":"Drawing from transfer learning, we also regularize a target policy (the student) towards the guide while the student is unreliable and gradually eliminate the influence of the guide as training progresses.","meta":{"url":"http://arxiv.org/abs/2307.14316v1"},"cats":{"new-dataset":0.044125703,"dev-research":0.3571681576,"prompt-eng":0.4718533433,"data-quality":0.2537052995,"ml-security":0.1867676364}}
{"text":"The empirical analysis shows that this method can achieve safe transfer learning and helps the student solve the target task faster.","meta":{"url":"http://arxiv.org/abs/2307.14316v1"},"cats":{"new-dataset":0.0249814128,"dev-research":0.3652602656,"prompt-eng":0.3992532886,"data-quality":0.1904898897,"ml-security":0.2305280903}}
{"text":"Reinforcement learning is of increasing importance in the field of robot control and simulation plays a~key role in this process.","meta":{"url":"http://arxiv.org/abs/2307.14313v1"},"cats":{"new-dataset":0.0608637689,"dev-research":0.2160212915,"prompt-eng":0.3593748984,"data-quality":0.0663635143,"ml-security":0.1067998633}}
{"text":"In the unmanned aerial vehicles (UAVs, drones), there is also an increase in the number of published scientific papers involving this approach.","meta":{"url":"http://arxiv.org/abs/2307.14313v1"},"cats":{"new-dataset":0.0503114125,"dev-research":0.2068166506,"prompt-eng":0.3550800242,"data-quality":0.080573773,"ml-security":0.0906617804}}
{"text":"In this work, an autonomous drone control system was prepared to fly forward (according to its coordinates system) and pass the trees encountered in the forest based on the data from a rotating LiDAR sensor.","meta":{"url":"http://arxiv.org/abs/2307.14313v1"},"cats":{"new-dataset":0.2541154748,"dev-research":0.2052153441,"prompt-eng":0.4131533107,"data-quality":0.0856946237,"ml-security":0.094743572}}
{"text":"The Proximal Policy Optimization (PPO) algorithm, an example of reinforcement learning (RL), was used to prepare it.","meta":{"url":"http://arxiv.org/abs/2307.14313v1"},"cats":{"new-dataset":0.1024345081,"dev-research":0.2162550913,"prompt-eng":0.3919858856,"data-quality":0.0779690525,"ml-security":0.1196334173}}
{"text":"A custom simulator in the Python language was developed for this purpose.","meta":{"url":"http://arxiv.org/abs/2307.14313v1"},"cats":{"new-dataset":0.3445058071,"dev-research":0.2178200367,"prompt-eng":0.4942673011,"data-quality":0.0958690204,"ml-security":0.0469995164}}
{"text":"The Gazebo environment, integrated with the Robot Operating System (ROS), was also used to test the resulting control algorithm.","meta":{"url":"http://arxiv.org/abs/2307.14313v1"},"cats":{"new-dataset":0.088589166,"dev-research":0.3102972941,"prompt-eng":0.4754218423,"data-quality":0.0595346747,"ml-security":0.0623355555}}
{"text":"Finally, the prepared solution was implemented in the Nvidia Jetson Nano eGPU and verified in the real tests scenarios.","meta":{"url":"http://arxiv.org/abs/2307.14313v1"},"cats":{"new-dataset":0.2183567355,"dev-research":0.1708899846,"prompt-eng":0.402254713,"data-quality":0.0904250436,"ml-security":0.0583266488}}
{"text":"During them, the drone successfully completed the set task and was able to repeatably avoid trees and fly through the forest.","meta":{"url":"http://arxiv.org/abs/2307.14313v1"},"cats":{"new-dataset":0.1181689598,"dev-research":0.2593367574,"prompt-eng":0.3768500699,"data-quality":0.1320879018,"ml-security":0.0614898955}}
{"text":"Experimental data can aid in gaining insights about a system operation, as well as determining critical aspects of a modelling or simulation process.","meta":{"url":"http://arxiv.org/abs/2307.14312v1"},"cats":{"new-dataset":0.1341557982,"dev-research":0.3957871575,"prompt-eng":0.434873499,"data-quality":0.1405001661,"ml-security":0.1426876822}}
{"text":"In this paper, we analyze the data acquired from an extensive experimentation process in a serverless Function as a Service system (based on the open source Apache Openwhisk) that has been deployed across 3 available cloud/edge locations with different system setups.","meta":{"url":"http://arxiv.org/abs/2307.14312v1"},"cats":{"new-dataset":0.389809422,"dev-research":0.2247434493,"prompt-eng":0.4068543781,"data-quality":0.1416354713,"ml-security":0.1294278114}}
{"text":"Thus, they can be used to model distribution of functions through multi-location aware scheduling mechanisms.","meta":{"url":"http://arxiv.org/abs/2307.14312v1"},"cats":{"new-dataset":0.0615124688,"dev-research":0.2844506557,"prompt-eng":0.4179030409,"data-quality":0.0871033774,"ml-security":0.0852475946}}
{"text":"The experiments include different traffic arrival rates, different setups for the FaaS system, as well as different configurations for the hardware and platform used.","meta":{"url":"http://arxiv.org/abs/2307.14312v1"},"cats":{"new-dataset":0.032265943,"dev-research":0.1932473404,"prompt-eng":0.3539630855,"data-quality":0.1005343241,"ml-security":0.0556209632}}
{"text":"We analyse the acquired data for the three FaaS system setups and discuss their differences presenting interesting conclusions with relation to transient effects of the system, such as the effect on wait and execution time.","meta":{"url":"http://arxiv.org/abs/2307.14312v1"},"cats":{"new-dataset":0.0628142591,"dev-research":0.2554447609,"prompt-eng":0.4191825167,"data-quality":0.1167091748,"ml-security":0.1174361106}}
{"text":"We also demonstrate interesting trade-offs with relation to system setup and indicate a number of factors that can affect system performance and should be taken under consideration in modelling attempts of such systems.","meta":{"url":"http://arxiv.org/abs/2307.14312v1"},"cats":{"new-dataset":0.0436074591,"dev-research":0.3450796039,"prompt-eng":0.5110168878,"data-quality":0.1130879231,"ml-security":0.0790590914}}
{"text":"This study is main goal is to provide a comparative comparison of libraries using machine learning methods.","meta":{"url":"http://arxiv.org/abs/2307.14311v1"},"cats":{"new-dataset":0.0855772711,"dev-research":0.2668796881,"prompt-eng":0.3908201183,"data-quality":0.1636876394,"ml-security":0.0728230291}}
{"text":"Experts in natural language processing (NLP) are becoming more and more interested in sentiment analysis (SA) of text changes.","meta":{"url":"http://arxiv.org/abs/2307.14311v1"},"cats":{"new-dataset":0.1068669022,"dev-research":0.3004815794,"prompt-eng":0.3483587895,"data-quality":0.2660992339,"ml-security":0.0846390041}}
{"text":"The objective of employing NLP text analysis techniques is to recognize and categorize feelings related to twitter users utterances.","meta":{"url":"http://arxiv.org/abs/2307.14311v1"},"cats":{"new-dataset":0.037067876,"dev-research":0.3117334378,"prompt-eng":0.3438921004,"data-quality":0.2389682804,"ml-security":0.0761514124}}
{"text":"In this examination, issues with SA and the libraries utilized are also looked at.","meta":{"url":"http://arxiv.org/abs/2307.14311v1"},"cats":{"new-dataset":0.2029863793,"dev-research":0.2926061206,"prompt-eng":0.3876884847,"data-quality":0.1499470418,"ml-security":0.0593190765}}
{"text":"provides a number of cooperative methods to classify emotional polarity.","meta":{"url":"http://arxiv.org/abs/2307.14311v1"},"cats":{"new-dataset":0.0360305664,"dev-research":0.2797619491,"prompt-eng":0.3941787174,"data-quality":0.1825423746,"ml-security":0.0936097886}}
{"text":"The Naive Bayes Classifier, Decision Tree Classifier, Maxent Classifier, Sklearn Classifier, Sklearn Classifier MultinomialNB, and other conjoint learning algorithms, according to recent research, are very effective.","meta":{"url":"http://arxiv.org/abs/2307.14311v1"},"cats":{"new-dataset":0.2063022889,"dev-research":0.2104611477,"prompt-eng":0.3725620433,"data-quality":0.2202176157,"ml-security":0.153501716}}
{"text":"In the project will use Five Python and R libraries NLTK, TextBlob, Vader, Transformers (GPT and BERT pretrained), and Tidytext will be used in the study to apply sentiment analysis techniques.","meta":{"url":"http://arxiv.org/abs/2307.14311v1"},"cats":{"new-dataset":0.3451933882,"dev-research":0.2681216148,"prompt-eng":0.3577129056,"data-quality":0.2147551197,"ml-security":0.0489499213}}
{"text":"Four machine learning models Tree of Decisions (DT), Support Vector Machine (SVM), Naive Bayes (NB), and K-Nearest Neighbor (KNN) will also be used.","meta":{"url":"http://arxiv.org/abs/2307.14311v1"},"cats":{"new-dataset":0.2743988227,"dev-research":0.2197924721,"prompt-eng":0.4263788994,"data-quality":0.1645160662,"ml-security":0.0980048785}}
{"text":"To evaluate how well libraries for SA operate in the social network environment, comparative study was also carried out.","meta":{"url":"http://arxiv.org/abs/2307.14311v1"},"cats":{"new-dataset":0.0756187454,"dev-research":0.3269435881,"prompt-eng":0.3518046772,"data-quality":0.1340658312,"ml-security":0.0557679482}}
{"text":"The measures to assess the best algorithms in this experiment, which used a single data set for each method, were precision, recall, and F1 score.","meta":{"url":"http://arxiv.org/abs/2307.14311v1"},"cats":{"new-dataset":0.071231018,"dev-research":0.2427153708,"prompt-eng":0.4218322042,"data-quality":0.1813920142,"ml-security":0.0440594501}}
{"text":"We conclude that the BERT transformer method with an Accuracy: 0.973 is recommended for sentiment analysis.","meta":{"url":"http://arxiv.org/abs/2307.14311v1"},"cats":{"new-dataset":0.0321285014,"dev-research":0.2427818657,"prompt-eng":0.3658681571,"data-quality":0.3498499287,"ml-security":0.0632045984}}
{"text":"When faced with a large number of product reviews, it is not clear that a human can remember all of them and weight opinions representatively to write a good reference summary.","meta":{"url":"http://arxiv.org/abs/2307.14305v1"},"cats":{"new-dataset":0.0740395521,"dev-research":0.2937554428,"prompt-eng":0.3536046054,"data-quality":0.2093974555,"ml-security":0.0470446532}}
{"text":"We propose an automatic metric to test the prevalence of the opinions that a summary expresses, based on counting the number of reviews that are consistent with each statement in the summary, while discrediting trivial or redundant statements.","meta":{"url":"http://arxiv.org/abs/2307.14305v1"},"cats":{"new-dataset":0.0574366001,"dev-research":0.3325926656,"prompt-eng":0.4225307856,"data-quality":0.4670987663,"ml-security":0.0948127731}}
{"text":"To formulate this opinion prevalence metric, we consider several existing methods to score the factual consistency of a summary statement with respect to each individual source review.","meta":{"url":"http://arxiv.org/abs/2307.14305v1"},"cats":{"new-dataset":0.0554914133,"dev-research":0.3304074514,"prompt-eng":0.373019007,"data-quality":0.4224931283,"ml-security":0.0710317376}}
{"text":"On a corpus of Amazon product reviews, we gather multiple human judgments of the opinion consistency, to determine which automatic metric best expresses consistency in product reviews.","meta":{"url":"http://arxiv.org/abs/2307.14305v1"},"cats":{"new-dataset":0.1626994469,"dev-research":0.2883995245,"prompt-eng":0.4180967184,"data-quality":0.5038520039,"ml-security":0.0487473645}}
{"text":"Using the resulting opinion prevalence metric, we show that a human authored summary has only slightly better opinion prevalence than randomly selected extracts from the source reviews, and previous extractive and abstractive unsupervised opinion summarization methods perform worse than humans.","meta":{"url":"http://arxiv.org/abs/2307.14305v1"},"cats":{"new-dataset":0.0864605469,"dev-research":0.2834648592,"prompt-eng":0.3564153039,"data-quality":0.3597067368,"ml-security":0.0799654142}}
{"text":"We demonstrate room for improvement with a greedy construction of extractive summaries with twice the opinion prevalence achieved by humans.","meta":{"url":"http://arxiv.org/abs/2307.14305v1"},"cats":{"new-dataset":0.1158247772,"dev-research":0.2705282085,"prompt-eng":0.3661480296,"data-quality":0.3306630625,"ml-security":0.0934471619}}
{"text":"Finally, we show that preprocessing source reviews by simplification can raise the opinion prevalence achieved by existing abstractive opinion summarization systems to the level of human performance.","meta":{"url":"http://arxiv.org/abs/2307.14305v1"},"cats":{"new-dataset":0.0698384598,"dev-research":0.4142740261,"prompt-eng":0.3725241581,"data-quality":0.3646435645,"ml-security":0.0899781155}}
{"text":"Recent tropical cyclones, e.g., Hurricane Harvey (2017), have lead to significant rainfall and resulting runoff with accompanying flooding.","meta":{"url":"http://arxiv.org/abs/2307.14302v1"},"cats":{"new-dataset":0.0873340194,"dev-research":0.2674136143,"prompt-eng":0.3659661643,"data-quality":0.1200614378,"ml-security":0.1735794111}}
{"text":"When the runoff interacts with storm surge, the resulting floods can be greatly amplified and lead to effects that cannot be modeled by simple superposition of its distinctive sources.","meta":{"url":"http://arxiv.org/abs/2307.14302v1"},"cats":{"new-dataset":0.0383664457,"dev-research":0.2651736141,"prompt-eng":0.4030482742,"data-quality":0.1712680889,"ml-security":0.248057019}}
{"text":"In an effort to develop accurate numerical simulations of runoff, surge, and compounding floods, we develop a local discontinuous Galerkin method for modified shallow water equations.","meta":{"url":"http://arxiv.org/abs/2307.14302v1"},"cats":{"new-dataset":0.066286228,"dev-research":0.2827468068,"prompt-eng":0.304929627,"data-quality":0.1100191191,"ml-security":0.0879272926}}
{"text":"In this modification, nonzero sources to the continuity equation are included to incorporate rainfall into the model using parametric rainfall models from literature as well as hindcast data.","meta":{"url":"http://arxiv.org/abs/2307.14302v1"},"cats":{"new-dataset":0.1933304277,"dev-research":0.18515586,"prompt-eng":0.3825031348,"data-quality":0.0829619062,"ml-security":0.0512213083}}
{"text":"The discontinuous Galerkin spatial discretization is accompanied with a strong stability preserving explicit Runge Kutta time integrator.","meta":{"url":"http://arxiv.org/abs/2307.14302v1"},"cats":{"new-dataset":0.0536183797,"dev-research":0.210776791,"prompt-eng":0.2833403772,"data-quality":0.0614127378,"ml-security":0.0781017579}}
{"text":"Hence, temporal stability is ensured through the CFL condition and we exploit the embarrassingly parallel nature of the developed method using MPI parallelization.","meta":{"url":"http://arxiv.org/abs/2307.14302v1"},"cats":{"new-dataset":0.0439348308,"dev-research":0.2790150385,"prompt-eng":0.3927535582,"data-quality":0.1146851498,"ml-security":0.0819068571}}
{"text":"We demonstrate the capabilities of the developed method though a sequence of physically relevant numerical tests, including small scale test cases based on laboratory measurements and large scale experiments with Hurricane Harvey in the Gulf of Mexico.","meta":{"url":"http://arxiv.org/abs/2307.14302v1"},"cats":{"new-dataset":0.1524548782,"dev-research":0.1922655592,"prompt-eng":0.3749783203,"data-quality":0.0954376506,"ml-security":0.0901768354}}
{"text":"The results highlight the conservation properties and robustness of the developed method and show the potential of compound flood modeling using our approach.","meta":{"url":"http://arxiv.org/abs/2307.14302v1"},"cats":{"new-dataset":0.0570064296,"dev-research":0.2428127962,"prompt-eng":0.3550244319,"data-quality":0.1017090044,"ml-security":0.123401982}}
{"text":"We contribute to the knowledge of linear codes from special polynomials and functions, which have been studied intensively in the past few years.","meta":{"url":"http://arxiv.org/abs/2307.14300v1"},"cats":{"new-dataset":0.1890131877,"dev-research":0.1653965148,"prompt-eng":0.3315405013,"data-quality":0.1499343835,"ml-security":0.1892702572}}
{"text":"Such codes have several applications in secret sharing, authentication codes, association schemes and strongly regular graphs.   ","meta":{"url":"http://arxiv.org/abs/2307.14300v1"},"cats":{"new-dataset":0.113608597,"dev-research":0.2100359459,"prompt-eng":0.3920460791,"data-quality":0.1526056782,"ml-security":0.3020366258}}
{"text":"This is the first work in which we study the dual codes in the framework of the two generic constructions; in particular, we propose a Gram-Schmidt (complexity of $\\mathcal{O}(n^3)$) process to compute them explicitly.","meta":{"url":"http://arxiv.org/abs/2307.14300v1"},"cats":{"new-dataset":0.207622438,"dev-research":0.1802615764,"prompt-eng":0.3187881547,"data-quality":0.1529578551,"ml-security":0.0931909828}}
{"text":"The originality of this contribution is in the study of the existence or not of defining sets $D'$, which can be used as ingredients to construct the dual code $\\mathcal{C}'$ for a given code $\\mathcal{C}$ in the context of the second generic construction.","meta":{"url":"http://arxiv.org/abs/2307.14300v1"},"cats":{"new-dataset":0.0698094262,"dev-research":0.3204905268,"prompt-eng":0.3149188141,"data-quality":0.1627911717,"ml-security":0.1578049691}}
{"text":"We also determine a necessary condition expressed by employing the Walsh transform for a codeword of $\\mathcal{C}$ to belong in the dual.","meta":{"url":"http://arxiv.org/abs/2307.14300v1"},"cats":{"new-dataset":0.0881562165,"dev-research":0.1806348963,"prompt-eng":0.3941089098,"data-quality":0.2229645125,"ml-security":0.1240820709}}
{"text":"This achievement was done in general and when the involved functions are weakly regularly bent.","meta":{"url":"http://arxiv.org/abs/2307.14300v1"},"cats":{"new-dataset":0.0460059518,"dev-research":0.1755922799,"prompt-eng":0.3754126993,"data-quality":0.1440904636,"ml-security":0.0751384961}}
{"text":"We shall give a novel description of the Hull code in the framework of the two generic constructions.","meta":{"url":"http://arxiv.org/abs/2307.14300v1"},"cats":{"new-dataset":0.2873500982,"dev-research":0.2226083962,"prompt-eng":0.3666340834,"data-quality":0.1151663643,"ml-security":0.071570403}}
{"text":"Our primary interest is constructing linear codes of fixed Hull dimension and determining the (Hamming) weight of the codewords in their duals.","meta":{"url":"http://arxiv.org/abs/2307.14300v1"},"cats":{"new-dataset":0.2306911649,"dev-research":0.2419282661,"prompt-eng":0.3681063164,"data-quality":0.166121141,"ml-security":0.1052597212}}
{"text":"Recommender systems have become indispensable tools in the hotel hospitality industry, enabling personalized and tailored experiences for guests.","meta":{"url":"http://arxiv.org/abs/2307.14298v1"},"cats":{"new-dataset":0.0241624407,"dev-research":0.2750995856,"prompt-eng":0.3890194728,"data-quality":0.1318367634,"ml-security":0.0977477682}}
{"text":"Recent advancements in large language models (LLMs), such as ChatGPT, and persuasive technologies, have opened new avenues for enhancing the effectiveness of those systems.","meta":{"url":"http://arxiv.org/abs/2307.14298v1"},"cats":{"new-dataset":0.0687419702,"dev-research":0.242853051,"prompt-eng":0.4080433635,"data-quality":0.1800003142,"ml-security":0.1232708993}}
{"text":"This paper explores the potential of integrating ChatGPT and persuasive technologies for automating and improving hotel hospitality recommender systems.","meta":{"url":"http://arxiv.org/abs/2307.14298v1"},"cats":{"new-dataset":0.0617618934,"dev-research":0.3462839628,"prompt-eng":0.4271679665,"data-quality":0.15577761,"ml-security":0.0731216562}}
{"text":"First, we delve into the capabilities of ChatGPT, which can understand and generate human-like text, enabling more accurate and context-aware recommendations.","meta":{"url":"http://arxiv.org/abs/2307.14298v1"},"cats":{"new-dataset":0.3249787175,"dev-research":0.3127851191,"prompt-eng":0.3953413817,"data-quality":0.1899293396,"ml-security":0.0590266121}}
{"text":"We discuss the integration of ChatGPT into recommender systems, highlighting the ability to analyze user preferences, extract valuable insights from online reviews, and generate personalized recommendations based on guest profiles.","meta":{"url":"http://arxiv.org/abs/2307.14298v1"},"cats":{"new-dataset":0.1352242029,"dev-research":0.3539347835,"prompt-eng":0.3972570194,"data-quality":0.1407746719,"ml-security":0.0695503372}}
{"text":"Second, we investigate the role of persuasive technology in influencing user behavior and enhancing the persuasive impact of hotel recommendations.","meta":{"url":"http://arxiv.org/abs/2307.14298v1"},"cats":{"new-dataset":0.0087660063,"dev-research":0.3757271156,"prompt-eng":0.4230095911,"data-quality":0.148705295,"ml-security":0.1365984748}}
{"text":"By incorporating persuasive techniques, such as social proof, scarcity and personalization, recommender systems can effectively influence user decision-making and encourage desired actions, such as booking a specific hotel or upgrading their room.","meta":{"url":"http://arxiv.org/abs/2307.14298v1"},"cats":{"new-dataset":0.0129945848,"dev-research":0.3944539435,"prompt-eng":0.417711591,"data-quality":0.1378436337,"ml-security":0.2033386576}}
{"text":"To investigate the efficacy of ChatGPT and persuasive technologies, we present a pilot experi-ment with a case study involving a hotel recommender system.","meta":{"url":"http://arxiv.org/abs/2307.14298v1"},"cats":{"new-dataset":0.0671783351,"dev-research":0.3745272479,"prompt-eng":0.4222986224,"data-quality":0.1418199707,"ml-security":0.0860116004}}
{"text":"We aim to study the impact of integrating ChatGPT and persua-sive techniques on user engagement, satisfaction, and conversion rates.","meta":{"url":"http://arxiv.org/abs/2307.14298v1"},"cats":{"new-dataset":0.0506497708,"dev-research":0.3454697107,"prompt-eng":0.423805435,"data-quality":0.1683528783,"ml-security":0.0485684481}}
{"text":"The preliminary results demonstrate the potential of these technologies in enhancing the overall guest experience and business performance.","meta":{"url":"http://arxiv.org/abs/2307.14298v1"},"cats":{"new-dataset":0.0098710782,"dev-research":0.3187768669,"prompt-eng":0.4315370169,"data-quality":0.1010774307,"ml-security":0.0455772742}}
{"text":"Overall, this paper contributes to the field of hotel hospitality by exploring the synergistic relationship between LLMs and persuasive technology in recommender systems, ultimately influencing guest satisfaction and hotel revenue.","meta":{"url":"http://arxiv.org/abs/2307.14298v1"},"cats":{"new-dataset":0.0119672214,"dev-research":0.2483779042,"prompt-eng":0.4113706937,"data-quality":0.1608468305,"ml-security":0.0881674789}}
{"text":"Splitting of sequential data, such as videos and time series, is an essential step in various data analysis tasks, including object tracking and anomaly detection.","meta":{"url":"http://arxiv.org/abs/2307.14294v1"},"cats":{"new-dataset":0.1400333829,"dev-research":0.2496867388,"prompt-eng":0.348370664,"data-quality":0.1669969125,"ml-security":0.1600765368}}
{"text":"However, splitting sequential data presents a variety of challenges that can impact the accuracy and reliability of subsequent analyses.","meta":{"url":"http://arxiv.org/abs/2307.14294v1"},"cats":{"new-dataset":0.0959511745,"dev-research":0.2627431628,"prompt-eng":0.3627637401,"data-quality":0.1748601212,"ml-security":0.0795669337}}
{"text":"This concept article examines the challenges associated with splitting sequential data, including data acquisition, data representation, split ratio selection, setting up quality criteria, and choosing suitable selection strategies.","meta":{"url":"http://arxiv.org/abs/2307.14294v1"},"cats":{"new-dataset":0.085666839,"dev-research":0.2615833338,"prompt-eng":0.4226464119,"data-quality":0.1328664092,"ml-security":0.0603998392}}
{"text":"We explore these challenges through two real-world examples: motor test benches and particle tracking in liquids.","meta":{"url":"http://arxiv.org/abs/2307.14294v1"},"cats":{"new-dataset":0.0628927799,"dev-research":0.2314852319,"prompt-eng":0.3958934108,"data-quality":0.1339388619,"ml-security":0.0835000645}}
{"text":"A proof-labeling scheme (PLS) for a boolean predicate $\\Pi$ on labeled graphs is a mechanism used for certifying the legality with respect to $\\Pi$ of global network states in a distributed manner.","meta":{"url":"http://arxiv.org/abs/2307.14292v1"},"cats":{"new-dataset":0.0671178649,"dev-research":0.2924227826,"prompt-eng":0.4186899823,"data-quality":0.313992807,"ml-security":0.2133489346}}
{"text":"In a PLS, a certificate is assigned to each processing node of the network, and the nodes are in charge of checking that the collection of certificates forms a global proof that the system is in a correct state, by exchanging the certificates once, between neighbors only.","meta":{"url":"http://arxiv.org/abs/2307.14292v1"},"cats":{"new-dataset":0.0324285951,"dev-research":0.2379123062,"prompt-eng":0.3981854964,"data-quality":0.1685255239,"ml-security":0.1595362079}}
{"text":"The main measure of complexity is the size of the certificates.","meta":{"url":"http://arxiv.org/abs/2307.14292v1"},"cats":{"new-dataset":0.0291759229,"dev-research":0.2506452919,"prompt-eng":0.304201025,"data-quality":0.1020584218,"ml-security":0.071159012}}
{"text":"Many PLSs have been designed for certifying specific predicates, including cycle-freeness, minimum-weight spanning tree, planarity, etc.   ","meta":{"url":"http://arxiv.org/abs/2307.14292v1"},"cats":{"new-dataset":0.0672730821,"dev-research":0.2527424609,"prompt-eng":0.4178288828,"data-quality":0.1300364392,"ml-security":0.0836681524}}
{"text":"In 2021, a breakthrough has been obtained, as a meta-theorem stating that a large set of properties have compact PLSs in a large class of networks.","meta":{"url":"http://arxiv.org/abs/2307.14292v1"},"cats":{"new-dataset":0.1943698943,"dev-research":0.1695857937,"prompt-eng":0.3228913793,"data-quality":0.1476478757,"ml-security":0.1712346048}}
{"text":"Namely, for every $\\mathrm{MSO}_2$ property $\\Pi$ on labeled graphs, there exists a PLS for $\\Pi$ with $O(\\log n)$-bit certificates for all graphs of bounded tree-depth.","meta":{"url":"http://arxiv.org/abs/2307.14292v1"},"cats":{"new-dataset":0.117346217,"dev-research":0.1881078283,"prompt-eng":0.3586315,"data-quality":0.2279780332,"ml-security":0.159359016}}
{"text":"This result has been extended to the larger class of graphs with bounded {tree-width}, using certificates on $O(\\log^2 n)$ bits.   ","meta":{"url":"http://arxiv.org/abs/2307.14292v1"},"cats":{"new-dataset":0.3216592586,"dev-research":0.1708957614,"prompt-eng":0.3204521184,"data-quality":0.2230679869,"ml-security":0.1601097906}}
{"text":"We extend this result even further, to the larger class of graphs with bounded clique-width, which, as opposed to the other two aforementioned classes, includes dense graphs.","meta":{"url":"http://arxiv.org/abs/2307.14292v1"},"cats":{"new-dataset":0.2045109024,"dev-research":0.2077551879,"prompt-eng":0.2845727827,"data-quality":0.2040459624,"ml-security":0.1617933294}}
{"text":"We show that, for every $\\mathrm{MSO}_1$ property $\\Pi$ on labeled graphs, there exists a PLS for $\\Pi$ with $O(\\log^2 n)$ bit certificates for all graphs of bounded clique-width.","meta":{"url":"http://arxiv.org/abs/2307.14292v1"},"cats":{"new-dataset":0.2200823698,"dev-research":0.2014296786,"prompt-eng":0.3455867966,"data-quality":0.2111122705,"ml-security":0.1774106049}}
{"text":"We take as a case study the spread of Germanic syntactic features into Romance dialects of North-Eastern Italy, which occurred after the immigration of German people in the Tyrol during the High Middle Ages.   ","meta":{"url":"http://arxiv.org/abs/2307.14291v1"},"cats":{"new-dataset":0.3911675392,"dev-research":0.2483068772,"prompt-eng":0.3690055937,"data-quality":0.1910551261,"ml-security":0.1245081677}}
{"text":"An interactive map is produced using tools of what is called Geographic Data Science.","meta":{"url":"http://arxiv.org/abs/2307.14291v1"},"cats":{"new-dataset":0.2685499447,"dev-research":0.3880883683,"prompt-eng":0.4390321449,"data-quality":0.1137520236,"ml-security":0.0460522634}}
{"text":"A smooth two-dimensional surface $\\mathcal{G}$ expresses locally which fraction of territory uses a given German language feature: it is obtained by interpolating a discrete function that says if at any surveyed locality that feature is used or not.\\newline   This surface $\\mathcal{G}$ is thought of as the value at the present time of a function describing a diffusion-convection phenomenon in two dimensions (here said \\emph{tidal} mode), which is subjected in a very natural way to the same equation, suitably contextualized, used in physics for a number of phenomenological facts like the heat diffusion.","meta":{"url":"http://arxiv.org/abs/2307.14291v1"},"cats":{"new-dataset":0.1810647001,"dev-research":0.2078770737,"prompt-eng":0.3056343733,"data-quality":0.1036044329,"ml-security":0.1011692332}}
{"text":"It is shown that solutions of this equation, evaluated at the present time, fit well with the data as interpolated by $\\mathcal{G}$, thus providing convincing pictures of diffusion-convection of the linguistic features of the case study, albeit simplifications and approximations.\\newline   Very importantly, it is shown that Schmidt's 'waves' can be counted among the solutions of the diffusion equation: superimposing Schmidt 'waves' to a 'tidal flooding' can reproduce complexities of real linguistic diffusion events.","meta":{"url":"http://arxiv.org/abs/2307.14291v1"},"cats":{"new-dataset":0.2229714945,"dev-research":0.2091341438,"prompt-eng":0.3298152389,"data-quality":0.1543196679,"ml-security":0.1179420596}}
{"text":"We introduce and study the cumulative information generating function, which provides a unifying mathematical tool suitable to deal with classical and fractional entropies based on the cumulative distribution function and on the survival function.","meta":{"url":"http://arxiv.org/abs/2307.14290v1"},"cats":{"new-dataset":0.1186016717,"dev-research":0.1656037832,"prompt-eng":0.4242314688,"data-quality":0.1500419306,"ml-security":0.1069197407}}
{"text":"Specifically, after establishing its main properties and some bounds, we show that it is a variability measure itself that extends the Gini mean semi-difference.","meta":{"url":"http://arxiv.org/abs/2307.14290v1"},"cats":{"new-dataset":0.1000463406,"dev-research":0.1917935699,"prompt-eng":0.3920329288,"data-quality":0.1741117562,"ml-security":0.0723415368}}
{"text":"We also provide (i) an extension of such a measure, based on distortion functions, and (ii) a weighted version based on a mixture distribution.","meta":{"url":"http://arxiv.org/abs/2307.14290v1"},"cats":{"new-dataset":0.2149003218,"dev-research":0.1115941935,"prompt-eng":0.4132000855,"data-quality":0.2134776577,"ml-security":0.0636844338}}
{"text":"Furthermore, we explore some connections with the reliability of $k$-out-of-$n$ systems and with stress-strength models for multi-component systems.","meta":{"url":"http://arxiv.org/abs/2307.14290v1"},"cats":{"new-dataset":0.0701626251,"dev-research":0.2184236506,"prompt-eng":0.3735119392,"data-quality":0.1879494803,"ml-security":0.1301448234}}
{"text":"Also, we address the problem of extending the cumulative information generating function to higher dimensions.","meta":{"url":"http://arxiv.org/abs/2307.14290v1"},"cats":{"new-dataset":0.1049887328,"dev-research":0.1949679218,"prompt-eng":0.3874079849,"data-quality":0.172988984,"ml-security":0.1462036996}}
{"text":"The study and development of innovative solutions for the advanced visualisation, representation and analysis of medical images offer different research directions.","meta":{"url":"http://arxiv.org/abs/2307.14288v1"},"cats":{"new-dataset":0.1018480575,"dev-research":0.2694635221,"prompt-eng":0.3619345943,"data-quality":0.0572875149,"ml-security":0.0513010843}}
{"text":"Current practice in medical imaging consists in combining real-time US with imaging modalities that allow internal anatomy acquisitions, such as CT, MRI, PET or similar.","meta":{"url":"http://arxiv.org/abs/2307.14288v1"},"cats":{"new-dataset":0.0324674,"dev-research":0.2731333618,"prompt-eng":0.3654041182,"data-quality":0.0682186514,"ml-security":0.0496776712}}
{"text":"Application of image-fusion approaches can be found in tracking surgical tools and/or needles, in real-time during interventions.","meta":{"url":"http://arxiv.org/abs/2307.14288v1"},"cats":{"new-dataset":0.0310594646,"dev-research":0.2303905944,"prompt-eng":0.3882344729,"data-quality":0.0855624309,"ml-security":0.0408910475}}
{"text":"Thus, this work proposes a fusion imaging system for the registration of CT and MRI images with real-time US acquisition leveraging a 3D camera sensor.","meta":{"url":"http://arxiv.org/abs/2307.14288v1"},"cats":{"new-dataset":0.1003249447,"dev-research":0.2227454442,"prompt-eng":0.4320082677,"data-quality":0.0890462407,"ml-security":0.047079833}}
{"text":"The main focus of the work is the portability of the system and its applicability to different anatomical districts.","meta":{"url":"http://arxiv.org/abs/2307.14288v1"},"cats":{"new-dataset":0.0528846116,"dev-research":0.2492026894,"prompt-eng":0.3563803667,"data-quality":0.0640366097,"ml-security":0.0486758283}}
{"text":"Stream processing has become a critical component in the architecture of modern applications.","meta":{"url":"http://arxiv.org/abs/2307.14287v1"},"cats":{"new-dataset":0.0455455645,"dev-research":0.3038070006,"prompt-eng":0.3588378369,"data-quality":0.1680611251,"ml-security":0.0650865149}}
{"text":"With the exponential growth of data generation from sources such as the Internet of Things, business intelligence, and telecommunications, real-time processing of unbounded data streams has become a necessity.","meta":{"url":"http://arxiv.org/abs/2307.14287v1"},"cats":{"new-dataset":0.1279301651,"dev-research":0.2315245857,"prompt-eng":0.3156289759,"data-quality":0.0858141653,"ml-security":0.1087249616}}
{"text":"DSP systems provide a solution to this challenge, offering high horizontal scalability, fault-tolerant execution, and the ability to process data streams from multiple sources in a single DSP job.","meta":{"url":"http://arxiv.org/abs/2307.14287v1"},"cats":{"new-dataset":0.1460369355,"dev-research":0.3546568402,"prompt-eng":0.4124083965,"data-quality":0.2192589019,"ml-security":0.1423250762}}
{"text":"Often enough though, data streams need to be enriched with extra information for correct processing, which introduces additional dependencies and potential bottlenecks.   ","meta":{"url":"http://arxiv.org/abs/2307.14287v1"},"cats":{"new-dataset":0.0246624539,"dev-research":0.3769198686,"prompt-eng":0.3508069658,"data-quality":0.2352591272,"ml-security":0.1375248533}}
{"text":"In this paper, we present an in-depth evaluation of data enrichment methods for DSP systems and identify the different use cases for stream processing in modern systems.","meta":{"url":"http://arxiv.org/abs/2307.14287v1"},"cats":{"new-dataset":0.1223044761,"dev-research":0.3297550775,"prompt-eng":0.4235783367,"data-quality":0.2158486423,"ml-security":0.0800041136}}
{"text":"Using a representative DSP system and conducting the evaluation in a realistic cloud environment, we found that outsourcing enrichment data to the DSP system can improve performance for specific use cases.","meta":{"url":"http://arxiv.org/abs/2307.14287v1"},"cats":{"new-dataset":0.2723353781,"dev-research":0.2995970762,"prompt-eng":0.4184579954,"data-quality":0.1952042388,"ml-security":0.1448397124}}
{"text":"However, this increased resource consumption highlights the need for stream processing solutions specifically designed for the performance-intensive workloads of cloud-based applications.","meta":{"url":"http://arxiv.org/abs/2307.14287v1"},"cats":{"new-dataset":0.0881928187,"dev-research":0.3155705354,"prompt-eng":0.3488355549,"data-quality":0.0924970336,"ml-security":0.0703821047}}
{"text":"Most applications of Artificial Intelligence (AI) are designed for a confined and specific task.","meta":{"url":"http://arxiv.org/abs/2307.14283v1"},"cats":{"new-dataset":0.0210931259,"dev-research":0.2934575223,"prompt-eng":0.3623629102,"data-quality":0.0826075914,"ml-security":0.2288060215}}
{"text":"However, there are many scenarios that call for a more general AI, capable of solving a wide array of tasks without being specifically designed for them.","meta":{"url":"http://arxiv.org/abs/2307.14283v1"},"cats":{"new-dataset":0.0171116094,"dev-research":0.2881286836,"prompt-eng":0.3302444779,"data-quality":0.0631541926,"ml-security":0.1778694233}}
{"text":"The term General-Purpose Artificial Intelligence Systems (GPAIS) has been defined to refer to these AI systems.","meta":{"url":"http://arxiv.org/abs/2307.14283v1"},"cats":{"new-dataset":0.0523326657,"dev-research":0.286820291,"prompt-eng":0.3444714587,"data-quality":0.0990829235,"ml-security":0.1392140208}}
{"text":"To date, the possibility of an Artificial General Intelligence, powerful enough to perform any intellectual task as if it were human, or even improve it, has remained an aspiration, fiction, and considered a risk for our society.","meta":{"url":"http://arxiv.org/abs/2307.14283v1"},"cats":{"new-dataset":0.0272654532,"dev-research":0.2553611852,"prompt-eng":0.3260244512,"data-quality":0.0982643128,"ml-security":0.2639336184}}
{"text":"Whilst we might still be far from achieving that, GPAIS is a reality and sitting at the forefront of AI research.   ","meta":{"url":"http://arxiv.org/abs/2307.14283v1"},"cats":{"new-dataset":0.0289711334,"dev-research":0.2309363209,"prompt-eng":0.3087924352,"data-quality":0.1101214129,"ml-security":0.1660870687}}
{"text":"This work discusses existing definitions for GPAIS and proposes a new definition that allows for a gradual differentiation among types of GPAIS according to their properties and limitations.","meta":{"url":"http://arxiv.org/abs/2307.14283v1"},"cats":{"new-dataset":0.0865185542,"dev-research":0.2033808294,"prompt-eng":0.4082255802,"data-quality":0.1409992299,"ml-security":0.093534035}}
{"text":"We distinguish between closed-world and open-world GPAIS, characterising their degree of autonomy and ability based on several factors such as adaptation to new tasks, competence in domains not intentionally trained for, ability to learn from few data, or proactive acknowledgment of their own limitations.","meta":{"url":"http://arxiv.org/abs/2307.14283v1"},"cats":{"new-dataset":0.1008499101,"dev-research":0.2684182798,"prompt-eng":0.3980599088,"data-quality":0.1493558373,"ml-security":0.1473076422}}
{"text":"We then propose a taxonomy of approaches to realise GPAIS, describing research trends such as the use of AI techniques to improve another AI or foundation models.","meta":{"url":"http://arxiv.org/abs/2307.14283v1"},"cats":{"new-dataset":0.0779123358,"dev-research":0.3015203284,"prompt-eng":0.3595523507,"data-quality":0.1261165618,"ml-security":0.109510848}}
{"text":"As a prime example, we delve into generative AI, aligning them with the terms and concepts presented in the taxonomy.","meta":{"url":"http://arxiv.org/abs/2307.14283v1"},"cats":{"new-dataset":0.05948348,"dev-research":0.3080374445,"prompt-eng":0.3755083385,"data-quality":0.2066368872,"ml-security":0.1377906727}}
{"text":"Through the proposed definition and taxonomy, our aim is to facilitate research collaboration across different areas that are tackling general-purpose tasks, as they share many common aspects.","meta":{"url":"http://arxiv.org/abs/2307.14283v1"},"cats":{"new-dataset":0.2119201296,"dev-research":0.3908069468,"prompt-eng":0.4648487724,"data-quality":0.1363145967,"ml-security":0.0614778676}}
{"text":"Finally, we discuss the current state of GPAIS, its challenges and prospects, implications for our society, and the need for responsible and trustworthy AI systems and regulation, with the goal of providing a holistic view of GPAIS.","meta":{"url":"http://arxiv.org/abs/2307.14283v1"},"cats":{"new-dataset":0.1259151395,"dev-research":0.2231644229,"prompt-eng":0.3803879579,"data-quality":0.1662247129,"ml-security":0.264460779}}
{"text":"Sequences with low aperiodic autocorrelation are used in communications and remote sensing for synchronization and ranging.","meta":{"url":"http://arxiv.org/abs/2307.14281v1"},"cats":{"new-dataset":0.2054784791,"dev-research":0.1853644216,"prompt-eng":0.397121465,"data-quality":0.1253453582,"ml-security":0.0490524189}}
{"text":"The autocorrelation demerit factor of a sequence is the sum of the squared magnitudes of its autocorrelation values at every nonzero shift when we normalize the sequence to have unit Euclidean length.","meta":{"url":"http://arxiv.org/abs/2307.14281v1"},"cats":{"new-dataset":0.1135028262,"dev-research":0.2153442939,"prompt-eng":0.294537685,"data-quality":0.1486903434,"ml-security":0.0905854973}}
{"text":"The merit factor, introduced by Golay, is the reciprocal of the demerit factor.","meta":{"url":"http://arxiv.org/abs/2307.14281v1"},"cats":{"new-dataset":0.0132777006,"dev-research":0.184566908,"prompt-eng":0.3707158112,"data-quality":0.0988303404,"ml-security":0.0798727263}}
{"text":"We consider the uniform probability measure on the $2^\\ell$ binary sequences of length $\\ell$ and investigate the distribution of the demerit factors of these sequences.","meta":{"url":"http://arxiv.org/abs/2307.14281v1"},"cats":{"new-dataset":0.4381020479,"dev-research":0.1415001108,"prompt-eng":0.3704092556,"data-quality":0.1745760969,"ml-security":0.1354153896}}
{"text":"Previous researchers have calculated the mean and variance of this distribution.","meta":{"url":"http://arxiv.org/abs/2307.14281v1"},"cats":{"new-dataset":0.1193427025,"dev-research":0.1558288712,"prompt-eng":0.3831942581,"data-quality":0.0981338051,"ml-security":0.0339769092}}
{"text":"We develop new combinatorial techniques to calculate the $p$th central moment of the demerit factor for binary sequences of length $\\ell$. These techniques prove that for $p\\geq 2$ and $\\ell \\geq 4$, all the central moments are strictly positive.","meta":{"url":"http://arxiv.org/abs/2307.14281v1"},"cats":{"new-dataset":0.1999411944,"dev-research":0.1602350224,"prompt-eng":0.3507383302,"data-quality":0.122995539,"ml-security":0.0883178057}}
{"text":"For any given $p$, one may use the technique to obtain an exact formula for the $p$th central moment of the demerit factor as a function of the length $\\ell$. The previously obtained formula for variance is confirmed by our technique with a short calculation, and we demonstrate that our techniques go beyond this by also deriving an exact formula for the skewness.","meta":{"url":"http://arxiv.org/abs/2307.14281v1"},"cats":{"new-dataset":0.0807506375,"dev-research":0.1482773551,"prompt-eng":0.3779686358,"data-quality":0.1214353326,"ml-security":0.0640481791}}
{"text":"With the advent of standards for deterministic network behavior, synthesizing network designs under delay constraints becomes the natural next task to tackle.","meta":{"url":"http://arxiv.org/abs/2307.14280v1"},"cats":{"new-dataset":0.0783517826,"dev-research":0.3533162763,"prompt-eng":0.4407753192,"data-quality":0.130598743,"ml-security":0.2417142921}}
{"text":"Network Calculus (NC) has become a key method for validating industrial networks, as it computes formally verified end-to-end delay bounds.","meta":{"url":"http://arxiv.org/abs/2307.14280v1"},"cats":{"new-dataset":0.0545224913,"dev-research":0.3557534194,"prompt-eng":0.3656774589,"data-quality":0.1895757069,"ml-security":0.161640671}}
{"text":"However, analyses from the NC framework have been designed to bound the delay of one flow at a time.","meta":{"url":"http://arxiv.org/abs/2307.14280v1"},"cats":{"new-dataset":0.0504067759,"dev-research":0.2529989363,"prompt-eng":0.3448377918,"data-quality":0.0781253603,"ml-security":0.079187163}}
{"text":"Attempts to use classical analyses to derive a network configuration have shown that this approach is poorly suited to practical use cases.","meta":{"url":"http://arxiv.org/abs/2307.14280v1"},"cats":{"new-dataset":0.0228906637,"dev-research":0.3169639024,"prompt-eng":0.3633606008,"data-quality":0.1939763279,"ml-security":0.1444205804}}
{"text":"Consider finding a delay-optimal routing configuration: one model had to be created for each routing alternative, then each flow delay had to be bounded, and then the bounds had to be compared to the given constraints.","meta":{"url":"http://arxiv.org/abs/2307.14280v1"},"cats":{"new-dataset":0.046182953,"dev-research":0.1815095539,"prompt-eng":0.3422938406,"data-quality":0.0808673423,"ml-security":0.0937990674}}
{"text":"To overcome this three-step process, we introduce Differential Network Calculus.","meta":{"url":"http://arxiv.org/abs/2307.14280v1"},"cats":{"new-dataset":0.0664855379,"dev-research":0.2763387128,"prompt-eng":0.3433984195,"data-quality":0.1453290566,"ml-security":0.1855420286}}
{"text":"We extend NC to allow the differentiation of delay bounds w.r.t.","meta":{"url":"http://arxiv.org/abs/2307.14280v1"},"cats":{"new-dataset":0.1228301351,"dev-research":0.2269005919,"prompt-eng":0.3773950357,"data-quality":0.1449617353,"ml-security":0.1383116373}}
{"text":"to a wide range of network parameters - such as flow paths or priority.","meta":{"url":"http://arxiv.org/abs/2307.14280v1"},"cats":{"new-dataset":0.0486254267,"dev-research":0.3121359632,"prompt-eng":0.4221722281,"data-quality":0.0723398413,"ml-security":0.1123149906}}
{"text":"This opens up NC to a class of efficient nonlinear optimization techniques that exploit the gradient of the delay bound.","meta":{"url":"http://arxiv.org/abs/2307.14280v1"},"cats":{"new-dataset":0.0630087133,"dev-research":0.205195745,"prompt-eng":0.3494002327,"data-quality":0.1341937231,"ml-security":0.0910934739}}
{"text":"Our numerical evaluation on the routing and priority assignment problem shows that our novel method can synthesize flow paths and priorities in a matter of seconds, outperforming existing methods by several orders of magnitude.","meta":{"url":"http://arxiv.org/abs/2307.14280v1"},"cats":{"new-dataset":0.083615541,"dev-research":0.2855128689,"prompt-eng":0.4370557697,"data-quality":0.0988894461,"ml-security":0.0768376136}}
{"text":"Fully-unsupervised Person and Vehicle Re-Identification have received increasing attention due to their broad applicability in surveillance, forensics, event understanding, and smart cities, without requiring any manual annotation.","meta":{"url":"http://arxiv.org/abs/2307.14278v1"},"cats":{"new-dataset":0.2751520382,"dev-research":0.1804312741,"prompt-eng":0.3855086117,"data-quality":0.1933933022,"ml-security":0.2137590639}}
{"text":"However, most of the prior art has been evaluated in datasets that have just a couple thousand samples.","meta":{"url":"http://arxiv.org/abs/2307.14278v1"},"cats":{"new-dataset":0.2308786003,"dev-research":0.1990620918,"prompt-eng":0.3076589652,"data-quality":0.1801063454,"ml-security":0.0796290792}}
{"text":"Such small-data setups often allow the use of costly techniques in time and memory footprints, such as Re-Ranking, to improve clustering results.","meta":{"url":"http://arxiv.org/abs/2307.14278v1"},"cats":{"new-dataset":0.0506223173,"dev-research":0.3121226211,"prompt-eng":0.3753318446,"data-quality":0.1796179797,"ml-security":0.0682802893}}
{"text":"Moreover, some previous work even pre-selects the best clustering hyper-parameters for each dataset, which is unrealistic in a large-scale fully-unsupervised scenario.","meta":{"url":"http://arxiv.org/abs/2307.14278v1"},"cats":{"new-dataset":0.2677474545,"dev-research":0.1769161287,"prompt-eng":0.3629563965,"data-quality":0.1988724013,"ml-security":0.1354213772}}
{"text":"In this context, this work tackles a more realistic scenario and proposes two strategies to learn from large-scale unlabeled data.","meta":{"url":"http://arxiv.org/abs/2307.14278v1"},"cats":{"new-dataset":0.3605827177,"dev-research":0.2159015516,"prompt-eng":0.399608382,"data-quality":0.3889891123,"ml-security":0.1613296734}}
{"text":"The first strategy performs a local neighborhood sampling to reduce the dataset size in each iteration without violating neighborhood relationships.","meta":{"url":"http://arxiv.org/abs/2307.14278v1"},"cats":{"new-dataset":0.211810752,"dev-research":0.2509722494,"prompt-eng":0.3269553866,"data-quality":0.1550507479,"ml-security":0.1300735099}}
{"text":"A second strategy leverages a novel Re-Ranking technique, which has a lower time upper bound complexity and reduces the memory complexity from O(n^2) to O(kn) with k << n. To avoid the pre-selection of specific hyper-parameter values for the clustering algorithm, we also present a novel scheduling algorithm that adjusts the density parameter during training, to leverage the diversity of samples and keep the learning robust to noisy labeling.","meta":{"url":"http://arxiv.org/abs/2307.14278v1"},"cats":{"new-dataset":0.1196924963,"dev-research":0.2374227753,"prompt-eng":0.4022854048,"data-quality":0.360641006,"ml-security":0.0747916639}}
{"text":"Finally, due to the complementary knowledge learned by different models, we also introduce a co-training strategy that relies upon the permutation of predicted pseudo-labels, among the backbones, with no need for any hyper-parameters or weighting optimization.","meta":{"url":"http://arxiv.org/abs/2307.14278v1"},"cats":{"new-dataset":0.1246837518,"dev-research":0.1808528253,"prompt-eng":0.3990125935,"data-quality":0.3149945546,"ml-security":0.1897515192}}
{"text":"The proposed methodology outperforms the state-of-the-art methods in well-known benchmarks and in the challenging large-scale Veri-Wild dataset, with a faster and memory-efficient Re-Ranking strategy, and a large-scale, noisy-robust, and ensemble-based learning approach.","meta":{"url":"http://arxiv.org/abs/2307.14278v1"},"cats":{"new-dataset":0.5790671364,"dev-research":0.1880927768,"prompt-eng":0.3564584811,"data-quality":0.2572466152,"ml-security":0.0778050814}}
{"text":"The recent video grounding works attempt to introduce vanilla contrastive learning into video grounding.","meta":{"url":"http://arxiv.org/abs/2307.14277v1"},"cats":{"new-dataset":0.1940577814,"dev-research":0.2520303448,"prompt-eng":0.3701194182,"data-quality":0.2018856394,"ml-security":0.113584164}}
{"text":"However, we claim that this naive solution is suboptimal.","meta":{"url":"http://arxiv.org/abs/2307.14277v1"},"cats":{"new-dataset":0.0241853212,"dev-research":0.225406773,"prompt-eng":0.2881732691,"data-quality":0.2463334147,"ml-security":0.2146063491}}
{"text":"Contrastive learning requires two key properties: (1) \\emph{alignment} of features of similar samples, and (2) \\emph{uniformity} of the induced distribution of the normalized features on the hypersphere.","meta":{"url":"http://arxiv.org/abs/2307.14277v1"},"cats":{"new-dataset":0.0502998849,"dev-research":0.1585368529,"prompt-eng":0.3047000049,"data-quality":0.2337798709,"ml-security":0.109398413}}
{"text":"Due to two annoying issues in video grounding: (1) the co-existence of some visual entities in both ground truth and other moments, \\ie semantic overlapping; (2) only a few moments in the video are annotated, \\ie sparse annotation dilemma, vanilla contrastive learning is unable to model the correlations between temporally distant moments and learned inconsistent video representations.","meta":{"url":"http://arxiv.org/abs/2307.14277v1"},"cats":{"new-dataset":0.1907068105,"dev-research":0.228663278,"prompt-eng":0.3292013592,"data-quality":0.3338857974,"ml-security":0.0956809353}}
{"text":"Both characteristics lead to vanilla contrastive learning being unsuitable for video grounding.","meta":{"url":"http://arxiv.org/abs/2307.14277v1"},"cats":{"new-dataset":0.0200133537,"dev-research":0.3082398299,"prompt-eng":0.321919289,"data-quality":0.2138719332,"ml-security":0.1618827509}}
{"text":"In this paper, we introduce Geodesic and Game Localization (G2L), a semantically aligned and uniform video grounding framework via geodesic and game theory.","meta":{"url":"http://arxiv.org/abs/2307.14277v1"},"cats":{"new-dataset":0.2607983098,"dev-research":0.289233336,"prompt-eng":0.3942261859,"data-quality":0.1781958958,"ml-security":0.086748942}}
{"text":"We quantify the correlations among moments leveraging the geodesic distance that guides the model to learn the correct cross-modal representations.","meta":{"url":"http://arxiv.org/abs/2307.14277v1"},"cats":{"new-dataset":0.0590189203,"dev-research":0.1553120905,"prompt-eng":0.3755224206,"data-quality":0.166233703,"ml-security":0.0552158236}}
{"text":"Furthermore, from the novel perspective of game theory, we propose semantic Shapley interaction based on geodesic distance sampling to learn fine-grained semantic alignment in similar moments.","meta":{"url":"http://arxiv.org/abs/2307.14277v1"},"cats":{"new-dataset":0.3150562364,"dev-research":0.2119440287,"prompt-eng":0.3792489005,"data-quality":0.169392453,"ml-security":0.0855864635}}
{"text":"Experiments on three benchmarks demonstrate the effectiveness of our method.","meta":{"url":"http://arxiv.org/abs/2307.14277v1"},"cats":{"new-dataset":0.0268487895,"dev-research":0.2280339594,"prompt-eng":0.4509907188,"data-quality":0.2064044762,"ml-security":0.0427509905}}
{"text":"Object pushing presents a key non-prehensile manipulation problem that is illustrative of more complex robotic manipulation tasks.","meta":{"url":"http://arxiv.org/abs/2307.14272v1"},"cats":{"new-dataset":0.0418465401,"dev-research":0.2450808953,"prompt-eng":0.4139389563,"data-quality":0.0871419603,"ml-security":0.0877893822}}
{"text":"While deep reinforcement learning (RL) methods have demonstrated impressive learning capabilities using visual input, a lack of tactile sensing limits their capability for fine and reliable control during manipulation.","meta":{"url":"http://arxiv.org/abs/2307.14272v1"},"cats":{"new-dataset":0.1238255327,"dev-research":0.2307128058,"prompt-eng":0.3831622784,"data-quality":0.0978551077,"ml-security":0.1452929971}}
{"text":"Here we propose a deep RL approach to object pushing using tactile sensing without visual input, namely tactile pushing.","meta":{"url":"http://arxiv.org/abs/2307.14272v1"},"cats":{"new-dataset":0.168178333,"dev-research":0.23698482,"prompt-eng":0.4182943906,"data-quality":0.0993302995,"ml-security":0.1058787643}}
{"text":"We present a goal-conditioned formulation that allows both model-free and model-based RL to obtain accurate policies for pushing an object to a goal.","meta":{"url":"http://arxiv.org/abs/2307.14272v1"},"cats":{"new-dataset":0.082838363,"dev-research":0.2914060224,"prompt-eng":0.4941261224,"data-quality":0.0988263424,"ml-security":0.1109196178}}
{"text":"To achieve real-world performance, we adopt a sim-to-real approach.","meta":{"url":"http://arxiv.org/abs/2307.14272v1"},"cats":{"new-dataset":0.054761059,"dev-research":0.3678805974,"prompt-eng":0.377920837,"data-quality":0.1099256639,"ml-security":0.0720580373}}
{"text":"Our results demonstrate that it is possible to train on a single object and a limited sample of goals to produce precise and reliable policies that can generalize to a variety of unseen objects and pushing scenarios without domain randomization.","meta":{"url":"http://arxiv.org/abs/2307.14272v1"},"cats":{"new-dataset":0.187014284,"dev-research":0.2654396781,"prompt-eng":0.4394191081,"data-quality":0.2060154524,"ml-security":0.4014710598}}
{"text":"We experiment with the trained agents in harsh pushing conditions, and show that with significantly more training samples, a model-free policy can outperform a model-based planner, generating shorter and more reliable pushing trajectories despite large disturbances.","meta":{"url":"http://arxiv.org/abs/2307.14272v1"},"cats":{"new-dataset":0.1654796913,"dev-research":0.2822108589,"prompt-eng":0.3703342043,"data-quality":0.067472277,"ml-security":0.1879592645}}
{"text":"The simplicity of our training environment and effective real-world performance highlights the value of rich tactile information for fine manipulation.","meta":{"url":"http://arxiv.org/abs/2307.14272v1"},"cats":{"new-dataset":0.1201095961,"dev-research":0.3055272632,"prompt-eng":0.4523382613,"data-quality":0.1167428714,"ml-security":0.120567848}}
{"text":"Code and videos are available at https://sites.google.com/view/tactile-rl-pushing/.","meta":{"url":"http://arxiv.org/abs/2307.14272v1"},"cats":{"new-dataset":0.2351746628,"dev-research":0.2566385785,"prompt-eng":0.4742255173,"data-quality":0.0699998358,"ml-security":0.0474237024}}
{"text":"The Internet of Things (IoT) is growing rapidly and so the need of ensuring protection against cybersecurity attacks to IoT devices.","meta":{"url":"http://arxiv.org/abs/2307.14268v1"},"cats":{"new-dataset":0.0776369068,"dev-research":0.2779718517,"prompt-eng":0.3480031044,"data-quality":0.0606490591,"ml-security":0.4765822656}}
{"text":"In this scenario, Intrusion Detection Systems (IDSs) play a crucial role and data-driven IDSs based on machine learning (ML) have recently attracted more and more interest by the research community.","meta":{"url":"http://arxiv.org/abs/2307.14268v1"},"cats":{"new-dataset":0.1353723485,"dev-research":0.2970250348,"prompt-eng":0.3772226827,"data-quality":0.18914511,"ml-security":0.591113634}}
{"text":"While conventional ML-based IDSs are based on a centralized architecture where IoT devices share their data with a central server for model training, we propose a novel approach that is based on federated learning (FL).","meta":{"url":"http://arxiv.org/abs/2307.14268v1"},"cats":{"new-dataset":0.1857144546,"dev-research":0.2506711396,"prompt-eng":0.3838903569,"data-quality":0.1405639124,"ml-security":0.2206104274}}
{"text":"However, conventional FL is ineffective in the considered scenario, due to the high statistical heterogeneity of data collected by IoT devices.","meta":{"url":"http://arxiv.org/abs/2307.14268v1"},"cats":{"new-dataset":0.0437817038,"dev-research":0.1954179528,"prompt-eng":0.4036748671,"data-quality":0.1547513433,"ml-security":0.1041626112}}
{"text":"To overcome this limitation, we propose a three-tier FL-based architecture where IoT devices are clustered together based on their statistical properties.","meta":{"url":"http://arxiv.org/abs/2307.14268v1"},"cats":{"new-dataset":0.2107880137,"dev-research":0.2167418421,"prompt-eng":0.4254838297,"data-quality":0.0664616871,"ml-security":0.0690798943}}
{"text":"Clustering decisions are taken by means of a novel entropy-based strategy, which helps improve model training performance.","meta":{"url":"http://arxiv.org/abs/2307.14268v1"},"cats":{"new-dataset":0.0122640074,"dev-research":0.2631048697,"prompt-eng":0.4151840818,"data-quality":0.2033988307,"ml-security":0.1324107208}}
{"text":"We tested our solution on the CIC-ToN-IoT dataset: our clustering strategy increases intrusion detection performance with respect to a conventional FL approach up to +17% in terms of F1-score, along with a significant reduction of the number of training rounds.","meta":{"url":"http://arxiv.org/abs/2307.14268v1"},"cats":{"new-dataset":0.3879195856,"dev-research":0.2229836882,"prompt-eng":0.3631261466,"data-quality":0.175997974,"ml-security":0.4143598287}}
{"text":"The Paris Agreement, considered a significant milestone in climate negotiations, has faced challenges in effectively addressing climate change due to the unconditional nature of most Nationally Determined Contributions (NDCs).","meta":{"url":"http://arxiv.org/abs/2307.14267v1"},"cats":{"new-dataset":0.0969766691,"dev-research":0.2684306157,"prompt-eng":0.3222872424,"data-quality":0.1822811476,"ml-security":0.1074516547}}
{"text":"This has resulted in a prevalence of free-riding behavior among major polluters and a lack of concrete conditionality in NDCs.","meta":{"url":"http://arxiv.org/abs/2307.14267v1"},"cats":{"new-dataset":0.0403257129,"dev-research":0.2969767118,"prompt-eng":0.3883012835,"data-quality":0.1597812276,"ml-security":0.3573243025}}
{"text":"To address this issue, we propose the implementation of a decentralized, bottom-up approach called the Conditional Commitment Mechanism.","meta":{"url":"http://arxiv.org/abs/2307.14267v1"},"cats":{"new-dataset":0.0448390793,"dev-research":0.2275295173,"prompt-eng":0.4494697496,"data-quality":0.1050919354,"ml-security":0.1233450285}}
{"text":"This mechanism, inspired by the National Popular Vote Interstate Compact, offers flexibility and incentives for early adopters, aiming to formalize conditional cooperation in international climate policy.","meta":{"url":"http://arxiv.org/abs/2307.14267v1"},"cats":{"new-dataset":0.0568969145,"dev-research":0.2608542475,"prompt-eng":0.4194269111,"data-quality":0.1048854714,"ml-security":0.0740344097}}
{"text":"In this paper, we provide an overview of the mechanism, its performance in the AI4ClimateCooperation challenge, and discuss potential real-world implementation aspects.","meta":{"url":"http://arxiv.org/abs/2307.14267v1"},"cats":{"new-dataset":0.1097428853,"dev-research":0.309837373,"prompt-eng":0.4607372212,"data-quality":0.1632319904,"ml-security":0.0589940429}}
{"text":"Prior knowledge of the climate mitigation collective action problem, basic economic principles, and game theory concepts are assumed.","meta":{"url":"http://arxiv.org/abs/2307.14267v1"},"cats":{"new-dataset":0.1342235624,"dev-research":0.2473766163,"prompt-eng":0.3349384441,"data-quality":0.1133861552,"ml-security":0.182013582}}
{"text":"This paper proposes enhancements to the RICE-N simulation and multi-agent reinforcement learning framework to improve the realism of international climate policy negotiations.","meta":{"url":"http://arxiv.org/abs/2307.14266v1"},"cats":{"new-dataset":0.2380541412,"dev-research":0.1975039422,"prompt-eng":0.3440026755,"data-quality":0.0890310105,"ml-security":0.1060799667}}
{"text":"Acknowledging the framework's value, we highlight the necessity of significant enhancements to address the diverse array of factors in modeling climate negotiations.","meta":{"url":"http://arxiv.org/abs/2307.14266v1"},"cats":{"new-dataset":0.169687565,"dev-research":0.2747076028,"prompt-eng":0.3670457645,"data-quality":0.0988924966,"ml-security":0.0852317996}}
{"text":"Building upon our previous work on the \"Conditional Commitments Mechanism\" (CCF mechanism) we discuss ways to bridge the gap between simulation and reality.","meta":{"url":"http://arxiv.org/abs/2307.14266v1"},"cats":{"new-dataset":0.0808640306,"dev-research":0.2747524241,"prompt-eng":0.465004779,"data-quality":0.1171463567,"ml-security":0.1215231438}}
{"text":"We suggest the inclusion of a recommender or planner agent to enhance coordination, address the Real2Sim gap by incorporating social factors and non-party stakeholder sub-agents, and propose enhancements to the underlying Reinforcement Learning solution algorithm.","meta":{"url":"http://arxiv.org/abs/2307.14266v1"},"cats":{"new-dataset":0.1341734191,"dev-research":0.3092885833,"prompt-eng":0.3962044167,"data-quality":0.0865964411,"ml-security":0.0759131805}}
{"text":"These proposed improvements aim to advance the evaluation and formulation of negotiation protocols for more effective international climate policy decision-making in Rice-N.","meta":{"url":"http://arxiv.org/abs/2307.14266v1"},"cats":{"new-dataset":0.2199596618,"dev-research":0.2418547558,"prompt-eng":0.3728282563,"data-quality":0.1091489472,"ml-security":0.0592645249}}
{"text":"However, further experimentation and testing are required to determine the implications and effectiveness of these suggestions.","meta":{"url":"http://arxiv.org/abs/2307.14266v1"},"cats":{"new-dataset":0.004664891,"dev-research":0.3142241604,"prompt-eng":0.4781115273,"data-quality":0.1837681608,"ml-security":0.0944575979}}
{"text":"Recently, Hegerfeld and Kratsch [ESA 2023] obtained the first tight algorithmic results for hard connectivity problems parameterized by clique-width.","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.1655980719,"dev-research":0.2046910517,"prompt-eng":0.3572423322,"data-quality":0.2045718206,"ml-security":0.1023839418}}
{"text":"Concretely, they gave one-sided error Monte-Carlo algorithms that given a $k$-clique-expression solve Connected Vertex Cover in time $6^kn^{O(1)}$ and Connected Dominating Set in time $5^kn^{O(1)}$. Moreover, under the Strong Exponential-Time Hypothesis (SETH) these results were showed to be tight.","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.1771555279,"dev-research":0.2122843741,"prompt-eng":0.3152636322,"data-quality":0.1280496769,"ml-security":0.1198112154}}
{"text":"However, they leave open several important benchmark problems, whose complexity relative to treewidth had been settled by Cygan et al.","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.2113109627,"dev-research":0.2547711651,"prompt-eng":0.2835775255,"data-quality":0.1850539167,"ml-security":0.0732589641}}
{"text":"[SODA 2011 & TALG 2018].","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.314412542,"dev-research":0.2265990406,"prompt-eng":0.3507533509,"data-quality":0.1821924669,"ml-security":0.0985236234}}
{"text":"Among which is the Steiner Tree problem.","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.1011414488,"dev-research":0.1919059348,"prompt-eng":0.3315868677,"data-quality":0.1732480481,"ml-security":0.0630311492}}
{"text":"As a key obstruction they point out the exponential gap between the rank of certain compatibility matrices, which is often used for algorithms, and the largest triangular submatrix therein, which is essential for current lower bound methods.","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.0275967413,"dev-research":0.2647282019,"prompt-eng":0.2964727095,"data-quality":0.1057499407,"ml-security":0.1246977543}}
{"text":"Concretely, for Steiner Tree the $GF(2)$-rank is $4^k$, while no triangular submatrix larger than $3^k$ was known.","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.1562085198,"dev-research":0.1371998511,"prompt-eng":0.2862003569,"data-quality":0.1056319561,"ml-security":0.0431575569}}
{"text":"This yields time $4^kn^{O(1)}$, while the obtainable impossibility of time $(3-\\varepsilon)^kn^{O(1)}$ under SETH was already known relative to pathwidth.   ","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.0894942211,"dev-research":0.1806397861,"prompt-eng":0.2634788099,"data-quality":0.1281680051,"ml-security":0.1185430755}}
{"text":"We close this gap by showing that Steiner Tree can be solved in time $3^kn^{O(1)}$ given a $k$-clique-expression.","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.3374686664,"dev-research":0.1742883524,"prompt-eng":0.3277168632,"data-quality":0.146587203,"ml-security":0.0678377309}}
{"text":"Hence, for all parameters between cutwidth and clique-width it has the same tight complexity.","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.0141552091,"dev-research":0.2626410803,"prompt-eng":0.2854321708,"data-quality":0.0962905887,"ml-security":0.0535769018}}
{"text":"We first show that there is a ``representative submatrix'' of GF(2)-rank $3^k$ (ruling out larger triangular submatrices).","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.5739411065,"dev-research":0.1245024264,"prompt-eng":0.3215289266,"data-quality":0.1354752861,"ml-security":0.099395593}}
{"text":"At first glance, this only allows to count (modulo 2) the number of representations of valid solutions, but not the number of solutions (even if a unique solution exists).","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.0211202912,"dev-research":0.2647644096,"prompt-eng":0.3177930683,"data-quality":0.1481953172,"ml-security":0.1196616635}}
{"text":"We show how to overcome this problem by isolating a unique representative of a unique solution, if one exists.","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.047519965,"dev-research":0.2511619068,"prompt-eng":0.3923348134,"data-quality":0.234742978,"ml-security":0.1972411059}}
{"text":"We believe that our approach will be instrumental for settling further open problems in this research program.","meta":{"url":"http://arxiv.org/abs/2307.14264v1"},"cats":{"new-dataset":0.1310403071,"dev-research":0.3236107436,"prompt-eng":0.3425772848,"data-quality":0.1758308616,"ml-security":0.1308975262}}
{"text":"Vision transformers (ViT) have been of broad interest in recent theoretical and empirical works.","meta":{"url":"http://arxiv.org/abs/2307.14253v1"},"cats":{"new-dataset":0.0908922421,"dev-research":0.1876164636,"prompt-eng":0.3784515896,"data-quality":0.0773165763,"ml-security":0.0500601546}}
{"text":"They are state-of-the-art thanks to their attention-based approach, which boosts the identification of key features and patterns within images thanks to the capability of avoiding inductive bias, resulting in highly accurate image analysis.","meta":{"url":"http://arxiv.org/abs/2307.14253v1"},"cats":{"new-dataset":0.1995670919,"dev-research":0.2078902531,"prompt-eng":0.3881835887,"data-quality":0.2164005154,"ml-security":0.0726679025}}
{"text":"Meanwhile, neoteric studies have reported a ``sparse double descent'' phenomenon that can occur in modern deep-learning models, where extremely over-parametrized models can generalize well.","meta":{"url":"http://arxiv.org/abs/2307.14253v1"},"cats":{"new-dataset":0.0531626796,"dev-research":0.1650373003,"prompt-eng":0.3209428154,"data-quality":0.2190855897,"ml-security":0.3792797139}}
{"text":"This raises practical questions about the optimal size of the model and the quest over finding the best trade-off between sparsity and performance is launched: are Vision Transformers also prone to sparse double descent?","meta":{"url":"http://arxiv.org/abs/2307.14253v1"},"cats":{"new-dataset":0.0113817851,"dev-research":0.1701227828,"prompt-eng":0.3540688992,"data-quality":0.1162171838,"ml-security":0.1186125625}}
{"text":"Can we find a way to avoid such a phenomenon?","meta":{"url":"http://arxiv.org/abs/2307.14253v1"},"cats":{"new-dataset":0.0106548762,"dev-research":0.260768337,"prompt-eng":0.410419383,"data-quality":0.3290684663,"ml-security":0.3474995153}}
{"text":"Our work tackles the occurrence of sparse double descent on ViTs.","meta":{"url":"http://arxiv.org/abs/2307.14253v1"},"cats":{"new-dataset":0.1626579456,"dev-research":0.2010193868,"prompt-eng":0.3857568195,"data-quality":0.1992608102,"ml-security":0.148355002}}
{"text":"Despite some works that have shown that traditional architectures, like Resnet, are condemned to the sparse double descent phenomenon, for ViTs we observe that an optimally-tuned $\\ell_2$ regularization relieves such a phenomenon.","meta":{"url":"http://arxiv.org/abs/2307.14253v1"},"cats":{"new-dataset":0.0454953748,"dev-research":0.199665685,"prompt-eng":0.3473729796,"data-quality":0.1894583934,"ml-security":0.2585151897}}
{"text":"However, everything comes at a cost: optimal lambda will sacrifice the potential compression of the ViT.","meta":{"url":"http://arxiv.org/abs/2307.14253v1"},"cats":{"new-dataset":0.0122257107,"dev-research":0.2107893139,"prompt-eng":0.3530667743,"data-quality":0.109061684,"ml-security":0.1210305594}}
{"text":"Navigation of a mobile robot is conditioned on the knowledge of its pose.","meta":{"url":"http://arxiv.org/abs/2307.14247v1"},"cats":{"new-dataset":0.1003341061,"dev-research":0.2080636939,"prompt-eng":0.4226621939,"data-quality":0.106736099,"ml-security":0.098103545}}
{"text":"In observer-based localisation configurations its initial pose may not be knowable in advance, leading to the need of its estimation.","meta":{"url":"http://arxiv.org/abs/2307.14247v1"},"cats":{"new-dataset":0.0768731864,"dev-research":0.2178818642,"prompt-eng":0.38105285,"data-quality":0.2067207197,"ml-security":0.122420627}}
{"text":"Solutions to the problem of global localisation are either robust against noise and environment arbitrariness but require motion and time, which may (need to) be economised on, or require minimal estimation time but assume environmental structure, may be sensitive to noise, and demand preprocessing and tuning.","meta":{"url":"http://arxiv.org/abs/2307.14247v1"},"cats":{"new-dataset":0.1190267917,"dev-research":0.2378083312,"prompt-eng":0.3787122557,"data-quality":0.1849843084,"ml-security":0.1227008696}}
{"text":"This article proposes a method that retains the strengths and avoids the weaknesses of the two approaches.","meta":{"url":"http://arxiv.org/abs/2307.14247v1"},"cats":{"new-dataset":0.0148378238,"dev-research":0.2388986255,"prompt-eng":0.4641966196,"data-quality":0.1958131405,"ml-security":0.0673441258}}
{"text":"The method leverages properties of the Cumulative Absolute Error per Ray metric with respect to the errors of pose estimates of a 2D LIDAR sensor, and utilises scan--to--map-scan matching for fine(r) pose approximations.","meta":{"url":"http://arxiv.org/abs/2307.14247v1"},"cats":{"new-dataset":0.1236972404,"dev-research":0.2095763031,"prompt-eng":0.3681437001,"data-quality":0.1716093381,"ml-security":0.0546241639}}
{"text":"A large number of tests, in real and simulated conditions, involving disparate environments and sensor properties, illustrate that the proposed method outperforms state-of-the-art methods of both classes of solutions in terms of pose discovery rate and execution time.","meta":{"url":"http://arxiv.org/abs/2307.14247v1"},"cats":{"new-dataset":0.2267758291,"dev-research":0.2008197396,"prompt-eng":0.4178514165,"data-quality":0.0991677785,"ml-security":0.0647914415}}
{"text":"The source code is available for download.","meta":{"url":"http://arxiv.org/abs/2307.14247v1"},"cats":{"new-dataset":0.4813017199,"dev-research":0.2948268006,"prompt-eng":0.3566638007,"data-quality":0.1482831325,"ml-security":0.0596618951}}
{"text":"Within the field of Requirements Engineering (RE), the increasing significance of Explainable Artificial Intelligence (XAI) in aligning AI-supported systems with user needs, societal expectations, and regulatory standards has garnered recognition.","meta":{"url":"http://arxiv.org/abs/2307.14239v1"},"cats":{"new-dataset":0.0678390297,"dev-research":0.4866425006,"prompt-eng":0.4441356662,"data-quality":0.1822038075,"ml-security":0.1986390482}}
{"text":"In general, explainability has emerged as an important non-functional requirement that impacts system quality.","meta":{"url":"http://arxiv.org/abs/2307.14239v1"},"cats":{"new-dataset":0.0086791683,"dev-research":0.4913785106,"prompt-eng":0.3700245782,"data-quality":0.2595983241,"ml-security":0.1887649755}}
{"text":"However, the supposed trade-off between explainability and performance challenges the presumed positive influence of explainability.","meta":{"url":"http://arxiv.org/abs/2307.14239v1"},"cats":{"new-dataset":0.0031235849,"dev-research":0.480577671,"prompt-eng":0.3725468884,"data-quality":0.3186040947,"ml-security":0.2121765178}}
{"text":"If meeting the requirement of explainability entails a reduction in system performance, then careful consideration must be given to which of these quality aspects takes precedence and how to compromise between them.","meta":{"url":"http://arxiv.org/abs/2307.14239v1"},"cats":{"new-dataset":0.0132405565,"dev-research":0.5370876828,"prompt-eng":0.4369586643,"data-quality":0.2484705511,"ml-security":0.2078079316}}
{"text":"In this paper, we critically examine the alleged trade-off.","meta":{"url":"http://arxiv.org/abs/2307.14239v1"},"cats":{"new-dataset":0.0193325674,"dev-research":0.2589078753,"prompt-eng":0.3113167788,"data-quality":0.1862798236,"ml-security":0.2185856063}}
{"text":"We argue that it is best approached in a nuanced way that incorporates resource availability, domain characteristics, and considerations of risk.","meta":{"url":"http://arxiv.org/abs/2307.14239v1"},"cats":{"new-dataset":0.0296981751,"dev-research":0.2561989488,"prompt-eng":0.3873327163,"data-quality":0.1786996891,"ml-security":0.2683758401}}
{"text":"By providing a foundation for future research and best practices, this work aims to advance the field of RE for AI.","meta":{"url":"http://arxiv.org/abs/2307.14239v1"},"cats":{"new-dataset":0.0759983427,"dev-research":0.2721123198,"prompt-eng":0.3957613498,"data-quality":0.1286215491,"ml-security":0.1065619318}}
{"text":"Creating an intelligent search and retrieval system for artwork images, particularly paintings, is crucial for documenting cultural heritage, fostering wider public engagement, and advancing artistic analysis and interpretation.","meta":{"url":"http://arxiv.org/abs/2307.14244v1"},"cats":{"new-dataset":0.1089712715,"dev-research":0.2487294345,"prompt-eng":0.395743848,"data-quality":0.1793037606,"ml-security":0.0394403321}}
{"text":"Visual-Semantic Embedding (VSE) networks are deep learning models used for information retrieval, which learn joint representations of textual and visual data, enabling 1) cross-modal search and retrieval tasks, such as image-to-text and text-to-image retrieval; and 2) relation-focused retrieval to capture entity relationships and provide more contextually relevant search results.","meta":{"url":"http://arxiv.org/abs/2307.14244v1"},"cats":{"new-dataset":0.0763416989,"dev-research":0.2970092541,"prompt-eng":0.3478288797,"data-quality":0.1927683645,"ml-security":0.0706213137}}
{"text":"Although VSE networks have played a significant role in cross-modal information retrieval, their application to painting datasets, such as ArtUK, remains unexplored.","meta":{"url":"http://arxiv.org/abs/2307.14244v1"},"cats":{"new-dataset":0.1961204988,"dev-research":0.3168258764,"prompt-eng":0.3579312093,"data-quality":0.1974592463,"ml-security":0.0908698609}}
{"text":"This paper introduces BoonArt, a VSE-based cross-modal search engine that allows users to search for images using textual queries, and to obtain textual descriptions along with the corresponding images when using image queries.","meta":{"url":"http://arxiv.org/abs/2307.14244v1"},"cats":{"new-dataset":0.0920236121,"dev-research":0.2619238194,"prompt-eng":0.4391976651,"data-quality":0.1560905162,"ml-security":0.0598514419}}
{"text":"The performance of BoonArt was evaluated using the ArtUK dataset.","meta":{"url":"http://arxiv.org/abs/2307.14244v1"},"cats":{"new-dataset":0.1461776923,"dev-research":0.3013929888,"prompt-eng":0.3985344977,"data-quality":0.1108145436,"ml-security":0.0467533504}}
{"text":"Experimental evaluations revealed that BoonArt achieved 97% Recall@10 for image-to-text retrieval, and 97.4% Recall@10 for text-to-image Retrieval.","meta":{"url":"http://arxiv.org/abs/2307.14244v1"},"cats":{"new-dataset":0.1347780761,"dev-research":0.2064247156,"prompt-eng":0.4255100414,"data-quality":0.2636614074,"ml-security":0.0690592027}}
{"text":"By bridging the gap between textual and visual modalities, BoonArt provides a much-improved search performance compared to traditional search engines, such as the one provided by the ArtUK website.","meta":{"url":"http://arxiv.org/abs/2307.14244v1"},"cats":{"new-dataset":0.0876046579,"dev-research":0.2882214399,"prompt-eng":0.4041054665,"data-quality":0.1705654688,"ml-security":0.0644685}}
{"text":"BoonArt can be utilised to work with other artwork datasets.","meta":{"url":"http://arxiv.org/abs/2307.14244v1"},"cats":{"new-dataset":0.3112592768,"dev-research":0.2491931188,"prompt-eng":0.3567371013,"data-quality":0.1322616732,"ml-security":0.0817312723}}
{"text":"Fluorescent Neuronal Cells v2 is a collection of fluorescence microscopy images and the corresponding ground-truth annotations, designed to foster innovative research in the domains of Life Sciences and Deep Learning.","meta":{"url":"http://arxiv.org/abs/2307.14243v1"},"cats":{"new-dataset":0.3041520473,"dev-research":0.2455026203,"prompt-eng":0.3223894211,"data-quality":0.2689678257,"ml-security":0.1360035922}}
{"text":"This dataset encompasses three image collections in which rodent neuronal cells' nuclei and cytoplasm are stained with diverse markers to highlight their anatomical or functional characteristics.","meta":{"url":"http://arxiv.org/abs/2307.14243v1"},"cats":{"new-dataset":0.7119130186,"dev-research":0.1787380095,"prompt-eng":0.3680237121,"data-quality":0.1975753931,"ml-security":0.0467089489}}
{"text":"Alongside the images, we provide ground-truth annotations for several learning tasks, including semantic segmentation, object detection, and counting.","meta":{"url":"http://arxiv.org/abs/2307.14243v1"},"cats":{"new-dataset":0.4917149927,"dev-research":0.2136155618,"prompt-eng":0.3947060458,"data-quality":0.3890342817,"ml-security":0.1701255308}}
{"text":"The contribution is two-fold.","meta":{"url":"http://arxiv.org/abs/2307.14243v1"},"cats":{"new-dataset":0.0271889711,"dev-research":0.1838161944,"prompt-eng":0.3187532522,"data-quality":0.1143017719,"ml-security":0.1037242591}}
{"text":"First, given the variety of annotations and their accessible formats, we envision our work facilitating methodological advancements in computer vision approaches for segmentation, detection, feature learning, unsupervised and self-supervised learning, transfer learning, and related areas.","meta":{"url":"http://arxiv.org/abs/2307.14243v1"},"cats":{"new-dataset":0.4568688789,"dev-research":0.2034417137,"prompt-eng":0.4301014641,"data-quality":0.3105590003,"ml-security":0.1165337004}}
{"text":"Second, by enabling extensive exploration and benchmarking, we hope Fluorescent Neuronal Cells v2 will catalyze breakthroughs in fluorescence microscopy analysis and promote cutting-edge discoveries in life sciences.","meta":{"url":"http://arxiv.org/abs/2307.14243v1"},"cats":{"new-dataset":0.1818294392,"dev-research":0.2823483591,"prompt-eng":0.3319980411,"data-quality":0.2164925889,"ml-security":0.116161249}}
{"text":"The data are available at: https://amsacta.unibo.it/id/eprint/7347","meta":{"url":"http://arxiv.org/abs/2307.14243v1"},"cats":{"new-dataset":0.8645830585,"dev-research":0.0855010045,"prompt-eng":0.3608584082,"data-quality":0.090314163,"ml-security":0.028520216}}
{"text":"Deep neural networks are successfully used in various applications, but show their vulnerability to adversarial examples.","meta":{"url":"http://arxiv.org/abs/2307.14242v1"},"cats":{"new-dataset":0.1260270964,"dev-research":0.2403901315,"prompt-eng":0.3316098078,"data-quality":0.4164355182,"ml-security":0.8575831696}}
{"text":"With the development of adversarial patches, the feasibility of attacks in physical scenes increases, and the defenses against patch attacks are urgently needed.","meta":{"url":"http://arxiv.org/abs/2307.14242v1"},"cats":{"new-dataset":0.2162497655,"dev-research":0.2721952218,"prompt-eng":0.3547393658,"data-quality":0.2523288971,"ml-security":0.7200521744}}
{"text":"However, defending such adversarial patch attacks is still an unsolved problem.","meta":{"url":"http://arxiv.org/abs/2307.14242v1"},"cats":{"new-dataset":0.0644066552,"dev-research":0.337228221,"prompt-eng":0.3034774669,"data-quality":0.3694397693,"ml-security":0.8484301359}}
{"text":"In this paper, we analyse the properties of adversarial patches, and find that: on the one hand, adversarial patches will lead to the appearance or contextual inconsistency in the target objects; on the other hand, the patch region will show abnormal changes on the high-level feature maps of the objects extracted by a backbone network.","meta":{"url":"http://arxiv.org/abs/2307.14242v1"},"cats":{"new-dataset":0.2230847215,"dev-research":0.2855787922,"prompt-eng":0.3309837359,"data-quality":0.4517668123,"ml-security":0.7174272991}}
{"text":"Considering the above two points, we propose a novel defense method based on a ``localizing and inpainting\" mechanism to pre-process the input examples.","meta":{"url":"http://arxiv.org/abs/2307.14242v1"},"cats":{"new-dataset":0.0797377787,"dev-research":0.3682401583,"prompt-eng":0.476810192,"data-quality":0.3513838071,"ml-security":0.6380469103}}
{"text":"Specifically, we design an unified framework, where the ``localizing\" sub-network utilizes a two-branch structure to represent the above two aspects to accurately detect the adversarial patch region in the image.","meta":{"url":"http://arxiv.org/abs/2307.14242v1"},"cats":{"new-dataset":0.2384190297,"dev-research":0.2827800369,"prompt-eng":0.3752376393,"data-quality":0.3823348731,"ml-security":0.4830614686}}
{"text":"For the ``inpainting\" sub-network, it utilizes the surrounding contextual cues to recover the original content covered by the adversarial patch.","meta":{"url":"http://arxiv.org/abs/2307.14242v1"},"cats":{"new-dataset":0.1196182091,"dev-research":0.3075996373,"prompt-eng":0.3314274305,"data-quality":0.3202399708,"ml-security":0.3308078269}}
{"text":"The quality of inpainted images is also evaluated by measuring the appearance consistency and the effects of adversarial attacks.","meta":{"url":"http://arxiv.org/abs/2307.14242v1"},"cats":{"new-dataset":0.086078129,"dev-research":0.2095833568,"prompt-eng":0.3383280429,"data-quality":0.3807773726,"ml-security":0.3758435882}}
{"text":"These two sub-networks are then jointly trained via an iterative optimization manner.","meta":{"url":"http://arxiv.org/abs/2307.14242v1"},"cats":{"new-dataset":0.0825926778,"dev-research":0.1998990164,"prompt-eng":0.3765864176,"data-quality":0.2242004504,"ml-security":0.0954068449}}
{"text":"In this way, the ``localizing\" and ``inpainting\" modules can interact closely with each other, and thus learn a better solution.","meta":{"url":"http://arxiv.org/abs/2307.14242v1"},"cats":{"new-dataset":0.0449579181,"dev-research":0.2993380534,"prompt-eng":0.4057472029,"data-quality":0.2266644257,"ml-security":0.0713604773}}
{"text":"A series of experiments versus traffic sign classification and detection tasks are conducted to defend against various adversarial patch attacks.","meta":{"url":"http://arxiv.org/abs/2307.14242v1"},"cats":{"new-dataset":0.0982347334,"dev-research":0.2787578586,"prompt-eng":0.3573735169,"data-quality":0.3451905751,"ml-security":0.7573052634}}
{"text":"Purpose:","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.0438844708,"dev-research":0.2992328649,"prompt-eng":0.3747107998,"data-quality":0.1018286404,"ml-security":0.1023605708}}
{"text":"Recent advances in Surgical Data Science (SDS) have contributed to an increase in video recordings from hospital environments.","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.1601739507,"dev-research":0.2509687166,"prompt-eng":0.3653139024,"data-quality":0.1405714524,"ml-security":0.0573820457}}
{"text":"While methods such as surgical workflow recognition show potential in increasing the quality of patient care, the quantity of video data has surpassed the scale at which images can be manually anonymized.","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.1331880273,"dev-research":0.1976048487,"prompt-eng":0.3523445748,"data-quality":0.1992907786,"ml-security":0.1574044451}}
{"text":"Existing automated 2D anonymization methods under-perform in Operating Rooms (OR), due to occlusions and obstructions.","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.263932528,"dev-research":0.2800383044,"prompt-eng":0.4049557702,"data-quality":0.2347414581,"ml-security":0.4320932502}}
{"text":"We propose to anonymize multi-view OR recordings using 3D data from multiple camera streams.","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.357664849,"dev-research":0.2076742487,"prompt-eng":0.3093287608,"data-quality":0.238401446,"ml-security":0.3881792411}}
{"text":"Methods: RGB and depth images from multiple cameras are fused into a 3D point cloud representation of the scene.","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.2232665262,"dev-research":0.1965582618,"prompt-eng":0.3489609899,"data-quality":0.0877704866,"ml-security":0.0483426083}}
{"text":"We then detect each individual's face in 3D by regressing a parametric human mesh model onto detected 3D human keypoints and aligning the face mesh with the fused 3D point cloud.","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.0947599798,"dev-research":0.217394336,"prompt-eng":0.3876659802,"data-quality":0.0794792183,"ml-security":0.1239666481}}
{"text":"The mesh model is rendered into every acquired camera view, replacing each individual's face.","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.0601701147,"dev-research":0.2235280562,"prompt-eng":0.361411784,"data-quality":0.0903159301,"ml-security":0.1000711643}}
{"text":"Results:","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.2375105481,"dev-research":0.2152985096,"prompt-eng":0.3445034375,"data-quality":0.2368385619,"ml-security":0.0712584655}}
{"text":"Our method shows promise in locating faces at a higher rate than existing approaches.","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.1059879102,"dev-research":0.2046159554,"prompt-eng":0.3815711622,"data-quality":0.1572630892,"ml-security":0.1116475025}}
{"text":"DisguisOR produces geometrically consistent anonymizations for each camera view, enabling more realistic anonymization that is less detrimental to downstream tasks.","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.1095386063,"dev-research":0.3038303192,"prompt-eng":0.3437360524,"data-quality":0.2642519018,"ml-security":0.4150639494}}
{"text":"Conclusion: Frequent obstructions and crowding in operating rooms leaves significant room for improvement for off-the-shelf anonymization methods.","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.1630922291,"dev-research":0.2884928667,"prompt-eng":0.3869972517,"data-quality":0.294519288,"ml-security":0.5184759173}}
{"text":"DisguisOR","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.2164170076,"dev-research":0.2669469686,"prompt-eng":0.3498067327,"data-quality":0.1901094008,"ml-security":0.2360970549}}
{"text":"addresses privacy on a scene level and has the potential to facilitate further research in SDS.","meta":{"url":"http://arxiv.org/abs/2307.14241v1"},"cats":{"new-dataset":0.1169278068,"dev-research":0.2552318005,"prompt-eng":0.3901570424,"data-quality":0.1455312218,"ml-security":0.2813278324}}
{"text":"Visual-Semantic Embedding (VSE) networks can help search engines better understand the meaning behind visual content and associate it with relevant textual information, leading to more accurate search results.","meta":{"url":"http://arxiv.org/abs/2307.14240v1"},"cats":{"new-dataset":0.0378235494,"dev-research":0.374520718,"prompt-eng":0.3643893217,"data-quality":0.3081391209,"ml-security":0.0929848028}}
{"text":"VSE networks can be used in cross-modal search engines to embed image and textual descriptions in a shared space, enabling image-to-text and text-to-image retrieval tasks.","meta":{"url":"http://arxiv.org/abs/2307.14240v1"},"cats":{"new-dataset":0.1051788308,"dev-research":0.2520553183,"prompt-eng":0.4004552233,"data-quality":0.1667289752,"ml-security":0.0588337252}}
{"text":"However, the full potential of VSE networks for search engines has yet to be fully explored.","meta":{"url":"http://arxiv.org/abs/2307.14240v1"},"cats":{"new-dataset":0.0403316819,"dev-research":0.2896841414,"prompt-eng":0.3547245715,"data-quality":0.1944691332,"ml-security":0.1358576154}}
{"text":"This paper presents Boon, a novel cross-modal search engine that combines two state-of-the-art networks: the GPT-3.5-turbo large language model, and the VSE network VITR (VIsion Transformers with Relation-focused learning) to enhance the engine's capabilities in extracting and reasoning with regional relationships in images.","meta":{"url":"http://arxiv.org/abs/2307.14240v1"},"cats":{"new-dataset":0.3189848548,"dev-research":0.2688648612,"prompt-eng":0.4027114653,"data-quality":0.1581704651,"ml-security":0.0515328615}}
{"text":"VITR employs encoders from CLIP that were trained with 400 million image-description pairs and it was fine-turned on the RefCOCOg dataset.","meta":{"url":"http://arxiv.org/abs/2307.14240v1"},"cats":{"new-dataset":0.3787554423,"dev-research":0.2130364309,"prompt-eng":0.3934546052,"data-quality":0.1867800666,"ml-security":0.0641449591}}
{"text":"Boon's neural-based components serve as its main functionalities: 1) a 'cross-modal search engine' that enables end-users to perform image-to-text and text-to-image retrieval.","meta":{"url":"http://arxiv.org/abs/2307.14240v1"},"cats":{"new-dataset":0.1311593375,"dev-research":0.2427312721,"prompt-eng":0.3831910469,"data-quality":0.1166175052,"ml-security":0.1037634138}}
{"text":"2) a 'multi-lingual conversational AI' component that enables the end-user to converse about one or more images selected by the end-user.","meta":{"url":"http://arxiv.org/abs/2307.14240v1"},"cats":{"new-dataset":0.1617580698,"dev-research":0.3111626327,"prompt-eng":0.4088149524,"data-quality":0.1794631194,"ml-security":0.0805334386}}
{"text":"Such a feature makes the search engine accessible to a wide audience, including those with visual impairments.","meta":{"url":"http://arxiv.org/abs/2307.14240v1"},"cats":{"new-dataset":0.0208170866,"dev-research":0.3263786665,"prompt-eng":0.4025142367,"data-quality":0.1911592594,"ml-security":0.1177715925}}
{"text":"3) Boon is multi-lingual and can take queries and handle conversations about images in multiple languages.","meta":{"url":"http://arxiv.org/abs/2307.14240v1"},"cats":{"new-dataset":0.2221962809,"dev-research":0.3438245261,"prompt-eng":0.3945786183,"data-quality":0.1442867218,"ml-security":0.0786421134}}
{"text":"Boon was implemented using the Django and PyTorch frameworks.","meta":{"url":"http://arxiv.org/abs/2307.14240v1"},"cats":{"new-dataset":0.0862390526,"dev-research":0.2508041806,"prompt-eng":0.4294965387,"data-quality":0.1307945271,"ml-security":0.1067356829}}
{"text":"The interface and capabilities of the Boon search engine are demonstrated using the RefCOCOg dataset, and the engine's ability to search for multimedia through the web is facilitated by Google's API.","meta":{"url":"http://arxiv.org/abs/2307.14240v1"},"cats":{"new-dataset":0.2269305924,"dev-research":0.220031281,"prompt-eng":0.4165203986,"data-quality":0.1925602201,"ml-security":0.094589841}}
{"text":"Many swarm robotics tasks consist of multiple conflicting objectives.","meta":{"url":"http://arxiv.org/abs/2307.14237v1"},"cats":{"new-dataset":0.0264764409,"dev-research":0.2926654208,"prompt-eng":0.4634233696,"data-quality":0.1398369174,"ml-security":0.0793009778}}
{"text":"This research proposes a multi-objective evolutionary neural network approach to developing controllers for swarms of robots.","meta":{"url":"http://arxiv.org/abs/2307.14237v1"},"cats":{"new-dataset":0.0767012614,"dev-research":0.2756526501,"prompt-eng":0.3765234418,"data-quality":0.0648162715,"ml-security":0.1132794337}}
{"text":"The swarm robot controllers are trained in a low-fidelity Python simulator and then tested in a high-fidelity simulated environment using Webots.","meta":{"url":"http://arxiv.org/abs/2307.14237v1"},"cats":{"new-dataset":0.1685222177,"dev-research":0.2868437218,"prompt-eng":0.439454144,"data-quality":0.0710293833,"ml-security":0.0865984504}}
{"text":"Simulations are then conducted to test the scalability of the evolved multi-objective robot controllers to environments with a larger number of robots.","meta":{"url":"http://arxiv.org/abs/2307.14237v1"},"cats":{"new-dataset":0.1310537752,"dev-research":0.2737990372,"prompt-eng":0.3932710564,"data-quality":0.0514188839,"ml-security":0.1054360845}}
{"text":"The results presented demonstrate that the proposed approach can effectively control each of the robots.","meta":{"url":"http://arxiv.org/abs/2307.14237v1"},"cats":{"new-dataset":0.0220453931,"dev-research":0.2671630277,"prompt-eng":0.4691640174,"data-quality":0.0739061867,"ml-security":0.0810038142}}
{"text":"The robot swarm exhibits different behaviours as the weighting for each objective is adjusted.","meta":{"url":"http://arxiv.org/abs/2307.14237v1"},"cats":{"new-dataset":0.0518910632,"dev-research":0.2634010578,"prompt-eng":0.4474620261,"data-quality":0.0909716196,"ml-security":0.1007583986}}
{"text":"The results also confirm that multi-objective neural network controllers evolved in a low-fidelity simulator can be transferred to high-fidelity simulated environments and that the controllers can scale to environments with a larger number of robots without further retraining needed.","meta":{"url":"http://arxiv.org/abs/2307.14237v1"},"cats":{"new-dataset":0.0961168674,"dev-research":0.2667242338,"prompt-eng":0.3393505973,"data-quality":0.1007652718,"ml-security":0.2067470859}}
{"text":"This demo paper presents UnScientify, an interactive system designed to detect scientific uncertainty in scholarly full text.","meta":{"url":"http://arxiv.org/abs/2307.14236v1"},"cats":{"new-dataset":0.2455338821,"dev-research":0.2977498054,"prompt-eng":0.4396863657,"data-quality":0.400799059,"ml-security":0.0699761724}}
{"text":"The system utilizes a weakly supervised technique that employs a fine-grained annotation scheme to identify verbally formulated uncertainty at the sentence level in scientific texts.","meta":{"url":"http://arxiv.org/abs/2307.14236v1"},"cats":{"new-dataset":0.1483376389,"dev-research":0.3142589556,"prompt-eng":0.4629217349,"data-quality":0.5468574085,"ml-security":0.0745802236}}
{"text":"The pipeline for the system includes a combination of pattern matching, complex sentence checking, and authorial reference checking.","meta":{"url":"http://arxiv.org/abs/2307.14236v1"},"cats":{"new-dataset":0.1060752537,"dev-research":0.3259907693,"prompt-eng":0.477312459,"data-quality":0.2064840101,"ml-security":0.057053951}}
{"text":"Our approach automates labeling and annotation tasks for scientific uncertainty identification, taking into account different types of scientific uncertainty, that can serve various applications such as information retrieval, text mining, and scholarly document processing.","meta":{"url":"http://arxiv.org/abs/2307.14236v1"},"cats":{"new-dataset":0.2375027378,"dev-research":0.2697065452,"prompt-eng":0.4590480303,"data-quality":0.5848269583,"ml-security":0.0570316261}}
{"text":"Additionally, UnScientify provides interpretable results, aiding in the comprehension of identified instances of scientific uncertainty in text.","meta":{"url":"http://arxiv.org/abs/2307.14236v1"},"cats":{"new-dataset":0.0816767701,"dev-research":0.3520538698,"prompt-eng":0.3985465545,"data-quality":0.4025752327,"ml-security":0.0971271059}}
{"text":"Modern computer systems are ubiquitous in contemporary life yet many of them remain opaque.","meta":{"url":"http://arxiv.org/abs/2307.14232v1"},"cats":{"new-dataset":0.0829036992,"dev-research":0.3144607472,"prompt-eng":0.379342212,"data-quality":0.1357060452,"ml-security":0.216346281}}
{"text":"This poses significant challenges in domains where desiderata such as fairness or accountability are crucial.","meta":{"url":"http://arxiv.org/abs/2307.14232v1"},"cats":{"new-dataset":0.0781987369,"dev-research":0.3106793248,"prompt-eng":0.343199793,"data-quality":0.2708595484,"ml-security":0.3725330372}}
{"text":"We suggest that the best strategy for achieving system transparency varies depending on the specific source of opacity prevalent in a given context.","meta":{"url":"http://arxiv.org/abs/2307.14232v1"},"cats":{"new-dataset":0.0734001018,"dev-research":0.2936843514,"prompt-eng":0.4217608089,"data-quality":0.1789930937,"ml-security":0.2410734075}}
{"text":"Synthesizing and extending existing discussions, we propose a taxonomy consisting of eight sources of opacity that fall into three main categories: architectural, analytical, and socio-technical.","meta":{"url":"http://arxiv.org/abs/2307.14232v1"},"cats":{"new-dataset":0.2524112077,"dev-research":0.3690847004,"prompt-eng":0.3936022972,"data-quality":0.1279187112,"ml-security":0.0932321845}}
{"text":"For each source, we provide initial suggestions as to how to address the resulting opacity in practice.","meta":{"url":"http://arxiv.org/abs/2307.14232v1"},"cats":{"new-dataset":0.134489891,"dev-research":0.2772837541,"prompt-eng":0.3922306402,"data-quality":0.1457595292,"ml-security":0.0727532838}}
{"text":"The taxonomy provides a starting point for requirements engineers and other practitioners to understand contextually prevalent sources of opacity, and to select or develop appropriate strategies for overcoming them.","meta":{"url":"http://arxiv.org/abs/2307.14232v1"},"cats":{"new-dataset":0.1132875205,"dev-research":0.44662115,"prompt-eng":0.4555399473,"data-quality":0.1429214105,"ml-security":0.0676527602}}
{"text":"Traditional Chinese Painting (TCP) is an invaluable cultural heritage resource and a unique visual art style.","meta":{"url":"http://arxiv.org/abs/2307.14227v1"},"cats":{"new-dataset":0.1483915943,"dev-research":0.2960419768,"prompt-eng":0.3564950847,"data-quality":0.0857581765,"ml-security":0.0533076366}}
{"text":"In recent years, increasing interest has been placed on digitalizing TCPs to preserve and revive the culture.","meta":{"url":"http://arxiv.org/abs/2307.14227v1"},"cats":{"new-dataset":0.1582473071,"dev-research":0.3327325685,"prompt-eng":0.3920046428,"data-quality":0.1233526934,"ml-security":0.1006241985}}
{"text":"The resulting digital copies have enabled the advancement of computational methods for structured and systematic understanding of TCPs.","meta":{"url":"http://arxiv.org/abs/2307.14227v1"},"cats":{"new-dataset":0.0713951685,"dev-research":0.3625268927,"prompt-eng":0.4512522042,"data-quality":0.134671138,"ml-security":0.0969965338}}
{"text":"To explore this topic, we conducted an in-depth analysis of 92 pieces of literature.","meta":{"url":"http://arxiv.org/abs/2307.14227v1"},"cats":{"new-dataset":0.1010893278,"dev-research":0.2666436373,"prompt-eng":0.3474999229,"data-quality":0.146390689,"ml-security":0.0918572522}}
{"text":"We examined the current use of computer technologies on TCPs from three perspectives, based on numerous conversations with specialists.","meta":{"url":"http://arxiv.org/abs/2307.14227v1"},"cats":{"new-dataset":0.0566442968,"dev-research":0.3936741144,"prompt-eng":0.4162022103,"data-quality":0.0867610452,"ml-security":0.0921930548}}
{"text":"First, in light of the \"Six Principles of Painting\" theory, we categorized the articles according to their research focus on artistic elements.","meta":{"url":"http://arxiv.org/abs/2307.14227v1"},"cats":{"new-dataset":0.0777415437,"dev-research":0.2002518015,"prompt-eng":0.3208056089,"data-quality":0.0896893585,"ml-security":0.0464719817}}
{"text":"Second, we created a four-stage framework to illustrate the purposes of TCP applications.","meta":{"url":"http://arxiv.org/abs/2307.14227v1"},"cats":{"new-dataset":0.125067581,"dev-research":0.3223952512,"prompt-eng":0.4308923373,"data-quality":0.0885798289,"ml-security":0.1095263751}}
{"text":"Third, we summarized the popular computational techniques applied to TCPs.","meta":{"url":"http://arxiv.org/abs/2307.14227v1"},"cats":{"new-dataset":0.1006682939,"dev-research":0.2184343211,"prompt-eng":0.4214245331,"data-quality":0.0935775514,"ml-security":0.0783680535}}
{"text":"The framework also provides insights into potential applications and future prospects, with professional opinion.","meta":{"url":"http://arxiv.org/abs/2307.14227v1"},"cats":{"new-dataset":0.0267018859,"dev-research":0.3569329466,"prompt-eng":0.3299768675,"data-quality":0.096980916,"ml-security":0.0838391401}}
{"text":"The list of surveyed publications and related information is available online at https://ca4tcp.com.","meta":{"url":"http://arxiv.org/abs/2307.14227v1"},"cats":{"new-dataset":0.5445291266,"dev-research":0.1619973126,"prompt-eng":0.3573081901,"data-quality":0.0725229706,"ml-security":0.0228997924}}
{"text":"Climate issues have become more and more important now.","meta":{"url":"http://arxiv.org/abs/2307.14226v1"},"cats":{"new-dataset":0.1241593796,"dev-research":0.3258713741,"prompt-eng":0.2973224356,"data-quality":0.1325353635,"ml-security":0.1091911332}}
{"text":"Although global governments have made some progress, we are still facing the truth that the prospect of international cooperation is not clear at present.","meta":{"url":"http://arxiv.org/abs/2307.14226v1"},"cats":{"new-dataset":0.0499268442,"dev-research":0.2328229915,"prompt-eng":0.2950379802,"data-quality":0.186336717,"ml-security":0.1373954419}}
{"text":"Due to the limitations of the Integrated assessment models (IAMs) model, it is difficult to simulate the dynamic negotiation process.","meta":{"url":"http://arxiv.org/abs/2307.14226v1"},"cats":{"new-dataset":0.033929438,"dev-research":0.2861199929,"prompt-eng":0.466548316,"data-quality":0.1002553665,"ml-security":0.0773590722}}
{"text":"Therefore, using deep learning to build a new agents based model (ABM) might can provide new theoretical support for climate negotiations.","meta":{"url":"http://arxiv.org/abs/2307.14226v1"},"cats":{"new-dataset":0.2332834317,"dev-research":0.2541776601,"prompt-eng":0.3318309542,"data-quality":0.0947389369,"ml-security":0.142027206}}
{"text":"Building on the RICE-N model, this work proposed an approach to climate negotiations based on existing trade groups.","meta":{"url":"http://arxiv.org/abs/2307.14226v1"},"cats":{"new-dataset":0.40394358,"dev-research":0.1813205457,"prompt-eng":0.3276359497,"data-quality":0.0811666524,"ml-security":0.0764223635}}
{"text":"Simulation results show that the scheme has a good prospect.","meta":{"url":"http://arxiv.org/abs/2307.14226v1"},"cats":{"new-dataset":0.0630963107,"dev-research":0.1579177942,"prompt-eng":0.4113523751,"data-quality":0.065181283,"ml-security":0.0630689355}}
{"text":"Traditional recommender systems leverage users' item preference history to recommend novel content that users may like.","meta":{"url":"http://arxiv.org/abs/2307.14225v1"},"cats":{"new-dataset":0.0138775759,"dev-research":0.3025125187,"prompt-eng":0.40542016,"data-quality":0.0854252672,"ml-security":0.0856968683}}
{"text":"However, modern dialog interfaces that allow users to express language-based preferences offer a fundamentally different modality for preference input.","meta":{"url":"http://arxiv.org/abs/2307.14225v1"},"cats":{"new-dataset":0.0551309727,"dev-research":0.3000357514,"prompt-eng":0.4465192375,"data-quality":0.1719949335,"ml-security":0.0980432882}}
{"text":"Inspired by recent successes of prompting paradigms for large language models (LLMs), we study their use for making recommendations from both item-based and language-based preferences in comparison to state-of-the-art item-based collaborative filtering (CF) methods.","meta":{"url":"http://arxiv.org/abs/2307.14225v1"},"cats":{"new-dataset":0.0725987569,"dev-research":0.2461920382,"prompt-eng":0.4590087407,"data-quality":0.187966664,"ml-security":0.1052276332}}
{"text":"To support this investigation, we collect a new dataset consisting of both item-based and language-based preferences elicited from users along with their ratings on a variety of (biased) recommended items and (unbiased) random items.","meta":{"url":"http://arxiv.org/abs/2307.14225v1"},"cats":{"new-dataset":0.1905628488,"dev-research":0.2671822027,"prompt-eng":0.4847096213,"data-quality":0.2459921497,"ml-security":0.1532778403}}
{"text":"Among numerous experimental results, we find that LLMs provide competitive recommendation performance for pure language-based preferences (no item preferences) in the near cold-start case in comparison to item-based CF methods, despite having no supervised training for this specific task (zero-shot) or only a few labels (few-shot).","meta":{"url":"http://arxiv.org/abs/2307.14225v1"},"cats":{"new-dataset":0.0843116559,"dev-research":0.2134951759,"prompt-eng":0.4534517072,"data-quality":0.2222468185,"ml-security":0.0876764095}}
{"text":"This is particularly promising as language-based preference representations are more explainable and scrutable than item-based or vector-based representations.","meta":{"url":"http://arxiv.org/abs/2307.14225v1"},"cats":{"new-dataset":0.0443941701,"dev-research":0.2962034827,"prompt-eng":0.4696925418,"data-quality":0.1957676156,"ml-security":0.1030680144}}
{"text":"The \"Sum-Over-Paths\" formalism is a way to symbolically manipulate linear maps that describe quantum systems, and is a tool that is used in formal verification of such systems.","meta":{"url":"http://arxiv.org/abs/2307.14223v1"},"cats":{"new-dataset":0.0264558792,"dev-research":0.2837157776,"prompt-eng":0.4190382526,"data-quality":0.12139305,"ml-security":0.1258739764}}
{"text":"We give here a new set of rewrite rules for the formalism, and show that it is complete for \"Toffoli-Hadamard\", the simplest approximately universal fragment of quantum mechanics.","meta":{"url":"http://arxiv.org/abs/2307.14223v1"},"cats":{"new-dataset":0.0696632418,"dev-research":0.1721074795,"prompt-eng":0.366762627,"data-quality":0.1101768279,"ml-security":0.1115686091}}
{"text":"We show that the rewriting is terminating, but not confluent (which is expected from the universality of the fragment).","meta":{"url":"http://arxiv.org/abs/2307.14223v1"},"cats":{"new-dataset":0.0413645281,"dev-research":0.2036259451,"prompt-eng":0.3505640836,"data-quality":0.2248490713,"ml-security":0.128339964}}
{"text":"We do so using the connection between Sum-over-Paths and graphical language ZH-calculus, and also show how the axiomatisation translates into the latter.","meta":{"url":"http://arxiv.org/abs/2307.14223v1"},"cats":{"new-dataset":0.1178901116,"dev-research":0.282039206,"prompt-eng":0.358351063,"data-quality":0.1076606082,"ml-security":0.1091392554}}
{"text":"We provide generalisations of the presented rewrite rules, that can prove useful when trying to reduce terms in practice, and we show how to graphically make sense of these new rules.","meta":{"url":"http://arxiv.org/abs/2307.14223v1"},"cats":{"new-dataset":0.040161485,"dev-research":0.3759733973,"prompt-eng":0.4288334909,"data-quality":0.2806582579,"ml-security":0.1368089167}}
{"text":"We show how to enrich the rewrite system to reach completeness for the dyadic fragments of quantum computation, used in particular in the Quantum Fourier Transform, and obtained by adding phase gates with dyadic multiples of $\\pi$ to the Toffoli-Hadamard gate-set.","meta":{"url":"http://arxiv.org/abs/2307.14223v1"},"cats":{"new-dataset":0.0848596964,"dev-research":0.2042110921,"prompt-eng":0.3649314598,"data-quality":0.084924711,"ml-security":0.1069238784}}
{"text":"Finally, we show how to perform sums and concatenation of arbitrary terms, something which is not native in a system designed for analysing gate-based quantum computation, but necessary when considering Hamiltonian-based quantum computation.","meta":{"url":"http://arxiv.org/abs/2307.14223v1"},"cats":{"new-dataset":0.0300978756,"dev-research":0.2158192209,"prompt-eng":0.3744932758,"data-quality":0.101916721,"ml-security":0.1500167155}}
{"text":"Flexible robots have advantages over rigid robots in their ability to conform physically to their environment and to form a wide variety of shapes.","meta":{"url":"http://arxiv.org/abs/2307.14213v1"},"cats":{"new-dataset":0.014023288,"dev-research":0.2193643576,"prompt-eng":0.3639926359,"data-quality":0.0614514509,"ml-security":0.0988713346}}
{"text":"Sensing the force applied by or to flexible robots is useful for both navigation and manipulation tasks, but it is challenging due to the need for the sensors to withstand the robots' shape change without encumbering their functionality.","meta":{"url":"http://arxiv.org/abs/2307.14213v1"},"cats":{"new-dataset":0.0253168245,"dev-research":0.1886754679,"prompt-eng":0.4204367861,"data-quality":0.0782192775,"ml-security":0.1149298216}}
{"text":"Also, for robots with long or large bodies, the number of sensors required to cover the entire surface area of the robot body can be prohibitive due to high cost and complexity.","meta":{"url":"http://arxiv.org/abs/2307.14213v1"},"cats":{"new-dataset":0.0398494392,"dev-research":0.2095145881,"prompt-eng":0.3578065943,"data-quality":0.0544051918,"ml-security":0.1327274024}}
{"text":"We present a novel soft air pocket force sensor that is highly flexible, lightweight, relatively inexpensive, and easily scalable to various sizes.","meta":{"url":"http://arxiv.org/abs/2307.14213v1"},"cats":{"new-dataset":0.1197258827,"dev-research":0.1747524898,"prompt-eng":0.4088593793,"data-quality":0.0879507013,"ml-security":0.0772483338}}
{"text":"Our sensor produces a change in internal pressure that is linear with the applied force.","meta":{"url":"http://arxiv.org/abs/2307.14213v1"},"cats":{"new-dataset":0.0430226312,"dev-research":0.210304167,"prompt-eng":0.3682404992,"data-quality":0.166667746,"ml-security":0.1547288095}}
{"text":"We present results of experimental testing of how uncontrollable factors (contact location and contact area) and controllable factors (initial internal pressure, thickness, size, and number of interior seals) affect the sensitivity.","meta":{"url":"http://arxiv.org/abs/2307.14213v1"},"cats":{"new-dataset":0.0458611452,"dev-research":0.2249288048,"prompt-eng":0.4827055767,"data-quality":0.1364019418,"ml-security":0.1087739359}}
{"text":"We demonstrate our sensor applied to a vine robot-a soft inflatable robot that \"grows\" from the tip via eversion-and we show that the robot can successfully grow and steer towards an object with which it senses contact.","meta":{"url":"http://arxiv.org/abs/2307.14213v1"},"cats":{"new-dataset":0.1506826329,"dev-research":0.1882522671,"prompt-eng":0.4081366843,"data-quality":0.0880226724,"ml-security":0.0739311527}}
{"text":"Data-driven requirements engineering leverages the abundance of openly accessible and crowdsourced information on the web.","meta":{"url":"http://arxiv.org/abs/2307.14212v1"},"cats":{"new-dataset":0.1822462675,"dev-research":0.4502490327,"prompt-eng":0.4501498349,"data-quality":0.1773943872,"ml-security":0.1286754686}}
{"text":"By incorporating user feedback provided about a software product, such as reviews in mobile app stores, these approaches facilitate the identification of issues, bug fixes, and implementation of change requests.","meta":{"url":"http://arxiv.org/abs/2307.14212v1"},"cats":{"new-dataset":0.0703756688,"dev-research":0.5585790768,"prompt-eng":0.4746760665,"data-quality":0.3849942912,"ml-security":0.1203376135}}
{"text":"However, relying solely on user feedback about a software product limits the possibility of eliciting all requirements, as users may not always have a clear understanding of their exact needs from the software, despite their wealth of experience with the problem, event, or challenges they encounter and use the software to assist them.","meta":{"url":"http://arxiv.org/abs/2307.14212v1"},"cats":{"new-dataset":0.0252509433,"dev-research":0.5396962428,"prompt-eng":0.4813065844,"data-quality":0.2356925824,"ml-security":0.1712970615}}
{"text":"In this study, we propose a shift in requirements elicitation, focusing on gathering feedback related to the problem itself rather than relying solely on feedback about the software product.","meta":{"url":"http://arxiv.org/abs/2307.14212v1"},"cats":{"new-dataset":0.0908152481,"dev-research":0.540044054,"prompt-eng":0.540981924,"data-quality":0.2233104283,"ml-security":0.0652418391}}
{"text":"We conducted a case study on student requirements during the COVID-19 pandemic in a higher education institution.","meta":{"url":"http://arxiv.org/abs/2307.14212v1"},"cats":{"new-dataset":0.1569470256,"dev-research":0.293905407,"prompt-eng":0.4235959375,"data-quality":0.0754327941,"ml-security":0.1444445174}}
{"text":"We gathered their communications from Reddit during the pandemic and employed multiple machine-learning and natural language processing techniques to identify requirement sentences.","meta":{"url":"http://arxiv.org/abs/2307.14212v1"},"cats":{"new-dataset":0.3514807688,"dev-research":0.2531250508,"prompt-eng":0.4541303595,"data-quality":0.1814522823,"ml-security":0.0984404219}}
{"text":"We achieved the F-score of 0.79 using Naive Bayes with TF-IDF when benchmarking multiple techniques.","meta":{"url":"http://arxiv.org/abs/2307.14212v1"},"cats":{"new-dataset":0.1817005966,"dev-research":0.1999423577,"prompt-eng":0.4232398637,"data-quality":0.3524756178,"ml-security":0.0499135137}}
{"text":"The results lead us to believe that mining requirements from communication about a problem are feasible.","meta":{"url":"http://arxiv.org/abs/2307.14212v1"},"cats":{"new-dataset":0.0282832908,"dev-research":0.2753930645,"prompt-eng":0.390641152,"data-quality":0.1769843935,"ml-security":0.1287196573}}
{"text":"While we present the preliminary results, we envision a future where these requirements complement conventionally elicited requirements and help to close the requirements gap.","meta":{"url":"http://arxiv.org/abs/2307.14212v1"},"cats":{"new-dataset":0.1254044515,"dev-research":0.3463808859,"prompt-eng":0.5216207437,"data-quality":0.1935276886,"ml-security":0.0759601552}}
{"text":"Monitoring a population of dependent processes under limited resources is critical for abnormal events detection.","meta":{"url":"http://arxiv.org/abs/2307.14208v1"},"cats":{"new-dataset":0.0890882077,"dev-research":0.2427198732,"prompt-eng":0.4560035902,"data-quality":0.2843507985,"ml-security":0.1801336029}}
{"text":"A novel online collaborative learning method is proposed to adaptively allocate the resources for exploitation of high-risk processes and exploration of dependent dynamics.","meta":{"url":"http://arxiv.org/abs/2307.14208v1"},"cats":{"new-dataset":0.0567324215,"dev-research":0.3538425509,"prompt-eng":0.3776455789,"data-quality":0.087845031,"ml-security":0.2078529}}
{"text":"Efficiency of the proposed method is proved through theoretical analysis and experiments.","meta":{"url":"http://arxiv.org/abs/2307.14208v1"},"cats":{"new-dataset":0.0052131947,"dev-research":0.2019641951,"prompt-eng":0.4161489247,"data-quality":0.1187647979,"ml-security":0.0349441468}}
{"text":"This exploratory study investigates the potential of the artificial intelligence tool, ChatGPT, to support systems thinking (ST) in various subjects.","meta":{"url":"http://arxiv.org/abs/2307.14206v1"},"cats":{"new-dataset":0.1149820635,"dev-research":0.4677991678,"prompt-eng":0.4023182583,"data-quality":0.0947773303,"ml-security":0.0858866605}}
{"text":"Using both general and subject specific prompts, the study assesses the accuracy, helpfulness, and reliability of ChatGPT's responses across different versions of the tool.","meta":{"url":"http://arxiv.org/abs/2307.14206v1"},"cats":{"new-dataset":0.0928305671,"dev-research":0.4000034871,"prompt-eng":0.4783170036,"data-quality":0.2052159339,"ml-security":0.041541832}}
{"text":"The results indicate that ChatGPT can provide largely correct and very helpful responses in various subjects, demonstrating its potential as a tool for enhancing ST skills.","meta":{"url":"http://arxiv.org/abs/2307.14206v1"},"cats":{"new-dataset":0.0666552533,"dev-research":0.3752403721,"prompt-eng":0.4147906267,"data-quality":0.1543253048,"ml-security":0.0564029549}}
{"text":"However, occasional inaccuracies highlight the need for users to remain critical of ChatGPT's responses.","meta":{"url":"http://arxiv.org/abs/2307.14206v1"},"cats":{"new-dataset":0.0438856184,"dev-research":0.4244107284,"prompt-eng":0.411777541,"data-quality":0.3681315148,"ml-security":0.141917921}}
{"text":"Despite some limitations, this study suggests that with careful use and attention to its idiosyncrasies, ChatGPT can be a valuable tool for teaching and learning ST.","meta":{"url":"http://arxiv.org/abs/2307.14206v1"},"cats":{"new-dataset":0.290369662,"dev-research":0.398324863,"prompt-eng":0.3745165295,"data-quality":0.150975181,"ml-security":0.0749505129}}
{"text":"This paper investigates a spherical transmitter (TX) with a membrane covered by heterogeneous receptors of varying sizes and arbitrary locations for molecular communication (MC), where molecules are encapsulated within vesicles and released from the TX through membrane fusion.","meta":{"url":"http://arxiv.org/abs/2307.14202v1"},"cats":{"new-dataset":0.0429219963,"dev-research":0.228938196,"prompt-eng":0.3944370931,"data-quality":0.0709480038,"ml-security":0.1458248983}}
{"text":"Assuming continuous vesicle generation at the TX and a transparent receiver (RX), we calculate the molecule release rate, the fraction of absorbed molecules at the TX, and the received signal at the RX.","meta":{"url":"http://arxiv.org/abs/2307.14202v1"},"cats":{"new-dataset":0.0422614739,"dev-research":0.1668174838,"prompt-eng":0.4204761733,"data-quality":0.0834971933,"ml-security":0.0743655788}}
{"text":"All obtained analytical expressions are functions of all receptors locations and sizes, and are validated by particle-based simulations.","meta":{"url":"http://arxiv.org/abs/2307.14202v1"},"cats":{"new-dataset":0.0274984897,"dev-research":0.1637256261,"prompt-eng":0.3919576092,"data-quality":0.0738843617,"ml-security":0.0856849367}}
{"text":"Our numerical results indicate that evenly distributed receptors on the TX membrane can absorb more molecules than randomly distributed receptors or a single receptor.","meta":{"url":"http://arxiv.org/abs/2307.14202v1"},"cats":{"new-dataset":0.0279530386,"dev-research":0.1320477277,"prompt-eng":0.3999439692,"data-quality":0.0737161525,"ml-security":0.1228899745}}
{"text":"Furthermore, inspired by the autoreceptor functionality in synaptic communication, we incorporate a negative feedback mechanism (NFM) at the TX, such that molecule release stops after a certain period.","meta":{"url":"http://arxiv.org/abs/2307.14202v1"},"cats":{"new-dataset":0.0230279168,"dev-research":0.259746635,"prompt-eng":0.4555912867,"data-quality":0.1538105079,"ml-security":0.1195580692}}
{"text":"We then derive the fraction of molecules that can be reused for the subsequent emissions when considering both NFM and molecule harvesting.","meta":{"url":"http://arxiv.org/abs/2307.14202v1"},"cats":{"new-dataset":0.039427478,"dev-research":0.1768499997,"prompt-eng":0.3682673833,"data-quality":0.143440798,"ml-security":0.0705540565}}
{"text":"Our numerical results demonstrate that incorporating NFM can reduce inter-symbol interference (ISI) while maintaining the same peak received signal as the case without NFM.","meta":{"url":"http://arxiv.org/abs/2307.14202v1"},"cats":{"new-dataset":0.0167395816,"dev-research":0.2531934101,"prompt-eng":0.4540176199,"data-quality":0.1708833794,"ml-security":0.0797630172}}
{"text":"Additionally, our results show that TXs incorporating both molecule harvesting and NFM can achieve a higher energy efficiency and lower error probability than TXs employing only molecule harvesting or neither functionality.","meta":{"url":"http://arxiv.org/abs/2307.14202v1"},"cats":{"new-dataset":0.0134466896,"dev-research":0.2192284497,"prompt-eng":0.4173310909,"data-quality":0.1422693977,"ml-security":0.0447269292}}
{"text":"The hydrometallurgical method of zinc production involves leaching zinc from ore and then separating the solid residue from the liquid solution by pressure filtration.","meta":{"url":"http://arxiv.org/abs/2307.14199v1"},"cats":{"new-dataset":0.0111145631,"dev-research":0.2933176293,"prompt-eng":0.3205489111,"data-quality":0.1148790915,"ml-security":0.0748212198}}
{"text":"This separation process is very important since the solid residue contains some moisture that can reduce the amount of zinc recovered.","meta":{"url":"http://arxiv.org/abs/2307.14199v1"},"cats":{"new-dataset":0.0101852292,"dev-research":0.259436649,"prompt-eng":0.315758779,"data-quality":0.1380925364,"ml-security":0.068140405}}
{"text":"This study modeled the pressure filtration process through Random Forest (RF) and Support Vector Machine (SVM).","meta":{"url":"http://arxiv.org/abs/2307.14199v1"},"cats":{"new-dataset":0.0290900316,"dev-research":0.2099263326,"prompt-eng":0.3909510005,"data-quality":0.1599356373,"ml-security":0.1432101343}}
{"text":"The models take continuous variables (extracted features) from the lab samples as inputs.","meta":{"url":"http://arxiv.org/abs/2307.14199v1"},"cats":{"new-dataset":0.1585106667,"dev-research":0.2335336488,"prompt-eng":0.3977491648,"data-quality":0.1218658551,"ml-security":0.0843859656}}
{"text":"Thus, regression models namely Random Forest Regression (RFR) and Support Vector Regression (SVR) were chosen.","meta":{"url":"http://arxiv.org/abs/2307.14199v1"},"cats":{"new-dataset":0.1303181654,"dev-research":0.2132969185,"prompt-eng":0.3866402977,"data-quality":0.1364952333,"ml-security":0.1091431275}}
{"text":"A total dataset was obtained during the pressure filtration process in two conditions: 1) Polypropylene (S1) and 2) Polyester fabrics (S2).","meta":{"url":"http://arxiv.org/abs/2307.14199v1"},"cats":{"new-dataset":0.1540975233,"dev-research":0.1949718679,"prompt-eng":0.3862845889,"data-quality":0.1172232047,"ml-security":0.0571760832}}
{"text":"To predict the cake moisture, solids concentration (0.2 and 0.38), temperature (35 and 65 centigrade), pH (2, 3.5, and 5), pressure, cake thickness (14, 20, 26, and 34 mm), air-blow time (2, 10 and 15 min) and filtration time were applied as input variables.","meta":{"url":"http://arxiv.org/abs/2307.14199v1"},"cats":{"new-dataset":0.0904259896,"dev-research":0.2040381512,"prompt-eng":0.4062242941,"data-quality":0.0640685388,"ml-security":0.0775126139}}
{"text":"The models' predictive accuracy was evaluated by the coefficient of determination (R2) parameter.","meta":{"url":"http://arxiv.org/abs/2307.14199v1"},"cats":{"new-dataset":0.0225869107,"dev-research":0.2032852822,"prompt-eng":0.4483610633,"data-quality":0.2096815535,"ml-security":0.066645896}}
{"text":"The results revealed that the RFR model is superior to the SVR model for cake moisture prediction.","meta":{"url":"http://arxiv.org/abs/2307.14199v1"},"cats":{"new-dataset":0.0470265926,"dev-research":0.1873431605,"prompt-eng":0.4481888428,"data-quality":0.0847667689,"ml-security":0.0557215447}}
{"text":"Numerous models for supervised and reinforcement learning benefit from combinations of discrete and continuous model components.","meta":{"url":"http://arxiv.org/abs/2307.14193v1"},"cats":{"new-dataset":0.0315945279,"dev-research":0.1731531691,"prompt-eng":0.3710309417,"data-quality":0.0790826188,"ml-security":0.09093924}}
{"text":"End-to-end learnable discrete-continuous models are compositional, tend to generalize better, and are more interpretable.","meta":{"url":"http://arxiv.org/abs/2307.14193v1"},"cats":{"new-dataset":0.0463119755,"dev-research":0.2194628732,"prompt-eng":0.3280552989,"data-quality":0.1778186133,"ml-security":0.1345987935}}
{"text":"A popular approach to building discrete-continuous computation graphs is that of integrating discrete probability distributions into neural networks using stochastic softmax tricks.","meta":{"url":"http://arxiv.org/abs/2307.14193v1"},"cats":{"new-dataset":0.0999896371,"dev-research":0.248411879,"prompt-eng":0.3353195175,"data-quality":0.1468454775,"ml-security":0.1522284203}}
{"text":"Prior work has mainly focused on computation graphs with a single discrete component on each of the graph's execution paths.","meta":{"url":"http://arxiv.org/abs/2307.14193v1"},"cats":{"new-dataset":0.1700877254,"dev-research":0.3452138396,"prompt-eng":0.3933049719,"data-quality":0.0885570531,"ml-security":0.0726255683}}
{"text":"We analyze the behavior of more complex stochastic computations graphs with multiple sequential discrete components.","meta":{"url":"http://arxiv.org/abs/2307.14193v1"},"cats":{"new-dataset":0.0920648854,"dev-research":0.2371623549,"prompt-eng":0.3598763567,"data-quality":0.1219273549,"ml-security":0.0816670758}}
{"text":"We show that it is challenging to optimize the parameters of these models, mainly due to small gradients and local minima.","meta":{"url":"http://arxiv.org/abs/2307.14193v1"},"cats":{"new-dataset":0.0652890156,"dev-research":0.142297816,"prompt-eng":0.3990033037,"data-quality":0.1817360693,"ml-security":0.1280880878}}
{"text":"We then propose two new strategies to overcome these challenges.","meta":{"url":"http://arxiv.org/abs/2307.14193v1"},"cats":{"new-dataset":0.0280977419,"dev-research":0.3334068692,"prompt-eng":0.3698652095,"data-quality":0.1257899706,"ml-security":0.1727370669}}
{"text":"First, we show that increasing the scale parameter of the Gumbel noise perturbations during training improves the learning behavior.","meta":{"url":"http://arxiv.org/abs/2307.14193v1"},"cats":{"new-dataset":0.0492717173,"dev-research":0.2354486702,"prompt-eng":0.3637526333,"data-quality":0.3266521984,"ml-security":0.2512025548}}
{"text":"Second, we propose dropout residual connections specifically tailored to stochastic, discrete-continuous computation graphs.","meta":{"url":"http://arxiv.org/abs/2307.14193v1"},"cats":{"new-dataset":0.125988851,"dev-research":0.271778953,"prompt-eng":0.3427138992,"data-quality":0.2255620966,"ml-security":0.1297514799}}
{"text":"With an extensive set of experiments, we show that we can train complex discrete-continuous models which one cannot train with standard stochastic softmax tricks.","meta":{"url":"http://arxiv.org/abs/2307.14193v1"},"cats":{"new-dataset":0.1268955564,"dev-research":0.1527544441,"prompt-eng":0.3138828577,"data-quality":0.2176052986,"ml-security":0.215390785}}
{"text":"We also show that complex discrete-stochastic models generalize better than their continuous counterparts on several benchmark datasets.","meta":{"url":"http://arxiv.org/abs/2307.14193v1"},"cats":{"new-dataset":0.1674727438,"dev-research":0.1683136086,"prompt-eng":0.3359161158,"data-quality":0.1580223482,"ml-security":0.087201058}}
{"text":"This paper delves into the realm of ChatGPT, an AI-powered chatbot that utilizes topic modeling and reinforcement learning to generate natural responses.","meta":{"url":"http://arxiv.org/abs/2307.14192v1"},"cats":{"new-dataset":0.1562546638,"dev-research":0.3082742674,"prompt-eng":0.4191840051,"data-quality":0.1709131046,"ml-security":0.0868780071}}
{"text":"Although ChatGPT holds immense promise across various industries, such as customer service, education, mental health treatment, personal productivity, and content creation, it is essential to address its security, privacy, and ethical implications.","meta":{"url":"http://arxiv.org/abs/2307.14192v1"},"cats":{"new-dataset":0.1529156277,"dev-research":0.3394924583,"prompt-eng":0.2945106958,"data-quality":0.1246208283,"ml-security":0.2307631173}}
{"text":"By exploring the upgrade path from GPT-1 to GPT-4, discussing the model's features, limitations, and potential applications, this study aims to shed light on the potential risks of integrating ChatGPT into our daily lives.","meta":{"url":"http://arxiv.org/abs/2307.14192v1"},"cats":{"new-dataset":0.1762413001,"dev-research":0.358246337,"prompt-eng":0.4023314196,"data-quality":0.1755214373,"ml-security":0.1985880804}}
{"text":"Focusing on security, privacy, and ethics issues, we highlight the challenges these concerns pose for widespread adoption.","meta":{"url":"http://arxiv.org/abs/2307.14192v1"},"cats":{"new-dataset":0.0495634932,"dev-research":0.2995769318,"prompt-eng":0.3668886174,"data-quality":0.2196579192,"ml-security":0.5390146713}}
{"text":"Finally, we analyze the open problems in these areas, calling for concerted efforts to ensure the development of secure and ethically sound large language models.","meta":{"url":"http://arxiv.org/abs/2307.14192v1"},"cats":{"new-dataset":0.2408879006,"dev-research":0.2258888557,"prompt-eng":0.3783483868,"data-quality":0.2346648971,"ml-security":0.4306247823}}
{"text":"Forecasting future trajectories of agents in complex traffic scenes requires reliable and efficient predictions for all agents in the scene.","meta":{"url":"http://arxiv.org/abs/2307.14187v1"},"cats":{"new-dataset":0.245918025,"dev-research":0.1783492151,"prompt-eng":0.3356873624,"data-quality":0.0810949118,"ml-security":0.1220680884}}
{"text":"However, existing methods for trajectory prediction are either inefficient or sacrifice accuracy.","meta":{"url":"http://arxiv.org/abs/2307.14187v1"},"cats":{"new-dataset":0.0264823914,"dev-research":0.2128793692,"prompt-eng":0.3204540555,"data-quality":0.1121626193,"ml-security":0.1262982006}}
{"text":"To address this challenge, we propose ADAPT, a novel approach for jointly predicting the trajectories of all agents in the scene with dynamic weight learning.","meta":{"url":"http://arxiv.org/abs/2307.14187v1"},"cats":{"new-dataset":0.2512856751,"dev-research":0.1507621807,"prompt-eng":0.3638606431,"data-quality":0.1148627468,"ml-security":0.1361805233}}
{"text":"Our approach outperforms state-of-the-art methods in both single-agent and multi-agent settings on the Argoverse and Interaction datasets, with a fraction of their computational overhead.","meta":{"url":"http://arxiv.org/abs/2307.14187v1"},"cats":{"new-dataset":0.6325216346,"dev-research":0.2059820914,"prompt-eng":0.3896378016,"data-quality":0.1007282189,"ml-security":0.0736615402}}
{"text":"We attribute the improvement in our performance: first, to the adaptive head augmenting the model capacity without increasing the model size; second, to our design choices in the endpoint-conditioned prediction, reinforced by gradient stopping.","meta":{"url":"http://arxiv.org/abs/2307.14187v1"},"cats":{"new-dataset":0.0958784711,"dev-research":0.2060585014,"prompt-eng":0.4361242848,"data-quality":0.1572764624,"ml-security":0.1449184729}}
{"text":"Our analyses show that ADAPT can focus on each agent with adaptive prediction, allowing for accurate predictions efficiently.","meta":{"url":"http://arxiv.org/abs/2307.14187v1"},"cats":{"new-dataset":0.0749733178,"dev-research":0.2535991794,"prompt-eng":0.4292750189,"data-quality":0.101554433,"ml-security":0.1663353899}}
{"text":"https://KUIS-AI.github.io/adapt","meta":{"url":"http://arxiv.org/abs/2307.14187v1"},"cats":{"new-dataset":0.3649495556,"dev-research":0.2121549685,"prompt-eng":0.4421202975,"data-quality":0.1086619239,"ml-security":0.0463888531}}
{"text":"Wireless communication is enabling billions of people to connect to each other and the internet, transforming every sector of the economy, and building the foundations for powerful new technologies that hold great promise to improve lives at an unprecedented rate and scale.","meta":{"url":"http://arxiv.org/abs/2307.14186v1"},"cats":{"new-dataset":0.0461777621,"dev-research":0.2842047659,"prompt-eng":0.3026295984,"data-quality":0.0726776297,"ml-security":0.1116672763}}
{"text":"The rapid increase in the number of devices and the associated demands for higher data rates and broader network coverage fuels the need for more robust wireless technologies.","meta":{"url":"http://arxiv.org/abs/2307.14186v1"},"cats":{"new-dataset":0.0505723196,"dev-research":0.2870477443,"prompt-eng":0.4146502479,"data-quality":0.1261417805,"ml-security":0.1493185644}}
{"text":"The key technology identified to address this problem is referred to as Cell-Free Massive MIMO (CF-mMIMO).","meta":{"url":"http://arxiv.org/abs/2307.14186v1"},"cats":{"new-dataset":0.0581292907,"dev-research":0.177862392,"prompt-eng":0.3505963862,"data-quality":0.0692507938,"ml-security":0.0794226088}}
{"text":"CF-mMIMO is accompanied by many challenges, one of which is efficiently allocating limited resources.","meta":{"url":"http://arxiv.org/abs/2307.14186v1"},"cats":{"new-dataset":0.0880645777,"dev-research":0.2991982536,"prompt-eng":0.3868531501,"data-quality":0.1136819899,"ml-security":0.0916033225}}
{"text":"In this paper, we focus on a major resource allocation problem in wireless networks, namely the Pilot Assignment problem (PA).","meta":{"url":"http://arxiv.org/abs/2307.14186v1"},"cats":{"new-dataset":0.0504350978,"dev-research":0.2619470923,"prompt-eng":0.392002766,"data-quality":0.1471225482,"ml-security":0.1294990425}}
{"text":"We show that PA is strongly NP-hard and that it does not admit a polynomial-time constant-factor approximation algorithm.","meta":{"url":"http://arxiv.org/abs/2307.14186v1"},"cats":{"new-dataset":0.1006658429,"dev-research":0.163966697,"prompt-eng":0.3553360324,"data-quality":0.1357354964,"ml-security":0.0870537145}}
{"text":"Further, we show that PA cannot be approximated in polynomial time within $\\mathcal{O}(K^2)$ (where $K$ is the number of users) when the system consists of at least three pilots.","meta":{"url":"http://arxiv.org/abs/2307.14186v1"},"cats":{"new-dataset":0.1025339136,"dev-research":0.2083221721,"prompt-eng":0.3591753201,"data-quality":0.135582936,"ml-security":0.1557505209}}
{"text":"Finally, we present an approximation lower bound of $1.058$ (resp.","meta":{"url":"http://arxiv.org/abs/2307.14186v1"},"cats":{"new-dataset":0.3332132583,"dev-research":0.1632443787,"prompt-eng":0.3868916388,"data-quality":0.2277957738,"ml-security":0.0884763231}}
{"text":"$\\epsilon|K|^2$, for $\\epsilon >0$) in special cases where the system consists of exactly two (resp.","meta":{"url":"http://arxiv.org/abs/2307.14186v1"},"cats":{"new-dataset":0.1678652698,"dev-research":0.1737519912,"prompt-eng":0.2931791228,"data-quality":0.1968755045,"ml-security":0.206727873}}
{"text":"three) pilots.","meta":{"url":"http://arxiv.org/abs/2307.14186v1"},"cats":{"new-dataset":0.2443474648,"dev-research":0.2187730552,"prompt-eng":0.3638314478,"data-quality":0.1675773424,"ml-security":0.102166057}}
{"text":"Low-lying coastal cities, exemplified by Norfolk, Virginia, face the challenge of street flooding caused by rainfall and tides, which strain transportation and sewer systems and can lead to property damage.","meta":{"url":"http://arxiv.org/abs/2307.14185v1"},"cats":{"new-dataset":0.1450368159,"dev-research":0.2888506143,"prompt-eng":0.3322823231,"data-quality":0.1077432039,"ml-security":0.2333933945}}
{"text":"While high-fidelity, physics-based simulations provide accurate predictions of urban pluvial flooding, their computational complexity renders them unsuitable for real-time applications.","meta":{"url":"http://arxiv.org/abs/2307.14185v1"},"cats":{"new-dataset":0.1140578672,"dev-research":0.2784266586,"prompt-eng":0.3572384341,"data-quality":0.0825240379,"ml-security":0.1211511891}}
{"text":"Using data from Norfolk rainfall events between 2016 and 2018, this study compares the performance of a previous surrogate model based on a random forest algorithm with two deep learning models: Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU).","meta":{"url":"http://arxiv.org/abs/2307.14185v1"},"cats":{"new-dataset":0.27281295,"dev-research":0.1791611501,"prompt-eng":0.3636045442,"data-quality":0.1010362596,"ml-security":0.0967119553}}
{"text":"This investigation underscores the importance of using a model architecture that supports the communication of prediction uncertainty and the effective integration of relevant, multi-modal features.","meta":{"url":"http://arxiv.org/abs/2307.14185v1"},"cats":{"new-dataset":0.0315571616,"dev-research":0.2866537823,"prompt-eng":0.448513076,"data-quality":0.188033232,"ml-security":0.0994873032}}
{"text":"DeepLab is a widely used deep neural network for semantic segmentation, whose success is attributed to its parallel architecture called atrous spatial pyramid pooling (ASPP).","meta":{"url":"http://arxiv.org/abs/2307.14179v1"},"cats":{"new-dataset":0.3723831308,"dev-research":0.2198106543,"prompt-eng":0.3659704062,"data-quality":0.2200613098,"ml-security":0.0981261487}}
{"text":"ASPP uses multiple atrous convolutions with different atrous rates to extract both local and global information.","meta":{"url":"http://arxiv.org/abs/2307.14179v1"},"cats":{"new-dataset":0.158995863,"dev-research":0.1959654682,"prompt-eng":0.3706574807,"data-quality":0.1333455657,"ml-security":0.0746147748}}
{"text":"However, fixed values of atrous rates are used for the ASPP module, which restricts the size of its field of view.","meta":{"url":"http://arxiv.org/abs/2307.14179v1"},"cats":{"new-dataset":0.0653459177,"dev-research":0.1896654758,"prompt-eng":0.3669444119,"data-quality":0.0977213692,"ml-security":0.0766165651}}
{"text":"In principle, atrous rate should be a hyperparameter to change the field of view size according to the target task or dataset.","meta":{"url":"http://arxiv.org/abs/2307.14179v1"},"cats":{"new-dataset":0.0213954725,"dev-research":0.1902005371,"prompt-eng":0.428704125,"data-quality":0.1250971014,"ml-security":0.0742410571}}
{"text":"However, the manipulation of atrous rate is not governed by any guidelines.","meta":{"url":"http://arxiv.org/abs/2307.14179v1"},"cats":{"new-dataset":0.0063794341,"dev-research":0.1814768333,"prompt-eng":0.316656346,"data-quality":0.1562687482,"ml-security":0.1355461215}}
{"text":"This study proposes practical guidelines for obtaining an optimal atrous rate.","meta":{"url":"http://arxiv.org/abs/2307.14179v1"},"cats":{"new-dataset":0.0079715857,"dev-research":0.2129984074,"prompt-eng":0.399107874,"data-quality":0.0803586844,"ml-security":0.0575848534}}
{"text":"First, an effective receptive field for semantic segmentation is introduced to analyze the inner behavior of segmentation networks.","meta":{"url":"http://arxiv.org/abs/2307.14179v1"},"cats":{"new-dataset":0.0721211105,"dev-research":0.2370716157,"prompt-eng":0.4281490221,"data-quality":0.278442082,"ml-security":0.1495016286}}
{"text":"We observed that the use of ASPP module yielded a specific pattern in the effective receptive field, which was traced to reveal the module's underlying mechanism.","meta":{"url":"http://arxiv.org/abs/2307.14179v1"},"cats":{"new-dataset":0.0296958386,"dev-research":0.2596862257,"prompt-eng":0.4496731798,"data-quality":0.1656361637,"ml-security":0.1441269863}}
{"text":"Accordingly, we derive practical guidelines for obtaining the optimal atrous rate, which should be controlled based on the size of input image.","meta":{"url":"http://arxiv.org/abs/2307.14179v1"},"cats":{"new-dataset":0.0415192824,"dev-research":0.1784728618,"prompt-eng":0.4489233145,"data-quality":0.1051150526,"ml-security":0.0516837117}}
{"text":"Compared to other values, using the optimal atrous rate consistently improved the segmentation results across multiple datasets, including the STARE, CHASE_DB1, HRF, Cityscapes, and iSAID datasets.","meta":{"url":"http://arxiv.org/abs/2307.14179v1"},"cats":{"new-dataset":0.4681647501,"dev-research":0.1626756363,"prompt-eng":0.3931878026,"data-quality":0.2182327652,"ml-security":0.0522003483}}
{"text":"In this paper we have addressed the implementation of the accumulation and projection of high-resolution event data stream (HD -1280 x 720 pixels) onto the image plane in FPGA devices.","meta":{"url":"http://arxiv.org/abs/2307.14177v1"},"cats":{"new-dataset":0.4744969992,"dev-research":0.2575074474,"prompt-eng":0.3948887307,"data-quality":0.0851995494,"ml-security":0.0668942936}}
{"text":"The results confirm the feasibility of this approach, but there are a number of challenges, limitations and trade-offs to be considered.","meta":{"url":"http://arxiv.org/abs/2307.14177v1"},"cats":{"new-dataset":0.0204233199,"dev-research":0.1850678148,"prompt-eng":0.4060844337,"data-quality":0.1519150968,"ml-security":0.0998699329}}
{"text":"The required hardware resources of selected data representations, such as binary frame, event frame, exponentially decaying time surface and event frequency, were compared with those available on several popular platforms from AMD Xilinx.","meta":{"url":"http://arxiv.org/abs/2307.14177v1"},"cats":{"new-dataset":0.2467466156,"dev-research":0.2590285408,"prompt-eng":0.4000887918,"data-quality":0.0678008797,"ml-security":0.0504414114}}
{"text":"The resulting event frames can be used for typical vision algorithms, such as object classification and detection, using both classical and deep neural network methods.","meta":{"url":"http://arxiv.org/abs/2307.14177v1"},"cats":{"new-dataset":0.1757825788,"dev-research":0.2000427895,"prompt-eng":0.3954800136,"data-quality":0.2122904926,"ml-security":0.1028192067}}
{"text":"$\\text{TT}^{\\Box}_{{\\mathcal C}}$ is a generic family of effectful, extensional type theories with a forcing interpretation parameterized by modalities.","meta":{"url":"http://arxiv.org/abs/2307.14168v1"},"cats":{"new-dataset":0.0675453323,"dev-research":0.2106804461,"prompt-eng":0.379779737,"data-quality":0.1071174711,"ml-security":0.1436283478}}
{"text":"This paper identifies a subclass of $\\text{TT}^{\\Box}_{{\\mathcal C}}$ theories that internally realizes continuity principles through stateful computations, such as reference cells.","meta":{"url":"http://arxiv.org/abs/2307.14168v1"},"cats":{"new-dataset":0.1029205004,"dev-research":0.2398159168,"prompt-eng":0.3403728072,"data-quality":0.0979020507,"ml-security":0.1336890505}}
{"text":"The principle of continuity is a seminal property that holds for a number of intuitionistic theories such as System T. Roughly speaking, it states that functions on real numbers only need approximations of these numbers to compute.","meta":{"url":"http://arxiv.org/abs/2307.14168v1"},"cats":{"new-dataset":0.0111163715,"dev-research":0.3157232334,"prompt-eng":0.2700989373,"data-quality":0.0798854342,"ml-security":0.1357977854}}
{"text":"Generally, continuity principles have been justified using semantical arguments, but it is known that the modulus of continuity of functions can be computed using effectful computations such as exceptions or reference cells.","meta":{"url":"http://arxiv.org/abs/2307.14168v1"},"cats":{"new-dataset":0.0304302662,"dev-research":0.374787763,"prompt-eng":0.3280360437,"data-quality":0.1446039626,"ml-security":0.0980862449}}
{"text":"In this paper, the modulus of continuity of the functionals on the Baire space is directly computed using the stateful computations enabled internally in the theory.","meta":{"url":"http://arxiv.org/abs/2307.14168v1"},"cats":{"new-dataset":0.0968778587,"dev-research":0.2261963801,"prompt-eng":0.3504944043,"data-quality":0.1611794262,"ml-security":0.0835843915}}
{"text":"The control of free-floating robots requires dealing with several challenges.","meta":{"url":"http://arxiv.org/abs/2307.14164v1"},"cats":{"new-dataset":0.0584497412,"dev-research":0.3032580759,"prompt-eng":0.3780567022,"data-quality":0.0815820693,"ml-security":0.1114546071}}
{"text":"The motion of such robots evolves on a continuous manifold described by the Special Euclidean Group of dimension 3, known as SE(3).","meta":{"url":"http://arxiv.org/abs/2307.14164v1"},"cats":{"new-dataset":0.2121597298,"dev-research":0.1408300726,"prompt-eng":0.3082360699,"data-quality":0.0536509011,"ml-security":0.0829496987}}
{"text":"Methods from finite horizon Linear Quadratic Regulators (LQR) control have gained recent traction in the robotics community.","meta":{"url":"http://arxiv.org/abs/2307.14164v1"},"cats":{"new-dataset":0.0383020842,"dev-research":0.2335895879,"prompt-eng":0.3650362794,"data-quality":0.0584889818,"ml-security":0.0816226193}}
{"text":"However, such approaches are inherently solving an unconstrained optimization problem and hence are unable to respect the manifold constraints imposed by the group structure of SE(3).","meta":{"url":"http://arxiv.org/abs/2307.14164v1"},"cats":{"new-dataset":0.0463305289,"dev-research":0.1626456903,"prompt-eng":0.2965119739,"data-quality":0.1351525194,"ml-security":0.1004758091}}
{"text":"This may lead to small errors, singularity problems and double cover issues depending on the choice of coordinates to model the floating base motion.","meta":{"url":"http://arxiv.org/abs/2307.14164v1"},"cats":{"new-dataset":0.0102722883,"dev-research":0.220158482,"prompt-eng":0.3623286604,"data-quality":0.2002658579,"ml-security":0.1177005522}}
{"text":"In this paper, we propose the use of canonical exponential coordinates of SE(3) and the associated Exponential map along with its differentials to embed this structure in the theory of finite horizon LQR controllers.","meta":{"url":"http://arxiv.org/abs/2307.14164v1"},"cats":{"new-dataset":0.0644632204,"dev-research":0.1900318443,"prompt-eng":0.3510694531,"data-quality":0.0453878168,"ml-security":0.1303743104}}
{"text":"We propose a new method to quantify the impact of cyber attacks in Cyber Physical Systems (CPSs).","meta":{"url":"http://arxiv.org/abs/2307.14161v1"},"cats":{"new-dataset":0.0501579676,"dev-research":0.367748775,"prompt-eng":0.3691952238,"data-quality":0.1410022738,"ml-security":0.4956022674}}
{"text":"In particular, our method allows to identify the Design Parameter (DPs) affected due to a cyber attack launched on a different set of DPs in the same CPS.","meta":{"url":"http://arxiv.org/abs/2307.14161v1"},"cats":{"new-dataset":0.1073287401,"dev-research":0.4393479667,"prompt-eng":0.5225300248,"data-quality":0.2026005679,"ml-security":0.3260916192}}
{"text":"To achieve this, we adopt causal graphs to causally link DPs with each other and quantify the impact of one DP on another.","meta":{"url":"http://arxiv.org/abs/2307.14161v1"},"cats":{"new-dataset":0.1367370269,"dev-research":0.3626536446,"prompt-eng":0.4428430538,"data-quality":0.24620153,"ml-security":0.1867239911}}
{"text":"Using SWaT, a real world testbed of a water treatment system, we demonstrate that causal graphs can be build in two ways: i) using domain knowledge of the control logic and the physical connectivity structure of the DPs, we call these causal domain graphs and ii) learning from operational data logs, we call these causal learnt graphs.","meta":{"url":"http://arxiv.org/abs/2307.14161v1"},"cats":{"new-dataset":0.2565553007,"dev-research":0.365104385,"prompt-eng":0.42353314,"data-quality":0.166133454,"ml-security":0.1419057661}}
{"text":"We then compare these graphs when a same set of DPs is used.","meta":{"url":"http://arxiv.org/abs/2307.14161v1"},"cats":{"new-dataset":0.1594218294,"dev-research":0.3046017221,"prompt-eng":0.385813137,"data-quality":0.2336775019,"ml-security":0.0878832804}}
{"text":"Our analysis shows a common set of edges between the causal domain graphs and the causal learnt graphs exists, which helps validate the causal learnt graphs.","meta":{"url":"http://arxiv.org/abs/2307.14161v1"},"cats":{"new-dataset":0.1294666398,"dev-research":0.3327704524,"prompt-eng":0.3634685051,"data-quality":0.2733378697,"ml-security":0.1767791234}}
{"text":"Additionally, we show that the learnt graphs can discover new causal relations, not initially considered in the domain graphs, that help significantly characterising the impact of the attack.","meta":{"url":"http://arxiv.org/abs/2307.14161v1"},"cats":{"new-dataset":0.1145964884,"dev-research":0.3580475448,"prompt-eng":0.3477175656,"data-quality":0.2754414912,"ml-security":0.5815812247}}
{"text":"We use causal domain graphs to estimate the parameters of the graphs, and the causal learnt graphs for causal inference.","meta":{"url":"http://arxiv.org/abs/2307.14161v1"},"cats":{"new-dataset":0.1238424116,"dev-research":0.288872497,"prompt-eng":0.3682453601,"data-quality":0.226139571,"ml-security":0.1588872909}}
{"text":"To learn the structure of the causal learnt graphs in all the six-stages of SWaT, we experiment with three learning algorithms: Peter Clarke (PC), Hill Climb (HC) search and Chow-Lie (CH).","meta":{"url":"http://arxiv.org/abs/2307.14161v1"},"cats":{"new-dataset":0.1670237291,"dev-research":0.2507007598,"prompt-eng":0.3606344254,"data-quality":0.2058479083,"ml-security":0.1505688284}}
{"text":"Finally, we demonstrate how causal graphs can be used to analyse the impact of cyber attacks by analysing nine well known cyber attacks on the SWaT test bed.","meta":{"url":"http://arxiv.org/abs/2307.14161v1"},"cats":{"new-dataset":0.1271189313,"dev-research":0.3779519159,"prompt-eng":0.3987966174,"data-quality":0.2018344974,"ml-security":0.6140621564}}
{"text":"We find that by using causal learnt graphs the DPs impacted by the attacks are correctly discovered with a probability greater than 0.9.","meta":{"url":"http://arxiv.org/abs/2307.14161v1"},"cats":{"new-dataset":0.1076017783,"dev-research":0.3498465778,"prompt-eng":0.3851654342,"data-quality":0.3551125634,"ml-security":0.7100799156}}
{"text":"The advent of 5G New Radio (NR) technology has revolutionized the landscape of wireless communication, offering various enhancements such as elevated system capacity, improved spectrum efficiency, and higher data transmission rates.","meta":{"url":"http://arxiv.org/abs/2307.14152v1"},"cats":{"new-dataset":0.0461924993,"dev-research":0.260329155,"prompt-eng":0.3406874293,"data-quality":0.0856748822,"ml-security":0.04825346}}
{"text":"To achieve these benefits, 5G has implemented the Ultra-Dense Network (UDN) architecture, characterized by the deployment of numerous small general Node B (gNB) units.","meta":{"url":"http://arxiv.org/abs/2307.14152v1"},"cats":{"new-dataset":0.0974413478,"dev-research":0.2022895205,"prompt-eng":0.2904498096,"data-quality":0.0984086377,"ml-security":0.1112733698}}
{"text":"While this approach boosts system capacity and frequency reuse, it also raises concerns such as increased signal interference, longer handover times, and higher handover failure rates.","meta":{"url":"http://arxiv.org/abs/2307.14152v1"},"cats":{"new-dataset":0.0052867046,"dev-research":0.3787648016,"prompt-eng":0.3891213797,"data-quality":0.1575355589,"ml-security":0.1533239483}}
{"text":"To address these challenges, the critical factor of Time to Trigger (TTT) in handover management must be accurately determined.","meta":{"url":"http://arxiv.org/abs/2307.14152v1"},"cats":{"new-dataset":0.0477373711,"dev-research":0.2996988297,"prompt-eng":0.4700441626,"data-quality":0.1186793418,"ml-security":0.1012511145}}
{"text":"Furthermore, the density of gNBs has a significant impact on handover performance.","meta":{"url":"http://arxiv.org/abs/2307.14152v1"},"cats":{"new-dataset":0.0381497486,"dev-research":0.17385668,"prompt-eng":0.3175058776,"data-quality":0.0912203297,"ml-security":0.0811732752}}
{"text":"This study provides a comprehensive analysis of 5G handover management.","meta":{"url":"http://arxiv.org/abs/2307.14152v1"},"cats":{"new-dataset":0.0747625386,"dev-research":0.2235312208,"prompt-eng":0.3501803595,"data-quality":0.0797258155,"ml-security":0.0549270341}}
{"text":"Through the development and utilization of a downlink system-level simulator, the effects of various TTT values and gNB densities on 5G handover were evaluated, taking into consideration the movement of Traffic Users (TUs) with varying velocities.","meta":{"url":"http://arxiv.org/abs/2307.14152v1"},"cats":{"new-dataset":0.045755949,"dev-research":0.2244091671,"prompt-eng":0.367020058,"data-quality":0.0687476306,"ml-security":0.0779434669}}
{"text":"Simulation results showed that the handover performance can be optimized by adjusting the TTT under different gNB densities, providing valuable insights into the proper selection of TTT, UDN, and TU velocity to enhance 5G handover performance.","meta":{"url":"http://arxiv.org/abs/2307.14152v1"},"cats":{"new-dataset":0.0401130783,"dev-research":0.228089295,"prompt-eng":0.3604859305,"data-quality":0.0770502019,"ml-security":0.062273456}}
{"text":"Recent successes in image generation, model-based reinforcement learning, and text-to-image generation have demonstrated the empirical advantages of discrete latent representations, although the reasons behind their benefits remain unclear.","meta":{"url":"http://arxiv.org/abs/2307.14151v1"},"cats":{"new-dataset":0.0618718933,"dev-research":0.2069364055,"prompt-eng":0.3846422877,"data-quality":0.1330006311,"ml-security":0.0742155579}}
{"text":"We explore the relationship between discrete latent spaces and disentangled representations by replacing the standard Gaussian variational autoencoder (VAE) with a tailored categorical variational autoencoder.","meta":{"url":"http://arxiv.org/abs/2307.14151v1"},"cats":{"new-dataset":0.0533501607,"dev-research":0.162135018,"prompt-eng":0.3325844458,"data-quality":0.1280276303,"ml-security":0.0958973259}}
{"text":"We show that the underlying grid structure of categorical distributions mitigates the problem of rotational invariance associated with multivariate Gaussian distributions, acting as an efficient inductive prior for disentangled representations.","meta":{"url":"http://arxiv.org/abs/2307.14151v1"},"cats":{"new-dataset":0.1072760697,"dev-research":0.1647587526,"prompt-eng":0.3565708262,"data-quality":0.1739390685,"ml-security":0.1491767445}}
{"text":"We provide both analytical and empirical findings that demonstrate the advantages of discrete VAEs for learning disentangled representations.","meta":{"url":"http://arxiv.org/abs/2307.14151v1"},"cats":{"new-dataset":0.0210916013,"dev-research":0.1924566392,"prompt-eng":0.3186439251,"data-quality":0.1637463062,"ml-security":0.1379702704}}
{"text":"Furthermore, we introduce the first unsupervised model selection strategy that favors disentangled representations.","meta":{"url":"http://arxiv.org/abs/2307.14151v1"},"cats":{"new-dataset":0.0162297426,"dev-research":0.1630628518,"prompt-eng":0.3748570172,"data-quality":0.1343577703,"ml-security":0.146405511}}
{"text":"We provide a critical assessment of the current set of benchmarks for relative SRS termination in the Termination Problems Database (TPDB): most of the benchmarks in Waldmann_19 and ICFP_10_relative are, in fact, strictly terminating (i. e., terminating when non-strict rules are considered strict), so these benchmarks should be removed, or relabelled.   ","meta":{"url":"http://arxiv.org/abs/2307.14149v1"},"cats":{"new-dataset":0.0893583633,"dev-research":0.3014805229,"prompt-eng":0.4182315086,"data-quality":0.2948213207,"ml-security":0.106705238}}
{"text":"To fill this gap, we enumerate small relative string rewrite systems.","meta":{"url":"http://arxiv.org/abs/2307.14149v1"},"cats":{"new-dataset":0.2508782177,"dev-research":0.2596981783,"prompt-eng":0.4343662402,"data-quality":0.2698712096,"ml-security":0.115106734}}
{"text":"At present, we have complete enumerations for a 2-letter alphabet up to size 11, and for a 3-letter alphabet up to size 8.   ","meta":{"url":"http://arxiv.org/abs/2307.14149v1"},"cats":{"new-dataset":0.4163138757,"dev-research":0.1719123709,"prompt-eng":0.4027531084,"data-quality":0.101950235,"ml-security":0.0554841237}}
{"text":"For some selected benchmarks, old and new, we discuss how to prove termination, automated or not.","meta":{"url":"http://arxiv.org/abs/2307.14149v1"},"cats":{"new-dataset":0.0780924022,"dev-research":0.3759504659,"prompt-eng":0.4776706377,"data-quality":0.3006027586,"ml-security":0.1692033725}}
{"text":"This paper focuses on a novel robotic system MorphoLander representing heterogeneous swarm of drones for exploring rough terrain environments.","meta":{"url":"http://arxiv.org/abs/2307.14147v1"},"cats":{"new-dataset":0.0888027567,"dev-research":0.2249732342,"prompt-eng":0.3736998963,"data-quality":0.0576203721,"ml-security":0.0698513666}}
{"text":"The morphogenetic leader drone is capable of landing on uneven terrain, traversing it, and maintaining horizontal position to deploy smaller drones for extensive area exploration.","meta":{"url":"http://arxiv.org/abs/2307.14147v1"},"cats":{"new-dataset":0.1059875577,"dev-research":0.2211154658,"prompt-eng":0.3986580148,"data-quality":0.0535233226,"ml-security":0.0591861395}}
{"text":"After completing their tasks, these drones return and land back on the landing pads of MorphoGear.","meta":{"url":"http://arxiv.org/abs/2307.14147v1"},"cats":{"new-dataset":0.1715925341,"dev-research":0.2292769458,"prompt-eng":0.4148859229,"data-quality":0.106530869,"ml-security":0.0747928314}}
{"text":"The reinforcement learning algorithm was developed for a precise landing of drones on the leader robot that either remains static during their mission or relocates to the new position.","meta":{"url":"http://arxiv.org/abs/2307.14147v1"},"cats":{"new-dataset":0.1118066674,"dev-research":0.2214498524,"prompt-eng":0.3971645429,"data-quality":0.0984961334,"ml-security":0.1397265429}}
{"text":"Several experiments were conducted to evaluate the performance of the developed landing algorithm under both even and uneven terrain conditions.","meta":{"url":"http://arxiv.org/abs/2307.14147v1"},"cats":{"new-dataset":0.0418273713,"dev-research":0.2582037874,"prompt-eng":0.4175794968,"data-quality":0.0745461403,"ml-security":0.0448533993}}
{"text":"The experiments revealed that the proposed system results in high landing accuracy of 0.5 cm when landing on the leader drone under even terrain conditions and 2.35 cm under uneven terrain conditions.","meta":{"url":"http://arxiv.org/abs/2307.14147v1"},"cats":{"new-dataset":0.1050741075,"dev-research":0.2122093932,"prompt-eng":0.4090132844,"data-quality":0.1275601378,"ml-security":0.0805726286}}
{"text":"MorphoLander has the potential to significantly enhance the efficiency of the industrial inspections, seismic surveys, and rescue missions in highly cluttered and unstructured environments.","meta":{"url":"http://arxiv.org/abs/2307.14147v1"},"cats":{"new-dataset":0.2568915347,"dev-research":0.260750177,"prompt-eng":0.4185415052,"data-quality":0.0800654605,"ml-security":0.0720325773}}
{"text":"Visual question answering (VQA) has been intensively studied as a multimodal task that requires effort in bridging vision and language to infer answers correctly.","meta":{"url":"http://arxiv.org/abs/2307.14142v1"},"cats":{"new-dataset":0.1546192062,"dev-research":0.3182604015,"prompt-eng":0.4145330441,"data-quality":0.1934010118,"ml-security":0.0721060632}}
{"text":"Recent attempts have developed various attention-based modules for solving VQA tasks.","meta":{"url":"http://arxiv.org/abs/2307.14142v1"},"cats":{"new-dataset":0.0770409547,"dev-research":0.2665464739,"prompt-eng":0.4417752263,"data-quality":0.1317550536,"ml-security":0.0422086864}}
{"text":"However, the performance of model inference is largely bottlenecked by visual processing for semantics understanding.","meta":{"url":"http://arxiv.org/abs/2307.14142v1"},"cats":{"new-dataset":0.0364289903,"dev-research":0.3339770045,"prompt-eng":0.3645770014,"data-quality":0.1801341042,"ml-security":0.1205206545}}
{"text":"Most existing detection methods rely on bounding boxes, remaining a serious challenge for VQA models to understand the causal nexus of object semantics in images and correctly infer contextual information.","meta":{"url":"http://arxiv.org/abs/2307.14142v1"},"cats":{"new-dataset":0.0792107594,"dev-research":0.2009182018,"prompt-eng":0.3850123231,"data-quality":0.3593448438,"ml-security":0.1759702302}}
{"text":"To this end, we propose a finer model framework without bounding boxes in this work, termed Looking Out of Instance Semantics (LOIS) to tackle this important issue.","meta":{"url":"http://arxiv.org/abs/2307.14142v1"},"cats":{"new-dataset":0.1372009009,"dev-research":0.260394935,"prompt-eng":0.4095305371,"data-quality":0.2514161172,"ml-security":0.1571412049}}
{"text":"LOIS enables more fine-grained feature descriptions to produce visual facts.","meta":{"url":"http://arxiv.org/abs/2307.14142v1"},"cats":{"new-dataset":0.3198492877,"dev-research":0.4044477738,"prompt-eng":0.3984387003,"data-quality":0.2298771581,"ml-security":0.0730568445}}
{"text":"Furthermore, to overcome the label ambiguity caused by instance masks, two types of relation attention modules: 1) intra-modality and 2) inter-modality, are devised to infer the correct answers from the different multi-view features.","meta":{"url":"http://arxiv.org/abs/2307.14142v1"},"cats":{"new-dataset":0.0576441201,"dev-research":0.280871376,"prompt-eng":0.4267665155,"data-quality":0.2875716676,"ml-security":0.0803618293}}
{"text":"Specifically, we implement a mutual relation attention module to model sophisticated and deeper visual semantic relations between instance objects and background information.","meta":{"url":"http://arxiv.org/abs/2307.14142v1"},"cats":{"new-dataset":0.2665407557,"dev-research":0.264797745,"prompt-eng":0.4166884004,"data-quality":0.1731071062,"ml-security":0.0766619138}}
{"text":"In addition, our proposed attention model can further analyze salient image regions by focusing on important word-related questions.","meta":{"url":"http://arxiv.org/abs/2307.14142v1"},"cats":{"new-dataset":0.1574919393,"dev-research":0.2258607504,"prompt-eng":0.4377942868,"data-quality":0.2318867609,"ml-security":0.0433961873}}
{"text":"Experimental results on four benchmark VQA datasets prove that our proposed method has favorable performance in improving visual reasoning capability.","meta":{"url":"http://arxiv.org/abs/2307.14142v1"},"cats":{"new-dataset":0.3848445651,"dev-research":0.3372039472,"prompt-eng":0.3823878149,"data-quality":0.189852921,"ml-security":0.0673586959}}
{"text":"We study the piecewise stationary combinatorial semi-bandit problem with causally related rewards.","meta":{"url":"http://arxiv.org/abs/2307.14138v1"},"cats":{"new-dataset":0.0881646133,"dev-research":0.1664920006,"prompt-eng":0.3732817046,"data-quality":0.1611009418,"ml-security":0.1455733583}}
{"text":"In our nonstationary environment, variations in the base arms' distributions, causal relationships between rewards, or both, change the reward generation process.","meta":{"url":"http://arxiv.org/abs/2307.14138v1"},"cats":{"new-dataset":0.0311997799,"dev-research":0.2193805221,"prompt-eng":0.3872991427,"data-quality":0.1274363163,"ml-security":0.1424589341}}
{"text":"In such an environment, an optimal decision-maker must follow both sources of change and adapt accordingly.","meta":{"url":"http://arxiv.org/abs/2307.14138v1"},"cats":{"new-dataset":0.0191196989,"dev-research":0.3261563505,"prompt-eng":0.3860265016,"data-quality":0.1277723552,"ml-security":0.1218334882}}
{"text":"The problem becomes aggravated in the combinatorial semi-bandit setting, where the decision-maker only observes the outcome of the selected bundle of arms.","meta":{"url":"http://arxiv.org/abs/2307.14138v1"},"cats":{"new-dataset":0.0497112022,"dev-research":0.2535081222,"prompt-eng":0.356399213,"data-quality":0.2599260286,"ml-security":0.2088660535}}
{"text":"The core of our proposed policy is the Upper Confidence Bound (UCB) algorithm.","meta":{"url":"http://arxiv.org/abs/2307.14138v1"},"cats":{"new-dataset":0.0964572429,"dev-research":0.1940100991,"prompt-eng":0.4608602186,"data-quality":0.1573146019,"ml-security":0.1503438562}}
{"text":"We assume the agent relies on an adaptive approach to overcome the challenge.","meta":{"url":"http://arxiv.org/abs/2307.14138v1"},"cats":{"new-dataset":0.0219328984,"dev-research":0.2829921063,"prompt-eng":0.4021994362,"data-quality":0.1335048656,"ml-security":0.2196341868}}
{"text":"More specifically, it employs a change-point detector based on the Generalized Likelihood Ratio (GLR) test.","meta":{"url":"http://arxiv.org/abs/2307.14138v1"},"cats":{"new-dataset":0.0754910236,"dev-research":0.1753102598,"prompt-eng":0.507211149,"data-quality":0.2188540132,"ml-security":0.102300337}}
{"text":"Besides, we introduce the notion of group restart as a new alternative restarting strategy in the decision making process in structured environments.","meta":{"url":"http://arxiv.org/abs/2307.14138v1"},"cats":{"new-dataset":0.147415742,"dev-research":0.4113605918,"prompt-eng":0.4829419152,"data-quality":0.1326612638,"ml-security":0.0651869411}}
{"text":"Finally, our algorithm integrates a mechanism to trace the variations of the underlying graph structure, which captures the causal relationships between the rewards in the bandit setting.","meta":{"url":"http://arxiv.org/abs/2307.14138v1"},"cats":{"new-dataset":0.0709290899,"dev-research":0.260613158,"prompt-eng":0.3945126777,"data-quality":0.1921291074,"ml-security":0.1703498691}}
{"text":"Theoretically, we establish a regret upper bound that reflects the effects of the number of structural- and distribution changes on the performance.","meta":{"url":"http://arxiv.org/abs/2307.14138v1"},"cats":{"new-dataset":0.0215438927,"dev-research":0.1814533999,"prompt-eng":0.4119394713,"data-quality":0.1560556158,"ml-security":0.167007696}}
{"text":"The outcome of our numerical experiments in real-world scenarios exhibits applicability and superior performance of our proposal compared to the state-of-the-art benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.14138v1"},"cats":{"new-dataset":0.1358658176,"dev-research":0.180731858,"prompt-eng":0.3934841917,"data-quality":0.1008378897,"ml-security":0.0684115997}}
{"text":"This study introduces and evaluates tiny, mini, small, and medium-sized uncased Turkish BERT models, aiming to bridge the research gap in less-resourced languages.","meta":{"url":"http://arxiv.org/abs/2307.14134v1"},"cats":{"new-dataset":0.1847693416,"dev-research":0.2199933835,"prompt-eng":0.3896141405,"data-quality":0.1924053539,"ml-security":0.0945964602}}
{"text":"We trained these models on a diverse dataset encompassing over 75GB of text from multiple sources and tested them on several tasks, including mask prediction, sentiment analysis, news classification, and, zero-shot classification.","meta":{"url":"http://arxiv.org/abs/2307.14134v1"},"cats":{"new-dataset":0.481516515,"dev-research":0.1755889093,"prompt-eng":0.3214866343,"data-quality":0.3231560116,"ml-security":0.2125113001}}
{"text":"Despite their smaller size, our models exhibited robust performance, including zero-shot task, while ensuring computational efficiency and faster execution times.","meta":{"url":"http://arxiv.org/abs/2307.14134v1"},"cats":{"new-dataset":0.1613736826,"dev-research":0.2326716437,"prompt-eng":0.4431419245,"data-quality":0.1998688835,"ml-security":0.1140835656}}
{"text":"Our findings provide valuable insights into the development and application of smaller language models, especially in the context of the Turkish language.","meta":{"url":"http://arxiv.org/abs/2307.14134v1"},"cats":{"new-dataset":0.0968104775,"dev-research":0.225836929,"prompt-eng":0.3639930911,"data-quality":0.2250215047,"ml-security":0.0796208021}}
{"text":"RNN-T models are widely used in ASR, which rely on the RNN-T loss to achieve length alignment between input audio and target sequence.","meta":{"url":"http://arxiv.org/abs/2307.14132v1"},"cats":{"new-dataset":0.1038073287,"dev-research":0.1970416703,"prompt-eng":0.373832865,"data-quality":0.1654544397,"ml-security":0.0665212924}}
{"text":"However, the implementation complexity and the alignment-based optimization target of RNN-T loss lead to computational redundancy and a reduced role for predictor network, respectively.","meta":{"url":"http://arxiv.org/abs/2307.14132v1"},"cats":{"new-dataset":0.0467411813,"dev-research":0.2351164937,"prompt-eng":0.3388765626,"data-quality":0.1451780902,"ml-security":0.1183319258}}
{"text":"In this paper, we propose a novel model named CIF-Transducer (CIF-T) which incorporates the Continuous Integrate-and-Fire (CIF) mechanism with the RNN-T model to achieve efficient alignment.","meta":{"url":"http://arxiv.org/abs/2307.14132v1"},"cats":{"new-dataset":0.1718034377,"dev-research":0.2201484859,"prompt-eng":0.4267933963,"data-quality":0.1622302677,"ml-security":0.0274273363}}
{"text":"In this way, the RNN-T loss is abandoned, thus bringing a computational reduction and allowing the predictor network a more significant role.","meta":{"url":"http://arxiv.org/abs/2307.14132v1"},"cats":{"new-dataset":0.0740566667,"dev-research":0.1986105093,"prompt-eng":0.3276093598,"data-quality":0.1608608259,"ml-security":0.1742765426}}
{"text":"We also introduce Funnel-CIF, Context Blocks, Unified Gating and Bilinear Pooling joint network, and auxiliary training strategy to further improve performance.","meta":{"url":"http://arxiv.org/abs/2307.14132v1"},"cats":{"new-dataset":0.1322852202,"dev-research":0.2104336862,"prompt-eng":0.375419651,"data-quality":0.2158551521,"ml-security":0.0644601371}}
{"text":"Experiments on the 178-hour AISHELL-1 and 10000-hour WenetSpeech datasets show that CIF-T achieves state-of-the-art results with lower computational overhead compared to RNN-T models.","meta":{"url":"http://arxiv.org/abs/2307.14132v1"},"cats":{"new-dataset":0.4479306147,"dev-research":0.178003243,"prompt-eng":0.3656302492,"data-quality":0.0901611714,"ml-security":0.054939284}}
{"text":"In this paper, we propose a novel method for single-view 3D style transfer that generates a unique 3D object with both shape and texture transfer.","meta":{"url":"http://arxiv.org/abs/2307.14127v1"},"cats":{"new-dataset":0.0516076752,"dev-research":0.2444921334,"prompt-eng":0.3660973875,"data-quality":0.0934096585,"ml-security":0.0822300409}}
{"text":"Our focus lies primarily on birds, a popular subject in 3D reconstruction, for which no existing single-view 3D transfer methods have been developed.","meta":{"url":"http://arxiv.org/abs/2307.14127v1"},"cats":{"new-dataset":0.2305941254,"dev-research":0.1392257742,"prompt-eng":0.3241854626,"data-quality":0.0688975619,"ml-security":0.0614272158}}
{"text":"The method we propose seeks to generate a 3D mesh shape and texture of a bird from two single-view images.","meta":{"url":"http://arxiv.org/abs/2307.14127v1"},"cats":{"new-dataset":0.1844255794,"dev-research":0.1786457846,"prompt-eng":0.3838255621,"data-quality":0.0741416549,"ml-security":0.0508475265}}
{"text":"To achieve this, we introduce a novel shape transfer generator that comprises a dual residual gated network (DRGNet), and a multi-layer perceptron (MLP).","meta":{"url":"http://arxiv.org/abs/2307.14127v1"},"cats":{"new-dataset":0.0775208062,"dev-research":0.2209268375,"prompt-eng":0.3769670855,"data-quality":0.1221380597,"ml-security":0.0860190484}}
{"text":"DRGNet extracts the features of source and target images using a shared coordinate gate unit, while the MLP generates spatial coordinates for building a 3D mesh.","meta":{"url":"http://arxiv.org/abs/2307.14127v1"},"cats":{"new-dataset":0.1452185284,"dev-research":0.2746605267,"prompt-eng":0.4027666631,"data-quality":0.1076209298,"ml-security":0.1030267691}}
{"text":"We also introduce a semantic UV texture transfer module that implements textural style transfer using semantic UV segmentation, which ensures consistency in the semantic meaning of the transferred regions.","meta":{"url":"http://arxiv.org/abs/2307.14127v1"},"cats":{"new-dataset":0.1651540262,"dev-research":0.290098318,"prompt-eng":0.3927093249,"data-quality":0.209927796,"ml-security":0.0732318103}}
{"text":"This module can be widely adapted to many existing approaches.","meta":{"url":"http://arxiv.org/abs/2307.14127v1"},"cats":{"new-dataset":0.1391473041,"dev-research":0.2469329279,"prompt-eng":0.436059043,"data-quality":0.0899690774,"ml-security":0.0470680994}}
{"text":"Finally, our method constructs a novel 3D bird using a differentiable renderer.","meta":{"url":"http://arxiv.org/abs/2307.14127v1"},"cats":{"new-dataset":0.237346296,"dev-research":0.197419023,"prompt-eng":0.3917390796,"data-quality":0.0787690152,"ml-security":0.0515317612}}
{"text":"Experimental results on the CUB dataset verify that our method achieves state-of-the-art performance on the single-view 3D style transfer task.","meta":{"url":"http://arxiv.org/abs/2307.14127v1"},"cats":{"new-dataset":0.1570375132,"dev-research":0.2424630789,"prompt-eng":0.3652417559,"data-quality":0.1027743781,"ml-security":0.0508293273}}
{"text":"Code is available in https://github.com/wrk226/2D-to-3D-Evolution-Transfer.","meta":{"url":"http://arxiv.org/abs/2307.14127v1"},"cats":{"new-dataset":0.2282666276,"dev-research":0.1727390563,"prompt-eng":0.3835586508,"data-quality":0.0607377858,"ml-security":0.0412341311}}
{"text":"The missing modality issue is critical but non-trivial to be solved by multi-modal models.","meta":{"url":"http://arxiv.org/abs/2307.14126v1"},"cats":{"new-dataset":0.0590068001,"dev-research":0.1708177505,"prompt-eng":0.358949769,"data-quality":0.3182596445,"ml-security":0.0791652315}}
{"text":"Current methods aiming to handle the missing modality problem in multi-modal tasks, either deal with missing modalities only during evaluation or train separate models to handle specific missing modality settings.","meta":{"url":"http://arxiv.org/abs/2307.14126v1"},"cats":{"new-dataset":0.0422776804,"dev-research":0.2271714672,"prompt-eng":0.4151631723,"data-quality":0.2904265231,"ml-security":0.0645264761}}
{"text":"In addition, these models are designed for specific tasks, so for example, classification models are not easily adapted to segmentation tasks and vice versa.","meta":{"url":"http://arxiv.org/abs/2307.14126v1"},"cats":{"new-dataset":0.0094809306,"dev-research":0.250834011,"prompt-eng":0.3490373205,"data-quality":0.1764979062,"ml-security":0.1362085515}}
{"text":"In this paper, we propose the Shared-Specific Feature Modelling (ShaSpec) method that is considerably simpler and more effective than competing approaches that address the issues above.","meta":{"url":"http://arxiv.org/abs/2307.14126v1"},"cats":{"new-dataset":0.0750889206,"dev-research":0.3813876045,"prompt-eng":0.4651376931,"data-quality":0.1785982989,"ml-security":0.1173806411}}
{"text":"ShaSpec is designed to take advantage of all available input modalities during training and evaluation by learning shared and specific features to better represent the input data.","meta":{"url":"http://arxiv.org/abs/2307.14126v1"},"cats":{"new-dataset":0.1550668114,"dev-research":0.3290037665,"prompt-eng":0.4610526779,"data-quality":0.1272861621,"ml-security":0.1306506763}}
{"text":"This is achieved from a strategy that relies on auxiliary tasks based on distribution alignment and domain classification, in addition to a residual feature fusion procedure.","meta":{"url":"http://arxiv.org/abs/2307.14126v1"},"cats":{"new-dataset":0.1428004132,"dev-research":0.2140657886,"prompt-eng":0.4500027473,"data-quality":0.3143473806,"ml-security":0.0915727587}}
{"text":"Also, the design simplicity of ShaSpec enables its easy adaptation to multiple tasks, such as classification and segmentation.","meta":{"url":"http://arxiv.org/abs/2307.14126v1"},"cats":{"new-dataset":0.0752156947,"dev-research":0.2978191455,"prompt-eng":0.4320207282,"data-quality":0.0960062893,"ml-security":0.0907266137}}
{"text":"Experiments are conducted on both medical image segmentation and computer vision classification, with results indicating that ShaSpec outperforms competing methods by a large margin.","meta":{"url":"http://arxiv.org/abs/2307.14126v1"},"cats":{"new-dataset":0.1289555241,"dev-research":0.1731289416,"prompt-eng":0.4083930606,"data-quality":0.1952641622,"ml-security":0.1119398417}}
{"text":"For instance, on BraTS2018, ShaSpec improves the SOTA by more than 3% for enhancing tumour, 5% for tumour core and 3% for whole tumour.","meta":{"url":"http://arxiv.org/abs/2307.14126v1"},"cats":{"new-dataset":0.0812637469,"dev-research":0.2186135613,"prompt-eng":0.3751626815,"data-quality":0.1047322046,"ml-security":0.104799443}}
{"text":"Algorithms for state estimation of humanoid robots usually assume that the feet remain flat and in a constant position while in contact with the ground.","meta":{"url":"http://arxiv.org/abs/2307.14125v1"},"cats":{"new-dataset":0.3788762475,"dev-research":0.1836281922,"prompt-eng":0.3997685085,"data-quality":0.0956473554,"ml-security":0.0786374369}}
{"text":"However, this hypothesis is easily violated while walking, especially for human-like gaits with heel-toe motion.","meta":{"url":"http://arxiv.org/abs/2307.14125v1"},"cats":{"new-dataset":0.0088609157,"dev-research":0.2563810663,"prompt-eng":0.354908437,"data-quality":0.1954107214,"ml-security":0.2146330307}}
{"text":"This reduces the time during which the contact assumption can be used, or requires higher variances to account for errors.","meta":{"url":"http://arxiv.org/abs/2307.14125v1"},"cats":{"new-dataset":0.0013365505,"dev-research":0.3582036141,"prompt-eng":0.3848802531,"data-quality":0.1333751967,"ml-security":0.1493678324}}
{"text":"In this paper, we present a novel state estimator based on the extended Kalman filter that can properly handle any contact configuration.","meta":{"url":"http://arxiv.org/abs/2307.14125v1"},"cats":{"new-dataset":0.162675861,"dev-research":0.1597994676,"prompt-eng":0.4432436803,"data-quality":0.0866286164,"ml-security":0.0544784186}}
{"text":"We consider multiple inertial measurement units (IMUs) distributed throughout the robot's structure, including on both feet, which are used to track multiple bodies of the robot.","meta":{"url":"http://arxiv.org/abs/2307.14125v1"},"cats":{"new-dataset":0.2479028739,"dev-research":0.214013162,"prompt-eng":0.3815653161,"data-quality":0.0876552701,"ml-security":0.04767621}}
{"text":"This multi-IMU instrumentation setup also has the advantage of allowing the deformations in the robot's structure to be estimated, improving the kinematic model used in the filter.","meta":{"url":"http://arxiv.org/abs/2307.14125v1"},"cats":{"new-dataset":0.1183363397,"dev-research":0.1989330268,"prompt-eng":0.3951967222,"data-quality":0.0680021006,"ml-security":0.0438530946}}
{"text":"The proposed approach is validated experimentally on the exoskeleton Atalante and is shown to present low drift, performing better than similar single-IMU filters.","meta":{"url":"http://arxiv.org/abs/2307.14125v1"},"cats":{"new-dataset":0.0115787571,"dev-research":0.1758556017,"prompt-eng":0.3409724843,"data-quality":0.1143643985,"ml-security":0.1069342883}}
{"text":"The obtained trajectory estimates are accurate enough to construct elevation maps that have little distortion with respect to the ground truth.","meta":{"url":"http://arxiv.org/abs/2307.14125v1"},"cats":{"new-dataset":0.0585994056,"dev-research":0.1694025781,"prompt-eng":0.3453001708,"data-quality":0.1340262589,"ml-security":0.0971577337}}
{"text":"Recent advances in event camera research emphasize processing data in its original sparse form, which allows the use of its unique features such as high temporal resolution, high dynamic range, low latency, and resistance to image blur.","meta":{"url":"http://arxiv.org/abs/2307.14124v1"},"cats":{"new-dataset":0.1265051551,"dev-research":0.2280179091,"prompt-eng":0.372169293,"data-quality":0.1250454663,"ml-security":0.0397353023}}
{"text":"One promising approach for analyzing event data is through graph convolutional networks (GCNs).","meta":{"url":"http://arxiv.org/abs/2307.14124v1"},"cats":{"new-dataset":0.2172795841,"dev-research":0.2690486375,"prompt-eng":0.3255057947,"data-quality":0.2227572524,"ml-security":0.0886904044}}
{"text":"However, current research in this domain primarily focuses on optimizing computational costs, neglecting the associated memory costs.","meta":{"url":"http://arxiv.org/abs/2307.14124v1"},"cats":{"new-dataset":0.0128642915,"dev-research":0.2845127102,"prompt-eng":0.3502875113,"data-quality":0.0977466274,"ml-security":0.0717568549}}
{"text":"In this paper, we consider both factors together in order to achieve satisfying results and relatively low model complexity.","meta":{"url":"http://arxiv.org/abs/2307.14124v1"},"cats":{"new-dataset":0.0457346485,"dev-research":0.1138681754,"prompt-eng":0.3955683879,"data-quality":0.1212470037,"ml-security":0.0561149628}}
{"text":"For this purpose, we performed a comparative analysis of different graph convolution operations, considering factors such as execution time, the number of trainable model parameters, data format requirements, and training outcomes.","meta":{"url":"http://arxiv.org/abs/2307.14124v1"},"cats":{"new-dataset":0.1557313538,"dev-research":0.2285974365,"prompt-eng":0.3391262099,"data-quality":0.1558881441,"ml-security":0.0548971937}}
{"text":"Our results show a 450-fold reduction in the number of parameters for the feature extraction module and a 4.5-fold reduction in the size of the data representation while maintaining a classification accuracy of 52.3%, which is 6.3% higher compared to the operation used in state-of-the-art approaches.","meta":{"url":"http://arxiv.org/abs/2307.14124v1"},"cats":{"new-dataset":0.2371249296,"dev-research":0.2949388141,"prompt-eng":0.4358881977,"data-quality":0.3183397872,"ml-security":0.1098692295}}
{"text":"To further evaluate performance, we implemented the object detection architecture and evaluated its performance on the N-Caltech101 dataset.","meta":{"url":"http://arxiv.org/abs/2307.14124v1"},"cats":{"new-dataset":0.3885857606,"dev-research":0.1922893555,"prompt-eng":0.3894554412,"data-quality":0.2997742339,"ml-security":0.1686746349}}
{"text":"The results showed an accuracy of 53.7 % mAP@0.5 and reached an execution rate of 82 graphs per second.","meta":{"url":"http://arxiv.org/abs/2307.14124v1"},"cats":{"new-dataset":0.1917901197,"dev-research":0.2470310334,"prompt-eng":0.3988833179,"data-quality":0.2249398861,"ml-security":0.0547794843}}
{"text":"Recent work in Machine Learning and Computer Vision has highlighted the presence of various types of systematic flaws inside ground truth object recognition benchmark datasets.","meta":{"url":"http://arxiv.org/abs/2307.14119v1"},"cats":{"new-dataset":0.3327693482,"dev-research":0.1875830217,"prompt-eng":0.3347664068,"data-quality":0.4532970059,"ml-security":0.2947417529}}
{"text":"Our basic tenet is that these flaws are rooted in the many-to-many mappings which exist between the visual information encoded in images and the intended semantics of the labels annotating them.","meta":{"url":"http://arxiv.org/abs/2307.14119v1"},"cats":{"new-dataset":0.1644477222,"dev-research":0.3261861418,"prompt-eng":0.3877941201,"data-quality":0.5723370847,"ml-security":0.198777704}}
{"text":"The net consequence is that the current annotation process is largely under-specified, thus leaving too much freedom to the subjective judgment of annotators.","meta":{"url":"http://arxiv.org/abs/2307.14119v1"},"cats":{"new-dataset":0.0102987048,"dev-research":0.4134030938,"prompt-eng":0.3419286969,"data-quality":0.5904400841,"ml-security":0.2728179711}}
{"text":"In this paper, we propose vTelos, an integrated Natural Language Processing, Knowledge Representation, and Computer Vision methodology whose main goal is to make explicit the (otherwise implicit) intended annotation semantics, thus minimizing the number and role of subjective choices.","meta":{"url":"http://arxiv.org/abs/2307.14119v1"},"cats":{"new-dataset":0.1651369786,"dev-research":0.4139782367,"prompt-eng":0.4477568941,"data-quality":0.3892349975,"ml-security":0.0709772617}}
{"text":"A key element of vTelos is the exploitation of the WordNet lexico-semantic hierarchy as the main means for providing the meaning of natural language labels and, as a consequence, for driving the annotation of images based on the objects and the visual properties they depict.","meta":{"url":"http://arxiv.org/abs/2307.14119v1"},"cats":{"new-dataset":0.2032843583,"dev-research":0.3205845596,"prompt-eng":0.4174280854,"data-quality":0.3152953405,"ml-security":0.0920617662}}
{"text":"The methodology is validated on images populating a subset of the ImageNet hierarchy.","meta":{"url":"http://arxiv.org/abs/2307.14119v1"},"cats":{"new-dataset":0.1827957548,"dev-research":0.2170905392,"prompt-eng":0.4215718307,"data-quality":0.2160924644,"ml-security":0.1267445714}}
{"text":"We study improving social conversational agents by learning from natural dialogue between users and a deployed model, without extra annotations.","meta":{"url":"http://arxiv.org/abs/2307.14117v1"},"cats":{"new-dataset":0.2467754391,"dev-research":0.2868821902,"prompt-eng":0.381447867,"data-quality":0.3074893216,"ml-security":0.1307388221}}
{"text":"To implicitly measure the quality of a machine-generated utterance, we leverage signals like user response length, sentiment and reaction of the future human utterances in the collected dialogue episodes.","meta":{"url":"http://arxiv.org/abs/2307.14117v1"},"cats":{"new-dataset":0.2664912144,"dev-research":0.3327029035,"prompt-eng":0.4259277622,"data-quality":0.3231701622,"ml-security":0.1129613578}}
{"text":"Our experiments use the publicly released deployment data from BlenderBot (Xu et al., 2023).","meta":{"url":"http://arxiv.org/abs/2307.14117v1"},"cats":{"new-dataset":0.5514141113,"dev-research":0.2439819871,"prompt-eng":0.4578367359,"data-quality":0.1460656746,"ml-security":0.0595308139}}
{"text":"Human evaluation indicates improvements in our new models over baseline responses; however, we find that some proxy signals can lead to more generations with undesirable properties as well.","meta":{"url":"http://arxiv.org/abs/2307.14117v1"},"cats":{"new-dataset":0.049199151,"dev-research":0.2215976642,"prompt-eng":0.4715309714,"data-quality":0.1891020821,"ml-security":0.163846395}}
{"text":"For example, optimizing for conversation length can lead to more controversial or unfriendly generations compared to the baseline, whereas optimizing for positive sentiment or reaction can decrease these behaviors.","meta":{"url":"http://arxiv.org/abs/2307.14117v1"},"cats":{"new-dataset":0.0022384377,"dev-research":0.4808870635,"prompt-eng":0.3101958173,"data-quality":0.1569687104,"ml-security":0.0744717603}}
{"text":"Risk assessment plays a crucial role in ensuring the security and resilience of modern computer systems.","meta":{"url":"http://arxiv.org/abs/2307.14114v1"},"cats":{"new-dataset":0.0341486081,"dev-research":0.4261707748,"prompt-eng":0.4503876527,"data-quality":0.1610389922,"ml-security":0.5742192219}}
{"text":"Existing methods for conducting risk assessments often suffer from tedious and time-consuming processes, making it challenging to maintain a comprehensive overview of potential security issues.","meta":{"url":"http://arxiv.org/abs/2307.14114v1"},"cats":{"new-dataset":0.0537446572,"dev-research":0.3704377651,"prompt-eng":0.4724842366,"data-quality":0.1831806922,"ml-security":0.5468245435}}
{"text":"In this paper, we propose a novel approach that leverages attack graphs to enhance the efficiency and effectiveness of risk assessment.","meta":{"url":"http://arxiv.org/abs/2307.14114v1"},"cats":{"new-dataset":0.0839896794,"dev-research":0.3391246274,"prompt-eng":0.4026564022,"data-quality":0.1769545536,"ml-security":0.7298465974}}
{"text":"Attack graphs visually represent the various attack paths that adversaries can exploit within a system, enabling a systematic exploration of potential vulnerabilities.","meta":{"url":"http://arxiv.org/abs/2307.14114v1"},"cats":{"new-dataset":0.1743837188,"dev-research":0.4536740554,"prompt-eng":0.394958993,"data-quality":0.1817309297,"ml-security":0.7367628268}}
{"text":"By extending attack graphs with capabilities to include countermeasures and consequences, they can be leveraged to constitute the complete risk assessment process.","meta":{"url":"http://arxiv.org/abs/2307.14114v1"},"cats":{"new-dataset":0.0980099304,"dev-research":0.3297041705,"prompt-eng":0.3858376333,"data-quality":0.1314351239,"ml-security":0.6155456579}}
{"text":"Our method offers a more streamlined and comprehensive analysis of system vulnerabilities, where system changes, or environment changes can easily be adapted and the issues exposing the highest risk can easily be identified.","meta":{"url":"http://arxiv.org/abs/2307.14114v1"},"cats":{"new-dataset":0.2302892292,"dev-research":0.4846991503,"prompt-eng":0.4245880207,"data-quality":0.2275168821,"ml-security":0.5377464075}}
{"text":"We demonstrate the effectiveness of our approach through a case study, as well as the applicability by combining existing risk assessment standards with our method.","meta":{"url":"http://arxiv.org/abs/2307.14114v1"},"cats":{"new-dataset":0.1022702843,"dev-research":0.3174422643,"prompt-eng":0.4279903327,"data-quality":0.2299953641,"ml-security":0.2844419805}}
{"text":"Our work aims to bridge the gap between risk assessment practices and evolving threat landscapes, offering an improved methodology for managing and mitigating risks in modern computer systems.","meta":{"url":"http://arxiv.org/abs/2307.14114v1"},"cats":{"new-dataset":0.0968936826,"dev-research":0.5050218124,"prompt-eng":0.4496456567,"data-quality":0.2014320938,"ml-security":0.596061608}}
{"text":"Periocular biometrics has been established as an independent modality due to concerns on the performance of iris or face systems in uncontrolled conditions.","meta":{"url":"http://arxiv.org/abs/2307.14111v1"},"cats":{"new-dataset":0.0269717516,"dev-research":0.1895110796,"prompt-eng":0.4037589924,"data-quality":0.0923626189,"ml-security":0.1006757759}}
{"text":"Periocular refers to the facial region in the eye vicinity, including eyelids, lashes and eyebrows.","meta":{"url":"http://arxiv.org/abs/2307.14111v1"},"cats":{"new-dataset":0.03221213,"dev-research":0.2592611916,"prompt-eng":0.3311697092,"data-quality":0.1626581016,"ml-security":0.0733961363}}
{"text":"It is available over a wide range of acquisition distances, representing a trade-off between the whole face (which can be occluded at close distances) and the iris texture (which do not have enough resolution at long distances).","meta":{"url":"http://arxiv.org/abs/2307.14111v1"},"cats":{"new-dataset":0.2835544818,"dev-research":0.1565899916,"prompt-eng":0.3579252077,"data-quality":0.0659599305,"ml-security":0.0509383184}}
{"text":"Since the periocular region appears in face or iris images, it can be used also in conjunction with these modalities.","meta":{"url":"http://arxiv.org/abs/2307.14111v1"},"cats":{"new-dataset":0.021214275,"dev-research":0.1820670223,"prompt-eng":0.374982419,"data-quality":0.0957375613,"ml-security":0.052104046}}
{"text":"Features extracted from the periocular region have been also used successfully for gender classification and ethnicity classification, and to study the impact of gender transformation or plastic surgery in the recognition performance.","meta":{"url":"http://arxiv.org/abs/2307.14111v1"},"cats":{"new-dataset":0.0787700531,"dev-research":0.1784649181,"prompt-eng":0.3660232414,"data-quality":0.2008448113,"ml-security":0.086566021}}
{"text":"This paper presents a review of the state of the art in periocular biometric research, providing an insight of the most relevant issues and giving a thorough coverage of the existing literature.","meta":{"url":"http://arxiv.org/abs/2307.14111v1"},"cats":{"new-dataset":0.0572680848,"dev-research":0.1526940472,"prompt-eng":0.4446962422,"data-quality":0.1493183234,"ml-security":0.0834817346}}
{"text":"Future research trends are also briefly discussed.","meta":{"url":"http://arxiv.org/abs/2307.14111v1"},"cats":{"new-dataset":0.1044638259,"dev-research":0.2214701555,"prompt-eng":0.3442162156,"data-quality":0.0806346955,"ml-security":0.0648814781}}
{"text":"Motion planning is challenging for multiple robots in cluttered environments without communication, especially in view of real-time efficiency, motion safety, distributed computation, and trajectory optimality, etc.","meta":{"url":"http://arxiv.org/abs/2307.14110v1"},"cats":{"new-dataset":0.2013657723,"dev-research":0.2528021763,"prompt-eng":0.3610044741,"data-quality":0.044764387,"ml-security":0.0659621613}}
{"text":"In this paper, a reinforced potential field method is developed for distributed multi-robot motion planning, which is a synthesized design of reinforcement learning and artificial potential fields.","meta":{"url":"http://arxiv.org/abs/2307.14110v1"},"cats":{"new-dataset":0.0675983241,"dev-research":0.2045296532,"prompt-eng":0.3649924967,"data-quality":0.0377398564,"ml-security":0.0740988274}}
{"text":"An observation embedding with a self-attention mechanism is presented to model the robot-robot and robot-environment interactions.","meta":{"url":"http://arxiv.org/abs/2307.14110v1"},"cats":{"new-dataset":0.1408309101,"dev-research":0.2571204993,"prompt-eng":0.4740000932,"data-quality":0.1197891582,"ml-security":0.0810668412}}
{"text":"A soft wall-following rule is developed to improve the trajectory smoothness.","meta":{"url":"http://arxiv.org/abs/2307.14110v1"},"cats":{"new-dataset":0.0283445872,"dev-research":0.2766575519,"prompt-eng":0.3793973413,"data-quality":0.0967657907,"ml-security":0.0716713113}}
{"text":"Our method belongs to reactive planning, but environment properties are implicitly encoded.","meta":{"url":"http://arxiv.org/abs/2307.14110v1"},"cats":{"new-dataset":0.2602144069,"dev-research":0.304147854,"prompt-eng":0.4438294364,"data-quality":0.0821746836,"ml-security":0.0804718306}}
{"text":"The total amount of robots in our method can be scaled up to any number.","meta":{"url":"http://arxiv.org/abs/2307.14110v1"},"cats":{"new-dataset":0.1205641777,"dev-research":0.2023998629,"prompt-eng":0.3816881993,"data-quality":0.0933347914,"ml-security":0.0808400425}}
{"text":"The performance improvement over a vanilla APF and RL method has been demonstrated via numerical simulations.","meta":{"url":"http://arxiv.org/abs/2307.14110v1"},"cats":{"new-dataset":0.0334351124,"dev-research":0.2073725321,"prompt-eng":0.4097714803,"data-quality":0.086522458,"ml-security":0.0244573098}}
{"text":"Experiments are also performed using quadrotors to further illustrate the competence of our method.","meta":{"url":"http://arxiv.org/abs/2307.14110v1"},"cats":{"new-dataset":0.0434270697,"dev-research":0.2078870837,"prompt-eng":0.3964138276,"data-quality":0.0688186586,"ml-security":0.0456871109}}
{"text":"GraphRNN is a deep learning-based architecture proposed by You et al. for learning generative models for graphs.","meta":{"url":"http://arxiv.org/abs/2307.14109v1"},"cats":{"new-dataset":0.3074417092,"dev-research":0.2459897036,"prompt-eng":0.3200290713,"data-quality":0.1418083227,"ml-security":0.0679176082}}
{"text":"We replicate the results of You et al.","meta":{"url":"http://arxiv.org/abs/2307.14109v1"},"cats":{"new-dataset":0.2523266098,"dev-research":0.1969009975,"prompt-eng":0.3391295112,"data-quality":0.1879026808,"ml-security":0.094194621}}
{"text":"using a reproduced implementation of the GraphRNN architecture and evaluate this against baseline models using new metrics.","meta":{"url":"http://arxiv.org/abs/2307.14109v1"},"cats":{"new-dataset":0.2576768165,"dev-research":0.2290718257,"prompt-eng":0.3922679563,"data-quality":0.2114336939,"ml-security":0.0440905389}}
{"text":"Through an ablation study, we find that the BFS traversal suggested by You et al. to collapse representations of isomorphic graphs contributes significantly to model performance.","meta":{"url":"http://arxiv.org/abs/2307.14109v1"},"cats":{"new-dataset":0.0785334259,"dev-research":0.2007810533,"prompt-eng":0.3734449913,"data-quality":0.123531262,"ml-security":0.0748041577}}
{"text":"Additionally, we extend GraphRNN to generate directed acyclic graphs by replacing the BFS traversal with a topological sort.","meta":{"url":"http://arxiv.org/abs/2307.14109v1"},"cats":{"new-dataset":0.4829030707,"dev-research":0.274621218,"prompt-eng":0.352016297,"data-quality":0.1407868473,"ml-security":0.0835672322}}
{"text":"We demonstrate that this method improves significantly over a directed-multiclass variant of GraphRNN on a real-world dataset.","meta":{"url":"http://arxiv.org/abs/2307.14109v1"},"cats":{"new-dataset":0.5060454738,"dev-research":0.2447569358,"prompt-eng":0.3384127495,"data-quality":0.2892636795,"ml-security":0.1041857031}}
{"text":"Chat Generative Pre-trained Transformer (ChatGPT) has gained significant interest and attention since its launch in November 2022.","meta":{"url":"http://arxiv.org/abs/2307.14107v1"},"cats":{"new-dataset":0.3119569345,"dev-research":0.2754438241,"prompt-eng":0.4032171693,"data-quality":0.1184370972,"ml-security":0.0798823289}}
{"text":"It has shown impressive performance in various domains, including passing exams and creative writing.","meta":{"url":"http://arxiv.org/abs/2307.14107v1"},"cats":{"new-dataset":0.0581256351,"dev-research":0.3136038078,"prompt-eng":0.3686709558,"data-quality":0.1057407421,"ml-security":0.0472109674}}
{"text":"However, challenges and concerns related to biases and trust persist.","meta":{"url":"http://arxiv.org/abs/2307.14107v1"},"cats":{"new-dataset":0.0228502005,"dev-research":0.2903600413,"prompt-eng":0.3588481476,"data-quality":0.2980585135,"ml-security":0.3127655301}}
{"text":"In this work, we present a comprehensive review of over 100 Scopus-indexed publications on ChatGPT, aiming to provide a taxonomy of ChatGPT research and explore its applications.","meta":{"url":"http://arxiv.org/abs/2307.14107v1"},"cats":{"new-dataset":0.3358195148,"dev-research":0.1891903506,"prompt-eng":0.3231889781,"data-quality":0.1115277986,"ml-security":0.0418480007}}
{"text":"We critically analyze the existing literature, identifying common approaches employed in the studies.","meta":{"url":"http://arxiv.org/abs/2307.14107v1"},"cats":{"new-dataset":0.0745695921,"dev-research":0.2454354358,"prompt-eng":0.3434218606,"data-quality":0.1158130492,"ml-security":0.0520438141}}
{"text":"Additionally, we investigate diverse application areas where ChatGPT has found utility, such as healthcare, marketing and financial services, software engineering, academic and scientific writing, research and education, environmental science, and natural language processing.","meta":{"url":"http://arxiv.org/abs/2307.14107v1"},"cats":{"new-dataset":0.2153756753,"dev-research":0.3360127557,"prompt-eng":0.3663208342,"data-quality":0.1277237585,"ml-security":0.0640377956}}
{"text":"Through examining these applications, we gain valuable insights into the potential of ChatGPT in addressing real-world challenges.","meta":{"url":"http://arxiv.org/abs/2307.14107v1"},"cats":{"new-dataset":0.2475364841,"dev-research":0.3875023835,"prompt-eng":0.3826952467,"data-quality":0.1825842891,"ml-security":0.1102114644}}
{"text":"We also discuss crucial issues related to ChatGPT, including biases and trustworthiness, emphasizing the need for further research and development in these areas.","meta":{"url":"http://arxiv.org/abs/2307.14107v1"},"cats":{"new-dataset":0.134276908,"dev-research":0.3303681238,"prompt-eng":0.4008659581,"data-quality":0.2918900076,"ml-security":0.1484839033}}
{"text":"Furthermore, we identify potential future directions for ChatGPT research, proposing solutions to current challenges and speculating on expected advancements.","meta":{"url":"http://arxiv.org/abs/2307.14107v1"},"cats":{"new-dataset":0.2432335697,"dev-research":0.2853825386,"prompt-eng":0.3924282872,"data-quality":0.1415209632,"ml-security":0.0667297662}}
{"text":"By fully leveraging the capabilities of ChatGPT, we can unlock its potential across various domains, leading to advancements in conversational AI and transformative impacts in society.","meta":{"url":"http://arxiv.org/abs/2307.14107v1"},"cats":{"new-dataset":0.3316475665,"dev-research":0.2890198707,"prompt-eng":0.32950998,"data-quality":0.16571907,"ml-security":0.1774509826}}
{"text":"In ground-view object change detection, the recently emerging map-less navigation has great potential as a means of navigating a robot to distantly detected objects and identifying their changing states (appear/disappear/no-change) with high resolution imagery.","meta":{"url":"http://arxiv.org/abs/2307.14105v1"},"cats":{"new-dataset":0.1910529638,"dev-research":0.1959012405,"prompt-eng":0.4026634873,"data-quality":0.1705415706,"ml-security":0.1107260146}}
{"text":"However, the brute-force naive action strategy of navigating to every distant object requires huge sense/plan/action costs proportional to the number of objects.","meta":{"url":"http://arxiv.org/abs/2307.14105v1"},"cats":{"new-dataset":0.0430340497,"dev-research":0.245860722,"prompt-eng":0.3465313408,"data-quality":0.0789841929,"ml-security":0.1524671975}}
{"text":"In this work, we study this new problem of ``Which distant objects should be prioritized for map-less navigation?\" and in order to speed up the R{\\&}D cycle, propose a highly-simplified approach that is easy to implement and easy to extend.","meta":{"url":"http://arxiv.org/abs/2307.14105v1"},"cats":{"new-dataset":0.231232536,"dev-research":0.2223025887,"prompt-eng":0.4017583501,"data-quality":0.1351962355,"ml-security":0.0583796827}}
{"text":"In our approach, a new layer called map-based navigation is added on top of the map-less navigation, which constitutes a hierarchical planner.","meta":{"url":"http://arxiv.org/abs/2307.14105v1"},"cats":{"new-dataset":0.1505975426,"dev-research":0.3001023577,"prompt-eng":0.4149290814,"data-quality":0.0524986035,"ml-security":0.0425936556}}
{"text":"First, a dataset consisting of $N$ view sequences is acquired by a real robot via map-less navigation.","meta":{"url":"http://arxiv.org/abs/2307.14105v1"},"cats":{"new-dataset":0.630705366,"dev-research":0.1841734312,"prompt-eng":0.3275280491,"data-quality":0.0847137583,"ml-security":0.0938460922}}
{"text":"Then, an environment simulator was built to simulate a simple action planning problem: ``Which view sequence should the robot select next?\".","meta":{"url":"http://arxiv.org/abs/2307.14105v1"},"cats":{"new-dataset":0.1684106875,"dev-research":0.3070479594,"prompt-eng":0.4345724527,"data-quality":0.0686189679,"ml-security":0.0719647798}}
{"text":"Then, a solver was built inspired by the analogy to the multi-armed bandit problem: ``Which arm should the player select next?\".","meta":{"url":"http://arxiv.org/abs/2307.14105v1"},"cats":{"new-dataset":0.0234720622,"dev-research":0.3467615049,"prompt-eng":0.407189396,"data-quality":0.1045641642,"ml-security":0.1396108903}}
{"text":"Finally, the effectiveness of the proposed framework was verified using the semantically non-trivial scenario ``sofa as bookshelf\".","meta":{"url":"http://arxiv.org/abs/2307.14105v1"},"cats":{"new-dataset":0.2299374449,"dev-research":0.3005246307,"prompt-eng":0.4536706068,"data-quality":0.1472849886,"ml-security":0.0742182492}}
{"text":"As for term rewrite systems, the dependency pair (DP, for short) framework with several kinds of DP processors is useful for proving termination of logically constrained term rewrite systems (LCTRSs, for short).","meta":{"url":"http://arxiv.org/abs/2307.14094v1"},"cats":{"new-dataset":0.0851335636,"dev-research":0.3842146609,"prompt-eng":0.4024778139,"data-quality":0.1380648489,"ml-security":0.0849750696}}
{"text":"However, the polynomial interpretation processor is not so effective against LCTRSs with bit-vector arithmetic (BV-LCTRSs, for short).","meta":{"url":"http://arxiv.org/abs/2307.14094v1"},"cats":{"new-dataset":0.0511803384,"dev-research":0.2610057966,"prompt-eng":0.3990178553,"data-quality":0.1353669618,"ml-security":0.0913214914}}
{"text":"In this paper, we propose a novel DP processor for BV-LCTRSs to solve a singleton DP problem consisting of a dependency pair forming a self-loop.","meta":{"url":"http://arxiv.org/abs/2307.14094v1"},"cats":{"new-dataset":0.2021614701,"dev-research":0.2706387428,"prompt-eng":0.4469324226,"data-quality":0.1304355227,"ml-security":0.0828428363}}
{"text":"The processor is based on an acyclic directed graph such that the nodes are bit-vectors and any dependency chain of the problem is projected to a path of the graph.","meta":{"url":"http://arxiv.org/abs/2307.14094v1"},"cats":{"new-dataset":0.1205513222,"dev-research":0.3411581613,"prompt-eng":0.4133481835,"data-quality":0.1076633136,"ml-security":0.0806575493}}
{"text":"We show a sufficient condition for the existence of such an acyclic graph, and simplify it for a specific case.","meta":{"url":"http://arxiv.org/abs/2307.14094v1"},"cats":{"new-dataset":0.2062313814,"dev-research":0.1973217397,"prompt-eng":0.3271217995,"data-quality":0.1813791395,"ml-security":0.094222277}}
{"text":"This paper proposes a stochastic block model with dynamics where the population grows using preferential attachment.","meta":{"url":"http://arxiv.org/abs/2307.13713v1"},"cats":{"new-dataset":0.0334555917,"dev-research":0.1392061771,"prompt-eng":0.3970608533,"data-quality":0.0838895261,"ml-security":0.0739532573}}
{"text":"Nodes with higher weighted degree are more likely to recruit new nodes, and nodes always recruit nodes from their own community.","meta":{"url":"http://arxiv.org/abs/2307.13713v1"},"cats":{"new-dataset":0.0020083413,"dev-research":0.2472957477,"prompt-eng":0.3520863339,"data-quality":0.1242255401,"ml-security":0.1126464949}}
{"text":"This model can capture how communities grow or shrink based on their collaborations with other nodes in the network, where an edge represents collaboration on a project.   ","meta":{"url":"http://arxiv.org/abs/2307.13713v1"},"cats":{"new-dataset":0.0911388303,"dev-research":0.375262285,"prompt-eng":0.3460564789,"data-quality":0.1390135725,"ml-security":0.0842351137}}
{"text":"Focusing on the case of two communities, we derive a deterministic approximation to the dynamics and characterize the phase transitions for diversity, i.e. the parameter regimes in which either one of the communities dies out or the two communities reach parity over time.   ","meta":{"url":"http://arxiv.org/abs/2307.13713v1"},"cats":{"new-dataset":0.1040491517,"dev-research":0.1422565063,"prompt-eng":0.3445188882,"data-quality":0.1232732916,"ml-security":0.1157332128}}
{"text":"In particular, we find that the minority may vanish when the probability of cross-community edges is low, even when cross-community projects are more valuable than projects with collaborators from the same community.","meta":{"url":"http://arxiv.org/abs/2307.13713v1"},"cats":{"new-dataset":0.0713817907,"dev-research":0.2551508005,"prompt-eng":0.3472905761,"data-quality":0.2961527307,"ml-security":0.2222775235}}
{"text":"We study reinforcement learning (RL) for learning a Quantal Stackelberg Equilibrium (QSE) in an episodic Markov game with a leader-follower structure.","meta":{"url":"http://arxiv.org/abs/2307.14085v1"},"cats":{"new-dataset":0.0823645268,"dev-research":0.1450592662,"prompt-eng":0.3798800302,"data-quality":0.0681338439,"ml-security":0.1377924393}}
{"text":"In specific, at the outset of the game, the leader announces her policy to the follower and commits to it.","meta":{"url":"http://arxiv.org/abs/2307.14085v1"},"cats":{"new-dataset":0.1267800721,"dev-research":0.2794969009,"prompt-eng":0.4088800289,"data-quality":0.0731586519,"ml-security":0.1281913592}}
{"text":"The follower observes the leader's policy and, in turn, adopts a quantal response policy by solving an entropy-regularized policy optimization problem induced by leader's policy.","meta":{"url":"http://arxiv.org/abs/2307.14085v1"},"cats":{"new-dataset":0.0731313416,"dev-research":0.1894860353,"prompt-eng":0.4321331532,"data-quality":0.0994517067,"ml-security":0.1367711809}}
{"text":"The goal of the leader is to find her optimal policy, which yields the optimal expected total return, by interacting with the follower and learning from data.","meta":{"url":"http://arxiv.org/abs/2307.14085v1"},"cats":{"new-dataset":0.0286793388,"dev-research":0.1800666563,"prompt-eng":0.3859093521,"data-quality":0.0607278595,"ml-security":0.146663035}}
{"text":"A key challenge of this problem is that the leader cannot observe the follower's reward, and needs to infer the follower's quantal response model from his actions against leader's policies.","meta":{"url":"http://arxiv.org/abs/2307.14085v1"},"cats":{"new-dataset":0.0929109055,"dev-research":0.1325898122,"prompt-eng":0.4498032087,"data-quality":0.1529374666,"ml-security":0.2581188691}}
{"text":"We propose sample-efficient algorithms for both the online and offline settings, in the context of function approximation.","meta":{"url":"http://arxiv.org/abs/2307.14085v1"},"cats":{"new-dataset":0.1305021608,"dev-research":0.210236694,"prompt-eng":0.3909923141,"data-quality":0.1305266908,"ml-security":0.0528442933}}
{"text":"Our algorithms are based on (i) learning the quantal response model via maximum likelihood estimation and (ii) model-free or model-based RL for solving the leader's decision making problem, and we show that they achieve sublinear regret upper bounds.","meta":{"url":"http://arxiv.org/abs/2307.14085v1"},"cats":{"new-dataset":0.1080951355,"dev-research":0.1688484921,"prompt-eng":0.4074952353,"data-quality":0.1469015175,"ml-security":0.1649448867}}
{"text":"Moreover, we quantify the uncertainty of these estimators and leverage the uncertainty to implement optimistic and pessimistic algorithms for online and offline settings.","meta":{"url":"http://arxiv.org/abs/2307.14085v1"},"cats":{"new-dataset":0.1843811412,"dev-research":0.2060372088,"prompt-eng":0.4122994175,"data-quality":0.1703896372,"ml-security":0.0922541045}}
{"text":"Besides, when specialized to the linear and myopic setting, our algorithms are also computationally efficient.","meta":{"url":"http://arxiv.org/abs/2307.14085v1"},"cats":{"new-dataset":0.0437376078,"dev-research":0.2614793004,"prompt-eng":0.3529538514,"data-quality":0.0955369338,"ml-security":0.0756861406}}
{"text":"Our theoretical analysis features a novel performance-difference lemma which incorporates the error of quantal response model, which might be of independent interest.","meta":{"url":"http://arxiv.org/abs/2307.14085v1"},"cats":{"new-dataset":0.0187232137,"dev-research":0.166395294,"prompt-eng":0.4410599066,"data-quality":0.15939494,"ml-security":0.0662415874}}
{"text":"RDMA has been widely adopted for high-speed datacenter networks.","meta":{"url":"http://arxiv.org/abs/2307.14074v1"},"cats":{"new-dataset":0.1031404274,"dev-research":0.3088813764,"prompt-eng":0.3614119736,"data-quality":0.0985248298,"ml-security":0.077443132}}
{"text":"However, native RDMA merely supports one-to-one reliable connection, which mismatches various applications with group communication patterns (e.g., one-to-many).","meta":{"url":"http://arxiv.org/abs/2307.14074v1"},"cats":{"new-dataset":0.0575486832,"dev-research":0.2762095645,"prompt-eng":0.3850385942,"data-quality":0.1783329775,"ml-security":0.1008928133}}
{"text":"While there are some multicast enhancements to address it, they all fail to simultaneously achieve optimal multicast forwarding and fully unleash the distinguished RDMA capabilities.   ","meta":{"url":"http://arxiv.org/abs/2307.14074v1"},"cats":{"new-dataset":0.0623095939,"dev-research":0.2233703455,"prompt-eng":0.3609263064,"data-quality":0.205784866,"ml-security":0.1552064817}}
{"text":"In this paper, we present Gleam, an RDMA-accelerated multicast protocol that simultaneously supports optimal multicast forwarding, efficient utilization of the prominent RDMA capabilities, and compatibility with the commodity RNICs.","meta":{"url":"http://arxiv.org/abs/2307.14074v1"},"cats":{"new-dataset":0.2393470589,"dev-research":0.2312875752,"prompt-eng":0.3487845269,"data-quality":0.1165132091,"ml-security":0.0866321874}}
{"text":"At its core, Gleam re-purposes the existing RDMA RC logic with careful switch coordination as an efficient multicast transport.","meta":{"url":"http://arxiv.org/abs/2307.14074v1"},"cats":{"new-dataset":0.1102593439,"dev-research":0.3157816486,"prompt-eng":0.4269446038,"data-quality":0.0748859952,"ml-security":0.069558466}}
{"text":"Gleam performs the one-to-many connection maintenance and many-to-one feedback aggregation, based on an extended multicast forwarding table structure, to achieve integration between standard RC logic and in-fabric multicast.","meta":{"url":"http://arxiv.org/abs/2307.14074v1"},"cats":{"new-dataset":0.0966315124,"dev-research":0.3125180915,"prompt-eng":0.4750480054,"data-quality":0.1092799634,"ml-security":0.0557057917}}
{"text":"We implement a fully functional Gleam prototype.","meta":{"url":"http://arxiv.org/abs/2307.14074v1"},"cats":{"new-dataset":0.0561749299,"dev-research":0.3110982163,"prompt-eng":0.4860468635,"data-quality":0.1034139163,"ml-security":0.0883542826}}
{"text":"With extensive testbed experiments and simulations, we demonstrate Gleam's significant improvement in accelerating multicast communication of realistic applications.","meta":{"url":"http://arxiv.org/abs/2307.14074v1"},"cats":{"new-dataset":0.1140296748,"dev-research":0.2646254919,"prompt-eng":0.3835775194,"data-quality":0.1494678909,"ml-security":0.0797710336}}
{"text":"For instance, Gleam achieves 2.9X lower communication time of an HPC benchmark application and 2.7X higher data replication throughput.","meta":{"url":"http://arxiv.org/abs/2307.14074v1"},"cats":{"new-dataset":0.0542086001,"dev-research":0.3384088097,"prompt-eng":0.3740039929,"data-quality":0.0944812003,"ml-security":0.0825677848}}
{"text":"Recently, diffusion models like StableDiffusion have achieved impressive image generation results.","meta":{"url":"http://arxiv.org/abs/2307.14073v1"},"cats":{"new-dataset":0.1195468899,"dev-research":0.1775731263,"prompt-eng":0.3546244402,"data-quality":0.1061095473,"ml-security":0.0614054277}}
{"text":"However, the generation process of such diffusion models is uncontrollable, which makes it hard to generate videos with continuous and consistent content.","meta":{"url":"http://arxiv.org/abs/2307.14073v1"},"cats":{"new-dataset":0.0355193407,"dev-research":0.1875189421,"prompt-eng":0.3208132091,"data-quality":0.1352591797,"ml-security":0.1031453692}}
{"text":"In this work, by using the diffusion model with ControlNet, we proposed a new motion-guided video-to-video translation framework called VideoControlNet to generate various videos based on the given prompts and the condition from the input video.","meta":{"url":"http://arxiv.org/abs/2307.14073v1"},"cats":{"new-dataset":0.1824391896,"dev-research":0.2277707035,"prompt-eng":0.4066291295,"data-quality":0.1451925675,"ml-security":0.0572638037}}
{"text":"Inspired by the video codecs that use motion information for reducing temporal redundancy, our framework uses motion information to prevent the regeneration of the redundant areas for content consistency.","meta":{"url":"http://arxiv.org/abs/2307.14073v1"},"cats":{"new-dataset":0.1322660327,"dev-research":0.3078495308,"prompt-eng":0.3806439609,"data-quality":0.2439111173,"ml-security":0.0658242643}}
{"text":"Specifically, we generate the first frame (i.e., the I-frame) by using the diffusion model with ControlNet.","meta":{"url":"http://arxiv.org/abs/2307.14073v1"},"cats":{"new-dataset":0.2818652468,"dev-research":0.1476680692,"prompt-eng":0.4009078967,"data-quality":0.0716438349,"ml-security":0.0542268354}}
{"text":"Then we generate other key frames (i.e., the P-frame) based on the previous I/P-frame by using our newly proposed motion-guided P-frame generation (MgPG) method, in which the P-frames are generated based on the motion information and the occlusion areas are inpainted by using the diffusion model.","meta":{"url":"http://arxiv.org/abs/2307.14073v1"},"cats":{"new-dataset":0.2030235493,"dev-research":0.1914515831,"prompt-eng":0.4057639022,"data-quality":0.0673942785,"ml-security":0.0287370953}}
{"text":"Finally, the rest frames (i.e., the B-frame) are generated by using our motion-guided B-frame interpolation (MgBI) module.","meta":{"url":"http://arxiv.org/abs/2307.14073v1"},"cats":{"new-dataset":0.3918227676,"dev-research":0.1523374075,"prompt-eng":0.3969571803,"data-quality":0.074543384,"ml-security":0.0278511017}}
{"text":"Our experiments demonstrate that our proposed VideoControlNet inherits the generation capability of the pre-trained large diffusion model and extends the image diffusion model to the video diffusion model by using motion information.","meta":{"url":"http://arxiv.org/abs/2307.14073v1"},"cats":{"new-dataset":0.1369071416,"dev-research":0.2156699711,"prompt-eng":0.3594977579,"data-quality":0.1189142989,"ml-security":0.1030575014}}
{"text":"More results are provided at our project page.","meta":{"url":"http://arxiv.org/abs/2307.14073v1"},"cats":{"new-dataset":0.5132033275,"dev-research":0.1709767658,"prompt-eng":0.3802815822,"data-quality":0.100434461,"ml-security":0.0300841714}}
{"text":"Correlation based stereo matching has achieved outstanding performance, which pursues cost volume between two feature maps.","meta":{"url":"http://arxiv.org/abs/2307.14071v1"},"cats":{"new-dataset":0.0361722779,"dev-research":0.2444947107,"prompt-eng":0.3938609691,"data-quality":0.1411447854,"ml-security":0.0352945479}}
{"text":"Unfortunately, current methods with a fixed model do not work uniformly well across various datasets, greatly limiting their real-world applicability.","meta":{"url":"http://arxiv.org/abs/2307.14071v1"},"cats":{"new-dataset":0.2254315104,"dev-research":0.1613759112,"prompt-eng":0.3661042219,"data-quality":0.2551524666,"ml-security":0.0881204482}}
{"text":"To tackle this issue, this paper proposes a new perspective to dynamically calculate correlation for robust stereo matching.","meta":{"url":"http://arxiv.org/abs/2307.14071v1"},"cats":{"new-dataset":0.0765616385,"dev-research":0.1905578484,"prompt-eng":0.4039718261,"data-quality":0.2087260307,"ml-security":0.0459805531}}
{"text":"A novel Uncertainty Guided Adaptive Correlation (UGAC) module is introduced to robustly adapt the same model for different scenarios.","meta":{"url":"http://arxiv.org/abs/2307.14071v1"},"cats":{"new-dataset":0.0444198999,"dev-research":0.2755329201,"prompt-eng":0.4675154642,"data-quality":0.2177483057,"ml-security":0.0586143759}}
{"text":"Specifically, a variance-based uncertainty estimation is employed to adaptively adjust the sampling area during warping operation.","meta":{"url":"http://arxiv.org/abs/2307.14071v1"},"cats":{"new-dataset":0.0256338131,"dev-research":0.2507389036,"prompt-eng":0.4442584174,"data-quality":0.244011674,"ml-security":0.0480076464}}
{"text":"Additionally, we improve the traditional non-parametric warping with learnable parameters, such that the position-specific weights can be learned.","meta":{"url":"http://arxiv.org/abs/2307.14071v1"},"cats":{"new-dataset":0.1338192861,"dev-research":0.1846032494,"prompt-eng":0.3549277114,"data-quality":0.1698070489,"ml-security":0.0846968151}}
{"text":"We show that by empowering the recurrent network with the UGAC module, stereo matching can be exploited more robustly and effectively.","meta":{"url":"http://arxiv.org/abs/2307.14071v1"},"cats":{"new-dataset":0.2399848763,"dev-research":0.1853217802,"prompt-eng":0.3711705499,"data-quality":0.2138052706,"ml-security":0.077837268}}
{"text":"Extensive experiments demonstrate that our method achieves state-of-the-art performance over the ETH3D, KITTI, and Middlebury datasets when employing the same fixed model over these datasets without any retraining procedure.","meta":{"url":"http://arxiv.org/abs/2307.14071v1"},"cats":{"new-dataset":0.4657732207,"dev-research":0.2050589183,"prompt-eng":0.3464285001,"data-quality":0.105134016,"ml-security":0.0601836751}}
{"text":"To target real-time applications, we further design a lightweight model based on UGAC, which also outperforms other methods over KITTI benchmarks with only 0.6 M parameters.","meta":{"url":"http://arxiv.org/abs/2307.14071v1"},"cats":{"new-dataset":0.1625326804,"dev-research":0.2979567312,"prompt-eng":0.4332430152,"data-quality":0.0864317004,"ml-security":0.0613984592}}
{"text":"Relying on large-scale training data with pixel-level labels, previous edge detection methods have achieved high performance.","meta":{"url":"http://arxiv.org/abs/2307.14070v1"},"cats":{"new-dataset":0.0616775886,"dev-research":0.2119501637,"prompt-eng":0.346442582,"data-quality":0.2464594143,"ml-security":0.156481918}}
{"text":"However, it is hard to manually label edges accurately, especially for large datasets, and thus the datasets inevitably contain noisy labels.","meta":{"url":"http://arxiv.org/abs/2307.14070v1"},"cats":{"new-dataset":0.0476043839,"dev-research":0.2915223905,"prompt-eng":0.3591635768,"data-quality":0.6495086194,"ml-security":0.1130510416}}
{"text":"This label-noise issue has been studied extensively for classification, while still remaining under-explored for edge detection.","meta":{"url":"http://arxiv.org/abs/2307.14070v1"},"cats":{"new-dataset":0.0815206776,"dev-research":0.174202883,"prompt-eng":0.3652931494,"data-quality":0.7263767637,"ml-security":0.2123854703}}
{"text":"To address the label-noise issue for edge detection, this paper proposes to learn Pixel-level NoiseTransitions to model the label-corruption process.","meta":{"url":"http://arxiv.org/abs/2307.14070v1"},"cats":{"new-dataset":0.0981944819,"dev-research":0.2815672729,"prompt-eng":0.3829549929,"data-quality":0.7495355471,"ml-security":0.2005583305}}
{"text":"To achieve it, we develop a novel Pixel-wise Shift Learning (PSL) module to estimate the transition from clean to noisy labels as a displacement field.","meta":{"url":"http://arxiv.org/abs/2307.14070v1"},"cats":{"new-dataset":0.1536802026,"dev-research":0.2087150662,"prompt-eng":0.4013834085,"data-quality":0.336957546,"ml-security":0.0682197167}}
{"text":"Exploiting the estimated noise transitions, our model, named PNT-Edge, is able to fit the prediction to clean labels.","meta":{"url":"http://arxiv.org/abs/2307.14070v1"},"cats":{"new-dataset":0.1642943122,"dev-research":0.1985234263,"prompt-eng":0.4146177053,"data-quality":0.6167541605,"ml-security":0.1180422545}}
{"text":"In addition, a local edge density regularization term is devised to exploit local structure information for better transition learning.","meta":{"url":"http://arxiv.org/abs/2307.14070v1"},"cats":{"new-dataset":0.0664944101,"dev-research":0.1677252862,"prompt-eng":0.3577347581,"data-quality":0.1608581418,"ml-security":0.0783556056}}
{"text":"This term encourages learning large shifts for the edges with complex local structures.","meta":{"url":"http://arxiv.org/abs/2307.14070v1"},"cats":{"new-dataset":0.0805103332,"dev-research":0.243167206,"prompt-eng":0.300397509,"data-quality":0.1665570563,"ml-security":0.1144543724}}
{"text":"Experiments on SBD and Cityscapes demonstrate the effectiveness of our method in relieving the impact of label noise.","meta":{"url":"http://arxiv.org/abs/2307.14070v1"},"cats":{"new-dataset":0.1184537371,"dev-research":0.276765892,"prompt-eng":0.4820324632,"data-quality":0.7284304103,"ml-security":0.112127344}}
{"text":"Codes will be available at github.","meta":{"url":"http://arxiv.org/abs/2307.14070v1"},"cats":{"new-dataset":0.5267520828,"dev-research":0.1992737915,"prompt-eng":0.4445060566,"data-quality":0.1544124418,"ml-security":0.0482433491}}
{"text":"Multi-source unsupervised domain adaptation (MUDA) aims to transfer knowledge from related source domains to an unlabeled target domain.","meta":{"url":"http://arxiv.org/abs/2307.14068v1"},"cats":{"new-dataset":0.1069793953,"dev-research":0.2690875934,"prompt-eng":0.4010784889,"data-quality":0.282893441,"ml-security":0.1294064044}}
{"text":"While recent MUDA methods have shown promising results, most focus on aligning the overall feature distributions across source domains, which can lead to negative effects due to redundant features within each domain.","meta":{"url":"http://arxiv.org/abs/2307.14068v1"},"cats":{"new-dataset":0.077544485,"dev-research":0.3206073361,"prompt-eng":0.3865936273,"data-quality":0.3278819514,"ml-security":0.1691154513}}
{"text":"Moreover, there is a significant performance gap between MUDA and supervised methods.","meta":{"url":"http://arxiv.org/abs/2307.14068v1"},"cats":{"new-dataset":0.0657694748,"dev-research":0.2247049286,"prompt-eng":0.3756621712,"data-quality":0.2511541367,"ml-security":0.0749691486}}
{"text":"To address these challenges, we propose a novel approach called Dynamic Domain Discrepancy Adjustment for Active Multi-Domain Adaptation (D3AAMDA).","meta":{"url":"http://arxiv.org/abs/2307.14068v1"},"cats":{"new-dataset":0.0830190786,"dev-research":0.3096926309,"prompt-eng":0.4314695111,"data-quality":0.3347325157,"ml-security":0.0810100127}}
{"text":"Firstly, we establish a multi-source dynamic modulation mechanism during the training process based on the degree of distribution differences between source and target domains.","meta":{"url":"http://arxiv.org/abs/2307.14068v1"},"cats":{"new-dataset":0.0319504597,"dev-research":0.2526262798,"prompt-eng":0.4489388119,"data-quality":0.1650223535,"ml-security":0.2001404524}}
{"text":"This mechanism controls the alignment level of features between each source domain and the target domain, effectively leveraging the local advantageous feature information within the source domains.","meta":{"url":"http://arxiv.org/abs/2307.14068v1"},"cats":{"new-dataset":0.0322580623,"dev-research":0.3856692504,"prompt-eng":0.4588677564,"data-quality":0.2011822335,"ml-security":0.1081312032}}
{"text":"Additionally, we propose a Multi-source Active Boundary Sample Selection (MABS) strategy, which utilizes a guided dynamic boundary loss to design an efficient query function for selecting important samples.","meta":{"url":"http://arxiv.org/abs/2307.14068v1"},"cats":{"new-dataset":0.1307085857,"dev-research":0.2335357532,"prompt-eng":0.4331669033,"data-quality":0.1987026858,"ml-security":0.1085329396}}
{"text":"This strategy achieves improved generalization to the target domain with minimal sampling costs.","meta":{"url":"http://arxiv.org/abs/2307.14068v1"},"cats":{"new-dataset":0.0446064742,"dev-research":0.1888306488,"prompt-eng":0.430987094,"data-quality":0.2454114074,"ml-security":0.1786606483}}
{"text":"We extensively evaluate our proposed method on commonly used domain adaptation datasets, comparing it against existing UDA and ADA methods.","meta":{"url":"http://arxiv.org/abs/2307.14068v1"},"cats":{"new-dataset":0.2434172588,"dev-research":0.2646446545,"prompt-eng":0.4215045281,"data-quality":0.2896055719,"ml-security":0.1123361405}}
{"text":"The experimental results unequivocally demonstrate the superiority of our approach.","meta":{"url":"http://arxiv.org/abs/2307.14068v1"},"cats":{"new-dataset":0.0189346097,"dev-research":0.197901496,"prompt-eng":0.4081574402,"data-quality":0.2743689579,"ml-security":0.1265492397}}
{"text":"Detection of easily missed hidden patterns with fast processing power makes machine learning (ML) indispensable to today's healthcare system.","meta":{"url":"http://arxiv.org/abs/2307.14067v1"},"cats":{"new-dataset":0.079661946,"dev-research":0.2863209758,"prompt-eng":0.3647719492,"data-quality":0.278457469,"ml-security":0.4159193739}}
{"text":"Though many ML applications have already been discovered and many are still under investigation, only a few have been adopted by current healthcare systems.","meta":{"url":"http://arxiv.org/abs/2307.14067v1"},"cats":{"new-dataset":0.0311627001,"dev-research":0.1946698286,"prompt-eng":0.3367251684,"data-quality":0.1347902471,"ml-security":0.1618815941}}
{"text":"As a result, there exists an enormous opportunity in healthcare system for ML but distributed information, scarcity of properly arranged and easily explainable documentation in related sector are major impede which are making ML applications difficult to healthcare professionals.","meta":{"url":"http://arxiv.org/abs/2307.14067v1"},"cats":{"new-dataset":0.0885034463,"dev-research":0.2948487444,"prompt-eng":0.3571865997,"data-quality":0.1378863366,"ml-security":0.2014281685}}
{"text":"This study aimed to gather ML applications in different areas of healthcare concisely and more effectively so that necessary information can be accessed immediately with relevant references.","meta":{"url":"http://arxiv.org/abs/2307.14067v1"},"cats":{"new-dataset":0.1825286431,"dev-research":0.2547771773,"prompt-eng":0.386383175,"data-quality":0.1046358603,"ml-security":0.1042245048}}
{"text":"We divided our study into five major groups: community level work, risk management/ preventive care, healthcare operation management, remote care, and early detection.","meta":{"url":"http://arxiv.org/abs/2307.14067v1"},"cats":{"new-dataset":0.1993065078,"dev-research":0.2411278417,"prompt-eng":0.3474410248,"data-quality":0.065673759,"ml-security":0.1000294968}}
{"text":"Dividing these groups into subgroups, we provided relevant references with description in tabular form for quick access.","meta":{"url":"http://arxiv.org/abs/2307.14067v1"},"cats":{"new-dataset":0.6604339771,"dev-research":0.1676632345,"prompt-eng":0.3973475883,"data-quality":0.1075604678,"ml-security":0.0468887023}}
{"text":"Our objective is to inform people about ML applicability in healthcare industry, reduce the knowledge gap of clinicians about the ML applications and motivate healthcare professionals towards more machine learning based healthcare system.","meta":{"url":"http://arxiv.org/abs/2307.14067v1"},"cats":{"new-dataset":0.0817787276,"dev-research":0.3370139682,"prompt-eng":0.3457234468,"data-quality":0.1588875724,"ml-security":0.309423006}}
{"text":"Medical radiography segmentation, and specifically dental radiography, is highly limited by the cost of labeling which requires specific expertise and labor-intensive annotations.","meta":{"url":"http://arxiv.org/abs/2307.14066v1"},"cats":{"new-dataset":0.0489250032,"dev-research":0.2201199585,"prompt-eng":0.3710351675,"data-quality":0.1906342231,"ml-security":0.0727373141}}
{"text":"In this work, we propose a straightforward pre-training method for semantic segmentation leveraging Denoising Diffusion Probabilistic Models (DDPM), which have shown impressive results for generative modeling.","meta":{"url":"http://arxiv.org/abs/2307.14066v1"},"cats":{"new-dataset":0.3418203316,"dev-research":0.1878817443,"prompt-eng":0.3994843766,"data-quality":0.2417243353,"ml-security":0.0936585615}}
{"text":"Our straightforward approach achieves remarkable performance in terms of label efficiency and does not require architectural modifications between pre-training and downstream tasks.","meta":{"url":"http://arxiv.org/abs/2307.14066v1"},"cats":{"new-dataset":0.1443451904,"dev-research":0.2454639674,"prompt-eng":0.45542692,"data-quality":0.4360573205,"ml-security":0.0782350026}}
{"text":"We propose to first pre-train a Unet by exploiting the DDPM training objective, and then fine-tune the resulting model on a segmentation task.","meta":{"url":"http://arxiv.org/abs/2307.14066v1"},"cats":{"new-dataset":0.5065142546,"dev-research":0.1802917833,"prompt-eng":0.4305861375,"data-quality":0.2741653108,"ml-security":0.0838537268}}
{"text":"Our experimental results on the segmentation of dental radiographs demonstrate that the proposed method is competitive with state-of-the-art pre-training methods.","meta":{"url":"http://arxiv.org/abs/2307.14066v1"},"cats":{"new-dataset":0.0882444553,"dev-research":0.1795508423,"prompt-eng":0.4180059219,"data-quality":0.2486866772,"ml-security":0.0721374749}}
{"text":"Relay-enabled backscatter communication (BC) is an intriguing paradigm to alleviate energy shortage and improve throughput of Internet-of-Things (IoT) devices.","meta":{"url":"http://arxiv.org/abs/2307.14064v1"},"cats":{"new-dataset":0.0286927128,"dev-research":0.2506377708,"prompt-eng":0.4417685295,"data-quality":0.1024722038,"ml-security":0.1646595292}}
{"text":"Most of the existing works focus on the resource allocation that considered the unequal and continuous time allocation for both source-relay and relay-destination links.","meta":{"url":"http://arxiv.org/abs/2307.14064v1"},"cats":{"new-dataset":0.0591755591,"dev-research":0.2833537277,"prompt-eng":0.3434239971,"data-quality":0.0992705235,"ml-security":0.087440763}}
{"text":"However, the continuous time allocation may be infeasible since in practice, the time allocation shall be carried out in integral multiple of the subframe duration unit.","meta":{"url":"http://arxiv.org/abs/2307.14064v1"},"cats":{"new-dataset":0.0813335032,"dev-research":0.2226607712,"prompt-eng":0.3439794252,"data-quality":0.0757749566,"ml-security":0.0799202684}}
{"text":"In this article, we study a discrete time scheme from the perspective of frame structure, where one transmission block is divided into two phases and the linear mapping is employed as a re-encoding method to determine the number of subframes for both phases and the power allocation for each subframe in a relay-enabled BC system.","meta":{"url":"http://arxiv.org/abs/2307.14064v1"},"cats":{"new-dataset":0.0692118701,"dev-research":0.2410844271,"prompt-eng":0.4017003744,"data-quality":0.0731631548,"ml-security":0.0918762469}}
{"text":"Based on this, we derive an accurate system-throughput expression and formulate a mixed-integral non-convex optimization problem to maximize the system throughput by jointly optimizing the power reflection coefficient (PRC) of the IoT node, the power allocation of the hybrid access point (HAP) and the linear mapping matrix, and solve it via a three-step approach.","meta":{"url":"http://arxiv.org/abs/2307.14064v1"},"cats":{"new-dataset":0.0204128209,"dev-research":0.2064018311,"prompt-eng":0.3901295329,"data-quality":0.0752559221,"ml-security":0.1017260952}}
{"text":"Accordingly, we propose a low complexity iterative algorithm to obtain the throughput maximization-based resource allocation solution.","meta":{"url":"http://arxiv.org/abs/2307.14064v1"},"cats":{"new-dataset":0.0455914817,"dev-research":0.2802736517,"prompt-eng":0.4094455937,"data-quality":0.0996956094,"ml-security":0.0830681773}}
{"text":"Numerical results analyze the performance of our proposed algorithm, verify the superiority of our proposed scheme, and evaluate the impacts of network parameters on the system throughput.","meta":{"url":"http://arxiv.org/abs/2307.14064v1"},"cats":{"new-dataset":0.0370222666,"dev-research":0.2183504004,"prompt-eng":0.4077278364,"data-quality":0.1324925573,"ml-security":0.0883328949}}
{"text":"Image recognition has recently witnessed a paradigm shift, where vision-language models are now used to perform few-shot classification based on textual prompts.","meta":{"url":"http://arxiv.org/abs/2307.14063v1"},"cats":{"new-dataset":0.1848881875,"dev-research":0.1861321399,"prompt-eng":0.4528509243,"data-quality":0.2982459413,"ml-security":0.1367674638}}
{"text":"Among these, the CLIP model has shown remarkable capabilities for zero-shot transfer by matching an image and a custom textual prompt in its latent space.","meta":{"url":"http://arxiv.org/abs/2307.14063v1"},"cats":{"new-dataset":0.2735272435,"dev-research":0.1522144364,"prompt-eng":0.450373565,"data-quality":0.1327629603,"ml-security":0.0850089935}}
{"text":"This has paved the way for several works that focus on engineering or learning textual contexts for maximizing CLIP's classification capabilities.","meta":{"url":"http://arxiv.org/abs/2307.14063v1"},"cats":{"new-dataset":0.1066354718,"dev-research":0.3137802151,"prompt-eng":0.4039376279,"data-quality":0.2914937801,"ml-security":0.1489086165}}
{"text":"In this paper, we follow this trend by learning an ensemble of prompts for image classification.","meta":{"url":"http://arxiv.org/abs/2307.14063v1"},"cats":{"new-dataset":0.1560685224,"dev-research":0.1819190614,"prompt-eng":0.5015991366,"data-quality":0.3460371269,"ml-security":0.2684335567}}
{"text":"We show that learning diverse and possibly shorter contexts improves considerably and consistently the results rather than relying on a single trainable prompt.","meta":{"url":"http://arxiv.org/abs/2307.14063v1"},"cats":{"new-dataset":0.1286334163,"dev-research":0.3054705832,"prompt-eng":0.5161209495,"data-quality":0.3241680017,"ml-security":0.1422737633}}
{"text":"In particular, we report better few-shot capabilities with no additional cost at inference time.","meta":{"url":"http://arxiv.org/abs/2307.14063v1"},"cats":{"new-dataset":0.0473455444,"dev-research":0.2314930221,"prompt-eng":0.3675631417,"data-quality":0.1635942699,"ml-security":0.1114188706}}
{"text":"We demonstrate the capabilities of our approach on 11 different benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.14063v1"},"cats":{"new-dataset":0.2397860514,"dev-research":0.2093938961,"prompt-eng":0.4108688998,"data-quality":0.1624028558,"ml-security":0.0571984431}}
{"text":"Vision-language pre-training (VLP) models have shown vulnerability to adversarial examples in multimodal tasks.","meta":{"url":"http://arxiv.org/abs/2307.14061v1"},"cats":{"new-dataset":0.2144818708,"dev-research":0.2855006862,"prompt-eng":0.3976391769,"data-quality":0.3764975392,"ml-security":0.5830894611}}
{"text":"Furthermore, malicious adversaries can be deliberately transferred to attack other black-box models.","meta":{"url":"http://arxiv.org/abs/2307.14061v1"},"cats":{"new-dataset":0.014112215,"dev-research":0.2961631993,"prompt-eng":0.3549189221,"data-quality":0.2110893552,"ml-security":0.8525831403}}
{"text":"However, existing work has mainly focused on investigating white-box attacks.","meta":{"url":"http://arxiv.org/abs/2307.14061v1"},"cats":{"new-dataset":0.0610970595,"dev-research":0.2985148155,"prompt-eng":0.342425118,"data-quality":0.0991890889,"ml-security":0.4884229672}}
{"text":"In this paper, we present the first study to investigate the adversarial transferability of recent VLP models.","meta":{"url":"http://arxiv.org/abs/2307.14061v1"},"cats":{"new-dataset":0.0417656558,"dev-research":0.1878262647,"prompt-eng":0.3468467629,"data-quality":0.2990118657,"ml-security":0.5392131575}}
{"text":"We observe that existing methods exhibit much lower transferability, compared to the strong attack performance in white-box settings.","meta":{"url":"http://arxiv.org/abs/2307.14061v1"},"cats":{"new-dataset":0.0253563942,"dev-research":0.2607442175,"prompt-eng":0.4002462607,"data-quality":0.1425317878,"ml-security":0.7135779738}}
{"text":"The transferability degradation is partly caused by the under-utilization of cross-modal interactions.","meta":{"url":"http://arxiv.org/abs/2307.14061v1"},"cats":{"new-dataset":0.0109337563,"dev-research":0.2677943396,"prompt-eng":0.3883598823,"data-quality":0.1390159268,"ml-security":0.1094292897}}
{"text":"Particularly, unlike unimodal learning, VLP models rely heavily on cross-modal interactions and the multimodal alignments are many-to-many, e.g., an image can be described in various natural languages.","meta":{"url":"http://arxiv.org/abs/2307.14061v1"},"cats":{"new-dataset":0.1363180043,"dev-research":0.1969429952,"prompt-eng":0.3740651556,"data-quality":0.1175826729,"ml-security":0.071744154}}
{"text":"To this end, we propose a highly transferable Set-level Guidance Attack (SGA) that thoroughly leverages modality interactions and incorporates alignment-preserving augmentation with cross-modal guidance.","meta":{"url":"http://arxiv.org/abs/2307.14061v1"},"cats":{"new-dataset":0.1900518014,"dev-research":0.3034414543,"prompt-eng":0.4248473647,"data-quality":0.278328485,"ml-security":0.4551896368}}
{"text":"Experimental results demonstrate that SGA could generate adversarial examples that can strongly transfer across different VLP models on multiple downstream vision-language tasks.","meta":{"url":"http://arxiv.org/abs/2307.14061v1"},"cats":{"new-dataset":0.0958888822,"dev-research":0.2380620085,"prompt-eng":0.3838469343,"data-quality":0.2914969176,"ml-security":0.3336412078}}
{"text":"On image-text retrieval, SGA significantly enhances the attack success rate for transfer attacks from ALBEF to TCL by a large margin (at least 9.78% and up to 30.21%), compared to the state-of-the-art.","meta":{"url":"http://arxiv.org/abs/2307.14061v1"},"cats":{"new-dataset":0.1085316701,"dev-research":0.213316845,"prompt-eng":0.3903427009,"data-quality":0.2035069687,"ml-security":0.3842358826}}
{"text":"Modern web-based platforms show ranked lists of recommendations to users, attempting to maximise user satisfaction or business metrics.","meta":{"url":"http://arxiv.org/abs/2307.14059v1"},"cats":{"new-dataset":0.0687521658,"dev-research":0.2687640611,"prompt-eng":0.4061702965,"data-quality":0.1220779433,"ml-security":0.0624592366}}
{"text":"Typically, the goal of such systems boils down to maximising the exposure probability for items that are deemed \"reward-maximising\" according to a metric of interest.","meta":{"url":"http://arxiv.org/abs/2307.14059v1"},"cats":{"new-dataset":0.008786363,"dev-research":0.21968399,"prompt-eng":0.4181784221,"data-quality":0.1146201101,"ml-security":0.1981164878}}
{"text":"This general framing comprises streaming applications, as well as e-commerce or job recommendations, and even web search.","meta":{"url":"http://arxiv.org/abs/2307.14059v1"},"cats":{"new-dataset":0.1144403066,"dev-research":0.236376844,"prompt-eng":0.3706227394,"data-quality":0.0970962018,"ml-security":0.0540005266}}
{"text":"Position bias or user models can be used to estimate exposure probabilities for each use-case, specifically tailored to how users interact with the presented rankings.","meta":{"url":"http://arxiv.org/abs/2307.14059v1"},"cats":{"new-dataset":0.0335739089,"dev-research":0.2611022865,"prompt-eng":0.503406185,"data-quality":0.1464019019,"ml-security":0.222548133}}
{"text":"A unifying factor in these diverse problem settings is that typically only one or several items will be engaged with (clicked, streamed,...) before a user leaves the ranked list.","meta":{"url":"http://arxiv.org/abs/2307.14059v1"},"cats":{"new-dataset":0.0178457048,"dev-research":0.3143316405,"prompt-eng":0.3925940166,"data-quality":0.1787003582,"ml-security":0.1366178575}}
{"text":"Short-video feeds on social media platforms diverge from this general framing in several ways, most notably that users do not tend to leave the feed after e.g. liking a post.","meta":{"url":"http://arxiv.org/abs/2307.14059v1"},"cats":{"new-dataset":0.0149554991,"dev-research":0.2309113265,"prompt-eng":0.3227624436,"data-quality":0.2422844822,"ml-security":0.1223536552}}
{"text":"Indeed, seemingly infinite feeds invite users to scroll further down the ranked list.","meta":{"url":"http://arxiv.org/abs/2307.14059v1"},"cats":{"new-dataset":0.0727045341,"dev-research":0.1840143691,"prompt-eng":0.3634461289,"data-quality":0.1155048425,"ml-security":0.1144259631}}
{"text":"For this reason, existing position bias or user models tend to fall short in such settings, as they do not accurately capture users' interaction modalities.   ","meta":{"url":"http://arxiv.org/abs/2307.14059v1"},"cats":{"new-dataset":0.0133941682,"dev-research":0.2814021843,"prompt-eng":0.4249901965,"data-quality":0.1875802186,"ml-security":0.1228562668}}
{"text":"In this work, we propose a novel and probabilistically sound personalised position bias model for feed recommendations.","meta":{"url":"http://arxiv.org/abs/2307.14059v1"},"cats":{"new-dataset":0.0528853955,"dev-research":0.1671637358,"prompt-eng":0.4599502686,"data-quality":0.1994917026,"ml-security":0.0918991416}}
{"text":"We focus on a 1st-level feed in a hierarchical structure, where users may enter a 2nd-level feed via any given 1st-level item.","meta":{"url":"http://arxiv.org/abs/2307.14059v1"},"cats":{"new-dataset":0.1452817394,"dev-research":0.2050130736,"prompt-eng":0.4918155127,"data-quality":0.143587215,"ml-security":0.0880704745}}
{"text":"We posit that users come to the platform with a scrolling budget drawn according to some distribution, and show how the survival function of said distribution can be used to obtain closed-form estimates for personalised exposure probabilities.","meta":{"url":"http://arxiv.org/abs/2307.14059v1"},"cats":{"new-dataset":0.4853759106,"dev-research":0.193370927,"prompt-eng":0.424549638,"data-quality":0.0963828242,"ml-security":0.2725138787}}
{"text":"Empirical insights from a large-scale social media platform show how our probabilistic position bias model more accurately captures empirical exposure than existing models, and paves the way for unbiased evaluation and learning-to-rank.","meta":{"url":"http://arxiv.org/abs/2307.14059v1"},"cats":{"new-dataset":0.0942061157,"dev-research":0.2385246506,"prompt-eng":0.370294302,"data-quality":0.304864932,"ml-security":0.1838029113}}
{"text":"Despite the presence of the classification task in many different benchmark datasets for perception in the automotive domain, few efforts have been undertaken to define consistent classification requirements.","meta":{"url":"http://arxiv.org/abs/2307.14058v1"},"cats":{"new-dataset":0.1146913699,"dev-research":0.2316159839,"prompt-eng":0.4169406712,"data-quality":0.3598428719,"ml-security":0.0808039125}}
{"text":"This work addresses the topic by proposing a structured method to generate a classification structure.","meta":{"url":"http://arxiv.org/abs/2307.14058v1"},"cats":{"new-dataset":0.206733273,"dev-research":0.2389862897,"prompt-eng":0.4745112261,"data-quality":0.2934975706,"ml-security":0.1262103665}}
{"text":"First, legal categories are identified based on behavioral requirements for the vehicle.","meta":{"url":"http://arxiv.org/abs/2307.14058v1"},"cats":{"new-dataset":0.0856040552,"dev-research":0.2351031364,"prompt-eng":0.3915645852,"data-quality":0.1757691639,"ml-security":0.112709059}}
{"text":"This structure is further substantiated by considering the two aspects of collision safety for objects as well as perceptual categories.","meta":{"url":"http://arxiv.org/abs/2307.14058v1"},"cats":{"new-dataset":0.1131713463,"dev-research":0.2175583415,"prompt-eng":0.3583890199,"data-quality":0.1344441322,"ml-security":0.206786516}}
{"text":"A classification hierarchy is obtained by applying the method to an exemplary legal text.","meta":{"url":"http://arxiv.org/abs/2307.14058v1"},"cats":{"new-dataset":0.1566202596,"dev-research":0.2500762985,"prompt-eng":0.3956294617,"data-quality":0.2273967301,"ml-security":0.1192853814}}
{"text":"A comparison of the results with benchmark dataset categories shows limited agreement.","meta":{"url":"http://arxiv.org/abs/2307.14058v1"},"cats":{"new-dataset":0.6824670402,"dev-research":0.1997129189,"prompt-eng":0.3405342058,"data-quality":0.3237964357,"ml-security":0.0836162225}}
{"text":"This indicates the necessity for explicit consideration of legal requirements regarding perception.","meta":{"url":"http://arxiv.org/abs/2307.14058v1"},"cats":{"new-dataset":0.0110920908,"dev-research":0.3405911989,"prompt-eng":0.3869162805,"data-quality":0.1919729787,"ml-security":0.0997632322}}
{"text":"With the advance in malware technology, attackers create new ways to hide their malicious code from antivirus services.","meta":{"url":"http://arxiv.org/abs/2307.14057v1"},"cats":{"new-dataset":0.0130895921,"dev-research":0.3780897,"prompt-eng":0.3920433396,"data-quality":0.1648414353,"ml-security":0.7168831175}}
{"text":"One way to obfuscate an attack is to use common files as cover to hide the malicious scripts, so the malware will look like a legitimate file.","meta":{"url":"http://arxiv.org/abs/2307.14057v1"},"cats":{"new-dataset":0.0188782491,"dev-research":0.3477572659,"prompt-eng":0.3476880245,"data-quality":0.2167669366,"ml-security":0.7659409007}}
{"text":"Although cutting-edge Artificial Intelligence and content signature exist, evasive malware successfully bypasses next-generation malware detection using advanced methods like steganography.","meta":{"url":"http://arxiv.org/abs/2307.14057v1"},"cats":{"new-dataset":0.026267125,"dev-research":0.2737791846,"prompt-eng":0.3823949701,"data-quality":0.2490058981,"ml-security":0.6277387934}}
{"text":"Some of the files commonly used to hide malware are image files (e.g., JPEG).","meta":{"url":"http://arxiv.org/abs/2307.14057v1"},"cats":{"new-dataset":0.0597110295,"dev-research":0.2946796571,"prompt-eng":0.3471611533,"data-quality":0.204966265,"ml-security":0.5160249882}}
{"text":"In addition, some malware use steganography to hide malicious scripts or sensitive data in images.","meta":{"url":"http://arxiv.org/abs/2307.14057v1"},"cats":{"new-dataset":0.0139381191,"dev-research":0.3121885448,"prompt-eng":0.3320819883,"data-quality":0.2149929431,"ml-security":0.5401449703}}
{"text":"Steganography in images is difficult to detect even with specialized tools.","meta":{"url":"http://arxiv.org/abs/2307.14057v1"},"cats":{"new-dataset":0.0173717569,"dev-research":0.1944697824,"prompt-eng":0.362353486,"data-quality":0.364839871,"ml-security":0.3631696672}}
{"text":"Image-based attacks try to attack the user's device using malicious payloads or utilize image steganography to hide sensitive data inside legitimate images and leak it outside the user's device.","meta":{"url":"http://arxiv.org/abs/2307.14057v1"},"cats":{"new-dataset":0.0240972636,"dev-research":0.3131334245,"prompt-eng":0.3823947511,"data-quality":0.2308826972,"ml-security":0.6754230785}}
{"text":"Therefore in this paper, we present a novel Image Content Disarm and Reconstruction (ICDR).","meta":{"url":"http://arxiv.org/abs/2307.14057v1"},"cats":{"new-dataset":0.2396583754,"dev-research":0.141117005,"prompt-eng":0.3695549948,"data-quality":0.1264712428,"ml-security":0.0725835408}}
{"text":"Our ICDR system removes potential malware, with a zero trust approach, while maintaining high image quality and file usability.","meta":{"url":"http://arxiv.org/abs/2307.14057v1"},"cats":{"new-dataset":0.0900932383,"dev-research":0.2939806401,"prompt-eng":0.4333099662,"data-quality":0.2388476253,"ml-security":0.3422276416}}
{"text":"By extracting the image data, removing it from the rest of the file, and manipulating the image pixels, it is possible to disable or remove the hidden malware inside the file.","meta":{"url":"http://arxiv.org/abs/2307.14057v1"},"cats":{"new-dataset":0.0392291953,"dev-research":0.2675584147,"prompt-eng":0.3704523154,"data-quality":0.2698899412,"ml-security":0.4442581766}}
{"text":"High-accuracy Dichotomous Image Segmentation (DIS) aims to pinpoint category-agnostic foreground objects from natural scenes.","meta":{"url":"http://arxiv.org/abs/2307.14052v1"},"cats":{"new-dataset":0.2195227281,"dev-research":0.1730059793,"prompt-eng":0.4140086296,"data-quality":0.2627062875,"ml-security":0.0966438676}}
{"text":"The main challenge for DIS involves identifying the highly accurate dominant area while rendering detailed object structure.","meta":{"url":"http://arxiv.org/abs/2307.14052v1"},"cats":{"new-dataset":0.23152498,"dev-research":0.2446235507,"prompt-eng":0.4122816523,"data-quality":0.123733885,"ml-security":0.089651582}}
{"text":"However, directly using a general encoder-decoder architecture may result in an oversupply of high-level features and neglect the shallow spatial information necessary for partitioning meticulous structures.","meta":{"url":"http://arxiv.org/abs/2307.14052v1"},"cats":{"new-dataset":0.0724869364,"dev-research":0.26552387,"prompt-eng":0.3903877483,"data-quality":0.1638505446,"ml-security":0.1253059743}}
{"text":"To fill this gap, we introduce a novel Unite-Divide-Unite Network (UDUN} that restructures and bipartitely arranges complementary features to simultaneously boost the effectiveness of trunk and structure identification.","meta":{"url":"http://arxiv.org/abs/2307.14052v1"},"cats":{"new-dataset":0.2252772418,"dev-research":0.2167294519,"prompt-eng":0.369135135,"data-quality":0.2116999148,"ml-security":0.1024285641}}
{"text":"The proposed UDUN proceeds from several strengths.","meta":{"url":"http://arxiv.org/abs/2307.14052v1"},"cats":{"new-dataset":0.0879113544,"dev-research":0.2717166097,"prompt-eng":0.3266937936,"data-quality":0.0815723553,"ml-security":0.081484248}}
{"text":"First, a dual-size input feeds into the shared backbone to produce more holistic and detailed features while keeping the model lightweight.","meta":{"url":"http://arxiv.org/abs/2307.14052v1"},"cats":{"new-dataset":0.1495235693,"dev-research":0.3018313181,"prompt-eng":0.4461347063,"data-quality":0.0921692532,"ml-security":0.0903674355}}
{"text":"Second, a simple Divide-and-Conquer Module (DCM) is proposed to decouple multiscale low- and high-level features into our structure decoder and trunk decoder to obtain structure and trunk information respectively.","meta":{"url":"http://arxiv.org/abs/2307.14052v1"},"cats":{"new-dataset":0.1259942565,"dev-research":0.2403261971,"prompt-eng":0.4135641605,"data-quality":0.1481541937,"ml-security":0.0808270754}}
{"text":"Moreover, we design a Trunk-Structure Aggregation module (TSA) in our union decoder that performs cascade integration for uniform high-accuracy segmentation.","meta":{"url":"http://arxiv.org/abs/2307.14052v1"},"cats":{"new-dataset":0.2549342692,"dev-research":0.189024683,"prompt-eng":0.3684968925,"data-quality":0.2145987557,"ml-security":0.0523423424}}
{"text":"As a result, UDUN performs favorably against state-of-the-art competitors in all six evaluation metrics on overall DIS-TE, i.e., achieving 0.772 weighted F-measure and 977 HCE.","meta":{"url":"http://arxiv.org/abs/2307.14052v1"},"cats":{"new-dataset":0.1189301252,"dev-research":0.2577517768,"prompt-eng":0.4099601454,"data-quality":0.1516000921,"ml-security":0.0835090445}}
{"text":"Using 1024*1024 input, our model enables real-time inference at 65.3 fps with ResNet-18.","meta":{"url":"http://arxiv.org/abs/2307.14052v1"},"cats":{"new-dataset":0.344260287,"dev-research":0.2287244707,"prompt-eng":0.3737847634,"data-quality":0.0830501507,"ml-security":0.0748869615}}
{"text":"Shape generation is the practice of producing 3D shapes as various representations for 3D content creation.","meta":{"url":"http://arxiv.org/abs/2307.14051v1"},"cats":{"new-dataset":0.0355407135,"dev-research":0.3871381198,"prompt-eng":0.3630349064,"data-quality":0.0888924611,"ml-security":0.0716610102}}
{"text":"Previous studies on 3D shape generation have focused on shape quality and structure, without or less considering the importance of semantic information.","meta":{"url":"http://arxiv.org/abs/2307.14051v1"},"cats":{"new-dataset":0.0613459187,"dev-research":0.2914992288,"prompt-eng":0.3525303913,"data-quality":0.1175597059,"ml-security":0.0484746491}}
{"text":"Consequently, such generative models often fail to preserve the semantic consistency of shape structure or enable manipulation of the semantic attributes of shapes during generation.","meta":{"url":"http://arxiv.org/abs/2307.14051v1"},"cats":{"new-dataset":0.0291880433,"dev-research":0.2781432983,"prompt-eng":0.4110874409,"data-quality":0.2497206587,"ml-security":0.1002673644}}
{"text":"In this paper, we proposed a novel semantic generative model named 3D Semantic Subspace Traverser that utilizes semantic attributes for category-specific 3D shape generation and editing.","meta":{"url":"http://arxiv.org/abs/2307.14051v1"},"cats":{"new-dataset":0.1422364247,"dev-research":0.3133350265,"prompt-eng":0.4019786774,"data-quality":0.1219637724,"ml-security":0.0475627114}}
{"text":"Our method utilizes implicit functions as the 3D shape representation and combines a novel latent-space GAN with a linear subspace model to discover semantic dimensions in the local latent space of 3D shapes.","meta":{"url":"http://arxiv.org/abs/2307.14051v1"},"cats":{"new-dataset":0.12165131,"dev-research":0.2821768669,"prompt-eng":0.3186970338,"data-quality":0.1431507882,"ml-security":0.1171033729}}
{"text":"Each dimension of the subspace corresponds to a particular semantic attribute, and we can edit the attributes of generated shapes by traversing the coefficients of those dimensions.","meta":{"url":"http://arxiv.org/abs/2307.14051v1"},"cats":{"new-dataset":0.0831155988,"dev-research":0.2716414019,"prompt-eng":0.3973534533,"data-quality":0.1529295095,"ml-security":0.0767539443}}
{"text":"Experimental results demonstrate that our method can produce plausible shapes with complex structures and enable the editing of semantic attributes.","meta":{"url":"http://arxiv.org/abs/2307.14051v1"},"cats":{"new-dataset":0.0656794516,"dev-research":0.34717167,"prompt-eng":0.4517730791,"data-quality":0.2307202397,"ml-security":0.0883227053}}
{"text":"The code and trained models are available at https://github.com/TrepangCat/3D_Semantic_Subspace_Traverser","meta":{"url":"http://arxiv.org/abs/2307.14051v1"},"cats":{"new-dataset":0.3695543169,"dev-research":0.1636646903,"prompt-eng":0.3936507623,"data-quality":0.122610476,"ml-security":0.0364594667}}
{"text":"In this paper, we consider intelligent reflecting surface (IRS) in a non-orthogonal multiple access (NOMA)-aided Integrated Sensing and Multicast-Unicast Communication (ISMUC) system, where the multicast signal is used for sensing and communications while the unicast signal is used only for communications.","meta":{"url":"http://arxiv.org/abs/2307.14050v1"},"cats":{"new-dataset":0.0341266286,"dev-research":0.2117375908,"prompt-eng":0.4080383941,"data-quality":0.0799565504,"ml-security":0.0572855273}}
{"text":"Our goal is to depict whether the IRS improves the performance of NOMA-ISMUC system or not under the imperfect/perfect successive interference cancellation (SIC) scenario.","meta":{"url":"http://arxiv.org/abs/2307.14050v1"},"cats":{"new-dataset":0.0522539024,"dev-research":0.1973125199,"prompt-eng":0.3988264311,"data-quality":0.1998861171,"ml-security":0.1074560228}}
{"text":"Towards this end, we formulate a non-convex problem to maximize the unicast rate while ensuring the minimum target illumination power and multicast rate.","meta":{"url":"http://arxiv.org/abs/2307.14050v1"},"cats":{"new-dataset":0.0832897035,"dev-research":0.1581159883,"prompt-eng":0.3949261827,"data-quality":0.1501583631,"ml-security":0.0993731669}}
{"text":"To settle this problem, we employ the Dinkelbach method to transform this original problem into an equivalent one, which is then solved via alternating optimization algorithm and semidefinite relaxation (SDR) with Sequential Rank-One Constraint Relaxation (SROCR).","meta":{"url":"http://arxiv.org/abs/2307.14050v1"},"cats":{"new-dataset":0.2425559284,"dev-research":0.1537613149,"prompt-eng":0.3817610422,"data-quality":0.156094603,"ml-security":0.0508457006}}
{"text":"Based on this, an iterative algorithm is devised to obtain a near-optimal solution.","meta":{"url":"http://arxiv.org/abs/2307.14050v1"},"cats":{"new-dataset":0.0574852724,"dev-research":0.1863082323,"prompt-eng":0.434406927,"data-quality":0.107294519,"ml-security":0.0368347368}}
{"text":"Computer simulations verify the quick convergence of the devised iterative algorithm, and provide insightful results.","meta":{"url":"http://arxiv.org/abs/2307.14050v1"},"cats":{"new-dataset":0.04711808,"dev-research":0.1991512566,"prompt-eng":0.3808320647,"data-quality":0.1127847925,"ml-security":0.0403277799}}
{"text":"Compared to NOMA-ISMUC without IRS, IRS-aided NOMA-ISMUC achieves a higher rate with perfect SIC but keeps the almost same rate in the case of imperfect SIC.","meta":{"url":"http://arxiv.org/abs/2307.14050v1"},"cats":{"new-dataset":0.0135162041,"dev-research":0.1910350911,"prompt-eng":0.3689790131,"data-quality":0.1481504995,"ml-security":0.0914266846}}
{"text":"We propose cryptographic protocols to incorporate time provenance guarantees while meeting confidentiality and controlled sharing needs for research data.","meta":{"url":"http://arxiv.org/abs/2307.14041v1"},"cats":{"new-dataset":0.2129884314,"dev-research":0.273272898,"prompt-eng":0.3747632978,"data-quality":0.1307190404,"ml-security":0.3227008688}}
{"text":"We demonstrate the efficacy of these mechanisms by developing and benchmarking a practical tool, GovernR, which furthermore takes into usability issues and is compatible with a popular open-sourced research data storage platform, Dataverse.","meta":{"url":"http://arxiv.org/abs/2307.14041v1"},"cats":{"new-dataset":0.268819453,"dev-research":0.3598357768,"prompt-eng":0.4550843074,"data-quality":0.2054914155,"ml-security":0.0796229665}}
{"text":"In doing so, we identify and provide a solution addressing an important gap (though applicable to only niche use cases) in practical research data management.","meta":{"url":"http://arxiv.org/abs/2307.14041v1"},"cats":{"new-dataset":0.1132614575,"dev-research":0.3026314874,"prompt-eng":0.3837474617,"data-quality":0.1863715373,"ml-security":0.0818241099}}
{"text":"Recent studies on face forgery detection have shown satisfactory performance for methods involved in training datasets, but are not ideal enough for unknown domains.","meta":{"url":"http://arxiv.org/abs/2307.14039v1"},"cats":{"new-dataset":0.1603982501,"dev-research":0.2125503514,"prompt-eng":0.3521299304,"data-quality":0.3668977225,"ml-security":0.4794786511}}
{"text":"This motivates many works to improve the generalization, but forgery-irrelevant information, such as image background and identity, still exists in different domain features and causes unexpected clustering, limiting the generalization.","meta":{"url":"http://arxiv.org/abs/2307.14039v1"},"cats":{"new-dataset":0.0113727794,"dev-research":0.2938778605,"prompt-eng":0.353283087,"data-quality":0.3693911976,"ml-security":0.4298932123}}
{"text":"In this paper, we propose a controllable guide-space (GS) method to enhance the discrimination of different forgery domains, so as to increase the forgery relevance of features and thereby improve the generalization.","meta":{"url":"http://arxiv.org/abs/2307.14039v1"},"cats":{"new-dataset":0.0562223025,"dev-research":0.3164802001,"prompt-eng":0.4812530667,"data-quality":0.3579940371,"ml-security":0.2409153417}}
{"text":"The well-designed guide-space can simultaneously achieve both the proper separation of forgery domains and the large distance between real-forgery domains in an explicit and controllable manner.","meta":{"url":"http://arxiv.org/abs/2307.14039v1"},"cats":{"new-dataset":0.0585996473,"dev-research":0.3231908034,"prompt-eng":0.4489191703,"data-quality":0.1895538566,"ml-security":0.2385640293}}
{"text":"Moreover, for better discrimination, we use a decoupling module to weaken the interference of forgery-irrelevant correlations between domains.","meta":{"url":"http://arxiv.org/abs/2307.14039v1"},"cats":{"new-dataset":0.0350731226,"dev-research":0.251058614,"prompt-eng":0.4391248678,"data-quality":0.4109268681,"ml-security":0.4023104429}}
{"text":"Furthermore, we make adjustments to the decision boundary manifold according to the clustering degree of the same domain features within the neighborhood.","meta":{"url":"http://arxiv.org/abs/2307.14039v1"},"cats":{"new-dataset":0.1166819399,"dev-research":0.2184368205,"prompt-eng":0.3866832425,"data-quality":0.2378675624,"ml-security":0.1264433332}}
{"text":"Extensive experiments in multiple in-domain and cross-domain settings confirm that our method can achieve state-of-the-art generalization.","meta":{"url":"http://arxiv.org/abs/2307.14039v1"},"cats":{"new-dataset":0.0562086939,"dev-research":0.2622602691,"prompt-eng":0.4692308056,"data-quality":0.2472923147,"ml-security":0.0750269756}}
{"text":"We first define appropriate state representation and action space, and then design an adjustment mechanism based on the actions selected by the intelligent agent.","meta":{"url":"http://arxiv.org/abs/2307.14038v1"},"cats":{"new-dataset":0.1748855082,"dev-research":0.2641857553,"prompt-eng":0.51753612,"data-quality":0.0997985379,"ml-security":0.0845962274}}
{"text":"The adjustment mechanism outputs the next state and reward value of the agent.","meta":{"url":"http://arxiv.org/abs/2307.14038v1"},"cats":{"new-dataset":0.0241639006,"dev-research":0.2407556396,"prompt-eng":0.4285165588,"data-quality":0.0907705979,"ml-security":0.0930424893}}
{"text":"Additionally, the adjustment mechanism calculates the error between the adjusted state and the unadjusted state.","meta":{"url":"http://arxiv.org/abs/2307.14038v1"},"cats":{"new-dataset":0.0147819149,"dev-research":0.2780391064,"prompt-eng":0.443682667,"data-quality":0.1792077154,"ml-security":0.0432671991}}
{"text":"Furthermore, the intelligent agent stores the acquired experience samples containing states and reward values in a buffer and replays the experiences during each iteration to learn the dynamic characteristics of the environment.","meta":{"url":"http://arxiv.org/abs/2307.14038v1"},"cats":{"new-dataset":0.1766771806,"dev-research":0.3505016498,"prompt-eng":0.4452566321,"data-quality":0.0960002489,"ml-security":0.1183169782}}
{"text":"We name the improved algorithm as the DQM algorithm.","meta":{"url":"http://arxiv.org/abs/2307.14038v1"},"cats":{"new-dataset":0.1402784121,"dev-research":0.1719841056,"prompt-eng":0.4087342603,"data-quality":0.1585443431,"ml-security":0.0625138558}}
{"text":"Experimental results demonstrate that the intelligent agent using our proposed algorithm effectively reduces the accumulated errors of inertial navigation in dynamic environments.","meta":{"url":"http://arxiv.org/abs/2307.14038v1"},"cats":{"new-dataset":0.0550502515,"dev-research":0.3631439244,"prompt-eng":0.4403358202,"data-quality":0.1319461808,"ml-security":0.0971296764}}
{"text":"Although our research provides a basis for achieving autonomous navigation of unmanned aerial vehicles, there is still room for significant optimization.","meta":{"url":"http://arxiv.org/abs/2307.14038v1"},"cats":{"new-dataset":0.0806099572,"dev-research":0.2256699805,"prompt-eng":0.3839306823,"data-quality":0.0689918387,"ml-security":0.1060399023}}
{"text":"Further research can include testing unmanned aerial vehicles in simulated environments, testing unmanned aerial vehicles in real-world environments, optimizing the design of reward functions, improving the algorithm workflow to enhance convergence speed and performance, and enhancing the algorithm's generalization ability.","meta":{"url":"http://arxiv.org/abs/2307.14038v1"},"cats":{"new-dataset":0.0793296941,"dev-research":0.3308169993,"prompt-eng":0.4075858319,"data-quality":0.0751686537,"ml-security":0.1293222002}}
{"text":"We present a termination proof for the Battle of Hercules and Hydra represented as a rewrite system with AC symbols.","meta":{"url":"http://arxiv.org/abs/2307.14036v1"},"cats":{"new-dataset":0.1295281144,"dev-research":0.3048122225,"prompt-eng":0.4288332134,"data-quality":0.1421602432,"ml-security":0.1892638682}}
{"text":"Our proof employs type introduction in connection with many-sorted semantic labeling for AC rewriting and AC-RPO.","meta":{"url":"http://arxiv.org/abs/2307.14036v1"},"cats":{"new-dataset":0.1443149236,"dev-research":0.3499340427,"prompt-eng":0.4195062403,"data-quality":0.2879121654,"ml-security":0.0723714757}}
{"text":"Creating high-quality annotated data for task-oriented dialog (ToD) is known to be notoriously difficult, and the challenges are amplified when the goal is to create equitable, culturally adapted, and large-scale ToD datasets for multiple languages.","meta":{"url":"http://arxiv.org/abs/2307.14031v1"},"cats":{"new-dataset":0.6659569708,"dev-research":0.3410782316,"prompt-eng":0.4473578049,"data-quality":0.2748244193,"ml-security":0.101019645}}
{"text":"Therefore, the current datasets are still very scarce and suffer from limitations such as translation-based non-native dialogs with translation artefacts, small scale, or lack of cultural adaptation, among others.","meta":{"url":"http://arxiv.org/abs/2307.14031v1"},"cats":{"new-dataset":0.7495622972,"dev-research":0.2162862662,"prompt-eng":0.2985976691,"data-quality":0.2436792288,"ml-security":0.0969938421}}
{"text":"In this work, we first take stock of the current landscape of multilingual ToD datasets, offering a systematic overview of their properties and limitations.","meta":{"url":"http://arxiv.org/abs/2307.14031v1"},"cats":{"new-dataset":0.8329547595,"dev-research":0.2001286277,"prompt-eng":0.3757608459,"data-quality":0.1445044326,"ml-security":0.0545322687}}
{"text":"Aiming to reduce all the detected limitations, we then introduce Multi3WOZ, a novel multilingual, multi-domain, multi-parallel ToD dataset.","meta":{"url":"http://arxiv.org/abs/2307.14031v1"},"cats":{"new-dataset":0.7035542323,"dev-research":0.2366767395,"prompt-eng":0.3771826216,"data-quality":0.1485363046,"ml-security":0.0685254752}}
{"text":"It is large-scale and offers culturally adapted dialogs in 4 languages to enable training and evaluation of multilingual and cross-lingual ToD systems.","meta":{"url":"http://arxiv.org/abs/2307.14031v1"},"cats":{"new-dataset":0.554624765,"dev-research":0.2911011993,"prompt-eng":0.4129459693,"data-quality":0.1305505237,"ml-security":0.0446432437}}
{"text":"We describe a complex bottom-up data collection process that yielded the final dataset, and offer the first sets of baseline scores across different ToD-related tasks for future reference, also highlighting its challenging nature.","meta":{"url":"http://arxiv.org/abs/2307.14031v1"},"cats":{"new-dataset":0.7761733753,"dev-research":0.2463375263,"prompt-eng":0.4315241688,"data-quality":0.1444948583,"ml-security":0.0401823315}}
{"text":"RANSAC and its variants are widely used for robust estimation, however, they commonly follow a greedy approach to finding the highest scoring model while ignoring other model hypotheses.","meta":{"url":"http://arxiv.org/abs/2307.14030v1"},"cats":{"new-dataset":0.2139567735,"dev-research":0.1815088323,"prompt-eng":0.4184765858,"data-quality":0.211470541,"ml-security":0.1702232167}}
{"text":"In contrast, Iteratively Reweighted Least Squares (IRLS) techniques gradually approach the model by iteratively updating the weight of each correspondence based on the residuals from previous iterations.","meta":{"url":"http://arxiv.org/abs/2307.14030v1"},"cats":{"new-dataset":0.0418889,"dev-research":0.2036067725,"prompt-eng":0.3900726004,"data-quality":0.115839503,"ml-security":0.058696918}}
{"text":"Inspired by these methods, we propose a new RANSAC framework that learns to explore the parameter space by considering the residuals seen so far via a novel attention layer.","meta":{"url":"http://arxiv.org/abs/2307.14030v1"},"cats":{"new-dataset":0.3048934389,"dev-research":0.2087050646,"prompt-eng":0.3970711827,"data-quality":0.2089505957,"ml-security":0.2225012725}}
{"text":"The attention mechanism operates on a batch of point-to-model residuals, and updates a per-point estimation state to take into account the consensus found through a lightweight one-step transformer.","meta":{"url":"http://arxiv.org/abs/2307.14030v1"},"cats":{"new-dataset":0.1488623372,"dev-research":0.2265285881,"prompt-eng":0.470201902,"data-quality":0.1927271596,"ml-security":0.083099873}}
{"text":"This rich state then guides the minimal sampling between iterations as well as the model refinement.","meta":{"url":"http://arxiv.org/abs/2307.14030v1"},"cats":{"new-dataset":0.091250734,"dev-research":0.1899912598,"prompt-eng":0.3947717691,"data-quality":0.1303989698,"ml-security":0.0551283518}}
{"text":"We evaluate the proposed approach on essential and fundamental matrix estimation on a number of indoor and outdoor datasets.","meta":{"url":"http://arxiv.org/abs/2307.14030v1"},"cats":{"new-dataset":0.3423213969,"dev-research":0.1873863212,"prompt-eng":0.3493073768,"data-quality":0.1259903907,"ml-security":0.0822359979}}
{"text":"It outperforms state-of-the-art estimators by a significant margin adding only a small runtime overhead.","meta":{"url":"http://arxiv.org/abs/2307.14030v1"},"cats":{"new-dataset":0.1632601903,"dev-research":0.1790292731,"prompt-eng":0.3800665013,"data-quality":0.2143636539,"ml-security":0.0985397288}}
{"text":"Moreover, we demonstrate good generalization properties of our trained model, indicating its effectiveness across different datasets and tasks.","meta":{"url":"http://arxiv.org/abs/2307.14030v1"},"cats":{"new-dataset":0.1299027864,"dev-research":0.1932900563,"prompt-eng":0.38267932,"data-quality":0.2640393708,"ml-security":0.1944164949}}
{"text":"The proposed attention mechanism and one-step transformer provide an adaptive behavior that enhances the performance of RANSAC, making it a more effective tool for robust estimation.","meta":{"url":"http://arxiv.org/abs/2307.14030v1"},"cats":{"new-dataset":0.1108805438,"dev-research":0.219460371,"prompt-eng":0.4732812023,"data-quality":0.2098968069,"ml-security":0.1127507935}}
{"text":"Code is available at https://github.com/cavalli1234/CA-RANSAC.","meta":{"url":"http://arxiv.org/abs/2307.14030v1"},"cats":{"new-dataset":0.4972262181,"dev-research":0.1726911679,"prompt-eng":0.4622303672,"data-quality":0.1259784551,"ml-security":0.0519029029}}
{"text":"Diagnosing rare anemia disorders using microscopic images is challenging for skilled specialists and machine-learning methods alike.","meta":{"url":"http://arxiv.org/abs/2307.14025v1"},"cats":{"new-dataset":0.1181574251,"dev-research":0.2227314627,"prompt-eng":0.3842235684,"data-quality":0.1758064355,"ml-security":0.0955600197}}
{"text":"Due to thousands of disease-relevant cells in a single blood sample, this constitutes a complex multiple-instance learning (MIL) problem.","meta":{"url":"http://arxiv.org/abs/2307.14025v1"},"cats":{"new-dataset":0.1007224623,"dev-research":0.179352308,"prompt-eng":0.3748463613,"data-quality":0.1987055933,"ml-security":0.1331368253}}
{"text":"While the spatial neighborhood of red blood cells is not meaningful per se, the topology, i.e., the geometry of blood samples as a whole, contains informative features to remedy typical MIL issues, such as vanishing gradients and overfitting when training on limited data.","meta":{"url":"http://arxiv.org/abs/2307.14025v1"},"cats":{"new-dataset":0.1863501565,"dev-research":0.2219818829,"prompt-eng":0.2844677797,"data-quality":0.1694870419,"ml-security":0.1547105642}}
{"text":"We thus develop a topology-based approach that extracts multi-scale topological features from bags of single red blood cell images.","meta":{"url":"http://arxiv.org/abs/2307.14025v1"},"cats":{"new-dataset":0.3222248995,"dev-research":0.1988540251,"prompt-eng":0.3339308486,"data-quality":0.1330777005,"ml-security":0.0769647968}}
{"text":"The topological features are used to regularize the model, enforcing the preservation of characteristic topological properties of the data.","meta":{"url":"http://arxiv.org/abs/2307.14025v1"},"cats":{"new-dataset":0.0828818357,"dev-research":0.2440699179,"prompt-eng":0.3979465526,"data-quality":0.1682221335,"ml-security":0.1229552315}}
{"text":"Applied to a dataset of 71 patients suffering from rare anemia disorders with 521 microscopic images of red blood cells, our experiments show that topological regularization is an effective method that leads to more than 3% performance improvements for the automated classification of rare anemia disorders based on single-cell images.","meta":{"url":"http://arxiv.org/abs/2307.14025v1"},"cats":{"new-dataset":0.2151160197,"dev-research":0.19845271,"prompt-eng":0.3628454831,"data-quality":0.1972720458,"ml-security":0.0787320841}}
{"text":"This is the first approach that uses topological properties for regularizing the MIL process.","meta":{"url":"http://arxiv.org/abs/2307.14025v1"},"cats":{"new-dataset":0.0900869345,"dev-research":0.1589418936,"prompt-eng":0.4197835381,"data-quality":0.1625009364,"ml-security":0.0586992549}}
{"text":"Conversational recommendation systems (CRS) aim to interactively acquire user preferences and accordingly recommend items to users.","meta":{"url":"http://arxiv.org/abs/2307.14024v1"},"cats":{"new-dataset":0.0919676439,"dev-research":0.2897128753,"prompt-eng":0.4285572155,"data-quality":0.1236176056,"ml-security":0.0822804699}}
{"text":"Accurately learning the dynamic user preferences is of crucial importance for CRS.","meta":{"url":"http://arxiv.org/abs/2307.14024v1"},"cats":{"new-dataset":0.0207069902,"dev-research":0.311425735,"prompt-eng":0.5121144328,"data-quality":0.1487593107,"ml-security":0.1588796913}}
{"text":"Previous works learn the user preferences with pairwise relations from the interactive conversation and item knowledge, while largely ignoring the fact that factors for a relationship in CRS are multiplex.","meta":{"url":"http://arxiv.org/abs/2307.14024v1"},"cats":{"new-dataset":0.236535666,"dev-research":0.2685375722,"prompt-eng":0.4624150346,"data-quality":0.1347967581,"ml-security":0.0478727816}}
{"text":"Specifically, the user likes/dislikes the items that satisfy some attributes (Like/Dislike view).","meta":{"url":"http://arxiv.org/abs/2307.14024v1"},"cats":{"new-dataset":0.0103006925,"dev-research":0.2794857703,"prompt-eng":0.4313433735,"data-quality":0.2097076143,"ml-security":0.2062791383}}
{"text":"Moreover social influence is another important factor that affects user preference towards the item (Social view), while is largely ignored by previous works in CRS.","meta":{"url":"http://arxiv.org/abs/2307.14024v1"},"cats":{"new-dataset":0.005711304,"dev-research":0.2770079976,"prompt-eng":0.3649209073,"data-quality":0.174991137,"ml-security":0.1124724171}}
{"text":"The user preferences from these three views are inherently different but also correlated as a whole.","meta":{"url":"http://arxiv.org/abs/2307.14024v1"},"cats":{"new-dataset":0.0170426744,"dev-research":0.2776663023,"prompt-eng":0.3643385444,"data-quality":0.1377355351,"ml-security":0.0795856392}}
{"text":"The user preferences from the same views should be more similar than that from different views.","meta":{"url":"http://arxiv.org/abs/2307.14024v1"},"cats":{"new-dataset":0.0302072576,"dev-research":0.2717771418,"prompt-eng":0.4004183125,"data-quality":0.1332143007,"ml-security":0.082890463}}
{"text":"The user preferences from Like View should be similar to Social View while different from Dislike View.","meta":{"url":"http://arxiv.org/abs/2307.14024v1"},"cats":{"new-dataset":0.0122958751,"dev-research":0.2727912305,"prompt-eng":0.3667285144,"data-quality":0.1667264189,"ml-security":0.1104511636}}
{"text":"To this end, we propose a novel model, namely Multi-view Hypergraph Contrastive Policy Learning (MHCPL).","meta":{"url":"http://arxiv.org/abs/2307.14024v1"},"cats":{"new-dataset":0.1970466967,"dev-research":0.192614191,"prompt-eng":0.3271971626,"data-quality":0.163444236,"ml-security":0.0891375173}}
{"text":"Specifically, MHCPL timely chooses useful social information according to the interactive history and builds a dynamic hypergraph with three types of multiplex relations from different views.","meta":{"url":"http://arxiv.org/abs/2307.14024v1"},"cats":{"new-dataset":0.2760604815,"dev-research":0.2662498825,"prompt-eng":0.3830179182,"data-quality":0.0908909965,"ml-security":0.0401526999}}
{"text":"The multiplex relations in each view are successively connected according to their generation order.","meta":{"url":"http://arxiv.org/abs/2307.14024v1"},"cats":{"new-dataset":0.1520939309,"dev-research":0.240826507,"prompt-eng":0.3307110501,"data-quality":0.1013590154,"ml-security":0.0427133905}}
{"text":"Existing analyses of the expressive capacity of Transformer models have required excessively deep layers for data memorization, leading to a discrepancy with the Transformers actually used in practice.","meta":{"url":"http://arxiv.org/abs/2307.14023v1"},"cats":{"new-dataset":0.0542417564,"dev-research":0.2756704313,"prompt-eng":0.3815213407,"data-quality":0.1431732436,"ml-security":0.1684103368}}
{"text":"This is primarily due to the interpretation of the softmax function as an approximation of the hardmax function.","meta":{"url":"http://arxiv.org/abs/2307.14023v1"},"cats":{"new-dataset":0.0072745027,"dev-research":0.2172024607,"prompt-eng":0.2545441852,"data-quality":0.1861859335,"ml-security":0.1893355845}}
{"text":"By clarifying the connection between the softmax function and the Boltzmann operator, we prove that a single layer of self-attention with low-rank weight matrices possesses the capability to perfectly capture the context of an entire input sequence.","meta":{"url":"http://arxiv.org/abs/2307.14023v1"},"cats":{"new-dataset":0.1079182013,"dev-research":0.1642160339,"prompt-eng":0.3486860271,"data-quality":0.1862925137,"ml-security":0.2169341702}}
{"text":"As a consequence, we show that single-layer Transformer has a memorization capacity for finite samples, and that Transformers consisting of one self-attention layer with two feed-forward neural networks are universal approximators for continuous functions on a compact domain.","meta":{"url":"http://arxiv.org/abs/2307.14023v1"},"cats":{"new-dataset":0.0924520499,"dev-research":0.1739146425,"prompt-eng":0.3222179818,"data-quality":0.1235047353,"ml-security":0.1958226453}}
{"text":"Brain encoding models aim to predict brain voxel-wise responses to stimuli images, replicating brain signals captured by neuroimaging techniques.","meta":{"url":"http://arxiv.org/abs/2307.14021v1"},"cats":{"new-dataset":0.0445513198,"dev-research":0.2225965436,"prompt-eng":0.412398493,"data-quality":0.1490546699,"ml-security":0.151811003}}
{"text":"There is a large volume of publicly available data, but training a comprehensive brain encoding model is challenging.","meta":{"url":"http://arxiv.org/abs/2307.14021v1"},"cats":{"new-dataset":0.2435149873,"dev-research":0.1773383744,"prompt-eng":0.3666870459,"data-quality":0.164052362,"ml-security":0.1493523708}}
{"text":"The main difficulties stem from a) diversity within individual brain, with functional heterogeneous brain regions; b) diversity of brains from different subjects, due to genetic and developmental differences; c) diversity of imaging modalities and processing pipelines.","meta":{"url":"http://arxiv.org/abs/2307.14021v1"},"cats":{"new-dataset":0.0171567009,"dev-research":0.2633052407,"prompt-eng":0.342545749,"data-quality":0.1666492084,"ml-security":0.0674700878}}
{"text":"We use this diversity to our advantage by introducing the All-for-One training recipe, which divides the challenging one-big-model problem into multiple small models, with the small models aggregating the knowledge while preserving the distinction between the different functional regions.","meta":{"url":"http://arxiv.org/abs/2307.14021v1"},"cats":{"new-dataset":0.2663448083,"dev-research":0.1544517279,"prompt-eng":0.3286580679,"data-quality":0.1989403559,"ml-security":0.1403346889}}
{"text":"Agnostic of the training recipe, we use biological knowledge of the brain, specifically retinotopy, to introduce inductive bias to learn a 3D brain-to-image mapping that ensures a) each neuron knows which image regions and semantic levels to gather information, and b) no neurons are left behind in the model.   ","meta":{"url":"http://arxiv.org/abs/2307.14021v1"},"cats":{"new-dataset":0.0930551855,"dev-research":0.242564511,"prompt-eng":0.354405608,"data-quality":0.15570656,"ml-security":0.1297564922}}
{"text":"We pre-trained a brain encoding model using over one million data points from five public datasets spanning three imaging modalities.","meta":{"url":"http://arxiv.org/abs/2307.14021v1"},"cats":{"new-dataset":0.4085479344,"dev-research":0.1938687992,"prompt-eng":0.4194461419,"data-quality":0.2061309054,"ml-security":0.1615468342}}
{"text":"To the best of our knowledge, this is the most comprehensive brain encoding model to the date.","meta":{"url":"http://arxiv.org/abs/2307.14021v1"},"cats":{"new-dataset":0.2096200856,"dev-research":0.1909320089,"prompt-eng":0.3924466695,"data-quality":0.1267670549,"ml-security":0.0911159848}}
{"text":"We demonstrate the effectiveness of the pre-trained model as a drop-in replacement for commonly used vision backbone models.","meta":{"url":"http://arxiv.org/abs/2307.14021v1"},"cats":{"new-dataset":0.0828238601,"dev-research":0.2131888335,"prompt-eng":0.4517385437,"data-quality":0.1333665488,"ml-security":0.0875895933}}
{"text":"Furthermore, we demonstrate the application of the model to brain decoding.","meta":{"url":"http://arxiv.org/abs/2307.14021v1"},"cats":{"new-dataset":0.0233797246,"dev-research":0.150870176,"prompt-eng":0.4077464362,"data-quality":0.1658502003,"ml-security":0.1439611605}}
{"text":"Code and the model checkpoint will be made available.","meta":{"url":"http://arxiv.org/abs/2307.14021v1"},"cats":{"new-dataset":0.4335651133,"dev-research":0.2808324636,"prompt-eng":0.4308952954,"data-quality":0.1319263855,"ml-security":0.1179475417}}
{"text":"Strip-decomposable quadrilateral (SDQ) meshes, i.e., quad meshes that can be decomposed into two transversal strip networks, are vital in numerous fabrication processes; examples include woven structures, surfaces from sheets, custom rebar, or cable-net structures.","meta":{"url":"http://arxiv.org/abs/2307.14020v1"},"cats":{"new-dataset":0.0430662821,"dev-research":0.2389466652,"prompt-eng":0.337764229,"data-quality":0.0808205497,"ml-security":0.0530512214}}
{"text":"However, their design is often challenging and includes tedious manual work, and there is a lack of methodologies for editing such meshes while preserving their strip decomposability.","meta":{"url":"http://arxiv.org/abs/2307.14020v1"},"cats":{"new-dataset":0.0832083844,"dev-research":0.2596152187,"prompt-eng":0.3730517824,"data-quality":0.1124856815,"ml-security":0.0629824721}}
{"text":"We present an interactive methodology to generate and edit SDQ meshes aligned to user-defined directions, while also incorporating desirable properties to the strips for fabrication.","meta":{"url":"http://arxiv.org/abs/2307.14020v1"},"cats":{"new-dataset":0.1100538205,"dev-research":0.3465824546,"prompt-eng":0.4286755699,"data-quality":0.0670382362,"ml-security":0.0269520833}}
{"text":"Our technique is based on the computation of two coupled transversal tangent direction fields, integrated into two overlapping networks of strips on the surface.","meta":{"url":"http://arxiv.org/abs/2307.14020v1"},"cats":{"new-dataset":0.0845381031,"dev-research":0.1853938428,"prompt-eng":0.374354317,"data-quality":0.0553032555,"ml-security":0.040023039}}
{"text":"As a case study, we consider the fabrication scenario of robotic non-planar 3D printing of freefrom shell surfaces and apply the presented methodology to design and fabricate non-planar print paths.","meta":{"url":"http://arxiv.org/abs/2307.14020v1"},"cats":{"new-dataset":0.0493560144,"dev-research":0.2466249677,"prompt-eng":0.3826608529,"data-quality":0.035757062,"ml-security":0.0349458048}}
{"text":"The precision of unsupervised point cloud registration methods is typically limited by the lack of reliable inlier estimation and self-supervised signal, especially in partially overlapping scenarios.","meta":{"url":"http://arxiv.org/abs/2307.14019v1"},"cats":{"new-dataset":0.1357435322,"dev-research":0.1794030675,"prompt-eng":0.3907515691,"data-quality":0.1935352478,"ml-security":0.0961663505}}
{"text":"In this paper, we propose an effective inlier estimation method for unsupervised point cloud registration by capturing geometric structure consistency between the source point cloud and its corresponding reference point cloud copy.","meta":{"url":"http://arxiv.org/abs/2307.14019v1"},"cats":{"new-dataset":0.2205481178,"dev-research":0.2286706495,"prompt-eng":0.3715501103,"data-quality":0.1729804819,"ml-security":0.0863626793}}
{"text":"Specifically, to obtain a high quality reference point cloud copy, an One-Nearest Neighborhood (1-NN) point cloud is generated by input point cloud.","meta":{"url":"http://arxiv.org/abs/2307.14019v1"},"cats":{"new-dataset":0.3762886159,"dev-research":0.2301744184,"prompt-eng":0.3867753859,"data-quality":0.1280120446,"ml-security":0.0426521546}}
{"text":"This facilitates matching map construction and allows for integrating dual neighborhood matching scores of 1-NN point cloud and input point cloud to improve matching confidence.","meta":{"url":"http://arxiv.org/abs/2307.14019v1"},"cats":{"new-dataset":0.2045845235,"dev-research":0.2266543273,"prompt-eng":0.4182760454,"data-quality":0.1762048096,"ml-security":0.0550808812}}
{"text":"Benefiting from the high quality reference copy, we argue that the neighborhood graph formed by inlier and its neighborhood should have consistency between source point cloud and its corresponding reference copy.","meta":{"url":"http://arxiv.org/abs/2307.14019v1"},"cats":{"new-dataset":0.4497719687,"dev-research":0.3041456108,"prompt-eng":0.3153275603,"data-quality":0.3459157574,"ml-security":0.1688545317}}
{"text":"Based on this observation, we construct transformation-invariant geometric structure representations and capture geometric structure consistency to score the inlier confidence for estimated correspondences between source point cloud and its reference copy.","meta":{"url":"http://arxiv.org/abs/2307.14019v1"},"cats":{"new-dataset":0.2143654197,"dev-research":0.2068597343,"prompt-eng":0.3730834739,"data-quality":0.2310770766,"ml-security":0.0934046191}}
{"text":"This strategy can simultaneously provide the reliable self-supervised signal for model optimization.","meta":{"url":"http://arxiv.org/abs/2307.14019v1"},"cats":{"new-dataset":0.0324607828,"dev-research":0.2282162062,"prompt-eng":0.473861723,"data-quality":0.277806236,"ml-security":0.1700683981}}
{"text":"Finally, we further calculate transformation estimation by the weighted SVD algorithm with the estimated correspondences and corresponding inlier confidence.","meta":{"url":"http://arxiv.org/abs/2307.14019v1"},"cats":{"new-dataset":0.209370726,"dev-research":0.1499771192,"prompt-eng":0.4202337472,"data-quality":0.2346127137,"ml-security":0.0788976135}}
{"text":"We train the proposed model in an unsupervised manner, and extensive experiments on synthetic and real-world datasets illustrate the effectiveness of the proposed method.","meta":{"url":"http://arxiv.org/abs/2307.14019v1"},"cats":{"new-dataset":0.4047076338,"dev-research":0.1691274167,"prompt-eng":0.4042991878,"data-quality":0.2262036606,"ml-security":0.1094082649}}
{"text":"Palmprint recently shows great potential in recognition applications as it is a privacy-friendly and stable biometric.","meta":{"url":"http://arxiv.org/abs/2307.14016v1"},"cats":{"new-dataset":0.0820577843,"dev-research":0.1850670708,"prompt-eng":0.3691648825,"data-quality":0.1271042326,"ml-security":0.2080879335}}
{"text":"However, the lack of large-scale public palmprint datasets limits further research and development of palmprint recognition.","meta":{"url":"http://arxiv.org/abs/2307.14016v1"},"cats":{"new-dataset":0.4752443371,"dev-research":0.1519938002,"prompt-eng":0.3211066399,"data-quality":0.1651816701,"ml-security":0.1458524942}}
{"text":"In this paper, we propose a novel realistic pseudo-palmprint generation (RPG) model to synthesize palmprints with massive identities.","meta":{"url":"http://arxiv.org/abs/2307.14016v1"},"cats":{"new-dataset":0.3181003869,"dev-research":0.2427331887,"prompt-eng":0.4004346949,"data-quality":0.1045597294,"ml-security":0.103566437}}
{"text":"We first introduce a conditional modulation generator to improve the intra-class diversity.","meta":{"url":"http://arxiv.org/abs/2307.14016v1"},"cats":{"new-dataset":0.0776222585,"dev-research":0.212231703,"prompt-eng":0.4490490871,"data-quality":0.1756092338,"ml-security":0.1314622248}}
{"text":"Then an identity-aware loss is proposed to ensure identity consistency against unpaired training.","meta":{"url":"http://arxiv.org/abs/2307.14016v1"},"cats":{"new-dataset":0.0204648689,"dev-research":0.2245937069,"prompt-eng":0.3818285216,"data-quality":0.5163439609,"ml-security":0.4411280661}}
{"text":"We further improve the B\\'ezier palm creases generation strategy to guarantee identity independence.","meta":{"url":"http://arxiv.org/abs/2307.14016v1"},"cats":{"new-dataset":0.1069040524,"dev-research":0.2600940623,"prompt-eng":0.4339842145,"data-quality":0.1773512968,"ml-security":0.1342193124}}
{"text":"Extensive experimental results demonstrate that synthetic pretraining significantly boosts the recognition model performance.","meta":{"url":"http://arxiv.org/abs/2307.14016v1"},"cats":{"new-dataset":0.0710758824,"dev-research":0.2631046119,"prompt-eng":0.4486810937,"data-quality":0.2175071462,"ml-security":0.1248115664}}
{"text":"For example, our model improves the state-of-the-art B\\'ezierPalm by more than $5\\%$ and $14\\%$ in terms of TAR@FAR=1e-6 under the $1:1$ and $1:3$ Open-set protocol.","meta":{"url":"http://arxiv.org/abs/2307.14016v1"},"cats":{"new-dataset":0.108829554,"dev-research":0.1849223609,"prompt-eng":0.4375810421,"data-quality":0.1216983405,"ml-security":0.1147871573}}
{"text":"When accessing only $10\\%$ of the real training data, our method still outperforms ArcFace with $100\\%$ real training data, indicating that we are closer to real-data-free palmprint recognition.","meta":{"url":"http://arxiv.org/abs/2307.14016v1"},"cats":{"new-dataset":0.2085629719,"dev-research":0.2383963527,"prompt-eng":0.3428839273,"data-quality":0.2635486597,"ml-security":0.2520138567}}
{"text":"Single hyperspectral image super-resolution (single-HSI-SR) aims to restore a high-resolution hyperspectral image from a low-resolution observation.","meta":{"url":"http://arxiv.org/abs/2307.14010v1"},"cats":{"new-dataset":0.0669225311,"dev-research":0.1539307028,"prompt-eng":0.3663015531,"data-quality":0.101536191,"ml-security":0.0404812588}}
{"text":"However, the prevailing CNN-based approaches have shown limitations in building long-range dependencies and capturing interaction information between spectral features.","meta":{"url":"http://arxiv.org/abs/2307.14010v1"},"cats":{"new-dataset":0.215758742,"dev-research":0.2643713992,"prompt-eng":0.3280047762,"data-quality":0.1551754693,"ml-security":0.1213595653}}
{"text":"This results in inadequate utilization of spectral information and artifacts after upsampling.","meta":{"url":"http://arxiv.org/abs/2307.14010v1"},"cats":{"new-dataset":0.0935743922,"dev-research":0.2214095628,"prompt-eng":0.3470959841,"data-quality":0.3615119454,"ml-security":0.0533387527}}
{"text":"To address this issue, we propose ESSAformer, an ESSA attention-embedded Transformer network for single-HSI-SR with an iterative refining structure.","meta":{"url":"http://arxiv.org/abs/2307.14010v1"},"cats":{"new-dataset":0.1311604595,"dev-research":0.2329042736,"prompt-eng":0.4282356789,"data-quality":0.1468924894,"ml-security":0.0615915222}}
{"text":"Specifically, we first introduce a robust and spectral-friendly similarity metric, \\ie, the spectral correlation coefficient of the spectrum (SCC), to replace the original attention matrix and incorporates inductive biases into the model to facilitate training.","meta":{"url":"http://arxiv.org/abs/2307.14010v1"},"cats":{"new-dataset":0.1811068581,"dev-research":0.1949307298,"prompt-eng":0.4133804189,"data-quality":0.2485707377,"ml-security":0.0564403027}}
{"text":"Built upon it, we further utilize the kernelizable attention technique with theoretical support to form a novel efficient SCC-kernel-based self-attention (ESSA) and reduce attention computation to linear complexity.","meta":{"url":"http://arxiv.org/abs/2307.14010v1"},"cats":{"new-dataset":0.0993427866,"dev-research":0.2536974931,"prompt-eng":0.4261196608,"data-quality":0.265538803,"ml-security":0.0922275683}}
{"text":"ESSA enlarges the receptive field for features after upsampling without bringing much computation and allows the model to effectively utilize spatial-spectral information from different scales, resulting in the generation of more natural high-resolution images.","meta":{"url":"http://arxiv.org/abs/2307.14010v1"},"cats":{"new-dataset":0.2183571703,"dev-research":0.1952610833,"prompt-eng":0.3425889274,"data-quality":0.1238853434,"ml-security":0.0905836854}}
{"text":"Without the need for pretraining on large-scale datasets, our experiments demonstrate ESSA's effectiveness in both visual quality and quantitative results.","meta":{"url":"http://arxiv.org/abs/2307.14010v1"},"cats":{"new-dataset":0.5220275659,"dev-research":0.2807432216,"prompt-eng":0.3579389437,"data-quality":0.2988546317,"ml-security":0.111085244}}
{"text":"Compositional neural scene graph studies have shown that radiance fields can be an efficient tool in an editable autonomous driving simulator.","meta":{"url":"http://arxiv.org/abs/2307.14009v1"},"cats":{"new-dataset":0.2189904088,"dev-research":0.2654595389,"prompt-eng":0.3672449701,"data-quality":0.138073717,"ml-security":0.1032022535}}
{"text":"However, previous studies learned within a sequence of autonomous driving datasets, resulting in unsatisfactory blurring when rotating the car in the simulator.","meta":{"url":"http://arxiv.org/abs/2307.14009v1"},"cats":{"new-dataset":0.1717179783,"dev-research":0.2617257791,"prompt-eng":0.3163049157,"data-quality":0.1870288456,"ml-security":0.155561094}}
{"text":"In this letter, we propose a pipeline for learning unconstrained images and building a dataset from processed images.","meta":{"url":"http://arxiv.org/abs/2307.14009v1"},"cats":{"new-dataset":0.5756909297,"dev-research":0.1748477266,"prompt-eng":0.3566795912,"data-quality":0.1698787384,"ml-security":0.097642643}}
{"text":"To meet the requirements of the simulator, which demands that the vehicle maintain clarity when the perspective changes and that the contour remains sharp from the background to avoid artifacts when editing, we design a radiation field of the vehicle, a crucial part of the urban scene foreground.","meta":{"url":"http://arxiv.org/abs/2307.14009v1"},"cats":{"new-dataset":0.3124812783,"dev-research":0.2703828071,"prompt-eng":0.427614749,"data-quality":0.1005335513,"ml-security":0.0919983631}}
{"text":"Through experiments, we demonstrate that our model achieves competitive performance compared to baselines.","meta":{"url":"http://arxiv.org/abs/2307.14009v1"},"cats":{"new-dataset":0.0239387426,"dev-research":0.2250773805,"prompt-eng":0.4246483423,"data-quality":0.1415170042,"ml-security":0.080327143}}
{"text":"Using the datasets built from in-the-wild images, our method gradually presents a controllable appearance editing function.","meta":{"url":"http://arxiv.org/abs/2307.14009v1"},"cats":{"new-dataset":0.4266639269,"dev-research":0.2502284468,"prompt-eng":0.4285728669,"data-quality":0.1759359891,"ml-security":0.0785733672}}
{"text":"We will release the dataset and code on https://lty2226262.github.io/car-studio/ to facilitate further research in the field.","meta":{"url":"http://arxiv.org/abs/2307.14009v1"},"cats":{"new-dataset":0.7977367533,"dev-research":0.1521288157,"prompt-eng":0.3853982832,"data-quality":0.1225225873,"ml-security":0.0411999334}}
{"text":"Recent vision transformers, large-kernel CNNs and MLPs have attained remarkable successes in broad vision tasks thanks to their effective information fusion in the global scope.","meta":{"url":"http://arxiv.org/abs/2307.14008v1"},"cats":{"new-dataset":0.1596023071,"dev-research":0.2007437548,"prompt-eng":0.3513465353,"data-quality":0.1489986274,"ml-security":0.1365408265}}
{"text":"However, their efficient deployments, especially on mobile devices, still suffer from noteworthy challenges due to the heavy computational costs of self-attention mechanisms, large kernels, or fully connected layers.","meta":{"url":"http://arxiv.org/abs/2307.14008v1"},"cats":{"new-dataset":0.1341394757,"dev-research":0.2707221308,"prompt-eng":0.4408100959,"data-quality":0.1854184238,"ml-security":0.1425679595}}
{"text":"In this work, we apply conventional convolution theorem to deep learning for addressing this and reveal that adaptive frequency filters can serve as efficient global token mixers.","meta":{"url":"http://arxiv.org/abs/2307.14008v1"},"cats":{"new-dataset":0.1064300806,"dev-research":0.2553127681,"prompt-eng":0.313520374,"data-quality":0.2331769383,"ml-security":0.1559441643}}
{"text":"With this insight, we propose Adaptive Frequency Filtering (AFF) token mixer.","meta":{"url":"http://arxiv.org/abs/2307.14008v1"},"cats":{"new-dataset":0.0445019556,"dev-research":0.2675469818,"prompt-eng":0.4138451167,"data-quality":0.2218718463,"ml-security":0.0554986859}}
{"text":"This neural operator transfers a latent representation to the frequency domain via a Fourier transform and performs semantic-adaptive frequency filtering via an elementwise multiplication, which mathematically equals to a token mixing operation in the original latent space with a dynamic convolution kernel as large as the spatial resolution of this latent representation.","meta":{"url":"http://arxiv.org/abs/2307.14008v1"},"cats":{"new-dataset":0.0850422644,"dev-research":0.2248044195,"prompt-eng":0.3262597784,"data-quality":0.1679957112,"ml-security":0.0928831411}}
{"text":"We take AFF token mixers as primary neural operators to build a lightweight neural network, dubbed AFFNet.","meta":{"url":"http://arxiv.org/abs/2307.14008v1"},"cats":{"new-dataset":0.2907508101,"dev-research":0.254279656,"prompt-eng":0.3956838885,"data-quality":0.1806424427,"ml-security":0.138040998}}
{"text":"Extensive experiments demonstrate the effectiveness of our proposed AFF token mixer and show that AFFNet achieve superior accuracy and efficiency trade-offs compared to other lightweight network designs on broad visual tasks, including visual recognition and dense prediction tasks.","meta":{"url":"http://arxiv.org/abs/2307.14008v1"},"cats":{"new-dataset":0.1999158195,"dev-research":0.297278953,"prompt-eng":0.3671406279,"data-quality":0.2250374739,"ml-security":0.1018677556}}
{"text":"Existing Graph Convolutional Networks to achieve human motion prediction largely adopt a one-step scheme, which output the prediction straight from history input, failing to exploit human motion patterns.","meta":{"url":"http://arxiv.org/abs/2307.14006v1"},"cats":{"new-dataset":0.227303961,"dev-research":0.2277756921,"prompt-eng":0.2910122684,"data-quality":0.111598719,"ml-security":0.1175926935}}
{"text":"We observe that human motions have transitional patterns and can be split into snippets representative of each transition.","meta":{"url":"http://arxiv.org/abs/2307.14006v1"},"cats":{"new-dataset":0.2187072529,"dev-research":0.2113133416,"prompt-eng":0.3994330558,"data-quality":0.089046152,"ml-security":0.0442807767}}
{"text":"Each snippet can be reconstructed from its starting and ending poses referred to as the transitional poses.","meta":{"url":"http://arxiv.org/abs/2307.14006v1"},"cats":{"new-dataset":0.3607099637,"dev-research":0.2097564958,"prompt-eng":0.3726757681,"data-quality":0.117167794,"ml-security":0.0646417995}}
{"text":"We propose a snippet-to-motion multi-stage framework that breaks motion prediction into sub-tasks easier to accomplish.","meta":{"url":"http://arxiv.org/abs/2307.14006v1"},"cats":{"new-dataset":0.2954070691,"dev-research":0.2379167927,"prompt-eng":0.3746672911,"data-quality":0.0843630242,"ml-security":0.0594333485}}
{"text":"Each sub-task integrates three modules: transitional pose prediction, snippet reconstruction, and snippet-to-motion prediction.","meta":{"url":"http://arxiv.org/abs/2307.14006v1"},"cats":{"new-dataset":0.3478050513,"dev-research":0.2129551792,"prompt-eng":0.371393467,"data-quality":0.0835533713,"ml-security":0.0503862445}}
{"text":"Specifically, we propose to first predict only the transitional poses.","meta":{"url":"http://arxiv.org/abs/2307.14006v1"},"cats":{"new-dataset":0.120882809,"dev-research":0.1627004463,"prompt-eng":0.3915577929,"data-quality":0.091492698,"ml-security":0.1098198853}}
{"text":"Then we use them to reconstruct the corresponding snippets, obtaining a close approximation to the true motion sequence.","meta":{"url":"http://arxiv.org/abs/2307.14006v1"},"cats":{"new-dataset":0.0990075986,"dev-research":0.2441550642,"prompt-eng":0.3626350747,"data-quality":0.1240193409,"ml-security":0.0712259687}}
{"text":"Finally we refine them to produce the final prediction output.","meta":{"url":"http://arxiv.org/abs/2307.14006v1"},"cats":{"new-dataset":0.1601357017,"dev-research":0.2773655867,"prompt-eng":0.4305184179,"data-quality":0.2554574563,"ml-security":0.1349868273}}
{"text":"To implement the network, we propose a novel unified graph modeling, which allows for direct and effective feature propagation compared to existing approaches which rely on separate space-time modeling.","meta":{"url":"http://arxiv.org/abs/2307.14006v1"},"cats":{"new-dataset":0.101195943,"dev-research":0.2988527825,"prompt-eng":0.352939448,"data-quality":0.1755733289,"ml-security":0.1038520937}}
{"text":"Extensive experiments on Human 3.6M, CMU Mocap and 3DPW datasets verify the effectiveness of our method which achieves state-of-the-art performance.","meta":{"url":"http://arxiv.org/abs/2307.14006v1"},"cats":{"new-dataset":0.1796259494,"dev-research":0.2028305926,"prompt-eng":0.4290680152,"data-quality":0.1029438099,"ml-security":0.0608313103}}
{"text":"We propose an unsupervised, corpus-independent method to extract keywords from a single text.","meta":{"url":"http://arxiv.org/abs/2307.14005v1"},"cats":{"new-dataset":0.1439381738,"dev-research":0.1819003567,"prompt-eng":0.4095887461,"data-quality":0.3099956423,"ml-security":0.0740774479}}
{"text":"It is based on the spatial distribution of words and the response of this distribution to a random permutation of words.","meta":{"url":"http://arxiv.org/abs/2307.14005v1"},"cats":{"new-dataset":0.1282302905,"dev-research":0.1497566474,"prompt-eng":0.3936587975,"data-quality":0.1813654869,"ml-security":0.067597685}}
{"text":"As compared to existing methods (such as e.g. YAKE)","meta":{"url":"http://arxiv.org/abs/2307.14005v1"},"cats":{"new-dataset":0.0102349257,"dev-research":0.3685334198,"prompt-eng":0.4065983349,"data-quality":0.1278673067,"ml-security":0.0725027969}}
{"text":"our method has three advantages.","meta":{"url":"http://arxiv.org/abs/2307.14005v1"},"cats":{"new-dataset":0.0096039859,"dev-research":0.3320539376,"prompt-eng":0.3411592133,"data-quality":0.0997288807,"ml-security":0.0965380319}}
{"text":"First, it is significantly more effective at extracting keywords from long texts.","meta":{"url":"http://arxiv.org/abs/2307.14005v1"},"cats":{"new-dataset":0.0310688624,"dev-research":0.2452175124,"prompt-eng":0.3439882484,"data-quality":0.2044336747,"ml-security":0.0627322632}}
{"text":"Second, it allows inference of two types of keywords: local and global.","meta":{"url":"http://arxiv.org/abs/2307.14005v1"},"cats":{"new-dataset":0.022286249,"dev-research":0.3194284054,"prompt-eng":0.3766410127,"data-quality":0.185338084,"ml-security":0.0727740872}}
{"text":"Third, it uncovers basic themes in texts.","meta":{"url":"http://arxiv.org/abs/2307.14005v1"},"cats":{"new-dataset":0.1191696752,"dev-research":0.3340767019,"prompt-eng":0.3556600526,"data-quality":0.1598816778,"ml-security":0.0857353625}}
{"text":"Additionally, our method is language-independent and applies to short texts.","meta":{"url":"http://arxiv.org/abs/2307.14005v1"},"cats":{"new-dataset":0.0671926101,"dev-research":0.2976655398,"prompt-eng":0.3662716722,"data-quality":0.2634680065,"ml-security":0.0701448383}}
{"text":"The results are obtained via human annotators with previous knowledge of texts from our database of classical literary works (the agreement between annotators is from moderate to substantial).","meta":{"url":"http://arxiv.org/abs/2307.14005v1"},"cats":{"new-dataset":0.4532129381,"dev-research":0.2202479285,"prompt-eng":0.3857879522,"data-quality":0.3609624315,"ml-security":0.0781314556}}
{"text":"Our results are supported via human-independent arguments based on the average length of extracted content words and on the average number of nouns in extracted words.","meta":{"url":"http://arxiv.org/abs/2307.14005v1"},"cats":{"new-dataset":0.1746596118,"dev-research":0.1879931393,"prompt-eng":0.4135021484,"data-quality":0.2952742353,"ml-security":0.1020949155}}
{"text":"We discuss relations of keywords with higher-order textual features and reveal a connection between keywords and chapter divisions.","meta":{"url":"http://arxiv.org/abs/2307.14005v1"},"cats":{"new-dataset":0.1497704146,"dev-research":0.2573672464,"prompt-eng":0.3962175814,"data-quality":0.2726693432,"ml-security":0.1134606881}}
{"text":"Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions.","meta":{"url":"http://arxiv.org/abs/2307.14004v1"},"cats":{"new-dataset":0.0946830875,"dev-research":0.2647322382,"prompt-eng":0.3799574652,"data-quality":0.1634850958,"ml-security":0.087259022}}
{"text":"This is appropriate when the goal is to create explicit emotion statements (\"The kid is happy.\").","meta":{"url":"http://arxiv.org/abs/2307.14004v1"},"cats":{"new-dataset":0.0523186844,"dev-research":0.3479614451,"prompt-eng":0.4169725138,"data-quality":0.2690550647,"ml-security":0.1133826078}}
{"text":"Emotions are, however, commonly communicated implicitly.","meta":{"url":"http://arxiv.org/abs/2307.14004v1"},"cats":{"new-dataset":0.0180004382,"dev-research":0.4119453687,"prompt-eng":0.3390857983,"data-quality":0.2414672075,"ml-security":0.1204595359}}
{"text":"For instance, the emotional interpretation of an event (\"Their dog died.\") does often not require an explicit emotion statement.","meta":{"url":"http://arxiv.org/abs/2307.14004v1"},"cats":{"new-dataset":0.0171340194,"dev-research":0.3434022426,"prompt-eng":0.3639476209,"data-quality":0.2857518553,"ml-security":0.1099123829}}
{"text":"In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion.","meta":{"url":"http://arxiv.org/abs/2307.14004v1"},"cats":{"new-dataset":0.00782326,"dev-research":0.3834510575,"prompt-eng":0.3954636771,"data-quality":0.134686878,"ml-security":0.1018676702}}
{"text":"They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens.","meta":{"url":"http://arxiv.org/abs/2307.14004v1"},"cats":{"new-dataset":0.0776282083,"dev-research":0.3141585427,"prompt-eng":0.4011980347,"data-quality":0.1503903847,"ml-security":0.1628584673}}
{"text":"We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages.","meta":{"url":"http://arxiv.org/abs/2307.14004v1"},"cats":{"new-dataset":0.0683540261,"dev-research":0.3772659115,"prompt-eng":0.4300572163,"data-quality":0.1302346112,"ml-security":0.0819315546}}
{"text":"(1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has.","meta":{"url":"http://arxiv.org/abs/2307.14004v1"},"cats":{"new-dataset":0.052092895,"dev-research":0.3152770273,"prompt-eng":0.3754531378,"data-quality":0.1318437485,"ml-security":0.1010277675}}
{"text":"This leads to text generation that better fulfills the condition.","meta":{"url":"http://arxiv.org/abs/2307.14004v1"},"cats":{"new-dataset":0.0379032113,"dev-research":0.3936069763,"prompt-eng":0.4364507761,"data-quality":0.3088426271,"ml-security":0.0982293362}}
{"text":"(2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category.","meta":{"url":"http://arxiv.org/abs/2307.14004v1"},"cats":{"new-dataset":0.0259679313,"dev-research":0.3987889105,"prompt-eng":0.4118620041,"data-quality":0.1730034723,"ml-security":0.1160653124}}
{"text":"Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1.","meta":{"url":"http://arxiv.org/abs/2307.14004v1"},"cats":{"new-dataset":0.1184932015,"dev-research":0.3424982841,"prompt-eng":0.4085721018,"data-quality":0.2703794998,"ml-security":0.1380051588}}
{"text":"Further, (2) the texts with appraisal variables are longer and contain more details.","meta":{"url":"http://arxiv.org/abs/2307.14004v1"},"cats":{"new-dataset":0.1584460395,"dev-research":0.2704150085,"prompt-eng":0.3283185696,"data-quality":0.1319613785,"ml-security":0.0431719591}}
{"text":"This exemplifies the greater control for users.","meta":{"url":"http://arxiv.org/abs/2307.14004v1"},"cats":{"new-dataset":0.0204126944,"dev-research":0.5009917475,"prompt-eng":0.4216847666,"data-quality":0.1471184247,"ml-security":0.249094862}}
{"text":"In this paper, we apply a Threshold-Decreasing Algorithm to maximize $k$-submodular functions under a matroid constraint, which reduces the query complexity of the algorithm compared to the greedy algorithm with little loss in approximation ratio.","meta":{"url":"http://arxiv.org/abs/2307.13996v1"},"cats":{"new-dataset":0.0763505023,"dev-research":0.1888705844,"prompt-eng":0.3552777972,"data-quality":0.1373969603,"ml-security":0.1276512902}}
{"text":"We give a $(\\frac{1}{2} - \\epsilon)$-approximation algorithm for monotone $k$-submodular function maximization, and a $(\\frac{1}{3} - \\epsilon)$-approximation algorithm for non-monotone case, with complexity $O(\\frac{n(k\\cdot EO + IO)}{\\epsilon} \\log \\frac{r}{\\epsilon})$, where $r$ denotes the rank of the matroid, and $IO, EO$ denote the number of oracles to evaluate whether a subset is an independent set and to compute the function value of $f$, respectively.","meta":{"url":"http://arxiv.org/abs/2307.13996v1"},"cats":{"new-dataset":0.1380216481,"dev-research":0.181575167,"prompt-eng":0.3432701184,"data-quality":0.2010993109,"ml-security":0.1177093614}}
{"text":"Since the constraint of total size can be looked as a special matroid, called uniform matroid, then we present the fast algorithm for maximizing $k$-submodular functions subject to a total size constraint as corollaries.","meta":{"url":"http://arxiv.org/abs/2307.13996v1"},"cats":{"new-dataset":0.2550385932,"dev-research":0.1772884927,"prompt-eng":0.3204478622,"data-quality":0.1271646785,"ml-security":0.1144901072}}
{"text":"corollaries.","meta":{"url":"http://arxiv.org/abs/2307.13996v1"},"cats":{"new-dataset":0.3497943434,"dev-research":0.2847932317,"prompt-eng":0.3481239804,"data-quality":0.1335322775,"ml-security":0.0860875498}}
{"text":"Personalized federated learning (PFL) is a popular framework that allows clients to have different models to address application scenarios where clients' data are in different domains.","meta":{"url":"http://arxiv.org/abs/2307.13995v1"},"cats":{"new-dataset":0.0748959369,"dev-research":0.233472667,"prompt-eng":0.4080442993,"data-quality":0.1207745425,"ml-security":0.1612516848}}
{"text":"The typical model of a client in PFL features a global encoder trained by all clients to extract universal features from the raw data and personalized layers (e.g., a classifier) trained using the client's local data.","meta":{"url":"http://arxiv.org/abs/2307.13995v1"},"cats":{"new-dataset":0.0975361387,"dev-research":0.2599204157,"prompt-eng":0.377514598,"data-quality":0.1354152,"ml-security":0.1309358582}}
{"text":"Nonetheless, due to the differences between the data distributions of different clients (aka, domain gaps), the universal features produced by the global encoder largely encompass numerous components irrelevant to a certain client's local task.","meta":{"url":"http://arxiv.org/abs/2307.13995v1"},"cats":{"new-dataset":0.0808090581,"dev-research":0.2935514771,"prompt-eng":0.3866221402,"data-quality":0.1763933148,"ml-security":0.1008724127}}
{"text":"Some recent PFL methods address the above problem by personalizing specific parameters within the encoder.","meta":{"url":"http://arxiv.org/abs/2307.13995v1"},"cats":{"new-dataset":0.1272033214,"dev-research":0.1517897978,"prompt-eng":0.4559898032,"data-quality":0.2442850046,"ml-security":0.0898202759}}
{"text":"However, these methods encounter substantial challenges attributed to the high dimensionality and non-linearity of neural network parameter space.","meta":{"url":"http://arxiv.org/abs/2307.13995v1"},"cats":{"new-dataset":0.0366965695,"dev-research":0.2061494063,"prompt-eng":0.3564580809,"data-quality":0.2335308926,"ml-security":0.2163269008}}
{"text":"In contrast, the feature space exhibits a lower dimensionality, providing greater intuitiveness and interpretability as compared to the parameter space.","meta":{"url":"http://arxiv.org/abs/2307.13995v1"},"cats":{"new-dataset":0.0097300851,"dev-research":0.3148871569,"prompt-eng":0.3238642374,"data-quality":0.1476601258,"ml-security":0.13668403}}
{"text":"To this end, we propose a novel PFL framework named FedPick.","meta":{"url":"http://arxiv.org/abs/2307.13995v1"},"cats":{"new-dataset":0.3436496216,"dev-research":0.2375129207,"prompt-eng":0.4358949657,"data-quality":0.1242812195,"ml-security":0.0788553649}}
{"text":"FedPick achieves PFL in the low-dimensional feature space by selecting task-relevant features adaptively for each client from the features generated by the global encoder based on its local data distribution.","meta":{"url":"http://arxiv.org/abs/2307.13995v1"},"cats":{"new-dataset":0.2302086048,"dev-research":0.2874082027,"prompt-eng":0.4073241919,"data-quality":0.1295699083,"ml-security":0.1140402522}}
{"text":"It presents a more accessible and interpretable implementation of PFL compared to those methods working in the parameter space.","meta":{"url":"http://arxiv.org/abs/2307.13995v1"},"cats":{"new-dataset":0.0971059853,"dev-research":0.2883466115,"prompt-eng":0.4346912541,"data-quality":0.1164998165,"ml-security":0.0526105312}}
{"text":"Extensive experimental results show that FedPick could effectively select task-relevant features for each client and improve model performance in cross-domain FL.","meta":{"url":"http://arxiv.org/abs/2307.13995v1"},"cats":{"new-dataset":0.1128152327,"dev-research":0.3423665421,"prompt-eng":0.4425152612,"data-quality":0.1102935857,"ml-security":0.0886434054}}
{"text":"There is a critical need to develop and validate non-invasive animal-based indicators of affective states in livestock species, in order to integrate them into on-farm assessment protocols, potentially via the use of precision livestock farming (PLF) tools.","meta":{"url":"http://arxiv.org/abs/2307.13994v1"},"cats":{"new-dataset":0.0961862054,"dev-research":0.2422907011,"prompt-eng":0.4578016325,"data-quality":0.1480562901,"ml-security":0.0871036434}}
{"text":"One such promising approach is the use of vocal indicators.","meta":{"url":"http://arxiv.org/abs/2307.13994v1"},"cats":{"new-dataset":0.0808885356,"dev-research":0.22695132,"prompt-eng":0.4637234339,"data-quality":0.2836707941,"ml-security":0.0937465818}}
{"text":"The acoustic structure of vocalizations and their functions were extensively studied in important livestock species, such as pigs, horses, poultry and goats, yet cattle remain understudied in this context to date.","meta":{"url":"http://arxiv.org/abs/2307.13994v1"},"cats":{"new-dataset":0.1458069696,"dev-research":0.1759252262,"prompt-eng":0.3446622241,"data-quality":0.1763663771,"ml-security":0.0971710134}}
{"text":"Cows were shown to produce two types vocalizations: low-frequency calls (LF), produced with the mouth closed, or partially closed, for close distance contacts and open mouth emitted high-frequency calls (HF), produced for long distance communication, with the latter considered to be largely associated with negative affective states.","meta":{"url":"http://arxiv.org/abs/2307.13994v1"},"cats":{"new-dataset":0.2288255676,"dev-research":0.2113230286,"prompt-eng":0.3737093755,"data-quality":0.2220268868,"ml-security":0.0706369328}}
{"text":"Moreover, cattle vocalizations were shown to contain information on individuality across a wide range of contexts, both negative and positive.","meta":{"url":"http://arxiv.org/abs/2307.13994v1"},"cats":{"new-dataset":0.1133504559,"dev-research":0.231593614,"prompt-eng":0.3745790413,"data-quality":0.2993220735,"ml-security":0.1110968}}
{"text":"Nowadays, dairy cows are facing a series of negative challenges and stressors in a typical production cycle, making vocalizations during negative affective states of special interest for research.","meta":{"url":"http://arxiv.org/abs/2307.13994v1"},"cats":{"new-dataset":0.1026815393,"dev-research":0.3498557234,"prompt-eng":0.3881518388,"data-quality":0.2775747009,"ml-security":0.1283907643}}
{"text":"One contribution of this study is providing the largest to date pre-processed (clean from noises) dataset of lactating adult multiparous dairy cows during negative affective states induced by visual isolation challenges.","meta":{"url":"http://arxiv.org/abs/2307.13994v1"},"cats":{"new-dataset":0.1986794019,"dev-research":0.2539564955,"prompt-eng":0.3874874322,"data-quality":0.2317856706,"ml-security":0.1147612451}}
{"text":"Here we present two computational frameworks - deep learning based and explainable machine learning based, to classify high and low-frequency cattle calls, and individual cow voice recognition.","meta":{"url":"http://arxiv.org/abs/2307.13994v1"},"cats":{"new-dataset":0.5194234729,"dev-research":0.1653188552,"prompt-eng":0.3509585266,"data-quality":0.2352812949,"ml-security":0.1711090509}}
{"text":"Our models in these two frameworks reached 87.2% and 89.4% accuracy for LF and HF classification, with 68.9% and 72.5% accuracy rates for the cow individual identification, respectively.","meta":{"url":"http://arxiv.org/abs/2307.13994v1"},"cats":{"new-dataset":0.2602928887,"dev-research":0.1174758719,"prompt-eng":0.4114050094,"data-quality":0.3092770783,"ml-security":0.0584337549}}
{"text":"Deep learning has revolutionized the field of artificial intelligence.","meta":{"url":"http://arxiv.org/abs/2307.13992v1"},"cats":{"new-dataset":0.0628778425,"dev-research":0.1869915643,"prompt-eng":0.3031219738,"data-quality":0.1093080868,"ml-security":0.1603194264}}
{"text":"Based on the statistical correlations uncovered by deep learning-based methods, computer vision technology has contributed to tremendous growth in areas such as autonomous driving and robotics.","meta":{"url":"http://arxiv.org/abs/2307.13992v1"},"cats":{"new-dataset":0.1458872852,"dev-research":0.2692734742,"prompt-eng":0.3319298658,"data-quality":0.1579554246,"ml-security":0.1504187277}}
{"text":"Despite being the basis of deep learning, such correlation is not stable and is susceptible to uncontrolled factors.","meta":{"url":"http://arxiv.org/abs/2307.13992v1"},"cats":{"new-dataset":0.0300289072,"dev-research":0.2163756536,"prompt-eng":0.3214310649,"data-quality":0.252102725,"ml-security":0.1702245108}}
{"text":"In the absence of the guidance of prior knowledge, statistical correlations can easily turn into spurious correlations and cause confounders.","meta":{"url":"http://arxiv.org/abs/2307.13992v1"},"cats":{"new-dataset":0.0127107986,"dev-research":0.367887925,"prompt-eng":0.3819404476,"data-quality":0.3485173449,"ml-security":0.4095202481}}
{"text":"As a result, researchers are beginning to refine deep learning-based methods with causal theory.","meta":{"url":"http://arxiv.org/abs/2307.13992v1"},"cats":{"new-dataset":0.0246534979,"dev-research":0.3191676515,"prompt-eng":0.333518777,"data-quality":0.2263307285,"ml-security":0.2551728424}}
{"text":"Causal theory models the intrinsic causal structure unaffected by data bias and is effective in avoiding spurious correlations.","meta":{"url":"http://arxiv.org/abs/2307.13992v1"},"cats":{"new-dataset":0.0061269462,"dev-research":0.2493915203,"prompt-eng":0.3514172937,"data-quality":0.2549563563,"ml-security":0.2645336849}}
{"text":"This paper aims to comprehensively review the existing causal methods in typical vision and vision-language tasks such as semantic segmentation, object detection, and image captioning.","meta":{"url":"http://arxiv.org/abs/2307.13992v1"},"cats":{"new-dataset":0.0550049185,"dev-research":0.2824602657,"prompt-eng":0.4362107856,"data-quality":0.3614412293,"ml-security":0.13982964}}
{"text":"The advantages of causality and the approaches for building causal paradigms will be summarized.","meta":{"url":"http://arxiv.org/abs/2307.13992v1"},"cats":{"new-dataset":0.0147653467,"dev-research":0.386018027,"prompt-eng":0.3710838622,"data-quality":0.1045160242,"ml-security":0.1558436107}}
{"text":"Future roadmaps are also proposed, including facilitating the development of causal theory and its application in other complex scenes and systems.","meta":{"url":"http://arxiv.org/abs/2307.13992v1"},"cats":{"new-dataset":0.0753014968,"dev-research":0.347796281,"prompt-eng":0.4109117906,"data-quality":0.116104533,"ml-security":0.0993699861}}
{"text":"Autonomous navigation in off-road conditions requires an accurate estimation of terrain traversability.","meta":{"url":"http://arxiv.org/abs/2307.13991v1"},"cats":{"new-dataset":0.0514691192,"dev-research":0.2246511672,"prompt-eng":0.3791979818,"data-quality":0.0905277052,"ml-security":0.072587455}}
{"text":"However, traversability estimation in unstructured environments is subject to high uncertainty due to the variability of numerous factors that influence vehicle-terrain interaction.","meta":{"url":"http://arxiv.org/abs/2307.13991v1"},"cats":{"new-dataset":0.0836640057,"dev-research":0.2315985354,"prompt-eng":0.3747976341,"data-quality":0.1153532971,"ml-security":0.0746660984}}
{"text":"Consequently, it is challenging to obtain a generalizable model that can accurately predict traversability in a variety of environments.","meta":{"url":"http://arxiv.org/abs/2307.13991v1"},"cats":{"new-dataset":0.0542314377,"dev-research":0.2428038223,"prompt-eng":0.4393042204,"data-quality":0.1223455862,"ml-security":0.2009766854}}
{"text":"This paper presents METAVerse, a meta-learning framework for learning a global model that accurately and reliably predicts terrain traversability across diverse environments.","meta":{"url":"http://arxiv.org/abs/2307.13991v1"},"cats":{"new-dataset":0.218951142,"dev-research":0.2319341838,"prompt-eng":0.3822259185,"data-quality":0.1059423184,"ml-security":0.1171707988}}
{"text":"We train the traversability prediction network to generate a dense and continuous-valued cost map from a sparse LiDAR point cloud, leveraging vehicle-terrain interaction feedback in a self-supervised manner.","meta":{"url":"http://arxiv.org/abs/2307.13991v1"},"cats":{"new-dataset":0.1906861733,"dev-research":0.2676066079,"prompt-eng":0.3793646923,"data-quality":0.1458081283,"ml-security":0.1306903395}}
{"text":"Meta-learning is utilized to train a global model with driving data collected from multiple environments, effectively minimizing estimation uncertainty.","meta":{"url":"http://arxiv.org/abs/2307.13991v1"},"cats":{"new-dataset":0.1498318745,"dev-research":0.2586302342,"prompt-eng":0.3951574385,"data-quality":0.2046574142,"ml-security":0.1411376801}}
{"text":"During deployment, online adaptation is performed to rapidly adapt the network to the local environment by exploiting recent interaction experiences.","meta":{"url":"http://arxiv.org/abs/2307.13991v1"},"cats":{"new-dataset":0.0593465214,"dev-research":0.4265741133,"prompt-eng":0.4534835813,"data-quality":0.1860498342,"ml-security":0.1262010392}}
{"text":"To conduct a comprehensive evaluation, we collect driving data from various terrains and demonstrate that our method can obtain a global model that minimizes uncertainty.","meta":{"url":"http://arxiv.org/abs/2307.13991v1"},"cats":{"new-dataset":0.2994900373,"dev-research":0.2500606344,"prompt-eng":0.3930388695,"data-quality":0.107188473,"ml-security":0.0811233882}}
{"text":"Moreover, by integrating our model with a model predictive controller, we demonstrate that the reduced uncertainty results in safe and stable navigation in unstructured and unknown terrains.","meta":{"url":"http://arxiv.org/abs/2307.13991v1"},"cats":{"new-dataset":0.1484353136,"dev-research":0.2118336736,"prompt-eng":0.3772410551,"data-quality":0.095591377,"ml-security":0.1794582305}}
{"text":"Large language models underestimate the impact of negations on how much they change the meaning of a sentence.","meta":{"url":"http://arxiv.org/abs/2307.13989v1"},"cats":{"new-dataset":0.0394777542,"dev-research":0.2693226602,"prompt-eng":0.3505046618,"data-quality":0.3278255784,"ml-security":0.1647405942}}
{"text":"Therefore, learned evaluation metrics based on these models are insensitive to negations.","meta":{"url":"http://arxiv.org/abs/2307.13989v1"},"cats":{"new-dataset":0.0461645761,"dev-research":0.3158953782,"prompt-eng":0.383717695,"data-quality":0.3963702617,"ml-security":0.1507866472}}
{"text":"In this paper, we propose NegBLEURT, a negation-aware version of the BLEURT evaluation metric.","meta":{"url":"http://arxiv.org/abs/2307.13989v1"},"cats":{"new-dataset":0.1157199163,"dev-research":0.3377040051,"prompt-eng":0.4523449259,"data-quality":0.4212041355,"ml-security":0.1085188142}}
{"text":"For that, we designed a rule-based sentence negation tool and used it to create the CANNOT negation evaluation dataset.","meta":{"url":"http://arxiv.org/abs/2307.13989v1"},"cats":{"new-dataset":0.3044799061,"dev-research":0.3039147293,"prompt-eng":0.3847738792,"data-quality":0.3751556463,"ml-security":0.1157020416}}
{"text":"Based on this dataset, we fine-tuned a sentence transformer and an evaluation metric to improve their negation sensitivity.","meta":{"url":"http://arxiv.org/abs/2307.13989v1"},"cats":{"new-dataset":0.1923234017,"dev-research":0.2621996409,"prompt-eng":0.4371041484,"data-quality":0.4025916547,"ml-security":0.1128040524}}
{"text":"Evaluating these models on existing benchmarks shows that our fine-tuned models outperform existing metrics on the negated sentences by far while preserving their base models' performances on other perturbations.","meta":{"url":"http://arxiv.org/abs/2307.13989v1"},"cats":{"new-dataset":0.109659645,"dev-research":0.2372824695,"prompt-eng":0.3787511037,"data-quality":0.3854950049,"ml-security":0.1269959995}}
{"text":"In this work, we consider the problem of distributed computing of functions of structured sources, focusing on the classical setting of two correlated sources and one user that seeks the outcome of the function while benefiting from low-rate side information provided by a helper node.","meta":{"url":"http://arxiv.org/abs/2307.13987v1"},"cats":{"new-dataset":0.1812671856,"dev-research":0.2377613034,"prompt-eng":0.3972476102,"data-quality":0.1831095804,"ml-security":0.1182915289}}
{"text":"Focusing on the case where the sources are jointly distributed according to a very general mixture model, we here provide an achievable coding scheme that manages to substantially reduce the communication cost of distributed computing by exploiting the nature of the joint distribution of the sources, the side information, as well as the symmetry enjoyed by the desired functions.","meta":{"url":"http://arxiv.org/abs/2307.13987v1"},"cats":{"new-dataset":0.1494255772,"dev-research":0.2110860215,"prompt-eng":0.3906348326,"data-quality":0.1758213374,"ml-security":0.1241022294}}
{"text":"Our scheme -- which can readily apply in a variety of real-life scenarios including learning, combinatorics, and graph neural network applications -- is here shown to provide substantial reductions in the communication costs, while simultaneously providing computational savings by reducing the exponential complexity of joint decoding techniques to a complexity that is merely linear.","meta":{"url":"http://arxiv.org/abs/2307.13987v1"},"cats":{"new-dataset":0.1099143936,"dev-research":0.2088799267,"prompt-eng":0.3216053597,"data-quality":0.1769097284,"ml-security":0.2070544332}}
{"text":"Deep neural networks (DNNs) are well known to be vulnerable to adversarial examples (AEs).","meta":{"url":"http://arxiv.org/abs/2307.13985v1"},"cats":{"new-dataset":0.1314345344,"dev-research":0.2716492206,"prompt-eng":0.3339593373,"data-quality":0.3349003046,"ml-security":0.8436690091}}
{"text":"In addition, AEs have adversarial transferability, which means AEs generated for a source model can fool another black-box model (target model) with a non-trivial probability.","meta":{"url":"http://arxiv.org/abs/2307.13985v1"},"cats":{"new-dataset":0.0049250422,"dev-research":0.2387473883,"prompt-eng":0.2869977957,"data-quality":0.1515272829,"ml-security":0.6201991403}}
{"text":"In previous studies, it was confirmed that the vision transformer (ViT) is more robust against the property of adversarial transferability than convolutional neural network (CNN) models such as ConvMixer, and moreover encrypted ViT is more robust than ViT without any encryption.","meta":{"url":"http://arxiv.org/abs/2307.13985v1"},"cats":{"new-dataset":0.0444764832,"dev-research":0.221739771,"prompt-eng":0.3154885402,"data-quality":0.1945033491,"ml-security":0.4819340934}}
{"text":"In this article, we propose a random ensemble of encrypted ViT models to achieve much more robust models.","meta":{"url":"http://arxiv.org/abs/2307.13985v1"},"cats":{"new-dataset":0.2511095502,"dev-research":0.1420577795,"prompt-eng":0.4060198794,"data-quality":0.1689908026,"ml-security":0.3564280598}}
{"text":"In experiments, the proposed scheme is verified to be more robust against not only black-box attacks but also white-box ones than convention methods.","meta":{"url":"http://arxiv.org/abs/2307.13985v1"},"cats":{"new-dataset":0.0171928266,"dev-research":0.2671660887,"prompt-eng":0.3805883009,"data-quality":0.2339953663,"ml-security":0.7675621677}}
{"text":"Blind video quality assessment (BVQA) plays an indispensable role in monitoring and improving the end-users' viewing experience in various real-world video-enabled media applications.","meta":{"url":"http://arxiv.org/abs/2307.13981v1"},"cats":{"new-dataset":0.084457202,"dev-research":0.2780287574,"prompt-eng":0.3348135459,"data-quality":0.2353076333,"ml-security":0.0760445088}}
{"text":"As an experimental field, the improvements of BVQA models have been measured primarily on a few human-rated VQA datasets.","meta":{"url":"http://arxiv.org/abs/2307.13981v1"},"cats":{"new-dataset":0.1650547652,"dev-research":0.1771010619,"prompt-eng":0.3828821207,"data-quality":0.1014678171,"ml-security":0.0757555992}}
{"text":"Thus, it is crucial to gain a better understanding of existing VQA datasets in order to properly evaluate the current progress in BVQA.","meta":{"url":"http://arxiv.org/abs/2307.13981v1"},"cats":{"new-dataset":0.2135340548,"dev-research":0.2790513806,"prompt-eng":0.3363710359,"data-quality":0.2074110032,"ml-security":0.0901585778}}
{"text":"Towards this goal, we conduct a first-of-its-kind computational analysis of VQA datasets via designing minimalistic BVQA models.","meta":{"url":"http://arxiv.org/abs/2307.13981v1"},"cats":{"new-dataset":0.4538925867,"dev-research":0.1811741179,"prompt-eng":0.363371681,"data-quality":0.178224224,"ml-security":0.089434865}}
{"text":"By minimalistic, we restrict our family of BVQA models to build only upon basic blocks: a video preprocessor (for aggressive spatiotemporal downsampling), a spatial quality analyzer, an optional temporal quality analyzer, and a quality regressor, all with the simplest possible instantiations.","meta":{"url":"http://arxiv.org/abs/2307.13981v1"},"cats":{"new-dataset":0.3775409698,"dev-research":0.2120938397,"prompt-eng":0.3409664576,"data-quality":0.1945559251,"ml-security":0.0561798445}}
{"text":"By comparing the quality prediction performance of different model variants on eight VQA datasets with realistic distortions, we find that nearly all datasets suffer from the easy dataset problem of varying severity, some of which even admit blind image quality assessment (BIQA) solutions.","meta":{"url":"http://arxiv.org/abs/2307.13981v1"},"cats":{"new-dataset":0.3536802247,"dev-research":0.2407759821,"prompt-eng":0.3331093073,"data-quality":0.4122792025,"ml-security":0.1620677024}}
{"text":"We additionally justify our claims by contrasting our model generalizability on these VQA datasets, and by ablating a dizzying set of BVQA design choices related to the basic building blocks.","meta":{"url":"http://arxiv.org/abs/2307.13981v1"},"cats":{"new-dataset":0.3427454705,"dev-research":0.1865910054,"prompt-eng":0.3576799764,"data-quality":0.1387865202,"ml-security":0.1177644572}}
{"text":"Our results cast doubt on the current progress in BVQA, and meanwhile shed light on good practices of constructing next-generation VQA datasets and models.","meta":{"url":"http://arxiv.org/abs/2307.13981v1"},"cats":{"new-dataset":0.6468558376,"dev-research":0.1895840372,"prompt-eng":0.3508986126,"data-quality":0.1628887185,"ml-security":0.0965924487}}
{"text":"Generative Adversarial Networks (GAN) have emerged as a formidable AI tool to generate realistic outputs based on training datasets.","meta":{"url":"http://arxiv.org/abs/2307.13978v1"},"cats":{"new-dataset":0.3384733891,"dev-research":0.2522536646,"prompt-eng":0.3332812732,"data-quality":0.2087738835,"ml-security":0.2861005178}}
{"text":"However, the challenge of exerting control over the generation process of GANs remains a significant hurdle.","meta":{"url":"http://arxiv.org/abs/2307.13978v1"},"cats":{"new-dataset":0.0209325004,"dev-research":0.3267618784,"prompt-eng":0.3614313499,"data-quality":0.1594805579,"ml-security":0.1966852765}}
{"text":"In this paper, we propose a novel methodology to address this issue by integrating a reinforcement learning (RL) agent with a latent-space GAN (l-GAN), thereby facilitating the generation of desired outputs.","meta":{"url":"http://arxiv.org/abs/2307.13978v1"},"cats":{"new-dataset":0.0873558598,"dev-research":0.2475277344,"prompt-eng":0.3671180358,"data-quality":0.1370414289,"ml-security":0.1419103389}}
{"text":"More specifically, we have developed an actor-critic RL agent with a meticulously designed reward policy, enabling it to acquire proficiency in navigating the latent space of the l-GAN and generating outputs based on specified tasks.","meta":{"url":"http://arxiv.org/abs/2307.13978v1"},"cats":{"new-dataset":0.1310701083,"dev-research":0.2594011646,"prompt-eng":0.3724190926,"data-quality":0.1238098047,"ml-security":0.1111969242}}
{"text":"To substantiate the efficacy of our approach, we have conducted a series of experiments employing the MNIST dataset, including arithmetic addition as an illustrative task.","meta":{"url":"http://arxiv.org/abs/2307.13978v1"},"cats":{"new-dataset":0.1384852559,"dev-research":0.2237142532,"prompt-eng":0.3975714555,"data-quality":0.2031843922,"ml-security":0.1225469309}}
{"text":"The outcomes of these experiments serve to validate our methodology.","meta":{"url":"http://arxiv.org/abs/2307.13978v1"},"cats":{"new-dataset":0.0290175443,"dev-research":0.2511414617,"prompt-eng":0.4166361057,"data-quality":0.2176320238,"ml-security":0.0958665106}}
{"text":"Our pioneering integration of an RL agent with a GAN model represents a novel advancement, holding great potential for enhancing generative networks in the future.","meta":{"url":"http://arxiv.org/abs/2307.13978v1"},"cats":{"new-dataset":0.1023153422,"dev-research":0.2564559361,"prompt-eng":0.3596218061,"data-quality":0.1033079361,"ml-security":0.1122862935}}
{"text":"Verifying the correct behavior of robots in contact tasks is challenging due to model uncertainties associated with contacts.","meta":{"url":"http://arxiv.org/abs/2307.13977v1"},"cats":{"new-dataset":0.1032135176,"dev-research":0.2688860237,"prompt-eng":0.5015053288,"data-quality":0.1639970101,"ml-security":0.0960304611}}
{"text":"Standard methods for testing often fall short since all (uncountable many) solutions cannot be obtained.","meta":{"url":"http://arxiv.org/abs/2307.13977v1"},"cats":{"new-dataset":0.0659312731,"dev-research":0.2531460716,"prompt-eng":0.381906507,"data-quality":0.2231900253,"ml-security":0.1407277807}}
{"text":"Instead, we propose to formally and efficiently verify robot behaviors in contact tasks using reachability analysis, which enables checking all the reachable states against user-provided specifications.","meta":{"url":"http://arxiv.org/abs/2307.13977v1"},"cats":{"new-dataset":0.2240724891,"dev-research":0.3555033333,"prompt-eng":0.4917251601,"data-quality":0.125408314,"ml-security":0.1199560706}}
{"text":"To this end, we extend the state of the art in reachability analysis for hybrid (mixed discrete and continuous) dynamics subject to discrete-time input trajectories.","meta":{"url":"http://arxiv.org/abs/2307.13977v1"},"cats":{"new-dataset":0.1048424812,"dev-research":0.2413838003,"prompt-eng":0.3529390255,"data-quality":0.1010646476,"ml-security":0.1054999783}}
{"text":"In particular, we present a novel and scalable guard intersection approach to reliably compute the complex behavior caused by contacts.","meta":{"url":"http://arxiv.org/abs/2307.13977v1"},"cats":{"new-dataset":0.0938332602,"dev-research":0.2638274059,"prompt-eng":0.4356129183,"data-quality":0.0981061505,"ml-security":0.2692886591}}
{"text":"We model robots subject to contacts as hybrid automata in which crucial time delays are included.","meta":{"url":"http://arxiv.org/abs/2307.13977v1"},"cats":{"new-dataset":0.1587976779,"dev-research":0.2281505066,"prompt-eng":0.4696177574,"data-quality":0.0596332357,"ml-security":0.0691553384}}
{"text":"The usefulness of our approach is demonstrated by verifying safe human-robot interaction in the presence of constrained collisions, which was out of reach for existing methods.","meta":{"url":"http://arxiv.org/abs/2307.13977v1"},"cats":{"new-dataset":0.1733744917,"dev-research":0.2977932296,"prompt-eng":0.4514458892,"data-quality":0.1374668358,"ml-security":0.2176529129}}
{"text":"Visual object tracking is a fundamental video task in computer vision.","meta":{"url":"http://arxiv.org/abs/2307.13974v1"},"cats":{"new-dataset":0.0209878843,"dev-research":0.312947841,"prompt-eng":0.3881471631,"data-quality":0.1916472015,"ml-security":0.0672173061}}
{"text":"Recently, the notably increasing power of perception algorithms allows the unification of single/multiobject and box/mask-based tracking.","meta":{"url":"http://arxiv.org/abs/2307.13974v1"},"cats":{"new-dataset":0.0563801165,"dev-research":0.2241006815,"prompt-eng":0.3898716445,"data-quality":0.1433673404,"ml-security":0.129884248}}
{"text":"Among them, the Segment Anything Model (SAM) attracts much attention.","meta":{"url":"http://arxiv.org/abs/2307.13974v1"},"cats":{"new-dataset":0.0701219728,"dev-research":0.1786978857,"prompt-eng":0.396019482,"data-quality":0.1033929282,"ml-security":0.067289497}}
{"text":"In this report, we propose HQTrack, a framework for High Quality Tracking anything in videos.","meta":{"url":"http://arxiv.org/abs/2307.13974v1"},"cats":{"new-dataset":0.265245354,"dev-research":0.2504581997,"prompt-eng":0.357120309,"data-quality":0.2627338222,"ml-security":0.0757755778}}
{"text":"HQTrack mainly consists of a video multi-object segmenter (VMOS) and a mask refiner (MR).","meta":{"url":"http://arxiv.org/abs/2307.13974v1"},"cats":{"new-dataset":0.369156676,"dev-research":0.1957751144,"prompt-eng":0.3778210526,"data-quality":0.1268139842,"ml-security":0.0430083969}}
{"text":"Given the object to be tracked in the initial frame of a video, VMOS propagates the object masks to the current frame.","meta":{"url":"http://arxiv.org/abs/2307.13974v1"},"cats":{"new-dataset":0.0456456145,"dev-research":0.2077439065,"prompt-eng":0.4068819556,"data-quality":0.1331207364,"ml-security":0.1135103703}}
{"text":"The mask results at this stage are not accurate enough since VMOS is trained on several closeset video object segmentation (VOS) datasets, which has limited ability to generalize to complex and corner scenes.","meta":{"url":"http://arxiv.org/abs/2307.13974v1"},"cats":{"new-dataset":0.1380824053,"dev-research":0.1931349991,"prompt-eng":0.3582300383,"data-quality":0.2621939288,"ml-security":0.1552640731}}
{"text":"To further improve the quality of tracking masks, a pretrained MR model is employed to refine the tracking results.","meta":{"url":"http://arxiv.org/abs/2307.13974v1"},"cats":{"new-dataset":0.0344906864,"dev-research":0.2608072895,"prompt-eng":0.4252513556,"data-quality":0.1124145711,"ml-security":0.0771895761}}
{"text":"As a compelling testament to the effectiveness of our paradigm, without employing any tricks such as test-time data augmentations and model ensemble, HQTrack ranks the 2nd place in the Visual Object Tracking and Segmentation (VOTS2023) challenge.","meta":{"url":"http://arxiv.org/abs/2307.13974v1"},"cats":{"new-dataset":0.3956057476,"dev-research":0.2403578225,"prompt-eng":0.3613903755,"data-quality":0.2855082859,"ml-security":0.1174454789}}
{"text":"Code and models are available at https://github.com/jiawen-zhu/HQTrack.","meta":{"url":"http://arxiv.org/abs/2307.13974v1"},"cats":{"new-dataset":0.4994159105,"dev-research":0.1612713622,"prompt-eng":0.452876311,"data-quality":0.0811343294,"ml-security":0.0271777764}}
{"text":"In this paper, we measure the linear separability of hidden layer outputs to study the characteristics of deep neural networks.","meta":{"url":"http://arxiv.org/abs/2307.13962v1"},"cats":{"new-dataset":0.0618691394,"dev-research":0.2289807517,"prompt-eng":0.3086896261,"data-quality":0.2696570074,"ml-security":0.4300892767}}
{"text":"In particular, we first propose Minkowski difference based linear separability measures (MD-LSMs) to evaluate the linear separability degree of two points sets.","meta":{"url":"http://arxiv.org/abs/2307.13962v1"},"cats":{"new-dataset":0.1626471453,"dev-research":0.1553706995,"prompt-eng":0.3473695347,"data-quality":0.1678081758,"ml-security":0.0656692007}}
{"text":"Then, we demonstrate that there is a synchronicity between the linear separability degree of hidden layer outputs and the network training performance, i.e., if the updated weights can enhance the linear separability degree of hidden layer outputs, the updated network will achieve a better training performance, and vice versa.","meta":{"url":"http://arxiv.org/abs/2307.13962v1"},"cats":{"new-dataset":0.0350237744,"dev-research":0.2280363456,"prompt-eng":0.3353060176,"data-quality":0.231663476,"ml-security":0.2926300322}}
{"text":"Moreover, we study the effect of activation function and network size (including width and depth) on the linear separability of hidden layers.","meta":{"url":"http://arxiv.org/abs/2307.13962v1"},"cats":{"new-dataset":0.0184620635,"dev-research":0.1904895839,"prompt-eng":0.2822319184,"data-quality":0.1357941039,"ml-security":0.3140108641}}
{"text":"Finally, we conduct the numerical experiments to validate our findings on some popular deep networks including multilayer perceptron (MLP), convolutional neural network (CNN), deep belief network (DBN), ResNet, VGGNet, AlexNet, vision transformer (ViT) and GoogLeNet.","meta":{"url":"http://arxiv.org/abs/2307.13962v1"},"cats":{"new-dataset":0.1545755513,"dev-research":0.1781868476,"prompt-eng":0.3614382031,"data-quality":0.2116846446,"ml-security":0.195440721}}
{"text":"Recently, vision transformer based multimodal learning methods have been proposed to improve the robustness of face anti-spoofing (FAS) systems.","meta":{"url":"http://arxiv.org/abs/2307.13958v1"},"cats":{"new-dataset":0.06055799,"dev-research":0.2641922049,"prompt-eng":0.3673759627,"data-quality":0.228809184,"ml-security":0.4214571762}}
{"text":"However, multimodal face data collected from the real world is often imperfect due to missing modalities from various imaging sensors.","meta":{"url":"http://arxiv.org/abs/2307.13958v1"},"cats":{"new-dataset":0.10383906,"dev-research":0.2249719454,"prompt-eng":0.3345244488,"data-quality":0.2228751174,"ml-security":0.1243942615}}
{"text":"Recently, flexible-modal FAS~\\cite{yu2023flexible} has attracted more attention, which aims to develop a unified multimodal FAS model using complete multimodal face data but is insensitive to test-time missing modalities.","meta":{"url":"http://arxiv.org/abs/2307.13958v1"},"cats":{"new-dataset":0.2220472494,"dev-research":0.1967237901,"prompt-eng":0.4143205639,"data-quality":0.1527068851,"ml-security":0.0656101998}}
{"text":"In this paper, we tackle one main challenge in flexible-modal FAS, i.e., when missing modality occurs either during training or testing in real-world situations.","meta":{"url":"http://arxiv.org/abs/2307.13958v1"},"cats":{"new-dataset":0.0587108793,"dev-research":0.2507991947,"prompt-eng":0.4797153499,"data-quality":0.3375631855,"ml-security":0.1328565823}}
{"text":"Inspired by the recent success of the prompt learning in language models, we propose \\textbf{V}isual \\textbf{P}rompt flexible-modal \\textbf{FAS} (VP-FAS), which learns the modal-relevant prompts to adapt the frozen pre-trained foundation model to downstream flexible-modal FAS task.","meta":{"url":"http://arxiv.org/abs/2307.13958v1"},"cats":{"new-dataset":0.10291374,"dev-research":0.2463817214,"prompt-eng":0.5247164581,"data-quality":0.2428014126,"ml-security":0.1162969709}}
{"text":"Specifically, both vanilla visual prompts and residual contextual prompts are plugged into multimodal transformers to handle general missing-modality cases, while only requiring less than 4\\% learnable parameters compared to training the entire model.","meta":{"url":"http://arxiv.org/abs/2307.13958v1"},"cats":{"new-dataset":0.0789481168,"dev-research":0.3244431365,"prompt-eng":0.4921174117,"data-quality":0.2090054874,"ml-security":0.1174422957}}
{"text":"Furthermore, missing-modality regularization is proposed to force models to learn consistent multimodal feature embeddings when missing partial modalities.","meta":{"url":"http://arxiv.org/abs/2307.13958v1"},"cats":{"new-dataset":0.1255094027,"dev-research":0.204617929,"prompt-eng":0.3610224398,"data-quality":0.3635499224,"ml-security":0.132696231}}
{"text":"Extensive experiments conducted on two multimodal FAS benchmark datasets demonstrate the effectiveness of our VP-FAS framework that improves the performance under various missing-modality cases while alleviating the requirement of heavy model re-training.","meta":{"url":"http://arxiv.org/abs/2307.13958v1"},"cats":{"new-dataset":0.2680676466,"dev-research":0.2211848565,"prompt-eng":0.405620771,"data-quality":0.2312366009,"ml-security":0.0642103777}}
{"text":"Multi-agent embodied tasks have recently been studied in complex indoor visual environments.","meta":{"url":"http://arxiv.org/abs/2307.13957v1"},"cats":{"new-dataset":0.0801424983,"dev-research":0.2952166082,"prompt-eng":0.4117502858,"data-quality":0.063234418,"ml-security":0.0611990344}}
{"text":"Collaboration among multiple agents can improve work efficiency and has significant practical value.","meta":{"url":"http://arxiv.org/abs/2307.13957v1"},"cats":{"new-dataset":0.0296899033,"dev-research":0.417369052,"prompt-eng":0.366370899,"data-quality":0.0683307188,"ml-security":0.0512805662}}
{"text":"However, most of the existing research focuses on homogeneous multi-agent tasks.","meta":{"url":"http://arxiv.org/abs/2307.13957v1"},"cats":{"new-dataset":0.0565332644,"dev-research":0.1946506936,"prompt-eng":0.3795740674,"data-quality":0.0524304609,"ml-security":0.048542592}}
{"text":"Compared with homogeneous agents, heterogeneous agents can leverage their different capabilities to allocate corresponding sub-tasks and cooperate to complete complex tasks.","meta":{"url":"http://arxiv.org/abs/2307.13957v1"},"cats":{"new-dataset":0.0282749718,"dev-research":0.3007772732,"prompt-eng":0.3939109092,"data-quality":0.0628256218,"ml-security":0.0675035771}}
{"text":"Heterogeneous multi-agent tasks are common in real-world scenarios, and the collaboration strategy among heterogeneous agents is a challenging and important problem to be solved.","meta":{"url":"http://arxiv.org/abs/2307.13957v1"},"cats":{"new-dataset":0.0684495309,"dev-research":0.2627546558,"prompt-eng":0.4161660438,"data-quality":0.0714779855,"ml-security":0.0662792114}}
{"text":"To study collaboration among heterogeneous agents, we propose the heterogeneous multi-agent tidying-up task, in which multiple heterogeneous agents with different capabilities collaborate with each other to detect misplaced objects and place them in reasonable locations.","meta":{"url":"http://arxiv.org/abs/2307.13957v1"},"cats":{"new-dataset":0.2257431069,"dev-research":0.2947283925,"prompt-eng":0.427064988,"data-quality":0.2261306256,"ml-security":0.0795455054}}
{"text":"This is a demanding task since it requires agents to make the best use of their different capabilities to conduct reasonable task planning and complete the whole task.","meta":{"url":"http://arxiv.org/abs/2307.13957v1"},"cats":{"new-dataset":0.0312459661,"dev-research":0.3226660411,"prompt-eng":0.465879579,"data-quality":0.0740258054,"ml-security":0.0573613492}}
{"text":"To solve this task, we build a heterogeneous multi-agent tidying-up benchmark dataset in a large number of houses with multiple rooms based on ProcTHOR-10K.","meta":{"url":"http://arxiv.org/abs/2307.13957v1"},"cats":{"new-dataset":0.7827540034,"dev-research":0.2479424794,"prompt-eng":0.3932823915,"data-quality":0.1235718847,"ml-security":0.0637485338}}
{"text":"We propose the hierarchical decision model based on misplaced object detection, reasonable receptacle prediction, as well as the handshake-based group communication mechanism.","meta":{"url":"http://arxiv.org/abs/2307.13957v1"},"cats":{"new-dataset":0.0761025151,"dev-research":0.184948919,"prompt-eng":0.4575351323,"data-quality":0.2264989938,"ml-security":0.1527007526}}
{"text":"Extensive experiments are conducted to demonstrate the effectiveness of the proposed model.","meta":{"url":"http://arxiv.org/abs/2307.13957v1"},"cats":{"new-dataset":0.0097044211,"dev-research":0.2100278133,"prompt-eng":0.4304018111,"data-quality":0.1124989445,"ml-security":0.0866783209}}
{"text":"The project's website and videos of experiments can be found at https://hetercol.github.io/.","meta":{"url":"http://arxiv.org/abs/2307.13957v1"},"cats":{"new-dataset":0.0799277647,"dev-research":0.1388292826,"prompt-eng":0.4643554074,"data-quality":0.1078941415,"ml-security":0.034289266}}
{"text":"This work unveils the enigmatic link between phonemes and facial features.","meta":{"url":"http://arxiv.org/abs/2307.13953v1"},"cats":{"new-dataset":0.1615592087,"dev-research":0.2180279328,"prompt-eng":0.3329581458,"data-quality":0.2302716393,"ml-security":0.1918170641}}
{"text":"Traditional studies on voice-face correlations typically involve using a long period of voice input, including generating face images from voices and reconstructing 3D face meshes from voices.","meta":{"url":"http://arxiv.org/abs/2307.13953v1"},"cats":{"new-dataset":0.1016030532,"dev-research":0.2723958383,"prompt-eng":0.3569376768,"data-quality":0.1408265067,"ml-security":0.1043560667}}
{"text":"However, in situations like voice-based crimes, the available voice evidence may be short and limited.","meta":{"url":"http://arxiv.org/abs/2307.13953v1"},"cats":{"new-dataset":0.0324401099,"dev-research":0.2113459473,"prompt-eng":0.2883501895,"data-quality":0.2229840641,"ml-security":0.3463841504}}
{"text":"Additionally, from a physiological perspective, each segment of speech -- phoneme -- corresponds to different types of airflow and movements in the face.","meta":{"url":"http://arxiv.org/abs/2307.13953v1"},"cats":{"new-dataset":0.0734573442,"dev-research":0.2021610232,"prompt-eng":0.3200414195,"data-quality":0.0893657294,"ml-security":0.0753904761}}
{"text":"Therefore, it is advantageous to discover the hidden link between phonemes and face attributes.","meta":{"url":"http://arxiv.org/abs/2307.13953v1"},"cats":{"new-dataset":0.0313586247,"dev-research":0.2475659755,"prompt-eng":0.3594776451,"data-quality":0.1466427115,"ml-security":0.1921101844}}
{"text":"In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM).","meta":{"url":"http://arxiv.org/abs/2307.13953v1"},"cats":{"new-dataset":0.2608769551,"dev-research":0.225405352,"prompt-eng":0.3495765451,"data-quality":0.1514492006,"ml-security":0.1011270956}}
{"text":"We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing.","meta":{"url":"http://arxiv.org/abs/2307.13953v1"},"cats":{"new-dataset":0.2692099103,"dev-research":0.1272455875,"prompt-eng":0.4561270963,"data-quality":0.1840451623,"ml-security":0.053666965}}
{"text":"Our results indicate that AMs are more predictable from vowels compared to consonants, particularly with plosives.","meta":{"url":"http://arxiv.org/abs/2307.13953v1"},"cats":{"new-dataset":0.0410345621,"dev-research":0.2168924149,"prompt-eng":0.3967681453,"data-quality":0.1605307461,"ml-security":0.0769408635}}
{"text":"Additionally, we observe that if a specific AM exhibits more movement during phoneme pronunciation, it is more predictable.","meta":{"url":"http://arxiv.org/abs/2307.13953v1"},"cats":{"new-dataset":0.0066905444,"dev-research":0.2135512935,"prompt-eng":0.388135003,"data-quality":0.1835028041,"ml-security":0.1082507651}}
{"text":"Our findings support those in physiology regarding correlation and lay the groundwork for future research on speech-face multimodal learning.","meta":{"url":"http://arxiv.org/abs/2307.13953v1"},"cats":{"new-dataset":0.1040226689,"dev-research":0.2870863755,"prompt-eng":0.3283396246,"data-quality":0.1434858475,"ml-security":0.1053562024}}
{"text":"A diverse set of Internet of Things (IoT) devices are becoming an integrated part of daily lives, and playing an increasingly vital role in various industry, enterprise and agricultural settings.","meta":{"url":"http://arxiv.org/abs/2307.13952v1"},"cats":{"new-dataset":0.1788677571,"dev-research":0.2484069431,"prompt-eng":0.3659149971,"data-quality":0.0661596687,"ml-security":0.0811158507}}
{"text":"The current IoT ecosystem relies on several IoT management platforms to manage and operate a large number of IoT devices, their data, and their connectivity.","meta":{"url":"http://arxiv.org/abs/2307.13952v1"},"cats":{"new-dataset":0.1557036005,"dev-research":0.2176604492,"prompt-eng":0.3745445353,"data-quality":0.0576779519,"ml-security":0.0974733205}}
{"text":"Considering their key role, these platforms must be properly secured against cyber attacks.","meta":{"url":"http://arxiv.org/abs/2307.13952v1"},"cats":{"new-dataset":0.1083728612,"dev-research":0.2493118789,"prompt-eng":0.337244321,"data-quality":0.1381480279,"ml-security":0.5513093188}}
{"text":"In this work, we first explore the core operations/features of leading platforms to design a framework to perform a systematic security evaluation of these platforms.","meta":{"url":"http://arxiv.org/abs/2307.13952v1"},"cats":{"new-dataset":0.1642221494,"dev-research":0.3483133634,"prompt-eng":0.4713620026,"data-quality":0.1234235752,"ml-security":0.5865742857}}
{"text":"Subsequently, we use our framework to analyze a representative set of 52 IoT management platforms, including 42 web-hosted and 10 locally-deployable platforms.","meta":{"url":"http://arxiv.org/abs/2307.13952v1"},"cats":{"new-dataset":0.6984287507,"dev-research":0.2338392851,"prompt-eng":0.4134790331,"data-quality":0.101464602,"ml-security":0.0777320237}}
{"text":"We discover a number of high severity unauthorized access vulnerabilities in 9/52 evaluated IoT management platforms, which could be abused to perform attacks such as remote IoT SIM deactivation, IoT SIM overcharging and IoT device data forgery.","meta":{"url":"http://arxiv.org/abs/2307.13952v1"},"cats":{"new-dataset":0.256311446,"dev-research":0.2851790807,"prompt-eng":0.4056446895,"data-quality":0.1809834799,"ml-security":0.6286842472}}
{"text":"More seriously, we also uncover instances of broken authentication in 13/52 platforms, including complete account takeover on 8/52 platforms along with remote code execution on 2/52 platforms.","meta":{"url":"http://arxiv.org/abs/2307.13952v1"},"cats":{"new-dataset":0.2396320937,"dev-research":0.3328965039,"prompt-eng":0.4358413837,"data-quality":0.2403731907,"ml-security":0.4447076673}}
{"text":"In effect, 17/52 platforms were affected by vulnerabilities that could lead to platform-wide attacks.","meta":{"url":"http://arxiv.org/abs/2307.13952v1"},"cats":{"new-dataset":0.0893747214,"dev-research":0.3854359347,"prompt-eng":0.366640197,"data-quality":0.1762028833,"ml-security":0.6031763743}}
{"text":"Overall, vulnerabilities were uncovered in 33 platforms, out of which 28 platforms responded to our responsible disclosure.","meta":{"url":"http://arxiv.org/abs/2307.13952v1"},"cats":{"new-dataset":0.4703291027,"dev-research":0.3372996787,"prompt-eng":0.3678975003,"data-quality":0.2299067648,"ml-security":0.5036882049}}
{"text":"We were also assigned 11 CVEs and awarded bounty for our findings.","meta":{"url":"http://arxiv.org/abs/2307.13952v1"},"cats":{"new-dataset":0.169034539,"dev-research":0.2069067262,"prompt-eng":0.3716681608,"data-quality":0.173882297,"ml-security":0.1373227461}}
{"text":"The success of re-localisation has crucial implications for the practical deployment of robots operating within a prior map or relative to one another in real-world scenarios.","meta":{"url":"http://arxiv.org/abs/2307.13950v1"},"cats":{"new-dataset":0.050115988,"dev-research":0.287463154,"prompt-eng":0.4243084563,"data-quality":0.1553432704,"ml-security":0.1004233652}}
{"text":"Using single-modality, place recognition and localisation can be compromised in challenging environments such as forests.","meta":{"url":"http://arxiv.org/abs/2307.13950v1"},"cats":{"new-dataset":0.1124015213,"dev-research":0.2179097895,"prompt-eng":0.3792416294,"data-quality":0.2392972527,"ml-security":0.2577197647}}
{"text":"To address this, we propose a strategy to prevent lidar-based re-localisation failure using lidar-image cross-modality.","meta":{"url":"http://arxiv.org/abs/2307.13950v1"},"cats":{"new-dataset":0.0498326337,"dev-research":0.2388452761,"prompt-eng":0.3855372819,"data-quality":0.2913386652,"ml-security":0.1642413046}}
{"text":"Our solution relies on self-supervised 2D-3D feature matching to predict alignment and misalignment.","meta":{"url":"http://arxiv.org/abs/2307.13950v1"},"cats":{"new-dataset":0.1165316245,"dev-research":0.2175095048,"prompt-eng":0.4122894489,"data-quality":0.2325725399,"ml-security":0.0600822825}}
{"text":"Leveraging a deep network for lidar feature extraction and relative pose estimation between point clouds, we train a model to evaluate the estimated transformation.","meta":{"url":"http://arxiv.org/abs/2307.13950v1"},"cats":{"new-dataset":0.2008151392,"dev-research":0.203075274,"prompt-eng":0.3416055315,"data-quality":0.1539806324,"ml-security":0.1496591979}}
{"text":"A model predicting the presence of misalignment is learned by analysing image-lidar similarity in the embedding space and the geometric constraints available within the region seen in both modalities in Euclidean space.","meta":{"url":"http://arxiv.org/abs/2307.13950v1"},"cats":{"new-dataset":0.0536493918,"dev-research":0.1977022719,"prompt-eng":0.3364466013,"data-quality":0.2720538002,"ml-security":0.1009334664}}
{"text":"Experimental results using real datasets (offline and online modes) demonstrate the effectiveness of the proposed pipeline for robust re-localisation in unstructured, natural environments.","meta":{"url":"http://arxiv.org/abs/2307.13950v1"},"cats":{"new-dataset":0.5598847335,"dev-research":0.2062334916,"prompt-eng":0.3689290802,"data-quality":0.2052750712,"ml-security":0.064158318}}
{"text":"Transformer-based pretrained language models (PLMs) have achieved great success in modern NLP.","meta":{"url":"http://arxiv.org/abs/2307.13949v1"},"cats":{"new-dataset":0.0862131053,"dev-research":0.1813199085,"prompt-eng":0.4263065963,"data-quality":0.1887468262,"ml-security":0.077959788}}
{"text":"An important advantage of PLMs is good out-of-distribution (OOD) robustness.","meta":{"url":"http://arxiv.org/abs/2307.13949v1"},"cats":{"new-dataset":0.0291109455,"dev-research":0.1976522957,"prompt-eng":0.4228699175,"data-quality":0.2115112866,"ml-security":0.1705612462}}
{"text":"Recently, diffusion models have attracted a lot of work to apply diffusion to PLMs.","meta":{"url":"http://arxiv.org/abs/2307.13949v1"},"cats":{"new-dataset":0.0091115941,"dev-research":0.1443842893,"prompt-eng":0.3823341216,"data-quality":0.0919100154,"ml-security":0.1121611851}}
{"text":"It remains under-explored how diffusion influences PLMs on OOD data.","meta":{"url":"http://arxiv.org/abs/2307.13949v1"},"cats":{"new-dataset":0.0309396037,"dev-research":0.1328724923,"prompt-eng":0.3399991512,"data-quality":0.1054058703,"ml-security":0.1126757253}}
{"text":"The core of diffusion models is a forward diffusion process which gradually applies Gaussian noise to inputs, and a reverse denoising process which removes noise.","meta":{"url":"http://arxiv.org/abs/2307.13949v1"},"cats":{"new-dataset":0.0127555407,"dev-research":0.2192621164,"prompt-eng":0.3498464779,"data-quality":0.1278144719,"ml-security":0.1910396074}}
{"text":"The noised input reconstruction is a fundamental ability of diffusion models.","meta":{"url":"http://arxiv.org/abs/2307.13949v1"},"cats":{"new-dataset":0.05968022,"dev-research":0.1610335489,"prompt-eng":0.3450674306,"data-quality":0.1633983949,"ml-security":0.1458844417}}
{"text":"We directly analyze OOD robustness by measuring the reconstruction loss, including testing the abilities to reconstruct OOD data, and to detect OOD samples.","meta":{"url":"http://arxiv.org/abs/2307.13949v1"},"cats":{"new-dataset":0.1426769727,"dev-research":0.2245754511,"prompt-eng":0.4166738144,"data-quality":0.2752002851,"ml-security":0.173203176}}
{"text":"Experiments are conducted by analyzing different training parameters and data statistical features on eight datasets.","meta":{"url":"http://arxiv.org/abs/2307.13949v1"},"cats":{"new-dataset":0.321153293,"dev-research":0.2348688276,"prompt-eng":0.4141625035,"data-quality":0.2477750651,"ml-security":0.1116387147}}
{"text":"It shows that finetuning PLMs with diffusion degrades the reconstruction ability on OOD data.","meta":{"url":"http://arxiv.org/abs/2307.13949v1"},"cats":{"new-dataset":0.0869082785,"dev-research":0.152597604,"prompt-eng":0.3528991168,"data-quality":0.1346347992,"ml-security":0.0772976243}}
{"text":"The comparison also shows that diffusion models can effectively detect OOD samples, achieving state-of-the-art performance in most of the datasets with an absolute accuracy improvement up to 18%.","meta":{"url":"http://arxiv.org/abs/2307.13949v1"},"cats":{"new-dataset":0.0829113642,"dev-research":0.1590642058,"prompt-eng":0.37720613,"data-quality":0.1682021812,"ml-security":0.1080027683}}
{"text":"These results indicate that diffusion reduces OOD robustness of PLMs.","meta":{"url":"http://arxiv.org/abs/2307.13949v1"},"cats":{"new-dataset":0.0061697748,"dev-research":0.1631191814,"prompt-eng":0.3721830227,"data-quality":0.1325198569,"ml-security":0.1509491986}}
{"text":"Previous works on voice-face matching and voice-guided face synthesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emotion.","meta":{"url":"http://arxiv.org/abs/2307.13948v1"},"cats":{"new-dataset":0.1222412095,"dev-research":0.278835733,"prompt-eng":0.3864640396,"data-quality":0.1910148,"ml-security":0.1101073493}}
{"text":"In this paper, we aim to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without any semantic information.","meta":{"url":"http://arxiv.org/abs/2307.13948v1"},"cats":{"new-dataset":0.1285908486,"dev-research":0.196965028,"prompt-eng":0.332603405,"data-quality":0.1059469769,"ml-security":0.0843903565}}
{"text":"We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction.","meta":{"url":"http://arxiv.org/abs/2307.13948v1"},"cats":{"new-dataset":0.1746661665,"dev-research":0.2234664431,"prompt-eng":0.354275976,"data-quality":0.1002999666,"ml-security":0.0890255026}}
{"text":"By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable.","meta":{"url":"http://arxiv.org/abs/2307.13948v1"},"cats":{"new-dataset":0.0599193264,"dev-research":0.2407114375,"prompt-eng":0.4116878674,"data-quality":0.1530207331,"ml-security":0.1549727953}}
{"text":"Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium.","meta":{"url":"http://arxiv.org/abs/2307.13948v1"},"cats":{"new-dataset":0.5135219215,"dev-research":0.1884644544,"prompt-eng":0.3388718318,"data-quality":0.1490455523,"ml-security":0.1121295196}}
{"text":"Our work offers a new perspective on voice-face correlation and can serve as a good empirical study for anthropometry science.","meta":{"url":"http://arxiv.org/abs/2307.13948v1"},"cats":{"new-dataset":0.132245291,"dev-research":0.2281199652,"prompt-eng":0.3240637444,"data-quality":0.1121924233,"ml-security":0.0788735839}}
{"text":"Cancer grading is an essential task in pathology.","meta":{"url":"http://arxiv.org/abs/2307.13947v1"},"cats":{"new-dataset":0.0147641566,"dev-research":0.2915215969,"prompt-eng":0.4212077174,"data-quality":0.196268862,"ml-security":0.0558456931}}
{"text":"The recent developments of artificial neural networks in computational pathology have shown that these methods hold great potential for improving the accuracy and quality of cancer diagnosis.","meta":{"url":"http://arxiv.org/abs/2307.13947v1"},"cats":{"new-dataset":0.0466564144,"dev-research":0.2539433581,"prompt-eng":0.3608523197,"data-quality":0.1987632222,"ml-security":0.1209406128}}
{"text":"However, the issues with the robustness and reliability of such methods have not been fully resolved yet.","meta":{"url":"http://arxiv.org/abs/2307.13947v1"},"cats":{"new-dataset":0.0470264788,"dev-research":0.2653757899,"prompt-eng":0.4089689755,"data-quality":0.336105043,"ml-security":0.0870187557}}
{"text":"Herein, we propose a centroid-aware feature recalibration network that can conduct cancer grading in an accurate and robust manner.","meta":{"url":"http://arxiv.org/abs/2307.13947v1"},"cats":{"new-dataset":0.1205886623,"dev-research":0.2818067237,"prompt-eng":0.4284816069,"data-quality":0.2851295388,"ml-security":0.0688073679}}
{"text":"The proposed network maps an input pathology image into an embedding space and adjusts it by using centroids embedding vectors of different cancer grades via attention mechanism.","meta":{"url":"http://arxiv.org/abs/2307.13947v1"},"cats":{"new-dataset":0.0873206003,"dev-research":0.2347369672,"prompt-eng":0.4121187939,"data-quality":0.2537314722,"ml-security":0.1037719126}}
{"text":"Equipped with the recalibrated embedding vector, the proposed network classifiers the input pathology image into a pertinent class label, i.e., cancer grade.","meta":{"url":"http://arxiv.org/abs/2307.13947v1"},"cats":{"new-dataset":0.0998679609,"dev-research":0.2106991265,"prompt-eng":0.3997651322,"data-quality":0.4175890314,"ml-security":0.1382917417}}
{"text":"We evaluate the proposed network using colorectal cancer datasets that were collected under different environments.","meta":{"url":"http://arxiv.org/abs/2307.13947v1"},"cats":{"new-dataset":0.5909758102,"dev-research":0.1919934384,"prompt-eng":0.3199380028,"data-quality":0.1425348568,"ml-security":0.115910227}}
{"text":"The experimental results confirm that the proposed network is able to conduct cancer grading in pathology images with high accuracy regardless of the environmental changes in the datasets.","meta":{"url":"http://arxiv.org/abs/2307.13947v1"},"cats":{"new-dataset":0.1366189641,"dev-research":0.2278233209,"prompt-eng":0.3785269968,"data-quality":0.2793256224,"ml-security":0.0955287267}}
{"text":"Contrastive learning on graphs aims at extracting distinguishable high-level representations of nodes.","meta":{"url":"http://arxiv.org/abs/2307.13944v1"},"cats":{"new-dataset":0.0739695451,"dev-research":0.2353232375,"prompt-eng":0.3372188052,"data-quality":0.2551510245,"ml-security":0.0973040167}}
{"text":"In this paper, we theoretically illustrate that the entropy of a dataset can be approximated by maximizing the lower bound of the mutual information across different views of a graph, \\ie, entropy is estimated by a neural network.","meta":{"url":"http://arxiv.org/abs/2307.13944v1"},"cats":{"new-dataset":0.1082993901,"dev-research":0.1838168559,"prompt-eng":0.3155190261,"data-quality":0.2453945932,"ml-security":0.211234251}}
{"text":"Based on this finding, we propose a simple yet effective subset sampling strategy to contrast pairwise representations between views of a dataset.","meta":{"url":"http://arxiv.org/abs/2307.13944v1"},"cats":{"new-dataset":0.43441016,"dev-research":0.2100712368,"prompt-eng":0.3125145479,"data-quality":0.2351107301,"ml-security":0.0927043979}}
{"text":"In particular, we randomly sample nodes and edges from a given graph to build the input subset for a view.","meta":{"url":"http://arxiv.org/abs/2307.13944v1"},"cats":{"new-dataset":0.0977900128,"dev-research":0.2757911411,"prompt-eng":0.374065402,"data-quality":0.1690765439,"ml-security":0.1096258714}}
{"text":"Two views are fed into a parameter-shared Siamese network to extract the high-dimensional embeddings and estimate the information entropy of the entire graph.","meta":{"url":"http://arxiv.org/abs/2307.13944v1"},"cats":{"new-dataset":0.1755127539,"dev-research":0.1799954957,"prompt-eng":0.318480391,"data-quality":0.18857477,"ml-security":0.1062634927}}
{"text":"For the learning process, we propose to optimize the network using two objectives, simultaneously.","meta":{"url":"http://arxiv.org/abs/2307.13944v1"},"cats":{"new-dataset":0.0111623576,"dev-research":0.2876647284,"prompt-eng":0.4218455556,"data-quality":0.1642577215,"ml-security":0.1204044859}}
{"text":"Concretely, the input of the contrastive loss function consists of positive and negative pairs.","meta":{"url":"http://arxiv.org/abs/2307.13944v1"},"cats":{"new-dataset":0.0391334744,"dev-research":0.1793095706,"prompt-eng":0.3260214099,"data-quality":0.1719841809,"ml-security":0.1216019194}}
{"text":"Our selection strategy of pairs is different from previous works and we present a novel strategy to enhance the representation ability of the graph encoder by selecting nodes based on cross-view similarities.","meta":{"url":"http://arxiv.org/abs/2307.13944v1"},"cats":{"new-dataset":0.1081015055,"dev-research":0.2514849902,"prompt-eng":0.3621558748,"data-quality":0.1382740014,"ml-security":0.0726707539}}
{"text":"We enrich the diversity of the positive and negative pairs by selecting highly similar samples and totally different data with the guidance of cross-view similarity scores, respectively.","meta":{"url":"http://arxiv.org/abs/2307.13944v1"},"cats":{"new-dataset":0.1320491162,"dev-research":0.200741922,"prompt-eng":0.344225741,"data-quality":0.2271325438,"ml-security":0.0722551832}}
{"text":"We also introduce a cross-view consistency constraint on the representations generated from the different views.","meta":{"url":"http://arxiv.org/abs/2307.13944v1"},"cats":{"new-dataset":0.0767195423,"dev-research":0.2435685538,"prompt-eng":0.3665057129,"data-quality":0.2970952555,"ml-security":0.0951310449}}
{"text":"This objective guarantees the learned representations are consistent across views from the perspective of the entire graph.","meta":{"url":"http://arxiv.org/abs/2307.13944v1"},"cats":{"new-dataset":0.0726045474,"dev-research":0.2530893698,"prompt-eng":0.3114683327,"data-quality":0.2799751428,"ml-security":0.1688948929}}
{"text":"We conduct extensive experiments on seven graph benchmarks, and the proposed approach achieves competitive performance compared to the current state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2307.13944v1"},"cats":{"new-dataset":0.0886151307,"dev-research":0.2315909059,"prompt-eng":0.391551461,"data-quality":0.1971950103,"ml-security":0.0440280466}}
{"text":"The source code will be publicly released once this paper is accepted.","meta":{"url":"http://arxiv.org/abs/2307.13944v1"},"cats":{"new-dataset":0.3414389165,"dev-research":0.2362510136,"prompt-eng":0.3459053329,"data-quality":0.1683090792,"ml-security":0.1116472247}}
{"text":"Out-of-distribution (OOD) generalization is a challenging machine learning problem yet highly desirable in many high-stake applications.","meta":{"url":"http://arxiv.org/abs/2307.13943v1"},"cats":{"new-dataset":0.1333467758,"dev-research":0.149332359,"prompt-eng":0.3305937096,"data-quality":0.2879830912,"ml-security":0.2742853313}}
{"text":"Existing methods suffer from overly pessimistic modeling with low generalization confidence.","meta":{"url":"http://arxiv.org/abs/2307.13943v1"},"cats":{"new-dataset":0.0110907766,"dev-research":0.2587517533,"prompt-eng":0.4029391512,"data-quality":0.2153696109,"ml-security":0.1640458324}}
{"text":"As generalizing to arbitrary test distributions is impossible, we hypothesize that further structure on the topology of distributions is crucial in developing strong OOD resilience.","meta":{"url":"http://arxiv.org/abs/2307.13943v1"},"cats":{"new-dataset":0.0946866332,"dev-research":0.2553209399,"prompt-eng":0.4024004697,"data-quality":0.2352759304,"ml-security":0.3936484114}}
{"text":"To this end, we propose topology-aware robust optimization (TRO) that seamlessly integrates distributional topology in a principled optimization framework.","meta":{"url":"http://arxiv.org/abs/2307.13943v1"},"cats":{"new-dataset":0.0565791158,"dev-research":0.2638382066,"prompt-eng":0.3903410916,"data-quality":0.17370272,"ml-security":0.1225704385}}
{"text":"More specifically, TRO solves two optimization objectives: (1) Topology Learning which explores data manifold to uncover the distributional topology; (2) Learning on Topology which exploits the topology to constrain robust optimization for tightly-bounded generalization risks.","meta":{"url":"http://arxiv.org/abs/2307.13943v1"},"cats":{"new-dataset":0.0265884795,"dev-research":0.2632991955,"prompt-eng":0.3426221688,"data-quality":0.1215511245,"ml-security":0.1969237632}}
{"text":"We theoretically demonstrate the effectiveness of our approach and empirically show that it significantly outperforms the state of the arts in a wide range of tasks including classification, regression, and semantic segmentation.","meta":{"url":"http://arxiv.org/abs/2307.13943v1"},"cats":{"new-dataset":0.1354643762,"dev-research":0.2238958868,"prompt-eng":0.4098743705,"data-quality":0.2967966466,"ml-security":0.0674236815}}
{"text":"Moreover, we empirically find the data-driven distributional topology is consistent with domain knowledge, enhancing the explainability of our approach.","meta":{"url":"http://arxiv.org/abs/2307.13943v1"},"cats":{"new-dataset":0.0795625574,"dev-research":0.2686405665,"prompt-eng":0.3797765346,"data-quality":0.172645181,"ml-security":0.098302536}}
{"text":"The weighted Euler characteristic transform (WECT) is a new tool for extracting shape information from data equipped with a weight function.","meta":{"url":"http://arxiv.org/abs/2307.13940v1"},"cats":{"new-dataset":0.1261623574,"dev-research":0.1817024894,"prompt-eng":0.4411393218,"data-quality":0.1310147072,"ml-security":0.0588329718}}
{"text":"Image data may benefit from the WECT where the intensity of the pixels are used to define the weight function.","meta":{"url":"http://arxiv.org/abs/2307.13940v1"},"cats":{"new-dataset":0.1618043221,"dev-research":0.1756897022,"prompt-eng":0.3960337838,"data-quality":0.132089276,"ml-security":0.0620741985}}
{"text":"In this work, an empirical assessment of the WECT's ability to distinguish shapes on images with different pixel intensity distributions is considered, along with visualization techniques to improve the intuition and understanding of what is captured by the WECT.","meta":{"url":"http://arxiv.org/abs/2307.13940v1"},"cats":{"new-dataset":0.1452895219,"dev-research":0.2311264596,"prompt-eng":0.4398901879,"data-quality":0.1837019116,"ml-security":0.0643989373}}
{"text":"Additionally, the expected weighted Euler characteristic and the expected WECT are derived.","meta":{"url":"http://arxiv.org/abs/2307.13940v1"},"cats":{"new-dataset":0.0697924794,"dev-research":0.1275147498,"prompt-eng":0.4375874078,"data-quality":0.1055183176,"ml-security":0.0657716269}}
{"text":"Semi-supervised semantic segmentation (SSS) is an important task that utilizes both labeled and unlabeled data to reduce expenses on labeling training examples.","meta":{"url":"http://arxiv.org/abs/2307.13938v1"},"cats":{"new-dataset":0.1560835403,"dev-research":0.2132384866,"prompt-eng":0.4243320442,"data-quality":0.4692150312,"ml-security":0.1033926076}}
{"text":"However, the effectiveness of SSS algorithms is limited by the difficulty of fully exploiting the potential of unlabeled data.","meta":{"url":"http://arxiv.org/abs/2307.13938v1"},"cats":{"new-dataset":0.029542581,"dev-research":0.2006652203,"prompt-eng":0.3988681304,"data-quality":0.2316776067,"ml-security":0.2018568257}}
{"text":"To address this, we propose a dual-level Siamese structure network (DSSN) for pixel-wise contrastive learning.","meta":{"url":"http://arxiv.org/abs/2307.13938v1"},"cats":{"new-dataset":0.4041661161,"dev-research":0.2000320674,"prompt-eng":0.3095946285,"data-quality":0.1385998954,"ml-security":0.086523166}}
{"text":"By aligning positive pairs with a pixel-wise contrastive loss using strong augmented views in both low-level image space and high-level feature space, the proposed DSSN is designed to maximize the utilization of available unlabeled data.","meta":{"url":"http://arxiv.org/abs/2307.13938v1"},"cats":{"new-dataset":0.1617036308,"dev-research":0.2187692639,"prompt-eng":0.3719590491,"data-quality":0.2423382183,"ml-security":0.130551647}}
{"text":"Additionally, we introduce a novel class-aware pseudo-label selection strategy for weak-to-strong supervision, which addresses the limitations of most existing methods that do not perform selection or apply a predefined threshold for all classes.","meta":{"url":"http://arxiv.org/abs/2307.13938v1"},"cats":{"new-dataset":0.0665074404,"dev-research":0.2725271748,"prompt-eng":0.4729980429,"data-quality":0.579324419,"ml-security":0.2582885762}}
{"text":"Specifically, our strategy selects the top high-confidence prediction of the weak view for each class to generate pseudo labels that supervise the strong augmented views.","meta":{"url":"http://arxiv.org/abs/2307.13938v1"},"cats":{"new-dataset":0.1142533694,"dev-research":0.2393746191,"prompt-eng":0.4504920024,"data-quality":0.2967806896,"ml-security":0.204272552}}
{"text":"This strategy is capable of taking into account the class imbalance and improving the performance of long-tailed classes.","meta":{"url":"http://arxiv.org/abs/2307.13938v1"},"cats":{"new-dataset":0.0402757217,"dev-research":0.2176103681,"prompt-eng":0.4439994571,"data-quality":0.1730540561,"ml-security":0.2030995008}}
{"text":"Our proposed method achieves state-of-the-art results on two datasets, PASCAL VOC 2012 and Cityscapes, outperforming other SSS algorithms by a significant margin.","meta":{"url":"http://arxiv.org/abs/2307.13938v1"},"cats":{"new-dataset":0.5073902493,"dev-research":0.1879283692,"prompt-eng":0.3672268977,"data-quality":0.2126404044,"ml-security":0.0761624869}}
{"text":"We consider the Generalized Makespan Problem (GMP) on unrelated machines, where we are given $n$ jobs and $m$ machines and each job $j$ has arbitrary processing time $p_{ij}$ on machine $i$. Additionally, there is a general symmetric monotone norm $\\psi_i$ for each machine $i$, that determines the load on machine $i$ as a function of the sizes of jobs assigned to it.","meta":{"url":"http://arxiv.org/abs/2307.13937v1"},"cats":{"new-dataset":0.0972751857,"dev-research":0.150155209,"prompt-eng":0.3321657467,"data-quality":0.1542744478,"ml-security":0.1369158379}}
{"text":"The goal is to assign the jobs to minimize the maximum machine load.   ","meta":{"url":"http://arxiv.org/abs/2307.13937v1"},"cats":{"new-dataset":0.0411220446,"dev-research":0.2703193884,"prompt-eng":0.3686764062,"data-quality":0.1065821269,"ml-security":0.1122180192}}
{"text":"Recently, Deng, Li, and Rabani (SODA'22) gave a $3$ approximation for GMP when the $\\psi_i$ are top-$k$ norms, and they ask the question whether an $O(1)$ approximation exists for general norms $\\psi$?","meta":{"url":"http://arxiv.org/abs/2307.13937v1"},"cats":{"new-dataset":0.0327579042,"dev-research":0.1503661518,"prompt-eng":0.3035448349,"data-quality":0.1219067866,"ml-security":0.083191884}}
{"text":"We answer this negatively and show that, under natural complexity assumptions, there is some fixed constant $\\delta>0$, such that GMP is $\\Omega(\\log^{\\delta} n)$ hard to approximate.","meta":{"url":"http://arxiv.org/abs/2307.13937v1"},"cats":{"new-dataset":0.0266288631,"dev-research":0.1402492629,"prompt-eng":0.3244645191,"data-quality":0.1642981347,"ml-security":0.1520846695}}
{"text":"We also give an $\\Omega(\\log^{1/2} n)$ integrality gap for the natural configuration LP.","meta":{"url":"http://arxiv.org/abs/2307.13937v1"},"cats":{"new-dataset":0.1975678653,"dev-research":0.1390126013,"prompt-eng":0.3584775685,"data-quality":0.1573130827,"ml-security":0.0542004922}}
{"text":"Driver distraction has become a significant cause of severe traffic accidents over the past decade.","meta":{"url":"http://arxiv.org/abs/2307.13933v1"},"cats":{"new-dataset":0.0223548985,"dev-research":0.4028921753,"prompt-eng":0.3427318105,"data-quality":0.1427722574,"ml-security":0.2208645813}}
{"text":"Despite the growing development of vision-driven driver monitoring systems, the lack of comprehensive perception datasets restricts road safety and traffic security.","meta":{"url":"http://arxiv.org/abs/2307.13933v1"},"cats":{"new-dataset":0.371938132,"dev-research":0.2661522592,"prompt-eng":0.3606978694,"data-quality":0.1925847552,"ml-security":0.4034869351}}
{"text":"In this paper, we present an AssIstive Driving pErception dataset (AIDE) that considers context information both inside and outside the vehicle in naturalistic scenarios.","meta":{"url":"http://arxiv.org/abs/2307.13933v1"},"cats":{"new-dataset":0.3189128522,"dev-research":0.2356240355,"prompt-eng":0.3952389724,"data-quality":0.2153240877,"ml-security":0.1263993398}}
{"text":"AIDE facilitates holistic driver monitoring through three distinctive characteristics, including multi-view settings of driver and scene, multi-modal annotations of face, body, posture, and gesture, and four pragmatic task designs for driving understanding.","meta":{"url":"http://arxiv.org/abs/2307.13933v1"},"cats":{"new-dataset":0.1491986859,"dev-research":0.4079601739,"prompt-eng":0.4332298218,"data-quality":0.1460540939,"ml-security":0.0986774449}}
{"text":"To thoroughly explore AIDE, we provide experimental benchmarks on three kinds of baseline frameworks via extensive methods.","meta":{"url":"http://arxiv.org/abs/2307.13933v1"},"cats":{"new-dataset":0.148003842,"dev-research":0.3492481201,"prompt-eng":0.4636894881,"data-quality":0.1761011392,"ml-security":0.0677442751}}
{"text":"Moreover, two fusion strategies are introduced to give new insights into learning effective multi-stream/modal representations.","meta":{"url":"http://arxiv.org/abs/2307.13933v1"},"cats":{"new-dataset":0.0230070411,"dev-research":0.2510072697,"prompt-eng":0.3599044961,"data-quality":0.1359067929,"ml-security":0.0903705409}}
{"text":"We also systematically investigate the importance and rationality of the key components in AIDE and benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.13933v1"},"cats":{"new-dataset":0.0472767077,"dev-research":0.3394810659,"prompt-eng":0.4136517129,"data-quality":0.1388678095,"ml-security":0.0783535703}}
{"text":"The project link is https://github.com/ydk122024/AIDE.","meta":{"url":"http://arxiv.org/abs/2307.13933v1"},"cats":{"new-dataset":0.4052018877,"dev-research":0.1892965009,"prompt-eng":0.4405502938,"data-quality":0.1263367278,"ml-security":0.0433391295}}
{"text":"Multi-agent collaborative perception as a potential application for vehicle-to-everything communication could significantly improve the perception performance of autonomous vehicles over single-agent perception.","meta":{"url":"http://arxiv.org/abs/2307.13929v1"},"cats":{"new-dataset":0.0365347324,"dev-research":0.2417181,"prompt-eng":0.3989857159,"data-quality":0.1117109084,"ml-security":0.0908431701}}
{"text":"However, several challenges remain in achieving pragmatic information sharing in this emerging research.","meta":{"url":"http://arxiv.org/abs/2307.13929v1"},"cats":{"new-dataset":0.0995752008,"dev-research":0.4454526863,"prompt-eng":0.3815500385,"data-quality":0.2096350096,"ml-security":0.1724662313}}
{"text":"In this paper, we propose SCOPE, a novel collaborative perception framework that aggregates the spatio-temporal awareness characteristics across on-road agents in an end-to-end manner.","meta":{"url":"http://arxiv.org/abs/2307.13929v1"},"cats":{"new-dataset":0.3537246622,"dev-research":0.2791679392,"prompt-eng":0.4219046277,"data-quality":0.1250900327,"ml-security":0.0857382141}}
{"text":"Specifically, SCOPE has three distinct strengths: i) it considers effective semantic cues of the temporal context to enhance current representations of the target agent; ii) it aggregates perceptually critical spatial information from heterogeneous agents and overcomes localization errors via multi-scale feature interactions; iii) it integrates multi-source representations of the target agent based on their complementary contributions by an adaptive fusion paradigm.","meta":{"url":"http://arxiv.org/abs/2307.13929v1"},"cats":{"new-dataset":0.0869383247,"dev-research":0.3132484069,"prompt-eng":0.3825426205,"data-quality":0.1268923898,"ml-security":0.1100469875}}
{"text":"To thoroughly evaluate SCOPE, we consider both real-world and simulated scenarios of collaborative 3D object detection tasks on three datasets.","meta":{"url":"http://arxiv.org/abs/2307.13929v1"},"cats":{"new-dataset":0.449796514,"dev-research":0.2146546992,"prompt-eng":0.3954027028,"data-quality":0.2005426829,"ml-security":0.1328022641}}
{"text":"Extensive experiments demonstrate the superiority of our approach and the necessity of the proposed components.","meta":{"url":"http://arxiv.org/abs/2307.13929v1"},"cats":{"new-dataset":0.0256835791,"dev-research":0.191224482,"prompt-eng":0.4571149902,"data-quality":0.1238373537,"ml-security":0.0598931592}}
{"text":"The behaviour of multi-agent learning in competitive settings is often considered under the restrictive assumption of a zero-sum game.","meta":{"url":"http://arxiv.org/abs/2307.13928v1"},"cats":{"new-dataset":0.0333103136,"dev-research":0.1836571823,"prompt-eng":0.3319010429,"data-quality":0.1342018455,"ml-security":0.3121422828}}
{"text":"Only under this strict requirement is the behaviour of learning well understood; beyond this, learning dynamics can often display non-convergent behaviours which prevent fixed-point analysis.","meta":{"url":"http://arxiv.org/abs/2307.13928v1"},"cats":{"new-dataset":0.07322063,"dev-research":0.2515464653,"prompt-eng":0.3270084513,"data-quality":0.1699377212,"ml-security":0.3030720465}}
{"text":"Nonetheless, many relevant competitive games do not satisfy the zero-sum assumption.   ","meta":{"url":"http://arxiv.org/abs/2307.13928v1"},"cats":{"new-dataset":0.0115856638,"dev-research":0.1957552503,"prompt-eng":0.2589595411,"data-quality":0.183715446,"ml-security":0.2399509657}}
{"text":"Motivated by this, we study a smooth variant of Q-Learning, a popular reinforcement learning dynamics which balances the agents' tendency to maximise their payoffs with their propensity to explore the state space.","meta":{"url":"http://arxiv.org/abs/2307.13928v1"},"cats":{"new-dataset":0.0767698652,"dev-research":0.1737520544,"prompt-eng":0.3459037774,"data-quality":0.0986196531,"ml-security":0.3026566604}}
{"text":"We examine this dynamic in games which are `close' to network zero-sum games and find that Q-Learning converges to a neighbourhood around a unique equilibrium.","meta":{"url":"http://arxiv.org/abs/2307.13928v1"},"cats":{"new-dataset":0.0895297418,"dev-research":0.1579149583,"prompt-eng":0.2774081278,"data-quality":0.1305300946,"ml-security":0.3776388448}}
{"text":"The size of the neighbourhood is determined by the `distance' to the zero-sum game, as well as the exploration rates of the agents.","meta":{"url":"http://arxiv.org/abs/2307.13928v1"},"cats":{"new-dataset":0.1757904155,"dev-research":0.1878463179,"prompt-eng":0.2923746754,"data-quality":0.0777767297,"ml-security":0.1082820341}}
{"text":"We complement these results by providing a method whereby, given an arbitrary network game, the `nearest' network zero-sum game can be found efficiently.","meta":{"url":"http://arxiv.org/abs/2307.13928v1"},"cats":{"new-dataset":0.272342184,"dev-research":0.1827390185,"prompt-eng":0.3221322644,"data-quality":0.1629673115,"ml-security":0.1928633866}}
{"text":"As our experiments show, these guarantees are independent of whether the dynamics ultimately reach an equilibrium, or remain non-convergent.","meta":{"url":"http://arxiv.org/abs/2307.13928v1"},"cats":{"new-dataset":0.030564152,"dev-research":0.1448402167,"prompt-eng":0.3034442279,"data-quality":0.1149339293,"ml-security":0.2716587062}}
{"text":"In image dehazing task, haze density is a key feature and affects the performance of dehazing methods.","meta":{"url":"http://arxiv.org/abs/2307.13927v1"},"cats":{"new-dataset":0.0236320309,"dev-research":0.3479751111,"prompt-eng":0.3455094065,"data-quality":0.1119412709,"ml-security":0.073336494}}
{"text":"However, some of the existing methods lack a comparative image to measure densities, and others create intermediate results but lack the exploitation of their density differences, which can facilitate perception of density.","meta":{"url":"http://arxiv.org/abs/2307.13927v1"},"cats":{"new-dataset":0.0327294182,"dev-research":0.2040910921,"prompt-eng":0.3622570794,"data-quality":0.1760043396,"ml-security":0.0611898}}
{"text":"To address these deficiencies, we propose a density-aware dehazing method named Density Feature Refinement Network (DFR-Net) that extracts haze density features from density differences and leverages density differences to refine density features.","meta":{"url":"http://arxiv.org/abs/2307.13927v1"},"cats":{"new-dataset":0.1438897546,"dev-research":0.3949928982,"prompt-eng":0.3529546848,"data-quality":0.1982343317,"ml-security":0.0992718746}}
{"text":"In DFR-Net, we first generate a proposal image that has lower overall density than the hazy input, bringing in global density differences.","meta":{"url":"http://arxiv.org/abs/2307.13927v1"},"cats":{"new-dataset":0.3058210851,"dev-research":0.2166771348,"prompt-eng":0.3834188194,"data-quality":0.1646556795,"ml-security":0.0651435313}}
{"text":"Additionally, the dehazing residual of the proposal image reflects the level of dehazing performance and provides local density differences that indicate localized hard dehazing or high density areas.","meta":{"url":"http://arxiv.org/abs/2307.13927v1"},"cats":{"new-dataset":0.1552935926,"dev-research":0.3242389171,"prompt-eng":0.3731473275,"data-quality":0.1296188303,"ml-security":0.077529441}}
{"text":"Subsequently, we introduce a Global Branch (GB) and a Local Branch (LB) to achieve density-awareness.","meta":{"url":"http://arxiv.org/abs/2307.13927v1"},"cats":{"new-dataset":0.1382022055,"dev-research":0.2032931096,"prompt-eng":0.4503743509,"data-quality":0.173412562,"ml-security":0.0642084059}}
{"text":"In GB, we use Siamese networks for feature extraction of hazy inputs and proposal images, and we propose a Global Density Feature Refinement (GDFR) module that can refine features by pushing features with different global densities further away.","meta":{"url":"http://arxiv.org/abs/2307.13927v1"},"cats":{"new-dataset":0.5118476032,"dev-research":0.3065142596,"prompt-eng":0.3629700408,"data-quality":0.2390965377,"ml-security":0.0872304102}}
{"text":"In LB, we explore local density features from the dehazing residuals between hazy inputs and proposal images and introduce an Intermediate Dehazing Residual Feedforward (IDRF) module to update local features and pull them closer to clear image features.","meta":{"url":"http://arxiv.org/abs/2307.13927v1"},"cats":{"new-dataset":0.2717325271,"dev-research":0.3276982897,"prompt-eng":0.361219354,"data-quality":0.2303965222,"ml-security":0.1279878745}}
{"text":"Sufficient experiments demonstrate that the proposed method achieves results beyond the state-of-the-art methods on various datasets.","meta":{"url":"http://arxiv.org/abs/2307.13927v1"},"cats":{"new-dataset":0.2609051445,"dev-research":0.1416522078,"prompt-eng":0.4051140191,"data-quality":0.2476891312,"ml-security":0.051165942}}
{"text":"The level-$k$ $\\ell_1$-Fourier weight of a Boolean function refers to the sum of absolute values of its level-$k$ Fourier coefficients.","meta":{"url":"http://arxiv.org/abs/2307.13926v1"},"cats":{"new-dataset":0.0283071797,"dev-research":0.2104482821,"prompt-eng":0.3452456963,"data-quality":0.1411590128,"ml-security":0.1104464292}}
{"text":"Fourier growth refers to the growth of these weights as $k$ grows.","meta":{"url":"http://arxiv.org/abs/2307.13926v1"},"cats":{"new-dataset":0.0400618369,"dev-research":0.1848552968,"prompt-eng":0.2798003594,"data-quality":0.1059383007,"ml-security":0.0910734696}}
{"text":"It has been extensively studied for various computational models, and bounds on the Fourier growth, even for the first few levels, have proven useful in learning theory, circuit lower bounds, pseudorandomness, and quantum-classical separations.   ","meta":{"url":"http://arxiv.org/abs/2307.13926v1"},"cats":{"new-dataset":0.0383826185,"dev-research":0.1261859432,"prompt-eng":0.3243474947,"data-quality":0.108681138,"ml-security":0.1693207271}}
{"text":"We investigate the Fourier growth of certain functions that naturally arise from communication protocols for XOR functions (partial functions evaluated on the bitwise XOR of the inputs to Alice and Bob).","meta":{"url":"http://arxiv.org/abs/2307.13926v1"},"cats":{"new-dataset":0.1231997265,"dev-research":0.2461168009,"prompt-eng":0.357088351,"data-quality":0.1262236289,"ml-security":0.2485465137}}
{"text":"If a protocol $\\mathcal C$ computes an XOR function, then $\\mathcal C(x,y)$ is a function of the parity $x\\oplus y$.","meta":{"url":"http://arxiv.org/abs/2307.13926v1"},"cats":{"new-dataset":0.1096996716,"dev-research":0.2597505801,"prompt-eng":0.3937857381,"data-quality":0.1968690837,"ml-security":0.208150632}}
{"text":"This motivates us to analyze the XOR-fiber of $\\mathcal C$, defined as $h(z):=\\mathbb E_{x,y}[\\mathcal C(x,y)|x\\oplus y=z]$.   We present improved Fourier growth bounds for the XOR-fibers of protocols that communicate $d$ bits.","meta":{"url":"http://arxiv.org/abs/2307.13926v1"},"cats":{"new-dataset":0.1878127771,"dev-research":0.2256175094,"prompt-eng":0.3588630508,"data-quality":0.1065904407,"ml-security":0.173118593}}
{"text":"For the first level, we show a tight $O(\\sqrt d)$ bound and obtain a new coin theorem, as well as an alternative proof for the tight randomized communication lower bound for Gap-Hamming.","meta":{"url":"http://arxiv.org/abs/2307.13926v1"},"cats":{"new-dataset":0.1816887198,"dev-research":0.1796692414,"prompt-eng":0.3442804079,"data-quality":0.2028487502,"ml-security":0.2162783153}}
{"text":"For the second level, we show an $d^{3/2}\\cdot\\mathrm{polylog}(n)$ bound, which improves the previous $O(d^2)$ bound by Girish, Raz, and Tal (ITCS 2021) and implies a polynomial improvement on the randomized communication lower bound for the XOR-lift of Forrelation, extending its quantum-classical gap.   ","meta":{"url":"http://arxiv.org/abs/2307.13926v1"},"cats":{"new-dataset":0.0943921965,"dev-research":0.1543602154,"prompt-eng":0.3357241745,"data-quality":0.1596885368,"ml-security":0.1936333232}}
{"text":"Our analysis is based on a new way of adaptively partitioning a relatively large set in Gaussian space to control its moments in all directions.","meta":{"url":"http://arxiv.org/abs/2307.13926v1"},"cats":{"new-dataset":0.1549520602,"dev-research":0.144275092,"prompt-eng":0.3556258087,"data-quality":0.1333464489,"ml-security":0.1353288103}}
{"text":"We achieve this via martingale arguments and allowing protocols to transmit real values.","meta":{"url":"http://arxiv.org/abs/2307.13926v1"},"cats":{"new-dataset":0.1222793823,"dev-research":0.1747461605,"prompt-eng":0.381799826,"data-quality":0.1541032929,"ml-security":0.2913631111}}
{"text":"We also show a connection between Fourier growth and lifting theorems with constant-sized gadgets as a potential approach to prove optimal bounds for the second level and beyond.","meta":{"url":"http://arxiv.org/abs/2307.13926v1"},"cats":{"new-dataset":0.0456852114,"dev-research":0.1861688485,"prompt-eng":0.3483697862,"data-quality":0.0919029835,"ml-security":0.1399103621}}
{"text":"3D anomaly detection is an emerging and vital computer vision task in industrial manufacturing (IM).","meta":{"url":"http://arxiv.org/abs/2307.13925v1"},"cats":{"new-dataset":0.120323298,"dev-research":0.2865081898,"prompt-eng":0.3644674192,"data-quality":0.2750668406,"ml-security":0.2176558017}}
{"text":"Recently many advanced algorithms have been published, but most of them cannot meet the needs of IM.","meta":{"url":"http://arxiv.org/abs/2307.13925v1"},"cats":{"new-dataset":0.1030407011,"dev-research":0.1621401367,"prompt-eng":0.3652527363,"data-quality":0.1322949626,"ml-security":0.0786388991}}
{"text":"There are several disadvantages: i) difficult to deploy on production lines since their algorithms heavily rely on large pre-trained models; ii) hugely increase storage overhead due to overuse of memory banks; iii) the inference speed cannot be achieved in real-time.","meta":{"url":"http://arxiv.org/abs/2307.13925v1"},"cats":{"new-dataset":0.0088328874,"dev-research":0.3315356329,"prompt-eng":0.3325952134,"data-quality":0.0963079169,"ml-security":0.1677457433}}
{"text":"To overcome these issues, we propose an easy and deployment-friendly network (called EasyNet) without using pre-trained models and memory banks: firstly, we design a multi-scale multi-modality feature encoder-decoder to accurately reconstruct the segmentation maps of anomalous regions and encourage the interaction between RGB images and depth images; secondly, we adopt a multi-modality anomaly segmentation network to achieve a precise anomaly map; thirdly, we propose an attention-based information entropy fusion module for feature fusion during inference, making it suitable for real-time deployment.","meta":{"url":"http://arxiv.org/abs/2307.13925v1"},"cats":{"new-dataset":0.2592046986,"dev-research":0.3101392525,"prompt-eng":0.4105588759,"data-quality":0.2690335731,"ml-security":0.2408774891}}
{"text":"Extensive experiments show that EasyNet achieves an anomaly detection AUROC of 92.6% without using pre-trained models and memory banks.","meta":{"url":"http://arxiv.org/abs/2307.13925v1"},"cats":{"new-dataset":0.0998308364,"dev-research":0.2961635864,"prompt-eng":0.4276328499,"data-quality":0.3718615464,"ml-security":0.5391717809}}
{"text":"In addition, EasyNet is faster than existing methods, with a high frame rate of 94.55 FPS on a Tesla V100 GPU.","meta":{"url":"http://arxiv.org/abs/2307.13925v1"},"cats":{"new-dataset":0.0876159592,"dev-research":0.2945424028,"prompt-eng":0.3756025268,"data-quality":0.1133819441,"ml-security":0.076199134}}
{"text":"The field of trajectory forecasting has grown significantly in recent years, partially owing to the release of numerous large-scale, real-world human trajectory datasets for autonomous vehicles (AVs) and pedestrian motion tracking.","meta":{"url":"http://arxiv.org/abs/2307.13924v1"},"cats":{"new-dataset":0.5030920915,"dev-research":0.18475945,"prompt-eng":0.3106809753,"data-quality":0.0677991862,"ml-security":0.1347879633}}
{"text":"While such datasets have been a boon for the community, they each use custom and unique data formats and APIs, making it cumbersome for researchers to train and evaluate methods across multiple datasets.","meta":{"url":"http://arxiv.org/abs/2307.13924v1"},"cats":{"new-dataset":0.5706895888,"dev-research":0.2705203212,"prompt-eng":0.3692624736,"data-quality":0.1854440125,"ml-security":0.078713664}}
{"text":"To remedy this, we present trajdata: a unified interface to multiple human trajectory datasets.","meta":{"url":"http://arxiv.org/abs/2307.13924v1"},"cats":{"new-dataset":0.7043943452,"dev-research":0.1602875876,"prompt-eng":0.3140470653,"data-quality":0.1007401083,"ml-security":0.0684791757}}
{"text":"At its core, trajdata provides a simple, uniform, and efficient representation and API for trajectory and map data.","meta":{"url":"http://arxiv.org/abs/2307.13924v1"},"cats":{"new-dataset":0.2946295993,"dev-research":0.2164443204,"prompt-eng":0.3324031569,"data-quality":0.0811072007,"ml-security":0.0574898549}}
{"text":"As a demonstration of its capabilities, in this work we conduct a comprehensive empirical evaluation of existing trajectory datasets, providing users with a rich understanding of the data underpinning much of current pedestrian and AV motion forecasting research, and proposing suggestions for future datasets from these insights.","meta":{"url":"http://arxiv.org/abs/2307.13924v1"},"cats":{"new-dataset":0.502850346,"dev-research":0.1860000413,"prompt-eng":0.322469646,"data-quality":0.0916270187,"ml-security":0.0942330433}}
{"text":"trajdata is permissively licensed (Apache 2.0) and can be accessed online at https://github.com/NVlabs/trajdata","meta":{"url":"http://arxiv.org/abs/2307.13924v1"},"cats":{"new-dataset":0.2802579089,"dev-research":0.1711820033,"prompt-eng":0.3380896419,"data-quality":0.0769823729,"ml-security":0.0554999169}}
{"text":"Grammatical error correction aims to correct ungrammatical sentences automatically.","meta":{"url":"http://arxiv.org/abs/2307.13923v1"},"cats":{"new-dataset":0.0153447893,"dev-research":0.4208672023,"prompt-eng":0.433834534,"data-quality":0.5217063709,"ml-security":0.0880589669}}
{"text":"Recently, some work has demonstrated the excellent capabilities of closed-source Large Language Models (LLMs, e.g., ChatGPT) in grammatical error correction.","meta":{"url":"http://arxiv.org/abs/2307.13923v1"},"cats":{"new-dataset":0.2673456194,"dev-research":0.2308631142,"prompt-eng":0.4190503861,"data-quality":0.4090994022,"ml-security":0.0936883365}}
{"text":"However, the potential of open-source LLMs remains unexplored.","meta":{"url":"http://arxiv.org/abs/2307.13923v1"},"cats":{"new-dataset":0.0852869253,"dev-research":0.1580054889,"prompt-eng":0.3265292465,"data-quality":0.184101955,"ml-security":0.1937457534}}
{"text":"In this paper, we introduced GrammarGPT, an open-source LLM, to preliminary explore its potential for native Chinese grammatical error correction.","meta":{"url":"http://arxiv.org/abs/2307.13923v1"},"cats":{"new-dataset":0.2023959888,"dev-research":0.2824915144,"prompt-eng":0.4489046965,"data-quality":0.4598417632,"ml-security":0.0688867091}}
{"text":"The core recipe of GrammarGPT is to leverage the hybrid dataset of ChatGPT-generated and human-annotated.","meta":{"url":"http://arxiv.org/abs/2307.13923v1"},"cats":{"new-dataset":0.6955363486,"dev-research":0.3100230439,"prompt-eng":0.4202881805,"data-quality":0.3039830683,"ml-security":0.0743227365}}
{"text":"For grammatical errors with clues, we proposed a heuristic method to guide ChatGPT to generate ungrammatical sentences by providing those clues.","meta":{"url":"http://arxiv.org/abs/2307.13923v1"},"cats":{"new-dataset":0.2255543546,"dev-research":0.4242410882,"prompt-eng":0.4747176506,"data-quality":0.3683884284,"ml-security":0.0648371252}}
{"text":"For grammatical errors without clues, we collected ungrammatical sentences from publicly available websites and manually corrected them.","meta":{"url":"http://arxiv.org/abs/2307.13923v1"},"cats":{"new-dataset":0.2127769571,"dev-research":0.3597675366,"prompt-eng":0.4369846143,"data-quality":0.5123085986,"ml-security":0.1101410868}}
{"text":"In addition, we employed an error-invariant augmentation method to enhance the ability of the model to correct native Chinese grammatical errors.","meta":{"url":"http://arxiv.org/abs/2307.13923v1"},"cats":{"new-dataset":0.0483551813,"dev-research":0.302237777,"prompt-eng":0.4767160265,"data-quality":0.4755920109,"ml-security":0.084942169}}
{"text":"We ultimately constructed about 1k parallel data and utilized these data to fine-tune open-source LLMs (e.g., Phoenix, released by The Chinese University of Hong Kong, Shenzhen) with instruction tuning.","meta":{"url":"http://arxiv.org/abs/2307.13923v1"},"cats":{"new-dataset":0.359289407,"dev-research":0.2263242026,"prompt-eng":0.4417787015,"data-quality":0.1333679372,"ml-security":0.0703645503}}
{"text":"The experimental results show that GrammarGPT outperforms the existing SOTA system significantly.","meta":{"url":"http://arxiv.org/abs/2307.13923v1"},"cats":{"new-dataset":0.1351547487,"dev-research":0.2463741821,"prompt-eng":0.4372744208,"data-quality":0.2185861987,"ml-security":0.0571030911}}
{"text":"Although model parameters are 20x larger than the SOTA baseline, the required amount of data for instruction tuning is 1200x smaller, illustrating the potential of open-source LLMs on native CGEC.","meta":{"url":"http://arxiv.org/abs/2307.13923v1"},"cats":{"new-dataset":0.1305022841,"dev-research":0.2409164745,"prompt-eng":0.4143369422,"data-quality":0.0924902929,"ml-security":0.0557130429}}
{"text":"Our GrammarGPT ranks $3^{rd}$ on NLPCC2023 SharedTask1, demonstrating our approach's effectiveness.","meta":{"url":"http://arxiv.org/abs/2307.13923v1"},"cats":{"new-dataset":0.5266257102,"dev-research":0.2346062557,"prompt-eng":0.4096780721,"data-quality":0.3088358876,"ml-security":0.0805146252}}
{"text":"The code and data are available at \\url{https://github.com/FreedomIntelligence/GrammarGPT}.","meta":{"url":"http://arxiv.org/abs/2307.13923v1"},"cats":{"new-dataset":0.5921935851,"dev-research":0.184112697,"prompt-eng":0.4457340039,"data-quality":0.1734154112,"ml-security":0.0536207205}}
{"text":"The behaviour of multi-agent learning in many player games has been shown to display complex dynamics outside of restrictive examples such as network zero-sum games.","meta":{"url":"http://arxiv.org/abs/2307.13922v1"},"cats":{"new-dataset":0.0939201171,"dev-research":0.2069335269,"prompt-eng":0.3272733953,"data-quality":0.1006959897,"ml-security":0.26180647}}
{"text":"In addition, it has been shown that convergent behaviour is less likely to occur as the number of players increase.","meta":{"url":"http://arxiv.org/abs/2307.13922v1"},"cats":{"new-dataset":0.0151607457,"dev-research":0.2471061829,"prompt-eng":0.326894962,"data-quality":0.1190038158,"ml-security":0.1815835508}}
{"text":"To make progress in resolving this problem, we study Q-Learning dynamics and determine a sufficient condition for the dynamics to converge to a unique equilibrium in any network game.","meta":{"url":"http://arxiv.org/abs/2307.13922v1"},"cats":{"new-dataset":0.0732654291,"dev-research":0.1594830488,"prompt-eng":0.3089226107,"data-quality":0.1148153693,"ml-security":0.370740071}}
{"text":"We find that this condition depends on the nature of pairwise interactions and on the network structure, but is explicitly independent of the total number of agents in the game.","meta":{"url":"http://arxiv.org/abs/2307.13922v1"},"cats":{"new-dataset":0.1448780093,"dev-research":0.1744339932,"prompt-eng":0.3160194461,"data-quality":0.0871913488,"ml-security":0.2276946892}}
{"text":"We evaluate this result on a number of representative network games and show that, under suitable network conditions, stable learning dynamics can be achieved with an arbitrary number of agents.","meta":{"url":"http://arxiv.org/abs/2307.13922v1"},"cats":{"new-dataset":0.1478353979,"dev-research":0.184847252,"prompt-eng":0.3260575827,"data-quality":0.1397200343,"ml-security":0.3185160265}}
{"text":"We consider the algorithmic problem of finding large \\textit{balanced} independent sets in sparse random bipartite graphs, and more generally the problem of finding independent sets with specified proportions of vertices on each side of the bipartition.","meta":{"url":"http://arxiv.org/abs/2307.13921v1"},"cats":{"new-dataset":0.3418591155,"dev-research":0.1335140085,"prompt-eng":0.3029935093,"data-quality":0.240076264,"ml-security":0.1829164337}}
{"text":"In a bipartite graph it is trivial to find an independent set of density at least half (take one of the partition classes).","meta":{"url":"http://arxiv.org/abs/2307.13921v1"},"cats":{"new-dataset":0.1335594433,"dev-research":0.1217149105,"prompt-eng":0.2773403884,"data-quality":0.2178955229,"ml-security":0.1128051198}}
{"text":"In contrast, in a random bipartite graph of average degree $d$, the largest balanced independent sets (containing equal number of vertices from each class) are typically of density $(2+o_d(1))","meta":{"url":"http://arxiv.org/abs/2307.13921v1"},"cats":{"new-dataset":0.0762465121,"dev-research":0.1526301084,"prompt-eng":0.2428872816,"data-quality":0.1416970592,"ml-security":0.1129330473}}
{"text":"\\frac{\\log d}{d}$. Can we find such large balanced independent sets in these graphs efficiently?","meta":{"url":"http://arxiv.org/abs/2307.13921v1"},"cats":{"new-dataset":0.3359860131,"dev-research":0.1346918377,"prompt-eng":0.3109466852,"data-quality":0.1560027185,"ml-security":0.1208578978}}
{"text":"By utilizing the overlap gap property and the low-degree algorithmic framework, we prove that local and low-degree algorithms (even those that know the bipartition) cannot find balanced independent sets of density greater than $(1+\\epsilon) \\frac{\\log d}{d}$ for any $\\epsilon>0$ fixed and $d$ large but constant.","meta":{"url":"http://arxiv.org/abs/2307.13921v1"},"cats":{"new-dataset":0.1259258231,"dev-research":0.1444088628,"prompt-eng":0.2994621058,"data-quality":0.2479769794,"ml-security":0.1416980283}}
{"text":"This factor $2$ statistical--computational gap between what exists and what local algorithms can achieve is analogous to the gap for finding large independent sets in (non-bipartite) random graphs.","meta":{"url":"http://arxiv.org/abs/2307.13921v1"},"cats":{"new-dataset":0.168689412,"dev-research":0.176894366,"prompt-eng":0.3004291162,"data-quality":0.201530962,"ml-security":0.1120952676}}
{"text":"Our results therefor suggest that this gap is pervasive in many models, and that hard computational problems can lurk inside otherwise tractable ones.","meta":{"url":"http://arxiv.org/abs/2307.13921v1"},"cats":{"new-dataset":0.0731819029,"dev-research":0.2248092714,"prompt-eng":0.355704332,"data-quality":0.2251610288,"ml-security":0.1404561248}}
{"text":"A particularly striking aspect of the gap in bipartite graphs is that the algorithm achieving the lower bound is extremely simple and can be implemented as a $1$-local algorithm and a degree-$1$ polynomial (a linear function).","meta":{"url":"http://arxiv.org/abs/2307.13921v1"},"cats":{"new-dataset":0.0828647913,"dev-research":0.2175599588,"prompt-eng":0.2825708335,"data-quality":0.1443126986,"ml-security":0.0868085809}}
{"text":"Bayesian causal discovery aims to infer the posterior distribution over causal models from observed data, quantifying epistemic uncertainty and benefiting downstream tasks.","meta":{"url":"http://arxiv.org/abs/2307.13917v1"},"cats":{"new-dataset":0.0474855736,"dev-research":0.2873351825,"prompt-eng":0.4190342623,"data-quality":0.3203352061,"ml-security":0.1640937508}}
{"text":"However, computational challenges arise due to joint inference over combinatorial space of Directed Acyclic Graphs (DAGs) and nonlinear functions.","meta":{"url":"http://arxiv.org/abs/2307.13917v1"},"cats":{"new-dataset":0.1122296061,"dev-research":0.2446139275,"prompt-eng":0.3497974675,"data-quality":0.1467936983,"ml-security":0.1201970721}}
{"text":"Despite recent progress towards efficient posterior inference over DAGs, existing methods are either limited to variational inference on node permutation matrices for linear causal models, leading to compromised inference accuracy, or continuous relaxation of adjacency matrices constrained by a DAG regularizer, which cannot ensure resulting graphs are DAGs.","meta":{"url":"http://arxiv.org/abs/2307.13917v1"},"cats":{"new-dataset":0.0492113108,"dev-research":0.2292399537,"prompt-eng":0.4088556505,"data-quality":0.207610088,"ml-security":0.1739538829}}
{"text":"In this work, we introduce a scalable Bayesian causal discovery framework based on stochastic gradient Markov Chain Monte Carlo (SG-MCMC) that overcomes these limitations.","meta":{"url":"http://arxiv.org/abs/2307.13917v1"},"cats":{"new-dataset":0.1577476443,"dev-research":0.2071982097,"prompt-eng":0.3781891372,"data-quality":0.1667867041,"ml-security":0.1713725104}}
{"text":"Our approach directly samples DAGs from the posterior without requiring any DAG regularization, simultaneously draws function parameter samples and is applicable to both linear and nonlinear causal models.","meta":{"url":"http://arxiv.org/abs/2307.13917v1"},"cats":{"new-dataset":0.0808429282,"dev-research":0.2172888218,"prompt-eng":0.451465376,"data-quality":0.205374171,"ml-security":0.1614838429}}
{"text":"To enable our approach, we derive a novel equivalence to the permutation-based DAG learning, which opens up possibilities of using any relaxed gradient estimator defined over permutations.","meta":{"url":"http://arxiv.org/abs/2307.13917v1"},"cats":{"new-dataset":0.1464645151,"dev-research":0.166607939,"prompt-eng":0.3515164763,"data-quality":0.2150861742,"ml-security":0.1597525994}}
{"text":"To our knowledge, this is the first framework applying gradient-based MCMC sampling for causal discovery.","meta":{"url":"http://arxiv.org/abs/2307.13917v1"},"cats":{"new-dataset":0.0654353118,"dev-research":0.1832901334,"prompt-eng":0.3879014747,"data-quality":0.2097358927,"ml-security":0.1349480162}}
{"text":"Empirical evaluations on synthetic and real-world datasets demonstrate our approach's effectiveness compared to state-of-the-art baselines.","meta":{"url":"http://arxiv.org/abs/2307.13917v1"},"cats":{"new-dataset":0.6896836726,"dev-research":0.274004625,"prompt-eng":0.3625816916,"data-quality":0.2927657898,"ml-security":0.1148543508}}
{"text":"This article aims to describe and explain the theoretical foundations of concurrent and set concurrent algorithms, considering an asynchronous shared memory system where any number of processes can crash.","meta":{"url":"http://arxiv.org/abs/2307.13915v1"},"cats":{"new-dataset":0.1843664249,"dev-research":0.2826463735,"prompt-eng":0.3644963054,"data-quality":0.1405604719,"ml-security":0.1704280176}}
{"text":"Verification of concurrent algorithms is often described in terms of their progress condition, which guarantees that eventually something good will happen, also called the security of the algorithms, and correctness, which guarantees that nothing bad will happen, also called liveliness.","meta":{"url":"http://arxiv.org/abs/2307.13915v1"},"cats":{"new-dataset":0.056118562,"dev-research":0.3597233023,"prompt-eng":0.370620508,"data-quality":0.1805920927,"ml-security":0.2401281857}}
{"text":"of the algorithms.","meta":{"url":"http://arxiv.org/abs/2307.13915v1"},"cats":{"new-dataset":0.1620511402,"dev-research":0.2440572394,"prompt-eng":0.3234521358,"data-quality":0.1544223612,"ml-security":0.1325414866}}
{"text":"The meaning of correctness of a concurrent algorithm is explained in detail, focusing on linearizability, and a generalization is addressed, concurrency by sets; which is much more recent and less well known.","meta":{"url":"http://arxiv.org/abs/2307.13915v1"},"cats":{"new-dataset":0.0439484601,"dev-research":0.3454900838,"prompt-eng":0.3693193146,"data-quality":0.2275655239,"ml-security":0.1273301085}}
{"text":"The {\\it SetStackLogic} algorithm is shown, which is a set-concurrent algorithm and is also an implementation of a stack with multiplicity.","meta":{"url":"http://arxiv.org/abs/2307.13915v1"},"cats":{"new-dataset":0.4030210138,"dev-research":0.2807131547,"prompt-eng":0.4262707621,"data-quality":0.1207791109,"ml-security":0.0750050034}}
{"text":"The properties of the algorithm {\\it SetStackLogic} are demonstrated in a formal and detailed way, in order to present a rigorous scheme in the formalization of this type of algorithm; same that could be used for other algorithms.","meta":{"url":"http://arxiv.org/abs/2307.13915v1"},"cats":{"new-dataset":0.2016676874,"dev-research":0.2780945795,"prompt-eng":0.4578393811,"data-quality":0.1794457557,"ml-security":0.0704259383}}
{"text":"In addition, the operation of the algorithm is explained through scenario examples that illustrate its dynamics in some possible executions.","meta":{"url":"http://arxiv.org/abs/2307.13915v1"},"cats":{"new-dataset":0.0418988688,"dev-research":0.3330578326,"prompt-eng":0.3836025642,"data-quality":0.0945651222,"ml-security":0.1258306697}}
{"text":"Can we design artificial intelligence (AI) systems that rank our social media feeds to consider democratic values such as mitigating partisan animosity as part of their objective functions?","meta":{"url":"http://arxiv.org/abs/2307.13912v1"},"cats":{"new-dataset":0.0572958066,"dev-research":0.2189122312,"prompt-eng":0.3750387608,"data-quality":0.2353313585,"ml-security":0.2963050118}}
{"text":"We introduce a method for translating established, vetted social scientific constructs into AI objective functions, which we term societal objective functions, and demonstrate the method with application to the political science construct of anti-democratic attitudes.","meta":{"url":"http://arxiv.org/abs/2307.13912v1"},"cats":{"new-dataset":0.0770861862,"dev-research":0.2907395257,"prompt-eng":0.3461340924,"data-quality":0.1795393352,"ml-security":0.2876212617}}
{"text":"Traditionally, we have lacked observable outcomes to use to train such models, however, the social sciences have developed survey instruments and qualitative codebooks for these constructs, and their precision facilitates translation into detailed prompts for large language models.","meta":{"url":"http://arxiv.org/abs/2307.13912v1"},"cats":{"new-dataset":0.2960359822,"dev-research":0.252342656,"prompt-eng":0.3773269926,"data-quality":0.2328187699,"ml-security":0.1097620242}}
{"text":"We apply this method to create a democratic attitude model that estimates the extent to which a social media post promotes anti-democratic attitudes, and test this democratic attitude model across three studies.","meta":{"url":"http://arxiv.org/abs/2307.13912v1"},"cats":{"new-dataset":0.0539592263,"dev-research":0.2218986957,"prompt-eng":0.3321040192,"data-quality":0.1521867613,"ml-security":0.1846047612}}
{"text":"In Study 1, we first test the attitudinal and behavioral effectiveness of the intervention among US partisans (N=1,380) by manually annotating (alpha=.895) social media posts with anti-democratic attitude scores and testing several feed ranking conditions based on these scores.","meta":{"url":"http://arxiv.org/abs/2307.13912v1"},"cats":{"new-dataset":0.0590702698,"dev-research":0.2570674799,"prompt-eng":0.4266958273,"data-quality":0.2442256305,"ml-security":0.1023733511}}
{"text":"Removal (d=.20) and downranking feeds (d=.25) reduced participants' partisan animosity without compromising their experience and engagement.","meta":{"url":"http://arxiv.org/abs/2307.13912v1"},"cats":{"new-dataset":0.0134147924,"dev-research":0.2428359365,"prompt-eng":0.3467594538,"data-quality":0.273201027,"ml-security":0.1929810508}}
{"text":"In Study 2, we scale up the manual labels by creating the democratic attitude model, finding strong agreement with manual labels (rho=.75).","meta":{"url":"http://arxiv.org/abs/2307.13912v1"},"cats":{"new-dataset":0.319792116,"dev-research":0.2193637027,"prompt-eng":0.4155887373,"data-quality":0.3505578236,"ml-security":0.1089979172}}
{"text":"Finally, in Study 3, we replicate Study 1 using the democratic attitude model instead of manual labels to test its attitudinal and behavioral impact (N=558), and again find that the feed downranking using the societal objective function reduced partisan animosity (d=.25).","meta":{"url":"http://arxiv.org/abs/2307.13912v1"},"cats":{"new-dataset":0.0831776415,"dev-research":0.2055689284,"prompt-eng":0.375443656,"data-quality":0.2599831781,"ml-security":0.1725903475}}
{"text":"This method presents a novel strategy to draw on social science theory and methods to mitigate societal harms in social media AIs.","meta":{"url":"http://arxiv.org/abs/2307.13912v1"},"cats":{"new-dataset":0.0258609614,"dev-research":0.3286561198,"prompt-eng":0.3434387064,"data-quality":0.2726120794,"ml-security":0.4505909345}}
{"text":"The conventional single-target Cross-Domain Recommendation (CDR) aims to improve the recommendation performance on a sparser target domain by transferring the knowledge from a source domain that contains relatively richer information.","meta":{"url":"http://arxiv.org/abs/2307.13910v1"},"cats":{"new-dataset":0.0196141542,"dev-research":0.2471484456,"prompt-eng":0.4230199409,"data-quality":0.1695067012,"ml-security":0.0892771871}}
{"text":"By contrast, in recent years, dual-target CDR has been proposed to improve the recommendation performance on both domains simultaneously.","meta":{"url":"http://arxiv.org/abs/2307.13910v1"},"cats":{"new-dataset":0.0129821567,"dev-research":0.2351113583,"prompt-eng":0.4718458173,"data-quality":0.1781842072,"ml-security":0.0457215752}}
{"text":"However, to this end, there are two challenges in dual-target CDR: (1) how to generate both relevant and diverse augmented user representations, and (2) how to effectively decouple domain-independent information from domain-specific information, in addition to domain-shared information, to capture comprehensive user preferences.","meta":{"url":"http://arxiv.org/abs/2307.13910v1"},"cats":{"new-dataset":0.0345976444,"dev-research":0.3043105905,"prompt-eng":0.5126595266,"data-quality":0.1943810565,"ml-security":0.1240227482}}
{"text":"To address the above two challenges, we propose a Disentanglement-based framework with Interpolative Data Augmentation for dual-target Cross-Domain Recommendation, called DIDA-CDR.","meta":{"url":"http://arxiv.org/abs/2307.13910v1"},"cats":{"new-dataset":0.0673690629,"dev-research":0.2479117535,"prompt-eng":0.4014348375,"data-quality":0.2154827166,"ml-security":0.1083278881}}
{"text":"In DIDA-CDR, we first propose an interpolative data augmentation approach to generating both relevant and diverse augmented user representations to augment sparser domain and explore potential user preferences.","meta":{"url":"http://arxiv.org/abs/2307.13910v1"},"cats":{"new-dataset":0.194546966,"dev-research":0.2449115898,"prompt-eng":0.4416077769,"data-quality":0.1566550414,"ml-security":0.0619775626}}
{"text":"We then propose a disentanglement module to effectively decouple domain-specific and domain-independent information to capture comprehensive user preferences.","meta":{"url":"http://arxiv.org/abs/2307.13910v1"},"cats":{"new-dataset":0.058431935,"dev-research":0.3929337573,"prompt-eng":0.5037931823,"data-quality":0.2015741137,"ml-security":0.1654546915}}
{"text":"Both steps significantly contribute to capturing more comprehensive user preferences, thereby improving the recommendation performance on each domain.","meta":{"url":"http://arxiv.org/abs/2307.13910v1"},"cats":{"new-dataset":0.0151157011,"dev-research":0.3492024364,"prompt-eng":0.4432676419,"data-quality":0.1240751416,"ml-security":0.0775430108}}
{"text":"Extensive experiments conducted on five real-world datasets show the significant superiority of DIDA-CDR over the state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2307.13910v1"},"cats":{"new-dataset":0.0947122454,"dev-research":0.2190230475,"prompt-eng":0.4448661238,"data-quality":0.1639241333,"ml-security":0.0462581014}}
{"text":"Graph Neural Networks have emerged as an effective machine learning tool for multi-disciplinary tasks such as pharmaceutical molecule classification and chemical reaction prediction, because they can model non-euclidean relationships between different entities.","meta":{"url":"http://arxiv.org/abs/2307.13909v1"},"cats":{"new-dataset":0.0642817446,"dev-research":0.1888922388,"prompt-eng":0.2911875202,"data-quality":0.2383592501,"ml-security":0.16494484}}
{"text":"Particle crushing, as a significant field of civil engineering, describes the breakage of granular materials caused by the breakage of particle fragment bonds under the modeling of numerical simulations, which motivates us to characterize the mechanical behaviors of particle crushing through the connectivity of particle fragments with Graph Neural Networks (GNNs).","meta":{"url":"http://arxiv.org/abs/2307.13909v1"},"cats":{"new-dataset":0.0789604912,"dev-research":0.2569278496,"prompt-eng":0.317286544,"data-quality":0.1795390858,"ml-security":0.1569031128}}
{"text":"However, there lacks an open-source large-scale particle crushing dataset for research due to the expensive costs of laboratory tests or numerical simulations.","meta":{"url":"http://arxiv.org/abs/2307.13909v1"},"cats":{"new-dataset":0.4226120829,"dev-research":0.1631441364,"prompt-eng":0.3222375781,"data-quality":0.118923343,"ml-security":0.1071952171}}
{"text":"Therefore, we firstly generate a dataset with 45,000 numerical simulations and 900 particle types to facilitate the research progress of machine learning for particle crushing.","meta":{"url":"http://arxiv.org/abs/2307.13909v1"},"cats":{"new-dataset":0.2990087543,"dev-research":0.2009770114,"prompt-eng":0.3516969887,"data-quality":0.1536206669,"ml-security":0.1870120222}}
{"text":"Secondly, we devise a hybrid framework based on GNNs to predict particle crushing strength in a particle fragment view with the advances of state of the art GNNs.","meta":{"url":"http://arxiv.org/abs/2307.13909v1"},"cats":{"new-dataset":0.0818620346,"dev-research":0.2066554787,"prompt-eng":0.3561304521,"data-quality":0.151386865,"ml-security":0.1548917159}}
{"text":"Finally, we compare our hybrid framework against traditional machine learning methods and the plain MLP to verify its effectiveness.","meta":{"url":"http://arxiv.org/abs/2307.13909v1"},"cats":{"new-dataset":0.103227288,"dev-research":0.2113033704,"prompt-eng":0.3993071208,"data-quality":0.2955055224,"ml-security":0.1736651743}}
{"text":"The usefulness of different features is further discussed through the gradient attribution explanation w.r.t the predictions.","meta":{"url":"http://arxiv.org/abs/2307.13909v1"},"cats":{"new-dataset":0.0280815973,"dev-research":0.2561857494,"prompt-eng":0.3782921148,"data-quality":0.2305031072,"ml-security":0.2138907416}}
{"text":"Our data and code are released at https://github.com/doujiang-zheng/GNN-For-Particle-Crushing.","meta":{"url":"http://arxiv.org/abs/2307.13909v1"},"cats":{"new-dataset":0.293500209,"dev-research":0.1542448497,"prompt-eng":0.3665595278,"data-quality":0.1027082469,"ml-security":0.0692357523}}
{"text":"Text-to-3D generation has recently garnered significant attention, fueled by 2D diffusion models trained on billions of image-text pairs.","meta":{"url":"http://arxiv.org/abs/2307.13908v1"},"cats":{"new-dataset":0.313747312,"dev-research":0.2130436456,"prompt-eng":0.3463653035,"data-quality":0.1334913734,"ml-security":0.0908540391}}
{"text":"Existing methods primarily rely on score distillation to leverage the 2D diffusion priors to supervise the generation of 3D models, e.g., NeRF.","meta":{"url":"http://arxiv.org/abs/2307.13908v1"},"cats":{"new-dataset":0.0518317071,"dev-research":0.2517986828,"prompt-eng":0.3757877968,"data-quality":0.0933345053,"ml-security":0.084501545}}
{"text":"However, score distillation is prone to suffer the view inconsistency problem, and implicit NeRF modeling can also lead to an arbitrary shape, thus leading to less realistic and uncontrollable 3D generation.","meta":{"url":"http://arxiv.org/abs/2307.13908v1"},"cats":{"new-dataset":0.0123478209,"dev-research":0.3899975491,"prompt-eng":0.3492079484,"data-quality":0.2228006545,"ml-security":0.1708637512}}
{"text":"In this work, we propose a flexible framework of Points-to-3D to bridge the gap between sparse yet freely available 3D points and realistic shape-controllable 3D generation by distilling the knowledge from both 2D and 3D diffusion models.","meta":{"url":"http://arxiv.org/abs/2307.13908v1"},"cats":{"new-dataset":0.2620806958,"dev-research":0.2245041536,"prompt-eng":0.3528917153,"data-quality":0.0762472498,"ml-security":0.0823142483}}
{"text":"The core idea of Points-to-3D is to introduce controllable sparse 3D points to guide the text-to-3D generation.","meta":{"url":"http://arxiv.org/abs/2307.13908v1"},"cats":{"new-dataset":0.1561122378,"dev-research":0.2737441085,"prompt-eng":0.3868920338,"data-quality":0.1142213135,"ml-security":0.0560249754}}
{"text":"Specifically, we use the sparse point cloud generated from the 3D diffusion model, Point-E, as the geometric prior, conditioned on a single reference image.","meta":{"url":"http://arxiv.org/abs/2307.13908v1"},"cats":{"new-dataset":0.2100785955,"dev-research":0.1393766966,"prompt-eng":0.3601167468,"data-quality":0.0856349527,"ml-security":0.0679637458}}
{"text":"To better utilize the sparse 3D points, we propose an efficient point cloud guidance loss to adaptively drive the NeRF's geometry to align with the shape of the sparse 3D points.","meta":{"url":"http://arxiv.org/abs/2307.13908v1"},"cats":{"new-dataset":0.057104542,"dev-research":0.2442887602,"prompt-eng":0.3847019671,"data-quality":0.1736517647,"ml-security":0.111698987}}
{"text":"In addition to controlling the geometry, we propose to optimize the NeRF for a more view-consistent appearance.","meta":{"url":"http://arxiv.org/abs/2307.13908v1"},"cats":{"new-dataset":0.0407638758,"dev-research":0.3242859911,"prompt-eng":0.3992940738,"data-quality":0.19294174,"ml-security":0.1447417311}}
{"text":"To be specific, we perform score distillation to the publicly available 2D image diffusion model ControlNet, conditioned on text as well as depth map of the learned compact geometry.","meta":{"url":"http://arxiv.org/abs/2307.13908v1"},"cats":{"new-dataset":0.2269099208,"dev-research":0.1731069397,"prompt-eng":0.3651190032,"data-quality":0.1213564387,"ml-security":0.1158381464}}
{"text":"Qualitative and quantitative comparisons demonstrate that Points-to-3D improves view consistency and achieves good shape controllability for text-to-3D generation.","meta":{"url":"http://arxiv.org/abs/2307.13908v1"},"cats":{"new-dataset":0.0830502531,"dev-research":0.3647942709,"prompt-eng":0.4022095689,"data-quality":0.1548351966,"ml-security":0.0584470176}}
{"text":"Points-to-3D provides users with a new way to improve and control text-to-3D generation.","meta":{"url":"http://arxiv.org/abs/2307.13908v1"},"cats":{"new-dataset":0.1355098808,"dev-research":0.3853265678,"prompt-eng":0.4157940569,"data-quality":0.1297180073,"ml-security":0.0577496606}}
{"text":"Data-driven, neural network (NN) based anomaly detection and predictive maintenance are emerging research areas.","meta":{"url":"http://arxiv.org/abs/2307.13907v1"},"cats":{"new-dataset":0.2502589636,"dev-research":0.3098999027,"prompt-eng":0.3376871765,"data-quality":0.3165234958,"ml-security":0.4439743678}}
{"text":"NN-based analytics of time-series data offer valuable insights into past behaviors and estimates of critical parameters like remaining useful life (RUL) of equipment and state-of-charge (SOC) of batteries.","meta":{"url":"http://arxiv.org/abs/2307.13907v1"},"cats":{"new-dataset":0.2120997912,"dev-research":0.2083293907,"prompt-eng":0.32262639,"data-quality":0.1511239635,"ml-security":0.0794376217}}
{"text":"However, input time series data can be exposed to intentional or unintentional noise when passing through sensors, necessitating robust validation and verification of these NNs.","meta":{"url":"http://arxiv.org/abs/2307.13907v1"},"cats":{"new-dataset":0.0997139781,"dev-research":0.2400687892,"prompt-eng":0.4110727602,"data-quality":0.3162773386,"ml-security":0.3096854369}}
{"text":"This paper presents a case study of the robustness verification approach for time series regression NNs (TSRegNN) using set-based formal methods.","meta":{"url":"http://arxiv.org/abs/2307.13907v1"},"cats":{"new-dataset":0.1844134895,"dev-research":0.2767018412,"prompt-eng":0.3862098534,"data-quality":0.2639350048,"ml-security":0.1868624185}}
{"text":"It focuses on utilizing variable-length input data to streamline input manipulation and enhance network architecture generalizability.","meta":{"url":"http://arxiv.org/abs/2307.13907v1"},"cats":{"new-dataset":0.1268389259,"dev-research":0.3550252972,"prompt-eng":0.3898574346,"data-quality":0.1265118629,"ml-security":0.1244594934}}
{"text":"The method is applied to two data sets in the Prognostics and Health Management (PHM) application areas: (1) SOC estimation of a Lithium-ion battery and (2) RUL estimation of a turbine engine.","meta":{"url":"http://arxiv.org/abs/2307.13907v1"},"cats":{"new-dataset":0.1058053832,"dev-research":0.2095727645,"prompt-eng":0.4105910293,"data-quality":0.1233923836,"ml-security":0.0621154334}}
{"text":"The NNs' robustness is checked using star-based reachability analysis, and several performance measures evaluate the effect of bounded perturbations in the input on network outputs, i.e., future outcomes.","meta":{"url":"http://arxiv.org/abs/2307.13907v1"},"cats":{"new-dataset":0.0348836033,"dev-research":0.2548086245,"prompt-eng":0.3820487923,"data-quality":0.2494097742,"ml-security":0.2118632165}}
{"text":"Overall, the paper offers a comprehensive case study for validating and verifying NN-based analytics of time-series data in real-world applications, emphasizing the importance of robustness testing for accurate and reliable predictions, especially considering the impact of noise on future outcomes.","meta":{"url":"http://arxiv.org/abs/2307.13907v1"},"cats":{"new-dataset":0.0995238698,"dev-research":0.2841166,"prompt-eng":0.3451717516,"data-quality":0.3017694263,"ml-security":0.1935407927}}
{"text":"In this work, we propose reinforcement learning (RL) for sequential decoding of moderate length generalized low-density parity-check (GLDPC) codes.","meta":{"url":"http://arxiv.org/abs/2307.13905v1"},"cats":{"new-dataset":0.1762470452,"dev-research":0.1745115455,"prompt-eng":0.3642196147,"data-quality":0.1536347017,"ml-security":0.0864923277}}
{"text":"Here, sequential decoding refers to scheduling all the generalized constraint nodes (GCNs) and single parity-check nodes (SPCNs) of a GLDPC code serially in each iteration.","meta":{"url":"http://arxiv.org/abs/2307.13905v1"},"cats":{"new-dataset":0.1538746068,"dev-research":0.2504159426,"prompt-eng":0.3949762677,"data-quality":0.0940850718,"ml-security":0.0733374967}}
{"text":"A GLDPC decoding environment is modeled as a finite Markov decision process (MDP) in which the state-space comprises of all possible sequences of hard-decision values of the variables nodes (VNs) connected to the scheduled GCN or SPCN, and the action-space of the MDP consists of all possible actions (GCN and SPCN scheduling).","meta":{"url":"http://arxiv.org/abs/2307.13905v1"},"cats":{"new-dataset":0.0902697031,"dev-research":0.2146200125,"prompt-eng":0.4061341265,"data-quality":0.1024430387,"ml-security":0.0894602388}}
{"text":"The goal of RL is to determine an optimized scheduling policy, i.e., one that results in a decoded codeword by minimizing the complexity of the belief propagation (BP) decoder.","meta":{"url":"http://arxiv.org/abs/2307.13905v1"},"cats":{"new-dataset":0.0541651493,"dev-research":0.3146006935,"prompt-eng":0.4008111591,"data-quality":0.1185479777,"ml-security":0.0998142849}}
{"text":"For training, we consider the proportion of correct bits at the output of the GCN or SPCN as a reward once it is scheduled.","meta":{"url":"http://arxiv.org/abs/2307.13905v1"},"cats":{"new-dataset":0.1321269407,"dev-research":0.1889730228,"prompt-eng":0.4125579014,"data-quality":0.1712299221,"ml-security":0.1329010884}}
{"text":"The expected rewards for scheduling all the GCNs/SPCNs in the code's Tanner graph are earned via BP decoding during the RL phase.","meta":{"url":"http://arxiv.org/abs/2307.13905v1"},"cats":{"new-dataset":0.1293481551,"dev-research":0.1984027634,"prompt-eng":0.378179153,"data-quality":0.1246552307,"ml-security":0.0980027186}}
{"text":"The proposed RL-based decoding scheme is shown to significantly outperform the standard BP flooding decoder, as well as a sequential decoder in which the GCNs/SPCNs are scheduled randomly.","meta":{"url":"http://arxiv.org/abs/2307.13905v1"},"cats":{"new-dataset":0.1756111157,"dev-research":0.2182284505,"prompt-eng":0.4050582166,"data-quality":0.140123804,"ml-security":0.1119824437}}
{"text":"I study the problem of learning a Lipschitz function with corrupted binary signals.","meta":{"url":"http://arxiv.org/abs/2307.13903v1"},"cats":{"new-dataset":0.192650085,"dev-research":0.1595175917,"prompt-eng":0.3581917485,"data-quality":0.3482831248,"ml-security":0.2279336591}}
{"text":"The learner tries to learn a Lipschitz function $f$ that the adversary chooses.","meta":{"url":"http://arxiv.org/abs/2307.13903v1"},"cats":{"new-dataset":0.0312246431,"dev-research":0.2380554072,"prompt-eng":0.2975093451,"data-quality":0.2555895219,"ml-security":0.585262092}}
{"text":"In each round, the adversary selects a context vector $x_t$ in the input space, and the learner makes a guess to the true function value $f(x_t)$ and receives a binary signal indicating whether the guess was high or low.","meta":{"url":"http://arxiv.org/abs/2307.13903v1"},"cats":{"new-dataset":0.0132429447,"dev-research":0.2554059599,"prompt-eng":0.3949072532,"data-quality":0.2023516403,"ml-security":0.5406601759}}
{"text":"In a total of $C$ rounds, the signal may be corrupted, though the value of $C$ is unknown to the learner.","meta":{"url":"http://arxiv.org/abs/2307.13903v1"},"cats":{"new-dataset":0.0276796171,"dev-research":0.2333115268,"prompt-eng":0.3560046022,"data-quality":0.4301669258,"ml-security":0.3326331547}}
{"text":"The learner's goal is to incur a small cumulative loss.","meta":{"url":"http://arxiv.org/abs/2307.13903v1"},"cats":{"new-dataset":0.0093774467,"dev-research":0.3025539262,"prompt-eng":0.3305693537,"data-quality":0.2405000566,"ml-security":0.2420301687}}
{"text":"I present a natural yet powerful technique sanity check, which proves useful in designing corruption-robust algorithms.","meta":{"url":"http://arxiv.org/abs/2307.13903v1"},"cats":{"new-dataset":0.1693887542,"dev-research":0.4273538905,"prompt-eng":0.4545211277,"data-quality":0.4789427006,"ml-security":0.3351061628}}
{"text":"I design algorithms which (treating the Lipschitz parameter $L$ as constant): for the symmetric loss, the learner achieves regret $O(C\\log T)$ with $d = 1$ and $O_d(C\\log T + T^{(d-1)/d})$ with $d > 1$; for the pricing loss the learner achieves regret $\\widetilde{O} (T^{d/(d+1)} + C\\cdot T^{1/(d+1)})$.","meta":{"url":"http://arxiv.org/abs/2307.13903v1"},"cats":{"new-dataset":0.0119479588,"dev-research":0.2037099402,"prompt-eng":0.2975704495,"data-quality":0.1768931897,"ml-security":0.3024232047}}
{"text":"We present YOLOBench, a benchmark comprised of 550+ YOLO-based object detection models on 4 different datasets and 4 different embedded hardware platforms (x86 CPU, ARM CPU, Nvidia GPU, NPU).","meta":{"url":"http://arxiv.org/abs/2307.13901v1"},"cats":{"new-dataset":0.3965175175,"dev-research":0.1925988155,"prompt-eng":0.3681300854,"data-quality":0.2036642523,"ml-security":0.1898393724}}
{"text":"We collect accuracy and latency numbers for a variety of YOLO-based one-stage detectors at different model scales by performing a fair, controlled comparison of these detectors with a fixed training environment (code and training hyperparameters).","meta":{"url":"http://arxiv.org/abs/2307.13901v1"},"cats":{"new-dataset":0.1516257706,"dev-research":0.1711893272,"prompt-eng":0.4567931176,"data-quality":0.2973176188,"ml-security":0.1418514819}}
{"text":"Pareto-optimality analysis of the collected data reveals that, if modern detection heads and training techniques are incorporated into the learning process, multiple architectures of the YOLO series achieve a good accuracy-latency trade-off, including older models like YOLOv3 and YOLOv4.","meta":{"url":"http://arxiv.org/abs/2307.13901v1"},"cats":{"new-dataset":0.0985990807,"dev-research":0.1618291844,"prompt-eng":0.4265551861,"data-quality":0.2455226169,"ml-security":0.1739272245}}
{"text":"We also evaluate training-free accuracy estimators used in neural architecture search on YOLOBench and demonstrate that, while most state-of-the-art zero-cost accuracy estimators are outperformed by a simple baseline like MAC count, some of them can be effectively used to predict Pareto-optimal detection models.","meta":{"url":"http://arxiv.org/abs/2307.13901v1"},"cats":{"new-dataset":0.1123729101,"dev-research":0.1781454273,"prompt-eng":0.413040105,"data-quality":0.308732362,"ml-security":0.3605832867}}
{"text":"We showcase that by using a zero-cost proxy to identify a YOLO architecture competitive against a state-of-the-art YOLOv8 model on a Raspberry Pi 4 CPU.","meta":{"url":"http://arxiv.org/abs/2307.13901v1"},"cats":{"new-dataset":0.2365595276,"dev-research":0.2468080046,"prompt-eng":0.4044247208,"data-quality":0.0880194548,"ml-security":0.1292085908}}
{"text":"The code and data are available at https://github.com/Deeplite/deeplite-torch-zoo","meta":{"url":"http://arxiv.org/abs/2307.13901v1"},"cats":{"new-dataset":0.5586630243,"dev-research":0.1429580808,"prompt-eng":0.4217334781,"data-quality":0.0933268605,"ml-security":0.0287889384}}
{"text":"We present FinTree, Financial Dataset Pretrain Transformer Encoder for Relation Extraction.","meta":{"url":"http://arxiv.org/abs/2307.13900v1"},"cats":{"new-dataset":0.3290353834,"dev-research":0.1953606348,"prompt-eng":0.3629690561,"data-quality":0.1797848887,"ml-security":0.0817023843}}
{"text":"Utilizing an encoder language model, we further pretrain FinTree on the financial dataset, adapting the model in financial domain tasks.","meta":{"url":"http://arxiv.org/abs/2307.13900v1"},"cats":{"new-dataset":0.188494179,"dev-research":0.2000623245,"prompt-eng":0.3996525636,"data-quality":0.1661189657,"ml-security":0.104305178}}
{"text":"FinTree stands out with its novel structure that predicts a masked token instead of the conventional [CLS] token, inspired by the Pattern Exploiting Training methodology.","meta":{"url":"http://arxiv.org/abs/2307.13900v1"},"cats":{"new-dataset":0.0734342845,"dev-research":0.2206859162,"prompt-eng":0.4728067388,"data-quality":0.2212357093,"ml-security":0.2350758038}}
{"text":"This structure allows for more accurate relation predictions between two given entities.","meta":{"url":"http://arxiv.org/abs/2307.13900v1"},"cats":{"new-dataset":0.0476912963,"dev-research":0.2436164639,"prompt-eng":0.4293877204,"data-quality":0.1345824443,"ml-security":0.0650047715}}
{"text":"The model is trained with a unique input pattern to provide contextual and positional information about the entities of interest, and a post-processing step ensures accurate predictions in line with the entity types.","meta":{"url":"http://arxiv.org/abs/2307.13900v1"},"cats":{"new-dataset":0.0688191637,"dev-research":0.2663376193,"prompt-eng":0.4336914723,"data-quality":0.1353145847,"ml-security":0.0807929899}}
{"text":"Our experiments demonstrate that FinTree outperforms on the REFinD, a large-scale financial relation extraction dataset.","meta":{"url":"http://arxiv.org/abs/2307.13900v1"},"cats":{"new-dataset":0.2718477498,"dev-research":0.1654577731,"prompt-eng":0.3444883006,"data-quality":0.1783615692,"ml-security":0.076307846}}
{"text":"The code and pretrained models are available at https://github.com/HJ-Ok/FinTree.","meta":{"url":"http://arxiv.org/abs/2307.13900v1"},"cats":{"new-dataset":0.3370957064,"dev-research":0.1596665483,"prompt-eng":0.4707874924,"data-quality":0.0748142,"ml-security":0.0312397305}}
{"text":"This paper investigates methods for improving generative data augmentation for deep learning.","meta":{"url":"http://arxiv.org/abs/2307.13899v1"},"cats":{"new-dataset":0.0899269989,"dev-research":0.3060887415,"prompt-eng":0.3937428724,"data-quality":0.2973543438,"ml-security":0.1252666692}}
{"text":"Generative data augmentation leverages the synthetic samples produced by generative models as an additional dataset for classification with small dataset settings.","meta":{"url":"http://arxiv.org/abs/2307.13899v1"},"cats":{"new-dataset":0.2766687312,"dev-research":0.2902242269,"prompt-eng":0.3827407136,"data-quality":0.2778400346,"ml-security":0.1783945782}}
{"text":"A key challenge of generative data augmentation is that the synthetic data contain uninformative samples that degrade accuracy.","meta":{"url":"http://arxiv.org/abs/2307.13899v1"},"cats":{"new-dataset":0.1447237642,"dev-research":0.2879585673,"prompt-eng":0.3854691786,"data-quality":0.3757268885,"ml-security":0.1569525012}}
{"text":"This is because the synthetic samples do not perfectly represent class categories in real data and uniform sampling does not necessarily provide useful samples for tasks.","meta":{"url":"http://arxiv.org/abs/2307.13899v1"},"cats":{"new-dataset":0.0723894177,"dev-research":0.2244436846,"prompt-eng":0.29596786,"data-quality":0.2892372593,"ml-security":0.145364056}}
{"text":"In this paper, we present a novel strategy for generative data augmentation called meta generative regularization (MGR).","meta":{"url":"http://arxiv.org/abs/2307.13899v1"},"cats":{"new-dataset":0.1227110522,"dev-research":0.2577844105,"prompt-eng":0.4532849875,"data-quality":0.2795017112,"ml-security":0.0858346495}}
{"text":"To avoid the degradation of generative data augmentation, MGR utilizes synthetic samples in the regularization term for feature extractors instead of in the loss function, e.g., cross-entropy.","meta":{"url":"http://arxiv.org/abs/2307.13899v1"},"cats":{"new-dataset":0.0355171437,"dev-research":0.218061176,"prompt-eng":0.4211934691,"data-quality":0.2311139833,"ml-security":0.0861621026}}
{"text":"These synthetic samples are dynamically determined to minimize the validation losses through meta-learning.","meta":{"url":"http://arxiv.org/abs/2307.13899v1"},"cats":{"new-dataset":0.0754667595,"dev-research":0.2508429793,"prompt-eng":0.4039532437,"data-quality":0.2603718413,"ml-security":0.199164142}}
{"text":"We observed that MGR can avoid the performance degradation of na\\\"ive generative data augmentation and boost the baselines.","meta":{"url":"http://arxiv.org/abs/2307.13899v1"},"cats":{"new-dataset":0.0717180516,"dev-research":0.2409564341,"prompt-eng":0.4227124932,"data-quality":0.1991006477,"ml-security":0.0717156997}}
{"text":"Experiments on six datasets showed that MGR is effective particularly when datasets are smaller and stably outperforms baselines.","meta":{"url":"http://arxiv.org/abs/2307.13899v1"},"cats":{"new-dataset":0.0603969718,"dev-research":0.2396188762,"prompt-eng":0.426270893,"data-quality":0.2405810096,"ml-security":0.0740160488}}
{"text":"Skin lesion segmentation (SLS) plays an important role in skin lesion analysis.","meta":{"url":"http://arxiv.org/abs/2307.13897v1"},"cats":{"new-dataset":0.0369133967,"dev-research":0.2528096615,"prompt-eng":0.3190441251,"data-quality":0.1529169298,"ml-security":0.0843651607}}
{"text":"Vision transformers (ViTs) are considered an auspicious solution for SLS, but they require more training data compared to convolutional neural networks (CNNs) due to their inherent parameter-heavy structure and lack of some inductive biases.","meta":{"url":"http://arxiv.org/abs/2307.13897v1"},"cats":{"new-dataset":0.0880842553,"dev-research":0.2156274319,"prompt-eng":0.3597709423,"data-quality":0.125025824,"ml-security":0.1327742763}}
{"text":"To alleviate this issue, current approaches fine-tune pre-trained ViT backbones on SLS datasets, aiming to leverage the knowledge learned from a larger set of natural images to lower the amount of skin training data needed.","meta":{"url":"http://arxiv.org/abs/2307.13897v1"},"cats":{"new-dataset":0.4123981818,"dev-research":0.2455193175,"prompt-eng":0.3838210304,"data-quality":0.1731343702,"ml-security":0.1724351426}}
{"text":"However, fully fine-tuning all parameters of large backbones is computationally expensive and memory intensive.","meta":{"url":"http://arxiv.org/abs/2307.13897v1"},"cats":{"new-dataset":0.0567459458,"dev-research":0.217737089,"prompt-eng":0.398336191,"data-quality":0.0770847098,"ml-security":0.1055176487}}
{"text":"In this paper, we propose AViT, a novel efficient strategy to mitigate ViTs' data-hunger by transferring any pre-trained ViTs to the SLS task.","meta":{"url":"http://arxiv.org/abs/2307.13897v1"},"cats":{"new-dataset":0.1358988788,"dev-research":0.2646394519,"prompt-eng":0.4583782965,"data-quality":0.2129044995,"ml-security":0.1425271502}}
{"text":"Specifically, we integrate lightweight modules (adapters) within the transformer layers, which modulate the feature representation of a ViT without updating its pre-trained weights.","meta":{"url":"http://arxiv.org/abs/2307.13897v1"},"cats":{"new-dataset":0.052990325,"dev-research":0.2927153874,"prompt-eng":0.4333383924,"data-quality":0.1158915151,"ml-security":0.1333586326}}
{"text":"In addition, we employ a shallow CNN as a prompt generator to create a prompt embedding from the input image, which grasps fine-grained information and CNN's inductive biases to guide the segmentation task on small datasets.","meta":{"url":"http://arxiv.org/abs/2307.13897v1"},"cats":{"new-dataset":0.3785418213,"dev-research":0.2128095595,"prompt-eng":0.4786344779,"data-quality":0.267089912,"ml-security":0.1613091886}}
{"text":"Our quantitative experiments on 4 skin lesion datasets demonstrate that AViT achieves competitive, and at times superior, performance to SOTA but with significantly fewer trainable parameters.","meta":{"url":"http://arxiv.org/abs/2307.13897v1"},"cats":{"new-dataset":0.227667674,"dev-research":0.2235878594,"prompt-eng":0.3527239274,"data-quality":0.125501424,"ml-security":0.1065169582}}
{"text":"Our code is available at https://github.com/siyi-wind/AViT.","meta":{"url":"http://arxiv.org/abs/2307.13897v1"},"cats":{"new-dataset":0.3558836868,"dev-research":0.1609160198,"prompt-eng":0.4273785188,"data-quality":0.0926850661,"ml-security":0.0323371039}}
{"text":"We study few-shot Natural Language Understanding (NLU) tasks with Large Language Models (LLMs) in federated learning (FL) scenarios.","meta":{"url":"http://arxiv.org/abs/2307.13896v1"},"cats":{"new-dataset":0.2205870498,"dev-research":0.2073826691,"prompt-eng":0.3922326963,"data-quality":0.2070454569,"ml-security":0.1039228729}}
{"text":"It is a challenging task due to limited labeled data and communication capacities in FL, especially with mobile devices.","meta":{"url":"http://arxiv.org/abs/2307.13896v1"},"cats":{"new-dataset":0.2680639359,"dev-research":0.245197342,"prompt-eng":0.4445622652,"data-quality":0.1887659286,"ml-security":0.0731218308}}
{"text":"Recent studies show LLMs can be prompted to perform few-shot NLU tasks like sentiment analysis and arithmetic reasoning.","meta":{"url":"http://arxiv.org/abs/2307.13896v1"},"cats":{"new-dataset":0.0578094184,"dev-research":0.2461741156,"prompt-eng":0.4077211296,"data-quality":0.2004637855,"ml-security":0.0919797098}}
{"text":"However, the huge sizes of LLMs result in high computation and communication costs, making classical FL schemes impractical.","meta":{"url":"http://arxiv.org/abs/2307.13896v1"},"cats":{"new-dataset":0.0263523841,"dev-research":0.1708226506,"prompt-eng":0.3302950342,"data-quality":0.0581769719,"ml-security":0.1186294494}}
{"text":"To address these challenges, we propose Low-Parameter Federated Learning (LP-FL).","meta":{"url":"http://arxiv.org/abs/2307.13896v1"},"cats":{"new-dataset":0.1142580709,"dev-research":0.1786240642,"prompt-eng":0.400117114,"data-quality":0.201414371,"ml-security":0.1606555035}}
{"text":"LP-FL combines few-shot prompt learning from LLMs with efficient communication and federating techniques.","meta":{"url":"http://arxiv.org/abs/2307.13896v1"},"cats":{"new-dataset":0.1531633415,"dev-research":0.2433135974,"prompt-eng":0.5514236079,"data-quality":0.1826589452,"ml-security":0.1007019333}}
{"text":"Our approach enables federated clients to assign soft labels to unlabeled data using gradually learned knowledge from the global model.","meta":{"url":"http://arxiv.org/abs/2307.13896v1"},"cats":{"new-dataset":0.1472855982,"dev-research":0.2550094143,"prompt-eng":0.4204105018,"data-quality":0.4681631378,"ml-security":0.1650289864}}
{"text":"Through iterative soft-label assigning, we continually expand the labeled set during the FL process.","meta":{"url":"http://arxiv.org/abs/2307.13896v1"},"cats":{"new-dataset":0.2257944037,"dev-research":0.2313272296,"prompt-eng":0.4363563557,"data-quality":0.2926457557,"ml-security":0.0552660485}}
{"text":"Additionally, to reduce computation and communication costs, LP-FL utilizes the Low-Rank Adaptation (LoRA) technique for compact learnable parameter construction, efficient local model fine-tuning, and affordable global model federation.","meta":{"url":"http://arxiv.org/abs/2307.13896v1"},"cats":{"new-dataset":0.1114079228,"dev-research":0.2024940694,"prompt-eng":0.4127010974,"data-quality":0.1346316996,"ml-security":0.0739743829}}
{"text":"LP-FL consistently outperforms Full-Parameter Federated Learning (FP-FL) in sentiment analysis tasks across various FL settings.","meta":{"url":"http://arxiv.org/abs/2307.13896v1"},"cats":{"new-dataset":0.0973669158,"dev-research":0.207784773,"prompt-eng":0.373204982,"data-quality":0.3087198929,"ml-security":0.0943866855}}
{"text":"Its resistance to overfitting allows LP-FL to equal or surpass centralized training in few-shot scenarios.","meta":{"url":"http://arxiv.org/abs/2307.13896v1"},"cats":{"new-dataset":0.0305360362,"dev-research":0.2449639262,"prompt-eng":0.3210722598,"data-quality":0.1845499253,"ml-security":0.2174336134}}
{"text":"We present a critical analysis of the simulation framework RICE-N, an integrated assessment model (IAM) for evaluating the impacts of climate change on the economy.","meta":{"url":"http://arxiv.org/abs/2307.13894v1"},"cats":{"new-dataset":0.137978176,"dev-research":0.2512270871,"prompt-eng":0.3838695754,"data-quality":0.1095276624,"ml-security":0.0569317526}}
{"text":"We identify key issues with RICE-N, including action masking and irrelevant actions, and suggest improvements such as utilizing tariff revenue and penalizing overproduction.","meta":{"url":"http://arxiv.org/abs/2307.13894v1"},"cats":{"new-dataset":0.1274284689,"dev-research":0.2227831244,"prompt-eng":0.361183742,"data-quality":0.3127886641,"ml-security":0.2659856374}}
{"text":"We also critically engage with features of IAMs in general, namely overly optimistic damage functions and unrealistic abatement cost functions.","meta":{"url":"http://arxiv.org/abs/2307.13894v1"},"cats":{"new-dataset":0.0709547377,"dev-research":0.319827916,"prompt-eng":0.3995287585,"data-quality":0.1832646947,"ml-security":0.3058912003}}
{"text":"Our findings contribute to the ongoing efforts to further develop the RICE-N framework in an effort to improve the simulation, making it more useful as an inspiration for policymakers.","meta":{"url":"http://arxiv.org/abs/2307.13894v1"},"cats":{"new-dataset":0.2650231697,"dev-research":0.2171176336,"prompt-eng":0.367262926,"data-quality":0.1176901892,"ml-security":0.0762312975}}
{"text":"In this paper, we propose a dynamic grouping negotiation model for climate mitigation based on real-world business and political negotiation protocols.","meta":{"url":"http://arxiv.org/abs/2307.13893v1"},"cats":{"new-dataset":0.2868537465,"dev-research":0.2662263614,"prompt-eng":0.3752334966,"data-quality":0.1066869486,"ml-security":0.1389617012}}
{"text":"Within the AI4GCC competition framework, we develop a three-stage process: group formation and updates, intra-group negotiation, and inter-group negotiation.","meta":{"url":"http://arxiv.org/abs/2307.13893v1"},"cats":{"new-dataset":0.3480647405,"dev-research":0.3305095773,"prompt-eng":0.440205041,"data-quality":0.1074784777,"ml-security":0.0679263406}}
{"text":"Our model promotes efficient and effective cooperation between various stakeholders to achieve global climate change objectives.","meta":{"url":"http://arxiv.org/abs/2307.13893v1"},"cats":{"new-dataset":0.0863439495,"dev-research":0.3000763701,"prompt-eng":0.3827401067,"data-quality":0.0770498752,"ml-security":0.0712353762}}
{"text":"By implementing a group-forming method and group updating strategy, we address the complexities and imbalances in multi-region climate negotiations.","meta":{"url":"http://arxiv.org/abs/2307.13893v1"},"cats":{"new-dataset":0.2357488962,"dev-research":0.2917051518,"prompt-eng":0.3795882971,"data-quality":0.1273117305,"ml-security":0.1150964569}}
{"text":"Intra-group negotiations ensure that all members contribute to mitigation efforts, while inter-group negotiations use the proposal-evaluation framework to set mitigation and savings rates.","meta":{"url":"http://arxiv.org/abs/2307.13893v1"},"cats":{"new-dataset":0.0526830768,"dev-research":0.3553600939,"prompt-eng":0.3506128859,"data-quality":0.1043889728,"ml-security":0.109014967}}
{"text":"We demonstrate our negotiation model within the RICE-N framework, illustrating a promising approach for facilitating international cooperation on climate change mitigation.","meta":{"url":"http://arxiv.org/abs/2307.13893v1"},"cats":{"new-dataset":0.4271072336,"dev-research":0.2270001602,"prompt-eng":0.3606223497,"data-quality":0.1288252479,"ml-security":0.1253726164}}
{"text":"As our submission for track three of the AI for Global Climate Cooperation (AI4GCC) competition, we propose a negotiation protocol for use in the RICE-N climate-economic simulation.","meta":{"url":"http://arxiv.org/abs/2307.13892v1"},"cats":{"new-dataset":0.3551256291,"dev-research":0.2056665737,"prompt-eng":0.3559862378,"data-quality":0.0849559609,"ml-security":0.0737203105}}
{"text":"Our proposal seeks to address the challenges of carbon leakage through methods inspired by the Carbon Border Adjustment Mechanism (CBAM) and Climate Clubs (CC).","meta":{"url":"http://arxiv.org/abs/2307.13892v1"},"cats":{"new-dataset":0.099113874,"dev-research":0.2950933331,"prompt-eng":0.3534648813,"data-quality":0.2698425947,"ml-security":0.1750499985}}
{"text":"We demonstrate the effectiveness of our approach by comparing simulated outcomes to representative concentration pathways (RCP) and shared socioeconomic pathways (SSP).","meta":{"url":"http://arxiv.org/abs/2307.13892v1"},"cats":{"new-dataset":0.0283335399,"dev-research":0.245668723,"prompt-eng":0.3956853523,"data-quality":0.0795725548,"ml-security":0.0726646934}}
{"text":"Our protocol results in a temperature rise comparable to RCP 3.4/4.5 and SSP 2.","meta":{"url":"http://arxiv.org/abs/2307.13892v1"},"cats":{"new-dataset":0.4026614818,"dev-research":0.1985667104,"prompt-eng":0.4425715918,"data-quality":0.1001787895,"ml-security":0.0650152016}}
{"text":"Furthermore, we provide an analysis of our protocol's World Trade Organization compliance, administrative and political feasibility, and ethical concerns.","meta":{"url":"http://arxiv.org/abs/2307.13892v1"},"cats":{"new-dataset":0.3427027336,"dev-research":0.2115986845,"prompt-eng":0.3480262067,"data-quality":0.1530924495,"ml-security":0.1662708368}}
{"text":"We recognize that our proposal risks hurting the least developing countries, and we suggest specific corrective measures to avoid exacerbating existing inequalities, such as technology sharing and wealth redistribution.","meta":{"url":"http://arxiv.org/abs/2307.13892v1"},"cats":{"new-dataset":0.0812426358,"dev-research":0.2889058596,"prompt-eng":0.362346064,"data-quality":0.2181481809,"ml-security":0.2616077201}}
{"text":"Future research should improve the RICE-N tariff mechanism and implement actions allowing for the aforementioned corrective measures.","meta":{"url":"http://arxiv.org/abs/2307.13892v1"},"cats":{"new-dataset":0.0478273149,"dev-research":0.1818300615,"prompt-eng":0.37689289,"data-quality":0.1944052372,"ml-security":0.0843604662}}
{"text":"The current framework for climate change negotiation models presents several limitations that warrant further research and development.","meta":{"url":"http://arxiv.org/abs/2307.13886v1"},"cats":{"new-dataset":0.1707848818,"dev-research":0.256290752,"prompt-eng":0.3328967915,"data-quality":0.0724876437,"ml-security":0.0826152748}}
{"text":"In this track, we discuss mainly two key areas for improvement, focusing on the geographical impacts and utility framework.","meta":{"url":"http://arxiv.org/abs/2307.13886v1"},"cats":{"new-dataset":0.1455358537,"dev-research":0.2988407684,"prompt-eng":0.3486821228,"data-quality":0.1060120492,"ml-security":0.0514963745}}
{"text":"In the aspects of geographical impacts, We explore five critical aspects: (1) the shift from local to global impact, (2) variability in climate change effects across regions, (3) heterogeneity in geographical location and political structures, and (4) collaborations between adjacent nations, (5) the importance of including historical and cultural factors influencing climate negotiations.","meta":{"url":"http://arxiv.org/abs/2307.13886v1"},"cats":{"new-dataset":0.1674613325,"dev-research":0.3050391925,"prompt-eng":0.3063528446,"data-quality":0.1088790446,"ml-security":0.0927871401}}
{"text":"Furthermore, we emphasize the need to refine the utility and rewards framework to reduce the homogeneity and the level of overestimating the climate mitigation by integrating the positive effects of saving rates into the reward function and heterogeneity among all regions.","meta":{"url":"http://arxiv.org/abs/2307.13886v1"},"cats":{"new-dataset":0.0510467577,"dev-research":0.251542489,"prompt-eng":0.3939884029,"data-quality":0.1507338984,"ml-security":0.1452212055}}
{"text":"By addressing these limitations, we hope to enhance the accuracy and effectiveness of climate change negotiation models, enabling policymakers and stakeholders to devise targeted and appropriate strategies to tackle climate change at both regional and global levels.","meta":{"url":"http://arxiv.org/abs/2307.13886v1"},"cats":{"new-dataset":0.2055196898,"dev-research":0.3087148325,"prompt-eng":0.3616146693,"data-quality":0.1118180891,"ml-security":0.0803728695}}
{"text":"Machine learning models often need to be robust to noisy input data.","meta":{"url":"http://arxiv.org/abs/2307.13885v1"},"cats":{"new-dataset":0.0301101858,"dev-research":0.3072161922,"prompt-eng":0.3753374707,"data-quality":0.4975944751,"ml-security":0.4824675958}}
{"text":"The effect of real-world noise (which is often random) on model predictions is captured by a model's local robustness, i.e., the consistency of model predictions in a local region around an input.","meta":{"url":"http://arxiv.org/abs/2307.13885v1"},"cats":{"new-dataset":0.0433552288,"dev-research":0.3239024443,"prompt-eng":0.355688163,"data-quality":0.3809922467,"ml-security":0.3213530519}}
{"text":"However, the na\\\"ive approach to computing local robustness based on Monte-Carlo sampling is statistically inefficient, leading to prohibitive computational costs for large-scale applications.","meta":{"url":"http://arxiv.org/abs/2307.13885v1"},"cats":{"new-dataset":0.1431801724,"dev-research":0.2453708105,"prompt-eng":0.3798709971,"data-quality":0.2256277099,"ml-security":0.1585883579}}
{"text":"In this work, we develop the first analytical estimators to efficiently compute local robustness of multi-class discriminative models using local linear function approximation and the multivariate Normal CDF.","meta":{"url":"http://arxiv.org/abs/2307.13885v1"},"cats":{"new-dataset":0.2630819298,"dev-research":0.1531072878,"prompt-eng":0.4129025946,"data-quality":0.3789664756,"ml-security":0.2005352457}}
{"text":"Through the derivation of these estimators, we show how local robustness is connected to concepts such as randomized smoothing and softmax probability.","meta":{"url":"http://arxiv.org/abs/2307.13885v1"},"cats":{"new-dataset":0.1293811721,"dev-research":0.211332339,"prompt-eng":0.3612487318,"data-quality":0.3809378342,"ml-security":0.2957868097}}
{"text":"We also confirm empirically that these estimators accurately and efficiently compute the local robustness of standard deep learning models.","meta":{"url":"http://arxiv.org/abs/2307.13885v1"},"cats":{"new-dataset":0.1771589706,"dev-research":0.2208949346,"prompt-eng":0.3436749019,"data-quality":0.4768362264,"ml-security":0.4000904196}}
{"text":"In addition, we demonstrate these estimators' usefulness for various tasks involving local robustness, such as measuring robustness bias and identifying examples that are vulnerable to noise perturbation in a dataset.","meta":{"url":"http://arxiv.org/abs/2307.13885v1"},"cats":{"new-dataset":0.3629684904,"dev-research":0.2513682402,"prompt-eng":0.3975074244,"data-quality":0.5712903459,"ml-security":0.3683841608}}
{"text":"By developing these analytical estimators, this work not only advances conceptual understanding of local robustness, but also makes its computation practical, enabling the use of local robustness in critical downstream applications.","meta":{"url":"http://arxiv.org/abs/2307.13885v1"},"cats":{"new-dataset":0.1055314229,"dev-research":0.275156562,"prompt-eng":0.4106999651,"data-quality":0.3454539066,"ml-security":0.262505433}}
{"text":"When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks.","meta":{"url":"http://arxiv.org/abs/2307.13883v1"},"cats":{"new-dataset":0.0292040975,"dev-research":0.5594595272,"prompt-eng":0.4062700563,"data-quality":0.1183372792,"ml-security":0.113970211}}
{"text":"While it is difficult to measure whether neural program synthesis methods have similar capabilities, we can measure whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks.","meta":{"url":"http://arxiv.org/abs/2307.13883v1"},"cats":{"new-dataset":0.0401044191,"dev-research":0.4109611359,"prompt-eng":0.3814428415,"data-quality":0.1532563109,"ml-security":0.2077274806}}
{"text":"In this paper, we characterize several different forms of compositional generalization that are desirable in program synthesis, forming a meta-benchmark which we use to create generalization tasks for two popular datasets, RobustFill and DeepCoder.","meta":{"url":"http://arxiv.org/abs/2307.13883v1"},"cats":{"new-dataset":0.2384178017,"dev-research":0.3971018859,"prompt-eng":0.385513419,"data-quality":0.2261596986,"ml-security":0.1602519205}}
{"text":"We then propose ExeDec, a novel decomposition-based synthesis strategy that predicts execution subgoals to solve problems step-by-step informed by program execution at each step.","meta":{"url":"http://arxiv.org/abs/2307.13883v1"},"cats":{"new-dataset":0.1759373677,"dev-research":0.507474047,"prompt-eng":0.4314306835,"data-quality":0.1280896967,"ml-security":0.1864597118}}
{"text":"ExeDec has better synthesis performance and greatly improved compositional generalization ability compared to baselines.","meta":{"url":"http://arxiv.org/abs/2307.13883v1"},"cats":{"new-dataset":0.0806344256,"dev-research":0.3621719232,"prompt-eng":0.3959924091,"data-quality":0.1198006344,"ml-security":0.0752267869}}
{"text":"Human culture research has witnessed an opportunity of revolution thanks to the big data and social network revolution.","meta":{"url":"http://arxiv.org/abs/2307.13882v1"},"cats":{"new-dataset":0.2709447123,"dev-research":0.2360273852,"prompt-eng":0.2904031778,"data-quality":0.1078749432,"ml-security":0.0654068869}}
{"text":"Websites such as Douban.com, Goodreads.com, Pandora and IMDB become the new gold mine for cultural researchers.","meta":{"url":"http://arxiv.org/abs/2307.13882v1"},"cats":{"new-dataset":0.4057104924,"dev-research":0.2144137795,"prompt-eng":0.291649007,"data-quality":0.1343349586,"ml-security":0.0607916632}}
{"text":"In 2021 and 2022, the author of this paper invented 2 data-free recommender systems for AI cold-start problem.","meta":{"url":"http://arxiv.org/abs/2307.13882v1"},"cats":{"new-dataset":0.2502459153,"dev-research":0.2658420537,"prompt-eng":0.377380169,"data-quality":0.1247846808,"ml-security":0.1536968653}}
{"text":"The algorithms can recommend cultural and commercial products to users without reference to users' past preferences.","meta":{"url":"http://arxiv.org/abs/2307.13882v1"},"cats":{"new-dataset":0.0713137348,"dev-research":0.2449759408,"prompt-eng":0.3908550064,"data-quality":0.1603774368,"ml-security":0.1079758876}}
{"text":"The social implications of the new inventions are human cultural tastes can be predicted very precisely without any information related to human individuals.","meta":{"url":"http://arxiv.org/abs/2307.13882v1"},"cats":{"new-dataset":0.0498415665,"dev-research":0.281203752,"prompt-eng":0.3050346205,"data-quality":0.2358672841,"ml-security":0.1973974297}}
{"text":"In this paper, we analyze the AI technologies and its cultural implications together with other AI algorithms.","meta":{"url":"http://arxiv.org/abs/2307.13882v1"},"cats":{"new-dataset":0.1298298981,"dev-research":0.2670870882,"prompt-eng":0.3550928994,"data-quality":0.1910898247,"ml-security":0.1299146002}}
{"text":"We show that human culture is (mostly) a history irrelevant and predictable experience.","meta":{"url":"http://arxiv.org/abs/2307.13882v1"},"cats":{"new-dataset":0.0519432318,"dev-research":0.2776768793,"prompt-eng":0.3218917811,"data-quality":0.2857638788,"ml-security":0.1139224261}}
{"text":"Physics-informed neural networks (PINNs) offer a novel and efficient approach to solving partial differential equations (PDEs).","meta":{"url":"http://arxiv.org/abs/2307.13869v1"},"cats":{"new-dataset":0.1183111441,"dev-research":0.2271005346,"prompt-eng":0.3325527985,"data-quality":0.0745176623,"ml-security":0.1670938098}}
{"text":"Their success lies in the physics-informed loss, which trains a neural network to satisfy a given PDE at specific points and to approximate the solution.","meta":{"url":"http://arxiv.org/abs/2307.13869v1"},"cats":{"new-dataset":0.0415334934,"dev-research":0.1884526964,"prompt-eng":0.3430786001,"data-quality":0.1646419661,"ml-security":0.1751694364}}
{"text":"However, the solutions to PDEs are inherently infinite-dimensional, and the distance between the output and the solution is defined by an integral over the domain.","meta":{"url":"http://arxiv.org/abs/2307.13869v1"},"cats":{"new-dataset":0.0177334361,"dev-research":0.2371761609,"prompt-eng":0.2584745983,"data-quality":0.0706643501,"ml-security":0.1940370688}}
{"text":"Therefore, the physics-informed loss only provides a finite approximation, and selecting appropriate collocation points becomes crucial to suppress the discretization errors, although this aspect has often been overlooked.","meta":{"url":"http://arxiv.org/abs/2307.13869v1"},"cats":{"new-dataset":0.0078767431,"dev-research":0.202869966,"prompt-eng":0.3375200404,"data-quality":0.1726909832,"ml-security":0.1114416451}}
{"text":"In this paper, we propose a new technique called good lattice training (GLT) for PINNs, inspired by number theoretic methods for numerical analysis.","meta":{"url":"http://arxiv.org/abs/2307.13869v1"},"cats":{"new-dataset":0.13937287,"dev-research":0.1736150104,"prompt-eng":0.3585482192,"data-quality":0.1218135142,"ml-security":0.1047825443}}
{"text":"GLT offers a set of collocation points that are effective even with a small number of points and for multi-dimensional spaces.","meta":{"url":"http://arxiv.org/abs/2307.13869v1"},"cats":{"new-dataset":0.2262443986,"dev-research":0.1962783503,"prompt-eng":0.3693865058,"data-quality":0.1213389677,"ml-security":0.0682921276}}
{"text":"Our experiments demonstrate that GLT requires 2--20 times fewer collocation points (resulting in lower computational cost) than uniformly random sampling or Latin hypercube sampling, while achieving competitive performance.","meta":{"url":"http://arxiv.org/abs/2307.13869v1"},"cats":{"new-dataset":0.1026371384,"dev-research":0.1806471929,"prompt-eng":0.3785375942,"data-quality":0.1896769468,"ml-security":0.0585977414}}
{"text":"Advancements in large pre-trained generative models have expanded their potential as effective data generators in visual recognition.","meta":{"url":"http://arxiv.org/abs/2307.13697v1"},"cats":{"new-dataset":0.1600762688,"dev-research":0.2264250363,"prompt-eng":0.4118943197,"data-quality":0.1575859447,"ml-security":0.1068094335}}
{"text":"This work delves into the impact of generative images, primarily comparing paradigms that harness external data (\\ie generative \\vs retrieval \\vs original).   ","meta":{"url":"http://arxiv.org/abs/2307.13697v1"},"cats":{"new-dataset":0.0913265676,"dev-research":0.3055727138,"prompt-eng":0.3754002534,"data-quality":0.2354485317,"ml-security":0.088598247}}
{"text":"Our key contributions are: \\textbf{1) GenBench Construction:}","meta":{"url":"http://arxiv.org/abs/2307.13697v1"},"cats":{"new-dataset":0.1910046917,"dev-research":0.2160224643,"prompt-eng":0.3808302421,"data-quality":0.2173954672,"ml-security":0.0745650846}}
{"text":"We devise \\textbf{GenBench}, a broad benchmark comprising 22 datasets with 2548 categories, to appraise generative data across various visual recognition tasks.","meta":{"url":"http://arxiv.org/abs/2307.13697v1"},"cats":{"new-dataset":0.7340526305,"dev-research":0.2289547126,"prompt-eng":0.3865772919,"data-quality":0.2182739595,"ml-security":0.0838435196}}
{"text":"\\textbf{2) CLER Score:} To address the insufficient correlation of existing metrics (\\eg, FID, CLIP score) with downstream recognition performance, we propose \\textbf{CLER}, a training-free metric indicating generative data's efficiency for recognition tasks prior to training.","meta":{"url":"http://arxiv.org/abs/2307.13697v1"},"cats":{"new-dataset":0.1995345491,"dev-research":0.2069761854,"prompt-eng":0.4164993162,"data-quality":0.2987478455,"ml-security":0.0939591678}}
{"text":"\\textbf{3) New Baselines:} Comparisons of generative data with retrieved data from the same external pool help to elucidate the unique traits of generative data.","meta":{"url":"http://arxiv.org/abs/2307.13697v1"},"cats":{"new-dataset":0.3502656722,"dev-research":0.2791719871,"prompt-eng":0.4073535083,"data-quality":0.2627077877,"ml-security":0.0761564381}}
{"text":"\\textbf{4)","meta":{"url":"http://arxiv.org/abs/2307.13697v1"},"cats":{"new-dataset":0.0573925533,"dev-research":0.2723169543,"prompt-eng":0.3571029095,"data-quality":0.3162370896,"ml-security":0.118083042}}
{"text":"External Knowledge Injection:} By fine-tuning special token embeddings for each category via Textual Inversion, performance improves across 17 datasets, except when dealing with low-resolution reference images.   ","meta":{"url":"http://arxiv.org/abs/2307.13697v1"},"cats":{"new-dataset":0.2791960982,"dev-research":0.2669148085,"prompt-eng":0.3673469397,"data-quality":0.3612908583,"ml-security":0.1774640252}}
{"text":"Our exhaustive benchmark and analysis spotlight generative data's promise in visual recognition, while identifying key challenges for future investigation.","meta":{"url":"http://arxiv.org/abs/2307.13697v1"},"cats":{"new-dataset":0.2065464857,"dev-research":0.2434862568,"prompt-eng":0.3941969149,"data-quality":0.2684700625,"ml-security":0.0868561076}}
{"text":"Maximal Common Subsequences (MCSs) between two strings X and Y are subsequences of both X and Y that are maximal under inclusion.","meta":{"url":"http://arxiv.org/abs/2307.13695v1"},"cats":{"new-dataset":0.4616429607,"dev-research":0.1795746974,"prompt-eng":0.3567052804,"data-quality":0.2183536901,"ml-security":0.0679384887}}
{"text":"MCSs relax and generalize the well known and widely used concept of Longest Common Subsequences (LCSs), which can be seen as MCSs of maximum length.","meta":{"url":"http://arxiv.org/abs/2307.13695v1"},"cats":{"new-dataset":0.3412600303,"dev-research":0.1792674288,"prompt-eng":0.3406589829,"data-quality":0.1362226575,"ml-security":0.073496469}}
{"text":"While the number both LCSs and MCSs can be exponential in the length of the strings, LCSs have been long exploited for string and text analysis, as simple compact representations of all LCSs between two strings, built via dynamic programming or automata, have been known since the '70s.","meta":{"url":"http://arxiv.org/abs/2307.13695v1"},"cats":{"new-dataset":0.1832937772,"dev-research":0.2006228312,"prompt-eng":0.3879648083,"data-quality":0.1664245282,"ml-security":0.1099153328}}
{"text":"MCSs appear to have a more challenging structure: even listing them efficiently was an open problem open until recently, thus narrowing the complexity difference between the two problems, but the gap remained significant.","meta":{"url":"http://arxiv.org/abs/2307.13695v1"},"cats":{"new-dataset":0.1942903331,"dev-research":0.2260779244,"prompt-eng":0.3713599052,"data-quality":0.1631511632,"ml-security":0.0669205401}}
{"text":"In this paper we close the complexity gap: we show how to build DAG of polynomial size-in polynomial time-which allows for efficient operations on the set of all MCSs such as enumeration in Constant Amortized Time per solution (CAT), counting, and random access to the i-th element (i.e., rank and select operations).","meta":{"url":"http://arxiv.org/abs/2307.13695v1"},"cats":{"new-dataset":0.2270841087,"dev-research":0.2431099955,"prompt-eng":0.3689654174,"data-quality":0.0918017957,"ml-security":0.079000872}}
{"text":"Other than improving known algorithmic results, this work paves the way for new sequence analysis methods based on MCSs.","meta":{"url":"http://arxiv.org/abs/2307.13695v1"},"cats":{"new-dataset":0.2570688947,"dev-research":0.197770042,"prompt-eng":0.3702508124,"data-quality":0.1807337234,"ml-security":0.0558883966}}
{"text":"The rise of large language models (LLMs) has marked a pivotal shift in the field of natural language processing (NLP).","meta":{"url":"http://arxiv.org/abs/2307.13693v1"},"cats":{"new-dataset":0.0952031466,"dev-research":0.1587207618,"prompt-eng":0.3851628122,"data-quality":0.1719926767,"ml-security":0.091679068}}
{"text":"LLMs have revolutionized a multitude of domains, and they have made a significant impact in the medical field.","meta":{"url":"http://arxiv.org/abs/2307.13693v1"},"cats":{"new-dataset":0.0208020668,"dev-research":0.1575115448,"prompt-eng":0.3515750669,"data-quality":0.07791009,"ml-security":0.0990131312}}
{"text":"Large language models are now more abundant than ever, and many of these models exhibit bilingual capabilities, proficient in both English and Chinese.","meta":{"url":"http://arxiv.org/abs/2307.13693v1"},"cats":{"new-dataset":0.0636549627,"dev-research":0.215356338,"prompt-eng":0.3201731513,"data-quality":0.1227086766,"ml-security":0.08110218}}
{"text":"However, a comprehensive evaluation of these models remains to be conducted.","meta":{"url":"http://arxiv.org/abs/2307.13693v1"},"cats":{"new-dataset":0.0567253232,"dev-research":0.1556031266,"prompt-eng":0.3846970082,"data-quality":0.1256873125,"ml-security":0.0419315057}}
{"text":"This lack of assessment is especially apparent within the context of radiology NLP.","meta":{"url":"http://arxiv.org/abs/2307.13693v1"},"cats":{"new-dataset":0.013272562,"dev-research":0.300437878,"prompt-eng":0.3869644696,"data-quality":0.430266307,"ml-security":0.0710570637}}
{"text":"This study seeks to bridge this gap by critically evaluating thirty two LLMs in interpreting radiology reports, a crucial component of radiology NLP.","meta":{"url":"http://arxiv.org/abs/2307.13693v1"},"cats":{"new-dataset":0.0457788953,"dev-research":0.2880470042,"prompt-eng":0.4150108949,"data-quality":0.2521809546,"ml-security":0.0374353942}}
{"text":"Specifically, the ability to derive impressions from radiologic findings is assessed.","meta":{"url":"http://arxiv.org/abs/2307.13693v1"},"cats":{"new-dataset":0.0147543688,"dev-research":0.2927945927,"prompt-eng":0.4766448702,"data-quality":0.192192174,"ml-security":0.059682038}}
{"text":"The outcomes of this evaluation provide key insights into the performance, strengths, and weaknesses of these LLMs, informing their practical applications within the medical domain.","meta":{"url":"http://arxiv.org/abs/2307.13693v1"},"cats":{"new-dataset":0.0173730241,"dev-research":0.1536577519,"prompt-eng":0.4148148259,"data-quality":0.1057310899,"ml-security":0.0594263399}}
{"text":"Large Language Models (LLMs) have demonstrated remarkable performance on various quantitative reasoning and knowledge benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.13692v1"},"cats":{"new-dataset":0.1844434451,"dev-research":0.2100723838,"prompt-eng":0.4063481162,"data-quality":0.1813152267,"ml-security":0.0853410103}}
{"text":"However, many of these benchmarks are losing utility as LLMs get increasingly high scores, despite not yet reaching expert performance in these domains.","meta":{"url":"http://arxiv.org/abs/2307.13692v1"},"cats":{"new-dataset":0.0265005092,"dev-research":0.221546054,"prompt-eng":0.4104485393,"data-quality":0.2533247268,"ml-security":0.1506170107}}
{"text":"We introduce ARB, a novel benchmark composed of advanced reasoning problems in multiple fields.","meta":{"url":"http://arxiv.org/abs/2307.13692v1"},"cats":{"new-dataset":0.1930213982,"dev-research":0.3007200948,"prompt-eng":0.4296100506,"data-quality":0.1863569686,"ml-security":0.0638124159}}
{"text":"ARB presents a more challenging test than prior benchmarks, featuring problems in mathematics, physics, biology, chemistry, and law.","meta":{"url":"http://arxiv.org/abs/2307.13692v1"},"cats":{"new-dataset":0.1137823759,"dev-research":0.2374443072,"prompt-eng":0.3985679693,"data-quality":0.1452503135,"ml-security":0.0724602262}}
{"text":"As a subset of ARB, we introduce a challenging set of math and physics problems which require advanced symbolic reasoning and domain knowledge.","meta":{"url":"http://arxiv.org/abs/2307.13692v1"},"cats":{"new-dataset":0.209950988,"dev-research":0.2416138161,"prompt-eng":0.3881711905,"data-quality":0.1259129432,"ml-security":0.0944505404}}
{"text":"We evaluate recent models such as GPT-4 and Claude on ARB and demonstrate that current models score well below 50% on more demanding tasks.","meta":{"url":"http://arxiv.org/abs/2307.13692v1"},"cats":{"new-dataset":0.1688307145,"dev-research":0.1971859556,"prompt-eng":0.4632560492,"data-quality":0.1178421835,"ml-security":0.0516135569}}
{"text":"In order to improve both automatic and assisted evaluation capabilities, we introduce a rubric-based evaluation approach, allowing GPT-4 to score its own intermediate reasoning steps.","meta":{"url":"http://arxiv.org/abs/2307.13692v1"},"cats":{"new-dataset":0.1550810532,"dev-research":0.3919182419,"prompt-eng":0.4996986312,"data-quality":0.222686765,"ml-security":0.0453752896}}
{"text":"Further, we conduct a human evaluation of the symbolic subset of ARB, finding promising agreement between annotators and GPT-4 rubric evaluation scores.","meta":{"url":"http://arxiv.org/abs/2307.13692v1"},"cats":{"new-dataset":0.2216319965,"dev-research":0.3099705496,"prompt-eng":0.4722406821,"data-quality":0.3027269639,"ml-security":0.0541799837}}
{"text":"The growing interest in unmanned aerial vehicles (UAVs) from both scientific and industrial sectors has attracted a wave of new researchers and substantial investments in this expansive field.","meta":{"url":"http://arxiv.org/abs/2307.13691v1"},"cats":{"new-dataset":0.1031126388,"dev-research":0.2593734143,"prompt-eng":0.3344467886,"data-quality":0.0562071437,"ml-security":0.10792359}}
{"text":"However, due to the wide range of topics and subdomains within UAV research, newcomers may find themselves overwhelmed by the numerous options available.","meta":{"url":"http://arxiv.org/abs/2307.13691v1"},"cats":{"new-dataset":0.1153473972,"dev-research":0.3011441834,"prompt-eng":0.4211697038,"data-quality":0.0730074205,"ml-security":0.0858108347}}
{"text":"It is therefore crucial for those involved in UAV research to recognize its interdisciplinary nature and its connections with other disciplines.","meta":{"url":"http://arxiv.org/abs/2307.13691v1"},"cats":{"new-dataset":0.0646112848,"dev-research":0.2460156293,"prompt-eng":0.3427826744,"data-quality":0.0687004716,"ml-security":0.0688130649}}
{"text":"This paper presents a comprehensive overview of the UAV field, highlighting recent trends and advancements.","meta":{"url":"http://arxiv.org/abs/2307.13691v1"},"cats":{"new-dataset":0.1413530719,"dev-research":0.1728916405,"prompt-eng":0.3939988948,"data-quality":0.0468447437,"ml-security":0.0838848239}}
{"text":"Drawing on recent literature reviews and surveys, the review begins by classifying UAVs based on their flight characteristics.","meta":{"url":"http://arxiv.org/abs/2307.13691v1"},"cats":{"new-dataset":0.1779365873,"dev-research":0.2031267216,"prompt-eng":0.3958678484,"data-quality":0.0919835655,"ml-security":0.121532854}}
{"text":"It then provides an overview of current research trends in UAVs, utilizing data from the Scopus database to quantify the number of scientific documents associated with each research direction and their interconnections.","meta":{"url":"http://arxiv.org/abs/2307.13691v1"},"cats":{"new-dataset":0.2672745593,"dev-research":0.2344869809,"prompt-eng":0.376234868,"data-quality":0.0538769205,"ml-security":0.0592994331}}
{"text":"The paper also explores potential areas for further development in UAVs, including communication, artificial intelligence, remote sensing, miniaturization, swarming and cooperative control, and transformability.","meta":{"url":"http://arxiv.org/abs/2307.13691v1"},"cats":{"new-dataset":0.1374494899,"dev-research":0.2519722976,"prompt-eng":0.358378823,"data-quality":0.0568744721,"ml-security":0.1057579866}}
{"text":"Additionally, it discusses the development of aircraft control, commonly used control techniques, and appropriate control algorithms in UAV research.","meta":{"url":"http://arxiv.org/abs/2307.13691v1"},"cats":{"new-dataset":0.2417951957,"dev-research":0.3113636307,"prompt-eng":0.3788271128,"data-quality":0.0530643047,"ml-security":0.0980443102}}
{"text":"Furthermore, the paper addresses the general hardware and software architecture of UAVs, their applications, and the key issues associated with them.","meta":{"url":"http://arxiv.org/abs/2307.13691v1"},"cats":{"new-dataset":0.0996666178,"dev-research":0.2637305504,"prompt-eng":0.3916132553,"data-quality":0.0575751445,"ml-security":0.0953260594}}
{"text":"It also provides an overview of current open-source software and hardware projects in the UAV field.","meta":{"url":"http://arxiv.org/abs/2307.13691v1"},"cats":{"new-dataset":0.3486352237,"dev-research":0.2594645068,"prompt-eng":0.3473953577,"data-quality":0.0465704819,"ml-security":0.0691289641}}
{"text":"By presenting a comprehensive view of the UAV field, this paper aims to enhance understanding of this rapidly evolving and highly interdisciplinary area of research.","meta":{"url":"http://arxiv.org/abs/2307.13691v1"},"cats":{"new-dataset":0.1501334208,"dev-research":0.2426315485,"prompt-eng":0.3859273903,"data-quality":0.0444159493,"ml-security":0.0828105542}}
{"text":"The $k$-means++ algorithm by Arthur and Vassilvitskii [SODA 2007] is a classical and time-tested algorithm for the $k$-means problem.","meta":{"url":"http://arxiv.org/abs/2307.13685v1"},"cats":{"new-dataset":0.2771368372,"dev-research":0.1782346607,"prompt-eng":0.3248019276,"data-quality":0.1755221626,"ml-security":0.1047501497}}
{"text":"While being very practical, the algorithm also has good theoretical guarantees: its solution is $O(\\log k)$-approximate, in expectation.   ","meta":{"url":"http://arxiv.org/abs/2307.13685v1"},"cats":{"new-dataset":0.0560834445,"dev-research":0.1508509107,"prompt-eng":0.3425124884,"data-quality":0.106791456,"ml-security":0.0744307718}}
{"text":"In a recent work, Bhattacharya, Eube, Roglin, and Schmidt [ESA 2020] considered the following question: does the algorithm retain its guarantees if we allow for a slight adversarial noise in the sampling probability distributions used by the algorithm?","meta":{"url":"http://arxiv.org/abs/2307.13685v1"},"cats":{"new-dataset":0.0296896149,"dev-research":0.1738782056,"prompt-eng":0.2876027631,"data-quality":0.3071912126,"ml-security":0.5210605991}}
{"text":"This is motivated e.g. by the fact that computations with real numbers in $k$-means++ implementations are inexact.   ","meta":{"url":"http://arxiv.org/abs/2307.13685v1"},"cats":{"new-dataset":0.0142664756,"dev-research":0.3419210737,"prompt-eng":0.2780344546,"data-quality":0.1596277106,"ml-security":0.2524867553}}
{"text":"Surprisingly, the analysis under this scenario gets substantially more difficult and the authors were able to prove only a weaker approximation guarantee of $O(\\log^2 k)$.","meta":{"url":"http://arxiv.org/abs/2307.13685v1"},"cats":{"new-dataset":0.1937046589,"dev-research":0.1185754746,"prompt-eng":0.3032342146,"data-quality":0.2001159777,"ml-security":0.1260629915}}
{"text":"In this paper, we close the gap by providing a tight, $O(\\log k)$-approximate guarantee for the $k$-means++ algorithm with noise.","meta":{"url":"http://arxiv.org/abs/2307.13685v1"},"cats":{"new-dataset":0.1806904037,"dev-research":0.1790761114,"prompt-eng":0.3256845128,"data-quality":0.3006228798,"ml-security":0.1312251284}}
{"text":"We introduce text2fabric, a novel dataset that links free-text descriptions to various fabric materials.","meta":{"url":"http://arxiv.org/abs/2307.13681v1"},"cats":{"new-dataset":0.6859280228,"dev-research":0.2417546499,"prompt-eng":0.3853649416,"data-quality":0.1624234286,"ml-security":0.0472479847}}
{"text":"The dataset comprises 15,000 natural language descriptions associated to 3,000 corresponding images of fabric materials.","meta":{"url":"http://arxiv.org/abs/2307.13681v1"},"cats":{"new-dataset":0.9093087495,"dev-research":0.2061109298,"prompt-eng":0.3500991055,"data-quality":0.1914574538,"ml-security":0.0613985867}}
{"text":"Traditionally, material descriptions come in the form of tags/keywords, which limits their expressivity, induces pre-existing knowledge of the appropriate vocabulary, and ultimately leads to a chopped description system.","meta":{"url":"http://arxiv.org/abs/2307.13681v1"},"cats":{"new-dataset":0.0654362606,"dev-research":0.3519731769,"prompt-eng":0.3859863762,"data-quality":0.2762188418,"ml-security":0.0629173952}}
{"text":"Therefore, we study the use of free-text as a more appropriate way to describe material appearance, taking the use case of fabrics as a common item that non-experts may often deal with.","meta":{"url":"http://arxiv.org/abs/2307.13681v1"},"cats":{"new-dataset":0.0972384464,"dev-research":0.3199428656,"prompt-eng":0.3962998815,"data-quality":0.2088139433,"ml-security":0.1010017589}}
{"text":"Based on the analysis of the dataset, we identify a compact lexicon, set of attributes and key structure that emerge from the descriptions.","meta":{"url":"http://arxiv.org/abs/2307.13681v1"},"cats":{"new-dataset":0.8130511277,"dev-research":0.2634796937,"prompt-eng":0.3690445444,"data-quality":0.2121978835,"ml-security":0.0939318253}}
{"text":"This allows us to accurately understand how people describe fabrics and draw directions for generalization to other types of materials.","meta":{"url":"http://arxiv.org/abs/2307.13681v1"},"cats":{"new-dataset":0.0291562625,"dev-research":0.3487251033,"prompt-eng":0.4027934187,"data-quality":0.129786651,"ml-security":0.0691599656}}
{"text":"We also show that our dataset enables specializing large vision-language models such as CLIP, creating a meaningful latent space for fabric appearance, and significantly improving applications such as fine-grained material retrieval and automatic captioning.","meta":{"url":"http://arxiv.org/abs/2307.13681v1"},"cats":{"new-dataset":0.6488444723,"dev-research":0.2271189969,"prompt-eng":0.3729634915,"data-quality":0.1756393993,"ml-security":0.0700582578}}
{"text":"Gradient clipping is a commonly used technique to stabilize the training process of neural networks.","meta":{"url":"http://arxiv.org/abs/2307.13680v1"},"cats":{"new-dataset":0.0090011292,"dev-research":0.2898421683,"prompt-eng":0.3591343808,"data-quality":0.2051383172,"ml-security":0.250932997}}
{"text":"A growing body of studies has shown that gradient clipping is a promising technique for dealing with the heavy-tailed behavior that emerged in stochastic optimization as well.","meta":{"url":"http://arxiv.org/abs/2307.13680v1"},"cats":{"new-dataset":0.0093679536,"dev-research":0.2182555086,"prompt-eng":0.4130277974,"data-quality":0.162917709,"ml-security":0.2387195067}}
{"text":"While gradient clipping is significant, its theoretical guarantees are scarce.","meta":{"url":"http://arxiv.org/abs/2307.13680v1"},"cats":{"new-dataset":0.0098981715,"dev-research":0.179334685,"prompt-eng":0.3399485425,"data-quality":0.1794289246,"ml-security":0.2347483465}}
{"text":"Most theoretical guarantees only provide an in-expectation analysis and only focus on optimization performance.","meta":{"url":"http://arxiv.org/abs/2307.13680v1"},"cats":{"new-dataset":0.0072181646,"dev-research":0.1665160359,"prompt-eng":0.3020431784,"data-quality":0.0876850182,"ml-security":0.2138788074}}
{"text":"In this paper, we provide high probability analysis in the non-convex setting and derive the optimization bound and the generalization bound simultaneously for popular stochastic optimization algorithms with gradient clipping, including stochastic gradient descent and its variants of momentum and adaptive stepsizes.","meta":{"url":"http://arxiv.org/abs/2307.13680v1"},"cats":{"new-dataset":0.0628145634,"dev-research":0.1543593907,"prompt-eng":0.3823713833,"data-quality":0.1632844838,"ml-security":0.1654502599}}
{"text":"With the gradient clipping, we study a heavy-tailed assumption that the gradients only have bounded $\\alpha$-th moments for some $\\alpha \\in (1, 2]$, which is much weaker than the standard bounded second-moment assumption.","meta":{"url":"http://arxiv.org/abs/2307.13680v1"},"cats":{"new-dataset":0.0468565449,"dev-research":0.1305322179,"prompt-eng":0.3435175233,"data-quality":0.1717174483,"ml-security":0.2866762746}}
{"text":"Overall, our study provides a relatively complete picture for the theoretical guarantee of stochastic optimization algorithms with clipping.","meta":{"url":"http://arxiv.org/abs/2307.13680v1"},"cats":{"new-dataset":0.0206979175,"dev-research":0.1676543364,"prompt-eng":0.3842934264,"data-quality":0.1778033451,"ml-security":0.1353834547}}
{"text":"Multivariate time series classification is a rapidly growing research field with practical applications in finance, healthcare, engineering, and more.","meta":{"url":"http://arxiv.org/abs/2307.13679v1"},"cats":{"new-dataset":0.1206212715,"dev-research":0.1399010614,"prompt-eng":0.324614161,"data-quality":0.1012182976,"ml-security":0.1093958252}}
{"text":"The complexity of classifying multivariate time series data arises from its high dimensionality, temporal dependencies, and varying lengths.","meta":{"url":"http://arxiv.org/abs/2307.13679v1"},"cats":{"new-dataset":0.1916766095,"dev-research":0.1390277176,"prompt-eng":0.2948042834,"data-quality":0.108158429,"ml-security":0.1136668098}}
{"text":"This paper introduces a novel ensemble classifier called RED CoMETS (Random Enhanced Co-eye for Multivariate Time Series), which addresses these challenges.","meta":{"url":"http://arxiv.org/abs/2307.13679v1"},"cats":{"new-dataset":0.3994139921,"dev-research":0.1678600081,"prompt-eng":0.3604130336,"data-quality":0.2021735192,"ml-security":0.1209938458}}
{"text":"RED CoMETS builds upon the success of Co-eye, an ensemble classifier specifically designed for symbolically represented univariate time series, and extends its capabilities to handle multivariate data.","meta":{"url":"http://arxiv.org/abs/2307.13679v1"},"cats":{"new-dataset":0.561429946,"dev-research":0.2072140208,"prompt-eng":0.3762816897,"data-quality":0.1541358308,"ml-security":0.1010511505}}
{"text":"The performance of RED CoMETS is evaluated on benchmark datasets from the UCR archive, where it demonstrates competitive accuracy when compared to state-of-the-art techniques in multivariate settings.","meta":{"url":"http://arxiv.org/abs/2307.13679v1"},"cats":{"new-dataset":0.4833627696,"dev-research":0.1897662354,"prompt-eng":0.4100566305,"data-quality":0.1438396041,"ml-security":0.0367746877}}
{"text":"Notably, it achieves the highest reported accuracy in the literature for the 'HandMovementDirection' dataset.","meta":{"url":"http://arxiv.org/abs/2307.13679v1"},"cats":{"new-dataset":0.2797863983,"dev-research":0.1911643995,"prompt-eng":0.3793356148,"data-quality":0.122974121,"ml-security":0.0384174958}}
{"text":"Moreover, the proposed method significantly reduces computation time compared to Co-eye, making it an efficient and effective choice for multivariate time series classification.","meta":{"url":"http://arxiv.org/abs/2307.13679v1"},"cats":{"new-dataset":0.113999786,"dev-research":0.1881846882,"prompt-eng":0.3593205354,"data-quality":0.1398224323,"ml-security":0.0873454225}}
{"text":"Many data analytic systems have adopted a newly emerging compute resource, serverless (SL), to handle data analytics queries in a timely and cost-efficient manner, i.e., serverless data analytics.","meta":{"url":"http://arxiv.org/abs/2307.13677v1"},"cats":{"new-dataset":0.1037758866,"dev-research":0.2591218086,"prompt-eng":0.3416448232,"data-quality":0.1091480889,"ml-security":0.1023711605}}
{"text":"While these systems can start processing queries quickly thanks to the agility and scalability of SL, they may encounter performance-","meta":{"url":"http://arxiv.org/abs/2307.13677v1"},"cats":{"new-dataset":0.0759670055,"dev-research":0.2330161852,"prompt-eng":0.4277397394,"data-quality":0.0993070126,"ml-security":0.0590517857}}
{"text":"and cost-bottlenecks based on workloads due to SL's worse performance and more expensive cost than traditional compute resources, e.g., virtual machine (VM).","meta":{"url":"http://arxiv.org/abs/2307.13677v1"},"cats":{"new-dataset":0.0138105026,"dev-research":0.3558638458,"prompt-eng":0.349619665,"data-quality":0.1023954285,"ml-security":0.1106054504}}
{"text":"In this project, we introduce Smartpick, a SL-enabled scalable data analytics system that exploits SL and VM together to realize composite benefits, i.e., agility from SL and better performance with reduced cost from VM.","meta":{"url":"http://arxiv.org/abs/2307.13677v1"},"cats":{"new-dataset":0.2200220987,"dev-research":0.3688265218,"prompt-eng":0.3799275744,"data-quality":0.160340415,"ml-security":0.1182300689}}
{"text":"Smartpick uses a machine learning prediction scheme, decision-tree based Random Forest with Bayesian Optimizer, to determine SL and VM configurations, i.e., how many SL and VM instances for queries, that meet cost-performance goals.","meta":{"url":"http://arxiv.org/abs/2307.13677v1"},"cats":{"new-dataset":0.0789604252,"dev-research":0.3009990932,"prompt-eng":0.3904456058,"data-quality":0.1198883749,"ml-security":0.1399340633}}
{"text":"Smartpick offers a knob for applications to allow them to explore a richer cost-performance tradeoff space opened by exploiting SL and VM together.","meta":{"url":"http://arxiv.org/abs/2307.13677v1"},"cats":{"new-dataset":0.0538675757,"dev-research":0.4164363593,"prompt-eng":0.4185411157,"data-quality":0.1175053841,"ml-security":0.149192657}}
{"text":"To maximize the benefits of SL, Smartpick supports a simple but strong mechanism, called relay-instances.","meta":{"url":"http://arxiv.org/abs/2307.13677v1"},"cats":{"new-dataset":0.0392445253,"dev-research":0.3105897882,"prompt-eng":0.4786045975,"data-quality":0.0873327504,"ml-security":0.1810082779}}
{"text":"Smartpick also supports event-driven prediction model retraining to deal with workload dynamics.","meta":{"url":"http://arxiv.org/abs/2307.13677v1"},"cats":{"new-dataset":0.1566268695,"dev-research":0.3796515189,"prompt-eng":0.4299905122,"data-quality":0.1142987469,"ml-security":0.1277137723}}
{"text":"A Smartpick prototype was implemented on Spark and deployed on live test-beds, Amazon AWS and Google Cloud Platform.","meta":{"url":"http://arxiv.org/abs/2307.13677v1"},"cats":{"new-dataset":0.3085544093,"dev-research":0.2921593732,"prompt-eng":0.4566558255,"data-quality":0.1252083458,"ml-security":0.1258426412}}
{"text":"Evaluation results indicate 97.05% and 83.49% prediction accuracies respectively with up to 50% cost reduction as opposed to the baselines.","meta":{"url":"http://arxiv.org/abs/2307.13677v1"},"cats":{"new-dataset":0.0382891055,"dev-research":0.2506088994,"prompt-eng":0.4458940526,"data-quality":0.1674481742,"ml-security":0.0513883965}}
{"text":"The results also confirm that Smartpick allows data analytics applications to navigate the richer cost-performance tradeoff space efficiently and to handle workload dynamics effectively and automatically.","meta":{"url":"http://arxiv.org/abs/2307.13677v1"},"cats":{"new-dataset":0.1752120058,"dev-research":0.4376173165,"prompt-eng":0.3791914945,"data-quality":0.1460731132,"ml-security":0.126841594}}
{"text":"We study the interaction of structural subtyping with parametric polymorphism and recursively defined type constructors.","meta":{"url":"http://arxiv.org/abs/2307.13661v1"},"cats":{"new-dataset":0.0330859545,"dev-research":0.2814070053,"prompt-eng":0.4194217447,"data-quality":0.1252420331,"ml-security":0.0971561558}}
{"text":"Although structural subtyping is undecidable in this setting, we describe a notion of parametricity for type constructors and then exploit it to define parametric subtyping, a conceptually simple, decidable, and expressive fragment of structural subtyping that strictly generalizes nominal subtyping.","meta":{"url":"http://arxiv.org/abs/2307.13661v1"},"cats":{"new-dataset":0.0343299224,"dev-research":0.3942505753,"prompt-eng":0.4383555157,"data-quality":0.1764073484,"ml-security":0.1233339357}}
{"text":"We present and prove correct an effective saturation-based decision procedure for parametric subtyping, demonstrating its applicability using a variety of examples.","meta":{"url":"http://arxiv.org/abs/2307.13661v1"},"cats":{"new-dataset":0.0396356337,"dev-research":0.2938991347,"prompt-eng":0.4855206021,"data-quality":0.1613109966,"ml-security":0.0784979161}}
{"text":"An implementation of this decision procedure is available in an online repository.","meta":{"url":"http://arxiv.org/abs/2307.13661v1"},"cats":{"new-dataset":0.2440336325,"dev-research":0.2007252972,"prompt-eng":0.4886279645,"data-quality":0.145992583,"ml-security":0.0300493492}}
{"text":"The Gromov--Hausdorff distance measures the difference in shape between compact metric spaces and poses a notoriously difficult problem in combinatorial optimization.","meta":{"url":"http://arxiv.org/abs/2307.13660v1"},"cats":{"new-dataset":0.1137643359,"dev-research":0.1870336957,"prompt-eng":0.3324044248,"data-quality":0.1427385643,"ml-security":0.0723514401}}
{"text":"We introduce its quadratic relaxation over a convex polytope whose solutions provably deliver the Gromov--Hausdorff distance.","meta":{"url":"http://arxiv.org/abs/2307.13660v1"},"cats":{"new-dataset":0.0824581672,"dev-research":0.1806138233,"prompt-eng":0.3219207971,"data-quality":0.1301988798,"ml-security":0.1202899634}}
{"text":"The optimality guarantee is enabled by the fact that the search space of our approach is not constrained to a generalization of bijections, unlike in other relaxations such as the Gromov--Wasserstein distance.   ","meta":{"url":"http://arxiv.org/abs/2307.13660v1"},"cats":{"new-dataset":0.0529572527,"dev-research":0.1250571909,"prompt-eng":0.3344469586,"data-quality":0.15805051,"ml-security":0.0989850168}}
{"text":"We suggest the Frank--Wolfe algorithm with $O(n^3)$-time iterations for solving the relaxation and numerically demonstrate its performance on metric spaces of hundreds of points.","meta":{"url":"http://arxiv.org/abs/2307.13660v1"},"cats":{"new-dataset":0.2379325761,"dev-research":0.2102151213,"prompt-eng":0.3378904754,"data-quality":0.1391292159,"ml-security":0.0549362974}}
{"text":"In particular, we obtain a new upper bound of the Gromov--Hausdorff distance between the unit circle and the unit hemisphere equipped with Euclidean metric.","meta":{"url":"http://arxiv.org/abs/2307.13660v1"},"cats":{"new-dataset":0.3343235209,"dev-research":0.1499610256,"prompt-eng":0.3337228527,"data-quality":0.1420098684,"ml-security":0.0856702829}}
{"text":"Our approach is implemented as a Python package dGH.","meta":{"url":"http://arxiv.org/abs/2307.13660v1"},"cats":{"new-dataset":0.3609910103,"dev-research":0.2336602862,"prompt-eng":0.4544908601,"data-quality":0.1619048283,"ml-security":0.0512029834}}
{"text":"This white paper is a response to the \"AI Accountability Policy Request for Comments\" by the National Telecommunications and Information Administration of the United States.","meta":{"url":"http://arxiv.org/abs/2307.13658v1"},"cats":{"new-dataset":0.1429889646,"dev-research":0.2765643237,"prompt-eng":0.3918539987,"data-quality":0.3019930005,"ml-security":0.2779571926}}
{"text":"The question numbers for which comments were requested are provided in superscripts at the end of key sentences answering the respective questions.","meta":{"url":"http://arxiv.org/abs/2307.13658v1"},"cats":{"new-dataset":0.2577960124,"dev-research":0.2531198278,"prompt-eng":0.4653907658,"data-quality":0.1240280231,"ml-security":0.0653715477}}
{"text":"The white paper offers a set of interconnected recommendations for an AI accountability policy.","meta":{"url":"http://arxiv.org/abs/2307.13658v1"},"cats":{"new-dataset":0.1286297975,"dev-research":0.2990243666,"prompt-eng":0.3545012887,"data-quality":0.1337135891,"ml-security":0.1943624489}}
{"text":"The human hand has an inherent ability to manipulate and re-orientate objects without external assistance.","meta":{"url":"http://arxiv.org/abs/2307.13657v1"},"cats":{"new-dataset":0.0262664741,"dev-research":0.2274086536,"prompt-eng":0.3690830034,"data-quality":0.0663987342,"ml-security":0.0755429658}}
{"text":"As a consequence, we are able to operate tools and perform an array of actions using just one hand, without having to continuously re-grasp objects.","meta":{"url":"http://arxiv.org/abs/2307.13657v1"},"cats":{"new-dataset":0.0522276583,"dev-research":0.2847244476,"prompt-eng":0.3436705742,"data-quality":0.0624195025,"ml-security":0.1473555429}}
{"text":"Emulating this functionality in robotic end-effectors remains a key area of study with efforts being made to create advanced control systems that could be used to operate complex manipulators.","meta":{"url":"http://arxiv.org/abs/2307.13657v1"},"cats":{"new-dataset":0.0498859935,"dev-research":0.2456543846,"prompt-eng":0.451690074,"data-quality":0.0705108999,"ml-security":0.0862638054}}
{"text":"In this paper, a three fingered soft gripper with an active rotary palm is presented as a simpler, alternative method of performing in-hand rotations.","meta":{"url":"http://arxiv.org/abs/2307.13657v1"},"cats":{"new-dataset":0.0315449241,"dev-research":0.2133037282,"prompt-eng":0.3692271698,"data-quality":0.0858037586,"ml-security":0.0463919978}}
{"text":"The gripper, complete with its pneumatic suction cup to prevent object slippage, was tested and found to be able to effectively grasp and rotate a variety of objects both quickly and precisely.","meta":{"url":"http://arxiv.org/abs/2307.13657v1"},"cats":{"new-dataset":0.0319719419,"dev-research":0.2266371976,"prompt-eng":0.3930883681,"data-quality":0.06711605,"ml-security":0.0570868342}}
{"text":"With the development of pre-trained models and the incorporation of phonetic and graphic information, neural models have achieved high scores in Chinese Spelling Check (CSC).","meta":{"url":"http://arxiv.org/abs/2307.13655v1"},"cats":{"new-dataset":0.1017679577,"dev-research":0.2441852179,"prompt-eng":0.4508211433,"data-quality":0.2681916373,"ml-security":0.1119482812}}
{"text":"However, it does not provide a comprehensive reflection of the models' capability due to the limited test sets.","meta":{"url":"http://arxiv.org/abs/2307.13655v1"},"cats":{"new-dataset":0.0446871782,"dev-research":0.1835483691,"prompt-eng":0.3919687489,"data-quality":0.1120867788,"ml-security":0.0783952823}}
{"text":"In this study, we abstract the representative model paradigm, implement it with nine structures and experiment them on comprehensive test sets we constructed with different purposes.","meta":{"url":"http://arxiv.org/abs/2307.13655v1"},"cats":{"new-dataset":0.1261591109,"dev-research":0.2466660195,"prompt-eng":0.5271533079,"data-quality":0.1517523407,"ml-security":0.0944186819}}
{"text":"We perform a detailed analysis of the results and find that: 1) Fusing phonetic and graphic information reasonably is effective for CSC.","meta":{"url":"http://arxiv.org/abs/2307.13655v1"},"cats":{"new-dataset":0.4636545268,"dev-research":0.3055535886,"prompt-eng":0.4562282178,"data-quality":0.2888440785,"ml-security":0.0903550472}}
{"text":"2) Models are sensitive to the error distribution of the test set, which reflects the shortcomings of models and reveals the direction we should work on.","meta":{"url":"http://arxiv.org/abs/2307.13655v1"},"cats":{"new-dataset":0.0672798827,"dev-research":0.2656910998,"prompt-eng":0.4338208058,"data-quality":0.3703114858,"ml-security":0.2012971486}}
{"text":"3) Whether or not the errors and contexts have been seen has a significant impact on models.","meta":{"url":"http://arxiv.org/abs/2307.13655v1"},"cats":{"new-dataset":0.0126425084,"dev-research":0.3367058409,"prompt-eng":0.3546216857,"data-quality":0.3452329459,"ml-security":0.1600403751}}
{"text":"4) The commonly used benchmark, SIGHAN, can not reliably evaluate models' performance.","meta":{"url":"http://arxiv.org/abs/2307.13655v1"},"cats":{"new-dataset":0.0487364777,"dev-research":0.2715789552,"prompt-eng":0.3603741529,"data-quality":0.2165910534,"ml-security":0.096083897}}
{"text":"Object detection has been widely applied for construction safety management, especially personal protective equipment (PPE) detection.","meta":{"url":"http://arxiv.org/abs/2307.13654v1"},"cats":{"new-dataset":0.0609723049,"dev-research":0.2641120395,"prompt-eng":0.4395754634,"data-quality":0.2179870998,"ml-security":0.2454868396}}
{"text":"Though the existing PPE detection models trained on conventional datasets have achieved excellent results, their performance dramatically declines in extreme construction conditions.","meta":{"url":"http://arxiv.org/abs/2307.13654v1"},"cats":{"new-dataset":0.0997401134,"dev-research":0.2311241355,"prompt-eng":0.4492682033,"data-quality":0.323664528,"ml-security":0.2287361106}}
{"text":"A robust detection model NST-YOLOv5 is developed by combining the neural style transfer (NST) and YOLOv5 technologies.","meta":{"url":"http://arxiv.org/abs/2307.13654v1"},"cats":{"new-dataset":0.0918488756,"dev-research":0.230115705,"prompt-eng":0.4555793972,"data-quality":0.3527405665,"ml-security":0.2034998298}}
{"text":"Five extreme conditions are considered and simulated via the NST module to endow the detection model with excellent robustness, including low light, intense light, sand dust, fog, and rain.","meta":{"url":"http://arxiv.org/abs/2307.13654v1"},"cats":{"new-dataset":0.2805666843,"dev-research":0.2155131919,"prompt-eng":0.4777047458,"data-quality":0.1668372827,"ml-security":0.1205074974}}
{"text":"Experiments show that the NST has great potential as a tool for extreme data synthesis since it is better at simulating extreme conditions than other traditional image processing algorithms and helps the NST-YOLOv5 achieve 0.141 and 0.083 mAP_(05:95) improvements in synthesized and real-world extreme data.","meta":{"url":"http://arxiv.org/abs/2307.13654v1"},"cats":{"new-dataset":0.3030640211,"dev-research":0.2258782389,"prompt-eng":0.3599828085,"data-quality":0.1045020147,"ml-security":0.0925035632}}
{"text":"This study provides a new feasible way to obtain a more robust detection model for extreme construction conditions.","meta":{"url":"http://arxiv.org/abs/2307.13654v1"},"cats":{"new-dataset":0.1573819596,"dev-research":0.2824753323,"prompt-eng":0.4485188055,"data-quality":0.2345560296,"ml-security":0.2185541095}}
{"text":"Image quality remains a key problem for both traditional and deep learning (DL)-based approaches to retinal image analysis, but identifying poor quality images can be time consuming and subjective.","meta":{"url":"http://arxiv.org/abs/2307.13646v1"},"cats":{"new-dataset":0.1104810822,"dev-research":0.2677424288,"prompt-eng":0.3538409449,"data-quality":0.3375617951,"ml-security":0.1108708927}}
{"text":"Thus, automated methods for retinal image quality scoring (RIQS) are needed.","meta":{"url":"http://arxiv.org/abs/2307.13646v1"},"cats":{"new-dataset":0.0621639254,"dev-research":0.2266954799,"prompt-eng":0.4370445712,"data-quality":0.2157396634,"ml-security":0.0342438836}}
{"text":"The current state-of-the-art is MCFNet, composed of three Densenet121 backbones each operating in a different colour space.","meta":{"url":"http://arxiv.org/abs/2307.13646v1"},"cats":{"new-dataset":0.4562748001,"dev-research":0.1754821731,"prompt-eng":0.3697785641,"data-quality":0.107785071,"ml-security":0.0786364614}}
{"text":"MCFNet, and the EyeQ dataset released by the same authors, was a huge step forward for RIQS.","meta":{"url":"http://arxiv.org/abs/2307.13646v1"},"cats":{"new-dataset":0.5226301496,"dev-research":0.1854062239,"prompt-eng":0.3744645717,"data-quality":0.1153763677,"ml-security":0.0512690695}}
{"text":"We present QuickQual, a simple approach to RIQS, consisting of a single off-the-shelf ImageNet-pretrained Densenet121 backbone plus a Support Vector Machine (SVM).","meta":{"url":"http://arxiv.org/abs/2307.13646v1"},"cats":{"new-dataset":0.4313382163,"dev-research":0.1828174315,"prompt-eng":0.3630282381,"data-quality":0.2048911394,"ml-security":0.1070401788}}
{"text":"QuickQual performs very well, setting a new state-of-the-art for EyeQ (Accuracy: 88.50% vs 88.00% for MCFNet; AUC: 0.9687 vs 0.9588).","meta":{"url":"http://arxiv.org/abs/2307.13646v1"},"cats":{"new-dataset":0.1685142758,"dev-research":0.2607279845,"prompt-eng":0.4582296958,"data-quality":0.1720340297,"ml-security":0.0296669426}}
{"text":"This suggests that RIQS can be solved with generic perceptual features learned on natural images, as opposed to requiring DL models trained on large amounts of fundus images.","meta":{"url":"http://arxiv.org/abs/2307.13646v1"},"cats":{"new-dataset":0.1530607034,"dev-research":0.1712762231,"prompt-eng":0.3882737919,"data-quality":0.1857992859,"ml-security":0.0942739504}}
{"text":"Additionally, we propose a Fixed Prior linearisation scheme, that converts EyeQ from a 3-way classification to a continuous logistic regression task.","meta":{"url":"http://arxiv.org/abs/2307.13646v1"},"cats":{"new-dataset":0.2320078653,"dev-research":0.2090928641,"prompt-eng":0.4299004379,"data-quality":0.1714550804,"ml-security":0.0862155107}}
{"text":"For this task, we present a second model, QuickQual MEga Minified Estimator (QuickQual-MEME), that consists of only 10 parameters on top of an off-the-shelf Densenet121 and can distinguish between gradable and ungradable images with an accuracy of 89.18% (AUC: 0.9537).","meta":{"url":"http://arxiv.org/abs/2307.13646v1"},"cats":{"new-dataset":0.4360251825,"dev-research":0.1473330956,"prompt-eng":0.3716483432,"data-quality":0.2695720576,"ml-security":0.0800940846}}
{"text":"Code and model are available on GitHub: https://github.com/justinengelmann/QuickQual .","meta":{"url":"http://arxiv.org/abs/2307.13646v1"},"cats":{"new-dataset":0.3049202817,"dev-research":0.1865073398,"prompt-eng":0.4452167263,"data-quality":0.0985751365,"ml-security":0.0346686023}}
{"text":"QuickQual is so lightweight, that the entire inference code (and even the parameters for QuickQual-MEME) is already contained in this paper.","meta":{"url":"http://arxiv.org/abs/2307.13646v1"},"cats":{"new-dataset":0.1117146569,"dev-research":0.2268405841,"prompt-eng":0.4256663523,"data-quality":0.1733555745,"ml-security":0.0921742333}}
{"text":"Obtaining labelled data in medical image segmentation is challenging due to the need for pixel-level annotations by experts.","meta":{"url":"http://arxiv.org/abs/2307.13645v1"},"cats":{"new-dataset":0.2519334279,"dev-research":0.2246611825,"prompt-eng":0.429311811,"data-quality":0.4332887568,"ml-security":0.1073412688}}
{"text":"Recent works have shown that augmenting the object of interest with deformable transformations can help mitigate this challenge.","meta":{"url":"http://arxiv.org/abs/2307.13645v1"},"cats":{"new-dataset":0.1392486201,"dev-research":0.2197118353,"prompt-eng":0.3808528679,"data-quality":0.1730704748,"ml-security":0.1518836056}}
{"text":"However, these transformations have been learned globally for the image, limiting their transferability across datasets or applicability in problems where image alignment is difficult.","meta":{"url":"http://arxiv.org/abs/2307.13645v1"},"cats":{"new-dataset":0.1692131332,"dev-research":0.1936705974,"prompt-eng":0.3301052945,"data-quality":0.1963855153,"ml-security":0.1207646525}}
{"text":"While object-centric augmentations provide a great opportunity to overcome these issues, existing works are only focused on position and random transformations without considering shape variations of the objects.","meta":{"url":"http://arxiv.org/abs/2307.13645v1"},"cats":{"new-dataset":0.0707673513,"dev-research":0.2106960486,"prompt-eng":0.3978532527,"data-quality":0.157254759,"ml-security":0.0940087085}}
{"text":"To this end, we propose a novel object-centric data augmentation model that is able to learn the shape variations for the objects of interest and augment the object in place without modifying the rest of the image.","meta":{"url":"http://arxiv.org/abs/2307.13645v1"},"cats":{"new-dataset":0.1821271386,"dev-research":0.2008067904,"prompt-eng":0.3823744141,"data-quality":0.1693520997,"ml-security":0.1055272087}}
{"text":"We demonstrated its effectiveness in improving kidney tumour segmentation when leveraging shape variations learned both from within the same dataset and transferred from external datasets.","meta":{"url":"http://arxiv.org/abs/2307.13645v1"},"cats":{"new-dataset":0.2088231473,"dev-research":0.1810822355,"prompt-eng":0.3397583463,"data-quality":0.1670473328,"ml-security":0.1254272468}}
{"text":"Any autonomous controller will be unsafe in some situations.","meta":{"url":"http://arxiv.org/abs/2307.13642v1"},"cats":{"new-dataset":0.0493462588,"dev-research":0.2350972335,"prompt-eng":0.3797621945,"data-quality":0.132374901,"ml-security":0.4471001733}}
{"text":"The ability to quantitatively identify when these unsafe situations are about to occur is crucial for drawing timely human oversight in, e.g., freight transportation applications.","meta":{"url":"http://arxiv.org/abs/2307.13642v1"},"cats":{"new-dataset":0.0790995423,"dev-research":0.3787824569,"prompt-eng":0.439289237,"data-quality":0.2187532944,"ml-security":0.2793936098}}
{"text":"In this work, we demonstrate that the true criticality of an agent's situation can be robustly defined as the mean reduction in reward given some number of random actions.","meta":{"url":"http://arxiv.org/abs/2307.13642v1"},"cats":{"new-dataset":0.1126574185,"dev-research":0.1872135208,"prompt-eng":0.4131213289,"data-quality":0.2182066437,"ml-security":0.3449614866}}
{"text":"Proxy criticality metrics that are computable in real-time (i.e., without actually simulating the effects of random actions) can be compared to the true criticality, and we show how to leverage these proxy metrics to generate safety margins, which directly tie the consequences of potentially incorrect actions to an anticipated loss in overall performance.","meta":{"url":"http://arxiv.org/abs/2307.13642v1"},"cats":{"new-dataset":0.0630539868,"dev-research":0.3841839853,"prompt-eng":0.4315000936,"data-quality":0.2387650526,"ml-security":0.4097695312}}
{"text":"We evaluate our approach on learned policies from APE-X and A3C within an Atari environment, and demonstrate how safety margins decrease as agents approach failure states.","meta":{"url":"http://arxiv.org/abs/2307.13642v1"},"cats":{"new-dataset":0.1699998775,"dev-research":0.3734917252,"prompt-eng":0.3999255673,"data-quality":0.2030224336,"ml-security":0.4364138426}}
{"text":"The integration of safety margins into programs for monitoring deployed agents allows for the real-time identification of potentially catastrophic situations.","meta":{"url":"http://arxiv.org/abs/2307.13642v1"},"cats":{"new-dataset":0.3692960331,"dev-research":0.4094416128,"prompt-eng":0.4463240962,"data-quality":0.191474504,"ml-security":0.3162087339}}
{"text":"Unsupervised localization and segmentation are long-standing robot vision challenges that describe the critical ability for an autonomous robot to learn to decompose images into individual objects without labeled data.","meta":{"url":"http://arxiv.org/abs/2307.13640v1"},"cats":{"new-dataset":0.1590148418,"dev-research":0.1790500494,"prompt-eng":0.3953789931,"data-quality":0.28300745,"ml-security":0.1388471438}}
{"text":"These tasks are important because of the limited availability of dense image manual annotation and the promising vision of adapting to an evolving set of object categories in lifelong learning.","meta":{"url":"http://arxiv.org/abs/2307.13640v1"},"cats":{"new-dataset":0.2999493959,"dev-research":0.2185865139,"prompt-eng":0.3710564012,"data-quality":0.2676011412,"ml-security":0.1128687426}}
{"text":"Most recent methods focus on using visual appearance continuity as object cues by spatially clustering features obtained from self-supervised vision transformers (ViT).","meta":{"url":"http://arxiv.org/abs/2307.13640v1"},"cats":{"new-dataset":0.0819870204,"dev-research":0.2465741526,"prompt-eng":0.4259801211,"data-quality":0.2393784478,"ml-security":0.0954626962}}
{"text":"In this work, we leverage motion cues, inspired by the common fate principle that pixels that share similar movements tend to belong to the same object.","meta":{"url":"http://arxiv.org/abs/2307.13640v1"},"cats":{"new-dataset":0.1482225597,"dev-research":0.2286595569,"prompt-eng":0.4052125246,"data-quality":0.1360071045,"ml-security":0.0863883865}}
{"text":"We propose a new loss term formulation that uses optical flow in unlabeled videos to encourage self-supervised ViT features to become closer to each other if their corresponding spatial locations share similar movements, and vice versa.","meta":{"url":"http://arxiv.org/abs/2307.13640v1"},"cats":{"new-dataset":0.1034399334,"dev-research":0.201754791,"prompt-eng":0.3536751807,"data-quality":0.2361071511,"ml-security":0.0737126306}}
{"text":"We use the proposed loss function to finetune vision transformers that were originally trained on static images.","meta":{"url":"http://arxiv.org/abs/2307.13640v1"},"cats":{"new-dataset":0.1144408703,"dev-research":0.2170338879,"prompt-eng":0.3678516828,"data-quality":0.2020106592,"ml-security":0.1369969387}}
{"text":"Our fine-tuning procedure outperforms state-of-the-art techniques for unsupervised semantic segmentation through linear probing, without the use of any labeled data.","meta":{"url":"http://arxiv.org/abs/2307.13640v1"},"cats":{"new-dataset":0.2688870904,"dev-research":0.2114038599,"prompt-eng":0.4359592797,"data-quality":0.3580241989,"ml-security":0.1020121887}}
{"text":"This procedure also demonstrates increased performance over original ViT networks across unsupervised object localization and semantic segmentation benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.13640v1"},"cats":{"new-dataset":0.2517087241,"dev-research":0.2193411891,"prompt-eng":0.377987501,"data-quality":0.2550951382,"ml-security":0.0914080859}}
{"text":"Accurate 3D face shape estimation is an enabling technology with applications in healthcare, security, and creative industries, yet current state-of-the-art methods either rely on self-supervised training with 2D image data or supervised training with very limited 3D data.","meta":{"url":"http://arxiv.org/abs/2307.13639v1"},"cats":{"new-dataset":0.0730593875,"dev-research":0.204057575,"prompt-eng":0.3459009825,"data-quality":0.1349202322,"ml-security":0.2012252096}}
{"text":"To bridge this gap, we present a novel approach which uses a conditioned stable diffusion model for face image generation, leveraging the abundance of 2D facial information to inform 3D space.","meta":{"url":"http://arxiv.org/abs/2307.13639v1"},"cats":{"new-dataset":0.2448386602,"dev-research":0.2316286286,"prompt-eng":0.3424328352,"data-quality":0.0988470947,"ml-security":0.1226361982}}
{"text":"By conditioning stable diffusion on depth maps sampled from a 3D Morphable Model (3DMM) of the human face, we generate diverse and shape-consistent images, forming the basis of SynthFace.","meta":{"url":"http://arxiv.org/abs/2307.13639v1"},"cats":{"new-dataset":0.1858356555,"dev-research":0.1940431561,"prompt-eng":0.3387739308,"data-quality":0.0724135017,"ml-security":0.1332135585}}
{"text":"We introduce this large-scale synthesised dataset of 250K photorealistic images and corresponding 3DMM parameters.","meta":{"url":"http://arxiv.org/abs/2307.13639v1"},"cats":{"new-dataset":0.8453383054,"dev-research":0.1860771003,"prompt-eng":0.3291788122,"data-quality":0.0778680964,"ml-security":0.0725970767}}
{"text":"We further propose ControlFace, a deep neural network, trained on SynthFace, which achieves competitive performance on the NoW benchmark, without requiring 3D supervision or manual 3D asset creation.","meta":{"url":"http://arxiv.org/abs/2307.13639v1"},"cats":{"new-dataset":0.3781993943,"dev-research":0.3121794759,"prompt-eng":0.3476363545,"data-quality":0.0951267129,"ml-security":0.1395362279}}
{"text":"The analysis of brain signals holds considerable importance in enhancing our comprehension of diverse learning techniques and cognitive mechanisms.","meta":{"url":"http://arxiv.org/abs/2307.13637v1"},"cats":{"new-dataset":0.0311401776,"dev-research":0.3178625485,"prompt-eng":0.3847377333,"data-quality":0.122638041,"ml-security":0.1262823465}}
{"text":"Game-based learning is increasingly being recognized for its interactive and engaging educational approach.","meta":{"url":"http://arxiv.org/abs/2307.13637v1"},"cats":{"new-dataset":0.099086607,"dev-research":0.3543426654,"prompt-eng":0.3660329636,"data-quality":0.0829024079,"ml-security":0.1331785788}}
{"text":"A pilot study of twelve participants divided into experimental and control groups was conducted to understand its effects on cognitive processes.","meta":{"url":"http://arxiv.org/abs/2307.13637v1"},"cats":{"new-dataset":0.0200050862,"dev-research":0.4164907701,"prompt-eng":0.4416353679,"data-quality":0.0952737405,"ml-security":0.0917487782}}
{"text":"Both groups were provided with the same contents regarding the basic structure of the graph.","meta":{"url":"http://arxiv.org/abs/2307.13637v1"},"cats":{"new-dataset":0.1750987213,"dev-research":0.1926375926,"prompt-eng":0.3067362313,"data-quality":0.1137243574,"ml-security":0.0372474957}}
{"text":"The participants in the experimental group engaged in a quiz-based game, while those in the control group watched a pre-recorded video.","meta":{"url":"http://arxiv.org/abs/2307.13637v1"},"cats":{"new-dataset":0.2797543175,"dev-research":0.3323306339,"prompt-eng":0.461969355,"data-quality":0.131565558,"ml-security":0.1173021636}}
{"text":"Functional Near-Infrared Spectroscopy (fNIRS) was employed to acquire cerebral signals, and a series of pre and post-tests were administered.","meta":{"url":"http://arxiv.org/abs/2307.13637v1"},"cats":{"new-dataset":0.0421055422,"dev-research":0.2556794924,"prompt-eng":0.4025627465,"data-quality":0.0869284678,"ml-security":0.0567724014}}
{"text":"The findings of our study indicate that the group engaged in the game activity displayed elevated levels of oxygenated hemoglobin compared to the group involved in watching videos.","meta":{"url":"http://arxiv.org/abs/2307.13637v1"},"cats":{"new-dataset":0.1501343835,"dev-research":0.3557025865,"prompt-eng":0.3644789194,"data-quality":0.1113630188,"ml-security":0.0821753248}}
{"text":"Conversely, the deoxygenated hemoglobin levels remained relatively consistent across both groups throughout the learning process.","meta":{"url":"http://arxiv.org/abs/2307.13637v1"},"cats":{"new-dataset":0.0103640666,"dev-research":0.2786838748,"prompt-eng":0.3342164136,"data-quality":0.1827591203,"ml-security":0.0693958578}}
{"text":"The aforementioned findings suggest that the use of game-based learning has a substantial influence on cognitive processes.","meta":{"url":"http://arxiv.org/abs/2307.13637v1"},"cats":{"new-dataset":0.0123854512,"dev-research":0.4166460845,"prompt-eng":0.3738478452,"data-quality":0.120677654,"ml-security":0.1255317422}}
{"text":"Furthermore, it is evident that both the game and video groups exhibited higher neural activity in the Lateral Prefrontal cortex (PFC).","meta":{"url":"http://arxiv.org/abs/2307.13637v1"},"cats":{"new-dataset":0.080692512,"dev-research":0.2408247641,"prompt-eng":0.352433915,"data-quality":0.0917594686,"ml-security":0.0898636541}}
{"text":"The oxygenated hemoglobin ratio demonstrates that the game group had 2.33 times more neural processing in the Lateral PFC than the video group.","meta":{"url":"http://arxiv.org/abs/2307.13637v1"},"cats":{"new-dataset":0.0643842612,"dev-research":0.2532122985,"prompt-eng":0.3536398469,"data-quality":0.1205659726,"ml-security":0.0531652741}}
{"text":"This data is further supported by the knowledge gain analysis, which indicates that the game-based approach resulted in a 47.74% higher knowledge gain than the video group, as calculated from the difference in pre-and post-test scores.","meta":{"url":"http://arxiv.org/abs/2307.13637v1"},"cats":{"new-dataset":0.1322416473,"dev-research":0.3198322506,"prompt-eng":0.4171101461,"data-quality":0.1491302159,"ml-security":0.0872212391}}
{"text":"Mainstream bias, where some users receive poor recommendations because their preferences are uncommon or simply because they are less active, is an important aspect to consider regarding fairness in recommender systems.","meta":{"url":"http://arxiv.org/abs/2307.13632v1"},"cats":{"new-dataset":0.0080974353,"dev-research":0.2772259795,"prompt-eng":0.3713319541,"data-quality":0.2795572891,"ml-security":0.2624806552}}
{"text":"Existing methods to mitigate mainstream bias do not explicitly model the importance of these non-mainstream users or, when they do, it is in a way that is not necessarily compatible with the data and recommendation model at hand.","meta":{"url":"http://arxiv.org/abs/2307.13632v1"},"cats":{"new-dataset":0.0062065563,"dev-research":0.2268287101,"prompt-eng":0.3269677927,"data-quality":0.2703190249,"ml-security":0.2759997794}}
{"text":"In contrast, we use the recommendation utility as a more generic and implicit proxy to quantify mainstreamness, and propose a simple user-weighting approach to incorporate it into the training process while taking the cost of potential recommendation errors into account.","meta":{"url":"http://arxiv.org/abs/2307.13632v1"},"cats":{"new-dataset":0.0401556148,"dev-research":0.2815483284,"prompt-eng":0.4120835823,"data-quality":0.3348120718,"ml-security":0.1543924373}}
{"text":"We provide extensive experimental results showing that quantifying mainstreamness via utility is better able at identifying non-mainstream users, and that they are indeed better served when training the model in a cost-sensitive way.","meta":{"url":"http://arxiv.org/abs/2307.13632v1"},"cats":{"new-dataset":0.0537787023,"dev-research":0.2637878311,"prompt-eng":0.4566115129,"data-quality":0.3535934088,"ml-security":0.3005770118}}
{"text":"This is achieved with negligible or no loss in overall recommendation accuracy, meaning that the models learn a better balance across users.","meta":{"url":"http://arxiv.org/abs/2307.13632v1"},"cats":{"new-dataset":0.0033073459,"dev-research":0.2668567244,"prompt-eng":0.3794247383,"data-quality":0.2490301368,"ml-security":0.1512959186}}
{"text":"In addition, we show that research of this kind, which evaluates recommendation quality at the individual user level, may not be reliable if not using enough interactions when assessing model performance.","meta":{"url":"http://arxiv.org/abs/2307.13632v1"},"cats":{"new-dataset":0.01908965,"dev-research":0.3183246337,"prompt-eng":0.431199253,"data-quality":0.2237508192,"ml-security":0.0996951489}}
{"text":"This thesis work falls within the framework of question answering (QA) in the biomedical domain where several specific challenges are addressed, such as specialized lexicons and terminologies, the types of treated questions, and the characteristics of targeted documents.","meta":{"url":"http://arxiv.org/abs/2307.13631v1"},"cats":{"new-dataset":0.1794064462,"dev-research":0.228460653,"prompt-eng":0.4371595059,"data-quality":0.1879273539,"ml-security":0.1059195791}}
{"text":"We are particularly interested in studying and improving methods that aim at finding accurate and short answers to biomedical natural language questions from a large scale of biomedical textual documents in English.","meta":{"url":"http://arxiv.org/abs/2307.13631v1"},"cats":{"new-dataset":0.2505216614,"dev-research":0.2454099561,"prompt-eng":0.4180135168,"data-quality":0.2689622086,"ml-security":0.0687794787}}
{"text":"QA aims at providing inquirers with direct, short and precise answers to their natural language questions.","meta":{"url":"http://arxiv.org/abs/2307.13631v1"},"cats":{"new-dataset":0.1426453255,"dev-research":0.2982828686,"prompt-eng":0.4256430177,"data-quality":0.1644705939,"ml-security":0.0768435038}}
{"text":"In this Ph.D. thesis, we propose four contributions to improve the performance of QA in the biomedical domain.","meta":{"url":"http://arxiv.org/abs/2307.13631v1"},"cats":{"new-dataset":0.0375640877,"dev-research":0.1920632462,"prompt-eng":0.4050802614,"data-quality":0.1178640866,"ml-security":0.0554186873}}
{"text":"In our first contribution, we propose a machine learning-based method for question type classification to determine the types of given questions which enable to a biomedical QA system to use the appropriate answer extraction method.","meta":{"url":"http://arxiv.org/abs/2307.13631v1"},"cats":{"new-dataset":0.0977342731,"dev-research":0.2402876791,"prompt-eng":0.4570517911,"data-quality":0.2535216676,"ml-security":0.116302422}}
{"text":"We also propose an another machine learning-based method to assign one or more topics (e.g., pharmacological, test, treatment, etc.) to given questions in order to determine the semantic types of the expected answers which are very useful in generating specific answer retrieval strategies.","meta":{"url":"http://arxiv.org/abs/2307.13631v1"},"cats":{"new-dataset":0.0379908349,"dev-research":0.2577171345,"prompt-eng":0.4442745536,"data-quality":0.2309720508,"ml-security":0.1396319506}}
{"text":"In the second contribution, we first propose a document retrieval method to retrieve a set of relevant documents that are likely to contain the answers to biomedical questions from the MEDLINE database.","meta":{"url":"http://arxiv.org/abs/2307.13631v1"},"cats":{"new-dataset":0.2805133659,"dev-research":0.1792691917,"prompt-eng":0.4246551357,"data-quality":0.1685924497,"ml-security":0.0393863654}}
{"text":"We then present a passage retrieval method to retrieve a set of relevant passages to questions.","meta":{"url":"http://arxiv.org/abs/2307.13631v1"},"cats":{"new-dataset":0.2674227122,"dev-research":0.2341737036,"prompt-eng":0.4656492764,"data-quality":0.2363991815,"ml-security":0.0452812406}}
{"text":"In the third contribution, we propose specific answer extraction methods to generate both exact and ideal answers.","meta":{"url":"http://arxiv.org/abs/2307.13631v1"},"cats":{"new-dataset":0.107133973,"dev-research":0.2507462813,"prompt-eng":0.4514019092,"data-quality":0.2118977248,"ml-security":0.0623279597}}
{"text":"Finally, in the fourth contribution, we develop a fully automated semantic biomedical QA system called SemBioNLQA which is able to deal with a variety of natural language questions and to generate appropriate answers by providing both exact and ideal answers.","meta":{"url":"http://arxiv.org/abs/2307.13631v1"},"cats":{"new-dataset":0.3422541391,"dev-research":0.289768515,"prompt-eng":0.4559175659,"data-quality":0.2152431652,"ml-security":0.05781304}}
{"text":"Idealized first-principles models of chemical plants can be inaccurate.","meta":{"url":"http://arxiv.org/abs/2307.13621v1"},"cats":{"new-dataset":0.0089738329,"dev-research":0.2737948481,"prompt-eng":0.3467078121,"data-quality":0.2366073298,"ml-security":0.0930034993}}
{"text":"An alternative is to fit a Machine Learning (ML) model directly to plant sensor data.","meta":{"url":"http://arxiv.org/abs/2307.13621v1"},"cats":{"new-dataset":0.1801314291,"dev-research":0.1865586009,"prompt-eng":0.4129803705,"data-quality":0.139446599,"ml-security":0.0996838917}}
{"text":"We use a structured approach: Each unit within the plant gets represented by one ML model.","meta":{"url":"http://arxiv.org/abs/2307.13621v1"},"cats":{"new-dataset":0.3002671431,"dev-research":0.1859188628,"prompt-eng":0.4469336819,"data-quality":0.1403032092,"ml-security":0.0448282748}}
{"text":"After fitting the models to the data, the models are connected into a flowsheet-like directed graph.","meta":{"url":"http://arxiv.org/abs/2307.13621v1"},"cats":{"new-dataset":0.2472654626,"dev-research":0.2331664917,"prompt-eng":0.3992195157,"data-quality":0.1171282144,"ml-security":0.0656738749}}
{"text":"We find that for smaller plants, this approach works well, but for larger plants, the complex dynamics arising from large and nested cycles in the flowsheet lead to instabilities in the cycle solver.","meta":{"url":"http://arxiv.org/abs/2307.13621v1"},"cats":{"new-dataset":0.1523074403,"dev-research":0.2336677023,"prompt-eng":0.3496549865,"data-quality":0.0901848468,"ml-security":0.0756898358}}
{"text":"We analyze this problem in depth and show that it is not merely a specialized concern but rather a more pervasive challenge that will likely occur whenever ML is applied to larger plants.","meta":{"url":"http://arxiv.org/abs/2307.13621v1"},"cats":{"new-dataset":0.2078592934,"dev-research":0.1760750667,"prompt-eng":0.4079089235,"data-quality":0.2681245328,"ml-security":0.1190700983}}
{"text":"To address this problem, we present a way to fine-tune ML models such that solving cycles with the usual methods becomes robust again.","meta":{"url":"http://arxiv.org/abs/2307.13621v1"},"cats":{"new-dataset":0.2374757511,"dev-research":0.2355289079,"prompt-eng":0.3977767388,"data-quality":0.3229940614,"ml-security":0.2047798108}}
{"text":"End-to-end region-based object detectors like Sparse R-CNN usually have multiple cascade bounding box decoding stages, which refine the current predictions according to their previous results.","meta":{"url":"http://arxiv.org/abs/2307.13619v1"},"cats":{"new-dataset":0.1743165302,"dev-research":0.1820697646,"prompt-eng":0.3741810247,"data-quality":0.2246547901,"ml-security":0.1589518793}}
{"text":"Model parameters within each stage are independent, evolving a huge cost.","meta":{"url":"http://arxiv.org/abs/2307.13619v1"},"cats":{"new-dataset":0.0232871407,"dev-research":0.2319070409,"prompt-eng":0.3585154132,"data-quality":0.091828065,"ml-security":0.149844793}}
{"text":"In this paper, we find the general setting of decoding stages is actually redundant.","meta":{"url":"http://arxiv.org/abs/2307.13619v1"},"cats":{"new-dataset":0.0693398029,"dev-research":0.2103945802,"prompt-eng":0.4220014408,"data-quality":0.2150308196,"ml-security":0.1459050488}}
{"text":"By simply sharing parameters and making a recursive decoder, the detector already obtains a significant improvement.","meta":{"url":"http://arxiv.org/abs/2307.13619v1"},"cats":{"new-dataset":0.0364614634,"dev-research":0.2290388353,"prompt-eng":0.4812345498,"data-quality":0.2419746469,"ml-security":0.1640848948}}
{"text":"The recursive decoder can be further enhanced by positional encoding (PE) of the proposal box, which makes it aware of the exact locations and sizes of input bounding boxes, thus becoming adaptive to proposals from different stages during the recursion.","meta":{"url":"http://arxiv.org/abs/2307.13619v1"},"cats":{"new-dataset":0.0899764089,"dev-research":0.3084350563,"prompt-eng":0.482862943,"data-quality":0.1333178781,"ml-security":0.084783585}}
{"text":"Moreover, we also design centerness-based PE to distinguish the RoI feature element and dynamic convolution kernels at different positions within the bounding box.","meta":{"url":"http://arxiv.org/abs/2307.13619v1"},"cats":{"new-dataset":0.1054729572,"dev-research":0.2080441938,"prompt-eng":0.3717012018,"data-quality":0.1854315932,"ml-security":0.1229576472}}
{"text":"To validate the effectiveness of the proposed method, we conduct intensive ablations and build the full model on three recent mainstream region-based detectors.","meta":{"url":"http://arxiv.org/abs/2307.13619v1"},"cats":{"new-dataset":0.1577701479,"dev-research":0.1653181026,"prompt-eng":0.4608644572,"data-quality":0.2361185463,"ml-security":0.0423915501}}
{"text":"The RecusiveDet is able to achieve obvious performance boosts with even fewer model parameters and slightly increased computation cost.","meta":{"url":"http://arxiv.org/abs/2307.13619v1"},"cats":{"new-dataset":0.0367228925,"dev-research":0.2685923095,"prompt-eng":0.4354876229,"data-quality":0.1217322119,"ml-security":0.088863134}}
{"text":"Codes are available at https://github.com/bravezzzzzz/RecursiveDet.","meta":{"url":"http://arxiv.org/abs/2307.13619v1"},"cats":{"new-dataset":0.4656449009,"dev-research":0.2248227352,"prompt-eng":0.4398511586,"data-quality":0.1182714763,"ml-security":0.0428703633}}
{"text":"Financial analysis is an important tool for evaluating company performance.","meta":{"url":"http://arxiv.org/abs/2307.13617v1"},"cats":{"new-dataset":0.0083172541,"dev-research":0.4119648856,"prompt-eng":0.3624305699,"data-quality":0.1086895609,"ml-security":0.0466773156}}
{"text":"Practitioners work to answer financial questions to make profitable investment decisions, and use advanced quantitative analyses to do so.","meta":{"url":"http://arxiv.org/abs/2307.13617v1"},"cats":{"new-dataset":0.0220238947,"dev-research":0.3828369638,"prompt-eng":0.3668621568,"data-quality":0.0656660945,"ml-security":0.0629079912}}
{"text":"As a result, Financial Question Answering (QA) is a question answering task that requires deep reasoning about numbers.","meta":{"url":"http://arxiv.org/abs/2307.13617v1"},"cats":{"new-dataset":0.0680254896,"dev-research":0.2382219114,"prompt-eng":0.3519829643,"data-quality":0.1500246088,"ml-security":0.0907467966}}
{"text":"Furthermore, it is unknown how well pre-trained language models can reason in the financial domain.","meta":{"url":"http://arxiv.org/abs/2307.13617v1"},"cats":{"new-dataset":0.0314424283,"dev-research":0.2723243997,"prompt-eng":0.3513045918,"data-quality":0.2855770514,"ml-security":0.2204467089}}
{"text":"The current state-of-the-art requires a retriever to collect relevant facts about the financial question from the text and a generator to produce a valid financial program and a final answer.","meta":{"url":"http://arxiv.org/abs/2307.13617v1"},"cats":{"new-dataset":0.1506988361,"dev-research":0.2175736738,"prompt-eng":0.4458410829,"data-quality":0.1492356727,"ml-security":0.0598634417}}
{"text":"However, recently large language models like GPT-3 have achieved state-of-the-art performance on wide variety of tasks with just a few shot examples.","meta":{"url":"http://arxiv.org/abs/2307.13617v1"},"cats":{"new-dataset":0.3158966191,"dev-research":0.2404970625,"prompt-eng":0.4076510572,"data-quality":0.1484769122,"ml-security":0.0585426832}}
{"text":"We run several experiments with GPT-3 and find that a separate retrieval model and logic engine continue to be essential components to achieving SOTA performance in this task, particularly due to the precise nature of financial questions and the complex information stored in financial documents.","meta":{"url":"http://arxiv.org/abs/2307.13617v1"},"cats":{"new-dataset":0.1164606267,"dev-research":0.2115200537,"prompt-eng":0.4242610475,"data-quality":0.1296475794,"ml-security":0.0477316064}}
{"text":"With this understanding, our refined prompt-engineering approach on GPT-3 achieves near SOTA accuracy without any fine-tuning.","meta":{"url":"http://arxiv.org/abs/2307.13617v1"},"cats":{"new-dataset":0.1341706485,"dev-research":0.2395366984,"prompt-eng":0.5021743279,"data-quality":0.1465024263,"ml-security":0.0615153532}}
{"text":"Similarity analysis using neural networks has emerged as a powerful technique for understanding and categorizing complex patterns in various domains.","meta":{"url":"http://arxiv.org/abs/2307.13606v1"},"cats":{"new-dataset":0.0513259032,"dev-research":0.273791806,"prompt-eng":0.355382839,"data-quality":0.1861803541,"ml-security":0.1032738581}}
{"text":"By leveraging the latent representations learned by neural networks, data objects such as images can be compared effectively.","meta":{"url":"http://arxiv.org/abs/2307.13606v1"},"cats":{"new-dataset":0.0640249241,"dev-research":0.2863989338,"prompt-eng":0.3697902719,"data-quality":0.2629244608,"ml-security":0.1018362931}}
{"text":"This research explores the utilization of latent information generated by fully convolutional networks (FCNs) in similarity analysis, notably to estimate the visual resemblance of objects segmented in 2D pictures.","meta":{"url":"http://arxiv.org/abs/2307.13606v1"},"cats":{"new-dataset":0.2597252059,"dev-research":0.2040047288,"prompt-eng":0.3171926355,"data-quality":0.1728811397,"ml-security":0.0638689724}}
{"text":"To do this, the analytical scheme comprises two steps: (1) extracting and transforming feature patterns per 2D object from a trained FCN, and (2) identifying the most similar patterns through fuzzy inference.","meta":{"url":"http://arxiv.org/abs/2307.13606v1"},"cats":{"new-dataset":0.3626911568,"dev-research":0.2217004285,"prompt-eng":0.400988812,"data-quality":0.115600659,"ml-security":0.0498500085}}
{"text":"The step (2) can be further enhanced by incorporating a weighting scheme that considers the significance of latent variables in the analysis.","meta":{"url":"http://arxiv.org/abs/2307.13606v1"},"cats":{"new-dataset":0.0298745599,"dev-research":0.210327892,"prompt-eng":0.4415115299,"data-quality":0.1914501559,"ml-security":0.0593053849}}
{"text":"The results provide valuable insights into the benefits and challenges of employing neural network-based similarity analysis for discerning data patterns effectively.","meta":{"url":"http://arxiv.org/abs/2307.13606v1"},"cats":{"new-dataset":0.0686393388,"dev-research":0.3061283974,"prompt-eng":0.3604752603,"data-quality":0.3520592776,"ml-security":0.1595112196}}
{"text":"In recent years the use of Artificial Intelligence (AI) has become increasingly prevalent in a growing number of fields.","meta":{"url":"http://arxiv.org/abs/2307.13601v1"},"cats":{"new-dataset":0.0376282088,"dev-research":0.3116148675,"prompt-eng":0.3544680796,"data-quality":0.0917928192,"ml-security":0.1657683122}}
{"text":"As AI systems are being adopted in more high-stakes areas such as medicine and finance, ensuring that they are trustworthy is of increasing importance.","meta":{"url":"http://arxiv.org/abs/2307.13601v1"},"cats":{"new-dataset":0.0556813555,"dev-research":0.3291053047,"prompt-eng":0.380645117,"data-quality":0.1468612245,"ml-security":0.3539338359}}
{"text":"A concern that is prominently addressed by the development and application of explainability methods, which are purported to increase trust from its users and wider society.","meta":{"url":"http://arxiv.org/abs/2307.13601v1"},"cats":{"new-dataset":0.0168274908,"dev-research":0.5051011392,"prompt-eng":0.4191688443,"data-quality":0.318422174,"ml-security":0.3474177588}}
{"text":"While an increase in trust may be desirable, an analysis of literature from different research fields shows that an exclusive focus on increasing trust may not be warranted.","meta":{"url":"http://arxiv.org/abs/2307.13601v1"},"cats":{"new-dataset":0.0059988428,"dev-research":0.284113832,"prompt-eng":0.3587740919,"data-quality":0.2207046223,"ml-security":0.3631583588}}
{"text":"Something which is well exemplified by the recent development in AI chatbots, which while highly coherent tend to make up facts.","meta":{"url":"http://arxiv.org/abs/2307.13601v1"},"cats":{"new-dataset":0.2341287199,"dev-research":0.3781839749,"prompt-eng":0.3607346827,"data-quality":0.1987643593,"ml-security":0.1329340441}}
{"text":"In this contribution, we investigate the concepts of trust, trustworthiness, and user reliance.   ","meta":{"url":"http://arxiv.org/abs/2307.13601v1"},"cats":{"new-dataset":0.0191970388,"dev-research":0.2790963749,"prompt-eng":0.4150786142,"data-quality":0.2188548218,"ml-security":0.162787979}}
{"text":"In order to foster appropriate reliance on AI we need to prevent both disuse of these systems as well as overtrust.","meta":{"url":"http://arxiv.org/abs/2307.13601v1"},"cats":{"new-dataset":0.0321149212,"dev-research":0.2996363132,"prompt-eng":0.3438485631,"data-quality":0.1510864014,"ml-security":0.5108359767}}
{"text":"From our analysis of research on interpersonal trust, trust in automation, and trust in (X)AI, we identify the potential merit of the distinction between trust and distrust (in AI).","meta":{"url":"http://arxiv.org/abs/2307.13601v1"},"cats":{"new-dataset":0.0566916151,"dev-research":0.4104465494,"prompt-eng":0.4186677947,"data-quality":0.2317589513,"ml-security":0.2792262927}}
{"text":"We propose that alongside trust a healthy amount of distrust is of additional value for mitigating disuse and overtrust.","meta":{"url":"http://arxiv.org/abs/2307.13601v1"},"cats":{"new-dataset":0.0901754829,"dev-research":0.2967274924,"prompt-eng":0.3830540497,"data-quality":0.2432411872,"ml-security":0.4729538906}}
{"text":"We argue that by considering and evaluating both trust and distrust, we can ensure that users can rely appropriately on trustworthy AI, which can both be useful as well as fallible.","meta":{"url":"http://arxiv.org/abs/2307.13601v1"},"cats":{"new-dataset":0.0550195776,"dev-research":0.3692366563,"prompt-eng":0.4242409442,"data-quality":0.293736036,"ml-security":0.4652061076}}
{"text":"Optical sensors have played a pivotal role in acquiring real world data for critical applications.","meta":{"url":"http://arxiv.org/abs/2307.13600v1"},"cats":{"new-dataset":0.1829260111,"dev-research":0.2063074911,"prompt-eng":0.3936985744,"data-quality":0.1117327653,"ml-security":0.0818466199}}
{"text":"This data, when integrated with advanced machine learning algorithms provides meaningful information thus enhancing human vision.","meta":{"url":"http://arxiv.org/abs/2307.13600v1"},"cats":{"new-dataset":0.3954605707,"dev-research":0.2258269843,"prompt-eng":0.3746587828,"data-quality":0.129512976,"ml-security":0.1019618085}}
{"text":"This paper focuses on various optical technologies for design and development of state-of-the-art out-cabin forward vision systems and in-cabin driver monitoring systems.","meta":{"url":"http://arxiv.org/abs/2307.13600v1"},"cats":{"new-dataset":0.1057012021,"dev-research":0.2110574287,"prompt-eng":0.4100949724,"data-quality":0.1412495579,"ml-security":0.0556455402}}
{"text":"The focused optical sensors include Longwave Thermal Imaging (LWIR) cameras, Near Infrared (NIR), Neuromorphic/ event cameras, Visible CMOS cameras and Depth cameras.","meta":{"url":"http://arxiv.org/abs/2307.13600v1"},"cats":{"new-dataset":0.3057894934,"dev-research":0.1757057754,"prompt-eng":0.3837331775,"data-quality":0.0720419384,"ml-security":0.0425958415}}
{"text":"Further the paper discusses different potential applications which can be employed using the unique strengths of each these optical modalities in real time environment.","meta":{"url":"http://arxiv.org/abs/2307.13600v1"},"cats":{"new-dataset":0.0377707988,"dev-research":0.1652773537,"prompt-eng":0.3885094143,"data-quality":0.0646887137,"ml-security":0.0237060434}}
{"text":"Mesh-based numerical solvers are an important part in many design tool chains.","meta":{"url":"http://arxiv.org/abs/2307.13592v1"},"cats":{"new-dataset":0.0225036362,"dev-research":0.3593291298,"prompt-eng":0.3689771591,"data-quality":0.0565707354,"ml-security":0.0585995572}}
{"text":"However, accurate simulations like computational fluid dynamics are time and resource consuming which is why surrogate models are employed to speed-up the solution process.","meta":{"url":"http://arxiv.org/abs/2307.13592v1"},"cats":{"new-dataset":0.0232475412,"dev-research":0.2618418776,"prompt-eng":0.3360608052,"data-quality":0.0433286423,"ml-security":0.0812945739}}
{"text":"Machine Learning based surrogate models on the other hand are fast in predicting approximate solutions but often lack accuracy.","meta":{"url":"http://arxiv.org/abs/2307.13592v1"},"cats":{"new-dataset":0.0181519469,"dev-research":0.2096635595,"prompt-eng":0.3403614907,"data-quality":0.1162835374,"ml-security":0.1492978339}}
{"text":"Thus, the development of the predictor in a predictor-corrector approach is the focus here, where the surrogate model predicts a flow field and the numerical solver corrects it.","meta":{"url":"http://arxiv.org/abs/2307.13592v1"},"cats":{"new-dataset":0.0373450196,"dev-research":0.2757589501,"prompt-eng":0.389794667,"data-quality":0.1270322461,"ml-security":0.1399000542}}
{"text":"This paper scales a state-of-the-art surrogate model from the domain of graph-based machine learning to industry-relevant mesh sizes of a numerical flow simulation.","meta":{"url":"http://arxiv.org/abs/2307.13592v1"},"cats":{"new-dataset":0.1177665063,"dev-research":0.2278565531,"prompt-eng":0.2993484867,"data-quality":0.0661843865,"ml-security":0.1106315239}}
{"text":"The approach partitions and distributes the flow domain to multiple GPUs and provides halo exchange between these partitions during training.","meta":{"url":"http://arxiv.org/abs/2307.13592v1"},"cats":{"new-dataset":0.1563927994,"dev-research":0.217278433,"prompt-eng":0.3814679389,"data-quality":0.0808216264,"ml-security":0.1068925277}}
{"text":"The utilized graph neural network operates directly on the numerical mesh and is able to preserve complex geometries as well as all other properties of the mesh.","meta":{"url":"http://arxiv.org/abs/2307.13592v1"},"cats":{"new-dataset":0.0518754328,"dev-research":0.2376999914,"prompt-eng":0.2801011447,"data-quality":0.0857808568,"ml-security":0.109918277}}
{"text":"The proposed surrogate model is evaluated with an application on a three dimensional turbomachinery setup and compared to a traditionally trained distributed model.","meta":{"url":"http://arxiv.org/abs/2307.13592v1"},"cats":{"new-dataset":0.0439464407,"dev-research":0.2079266811,"prompt-eng":0.3966564017,"data-quality":0.0727927825,"ml-security":0.1234249732}}
{"text":"The results show that the traditional approach produces superior predictions and outperforms the proposed surrogate model.","meta":{"url":"http://arxiv.org/abs/2307.13592v1"},"cats":{"new-dataset":0.0354073324,"dev-research":0.1542031078,"prompt-eng":0.4053143003,"data-quality":0.1045573268,"ml-security":0.0991382417}}
{"text":"Possible explanations, improvements and future directions are outlined.","meta":{"url":"http://arxiv.org/abs/2307.13592v1"},"cats":{"new-dataset":0.015545687,"dev-research":0.3166798079,"prompt-eng":0.3997847609,"data-quality":0.1431050769,"ml-security":0.0860925319}}
{"text":"A central issue lying at the heart of online reinforcement learning (RL) is data efficiency.","meta":{"url":"http://arxiv.org/abs/2307.13586v1"},"cats":{"new-dataset":0.0170083033,"dev-research":0.2608404934,"prompt-eng":0.3257559961,"data-quality":0.1344926417,"ml-security":0.1577101089}}
{"text":"While a number of recent works achieved asymptotically minimal regret in online RL, the optimality of these results is only guaranteed in a ``large-sample'' regime, imposing enormous burn-in cost in order for their algorithms to operate optimally.","meta":{"url":"http://arxiv.org/abs/2307.13586v1"},"cats":{"new-dataset":0.0514642967,"dev-research":0.1494092477,"prompt-eng":0.337493081,"data-quality":0.1660010778,"ml-security":0.1597254777}}
{"text":"How to achieve minimax-optimal regret without incurring any burn-in cost has been an open problem in RL theory.   ","meta":{"url":"http://arxiv.org/abs/2307.13586v1"},"cats":{"new-dataset":0.0257145985,"dev-research":0.1656120115,"prompt-eng":0.3171263226,"data-quality":0.1274462403,"ml-security":0.1869217379}}
{"text":"We settle this problem for the context of finite-horizon inhomogeneous Markov decision processes.","meta":{"url":"http://arxiv.org/abs/2307.13586v1"},"cats":{"new-dataset":0.1222116875,"dev-research":0.1466063496,"prompt-eng":0.3853094299,"data-quality":0.1311289022,"ml-security":0.1660046997}}
{"text":"Specifically, we prove that a modified version of Monotonic Value Propagation (MVP), a model-based algorithm proposed by \\cite{zhang2020reinforcement}, achieves a regret on the order of (modulo log factors)","meta":{"url":"http://arxiv.org/abs/2307.13586v1"},"cats":{"new-dataset":0.0604893824,"dev-research":0.2018625113,"prompt-eng":0.4164810926,"data-quality":0.1811793389,"ml-security":0.0993975048}}
{"text":"\\begin{equation*}   \\min\\big\\{ \\sqrt{SAH^3K}, \\,HK \\big\\}, \\end{equation*} where $S$ is the number of states, $A$ is the number of actions, $H$ is the planning horizon, and $K$ is the total number of episodes.","meta":{"url":"http://arxiv.org/abs/2307.13586v1"},"cats":{"new-dataset":0.3602357901,"dev-research":0.1857573524,"prompt-eng":0.3496585621,"data-quality":0.0548731553,"ml-security":0.0570415069}}
{"text":"This regret matches the minimax lower bound for the entire range of sample size $K\\geq 1$, essentially eliminating any burn-in requirement.","meta":{"url":"http://arxiv.org/abs/2307.13586v1"},"cats":{"new-dataset":0.0551107763,"dev-research":0.1622939911,"prompt-eng":0.3199157285,"data-quality":0.2208660697,"ml-security":0.1270427809}}
{"text":"It also translates to a PAC sample complexity (i.e., the number of episodes needed to yield $\\varepsilon$-accuracy) of $\\frac{SAH^3}{\\varepsilon^2}$ up to log factor, which is minimax-optimal for the full $\\varepsilon$-range.   ","meta":{"url":"http://arxiv.org/abs/2307.13586v1"},"cats":{"new-dataset":0.0258559742,"dev-research":0.1590401156,"prompt-eng":0.2779126661,"data-quality":0.1108600504,"ml-security":0.0618685625}}
{"text":"Further, we extend our theory to unveil the influences of problem-dependent quantities like the optimal value/cost and certain variances.","meta":{"url":"http://arxiv.org/abs/2307.13586v1"},"cats":{"new-dataset":0.0163481385,"dev-research":0.1807544128,"prompt-eng":0.3632977355,"data-quality":0.1810499035,"ml-security":0.2134622838}}
{"text":"The key technical innovation lies in the development of a new regret decomposition strategy and a novel analysis paradigm to decouple complicated statistical dependency -- a long-standing challenge facing the analysis of online RL in the sample-hungry regime.","meta":{"url":"http://arxiv.org/abs/2307.13586v1"},"cats":{"new-dataset":0.0521578073,"dev-research":0.2479512684,"prompt-eng":0.398756736,"data-quality":0.1924322526,"ml-security":0.1078770095}}
{"text":"Argumentative explainable AI has been advocated by several in recent years, with an increasing interest on explaining the reasoning outcomes of Argumentation Frameworks (AFs).","meta":{"url":"http://arxiv.org/abs/2307.13582v1"},"cats":{"new-dataset":0.0896776801,"dev-research":0.3305737874,"prompt-eng":0.3999842059,"data-quality":0.1989404192,"ml-security":0.205794111}}
{"text":"While there is a considerable body of research on qualitatively explaining the reasoning outcomes of AFs with debates/disputes/dialogues in the spirit of \\emph{extension-based semantics}, explaining the quantitative reasoning outcomes of AFs under \\emph{gradual semantics} has not received much attention, despite widespread use in applications.","meta":{"url":"http://arxiv.org/abs/2307.13582v1"},"cats":{"new-dataset":0.0470698681,"dev-research":0.4290134548,"prompt-eng":0.4066931102,"data-quality":0.2447054064,"ml-security":0.141325334}}
{"text":"In this paper, we contribute to filling this gap by proposing a novel theory of \\emph{Argument Attribution Explanations (AAEs)} by incorporating the spirit of feature attribution from machine learning in the context of Quantitative Bipolar Argumentation Frameworks (QBAFs): whereas feature attribution is used to determine the influence of features towards outputs of machine learning models, AAEs are used to determine the influence of arguments towards \\emph{topic argument}s of interest.","meta":{"url":"http://arxiv.org/abs/2307.13582v1"},"cats":{"new-dataset":0.0237953421,"dev-research":0.3961157703,"prompt-eng":0.3883097867,"data-quality":0.3731972231,"ml-security":0.3572584227}}
{"text":"We study desirable properties of AAEs, including some new ones and some partially adapted from the literature to our setting.","meta":{"url":"http://arxiv.org/abs/2307.13582v1"},"cats":{"new-dataset":0.0802359209,"dev-research":0.1418610158,"prompt-eng":0.3936834274,"data-quality":0.1546252441,"ml-security":0.0951732357}}
{"text":"To demonstrate the applicability of our AAEs in practice, we conclude by carrying out two case studies in the scenarios of fake news detection and movie recommender systems.","meta":{"url":"http://arxiv.org/abs/2307.13582v1"},"cats":{"new-dataset":0.0866554747,"dev-research":0.2223706272,"prompt-eng":0.3525311603,"data-quality":0.3574263496,"ml-security":0.2871906373}}
{"text":"Survival analysis is an integral part of the statistical toolbox.","meta":{"url":"http://arxiv.org/abs/2307.13579v1"},"cats":{"new-dataset":0.1385648441,"dev-research":0.1819222167,"prompt-eng":0.3471545852,"data-quality":0.089333768,"ml-security":0.0766035649}}
{"text":"However, while most domains of classical statistics have embraced deep learning, survival analysis only recently gained some minor attention from the deep learning community.","meta":{"url":"http://arxiv.org/abs/2307.13579v1"},"cats":{"new-dataset":0.1827469049,"dev-research":0.1730774402,"prompt-eng":0.268358655,"data-quality":0.1362579585,"ml-security":0.1639564674}}
{"text":"This recent development is likely in part motivated by the COVID-19 pandemic.","meta":{"url":"http://arxiv.org/abs/2307.13579v1"},"cats":{"new-dataset":0.1240066562,"dev-research":0.264542947,"prompt-eng":0.3942663676,"data-quality":0.1173748391,"ml-security":0.1926951849}}
{"text":"We aim to provide the tools needed to fully harness the potential of survival analysis in deep learning.","meta":{"url":"http://arxiv.org/abs/2307.13579v1"},"cats":{"new-dataset":0.204104478,"dev-research":0.2157293453,"prompt-eng":0.3194208901,"data-quality":0.1784441724,"ml-security":0.1969597936}}
{"text":"On the one hand, we discuss how survival analysis connects to classification and regression.","meta":{"url":"http://arxiv.org/abs/2307.13579v1"},"cats":{"new-dataset":0.0684882243,"dev-research":0.2365494934,"prompt-eng":0.3186504393,"data-quality":0.2087925516,"ml-security":0.1940558897}}
{"text":"On the other hand, we provide technical tools.","meta":{"url":"http://arxiv.org/abs/2307.13579v1"},"cats":{"new-dataset":0.061894359,"dev-research":0.4569507525,"prompt-eng":0.3582585971,"data-quality":0.1184304748,"ml-security":0.071018504}}
{"text":"We provide a new loss function, evaluation metrics, and the first universal approximating network that provably produces survival curves without numeric integration.","meta":{"url":"http://arxiv.org/abs/2307.13579v1"},"cats":{"new-dataset":0.2350109813,"dev-research":0.1463650021,"prompt-eng":0.3353011544,"data-quality":0.1565023582,"ml-security":0.1258253779}}
{"text":"We show that the loss function and model outperform other approaches using a large numerical study.","meta":{"url":"http://arxiv.org/abs/2307.13579v1"},"cats":{"new-dataset":0.0359517716,"dev-research":0.1564610236,"prompt-eng":0.3560774301,"data-quality":0.2196807638,"ml-security":0.1093916364}}
{"text":"Optimal transport and its related problems, including optimal partial transport, have proven to be valuable tools in machine learning for computing meaningful distances between probability or positive measures.","meta":{"url":"http://arxiv.org/abs/2307.13571v1"},"cats":{"new-dataset":0.0577733069,"dev-research":0.1647525322,"prompt-eng":0.367143825,"data-quality":0.1644124944,"ml-security":0.1437009895}}
{"text":"This success has led to a growing interest in defining transport-based distances that allow for comparing signed measures and, more generally, multi-channeled signals.","meta":{"url":"http://arxiv.org/abs/2307.13571v1"},"cats":{"new-dataset":0.0603492707,"dev-research":0.2163889725,"prompt-eng":0.4170165246,"data-quality":0.1188842004,"ml-security":0.0563933152}}
{"text":"Transport $\\mathrm{L}^{p}$ distances are notable extensions of the optimal transport framework to signed and possibly multi-channeled signals.","meta":{"url":"http://arxiv.org/abs/2307.13571v1"},"cats":{"new-dataset":0.065934569,"dev-research":0.1489809226,"prompt-eng":0.358430582,"data-quality":0.0893992661,"ml-security":0.0822253306}}
{"text":"In this paper, we introduce partial transport $\\mathrm{L}^{p}$ distances as a new family of metrics for comparing generic signals, benefiting from the robustness of partial transport distances.","meta":{"url":"http://arxiv.org/abs/2307.13571v1"},"cats":{"new-dataset":0.106084902,"dev-research":0.1897571185,"prompt-eng":0.3811414807,"data-quality":0.1728376311,"ml-security":0.1099456282}}
{"text":"We provide theoretical background such as the existence of optimal plans and the behavior of the distance in various limits.","meta":{"url":"http://arxiv.org/abs/2307.13571v1"},"cats":{"new-dataset":0.0745693138,"dev-research":0.2037684579,"prompt-eng":0.3233817098,"data-quality":0.0802074053,"ml-security":0.112490972}}
{"text":"Furthermore, we introduce the sliced variation of these distances, which allows for rapid comparison of generic signals.","meta":{"url":"http://arxiv.org/abs/2307.13571v1"},"cats":{"new-dataset":0.1311822508,"dev-research":0.1560540968,"prompt-eng":0.3948055447,"data-quality":0.1345087581,"ml-security":0.0542333837}}
{"text":"Finally, we demonstrate the application of the proposed distances in signal class separability and nearest neighbor classification.","meta":{"url":"http://arxiv.org/abs/2307.13571v1"},"cats":{"new-dataset":0.0829894676,"dev-research":0.1824385589,"prompt-eng":0.3410691984,"data-quality":0.3042995568,"ml-security":0.1831341162}}
{"text":"Next-generation wireless communication systems impose much stricter requirements for transmission rate, latency, and reliability.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.0200893438,"dev-research":0.2605940758,"prompt-eng":0.3892362413,"data-quality":0.1712878092,"ml-security":0.1218797835}}
{"text":"The peak data rate of 6G networks should be no less than 1 Tb/s, which is comparable to existing long-haul optical transport networks.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.0927073872,"dev-research":0.1298655219,"prompt-eng":0.301080561,"data-quality":0.1231256155,"ml-security":0.0645851584}}
{"text":"It is believed that using long error-correcting codes (ECC) with soft-decision decoding (SDD) is not feasible in this case due to the resulting high power consumption.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.0307532062,"dev-research":0.3087115749,"prompt-eng":0.426454265,"data-quality":0.3713065076,"ml-security":0.1581011246}}
{"text":"On the other hand, ECC with hard-decision decoding (HDD) suffers from significant performance degradation.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.013839423,"dev-research":0.3051713525,"prompt-eng":0.3623920347,"data-quality":0.1861448023,"ml-security":0.1338953112}}
{"text":"In this paper, we consider a concatenated solution consisting of an outer long HDD code and an inner short SDD code.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.2630933186,"dev-research":0.2367474839,"prompt-eng":0.3627647234,"data-quality":0.1343035718,"ml-security":0.0841816992}}
{"text":"The latter code is a crucial component of the system and the focus of our research.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.0801148903,"dev-research":0.3331455173,"prompt-eng":0.3859963482,"data-quality":0.1263611791,"ml-security":0.0596293093}}
{"text":"Due to its short length, the code cannot correct all errors, but it is designed to minimize the number of errors.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.0151625744,"dev-research":0.4009011516,"prompt-eng":0.3914446639,"data-quality":0.4644527525,"ml-security":0.1168701932}}
{"text":"Such codes are known as error-reducing codes.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.0469600952,"dev-research":0.3296561376,"prompt-eng":0.4197146262,"data-quality":0.4754270504,"ml-security":0.1459720699}}
{"text":"We investigate the error-reducing properties of superposition codes.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.0220726479,"dev-research":0.2555565478,"prompt-eng":0.3797700028,"data-quality":0.3402620358,"ml-security":0.1786129854}}
{"text":"Initially, we explore sparse regression codes (SPARCs) with Gaussian signals.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.2226669203,"dev-research":0.1729893931,"prompt-eng":0.3741236765,"data-quality":0.2008488491,"ml-security":0.1630390013}}
{"text":"This approach outperforms error-reducing binary LDPC codes optimized by Barakatain, et al.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.0788306778,"dev-research":0.2837391468,"prompt-eng":0.451982505,"data-quality":0.3354983896,"ml-security":0.1168404373}}
{"text":"(2018) in terms of performance","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.0605539752,"dev-research":0.27285942,"prompt-eng":0.3450014197,"data-quality":0.0975933723,"ml-security":0.0519271328}}
{"text":"but faces limitations in practical applicability due to high implementation complexity.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.0124348339,"dev-research":0.4464788103,"prompt-eng":0.3370366205,"data-quality":0.1065029749,"ml-security":0.1421963499}}
{"text":"Subsequently, we propose an LDPC-based superposition code scheme with low-complexity soft successive interference cancellation (SIC) decoding.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.0476112651,"dev-research":0.2608327747,"prompt-eng":0.3661460541,"data-quality":0.1639225964,"ml-security":0.1091070989}}
{"text":"This scheme demonstrates comparable performance to SPARCs while maintaining manageable complexity.","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.0754092363,"dev-research":0.3413442891,"prompt-eng":0.4828573596,"data-quality":0.1483445997,"ml-security":0.0868814264}}
{"text":"Numerical results were obtained for inner codes with an overhead (OH) of 8.24% within a concatenated scheme (15% OH) with an outer hard-decision decoded staircase code (6.25% OH).","meta":{"url":"http://arxiv.org/abs/2307.13570v1"},"cats":{"new-dataset":0.0678272815,"dev-research":0.2490110977,"prompt-eng":0.4006840153,"data-quality":0.1721817077,"ml-security":0.0872849186}}
{"text":"To facilitate the reuse of existing charts, previous research has examined how to obtain a semantic understanding of a chart by deconstructing its visual representation into reusable components, such as encodings.","meta":{"url":"http://arxiv.org/abs/2307.13567v1"},"cats":{"new-dataset":0.1673080519,"dev-research":0.4135592636,"prompt-eng":0.4106436254,"data-quality":0.1851132254,"ml-security":0.0692227882}}
{"text":"However, existing deconstruction approaches primarily focus on chart styles, handling only basic layouts.","meta":{"url":"http://arxiv.org/abs/2307.13567v1"},"cats":{"new-dataset":0.0427495414,"dev-research":0.4343873326,"prompt-eng":0.3648535484,"data-quality":0.1504171354,"ml-security":0.1189153369}}
{"text":"In this paper, we investigate how to deconstruct chart layouts, focusing on rectangle-based ones as they cover not only 17 chart types but also advanced layouts (e.g., small multiples, nested layouts).","meta":{"url":"http://arxiv.org/abs/2307.13567v1"},"cats":{"new-dataset":0.2787333269,"dev-research":0.3724513248,"prompt-eng":0.387805844,"data-quality":0.1361490912,"ml-security":0.0921290339}}
{"text":"We develop an interactive tool, called Mystique, adopting a mixed-initiative approach to extract the axes and legend, and deconstruct a chart's layout into four semantic components: mark groups, spatial relationships, data encodings, and graphical constraints.","meta":{"url":"http://arxiv.org/abs/2307.13567v1"},"cats":{"new-dataset":0.4755475532,"dev-research":0.3559124272,"prompt-eng":0.4205043791,"data-quality":0.1464750859,"ml-security":0.0410459131}}
{"text":"Mystique employs a wizard interface that guides chart authors through a series of steps to specify how the deconstructed components map to their own data.","meta":{"url":"http://arxiv.org/abs/2307.13567v1"},"cats":{"new-dataset":0.3841701713,"dev-research":0.3514086965,"prompt-eng":0.4383214121,"data-quality":0.1247486753,"ml-security":0.0492649829}}
{"text":"On 150 rectangle-based SVG charts, Mystique achieves above 85% accuracy for axis and legend extraction and 96% accuracy for layout deconstruction.","meta":{"url":"http://arxiv.org/abs/2307.13567v1"},"cats":{"new-dataset":0.279782648,"dev-research":0.3065640589,"prompt-eng":0.389663827,"data-quality":0.1639603283,"ml-security":0.0418237527}}
{"text":"In a chart reproduction study, participants could easily reuse existing charts on new datasets.","meta":{"url":"http://arxiv.org/abs/2307.13567v1"},"cats":{"new-dataset":0.3050938856,"dev-research":0.3424277883,"prompt-eng":0.3770331557,"data-quality":0.146773163,"ml-security":0.0920730118}}
{"text":"We discuss the current limitations of Mystique and future research directions.","meta":{"url":"http://arxiv.org/abs/2307.13567v1"},"cats":{"new-dataset":0.0749527006,"dev-research":0.2115503638,"prompt-eng":0.3609867103,"data-quality":0.086943647,"ml-security":0.076880251}}
{"text":"Explainability techniques are rapidly being developed to improve human-AI decision-making across various cooperative work settings.","meta":{"url":"http://arxiv.org/abs/2307.13566v1"},"cats":{"new-dataset":0.0363819349,"dev-research":0.5037929957,"prompt-eng":0.4114522366,"data-quality":0.2350988435,"ml-security":0.1623846933}}
{"text":"Consequently, previous research has evaluated how decision-makers collaborate with imperfect AI by investigating appropriate reliance and task performance with the aim of designing more human-centered computer-supported collaborative tools.","meta":{"url":"http://arxiv.org/abs/2307.13566v1"},"cats":{"new-dataset":0.0263651639,"dev-research":0.5126329791,"prompt-eng":0.4235635742,"data-quality":0.1852652818,"ml-security":0.0798874557}}
{"text":"Several human-centered explainable AI (XAI) techniques have been proposed in hopes of improving decision-makers' collaboration with AI; however, these techniques are grounded in findings from previous studies that primarily focus on the impact of incorrect AI advice.","meta":{"url":"http://arxiv.org/abs/2307.13566v1"},"cats":{"new-dataset":0.0436766518,"dev-research":0.5392424732,"prompt-eng":0.4072583635,"data-quality":0.312640867,"ml-security":0.208403949}}
{"text":"Few studies acknowledge the possibility for the explanations to be incorrect even if the AI advice is correct.","meta":{"url":"http://arxiv.org/abs/2307.13566v1"},"cats":{"new-dataset":0.007909513,"dev-research":0.317339614,"prompt-eng":0.3774503994,"data-quality":0.331664373,"ml-security":0.182589301}}
{"text":"Thus, it is crucial to understand how imperfect XAI affects human-AI decision-making.","meta":{"url":"http://arxiv.org/abs/2307.13566v1"},"cats":{"new-dataset":0.011261788,"dev-research":0.4212190644,"prompt-eng":0.3440894508,"data-quality":0.222117911,"ml-security":0.2009603153}}
{"text":"In this work, we contribute a robust, mixed-methods user study with 136 participants to evaluate how incorrect explanations influence humans' decision-making behavior in a bird species identification task taking into account their level of expertise and an explanation's level of assertiveness.","meta":{"url":"http://arxiv.org/abs/2307.13566v1"},"cats":{"new-dataset":0.0797841234,"dev-research":0.4216878082,"prompt-eng":0.4762853,"data-quality":0.5008144945,"ml-security":0.1920228077}}
{"text":"Our findings reveal the influence of imperfect XAI and humans' level of expertise on their reliance on AI and human-AI team performance.","meta":{"url":"http://arxiv.org/abs/2307.13566v1"},"cats":{"new-dataset":0.0481946434,"dev-research":0.4482494321,"prompt-eng":0.3701135158,"data-quality":0.1707979038,"ml-security":0.1464176853}}
{"text":"We also discuss how explanations can deceive decision-makers during human-AI collaboration.","meta":{"url":"http://arxiv.org/abs/2307.13566v1"},"cats":{"new-dataset":0.0771210977,"dev-research":0.4627987235,"prompt-eng":0.4004175524,"data-quality":0.2901422617,"ml-security":0.477246751}}
{"text":"Hence, we shed light on the impacts of imperfect XAI in the field of computer-supported cooperative work and provide guidelines for designers of human-AI collaboration systems.","meta":{"url":"http://arxiv.org/abs/2307.13566v1"},"cats":{"new-dataset":0.1153082329,"dev-research":0.4476212003,"prompt-eng":0.4106206094,"data-quality":0.1949165067,"ml-security":0.1453305199}}
{"text":"Decision-focused learning (DFL) is an emerging paradigm in machine learning which trains a model to optimize decisions, integrating prediction and optimization in an end-to-end system.","meta":{"url":"http://arxiv.org/abs/2307.13565v1"},"cats":{"new-dataset":0.0707408729,"dev-research":0.3251456368,"prompt-eng":0.3950717142,"data-quality":0.1473336236,"ml-security":0.139992894}}
{"text":"This paradigm holds the promise to revolutionize decision-making in many real-world applications which operate under uncertainty, where the estimation of unknown parameters within these decision models often becomes a substantial roadblock.","meta":{"url":"http://arxiv.org/abs/2307.13565v1"},"cats":{"new-dataset":0.0648723712,"dev-research":0.2413753005,"prompt-eng":0.4118799225,"data-quality":0.2049195987,"ml-security":0.2998837267}}
{"text":"This paper presents a comprehensive review of DFL.","meta":{"url":"http://arxiv.org/abs/2307.13565v1"},"cats":{"new-dataset":0.1076084481,"dev-research":0.319169062,"prompt-eng":0.4206112409,"data-quality":0.1683737951,"ml-security":0.0637909577}}
{"text":"It provides an in-depth analysis of the various techniques devised to integrate machine learning and optimization models introduces a taxonomy of DFL methods distinguished by their unique characteristics, and conducts an extensive empirical evaluation of these methods proposing suitable benchmark dataset and tasks for DFL.","meta":{"url":"http://arxiv.org/abs/2307.13565v1"},"cats":{"new-dataset":0.1305323096,"dev-research":0.2421097021,"prompt-eng":0.4326790671,"data-quality":0.2160521369,"ml-security":0.0858681267}}
{"text":"Finally, the study provides valuable insights into current and potential future avenues in DFL research.","meta":{"url":"http://arxiv.org/abs/2307.13565v1"},"cats":{"new-dataset":0.084762254,"dev-research":0.2669054421,"prompt-eng":0.3748276278,"data-quality":0.1406097456,"ml-security":0.0665982939}}
{"text":"Recently, diffusion models have excelled in image generation tasks and have also been applied to neural language processing (NLP) for controllable text generation.","meta":{"url":"http://arxiv.org/abs/2307.13560v1"},"cats":{"new-dataset":0.102696561,"dev-research":0.2242141119,"prompt-eng":0.3952666518,"data-quality":0.1945505102,"ml-security":0.1054937752}}
{"text":"However, the application of diffusion models in a cross-lingual setting is less unexplored.","meta":{"url":"http://arxiv.org/abs/2307.13560v1"},"cats":{"new-dataset":0.0442272162,"dev-research":0.1769174481,"prompt-eng":0.2891340862,"data-quality":0.1830385393,"ml-security":0.0988521863}}
{"text":"Additionally, while pretraining with diffusion models has been studied within a single language, the potential of cross-lingual pretraining remains understudied.","meta":{"url":"http://arxiv.org/abs/2307.13560v1"},"cats":{"new-dataset":0.0508929023,"dev-research":0.2221887631,"prompt-eng":0.3973056497,"data-quality":0.1771874492,"ml-security":0.0978761625}}
{"text":"To address these gaps, we propose XDLM, a novel Cross-lingual diffusion model for machine translation, consisting of pretraining and fine-tuning stages.","meta":{"url":"http://arxiv.org/abs/2307.13560v1"},"cats":{"new-dataset":0.1435716805,"dev-research":0.1880579896,"prompt-eng":0.3937905252,"data-quality":0.1962425449,"ml-security":0.0536215027}}
{"text":"In the pretraining stage, we propose TLDM, a new training objective for mastering the mapping between different languages; in the fine-tuning stage, we build up the translation system based on the pretrained model.","meta":{"url":"http://arxiv.org/abs/2307.13560v1"},"cats":{"new-dataset":0.297898982,"dev-research":0.2945346018,"prompt-eng":0.4478833749,"data-quality":0.2057170235,"ml-security":0.0695118342}}
{"text":"We evaluate the result on several machine translation benchmarks and outperformed both diffusion and Transformer baselines.","meta":{"url":"http://arxiv.org/abs/2307.13560v1"},"cats":{"new-dataset":0.180434405,"dev-research":0.173735457,"prompt-eng":0.3824717231,"data-quality":0.1834559354,"ml-security":0.0477477345}}
{"text":"Rubik's Cube (RC) is a well-known and computationally challenging puzzle that has motivated AI researchers to explore efficient alternative representations and problem-solving methods.","meta":{"url":"http://arxiv.org/abs/2307.13552v1"},"cats":{"new-dataset":0.1292222167,"dev-research":0.2790474664,"prompt-eng":0.3580193817,"data-quality":0.0850749739,"ml-security":0.0711935863}}
{"text":"The ideal situation for planning here is that a problem be solved optimally and efficiently represented in a standard notation using a general-purpose solver and heuristics.","meta":{"url":"http://arxiv.org/abs/2307.13552v1"},"cats":{"new-dataset":0.1487600674,"dev-research":0.3323599792,"prompt-eng":0.4689454926,"data-quality":0.0779164673,"ml-security":0.0501730123}}
{"text":"The fastest solver today for RC is DeepCubeA with a custom representation, and another approach is with Scorpion planner with State-Action-Space+ (SAS+) representation.","meta":{"url":"http://arxiv.org/abs/2307.13552v1"},"cats":{"new-dataset":0.3621210202,"dev-research":0.2980018748,"prompt-eng":0.418379013,"data-quality":0.0560321347,"ml-security":0.0551723903}}
{"text":"In this paper, we present the first RC representation in the popular PDDL language so that the domain becomes more accessible to PDDL planners, competitions, and knowledge engineering tools, and is more human-readable.","meta":{"url":"http://arxiv.org/abs/2307.13552v1"},"cats":{"new-dataset":0.4173622621,"dev-research":0.4212963456,"prompt-eng":0.4782211664,"data-quality":0.1142319525,"ml-security":0.0676084986}}
{"text":"We then bridge across existing approaches and compare performance.","meta":{"url":"http://arxiv.org/abs/2307.13552v1"},"cats":{"new-dataset":0.0283973457,"dev-research":0.4095733255,"prompt-eng":0.379779711,"data-quality":0.1539680082,"ml-security":0.0732696712}}
{"text":"We find that in one comparable experiment, DeepCubeA solves all problems with varying complexities, albeit only 18\\% are optimal plans.","meta":{"url":"http://arxiv.org/abs/2307.13552v1"},"cats":{"new-dataset":0.1075676514,"dev-research":0.2175495714,"prompt-eng":0.353097081,"data-quality":0.0992815307,"ml-security":0.1067315264}}
{"text":"For the same problem set, Scorpion with SAS+ representation and pattern database heuristics solves 61.50\\% problems, while FastDownward with PDDL representation and FF heuristic solves 56.50\\% problems, out of which all the plans generated were optimal.","meta":{"url":"http://arxiv.org/abs/2307.13552v1"},"cats":{"new-dataset":0.1798982357,"dev-research":0.3180038223,"prompt-eng":0.429348611,"data-quality":0.0950258855,"ml-security":0.0543551074}}
{"text":"Our study provides valuable insights into the trade-offs between representational choice and plan optimality that can help researchers design future strategies for challenging domains combining general-purpose solving methods (planning, reinforcement learning), heuristics, and representations (standard or custom).","meta":{"url":"http://arxiv.org/abs/2307.13552v1"},"cats":{"new-dataset":0.0302168882,"dev-research":0.2960089858,"prompt-eng":0.3731144109,"data-quality":0.0502663202,"ml-security":0.0923337119}}
{"text":"Ontologies are known for their ability to organize rich metadata, support the identification of novel insights via semantic queries, and promote reuse.","meta":{"url":"http://arxiv.org/abs/2307.13549v1"},"cats":{"new-dataset":0.2192530815,"dev-research":0.3295509349,"prompt-eng":0.379283196,"data-quality":0.178400044,"ml-security":0.0917627369}}
{"text":"In this paper, we consider the problem of automated planning, where the objective is to find a sequence of actions that will move an agent from an initial state of the world to a desired goal state.","meta":{"url":"http://arxiv.org/abs/2307.13549v1"},"cats":{"new-dataset":0.2812981904,"dev-research":0.2677543336,"prompt-eng":0.4450844745,"data-quality":0.0798714445,"ml-security":0.0652605852}}
{"text":"We hypothesize that given a large number of available planners and diverse planning domains; they carry essential information that can be leveraged to identify suitable planners and improve their performance for a domain.","meta":{"url":"http://arxiv.org/abs/2307.13549v1"},"cats":{"new-dataset":0.1888203795,"dev-research":0.3877753514,"prompt-eng":0.4489498061,"data-quality":0.0891873245,"ml-security":0.0801461207}}
{"text":"We use data on planning domains and planners from the International Planning Competition (IPC) to construct a planning ontology and demonstrate via experiments in two use cases that the ontology can lead to the selection of promising planners and improving their performance using macros - a form of action ordering constraints extracted from planning ontology.","meta":{"url":"http://arxiv.org/abs/2307.13549v1"},"cats":{"new-dataset":0.2401393506,"dev-research":0.3353095359,"prompt-eng":0.4410719814,"data-quality":0.0740991653,"ml-security":0.0402349227}}
{"text":"We also make the planning ontology and associated resources available to the community to promote further research.","meta":{"url":"http://arxiv.org/abs/2307.13549v1"},"cats":{"new-dataset":0.288614468,"dev-research":0.2820802618,"prompt-eng":0.40806561,"data-quality":0.0806810636,"ml-security":0.0384094634}}
{"text":"In this paper, we present a stealthy and effective attack that exposes privacy vulnerabilities in Graph Neural Networks (GNNs) by inferring private links within graph-structured data.","meta":{"url":"http://arxiv.org/abs/2307.13548v1"},"cats":{"new-dataset":0.2114785914,"dev-research":0.2809848614,"prompt-eng":0.2855459726,"data-quality":0.3251112973,"ml-security":0.8811174577}}
{"text":"Focusing on the inductive setting where new nodes join the graph and an API is used to query predictions, we investigate the potential leakage of private edge information.","meta":{"url":"http://arxiv.org/abs/2307.13548v1"},"cats":{"new-dataset":0.0476064335,"dev-research":0.2429060679,"prompt-eng":0.3518061948,"data-quality":0.2801176657,"ml-security":0.5588616069}}
{"text":"We also propose methods to preserve privacy while maintaining model utility.","meta":{"url":"http://arxiv.org/abs/2307.13548v1"},"cats":{"new-dataset":0.0547786531,"dev-research":0.2341158503,"prompt-eng":0.4095794503,"data-quality":0.1892624474,"ml-security":0.4527377141}}
{"text":"Our attack demonstrates superior performance in inferring the links compared to the state of the art.","meta":{"url":"http://arxiv.org/abs/2307.13548v1"},"cats":{"new-dataset":0.1224192428,"dev-research":0.2863916478,"prompt-eng":0.4272045575,"data-quality":0.2008983394,"ml-security":0.409666938}}
{"text":"Furthermore, we examine the application of differential privacy (DP) mechanisms to mitigate the impact of our proposed attack, we analyze the trade-off between privacy preservation and model utility.","meta":{"url":"http://arxiv.org/abs/2307.13548v1"},"cats":{"new-dataset":0.0687910929,"dev-research":0.3057198717,"prompt-eng":0.3668413053,"data-quality":0.202224325,"ml-security":0.8473858294}}
{"text":"Our work highlights the privacy vulnerabilities inherent in GNNs, underscoring the importance of developing robust privacy-preserving mechanisms for their application.","meta":{"url":"http://arxiv.org/abs/2307.13548v1"},"cats":{"new-dataset":0.1902341978,"dev-research":0.3029023252,"prompt-eng":0.3222080539,"data-quality":0.2920113709,"ml-security":0.8326123093}}
{"text":"Group activity recognition is a hot topic in computer vision.","meta":{"url":"http://arxiv.org/abs/2307.13541v1"},"cats":{"new-dataset":0.1724605627,"dev-research":0.2150434716,"prompt-eng":0.3603428882,"data-quality":0.1448027218,"ml-security":0.113486159}}
{"text":"Recognizing activities through group relationships plays a vital role in group activity recognition.","meta":{"url":"http://arxiv.org/abs/2307.13541v1"},"cats":{"new-dataset":0.0876646064,"dev-research":0.23442045,"prompt-eng":0.3277536621,"data-quality":0.1671359155,"ml-security":0.1133640721}}
{"text":"It holds practical implications in various scenarios, such as video analysis, surveillance, automatic driving, and understanding social activities.","meta":{"url":"http://arxiv.org/abs/2307.13541v1"},"cats":{"new-dataset":0.0463958987,"dev-research":0.2860633966,"prompt-eng":0.3362851855,"data-quality":0.1402378198,"ml-security":0.1844333395}}
{"text":"The model's key capabilities encompass efficiently modeling hierarchical relationships within a scene and accurately extracting distinctive spatiotemporal features from groups.","meta":{"url":"http://arxiv.org/abs/2307.13541v1"},"cats":{"new-dataset":0.2168513315,"dev-research":0.2133378997,"prompt-eng":0.3477875949,"data-quality":0.1275258992,"ml-security":0.0706997954}}
{"text":"Given this technology's extensive applicability, identifying group activities has garnered significant research attention.","meta":{"url":"http://arxiv.org/abs/2307.13541v1"},"cats":{"new-dataset":0.1750398637,"dev-research":0.2117912555,"prompt-eng":0.4286230661,"data-quality":0.1345997356,"ml-security":0.0699327934}}
{"text":"This work examines the current progress in technology for recognizing group activities, with a specific focus on global interactivity and activities.","meta":{"url":"http://arxiv.org/abs/2307.13541v1"},"cats":{"new-dataset":0.253929358,"dev-research":0.230213958,"prompt-eng":0.4104619184,"data-quality":0.1687632556,"ml-security":0.0692959551}}
{"text":"Firstly, we comprehensively review the pertinent literature and various group activity recognition approaches, from traditional methodologies to the latest methods based on spatial structure, descriptors, non-deep learning, hierarchical recurrent neural networks (HRNN), relationship models, and attention mechanisms.","meta":{"url":"http://arxiv.org/abs/2307.13541v1"},"cats":{"new-dataset":0.3290390763,"dev-research":0.1750292828,"prompt-eng":0.3449492532,"data-quality":0.1124189641,"ml-security":0.0995349656}}
{"text":"Subsequently, we present the relational network and relational architectures for each module.","meta":{"url":"http://arxiv.org/abs/2307.13541v1"},"cats":{"new-dataset":0.2942902454,"dev-research":0.2478071906,"prompt-eng":0.407557236,"data-quality":0.0915504374,"ml-security":0.0532534329}}
{"text":"Thirdly, we investigate methods for recognizing group activity and compare their performance with state-of-the-art technologies.","meta":{"url":"http://arxiv.org/abs/2307.13541v1"},"cats":{"new-dataset":0.142120777,"dev-research":0.2497738035,"prompt-eng":0.4204130039,"data-quality":0.2250804279,"ml-security":0.0852379711}}
{"text":"We summarize the existing challenges and provide comprehensive guidance for newcomers to understand group activity recognition.","meta":{"url":"http://arxiv.org/abs/2307.13541v1"},"cats":{"new-dataset":0.2301574642,"dev-research":0.2690805887,"prompt-eng":0.3608694488,"data-quality":0.2242583957,"ml-security":0.1032486614}}
{"text":"Furthermore, we review emerging perspectives in group activity recognition to explore new directions and possibilities.","meta":{"url":"http://arxiv.org/abs/2307.13541v1"},"cats":{"new-dataset":0.1582279957,"dev-research":0.202023832,"prompt-eng":0.3448502965,"data-quality":0.1606158851,"ml-security":0.1177649312}}
{"text":"For safety-related applications, it is crucial to produce trustworthy deep neural networks whose prediction is associated with confidence that can represent the likelihood of correctness for subsequent decision-making.","meta":{"url":"http://arxiv.org/abs/2307.13539v1"},"cats":{"new-dataset":0.0644885984,"dev-research":0.3165739789,"prompt-eng":0.3659331819,"data-quality":0.3657849407,"ml-security":0.6992906983}}
{"text":"Existing dense binary classification models are prone to being over-confident.","meta":{"url":"http://arxiv.org/abs/2307.13539v1"},"cats":{"new-dataset":0.0555245222,"dev-research":0.2413629662,"prompt-eng":0.4016282836,"data-quality":0.4196124191,"ml-security":0.3964407464}}
{"text":"To improve model calibration, we propose Adaptive Stochastic Label Perturbation (ASLP) which learns a unique label perturbation level for each training image.","meta":{"url":"http://arxiv.org/abs/2307.13539v1"},"cats":{"new-dataset":0.1133105728,"dev-research":0.1887333679,"prompt-eng":0.3972015158,"data-quality":0.5957747982,"ml-security":0.1821469327}}
{"text":"ASLP employs our proposed Self-Calibrating Binary Cross Entropy (SC-BCE) loss, which unifies label perturbation processes including stochastic approaches (like DisturbLabel), and label smoothing, to correct calibration while maintaining classification rates.","meta":{"url":"http://arxiv.org/abs/2307.13539v1"},"cats":{"new-dataset":0.0772449206,"dev-research":0.2336720442,"prompt-eng":0.4680266936,"data-quality":0.5739974724,"ml-security":0.1971679516}}
{"text":"ASLP follows Maximum Entropy Inference of classic statistical mechanics to maximise prediction entropy with respect to missing information.","meta":{"url":"http://arxiv.org/abs/2307.13539v1"},"cats":{"new-dataset":0.0872823425,"dev-research":0.1582453406,"prompt-eng":0.4054390354,"data-quality":0.179336708,"ml-security":0.1264866917}}
{"text":"It performs this while: (1) preserving classification accuracy on known data as a conservative solution, or (2) specifically improves model calibration degree by minimising the gap between the prediction accuracy and expected confidence of the target training label.","meta":{"url":"http://arxiv.org/abs/2307.13539v1"},"cats":{"new-dataset":0.0073208623,"dev-research":0.2599517142,"prompt-eng":0.4262167867,"data-quality":0.3597909523,"ml-security":0.1633967288}}
{"text":"Extensive results demonstrate that ASLP can significantly improve calibration degrees of dense binary classification models on both in-distribution and out-of-distribution data.","meta":{"url":"http://arxiv.org/abs/2307.13539v1"},"cats":{"new-dataset":0.2296426995,"dev-research":0.1839166035,"prompt-eng":0.4058813342,"data-quality":0.3616181712,"ml-security":0.1794257546}}
{"text":"The code is available on https://github.com/Carlisle-Liu/ASLP.","meta":{"url":"http://arxiv.org/abs/2307.13539v1"},"cats":{"new-dataset":0.3346995335,"dev-research":0.1593816212,"prompt-eng":0.4608892306,"data-quality":0.1063960155,"ml-security":0.0352458245}}
{"text":"For numerical design, the development of efficient and accurate surrogate models is paramount.","meta":{"url":"http://arxiv.org/abs/2307.13538v1"},"cats":{"new-dataset":0.0269151633,"dev-research":0.1896169462,"prompt-eng":0.3777002806,"data-quality":0.0508513742,"ml-security":0.0856616432}}
{"text":"They allow us to approximate complex physical phenomena, thereby reducing the computational burden of direct numerical simulations.","meta":{"url":"http://arxiv.org/abs/2307.13538v1"},"cats":{"new-dataset":0.0138008223,"dev-research":0.305319103,"prompt-eng":0.3342751767,"data-quality":0.0542000459,"ml-security":0.0837290661}}
{"text":"We propose INFINITY, a deep learning model that utilizes implicit neural representations (INRs) to address this challenge.","meta":{"url":"http://arxiv.org/abs/2307.13538v1"},"cats":{"new-dataset":0.195706698,"dev-research":0.2217428919,"prompt-eng":0.3460460813,"data-quality":0.2313678157,"ml-security":0.2482151867}}
{"text":"Our framework encodes geometric information and physical fields into compact representations and learns a mapping between them to infer the physical fields.","meta":{"url":"http://arxiv.org/abs/2307.13538v1"},"cats":{"new-dataset":0.1487071189,"dev-research":0.2075629027,"prompt-eng":0.3653190634,"data-quality":0.1102229662,"ml-security":0.0994937717}}
{"text":"We use an airfoil design optimization problem as an example task and we evaluate our approach on the challenging AirfRANS dataset, which closely resembles real-world industrial use-cases.","meta":{"url":"http://arxiv.org/abs/2307.13538v1"},"cats":{"new-dataset":0.6218171114,"dev-research":0.2483201803,"prompt-eng":0.3472271408,"data-quality":0.0673013578,"ml-security":0.0993774266}}
{"text":"The experimental results demonstrate that our framework achieves state-of-the-art performance by accurately inferring physical fields throughout the volume and surface.","meta":{"url":"http://arxiv.org/abs/2307.13538v1"},"cats":{"new-dataset":0.078332723,"dev-research":0.2272247254,"prompt-eng":0.4394165756,"data-quality":0.1267253612,"ml-security":0.0549919941}}
{"text":"Additionally we demonstrate its applicability in contexts such as design exploration and shape optimization: our model can correctly predict drag and lift coefficients while adhering to the equations.","meta":{"url":"http://arxiv.org/abs/2307.13538v1"},"cats":{"new-dataset":0.0373507536,"dev-research":0.2909184392,"prompt-eng":0.3814697135,"data-quality":0.0676696344,"ml-security":0.0992440741}}
{"text":"Current referring video object segmentation (R-VOS) techniques extract conditional kernels from encoded (low-resolution) vision-language features to segment the decoded high-resolution features.","meta":{"url":"http://arxiv.org/abs/2307.13537v1"},"cats":{"new-dataset":0.2594967632,"dev-research":0.2173734325,"prompt-eng":0.3891431147,"data-quality":0.2769816099,"ml-security":0.0730224619}}
{"text":"We discovered that this causes significant feature drift, which the segmentation kernels struggle to perceive during the forward computation.","meta":{"url":"http://arxiv.org/abs/2307.13537v1"},"cats":{"new-dataset":0.061812051,"dev-research":0.313509285,"prompt-eng":0.3679146389,"data-quality":0.3603965829,"ml-security":0.2415880119}}
{"text":"This negatively affects the ability of segmentation kernels.","meta":{"url":"http://arxiv.org/abs/2307.13537v1"},"cats":{"new-dataset":0.0111323961,"dev-research":0.253555445,"prompt-eng":0.368497886,"data-quality":0.370105576,"ml-security":0.2337800926}}
{"text":"To address the drift problem, we propose a Spectrum-guided Multi-granularity (SgMg) approach, which performs direct segmentation on the encoded features and employs visual details to further optimize the masks.","meta":{"url":"http://arxiv.org/abs/2307.13537v1"},"cats":{"new-dataset":0.1639885607,"dev-research":0.2302633071,"prompt-eng":0.3812541849,"data-quality":0.2366669296,"ml-security":0.0896061004}}
{"text":"In addition, we propose Spectrum-guided Cross-modal Fusion (SCF) to perform intra-frame global interactions in the spectral domain for effective multimodal representation.","meta":{"url":"http://arxiv.org/abs/2307.13537v1"},"cats":{"new-dataset":0.0924938366,"dev-research":0.2457054302,"prompt-eng":0.4108156852,"data-quality":0.0965081033,"ml-security":0.049776038}}
{"text":"Finally, we extend SgMg to perform multi-object R-VOS, a new paradigm that enables simultaneous segmentation of multiple referred objects in a video.","meta":{"url":"http://arxiv.org/abs/2307.13537v1"},"cats":{"new-dataset":0.227180185,"dev-research":0.1694479826,"prompt-eng":0.3818359767,"data-quality":0.1756281295,"ml-security":0.042548522}}
{"text":"This not only makes R-VOS faster, but also more practical.","meta":{"url":"http://arxiv.org/abs/2307.13537v1"},"cats":{"new-dataset":0.0149663241,"dev-research":0.259826481,"prompt-eng":0.3520487429,"data-quality":0.1227061338,"ml-security":0.076646267}}
{"text":"Extensive experiments show that SgMg achieves state-of-the-art performance on four video benchmark datasets, outperforming the nearest competitor by 2.8% points on Ref-YouTube-VOS.","meta":{"url":"http://arxiv.org/abs/2307.13537v1"},"cats":{"new-dataset":0.237145427,"dev-research":0.2260646827,"prompt-eng":0.366712054,"data-quality":0.2495257862,"ml-security":0.0664102984}}
{"text":"Our extended SgMg enables multi-object R-VOS, runs about 3 times faster while maintaining satisfactory performance.","meta":{"url":"http://arxiv.org/abs/2307.13537v1"},"cats":{"new-dataset":0.0552322296,"dev-research":0.2078664175,"prompt-eng":0.3707377101,"data-quality":0.0784199618,"ml-security":0.0582130475}}
{"text":"Code is available at https://github.com/bo-miao/SgMg.","meta":{"url":"http://arxiv.org/abs/2307.13537v1"},"cats":{"new-dataset":0.2772534477,"dev-research":0.1586196137,"prompt-eng":0.4668713238,"data-quality":0.0972730672,"ml-security":0.0422835869}}
{"text":"Human-Object Interaction (HOI) detection is a challenging computer vision task that requires visual models to address the complex interactive relationship between humans and objects and predict HOI triplets.","meta":{"url":"http://arxiv.org/abs/2307.13529v1"},"cats":{"new-dataset":0.11684921,"dev-research":0.2629252749,"prompt-eng":0.4629667426,"data-quality":0.1769686502,"ml-security":0.118885368}}
{"text":"Despite the challenges posed by the numerous interaction combinations, they also offer opportunities for multimodal learning of visual texts.","meta":{"url":"http://arxiv.org/abs/2307.13529v1"},"cats":{"new-dataset":0.1549690585,"dev-research":0.3136960326,"prompt-eng":0.3632583426,"data-quality":0.1501798862,"ml-security":0.0550724302}}
{"text":"In this paper, we present a systematic and unified framework (RmLR) that enhances HOI detection by incorporating structured text knowledge.","meta":{"url":"http://arxiv.org/abs/2307.13529v1"},"cats":{"new-dataset":0.1476703051,"dev-research":0.2979972187,"prompt-eng":0.5250714674,"data-quality":0.3796005212,"ml-security":0.1574756741}}
{"text":"Firstly, we qualitatively and quantitatively analyze the loss of interaction information in the two-stage HOI detector and propose a re-mining strategy to generate more comprehensive visual representation.","meta":{"url":"http://arxiv.org/abs/2307.13529v1"},"cats":{"new-dataset":0.1343251545,"dev-research":0.2678547432,"prompt-eng":0.5034276845,"data-quality":0.2334140968,"ml-security":0.093591084}}
{"text":"Secondly, we design more fine-grained sentence-","meta":{"url":"http://arxiv.org/abs/2307.13529v1"},"cats":{"new-dataset":0.0559011842,"dev-research":0.3350250892,"prompt-eng":0.4014452332,"data-quality":0.3040334395,"ml-security":0.1141747572}}
{"text":"and word-level alignment and knowledge transfer strategies to effectively address the many-to-many matching problem between multiple interactions and multiple texts.","meta":{"url":"http://arxiv.org/abs/2307.13529v1"},"cats":{"new-dataset":0.0931113206,"dev-research":0.2428007719,"prompt-eng":0.3972669202,"data-quality":0.1853300332,"ml-security":0.0607098452}}
{"text":"These strategies alleviate the matching confusion problem that arises when multiple interactions occur simultaneously, thereby improving the effectiveness of the alignment process.","meta":{"url":"http://arxiv.org/abs/2307.13529v1"},"cats":{"new-dataset":0.0143299357,"dev-research":0.3336614138,"prompt-eng":0.4762593621,"data-quality":0.278377552,"ml-security":0.0621006924}}
{"text":"Finally, HOI reasoning by visual features augmented with textual knowledge substantially improves the understanding of interactions.","meta":{"url":"http://arxiv.org/abs/2307.13529v1"},"cats":{"new-dataset":0.1435281517,"dev-research":0.4624700286,"prompt-eng":0.4616453849,"data-quality":0.1879736638,"ml-security":0.0825373208}}
{"text":"Experimental results illustrate the effectiveness of our approach, where state-of-the-art performance is achieved on public benchmarks.","meta":{"url":"http://arxiv.org/abs/2307.13529v1"},"cats":{"new-dataset":0.077580532,"dev-research":0.2248061569,"prompt-eng":0.4850515819,"data-quality":0.2226091955,"ml-security":0.0479583466}}
{"text":"We further analyze the effects of different components of our approach to provide insights into its efficacy.","meta":{"url":"http://arxiv.org/abs/2307.13529v1"},"cats":{"new-dataset":0.0054975738,"dev-research":0.3214430568,"prompt-eng":0.3948560598,"data-quality":0.1455958682,"ml-security":0.1039862393}}
{"text":"The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text.","meta":{"url":"http://arxiv.org/abs/2307.13528v1"},"cats":{"new-dataset":0.140708846,"dev-research":0.3529992374,"prompt-eng":0.4245300053,"data-quality":0.4263994538,"ml-security":0.1461177474}}
{"text":"In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models.","meta":{"url":"http://arxiv.org/abs/2307.13528v1"},"cats":{"new-dataset":0.0237387756,"dev-research":0.3684427006,"prompt-eng":0.3947130307,"data-quality":0.2869909383,"ml-security":0.207432787}}
{"text":"(2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts.","meta":{"url":"http://arxiv.org/abs/2307.13528v1"},"cats":{"new-dataset":0.071565861,"dev-research":0.3727345149,"prompt-eng":0.3102770559,"data-quality":0.3207175175,"ml-security":0.0761040241}}
{"text":"(3) There is a scarcity of explicit evidence available during the process of fact checking.","meta":{"url":"http://arxiv.org/abs/2307.13528v1"},"cats":{"new-dataset":0.0469368633,"dev-research":0.2832751091,"prompt-eng":0.3183224106,"data-quality":0.295995861,"ml-security":0.2564649853}}
{"text":"With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT).","meta":{"url":"http://arxiv.org/abs/2307.13528v1"},"cats":{"new-dataset":0.3359118479,"dev-research":0.3527527071,"prompt-eng":0.4184841806,"data-quality":0.5246229464,"ml-security":0.1379890312}}
{"text":"Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method.","meta":{"url":"http://arxiv.org/abs/2307.13528v1"},"cats":{"new-dataset":0.0501720652,"dev-research":0.4014243005,"prompt-eng":0.4520303578,"data-quality":0.1292899035,"ml-security":0.0451007843}}
{"text":"Diffusion Models (DM) are highly effective at generating realistic, high-quality images.","meta":{"url":"http://arxiv.org/abs/2307.13527v1"},"cats":{"new-dataset":0.0828112467,"dev-research":0.1535931978,"prompt-eng":0.3666486193,"data-quality":0.1078516306,"ml-security":0.076364699}}
{"text":"However, these models lack creativity and merely compose outputs based on their training data, guided by a textual input provided at creation time.","meta":{"url":"http://arxiv.org/abs/2307.13527v1"},"cats":{"new-dataset":0.0718024286,"dev-research":0.2792175985,"prompt-eng":0.3755434316,"data-quality":0.2826688345,"ml-security":0.1364261242}}
{"text":"Is it acceptable to generate images reminiscent of an artist, employing his name as input?","meta":{"url":"http://arxiv.org/abs/2307.13527v1"},"cats":{"new-dataset":0.0191606469,"dev-research":0.2828334579,"prompt-eng":0.4327470932,"data-quality":0.288485283,"ml-security":0.1731654754}}
{"text":"This imply that if the DM is able to replicate an artist's work then it was trained on some or all of his artworks thus violating copyright.","meta":{"url":"http://arxiv.org/abs/2307.13527v1"},"cats":{"new-dataset":0.0128577185,"dev-research":0.2649909844,"prompt-eng":0.2967773407,"data-quality":0.2553626107,"ml-security":0.2528549864}}
{"text":"In this paper, a preliminary study to infer the probability of use of an artist's name in the input string of a generated image is presented.","meta":{"url":"http://arxiv.org/abs/2307.13527v1"},"cats":{"new-dataset":0.0541362214,"dev-research":0.2084759129,"prompt-eng":0.4889590323,"data-quality":0.3833991753,"ml-security":0.1383206922}}
{"text":"To this aim we focused only on images generated by the famous DALL-E 2 and collected images (both original and generated) of five renowned artists.","meta":{"url":"http://arxiv.org/abs/2307.13527v1"},"cats":{"new-dataset":0.6115330946,"dev-research":0.1814443519,"prompt-eng":0.3462467637,"data-quality":0.1573642585,"ml-security":0.0643276925}}
{"text":"Finally, a dedicated Siamese Neural Network was employed to have a first kind of probability.","meta":{"url":"http://arxiv.org/abs/2307.13527v1"},"cats":{"new-dataset":0.1374330006,"dev-research":0.163973439,"prompt-eng":0.3726305555,"data-quality":0.1439921772,"ml-security":0.0941498401}}
{"text":"Experimental results demonstrate that our approach is an optimal starting point and can be employed as a prior for predicting a complete input string of an investigated image.","meta":{"url":"http://arxiv.org/abs/2307.13527v1"},"cats":{"new-dataset":0.1680310594,"dev-research":0.132014557,"prompt-eng":0.4698488655,"data-quality":0.2017901953,"ml-security":0.0743978615}}
{"text":"Dataset and code are available at: https://github.com/ictlab-unict/not-with-my-name .","meta":{"url":"http://arxiv.org/abs/2307.13527v1"},"cats":{"new-dataset":0.7893658602,"dev-research":0.1631307616,"prompt-eng":0.4302820747,"data-quality":0.1772288381,"ml-security":0.0735801902}}
{"text":"Logically constrained term rewriting systems (LCTRSs) are a program analyzing formalism with native support for data types which are not (co)inductively defined.","meta":{"url":"http://arxiv.org/abs/2307.13519v1"},"cats":{"new-dataset":0.1139540162,"dev-research":0.3865017907,"prompt-eng":0.4283588032,"data-quality":0.150882674,"ml-security":0.0819255905}}
{"text":"As a first-order formalism, LCTRSs have accommodated only analysis of imperative programs so far.","meta":{"url":"http://arxiv.org/abs/2307.13519v1"},"cats":{"new-dataset":0.0801380758,"dev-research":0.2865194598,"prompt-eng":0.3844211255,"data-quality":0.0817858563,"ml-security":0.1150633299}}
{"text":"In this paper, we present a higher-order variant of the LCTRS formalism, which can be used to analyze functional programs.","meta":{"url":"http://arxiv.org/abs/2307.13519v1"},"cats":{"new-dataset":0.0719178234,"dev-research":0.3551638178,"prompt-eng":0.4787974972,"data-quality":0.1136050967,"ml-security":0.0842771509}}
{"text":"Then we study the termination problem and define a higher-order recursive path ordering (HORPO) for this new formalism.","meta":{"url":"http://arxiv.org/abs/2307.13519v1"},"cats":{"new-dataset":0.1385608188,"dev-research":0.243525185,"prompt-eng":0.427633005,"data-quality":0.1381014747,"ml-security":0.0856527712}}
{"text":"Dragonfly is scheduled to begin exploring Titan by 2034 using a series of multi-kilometer surface flights.","meta":{"url":"http://arxiv.org/abs/2307.13513v1"},"cats":{"new-dataset":0.2357559075,"dev-research":0.2277789662,"prompt-eng":0.3599912252,"data-quality":0.0764788486,"ml-security":0.0770831013}}
{"text":"This paper outlines the preliminary design of the navigation filter for the Dragonfly Mobility subsystem.","meta":{"url":"http://arxiv.org/abs/2307.13513v1"},"cats":{"new-dataset":0.0779295201,"dev-research":0.2260542354,"prompt-eng":0.4449644081,"data-quality":0.0694145838,"ml-security":0.0503793207}}
{"text":"The software architecture and filter formulation for lidar, visual odometry, pressure sensors, and redundant IMUs are described in detail.","meta":{"url":"http://arxiv.org/abs/2307.13513v1"},"cats":{"new-dataset":0.0867425002,"dev-research":0.2618286047,"prompt-eng":0.3599214294,"data-quality":0.0891331151,"ml-security":0.0583693451}}
{"text":"Special discussion is given to developments to achieve multi-kilometer surface flights, including optimizing sequential image baselines, modeling correlating image processing errors, and an efficient approximation to the Simultaneous Localization and Mapping (SLAM) problem.","meta":{"url":"http://arxiv.org/abs/2307.13513v1"},"cats":{"new-dataset":0.2208989333,"dev-research":0.2217645582,"prompt-eng":0.3603974091,"data-quality":0.0844094587,"ml-security":0.0361675776}}
{"text":"Vision-based Bird's Eye View (BEV) representation is an emerging perception formulation for autonomous driving.","meta":{"url":"http://arxiv.org/abs/2307.13510v1"},"cats":{"new-dataset":0.0743882558,"dev-research":0.2397855031,"prompt-eng":0.4046700615,"data-quality":0.1028797575,"ml-security":0.0740314983}}
{"text":"The core challenge is to construct BEV space with multi-camera features, which is a one-to-many ill-posed problem.","meta":{"url":"http://arxiv.org/abs/2307.13510v1"},"cats":{"new-dataset":0.3794517848,"dev-research":0.1851527797,"prompt-eng":0.3606148643,"data-quality":0.1228186096,"ml-security":0.0865921674}}
{"text":"Diving into all previous BEV representation generation methods, we found that most of them fall into two types: modeling depths in image views or modeling heights in the BEV space, mostly in an implicit way.","meta":{"url":"http://arxiv.org/abs/2307.13510v1"},"cats":{"new-dataset":0.1591174632,"dev-research":0.2402287733,"prompt-eng":0.3907532785,"data-quality":0.1078441696,"ml-security":0.0618608218}}
{"text":"In this work, we propose to explicitly model heights in the BEV space, which needs no extra data like LiDAR and can fit arbitrary camera rigs and types compared to modeling depths.","meta":{"url":"http://arxiv.org/abs/2307.13510v1"},"cats":{"new-dataset":0.401930688,"dev-research":0.1623632905,"prompt-eng":0.3655606526,"data-quality":0.0757476995,"ml-security":0.092220276}}
{"text":"Theoretically, we give proof of the equivalence between height-based methods and depth-based methods.","meta":{"url":"http://arxiv.org/abs/2307.13510v1"},"cats":{"new-dataset":0.0734710869,"dev-research":0.2120849426,"prompt-eng":0.3519357994,"data-quality":0.1182653852,"ml-security":0.0710126085}}
{"text":"Considering the equivalence and some advantages of modeling heights, we propose HeightFormer, which models heights and uncertainties in a self-recursive way.","meta":{"url":"http://arxiv.org/abs/2307.13510v1"},"cats":{"new-dataset":0.1291520536,"dev-research":0.218402177,"prompt-eng":0.449833934,"data-quality":0.097674842,"ml-security":0.0775833712}}
{"text":"Without any extra data, the proposed HeightFormer could estimate heights in BEV accurately.","meta":{"url":"http://arxiv.org/abs/2307.13510v1"},"cats":{"new-dataset":0.0736096209,"dev-research":0.1827308257,"prompt-eng":0.421541787,"data-quality":0.0985202053,"ml-security":0.0524768742}}
{"text":"Benchmark results show that the performance of HeightFormer achieves SOTA compared with those camera-only methods.","meta":{"url":"http://arxiv.org/abs/2307.13510v1"},"cats":{"new-dataset":0.072161858,"dev-research":0.2058550595,"prompt-eng":0.408962252,"data-quality":0.061322173,"ml-security":0.0327129011}}
{"text":"In this paper, we shall give an explicit proof that constacyclic codes over finite commutative rings can be realized as ideals in some twisted group rings.","meta":{"url":"http://arxiv.org/abs/2307.13507v1"},"cats":{"new-dataset":0.1486706536,"dev-research":0.2451187234,"prompt-eng":0.335828422,"data-quality":0.1372969317,"ml-security":0.1818098965}}
{"text":"Also, we shall study isometries between those codes and, finally, we shall study k-Galois LCD constacyclic codes over finite fields.","meta":{"url":"http://arxiv.org/abs/2307.13507v1"},"cats":{"new-dataset":0.5151822604,"dev-research":0.1888456109,"prompt-eng":0.3952088484,"data-quality":0.1371354634,"ml-security":0.0709077738}}
{"text":"In particular, we shall characterize constacyclic LCD codes with respect to Euclidean inner product in terms of its idempotent generators and the classical involution using the twisted group algebras structures and find some good LCD codes.","meta":{"url":"http://arxiv.org/abs/2307.13507v1"},"cats":{"new-dataset":0.4919189019,"dev-research":0.2184110511,"prompt-eng":0.3645913223,"data-quality":0.1338549866,"ml-security":0.1132197514}}
{"text":"Weighted automata (WA) are an extension of finite automata that defines functions from words to values in a given semi-ring.","meta":{"url":"http://arxiv.org/abs/2307.13505v1"},"cats":{"new-dataset":0.0863802476,"dev-research":0.2006347087,"prompt-eng":0.4245805578,"data-quality":0.1493562157,"ml-security":0.095097976}}
{"text":"An alternative model that is deterministic, called Cost Register Automata (CRA), was introduced by Alur et al.","meta":{"url":"http://arxiv.org/abs/2307.13505v1"},"cats":{"new-dataset":0.1041204225,"dev-research":0.2908560816,"prompt-eng":0.4625911479,"data-quality":0.1368290813,"ml-security":0.1105204468}}
{"text":"It enriches deterministic finite automata with a finite number of registers, which store values, are updated at each transition using the operations of the semi-ring, and are combined to produce the output.","meta":{"url":"http://arxiv.org/abs/2307.13505v1"},"cats":{"new-dataset":0.1974260977,"dev-research":0.263609125,"prompt-eng":0.4175215822,"data-quality":0.0946866241,"ml-security":0.0950286578}}
{"text":"The expressiveness of a CRA depends on the number of its registers and the type of register updates allowed for each of its transitions.","meta":{"url":"http://arxiv.org/abs/2307.13505v1"},"cats":{"new-dataset":0.0461865704,"dev-research":0.2515581254,"prompt-eng":0.3784429072,"data-quality":0.1147399472,"ml-security":0.0866292748}}
{"text":"In particular, the class of functions computable by a CRA with register updates defined by linear (or affine) maps correspond exactly with rational functions (functions computable by a WA).","meta":{"url":"http://arxiv.org/abs/2307.13505v1"},"cats":{"new-dataset":0.1233798782,"dev-research":0.2753452268,"prompt-eng":0.3318488491,"data-quality":0.1210064626,"ml-security":0.1463989998}}
{"text":"A natural problem for CRA is the register minimization problem: given a function defined by a CRA, what is the minimal number of registers needed to realize this function?   ","meta":{"url":"http://arxiv.org/abs/2307.13505v1"},"cats":{"new-dataset":0.0960321141,"dev-research":0.252180807,"prompt-eng":0.3358346896,"data-quality":0.1356565797,"ml-security":0.0870167655}}
{"text":"In this paper, we solve the register minimization problem for CRA over a field with linear (or affine) register updates, using an algebraic invariant of a WA introduced recently by Bell and Smertnig, the so-called the linear hull of the automaton.","meta":{"url":"http://arxiv.org/abs/2307.13505v1"},"cats":{"new-dataset":0.1601436149,"dev-research":0.2633610352,"prompt-eng":0.4205265008,"data-quality":0.1753951168,"ml-security":0.0959277506}}
{"text":"This invariant being computable, we are able to explicitly compute a CRA with linear (or affine) updates, using the minimal number of registers.   ","meta":{"url":"http://arxiv.org/abs/2307.13505v1"},"cats":{"new-dataset":0.1915595067,"dev-research":0.195977509,"prompt-eng":0.3976027956,"data-quality":0.1278026718,"ml-security":0.1045107373}}
{"text":"Using these techniques, we are also able to solve the more general CRA minimisation problem: given a CRA and integers $k,d$, is there an equivalent linear (resp.~affine) CRA using at most $k$ states and $d$ registers?","meta":{"url":"http://arxiv.org/abs/2307.13505v1"},"cats":{"new-dataset":0.1545687174,"dev-research":0.1475789215,"prompt-eng":0.3710805295,"data-quality":0.1165164345,"ml-security":0.0602015554}}
{"text":"Prevalent in many real-world settings such as healthcare, irregular time series are challenging to formulate predictions from.","meta":{"url":"http://arxiv.org/abs/2307.13503v1"},"cats":{"new-dataset":0.0471625474,"dev-research":0.2134296886,"prompt-eng":0.3440670147,"data-quality":0.1711929018,"ml-security":0.241958047}}
{"text":"It is difficult to infer the value of a feature at any given time when observations are sporadic, as it could take on a range of values depending on when it was last observed.","meta":{"url":"http://arxiv.org/abs/2307.13503v1"},"cats":{"new-dataset":0.0374946662,"dev-research":0.2093577616,"prompt-eng":0.4408966027,"data-quality":0.2500754905,"ml-security":0.122004146}}
{"text":"To characterize this uncertainty we present EDICT, a strategy that learns an evidential distribution over irregular time series in continuous time.","meta":{"url":"http://arxiv.org/abs/2307.13503v1"},"cats":{"new-dataset":0.1428416922,"dev-research":0.166572955,"prompt-eng":0.4079558435,"data-quality":0.2829968724,"ml-security":0.2270208515}}
{"text":"This distribution enables well-calibrated and flexible inference of partially observed features at any time of interest, while expanding uncertainty temporally for sparse, irregular observations.","meta":{"url":"http://arxiv.org/abs/2307.13503v1"},"cats":{"new-dataset":0.3323967641,"dev-research":0.2029650744,"prompt-eng":0.3842998957,"data-quality":0.2035099012,"ml-security":0.1141398217}}
{"text":"We demonstrate that EDICT attains competitive performance on challenging time series classification tasks and enabling uncertainty-guided inference when encountering noisy data.","meta":{"url":"http://arxiv.org/abs/2307.13503v1"},"cats":{"new-dataset":0.1539811353,"dev-research":0.2187140151,"prompt-eng":0.3682219001,"data-quality":0.4024124147,"ml-security":0.2072582394}}
{"text":"Current anti-money laundering (AML) systems, predominantly rule-based, exhibit notable shortcomings in efficiently and precisely detecting instances of money laundering.","meta":{"url":"http://arxiv.org/abs/2307.13499v1"},"cats":{"new-dataset":0.0687412311,"dev-research":0.2403917949,"prompt-eng":0.369320304,"data-quality":0.275346758,"ml-security":0.3245835406}}
{"text":"As a result, there has been a recent surge toward exploring alternative approaches, particularly those utilizing machine learning.","meta":{"url":"http://arxiv.org/abs/2307.13499v1"},"cats":{"new-dataset":0.0243643197,"dev-research":0.2635775645,"prompt-eng":0.3907194688,"data-quality":0.1763837319,"ml-security":0.1812647497}}
{"text":"Since criminals often collaborate in their money laundering endeavors, accounting for diverse types of customer relations and links becomes crucial.","meta":{"url":"http://arxiv.org/abs/2307.13499v1"},"cats":{"new-dataset":0.0412058939,"dev-research":0.2524984832,"prompt-eng":0.3214105518,"data-quality":0.1867019873,"ml-security":0.2723137026}}
{"text":"In line with this, the present paper introduces a graph neural network (GNN) approach to identify money laundering activities within a large heterogeneous network constructed from real-world bank transactions and business role data belonging to DNB, Norway's largest bank.","meta":{"url":"http://arxiv.org/abs/2307.13499v1"},"cats":{"new-dataset":0.2798157781,"dev-research":0.1966635088,"prompt-eng":0.2775617698,"data-quality":0.2275924394,"ml-security":0.3057759226}}
{"text":"Specifically, we extend the homogeneous GNN method known as the Message Passing Neural Network (MPNN) to operate effectively on a heterogeneous graph.","meta":{"url":"http://arxiv.org/abs/2307.13499v1"},"cats":{"new-dataset":0.1171863984,"dev-research":0.2132115525,"prompt-eng":0.3087956151,"data-quality":0.206970115,"ml-security":0.1194672872}}
{"text":"As part of this procedure, we propose a novel method for aggregating messages across different edges of the graph.","meta":{"url":"http://arxiv.org/abs/2307.13499v1"},"cats":{"new-dataset":0.1381270552,"dev-research":0.2183475286,"prompt-eng":0.3789782428,"data-quality":0.2841290586,"ml-security":0.0768923518}}
{"text":"Our findings highlight the importance of using an appropriate GNN architecture when combining information in heterogeneous graphs.","meta":{"url":"http://arxiv.org/abs/2307.13499v1"},"cats":{"new-dataset":0.0897377667,"dev-research":0.2478012055,"prompt-eng":0.3150805897,"data-quality":0.2102581685,"ml-security":0.0955359843}}
{"text":"The performance results of our model demonstrate great potential in enhancing the quality of electronic surveillance systems employed by banks to detect instances of money laundering.","meta":{"url":"http://arxiv.org/abs/2307.13499v1"},"cats":{"new-dataset":0.0724545548,"dev-research":0.2095963958,"prompt-eng":0.4298640766,"data-quality":0.2446654831,"ml-security":0.3206604563}}
{"text":"To the best of our knowledge, this is the first published work applying GNN on a large real-world heterogeneous network for anti-money laundering purposes.","meta":{"url":"http://arxiv.org/abs/2307.13499v1"},"cats":{"new-dataset":0.4032927861,"dev-research":0.172305313,"prompt-eng":0.3024442295,"data-quality":0.1879988961,"ml-security":0.309339767}}
{"text":"The Zero-Shot Learning (ZSL) task pertains to the identification of entities or relations in texts that were not seen during training.","meta":{"url":"http://arxiv.org/abs/2307.13497v1"},"cats":{"new-dataset":0.098114416,"dev-research":0.1939154801,"prompt-eng":0.3886732105,"data-quality":0.283194882,"ml-security":0.1252798952}}
{"text":"ZSL has emerged as a critical research area due to the scarcity of labeled data in specific domains, and its applications have grown significantly in recent years.","meta":{"url":"http://arxiv.org/abs/2307.13497v1"},"cats":{"new-dataset":0.2360862769,"dev-research":0.2317605712,"prompt-eng":0.4426677065,"data-quality":0.2803502383,"ml-security":0.0754282679}}
{"text":"With the advent of large pretrained language models, several novel methods have been proposed, resulting in substantial improvements in ZSL performance.","meta":{"url":"http://arxiv.org/abs/2307.13497v1"},"cats":{"new-dataset":0.1320575765,"dev-research":0.2416177393,"prompt-eng":0.445521788,"data-quality":0.1742346365,"ml-security":0.0497351527}}
{"text":"There is a growing demand, both in the research community and industry, for a comprehensive ZSL framework that facilitates the development and accessibility of the latest methods and pretrained models.","meta":{"url":"http://arxiv.org/abs/2307.13497v1"},"cats":{"new-dataset":0.1583742762,"dev-research":0.2584633446,"prompt-eng":0.4230634037,"data-quality":0.0619055803,"ml-security":0.0319205942}}
{"text":"In this study, we propose a novel ZSL framework called Zshot that aims to address the aforementioned challenges.","meta":{"url":"http://arxiv.org/abs/2307.13497v1"},"cats":{"new-dataset":0.2489961493,"dev-research":0.2912609518,"prompt-eng":0.4394959582,"data-quality":0.0963297128,"ml-security":0.0603892139}}
{"text":"Our primary objective is to provide a platform that allows researchers to compare different state-of-the-art ZSL methods with standard benchmark datasets.","meta":{"url":"http://arxiv.org/abs/2307.13497v1"},"cats":{"new-dataset":0.2815319983,"dev-research":0.2134825611,"prompt-eng":0.3965778737,"data-quality":0.1030289526,"ml-security":0.0381377178}}
{"text":"Additionally, we have designed our framework to support the industry with readily available APIs for production under the standard SpaCy NLP pipeline.","meta":{"url":"http://arxiv.org/abs/2307.13497v1"},"cats":{"new-dataset":0.2749877852,"dev-research":0.3019688322,"prompt-eng":0.4058140512,"data-quality":0.1907111676,"ml-security":0.0785022812}}
{"text":"Our API is extendible and evaluable, moreover, we include numerous enhancements such as boosting the accuracy with pipeline ensembling and visualization utilities available as a SpaCy extension.","meta":{"url":"http://arxiv.org/abs/2307.13497v1"},"cats":{"new-dataset":0.3377615204,"dev-research":0.2735342457,"prompt-eng":0.4079724646,"data-quality":0.2276969935,"ml-security":0.0870480837}}
{"text":"Learned cardinality estimation methods have achieved high precision compared to traditional methods.","meta":{"url":"http://arxiv.org/abs/2307.13494v2"},"cats":{"new-dataset":0.0863466062,"dev-research":0.2035090529,"prompt-eng":0.3841338731,"data-quality":0.2900277307,"ml-security":0.1094309463}}
{"text":"Among learned methods, query-driven approaches face the data and workload drift problem for a long time.","meta":{"url":"http://arxiv.org/abs/2307.13494v2"},"cats":{"new-dataset":0.0771297051,"dev-research":0.343226028,"prompt-eng":0.3543472936,"data-quality":0.2096132042,"ml-security":0.230974263}}
{"text":"Although both query-driven and hybrid methods are proposed to avoid this problem, even the state-of-art of them suffer from high training and estimation costs, limited scalability, instability, and long-tailed distribution problem on high cardinality and high dimensional tables, which seriously affects the practical application of learned cardinality estimators.","meta":{"url":"http://arxiv.org/abs/2307.13494v2"},"cats":{"new-dataset":0.1729809056,"dev-research":0.1634378196,"prompt-eng":0.3794878836,"data-quality":0.2278244737,"ml-security":0.1502480614}}
{"text":"In this paper, we prove that most of these problems are directly caused by the widely used progressive sampling.","meta":{"url":"http://arxiv.org/abs/2307.13494v2"},"cats":{"new-dataset":0.1672366625,"dev-research":0.1707466385,"prompt-eng":0.3791376236,"data-quality":0.2853395157,"ml-security":0.1280172351}}
{"text":"We solve this problem by introducing predicates into the autoregressive model and propose Duet, a stable, efficient, and scalable hybrid method to estimate cardinality directly without sampling or any non-differentiable process, which can not only reduces the inference complexity from $O(n)$ to $O(1)$ compared to Naru and UAE but also achieve higher accuracy on high cardinality and high dimensional tables.","meta":{"url":"http://arxiv.org/abs/2307.13494v2"},"cats":{"new-dataset":0.1733110825,"dev-research":0.1804765137,"prompt-eng":0.3862129997,"data-quality":0.1471075594,"ml-security":0.0685185151}}
{"text":"Experimental results show that Duet can achieve all the design goals above and be much more practical and even has a lower inference cost on CPU than that of most learned methods on GPU.","meta":{"url":"http://arxiv.org/abs/2307.13494v2"},"cats":{"new-dataset":0.0470108786,"dev-research":0.2737779977,"prompt-eng":0.3899731772,"data-quality":0.0898473076,"ml-security":0.0903016143}}
{"text":"Deep learning has made significant advancements in supervised learning.","meta":{"url":"http://arxiv.org/abs/2307.13492v1"},"cats":{"new-dataset":0.0698079834,"dev-research":0.2373186779,"prompt-eng":0.333026779,"data-quality":0.2237333099,"ml-security":0.1663982493}}
{"text":"However, models trained in this setting often face challenges due to domain shift between training and test sets, resulting in a significant drop in performance during testing.","meta":{"url":"http://arxiv.org/abs/2307.13492v1"},"cats":{"new-dataset":0.0259121848,"dev-research":0.3426456914,"prompt-eng":0.4161020688,"data-quality":0.3066001554,"ml-security":0.1980665919}}
{"text":"To address this issue, several domain generalization methods have been developed to learn robust and domain-invariant features from multiple training domains that can generalize well to unseen test domains.","meta":{"url":"http://arxiv.org/abs/2307.13492v1"},"cats":{"new-dataset":0.1414071689,"dev-research":0.277306719,"prompt-eng":0.440202387,"data-quality":0.4088453885,"ml-security":0.2988721985}}
{"text":"Data augmentation plays a crucial role in achieving this goal by enhancing the diversity of the training data.","meta":{"url":"http://arxiv.org/abs/2307.13492v1"},"cats":{"new-dataset":0.056328234,"dev-research":0.2645543323,"prompt-eng":0.3698907472,"data-quality":0.2519693435,"ml-security":0.1479927225}}
{"text":"In this paper, inspired by the observation that normalizing an image with different statistics generated by different batches with various domains can perturb its feature, we propose a simple yet effective method called NormAUG (Normalization-guided Augmentation).","meta":{"url":"http://arxiv.org/abs/2307.13492v1"},"cats":{"new-dataset":0.0938975706,"dev-research":0.2181657041,"prompt-eng":0.4031579485,"data-quality":0.2963429503,"ml-security":0.1085375729}}
{"text":"Our method includes two paths: the main path and the auxiliary (augmented) path.","meta":{"url":"http://arxiv.org/abs/2307.13492v1"},"cats":{"new-dataset":0.0713217957,"dev-research":0.2358325013,"prompt-eng":0.4409957184,"data-quality":0.1270165177,"ml-security":0.0411420855}}
{"text":"During training, the auxiliary path includes multiple sub-paths, each corresponding to batch normalization for a single domain or a random combination of multiple domains.","meta":{"url":"http://arxiv.org/abs/2307.13492v1"},"cats":{"new-dataset":0.0901972485,"dev-research":0.2331054518,"prompt-eng":0.412271766,"data-quality":0.1707978975,"ml-security":0.0906127756}}
{"text":"This introduces diverse information at the feature level and improves the generalization of the main path.","meta":{"url":"http://arxiv.org/abs/2307.13492v1"},"cats":{"new-dataset":0.0930413001,"dev-research":0.3178416263,"prompt-eng":0.4086190263,"data-quality":0.1571372229,"ml-security":0.0850770747}}
{"text":"Moreover, our NormAUG method effectively reduces the existing upper boundary for generalization based on theoretical perspectives.","meta":{"url":"http://arxiv.org/abs/2307.13492v1"},"cats":{"new-dataset":0.0102546896,"dev-research":0.2008801895,"prompt-eng":0.3841653813,"data-quality":0.2002063285,"ml-security":0.1271059266}}
{"text":"During the test stage, we leverage an ensemble strategy to combine the predictions from the auxiliary path of our model, further boosting performance.","meta":{"url":"http://arxiv.org/abs/2307.13492v1"},"cats":{"new-dataset":0.0719753229,"dev-research":0.2629902184,"prompt-eng":0.4798565217,"data-quality":0.2063546126,"ml-security":0.1461304354}}
{"text":"Extensive experiments are conducted on multiple benchmark datasets to validate the effectiveness of our proposed method.","meta":{"url":"http://arxiv.org/abs/2307.13492v1"},"cats":{"new-dataset":0.11057341,"dev-research":0.2021758547,"prompt-eng":0.423357145,"data-quality":0.2743147089,"ml-security":0.0648731615}}
{"text":"We propose Cos R-CNN, a simple exemplar-based R-CNN formulation that is designed for online few-shot object detection.","meta":{"url":"http://arxiv.org/abs/2307.13485v1"},"cats":{"new-dataset":0.1908894851,"dev-research":0.1842125607,"prompt-eng":0.3262504794,"data-quality":0.1775867736,"ml-security":0.1579003335}}
{"text":"That is, it is able to localise and classify novel object categories in images with few examples without fine-tuning.","meta":{"url":"http://arxiv.org/abs/2307.13485v1"},"cats":{"new-dataset":0.0659934555,"dev-research":0.2212703284,"prompt-eng":0.3912044512,"data-quality":0.2845485422,"ml-security":0.0825057553}}
{"text":"Cos R-CNN frames detection as a learning-to-compare task: unseen classes are represented as exemplar images, and objects are detected based on their similarity to these exemplars.","meta":{"url":"http://arxiv.org/abs/2307.13485v1"},"cats":{"new-dataset":0.1900640091,"dev-research":0.2425332601,"prompt-eng":0.3502550088,"data-quality":0.3174489124,"ml-security":0.1579770381}}
{"text":"The cosine-based classification head allows for dynamic adaptation of classification parameters to the exemplar embedding, and encourages the clustering of similar classes in embedding space without the need for manual tuning of distance-metric hyperparameters.","meta":{"url":"http://arxiv.org/abs/2307.13485v1"},"cats":{"new-dataset":0.0704501483,"dev-research":0.2499093381,"prompt-eng":0.3961696344,"data-quality":0.2594766501,"ml-security":0.1383355585}}
{"text":"This simple formulation achieves best results on the recently proposed 5-way ImageNet few-shot detection benchmark, beating the online 1/5/10-shot scenarios by more than 8/3/1%, as well as performing up to 20% better in online 20-way few-shot VOC across all shots on novel classes.","meta":{"url":"http://arxiv.org/abs/2307.13485v1"},"cats":{"new-dataset":0.1350923688,"dev-research":0.1994434661,"prompt-eng":0.333993517,"data-quality":0.2801973624,"ml-security":0.1718142799}}
{"text":"This work is concerned with the kernel-based approximation of a complex-valued function from data, where the frequency response function of a partial differential equation in the frequency domain is of particular interest.","meta":{"url":"http://arxiv.org/abs/2307.13484v1"},"cats":{"new-dataset":0.1202474651,"dev-research":0.1572026029,"prompt-eng":0.3597993106,"data-quality":0.1534102672,"ml-security":0.1019407892}}
{"text":"In this setting, kernel methods are employed more and more frequently, however, standard kernels do not perform well.","meta":{"url":"http://arxiv.org/abs/2307.13484v1"},"cats":{"new-dataset":0.0138536576,"dev-research":0.2849020052,"prompt-eng":0.3505500282,"data-quality":0.2341462866,"ml-security":0.1087241766}}
{"text":"Moreover, the role and mathematical implications of the underlying pair of kernels, which arises naturally in the complex-valued case, remain to be addressed.","meta":{"url":"http://arxiv.org/abs/2307.13484v1"},"cats":{"new-dataset":0.0199714898,"dev-research":0.1957507599,"prompt-eng":0.3077476634,"data-quality":0.1659616255,"ml-security":0.2108854896}}
{"text":"We introduce new reproducing kernel Hilbert spaces of complex-valued functions, and formulate the problem of complex-valued interpolation with a kernel pair as minimum norm interpolation in these spaces.","meta":{"url":"http://arxiv.org/abs/2307.13484v1"},"cats":{"new-dataset":0.1478314175,"dev-research":0.2134918423,"prompt-eng":0.3566355642,"data-quality":0.2159818141,"ml-security":0.1185931501}}
{"text":"Moreover, we combine the interpolant with a low-order rational function, where the order is adaptively selected based on a new model selection criterion.","meta":{"url":"http://arxiv.org/abs/2307.13484v1"},"cats":{"new-dataset":0.0247569609,"dev-research":0.1326971593,"prompt-eng":0.3781271085,"data-quality":0.0907070513,"ml-security":0.0683781992}}
{"text":"Numerical results on examples from different fields, including electromagnetics and acoustic examples, illustrate the performance of the method, also in comparison to available rational approximation methods.","meta":{"url":"http://arxiv.org/abs/2307.13484v1"},"cats":{"new-dataset":0.03785533,"dev-research":0.1516853738,"prompt-eng":0.3345678166,"data-quality":0.0887991158,"ml-security":0.0494955605}}
{"text":"Secure aggregation usually aims at securely computing the sum of the inputs from $K$ users at a server.","meta":{"url":"http://arxiv.org/abs/2307.13474v1"},"cats":{"new-dataset":0.0428190652,"dev-research":0.2177828248,"prompt-eng":0.3584082146,"data-quality":0.1179275055,"ml-security":0.3906274486}}
{"text":"Noticing that the sum might inevitably reveal information about the inputs (when the inputs are non-uniform) and typically the users (not the server) desire the sum (in applications such as federated learning), we consider a variant of secure aggregation where the server is oblivious, i.e., the server only serves as a communication facilitator/helper to enable the users to securely compute the sum and learns nothing in the process.","meta":{"url":"http://arxiv.org/abs/2307.13474v1"},"cats":{"new-dataset":0.0484124717,"dev-research":0.212417168,"prompt-eng":0.3773289372,"data-quality":0.1753423596,"ml-security":0.5099430408}}
{"text":"Our communication protocol involves one round of messages from the users to the server and one round of messages from the server to each user such that in the end each user only learns the sum of all $K$ inputs and the server learns no information about the inputs.","meta":{"url":"http://arxiv.org/abs/2307.13474v1"},"cats":{"new-dataset":0.2924674081,"dev-research":0.2251665444,"prompt-eng":0.3966019492,"data-quality":0.1748798204,"ml-security":0.2748193229}}
{"text":"For this secure aggregation with an oblivious server problem, we show that to compute $1$ bit of the sum securely, each user needs to send at least $1$ bit to the server, the server needs to send at least $1$ bit to each user, each user needs to hold a key of at least $2$ bits, and all users need to collectively hold at least $K$ key bits.","meta":{"url":"http://arxiv.org/abs/2307.13474v1"},"cats":{"new-dataset":0.1908172632,"dev-research":0.1661277342,"prompt-eng":0.3507015841,"data-quality":0.1306679518,"ml-security":0.3635055582}}
{"text":"In addition, when user dropouts are allowed, the optimal performance remains the same, except that the minimum size of the key held by each user increases to $K$ bits, per sum bit.","meta":{"url":"http://arxiv.org/abs/2307.13474v1"},"cats":{"new-dataset":0.0061634283,"dev-research":0.2459693081,"prompt-eng":0.3396958404,"data-quality":0.1088070211,"ml-security":0.1097905401}}
{"text":"This paper proposes a new combinatorial auction framework for local energy flexibility markets, which addresses the issue of prosumers' inability to bundle multiple flexibility time intervals.","meta":{"url":"http://arxiv.org/abs/2307.13470v1"},"cats":{"new-dataset":0.0549360593,"dev-research":0.2163259506,"prompt-eng":0.3688333374,"data-quality":0.1040945173,"ml-security":0.0753423638}}
{"text":"To solve the underlying NP-complete winner determination problems, we present a simple yet powerful heterogeneous tri-partite graph representation and design graph neural network-based models.","meta":{"url":"http://arxiv.org/abs/2307.13470v1"},"cats":{"new-dataset":0.1752317028,"dev-research":0.2278872404,"prompt-eng":0.3033904281,"data-quality":0.2018727178,"ml-security":0.1380089196}}
{"text":"Our models achieve an average optimal value deviation of less than 5\\% from an off-the-shelf optimization tool and show linear inference time complexity compared to the exponential complexity of the commercial solver.","meta":{"url":"http://arxiv.org/abs/2307.13470v1"},"cats":{"new-dataset":0.0479921521,"dev-research":0.2504796977,"prompt-eng":0.4142863747,"data-quality":0.1485405321,"ml-security":0.1006366094}}
{"text":"Contributions and results demonstrate the potential of using machine learning to efficiently allocate energy flexibility resources in local markets and solving optimization problems in general.","meta":{"url":"http://arxiv.org/abs/2307.13470v1"},"cats":{"new-dataset":0.0377315212,"dev-research":0.2629978145,"prompt-eng":0.3473760256,"data-quality":0.144344477,"ml-security":0.1777640354}}
{"text":"Bundle recommendation aims to provide a bundle of items to satisfy the user preference on e-commerce platform.","meta":{"url":"http://arxiv.org/abs/2307.13468v1"},"cats":{"new-dataset":0.0321177765,"dev-research":0.2584551945,"prompt-eng":0.4404607624,"data-quality":0.0943436059,"ml-security":0.0595186866}}
{"text":"Existing successful solutions are based on the contrastive graph learning paradigm where graph neural networks (GNNs) are employed to learn representations from user-level and bundle-level graph views with a contrastive learning module to enhance the cooperative association between different views.","meta":{"url":"http://arxiv.org/abs/2307.13468v1"},"cats":{"new-dataset":0.1300156674,"dev-research":0.2436712969,"prompt-eng":0.3096856942,"data-quality":0.211363673,"ml-security":0.1007834866}}
{"text":"Nevertheless, they ignore the uncertainty issue which has a significant impact in real bundle recommendation scenarios due to the lack of discriminative information caused by highly sparsity or diversity.","meta":{"url":"http://arxiv.org/abs/2307.13468v1"},"cats":{"new-dataset":0.0327012187,"dev-research":0.2275430813,"prompt-eng":0.3522789468,"data-quality":0.3567132647,"ml-security":0.140700418}}
{"text":"We further suggest that their instancewise contrastive learning fails to distinguish the semantically similar negatives (i.e., sampling bias issue), resulting in performance degradation.","meta":{"url":"http://arxiv.org/abs/2307.13468v1"},"cats":{"new-dataset":0.0452139781,"dev-research":0.2341526236,"prompt-eng":0.342917157,"data-quality":0.4177995059,"ml-security":0.1653025306}}
{"text":"In this paper, we propose a novel Gaussian Graph with Prototypical Contrastive Learning (GPCL) framework to overcome these challenges.","meta":{"url":"http://arxiv.org/abs/2307.13468v1"},"cats":{"new-dataset":0.2878817713,"dev-research":0.2083164201,"prompt-eng":0.3216831297,"data-quality":0.1619682157,"ml-security":0.1026180401}}
{"text":"In particular, GPCL embeds each user/bundle/item as a Gaussian distribution rather than a fixed vector.","meta":{"url":"http://arxiv.org/abs/2307.13468v1"},"cats":{"new-dataset":0.031050696,"dev-research":0.1914557834,"prompt-eng":0.3683330596,"data-quality":0.1029730721,"ml-security":0.1013768023}}
{"text":"We further design a prototypical contrastive learning module to capture the contextual information and mitigate the sampling bias issue.","meta":{"url":"http://arxiv.org/abs/2307.13468v1"},"cats":{"new-dataset":0.1307866668,"dev-research":0.2793743846,"prompt-eng":0.375018259,"data-quality":0.2935514178,"ml-security":0.1232804447}}
{"text":"Extensive experiments demonstrate that benefiting from the proposed components, we achieve new state-of-the-art performance compared to previous methods on several public datasets.","meta":{"url":"http://arxiv.org/abs/2307.13468v1"},"cats":{"new-dataset":0.4041850515,"dev-research":0.1708705049,"prompt-eng":0.4108989822,"data-quality":0.2365550007,"ml-security":0.0632932793}}
{"text":"Moreover, GPCL has been deployed on real-world e-commerce platform and achieved substantial improvements.","meta":{"url":"http://arxiv.org/abs/2307.13468v1"},"cats":{"new-dataset":0.127317592,"dev-research":0.2599268835,"prompt-eng":0.3846261126,"data-quality":0.0961707666,"ml-security":0.0728845553}}
{"text":"Holographic MIMO refers to an array (possibly large) with a massive number of antennas that are individually controlled and densely deployed.","meta":{"url":"http://arxiv.org/abs/2307.13467v1"},"cats":{"new-dataset":0.09337099,"dev-research":0.1979591915,"prompt-eng":0.3532853917,"data-quality":0.0609598767,"ml-security":0.0576996864}}
{"text":"The aim of this paper is to provide further insights into the advantages (if any) of having closely spaced antennas in the uplink and downlink of a multi-user Holographic MIMO system.","meta":{"url":"http://arxiv.org/abs/2307.13467v1"},"cats":{"new-dataset":0.015052564,"dev-research":0.2175222331,"prompt-eng":0.3964663418,"data-quality":0.0712832802,"ml-security":0.0532019712}}
{"text":"To this end, we make use of the multiport communication theory, which ensures physically consistent uplink and downlink models.","meta":{"url":"http://arxiv.org/abs/2307.13467v1"},"cats":{"new-dataset":0.0353668107,"dev-research":0.2202589603,"prompt-eng":0.3910830448,"data-quality":0.0924648201,"ml-security":0.0794582322}}
{"text":"We first consider a simple uplink scenario with two side-by-side half-wavelength dipoles, two users and single path line-of-sight propagation, and show both analytically and numerically that the channel gain and average spectral efficiency depend strongly on the directions from which the signals are received and on the array matching network used.","meta":{"url":"http://arxiv.org/abs/2307.13467v1"},"cats":{"new-dataset":0.0257516971,"dev-research":0.1941811576,"prompt-eng":0.3828480087,"data-quality":0.1127914625,"ml-security":0.077514178}}
{"text":"Numerical results are then used to extend the analysis to more practical scenarios with a larger number of dipoles and users.","meta":{"url":"http://arxiv.org/abs/2307.13467v1"},"cats":{"new-dataset":0.0592166536,"dev-research":0.2638261304,"prompt-eng":0.3950153627,"data-quality":0.0791472202,"ml-security":0.0740283037}}
{"text":"The case in which the antennas are densely packed in a space-constrained factor form is also considered.","meta":{"url":"http://arxiv.org/abs/2307.13467v1"},"cats":{"new-dataset":0.0513143709,"dev-research":0.1505581803,"prompt-eng":0.3526993707,"data-quality":0.1041435528,"ml-security":0.0628931469}}
{"text":"It turns out that the spectral efficiency increases as the antenna distance reduces thanks to the larger number of antennas that allow to collect more energy, not because of the mutual coupling.","meta":{"url":"http://arxiv.org/abs/2307.13467v1"},"cats":{"new-dataset":0.0037082875,"dev-research":0.244012298,"prompt-eng":0.321894797,"data-quality":0.091960744,"ml-security":0.0425444793}}
{"text":"Crop yield prediction typically involves the utilization of either theory-driven process-based crop growth models, which have proven to be difficult to calibrate for local conditions, or data-driven machine learning methods, which are known to require large datasets.","meta":{"url":"http://arxiv.org/abs/2307.13466v1"},"cats":{"new-dataset":0.0822029998,"dev-research":0.2744309404,"prompt-eng":0.366671219,"data-quality":0.1603148126,"ml-security":0.1452576887}}
{"text":"In this work we investigate potato yield prediction using a hybrid meta-modeling approach.","meta":{"url":"http://arxiv.org/abs/2307.13466v1"},"cats":{"new-dataset":0.0689707289,"dev-research":0.189031997,"prompt-eng":0.4149543859,"data-quality":0.1261860009,"ml-security":0.0800670258}}
{"text":"A crop growth model is employed to generate synthetic data for (pre)training a convolutional neural net, which is then fine-tuned with observational data.","meta":{"url":"http://arxiv.org/abs/2307.13466v1"},"cats":{"new-dataset":0.3891337985,"dev-research":0.1998154612,"prompt-eng":0.3444684486,"data-quality":0.135420297,"ml-security":0.106055166}}
{"text":"When applied in silico, our meta-modeling approach yields better predictions than a baseline comprising a purely data-driven approach.","meta":{"url":"http://arxiv.org/abs/2307.13466v1"},"cats":{"new-dataset":0.080880022,"dev-research":0.2555991935,"prompt-eng":0.4342397491,"data-quality":0.1401769603,"ml-security":0.0804644982}}
{"text":"When tested on real-world data from field trials (n=303) and commercial fields (n=77), the meta-modeling approach yields competitive results with respect to the crop growth model.","meta":{"url":"http://arxiv.org/abs/2307.13466v1"},"cats":{"new-dataset":0.077072116,"dev-research":0.1686829069,"prompt-eng":0.3703309426,"data-quality":0.1015664209,"ml-security":0.0464374517}}
{"text":"In the latter set, however, both models perform worse than a simple linear regression with a hand-picked feature set and dedicated preprocessing designed by domain experts.","meta":{"url":"http://arxiv.org/abs/2307.13466v1"},"cats":{"new-dataset":0.0786475306,"dev-research":0.3156139569,"prompt-eng":0.388119043,"data-quality":0.2307875436,"ml-security":0.1242326683}}
{"text":"Our findings indicate the potential of meta-modeling for accurate crop yield prediction; however, further advancements and validation using extensive real-world datasets is recommended to solidify its practical effectiveness.","meta":{"url":"http://arxiv.org/abs/2307.13466v1"},"cats":{"new-dataset":0.0676736989,"dev-research":0.2064955977,"prompt-eng":0.3918058942,"data-quality":0.1669120162,"ml-security":0.0980467013}}
{"text":"The emergence of artificial emotional intelligence technology is revolutionizing the fields of computers and robotics, allowing for a new level of communication and understanding of human behavior that was once thought impossible.","meta":{"url":"http://arxiv.org/abs/2307.13463v1"},"cats":{"new-dataset":0.0728280292,"dev-research":0.3012653604,"prompt-eng":0.3336247368,"data-quality":0.0953181924,"ml-security":0.1424575483}}
{"text":"While recent advancements in deep learning have transformed the field of computer vision, automated understanding of evoked or expressed emotions in visual media remains in its infancy.","meta":{"url":"http://arxiv.org/abs/2307.13463v1"},"cats":{"new-dataset":0.1370122868,"dev-research":0.2554510996,"prompt-eng":0.3553765718,"data-quality":0.2062700769,"ml-security":0.1436939187}}
{"text":"This foundering stems from the absence of a universally accepted definition of \"emotion\", coupled with the inherently subjective nature of emotions and their intricate nuances.","meta":{"url":"http://arxiv.org/abs/2307.13463v1"},"cats":{"new-dataset":0.0342186503,"dev-research":0.3027626621,"prompt-eng":0.2777137538,"data-quality":0.1720189632,"ml-security":0.0843554346}}
{"text":"In this article, we provide a comprehensive, multidisciplinary overview of the field of emotion analysis in visual media, drawing on insights from psychology, engineering, and the arts.","meta":{"url":"http://arxiv.org/abs/2307.13463v1"},"cats":{"new-dataset":0.2318467114,"dev-research":0.2874622335,"prompt-eng":0.350425015,"data-quality":0.2041959262,"ml-security":0.0728657747}}
{"text":"We begin by exploring the psychological foundations of emotion and the computational principles that underpin the understanding of emotions from images and videos.","meta":{"url":"http://arxiv.org/abs/2307.13463v1"},"cats":{"new-dataset":0.1748172144,"dev-research":0.24019322,"prompt-eng":0.3260114843,"data-quality":0.1631242787,"ml-security":0.1062730782}}
{"text":"We then review the latest research and systems within the field, accentuating the most promising approaches.","meta":{"url":"http://arxiv.org/abs/2307.13463v1"},"cats":{"new-dataset":0.0652643468,"dev-research":0.221865789,"prompt-eng":0.4447535717,"data-quality":0.126250578,"ml-security":0.0451712689}}
{"text":"We also discuss the current technological challenges and limitations of emotion analysis, underscoring the necessity for continued investigation and innovation.","meta":{"url":"http://arxiv.org/abs/2307.13463v1"},"cats":{"new-dataset":0.0997142637,"dev-research":0.2782856644,"prompt-eng":0.3625557399,"data-quality":0.2221937313,"ml-security":0.0946310342}}
{"text":"We contend that this represents a \"Holy Grail\" research problem in computing and delineate pivotal directions for future inquiry.","meta":{"url":"http://arxiv.org/abs/2307.13463v1"},"cats":{"new-dataset":0.1257715816,"dev-research":0.2603552428,"prompt-eng":0.4262274714,"data-quality":0.1066326964,"ml-security":0.1094169741}}
{"text":"Finally, we examine the ethical ramifications of emotion-understanding technologies and contemplate their potential societal impacts.","meta":{"url":"http://arxiv.org/abs/2307.13463v1"},"cats":{"new-dataset":0.1018780971,"dev-research":0.3665568303,"prompt-eng":0.3491941949,"data-quality":0.1737142669,"ml-security":0.2132624848}}
{"text":"Overall, this article endeavors to equip readers with a deeper understanding of the domain of emotion analysis in visual media and to inspire further research and development in this captivating and rapidly evolving field.","meta":{"url":"http://arxiv.org/abs/2307.13463v1"},"cats":{"new-dataset":0.1777196777,"dev-research":0.3020298502,"prompt-eng":0.337313819,"data-quality":0.1938350274,"ml-security":0.0820833527}}
{"text":"The main challenges of 3D pose transfer are: 1) Lack of paired training data with different characters performing the same pose; 2) Disentangling pose and shape information from the target mesh; 3) Difficulty in applying to meshes with different topologies.","meta":{"url":"http://arxiv.org/abs/2307.13459v1"},"cats":{"new-dataset":0.0442798602,"dev-research":0.2732291824,"prompt-eng":0.2802975086,"data-quality":0.0968097806,"ml-security":0.163743827}}
{"text":"We thus propose a novel weakly-supervised keypoint-based framework to overcome these difficulties.","meta":{"url":"http://arxiv.org/abs/2307.13459v1"},"cats":{"new-dataset":0.122522164,"dev-research":0.2296945654,"prompt-eng":0.4402778543,"data-quality":0.379882584,"ml-security":0.0997904015}}
{"text":"Specifically, we use a topology-agnostic keypoint detector with inverse kinematics to compute transformations between the source and target meshes.","meta":{"url":"http://arxiv.org/abs/2307.13459v1"},"cats":{"new-dataset":0.1401408509,"dev-research":0.2122671159,"prompt-eng":0.4106912066,"data-quality":0.1335357566,"ml-security":0.1270966407}}
{"text":"Our method only requires supervision on the keypoints, can be applied to meshes with different topologies and is shape-invariant for the target which allows extraction of pose-only information from the target meshes without transferring shape information.","meta":{"url":"http://arxiv.org/abs/2307.13459v1"},"cats":{"new-dataset":0.095458721,"dev-research":0.2134208093,"prompt-eng":0.3800320709,"data-quality":0.115035405,"ml-security":0.1243001638}}
{"text":"We further design a cycle reconstruction to perform self-supervised pose transfer without the need for ground truth deformed mesh with the same pose and shape as the target and source, respectively.","meta":{"url":"http://arxiv.org/abs/2307.13459v1"},"cats":{"new-dataset":0.2731317818,"dev-research":0.2033161045,"prompt-eng":0.3608819954,"data-quality":0.1482442609,"ml-security":0.1919042976}}
{"text":"We evaluate our approach on benchmark human and animal datasets, where we achieve superior performance compared to the state-of-the-art unsupervised approaches and even comparable performance with the fully supervised approaches.","meta":{"url":"http://arxiv.org/abs/2307.13459v1"},"cats":{"new-dataset":0.7171116826,"dev-research":0.1885825295,"prompt-eng":0.3794282572,"data-quality":0.242107123,"ml-security":0.0934314719}}
{"text":"We test on the more challenging Mixamo dataset to verify our approach's ability in handling meshes with different topologies and complex clothes.","meta":{"url":"http://arxiv.org/abs/2307.13459v1"},"cats":{"new-dataset":0.444081869,"dev-research":0.2179061734,"prompt-eng":0.377014078,"data-quality":0.1431558652,"ml-security":0.0751252419}}
{"text":"Cross-dataset evaluation further shows the strong generalization ability of our approach.","meta":{"url":"http://arxiv.org/abs/2307.13459v1"},"cats":{"new-dataset":0.3676026282,"dev-research":0.1786298121,"prompt-eng":0.3621221146,"data-quality":0.2466054071,"ml-security":0.1077697255}}
{"text":"In this work we study a well-known and challenging problem of Multi-agent Pathfinding, when a set of agents is confined to a graph, each agent is assigned a unique start and goal vertices and the task is to find a set of collision-free paths (one for each agent) such that each agent reaches its respective goal.","meta":{"url":"http://arxiv.org/abs/2307.13453v1"},"cats":{"new-dataset":0.3699625786,"dev-research":0.1925003929,"prompt-eng":0.3472195033,"data-quality":0.1032618972,"ml-security":0.1265377371}}
{"text":"We investigate how to utilize Monte-Carlo Tree Search (MCTS) to solve the problem.","meta":{"url":"http://arxiv.org/abs/2307.13453v1"},"cats":{"new-dataset":0.110403477,"dev-research":0.17513259,"prompt-eng":0.4492541798,"data-quality":0.1526439619,"ml-security":0.0702905601}}
{"text":"Although MCTS was shown to demonstrate superior performance in a wide range of problems like playing antagonistic games (e.g. Go, Chess etc.), discovering faster matrix multiplication algorithms etc., its application to the problem at hand was not well studied before.","meta":{"url":"http://arxiv.org/abs/2307.13453v1"},"cats":{"new-dataset":0.0240394484,"dev-research":0.2812867154,"prompt-eng":0.3538675655,"data-quality":0.096553597,"ml-security":0.1077131672}}
{"text":"To this end we introduce an original variant of MCTS, tailored to multi-agent pathfinding.","meta":{"url":"http://arxiv.org/abs/2307.13453v1"},"cats":{"new-dataset":0.1662525135,"dev-research":0.1883698158,"prompt-eng":0.4234919778,"data-quality":0.1004768535,"ml-security":0.0820829526}}
{"text":"The crux of our approach is how the reward, that guides MCTS, is computed.","meta":{"url":"http://arxiv.org/abs/2307.13453v1"},"cats":{"new-dataset":0.0174821605,"dev-research":0.2269709282,"prompt-eng":0.4183416576,"data-quality":0.1046017134,"ml-security":0.0826454571}}
{"text":"Specifically, we use individual paths to assist the agents with the the goal-reaching behavior, while leaving them freedom to get off the track if it is needed to avoid collisions.","meta":{"url":"http://arxiv.org/abs/2307.13453v1"},"cats":{"new-dataset":0.0459533118,"dev-research":0.3000459375,"prompt-eng":0.4010564619,"data-quality":0.0661261966,"ml-security":0.1214683437}}
{"text":"We also use a dedicated decomposition technique to reduce the branching factor of the tree search procedure.","meta":{"url":"http://arxiv.org/abs/2307.13453v1"},"cats":{"new-dataset":0.0707146637,"dev-research":0.1876337028,"prompt-eng":0.4499549889,"data-quality":0.1316194808,"ml-security":0.0452122393}}
{"text":"Empirically we show that the suggested method outperforms the baseline planning algorithm that invokes heuristic search, e.g. A*, at each re-planning step.","meta":{"url":"http://arxiv.org/abs/2307.13453v1"},"cats":{"new-dataset":0.0647338349,"dev-research":0.3276582128,"prompt-eng":0.468040466,"data-quality":0.0867517009,"ml-security":0.0337568549}}
{"text":"A key challenge in human-robot collaboration is the non-stationarity created by humans due to changes in their behaviour.","meta":{"url":"http://arxiv.org/abs/2307.13447v1"},"cats":{"new-dataset":0.1661946613,"dev-research":0.3407130376,"prompt-eng":0.3977681617,"data-quality":0.157982738,"ml-security":0.0949042901}}
{"text":"This alters environmental transitions and hinders human-robot collaboration.","meta":{"url":"http://arxiv.org/abs/2307.13447v1"},"cats":{"new-dataset":0.0221554127,"dev-research":0.411288514,"prompt-eng":0.3821936703,"data-quality":0.0989982582,"ml-security":0.1404231957}}
{"text":"We propose a principled meta-learning framework to explore how robots could better predict human behaviour, and thereby deal with issues of non-stationarity.","meta":{"url":"http://arxiv.org/abs/2307.13447v1"},"cats":{"new-dataset":0.1020077272,"dev-research":0.2290262997,"prompt-eng":0.4209012987,"data-quality":0.1898351614,"ml-security":0.1936898821}}
{"text":"On the basis of this framework, we developed Behaviour-Transform (BeTrans).","meta":{"url":"http://arxiv.org/abs/2307.13447v1"},"cats":{"new-dataset":0.1921112064,"dev-research":0.2821066908,"prompt-eng":0.4590386829,"data-quality":0.1143065799,"ml-security":0.1041671852}}
{"text":"BeTrans is a conditional transformer that enables a robot agent to adapt quickly to new human agents with non-stationary behaviours, due to its notable performance with sequential data.","meta":{"url":"http://arxiv.org/abs/2307.13447v1"},"cats":{"new-dataset":0.217934867,"dev-research":0.2424872333,"prompt-eng":0.4317612679,"data-quality":0.0552205725,"ml-security":0.0904854024}}
{"text":"We trained BeTrans on simulated human agents with different systematic biases in collaborative settings.","meta":{"url":"http://arxiv.org/abs/2307.13447v1"},"cats":{"new-dataset":0.2361596606,"dev-research":0.3361876713,"prompt-eng":0.4124725214,"data-quality":0.1296293015,"ml-security":0.1798623248}}
{"text":"We used an original customisable environment to show that BeTrans effectively collaborates with simulated human agents and adapts faster to non-stationary simulated human agents than SOTA techniques.","meta":{"url":"http://arxiv.org/abs/2307.13447v1"},"cats":{"new-dataset":0.2547212006,"dev-research":0.2965198266,"prompt-eng":0.421171061,"data-quality":0.0676959156,"ml-security":0.1029834892}}
{"text":"Multiple low-Earth orbit satellite constellations, aimed at beaming broadband connectivity from space, are currently under active deployment.","meta":{"url":"http://arxiv.org/abs/2307.13441v1"},"cats":{"new-dataset":0.1600513514,"dev-research":0.1969206314,"prompt-eng":0.3896574423,"data-quality":0.0958653171,"ml-security":0.0506423733}}
{"text":"While such space-based Internet is set to augment, globally, today's terrestrial connectivity, and has managed to generate significant hype, it has been largely difficult for the community to measure, quantify, or understand the nuances of these offerings in the absence of a global measurement infrastructure -- the research community has mostly resorted to simulators, emulators, and limited measurements till now.","meta":{"url":"http://arxiv.org/abs/2307.13441v1"},"cats":{"new-dataset":0.3458122389,"dev-research":0.2240982072,"prompt-eng":0.3869447059,"data-quality":0.1234983121,"ml-security":0.0767227204}}
{"text":"In this paper, we identify an opportunity to use the social media `lens' to complement such measurements and mine user-centric insights on the evolving ecosystem at scale.","meta":{"url":"http://arxiv.org/abs/2307.13441v1"},"cats":{"new-dataset":0.2131010952,"dev-research":0.2635504396,"prompt-eng":0.319249351,"data-quality":0.1608634915,"ml-security":0.0966382415}}
{"text":"Network traffic monitoring using IP flows is used to handle the current challenge of analyzing encrypted network communication.","meta":{"url":"http://arxiv.org/abs/2307.13434v1"},"cats":{"new-dataset":0.0541077739,"dev-research":0.2474282832,"prompt-eng":0.3555497573,"data-quality":0.1632893599,"ml-security":0.3824099263}}
{"text":"Nevertheless, the packet aggregation into flow records naturally causes information loss; therefore, this paper proposes a novel flow extension for traffic features based on the time series analysis of the Single Flow Time series, i.e., a time series created by the number of bytes in each packet and its timestamp.","meta":{"url":"http://arxiv.org/abs/2307.13434v1"},"cats":{"new-dataset":0.1029109067,"dev-research":0.2426994301,"prompt-eng":0.3048719986,"data-quality":0.1524047489,"ml-security":0.2148739601}}
{"text":"We propose 69 universal features based on the statistical analysis of data points, time domain analysis, packet distribution within the flow timespan, time series behavior, and frequency domain analysis.","meta":{"url":"http://arxiv.org/abs/2307.13434v1"},"cats":{"new-dataset":0.1826200049,"dev-research":0.2553142749,"prompt-eng":0.3808515484,"data-quality":0.1689456762,"ml-security":0.148730658}}
{"text":"We have demonstrated the usability and universality of the proposed feature vector for various network traffic classification tasks using 15 well-known publicly available datasets.","meta":{"url":"http://arxiv.org/abs/2307.13434v1"},"cats":{"new-dataset":0.1449485233,"dev-research":0.2489112994,"prompt-eng":0.3479038294,"data-quality":0.271431779,"ml-security":0.2741831116}}
{"text":"Our evaluation shows that the novel feature vector achieves classification performance similar or better than related works on both binary and multiclass classification tasks.","meta":{"url":"http://arxiv.org/abs/2307.13434v1"},"cats":{"new-dataset":0.1339474778,"dev-research":0.247845191,"prompt-eng":0.4224363026,"data-quality":0.2722613889,"ml-security":0.1319834031}}
{"text":"In more than half of the evaluated tasks, the classification performance increased by up to 5\\%.","meta":{"url":"http://arxiv.org/abs/2307.13434v1"},"cats":{"new-dataset":0.0275576296,"dev-research":0.2260078681,"prompt-eng":0.4161630257,"data-quality":0.2796411917,"ml-security":0.1149109515}}
{"text":"Metaverse aims for building a fully immersive virtual shared space, where the users are able to engage in various activities.","meta":{"url":"http://arxiv.org/abs/2307.13429v1"},"cats":{"new-dataset":0.2149161728,"dev-research":0.3421867771,"prompt-eng":0.3982159417,"data-quality":0.0878060383,"ml-security":0.0786733435}}
{"text":"To successfully deploy the service for each user, the Metaverse service provider and network service provider generally localise the user first and then support the communication between the base station (BS) and the user.","meta":{"url":"http://arxiv.org/abs/2307.13429v1"},"cats":{"new-dataset":0.0964082323,"dev-research":0.2575223405,"prompt-eng":0.4373060366,"data-quality":0.139325613,"ml-security":0.0493145412}}
{"text":"A reconfigurable intelligent surface (RIS) is capable of creating a reflected link between the BS and the user to enhance line-of-sight.","meta":{"url":"http://arxiv.org/abs/2307.13429v1"},"cats":{"new-dataset":0.0490906548,"dev-research":0.2246734839,"prompt-eng":0.4615938505,"data-quality":0.0700292475,"ml-security":0.0560523153}}
{"text":"Furthermore, the new key performance indicators (KPIs) in Metaverse, such as its energy-consumption-dependent total service cost and transmission latency, are often overlooked in ultra-reliable low latency communication (URLLC) designs, which have to be carefully considered in next-generation URLLC (xURLLC) regimes.","meta":{"url":"http://arxiv.org/abs/2307.13429v1"},"cats":{"new-dataset":0.0349749559,"dev-research":0.2622306948,"prompt-eng":0.4266677806,"data-quality":0.1393996356,"ml-security":0.043157998}}
{"text":"In this paper, our design objective is to jointly optimise the transmit power, the RIS phase shifts, and the decoding error probability to simultaneously minimise the total service cost and transmission latency and approach the Pareto Front (PF).","meta":{"url":"http://arxiv.org/abs/2307.13429v1"},"cats":{"new-dataset":0.0190143157,"dev-research":0.1746349288,"prompt-eng":0.4442745849,"data-quality":0.138809573,"ml-security":0.0734331933}}
{"text":"We conceive a twin-stage central controller, which aims for localising the users first and then supports the communication between the BS and users.","meta":{"url":"http://arxiv.org/abs/2307.13429v1"},"cats":{"new-dataset":0.1283963848,"dev-research":0.3520761953,"prompt-eng":0.5081790528,"data-quality":0.1003230763,"ml-security":0.1047095692}}
{"text":"In the first stage, we localise the Metaverse users, where the stochastic gradient descent (SGD) algorithm is invoked for accurate user localisation.","meta":{"url":"http://arxiv.org/abs/2307.13429v1"},"cats":{"new-dataset":0.1405369279,"dev-research":0.2658786968,"prompt-eng":0.4405670907,"data-quality":0.2607116429,"ml-security":0.1439474149}}
{"text":"In the second stage, a meta-learning-based position-dependent multi-objective soft actor and critic (MO-SAC) algorithm is proposed to approach the PF between the total service cost and transmission latency and to further optimise the latency-dependent reliability.","meta":{"url":"http://arxiv.org/abs/2307.13429v1"},"cats":{"new-dataset":0.0197756944,"dev-research":0.2270385902,"prompt-eng":0.364412717,"data-quality":0.1880885617,"ml-security":0.0815912637}}
{"text":"Our numerical results demonstrate that ...","meta":{"url":"http://arxiv.org/abs/2307.13429v1"},"cats":{"new-dataset":0.0601665274,"dev-research":0.1695375032,"prompt-eng":0.3708644344,"data-quality":0.159401632,"ml-security":0.0815516573}}
{"text":"This paper describes an adaptation of the Local Interpretable Model-Agnostic Explanations (LIME) AI method to operate under a biometric verification setting.","meta":{"url":"http://arxiv.org/abs/2307.13428v1"},"cats":{"new-dataset":0.0426846725,"dev-research":0.3165133582,"prompt-eng":0.4450001463,"data-quality":0.2612001375,"ml-security":0.2015530389}}
{"text":"LIME was initially proposed for networks with the same output classes used for training, and it employs the softmax probability to determine which regions of the image contribute the most to classification.","meta":{"url":"http://arxiv.org/abs/2307.13428v1"},"cats":{"new-dataset":0.0689334155,"dev-research":0.2118712543,"prompt-eng":0.3454210246,"data-quality":0.2786322585,"ml-security":0.1651470299}}
{"text":"However, in a verification setting, the classes to be recognized have not been seen during training.","meta":{"url":"http://arxiv.org/abs/2307.13428v1"},"cats":{"new-dataset":0.0496998227,"dev-research":0.1847307332,"prompt-eng":0.3481699881,"data-quality":0.4135758253,"ml-security":0.1963049581}}
{"text":"In addition, instead of using the softmax output, face descriptors are usually obtained from a layer before the classification layer.","meta":{"url":"http://arxiv.org/abs/2307.13428v1"},"cats":{"new-dataset":0.0926576929,"dev-research":0.2334126098,"prompt-eng":0.3389696427,"data-quality":0.1653076044,"ml-security":0.1748917026}}
{"text":"The model is adapted to achieve explainability via cosine similarity between feature vectors of perturbated versions of the input image.","meta":{"url":"http://arxiv.org/abs/2307.13428v1"},"cats":{"new-dataset":0.0637150024,"dev-research":0.2502347491,"prompt-eng":0.4152198074,"data-quality":0.2121457057,"ml-security":0.1131712423}}
{"text":"The method is showcased for face biometrics with two CNN models based on MobileNetv2 and ResNet50.","meta":{"url":"http://arxiv.org/abs/2307.13428v1"},"cats":{"new-dataset":0.1861488035,"dev-research":0.2101831793,"prompt-eng":0.3436108322,"data-quality":0.1209337547,"ml-security":0.2063154397}}
{"text":"Situation awareness is a crucial cognitive skill that enables individuals to perceive, comprehend, and project the current state of their environment accurately.","meta":{"url":"http://arxiv.org/abs/2307.13427v1"},"cats":{"new-dataset":0.1302980859,"dev-research":0.4095173565,"prompt-eng":0.4025260301,"data-quality":0.1167643328,"ml-security":0.1234228261}}
{"text":"It involves being conscious of relevant information, understanding its meaning, and using that understanding to make well-informed decisions.","meta":{"url":"http://arxiv.org/abs/2307.13427v1"},"cats":{"new-dataset":0.0151314302,"dev-research":0.3939895646,"prompt-eng":0.360378258,"data-quality":0.1020321296,"ml-security":0.0831472613}}
{"text":"Awareness systems often need to integrate new knowledge and adapt to changing environments.","meta":{"url":"http://arxiv.org/abs/2307.13427v1"},"cats":{"new-dataset":0.0564501339,"dev-research":0.3653955567,"prompt-eng":0.422106449,"data-quality":0.1560647066,"ml-security":0.134224771}}
{"text":"Ontology reasoning facilitates knowledge integration and evolution, allowing for seamless updates and expansions of the ontology.","meta":{"url":"http://arxiv.org/abs/2307.13427v1"},"cats":{"new-dataset":0.0914728904,"dev-research":0.3841530169,"prompt-eng":0.4004362125,"data-quality":0.1313146942,"ml-security":0.0688121818}}
{"text":"With the consideration of above, we are providing a quick review on semantic information retrieval and ontology engineering to understand the emerging challenges and future research.","meta":{"url":"http://arxiv.org/abs/2307.13427v1"},"cats":{"new-dataset":0.0591551551,"dev-research":0.2887818914,"prompt-eng":0.4325453358,"data-quality":0.2388139471,"ml-security":0.0429312411}}
{"text":"In the review we have found that the ontology reasoning addresses the limitations of traditional systems by providing a formal, flexible, and scalable framework for knowledge representation, reasoning, and inference.","meta":{"url":"http://arxiv.org/abs/2307.13427v1"},"cats":{"new-dataset":0.1492673365,"dev-research":0.3209955576,"prompt-eng":0.4321239723,"data-quality":0.1284633007,"ml-security":0.0693873561}}
{"text":"In this short paper, we consider a form of higher-order rewriting with a call-by-value evaluation strategy so as to model call-by-value programs.","meta":{"url":"http://arxiv.org/abs/2307.13426v1"},"cats":{"new-dataset":0.0736166331,"dev-research":0.4269737918,"prompt-eng":0.4470451931,"data-quality":0.1447654181,"ml-security":0.0934469059}}
{"text":"We briefly present a cost-size semantics to call-by-value rewriting: a class of algebraic interpretations that map terms to tuples that bound both the reductions' cost and the size of normal forms.","meta":{"url":"http://arxiv.org/abs/2307.13426v1"},"cats":{"new-dataset":0.0551631589,"dev-research":0.4000359551,"prompt-eng":0.3977340588,"data-quality":0.1932617247,"ml-security":0.1445542112}}
{"text":"Encoding-decoding CNNs play a central role in data-driven noise reduction and can be found within numerous deep-learning algorithms.","meta":{"url":"http://arxiv.org/abs/2307.13425v1"},"cats":{"new-dataset":0.1586638233,"dev-research":0.2424531548,"prompt-eng":0.3095068219,"data-quality":0.3151918032,"ml-security":0.2513976944}}
{"text":"However, the development of these CNN architectures is often done in ad-hoc fashion and theoretical underpinnings for important design choices is generally lacking.","meta":{"url":"http://arxiv.org/abs/2307.13425v1"},"cats":{"new-dataset":0.1066691034,"dev-research":0.251835921,"prompt-eng":0.3401426224,"data-quality":0.1196195815,"ml-security":0.1524125496}}
{"text":"Up to this moment there are different existing relevant works that strive to explain the internal operation of these CNNs.","meta":{"url":"http://arxiv.org/abs/2307.13425v1"},"cats":{"new-dataset":0.0767076418,"dev-research":0.2567978119,"prompt-eng":0.3077910244,"data-quality":0.227421921,"ml-security":0.1699611063}}
{"text":"Still, these ideas are either scattered and/or may require significant expertise to be accessible for a bigger audience.","meta":{"url":"http://arxiv.org/abs/2307.13425v1"},"cats":{"new-dataset":0.0487249041,"dev-research":0.2863372736,"prompt-eng":0.3452268264,"data-quality":0.1518431642,"ml-security":0.1096394541}}
{"text":"In order to open up this exciting field, this article builds intuition on the theory of deep convolutional framelets and explains diverse ED CNN architectures in a unified theoretical framework.","meta":{"url":"http://arxiv.org/abs/2307.13425v1"},"cats":{"new-dataset":0.3594689097,"dev-research":0.1987312464,"prompt-eng":0.3162946705,"data-quality":0.1964787028,"ml-security":0.1656802668}}
{"text":"By connecting basic principles from signal processing to the field of deep learning, this self-contained material offers significant guidance for designing robust and efficient novel CNN architectures.","meta":{"url":"http://arxiv.org/abs/2307.13425v1"},"cats":{"new-dataset":0.1396997028,"dev-research":0.2443151884,"prompt-eng":0.3267283536,"data-quality":0.2021443725,"ml-security":0.2329479872}}
{"text":"In this paper, we conduct a holistic exploration of the Universal Decompositional Semantic (UDS) Parsing.","meta":{"url":"http://arxiv.org/abs/2307.13424v1"},"cats":{"new-dataset":0.2168853296,"dev-research":0.2597116297,"prompt-eng":0.3905238834,"data-quality":0.2582860127,"ml-security":0.0930851334}}
{"text":"We first introduce a cascade model for UDS parsing that decomposes the complex parsing task into semantically appropriate subtasks.","meta":{"url":"http://arxiv.org/abs/2307.13424v1"},"cats":{"new-dataset":0.1884619192,"dev-research":0.3120313832,"prompt-eng":0.4504261371,"data-quality":0.1827123271,"ml-security":0.0953729842}}
{"text":"Our approach outperforms the prior models, while significantly reducing inference time.","meta":{"url":"http://arxiv.org/abs/2307.13424v1"},"cats":{"new-dataset":0.0501868868,"dev-research":0.2023327021,"prompt-eng":0.420821011,"data-quality":0.1975458871,"ml-security":0.0985101155}}
{"text":"We also incorporate syntactic information and further optimized the architecture.","meta":{"url":"http://arxiv.org/abs/2307.13424v1"},"cats":{"new-dataset":0.137530041,"dev-research":0.3251775015,"prompt-eng":0.4374707557,"data-quality":0.1802241878,"ml-security":0.0618657077}}
{"text":"Besides, different ways for data augmentation are explored, which further improve the UDS Parsing.","meta":{"url":"http://arxiv.org/abs/2307.13424v1"},"cats":{"new-dataset":0.2315546271,"dev-research":0.3048881188,"prompt-eng":0.4405871448,"data-quality":0.2755103534,"ml-security":0.107111201}}
{"text":"Lastly, we conduct experiments to investigate the efficacy of ChatGPT in handling the UDS task, revealing that it excels in attribute parsing but struggles in relation parsing, and using ChatGPT for data augmentation yields suboptimal results.","meta":{"url":"http://arxiv.org/abs/2307.13424v1"},"cats":{"new-dataset":0.3450018286,"dev-research":0.3375949822,"prompt-eng":0.4585608826,"data-quality":0.313660922,"ml-security":0.0945687407}}
{"text":"Our code is available at https://github.com/hexuandeng/HExp4UDS.","meta":{"url":"http://arxiv.org/abs/2307.13424v1"},"cats":{"new-dataset":0.4250935205,"dev-research":0.1558955691,"prompt-eng":0.4690372555,"data-quality":0.1001091206,"ml-security":0.0332107199}}
{"text":"Self-supervised speech representations (SSSRs) have been successfully applied to a number of speech-processing tasks, e.g. as feature extractor for speech quality (SQ) prediction, which is, in turn, relevant for assessment and training speech enhancement systems for users with normal or impaired hearing.","meta":{"url":"http://arxiv.org/abs/2307.13423v1"},"cats":{"new-dataset":0.0682390256,"dev-research":0.2661790522,"prompt-eng":0.391128747,"data-quality":0.283017273,"ml-security":0.1104285992}}
{"text":"However, exact knowledge of why and how quality-related information is encoded well in such representations remains poorly understood.","meta":{"url":"http://arxiv.org/abs/2307.13423v1"},"cats":{"new-dataset":0.0411428539,"dev-research":0.3149132289,"prompt-eng":0.3404305053,"data-quality":0.4902368257,"ml-security":0.2073513606}}
{"text":"In this work, techniques for non-intrusive prediction of SQ ratings are extended to the prediction of intelligibility for hearing-impaired users.","meta":{"url":"http://arxiv.org/abs/2307.13423v1"},"cats":{"new-dataset":0.0289442791,"dev-research":0.2798912517,"prompt-eng":0.409061159,"data-quality":0.2648712169,"ml-security":0.1891949447}}
{"text":"It is found that self-supervised representations are useful as input features to non-intrusive prediction models, achieving competitive performance to more complex systems.","meta":{"url":"http://arxiv.org/abs/2307.13423v1"},"cats":{"new-dataset":0.030102098,"dev-research":0.274464234,"prompt-eng":0.420845059,"data-quality":0.2082052377,"ml-security":0.3636025729}}
{"text":"A detailed analysis of the performance depending on Clarity Prediction Challenge 1 listeners and enhancement systems indicates that more data might be needed to allow generalisation to unknown systems and","meta":{"url":"http://arxiv.org/abs/2307.13423v1"},"cats":{"new-dataset":0.0823600971,"dev-research":0.388166808,"prompt-eng":0.472349135,"data-quality":0.3854525731,"ml-security":0.154143426}}
{"text":"(hearing-impaired) individuals","meta":{"url":"http://arxiv.org/abs/2307.13423v1"},"cats":{"new-dataset":0.0566106944,"dev-research":0.2487978113,"prompt-eng":0.3548540099,"data-quality":0.1935058252,"ml-security":0.0851913747}}
{"text":"Attention models are typically learned by optimizing one of three standard loss functions that are variously called -- soft attention, hard attention, and latent variable marginal likelihood (LVML) attention.","meta":{"url":"http://arxiv.org/abs/2307.13421v1"},"cats":{"new-dataset":0.0474486931,"dev-research":0.1836057714,"prompt-eng":0.3805381929,"data-quality":0.1964794096,"ml-security":0.120645696}}
{"text":"All three paradigms are motivated by the same goal of finding two models -- a `focus' model that `selects' the right \\textit{segment} of the input and a `classification' model that processes the selected segment into the target label.","meta":{"url":"http://arxiv.org/abs/2307.13421v1"},"cats":{"new-dataset":0.0280001111,"dev-research":0.273022145,"prompt-eng":0.3984888663,"data-quality":0.1429451335,"ml-security":0.0642260748}}
{"text":"However, they differ significantly in the way the selected segments are aggregated, resulting in distinct dynamics and final results.","meta":{"url":"http://arxiv.org/abs/2307.13421v1"},"cats":{"new-dataset":0.0436278369,"dev-research":0.1911045715,"prompt-eng":0.3365219404,"data-quality":0.1181973718,"ml-security":0.0341751772}}
{"text":"We observe a unique signature of models learned using these paradigms and explain this as a consequence of the evolution of the classification model under gradient descent when the focus model is fixed.","meta":{"url":"http://arxiv.org/abs/2307.13421v1"},"cats":{"new-dataset":0.0585830585,"dev-research":0.189985201,"prompt-eng":0.3611753238,"data-quality":0.2859635728,"ml-security":0.2626043922}}
{"text":"We also analyze these paradigms in a simple setting and derive closed-form expressions for the parameter trajectory under gradient flow.","meta":{"url":"http://arxiv.org/abs/2307.13421v1"},"cats":{"new-dataset":0.0728571997,"dev-research":0.2144663698,"prompt-eng":0.3601984031,"data-quality":0.103964551,"ml-security":0.1221811165}}
{"text":"With the soft attention loss, the focus model improves quickly at initialization and splutters later on.","meta":{"url":"http://arxiv.org/abs/2307.13421v1"},"cats":{"new-dataset":0.0373994038,"dev-research":0.2918120985,"prompt-eng":0.4043776649,"data-quality":0.1442863067,"ml-security":0.0899708878}}
{"text":"On the other hand, hard attention loss behaves in the opposite fashion.","meta":{"url":"http://arxiv.org/abs/2307.13421v1"},"cats":{"new-dataset":0.0024105323,"dev-research":0.2761001021,"prompt-eng":0.3445739737,"data-quality":0.2705800041,"ml-security":0.2077016492}}
{"text":"Based on our observations, we propose a simple hybrid approach that combines the advantages of the different loss functions and demonstrates it on a collection of semi-synthetic and real-world datasets","meta":{"url":"http://arxiv.org/abs/2307.13421v1"},"cats":{"new-dataset":0.4999562751,"dev-research":0.1475262021,"prompt-eng":0.3632428348,"data-quality":0.2129711689,"ml-security":0.1016871288}}
{"text":"Learning enabled components (LECs), while critical for decision making in autonomous vehicles (AVs), are likely to make incorrect decisions when presented with samples outside of their training distributions.","meta":{"url":"http://arxiv.org/abs/2307.13419v1"},"cats":{"new-dataset":0.0397051577,"dev-research":0.2838224228,"prompt-eng":0.3919895469,"data-quality":0.2768979158,"ml-security":0.2284555376}}
{"text":"Out-of-distribution (OOD) detectors have been proposed to detect such samples, thereby acting as a safety monitor, however, both OOD detectors and LECs require heavy utilization of embedded hardware typically found in AVs.","meta":{"url":"http://arxiv.org/abs/2307.13419v1"},"cats":{"new-dataset":0.2040794211,"dev-research":0.1954499635,"prompt-eng":0.4481589614,"data-quality":0.3136950603,"ml-security":0.2388426527}}
{"text":"For both components, there is a tradeoff between non-functional and functional performance, and both impact a vehicle's safety.","meta":{"url":"http://arxiv.org/abs/2307.13419v1"},"cats":{"new-dataset":0.0063077475,"dev-research":0.3412045133,"prompt-eng":0.3065391256,"data-quality":0.1139571761,"ml-security":0.1032014702}}
{"text":"For instance, giving an OOD detector a longer response time can increase its accuracy at the expense of the LEC.","meta":{"url":"http://arxiv.org/abs/2307.13419v1"},"cats":{"new-dataset":0.0032536146,"dev-research":0.2310495232,"prompt-eng":0.4073499768,"data-quality":0.1743099013,"ml-security":0.1463220423}}
{"text":"We consider an LEC with binary output like an autonomous emergency braking system (AEBS) and use risk, the combination of severity and occurrence of a failure, to model the effect of both components' design parameters on each other's functional and non-functional performance, as well as their impact on system safety.","meta":{"url":"http://arxiv.org/abs/2307.13419v1"},"cats":{"new-dataset":0.0522285714,"dev-research":0.2805918688,"prompt-eng":0.4575725191,"data-quality":0.1597620229,"ml-security":0.2379538015}}
{"text":"We formulate a co-design methodology that uses this risk model to find the design parameters for an OOD detector and LEC that decrease risk below that of the baseline system and demonstrate it on a vision based AEBS.","meta":{"url":"http://arxiv.org/abs/2307.13419v1"},"cats":{"new-dataset":0.087973138,"dev-research":0.2225698534,"prompt-eng":0.4688133074,"data-quality":0.2055029637,"ml-security":0.2045788113}}
{"text":"Using our methodology, we achieve a 42.3% risk reduction while maintaining equivalent resource utilization.","meta":{"url":"http://arxiv.org/abs/2307.13419v1"},"cats":{"new-dataset":0.0872521344,"dev-research":0.2820734632,"prompt-eng":0.3813243645,"data-quality":0.1227744328,"ml-security":0.1499042545}}
{"text":"Ambiguity is ubiquitous in natural language.","meta":{"url":"http://arxiv.org/abs/2307.13417v1"},"cats":{"new-dataset":0.0171414939,"dev-research":0.3974922925,"prompt-eng":0.3652329461,"data-quality":0.3851922358,"ml-security":0.1083038845}}
{"text":"Resolving ambiguous meanings is especially important in information retrieval tasks.","meta":{"url":"http://arxiv.org/abs/2307.13417v1"},"cats":{"new-dataset":0.0128965546,"dev-research":0.3455555308,"prompt-eng":0.4180590162,"data-quality":0.346164716,"ml-security":0.0486654143}}
{"text":"While word embeddings carry semantic information, they fail to handle ambiguity well.","meta":{"url":"http://arxiv.org/abs/2307.13417v1"},"cats":{"new-dataset":0.0192940585,"dev-research":0.2912837158,"prompt-eng":0.3456432854,"data-quality":0.5512867829,"ml-security":0.1261335115}}
{"text":"Transformer models have been shown to handle word ambiguity for complex queries, but they cannot be used to identify ambiguous words, e.g. for a 1-word query.","meta":{"url":"http://arxiv.org/abs/2307.13417v1"},"cats":{"new-dataset":0.0186258988,"dev-research":0.2137125025,"prompt-eng":0.4457048104,"data-quality":0.3018412796,"ml-security":0.0900253561}}
{"text":"Furthermore, training these models is costly in terms of time, hardware resources, and training data, prohibiting their use in specialized environments with sensitive data.","meta":{"url":"http://arxiv.org/abs/2307.13417v1"},"cats":{"new-dataset":0.0418991002,"dev-research":0.2389602942,"prompt-eng":0.3353111105,"data-quality":0.1466510508,"ml-security":0.3921200682}}
{"text":"Word embeddings can be trained using moderate hardware resources.","meta":{"url":"http://arxiv.org/abs/2307.13417v1"},"cats":{"new-dataset":0.1324794632,"dev-research":0.2732245274,"prompt-eng":0.3980984543,"data-quality":0.2492567847,"ml-security":0.0916866043}}
{"text":"This paper shows that applying DBSCAN clustering to the latent space can identify ambiguous words and evaluate their level of ambiguity.","meta":{"url":"http://arxiv.org/abs/2307.13417v1"},"cats":{"new-dataset":0.0859138371,"dev-research":0.2507369484,"prompt-eng":0.4286365458,"data-quality":0.4773174422,"ml-security":0.0647796091}}
{"text":"An automatic DBSCAN parameter selection leads to high-quality clusters, which are semantically coherent and correspond well to the perceived meanings of a given word.","meta":{"url":"http://arxiv.org/abs/2307.13417v1"},"cats":{"new-dataset":0.0895176371,"dev-research":0.2996159181,"prompt-eng":0.4888366506,"data-quality":0.2983917946,"ml-security":0.0568006484}}
{"text":"The unprecedented accuracy of convolutional neural networks (CNNs) across a broad range of AI tasks has led to their widespread deployment in mobile and embedded settings.","meta":{"url":"http://arxiv.org/abs/2307.13412v1"},"cats":{"new-dataset":0.2744108229,"dev-research":0.255120021,"prompt-eng":0.3377910651,"data-quality":0.1599836396,"ml-security":0.2268767179}}
{"text":"In a pursuit for high-performance and energy-efficient inference, significant research effort has been invested in the design of FPGA-based CNN accelerators.","meta":{"url":"http://arxiv.org/abs/2307.13412v1"},"cats":{"new-dataset":0.1019157845,"dev-research":0.2078517769,"prompt-eng":0.3519967658,"data-quality":0.0813316549,"ml-security":0.1226868303}}
{"text":"In this context, single computation engines constitute a popular approach to support diverse CNN modes without the overhead of fabric reconfiguration.","meta":{"url":"http://arxiv.org/abs/2307.13412v1"},"cats":{"new-dataset":0.1330734323,"dev-research":0.234716726,"prompt-eng":0.3337308859,"data-quality":0.1138407528,"ml-security":0.1349526637}}
{"text":"Nevertheless, this flexibility often comes with significantly degraded performance on memory-bound layers and resource underutilisation due to the suboptimal mapping of certain layers on the engine's fixed configuration.","meta":{"url":"http://arxiv.org/abs/2307.13412v1"},"cats":{"new-dataset":0.0439221925,"dev-research":0.3340786197,"prompt-eng":0.3797883144,"data-quality":0.1649504033,"ml-security":0.1727599313}}
{"text":"In this work, we investigate the implications in terms of CNN engine design for a class of models that introduce a pre-convolution stage to decompress the weights at run time.","meta":{"url":"http://arxiv.org/abs/2307.13412v1"},"cats":{"new-dataset":0.1527848513,"dev-research":0.2049516789,"prompt-eng":0.3487853138,"data-quality":0.1402423643,"ml-security":0.2790011973}}
{"text":"We refer to these approaches as on-the-fly.","meta":{"url":"http://arxiv.org/abs/2307.13412v1"},"cats":{"new-dataset":0.0344072324,"dev-research":0.3520933604,"prompt-eng":0.3640225606,"data-quality":0.1222951345,"ml-security":0.1236234534}}
{"text":"This paper presents unzipFPGA, a novel CNN inference system that counteracts the limitations of existing CNN engines.","meta":{"url":"http://arxiv.org/abs/2307.13412v1"},"cats":{"new-dataset":0.2370279924,"dev-research":0.2145447372,"prompt-eng":0.3341425906,"data-quality":0.1870367535,"ml-security":0.2419424059}}
{"text":"The proposed framework comprises a novel CNN hardware architecture that introduces a weights generator module that enables the on-chip on-the-fly generation of weights, alleviating the negative impact of limited bandwidth on memory-bound layers.","meta":{"url":"http://arxiv.org/abs/2307.13412v1"},"cats":{"new-dataset":0.1675812732,"dev-research":0.2513602992,"prompt-eng":0.3358423891,"data-quality":0.1362424889,"ml-security":0.2206123231}}
{"text":"We further enhance unzipFPGA with an automated hardware-aware methodology that tailors the weights generation mechanism to the target CNN-device pair, leading to an improved accuracy-performance balance.","meta":{"url":"http://arxiv.org/abs/2307.13412v1"},"cats":{"new-dataset":0.2007966887,"dev-research":0.2570764437,"prompt-eng":0.3526875947,"data-quality":0.1312037185,"ml-security":0.1219221677}}
{"text":"Finally, we introduce an input selective processing element (PE) design that balances the load between PEs in suboptimally mapped layers.","meta":{"url":"http://arxiv.org/abs/2307.13412v1"},"cats":{"new-dataset":0.0299954607,"dev-research":0.2820988804,"prompt-eng":0.4498892551,"data-quality":0.1017180061,"ml-security":0.0877713052}}
{"text":"The proposed framework yields hardware designs that achieve an average of 2.57x performance efficiency gain over highly optimised GPU designs for the same power constraints and up to 3.94x higher performance density over a diverse range of state-of-the-art FPGA-based CNN accelerators.","meta":{"url":"http://arxiv.org/abs/2307.13412v1"},"cats":{"new-dataset":0.1406046789,"dev-research":0.2322004124,"prompt-eng":0.3241268616,"data-quality":0.0787389378,"ml-security":0.1450630097}}
{"text":"This research article analyses and demonstrates the hidden implications for fairness of seemingly neutral data coupled with powerful technology, such as machine learning (ML), using Open Banking as an example.","meta":{"url":"http://arxiv.org/abs/2307.13408v1"},"cats":{"new-dataset":0.0392049453,"dev-research":0.2426606355,"prompt-eng":0.3407989574,"data-quality":0.2871998511,"ml-security":0.5227646964}}
{"text":"Open Banking has ignited a revolution in financial services, opening new opportunities for customer acquisition, management, retention, and risk assessment.","meta":{"url":"http://arxiv.org/abs/2307.13408v1"},"cats":{"new-dataset":0.0286600348,"dev-research":0.2224209908,"prompt-eng":0.3427501044,"data-quality":0.10564563,"ml-security":0.1533393159}}
{"text":"However, the granularity of transaction data holds potential for harm where unnoticed proxies for sensitive and prohibited characteristics may lead to indirect discrimination.","meta":{"url":"http://arxiv.org/abs/2307.13408v1"},"cats":{"new-dataset":0.0200494184,"dev-research":0.2455018041,"prompt-eng":0.3593768082,"data-quality":0.3157970019,"ml-security":0.5679085466}}
{"text":"Against this backdrop, we investigate the dimensions of financial vulnerability (FV), a global concern resulting from COVID-19 and rising inflation.","meta":{"url":"http://arxiv.org/abs/2307.13408v1"},"cats":{"new-dataset":0.2436153706,"dev-research":0.2491053655,"prompt-eng":0.358281368,"data-quality":0.1348180413,"ml-security":0.4090608826}}
{"text":"Specifically, we look to understand the behavioral elements leading up to FV and its impact on at-risk, disadvantaged groups through the lens of fair interpretation.","meta":{"url":"http://arxiv.org/abs/2307.13408v1"},"cats":{"new-dataset":0.1013700807,"dev-research":0.2892791487,"prompt-eng":0.3954859256,"data-quality":0.1488021107,"ml-security":0.2547756779}}
{"text":"Using a unique dataset from a UK FinTech lender, we demonstrate the power of fine-grained transaction data while simultaneously cautioning its safe usage.","meta":{"url":"http://arxiv.org/abs/2307.13408v1"},"cats":{"new-dataset":0.5020295398,"dev-research":0.2024501163,"prompt-eng":0.3749295355,"data-quality":0.203799585,"ml-security":0.2458628699}}
{"text":"Three ML classifiers are compared in predicting the likelihood of FV, and groups exhibiting different magnitudes and forms of FV are identified via clustering to highlight the effects of feature combination.","meta":{"url":"http://arxiv.org/abs/2307.13408v1"},"cats":{"new-dataset":0.0432968035,"dev-research":0.2274367858,"prompt-eng":0.4301366143,"data-quality":0.2835536137,"ml-security":0.2115685687}}
{"text":"Our results indicate that engineered features of financial behavior can be predictive of omitted personal information, particularly sensitive or protected characteristics, shedding light on the hidden dangers of Open Banking data.","meta":{"url":"http://arxiv.org/abs/2307.13408v1"},"cats":{"new-dataset":0.0459610235,"dev-research":0.2800603363,"prompt-eng":0.4063778258,"data-quality":0.2184112425,"ml-security":0.5691953495}}
{"text":"We discuss the implications and conclude fairness via unawareness is ineffective in this new technological environment.","meta":{"url":"http://arxiv.org/abs/2307.13408v1"},"cats":{"new-dataset":0.0213936848,"dev-research":0.2930959479,"prompt-eng":0.3720229231,"data-quality":0.3981052372,"ml-security":0.5137423452}}
{"text":"It is a well-known fact that current AI-based language technology -- language models, machine translation systems, multilingual dictionaries and corpora -- focuses on the world's 2-3% most widely spoken languages.","meta":{"url":"http://arxiv.org/abs/2307.13405v1"},"cats":{"new-dataset":0.51588432,"dev-research":0.2475833658,"prompt-eng":0.3461173881,"data-quality":0.2102665538,"ml-security":0.1206578617}}
{"text":"Recent research efforts have attempted to expand the coverage of AI technology to `under-resourced languages.'","meta":{"url":"http://arxiv.org/abs/2307.13405v1"},"cats":{"new-dataset":0.0828082038,"dev-research":0.3379425054,"prompt-eng":0.3584555945,"data-quality":0.1806659944,"ml-security":0.1626816451}}
{"text":"The goal of our paper is to bring attention to a phenomenon that we call linguistic bias: multilingual language processing systems often exhibit a hardwired, yet usually involuntary and hidden representational preference towards certain languages.","meta":{"url":"http://arxiv.org/abs/2307.13405v1"},"cats":{"new-dataset":0.0421273127,"dev-research":0.2892064422,"prompt-eng":0.440289115,"data-quality":0.4260723813,"ml-security":0.2249312821}}
{"text":"Linguistic bias is manifested in uneven per-language performance even in the case of similar test conditions.","meta":{"url":"http://arxiv.org/abs/2307.13405v1"},"cats":{"new-dataset":0.0052497478,"dev-research":0.3339027539,"prompt-eng":0.4246236832,"data-quality":0.4750161137,"ml-security":0.1078797247}}
{"text":"We show that biased technology is often the result of research and development methodologies that do not do justice to the complexity of the languages being represented, and that can even become ethically problematic as they disregard valuable aspects of diversity as well as the needs of the language communities themselves.","meta":{"url":"http://arxiv.org/abs/2307.13405v1"},"cats":{"new-dataset":0.0806263229,"dev-research":0.3823708255,"prompt-eng":0.3358065755,"data-quality":0.4122598354,"ml-security":0.2815990861}}
{"text":"As our attempt at building diversity-aware language resources, we present a new initiative that aims at reducing linguistic bias through both technological design and methodology, based on an eye-level collaboration with local communities.","meta":{"url":"http://arxiv.org/abs/2307.13405v1"},"cats":{"new-dataset":0.244939712,"dev-research":0.361095745,"prompt-eng":0.3568725193,"data-quality":0.2581348243,"ml-security":0.0669997577}}
{"text":"DAG (directed acyclic graph) tasks are widely used to model parallel real-time workload.","meta":{"url":"http://arxiv.org/abs/2307.13401v1"},"cats":{"new-dataset":0.1268917791,"dev-research":0.325798568,"prompt-eng":0.3559842974,"data-quality":0.0739195315,"ml-security":0.0713189238}}
{"text":"The real-time performance of a DAG task not only depends on its total workload, but also its graph structure.","meta":{"url":"http://arxiv.org/abs/2307.13401v1"},"cats":{"new-dataset":0.0444823093,"dev-research":0.3717667337,"prompt-eng":0.3669984795,"data-quality":0.0766373821,"ml-security":0.0468573239}}
{"text":"Intuitively, with the same total workload, a DAG task with looser precedence constraints tends to have better real-time performance in terms of worst-case response time.","meta":{"url":"http://arxiv.org/abs/2307.13401v1"},"cats":{"new-dataset":0.0100693665,"dev-research":0.4055682827,"prompt-eng":0.3975477438,"data-quality":0.0991628014,"ml-security":0.0984462358}}
{"text":"However, this paper shows that actually we can shorten the worst-case response time of a DAG task by carefully adding new edges and constructing longer paths.","meta":{"url":"http://arxiv.org/abs/2307.13401v1"},"cats":{"new-dataset":0.0638510002,"dev-research":0.3545333527,"prompt-eng":0.4654324657,"data-quality":0.1613341709,"ml-security":0.1444381474}}
{"text":"We develop techniques based on the state-of-the-art DAG response time analysis techniques to properly add new edges so that the worst-case response time bound guaranteed by formal analysis can be significantly reduced.","meta":{"url":"http://arxiv.org/abs/2307.13401v1"},"cats":{"new-dataset":0.0939640354,"dev-research":0.2933989698,"prompt-eng":0.4386759417,"data-quality":0.1713537209,"ml-security":0.144864105}}
{"text":"Experiments under different parameter settings demonstrate the effectiveness of the proposed techniques.","meta":{"url":"http://arxiv.org/abs/2307.13401v1"},"cats":{"new-dataset":0.0102268874,"dev-research":0.2130121164,"prompt-eng":0.5094060072,"data-quality":0.1239547044,"ml-security":0.0582466209}}
{"text":"Today, many cities seek to transition to more sustainable transportation systems.","meta":{"url":"http://arxiv.org/abs/2307.13397v1"},"cats":{"new-dataset":0.0292258205,"dev-research":0.2291228746,"prompt-eng":0.3244852773,"data-quality":0.065846889,"ml-security":0.0715933248}}
{"text":"Cycling is critical in this transition for shorter trips, including first-and-last-mile links to transit.","meta":{"url":"http://arxiv.org/abs/2307.13397v1"},"cats":{"new-dataset":0.0158808929,"dev-research":0.2746946681,"prompt-eng":0.3269932831,"data-quality":0.0952330778,"ml-security":0.0501257778}}
{"text":"Yet, if individuals perceive cycling as unsafe, they will not cycle and choose other transportation modes.","meta":{"url":"http://arxiv.org/abs/2307.13397v1"},"cats":{"new-dataset":0.0095112499,"dev-research":0.2833429052,"prompt-eng":0.3292560142,"data-quality":0.1476931269,"ml-security":0.349305762}}
{"text":"This study presents a novel approach to identifying how the perception of cycling safety can be analyzed and understood and the impact of the built environment and cycling contexts on such perceptions.","meta":{"url":"http://arxiv.org/abs/2307.13397v1"},"cats":{"new-dataset":0.1282203507,"dev-research":0.4614870885,"prompt-eng":0.3681706248,"data-quality":0.1716165407,"ml-security":0.1722599643}}
{"text":"We base our work on other perception studies and pairwise comparisons, using real-world images to survey respondents.","meta":{"url":"http://arxiv.org/abs/2307.13397v1"},"cats":{"new-dataset":0.1293141013,"dev-research":0.2018442682,"prompt-eng":0.3900169709,"data-quality":0.197213029,"ml-security":0.0772831404}}
{"text":"We repeatedly show respondents two road environments and ask them to select the one they perceive as safer for cycling.","meta":{"url":"http://arxiv.org/abs/2307.13397v1"},"cats":{"new-dataset":0.0899800001,"dev-research":0.2954670034,"prompt-eng":0.4123929687,"data-quality":0.1117601361,"ml-security":0.1881772396}}
{"text":"We compare several methods capable of rating cycling environments from pairwise comparisons and classify cycling environments perceived as safe or unsafe.","meta":{"url":"http://arxiv.org/abs/2307.13397v1"},"cats":{"new-dataset":0.0703316068,"dev-research":0.3220275138,"prompt-eng":0.4325547735,"data-quality":0.2295302999,"ml-security":0.2491752187}}
{"text":"Urban planning can use this score to improve interventions' effectiveness and improve cycling promotion campaigns.","meta":{"url":"http://arxiv.org/abs/2307.13397v1"},"cats":{"new-dataset":0.0284457117,"dev-research":0.3339885949,"prompt-eng":0.3739394149,"data-quality":0.0923474365,"ml-security":0.0843836511}}
{"text":"Furthermore, this approach facilitates the continuous assessment of changing cycling environments, allows for a short-term evaluation of measures, and is efficiently deployed in different locations or contexts.","meta":{"url":"http://arxiv.org/abs/2307.13397v1"},"cats":{"new-dataset":0.1429137318,"dev-research":0.3666350356,"prompt-eng":0.4387929555,"data-quality":0.127660102,"ml-security":0.0402176077}}
{"text":"This paper discusses the problem of efficiently solving parity games where player Odd has to obey an additional 'strong transition fairness constraint' on its vertices -- given that a player Odd vertex $v$ is visited infinitely often, a particular subset of the outgoing edges (called live edges) of $v$ has to be taken infinitely often.","meta":{"url":"http://arxiv.org/abs/2307.13396v1"},"cats":{"new-dataset":0.0762272705,"dev-research":0.2087554369,"prompt-eng":0.3565384649,"data-quality":0.1583522413,"ml-security":0.2751846449}}
{"text":"Such games, which we call 'Odd-fair parity games', naturally arise from abstractions of cyber-physical systems for planning and control.   ","meta":{"url":"http://arxiv.org/abs/2307.13396v1"},"cats":{"new-dataset":0.2178699064,"dev-research":0.2745623061,"prompt-eng":0.3978178891,"data-quality":0.0819136416,"ml-security":0.2806972657}}
{"text":"In this paper, we present a new Zielonka-type algorithm for solving Odd-fair parity games.","meta":{"url":"http://arxiv.org/abs/2307.13396v1"},"cats":{"new-dataset":0.2642345563,"dev-research":0.1574378755,"prompt-eng":0.3559073712,"data-quality":0.1559793711,"ml-security":0.1534472296}}
{"text":"This algorithm not only shares 'the same worst-case time complexity' as Zielonka's algorithm for (normal) parity games but also preserves the algorithmic advantage Zielonka's algorithm possesses over other parity solvers with exponential time complexity.   ","meta":{"url":"http://arxiv.org/abs/2307.13396v1"},"cats":{"new-dataset":0.0432629066,"dev-research":0.2057218656,"prompt-eng":0.3007447751,"data-quality":0.0867827986,"ml-security":0.1547611748}}
{"text":"We additionally introduce a formalization of Odd player winning strategies in such games, which were unexplored previous to this work.","meta":{"url":"http://arxiv.org/abs/2307.13396v1"},"cats":{"new-dataset":0.1002076783,"dev-research":0.2386888022,"prompt-eng":0.3982887328,"data-quality":0.1548969554,"ml-security":0.2546144708}}
{"text":"This formalization serves dual purposes: firstly, it enables us to prove our Zielonka-type algorithm; secondly, it stands as a noteworthy contribution in its own right, augmenting our understanding of additional fairness assumptions in two-player games.","meta":{"url":"http://arxiv.org/abs/2307.13396v1"},"cats":{"new-dataset":0.1095084754,"dev-research":0.2187568289,"prompt-eng":0.3493068492,"data-quality":0.1764085892,"ml-security":0.2456779411}}
{"text":"The consumption of podcast media has been increasing rapidly.","meta":{"url":"http://arxiv.org/abs/2307.13394v1"},"cats":{"new-dataset":0.0751666122,"dev-research":0.2428398374,"prompt-eng":0.3113252678,"data-quality":0.1679856418,"ml-security":0.1041339417}}
{"text":"Due to the lengthy nature of podcast episodes, users often carefully select which ones to listen to.","meta":{"url":"http://arxiv.org/abs/2307.13394v1"},"cats":{"new-dataset":0.0243381121,"dev-research":0.2747366425,"prompt-eng":0.3912538932,"data-quality":0.1313873352,"ml-security":0.0877340443}}
{"text":"Although episode descriptions aid users by providing a summary of the entire podcast, they do not provide a topic-by-topic breakdown.","meta":{"url":"http://arxiv.org/abs/2307.13394v1"},"cats":{"new-dataset":0.0970431605,"dev-research":0.2308935136,"prompt-eng":0.3670103338,"data-quality":0.1718627461,"ml-security":0.0468465289}}
{"text":"This study explores the combined application of topic segmentation and text summarisation methods to investigate how podcast episode comprehension can be improved.","meta":{"url":"http://arxiv.org/abs/2307.13394v1"},"cats":{"new-dataset":0.0612827272,"dev-research":0.3078403139,"prompt-eng":0.3880380309,"data-quality":0.2699945258,"ml-security":0.0448536149}}
{"text":"We have sampled 10 episodes from Spotify's English-Language Podcast Dataset and employed TextTiling and TextSplit to segment them.","meta":{"url":"http://arxiv.org/abs/2307.13394v1"},"cats":{"new-dataset":0.8089205021,"dev-research":0.2456309588,"prompt-eng":0.375825466,"data-quality":0.2708589021,"ml-security":0.0504704179}}
{"text":"Moreover, three text summarisation models, namely T5, BART, and Pegasus, were applied to provide a very short title for each segment.","meta":{"url":"http://arxiv.org/abs/2307.13394v1"},"cats":{"new-dataset":0.1934313071,"dev-research":0.1932578414,"prompt-eng":0.3834211673,"data-quality":0.1936592755,"ml-security":0.0325436849}}
{"text":"The segmentation part was evaluated using our annotated sample with the $P_k$ and WindowDiff ($WD$) metrics.","meta":{"url":"http://arxiv.org/abs/2307.13394v1"},"cats":{"new-dataset":0.4343844981,"dev-research":0.1422475124,"prompt-eng":0.4296962146,"data-quality":0.2372274141,"ml-security":0.0399267497}}
{"text":"A survey was also rolled out ($N=25$) to assess the quality of the generated summaries.","meta":{"url":"http://arxiv.org/abs/2307.13394v1"},"cats":{"new-dataset":0.3052732712,"dev-research":0.2651927502,"prompt-eng":0.3813217458,"data-quality":0.2493798029,"ml-security":0.040942278}}
{"text":"The TextSplit algorithm achieved the lowest mean for both evaluation metrics ($\\bar{P_k}=0.41$ and $\\bar{WD}=0.41$), while the T5 model produced the best summaries, achieving a relevancy score only $8\\%$ less to the one achieved by the human-written titles.","meta":{"url":"http://arxiv.org/abs/2307.13394v1"},"cats":{"new-dataset":0.0429829589,"dev-research":0.2273283526,"prompt-eng":0.3922514422,"data-quality":0.1947056903,"ml-security":0.0280684987}}
{"text":"Counterfactual Explanations (CEs) are an important tool in Algorithmic Recourse for addressing two questions:","meta":{"url":"http://arxiv.org/abs/2307.13390v1"},"cats":{"new-dataset":0.0535362981,"dev-research":0.4763265963,"prompt-eng":0.4279023671,"data-quality":0.3792048444,"ml-security":0.3175174627}}
{"text":"1.","meta":{"url":"http://arxiv.org/abs/2307.13390v1"},"cats":{"new-dataset":0.3514432999,"dev-research":0.1971378504,"prompt-eng":0.4116801856,"data-quality":0.1978560651,"ml-security":0.1004690052}}
{"text":"What are the crucial factors that led to an automated prediction/decision?","meta":{"url":"http://arxiv.org/abs/2307.13390v1"},"cats":{"new-dataset":0.0092394982,"dev-research":0.3514574164,"prompt-eng":0.4194398841,"data-quality":0.170650536,"ml-security":0.1696072103}}
{"text":"2. How can these factors be changed to achieve a more favorable outcome from a user's perspective?","meta":{"url":"http://arxiv.org/abs/2307.13390v1"},"cats":{"new-dataset":0.0079722622,"dev-research":0.3102726967,"prompt-eng":0.394110557,"data-quality":0.1215706359,"ml-security":0.1119978369}}
{"text":"Thus, guiding the user's interaction with AI systems by proposing easy-to-understand explanations and easy-to-attain feasible changes is essential for the trustworthy adoption and long-term acceptance of AI systems.","meta":{"url":"http://arxiv.org/abs/2307.13390v1"},"cats":{"new-dataset":0.0476436775,"dev-research":0.4182094322,"prompt-eng":0.4226136294,"data-quality":0.1717998205,"ml-security":0.2424895532}}
{"text":"In the literature, various methods have been proposed to generate CEs, and different quality measures have been suggested to evaluate these methods.","meta":{"url":"http://arxiv.org/abs/2307.13390v1"},"cats":{"new-dataset":0.0796992283,"dev-research":0.3337998813,"prompt-eng":0.5129131629,"data-quality":0.2650166022,"ml-security":0.0354358073}}
{"text":"However, the generation of CEs is usually computationally expensive, and the resulting suggestions are unrealistic and thus non-actionable.","meta":{"url":"http://arxiv.org/abs/2307.13390v1"},"cats":{"new-dataset":0.0236873876,"dev-research":0.3270384615,"prompt-eng":0.4137456122,"data-quality":0.1406960458,"ml-security":0.1187253057}}
{"text":"In this paper, we introduce a new method to generate CEs for a pre-trained binary classifier by first shaping the latent space of an autoencoder to be a mixture of Gaussian distributions.","meta":{"url":"http://arxiv.org/abs/2307.13390v1"},"cats":{"new-dataset":0.1455200481,"dev-research":0.2287240344,"prompt-eng":0.4711722186,"data-quality":0.2858113335,"ml-security":0.1566198261}}
{"text":"CEs are then generated in latent space by linear interpolation between the query sample and the centroid of the target class.","meta":{"url":"http://arxiv.org/abs/2307.13390v1"},"cats":{"new-dataset":0.2114579472,"dev-research":0.1974351224,"prompt-eng":0.4338963843,"data-quality":0.1544034599,"ml-security":0.0620259657}}
{"text":"We show that our method maintains the characteristics of the input sample during the counterfactual search.","meta":{"url":"http://arxiv.org/abs/2307.13390v1"},"cats":{"new-dataset":0.1133318256,"dev-research":0.2515029806,"prompt-eng":0.4840619519,"data-quality":0.3852473557,"ml-security":0.1846207533}}
{"text":"In various experiments, we show that the proposed method is competitive based on different quality measures on image and tabular datasets -- efficiently returns results that are closer to the original data manifold compared to three state-of-the-art methods, which are essential for realistic high-dimensional machine learning applications.","meta":{"url":"http://arxiv.org/abs/2307.13390v1"},"cats":{"new-dataset":0.2879332501,"dev-research":0.1752304416,"prompt-eng":0.3304734149,"data-quality":0.2685575141,"ml-security":0.1000193939}}
{"text":"Social coding platforms have revolutionized collaboration in software development, leading to using software bots for streamlining operations.","meta":{"url":"http://arxiv.org/abs/2307.13386v1"},"cats":{"new-dataset":0.1197541213,"dev-research":0.5606847929,"prompt-eng":0.4049509626,"data-quality":0.1837214894,"ml-security":0.1534850479}}
{"text":"However, The presence of open-source software (OSS) bots gives rise to problems including impersonation, spamming, bias, and security risks.","meta":{"url":"http://arxiv.org/abs/2307.13386v1"},"cats":{"new-dataset":0.0659215881,"dev-research":0.3957020446,"prompt-eng":0.3822629418,"data-quality":0.2468181203,"ml-security":0.5656049326}}
{"text":"Identifying bot accounts and behavior is a challenging task in the OSS project.","meta":{"url":"http://arxiv.org/abs/2307.13386v1"},"cats":{"new-dataset":0.0967310797,"dev-research":0.2877911174,"prompt-eng":0.454431891,"data-quality":0.2883349993,"ml-security":0.3603148808}}
{"text":"This research aims to investigate bots' behavior in open-source software projects and identify bot accounts with maximum possible accuracy.","meta":{"url":"http://arxiv.org/abs/2307.13386v1"},"cats":{"new-dataset":0.0831363259,"dev-research":0.412772365,"prompt-eng":0.4306704411,"data-quality":0.3133087243,"ml-security":0.31615353}}
{"text":"Our team gathered a dataset of 19,779 accounts that meet standardized criteria to enable future research on bots in open-source projects.","meta":{"url":"http://arxiv.org/abs/2307.13386v1"},"cats":{"new-dataset":0.7064968997,"dev-research":0.2702667907,"prompt-eng":0.383737136,"data-quality":0.1356141744,"ml-security":0.191981397}}
{"text":"We follow a rigorous workflow to ensure that the data we collect is accurate, generalizable, scalable, and up-to-date.","meta":{"url":"http://arxiv.org/abs/2307.13386v1"},"cats":{"new-dataset":0.3384960866,"dev-research":0.3066165479,"prompt-eng":0.3975442544,"data-quality":0.2014343831,"ml-security":0.1168870932}}
{"text":"We've identified four types of bot accounts in open-source software projects by analyzing their behavior across 17 features in 5 dimensions.","meta":{"url":"http://arxiv.org/abs/2307.13386v1"},"cats":{"new-dataset":0.183388855,"dev-research":0.4014640458,"prompt-eng":0.4019200099,"data-quality":0.1844412765,"ml-security":0.2503375441}}
{"text":"Our team created BotHawk, a highly effective model for detecting bots in open-source software projects.","meta":{"url":"http://arxiv.org/abs/2307.13386v1"},"cats":{"new-dataset":0.2378273118,"dev-research":0.3990699958,"prompt-eng":0.4277481506,"data-quality":0.2688609367,"ml-security":0.3656901643}}
{"text":"It outperforms other models, achieving an AUC of 0.947 and an F1-score of 0.89.","meta":{"url":"http://arxiv.org/abs/2307.13386v1"},"cats":{"new-dataset":0.0200263483,"dev-research":0.2067990978,"prompt-eng":0.4002830211,"data-quality":0.1865446023,"ml-security":0.0830410752}}
{"text":"BotHawk can detect a wider variety of bots, including CI/CD and scanning bots.","meta":{"url":"http://arxiv.org/abs/2307.13386v1"},"cats":{"new-dataset":0.0783709344,"dev-research":0.2897364024,"prompt-eng":0.4436006887,"data-quality":0.2074318457,"ml-security":0.1584536487}}
{"text":"Furthermore, we find that the number of followers, number of repositories, and tags contain the most relevant features to identify the account type.","meta":{"url":"http://arxiv.org/abs/2307.13386v1"},"cats":{"new-dataset":0.1222798127,"dev-research":0.2515151813,"prompt-eng":0.4257151553,"data-quality":0.1858266097,"ml-security":0.1319223239}}
{"text":"Code coverage is a widely used metric for quantifying the extent to which program elements, such as statements or branches, are executed during testing.","meta":{"url":"http://arxiv.org/abs/2307.13383v1"},"cats":{"new-dataset":0.1021720877,"dev-research":0.5499505916,"prompt-eng":0.4409049095,"data-quality":0.2518402948,"ml-security":0.1664828346}}
{"text":"Calculating code coverage is resource-intensive, requiring code building and execution with additional overhead for the instrumentation.","meta":{"url":"http://arxiv.org/abs/2307.13383v1"},"cats":{"new-dataset":0.0978834636,"dev-research":0.4759299774,"prompt-eng":0.3740865756,"data-quality":0.1202666314,"ml-security":0.1506792546}}
{"text":"Furthermore, computing coverage of any snippet of code requires the whole program context.","meta":{"url":"http://arxiv.org/abs/2307.13383v1"},"cats":{"new-dataset":0.0299144544,"dev-research":0.4585149684,"prompt-eng":0.3908029257,"data-quality":0.1923751985,"ml-security":0.229372127}}
{"text":"Using Machine Learning to amortize this expensive process could lower the cost of code coverage by requiring only the source code context, and the task of code coverage prediction can be a novel benchmark for judging the ability of models to understand code.","meta":{"url":"http://arxiv.org/abs/2307.13383v1"},"cats":{"new-dataset":0.0476819476,"dev-research":0.4749909628,"prompt-eng":0.379569607,"data-quality":0.2294273386,"ml-security":0.4313189598}}
{"text":"We propose a novel benchmark task called Code Coverage Prediction for Large Language Models (LLMs).","meta":{"url":"http://arxiv.org/abs/2307.13383v1"},"cats":{"new-dataset":0.2719010283,"dev-research":0.3163005451,"prompt-eng":0.4298611371,"data-quality":0.3105972726,"ml-security":0.2712744661}}
{"text":"We formalize this task to evaluate the capability of LLMs in understanding code execution by determining which lines of a method are executed by a given test case and inputs.","meta":{"url":"http://arxiv.org/abs/2307.13383v1"},"cats":{"new-dataset":0.0431301278,"dev-research":0.4471455779,"prompt-eng":0.5119380093,"data-quality":0.2133932922,"ml-security":0.1827495882}}
{"text":"We curate and release a dataset we call COVERAGEEVAL by executing tests and code from the HumanEval dataset and collecting code coverage information.","meta":{"url":"http://arxiv.org/abs/2307.13383v1"},"cats":{"new-dataset":0.889921495,"dev-research":0.3433560085,"prompt-eng":0.4321892439,"data-quality":0.2111128258,"ml-security":0.2329015361}}
{"text":"We report the performance of four state-of-the-art LLMs used for code-related tasks, including OpenAI's GPT-4 and GPT-3.5-Turbo, Google's BARD, and Anthropic's Claude, on the Code Coverage Prediction task.","meta":{"url":"http://arxiv.org/abs/2307.13383v1"},"cats":{"new-dataset":0.2576031555,"dev-research":0.3304030529,"prompt-eng":0.4605219965,"data-quality":0.1874877623,"ml-security":0.1457859409}}
{"text":"Finally, we argue that code coverage as a metric and pre-training data source are valuable for overall LLM performance on software engineering tasks.","meta":{"url":"http://arxiv.org/abs/2307.13383v1"},"cats":{"new-dataset":0.110345396,"dev-research":0.4336093042,"prompt-eng":0.4316835423,"data-quality":0.1980773441,"ml-security":0.1800168803}}
{"text":"We present Scaff-PD, a fast and communication-efficient algorithm for distributionally robust federated learning.","meta":{"url":"http://arxiv.org/abs/2307.13381v1"},"cats":{"new-dataset":0.3199488341,"dev-research":0.1889694764,"prompt-eng":0.3748203025,"data-quality":0.2367804231,"ml-security":0.2037206457}}
{"text":"Our approach improves fairness by optimizing a family of distributionally robust objectives tailored to heterogeneous clients.","meta":{"url":"http://arxiv.org/abs/2307.13381v1"},"cats":{"new-dataset":0.0454725781,"dev-research":0.2450556778,"prompt-eng":0.402310857,"data-quality":0.2711846377,"ml-security":0.3679052424}}
{"text":"We leverage the special structure of these objectives, and design an accelerated primal dual (APD) algorithm which uses bias corrected local steps (as in Scaffold) to achieve significant gains in communication efficiency and convergence speed.","meta":{"url":"http://arxiv.org/abs/2307.13381v1"},"cats":{"new-dataset":0.0518357486,"dev-research":0.2277670705,"prompt-eng":0.4180470012,"data-quality":0.1326637388,"ml-security":0.0983866352}}
{"text":"We evaluate Scaff-PD on several benchmark datasets and demonstrate its effectiveness in improving fairness and robustness while maintaining competitive accuracy.","meta":{"url":"http://arxiv.org/abs/2307.13381v1"},"cats":{"new-dataset":0.5073813403,"dev-research":0.2218840224,"prompt-eng":0.3588373965,"data-quality":0.3065439758,"ml-security":0.2834666911}}
{"text":"Our results suggest that Scaff-PD is a promising approach for federated learning in resource-constrained and heterogeneous settings.","meta":{"url":"http://arxiv.org/abs/2307.13381v1"},"cats":{"new-dataset":0.2634719763,"dev-research":0.2047132218,"prompt-eng":0.3729108403,"data-quality":0.147845979,"ml-security":0.1060677108}}
{"text":"Acknowledgments in scientific papers may give an insight into aspects of the scientific community, such as reward systems, collaboration patterns, and hidden research trends.","meta":{"url":"http://arxiv.org/abs/2307.13377v1"},"cats":{"new-dataset":0.0604583184,"dev-research":0.2948359623,"prompt-eng":0.3495385812,"data-quality":0.2732305334,"ml-security":0.0822032928}}
{"text":"The aim of the paper is to evaluate the performance of different embedding models for the task of automatic extraction and classification of acknowledged entities from the acknowledgment text in scientific papers.","meta":{"url":"http://arxiv.org/abs/2307.13377v1"},"cats":{"new-dataset":0.0619058295,"dev-research":0.1947286779,"prompt-eng":0.4190897404,"data-quality":0.4158411027,"ml-security":0.0545184375}}
{"text":"We trained and implemented a named entity recognition (NER) task using the Flair NLP framework.","meta":{"url":"http://arxiv.org/abs/2307.13377v1"},"cats":{"new-dataset":0.1013169319,"dev-research":0.2630393239,"prompt-eng":0.4527283896,"data-quality":0.3264263287,"ml-security":0.0861011963}}
{"text":"The training was conducted using three default Flair NER models with four differently-sized corpora and different versions of the Flair NLP framework.","meta":{"url":"http://arxiv.org/abs/2307.13377v1"},"cats":{"new-dataset":0.2360895699,"dev-research":0.2473213041,"prompt-eng":0.387197375,"data-quality":0.1916635266,"ml-security":0.052027574}}
{"text":"The Flair Embeddings model trained on the medium corpus with the latest FLAIR version showed the best accuracy of 0.79.","meta":{"url":"http://arxiv.org/abs/2307.13377v1"},"cats":{"new-dataset":0.2767665176,"dev-research":0.2306910484,"prompt-eng":0.3954425472,"data-quality":0.3265665514,"ml-security":0.070204417}}
{"text":"Expanding the size of a training corpus from very small to medium size massively increased the accuracy of all training algorithms, but further expansion of the training corpus did not bring further improvement.","meta":{"url":"http://arxiv.org/abs/2307.13377v1"},"cats":{"new-dataset":0.0201028025,"dev-research":0.2294876324,"prompt-eng":0.2963264647,"data-quality":0.3431037137,"ml-security":0.156370557}}
{"text":"Moreover, the performance of the model slightly deteriorated.","meta":{"url":"http://arxiv.org/abs/2307.13377v1"},"cats":{"new-dataset":0.0127301623,"dev-research":0.1945814912,"prompt-eng":0.3738540643,"data-quality":0.2320941662,"ml-security":0.0740849724}}
{"text":"Our model is able to recognize six entity types: funding agency, grant number, individuals, university, corporation, and miscellaneous.","meta":{"url":"http://arxiv.org/abs/2307.13377v1"},"cats":{"new-dataset":0.2313321656,"dev-research":0.1436607142,"prompt-eng":0.4099668595,"data-quality":0.1388994039,"ml-security":0.0565256946}}
{"text":"The model works more precisely for some entity types than for others; thus, individuals and grant numbers showed a very good F1-Score over 0.9.","meta":{"url":"http://arxiv.org/abs/2307.13377v1"},"cats":{"new-dataset":0.0328565618,"dev-research":0.185685871,"prompt-eng":0.3903487679,"data-quality":0.1722293067,"ml-security":0.0682434759}}
{"text":"Most of the previous works on acknowledgment analysis were limited by the manual evaluation of data and therefore by the amount of processed data.","meta":{"url":"http://arxiv.org/abs/2307.13377v1"},"cats":{"new-dataset":0.2301411232,"dev-research":0.2760945835,"prompt-eng":0.3673232445,"data-quality":0.3062427809,"ml-security":0.0938291756}}
{"text":"This model can be applied for the comprehensive analysis of acknowledgment texts and may potentially make a great contribution to the field of automated acknowledgment analysis.","meta":{"url":"http://arxiv.org/abs/2307.13377v1"},"cats":{"new-dataset":0.1119644225,"dev-research":0.2937814369,"prompt-eng":0.4641571422,"data-quality":0.4033807486,"ml-security":0.084412114}}
{"text":"In reinforcement learning (RL), rewards of states are typically considered additive, and following the Markov assumption, they are $\\textit{independent}$ of states visited previously.","meta":{"url":"http://arxiv.org/abs/2307.13372v1"},"cats":{"new-dataset":0.0180327375,"dev-research":0.1968664259,"prompt-eng":0.3136134637,"data-quality":0.096666531,"ml-security":0.1281979221}}
{"text":"In many important applications, such as coverage control, experiment design and informative path planning, rewards naturally have diminishing returns, i.e., their value decreases in light of similar states visited previously.","meta":{"url":"http://arxiv.org/abs/2307.13372v1"},"cats":{"new-dataset":0.0089262769,"dev-research":0.2786387566,"prompt-eng":0.4008231771,"data-quality":0.1041828673,"ml-security":0.1501937049}}
{"text":"To tackle this, we propose $\\textit{submodular RL}$ (SubRL), a paradigm which seeks to optimize more general, non-additive (and history-dependent) rewards modelled via submodular set functions which capture diminishing returns.","meta":{"url":"http://arxiv.org/abs/2307.13372v1"},"cats":{"new-dataset":0.0676765612,"dev-research":0.2327573352,"prompt-eng":0.3827822278,"data-quality":0.1432395315,"ml-security":0.146915208}}
{"text":"Unfortunately, in general, even in tabular settings, we show that the resulting optimization problem is hard to approximate.","meta":{"url":"http://arxiv.org/abs/2307.13372v1"},"cats":{"new-dataset":0.1023678008,"dev-research":0.1931500539,"prompt-eng":0.3936942303,"data-quality":0.1888925365,"ml-security":0.0594619028}}
{"text":"On the other hand, motivated by the success of greedy algorithms in classical submodular optimization, we propose SubPO, a simple policy gradient-based algorithm for SubRL that handles non-additive rewards by greedily maximizing marginal gains.","meta":{"url":"http://arxiv.org/abs/2307.13372v1"},"cats":{"new-dataset":0.0501466918,"dev-research":0.2076006984,"prompt-eng":0.3359470971,"data-quality":0.1129133178,"ml-security":0.1456121291}}
{"text":"Indeed, under some assumptions on the underlying Markov Decision Process (MDP), SubPO recovers optimal constant factor approximations of submodular bandits.","meta":{"url":"http://arxiv.org/abs/2307.13372v1"},"cats":{"new-dataset":0.0210848438,"dev-research":0.1809711142,"prompt-eng":0.3539034673,"data-quality":0.126111948,"ml-security":0.1481547233}}
{"text":"Moreover, we derive a natural policy gradient approach for locally optimizing SubRL instances even in large state- and action- spaces.","meta":{"url":"http://arxiv.org/abs/2307.13372v1"},"cats":{"new-dataset":0.1105378836,"dev-research":0.2246822162,"prompt-eng":0.3669687455,"data-quality":0.1251772687,"ml-security":0.1567484408}}
{"text":"We showcase the versatility of our approach by applying SubPO to several applications, such as biodiversity monitoring, Bayesian experiment design, informative path planning, and coverage maximization.","meta":{"url":"http://arxiv.org/abs/2307.13372v1"},"cats":{"new-dataset":0.2083899291,"dev-research":0.224296258,"prompt-eng":0.4679745384,"data-quality":0.1013289983,"ml-security":0.0412027412}}
{"text":"Our results demonstrate sample efficiency, as well as scalability to high-dimensional state-action spaces.","meta":{"url":"http://arxiv.org/abs/2307.13372v1"},"cats":{"new-dataset":0.1227245378,"dev-research":0.1814622025,"prompt-eng":0.4049141999,"data-quality":0.0834207812,"ml-security":0.1190486621}}
{"text":"We study Bayesian optimization (BO) in high-dimensional and non-stationary scenarios.","meta":{"url":"http://arxiv.org/abs/2307.13371v1"},"cats":{"new-dataset":0.0453145795,"dev-research":0.1697459021,"prompt-eng":0.4072229498,"data-quality":0.0909251846,"ml-security":0.1333088104}}
{"text":"Existing algorithms for such scenarios typically require extensive hyperparameter tuning, which limits their practical effectiveness.","meta":{"url":"http://arxiv.org/abs/2307.13371v1"},"cats":{"new-dataset":0.0203581836,"dev-research":0.2052944908,"prompt-eng":0.513147685,"data-quality":0.2203247308,"ml-security":0.1217117857}}
{"text":"We propose a framework, called BALLET, which adaptively filters for a high-confidence region of interest (ROI) as a superlevel-set of a nonparametric probabilistic model such as a Gaussian process (GP).","meta":{"url":"http://arxiv.org/abs/2307.13371v1"},"cats":{"new-dataset":0.0848894444,"dev-research":0.1571688334,"prompt-eng":0.4424364356,"data-quality":0.1308330021,"ml-security":0.0902304584}}
{"text":"Our approach is easy to tune, and is able to focus on local region of the optimization space that can be tackled by existing BO methods.","meta":{"url":"http://arxiv.org/abs/2307.13371v1"},"cats":{"new-dataset":0.08210727,"dev-research":0.2255573375,"prompt-eng":0.3921464115,"data-quality":0.1673624628,"ml-security":0.0739092997}}
{"text":"The key idea is to use two probabilistic models: a coarse GP to identify the ROI, and a localized GP for optimization within the ROI.","meta":{"url":"http://arxiv.org/abs/2307.13371v1"},"cats":{"new-dataset":0.0475660287,"dev-research":0.1847382514,"prompt-eng":0.4201741172,"data-quality":0.1327023961,"ml-security":0.0822584312}}
{"text":"We show theoretically that BALLET can efficiently shrink the search space, and can exhibit a tighter regret bound than standard BO without ROI filtering.","meta":{"url":"http://arxiv.org/abs/2307.13371v1"},"cats":{"new-dataset":0.0436445099,"dev-research":0.1747467389,"prompt-eng":0.36325572,"data-quality":0.1218367707,"ml-security":0.1702887425}}
{"text":"We demonstrate empirically the effectiveness of BALLET on both synthetic and real-world optimization tasks.","meta":{"url":"http://arxiv.org/abs/2307.13371v1"},"cats":{"new-dataset":0.0503495627,"dev-research":0.3347350166,"prompt-eng":0.3999172037,"data-quality":0.0882530844,"ml-security":0.1021135336}}
{"text":"We introduce a novel speaker model \\textsc{Kefa} for navigation instruction generation.","meta":{"url":"http://arxiv.org/abs/2307.13368v1"},"cats":{"new-dataset":0.2706571249,"dev-research":0.3093406092,"prompt-eng":0.4461982491,"data-quality":0.1399071789,"ml-security":0.0421854403}}
{"text":"The existing speaker models in Vision-and-Language Navigation suffer from the large domain gap of vision features between different environments and insufficient temporal grounding capability.","meta":{"url":"http://arxiv.org/abs/2307.13368v1"},"cats":{"new-dataset":0.1548229175,"dev-research":0.2073907274,"prompt-eng":0.3775977306,"data-quality":0.1485697897,"ml-security":0.0690246023}}
{"text":"To address the challenges, we propose a Knowledge Refinement Module to enhance the feature representation with external knowledge facts, and an Adaptive Temporal Alignment method to enforce fine-grained alignment between the generated instructions and the observation sequences.","meta":{"url":"http://arxiv.org/abs/2307.13368v1"},"cats":{"new-dataset":0.2936546398,"dev-research":0.4650992734,"prompt-eng":0.4205265748,"data-quality":0.246878845,"ml-security":0.0796739321}}
{"text":"Moreover, we propose a new metric SPICE-D for navigation instruction evaluation, which is aware of the correctness of direction phrases.","meta":{"url":"http://arxiv.org/abs/2307.13368v1"},"cats":{"new-dataset":0.1549244927,"dev-research":0.4124366943,"prompt-eng":0.4896091251,"data-quality":0.2218900159,"ml-security":0.0490345378}}
{"text":"The experimental results on R2R and UrbanWalk datasets show that the proposed KEFA speaker achieves state-of-the-art instruction generation performance for both indoor and outdoor scenes.","meta":{"url":"http://arxiv.org/abs/2307.13368v1"},"cats":{"new-dataset":0.542322701,"dev-research":0.3305536774,"prompt-eng":0.404201783,"data-quality":0.1379074927,"ml-security":0.0341827669}}
{"text":"Recently, with the emergence of numerous Large Language Models (LLMs), the implementation of AI has entered a new era.","meta":{"url":"http://arxiv.org/abs/2307.13365v1"},"cats":{"new-dataset":0.1151955562,"dev-research":0.2022283456,"prompt-eng":0.4003407282,"data-quality":0.1689811304,"ml-security":0.1119629718}}
{"text":"Irrespective of these models' own capacity and structure, there is a growing demand for LLMs to possess enhanced comprehension of longer and more complex contexts with relatively smaller sizes.","meta":{"url":"http://arxiv.org/abs/2307.13365v1"},"cats":{"new-dataset":0.0389436834,"dev-research":0.2026585113,"prompt-eng":0.3897963719,"data-quality":0.1016060055,"ml-security":0.1110412337}}
{"text":"Models often encounter an upper limit when processing sequences of sentences that extend beyond their comprehension capacity and result in off-topic or even chaotic responses.","meta":{"url":"http://arxiv.org/abs/2307.13365v1"},"cats":{"new-dataset":0.0597709542,"dev-research":0.2012450071,"prompt-eng":0.3506052839,"data-quality":0.1830904375,"ml-security":0.1619228329}}
{"text":"While several recent works attempt to address this issue in various ways, they rarely focus on \"why models are unable to compensate or strengthen their capabilities on their own\".","meta":{"url":"http://arxiv.org/abs/2307.13365v1"},"cats":{"new-dataset":0.0053012684,"dev-research":0.2562334357,"prompt-eng":0.3483245796,"data-quality":0.2285567187,"ml-security":0.2384098502}}
{"text":"In this paper, we thoroughly investigate the nature of information transfer within LLMs and propose a novel technique called Attention Transition.","meta":{"url":"http://arxiv.org/abs/2307.13365v1"},"cats":{"new-dataset":0.0118523902,"dev-research":0.2134915127,"prompt-eng":0.5001774248,"data-quality":0.1591720291,"ml-security":0.0994991538}}
{"text":"This technique empowers models to achieve longer and better context comprehension with minimal additional training or impact on generation fluency.","meta":{"url":"http://arxiv.org/abs/2307.13365v1"},"cats":{"new-dataset":0.035675983,"dev-research":0.3912099943,"prompt-eng":0.4146444442,"data-quality":0.1818561309,"ml-security":0.0907220722}}
{"text":"Our experiments are conducted in XSum and achieve substantial improvement compared with the original generation results.","meta":{"url":"http://arxiv.org/abs/2307.13365v1"},"cats":{"new-dataset":0.2246814921,"dev-research":0.2663309802,"prompt-eng":0.4473494356,"data-quality":0.207776355,"ml-security":0.0434646349}}
{"text":"3D visual grounding aims to localize the target object in a 3D point cloud by a free-form language description.","meta":{"url":"http://arxiv.org/abs/2307.13363v1"},"cats":{"new-dataset":0.2100649669,"dev-research":0.2995435756,"prompt-eng":0.3824115378,"data-quality":0.1369828401,"ml-security":0.1035212975}}
{"text":"Typically, the sentences describing the target object tend to provide information about its relative relation between other objects and its position within the whole scene.","meta":{"url":"http://arxiv.org/abs/2307.13363v1"},"cats":{"new-dataset":0.0266488739,"dev-research":0.2952156941,"prompt-eng":0.3932677826,"data-quality":0.2049569213,"ml-security":0.0974579113}}
{"text":"In this work, we propose a relation-aware one-stage framework, named 3D Relative Position-aware Network (3DRP-Net), which can effectively capture the relative spatial relationships between objects and enhance object attributes.","meta":{"url":"http://arxiv.org/abs/2307.13363v1"},"cats":{"new-dataset":0.2766724493,"dev-research":0.2856221542,"prompt-eng":0.370551117,"data-quality":0.163502079,"ml-security":0.0924395783}}
{"text":"Specifically, 1) we propose a 3D Relative Position Multi-head Attention (3DRP-MA) module to analyze relative relations from different directions in the context of object pairs, which helps the model to focus on the specific object relations mentioned in the sentence.","meta":{"url":"http://arxiv.org/abs/2307.13363v1"},"cats":{"new-dataset":0.2427235882,"dev-research":0.2430129843,"prompt-eng":0.415090515,"data-quality":0.1512567364,"ml-security":0.050273444}}
{"text":"2) We designed a soft-labeling strategy to alleviate the spatial ambiguity caused by redundant points, which further stabilizes and enhances the learning process through a constant and discriminative distribution.","meta":{"url":"http://arxiv.org/abs/2307.13363v1"},"cats":{"new-dataset":0.1281743081,"dev-research":0.2614331938,"prompt-eng":0.4140959695,"data-quality":0.4654270574,"ml-security":0.1065789823}}
{"text":"Extensive experiments conducted on three benchmarks (i.e., ScanRefer and Nr3D/Sr3D) demonstrate that our method outperforms all the state-of-the-art methods in general.","meta":{"url":"http://arxiv.org/abs/2307.13363v1"},"cats":{"new-dataset":0.0998752467,"dev-research":0.1942858121,"prompt-eng":0.382144088,"data-quality":0.1080863124,"ml-security":0.030831544}}
{"text":"The source code will be released on GitHub.","meta":{"url":"http://arxiv.org/abs/2307.13363v1"},"cats":{"new-dataset":0.3928888224,"dev-research":0.220852974,"prompt-eng":0.4053890915,"data-quality":0.1897979934,"ml-security":0.0573530338}}
{"text":"Numerous fields, such as ecology, biology, and neuroscience, use animal recordings to track and measure animal behaviour.","meta":{"url":"http://arxiv.org/abs/2307.13361v1"},"cats":{"new-dataset":0.094892026,"dev-research":0.2450497071,"prompt-eng":0.3895461156,"data-quality":0.1302999847,"ml-security":0.066532058}}
{"text":"Over time, a significant volume of such data has been produced, but some computer vision techniques cannot explore it due to the lack of annotations.","meta":{"url":"http://arxiv.org/abs/2307.13361v1"},"cats":{"new-dataset":0.4445285731,"dev-research":0.1571279138,"prompt-eng":0.3688351915,"data-quality":0.2531595587,"ml-security":0.1020306318}}
{"text":"To address this, we propose an approach for estimating 2D mouse body pose from unlabelled images using a synthetically generated empirical pose prior.","meta":{"url":"http://arxiv.org/abs/2307.13361v1"},"cats":{"new-dataset":0.602850398,"dev-research":0.2481460548,"prompt-eng":0.3687532261,"data-quality":0.1492891125,"ml-security":0.0998541846}}
{"text":"Our proposal is based on a recent self-supervised method for estimating 2D human pose that uses single images and a set of unpaired typical 2D poses within a GAN framework.","meta":{"url":"http://arxiv.org/abs/2307.13361v1"},"cats":{"new-dataset":0.5122170225,"dev-research":0.223707683,"prompt-eng":0.3360223446,"data-quality":0.1420750235,"ml-security":0.1730348151}}
{"text":"We adapt this method to the limb structure of the mouse and generate the empirical prior of 2D poses from a synthetic 3D mouse model, thereby avoiding manual annotation.","meta":{"url":"http://arxiv.org/abs/2307.13361v1"},"cats":{"new-dataset":0.3732602105,"dev-research":0.2989086716,"prompt-eng":0.3985187071,"data-quality":0.1553499763,"ml-security":0.0900838621}}
{"text":"In experiments on a new mouse video dataset, we evaluate the performance of the approach by comparing pose predictions to a manually obtained ground truth.","meta":{"url":"http://arxiv.org/abs/2307.13361v1"},"cats":{"new-dataset":0.416868065,"dev-research":0.2139456849,"prompt-eng":0.3781461013,"data-quality":0.1946845943,"ml-security":0.0953661742}}
{"text":"We also compare predictions with those from a supervised state-of-the-art method for animal pose estimation.","meta":{"url":"http://arxiv.org/abs/2307.13361v1"},"cats":{"new-dataset":0.4225422581,"dev-research":0.1758477654,"prompt-eng":0.3926694379,"data-quality":0.1626143115,"ml-security":0.097238338}}
{"text":"The latter evaluation indicates promising results despite the lack of paired training data.","meta":{"url":"http://arxiv.org/abs/2307.13361v1"},"cats":{"new-dataset":0.0744299891,"dev-research":0.2059794178,"prompt-eng":0.3639624838,"data-quality":0.2782206364,"ml-security":0.0864103713}}
{"text":"Finally, qualitative results using a dataset of horse images show the potential of the setting to adapt to other animal species.","meta":{"url":"http://arxiv.org/abs/2307.13361v1"},"cats":{"new-dataset":0.4726341687,"dev-research":0.2031843013,"prompt-eng":0.3771851927,"data-quality":0.1000458646,"ml-security":0.0558788358}}
{"text":"Undoing computations of a concurrent system is beneficial in many situations, e.g., in reversible debugging of multi-threaded programs and in recovery from errors due to optimistic execution in parallel discrete event simulation.","meta":{"url":"http://arxiv.org/abs/2307.13360v1"},"cats":{"new-dataset":0.0416607709,"dev-research":0.4805126388,"prompt-eng":0.4103183708,"data-quality":0.1451611125,"ml-security":0.1874445088}}
{"text":"A number of approaches have been proposed for how to reverse formal models of concurrent computation including process calculi such as CCS, languages like Erlang, prime event structures and occurrence nets.","meta":{"url":"http://arxiv.org/abs/2307.13360v1"},"cats":{"new-dataset":0.1288849053,"dev-research":0.3744119413,"prompt-eng":0.4681716031,"data-quality":0.1152399187,"ml-security":0.0729856944}}
{"text":"However it has not been settled what properties a reversible system should enjoy, nor how the various properties that have been suggested, such as the parabolic lemma and the causal-consistency property, are related.","meta":{"url":"http://arxiv.org/abs/2307.13360v1"},"cats":{"new-dataset":0.013119792,"dev-research":0.1665058531,"prompt-eng":0.3520267387,"data-quality":0.1135184372,"ml-security":0.1903103712}}
{"text":"We contribute to a solution to these issues by using a generic labelled transition system equipped with a relation capturing whether transitions are independent to explore the implications between these properties.","meta":{"url":"http://arxiv.org/abs/2307.13360v1"},"cats":{"new-dataset":0.0488793543,"dev-research":0.1938608905,"prompt-eng":0.478457244,"data-quality":0.2623105458,"ml-security":0.0725177324}}
{"text":"In particular, we show how they are derivable from a set of axioms.","meta":{"url":"http://arxiv.org/abs/2307.13360v1"},"cats":{"new-dataset":0.0975438597,"dev-research":0.3076557971,"prompt-eng":0.3251920998,"data-quality":0.1861144239,"ml-security":0.3225313358}}
{"text":"Our intention is that when establishing properties of some formalism it will be easier to verify the axioms rather than proving properties such as the parabolic lemma directly.","meta":{"url":"http://arxiv.org/abs/2307.13360v1"},"cats":{"new-dataset":0.0160475993,"dev-research":0.2850257952,"prompt-eng":0.3359514173,"data-quality":0.1194455843,"ml-security":0.1562360474}}
{"text":"We also introduce two new notions related to causal consistent reversibility, namely causal liveness and causal safety, stating, respectively, that an action can be undone if and only if it is independent from all the following ones.","meta":{"url":"http://arxiv.org/abs/2307.13360v1"},"cats":{"new-dataset":0.0288260226,"dev-research":0.2703129166,"prompt-eng":0.3769788512,"data-quality":0.2411880473,"ml-security":0.3044289987}}
{"text":"We show that both causal liveness and causal safety are derivable from our axioms.","meta":{"url":"http://arxiv.org/abs/2307.13360v1"},"cats":{"new-dataset":0.0525060897,"dev-research":0.3466832683,"prompt-eng":0.3624072976,"data-quality":0.2005520204,"ml-security":0.3801411011}}
{"text":"Motivated by real-life deployments of multi-round federated analytics with secure aggregation, we investigate the fundamental communication-accuracy tradeoffs of the heavy hitter discovery and approximate (open-domain) histogram problems under a linear sketching constraint.","meta":{"url":"http://arxiv.org/abs/2307.13347v1"},"cats":{"new-dataset":0.3839399174,"dev-research":0.2703338246,"prompt-eng":0.3299890091,"data-quality":0.1555097531,"ml-security":0.1597020012}}
{"text":"We propose efficient algorithms based on local subsampling and invertible bloom look-up tables (IBLTs).","meta":{"url":"http://arxiv.org/abs/2307.13347v1"},"cats":{"new-dataset":0.3355585813,"dev-research":0.177415916,"prompt-eng":0.4022722625,"data-quality":0.171958741,"ml-security":0.0552656913}}
{"text":"We also show that our algorithms are information-theoretically optimal for a broad class of interactive schemes.","meta":{"url":"http://arxiv.org/abs/2307.13347v1"},"cats":{"new-dataset":0.2032088464,"dev-research":0.2356144869,"prompt-eng":0.4330858319,"data-quality":0.1000229655,"ml-security":0.1445916011}}
{"text":"The results show that the linear sketching constraint does increase the communication cost for both tasks by introducing an extra linear dependence on the number of users in a round.","meta":{"url":"http://arxiv.org/abs/2307.13347v1"},"cats":{"new-dataset":0.0520064575,"dev-research":0.4260610689,"prompt-eng":0.459297543,"data-quality":0.0870095099,"ml-security":0.0889250202}}
{"text":"Moreover, our results also establish a separation between the communication cost for heavy hitter discovery and approximate histogram in the multi-round setting.","meta":{"url":"http://arxiv.org/abs/2307.13347v1"},"cats":{"new-dataset":0.1974064446,"dev-research":0.2000861558,"prompt-eng":0.3716222258,"data-quality":0.1624432833,"ml-security":0.1027697314}}
{"text":"The dependence on the number of rounds $R$ is at most logarithmic for heavy hitter discovery whereas that of approximate histogram is $\\Theta(\\sqrt{R})$. We also empirically demonstrate our findings.","meta":{"url":"http://arxiv.org/abs/2307.13347v1"},"cats":{"new-dataset":0.1713865077,"dev-research":0.2000967443,"prompt-eng":0.3309833852,"data-quality":0.1682786688,"ml-security":0.1083340316}}
{"text":"Obstructive Sleep Apnea-Hypopnea Syndrome (OSAHS) is a chronic breathing disorder caused by a blockage in the upper airways.","meta":{"url":"http://arxiv.org/abs/2307.13346v1"},"cats":{"new-dataset":0.0506023908,"dev-research":0.2273057059,"prompt-eng":0.2761177408,"data-quality":0.0904498412,"ml-security":0.1781047632}}
{"text":"Snoring is a prominent symptom of OSAHS, and previous studies have attempted to identify the obstruction site of the upper airways by snoring sounds.","meta":{"url":"http://arxiv.org/abs/2307.13346v1"},"cats":{"new-dataset":0.0104660764,"dev-research":0.2141734067,"prompt-eng":0.3352385339,"data-quality":0.1232703435,"ml-security":0.1535319011}}
{"text":"Despite some progress, the classification of the obstruction site remains challenging in real-world clinical settings due to the influence of sleep body position on upper airways.","meta":{"url":"http://arxiv.org/abs/2307.13346v1"},"cats":{"new-dataset":0.0320325238,"dev-research":0.1847712703,"prompt-eng":0.370837623,"data-quality":0.1298062239,"ml-security":0.1071167921}}
{"text":"To address this challenge, this paper proposes a snore-based sleep body position recognition dataset (SSBPR) consisting of 7570 snoring recordings, which comprises six distinct labels for sleep body position: supine, supine but left lateral head, supine but right lateral head, left-side lying, right-side lying and prone.","meta":{"url":"http://arxiv.org/abs/2307.13346v1"},"cats":{"new-dataset":0.5225984418,"dev-research":0.1429445326,"prompt-eng":0.3603727491,"data-quality":0.1576660819,"ml-security":0.1325516762}}
{"text":"Experimental results show that snoring sounds exhibit certain acoustic features that enable their effective utilization for identifying body posture during sleep in real-world scenarios.","meta":{"url":"http://arxiv.org/abs/2307.13346v1"},"cats":{"new-dataset":0.0429810611,"dev-research":0.2124339097,"prompt-eng":0.3708755787,"data-quality":0.1545698547,"ml-security":0.1780751356}}
{"text":"Deep Learning models like Convolutional Neural Networks (CNN) are powerful image classifiers, but what factors determine whether they attend to similar image areas as humans do?","meta":{"url":"http://arxiv.org/abs/2307.13345v1"},"cats":{"new-dataset":0.0163801412,"dev-research":0.23478318,"prompt-eng":0.3290789648,"data-quality":0.1571620736,"ml-security":0.1576130545}}
{"text":"While previous studies have focused on technological factors, little is known about the role of factors that affect human attention.","meta":{"url":"http://arxiv.org/abs/2307.13345v1"},"cats":{"new-dataset":0.0120440006,"dev-research":0.2869545461,"prompt-eng":0.3498977558,"data-quality":0.1225941129,"ml-security":0.0830651414}}
{"text":"In the present study, we investigated how the tasks used to elicit human attention maps interact with image characteristics in modulating the similarity between humans and CNN.","meta":{"url":"http://arxiv.org/abs/2307.13345v1"},"cats":{"new-dataset":0.0290502428,"dev-research":0.2621273593,"prompt-eng":0.4577101838,"data-quality":0.1532176755,"ml-security":0.1074021818}}
{"text":"We varied the intentionality of human tasks, ranging from spontaneous gaze during categorization over intentional gaze-pointing up to manual area selection.","meta":{"url":"http://arxiv.org/abs/2307.13345v1"},"cats":{"new-dataset":0.0190718665,"dev-research":0.3120955045,"prompt-eng":0.481270047,"data-quality":0.1766034784,"ml-security":0.0947939911}}
{"text":"Moreover, we varied the type of image to be categorized, using either singular, salient objects, indoor scenes consisting of object arrangements, or landscapes without distinct objects defining the category.","meta":{"url":"http://arxiv.org/abs/2307.13345v1"},"cats":{"new-dataset":0.3583897361,"dev-research":0.1895123102,"prompt-eng":0.3909019028,"data-quality":0.1626703695,"ml-security":0.0679501122}}
{"text":"The human attention maps generated in this way were compared to the CNN attention maps revealed by explainable artificial intelligence (Grad-CAM).","meta":{"url":"http://arxiv.org/abs/2307.13345v1"},"cats":{"new-dataset":0.1169165014,"dev-research":0.2705490093,"prompt-eng":0.3701388753,"data-quality":0.1727308356,"ml-security":0.1601224802}}
{"text":"The influence of human tasks strongly depended on image type:","meta":{"url":"http://arxiv.org/abs/2307.13345v1"},"cats":{"new-dataset":0.0136217118,"dev-research":0.2398309868,"prompt-eng":0.3887100581,"data-quality":0.1098247632,"ml-security":0.0732837407}}
{"text":"For objects, human manual selection produced maps that were most similar to CNN, while the specific eye movement task has little impact.","meta":{"url":"http://arxiv.org/abs/2307.13345v1"},"cats":{"new-dataset":0.0217001156,"dev-research":0.2951919063,"prompt-eng":0.3729519276,"data-quality":0.1203383299,"ml-security":0.0679800464}}
{"text":"For indoor scenes, spontaneous gaze produced the least similarity, while for landscapes, similarity was equally low across all human tasks.","meta":{"url":"http://arxiv.org/abs/2307.13345v1"},"cats":{"new-dataset":0.0157265964,"dev-research":0.2628501357,"prompt-eng":0.3723822071,"data-quality":0.1529853824,"ml-security":0.043814989}}
{"text":"To better understand these results, we also compared the different human attention maps to each other.","meta":{"url":"http://arxiv.org/abs/2307.13345v1"},"cats":{"new-dataset":0.047729848,"dev-research":0.2221749928,"prompt-eng":0.3546999494,"data-quality":0.2157203626,"ml-security":0.0651795836}}
{"text":"Our results highlight the importance of taking human factors into account when comparing the attention of humans and CNN.","meta":{"url":"http://arxiv.org/abs/2307.13345v1"},"cats":{"new-dataset":0.1233295023,"dev-research":0.2656555826,"prompt-eng":0.3873362304,"data-quality":0.1996012131,"ml-security":0.087431693}}
{"text":"The local road network information is essential for autonomous navigation.","meta":{"url":"http://arxiv.org/abs/2307.13344v1"},"cats":{"new-dataset":0.0971316932,"dev-research":0.2394804856,"prompt-eng":0.3619673129,"data-quality":0.1220576263,"ml-security":0.1142333921}}
{"text":"This information is commonly obtained from offline HD-Maps in terms of lane graphs.","meta":{"url":"http://arxiv.org/abs/2307.13344v1"},"cats":{"new-dataset":0.5468087745,"dev-research":0.1626405417,"prompt-eng":0.3667958271,"data-quality":0.0973678128,"ml-security":0.037782401}}
{"text":"However, the local road network at a given moment can be drastically different than the one given in the offline maps; due to construction works, accidents etc.","meta":{"url":"http://arxiv.org/abs/2307.13344v1"},"cats":{"new-dataset":0.0665941279,"dev-research":0.2783127053,"prompt-eng":0.3096354313,"data-quality":0.1581650687,"ml-security":0.0791752183}}
{"text":"Moreover, the autonomous vehicle might be at a location not covered in the offline HD-Map.","meta":{"url":"http://arxiv.org/abs/2307.13344v1"},"cats":{"new-dataset":0.0547691794,"dev-research":0.1949213577,"prompt-eng":0.354387723,"data-quality":0.1531489311,"ml-security":0.1584271386}}
{"text":"Thus, online estimation of the lane graph is crucial for widespread and reliable autonomous navigation.","meta":{"url":"http://arxiv.org/abs/2307.13344v1"},"cats":{"new-dataset":0.1260108761,"dev-research":0.2037810529,"prompt-eng":0.3482240767,"data-quality":0.131982191,"ml-security":0.0625707354}}
{"text":"In this work, we tackle online Bird's-Eye-View lane graph extraction from a single onboard camera image.","meta":{"url":"http://arxiv.org/abs/2307.13344v1"},"cats":{"new-dataset":0.3933923873,"dev-research":0.1998730277,"prompt-eng":0.3635045091,"data-quality":0.1380917696,"ml-security":0.0528387999}}
{"text":"We propose to use prior information to increase quality of the estimations.","meta":{"url":"http://arxiv.org/abs/2307.13344v1"},"cats":{"new-dataset":0.0597909236,"dev-research":0.2432272534,"prompt-eng":0.443142937,"data-quality":0.2497868907,"ml-security":0.0943519858}}
{"text":"The prior is extracted from the dataset through a transformer based Wasserstein Autoencoder.","meta":{"url":"http://arxiv.org/abs/2307.13344v1"},"cats":{"new-dataset":0.3251841752,"dev-research":0.1657789037,"prompt-eng":0.4085726961,"data-quality":0.153111062,"ml-security":0.0735940614}}
{"text":"The autoencoder is then used to enhance the initial lane graph estimates.","meta":{"url":"http://arxiv.org/abs/2307.13344v1"},"cats":{"new-dataset":0.0792238494,"dev-research":0.2958784231,"prompt-eng":0.3833481502,"data-quality":0.1473439871,"ml-security":0.0567109457}}
{"text":"This is done through optimization of the latent space vector.","meta":{"url":"http://arxiv.org/abs/2307.13344v1"},"cats":{"new-dataset":0.023194354,"dev-research":0.1385137629,"prompt-eng":0.352720304,"data-quality":0.1696741067,"ml-security":0.108845978}}
{"text":"The optimization encourages the lane graph estimation to be logical by discouraging it to diverge from the prior distribution.","meta":{"url":"http://arxiv.org/abs/2307.13344v1"},"cats":{"new-dataset":0.012215588,"dev-research":0.2843297299,"prompt-eng":0.3550130524,"data-quality":0.1764537834,"ml-security":0.0973827435}}
{"text":"We test the method on two benchmark datasets, NuScenes and Argoverse.","meta":{"url":"http://arxiv.org/abs/2307.13344v1"},"cats":{"new-dataset":0.5648095946,"dev-research":0.1598270698,"prompt-eng":0.3506010665,"data-quality":0.1947159943,"ml-security":0.0603812899}}
{"text":"The results show that the proposed method significantly improves the performance compared to state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2307.13344v1"},"cats":{"new-dataset":0.0140606107,"dev-research":0.2521187291,"prompt-eng":0.4815719602,"data-quality":0.2226997749,"ml-security":0.0273769778}}
{"text":"Chain-of-thought (CoT) prompting has been shown to empirically improve the accuracy of large language models (LLMs) on various question answering tasks.","meta":{"url":"http://arxiv.org/abs/2307.13339v1"},"cats":{"new-dataset":0.0339367555,"dev-research":0.2348980945,"prompt-eng":0.5247047132,"data-quality":0.1933644243,"ml-security":0.0723025933}}
{"text":"While understanding why CoT prompting is effective is crucial to ensuring that this phenomenon is a consequence of desired model behavior, little work has addressed this; nonetheless, such an understanding is a critical prerequisite for responsible model deployment.","meta":{"url":"http://arxiv.org/abs/2307.13339v1"},"cats":{"new-dataset":0.0066750682,"dev-research":0.4804784859,"prompt-eng":0.5613647829,"data-quality":0.2184812183,"ml-security":0.2265378029}}
{"text":"We address this question by leveraging gradient-based feature attribution methods which produce saliency scores that capture the influence of input tokens on model output.","meta":{"url":"http://arxiv.org/abs/2307.13339v1"},"cats":{"new-dataset":0.0799848003,"dev-research":0.2701205146,"prompt-eng":0.4067830759,"data-quality":0.3652476109,"ml-security":0.1713046454}}
{"text":"Specifically, we probe several open-source LLMs to investigate whether CoT prompting affects the relative importances they assign to particular input tokens.","meta":{"url":"http://arxiv.org/abs/2307.13339v1"},"cats":{"new-dataset":0.0121762384,"dev-research":0.336678653,"prompt-eng":0.5769176414,"data-quality":0.2485197075,"ml-security":0.2172103546}}
{"text":"Our results indicate that while CoT prompting does not increase the magnitude of saliency scores attributed to semantically relevant tokens in the prompt compared to standard few-shot prompting, it increases the robustness of saliency scores to question perturbations and variations in model output.","meta":{"url":"http://arxiv.org/abs/2307.13339v1"},"cats":{"new-dataset":0.0565148051,"dev-research":0.3376524011,"prompt-eng":0.5454502643,"data-quality":0.3095509317,"ml-security":0.0992942347}}
{"text":"Quantization is a promising approach to reduce the high computational complexity of image super-resolution (SR) networks.","meta":{"url":"http://arxiv.org/abs/2307.13337v1"},"cats":{"new-dataset":0.0446273184,"dev-research":0.2339626949,"prompt-eng":0.316213429,"data-quality":0.1143512135,"ml-security":0.0889116216}}
{"text":"However, compared to high-level tasks like image classification, low-bit quantization leads to severe accuracy loss in SR networks.","meta":{"url":"http://arxiv.org/abs/2307.13337v1"},"cats":{"new-dataset":0.0311339186,"dev-research":0.2625363273,"prompt-eng":0.3490257605,"data-quality":0.3297951358,"ml-security":0.2214118961}}
{"text":"This is because feature distributions of SR networks are significantly divergent for each channel or input image, and is thus difficult to determine a quantization range.","meta":{"url":"http://arxiv.org/abs/2307.13337v1"},"cats":{"new-dataset":0.0198157447,"dev-research":0.2051906035,"prompt-eng":0.2891824736,"data-quality":0.2234228253,"ml-security":0.129784748}}
{"text":"Existing SR quantization works approach this distribution mismatch problem by dynamically adapting quantization ranges to the variant distributions during test time.","meta":{"url":"http://arxiv.org/abs/2307.13337v1"},"cats":{"new-dataset":0.076131532,"dev-research":0.2251858858,"prompt-eng":0.4269305381,"data-quality":0.3587152992,"ml-security":0.1722348015}}
{"text":"However, such dynamic adaptation incurs additional computational costs that limit the benefits of quantization.","meta":{"url":"http://arxiv.org/abs/2307.13337v1"},"cats":{"new-dataset":0.0136613181,"dev-research":0.2391516113,"prompt-eng":0.3636819457,"data-quality":0.1206656913,"ml-security":0.1448945664}}
{"text":"Instead, we propose a new quantization-aware training framework that effectively Overcomes the Distribution Mismatch problem in SR networks without the need for dynamic adaptation.","meta":{"url":"http://arxiv.org/abs/2307.13337v1"},"cats":{"new-dataset":0.0532964652,"dev-research":0.2519545837,"prompt-eng":0.3811421595,"data-quality":0.4690860935,"ml-security":0.3082443328}}
{"text":"Intuitively, the mismatch can be reduced by directly regularizing the variance in features during training.","meta":{"url":"http://arxiv.org/abs/2307.13337v1"},"cats":{"new-dataset":0.0077730838,"dev-research":0.3111332858,"prompt-eng":0.3928838083,"data-quality":0.5780587902,"ml-security":0.2622063534}}
{"text":"However, we observe that variance regularization can collide with the reconstruction loss during training and adversely impact SR accuracy.","meta":{"url":"http://arxiv.org/abs/2307.13337v1"},"cats":{"new-dataset":0.0197649855,"dev-research":0.2270313263,"prompt-eng":0.3471641448,"data-quality":0.2995284775,"ml-security":0.2476433997}}
{"text":"Thus, we avoid the conflict between two losses by regularizing the variance only when the gradients of variance regularization are cooperative with that of reconstruction.","meta":{"url":"http://arxiv.org/abs/2307.13337v1"},"cats":{"new-dataset":0.0203834618,"dev-research":0.1797502965,"prompt-eng":0.3541636744,"data-quality":0.2794879516,"ml-security":0.2878210351}}
{"text":"Additionally, to further reduce the distribution mismatch, we introduce distribution offsets to layers with a significant mismatch, which either scales or shifts channel-wise features.","meta":{"url":"http://arxiv.org/abs/2307.13337v1"},"cats":{"new-dataset":0.1219774294,"dev-research":0.2729929229,"prompt-eng":0.3950857313,"data-quality":0.2914317956,"ml-security":0.1463305007}}
{"text":"Our proposed algorithm, called ODM, effectively reduces the mismatch in distributions with minimal computational overhead.","meta":{"url":"http://arxiv.org/abs/2307.13337v1"},"cats":{"new-dataset":0.100295584,"dev-research":0.2378119278,"prompt-eng":0.4556741908,"data-quality":0.2719167631,"ml-security":0.0855793387}}
{"text":"Experimental results show that ODM effectively outperforms existing SR quantization approaches with similar or fewer computations, demonstrating the importance of reducing the distribution mismatch problem.","meta":{"url":"http://arxiv.org/abs/2307.13337v1"},"cats":{"new-dataset":0.0391402409,"dev-research":0.277822767,"prompt-eng":0.3853641206,"data-quality":0.1922031879,"ml-security":0.0979891985}}
{"text":"Our code is available at https://github.com/Cheeun/ODM.","meta":{"url":"http://arxiv.org/abs/2307.13337v1"},"cats":{"new-dataset":0.3118578454,"dev-research":0.1641310324,"prompt-eng":0.4606787673,"data-quality":0.0804904362,"ml-security":0.0374673134}}
{"text":"Random forest is effective for prediction tasks but the randomness of tree generation hinders interpretability in feature importance analysis.","meta":{"url":"http://arxiv.org/abs/2307.13333v1"},"cats":{"new-dataset":0.0138336313,"dev-research":0.319125166,"prompt-eng":0.3879956543,"data-quality":0.2535045662,"ml-security":0.2261871543}}
{"text":"To address this, we proposed DT-Sampler, a SAT-based method for measuring feature importance in tree-based model.","meta":{"url":"http://arxiv.org/abs/2307.13333v1"},"cats":{"new-dataset":0.0483112975,"dev-research":0.3155777579,"prompt-eng":0.4402053846,"data-quality":0.1948620098,"ml-security":0.0742374263}}
{"text":"Our method has fewer parameters than random forest and provides higher interpretability and stability for the analysis in real-world problems.","meta":{"url":"http://arxiv.org/abs/2307.13333v1"},"cats":{"new-dataset":0.13455879,"dev-research":0.2022512153,"prompt-eng":0.3457160414,"data-quality":0.2594735617,"ml-security":0.1367277208}}
{"text":"An implementation of DT-Sampler is available at https://github.com/tsudalab/DT-sampler.","meta":{"url":"http://arxiv.org/abs/2307.13333v1"},"cats":{"new-dataset":0.3572974761,"dev-research":0.1812223894,"prompt-eng":0.4738334998,"data-quality":0.1290032295,"ml-security":0.027806776}}
{"text":"Theoretical guarantees in reinforcement learning (RL) are known to suffer multiplicative blow-up factors with respect to the misspecification error of function approximation.","meta":{"url":"http://arxiv.org/abs/2307.13332v1"},"cats":{"new-dataset":0.027727949,"dev-research":0.1812651922,"prompt-eng":0.3259415337,"data-quality":0.1385349434,"ml-security":0.270849839}}
{"text":"Yet, the nature of such \\emph{approximation factors} -- especially their optimal form in a given learning problem -- is poorly understood.","meta":{"url":"http://arxiv.org/abs/2307.13332v1"},"cats":{"new-dataset":0.0191539333,"dev-research":0.1448434252,"prompt-eng":0.3509646677,"data-quality":0.1872772307,"ml-security":0.1120763595}}
{"text":"In this paper we study this question in linear off-policy value function estimation, where many open questions remain.","meta":{"url":"http://arxiv.org/abs/2307.13332v1"},"cats":{"new-dataset":0.2766942115,"dev-research":0.1524835539,"prompt-eng":0.3975020343,"data-quality":0.1781298536,"ml-security":0.150722699}}
{"text":"We study the approximation factor in a broad spectrum of settings, such as with the weighted $L_2$-norm (where the weighting is the offline state distribution), the $L_\\infty$ norm, the presence vs. absence of state aliasing, and full vs. partial coverage of the state space.","meta":{"url":"http://arxiv.org/abs/2307.13332v1"},"cats":{"new-dataset":0.1213580473,"dev-research":0.164376778,"prompt-eng":0.3746465755,"data-quality":0.1324840459,"ml-security":0.1031678999}}
{"text":"We establish the optimal asymptotic approximation factors (up to constants) for all of these settings.","meta":{"url":"http://arxiv.org/abs/2307.13332v1"},"cats":{"new-dataset":0.1083155978,"dev-research":0.124806104,"prompt-eng":0.3487877387,"data-quality":0.1181688287,"ml-security":0.1040268159}}
{"text":"In particular, our bounds identify two instance-dependent factors for the $L_2(\\mu)$ norm and only one for the $L_\\infty$ norm, which are shown to dictate the hardness of off-policy evaluation under misspecification.","meta":{"url":"http://arxiv.org/abs/2307.13332v1"},"cats":{"new-dataset":0.0787513949,"dev-research":0.1890218094,"prompt-eng":0.3601847188,"data-quality":0.2335978238,"ml-security":0.2149098576}}
{"text":"As medical ultrasound is becoming a prevailing examination approach nowadays, robotic ultrasound systems can facilitate the scanning process and prevent professional sonographers from repetitive and tedious work.","meta":{"url":"http://arxiv.org/abs/2307.13323v1"},"cats":{"new-dataset":0.0177641163,"dev-research":0.2681744816,"prompt-eng":0.4513868361,"data-quality":0.0713604423,"ml-security":0.0766994191}}
{"text":"Despite the recent progress, it is still a challenge to enable robots to autonomously accomplish the ultrasound examination, which is largely due to the lack of a proper task representation method, and also an adaptation approach to generalize learned skills across different patients.","meta":{"url":"http://arxiv.org/abs/2307.13323v1"},"cats":{"new-dataset":0.0415379821,"dev-research":0.2491501183,"prompt-eng":0.4356903329,"data-quality":0.108836864,"ml-security":0.1164467571}}
{"text":"To solve these problems, we propose the latent task representation and the robotic skills adaptation for autonomous ultrasound in this paper.","meta":{"url":"http://arxiv.org/abs/2307.13323v1"},"cats":{"new-dataset":0.0651803402,"dev-research":0.2171032464,"prompt-eng":0.4171312403,"data-quality":0.1001267499,"ml-security":0.0538261681}}
{"text":"During the offline stage, the multimodal ultrasound skills are merged and encapsulated into a low-dimensional probability model through a fully self-supervised framework, which takes clinically demonstrated ultrasound images, probe orientations, and contact forces into account.","meta":{"url":"http://arxiv.org/abs/2307.13323v1"},"cats":{"new-dataset":0.1692171826,"dev-research":0.2082396183,"prompt-eng":0.4314342911,"data-quality":0.0870981572,"ml-security":0.0705956687}}
{"text":"During the online stage, the probability model will select and evaluate the optimal prediction.","meta":{"url":"http://arxiv.org/abs/2307.13323v1"},"cats":{"new-dataset":0.0106620129,"dev-research":0.1998237536,"prompt-eng":0.4416166747,"data-quality":0.0917147079,"ml-security":0.0858701682}}
{"text":"For unstable singularities, the adaptive optimizer fine-tunes them to near and stable predictions in high-confidence regions.","meta":{"url":"http://arxiv.org/abs/2307.13323v1"},"cats":{"new-dataset":0.0562289751,"dev-research":0.2430266325,"prompt-eng":0.4016888041,"data-quality":0.1970344459,"ml-security":0.2328750892}}
{"text":"Experimental results show that the proposed approach can generate complex ultrasound strategies for diverse populations and achieve significantly better quantitative results than our previous method.","meta":{"url":"http://arxiv.org/abs/2307.13323v1"},"cats":{"new-dataset":0.151349197,"dev-research":0.2150373904,"prompt-eng":0.407320507,"data-quality":0.071050045,"ml-security":0.0606165255}}
{"text":"For the discrete-time AWGN channel with a power constraint, we give an alternative derivation of Shannon's sphere-packing upper bound on the optimal block error exponent and prove for the first time an analogous lower bound on the optimal correct-decoding exponent.","meta":{"url":"http://arxiv.org/abs/2307.13322v1"},"cats":{"new-dataset":0.0745909423,"dev-research":0.1803787469,"prompt-eng":0.3239198407,"data-quality":0.1770340309,"ml-security":0.1098823126}}
{"text":"The derivations use the method of types with finite alphabets of sizes depending on the block length n and with the number of types sub-exponential in n.","meta":{"url":"http://arxiv.org/abs/2307.13322v1"},"cats":{"new-dataset":0.0832702182,"dev-research":0.2405935885,"prompt-eng":0.3230236695,"data-quality":0.0891473993,"ml-security":0.0882732994}}
{"text":"Invariant generation is the classical problem that aims at automated generation of assertions that over-approximates the set of reachable program states in a program.","meta":{"url":"http://arxiv.org/abs/2307.13318v1"},"cats":{"new-dataset":0.0755656752,"dev-research":0.4126689446,"prompt-eng":0.447309249,"data-quality":0.2475871625,"ml-security":0.2734820939}}
{"text":"We consider the problem of generating affine invariants over affine while loops (i.e., loops with affine loop guards, conditional branches and assignment statements), and explore the automated generation of disjunctive affine invariants.","meta":{"url":"http://arxiv.org/abs/2307.13318v1"},"cats":{"new-dataset":0.214996696,"dev-research":0.351628385,"prompt-eng":0.4322497249,"data-quality":0.1790973397,"ml-security":0.1427960224}}
{"text":"Disjunctive invariants are an important class of invariants that capture disjunctive features in programs such as multiple phases, transitions between different modes, etc., and are typically more precise than conjunctive invariants over programs with these features.","meta":{"url":"http://arxiv.org/abs/2307.13318v1"},"cats":{"new-dataset":0.0579067492,"dev-research":0.3780308982,"prompt-eng":0.4258537136,"data-quality":0.1643967844,"ml-security":0.1908020881}}
{"text":"To generate tight affine invariants, existing constraint-solving approaches have investigated the application of Farkas' Lemma to conjunctive affine invariant generation, but none of them considers disjunctive affine invariants.","meta":{"url":"http://arxiv.org/abs/2307.13318v1"},"cats":{"new-dataset":0.1515059889,"dev-research":0.2623284173,"prompt-eng":0.3799381699,"data-quality":0.1511590575,"ml-security":0.1137887769}}
{"text":"Anomaly segmentation is a critical task for driving applications, and it is approached traditionally as a per-pixel classification problem.","meta":{"url":"http://arxiv.org/abs/2307.13316v1"},"cats":{"new-dataset":0.0969847686,"dev-research":0.2476683463,"prompt-eng":0.377344231,"data-quality":0.4141325758,"ml-security":0.3483233084}}
{"text":"However, reasoning individually about each pixel without considering their contextual semantics results in high uncertainty around the objects' boundaries and numerous false positives.","meta":{"url":"http://arxiv.org/abs/2307.13316v1"},"cats":{"new-dataset":0.049442466,"dev-research":0.284079582,"prompt-eng":0.3835668566,"data-quality":0.3095358866,"ml-security":0.144440819}}
{"text":"We propose a paradigm change by shifting from a per-pixel classification to a mask classification.","meta":{"url":"http://arxiv.org/abs/2307.13316v1"},"cats":{"new-dataset":0.1185552653,"dev-research":0.2071550213,"prompt-eng":0.3741025141,"data-quality":0.2832700731,"ml-security":0.2331495046}}
{"text":"Our mask-based method, Mask2Anomaly, demonstrates the feasibility of integrating an anomaly detection method in a mask-classification architecture.","meta":{"url":"http://arxiv.org/abs/2307.13316v1"},"cats":{"new-dataset":0.1169252727,"dev-research":0.3173649123,"prompt-eng":0.4007406668,"data-quality":0.4158219838,"ml-security":0.5890483873}}
{"text":"Mask2Anomaly includes several technical novelties that are designed to improve the detection of anomalies in masks: i) a global masked attention module to focus individually on the foreground and background regions; ii) a mask contrastive learning that maximizes the margin between an anomaly and known classes; and iii) a mask refinement solution to reduce false positives.","meta":{"url":"http://arxiv.org/abs/2307.13316v1"},"cats":{"new-dataset":0.1771297005,"dev-research":0.3034397758,"prompt-eng":0.410485101,"data-quality":0.3816911918,"ml-security":0.3693054991}}
{"text":"Mask2Anomaly achieves new state-of-the-art results across a range of benchmarks, both in the per-pixel and component-level evaluations.","meta":{"url":"http://arxiv.org/abs/2307.13316v1"},"cats":{"new-dataset":0.1956188947,"dev-research":0.2257519785,"prompt-eng":0.3770370565,"data-quality":0.1844710887,"ml-security":0.0967949374}}
{"text":"In particular, Mask2Anomaly reduces the average false positives rate by 60% wrt","meta":{"url":"http://arxiv.org/abs/2307.13316v1"},"cats":{"new-dataset":0.0079399467,"dev-research":0.2247978728,"prompt-eng":0.4018048298,"data-quality":0.307050642,"ml-security":0.2797690325}}
{"text":"the previous state-of-the-art.","meta":{"url":"http://arxiv.org/abs/2307.13316v1"},"cats":{"new-dataset":0.1759227789,"dev-research":0.2236282402,"prompt-eng":0.4069987476,"data-quality":0.1747822626,"ml-security":0.0559515396}}
{"text":"Github page: https://github.com/shyam671/Mask2Anomaly-Unmasking-Anomalies-in-Road-Scene-Segmentation.","meta":{"url":"http://arxiv.org/abs/2307.13316v1"},"cats":{"new-dataset":0.4202105382,"dev-research":0.1621280848,"prompt-eng":0.3951938628,"data-quality":0.3269258478,"ml-security":0.1750411503}}
{"text":"Machine learning makes multimedia data (e.g., images) more attractive, however, multimedia data is usually distributed and privacy sensitive.","meta":{"url":"http://arxiv.org/abs/2307.13314v1"},"cats":{"new-dataset":0.0565973734,"dev-research":0.2270549205,"prompt-eng":0.3131864938,"data-quality":0.2265088274,"ml-security":0.4047743015}}
{"text":"Multiple distributed multimedia clients can resort to federated learning (FL) to jointly learn a global shared model without requiring to share their private samples with any third-party entities.","meta":{"url":"http://arxiv.org/abs/2307.13314v1"},"cats":{"new-dataset":0.1771110018,"dev-research":0.2067392932,"prompt-eng":0.3637594734,"data-quality":0.1627141598,"ml-security":0.1429969488}}
{"text":"In this paper, we show that FL suffers from the cross-client generative adversarial networks (GANs)-based (C-GANs) attack, in which a malicious client (i.e., adversary) can reconstruct samples with the same distribution as the training samples from other clients (i.e., victims).","meta":{"url":"http://arxiv.org/abs/2307.13314v1"},"cats":{"new-dataset":0.1267300875,"dev-research":0.2589855284,"prompt-eng":0.3277480492,"data-quality":0.2983602213,"ml-security":0.8086375614}}
{"text":"Since a benign client's data can be leaked to the adversary, this attack brings the risk of local data leakage for clients in many security-critical FL applications.","meta":{"url":"http://arxiv.org/abs/2307.13314v1"},"cats":{"new-dataset":0.0731475237,"dev-research":0.3447468143,"prompt-eng":0.3722925653,"data-quality":0.2877636705,"ml-security":0.7952777674}}
{"text":"Thus, we propose Fed-EDKD (i.e., Federated Ensemble Data-free Knowledge Distillation) technique to improve the current popular FL schemes to resist C-GANs attack.","meta":{"url":"http://arxiv.org/abs/2307.13314v1"},"cats":{"new-dataset":0.1701261391,"dev-research":0.2912425837,"prompt-eng":0.3239945419,"data-quality":0.1622678484,"ml-security":0.4304991833}}
{"text":"In Fed-EDKD, each client submits a local model to the server for obtaining an ensemble global model.","meta":{"url":"http://arxiv.org/abs/2307.13314v1"},"cats":{"new-dataset":0.2468307263,"dev-research":0.2233598748,"prompt-eng":0.4184255619,"data-quality":0.1173089951,"ml-security":0.1123885085}}
{"text":"Then, to avoid model expansion, Fed-EDKD adopts data-free knowledge distillation techniques to transfer knowledge from the ensemble global model to a compressed model.","meta":{"url":"http://arxiv.org/abs/2307.13314v1"},"cats":{"new-dataset":0.1223736616,"dev-research":0.2770209149,"prompt-eng":0.3429246316,"data-quality":0.1593750158,"ml-security":0.1378096689}}
{"text":"By this way, Fed-EDKD reduces the adversary's control capability over the global model, so Fed-EDKD can effectively mitigate C-GANs attack.","meta":{"url":"http://arxiv.org/abs/2307.13314v1"},"cats":{"new-dataset":0.024206117,"dev-research":0.3334791186,"prompt-eng":0.3250105096,"data-quality":0.1694894827,"ml-security":0.490816423}}
{"text":"Finally, the experimental results demonstrate that Fed-EDKD significantly mitigates C-GANs attack while only incurring a slight accuracy degradation of FL.","meta":{"url":"http://arxiv.org/abs/2307.13314v1"},"cats":{"new-dataset":0.058871955,"dev-research":0.3358169058,"prompt-eng":0.3438634457,"data-quality":0.2475156502,"ml-security":0.5045314981}}
{"text":"Contour based scene text detection methods have rapidly developed recently, but still suffer from inaccurate frontend contour initialization, multi-stage error accumulation, or deficient local information aggregation.","meta":{"url":"http://arxiv.org/abs/2307.13310v1"},"cats":{"new-dataset":0.1508428432,"dev-research":0.1884958323,"prompt-eng":0.3943305517,"data-quality":0.5113609566,"ml-security":0.0830383504}}
{"text":"To tackle these limitations, we propose a novel arbitrary-shaped scene text detection framework named CT-Net by progressive contour regression with contour transformers.","meta":{"url":"http://arxiv.org/abs/2307.13310v1"},"cats":{"new-dataset":0.2349621848,"dev-research":0.1861305534,"prompt-eng":0.3581189169,"data-quality":0.3429138486,"ml-security":0.1006652131}}
{"text":"Specifically, we first employ a contour initialization module that generates coarse text contours without any post-processing.","meta":{"url":"http://arxiv.org/abs/2307.13310v1"},"cats":{"new-dataset":0.1635998397,"dev-research":0.2404795212,"prompt-eng":0.4276210281,"data-quality":0.1824529055,"ml-security":0.0555098842}}
{"text":"Then, we adopt contour refinement modules to adaptively refine text contours in an iterative manner, which are beneficial for context information capturing and progressive global contour deformation.","meta":{"url":"http://arxiv.org/abs/2307.13310v1"},"cats":{"new-dataset":0.1266223604,"dev-research":0.2954686015,"prompt-eng":0.4143634051,"data-quality":0.2241795022,"ml-security":0.0484101779}}
{"text":"Besides, we propose an adaptive training strategy to enable the contour transformers to learn more potential deformation paths, and introduce a re-score mechanism that can effectively suppress false positives.","meta":{"url":"http://arxiv.org/abs/2307.13310v1"},"cats":{"new-dataset":0.0530278981,"dev-research":0.2518244908,"prompt-eng":0.4472545338,"data-quality":0.2771541532,"ml-security":0.1546663194}}
{"text":"Extensive experiments are conducted on four challenging datasets, which demonstrate the accuracy and efficiency of our CT-Net over state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2307.13310v1"},"cats":{"new-dataset":0.3800542068,"dev-research":0.217295646,"prompt-eng":0.3623419188,"data-quality":0.1745793192,"ml-security":0.0809981019}}
{"text":"Particularly, CT-Net achieves F-measure of 86.1 at 11.2 frames per second (FPS) and F-measure of 87.8 at 10.1 FPS for CTW1500 and Total-Text datasets, respectively.","meta":{"url":"http://arxiv.org/abs/2307.13310v1"},"cats":{"new-dataset":0.3726692308,"dev-research":0.2028705,"prompt-eng":0.3822610876,"data-quality":0.1354271998,"ml-security":0.0447675045}}
{"text":"This work studies post-training parameter quantization in large language models (LLMs).","meta":{"url":"http://arxiv.org/abs/2307.13304v1"},"cats":{"new-dataset":0.0972797522,"dev-research":0.1582127189,"prompt-eng":0.3982550065,"data-quality":0.2841981375,"ml-security":0.1529438163}}
{"text":"We introduce quantization with incoherence processing (QuIP), a new method based on the insight that quantization benefits from incoherent weight and Hessian matrices, i.e., from the weights and the directions in which it is important to round them accurately being unaligned with the coordinate axes.","meta":{"url":"http://arxiv.org/abs/2307.13304v1"},"cats":{"new-dataset":0.0257483462,"dev-research":0.2151162296,"prompt-eng":0.3645243718,"data-quality":0.2201013579,"ml-security":0.1611529226}}
{"text":"QuIP consists of two steps: (1) an adaptive rounding procedure minimizing a quadratic proxy objective; (2) efficient pre- and post-processing that ensures weight and Hessian incoherence via multiplication by random orthogonal matrices.","meta":{"url":"http://arxiv.org/abs/2307.13304v1"},"cats":{"new-dataset":0.0460700178,"dev-research":0.2659638154,"prompt-eng":0.448724775,"data-quality":0.1269508721,"ml-security":0.0750281373}}
{"text":"We complement QuIP with the first theoretical analysis for an LLM-scale quantization algorithm, and show that our theory also applies to an existing method, OPTQ.","meta":{"url":"http://arxiv.org/abs/2307.13304v1"},"cats":{"new-dataset":0.0926675338,"dev-research":0.1561173524,"prompt-eng":0.382410002,"data-quality":0.2026366027,"ml-security":0.0907970022}}
{"text":"Empirically, we find that our incoherence preprocessing improves several existing quantization algorithms and yields the first LLM quantization methods that produce viable results using only two bits per weight.","meta":{"url":"http://arxiv.org/abs/2307.13304v1"},"cats":{"new-dataset":0.0983954431,"dev-research":0.2483948894,"prompt-eng":0.3937131383,"data-quality":0.2812229522,"ml-security":0.1646684433}}
{"text":"Our code can be found at https://github.com/jerry-chee/QuIP .","meta":{"url":"http://arxiv.org/abs/2307.13304v1"},"cats":{"new-dataset":0.416204281,"dev-research":0.1693568139,"prompt-eng":0.4677376553,"data-quality":0.1156209411,"ml-security":0.0366858125}}
{"text":"Common deep learning models for 3D environment perception often use pillarization/voxelization methods to convert point cloud data into pillars/voxels and then process it with a 2D/3D convolutional neural network (CNN).","meta":{"url":"http://arxiv.org/abs/2307.13300v1"},"cats":{"new-dataset":0.1844230766,"dev-research":0.2166762056,"prompt-eng":0.3256228084,"data-quality":0.0845434309,"ml-security":0.1165982631}}
{"text":"The pioneer work PointNet has been widely applied as a local feature descriptor, a fundamental component in deep learning models for 3D perception, to extract features of a point cloud.","meta":{"url":"http://arxiv.org/abs/2307.13300v1"},"cats":{"new-dataset":0.2061326833,"dev-research":0.2277980917,"prompt-eng":0.3384522956,"data-quality":0.1559329403,"ml-security":0.1124319742}}
{"text":"This is achieved by using a symmetric max-pooling operator which provides unique pillar/voxel features.","meta":{"url":"http://arxiv.org/abs/2307.13300v1"},"cats":{"new-dataset":0.1182261763,"dev-research":0.1770025133,"prompt-eng":0.3825547544,"data-quality":0.0989826556,"ml-security":0.0456086494}}
{"text":"However, by ignoring most of the points, the max-pooling operator causes an information loss, which reduces the model performance.","meta":{"url":"http://arxiv.org/abs/2307.13300v1"},"cats":{"new-dataset":0.0055806524,"dev-research":0.2116466343,"prompt-eng":0.3416084207,"data-quality":0.2081063807,"ml-security":0.1427880957}}
{"text":"To address this issue, we propose a novel local feature descriptor, mini-PointNetPlus, as an alternative for plug-and-play to PointNet.","meta":{"url":"http://arxiv.org/abs/2307.13300v1"},"cats":{"new-dataset":0.1745258201,"dev-research":0.3279098605,"prompt-eng":0.440218775,"data-quality":0.2715699593,"ml-security":0.0966264849}}
{"text":"Our basic idea is to separately project the data points to the individual features considered, each leading to a permutation invariant.","meta":{"url":"http://arxiv.org/abs/2307.13300v1"},"cats":{"new-dataset":0.3162718017,"dev-research":0.2134751641,"prompt-eng":0.4058616149,"data-quality":0.1564679935,"ml-security":0.1075107324}}
{"text":"Thus, the proposed descriptor transforms an unordered point cloud to a stable order.","meta":{"url":"http://arxiv.org/abs/2307.13300v1"},"cats":{"new-dataset":0.1566646929,"dev-research":0.1669891251,"prompt-eng":0.3840482005,"data-quality":0.109061151,"ml-security":0.0687959287}}
{"text":"The vanilla PointNet is proved to be a special case of our mini-PointNetPlus.","meta":{"url":"http://arxiv.org/abs/2307.13300v1"},"cats":{"new-dataset":0.2653423027,"dev-research":0.1582019683,"prompt-eng":0.3276669484,"data-quality":0.2136112856,"ml-security":0.1814397967}}
{"text":"Due to fully utilizing the features by the proposed descriptor, we demonstrate in experiment a considerable performance improvement for 3D perception.","meta":{"url":"http://arxiv.org/abs/2307.13300v1"},"cats":{"new-dataset":0.072748335,"dev-research":0.2310626571,"prompt-eng":0.4144864439,"data-quality":0.1453066552,"ml-security":0.0718262536}}
{"text":"Legal case retrieval is a special Information Retrieval~(IR) task focusing on legal case documents.","meta":{"url":"http://arxiv.org/abs/2307.13298v1"},"cats":{"new-dataset":0.1122575067,"dev-research":0.2423246241,"prompt-eng":0.394129451,"data-quality":0.1527036462,"ml-security":0.0685906937}}
{"text":"Depending on the downstream tasks of the retrieved case documents, users' information needs in legal case retrieval could be significantly different from those in Web search and traditional ad-hoc retrieval tasks.","meta":{"url":"http://arxiv.org/abs/2307.13298v1"},"cats":{"new-dataset":0.0545200476,"dev-research":0.2209554163,"prompt-eng":0.4136820162,"data-quality":0.1339164479,"ml-security":0.0872757369}}
{"text":"While there are several studies that retrieve legal cases based on text similarity, the underlying search intents of legal retrieval users, as shown in this paper, are more complicated than that yet mostly unexplored.","meta":{"url":"http://arxiv.org/abs/2307.13298v1"},"cats":{"new-dataset":0.0948028223,"dev-research":0.2029916047,"prompt-eng":0.3578246107,"data-quality":0.1843451097,"ml-security":0.1540474481}}
{"text":"To this end, we present a novel hierarchical intent taxonomy of legal case retrieval.","meta":{"url":"http://arxiv.org/abs/2307.13298v1"},"cats":{"new-dataset":0.2071381496,"dev-research":0.2041216051,"prompt-eng":0.391534855,"data-quality":0.1594389252,"ml-security":0.0839916862}}
{"text":"It consists of five intent types categorized by three criteria, i.e., search for Particular Case(s), Characterization, Penalty, Procedure, and Interest.","meta":{"url":"http://arxiv.org/abs/2307.13298v1"},"cats":{"new-dataset":0.0584709666,"dev-research":0.2052750413,"prompt-eng":0.4137025911,"data-quality":0.0773808849,"ml-security":0.0529448424}}
{"text":"The taxonomy was constructed transparently and evaluated extensively through interviews, editorial user studies, and query log analysis.","meta":{"url":"http://arxiv.org/abs/2307.13298v1"},"cats":{"new-dataset":0.1407935981,"dev-research":0.2715382686,"prompt-eng":0.4226466145,"data-quality":0.1731306934,"ml-security":0.0720904915}}
{"text":"Through a laboratory user study, we reveal significant differences in user behavior and satisfaction under different search intents in legal case retrieval.","meta":{"url":"http://arxiv.org/abs/2307.13298v1"},"cats":{"new-dataset":0.0204016719,"dev-research":0.2654941697,"prompt-eng":0.4318276675,"data-quality":0.1821207674,"ml-security":0.0756514934}}
{"text":"Furthermore, we apply the proposed taxonomy to various downstream legal retrieval tasks, e.g., result ranking and satisfaction prediction, and demonstrate its effectiveness.","meta":{"url":"http://arxiv.org/abs/2307.13298v1"},"cats":{"new-dataset":0.1014428421,"dev-research":0.2138562121,"prompt-eng":0.4271124597,"data-quality":0.2347433987,"ml-security":0.0571210011}}
{"text":"Our work provides important insights into the understanding of user intents in legal case retrieval and potentially leads to better retrieval techniques in the legal domain, such as intent-aware ranking strategies and evaluation methodologies.","meta":{"url":"http://arxiv.org/abs/2307.13298v1"},"cats":{"new-dataset":0.0824855296,"dev-research":0.2516017944,"prompt-eng":0.4023651659,"data-quality":0.1705396253,"ml-security":0.0895579321}}
{"text":"Recently, speech codecs based on neural networks have proven to perform better than traditional methods.","meta":{"url":"http://arxiv.org/abs/2307.13295v1"},"cats":{"new-dataset":0.0809234171,"dev-research":0.2841784298,"prompt-eng":0.3157624501,"data-quality":0.2669238406,"ml-security":0.1152289262}}
{"text":"However, redundancy in traditional parameter quantization is visible within the codec architecture of combining the traditional codec with the neural vocoder.","meta":{"url":"http://arxiv.org/abs/2307.13295v1"},"cats":{"new-dataset":0.0425255914,"dev-research":0.2981143246,"prompt-eng":0.3624066899,"data-quality":0.2416938651,"ml-security":0.1900835335}}
{"text":"In this paper, we propose a novel framework named CQNV, which combines the coarsely quantized parameters of a traditional parametric codec to reduce the bitrate with a neural vocoder to improve the quality of the decoded speech.","meta":{"url":"http://arxiv.org/abs/2307.13295v1"},"cats":{"new-dataset":0.262133922,"dev-research":0.2539743653,"prompt-eng":0.3421100349,"data-quality":0.1804757826,"ml-security":0.14615872}}
{"text":"Furthermore, we introduce a parameters processing module into the neural vocoder to enhance the application of the bitstream of traditional speech coding parameters to the neural vocoder, further improving the reconstructed speech's quality.","meta":{"url":"http://arxiv.org/abs/2307.13295v1"},"cats":{"new-dataset":0.1772113998,"dev-research":0.2757461454,"prompt-eng":0.3657699769,"data-quality":0.2093009324,"ml-security":0.1373151701}}
{"text":"In the experiments, both subjective and objective evaluations demonstrate the effectiveness of the proposed CQNV framework.","meta":{"url":"http://arxiv.org/abs/2307.13295v1"},"cats":{"new-dataset":0.0295719273,"dev-research":0.302768038,"prompt-eng":0.4406447209,"data-quality":0.223063993,"ml-security":0.0581384037}}
{"text":"Specifically, our proposed method can achieve higher quality reconstructed speech at 1.1 kbps than Lyra and Encodec at 3 kbps.","meta":{"url":"http://arxiv.org/abs/2307.13295v1"},"cats":{"new-dataset":0.1571545904,"dev-research":0.2120525308,"prompt-eng":0.3483541711,"data-quality":0.1539147118,"ml-security":0.06054256}}
{"text":"Although face recognition starts to play an important role in our daily life, we need to pay attention that data-driven face recognition vision systems are vulnerable to adversarial attacks.","meta":{"url":"http://arxiv.org/abs/2307.13294v1"},"cats":{"new-dataset":0.1077338322,"dev-research":0.24188035,"prompt-eng":0.3301529281,"data-quality":0.2722191713,"ml-security":0.7515949917}}
{"text":"However, the current two categories of adversarial attacks, namely digital attacks and physical attacks both have drawbacks, with the former ones impractical and the latter one conspicuous, high-computational and inexecutable.","meta":{"url":"http://arxiv.org/abs/2307.13294v1"},"cats":{"new-dataset":0.0476328363,"dev-research":0.2673905623,"prompt-eng":0.30317946,"data-quality":0.2319344551,"ml-security":0.8563961736}}
{"text":"To address the issues, we propose a practical, executable, inconspicuous and low computational adversarial attack based on LED illumination modulation.","meta":{"url":"http://arxiv.org/abs/2307.13294v1"},"cats":{"new-dataset":0.1113407202,"dev-research":0.273523234,"prompt-eng":0.3667772685,"data-quality":0.2288261644,"ml-security":0.7636365254}}
{"text":"To fool the systems, the proposed attack generates imperceptible luminance changes to human eyes through fast intensity modulation of scene LED illumination and uses the rolling shutter effect of CMOS image sensors in face recognition systems to implant luminance information perturbation to the captured face images.","meta":{"url":"http://arxiv.org/abs/2307.13294v1"},"cats":{"new-dataset":0.0561314362,"dev-research":0.231231044,"prompt-eng":0.4258584207,"data-quality":0.1542182008,"ml-security":0.5867237659}}
{"text":"In summary,we present a denial-of-service (DoS) attack for face detection and a dodging attack for face verification.","meta":{"url":"http://arxiv.org/abs/2307.13294v1"},"cats":{"new-dataset":0.0850683318,"dev-research":0.2336953604,"prompt-eng":0.3910241376,"data-quality":0.2118108172,"ml-security":0.637360225}}
{"text":"We also evaluate their effectiveness against well-known face detection models, Dlib, MTCNN and RetinaFace , and face verification models, Dlib, FaceNet,and ArcFace.","meta":{"url":"http://arxiv.org/abs/2307.13294v1"},"cats":{"new-dataset":0.1363980269,"dev-research":0.2764641615,"prompt-eng":0.4196156616,"data-quality":0.2043801915,"ml-security":0.2218415848}}
{"text":"The extensive experiments show that the success rates of DoS attacks against face detection models reach 97.67%, 100%, and 100%, respectively, and the success rates of dodging attacks against all face verification models reach 100%.","meta":{"url":"http://arxiv.org/abs/2307.13294v1"},"cats":{"new-dataset":0.0314943287,"dev-research":0.2500076453,"prompt-eng":0.4133132279,"data-quality":0.2579925456,"ml-security":0.7112749208}}
{"text":"Probabilistic shaping is a pragmatic approach to improve the performance of coherent optical fiber communication systems.","meta":{"url":"http://arxiv.org/abs/2307.13292v1"},"cats":{"new-dataset":0.0110741,"dev-research":0.300250912,"prompt-eng":0.4089063588,"data-quality":0.1331263801,"ml-security":0.0546668048}}
{"text":"In the nonlinear regime, the advantages offered by probabilistic shaping might increase thanks to the opportunity to obtain an additional nonlinear shaping gain.","meta":{"url":"http://arxiv.org/abs/2307.13292v1"},"cats":{"new-dataset":0.0111646607,"dev-research":0.1879234313,"prompt-eng":0.3912308955,"data-quality":0.1055405554,"ml-security":0.1037733648}}
{"text":"Unfortunately, the optimization of conventional shaping techniques, such as probabilistic amplitude shaping (PAS), yields a relevant nonlinear shaping gain only in scenarios of limited practical interest.","meta":{"url":"http://arxiv.org/abs/2307.13292v1"},"cats":{"new-dataset":0.0169188061,"dev-research":0.2149801472,"prompt-eng":0.4150175981,"data-quality":0.1308500846,"ml-security":0.09200804}}
{"text":"In this manuscript we use sequence selection to investigate the potential, opportunities, and challenges offered by nonlinear probabilistic shaping.","meta":{"url":"http://arxiv.org/abs/2307.13292v1"},"cats":{"new-dataset":0.044450281,"dev-research":0.1866460528,"prompt-eng":0.4239983158,"data-quality":0.1348388051,"ml-security":0.0843121402}}
{"text":"First, we show that ideal sequence selection is able to provide up to 0.13 bit/s/Hz gain with respect to PAS with an optimized blocklength.","meta":{"url":"http://arxiv.org/abs/2307.13292v1"},"cats":{"new-dataset":0.1218034274,"dev-research":0.1769208347,"prompt-eng":0.408865482,"data-quality":0.1184542843,"ml-security":0.0891977353}}
{"text":"However, this additional gain is obtained only if the selection metric accounts for the signs of the symbols: they must be known to compute the selection metric, but there is no need to shape them.","meta":{"url":"http://arxiv.org/abs/2307.13292v1"},"cats":{"new-dataset":0.0065362729,"dev-research":0.1577048286,"prompt-eng":0.3940803468,"data-quality":0.1805887072,"ml-security":0.1267053581}}
{"text":"Furthermore, we show that the selection depends in a non-critical way on the symbol rate and link length: the sequences selected for a certain scenario still provide a relevant gain if these are modified.","meta":{"url":"http://arxiv.org/abs/2307.13292v1"},"cats":{"new-dataset":0.0254774635,"dev-research":0.1649135405,"prompt-eng":0.4107316238,"data-quality":0.1659475674,"ml-security":0.0991856006}}
{"text":"Then, we analyze and compare several practical implementations of sequence selection by taking into account interaction with forward error correction (FEC) and complexity.","meta":{"url":"http://arxiv.org/abs/2307.13292v1"},"cats":{"new-dataset":0.036671044,"dev-research":0.2226861594,"prompt-eng":0.4294068332,"data-quality":0.2040712699,"ml-security":0.0653084399}}
{"text":"Overall, the single block and the multi block FEC-independent bit scrambling are the best options, with a gain up to 0.08 bit/s/Hz.","meta":{"url":"http://arxiv.org/abs/2307.13292v1"},"cats":{"new-dataset":0.0945982678,"dev-research":0.1558414277,"prompt-eng":0.4025368294,"data-quality":0.0943479643,"ml-security":0.0807180297}}
{"text":"The main challenge and limitation to their practical implementation remains the evaluation of the metric, whose complexity is currently too high.","meta":{"url":"http://arxiv.org/abs/2307.13292v1"},"cats":{"new-dataset":0.1157612225,"dev-research":0.2405566401,"prompt-eng":0.352572983,"data-quality":0.2395921686,"ml-security":0.0799424295}}
{"text":"Finally, we show that the nonlinear shaping gain provided by sequence selection persists when carrier phase recovery is included.","meta":{"url":"http://arxiv.org/abs/2307.13292v1"},"cats":{"new-dataset":0.0221816349,"dev-research":0.1762920329,"prompt-eng":0.4115127616,"data-quality":0.1746605586,"ml-security":0.0983528461}}
{"text":"Background: Biomedical data are usually collections of longitudinal data assessed at certain points in time.","meta":{"url":"http://arxiv.org/abs/2307.13288v1"},"cats":{"new-dataset":0.1857481034,"dev-research":0.1871662743,"prompt-eng":0.3732515194,"data-quality":0.1199212318,"ml-security":0.0642222778}}
{"text":"Clinical observations assess the presences and severity of symptoms, which are the basis for description and modeling of disease progression.","meta":{"url":"http://arxiv.org/abs/2307.13288v1"},"cats":{"new-dataset":0.0430832598,"dev-research":0.2837962425,"prompt-eng":0.4707423553,"data-quality":0.112352392,"ml-security":0.0598121251}}
{"text":"Deciphering potential underlying unknowns solely from the distinct observation would substantially improve the understanding of pathological cascades.","meta":{"url":"http://arxiv.org/abs/2307.13288v1"},"cats":{"new-dataset":0.0175342532,"dev-research":0.2630131332,"prompt-eng":0.3841385921,"data-quality":0.2425764638,"ml-security":0.2261616144}}
{"text":"Hidden Markov Models (HMMs) have been successfully applied to the processing of possibly noisy continuous signals.","meta":{"url":"http://arxiv.org/abs/2307.13288v1"},"cats":{"new-dataset":0.0760771706,"dev-research":0.1618778462,"prompt-eng":0.4105304687,"data-quality":0.2453554831,"ml-security":0.1557270738}}
{"text":"The aim was to improve the application HMMs to multivariate time-series of categorically distributed data.","meta":{"url":"http://arxiv.org/abs/2307.13288v1"},"cats":{"new-dataset":0.2422869397,"dev-research":0.1470315168,"prompt-eng":0.375095316,"data-quality":0.1119531554,"ml-security":0.0758074151}}
{"text":"Here, we used HHMs to study prediction of the loss of free walking ability as one major clinical deterioration in the most common autosomal dominantly inherited ataxia disorder worldwide.","meta":{"url":"http://arxiv.org/abs/2307.13288v1"},"cats":{"new-dataset":0.0629303553,"dev-research":0.225297182,"prompt-eng":0.4308675905,"data-quality":0.1604697213,"ml-security":0.0973089556}}
{"text":"We used HHMs to investigate the prediction of loss of the ability to walk freely, representing a major clinical deterioration in the most common autosomal-dominant inherited ataxia disorder worldwide.   ","meta":{"url":"http://arxiv.org/abs/2307.13288v1"},"cats":{"new-dataset":0.0406632455,"dev-research":0.2155954913,"prompt-eng":0.4303865277,"data-quality":0.1590389614,"ml-security":0.1008361705}}
{"text":"Results: We present a prediction pipeline which processes data paired with a configuration file, enabling to construct, validate and query a fully parameterized HMM-based model.","meta":{"url":"http://arxiv.org/abs/2307.13288v1"},"cats":{"new-dataset":0.4352923631,"dev-research":0.2367261751,"prompt-eng":0.4913613639,"data-quality":0.1562734202,"ml-security":0.1093027902}}
{"text":"In particular, we provide a theoretical and practical framework for multivariate time-series inference based on HMMs that includes constructing multiple HMMs, each to predict a particular observable variable.","meta":{"url":"http://arxiv.org/abs/2307.13288v1"},"cats":{"new-dataset":0.185940298,"dev-research":0.1475085767,"prompt-eng":0.405041728,"data-quality":0.1099866478,"ml-security":0.1247122783}}
{"text":"Our analysis is done on random data, but also on biomedical data based on Spinocerebellar ataxia type 3 disease.   ","meta":{"url":"http://arxiv.org/abs/2307.13288v1"},"cats":{"new-dataset":0.1852513561,"dev-research":0.1811550948,"prompt-eng":0.3892887339,"data-quality":0.1289653527,"ml-security":0.088174491}}
{"text":"Conclusions: HHMs are a promising approach to study biomedical data that naturally are represented as multivariate time-series.","meta":{"url":"http://arxiv.org/abs/2307.13288v1"},"cats":{"new-dataset":0.1086383945,"dev-research":0.1609303717,"prompt-eng":0.3333774308,"data-quality":0.0797550186,"ml-security":0.0588819818}}
{"text":"Our implementation of a HHMs framework is publicly available and can easily be adapted for further applications.","meta":{"url":"http://arxiv.org/abs/2307.13288v1"},"cats":{"new-dataset":0.2110987325,"dev-research":0.2405713137,"prompt-eng":0.454815407,"data-quality":0.0850832272,"ml-security":0.0544680978}}
{"text":"Spawning duplicate requests, called cloning, is a powerful technique to reduce tail latency by masking service-time variability.","meta":{"url":"http://arxiv.org/abs/2307.13285v1"},"cats":{"new-dataset":0.0305044055,"dev-research":0.296485882,"prompt-eng":0.4787378291,"data-quality":0.1377735768,"ml-security":0.1424127094}}
{"text":"However, traditional client-based cloning is static and harmful to performance under high load, while a recent coordinator-based approach is slow and not scalable.","meta":{"url":"http://arxiv.org/abs/2307.13285v1"},"cats":{"new-dataset":0.0626682174,"dev-research":0.3727082353,"prompt-eng":0.4543998561,"data-quality":0.1032646616,"ml-security":0.0695698156}}
{"text":"Both approaches are insufficient to serve modern microsecond-scale Remote Procedure Calls (RPCs).","meta":{"url":"http://arxiv.org/abs/2307.13285v1"},"cats":{"new-dataset":0.0568355512,"dev-research":0.3355473014,"prompt-eng":0.3863131697,"data-quality":0.0964674494,"ml-security":0.0764782406}}
{"text":"To this end, we present NetClone, a request cloning system that performs cloning decisions dynamically within nanoseconds at scale.","meta":{"url":"http://arxiv.org/abs/2307.13285v1"},"cats":{"new-dataset":0.1941218665,"dev-research":0.3012438579,"prompt-eng":0.4968103908,"data-quality":0.107535113,"ml-security":0.1296436007}}
{"text":"Rather than the client or the coordinator, NetClone performs request cloning in the network switch by leveraging the capability of programmable switch ASICs.","meta":{"url":"http://arxiv.org/abs/2307.13285v1"},"cats":{"new-dataset":0.0209344921,"dev-research":0.3389328471,"prompt-eng":0.453336369,"data-quality":0.1026151692,"ml-security":0.0990113107}}
{"text":"Specifically, NetClone replicates requests based on server states and blocks redundant responses using request fingerprints in the switch data plane.","meta":{"url":"http://arxiv.org/abs/2307.13285v1"},"cats":{"new-dataset":0.0497117457,"dev-research":0.2711460013,"prompt-eng":0.444184538,"data-quality":0.1141345026,"ml-security":0.1772809909}}
{"text":"To realize the idea while satisfying the strict hardware constraints, we address several technical challenges when designing a custom switch data plane.","meta":{"url":"http://arxiv.org/abs/2307.13285v1"},"cats":{"new-dataset":0.2157050305,"dev-research":0.2868637509,"prompt-eng":0.4333353991,"data-quality":0.0914588801,"ml-security":0.0730186938}}
{"text":"NetClone can be integrated with emerging in-network request schedulers like RackSched.","meta":{"url":"http://arxiv.org/abs/2307.13285v1"},"cats":{"new-dataset":0.0583786292,"dev-research":0.2562288574,"prompt-eng":0.4380988503,"data-quality":0.0836943626,"ml-security":0.088895974}}
{"text":"We implement a NetClone prototype with an Intel Tofino switch and a cluster of commodity servers.","meta":{"url":"http://arxiv.org/abs/2307.13285v1"},"cats":{"new-dataset":0.2183580178,"dev-research":0.2786751081,"prompt-eng":0.4165473579,"data-quality":0.091418887,"ml-security":0.0926605019}}
{"text":"Our experimental results show that NetClone can improve the tail latency of microsecond-scale RPCs for synthetic and real-world application workloads and is robust to various system conditions.","meta":{"url":"http://arxiv.org/abs/2307.13285v1"},"cats":{"new-dataset":0.1368943681,"dev-research":0.314639492,"prompt-eng":0.4013236214,"data-quality":0.0923569704,"ml-security":0.089900865}}
{"text":"We present a novel method for reconstructing clothed humans from a sparse set of, e.g., 1 to 6 RGB images.","meta":{"url":"http://arxiv.org/abs/2307.13282v1"},"cats":{"new-dataset":0.6023746066,"dev-research":0.1650980497,"prompt-eng":0.3948179037,"data-quality":0.121499044,"ml-security":0.0844239552}}
{"text":"Despite impressive results from recent works employing deep implicit representation, we revisit the volumetric approach and demonstrate that better performance can be achieved with proper system design.","meta":{"url":"http://arxiv.org/abs/2307.13282v1"},"cats":{"new-dataset":0.1677281121,"dev-research":0.260436569,"prompt-eng":0.3609019413,"data-quality":0.1568192322,"ml-security":0.1040960117}}
{"text":"The volumetric representation offers significant advantages in leveraging 3D spatial context through 3D convolutions, and the notorious quantization error is largely negligible with a reasonably large yet affordable volume resolution, e.g., 512.","meta":{"url":"http://arxiv.org/abs/2307.13282v1"},"cats":{"new-dataset":0.2330380164,"dev-research":0.2141996449,"prompt-eng":0.3051885465,"data-quality":0.1227120539,"ml-security":0.0729512345}}
{"text":"To handle memory and computation costs, we propose a sophisticated coarse-to-fine strategy with voxel culling and subspace sparse convolution.","meta":{"url":"http://arxiv.org/abs/2307.13282v1"},"cats":{"new-dataset":0.2402499354,"dev-research":0.231995195,"prompt-eng":0.3374193172,"data-quality":0.1579528626,"ml-security":0.1017564161}}
{"text":"Our method starts with a discretized visual hull to compute a coarse shape and then focuses on a narrow band nearby the coarse shape for refinement.","meta":{"url":"http://arxiv.org/abs/2307.13282v1"},"cats":{"new-dataset":0.346688517,"dev-research":0.2026661433,"prompt-eng":0.39366507,"data-quality":0.0984527837,"ml-security":0.0357314945}}
{"text":"Once the shape is reconstructed, we adopt an image-based rendering approach, which computes the colors of surface points by blending input images with learned weights.","meta":{"url":"http://arxiv.org/abs/2307.13282v1"},"cats":{"new-dataset":0.1981413238,"dev-research":0.2041594133,"prompt-eng":0.3643116472,"data-quality":0.1013796428,"ml-security":0.0796994259}}
{"text":"Extensive experimental results show that our method significantly reduces the mean point-to-surface (P2S) precision of state-of-the-art methods by more than 50% to achieve approximately 2mm accuracy with a 512 volume resolution.","meta":{"url":"http://arxiv.org/abs/2307.13282v1"},"cats":{"new-dataset":0.0434348744,"dev-research":0.1919753255,"prompt-eng":0.4194741096,"data-quality":0.1803137082,"ml-security":0.0298861289}}
{"text":"Additionally, images rendered from our textured model achieve a higher peak signal-to-noise ratio (PSNR) compared to state-of-the-art methods.","meta":{"url":"http://arxiv.org/abs/2307.13282v1"},"cats":{"new-dataset":0.13227696,"dev-research":0.1861772114,"prompt-eng":0.4174498987,"data-quality":0.1558863179,"ml-security":0.054568079}}
{"text":"The prediction of molecular properties is one of the most important and challenging tasks in the field of artificial intelligence-based drug design.","meta":{"url":"http://arxiv.org/abs/2307.13275v1"},"cats":{"new-dataset":0.0432682716,"dev-research":0.169574134,"prompt-eng":0.3685399836,"data-quality":0.0934416333,"ml-security":0.1336865701}}
{"text":"Among the current mainstream methods, the most commonly used feature representation for training DNN models is based on SMILES and molecular graphs, although these methods are concise and effective, they also limit the ability to capture spatial information.","meta":{"url":"http://arxiv.org/abs/2307.13275v1"},"cats":{"new-dataset":0.2408422426,"dev-research":0.2919029108,"prompt-eng":0.3338228566,"data-quality":0.1832615622,"ml-security":0.1261916785}}
{"text":"In this work, we propose Curvature-based Transformer to improve the ability of Graph Transformer neural network models to extract structural information on molecular graph data by introducing Discretization of Ricci Curvature.","meta":{"url":"http://arxiv.org/abs/2307.13275v1"},"cats":{"new-dataset":0.0651834079,"dev-research":0.1555157702,"prompt-eng":0.3006583005,"data-quality":0.1238536121,"ml-security":0.0866010782}}
